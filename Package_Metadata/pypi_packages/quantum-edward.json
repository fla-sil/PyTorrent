{"info": {"author": "Robert Tucci", "author_email": "Robert.Tucci@artiste-qb.net", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Quantum Edward\n\n## Installation\n\nYou can install Quantum Edward from the Python package manager `pip` using:\n```\npip install qedward --user\n```\n\nQuantum Edward at this point is just a small library of Python tools for \ndoing classical supervised learning on Quantum Neural Networks (QNNs). \n\nAn analytical model of the QNN is entered as input into QEdward and the training\nis done on a classical computer, using training data already available (e.g., \nMNIST), and using the famous BBVI (Black Box Variational Inference) method \ndescribed in Reference 1 below. \n\nThe input analytical model of the QNN is given as a sequence of gate \noperations for a gate model quantum computer. The hidden variables are \nangles by which the qubits are rotated. The observed variables are the input \nand output of the quantum circuit. Since it is already expressed in the qc's \nnative language, once the QNN has been trained using QEdward, it can be \nrun immediately on a physical gate model qc such as the ones that IBM and \nGoogle have already built. By running the QNN on a qc and doing \nclassification with it, we can compare the performance in classification \ntasks of QNNs and classical artificial neural nets (ANNs). \n\nOther workers have proposed training a QNN on an actual physical qc. But \ncurrent qc's are still fairly quantum noisy. Training an analytical QNN on a \nclassical computer might yield better results than training it on a qc \nbecause in the first strategy, the qc's quantum noise does not degrade the \ntraining. \n\nThe BBVI method is a mainstay of the \"Edward\" software library. Edward uses \nGoogle's TensorFlow lib to implement various inference methods (Monte Carlo \nand Variational ones) for Classical Bayesian Networks and for Hierarchical \nModels. H.M.s (pioneered by Andrew Gelman) are a subset of C.B. nets \n(pioneered by Judea Pearl). Edward is now officially a part of TensorFlow, \nand the original author of Edward, Dustin Tran, now works for Google. Before \nEdward came along, TensorFlow could only do networks with deterministic \nnodes. With the addition of Edward, TensorFlow now can do nets with both \ndeterministic and non-deterministic (probabilistic) nodes. \n\nThis first baby-step lib does not do distributed computing. The hope is that \nit can be used as a kindergarten to learn about these techniques, and that \nthen the lessons learned can be used to write a library that does the same \nthing, classical supervised learning on QNNs, but in a distributed fashion \nusing Edward/TensorFlow on the cloud. \n\nThe first version of Quantum Edward analyzes two QNN models called NbTrols \nand NoNbTrols. These two models were chosen because they are interesting to \nthe author, but the author attempted to make the library general enough so \nthat it can accommodate other akin models in the future. The allowable \nmodels are referred to as QNNs because they consist of 'layers', \nas do classical ANNs (Artificial Neural Nets). TensorFlow can analyze \nlayered models (e.g., ANN) or more general DAG (directed acyclic graph) \nmodels (e.g., Bayesian networks). \n\nThis software is distributed under the MIT License.\n\nReferences\n----------\n\n1. R. Ranganath, S. Gerrish, D. M. Blei, \"Black Box Variational\nInference\", https://arxiv.org/abs/1401.0118\n\n2. https://en.wikipedia.org/wiki/Stochastic_approximation\ndiscusses Robbins-Monro conditions\n\n3. https://github.com/keyonvafa/logistic-reg-bbvi-blog/blob/master/log_reg_bbvi.py\n\n4. http://edwardlib.org/\n\n5. https://discourse.edwardlib.org/\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/artiste-qb-net/Quantum_Edward", "keywords": "Quantum Neural Networks", "license": "", "maintainer": "", "maintainer_email": "", "name": "quantum-edward", "package_url": "https://pypi.org/project/quantum-edward/", "platform": "", "project_url": "https://pypi.org/project/quantum-edward/", "project_urls": {"Homepage": "https://github.com/artiste-qb-net/Quantum_Edward"}, "release_url": "https://pypi.org/project/quantum-edward/0.0.0/", "requires_dist": ["numpy", "matplotlib", "scipy"], "requires_python": "", "summary": "Python tools for supervised learning by Quantum Neural Networks.", "version": "0.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Quantum Edward</h1>\n<h2>Installation</h2>\n<p>You can install Quantum Edward from the Python package manager <code>pip</code> using:</p>\n<pre><code>pip install qedward --user\n</code></pre>\n<p>Quantum Edward at this point is just a small library of Python tools for\ndoing classical supervised learning on Quantum Neural Networks (QNNs).</p>\n<p>An analytical model of the QNN is entered as input into QEdward and the training\nis done on a classical computer, using training data already available (e.g.,\nMNIST), and using the famous BBVI (Black Box Variational Inference) method\ndescribed in Reference 1 below.</p>\n<p>The input analytical model of the QNN is given as a sequence of gate\noperations for a gate model quantum computer. The hidden variables are\nangles by which the qubits are rotated. The observed variables are the input\nand output of the quantum circuit. Since it is already expressed in the qc's\nnative language, once the QNN has been trained using QEdward, it can be\nrun immediately on a physical gate model qc such as the ones that IBM and\nGoogle have already built. By running the QNN on a qc and doing\nclassification with it, we can compare the performance in classification\ntasks of QNNs and classical artificial neural nets (ANNs).</p>\n<p>Other workers have proposed training a QNN on an actual physical qc. But\ncurrent qc's are still fairly quantum noisy. Training an analytical QNN on a\nclassical computer might yield better results than training it on a qc\nbecause in the first strategy, the qc's quantum noise does not degrade the\ntraining.</p>\n<p>The BBVI method is a mainstay of the \"Edward\" software library. Edward uses\nGoogle's TensorFlow lib to implement various inference methods (Monte Carlo\nand Variational ones) for Classical Bayesian Networks and for Hierarchical\nModels. H.M.s (pioneered by Andrew Gelman) are a subset of C.B. nets\n(pioneered by Judea Pearl). Edward is now officially a part of TensorFlow,\nand the original author of Edward, Dustin Tran, now works for Google. Before\nEdward came along, TensorFlow could only do networks with deterministic\nnodes. With the addition of Edward, TensorFlow now can do nets with both\ndeterministic and non-deterministic (probabilistic) nodes.</p>\n<p>This first baby-step lib does not do distributed computing. The hope is that\nit can be used as a kindergarten to learn about these techniques, and that\nthen the lessons learned can be used to write a library that does the same\nthing, classical supervised learning on QNNs, but in a distributed fashion\nusing Edward/TensorFlow on the cloud.</p>\n<p>The first version of Quantum Edward analyzes two QNN models called NbTrols\nand NoNbTrols. These two models were chosen because they are interesting to\nthe author, but the author attempted to make the library general enough so\nthat it can accommodate other akin models in the future. The allowable\nmodels are referred to as QNNs because they consist of 'layers',\nas do classical ANNs (Artificial Neural Nets). TensorFlow can analyze\nlayered models (e.g., ANN) or more general DAG (directed acyclic graph)\nmodels (e.g., Bayesian networks).</p>\n<p>This software is distributed under the MIT License.</p>\n<h2>References</h2>\n<ol>\n<li>\n<p>R. Ranganath, S. Gerrish, D. M. Blei, \"Black Box Variational\nInference\", <a href=\"https://arxiv.org/abs/1401.0118\" rel=\"nofollow\">https://arxiv.org/abs/1401.0118</a></p>\n</li>\n<li>\n<p><a href=\"https://en.wikipedia.org/wiki/Stochastic_approximation\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Stochastic_approximation</a>\ndiscusses Robbins-Monro conditions</p>\n</li>\n<li>\n<p><a href=\"https://github.com/keyonvafa/logistic-reg-bbvi-blog/blob/master/log_reg_bbvi.py\" rel=\"nofollow\">https://github.com/keyonvafa/logistic-reg-bbvi-blog/blob/master/log_reg_bbvi.py</a></p>\n</li>\n<li>\n<p><a href=\"http://edwardlib.org/\" rel=\"nofollow\">http://edwardlib.org/</a></p>\n</li>\n<li>\n<p><a href=\"https://discourse.edwardlib.org/\" rel=\"nofollow\">https://discourse.edwardlib.org/</a></p>\n</li>\n</ol>\n\n          </div>"}, "last_serial": 4460734, "releases": {"0.0.0": [{"comment_text": "", "digests": {"md5": "6779c58a648abaa7780cddfe45416de2", "sha256": "3ca0a36c694aac2100c9536b58e08802fd505a1cd520f1d5022e0dc8535c7cd2"}, "downloads": -1, "filename": "quantum_edward-0.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6779c58a648abaa7780cddfe45416de2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 18294, "upload_time": "2018-11-07T09:51:28", "upload_time_iso_8601": "2018-11-07T09:51:28.563623Z", "url": "https://files.pythonhosted.org/packages/e5/c8/c79afb49272c9949c1dc0c7479382003f477418fd19cff5abd9f7447003b/quantum_edward-0.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a9add5eb70c27532b16b338dfd143ecd", "sha256": "5784d7d7bd263cb6cd0ba8c9a33bb105ee06383526bfe1ec0e8f3af45ea41cab"}, "downloads": -1, "filename": "quantum_edward-0.0.0.tar.gz", "has_sig": false, "md5_digest": "a9add5eb70c27532b16b338dfd143ecd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15494, "upload_time": "2018-11-07T09:51:30", "upload_time_iso_8601": "2018-11-07T09:51:30.750592Z", "url": "https://files.pythonhosted.org/packages/b6/b9/7564600f1325b3778bf35a6dd7db10ba73ebdcb93796096f660c5cf7e0cc/quantum_edward-0.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6779c58a648abaa7780cddfe45416de2", "sha256": "3ca0a36c694aac2100c9536b58e08802fd505a1cd520f1d5022e0dc8535c7cd2"}, "downloads": -1, "filename": "quantum_edward-0.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6779c58a648abaa7780cddfe45416de2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 18294, "upload_time": "2018-11-07T09:51:28", "upload_time_iso_8601": "2018-11-07T09:51:28.563623Z", "url": "https://files.pythonhosted.org/packages/e5/c8/c79afb49272c9949c1dc0c7479382003f477418fd19cff5abd9f7447003b/quantum_edward-0.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a9add5eb70c27532b16b338dfd143ecd", "sha256": "5784d7d7bd263cb6cd0ba8c9a33bb105ee06383526bfe1ec0e8f3af45ea41cab"}, "downloads": -1, "filename": "quantum_edward-0.0.0.tar.gz", "has_sig": false, "md5_digest": "a9add5eb70c27532b16b338dfd143ecd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15494, "upload_time": "2018-11-07T09:51:30", "upload_time_iso_8601": "2018-11-07T09:51:30.750592Z", "url": "https://files.pythonhosted.org/packages/b6/b9/7564600f1325b3778bf35a6dd7db10ba73ebdcb93796096f660c5cf7e0cc/quantum_edward-0.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:08:50 2020"}