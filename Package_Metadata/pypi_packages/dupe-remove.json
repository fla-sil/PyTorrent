{"info": {"author": "Sanhe Hu", "author_email": "husanhe@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: Unix", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6"], "description": "\n.. image:: https://readthedocs.org/projects/dupe_remove/badge/?version=latest\n    :target: https://dupe_remove.readthedocs.io/index.html\n    :alt: Documentation Status\n\n.. image:: https://travis-ci.org/MacHu-GWU/dupe_remove-project.svg?branch=master\n    :target: https://travis-ci.org/MacHu-GWU/dupe_remove-project?branch=master\n\n.. image:: https://codecov.io/gh/MacHu-GWU/dupe_remove-project/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/MacHu-GWU/dupe_remove-project\n\n.. image:: https://img.shields.io/pypi/v/dupe_remove.svg\n    :target: https://pypi.python.org/pypi/dupe_remove\n\n.. image:: https://img.shields.io/pypi/l/dupe_remove.svg\n    :target: https://pypi.python.org/pypi/dupe_remove\n\n.. image:: https://img.shields.io/pypi/pyversions/dupe_remove.svg\n    :target: https://pypi.python.org/pypi/dupe_remove\n\n.. image:: https://img.shields.io/badge/STAR_Me_on_GitHub!--None.svg?style=social\n    :target: https://github.com/MacHu-GWU/dupe_remove-project\n\n------\n\n\n.. image:: https://img.shields.io/badge/Link-Document-blue.svg\n      :target: https://dupe_remove.readthedocs.io/index.html\n\n.. image:: https://img.shields.io/badge/Link-API-blue.svg\n      :target: https://dupe_remove.readthedocs.io/py-modindex.html\n\n.. image:: https://img.shields.io/badge/Link-Source_Code-blue.svg\n      :target: https://dupe_remove.readthedocs.io/py-modindex.html\n\n.. image:: https://img.shields.io/badge/Link-Install-blue.svg\n      :target: `install`_\n\n.. image:: https://img.shields.io/badge/Link-GitHub-blue.svg\n      :target: https://github.com/MacHu-GWU/dupe_remove-project\n\n.. image:: https://img.shields.io/badge/Link-Submit_Issue-blue.svg\n      :target: https://github.com/MacHu-GWU/dupe_remove-project/issues\n\n.. image:: https://img.shields.io/badge/Link-Request_Feature-blue.svg\n      :target: https://github.com/MacHu-GWU/dupe_remove-project/issues\n\n.. image:: https://img.shields.io/badge/Link-Download-blue.svg\n      :target: https://pypi.org/pypi/dupe_remove#files\n\n\nWelcome to ``dupe_remove`` Documentation\n==============================================================================\n\n**How come duplicate data in database?**\n\nIn OLAP database Redshift, the ``primary_key`` column doesn't apply any restriction due to performance issue. What if our ETL pipeline load duplicate same data multiple times in retry?\n\n**How** dupe_remove **solve the problem?**\n\n``dupe_remove`` use a optimized strategy to remove duplicate precisely and fast. You only need to specify:\n\n- database connection\n- table name, id column, sort key column\n\n``dupe_remove`` will do these on your own will:\n\n- remove duplicate data in specified sort key range\n- deploy as cron job on AWS Lambda to automatically remove all duplicate data in a table.\n\n\nUsage Example\n------------------------------------------------------------------------------\nOur database::\n\n    table.events\n    |-- column(id, type=string)         # id column\n    |-- column(time, type=timestamp)    # sort key column\n    |-- other columns ...\n\n\nOn Local Machine\n------------------------------------------------------------------------------\n\n.. code-block:: python\n\n    from datetime import datetime, timedelta\n    from sqlalchemy_mate import EngineCreator\n    from dupe_remove import Worker\n\n    table_name = \"events\"\n    id_col_name = \"id\"\n    sort_col_name = \"time\"\n    credential_file = \"/Users/admin/db.json\"\n    engine_creator = EngineCreator.from_json(credential_file)\n    engine = engine_creator.create_redshift()\n\n    worker = Worker(\n        engine=engine,\n        table_name=table_name,\n        id_col_name=id_col_name,\n        sort_col_name=sort_col_name,\n    )\n\n    worker.remove_duplicate(\n        lower=datetime(2018, 1, 1),\n        upper=datetime(2018, 2, 1),\n    )\n\n\nOn AWS Lambda Cron Job\n------------------------------------------------------------------------------\n\n.. code-block:: python\n\n    def handler(event, context):\n        from datetime import datetime, timedelta\n        from sqlalchemy_mate import EngineCreator\n        from dupe_remove import Scheduler, Worker, Handler\n\n        table_name = \"events\"\n        id_col_name = \"id\"\n        sort_col_name = \"time\"\n\n        engine_creator = EngineCreator.from_env(prefix=\"DEV_DB\", kms_decrypt=True)\n        engine = engine_creator.create_redshift()\n        test_connection(engine, 6)\n\n        worker = Worker(\n            engine=engine,\n            table_name=table_name,\n            id_col_name=id_col_name,\n            sort_col_name=sort_col_name,\n        )\n\n        # run every 5 min, clean 31 days data at a time from 2018-01-01,\n        # start over in 12 cycle\n        cron_freq_in_seconds = 300\n        start = datetime(2018, 1, 1)\n        delta = timedelta(days=31)\n        bin_size = 12\n        scheduler = Scheduler(\n            cron_freq_in_seconds=cron_freq_in_seconds,\n            start=start,\n            delta=delta,\n            bin_size=bin_size,\n        )\n\n        real_handler = Handler(worker=worker, scheduler=scheduler)\n        real_handler.handler(event, context)\n\n\n.. _install:\n\nInstall\n------------------------------------------------------------------------------\n\n``dupe_remove`` is released on PyPI, so all you need is:\n\n.. code-block:: console\n\n    $ pip install dupe_remove\n\nTo upgrade to latest version:\n\n.. code-block:: console\n\n    $ pip install --upgrade dupe_remove\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://pypi.python.org/pypi/dupe_remove/0.0.1#downloads", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MacHu-GWU/", "keywords": "", "license": "MIT", "maintainer": "Unknown", "maintainer_email": "", "name": "dupe-remove", "package_url": "https://pypi.org/project/dupe-remove/", "platform": "Windows", "project_url": "https://pypi.org/project/dupe-remove/", "project_urls": {"Download": "https://pypi.python.org/pypi/dupe_remove/0.0.1#downloads", "Homepage": "https://github.com/MacHu-GWU/"}, "release_url": "https://pypi.org/project/dupe-remove/0.0.1/", "requires_dist": ["six", "attrs", "sqlalchemy", "sqlalchemy-redshift", "psycopg2-binary", "loggerFactory (==0.0.5)", "sqlalchemy-mate (==0.0.7)", "sphinx (==1.8.1) ; extra == 'docs'", "sphinx-rtd-theme ; extra == 'docs'", "sphinx-jinja ; extra == 'docs'", "sphinx-copybutton ; extra == 'docs'", "docfly (>=0.0.17) ; extra == 'docs'", "rstobj (>=0.0.5) ; extra == 'docs'", "pygments ; extra == 'docs'", "pytest (==3.2.3) ; extra == 'tests'", "pytest-cov (==2.5.1) ; extra == 'tests'"], "requires_python": "", "summary": "Build Lambda Function to remove duplicate data from Redshift in minutes.", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://dupe_remove.readthedocs.io/index.html\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/298dc1afedc9bb76274d1de3319c93c28ef29e09/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f647570655f72656d6f76652f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://travis-ci.org/MacHu-GWU/dupe_remove-project?branch=master\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/MacHu-GWU/dupe_remove-project.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ca04e5a433914512557134b792c23ed2e5fa0c6e/68747470733a2f2f7472617669732d63692e6f72672f4d616348752d4757552f647570655f72656d6f76652d70726f6a6563742e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/MacHu-GWU/dupe_remove-project\" rel=\"nofollow\"><img alt=\"https://codecov.io/gh/MacHu-GWU/dupe_remove-project/branch/master/graph/badge.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6de9959246b1a6587a94a811c77a077376251b0d/68747470733a2f2f636f6465636f762e696f2f67682f4d616348752d4757552f647570655f72656d6f76652d70726f6a6563742f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/dupe_remove\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/dupe_remove.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5da28494d15bdfda182758f49d611ab111547f2e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f647570655f72656d6f76652e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/dupe_remove\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/l/dupe_remove.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/661e53983c86016dbef60306a57f3ba52e06983e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f647570655f72656d6f76652e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/dupe_remove\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/pyversions/dupe_remove.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e9fc29e5b8cb5b98839bb746b9e47b86046f3cbc/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f647570655f72656d6f76652e737667\"></a>\n<a href=\"https://github.com/MacHu-GWU/dupe_remove-project\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/STAR_Me_on_GitHub!--None.svg?style=social\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88cea09b708639318e023fda9ac4a3d3dbd4913e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f535441525f4d655f6f6e5f476974487562212d2d4e6f6e652e7376673f7374796c653d736f6369616c\"></a>\n<hr class=\"docutils\">\n<a href=\"https://dupe_remove.readthedocs.io/index.html\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-Document-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/72169197d626e9423d781eb78da036701b9d9a98/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d446f63756d656e742d626c75652e737667\"></a>\n<a href=\"https://dupe_remove.readthedocs.io/py-modindex.html\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-API-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b5c039f4ebca0e2653e6f930d982271fae9b6c62/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d4150492d626c75652e737667\"></a>\n<a href=\"https://dupe_remove.readthedocs.io/py-modindex.html\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-Source_Code-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f0d422b71b3e2a98ca914c3f9b07a6fd0ccbf6f5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d536f757263655f436f64652d626c75652e737667\"></a>\n<a href=\"#install\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-Install-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c7bf0296a17baff5c64335b1557b8c99de518863/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d496e7374616c6c2d626c75652e737667\"></a>\n<a href=\"https://github.com/MacHu-GWU/dupe_remove-project\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-GitHub-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/40760fc6f9c2f034b2f44fb3441622fd43d33f71/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d4769744875622d626c75652e737667\"></a>\n<a href=\"https://github.com/MacHu-GWU/dupe_remove-project/issues\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-Submit_Issue-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aaf85195ff7754d210475d1a26ab797376626e70/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d5375626d69745f49737375652d626c75652e737667\"></a>\n<a href=\"https://github.com/MacHu-GWU/dupe_remove-project/issues\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-Request_Feature-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/028fe51c7aa4c503e85a901affc8519722c888fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d526571756573745f466561747572652d626c75652e737667\"></a>\n<a href=\"https://pypi.org/pypi/dupe_remove#files\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/Link-Download-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/01616d53c2f6efee987f922046ed988550b12ff9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b2d446f776e6c6f61642d626c75652e737667\"></a>\n<div id=\"welcome-to-dupe-remove-documentation\">\n<h2>Welcome to <tt>dupe_remove</tt> Documentation</h2>\n<p><strong>How come duplicate data in database?</strong></p>\n<p>In OLAP database Redshift, the <tt>primary_key</tt> column doesn\u2019t apply any restriction due to performance issue. What if our ETL pipeline load duplicate same data multiple times in retry?</p>\n<p><strong>How</strong> dupe_remove <strong>solve the problem?</strong></p>\n<p><tt>dupe_remove</tt> use a optimized strategy to remove duplicate precisely and fast. You only need to specify:</p>\n<ul>\n<li>database connection</li>\n<li>table name, id column, sort key column</li>\n</ul>\n<p><tt>dupe_remove</tt> will do these on your own will:</p>\n<ul>\n<li>remove duplicate data in specified sort key range</li>\n<li>deploy as cron job on AWS Lambda to automatically remove all duplicate data in a table.</li>\n</ul>\n<div id=\"usage-example\">\n<h3>Usage Example</h3>\n<p>Our database:</p>\n<pre>table.events\n|-- column(id, type=string)         # id column\n|-- column(time, type=timestamp)    # sort key column\n|-- other columns ...\n</pre>\n</div>\n<div id=\"on-local-machine\">\n<h3>On Local Machine</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span><span class=\"p\">,</span> <span class=\"n\">timedelta</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sqlalchemy_mate</span> <span class=\"kn\">import</span> <span class=\"n\">EngineCreator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dupe_remove</span> <span class=\"kn\">import</span> <span class=\"n\">Worker</span>\n\n<span class=\"n\">table_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"events\"</span>\n<span class=\"n\">id_col_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"id\"</span>\n<span class=\"n\">sort_col_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"time\"</span>\n<span class=\"n\">credential_file</span> <span class=\"o\">=</span> <span class=\"s2\">\"/Users/admin/db.json\"</span>\n<span class=\"n\">engine_creator</span> <span class=\"o\">=</span> <span class=\"n\">EngineCreator</span><span class=\"o\">.</span><span class=\"n\">from_json</span><span class=\"p\">(</span><span class=\"n\">credential_file</span><span class=\"p\">)</span>\n<span class=\"n\">engine</span> <span class=\"o\">=</span> <span class=\"n\">engine_creator</span><span class=\"o\">.</span><span class=\"n\">create_redshift</span><span class=\"p\">()</span>\n\n<span class=\"n\">worker</span> <span class=\"o\">=</span> <span class=\"n\">Worker</span><span class=\"p\">(</span>\n    <span class=\"n\">engine</span><span class=\"o\">=</span><span class=\"n\">engine</span><span class=\"p\">,</span>\n    <span class=\"n\">table_name</span><span class=\"o\">=</span><span class=\"n\">table_name</span><span class=\"p\">,</span>\n    <span class=\"n\">id_col_name</span><span class=\"o\">=</span><span class=\"n\">id_col_name</span><span class=\"p\">,</span>\n    <span class=\"n\">sort_col_name</span><span class=\"o\">=</span><span class=\"n\">sort_col_name</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">worker</span><span class=\"o\">.</span><span class=\"n\">remove_duplicate</span><span class=\"p\">(</span>\n    <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2018</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n    <span class=\"n\">upper</span><span class=\"o\">=</span><span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2018</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"on-aws-lambda-cron-job\">\n<h3>On AWS Lambda Cron Job</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">handler</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">,</span> <span class=\"n\">context</span><span class=\"p\">):</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span><span class=\"p\">,</span> <span class=\"n\">timedelta</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">sqlalchemy_mate</span> <span class=\"kn\">import</span> <span class=\"n\">EngineCreator</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">dupe_remove</span> <span class=\"kn\">import</span> <span class=\"n\">Scheduler</span><span class=\"p\">,</span> <span class=\"n\">Worker</span><span class=\"p\">,</span> <span class=\"n\">Handler</span>\n\n    <span class=\"n\">table_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"events\"</span>\n    <span class=\"n\">id_col_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"id\"</span>\n    <span class=\"n\">sort_col_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"time\"</span>\n\n    <span class=\"n\">engine_creator</span> <span class=\"o\">=</span> <span class=\"n\">EngineCreator</span><span class=\"o\">.</span><span class=\"n\">from_env</span><span class=\"p\">(</span><span class=\"n\">prefix</span><span class=\"o\">=</span><span class=\"s2\">\"DEV_DB\"</span><span class=\"p\">,</span> <span class=\"n\">kms_decrypt</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"n\">engine</span> <span class=\"o\">=</span> <span class=\"n\">engine_creator</span><span class=\"o\">.</span><span class=\"n\">create_redshift</span><span class=\"p\">()</span>\n    <span class=\"n\">test_connection</span><span class=\"p\">(</span><span class=\"n\">engine</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">)</span>\n\n    <span class=\"n\">worker</span> <span class=\"o\">=</span> <span class=\"n\">Worker</span><span class=\"p\">(</span>\n        <span class=\"n\">engine</span><span class=\"o\">=</span><span class=\"n\">engine</span><span class=\"p\">,</span>\n        <span class=\"n\">table_name</span><span class=\"o\">=</span><span class=\"n\">table_name</span><span class=\"p\">,</span>\n        <span class=\"n\">id_col_name</span><span class=\"o\">=</span><span class=\"n\">id_col_name</span><span class=\"p\">,</span>\n        <span class=\"n\">sort_col_name</span><span class=\"o\">=</span><span class=\"n\">sort_col_name</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"c1\"># run every 5 min, clean 31 days data at a time from 2018-01-01,</span>\n    <span class=\"c1\"># start over in 12 cycle</span>\n    <span class=\"n\">cron_freq_in_seconds</span> <span class=\"o\">=</span> <span class=\"mi\">300</span>\n    <span class=\"n\">start</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"p\">(</span><span class=\"mi\">2018</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">delta</span> <span class=\"o\">=</span> <span class=\"n\">timedelta</span><span class=\"p\">(</span><span class=\"n\">days</span><span class=\"o\">=</span><span class=\"mi\">31</span><span class=\"p\">)</span>\n    <span class=\"n\">bin_size</span> <span class=\"o\">=</span> <span class=\"mi\">12</span>\n    <span class=\"n\">scheduler</span> <span class=\"o\">=</span> <span class=\"n\">Scheduler</span><span class=\"p\">(</span>\n        <span class=\"n\">cron_freq_in_seconds</span><span class=\"o\">=</span><span class=\"n\">cron_freq_in_seconds</span><span class=\"p\">,</span>\n        <span class=\"n\">start</span><span class=\"o\">=</span><span class=\"n\">start</span><span class=\"p\">,</span>\n        <span class=\"n\">delta</span><span class=\"o\">=</span><span class=\"n\">delta</span><span class=\"p\">,</span>\n        <span class=\"n\">bin_size</span><span class=\"o\">=</span><span class=\"n\">bin_size</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">real_handler</span> <span class=\"o\">=</span> <span class=\"n\">Handler</span><span class=\"p\">(</span><span class=\"n\">worker</span><span class=\"o\">=</span><span class=\"n\">worker</span><span class=\"p\">,</span> <span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"n\">scheduler</span><span class=\"p\">)</span>\n    <span class=\"n\">real_handler</span><span class=\"o\">.</span><span class=\"n\">handler</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">,</span> <span class=\"n\">context</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"id1\">\n<span id=\"install\"></span><h3>Install</h3>\n<p><tt>dupe_remove</tt> is released on PyPI, so all you need is:</p>\n<pre><span class=\"gp\">$</span> pip install dupe_remove\n</pre>\n<p>To upgrade to latest version:</p>\n<pre><span class=\"gp\">$</span> pip install --upgrade dupe_remove\n</pre>\n</div>\n</div>\n\n          </div>"}, "last_serial": 4926566, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "fcf7d7d31c6d9d572c7c50ace7ae20de", "sha256": "1b2f3e1a55a47982ed216ac658c776e24697244696e64d53936771fef132420a"}, "downloads": -1, "filename": "dupe_remove-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fcf7d7d31c6d9d572c7c50ace7ae20de", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 23662, "upload_time": "2019-03-11T19:09:43", "upload_time_iso_8601": "2019-03-11T19:09:43.655689Z", "url": "https://files.pythonhosted.org/packages/94/04/b8151b35f56cb61b9441748209b901493ecbaacf2e342625759f54aa544a/dupe_remove-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d33f9809145895491b603e7e4aa2f145", "sha256": "9579eaffa38c0a53490479c61dbc40c6b4bab9534f4ee5a5b9a4a46629cdac57"}, "downloads": -1, "filename": "dupe_remove-0.0.1.tar.gz", "has_sig": false, "md5_digest": "d33f9809145895491b603e7e4aa2f145", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18134, "upload_time": "2019-03-11T19:09:45", "upload_time_iso_8601": "2019-03-11T19:09:45.947666Z", "url": "https://files.pythonhosted.org/packages/fa/27/d6c468029aabe8e105aa78207693800840116899cd269008ea4ed0896224/dupe_remove-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fcf7d7d31c6d9d572c7c50ace7ae20de", "sha256": "1b2f3e1a55a47982ed216ac658c776e24697244696e64d53936771fef132420a"}, "downloads": -1, "filename": "dupe_remove-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fcf7d7d31c6d9d572c7c50ace7ae20de", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 23662, "upload_time": "2019-03-11T19:09:43", "upload_time_iso_8601": "2019-03-11T19:09:43.655689Z", "url": "https://files.pythonhosted.org/packages/94/04/b8151b35f56cb61b9441748209b901493ecbaacf2e342625759f54aa544a/dupe_remove-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d33f9809145895491b603e7e4aa2f145", "sha256": "9579eaffa38c0a53490479c61dbc40c6b4bab9534f4ee5a5b9a4a46629cdac57"}, "downloads": -1, "filename": "dupe_remove-0.0.1.tar.gz", "has_sig": false, "md5_digest": "d33f9809145895491b603e7e4aa2f145", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18134, "upload_time": "2019-03-11T19:09:45", "upload_time_iso_8601": "2019-03-11T19:09:45.947666Z", "url": "https://files.pythonhosted.org/packages/fa/27/d6c468029aabe8e105aa78207693800840116899cd269008ea4ed0896224/dupe_remove-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:00 2020"}