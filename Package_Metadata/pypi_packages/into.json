{"info": {"author": "Matthew Rocklin", "author_email": "mrocklin@continuum.io", "bugtrack_url": null, "classifiers": [], "description": "Into\n====\n\n|Build Status| |Doc Status|\n\nData migration in Python\n\nDocumentation_\n\nExample\n-------\n\nInto migrates data between different containers\n\n.. code-block:: python\n\n   >>> from into import into\n\n   >>> into(list, (1, 2, 3))\n   [1, 2, 3]\n\nIt operates on small, in-memory containers (as above) and large, out-of-core\ncontainers (as below)\n\n.. code-block:: python\n\n   >>> into('postgresql://user:pass@host::my-table', 'myfile.hdf5::/data')\n   Table('my-table', MetaData(bind=Engine(postgresql://user:****@host)), ...)\n\nInto leverages the existing Python ecosystem.  The example above uses\n``sqlalchemy`` for SQL interation and ``h5py`` for HDF5 interaction.\n\n\nMethod\n------\n\nInto migrates data using network of small data conersion functions between\ntype pairs. That network is below:\n\n.. image:: https://raw.githubusercontent.com/ContinuumIO/into/master/docs/source/images/conversions.png\n   :alt: into conversions\n\nEach node is a container type (like ``pandas.DataFrame`` or\n``sqlalchemy.Table``) and each directed edge is a function that transforms or\nappends one container into or onto another.  We annotate these functions/edges\nwith relative costs.\n\nThis network approach allows ``into`` to select the shortest path between any\ntwo types (thank you networkx_).  For performance reasons these functions often\nleverage non-Pythonic systems like NumPy arrays or native ``CSV->SQL`` loading\nfunctions.  Into is not dependent on only Python iterators.\n\nThis network approach is also robust.  When libraries go missing or runtime\nerrors occur ``into`` can work around these holes and find new paths.\n\nThis network approach is extensible.  It is easy to write small functions and\nregister them to the overall graph.  In the following example showing how we\nconvert from ``pandas.DataFrame`` to a ``numpy.ndarray``.\n\n.. code-block:: python\n\n   from into import convert\n\n   @convert.register(np.ndarray, pd.DataFrame, cost=1.0)\n   def dataframe_to_numpy(df, **kwargs):\n       return df.to_records(index=False)\n\nWe decorate ``convert`` functions with the target and source types as well as a\nrelative cost.  This decoration establishes a contract that the underlying\nfunction must fulfill, in this case with the fast ``DataFrame.to_records``\nmethod.  Similar functions exist for ``append``, to add to existing data, and\n``resource`` for URI resolution.\n\n* ``convert``: Transform dataset into new container\n* ``append``: Add dataset onto existing container\n* ``resource``: Given a URI find the appropriate data resource\n* ``into``: Call one of the above based on inputs.\n  E.g. ``into(list, (1, 2, 3)) -> convert(list, (1, 2, 3))``\n  while ``L = []; into(L, (1, 2, 3)) -> append(L, (1, 2, 3))``\n\nFinally, ``into`` is also aware of which containers must reside in memory and\nwhich do not.  In the graph above the *red-colored* nodes are robust to\nlarger-than-memory datasets.  Transformations between two out-of-core datasets\noperate only on the subgraph of the red nodes.\n\n\nLICENSE\n-------\n\nNew BSD. See `License File <https://github.com/ContinuumIO/into/blob/master/LICENSE.txt>`__.\n\nHistory\n-------\n\nInto was factored out from the Blaze_ project.\n\n\n.. _Blaze: http://blaze.pydata.org/\n.. _networkx: https://networkx.github.io/\n.. _Documentation: https://into.readthedocs.org/en/latest/\n.. |Build Status| image:: https://travis-ci.org/ContinuumIO/into.png\n   :target: https://travis-ci.org/ContinuumIO/into\n.. |Doc Status| image:: https://readthedocs.org/projects/into/badge/?version=latest\n   :target: https://readthedocs.org/projects/into/?badge=latest\n   :alt: Documentation Status", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/ContinuumIO/into/", "keywords": "into data conversion hdf5 sql blaze", "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "into", "package_url": "https://pypi.org/project/into/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/into/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://github.com/ContinuumIO/into/"}, "release_url": "https://pypi.org/project/into/0.2.2/", "requires_dist": null, "requires_python": null, "summary": "Data migration utilities", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/ContinuumIO/into\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d14d906b984ca7daf7b6d32865bcd88d6e5bb599/68747470733a2f2f7472617669732d63692e6f72672f436f6e74696e75756d494f2f696e746f2e706e67\"></a> <a href=\"https://readthedocs.org/projects/into/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/31296064a435674ade5e00dd7086b16c0b538231/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f696e746f2f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p>Data migration in Python</p>\n<p><a href=\"https://into.readthedocs.org/en/latest/\" rel=\"nofollow\">Documentation</a></p>\n<div id=\"example\">\n<h2>Example</h2>\n<p>Into migrates data between different containers</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">into</span> <span class=\"kn\">import</span> <span class=\"n\">into</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"nb\">list</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n<span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">]</span>\n</pre>\n<p>It operates on small, in-memory containers (as above) and large, out-of-core\ncontainers (as below)</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">into</span><span class=\"p\">(</span><span class=\"s1\">'postgresql://user:pass@host::my-table'</span><span class=\"p\">,</span> <span class=\"s1\">'myfile.hdf5::/data'</span><span class=\"p\">)</span>\n<span class=\"n\">Table</span><span class=\"p\">(</span><span class=\"s1\">'my-table'</span><span class=\"p\">,</span> <span class=\"n\">MetaData</span><span class=\"p\">(</span><span class=\"n\">bind</span><span class=\"o\">=</span><span class=\"n\">Engine</span><span class=\"p\">(</span><span class=\"n\">postgresql</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">user</span><span class=\"p\">:</span><span class=\"o\">****</span><span class=\"nd\">@host</span><span class=\"p\">)),</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<p>Into leverages the existing Python ecosystem.  The example above uses\n<tt>sqlalchemy</tt> for SQL interation and <tt>h5py</tt> for HDF5 interaction.</p>\n</div>\n<div id=\"method\">\n<h2>Method</h2>\n<p>Into migrates data using network of small data conersion functions between\ntype pairs. That network is below:</p>\n<img alt=\"into conversions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/884bdcbb74b8dc87337604898e39a90db2d2c311/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f436f6e74696e75756d494f2f696e746f2f6d61737465722f646f63732f736f757263652f696d616765732f636f6e76657273696f6e732e706e67\">\n<p>Each node is a container type (like <tt>pandas.DataFrame</tt> or\n<tt>sqlalchemy.Table</tt>) and each directed edge is a function that transforms or\nappends one container into or onto another.  We annotate these functions/edges\nwith relative costs.</p>\n<p>This network approach allows <tt>into</tt> to select the shortest path between any\ntwo types (thank you <a href=\"https://networkx.github.io/\" rel=\"nofollow\">networkx</a>).  For performance reasons these functions often\nleverage non-Pythonic systems like NumPy arrays or native <tt><span class=\"pre\">CSV-&gt;SQL</span></tt> loading\nfunctions.  Into is not dependent on only Python iterators.</p>\n<p>This network approach is also robust.  When libraries go missing or runtime\nerrors occur <tt>into</tt> can work around these holes and find new paths.</p>\n<p>This network approach is extensible.  It is easy to write small functions and\nregister them to the overall graph.  In the following example showing how we\nconvert from <tt>pandas.DataFrame</tt> to a <tt>numpy.ndarray</tt>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">into</span> <span class=\"kn\">import</span> <span class=\"n\">convert</span>\n\n<span class=\"nd\">@convert</span><span class=\"o\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">,</span> <span class=\"n\">cost</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">dataframe_to_numpy</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">to_records</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>We decorate <tt>convert</tt> functions with the target and source types as well as a\nrelative cost.  This decoration establishes a contract that the underlying\nfunction must fulfill, in this case with the fast <tt>DataFrame.to_records</tt>\nmethod.  Similar functions exist for <tt>append</tt>, to add to existing data, and\n<tt>resource</tt> for URI resolution.</p>\n<ul>\n<li><tt>convert</tt>: Transform dataset into new container</li>\n<li><tt>append</tt>: Add dataset onto existing container</li>\n<li><tt>resource</tt>: Given a URI find the appropriate data resource</li>\n<li><tt>into</tt>: Call one of the above based on inputs.\nE.g. <tt>into(list, (1, 2, 3)) <span class=\"pre\">-&gt;</span> convert(list, (1, 2, 3))</tt>\nwhile <tt>L = []; into(L, (1, 2, 3)) <span class=\"pre\">-&gt;</span> append(L, (1, 2, 3))</tt></li>\n</ul>\n<p>Finally, <tt>into</tt> is also aware of which containers must reside in memory and\nwhich do not.  In the graph above the <em>red-colored</em> nodes are robust to\nlarger-than-memory datasets.  Transformations between two out-of-core datasets\noperate only on the subgraph of the red nodes.</p>\n</div>\n<div id=\"license\">\n<h2>LICENSE</h2>\n<p>New BSD. See <a href=\"https://github.com/ContinuumIO/into/blob/master/LICENSE.txt\" rel=\"nofollow\">License File</a>.</p>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<p>Into was factored out from the <a href=\"http://blaze.pydata.org/\" rel=\"nofollow\">Blaze</a> project.</p>\n</div>\n\n          </div>"}, "last_serial": 1427215, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "209e23ad25ee103567bd9274798be047", "sha256": "603450c1e9577d0e8e830fea32d41b10a7a7a7f5ce783b9cb3a3026f985aaa8d"}, "downloads": -1, "filename": "into-0.1.0.tar.gz", "has_sig": false, "md5_digest": "209e23ad25ee103567bd9274798be047", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9328, "upload_time": "2014-12-10T01:37:35", "upload_time_iso_8601": "2014-12-10T01:37:35.030047Z", "url": "https://files.pythonhosted.org/packages/46/34/29865d4a785dbb4cef84e1a9727796a42e5f7bfe7e169b3c7a6df36ce80b/into-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "bfe5cced44f4066472779790b7c53622", "sha256": "f52e83db429180ce23827ccae10e056b7753af7a4e429dbacab3c40a46339e46"}, "downloads": -1, "filename": "into-0.1.1.tar.gz", "has_sig": false, "md5_digest": "bfe5cced44f4066472779790b7c53622", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20539, "upload_time": "2014-12-16T00:52:17", "upload_time_iso_8601": "2014-12-16T00:52:17.272008Z", "url": "https://files.pythonhosted.org/packages/c4/36/064da6148c0134184758b9193b69c895447e92aa165d0a19269c817ce366/into-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "a8897ffb45ab2dbe73ab29558529b906", "sha256": "b13bc06ce47c42a6e43708dbbff79e0a02a16365f013c689fab85c32d52fb132"}, "downloads": -1, "filename": "into-0.1.2.tar.gz", "has_sig": false, "md5_digest": "a8897ffb45ab2dbe73ab29558529b906", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30869, "upload_time": "2014-12-16T00:54:22", "upload_time_iso_8601": "2014-12-16T00:54:22.885343Z", "url": "https://files.pythonhosted.org/packages/b9/f7/f19a917e1dd86f9558477c99ddc0143d319fd6520d839ed05a57bac8e611/into-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "04f5050c24a75288122ab17acf2a9bf0", "sha256": "a92642e2a7372b477488c9d92c3e4d03b5412908dd291dd85020a7eb97c49d44"}, "downloads": -1, "filename": "into-0.1.3.tar.gz", "has_sig": false, "md5_digest": "04f5050c24a75288122ab17acf2a9bf0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31161, "upload_time": "2014-12-17T19:48:28", "upload_time_iso_8601": "2014-12-17T19:48:28.384846Z", "url": "https://files.pythonhosted.org/packages/21/71/34e00ca083a4d149ed44a322b07a4e896f1f9bbde21a93d766fad62bedff/into-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "7c4156d566d0cf0fcf82ca72d5bdf4db", "sha256": "05b6df96a1e97e07a625e646e64c499dc6abcba3dcae1daa128822373c48c3bb"}, "downloads": -1, "filename": "into-0.1.4.tar.gz", "has_sig": false, "md5_digest": "7c4156d566d0cf0fcf82ca72d5bdf4db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 51539, "upload_time": "2015-02-03T03:35:49", "upload_time_iso_8601": "2015-02-03T03:35:49.817186Z", "url": "https://files.pythonhosted.org/packages/0f/6c/d56673a37a7e08224ce53d6a9f6dd445e3e864bd553e657c391a9f14dd83/into-0.1.4.tar.gz", "yanked": false}], "0.2.0": [], "0.2.1": [{"comment_text": "", "digests": {"md5": "aa345dd2b36b9a6524b7113b35658920", "sha256": "bf4a8d7c4141984ba5db201e076d5ecfdb3a32c0f8ca311d4f49b030fcb04a2f"}, "downloads": -1, "filename": "into-0.2.1.tar.gz", "has_sig": false, "md5_digest": "aa345dd2b36b9a6524b7113b35658920", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 75510, "upload_time": "2015-02-11T06:00:03", "upload_time_iso_8601": "2015-02-11T06:00:03.817554Z", "url": "https://files.pythonhosted.org/packages/c0/ca/ad980b094558d169b735652cfb2b6848aa96403174938b438c2ddaf9f849/into-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "56efff98d9255a6073e62e958545e984", "sha256": "8a6d5595625a1c2de0732ba4448c554b707a8259b477c9b0b7bb94a1f1ca887b"}, "downloads": -1, "filename": "into-0.2.2.tar.gz", "has_sig": false, "md5_digest": "56efff98d9255a6073e62e958545e984", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 85008, "upload_time": "2015-02-17T18:52:58", "upload_time_iso_8601": "2015-02-17T18:52:58.165343Z", "url": "https://files.pythonhosted.org/packages/d8/19/b8ae3ef5df6288c42f1c119b2607825469bb4e155f4d49b714743a71af53/into-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "56efff98d9255a6073e62e958545e984", "sha256": "8a6d5595625a1c2de0732ba4448c554b707a8259b477c9b0b7bb94a1f1ca887b"}, "downloads": -1, "filename": "into-0.2.2.tar.gz", "has_sig": false, "md5_digest": "56efff98d9255a6073e62e958545e984", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 85008, "upload_time": "2015-02-17T18:52:58", "upload_time_iso_8601": "2015-02-17T18:52:58.165343Z", "url": "https://files.pythonhosted.org/packages/d8/19/b8ae3ef5df6288c42f1c119b2607825469bb4e155f4d49b714743a71af53/into-0.2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:55:23 2020"}