{"info": {"author": "Shinya Fujino", "author_email": "shf0811@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Other Environment", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: MacOS :: MacOS X", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3 :: Only", "Topic :: Education", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Text Processing :: Linguistic"], "description": "chinese\n=======\n\nchinese is a Chinese text analyzer.\n\n.. figure:: https://github.com/morinokami/chinese/blob/master/docs/overview.png?raw=true\n   :alt: Overview\n\nNOTE: Python 2.\\* is not supported.\n\nGetting Started\n---------------\n\nInstall chinese using pip:\n\n.. code:: sh\n\n    $ pip install chinese\n    $ pynlpir update\n\nStart analyzing Chinese text:\n\n.. code:: py\n\n    >>> from chinese import ChineseAnalyzer\n    >>> analyzer = ChineseAnalyzer()\n    >>> result = analyzer.parse('\u6211\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60')\n    >>> result.tokens()\n    ['\u6211', '\u5f88', '\u9ad8\u5174', '\u8ba4\u8bc6', '\u4f60']\n    >>> result.pinyin()\n    'w\u01d2 h\u011bn g\u0101ox\u00ecng r\u00e8nshi n\u01d0'\n    >>> result.pprint()\n    {'original': '\u6211\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60',\n     'parsed': [{'dict_data': [{'definitions': ['I', 'me', 'my'],\n                              'kind': 'Simplified',\n                              'match': '\u6211',\n                              'pinyin': ['wo3']}],\n               'token': ('\u6211', 0, 1)},\n               {'dict_data': [{'definitions': ['(adverb of degree)',\n                                             'quite',\n                                             'very',\n                                             'awfully'],\n                              'kind': 'Simplified',\n                              'match': '\u5f88',\n                              'pinyin': ['hen3']}],\n               'token': ('\u5f88', 1, 2)},\n               {'dict_data': [{'definitions': ['happy',\n                                             'glad',\n                                             'willing (to do sth)',\n                                             'in a cheerful mood'],\n                              'kind': 'Simplified',\n                              'match': '\u9ad8\u8208',\n                              'pinyin': ['gao1', 'xing4']}],\n               'token': ('\u9ad8\u5174', 2, 4)},\n               {'dict_data': [{'definitions': ['to know',\n                                             'to recognize',\n                                             'to be familiar with',\n                                             'to get acquainted with sb',\n                                             'knowledge',\n                                             'understanding',\n                                             'awareness',\n                                             'cognition'],\n                              'kind': 'Simplified',\n                              'match': '\u8a8d\u8b58',\n                              'pinyin': ['ren4', 'shi5']}],\n               'token': ('\u8ba4\u8bc6', 4, 6)},\n               {'dict_data': [{'definitions': ['you (informal, as opposed to '\n                                             'courteous \u60a8[nin2])'],\n                              'kind': 'Simplified',\n                              'match': '\u4f60',\n                              'pinyin': ['ni3']}],\n               'token': ('\u4f60', 6, 7)}]}\n    >>> result = analyzer.parse('\u6211\u559c\u6b61\u9019\u500b\u5473\u9053', traditional=True)\n    >>> print(res)\n    {'\u5473\u9053': [{'definitions': ['flavor', 'smell', 'hint of'],\n          'kind': 'Traditional',\n          'match': '\u5473\u9053',\n          'pinyin': ['wei4', 'dao5']}],\n     '\u559c\u6b61': [{'definitions': ['to like', 'to be fond of'],\n          'kind': 'Traditional',\n          'match': '\u559c\u6b22',\n          'pinyin': ['xi3', 'huan5']}],\n     '\u6211': [{'definitions': ['I', 'me', 'my'],\n          'kind': 'Traditional',\n          'match': '\u6211',a\n          'pinyin': ['wo3']}],\n     '\u9019\u500b': [{'definitions': ['this', 'this one'],\n          'kind': 'Traditional',\n          'match': '\u8fd9\u4e2a',\n          'pinyin': ['zhe4', 'ge5']}]}\n\nFeatures\n--------\n\n-  ``parse()`` returns a ChineseAnalyzerResult object.\n\n.. code:: py\n\n    >>> from chinese import ChineseAnalyzer\n    >>> analyzer = ChineseAnalyzer()\n    # Basic usage.\n    >>> result = analyzer.parse('\u4f60\u597d\u4e16\u754c')\n    # If the traditional option is set to True, the analyzer tries to parse the\n    # provided text as \u7e41\u4f53\u5b57.\n    >>> result = analyzer.parse('\u4f60\u597d\u4e16\u754c', traditional=True)\n    # The default tokenizer uses jieba's. You can also use pynlpir's to tokenize.\n    >>> result = analyzer.parse('\u4f60\u597d\u4e16\u754c', using=analyzer.tokenizer.pynlpir)\n    # In addition, a custom tokenizer can be passed to the method.\n    >>> from chinese.tokenizer import TokenizerInterface\n    >>> class MyTokenizer(TokenizerInterface): # Custom tokenizer must inherit from TokenizerInterface.\n    ...     # Custom tokenizer must implement tokenize() method.\n    ...     def tokenize(self, string):\n    ...         # tokenize() must return a list of tuples containing at least\n    ...         # a string as a first element.\n    ...         # For example: [('token1', ...), ('token2', ...), ...].\n    ...\n    >>> my_tokenizer = MyTokenizer()\n    >>> result = analyzer.parse('\u4f60\u597d\u4e16\u754c', using=my_tokenizer)\n    # You can also specify the dictionary used for looking up each token.\n    # You specify a path to a dictionary file for that and the file must have\n    # the CC-CEDICT's dictionary file structure.\n    # CC-CEDICT's dictionary is used for looking up by default.\n    >>> result = analyzer.parse('\u4f60\u597d\u4e16\u754c', dictionary='path/to/dict')\n\n-  ``original()`` returns the supplied text as is.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u6211\u6700\u559c\u6b22\u5403\u6c34\u716e\u8089\u7247')\n    >>> result.original()\n    '\u6211\u6700\u559c\u6b22\u5403\u6c34\u716e\u8089\u7247'\n\n-  ``tokens()`` returns tokens in the provided text.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u6211\u7684\u6c49\u8bed\u9a6c\u9a6c\u864e\u864e')\n    >>> result.tokens()\n    ['\u6211', '\u7684', '\u6c49\u8bed', '\u9a6c\u9a6c\u864e\u864e']\n    >>> result.tokens(details=True) # If the details option is set to True, additional information is also attached.\n    [('\u6211', 0, 1), ('\u7684', 1, 2), ('\u6c49\u8bed', 2, 4), ('\u9a6c\u9a6c\u864e\u864e', 4, 8)] # In this case, the positions of tokens are included.\n    >>> result = analyzer.parse('\u7684\u7684\u7684\u7684\u7684\u5728\u7684\u7684\u7684\u7684\u5c31\u4ee5\u548c\u548c\u548c')\n    >>> result.tokens(unique=True) # You can get a unique collection of tokens using unique option.\n    ['\u7684', '\u5728', '\u5c31', '\u4ee5', '\u548c']\n\n-  ``freq()`` returns a Counter object that counts the number of\n   occurrences for each token.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u7684\u7684\u7684\u7684\u7684\u5728\u7684\u7684\u7684\u7684\u5c31\u4ee5\u548c\u548c\u548c')\n    >>> result.freq()\n    Counter({'\u7684': 9, '\u548c': 3, '\u5728': 1, '\u5c31': 1, '\u4ee5': 1})\n\n-  ``sentences()`` returns a list of paragraphs in a provided text.\n\n.. code:: py\n\n    >>> s = '''\u60a8\u597d\u3002\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417\uff1f\n    ...\n    ... \u5728\u3002\u8bf7\u7a0d\u7b49\u3002'''\n    >>> result = analyzer.parse(s)\n    >>> result.sentences()\n    ['\u60a8\u597d', '\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417', '\u5728', '\u8bf7\u7a0d\u7b49']\n\n-  ``search()`` returns a list of sentences containing the argument\n   string.\n\n.. code:: py\n\n    >>> s = '\u81ea\u7136\u8bed\u8a00\u5904\u7406\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u4e0e\u4eba\u5de5\u667a\u80fd\u9886\u57df\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u65b9\u5411\u3002\u5b83\u7814\u7a76\u80fd\u5b9e\u73b0\u4eba\u4e0e\u8ba1\u7b97\u673a\u4e4b\u95f4\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u6709\u6548\u901a\u4fe1\u7684\u5404\u79cd\u7406\u8bba\u548c\u65b9\u6cd5\u3002\u81ea\u7136\u8bed\u8a00\u5904\u7406\u662f\u4e00\u95e8\u878d\u8bed\u8a00\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u6570\u5b66\u4e8e\u4e00\u4f53\u7684\u79d1\u5b66\u3002\u56e0\u6b64\uff0c\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u5c06\u6d89\u53ca\u81ea\u7136\u8bed\u8a00\uff0c\u5373\u4eba\u4eec\u65e5\u5e38\u4f7f\u7528\u7684\u8bed\u8a00\uff0c\u6240\u4ee5\u5b83\u4e0e\u8bed\u8a00\u5b66\u7684\u7814\u7a76\u6709\u7740\u5bc6\u5207\u7684\u8054\u7cfb\uff0c\u4f46\u53c8\u6709\u91cd\u8981\u7684\u533a\u522b\u3002\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e76\u4e0d\u662f\u4e00\u822c\u5730\u7814\u7a76\u81ea\u7136\u8bed\u8a00\uff0c\u800c\u5728\u4e8e\u7814\u5236\u80fd\u6709\u6548\u5730\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u901a\u4fe1\u7684\u8ba1\u7b97\u673a\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5176\u4e2d\u7684\u8f6f\u4ef6\u7cfb\u7edf\u3002\u56e0\u800c\u5b83\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u4e00\u90e8\u5206\u3002'\n    >>> result = analyzer.parse(s)\n    >>> result.search('\u6570\u5b66')\n    ['\u81ea\u7136\u8bed\u8a00\u5904\u7406\u662f\u4e00\u95e8\u878d\u8bed\u8a00\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u6570\u5b66\u4e8e\u4e00\u4f53\u7684\u79d1\u5b66']\n\n-  ``paragraphs()`` returns a list of sentences in a provided text.\n\n.. code:: py\n\n    >>> s = '''\u60a8\u597d\u3002\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417\uff1f\n    ...\n    ... \u5728\u3002\u8bf7\u7a0d\u7b49\u3002'''\n    >>> result = analyzer.parse(s)\n    >>> result.paragraphs()\n    ['\u60a8\u597d\u3002\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417\uff1f', '\u5728\u3002\u8bf7\u7a0d\u7b49\u3002']\n\n-  ``pinyin()`` returns a pinyin representation of the provided text.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u6211\u559c\u6b22Python\u3002')\n    >>> result.pinyin()\n    'w\u01d2 x\u01d0huan Python.'\n    >>> result = analyzer.parse('\u4e0b\u4e2a\u6708\u6211\u53bb\u6da9\u8c37')\n    >>> result.pinyin() # Sometimes the analyzer cannot find a correponding pinyin.\n    'xi\u00e0g\u00e8yu\u00e8 w\u01d2 q\u00f9 \u6da9\u8c37'\n    >>> result.pinyin(force=True) # The force option forces it to try to convert an unknown word to pinyin.\n    'xi\u00e0g\u00e8yu\u00e8 w\u01d2 q\u00f9 s\u00e8g\u01d4'\n\n-  ``pprint()`` prints a formatted description of the parsed text.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u6211\u7231\u770b\u4e66')\n    >>> result.pprint()\n    {'original': '\u6211\u7231\u770b\u4e66',\n     'parsed': [{'dict_data': [{'definitions': ['I', 'me', 'my'],\n                                'kind': 'Simplified',\n                                'match': '\u6211',\n                                'pinyin': ['wo3']}],\n                 'token': ('\u6211', 0, 1)},\n                {'dict_data': [{'definitions': ['to love',\n                                                'to be fond of',\n                                                'to like',\n                                                'affection',\n                                                'to be inclined (to do sth)',\n                                                'to tend to (happen)'],\n                                'kind': 'Simplified',\n                                'match': '\u611b',\n                                'pinyin': ['ai4']}],\n                 'token': ('\u7231', 1, 2)},\n                {'dict_data': [{'definitions': ['to read', 'to study'],\n                                'kind': 'Simplified',\n                                'match': '\u770b\u66f8',\n                                'pinyin': ['kan4', 'shu1']}],\n                 'token': ('\u770b\u4e66', 2, 4)}]}\n\n-  ``say()`` converts the provided text to Chinese audible speech (macOS\n   only).\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u60a8\u597d\uff0c\u6211\u53ebTing-Ting\u3002\u6211\u8bb2\u4e2d\u6587\u666e\u901a\u8bdd\u3002')\n    >>> result.say()              # Output the speech.\n    >>> result.say(out='say.aac') # Save the speech to out.\n\n-  Get the number of tokens.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u6211\u662f\u4e2d\u56fd\u4eba')\n    >>> result.tokens()\n    ['\u6211', '\u662f', '\u4e2d\u56fd', '\u4eba']\n    >>> len(result)\n    4\n\n-  Check whether a token is in the result.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u6211\u662f\u4e2d\u56fd\u4eba')\n    >>> '\u4e2d\u56fd' in result\n    True\n    >>> '\u6211\u662f' in result\n    False\n\n-  Extract the lookup result.\n\n.. code:: py\n\n    >>> result = analyzer.parse('\u4f60\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f')\n    >>> result.tokens()\n    ['\u4f60', '\u53eb', '\u4ec0\u4e48', '\u540d\u5b57', '\uff1f']\n    >>> shenme = result['\u4ec0\u4e48'] # It's just a list of lookup results.\n    >>> len(shenme)             # It has only one entry.\n    1\n    >>> print(shenme[0])        # Print that entry.\n    {'definitions': ['what?', 'something', 'anything'],\n     'kind': 'Simplified',\n     'match': '\u4ec0\u9ebc',\n     'pinyin': ['shen2', 'me5']}\n    >>> shenme_info = shenme[0]\n    >>> shenme_info.definitions # Definitions of the token.\n    ['what?', 'something', 'anything']\n    >>> shenme_info.match       # The corresponding \u7e41\u4f53\u5b57.\n    '\u4ec0\u9ebc'\n    >>> shenme_info.pinyin      # The pinyin of the token.\n    ['shen2', 'me5']\n\nLicense\n-------\n\nMIT License\n\nThanks\n------\n\n`jieba <https://github.com/fxsjy/jieba>`__ and\n`PyNLPIR <https://github.com/tsroten/pynlpir>`__ are used to tokenize a\nChinese text.\n\n`CC-CEDICT <https://www.mdbg.net/chinese/dictionary?page=cc-cedict>`__\nis used to lookup information for tokens.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/morinokami/chinese", "keywords": "Chinese,text analysis", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "chinese", "package_url": "https://pypi.org/project/chinese/", "platform": "", "project_url": "https://pypi.org/project/chinese/", "project_urls": {"Homepage": "https://github.com/morinokami/chinese"}, "release_url": "https://pypi.org/project/chinese/0.2.1/", "requires_dist": ["jieba", "pynlpir"], "requires_python": "", "summary": "Chinese text analyzer", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>chinese is a Chinese text analyzer.</p>\n<div>\n<img alt=\"Overview\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3fdcb5108d01e2a47e8ad70c69e5335357dbbaeb/68747470733a2f2f6769746875622e636f6d2f6d6f72696e6f6b616d692f6368696e6573652f626c6f622f6d61737465722f646f63732f6f766572766965772e706e673f7261773d74727565\">\n</div>\n<p>NOTE: Python 2.* is not supported.</p>\n<div id=\"getting-started\">\n<h2>Getting Started</h2>\n<p>Install chinese using pip:</p>\n<pre>$ pip install chinese\n$ pynlpir update\n</pre>\n<p>Start analyzing Chinese text:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">chinese</span> <span class=\"kn\">import</span> <span class=\"n\">ChineseAnalyzer</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">analyzer</span> <span class=\"o\">=</span> <span class=\"n\">ChineseAnalyzer</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u6211'</span><span class=\"p\">,</span> <span class=\"s1\">'\u5f88'</span><span class=\"p\">,</span> <span class=\"s1\">'\u9ad8\u5174'</span><span class=\"p\">,</span> <span class=\"s1\">'\u8ba4\u8bc6'</span><span class=\"p\">,</span> <span class=\"s1\">'\u4f60'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">pinyin</span><span class=\"p\">()</span>\n<span class=\"s1\">'w\u01d2 h\u011bn g\u0101ox\u00ecng r\u00e8nshi n\u01d0'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">pprint</span><span class=\"p\">()</span>\n<span class=\"p\">{</span><span class=\"s1\">'original'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60'</span><span class=\"p\">,</span>\n <span class=\"s1\">'parsed'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'me'</span><span class=\"p\">,</span> <span class=\"s1\">'my'</span><span class=\"p\">],</span>\n                          <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'wo3'</span><span class=\"p\">]}],</span>\n           <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u6211'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)},</span>\n           <span class=\"p\">{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'(adverb of degree)'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'quite'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'very'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'awfully'</span><span class=\"p\">],</span>\n                          <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u5f88'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'hen3'</span><span class=\"p\">]}],</span>\n           <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u5f88'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)},</span>\n           <span class=\"p\">{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'happy'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'glad'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'willing (to do sth)'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'in a cheerful mood'</span><span class=\"p\">],</span>\n                          <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u9ad8\u8208'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'gao1'</span><span class=\"p\">,</span> <span class=\"s1\">'xing4'</span><span class=\"p\">]}],</span>\n           <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u9ad8\u5174'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)},</span>\n           <span class=\"p\">{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'to know'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'to recognize'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'to be familiar with'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'to get acquainted with sb'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'knowledge'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'understanding'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'awareness'</span><span class=\"p\">,</span>\n                                         <span class=\"s1\">'cognition'</span><span class=\"p\">],</span>\n                          <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u8a8d\u8b58'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'ren4'</span><span class=\"p\">,</span> <span class=\"s1\">'shi5'</span><span class=\"p\">]}],</span>\n           <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u8ba4\u8bc6'</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">)},</span>\n           <span class=\"p\">{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'you (informal, as opposed to '</span>\n                                         <span class=\"s1\">'courteous \u60a8[nin2])'</span><span class=\"p\">],</span>\n                          <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u4f60'</span><span class=\"p\">,</span>\n                          <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'ni3'</span><span class=\"p\">]}],</span>\n           <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u4f60'</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">)}]}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u559c\u6b61\u9019\u500b\u5473\u9053'</span><span class=\"p\">,</span> <span class=\"n\">traditional</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">)</span>\n<span class=\"p\">{</span><span class=\"s1\">'\u5473\u9053'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'flavor'</span><span class=\"p\">,</span> <span class=\"s1\">'smell'</span><span class=\"p\">,</span> <span class=\"s1\">'hint of'</span><span class=\"p\">],</span>\n      <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Traditional'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u5473\u9053'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'wei4'</span><span class=\"p\">,</span> <span class=\"s1\">'dao5'</span><span class=\"p\">]}],</span>\n <span class=\"s1\">'\u559c\u6b61'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'to like'</span><span class=\"p\">,</span> <span class=\"s1\">'to be fond of'</span><span class=\"p\">],</span>\n      <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Traditional'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u559c\u6b22'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'xi3'</span><span class=\"p\">,</span> <span class=\"s1\">'huan5'</span><span class=\"p\">]}],</span>\n <span class=\"s1\">'\u6211'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'me'</span><span class=\"p\">,</span> <span class=\"s1\">'my'</span><span class=\"p\">],</span>\n      <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Traditional'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211'</span><span class=\"p\">,</span><span class=\"n\">a</span>\n      <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'wo3'</span><span class=\"p\">]}],</span>\n <span class=\"s1\">'\u9019\u500b'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'this'</span><span class=\"p\">,</span> <span class=\"s1\">'this one'</span><span class=\"p\">],</span>\n      <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Traditional'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u8fd9\u4e2a'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'zhe4'</span><span class=\"p\">,</span> <span class=\"s1\">'ge5'</span><span class=\"p\">]}]}</span>\n</pre>\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li><tt>parse()</tt> returns a ChineseAnalyzerResult object.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">chinese</span> <span class=\"kn\">import</span> <span class=\"n\">ChineseAnalyzer</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">analyzer</span> <span class=\"o\">=</span> <span class=\"n\">ChineseAnalyzer</span><span class=\"p\">()</span>\n<span class=\"c1\"># Basic usage.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4f60\u597d\u4e16\u754c'</span><span class=\"p\">)</span>\n<span class=\"c1\"># If the traditional option is set to True, the analyzer tries to parse the</span>\n<span class=\"c1\"># provided text as \u7e41\u4f53\u5b57.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4f60\u597d\u4e16\u754c'</span><span class=\"p\">,</span> <span class=\"n\">traditional</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"c1\"># The default tokenizer uses jieba's. You can also use pynlpir's to tokenize.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4f60\u597d\u4e16\u754c'</span><span class=\"p\">,</span> <span class=\"n\">using</span><span class=\"o\">=</span><span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">tokenizer</span><span class=\"o\">.</span><span class=\"n\">pynlpir</span><span class=\"p\">)</span>\n<span class=\"c1\"># In addition, a custom tokenizer can be passed to the method.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">chinese.tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">TokenizerInterface</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">class</span> <span class=\"nc\">MyTokenizer</span><span class=\"p\">(</span><span class=\"n\">TokenizerInterface</span><span class=\"p\">):</span> <span class=\"c1\"># Custom tokenizer must inherit from TokenizerInterface.</span>\n<span class=\"o\">...</span>     <span class=\"c1\"># Custom tokenizer must implement tokenize() method.</span>\n<span class=\"o\">...</span>     <span class=\"k\">def</span> <span class=\"nf\">tokenize</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">string</span><span class=\"p\">):</span>\n<span class=\"o\">...</span>         <span class=\"c1\"># tokenize() must return a list of tuples containing at least</span>\n<span class=\"o\">...</span>         <span class=\"c1\"># a string as a first element.</span>\n<span class=\"o\">...</span>         <span class=\"c1\"># For example: [('token1', ...), ('token2', ...), ...].</span>\n<span class=\"o\">...</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">my_tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">MyTokenizer</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4f60\u597d\u4e16\u754c'</span><span class=\"p\">,</span> <span class=\"n\">using</span><span class=\"o\">=</span><span class=\"n\">my_tokenizer</span><span class=\"p\">)</span>\n<span class=\"c1\"># You can also specify the dictionary used for looking up each token.</span>\n<span class=\"c1\"># You specify a path to a dictionary file for that and the file must have</span>\n<span class=\"c1\"># the CC-CEDICT's dictionary file structure.</span>\n<span class=\"c1\"># CC-CEDICT's dictionary is used for looking up by default.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4f60\u597d\u4e16\u754c'</span><span class=\"p\">,</span> <span class=\"n\">dictionary</span><span class=\"o\">=</span><span class=\"s1\">'path/to/dict'</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li><tt>original()</tt> returns the supplied text as is.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u6700\u559c\u6b22\u5403\u6c34\u716e\u8089\u7247'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">original</span><span class=\"p\">()</span>\n<span class=\"s1\">'\u6211\u6700\u559c\u6b22\u5403\u6c34\u716e\u8089\u7247'</span>\n</pre>\n<ul>\n<li><tt>tokens()</tt> returns tokens in the provided text.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u7684\u6c49\u8bed\u9a6c\u9a6c\u864e\u864e'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u6211'</span><span class=\"p\">,</span> <span class=\"s1\">'\u7684'</span><span class=\"p\">,</span> <span class=\"s1\">'\u6c49\u8bed'</span><span class=\"p\">,</span> <span class=\"s1\">'\u9a6c\u9a6c\u864e\u864e'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">(</span><span class=\"n\">details</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># If the details option is set to True, additional information is also attached.</span>\n<span class=\"p\">[(</span><span class=\"s1\">'\u6211'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u7684'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u6c49\u8bed'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u9a6c\u9a6c\u864e\u864e'</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">)]</span> <span class=\"c1\"># In this case, the positions of tokens are included.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u7684\u7684\u7684\u7684\u7684\u5728\u7684\u7684\u7684\u7684\u5c31\u4ee5\u548c\u548c\u548c'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">(</span><span class=\"n\">unique</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># You can get a unique collection of tokens using unique option.</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u7684'</span><span class=\"p\">,</span> <span class=\"s1\">'\u5728'</span><span class=\"p\">,</span> <span class=\"s1\">'\u5c31'</span><span class=\"p\">,</span> <span class=\"s1\">'\u4ee5'</span><span class=\"p\">,</span> <span class=\"s1\">'\u548c'</span><span class=\"p\">]</span>\n</pre>\n<ul>\n<li><tt>freq()</tt> returns a Counter object that counts the number of\noccurrences for each token.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u7684\u7684\u7684\u7684\u7684\u5728\u7684\u7684\u7684\u7684\u5c31\u4ee5\u548c\u548c\u548c'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">freq</span><span class=\"p\">()</span>\n<span class=\"n\">Counter</span><span class=\"p\">({</span><span class=\"s1\">'\u7684'</span><span class=\"p\">:</span> <span class=\"mi\">9</span><span class=\"p\">,</span> <span class=\"s1\">'\u548c'</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"s1\">'\u5728'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'\u5c31'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'\u4ee5'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">})</span>\n</pre>\n<ul>\n<li><tt>sentences()</tt> returns a list of paragraphs in a provided text.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"s1\">'''\u60a8\u597d\u3002\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417\uff1f\n...\n... \u5728\u3002\u8bf7\u7a0d\u7b49\u3002'''</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">sentences</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u60a8\u597d'</span><span class=\"p\">,</span> <span class=\"s1\">'\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417'</span><span class=\"p\">,</span> <span class=\"s1\">'\u5728'</span><span class=\"p\">,</span> <span class=\"s1\">'\u8bf7\u7a0d\u7b49'</span><span class=\"p\">]</span>\n</pre>\n<ul>\n<li><tt>search()</tt> returns a list of sentences containing the argument\nstring.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"s1\">'\u81ea\u7136\u8bed\u8a00\u5904\u7406\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u4e0e\u4eba\u5de5\u667a\u80fd\u9886\u57df\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u65b9\u5411\u3002\u5b83\u7814\u7a76\u80fd\u5b9e\u73b0\u4eba\u4e0e\u8ba1\u7b97\u673a\u4e4b\u95f4\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u6709\u6548\u901a\u4fe1\u7684\u5404\u79cd\u7406\u8bba\u548c\u65b9\u6cd5\u3002\u81ea\u7136\u8bed\u8a00\u5904\u7406\u662f\u4e00\u95e8\u878d\u8bed\u8a00\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u6570\u5b66\u4e8e\u4e00\u4f53\u7684\u79d1\u5b66\u3002\u56e0\u6b64\uff0c\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u5c06\u6d89\u53ca\u81ea\u7136\u8bed\u8a00\uff0c\u5373\u4eba\u4eec\u65e5\u5e38\u4f7f\u7528\u7684\u8bed\u8a00\uff0c\u6240\u4ee5\u5b83\u4e0e\u8bed\u8a00\u5b66\u7684\u7814\u7a76\u6709\u7740\u5bc6\u5207\u7684\u8054\u7cfb\uff0c\u4f46\u53c8\u6709\u91cd\u8981\u7684\u533a\u522b\u3002\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e76\u4e0d\u662f\u4e00\u822c\u5730\u7814\u7a76\u81ea\u7136\u8bed\u8a00\uff0c\u800c\u5728\u4e8e\u7814\u5236\u80fd\u6709\u6548\u5730\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u901a\u4fe1\u7684\u8ba1\u7b97\u673a\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5176\u4e2d\u7684\u8f6f\u4ef6\u7cfb\u7edf\u3002\u56e0\u800c\u5b83\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u4e00\u90e8\u5206\u3002'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"s1\">'\u6570\u5b66'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u81ea\u7136\u8bed\u8a00\u5904\u7406\u662f\u4e00\u95e8\u878d\u8bed\u8a00\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u6570\u5b66\u4e8e\u4e00\u4f53\u7684\u79d1\u5b66'</span><span class=\"p\">]</span>\n</pre>\n<ul>\n<li><tt>paragraphs()</tt> returns a list of sentences in a provided text.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"s1\">'''\u60a8\u597d\u3002\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417\uff1f\n...\n... \u5728\u3002\u8bf7\u7a0d\u7b49\u3002'''</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">paragraphs</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u60a8\u597d\u3002\u8bf7\u95ee\u5c0f\u7f8e\u5728\u5bb6\u5417\uff1f'</span><span class=\"p\">,</span> <span class=\"s1\">'\u5728\u3002\u8bf7\u7a0d\u7b49\u3002'</span><span class=\"p\">]</span>\n</pre>\n<ul>\n<li><tt>pinyin()</tt> returns a pinyin representation of the provided text.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u559c\u6b22Python\u3002'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">pinyin</span><span class=\"p\">()</span>\n<span class=\"s1\">'w\u01d2 x\u01d0huan Python.'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4e0b\u4e2a\u6708\u6211\u53bb\u6da9\u8c37'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">pinyin</span><span class=\"p\">()</span> <span class=\"c1\"># Sometimes the analyzer cannot find a correponding pinyin.</span>\n<span class=\"s1\">'xi\u00e0g\u00e8yu\u00e8 w\u01d2 q\u00f9 \u6da9\u8c37'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">pinyin</span><span class=\"p\">(</span><span class=\"n\">force</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># The force option forces it to try to convert an unknown word to pinyin.</span>\n<span class=\"s1\">'xi\u00e0g\u00e8yu\u00e8 w\u01d2 q\u00f9 s\u00e8g\u01d4'</span>\n</pre>\n<ul>\n<li><tt>pprint()</tt> prints a formatted description of the parsed text.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u7231\u770b\u4e66'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">pprint</span><span class=\"p\">()</span>\n<span class=\"p\">{</span><span class=\"s1\">'original'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211\u7231\u770b\u4e66'</span><span class=\"p\">,</span>\n <span class=\"s1\">'parsed'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'me'</span><span class=\"p\">,</span> <span class=\"s1\">'my'</span><span class=\"p\">],</span>\n                            <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'wo3'</span><span class=\"p\">]}],</span>\n             <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u6211'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)},</span>\n            <span class=\"p\">{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'to love'</span><span class=\"p\">,</span>\n                                            <span class=\"s1\">'to be fond of'</span><span class=\"p\">,</span>\n                                            <span class=\"s1\">'to like'</span><span class=\"p\">,</span>\n                                            <span class=\"s1\">'affection'</span><span class=\"p\">,</span>\n                                            <span class=\"s1\">'to be inclined (to do sth)'</span><span class=\"p\">,</span>\n                                            <span class=\"s1\">'to tend to (happen)'</span><span class=\"p\">],</span>\n                            <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u611b'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'ai4'</span><span class=\"p\">]}],</span>\n             <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u7231'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)},</span>\n            <span class=\"p\">{</span><span class=\"s1\">'dict_data'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'to read'</span><span class=\"p\">,</span> <span class=\"s1\">'to study'</span><span class=\"p\">],</span>\n                            <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u770b\u66f8'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'kan4'</span><span class=\"p\">,</span> <span class=\"s1\">'shu1'</span><span class=\"p\">]}],</span>\n             <span class=\"s1\">'token'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'\u770b\u4e66'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)}]}</span>\n</pre>\n<ul>\n<li><tt>say()</tt> converts the provided text to Chinese audible speech (macOS\nonly).</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u60a8\u597d\uff0c\u6211\u53ebTing-Ting\u3002\u6211\u8bb2\u4e2d\u6587\u666e\u901a\u8bdd\u3002'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">say</span><span class=\"p\">()</span>              <span class=\"c1\"># Output the speech.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">say</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"o\">=</span><span class=\"s1\">'say.aac'</span><span class=\"p\">)</span> <span class=\"c1\"># Save the speech to out.</span>\n</pre>\n<ul>\n<li>Get the number of tokens.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u662f\u4e2d\u56fd\u4eba'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u6211'</span><span class=\"p\">,</span> <span class=\"s1\">'\u662f'</span><span class=\"p\">,</span> <span class=\"s1\">'\u4e2d\u56fd'</span><span class=\"p\">,</span> <span class=\"s1\">'\u4eba'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n<span class=\"mi\">4</span>\n</pre>\n<ul>\n<li>Check whether a token is in the result.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u6211\u662f\u4e2d\u56fd\u4eba'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"s1\">'\u4e2d\u56fd'</span> <span class=\"ow\">in</span> <span class=\"n\">result</span>\n<span class=\"kc\">True</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"s1\">'\u6211\u662f'</span> <span class=\"ow\">in</span> <span class=\"n\">result</span>\n<span class=\"kc\">False</span>\n</pre>\n<ul>\n<li>Extract the lookup result.</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">analyzer</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s1\">'\u4f60\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">()</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u4f60'</span><span class=\"p\">,</span> <span class=\"s1\">'\u53eb'</span><span class=\"p\">,</span> <span class=\"s1\">'\u4ec0\u4e48'</span><span class=\"p\">,</span> <span class=\"s1\">'\u540d\u5b57'</span><span class=\"p\">,</span> <span class=\"s1\">'\uff1f'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">shenme</span> <span class=\"o\">=</span> <span class=\"n\">result</span><span class=\"p\">[</span><span class=\"s1\">'\u4ec0\u4e48'</span><span class=\"p\">]</span> <span class=\"c1\"># It's just a list of lookup results.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">shenme</span><span class=\"p\">)</span>             <span class=\"c1\"># It has only one entry.</span>\n<span class=\"mi\">1</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">shenme</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>        <span class=\"c1\"># Print that entry.</span>\n<span class=\"p\">{</span><span class=\"s1\">'definitions'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'what?'</span><span class=\"p\">,</span> <span class=\"s1\">'something'</span><span class=\"p\">,</span> <span class=\"s1\">'anything'</span><span class=\"p\">],</span>\n <span class=\"s1\">'kind'</span><span class=\"p\">:</span> <span class=\"s1\">'Simplified'</span><span class=\"p\">,</span>\n <span class=\"s1\">'match'</span><span class=\"p\">:</span> <span class=\"s1\">'\u4ec0\u9ebc'</span><span class=\"p\">,</span>\n <span class=\"s1\">'pinyin'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'shen2'</span><span class=\"p\">,</span> <span class=\"s1\">'me5'</span><span class=\"p\">]}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">shenme_info</span> <span class=\"o\">=</span> <span class=\"n\">shenme</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">shenme_info</span><span class=\"o\">.</span><span class=\"n\">definitions</span> <span class=\"c1\"># Definitions of the token.</span>\n<span class=\"p\">[</span><span class=\"s1\">'what?'</span><span class=\"p\">,</span> <span class=\"s1\">'something'</span><span class=\"p\">,</span> <span class=\"s1\">'anything'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">shenme_info</span><span class=\"o\">.</span><span class=\"n\">match</span>       <span class=\"c1\"># The corresponding \u7e41\u4f53\u5b57.</span>\n<span class=\"s1\">'\u4ec0\u9ebc'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">shenme_info</span><span class=\"o\">.</span><span class=\"n\">pinyin</span>      <span class=\"c1\"># The pinyin of the token.</span>\n<span class=\"p\">[</span><span class=\"s1\">'shen2'</span><span class=\"p\">,</span> <span class=\"s1\">'me5'</span><span class=\"p\">]</span>\n</pre>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>MIT License</p>\n</div>\n<div id=\"thanks\">\n<h2>Thanks</h2>\n<p><a href=\"https://github.com/fxsjy/jieba\" rel=\"nofollow\">jieba</a> and\n<a href=\"https://github.com/tsroten/pynlpir\" rel=\"nofollow\">PyNLPIR</a> are used to tokenize a\nChinese text.</p>\n<p><a href=\"https://www.mdbg.net/chinese/dictionary?page=cc-cedict\" rel=\"nofollow\">CC-CEDICT</a>\nis used to lookup information for tokens.</p>\n</div>\n\n          </div>"}, "last_serial": 3703203, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "1cc7cc14d3bdbbe86f524987f46d3159", "sha256": "f64b1ae7ab47d6e462f5b8c5e7b0b5a2aa76b06c47299a076b2e8e58ef205e4e"}, "downloads": -1, "filename": "chinese-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1cc7cc14d3bdbbe86f524987f46d3159", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6595854, "upload_time": "2018-03-19T16:07:00", "upload_time_iso_8601": "2018-03-19T16:07:00.607501Z", "url": "https://files.pythonhosted.org/packages/84/a1/8bd5790e838ccf39ca09e77c826c6b8ff94472609812ded82eb90fd8a0b0/chinese-0.1.0-py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "6e5113f1461e4249cbf5f9886fbdaa7e", "sha256": "63f2ee4b943dc22a704dc8b8e9b83f708aa3e447973f605eb2bdfc508b1544c1"}, "downloads": -1, "filename": "chinese-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6e5113f1461e4249cbf5f9886fbdaa7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6597610, "upload_time": "2018-03-24T16:35:09", "upload_time_iso_8601": "2018-03-24T16:35:09.404084Z", "url": "https://files.pythonhosted.org/packages/74/73/8171d46b1e4c341e769f29b73550e7c7e30af1ba9128b6d8a9d04d274ac6/chinese-0.2.0-py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "e23b5fd511782f67c9556be82712d7ba", "sha256": "04a8052166fd9524ef5a6022810223da2a765b394b6280b6014f33de635842b1"}, "downloads": -1, "filename": "chinese-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e23b5fd511782f67c9556be82712d7ba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12583488, "upload_time": "2018-03-25T10:27:30", "upload_time_iso_8601": "2018-03-25T10:27:30.047194Z", "url": "https://files.pythonhosted.org/packages/15/fe/35c1cd7792f0c899fbeae66d35491721cae6be6d8a128d4f77e6e3479b3a/chinese-0.2.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e23b5fd511782f67c9556be82712d7ba", "sha256": "04a8052166fd9524ef5a6022810223da2a765b394b6280b6014f33de635842b1"}, "downloads": -1, "filename": "chinese-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e23b5fd511782f67c9556be82712d7ba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12583488, "upload_time": "2018-03-25T10:27:30", "upload_time_iso_8601": "2018-03-25T10:27:30.047194Z", "url": "https://files.pythonhosted.org/packages/15/fe/35c1cd7792f0c899fbeae66d35491721cae6be6d8a128d4f77e6e3479b3a/chinese-0.2.1-py3-none-any.whl", "yanked": false}], "timestamp": "Thu May  7 22:19:33 2020"}