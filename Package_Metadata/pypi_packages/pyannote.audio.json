{"info": {"author": "Herv\u00e9 Bredin", "author_email": "bredin@limsi.fr", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Scientific/Engineering"], "description": "# `pyannote-audio` | neural building blocks for speaker diarization\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pyannote/pyannote-audio/blob/develop/notebooks/introduction_to_pyannote_audio_speaker_diarization_toolkit.ipynb)\n\n`pyannote.audio` is an open-source toolkit written in Python for speaker diarization. Based on [PyTorch](pytorch.org) machine learning framework, it provides a set of trainable end-to-end neural building blocks that can be combined and jointly optimized to build speaker diarization pipelines:\n\n<p align=\"center\"> \n<img src=\"pipeline.png\">\n</p>\n\n`pyannote.audio` also comes with [pretrained models](https://github.com/pyannote/pyannote-audio-hub) covering a wide range of domains for voice activity detection, speaker change detection, overlapped speech detection, and speaker embedding:\n\n![segmentation](tutorials/pretrained/model/segmentation.png)\n\n## Installation\n\n`pyannote.audio` only supports Python 3.7 (or later) on Linux and macOS. It might work on Windows but there is no garantee that it does, nor any plan to add official support for Windows.\n\nThe instructions below assume that `pytorch` has been installed using the instructions from https://pytorch.org.\n\nUntil a proper release of `pyannote.audio` is available on `PyPI`, it must be installed from source using the develop branch of the official repository:\n\n```bash\n$ git clone https://github.com/pyannote/pyannote-audio.git\n$ cd pyannote-audio\n$ git checkout develop\n$ pip install .\n```\n\n## Documentation\n\nPart of the API is described in [this](tutorials/pretrained/model) tutorial.  \n\nDocumentation is a work in progress and is scheduled to be ready by end of April 2020.\n\n## Tutorials\n\n* Use [pretrained](https://github.com/pyannote/pyannote-audio-hub) models and pipelines\n  * [Apply pretrained pipelines on your own data](tutorials/pretrained/pipeline)\n  * [Apply pretrained models on your own data](tutorials/pretrained/model)\n* [Prepare your own dataset for training or fine-tuning](tutorials/data_preparation)\n* [Fine-tune pretrained models to your own data](tutorials/finetune)\n* Train models on your own data\n  * [Speech activity detection](tutorials/models/speech_activity_detection)\n  * [Speaker change detection](tutorials/models/speaker_change_detection)\n  * [Overlapped speech detection](tutorials/models/overlap_detection)\n  * [Speaker embedding](tutorials/models/speaker_embedding)\n* Tune pipelines on your own data\n  * [Speech activity detection pipeline](tutorials/pipelines/speech_activity_detection)\n  * [Speaker diarization pipeline](tutorials/pipelines/speaker_diarization)\n\n## Citation\n\nIf you use `pyannote.audio` please use the following citation\n\n```bibtex\n@inproceedings{Bredin2020,\n  Title = {{pyannote.audio: neural building blocks for speaker diarization}},\n  Author = {{Bredin}, Herv{\\'e} and {Yin}, Ruiqing and {Coria}, Juan Manuel and {Gelly}, Gregory and {Korshunov}, Pavel and {Lavechin}, Marvin and {Fustes}, Diego and {Titeux}, Hadrien and {Bouaziz}, Wassim and {Gill}, Marie-Philippe},\n  Booktitle = {ICASSP 2020, IEEE International Conference on Acoustics, Speech, and Signal Processing},\n  Address = {Barcelona, Spain},\n  Month = {May},\n  Year = {2020},\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/pyannote/pyannote-audio", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pyannote.audio", "package_url": "https://pypi.org/project/pyannote.audio/", "platform": "", "project_url": "https://pypi.org/project/pyannote.audio/", "project_urls": {"Homepage": "https://github.com/pyannote/pyannote-audio"}, "release_url": "https://pypi.org/project/pyannote.audio/2.0a1/", "requires_dist": ["cachetools (>=2.0.0)", "librosa (>=0.7.0)", "pandas (>=0.18.0)", "pyannote.core (>=3.7.1)", "pyannote.database (>=3.0)", "pyannote.metrics (>=2.3)", "pyannote.pipeline (>=1.3)", "pyYAML (>=3.12)", "scikit-learn (>=0.20.2)", "sortedcollections (>=1.0.1)", "sortedcontainers (>=2.0.4)", "soundfile (>=0.10.2)", "tqdm (>=4.29.1)", "tensorboard (>=2.0.0)", "typing-extensions (>=3.7.4)", "pescador (>=2.1.0)", "Pillow (>=6.2.1)"], "requires_python": "", "summary": "Neural building blocks for speaker diarization", "version": "2.0a1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1><code>pyannote-audio</code> | neural building blocks for speaker diarization</h1>\n<p><a href=\"https://colab.research.google.com/github/pyannote/pyannote-audio/blob/develop/notebooks/introduction_to_pyannote_audio_speaker_diarization_toolkit.ipynb\" rel=\"nofollow\"><img alt=\"Open In Colab\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/74d996556a82b2f1dd5252d2fd8bead60f9e9d21/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667\"></a></p>\n<p><code>pyannote.audio</code> is an open-source toolkit written in Python for speaker diarization. Based on <a href=\"pytorch.org\" rel=\"nofollow\">PyTorch</a> machine learning framework, it provides a set of trainable end-to-end neural building blocks that can be combined and jointly optimized to build speaker diarization pipelines:</p>\n<p align=\"center\"> \n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9c43d0754c7eddb455ff518664196cb88348a0ca/706970656c696e652e706e67\">\n</p>\n<p><code>pyannote.audio</code> also comes with <a href=\"https://github.com/pyannote/pyannote-audio-hub\" rel=\"nofollow\">pretrained models</a> covering a wide range of domains for voice activity detection, speaker change detection, overlapped speech detection, and speaker embedding:</p>\n<p><img alt=\"segmentation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6db5f699adfa3010bdcf908a4e6f1517afd1e1bf/7475746f7269616c732f707265747261696e65642f6d6f64656c2f7365676d656e746174696f6e2e706e67\"></p>\n<h2>Installation</h2>\n<p><code>pyannote.audio</code> only supports Python 3.7 (or later) on Linux and macOS. It might work on Windows but there is no garantee that it does, nor any plan to add official support for Windows.</p>\n<p>The instructions below assume that <code>pytorch</code> has been installed using the instructions from <a href=\"https://pytorch.org\" rel=\"nofollow\">https://pytorch.org</a>.</p>\n<p>Until a proper release of <code>pyannote.audio</code> is available on <code>PyPI</code>, it must be installed from source using the develop branch of the official repository:</p>\n<pre>$ git clone https://github.com/pyannote/pyannote-audio.git\n$ <span class=\"nb\">cd</span> pyannote-audio\n$ git checkout develop\n$ pip install .\n</pre>\n<h2>Documentation</h2>\n<p>Part of the API is described in <a href=\"tutorials/pretrained/model\" rel=\"nofollow\">this</a> tutorial.</p>\n<p>Documentation is a work in progress and is scheduled to be ready by end of April 2020.</p>\n<h2>Tutorials</h2>\n<ul>\n<li>Use <a href=\"https://github.com/pyannote/pyannote-audio-hub\" rel=\"nofollow\">pretrained</a> models and pipelines\n<ul>\n<li><a href=\"tutorials/pretrained/pipeline\" rel=\"nofollow\">Apply pretrained pipelines on your own data</a></li>\n<li><a href=\"tutorials/pretrained/model\" rel=\"nofollow\">Apply pretrained models on your own data</a></li>\n</ul>\n</li>\n<li><a href=\"tutorials/data_preparation\" rel=\"nofollow\">Prepare your own dataset for training or fine-tuning</a></li>\n<li><a href=\"tutorials/finetune\" rel=\"nofollow\">Fine-tune pretrained models to your own data</a></li>\n<li>Train models on your own data\n<ul>\n<li><a href=\"tutorials/models/speech_activity_detection\" rel=\"nofollow\">Speech activity detection</a></li>\n<li><a href=\"tutorials/models/speaker_change_detection\" rel=\"nofollow\">Speaker change detection</a></li>\n<li><a href=\"tutorials/models/overlap_detection\" rel=\"nofollow\">Overlapped speech detection</a></li>\n<li><a href=\"tutorials/models/speaker_embedding\" rel=\"nofollow\">Speaker embedding</a></li>\n</ul>\n</li>\n<li>Tune pipelines on your own data\n<ul>\n<li><a href=\"tutorials/pipelines/speech_activity_detection\" rel=\"nofollow\">Speech activity detection pipeline</a></li>\n<li><a href=\"tutorials/pipelines/speaker_diarization\" rel=\"nofollow\">Speaker diarization pipeline</a></li>\n</ul>\n</li>\n</ul>\n<h2>Citation</h2>\n<p>If you use <code>pyannote.audio</code> please use the following citation</p>\n<pre><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">Bredin2020</span><span class=\"p\">,</span>\n  <span class=\"na\">Title</span> <span class=\"p\">=</span> <span class=\"s\">{{pyannote.audio: neural building blocks for speaker diarization}}</span><span class=\"p\">,</span>\n  <span class=\"na\">Author</span> <span class=\"p\">=</span> <span class=\"s\">{{Bredin}, Herv{\\'e} and {Yin}, Ruiqing and {Coria}, Juan Manuel and {Gelly}, Gregory and {Korshunov}, Pavel and {Lavechin}, Marvin and {Fustes}, Diego and {Titeux}, Hadrien and {Bouaziz}, Wassim and {Gill}, Marie-Philippe}</span><span class=\"p\">,</span>\n  <span class=\"na\">Booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ICASSP 2020, IEEE International Conference on Acoustics, Speech, and Signal Processing}</span><span class=\"p\">,</span>\n  <span class=\"na\">Address</span> <span class=\"p\">=</span> <span class=\"s\">{Barcelona, Spain}</span><span class=\"p\">,</span>\n  <span class=\"na\">Month</span> <span class=\"p\">=</span> <span class=\"s\">{May}</span><span class=\"p\">,</span>\n  <span class=\"na\">Year</span> <span class=\"p\">=</span> <span class=\"s\">{2020}</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre>\n\n          </div>"}, "last_serial": 6927028, "releases": {"2.0a1": [{"comment_text": "", "digests": {"md5": "7bd296edd7ea3f9988e0c2953021c1c4", "sha256": "d4a615155c86dbaf42a5949f92fecb20b595070753e21061f7f6fda4553816fa"}, "downloads": -1, "filename": "pyannote.audio-2.0a1-py3-none-any.whl", "has_sig": false, "md5_digest": "7bd296edd7ea3f9988e0c2953021c1c4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 203968, "upload_time": "2020-04-01T11:32:51", "upload_time_iso_8601": "2020-04-01T11:32:51.260287Z", "url": "https://files.pythonhosted.org/packages/ee/18/c0a5bf569c84c4bfcef6ad2f7f2b0b078bc7950adbabb07e1088748faa70/pyannote.audio-2.0a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a492e6b94df8ebeb89cfe4f05a9c5a67", "sha256": "12ddaf572c2e05b7d29baf223f944a15024928356bbb98231b26288dcf5b6cae"}, "downloads": -1, "filename": "pyannote.audio-2.0a1.tar.gz", "has_sig": false, "md5_digest": "a492e6b94df8ebeb89cfe4f05a9c5a67", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124264, "upload_time": "2020-04-01T11:32:52", "upload_time_iso_8601": "2020-04-01T11:32:52.689653Z", "url": "https://files.pythonhosted.org/packages/31/cc/1070511d78df8eea87c64f1d97afe03079d0009c8097600cfe6715667702/pyannote.audio-2.0a1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7bd296edd7ea3f9988e0c2953021c1c4", "sha256": "d4a615155c86dbaf42a5949f92fecb20b595070753e21061f7f6fda4553816fa"}, "downloads": -1, "filename": "pyannote.audio-2.0a1-py3-none-any.whl", "has_sig": false, "md5_digest": "7bd296edd7ea3f9988e0c2953021c1c4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 203968, "upload_time": "2020-04-01T11:32:51", "upload_time_iso_8601": "2020-04-01T11:32:51.260287Z", "url": "https://files.pythonhosted.org/packages/ee/18/c0a5bf569c84c4bfcef6ad2f7f2b0b078bc7950adbabb07e1088748faa70/pyannote.audio-2.0a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a492e6b94df8ebeb89cfe4f05a9c5a67", "sha256": "12ddaf572c2e05b7d29baf223f944a15024928356bbb98231b26288dcf5b6cae"}, "downloads": -1, "filename": "pyannote.audio-2.0a1.tar.gz", "has_sig": false, "md5_digest": "a492e6b94df8ebeb89cfe4f05a9c5a67", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124264, "upload_time": "2020-04-01T11:32:52", "upload_time_iso_8601": "2020-04-01T11:32:52.689653Z", "url": "https://files.pythonhosted.org/packages/31/cc/1070511d78df8eea87c64f1d97afe03079d0009c8097600cfe6715667702/pyannote.audio-2.0a1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:10:36 2020"}