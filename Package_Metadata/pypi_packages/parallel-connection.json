{"info": {"author": "Niels Zeilemaker, Giovanni Lanzani", "author_email": "niels@zeilemaker.nl, giovanni@lanzani.nl", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Database :: Front-Ends"], "description": "ParallelConnection\n==================\n\nThis class manages multiple database connections, handles the parallel\naccess to it, and hides the complexity this entails. The execution of\nqueries is distributed by running it for each connection in parallel.\nThe result (as retrieved by fetchall() and fetchone()) is the union of\nthe parallelized query results from each connection.\n\nThe use case we had in mind when we created this class was having\nsharded tables (distributed across n database instances) that we needed\nto query concurrently and merging the results.\n\nSee below for an architecture overview for possible inspiration.\n\nUsage\n-----\n\nThe package is in principle database independent, as long as you expect\na connection object to respond to (part of) these methods:\n\n.. code:: python\n\n    cursor\n    cursor.execute\n    cursor.fetchone\n    cursor.fetchall\n    cursor.mogrify\n    cursor.commit\n    cursor.close\n    putconn\n\nTo use in its simplest form, do (example using psycopg2 and assuming\nthat dsns is a list containing your databases' connection strings)\n\n.. code:: python\n\n    n = 20  # maximum connections per pool\n    pools = [psycopg2.ThreadedConnectionPool(1, n, dsn=d) for d in dsns]\n    connections = [p.getconn() for p in pools]\n    pdb = ParallelConnection(connections)\n\nThe ``pdb`` object works for the rest like a normal, single, database\nconnection object, but it merges results return by each database. You\ncan therefore use it like so:\n\n.. code:: python\n\n    c = pdb.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n    c.execute(\"SELECT * FROM my_shrd_tbl WHERE shrd_column = 1543\", parameters)\n    results = c.fetchall()\n    c.close\n\nResults will fetch everything from all database. In case your query has\na where in the sharded column (``shrd_column``) the results from all but\none databases will be empty. This is fine, as the package handles it for\nyou. When it gets more interesting is a query like\n\n.. code:: python\n\n    c = pdb.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n    c.execute(\"SELECT * FROM my_shrd_tbl WHERE not_shrd_column = 543\", parameters)\n    results = c.fetchall()\n    c.close\n\nIn this case the query does *not* have a ``WHERE`` on a sharded column,\nso the package will fetch results from each database and merge them. Why\nthat may be of interest for you, will be shown below.\n\nIf you are executing a query on a non-sharded table you should use a\nnormal connection object.\n\nArchitectural motivation\n------------------------\n\nWe found ourselves having long running queries that where aggregating\nrecords on a particular column (let's call it ``shrd_column``). To\nreduce the run-time we decided to split only the table(s) containing\n``shrd_column`` between multiple databases, and have each database have\na copy of all non-sharded tables.\n\nThen each query grouping on ``shrd_column`` can be basically be executed\nindependently in each databases. The results still need to be merged\nthough, so that's why we build this package (we call it package even if\nNiels insists on calling it \"just a class\").\n\nFAQ\n---\n\n**Q.** Why don't you use things as\n`pg\\_shard <https://github.com/citusdata/pg_shard>`__?\n\n**A.** Because pg\\_shard doesn't handle ``JOIN`` on the distributed\nquery, which we want to do. Our package has the additional advantage\nthat all the databases are completely unaware of each other. It all\nhappens on the application layer and on the ingestion layer.\n\n--------------\n\n**Q.** What about if a machine goes down, etc.?\n\n**A.** Just use two machines with a load balancer in front of them.\n\n--------------\n\n**Q.** What about ``INSERT``?\n\n**A.** Yeah, we don't do that sort of things (it's read-only application\nfor explorative purposes). But feel to see if it works, and fix it plus\nsubmitting a PR if it doesn't.\n\n--------------\n\n**Q.** What about how to shard the data? This package does nothing,\nNiels is right!\n\n**A.** We trust you are savvy enough to do that by yourself before\ningestion. We could help you with that though, just drop\n`us <mailto:signal@godatadriven.com>`__ a line.\n\n--------------\n\n**Q.** I want to know more!\n\n**A.** That's technically not a question, but you can begin by watching\nNiels present the project at PyData Paris 2015. It's on\n`Youtube <https://www.youtube.com/watch?v=g0eNQSzIbpQ>`__.", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/godatadriven/ParallelConnection", "keywords": "development databases parallel", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "parallel-connection", "package_url": "https://pypi.org/project/parallel-connection/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/parallel-connection/", "project_urls": {"Homepage": "https://github.com/godatadriven/ParallelConnection"}, "release_url": "https://pypi.org/project/parallel-connection/0.1.2/", "requires_dist": ["nose; extra == 'test'"], "requires_python": "", "summary": "A package to query Postgres databases in parallel", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This class manages multiple database connections, handles the parallel\naccess to it, and hides the complexity this entails. The execution of\nqueries is distributed by running it for each connection in parallel.\nThe result (as retrieved by fetchall() and fetchone()) is the union of\nthe parallelized query results from each connection.</p>\n<p>The use case we had in mind when we created this class was having\nsharded tables (distributed across n database instances) that we needed\nto query concurrently and merging the results.</p>\n<p>See below for an architecture overview for possible inspiration.</p>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>The package is in principle database independent, as long as you expect\na connection object to respond to (part of) these methods:</p>\n<pre><span class=\"n\">cursor</span>\n<span class=\"n\">cursor</span><span class=\"o\">.</span><span class=\"n\">execute</span>\n<span class=\"n\">cursor</span><span class=\"o\">.</span><span class=\"n\">fetchone</span>\n<span class=\"n\">cursor</span><span class=\"o\">.</span><span class=\"n\">fetchall</span>\n<span class=\"n\">cursor</span><span class=\"o\">.</span><span class=\"n\">mogrify</span>\n<span class=\"n\">cursor</span><span class=\"o\">.</span><span class=\"n\">commit</span>\n<span class=\"n\">cursor</span><span class=\"o\">.</span><span class=\"n\">close</span>\n<span class=\"n\">putconn</span>\n</pre>\n<p>To use in its simplest form, do (example using psycopg2 and assuming\nthat dsns is a list containing your databases\u2019 connection strings)</p>\n<pre><span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>  <span class=\"c1\"># maximum connections per pool</span>\n<span class=\"n\">pools</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">psycopg2</span><span class=\"o\">.</span><span class=\"n\">ThreadedConnectionPool</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">dsn</span><span class=\"o\">=</span><span class=\"n\">d</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">d</span> <span class=\"ow\">in</span> <span class=\"n\">dsns</span><span class=\"p\">]</span>\n<span class=\"n\">connections</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">getconn</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">p</span> <span class=\"ow\">in</span> <span class=\"n\">pools</span><span class=\"p\">]</span>\n<span class=\"n\">pdb</span> <span class=\"o\">=</span> <span class=\"n\">ParallelConnection</span><span class=\"p\">(</span><span class=\"n\">connections</span><span class=\"p\">)</span>\n</pre>\n<p>The <tt>pdb</tt> object works for the rest like a normal, single, database\nconnection object, but it merges results return by each database. You\ncan therefore use it like so:</p>\n<pre><span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">pdb</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">(</span><span class=\"n\">cursor_factory</span><span class=\"o\">=</span><span class=\"n\">psycopg2</span><span class=\"o\">.</span><span class=\"n\">extras</span><span class=\"o\">.</span><span class=\"n\">RealDictCursor</span><span class=\"p\">)</span>\n<span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"SELECT * FROM my_shrd_tbl WHERE shrd_column = 1543\"</span><span class=\"p\">,</span> <span class=\"n\">parameters</span><span class=\"p\">)</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">fetchall</span><span class=\"p\">()</span>\n<span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">close</span>\n</pre>\n<p>Results will fetch everything from all database. In case your query has\na where in the sharded column (<tt>shrd_column</tt>) the results from all but\none databases will be empty. This is fine, as the package handles it for\nyou. When it gets more interesting is a query like</p>\n<pre><span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">pdb</span><span class=\"o\">.</span><span class=\"n\">cursor</span><span class=\"p\">(</span><span class=\"n\">cursor_factory</span><span class=\"o\">=</span><span class=\"n\">psycopg2</span><span class=\"o\">.</span><span class=\"n\">extras</span><span class=\"o\">.</span><span class=\"n\">RealDictCursor</span><span class=\"p\">)</span>\n<span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"s2\">\"SELECT * FROM my_shrd_tbl WHERE not_shrd_column = 543\"</span><span class=\"p\">,</span> <span class=\"n\">parameters</span><span class=\"p\">)</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">fetchall</span><span class=\"p\">()</span>\n<span class=\"n\">c</span><span class=\"o\">.</span><span class=\"n\">close</span>\n</pre>\n<p>In this case the query does <em>not</em> have a <tt>WHERE</tt> on a sharded column,\nso the package will fetch results from each database and merge them. Why\nthat may be of interest for you, will be shown below.</p>\n<p>If you are executing a query on a non-sharded table you should use a\nnormal connection object.</p>\n</div>\n<div id=\"architectural-motivation\">\n<h2>Architectural motivation</h2>\n<p>We found ourselves having long running queries that where aggregating\nrecords on a particular column (let\u2019s call it <tt>shrd_column</tt>). To\nreduce the run-time we decided to split only the table(s) containing\n<tt>shrd_column</tt> between multiple databases, and have each database have\na copy of all non-sharded tables.</p>\n<p>Then each query grouping on <tt>shrd_column</tt> can be basically be executed\nindependently in each databases. The results still need to be merged\nthough, so that\u2019s why we build this package (we call it package even if\nNiels insists on calling it \u201cjust a class\u201d).</p>\n</div>\n<div id=\"faq\">\n<h2>FAQ</h2>\n<p><strong>Q.</strong> Why don\u2019t you use things as\n<a href=\"https://github.com/citusdata/pg_shard\" rel=\"nofollow\">pg_shard</a>?</p>\n<p><strong>A.</strong> Because pg_shard doesn\u2019t handle <tt>JOIN</tt> on the distributed\nquery, which we want to do. Our package has the additional advantage\nthat all the databases are completely unaware of each other. It all\nhappens on the application layer and on the ingestion layer.</p>\n<hr class=\"docutils\">\n<p><strong>Q.</strong> What about if a machine goes down, etc.?</p>\n<p><strong>A.</strong> Just use two machines with a load balancer in front of them.</p>\n<hr class=\"docutils\">\n<p><strong>Q.</strong> What about <tt>INSERT</tt>?</p>\n<p><strong>A.</strong> Yeah, we don\u2019t do that sort of things (it\u2019s read-only application\nfor explorative purposes). But feel to see if it works, and fix it plus\nsubmitting a PR if it doesn\u2019t.</p>\n<hr class=\"docutils\">\n<p><strong>Q.</strong> What about how to shard the data? This package does nothing,\nNiels is right!</p>\n<p><strong>A.</strong> We trust you are savvy enough to do that by yourself before\ningestion. We could help you with that though, just drop\n<a href=\"mailto:signal%40godatadriven.com\">us</a> a line.</p>\n<hr class=\"docutils\">\n<p><strong>Q.</strong> I want to know more!</p>\n<p><strong>A.</strong> That\u2019s technically not a question, but you can begin by watching\nNiels present the project at PyData Paris 2015. It\u2019s on\n<a href=\"https://www.youtube.com/watch?v=g0eNQSzIbpQ\" rel=\"nofollow\">Youtube</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 1972540, "releases": {"0.0.1": [], "0.1.1": [{"comment_text": "", "digests": {"md5": "c3dacba9bdfd02aed4f842f3c3227e11", "sha256": "bea320e2d4c17d2bae4ebb00e2444a27230c44168053cc60f34a2b5f4188e2e8"}, "downloads": -1, "filename": "parallel_connection-0.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c3dacba9bdfd02aed4f842f3c3227e11", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7391, "upload_time": "2015-08-21T12:35:04", "upload_time_iso_8601": "2015-08-21T12:35:04.227957Z", "url": "https://files.pythonhosted.org/packages/e5/5d/6c0712917449662f006ded7df0c36bc9acd0df98e68105bb52158468e53a/parallel_connection-0.1.1-py2.py3-none-any.whl", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "c3832447c54575484fee62bacddfa15f", "sha256": "be75a7ca03db93a9be7385a4a1d02297d7c67c6767f1be0eaf3a6ea2fbc9482c"}, "downloads": -1, "filename": "parallel_connection-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c3832447c54575484fee62bacddfa15f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7363, "upload_time": "2016-02-23T21:12:49", "upload_time_iso_8601": "2016-02-23T21:12:49.024759Z", "url": "https://files.pythonhosted.org/packages/a1/92/7535166d52a65e6adfbedfc2e68aa6778eb2642f6cbf7cdfc23b6aefc734/parallel_connection-0.1.2-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c3832447c54575484fee62bacddfa15f", "sha256": "be75a7ca03db93a9be7385a4a1d02297d7c67c6767f1be0eaf3a6ea2fbc9482c"}, "downloads": -1, "filename": "parallel_connection-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c3832447c54575484fee62bacddfa15f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7363, "upload_time": "2016-02-23T21:12:49", "upload_time_iso_8601": "2016-02-23T21:12:49.024759Z", "url": "https://files.pythonhosted.org/packages/a1/92/7535166d52a65e6adfbedfc2e68aa6778eb2642f6cbf7cdfc23b6aefc734/parallel_connection-0.1.2-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 02:58:39 2020"}