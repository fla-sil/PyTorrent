{"info": {"author": "Ashton Sidhu", "author_email": "ashton.sidhu1994@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "[![PyPI version](https://badge.fury.io/py/aethos.svg)](https://badge.fury.io/py/aethos) ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aethos) [![CircleCI](https://circleci.com/gh/Ashton-Sidhu/aethos/tree/develop.svg?style=svg)](https://circleci.com/gh/Ashton-Sidhu/aethos/tree/develop) [![Documentation Status](https://readthedocs.org/projects/aethos/badge/?version=latest)](https://aethos.readthedocs.io/en/latest/?badge=latest) [![codecov](https://codecov.io/gh/Ashton-Sidhu/aethos/branch/develop/graph/badge.svg)](https://codecov.io/gh/Ashton-Sidhu/aethos)\n\n\n\n# Aethos\n\n<i>\"A collection of tools for Data Scientists and ML Engineers to automate their workflow of performing analysis to deploying models and pipelines.\"</i>\n\nTo track development of the project, you can view the [Trello board](https://trello.com/b/EZVs9Hxz/automated-ds-ml).\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n## Table of Contents\n\n- [Introduction](#introduction)\n- [Usage](#usage)\n- [Installation](#installation)\n- [Development Phases](#development-phases)\n- [Feedback](#feedback)\n- [Contributors](#contributors)\n- [Sponsors](#sponsors)\n- [Acknowledgments](#acknowledgments)\n- [For Developers](#for-developers)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Introduction\n\nAethos is a library/platform that automates your data science and analytical tasks at any stage in the pipeline. Aethos is, at its core, a uniform API that helps automate analytical techniques from various libaries such as pandas, sci-kit learn, gensim, etc. \n\nAethos provides:\n\n  - Automated data science cleaning, preprocessing, feature engineering and modelling techniques through one line of code\n  - Automated reporting - as you perform your analysis, a report is created along side with it\n  - Automated visualizations through one line of code\n  - Reusable code - no more copying code from notebook to notebook\n  - Automated dependency and corpus management\n  - Datascience project templates\n  - Integrated 3rd party jupyter plugins to make analyzing data more friendly\n  - Model analysis use cases - Confusion Matrix, ROC Curve, all metrics, decision tree plots, etc.\n  - Model interpretability - Local through SHAP and LIME, global through Morris Sensitivity\n  - Interactive checklists and tips to either remind or help you through your analysis.\n  - Comparing train and test data distribution\n  - Exporting trained models as a service (Generates the necessary code, files and folder structure)\n  - Experiment tracking with MLFlow\n  - Pre-trained models - BERT, GPT2, etc.\n  - Statistical tests - Anova, T-test, etc.\n  \nYou can view a full list of implemented techniques in the documentation or here: [TECHNIQUES.md](https://github.com/Ashton-Sidhu/aethos/blob/develop/TECHNIQUES.md)\n\nPlus more coming soon such as:\n\n  - Testing for model drift\n  - Recommendation models\n  - Parralelization through Dask and/or Spark\n  - Uniform API for deep learning models\n  - Automated code and file generation for jupyter notebook development and a python file of your data pipeline.\n\nAethos makes it easy to PoC, experiment and compare different techniques and models from various libraries. From imputations, visualizations, scaling, dimensionality reduction, feature engineering to modelling, model results and model deployment - all done with a single, human readable, line of code!\n\nAethos utilizes other open source libraries to help enhance your analysis from enhanced stastical information, interactive visual plots or statistical tests and models - all your tools in one place, all accessible with one line of code or a click! See below in the [Acknowledgments](#acknowledgments) for the open source libraries being used in this project.\n\n## Usage\nFor full documentation on all the techniques and models, click [here](https://aethos.readthedocs.io/en/latest/?badge=latest) or [here](https://aethos.readthedocs.io/en/latest/source/aethos.html#)\n\nExamples can be viewed [here](https://github.com/Ashton-Sidhu/aethos/tree/develop/examples)\n\nTo start, we need to import Aethos dependencies as well as pandas.\n\nBefore that, we can create a full data science folder structure by running `aethos create` from the command line and follow the command prompts.\n\n### Options\n\nTo enable extensions, such as QGrid interactive filtering, enable them as you would in pandas:\n\n```python\nimport aethos as at\n\nat.options.interactive_df = True\n```\n\nCurrently the following options are:\n\n  - `interactive_df`: Interactive grid with QGrid\n  - `interactive_table`: Interactive grid with Itable - comes with built in client side searching\n  - `project_metrics`: Setting project metrics\n    - Project metrics is a metric or set of metrics to evaluate models.\n  - `word_report`: Writes report to a word document as well as the .txt file\n  - `track_experiments`: Uses MLFlow to track models and experiments.\n\nUser options such as changing the directory where images, reports, and projects are saved can be edited in the config file. This is located at `USER_HOME`/.aethos/ .\n\nThis location is also the default location of where any images, reports and projects are stored.\n\n### Analysis\n\n```python\nimport aethos as at\nimport pandas as pd\n\nx_train = pd.read_csv('data/train.csv') # load data into pandas\n\n# Initialize Data object with training data\n# By default, if no test data (x_test) is provided, then the data is split with 20% going to the test set\n# Specify predictor field as 'Survived'\n# Specify report name\ndf = at.Data(x_train, target_field='Survived', report_name='Titanic')\n\ndf.x_train # View your training data\ndf.x_test # View your testing data\n\ndf # Glance at your training data\n\ndf[df.Age > 25] # Filter the data\n\ndf['new_col'] = [1, 2]  # Add a new column to the data, based off the length of the data provided, it will add it to the train or test set.\n\ndf.x_train['new_col'] = [1,2] # This is the exact same as the either of code above\ndf.x_test['new_col'] = [1,2]\n\ndf.data_report(title='Titanic Summary', output_file='titanic_summary.html') # Automate EDA with pandas profiling with an autogenerated report\n\ndf.describe() # Display a high level view of your data using an extended version of pandas describe\n\ndf.describe_column('Fare') # Get indepth statistics about the 'Fare' column\n\ndf.mean() # Run pandas functions on the aethos objects\n\ndf.missing_data # View your missing data at anytime\n\ndf.correlation_matrix() # Generate a correlation matrix for your training data\n\ndf.pairplot() # Generate pairplots for your training data features at any time\n\ndf.checklist() # Will provide an iteractive checklist to keep track of your cleaning tasks\n```\n\n**NOTE:** One of the benefits of using `aethos` is that any method you apply on your train set, gets applied to your test dataset. For any method that requires fitting (replacing missing data with mean), the method is fit on the training data and then applied to the testing data to avoid data leakage.\n\n```python\n# Replace missing values in the 'Fare' and 'Embarked' column with the most common values in each of the respective columns.\ndf.replace_missing_mostcommon('Fare', 'Embarked')\n\n# To create a \"checkpoint\" of your data (i.e. if you just want to test this analytical method), assign it to a variable\ndf.replace_missing_mostcommon('Fare', 'Embarked')\n\n# Replace missing values in the 'Age' column with a random value that follows the probability distribution of the 'Age' column in the training set. \ndf.replace_missing_random_discrete('Age')\n\ndf.drop('Cabin') # Drop the cabin column\n```\n\nAs you've started to notice, alot of tasks to df the data and to explore the data have been reduced down to one command, and are also customizable by providing the respective keyword arguments (see documentation).\n\n\n```python\n# Create a barplot of the mean surivial rate grouped by age.\ndf.barplot(x='Age', y=['Survived'], method='mean', xlabel='Age') \n\n# One hot encode the `Person` and `Embarked` columns and then drop the original columns\ndf.onehot_encode('Person', 'Embarked', drop_col=True) \n```\n\n### Modelling\n\n```python\nmodel = at.Model(df)\n```\n\n#### Running a Single Model\n\nModels can be trained one at a time or multiple at a time. They can also be trained by passing in the params for the sklearn, xgboost, etc constructor, by passing in a gridsearch dictionary & params, cross validating with gridsearch & params.\n\nAfter a model has been ran, it comes with use cases such as plotting RoC curves, calculating performance metrics, confusion matrices, SHAP plots, decision tree plots and other local and global model interpretability use cases.\n\n```python\nlr_model = model.LogisticRegression(random_state=42) # Train a logistic regression model\n\n# Train a logistic regression model with gridsearch\nlr_model = model.LogisticRegression(gridsearch={'penalty': ['l1', 'l2']}, random_state=42)\n\n# Crossvalidatea a logistic regression model, displays the scores and the learning curve and builds the model\nlr_model = model.LogisticRegression(cv=5, n_splits=10)\n\n# Build a Logistic Regression model with Gridsearch and then cross validates the best model using stratified K-Fold cross validation.\nlr_model = model.LogisticRegression(gridsearch={'penalty': ['l1', 'l2']}, cv='strat-kfold', n_splits=10) \n\nlr_model.metrics() # Views all metrics for the model\nlr_model.confusion_matrix()\nlr_model.roc_curve()\n```\n\n#### Running multiple models in parallel\n\n```python\n# Add a Logistic Regression, Random Forest Classification and a XGBoost Classification model to the queue.\nmodel.LogisticRegression(random_state=42, model_name='log_reg', run=False)\nmodel.RandomForestClassification(run=False)\nmodel.XGBoostClassification(run=False)\n\nmodel.run_models() # This will run all queued models in parallel\nmodel.run_models(method='series') # Run each model one after the other\n\nmodel.compare_models() # This will display each model evaluated against every metric\n\n# Every model is accessed by a unique name that is assiged when you run the model.\n# Default model names can be seen in the function header of each model.\n\nmodel.log_reg.confusion_matrix() # Displays a confusion matrix for the logistic regression model\nmodel.rf_cls.confusion_matrix() # Displays a confusion matrix for the random forest model\n```\n\n#### Using Pretrained Models\n\nCurrently you can use pretrained models such as BERT, XLNet, AlBERT, etc. to calculate sentiment and answer questions.\n\n```python\nmodel.pretrained_sentiment_analysis(`text_column`)\n\n# To answer questions, context for the question has to be supplied\nmodel.pretrained_question_answer(`context_column`, `question_column`)\n```\n\n### Model Interpretability\n\nAs mentioned in the Model section, whenever a model is trained you have access to use cases for model interpretability as well. There are prebuild SHAP usecases and an interactive dashboard that is equipped with LIME and SHAP for local model interpretability and Morris Sensitivity for global model interpretability.\n\n```python\nlr_model = model.LogisticRegression(random_state=42)\n\nlr_model.summary_plot() # SHAP summary plot\nlr_model.force_plot() # SHAP force plot\nlr_model.decision_plot() # SHAP decision plot\nlr_model.dependence_plot() # SHAP depencence plot\n\n# Creates an interactive dashboard to interpret predictions of the model\nlr_model.interpret_model() \n```\n\n### Code Generation\n\nCurrently you are only able to export your model to be ran a service, and will be able to automatically generate the required files. The automatic creation of a data pipeline is still in progress.\n\n```python\n\nlr_model.to_service('titanic')\n```\n\nNow navigate to 'your_home_folder'('~' on linux and Users/'your_user_name' on windows)/.aethos/projects/titanic/ and you will see the files needed to run the model as a service using FastAPI and uvicorn. \n\n## Installation\n\n**Python Requirements**: 3.6, 3.7\n\n`pip install aethos`\n\nTo install the dependencies to use pretrained models such as BERT, XLNet, AlBERT, etc:\n\n`pip install aethos[ptmodels]`\n\nTo install associating corpora for nltk analysis:\n\n`aethos install-corpora`\n\nTo install and use the extensions such as `qgrid` for interactive filtering and analysis with DataFrames:\n\n`aethos enable-extensions`\n\nCurrently working on condas implementation.\n\nTo create a Data Science project run:\n\n`aethos create`\n\nThis will create a full folder strucuture for you to manage data, unit tests, experiments and source code.\n\nIf experiment tracking is enabled or if you want to start the MLFlow UI:\n\n`aethos mlflow-ui`\n\nThis will start the MLFlow UI in the directory where your Aethos experiemnts are run.\nNOTE: This only works for local use of MLFLOW, if you are running MLFlow on a remote server, just start it on the remote server and enter the address in the `%HOME%/.aethos/config.yml` file.\n\n\n## Development Phases\n\n#### Phase 1\n  - [x]\tData Processing techniques\n    - [x] Data Cleaning V1\n    - [x] Feature Engineering V1\n  - [x]\tReporting V1\n\n#### Phase 2\n  - [x]\tData visualizations\n  - [x]\tModels and Evaluation\n  - [x]\tReporting V2\n\n#### Phase 3\n  - [x] Quality of life/addons\n  - [x] Code Generation V1\n  - [x] Experiment Tracking\n  - [x] Pre trained models\n\n#### Phase 4\n  - [ ]\tDeep learning integration\n  - [x] Statistical Tests\n  - [ ] Recommendation Models\n  - [ ] Code Generation V2\n    \n#### Phase 5\n  - [ ] Add time series models (i.e ARIMA) and feature engineering\n  - [ ] Parallelization (Spark, Dask, etc.)\n  - [ ]\tCloud computing\n  - [ ] Graph based learning and representation\n\n#### Phase 6\n  - [ ] Web App\n  \nThese are subject to change.\n\n## Feedback\n\nI appreciate any feedback so if you have any feature requests or issues make an issue with the appropriate tag or futhermore, send me an email at sidhuashton@gmail.com\n\n## Contributors\n\nThis project follows the [all-contributors](https://github.com/kentcdodds/all-contributors) specification and is brought to you by these [awesome contributors](./CONTRIBUTORS.md).\n\n## Sponsors\n\nN/A\n\n## Acknowledgments\n\nCredits go to the backbone of open source DataScience and ML: Pandas, Numpy, Scipy, Scikit Learn, Matplotlib, Plotly, Gensim and Jupyter.\n\nCommunity credits go to:\n\n[@mouradmourafiq](https://github.com/mouradmourafiq) for his [pandas-summary](https://github.com/mouradmourafiq/pandas-summary) library.\n\n[@PatrikHlobil](https://github.com/PatrikHlobil) for his [Pandas-Bokeh](https://github.com/PatrikHlobil/Pandas-Bokeh) library.\n\n[@pandas-profiling](https://github.com/pandas-profiling) for their automated [EDA report generation](https://github.com/pandas-profiling/pandas-profiling) library.\n\n[@slundberg](https://github.com/slundberg/) for his [shap](https://github.com/slundberg/shap) model explanation library.\n\n[@microsoft](https://github.com/microsoft/) for their [interpret](https://github.com/microsoft/interpret) model explanation library.\n\n[@DistrictDataLabs](https://github.com/DistrictDataLabs?type=source) for their [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) visual analysis and model diagnostic tool.\n\n[@Quantopian](https://github.com/quantopian?type=source) for their interactive DataFrame library [qgrid](https://github.com/quantopian/qgrid).\n\n[@mwouts](https://github.com/mwouts) for their interactive Dataframe library [itable](https://github.com/mwouts/itables).\n\n[@jmcarpenter2](https://github.com/jmcarpenter2/) for his parallelization library [Swifter](https://github.com/jmcarpenter2/swifter).\n\n[@mlflow](https://github.com/mlflow/) for their model tracking library [mlflow](https://github.com/mlflow/mlflow/).\n\n[@huggingface](https://github.com/huggingface/) for their automated pretrained model library [transformers](https://github.com/huggingface/transformers).\n\n## For Developers\n\n### Contributing data analysis techniques\n\n  1. The code for the transformation belongs in the `numeric`, `categorical`, etc. file for the stage it belongs.\n  2. In the stage.py (`clean.py`, `preprocess.py`, etc. ) file, call the analytical method as well as add the reporting code\n  3. Add a description for the technique in the `aethos/config/technique_reasons.yml` file.\n  4. Write the unit test in the `test_unittest.py` file in the stage folder.\n\n### Contributing models\n\n  1. Define the model as its own function in `model.py`\n  2. The import statements happen within the function.\n  3. Call the approriate `_run_` function (supervised or unsupervised)\n      - Text models go in text.py and call them from model.py\n  4. Add the model type to the dictionaries `SHAP_LEARNER` AND `PROBLEM_TYPE` dict in `model/constants.py`\n  5. Write the unittest in `test_unittest.py`\n\n### Contributing model analysis use cases\n\n  1. Generic model analysis goes in `model_analysis.py`\n  2. Model interpretability goes in `model_explanation.py`\n\nTo install packages `pip3 install -r requirements-dev.txt`\n\nTo run tests `python3 -m unittest discover aethos/`", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Ashton-Sidhu/aethos", "keywords": "datascience,machinelearning,automation,analysis", "license": "GPL-3.0", "maintainer": "", "maintainer_email": "", "name": "aethos", "package_url": "https://pypi.org/project/aethos/", "platform": "", "project_url": "https://pypi.org/project/aethos/", "project_urls": {"Homepage": "https://github.com/Ashton-Sidhu/aethos"}, "release_url": "https://pypi.org/project/aethos/1.2.5/", "requires_dist": null, "requires_python": ">= 3.6", "summary": "A library of data science and machine learning techniques to help automate your workflow.", "version": "1.2.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://badge.fury.io/py/aethos\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b3d2c027e21db4c328699a9b6def7c6237204313/68747470733a2f2f62616467652e667572792e696f2f70792f616574686f732e737667\"></a> <img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f6801c464f580bc397c0e59fc0c41eddef207aa1/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f616574686f73\"> <a href=\"https://circleci.com/gh/Ashton-Sidhu/aethos/tree/develop\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ca122757bad35ad1366624cf2d389eca28e2f1e/68747470733a2f2f636972636c6563692e636f6d2f67682f417368746f6e2d53696468752f616574686f732f747265652f646576656c6f702e7376673f7374796c653d737667\"></a> <a href=\"https://aethos.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1e326600566a39a97fbcc65572aa8ad214dabf49/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616574686f732f62616467652f3f76657273696f6e3d6c6174657374\"></a> <a href=\"https://codecov.io/gh/Ashton-Sidhu/aethos\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/84b6cbcdac4005811418f21dacc59fc2cf69f372/68747470733a2f2f636f6465636f762e696f2f67682f417368746f6e2d53696468752f616574686f732f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"></a></p>\n<h1>Aethos</h1>\n<p><i>\"A collection of tools for Data Scientists and ML Engineers to automate their workflow of performing analysis to deploying models and pipelines.\"</i></p>\n<p>To track development of the project, you can view the <a href=\"https://trello.com/b/EZVs9Hxz/automated-ds-ml\" rel=\"nofollow\">Trello board</a>.</p>\n\n\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#introduction\" rel=\"nofollow\">Introduction</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#development-phases\" rel=\"nofollow\">Development Phases</a></li>\n<li><a href=\"#feedback\" rel=\"nofollow\">Feedback</a></li>\n<li><a href=\"#contributors\" rel=\"nofollow\">Contributors</a></li>\n<li><a href=\"#sponsors\" rel=\"nofollow\">Sponsors</a></li>\n<li><a href=\"#acknowledgments\" rel=\"nofollow\">Acknowledgments</a></li>\n<li><a href=\"#for-developers\" rel=\"nofollow\">For Developers</a></li>\n</ul>\n\n<h2>Introduction</h2>\n<p>Aethos is a library/platform that automates your data science and analytical tasks at any stage in the pipeline. Aethos is, at its core, a uniform API that helps automate analytical techniques from various libaries such as pandas, sci-kit learn, gensim, etc.</p>\n<p>Aethos provides:</p>\n<ul>\n<li>Automated data science cleaning, preprocessing, feature engineering and modelling techniques through one line of code</li>\n<li>Automated reporting - as you perform your analysis, a report is created along side with it</li>\n<li>Automated visualizations through one line of code</li>\n<li>Reusable code - no more copying code from notebook to notebook</li>\n<li>Automated dependency and corpus management</li>\n<li>Datascience project templates</li>\n<li>Integrated 3rd party jupyter plugins to make analyzing data more friendly</li>\n<li>Model analysis use cases - Confusion Matrix, ROC Curve, all metrics, decision tree plots, etc.</li>\n<li>Model interpretability - Local through SHAP and LIME, global through Morris Sensitivity</li>\n<li>Interactive checklists and tips to either remind or help you through your analysis.</li>\n<li>Comparing train and test data distribution</li>\n<li>Exporting trained models as a service (Generates the necessary code, files and folder structure)</li>\n<li>Experiment tracking with MLFlow</li>\n<li>Pre-trained models - BERT, GPT2, etc.</li>\n<li>Statistical tests - Anova, T-test, etc.</li>\n</ul>\n<p>You can view a full list of implemented techniques in the documentation or here: <a href=\"https://github.com/Ashton-Sidhu/aethos/blob/develop/TECHNIQUES.md\" rel=\"nofollow\">TECHNIQUES.md</a></p>\n<p>Plus more coming soon such as:</p>\n<ul>\n<li>Testing for model drift</li>\n<li>Recommendation models</li>\n<li>Parralelization through Dask and/or Spark</li>\n<li>Uniform API for deep learning models</li>\n<li>Automated code and file generation for jupyter notebook development and a python file of your data pipeline.</li>\n</ul>\n<p>Aethos makes it easy to PoC, experiment and compare different techniques and models from various libraries. From imputations, visualizations, scaling, dimensionality reduction, feature engineering to modelling, model results and model deployment - all done with a single, human readable, line of code!</p>\n<p>Aethos utilizes other open source libraries to help enhance your analysis from enhanced stastical information, interactive visual plots or statistical tests and models - all your tools in one place, all accessible with one line of code or a click! See below in the <a href=\"#acknowledgments\" rel=\"nofollow\">Acknowledgments</a> for the open source libraries being used in this project.</p>\n<h2>Usage</h2>\n<p>For full documentation on all the techniques and models, click <a href=\"https://aethos.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">here</a> or <a href=\"https://aethos.readthedocs.io/en/latest/source/aethos.html#\" rel=\"nofollow\">here</a></p>\n<p>Examples can be viewed <a href=\"https://github.com/Ashton-Sidhu/aethos/tree/develop/examples\" rel=\"nofollow\">here</a></p>\n<p>To start, we need to import Aethos dependencies as well as pandas.</p>\n<p>Before that, we can create a full data science folder structure by running <code>aethos create</code> from the command line and follow the command prompts.</p>\n<h3>Options</h3>\n<p>To enable extensions, such as QGrid interactive filtering, enable them as you would in pandas:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">aethos</span> <span class=\"k\">as</span> <span class=\"nn\">at</span>\n\n<span class=\"n\">at</span><span class=\"o\">.</span><span class=\"n\">options</span><span class=\"o\">.</span><span class=\"n\">interactive_df</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre>\n<p>Currently the following options are:</p>\n<ul>\n<li><code>interactive_df</code>: Interactive grid with QGrid</li>\n<li><code>interactive_table</code>: Interactive grid with Itable - comes with built in client side searching</li>\n<li><code>project_metrics</code>: Setting project metrics\n<ul>\n<li>Project metrics is a metric or set of metrics to evaluate models.</li>\n</ul>\n</li>\n<li><code>word_report</code>: Writes report to a word document as well as the .txt file</li>\n<li><code>track_experiments</code>: Uses MLFlow to track models and experiments.</li>\n</ul>\n<p>User options such as changing the directory where images, reports, and projects are saved can be edited in the config file. This is located at <code>USER_HOME</code>/.aethos/ .</p>\n<p>This location is also the default location of where any images, reports and projects are stored.</p>\n<h3>Analysis</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">aethos</span> <span class=\"k\">as</span> <span class=\"nn\">at</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"n\">x_train</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'data/train.csv'</span><span class=\"p\">)</span> <span class=\"c1\"># load data into pandas</span>\n\n<span class=\"c1\"># Initialize Data object with training data</span>\n<span class=\"c1\"># By default, if no test data (x_test) is provided, then the data is split with 20% going to the test set</span>\n<span class=\"c1\"># Specify predictor field as 'Survived'</span>\n<span class=\"c1\"># Specify report name</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">at</span><span class=\"o\">.</span><span class=\"n\">Data</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">target_field</span><span class=\"o\">=</span><span class=\"s1\">'Survived'</span><span class=\"p\">,</span> <span class=\"n\">report_name</span><span class=\"o\">=</span><span class=\"s1\">'Titanic'</span><span class=\"p\">)</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">x_train</span> <span class=\"c1\"># View your training data</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">x_test</span> <span class=\"c1\"># View your testing data</span>\n\n<span class=\"n\">df</span> <span class=\"c1\"># Glance at your training data</span>\n\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">Age</span> <span class=\"o\">&gt;</span> <span class=\"mi\">25</span><span class=\"p\">]</span> <span class=\"c1\"># Filter the data</span>\n\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'new_col'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]</span>  <span class=\"c1\"># Add a new column to the data, based off the length of the data provided, it will add it to the train or test set.</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">x_train</span><span class=\"p\">[</span><span class=\"s1\">'new_col'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"c1\"># This is the exact same as the either of code above</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">x_test</span><span class=\"p\">[</span><span class=\"s1\">'new_col'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">data_report</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"o\">=</span><span class=\"s1\">'Titanic Summary'</span><span class=\"p\">,</span> <span class=\"n\">output_file</span><span class=\"o\">=</span><span class=\"s1\">'titanic_summary.html'</span><span class=\"p\">)</span> <span class=\"c1\"># Automate EDA with pandas profiling with an autogenerated report</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">describe</span><span class=\"p\">()</span> <span class=\"c1\"># Display a high level view of your data using an extended version of pandas describe</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">describe_column</span><span class=\"p\">(</span><span class=\"s1\">'Fare'</span><span class=\"p\">)</span> <span class=\"c1\"># Get indepth statistics about the 'Fare' column</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span> <span class=\"c1\"># Run pandas functions on the aethos objects</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">missing_data</span> <span class=\"c1\"># View your missing data at anytime</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">correlation_matrix</span><span class=\"p\">()</span> <span class=\"c1\"># Generate a correlation matrix for your training data</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">pairplot</span><span class=\"p\">()</span> <span class=\"c1\"># Generate pairplots for your training data features at any time</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">checklist</span><span class=\"p\">()</span> <span class=\"c1\"># Will provide an iteractive checklist to keep track of your cleaning tasks</span>\n</pre>\n<p><strong>NOTE:</strong> One of the benefits of using <code>aethos</code> is that any method you apply on your train set, gets applied to your test dataset. For any method that requires fitting (replacing missing data with mean), the method is fit on the training data and then applied to the testing data to avoid data leakage.</p>\n<pre><span class=\"c1\"># Replace missing values in the 'Fare' and 'Embarked' column with the most common values in each of the respective columns.</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">replace_missing_mostcommon</span><span class=\"p\">(</span><span class=\"s1\">'Fare'</span><span class=\"p\">,</span> <span class=\"s1\">'Embarked'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># To create a \"checkpoint\" of your data (i.e. if you just want to test this analytical method), assign it to a variable</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">replace_missing_mostcommon</span><span class=\"p\">(</span><span class=\"s1\">'Fare'</span><span class=\"p\">,</span> <span class=\"s1\">'Embarked'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Replace missing values in the 'Age' column with a random value that follows the probability distribution of the 'Age' column in the training set. </span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">replace_missing_random_discrete</span><span class=\"p\">(</span><span class=\"s1\">'Age'</span><span class=\"p\">)</span>\n\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">'Cabin'</span><span class=\"p\">)</span> <span class=\"c1\"># Drop the cabin column</span>\n</pre>\n<p>As you've started to notice, alot of tasks to df the data and to explore the data have been reduced down to one command, and are also customizable by providing the respective keyword arguments (see documentation).</p>\n<pre><span class=\"c1\"># Create a barplot of the mean surivial rate grouped by age.</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">barplot</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"s1\">'Age'</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'Survived'</span><span class=\"p\">],</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s1\">'mean'</span><span class=\"p\">,</span> <span class=\"n\">xlabel</span><span class=\"o\">=</span><span class=\"s1\">'Age'</span><span class=\"p\">)</span> \n\n<span class=\"c1\"># One hot encode the `Person` and `Embarked` columns and then drop the original columns</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">onehot_encode</span><span class=\"p\">(</span><span class=\"s1\">'Person'</span><span class=\"p\">,</span> <span class=\"s1\">'Embarked'</span><span class=\"p\">,</span> <span class=\"n\">drop_col</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> \n</pre>\n<h3>Modelling</h3>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">at</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n</pre>\n<h4>Running a Single Model</h4>\n<p>Models can be trained one at a time or multiple at a time. They can also be trained by passing in the params for the sklearn, xgboost, etc constructor, by passing in a gridsearch dictionary &amp; params, cross validating with gridsearch &amp; params.</p>\n<p>After a model has been ran, it comes with use cases such as plotting RoC curves, calculating performance metrics, confusion matrices, SHAP plots, decision tree plots and other local and global model interpretability use cases.</p>\n<pre><span class=\"n\">lr_model</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span> <span class=\"c1\"># Train a logistic regression model</span>\n\n<span class=\"c1\"># Train a logistic regression model with gridsearch</span>\n<span class=\"n\">lr_model</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">gridsearch</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'penalty'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'l1'</span><span class=\"p\">,</span> <span class=\"s1\">'l2'</span><span class=\"p\">]},</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Crossvalidatea a logistic regression model, displays the scores and the learning curve and builds the model</span>\n<span class=\"n\">lr_model</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">n_splits</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Build a Logistic Regression model with Gridsearch and then cross validates the best model using stratified K-Fold cross validation.</span>\n<span class=\"n\">lr_model</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">gridsearch</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'penalty'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'l1'</span><span class=\"p\">,</span> <span class=\"s1\">'l2'</span><span class=\"p\">]},</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"s1\">'strat-kfold'</span><span class=\"p\">,</span> <span class=\"n\">n_splits</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span> \n\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"p\">()</span> <span class=\"c1\"># Views all metrics for the model</span>\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">confusion_matrix</span><span class=\"p\">()</span>\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">roc_curve</span><span class=\"p\">()</span>\n</pre>\n<h4>Running multiple models in parallel</h4>\n<pre><span class=\"c1\"># Add a Logistic Regression, Random Forest Classification and a XGBoost Classification model to the queue.</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'log_reg'</span><span class=\"p\">,</span> <span class=\"n\">run</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">RandomForestClassification</span><span class=\"p\">(</span><span class=\"n\">run</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">XGBoostClassification</span><span class=\"p\">(</span><span class=\"n\">run</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">run_models</span><span class=\"p\">()</span> <span class=\"c1\"># This will run all queued models in parallel</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">run_models</span><span class=\"p\">(</span><span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s1\">'series'</span><span class=\"p\">)</span> <span class=\"c1\"># Run each model one after the other</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compare_models</span><span class=\"p\">()</span> <span class=\"c1\"># This will display each model evaluated against every metric</span>\n\n<span class=\"c1\"># Every model is accessed by a unique name that is assiged when you run the model.</span>\n<span class=\"c1\"># Default model names can be seen in the function header of each model.</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">log_reg</span><span class=\"o\">.</span><span class=\"n\">confusion_matrix</span><span class=\"p\">()</span> <span class=\"c1\"># Displays a confusion matrix for the logistic regression model</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">rf_cls</span><span class=\"o\">.</span><span class=\"n\">confusion_matrix</span><span class=\"p\">()</span> <span class=\"c1\"># Displays a confusion matrix for the random forest model</span>\n</pre>\n<h4>Using Pretrained Models</h4>\n<p>Currently you can use pretrained models such as BERT, XLNet, AlBERT, etc. to calculate sentiment and answer questions.</p>\n<pre><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">pretrained_sentiment_analysis</span><span class=\"p\">(</span><span class=\"err\">`</span><span class=\"n\">text_column</span><span class=\"err\">`</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># To answer questions, context for the question has to be supplied</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">pretrained_question_answer</span><span class=\"p\">(</span><span class=\"err\">`</span><span class=\"n\">context_column</span><span class=\"err\">`</span><span class=\"p\">,</span> <span class=\"err\">`</span><span class=\"n\">question_column</span><span class=\"err\">`</span><span class=\"p\">)</span>\n</pre>\n<h3>Model Interpretability</h3>\n<p>As mentioned in the Model section, whenever a model is trained you have access to use cases for model interpretability as well. There are prebuild SHAP usecases and an interactive dashboard that is equipped with LIME and SHAP for local model interpretability and Morris Sensitivity for global model interpretability.</p>\n<pre><span class=\"n\">lr_model</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">summary_plot</span><span class=\"p\">()</span> <span class=\"c1\"># SHAP summary plot</span>\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">force_plot</span><span class=\"p\">()</span> <span class=\"c1\"># SHAP force plot</span>\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">decision_plot</span><span class=\"p\">()</span> <span class=\"c1\"># SHAP decision plot</span>\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">dependence_plot</span><span class=\"p\">()</span> <span class=\"c1\"># SHAP depencence plot</span>\n\n<span class=\"c1\"># Creates an interactive dashboard to interpret predictions of the model</span>\n<span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">interpret_model</span><span class=\"p\">()</span> \n</pre>\n<h3>Code Generation</h3>\n<p>Currently you are only able to export your model to be ran a service, and will be able to automatically generate the required files. The automatic creation of a data pipeline is still in progress.</p>\n<pre><span class=\"n\">lr_model</span><span class=\"o\">.</span><span class=\"n\">to_service</span><span class=\"p\">(</span><span class=\"s1\">'titanic'</span><span class=\"p\">)</span>\n</pre>\n<p>Now navigate to 'your_home_folder'('~' on linux and Users/'your_user_name' on windows)/.aethos/projects/titanic/ and you will see the files needed to run the model as a service using FastAPI and uvicorn.</p>\n<h2>Installation</h2>\n<p><strong>Python Requirements</strong>: 3.6, 3.7</p>\n<p><code>pip install aethos</code></p>\n<p>To install the dependencies to use pretrained models such as BERT, XLNet, AlBERT, etc:</p>\n<p><code>pip install aethos[ptmodels]</code></p>\n<p>To install associating corpora for nltk analysis:</p>\n<p><code>aethos install-corpora</code></p>\n<p>To install and use the extensions such as <code>qgrid</code> for interactive filtering and analysis with DataFrames:</p>\n<p><code>aethos enable-extensions</code></p>\n<p>Currently working on condas implementation.</p>\n<p>To create a Data Science project run:</p>\n<p><code>aethos create</code></p>\n<p>This will create a full folder strucuture for you to manage data, unit tests, experiments and source code.</p>\n<p>If experiment tracking is enabled or if you want to start the MLFlow UI:</p>\n<p><code>aethos mlflow-ui</code></p>\n<p>This will start the MLFlow UI in the directory where your Aethos experiemnts are run.\nNOTE: This only works for local use of MLFLOW, if you are running MLFlow on a remote server, just start it on the remote server and enter the address in the <code>%HOME%/.aethos/config.yml</code> file.</p>\n<h2>Development Phases</h2>\n<h4>Phase 1</h4>\n<ul>\n<li>[x]\tData Processing techniques\n<ul>\n<li>[x] Data Cleaning V1</li>\n<li>[x] Feature Engineering V1</li>\n</ul>\n</li>\n<li>[x]\tReporting V1</li>\n</ul>\n<h4>Phase 2</h4>\n<ul>\n<li>[x]\tData visualizations</li>\n<li>[x]\tModels and Evaluation</li>\n<li>[x]\tReporting V2</li>\n</ul>\n<h4>Phase 3</h4>\n<ul>\n<li>[x] Quality of life/addons</li>\n<li>[x] Code Generation V1</li>\n<li>[x] Experiment Tracking</li>\n<li>[x] Pre trained models</li>\n</ul>\n<h4>Phase 4</h4>\n<ul>\n<li>[ ]\tDeep learning integration</li>\n<li>[x] Statistical Tests</li>\n<li>[ ] Recommendation Models</li>\n<li>[ ] Code Generation V2</li>\n</ul>\n<h4>Phase 5</h4>\n<ul>\n<li>[ ] Add time series models (i.e ARIMA) and feature engineering</li>\n<li>[ ] Parallelization (Spark, Dask, etc.)</li>\n<li>[ ]\tCloud computing</li>\n<li>[ ] Graph based learning and representation</li>\n</ul>\n<h4>Phase 6</h4>\n<ul>\n<li>[ ] Web App</li>\n</ul>\n<p>These are subject to change.</p>\n<h2>Feedback</h2>\n<p>I appreciate any feedback so if you have any feature requests or issues make an issue with the appropriate tag or futhermore, send me an email at <a href=\"mailto:sidhuashton@gmail.com\">sidhuashton@gmail.com</a></p>\n<h2>Contributors</h2>\n<p>This project follows the <a href=\"https://github.com/kentcdodds/all-contributors\" rel=\"nofollow\">all-contributors</a> specification and is brought to you by these <a href=\"./CONTRIBUTORS.md\" rel=\"nofollow\">awesome contributors</a>.</p>\n<h2>Sponsors</h2>\n<p>N/A</p>\n<h2>Acknowledgments</h2>\n<p>Credits go to the backbone of open source DataScience and ML: Pandas, Numpy, Scipy, Scikit Learn, Matplotlib, Plotly, Gensim and Jupyter.</p>\n<p>Community credits go to:</p>\n<p><a href=\"https://github.com/mouradmourafiq\" rel=\"nofollow\">@mouradmourafiq</a> for his <a href=\"https://github.com/mouradmourafiq/pandas-summary\" rel=\"nofollow\">pandas-summary</a> library.</p>\n<p><a href=\"https://github.com/PatrikHlobil\" rel=\"nofollow\">@PatrikHlobil</a> for his <a href=\"https://github.com/PatrikHlobil/Pandas-Bokeh\" rel=\"nofollow\">Pandas-Bokeh</a> library.</p>\n<p><a href=\"https://github.com/pandas-profiling\" rel=\"nofollow\">@pandas-profiling</a> for their automated <a href=\"https://github.com/pandas-profiling/pandas-profiling\" rel=\"nofollow\">EDA report generation</a> library.</p>\n<p><a href=\"https://github.com/slundberg/\" rel=\"nofollow\">@slundberg</a> for his <a href=\"https://github.com/slundberg/shap\" rel=\"nofollow\">shap</a> model explanation library.</p>\n<p><a href=\"https://github.com/microsoft/\" rel=\"nofollow\">@microsoft</a> for their <a href=\"https://github.com/microsoft/interpret\" rel=\"nofollow\">interpret</a> model explanation library.</p>\n<p><a href=\"https://github.com/DistrictDataLabs?type=source\" rel=\"nofollow\">@DistrictDataLabs</a> for their <a href=\"https://github.com/DistrictDataLabs/yellowbrick\" rel=\"nofollow\">yellowbrick</a> visual analysis and model diagnostic tool.</p>\n<p><a href=\"https://github.com/quantopian?type=source\" rel=\"nofollow\">@Quantopian</a> for their interactive DataFrame library <a href=\"https://github.com/quantopian/qgrid\" rel=\"nofollow\">qgrid</a>.</p>\n<p><a href=\"https://github.com/mwouts\" rel=\"nofollow\">@mwouts</a> for their interactive Dataframe library <a href=\"https://github.com/mwouts/itables\" rel=\"nofollow\">itable</a>.</p>\n<p><a href=\"https://github.com/jmcarpenter2/\" rel=\"nofollow\">@jmcarpenter2</a> for his parallelization library <a href=\"https://github.com/jmcarpenter2/swifter\" rel=\"nofollow\">Swifter</a>.</p>\n<p><a href=\"https://github.com/mlflow/\" rel=\"nofollow\">@mlflow</a> for their model tracking library <a href=\"https://github.com/mlflow/mlflow/\" rel=\"nofollow\">mlflow</a>.</p>\n<p><a href=\"https://github.com/huggingface/\" rel=\"nofollow\">@huggingface</a> for their automated pretrained model library <a href=\"https://github.com/huggingface/transformers\" rel=\"nofollow\">transformers</a>.</p>\n<h2>For Developers</h2>\n<h3>Contributing data analysis techniques</h3>\n<ol>\n<li>The code for the transformation belongs in the <code>numeric</code>, <code>categorical</code>, etc. file for the stage it belongs.</li>\n<li>In the stage.py (<code>clean.py</code>, <code>preprocess.py</code>, etc. ) file, call the analytical method as well as add the reporting code</li>\n<li>Add a description for the technique in the <code>aethos/config/technique_reasons.yml</code> file.</li>\n<li>Write the unit test in the <code>test_unittest.py</code> file in the stage folder.</li>\n</ol>\n<h3>Contributing models</h3>\n<ol>\n<li>Define the model as its own function in <code>model.py</code></li>\n<li>The import statements happen within the function.</li>\n<li>Call the approriate <code>_run_</code> function (supervised or unsupervised)\n<ul>\n<li>Text models go in text.py and call them from model.py</li>\n</ul>\n</li>\n<li>Add the model type to the dictionaries <code>SHAP_LEARNER</code> AND <code>PROBLEM_TYPE</code> dict in <code>model/constants.py</code></li>\n<li>Write the unittest in <code>test_unittest.py</code></li>\n</ol>\n<h3>Contributing model analysis use cases</h3>\n<ol>\n<li>Generic model analysis goes in <code>model_analysis.py</code></li>\n<li>Model interpretability goes in <code>model_explanation.py</code></li>\n</ol>\n<p>To install packages <code>pip3 install -r requirements-dev.txt</code></p>\n<p>To run tests <code>python3 -m unittest discover aethos/</code></p>\n\n          </div>"}, "last_serial": 6673011, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "b2985c81b824180862246701d5589cf7", "sha256": "332631fee21f30d1d86896bbb4b260b5193152cd8746f03eb31e3bd91e85ef97"}, "downloads": -1, "filename": "aethos-1.0.0.tar.gz", "has_sig": false, "md5_digest": "b2985c81b824180862246701d5589cf7", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 141758, "upload_time": "2019-12-24T20:49:02", "upload_time_iso_8601": "2019-12-24T20:49:02.962007Z", "url": "https://files.pythonhosted.org/packages/d6/46/2316dd8904699e4aa267980d5b9c97b6b148e554a8c1ca2ccfd58c54db17/aethos-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "87e3a14b8ba95e4753564396a00a3910", "sha256": "f61ad9366a3cae77c5ca1ed0b326b4c2bbc0797ca154227b26016a88e69531a5"}, "downloads": -1, "filename": "aethos-1.0.1.tar.gz", "has_sig": false, "md5_digest": "87e3a14b8ba95e4753564396a00a3910", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 141458, "upload_time": "2019-12-31T07:00:50", "upload_time_iso_8601": "2019-12-31T07:00:50.933661Z", "url": "https://files.pythonhosted.org/packages/d2/c1/f08e54016737dd46b2632f0f6a028166f010980079516611f9c105d48732/aethos-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "9eda1c4cf46d98bf1c850c45be746a0c", "sha256": "1c0b28eac9578702d87a546a8799aebbe1b44ff8df9f1b8d36d299eb1b579b42"}, "downloads": -1, "filename": "aethos-1.1.0.tar.gz", "has_sig": false, "md5_digest": "9eda1c4cf46d98bf1c850c45be746a0c", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 141318, "upload_time": "2020-01-09T21:08:54", "upload_time_iso_8601": "2020-01-09T21:08:54.354162Z", "url": "https://files.pythonhosted.org/packages/f4/42/1d78c9cb80621bcf9b174e4382f25e6c5dd65d2d1c0de549558474f47a36/aethos-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "574c43961ca0e9c093307af5b819f0ed", "sha256": "71707cdb47c17e3a1d85aeb6efd1107e7a777c9aa6a73879b8bae07b5b5fc55f"}, "downloads": -1, "filename": "aethos-1.1.1.tar.gz", "has_sig": false, "md5_digest": "574c43961ca0e9c093307af5b819f0ed", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 147102, "upload_time": "2020-01-11T06:13:00", "upload_time_iso_8601": "2020-01-11T06:13:00.958313Z", "url": "https://files.pythonhosted.org/packages/b0/5f/d81db1709dc2df0b2120804f5d50bc9623bd4240fca18ef535fcbed79bca/aethos-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "727663a9924dcc463aaa5f07c4ea435e", "sha256": "54dbea0337b03d6357108049c10738aaf24c4b5329543b72806d8ce5981a4835"}, "downloads": -1, "filename": "aethos-1.1.2.tar.gz", "has_sig": false, "md5_digest": "727663a9924dcc463aaa5f07c4ea435e", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 142082, "upload_time": "2020-01-12T09:43:54", "upload_time_iso_8601": "2020-01-12T09:43:54.873767Z", "url": "https://files.pythonhosted.org/packages/80/d6/e0757a152065d1a58ba6c35736d7b62642e9704132028074a5615782ad1a/aethos-1.1.2.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "b7f9920d3bff5dc883a118e557187c78", "sha256": "aa547f2dac1baac057ecbe564421e17b95f610adaa6e9fe76cb27cb6fcb87950"}, "downloads": -1, "filename": "aethos-1.2.0.tar.gz", "has_sig": false, "md5_digest": "b7f9920d3bff5dc883a118e557187c78", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 149571, "upload_time": "2020-01-23T03:14:23", "upload_time_iso_8601": "2020-01-23T03:14:23.133108Z", "url": "https://files.pythonhosted.org/packages/e2/9e/51ba724ce4635215fa0deefff958029976a35e5479d6026867f0476d3db1/aethos-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "035a1a8526d05daad0366cd4d6aba1e2", "sha256": "33fc258ca3258cdc7c107feb62833208f13cef9ef924b8d49a422444b1943cde"}, "downloads": -1, "filename": "aethos-1.2.1.tar.gz", "has_sig": false, "md5_digest": "035a1a8526d05daad0366cd4d6aba1e2", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 150305, "upload_time": "2020-01-25T06:59:12", "upload_time_iso_8601": "2020-01-25T06:59:12.394479Z", "url": "https://files.pythonhosted.org/packages/a7/a3/e29ad218d8de7ec8a2dae30cca4246958205f151f3031ae33692cab4215b/aethos-1.2.1.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "c1f735f3611f0e97836d649b655a1028", "sha256": "bddcba5e9df8e1c14a65857b519861cf4141b8cfe8b1a0aa8b2d6f9c874a7db1"}, "downloads": -1, "filename": "aethos-1.2.2.tar.gz", "has_sig": false, "md5_digest": "c1f735f3611f0e97836d649b655a1028", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 146028, "upload_time": "2020-01-26T06:32:02", "upload_time_iso_8601": "2020-01-26T06:32:02.921628Z", "url": "https://files.pythonhosted.org/packages/fb/39/99f77cdf15312d98c04185d6a7fff6e7b8b57cfc9f0fb4935ba03fbab665/aethos-1.2.2.tar.gz", "yanked": false}], "1.2.3": [{"comment_text": "", "digests": {"md5": "e5b1d2c740e2548e3d0107d6aa43d983", "sha256": "1f585903122853a1e567e5075510dac95d5b33379c2392f1a62721d17f23030b"}, "downloads": -1, "filename": "aethos-1.2.3.tar.gz", "has_sig": false, "md5_digest": "e5b1d2c740e2548e3d0107d6aa43d983", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 149870, "upload_time": "2020-01-26T07:15:44", "upload_time_iso_8601": "2020-01-26T07:15:44.133756Z", "url": "https://files.pythonhosted.org/packages/6d/de/5daafd4ad35670756822c05853a013699e959d96f9fbbcb972198dcb4b4d/aethos-1.2.3.tar.gz", "yanked": false}], "1.2.4": [{"comment_text": "", "digests": {"md5": "79a2fcf943da2708b921e92af4d614ec", "sha256": "93c71b1cb09c0f6364134517c1c11ca217dcccd596841977d08e7061beecffea"}, "downloads": -1, "filename": "aethos-1.2.4.tar.gz", "has_sig": false, "md5_digest": "79a2fcf943da2708b921e92af4d614ec", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 144919, "upload_time": "2020-01-30T20:20:07", "upload_time_iso_8601": "2020-01-30T20:20:07.822868Z", "url": "https://files.pythonhosted.org/packages/c8/23/8cb787b4092d6767f98b5cd4d845186c1ab63f462fc0ee9c9240346d62a0/aethos-1.2.4.tar.gz", "yanked": false}], "1.2.5": [{"comment_text": "", "digests": {"md5": "ad86c994f162886a47a1ed9beaa918a5", "sha256": "470080c725461f2bbf957d0654001d71993cba957424d8434748621abe35f04d"}, "downloads": -1, "filename": "aethos-1.2.5.tar.gz", "has_sig": false, "md5_digest": "ad86c994f162886a47a1ed9beaa918a5", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 149866, "upload_time": "2020-02-21T04:23:21", "upload_time_iso_8601": "2020-02-21T04:23:21.872156Z", "url": "https://files.pythonhosted.org/packages/a6/1a/7144bcbed59c78338c4a6b0fcf7029135be756ace6a70d9339806dc6afdf/aethos-1.2.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ad86c994f162886a47a1ed9beaa918a5", "sha256": "470080c725461f2bbf957d0654001d71993cba957424d8434748621abe35f04d"}, "downloads": -1, "filename": "aethos-1.2.5.tar.gz", "has_sig": false, "md5_digest": "ad86c994f162886a47a1ed9beaa918a5", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 149866, "upload_time": "2020-02-21T04:23:21", "upload_time_iso_8601": "2020-02-21T04:23:21.872156Z", "url": "https://files.pythonhosted.org/packages/a6/1a/7144bcbed59c78338c4a6b0fcf7029135be756ace6a70d9339806dc6afdf/aethos-1.2.5.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:22:49 2020"}