{"info": {"author": "Petrochenko Pavel", "author_email": "petrochenko.pavel.a@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "\n# Classification training pipeline\n\n![Build status](https://travis-ci.com/musket-ml/classification_training_pipeline.svg?branch=master)\n\nMy puny attempt to build reusable training pipeline for image classification\n\n  * [Motivation](#motivation)\n  * [Installation](#installation)\n  * [Usage guide](#usage-guide)\n    + [Training a model](#training-a-model)\n      - [Image/Mask Augmentations](#image-and-mask-augmentations)\n      - [Freezing/Unfreezing encoder](#freezing-and-unfreezing-encoder)\n      - [Custom datasets](#custom-datasets)      \n      - [Balancing your data](#balancing-your-data)\n      - [Multistage training](#multistage-training)\n      - [Composite losses](#composite-losses)\n      - [Cyclical learning rates](#cyclical-learning-rates)\n      - [LR Finder](#lr-finder)      \n      - [Background Augmenter](#background-augmenter)\n      - [Training on crops](#training-on-crops)\n    + [Using trained model](#using-trained-model)\n      - [Ensembling predictions and test time augmentation](#ensembling-predictions)\n    + [Custom evaluation code](#custom-evaluation-code)\n    + [Accessing model](#accessing-model)\n  * [Analyzing Experiments Results](#analyzing-experiments-results)\n  * [What is supported?](#what-is-supported-)    \n  * [Custom architectures, callbacks, metrics](#custom-architectures--callbacks--metrics)\n  * [Examples](#examples)\n  * [Faq](#faq)\n\n\n## Motivation\n\nIdea for this project came from my first attempts to participate in Kaggle competitions. My programmers heart was painfully damaged by looking on my own code as well as on other people kernels. Code was highly repetitive, suffering from numerous reimplementations of same or almost same things through the kernels, model/experiment configuration was often mixed with models code, in other words - from programmer perspective it all looked horrible. \n\nSo I decided to extract repetitive things into framework that will work at least for me and will follow these statements: \n - experiment configurations should be cleanly separated from model definitions;\n - experiment configuration files should be easy to compare and should fully describe experiment that is being performed except for the dataset;\n- common blocks like an architecture, callbacks, storing model metrics, visualizing network predictions, should be written once and be a part of common library\n\n\n## Installation\n\n```\npip install classification_pipeline\n```\n*Note: this package requires python 3.6*\n\n## Usage guide\n\n### Training a model \n\nLet's start from a simple example of classification. Suppose, your data are structured as follows: a .cvs file with images ids and their labels and a folder with all these images. For training a neural network to classify these images all you need are few lines of python code:\n\n```python\nimport musket_core\nfrom classification_pipeline import classification\nclass ProteinDataGenerator:\n\n    def __init__(self, paths, labels):\n        self.paths, self.labels = paths, labels\n\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        X,y = self.__load_image(self.paths[idx]),self.labels[idx]\n        return PredictionItem(self.paths[idx],X, y)\n\n    def __load_image(self, path):\n        R = Image.open(path + '_red.png')\n        G = Image.open(path + '_green.png')\n        B = Image.open(path + '_blue.png')\n\n\n        im = np.stack((\n            np.array(R),\n            np.array(G),\n            np.array(B),\n        ), -1)\n        return im\ndataset = ProteinDataGenerator(paths,labels)\ncfg = classification.parse(\"config.yaml\")\ncfg.fit(dataset)\n```\n\nLooks simple, but there is a `config.yaml` file in the code, and probably it is the place where everything actually happens.\n\n```yaml\narchitecture: DenseNet201 #pre-trained model we are going to use\npooling: avg\naugmentation: #define some minimal augmentations on images\n Fliplr: 0.5\n Flipud: 0.5\nclasses: 28 #define the number of classes\nactivation: sigmoid #as we have multilabel classification, the activation for last layer is sigmoid\nweights: imagenet #we would like to start from network pretrained on imagenet dataset\nshape: [224, 224, 3] #our desired input image size, everything will be resized to fit\noptimizer: Adam #Adam optimizer is a good default choice\nbatch: 16 #our batch size will be 16\nlr: 0.005\ncopyWeights: true\nmetrics: #we would like to track some metrics\n  - binary_accuracy\n  - macro_f1\nprimary_metric: val_binary_accuracy #the most interesting metric is val_binary_accuracy\nprimary_metric_mode: max\ncallbacks: #configure some minimal callbacks\n  EarlyStopping:\n    patience: 3\n    monitor: val_macro_f1\n    mode: max\n    verbose: 1\n  ReduceLROnPlateau:\n    patience: 2\n    factor: 0.3\n    monitor: val_binary_accuracy\n    mode: max\n    cooldown: 1\n    verbose: 1\nloss: binary_crossentropy #we use binary_crossentropy loss\nstages:\n  - epochs: 10 #let's go for 100 epochs\n```\n\nSo as you see, we have decomposed our task in two parts, *code that actually trains the model* and *experiment configuration*,\nwhich determines the model and how it should be trained from the set of predefined building blocks.\n\nWhat does this code actually do behind the scenes?\n\n-  it splits your data into 5 folds, and trains one model per fold;\n-  it takes care of model checkpointing, generates example image/label tuples, collects training metrics. All this data will\n   be stored in the folders just near your `config.yaml`;\n-  All your folds are initialized from fixed default seed, so different experiments will use exactly the same train/validation splits.\n\n#### Image Augmentations\n\nFramework uses awesome [imgaug](https://github.com/aleju/imgaug) library for augmentation, so you only need to configure your augmentation process in declarative way like in the following example:\n\n```yaml\naugmentation:  \n  Fliplr: 0.5\n  Flipud: 0.5\n  Affine:\n    scale: [0.8, 1.5] #random scalings\n    translate_percent:\n      x: [-0.2,0.2] #random shifts\n      y: [-0.2,0.2]\n    rotate: [-16, 16] #random rotations on -16,16 degrees\n    shear: [-16, 16] #random shears on -16,16 degrees\n```\n\n\n#### Freezing/Unfreezing encoder\n\nFreezing encoder is often used with transfer learning. If you want to start with frozen encoder just add\n\n```yaml\nfreeze_encoder: true\nstages:\n  - epochs: 10 #Let's go for 10 epochs with frozen encoder\n\n  - epochs: 100 #Now let's go for 100 epochs with trainable encoder\n    unfreeze_encoder: true  \n```\n\nin your experiments configuration, then on some stage configuration just add\n\n```yaml\nunfreeze_encoder: true\n```\nto stage settings.\n\n\n*Note: This option is not supported for DeeplabV3 architecture.*\n\n#### Custom datasets\n\nYou can declare your own dataset class as in this example:\n\n```python\nfrom musket_core.datasets import PredictionItem\nimport os\nimport imageio\nimport pandas as pd\nimport numpy as np\nimport cv2\n\nclass Classification:\n\n    def __init__(self,imgPath):\n        self.species = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat',\n           'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed',\n           'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n        self.data = []\n        self.targets = []\n        self.ids = []\n        for s_id, s in enumerate(self.species):\n            s_folder = os.path.join(imgPath,s)\n            for file in os.listdir(s_folder):\n                self.data.append(os.path.join(s_folder, file))\n                self.targets.append(s_id)\n                self.ids.append(file)\n\n\n    def __len__(self):\n        return len(self.data)\n\n\n    def __getitem__(self, item):\n        item_file = self.data[item]\n        target = self.targets[item]\n        t = np.zeros(len(self.species))\n        t[target] = 1.0\n        image = self.read_image(item_file, (224,224))\n        return PredictionItem(self.ids[item], image, t)\n\n    def read_image(self, filepath, target_size=None):\n        img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n        img = cv2.resize(img.copy(), target_size, interpolation = cv2.INTER_AREA)\n        return img\n\n```\n\n### Multi output classification\n\nSometimes you need to create network that performs several classification tasks at the same moment, in this situation\nyou need to declare `classes` , `activation` and `loss` as the lists of class counts, activation functions and losses\nlike in the following snippet:\n\n```yaml\nclasses: [ 4, 4 ] #define the number of classes\nactivation: [sigmoid,sigmoid]\nloss: \n  - binary_crossentropy\n  - binary_crossentropy\nprimary_metric: val_loss #the most interesting metric is val_binary_accuracy\nprimary_metric_mode: min  \n```\n\nit is also very likely that you need to change primary metric to `val_loss`   \n\n\n#### Balancing your data \n\nOne common case is the situation when part of your images does not contain any objects of interest, like in \n[Airbus ship detection challenge](https://www.kaggle.com/c/airbus-ship-detection/overview). More over your data may\nbe to heavily inbalanced, so you may want to rebalance it. Alternatively you may want to inject some additional\nimages that do not contain objects of interest to decrease amount of false positives that will be produced by the framework.\n\nThese scenarios are supported by `negatives` and `validation_negatives` settings of training stage configuration,\nthese settings accept following values:\n\n- none - exclude negative examples from the data\n- real - include all negative examples \n- integer number(1 or 2 or anything), how many negative examples should be included per one positive example   \n\nif you are using this setting your dataset class must support `isPositive` method which returns true for indexes\nwhich contain positive examples: \n\n```python        \n    def isPositive(self, item):\n        pixels=self.ddd.get_group(self.ids[item])[\"EncodedPixels\"]\n        for mask in pixels:\n            if isinstance(mask, str):\n                return True;\n        return False\n```     \n\n\n#### Multistage training\n\nSometimes you need to split your training into several stages. You can easily do it by adding several stage entries\nin your experiment configuration file like in the following example:\n\n```yaml\nstages:\n  - epochs: 6 #Train for 6 epochs\n    negatives: none #do not include negative examples in your training set \n    validation_negatives: real #validation should contain all negative examples    \n\n  - lr: 0.0001 #let's use different starting learning rate\n    epochs: 6\n    negatives: real\n    validation_negatives: real\n\n  - loss: lovasz_loss #let's override loss function\n    lr: 0.00001\n    epochs: 6\n    initial_weights: ./fpn-resnext2/weights/best-0.1.weights #let's load weights from this file    \n```\n\nStage entries allow you to configure custom learning rate, balance of negative examples, callbacks, loss function\nand even initial weights which should be used on a particular stage.\n\n#### Composite losses\n\nFramework supports composing loss as a weighted sum of predefined loss functions. For example, following construction\n```yaml\nloss: binary_crossentropy+0.1*dice_loss\n```\nwill result in loss function which is composed from `binary_crossentropy` and  `dice_loss` functions.\n\n#### Cyclical learning rates\n\n![Example](https://github.com/bckenstler/CLR/blob/master/images/triangularDiag.png?raw=true)\n\nAs told in [Cyclical learning rates for training neural networks](https://arxiv.org/abs/1506.01186) CLR policies can provide quicker converge for some neural network tasks and architectures. \n\n![Example2](https://github.com/bckenstler/CLR/raw/master/images/cifar.png)\n\nWe support them by adopting Brad Kenstler [CLR callback](https://github.com/bckenstler/CLR) for Keras.\n\nIf you want to use them, just add `CyclicLR` in your experiment configuration file as shown below: \n\n```yaml\ncallbacks:\n  EarlyStopping:\n    patience: 40\n    monitor: val_binary_accuracy\n    verbose: 1\n  CyclicLR:\n     base_lr: 0.0001\n     max_lr: 0.01\n     mode: triangular2\n     step_size: 300\n```\n\n#### LR Finder\n\n[Estimating optimal learning rate for your model](https://arxiv.org/abs/1506.01186) is an important thing, we support this by using slightly changed \nversion of [Pavel Surmenok - Keras LR Finder](https://github.com/surmenok/keras_lr_finder)\n\n```python\ncfg = classification.parse(config.yaml)\nds = SimplePNGMaskDataSet(\"./train\",\"./train_mask\") - ???????????????????\nfinder=cfg.lr_find(ds,start_lr=0.00001,end_lr=1,epochs=5)\nfinder.plot_loss(n_skip_beginning=20, n_skip_end=5)\nplt.show()\nfinder.plot_loss_change(sma=20, n_skip_beginning=20, n_skip_end=5, y_lim=(-0.01, 0.01))\nplt.show()\n```\nwill result in this couple of helpful images: \n\n![image](https://camo.githubusercontent.com/b41aeaff00fb7b214b5eb2e5c151e7e353a7263e/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a48566a5f344c57656d6a764f57762d63514f397939672e706e67)\n\n![image](https://camo.githubusercontent.com/834996d32bbd2edf7435c5e105b53a6b447ef083/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a38376d4b715f586f6d59794a4532396c39314b3064772e706e67)\n\n#### Training on crops\n\nYour images can be too large to train model on them. In this case you probably want to train model on crops. All\nthat you need to do is to specify number of splits per axis. For example, following lines in config \n\n```yaml\nshape: [768, 768, 3]\ncrops: 3\n``` \nwill lead to splitting each image into 9 cells (3 horizontal splits and 3 vertical splits) and training model on these splits.\nAugmentations will be run separately on each cell.\n\nDuring prediction time, your images will be split into these cells, prediction will be executed on each cell, and then results\nwill be assembled in single final mask. Thus the whole process of cropping will be invisible from a consumer perspective.\n\n### Using trained model\n\nOkey, our model is trained, now we need to actually do image classification. Let's say, we need to run image classification on\nimages in the directory and store results in csv file:\n\n```python\n\npredictions = []\nimages = []\n\n#Now let's use best model from fold 0 to do image segmentation on images from images_to_segment\npreds = cfg.predict_all_to_array(dataset_test, 0, 0)\nfor i, item in enumerate(dataset_test):\n    images.append(dataset_test.get_id(i))\n    p = np.argmax(preds[i])\n    predictions.append(dataset_test.get_label(p))\n\n#Let's store results in csv\ndf = pd.DataFrame.from_dict({'file': images, 'species': predictions})\ndf.to_csv('submission.csv', index=False)\n``` \n\n#### Ensembling predictions\n\nAnd what if you want to ensemble models from several folds? Just pass a list of fold numbers to\n`predict_all_to_array` like in the following example:\n\n```python\n cfg.predict_all_to_array(dataset_test, [0,1,2,3,4], 0)\n```\nAnother supported option is to ensemble results from extra test time augmentation (flips) by adding keyword arg `ttflips=True`.\n\n### Custom evaluation code \n\nSometimes you need to run custom evaluation code. In such case you may use: `evaluateAll` method, which provides an iterator\non the batches containing original images, training masks and predicted masks\n\n```python\nfor batch in cfg.evaluateAll(ds,2):\n    for i in range(len(batch.predicted_maps_aug)):\n        masks = ds.get_masks(batch.data[i])\n        for d in range(1,20):\n            cur_seg = binary_opening(batch.predicted_maps_aug[i].arr > d/20, np.expand_dims(disk(2), -1))\n            cm = rle.masks_as_images(rle.multi_rle_encode(cur_seg))\n            pr = f2(masks, cm);\n            total[d]=total[d]+pr\n```\n\n### Accessing model\nYou may get trained keras model by calling: ```cfg.load_model(fold, stage)```.\n\n## Analyzing experiments results\n\nOkey, we have done a lot of experiments and now we need to compare the results and understand what works better. This repository\ncontains [script](segmentation_pipeline/analize.py) which may be used to analyze folder containing sub folders\nwith experiment configurations and results. This script gathers all configurations, diffs them by doing structural diff, then \nfor each configuration it averages metrics for all folds and  generates csv file containing metrics and parameters that\nwas actually changed in your experiment like in the following [example](report.csv)\n\nThis script accepts following arguments:\n\n - inputFolder - root folder to search for experiments configurations and results\n - output - file to store aggregated metrics\n - onlyMetric - if you specify this option all other metrics will not be written in the report file\n - sortBy - metric that should be used to sort results \n\nExample: \n```commandline\npython analize.py --inputFolder ./experiments --output ./result.py\n``` \n\n## What is supported?\n\nAt this moment classification pipeline supports following pre-trained models:\n  - [Resnet](https://arxiv.org/abs/1512.03385)\n    - ResNet18\n    - ResNet34\n    - ResNet50\n    - ResNet101\n    - ResNet152\n    - ResNeXt50\n    - ResNeXt101\n  - [VGG](https://arxiv.org/abs/1409.1556):  \n     - VGG16\n     - VGG19\n  - [InceptionV3](https://arxiv.org/abs/1512.00567)\n  - [InceptionResNetV2](https://arxiv.org/abs/1602.07261)\n  - [Xception](https://arxiv.org/abs/1610.02357)\n  - [MobileNet](https://arxiv.org/pdf/1704.04861.pdf)\n  - [MobileNetV2](https://arxiv.org/abs/1801.04381)\n  - [DenseNet](https://arxiv.org/abs/1608.06993):\n    - DenseNet121\n    - DenseNet169\n    - DenseNet201\n  - [NasNet](https://arxiv.org/abs/1707.07012):  \n    - NASNetMobile\n    - NASNetLarge\n\n\nEach architecture also supports some specific options, list of options is documented in [segmentation RAML library](segmentation_pipeline/schemas/segmentation.raml#L166).\n\nSupported augmentations are documented in [augmentation RAML library](segmentation_pipeline/schemas/augmenters.raml).\n\nCallbacks are documented in [callbacks RAML library](segmentation_pipeline/schemas/callbacks.raml).  \n\n## Custom architectures, callbacks, metrics\n\nClassification pipeline uses keras custom objects registry to find entities, so if you need to use\ncustom loss function, activation or metric all that you need to do is to register it in Keras as: \n\n```python\nkeras.utils.get_custom_objects()[\"my_loss\"]= my_loss\n```\n\nIf you want to inject new architecture, you should register it in `classification.custom_models` dictionary.\n\nFor example:\n```python\nclassification.custom.models['MyUnet']=MyUnet \n```\nwhere `MyUnet` is a function that accepts architecture parameters as arguments and returns an instance\nof keras model.\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/musket-ml/classification_training_pipeline", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "classification-pipeline", "package_url": "https://pypi.org/project/classification-pipeline/", "platform": "", "project_url": "https://pypi.org/project/classification-pipeline/", "project_urls": {"Homepage": "https://github.com/musket-ml/classification_training_pipeline"}, "release_url": "https://pypi.org/project/classification-pipeline/0.432/", "requires_dist": ["musket-core"], "requires_python": "", "summary": "Declaratively configured pipeline for image classification", "version": "0.432", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Classification training pipeline</h1>\n<p><img alt=\"Build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/261e3d4dbd2eb672c71ad74f0d8ec5a1f33b813f/68747470733a2f2f7472617669732d63692e636f6d2f6d75736b65742d6d6c2f636c617373696669636174696f6e5f747261696e696e675f706970656c696e652e7376673f6272616e63683d6d6173746572\"></p>\n<p>My puny attempt to build reusable training pipeline for image classification</p>\n<ul>\n<li><a href=\"#motivation\" rel=\"nofollow\">Motivation</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage-guide\" rel=\"nofollow\">Usage guide</a>\n<ul>\n<li><a href=\"#training-a-model\" rel=\"nofollow\">Training a model</a>\n<ul>\n<li><a href=\"#image-and-mask-augmentations\" rel=\"nofollow\">Image/Mask Augmentations</a></li>\n<li><a href=\"#freezing-and-unfreezing-encoder\" rel=\"nofollow\">Freezing/Unfreezing encoder</a></li>\n<li><a href=\"#custom-datasets\" rel=\"nofollow\">Custom datasets</a></li>\n<li><a href=\"#balancing-your-data\" rel=\"nofollow\">Balancing your data</a></li>\n<li><a href=\"#multistage-training\" rel=\"nofollow\">Multistage training</a></li>\n<li><a href=\"#composite-losses\" rel=\"nofollow\">Composite losses</a></li>\n<li><a href=\"#cyclical-learning-rates\" rel=\"nofollow\">Cyclical learning rates</a></li>\n<li><a href=\"#lr-finder\" rel=\"nofollow\">LR Finder</a></li>\n<li><a href=\"#background-augmenter\" rel=\"nofollow\">Background Augmenter</a></li>\n<li><a href=\"#training-on-crops\" rel=\"nofollow\">Training on crops</a></li>\n</ul>\n</li>\n<li><a href=\"#using-trained-model\" rel=\"nofollow\">Using trained model</a>\n<ul>\n<li><a href=\"#ensembling-predictions\" rel=\"nofollow\">Ensembling predictions and test time augmentation</a></li>\n</ul>\n</li>\n<li><a href=\"#custom-evaluation-code\" rel=\"nofollow\">Custom evaluation code</a></li>\n<li><a href=\"#accessing-model\" rel=\"nofollow\">Accessing model</a></li>\n</ul>\n</li>\n<li><a href=\"#analyzing-experiments-results\" rel=\"nofollow\">Analyzing Experiments Results</a></li>\n<li><a href=\"#what-is-supported-\" rel=\"nofollow\">What is supported?</a></li>\n<li><a href=\"#custom-architectures--callbacks--metrics\" rel=\"nofollow\">Custom architectures, callbacks, metrics</a></li>\n<li><a href=\"#examples\" rel=\"nofollow\">Examples</a></li>\n<li><a href=\"#faq\" rel=\"nofollow\">Faq</a></li>\n</ul>\n<h2>Motivation</h2>\n<p>Idea for this project came from my first attempts to participate in Kaggle competitions. My programmers heart was painfully damaged by looking on my own code as well as on other people kernels. Code was highly repetitive, suffering from numerous reimplementations of same or almost same things through the kernels, model/experiment configuration was often mixed with models code, in other words - from programmer perspective it all looked horrible.</p>\n<p>So I decided to extract repetitive things into framework that will work at least for me and will follow these statements:</p>\n<ul>\n<li>experiment configurations should be cleanly separated from model definitions;</li>\n<li>experiment configuration files should be easy to compare and should fully describe experiment that is being performed except for the dataset;</li>\n<li>common blocks like an architecture, callbacks, storing model metrics, visualizing network predictions, should be written once and be a part of common library</li>\n</ul>\n<h2>Installation</h2>\n<pre><code>pip install classification_pipeline\n</code></pre>\n<p><em>Note: this package requires python 3.6</em></p>\n<h2>Usage guide</h2>\n<h3>Training a model</h3>\n<p>Let's start from a simple example of classification. Suppose, your data are structured as follows: a .cvs file with images ids and their labels and a folder with all these images. For training a neural network to classify these images all you need are few lines of python code:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">musket_core</span>\n<span class=\"kn\">from</span> <span class=\"nn\">classification_pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">classification</span>\n<span class=\"k\">class</span> <span class=\"nc\">ProteinDataGenerator</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">paths</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">paths</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">paths</span><span class=\"p\">,</span> <span class=\"n\">labels</span>\n\n\n    <span class=\"k\">def</span> <span class=\"fm\">__len__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">paths</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">idx</span><span class=\"p\">):</span>\n        <span class=\"n\">X</span><span class=\"p\">,</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">__load_image</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">paths</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]),</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">labels</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">PredictionItem</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">paths</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">],</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">__load_image</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">path</span><span class=\"p\">):</span>\n        <span class=\"n\">R</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">path</span> <span class=\"o\">+</span> <span class=\"s1\">'_red.png'</span><span class=\"p\">)</span>\n        <span class=\"n\">G</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">path</span> <span class=\"o\">+</span> <span class=\"s1\">'_green.png'</span><span class=\"p\">)</span>\n        <span class=\"n\">B</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">path</span> <span class=\"o\">+</span> <span class=\"s1\">'_blue.png'</span><span class=\"p\">)</span>\n\n\n        <span class=\"n\">im</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">((</span>\n            <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">R</span><span class=\"p\">),</span>\n            <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">G</span><span class=\"p\">),</span>\n            <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">),</span>\n        <span class=\"p\">),</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">im</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">ProteinDataGenerator</span><span class=\"p\">(</span><span class=\"n\">paths</span><span class=\"p\">,</span><span class=\"n\">labels</span><span class=\"p\">)</span>\n<span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"s2\">\"config.yaml\"</span><span class=\"p\">)</span>\n<span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">)</span>\n</pre>\n<p>Looks simple, but there is a <code>config.yaml</code> file in the code, and probably it is the place where everything actually happens.</p>\n<pre><span class=\"nt\">architecture</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">DenseNet201</span> <span class=\"c1\">#pre-trained model we are going to use</span>\n<span class=\"nt\">pooling</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">avg</span>\n<span class=\"nt\">augmentation</span><span class=\"p\">:</span> <span class=\"c1\">#define some minimal augmentations on images</span>\n <span class=\"nt\">Fliplr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.5</span>\n <span class=\"nt\">Flipud</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.5</span>\n<span class=\"nt\">classes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">28</span> <span class=\"c1\">#define the number of classes</span>\n<span class=\"nt\">activation</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">sigmoid</span> <span class=\"c1\">#as we have multilabel classification, the activation for last layer is sigmoid</span>\n<span class=\"nt\">weights</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">imagenet</span> <span class=\"c1\">#we would like to start from network pretrained on imagenet dataset</span>\n<span class=\"nt\">shape</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">224</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">224</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">3</span><span class=\"p p-Indicator\">]</span> <span class=\"c1\">#our desired input image size, everything will be resized to fit</span>\n<span class=\"nt\">optimizer</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Adam</span> <span class=\"c1\">#Adam optimizer is a good default choice</span>\n<span class=\"nt\">batch</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">16</span> <span class=\"c1\">#our batch size will be 16</span>\n<span class=\"nt\">lr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.005</span>\n<span class=\"nt\">copyWeights</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>\n<span class=\"nt\">metrics</span><span class=\"p\">:</span> <span class=\"c1\">#we would like to track some metrics</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">binary_accuracy</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">macro_f1</span>\n<span class=\"nt\">primary_metric</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">val_binary_accuracy</span> <span class=\"c1\">#the most interesting metric is val_binary_accuracy</span>\n<span class=\"nt\">primary_metric_mode</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">max</span>\n<span class=\"nt\">callbacks</span><span class=\"p\">:</span> <span class=\"c1\">#configure some minimal callbacks</span>\n  <span class=\"nt\">EarlyStopping</span><span class=\"p\">:</span>\n    <span class=\"nt\">patience</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">3</span>\n    <span class=\"nt\">monitor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">val_macro_f1</span>\n    <span class=\"nt\">mode</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">max</span>\n    <span class=\"nt\">verbose</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">1</span>\n  <span class=\"nt\">ReduceLROnPlateau</span><span class=\"p\">:</span>\n    <span class=\"nt\">patience</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">2</span>\n    <span class=\"nt\">factor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.3</span>\n    <span class=\"nt\">monitor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">val_binary_accuracy</span>\n    <span class=\"nt\">mode</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">max</span>\n    <span class=\"nt\">cooldown</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">1</span>\n    <span class=\"nt\">verbose</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">1</span>\n<span class=\"nt\">loss</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">binary_crossentropy</span> <span class=\"c1\">#we use binary_crossentropy loss</span>\n<span class=\"nt\">stages</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">epochs</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">10</span> <span class=\"c1\">#let's go for 100 epochs</span>\n</pre>\n<p>So as you see, we have decomposed our task in two parts, <em>code that actually trains the model</em> and <em>experiment configuration</em>,\nwhich determines the model and how it should be trained from the set of predefined building blocks.</p>\n<p>What does this code actually do behind the scenes?</p>\n<ul>\n<li>it splits your data into 5 folds, and trains one model per fold;</li>\n<li>it takes care of model checkpointing, generates example image/label tuples, collects training metrics. All this data will\nbe stored in the folders just near your <code>config.yaml</code>;</li>\n<li>All your folds are initialized from fixed default seed, so different experiments will use exactly the same train/validation splits.</li>\n</ul>\n<h4>Image Augmentations</h4>\n<p>Framework uses awesome <a href=\"https://github.com/aleju/imgaug\" rel=\"nofollow\">imgaug</a> library for augmentation, so you only need to configure your augmentation process in declarative way like in the following example:</p>\n<pre><span class=\"nt\">augmentation</span><span class=\"p\">:</span>  \n  <span class=\"nt\">Fliplr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.5</span>\n  <span class=\"nt\">Flipud</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.5</span>\n  <span class=\"nt\">Affine</span><span class=\"p\">:</span>\n    <span class=\"nt\">scale</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">0.8</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">1.5</span><span class=\"p p-Indicator\">]</span> <span class=\"c1\">#random scalings</span>\n    <span class=\"nt\">translate_percent</span><span class=\"p\">:</span>\n      <span class=\"nt\">x</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">-0.2</span><span class=\"p p-Indicator\">,</span><span class=\"nv\">0.2</span><span class=\"p p-Indicator\">]</span> <span class=\"c1\">#random shifts</span>\n      <span class=\"nt\">y</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">-0.2</span><span class=\"p p-Indicator\">,</span><span class=\"nv\">0.2</span><span class=\"p p-Indicator\">]</span>\n    <span class=\"nt\">rotate</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">-16</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">16</span><span class=\"p p-Indicator\">]</span> <span class=\"c1\">#random rotations on -16,16 degrees</span>\n    <span class=\"nt\">shear</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">-16</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">16</span><span class=\"p p-Indicator\">]</span> <span class=\"c1\">#random shears on -16,16 degrees</span>\n</pre>\n<h4>Freezing/Unfreezing encoder</h4>\n<p>Freezing encoder is often used with transfer learning. If you want to start with frozen encoder just add</p>\n<pre><span class=\"nt\">freeze_encoder</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>\n<span class=\"nt\">stages</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">epochs</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">10</span> <span class=\"c1\">#Let's go for 10 epochs with frozen encoder</span>\n\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">epochs</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">100</span> <span class=\"c1\">#Now let's go for 100 epochs with trainable encoder</span>\n    <span class=\"nt\">unfreeze_encoder</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>  \n</pre>\n<p>in your experiments configuration, then on some stage configuration just add</p>\n<pre><span class=\"nt\">unfreeze_encoder</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>\n</pre>\n<p>to stage settings.</p>\n<p><em>Note: This option is not supported for DeeplabV3 architecture.</em></p>\n<h4>Custom datasets</h4>\n<p>You can declare your own dataset class as in this example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">musket_core.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">PredictionItem</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">imageio</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">cv2</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Classification</span><span class=\"p\">:</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"n\">imgPath</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">species</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'Black-grass'</span><span class=\"p\">,</span> <span class=\"s1\">'Charlock'</span><span class=\"p\">,</span> <span class=\"s1\">'Cleavers'</span><span class=\"p\">,</span> <span class=\"s1\">'Common Chickweed'</span><span class=\"p\">,</span> <span class=\"s1\">'Common wheat'</span><span class=\"p\">,</span>\n           <span class=\"s1\">'Fat Hen'</span><span class=\"p\">,</span> <span class=\"s1\">'Loose Silky-bent'</span><span class=\"p\">,</span> <span class=\"s1\">'Maize'</span><span class=\"p\">,</span> <span class=\"s1\">'Scentless Mayweed'</span><span class=\"p\">,</span>\n           <span class=\"s1\">'Shepherds Purse'</span><span class=\"p\">,</span> <span class=\"s1\">'Small-flowered Cranesbill'</span><span class=\"p\">,</span> <span class=\"s1\">'Sugar beet'</span><span class=\"p\">]</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">targets</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">s_id</span><span class=\"p\">,</span> <span class=\"n\">s</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">species</span><span class=\"p\">):</span>\n            <span class=\"n\">s_folder</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">imgPath</span><span class=\"p\">,</span><span class=\"n\">s</span><span class=\"p\">)</span>\n            <span class=\"k\">for</span> <span class=\"n\">file</span> <span class=\"ow\">in</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">listdir</span><span class=\"p\">(</span><span class=\"n\">s_folder</span><span class=\"p\">):</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">s_folder</span><span class=\"p\">,</span> <span class=\"n\">file</span><span class=\"p\">))</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">targets</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">s_id</span><span class=\"p\">)</span>\n                <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">)</span>\n\n\n    <span class=\"k\">def</span> <span class=\"fm\">__len__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">)</span>\n\n\n    <span class=\"k\">def</span> <span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">item_file</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">item</span><span class=\"p\">]</span>\n        <span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">targets</span><span class=\"p\">[</span><span class=\"n\">item</span><span class=\"p\">]</span>\n        <span class=\"n\">t</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">species</span><span class=\"p\">))</span>\n        <span class=\"n\">t</span><span class=\"p\">[</span><span class=\"n\">target</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>\n        <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">read_image</span><span class=\"p\">(</span><span class=\"n\">item_file</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">))</span>\n        <span class=\"k\">return</span> <span class=\"n\">PredictionItem</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids</span><span class=\"p\">[</span><span class=\"n\">item</span><span class=\"p\">],</span> <span class=\"n\">image</span><span class=\"p\">,</span> <span class=\"n\">t</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">read_image</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">filepath</span><span class=\"p\">,</span> <span class=\"n\">target_size</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n        <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"n\">filepath</span><span class=\"p\">,</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">IMREAD_COLOR</span><span class=\"p\">)</span>\n        <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">resize</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">(),</span> <span class=\"n\">target_size</span><span class=\"p\">,</span> <span class=\"n\">interpolation</span> <span class=\"o\">=</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">INTER_AREA</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">img</span>\n</pre>\n<h3>Multi output classification</h3>\n<p>Sometimes you need to create network that performs several classification tasks at the same moment, in this situation\nyou need to declare <code>classes</code> , <code>activation</code> and <code>loss</code> as the lists of class counts, activation functions and losses\nlike in the following snippet:</p>\n<pre><span class=\"nt\">classes</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span> <span class=\"nv\">4</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">4</span> <span class=\"p p-Indicator\">]</span> <span class=\"c1\">#define the number of classes</span>\n<span class=\"nt\">activation</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">sigmoid</span><span class=\"p p-Indicator\">,</span><span class=\"nv\">sigmoid</span><span class=\"p p-Indicator\">]</span>\n<span class=\"nt\">loss</span><span class=\"p\">:</span> \n  <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">binary_crossentropy</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">binary_crossentropy</span>\n<span class=\"nt\">primary_metric</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">val_loss</span> <span class=\"c1\">#the most interesting metric is val_binary_accuracy</span>\n<span class=\"nt\">primary_metric_mode</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">min</span>  \n</pre>\n<p>it is also very likely that you need to change primary metric to <code>val_loss</code></p>\n<h4>Balancing your data</h4>\n<p>One common case is the situation when part of your images does not contain any objects of interest, like in\n<a href=\"https://www.kaggle.com/c/airbus-ship-detection/overview\" rel=\"nofollow\">Airbus ship detection challenge</a>. More over your data may\nbe to heavily inbalanced, so you may want to rebalance it. Alternatively you may want to inject some additional\nimages that do not contain objects of interest to decrease amount of false positives that will be produced by the framework.</p>\n<p>These scenarios are supported by <code>negatives</code> and <code>validation_negatives</code> settings of training stage configuration,\nthese settings accept following values:</p>\n<ul>\n<li>none - exclude negative examples from the data</li>\n<li>real - include all negative examples</li>\n<li>integer number(1 or 2 or anything), how many negative examples should be included per one positive example</li>\n</ul>\n<p>if you are using this setting your dataset class must support <code>isPositive</code> method which returns true for indexes\nwhich contain positive examples:</p>\n<pre>    <span class=\"k\">def</span> <span class=\"nf\">isPositive</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"n\">pixels</span><span class=\"o\">=</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ddd</span><span class=\"o\">.</span><span class=\"n\">get_group</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">ids</span><span class=\"p\">[</span><span class=\"n\">item</span><span class=\"p\">])[</span><span class=\"s2\">\"EncodedPixels\"</span><span class=\"p\">]</span>\n        <span class=\"k\">for</span> <span class=\"n\">mask</span> <span class=\"ow\">in</span> <span class=\"n\">pixels</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">):</span>\n                <span class=\"k\">return</span> <span class=\"kc\">True</span><span class=\"p\">;</span>\n        <span class=\"k\">return</span> <span class=\"kc\">False</span>\n</pre>\n<h4>Multistage training</h4>\n<p>Sometimes you need to split your training into several stages. You can easily do it by adding several stage entries\nin your experiment configuration file like in the following example:</p>\n<pre><span class=\"nt\">stages</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">epochs</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">6</span> <span class=\"c1\">#Train for 6 epochs</span>\n    <span class=\"nt\">negatives</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">none</span> <span class=\"c1\">#do not include negative examples in your training set </span>\n    <span class=\"nt\">validation_negatives</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">real</span> <span class=\"c1\">#validation should contain all negative examples    </span>\n\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">lr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.0001</span> <span class=\"c1\">#let's use different starting learning rate</span>\n    <span class=\"nt\">epochs</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">6</span>\n    <span class=\"nt\">negatives</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">real</span>\n    <span class=\"nt\">validation_negatives</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">real</span>\n\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">loss</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">lovasz_loss</span> <span class=\"c1\">#let's override loss function</span>\n    <span class=\"nt\">lr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.00001</span>\n    <span class=\"nt\">epochs</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">6</span>\n    <span class=\"nt\">initial_weights</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">./fpn-resnext2/weights/best-0.1.weights</span> <span class=\"c1\">#let's load weights from this file    </span>\n</pre>\n<p>Stage entries allow you to configure custom learning rate, balance of negative examples, callbacks, loss function\nand even initial weights which should be used on a particular stage.</p>\n<h4>Composite losses</h4>\n<p>Framework supports composing loss as a weighted sum of predefined loss functions. For example, following construction</p>\n<pre><span class=\"nt\">loss</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">binary_crossentropy+0.1*dice_loss</span>\n</pre>\n<p>will result in loss function which is composed from <code>binary_crossentropy</code> and  <code>dice_loss</code> functions.</p>\n<h4>Cyclical learning rates</h4>\n<p><img alt=\"Example\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/96b9e4ff1b745905a2ab709896d0a7baf2b7b117/68747470733a2f2f6769746875622e636f6d2f62636b656e73746c65722f434c522f626c6f622f6d61737465722f696d616765732f747269616e67756c6172446961672e706e673f7261773d74727565\"></p>\n<p>As told in <a href=\"https://arxiv.org/abs/1506.01186\" rel=\"nofollow\">Cyclical learning rates for training neural networks</a> CLR policies can provide quicker converge for some neural network tasks and architectures.</p>\n<p><img alt=\"Example2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f920af2b7f25c7c0341d0f6d325c33779f8b57d0/68747470733a2f2f6769746875622e636f6d2f62636b656e73746c65722f434c522f7261772f6d61737465722f696d616765732f63696661722e706e67\"></p>\n<p>We support them by adopting Brad Kenstler <a href=\"https://github.com/bckenstler/CLR\" rel=\"nofollow\">CLR callback</a> for Keras.</p>\n<p>If you want to use them, just add <code>CyclicLR</code> in your experiment configuration file as shown below:</p>\n<pre><span class=\"nt\">callbacks</span><span class=\"p\">:</span>\n  <span class=\"nt\">EarlyStopping</span><span class=\"p\">:</span>\n    <span class=\"nt\">patience</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">40</span>\n    <span class=\"nt\">monitor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">val_binary_accuracy</span>\n    <span class=\"nt\">verbose</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">1</span>\n  <span class=\"nt\">CyclicLR</span><span class=\"p\">:</span>\n     <span class=\"nt\">base_lr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.0001</span>\n     <span class=\"nt\">max_lr</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">0.01</span>\n     <span class=\"nt\">mode</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">triangular2</span>\n     <span class=\"nt\">step_size</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">300</span>\n</pre>\n<h4>LR Finder</h4>\n<p><a href=\"https://arxiv.org/abs/1506.01186\" rel=\"nofollow\">Estimating optimal learning rate for your model</a> is an important thing, we support this by using slightly changed\nversion of <a href=\"https://github.com/surmenok/keras_lr_finder\" rel=\"nofollow\">Pavel Surmenok - Keras LR Finder</a></p>\n<pre><span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">yaml</span><span class=\"p\">)</span>\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">SimplePNGMaskDataSet</span><span class=\"p\">(</span><span class=\"s2\">\"./train\"</span><span class=\"p\">,</span><span class=\"s2\">\"./train_mask\"</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"err\">???????????????????</span>\n<span class=\"n\">finder</span><span class=\"o\">=</span><span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">lr_find</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">,</span><span class=\"n\">start_lr</span><span class=\"o\">=</span><span class=\"mf\">0.00001</span><span class=\"p\">,</span><span class=\"n\">end_lr</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">finder</span><span class=\"o\">.</span><span class=\"n\">plot_loss</span><span class=\"p\">(</span><span class=\"n\">n_skip_beginning</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">n_skip_end</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n<span class=\"n\">finder</span><span class=\"o\">.</span><span class=\"n\">plot_loss_change</span><span class=\"p\">(</span><span class=\"n\">sma</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">n_skip_beginning</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">n_skip_end</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">y_lim</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"mf\">0.01</span><span class=\"p\">))</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<p>will result in this couple of helpful images:</p>\n<p><img alt=\"image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4deba800b74436b525f9320bea5ccb72b277eeba/68747470733a2f2f63616d6f2e67697468756275736572636f6e74656e742e636f6d2f623431616561666630306662376232313462356562326535633135316537653335336137323633652f363837343734373037333361326632663633363436653264363936643631363736353733326433313265366436353634363937353664326536333666366432663664363137383266333133363330333032663331326134383536366135663334346335373635366436613736346635373736326436333531346633393739333936373265373036653637\"></p>\n<p><img alt=\"image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2424132b03692a778624663b1965650c7eaba5c/68747470733a2f2f63616d6f2e67697468756275736572636f6e74656e742e636f6d2f383334393936643332626264326564663734333563356531303562353361366234343765663038332f363837343734373037333361326632663633363436653264363936643631363736353733326433313265366436353634363937353664326536333666366432663664363137383266333133363330333032663331326133383337366434623731356635383666366435393739346134353332333936633339333134623330363437373265373036653637\"></p>\n<h4>Training on crops</h4>\n<p>Your images can be too large to train model on them. In this case you probably want to train model on crops. All\nthat you need to do is to specify number of splits per axis. For example, following lines in config</p>\n<pre><span class=\"nt\">shape</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">[</span><span class=\"nv\">768</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">768</span><span class=\"p p-Indicator\">,</span> <span class=\"nv\">3</span><span class=\"p p-Indicator\">]</span>\n<span class=\"nt\">crops</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">3</span>\n</pre>\n<p>will lead to splitting each image into 9 cells (3 horizontal splits and 3 vertical splits) and training model on these splits.\nAugmentations will be run separately on each cell.</p>\n<p>During prediction time, your images will be split into these cells, prediction will be executed on each cell, and then results\nwill be assembled in single final mask. Thus the whole process of cropping will be invisible from a consumer perspective.</p>\n<h3>Using trained model</h3>\n<p>Okey, our model is trained, now we need to actually do image classification. Let's say, we need to run image classification on\nimages in the directory and store results in csv file:</p>\n<pre><span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"n\">images</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"c1\">#Now let's use best model from fold 0 to do image segmentation on images from images_to_segment</span>\n<span class=\"n\">preds</span> <span class=\"o\">=</span> <span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">predict_all_to_array</span><span class=\"p\">(</span><span class=\"n\">dataset_test</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">dataset_test</span><span class=\"p\">):</span>\n    <span class=\"n\">images</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">dataset_test</span><span class=\"o\">.</span><span class=\"n\">get_id</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">))</span>\n    <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">preds</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n    <span class=\"n\">predictions</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">dataset_test</span><span class=\"o\">.</span><span class=\"n\">get_label</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">))</span>\n\n<span class=\"c1\">#Let's store results in csv</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">.</span><span class=\"n\">from_dict</span><span class=\"p\">({</span><span class=\"s1\">'file'</span><span class=\"p\">:</span> <span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"s1\">'species'</span><span class=\"p\">:</span> <span class=\"n\">predictions</span><span class=\"p\">})</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s1\">'submission.csv'</span><span class=\"p\">,</span> <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<h4>Ensembling predictions</h4>\n<p>And what if you want to ensemble models from several folds? Just pass a list of fold numbers to\n<code>predict_all_to_array</code> like in the following example:</p>\n<pre> <span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">predict_all_to_array</span><span class=\"p\">(</span><span class=\"n\">dataset_test</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">],</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Another supported option is to ensemble results from extra test time augmentation (flips) by adding keyword arg <code>ttflips=True</code>.</p>\n<h3>Custom evaluation code</h3>\n<p>Sometimes you need to run custom evaluation code. In such case you may use: <code>evaluateAll</code> method, which provides an iterator\non the batches containing original images, training masks and predicted masks</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">evaluateAll</span><span class=\"p\">(</span><span class=\"n\">ds</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"o\">.</span><span class=\"n\">predicted_maps_aug</span><span class=\"p\">)):</span>\n        <span class=\"n\">masks</span> <span class=\"o\">=</span> <span class=\"n\">ds</span><span class=\"o\">.</span><span class=\"n\">get_masks</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n        <span class=\"k\">for</span> <span class=\"n\">d</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">20</span><span class=\"p\">):</span>\n            <span class=\"n\">cur_seg</span> <span class=\"o\">=</span> <span class=\"n\">binary_opening</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"o\">.</span><span class=\"n\">predicted_maps_aug</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">arr</span> <span class=\"o\">&gt;</span> <span class=\"n\">d</span><span class=\"o\">/</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">disk</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n            <span class=\"n\">cm</span> <span class=\"o\">=</span> <span class=\"n\">rle</span><span class=\"o\">.</span><span class=\"n\">masks_as_images</span><span class=\"p\">(</span><span class=\"n\">rle</span><span class=\"o\">.</span><span class=\"n\">multi_rle_encode</span><span class=\"p\">(</span><span class=\"n\">cur_seg</span><span class=\"p\">))</span>\n            <span class=\"n\">pr</span> <span class=\"o\">=</span> <span class=\"n\">f2</span><span class=\"p\">(</span><span class=\"n\">masks</span><span class=\"p\">,</span> <span class=\"n\">cm</span><span class=\"p\">);</span>\n            <span class=\"n\">total</span><span class=\"p\">[</span><span class=\"n\">d</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">total</span><span class=\"p\">[</span><span class=\"n\">d</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"n\">pr</span>\n</pre>\n<h3>Accessing model</h3>\n<p>You may get trained keras model by calling: <code>cfg.load_model(fold, stage)</code>.</p>\n<h2>Analyzing experiments results</h2>\n<p>Okey, we have done a lot of experiments and now we need to compare the results and understand what works better. This repository\ncontains <a href=\"segmentation_pipeline/analize.py\" rel=\"nofollow\">script</a> which may be used to analyze folder containing sub folders\nwith experiment configurations and results. This script gathers all configurations, diffs them by doing structural diff, then\nfor each configuration it averages metrics for all folds and  generates csv file containing metrics and parameters that\nwas actually changed in your experiment like in the following <a href=\"report.csv\" rel=\"nofollow\">example</a></p>\n<p>This script accepts following arguments:</p>\n<ul>\n<li>inputFolder - root folder to search for experiments configurations and results</li>\n<li>output - file to store aggregated metrics</li>\n<li>onlyMetric - if you specify this option all other metrics will not be written in the report file</li>\n<li>sortBy - metric that should be used to sort results</li>\n</ul>\n<p>Example:</p>\n<pre>python analize.py --inputFolder ./experiments --output ./result.py\n</pre>\n<h2>What is supported?</h2>\n<p>At this moment classification pipeline supports following pre-trained models:</p>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">Resnet</a>\n<ul>\n<li>ResNet18</li>\n<li>ResNet34</li>\n<li>ResNet50</li>\n<li>ResNet101</li>\n<li>ResNet152</li>\n<li>ResNeXt50</li>\n<li>ResNeXt101</li>\n</ul>\n</li>\n<li><a href=\"https://arxiv.org/abs/1409.1556\" rel=\"nofollow\">VGG</a>:\n<ul>\n<li>VGG16</li>\n<li>VGG19</li>\n</ul>\n</li>\n<li><a href=\"https://arxiv.org/abs/1512.00567\" rel=\"nofollow\">InceptionV3</a></li>\n<li><a href=\"https://arxiv.org/abs/1602.07261\" rel=\"nofollow\">InceptionResNetV2</a></li>\n<li><a href=\"https://arxiv.org/abs/1610.02357\" rel=\"nofollow\">Xception</a></li>\n<li><a href=\"https://arxiv.org/pdf/1704.04861.pdf\" rel=\"nofollow\">MobileNet</a></li>\n<li><a href=\"https://arxiv.org/abs/1801.04381\" rel=\"nofollow\">MobileNetV2</a></li>\n<li><a href=\"https://arxiv.org/abs/1608.06993\" rel=\"nofollow\">DenseNet</a>:\n<ul>\n<li>DenseNet121</li>\n<li>DenseNet169</li>\n<li>DenseNet201</li>\n</ul>\n</li>\n<li><a href=\"https://arxiv.org/abs/1707.07012\" rel=\"nofollow\">NasNet</a>:\n<ul>\n<li>NASNetMobile</li>\n<li>NASNetLarge</li>\n</ul>\n</li>\n</ul>\n<p>Each architecture also supports some specific options, list of options is documented in <a href=\"segmentation_pipeline/schemas/segmentation.raml#L166\" rel=\"nofollow\">segmentation RAML library</a>.</p>\n<p>Supported augmentations are documented in <a href=\"segmentation_pipeline/schemas/augmenters.raml\" rel=\"nofollow\">augmentation RAML library</a>.</p>\n<p>Callbacks are documented in <a href=\"segmentation_pipeline/schemas/callbacks.raml\" rel=\"nofollow\">callbacks RAML library</a>.</p>\n<h2>Custom architectures, callbacks, metrics</h2>\n<p>Classification pipeline uses keras custom objects registry to find entities, so if you need to use\ncustom loss function, activation or metric all that you need to do is to register it in Keras as:</p>\n<pre><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">get_custom_objects</span><span class=\"p\">()[</span><span class=\"s2\">\"my_loss\"</span><span class=\"p\">]</span><span class=\"o\">=</span> <span class=\"n\">my_loss</span>\n</pre>\n<p>If you want to inject new architecture, you should register it in <code>classification.custom_models</code> dictionary.</p>\n<p>For example:</p>\n<pre><span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">custom</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"p\">[</span><span class=\"s1\">'MyUnet'</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">MyUnet</span> \n</pre>\n<p>where <code>MyUnet</code> is a function that accepts architecture parameters as arguments and returns an instance\nof keras model.</p>\n\n          </div>"}, "last_serial": 6172736, "releases": {"0.22": [{"comment_text": "", "digests": {"md5": "57aabc5a148e6c40bd48d76ef9dc19c6", "sha256": "efa5996926b4d9fb65ce597ef9a1891522c873efdd57e5988a972ec2ecc6a8d4"}, "downloads": -1, "filename": "classification_pipeline-0.22-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "57aabc5a148e6c40bd48d76ef9dc19c6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 2394, "upload_time": "2018-12-04T13:23:24", "upload_time_iso_8601": "2018-12-04T13:23:24.104078Z", "url": "https://files.pythonhosted.org/packages/1c/89/aea316abdc09822d41b0b5559a38449813fc8e172cf65f35acc877c2a852/classification_pipeline-0.22-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d458814eafd976bac00253a293f5a86", "sha256": "c8ae2fe2874cb1d2cbd126ae80076b9dfb4d1662e35936edc4d00c9c7f81b8d2"}, "downloads": -1, "filename": "classification_pipeline-0.22.tar.gz", "has_sig": false, "md5_digest": "0d458814eafd976bac00253a293f5a86", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1001, "upload_time": "2018-12-04T13:23:26", "upload_time_iso_8601": "2018-12-04T13:23:26.404169Z", "url": "https://files.pythonhosted.org/packages/46/88/18ca3568b37c9ba95494acd614a1fc31a3a9712380dfe93c710e9610b9a9/classification_pipeline-0.22.tar.gz", "yanked": false}], "0.23": [{"comment_text": "", "digests": {"md5": "69e974c732e22660c44e9a089b85edf5", "sha256": "0ed8c33bd1a5ed249e52a7424e29b46d6f86f7d19523954beb64dd4d8a8e900b"}, "downloads": -1, "filename": "classification_pipeline-0.23-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "69e974c732e22660c44e9a089b85edf5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4413, "upload_time": "2018-12-04T13:31:06", "upload_time_iso_8601": "2018-12-04T13:31:06.925249Z", "url": "https://files.pythonhosted.org/packages/da/00/eff0cdb4af6d2b028f965a4d8cc33b8dfd6b043fc2a14d475fa4a4a610b9/classification_pipeline-0.23-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7a2a6c859b64596cff1d950457a5087d", "sha256": "354a62a06d89c77a6f0edda170210360cce52979e8e3802260b94a3696bba0cb"}, "downloads": -1, "filename": "classification_pipeline-0.23.tar.gz", "has_sig": false, "md5_digest": "7a2a6c859b64596cff1d950457a5087d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2629, "upload_time": "2018-12-04T13:31:08", "upload_time_iso_8601": "2018-12-04T13:31:08.047220Z", "url": "https://files.pythonhosted.org/packages/1a/34/3c80e35534f3c956bf85e662fca9695e1d32f2f5f187dcacd103c8ab6368/classification_pipeline-0.23.tar.gz", "yanked": false}], "0.24": [{"comment_text": "", "digests": {"md5": "bec7207fc688904c5ed16810078d2306", "sha256": "7ef66240abc7af2e332c2e1298073fa6ac3d93a7af1841ca10f18665b649f9c8"}, "downloads": -1, "filename": "classification_pipeline-0.24-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bec7207fc688904c5ed16810078d2306", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4425, "upload_time": "2018-12-04T13:57:59", "upload_time_iso_8601": "2018-12-04T13:57:59.159415Z", "url": "https://files.pythonhosted.org/packages/1c/f1/75e23403ef8e2d9f785337102dffea6f72cfd254943ae334ca7eb746c56f/classification_pipeline-0.24-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef739a615d5c568eb0551870e6f0f754", "sha256": "71b389077ee206010472798590e6b1dfb86b312c2c6cfcca86ef8df6959ca3b6"}, "downloads": -1, "filename": "classification_pipeline-0.24.tar.gz", "has_sig": false, "md5_digest": "ef739a615d5c568eb0551870e6f0f754", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2624, "upload_time": "2018-12-04T13:58:00", "upload_time_iso_8601": "2018-12-04T13:58:00.522397Z", "url": "https://files.pythonhosted.org/packages/d9/c0/ff4a42d28d5726a50ac9deae26f835bf7382c4421f5272f86f1bb6534823/classification_pipeline-0.24.tar.gz", "yanked": false}], "0.26": [{"comment_text": "", "digests": {"md5": "c5bda8e8a8db1eb4d40e75c2b0b45674", "sha256": "dbc939fc74be2bd74683594267061b3f42ed883cfd56392df6c169c95c2a49e9"}, "downloads": -1, "filename": "classification_pipeline-0.26-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c5bda8e8a8db1eb4d40e75c2b0b45674", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4443, "upload_time": "2018-12-10T08:09:03", "upload_time_iso_8601": "2018-12-10T08:09:03.735864Z", "url": "https://files.pythonhosted.org/packages/15/84/09073296cad1259521f193c725bb9040e9b6cb6ed096955218d711664a8e/classification_pipeline-0.26-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6ab4e499f3130425bc26cc1e56215cb2", "sha256": "7ed78b7126c710a5ca6e0fc1a9b7ca970447d0538355aaa8d09fcd2b48e5d101"}, "downloads": -1, "filename": "classification_pipeline-0.26.tar.gz", "has_sig": false, "md5_digest": "6ab4e499f3130425bc26cc1e56215cb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2647, "upload_time": "2018-12-10T08:09:05", "upload_time_iso_8601": "2018-12-10T08:09:05.571071Z", "url": "https://files.pythonhosted.org/packages/8e/5c/a8c5fa2d577840aad8c32f73b0e7e2c00b06e0805a9a36688975093adf64/classification_pipeline-0.26.tar.gz", "yanked": false}], "0.27": [{"comment_text": "", "digests": {"md5": "6436d28294061f80a9fccb84a979383b", "sha256": "d660a28fd6f5ea68d1ed8afa071504e4ecc8de1be42a9da75d56127cf47a0f01"}, "downloads": -1, "filename": "classification_pipeline-0.27-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6436d28294061f80a9fccb84a979383b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4498, "upload_time": "2018-12-15T10:51:26", "upload_time_iso_8601": "2018-12-15T10:51:26.126415Z", "url": "https://files.pythonhosted.org/packages/b5/02/39b689c9ae47d19327aec7c07203ad3f6f3b8619941a7b09524a5ddc83b3/classification_pipeline-0.27-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5b1dfed0083ff87b90213ddc95a5a823", "sha256": "d4528fcec5bdc23e8e670b6fb562b14e61c43a29297de0fce0a8923eb4b914b3"}, "downloads": -1, "filename": "classification_pipeline-0.27.tar.gz", "has_sig": false, "md5_digest": "5b1dfed0083ff87b90213ddc95a5a823", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2705, "upload_time": "2018-12-15T10:51:27", "upload_time_iso_8601": "2018-12-15T10:51:27.804449Z", "url": "https://files.pythonhosted.org/packages/5f/91/38a650de3e47f641c2957b06e33debb9d8f6f1023111eb660d428f7a0cb5/classification_pipeline-0.27.tar.gz", "yanked": false}], "0.29": [{"comment_text": "", "digests": {"md5": "505f5e7f80e50066496d7e2634ba8a11", "sha256": "8356e8cfc0e6475e14f59131f65dd75a0eee9f0daa1b8e5bbae2b1bae44110fa"}, "downloads": -1, "filename": "classification_pipeline-0.29-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "505f5e7f80e50066496d7e2634ba8a11", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4620, "upload_time": "2019-01-02T20:11:03", "upload_time_iso_8601": "2019-01-02T20:11:03.377421Z", "url": "https://files.pythonhosted.org/packages/13/42/b129317c6ae66ff131b2edb66b15e6fdbe290329299af09d1a5c27af6dfb/classification_pipeline-0.29-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5a1f01536c0b79f4c698e916a0a53481", "sha256": "00fbc9f5bc566f105ee16c565f0a36f5b7ddcc24fb139f61e7a942fc90e7585f"}, "downloads": -1, "filename": "classification_pipeline-0.29.tar.gz", "has_sig": false, "md5_digest": "5a1f01536c0b79f4c698e916a0a53481", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2872, "upload_time": "2019-01-02T20:11:05", "upload_time_iso_8601": "2019-01-02T20:11:05.929381Z", "url": "https://files.pythonhosted.org/packages/8b/75/fb54ca39e88cbcc2bf6da378d4746da85057dfd5cfad30e8b91dede62eaa/classification_pipeline-0.29.tar.gz", "yanked": false}], "0.30": [{"comment_text": "", "digests": {"md5": "041cef17bb99bf335c4f1ad95de459ec", "sha256": "9222bd0755af53e7e4e500099218f8f9e085b3e819d06db29b5dbb173e102209"}, "downloads": -1, "filename": "classification_pipeline-0.30-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "041cef17bb99bf335c4f1ad95de459ec", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4744, "upload_time": "2019-01-04T09:10:47", "upload_time_iso_8601": "2019-01-04T09:10:47.494493Z", "url": "https://files.pythonhosted.org/packages/a0/4f/e63d31043e9b50074018249ef6dec3516abadbc1236c7931fe039d388cb9/classification_pipeline-0.30-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0525638523f38ccc578d197f13e3c1c6", "sha256": "3e9f37033ad1ddee6c4611c96ccaf74e9bfa982dd5275626ce77db650b0cc8ea"}, "downloads": -1, "filename": "classification_pipeline-0.30.tar.gz", "has_sig": false, "md5_digest": "0525638523f38ccc578d197f13e3c1c6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9108, "upload_time": "2019-01-04T09:10:50", "upload_time_iso_8601": "2019-01-04T09:10:50.073868Z", "url": "https://files.pythonhosted.org/packages/07/75/e1b5607e558bc4da0733b8858a1fe1ad505154e02f71310d206dc9d8780c/classification_pipeline-0.30.tar.gz", "yanked": false}], "0.31": [{"comment_text": "", "digests": {"md5": "3b0657ebd8ca511e62b94474edcdeda7", "sha256": "40d464a3f1af45cc6b90d3c7ccfa5e35258d86393e6193260bf2c77d06ecd782"}, "downloads": -1, "filename": "classification_pipeline-0.31-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3b0657ebd8ca511e62b94474edcdeda7", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4745, "upload_time": "2019-01-04T09:10:48", "upload_time_iso_8601": "2019-01-04T09:10:48.696029Z", "url": "https://files.pythonhosted.org/packages/a5/3f/38f7561238eeeb072264b9d02e83530b663de6b1266ce457ab7fe9bd43c6/classification_pipeline-0.31-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fd1044002eab9749fd70a8de4c35bb43", "sha256": "09643ccbbc6f7736a7888cb744f9a04c9d377ac99898aba096a490ac43c6ed87"}, "downloads": -1, "filename": "classification_pipeline-0.31.tar.gz", "has_sig": false, "md5_digest": "fd1044002eab9749fd70a8de4c35bb43", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9111, "upload_time": "2019-01-04T09:10:51", "upload_time_iso_8601": "2019-01-04T09:10:51.621612Z", "url": "https://files.pythonhosted.org/packages/f7/05/14bf8d0b0e09fd68ac41c81b5ee0806e4cfe9d04870a5fcaebe2db3c887d/classification_pipeline-0.31.tar.gz", "yanked": false}], "0.32": [{"comment_text": "", "digests": {"md5": "47330827fdb7ddaae2b56d42919a5ef6", "sha256": "0d5d612d2f127d1fcdb21ea963a247f79dd660a0f5b3bc81aef4a09bad6188c5"}, "downloads": -1, "filename": "classification_pipeline-0.32-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "47330827fdb7ddaae2b56d42919a5ef6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4779, "upload_time": "2019-01-04T09:23:04", "upload_time_iso_8601": "2019-01-04T09:23:04.166933Z", "url": "https://files.pythonhosted.org/packages/da/dc/d22a8c524020dfad80452d8ea541223927b68cde7304be588387d42d678a/classification_pipeline-0.32-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0253d6bfa5f2ddbdc043419fd226b719", "sha256": "23a4022b95b72c2e1a92b333767c6dbe107570f75e6019ebe1b6ac93270a0e4c"}, "downloads": -1, "filename": "classification_pipeline-0.32.tar.gz", "has_sig": false, "md5_digest": "0253d6bfa5f2ddbdc043419fd226b719", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9148, "upload_time": "2019-01-04T09:23:05", "upload_time_iso_8601": "2019-01-04T09:23:05.430240Z", "url": "https://files.pythonhosted.org/packages/14/b4/554bdf4d4c75921aefacd116bbc07c98a10f6606fa0e300219972f97b0a3/classification_pipeline-0.32.tar.gz", "yanked": false}], "0.34": [{"comment_text": "", "digests": {"md5": "c62dc0dcdd0aca990fd395acab901a4f", "sha256": "755a3ce736092d6c450758b9a33db29b325b522460c6fe0df4075e13a7190a8f"}, "downloads": -1, "filename": "classification_pipeline-0.34-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c62dc0dcdd0aca990fd395acab901a4f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4779, "upload_time": "2019-01-04T09:33:54", "upload_time_iso_8601": "2019-01-04T09:33:54.287424Z", "url": "https://files.pythonhosted.org/packages/88/5c/2f5dcb241e56a6fb116228097a31f51498182f5fea6b9db0d4a4051b7ea3/classification_pipeline-0.34-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d805e178024f175e5bf7ef171c3ed5ca", "sha256": "af85b94628d87ee2e92bce58ce1ba93791ce211165311123051978ebfed68317"}, "downloads": -1, "filename": "classification_pipeline-0.34.tar.gz", "has_sig": false, "md5_digest": "d805e178024f175e5bf7ef171c3ed5ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9146, "upload_time": "2019-01-04T09:33:56", "upload_time_iso_8601": "2019-01-04T09:33:56.144522Z", "url": "https://files.pythonhosted.org/packages/9c/9d/702a6cfadf06ea56aa46b0a2365283ac9c902ae0e60685323052cd0980f3/classification_pipeline-0.34.tar.gz", "yanked": false}], "0.36": [{"comment_text": "", "digests": {"md5": "d940a4f9d304613859837eaa7bdc72f2", "sha256": "86c62cedd431b42f51ef0d0ea661d71b6afcef644e605e2cfdcca3c2e832cd10"}, "downloads": -1, "filename": "classification_pipeline-0.36-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d940a4f9d304613859837eaa7bdc72f2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4778, "upload_time": "2019-01-04T12:58:26", "upload_time_iso_8601": "2019-01-04T12:58:26.573466Z", "url": "https://files.pythonhosted.org/packages/cd/ae/b57e16c940799e283a93a3132849a9d77d57d0f6ddf635ba9c1119d38ae1/classification_pipeline-0.36-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4cd9aa62929eb1340c5c38f67c734fe2", "sha256": "6ef5c0338b893032d0a7ac93c9ba7f8d7787fa6fbfba9abc146178dad6d8d24a"}, "downloads": -1, "filename": "classification_pipeline-0.36.tar.gz", "has_sig": false, "md5_digest": "4cd9aa62929eb1340c5c38f67c734fe2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9143, "upload_time": "2019-01-04T12:58:29", "upload_time_iso_8601": "2019-01-04T12:58:29.232539Z", "url": "https://files.pythonhosted.org/packages/73/7b/2e8171746f90b89c26202867baecbcca6bc31a4dcd88191efd131a6ddbb5/classification_pipeline-0.36.tar.gz", "yanked": false}], "0.37": [{"comment_text": "", "digests": {"md5": "bf115b2b074485f3d2a4d69b5dd5ba4c", "sha256": "acb79d7583c1d23e524a1a4048d8e6399b226fefd1707a7be9f7648afb01cf70"}, "downloads": -1, "filename": "classification_pipeline-0.37-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bf115b2b074485f3d2a4d69b5dd5ba4c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4777, "upload_time": "2019-01-04T16:30:28", "upload_time_iso_8601": "2019-01-04T16:30:28.061986Z", "url": "https://files.pythonhosted.org/packages/b6/c3/8b5c787a17a3f4ce7e571b1790703f56a7a4de1d5801924957225d0fb551/classification_pipeline-0.37-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c9ea1471162c57d054f8c3607e7e385d", "sha256": "20391859c07c28f02e15d05c632aaa3aa4005a5a7bb06168114ea502468c0a09"}, "downloads": -1, "filename": "classification_pipeline-0.37.tar.gz", "has_sig": false, "md5_digest": "c9ea1471162c57d054f8c3607e7e385d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9155, "upload_time": "2019-01-04T16:30:29", "upload_time_iso_8601": "2019-01-04T16:30:29.418812Z", "url": "https://files.pythonhosted.org/packages/b8/df/d4a94dfe0b7958edef489e5e2c0c6431eb2b31346cc72a2d931fc9f3a222/classification_pipeline-0.37.tar.gz", "yanked": false}], "0.38": [{"comment_text": "", "digests": {"md5": "9f506c9c8998df1d8764cfa73990b4e5", "sha256": "c4751a8646e35816dde374ee59b7d487b5c1980ea3fe07bf32af0d566a62f2fe"}, "downloads": -1, "filename": "classification_pipeline-0.38-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9f506c9c8998df1d8764cfa73990b4e5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4777, "upload_time": "2019-01-05T08:45:45", "upload_time_iso_8601": "2019-01-05T08:45:45.577678Z", "url": "https://files.pythonhosted.org/packages/23/9e/c62ace3f7ce101514be3c904fb9df2e4f566a43e2f8f691d301539364e9c/classification_pipeline-0.38-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "467b8bac889b2a6fca20717c3f971bb8", "sha256": "57df1f960bc798b962f33e55b1fa8e5b86900ff4f9205b0a5bfbb0d9df950480"}, "downloads": -1, "filename": "classification_pipeline-0.38.tar.gz", "has_sig": false, "md5_digest": "467b8bac889b2a6fca20717c3f971bb8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9152, "upload_time": "2019-01-05T08:45:49", "upload_time_iso_8601": "2019-01-05T08:45:49.159780Z", "url": "https://files.pythonhosted.org/packages/7f/bc/ef93ff6a8fbd895ef24b2c66852edea8a23302fc572b9a5467fb4165b23d/classification_pipeline-0.38.tar.gz", "yanked": false}], "0.41": [{"comment_text": "", "digests": {"md5": "95697ba72a5f0ae1e654c4b35f7fe8c9", "sha256": "cb372a746bc58670d3151e98d1dabb67a6e4c2596692825392e6300680a81cd0"}, "downloads": -1, "filename": "classification_pipeline-0.41-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "95697ba72a5f0ae1e654c4b35f7fe8c9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4924, "upload_time": "2019-09-26T17:45:53", "upload_time_iso_8601": "2019-09-26T17:45:53.320405Z", "url": "https://files.pythonhosted.org/packages/82/5e/ea18b5482cfedd43a60fe5b1b9c2fb36737c05766ecec4ef62f276fe6f74/classification_pipeline-0.41-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d1342fc2438cebc19280d1117b2c503a", "sha256": "9e78fbc380c06e853d5f4d702cf8dde53b400b9612addb65c8e47ff414fbdb0e"}, "downloads": -1, "filename": "classification_pipeline-0.41.tar.gz", "has_sig": false, "md5_digest": "d1342fc2438cebc19280d1117b2c503a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9944, "upload_time": "2019-09-26T17:45:54", "upload_time_iso_8601": "2019-09-26T17:45:54.647440Z", "url": "https://files.pythonhosted.org/packages/59/69/aff364b538e44f5dd725aeee69ab0eb363eb11e1a53363ed0e0663a86060/classification_pipeline-0.41.tar.gz", "yanked": false}], "0.42": [{"comment_text": "", "digests": {"md5": "d05deab13892ba4c0717b733713c10af", "sha256": "daf60b7d2240a40b7583df14bca9472d3409d27c56e3a54f1feb322e954606b4"}, "downloads": -1, "filename": "classification_pipeline-0.42-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d05deab13892ba4c0717b733713c10af", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4700, "upload_time": "2019-10-23T12:54:05", "upload_time_iso_8601": "2019-10-23T12:54:05.277721Z", "url": "https://files.pythonhosted.org/packages/7f/ea/68970a55b80ddd960af8302a643a54b9ec7a68889a03720eeef64d44339b/classification_pipeline-0.42-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0eab4cdfae7f4f5a8fcc5db0fb710b78", "sha256": "d4113663466c6581e91aadb16482365d7a701af96113fe48ea3ae45805476b6b"}, "downloads": -1, "filename": "classification_pipeline-0.42.tar.gz", "has_sig": false, "md5_digest": "0eab4cdfae7f4f5a8fcc5db0fb710b78", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10088, "upload_time": "2019-10-23T12:54:07", "upload_time_iso_8601": "2019-10-23T12:54:07.598893Z", "url": "https://files.pythonhosted.org/packages/71/5c/4ccc9671e4addf370e36464431ab450e4301784fd3eaee41f3f1e9b7f7d0/classification_pipeline-0.42.tar.gz", "yanked": false}], "0.43": [{"comment_text": "", "digests": {"md5": "6fdc7ec3a709d991c853a183d3d13609", "sha256": "98492e812dfb064eef13e1b59559d084a8e4fc0fa8b658bb392f8649cfe64d74"}, "downloads": -1, "filename": "classification_pipeline-0.43-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6fdc7ec3a709d991c853a183d3d13609", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4676, "upload_time": "2019-10-24T10:00:55", "upload_time_iso_8601": "2019-10-24T10:00:55.233932Z", "url": "https://files.pythonhosted.org/packages/d4/12/058beeea689203f3e1da0262c9daf779838956b65f7dea774fdb168ef49e/classification_pipeline-0.43-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6361267bcd24be51419570a050c2af06", "sha256": "5e3fb78ee0ab854789d5eb45eb71707421655fcd301391c0d5987d209b5c0d1f"}, "downloads": -1, "filename": "classification_pipeline-0.43.tar.gz", "has_sig": false, "md5_digest": "6361267bcd24be51419570a050c2af06", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10066, "upload_time": "2019-10-24T10:00:58", "upload_time_iso_8601": "2019-10-24T10:00:58.027733Z", "url": "https://files.pythonhosted.org/packages/a3/d9/6c470a601ce805d8fb510f472e6624cd91442e2564232311ce0b67c4af2a/classification_pipeline-0.43.tar.gz", "yanked": false}], "0.431": [{"comment_text": "", "digests": {"md5": "d695cebc24d70fb6753e75268de20dc5", "sha256": "0427dd7787f82791c22615b466adfbbff155fa3f4db6cc69e45c684c760786ca"}, "downloads": -1, "filename": "classification_pipeline-0.431-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d695cebc24d70fb6753e75268de20dc5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4685, "upload_time": "2019-11-10T09:22:56", "upload_time_iso_8601": "2019-11-10T09:22:56.268562Z", "url": "https://files.pythonhosted.org/packages/3f/85/bbffd96825e55292b845bb52b0cf89b9bd7eaefd0864fdc47090044edf72/classification_pipeline-0.431-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a23f6fb59d2acc9f87f8d8d5b733ca31", "sha256": "fb2ad74cf694adbea3bf5aa7b72195327a5add1ade7633e12f4578b31c984408"}, "downloads": -1, "filename": "classification_pipeline-0.431.tar.gz", "has_sig": false, "md5_digest": "a23f6fb59d2acc9f87f8d8d5b733ca31", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10116, "upload_time": "2019-11-10T09:23:00", "upload_time_iso_8601": "2019-11-10T09:23:00.197763Z", "url": "https://files.pythonhosted.org/packages/20/29/e001a0f71838c8fe52f3d279b134e1dd78cfcef05cf695409c287e7b5580/classification_pipeline-0.431.tar.gz", "yanked": false}], "0.432": [{"comment_text": "", "digests": {"md5": "2dda3356c0017ed7eef93d7117aab414", "sha256": "5268ad396f12883ce6e5ee3d78483361d45c5b008a192f8798ecad6a2358ec70"}, "downloads": -1, "filename": "classification_pipeline-0.432-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2dda3356c0017ed7eef93d7117aab414", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11701, "upload_time": "2019-11-21T03:00:04", "upload_time_iso_8601": "2019-11-21T03:00:04.294654Z", "url": "https://files.pythonhosted.org/packages/8c/6f/9b4663244ca69717c31885fab34ea28701a51fdf2cf6441e03025647df02/classification_pipeline-0.432-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef41aba91910be627a81813443df79d0", "sha256": "395a1f38c4829cdc1173cfb7ca545505f36d72523e6948f63ad7f6a7f54f6292"}, "downloads": -1, "filename": "classification_pipeline-0.432.tar.gz", "has_sig": false, "md5_digest": "ef41aba91910be627a81813443df79d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12158, "upload_time": "2019-11-21T03:00:09", "upload_time_iso_8601": "2019-11-21T03:00:09.619316Z", "url": "https://files.pythonhosted.org/packages/bf/0c/ec1ea1d0d61bcb3ca4423d73a8b98ac9ec2de0310e5986eb183c9d810bd0/classification_pipeline-0.432.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2dda3356c0017ed7eef93d7117aab414", "sha256": "5268ad396f12883ce6e5ee3d78483361d45c5b008a192f8798ecad6a2358ec70"}, "downloads": -1, "filename": "classification_pipeline-0.432-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2dda3356c0017ed7eef93d7117aab414", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11701, "upload_time": "2019-11-21T03:00:04", "upload_time_iso_8601": "2019-11-21T03:00:04.294654Z", "url": "https://files.pythonhosted.org/packages/8c/6f/9b4663244ca69717c31885fab34ea28701a51fdf2cf6441e03025647df02/classification_pipeline-0.432-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef41aba91910be627a81813443df79d0", "sha256": "395a1f38c4829cdc1173cfb7ca545505f36d72523e6948f63ad7f6a7f54f6292"}, "downloads": -1, "filename": "classification_pipeline-0.432.tar.gz", "has_sig": false, "md5_digest": "ef41aba91910be627a81813443df79d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12158, "upload_time": "2019-11-21T03:00:09", "upload_time_iso_8601": "2019-11-21T03:00:09.619316Z", "url": "https://files.pythonhosted.org/packages/bf/0c/ec1ea1d0d61bcb3ca4423d73a8b98ac9ec2de0310e5986eb183c9d810bd0/classification_pipeline-0.432.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:19:08 2020"}