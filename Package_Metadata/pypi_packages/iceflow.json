{"info": {"author": "Thomas Gilgenast", "author_email": "thomasgilgenast@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Science/Research", "Programming Language :: Python :: 3 :: Only", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "IceFlow\n=======\n\n_ice floe, nowhere to go_\n\nA lightweight meta-framework for training neural networks with [TensorFlow](https://www.tensorflow.org/).\n\nInstallation\n------------\n\n    pip install iceflow\n\n### Dependencies\n\n - `tensorflow>=1.3.0`\n - `dm-sonnet>=1.11`\n\nQuick start\n-----------\n\n1. Define [Sonnet modules](https://deepmind.github.io/sonnet/) in `models.py`:\n\n       import tensorflow as tf\n       import sonnet as snt\n\n\n       class MLP(snt.AbstractModule):\n           def __init__(self, hidden_size, output_size, nonlinearity=tf.tanh):\n               super(MLP, self).__init__()\n               self._hidden_size = hidden_size\n               self._output_size = output_size\n               self._nonlinearity = nonlinearity\n\n           def _build(self, inputs):\n               lin_x_to_h = snt.Linear(output_size=self._hidden_size, name=\"x_to_h\")\n               lin_h_to_o = snt.Linear(output_size=self._output_size, name=\"h_to_o\")\n               return lin_h_to_o(self._nonlinearity(lin_x_to_h(inputs)))\n\n\n2. Define [Datasets](https://www.tensorflow.org/programmers_guide/datasets)\n   in `datasets.py`:\n\n       from tensorflow.contrib.data import Dataset\n       from tensorflow.examples.tutorials.mnist import input_data\n\n\n       def mnist():\n           # load mnist data\n           mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\n           # make Datasets\n           train_dataset = Dataset.from_tensor_slices(\n               (mnist.train._images, mnist.train._labels))\n           test_dataset = Dataset.from_tensor_slices(\n               (mnist.test._images, mnist.test._labels))\n\n           return train_dataset, test_dataset\n\n3. Describe what you want to do in `test1.cfg`:\n\n       [DEFAULT]\n       model_dir=test1\n       model=MLP\n       hidden_size=50\n       output_size=10\n\n4. Train your model, evaluating every 1000 steps:\n\n       $ iceflow train test1.cfg mnist --eval_period 1000\n\n5. Evaluate your model:\n\n       $ iceflow eval test1.cfg mnist\n       {'global_step': 10000, 'loss': 0.13652229, 'accuracy': 0.96079999}\n\n6. Visualize your learning in TensorBoard:\n\n       $ tensorboard --logdir=test1\n\n   Navigate to <http://localhost:6006> to see the metrics:\n\n   ![](images/tensorboard.png)\n\n7. Add some new data to `datasets.py`\n\n       import numpy as np\n\n\n       def random_image():\n           return None, Dataset.from_tensors(\n               np.random.random((784,)).astype(np.float32))\n\n\n       def random_images():\n           return None, Dataset.from_tensor_slices(\n               np.random.random((32, 784,)).astype(np.float32))\n\n   and make predictions on it\n\n       $ iceflow predict test1.cfg random_image\n       [5]\n\n       $ iceflow predict test1.cfg random_images\n       [5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 3, 5]\n\nConfig format reference\n-----------------------\n\nThe format of the `iceflow` config file is roughly\n\n    [DEFAULT]\n    model_dir=test1\n    model=MLP\n    hyperparam_1=50\n    hyperparam_2=10\n\n    [more_hiddens]\n    model_dir=test2\n    hyperparam_1=100\n\nTo train the model defined in the `[DEFAULT]` section, run\n\n    $ iceflow train <config_file> <dataset>\n\nTo train the `[more_hiddens]` variant model, which inherits all hyperparameters\nfrom the `[DEFAULT]` section but overrides `model_dir` (to avoid conflicting\nwith the `[DEFAULT]` model) and `hyperparam_1`, run\n\n    $ iceflow train <config_file> <dataset> --config_section more_hiddens\n\n`model` must refer to a Sonnet module defined in `models.py`.\n\nEvery key besides `model_dir` and `model` is taken to be a hyperparameter which\nwill be passed as a kwarg to the constructor of the Sonnet module.\n\nDesign philosophy\n-----------------\n\nOur typical workload involves training lots of models (usually with complex or\nexperimental architecture) with different sets of hyperparameters on different\ndatasets.\n\nPreviously, we had been using a hand-built meta-framework around TensorFlow to\norganize training, evaluation, and inference.\n\nAs of TensorFlow 1.3, the [Dataset API](https://www.tensorflow.org/programmers_guide/datasets),\n[Estimator API](https://www.tensorflow.org/programmers_guide/estimators), and\n[DeepMind's Sonnet library](https://deepmind.github.io/sonnet/) have arisen as\nmature alternatives to our hand-crafted solutions.\n\nIceFlow aims to provide the small bit of code needed to get these three APIs to\nwork together seamlessly - without sacrificing flexibility - and provide an\nefficient \"command line and config file\"-based interface to the basic train, \neval, predict cycle.\n\nCaveats and future directions\n-----------------------------\n\n - Currently, the only supported type of problem is a softmax classification\n   problem with one-hot labels. We plan to extend this.\n - Currently, the only possible output you can obtain from `iceflow predict` is\n   tensors being printed to the command line. We plan to extend this to allow\n   specification of an arbitrary Python function that takes the prediction\n   results (arrays) as input.\n - Currently, the optimizer used for training is hard-coded. We plan to expose\n   this as a parameter either in the config or on the command line. We also plan\n   to extend this to support learning rate decay and related use cases.\n - Currently, there is no easy way to use IceFlow to inject a properly-restored\n   Estimator into arbitrary Python code. We plan to add this capability.\n - Currently, the batch size and shuffle buffer size are not exposed. We plan to\n   expose this soon.\n - Currently, performing validation every so often during training is very\n   awkward. We are awaiting the return of [`ValidationMonitor`](https://www.tensorflow.org/get_started/monitors#configuring_a_validationmonitor_for_streaming_evaluation)\n   from its banishment in the desert of deprecation (and following\n   [this GitHub issue](https://github.com/tensorflow/tensorflow/issues/7669)).\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sclabs/iceflow", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "iceflow", "package_url": "https://pypi.org/project/iceflow/", "platform": "", "project_url": "https://pypi.org/project/iceflow/", "project_urls": {"Homepage": "https://github.com/sclabs/iceflow"}, "release_url": "https://pypi.org/project/iceflow/0.0.1a2/", "requires_dist": ["dm-sonnet (>=1.11)", "tensorflow (>=1.3.0)"], "requires_python": "", "summary": "tensorflow meta-framework", "version": "0.0.1a2", "yanked": false, "html_description": "<div class=\"project-description\">\n            IceFlow<br>=======<br><br>_ice floe, nowhere to go_<br><br>A lightweight meta-framework for training neural networks with [TensorFlow](https://www.tensorflow.org/).<br><br>Installation<br>------------<br><br>    pip install iceflow<br><br>### Dependencies<br><br> - `tensorflow&gt;=1.3.0`<br> - `dm-sonnet&gt;=1.11`<br><br>Quick start<br>-----------<br><br>1. Define [Sonnet modules](https://deepmind.github.io/sonnet/) in `models.py`:<br><br>       import tensorflow as tf<br>       import sonnet as snt<br><br><br>       class MLP(snt.AbstractModule):<br>           def __init__(self, hidden_size, output_size, nonlinearity=tf.tanh):<br>               super(MLP, self).__init__()<br>               self._hidden_size = hidden_size<br>               self._output_size = output_size<br>               self._nonlinearity = nonlinearity<br><br>           def _build(self, inputs):<br>               lin_x_to_h = snt.Linear(output_size=self._hidden_size, name=\"x_to_h\")<br>               lin_h_to_o = snt.Linear(output_size=self._output_size, name=\"h_to_o\")<br>               return lin_h_to_o(self._nonlinearity(lin_x_to_h(inputs)))<br><br><br>2. Define [Datasets](https://www.tensorflow.org/programmers_guide/datasets)<br>   in `datasets.py`:<br><br>       from tensorflow.contrib.data import Dataset<br>       from tensorflow.examples.tutorials.mnist import input_data<br><br><br>       def mnist():<br>           # load mnist data<br>           mnist = input_data.read_data_sets('MNIST_data', one_hot=True)<br><br>           # make Datasets<br>           train_dataset = Dataset.from_tensor_slices(<br>               (mnist.train._images, mnist.train._labels))<br>           test_dataset = Dataset.from_tensor_slices(<br>               (mnist.test._images, mnist.test._labels))<br><br>           return train_dataset, test_dataset<br><br>3. Describe what you want to do in `test1.cfg`:<br><br>       [DEFAULT]<br>       model_dir=test1<br>       model=MLP<br>       hidden_size=50<br>       output_size=10<br><br>4. Train your model, evaluating every 1000 steps:<br><br>       $ iceflow train test1.cfg mnist --eval_period 1000<br><br>5. Evaluate your model:<br><br>       $ iceflow eval test1.cfg mnist<br>       {'global_step': 10000, 'loss': 0.13652229, 'accuracy': 0.96079999}<br><br>6. Visualize your learning in TensorBoard:<br><br>       $ tensorboard --logdir=test1<br><br>   Navigate to &lt;http://localhost:6006&gt; to see the metrics:<br><br>   ![](images/tensorboard.png)<br><br>7. Add some new data to `datasets.py`<br><br>       import numpy as np<br><br><br>       def random_image():<br>           return None, Dataset.from_tensors(<br>               np.random.random((784,)).astype(np.float32))<br><br><br>       def random_images():<br>           return None, Dataset.from_tensor_slices(<br>               np.random.random((32, 784,)).astype(np.float32))<br><br>   and make predictions on it<br><br>       $ iceflow predict test1.cfg random_image<br>       [5]<br><br>       $ iceflow predict test1.cfg random_images<br>       [5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 3, 5]<br><br>Config format reference<br>-----------------------<br><br>The format of the `iceflow` config file is roughly<br><br>    [DEFAULT]<br>    model_dir=test1<br>    model=MLP<br>    hyperparam_1=50<br>    hyperparam_2=10<br><br>    [more_hiddens]<br>    model_dir=test2<br>    hyperparam_1=100<br><br>To train the model defined in the `[DEFAULT]` section, run<br><br>    $ iceflow train &lt;config_file&gt; &lt;dataset&gt;<br><br>To train the `[more_hiddens]` variant model, which inherits all hyperparameters<br>from the `[DEFAULT]` section but overrides `model_dir` (to avoid conflicting<br>with the `[DEFAULT]` model) and `hyperparam_1`, run<br><br>    $ iceflow train &lt;config_file&gt; &lt;dataset&gt; --config_section more_hiddens<br><br>`model` must refer to a Sonnet module defined in `models.py`.<br><br>Every key besides `model_dir` and `model` is taken to be a hyperparameter which<br>will be passed as a kwarg to the constructor of the Sonnet module.<br><br>Design philosophy<br>-----------------<br><br>Our typical workload involves training lots of models (usually with complex or<br>experimental architecture) with different sets of hyperparameters on different<br>datasets.<br><br>Previously, we had been using a hand-built meta-framework around TensorFlow to<br>organize training, evaluation, and inference.<br><br>As of TensorFlow 1.3, the [Dataset API](https://www.tensorflow.org/programmers_guide/datasets),<br>[Estimator API](https://www.tensorflow.org/programmers_guide/estimators), and<br>[DeepMind's Sonnet library](https://deepmind.github.io/sonnet/) have arisen as<br>mature alternatives to our hand-crafted solutions.<br><br>IceFlow aims to provide the small bit of code needed to get these three APIs to<br>work together seamlessly - without sacrificing flexibility - and provide an<br>efficient \"command line and config file\"-based interface to the basic train, <br>eval, predict cycle.<br><br>Caveats and future directions<br>-----------------------------<br><br> - Currently, the only supported type of problem is a softmax classification<br>   problem with one-hot labels. We plan to extend this.<br> - Currently, the only possible output you can obtain from `iceflow predict` is<br>   tensors being printed to the command line. We plan to extend this to allow<br>   specification of an arbitrary Python function that takes the prediction<br>   results (arrays) as input.<br> - Currently, the optimizer used for training is hard-coded. We plan to expose<br>   this as a parameter either in the config or on the command line. We also plan<br>   to extend this to support learning rate decay and related use cases.<br> - Currently, there is no easy way to use IceFlow to inject a properly-restored<br>   Estimator into arbitrary Python code. We plan to add this capability.<br> - Currently, the batch size and shuffle buffer size are not exposed. We plan to<br>   expose this soon.<br> - Currently, performing validation every so often during training is very<br>   awkward. We are awaiting the return of [`ValidationMonitor`](https://www.tensorflow.org/get_started/monitors#configuring_a_validationmonitor_for_streaming_evaluation)<br>   from its banishment in the desert of deprecation (and following<br>   [this GitHub issue](https://github.com/tensorflow/tensorflow/issues/7669)).<br><br><br>\n          </div>"}, "last_serial": 3152871, "releases": {"0.0.1a2": [{"comment_text": "", "digests": {"md5": "a18495a85160759dff5221f08a4398e7", "sha256": "5c59d3fc8630e58acc5509eb9993d834fcfe390300a22b7e2cfc389fc4fc0c3f"}, "downloads": -1, "filename": "iceflow-0.0.1a2-py3-none-any.whl", "has_sig": false, "md5_digest": "a18495a85160759dff5221f08a4398e7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9324, "upload_time": "2017-09-06T09:34:15", "upload_time_iso_8601": "2017-09-06T09:34:15.847012Z", "url": "https://files.pythonhosted.org/packages/b5/22/36dea2f26cf8947da954044b0b0ac4675c1bb2fdd33f37d5c4e4077c927e/iceflow-0.0.1a2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7016c9000353d2df25df15d00eb62c7f", "sha256": "32e7319d9cee9faa4c8fe434a368a9f933d8c69dda19042e569667387c1e4dc5"}, "downloads": -1, "filename": "iceflow-0.0.1a2.tar.gz", "has_sig": false, "md5_digest": "7016c9000353d2df25df15d00eb62c7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21612, "upload_time": "2017-09-06T09:34:16", "upload_time_iso_8601": "2017-09-06T09:34:16.847851Z", "url": "https://files.pythonhosted.org/packages/5d/66/57b468812cd66b00f0d5b82c85ffb43f0f8f8230f6e53f29766566ba1bc9/iceflow-0.0.1a2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a18495a85160759dff5221f08a4398e7", "sha256": "5c59d3fc8630e58acc5509eb9993d834fcfe390300a22b7e2cfc389fc4fc0c3f"}, "downloads": -1, "filename": "iceflow-0.0.1a2-py3-none-any.whl", "has_sig": false, "md5_digest": "a18495a85160759dff5221f08a4398e7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9324, "upload_time": "2017-09-06T09:34:15", "upload_time_iso_8601": "2017-09-06T09:34:15.847012Z", "url": "https://files.pythonhosted.org/packages/b5/22/36dea2f26cf8947da954044b0b0ac4675c1bb2fdd33f37d5c4e4077c927e/iceflow-0.0.1a2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7016c9000353d2df25df15d00eb62c7f", "sha256": "32e7319d9cee9faa4c8fe434a368a9f933d8c69dda19042e569667387c1e4dc5"}, "downloads": -1, "filename": "iceflow-0.0.1a2.tar.gz", "has_sig": false, "md5_digest": "7016c9000353d2df25df15d00eb62c7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21612, "upload_time": "2017-09-06T09:34:16", "upload_time_iso_8601": "2017-09-06T09:34:16.847851Z", "url": "https://files.pythonhosted.org/packages/5d/66/57b468812cd66b00f0d5b82c85ffb43f0f8f8230f6e53f29766566ba1bc9/iceflow-0.0.1a2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:06 2020"}