{"info": {"author": "David Beath", "author_email": "davidgbeath@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3.7"], "description": "# Feedsearch Crawler\n[![PyPI](https://img.shields.io/pypi/v/feedsearch-crawler.svg)](https://pypi.org/project/feedsearch-crawler/)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/feedsearch-crawler.svg)\n![PyPI - License](https://img.shields.io/pypi/l/feedsearch-crawler.svg)\n[![Downloads](https://pepy.tech/badge/feedsearch-crawler/month)](https://pepy.tech/project/feedsearch-crawler/month)\n\nFeedsearch Crawler is a Python library for searching websites for [RSS](https://en.wikipedia.org/wiki/RSS), [Atom](https://en.wikipedia.org/wiki/Atom_(Web_standard)), and [JSON](https://jsonfeed.org/) feeds.\n\nIt is a continuation of my work on [Feedsearch](https://github.com/DBeath/feedsearch), which is itself a continuation of the work done by [Dan Foreman-Mackey](http://dfm.io/) on [Feedfinder2](https://github.com/dfm/feedfinder2), which in turn is based on [feedfinder](http://www.aaronsw.com/2002/feedfinder/) - originally written by [Mark Pilgrim](http://en.wikipedia.org/wiki/Mark_Pilgrim_(software_developer)) and subsequently maintained by\n[Aaron Swartz](http://en.wikipedia.org/wiki/Aaron_Swartz) until his untimely death.\n\nFeedsearch Crawler differs with all of the above in that it is now built as an asynchronous [Web crawler](https://en.wikipedia.org/wiki/Web_crawler) for [Python 3.7](https://www.python.org/downloads/release/python-370/) and above, using [asyncio](https://docs.python.org/3/library/asyncio.html) and [aiohttp](https://aiohttp.readthedocs.io/en/stable/), to allow much more rapid scanning of possible feed urls.\n\nAn implementation using this library to provide a public Feed Search API is available at https://feedsearch.dev\n\nPull requests and suggestions are welcome.\n\n## Installation\nThe library is available on [PyPI](https://pypi.org/project/feedsearch-crawler/):\n\n```\npip install feedsearch-crawler\n```\n\nThe library requires Python 3.7+.\n\n## Usage\nFeedsearch Crawler is called with the single function ``search``:\n\n``` python\n>>> from feedsearch_crawler import search\n>>> feeds = search('xkcd.com')\n>>> feeds\n[FeedInfo('https://xkcd.com/rss.xml'), FeedInfo('https://xkcd.com/atom.xml')]\n>>> feeds[0].url\nURL('https://xkcd.com/rss.xml')\n>>> str(feeds[0].url)\n'https://xkcd.com/rss.xml'\n>>> feeds[0].serialize()\n{'url': 'https://xkcd.com/rss.xml', 'title': 'xkcd.com', 'version': 'rss20', 'score': 24, 'hubs': [], 'description': 'xkcd.com: A webcomic of romance and math humor.', 'is_push': False, 'self_url': '', 'favicon': 'https://xkcd.com/s/919f27.ico', 'content_type': 'text/xml; charset=UTF-8', 'bozo': 0, 'site_url': 'https://xkcd.com/', 'site_name': 'xkcd: Chernobyl', 'favicon_data_uri': '', 'content_length': 2847}\n```\n\nIf you are already running in an [asyncio event loop](https://docs.python.org/3/library/asyncio-eventloop.html), then you can import and await ``search_async`` instead. The ``search`` function is only a wrapper that runs ``search_async`` in a new asyncio event loop.\n\n``` python\nfrom feedsearch_crawler import search_async\n\nfeeds = await search_async('xkcd.com')\n```\n\nA search will always return a list of *FeedInfo* objects, each of which will always have a *url* property, which is a [URL](https://yarl.readthedocs.io/en/latest/api.html) object that can be decoded to a string with ``str(url)``.\nThe returned *FeedInfo* are sorted by the *score* value from highest to lowest, with a higher score theoretically indicating a more relevant feed compared to the original URL provided. A *FeedInfo* can also be serialized to a JSON compatible dictionary by calling it's ``.serialize()`` method.\n\nThe crawl logs can be accessed with:\n\n``` python\nimport logging\n\nlogger = logging.getLogger(\"feedsearch_crawler\")\n```\n\nFeedsearch Crawler also provides a handy function to output the returned feeds as an [OPML](https://en.wikipedia.org/wiki/OPML) subscription list, encoded as a UTF-8 bytestring. \n\n``` python\nfrom feedsearch_crawler import output_opml\n\noutput_opml(feeds).decode()\n```\n\n## Search Arguments\n``search`` and ``search_async`` take the following arguments:\n\n``` python\nsearch(\n    url: Union[URL, str, List[Union[URL, str]]],\n    crawl_hosts: bool=True,\n    try_urls: Union[List[str], bool]=False,\n    concurrency: int=10,\n    total_timeout: Union[float, aiohttp.ClientTimeout]=10,\n    request_timeout: Union[float, aiohttp.ClientTimeout]=3,\n    user_agent: str=\"Feedsearch Bot\",\n    max_content_length: int=1024 * 1024 * 10,\n    max_depth: int=10,\n    headers: dict={\"X-Custom-Header\": \"Custom Header\"},\n    favicon_data_uri: bool=True,\n    delay: float=0\n)\n```\n\n- **url**: *Union[str, List[str]]*: The initial URL or list of URLs at which to search for feeds. You may also provide [URL](https://yarl.readthedocs.io/en/latest/api.html) objects.\n- **crawl_hosts**: *bool*: (default True): An optional argument to add the site host origin URL to the list of initial crawl URLs. (e.g. add \"example.com\" if crawling \"example.com/path/rss.xml\"). If **False**, site metadata and favicon data may not be found.\n- **try_urls**: *Union[List[str], bool]*: (default False): An optional list of URL paths to query for feeds. Takes the origins of the *url* parameter and appends the provided paths. If no list is provided, but *try_urls* is **True**, then a list of common feed locations will be used.\n- **concurrency**: *int*: (default 10): An optional argument to specify the maximum number of concurrent HTTP requests.\n- **total_timeout**: *float*: (default 30.0): An optional argument to specify the time this function may run before timing out.\n- **request_timeout**: *float*: (default 3.0): An optional argument that controls how long before each individual HTTP request times out.\n- **user_agent**: *str*: An optional argument to override the default User-Agent header.\n- **max_content_length**: *int*: (default 10Mb): An optional argument to specify the maximum size in bytes of each HTTP Response.\n- **max_depth**: *int*: (default 10): An optional argument to limit the maximum depth of requests while following urls.\n- **headers**: *dict*: An optional dictionary of headers to pass to each HTTP request.\n- **favicon_data_uri**: *bool*: (default True): Optionally control whether to fetch found favicons and return them as a Data Uri.\n- **delay**: *float*: (default 0.0): An optional argument to delay each HTTP request by the specified time in seconds. Used in conjunction with the concurrency setting to avoid overloading sites.\n\n## FeedInfo Values\nIn addition to the *url*, FeedInfo objects may have the following values:\n\n- **bozo**: *int*: Set to 1 when feed data is not well formed or may not be a feed. Defaults 0.\n- **content_length**: *int*: Current length of the feed in bytes.\n- **content_type**: *str*: [Content-Type](https://en.wikipedia.org/wiki/Media_type) value of the returned feed.\n- **description**: *str*: Feed description.\n- **favicon**: *URL*: [URL](https://yarl.readthedocs.io/en/latest/api.html) of feed or site [Favicon](https://en.wikipedia.org/wiki/Favicon).\n- **favicon_data_uri**: *str*: [Data Uri](https://en.wikipedia.org/wiki/Data_URI_scheme) of Favicon.\n- **hubs**: *List[str]*: List of [Websub](https://en.wikipedia.org/wiki/WebSub) hubs of feed if available.\n- **is_podcast**: *bool*: True if the feed contains valid [podcast](https://en.wikipedia.org/wiki/Podcast) elements and enclosures.\n- **is_push**: *bool*: True if feed contains valid Websub data.\n- **item_count**: *int*: Number of items currently in the feed.\n- **last_updated**: *datetime*: Date of the latest published entry.\n- **score**: *int*: Computed relevance of feed url value to provided URL. May be safely ignored.\n- **self_url**: *URL*: *ref=\"self\"* value returned from feed links. In some cases may be different from feed url.\n- **site_name**: *str*: Name of feed's website.\n- **site_url**: *URL*: [URL](https://yarl.readthedocs.io/en/latest/api.html) of feed's website.\n- **title**: *str*: Feed Title.\n- **url**: *URL*: [URL](https://yarl.readthedocs.io/en/latest/api.html) location of feed.\n- **velocity**: *float*: Mean number of items per day in the feed at the current time.\n- **version**: *str*: Feed version [XML values](https://pythonhosted.org/feedparser/version-detection.html),\n  or [JSON feed](https://jsonfeed.org/version/1).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/DBeath/feedsearch-crawler", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "feedsearch-crawler", "package_url": "https://pypi.org/project/feedsearch-crawler/", "platform": "", "project_url": "https://pypi.org/project/feedsearch-crawler/", "project_urls": {"Homepage": "https://github.com/DBeath/feedsearch-crawler"}, "release_url": "https://pypi.org/project/feedsearch-crawler/0.2.4/", "requires_dist": ["aiohttp", "beautifulsoup4", "feedparser", "cchardet", "aiodns", "w3lib", "uvloop"], "requires_python": ">=3.7", "summary": "Search sites for RSS, Atom, and JSON feeds", "version": "0.2.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Feedsearch Crawler</h1>\n<p><a href=\"https://pypi.org/project/feedsearch-crawler/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1183d69de9f5a6e6d3c9d92c5b89fabafad2e168/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f666565647365617263682d637261776c65722e737667\"></a>\n<img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5f674e7bb21bf093cc4a40d879d64c6b7bda6b2c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f666565647365617263682d637261776c65722e737667\">\n<img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e3d3688be68b79e3daff8d45986b98e750c8a8fc/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f666565647365617263682d637261776c65722e737667\">\n<a href=\"https://pepy.tech/project/feedsearch-crawler/month\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e258d437f38734e64239d91cf365c2255665d6fb/68747470733a2f2f706570792e746563682f62616467652f666565647365617263682d637261776c65722f6d6f6e7468\"></a></p>\n<p>Feedsearch Crawler is a Python library for searching websites for <a href=\"https://en.wikipedia.org/wiki/RSS\" rel=\"nofollow\">RSS</a>, <a href=\"https://en.wikipedia.org/wiki/Atom_(Web_standard)\" rel=\"nofollow\">Atom</a>, and <a href=\"https://jsonfeed.org/\" rel=\"nofollow\">JSON</a> feeds.</p>\n<p>It is a continuation of my work on <a href=\"https://github.com/DBeath/feedsearch\" rel=\"nofollow\">Feedsearch</a>, which is itself a continuation of the work done by <a href=\"http://dfm.io/\" rel=\"nofollow\">Dan Foreman-Mackey</a> on <a href=\"https://github.com/dfm/feedfinder2\" rel=\"nofollow\">Feedfinder2</a>, which in turn is based on <a href=\"http://www.aaronsw.com/2002/feedfinder/\" rel=\"nofollow\">feedfinder</a> - originally written by <a href=\"http://en.wikipedia.org/wiki/Mark_Pilgrim_(software_developer)\" rel=\"nofollow\">Mark Pilgrim</a> and subsequently maintained by\n<a href=\"http://en.wikipedia.org/wiki/Aaron_Swartz\" rel=\"nofollow\">Aaron Swartz</a> until his untimely death.</p>\n<p>Feedsearch Crawler differs with all of the above in that it is now built as an asynchronous <a href=\"https://en.wikipedia.org/wiki/Web_crawler\" rel=\"nofollow\">Web crawler</a> for <a href=\"https://www.python.org/downloads/release/python-370/\" rel=\"nofollow\">Python 3.7</a> and above, using <a href=\"https://docs.python.org/3/library/asyncio.html\" rel=\"nofollow\">asyncio</a> and <a href=\"https://aiohttp.readthedocs.io/en/stable/\" rel=\"nofollow\">aiohttp</a>, to allow much more rapid scanning of possible feed urls.</p>\n<p>An implementation using this library to provide a public Feed Search API is available at <a href=\"https://feedsearch.dev\" rel=\"nofollow\">https://feedsearch.dev</a></p>\n<p>Pull requests and suggestions are welcome.</p>\n<h2>Installation</h2>\n<p>The library is available on <a href=\"https://pypi.org/project/feedsearch-crawler/\" rel=\"nofollow\">PyPI</a>:</p>\n<pre><code>pip install feedsearch-crawler\n</code></pre>\n<p>The library requires Python 3.7+.</p>\n<h2>Usage</h2>\n<p>Feedsearch Crawler is called with the single function <code>search</code>:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">feedsearch_crawler</span> <span class=\"kn\">import</span> <span class=\"n\">search</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">feeds</span> <span class=\"o\">=</span> <span class=\"n\">search</span><span class=\"p\">(</span><span class=\"s1\">'xkcd.com'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">feeds</span>\n<span class=\"p\">[</span><span class=\"n\">FeedInfo</span><span class=\"p\">(</span><span class=\"s1\">'https://xkcd.com/rss.xml'</span><span class=\"p\">),</span> <span class=\"n\">FeedInfo</span><span class=\"p\">(</span><span class=\"s1\">'https://xkcd.com/atom.xml'</span><span class=\"p\">)]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">feeds</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">url</span>\n<span class=\"n\">URL</span><span class=\"p\">(</span><span class=\"s1\">'https://xkcd.com/rss.xml'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">feeds</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">)</span>\n<span class=\"s1\">'https://xkcd.com/rss.xml'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">feeds</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">serialize</span><span class=\"p\">()</span>\n<span class=\"p\">{</span><span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"s1\">'https://xkcd.com/rss.xml'</span><span class=\"p\">,</span> <span class=\"s1\">'title'</span><span class=\"p\">:</span> <span class=\"s1\">'xkcd.com'</span><span class=\"p\">,</span> <span class=\"s1\">'version'</span><span class=\"p\">:</span> <span class=\"s1\">'rss20'</span><span class=\"p\">,</span> <span class=\"s1\">'score'</span><span class=\"p\">:</span> <span class=\"mi\">24</span><span class=\"p\">,</span> <span class=\"s1\">'hubs'</span><span class=\"p\">:</span> <span class=\"p\">[],</span> <span class=\"s1\">'description'</span><span class=\"p\">:</span> <span class=\"s1\">'xkcd.com: A webcomic of romance and math humor.'</span><span class=\"p\">,</span> <span class=\"s1\">'is_push'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"s1\">'self_url'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"s1\">'favicon'</span><span class=\"p\">:</span> <span class=\"s1\">'https://xkcd.com/s/919f27.ico'</span><span class=\"p\">,</span> <span class=\"s1\">'content_type'</span><span class=\"p\">:</span> <span class=\"s1\">'text/xml; charset=UTF-8'</span><span class=\"p\">,</span> <span class=\"s1\">'bozo'</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"s1\">'site_url'</span><span class=\"p\">:</span> <span class=\"s1\">'https://xkcd.com/'</span><span class=\"p\">,</span> <span class=\"s1\">'site_name'</span><span class=\"p\">:</span> <span class=\"s1\">'xkcd: Chernobyl'</span><span class=\"p\">,</span> <span class=\"s1\">'favicon_data_uri'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"s1\">'content_length'</span><span class=\"p\">:</span> <span class=\"mi\">2847</span><span class=\"p\">}</span>\n</pre>\n<p>If you are already running in an <a href=\"https://docs.python.org/3/library/asyncio-eventloop.html\" rel=\"nofollow\">asyncio event loop</a>, then you can import and await <code>search_async</code> instead. The <code>search</code> function is only a wrapper that runs <code>search_async</code> in a new asyncio event loop.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">feedsearch_crawler</span> <span class=\"kn\">import</span> <span class=\"n\">search_async</span>\n\n<span class=\"n\">feeds</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">search_async</span><span class=\"p\">(</span><span class=\"s1\">'xkcd.com'</span><span class=\"p\">)</span>\n</pre>\n<p>A search will always return a list of <em>FeedInfo</em> objects, each of which will always have a <em>url</em> property, which is a <a href=\"https://yarl.readthedocs.io/en/latest/api.html\" rel=\"nofollow\">URL</a> object that can be decoded to a string with <code>str(url)</code>.\nThe returned <em>FeedInfo</em> are sorted by the <em>score</em> value from highest to lowest, with a higher score theoretically indicating a more relevant feed compared to the original URL provided. A <em>FeedInfo</em> can also be serialized to a JSON compatible dictionary by calling it's <code>.serialize()</code> method.</p>\n<p>The crawl logs can be accessed with:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s2\">\"feedsearch_crawler\"</span><span class=\"p\">)</span>\n</pre>\n<p>Feedsearch Crawler also provides a handy function to output the returned feeds as an <a href=\"https://en.wikipedia.org/wiki/OPML\" rel=\"nofollow\">OPML</a> subscription list, encoded as a UTF-8 bytestring.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">feedsearch_crawler</span> <span class=\"kn\">import</span> <span class=\"n\">output_opml</span>\n\n<span class=\"n\">output_opml</span><span class=\"p\">(</span><span class=\"n\">feeds</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">()</span>\n</pre>\n<h2>Search Arguments</h2>\n<p><code>search</code> and <code>search_async</code> take the following arguments:</p>\n<pre><span class=\"n\">search</span><span class=\"p\">(</span>\n    <span class=\"n\">url</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">URL</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">URL</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]]],</span>\n    <span class=\"n\">crawl_hosts</span><span class=\"p\">:</span> <span class=\"nb\">bool</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"n\">try_urls</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">],</span> <span class=\"nb\">bool</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"n\">concurrency</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">total_timeout</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"n\">aiohttp</span><span class=\"o\">.</span><span class=\"n\">ClientTimeout</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">request_timeout</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">float</span><span class=\"p\">,</span> <span class=\"n\">aiohttp</span><span class=\"o\">.</span><span class=\"n\">ClientTimeout</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span>\n    <span class=\"n\">user_agent</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"o\">=</span><span class=\"s2\">\"Feedsearch Bot\"</span><span class=\"p\">,</span>\n    <span class=\"n\">max_content_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"o\">=</span><span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"mi\">1024</span> <span class=\"o\">*</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">max_depth</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"n\">headers</span><span class=\"p\">:</span> <span class=\"nb\">dict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"X-Custom-Header\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Custom Header\"</span><span class=\"p\">},</span>\n    <span class=\"n\">favicon_data_uri</span><span class=\"p\">:</span> <span class=\"nb\">bool</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"n\">delay</span><span class=\"p\">:</span> <span class=\"nb\">float</span><span class=\"o\">=</span><span class=\"mi\">0</span>\n<span class=\"p\">)</span>\n</pre>\n<ul>\n<li><strong>url</strong>: <em>Union[str, List[str]]</em>: The initial URL or list of URLs at which to search for feeds. You may also provide <a href=\"https://yarl.readthedocs.io/en/latest/api.html\" rel=\"nofollow\">URL</a> objects.</li>\n<li><strong>crawl_hosts</strong>: <em>bool</em>: (default True): An optional argument to add the site host origin URL to the list of initial crawl URLs. (e.g. add \"example.com\" if crawling \"example.com/path/rss.xml\"). If <strong>False</strong>, site metadata and favicon data may not be found.</li>\n<li><strong>try_urls</strong>: <em>Union[List[str], bool]</em>: (default False): An optional list of URL paths to query for feeds. Takes the origins of the <em>url</em> parameter and appends the provided paths. If no list is provided, but <em>try_urls</em> is <strong>True</strong>, then a list of common feed locations will be used.</li>\n<li><strong>concurrency</strong>: <em>int</em>: (default 10): An optional argument to specify the maximum number of concurrent HTTP requests.</li>\n<li><strong>total_timeout</strong>: <em>float</em>: (default 30.0): An optional argument to specify the time this function may run before timing out.</li>\n<li><strong>request_timeout</strong>: <em>float</em>: (default 3.0): An optional argument that controls how long before each individual HTTP request times out.</li>\n<li><strong>user_agent</strong>: <em>str</em>: An optional argument to override the default User-Agent header.</li>\n<li><strong>max_content_length</strong>: <em>int</em>: (default 10Mb): An optional argument to specify the maximum size in bytes of each HTTP Response.</li>\n<li><strong>max_depth</strong>: <em>int</em>: (default 10): An optional argument to limit the maximum depth of requests while following urls.</li>\n<li><strong>headers</strong>: <em>dict</em>: An optional dictionary of headers to pass to each HTTP request.</li>\n<li><strong>favicon_data_uri</strong>: <em>bool</em>: (default True): Optionally control whether to fetch found favicons and return them as a Data Uri.</li>\n<li><strong>delay</strong>: <em>float</em>: (default 0.0): An optional argument to delay each HTTP request by the specified time in seconds. Used in conjunction with the concurrency setting to avoid overloading sites.</li>\n</ul>\n<h2>FeedInfo Values</h2>\n<p>In addition to the <em>url</em>, FeedInfo objects may have the following values:</p>\n<ul>\n<li><strong>bozo</strong>: <em>int</em>: Set to 1 when feed data is not well formed or may not be a feed. Defaults 0.</li>\n<li><strong>content_length</strong>: <em>int</em>: Current length of the feed in bytes.</li>\n<li><strong>content_type</strong>: <em>str</em>: <a href=\"https://en.wikipedia.org/wiki/Media_type\" rel=\"nofollow\">Content-Type</a> value of the returned feed.</li>\n<li><strong>description</strong>: <em>str</em>: Feed description.</li>\n<li><strong>favicon</strong>: <em>URL</em>: <a href=\"https://yarl.readthedocs.io/en/latest/api.html\" rel=\"nofollow\">URL</a> of feed or site <a href=\"https://en.wikipedia.org/wiki/Favicon\" rel=\"nofollow\">Favicon</a>.</li>\n<li><strong>favicon_data_uri</strong>: <em>str</em>: <a href=\"https://en.wikipedia.org/wiki/Data_URI_scheme\" rel=\"nofollow\">Data Uri</a> of Favicon.</li>\n<li><strong>hubs</strong>: <em>List[str]</em>: List of <a href=\"https://en.wikipedia.org/wiki/WebSub\" rel=\"nofollow\">Websub</a> hubs of feed if available.</li>\n<li><strong>is_podcast</strong>: <em>bool</em>: True if the feed contains valid <a href=\"https://en.wikipedia.org/wiki/Podcast\" rel=\"nofollow\">podcast</a> elements and enclosures.</li>\n<li><strong>is_push</strong>: <em>bool</em>: True if feed contains valid Websub data.</li>\n<li><strong>item_count</strong>: <em>int</em>: Number of items currently in the feed.</li>\n<li><strong>last_updated</strong>: <em>datetime</em>: Date of the latest published entry.</li>\n<li><strong>score</strong>: <em>int</em>: Computed relevance of feed url value to provided URL. May be safely ignored.</li>\n<li><strong>self_url</strong>: <em>URL</em>: <em>ref=\"self\"</em> value returned from feed links. In some cases may be different from feed url.</li>\n<li><strong>site_name</strong>: <em>str</em>: Name of feed's website.</li>\n<li><strong>site_url</strong>: <em>URL</em>: <a href=\"https://yarl.readthedocs.io/en/latest/api.html\" rel=\"nofollow\">URL</a> of feed's website.</li>\n<li><strong>title</strong>: <em>str</em>: Feed Title.</li>\n<li><strong>url</strong>: <em>URL</em>: <a href=\"https://yarl.readthedocs.io/en/latest/api.html\" rel=\"nofollow\">URL</a> location of feed.</li>\n<li><strong>velocity</strong>: <em>float</em>: Mean number of items per day in the feed at the current time.</li>\n<li><strong>version</strong>: <em>str</em>: Feed version <a href=\"https://pythonhosted.org/feedparser/version-detection.html\" rel=\"nofollow\">XML values</a>,\nor <a href=\"https://jsonfeed.org/version/1\" rel=\"nofollow\">JSON feed</a>.</li>\n</ul>\n\n          </div>"}, "last_serial": 6906552, "releases": {"0.0.4": [{"comment_text": "", "digests": {"md5": "b454208b075e73f058fb46ad07d42319", "sha256": "bb256e2813e4e57ad59b896068c853b5f76018921d55e823c21c35a0afe123d1"}, "downloads": -1, "filename": "feedsearch_crawler-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "b454208b075e73f058fb46ad07d42319", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 19870, "upload_time": "2019-06-10T14:42:21", "upload_time_iso_8601": "2019-06-10T14:42:21.331274Z", "url": "https://files.pythonhosted.org/packages/f6/4e/fed437b2993656b5ab807552bdcbd804a8beaa2d1cb72d5af57242d0ab6b/feedsearch_crawler-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7377a17ac8ac3437a50fe143618d8f7", "sha256": "811c577bd9c170e697cf3b85be5b4352b32790075037c4107b520d09835a8997"}, "downloads": -1, "filename": "feedsearch-crawler-0.0.4.tar.gz", "has_sig": false, "md5_digest": "d7377a17ac8ac3437a50fe143618d8f7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 12584, "upload_time": "2019-06-10T14:42:23", "upload_time_iso_8601": "2019-06-10T14:42:23.491561Z", "url": "https://files.pythonhosted.org/packages/73/b5/e33c8dd6684c991cd18a32c1d148c397f3215a2142f49178bd4e5d2933ad/feedsearch-crawler-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "cab6133f3175ecd662466400e75e7483", "sha256": "2e9005d61e113fab403e5fc898981b62ba3418aca9fbee9b6d0f2108c65d4577"}, "downloads": -1, "filename": "feedsearch_crawler-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "cab6133f3175ecd662466400e75e7483", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 20405, "upload_time": "2019-06-11T19:21:39", "upload_time_iso_8601": "2019-06-11T19:21:39.492999Z", "url": "https://files.pythonhosted.org/packages/69/09/89727f23e86bd2c32a5e21f59e7689c65ba49612fbf2949bfa6ca190f5c8/feedsearch_crawler-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "12837ffb11ef870618f8e6ade43fe26e", "sha256": "b622e72f099b983e8e332d98d3bf3ff1152e029bd312a3049c20d562d453c75e"}, "downloads": -1, "filename": "feedsearch-crawler-0.0.5.tar.gz", "has_sig": false, "md5_digest": "12837ffb11ef870618f8e6ade43fe26e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 13184, "upload_time": "2019-06-11T19:21:41", "upload_time_iso_8601": "2019-06-11T19:21:41.443171Z", "url": "https://files.pythonhosted.org/packages/32/a5/63aa187bfb484e76dd2673dce523af4d22dc8086da458ac6280daa840d53/feedsearch-crawler-0.0.5.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "885a8bd0a9fed6ad2b528660eaa7c085", "sha256": "ee6e1e63a747a097514dc91a7c43ae443de0fc5d9399f30a115289c22f52cd6f"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "885a8bd0a9fed6ad2b528660eaa7c085", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 43074, "upload_time": "2019-06-15T20:50:21", "upload_time_iso_8601": "2019-06-15T20:50:21.871989Z", "url": "https://files.pythonhosted.org/packages/56/e5/50a0a716b1868b8a7b2a23713dbe0087b39fe3bc02d5374c7d42daccf80e/feedsearch_crawler-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e14596ca2e02c5a5ab10054cde57c33d", "sha256": "c9fddae6773e99d3f6f18ff054d64be56da92ee4ce6ed5f9e71bbac89b2760dc"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e14596ca2e02c5a5ab10054cde57c33d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 20101, "upload_time": "2019-06-15T20:50:25", "upload_time_iso_8601": "2019-06-15T20:50:25.223344Z", "url": "https://files.pythonhosted.org/packages/dc/b1/dd83cbddc34e759042c80281144a398a1b2d155e60227c75495e348d6e13/feedsearch-crawler-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "84ecec506e101b77f129a3c02fbea0bf", "sha256": "8b811b37546cf62034ffbc6f8e2c546dd6278e1938554f852187ffe07a3e81af"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "84ecec506e101b77f129a3c02fbea0bf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 43079, "upload_time": "2019-06-16T10:00:18", "upload_time_iso_8601": "2019-06-16T10:00:18.706195Z", "url": "https://files.pythonhosted.org/packages/78/3e/d589a18f939b5baecad64311dd3339e66b743edae138382cbebf492c9e73/feedsearch_crawler-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3178d6697237cbcc9e3616bd05b49043", "sha256": "088f07e5bbb0bfc64e3acbd2404b7ae1a106787d9dd2e320276e7c2d4014af30"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.1.tar.gz", "has_sig": false, "md5_digest": "3178d6697237cbcc9e3616bd05b49043", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 20088, "upload_time": "2019-06-16T10:00:22", "upload_time_iso_8601": "2019-06-16T10:00:22.631578Z", "url": "https://files.pythonhosted.org/packages/97/54/926637ce08e8aa9c18aed9f13c086dc79769a0a3613812a3fa12918e8bb5/feedsearch-crawler-0.1.1.tar.gz", "yanked": false}], "0.1.11": [{"comment_text": "", "digests": {"md5": "37c62531e87bd39f672230d38aad40d5", "sha256": "83221d5fcc0b7754bf3768bec1d6e9f6b40b7652572db76feaa75570a2bb3bec"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.11-py3-none-any.whl", "has_sig": false, "md5_digest": "37c62531e87bd39f672230d38aad40d5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 36224, "upload_time": "2019-09-03T09:39:15", "upload_time_iso_8601": "2019-09-03T09:39:15.780077Z", "url": "https://files.pythonhosted.org/packages/cd/4b/88ca26959334fcd858074cd833e1d4114adee054db2e9eda94fdfe50a53d/feedsearch_crawler-0.1.11-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f36564e7dd64cbd5015f13d63d71d185", "sha256": "f0a449ac22822d146e10ac5aae2dc3d6fac6e2489eca469d041895552561743e"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.11.tar.gz", "has_sig": false, "md5_digest": "f36564e7dd64cbd5015f13d63d71d185", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 30142, "upload_time": "2019-09-03T09:39:37", "upload_time_iso_8601": "2019-09-03T09:39:37.673777Z", "url": "https://files.pythonhosted.org/packages/af/03/9571129f3a09ef5f2cb50d4c09804278d5a47b62b29833066acc56134049/feedsearch-crawler-0.1.11.tar.gz", "yanked": false}], "0.1.12": [{"comment_text": "", "digests": {"md5": "877410f7f285fa8b9935d5ddfabe21eb", "sha256": "9ee713addd7f56710cd7a167e1299966dd645430ee239b329683892022e8b794"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.12-py3-none-any.whl", "has_sig": false, "md5_digest": "877410f7f285fa8b9935d5ddfabe21eb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 37277, "upload_time": "2019-09-12T19:51:25", "upload_time_iso_8601": "2019-09-12T19:51:25.762037Z", "url": "https://files.pythonhosted.org/packages/44/c6/1815e651e32332e47dfc1e2095e8753b22cd6f7e0b2669ed0d2991a26ee8/feedsearch_crawler-0.1.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b65a0804b50c5f1c548fc6f8e46a107", "sha256": "15e486c5c25402eb23e6f162a2a2f146580a6199cdfbdb4a8815ee5908f3d63c"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.12.tar.gz", "has_sig": false, "md5_digest": "8b65a0804b50c5f1c548fc6f8e46a107", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 30825, "upload_time": "2019-09-12T19:51:27", "upload_time_iso_8601": "2019-09-12T19:51:27.607357Z", "url": "https://files.pythonhosted.org/packages/1e/a3/a4ea729f970baefd42f383c08c1d47d9fc847baa60a5f26c6fea3a7e72ec/feedsearch-crawler-0.1.12.tar.gz", "yanked": false}], "0.1.13": [{"comment_text": "", "digests": {"md5": "a87aa066f2a5386d57bc5543a0dddafd", "sha256": "01081b69542603d201d3af016526874b6a2a6fe9bc116ba9b678c5b8a8b956cf"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.13-py3-none-any.whl", "has_sig": false, "md5_digest": "a87aa066f2a5386d57bc5543a0dddafd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 37314, "upload_time": "2019-09-13T17:19:37", "upload_time_iso_8601": "2019-09-13T17:19:37.362915Z", "url": "https://files.pythonhosted.org/packages/b4/d6/a012423dad5616bfb30a1552db9ea5bc1b28985919f825db0a1b93502aed/feedsearch_crawler-0.1.13-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "faa59075dfea19de6943f0b00cd51765", "sha256": "291b11ed9ee6a2072778ba696209f3c7863a4379d63719477e02ef5fbca312a7"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.13.tar.gz", "has_sig": false, "md5_digest": "faa59075dfea19de6943f0b00cd51765", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 30878, "upload_time": "2019-09-13T17:19:40", "upload_time_iso_8601": "2019-09-13T17:19:40.516357Z", "url": "https://files.pythonhosted.org/packages/86/fa/c19177ce137b141cbf9770f93c7a1c61fd9bf428991dbccfb71c40e87c5a/feedsearch-crawler-0.1.13.tar.gz", "yanked": false}], "0.1.14": [{"comment_text": "", "digests": {"md5": "0fc96900f2ca2ec1fba62c5104ea6a43", "sha256": "2117fbd94db807ac47dce0e2b5b396090e1ef9ee7818db950bdfb2047001bb09"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.14-py3-none-any.whl", "has_sig": false, "md5_digest": "0fc96900f2ca2ec1fba62c5104ea6a43", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 37311, "upload_time": "2019-09-14T08:48:50", "upload_time_iso_8601": "2019-09-14T08:48:50.825206Z", "url": "https://files.pythonhosted.org/packages/23/3a/be4f9268d79644bc8078aca218b6dd16c3d4d4cb77ba92a23465d97735db/feedsearch_crawler-0.1.14-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2c5d59849fd69d5985d97a9b39452bf5", "sha256": "38f6c19c670256d57fc87c2b26e8ce5312a7ddb5e8b1f85d5c844587c1636a64"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.14.tar.gz", "has_sig": false, "md5_digest": "2c5d59849fd69d5985d97a9b39452bf5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 30889, "upload_time": "2019-09-14T08:48:55", "upload_time_iso_8601": "2019-09-14T08:48:55.029005Z", "url": "https://files.pythonhosted.org/packages/a9/64/f440968c6087103ec4caa667a66ca11f8173ee2df9c6cb68120e4bae137e/feedsearch-crawler-0.1.14.tar.gz", "yanked": false}], "0.1.15": [{"comment_text": "", "digests": {"md5": "ed988ec60a5cd1dec184c1ef1c1bfd7f", "sha256": "ddad30124e8cc2a997053086abe87729dc204f6c3a1a6251e33bbadfb4a51803"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.15-py3-none-any.whl", "has_sig": false, "md5_digest": "ed988ec60a5cd1dec184c1ef1c1bfd7f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 37325, "upload_time": "2019-09-14T13:24:02", "upload_time_iso_8601": "2019-09-14T13:24:02.094782Z", "url": "https://files.pythonhosted.org/packages/b0/f2/e2081a1877bcf55910ceae317393f48a20c8ee3229b5a476607cf1174376/feedsearch_crawler-0.1.15-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "065d1cf8700dece17144dd2344de5c87", "sha256": "2835c30303b6d6fcda036de49238dd23e3a54a3f30be2614299b677df0125ff8"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.15.tar.gz", "has_sig": false, "md5_digest": "065d1cf8700dece17144dd2344de5c87", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 30898, "upload_time": "2019-09-14T13:24:07", "upload_time_iso_8601": "2019-09-14T13:24:07.908676Z", "url": "https://files.pythonhosted.org/packages/5c/10/039b64094dfbf84ac6d5b08443fe4fa6399b152cba01365e6e613bc82eba/feedsearch-crawler-0.1.15.tar.gz", "yanked": false}], "0.1.16": [{"comment_text": "", "digests": {"md5": "2f7aafbf569a116ac8d2287466d29356", "sha256": "a70fe4954308fba48523d494ea7030f19cb9ec6de8047bb615523534af34e4d6"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.16-py3-none-any.whl", "has_sig": false, "md5_digest": "2f7aafbf569a116ac8d2287466d29356", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 37793, "upload_time": "2019-09-22T17:48:34", "upload_time_iso_8601": "2019-09-22T17:48:34.260511Z", "url": "https://files.pythonhosted.org/packages/76/ce/4a53d462ec3edfde81d974c4dc2494b167fbc2e0f4f0ab128b348b086530/feedsearch_crawler-0.1.16-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "741055b96ae746eb0b0dec4eeda2a436", "sha256": "1b24db1af50a3214f3cd16d53a2f3428c6a517df36f4f079bcbfdc65a21fbc41"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.16.tar.gz", "has_sig": false, "md5_digest": "741055b96ae746eb0b0dec4eeda2a436", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 31406, "upload_time": "2019-09-22T17:48:36", "upload_time_iso_8601": "2019-09-22T17:48:36.107731Z", "url": "https://files.pythonhosted.org/packages/02/17/b386a18b7534e2f4cdef669d84f89af75bad82fdc8126a2f67675b179d0a/feedsearch-crawler-0.1.16.tar.gz", "yanked": false}], "0.1.17": [{"comment_text": "", "digests": {"md5": "3e5923e3093bdd74085b22f01ea2d964", "sha256": "da0fa9c289e223b0aaf569800b6efd92da3c599c1941a4e64909b17c81610c2c"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.17-py3-none-any.whl", "has_sig": false, "md5_digest": "3e5923e3093bdd74085b22f01ea2d964", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 38097, "upload_time": "2019-10-24T08:35:36", "upload_time_iso_8601": "2019-10-24T08:35:36.643763Z", "url": "https://files.pythonhosted.org/packages/9c/04/d3df5d20c54f0e15c30510f0a4bf248a04a8f203bcc44654829219e83707/feedsearch_crawler-0.1.17-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "390be88a9634ba43a0c1be87ac97644e", "sha256": "24472e0d075c1f813c36edf83333e4ae099b2273c3d9786ee007b3918d3e4ae5"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.17.tar.gz", "has_sig": false, "md5_digest": "390be88a9634ba43a0c1be87ac97644e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 31643, "upload_time": "2019-10-24T08:35:38", "upload_time_iso_8601": "2019-10-24T08:35:38.018908Z", "url": "https://files.pythonhosted.org/packages/9c/78/f766111a801dc09250a340a36d3bd5ffe145121be5836e5ca7427081b55e/feedsearch-crawler-0.1.17.tar.gz", "yanked": false}], "0.1.18": [{"comment_text": "", "digests": {"md5": "6dc9f18101fea06648faea9b3967769f", "sha256": "1c209f36d00857b5329749368ae33046357c33bab32da3bcf17af6c02638ad2d"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.18-py3-none-any.whl", "has_sig": false, "md5_digest": "6dc9f18101fea06648faea9b3967769f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 38335, "upload_time": "2019-10-30T12:32:18", "upload_time_iso_8601": "2019-10-30T12:32:18.683136Z", "url": "https://files.pythonhosted.org/packages/e6/b5/e1846f17ed9d18413783f0188478b22e51e73a82f7e74fc216d231501767/feedsearch_crawler-0.1.18-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d915cd99d9a8e8ae12f1a2e07a6d66b", "sha256": "4c6cd0086dfcabe127a29aee314b1f8da9b211f33d2a45be3992a66d10d53ae7"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.18.tar.gz", "has_sig": false, "md5_digest": "9d915cd99d9a8e8ae12f1a2e07a6d66b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 31878, "upload_time": "2019-10-30T12:32:21", "upload_time_iso_8601": "2019-10-30T12:32:21.105294Z", "url": "https://files.pythonhosted.org/packages/ce/48/f09f4b9a748e1f043eb1e45abb6be4eaf0a72eae53c059c2c0cf20635a8e/feedsearch-crawler-0.1.18.tar.gz", "yanked": false}], "0.1.19": [{"comment_text": "", "digests": {"md5": "00e3020908fc5cd9c78e0f5e26948274", "sha256": "f9337c1a61990f8d8cee731f6099d5929650da53396d7b86b960d35fd1425f8b"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.19-py3-none-any.whl", "has_sig": false, "md5_digest": "00e3020908fc5cd9c78e0f5e26948274", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 38517, "upload_time": "2019-10-31T14:04:10", "upload_time_iso_8601": "2019-10-31T14:04:10.590776Z", "url": "https://files.pythonhosted.org/packages/77/9d/3a2c5149668005924c6e6891949376a537e92c42441fff07687b23e2fe20/feedsearch_crawler-0.1.19-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "51ebf177fac0e809a38bb0f018cd1851", "sha256": "8de9afdb311250da2c334fa549cb97e4a3bafe867623c48cc8b1e2cb48921d06"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.19.tar.gz", "has_sig": false, "md5_digest": "51ebf177fac0e809a38bb0f018cd1851", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32076, "upload_time": "2019-10-31T14:04:15", "upload_time_iso_8601": "2019-10-31T14:04:15.006753Z", "url": "https://files.pythonhosted.org/packages/d0/75/d1026a2047256119ef4398b3d2262886a6562dc970a7f3773442015a90d1/feedsearch-crawler-0.1.19.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "588009f167743af32a390ca3ced9a05b", "sha256": "3b33702c95d758d8b6b63f432c1046dcb9895f28f47d72c94d507bcb064cb5e0"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "588009f167743af32a390ca3ced9a05b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 29527, "upload_time": "2019-06-25T19:07:30", "upload_time_iso_8601": "2019-06-25T19:07:30.489283Z", "url": "https://files.pythonhosted.org/packages/06/bb/d0cdba6d1466797d8c7d5fba762b527d7097560ef810fb3bb18cbf345c4a/feedsearch_crawler-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3fb22399f417a0100acead43a77003dc", "sha256": "82f8663a478587186ef8a17a8a166df22b4f7e429b05371daed93413178371aa"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.2.tar.gz", "has_sig": false, "md5_digest": "3fb22399f417a0100acead43a77003dc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 24235, "upload_time": "2019-06-25T19:07:32", "upload_time_iso_8601": "2019-06-25T19:07:32.246547Z", "url": "https://files.pythonhosted.org/packages/b8/a4/8cda0e4ea87a471af48e48d9947cf2c616e71b3b6dbcf49f332a00e92dfa/feedsearch-crawler-0.1.2.tar.gz", "yanked": false}], "0.1.20": [{"comment_text": "", "digests": {"md5": "969c8b4d6791038eecea3ceceea6e12e", "sha256": "8a54b2b5f1bc1199b3549e0eac50dab5fc797564738ce2ae70ff01a197d325c8"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.20-py3-none-any.whl", "has_sig": false, "md5_digest": "969c8b4d6791038eecea3ceceea6e12e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 38648, "upload_time": "2019-11-02T17:05:18", "upload_time_iso_8601": "2019-11-02T17:05:18.960754Z", "url": "https://files.pythonhosted.org/packages/74/8e/c4bd3d1e0ddd4ac0cf66b96da6c60aba62f4237d1b6e43288f192beabace/feedsearch_crawler-0.1.20-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8198a33094b2a65febd9d3ad3cd89feb", "sha256": "9f62e6d5302d5bda4f901ad5869a05b30b764e70cabcd7fce67a8a2d5cb36359"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.20.tar.gz", "has_sig": false, "md5_digest": "8198a33094b2a65febd9d3ad3cd89feb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32290, "upload_time": "2019-11-02T17:05:20", "upload_time_iso_8601": "2019-11-02T17:05:20.370340Z", "url": "https://files.pythonhosted.org/packages/15/8b/c32af96e1aa507704b2821d201c34eaa95789dc67545d6e29d4304147abf/feedsearch-crawler-0.1.20.tar.gz", "yanked": false}], "0.1.21": [{"comment_text": "", "digests": {"md5": "cc754d7c7f6d304027c6f468b025ce81", "sha256": "269e3eb69337afca12f466eb4f94e556abc4d25128e968f47ecbb90b60a90202"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.21-py3-none-any.whl", "has_sig": false, "md5_digest": "cc754d7c7f6d304027c6f468b025ce81", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 38764, "upload_time": "2019-11-02T19:27:11", "upload_time_iso_8601": "2019-11-02T19:27:11.939293Z", "url": "https://files.pythonhosted.org/packages/34/47/3c8acb95c31555a0b7c652453c84818454b657690785e03900ba13f23f61/feedsearch_crawler-0.1.21-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c78ef70082ef7a1e43e6986bde2c827f", "sha256": "bee9eafc28b18bec0893703ccc0c90462bbc263be32f1436602ad12788a271b9"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.21.tar.gz", "has_sig": false, "md5_digest": "c78ef70082ef7a1e43e6986bde2c827f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32542, "upload_time": "2019-11-02T19:27:13", "upload_time_iso_8601": "2019-11-02T19:27:13.702945Z", "url": "https://files.pythonhosted.org/packages/fd/66/7b29a1c49718620b9477530e3bf5d77d7136b1157e207e5a9418242fe18c/feedsearch-crawler-0.1.21.tar.gz", "yanked": false}], "0.1.22": [{"comment_text": "", "digests": {"md5": "c9bd80779527fe6369c3ee9acdae217f", "sha256": "832ad0ef37553475714b66c1f1ccd6fc90035f9c32e9392870c0f9e181d8e27a"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.22-py3-none-any.whl", "has_sig": false, "md5_digest": "c9bd80779527fe6369c3ee9acdae217f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 38858, "upload_time": "2019-11-06T10:36:48", "upload_time_iso_8601": "2019-11-06T10:36:48.698005Z", "url": "https://files.pythonhosted.org/packages/c9/ca/7858155dad3bf62029ac9214a4802d141c0c5290baca0146b762fdc69f35/feedsearch_crawler-0.1.22-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e1e6a01bf29b0fb44489b0ef990c07b3", "sha256": "bf001217ae3704fb1c6d69838d979e709ecb17d0ee6fbdafef38fddf1b71294a"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.22.tar.gz", "has_sig": false, "md5_digest": "e1e6a01bf29b0fb44489b0ef990c07b3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32593, "upload_time": "2019-11-06T10:36:51", "upload_time_iso_8601": "2019-11-06T10:36:51.116862Z", "url": "https://files.pythonhosted.org/packages/e3/87/bd4cb29196e32e957fa0921fe971bc2fa762be76ffbccf710f6e1e143071/feedsearch-crawler-0.1.22.tar.gz", "yanked": false}], "0.1.23": [{"comment_text": "", "digests": {"md5": "3b429084efd1807a49aa23d70512eea4", "sha256": "68ab55e5f85f42f3fefa34f826442d4cf400491ddc0ea6cbdf3975feebe12796"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.23-py3-none-any.whl", "has_sig": false, "md5_digest": "3b429084efd1807a49aa23d70512eea4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 39103, "upload_time": "2019-11-20T20:39:11", "upload_time_iso_8601": "2019-11-20T20:39:11.506459Z", "url": "https://files.pythonhosted.org/packages/cb/aa/3608b2db5968af0e0e702a9abde0afc0a51ba5e92481b00380707e62c8ae/feedsearch_crawler-0.1.23-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5d7bbc0003b541d1d609ab5f4b35c4bb", "sha256": "4ded323e5bf3ee0348cc5ed7a893157fc86077ba96e7286740c75d489efad407"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.23.tar.gz", "has_sig": false, "md5_digest": "5d7bbc0003b541d1d609ab5f4b35c4bb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32855, "upload_time": "2019-11-20T20:39:14", "upload_time_iso_8601": "2019-11-20T20:39:14.187323Z", "url": "https://files.pythonhosted.org/packages/be/3e/d7bdd69010b5d650bd9c97f07c8c9527b914d57e6ec52968075afd31c71b/feedsearch-crawler-0.1.23.tar.gz", "yanked": false}], "0.1.24": [{"comment_text": "", "digests": {"md5": "5a801abb4efa4172e4ac1a0318b2ef6e", "sha256": "2f92984c61ea2052976cf5664e5f17b2a1a4b050c91c267bc27d574145c27254"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.24-py3-none-any.whl", "has_sig": false, "md5_digest": "5a801abb4efa4172e4ac1a0318b2ef6e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 39177, "upload_time": "2019-11-22T14:49:12", "upload_time_iso_8601": "2019-11-22T14:49:12.216431Z", "url": "https://files.pythonhosted.org/packages/ac/f8/ebe981e3cb8f6b16af31d49c4a1e7bd630fa0ed03be515f6f0c6c3d052f8/feedsearch_crawler-0.1.24-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cde47dff5b03b1fb03073df824c80074", "sha256": "1653622f148f438209a08fed612b5a2e4f21bde845b4faf61f4172e8708d4f1c"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.24.tar.gz", "has_sig": false, "md5_digest": "cde47dff5b03b1fb03073df824c80074", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32894, "upload_time": "2019-11-22T14:49:13", "upload_time_iso_8601": "2019-11-22T14:49:13.663957Z", "url": "https://files.pythonhosted.org/packages/d9/ea/36677ea8f677bcf48fd30f7928f9f64995b79a68762ccff6b8fbd8ef6956/feedsearch-crawler-0.1.24.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "db856e0c32880a0a7183cf5710976c42", "sha256": "771ad76789cfe761d9b75f30ca3754d8b93cbc54c57c8798abd4e3cc332178c6"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "db856e0c32880a0a7183cf5710976c42", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 34927, "upload_time": "2019-07-04T20:33:27", "upload_time_iso_8601": "2019-07-04T20:33:27.568986Z", "url": "https://files.pythonhosted.org/packages/4c/5f/4984ea2b07bc4bf4e729f5765aa36e0f41a97189d974af47a2761c84962b/feedsearch_crawler-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "68be70a9304082c40689e7f3a2e614a8", "sha256": "2e34d471b1ab2ba3595b171361ec0131b5c857c423324d23319d6d971233f6fc"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.3.tar.gz", "has_sig": false, "md5_digest": "68be70a9304082c40689e7f3a2e614a8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 29105, "upload_time": "2019-07-04T20:33:30", "upload_time_iso_8601": "2019-07-04T20:33:30.017160Z", "url": "https://files.pythonhosted.org/packages/34/63/4232e6c5f537473f5f77629a8b8fab6ad432a1ce7590ab5cb28e654c8cf7/feedsearch-crawler-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "b905076205074e49e3b078c892fe0281", "sha256": "99ae2ef122475b05a5324ee22d069547a0907a90e7c06467ceeac5b6e5036e63"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "b905076205074e49e3b078c892fe0281", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 34949, "upload_time": "2019-07-04T21:24:57", "upload_time_iso_8601": "2019-07-04T21:24:57.202280Z", "url": "https://files.pythonhosted.org/packages/9d/84/36803c947f6bc60a95d54cf5ee9bb2a6fb251e5db22ac837b42f051243b9/feedsearch_crawler-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "911055d4d393f16192d5ca2ad22316b3", "sha256": "3272b5b52859e5a1358377b510e5c1eb935232d476beb5f24a464bbdb37601c2"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.4.tar.gz", "has_sig": false, "md5_digest": "911055d4d393f16192d5ca2ad22316b3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 29128, "upload_time": "2019-07-04T21:25:00", "upload_time_iso_8601": "2019-07-04T21:25:00.703092Z", "url": "https://files.pythonhosted.org/packages/da/c8/77211f2039acb24be1cddb343a831b1e59f79e9ff12f8df7f045309dc8bd/feedsearch-crawler-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "ccf4374cffc983486474a82e288960c1", "sha256": "428bc10411c6a0880f9f3577317b3047d03c0c5c6ee1df053ec8441ae94c6a15"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "ccf4374cffc983486474a82e288960c1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 35164, "upload_time": "2019-07-05T10:42:16", "upload_time_iso_8601": "2019-07-05T10:42:16.336862Z", "url": "https://files.pythonhosted.org/packages/87/b3/59295cbaa19728bb02a25f29f98ec8efd87ca35903ac26d80b0fe1f9664d/feedsearch_crawler-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7896940dc879fe313f2b046e7029a07", "sha256": "df4409c243fd2c7562fef4457ab8846fed72feb32be9bcb2cd280ca28ef75f5e"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.5.tar.gz", "has_sig": false, "md5_digest": "d7896940dc879fe313f2b046e7029a07", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 29324, "upload_time": "2019-07-05T10:42:20", "upload_time_iso_8601": "2019-07-05T10:42:20.104023Z", "url": "https://files.pythonhosted.org/packages/a4/28/c004381bb460ef8556440122091b92620132eecb901608d054f8de8816cd/feedsearch-crawler-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "3af0782b89c85f339ffdff849066b5b3", "sha256": "aa0af6824139c1c47b83e068a6170159d09a620c04cd60ccb6ced81523e56bcc"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "3af0782b89c85f339ffdff849066b5b3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 35292, "upload_time": "2019-07-05T21:21:04", "upload_time_iso_8601": "2019-07-05T21:21:04.541947Z", "url": "https://files.pythonhosted.org/packages/b9/4a/6c9edd6d9302a45709b82486df97d7a821f311abc9fd5b596c7599af5a82/feedsearch_crawler-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "659caf0433e8ac7e9e81e42ee482f816", "sha256": "6b3e7733812c7d580d68eddad1a61ef3dd03441ab03d91e5808c7ba3ce42762c"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.6.tar.gz", "has_sig": false, "md5_digest": "659caf0433e8ac7e9e81e42ee482f816", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 29477, "upload_time": "2019-07-05T21:21:10", "upload_time_iso_8601": "2019-07-05T21:21:10.080486Z", "url": "https://files.pythonhosted.org/packages/d6/87/c87e201881b94d62f4405fd54d54361b19bf221617a8551d9e639bdbdd89/feedsearch-crawler-0.1.6.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "804a55def06b339bf292b8df3f43d6a7", "sha256": "797e1c4dd6d934c78485b636cdd15a3c280c1cb3c37f5ee830a90065b1ced4ad"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "804a55def06b339bf292b8df3f43d6a7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 35871, "upload_time": "2019-08-27T19:32:36", "upload_time_iso_8601": "2019-08-27T19:32:36.429840Z", "url": "https://files.pythonhosted.org/packages/af/e5/ffbc5c06b1628bd00aed5cb50eaa140a321c0fcce0bfc84e644be8302a78/feedsearch_crawler-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65fbf23e97171338019dc1fdc7fe0436", "sha256": "a9204fc92ca40c6c014d6b9b7752c8a7aab511fb0e4f9b2b667b414aa396f81f"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.8.tar.gz", "has_sig": false, "md5_digest": "65fbf23e97171338019dc1fdc7fe0436", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 29950, "upload_time": "2019-08-27T19:32:42", "upload_time_iso_8601": "2019-08-27T19:32:42.660798Z", "url": "https://files.pythonhosted.org/packages/ab/ba/408d312edb9ec26c523abb4d2a6b442f1027b9c207f06ed70fec99192933/feedsearch-crawler-0.1.8.tar.gz", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "7690f6b13cff227c8c765fa1f9747f62", "sha256": "1838f40641fd887468c210a2e6af2976d035e8da9af7215ab7c181b3d5f259b3"}, "downloads": -1, "filename": "feedsearch_crawler-0.1.9-py3-none-any.whl", "has_sig": false, "md5_digest": "7690f6b13cff227c8c765fa1f9747f62", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 36200, "upload_time": "2019-09-03T07:48:38", "upload_time_iso_8601": "2019-09-03T07:48:38.460850Z", "url": "https://files.pythonhosted.org/packages/ba/77/516f7dbf73b04af0aadc6c3c0d86741ff75835a9d54da4b34527c5a0a2f3/feedsearch_crawler-0.1.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8ee2d705821125a765e4d423658eac36", "sha256": "d38aa8fc50b7c26c00e6e8386e33637c8ca51105b84f26ea6edf8a9125dd3db6"}, "downloads": -1, "filename": "feedsearch-crawler-0.1.9.tar.gz", "has_sig": false, "md5_digest": "8ee2d705821125a765e4d423658eac36", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 30129, "upload_time": "2019-09-03T07:48:39", "upload_time_iso_8601": "2019-09-03T07:48:39.884675Z", "url": "https://files.pythonhosted.org/packages/33/30/dfb3b377e77e1da5217f2e23882431e819ad14524b30fa99b9cd5effeb86/feedsearch-crawler-0.1.9.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "537cef14d79f79a7586ce0569f1901ac", "sha256": "badbb4b9b60699520b13e1af70994b086e4d519faea507f47b43ba86a180dd01"}, "downloads": -1, "filename": "feedsearch_crawler-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "537cef14d79f79a7586ce0569f1901ac", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 39218, "upload_time": "2019-11-25T20:13:17", "upload_time_iso_8601": "2019-11-25T20:13:17.636548Z", "url": "https://files.pythonhosted.org/packages/b4/b2/5dd264fce08609c80ffe2b57fba5285ae80ed1a35bca4805d6c2a2746ca7/feedsearch_crawler-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b6d71632ec51343b0876513b4acd24e5", "sha256": "71e833d48eccad11b67d09315b8e9326d01f694f6bba92c4f99bebc5245b88fd"}, "downloads": -1, "filename": "feedsearch-crawler-0.2.0.tar.gz", "has_sig": false, "md5_digest": "b6d71632ec51343b0876513b4acd24e5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32990, "upload_time": "2019-11-25T20:13:20", "upload_time_iso_8601": "2019-11-25T20:13:20.915264Z", "url": "https://files.pythonhosted.org/packages/af/be/16c782df962f7186107866c921003651660442cdc6bdc06fe2d547349ccb/feedsearch-crawler-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "a022277ca2031fbb677ce5f1d15b6f31", "sha256": "56292a09728fd2b683cf58633d27cdf7d70b229aa760e247ea1f0bd764870019"}, "downloads": -1, "filename": "feedsearch_crawler-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a022277ca2031fbb677ce5f1d15b6f31", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 39723, "upload_time": "2019-12-05T13:47:25", "upload_time_iso_8601": "2019-12-05T13:47:25.635230Z", "url": "https://files.pythonhosted.org/packages/0c/b5/4aad1c6aa6d62208d71047cde76f7dc812b6a0be9e06d1f8a62ff1887e30/feedsearch_crawler-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "151d4a9661e7dd86461048f5bb394fdb", "sha256": "1b8406caa5a1190c33a360b4eb792da246a98caf357095da9610c6c2fd5f003d"}, "downloads": -1, "filename": "feedsearch-crawler-0.2.1.tar.gz", "has_sig": false, "md5_digest": "151d4a9661e7dd86461048f5bb394fdb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 33347, "upload_time": "2019-12-05T13:47:27", "upload_time_iso_8601": "2019-12-05T13:47:27.760428Z", "url": "https://files.pythonhosted.org/packages/11/9b/5e220d837939ca6db1bd043873a4c4936f5b957f3640887241516d56f4ee/feedsearch-crawler-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "30c4ef120e83e6c0d6b9a4e2888034a3", "sha256": "f1ac9edefd8ce25a164aaa046b05767299385b1bc680e45ba95e3bb9602b3b41"}, "downloads": -1, "filename": "feedsearch_crawler-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "30c4ef120e83e6c0d6b9a4e2888034a3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 39732, "upload_time": "2019-12-12T11:42:44", "upload_time_iso_8601": "2019-12-12T11:42:44.326531Z", "url": "https://files.pythonhosted.org/packages/e6/c7/f173d2ab49d87e036396ae0d908925625543897e93498e162826e3554971/feedsearch_crawler-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d4c32108f05532e12f0892619a546852", "sha256": "f2bc0978e471db9f39a4491c0aeddf5bd6108dd366ed824bf0bf60c8beef5cab"}, "downloads": -1, "filename": "feedsearch-crawler-0.2.2.tar.gz", "has_sig": false, "md5_digest": "d4c32108f05532e12f0892619a546852", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 33355, "upload_time": "2019-12-12T11:42:45", "upload_time_iso_8601": "2019-12-12T11:42:45.743970Z", "url": "https://files.pythonhosted.org/packages/98/d2/9e5e27f1fcabd72a9f169a809effc9221ea7b03204e5dae6448bf7ad406e/feedsearch-crawler-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "d65ba5b00685aee7d48f338d470d5bb0", "sha256": "bfccceb768ffa37f3e8ad333963c4ec793d11b29620d388f8258b5d2efbdef5f"}, "downloads": -1, "filename": "feedsearch_crawler-0.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "d65ba5b00685aee7d48f338d470d5bb0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 40778, "upload_time": "2020-02-26T13:15:09", "upload_time_iso_8601": "2020-02-26T13:15:09.155765Z", "url": "https://files.pythonhosted.org/packages/4b/5d/acc8d414031cfe2e1c5e53ffe1c5f8213795d08ea108799011b72c24e5a8/feedsearch_crawler-0.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "874fd8dc6958e68332fbc673c015597f", "sha256": "fc211535f83f434eecf98838383d85bd8a1dd5ecf4ec7a4f7aa73eaac993a18c"}, "downloads": -1, "filename": "feedsearch-crawler-0.2.3.tar.gz", "has_sig": false, "md5_digest": "874fd8dc6958e68332fbc673c015597f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 33785, "upload_time": "2020-02-26T13:15:11", "upload_time_iso_8601": "2020-02-26T13:15:11.790702Z", "url": "https://files.pythonhosted.org/packages/48/86/ccf26a9999dcd561f9424947738709ad27bdaed03e9a255483aad210c0e9/feedsearch-crawler-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "a469ccd68db27eda12434cbe58196bf3", "sha256": "64dcf1c18dfe7b79b4a28717333a026d1472735beda9f3729cb99a55967d54a8"}, "downloads": -1, "filename": "feedsearch_crawler-0.2.4-py3-none-any.whl", "has_sig": false, "md5_digest": "a469ccd68db27eda12434cbe58196bf3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 40749, "upload_time": "2020-03-29T13:14:47", "upload_time_iso_8601": "2020-03-29T13:14:47.060401Z", "url": "https://files.pythonhosted.org/packages/80/d4/fbafda1874cca2b60984eb9f1bd37579bffa06c5d5cb3b25515d9bf4a004/feedsearch_crawler-0.2.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bf796752caa9e2c3c72bc3cdb42fe897", "sha256": "9c3070cce58413572a3abf6c01ac4988bf66f1bcff680fb6042ae6320a4b8fd0"}, "downloads": -1, "filename": "feedsearch-crawler-0.2.4.tar.gz", "has_sig": false, "md5_digest": "bf796752caa9e2c3c72bc3cdb42fe897", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 33894, "upload_time": "2020-03-29T13:14:51", "upload_time_iso_8601": "2020-03-29T13:14:51.088705Z", "url": "https://files.pythonhosted.org/packages/c6/2b/2909e212cf8cae7fb82263044046ad1fc056060b2c705cab67c9f80f9b8e/feedsearch-crawler-0.2.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a469ccd68db27eda12434cbe58196bf3", "sha256": "64dcf1c18dfe7b79b4a28717333a026d1472735beda9f3729cb99a55967d54a8"}, "downloads": -1, "filename": "feedsearch_crawler-0.2.4-py3-none-any.whl", "has_sig": false, "md5_digest": "a469ccd68db27eda12434cbe58196bf3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 40749, "upload_time": "2020-03-29T13:14:47", "upload_time_iso_8601": "2020-03-29T13:14:47.060401Z", "url": "https://files.pythonhosted.org/packages/80/d4/fbafda1874cca2b60984eb9f1bd37579bffa06c5d5cb3b25515d9bf4a004/feedsearch_crawler-0.2.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bf796752caa9e2c3c72bc3cdb42fe897", "sha256": "9c3070cce58413572a3abf6c01ac4988bf66f1bcff680fb6042ae6320a4b8fd0"}, "downloads": -1, "filename": "feedsearch-crawler-0.2.4.tar.gz", "has_sig": false, "md5_digest": "bf796752caa9e2c3c72bc3cdb42fe897", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 33894, "upload_time": "2020-03-29T13:14:51", "upload_time_iso_8601": "2020-03-29T13:14:51.088705Z", "url": "https://files.pythonhosted.org/packages/c6/2b/2909e212cf8cae7fb82263044046ad1fc056060b2c705cab67c9f80f9b8e/feedsearch-crawler-0.2.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:59 2020"}