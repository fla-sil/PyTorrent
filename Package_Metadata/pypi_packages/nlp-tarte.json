{"info": {"author": "Thibault Cl\u00e9rice", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy", "Topic :: Text Processing :: Linguistic"], "description": "\nTarte\n=======================\n\nA secondary layer for pie for disambiguation\n\n# What it aims to do\n\n- This tagger is supposed to come as a secondary layer for lemma that should be disambiguated.\n- Its core object (`Tarte`) should filter things that need to be disambiguated\n- Its training capacities should reorganize a training set so that it dispatch training samples across all sets and\nit should not care about sample not containing unambiguous tokens.\n- It takes POS, lemma context and form characters into the network to predict the disambiguated form.\n\n# Notes\n\n- Given that not all sentences will have things to disambiguate, pretraining vector might be an important task. It\n is [possible with PyTorch](https://stackoverflow.com/questions/49710537/pytorch-gensim-how-to-load-pre-trained-word-embeddings)\n to load Gensim data easily. This would **require** to generate temps file where lemma AND pos are fed to \n fake sentences.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ponteineptique/tarte", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "nlp-tarte", "package_url": "https://pypi.org/project/nlp-tarte/", "platform": "", "project_url": "https://pypi.org/project/nlp-tarte/", "project_urls": {"Homepage": "https://github.com/ponteineptique/tarte"}, "release_url": "https://pypi.org/project/nlp-tarte/0.0.1/", "requires_dist": ["nlp-pie (<=1.0.0,>=0.2.2)", "regex"], "requires_python": ">=3.6.0", "summary": "A framework for disambiguation", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Tarte</h1>\n<p>A secondary layer for pie for disambiguation</p>\n<h1>What it aims to do</h1>\n<ul>\n<li>This tagger is supposed to come as a secondary layer for lemma that should be disambiguated.</li>\n<li>Its core object (<code>Tarte</code>) should filter things that need to be disambiguated</li>\n<li>Its training capacities should reorganize a training set so that it dispatch training samples across all sets and\nit should not care about sample not containing unambiguous tokens.</li>\n<li>It takes POS, lemma context and form characters into the network to predict the disambiguated form.</li>\n</ul>\n<h1>Notes</h1>\n<ul>\n<li>Given that not all sentences will have things to disambiguate, pretraining vector might be an important task. It\nis <a href=\"https://stackoverflow.com/questions/49710537/pytorch-gensim-how-to-load-pre-trained-word-embeddings\" rel=\"nofollow\">possible with PyTorch</a>\nto load Gensim data easily. This would <strong>require</strong> to generate temps file where lemma AND pos are fed to\nfake sentences.</li>\n</ul>\n\n          </div>"}, "last_serial": 5742595, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "7c8c484c31778b329bf58f33d3942854", "sha256": "bc82d3828c13e34944b51bc737f369ab94a3621d1151227342546b599596e295"}, "downloads": -1, "filename": "nlp_tarte-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7c8c484c31778b329bf58f33d3942854", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 25561, "upload_time": "2019-08-28T13:35:43", "upload_time_iso_8601": "2019-08-28T13:35:43.211676Z", "url": "https://files.pythonhosted.org/packages/fc/66/2b2fcef56a4c92d82888d74c4711db95fa0aea445a841c29c73275629c58/nlp_tarte-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5dabac05f9454d83e405bdcfc6a7b590", "sha256": "d08a64d07595fd83d290d82ddd992160ab66be8d521cf7b6eb4a8f9c9529a1e8"}, "downloads": -1, "filename": "nlp_tarte-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5dabac05f9454d83e405bdcfc6a7b590", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 20563, "upload_time": "2019-08-28T13:35:45", "upload_time_iso_8601": "2019-08-28T13:35:45.498781Z", "url": "https://files.pythonhosted.org/packages/8f/6c/1ffbcb00902a806668f9bc58c35be7d91dbc93070d0934ece0757fb92c23/nlp_tarte-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7c8c484c31778b329bf58f33d3942854", "sha256": "bc82d3828c13e34944b51bc737f369ab94a3621d1151227342546b599596e295"}, "downloads": -1, "filename": "nlp_tarte-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7c8c484c31778b329bf58f33d3942854", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 25561, "upload_time": "2019-08-28T13:35:43", "upload_time_iso_8601": "2019-08-28T13:35:43.211676Z", "url": "https://files.pythonhosted.org/packages/fc/66/2b2fcef56a4c92d82888d74c4711db95fa0aea445a841c29c73275629c58/nlp_tarte-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5dabac05f9454d83e405bdcfc6a7b590", "sha256": "d08a64d07595fd83d290d82ddd992160ab66be8d521cf7b6eb4a8f9c9529a1e8"}, "downloads": -1, "filename": "nlp_tarte-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5dabac05f9454d83e405bdcfc6a7b590", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 20563, "upload_time": "2019-08-28T13:35:45", "upload_time_iso_8601": "2019-08-28T13:35:45.498781Z", "url": "https://files.pythonhosted.org/packages/8f/6c/1ffbcb00902a806668f9bc58c35be7d91dbc93070d0934ece0757fb92c23/nlp_tarte-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:10 2020"}