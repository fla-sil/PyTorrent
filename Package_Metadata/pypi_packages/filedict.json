{"info": {"author": "David Kuryakin", "author_email": "dkuryakin@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Other Environment", "Intended Audience :: Developers", "License :: Freeware", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Database :: Database Engines/Servers"], "description": "filedict\n========\n\n\nPurposes\n--------\n\nThere are a lot of great in-memory key-value storages like Redis/Memcache. But\nall of them are limited by RAM. Imagine you want to store 100,000,000,000 of\nkey-value pairs and have quite fast random-access to items by key. Filedict\nwas designed exactly for this case.\n\n\nInstall\n-------\n::\n\n    $ git clone https://bitbucket.org/dkuryakin/filedict.git\n    $ cd filedict && python setup.py install\n\n\nor\n\n::\n\n    $ pip install filedict\n\n\nDocumentation\n-------------\n\nI believe that the best documentation - is a comprehensive and in-place\ncommented set of examples. So here they are:\n\n.. code-block:: python\n\n    import ctypes\n    import filedict\n\n\n    class Storage(filedict.BaseStorage):\n        # This is simple in-file storage based on hash table.\n\n        max_records = 1000\n        # You can not save more than 1000 values in this database! This limit\n        # can not be changed in the future. It is necessary to initially\n        # correctly estimate the maximum number of entries in the database.\n        # In the worst case it is necessary to copy this database to the new\n        # larger database element by element.\n\n        key_types = ctypes.c_uint64,\n        val_types = ctypes.c_uint32, ctypes.c_uint32\n        # Specify key & value binary representation. Each record in database\n        # file has size = 1 + sizeof(key) + sizeof(val). In current case it's\n        # 1 + 8 + (4 + 4) = 17 bytes. So resulting database file has size\n        # 1000 * 17 = 17000 bytes. You can check this fact yourself. Note:\n        # key-value types are fixed, and can't be changed in future!\n\n\n    # Use simple try-finally form:\n    db = Storage('/path/to/db', read_only=False, read_count=100)\n    # There are 3 parameters when create instance of Storage: path, read_only\n    # and read_count. Path - path to database dir. Only one writer per database\n    # is allowed, so use read_only=True if you don't need any writes. Read\n    # count specify read block size for all operations which involve a lot of\n    # sequential reads. Default value for read_count is quite good for most of\n    # cases.\n    db.record_size == 1 + 8 + (4 + 4)  # True.\n    try:\n        db.open()\n        # do something with db\n    finally:\n        db.close()\n\n\n    # Or use context-manager form:\n    with Storage('/path/to/db', read_only=False, read_count=100) as db:\n        # You can add key-value pair to database. Return None. Duplicate keys\n        # allowed. Duplicate key-value pairs allowed too.\n        key1 = 0,\n        key2 = 1,\n        val1 = 0, 1\n        val2 = 1, 2\n        val3 = 2, 3\n        db.add(key1, val1)\n        db.add(key1, val2)\n        db.add(key2, val3)\n        # Note: this type of storage is rapidly becoming ineffective in the\n        # case of a large number of records with the same key. So it is\n        # recommended to take care of a high degree of uniqueness at the\n        # application level. Besides the performance starts to drop\n        # dramatically when free space ends in the database. It is recommended\n        # to set value of max_records 10-15% more than the actual maximum\n        # size of the database. Also writes slow down on SATA disks for huge\n        # databases. If you want to store huge amount of data and you don't\n        # have SSD disk - try to use BaseShardedStorage instead (see below).\n\n        # You can iterate over different values for target key.\n        it = db.values(key1)  # Return generator.\n        set(it) == set([val1, val2])  # Sets are equal, but iteration order is\n                                      # not defined!\n\n        # You can iterate over all key-value pairs in database. Note: order is\n        # not defined!\n        it = db.items()  # Returns generator.\n        set(it) == set([(key1, val1), (key1, val2), (key2, val3)])\n\n        # You can get estimation for database size. Note: this estimation is\n        # precise for writer. It can be outdated for readers in case of active\n        # writer. But if there is no active writer, estimation will be precise\n        # for readers too.\n        len(db) == 3  # That's True.\n\n        # It's possible to delete all mentions of key-value pair from database.\n        1 == db.del_value(key1, val1)  # Return number of deleted records.\n        len(db) == 2  # True.\n        db.deleted_count == 1  # True.\n\n        # We also can delete all records with target key.\n        1 == db.del_key(key1)  # Return number of deleted records.\n        len(db) == 1  # True.\n        db.deleted_count == 2  # True.\n\n        # After set of add-del operations database can come to not optimized\n        # state. We can fix it in-place:\n        db.defragmentation()\n        db.deleted_count == 0  # True. All \"voids\" are optimized.\n        # Note: this is VERY heavy operation. Use it only at worst case.\n\n        # len(db) & db.deleted_count - are kind of estimations. If server is\n        # hung or shut down suddenly - these estimations may deviate from the\n        # actual values. In that case we can fix it by following way:\n        db.fix_statistis()\n        # Note: this is really SLOW operation. Use it as seldom as possible.\n\n        # You can create defragmented copy of database:\n        db.copy('/path/to/db-copy', read_count=100)\n        # Read count - read_count parameter passed to constructor of created\n        # database. Note: this is VERY heavy operation!\n\n        # And finally, you can copy database content to another storage:\n        class ExtendedStorage(Storage):\n            max_records = 2000\n        with ExtendedStorage('/path/to/extended-db-copy') as edb:\n            db.copy_to_storage(edb)\n            len(db) == len(edb)  # True.\n            set(db.items()) == set(edb.items())  # True.\n\n    # Congratulations! Now you know everything about filedict.BaseStorage. But\n    # there is one more component: filedict.BaseShardedStorage:\n    class Storage(filedict.BaseShardedStorage):\n        # It has some familiar parameters:\n        max_records = 1000\n        key_types = ctypes.c_uint64,\n        val_types = ctypes.c_uint32, ctypes.c_uint32\n\n        # And some new parameters:\n\n        shard_name_width = 5\n        # Length of shards names. In case of 3, shard names will be: 00000,\n        # 00001, 00002, .. etc. Default value is good for most of cases.\n\n        max_shard_fulness = 0.9\n        # Maximum allowed fulness of each shard subdatabase. Default value is\n        # good for most of cases.\n\n        # It's worth noting that sharded storage has no limitation for maximum\n        # number of records in database. Value of max_records - is just a\n        # limitation for single shard. And there is no limits for shards count.\n        # But this feature leads to changes in performance balance. First,\n        # ALL reads are slowed SHARDS_COUNT times (both SATA & SSD). Second,\n        # writes on SATA are not slowed if use max_records =\n        # (RAM_SIZE - RAM_SIZE_USED_BY_OS) / (1 + sizeof(key) + sizeof(val)).\n\n        # For example, we have SATA and 16Gb of RAM. And 4Gb are permanently\n        # used by OS and some applications. In this case, recommended\n        # value for max_records is:\n        # (16 - 4)*1024*1024*1024 / (1 + 8 + (4 + 4)) ~ 750,000,000\n        # So, set max_records to 750000000 and obtain fast writes!\n\n        # If you have SSD - just use BaseStorage!\n\n    # Now let's consider possible exceptions.\n    try:\n        # create database object, open it and perform some operations.\n    except filedict.WrongFileSizeError:\n        # Will be raised if change max_records for existing database.\n    except filedict.UnableToSeekError:\n        # Will be raised if try to seek to position that is greater than file\n        # size.\n    except filedict.UnableToReadError:\n        # Will be raised if can not read from database file.\n    except filedict.UnableToWriteError:\n        # Will be raised if can not write to database file.\n    except filedict.UnableToWriteRawError:\n        # Will be raised if can not write raw data to database file.\n    except filedict.RequiredAttrNotExistsError:\n        # Will be raised if some of required params are not specified (for\n        # example max_records).\n    except filedict.WriteInReadOnlyModeError:\n        # Will be raised if try to perform write operation for read-only opened\n        # database.\n    except filedict.StorageIsFullError:\n        # Will be raised if try to add item in full database.\n    except filedict.CopyAlreadyExistsError:\n        # Will be raised if try to copy database to path that already exists.\n    except filedict.NotOpenedError:\n        # Will be raised if try to perform some operation on database that was\n        # not opened.\n\n    # Note:\n    # StorageFileError - is base class for WrongFileSizeError,\n    # UnableToSeekError, UnableToReadError, UnableToWriteError,\n    # UnableToWriteRawError.\n    # BaseStorageError - base class for RequiredAttrNotExistsError,\n    # WriteInReadOnlyModeError, StorageIsFullError, CopyAlreadyExistsError,\n    # NotOpenedError\n\n\nFeatures\n--------\n\n - Simple in-file hash table.\n - Can store billions of records providing really fast access.\n - Use disk space effectively.\n - Use a little bit RAM.\n - Support both add & del operations.\n - Support defragmentation, copy operation.\n - No limits to readers number.\n - Support multiple values for single key.\n - Get value for given key only in 1 seek + 1 read (in best case, if keys are quite unique).\n - Supports local sharding.\n\n\nLimitations\n-----------\n\n - Only python2, only linux for now.\n - Max number of records is constant for any database. So it can be choosen only once.\n - Supports only fixed data schema.\n - Can store only integers & floats.\n - Very slow in case of huge amount of duplicate keys.\n - Only one writer allowed.\n - No transactions, no ACID support.\n - If your data can be placed in RAM, use Redis/Memcache instead!\n - Not distributed.\n\n\nTests\n-----\n\nVery simple, just run:\n::\n\n    $ git clone https://bitbucket.org/dkuryakin/filedict.git\n    $ cd filedict && python setup.py test\n\n\nor\n\n::\n\n    $ python -mfiledict.test\n\n\nChangelog\n---------\n\nhttps://bitbucket.org/dkuryakin/filedict/raw/master/CHANGES.txt\n\n\nLicense\n-------\n\n::\n\n    This is free and unencumbered software released into the public domain.\n\n    Anyone is free to copy, modify, publish, use, compile, sell, or\n    distribute this software, either in source code form or as a compiled\n    binary, for any purpose, commercial or non-commercial, and by any\n    means.\n\n    In jurisdictions that recognize copyright laws, the author or authors\n    of this software dedicate any and all copyright interest in the\n    software to the public domain. We make this dedication for the benefit\n    of the public at large and to the detriment of our heirs and\n    successors. We intend this dedication to be an overt act of\n    relinquishment in perpetuity of all present and future rights to this\n    software under copyright law.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n    IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n    OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\n    ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n    OTHER DEALINGS IN THE SOFTWARE.\n\n    For more information, please refer to <http://unlicense.org/>", "description_content_type": null, "docs_url": null, "download_url": "https://bitbucket.org/dkuryakin/filedict/get/master.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://bitbucket.org/dkuryakin/filedict", "keywords": "storage,hash table,key value,database", "license": "unlicense", "maintainer": null, "maintainer_email": null, "name": "filedict", "package_url": "https://pypi.org/project/filedict/", "platform": "any", "project_url": "https://pypi.org/project/filedict/", "project_urls": {"Download": "https://bitbucket.org/dkuryakin/filedict/get/master.tar.gz", "Homepage": "https://bitbucket.org/dkuryakin/filedict"}, "release_url": "https://pypi.org/project/filedict/0.0.8/", "requires_dist": null, "requires_python": null, "summary": "Fast & simple key-value storage.", "version": "0.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"purposes\">\n<h2>Purposes</h2>\n<p>There are a lot of great in-memory key-value storages like Redis/Memcache. But\nall of them are limited by RAM. Imagine you want to store 100,000,000,000 of\nkey-value pairs and have quite fast random-access to items by key. Filedict\nwas designed exactly for this case.</p>\n</div>\n<div id=\"install\">\n<h2>Install</h2>\n<pre>$ git clone https://bitbucket.org/dkuryakin/filedict.git\n$ cd filedict &amp;&amp; python setup.py install\n</pre>\n<p>or</p>\n<pre>$ pip install filedict\n</pre>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>I believe that the best documentation - is a comprehensive and in-place\ncommented set of examples. So here they are:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">ctypes</span>\n<span class=\"kn\">import</span> <span class=\"nn\">filedict</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">Storage</span><span class=\"p\">(</span><span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">BaseStorage</span><span class=\"p\">):</span>\n    <span class=\"c1\"># This is simple in-file storage based on hash table.</span>\n\n    <span class=\"n\">max_records</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n    <span class=\"c1\"># You can not save more than 1000 values in this database! This limit</span>\n    <span class=\"c1\"># can not be changed in the future. It is necessary to initially</span>\n    <span class=\"c1\"># correctly estimate the maximum number of entries in the database.</span>\n    <span class=\"c1\"># In the worst case it is necessary to copy this database to the new</span>\n    <span class=\"c1\"># larger database element by element.</span>\n\n    <span class=\"n\">key_types</span> <span class=\"o\">=</span> <span class=\"n\">ctypes</span><span class=\"o\">.</span><span class=\"n\">c_uint64</span><span class=\"p\">,</span>\n    <span class=\"n\">val_types</span> <span class=\"o\">=</span> <span class=\"n\">ctypes</span><span class=\"o\">.</span><span class=\"n\">c_uint32</span><span class=\"p\">,</span> <span class=\"n\">ctypes</span><span class=\"o\">.</span><span class=\"n\">c_uint32</span>\n    <span class=\"c1\"># Specify key &amp; value binary representation. Each record in database</span>\n    <span class=\"c1\"># file has size = 1 + sizeof(key) + sizeof(val). In current case it's</span>\n    <span class=\"c1\"># 1 + 8 + (4 + 4) = 17 bytes. So resulting database file has size</span>\n    <span class=\"c1\"># 1000 * 17 = 17000 bytes. You can check this fact yourself. Note:</span>\n    <span class=\"c1\"># key-value types are fixed, and can't be changed in future!</span>\n\n\n<span class=\"c1\"># Use simple try-finally form:</span>\n<span class=\"n\">db</span> <span class=\"o\">=</span> <span class=\"n\">Storage</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/db'</span><span class=\"p\">,</span> <span class=\"n\">read_only</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">read_count</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n<span class=\"c1\"># There are 3 parameters when create instance of Storage: path, read_only</span>\n<span class=\"c1\"># and read_count. Path - path to database dir. Only one writer per database</span>\n<span class=\"c1\"># is allowed, so use read_only=True if you don't need any writes. Read</span>\n<span class=\"c1\"># count specify read block size for all operations which involve a lot of</span>\n<span class=\"c1\"># sequential reads. Default value for read_count is quite good for most of</span>\n<span class=\"c1\"># cases.</span>\n<span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">record_size</span> <span class=\"o\">==</span> <span class=\"mi\">1</span> <span class=\"o\">+</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"p\">(</span><span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"mi\">4</span><span class=\"p\">)</span>  <span class=\"c1\"># True.</span>\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">()</span>\n    <span class=\"c1\"># do something with db</span>\n<span class=\"k\">finally</span><span class=\"p\">:</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n\n\n<span class=\"c1\"># Or use context-manager form:</span>\n<span class=\"k\">with</span> <span class=\"n\">Storage</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/db'</span><span class=\"p\">,</span> <span class=\"n\">read_only</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">read_count</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">db</span><span class=\"p\">:</span>\n    <span class=\"c1\"># You can add key-value pair to database. Return None. Duplicate keys</span>\n    <span class=\"c1\"># allowed. Duplicate key-value pairs allowed too.</span>\n    <span class=\"n\">key1</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"n\">key2</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">val1</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span>\n    <span class=\"n\">val2</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span>\n    <span class=\"n\">val3</span> <span class=\"o\">=</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">key1</span><span class=\"p\">,</span> <span class=\"n\">val1</span><span class=\"p\">)</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">key1</span><span class=\"p\">,</span> <span class=\"n\">val2</span><span class=\"p\">)</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">key2</span><span class=\"p\">,</span> <span class=\"n\">val3</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Note: this type of storage is rapidly becoming ineffective in the</span>\n    <span class=\"c1\"># case of a large number of records with the same key. So it is</span>\n    <span class=\"c1\"># recommended to take care of a high degree of uniqueness at the</span>\n    <span class=\"c1\"># application level. Besides the performance starts to drop</span>\n    <span class=\"c1\"># dramatically when free space ends in the database. It is recommended</span>\n    <span class=\"c1\"># to set value of max_records 10-15% more than the actual maximum</span>\n    <span class=\"c1\"># size of the database. Also writes slow down on SATA disks for huge</span>\n    <span class=\"c1\"># databases. If you want to store huge amount of data and you don't</span>\n    <span class=\"c1\"># have SSD disk - try to use BaseShardedStorage instead (see below).</span>\n\n    <span class=\"c1\"># You can iterate over different values for target key.</span>\n    <span class=\"n\">it</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">(</span><span class=\"n\">key1</span><span class=\"p\">)</span>  <span class=\"c1\"># Return generator.</span>\n    <span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"nb\">set</span><span class=\"p\">([</span><span class=\"n\">val1</span><span class=\"p\">,</span> <span class=\"n\">val2</span><span class=\"p\">])</span>  <span class=\"c1\"># Sets are equal, but iteration order is</span>\n                                  <span class=\"c1\"># not defined!</span>\n\n    <span class=\"c1\"># You can iterate over all key-value pairs in database. Note: order is</span>\n    <span class=\"c1\"># not defined!</span>\n    <span class=\"n\">it</span> <span class=\"o\">=</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>  <span class=\"c1\"># Returns generator.</span>\n    <span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"nb\">set</span><span class=\"p\">([(</span><span class=\"n\">key1</span><span class=\"p\">,</span> <span class=\"n\">val1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">key1</span><span class=\"p\">,</span> <span class=\"n\">val2</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">key2</span><span class=\"p\">,</span> <span class=\"n\">val3</span><span class=\"p\">)])</span>\n\n    <span class=\"c1\"># You can get estimation for database size. Note: this estimation is</span>\n    <span class=\"c1\"># precise for writer. It can be outdated for readers in case of active</span>\n    <span class=\"c1\"># writer. But if there is no active writer, estimation will be precise</span>\n    <span class=\"c1\"># for readers too.</span>\n    <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">3</span>  <span class=\"c1\"># That's True.</span>\n\n    <span class=\"c1\"># It's possible to delete all mentions of key-value pair from database.</span>\n    <span class=\"mi\">1</span> <span class=\"o\">==</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">del_value</span><span class=\"p\">(</span><span class=\"n\">key1</span><span class=\"p\">,</span> <span class=\"n\">val1</span><span class=\"p\">)</span>  <span class=\"c1\"># Return number of deleted records.</span>\n    <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">2</span>  <span class=\"c1\"># True.</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">deleted_count</span> <span class=\"o\">==</span> <span class=\"mi\">1</span>  <span class=\"c1\"># True.</span>\n\n    <span class=\"c1\"># We also can delete all records with target key.</span>\n    <span class=\"mi\">1</span> <span class=\"o\">==</span> <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">del_key</span><span class=\"p\">(</span><span class=\"n\">key1</span><span class=\"p\">)</span>  <span class=\"c1\"># Return number of deleted records.</span>\n    <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"mi\">1</span>  <span class=\"c1\"># True.</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">deleted_count</span> <span class=\"o\">==</span> <span class=\"mi\">2</span>  <span class=\"c1\"># True.</span>\n\n    <span class=\"c1\"># After set of add-del operations database can come to not optimized</span>\n    <span class=\"c1\"># state. We can fix it in-place:</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">defragmentation</span><span class=\"p\">()</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">deleted_count</span> <span class=\"o\">==</span> <span class=\"mi\">0</span>  <span class=\"c1\"># True. All \"voids\" are optimized.</span>\n    <span class=\"c1\"># Note: this is VERY heavy operation. Use it only at worst case.</span>\n\n    <span class=\"c1\"># len(db) &amp; db.deleted_count - are kind of estimations. If server is</span>\n    <span class=\"c1\"># hung or shut down suddenly - these estimations may deviate from the</span>\n    <span class=\"c1\"># actual values. In that case we can fix it by following way:</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">fix_statistis</span><span class=\"p\">()</span>\n    <span class=\"c1\"># Note: this is really SLOW operation. Use it as seldom as possible.</span>\n\n    <span class=\"c1\"># You can create defragmented copy of database:</span>\n    <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/db-copy'</span><span class=\"p\">,</span> <span class=\"n\">read_count</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Read count - read_count parameter passed to constructor of created</span>\n    <span class=\"c1\"># database. Note: this is VERY heavy operation!</span>\n\n    <span class=\"c1\"># And finally, you can copy database content to another storage:</span>\n    <span class=\"k\">class</span> <span class=\"nc\">ExtendedStorage</span><span class=\"p\">(</span><span class=\"n\">Storage</span><span class=\"p\">):</span>\n        <span class=\"n\">max_records</span> <span class=\"o\">=</span> <span class=\"mi\">2000</span>\n    <span class=\"k\">with</span> <span class=\"n\">ExtendedStorage</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/extended-db-copy'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">edb</span><span class=\"p\">:</span>\n        <span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">copy_to_storage</span><span class=\"p\">(</span><span class=\"n\">edb</span><span class=\"p\">)</span>\n        <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">edb</span><span class=\"p\">)</span>  <span class=\"c1\"># True.</span>\n        <span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">db</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">())</span> <span class=\"o\">==</span> <span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">edb</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">())</span>  <span class=\"c1\"># True.</span>\n\n<span class=\"c1\"># Congratulations! Now you know everything about filedict.BaseStorage. But</span>\n<span class=\"c1\"># there is one more component: filedict.BaseShardedStorage:</span>\n<span class=\"k\">class</span> <span class=\"nc\">Storage</span><span class=\"p\">(</span><span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">BaseShardedStorage</span><span class=\"p\">):</span>\n    <span class=\"c1\"># It has some familiar parameters:</span>\n    <span class=\"n\">max_records</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n    <span class=\"n\">key_types</span> <span class=\"o\">=</span> <span class=\"n\">ctypes</span><span class=\"o\">.</span><span class=\"n\">c_uint64</span><span class=\"p\">,</span>\n    <span class=\"n\">val_types</span> <span class=\"o\">=</span> <span class=\"n\">ctypes</span><span class=\"o\">.</span><span class=\"n\">c_uint32</span><span class=\"p\">,</span> <span class=\"n\">ctypes</span><span class=\"o\">.</span><span class=\"n\">c_uint32</span>\n\n    <span class=\"c1\"># And some new parameters:</span>\n\n    <span class=\"n\">shard_name_width</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n    <span class=\"c1\"># Length of shards names. In case of 3, shard names will be: 00000,</span>\n    <span class=\"c1\"># 00001, 00002, .. etc. Default value is good for most of cases.</span>\n\n    <span class=\"n\">max_shard_fulness</span> <span class=\"o\">=</span> <span class=\"mf\">0.9</span>\n    <span class=\"c1\"># Maximum allowed fulness of each shard subdatabase. Default value is</span>\n    <span class=\"c1\"># good for most of cases.</span>\n\n    <span class=\"c1\"># It's worth noting that sharded storage has no limitation for maximum</span>\n    <span class=\"c1\"># number of records in database. Value of max_records - is just a</span>\n    <span class=\"c1\"># limitation for single shard. And there is no limits for shards count.</span>\n    <span class=\"c1\"># But this feature leads to changes in performance balance. First,</span>\n    <span class=\"c1\"># ALL reads are slowed SHARDS_COUNT times (both SATA &amp; SSD). Second,</span>\n    <span class=\"c1\"># writes on SATA are not slowed if use max_records =</span>\n    <span class=\"c1\"># (RAM_SIZE - RAM_SIZE_USED_BY_OS) / (1 + sizeof(key) + sizeof(val)).</span>\n\n    <span class=\"c1\"># For example, we have SATA and 16Gb of RAM. And 4Gb are permanently</span>\n    <span class=\"c1\"># used by OS and some applications. In this case, recommended</span>\n    <span class=\"c1\"># value for max_records is:</span>\n    <span class=\"c1\"># (16 - 4)*1024*1024*1024 / (1 + 8 + (4 + 4)) ~ 750,000,000</span>\n    <span class=\"c1\"># So, set max_records to 750000000 and obtain fast writes!</span>\n\n    <span class=\"c1\"># If you have SSD - just use BaseStorage!</span>\n\n<span class=\"c1\"># Now let's consider possible exceptions.</span>\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"c1\"># create database object, open it and perform some operations.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">WrongFileSizeError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if change max_records for existing database.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">UnableToSeekError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if try to seek to position that is greater than file</span>\n    <span class=\"c1\"># size.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">UnableToReadError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if can not read from database file.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">UnableToWriteError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if can not write to database file.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">UnableToWriteRawError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if can not write raw data to database file.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">RequiredAttrNotExistsError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if some of required params are not specified (for</span>\n    <span class=\"c1\"># example max_records).</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">WriteInReadOnlyModeError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if try to perform write operation for read-only opened</span>\n    <span class=\"c1\"># database.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">StorageIsFullError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if try to add item in full database.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">CopyAlreadyExistsError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if try to copy database to path that already exists.</span>\n<span class=\"k\">except</span> <span class=\"n\">filedict</span><span class=\"o\">.</span><span class=\"n\">NotOpenedError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Will be raised if try to perform some operation on database that was</span>\n    <span class=\"c1\"># not opened.</span>\n\n<span class=\"c1\"># Note:</span>\n<span class=\"c1\"># StorageFileError - is base class for WrongFileSizeError,</span>\n<span class=\"c1\"># UnableToSeekError, UnableToReadError, UnableToWriteError,</span>\n<span class=\"c1\"># UnableToWriteRawError.</span>\n<span class=\"c1\"># BaseStorageError - base class for RequiredAttrNotExistsError,</span>\n<span class=\"c1\"># WriteInReadOnlyModeError, StorageIsFullError, CopyAlreadyExistsError,</span>\n<span class=\"c1\"># NotOpenedError</span>\n</pre>\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<blockquote>\n<ul>\n<li>Simple in-file hash table.</li>\n<li>Can store billions of records providing really fast access.</li>\n<li>Use disk space effectively.</li>\n<li>Use a little bit RAM.</li>\n<li>Support both add &amp; del operations.</li>\n<li>Support defragmentation, copy operation.</li>\n<li>No limits to readers number.</li>\n<li>Support multiple values for single key.</li>\n<li>Get value for given key only in 1 seek + 1 read (in best case, if keys are quite unique).</li>\n<li>Supports local sharding.</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"limitations\">\n<h2>Limitations</h2>\n<blockquote>\n<ul>\n<li>Only python2, only linux for now.</li>\n<li>Max number of records is constant for any database. So it can be choosen only once.</li>\n<li>Supports only fixed data schema.</li>\n<li>Can store only integers &amp; floats.</li>\n<li>Very slow in case of huge amount of duplicate keys.</li>\n<li>Only one writer allowed.</li>\n<li>No transactions, no ACID support.</li>\n<li>If your data can be placed in RAM, use Redis/Memcache instead!</li>\n<li>Not distributed.</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"tests\">\n<h2>Tests</h2>\n<p>Very simple, just run:</p>\n<pre>$ git clone https://bitbucket.org/dkuryakin/filedict.git\n$ cd filedict &amp;&amp; python setup.py test\n</pre>\n<p>or</p>\n<pre>$ python -mfiledict.test\n</pre>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<p><a href=\"https://bitbucket.org/dkuryakin/filedict/raw/master/CHANGES.txt\" rel=\"nofollow\">https://bitbucket.org/dkuryakin/filedict/raw/master/CHANGES.txt</a></p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<pre>This is free and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any\nmeans.\n\nIn jurisdictions that recognize copyright laws, the author or authors\nof this software dedicate any and all copyright interest in the\nsoftware to the public domain. We make this dedication for the benefit\nof the public at large and to the detriment of our heirs and\nsuccessors. We intend this dedication to be an overt act of\nrelinquishment in perpetuity of all present and future rights to this\nsoftware under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to &lt;http://unlicense.org/&gt;\n</pre>\n</div>\n\n          </div>"}, "last_serial": 2541508, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "a7ef543f538b58c6881e72154828b78f", "sha256": "bbdadb647825425e8e9c2baf1e151e1ca7d60a743f5b7e8eb8d39c543056edf7"}, "downloads": -1, "filename": "filedict-0.0.1.tar.gz", "has_sig": false, "md5_digest": "a7ef543f538b58c6881e72154828b78f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11198, "upload_time": "2016-12-15T21:50:33", "upload_time_iso_8601": "2016-12-15T21:50:33.857938Z", "url": "https://files.pythonhosted.org/packages/3c/e6/b51ac734a38bbb01cc3fd629676951d681edc5b9476c4714ba17f6866327/filedict-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "506b96a50c5f0c2c04bfe2902f6db30a", "sha256": "a2b7d59f50cf052b8137b16ca3209c85818f734e330c4d4e58df77c27491abbb"}, "downloads": -1, "filename": "filedict-0.0.2.tar.gz", "has_sig": false, "md5_digest": "506b96a50c5f0c2c04bfe2902f6db30a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11178, "upload_time": "2016-12-16T13:55:54", "upload_time_iso_8601": "2016-12-16T13:55:54.725659Z", "url": "https://files.pythonhosted.org/packages/50/17/b789c45f152c4338ba7d5a7c715d1659c3dfedc7da0cbdc77cdfb397e4fa/filedict-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "fcf34d32285d07ec055e9abf92eb947b", "sha256": "ce4d4cfbee1a16fe34dc7ca35f46760921a204091f6ba34af2ab84220abbecc7"}, "downloads": -1, "filename": "filedict-0.0.3.tar.gz", "has_sig": false, "md5_digest": "fcf34d32285d07ec055e9abf92eb947b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12344, "upload_time": "2016-12-16T14:09:03", "upload_time_iso_8601": "2016-12-16T14:09:03.312641Z", "url": "https://files.pythonhosted.org/packages/9c/38/119011cdc1a78deec6e975ebc7dd5b610a7138b37e534fd301aed43b19c1/filedict-0.0.3.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "8745065fb0d001d7a10ab2c6d00acdf9", "sha256": "a009282015232d4ea76b7f354459d7e6e97e3ae3eb1fc9f3552a32d61564f5fe"}, "downloads": -1, "filename": "filedict-0.0.6.tar.gz", "has_sig": false, "md5_digest": "8745065fb0d001d7a10ab2c6d00acdf9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14247, "upload_time": "2016-12-19T09:49:40", "upload_time_iso_8601": "2016-12-19T09:49:40.736381Z", "url": "https://files.pythonhosted.org/packages/63/ed/db146092467fc192d0afeb216d52e9e14bf68aa52809e193ee0fa63ed840/filedict-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "e15d9e689bfb027673b467e385b2388d", "sha256": "4926da010e24c01bc888b88a8095ecb1580176b4365f3c07f4ea9af6efd2cbdf"}, "downloads": -1, "filename": "filedict-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e15d9e689bfb027673b467e385b2388d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14309, "upload_time": "2016-12-20T02:44:53", "upload_time_iso_8601": "2016-12-20T02:44:53.291960Z", "url": "https://files.pythonhosted.org/packages/aa/09/23576631c4ad58f605e1c058f8e8ba82ad2b673d3a5fff644156377b8c7f/filedict-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "898cc5f7955238dbe56b168232c66375", "sha256": "a4288843eabb3da1ffebeaea050884f93e70854bc1657a90795bb92e2d7aefd2"}, "downloads": -1, "filename": "filedict-0.0.8.tar.gz", "has_sig": false, "md5_digest": "898cc5f7955238dbe56b168232c66375", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14363, "upload_time": "2016-12-27T22:33:27", "upload_time_iso_8601": "2016-12-27T22:33:27.265754Z", "url": "https://files.pythonhosted.org/packages/8c/5b/fad3ea1d8a967e0126e260fe5e15af87acf9549e9037e47dda5a351769b9/filedict-0.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "898cc5f7955238dbe56b168232c66375", "sha256": "a4288843eabb3da1ffebeaea050884f93e70854bc1657a90795bb92e2d7aefd2"}, "downloads": -1, "filename": "filedict-0.0.8.tar.gz", "has_sig": false, "md5_digest": "898cc5f7955238dbe56b168232c66375", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14363, "upload_time": "2016-12-27T22:33:27", "upload_time_iso_8601": "2016-12-27T22:33:27.265754Z", "url": "https://files.pythonhosted.org/packages/8c/5b/fad3ea1d8a967e0126e260fe5e15af87acf9549e9037e47dda5a351769b9/filedict-0.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:36 2020"}