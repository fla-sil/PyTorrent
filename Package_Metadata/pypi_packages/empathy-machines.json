{"info": {"author": "Preston Parry", "author_email": "ClimbsBytes@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# empathyMachines\n> A standalone NLP sentiment classifier you can import as a module\n\n## Purposes\n\n1. Offer a batteries-included NLP classifier you can use either on it's own, or to make sentiment predictions as part of a broder NLP project (for example, when classifying customer messages, whether the customer is angry or not might help you determine if this is a compensation request, or a request to adjust their address.)\n1. Have the entire sentiment prediction process scaffolded so you can feed in your own training corpus, and easily train an NLP sentiment classifier.\n\n## How to use\n\n1. Download the repo from GitHub (pip install coming later)\n1. `cd` into repo, and `pip install -r requirements.txt`\n1. In your Python code, `from EmpathyMachines import EmpathyMachines`\n1. `nlp_classifier = EmpathyMachines()`\n1. `nlp_classifier.train(corpus='Twitter')`\n1. `nlp_classifier.predict(text_string)`\n\n\n### Corpora included\n\n\n### Include your own corpus (UNDER CONSTRUCTION)\n\nFeel free to train a classifier on your own corpus!\n\nTwo ways to do this:\n1. Read in a .csv file with header row containing \"sentiment\", \"text\", and optionally, \"confidence\"\n1. Pass in an array of Python dictionaries, with attributes for \"sentiment\", \"text\", and optionally, \"confidence\"\n\n\n1. Create a .csv file with the following fields\n1. `nlp_classifier.train(corpus='custom', corpus_path='path/to/custom/corpus.csv', analytics_output=False)`", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ClimbsRocks/EmpathyMachines", "keywords": "machine learning,data science,NLP,natural language processing,sentiment,sentiment analysis,sentiment prediction,twitter corpus,twitter,tweets corpus,movie reviews corpus,NLTK,automated machine learning", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "empathy-machines", "package_url": "https://pypi.org/project/empathy-machines/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/empathy-machines/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/ClimbsRocks/EmpathyMachines"}, "release_url": "https://pypi.org/project/empathy-machines/0.5.1/", "requires_dist": null, "requires_python": null, "summary": "An off-the-rack NLP sentiment classifier- upload your own corpus or use the pre-installed ones", "version": "0.5.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p># empathyMachines\n&gt; A standalone NLP sentiment classifier you can import as a module</p>\n<p>## Purposes</p>\n<p>1. Offer a batteries-included NLP classifier you can use either on it\u2019s own, or to make sentiment predictions as part of a broder NLP project (for example, when classifying customer messages, whether the customer is angry or not might help you determine if this is a compensation request, or a request to adjust their address.)\n1. Have the entire sentiment prediction process scaffolded so you can feed in your own training corpus, and easily train an NLP sentiment classifier.</p>\n<p>## How to use</p>\n<p>1. Download the repo from GitHub (pip install coming later)\n1. <cite>cd</cite> into repo, and <cite>pip install -r requirements.txt</cite>\n1. In your Python code, <cite>from EmpathyMachines import EmpathyMachines</cite>\n1. <cite>nlp_classifier = EmpathyMachines()</cite>\n1. <cite>nlp_classifier.train(corpus=\u2019Twitter\u2019)</cite>\n1. <cite>nlp_classifier.predict(text_string)</cite></p>\n<p>### Corpora included</p>\n<p>### Include your own corpus (UNDER CONSTRUCTION)</p>\n<p>Feel free to train a classifier on your own corpus!</p>\n<p>Two ways to do this:\n1. Read in a .csv file with header row containing \u201csentiment\u201d, \u201ctext\u201d, and optionally, \u201cconfidence\u201d\n1. Pass in an array of Python dictionaries, with attributes for \u201csentiment\u201d, \u201ctext\u201d, and optionally, \u201cconfidence\u201d</p>\n<p>1. Create a .csv file with the following fields\n1. <cite>nlp_classifier.train(corpus=\u2019custom\u2019, corpus_path=\u2019path/to/custom/corpus.csv\u2019, analytics_output=False)</cite></p>\n\n          </div>"}, "last_serial": 2263335, "releases": {"0.5.1": [{"comment_text": "", "digests": {"md5": "8823810c0f53d82881f971ce30027205", "sha256": "f426bae6401fa67386049ee46c569d1e5e860ddb72fb8c365a2aa91179ffde47"}, "downloads": -1, "filename": "empathy_machines-0.5.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8823810c0f53d82881f971ce30027205", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 3806, "upload_time": "2016-08-05T02:29:23", "upload_time_iso_8601": "2016-08-05T02:29:23.813118Z", "url": "https://files.pythonhosted.org/packages/c1/a9/a8892e76b3ed49b1aba724ec7b34d8d81552060f97342ee20365e448978f/empathy_machines-0.5.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "72ab5787f6cac9b9d35028a1f9038749", "sha256": "0533dd6faf43c1e4cc780e099f7f74cd76b61128e27889f8b0a52b0c0922a341"}, "downloads": -1, "filename": "empathy-machines-0.5.1.tar.gz", "has_sig": false, "md5_digest": "72ab5787f6cac9b9d35028a1f9038749", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3445385, "upload_time": "2016-08-05T02:29:34", "upload_time_iso_8601": "2016-08-05T02:29:34.992176Z", "url": "https://files.pythonhosted.org/packages/5a/ef/561e2c746e4bf1979560e8031c571b92287fa5e73541b2d4632592f75134/empathy-machines-0.5.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8823810c0f53d82881f971ce30027205", "sha256": "f426bae6401fa67386049ee46c569d1e5e860ddb72fb8c365a2aa91179ffde47"}, "downloads": -1, "filename": "empathy_machines-0.5.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8823810c0f53d82881f971ce30027205", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 3806, "upload_time": "2016-08-05T02:29:23", "upload_time_iso_8601": "2016-08-05T02:29:23.813118Z", "url": "https://files.pythonhosted.org/packages/c1/a9/a8892e76b3ed49b1aba724ec7b34d8d81552060f97342ee20365e448978f/empathy_machines-0.5.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "72ab5787f6cac9b9d35028a1f9038749", "sha256": "0533dd6faf43c1e4cc780e099f7f74cd76b61128e27889f8b0a52b0c0922a341"}, "downloads": -1, "filename": "empathy-machines-0.5.1.tar.gz", "has_sig": false, "md5_digest": "72ab5787f6cac9b9d35028a1f9038749", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3445385, "upload_time": "2016-08-05T02:29:34", "upload_time_iso_8601": "2016-08-05T02:29:34.992176Z", "url": "https://files.pythonhosted.org/packages/5a/ef/561e2c746e4bf1979560e8031c571b92287fa5e73541b2d4632592f75134/empathy-machines-0.5.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:32 2020"}