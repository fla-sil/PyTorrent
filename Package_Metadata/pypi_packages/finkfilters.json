{"info": {"author": "JulienPeloton", "author_email": "peloton@lal.in2p3.fr", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Operating System :: Unix", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "[![pypi](https://img.shields.io/pypi/v/finkfilters.svg)](https://pypi.python.org/pypi/finkfilters)\n\n# Fink filters\n\nThis repository contains filters used to define which information will be sent to the community. \n\n## Step 0: Fork this repository\n\nFork and clone the repository, and create a new folder at the root of the repo. The name of the new folder does not matter much, but try to make it meaningful as much as possible! Let's call it `filter_rrlyr` for the sake of this example.\n\n## Step 1: Define your filter\n\nA filter is typically a Python routine that selects which alerts need to be sent based on user-defined criteria. Criteria are based on the alert entries: position, flux, properties, ... You can find what's in alert here [link to be added]. \n\nIn this example, let's imagine you want to receive all alerts flagged as RRLyr by the xmatch module. You would create a file called `filter.py` and define a simple routine (see full template in the repo):\n\n```python\n@pandas_udf(BooleanType(), PandasUDFType.SCALAR) # <- mandatory\ndef rrlyr(cdsxmatch: Any) -> pd.Series:\n    \"\"\" Return alerts identified as RRLyr by the xmatch module.\n\n    Parameters\n    ----------\n    cdsxmatch: Spark DataFrame Column\n        Alert column containing the cross-match values\n\n    Returns\n    ----------\n    out: pandas.Series of bool\n        Return a Pandas DataFrame with the appropriate flag: \n        false for bad alert, and true for good alert.\n\n    \"\"\"\n    # Here goes your logic\n    mask = cdsxmatch.values == \"RRLyr\"\n\n    return pd.Series(mask)\n```\n\nRemarks:\n\n- Note the use of the decorator is mandatory. It is a decorator for Apache Spark, and it specifies the output type as well as the type of operation. Just copy and paste it for simplicity.\n- The name of the routine will be used as the name of the Kafka topic. So once the filter loaded, you would subscribe to the topic `rrlyr` to receive alerts from this filter. Hence choose a meaningful name!\n- The name of the input argument must match the name of an alert entry. Here `cdsxmatch` is one column added by the xmatch module.\n- You can have several input columns. Just add them one after the other:\n\n\n```python\n@pandas_udf(BooleanType(), PandasUDFType.SCALAR) # <- mandatory\ndef filter_w_several_input(acol: Any, anothercol: Any) -> pd.Series:\n    \"\"\" Documentation \"\"\"\n    pass\n```\n\n## Step 3: Open a pull request\n\nOnce your filter is done, we will review it. The criteria for acceptance are:\n\n- The filter works ;-)\n- The volume of data to be transfered is tractable on our side. Keep in mind, LSST incoming stream is 10 million alerts per night, or ~1TB/night. Hence your filter must focus on a specific aspect of the stream, to reduce the outgoing volume of alerts. Based on your submission, we will provide estimate of the volume to be transfered.\n\n## Step 4: Play!\n\nIf your filter is accepted, it will be plugged in the broker, and you will be able to receive your alerts in real-time using the [finkclient](https://github.com/astrolabsoftware/fink-client). Note that we do not keep alerts forever available in the broker. While the retention period is not yet defined, you can expect emitted alerts to be available no longer than one week.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://fink-broker.readthedocs.io/en/latest/", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "finkfilters", "package_url": "https://pypi.org/project/finkfilters/", "platform": "", "project_url": "https://pypi.org/project/finkfilters/", "project_urls": {"Documentation": "https://fink-broker.readthedocs.io/en/latest/", "Homepage": "https://fink-broker.readthedocs.io/en/latest/", "Source": "https://github.com/astrolabsoftware/finkfilters"}, "release_url": "https://pypi.org/project/finkfilters/0.1.4/", "requires_dist": null, "requires_python": "", "summary": "User-defined filters for the Fink broker.", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://pypi.python.org/pypi/finkfilters\" rel=\"nofollow\"><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/07bda3373f63e3f7e4ca9a5fadc09aa3f276fdbb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f66696e6b66696c746572732e737667\"></a></p>\n<h1>Fink filters</h1>\n<p>This repository contains filters used to define which information will be sent to the community.</p>\n<h2>Step 0: Fork this repository</h2>\n<p>Fork and clone the repository, and create a new folder at the root of the repo. The name of the new folder does not matter much, but try to make it meaningful as much as possible! Let's call it <code>filter_rrlyr</code> for the sake of this example.</p>\n<h2>Step 1: Define your filter</h2>\n<p>A filter is typically a Python routine that selects which alerts need to be sent based on user-defined criteria. Criteria are based on the alert entries: position, flux, properties, ... You can find what's in alert here [link to be added].</p>\n<p>In this example, let's imagine you want to receive all alerts flagged as RRLyr by the xmatch module. You would create a file called <code>filter.py</code> and define a simple routine (see full template in the repo):</p>\n<pre><span class=\"nd\">@pandas_udf</span><span class=\"p\">(</span><span class=\"n\">BooleanType</span><span class=\"p\">(),</span> <span class=\"n\">PandasUDFType</span><span class=\"o\">.</span><span class=\"n\">SCALAR</span><span class=\"p\">)</span> <span class=\"c1\"># &lt;- mandatory</span>\n<span class=\"k\">def</span> <span class=\"nf\">rrlyr</span><span class=\"p\">(</span><span class=\"n\">cdsxmatch</span><span class=\"p\">:</span> <span class=\"n\">Any</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\" Return alerts identified as RRLyr by the xmatch module.</span>\n\n<span class=\"sd\">    Parameters</span>\n<span class=\"sd\">    ----------</span>\n<span class=\"sd\">    cdsxmatch: Spark DataFrame Column</span>\n<span class=\"sd\">        Alert column containing the cross-match values</span>\n\n<span class=\"sd\">    Returns</span>\n<span class=\"sd\">    ----------</span>\n<span class=\"sd\">    out: pandas.Series of bool</span>\n<span class=\"sd\">        Return a Pandas DataFrame with the appropriate flag: </span>\n<span class=\"sd\">        false for bad alert, and true for good alert.</span>\n\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"c1\"># Here goes your logic</span>\n    <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">cdsxmatch</span><span class=\"o\">.</span><span class=\"n\">values</span> <span class=\"o\">==</span> <span class=\"s2\">\"RRLyr\"</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">(</span><span class=\"n\">mask</span><span class=\"p\">)</span>\n</pre>\n<p>Remarks:</p>\n<ul>\n<li>Note the use of the decorator is mandatory. It is a decorator for Apache Spark, and it specifies the output type as well as the type of operation. Just copy and paste it for simplicity.</li>\n<li>The name of the routine will be used as the name of the Kafka topic. So once the filter loaded, you would subscribe to the topic <code>rrlyr</code> to receive alerts from this filter. Hence choose a meaningful name!</li>\n<li>The name of the input argument must match the name of an alert entry. Here <code>cdsxmatch</code> is one column added by the xmatch module.</li>\n<li>You can have several input columns. Just add them one after the other:</li>\n</ul>\n<pre><span class=\"nd\">@pandas_udf</span><span class=\"p\">(</span><span class=\"n\">BooleanType</span><span class=\"p\">(),</span> <span class=\"n\">PandasUDFType</span><span class=\"o\">.</span><span class=\"n\">SCALAR</span><span class=\"p\">)</span> <span class=\"c1\"># &lt;- mandatory</span>\n<span class=\"k\">def</span> <span class=\"nf\">filter_w_several_input</span><span class=\"p\">(</span><span class=\"n\">acol</span><span class=\"p\">:</span> <span class=\"n\">Any</span><span class=\"p\">,</span> <span class=\"n\">anothercol</span><span class=\"p\">:</span> <span class=\"n\">Any</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">Series</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\" Documentation \"\"\"</span>\n    <span class=\"k\">pass</span>\n</pre>\n<h2>Step 3: Open a pull request</h2>\n<p>Once your filter is done, we will review it. The criteria for acceptance are:</p>\n<ul>\n<li>The filter works ;-)</li>\n<li>The volume of data to be transfered is tractable on our side. Keep in mind, LSST incoming stream is 10 million alerts per night, or ~1TB/night. Hence your filter must focus on a specific aspect of the stream, to reduce the outgoing volume of alerts. Based on your submission, we will provide estimate of the volume to be transfered.</li>\n</ul>\n<h2>Step 4: Play!</h2>\n<p>If your filter is accepted, it will be plugged in the broker, and you will be able to receive your alerts in real-time using the <a href=\"https://github.com/astrolabsoftware/fink-client\" rel=\"nofollow\">finkclient</a>. Note that we do not keep alerts forever available in the broker. While the retention period is not yet defined, you can expect emitted alerts to be available no longer than one week.</p>\n\n          </div>"}, "last_serial": 6143450, "releases": {"0.1.3": [{"comment_text": "", "digests": {"md5": "c29b861c20af6e48594ea3f35b5d4b94", "sha256": "bf19aef4b4466e34e01f475b08bd4ce935e89b15259e235c1d0ce6a4b4309c09"}, "downloads": -1, "filename": "finkfilters-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "c29b861c20af6e48594ea3f35b5d4b94", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6877, "upload_time": "2019-11-15T14:29:40", "upload_time_iso_8601": "2019-11-15T14:29:40.018603Z", "url": "https://files.pythonhosted.org/packages/6b/ec/138720d8cf3a561f3f88e213fb590398a961a101499455ef0f6c63f86230/finkfilters-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bc4d2c7fc445d051f89153cedd232d77", "sha256": "0ab1c04c0f29bc7c3fffcfaf5e305d3ab113f2eeec1c0d93b996c92f3d856418"}, "downloads": -1, "filename": "finkfilters-0.1.3.tar.gz", "has_sig": false, "md5_digest": "bc4d2c7fc445d051f89153cedd232d77", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3140, "upload_time": "2019-11-15T14:29:42", "upload_time_iso_8601": "2019-11-15T14:29:42.314929Z", "url": "https://files.pythonhosted.org/packages/69/72/1c078299b23d85206d9944b375f774db178fe7806d87f1f4e8139fda03ff/finkfilters-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "f396a13da0fe4eef686da189298b2494", "sha256": "d0691a3f2ce4363827b44d93005b9e7acb48ac24941470607edd1889e2991137"}, "downloads": -1, "filename": "finkfilters-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "f396a13da0fe4eef686da189298b2494", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7920, "upload_time": "2019-11-15T14:40:23", "upload_time_iso_8601": "2019-11-15T14:40:23.668144Z", "url": "https://files.pythonhosted.org/packages/4a/83/3bdb0cdd7efa4d03c5e462383c8388aad8825bab1d1c8ebe0eaac1241975/finkfilters-0.1.4-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f396a13da0fe4eef686da189298b2494", "sha256": "d0691a3f2ce4363827b44d93005b9e7acb48ac24941470607edd1889e2991137"}, "downloads": -1, "filename": "finkfilters-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "f396a13da0fe4eef686da189298b2494", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7920, "upload_time": "2019-11-15T14:40:23", "upload_time_iso_8601": "2019-11-15T14:40:23.668144Z", "url": "https://files.pythonhosted.org/packages/4a/83/3bdb0cdd7efa4d03c5e462383c8388aad8825bab1d1c8ebe0eaac1241975/finkfilters-0.1.4-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:42:21 2020"}