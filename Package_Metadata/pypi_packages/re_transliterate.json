{"info": {"author": "Matthew Darling", "author_email": "matthewjdarling@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering"], "description": "\ufeffTransliteration is the conversion of text from one orthography to\r\nanother, or if you're a linguist, from a phonetic orthography to \r\ntranscription. I wrote this module to convert the orthography of an\r\nindigenuous Mexican language into IPA: their orthography was based\r\non Spanish, so there weren't any confusing irregularities like in\r\nEnglish.\r\n\r\nre_transliterate supports Unicode, though there might be corner cases\r\nfor particular languages. If that's the case, let me know, and I'll \r\nlook into using the regex module from PyPI rather than the built-in re\r\nmodule.\r\n\r\nUnlike the transliterate package on PyPI, re_transliterate allows for \r\nmapping between arbitrary strings: one (or more) letters can correspond\r\nto one (or more) letters. Since it's based on regular expressions, you\r\ncan also define language-specific character classes, like a set of\r\nvowels. This is extremely useful for handling diacritics and other\r\nsuprasegmental features.\r\n\r\nHow does it work?\r\n-----------------\r\n\r\nre_transliterate relies on Python dictionaries - mappings of x:y. These\r\nmappings should be written as regular expressions, which you may \r\nalready be familiar with. If not, find a computer science undergrad and\r\nmake them write your mappings :)\r\n\r\nIn simple cases, you can simply use normal strings (prefaced by 'u' for\r\nUnicode in Python 2):\r\n\r\n    >>> consonant_map = {u\"ch\":u\"\u010d\", u\"x\u2019\":u\"\u0161\u2019\"}\r\n    >>> word_replace(consonant_map, u\"ch\")\r\n    \u010d\r\n\r\nWith that mapping, occurrences of \"ch\" will be turned into '\u010d' and \r\nejectives written with 'x' will instead use '\u0161'.\r\n\r\nThe power of regular expressions\r\n--------------------------------\r\n\r\nIn more complicated cases, allowing regular expressions makes life\r\nmuch simpler. We can use character classes to reduce repetition, and \r\nuse backslashes to do fancy things. If your string contains a \r\nbackslash, preface it with 'r' as well as 'u'. An example of both:\r\n\r\n    >>> VOWELS = u\"([aeiou\u00e1\u00e9\u00ed\u00f3\u00fa])\"\r\n    >>> long_vowels = {VOWELS + u\":\":ur\"\\g<1>\u02d0\"}\r\n    >>> word_replace(long_vowels, u\"a:'\")\r\n    a\u02d0\r\n\r\nWith this mapping, vowels followed by a colon character (':') will be\r\nchanged to use the IPA symbol for length ('\u02d0'). Here, square brackets []\r\nindicate a \"character class\": these characters will be treated in the \r\nsame way, such that the string \"a:\" will be matched just like \"i:\" or \r\n\"\u00fa:\".\r\n\r\nThen, the parentheses () indicate a \"group\" in the regular expression:\r\nthis allows us to reference what it is that the pattern matched - \r\nthat's what the \\g<1> does, referring to \"group 1\". If the pattern were\r\nto match \"a:\", it would insert \"a\u02d0\". This is the primary benefit of\r\nusing regular expressions: we don't have to specify that \"a:\" turns\r\ninto \"a\u02d0\", and that \"e:\" turns into \"e\u02d0\", etc.\r\n\r\nComplicated mappings\r\n--------------------\r\n\r\nIn the previous example, did you see that I used addition inside the\r\nmapping? This allows useful patterns and special Unicode sequences to\r\nbe saved globally and reused elsewhere. In my own work, I defined the \r\nabove character class of vowels, and the Unicode sequence for the \"tilde\r\nbelow letter\" diacritic:\r\n\r\n    >>> LARYNGEAL = ur\"\\u0330\"\r\n\r\nThis allowed me to write mappings like this, where the ' character\r\nrepresents laryngealization and may occur before/after a marker for\r\nlength:\r\n\r\n    >>> long_laryngealized = {VOWELS + u\"(:'|':)\":\r\n                              ur\"\\g<1>\" + LARYNGEAL + u\"\u02d0\"}\r\n\r\nThis converts any vowel, followed by either (marked by '|') \":'\" or\r\n\"':\", into the vowel + laryngealization diacritic + length marker.\r\n\r\nApplying your mappings\r\n----------------------\r\n\r\nOnce you've created all your mappings, you can then either apply them\r\none at a time to a word (word_replace) or list of words\r\n(word_list_replace). As you develop your conversion code, you should\r\nuse these functions first, to make sure everything is working correctly.\r\n\r\nGenerally, you'll want to have multiple mappings, because some\r\nconversions will be sensitive to ordering. For my work, I created three\r\nmappings: trigraphs (sequences of three characters), bigraphs, and \r\nmonographs. I then applied each of those in order, using the two\r\ntransliterate functions. Example:\r\n\r\n    >>> re_trigraphs = {u\"lh\u2019\":u\"\u026c\u2019\",\r\n                        VOWELS + u\":'|':\":ur\"\\g<1>\" + LARYNGEAL + u\"\u02d0\"}\r\n    >>> re_bigraphs = {u\"ch\":u\"\u010d\", u\"lh\":u\"\u026c\", u\"nh\":u\"\u014b\u0294\",\r\n                       u\"tz\":u\"c\", u\"uj\":u\"\u028d\",\r\n                       u\"s\u2019\":u\"s\u2019\", u\"x\u2019\":u\"\u0161\u2019\",\r\n                       VOWELS + u\":\":ur\"\\g<1>\u02d0\",\r\n                       VOWELS + u\"'\":ur\"\\g<1>\" + LARYNGEAL}\r\n    >>> re_monographs = {u\"h\":u\"\u0294\", u\"r\":u\"\u027e\", u\"x\":u\"\u0161\"}\r\n    >>> order = [re_trigraphs, re_bigraphs, re_monographs]\r\n    >>> transliterate(order, u\"a:ma'ha:'pi'tz\u00edn\")\r\n    a\u02d0ma\u0330\u0294a\u0330\u02d0pi\u0330c\u00edn\r\n\r\nThis way, the conversion for \"lh\":\"\u026c\" won't interrupt the conversion of\r\n\"lh\u2019\":u\"\u026c\u2019\". Alternatively, I suppose you could use an OrderedDict with\r\nthe word_replace/word_list_replace functions, but I personally like it\r\nthis way.\r\n\r\nConclusion\r\n----------\r\n\r\nIf you're writing your code in an interactive environment such as IPython,\r\nnote that if you change the contents of a dictionary, it will not be\r\nupdated inside any lists you may have created. I learned this the hard way,\r\nwhen my code didn't work until I redefined the order list used above. If you\r\nsee any weird bugs, that might be the cause.\r\n\r\nOther than that, if you have any other questions/issues with the module,\r\nshoot me an e-mail; especially if you run into any issues with Unicode\r\nsupport or bugs specific to Python 3/PyPy/another interpreter.\r\n\r\nFor an example transliteration script, see the script I wrote for\r\n`Upper Necaxa Totonac <https://github.com/MatthewDarling/UNT_to_IPA/>`_.\r\nThe example usage above is all drawn from that code - but it might help to see\r\na working example.\r\n\r\n\ufeff========\r\nVersions\r\n========\r\n\r\n1.3\r\n----------\r\n\r\nDebugged readme examples (Unicode escape was wrong, and | was used incorrectly)\r\n\r\n1.2\r\n----------\r\n\r\nReadme should be perfect\r\n\r\n1.1\r\n----------\r\n\r\nFixing readme for PyPI\r\n\r\n1.0\r\n----------\r\n\r\nFactored out of the UNT_to_IPA module", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MatthewDarling/re_transliterate/", "keywords": "", "license": "http://opensource.org/licenses/MIT", "maintainer": "", "maintainer_email": "", "name": "re_transliterate", "package_url": "https://pypi.org/project/re_transliterate/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/re_transliterate/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/MatthewDarling/re_transliterate/"}, "release_url": "https://pypi.org/project/re_transliterate/1.3/", "requires_dist": null, "requires_python": null, "summary": "Functions for transliteration using regular expressions", "version": "1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>\ufeffTransliteration is the conversion of text from one orthography to\nanother, or if you\u2019re a linguist, from a phonetic orthography to\ntranscription. I wrote this module to convert the orthography of an\nindigenuous Mexican language into IPA: their orthography was based\non Spanish, so there weren\u2019t any confusing irregularities like in\nEnglish.</p>\n<p>re_transliterate supports Unicode, though there might be corner cases\nfor particular languages. If that\u2019s the case, let me know, and I\u2019ll\nlook into using the regex module from PyPI rather than the built-in re\nmodule.</p>\n<p>Unlike the transliterate package on PyPI, re_transliterate allows for\nmapping between arbitrary strings: one (or more) letters can correspond\nto one (or more) letters. Since it\u2019s based on regular expressions, you\ncan also define language-specific character classes, like a set of\nvowels. This is extremely useful for handling diacritics and other\nsuprasegmental features.</p>\n<div id=\"how-does-it-work\">\n<h2>How does it work?</h2>\n<p>re_transliterate relies on Python dictionaries - mappings of x:y. These\nmappings should be written as regular expressions, which you may\nalready be familiar with. If not, find a computer science undergrad and\nmake them write your mappings :)</p>\n<p>In simple cases, you can simply use normal strings (prefaced by \u2018u\u2019 for\nUnicode in Python 2):</p>\n<blockquote>\n<pre>&gt;&gt;&gt; consonant_map = {u\"ch\":u\"\u010d\", u\"x\u2019\":u\"\u0161\u2019\"}\n&gt;&gt;&gt; word_replace(consonant_map, u\"ch\")\n\u010d\n</pre>\n</blockquote>\n<p>With that mapping, occurrences of \u201cch\u201d will be turned into \u2018\u010d\u2019 and\nejectives written with \u2018x\u2019 will instead use \u2018\u0161\u2019.</p>\n</div>\n<div id=\"the-power-of-regular-expressions\">\n<h2>The power of regular expressions</h2>\n<p>In more complicated cases, allowing regular expressions makes life\nmuch simpler. We can use character classes to reduce repetition, and\nuse backslashes to do fancy things. If your string contains a\nbackslash, preface it with \u2018r\u2019 as well as \u2018u\u2019. An example of both:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; VOWELS = u\"([aeiou\u00e1\u00e9\u00ed\u00f3\u00fa])\"\n&gt;&gt;&gt; long_vowels = {VOWELS + u\":\":ur\"\\g&lt;1&gt;\u02d0\"}\n&gt;&gt;&gt; word_replace(long_vowels, u\"a:'\")\na\u02d0\n</pre>\n</blockquote>\n<p>With this mapping, vowels followed by a colon character (\u2018:\u2019) will be\nchanged to use the IPA symbol for length (\u2018\u02d0\u2019). Here, square brackets []\nindicate a \u201ccharacter class\u201d: these characters will be treated in the\nsame way, such that the string \u201ca:\u201d will be matched just like \u201ci:\u201d or\n\u201c\u00fa:\u201d.</p>\n<p>Then, the parentheses () indicate a \u201cgroup\u201d in the regular expression:\nthis allows us to reference what it is that the pattern matched -\nthat\u2019s what the g&lt;1&gt; does, referring to \u201cgroup 1\u201d. If the pattern were\nto match \u201ca:\u201d, it would insert \u201ca\u02d0\u201d. This is the primary benefit of\nusing regular expressions: we don\u2019t have to specify that \u201ca:\u201d turns\ninto \u201ca\u02d0\u201d, and that \u201ce:\u201d turns into \u201ce\u02d0\u201d, etc.</p>\n</div>\n<div id=\"complicated-mappings\">\n<h2>Complicated mappings</h2>\n<p>In the previous example, did you see that I used addition inside the\nmapping? This allows useful patterns and special Unicode sequences to\nbe saved globally and reused elsewhere. In my own work, I defined the\nabove character class of vowels, and the Unicode sequence for the \u201ctilde\nbelow letter\u201d diacritic:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; LARYNGEAL = ur\"\\u0330\"\n</pre>\n</blockquote>\n<p>This allowed me to write mappings like this, where the \u2018 character\nrepresents laryngealization and may occur before/after a marker for\nlength:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; long_laryngealized = {VOWELS + u\"(:'|':)\":\n                          ur\"\\g&lt;1&gt;\" + LARYNGEAL + u\"\u02d0\"}\n</pre>\n</blockquote>\n<p>This converts any vowel, followed by either (marked by \u2018|\u2019) \u201c:\u2019\u201d or\n\u201c\u2019:\u201d, into the vowel + laryngealization diacritic + length marker.</p>\n</div>\n<div id=\"applying-your-mappings\">\n<h2>Applying your mappings</h2>\n<p>Once you\u2019ve created all your mappings, you can then either apply them\none at a time to a word (word_replace) or list of words\n(word_list_replace). As you develop your conversion code, you should\nuse these functions first, to make sure everything is working correctly.</p>\n<p>Generally, you\u2019ll want to have multiple mappings, because some\nconversions will be sensitive to ordering. For my work, I created three\nmappings: trigraphs (sequences of three characters), bigraphs, and\nmonographs. I then applied each of those in order, using the two\ntransliterate functions. Example:</p>\n<blockquote>\n<pre>&gt;&gt;&gt; re_trigraphs = {u\"lh\u2019\":u\"\u026c\u2019\",\n                    VOWELS + u\":'|':\":ur\"\\g&lt;1&gt;\" + LARYNGEAL + u\"\u02d0\"}\n&gt;&gt;&gt; re_bigraphs = {u\"ch\":u\"\u010d\", u\"lh\":u\"\u026c\", u\"nh\":u\"\u014b\u0294\",\n                   u\"tz\":u\"c\", u\"uj\":u\"\u028d\",\n                   u\"s\u2019\":u\"s\u2019\", u\"x\u2019\":u\"\u0161\u2019\",\n                   VOWELS + u\":\":ur\"\\g&lt;1&gt;\u02d0\",\n                   VOWELS + u\"'\":ur\"\\g&lt;1&gt;\" + LARYNGEAL}\n&gt;&gt;&gt; re_monographs = {u\"h\":u\"\u0294\", u\"r\":u\"\u027e\", u\"x\":u\"\u0161\"}\n&gt;&gt;&gt; order = [re_trigraphs, re_bigraphs, re_monographs]\n&gt;&gt;&gt; transliterate(order, u\"a:ma'ha:'pi'tz\u00edn\")\na\u02d0ma\u0330\u0294a\u0330\u02d0pi\u0330c\u00edn\n</pre>\n</blockquote>\n<p>This way, the conversion for \u201clh\u201d:\u201d\u026c\u201d won\u2019t interrupt the conversion of\n\u201clh\u2019\u201d:u\u201d\u026c\u2019\u201d. Alternatively, I suppose you could use an OrderedDict with\nthe word_replace/word_list_replace functions, but I personally like it\nthis way.</p>\n</div>\n<div id=\"conclusion\">\n<h2>Conclusion</h2>\n<p>If you\u2019re writing your code in an interactive environment such as IPython,\nnote that if you change the contents of a dictionary, it will not be\nupdated inside any lists you may have created. I learned this the hard way,\nwhen my code didn\u2019t work until I redefined the order list used above. If you\nsee any weird bugs, that might be the cause.</p>\n<p>Other than that, if you have any other questions/issues with the module,\nshoot me an e-mail; especially if you run into any issues with Unicode\nsupport or bugs specific to Python 3/PyPy/another interpreter.</p>\n<p>For an example transliteration script, see the script I wrote for\n<a href=\"https://github.com/MatthewDarling/UNT_to_IPA/\" rel=\"nofollow\">Upper Necaxa Totonac</a>.\nThe example usage above is all drawn from that code - but it might help to see\na working example.</p>\n<p>\ufeff========\nVersions\n========</p>\n</div>\n<div id=\"id1\">\n<h2>1.3</h2>\n<p>Debugged readme examples (Unicode escape was wrong, and | was used incorrectly)</p>\n</div>\n<div id=\"id2\">\n<h2>1.2</h2>\n<p>Readme should be perfect</p>\n</div>\n<div id=\"id3\">\n<h2>1.1</h2>\n<p>Fixing readme for PyPI</p>\n</div>\n<div id=\"id4\">\n<h2>1.0</h2>\n<p>Factored out of the UNT_to_IPA module</p>\n</div>\n\n          </div>"}, "last_serial": 925787, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "f9940211bf789bb40453f0e0392b0036", "sha256": "eb7e1b0eb63bc045f5d3a25544fac9582bdc73176fe5980babc3699c3e1b5089"}, "downloads": -1, "filename": "re_transliterate-1.0-py27-none-any.whl", "has_sig": false, "md5_digest": "f9940211bf789bb40453f0e0392b0036", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 7665, "upload_time": "2013-11-20T22:43:34", "upload_time_iso_8601": "2013-11-20T22:43:34.867807Z", "url": "https://files.pythonhosted.org/packages/f4/db/4c7bb2a073323d25b56b102be5e20daa6c97c165f09890a844327b6091ba/re_transliterate-1.0-py27-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6ecf6feb4028d0220fc5e4b24ef12c01", "sha256": "cc0fc46cae7d6b81ea0f60659c311bd0af0a48154f4812bf89f6e37ddbc11f1a"}, "downloads": -1, "filename": "re_transliterate-1.0.zip", "has_sig": false, "md5_digest": "6ecf6feb4028d0220fc5e4b24ef12c01", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12006, "upload_time": "2013-11-20T22:43:21", "upload_time_iso_8601": "2013-11-20T22:43:21.591864Z", "url": "https://files.pythonhosted.org/packages/12/ed/5c808ed1c40d37f31597239772a8641c3f459a9be418e61bfe7e2f2d22d8/re_transliterate-1.0.zip", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "22ef1254d934076374dd95b7a5d2f75e", "sha256": "5871010b82d8cb284f97d71364688614b929b9fc8f92667056e62ba5d09678f8"}, "downloads": -1, "filename": "re_transliterate-1.1-py27-none-any.whl", "has_sig": false, "md5_digest": "22ef1254d934076374dd95b7a5d2f75e", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 7692, "upload_time": "2013-11-20T22:48:18", "upload_time_iso_8601": "2013-11-20T22:48:18.342562Z", "url": "https://files.pythonhosted.org/packages/1a/51/753b1aa5bb387c432b4abeebab5aa0bccbdfcedb09ac58923b324e70f013/re_transliterate-1.1-py27-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "43da66313f25ac20aa3ca37c81c62caf", "sha256": "d433f6f5cf8b017c51148b7d92fb3be533d0f53415ffac38de49a3abc451c3ec"}, "downloads": -1, "filename": "re_transliterate-1.1.zip", "has_sig": false, "md5_digest": "43da66313f25ac20aa3ca37c81c62caf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12048, "upload_time": "2013-11-20T22:48:29", "upload_time_iso_8601": "2013-11-20T22:48:29.079470Z", "url": "https://files.pythonhosted.org/packages/67/4a/8c61df330d1a1d43859fe070cd96f00c5ec265add997cd06e9aa8f6f8652/re_transliterate-1.1.zip", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "bf598f64387c46968319c546bff71c80", "sha256": "3f122064f7b85a86d3b3524f20f36e13003f5cea02868bcbb9602a80999d6612"}, "downloads": -1, "filename": "re_transliterate-1.2-py27-none-any.whl", "has_sig": false, "md5_digest": "bf598f64387c46968319c546bff71c80", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 7713, "upload_time": "2013-11-20T22:50:14", "upload_time_iso_8601": "2013-11-20T22:50:14.200264Z", "url": "https://files.pythonhosted.org/packages/fa/d6/62edf897118957e99cd34573b5a4264bfe9ed9f7f7b253eb9344169e341a/re_transliterate-1.2-py27-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b43a02f3f455f40a5a5ee43165d0103d", "sha256": "414869ee869b728bc484445184fdb6027d7b2868a1762a3bb7fb241b0a2061b4"}, "downloads": -1, "filename": "re_transliterate-1.2.zip", "has_sig": false, "md5_digest": "b43a02f3f455f40a5a5ee43165d0103d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12092, "upload_time": "2013-11-20T22:50:01", "upload_time_iso_8601": "2013-11-20T22:50:01.630733Z", "url": "https://files.pythonhosted.org/packages/6d/72/7a5f80ae21fdc640e08ccd73624ed9ba7f12dd129006863ae44fb20ff560/re_transliterate-1.2.zip", "yanked": false}], "1.3": [{"comment_text": "", "digests": {"md5": "4b713b8e40083dd6a1730144d1aaf8cf", "sha256": "bb546dcad9686230ab37da99e83b02a0d74717d77005e2f0cddfaeb1c59ee856"}, "downloads": -1, "filename": "re_transliterate-1.3-py27-none-any.whl", "has_sig": false, "md5_digest": "4b713b8e40083dd6a1730144d1aaf8cf", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 8081, "upload_time": "2013-11-21T17:01:52", "upload_time_iso_8601": "2013-11-21T17:01:52.327594Z", "url": "https://files.pythonhosted.org/packages/b2/64/b8da2008704628babd2fb95a0f34b7b044e5060534244f1544183784723b/re_transliterate-1.3-py27-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d255ecf726b1084dba060b71f9fe67a6", "sha256": "746f4485266bd3d11979c1d41eee5759af1a990f083527e056ab18764a9628ff"}, "downloads": -1, "filename": "re_transliterate-1.3.zip", "has_sig": false, "md5_digest": "d255ecf726b1084dba060b71f9fe67a6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12634, "upload_time": "2013-11-21T17:02:11", "upload_time_iso_8601": "2013-11-21T17:02:11.643696Z", "url": "https://files.pythonhosted.org/packages/b4/67/5497989e51341c478a1672bd761c83c0c8b5675c0e6824ff97c0821e5a56/re_transliterate-1.3.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4b713b8e40083dd6a1730144d1aaf8cf", "sha256": "bb546dcad9686230ab37da99e83b02a0d74717d77005e2f0cddfaeb1c59ee856"}, "downloads": -1, "filename": "re_transliterate-1.3-py27-none-any.whl", "has_sig": false, "md5_digest": "4b713b8e40083dd6a1730144d1aaf8cf", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 8081, "upload_time": "2013-11-21T17:01:52", "upload_time_iso_8601": "2013-11-21T17:01:52.327594Z", "url": "https://files.pythonhosted.org/packages/b2/64/b8da2008704628babd2fb95a0f34b7b044e5060534244f1544183784723b/re_transliterate-1.3-py27-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d255ecf726b1084dba060b71f9fe67a6", "sha256": "746f4485266bd3d11979c1d41eee5759af1a990f083527e056ab18764a9628ff"}, "downloads": -1, "filename": "re_transliterate-1.3.zip", "has_sig": false, "md5_digest": "d255ecf726b1084dba060b71f9fe67a6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12634, "upload_time": "2013-11-21T17:02:11", "upload_time_iso_8601": "2013-11-21T17:02:11.643696Z", "url": "https://files.pythonhosted.org/packages/b4/67/5497989e51341c478a1672bd761c83c0c8b5675c0e6824ff97c0821e5a56/re_transliterate-1.3.zip", "yanked": false}], "timestamp": "Fri May  8 03:03:24 2020"}