{"info": {"author": "Scrapinghub", "author_email": "info@scrapinghub.com", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Environment :: No Input/Output (Daemon)", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Internet :: WWW/HTTP"], "description": "==========================\nScrapyrt (Scrapy realtime)\n==========================\n\n.. image:: https://travis-ci.org/scrapinghub/scrapyrt.svg?branch=master\n    :target: https://travis-ci.org/scrapinghub/scrapyrt\n\n.. image:: https://img.shields.io/pypi/pyversions/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/v/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/l/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\nHTTP server which provides API for scheduling Scrapy spiders and\nmaking requests with spiders.\n\nAllows you to easily add HTTP API to your existing Scrapy project. All Scrapy project\ncomponents (e.g. middleware, pipelines, extensions) are supported out of the box. You\nsimply run Scrapyrt in Scrapy project directory and it starts HTTP server allowing you\nto schedule your spiders and get spider output in JSON format.\n\n\nDocumentation\n=============\n\nDocumentation is available here: http://scrapyrt.readthedocs.org/en/latest/index.html\n\n\nSupport\n=======\n\nOpen source support is provided here in Github. Please `create a question\nissue`_ (ie. issue with \"question\" label).\n\nCommercial support is also available by `Scrapinghub`_.\n\n.. _create a question issue: https://github.com/scrapinghub/scrapyrt/issues/new?labels=question\n.. _Scrapinghub: http://scrapinghub.com\n\nDevelopment\n===========\n\nRelease\n-------\n\nUse `bumpversion`_ tool, e.g. to release minor version do::\n\n    bumpversion minor --verbose\n    git push origin master\n    git push origin <new_version_tag>\n\n.. _bumpversion: https://pypi.python.org/pypi/bumpversion\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/scrapinghub/scrapyrt", "keywords": "", "license": "BSD", "maintainer": "Scrapinghub", "maintainer_email": "info@scrapinghub.com", "name": "scrapyrt", "package_url": "https://pypi.org/project/scrapyrt/", "platform": "", "project_url": "https://pypi.org/project/scrapyrt/", "project_urls": {"Homepage": "https://github.com/scrapinghub/scrapyrt"}, "release_url": "https://pypi.org/project/scrapyrt/0.11.0/", "requires_dist": ["Twisted (>=14.0.0)", "Scrapy (>=1.0.0)", "demjson", "six (>=1.5.2)"], "requires_python": "", "summary": "Put Scrapy spiders behind an HTTP API", "version": "0.11.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/scrapinghub/scrapyrt\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/scrapinghub/scrapyrt.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57eaf989c2f4b8c48007b4328cabf46d82b48559/68747470733a2f2f7472617669732d63692e6f72672f7363726170696e676875622f73637261707972742e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pypi.python.org/pypi/scrapyrt\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/pyversions/scrapyrt.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4260d1e79fb4fc6c314422e71737d5b602876dc5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f73637261707972742e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/scrapyrt\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/scrapyrt.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9737e64b2d9c883c07dfc8716e28eab37750670c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f73637261707972742e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/scrapyrt\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/l/scrapyrt.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1f0a2dc680f6dcde6b8c7927b704cdc8b2b77db8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f73637261707972742e737667\"></a>\n<p>HTTP server which provides API for scheduling Scrapy spiders and\nmaking requests with spiders.</p>\n<p>Allows you to easily add HTTP API to your existing Scrapy project. All Scrapy project\ncomponents (e.g. middleware, pipelines, extensions) are supported out of the box. You\nsimply run Scrapyrt in Scrapy project directory and it starts HTTP server allowing you\nto schedule your spiders and get spider output in JSON format.</p>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>Documentation is available here: <a href=\"http://scrapyrt.readthedocs.org/en/latest/index.html\" rel=\"nofollow\">http://scrapyrt.readthedocs.org/en/latest/index.html</a></p>\n</div>\n<div id=\"support\">\n<h2>Support</h2>\n<p>Open source support is provided here in Github. Please <a href=\"https://github.com/scrapinghub/scrapyrt/issues/new?labels=question\" rel=\"nofollow\">create a question\nissue</a> (ie. issue with \u201cquestion\u201d label).</p>\n<p>Commercial support is also available by <a href=\"http://scrapinghub.com\" rel=\"nofollow\">Scrapinghub</a>.</p>\n</div>\n<div id=\"development\">\n<h2>Development</h2>\n<h2 id=\"release\"><span class=\"section-subtitle\">Release</span></h2>\n<p>Use <a href=\"https://pypi.python.org/pypi/bumpversion\" rel=\"nofollow\">bumpversion</a> tool, e.g. to release minor version do:</p>\n<pre>bumpversion minor --verbose\ngit push origin master\ngit push origin &lt;new_version_tag&gt;\n</pre>\n</div>\n\n          </div>"}, "last_serial": 5861916, "releases": {"0.10": [{"comment_text": "", "digests": {"md5": "2fa44db94e6286e653dc37bbdf9d9231", "sha256": "2b439cba2d96cce88a1d47a0b3a8cf8bdbe8312e0b1bc97c8e64e20cea840d40"}, "downloads": -1, "filename": "scrapyrt-0.10.tar.gz", "has_sig": false, "md5_digest": "2fa44db94e6286e653dc37bbdf9d9231", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23544, "upload_time": "2017-04-18T10:36:53", "upload_time_iso_8601": "2017-04-18T10:36:53.373491Z", "url": "https://files.pythonhosted.org/packages/cc/ca/e04513d8a7f900ed09d5558b7ef0768197ecd519c7359815b4b744ff4bab/scrapyrt-0.10.tar.gz", "yanked": false}], "0.11.0": [{"comment_text": "", "digests": {"md5": "bc7a99a624366bfbead69979763ee8c0", "sha256": "5fb05b27bda1b6b270aac40bc827ed31da5b17a92864069cbcda6dc489ceb90b"}, "downloads": -1, "filename": "scrapyrt-0.11.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bc7a99a624366bfbead69979763ee8c0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33299, "upload_time": "2019-09-20T11:55:03", "upload_time_iso_8601": "2019-09-20T11:55:03.250063Z", "url": "https://files.pythonhosted.org/packages/ec/f3/e6010c5cc59c7acdce8589e696d3d8546985155107294f2a92ee3086da5b/scrapyrt-0.11.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f6bf1376f9c8a910271bef6a9aa4b451", "sha256": "4ad45c6f35f2ccaab4ef8d0c8f0a54bfe598f4c4162d0b89af8255703a2d7573"}, "downloads": -1, "filename": "scrapyrt-0.11.0.tar.gz", "has_sig": false, "md5_digest": "f6bf1376f9c8a910271bef6a9aa4b451", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24156, "upload_time": "2019-09-20T11:55:04", "upload_time_iso_8601": "2019-09-20T11:55:04.672624Z", "url": "https://files.pythonhosted.org/packages/40/2e/2bae97fe4e05878c44f4ba3763fce142693c84cfda405b8ca5afa60a8287/scrapyrt-0.11.0.tar.gz", "yanked": false}], "0.9": [{"comment_text": "", "digests": {"md5": "8b128cf59b7629c88573792b7e7b3059", "sha256": "66e93fb22f3e8ee246be34a6f136ca8810ad202f5cfd4f550633c5c427c7e4c7"}, "downloads": -1, "filename": "scrapyrt-0.9.tar.gz", "has_sig": false, "md5_digest": "8b128cf59b7629c88573792b7e7b3059", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19897, "upload_time": "2016-05-11T15:29:41", "upload_time_iso_8601": "2016-05-11T15:29:41.818182Z", "url": "https://files.pythonhosted.org/packages/28/09/5fb168ded6859305297f276fb0ef0b4b5c626afed57ea6bc0bad4d7cc698/scrapyrt-0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bc7a99a624366bfbead69979763ee8c0", "sha256": "5fb05b27bda1b6b270aac40bc827ed31da5b17a92864069cbcda6dc489ceb90b"}, "downloads": -1, "filename": "scrapyrt-0.11.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bc7a99a624366bfbead69979763ee8c0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33299, "upload_time": "2019-09-20T11:55:03", "upload_time_iso_8601": "2019-09-20T11:55:03.250063Z", "url": "https://files.pythonhosted.org/packages/ec/f3/e6010c5cc59c7acdce8589e696d3d8546985155107294f2a92ee3086da5b/scrapyrt-0.11.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f6bf1376f9c8a910271bef6a9aa4b451", "sha256": "4ad45c6f35f2ccaab4ef8d0c8f0a54bfe598f4c4162d0b89af8255703a2d7573"}, "downloads": -1, "filename": "scrapyrt-0.11.0.tar.gz", "has_sig": false, "md5_digest": "f6bf1376f9c8a910271bef6a9aa4b451", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24156, "upload_time": "2019-09-20T11:55:04", "upload_time_iso_8601": "2019-09-20T11:55:04.672624Z", "url": "https://files.pythonhosted.org/packages/40/2e/2bae97fe4e05878c44f4ba3763fce142693c84cfda405b8ca5afa60a8287/scrapyrt-0.11.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:41 2020"}