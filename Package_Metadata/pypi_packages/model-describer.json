{"info": {"author": "Jason Lewris, Venkat Gangavarapu, Daniel Byler,  Shruti Panda", "author_email": "jlewris@deloitte.com, vegangavarapu@deloitte.com, dybler@deloitte.com, shrupanda@deloitte.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "License :: OSI Approved :: MIT License", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Communications :: Email", "Topic :: Education", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Scientific/Engineering :: Visualization"], "description": ".. -*- mode: rst -*-\n.. image:: https://travis-ci.com/DataScienceSquad/model-describer.svg?token=1GNkopDprh4icqumn6Mz&branch=master\n    :target: https://travis-ci.com/DataScienceSquad/model-describer\n\n.. image:: https://img.shields.io/badge/License-MIT-blue.svg\n    :target: https://lbesson.mit-license.org/\n    \n.. image:: https://img.shields.io/pypi/pyversions/ansicolortags.svg\n    :target: https://pypi.python.org/pypi/model-describer\n\nmodel-describer: Simple code to make 'black box' machine learning models interpretable to humans\n===================================================================================================\n\nmodel-describer makes it possible for everyday humans to understand 'black-box' machine learning models in two key ways:\n\n1. model-describer helps us understand how the model 'believes' different groups behave within the model \n\n2. model-describer helps makes it clear where the model is making particularly accurate or inaccurate predictions\n\nTo make communicating these findings to your team easy, model-describer outputs: \n\n- Are created with simple Python code at the end of your existing machine learning workflow and require no model re-training\n- Are compelling interactive HTML files that are small enough to be emailed. \n- Attachment only require your teammate/client to have a web browser to open your attachment. No server or messy installation required.\n- Do not expose your potentially sensitive raw data. Only summaries of the data are included in the final HTML file. This also makes it possible to summarize models built on extremely large datasets into file sizes that are small enough for email. \n\nSample Outputs\n================\n\nImpact\n------------\n\nCurrently, many people substitute `variable importance <https://en.wikipedia.org/wiki/Random_forest#Variable_importance>`_  charts for an understanding of how the model works. While genuinely helpful, these plots do not contribute to understanding how different subgroups behave differently under the hood of the model. In the example below (`full notebook here <https://github.com/DataScienceSquad/model-describer/blob/master/docs/notebooks/WineQuality_Example.ipynb>`_ and `parameter list here <https://github.com/DataScienceSquad/model-describer/tree/master/docs>`_ ) all you have to do to produce the interactive chart is this simple segment of code:\n\n.. code-block:: python\n\n    SV = SensitivityViz(clf,\n                       model_df=finaldf,\n                       ydepend=ydepend,\n                       cat_df=df,\n                       featuredict=None,\n                       groupbyvars=['AlcoholContent'],\n                       aggregate_func=np.mean,\n                       verbose=None,\n                        std_num=2\n                       )\n    SV.run(output_type='html', output_path='path/to/save.html')\n\nPlease note all descriptive text is automatically generated by model-describer and use quartiles as cutoff points for the narrative text:\n\n.. image:: https://github.com/DataScienceSquad/model-describer/blob/master/images/Impact_Gif.gif\n    :target: https://github.com/DataScienceSquad/model-describer/blob/master/images/Impact_Gif.gif\n\nIn the above example, each variable's chart is generated by going through the dataset and generating two predictions for each row. First, model-describer uses the modelObject to generate a prediction on all of the original data. Then each variable in question is increased by one standard deviation and the model is run again on the synthetic data. The average gap in predictions between the real data and the simulated data is the 'impact' that variable has on the dependent variable. This is repeated for all variables you are interested in. For categorical variables, the synthetic data is created by setting data not at the mode to the mode and measuring the change in the predicted values.   \n\nError\n------------\n\nThere are a hundred ways to skin an error chart. Almost all of them are reasonable. However, few can be proceeded by the comment\n\n.. code-block:: python\n\n   #Send To Boss As Attachment With No Additional Editing\n    EV.save('/filepathtoboss')\n\nmodel-describer helps fill that gap for you. These error charts group the level of error by type and show where the error vary for different parts of different variables. Again, only one line of code is required to run it.\n\n.. code-block:: python\n\n    EV = ErrorViz(modelobj = modelObjc,\n                       model_df = xTrainData,\n                       ydepend= yDepend,\n                       cat_df = wine_sub,\n                       groupbyvars = groupbyVars,\n                       featuredict = featuredict,\n                       verbose=None)\n    EV.run(output_type='html', output_path='path/to/save.html')\n\n\n.. image:: https://github.com/DataScienceSquad/model-describer/blob/master/images/Error_Gif.gif\n    :target: https://github.com/DataScienceSquad/model-describer/blob/master/images/Error_Gif.gif\n\nFor a more detailed example, see our `example notebook <https://github.com/DataScienceSquad/model-describer/blob/master/docs/notebooks/WineQuality_Example.ipynb>`_ and `parameter list here <https://github.com/DataScienceSquad/model-describer/tree/master/docs>`_.\n\nInstallation\n==============\n\nInstallation is easy.\n\n.. code-block:: python\n\n   pip install model-describer\n\nRequirements\n----------------\n\nmodel-describer requires:\n\n- numpy >= 1.14.0 \n- pandas >= 0.22.0 \n- scikit-learn >= 0.19.1 \n- scipy >= 1.0.0\n\nHelpful Tips\n===============\n\nHandling Categorical Variables\n---------------------------------\n\nIn many models, categorical variables are present as independent variables. To provide meaningful charts, model-describer require categorical dummies to have the naming convention varname_category (for example Gender_Male and Gender_Female). One way to generate these is:\n\n.. code-block:: python\n\n   # depndent variable\n   ydepend = 'target'\n   # construct dataframe for modelling\n   model_df = df.loc[:, df.columns != ydepend]\n   model_df = pd.get_dummies(model_df)\n\nHandling NaNs\n-----------------\n\nMissing data needs to be specially handled within model-describer. For any data the user wishes to treat as missing, numeric columns must maintain the original missing value NaN. Users should map NaN values in string variables to a more descriptive value like 'Missing'. In order to make missing data more visually appealing the html output, you can use the following construct:\n\n.. code-block:: python\n\n    # fill object dtype columns with null to map to html output as a category\n    df = df.apply(lambda x: x.fillna('Missing') if x.dtype.kind == 'O' else x)\n    # and get dummies as usual\n    ydepend = 'target'\n    model_df = pd.get_dummies(df.loc[:, df.columns != ydepend])\n    # build and train model, etc.\n    ...\n    # pass to model-describer\n    WB = ErrorViz(...cat_df = df, model_df = model_df)\n\nmodel-describer uses the prediction methods native to the machine learning method used for training. As such, if the trained model fed to model-describer cannot process NaNs, model-describer will also be unable to process those NaNs.\n\nManaging Output Length\n------------------------\n\nMany times, models will have hundreds (or more) of independent variables. To select a more managable subset of variables, use the keepfeaturelist parameter (present in both functions). By feeding in this list the user will make the HTML output only print output relating to the specified variables.\n\n.. code-block:: python\n\n    keepfeaturelist = ['col1', 'col2', 'col3']\n\n    SV = SensitivityViz(...\n                            keepfeaturelist=keepfeaturelist)\n\n\nFormatting Column Names for Output HTML\n----------------------------------------\n\nIf columns have unintuitive or especially long names, simply rename the columns up front in your anlaysis script and the new names will propagate throughout the pipeline into the html output.\n\n.. code-block:: python\n\n    col_rename = {'col1': 'demographic_age', 'col2': 'demographic_sex', 'col3': 'demographic_race'}\n    df.rename(columns=col_rename, inplace=True)\n    # create modelling dataframe, create dummies, build model, and specify model-describer\n\nFormatting numeric variable outputs\n--------------------------------------\n\nIf some variables contain especially long or small numbers, it is advisable to format these for better looking output.\n\n.. code-block:: python\n\n    df = pd.DataFrame({'col1': np.random.uniform(10000000, 20000000, 1000)})\n    # format numbers\n    df['col1'] = list(map(lambda p: round(p, 2), df['col1']/10000000))\n    # rename column\n    df.rename(columns={'col1': 'col1(10000000s)'}, inplace=True)\n\nFAQs\n--------------\n\nAnswers to additional questions about assumptions model-describer makes in its calculations can be found `here <https://github.com/DataScienceSquad/model-describer/wiki/FAQ>`_. \n\n\nSupported Machine Learning Libraries\n=======================================\n\nmodel-describer currently supports all traditional sklearn regression methods and all sklearn binary classification methods. model-describer does not support multi-class classification at this time. PLS Regression, PLS Cannonical, Isotonic Regression, Mutlitask Lasso & Multi-task ElasticNet are not supported as they do not produce a single prediction for each row like other classifiers do. model-describer will look to add support for other machine learning libraries the future. In all implementations, model-describer is committed to keeping our 'one line of code' promise. \n\nmodel-describer currently only supports traditional tabular data. model-describer is hoping to include text, audio, video, and images in the future but they are not part of the current implementation. \n\nOther Python Machine Learning Interpretability Projects\n----------------------------------------------------------\n\nFor those looking for intepretation of individual points, please see the `Lime <https://github.com/marcotcr/lime>`_ project and its good work. `PyCEbox <https://github.com/AustinRochford/PyCEbox>`_ also has a different take on `classic partial dependence plots <http://scikit-learn.org/stable/auto_examples/ensemble/plot_partial_dependence.html>`_. `SHAP <https://github.com/slundberg/shap>`_ is another model-agnostic method for machine learning interpretation. \n\n\nAuthors:\n==========\n\nAuthors include: `Daniel Byler <https://www.linkedin.com/in/danielbyler/>`_, `Venkatesh Gangavarapu <https://www.linkedin.com/in/venkatesh-gangavarapu-9845b36b/>`_, `Jason Lewris <https://www.linkedin.com/in/jasonlewris/>`_, `Shruti Panda <https://www.linkedin.com/in/shruti-panda-1466216a/>`_\n\nAcknowledgements\n-------------------\n\nThanks to `Kenton Andersen <https://www.linkedin.com/in/kentonandersen/>`_ for his tireless help in running and operating our development environment. Additional acknowledgements include:\n\n- `Shanti Jha <https://www.linkedin.com/in/shantijha/>`_\n- `Brian Ray <https://www.linkedin.com/in/brianray/>`_\n- `Jim Guszcza <https://www.linkedin.com/in/jim-guszcza-5330375/>`_\n \nPlease drop us a line in the issues section as bugs or feature requests arise. \n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/DataScienceSquad/model-describer/archive/0.1.2.2.zip", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/DataScienceSquad/model-describer", "keywords": "machine learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "model-describer", "package_url": "https://pypi.org/project/model-describer/", "platform": "", "project_url": "https://pypi.org/project/model-describer/", "project_urls": {"Download": "https://github.com/DataScienceSquad/model-describer/archive/0.1.2.2.zip", "Homepage": "https://github.com/DataScienceSquad/model-describer"}, "release_url": "https://pypi.org/project/model-describer/0.1.2.2/", "requires_dist": null, "requires_python": "", "summary": "How can I unlock what my model is thinking? model-describer helps answer this problem for sklearn machine learning models. Specifically, model-describer helps address two key issues: error and model sensitivity. For error, model-describer analyzes how well the model is performing within key regions of the data in a visually compelling way. For sensitivity, model-describer identifies what parts of different variable distributions have the biggest impact on model predictions and plots them.", "version": "0.1.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.com/DataScienceSquad/model-describer\" rel=\"nofollow\"><img alt=\"https://travis-ci.com/DataScienceSquad/model-describer.svg?token=1GNkopDprh4icqumn6Mz&amp;branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3d0dab9d95a67553cb8ca7e57601fd9b5fcfbed5/68747470733a2f2f7472617669732d63692e636f6d2f44617461536369656e636553717561642f6d6f64656c2d6465736372696265722e7376673f746f6b656e3d31474e6b6f704470726834696371756d6e364d7a266272616e63683d6d6173746572\"></a>\n<a href=\"https://lbesson.mit-license.org/\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/License-MIT-blue.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4150014b4dfdd7b565fa18de88e9bb1b8ccd7c08/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/model-describer\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/pyversions/ansicolortags.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7ce087dbe02f90423263426209feb4854240523b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f616e7369636f6c6f72746167732e737667\"></a>\n<div id=\"model-describer-simple-code-to-make-black-box-machine-learning-models-interpretable-to-humans\">\n<h2>model-describer: Simple code to make \u2018black box\u2019 machine learning models interpretable to humans</h2>\n<p>model-describer makes it possible for everyday humans to understand \u2018black-box\u2019 machine learning models in two key ways:</p>\n<ol>\n<li>model-describer helps us understand how the model \u2018believes\u2019 different groups behave within the model</li>\n<li>model-describer helps makes it clear where the model is making particularly accurate or inaccurate predictions</li>\n</ol>\n<p>To make communicating these findings to your team easy, model-describer outputs:</p>\n<ul>\n<li>Are created with simple Python code at the end of your existing machine learning workflow and require no model re-training</li>\n<li>Are compelling interactive HTML files that are small enough to be emailed.</li>\n<li>Attachment only require your teammate/client to have a web browser to open your attachment. No server or messy installation required.</li>\n<li>Do not expose your potentially sensitive raw data. Only summaries of the data are included in the final HTML file. This also makes it possible to summarize models built on extremely large datasets into file sizes that are small enough for email.</li>\n</ul>\n</div>\n<div id=\"sample-outputs\">\n<h2>Sample Outputs</h2>\n<div id=\"impact\">\n<h3>Impact</h3>\n<p>Currently, many people substitute <a href=\"https://en.wikipedia.org/wiki/Random_forest#Variable_importance\" rel=\"nofollow\">variable importance</a>  charts for an understanding of how the model works. While genuinely helpful, these plots do not contribute to understanding how different subgroups behave differently under the hood of the model. In the example below (<a href=\"https://github.com/DataScienceSquad/model-describer/blob/master/docs/notebooks/WineQuality_Example.ipynb\" rel=\"nofollow\">full notebook here</a> and <a href=\"https://github.com/DataScienceSquad/model-describer/tree/master/docs\" rel=\"nofollow\">parameter list here</a> ) all you have to do to produce the interactive chart is this simple segment of code:</p>\n<pre><span class=\"n\">SV</span> <span class=\"o\">=</span> <span class=\"n\">SensitivityViz</span><span class=\"p\">(</span><span class=\"n\">clf</span><span class=\"p\">,</span>\n                   <span class=\"n\">model_df</span><span class=\"o\">=</span><span class=\"n\">finaldf</span><span class=\"p\">,</span>\n                   <span class=\"n\">ydepend</span><span class=\"o\">=</span><span class=\"n\">ydepend</span><span class=\"p\">,</span>\n                   <span class=\"n\">cat_df</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">,</span>\n                   <span class=\"n\">featuredict</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                   <span class=\"n\">groupbyvars</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'AlcoholContent'</span><span class=\"p\">],</span>\n                   <span class=\"n\">aggregate_func</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">,</span>\n                   <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                    <span class=\"n\">std_num</span><span class=\"o\">=</span><span class=\"mi\">2</span>\n                   <span class=\"p\">)</span>\n<span class=\"n\">SV</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">output_type</span><span class=\"o\">=</span><span class=\"s1\">'html'</span><span class=\"p\">,</span> <span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"s1\">'path/to/save.html'</span><span class=\"p\">)</span>\n</pre>\n<p>Please note all descriptive text is automatically generated by model-describer and use quartiles as cutoff points for the narrative text:</p>\n<a href=\"https://github.com/DataScienceSquad/model-describer/blob/master/images/Impact_Gif.gif\" rel=\"nofollow\"><img alt=\"https://github.com/DataScienceSquad/model-describer/blob/master/images/Impact_Gif.gif\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5c90265b49263af8445b6f3f12805446db699f41/68747470733a2f2f6769746875622e636f6d2f44617461536369656e636553717561642f6d6f64656c2d6465736372696265722f626c6f622f6d61737465722f696d616765732f496d706163745f4769662e676966\"></a>\n<p>In the above example, each variable\u2019s chart is generated by going through the dataset and generating two predictions for each row. First, model-describer uses the modelObject to generate a prediction on all of the original data. Then each variable in question is increased by one standard deviation and the model is run again on the synthetic data. The average gap in predictions between the real data and the simulated data is the \u2018impact\u2019 that variable has on the dependent variable. This is repeated for all variables you are interested in. For categorical variables, the synthetic data is created by setting data not at the mode to the mode and measuring the change in the predicted values.</p>\n</div>\n<div id=\"error\">\n<h3>Error</h3>\n<p>There are a hundred ways to skin an error chart. Almost all of them are reasonable. However, few can be proceeded by the comment</p>\n<pre><span class=\"c1\">#Send To Boss As Attachment With No Additional Editing</span>\n <span class=\"n\">EV</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'/filepathtoboss'</span><span class=\"p\">)</span>\n</pre>\n<p>model-describer helps fill that gap for you. These error charts group the level of error by type and show where the error vary for different parts of different variables. Again, only one line of code is required to run it.</p>\n<pre><span class=\"n\">EV</span> <span class=\"o\">=</span> <span class=\"n\">ErrorViz</span><span class=\"p\">(</span><span class=\"n\">modelobj</span> <span class=\"o\">=</span> <span class=\"n\">modelObjc</span><span class=\"p\">,</span>\n                   <span class=\"n\">model_df</span> <span class=\"o\">=</span> <span class=\"n\">xTrainData</span><span class=\"p\">,</span>\n                   <span class=\"n\">ydepend</span><span class=\"o\">=</span> <span class=\"n\">yDepend</span><span class=\"p\">,</span>\n                   <span class=\"n\">cat_df</span> <span class=\"o\">=</span> <span class=\"n\">wine_sub</span><span class=\"p\">,</span>\n                   <span class=\"n\">groupbyvars</span> <span class=\"o\">=</span> <span class=\"n\">groupbyVars</span><span class=\"p\">,</span>\n                   <span class=\"n\">featuredict</span> <span class=\"o\">=</span> <span class=\"n\">featuredict</span><span class=\"p\">,</span>\n                   <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"n\">EV</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">output_type</span><span class=\"o\">=</span><span class=\"s1\">'html'</span><span class=\"p\">,</span> <span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"s1\">'path/to/save.html'</span><span class=\"p\">)</span>\n</pre>\n<a href=\"https://github.com/DataScienceSquad/model-describer/blob/master/images/Error_Gif.gif\" rel=\"nofollow\"><img alt=\"https://github.com/DataScienceSquad/model-describer/blob/master/images/Error_Gif.gif\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e1ff5a9b8e54a58bd7e61b819298bd2a9ae42870/68747470733a2f2f6769746875622e636f6d2f44617461536369656e636553717561642f6d6f64656c2d6465736372696265722f626c6f622f6d61737465722f696d616765732f4572726f725f4769662e676966\"></a>\n<p>For a more detailed example, see our <a href=\"https://github.com/DataScienceSquad/model-describer/blob/master/docs/notebooks/WineQuality_Example.ipynb\" rel=\"nofollow\">example notebook</a> and <a href=\"https://github.com/DataScienceSquad/model-describer/tree/master/docs\" rel=\"nofollow\">parameter list here</a>.</p>\n</div>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Installation is easy.</p>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">model</span><span class=\"o\">-</span><span class=\"n\">describer</span>\n</pre>\n<div id=\"requirements\">\n<h3>Requirements</h3>\n<p>model-describer requires:</p>\n<ul>\n<li>numpy &gt;= 1.14.0</li>\n<li>pandas &gt;= 0.22.0</li>\n<li>scikit-learn &gt;= 0.19.1</li>\n<li>scipy &gt;= 1.0.0</li>\n</ul>\n</div>\n</div>\n<div id=\"helpful-tips\">\n<h2>Helpful Tips</h2>\n<div id=\"handling-categorical-variables\">\n<h3>Handling Categorical Variables</h3>\n<p>In many models, categorical variables are present as independent variables. To provide meaningful charts, model-describer require categorical dummies to have the naming convention varname_category (for example Gender_Male and Gender_Female). One way to generate these is:</p>\n<pre><span class=\"c1\"># depndent variable</span>\n<span class=\"n\">ydepend</span> <span class=\"o\">=</span> <span class=\"s1\">'target'</span>\n<span class=\"c1\"># construct dataframe for modelling</span>\n<span class=\"n\">model_df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[:,</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span> <span class=\"o\">!=</span> <span class=\"n\">ydepend</span><span class=\"p\">]</span>\n<span class=\"n\">model_df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">get_dummies</span><span class=\"p\">(</span><span class=\"n\">model_df</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"handling-nans\">\n<h3>Handling NaNs</h3>\n<p>Missing data needs to be specially handled within model-describer. For any data the user wishes to treat as missing, numeric columns must maintain the original missing value NaN. Users should map NaN values in string variables to a more descriptive value like \u2018Missing\u2019. In order to make missing data more visually appealing the html output, you can use the following construct:</p>\n<pre><span class=\"c1\"># fill object dtype columns with null to map to html output as a category</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">fillna</span><span class=\"p\">(</span><span class=\"s1\">'Missing'</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">dtype</span><span class=\"o\">.</span><span class=\"n\">kind</span> <span class=\"o\">==</span> <span class=\"s1\">'O'</span> <span class=\"k\">else</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"c1\"># and get dummies as usual</span>\n<span class=\"n\">ydepend</span> <span class=\"o\">=</span> <span class=\"s1\">'target'</span>\n<span class=\"n\">model_df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">get_dummies</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[:,</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span> <span class=\"o\">!=</span> <span class=\"n\">ydepend</span><span class=\"p\">])</span>\n<span class=\"c1\"># build and train model, etc.</span>\n<span class=\"o\">...</span>\n<span class=\"c1\"># pass to model-describer</span>\n<span class=\"n\">WB</span> <span class=\"o\">=</span> <span class=\"n\">ErrorViz</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"n\">cat_df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">model_df</span> <span class=\"o\">=</span> <span class=\"n\">model_df</span><span class=\"p\">)</span>\n</pre>\n<p>model-describer uses the prediction methods native to the machine learning method used for training. As such, if the trained model fed to model-describer cannot process NaNs, model-describer will also be unable to process those NaNs.</p>\n</div>\n<div id=\"managing-output-length\">\n<h3>Managing Output Length</h3>\n<p>Many times, models will have hundreds (or more) of independent variables. To select a more managable subset of variables, use the keepfeaturelist parameter (present in both functions). By feeding in this list the user will make the HTML output only print output relating to the specified variables.</p>\n<pre><span class=\"n\">keepfeaturelist</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'col1'</span><span class=\"p\">,</span> <span class=\"s1\">'col2'</span><span class=\"p\">,</span> <span class=\"s1\">'col3'</span><span class=\"p\">]</span>\n\n<span class=\"n\">SV</span> <span class=\"o\">=</span> <span class=\"n\">SensitivityViz</span><span class=\"p\">(</span><span class=\"o\">...</span>\n                        <span class=\"n\">keepfeaturelist</span><span class=\"o\">=</span><span class=\"n\">keepfeaturelist</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"formatting-column-names-for-output-html\">\n<h3>Formatting Column Names for Output HTML</h3>\n<p>If columns have unintuitive or especially long names, simply rename the columns up front in your anlaysis script and the new names will propagate throughout the pipeline into the html output.</p>\n<pre><span class=\"n\">col_rename</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'col1'</span><span class=\"p\">:</span> <span class=\"s1\">'demographic_age'</span><span class=\"p\">,</span> <span class=\"s1\">'col2'</span><span class=\"p\">:</span> <span class=\"s1\">'demographic_sex'</span><span class=\"p\">,</span> <span class=\"s1\">'col3'</span><span class=\"p\">:</span> <span class=\"s1\">'demographic_race'</span><span class=\"p\">}</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">(</span><span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">col_rename</span><span class=\"p\">,</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"c1\"># create modelling dataframe, create dummies, build model, and specify model-describer</span>\n</pre>\n</div>\n<div id=\"formatting-numeric-variable-outputs\">\n<h3>Formatting numeric variable outputs</h3>\n<p>If some variables contain especially long or small numbers, it is advisable to format these for better looking output.</p>\n<pre><span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s1\">'col1'</span><span class=\"p\">:</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"mi\">10000000</span><span class=\"p\">,</span> <span class=\"mi\">20000000</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">)})</span>\n<span class=\"c1\"># format numbers</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'col1'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"nb\">round</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'col1'</span><span class=\"p\">]</span><span class=\"o\">/</span><span class=\"mi\">10000000</span><span class=\"p\">))</span>\n<span class=\"c1\"># rename column</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">(</span><span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'col1'</span><span class=\"p\">:</span> <span class=\"s1\">'col1(10000000s)'</span><span class=\"p\">},</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"faqs\">\n<h3>FAQs</h3>\n<p>Answers to additional questions about assumptions model-describer makes in its calculations can be found <a href=\"https://github.com/DataScienceSquad/model-describer/wiki/FAQ\" rel=\"nofollow\">here</a>.</p>\n</div>\n</div>\n<div id=\"supported-machine-learning-libraries\">\n<h2>Supported Machine Learning Libraries</h2>\n<p>model-describer currently supports all traditional sklearn regression methods and all sklearn binary classification methods. model-describer does not support multi-class classification at this time. PLS Regression, PLS Cannonical, Isotonic Regression, Mutlitask Lasso &amp; Multi-task ElasticNet are not supported as they do not produce a single prediction for each row like other classifiers do. model-describer will look to add support for other machine learning libraries the future. In all implementations, model-describer is committed to keeping our \u2018one line of code\u2019 promise.</p>\n<p>model-describer currently only supports traditional tabular data. model-describer is hoping to include text, audio, video, and images in the future but they are not part of the current implementation.</p>\n<div id=\"other-python-machine-learning-interpretability-projects\">\n<h3>Other Python Machine Learning Interpretability Projects</h3>\n<p>For those looking for intepretation of individual points, please see the <a href=\"https://github.com/marcotcr/lime\" rel=\"nofollow\">Lime</a> project and its good work. <a href=\"https://github.com/AustinRochford/PyCEbox\" rel=\"nofollow\">PyCEbox</a> also has a different take on <a href=\"http://scikit-learn.org/stable/auto_examples/ensemble/plot_partial_dependence.html\" rel=\"nofollow\">classic partial dependence plots</a>. <a href=\"https://github.com/slundberg/shap\" rel=\"nofollow\">SHAP</a> is another model-agnostic method for machine learning interpretation.</p>\n</div>\n</div>\n<div id=\"authors\">\n<h2>Authors:</h2>\n<p>Authors include: <a href=\"https://www.linkedin.com/in/danielbyler/\" rel=\"nofollow\">Daniel Byler</a>, <a href=\"https://www.linkedin.com/in/venkatesh-gangavarapu-9845b36b/\" rel=\"nofollow\">Venkatesh Gangavarapu</a>, <a href=\"https://www.linkedin.com/in/jasonlewris/\" rel=\"nofollow\">Jason Lewris</a>, <a href=\"https://www.linkedin.com/in/shruti-panda-1466216a/\" rel=\"nofollow\">Shruti Panda</a></p>\n<div id=\"acknowledgements\">\n<h3>Acknowledgements</h3>\n<p>Thanks to <a href=\"https://www.linkedin.com/in/kentonandersen/\" rel=\"nofollow\">Kenton Andersen</a> for his tireless help in running and operating our development environment. Additional acknowledgements include:</p>\n<ul>\n<li><a href=\"https://www.linkedin.com/in/shantijha/\" rel=\"nofollow\">Shanti Jha</a></li>\n<li><a href=\"https://www.linkedin.com/in/brianray/\" rel=\"nofollow\">Brian Ray</a></li>\n<li><a href=\"https://www.linkedin.com/in/jim-guszcza-5330375/\" rel=\"nofollow\">Jim Guszcza</a></li>\n</ul>\n<p>Please drop us a line in the issues section as bugs or feature requests arise.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 3762988, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "00a39b353d01a02ffb5329a106ab1325", "sha256": "cb89c1ae12e79bd2503c255ab728ce9adcfa3d442f2d15a8559bcf328c499fe4"}, "downloads": -1, "filename": "model-describer-0.1.1.tar.gz", "has_sig": false, "md5_digest": "00a39b353d01a02ffb5329a106ab1325", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 198648, "upload_time": "2018-03-07T01:47:25", "upload_time_iso_8601": "2018-03-07T01:47:25.860384Z", "url": "https://files.pythonhosted.org/packages/96/d2/16b68d4724adf44adddd582430133d25545b7308b427b8959076ba928e28/model-describer-0.1.1.tar.gz", "yanked": false}], "0.1.2.1": [{"comment_text": "", "digests": {"md5": "70ef4bbce7a860bc22fa9f85424517f6", "sha256": "9a9726814a8857c15bcdad3b9ec0b49fb0fc22e793f12caa9714f9f08b99c617"}, "downloads": -1, "filename": "model-describer-0.1.2.1.tar.gz", "has_sig": false, "md5_digest": "70ef4bbce7a860bc22fa9f85424517f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 190109, "upload_time": "2018-04-03T16:20:37", "upload_time_iso_8601": "2018-04-03T16:20:37.341838Z", "url": "https://files.pythonhosted.org/packages/f4/16/4139005890fd5fe82c4054f9fd058df5a84fb0f555b4d9cffb8ed39a83b9/model-describer-0.1.2.1.tar.gz", "yanked": false}], "0.1.2.2": [{"comment_text": "", "digests": {"md5": "7d81fb89408151302d2c5ff60b75e4a8", "sha256": "de9599d2fbe8f917b6347aa2a39a6727a0f2a9ffb02713626720d05ab2b7353a"}, "downloads": -1, "filename": "model-describer-0.1.2.2.tar.gz", "has_sig": false, "md5_digest": "7d81fb89408151302d2c5ff60b75e4a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 190147, "upload_time": "2018-04-13T19:54:08", "upload_time_iso_8601": "2018-04-13T19:54:08.765219Z", "url": "https://files.pythonhosted.org/packages/5d/86/9f4189427192904abb5bcce325fd2244cc8eef48232b159d9670ba1b4d06/model-describer-0.1.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7d81fb89408151302d2c5ff60b75e4a8", "sha256": "de9599d2fbe8f917b6347aa2a39a6727a0f2a9ffb02713626720d05ab2b7353a"}, "downloads": -1, "filename": "model-describer-0.1.2.2.tar.gz", "has_sig": false, "md5_digest": "7d81fb89408151302d2c5ff60b75e4a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 190147, "upload_time": "2018-04-13T19:54:08", "upload_time_iso_8601": "2018-04-13T19:54:08.765219Z", "url": "https://files.pythonhosted.org/packages/5d/86/9f4189427192904abb5bcce325fd2244cc8eef48232b159d9670ba1b4d06/model-describer-0.1.2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:55 2020"}