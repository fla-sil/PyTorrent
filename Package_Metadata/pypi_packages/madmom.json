{"info": {"author": "Department of Computational Perception, Johannes Kepler University, Linz, Austria and Austrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria", "author_email": "madmom-users@googlegroups.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "License :: Free for non-commercial use", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Multimedia :: Sound/Audio :: Analysis", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "======\nmadmom\n======\n\nMadmom is an audio signal processing library written in Python with a strong\nfocus on music information retrieval (MIR) tasks.\n\nThe library is internally used by the Department of Computational Perception,\nJohannes Kepler University, Linz, Austria (http://www.cp.jku.at) and the\nAustrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria\n(http://www.ofai.at).\n\nPossible acronyms are:\n\n- Madmom Analyzes Digitized Music Of Musicians\n- Mostly Audio / Dominantly Music Oriented Modules\n\nIt includes reference implementations for some music information retrieval\nalgorithms, please see the `References`_ section.\n\n\nDocumentation\n=============\n\nDocumentation of the package can be found online http://madmom.readthedocs.org\n\n\nLicense\n=======\n\nThe package has two licenses, one for source code and one for model/data files.\n\nSource code\n-----------\n\nUnless indicated otherwise, all source code files are published under the BSD\nlicense. For details, please see the `LICENSE <LICENSE>`_ file.\n\nModel and data files\n--------------------\n\nUnless indicated otherwise, all model and data files are distributed under the\n`Creative Commons Attribution-NonCommercial-ShareAlike 4.0\n<http://creativecommons.org/licenses/by-nc-sa/4.0/legalcode>`_ license.\n\nIf you want to include any of these files (or a variation or modification\nthereof) or technology which utilises them in a commercial product, please\ncontact `Gerhard Widmer <http://www.cp.jku.at/people/widmer/>`_.\n\n\nInstallation\n============\n\nPlease do not try to install from the .zip files provided by GitHub. Rather\ninstall it from package (if you just want to use it) or source (if you plan to\nuse it for development) by following the instructions below. Whichever variant\nyou choose, please make sure that all prerequisites are installed.\n\nPrerequisites\n-------------\n\nTo install the ``madmom`` package, you must have either Python 2.7 or Python\n3.3 or newer and the following packages installed:\n\n- `numpy <http://www.numpy.org>`_\n- `scipy <http://www.scipy.org>`_\n- `cython <http://www.cython.org>`_\n- `mido <https://github.com/olemb/mido>`_ (for MIDI handling)\n- `pytest <https://www.pytest.org/>`_ (to run the tests)\n- `pyaudio <http://people.csail.mit.edu/hubert/pyaudio/>`_ (to process live\n  audio input)\n- `pyfftw <https://github.com/pyFFTW/pyFFTW/>`_ (for better FFT performance)\n\nIf you need support for audio files other than ``.wav`` with a sample rate of\n44.1kHz and 16 bit depth, you need ``ffmpeg`` (``avconv`` on Ubuntu Linux has\nsome decoding bugs, so we advise not to use it!).\n\nPlease refer to the `requirements.txt <requirements.txt>`_ file for the minimum\nrequired versions and make sure that these modules are up to date, otherwise it\ncan result in unexpected errors or false computations!\n\nInstall from package\n--------------------\n\nThe instructions given here should be used if you just want to install the\npackage, e.g. to run the bundled programs or use some functionality for your\nown project. If you intend to change anything within the `madmom` package,\nplease follow the steps in the next section.\n\nThe easiest way to install the package is via ``pip`` from the `PyPI (Python\nPackage Index) <https://pypi.python.org/pypi>`_::\n\n    pip install madmom\n\nThis includes the latest code and trained models and will install all\ndependencies automatically.\n\nYou might need higher privileges (use su or sudo) to install the package, model\nfiles and scripts globally. Alternatively you can install the package locally\n(i.e. only for you) by adding the ``--user`` argument::\n\n    pip install --user madmom\n\nThis will also install the executable programs to a common place (e.g.\n``/usr/local/bin``), which should be in your ``$PATH`` already. If you\ninstalled the package locally, the programs will be copied to a folder which\nmight not be included in your ``$PATH`` (e.g. ``~/Library/Python/2.7/bin``\non Mac OS X or ``~/.local/bin`` on Ubuntu Linux, ``pip`` will tell you). Thus\nthe programs need to be called explicitely or you can add their install path\nto your ``$PATH`` environment variable::\n\n    export PATH='path/to/scripts':$PATH\n\nInstall from source\n-------------------\n\nIf you plan to use the package as a developer, clone the Git repository::\n\n    git clone --recursive https://github.com/CPJKU/madmom.git\n\nSince the pre-trained model/data files are not included in this repository but\nrather added as a Git submodule, you either have to clone the repo recursively.\nThis is equivalent to these steps::\n\n    git clone https://github.com/CPJKU/madmom.git\n    cd madmom\n    git submodule update --init --remote\n\nThen you can simply install the package in development mode::\n\n    python setup.py develop --user\n\nTo run the included tests::\n\n    python setup.py pytest\n\nUpgrade of existing installations\n---------------------------------\n\nTo upgrade the package, please use the same mechanism (pip vs. source) as you\ndid for installation. If you want to change from package to source, please\nuninstall the package first.\n\nUpgrade a package\n~~~~~~~~~~~~~~~~~\n\nSimply upgrade the package via pip::\n\n    pip install --upgrade madmom [--user]\n\nIf some of the provided programs or models changed (please refer to the\nCHANGELOG) you should first uninstall the package and then reinstall::\n\n    pip uninstall madmom\n    pip install madmom [--user]\n\nUpgrade from source\n~~~~~~~~~~~~~~~~~~~\n\nSimply pull the latest sources::\n\n    git pull\n\nTo update the models contained in the submodule::\n\n    git submodule update\n\nIf any of the ``.pyx`` or ``.pxd`` files changed, you have to recompile the\nmodules with Cython::\n\n    python setup.py build_ext --inplace\n\nPackage structure\n-----------------\n\nThe package has a very simple structure, divided into the following folders:\n\n`/bin <bin>`_\n  this folder includes example programs (i.e. executable algorithms)\n`/docs <docs>`_\n  package documentation\n`/madmom <madmom>`_\n  the actual Python package\n`/madmom/audio <madmom/audio>`_\n  low level features (e.g. audio file handling, STFT)\n`/madmom/evaluation <madmom/evaluation>`_\n  evaluation code\n`/madmom/features <madmom/features>`_\n  higher level features (e.g. onsets, beats)\n`/madmom/ml <madmom/ml>`_\n  machine learning stuff (e.g. RNNs, HMMs)\n`/madmom/models <../../../madmom_models>`_\n  pre-trained model/data files (see the License section)\n`/madmom/utils <madmom/utils>`_\n  misc stuff (e.g. MIDI and general file handling)\n`/tests <tests>`_\n  tests\n\nExecutable programs\n-------------------\n\nThe package includes executable programs in the `/bin <bin>`_ folder.\nIf you installed the package, they were copied to a common place.\n\nAll scripts can be run in different modes: in ``single`` file mode to process\na single audio file and write the output to STDOUT or the given output file::\n\n    DBNBeatTracker single [-o OUTFILE] INFILE\n\nIf multiple audio files should be processed, the scripts can also be run in\n``batch`` mode to write the outputs to files with the given suffix::\n\n    DBNBeatTracker batch [-o OUTPUT_DIR] [-s OUTPUT_SUFFIX] FILES\n\nIf no output directory is given, the program writes the output files to the\nsame location as the audio files.\n\nSome programs can also be run in ``online`` mode, i.e. operate on live audio\nsignals. This requires `pyaudio <http://people.csail.mit.edu/hubert/pyaudio/>`_\nto be installed::\n\n    DBNBeatTracker online [-o OUTFILE] [INFILE]\n\nThe ``pickle`` mode can be used to store the used parameters to be able to\nexactly reproduce experiments.\n\nPlease note that the program itself as well as the modes have help messages::\n\n    DBNBeatTracker -h\n\n    DBNBeatTracker single -h\n\n    DBNBeatTracker batch -h\n\n    DBNBeatTracker online -h\n\n    DBNBeatTracker pickle -h\n\nwill give different help messages.\n\n\nAdditional resources\n====================\n\nMailing list\n------------\n\nThe `mailing list <https://groups.google.com/d/forum/madmom-users>`_ should be\nused to get in touch with the developers and other users.\n\nWiki\n----\n\nThe wiki can be found here: https://github.com/CPJKU/madmom/wiki\n\nFAQ\n---\n\nFrequently asked questions can be found here:\nhttps://github.com/CPJKU/madmom/wiki/FAQ\n\nCitation\n========\n\nIf you use madmom in your work, please consider citing it:\n\n.. code-block:: latex\n\n   @inproceedings{madmom,\n      Title = {{madmom: a new Python Audio and Music Signal Processing Library}},\n      Author = {B{\\\"o}ck, Sebastian and Korzeniowski, Filip and Schl{\\\"u}ter, Jan and Krebs, Florian and Widmer, Gerhard},\n      Booktitle = {Proceedings of the 24th ACM International Conference on\n      Multimedia},\n      Month = {10},\n      Year = {2016},\n      Pages = {1174--1178},\n      Address = {Amsterdam, The Netherlands},\n      Doi = {10.1145/2964284.2973795}\n   }\n\nReferences\n==========\n\n.. [1] Florian Eyben, Sebastian B\u00f6ck, Bj\u00f6rn Schuller and Alex Graves,\n    *Universal Onset Detection with bidirectional Long Short-Term Memory\n    Neural Networks*,\n    Proceedings of the 11th International Society for Music Information\n    Retrieval Conference (ISMIR), 2010.\n.. [2] Sebastian B\u00f6ck and Markus Schedl,\n    *Enhanced Beat Tracking with Context-Aware Neural Networks*,\n    Proceedings of the 14th International Conference on Digital Audio Effects\n    (DAFx), 2011.\n.. [3] Sebastian B\u00f6ck and Markus Schedl,\n    *Polyphonic Piano Note Transcription with Recurrent Neural Networks*,\n    Proceedings of the 37th International Conference on Acoustics, Speech and\n    Signal Processing (ICASSP), 2012.\n.. [4] Sebastian B\u00f6ck, Andreas Arzt, Florian Krebs and Markus Schedl,\n    *Online Real-time Onset Detection with Recurrent Neural Networks*,\n    Proceedings of the 15th International Conference on Digital Audio Effects\n    (DAFx), 2012.\n.. [5] Sebastian B\u00f6ck, Florian Krebs and Markus Schedl,\n    *Evaluating the Online Capabilities of Onset Detection Methods*,\n    Proceedings of the 13th International Society for Music Information\n    Retrieval Conference (ISMIR), 2012.\n.. [6] Sebastian B\u00f6ck and Gerhard Widmer,\n    *Maximum Filter Vibrato Suppression for Onset Detection*,\n    Proceedings of the 16th International Conference on Digital Audio Effects\n    (DAFx), 2013.\n.. [7] Sebastian B\u00f6ck and Gerhard Widmer,\n    *Local Group Delay based Vibrato and Tremolo Suppression for Onset\n    Detection*,\n    Proceedings of the 13th International Society for Music Information\n    Retrieval Conference (ISMIR), 2013.\n.. [8] Florian Krebs, Sebastian B\u00f6ck and Gerhard Widmer,\n    *Rhythmic Pattern Modelling for Beat and Downbeat Tracking in Musical\n    Audio*,\n    Proceedings of the 14th International Society for Music Information\n    Retrieval Conference (ISMIR), 2013.\n.. [9] Sebastian B\u00f6ck, Jan Schl\u00fcter and Gerhard Widmer,\n    *Enhanced Peak Picking for Onset Detection with Recurrent Neural Networks*,\n    Proceedings of the 6th International Workshop on Machine Learning and\n    Music (MML), 2013.\n.. [10] Sebastian B\u00f6ck, Florian Krebs and Gerhard Widmer,\n    *A Multi-Model Approach to Beat Tracking Considering Heterogeneous Music\n    Styles*,\n    Proceedings of the 15th International Society for Music Information\n    Retrieval Conference (ISMIR), 2014.\n.. [11] Filip Korzeniowski, Sebastian B\u00f6ck and Gerhard Widmer,\n    *Probabilistic Extraction of Beat Positions from a Beat Activation\n    Function*,\n    Proceedings of the 15th International Society for Music Information\n    Retrieval Conference (ISMIR), 2014.\n.. [12] Sebastian B\u00f6ck, Florian Krebs and Gerhard Widmer,\n    *Accurate Tempo Estimation based on Recurrent Neural Networks and\n    Resonating Comb Filters*,\n    Proceedings of the 16th International Society for Music Information\n    Retrieval Conference (ISMIR), 2015.\n.. [13] Florian Krebs, Sebastian B\u00f6ck and Gerhard Widmer,\n    *An Efficient State Space Model for Joint Tempo and Meter Tracking*,\n    Proceedings of the 16th International Society for Music Information\n    Retrieval Conference (ISMIR), 2015.\n.. [14] Sebastian B\u00f6ck, Florian Krebs and Gerhard Widmer,\n    *Joint Beat and Downbeat Tracking with Recurrent Neural Networks*,\n    Proceedings of the 17th International Society for Music Information\n    Retrieval Conference (ISMIR), 2016.\n.. [15] Filip Korzeniowski and Gerhard Widmer,\n    *Feature Learning for Chord Recognition: The Deep Chroma Extractor*,\n    Proceedings of the 17th International Society for Music Information\n    Retrieval Conference (ISMIR), 2016.\n.. [16] Florian Krebs, Sebastian B\u00f6ck, Matthias Dorfer and Gerhard Widmer,\n    *Downbeat Tracking Using Beat-Synchronous Features and Recurrent Networks*,\n    Proceedings of the 17th International Society for Music Information\n    Retrieval Conference (ISMIR), 2016.\n.. [17] Filip Korzeniowski and Gerhard Widmer,\n    *A Fully Convolutional Deep Auditory Model for Musical Chord Recognition*,\n    Proceedings of IEEE International Workshop on Machine Learning for Signal\n    Processing (MLSP), 2016.\n.. [18] Filip Korzeniowski and Gerhard Widmer,\n    *Genre-Agnostic Key Classification with Convolutional Neural Networks*,\n    Proceedings of the 19th International Society for Music Information\n    Retrieval Conference (ISMIR), 2018.\n\nAcknowledgements\n================\n\nSupported by the European Commission through the `GiantSteps project\n<http://www.giantsteps-project.eu>`_ (FP7 grant agreement no. 610591) and the\n`Phenicx project <http://phenicx.upf.edu>`_ (FP7 grant agreement no. 601166)\nas well as the `Austrian Science Fund (FWF) <https://www.fwf.ac.at>`_ project\nZ159.\n\nRelease Notes\n=============\n\nVersion 0.16.1 (release date: 2017-11-14)\n-----------------------------------------\n\nThis is a maintenance release.\n\n* Include .pyx files in source distribution\n\nVersion 0.16 (release date: 2017-11-13)\n---------------------------------------\n\nNew features:\n\n* `TempoDetector` can operate on live audio signals  (#292)\n* Added chord evaluation (#309)\n* Bar tracking functionality (#316)\n* Added `quantize_notes` function (#327)\n* Added global key evaluation (#336)\n* Added key recognition feature and program (#345, #381)\n\nBug fixes:\n\n* Fix `TransitionModel` number of states when last state is unreachable (#287)\n* Fix double beat detections in `BeatTrackingProcessor` (#298)\n* Fix ffmpeg unicode filename handling (#305)\n* Fix STFT zero padding (#319)\n* Fix memory leak when accessing signal frames (#322)\n* Quantization of events does not alter them (#327)\n\nAPI relevant changes:\n\n* `BufferProcessor` uses `data` instead of `buffer` for data storage (#292)\n* `DBNBeatTrackingProcessor` expects 1D inputs (#299)\n* Moved downbeat and pattern tracking to `features.downbeats` (#316)\n* Write/load functions moved to `io` module (#346)\n* Write functions do not return any data (#346)\n* Evaluation classes expect annotations/detections, cannot handle files (#346)\n* New MIDI module (io.midi) replacing (utils.midi) based on mido (#46)\n\nOther changes:\n\n* Viterbi decoding of `HMM` raises a warning if no valid path is found (#279)\n* Add option to include Nyquist frequency in `STFT` (#280)\n* Use `pyfftw` to compute FFT (#363)\n* Python 3.7 support (#374)\n* Use pytest instead of nose to run tests (#385)\n* Removed obsolete code (#385)\n\n\nVersion 0.15.1 (release date: 2017-07-07)\n-----------------------------------------\n\nThis is a maintenance release.\n\n* NumPy boolean subtract fix (#296)\n\n\nVersion 0.15 (release date: 2017-04-25)\n---------------------------------------\n\nNew features:\n\n* Streaming mode allows framewise processing of live audio input (#185)\n* Exponential linear unit (ELU) activation function (#232)\n* `DBNBeatTracker` can operate on live audio signals (#238)\n* `OnsetDetectorLL` can operate on live audio signals (#256)\n\nBug fixes:\n\n* Fix downbeat evaluation failure with a single annotation / detection (#216)\n* Fix tempo handling of multi-track MIDI files (#219)\n* Fix error loading unicode filenames (#223)\n* Fix ffmpeg unicode filename handling (#236)\n* Fix smoothing for `peak_picking` (#247)\n* Fix combining onsets/notes (#255)\n\nAPI relevant changes:\n\n* `NeuralNetwork` expect 2D inputs; activation can be computed stepwise (#244)\n* Reorder `GRUCell` parameters, to be consistent with all other layers (#243)\n* Rename `GRULayer` parameters, to be consistent with all other layers (#243)\n\nOther changes:\n\n* SPL and RMS can be computed on `Signal` and `FramedSignal` (#208)\n* `num_threads` is passed to `ParallelProcessor` in single mode (#217)\n* Use `install_requires` in `setup.py` to specify dependencies (#226)\n* Use new Cython build system to build extensions (#227)\n* Allow initialisation of previous/hidden states in RNNs (#243)\n* Forward path of `HMM` can be computed stepwise (#244)\n\n\nVersion 0.14.1 (release date: 2016-08-01)\n-----------------------------------------\n\nThis is a maintenance release.\n\n* `RNNDownBeatProcessor` returns only beat and downbeat activations (#197)\n* Update programs to reflect MIREX 2016 submissions (#198)\n\nVersion 0.14 (release date: 2016-07-28)\n---------------------------------------\n\nNew features:\n\n* Downbeat tracking based on Recurrent Neural Network (RNN) and Dynamic\n  Bayesian Network (DBN) (#130)\n* Convolutional Neural Networks (CNN) and CNN onset detection (#133)\n* Linear-Chain Conditional Random Field (CRF) implementation (#144)\n* Deep Neural Network (DNN) based chroma vector extraction (#148)\n* CRF chord recognition using DNN chroma vectors (#148)\n* CNN chord recognition using CRF decoding (#152)\n* Initial Windows support (Python 2.7 only, no pip packages yet) (#157)\n* Gated Recurrent Unit (GRU) network layer (#167)\n\nBug fixes:\n\n* Fix downbeat output bug (#128)\n* MIDI file creation bug (#166)\n\nAPI relevant changes:\n\n* Refactored the `ml.rnn` to `ml.nn` and converted the models to pickles (#110)\n* Reordered the dimensions of comb_filters to time, freq, tau (#135)\n* `write_notes` uses `delimiter` instead of `sep` to separate columns (#155)\n* `LSTMLayer` takes `Gate` as arguments, all layers are callable (#161)\n* Replaced `online` parameter of `FramedSignalProcessor` by `origin` (#169)\n\nOther changes:\n\n* Added classes for onset/note/beat detection with RNNs to `features.*` (#118)\n* Add examples to docstrings of classes (#119)\n* Converted `madmom.modules` into a Python package (#125)\n* `match_files` can handle inexact matches (#137)\n* Updated beat tracking models to MIREX 2015 ones (#146)\n* Tempo and time signature can be set for created MIDI files (#166)\n\n\nVersion 0.13.2 (release date: 2016-06-09)\n-----------------------------------------\n\nThis is a bugfix release.\n\n* Fix custom filterbank in FilteredSpectrogram (#142)\n\nVersion 0.13.1 (release date: 2016-03-14)\n-----------------------------------------\n\nThis is a bugfix release.\n\n* Fix beat evaluation argument parsing (#116)\n\nVersion 0.13 (release date: 2016-03-07)\n---------------------------------------\n\nNew features:\n\n* Python 3 support (3.3+) (#15)\n* Online documentation available at http://madmom.readthedocs.org (#60)\n\nBug fixes:\n\n* Fix nasty unsigned indexing bug (#88)\n* MIDI note timing could get corrupted if `note_ticks_to_beats()` was called\n  multiple times (#90)\n\nAPI relevant changes:\n\n* Renamed `DownBeatTracker` and all relevant classes to `PatternTracker` (#25)\n* Complete refactoring of the `features.beats_hmm` module (#52)\n* Unified negative index behaviour of `FramedSignal` (#72)\n* Removed pickling of data classes since it was not tested thoroughly (#81)\n* Reworked stacking of spectrogram differences (#82)\n* Renamed `norm_bands` argument of `MultiBandSpectrogram` to `norm_filters`\n  (#83)\n\nOther changes:\n\n* Added alignment evaluation (#12)\n* Added continuous integration testing (#16)\n* Added `-o` option to both `single`/`batch` processing mode to not overwrite\n  files accidentally in `single` mode (#18)\n* Removed `block_size` parameter from `FilteredSpectrogram` (#22)\n* Sample rate is always integer (#23)\n* Converted all docstrings to the numpydoc format (#48)\n* Batch processing continues if non-audio files are given (#53)\n* Added code quality checks (#61)\n* Added coverage measuring (#74)\n* Added `--down`` option to evaluate only downbeats (#76)\n* Removed option to normalise the observations (#95)\n* Moved filterbank related argument parser to `FilterbankProcessor` (#96)\n\nVersion 0.12.1 (release date: 2016-01-22)\n-----------------------------------------\n\nAdded Python 3 compatibility to setup.py (needed for the tutorials to work)\n\nVersion 0.12 (release date: 2015-10-16)\n---------------------------------------\n\nInitial public release of madmom", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/CPJKU/madmom", "keywords": "", "license": "BSD, CC BY-NC-SA", "maintainer": "", "maintainer_email": "", "name": "madmom", "package_url": "https://pypi.org/project/madmom/", "platform": "", "project_url": "https://pypi.org/project/madmom/", "project_urls": {"Homepage": "https://github.com/CPJKU/madmom"}, "release_url": "https://pypi.org/project/madmom/0.16.1/", "requires_dist": null, "requires_python": "", "summary": "Python audio signal processing library", "version": "0.16.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Madmom is an audio signal processing library written in Python with a strong\nfocus on music information retrieval (MIR) tasks.</p>\n<p>The library is internally used by the Department of Computational Perception,\nJohannes Kepler University, Linz, Austria (<a href=\"http://www.cp.jku.at\" rel=\"nofollow\">http://www.cp.jku.at</a>) and the\nAustrian Research Institute for Artificial Intelligence (OFAI), Vienna, Austria\n(<a href=\"http://www.ofai.at\" rel=\"nofollow\">http://www.ofai.at</a>).</p>\n<p>Possible acronyms are:</p>\n<ul>\n<li>Madmom Analyzes Digitized Music Of Musicians</li>\n<li>Mostly Audio / Dominantly Music Oriented Modules</li>\n</ul>\n<p>It includes reference implementations for some music information retrieval\nalgorithms, please see the <a href=\"#references\" rel=\"nofollow\">References</a> section.</p>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>Documentation of the package can be found online <a href=\"http://madmom.readthedocs.org\" rel=\"nofollow\">http://madmom.readthedocs.org</a></p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>The package has two licenses, one for source code and one for model/data files.</p>\n<div id=\"source-code\">\n<h3>Source code</h3>\n<p>Unless indicated otherwise, all source code files are published under the BSD\nlicense. For details, please see the <a href=\"LICENSE\" rel=\"nofollow\">LICENSE</a> file.</p>\n</div>\n<div id=\"model-and-data-files\">\n<h3>Model and data files</h3>\n<p>Unless indicated otherwise, all model and data files are distributed under the\n<a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/legalcode\" rel=\"nofollow\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0</a> license.</p>\n<p>If you want to include any of these files (or a variation or modification\nthereof) or technology which utilises them in a commercial product, please\ncontact <a href=\"http://www.cp.jku.at/people/widmer/\" rel=\"nofollow\">Gerhard Widmer</a>.</p>\n</div>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Please do not try to install from the .zip files provided by GitHub. Rather\ninstall it from package (if you just want to use it) or source (if you plan to\nuse it for development) by following the instructions below. Whichever variant\nyou choose, please make sure that all prerequisites are installed.</p>\n<div id=\"prerequisites\">\n<h3>Prerequisites</h3>\n<p>To install the <tt>madmom</tt> package, you must have either Python 2.7 or Python\n3.3 or newer and the following packages installed:</p>\n<ul>\n<li><a href=\"http://www.numpy.org\" rel=\"nofollow\">numpy</a></li>\n<li><a href=\"http://www.scipy.org\" rel=\"nofollow\">scipy</a></li>\n<li><a href=\"http://www.cython.org\" rel=\"nofollow\">cython</a></li>\n<li><a href=\"https://github.com/olemb/mido\" rel=\"nofollow\">mido</a> (for MIDI handling)</li>\n<li><a href=\"https://www.pytest.org/\" rel=\"nofollow\">pytest</a> (to run the tests)</li>\n<li><a href=\"http://people.csail.mit.edu/hubert/pyaudio/\" rel=\"nofollow\">pyaudio</a> (to process live\naudio input)</li>\n<li><a href=\"https://github.com/pyFFTW/pyFFTW/\" rel=\"nofollow\">pyfftw</a> (for better FFT performance)</li>\n</ul>\n<p>If you need support for audio files other than <tt>.wav</tt> with a sample rate of\n44.1kHz and 16 bit depth, you need <tt>ffmpeg</tt> (<tt>avconv</tt> on Ubuntu Linux has\nsome decoding bugs, so we advise not to use it!).</p>\n<p>Please refer to the <a href=\"requirements.txt\" rel=\"nofollow\">requirements.txt</a> file for the minimum\nrequired versions and make sure that these modules are up to date, otherwise it\ncan result in unexpected errors or false computations!</p>\n</div>\n<div id=\"install-from-package\">\n<h3>Install from package</h3>\n<p>The instructions given here should be used if you just want to install the\npackage, e.g. to run the bundled programs or use some functionality for your\nown project. If you intend to change anything within the <cite>madmom</cite> package,\nplease follow the steps in the next section.</p>\n<p>The easiest way to install the package is via <tt>pip</tt> from the <a href=\"https://pypi.python.org/pypi\" rel=\"nofollow\">PyPI (Python\nPackage Index)</a>:</p>\n<pre>pip install madmom\n</pre>\n<p>This includes the latest code and trained models and will install all\ndependencies automatically.</p>\n<p>You might need higher privileges (use su or sudo) to install the package, model\nfiles and scripts globally. Alternatively you can install the package locally\n(i.e. only for you) by adding the <tt><span class=\"pre\">--user</span></tt> argument:</p>\n<pre>pip install --user madmom\n</pre>\n<p>This will also install the executable programs to a common place (e.g.\n<tt>/usr/local/bin</tt>), which should be in your <tt>$PATH</tt> already. If you\ninstalled the package locally, the programs will be copied to a folder which\nmight not be included in your <tt>$PATH</tt> (e.g. <tt>~/Library/Python/2.7/bin</tt>\non Mac OS X or <tt><span class=\"pre\">~/.local/bin</span></tt> on Ubuntu Linux, <tt>pip</tt> will tell you). Thus\nthe programs need to be called explicitely or you can add their install path\nto your <tt>$PATH</tt> environment variable:</p>\n<pre>export PATH='path/to/scripts':$PATH\n</pre>\n</div>\n<div id=\"install-from-source\">\n<h3>Install from source</h3>\n<p>If you plan to use the package as a developer, clone the Git repository:</p>\n<pre>git clone --recursive https://github.com/CPJKU/madmom.git\n</pre>\n<p>Since the pre-trained model/data files are not included in this repository but\nrather added as a Git submodule, you either have to clone the repo recursively.\nThis is equivalent to these steps:</p>\n<pre>git clone https://github.com/CPJKU/madmom.git\ncd madmom\ngit submodule update --init --remote\n</pre>\n<p>Then you can simply install the package in development mode:</p>\n<pre>python setup.py develop --user\n</pre>\n<p>To run the included tests:</p>\n<pre>python setup.py pytest\n</pre>\n</div>\n<div id=\"upgrade-of-existing-installations\">\n<h3>Upgrade of existing installations</h3>\n<p>To upgrade the package, please use the same mechanism (pip vs. source) as you\ndid for installation. If you want to change from package to source, please\nuninstall the package first.</p>\n<div id=\"upgrade-a-package\">\n<h4>Upgrade a package</h4>\n<p>Simply upgrade the package via pip:</p>\n<pre>pip install --upgrade madmom [--user]\n</pre>\n<p>If some of the provided programs or models changed (please refer to the\nCHANGELOG) you should first uninstall the package and then reinstall:</p>\n<pre>pip uninstall madmom\npip install madmom [--user]\n</pre>\n</div>\n<div id=\"upgrade-from-source\">\n<h4>Upgrade from source</h4>\n<p>Simply pull the latest sources:</p>\n<pre>git pull\n</pre>\n<p>To update the models contained in the submodule:</p>\n<pre>git submodule update\n</pre>\n<p>If any of the <tt>.pyx</tt> or <tt>.pxd</tt> files changed, you have to recompile the\nmodules with Cython:</p>\n<pre>python setup.py build_ext --inplace\n</pre>\n</div>\n</div>\n<div id=\"package-structure\">\n<h3>Package structure</h3>\n<p>The package has a very simple structure, divided into the following folders:</p>\n<dl>\n<dt><a href=\"bin\" rel=\"nofollow\">/bin</a></dt>\n<dd>this folder includes example programs (i.e. executable algorithms)</dd>\n<dt><a href=\"docs\" rel=\"nofollow\">/docs</a></dt>\n<dd>package documentation</dd>\n<dt><a href=\"madmom\" rel=\"nofollow\">/madmom</a></dt>\n<dd>the actual Python package</dd>\n<dt><a href=\"madmom/audio\" rel=\"nofollow\">/madmom/audio</a></dt>\n<dd>low level features (e.g. audio file handling, STFT)</dd>\n<dt><a href=\"madmom/evaluation\" rel=\"nofollow\">/madmom/evaluation</a></dt>\n<dd>evaluation code</dd>\n<dt><a href=\"madmom/features\" rel=\"nofollow\">/madmom/features</a></dt>\n<dd>higher level features (e.g. onsets, beats)</dd>\n<dt><a href=\"madmom/ml\" rel=\"nofollow\">/madmom/ml</a></dt>\n<dd>machine learning stuff (e.g. RNNs, HMMs)</dd>\n<dt><a href=\"../../../madmom_models\" rel=\"nofollow\">/madmom/models</a></dt>\n<dd>pre-trained model/data files (see the License section)</dd>\n<dt><a href=\"madmom/utils\" rel=\"nofollow\">/madmom/utils</a></dt>\n<dd>misc stuff (e.g. MIDI and general file handling)</dd>\n<dt><a href=\"tests\" rel=\"nofollow\">/tests</a></dt>\n<dd>tests</dd>\n</dl>\n</div>\n<div id=\"executable-programs\">\n<h3>Executable programs</h3>\n<p>The package includes executable programs in the <a href=\"bin\" rel=\"nofollow\">/bin</a> folder.\nIf you installed the package, they were copied to a common place.</p>\n<p>All scripts can be run in different modes: in <tt>single</tt> file mode to process\na single audio file and write the output to STDOUT or the given output file:</p>\n<pre>DBNBeatTracker single [-o OUTFILE] INFILE\n</pre>\n<p>If multiple audio files should be processed, the scripts can also be run in\n<tt>batch</tt> mode to write the outputs to files with the given suffix:</p>\n<pre>DBNBeatTracker batch [-o OUTPUT_DIR] [-s OUTPUT_SUFFIX] FILES\n</pre>\n<p>If no output directory is given, the program writes the output files to the\nsame location as the audio files.</p>\n<p>Some programs can also be run in <tt>online</tt> mode, i.e. operate on live audio\nsignals. This requires <a href=\"http://people.csail.mit.edu/hubert/pyaudio/\" rel=\"nofollow\">pyaudio</a>\nto be installed:</p>\n<pre>DBNBeatTracker online [-o OUTFILE] [INFILE]\n</pre>\n<p>The <tt>pickle</tt> mode can be used to store the used parameters to be able to\nexactly reproduce experiments.</p>\n<p>Please note that the program itself as well as the modes have help messages:</p>\n<pre>DBNBeatTracker -h\n\nDBNBeatTracker single -h\n\nDBNBeatTracker batch -h\n\nDBNBeatTracker online -h\n\nDBNBeatTracker pickle -h\n</pre>\n<p>will give different help messages.</p>\n</div>\n</div>\n<div id=\"additional-resources\">\n<h2>Additional resources</h2>\n<div id=\"mailing-list\">\n<h3>Mailing list</h3>\n<p>The <a href=\"https://groups.google.com/d/forum/madmom-users\" rel=\"nofollow\">mailing list</a> should be\nused to get in touch with the developers and other users.</p>\n</div>\n<div id=\"wiki\">\n<h3>Wiki</h3>\n<p>The wiki can be found here: <a href=\"https://github.com/CPJKU/madmom/wiki\" rel=\"nofollow\">https://github.com/CPJKU/madmom/wiki</a></p>\n</div>\n<div id=\"faq\">\n<h3>FAQ</h3>\n<p>Frequently asked questions can be found here:\n<a href=\"https://github.com/CPJKU/madmom/wiki/FAQ\" rel=\"nofollow\">https://github.com/CPJKU/madmom/wiki/FAQ</a></p>\n</div>\n</div>\n<div id=\"citation\">\n<h2>Citation</h2>\n<p>If you use madmom in your work, please consider citing it:</p>\n<pre>@inproceedings<span class=\"nb\">{</span>madmom,\n   Title = <span class=\"nb\">{{</span>madmom: a new Python Audio and Music Signal Processing Library<span class=\"nb\">}}</span>,\n   Author = <span class=\"nb\">{</span>B<span class=\"nb\">{</span><span class=\"k\">\\\"</span>o<span class=\"nb\">}</span>ck, Sebastian and Korzeniowski, Filip and Schl<span class=\"nb\">{</span><span class=\"k\">\\\"</span>u<span class=\"nb\">}</span>ter, Jan and Krebs, Florian and Widmer, Gerhard<span class=\"nb\">}</span>,\n   Booktitle = <span class=\"nb\">{</span>Proceedings of the 24th ACM International Conference on\n   Multimedia<span class=\"nb\">}</span>,\n   Month = <span class=\"nb\">{</span>10<span class=\"nb\">}</span>,\n   Year = <span class=\"nb\">{</span>2016<span class=\"nb\">}</span>,\n   Pages = <span class=\"nb\">{</span>1174--1178<span class=\"nb\">}</span>,\n   Address = <span class=\"nb\">{</span>Amsterdam, The Netherlands<span class=\"nb\">}</span>,\n   Doi = <span class=\"nb\">{</span>10.1145/2964284.2973795<span class=\"nb\">}</span>\n<span class=\"nb\">}</span>\n</pre>\n</div>\n<div id=\"references\">\n<h2>References</h2>\n<table id=\"id6\">\n<col><col>\n<tbody>\n<tr><td>[1]</td><td>Florian Eyben, Sebastian B\u00f6ck, Bj\u00f6rn Schuller and Alex Graves,\n<em>Universal Onset Detection with bidirectional Long Short-Term Memory\nNeural Networks</em>,\nProceedings of the 11th International Society for Music Information\nRetrieval Conference (ISMIR), 2010.</td></tr>\n</tbody>\n</table>\n<table id=\"id7\">\n<col><col>\n<tbody>\n<tr><td>[2]</td><td>Sebastian B\u00f6ck and Markus Schedl,\n<em>Enhanced Beat Tracking with Context-Aware Neural Networks</em>,\nProceedings of the 14th International Conference on Digital Audio Effects\n(DAFx), 2011.</td></tr>\n</tbody>\n</table>\n<table id=\"id8\">\n<col><col>\n<tbody>\n<tr><td>[3]</td><td>Sebastian B\u00f6ck and Markus Schedl,\n<em>Polyphonic Piano Note Transcription with Recurrent Neural Networks</em>,\nProceedings of the 37th International Conference on Acoustics, Speech and\nSignal Processing (ICASSP), 2012.</td></tr>\n</tbody>\n</table>\n<table id=\"id9\">\n<col><col>\n<tbody>\n<tr><td>[4]</td><td>Sebastian B\u00f6ck, Andreas Arzt, Florian Krebs and Markus Schedl,\n<em>Online Real-time Onset Detection with Recurrent Neural Networks</em>,\nProceedings of the 15th International Conference on Digital Audio Effects\n(DAFx), 2012.</td></tr>\n</tbody>\n</table>\n<table id=\"id10\">\n<col><col>\n<tbody>\n<tr><td>[5]</td><td>Sebastian B\u00f6ck, Florian Krebs and Markus Schedl,\n<em>Evaluating the Online Capabilities of Onset Detection Methods</em>,\nProceedings of the 13th International Society for Music Information\nRetrieval Conference (ISMIR), 2012.</td></tr>\n</tbody>\n</table>\n<table id=\"id11\">\n<col><col>\n<tbody>\n<tr><td>[6]</td><td>Sebastian B\u00f6ck and Gerhard Widmer,\n<em>Maximum Filter Vibrato Suppression for Onset Detection</em>,\nProceedings of the 16th International Conference on Digital Audio Effects\n(DAFx), 2013.</td></tr>\n</tbody>\n</table>\n<table id=\"id12\">\n<col><col>\n<tbody>\n<tr><td>[7]</td><td>Sebastian B\u00f6ck and Gerhard Widmer,\n<em>Local Group Delay based Vibrato and Tremolo Suppression for Onset\nDetection</em>,\nProceedings of the 13th International Society for Music Information\nRetrieval Conference (ISMIR), 2013.</td></tr>\n</tbody>\n</table>\n<table id=\"id13\">\n<col><col>\n<tbody>\n<tr><td>[8]</td><td>Florian Krebs, Sebastian B\u00f6ck and Gerhard Widmer,\n<em>Rhythmic Pattern Modelling for Beat and Downbeat Tracking in Musical\nAudio</em>,\nProceedings of the 14th International Society for Music Information\nRetrieval Conference (ISMIR), 2013.</td></tr>\n</tbody>\n</table>\n<table id=\"id14\">\n<col><col>\n<tbody>\n<tr><td>[9]</td><td>Sebastian B\u00f6ck, Jan Schl\u00fcter and Gerhard Widmer,\n<em>Enhanced Peak Picking for Onset Detection with Recurrent Neural Networks</em>,\nProceedings of the 6th International Workshop on Machine Learning and\nMusic (MML), 2013.</td></tr>\n</tbody>\n</table>\n<table id=\"id15\">\n<col><col>\n<tbody>\n<tr><td>[10]</td><td>Sebastian B\u00f6ck, Florian Krebs and Gerhard Widmer,\n<em>A Multi-Model Approach to Beat Tracking Considering Heterogeneous Music\nStyles</em>,\nProceedings of the 15th International Society for Music Information\nRetrieval Conference (ISMIR), 2014.</td></tr>\n</tbody>\n</table>\n<table id=\"id16\">\n<col><col>\n<tbody>\n<tr><td>[11]</td><td>Filip Korzeniowski, Sebastian B\u00f6ck and Gerhard Widmer,\n<em>Probabilistic Extraction of Beat Positions from a Beat Activation\nFunction</em>,\nProceedings of the 15th International Society for Music Information\nRetrieval Conference (ISMIR), 2014.</td></tr>\n</tbody>\n</table>\n<table id=\"id17\">\n<col><col>\n<tbody>\n<tr><td>[12]</td><td>Sebastian B\u00f6ck, Florian Krebs and Gerhard Widmer,\n<em>Accurate Tempo Estimation based on Recurrent Neural Networks and\nResonating Comb Filters</em>,\nProceedings of the 16th International Society for Music Information\nRetrieval Conference (ISMIR), 2015.</td></tr>\n</tbody>\n</table>\n<table id=\"id18\">\n<col><col>\n<tbody>\n<tr><td>[13]</td><td>Florian Krebs, Sebastian B\u00f6ck and Gerhard Widmer,\n<em>An Efficient State Space Model for Joint Tempo and Meter Tracking</em>,\nProceedings of the 16th International Society for Music Information\nRetrieval Conference (ISMIR), 2015.</td></tr>\n</tbody>\n</table>\n<table id=\"id19\">\n<col><col>\n<tbody>\n<tr><td>[14]</td><td>Sebastian B\u00f6ck, Florian Krebs and Gerhard Widmer,\n<em>Joint Beat and Downbeat Tracking with Recurrent Neural Networks</em>,\nProceedings of the 17th International Society for Music Information\nRetrieval Conference (ISMIR), 2016.</td></tr>\n</tbody>\n</table>\n<table id=\"id20\">\n<col><col>\n<tbody>\n<tr><td>[15]</td><td>Filip Korzeniowski and Gerhard Widmer,\n<em>Feature Learning for Chord Recognition: The Deep Chroma Extractor</em>,\nProceedings of the 17th International Society for Music Information\nRetrieval Conference (ISMIR), 2016.</td></tr>\n</tbody>\n</table>\n<table id=\"id21\">\n<col><col>\n<tbody>\n<tr><td>[16]</td><td>Florian Krebs, Sebastian B\u00f6ck, Matthias Dorfer and Gerhard Widmer,\n<em>Downbeat Tracking Using Beat-Synchronous Features and Recurrent Networks</em>,\nProceedings of the 17th International Society for Music Information\nRetrieval Conference (ISMIR), 2016.</td></tr>\n</tbody>\n</table>\n<table id=\"id22\">\n<col><col>\n<tbody>\n<tr><td>[17]</td><td>Filip Korzeniowski and Gerhard Widmer,\n<em>A Fully Convolutional Deep Auditory Model for Musical Chord Recognition</em>,\nProceedings of IEEE International Workshop on Machine Learning for Signal\nProcessing (MLSP), 2016.</td></tr>\n</tbody>\n</table>\n<table id=\"id23\">\n<col><col>\n<tbody>\n<tr><td>[18]</td><td>Filip Korzeniowski and Gerhard Widmer,\n<em>Genre-Agnostic Key Classification with Convolutional Neural Networks</em>,\nProceedings of the 19th International Society for Music Information\nRetrieval Conference (ISMIR), 2018.</td></tr>\n</tbody>\n</table>\n</div>\n<div id=\"acknowledgements\">\n<h2>Acknowledgements</h2>\n<p>Supported by the European Commission through the <a href=\"http://www.giantsteps-project.eu\" rel=\"nofollow\">GiantSteps project</a> (FP7 grant agreement no. 610591) and the\n<a href=\"http://phenicx.upf.edu\" rel=\"nofollow\">Phenicx project</a> (FP7 grant agreement no. 601166)\nas well as the <a href=\"https://www.fwf.ac.at\" rel=\"nofollow\">Austrian Science Fund (FWF)</a> project\nZ159.</p>\n</div>\n<div id=\"release-notes\">\n<h2>Release Notes</h2>\n<div id=\"version-0-16-1-release-date-2017-11-14\">\n<h3>Version 0.16.1 (release date: 2017-11-14)</h3>\n<p>This is a maintenance release.</p>\n<ul>\n<li>Include .pyx files in source distribution</li>\n</ul>\n</div>\n<div id=\"version-0-16-release-date-2017-11-13\">\n<h3>Version 0.16 (release date: 2017-11-13)</h3>\n<p>New features:</p>\n<ul>\n<li><cite>TempoDetector</cite> can operate on live audio signals  (#292)</li>\n<li>Added chord evaluation (#309)</li>\n<li>Bar tracking functionality (#316)</li>\n<li>Added <cite>quantize_notes</cite> function (#327)</li>\n<li>Added global key evaluation (#336)</li>\n<li>Added key recognition feature and program (#345, #381)</li>\n</ul>\n<p>Bug fixes:</p>\n<ul>\n<li>Fix <cite>TransitionModel</cite> number of states when last state is unreachable (#287)</li>\n<li>Fix double beat detections in <cite>BeatTrackingProcessor</cite> (#298)</li>\n<li>Fix ffmpeg unicode filename handling (#305)</li>\n<li>Fix STFT zero padding (#319)</li>\n<li>Fix memory leak when accessing signal frames (#322)</li>\n<li>Quantization of events does not alter them (#327)</li>\n</ul>\n<p>API relevant changes:</p>\n<ul>\n<li><cite>BufferProcessor</cite> uses <cite>data</cite> instead of <cite>buffer</cite> for data storage (#292)</li>\n<li><cite>DBNBeatTrackingProcessor</cite> expects 1D inputs (#299)</li>\n<li>Moved downbeat and pattern tracking to <cite>features.downbeats</cite> (#316)</li>\n<li>Write/load functions moved to <cite>io</cite> module (#346)</li>\n<li>Write functions do not return any data (#346)</li>\n<li>Evaluation classes expect annotations/detections, cannot handle files (#346)</li>\n<li>New MIDI module (io.midi) replacing (utils.midi) based on mido (#46)</li>\n</ul>\n<p>Other changes:</p>\n<ul>\n<li>Viterbi decoding of <cite>HMM</cite> raises a warning if no valid path is found (#279)</li>\n<li>Add option to include Nyquist frequency in <cite>STFT</cite> (#280)</li>\n<li>Use <cite>pyfftw</cite> to compute FFT (#363)</li>\n<li>Python 3.7 support (#374)</li>\n<li>Use pytest instead of nose to run tests (#385)</li>\n<li>Removed obsolete code (#385)</li>\n</ul>\n</div>\n<div id=\"version-0-15-1-release-date-2017-07-07\">\n<h3>Version 0.15.1 (release date: 2017-07-07)</h3>\n<p>This is a maintenance release.</p>\n<ul>\n<li>NumPy boolean subtract fix (#296)</li>\n</ul>\n</div>\n<div id=\"version-0-15-release-date-2017-04-25\">\n<h3>Version 0.15 (release date: 2017-04-25)</h3>\n<p>New features:</p>\n<ul>\n<li>Streaming mode allows framewise processing of live audio input (#185)</li>\n<li>Exponential linear unit (ELU) activation function (#232)</li>\n<li><cite>DBNBeatTracker</cite> can operate on live audio signals (#238)</li>\n<li><cite>OnsetDetectorLL</cite> can operate on live audio signals (#256)</li>\n</ul>\n<p>Bug fixes:</p>\n<ul>\n<li>Fix downbeat evaluation failure with a single annotation / detection (#216)</li>\n<li>Fix tempo handling of multi-track MIDI files (#219)</li>\n<li>Fix error loading unicode filenames (#223)</li>\n<li>Fix ffmpeg unicode filename handling (#236)</li>\n<li>Fix smoothing for <cite>peak_picking</cite> (#247)</li>\n<li>Fix combining onsets/notes (#255)</li>\n</ul>\n<p>API relevant changes:</p>\n<ul>\n<li><cite>NeuralNetwork</cite> expect 2D inputs; activation can be computed stepwise (#244)</li>\n<li>Reorder <cite>GRUCell</cite> parameters, to be consistent with all other layers (#243)</li>\n<li>Rename <cite>GRULayer</cite> parameters, to be consistent with all other layers (#243)</li>\n</ul>\n<p>Other changes:</p>\n<ul>\n<li>SPL and RMS can be computed on <cite>Signal</cite> and <cite>FramedSignal</cite> (#208)</li>\n<li><cite>num_threads</cite> is passed to <cite>ParallelProcessor</cite> in single mode (#217)</li>\n<li>Use <cite>install_requires</cite> in <cite>setup.py</cite> to specify dependencies (#226)</li>\n<li>Use new Cython build system to build extensions (#227)</li>\n<li>Allow initialisation of previous/hidden states in RNNs (#243)</li>\n<li>Forward path of <cite>HMM</cite> can be computed stepwise (#244)</li>\n</ul>\n</div>\n<div id=\"version-0-14-1-release-date-2016-08-01\">\n<h3>Version 0.14.1 (release date: 2016-08-01)</h3>\n<p>This is a maintenance release.</p>\n<ul>\n<li><cite>RNNDownBeatProcessor</cite> returns only beat and downbeat activations (#197)</li>\n<li>Update programs to reflect MIREX 2016 submissions (#198)</li>\n</ul>\n</div>\n<div id=\"version-0-14-release-date-2016-07-28\">\n<h3>Version 0.14 (release date: 2016-07-28)</h3>\n<p>New features:</p>\n<ul>\n<li>Downbeat tracking based on Recurrent Neural Network (RNN) and Dynamic\nBayesian Network (DBN) (#130)</li>\n<li>Convolutional Neural Networks (CNN) and CNN onset detection (#133)</li>\n<li>Linear-Chain Conditional Random Field (CRF) implementation (#144)</li>\n<li>Deep Neural Network (DNN) based chroma vector extraction (#148)</li>\n<li>CRF chord recognition using DNN chroma vectors (#148)</li>\n<li>CNN chord recognition using CRF decoding (#152)</li>\n<li>Initial Windows support (Python 2.7 only, no pip packages yet) (#157)</li>\n<li>Gated Recurrent Unit (GRU) network layer (#167)</li>\n</ul>\n<p>Bug fixes:</p>\n<ul>\n<li>Fix downbeat output bug (#128)</li>\n<li>MIDI file creation bug (#166)</li>\n</ul>\n<p>API relevant changes:</p>\n<ul>\n<li>Refactored the <cite>ml.rnn</cite> to <cite>ml.nn</cite> and converted the models to pickles (#110)</li>\n<li>Reordered the dimensions of comb_filters to time, freq, tau (#135)</li>\n<li><cite>write_notes</cite> uses <cite>delimiter</cite> instead of <cite>sep</cite> to separate columns (#155)</li>\n<li><cite>LSTMLayer</cite> takes <cite>Gate</cite> as arguments, all layers are callable (#161)</li>\n<li>Replaced <cite>online</cite> parameter of <cite>FramedSignalProcessor</cite> by <cite>origin</cite> (#169)</li>\n</ul>\n<p>Other changes:</p>\n<ul>\n<li>Added classes for onset/note/beat detection with RNNs to <cite>features.*</cite> (#118)</li>\n<li>Add examples to docstrings of classes (#119)</li>\n<li>Converted <cite>madmom.modules</cite> into a Python package (#125)</li>\n<li><cite>match_files</cite> can handle inexact matches (#137)</li>\n<li>Updated beat tracking models to MIREX 2015 ones (#146)</li>\n<li>Tempo and time signature can be set for created MIDI files (#166)</li>\n</ul>\n</div>\n<div id=\"version-0-13-2-release-date-2016-06-09\">\n<h3>Version 0.13.2 (release date: 2016-06-09)</h3>\n<p>This is a bugfix release.</p>\n<ul>\n<li>Fix custom filterbank in FilteredSpectrogram (#142)</li>\n</ul>\n</div>\n<div id=\"version-0-13-1-release-date-2016-03-14\">\n<h3>Version 0.13.1 (release date: 2016-03-14)</h3>\n<p>This is a bugfix release.</p>\n<ul>\n<li>Fix beat evaluation argument parsing (#116)</li>\n</ul>\n</div>\n<div id=\"version-0-13-release-date-2016-03-07\">\n<h3>Version 0.13 (release date: 2016-03-07)</h3>\n<p>New features:</p>\n<ul>\n<li>Python 3 support (3.3+) (#15)</li>\n<li>Online documentation available at <a href=\"http://madmom.readthedocs.org\" rel=\"nofollow\">http://madmom.readthedocs.org</a> (#60)</li>\n</ul>\n<p>Bug fixes:</p>\n<ul>\n<li>Fix nasty unsigned indexing bug (#88)</li>\n<li>MIDI note timing could get corrupted if <cite>note_ticks_to_beats()</cite> was called\nmultiple times (#90)</li>\n</ul>\n<p>API relevant changes:</p>\n<ul>\n<li>Renamed <cite>DownBeatTracker</cite> and all relevant classes to <cite>PatternTracker</cite> (#25)</li>\n<li>Complete refactoring of the <cite>features.beats_hmm</cite> module (#52)</li>\n<li>Unified negative index behaviour of <cite>FramedSignal</cite> (#72)</li>\n<li>Removed pickling of data classes since it was not tested thoroughly (#81)</li>\n<li>Reworked stacking of spectrogram differences (#82)</li>\n<li>Renamed <cite>norm_bands</cite> argument of <cite>MultiBandSpectrogram</cite> to <cite>norm_filters</cite>\n(#83)</li>\n</ul>\n<p>Other changes:</p>\n<ul>\n<li>Added alignment evaluation (#12)</li>\n<li>Added continuous integration testing (#16)</li>\n<li>Added <cite>-o</cite> option to both <cite>single</cite>/<cite>batch</cite> processing mode to not overwrite\nfiles accidentally in <cite>single</cite> mode (#18)</li>\n<li>Removed <cite>block_size</cite> parameter from <cite>FilteredSpectrogram</cite> (#22)</li>\n<li>Sample rate is always integer (#23)</li>\n<li>Converted all docstrings to the numpydoc format (#48)</li>\n<li>Batch processing continues if non-audio files are given (#53)</li>\n<li>Added code quality checks (#61)</li>\n<li>Added coverage measuring (#74)</li>\n<li>Added <cite>\u2013down`</cite> option to evaluate only downbeats (#76)</li>\n<li>Removed option to normalise the observations (#95)</li>\n<li>Moved filterbank related argument parser to <cite>FilterbankProcessor</cite> (#96)</li>\n</ul>\n</div>\n<div id=\"version-0-12-1-release-date-2016-01-22\">\n<h3>Version 0.12.1 (release date: 2016-01-22)</h3>\n<p>Added Python 3 compatibility to setup.py (needed for the tutorials to work)</p>\n</div>\n<div id=\"version-0-12-release-date-2015-10-16\">\n<h3>Version 0.12 (release date: 2015-10-16)</h3>\n<p>Initial public release of madmom</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 4485930, "releases": {"0.12": [{"comment_text": "", "digests": {"md5": "68f134befe7e5dbf29c5a9d7f165124a", "sha256": "d21c7dd059c811bd8c5704c7fb18b3effa9f59d20224ca1cc6fae2cf70ae3df3"}, "downloads": -1, "filename": "madmom-0.12.tar.gz", "has_sig": false, "md5_digest": "68f134befe7e5dbf29c5a9d7f165124a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3802724, "upload_time": "2015-10-16T09:37:21", "upload_time_iso_8601": "2015-10-16T09:37:21.821038Z", "url": "https://files.pythonhosted.org/packages/28/0e/752fa1aa85c99a18036be8e2301cef9fc60a02824bba962052aa32c017a6/madmom-0.12.tar.gz", "yanked": false}], "0.12.1": [{"comment_text": "", "digests": {"md5": "b1605898617d5a089be681c436f2f1a1", "sha256": "79b4fcffb3b1143e3ad80210cd095a5ff10c4f375d2f5451de69f68ad74410fc"}, "downloads": -1, "filename": "madmom-0.12.1.tar.gz", "has_sig": false, "md5_digest": "b1605898617d5a089be681c436f2f1a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3791811, "upload_time": "2016-01-22T08:26:36", "upload_time_iso_8601": "2016-01-22T08:26:36.286441Z", "url": "https://files.pythonhosted.org/packages/c7/92/ec038532e1f174e0b9672662218b30faa4448c1438d4ba68b2289a7f8369/madmom-0.12.1.tar.gz", "yanked": false}], "0.13": [{"comment_text": "", "digests": {"md5": "d864a5a0fffa01a2d7dd53d43aecb56d", "sha256": "4c5c01b2a1e106949c8d41533a3d4eccd0e57ab6529fea5ffe7b82b68caca270"}, "downloads": -1, "filename": "madmom-0.13.tar.gz", "has_sig": false, "md5_digest": "d864a5a0fffa01a2d7dd53d43aecb56d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3812891, "upload_time": "2016-03-07T11:52:52", "upload_time_iso_8601": "2016-03-07T11:52:52.598560Z", "url": "https://files.pythonhosted.org/packages/f6/38/64a07d5cabc3099484b177f4ad6c8b8148a11b6a21206a0729a257e43e97/madmom-0.13.tar.gz", "yanked": false}], "0.13.1": [{"comment_text": "", "digests": {"md5": "395490aab6b04e23900a0fb2ff2cf402", "sha256": "0a553d17fc70d481718a640eb342667410e2ca8af5cec43e5459ab036b330bda"}, "downloads": -1, "filename": "madmom-0.13.1.tar.gz", "has_sig": false, "md5_digest": "395490aab6b04e23900a0fb2ff2cf402", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3813033, "upload_time": "2016-03-14T09:35:59", "upload_time_iso_8601": "2016-03-14T09:35:59.146896Z", "url": "https://files.pythonhosted.org/packages/bb/5e/c2ef8193a8201c6fbc6b10fa5e44ea9e50a6a7643590de6fbf893809ecb9/madmom-0.13.1.tar.gz", "yanked": false}], "0.13.2": [{"comment_text": "", "digests": {"md5": "2b136d59c1f198e57c0f10f243f90edc", "sha256": "aa8fcd858bb29f016f425792df655f40040098052b065c0fa0a5393a6a70d171"}, "downloads": -1, "filename": "madmom-0.13.2.tar.gz", "has_sig": false, "md5_digest": "2b136d59c1f198e57c0f10f243f90edc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3812960, "upload_time": "2016-06-09T07:26:06", "upload_time_iso_8601": "2016-06-09T07:26:06.246923Z", "url": "https://files.pythonhosted.org/packages/6a/c1/3a93ec4ce0be0b0f68409d5974137f9999a833976cceae971d876ff86a04/madmom-0.13.2.tar.gz", "yanked": false}], "0.14": [{"comment_text": "", "digests": {"md5": "41e8c2a88512ba61b49d42fca83729a3", "sha256": "e0dcb65aba5fb8816a6792a44aca02f356b9003943079a5a9863d12fb2863d0a"}, "downloads": -1, "filename": "madmom-0.14.tar.gz", "has_sig": false, "md5_digest": "41e8c2a88512ba61b49d42fca83729a3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16274422, "upload_time": "2016-07-28T11:43:56", "upload_time_iso_8601": "2016-07-28T11:43:56.299609Z", "url": "https://files.pythonhosted.org/packages/8f/46/64dd93a1211e710a7b75a92c1fb223d601d391744f1c0829d7e7afe6791f/madmom-0.14.tar.gz", "yanked": false}], "0.14.1": [{"comment_text": "", "digests": {"md5": "8b80d8992444216e244e1300a7cdfaae", "sha256": "1a6b8a736e561d5adabd49f0946e531f2439a9d1af4dd5452b8188f4da97b170"}, "downloads": -1, "filename": "madmom-0.14.1.tar.gz", "has_sig": false, "md5_digest": "8b80d8992444216e244e1300a7cdfaae", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14336383, "upload_time": "2016-08-01T16:58:32", "upload_time_iso_8601": "2016-08-01T16:58:32.091608Z", "url": "https://files.pythonhosted.org/packages/14/06/0b9d9d1b271171e0d8c739856f51a7553dacf662e4a5753fc7c54655144f/madmom-0.14.1.tar.gz", "yanked": false}], "0.15": [{"comment_text": "", "digests": {"md5": "ebb8dfd0133de1833ae890013e54de62", "sha256": "8ad1e68be070a26095ec8c972b859a47c3cc86b51aebdcf672a39878c0e4af41"}, "downloads": -1, "filename": "madmom-0.15.tar.gz", "has_sig": false, "md5_digest": "ebb8dfd0133de1833ae890013e54de62", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15666982, "upload_time": "2017-04-25T08:54:05", "upload_time_iso_8601": "2017-04-25T08:54:05.707998Z", "url": "https://files.pythonhosted.org/packages/fb/cb/67f1a1e5a82e520d60899973e3ea0a96125a662ea2c7bd90a9147970fd60/madmom-0.15.tar.gz", "yanked": false}], "0.15.1": [{"comment_text": "", "digests": {"md5": "04065a917850fa564a83c7ba2e8641d1", "sha256": "2a1325b0c0932611cb8da3890cae6320540fba806881a9dc7957aa909568acee"}, "downloads": -1, "filename": "madmom-0.15.1.tar.gz", "has_sig": false, "md5_digest": "04065a917850fa564a83c7ba2e8641d1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15667163, "upload_time": "2017-07-07T10:22:58", "upload_time_iso_8601": "2017-07-07T10:22:58.406032Z", "url": "https://files.pythonhosted.org/packages/b7/bb/b9b88d504f5ed3d87dd8a952c4feb37165a96ba1015f912cd4d6f050d75f/madmom-0.15.1.tar.gz", "yanked": false}], "0.16": [{"comment_text": "", "digests": {"md5": "26647abf9cea0b490984b17b3be3f50a", "sha256": "7f63f18bfb5e54ba7ea59ad4e1713f489fd5409c9f1aaaf706757be6e4d9b042"}, "downloads": -1, "filename": "madmom-0.16.tar.gz", "has_sig": false, "md5_digest": "26647abf9cea0b490984b17b3be3f50a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20031952, "upload_time": "2018-11-13T14:08:45", "upload_time_iso_8601": "2018-11-13T14:08:45.403192Z", "url": "https://files.pythonhosted.org/packages/cb/fd/72afb59ac0dc760df0abe7f60a8474e727d3cca96ac3b44b56b26d5e983e/madmom-0.16.tar.gz", "yanked": false}], "0.16.1": [{"comment_text": "", "digests": {"md5": "c800fb8499e10af554d3b3f43405169c", "sha256": "64a86a29106e7c4e0c5f4ec96801c2d1a8492db710e4fe27e097da5517d68cb2"}, "downloads": -1, "filename": "madmom-0.16.1.tar.gz", "has_sig": false, "md5_digest": "c800fb8499e10af554d3b3f43405169c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20040947, "upload_time": "2018-11-14T14:56:22", "upload_time_iso_8601": "2018-11-14T14:56:22.830985Z", "url": "https://files.pythonhosted.org/packages/c7/a3/9f3de3e8068a3606331134d96b84c8db4f7624d6715be8ab3c1f56e6731d/madmom-0.16.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c800fb8499e10af554d3b3f43405169c", "sha256": "64a86a29106e7c4e0c5f4ec96801c2d1a8492db710e4fe27e097da5517d68cb2"}, "downloads": -1, "filename": "madmom-0.16.1.tar.gz", "has_sig": false, "md5_digest": "c800fb8499e10af554d3b3f43405169c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20040947, "upload_time": "2018-11-14T14:56:22", "upload_time_iso_8601": "2018-11-14T14:56:22.830985Z", "url": "https://files.pythonhosted.org/packages/c7/a3/9f3de3e8068a3606331134d96b84c8db4f7624d6715be8ab3c1f56e6731d/madmom-0.16.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:12 2020"}