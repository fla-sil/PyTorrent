{"info": {"author": "Wibowo Arindrarto", "author_email": "bow@bow.web.id", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Operating System :: POSIX", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Testing", "Topic :: Utilities"], "description": "pytest-pipeline\n===============\n\n|ci| |coverage| |pypi|\n\n.. |ci| image:: https://travis-ci.org/bow/pytest-pipeline.png?branch=master\n        :target: https://travis-ci.org/bow/pytest-pipeline\n\n.. |coverage| image:: https://codecov.io/gh/bow/pytest-pipeline/branch/master/graph/badge.svg\n        :target: https://codecov.io/gh/bow/pytest-pipeline\n\n.. |pypi| image:: https://badge.fury.io/py/pytest-pipeline.svg\n        :target: http://badge.fury.io/py/pytest-pipeline\n\n\npytest-pipeline is a pytest plugin for functional testing of data analysis\npipelines. They are usually long-running scripts or executables with multiple\ninput and/or output files + directories. The plugin is meant for end-to-end\ntesting where you test for conditions before the pipeline run and after the\npipeline runs (output files, checksums, etc.).\n\npytest-pipeline is tested against Python versions 2.7, 3.3, 3.4, 3.5, and 3.6.\n\n\nInstallation\n============\n\n::\n\n    pip install pytest-pipeline\n\n\nWalkthrough\n===========\n\nFor our example, we will use a super simple pipeline that writes a file and\nprints to stdout:\n\n.. code-block:: python\n\n    #!/usr/bin/env python\n\n    from __future__ import print_function\n\n    if __name__ == \"__main__\":\n\n        with open(\"result.txt\", \"w\") as result:\n            result.write(\"42\\n\")\n        print(\"Result computed\")\n\nAt this point it's just a simple script, but it should be enough to illustrate\nthe plugin. Also, if you want to follow along, save the above file as\n``run_pipeline``.\n\nWith the pipeline above, here's how your test would look like with\n``pytest_pipeline``:\n\n.. code-block:: python\n\n    import os\n    import shutil\n    import unittest\n    from pytest_pipeline import PipelineRun, mark, utils\n\n    # we can subclass `PipelineRun` to add custom methods\n    # using `PipelineRun` as-is is also possible\n    class MyRun(PipelineRun):\n\n        # before_run-marked functions will be run before the pipeline is executed\n        @mark.before_run\n        def test_prep_executable(self):\n            # copy the executable to the run directory\n            shutil.copy2(\"/path/to/run_pipeline\", \"run_pipeline\")\n            # ensure that the file is executable\n            assert os.access(\"run_pipeline\", os.X_OK)\n\n    # a pipeline run is treated as a test fixture\n    run = MyRun.class_fixture(cmd=\"./run_pipeline\", stdout=\"run.stdout\")\n\n    # the fixture is bound to a unittest.TestCase using the usefixtures mark\n    @pytest.mark.usefixtures(\"run\")\n    # tests per-pipeline run are grouped in one unittest.TestCase instance\n    class TestMyPipeline(unittest.TestCase):\n\n        def test_result_md5(self):\n            assert utils.file_md5sum(\"result.txt\") == \"50a2fabfdd276f573ff97ace8b11c5f4\"\n\n        def test_exit_code(self):\n            # the run fixture is stored as the `run_fixture` attribute\n            assert self.run_fixture.exit_code == 0\n\n        # we can check the stdout that we capture as well\n        def test_stdout(self):\n            assert open(\"run.stdout\", \"r\").read().strip() == \"Result computed\"\n\nIf the test above is saved as ``test_demo.py``, you can then run the test by\nexecuting ``py.test -v test_demo.py``. You should see that three tests were\nexecuted and all four passed.\n\nWhat just happened?\n-------------------\n\nYou just executed your first pipeline test. The plugin itself gives you:\n\n- Test directory creation (one class gets one directory).\n  By default, testdirectories are all created in the ``/tmp/pipeline_test``\n  directory. You can tweak this location by supplying the\n  ``--base-pipeline-dir`` command line flag.\n\n- Automatic execution of the pipeline.\n  No need to ``import subprocess``, just define the command via the\n  ``PipelineRun`` object. We optionally captured the standard output to a file\n  called ``run.stdout``. Not a fan of doing disk IO? You can also set ``stdout``\n  and/or ``stderr`` to ``True`` and have their values captured in-memory.\n\n- Timeout control.\n  For long running pipelines, you can also supply a ``timeout`` argument which\n  limits how long the pipeline process can run.\n\nAnd since this is a py.test plugin, test discovery and execution is done via\npy.test.\n\n\nGetting + giving help\n=====================\n\nPlease use the `issue tracker <https://github.com/bow/pytest-pipeline/issues>`_\nto report bugs or feature requests. You can always fork and submit a pull\nrequest as well.\n\n\nLicense\n=======\n\nSee LICENSE.\n\n\n\n\nChangelog\n=========\n\nVersion 0.3\n-----------\n\nRelease 0.3.0\n^^^^^^^^^^^^^\n\nRelease date: 24 January 2017\n\n* Allow stdout and/or stderr capture in-memory. This can be done by\n  setting their respective keyword arguments to ``True`` when creating\n  the run fixture.\n\n\nVersion 0.2\n-----------\n\nRelease 0.2.0\n^^^^^^^^^^^^^\n\nRelease date: 31 March 2015\n\n* Pipeline runs are now modelled differently. Instead of a class attribute,\n  they are now created as pytest fixtures. This allows the pipeline runs\n  to be used in non-`unittest.TestCase` tests.\n\n* The `after_run` decorator is deprecated.\n\n* The command line flags `--xfail-pipeline` and `--skip-run` are deprecated.\n\n\nVersion 0.1\n-----------\n\nRelease 0.1.0\n^^^^^^^^^^^^^\n\nRelease date: 25 August 2014\n\n* First release on PyPI.\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/bow/pytest-pipeline", "keywords": "pytest pipeline plugin testing", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "pytest-pipeline", "package_url": "https://pypi.org/project/pytest-pipeline/", "platform": "", "project_url": "https://pypi.org/project/pytest-pipeline/", "project_urls": {"Homepage": "https://github.com/bow/pytest-pipeline"}, "release_url": "https://pypi.org/project/pytest-pipeline/0.3.0/", "requires_dist": null, "requires_python": "", "summary": "Pytest plugin for functional testing of data analysispipelines", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"pytest-pipeline\">\n<h2>pytest-pipeline</h2>\n<p><a href=\"https://travis-ci.org/bow/pytest-pipeline\" rel=\"nofollow\"><img alt=\"ci\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ff2205a761853f8709aef0a0fdcbe46017e50f64/68747470733a2f2f7472617669732d63692e6f72672f626f772f7079746573742d706970656c696e652e706e673f6272616e63683d6d6173746572\"></a> <a href=\"https://codecov.io/gh/bow/pytest-pipeline\" rel=\"nofollow\"><img alt=\"coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a5ea9a7c8e35c396d89c530fd30972b52c9994b9/68747470733a2f2f636f6465636f762e696f2f67682f626f772f7079746573742d706970656c696e652f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a> <a href=\"http://badge.fury.io/py/pytest-pipeline\" rel=\"nofollow\"><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2017d11e64afc7c7f95fee20fa7475e72b6de501/68747470733a2f2f62616467652e667572792e696f2f70792f7079746573742d706970656c696e652e737667\"></a></p>\n<p>pytest-pipeline is a pytest plugin for functional testing of data analysis\npipelines. They are usually long-running scripts or executables with multiple\ninput and/or output files + directories. The plugin is meant for end-to-end\ntesting where you test for conditions before the pipeline run and after the\npipeline runs (output files, checksums, etc.).</p>\n<p>pytest-pipeline is tested against Python versions 2.7, 3.3, 3.4, 3.5, and 3.6.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install pytest-pipeline\n</pre>\n</div>\n<div id=\"walkthrough\">\n<h2>Walkthrough</h2>\n<p>For our example, we will use a super simple pipeline that writes a file and\nprints to stdout:</p>\n<pre><span class=\"ch\">#!/usr/bin/env python</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">__future__</span> <span class=\"kn\">import</span> <span class=\"n\">print_function</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n\n    <span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"result.txt\"</span><span class=\"p\">,</span> <span class=\"s2\">\"w\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">result</span><span class=\"p\">:</span>\n        <span class=\"n\">result</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"s2\">\"42</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Result computed\"</span><span class=\"p\">)</span>\n</pre>\n<p>At this point it\u2019s just a simple script, but it should be enough to illustrate\nthe plugin. Also, if you want to follow along, save the above file as\n<tt>run_pipeline</tt>.</p>\n<p>With the pipeline above, here\u2019s how your test would look like with\n<tt>pytest_pipeline</tt>:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">shutil</span>\n<span class=\"kn\">import</span> <span class=\"nn\">unittest</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pytest_pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">PipelineRun</span><span class=\"p\">,</span> <span class=\"n\">mark</span><span class=\"p\">,</span> <span class=\"n\">utils</span>\n\n<span class=\"c1\"># we can subclass `PipelineRun` to add custom methods</span>\n<span class=\"c1\"># using `PipelineRun` as-is is also possible</span>\n<span class=\"k\">class</span> <span class=\"nc\">MyRun</span><span class=\"p\">(</span><span class=\"n\">PipelineRun</span><span class=\"p\">):</span>\n\n    <span class=\"c1\"># before_run-marked functions will be run before the pipeline is executed</span>\n    <span class=\"nd\">@mark</span><span class=\"o\">.</span><span class=\"n\">before_run</span>\n    <span class=\"k\">def</span> <span class=\"nf\">test_prep_executable</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"c1\"># copy the executable to the run directory</span>\n        <span class=\"n\">shutil</span><span class=\"o\">.</span><span class=\"n\">copy2</span><span class=\"p\">(</span><span class=\"s2\">\"/path/to/run_pipeline\"</span><span class=\"p\">,</span> <span class=\"s2\">\"run_pipeline\"</span><span class=\"p\">)</span>\n        <span class=\"c1\"># ensure that the file is executable</span>\n        <span class=\"k\">assert</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">access</span><span class=\"p\">(</span><span class=\"s2\">\"run_pipeline\"</span><span class=\"p\">,</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">X_OK</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># a pipeline run is treated as a test fixture</span>\n<span class=\"n\">run</span> <span class=\"o\">=</span> <span class=\"n\">MyRun</span><span class=\"o\">.</span><span class=\"n\">class_fixture</span><span class=\"p\">(</span><span class=\"n\">cmd</span><span class=\"o\">=</span><span class=\"s2\">\"./run_pipeline\"</span><span class=\"p\">,</span> <span class=\"n\">stdout</span><span class=\"o\">=</span><span class=\"s2\">\"run.stdout\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># the fixture is bound to a unittest.TestCase using the usefixtures mark</span>\n<span class=\"nd\">@pytest</span><span class=\"o\">.</span><span class=\"n\">mark</span><span class=\"o\">.</span><span class=\"n\">usefixtures</span><span class=\"p\">(</span><span class=\"s2\">\"run\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># tests per-pipeline run are grouped in one unittest.TestCase instance</span>\n<span class=\"k\">class</span> <span class=\"nc\">TestMyPipeline</span><span class=\"p\">(</span><span class=\"n\">unittest</span><span class=\"o\">.</span><span class=\"n\">TestCase</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">test_result_md5</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">assert</span> <span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">file_md5sum</span><span class=\"p\">(</span><span class=\"s2\">\"result.txt\"</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"s2\">\"50a2fabfdd276f573ff97ace8b11c5f4\"</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">test_exit_code</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"c1\"># the run fixture is stored as the `run_fixture` attribute</span>\n        <span class=\"k\">assert</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">run_fixture</span><span class=\"o\">.</span><span class=\"n\">exit_code</span> <span class=\"o\">==</span> <span class=\"mi\">0</span>\n\n    <span class=\"c1\"># we can check the stdout that we capture as well</span>\n    <span class=\"k\">def</span> <span class=\"nf\">test_stdout</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">assert</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"run.stdout\"</span><span class=\"p\">,</span> <span class=\"s2\">\"r\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">()</span> <span class=\"o\">==</span> <span class=\"s2\">\"Result computed\"</span>\n</pre>\n<p>If the test above is saved as <tt>test_demo.py</tt>, you can then run the test by\nexecuting <tt>py.test <span class=\"pre\">-v</span> test_demo.py</tt>. You should see that three tests were\nexecuted and all four passed.</p>\n<div id=\"what-just-happened\">\n<h3>What just happened?</h3>\n<p>You just executed your first pipeline test. The plugin itself gives you:</p>\n<ul>\n<li>Test directory creation (one class gets one directory).\nBy default, testdirectories are all created in the <tt>/tmp/pipeline_test</tt>\ndirectory. You can tweak this location by supplying the\n<tt><span class=\"pre\">--base-pipeline-dir</span></tt> command line flag.</li>\n<li>Automatic execution of the pipeline.\nNo need to <tt>import subprocess</tt>, just define the command via the\n<tt>PipelineRun</tt> object. We optionally captured the standard output to a file\ncalled <tt>run.stdout</tt>. Not a fan of doing disk IO? You can also set <tt>stdout</tt>\nand/or <tt>stderr</tt> to <tt>True</tt> and have their values captured in-memory.</li>\n<li>Timeout control.\nFor long running pipelines, you can also supply a <tt>timeout</tt> argument which\nlimits how long the pipeline process can run.</li>\n</ul>\n<p>And since this is a py.test plugin, test discovery and execution is done via\npy.test.</p>\n</div>\n</div>\n<div id=\"getting-giving-help\">\n<h2>Getting + giving help</h2>\n<p>Please use the <a href=\"https://github.com/bow/pytest-pipeline/issues\" rel=\"nofollow\">issue tracker</a>\nto report bugs or feature requests. You can always fork and submit a pull\nrequest as well.</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>See LICENSE.</p>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<div id=\"version-0-3\">\n<h3>Version 0.3</h3>\n<h3 id=\"release-0-3-0\"><span class=\"section-subtitle\">Release 0.3.0</span></h3>\n<p>Release date: 24 January 2017</p>\n<ul>\n<li>Allow stdout and/or stderr capture in-memory. This can be done by\nsetting their respective keyword arguments to <tt>True</tt> when creating\nthe run fixture.</li>\n</ul>\n</div>\n<div id=\"version-0-2\">\n<h3>Version 0.2</h3>\n<h3 id=\"release-0-2-0\"><span class=\"section-subtitle\">Release 0.2.0</span></h3>\n<p>Release date: 31 March 2015</p>\n<ul>\n<li>Pipeline runs are now modelled differently. Instead of a class attribute,\nthey are now created as pytest fixtures. This allows the pipeline runs\nto be used in non-<cite>unittest.TestCase</cite> tests.</li>\n<li>The <cite>after_run</cite> decorator is deprecated.</li>\n<li>The command line flags <cite>\u2013xfail-pipeline</cite> and <cite>\u2013skip-run</cite> are deprecated.</li>\n</ul>\n</div>\n<div id=\"version-0-1\">\n<h3>Version 0.1</h3>\n<h3 id=\"release-0-1-0\"><span class=\"section-subtitle\">Release 0.1.0</span></h3>\n<p>Release date: 25 August 2014</p>\n<ul>\n<li>First release on PyPI.</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 2594829, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "b455c4f8fa44e65b1af19b0d42587948", "sha256": "5eb5e4f13c9561a741c470b1e3dd1061218b18e65227ecb0cfbb951e303076d6"}, "downloads": -1, "filename": "pytest_pipeline-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b455c4f8fa44e65b1af19b0d42587948", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 11450, "upload_time": "2014-08-25T19:26:49", "upload_time_iso_8601": "2014-08-25T19:26:49.125540Z", "url": "https://files.pythonhosted.org/packages/a4/f3/36a76e4bfa4f26485eda345bdcfeaead440741a6600ca69b02b5eaf1440c/pytest_pipeline-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b127955d2d4040322122173ee782d5c", "sha256": "172ac507dd6d81a8de49ac86d0ebfe01b5803399d5bf48d1038957f53d4edfac"}, "downloads": -1, "filename": "pytest-pipeline-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8b127955d2d4040322122173ee782d5c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16890, "upload_time": "2014-08-25T19:26:44", "upload_time_iso_8601": "2014-08-25T19:26:44.970773Z", "url": "https://files.pythonhosted.org/packages/76/db/9b9ad4a9aa3f1aa3d9cafab2b3d71c85920ba9f80e95f055b1d7ffee0c09/pytest-pipeline-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "1521e78308225e3f7d24077ba8648f80", "sha256": "9ae93c6d1fc2d10b64c38510089691c2c1d014dc099f32a7ea589f3d8fc22cc5"}, "downloads": -1, "filename": "pytest-pipeline-0.2.0.zip", "has_sig": false, "md5_digest": "1521e78308225e3f7d24077ba8648f80", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25602, "upload_time": "2015-03-31T16:07:03", "upload_time_iso_8601": "2015-03-31T16:07:03.020437Z", "url": "https://files.pythonhosted.org/packages/32/93/9a81cc2d01707efdf297fe0a21b24a18aecad49ac4b17470855739b1ca72/pytest-pipeline-0.2.0.zip", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "6151c8c9edb2406b0359d171022ee212", "sha256": "ae366e78d35b61f7a38c1aacb70ff5d296c002f8231030d2d5de786039cce38e"}, "downloads": -1, "filename": "pytest-pipeline-0.3.0.tar.gz", "has_sig": false, "md5_digest": "6151c8c9edb2406b0359d171022ee212", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8956, "upload_time": "2017-01-24T09:27:10", "upload_time_iso_8601": "2017-01-24T09:27:10.545285Z", "url": "https://files.pythonhosted.org/packages/ed/ec/67d86da83fcfafb8ee040e2a6edd9cb9aeb9e1ea218eb8a612bad563b2d5/pytest-pipeline-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6151c8c9edb2406b0359d171022ee212", "sha256": "ae366e78d35b61f7a38c1aacb70ff5d296c002f8231030d2d5de786039cce38e"}, "downloads": -1, "filename": "pytest-pipeline-0.3.0.tar.gz", "has_sig": false, "md5_digest": "6151c8c9edb2406b0359d171022ee212", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8956, "upload_time": "2017-01-24T09:27:10", "upload_time_iso_8601": "2017-01-24T09:27:10.545285Z", "url": "https://files.pythonhosted.org/packages/ed/ec/67d86da83fcfafb8ee040e2a6edd9cb9aeb9e1ea218eb8a612bad563b2d5/pytest-pipeline-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:53 2020"}