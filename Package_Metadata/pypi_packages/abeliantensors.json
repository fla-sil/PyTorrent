{"info": {"author": "Markus Hauru", "author_email": "markus@mhauru.org", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering"], "description": "# Introduction\n[![Readthedocs status badge][rtd-badge]][rtd-url]\n[![Travis status badge][travis-img]][travis-url]\n[![Codecov status badge][codecov-img]][codecov-url]\n\nabeliantensors is a Python 3 package that implements U(1) and Zn symmetry preserving\ntensors, as described by Singh et al. in\n[arXiv: 0907.2994](https://arxiv.org/abs/0907.2994) and\n[arXiv: 1008.4774](https://arxiv.org/abs/1008.4774). abeliantensors has been designed\nfor use in tensor network algorithms, and works well with the\n[ncon function](https://github.com/mhauru/ncon).\n\n## Installation\n\nIf you just want to use the library:\n```\npip install --user git+https://github.com/mhauru/abeliantensors\n```\n\nIf you also want to modify and develop the library\n```\ngit clone https://github.com/mhauru/abeliantensors\ncd abeliantensors\npip install --user -e .[tests]\n```\nafter which you can run the test suite by just calling `pytest`.\n\n## Usage\n\nabeliantensors exports classes `TensorU1`, `TensorZ2`, and `TensorZ3`. Other\ncyclic groups Zn can be implemented with one-liners, see the file\n`symmetrytensors.py` for examples. abeliantensors also exports a class called\n`Tensor`, that is just a wrapper around regular numpy ndarrays, but that\nimplements the exact same interface as the symmetric tensor classes. This\nallows for easy switching between utilizing and not utilizing the symmetry\npreserving tensors by simply changing the class that is imported.\n\nEach symmetric tensor has, in addition to its tensor elements, the following\npieces of what we call form data:\n* `shape` describes the dimensions of the tensors, just like with numpy arrays.\n  The difference is that for symmetric tensors the dimension of each index\n  isn't just a number, but a list of numbers, that sets how the vector space is\n  partitioned by the irreducible representations (irreps) of the symmetry. So\n  for instance `shape=[[2,3], [5,4]]` could be the shape of a Z2 symmetric\n  matrix of dimensions 5 x 9, where the first 2 rows and 5 columns are\n  associated with one of the two irreps of Z2, and the remaining 3 rows and 4\n  columns with the other.\n* `qhape` is like `shape`, but lists the irrep charges instead of the\n  dimensions. Irrep charges are often also called quantum numbers, hence the q.\n  In the above example `qhape=[[0,1], [0,1]]` would mark the first part of both\n  the row and column space to belong to the trivial irrep of charge 0, and the\n  second part to the irrep with charge 1. For Zn the possible charges are 0, 1,\n  ..., n, for U(1) they are all positive and negative integers.\n* `dirs` is a list of 1s and -1s, that gives a direction to each index: either\n  1 for outgoing or -1 for ingoing.\n* `charge` is an integer, the irrep charge associated to tensor. In most cases\n  you want `charge=0`, which is also the default when creating new tensors.\n\nNote that each element of the tensor is associated with one irrep charge for\neach of the indices. The symmetry property is then that an element can only be\nnon-zero if the charges from each index, multiplied by the direction of that\nindex, add up to the charge of the tensor. Addition of charges for Zn tensors\nis modulo n. For instance for a `charge=0` `TensorZ2` object this means that\nthe charges on each leg must add up to an even number for an element to be\nnon-zero. The whole point of this library is to store and use such symmetric\ntensors in an efficient way, where we don't waste memory or computation time on\nthe elements we know are zero by symmetry, and can't accidentally let them be\nnon-zero.\n\nHere's a simple nonsense example of how abeliantensors can be used:\n```\nimport numpy as np\nfrom abeliantensors import TensorZ2\n\n# Create a symmetric tensor from an ndarray. All elements that should be zero\n# by symmetry are simply discarded, whether they are zero or not.\nsigmaz = np.array([[1, 0], [0, -1]])\nsigmaz = TensorZ2.from_ndarray(\n    sigmaz, shape=[[1, 1], [1, 1]], qhape=[[0, 1], [0, 1]], dirs=[1, -1]\n)\n\n# Create a random symmetric tensor.\na = TensorZ2.random(\n    shape=[[3, 2], [2, 4], [4, 4], [1, 1]],\n    qhape=[[0, 1]] * 4,\n    dirs=[-1, 1, 1, -1],\n)\n\n# Do a singular value decomposition of a tensor, thinking of it as a matrix\n# with some of the indices combined to a single matrix index, like one does\n# with numpy.reshape. Here we combine indices 0 and 2 to form the left matrix\n# index, and 1 and 3 to form the right one. The indices are reshaped back to\n# the original form after the SVD, so U and V are in this case order-3 tensors.\nU, S, V = a.svd([0, 2], [1, 3])\n\n# You can also do a truncated SVD, in this case to truncating to dimension 4.\nU, S, V = a.svd([0, 2], [1, 3], chis=4)\n\n# We can contract tensors together easily using the ncon package.\n# Note that conjugation flips the direction of each index, as well as the\n# charge of the tensor, which in this case though is 0.\nfrom ncon import ncon\naadg = ncon((a, a.conjugate()), ([1, 2, -1, -2], [1, 2, -11, -12]))\n\n# Finally, knowing that aadg is Hermitian, do an eigenvalue\n# decomposition of it, this time truncating not to a specific dimension, but\n# to a maximum relative truncation error of 1e-5.\nE, U = aadg.eig([0, 1], [2, 3], hermitian=True, eps=1e-5)\n```\n\nThere are many other user-facing methods and features, for more, see\nthe [API docs](https://abeliantensors.readthedocs.io/en/latest/API.html).\n\n## Demo and performance\n\nThe folder `demo` has an implementation of Levin and Nave's [TRG\nalgorithm](https://arxiv.org/abs/cond-mat/0611687), and a script\nthat runs it on the square lattice Ising model, using both symmetric tensors\nof the TensorZ2 class and dense Tensors, and compares the run times.\nBelow is a plot of how long it takes to run a single TRG step at various\nbond dimensions for both of them.\n\n![Running time of a single TRG step as a function of bond dimension, compared\nbetween using and not using symmetric tensors](demo/trg_performance.svg)\n\nNote that both axes are logarithmic.\n\nAt low bond dimensions the simple `Tensor` class outperforms `TensorZ2`, because\nkeeping track of the symmetry structure imposes an overhead. The time\ncomplexity of the overhead is subleading as a function of bond dimension, and\nas one goes to higher bond dimensions the symmetric tensors become faster.\nAsymptotically both have the same scaling as a function of bond dimension, but\nthe prefactor is smaller for `TensorZ2` by a factor of 1/4. This is because\ninstead of multiplying or decomposing an `m` x `m` matrix at cost `m**3`, we\nare multiplying two `m/2` by `m/2` matrices, at a total cost of `2*(m/2)**3 =\n(m**3)/4`.  For larger symmetry groups, the asymptotic benefit would be\ngreater. For instance for `TensorZ3`, we should see an approximately 9-fold\nspeed-up.\n\nSimilar results can be obtained for other algorithms, although the cross-over\npoint in bond dimension will be different.\n\n## Design and structure\n\nThe implementation is built on top of numpy, and the block-wise sparse\nstructure of the symmetry preserving tensors is implemented with Python\ndictionaries. Here's a quick summary of what each file does.\n\n`tensorcommon.py`: A parent class of all the other classes, `TensorCommon`,\nthat implements some higher-level features using the lower-level methods.\n\n`abeliantensor.py`: All the fun is in here. Implements the class\n`AbelianTensor`, that is the parent of all the symmetric tensor classes. This\nincludes implementations of various common tensor operations, such as\ncontractions and decompositions, preserving and making use of the block-wise\nsparse structure these tensors have.\n\n`tensor.py`: `Tensor`, the wrapper class for numpy arrays. It is designed so that\nany call to a method of the `AbelianTensor` class is also a valid call to a\nsimilarly named method of the `Tensor` class. All the symmetry-related\ninformation is simply discarded and some underlying numpy function is called.\nEven if one doesn't use symmetry preserving tensors, the `Tensor` class provides\nsome neat convenience functions, such as an easy-to-read one-liner for the\ntranspose-reshape-decompose-reshape-transpose procedure for singular value and\neigenvalue decompositions of tensors.\n\n`symmetrytensors.py`: A small file that simply creates subclasses of\n`AbelianTensor` for specific symmetry groups. If you need something other than\nZ2, Z3 and U(1), check this file to see how you could add what you need.\n\n## Tests\n\nThe `tests` folder has plenty of tests for the various classes. They can be run\nby calling `pytest`, provided abeliantensors was installed with the extras option\n`tests`.\n\nMost of the tests are based on generating a random instance of one of the\n\"fancy\" tensor classes in this package, and confirming that the following\ndiagram commutes:\n```\nFancy tensor \u2500\u2500\u2500 map to numpy ndarray \u2500\u2500\u2500> ndarray\n    \u2502                                         \u2502\n    \u2502                                         \u2502\nDo the thing                             Do the thing\n    \u2502                                         \u2502\n    \u2502                                         \u2502\n    V                                         V\nFancy tensor \u2500\u2500\u2500 map to numpy ndarray \u2500\u2500\u2500> ndarray\n```\n\nTwo command line arguments can be provided, `--n_iters` which sets how many\ntimes each test is run, with different random tensors each time (100 by\ndefault), and `--tensorclass` which can be used to specify which\ntensorclass(es) the tests are run on (by default all of them). Here's an\nexample of how one might run a specific test repeatedly:\n```\npytest tests/test_tensors.py::test_to_and_from_ndarray --tensorclass TensorZ2 --n_iters 1000\n```\n\n\n[travis-img]: https://travis-ci.org/mhauru/abeliantensors.svg?branch=master\n[travis-url]: https://travis-ci.org/mhauru/abeliantensors\n[codecov-img]: https://codecov.io/gh/mhauru/abeliantensors/branch/master/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/mhauru/abeliantensors\n[rtd-badge]: https://readthedocs.org/projects/abeliantensors/badge/?version=latest\n[rtd-url]: https://abeliantensors.readthedocs.io/en/latest/?badge=latest\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mhauru/abeliantensors", "keywords": "tensor,tensor networks,linear algebra", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "abeliantensors", "package_url": "https://pypi.org/project/abeliantensors/", "platform": "", "project_url": "https://pypi.org/project/abeliantensors/", "project_urls": {"Homepage": "https://github.com/mhauru/abeliantensors"}, "release_url": "https://pypi.org/project/abeliantensors/0.1.0/", "requires_dist": ["scipy (>=1.0.0)", "ncon ; extra == 'demo'", "timeit ; extra == 'demo'", "matplotlib ; extra == 'demo'", "seaborn ; extra == 'demo'", "sphinx ; extra == 'doc'", "sphinx-rtd-theme ; extra == 'doc'", "recommonmark ; extra == 'doc'", "ncon ; extra == 'tests'", "pytest ; extra == 'tests'", "pytest-randomly ; extra == 'tests'", "coverage ; extra == 'tests'"], "requires_python": ">=3.6", "summary": "Library for Abelian symmetry preserving tensors.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Introduction</h1>\n<p><a href=\"https://abeliantensors.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Readthedocs status badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/911c771cbf0e01e977e19436b5ec316b9aa7b6a3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6162656c69616e74656e736f72732f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://travis-ci.org/mhauru/abeliantensors\" rel=\"nofollow\"><img alt=\"Travis status badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1a1195aa033dc8175aa736fd83c9f25d29132812/68747470733a2f2f7472617669732d63692e6f72672f6d68617572752f6162656c69616e74656e736f72732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/mhauru/abeliantensors\" rel=\"nofollow\"><img alt=\"Codecov status badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2c8d9d5f06a9ebf6b695b501a3fe16b94589f970/68747470733a2f2f636f6465636f762e696f2f67682f6d68617572752f6162656c69616e74656e736f72732f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<p>abeliantensors is a Python 3 package that implements U(1) and Zn symmetry preserving\ntensors, as described by Singh et al. in\n<a href=\"https://arxiv.org/abs/0907.2994\" rel=\"nofollow\">arXiv: 0907.2994</a> and\n<a href=\"https://arxiv.org/abs/1008.4774\" rel=\"nofollow\">arXiv: 1008.4774</a>. abeliantensors has been designed\nfor use in tensor network algorithms, and works well with the\n<a href=\"https://github.com/mhauru/ncon\" rel=\"nofollow\">ncon function</a>.</p>\n<h2>Installation</h2>\n<p>If you just want to use the library:</p>\n<pre><code>pip install --user git+https://github.com/mhauru/abeliantensors\n</code></pre>\n<p>If you also want to modify and develop the library</p>\n<pre><code>git clone https://github.com/mhauru/abeliantensors\ncd abeliantensors\npip install --user -e .[tests]\n</code></pre>\n<p>after which you can run the test suite by just calling <code>pytest</code>.</p>\n<h2>Usage</h2>\n<p>abeliantensors exports classes <code>TensorU1</code>, <code>TensorZ2</code>, and <code>TensorZ3</code>. Other\ncyclic groups Zn can be implemented with one-liners, see the file\n<code>symmetrytensors.py</code> for examples. abeliantensors also exports a class called\n<code>Tensor</code>, that is just a wrapper around regular numpy ndarrays, but that\nimplements the exact same interface as the symmetric tensor classes. This\nallows for easy switching between utilizing and not utilizing the symmetry\npreserving tensors by simply changing the class that is imported.</p>\n<p>Each symmetric tensor has, in addition to its tensor elements, the following\npieces of what we call form data:</p>\n<ul>\n<li><code>shape</code> describes the dimensions of the tensors, just like with numpy arrays.\nThe difference is that for symmetric tensors the dimension of each index\nisn't just a number, but a list of numbers, that sets how the vector space is\npartitioned by the irreducible representations (irreps) of the symmetry. So\nfor instance <code>shape=[[2,3], [5,4]]</code> could be the shape of a Z2 symmetric\nmatrix of dimensions 5 x 9, where the first 2 rows and 5 columns are\nassociated with one of the two irreps of Z2, and the remaining 3 rows and 4\ncolumns with the other.</li>\n<li><code>qhape</code> is like <code>shape</code>, but lists the irrep charges instead of the\ndimensions. Irrep charges are often also called quantum numbers, hence the q.\nIn the above example <code>qhape=[[0,1], [0,1]]</code> would mark the first part of both\nthe row and column space to belong to the trivial irrep of charge 0, and the\nsecond part to the irrep with charge 1. For Zn the possible charges are 0, 1,\n..., n, for U(1) they are all positive and negative integers.</li>\n<li><code>dirs</code> is a list of 1s and -1s, that gives a direction to each index: either\n1 for outgoing or -1 for ingoing.</li>\n<li><code>charge</code> is an integer, the irrep charge associated to tensor. In most cases\nyou want <code>charge=0</code>, which is also the default when creating new tensors.</li>\n</ul>\n<p>Note that each element of the tensor is associated with one irrep charge for\neach of the indices. The symmetry property is then that an element can only be\nnon-zero if the charges from each index, multiplied by the direction of that\nindex, add up to the charge of the tensor. Addition of charges for Zn tensors\nis modulo n. For instance for a <code>charge=0</code> <code>TensorZ2</code> object this means that\nthe charges on each leg must add up to an even number for an element to be\nnon-zero. The whole point of this library is to store and use such symmetric\ntensors in an efficient way, where we don't waste memory or computation time on\nthe elements we know are zero by symmetry, and can't accidentally let them be\nnon-zero.</p>\n<p>Here's a simple nonsense example of how abeliantensors can be used:</p>\n<pre><code>import numpy as np\nfrom abeliantensors import TensorZ2\n\n# Create a symmetric tensor from an ndarray. All elements that should be zero\n# by symmetry are simply discarded, whether they are zero or not.\nsigmaz = np.array([[1, 0], [0, -1]])\nsigmaz = TensorZ2.from_ndarray(\n    sigmaz, shape=[[1, 1], [1, 1]], qhape=[[0, 1], [0, 1]], dirs=[1, -1]\n)\n\n# Create a random symmetric tensor.\na = TensorZ2.random(\n    shape=[[3, 2], [2, 4], [4, 4], [1, 1]],\n    qhape=[[0, 1]] * 4,\n    dirs=[-1, 1, 1, -1],\n)\n\n# Do a singular value decomposition of a tensor, thinking of it as a matrix\n# with some of the indices combined to a single matrix index, like one does\n# with numpy.reshape. Here we combine indices 0 and 2 to form the left matrix\n# index, and 1 and 3 to form the right one. The indices are reshaped back to\n# the original form after the SVD, so U and V are in this case order-3 tensors.\nU, S, V = a.svd([0, 2], [1, 3])\n\n# You can also do a truncated SVD, in this case to truncating to dimension 4.\nU, S, V = a.svd([0, 2], [1, 3], chis=4)\n\n# We can contract tensors together easily using the ncon package.\n# Note that conjugation flips the direction of each index, as well as the\n# charge of the tensor, which in this case though is 0.\nfrom ncon import ncon\naadg = ncon((a, a.conjugate()), ([1, 2, -1, -2], [1, 2, -11, -12]))\n\n# Finally, knowing that aadg is Hermitian, do an eigenvalue\n# decomposition of it, this time truncating not to a specific dimension, but\n# to a maximum relative truncation error of 1e-5.\nE, U = aadg.eig([0, 1], [2, 3], hermitian=True, eps=1e-5)\n</code></pre>\n<p>There are many other user-facing methods and features, for more, see\nthe <a href=\"https://abeliantensors.readthedocs.io/en/latest/API.html\" rel=\"nofollow\">API docs</a>.</p>\n<h2>Demo and performance</h2>\n<p>The folder <code>demo</code> has an implementation of Levin and Nave's <a href=\"https://arxiv.org/abs/cond-mat/0611687\" rel=\"nofollow\">TRG\nalgorithm</a>, and a script\nthat runs it on the square lattice Ising model, using both symmetric tensors\nof the TensorZ2 class and dense Tensors, and compares the run times.\nBelow is a plot of how long it takes to run a single TRG step at various\nbond dimensions for both of them.</p>\n<p><img alt=\"Running time of a single TRG step as a function of bond dimension, compared between using and not using symmetric tensors\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f5ccd2a11b3a3e56a2a417ebd29cbd742a7c1285/64656d6f2f7472675f706572666f726d616e63652e737667\"></p>\n<p>Note that both axes are logarithmic.</p>\n<p>At low bond dimensions the simple <code>Tensor</code> class outperforms <code>TensorZ2</code>, because\nkeeping track of the symmetry structure imposes an overhead. The time\ncomplexity of the overhead is subleading as a function of bond dimension, and\nas one goes to higher bond dimensions the symmetric tensors become faster.\nAsymptotically both have the same scaling as a function of bond dimension, but\nthe prefactor is smaller for <code>TensorZ2</code> by a factor of 1/4. This is because\ninstead of multiplying or decomposing an <code>m</code> x <code>m</code> matrix at cost <code>m**3</code>, we\nare multiplying two <code>m/2</code> by <code>m/2</code> matrices, at a total cost of <code>2*(m/2)**3 = (m**3)/4</code>.  For larger symmetry groups, the asymptotic benefit would be\ngreater. For instance for <code>TensorZ3</code>, we should see an approximately 9-fold\nspeed-up.</p>\n<p>Similar results can be obtained for other algorithms, although the cross-over\npoint in bond dimension will be different.</p>\n<h2>Design and structure</h2>\n<p>The implementation is built on top of numpy, and the block-wise sparse\nstructure of the symmetry preserving tensors is implemented with Python\ndictionaries. Here's a quick summary of what each file does.</p>\n<p><code>tensorcommon.py</code>: A parent class of all the other classes, <code>TensorCommon</code>,\nthat implements some higher-level features using the lower-level methods.</p>\n<p><code>abeliantensor.py</code>: All the fun is in here. Implements the class\n<code>AbelianTensor</code>, that is the parent of all the symmetric tensor classes. This\nincludes implementations of various common tensor operations, such as\ncontractions and decompositions, preserving and making use of the block-wise\nsparse structure these tensors have.</p>\n<p><code>tensor.py</code>: <code>Tensor</code>, the wrapper class for numpy arrays. It is designed so that\nany call to a method of the <code>AbelianTensor</code> class is also a valid call to a\nsimilarly named method of the <code>Tensor</code> class. All the symmetry-related\ninformation is simply discarded and some underlying numpy function is called.\nEven if one doesn't use symmetry preserving tensors, the <code>Tensor</code> class provides\nsome neat convenience functions, such as an easy-to-read one-liner for the\ntranspose-reshape-decompose-reshape-transpose procedure for singular value and\neigenvalue decompositions of tensors.</p>\n<p><code>symmetrytensors.py</code>: A small file that simply creates subclasses of\n<code>AbelianTensor</code> for specific symmetry groups. If you need something other than\nZ2, Z3 and U(1), check this file to see how you could add what you need.</p>\n<h2>Tests</h2>\n<p>The <code>tests</code> folder has plenty of tests for the various classes. They can be run\nby calling <code>pytest</code>, provided abeliantensors was installed with the extras option\n<code>tests</code>.</p>\n<p>Most of the tests are based on generating a random instance of one of the\n\"fancy\" tensor classes in this package, and confirming that the following\ndiagram commutes:</p>\n<pre><code>Fancy tensor \u2500\u2500\u2500 map to numpy ndarray \u2500\u2500\u2500&gt; ndarray\n    \u2502                                         \u2502\n    \u2502                                         \u2502\nDo the thing                             Do the thing\n    \u2502                                         \u2502\n    \u2502                                         \u2502\n    V                                         V\nFancy tensor \u2500\u2500\u2500 map to numpy ndarray \u2500\u2500\u2500&gt; ndarray\n</code></pre>\n<p>Two command line arguments can be provided, <code>--n_iters</code> which sets how many\ntimes each test is run, with different random tensors each time (100 by\ndefault), and <code>--tensorclass</code> which can be used to specify which\ntensorclass(es) the tests are run on (by default all of them). Here's an\nexample of how one might run a specific test repeatedly:</p>\n<pre><code>pytest tests/test_tensors.py::test_to_and_from_ndarray --tensorclass TensorZ2 --n_iters 1000\n</code></pre>\n\n          </div>"}, "last_serial": 6622666, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "aef067e614a1eca0c0b22047cf342df4", "sha256": "e5bcfb2a3a6db3b98dc507a4fbc120c4450773161f26bbd27a1321dc4dbba987"}, "downloads": -1, "filename": "abeliantensors-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "aef067e614a1eca0c0b22047cf342df4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 40570, "upload_time": "2020-02-13T11:15:39", "upload_time_iso_8601": "2020-02-13T11:15:39.806515Z", "url": "https://files.pythonhosted.org/packages/db/30/c09b7fa7a3dcfd2b395eccc6fb107ddf00b8054ab3d00ac87d5f4fee29a1/abeliantensors-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "57c93663d3e5f641d5999669600433c6", "sha256": "815b4801b0707001b0393f72b7ec6a1588b4441c3cab608aa11625ce09159e7c"}, "downloads": -1, "filename": "abeliantensors-0.1.0.tar.gz", "has_sig": false, "md5_digest": "57c93663d3e5f641d5999669600433c6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40219, "upload_time": "2020-02-13T11:15:42", "upload_time_iso_8601": "2020-02-13T11:15:42.396365Z", "url": "https://files.pythonhosted.org/packages/90/15/0a838eb6edae21b83bff7acc2766c604eeac964a1abef164bcc2b630fc27/abeliantensors-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "aef067e614a1eca0c0b22047cf342df4", "sha256": "e5bcfb2a3a6db3b98dc507a4fbc120c4450773161f26bbd27a1321dc4dbba987"}, "downloads": -1, "filename": "abeliantensors-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "aef067e614a1eca0c0b22047cf342df4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 40570, "upload_time": "2020-02-13T11:15:39", "upload_time_iso_8601": "2020-02-13T11:15:39.806515Z", "url": "https://files.pythonhosted.org/packages/db/30/c09b7fa7a3dcfd2b395eccc6fb107ddf00b8054ab3d00ac87d5f4fee29a1/abeliantensors-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "57c93663d3e5f641d5999669600433c6", "sha256": "815b4801b0707001b0393f72b7ec6a1588b4441c3cab608aa11625ce09159e7c"}, "downloads": -1, "filename": "abeliantensors-0.1.0.tar.gz", "has_sig": false, "md5_digest": "57c93663d3e5f641d5999669600433c6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 40219, "upload_time": "2020-02-13T11:15:42", "upload_time_iso_8601": "2020-02-13T11:15:42.396365Z", "url": "https://files.pythonhosted.org/packages/90/15/0a838eb6edae21b83bff7acc2766c604eeac964a1abef164bcc2b630fc27/abeliantensors-0.1.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 15:55:17 2020"}