{"info": {"author": "Robin Br\u00fcgger", "author_email": "brueggerrobin+revtorch@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# RevTorch\nFramework for creating (partially) reversible neural networks with PyTorch\n\nRevTorch is introduced and explained in our paper [A Partially Reversible U-Net for Memory-Efficient Volumetric Image Segmentation](https://arxiv.org/abs/1906.06148),\nwhich was accepted for presentation at [MICCAI 2019](https://www.miccai2019.org/). \n\nIf you find this code helpful in your research please cite the following paper:\n```\n@article{PartiallyRevUnet2019Bruegger,\n         author={Br{\\\"u}gger, Robin and Baumgartner, Christian F.\n         and Konukoglu, Ender},\n         title={A Partially Reversible U-Net for Memory-Efficient Volumetric Image Segmentation},\n         journal={arXiv:1906.06148},\n         year={2019},\n```\n\n## Installation\nUse pip to install RevTorch:\n```sh\n$ pip install revtorch\n```\nRevTorch requires PyTorch. However, PyTorch is not included in the dependencies since the required PyTorch version is dependent on your system. Please install PyTorch following the instructions on the [PyTorch website](https://pytorch.org/).\n\n## Usage\nThis example shows how to use the RevTorch framework.\n```python\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport revtorch as rv\n\ndef train():\n    trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n\n    net = PartiallyReversibleNet()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(net.parameters())\n\n    for epoch in range(2):\n\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            inputs, labels = data\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            #logging stuff\n            running_loss += loss.item()\n            LOG_INTERVAL = 200\n            if i % LOG_INTERVAL == (LOG_INTERVAL-1):  # print every 2000 mini-batches\n                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / LOG_INTERVAL))\n                running_loss = 0.0\n\nclass PartiallyReversibleNet(nn.Module):\n    def __init__(self):\n        super(PartiallyReversibleNet, self).__init__()\n\n        #initial non-reversible convolution to get to 32 channels\n        self.conv1 = nn.Conv2d(3, 32, 3)\n\n        #construct reversible sequencce with 4 reversible blocks\n        blocks = []\n        for i in range(4):\n\n            #f and g must both be a nn.Module whos output has the same shape as its input\n            f_func = nn.Sequential(nn.ReLU(), nn.Conv2d(16, 16, 3, padding=1))\n            g_func = nn.Sequential(nn.ReLU(), nn.Conv2d(16, 16, 3, padding=1))\n\n            #we construct a reversible block with our F and G functions\n            blocks.append(rv.ReversibleBlock(f_func, g_func))\n\n        #pack all reversible blocks into a reversible sequence\n        self.sequence = rv.ReversibleSequence(nn.ModuleList(blocks))\n\n        #non-reversible convolution to get to 10 channels (one for each label)\n        self.conv2 = nn.Conv2d(32, 10, 3)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        #the reversible sequence can be used like any other nn.Module. Memory-saving backpropagation is used automatically\n        x = self.sequence(x)\n\n        x = self.conv2(F.relu(x))\n        x = F.avg_pool2d(x, (x.shape[2], x.shape[3]))\n        x = x.view(x.shape[0], x.shape[1])\n        return x\n\nif __name__ == \"__main__\":\n    train()\n```\n\n## Python version\nTested with Python 3.6 and PyTorch 1.1.0. Should work with any version of Python 3.\n\n## Changelog\n\n#### Version 0.2.4\n- Added option to disable eager discarding of variables to allow for multiple backward() calls\n\n#### Version 0.2.3\n- Added option to use the same random seed for the forward and backwar pass ([Pull request](https://github.com/RobinBruegger/RevTorch/pull/4))\n\n#### Version 0.2.1\n- Added option to select the dimension along which the tensor is split ([Pull request](https://github.com/RobinBruegger/RevTorch/pull/2))\n\n#### Version 0.2.0\n- Fixed memory leak when not consuming output of the reversible block ([Issue](https://github.com/RobinBruegger/RevTorch/issues/1))\n\n#### Version 0.1.0\n- Initial release", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/RobinBruegger/RevTorch/archive/v0.2.4.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/RobinBruegger/RevTorch", "keywords": "reversbile neural network", "license": "bsd-3-clause", "maintainer": "", "maintainer_email": "", "name": "revtorch", "package_url": "https://pypi.org/project/revtorch/", "platform": "", "project_url": "https://pypi.org/project/revtorch/", "project_urls": {"Download": "https://github.com/RobinBruegger/RevTorch/archive/v0.2.4.tar.gz", "Homepage": "https://github.com/RobinBruegger/RevTorch"}, "release_url": "https://pypi.org/project/revtorch/0.2.4/", "requires_dist": null, "requires_python": "", "summary": "Framework for creating (partially) reversible neural networks with PyTorch", "version": "0.2.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>RevTorch</h1>\n<p>Framework for creating (partially) reversible neural networks with PyTorch</p>\n<p>RevTorch is introduced and explained in our paper <a href=\"https://arxiv.org/abs/1906.06148\" rel=\"nofollow\">A Partially Reversible U-Net for Memory-Efficient Volumetric Image Segmentation</a>,\nwhich was accepted for presentation at <a href=\"https://www.miccai2019.org/\" rel=\"nofollow\">MICCAI 2019</a>.</p>\n<p>If you find this code helpful in your research please cite the following paper:</p>\n<pre><code>@article{PartiallyRevUnet2019Bruegger,\n         author={Br{\\\"u}gger, Robin and Baumgartner, Christian F.\n         and Konukoglu, Ender},\n         title={A Partially Reversible U-Net for Memory-Efficient Volumetric Image Segmentation},\n         journal={arXiv:1906.06148},\n         year={2019},\n</code></pre>\n<h2>Installation</h2>\n<p>Use pip to install RevTorch:</p>\n<pre>$ pip install revtorch\n</pre>\n<p>RevTorch requires PyTorch. However, PyTorch is not included in the dependencies since the required PyTorch version is dependent on your system. Please install PyTorch following the instructions on the <a href=\"https://pytorch.org/\" rel=\"nofollow\">PyTorch website</a>.</p>\n<h2>Usage</h2>\n<p>This example shows how to use the RevTorch framework.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"k\">as</span> <span class=\"nn\">transforms</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"k\">as</span> <span class=\"nn\">F</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.optim</span> <span class=\"k\">as</span> <span class=\"nn\">optim</span>\n<span class=\"kn\">import</span> <span class=\"nn\">revtorch</span> <span class=\"k\">as</span> <span class=\"nn\">rv</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">():</span>\n    <span class=\"n\">trainset</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">CIFAR10</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s2\">\"./data\"</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">())</span>\n    <span class=\"n\">trainloader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">trainset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">PartiallyReversibleNet</span><span class=\"p\">()</span>\n    <span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n    <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n\n        <span class=\"n\">running_loss</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">data</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">trainloader</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">):</span>\n            <span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">data</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n            <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n            <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n            <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n\n            <span class=\"c1\">#logging stuff</span>\n            <span class=\"n\">running_loss</span> <span class=\"o\">+=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n            <span class=\"n\">LOG_INTERVAL</span> <span class=\"o\">=</span> <span class=\"mi\">200</span>\n            <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"n\">LOG_INTERVAL</span> <span class=\"o\">==</span> <span class=\"p\">(</span><span class=\"n\">LOG_INTERVAL</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">):</span>  <span class=\"c1\"># print every 2000 mini-batches</span>\n                <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'[</span><span class=\"si\">%d</span><span class=\"s1\">, </span><span class=\"si\">%5d</span><span class=\"s1\">] loss: </span><span class=\"si\">%.3f</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">epoch</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">running_loss</span> <span class=\"o\">/</span> <span class=\"n\">LOG_INTERVAL</span><span class=\"p\">))</span>\n                <span class=\"n\">running_loss</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">PartiallyReversibleNet</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">PartiallyReversibleNet</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n\n        <span class=\"c1\">#initial non-reversible convolution to get to 32 channels</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">#construct reversible sequencce with 4 reversible blocks</span>\n        <span class=\"n\">blocks</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n\n            <span class=\"c1\">#f and g must both be a nn.Module whos output has the same shape as its input</span>\n            <span class=\"n\">f_func</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n            <span class=\"n\">g_func</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n\n            <span class=\"c1\">#we construct a reversible block with our F and G functions</span>\n            <span class=\"n\">blocks</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">rv</span><span class=\"o\">.</span><span class=\"n\">ReversibleBlock</span><span class=\"p\">(</span><span class=\"n\">f_func</span><span class=\"p\">,</span> <span class=\"n\">g_func</span><span class=\"p\">))</span>\n\n        <span class=\"c1\">#pack all reversible blocks into a reversible sequence</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">sequence</span> <span class=\"o\">=</span> <span class=\"n\">rv</span><span class=\"o\">.</span><span class=\"n\">ReversibleSequence</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ModuleList</span><span class=\"p\">(</span><span class=\"n\">blocks</span><span class=\"p\">))</span>\n\n        <span class=\"c1\">#non-reversible convolution to get to 10 channels (one for each label)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">#the reversible sequence can be used like any other nn.Module. Memory-saving backpropagation is used automatically</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">sequence</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">avg_pool2d</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"n\">train</span><span class=\"p\">()</span>\n</pre>\n<h2>Python version</h2>\n<p>Tested with Python 3.6 and PyTorch 1.1.0. Should work with any version of Python 3.</p>\n<h2>Changelog</h2>\n<h4>Version 0.2.4</h4>\n<ul>\n<li>Added option to disable eager discarding of variables to allow for multiple backward() calls</li>\n</ul>\n<h4>Version 0.2.3</h4>\n<ul>\n<li>Added option to use the same random seed for the forward and backwar pass (<a href=\"https://github.com/RobinBruegger/RevTorch/pull/4\" rel=\"nofollow\">Pull request</a>)</li>\n</ul>\n<h4>Version 0.2.1</h4>\n<ul>\n<li>Added option to select the dimension along which the tensor is split (<a href=\"https://github.com/RobinBruegger/RevTorch/pull/2\" rel=\"nofollow\">Pull request</a>)</li>\n</ul>\n<h4>Version 0.2.0</h4>\n<ul>\n<li>Fixed memory leak when not consuming output of the reversible block (<a href=\"https://github.com/RobinBruegger/RevTorch/issues/1\" rel=\"nofollow\">Issue</a>)</li>\n</ul>\n<h4>Version 0.1.0</h4>\n<ul>\n<li>Initial release</li>\n</ul>\n\n          </div>"}, "last_serial": 6545740, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "883389f9f732fb16808561a6404452d0", "sha256": "af9307d1250286c7c16a23c19f711af33b3dccc2cd98f1bc7b2e91cacfcd2695"}, "downloads": -1, "filename": "revtorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "883389f9f732fb16808561a6404452d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2819, "upload_time": "2019-06-13T11:41:28", "upload_time_iso_8601": "2019-06-13T11:41:28.956009Z", "url": "https://files.pythonhosted.org/packages/df/e3/28327129901ac65131ad8a948060a06642f0645ac52a1b25a1f7a0540c04/revtorch-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "f192076fb02e8261cb720ce340ce987a", "sha256": "a8bf17a05b8a4c7a3d0e559305ce3080d6fbdd6ab463764f03ad970541fa2ad6"}, "downloads": -1, "filename": "revtorch-0.1.1.tar.gz", "has_sig": false, "md5_digest": "f192076fb02e8261cb720ce340ce987a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4946, "upload_time": "2019-06-18T15:56:07", "upload_time_iso_8601": "2019-06-18T15:56:07.951666Z", "url": "https://files.pythonhosted.org/packages/e0/f0/10869ad425c8de0bee0ebd254d1ec75af69e9e1c7c97a2b4e828deede789/revtorch-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "0681cc6f6891e1572ccaaa86b44b477d", "sha256": "107b72f9dc3a8a581bb57e5909fea414bda2f738e916ffea5a0338c1cf3c9862"}, "downloads": -1, "filename": "revtorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "0681cc6f6891e1572ccaaa86b44b477d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4934, "upload_time": "2019-09-15T15:50:56", "upload_time_iso_8601": "2019-09-15T15:50:56.231288Z", "url": "https://files.pythonhosted.org/packages/ee/af/6b44c2def528b4d80e1f5719ef5954422e2efe4efeccc569d7075292054d/revtorch-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "581b1f6054833274c781a112f22aaf46", "sha256": "8358ec286bdec76e9e97f9aee4402a28167a5c2c0fe33f439353bd57a854c408"}, "downloads": -1, "filename": "revtorch-0.2.1.tar.gz", "has_sig": false, "md5_digest": "581b1f6054833274c781a112f22aaf46", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5108, "upload_time": "2020-01-09T20:43:43", "upload_time_iso_8601": "2020-01-09T20:43:43.402679Z", "url": "https://files.pythonhosted.org/packages/ac/c9/c357bfccd16e81b671316135873722fca8645223a16af466637d038e22a9/revtorch-0.2.1.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "77ebc5157af1df20e04f64d1b48b10d5", "sha256": "2c6eaca80d8ed980ab96df1ef4366d18283bed3e6c0ad99b9d7f65a38ce03b1d"}, "downloads": -1, "filename": "revtorch-0.2.3.tar.gz", "has_sig": false, "md5_digest": "77ebc5157af1df20e04f64d1b48b10d5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5354, "upload_time": "2020-01-23T22:04:40", "upload_time_iso_8601": "2020-01-23T22:04:40.811857Z", "url": "https://files.pythonhosted.org/packages/2d/73/b4f504d5bd2533cc5cd9feda5e442e08285a83162e4cc0b92d38b975e4a6/revtorch-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "bd103589b8b674e7a2a9b00030357c99", "sha256": "b028324b7430a7ee9311b0472e7bf741e40c51f8c266fb0cd2fd032f2679b0ec"}, "downloads": -1, "filename": "revtorch-0.2.4.tar.gz", "has_sig": false, "md5_digest": "bd103589b8b674e7a2a9b00030357c99", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5566, "upload_time": "2020-01-30T21:15:20", "upload_time_iso_8601": "2020-01-30T21:15:20.540649Z", "url": "https://files.pythonhosted.org/packages/7b/7f/6b2247e5ce4b8969dedfcaec064c59ce0417cddbe638bfa6169ff586eaea/revtorch-0.2.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bd103589b8b674e7a2a9b00030357c99", "sha256": "b028324b7430a7ee9311b0472e7bf741e40c51f8c266fb0cd2fd032f2679b0ec"}, "downloads": -1, "filename": "revtorch-0.2.4.tar.gz", "has_sig": false, "md5_digest": "bd103589b8b674e7a2a9b00030357c99", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5566, "upload_time": "2020-01-30T21:15:20", "upload_time_iso_8601": "2020-01-30T21:15:20.540649Z", "url": "https://files.pythonhosted.org/packages/7b/7f/6b2247e5ce4b8969dedfcaec064c59ce0417cddbe638bfa6169ff586eaea/revtorch-0.2.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:03:14 2020"}