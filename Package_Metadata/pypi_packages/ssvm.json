{"info": {"author": "Zi-Wen Gui", "author_email": "evan176@hotmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "SSVM-Python is a Python version of DSMI Lab's Smooth Support Vector Machine Toolbox\nSee: http://dmlab8.csie.ntust.edu.tw/download.html#toolbox\n\nReferences:\nSmooth Support Vector Machine is Prof.Lee's paper.\nSee: http://research.cs.wisc.edu/dmi/svm/ssvm/\n\nModel Selection for Support Vector Machines via Uniform Design\nSee: http://140.118.155.137/%E8%80%81%E5%B8%AB%E8%AB%96%E6%96%87/%E6%9C%9F%E5%88%8A/J8_Model%20Selection%20for%20Support%20Vector%20Machines%20via%20Uniform%20Design.pdf\n\nUniform Design Tables\nSee: http://uic.edu.hk/isci/UniformDesign/UD%20Tables.html\n\nUsage:\nPut SSVM-Python on the PYTHON-PATH and install \"Numpy\"\n\n=======================================================================================================\nTraining:\nTrainer( data, label_pos )                      Instantiate the Trainer object with a data set.\nTrainer.make( r = 1 , v = 1 )                   Setup the partitions to use for cross-validation.\nTrainer.tune( c = 100, g = 0.1, k = 1, s = 0 )  Set parameters for model training.\nTrainer.train()                                 Train\nTrainer.save( model_name = model)               Save the trained model.\n=======================================================================================================\n\n\n#Training\n1)Import the module\n----------------------------------\nfrom ssvm.trainer import Trainer\n\n2)Create a Trainer object\n----------------------------------\nA Trainer object expects to be initialized with a 2D Numpy array representing \ncontaining the data. label_pos indicates which column is the label.\n\ntrainer = Trainer( data, label_pos )\n\n3)Setup the Trainer\n----------------------------------\nr -> How much of the data to use for the reduced set\nv -> How many folds to use for cross-validation\n\ntrainer.make( r = 1 , v = 1 )\n\n4)Set Training parameters\n----------------------------------\nc = SVM penality\ng = gamma parameter of the RBF kernel\nk = linear vs nonlinear, 0 -> linear, 1 -> nonlinear\ns = How to deal with multi-class classification, 0 -> One-Against-One, 1 -> One-Against-Rest\n\ntrainer.tune( c = 100, g = 0.1, k = 1, s = 0 )\n\n5)Begin Training\n----------------------------------\nUse the train() method to begin training.\nWhich parameters are used during training depends on what was passed to the\ntune() method earlier.\n\ntrainer.train()\n\n6)Save the model\n----------------------------------\nSave the trained model to use for prediction later on.\ntrainer.save( model_name = model )\n\n\n\n=======================================================================================================\nPrediction:\nPredictor( model )                              Instantiate Predictor object with a saved trained model\nPredictor.predict( data )                       Make prediction on data with the Predictor object\n=======================================================================================================\n\n\n\n#Prediction\n1)Indicated the saved model to use\n----------------------------------\nfrom ssvm.predictor import Predictor\npredictor = Predictor( model.pkl )\n\n2)Make predictions\n----------------------------------\nUse the Predictor to make predictions on the data, assumed to be 2D numpy array\nwith the same number of columns (minus the label) as that used in the Training \nobject.\n\npredictor.predict( data )\n\n\n\n=======================================================================================================\nTuning:\nGridSearch(trainer, C_start=-6, C_end=10, G_start=-12, r=1, v=10, k=1, s=0) \n                                                Hyperparameter optimization\nHibiscus(trainer, fround=13, sround=9, tround=5, C_start=-6, C_end=10, G_start=-12, r=1, v=10, k=1, s=0)\n                                                Fast model selection via uniform design\n=======================================================================================================\n\n\n\n#Tuning\n1)GridSearch\n----------------------------------\nFirst, we instantiate the Trainer object with a data set and import the GirdSearch function from tuning.\nSetting trainer before we start training.\n\ntrainer.make(r = 1, v = 10)\n\nReturn is list [Best_C, Best_G].\nThere also print others information.\n\nfrom ssvm.tuning import GridSearch\n[Best_C, Best_G] = GridSearch( trainer, -3, 12, -6 )\n\n\"\"\"\nBest C value: XXX\nBest Gamma value: XXX\nTraining accuracy: XXX\nValidation accuracy: XXX\nDuring time: XXX\n\"\"\"\n\n2)Hibiscus\n----------------------------------\nFirst, we instantiate the Trainer object with a data set and import the Hibiscus function from tuning.\nSetting trainer before we start training.\n\ntrainer.make(r = 1, v = 10)\n\n\nWe need to assign how much point want to sprinkle in three round.\nUniform table range: 3 ~ 30\nReturn is list [Best_C, Best_G]\nThere also print others information.\n\nfrom ssvm.tuning import Hibiscus\n[Best_C, Best_G] = Hibiscus( trainer, 30, 20, 10 )\n\n\"\"\"\nBest C value: XXX\nBest Gamma value: XXX\nTraining accuracy: XXX\nValidation accuracy: XXX\nDuring time: XXX\n\"\"\"\n\n\n\n\n=======================================================================================================\n\nIf you have any questions, please contact any of the following:\nAuthor:\n    Prof.Lee(yuh-jye@mail.ntust.edu.tw)\nMaintainer:\n    Evan(evan176@hotmail.com)\n    \n=======================================================================================================", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://dmlab8.csie.ntust.edu.tw/", "keywords": null, "license": "UNKNOWN", "maintainer": null, "maintainer_email": null, "name": "ssvm", "package_url": "https://pypi.org/project/ssvm/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/ssvm/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://dmlab8.csie.ntust.edu.tw/"}, "release_url": "https://pypi.org/project/ssvm/0.24/", "requires_dist": null, "requires_python": null, "summary": "fix data module problem", "version": "0.24", "yanked": false, "html_description": "<div class=\"project-description\">\n            SSVM-Python is a Python version of DSMI Lab's Smooth Support Vector Machine Toolbox<br>See: http://dmlab8.csie.ntust.edu.tw/download.html#toolbox<br><br>References:<br>Smooth Support Vector Machine is Prof.Lee's paper.<br>See: http://research.cs.wisc.edu/dmi/svm/ssvm/<br><br>Model Selection for Support Vector Machines via Uniform Design<br>See: http://140.118.155.137/%E8%80%81%E5%B8%AB%E8%AB%96%E6%96%87/%E6%9C%9F%E5%88%8A/J8_Model%20Selection%20for%20Support%20Vector%20Machines%20via%20Uniform%20Design.pdf<br><br>Uniform Design Tables<br>See: http://uic.edu.hk/isci/UniformDesign/UD%20Tables.html<br><br>Usage:<br>Put SSVM-Python on the PYTHON-PATH and install \"Numpy\"<br><br>=======================================================================================================<br>Training:<br>Trainer( data, label_pos )                      Instantiate the Trainer object with a data set.<br>Trainer.make( r = 1 , v = 1 )                   Setup the partitions to use for cross-validation.<br>Trainer.tune( c = 100, g = 0.1, k = 1, s = 0 )  Set parameters for model training.<br>Trainer.train()                                 Train<br>Trainer.save( model_name = model)               Save the trained model.<br>=======================================================================================================<br><br><br>#Training<br>1)Import the module<br>----------------------------------<br>from ssvm.trainer import Trainer<br><br>2)Create a Trainer object<br>----------------------------------<br>A Trainer object expects to be initialized with a 2D Numpy array representing <br>containing the data. label_pos indicates which column is the label.<br><br>trainer = Trainer( data, label_pos )<br><br>3)Setup the Trainer<br>----------------------------------<br>r -&gt; How much of the data to use for the reduced set<br>v -&gt; How many folds to use for cross-validation<br><br>trainer.make( r = 1 , v = 1 )<br><br>4)Set Training parameters<br>----------------------------------<br>c = SVM penality<br>g = gamma parameter of the RBF kernel<br>k = linear vs nonlinear, 0 -&gt; linear, 1 -&gt; nonlinear<br>s = How to deal with multi-class classification, 0 -&gt; One-Against-One, 1 -&gt; One-Against-Rest<br><br>trainer.tune( c = 100, g = 0.1, k = 1, s = 0 )<br><br>5)Begin Training<br>----------------------------------<br>Use the train() method to begin training.<br>Which parameters are used during training depends on what was passed to the<br>tune() method earlier.<br><br>trainer.train()<br><br>6)Save the model<br>----------------------------------<br>Save the trained model to use for prediction later on.<br>trainer.save( model_name = model )<br><br><br><br>=======================================================================================================<br>Prediction:<br>Predictor( model )                              Instantiate Predictor object with a saved trained model<br>Predictor.predict( data )                       Make prediction on data with the Predictor object<br>=======================================================================================================<br><br><br><br>#Prediction<br>1)Indicated the saved model to use<br>----------------------------------<br>from ssvm.predictor import Predictor<br>predictor = Predictor( model.pkl )<br><br>2)Make predictions<br>----------------------------------<br>Use the Predictor to make predictions on the data, assumed to be 2D numpy array<br>with the same number of columns (minus the label) as that used in the Training <br>object.<br><br>predictor.predict( data )<br><br><br><br>=======================================================================================================<br>Tuning:<br>GridSearch(trainer, C_start=-6, C_end=10, G_start=-12, r=1, v=10, k=1, s=0) <br>                                                Hyperparameter optimization<br>Hibiscus(trainer, fround=13, sround=9, tround=5, C_start=-6, C_end=10, G_start=-12, r=1, v=10, k=1, s=0)<br>                                                Fast model selection via uniform design<br>=======================================================================================================<br><br><br><br>#Tuning<br>1)GridSearch<br>----------------------------------<br>First, we instantiate the Trainer object with a data set and import the GirdSearch function from tuning.<br>Setting trainer before we start training.<br><br>trainer.make(r = 1, v = 10)<br><br>Return is list [Best_C, Best_G].<br>There also print others information.<br><br>from ssvm.tuning import GridSearch<br>[Best_C, Best_G] = GridSearch( trainer, -3, 12, -6 )<br><br>\"\"\"<br>Best C value: XXX<br>Best Gamma value: XXX<br>Training accuracy: XXX<br>Validation accuracy: XXX<br>During time: XXX<br>\"\"\"<br><br>2)Hibiscus<br>----------------------------------<br>First, we instantiate the Trainer object with a data set and import the Hibiscus function from tuning.<br>Setting trainer before we start training.<br><br>trainer.make(r = 1, v = 10)<br><br><br>We need to assign how much point want to sprinkle in three round.<br>Uniform table range: 3 ~ 30<br>Return is list [Best_C, Best_G]<br>There also print others information.<br><br>from ssvm.tuning import Hibiscus<br>[Best_C, Best_G] = Hibiscus( trainer, 30, 20, 10 )<br><br>\"\"\"<br>Best C value: XXX<br>Best Gamma value: XXX<br>Training accuracy: XXX<br>Validation accuracy: XXX<br>During time: XXX<br>\"\"\"<br><br><br><br><br>=======================================================================================================<br><br>If you have any questions, please contact any of the following:<br>Author:<br>    Prof.Lee(yuh-jye@mail.ntust.edu.tw)<br>Maintainer:<br>    Evan(evan176@hotmail.com)<br>    <br>=======================================================================================================\n          </div>"}, "last_serial": 1102740, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "5e117ed01ccaa82eb39519a9333b029d", "sha256": "dba8eddce0585237788696e275a42b317a6fc57f419b45a4365eba483c0a192e"}, "downloads": -1, "filename": "ssvm-0.1.tar.gz", "has_sig": false, "md5_digest": "5e117ed01ccaa82eb39519a9333b029d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12435, "upload_time": "2013-05-28T16:32:26", "upload_time_iso_8601": "2013-05-28T16:32:26.836331Z", "url": "https://files.pythonhosted.org/packages/2f/4a/d602286aad2ac1728e84b979e2373acd6a66d19998485365a2348d4deb4b/ssvm-0.1.tar.gz", "yanked": false}], "0.11": [{"comment_text": "", "digests": {"md5": "ed58c547b49a429e272ab5c597378d64", "sha256": "c7160ec236495a95c02727ca05bb9ea57b5f0a6f0524420c613d824f385c34a8"}, "downloads": -1, "filename": "ssvm-0.11.tar.gz", "has_sig": false, "md5_digest": "ed58c547b49a429e272ab5c597378d64", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11413, "upload_time": "2013-06-06T07:28:15", "upload_time_iso_8601": "2013-06-06T07:28:15.991901Z", "url": "https://files.pythonhosted.org/packages/11/7a/bd89297602fd79f7671dad67cd880c5b2401afcd2c2dd0f9adb68b72e317/ssvm-0.11.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "09022d52d7acad3b39f45f62e77f9e4c", "sha256": "f65c818cd896b21a522fc3eae677467e384f95f82f16dbe17d7fd642d1886ad9"}, "downloads": -1, "filename": "ssvm-0.2.tar.gz", "has_sig": false, "md5_digest": "09022d52d7acad3b39f45f62e77f9e4c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15043, "upload_time": "2013-08-18T06:18:56", "upload_time_iso_8601": "2013-08-18T06:18:56.545062Z", "url": "https://files.pythonhosted.org/packages/fa/17/4778e08f46ce2ed7833b1ef16be8c202db72eeacd85d02eafc525df1c1e1/ssvm-0.2.tar.gz", "yanked": false}], "0.21": [{"comment_text": "", "digests": {"md5": "ed6d88e7f58199a85fae4cae16a77d11", "sha256": "eeab361e6892d3df1750d8432c23bdf26e056b19ffb5a77fd3c156cfec612352"}, "downloads": -1, "filename": "ssvm-0.21.tar.gz", "has_sig": false, "md5_digest": "ed6d88e7f58199a85fae4cae16a77d11", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15063, "upload_time": "2013-08-25T12:57:35", "upload_time_iso_8601": "2013-08-25T12:57:35.275630Z", "url": "https://files.pythonhosted.org/packages/84/e1/c8ba7e81603225d86f60448d4d040a70c6b5fcc064600bf5dbcfc027b8ac/ssvm-0.21.tar.gz", "yanked": false}], "0.22": [{"comment_text": "", "digests": {"md5": "84af3789601201f1c6e761e4d5fc35a1", "sha256": "ad7356ea4606a151e2b8119f55371dbe306d778842b66b9e4c6c4ebdfe53b37c"}, "downloads": -1, "filename": "ssvm-0.22.tar.gz", "has_sig": false, "md5_digest": "84af3789601201f1c6e761e4d5fc35a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14839, "upload_time": "2013-09-02T03:21:40", "upload_time_iso_8601": "2013-09-02T03:21:40.350725Z", "url": "https://files.pythonhosted.org/packages/75/a1/d00ac9884a1c0018814e73da3020c6089fd93e78b33db37a83d7740b44b1/ssvm-0.22.tar.gz", "yanked": false}], "0.23": [], "0.24": [], "0.3": [{"comment_text": "", "digests": {"md5": "755b9545edf842b39ca14e291dc9d675", "sha256": "95c07d41c6fae658eb9b762c9b6cda9299c5856d0a21f4cbef448291ef5917d8"}, "downloads": -1, "filename": "ssvm-0.3.zip", "has_sig": false, "md5_digest": "755b9545edf842b39ca14e291dc9d675", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17345, "upload_time": "2014-05-24T05:40:37", "upload_time_iso_8601": "2014-05-24T05:40:37.148126Z", "url": "https://files.pythonhosted.org/packages/53/21/3a6a8f850608a763bebe77124553d3a76228319a4e291f031903d15a216c/ssvm-0.3.zip", "yanked": false}]}, "urls": [], "timestamp": "Fri May  8 03:02:55 2020"}