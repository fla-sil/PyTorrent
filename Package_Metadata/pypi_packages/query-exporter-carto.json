{"info": {"author": "Geographica.gs (fork from https://github.com/albertodonato/query-exporter)", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: System Administrators", "License :: OSI Approved :: GNU General Public License (GPL)", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Utilities"], "description": "query-exporter - Export Prometheus metrics from SQL queries\n===========================================================\n\n|Latest Version| |Build Status| |Coverage Status| |Snap Status|\n\n``query-exporter`` is a Prometheus_ exporter which allows collecting metrics\nfrom database queries, at specified time intervals.\n\nIt uses SQLAlchemy_ to connect to different database engines, including\nPostgreSQL, MySQL, Oracle and Microsoft SQL Server.\n\nEach query can be run on multiple databases, and update multiple metrics.\n\nThe application is called with a configuration file that looks like this:\n\n.. code:: yaml\n\n    databases:\n      db1:\n        dsn: sqlite://\n      db2:\n        dsn: sqlite://\n\n    metrics:\n      metric1:\n        type: gauge\n        description: A sample gauge\n      metric2:\n        type: summary\n        description: A sample summary\n      metric3:\n        type: histogram\n        description: A sample histogram\n        buckets: [10, 20, 50, 100, 1000]\n      metric4:\n        type: enum\n        description: A sample enum\n        states: [foo, bar, baz]\n\n    queries:\n      query1:\n        interval: 5\n        databases: [db1]\n        metrics: [metric1]\n        sql: SELECT random() / 1000000000000000\n      query2:\n        interval: 20\n        databases: [db1, db2]\n        metrics: [metric2, metric3]\n        sql: |\n          SELECT abs(random() / 1000000000000000),\n                 abs(random() / 10000000000000000)\n      query3:\n        interval: 10\n        databases: [db2]\n        metrics: [metric4]\n        sql: |\n          SELECT value FROM (\n            SELECT 'foo' AS value UNION\n            SELECT 'bar'\n            UNION SELECT 'baz')\n          ORDER BY random()\n          LIMIT 1\n\n\nThe ``dsn`` connection string has the following format::\n\n    dialect[+driver]://[username:password][@host:port]/database\n\n(see `SQLAlchemy documentation`_ for details on the available options).\n\nThe ``metrics`` list in the query configuration must match values returned by\nthe query defined in ``sql``.\n\nThe ``interval`` value is interpreted as seconds if no suffix is specified;\nvalid suffix are ``s``, ``m``, ``h``, ``d``. Only integer values can be\nspecified. If no value is specified (or specified as ``null``), the query is\nexecuted at every HTTP request.\n\nQueries will usually return a single row, but multiple rows are supported, and\neach row will cause an update of the related metrics.  This is relevant for any\nkind of metric except gauges, which will be effectively updated to the value\nfrom the last row.\n\nFor the configuration above, exported metrics look like this::\n\n    # HELP metric1 A sample gauge\n    # TYPE metric1 gauge\n    metric1{database=\"db1\"} 1549.0\n    # HELP metric2 A sample summary\n    # TYPE metric2 summary\n    metric2_count{database=\"db2\"} 1.0\n    metric2_sum{database=\"db2\"} 5229.0\n    metric2_count{database=\"db1\"} 1.0\n    metric2_sum{database=\"db1\"} 4513.0\n    # TYPE metric2_created gauge\n    metric2_created{database=\"db2\"} 1.5456472955657206e+09\n    metric2_created{database=\"db1\"} 1.5456472955663064e+09\n    # HELP metric3 A sample histogram\n    # TYPE metric3 histogram\n    metric3_bucket{database=\"db2\",le=\"10.0\"} 0.0\n    metric3_bucket{database=\"db2\",le=\"20.0\"} 0.0\n    metric3_bucket{database=\"db2\",le=\"50.0\"} 0.0\n    metric3_bucket{database=\"db2\",le=\"100.0\"} 0.0\n    metric3_bucket{database=\"db2\",le=\"1000.0\"} 1.0\n    metric3_bucket{database=\"db2\",le=\"+Inf\"} 1.0\n    metric3_count{database=\"db2\"} 1.0\n    metric3_sum{database=\"db2\"} 714.0\n    metric3_bucket{database=\"db1\",le=\"10.0\"} 0.0\n    metric3_bucket{database=\"db1\",le=\"20.0\"} 0.0\n    metric3_bucket{database=\"db1\",le=\"50.0\"} 0.0\n    metric3_bucket{database=\"db1\",le=\"100.0\"} 0.0\n    metric3_bucket{database=\"db1\",le=\"1000.0\"} 1.0\n    metric3_bucket{database=\"db1\",le=\"+Inf\"} 1.0\n    metric3_count{database=\"db1\"} 1.0\n    metric3_sum{database=\"db1\"} 602.0\n    # TYPE metric3_created gauge\n    metric3_created{database=\"db2\"} 1.545647295565831e+09\n    metric3_created{database=\"db1\"} 1.5456472955663848e+09\n    # HELP metric4 A sample enum\n    # TYPE metric4 gauge\n    metric4{database=\"db2\",metric4=\"foo\"} 0.0\n    metric4{database=\"db2\",metric4=\"bar\"} 1.0\n    metric4{database=\"db2\",metric4=\"baz\"} 0.0\n\nMetrics are automatically tagged with the ``database`` label so that\nindipendent series are generated for each database.\n\n\nDatabase engines\n----------------\n\nSQLAlchemy doesn't depend on specific Python database modules at\ninstallation. This means additional modules might need to be installed for\nengines in use, as follows::\n\n    pip install SQLAlchemy[postgresql] SQLAlchemy[mysql] ...\n\nbased on which databased is in use.\n\nSee `supported databases`_ for details.\n\n\n.. _Prometheus: https://prometheus.io/\n.. _SQLAlchemy: https://www.sqlalchemy.org/\n.. _`SQLAlchemy documentation`:\n   http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls\n.. _`supported databases`:\n   http://docs.sqlalchemy.org/en/latest/core/engines.html#supported-databases\n\n.. |Latest Version| image:: https://img.shields.io/pypi/v/query-exporter.svg\n   :target: https://pypi.python.org/pypi/query-exporter\n.. |Build Status| image:: https://img.shields.io/travis/albertodonato/query-exporter.svg\n   :target: https://travis-ci.org/albertodonato/query-exporter\n.. |Coverage Status| image:: https://img.shields.io/codecov/c/github/albertodonato/query-exporter/master.svg\n   :target: https://codecov.io/gh/albertodonato/query-exporter\n.. |Snap Status| image:: https://build.snapcraft.io/badge/albertodonato/query-exporter.svg\n   :target: https://build.snapcraft.io/user/albertodonato/query-exporter\n\nCarto extension\n---------------\n\nYou can define a carto connection instead of a SQL DSN. If you want to do so, use a `carto:` entry in your database.\n\nExample::\n\n    databases:\n      test_carto:\n        carto:\n          user: my_carto_user\n          api_key: my_carto_api_key\n\n    metrics:\n      observations_simple_count:\n        type: gauge\n        description: Simple count to check if this works...\n\n    queries:\n      query_count_simple_count:\n        interval: 120s\n        databases: [test_carto]\n        metrics: [observations_simple_count]\n        sql: SELECT count(*) from county_population;\n\n\n* You cannot use both `dsn` and `carto` entries in the same database as that makes no sense.\n* The available fields for the configuration object are the same as for the Longitude CartoDataSource objects.\n* As of today, such fields are (keep in mind that some might not make sense for monitoring):\n\n  * ``api_version``: ``v2`` by default\n  * ``uses_batch``: ``False`` by default\n  * ``on_premise_domain``: ``''`` by default. If provided, the Carto URL will use it. If not, the default user URL will.\n  * ``api_key``: ``''`` by default. Mandatory. Master api key recommended.\n  * ``user``: ``''`` by default. Mandatory. CARTO user (not email)\n  * ``cache``: Empty by default. Cache configuration. Useless in this context for now.\n\nDevelopment environment\n-----------------------\n\nThe easiest way to install the required dependencies is to create a virtual environment and install the package:\n\n    python setup.py install\n    pipenv install -e .\n\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/GeographicaGS/query-exporter", "keywords": "sql metric prometheus exporter", "license": "GPLv3+", "maintainer": "Daniel Ramirez", "maintainer_email": "daniel.ramirez@geographica.com", "name": "query-exporter-carto", "package_url": "https://pypi.org/project/query-exporter-carto/", "platform": "", "project_url": "https://pypi.org/project/query-exporter-carto/", "project_urls": {"Homepage": "https://github.com/GeographicaGS/query-exporter"}, "release_url": "https://pypi.org/project/query-exporter-carto/1.5.1/", "requires_dist": ["aiohttp", "prometheus-client", "prometheus-aioexporter (>=1.5.1)", "PyYaml", "SQLAlchemy (==1.3.0b2)", "sqlalchemy-aio", "toolrack (>=2.1.0)", "geographica-longitude (==1.0.0a1)", "pytest ; extra == 'testing'", "pytest-asyncio ; extra == 'testing'", "pytest-mock ; extra == 'testing'"], "requires_python": "", "summary": "Publish Prometheus metrics generated from SQL queries (also for CARTO SQL API).", "version": "1.5.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://pypi.python.org/pypi/query-exporter\" rel=\"nofollow\"><img alt=\"Latest Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5665d129f71f7860e676e79ecb74e4358ce9dc60/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f71756572792d6578706f727465722e737667\"></a> <a href=\"https://travis-ci.org/albertodonato/query-exporter\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1573373dea8364743f9d5a7f3648da29d0b7e7a3/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f616c626572746f646f6e61746f2f71756572792d6578706f727465722e737667\"></a> <a href=\"https://codecov.io/gh/albertodonato/query-exporter\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bb287686fd6819d9ab1ee6551d2436e2faa624de/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f616c626572746f646f6e61746f2f71756572792d6578706f727465722f6d61737465722e737667\"></a> <a href=\"https://build.snapcraft.io/user/albertodonato/query-exporter\" rel=\"nofollow\"><img alt=\"Snap Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/22d5dda5f1f7e334e360a62ecd0e3179ebca1637/68747470733a2f2f6275696c642e736e617063726166742e696f2f62616467652f616c626572746f646f6e61746f2f71756572792d6578706f727465722e737667\"></a></p>\n<p><tt><span class=\"pre\">query-exporter</span></tt> is a <a href=\"https://prometheus.io/\" rel=\"nofollow\">Prometheus</a> exporter which allows collecting metrics\nfrom database queries, at specified time intervals.</p>\n<p>It uses <a href=\"https://www.sqlalchemy.org/\" rel=\"nofollow\">SQLAlchemy</a> to connect to different database engines, including\nPostgreSQL, MySQL, Oracle and Microsoft SQL Server.</p>\n<p>Each query can be run on multiple databases, and update multiple metrics.</p>\n<p>The application is called with a configuration file that looks like this:</p>\n<pre><span class=\"nt\">databases</span><span class=\"p\">:</span>\n  <span class=\"nt\">db1</span><span class=\"p\">:</span>\n    <span class=\"nt\">dsn</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">sqlite://</span>\n  <span class=\"nt\">db2</span><span class=\"p\">:</span>\n    <span class=\"nt\">dsn</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">sqlite://</span>\n\n<span class=\"nt\">metrics</span><span class=\"p\">:</span>\n  <span class=\"nt\">metric1</span><span class=\"p\">:</span>\n    <span class=\"nt\">type</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">gauge</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">A sample gauge</span>\n  <span class=\"nt\">metric2</span><span class=\"p\">:</span>\n    <span class=\"nt\">type</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">summary</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">A sample summary</span>\n  <span class=\"nt\">metric3</span><span class=\"p\">:</span>\n    <span class=\"nt\">type</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">histogram</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">A sample histogram</span>\n    <span class=\"nt\">buckets</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">10</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">20</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">50</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">100</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">1000</span><span class=\"p-Indicator\">]</span>\n  <span class=\"nt\">metric4</span><span class=\"p\">:</span>\n    <span class=\"nt\">type</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">enum</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">A sample enum</span>\n    <span class=\"nt\">states</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">foo</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">bar</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">baz</span><span class=\"p-Indicator\">]</span>\n\n<span class=\"nt\">queries</span><span class=\"p\">:</span>\n  <span class=\"nt\">query1</span><span class=\"p\">:</span>\n    <span class=\"nt\">interval</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">5</span>\n    <span class=\"nt\">databases</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">db1</span><span class=\"p-Indicator\">]</span>\n    <span class=\"nt\">metrics</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">metric1</span><span class=\"p-Indicator\">]</span>\n    <span class=\"nt\">sql</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">SELECT random() / 1000000000000000</span>\n  <span class=\"nt\">query2</span><span class=\"p\">:</span>\n    <span class=\"nt\">interval</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">20</span>\n    <span class=\"nt\">databases</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">db1</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">db2</span><span class=\"p-Indicator\">]</span>\n    <span class=\"nt\">metrics</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">metric2</span><span class=\"p-Indicator\">,</span> <span class=\"nv\">metric3</span><span class=\"p-Indicator\">]</span>\n    <span class=\"nt\">sql</span><span class=\"p\">:</span> <span class=\"p-Indicator\">|</span>\n      <span class=\"no\">SELECT abs(random() / 1000000000000000),</span>\n             <span class=\"no\">abs(random() / 10000000000000000)</span>\n  <span class=\"nt\">query3</span><span class=\"p\">:</span>\n    <span class=\"nt\">interval</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">10</span>\n    <span class=\"nt\">databases</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">db2</span><span class=\"p-Indicator\">]</span>\n    <span class=\"nt\">metrics</span><span class=\"p\">:</span> <span class=\"p-Indicator\">[</span><span class=\"nv\">metric4</span><span class=\"p-Indicator\">]</span>\n    <span class=\"nt\">sql</span><span class=\"p\">:</span> <span class=\"p-Indicator\">|</span>\n      <span class=\"no\">SELECT value FROM (</span>\n        <span class=\"no\">SELECT 'foo' AS value UNION</span>\n        <span class=\"no\">SELECT 'bar'</span>\n        <span class=\"no\">UNION SELECT 'baz')</span>\n      <span class=\"no\">ORDER BY random()</span>\n      <span class=\"no\">LIMIT 1</span>\n</pre>\n<p>The <tt>dsn</tt> connection string has the following format:</p>\n<pre>dialect[+driver]://[username:password][@host:port]/database\n</pre>\n<p>(see <a href=\"http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls\" rel=\"nofollow\">SQLAlchemy documentation</a> for details on the available options).</p>\n<p>The <tt>metrics</tt> list in the query configuration must match values returned by\nthe query defined in <tt>sql</tt>.</p>\n<p>The <tt>interval</tt> value is interpreted as seconds if no suffix is specified;\nvalid suffix are <tt>s</tt>, <tt>m</tt>, <tt>h</tt>, <tt>d</tt>. Only integer values can be\nspecified. If no value is specified (or specified as <tt>null</tt>), the query is\nexecuted at every HTTP request.</p>\n<p>Queries will usually return a single row, but multiple rows are supported, and\neach row will cause an update of the related metrics.  This is relevant for any\nkind of metric except gauges, which will be effectively updated to the value\nfrom the last row.</p>\n<p>For the configuration above, exported metrics look like this:</p>\n<pre># HELP metric1 A sample gauge\n# TYPE metric1 gauge\nmetric1{database=\"db1\"} 1549.0\n# HELP metric2 A sample summary\n# TYPE metric2 summary\nmetric2_count{database=\"db2\"} 1.0\nmetric2_sum{database=\"db2\"} 5229.0\nmetric2_count{database=\"db1\"} 1.0\nmetric2_sum{database=\"db1\"} 4513.0\n# TYPE metric2_created gauge\nmetric2_created{database=\"db2\"} 1.5456472955657206e+09\nmetric2_created{database=\"db1\"} 1.5456472955663064e+09\n# HELP metric3 A sample histogram\n# TYPE metric3 histogram\nmetric3_bucket{database=\"db2\",le=\"10.0\"} 0.0\nmetric3_bucket{database=\"db2\",le=\"20.0\"} 0.0\nmetric3_bucket{database=\"db2\",le=\"50.0\"} 0.0\nmetric3_bucket{database=\"db2\",le=\"100.0\"} 0.0\nmetric3_bucket{database=\"db2\",le=\"1000.0\"} 1.0\nmetric3_bucket{database=\"db2\",le=\"+Inf\"} 1.0\nmetric3_count{database=\"db2\"} 1.0\nmetric3_sum{database=\"db2\"} 714.0\nmetric3_bucket{database=\"db1\",le=\"10.0\"} 0.0\nmetric3_bucket{database=\"db1\",le=\"20.0\"} 0.0\nmetric3_bucket{database=\"db1\",le=\"50.0\"} 0.0\nmetric3_bucket{database=\"db1\",le=\"100.0\"} 0.0\nmetric3_bucket{database=\"db1\",le=\"1000.0\"} 1.0\nmetric3_bucket{database=\"db1\",le=\"+Inf\"} 1.0\nmetric3_count{database=\"db1\"} 1.0\nmetric3_sum{database=\"db1\"} 602.0\n# TYPE metric3_created gauge\nmetric3_created{database=\"db2\"} 1.545647295565831e+09\nmetric3_created{database=\"db1\"} 1.5456472955663848e+09\n# HELP metric4 A sample enum\n# TYPE metric4 gauge\nmetric4{database=\"db2\",metric4=\"foo\"} 0.0\nmetric4{database=\"db2\",metric4=\"bar\"} 1.0\nmetric4{database=\"db2\",metric4=\"baz\"} 0.0\n</pre>\n<p>Metrics are automatically tagged with the <tt>database</tt> label so that\nindipendent series are generated for each database.</p>\n<div id=\"database-engines\">\n<h2>Database engines</h2>\n<p>SQLAlchemy doesn\u2019t depend on specific Python database modules at\ninstallation. This means additional modules might need to be installed for\nengines in use, as follows:</p>\n<pre>pip install SQLAlchemy[postgresql] SQLAlchemy[mysql] ...\n</pre>\n<p>based on which databased is in use.</p>\n<p>See <a href=\"http://docs.sqlalchemy.org/en/latest/core/engines.html#supported-databases\" rel=\"nofollow\">supported databases</a> for details.</p>\n</div>\n<div id=\"carto-extension\">\n<h2>Carto extension</h2>\n<p>You can define a carto connection instead of a SQL DSN. If you want to do so, use a <cite>carto:</cite> entry in your database.</p>\n<p>Example:</p>\n<pre>databases:\n  test_carto:\n    carto:\n      user: my_carto_user\n      api_key: my_carto_api_key\n\nmetrics:\n  observations_simple_count:\n    type: gauge\n    description: Simple count to check if this works...\n\nqueries:\n  query_count_simple_count:\n    interval: 120s\n    databases: [test_carto]\n    metrics: [observations_simple_count]\n    sql: SELECT count(*) from county_population;\n</pre>\n<ul>\n<li>You cannot use both <cite>dsn</cite> and <cite>carto</cite> entries in the same database as that makes no sense.</li>\n<li>The available fields for the configuration object are the same as for the Longitude CartoDataSource objects.</li>\n<li>As of today, such fields are (keep in mind that some might not make sense for monitoring):<ul>\n<li><tt>api_version</tt>: <tt>v2</tt> by default</li>\n<li><tt>uses_batch</tt>: <tt>False</tt> by default</li>\n<li><tt>on_premise_domain</tt>: <tt>''</tt> by default. If provided, the Carto URL will use it. If not, the default user URL will.</li>\n<li><tt>api_key</tt>: <tt>''</tt> by default. Mandatory. Master api key recommended.</li>\n<li><tt>user</tt>: <tt>''</tt> by default. Mandatory. CARTO user (not email)</li>\n<li><tt>cache</tt>: Empty by default. Cache configuration. Useless in this context for now.</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"development-environment\">\n<h2>Development environment</h2>\n<p>The easiest way to install the required dependencies is to create a virtual environment and install the package:</p>\n<blockquote>\npython setup.py install\npipenv install -e .</blockquote>\n</div>\n\n          </div>"}, "last_serial": 4893301, "releases": {"1.5.0": [{"comment_text": "", "digests": {"md5": "cab9464b1175c52687b7300015d73897", "sha256": "d06f621d55913cf26beff74d901559a37e8360249316cfac6bd3f582c76393ae"}, "downloads": -1, "filename": "query_exporter_carto-1.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "cab9464b1175c52687b7300015d73897", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28620, "upload_time": "2019-02-25T18:04:52", "upload_time_iso_8601": "2019-02-25T18:04:52.846788Z", "url": "https://files.pythonhosted.org/packages/f1/05/965f4f75c435b120357aea82afc0365e497341010b5abf10f7481a15c265/query_exporter_carto-1.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0eb6eefc1ae387fd01af21dff5d2242b", "sha256": "b28d12df43f7e30d56fecfad6c91fdb562e25923bd9834522b4e931e81ae7428"}, "downloads": -1, "filename": "query-exporter-carto-1.5.0.tar.gz", "has_sig": false, "md5_digest": "0eb6eefc1ae387fd01af21dff5d2242b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28013, "upload_time": "2019-02-25T18:04:54", "upload_time_iso_8601": "2019-02-25T18:04:54.805158Z", "url": "https://files.pythonhosted.org/packages/d1/75/c99becd2fd0e22beb1dbaf6a26b36a0f5279f85918609e25294693a555fd/query-exporter-carto-1.5.0.tar.gz", "yanked": false}], "1.5.0a1": [{"comment_text": "", "digests": {"md5": "99b755433c05a7e440097884313b589f", "sha256": "473391106c2d581a2e24b8f2350c19f9510c78d949d4ea5874fefff4b84691c8"}, "downloads": -1, "filename": "query_exporter_carto-1.5.0a1-py3-none-any.whl", "has_sig": false, "md5_digest": "99b755433c05a7e440097884313b589f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23119, "upload_time": "2019-02-25T19:26:51", "upload_time_iso_8601": "2019-02-25T19:26:51.986734Z", "url": "https://files.pythonhosted.org/packages/03/a5/443581e9ddf5aacef115c13b10cb4fc3f54abfc65275b752f7f93a7e8a68/query_exporter_carto-1.5.0a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a4fbc54041b588e438369ed542a3041", "sha256": "337459f082f65d87f4b46906ea5629426871609cfdc8ffe455c0f8582b9bf63b"}, "downloads": -1, "filename": "query-exporter-carto-1.5.0a1.tar.gz", "has_sig": false, "md5_digest": "0a4fbc54041b588e438369ed542a3041", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24334, "upload_time": "2019-02-25T19:26:53", "upload_time_iso_8601": "2019-02-25T19:26:53.118653Z", "url": "https://files.pythonhosted.org/packages/8c/4b/2be3c7c76fe85d3ef7ac0d04abae65688904ff4c96cc71076c878fae69d1/query-exporter-carto-1.5.0a1.tar.gz", "yanked": false}], "1.5.1": [{"comment_text": "", "digests": {"md5": "4f5ff1e72ae9ace254f34b68e4a17a8e", "sha256": "d90d0730939c5caed064046747fd10d417590db38ede533827cb7a76444fa86d"}, "downloads": -1, "filename": "query_exporter_carto-1.5.1-py3-none-any.whl", "has_sig": false, "md5_digest": "4f5ff1e72ae9ace254f34b68e4a17a8e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28622, "upload_time": "2019-03-04T08:12:54", "upload_time_iso_8601": "2019-03-04T08:12:54.093411Z", "url": "https://files.pythonhosted.org/packages/bc/8a/0cfe78332b0430e559c70d7fbfd64c300e8606cabbd8d4c2932f98f9bf82/query_exporter_carto-1.5.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aaf1e060f870b1ddaa234957cbe11220", "sha256": "a1e6ebdb1b6c8a1ee69b05e9cf05c87f11709cfdf418883b79db97c40887e1d5"}, "downloads": -1, "filename": "query-exporter-carto-1.5.1.tar.gz", "has_sig": false, "md5_digest": "aaf1e060f870b1ddaa234957cbe11220", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28012, "upload_time": "2019-03-04T08:12:55", "upload_time_iso_8601": "2019-03-04T08:12:55.485068Z", "url": "https://files.pythonhosted.org/packages/0f/60/bf9a235e8d5cc5a5cc17bd3b81434152ae385c08b61bc04e09d191afe2f9/query-exporter-carto-1.5.1.tar.gz", "yanked": false}], "1.5.1a1": [{"comment_text": "", "digests": {"md5": "187cc6fafe8dd528b55ab5b077ffe3f1", "sha256": "da5fcadac6c9c71fb50f807a6e161e1a7dbbcc13a5e37d3782e7e525abc7fd56"}, "downloads": -1, "filename": "query_exporter_carto-1.5.1a1-py3-none-any.whl", "has_sig": false, "md5_digest": "187cc6fafe8dd528b55ab5b077ffe3f1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23119, "upload_time": "2019-02-25T19:49:46", "upload_time_iso_8601": "2019-02-25T19:49:46.757338Z", "url": "https://files.pythonhosted.org/packages/1c/87/70d8c490a90abc70a4003538d54fc8080b1f9288022d2d631644f922a454/query_exporter_carto-1.5.1a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "353f67c95241662dd05d013eb625ac4e", "sha256": "16fba5897f63fd1c9e803f4e1cad00354ebc36da7baf7a95778fdef9565ed370"}, "downloads": -1, "filename": "query-exporter-carto-1.5.1a1.tar.gz", "has_sig": false, "md5_digest": "353f67c95241662dd05d013eb625ac4e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24338, "upload_time": "2019-02-25T19:49:48", "upload_time_iso_8601": "2019-02-25T19:49:48.860143Z", "url": "https://files.pythonhosted.org/packages/af/d4/8e57e14d24d77a52257af94a13ba84ce558a49812c6f8ee20e7b24625c99/query-exporter-carto-1.5.1a1.tar.gz", "yanked": false}], "1.5.1a2": [{"comment_text": "", "digests": {"md5": "2e331135b11fe82a82164f8c38c5e557", "sha256": "406881e0ca27c9046b060419d368bfb290f17f4bdb7dc2f730bba5b320e65000"}, "downloads": -1, "filename": "query_exporter_carto-1.5.1a2-py3-none-any.whl", "has_sig": false, "md5_digest": "2e331135b11fe82a82164f8c38c5e557", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28653, "upload_time": "2019-03-01T10:44:20", "upload_time_iso_8601": "2019-03-01T10:44:20.500321Z", "url": "https://files.pythonhosted.org/packages/6a/c4/18dbc71936485b1418e22c0703267285b23af5da401f0caeaf3b081bcf1b/query_exporter_carto-1.5.1a2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e594bc99ef216eb4eb37a5b643910e28", "sha256": "6adf37248d624210694c6de15b282d80a81a86aae25b74676cc6e72b317eb306"}, "downloads": -1, "filename": "query-exporter-carto-1.5.1a2.tar.gz", "has_sig": false, "md5_digest": "e594bc99ef216eb4eb37a5b643910e28", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28012, "upload_time": "2019-03-01T10:44:21", "upload_time_iso_8601": "2019-03-01T10:44:21.809933Z", "url": "https://files.pythonhosted.org/packages/6a/d8/3fdf25ec2a7bc69178ebd7294a76757aad8d804b42c5e9af05ef0da6725b/query-exporter-carto-1.5.1a2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4f5ff1e72ae9ace254f34b68e4a17a8e", "sha256": "d90d0730939c5caed064046747fd10d417590db38ede533827cb7a76444fa86d"}, "downloads": -1, "filename": "query_exporter_carto-1.5.1-py3-none-any.whl", "has_sig": false, "md5_digest": "4f5ff1e72ae9ace254f34b68e4a17a8e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28622, "upload_time": "2019-03-04T08:12:54", "upload_time_iso_8601": "2019-03-04T08:12:54.093411Z", "url": "https://files.pythonhosted.org/packages/bc/8a/0cfe78332b0430e559c70d7fbfd64c300e8606cabbd8d4c2932f98f9bf82/query_exporter_carto-1.5.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aaf1e060f870b1ddaa234957cbe11220", "sha256": "a1e6ebdb1b6c8a1ee69b05e9cf05c87f11709cfdf418883b79db97c40887e1d5"}, "downloads": -1, "filename": "query-exporter-carto-1.5.1.tar.gz", "has_sig": false, "md5_digest": "aaf1e060f870b1ddaa234957cbe11220", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28012, "upload_time": "2019-03-04T08:12:55", "upload_time_iso_8601": "2019-03-04T08:12:55.485068Z", "url": "https://files.pythonhosted.org/packages/0f/60/bf9a235e8d5cc5a5cc17bd3b81434152ae385c08b61bc04e09d191afe2f9/query-exporter-carto-1.5.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:08:38 2020"}