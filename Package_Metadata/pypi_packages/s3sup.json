{"info": {"author": "Alistair Wooldrige", "author_email": "s3sup@woolie.co.uk", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only"], "description": "# s3sup - static site uploader for Amazon S3\ns3sup may be better than other S3 syncing solutions (e.g. `s3sync`) if you host\na static site on S3. Main features include:\n\n * MIME type detection, with `Content-Type` set correctly for most files.\n * Fast and efficient synchronisation to S3 through maintaining a catalogue of\n   content/metadata checksums for files already uploaded.\n * Hierarchical configuration of important HTTP headers (e.g. `Cache-Control`\n   and `Content-Disposition`) on groups of files or individually.\n\nDemo of new site being uploaded to S3:\n\n\nOther features:\n\n * Ordering of uploads to prevent HTML files referencing static assets that\n   haven't been uploaded yet.\n * Deletes files from S3 that no longer exist in the local project directory.\n   This can also be prevented with `--nodelete` command line option or\n   `preserve_deleted_files` config file key, should you want them to stick\n   around.\n\n\n## Getting started\nFollow these steps to get a new site uploaded to S3 with s3sup.\n\n#### 1) Add s3sup.toml file to your local static site root\nInside your local static site directory, add an s3sup configuration file for\nthe first time using:\n\n    s3sup init\n\nThen edit the skeleton configuration file created at `./s3sup.toml`. For a\nguide to the configuration settings, see section below. To verify the\ndestination path, HTTP headers and defaults that s3sup will set for an\nindividual file, use:\n\n    s3sup inspect <filepath>\n\n\n#### 2) Configure AWS credentials\nAWS credentials can be configured using [any method that the underlying boto3 library supports](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html).\nFor most users, this will mean creating a credentials file at\n`~/.aws/credentials` following this template:\n\n    [default]\n    aws_access_key_id=foo\n    aws_secret_access_key=bar\n\nOr alternatively credentials can be provided as environment variables\n`AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.\n\n\n#### 3) Run s3sup\nCheck what changes s3sup thinks needs to be made to S3. At the beginning, this\nwill indicate that all files are new and need to be uploaded:\n\n    s3sup status\n\nThen upload changes to S3:\n\n    s3sup push\n\n\n## Installation\ns3sup can be installed using `pip`. Please note `s3sup` supports Python 3 only:\n\n    pip3 install s3sup\n\nNo distribution specific packages are available yet, please use the `pip`\ninstallation method or download source from\n[GitHub](https://github.com/awooldrige/s3sup).\n\nTo see the commands available, run s3sup with `--help`:\n\n    $ s3sup --help\n    Usage: s3sup [OPTIONS] COMMAND [ARGS]...\n\n      s3sup - Amazon S3 static site uploader\n\n    Options:\n      --help  Show this message and exit.\n\n    Commands:\n      init     Create a skeleton s3sup.toml in the current directory.\n      inspect  Show calculated metadata for individual files.\n      push     Synchronise local static site to S3.\n      status   Show S3 changes that will be made on next push.\n\nEach command also provides a `--help`:\n\n    $ s3sup push --help\n    Usage: s3sup push [OPTIONS]\n\n      Synchronise local static site to S3.\n\n      Use --dryrun to test behaviour without changes actually being made to S3.\n      Or use \"s3sup status\".\n\n      This command has two other aliases: upload or sync.\n\n    Options:\n      -v, --verbose          Output more informational messages than normal.\n      -p, --projectdir TEXT  Specify local s3sup static site directory (containing\n                             s3sup.toml). By default the current directory is\n                             used.\n      -n, --nodelete         Do not delete any files on S3, add/modify operations\n                             only. Alternatively set \"preserve_deleted_files\" in\n                             s3sup.toml.\n      -d, --dryrun           Simulate changes to be made. Do not modify files on\n                             S3.\n      --help                 Show this message and exit.\n\n\n## Configuration file guide\ns3sup expects an `s3sup.toml` configuration file within the root directory of\nyour static site. Only the `[aws]` section must be included at minimum:\n\n\n### Optional: Global configuration section\nThese settings must be placed at the top of the `s3sup.toml` file otherwise\nschema validation errors will occur (TOML interprets them as as belonging to\nthe previous section otherwise):\n\n| Configuration key | Required | Default | Type | Expected value |\n| ----------------- | -------- | ------- | ---- | -------------- |\n| `preserve_deleted_files` | Optional | `false` |  Boolean | Setting to `true` will prevent files being deleted from S3 when they are deleted in the local project. This can be useful if your site has a long cache lifetime and you don't want cached pages to reference stylesheets/JavaScript files that suddenly disappear. This feature only prevents file deletions, it doesn't prevent file contents being overwritten if updated locally. This can also be achieved by supplying `--nodelete` as a command line option. |\n| `charset` | Optional | `'utf-8'` | String | Specify the character encoding of text files within this s3sup project. The charset is appended to `Content-Type` header. This can also be overriden on a `[[path_specific]]` basis. |\n\n\n### Required: `[aws]` section\nConfiguration settings related to AWS:\n\n| Configuration key | Required | Default | Type | Expected value |\n| ----------------- | -------- | ------- | ---- | -------------- |\n| `region_name` | Required | N/A | String | AWS region that the S3 bucket is located in. E.g. 'eu-west-1'. |\n| `s3_bucket_name` | Required | N/A | String | Name of the S3 bucket. E.g.  'mywebsitebucketname' |\n| `s3_project_root` | Optional | Bucket root | String | S3 sub path where the local project should be uploaded to, without a leading slash. E.g. 'staging/'. By default the local project is uploaded to the root of the S3 bucket. |\n\n### Optional: One or more `[[path_specific]]` sections\nOne or more `[[path_specific]]` sections may be included. Each\n`[[path_specific]]` section must contain a `path` specification for which the\ndirectives in that section should apply to.  The `path` can be the relative\npath to a file within the project directory, or a regular expression matching\nmultiple paths.\n\nIf multiple `[[path_specific]]` entries match the same path, directives are\ncombined from all matching `[[path_specific]]` entries, with the last matching\n`[[path_specific]]` directive entry in the configuration file winning for\nequivalent directive keys.\n\nAlong with `path`, the following directives can be set:\n\n| Configuration key | Required | Default | Type | Expected value |\n| ----------------- | -------- | ------- | ---- | -------------- |\n| `path` | Required | N/A | String | Regular expression matching multiple relative paths, or an individual relative path to a file. |\n| `ACL` | Optional | `'public-read'` | String | S3 access permissions for the matching paths. One of: private, public-read, authenticated-read. |\n| `StorageClass` | Optional | `'STANDARD'` | String | S3 storage resiliency class. One of: STANDARD, REDUCED_REDUNDANCY, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING or GLACIER. |\n| `WebsiteRedirectLocation` | Optional | None | String | Instead of serving the file when a client requests this path, instruct S3 to respond with a redirect to the specified URL instead. Note that URLs must be absolute, e.g. 'https://www.example.com/new_home'. |\n| `Cache-Control` | Optional | `max-age=10` | String | Set HTTP header value to control cache lifetime. A short default cache lifetime is set to provide basic origin shielding should an explicit one not be set. |\n| `Content-Disposition` | Optional | None | String | Set HTTP header value to control whether the browser should display the file contents or provide a download dialog to the user |\n| `Content-Type` | Optional | Automatic | String | Override Content-Type HTTP header value. Only override this if absolutely necessary as s3sup MIME type detection normally sets this header correctly. |\n| `charset` | Optional | `'utf-8'` | String | Manually specify the character encoding of text containing files. This is appended to `Content-Type` HTTP header. Usually setting `charset` in the global configuration section is adequate but this directives allows control on a path level. |\n| `Content-Encoding` | Optional | Automatic | String | Set Content-Encoding HTTP header value. Only override this if absolutely necessary as s3sup detects encoding automatically. For wide browser support, it is recommended to store content uncompressed in S3 and then use dynamic gzip compression in a CDN layer. |\n\nUse `s3sup inspect <filename>` to check the attributes that s3sup will set\nbased on your configuration settings and defaults.\n\n### Optional: `[mimetype_overrides]` section\nOptional, usually not required. Provide manual mappings of file extensions to\nMIME type, which will take precedence over any automatic MIME type detection\nthat s3sup has made. This can be useful for very modern MIME types E.g.\n\n    [mimetype_overrides]\n    '.woff3' = 'font/woff3'\n    '.oml' = 'application/oml'\n\n\n### Example configuration file\nThe following example configuration:\n\n * Sets all files with a cache lifetime of two minutes by default.\n * Sets a longer cache lifetime on PDFs and a response header to trigger the\n   browser to download the file rather than display it.\n\nExample `s3sup.toml`:\n\n    [aws]\n    region_name = 'eu-west-1'\n    s3_bucket_name = 'mys3websitebucket'\n\n\n    [[path_specific]]\n    path = '^.*$'\n    Cache-Control = 'max-age=120'\n\n    [[path_specific]]\n    path= '^/assets/download/[0-9]+.pdf$'\n    Content-Disposition = 'attachment'\n    Cache-Control = 'max-age=360'\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/awooldrige/s3sup", "keywords": "s3sup AWS S3 static", "license": "", "maintainer": "", "maintainer_email": "", "name": "s3sup", "package_url": "https://pypi.org/project/s3sup/", "platform": "", "project_url": "https://pypi.org/project/s3sup/", "project_urls": {"Bug Reports": "https://github.com/awooldrige/s3sup/issues", "Homepage": "https://github.com/awooldrige/s3sup", "Source": "https://github.com/awooldrige/s3sup/"}, "release_url": "https://pypi.org/project/s3sup/0.5.0/", "requires_dist": ["boto3 (<2,>=1)", "click (<9,>=7)", "humanize (<1,>=0.4)", "inflect (<3,>=2)", "jsonschema (<4,>=2)", "toml (<1,>=0.9)", "flake8 ; extra == 'test'", "moto ; extra == 'test'"], "requires_python": ">=3, <4", "summary": "Static site uploader for Amazon S3", "version": "0.5.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>s3sup - static site uploader for Amazon S3</h1>\n<p>s3sup may be better than other S3 syncing solutions (e.g. <code>s3sync</code>) if you host\na static site on S3. Main features include:</p>\n<ul>\n<li>MIME type detection, with <code>Content-Type</code> set correctly for most files.</li>\n<li>Fast and efficient synchronisation to S3 through maintaining a catalogue of\ncontent/metadata checksums for files already uploaded.</li>\n<li>Hierarchical configuration of important HTTP headers (e.g. <code>Cache-Control</code>\nand <code>Content-Disposition</code>) on groups of files or individually.</li>\n</ul>\n<p>Demo of new site being uploaded to S3:</p>\n<p>Other features:</p>\n<ul>\n<li>Ordering of uploads to prevent HTML files referencing static assets that\nhaven't been uploaded yet.</li>\n<li>Deletes files from S3 that no longer exist in the local project directory.\nThis can also be prevented with <code>--nodelete</code> command line option or\n<code>preserve_deleted_files</code> config file key, should you want them to stick\naround.</li>\n</ul>\n<h2>Getting started</h2>\n<p>Follow these steps to get a new site uploaded to S3 with s3sup.</p>\n<h4>1) Add s3sup.toml file to your local static site root</h4>\n<p>Inside your local static site directory, add an s3sup configuration file for\nthe first time using:</p>\n<pre><code>s3sup init\n</code></pre>\n<p>Then edit the skeleton configuration file created at <code>./s3sup.toml</code>. For a\nguide to the configuration settings, see section below. To verify the\ndestination path, HTTP headers and defaults that s3sup will set for an\nindividual file, use:</p>\n<pre><code>s3sup inspect &lt;filepath&gt;\n</code></pre>\n<h4>2) Configure AWS credentials</h4>\n<p>AWS credentials can be configured using <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\" rel=\"nofollow\">any method that the underlying boto3 library supports</a>.\nFor most users, this will mean creating a credentials file at\n<code>~/.aws/credentials</code> following this template:</p>\n<pre><code>[default]\naws_access_key_id=foo\naws_secret_access_key=bar\n</code></pre>\n<p>Or alternatively credentials can be provided as environment variables\n<code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>.</p>\n<h4>3) Run s3sup</h4>\n<p>Check what changes s3sup thinks needs to be made to S3. At the beginning, this\nwill indicate that all files are new and need to be uploaded:</p>\n<pre><code>s3sup status\n</code></pre>\n<p>Then upload changes to S3:</p>\n<pre><code>s3sup push\n</code></pre>\n<h2>Installation</h2>\n<p>s3sup can be installed using <code>pip</code>. Please note <code>s3sup</code> supports Python 3 only:</p>\n<pre><code>pip3 install s3sup\n</code></pre>\n<p>No distribution specific packages are available yet, please use the <code>pip</code>\ninstallation method or download source from\n<a href=\"https://github.com/awooldrige/s3sup\" rel=\"nofollow\">GitHub</a>.</p>\n<p>To see the commands available, run s3sup with <code>--help</code>:</p>\n<pre><code>$ s3sup --help\nUsage: s3sup [OPTIONS] COMMAND [ARGS]...\n\n  s3sup - Amazon S3 static site uploader\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  init     Create a skeleton s3sup.toml in the current directory.\n  inspect  Show calculated metadata for individual files.\n  push     Synchronise local static site to S3.\n  status   Show S3 changes that will be made on next push.\n</code></pre>\n<p>Each command also provides a <code>--help</code>:</p>\n<pre><code>$ s3sup push --help\nUsage: s3sup push [OPTIONS]\n\n  Synchronise local static site to S3.\n\n  Use --dryrun to test behaviour without changes actually being made to S3.\n  Or use \"s3sup status\".\n\n  This command has two other aliases: upload or sync.\n\nOptions:\n  -v, --verbose          Output more informational messages than normal.\n  -p, --projectdir TEXT  Specify local s3sup static site directory (containing\n                         s3sup.toml). By default the current directory is\n                         used.\n  -n, --nodelete         Do not delete any files on S3, add/modify operations\n                         only. Alternatively set \"preserve_deleted_files\" in\n                         s3sup.toml.\n  -d, --dryrun           Simulate changes to be made. Do not modify files on\n                         S3.\n  --help                 Show this message and exit.\n</code></pre>\n<h2>Configuration file guide</h2>\n<p>s3sup expects an <code>s3sup.toml</code> configuration file within the root directory of\nyour static site. Only the <code>[aws]</code> section must be included at minimum:</p>\n<h3>Optional: Global configuration section</h3>\n<p>These settings must be placed at the top of the <code>s3sup.toml</code> file otherwise\nschema validation errors will occur (TOML interprets them as as belonging to\nthe previous section otherwise):</p>\n<table>\n<thead>\n<tr>\n<th>Configuration key</th>\n<th>Required</th>\n<th>Default</th>\n<th>Type</th>\n<th>Expected value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>preserve_deleted_files</code></td>\n<td>Optional</td>\n<td><code>false</code></td>\n<td>Boolean</td>\n<td>Setting to <code>true</code> will prevent files being deleted from S3 when they are deleted in the local project. This can be useful if your site has a long cache lifetime and you don't want cached pages to reference stylesheets/JavaScript files that suddenly disappear. This feature only prevents file deletions, it doesn't prevent file contents being overwritten if updated locally. This can also be achieved by supplying <code>--nodelete</code> as a command line option.</td>\n</tr>\n<tr>\n<td><code>charset</code></td>\n<td>Optional</td>\n<td><code>'utf-8'</code></td>\n<td>String</td>\n<td>Specify the character encoding of text files within this s3sup project. The charset is appended to <code>Content-Type</code> header. This can also be overriden on a <code>[[path_specific]]</code> basis.</td>\n</tr></tbody></table>\n<h3>Required: <code>[aws]</code> section</h3>\n<p>Configuration settings related to AWS:</p>\n<table>\n<thead>\n<tr>\n<th>Configuration key</th>\n<th>Required</th>\n<th>Default</th>\n<th>Type</th>\n<th>Expected value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>region_name</code></td>\n<td>Required</td>\n<td>N/A</td>\n<td>String</td>\n<td>AWS region that the S3 bucket is located in. E.g. 'eu-west-1'.</td>\n</tr>\n<tr>\n<td><code>s3_bucket_name</code></td>\n<td>Required</td>\n<td>N/A</td>\n<td>String</td>\n<td>Name of the S3 bucket. E.g.  'mywebsitebucketname'</td>\n</tr>\n<tr>\n<td><code>s3_project_root</code></td>\n<td>Optional</td>\n<td>Bucket root</td>\n<td>String</td>\n<td>S3 sub path where the local project should be uploaded to, without a leading slash. E.g. 'staging/'. By default the local project is uploaded to the root of the S3 bucket.</td>\n</tr></tbody></table>\n<h3>Optional: One or more <code>[[path_specific]]</code> sections</h3>\n<p>One or more <code>[[path_specific]]</code> sections may be included. Each\n<code>[[path_specific]]</code> section must contain a <code>path</code> specification for which the\ndirectives in that section should apply to.  The <code>path</code> can be the relative\npath to a file within the project directory, or a regular expression matching\nmultiple paths.</p>\n<p>If multiple <code>[[path_specific]]</code> entries match the same path, directives are\ncombined from all matching <code>[[path_specific]]</code> entries, with the last matching\n<code>[[path_specific]]</code> directive entry in the configuration file winning for\nequivalent directive keys.</p>\n<p>Along with <code>path</code>, the following directives can be set:</p>\n<table>\n<thead>\n<tr>\n<th>Configuration key</th>\n<th>Required</th>\n<th>Default</th>\n<th>Type</th>\n<th>Expected value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>path</code></td>\n<td>Required</td>\n<td>N/A</td>\n<td>String</td>\n<td>Regular expression matching multiple relative paths, or an individual relative path to a file.</td>\n</tr>\n<tr>\n<td><code>ACL</code></td>\n<td>Optional</td>\n<td><code>'public-read'</code></td>\n<td>String</td>\n<td>S3 access permissions for the matching paths. One of: private, public-read, authenticated-read.</td>\n</tr>\n<tr>\n<td><code>StorageClass</code></td>\n<td>Optional</td>\n<td><code>'STANDARD'</code></td>\n<td>String</td>\n<td>S3 storage resiliency class. One of: STANDARD, REDUCED_REDUNDANCY, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING or GLACIER.</td>\n</tr>\n<tr>\n<td><code>WebsiteRedirectLocation</code></td>\n<td>Optional</td>\n<td>None</td>\n<td>String</td>\n<td>Instead of serving the file when a client requests this path, instruct S3 to respond with a redirect to the specified URL instead. Note that URLs must be absolute, e.g. '<a href=\"https://www.example.com/new_home\" rel=\"nofollow\">https://www.example.com/new_home</a>'.</td>\n</tr>\n<tr>\n<td><code>Cache-Control</code></td>\n<td>Optional</td>\n<td><code>max-age=10</code></td>\n<td>String</td>\n<td>Set HTTP header value to control cache lifetime. A short default cache lifetime is set to provide basic origin shielding should an explicit one not be set.</td>\n</tr>\n<tr>\n<td><code>Content-Disposition</code></td>\n<td>Optional</td>\n<td>None</td>\n<td>String</td>\n<td>Set HTTP header value to control whether the browser should display the file contents or provide a download dialog to the user</td>\n</tr>\n<tr>\n<td><code>Content-Type</code></td>\n<td>Optional</td>\n<td>Automatic</td>\n<td>String</td>\n<td>Override Content-Type HTTP header value. Only override this if absolutely necessary as s3sup MIME type detection normally sets this header correctly.</td>\n</tr>\n<tr>\n<td><code>charset</code></td>\n<td>Optional</td>\n<td><code>'utf-8'</code></td>\n<td>String</td>\n<td>Manually specify the character encoding of text containing files. This is appended to <code>Content-Type</code> HTTP header. Usually setting <code>charset</code> in the global configuration section is adequate but this directives allows control on a path level.</td>\n</tr>\n<tr>\n<td><code>Content-Encoding</code></td>\n<td>Optional</td>\n<td>Automatic</td>\n<td>String</td>\n<td>Set Content-Encoding HTTP header value. Only override this if absolutely necessary as s3sup detects encoding automatically. For wide browser support, it is recommended to store content uncompressed in S3 and then use dynamic gzip compression in a CDN layer.</td>\n</tr></tbody></table>\n<p>Use <code>s3sup inspect &lt;filename&gt;</code> to check the attributes that s3sup will set\nbased on your configuration settings and defaults.</p>\n<h3>Optional: <code>[mimetype_overrides]</code> section</h3>\n<p>Optional, usually not required. Provide manual mappings of file extensions to\nMIME type, which will take precedence over any automatic MIME type detection\nthat s3sup has made. This can be useful for very modern MIME types E.g.</p>\n<pre><code>[mimetype_overrides]\n'.woff3' = 'font/woff3'\n'.oml' = 'application/oml'\n</code></pre>\n<h3>Example configuration file</h3>\n<p>The following example configuration:</p>\n<ul>\n<li>Sets all files with a cache lifetime of two minutes by default.</li>\n<li>Sets a longer cache lifetime on PDFs and a response header to trigger the\nbrowser to download the file rather than display it.</li>\n</ul>\n<p>Example <code>s3sup.toml</code>:</p>\n<pre><code>[aws]\nregion_name = 'eu-west-1'\ns3_bucket_name = 'mys3websitebucket'\n\n\n[[path_specific]]\npath = '^.*$'\nCache-Control = 'max-age=120'\n\n[[path_specific]]\npath= '^/assets/download/[0-9]+.pdf$'\nContent-Disposition = 'attachment'\nCache-Control = 'max-age=360'\n</code></pre>\n\n          </div>"}, "last_serial": 5250824, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "dfa528e169677c831d6fef2e7adc0e04", "sha256": "39e100e0e99ec8455395eeafc3ff28d82652989c3dabdec4c8896101b1436784"}, "downloads": -1, "filename": "s3sup-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "dfa528e169677c831d6fef2e7adc0e04", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 24826, "upload_time": "2019-03-02T11:01:15", "upload_time_iso_8601": "2019-03-02T11:01:15.679772Z", "url": "https://files.pythonhosted.org/packages/68/63/19965a5cb5080f983301c4204b61620f8c5cdee933d6dd5aaa7f276ffba6/s3sup-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "72ec0a1bcac7406061d80169d1090c90", "sha256": "81133dc0d98cfcb31dcac95a3dd2c25d2b5b2e3041b1d218d51f7acea5f614d1"}, "downloads": -1, "filename": "s3sup-0.1.1.tar.gz", "has_sig": false, "md5_digest": "72ec0a1bcac7406061d80169d1090c90", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 12141, "upload_time": "2019-03-02T11:01:17", "upload_time_iso_8601": "2019-03-02T11:01:17.784587Z", "url": "https://files.pythonhosted.org/packages/63/dd/6b2cf6763dfe74210b11ec1e4a8d656fc42aac12b69a91087e649f4c3659/s3sup-0.1.1.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "0b9faa256a14b9fc1f5977e325dfe38a", "sha256": "f282e3038ea49cc3de1863918423caeb2636f927585fad8843e881c2500c23cc"}, "downloads": -1, "filename": "s3sup-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0b9faa256a14b9fc1f5977e325dfe38a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 25961, "upload_time": "2019-03-11T19:05:50", "upload_time_iso_8601": "2019-03-11T19:05:50.902466Z", "url": "https://files.pythonhosted.org/packages/df/b1/f3083933ceb5fd3c905e1da25a42759e95ae65763c5e008e156c71fb1d41/s3sup-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d9a19e365e0e4ab59a007cf966a58cb5", "sha256": "adceb702d25142d5306efdda44ca252e46663120664fd1e1203abc9b813d9f98"}, "downloads": -1, "filename": "s3sup-0.2.1.tar.gz", "has_sig": false, "md5_digest": "d9a19e365e0e4ab59a007cf966a58cb5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 11412, "upload_time": "2019-03-11T19:05:52", "upload_time_iso_8601": "2019-03-11T19:05:52.497160Z", "url": "https://files.pythonhosted.org/packages/c8/e2/2a155ca34d832ce36e7dea759904136297737773c1549be3c4868f094636/s3sup-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "96bc47769a302a43ad048b790313bba9", "sha256": "b9c0ae77269a303d2193f73ec178818f8409370b5f2754d6fb5eba5cd84060ea"}, "downloads": -1, "filename": "s3sup-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "96bc47769a302a43ad048b790313bba9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 26208, "upload_time": "2019-03-19T21:36:55", "upload_time_iso_8601": "2019-03-19T21:36:55.612904Z", "url": "https://files.pythonhosted.org/packages/7a/cf/54929b18eb4b665876dbe168fb1e72ff3c5ea68b359f333940007fb1bf33/s3sup-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b531aa5df653fa438d22c1a9d33510a7", "sha256": "66ecee4565673889a46b8d359277566a241e867269b0ee6d25a7f4daf4e36633"}, "downloads": -1, "filename": "s3sup-0.2.2.tar.gz", "has_sig": false, "md5_digest": "b531aa5df653fa438d22c1a9d33510a7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 11724, "upload_time": "2019-03-19T21:36:57", "upload_time_iso_8601": "2019-03-19T21:36:57.513957Z", "url": "https://files.pythonhosted.org/packages/24/77/2befedd7faa38fe9ab5009c99437e00f178a65b2ef10463bd2802bde166e/s3sup-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "f5b4d4136f40823f047a33904ea7f4d3", "sha256": "74279c9dc1a8c656bdf3067afea477fcb1690414942880fc68ec6a52e4fd9ac5"}, "downloads": -1, "filename": "s3sup-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f5b4d4136f40823f047a33904ea7f4d3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 29188, "upload_time": "2019-04-09T06:44:00", "upload_time_iso_8601": "2019-04-09T06:44:00.960386Z", "url": "https://files.pythonhosted.org/packages/8f/53/267855206ee5f6459dff9783af179a9d3ab4c3a77f90e49230371114eee9/s3sup-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4eb046d29004e053fc085f9b93998450", "sha256": "594c59a2afaa2f8ee3243ec7f16286a641c81eef49518acafe17e6018244aa9e"}, "downloads": -1, "filename": "s3sup-0.3.0.tar.gz", "has_sig": false, "md5_digest": "4eb046d29004e053fc085f9b93998450", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 17103, "upload_time": "2019-04-09T06:44:23", "upload_time_iso_8601": "2019-04-09T06:44:23.373694Z", "url": "https://files.pythonhosted.org/packages/2d/ef/14baa1e1c82d727a80467864b0c185ee3bfb1ef323f6be14412df35e1c00/s3sup-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "c9fdab8acf7599dde2ce4e3365afce39", "sha256": "e20066faf892cd7703d462956227624b892d9d9a216e156e7459a4edba33b790"}, "downloads": -1, "filename": "s3sup-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c9fdab8acf7599dde2ce4e3365afce39", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 30316, "upload_time": "2019-05-03T16:33:46", "upload_time_iso_8601": "2019-05-03T16:33:46.362843Z", "url": "https://files.pythonhosted.org/packages/4d/05/d1195ada5f680ab21738e5a96aabf6881e3bf1376c665c777dc8de91f7f4/s3sup-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ce661f8b241a2c00dc19b051ab88307a", "sha256": "ee1e22c887fe7578db76b9a47beb77aa8971cd3a938162ed58dab2baa64aabfe"}, "downloads": -1, "filename": "s3sup-0.4.0.tar.gz", "has_sig": false, "md5_digest": "ce661f8b241a2c00dc19b051ab88307a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 18173, "upload_time": "2019-05-03T16:33:54", "upload_time_iso_8601": "2019-05-03T16:33:54.469265Z", "url": "https://files.pythonhosted.org/packages/52/f4/0a1dd793300995c2128b0f206c324437d6b7144a08cbefaf6ac6d601feaf/s3sup-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "b07c705a58b72b4c7a7e58af58d5af99", "sha256": "ce6544b09d9bfbe4cb9c7ebafc5afa405d257bf856bfdee3cda7e0ca1747a82d"}, "downloads": -1, "filename": "s3sup-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b07c705a58b72b4c7a7e58af58d5af99", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 30729, "upload_time": "2019-05-10T06:16:54", "upload_time_iso_8601": "2019-05-10T06:16:54.723770Z", "url": "https://files.pythonhosted.org/packages/91/8c/189575fd531d254debfaf3e6c2bbf0fa013d20495d0a0bbbe951ac58bb6f/s3sup-0.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "be48f749fd89d47536e5133633c1b8d7", "sha256": "4ae172e0283d42674133df8571ebbfbcdde8929b74ff6fe2623fe6943b7aafb6"}, "downloads": -1, "filename": "s3sup-0.5.0.tar.gz", "has_sig": false, "md5_digest": "be48f749fd89d47536e5133633c1b8d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 19376, "upload_time": "2019-05-10T06:16:56", "upload_time_iso_8601": "2019-05-10T06:16:56.596921Z", "url": "https://files.pythonhosted.org/packages/5d/80/f5cabbf39fce5773b2c6120f58e0ae66b72ed38c5a04dd9830016d5da6f4/s3sup-0.5.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b07c705a58b72b4c7a7e58af58d5af99", "sha256": "ce6544b09d9bfbe4cb9c7ebafc5afa405d257bf856bfdee3cda7e0ca1747a82d"}, "downloads": -1, "filename": "s3sup-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b07c705a58b72b4c7a7e58af58d5af99", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <4", "size": 30729, "upload_time": "2019-05-10T06:16:54", "upload_time_iso_8601": "2019-05-10T06:16:54.723770Z", "url": "https://files.pythonhosted.org/packages/91/8c/189575fd531d254debfaf3e6c2bbf0fa013d20495d0a0bbbe951ac58bb6f/s3sup-0.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "be48f749fd89d47536e5133633c1b8d7", "sha256": "4ae172e0283d42674133df8571ebbfbcdde8929b74ff6fe2623fe6943b7aafb6"}, "downloads": -1, "filename": "s3sup-0.5.0.tar.gz", "has_sig": false, "md5_digest": "be48f749fd89d47536e5133633c1b8d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <4", "size": 19376, "upload_time": "2019-05-10T06:16:56", "upload_time_iso_8601": "2019-05-10T06:16:56.596921Z", "url": "https://files.pythonhosted.org/packages/5d/80/f5cabbf39fce5773b2c6120f58e0ae66b72ed38c5a04dd9830016d5da6f4/s3sup-0.5.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:34 2020"}