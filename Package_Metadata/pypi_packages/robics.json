{"info": {"author": "Christoph Kralj", "author_email": "christoph.kralj@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Text Processing"], "description": "# robics\n**rob**ustTop**ics** is a library targeted at **non-machine learning experts** interested in building robust\ntopic models. The main goal is to provide a simple to use framework to check if\na topic model reaches each run the same or at least a similar result.\n\n## Features\n- Supports sklearn (LatentDirichletAllocation, NMF) and gensim (LdaModel, ldamulticore, nmf) topic models\n- Creates samples based on the [sobol sequence](https://en.wikipedia.org/wiki/Sobol_sequence) which requires less samples than grid-search and makes sure the whole parameter space is used which is not sure in random-sampling.\n- Simple topic matching between the different re-initializations for each sample using word vector based coherence scores.\n- Ranking of all models based on three metrics:\n  - [Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) of the top n words for each topic\n  - Similarity of topic distributions based on the [Jensen Shannon Divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)\n  - Ranking correlation of the top n words based on [Kendall's Tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient)\n- Word based analysis of samples and topic model instances.\n\n## Install\n- **Python Version:** 3.5+\n- **Package Managers:** pip\n\n### pip\nUsing pip, robics releases are available as source packages and binary wheels:\n```\npip install robics\n```\n\n## Example\nThis is a full example including the preprocessing steps. Feel free to adapt it to your own needs.\n```python\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom gensim.models import LdaModel, nmf, ldamulticore\nfrom gensim.utils import simple_preprocess\nfrom gensim import corpora\nimport spacy\nfrom robics import robustTopics\n\nnlp = spacy.load(\"en\")\n\n# PREPROCESSING\ndataset = fetch_20newsgroups(\n    shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\ndocuments = dataset.data[:1000] # Only 1000 dokuments for performance reasons\n\n# sklearn\nno_features = 1000\n\n# counts for the NMF model\ntfidf_vectorizer = TfidfVectorizer(\n    max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\ntfidf = tfidf_vectorizer.fit_transform(documents)\ntfidf_feature_names = tfidf_vectorizer.get_feature_names()\n\n# tfidf for the LDA model\ntf_vectorizer = CountVectorizer(\n    max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\ntf = tf_vectorizer.fit_transform(documents)\ntf_feature_names = tf_vectorizer.get_feature_names()\n\n# gensim\ndef docs_to_words(docs):\n    for doc in docs:\n        yield(simple_preprocess(str(doc), deacc=True))\n\ntokenized_data = list(docs_to_words(documents))\ndictionary = corpora.Dictionary(tokenized_data)\ncorpus = [dictionary.doc2bow(text) for text in tokenized_data]\n\n# TOPIC MODELLING\nrobustTopics = RobustTopics(nlp)\n\n# Load 4 different models\nrobustTopics.load_gensim_model(\n    ldamulticore.LdaModel, corpus, dictionary, n_samples=5, n_initializations=6)\nrobustTopics.load_gensim_model(\n    nmf.Nmf, corpus, dictionary, n_samples=5, n_initializations=6)\nrobustTopics.load_sklearn_model(\n    LatentDirichletAllocation, tf, tf_vectorizer, n_samples=5, n_initializations=6)\nrobustTopics.load_sklearn_model(NMF, tf, tf_vectorizer, n_samples=5, n_initializations=3)\n\nrobustTopics.fit_models()\n\n# ANALYSIS\n# Compare different samples\nrobustTopics.rank_models()\n\n# Look at the topics\nrobustTopics.display_sample_topics(1, 0, 0.5)\nrobustTopics.display_run_topics(0, 0, 0, 10)\n\n# Look at the full reports inclusing separate values for each initialization\nrobustTopics.models[model_id].report_full\n\n# Convert the reports to a pandas dataframe\npd.DataFrame.from_records(robustTopics.models[model_id].report)\n```\n\n## Next Steps\n- Adding support for more modells if required.\n- Writing unit tests.\n- Improving the overall performance.\n- Implementing the Cv coherence measure from this [paper](https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)\n\n## Contribution\nI am happy to receive help in any of the things mentioned above or other interesting feature request.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/Christoph/robics/archive/v_011.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Christoph/robics", "keywords": "nlp,Topic Model,sklearn,gensim,topic-modeling", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "robics", "package_url": "https://pypi.org/project/robics/", "platform": "", "project_url": "https://pypi.org/project/robics/", "project_urls": {"Download": "https://github.com/Christoph/robics/archive/v_011.tar.gz", "Homepage": "https://github.com/Christoph/robics"}, "release_url": "https://pypi.org/project/robics/0.11/", "requires_dist": null, "requires_python": "", "summary": "Automatic detection of robust parametrizations for LDA and NMF. Compatible with scikit-learn and gensim.", "version": "0.11", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>robics</h1>\n<p><strong>rob</strong>ustTop<strong>ics</strong> is a library targeted at <strong>non-machine learning experts</strong> interested in building robust\ntopic models. The main goal is to provide a simple to use framework to check if\na topic model reaches each run the same or at least a similar result.</p>\n<h2>Features</h2>\n<ul>\n<li>Supports sklearn (LatentDirichletAllocation, NMF) and gensim (LdaModel, ldamulticore, nmf) topic models</li>\n<li>Creates samples based on the <a href=\"https://en.wikipedia.org/wiki/Sobol_sequence\" rel=\"nofollow\">sobol sequence</a> which requires less samples than grid-search and makes sure the whole parameter space is used which is not sure in random-sampling.</li>\n<li>Simple topic matching between the different re-initializations for each sample using word vector based coherence scores.</li>\n<li>Ranking of all models based on three metrics:\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Jaccard_index\" rel=\"nofollow\">Jaccard distance</a> of the top n words for each topic</li>\n<li>Similarity of topic distributions based on the <a href=\"https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\" rel=\"nofollow\">Jensen Shannon Divergence</a></li>\n<li>Ranking correlation of the top n words based on <a href=\"https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient\" rel=\"nofollow\">Kendall's Tau</a></li>\n</ul>\n</li>\n<li>Word based analysis of samples and topic model instances.</li>\n</ul>\n<h2>Install</h2>\n<ul>\n<li><strong>Python Version:</strong> 3.5+</li>\n<li><strong>Package Managers:</strong> pip</li>\n</ul>\n<h3>pip</h3>\n<p>Using pip, robics releases are available as source packages and binary wheels:</p>\n<pre><code>pip install robics\n</code></pre>\n<h2>Example</h2>\n<p>This is a full example including the preprocessing steps. Feel free to adapt it to your own needs.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">fetch_20newsgroups</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.feature_extraction.text</span> <span class=\"kn\">import</span> <span class=\"n\">TfidfVectorizer</span><span class=\"p\">,</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.decomposition</span> <span class=\"kn\">import</span> <span class=\"n\">LatentDirichletAllocation</span><span class=\"p\">,</span> <span class=\"n\">NMF</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gensim.models</span> <span class=\"kn\">import</span> <span class=\"n\">LdaModel</span><span class=\"p\">,</span> <span class=\"n\">nmf</span><span class=\"p\">,</span> <span class=\"n\">ldamulticore</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gensim.utils</span> <span class=\"kn\">import</span> <span class=\"n\">simple_preprocess</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gensim</span> <span class=\"kn\">import</span> <span class=\"n\">corpora</span>\n<span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">robics</span> <span class=\"kn\">import</span> <span class=\"n\">robustTopics</span>\n\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"en\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># PREPROCESSING</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">fetch_20newsgroups</span><span class=\"p\">(</span>\n    <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">remove</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'headers'</span><span class=\"p\">,</span> <span class=\"s1\">'footers'</span><span class=\"p\">,</span> <span class=\"s1\">'quotes'</span><span class=\"p\">))</span>\n<span class=\"n\">documents</span> <span class=\"o\">=</span> <span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">[:</span><span class=\"mi\">1000</span><span class=\"p\">]</span> <span class=\"c1\"># Only 1000 dokuments for performance reasons</span>\n\n<span class=\"c1\"># sklearn</span>\n<span class=\"n\">no_features</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n\n<span class=\"c1\"># counts for the NMF model</span>\n<span class=\"n\">tfidf_vectorizer</span> <span class=\"o\">=</span> <span class=\"n\">TfidfVectorizer</span><span class=\"p\">(</span>\n    <span class=\"n\">max_df</span><span class=\"o\">=</span><span class=\"mf\">0.95</span><span class=\"p\">,</span> <span class=\"n\">min_df</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">max_features</span><span class=\"o\">=</span><span class=\"n\">no_features</span><span class=\"p\">,</span> <span class=\"n\">stop_words</span><span class=\"o\">=</span><span class=\"s1\">'english'</span><span class=\"p\">)</span>\n<span class=\"n\">tfidf</span> <span class=\"o\">=</span> <span class=\"n\">tfidf_vectorizer</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">)</span>\n<span class=\"n\">tfidf_feature_names</span> <span class=\"o\">=</span> <span class=\"n\">tfidf_vectorizer</span><span class=\"o\">.</span><span class=\"n\">get_feature_names</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># tfidf for the LDA model</span>\n<span class=\"n\">tf_vectorizer</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">(</span>\n    <span class=\"n\">max_df</span><span class=\"o\">=</span><span class=\"mf\">0.95</span><span class=\"p\">,</span> <span class=\"n\">min_df</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">max_features</span><span class=\"o\">=</span><span class=\"n\">no_features</span><span class=\"p\">,</span> <span class=\"n\">stop_words</span><span class=\"o\">=</span><span class=\"s1\">'english'</span><span class=\"p\">)</span>\n<span class=\"n\">tf</span> <span class=\"o\">=</span> <span class=\"n\">tf_vectorizer</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">)</span>\n<span class=\"n\">tf_feature_names</span> <span class=\"o\">=</span> <span class=\"n\">tf_vectorizer</span><span class=\"o\">.</span><span class=\"n\">get_feature_names</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># gensim</span>\n<span class=\"k\">def</span> <span class=\"nf\">docs_to_words</span><span class=\"p\">(</span><span class=\"n\">docs</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">doc</span> <span class=\"ow\">in</span> <span class=\"n\">docs</span><span class=\"p\">:</span>\n        <span class=\"k\">yield</span><span class=\"p\">(</span><span class=\"n\">simple_preprocess</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">),</span> <span class=\"n\">deacc</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">))</span>\n\n<span class=\"n\">tokenized_data</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">docs_to_words</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">))</span>\n<span class=\"n\">dictionary</span> <span class=\"o\">=</span> <span class=\"n\">corpora</span><span class=\"o\">.</span><span class=\"n\">Dictionary</span><span class=\"p\">(</span><span class=\"n\">tokenized_data</span><span class=\"p\">)</span>\n<span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">dictionary</span><span class=\"o\">.</span><span class=\"n\">doc2bow</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">text</span> <span class=\"ow\">in</span> <span class=\"n\">tokenized_data</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># TOPIC MODELLING</span>\n<span class=\"n\">robustTopics</span> <span class=\"o\">=</span> <span class=\"n\">RobustTopics</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Load 4 different models</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">load_gensim_model</span><span class=\"p\">(</span>\n    <span class=\"n\">ldamulticore</span><span class=\"o\">.</span><span class=\"n\">LdaModel</span><span class=\"p\">,</span> <span class=\"n\">corpus</span><span class=\"p\">,</span> <span class=\"n\">dictionary</span><span class=\"p\">,</span> <span class=\"n\">n_samples</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">n_initializations</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">)</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">load_gensim_model</span><span class=\"p\">(</span>\n    <span class=\"n\">nmf</span><span class=\"o\">.</span><span class=\"n\">Nmf</span><span class=\"p\">,</span> <span class=\"n\">corpus</span><span class=\"p\">,</span> <span class=\"n\">dictionary</span><span class=\"p\">,</span> <span class=\"n\">n_samples</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">n_initializations</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">)</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">load_sklearn_model</span><span class=\"p\">(</span>\n    <span class=\"n\">LatentDirichletAllocation</span><span class=\"p\">,</span> <span class=\"n\">tf</span><span class=\"p\">,</span> <span class=\"n\">tf_vectorizer</span><span class=\"p\">,</span> <span class=\"n\">n_samples</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">n_initializations</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">)</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">load_sklearn_model</span><span class=\"p\">(</span><span class=\"n\">NMF</span><span class=\"p\">,</span> <span class=\"n\">tf</span><span class=\"p\">,</span> <span class=\"n\">tf_vectorizer</span><span class=\"p\">,</span> <span class=\"n\">n_samples</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">n_initializations</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">fit_models</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># ANALYSIS</span>\n<span class=\"c1\"># Compare different samples</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">rank_models</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Look at the topics</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">display_sample_topics</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">display_run_topics</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Look at the full reports inclusing separate values for each initialization</span>\n<span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"p\">[</span><span class=\"n\">model_id</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">report_full</span>\n\n<span class=\"c1\"># Convert the reports to a pandas dataframe</span>\n<span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">.</span><span class=\"n\">from_records</span><span class=\"p\">(</span><span class=\"n\">robustTopics</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"p\">[</span><span class=\"n\">model_id</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">report</span><span class=\"p\">)</span>\n</pre>\n<h2>Next Steps</h2>\n<ul>\n<li>Adding support for more modells if required.</li>\n<li>Writing unit tests.</li>\n<li>Improving the overall performance.</li>\n<li>Implementing the Cv coherence measure from this <a href=\"https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\" rel=\"nofollow\">paper</a></li>\n</ul>\n<h2>Contribution</h2>\n<p>I am happy to receive help in any of the things mentioned above or other interesting feature request.</p>\n\n          </div>"}, "last_serial": 6816374, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "663ac2a1df6f184417dd5c376d315c01", "sha256": "8463a0206e855825631903f3b9df0ce3ee1f9cf8f67cebab6f689cc47af5d915"}, "downloads": -1, "filename": "robics-0.1.tar.gz", "has_sig": false, "md5_digest": "663ac2a1df6f184417dd5c376d315c01", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7940, "upload_time": "2020-03-15T17:08:03", "upload_time_iso_8601": "2020-03-15T17:08:03.320199Z", "url": "https://files.pythonhosted.org/packages/54/fe/f47654f1ec89b36a3ee4edbf8cffed3489a90f5f8b47ad3913dc231f88de/robics-0.1.tar.gz", "yanked": false}], "0.11": [{"comment_text": "", "digests": {"md5": "678c8418745fb5add6bb3214a99e16c1", "sha256": "bec0462a3215abe93e0bbbe38a6e9b7dc4fb0c268242300fca748f83ce7c1113"}, "downloads": -1, "filename": "robics-0.11.tar.gz", "has_sig": false, "md5_digest": "678c8418745fb5add6bb3214a99e16c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11010, "upload_time": "2020-03-15T17:19:40", "upload_time_iso_8601": "2020-03-15T17:19:40.589512Z", "url": "https://files.pythonhosted.org/packages/d6/93/d9a9ea834aec427cc7f521e59a5879fc15442d76d0f61afb4997080176eb/robics-0.11.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "678c8418745fb5add6bb3214a99e16c1", "sha256": "bec0462a3215abe93e0bbbe38a6e9b7dc4fb0c268242300fca748f83ce7c1113"}, "downloads": -1, "filename": "robics-0.11.tar.gz", "has_sig": false, "md5_digest": "678c8418745fb5add6bb3214a99e16c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11010, "upload_time": "2020-03-15T17:19:40", "upload_time_iso_8601": "2020-03-15T17:19:40.589512Z", "url": "https://files.pythonhosted.org/packages/d6/93/d9a9ea834aec427cc7f521e59a5879fc15442d76d0f61afb4997080176eb/robics-0.11.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:05 2020"}