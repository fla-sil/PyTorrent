{"info": {"author": "Edwin Bedolla", "author_email": "developeredwin@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "# SegMed [![Build Status](https://travis-ci.org/DCI-NET/segmed.svg?branch=master)](https://travis-ci.org/DCI-NET/segmed)\n\nThis is a collection of Deep Learning semantic segmentation models to use for\nspecific tasks, namely medical images, cells, histological data and related.\n\n## Models\n\nThe models here presented are just two, namely the [U-Net](https://arxiv.org/pdf/1505.04597.pdf)\nand the [MultiResUNet](https://arxiv.org/pdf/1902.04049.pdf). These models have been a very good\napplication of Fully Convolutional Networks to the medical image segmentation task, and are very\nwell suited for it.\n\n## Implementation\n\nEverything is implemented with [TensorFlow 2.0](tensorflow.org), using the newly acquired Keras API\nwithin TensorFlow. This allows for the flexibility and completeness of using the full TensorFlow\nlibrary while still having very good scripting capabilities with Keras.\n\n## Dependencies\n\nThere are several ways to install this package.\n\n### Using `pip`\n\nThe easiest way to install this package is using `pip` with the following command\n\n    pip install segmed\n\nalthough it is _highly encouraged_ to do this inside a virtual environment.\n\nIf using [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb)\nthen this is the **preferred** way to use the package.\n\n**IMPORTANT**: When using Colaboratory one must always install `TensorFlow 2.0` first and then install `segmed`,\ni.e. this package, using the following commands in a cell within a Colaboratory notebook:\n```\n!pip install --upgrade pip\n!pip install segmed\n!pip install --upgrade tensorflow\n```\n\n### Using `poetry`\n\n[`poetry`](https://poetry.eustace.io/) is supported, by following the\n[installation](https://poetry.eustace.io/docs/#installation) instructions to get `poetry` installed, the following\ncommand should install `segmed` in a virtual environment:\n```shell\n# clone the repository\ngit clone https://github.com/DCI-NET/segmed\n# run poetry and install\npoetry install\n```\n\n`poetry` is a next-gen dependecy manager and makes everything a lot easier.\n\n### Using `conda`\n\nThis package also comes with a\n[conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)\nfor those that use the [Anaconda distribution](https://www.anaconda.com/distribution/).\n\nTo install the environment make sure you have [conda](https://conda.io/en/latest/) installed, then run the following\n\n    conda env create -f segmed_env.yml\n\nthis should ask you to confirm the installation, say yes and proceed with the installation. After that, activate the newly\ncreated environment\n\n    conda activate segmed\n\nand now you are ready to run the code within this repository.\n\n## Unit tests\n\nThis repository has some unit tests available that should be running constantly in the background,\nand the status of the current code build is displayed in the badge above (the one right to the title).\n\nOne can manually run the tests, too. You can download this repository with `git` like so:\n\n    git clone https://github.com/DCI-NET/segmed.git\n\nThen, you install [pytest](https://pytest.org/en/latest/) and just run the following command\n\n    pytest\n\nand the test suite should start running, with a few import and API warnings, but everything should pass\nif the badge above says _passing_ in green.\n\n## Examples\n\nThis repository also has some (_very_) barebones examples of how to use these models.\nHowever, they were run in a local machine and most of the data cannot be used.\nThese examples should be used as a _tutorial_ for the package,\njust to have a basic idea of how to run and create an image segmentation pipeline with `segmed`, \nbut you will _not_ be able to rerun the notebooks.\n\nThe reason for this is that most of the datasets are **very** large, so they cannot be bundled\nwith this repository; some other datasets **cannot** be redistributed as per request of the original authors.\n\nEither way, **all** of the trained models and weights are **freely available** upon request.\n\n### Demo\n\nFor completeness, here is a simple example. Assuming you have followed the instructions and everything is installed\ncorrectly, you can do the following to train a simple U-Net model:\n```python\nfrom segmed.train import train_unet\nfrom segmed.models import Unet\n\n# Define some example hyperparameters\nbatch_size = 8\nepochs = 50\nsteps_per_epoch=100\n\n# Declare the paths to use (following the Keras convention)\n# https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator\ndata_path = \"general/path/to/images\"\nimg_path = data_path + \"augmented/images/path\"\nmasks_path = data_path + \"augmented/masks/path\"\nmodel_file = \"path/to/save/model/unet_model.h5\"\n\n# Create a Unet (custom) model with a regularizer and\n# batch normalization\ncustom_params = {\n    \"activation\": \"relu\",\n    \"padding\": \"same\",\n    \"batch_norm\": True,\n    \"l2_reg\": 0.995\n}\nmodel = Unet(variant=\"custom\", parameters=custom_params)\n# Train the model!\nhistory = train_unet(\n    model,\n    img_path,\n    masks_path,\n    batch_size=batch_size,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    model_file=model_file,\n)\n```\nNow, the training should have started and you're good to go!\n\n## Datasets\n\nThe datasets employed in some of the parts of this repository are the following:\n\n- [ISBI 2012 Challenge](http://brainiac2.mit.edu/isbi_challenge/home)\n- [Motion-based Segmentation and Recognition Dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/)\n- [DRIVE: Digital Retinal Images for Vessel Extraction](https://www.isi.uu.nl/Research/Databases/DRIVE/)\n- [Fast and Robust Segmentation of White Blood Cell Images by Self-supervised Learning](https://github.com/zxaoyou/segmentation_WBC)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/DCI-NET/segmed", "keywords": "", "license": "MIT", "maintainer": "Edwin Bedolla", "maintainer_email": "developeredwin@gmail.com", "name": "segmed", "package_url": "https://pypi.org/project/segmed/", "platform": "", "project_url": "https://pypi.org/project/segmed/", "project_urls": {"Homepage": "https://github.com/DCI-NET/segmed", "Repository": "https://github.com/DCI-NET/segmed"}, "release_url": "https://pypi.org/project/segmed/0.6.12/", "requires_dist": ["scikit-learn (>=0.21.3,<0.22.0)", "scikit-image (>=0.16.2,<0.17.0)", "tensorflow (>=2.0,<3.0)"], "requires_python": ">=3.7,<4.0", "summary": "Applying Deep Learning to medical image segmentation tasks", "version": "0.6.12", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>SegMed <a href=\"https://travis-ci.org/DCI-NET/segmed\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd138f12cf9c2f019ab84ef82c6e6cc9489b3c5f/68747470733a2f2f7472617669732d63692e6f72672f4443492d4e45542f7365676d65642e7376673f6272616e63683d6d6173746572\"></a></h1>\n<p>This is a collection of Deep Learning semantic segmentation models to use for\nspecific tasks, namely medical images, cells, histological data and related.</p>\n<h2>Models</h2>\n<p>The models here presented are just two, namely the <a href=\"https://arxiv.org/pdf/1505.04597.pdf\" rel=\"nofollow\">U-Net</a>\nand the <a href=\"https://arxiv.org/pdf/1902.04049.pdf\" rel=\"nofollow\">MultiResUNet</a>. These models have been a very good\napplication of Fully Convolutional Networks to the medical image segmentation task, and are very\nwell suited for it.</p>\n<h2>Implementation</h2>\n<p>Everything is implemented with <a href=\"tensorflow.org\" rel=\"nofollow\">TensorFlow 2.0</a>, using the newly acquired Keras API\nwithin TensorFlow. This allows for the flexibility and completeness of using the full TensorFlow\nlibrary while still having very good scripting capabilities with Keras.</p>\n<h2>Dependencies</h2>\n<p>There are several ways to install this package.</p>\n<h3>Using <code>pip</code></h3>\n<p>The easiest way to install this package is using <code>pip</code> with the following command</p>\n<pre><code>pip install segmed\n</code></pre>\n<p>although it is <em>highly encouraged</em> to do this inside a virtual environment.</p>\n<p>If using <a href=\"https://colab.research.google.com/notebooks/welcome.ipynb\" rel=\"nofollow\">Colaboratory</a>\nthen this is the <strong>preferred</strong> way to use the package.</p>\n<p><strong>IMPORTANT</strong>: When using Colaboratory one must always install <code>TensorFlow 2.0</code> first and then install <code>segmed</code>,\ni.e. this package, using the following commands in a cell within a Colaboratory notebook:</p>\n<pre><code>!pip install --upgrade pip\n!pip install segmed\n!pip install --upgrade tensorflow\n</code></pre>\n<h3>Using <code>poetry</code></h3>\n<p><a href=\"https://poetry.eustace.io/\" rel=\"nofollow\"><code>poetry</code></a> is supported, by following the\n<a href=\"https://poetry.eustace.io/docs/#installation\" rel=\"nofollow\">installation</a> instructions to get <code>poetry</code> installed, the following\ncommand should install <code>segmed</code> in a virtual environment:</p>\n<pre><span class=\"c1\"># clone the repository</span>\ngit clone https://github.com/DCI-NET/segmed\n<span class=\"c1\"># run poetry and install</span>\npoetry install\n</pre>\n<p><code>poetry</code> is a next-gen dependecy manager and makes everything a lot easier.</p>\n<h3>Using <code>conda</code></h3>\n<p>This package also comes with a\n<a href=\"https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\" rel=\"nofollow\">conda environment</a>\nfor those that use the <a href=\"https://www.anaconda.com/distribution/\" rel=\"nofollow\">Anaconda distribution</a>.</p>\n<p>To install the environment make sure you have <a href=\"https://conda.io/en/latest/\" rel=\"nofollow\">conda</a> installed, then run the following</p>\n<pre><code>conda env create -f segmed_env.yml\n</code></pre>\n<p>this should ask you to confirm the installation, say yes and proceed with the installation. After that, activate the newly\ncreated environment</p>\n<pre><code>conda activate segmed\n</code></pre>\n<p>and now you are ready to run the code within this repository.</p>\n<h2>Unit tests</h2>\n<p>This repository has some unit tests available that should be running constantly in the background,\nand the status of the current code build is displayed in the badge above (the one right to the title).</p>\n<p>One can manually run the tests, too. You can download this repository with <code>git</code> like so:</p>\n<pre><code>git clone https://github.com/DCI-NET/segmed.git\n</code></pre>\n<p>Then, you install <a href=\"https://pytest.org/en/latest/\" rel=\"nofollow\">pytest</a> and just run the following command</p>\n<pre><code>pytest\n</code></pre>\n<p>and the test suite should start running, with a few import and API warnings, but everything should pass\nif the badge above says <em>passing</em> in green.</p>\n<h2>Examples</h2>\n<p>This repository also has some (<em>very</em>) barebones examples of how to use these models.\nHowever, they were run in a local machine and most of the data cannot be used.\nThese examples should be used as a <em>tutorial</em> for the package,\njust to have a basic idea of how to run and create an image segmentation pipeline with <code>segmed</code>,\nbut you will <em>not</em> be able to rerun the notebooks.</p>\n<p>The reason for this is that most of the datasets are <strong>very</strong> large, so they cannot be bundled\nwith this repository; some other datasets <strong>cannot</strong> be redistributed as per request of the original authors.</p>\n<p>Either way, <strong>all</strong> of the trained models and weights are <strong>freely available</strong> upon request.</p>\n<h3>Demo</h3>\n<p>For completeness, here is a simple example. Assuming you have followed the instructions and everything is installed\ncorrectly, you can do the following to train a simple U-Net model:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">segmed.train</span> <span class=\"kn\">import</span> <span class=\"n\">train_unet</span>\n<span class=\"kn\">from</span> <span class=\"nn\">segmed.models</span> <span class=\"kn\">import</span> <span class=\"n\">Unet</span>\n\n<span class=\"c1\"># Define some example hyperparameters</span>\n<span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">8</span>\n<span class=\"n\">epochs</span> <span class=\"o\">=</span> <span class=\"mi\">50</span>\n<span class=\"n\">steps_per_epoch</span><span class=\"o\">=</span><span class=\"mi\">100</span>\n\n<span class=\"c1\"># Declare the paths to use (following the Keras convention)</span>\n<span class=\"c1\"># https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator</span>\n<span class=\"n\">data_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"general/path/to/images\"</span>\n<span class=\"n\">img_path</span> <span class=\"o\">=</span> <span class=\"n\">data_path</span> <span class=\"o\">+</span> <span class=\"s2\">\"augmented/images/path\"</span>\n<span class=\"n\">masks_path</span> <span class=\"o\">=</span> <span class=\"n\">data_path</span> <span class=\"o\">+</span> <span class=\"s2\">\"augmented/masks/path\"</span>\n<span class=\"n\">model_file</span> <span class=\"o\">=</span> <span class=\"s2\">\"path/to/save/model/unet_model.h5\"</span>\n\n<span class=\"c1\"># Create a Unet (custom) model with a regularizer and</span>\n<span class=\"c1\"># batch normalization</span>\n<span class=\"n\">custom_params</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"activation\"</span><span class=\"p\">:</span> <span class=\"s2\">\"relu\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"padding\"</span><span class=\"p\">:</span> <span class=\"s2\">\"same\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"batch_norm\"</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"l2_reg\"</span><span class=\"p\">:</span> <span class=\"mf\">0.995</span>\n<span class=\"p\">}</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Unet</span><span class=\"p\">(</span><span class=\"n\">variant</span><span class=\"o\">=</span><span class=\"s2\">\"custom\"</span><span class=\"p\">,</span> <span class=\"n\">parameters</span><span class=\"o\">=</span><span class=\"n\">custom_params</span><span class=\"p\">)</span>\n<span class=\"c1\"># Train the model!</span>\n<span class=\"n\">history</span> <span class=\"o\">=</span> <span class=\"n\">train_unet</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span>\n    <span class=\"n\">img_path</span><span class=\"p\">,</span>\n    <span class=\"n\">masks_path</span><span class=\"p\">,</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span>\n    <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"n\">epochs</span><span class=\"p\">,</span>\n    <span class=\"n\">steps_per_epoch</span><span class=\"o\">=</span><span class=\"n\">steps_per_epoch</span><span class=\"p\">,</span>\n    <span class=\"n\">model_file</span><span class=\"o\">=</span><span class=\"n\">model_file</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n</pre>\n<p>Now, the training should have started and you're good to go!</p>\n<h2>Datasets</h2>\n<p>The datasets employed in some of the parts of this repository are the following:</p>\n<ul>\n<li><a href=\"http://brainiac2.mit.edu/isbi_challenge/home\" rel=\"nofollow\">ISBI 2012 Challenge</a></li>\n<li><a href=\"http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/\" rel=\"nofollow\">Motion-based Segmentation and Recognition Dataset</a></li>\n<li><a href=\"https://www.isi.uu.nl/Research/Databases/DRIVE/\" rel=\"nofollow\">DRIVE: Digital Retinal Images for Vessel Extraction</a></li>\n<li><a href=\"https://github.com/zxaoyou/segmentation_WBC\" rel=\"nofollow\">Fast and Robust Segmentation of White Blood Cell Images by Self-supervised Learning</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6067153, "releases": {"0.6.12": [{"comment_text": "", "digests": {"md5": "0bb9f53491cca81de6e4ff199e1b4b0a", "sha256": "2e86e3c8e8607bf8156376fa1724b2b028dc98c57ede350a5bfb890f6a4eb1a7"}, "downloads": -1, "filename": "segmed-0.6.12-py3-none-any.whl", "has_sig": false, "md5_digest": "0bb9f53491cca81de6e4ff199e1b4b0a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 22005, "upload_time": "2019-11-02T05:04:22", "upload_time_iso_8601": "2019-11-02T05:04:22.482014Z", "url": "https://files.pythonhosted.org/packages/8e/26/a716dbc71ef6f0b58df6f894f24cdfc687c979db87aacbb454768f0c2116/segmed-0.6.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5f0e738a888e283aeb1d5d732ca5a2e4", "sha256": "7aadb6c0de183c270e13cb917bf797452e70d1ac9442e8394012d52678b39124"}, "downloads": -1, "filename": "segmed-0.6.12.tar.gz", "has_sig": false, "md5_digest": "5f0e738a888e283aeb1d5d732ca5a2e4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7,<4.0", "size": 18705, "upload_time": "2019-11-02T05:04:24", "upload_time_iso_8601": "2019-11-02T05:04:24.855686Z", "url": "https://files.pythonhosted.org/packages/56/fb/caf07ce708729a3a10c02cdf999d34c83e5a3412743719bba4b66117af73/segmed-0.6.12.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0bb9f53491cca81de6e4ff199e1b4b0a", "sha256": "2e86e3c8e8607bf8156376fa1724b2b028dc98c57ede350a5bfb890f6a4eb1a7"}, "downloads": -1, "filename": "segmed-0.6.12-py3-none-any.whl", "has_sig": false, "md5_digest": "0bb9f53491cca81de6e4ff199e1b4b0a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 22005, "upload_time": "2019-11-02T05:04:22", "upload_time_iso_8601": "2019-11-02T05:04:22.482014Z", "url": "https://files.pythonhosted.org/packages/8e/26/a716dbc71ef6f0b58df6f894f24cdfc687c979db87aacbb454768f0c2116/segmed-0.6.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5f0e738a888e283aeb1d5d732ca5a2e4", "sha256": "7aadb6c0de183c270e13cb917bf797452e70d1ac9442e8394012d52678b39124"}, "downloads": -1, "filename": "segmed-0.6.12.tar.gz", "has_sig": false, "md5_digest": "5f0e738a888e283aeb1d5d732ca5a2e4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7,<4.0", "size": 18705, "upload_time": "2019-11-02T05:04:24", "upload_time_iso_8601": "2019-11-02T05:04:24.855686Z", "url": "https://files.pythonhosted.org/packages/56/fb/caf07ce708729a3a10c02cdf999d34c83e5a3412743719bba4b66117af73/segmed-0.6.12.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:44 2020"}