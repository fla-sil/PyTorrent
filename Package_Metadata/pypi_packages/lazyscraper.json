{"info": {"author": "Ivan Begtin", "author_email": "ivan@begtin.tech", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "About Lazyscraper\n=================\n\nLazyscraper is a simple command line tool and library, a swiss knife for scraper writers. It's created to work only from command line and to make easier\nscraper writing for very simple tasks like extraction of external urls or simple table.\n\n\nSupported patterns\n==================\n* simpleul - Extracts list of urls with pattern ul/li/a. Returns array of urls with \"_text\" and \"href\" fields\n* simpleopt - Extracts list of options values with pattern select/option. Returns array: \"_text\", \"value\"\n* exturls - Extracts list of urls that leads to external websites. Returns array of urls with \"_text\" and \"href\" fields\n* getforms - Extracts all forms from website. Returns complex JSON data with each form on the page\n\n\nCommand-line tool\n=================\nUsage: lazyscraper.py [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n* extract   Extract data with xpath\n* gettable  Extracts table with data from html\n* use       Uses predefined pattern to extract page data\n\nExamples\n========\n\nExtracts list of photos and names of Russian government ministers and outputs it to \"gov_persons.csv\"\n\n    python lscraper.py extract --url http://government.ru/en/gov/persons/ --xpath \"//img[@class='photo']\" --fieldnames src,srcset,alt --absolutize True --output gov_persons.csv --format csv\n\nExtracts list of ministries from Russian government website using pattern \"simpleul\" and from UL tag with class \"departments col col__wide\" and outputs absolutized urls.\n\n    python lscraper.py use --pattern simpleul --nodeclass \"departments col col__wide\" --url http://government.ru/en/ministries  --absolutize True\n\n\nExtracts list of territorial organizations urls from Russian tax service website using pattern \"simpleopt\".\n\n    python lscraper.py use --pattern simpleopt --url http://nalog.ru\n\nExtracts all forms from Russian tax service website using pattern \"getforms\". Returns JSON with each form and each button, input and select\n\n    python lscraper.py use --pattern getforms --url http://nalog.ru\n\nExtracts list of websites urls of Russian Federal Treasury and uses awk to extract domains.\n\n    python lscraper.py extract --url http://roskazna.ru --xpath \"//ul[@class='site-list']/li/a\" --fieldnames href | awk -F/ '{print $3}'\n\nHow to use library\n==================\n\nExtracts all urls with fields: src, alt, href and _text from gov.uk website\n    >>> from lazyscraper import extract_data_xpath\n    >>> extract_data_xpath('http://gov.uk', xpath='//a', fieldnames='src,alt,href,_text', absolutize=True)\n\n\nRun pattern 'simpleopt' against Russian federal treasury website\n    >>> from lazyscraper import use_pattern\n    >>> use_pattern('http://roskazna.ru', 'simpleopt')\n\nRequirements\n============\n* Python3 https://www.python.org\n* click https://github.com/pallets/click\n* lxml http://lxml.de/", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ivbeg/lazyscraper", "keywords": "scraping lazy lazy-scraping htmlpatterns", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "lazyscraper", "package_url": "https://pypi.org/project/lazyscraper/", "platform": "", "project_url": "https://pypi.org/project/lazyscraper/", "project_urls": {"Homepage": "https://github.com/ivbeg/lazyscraper"}, "release_url": "https://pypi.org/project/lazyscraper/0.1.2/", "requires_dist": null, "requires_python": "", "summary": "Lazy simple command line tool, a swiss knife for scraper writers. Automates scraping so much as possible", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"about-lazyscraper\">\n<h2>About Lazyscraper</h2>\n<p>Lazyscraper is a simple command line tool and library, a swiss knife for scraper writers. It\u2019s created to work only from command line and to make easier\nscraper writing for very simple tasks like extraction of external urls or simple table.</p>\n</div>\n<div id=\"supported-patterns\">\n<h2>Supported patterns</h2>\n<ul>\n<li>simpleul - Extracts list of urls with pattern ul/li/a. Returns array of urls with \u201c_text\u201d and \u201chref\u201d fields</li>\n<li>simpleopt - Extracts list of options values with pattern select/option. Returns array: \u201c_text\u201d, \u201cvalue\u201d</li>\n<li>exturls - Extracts list of urls that leads to external websites. Returns array of urls with \u201c_text\u201d and \u201chref\u201d fields</li>\n<li>getforms - Extracts all forms from website. Returns complex JSON data with each form on the page</li>\n</ul>\n</div>\n<div id=\"command-line-tool\">\n<h2>Command-line tool</h2>\n<p>Usage: lazyscraper.py [OPTIONS] COMMAND [ARGS]\u2026</p>\n<dl>\n<dt>Options:</dt>\n<dd><table>\n<col>\n<col>\n<tbody>\n<tr><td>\n<kbd><span class=\"option\">--help</span></kbd></td>\n<td>Show this message and exit.</td></tr>\n</tbody>\n</table>\n</dd>\n</dl>\n<p>Commands:\n* extract   Extract data with xpath\n* gettable  Extracts table with data from html\n* use       Uses predefined pattern to extract page data</p>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<p>Extracts list of photos and names of Russian government ministers and outputs it to \u201cgov_persons.csv\u201d</p>\n<blockquote>\npython lscraper.py extract \u2013url <a href=\"http://government.ru/en/gov/persons/\" rel=\"nofollow\">http://government.ru/en/gov/persons/</a> \u2013xpath \u201c//img[@class=\u2019photo\u2019]\u201d \u2013fieldnames src,srcset,alt \u2013absolutize True \u2013output gov_persons.csv \u2013format csv</blockquote>\n<p>Extracts list of ministries from Russian government website using pattern \u201csimpleul\u201d and from UL tag with class \u201cdepartments col col__wide\u201d and outputs absolutized urls.</p>\n<blockquote>\npython lscraper.py use \u2013pattern simpleul \u2013nodeclass \u201cdepartments col col__wide\u201d \u2013url <a href=\"http://government.ru/en/ministries\" rel=\"nofollow\">http://government.ru/en/ministries</a>  \u2013absolutize True</blockquote>\n<p>Extracts list of territorial organizations urls from Russian tax service website using pattern \u201csimpleopt\u201d.</p>\n<blockquote>\npython lscraper.py use \u2013pattern simpleopt \u2013url <a href=\"http://nalog.ru\" rel=\"nofollow\">http://nalog.ru</a></blockquote>\n<p>Extracts all forms from Russian tax service website using pattern \u201cgetforms\u201d. Returns JSON with each form and each button, input and select</p>\n<blockquote>\npython lscraper.py use \u2013pattern getforms \u2013url <a href=\"http://nalog.ru\" rel=\"nofollow\">http://nalog.ru</a></blockquote>\n<p>Extracts list of websites urls of Russian Federal Treasury and uses awk to extract domains.</p>\n<blockquote>\npython lscraper.py extract \u2013url <a href=\"http://roskazna.ru\" rel=\"nofollow\">http://roskazna.ru</a> \u2013xpath \u201c//ul[@class=\u2019site-list\u2019]/li/a\u201d \u2013fieldnames href | awk -F/ \u2018{print $3}\u2019</blockquote>\n</div>\n<div id=\"how-to-use-library\">\n<h2>How to use library</h2>\n<dl>\n<dt>Extracts all urls with fields: src, alt, href and _text from gov.uk website</dt>\n<dd><pre>&gt;&gt;&gt; from lazyscraper import extract_data_xpath\n&gt;&gt;&gt; extract_data_xpath('http://gov.uk', xpath='//a', fieldnames='src,alt,href,_text', absolutize=True)\n</pre>\n</dd>\n<dt>Run pattern \u2018simpleopt\u2019 against Russian federal treasury website</dt>\n<dd><pre>&gt;&gt;&gt; from lazyscraper import use_pattern\n&gt;&gt;&gt; use_pattern('http://roskazna.ru', 'simpleopt')\n</pre>\n</dd>\n</dl>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<ul>\n<li>Python3 <a href=\"https://www.python.org\" rel=\"nofollow\">https://www.python.org</a></li>\n<li>click <a href=\"https://github.com/pallets/click\" rel=\"nofollow\">https://github.com/pallets/click</a></li>\n<li>lxml <a href=\"http://lxml.de/\" rel=\"nofollow\">http://lxml.de/</a></li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 7103833, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "8fc0dd95e98480c3219865782f1b004d", "sha256": "1dc4ea98785e8d6d95b54e74a0fff4cd9dcdb4df6f141c19a7d638561d6363bc"}, "downloads": -1, "filename": "lazyscraper-0.1.0-py2.7.egg", "has_sig": false, "md5_digest": "8fc0dd95e98480c3219865782f1b004d", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 18994, "upload_time": "2018-01-14T21:54:25", "upload_time_iso_8601": "2018-01-14T21:54:25.691479Z", "url": "https://files.pythonhosted.org/packages/ee/36/d4470d3c9268be94ba9b408f0b4a1b1b2e86759ad6767dfc1ef48af3790e/lazyscraper-0.1.0-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "93165ef4dc31811024260fbb201eda71", "sha256": "a842195f1183d7b909ffd249997ea3471a2c11b1de7e90804a723a18f9b05aec"}, "downloads": -1, "filename": "lazyscraper-0.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "93165ef4dc31811024260fbb201eda71", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16923, "upload_time": "2018-01-14T21:54:23", "upload_time_iso_8601": "2018-01-14T21:54:23.444041Z", "url": "https://files.pythonhosted.org/packages/6b/3d/ce41cb623f9c0b174cd357d04e8982eccc9c9c0751db622be55214b344a1/lazyscraper-0.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "01c511678d87a6e7066063c552f58ef2", "sha256": "99d3b9c150160344aa86ba2e153c8df261a20980d486792661145981b7f14fc3"}, "downloads": -1, "filename": "lazyscraper-0.1.0-py3.6.egg", "has_sig": false, "md5_digest": "01c511678d87a6e7066063c552f58ef2", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 20588, "upload_time": "2018-01-14T21:54:27", "upload_time_iso_8601": "2018-01-14T21:54:27.219074Z", "url": "https://files.pythonhosted.org/packages/60/f4/afda9312b4544faa08008b1033fafc3f237a4bbada61b780cd5dbf23a52c/lazyscraper-0.1.0-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "ea3b0220fd3152bec84a8009f0cdb9d5", "sha256": "4adedfc28583f9885f48ac833d3cca8b675a7e33d04591591d1b159535227eb2"}, "downloads": -1, "filename": "lazyscraper-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ea3b0220fd3152bec84a8009f0cdb9d5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15005, "upload_time": "2018-02-10T14:49:00", "upload_time_iso_8601": "2018-02-10T14:49:00.632057Z", "url": "https://files.pythonhosted.org/packages/98/40/dca99f363bc39632e63a929fc873fee315261e6b90cf58341ec118dec192/lazyscraper-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c8c754d4a7ff0ceb13660627ed7573b", "sha256": "bd22af8ea53f68ba30395fbd8d9e6e37e934f244d8ae319dfdf761f95175a8f3"}, "downloads": -1, "filename": "lazyscraper-0.1.0.tar.gz", "has_sig": false, "md5_digest": "7c8c754d4a7ff0ceb13660627ed7573b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10534, "upload_time": "2018-01-14T21:54:29", "upload_time_iso_8601": "2018-01-14T21:54:29.008458Z", "url": "https://files.pythonhosted.org/packages/1a/15/b6a0c42be87100d0e6dc82644f576ca12119ab84cab319b946d06cf7efa7/lazyscraper-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "18d60e2001e0c0b3683a7a6ba0ed52bf", "sha256": "775499afb75dfd2c5ea4cf88e69295c662fcef3cce86fdf8846a7a2bd2aabfb0"}, "downloads": -1, "filename": "lazyscraper-0.1.1.tar.gz", "has_sig": false, "md5_digest": "18d60e2001e0c0b3683a7a6ba0ed52bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8074, "upload_time": "2020-04-26T09:15:23", "upload_time_iso_8601": "2020-04-26T09:15:23.308955Z", "url": "https://files.pythonhosted.org/packages/d3/7f/d8380b7a442880a9547e273b2111cabb05b9a237b16277976445d1af3142/lazyscraper-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "8be59d8057ef58692b14533490e5aa62", "sha256": "7aa22949dffeddbfc8fa0d54fe4b23060c2bae9e20c57a7d8dae5e860c2029ec"}, "downloads": -1, "filename": "lazyscraper-0.1.2.tar.gz", "has_sig": false, "md5_digest": "8be59d8057ef58692b14533490e5aa62", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7972, "upload_time": "2020-04-26T09:23:36", "upload_time_iso_8601": "2020-04-26T09:23:36.193135Z", "url": "https://files.pythonhosted.org/packages/5f/90/02a840d71ff46108c9161a53e9c2175b97b8dd07fbe264bef4d0fc0cfc44/lazyscraper-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8be59d8057ef58692b14533490e5aa62", "sha256": "7aa22949dffeddbfc8fa0d54fe4b23060c2bae9e20c57a7d8dae5e860c2029ec"}, "downloads": -1, "filename": "lazyscraper-0.1.2.tar.gz", "has_sig": false, "md5_digest": "8be59d8057ef58692b14533490e5aa62", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7972, "upload_time": "2020-04-26T09:23:36", "upload_time_iso_8601": "2020-04-26T09:23:36.193135Z", "url": "https://files.pythonhosted.org/packages/5f/90/02a840d71ff46108c9161a53e9c2175b97b8dd07fbe264bef4d0fc0cfc44/lazyscraper-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:35 2020"}