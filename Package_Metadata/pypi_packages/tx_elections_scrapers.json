{"info": {"author": "Chris Chang", "author_email": "c@crccheck.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7"], "description": "Texas Elections Scrapers\n========================\n\n.. image:: https://travis-ci.org/texastribune/tx_election_scrapers.svg\n    :target: https://travis-ci.org/texastribune/tx_election_scrapers\n\nHi. This is just me fooling around trying to come up a better way to scrape\nelection results. The tricky logic has been refined in other Texas Tribune\nprojects, but they were deeply tied to other logic.\n\nThe idea is to split the process up into multiple logical steps that other\npeople might find useful:\n\n1. Ingest results: Typically either with `curl` or `cat` or anything that pipes\n   output to stdout.\n2. Serialize the output html as JSON: Does not attempt to extract information.\n   Just separates data from the html. This is the hard part that scrapers have\n   trouble with.\n3. Interpret the serialized output: Turns the raw serialized data into\n   something you might expect to see from a nice API.\n\nIn a Extract, transform, load (ETL) process, this just covers the extractions,\nwith support for minor transforming.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/texastribune/tx_election_scrapers", "keywords": null, "license": "Apache License, Version 2.0", "maintainer": null, "maintainer_email": null, "name": "tx_elections_scrapers", "package_url": "https://pypi.org/project/tx_elections_scrapers/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/tx_elections_scrapers/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/texastribune/tx_election_scrapers"}, "release_url": "https://pypi.org/project/tx_elections_scrapers/0.4.1/", "requires_dist": null, "requires_python": null, "summary": "Scrapers for Texas elections results", "version": "0.4.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/texastribune/tx_election_scrapers\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/texastribune/tx_election_scrapers.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4f7521b51c78421d4cad188edd232b05642a18c0/68747470733a2f2f7472617669732d63692e6f72672f746578617374726962756e652f74785f656c656374696f6e5f73637261706572732e737667\"></a>\n<p>Hi. This is just me fooling around trying to come up a better way to scrape\nelection results. The tricky logic has been refined in other Texas Tribune\nprojects, but they were deeply tied to other logic.</p>\n<p>The idea is to split the process up into multiple logical steps that other\npeople might find useful:</p>\n<ol>\n<li>Ingest results: Typically either with <cite>curl</cite> or <cite>cat</cite> or anything that pipes\noutput to stdout.</li>\n<li>Serialize the output html as JSON: Does not attempt to extract information.\nJust separates data from the html. This is the hard part that scrapers have\ntrouble with.</li>\n<li>Interpret the serialized output: Turns the raw serialized data into\nsomething you might expect to see from a nice API.</li>\n</ol>\n<p>In a Extract, transform, load (ETL) process, this just covers the extractions,\nwith support for minor transforming.</p>\n\n          </div>"}, "last_serial": 1427086, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "aa5528fb980a893caf24f22199b48983", "sha256": "075506a09280afaa216728a05b1ab71e2243cb86e4c69c6875801560d35f0ccc"}, "downloads": -1, "filename": "tx_elections_scrapers-0.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "aa5528fb980a893caf24f22199b48983", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 16686, "upload_time": "2015-01-02T04:28:39", "upload_time_iso_8601": "2015-01-02T04:28:39.521088Z", "url": "https://files.pythonhosted.org/packages/22/82/e71e7d3d1a2f4c5e260b9a5ac5fc8e6daacb73908259be30cf28fba74ce1/tx_elections_scrapers-0.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f9a7e1a5ddff7b39110a42d39ca46564", "sha256": "7aa38f02e5953d86e736750c75e3fd3c5f6fe6c7ac0c6d1ab397481b53cfc401"}, "downloads": -1, "filename": "tx_elections_scrapers-0.1.0.tar.gz", "has_sig": false, "md5_digest": "f9a7e1a5ddff7b39110a42d39ca46564", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10843, "upload_time": "2015-01-02T04:28:36", "upload_time_iso_8601": "2015-01-02T04:28:36.186287Z", "url": "https://files.pythonhosted.org/packages/e3/40/b6dcd1e0549f09700c64481317b9c8ac6e354bfb2166c2b1372b2d234930/tx_elections_scrapers-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "47b897f655f9ed9261f4aac5fb48404b", "sha256": "f59516eb1f7bb6383d392e4a86a6a64075deec4b14cd6ab19134b77637d70f02"}, "downloads": -1, "filename": "tx_elections_scrapers-0.2.0-py2-none-any.whl", "has_sig": false, "md5_digest": "47b897f655f9ed9261f4aac5fb48404b", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 17251, "upload_time": "2015-01-16T06:29:29", "upload_time_iso_8601": "2015-01-16T06:29:29.931004Z", "url": "https://files.pythonhosted.org/packages/57/59/e361d2bd419217d7c6b827fa974c6757b07f48336398f37949d93ff8feee/tx_elections_scrapers-0.2.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "77e834ff413349e5b4ff6922b5d6425f", "sha256": "f9b6181e4beccab9e21859c1949c72efe4dc740a048a38e5a868bfe9b87469b4"}, "downloads": -1, "filename": "tx_elections_scrapers-0.2.0.tar.gz", "has_sig": false, "md5_digest": "77e834ff413349e5b4ff6922b5d6425f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11392, "upload_time": "2015-01-16T06:29:27", "upload_time_iso_8601": "2015-01-16T06:29:27.881384Z", "url": "https://files.pythonhosted.org/packages/25/1a/f0046944aa9c44591d9a1bd74448ffe6360c1cbd2ad082a396534a6ebb0e/tx_elections_scrapers-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "37edb8f23f9109334f098253fce2acfb", "sha256": "81bde5457208568159a4050fa687df7289643beb018c677ba6e0f7b46c863bcb"}, "downloads": -1, "filename": "tx_elections_scrapers-0.3.0.tar.gz", "has_sig": false, "md5_digest": "37edb8f23f9109334f098253fce2acfb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11466, "upload_time": "2015-01-16T17:21:11", "upload_time_iso_8601": "2015-01-16T17:21:11.130691Z", "url": "https://files.pythonhosted.org/packages/71/a1/0d49c92326c35016da195ea55c23715e28ad06fa416b03e387505b8d0c74/tx_elections_scrapers-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "57fb6b48b5b8f298097eb9cb23b17c68", "sha256": "3863993c9f9fa46bec45f1ba6a24ba87ff22c6136b978ff8e3e79edb9b839ff1"}, "downloads": -1, "filename": "tx_elections_scrapers-0.4.0-py2-none-any.whl", "has_sig": false, "md5_digest": "57fb6b48b5b8f298097eb9cb23b17c68", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 18848, "upload_time": "2015-01-20T00:44:03", "upload_time_iso_8601": "2015-01-20T00:44:03.948834Z", "url": "https://files.pythonhosted.org/packages/77/df/98dea28aa70bc8a1c58ff4d6a1181a7e3532b31e7a96dfb3937ce99df2dd/tx_elections_scrapers-0.4.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bfbf2684f9b098034d0dde954a154426", "sha256": "397ca16131c3ef07e8857356d753f39c9067950598d125aee2172f2f080888b3"}, "downloads": -1, "filename": "tx_elections_scrapers-0.4.0.tar.gz", "has_sig": false, "md5_digest": "bfbf2684f9b098034d0dde954a154426", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12401, "upload_time": "2015-01-20T00:44:02", "upload_time_iso_8601": "2015-01-20T00:44:02.170313Z", "url": "https://files.pythonhosted.org/packages/7c/66/10a350cf05a8e7c1da0cf2ab45f60344fe3ddafb7dd1981655712c3cdbc1/tx_elections_scrapers-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "40ac3dd259f1e8a7065f1bd30a2e2332", "sha256": "0b957b7c7c147def6fba69b6c46ba1643339bfcd5ac14be46ac884dba066644d"}, "downloads": -1, "filename": "tx_elections_scrapers-0.4.1-py2-none-any.whl", "has_sig": false, "md5_digest": "40ac3dd259f1e8a7065f1bd30a2e2332", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 19522, "upload_time": "2015-02-17T17:15:37", "upload_time_iso_8601": "2015-02-17T17:15:37.115056Z", "url": "https://files.pythonhosted.org/packages/a2/ab/47a9874b1b485c5845836cb3c2cc68edb903df09c094e0207f82748c573a/tx_elections_scrapers-0.4.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2c0f70c81935149514764cfda6b57340", "sha256": "e4e1f077b8eb2d4a33664c3b13c0d50b71b4452cb3f9a1e68d3540d6ab608d6c"}, "downloads": -1, "filename": "tx_elections_scrapers-0.4.1.tar.gz", "has_sig": false, "md5_digest": "2c0f70c81935149514764cfda6b57340", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12975, "upload_time": "2015-02-17T17:15:34", "upload_time_iso_8601": "2015-02-17T17:15:34.746450Z", "url": "https://files.pythonhosted.org/packages/6d/86/9a48ca92cba88bd71e35f548e40a870d8cf088d00c748bf1a8ed7cba923b/tx_elections_scrapers-0.4.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "40ac3dd259f1e8a7065f1bd30a2e2332", "sha256": "0b957b7c7c147def6fba69b6c46ba1643339bfcd5ac14be46ac884dba066644d"}, "downloads": -1, "filename": "tx_elections_scrapers-0.4.1-py2-none-any.whl", "has_sig": false, "md5_digest": "40ac3dd259f1e8a7065f1bd30a2e2332", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 19522, "upload_time": "2015-02-17T17:15:37", "upload_time_iso_8601": "2015-02-17T17:15:37.115056Z", "url": "https://files.pythonhosted.org/packages/a2/ab/47a9874b1b485c5845836cb3c2cc68edb903df09c094e0207f82748c573a/tx_elections_scrapers-0.4.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2c0f70c81935149514764cfda6b57340", "sha256": "e4e1f077b8eb2d4a33664c3b13c0d50b71b4452cb3f9a1e68d3540d6ab608d6c"}, "downloads": -1, "filename": "tx_elections_scrapers-0.4.1.tar.gz", "has_sig": false, "md5_digest": "2c0f70c81935149514764cfda6b57340", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12975, "upload_time": "2015-02-17T17:15:34", "upload_time_iso_8601": "2015-02-17T17:15:34.746450Z", "url": "https://files.pythonhosted.org/packages/6d/86/9a48ca92cba88bd71e35f548e40a870d8cf088d00c748bf1a8ed7cba923b/tx_elections_scrapers-0.4.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:43:16 2020"}