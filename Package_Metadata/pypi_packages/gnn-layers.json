{"info": {"author": "shobrook", "author_email": "shobrookj@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# custom-gnn-layers\n\nThis is a little collection of the custom graph convolutional and pooling layers I've made for various projects. Everything here is built on the [PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric) library and can be used like a regular PyTorch module.\n\n## Installation\n\n> Requires Python 3.X, PyTorch 1.2.X, and PyTorch Geometric\n\nYou can install these layers with pip:\n\n`$ pip install gnn_layers`\n\n## Convolutional Layers\n\n### EdgeAttentionConv\n\n`EdgeAttentionConv` is an edge-conditioned filter with an attention mechanism. It's the same as [`NNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.NNConv), except an attention coefficient for each message is calculated from the edge features. The idea is that messages from some neighbors may be more important than others, depending on their connection with the root node. Node embeddings are updated like so:\n\n<p align=\"center\">\n  <img align=\"center\" src=\"assets/edge_attention_eq.png\" width=\"50%\" />\n</p>\n\nwhere _W<sub>r</sub>_ and _W<sub>g</sub>_ are trainable weight matrices, and _h<sub>e</sub>_ is a neural network (e.g. a MLP). _W<sub>r</sub>_ is used to transform the root node features and _W<sub>g</sub>_ is used to calculate an attention coefficient.\n\n**Parameters:**\n\n- **in_channels** (_int_): Size of each input node embedding.\n- **out_channels** (_int_): Size of each output node embedding.\n- **edge_nn** (_torch.nn.Module_): A neural network _h<sub>e</sub>_ that maps edge features `edge_attr` of shape `[-1, num_edge_features]` to shape `[-1, in_channels * out_channels]`\n- **root_weight** (_bool, optional_): If set to `False`, the layer will not add the transformed root node features to the output. (default: `True`)\n- **bias** (_bool, optional_): If set to `False`, the layer will not learn an additive bias. (default: `True`)\n\n**Example:**\n\n```python\nimport torch\nfrom gnn_layers import EdgeAttentionConv\n\n# Convolutional layer\nconv = EdgeAttentionConv(\n  in_channels=1,\n  out_channels=4,\n  edge_nn=torch.nn.Linear(2, 1 * 4),\n)\n\n# Your input graph\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nedge_attr = torch.tensor([[0, 1], [1, 0], [1, 0], [0, 1]], dtype=torch.long)\n\n# Your output graph\nx = conv(x, edge_index, edge_attr) # Shape is now [3, 4]\n```\n\n### ImageConv\n\n`ImageConv` is an edge-conditioned filter for graphs where the node features are n-dimensional matrices, such as 2D or 3D images, rather than vectors. The filter applies a (non-graph) convolution, i.e. `torch.nn.Conv2d` or `torch.nn.Conv3d`, to transform the node features. Node embeddings are updated like so:\n\n<p align=\"center\">\n  <img src=\"assets/image_eq.png\" width=\"47%\" />\n</p>\n\nwhere _&phi;<sub>r</sub>_ and _&phi;<sub>m</sub>_ are convolutional layers, and _W<sub>e</sub>_ is a weight matrix.\n\n**Parameters:**\n\n- **in_channels** (_int_): Number of channels in the input node image.\n- **out_channels** (_int_): Number of channels in the output node image.\n- **image_dims** (_tuple_): Dimensions of the input node image as a tuple, e.g. for a 4x4 image, set to `(4, 4)`.\n- **kernel_size** (_tuple_): Size of the convolving kernel.\n- **num_edge_attr** (_int_): Number of edge features.\n- **bias** (_bool, optional_): If set to `False`, the layer will not learn an additive bias. (default: `True`)\n- **aggr** (_str, optional_): The aggregation scheme to use (`\"add\"`, `\"mean\"`, `\"max\"`). (default: `\"add\"`)\n- **\\*\\*kwargs** (_optional_): Additional arguments for `torch.nn.Conv1d`, `torch.nn.Conv2d`, or `torch.nn.Conv3d`.\n\n**Example:**\n\n```python\nimport torch\nfrom gnn_layers import ImageConv\n\n# Convolutional layer\nconv = ImageConv(\n  in_channels=1,\n  out_channels=4,\n  image_dims=(8, 8),\n  kernel_size=(2, 2),\n  num_edge_attr=2\n)\n\n# Your input graph\nx = torch.randn((3, 1, 8, 8), dtype=torch.float)\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nedge_attr = torch.tensor([[0, 1], [1, 0], [1, 0], [0, 1]], dtype=torch.long)\n\n# Your output graph\nx = conv(x, edge_index, edge_attr) # Shape is now [3, 4, 7, 7]\n```\n\n<!--This is useful for learning on images that have some sort of embedded relational structure. For example, ...-->\n\n<!-- ## Pooling Layers\n\n### SimPool\n\nSimPool can either learn which nodes to merge together or which edges to drop.\n\n### DiffPool\n\n### GlobalEdgePool\n\nAverage the edge features and add them to the graph embedding. -->", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/shobrook/custom-gnn-layers", "keywords": "gnn,graph-neural-network,convolution,pooling,pytorch,graph", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "gnn-layers", "package_url": "https://pypi.org/project/gnn-layers/", "platform": "", "project_url": "https://pypi.org/project/gnn-layers/", "project_urls": {"Homepage": "https://github.com/shobrook/custom-gnn-layers"}, "release_url": "https://pypi.org/project/gnn-layers/1.0.2/", "requires_dist": null, "requires_python": ">=3", "summary": "Some custom GNN layers for PyTorch Geometric", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>custom-gnn-layers</h1>\n<p>This is a little collection of the custom graph convolutional and pooling layers I've made for various projects. Everything here is built on the <a href=\"https://github.com/rusty1s/pytorch_geometric\" rel=\"nofollow\">PyTorch Geometric</a> library and can be used like a regular PyTorch module.</p>\n<h2>Installation</h2>\n<blockquote>\n<p>Requires Python 3.X, PyTorch 1.2.X, and PyTorch Geometric</p>\n</blockquote>\n<p>You can install these layers with pip:</p>\n<p><code>$ pip install gnn_layers</code></p>\n<h2>Convolutional Layers</h2>\n<h3>EdgeAttentionConv</h3>\n<p><code>EdgeAttentionConv</code> is an edge-conditioned filter with an attention mechanism. It's the same as <a href=\"https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.NNConv\" rel=\"nofollow\"><code>NNConv</code></a>, except an attention coefficient for each message is calculated from the edge features. The idea is that messages from some neighbors may be more important than others, depending on their connection with the root node. Node embeddings are updated like so:</p>\n<p align=\"center\">\n  <img align=\"center\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7b024d5ebe3320a0eb4eac662d536af1badb9f30/6173736574732f656467655f617474656e74696f6e5f65712e706e67\" width=\"50%\">\n</p>\n<p>where <em>W<sub>r</sub></em> and <em>W<sub>g</sub></em> are trainable weight matrices, and <em>h<sub>e</sub></em> is a neural network (e.g. a MLP). <em>W<sub>r</sub></em> is used to transform the root node features and <em>W<sub>g</sub></em> is used to calculate an attention coefficient.</p>\n<p><strong>Parameters:</strong></p>\n<ul>\n<li><strong>in_channels</strong> (<em>int</em>): Size of each input node embedding.</li>\n<li><strong>out_channels</strong> (<em>int</em>): Size of each output node embedding.</li>\n<li><strong>edge_nn</strong> (<em>torch.nn.Module</em>): A neural network <em>h<sub>e</sub></em> that maps edge features <code>edge_attr</code> of shape <code>[-1, num_edge_features]</code> to shape <code>[-1, in_channels * out_channels]</code></li>\n<li><strong>root_weight</strong> (<em>bool, optional</em>): If set to <code>False</code>, the layer will not add the transformed root node features to the output. (default: <code>True</code>)</li>\n<li><strong>bias</strong> (<em>bool, optional</em>): If set to <code>False</code>, the layer will not learn an additive bias. (default: <code>True</code>)</li>\n</ul>\n<p><strong>Example:</strong></p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gnn_layers</span> <span class=\"kn\">import</span> <span class=\"n\">EdgeAttentionConv</span>\n\n<span class=\"c1\"># Convolutional layer</span>\n<span class=\"n\">conv</span> <span class=\"o\">=</span> <span class=\"n\">EdgeAttentionConv</span><span class=\"p\">(</span>\n  <span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n  <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span>\n  <span class=\"n\">edge_nn</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Your input graph</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">)</span>\n<span class=\"n\">edge_index</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span>\n                           <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">)</span>\n<span class=\"n\">edge_attr</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Your output graph</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">edge_index</span><span class=\"p\">,</span> <span class=\"n\">edge_attr</span><span class=\"p\">)</span> <span class=\"c1\"># Shape is now [3, 4]</span>\n</pre>\n<h3>ImageConv</h3>\n<p><code>ImageConv</code> is an edge-conditioned filter for graphs where the node features are n-dimensional matrices, such as 2D or 3D images, rather than vectors. The filter applies a (non-graph) convolution, i.e. <code>torch.nn.Conv2d</code> or <code>torch.nn.Conv3d</code>, to transform the node features. Node embeddings are updated like so:</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/be9145e5022d145866c24761971a45292a58e391/6173736574732f696d6167655f65712e706e67\" width=\"47%\">\n</p>\n<p>where <em>\u03c6<sub>r</sub></em> and <em>\u03c6<sub>m</sub></em> are convolutional layers, and <em>W<sub>e</sub></em> is a weight matrix.</p>\n<p><strong>Parameters:</strong></p>\n<ul>\n<li><strong>in_channels</strong> (<em>int</em>): Number of channels in the input node image.</li>\n<li><strong>out_channels</strong> (<em>int</em>): Number of channels in the output node image.</li>\n<li><strong>image_dims</strong> (<em>tuple</em>): Dimensions of the input node image as a tuple, e.g. for a 4x4 image, set to <code>(4, 4)</code>.</li>\n<li><strong>kernel_size</strong> (<em>tuple</em>): Size of the convolving kernel.</li>\n<li><strong>num_edge_attr</strong> (<em>int</em>): Number of edge features.</li>\n<li><strong>bias</strong> (<em>bool, optional</em>): If set to <code>False</code>, the layer will not learn an additive bias. (default: <code>True</code>)</li>\n<li><strong>aggr</strong> (<em>str, optional</em>): The aggregation scheme to use (<code>\"add\"</code>, <code>\"mean\"</code>, <code>\"max\"</code>). (default: <code>\"add\"</code>)</li>\n<li><strong>**kwargs</strong> (<em>optional</em>): Additional arguments for <code>torch.nn.Conv1d</code>, <code>torch.nn.Conv2d</code>, or <code>torch.nn.Conv3d</code>.</li>\n</ul>\n<p><strong>Example:</strong></p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">gnn_layers</span> <span class=\"kn\">import</span> <span class=\"n\">ImageConv</span>\n\n<span class=\"c1\"># Convolutional layer</span>\n<span class=\"n\">conv</span> <span class=\"o\">=</span> <span class=\"n\">ImageConv</span><span class=\"p\">(</span>\n  <span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n  <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span>\n  <span class=\"n\">image_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">),</span>\n  <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span>\n  <span class=\"n\">num_edge_attr</span><span class=\"o\">=</span><span class=\"mi\">2</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Your input graph</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">((</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">)</span>\n<span class=\"n\">edge_index</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span>\n                           <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">)</span>\n<span class=\"n\">edge_attr</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Your output graph</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">edge_index</span><span class=\"p\">,</span> <span class=\"n\">edge_attr</span><span class=\"p\">)</span> <span class=\"c1\"># Shape is now [3, 4, 7, 7]</span>\n</pre>\n\n\n\n          </div>"}, "last_serial": 6480459, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "4295184eb240bbdf7fea7314887af062", "sha256": "aa7c9a785c6ec04b772995def3e296d64025cf3734d217ddcde77c2cde1b48d1"}, "downloads": -1, "filename": "gnn_layers-1.0.0.tar.gz", "has_sig": false, "md5_digest": "4295184eb240bbdf7fea7314887af062", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3082, "upload_time": "2020-01-18T23:36:40", "upload_time_iso_8601": "2020-01-18T23:36:40.510110Z", "url": "https://files.pythonhosted.org/packages/f6/1f/1e2c4f313e06b9f02705a81fe5bfbd4b294115abaaffff6030110a626482/gnn_layers-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "9af15f84af1bdd06f7df05aa355e447a", "sha256": "33e4fcaddf5d78f005a6953c0d8b357a74a1b325216717cc4f31b1d0b63881a6"}, "downloads": -1, "filename": "gnn_layers-1.0.1.tar.gz", "has_sig": false, "md5_digest": "9af15f84af1bdd06f7df05aa355e447a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 3172, "upload_time": "2020-01-19T01:55:38", "upload_time_iso_8601": "2020-01-19T01:55:38.370697Z", "url": "https://files.pythonhosted.org/packages/7f/d0/b17f32f10dfb3768ed33e92cac4d8a53083f19904bfc0bfe6d27077f60b3/gnn_layers-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "cb9479013443a5736d053fc9d900d830", "sha256": "dbbba94735a5356b84476f701e67f8da83b0776e5c47e955f4f81fea91a1ca16"}, "downloads": -1, "filename": "gnn_layers-1.0.2.tar.gz", "has_sig": false, "md5_digest": "cb9479013443a5736d053fc9d900d830", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 4953, "upload_time": "2020-01-19T02:48:47", "upload_time_iso_8601": "2020-01-19T02:48:47.310789Z", "url": "https://files.pythonhosted.org/packages/d1/02/2e608230365d791f3d7e1187fe79a607423696411bf9ca732fe1074ce61c/gnn_layers-1.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cb9479013443a5736d053fc9d900d830", "sha256": "dbbba94735a5356b84476f701e67f8da83b0776e5c47e955f4f81fea91a1ca16"}, "downloads": -1, "filename": "gnn_layers-1.0.2.tar.gz", "has_sig": false, "md5_digest": "cb9479013443a5736d053fc9d900d830", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 4953, "upload_time": "2020-01-19T02:48:47", "upload_time_iso_8601": "2020-01-19T02:48:47.310789Z", "url": "https://files.pythonhosted.org/packages/d1/02/2e608230365d791f3d7e1187fe79a607423696411bf9ca732fe1074ce61c/gnn_layers-1.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:13 2020"}