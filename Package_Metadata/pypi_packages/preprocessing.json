{"info": {"author": "Mitchell Murphy", "author_email": "mwtmurphy@gmail.com", "bugtrack_url": null, "classifiers": ["Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6"], "description": ".. image:: logo.png\n   :align: center\n   :alt: Spotlight Data Logo\n\n'preprocessing'\n===============\n.. image:: https://readthedocs.org/projects/preprocessing/badge/?version=latest\n   :target: http://preprocessing.readthedocs.io/en/latest/?badge=latest\n   :alt: Documentation Status\n\nSummary\n-------\n\nText pre-processing package to aid in NLP package development for Python3. With this package you \ncan order text cleaning functions in the order you prefer rather than relying on the order of an \narbitrary NLP package.\n\nInstallation\n------------\n\npip:\n\n.. code-block:: console\n\n   pip install preprocessing\n\nPyPI - You can also download the source distribution from:\n\n`https://pypi.python.org/pypi/preprocessing/ \n<https://pypi.python.org/pypi/preprocessing/>`_\n\nYou can then perform:\n\n.. code-block:: console\n\n   pip install <path_to_tar_file>\n\non the tar file, or\n\n.. code-block:: console\n\n   python setup.py install\n\non/inside, respectively, the extracted package to install *preprocessing*.\n\nExample\n-------\n\nOnce you have the package installed, implementing it with Python3 takes the following form:\n\n.. code-block:: python\n\n   import preprocessing.text as ptext\n   from preprocessing.text import keyword_tokenize, remove_unbound_punct, remove_urls\n\n   text_string = \"important string at: http://example.com\"\n\n   clean_string = ptext.preprocess_text(text_string, [\n       remove_urls,\n       remove_unbound_punct,\n       keyword_tokenize\n   ])\n\n>>> print(clean_string)\n\"important string\"\n\nShould the functions be performed in a different order (i.e. keyword_tokenize -> remove_urls -> \nremove_non_bound_punct) :\n\n>>> print(clean_string)\n\"important string http example.com\"\n\nOrganisation\n------------\n\nThis package is comprised of a single module with no intended subpackages currently. The \n*preprocessing* package is dependent on NLTK for tokenizers and stopwords. However, ignoring this,\nthe package only has built-in dependencies from Python 3.\n\nContributing\n------------\n\nIf you feel like contributing:\n\n* `Check for open issues <https://github.com/SpotlightData/preprocessing/issues>`_ or open a new issue\n* Fork the preprocessing repository to start making your changes\n* Write a test which shows the bug was fixed or that the feature works as expected\n* Send a pull request and remember to add yourself to `CONTRIBUTORS.md <https://github.com/SpotlightData/preprocessing/blob/master/CONTRIBUTORS.md>`_\n\nLicense\n-------\n\nThis project is licensed under the MIT license (see `LICENSE <https://github.com/SpotlightData/preprocessing/blob/master/LICENSE>`_)\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/SpotlightData/preprocessing", "keywords": "text pre-processing", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "preprocessing", "package_url": "https://pypi.org/project/preprocessing/", "platform": "", "project_url": "https://pypi.org/project/preprocessing/", "project_urls": {"Homepage": "https://github.com/SpotlightData/preprocessing"}, "release_url": "https://pypi.org/project/preprocessing/0.1.13/", "requires_dist": ["nltk (==3.2.4)", "sphinx-rtd-theme (==0.2.4)"], "requires_python": ">=3", "summary": "pre-processing package for text strings", "version": "0.1.13", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img alt=\"Spotlight Data Logo\" class=\"align-center\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/388655114bc901a8aeb49270f41e805988057feb/6c6f676f2e706e67\">\n<div id=\"preprocessing\">\n<h2>\u2018preprocessing\u2019</h2>\n<a href=\"http://preprocessing.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0b2c828add35cb00365be34ed7a6004bd8b46228/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f70726570726f63657373696e672f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<div id=\"summary\">\n<h3>Summary</h3>\n<p>Text pre-processing package to aid in NLP package development for Python3. With this package you\ncan order text cleaning functions in the order you prefer rather than relying on the order of an\narbitrary NLP package.</p>\n</div>\n<div id=\"installation\">\n<h3>Installation</h3>\n<p>pip:</p>\n<pre><span class=\"go\">pip install preprocessing</span>\n</pre>\n<p>PyPI - You can also download the source distribution from:</p>\n<p><a href=\"https://pypi.python.org/pypi/preprocessing/\" rel=\"nofollow\">https://pypi.python.org/pypi/preprocessing/</a></p>\n<p>You can then perform:</p>\n<pre><span class=\"go\">pip install &lt;path_to_tar_file&gt;</span>\n</pre>\n<p>on the tar file, or</p>\n<pre><span class=\"go\">python setup.py install</span>\n</pre>\n<p>on/inside, respectively, the extracted package to install <em>preprocessing</em>.</p>\n</div>\n<div id=\"example\">\n<h3>Example</h3>\n<p>Once you have the package installed, implementing it with Python3 takes the following form:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">preprocessing.text</span> <span class=\"k\">as</span> <span class=\"nn\">ptext</span>\n<span class=\"kn\">from</span> <span class=\"nn\">preprocessing.text</span> <span class=\"kn\">import</span> <span class=\"n\">keyword_tokenize</span><span class=\"p\">,</span> <span class=\"n\">remove_unbound_punct</span><span class=\"p\">,</span> <span class=\"n\">remove_urls</span>\n\n<span class=\"n\">text_string</span> <span class=\"o\">=</span> <span class=\"s2\">\"important string at: http://example.com\"</span>\n\n<span class=\"n\">clean_string</span> <span class=\"o\">=</span> <span class=\"n\">ptext</span><span class=\"o\">.</span><span class=\"n\">preprocess_text</span><span class=\"p\">(</span><span class=\"n\">text_string</span><span class=\"p\">,</span> <span class=\"p\">[</span>\n    <span class=\"n\">remove_urls</span><span class=\"p\">,</span>\n    <span class=\"n\">remove_unbound_punct</span><span class=\"p\">,</span>\n    <span class=\"n\">keyword_tokenize</span>\n<span class=\"p\">])</span>\n</pre>\n<pre>&gt;&gt;&gt; print(clean_string)\n\"important string\"\n</pre>\n<p>Should the functions be performed in a different order (i.e. keyword_tokenize -&gt; remove_urls -&gt;\nremove_non_bound_punct) :</p>\n<pre>&gt;&gt;&gt; print(clean_string)\n\"important string http example.com\"\n</pre>\n</div>\n<div id=\"organisation\">\n<h3>Organisation</h3>\n<p>This package is comprised of a single module with no intended subpackages currently. The\n<em>preprocessing</em> package is dependent on NLTK for tokenizers and stopwords. However, ignoring this,\nthe package only has built-in dependencies from Python 3.</p>\n</div>\n<div id=\"contributing\">\n<h3>Contributing</h3>\n<p>If you feel like contributing:</p>\n<ul>\n<li><a href=\"https://github.com/SpotlightData/preprocessing/issues\" rel=\"nofollow\">Check for open issues</a> or open a new issue</li>\n<li>Fork the preprocessing repository to start making your changes</li>\n<li>Write a test which shows the bug was fixed or that the feature works as expected</li>\n<li>Send a pull request and remember to add yourself to <a href=\"https://github.com/SpotlightData/preprocessing/blob/master/CONTRIBUTORS.md\" rel=\"nofollow\">CONTRIBUTORS.md</a></li>\n</ul>\n</div>\n<div id=\"license\">\n<h3>License</h3>\n<p>This project is licensed under the MIT license (see <a href=\"https://github.com/SpotlightData/preprocessing/blob/master/LICENSE\" rel=\"nofollow\">LICENSE</a>)</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 3280527, "releases": {"0.1.12": [{"comment_text": "", "digests": {"md5": "46fe84715d76e917c55a428b6725021a", "sha256": "52e8dc499d6840c0b8cd790603a29bfe2a422b9140ef4f92b40e2a0f7c01c66d"}, "downloads": -1, "filename": "preprocessing-0.1.12-py3-none-any.whl", "has_sig": false, "md5_digest": "46fe84715d76e917c55a428b6725021a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 2735920, "upload_time": "2017-08-30T15:41:49", "upload_time_iso_8601": "2017-08-30T15:41:49.990104Z", "url": "https://files.pythonhosted.org/packages/37/52/6bd786d3c78ac3486a28158c7588e4dd15ffa11999197f6d11d471daf45b/preprocessing-0.1.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1a9397210d8eca842d1412a0668feb05", "sha256": "97080c29029375b8c9293f4e767b44e3675013cd405dc502e3cec1df11d9b760"}, "downloads": -1, "filename": "preprocessing-0.1.12.tar.gz", "has_sig": false, "md5_digest": "1a9397210d8eca842d1412a0668feb05", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 8479, "upload_time": "2017-08-30T15:41:54", "upload_time_iso_8601": "2017-08-30T15:41:54.018151Z", "url": "https://files.pythonhosted.org/packages/18/01/9087446663736030548f209bc17636a93f105306e3fb0367411ac2569d4c/preprocessing-0.1.12.tar.gz", "yanked": false}], "0.1.13": [{"comment_text": "", "digests": {"md5": "4fb36e168ef5d18fdeff3036bf75966a", "sha256": "7323b9bd514f676019b3bd5d97360df0cc7262a58fb7eee6e80e87a1894c7f15"}, "downloads": -1, "filename": "preprocessing-0.1.13-py3-none-any.whl", "has_sig": false, "md5_digest": "4fb36e168ef5d18fdeff3036bf75966a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 349593, "upload_time": "2017-10-25T09:07:50", "upload_time_iso_8601": "2017-10-25T09:07:50.422328Z", "url": "https://files.pythonhosted.org/packages/79/f9/cadc71dbd774398e486f0608fb6746de36f562edf32fc59ebbe94a589c79/preprocessing-0.1.13-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0e1a2b853c7f0e5312cf6c4af3ada664", "sha256": "4c6ef9f4b94bf02664fc4c6bdc3814dfc17a94bbbde002f2a9113c91fdfe7f87"}, "downloads": -1, "filename": "preprocessing-0.1.13.tar.gz", "has_sig": false, "md5_digest": "0e1a2b853c7f0e5312cf6c4af3ada664", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 14810, "upload_time": "2017-10-25T09:07:52", "upload_time_iso_8601": "2017-10-25T09:07:52.625681Z", "url": "https://files.pythonhosted.org/packages/e3/ca/102f0cb754c3dfdd095110711faa8566c66fa857fa0ffd2c3040ab2d8a81/preprocessing-0.1.13.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4fb36e168ef5d18fdeff3036bf75966a", "sha256": "7323b9bd514f676019b3bd5d97360df0cc7262a58fb7eee6e80e87a1894c7f15"}, "downloads": -1, "filename": "preprocessing-0.1.13-py3-none-any.whl", "has_sig": false, "md5_digest": "4fb36e168ef5d18fdeff3036bf75966a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 349593, "upload_time": "2017-10-25T09:07:50", "upload_time_iso_8601": "2017-10-25T09:07:50.422328Z", "url": "https://files.pythonhosted.org/packages/79/f9/cadc71dbd774398e486f0608fb6746de36f562edf32fc59ebbe94a589c79/preprocessing-0.1.13-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0e1a2b853c7f0e5312cf6c4af3ada664", "sha256": "4c6ef9f4b94bf02664fc4c6bdc3814dfc17a94bbbde002f2a9113c91fdfe7f87"}, "downloads": -1, "filename": "preprocessing-0.1.13.tar.gz", "has_sig": false, "md5_digest": "0e1a2b853c7f0e5312cf6c4af3ada664", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 14810, "upload_time": "2017-10-25T09:07:52", "upload_time_iso_8601": "2017-10-25T09:07:52.625681Z", "url": "https://files.pythonhosted.org/packages/e3/ca/102f0cb754c3dfdd095110711faa8566c66fa857fa0ffd2c3040ab2d8a81/preprocessing-0.1.13.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:19:52 2020"}