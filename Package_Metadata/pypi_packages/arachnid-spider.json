{"info": {"author": "Jacob Bickle, Tobin Shields", "author_email": "bickle.jake@gmail.com, tobin.shields@mhcc.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Programming Language :: Python :: 3"], "description": "# Arachnid \nArachnid is an OSINT web crawler that targets a website, attempts to enumerate all of the pages within it, and then search for interesting or sensitive information both defined by the tool and/or the user. Arachnid is built in Python, and the data is visualized via a php web app. \n\n![Scan Dashboard](https://github.com/jake-bickle/Arachnid/blob/master/scan_dashboard_feature.png)\n\n## Overview\nArachnid started with a simple question: \u201cis there a way that users could find all the emails of a supplied domain to help with OSINT efforts?\u201d This of course could only be answered by using a web crawler to visit and search every page in a given domain. But then followup questions arose: \u201cif we are already visiting each page and looking for emails, couldn\u2019t we look for other interesting information as well?\u201d And thus, the idea for a fully developed OSINT web crawler was born.  Presently, the default scan for Arachnid searches for the following information:\n\n* Email addresses\n* Phone numbers\n* Common documents and files\n* Social Media Handles\n* User supplied strings and regex (optional)\n\nTo help support scanning efforts, Arachnid also comes with some other features such as:\n\n* The ability to choose a given user agent to make the scan requests\n* The ability to add a delay to the scan requests as a mean to reduce scan noise\n* The ability to fuzz for interesting files and directories as a mean to discover hidden information (similar to dirb)\n\n## Installation\n[Coming Soon]\n\n## Basic usage\nArachnid can be hyper-customized to only search for information that is relevant to the user\u2014however, it also comes preloaded with default scans that find generally useful or interesting information.  To use the default scan, users can simple issue the following command:\n\n```\narachnid https://www.example.com/\n```\n\nThis will launch a local php server that displays the visualized data. The output will be reloaded every 30 seconds to reflect newly found information. \n\n## Predefined Scan Types\nTo help make this tool more useful, in addition to the default scan listed above, there are a few other preconfigured scan types that users can make use of.\n\n### \u201cStealth\u201d Scan\n```\narachnid https://example.com --stealth\n```\nA stealth scan will use the Google bot user agent, masking the crawler  instead of a regular firefox user. It also has a substantial delay between page requests to help make the scan less noisy. **This scan has the potential to take a long time to finish**\n\n### \u201cAggressive\u201d Scan\n```\narachnid https://example.com --aggressive\n```\n\nAn aggressive scan will ignore robots.txt rules and crawl all pages found on it. Aggressive also enables fuzzing for many pages and subdomains, and crawls at the fastest possible speed. This is ideally used when triggering alerts_IDS_WAF is not a concern. \n\n### \u201cPage Only\u201d Scan\n```\narachnid https://example.com/example_page.php --page-only\n```\n\nUsers can scrape a ingle web page instead of imitating a full site crawl. This is ideal if users want to scrape sensitive information from a data-rich page (such as a web directory)\n\nAll predefined scan types are only a base plate of options. Users may override any options they provide by supplying additional arguments. \n\n## Custom Scans\nArachnid also allows users very granular control over how they want to scan to run. Here is a sample custom scan:\n```\narachnid https://example.com --aggressive --find docs phone --agent y --delay medium --doc \".psd\" --string \"John Doe\" --regex \"^\\d{3}\\s?\\d{3}$\" --fuzz --fuzz_subdomains\n\n```\n\nHere is that scan broken down into its parts:\n```\nhttps://example.com           : Required argument, specifies the domain to target\n    --aggressive                  : Causes the formerly mentioned aggressive scan\n    --find docs phone             : Only scrapes for common documents and phone numbers\n    --agent y                     : Uses the Yahoo SearchBot header sting\n    --delay medium                : Overrides the timing of the aggressive scan and causes a medium delay, or about 4-11 seconds\n    --doc \".psd\"                  : In addition to common docs, the crawler will also look for .psd files\n    --string \"John Doe\"           : Searches for amount of occurances of \"John Doe\" on each page\n    --regex  \"^\\d{3}\\s?\\d{3}$\"    : Searches for any values that matches the provided regular expression\n    --fuzz                        : Turns on page fuzzing which searchs for over 4000 common pages\n    --fuzz_subdomains             : Turns on subdomain fuzzing which searchs for various common subdomains\n```\n\nThis does not represent all of the custom scan options available, but should give a snapshot of what Arachnid can do. For a full breakdown on each option please refer to the full documentation or use **arachnid \u2014help**.\n\n## Disclaimer\nArachnid is a OSINT tool built to aid penetration testers, web developers, and system admins to scan an authorized domain for data leakage. While there is nothing inherently illegal about scanning or scraping information from a website users should use caution when using this tool:\n**Scanning and scraping can be considered the pretext to an attack**. Some security teams consider any OSINT recon the pretext to an attack and may pursue criminal charges if they are able to identify the source of the scans.\n\n**Aggressive scans might inadvertently cause a DoS**. This tool could possibly send out thousands of requests to a given server (depending on the size of the website and the fuzzing level set). If the server is not configured to handle that much bandwidth then this tool may inadvertently result in causing a denial-of-service (DoS). Even if it is unintentional, this could result in criminal charges.\n\n**This tool does not hide your identity**. While the stealth scans might modify the header information and timing to avoid IPS/IDS detection, it does not do anything to spoof or obfuscate the origin of the request. If users want to make their requests anonymous then they should consider routing their traffic through something like TOR or a VPN.\nIn short, only use this tool to scan targets that you are authorized to scan, and that you know can handle the scan types that you configure. By using this Arachnid you agree to not use this tool if engage in malicious activity or scan unauthorized targets. In addition, the authors and contributors of this project are not responsible for any malicious usage or damage caused by this tool.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jake-bickle/Arachnid", "keywords": "", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "arachnid-spider", "package_url": "https://pypi.org/project/arachnid-spider/", "platform": "", "project_url": "https://pypi.org/project/arachnid-spider/", "project_urls": {"Homepage": "https://github.com/jake-bickle/Arachnid"}, "release_url": "https://pypi.org/project/arachnid-spider/0.9.4/", "requires_dist": ["requests", "beautifulsoup4", "tldextract", "ndg-httpsclient", "pyopenssl", "chardet", "pyasn1"], "requires_python": ">=3.7", "summary": "An OSINT tool to find data leaks on a targeted domain", "version": "0.9.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Arachnid</h1>\n<p>Arachnid is an OSINT web crawler that targets a website, attempts to enumerate all of the pages within it, and then search for interesting or sensitive information both defined by the tool and/or the user. Arachnid is built in Python, and the data is visualized via a php web app.</p>\n<p><img alt=\"Scan Dashboard\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/51f270f36e19c60839294326b4062442f1045de1/68747470733a2f2f6769746875622e636f6d2f6a616b652d6269636b6c652f41726163686e69642f626c6f622f6d61737465722f7363616e5f64617368626f6172645f666561747572652e706e67\"></p>\n<h2>Overview</h2>\n<p>Arachnid started with a simple question: \u201cis there a way that users could find all the emails of a supplied domain to help with OSINT efforts?\u201d This of course could only be answered by using a web crawler to visit and search every page in a given domain. But then followup questions arose: \u201cif we are already visiting each page and looking for emails, couldn\u2019t we look for other interesting information as well?\u201d And thus, the idea for a fully developed OSINT web crawler was born.  Presently, the default scan for Arachnid searches for the following information:</p>\n<ul>\n<li>Email addresses</li>\n<li>Phone numbers</li>\n<li>Common documents and files</li>\n<li>Social Media Handles</li>\n<li>User supplied strings and regex (optional)</li>\n</ul>\n<p>To help support scanning efforts, Arachnid also comes with some other features such as:</p>\n<ul>\n<li>The ability to choose a given user agent to make the scan requests</li>\n<li>The ability to add a delay to the scan requests as a mean to reduce scan noise</li>\n<li>The ability to fuzz for interesting files and directories as a mean to discover hidden information (similar to dirb)</li>\n</ul>\n<h2>Installation</h2>\n<p>[Coming Soon]</p>\n<h2>Basic usage</h2>\n<p>Arachnid can be hyper-customized to only search for information that is relevant to the user\u2014however, it also comes preloaded with default scans that find generally useful or interesting information.  To use the default scan, users can simple issue the following command:</p>\n<pre><code>arachnid https://www.example.com/\n</code></pre>\n<p>This will launch a local php server that displays the visualized data. The output will be reloaded every 30 seconds to reflect newly found information.</p>\n<h2>Predefined Scan Types</h2>\n<p>To help make this tool more useful, in addition to the default scan listed above, there are a few other preconfigured scan types that users can make use of.</p>\n<h3>\u201cStealth\u201d Scan</h3>\n<pre><code>arachnid https://example.com --stealth\n</code></pre>\n<p>A stealth scan will use the Google bot user agent, masking the crawler  instead of a regular firefox user. It also has a substantial delay between page requests to help make the scan less noisy. <strong>This scan has the potential to take a long time to finish</strong></p>\n<h3>\u201cAggressive\u201d Scan</h3>\n<pre><code>arachnid https://example.com --aggressive\n</code></pre>\n<p>An aggressive scan will ignore robots.txt rules and crawl all pages found on it. Aggressive also enables fuzzing for many pages and subdomains, and crawls at the fastest possible speed. This is ideally used when triggering alerts_IDS_WAF is not a concern.</p>\n<h3>\u201cPage Only\u201d Scan</h3>\n<pre><code>arachnid https://example.com/example_page.php --page-only\n</code></pre>\n<p>Users can scrape a ingle web page instead of imitating a full site crawl. This is ideal if users want to scrape sensitive information from a data-rich page (such as a web directory)</p>\n<p>All predefined scan types are only a base plate of options. Users may override any options they provide by supplying additional arguments.</p>\n<h2>Custom Scans</h2>\n<p>Arachnid also allows users very granular control over how they want to scan to run. Here is a sample custom scan:</p>\n<pre><code>arachnid https://example.com --aggressive --find docs phone --agent y --delay medium --doc \".psd\" --string \"John Doe\" --regex \"^\\d{3}\\s?\\d{3}$\" --fuzz --fuzz_subdomains\n\n</code></pre>\n<p>Here is that scan broken down into its parts:</p>\n<pre><code>https://example.com           : Required argument, specifies the domain to target\n    --aggressive                  : Causes the formerly mentioned aggressive scan\n    --find docs phone             : Only scrapes for common documents and phone numbers\n    --agent y                     : Uses the Yahoo SearchBot header sting\n    --delay medium                : Overrides the timing of the aggressive scan and causes a medium delay, or about 4-11 seconds\n    --doc \".psd\"                  : In addition to common docs, the crawler will also look for .psd files\n    --string \"John Doe\"           : Searches for amount of occurances of \"John Doe\" on each page\n    --regex  \"^\\d{3}\\s?\\d{3}$\"    : Searches for any values that matches the provided regular expression\n    --fuzz                        : Turns on page fuzzing which searchs for over 4000 common pages\n    --fuzz_subdomains             : Turns on subdomain fuzzing which searchs for various common subdomains\n</code></pre>\n<p>This does not represent all of the custom scan options available, but should give a snapshot of what Arachnid can do. For a full breakdown on each option please refer to the full documentation or use <strong>arachnid \u2014help</strong>.</p>\n<h2>Disclaimer</h2>\n<p>Arachnid is a OSINT tool built to aid penetration testers, web developers, and system admins to scan an authorized domain for data leakage. While there is nothing inherently illegal about scanning or scraping information from a website users should use caution when using this tool:\n<strong>Scanning and scraping can be considered the pretext to an attack</strong>. Some security teams consider any OSINT recon the pretext to an attack and may pursue criminal charges if they are able to identify the source of the scans.</p>\n<p><strong>Aggressive scans might inadvertently cause a DoS</strong>. This tool could possibly send out thousands of requests to a given server (depending on the size of the website and the fuzzing level set). If the server is not configured to handle that much bandwidth then this tool may inadvertently result in causing a denial-of-service (DoS). Even if it is unintentional, this could result in criminal charges.</p>\n<p><strong>This tool does not hide your identity</strong>. While the stealth scans might modify the header information and timing to avoid IPS/IDS detection, it does not do anything to spoof or obfuscate the origin of the request. If users want to make their requests anonymous then they should consider routing their traffic through something like TOR or a VPN.\nIn short, only use this tool to scan targets that you are authorized to scan, and that you know can handle the scan types that you configure. By using this Arachnid you agree to not use this tool if engage in malicious activity or scan unauthorized targets. In addition, the authors and contributors of this project are not responsible for any malicious usage or damage caused by this tool.</p>\n\n          </div>"}, "last_serial": 5980101, "releases": {"0.9.1": [{"comment_text": "", "digests": {"md5": "a5547573871c3a33237ff271b63b4bf1", "sha256": "a35b039e008d5540884dbb83e43d06578ec9a16f48fb73bed92b7b4a585d44fa"}, "downloads": -1, "filename": "arachnid_spider-0.9.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a5547573871c3a33237ff271b63b4bf1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1815845, "upload_time": "2019-09-11T20:11:05", "upload_time_iso_8601": "2019-09-11T20:11:05.649822Z", "url": "https://files.pythonhosted.org/packages/6e/b7/17e9fa25a13ca5715efe06784d2a8aed92ff6bf72ec1afdea1bc813776bc/arachnid_spider-0.9.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8fd0d5e7b97cf0ed172a8043df432895", "sha256": "ff19a79b2d2230d6a9971d09b6821556a5dd7b2cce8a90385815d69b186304b1"}, "downloads": -1, "filename": "arachnid-spider-0.9.1.tar.gz", "has_sig": false, "md5_digest": "8fd0d5e7b97cf0ed172a8043df432895", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1970764, "upload_time": "2019-09-11T20:11:09", "upload_time_iso_8601": "2019-09-11T20:11:09.170847Z", "url": "https://files.pythonhosted.org/packages/47/35/d48b83c0004f82bab725442898a5ce5217f33c76f7599c2a014ee6263255/arachnid-spider-0.9.1.tar.gz", "yanked": false}], "0.9.2": [{"comment_text": "", "digests": {"md5": "beaff651caa5dda4adefff11b78cc2b7", "sha256": "d2e6b94e52d1b54f23612357810d3e64b735ce0664363f5fd8a8145c180401f7"}, "downloads": -1, "filename": "arachnid_spider-0.9.2-py3-none-any.whl", "has_sig": false, "md5_digest": "beaff651caa5dda4adefff11b78cc2b7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1836214, "upload_time": "2019-09-28T03:50:12", "upload_time_iso_8601": "2019-09-28T03:50:12.834967Z", "url": "https://files.pythonhosted.org/packages/12/8e/8c8105792a0b1d21baa2a414511a93418311f8afa8e6aed8386a6791ba23/arachnid_spider-0.9.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5611c93d30a2d706b846ef32f11b3563", "sha256": "fa3849f1b322a0d731c1c1a5c647615ab2ddfd7b16c5e248f32c174630d504e0"}, "downloads": -1, "filename": "arachnid-spider-0.9.2.tar.gz", "has_sig": false, "md5_digest": "5611c93d30a2d706b846ef32f11b3563", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1991573, "upload_time": "2019-09-28T03:50:15", "upload_time_iso_8601": "2019-09-28T03:50:15.644609Z", "url": "https://files.pythonhosted.org/packages/63/13/27794a0d781bde89f36aaa378fed2057103ee64099c13d4cca2a31104aed/arachnid-spider-0.9.2.tar.gz", "yanked": false}], "0.9.2.1": [{"comment_text": "", "digests": {"md5": "f67a752d782e3ca03fb3cfb5878607b2", "sha256": "a3d5933757668ca5d017137c8c7b159a06d1cfce40ff3a66c055cdb6222f0c40"}, "downloads": -1, "filename": "arachnid_spider-0.9.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f67a752d782e3ca03fb3cfb5878607b2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1836376, "upload_time": "2019-09-28T07:26:30", "upload_time_iso_8601": "2019-09-28T07:26:30.720618Z", "url": "https://files.pythonhosted.org/packages/62/d6/a90ad6d07581b9aea89e609f0572f08ce9c0f2573de5f61d2a2e4dc8c927/arachnid_spider-0.9.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6364d517d493d9aa8e235d1660e07031", "sha256": "42c56083fb20be72faf77d8c1444bbe8deb0653c166982a3162135a1974ecea0"}, "downloads": -1, "filename": "arachnid-spider-0.9.2.1.tar.gz", "has_sig": false, "md5_digest": "6364d517d493d9aa8e235d1660e07031", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1991756, "upload_time": "2019-09-28T07:26:52", "upload_time_iso_8601": "2019-09-28T07:26:52.304241Z", "url": "https://files.pythonhosted.org/packages/8f/49/ef1a668a31fb18895ca92386bcee53fc67440f9115efe56c0af169137674/arachnid-spider-0.9.2.1.tar.gz", "yanked": false}], "0.9.3": [{"comment_text": "", "digests": {"md5": "a415e23a421eaef04e09096ea7274a6d", "sha256": "0d76b817ab7d809f4e80841802c48ba928548f2f0fa330bf457c3337cf99d31d"}, "downloads": -1, "filename": "arachnid_spider-0.9.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a415e23a421eaef04e09096ea7274a6d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840766, "upload_time": "2019-10-14T22:33:41", "upload_time_iso_8601": "2019-10-14T22:33:41.519479Z", "url": "https://files.pythonhosted.org/packages/14/3e/12f49af3d7cceb34b55864c91596588a6bd4b7384537b457fca984251973/arachnid_spider-0.9.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a2d01cb2dfecdd9eb6f46dfd290b7ca8", "sha256": "6b2088a6186cff5bb313727f9c2bd6e9ac96e5e3a7da597f2328bbec1411b127"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.tar.gz", "has_sig": false, "md5_digest": "a2d01cb2dfecdd9eb6f46dfd290b7ca8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1994360, "upload_time": "2019-10-14T22:33:47", "upload_time_iso_8601": "2019-10-14T22:33:47.225925Z", "url": "https://files.pythonhosted.org/packages/42/b9/4b493af29179fc56cec26378f9262c37b2046aa1a6d7f87e854ff6c822d5/arachnid-spider-0.9.3.tar.gz", "yanked": false}], "0.9.3.1": [{"comment_text": "", "digests": {"md5": "e3b3ef4335e36c338f3af5323615a0bb", "sha256": "74939d571fdae8122efc36de3500cbaf71adc2a81a49b610028f4788662ccab8"}, "downloads": -1, "filename": "arachnid_spider-0.9.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e3b3ef4335e36c338f3af5323615a0bb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840965, "upload_time": "2019-10-14T22:56:17", "upload_time_iso_8601": "2019-10-14T22:56:17.960609Z", "url": "https://files.pythonhosted.org/packages/13/66/ee8c9d06528c6e630f2e2f4d6290d93f321389c8a9435c77b07b6d5802c0/arachnid_spider-0.9.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2acda6b87b6a77ce4928dad3106765e1", "sha256": "2c498829c3703386931317cf7cb465d68aaa318d0ad79f814982c473b50199ee"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.1.tar.gz", "has_sig": false, "md5_digest": "2acda6b87b6a77ce4928dad3106765e1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1994423, "upload_time": "2019-10-14T22:56:23", "upload_time_iso_8601": "2019-10-14T22:56:23.598249Z", "url": "https://files.pythonhosted.org/packages/d3/ba/6b3ce740f883e151fab5189607d33c061534bbf005105e923ea911cd0cc8/arachnid-spider-0.9.3.1.tar.gz", "yanked": false}], "0.9.3.2": [{"comment_text": "", "digests": {"md5": "9341ad316f5fbaaabe96dab78ebd1ba6", "sha256": "4a4c48e6ac3cb7f771c120b1aa850f668d640f26ef4632f92b6fd78951f48d4f"}, "downloads": -1, "filename": "arachnid_spider-0.9.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "9341ad316f5fbaaabe96dab78ebd1ba6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840975, "upload_time": "2019-10-14T23:00:03", "upload_time_iso_8601": "2019-10-14T23:00:03.165588Z", "url": "https://files.pythonhosted.org/packages/99/24/790d9089a6f84092782c0f95b1ab38550e691427cde4853cfd188bc0ee75/arachnid_spider-0.9.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "49b54d78450748c0ed0647b3f5b2f80c", "sha256": "d4d2ce1ddafbf87bd43c9ee89ae71fbc9041fa684564d287658c49e05351441d"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.2.tar.gz", "has_sig": false, "md5_digest": "49b54d78450748c0ed0647b3f5b2f80c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1994438, "upload_time": "2019-10-14T23:00:08", "upload_time_iso_8601": "2019-10-14T23:00:08.480869Z", "url": "https://files.pythonhosted.org/packages/45/18/bd4273a75f716ad02a864c38bbae2edb794c8f2c591d5a4cfdbb6fc79962/arachnid-spider-0.9.3.2.tar.gz", "yanked": false}], "0.9.3.3": [{"comment_text": "", "digests": {"md5": "3a53622631423222548590bad76af547", "sha256": "2e9be9342a7d34490555fa8ef6a52b976f63e2f268a644994be43751867c2435"}, "downloads": -1, "filename": "arachnid_spider-0.9.3.3-py3-none-any.whl", "has_sig": false, "md5_digest": "3a53622631423222548590bad76af547", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840974, "upload_time": "2019-10-14T23:44:19", "upload_time_iso_8601": "2019-10-14T23:44:19.263905Z", "url": "https://files.pythonhosted.org/packages/93/86/19f65f77307a0410d734074653567ccd2c8898668ef6912d950a83960111/arachnid_spider-0.9.3.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7322eee51b6e75bbbfa97652e13add0", "sha256": "42c7ad88f4cce1baf80391a49f5d24c1d5c487f4970814e76348b17032f5936b"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.3.tar.gz", "has_sig": false, "md5_digest": "d7322eee51b6e75bbbfa97652e13add0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1994433, "upload_time": "2019-10-14T23:44:24", "upload_time_iso_8601": "2019-10-14T23:44:24.676541Z", "url": "https://files.pythonhosted.org/packages/2b/40/cbb56d15bb09eb9d10f5650e354511529e1e4ab1378729c17b3047bbcecc/arachnid-spider-0.9.3.3.tar.gz", "yanked": false}], "0.9.3.4": [{"comment_text": "", "digests": {"md5": "4cf8b31d30fdd542b94e028f3d296a8a", "sha256": "5e4474d77a8197a2b5a2414febf1a7228ad903b3f769d18e28e24fd5375bc836"}, "downloads": -1, "filename": "arachnid_spider-0.9.3.4-py3-none-any.whl", "has_sig": false, "md5_digest": "4cf8b31d30fdd542b94e028f3d296a8a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840976, "upload_time": "2019-10-14T23:52:34", "upload_time_iso_8601": "2019-10-14T23:52:34.326985Z", "url": "https://files.pythonhosted.org/packages/74/df/b3f95c45859f653ad5988e9ec7b22b9151e2ab72add2ccc5da2aa8475842/arachnid_spider-0.9.3.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "13c503471b105ebdf2678411e1b12e6d", "sha256": "c0b8aae84e75f1e7ced911a49e72e2caacfac51c3f64eba25715552bc657cda2"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.4.tar.gz", "has_sig": false, "md5_digest": "13c503471b105ebdf2678411e1b12e6d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1994450, "upload_time": "2019-10-14T23:52:40", "upload_time_iso_8601": "2019-10-14T23:52:40.165869Z", "url": "https://files.pythonhosted.org/packages/38/27/caf3d667e4ca79cef0ecd9b11c1d2c5741f588bc33b9a116196a50f8a7af/arachnid-spider-0.9.3.4.tar.gz", "yanked": false}], "0.9.3.5": [{"comment_text": "", "digests": {"md5": "d9af2237b5aec5b71fa9b4e75288313b", "sha256": "f3978b8d68d0fcc779d1a1098af7c62970cfd0f55faa6cc8fd69d723aa9c9aaf"}, "downloads": -1, "filename": "arachnid_spider-0.9.3.5-py3-none-any.whl", "has_sig": false, "md5_digest": "d9af2237b5aec5b71fa9b4e75288313b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1841553, "upload_time": "2019-10-15T21:46:44", "upload_time_iso_8601": "2019-10-15T21:46:44.431071Z", "url": "https://files.pythonhosted.org/packages/d6/30/130eb2dcf98300646698c23fe55bd3b254477a9243bc46e690be0ed9e14b/arachnid_spider-0.9.3.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4102eb5c2c614206b6a366b76333e4fd", "sha256": "95ea83c7ebe900ca58b3ba625f5c9b9d75b39dfe3c60aa0ea9d7ce13ad5cbc99"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.5.tar.gz", "has_sig": false, "md5_digest": "4102eb5c2c614206b6a366b76333e4fd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1994697, "upload_time": "2019-10-15T21:46:46", "upload_time_iso_8601": "2019-10-15T21:46:46.826788Z", "url": "https://files.pythonhosted.org/packages/c1/f9/d53bf09c4f7a83fcb01bc741bf9e3160b07468f42b30a1cc3df5f6350515/arachnid-spider-0.9.3.5.tar.gz", "yanked": false}], "0.9.3.6": [{"comment_text": "", "digests": {"md5": "dd927fb51d54d18fe8ee93bbe8d6ceae", "sha256": "1f84afd2a06c58d2730589ea49c572d57cc2a4dad0c9b462b33b0f41bedad11b"}, "downloads": -1, "filename": "arachnid_spider-0.9.3.6-py3-none-any.whl", "has_sig": false, "md5_digest": "dd927fb51d54d18fe8ee93bbe8d6ceae", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840428, "upload_time": "2019-10-15T21:49:01", "upload_time_iso_8601": "2019-10-15T21:49:01.131486Z", "url": "https://files.pythonhosted.org/packages/9e/3b/d6849dbd11ab4f60ac232fd9161fb32ce90e54199eceb9898f0345dbefb9/arachnid_spider-0.9.3.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7e1b94edfdd4fc82dd6675864ac8b48a", "sha256": "7de0daec17be50a5bb640c3e75c579800f10c84efd2e19c531bd0293931b514c"}, "downloads": -1, "filename": "arachnid-spider-0.9.3.6.tar.gz", "has_sig": false, "md5_digest": "7e1b94edfdd4fc82dd6675864ac8b48a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1993408, "upload_time": "2019-10-15T21:49:03", "upload_time_iso_8601": "2019-10-15T21:49:03.522251Z", "url": "https://files.pythonhosted.org/packages/21/47/305f2cfd1ecd4015ee8d9bbc5b4b438832b24e0ba7b48465bcff9289ea8a/arachnid-spider-0.9.3.6.tar.gz", "yanked": false}], "0.9.4": [{"comment_text": "", "digests": {"md5": "40b2dbcc76a924ae44f3edcf6cf667e1", "sha256": "f4e93d1f265edb67c430999f1c1a84f05edfc1c36697dc1674fafcf9351a8eda"}, "downloads": -1, "filename": "arachnid_spider-0.9.4-py3-none-any.whl", "has_sig": false, "md5_digest": "40b2dbcc76a924ae44f3edcf6cf667e1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840399, "upload_time": "2019-10-15T21:59:51", "upload_time_iso_8601": "2019-10-15T21:59:51.466778Z", "url": "https://files.pythonhosted.org/packages/fc/8e/620374119871b388d322184ae513efa855c4c8b7731e4c6322022beff855/arachnid_spider-0.9.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8d930ea7115fe4808f521745e07cad86", "sha256": "c8ff1b75269d0c949d836abfaa66e7af92be72e8670a595b724486675b8fcf7c"}, "downloads": -1, "filename": "arachnid-spider-0.9.4.tar.gz", "has_sig": false, "md5_digest": "8d930ea7115fe4808f521745e07cad86", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1993386, "upload_time": "2019-10-15T21:59:53", "upload_time_iso_8601": "2019-10-15T21:59:53.637645Z", "url": "https://files.pythonhosted.org/packages/2c/16/8c81b5ad4f31191d2d530d19faabbfa0a78badcbb13bfff8670a48406d9f/arachnid-spider-0.9.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "40b2dbcc76a924ae44f3edcf6cf667e1", "sha256": "f4e93d1f265edb67c430999f1c1a84f05edfc1c36697dc1674fafcf9351a8eda"}, "downloads": -1, "filename": "arachnid_spider-0.9.4-py3-none-any.whl", "has_sig": false, "md5_digest": "40b2dbcc76a924ae44f3edcf6cf667e1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 1840399, "upload_time": "2019-10-15T21:59:51", "upload_time_iso_8601": "2019-10-15T21:59:51.466778Z", "url": "https://files.pythonhosted.org/packages/fc/8e/620374119871b388d322184ae513efa855c4c8b7731e4c6322022beff855/arachnid_spider-0.9.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8d930ea7115fe4808f521745e07cad86", "sha256": "c8ff1b75269d0c949d836abfaa66e7af92be72e8670a595b724486675b8fcf7c"}, "downloads": -1, "filename": "arachnid-spider-0.9.4.tar.gz", "has_sig": false, "md5_digest": "8d930ea7115fe4808f521745e07cad86", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 1993386, "upload_time": "2019-10-15T21:59:53", "upload_time_iso_8601": "2019-10-15T21:59:53.637645Z", "url": "https://files.pythonhosted.org/packages/2c/16/8c81b5ad4f31191d2d530d19faabbfa0a78badcbb13bfff8670a48406d9f/arachnid-spider-0.9.4.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:17:27 2020"}