{"info": {"author": "Grammy Jiang", "author_email": "grammy.jiang@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Environment :: Plugins", "Framework :: Scrapy", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Internet :: WWW/HTTP", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "=================\nScrapy-UserAgents\n=================\n\nOverview\n========\n\nScrapy is a great framework for web crawling. This downloader middleware\nprovides a user-agent rotation based on the settings in settings.py, spider,\nrequest.\n\nRequirements\n============\n\n* Tests on Python 2.7 and Python 3.5, but it should work on other version higher\n  then Python 3.3\n\n* Tests on Linux, but it's a pure python module, it should work on other\n  platforms with official python supported, e.g. Windows, Mac OSX, BSD\n\nInstallation\n============\n\nThe quick way::\n\n    pip install scrapy-useragents\n\nOr put this middleware just beside the scrapy project.\n\nDocumentation\n=============\n\nIn setting.py, for example::\n\n    # -----------------------------------------------------------------------------\n    # USER AGENT\n    # -----------------------------------------------------------------------------\n\n    DOWNLOADER_MIDDLEWARES.update({\n        'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n        'scrapy_useragents.downloadermiddlewares.useragents.UserAgentsMiddleware': 500,\n    })\n\n    USER_AGENTS = [\n        ('Mozilla/5.0 (X11; Linux x86_64) '\n         'AppleWebKit/537.36 (KHTML, like Gecko) '\n         'Chrome/57.0.2987.110 '\n         'Safari/537.36'),  # chrome\n        ('Mozilla/5.0 (X11; Linux x86_64) '\n         'AppleWebKit/537.36 (KHTML, like Gecko) '\n         'Chrome/61.0.3163.79 '\n         'Safari/537.36'),  # chrome\n        ('Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) '\n         'Gecko/20100101 '\n         'Firefox/55.0')  # firefox\n    ]\n\nSettings Reference\n------------------\n\nUSER_AGENTS\n~~~~~~~~~~~\n\nA list of User-Agent to use when crawling, unless overridden.\n\nThe middleware will rotate this list by function cycle from the module\nitertools.\n\n**Be careful this middleware can't handle the situation that the\nCOOKIES_ENABLED is True, and the website binds the cookies with\nUser-Agent, it may cause unpredictable result of the spider. This problem will\nbe solved in the future.**\n\nTODO\n====\n\n* Read User-Agent from a backend, e.g. MongoDB, MySQL, or even a file saved on\n  the local disk.\n\n* Rotate User-Agent binding with cookies, keep the consistence\n\n* Add meta key for User-Agent selection based on each request\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/grammy-jiang/scrapy-useragents", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "Scrapy-UserAgents", "package_url": "https://pypi.org/project/Scrapy-UserAgents/", "platform": "", "project_url": "https://pypi.org/project/Scrapy-UserAgents/", "project_urls": {"Homepage": "https://github.com/grammy-jiang/scrapy-useragents"}, "release_url": "https://pypi.org/project/Scrapy-UserAgents/0.0.1/", "requires_dist": ["scrapy (>=1.4.0)", "PyPyDispatcher (>=2.1.0); platform_python_implementation == \"PyPy\""], "requires_python": "", "summary": "A middleware to change user-agent in request for Scrapy", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"overview\">\n<h2>Overview</h2>\n<p>Scrapy is a great framework for web crawling. This downloader middleware\nprovides a user-agent rotation based on the settings in settings.py, spider,\nrequest.</p>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<ul>\n<li>Tests on Python 2.7 and Python 3.5, but it should work on other version higher\nthen Python 3.3</li>\n<li>Tests on Linux, but it\u2019s a pure python module, it should work on other\nplatforms with official python supported, e.g. Windows, Mac OSX, BSD</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>The quick way:</p>\n<pre>pip install scrapy-useragents\n</pre>\n<p>Or put this middleware just beside the scrapy project.</p>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>In setting.py, for example:</p>\n<pre># -----------------------------------------------------------------------------\n# USER AGENT\n# -----------------------------------------------------------------------------\n\nDOWNLOADER_MIDDLEWARES.update({\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n    'scrapy_useragents.downloadermiddlewares.useragents.UserAgentsMiddleware': 500,\n})\n\nUSER_AGENTS = [\n    ('Mozilla/5.0 (X11; Linux x86_64) '\n     'AppleWebKit/537.36 (KHTML, like Gecko) '\n     'Chrome/57.0.2987.110 '\n     'Safari/537.36'),  # chrome\n    ('Mozilla/5.0 (X11; Linux x86_64) '\n     'AppleWebKit/537.36 (KHTML, like Gecko) '\n     'Chrome/61.0.3163.79 '\n     'Safari/537.36'),  # chrome\n    ('Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) '\n     'Gecko/20100101 '\n     'Firefox/55.0')  # firefox\n]\n</pre>\n<div id=\"settings-reference\">\n<h3>Settings Reference</h3>\n<h3 id=\"user-agents\"><span class=\"section-subtitle\">USER_AGENTS</span></h3>\n<p>A list of User-Agent to use when crawling, unless overridden.</p>\n<p>The middleware will rotate this list by function cycle from the module\nitertools.</p>\n<p><strong>Be careful this middleware can\u2019t handle the situation that the\nCOOKIES_ENABLED is True, and the website binds the cookies with\nUser-Agent, it may cause unpredictable result of the spider. This problem will\nbe solved in the future.</strong></p>\n</div>\n</div>\n<div id=\"todo\">\n<h2>TODO</h2>\n<ul>\n<li>Read User-Agent from a backend, e.g. MongoDB, MySQL, or even a file saved on\nthe local disk.</li>\n<li>Rotate User-Agent binding with cookies, keep the consistence</li>\n<li>Add meta key for User-Agent selection based on each request</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 3191104, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "95d2296b49f8ee2345196a7a7918dbcf", "sha256": "316ef88068aa5107591e97c9d04a75effc2600914ac7198bbed52a1c65a4434c"}, "downloads": -1, "filename": "Scrapy_UserAgents-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "95d2296b49f8ee2345196a7a7918dbcf", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 5809, "upload_time": "2017-09-21T09:23:49", "upload_time_iso_8601": "2017-09-21T09:23:49.756766Z", "url": "https://files.pythonhosted.org/packages/ee/37/efaea9801d3080facde05b79ece2fe65c0c2265a88ba5d1767432efe6ca9/Scrapy_UserAgents-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a9d0d5de20b134d5e29db718a0274c54", "sha256": "caa6d5b3bdbddcd79678caad3bae5d5cd0f3a96144807acf491925795e75c44e"}, "downloads": -1, "filename": "Scrapy-UserAgents-0.0.1.tar.gz", "has_sig": false, "md5_digest": "a9d0d5de20b134d5e29db718a0274c54", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4520, "upload_time": "2017-09-21T09:23:51", "upload_time_iso_8601": "2017-09-21T09:23:51.084216Z", "url": "https://files.pythonhosted.org/packages/d7/53/f83dd78f44ad6310aec870f50b216d56f938478b4bdb9886c86aff81bfc4/Scrapy-UserAgents-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "95d2296b49f8ee2345196a7a7918dbcf", "sha256": "316ef88068aa5107591e97c9d04a75effc2600914ac7198bbed52a1c65a4434c"}, "downloads": -1, "filename": "Scrapy_UserAgents-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "95d2296b49f8ee2345196a7a7918dbcf", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 5809, "upload_time": "2017-09-21T09:23:49", "upload_time_iso_8601": "2017-09-21T09:23:49.756766Z", "url": "https://files.pythonhosted.org/packages/ee/37/efaea9801d3080facde05b79ece2fe65c0c2265a88ba5d1767432efe6ca9/Scrapy_UserAgents-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a9d0d5de20b134d5e29db718a0274c54", "sha256": "caa6d5b3bdbddcd79678caad3bae5d5cd0f3a96144807acf491925795e75c44e"}, "downloads": -1, "filename": "Scrapy-UserAgents-0.0.1.tar.gz", "has_sig": false, "md5_digest": "a9d0d5de20b134d5e29db718a0274c54", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4520, "upload_time": "2017-09-21T09:23:51", "upload_time_iso_8601": "2017-09-21T09:23:51.084216Z", "url": "https://files.pythonhosted.org/packages/d7/53/f83dd78f44ad6310aec870f50b216d56f938478b4bdb9886c86aff81bfc4/Scrapy-UserAgents-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:39 2020"}