{"info": {"author": "Melvin Mathew", "author_email": "melvin15may@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5"], "description": "============================\nssdedupe\n============================\n\n.. image:: https://img.shields.io/pypi/v/ssdedupe.svg\n        :target: https://pypi.python.org/pypi/ssdedupe\n\n.. image:: https://img.shields.io/travis/melvin15may/ssdedupe.svg\n        :target: https://travis-ci.org/melvin15may/ssdedupe\n\n.. image:: https://codecov.io/gh/melvin15may/ssdedupe/branch/master/graph/badge.svg\n\t    :target: https://codecov.io/gh/melvin15may/ssdedupe\n\n.. image:: https://readthedocs.org/projects/pgdedupe/badge/?version=latest\n        :target: https://pgdedupe.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n.. image:: https://pyup.io/repos/github/melvin15may/ssdedupe/shield.svg\n     :target: https://pyup.io/account/repos/github/melvin15may/ssdedupe/\n     :alt: Updates\n\n\n**This is a fork from** `dssg/pgdedupe <http://github.com/dssg/pgdedupe>`_. **This will now be a separate repo for MS SQL Server implementation.** (See `PR#40 <https://github.com/dssg/pgdedupe/pull/40>`_)\n\n**This packages is for working with Microsoft SQL Server. I will be slowly removing support for PostgreSQL, please use pgdedupe for working with PostgreSQL**\n\nA work-in-progress to provide a standard interface for deduplication of large\ndatabases with custom pre-processing and post-processing steps.\n\n\n* Free software: MIT license\n* Documentation: https://pgdedupe.readthedocs.io.\n\n\nInterface\n---------\n\nThis provides a simple command-line program, ``ssdedupe``. Two configuration\nfiles specify the deduplication parameters and database connection settings. To\nrun deduplication on a generated dataset, create a ``database.yml`` file that\nspecifies the following parameters::\n\n\tuser:\n\tpassword:\n\tdatabase:\n\thost:\n\tport:\n\nTo connect to Microsoft SQL Server, an additional parameter ``type: mssql`` needs to added to ``database.yml`` file.\n\nYou can now create a sample CSV file with::\n\n\t$ python generate_fake_dataset.py --csv people.csv\n\tcreating people: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9500/9500 [00:21<00:00, 445.38it/s]\n\tadding twins: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:00<00:00, 1854.72it/s]\n\twriting csv:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b             | 4666/10000 [00:42<00:55, 96.28it/s]\n\nOnce complete, store this example dataset in a database with::\n\n\t$ python test/initialize_db.py --db database.yml --csv people.csv\n\tCREATE SCHEMA\n\tDROP TABLE\n\tCREATE TABLE\n\tCOPY 197617\n\tALTER TABLE\n\tALTER TABLE\n\tUPDATE 197617\n\nNow you can deduplicate this dataset. This will run dedupe as well as the\ncustom pre-processing and post-processing steps as defined in config.yml::\n\n\t$ ssdedupe --config config.yml --db database.yml\n\n\nCustom pre- and post-processing\n-------------------------------\n\nIn addition to running a database-level deduplication with ``dedupe``, this\nscript adds custom pre- and post-processing steps to improve the run-time and\nresults, making this a hybrid between fuzzy matching and record linkage.\n\n* **Pre-processing:** Before running dedupe, this script does an exact-match\n  deduplication. Some systems create many identical rows; this can make it\n  challenging for dedupe to create an effective blocking strategy and generally\n  makes the fuzzy matching much harder and time intensive.\n\n* **Post-processing:** After running dedupe, this script does an optional\n  exact-match merge across subsets of columns. For example, in some instances\n  an exact match of just the last name and social security number are\n  sufficient evidence that two clusters are indeed the same identity.\n\n\nFurther steps\n-------------\n\nThis script was based upon and extended from the example in `dedupe-examples`_. It would be nice to use this common interface across all\ndatabase types, and potentially even allow reading from flat CSV files.\n\n.. _dedupe-examples: https://github.com/datamade/dedupe-examples/tree/master/pgsql_big_dedupe_example\n\n\n=======\nHistory\n=======\n\n0.2.1 (2017-05-03)\n------------------\n\n* Make command line arguments required, resulting in better error messages.\n* Refactored testing scripts to be more user-friendly.\n\n\n0.2.0 (2017-04-19)\n------------------\n\n* First release on PyPI (as pgdedupe).\n\n\n0.1.0 (2016-12-14)\n------------------\n\n* First release on PyPI (as superdeduper).\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/melvin15may/ssdedupe", "keywords": "ssdedupe", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "ssdedupe", "package_url": "https://pypi.org/project/ssdedupe/", "platform": "", "project_url": "https://pypi.org/project/ssdedupe/", "project_urls": {"Homepage": "https://github.com/melvin15may/ssdedupe"}, "release_url": "https://pypi.org/project/ssdedupe/0.0.3/", "requires_dist": null, "requires_python": "", "summary": "A simple interface to datamade/dedupe to make probabilistic record linkage easy.", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"ssdedupe\">\n<h2>ssdedupe</h2>\n<a href=\"https://pypi.python.org/pypi/ssdedupe\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/ssdedupe.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4ff985d41167beb1d22f4e6bcc06bb85c4e31324/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f73736465647570652e737667\"></a>\n<a href=\"https://travis-ci.org/melvin15may/ssdedupe\" rel=\"nofollow\"><img alt=\"https://img.shields.io/travis/melvin15may/ssdedupe.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0a4f84ea96e200f37a61bfc4bbe717b09ee2fb7f/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6d656c76696e31356d61792f73736465647570652e737667\"></a>\n<a href=\"https://codecov.io/gh/melvin15may/ssdedupe\" rel=\"nofollow\"><img alt=\"https://codecov.io/gh/melvin15may/ssdedupe/branch/master/graph/badge.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bda06ed849091f3f805fa47cfda7f7f258b47cff/68747470733a2f2f636f6465636f762e696f2f67682f6d656c76696e31356d61792f73736465647570652f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://pgdedupe.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a5355f7bae5621679c9cd269e5448a0f8ee6cfda/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f70676465647570652f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://pyup.io/account/repos/github/melvin15may/ssdedupe/\" rel=\"nofollow\"><img alt=\"Updates\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4f07c840f33a6c761b1cbfe10b55d7c782949652/68747470733a2f2f707975702e696f2f7265706f732f6769746875622f6d656c76696e31356d61792f73736465647570652f736869656c642e737667\"></a>\n<p><strong>This is a fork from</strong> <a href=\"http://github.com/dssg/pgdedupe\" rel=\"nofollow\">dssg/pgdedupe</a>. <strong>This will now be a separate repo for MS SQL Server implementation.</strong> (See <a href=\"https://github.com/dssg/pgdedupe/pull/40\" rel=\"nofollow\">PR#40</a>)</p>\n<p><strong>This packages is for working with Microsoft SQL Server. I will be slowly removing support for PostgreSQL, please use pgdedupe for working with PostgreSQL</strong></p>\n<p>A work-in-progress to provide a standard interface for deduplication of large\ndatabases with custom pre-processing and post-processing steps.</p>\n<ul>\n<li>Free software: MIT license</li>\n<li>Documentation: <a href=\"https://pgdedupe.readthedocs.io\" rel=\"nofollow\">https://pgdedupe.readthedocs.io</a>.</li>\n</ul>\n<div id=\"interface\">\n<h3>Interface</h3>\n<p>This provides a simple command-line program, <tt>ssdedupe</tt>. Two configuration\nfiles specify the deduplication parameters and database connection settings. To\nrun deduplication on a generated dataset, create a <tt>database.yml</tt> file that\nspecifies the following parameters:</p>\n<pre>user:\npassword:\ndatabase:\nhost:\nport:\n</pre>\n<p>To connect to Microsoft SQL Server, an additional parameter <tt>type: mssql</tt> needs to added to <tt>database.yml</tt> file.</p>\n<p>You can now create a sample CSV file with:</p>\n<pre>$ python generate_fake_dataset.py --csv people.csv\ncreating people: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9500/9500 [00:21&lt;00:00, 445.38it/s]\nadding twins: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:00&lt;00:00, 1854.72it/s]\nwriting csv:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b             | 4666/10000 [00:42&lt;00:55, 96.28it/s]\n</pre>\n<p>Once complete, store this example dataset in a database with:</p>\n<pre>$ python test/initialize_db.py --db database.yml --csv people.csv\nCREATE SCHEMA\nDROP TABLE\nCREATE TABLE\nCOPY 197617\nALTER TABLE\nALTER TABLE\nUPDATE 197617\n</pre>\n<p>Now you can deduplicate this dataset. This will run dedupe as well as the\ncustom pre-processing and post-processing steps as defined in config.yml:</p>\n<pre>$ ssdedupe --config config.yml --db database.yml\n</pre>\n</div>\n<div id=\"custom-pre-and-post-processing\">\n<h3>Custom pre- and post-processing</h3>\n<p>In addition to running a database-level deduplication with <tt>dedupe</tt>, this\nscript adds custom pre- and post-processing steps to improve the run-time and\nresults, making this a hybrid between fuzzy matching and record linkage.</p>\n<ul>\n<li><strong>Pre-processing:</strong> Before running dedupe, this script does an exact-match\ndeduplication. Some systems create many identical rows; this can make it\nchallenging for dedupe to create an effective blocking strategy and generally\nmakes the fuzzy matching much harder and time intensive.</li>\n<li><strong>Post-processing:</strong> After running dedupe, this script does an optional\nexact-match merge across subsets of columns. For example, in some instances\nan exact match of just the last name and social security number are\nsufficient evidence that two clusters are indeed the same identity.</li>\n</ul>\n</div>\n<div id=\"further-steps\">\n<h3>Further steps</h3>\n<p>This script was based upon and extended from the example in <a href=\"https://github.com/datamade/dedupe-examples/tree/master/pgsql_big_dedupe_example\" rel=\"nofollow\">dedupe-examples</a>. It would be nice to use this common interface across all\ndatabase types, and potentially even allow reading from flat CSV files.</p>\n</div>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<div id=\"id1\">\n<h3>0.2.1 (2017-05-03)</h3>\n<ul>\n<li>Make command line arguments required, resulting in better error messages.</li>\n<li>Refactored testing scripts to be more user-friendly.</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h3>0.2.0 (2017-04-19)</h3>\n<ul>\n<li>First release on PyPI (as pgdedupe).</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h3>0.1.0 (2016-12-14)</h3>\n<ul>\n<li>First release on PyPI (as superdeduper).</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 3109194, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "e186f2a2ea0c695256b4f503946e192c", "sha256": "f9c9e745db7920913da802bd02bc8ff02df4d066b32584a8c159df7495825514"}, "downloads": -1, "filename": "ssdedupe-0.0.2.tar.gz", "has_sig": false, "md5_digest": "e186f2a2ea0c695256b4f503946e192c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 301616, "upload_time": "2017-08-20T03:19:22", "upload_time_iso_8601": "2017-08-20T03:19:22.064696Z", "url": "https://files.pythonhosted.org/packages/9e/82/6c320d2a88b34d81684802c9d3ca25d3c6b8771b873601d852b437429a8b/ssdedupe-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "528379965bbed3252bd37714e0115d33", "sha256": "67aca30da8848634095f7c66dcf4dd0a97ffb05ee7bff5ae1c8bf836886d878b"}, "downloads": -1, "filename": "ssdedupe-0.0.3.tar.gz", "has_sig": false, "md5_digest": "528379965bbed3252bd37714e0115d33", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 301652, "upload_time": "2017-08-20T04:37:23", "upload_time_iso_8601": "2017-08-20T04:37:23.205546Z", "url": "https://files.pythonhosted.org/packages/c4/7a/b5f798bddbb276dfc732e44b7ff45913c2982a531348fe523e9404236994/ssdedupe-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "528379965bbed3252bd37714e0115d33", "sha256": "67aca30da8848634095f7c66dcf4dd0a97ffb05ee7bff5ae1c8bf836886d878b"}, "downloads": -1, "filename": "ssdedupe-0.0.3.tar.gz", "has_sig": false, "md5_digest": "528379965bbed3252bd37714e0115d33", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 301652, "upload_time": "2017-08-20T04:37:23", "upload_time_iso_8601": "2017-08-20T04:37:23.205546Z", "url": "https://files.pythonhosted.org/packages/c4/7a/b5f798bddbb276dfc732e44b7ff45913c2982a531348fe523e9404236994/ssdedupe-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:03:13 2020"}