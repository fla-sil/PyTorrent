{"info": {"author": "Johnnie Gray", "author_email": "johnniemcgray@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "\nA lightweight python AUTOmatic-arRAY library. Write numeric code that works for:\n\n* `numpy <https://github.com/numpy/numpy>`_\n* `cupy <https://github.com/cupy/cupy>`_\n* `dask <https://github.com/dask/dask>`_\n* `autograd <https://github.com/HIPS/autograd>`_\n* `jax <https://github.com/google/jax>`_\n* `mars <https://github.com/mars-project/mars>`_\n* `tensorflow <https://github.com/tensorflow/tensorflow>`_\n* `pytorch <https://pytorch.org/>`_\n* ... and indeed **any** library that provides a numpy-*ish* api.\n\n.. image:: https://travis-ci.org/jcmgray/autoray.svg?branch=master\n  :target: https://travis-ci.org/jcmgray/autoray\n  :alt: Travis-CI\n.. image:: https://codecov.io/gh/jcmgray/autoray/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/jcmgray/autoray\n  :alt: Code Coverage\n.. image:: https://img.shields.io/lgtm/grade/python/g/jcmgray/autoray.svg\n  :target: https://lgtm.com/projects/g/jcmgray/autoray/\n  :alt: Code Quality\n\nAs an example consider this function that orthogonalizes a matrix using the modified Gram-Schmidt algorithm:\n\n.. code:: python3\n\n    from autoray import do\n\n    def modified_gram_schmidt(X):\n\n        Q = []\n        for j in range(0, X.shape[0]):\n\n            q = X[j, :]\n            for i in range(0, j):\n                rij = do('tensordot', do('conj', Q[i]), q, 1)\n                q = q - rij * Q[i]\n\n            rjj = do('linalg.norm', q, 2)\n            Q.append(q / rjj)\n\n        return do('stack', Q, axis=0, like=X)\n\nWhich is now compatible with **all** of the above mentioned libraries! (N.B. this particular example is also probably slow). If you don't like the explicit ``do`` syntax, then you can import the fake ``numpy`` object as a **drop-in replacement** instead:\n\n.. code:: python3\n\n    from autoray import numpy as np\n\n    x = np.random.uniform(size=(2, 3, 4), like='tensorflow')\n    np.tensordot(x, x, [(2, 1), (2, 1)])\n    # <tf.Tensor 'Tensordot:0' shape=(2, 2) dtype=float32>\n\n    np.eye(3, like=x)  # many functions obviously can't dispatch without the `like` keyword\n    # <tf.Tensor 'eye/MatrixDiag:0' shape=(3, 3) dtype=float32>\n\nOf course complete compatibility is not going to be possible for all functions, operations and libraries, but ``autoray`` hopefully makes the job much easier. Of the above, ``tensorflow`` has *quite* a different interface and ``pytorch`` probably the *most* different. Whilst for example not every function will work out-of-the-box for these two, ``autoray`` is also designed with the easy addition of new functions in mind (for example adding new translations is often a one-liner).\n\n**How does it work?**\n\n``autoray`` works using essentially a single dispatch mechanism on the first  argument for ``do``, or the ``like`` keyword argument if specified, fetching functions from the whichever module defined that supplied array. Additionally, it caches a few custom translations and lookups so as to handle libraries like ``tensorflow`` that don't exactly replicate the ``numpy`` api (for example ``sum`` gets translated to ``tensorflow.reduce_sum``).\n\nSpecial Functions\n-----------------\n\nThe main function is ``do``, but the following special (i.e. not in ``numpy``) functions are also implemented that may be useful:\n\n* ``autoray.infer_backend`` - check what library is being inferred for a given array\n* ``autoray.to_backend_dtype`` - convert a string specified dtype like ``'float32'`` to ``torch.float32`` for example\n* ``autoray.get_dtype_name`` - convert a backend dtype back into the equivalent string specifier like ``'complex64'``\n* ``autoray.astype`` - backend agnostic dtype conversion of arrays\n* ``autoray.to_numpy`` - convert any array to a ``numpy.ndarray``\n\nHere are all of those in action:\n\n.. code:: python3\n\n    import autoray as ar\n\n    backend = 'torch'\n    dtype = ar.to_backend_dtype('float64', like=backend)\n    dtype\n    # torch.float64\n\n    x = ar.do('random.normal', size=(4,), dtype=dtype, like=backend)\n    x\n    # tensor([ 0.0461,  0.3028,  0.1790, -0.1494], dtype=torch.float64)\n\n    ar.infer_backend(x)\n    # 'torch'\n\n    ar.get_dtype_name(x)\n    # 'float64'\n\n    x32 = ar.astype(x, 'float32')\n    ar.to_numpy(x32)\n    # array([ 0.04605161,  0.30280888,  0.17903718, -0.14936243], dtype=float32)\n\nRegistering Your Own functions\n------------------------------\n\nIf you want to directly provide a missing or alternative implementation of some function for a particular backend you can do so with ``autoray.register_function``:\n\n.. code:: python3\n\n    def my_custom_torch_svd(x):\n        import torch\n\n        print('Hello SVD!')\n        u, s, v = torch.svd(x)\n\n        return u, s, v.T\n\n    ar.register_function('torch', 'linalg.svd', my_custom_torch_svd)\n\n    x = ar.do('random.uniform', size=(3, 4), like='torch')\n\n    ar.do('linalg.svd', x)\n    # Hello SVD!\n    # (tensor([[-0.5832,  0.6188, -0.5262],\n    #          [-0.5787, -0.7711, -0.2655],\n    #          [-0.5701,  0.1497,  0.8078]]),\n    #  tensor([2.0336, 0.8518, 0.4572]),\n    #  tensor([[-0.4568, -0.3166, -0.6835, -0.4732],\n    #          [-0.5477,  0.2825, -0.2756,  0.7377],\n    #          [ 0.2468, -0.8423, -0.0993,  0.4687]]))\n\nIf you want to make use of the existing function you can supply ``wrap=True`` in which case the custom function supplied should act like a decorator:\n\n.. code:: python3\n\n    def my_custom_sum_wrapper(old_fn):\n\n        def new_fn(*args, **kwargs):\n            print('Hello sum!')\n            return old_fn(*args **kwargs)\n\n        return new_fn\n\n    ar.register_function('torch', 'sum', my_custom_sum_wrapper, wrap=True)\n\n    ar.do('sum', x)\n    # Hello sum!\n    # tensor(5.4099)\n\nThough be careful, if you call ``register_function`` again it will now wrap the *new* function!\n\nDeviations from `numpy`\n=======================\n\n`autoray` doesn't have an API as such, since it is essentially just a fancy single dispatch mechanism.\nOn the other hand, where translations *are* in place, they generally use the numpy API. So\n``autoray.do('stack', arrays=pytorch_tensors, axis=0)``\ngets automatically translated into\n``torch.stack(tensors=pytorch_tensors, dims=0)``\nand so forth.\n\nCurrently the one place this isn't true is ``autoray.do('linalg.svd', x)`` where instead ``full_matrices=False``\nis used as the default since this generally makes more sense and many libraries don't even implement the other case.\nAutoray also dispatches ``'linalg.expm'`` for ``numpy`` arrays to ``scipy``, and may well do with other scipy-only functions at some point.\n\nInstallation\n------------\n\nYou can install ``autoray`` via `conda-forge <https://conda-forge.org/>`_ as well as with ``pip``. Alternatively, simply copy the monolithic ``autoray.py`` into your project internally (if dependencies aren't your thing).\n\n**Alternatives**\n\n* The ``__array_function__`` protocol has been `suggested <https://www.numpy.org/neps/nep-0018-array-function-protocol.html>`_ and now implemented in ``numpy``. Hopefully this will eventually negate the need for ``autoray``. On the other hand, third party libraries themselves need to implement the interface, which has not been done, for example, in ``tensorflow`` yet.\n* The `uarray <https://github.com/Quansight-Labs/uarray>`_ project aims to develop a generic array interface but comes with the warning *\"This is experimental and very early research code. Don't use this.\"*.\n\nContributing\n------------\n\nPull requests such as extra translations are very welcome!\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/jcmgray/autoray", "keywords": "array agnostic numeric numpy cupy dask tensorflow jax autograd", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "autoray", "package_url": "https://pypi.org/project/autoray/", "platform": "", "project_url": "https://pypi.org/project/autoray/", "project_urls": {"Homepage": "http://github.com/jcmgray/autoray"}, "release_url": "https://pypi.org/project/autoray/0.2.2/", "requires_dist": ["numpy", "coverage ; extra == 'tests'", "pytest ; extra == 'tests'", "pytest-cov ; extra == 'tests'"], "requires_python": ">=3.5", "summary": "Write backend agnostic numeric code compatible with any numpy-ish array library.", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A lightweight python AUTOmatic-arRAY library. Write numeric code that works for:</p>\n<ul>\n<li><a href=\"https://github.com/numpy/numpy\" rel=\"nofollow\">numpy</a></li>\n<li><a href=\"https://github.com/cupy/cupy\" rel=\"nofollow\">cupy</a></li>\n<li><a href=\"https://github.com/dask/dask\" rel=\"nofollow\">dask</a></li>\n<li><a href=\"https://github.com/HIPS/autograd\" rel=\"nofollow\">autograd</a></li>\n<li><a href=\"https://github.com/google/jax\" rel=\"nofollow\">jax</a></li>\n<li><a href=\"https://github.com/mars-project/mars\" rel=\"nofollow\">mars</a></li>\n<li><a href=\"https://github.com/tensorflow/tensorflow\" rel=\"nofollow\">tensorflow</a></li>\n<li><a href=\"https://pytorch.org/\" rel=\"nofollow\">pytorch</a></li>\n<li>\u2026 and indeed <strong>any</strong> library that provides a numpy-<em>ish</em> api.</li>\n</ul>\n<a href=\"https://travis-ci.org/jcmgray/autoray\" rel=\"nofollow\"><img alt=\"Travis-CI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1fd61e8ccab2fb034eff3c9f7be5aa67992f0707/68747470733a2f2f7472617669732d63692e6f72672f6a636d677261792f6175746f7261792e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/jcmgray/autoray\" rel=\"nofollow\"><img alt=\"Code Coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/36bcc0aee50ca1c95e804f6204152cd33a7274c5/68747470733a2f2f636f6465636f762e696f2f67682f6a636d677261792f6175746f7261792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://lgtm.com/projects/g/jcmgray/autoray/\" rel=\"nofollow\"><img alt=\"Code Quality\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/031fd61afeb405259373f7cfcbdb9e5b8e96ec1e/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f6a636d677261792f6175746f7261792e737667\"></a>\n<p>As an example consider this function that orthogonalizes a matrix using the modified Gram-Schmidt algorithm:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">autoray</span> <span class=\"kn\">import</span> <span class=\"n\">do</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">modified_gram_schmidt</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">):</span>\n\n    <span class=\"n\">Q</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n    <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]):</span>\n\n        <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">):</span>\n            <span class=\"n\">rij</span> <span class=\"o\">=</span> <span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'tensordot'</span><span class=\"p\">,</span> <span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'conj'</span><span class=\"p\">,</span> <span class=\"n\">Q</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]),</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n            <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">q</span> <span class=\"o\">-</span> <span class=\"n\">rij</span> <span class=\"o\">*</span> <span class=\"n\">Q</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>\n\n        <span class=\"n\">rjj</span> <span class=\"o\">=</span> <span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'linalg.norm'</span><span class=\"p\">,</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"n\">Q</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">q</span> <span class=\"o\">/</span> <span class=\"n\">rjj</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'stack'</span><span class=\"p\">,</span> <span class=\"n\">Q</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">like</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"p\">)</span>\n</pre>\n<p>Which is now compatible with <strong>all</strong> of the above mentioned libraries! (N.B. this particular example is also probably slow). If you don\u2019t like the explicit <tt>do</tt> syntax, then you can import the fake <tt>numpy</tt> object as a <strong>drop-in replacement</strong> instead:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">autoray</span> <span class=\"kn\">import</span> <span class=\"n\">numpy</span> <span class=\"k\">as</span> <span class=\"n\">np</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"n\">like</span><span class=\"o\">=</span><span class=\"s1\">'tensorflow'</span><span class=\"p\">)</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">tensordot</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">[(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)])</span>\n<span class=\"c1\"># &lt;tf.Tensor 'Tensordot:0' shape=(2, 2) dtype=float32&gt;</span>\n\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">eye</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">like</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># many functions obviously can't dispatch without the `like` keyword</span>\n<span class=\"c1\"># &lt;tf.Tensor 'eye/MatrixDiag:0' shape=(3, 3) dtype=float32&gt;</span>\n</pre>\n<p>Of course complete compatibility is not going to be possible for all functions, operations and libraries, but <tt>autoray</tt> hopefully makes the job much easier. Of the above, <tt>tensorflow</tt> has <em>quite</em> a different interface and <tt>pytorch</tt> probably the <em>most</em> different. Whilst for example not every function will work out-of-the-box for these two, <tt>autoray</tt> is also designed with the easy addition of new functions in mind (for example adding new translations is often a one-liner).</p>\n<p><strong>How does it work?</strong></p>\n<p><tt>autoray</tt> works using essentially a single dispatch mechanism on the first  argument for <tt>do</tt>, or the <tt>like</tt> keyword argument if specified, fetching functions from the whichever module defined that supplied array. Additionally, it caches a few custom translations and lookups so as to handle libraries like <tt>tensorflow</tt> that don\u2019t exactly replicate the <tt>numpy</tt> api (for example <tt>sum</tt> gets translated to <tt>tensorflow.reduce_sum</tt>).</p>\n<div id=\"special-functions\">\n<h2>Special Functions</h2>\n<p>The main function is <tt>do</tt>, but the following special (i.e. not in <tt>numpy</tt>) functions are also implemented that may be useful:</p>\n<ul>\n<li><tt>autoray.infer_backend</tt> - check what library is being inferred for a given array</li>\n<li><tt>autoray.to_backend_dtype</tt> - convert a string specified dtype like <tt>'float32'</tt> to <tt>torch.float32</tt> for example</li>\n<li><tt>autoray.get_dtype_name</tt> - convert a backend dtype back into the equivalent string specifier like <tt>'complex64'</tt></li>\n<li><tt>autoray.astype</tt> - backend agnostic dtype conversion of arrays</li>\n<li><tt>autoray.to_numpy</tt> - convert any array to a <tt>numpy.ndarray</tt></li>\n</ul>\n<p>Here are all of those in action:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">autoray</span> <span class=\"k\">as</span> <span class=\"nn\">ar</span>\n\n<span class=\"n\">backend</span> <span class=\"o\">=</span> <span class=\"s1\">'torch'</span>\n<span class=\"n\">dtype</span> <span class=\"o\">=</span> <span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">to_backend_dtype</span><span class=\"p\">(</span><span class=\"s1\">'float64'</span><span class=\"p\">,</span> <span class=\"n\">like</span><span class=\"o\">=</span><span class=\"n\">backend</span><span class=\"p\">)</span>\n<span class=\"n\">dtype</span>\n<span class=\"c1\"># torch.float64</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'random.normal'</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">like</span><span class=\"o\">=</span><span class=\"n\">backend</span><span class=\"p\">)</span>\n<span class=\"n\">x</span>\n<span class=\"c1\"># tensor([ 0.0461,  0.3028,  0.1790, -0.1494], dtype=torch.float64)</span>\n\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">infer_backend</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"c1\"># 'torch'</span>\n\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">get_dtype_name</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"c1\"># 'float64'</span>\n\n<span class=\"n\">x32</span> <span class=\"o\">=</span> <span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"s1\">'float32'</span><span class=\"p\">)</span>\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">to_numpy</span><span class=\"p\">(</span><span class=\"n\">x32</span><span class=\"p\">)</span>\n<span class=\"c1\"># array([ 0.04605161,  0.30280888,  0.17903718, -0.14936243], dtype=float32)</span>\n</pre>\n</div>\n<div id=\"registering-your-own-functions\">\n<h2>Registering Your Own functions</h2>\n<p>If you want to directly provide a missing or alternative implementation of some function for a particular backend you can do so with <tt>autoray.register_function</tt>:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">my_custom_torch_svd</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Hello SVD!'</span><span class=\"p\">)</span>\n    <span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">svd</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">u</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">T</span>\n\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">register_function</span><span class=\"p\">(</span><span class=\"s1\">'torch'</span><span class=\"p\">,</span> <span class=\"s1\">'linalg.svd'</span><span class=\"p\">,</span> <span class=\"n\">my_custom_torch_svd</span><span class=\"p\">)</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'random.uniform'</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"n\">like</span><span class=\"o\">=</span><span class=\"s1\">'torch'</span><span class=\"p\">)</span>\n\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'linalg.svd'</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"c1\"># Hello SVD!</span>\n<span class=\"c1\"># (tensor([[-0.5832,  0.6188, -0.5262],</span>\n<span class=\"c1\">#          [-0.5787, -0.7711, -0.2655],</span>\n<span class=\"c1\">#          [-0.5701,  0.1497,  0.8078]]),</span>\n<span class=\"c1\">#  tensor([2.0336, 0.8518, 0.4572]),</span>\n<span class=\"c1\">#  tensor([[-0.4568, -0.3166, -0.6835, -0.4732],</span>\n<span class=\"c1\">#          [-0.5477,  0.2825, -0.2756,  0.7377],</span>\n<span class=\"c1\">#          [ 0.2468, -0.8423, -0.0993,  0.4687]]))</span>\n</pre>\n<p>If you want to make use of the existing function you can supply <tt>wrap=True</tt> in which case the custom function supplied should act like a decorator:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">my_custom_sum_wrapper</span><span class=\"p\">(</span><span class=\"n\">old_fn</span><span class=\"p\">):</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">new_fn</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Hello sum!'</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">old_fn</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">args</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">new_fn</span>\n\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">register_function</span><span class=\"p\">(</span><span class=\"s1\">'torch'</span><span class=\"p\">,</span> <span class=\"s1\">'sum'</span><span class=\"p\">,</span> <span class=\"n\">my_custom_sum_wrapper</span><span class=\"p\">,</span> <span class=\"n\">wrap</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">ar</span><span class=\"o\">.</span><span class=\"n\">do</span><span class=\"p\">(</span><span class=\"s1\">'sum'</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"c1\"># Hello sum!</span>\n<span class=\"c1\"># tensor(5.4099)</span>\n</pre>\n<p>Though be careful, if you call <tt>register_function</tt> again it will now wrap the <em>new</em> function!</p>\n<div id=\"deviations-from-numpy\">\n<h3>Deviations from <cite>numpy</cite></h3>\n<p><cite>autoray</cite> doesn\u2019t have an API as such, since it is essentially just a fancy single dispatch mechanism.\nOn the other hand, where translations <em>are</em> in place, they generally use the numpy API. So\n<tt><span class=\"pre\">autoray.do('stack',</span> arrays=pytorch_tensors, axis=0)</tt>\ngets automatically translated into\n<tt>torch.stack(tensors=pytorch_tensors, dims=0)</tt>\nand so forth.</p>\n<p>Currently the one place this isn\u2019t true is <tt><span class=\"pre\">autoray.do('linalg.svd',</span> x)</tt> where instead <tt>full_matrices=False</tt>\nis used as the default since this generally makes more sense and many libraries don\u2019t even implement the other case.\nAutoray also dispatches <tt>'linalg.expm'</tt> for <tt>numpy</tt> arrays to <tt>scipy</tt>, and may well do with other scipy-only functions at some point.</p>\n</div>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>You can install <tt>autoray</tt> via <a href=\"https://conda-forge.org/\" rel=\"nofollow\">conda-forge</a> as well as with <tt>pip</tt>. Alternatively, simply copy the monolithic <tt>autoray.py</tt> into your project internally (if dependencies aren\u2019t your thing).</p>\n<p><strong>Alternatives</strong></p>\n<ul>\n<li>The <tt>__array_function__</tt> protocol has been <a href=\"https://www.numpy.org/neps/nep-0018-array-function-protocol.html\" rel=\"nofollow\">suggested</a> and now implemented in <tt>numpy</tt>. Hopefully this will eventually negate the need for <tt>autoray</tt>. On the other hand, third party libraries themselves need to implement the interface, which has not been done, for example, in <tt>tensorflow</tt> yet.</li>\n<li>The <a href=\"https://github.com/Quansight-Labs/uarray\" rel=\"nofollow\">uarray</a> project aims to develop a generic array interface but comes with the warning <em>\u201cThis is experimental and very early research code. Don\u2019t use this.\u201d</em>.</li>\n</ul>\n</div>\n<div id=\"contributing\">\n<h2>Contributing</h2>\n<p>Pull requests such as extra translations are very welcome!</p>\n</div>\n\n          </div>"}, "last_serial": 7020601, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "45b7024601ea3d0357e85ddfb582a957", "sha256": "7fd4cf0a4280a39dcc5df310612d3f946a451f495e9356590eb4dfcfaa89ca68"}, "downloads": -1, "filename": "autoray-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "45b7024601ea3d0357e85ddfb582a957", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10655, "upload_time": "2019-04-04T14:44:51", "upload_time_iso_8601": "2019-04-04T14:44:51.300483Z", "url": "https://files.pythonhosted.org/packages/ab/0f/f38840fc7f1b945a864ec5b4a12b9888151ee8971bc15b50ba2c08395c85/autoray-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "236950930bcb8444df84f11b4b514b3b", "sha256": "0f364715e2802b0bc0c17f0c873d167c2549ac0adbde545aa1ece493a1b87bc0"}, "downloads": -1, "filename": "autoray-0.1.0.tar.gz", "has_sig": false, "md5_digest": "236950930bcb8444df84f11b4b514b3b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 25928, "upload_time": "2019-04-04T14:44:53", "upload_time_iso_8601": "2019-04-04T14:44:53.732013Z", "url": "https://files.pythonhosted.org/packages/b3/ab/37fe12c451d0261a9083ae1869417d468eee1825fcb5ded0b162e6ca397d/autoray-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "cb99680fdf5fe9c519457f218b1dc4b1", "sha256": "e31e36f8f7870f56278bae9114086cf0e51a591f6c210bc77fe02f9ad757ab04"}, "downloads": -1, "filename": "autoray-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "cb99680fdf5fe9c519457f218b1dc4b1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 12073, "upload_time": "2019-10-23T11:59:39", "upload_time_iso_8601": "2019-10-23T11:59:39.479233Z", "url": "https://files.pythonhosted.org/packages/f0/3b/03b5e645f8cd8d041c301ebb93551df644604b60d4451f178eb4df243587/autoray-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "40660fb6ec91872cc8fa4ce491766cee", "sha256": "d5e0c061482839d8b024e30c549b0736ec262d4244aab66b36279b2d136dbed2"}, "downloads": -1, "filename": "autoray-0.1.1.tar.gz", "has_sig": false, "md5_digest": "40660fb6ec91872cc8fa4ce491766cee", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 27002, "upload_time": "2019-10-23T11:59:41", "upload_time_iso_8601": "2019-10-23T11:59:41.383372Z", "url": "https://files.pythonhosted.org/packages/14/0e/a5117ce3908e573803e41282ffb70a1c96ed19665e6871c6160d90ec8979/autoray-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "1e6677ed491f2d3ba7071a9e6d260cdd", "sha256": "87996ca01b72bc6b9f3e815c18e3c4128f973a4330bdeca868352ec5edad8dd9"}, "downloads": -1, "filename": "autoray-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1e6677ed491f2d3ba7071a9e6d260cdd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 13340, "upload_time": "2020-02-15T03:17:34", "upload_time_iso_8601": "2020-02-15T03:17:34.763933Z", "url": "https://files.pythonhosted.org/packages/64/aa/9b8e76d2150c6451a2db6c769571c79913829325bb0a39974d462800bb1b/autoray-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4f6e72988a052e375883dd06e6d08eb3", "sha256": "4ed18fb851358fcaa303dc2fe1dd9f624f2a7b72badfc545b005895d0392cfa8"}, "downloads": -1, "filename": "autoray-0.2.0.tar.gz", "has_sig": false, "md5_digest": "4f6e72988a052e375883dd06e6d08eb3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 28952, "upload_time": "2020-02-15T03:17:36", "upload_time_iso_8601": "2020-02-15T03:17:36.587711Z", "url": "https://files.pythonhosted.org/packages/96/59/9409f740c68412a5267abeb7ed42454f4ec84186a5818ade726276055ea0/autoray-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "7e6234d83464fac48ea77de01730c1d0", "sha256": "b9ceaa6e3ebf50e357b62cdb6b899657c28e721019757f63e6b83790489e0a10"}, "downloads": -1, "filename": "autoray-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "7e6234d83464fac48ea77de01730c1d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 14227, "upload_time": "2020-03-11T18:36:55", "upload_time_iso_8601": "2020-03-11T18:36:55.103043Z", "url": "https://files.pythonhosted.org/packages/d7/12/9bed8f8fca758dfcb36921120613459053d9e099b6aedad3cc0f2b5401de/autoray-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "92f73f092cf632db5d797699d41296e6", "sha256": "dc60095fbcc464e1d72ae7c4447438cff947e0cdb14626045b70abea8b58fe9e"}, "downloads": -1, "filename": "autoray-0.2.1.tar.gz", "has_sig": false, "md5_digest": "92f73f092cf632db5d797699d41296e6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 30607, "upload_time": "2020-03-11T18:36:56", "upload_time_iso_8601": "2020-03-11T18:36:56.305603Z", "url": "https://files.pythonhosted.org/packages/dd/91/d66c5426595f6d20429fa1e1871402cc9638376b244009f4ff09ab465c90/autoray-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "fa08547b22aefd320fe169d4a392e45e", "sha256": "b1dcad62088a8b3cbf7dc133028c1a25466b2a60f3c1ba3e7acf35f2cc239d68"}, "downloads": -1, "filename": "autoray-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "fa08547b22aefd320fe169d4a392e45e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 15128, "upload_time": "2020-04-14T22:11:33", "upload_time_iso_8601": "2020-04-14T22:11:33.216891Z", "url": "https://files.pythonhosted.org/packages/10/df/28b83097dae493bcee3f3b0629348be618738b0d4805d3986527245ff88e/autoray-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8dff849a677447a6234517c17fdc4d64", "sha256": "004e964b40309bf1a91b37b0a4e5ad5e014eb139eecf75830dde23c8379940fb"}, "downloads": -1, "filename": "autoray-0.2.2.tar.gz", "has_sig": false, "md5_digest": "8dff849a677447a6234517c17fdc4d64", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 33291, "upload_time": "2020-04-14T22:11:34", "upload_time_iso_8601": "2020-04-14T22:11:34.916869Z", "url": "https://files.pythonhosted.org/packages/4a/cf/5846296615734143bf6d2ddd75b7ae4b4cd697c36bcd031b07015bb06b5d/autoray-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fa08547b22aefd320fe169d4a392e45e", "sha256": "b1dcad62088a8b3cbf7dc133028c1a25466b2a60f3c1ba3e7acf35f2cc239d68"}, "downloads": -1, "filename": "autoray-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "fa08547b22aefd320fe169d4a392e45e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 15128, "upload_time": "2020-04-14T22:11:33", "upload_time_iso_8601": "2020-04-14T22:11:33.216891Z", "url": "https://files.pythonhosted.org/packages/10/df/28b83097dae493bcee3f3b0629348be618738b0d4805d3986527245ff88e/autoray-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8dff849a677447a6234517c17fdc4d64", "sha256": "004e964b40309bf1a91b37b0a4e5ad5e014eb139eecf75830dde23c8379940fb"}, "downloads": -1, "filename": "autoray-0.2.2.tar.gz", "has_sig": false, "md5_digest": "8dff849a677447a6234517c17fdc4d64", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 33291, "upload_time": "2020-04-14T22:11:34", "upload_time_iso_8601": "2020-04-14T22:11:34.916869Z", "url": "https://files.pythonhosted.org/packages/4a/cf/5846296615734143bf6d2ddd75b7ae4b4cd697c36bcd031b07015bb06b5d/autoray-0.2.2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:10 2020"}