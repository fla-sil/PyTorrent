{"info": {"author": "Rayyan Akhtar", "author_email": "akhtar.rayyan@live.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "#Project Description\n\n    Facial Emotion Recognition using PyTorch.\n\n    It creates a bounding box around the face of the person present in the picture and put a text\n    at the top of the bounding box representing the recognised emotion.\n\n#\n\n\n\n#Install\n\n    pip install emotion_recognition\n    \n    \n#\n\n# Requirements\n\npytorch >= 1.2.0\n\ntorchvision >= 0.3.0\n#\n\n#Usage:\n\n    from facial_emotion_recognition import EmotionRecognition\n    \n    import cv2 as cv\n    \n    er = EmotionRecognition(device='gpu', gpu_id=0)\n    \n    cam = cv.VideoCapture(0)\n    \n    success, frame = cam.read()\n    \n    frame = er.recognise_emotion(frame, return_type='BGR')\n    \n    cv.imshow('frame', frame)\n    \n    cv.waitkey(0)\n    \n#\n\n#Arguments\n\n    er = EmotionRecognition(device='gpu', gpu_id=0)\n    \n    device = 'gpu' or cpu'\n    \n    gpu_id will be effective only when more than two GPUs are detected or it will through error.\n    \n    frame = er.recognise_emotion(frame, return_type='BGR')\n    \n    return_type='BGR' or 'RGB'\n#\n\n#References\n\n1. \"Challenges in Representation Learning: A report on three machine learning\ncontests.\" I Goodfellow, D Erhan, PL Carrier, A Courville, M Mirza, B\nHamner, W Cukierski, Y Tang, DH Lee, Y Zhou, C Ramaiah, F Feng, R Li,\nX Wang, D Athanasakis, J Shawe-Taylor, M Milakov, J Park, R Ionescu,\nM Popescu, C Grozea, J Bergstra, J Xie, L Romaszko, B Xu, Z Chuang, and\nY. Bengio. arXiv 2013.\n\n#", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "facial-emotion-recognition", "package_url": "https://pypi.org/project/facial-emotion-recognition/", "platform": "", "project_url": "https://pypi.org/project/facial-emotion-recognition/", "project_urls": null, "release_url": "https://pypi.org/project/facial-emotion-recognition/0.3.3/", "requires_dist": null, "requires_python": "", "summary": "It recognize facial emotions from the image", "version": "0.3.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>#Project Description</p>\n<pre><code>Facial Emotion Recognition using PyTorch.\n\nIt creates a bounding box around the face of the person present in the picture and put a text\nat the top of the bounding box representing the recognised emotion.\n</code></pre>\n<h1></h1>\n<p>#Install</p>\n<pre><code>pip install emotion_recognition\n</code></pre>\n<h1></h1>\n<h1>Requirements</h1>\n<p>pytorch &gt;= 1.2.0</p>\n<p>torchvision &gt;= 0.3.0</p>\n<h1></h1>\n<p>#Usage:</p>\n<pre><code>from facial_emotion_recognition import EmotionRecognition\n\nimport cv2 as cv\n\ner = EmotionRecognition(device='gpu', gpu_id=0)\n\ncam = cv.VideoCapture(0)\n\nsuccess, frame = cam.read()\n\nframe = er.recognise_emotion(frame, return_type='BGR')\n\ncv.imshow('frame', frame)\n\ncv.waitkey(0)\n</code></pre>\n<h1></h1>\n<p>#Arguments</p>\n<pre><code>er = EmotionRecognition(device='gpu', gpu_id=0)\n\ndevice = 'gpu' or cpu'\n\ngpu_id will be effective only when more than two GPUs are detected or it will through error.\n\nframe = er.recognise_emotion(frame, return_type='BGR')\n\nreturn_type='BGR' or 'RGB'\n</code></pre>\n<h1></h1>\n<p>#References</p>\n<ol>\n<li>\"Challenges in Representation Learning: A report on three machine learning\ncontests.\" I Goodfellow, D Erhan, PL Carrier, A Courville, M Mirza, B\nHamner, W Cukierski, Y Tang, DH Lee, Y Zhou, C Ramaiah, F Feng, R Li,\nX Wang, D Athanasakis, J Shawe-Taylor, M Milakov, J Park, R Ionescu,\nM Popescu, C Grozea, J Bergstra, J Xie, L Romaszko, B Xu, Z Chuang, and\nY. Bengio. arXiv 2013.</li>\n</ol>\n<h1></h1>\n\n          </div>"}, "last_serial": 7155319, "releases": {"0.3.3": [{"comment_text": "", "digests": {"md5": "dfd973507d34d1496e6066b04a7515de", "sha256": "1678ce3d23c3c90639d59a93358d5783478dc91fa6311a4860b2ce59dff9447d"}, "downloads": -1, "filename": "facial_emotion_recognition-0.3.3.tar.gz", "has_sig": false, "md5_digest": "dfd973507d34d1496e6066b04a7515de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27119180, "upload_time": "2020-05-03T07:29:29", "upload_time_iso_8601": "2020-05-03T07:29:29.087777Z", "url": "https://files.pythonhosted.org/packages/f7/d1/c63d32b85599d6628f1cb1eba1d0f6ce7f9bcff332ebd0011df5ce7cc14f/facial_emotion_recognition-0.3.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dfd973507d34d1496e6066b04a7515de", "sha256": "1678ce3d23c3c90639d59a93358d5783478dc91fa6311a4860b2ce59dff9447d"}, "downloads": -1, "filename": "facial_emotion_recognition-0.3.3.tar.gz", "has_sig": false, "md5_digest": "dfd973507d34d1496e6066b04a7515de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27119180, "upload_time": "2020-05-03T07:29:29", "upload_time_iso_8601": "2020-05-03T07:29:29.087777Z", "url": "https://files.pythonhosted.org/packages/f7/d1/c63d32b85599d6628f1cb1eba1d0f6ce7f9bcff332ebd0011df5ce7cc14f/facial_emotion_recognition-0.3.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:05 2020"}