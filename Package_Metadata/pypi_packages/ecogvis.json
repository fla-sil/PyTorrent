{"info": {"author": "Luiz Tauffer and Ben Dichter", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# ecogVIS\nTimeseries visualizer and data processing tools for Electrocorticography (ECoG) signals stored in [NWB](https://neurodatawithoutborders.github.io/) files, for Python.\n\n[![codecov](https://codecov.io/gh/ben-dichter-consulting/ecogVIS/branch/master/graph/badge.svg)](https://codecov.io/gh/ben-dichter-consulting/ecogVIS)\n\n\nA collaboration with with [Chang Lab](http://changlab.ucsf.edu/).\n\n![](media/screenshot_1.png)\n\n## Installation\nTo clone the repository and set up a conda environment, do:\n```\n$ git clone https://github.com/ben-dichter-consulting/ecogVIS\n$ conda env create -f ecogVIS/make_env.yml\n$ source activate ecog_vis\n```\n\nAlternatively, to install **ecogVIS** directly in an existing environment:\n```\n$ pip install git+https://github.com/ben-dichter-consulting/ecogVIS\n```\n\nAfter activating the correct environment, **ecogVIS** can be imported and run from python. If the file does not exist (or if you provide an empty string ''), you'll be prompted to choose a file from a dialog.\n```python\nfrom ecogvis.ecogvis import main\nimport os\n\nfpath = os.path.join('path_to','file.nwb')\nmain(fpath)\n```\n\n\n## Features\n**ecogVIS** makes it intuitive and simple to viualize and process ECoG signals. It currently features:\n\n<details>\n  <summary> \n    <strong>Navigation</strong> \n  </summary>\n  Seamless visual navigation through long signals from large arrays of electrodes, by mouse-dragging visualization window, control buttons, value fields and keyboard keys. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_time_navigation.gif?raw=true)\n\n  ![](media/https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_channel_navigation.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Annotations</strong> \n  </summary>\n  Add, delete, save and load annotations for meaningful comments anywhere in the visualization. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_annotations.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Intervals</strong> \n  </summary>\n  Add, delete, save, load and create custom intervals types to mark specific points in time, with simple click-drag-release mouse movements. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_intervals.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Bad Channels</strong> \n  </summary>\n  Mark and un-mark bad channels. Choices are saved in the <em>electrodes</em> group of the current NWB file. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_badchannels.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Signal preprocessing</strong> \n  </summary>\n  Preprocessing of raw voltage signals, including user-defined Downsampling, CAR and Notch filtering. The resulting processed signals are stored as an <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.ecephys.html#pynwb.ecephys.LFP\">LFP</a> object, in the <em>processing</em> group of the current NWB file. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_preprocessing.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Events detection</strong> \n  </summary>\n  Automatic detection of events in audio recordings for Consonant-Vowel tasks. The audio data should be stored in the NWB file in the following way:\n  <ul>\n    <li>Speaker audio - As a <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries\">TimeSeries</a> object, named 'Speaker CV', in the <em>stimulus</em> group.</li>\n    <li>Microphone audio - As a <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries\">TimeSeries</a>  object, named 'Microphone CV', in the <em>acquisition</em> group.\n</li>\n  </ul> \n  The resulting detected intervals, 'TimeIntervals_mic' and 'TimeIntervals_speaker', are saved as <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.epoch.html#pynwb.epoch.TimeIntervals\">TimeIntervals</a> objects in the <em>intervals</em> group of the current NWB file and can be used later for ERP analysis. A preview allows for testing of the detection parameters before running it for the whole duration of the audio signals. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_event_detection.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>High Gamma</strong> \n  </summary>\n  Estimation of high gamma analytic amplitude, with the average of user-defined specific bands. The results are saved as a <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries\">TimeSeries</a> object, named 'high_gamma', in the <em>processing</em> group of the current or of a new NWB file. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_highgamma.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Event-Related Potentials</strong> \n  </summary>\n  Grid visualization of high gamma ERP calculated in reference to:\n  <ul>\n    <li>Stimulus (speaker) or response (microphone) time intervals</li>\n    <li>Onset or offset points</li>\n  </ul> \n  The grid items are coloured to mark specific cortical areas and can be rotated to correspond anatomically to them. Emphasis can be given to specific areas of interest and double-clicking an item allows for fast inspection of the single electrode's ERP in detail. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_erp.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Periodograms</strong> \n  </summary>\n  Grid visualization of Periodograms:\n  <ul>\n    <li>Raw and preprocessed data</li>\n    <li>FFT and Welch methods</li>\n    <li>Individual devices</li>\n  </ul> \n  The grid items are coloured to mark specific cortical areas and can be rotated to correspond anatomically to them. Emphasis can be given to specific areas of interest and double-clicking an item allows for fast inspection of the single electrode's Periodogram in detail. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_periodograms.gif?raw=true)\n</details>\n\n<details>\n  <summary> \n    <strong>Spectral Decomposition</strong> \n  </summary>\n  Analytic signal amplitude estimation by Hilbert transform of user-defined frequency bands. <br></br>\n  WARNING: This function will manipulate an array of size (nSamples, nChannels, nBands), which might be in the order of gigabytes and demand a large memory to operate and is likely to produce a large file. <br></br>\n\n  ![](https://github.com/catalystneuro/ecogVIS/blob/master/media/gif_decomposition.gif?raw=true)\n</details>\n\n### Plus\n- Select electrodes from specific brain areas\n- Easy moving between block files for the same subject\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "ecogvis", "package_url": "https://pypi.org/project/ecogvis/", "platform": "", "project_url": "https://pypi.org/project/ecogvis/", "project_urls": null, "release_url": "https://pypi.org/project/ecogvis/1.0.1/", "requires_dist": ["PyQt5", "matplotlib", "cycler", "scipy", "numpy", "h5py", "pyqtgraph", "pandas", "pynwb", "nwbext-ecog", "ndx-spectrum", "pyopengl", "process-nwb"], "requires_python": "", "summary": "Timeseries visualizer for Electrocorticography (ECoG) signals stored in NWB files.", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>ecogVIS</h1>\n<p>Timeseries visualizer and data processing tools for Electrocorticography (ECoG) signals stored in <a href=\"https://neurodatawithoutborders.github.io/\" rel=\"nofollow\">NWB</a> files, for Python.</p>\n<p><a href=\"https://codecov.io/gh/ben-dichter-consulting/ecogVIS\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e0578c81326031ae05c14b254e06051e724c98ea/68747470733a2f2f636f6465636f762e696f2f67682f62656e2d646963687465722d636f6e73756c74696e672f65636f675649532f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<p>A collaboration with with <a href=\"http://changlab.ucsf.edu/\" rel=\"nofollow\">Chang Lab</a>.</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/93680d36f15c9c310fdc40a529597ba6acad054d/6d656469612f73637265656e73686f745f312e706e67\"></p>\n<h2>Installation</h2>\n<p>To clone the repository and set up a conda environment, do:</p>\n<pre><code>$ git clone https://github.com/ben-dichter-consulting/ecogVIS\n$ conda env create -f ecogVIS/make_env.yml\n$ source activate ecog_vis\n</code></pre>\n<p>Alternatively, to install <strong>ecogVIS</strong> directly in an existing environment:</p>\n<pre><code>$ pip install git+https://github.com/ben-dichter-consulting/ecogVIS\n</code></pre>\n<p>After activating the correct environment, <strong>ecogVIS</strong> can be imported and run from python. If the file does not exist (or if you provide an empty string ''), you'll be prompted to choose a file from a dialog.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ecogvis.ecogvis</span> <span class=\"kn\">import</span> <span class=\"n\">main</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n<span class=\"n\">fpath</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"s1\">'path_to'</span><span class=\"p\">,</span><span class=\"s1\">'file.nwb'</span><span class=\"p\">)</span>\n<span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">fpath</span><span class=\"p\">)</span>\n</pre>\n<h2>Features</h2>\n<p><strong>ecogVIS</strong> makes it intuitive and simple to viualize and process ECoG signals. It currently features:</p>\n<details>\n  <summary> \n    <strong>Navigation</strong> \n  </summary>\n  Seamless visual navigation through long signals from large arrays of electrodes, by mouse-dragging visualization window, control buttons, value fields and keyboard keys. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/44df8a85cae1bb461bae98039aab8b89e9945d10/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f74696d655f6e617669676174696f6e2e6769663f7261773d74727565\"></p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/99aa254d4cab4c518b03ce1e3b6bc9ca3096a4db/6d656469612f68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f6368616e6e656c5f6e617669676174696f6e2e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Annotations</strong> \n  </summary>\n  Add, delete, save and load annotations for meaningful comments anywhere in the visualization. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/423c16d71f6728dd128b61844d0accc7b0dd7a57/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f616e6e6f746174696f6e732e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Intervals</strong> \n  </summary>\n  Add, delete, save, load and create custom intervals types to mark specific points in time, with simple click-drag-release mouse movements. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f80fcb79d86b03062188f1ce6340dc3df32cc9a4/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f696e74657276616c732e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Bad Channels</strong> \n  </summary>\n  Mark and un-mark bad channels. Choices are saved in the <em>electrodes</em> group of the current NWB file. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/763e206b1bb898037a91d9275e557c07afe98d88/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f6261646368616e6e656c732e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Signal preprocessing</strong> \n  </summary>\n  Preprocessing of raw voltage signals, including user-defined Downsampling, CAR and Notch filtering. The resulting processed signals are stored as an <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.ecephys.html#pynwb.ecephys.LFP\" rel=\"nofollow\">LFP</a> object, in the <em>processing</em> group of the current NWB file. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3324e59b5e62e265f2377f41d30474269a06f9eb/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f70726570726f63657373696e672e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Events detection</strong> \n  </summary>\n  Automatic detection of events in audio recordings for Consonant-Vowel tasks. The audio data should be stored in the NWB file in the following way:\n  <ul>\n    <li>Speaker audio - As a <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries\" rel=\"nofollow\">TimeSeries</a> object, named 'Speaker CV', in the <em>stimulus</em> group.</li>\n    <li>Microphone audio - As a <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries\" rel=\"nofollow\">TimeSeries</a>  object, named 'Microphone CV', in the <em>acquisition</em> group.\n</li>\n  </ul> \n  The resulting detected intervals, 'TimeIntervals_mic' and 'TimeIntervals_speaker', are saved as <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.epoch.html#pynwb.epoch.TimeIntervals\" rel=\"nofollow\">TimeIntervals</a> objects in the <em>intervals</em> group of the current NWB file and can be used later for ERP analysis. A preview allows for testing of the detection parameters before running it for the whole duration of the audio signals. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/68862d96828dedda6eb4b005e2f4aaba062ced2a/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f6576656e745f646574656374696f6e2e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>High Gamma</strong> \n  </summary>\n  Estimation of high gamma analytic amplitude, with the average of user-defined specific bands. The results are saved as a <a href=\"https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries\" rel=\"nofollow\">TimeSeries</a> object, named 'high_gamma', in the <em>processing</em> group of the current or of a new NWB file. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4c509d441c7cb20477150d0fb49dd1347982542b/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f6869676867616d6d612e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Event-Related Potentials</strong> \n  </summary>\n  Grid visualization of high gamma ERP calculated in reference to:\n  <ul>\n    <li>Stimulus (speaker) or response (microphone) time intervals</li>\n    <li>Onset or offset points</li>\n  </ul> \n  The grid items are coloured to mark specific cortical areas and can be rotated to correspond anatomically to them. Emphasis can be given to specific areas of interest and double-clicking an item allows for fast inspection of the single electrode's ERP in detail. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4d1e3f7cc4f6846b9df86c575b41a6a0a5e1a6a5/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f6572702e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Periodograms</strong> \n  </summary>\n  Grid visualization of Periodograms:\n  <ul>\n    <li>Raw and preprocessed data</li>\n    <li>FFT and Welch methods</li>\n    <li>Individual devices</li>\n  </ul> \n  The grid items are coloured to mark specific cortical areas and can be rotated to correspond anatomically to them. Emphasis can be given to specific areas of interest and double-clicking an item allows for fast inspection of the single electrode's Periodogram in detail. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1d7877f667657a51e81c353139b2c41d131be06e/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f706572696f646f6772616d732e6769663f7261773d74727565\"></p>\n</details>\n<details>\n  <summary> \n    <strong>Spectral Decomposition</strong> \n  </summary>\n  Analytic signal amplitude estimation by Hilbert transform of user-defined frequency bands. <br><br>\n  WARNING: This function will manipulate an array of size (nSamples, nChannels, nBands), which might be in the order of gigabytes and demand a large memory to operate and is likely to produce a large file. <br><br>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6810844b6c616c858b3740c4df6bdceb70b91de0/68747470733a2f2f6769746875622e636f6d2f636174616c7973746e6575726f2f65636f675649532f626c6f622f6d61737465722f6d656469612f6769665f6465636f6d706f736974696f6e2e6769663f7261773d74727565\"></p>\n</details>\n<h3>Plus</h3>\n<ul>\n<li>Select electrodes from specific brain areas</li>\n<li>Easy moving between block files for the same subject</li>\n</ul>\n\n          </div>"}, "last_serial": 6921815, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "3175def83292568973efa58e9365d020", "sha256": "81782fb922632d4e9b9c0b657bd357519d634a5a14cf2e3cd53c7a484d3d83e2"}, "downloads": -1, "filename": "ecogvis-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3175def83292568973efa58e9365d020", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66315, "upload_time": "2020-03-31T16:47:28", "upload_time_iso_8601": "2020-03-31T16:47:28.794078Z", "url": "https://files.pythonhosted.org/packages/89/dc/29cb9fa674d7d4ca57fabf51b2f9c004f4beed142164c1bbf1f95a4927b1/ecogvis-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9de22d126a620106bf77562c06584ca7", "sha256": "019b2c7ba4e0113c8820219a38a082c9f697b448372fffe5ee9f7b467266e10d"}, "downloads": -1, "filename": "ecogvis-1.0.0.tar.gz", "has_sig": false, "md5_digest": "9de22d126a620106bf77562c06584ca7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 59871, "upload_time": "2020-03-31T16:47:31", "upload_time_iso_8601": "2020-03-31T16:47:31.493212Z", "url": "https://files.pythonhosted.org/packages/68/20/b1a2b62c28c6ca7049c7e32277e8a32dbd47b0418c2c6ec0693cb8832110/ecogvis-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "76cc92e2ef1f4eba4b30f802f3b6b88f", "sha256": "7f90189559c07e5b656f35b048189a49a5a4b218effb88b98e5f956239756d5f"}, "downloads": -1, "filename": "ecogvis-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "76cc92e2ef1f4eba4b30f802f3b6b88f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66358, "upload_time": "2020-03-31T17:53:31", "upload_time_iso_8601": "2020-03-31T17:53:31.851370Z", "url": "https://files.pythonhosted.org/packages/06/44/6dd9fe7315fb1b5dd887a514b6a07ee52e46a524db4464402a72d234c137/ecogvis-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b0086bac13d9cf460d3cf9e3889f35a", "sha256": "c5af4b175eb0c5d449bc81a7a8467f4acbf2cb90086b1b8574a685efd0d204c2"}, "downloads": -1, "filename": "ecogvis-1.0.1.tar.gz", "has_sig": false, "md5_digest": "8b0086bac13d9cf460d3cf9e3889f35a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 60009, "upload_time": "2020-03-31T17:53:34", "upload_time_iso_8601": "2020-03-31T17:53:34.359634Z", "url": "https://files.pythonhosted.org/packages/16/3e/297980d35b1e766747adc4b4ee5b51091853b4abc1b15ea6f82413e62929/ecogvis-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "76cc92e2ef1f4eba4b30f802f3b6b88f", "sha256": "7f90189559c07e5b656f35b048189a49a5a4b218effb88b98e5f956239756d5f"}, "downloads": -1, "filename": "ecogvis-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "76cc92e2ef1f4eba4b30f802f3b6b88f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66358, "upload_time": "2020-03-31T17:53:31", "upload_time_iso_8601": "2020-03-31T17:53:31.851370Z", "url": "https://files.pythonhosted.org/packages/06/44/6dd9fe7315fb1b5dd887a514b6a07ee52e46a524db4464402a72d234c137/ecogvis-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b0086bac13d9cf460d3cf9e3889f35a", "sha256": "c5af4b175eb0c5d449bc81a7a8467f4acbf2cb90086b1b8574a685efd0d204c2"}, "downloads": -1, "filename": "ecogvis-1.0.1.tar.gz", "has_sig": false, "md5_digest": "8b0086bac13d9cf460d3cf9e3889f35a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 60009, "upload_time": "2020-03-31T17:53:34", "upload_time_iso_8601": "2020-03-31T17:53:34.359634Z", "url": "https://files.pythonhosted.org/packages/16/3e/297980d35b1e766747adc4b4ee5b51091853b4abc1b15ea6f82413e62929/ecogvis-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:59 2020"}