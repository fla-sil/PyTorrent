{"info": {"author": "Gregory Petukhov", "author_email": "lorien@lorien.name", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: Implementation :: CPython", "Topic :: Internet :: WWW/HTTP", "Topic :: Software Development :: Libraries :: Application Frameworks", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "=======\nCrawler\n=======\n\n.. image:: https://travis-ci.org/lorien/crawler.png?branch=master\n    :target: https://travis-ci.org/lorien/crawler\n\n.. image:: https://coveralls.io/repos/lorien/crawler/badge.svg?branch=master\n    :target: https://coveralls.io/r/lorien/crawler?branch=master\n\n.. image:: https://pypip.in/download/crawler/badge.svg?period=month\n    :target: https://pypi.python.org/pypi/crawler\n\n.. image:: https://pypip.in/version/crawler/badge.svg\n    :target: https://pypi.python.org/pypi/crawler\n\n.. image:: https://landscape.io/github/lorien/crawler/master/landscape.png\n   :target: https://landscape.io/github/lorien/crawler/master\n\nWeb scraping framework based on py3 asyncio & aiohttp libraries.\n\n\nUsage Example\n=============\n\n.. code:: python\n\n    import re\n    from itertools import islice\n\n    from crawler import Crawler, Request\n\n    RE_TITLE = re.compile(r'<title>([^<]+)</title>', re.S | re.I)\n\n    class TestCrawler(Crawler):\n        def task_generator(self):\n            for host in islice(open('var/domains.txt'), 100):\n                host = host.strip()\n                if host:\n                    yield Request('http://%s/' % host, tag='page')\n\n        def handler_page(self, req, res):\n            print('Result of request to {}'.format(req.url))\n            try:\n                title = RE_TITLE.search(res.body).group(1)\n            except AttributeError:\n                title = 'N/A'\n            print('Title: {}'.format(title))\n\n    bot = TestCrawler(concurrency=10)\n    bot.run()\n\n\nInstallation\n============\n\n.. code:: bash\n\n    pip install crawler\n\n\nDependencies\n============\n\n* Python>=3.4\n* aiohttp", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "UNKNOWN", "keywords": null, "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "crawler", "package_url": "https://pypi.org/project/crawler/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/crawler/", "project_urls": {"Download": "UNKNOWN", "Homepage": "UNKNOWN"}, "release_url": "https://pypi.org/project/crawler/0.0.2/", "requires_dist": null, "requires_python": null, "summary": "Web Scraping Framework based on py3 asyncio", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/lorien/crawler\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/lorien/crawler.png?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5fb9d7a5592cf38e465d7842960c33144ca2217e/68747470733a2f2f7472617669732d63692e6f72672f6c6f7269656e2f637261776c65722e706e673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/r/lorien/crawler?branch=master\" rel=\"nofollow\"><img alt=\"https://coveralls.io/repos/lorien/crawler/badge.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f0676714162c1c661c8a08be0e6771407ca57d91/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6c6f7269656e2f637261776c65722f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pypi.python.org/pypi/crawler\" rel=\"nofollow\"><img alt=\"https://pypip.in/download/crawler/badge.svg?period=month\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8ff6315ce3b104916866d5c1dd1a54b502293566/68747470733a2f2f70797069702e696e2f646f776e6c6f61642f637261776c65722f62616467652e7376673f706572696f643d6d6f6e7468\"></a>\n<a href=\"https://pypi.python.org/pypi/crawler\" rel=\"nofollow\"><img alt=\"https://pypip.in/version/crawler/badge.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a33eecaeeaefd5aaba043bc743d231490fc52a19/68747470733a2f2f70797069702e696e2f76657273696f6e2f637261776c65722f62616467652e737667\"></a>\n<a href=\"https://landscape.io/github/lorien/crawler/master\" rel=\"nofollow\"><img alt=\"https://landscape.io/github/lorien/crawler/master/landscape.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6d0beebb11f767359ac75e4da1595bd8dc5e6273/68747470733a2f2f6c616e6473636170652e696f2f6769746875622f6c6f7269656e2f637261776c65722f6d61737465722f6c616e6473636170652e706e67\"></a>\n<p>Web scraping framework based on py3 asyncio &amp; aiohttp libraries.</p>\n<div id=\"usage-example\">\n<h2>Usage Example</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">re</span>\n<span class=\"kn\">from</span> <span class=\"nn\">itertools</span> <span class=\"kn\">import</span> <span class=\"n\">islice</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">crawler</span> <span class=\"kn\">import</span> <span class=\"n\">Crawler</span><span class=\"p\">,</span> <span class=\"n\">Request</span>\n\n<span class=\"n\">RE_TITLE</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"sa\">r</span><span class=\"s1\">'&lt;title&gt;([^&lt;]+)&lt;/title&gt;'</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">S</span> <span class=\"o\">|</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">I</span><span class=\"p\">)</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">TestCrawler</span><span class=\"p\">(</span><span class=\"n\">Crawler</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">task_generator</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">for</span> <span class=\"n\">host</span> <span class=\"ow\">in</span> <span class=\"n\">islice</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'var/domains.txt'</span><span class=\"p\">),</span> <span class=\"mi\">100</span><span class=\"p\">):</span>\n            <span class=\"n\">host</span> <span class=\"o\">=</span> <span class=\"n\">host</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n            <span class=\"k\">if</span> <span class=\"n\">host</span><span class=\"p\">:</span>\n                <span class=\"k\">yield</span> <span class=\"n\">Request</span><span class=\"p\">(</span><span class=\"s1\">'http://</span><span class=\"si\">%s</span><span class=\"s1\">/'</span> <span class=\"o\">%</span> <span class=\"n\">host</span><span class=\"p\">,</span> <span class=\"n\">tag</span><span class=\"o\">=</span><span class=\"s1\">'page'</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">handler_page</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">req</span><span class=\"p\">,</span> <span class=\"n\">res</span><span class=\"p\">):</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Result of request to </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">req</span><span class=\"o\">.</span><span class=\"n\">url</span><span class=\"p\">))</span>\n        <span class=\"k\">try</span><span class=\"p\">:</span>\n            <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">RE_TITLE</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">group</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"k\">except</span> <span class=\"ne\">AttributeError</span><span class=\"p\">:</span>\n            <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"s1\">'N/A'</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Title: </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"p\">))</span>\n\n<span class=\"n\">bot</span> <span class=\"o\">=</span> <span class=\"n\">TestCrawler</span><span class=\"p\">(</span><span class=\"n\">concurrency</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">bot</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">()</span>\n</pre>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install crawler\n</pre>\n</div>\n<div id=\"dependencies\">\n<h2>Dependencies</h2>\n<ul>\n<li>Python&gt;=3.4</li>\n<li>aiohttp</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 2168271, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "272f2a88e1376ac09f2d310405ff2bb8", "sha256": "b6b5bcc2f2a64ac60251bee1494bd7ea98605ef1a8bf87db5194bea4bdd420d2"}, "downloads": -1, "filename": "crawler-0.0.2.tar.gz", "has_sig": false, "md5_digest": "272f2a88e1376ac09f2d310405ff2bb8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6028, "upload_time": "2016-06-15T09:47:49", "upload_time_iso_8601": "2016-06-15T09:47:49.609926Z", "url": "https://files.pythonhosted.org/packages/8d/42/2b042beebf63f6d490d38b698f06ee4fdd16a1d32fa2373a6b662a37a33d/crawler-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "272f2a88e1376ac09f2d310405ff2bb8", "sha256": "b6b5bcc2f2a64ac60251bee1494bd7ea98605ef1a8bf87db5194bea4bdd420d2"}, "downloads": -1, "filename": "crawler-0.0.2.tar.gz", "has_sig": false, "md5_digest": "272f2a88e1376ac09f2d310405ff2bb8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6028, "upload_time": "2016-06-15T09:47:49", "upload_time_iso_8601": "2016-06-15T09:47:49.609926Z", "url": "https://files.pythonhosted.org/packages/8d/42/2b042beebf63f6d490d38b698f06ee4fdd16a1d32fa2373a6b662a37a33d/crawler-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:27 2020"}