{"info": {"author": "Thomas Gilgenast", "author_email": "thomasgilgenast@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Bio-Informatics"], "description": "hic3defdr\n=========\n\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/hic3defdr.svg)\n![PyPI - License](https://img.shields.io/pypi/l/hic3defdr)\n[![PyPI - Wheel](https://img.shields.io/pypi/wheel/hic3defdr.svg)](https://pypi.org/project/hic3defdr)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/hic3defdr.svg)](https://pypi.org/project/hic3defdr)\n[![Bitbucket Pipelines](https://img.shields.io/bitbucket/pipelines/creminslab/3defdr-hic.svg)](https://bitbucket.org/creminslab/3defdr-hic/addon/pipelines/home)\n[![Read the Docs (version)](https://img.shields.io/readthedocs/hic3defdr/stable.svg)](https://hic3defdr.readthedocs.io/en/stable)\n\nA genome-scale differential loop finder.\n\nFor the latest source, discussion, etc, please visit the Bitbucket repository at\nhttps://bitbucket.org/creminslab/hic3defdr\n\nInstallation\n------------\n\nWe require Python 2.7.11+ or 3.6+ and the dependencies listed in `setup.py`.\n\nA typical quick install process should be:\n\n    $ virtualenv venv\n    $ source venv/bin/activate\n    (venv)$ pip install hic3defdr\n\nA typical dev-mode install process should be:\n\n    $ git clone https://bitbucket.org/creminslab/hic3defdr.git\n    $ cd hic3defdr\n    $ virtualenv venv\n    $ source venv/bin/activate\n    (venv)$ pip install -e .\n\nIf installation succeeded then `hic3defdr.HiC3DeFDR` should be importable from\nan interactive shell started in some other directory:\n\n    (venv)$ cd <some other directory>\n    (venv)$ python\n    >>> from hic3defdr import HiC3DeFDR\n\n### Optional dependencies\n\nEvaluating simulations requires scikit-learn:\n\n    (venv)$ pip install scikit-learn\n\nTo display progress bars during selected steps of the analysis, install [tqdm](https://github.com/tqdm/tqdm):\n\n    (venv)$ pip install tqdm\n\nBasic walkthrough\n-----------------\n\nBefore we start, we'll seed numpy's random number generator for reproducibility:\n\n    >>> import numpy as np\n    >>> np.random.seed(42)\n\nTo analyze the ES_1, ES_3, NPC_1, and NPC_2 reps of the dataset dataset from\n[Bonev et al. 2017](https://www.ncbi.nlm.nih.gov/pubmed/29053968) with default\nparameters, we would first describe the dataset in terms of replicate names,\nchromosome names, and a design matrix. We will just analyze chromosomes 18 and\n19 here for illustrative purposes.\n\n    >>> import pandas as pd\n    >>>\n    >>> repnames = ['ES_1', 'ES_3', 'NPC_1', 'NPC_2']\n    >>> #chroms = ['chr%i' % i for i in range(1, 20)] + ['chrX']\n    >>> chroms = ['chr18', 'chr19']\n    >>> design = pd.DataFrame({'ES': [1, 1, 0, 0], 'NPC': [0, 0, 1, 1]},\n    ...                       dtype=bool, index=repnames)\n\nIf you're following along, you can download the data like this:\n\n    $ python -m hic3defdr.util.demo_data\n\nor from inside an interactive shell:\n\n    >>> from hic3defdr.util.demo_data import ensure_demo_data\n    >>> ensure_demo_data()\n\nThe data will be downloaded to a folder called `hic3defdr-demo-data` under your\nhome directory.\n\nThe required input files consist of:\n\n - upper triangular, raw contact matrices in `scipy.sparse` NPZ format,\n - bias vectors in plain-text `np.savetxt()` format, and\n - loop cluster files in sparse JSON format (see below for more details),\n   specifying the locations of loops present in each condition\n\nTODO: explain how to import data from common Hi-C analysis tools into this\nformat\n\nWe would next describe the location of the input data files and use those to\nconstruct a `HiC3DeFDR` object:\n\n    >>> import os.path\n    >>> from hic3defdr import HiC3DeFDR\n    >>>\n    >>> base_path = os.path.expanduser('~/hic3defdr-demo-data/')\n    >>> h = HiC3DeFDR(\n    ...     raw_npz_patterns=[base_path + '<rep>/<chrom>_raw.npz'.replace('<rep>', repname) for repname in repnames],\n    ...     bias_patterns=[base_path + '<rep>/<chrom>_kr.bias'.replace('<rep>', repname) for repname in repnames],\n    ...     chroms=chroms,\n    ...     design=design,\n    ...     outdir='output',\n    ...     loop_patterns={c: base_path + 'clusters/%s_<chrom>_clusters.json' % c for c in ['ES', 'NPC']},\n    ...     res=10000\n    ... )\n    creating directory output\n\nThis object saves itself to disk, so it can be re-loaded at any time:\n\n    >>> h = HiC3DeFDR.load('output')\n\nTo run the analysis for all chromosomes through q-values, run:\n\n    >>> h.run_to_qvalues()\n\nTo threshold, cluster, and classify the significantly differential loops, and\ncollect all the results into a single TSV output file, run:\n\n    >>> h.collect()\n\nThe output file will be written to `output/results_0.01_3.tsv`, where \"output\"\nrefers to the `outdir` we passed when constructing the `HiC3DeFDR` object,\n\"0.01\" refers to the default FDR of 1%, and \"3\" refers to the default cluster\nsize threshold of 3.\n\n    >>> import pandas as pd\n    >>> pd.read_csv('output/results_0.05_3.tsv', sep='\\t', index_col=0).head()\n                                                us_chrom  ...  classification\n    loop_id                                               ...                \n    chr18:3480000-3500000_chr18:4680000-4710000    chr18  ...    constitutive\n    chr18:3490000-3510000_chr18:3790000-3810000    chr18  ...              ES\n    chr18:3490000-3510000_chr18:3970000-3990000    chr18  ...    constitutive\n    chr18:3490000-3510000_chr18:4170000-4200000    chr18  ...    constitutive\n    chr18:3490000-3520000_chr18:4120000-4150000    chr18  ...    constitutive\n    <BLANKLINE>\n    [5 rows x 9 columns]\n\nSee the section \"TSV output format\" below for more details about the output\nformat.\n\nStep-by-step walkthrough\n------------------------\n\nCalling `h.run_to_qvalues()` runs the four main steps of the analysis in\nsequence. These four steps are described in further detail below. Any kwargs\npassed to `h.run_to_qvalues()` will be passed along to the appropriate step; see\n`help(HiC3DeFDR.run_to_qvalues)` for details.\n\n### Step 1: Preparing input data\n\nThe function call `h.prepare_data()` prepares the input raw contact matrices and\nbias vectors specified by `h.raw_npz_patterns` and `h.bias_patterns` for all\nchromosomes specified in `h.chroms`, performs library size normalization, and\ndetermines what points should be considered for dispersion estimation. This\ncreates intermediate files in the output directory `h.outdir` that represent the\nraw and scaled values, as well as the estimated size factors, and a boolean\nvector `disp_idx` indicating which points will be used for dispersion\nestimation. If `loop_patterns` was passed to the constructor, an additional\nboolean vector `loop_idx` is created to mark which points that pass `disp_idx`\nlie within looping interactions specified by `h.loop_patterns`. The raw and\nscaled data are stored in a rectangular matrix format where each row is a pixel\nof the contact matrix and each column is a replicate. If the size factors are\nestimated as a function of distance, the estimated size factors are also stored\nin this format. Two separate vectors called `row` and `col` are used to store\nthe row and column index of the pixel represented by each row of the rectangular\nmatrices. Together, the `row` and `col` vectors plus any of the rectangular\nmatrices represent a generalization of a COO format sparse matrix to multiple\nreplicates (in the standard COO format the `row` and `col` vectors are\ncomplemented by a single `value` vector).\n\nThe size factors can be estimated with a variety of methods defined in the\n`hic3defdr.scaling` module. The method to use is specified by the `norm` kwarg\npassed to `h.prepare_data()`. Some of these methods estimate size factors as a\nfunction of interaction distance, instead of simply estimating one size factor\nfor each replicate as is common in RNA-seq differential expression analysis.\nWhen these methods are used, the number of bins to use when binning distances\nfor distance-based estimation of the size factors can be specified with the\n`n_bins` kwarg. The defaults for this function use the conditional median of\nratios approach (`hic3defdr.scaling.conditional_mor`) and an\nautomatically-selected number of bins.\n\n### Step 2: Estimating dispersions\n\nThe function call `h.estimate_disp()` estimates the dispersion parameters at\neach distance scale in the data and fits a lowess curve through the graph of\ndistance versus dispersion to obtain final smoothed dispersion estimates for\neach pixel.\n\nThe `estimator` kwarg on `h.estimate_disp()` specifies which dispersion\nestimation method to use, out of a selection of options defined in the\n`hic3defdr.dispersion` module. The default is to use quantile-adjusted\nconditional maximum likelihood (qCML).\n\n### Step 3: Likelihood ratio test\n\nThe function call `h.lrt()` performs a likelihood ratio test (LRT) for each\npixel. This LRT compares a null model of no differential expression (fitting one\ntrue mean parameter shared by all replicates irrespective of condition) to an\nalternative model in which the two conditions have different true mean\nparameters.\n\n### Step 4: False discovery rate (FDR) control\n\nThe function call `h.bh()` performs Benjamini-Hochberg FDR correction on the\np-values called via the LRT in the previous step, considering only a subset of\npixels that are involved in looping interactions (as specified by\n`h.loop_patterns`; if `loop_patterns` was not passed to the constructor then all\npixels are included in the BH-FDR correction). This results in final q-values\nfor each loop pixel.\n\n### Thresholding, clustering, and classification\n\nWe can threshold, cluster, classify, and collect the significantly differential\nloops:\n\n    >>> h.collect(fdr=0.05, cluster_size=3)\n\nWe can also sweep across FDR and/or cluster size thresholds:\n\n    >>> h.collect(fdr=[0.01, 0.05], cluster_size=[3, 4])\n\nThe final output file for each combination of thresholding parameters will be\nwritten to `<h.outdir>/results_<fdr>_<cluster_size>.tsv`.\n\nThis example walkthrough should take less than 5 minutes for the two chromosomes\nincluded in the demo data. Run time for a whole-genome analysis will depend on\nparallelization as discussed in the next section.\n\nParallelization\n---------------\n\nThe functions `run_to_qvalues()`, `prepare_data()`, `lrt()`, `threshold()`,\n`classify()`, and `simulate()` operate in a per-chromosome manner. By default,\neach chromosome in the dataset will be processed in series. If multiple cores\nand sufficient memory are available, you can use the `n_threads` kwarg on these\nfunctions to use multiple subprocesses to process multiple chromosomes in\nparallel. Pass either a desired number of subprocesses to use, or pass\n`n_threads=-1` to use all available cores. The output logged to stderr will be\ntruncated to reduce clutter from multiple subprocesses printing to stderr at the\nsame time. This truncation is controlled by the `verbose` kwarg which is\navailable on some of these parallelized functions.\n\nThe function `estimate_disp()` also accepts an `n_threads` kwarg, using it to\nparallelize itself across distance scales.\n\nThe function `run_to_qvalues()` passes the `n_threads` kwarg through to all the\nsteps it calls.\n\nIntermediates and final output files\n------------------------------------\n\nAll intermediates used in the computation will be saved to the disk inside the\n`outdir` folder as `<intermediate>_<chrom>.npy` (most intermediates),\n`<intermediate>_<chrom>.json`/`<intermediate>_<chrom>.tsv` (thresholded or\nclassified clusters).\n\nTwo intermediates are not generated per chromosome. These are\n`disp_fn_<c>.pickle` (dispersion function estimated across all chromosomes for\ncondition `<c>`) and `results_<f>_<s>.tsv` (final combined results from all\nchromosomes).\n\n| Step              | Intermediate      | Shape                               | Description                                 |\n|-------------------|-------------------|-------------------------------------|---------------------------------------------|\n| `prepare_data()`  | `row`             | `(n_pixels,)`                       | Top-level row index                         |\n| `prepare_data()`  | `col`             | `(n_pixels,)`                       | Top-level column index                      |\n| `prepare_data()`  | `bias`            | `(n_bins, n_reps)`                  | Bias vectors                                |\n| `prepare_data()`  | `raw`             | `(n_pixels, n_reps)`                | Raw count values                            |\n| `prepare_data()`  | `size_factors`    | `(n_reps,)` or `(n_pixels, n_reps)` | Size factors                                |\n| `prepare_data()`  | `scaled`          | `(n_pixels, n_reps)`                | Normalized count values                     |\n| `prepare_data()`  | `disp_idx`        | `(n_pixels,)`                       | Marks pixels for which dispersion is fitted |\n| `prepare_data()`  | `loop_idx`        | `(disp_idx.sum(),)`                 | Marks pixels which lie in loops             |\n| `estimate_disp()` | `cov_per_bin`     | `(n_bins, n_conds)`                 | Average mean count or distance in each bin  |\n| `estimate_disp()` | `disp_per_bin`    | `(n_bins, n_conds)`                 | Pooled dispersion estimates in each bin     |\n| `estimate_disp()` | `disp_fn_<c>`     | pickled function                    | Fitted dispersion function                  |\n| `estimate_disp()` | `disp`            | `(disp_idx.sum(), n_conds)`         | Smoothed dispersion estimates               |\n| `lrt()`           | `mu_hat_null`     | `(disp_idx.sum(),)`                 | Null model mean parameters                  |\n| `lrt()`           | `mu_hat_alt`      | `(disp_idx.sum(), n_conds)`         | Alternative model mean parameters           |\n| `lrt()`           | `llr`             | `(disp_idx.sum(),)`                 | Log-likelihood ratio                        |\n| `lrt()`           | `pvalues`         | `(disp_idx.sum(),)`                 | LRT-based p-value                           |\n| `bh()`            | `qvalues`         | `(loop_idx.sum(),)`                 | BH-corrected q-values                       |\n| `threshold()`     | `sig_<f>_<s>`     | JSON/TSV                            | Significantly differential clusters         |\n| `threshold()`     | `insig_<f>_<s>`   | JSON/TSV                            | Constitutive clusters                       |\n| `classify()`      | `<c>_<f>_<s>`     | JSON/TSV                            | Classified differential clusters            |\n| `collect()`       | `results_<f>_<s>` | TSV                                 | Final results table                         |\n\nThe table uses these abbreviations to refer to variable parts of certain\nintermediate names:\n\n - `<f>`: FDR threshold\n - `<s>`: cluster size threshold\n - `<c>`: condition/class label\n\nSparse JSON cluster format\n--------------------------\n\nThis is the format used both for supplying pre-identified, per-condition loop\nclusters as input to HiC3DeFDR as well as the format in which differential and\nconstitutive interaction clusters are reported as output.\n\nThe format describes the clusters on each chromosome in a separate JSON file.\nThis JSON file contains a single JSON object, which is a list of list of list of\nintegers. The inner lists are all of length 2 and represent specific pixels of\nthe heatmap for that chromosome in terms of there row and column coordinates in\nzero-indexed bin units. The outer middle lists can be of any length and\nrepresent groups of pixels that belong to the same cluster. The length of the\nouter list corresponds to the number of clusters on that chromosome.\n\nThese clusters can be loaded into and written from the corresponding plain\nPython objects using `hic3defdr.clusters.load_clusters()` and\n`hic3defdr.clusters.save_clusters()`, respectively. The plain Python objects can\nbe converted to and from scipy sparse matrix objects using\n`hic3defdr.clusters.clusters_to_coo()` and\n`hic3defdr.clusters.convert_cluster_array_to_sparse()`, respectively.\n\nTSV output format\n-----------------\n\nThe final TSV output file `results_<f>_<s>.tsv` has as its first column a\n`loop_id`, a string of the form\n`<us_chrom>:<us_start>-<us_end>_<ds_chrom>:<ds_start>-<ds_end>` specifying a\nrectangle that surrounds the cluster of pixels that make up the loop. The next\nsix columns are the six individual pieces of this `loop_id`. This is followed\nby:\n - `cluster_size`: the number of pixels in the cluster\n - `cluster`: a list of the exact (row, col) indices of the pixels in the\n   cluster\n - `classification`: this will be \"constitutive\" if the loop is not\n   differential, or the name of the condition the loop is specific to (i.e.,\n   strongest in) if it is differential\n\nVisualizations\n--------------\n\nThe `HiC3DeFDR` object can be used to draw visualizations of the analysis.\n\nThe visualization functions are wrapped with the [@plotter decorator](https://lib5c.readthedocs.io/en/latest/plotting/)\nand therefore all support the convenience kwargs provided by that decorator\n(such as `outfile`).\n\n### Distance dependence curves before and after scaling\n\n    >>> _ = h.plot_dd_curves('chr18', outfile='images/dd.png')\n\n![](images/dd.png)\n\n### Simple heatmap plotting\n\n    >>> _ = h.plot_heatmap('chr18', slice(1000, 1100), slice(1000, 1100), rep='ES_1',\n    ...                    outfile='images/heatmap.png')\n\n![](images/heatmap.png)\n\nBy default, this plots data at the \"scaled\" stage (normalized for bias and\nsequencing depth differences), but you can plot any stage of the data by passing\na `stage` kwarg.\n\n### Condition-average heatmap plotting\n\nTo plot a within-condition average heatmap, pass a `stage` name with a '_mean'\nsuffix appended and `cond` to specify the condition to average within:\n\n    >>> _ = h.plot_heatmap('chr18', slice(1000, 1100), slice(1000, 1100),\n    ...                    stage='scaled_mean', cond='ES',\n    ...                    outfile='images/heatmap_mean.png')\n\n![](images/heatmap_mean.png)\n\n### Loop zoomin heatmap plotting\n\nWe can combine `h.plot_heatmap()` with the `load_clusters()` and\n`cluster_to_slices()` utility functions in `hic3defdr.util.clusters` to plot\nzoomins around specific loops:\n\n    >>> from hic3defdr.util.clusters import load_clusters, cluster_to_slices\n    >>> chrom = 'chr18'\n    >>> clusters = load_clusters(h.loop_patterns['ES'].replace('<chrom>', chrom))\n    >>> slices = cluster_to_slices(clusters[23])\n    >>> _ = h.plot_heatmap(chrom, *slices, rep='ES_1', outfile='images/zoomin.png')\n\n![](images/zoomin.png)\n\n### Per-pixel significance plotting\n\nWe can pass `stage='qvalues'` to `h.plot_heatmap()` to draw heatmaps showing the\nsignificance of each pixel:\n\n    >>> _ = h.plot_heatmap('chr18', slice(1310, 1370), slice(1310, 1370),\n    ...                    stage='qvalues', cmap='bwr_r', vmin=0.099, vmax=0.101,\n    ...                    outfile='images/heatmap_sig.png')\n\n![](images/heatmap_sig.png)\n\nBy passing `cmap='bwr_r'` we ensure that significant, low q-value pixels will be\nred while insignificant, high q-value pixels will be blue. By passing\n`vmin=0.099, vmax=0.101`, we ensure that the colorbar is focused on a narrow\nrange around an FDR threshold of 10%, allowing us to more easily tell the\ndifference between significant and insignificant pixels.\n\n### Correlation matrices\n\n    >>> _ = h.plot_correlation_matrix(outfile='images/correlation.png')\n\n![](images/correlation.png)\n\n### Dispersion fitting\n\n    >>> _ = h.plot_dispersion_fit('ES', outfile='images/ddr.png')\n\n![](images/ddr.png)\n\nIt's possible to use the the one-dimensional distance dependence curve to\nconvert distances to means. Doing so allows plotting the y-axis in terms of\nvariance. You can do this by passing `yaxis='var'`:\n\n    >>> _ = h.plot_dispersion_fit('ES', yaxis='var', outfile='images/dvr.png')\n\n![](images/dvr.png)\n\nUsing the same trick, you can plot the x-axis in terms of mean by passing\n`xaxis='mean'`:\n\n    >>> _ = h.plot_dispersion_fit('ES', xaxis='mean', yaxis='var',\n    ...                           outfile='images/mvr.png')\n\n![](images/mvr.png)\n\nAt low mean and high distance, the distance dependence curve flattens out and\nthe data become more noisy, making this conversion unreliable.\n\nIt's also possible to show the dispersion fitted at just one distance scale,\noverlaying the sample mean and sample variance across replicates for each pixel\nas a blue hexbin plot:\n\n    >>> _ = h.plot_dispersion_fit('ES', distance=25, hexbin=True, xaxis='mean',\n    ...                           yaxis='var', logx=True, logy=True,\n    ...                           outfile='images/mvr_25.png')\n\n![](images/mvr_25.png)\n\nIf dispersion was fitted against distance rather than mean, pass `xaxis='dist'`\nto plot dispersion/variance versus distance.\n\n### Comparing dispersion fits\n\nIt's possible to compare different dispersion fits using the function\n`compare_disp_fits()` as shown here:\n\n    >>> from hic3defdr import compare_disp_fits\n    >>>\n    >>> _ = compare_disp_fits(\n    ...     [h.load_disp_fn(cond) for cond in h.design.columns],\n    ...     h.design.columns,\n    ...     max_dist=100,\n    ...     outfile='images/disp_comparison.png'\n    ... )\n\n![](images/disp_comparison.png)\n\n### P-value distribution\n\n    >>> _ = h.plot_pvalue_distribution(outfile='images/pvalue_dist.png')\n\n![](images/pvalue_dist.png)\n\nBy default, this plots the p-value distribution over all pixels for which\ndispersion was estimated. To plot the p-value distribution only over points in\nloops, pass `idx='loop'`.\n\n### Q-value distribution\n\n    >>> _ = h.plot_qvalue_distribution(outfile='images/qvalue_dist.png')\n\n![](images/qvalue_dist.png)\n\n### MA plot\n\n    >>> _ = h.plot_ma(outfile='images/ma.png')\n\n![](images/ma.png)\n\n### Pixel detail grid\n\n    >>> _ = h.plot_grid('chr18', 2218, 2236, 20, outfile='images/grid.png')\n\n![](images/grid.png)\n\nThe upper right heatmaps show the balanced and scaled values in each replicate,\nwith each condition on its own row.\n\nThe upper left heatmaps show the alternative model mean parameter estimates for\neach condition. Significantly differential clusters are purple while\nconstitutive ones are gray.\n\nThe lower left heatmap shows the q-values. Significantly differential clusters\nare orange while constitutive ones are gray.\n\nThe stripplots in the lower left show details information about the specific\npixel in the center of the heatmaps (in this example `(2218, 2236)`). The dots\nshow the values at that pixel for each replicate in normalized and raw space,\nrepsectively. The solid and dashed lines represent the mean parameters under the\nalt and null models, repsectively.\n\nGreen points in the heatmaps represent points that have been filtered out. For\nthe per-replicate heatmaps in the upper right of the grid, the only filters\napplied are the zero filter, bias filter, and distance filter. For the alt model\nmean heatmaps in the upper left, this additionally includes the dispersion\nfilter. For the q-value heatmap in the lower left, it additionally includes the\nloop filter if loop locations were supplied.\n\n### Interactive thresholding\n\nIn a Jupyter notebook environment with `ipywidgets` installed, you can play with\nthresholds on a live-updating plot by running:\n\n    %matplotlib notebook\n\n    from ipywidgets import interact\n    from hic3defdr import HiC3DeFDR\n\n    h = HiC3DeFDR.load('output')\n    _, _, outline_clusters = h.plot_grid('chr18', 2218, 2236, 50)\n    _ = interact(outline_clusters, fdr=[0.01, 0.05, 0.1, 0.2],\n                 cluster_size=[3, 4])\n\nSimulation\n----------\n\nAfter the `estimate_disp()` step has been run, a HiC3DeFDR object can be used to\ngenerate simulations of differential looping.\n\n### Generating simulations\n\nTo create an ES-based simulation over all chromosomes listed in `h.chroms`, we\nrun\n\n    >>> from hic3defdr import HiC3DeFDR\n    >>>\n    >>> h = HiC3DeFDR.load('output')\n    >>> h.simulate('ES')\n\nIf we passed `trend='dist'` to `h.estimate_disp()`, we need to pass it to\n`h.simulate()` as well to ensure that the simulation function knows to treat the\npreviously-fitted dispersion function as a function of distance.\n\nThis takes the mean of the real scaled data across the ES replicates and\nperturbs the loops specified in `h.loop_patterns['ES']` up or down at random to\ngenerate two new conditions called \"A\" and \"B\". The scaled mean matrices for\nthese conditions are then biased and scaled by the bias vectors and size factors\ntaken from the real experimental replicates, and the ES dispersion function\nfitted to the real ES data is applied to the biased and scaled means to obtain\ndispersion values. These means and dispersions are used to draw an NB random\nvariable for each pixel of each simulated replicate. The number of replicates in\neach of the simulated conditions \"A\" and \"B\" will match the design of the real\nanalysis.\n\nThe simulated raw contact matrices will be written to disk in CSR format as\n`<cond><rep>_<chrom>_raw.npz` where `<cond>` is \"A\" or \"B\" and `<rep>` is the\nrep number within the condition. The design matrix will also be written to disk\nas `design.csv`.\n\nThe true labels used to perturb the loops will also be written to disk as\n`labels_<chrom>.txt`. This file contains as many lines as there are clusters in\n`h.loop_patterns['ES']`, with the `i`th line providing the label for the `i`th\ncluster. This file can be loaded with `np.loadtxt(..., dtype='|S7')`.\n\n### Evaluating simulations\n\nAfter generating simulated data, HiC3DeFDR can be run on the simulated data.\nThen, the true labels can be used to evaluate the performance of HiC3DeFDR on\nthe simulated data.\n\nEvaluation of simulated data requires scikit-learn. To install this package, run\n\n    (venv)$ pip install scikit-learn\n\nIn order to run HiC3DeFDR on the simulated data, we first need to balance the\nsimulated raw contact matrices to obtain bias vectors for each simulated\nreplicate and chromosome. We will assume are saved next to the raw contact\nmatrices and named `<rep>_<chrom>_kr.bias`. One example of how this can be done\nis shown in the following script:\n\n    >>> import sys\n    >>>\n    >>> import numpy as np\n    >>> import scipy.sparse as sparse\n    >>>\n    >>> from hic3defdr.util.filtering import filter_sparse_rows_count\n    >>> from hic3defdr.util.balancing import kr_balance\n    >>> from hic3defdr.util.printing import eprint\n    >>>\n    >>>\n    >>> infile_pattern = 'sim/<rep>_<chrom>_raw.npz'\n    >>> repnames = ['A1', 'A2', 'B1', 'B2']\n    >>> chroms = ['chr18', 'chr19']\n    >>>\n    >>> for repname in repnames:\n    ...     for chrom in chroms:\n    ...         eprint('balancing rep %s chrom %s' % (repname, chrom))\n    ...         infile = infile_pattern.replace('<rep>', repname)\\\n    ...             .replace('<chrom>', chrom)\n    ...         outfile = infile.replace('_raw.npz', '_kr.bias')\n    ...         _, bias, _ = kr_balance(\n    ...             filter_sparse_rows_count(sparse.load_npz(infile)), fl=0)\n    ...         np.savetxt(outfile, bias)\n\nNext, we create a new HiC3DeFDR object to analyze the simulated data and run the\nanalysis through to q-values:\n\n    >>> import os.path\n    >>> from hic3defdr import HiC3DeFDR\n    >>>\n    >>> repnames = ['A1', 'A2', 'B1', 'B2']\n    >>> chroms = ['chr18', 'chr19']\n    >>> sim_path = 'sim/'\n    >>> base_path = os.path.expanduser('~/hic3defdr-demo-data/')\n    >>> h_sim = HiC3DeFDR(\n    ...     raw_npz_patterns=[sim_path + '<rep>_<chrom>_raw.npz'.replace('<rep>', repname) for repname in repnames],\n    ...     bias_patterns=[sim_path + '<rep>_<chrom>_kr.bias'.replace('<rep>', repname) for repname in repnames],\n    ...     chroms=chroms,\n    ...     design=sim_path + 'design.csv',\n    ...     outdir='output-sim',\n    ...     loop_patterns={'ES': base_path + 'clusters/ES_<chrom>_clusters.json'}\n    ... )\n    creating directory output-sim\n    >>> h_sim.run_to_qvalues()\n\nNext, we can evaluate the simulation against the clusters in\n`h_sim.loop_patterns['ES']` with true labels from `sim/labels_<chrom>.txt`:\n\n    >>> h_sim.evaluate('ES', 'sim/labels_<chrom>.txt')\n\nThis writes a file in `h_sim`'s output directory called `eval.npz`. This file\ncan be loaded with `np.load()` and has four keys whose values are all one\ndimensional vectors:\n\n - `'thresh'`: the thresholds (in `1 - qvalue` space) which make up the convex\n   edge of the ROC curve; all other vectors are parallel to this one\n - `'fdr'`: the observed false discovery rate at each threshold\n - `'tpr'`: the observed true positive rate at each threshold\n - `'fpr'`: the observed false positive rate at each threshold\n\n`eval.npz` files (possibly across many runs) can be visualized as ROC curves and\nFDR control curves by running:\n\n    >>> import numpy as np\n    >>> from hic3defdr import plot_roc, plot_fdr\n    >>>\n    >>> _ = plot_roc([np.load('output-sim/eval.npz')], ['hic3defdr'], outfile='images/roc.png')\n    >>> _ = plot_fdr([np.load('output-sim/eval.npz')], ['hic3defdr'], outfile='images/fdr.png')\n\n![](images/roc.png)\n![](images/fdr.png)\n\nMultiple `eval.npz` files can be compared in the same plot by simply adding\nelements to the lists in these function calls.\n\nThe ROC plot shows FPR versus TPR, with the gray diagonal line representing the\nperformance of random guessing. The AUROC for each curve is shown in the legend.\nIf only one curve is plotted, selected thresholds (in units of FDR threshold)\nare annotated with black arrows.\n\nThe FDR control plot shows the observed FDR as a function of the FDR threshold.\nPoints below the gray diagonal line represent points at which FDR is\nsuccessfully controlled.\n\nAs an added bonus, it's also possible to evaluate the performance on specific\nsubsets of distance scales by using the `min_dist` and `max_dist` kwargs on\n`HiC3DeFDR.evaluate()` as illustrated below:\n\n    >>> dist_bins = [\n    ...    ('short', (None, 15)),  # distances in bin units\n    ...    ('mid', (16, 30)),\n    ...    ('long', (31, None))\n    ... ]\n    >>> for _, (min_dist, max_dist) in dist_bins:\n    ...     h_sim.evaluate('ES', 'sim/labels_<chrom>.txt', min_dist=min_dist,\n    ...                    max_dist=max_dist)\n    >>> _ = plot_roc([np.load('output-sim/eval_%s_%s.npz' % (min_dist, max_dist))\n    ...               for _, (min_dist, max_dist) in dist_bins],\n    ...              [label for label, _ in dist_bins],\n    ...              outfile='images/roc_by_dist.png')\n    >>> _ = plot_fdr([np.load('output-sim/eval_%s_%s.npz' % (min_dist, max_dist))\n    ...               for _, (min_dist, max_dist) in dist_bins],\n    ...              [label for label, _ in dist_bins],\n    ...              outfile='images/fdr_by_dist.png')\n\n![](images/roc_by_dist.png)\n![](images/fdr_by_dist.png)\n\nIt's also possible to compare the FPR and FNR at the different subsets:\n\n    >>> from hic3defdr import plot_fn_vs_fp\n    >>>\n    >>> _ = plot_fn_vs_fp([np.load('output-sim/eval_%s_%s.npz' % (min_dist, max_dist))\n    ...                    for _, (min_dist, max_dist) in dist_bins],\n    ...                   [label for label, _ in dist_bins], xlabel='distance subset',\n    ...                   outfile='images/fn_vs_fp.png')\n\n![](images/fn_vs_fp.png)\n\nOther visualizations\n--------------------\n\n### Distance bias\n\nWe can visualize and compare the distance bias of different simulations (the\ndegree to which low p-values are enriched or depleted in different distance\nscales) using the `plot_distance_bias()` function as shown below:\n\n    >>> from hic3defdr import plot_distance_bias\n    >>>\n    >>> dist_bins = [\n    ...    ('short', (None, 15)),  # distances in bin units\n    ...    ('mid', (16, 30)),\n    ...    ('long', (31, None))\n    ... ]\n    >>> _ = plot_distance_bias([h, h_sim], [b for _, b in dist_bins], labels=['real', 'sim'], outfile='images/distance_bias.png')\n\n![](images/distance_bias.png)\n\nPackage structure\n-----------------\n\nThe `hic3defdr` package is layed out in three parts:\n\n 1. `hic3defdr.util`: library of re-usable functions for performing computations\n    related to differential loop calling\n 2. `hic3defdr.plotting`: library of re-usable functions to plotting\n    visualizations related to differential loop calling\n 3. `hic3defdr.analysis`: a module that defines the HiC3DeFDR class, which\n    provides an implementation of stitching together all the computational steps\n    and visualizations in an easy-to-use way\n\nThe HiC3DeFDR class includes many methods, so to keep things organized these\nmethods are defined in four separate mixin classes which are combined to form\nthe full HiC3DeFDR class in `hic3defdr/analysis/constructor.py`:\n\n - `hic3defdr.analysis.core.CoreHiC3DeFDR`\n - `hic3defdr.analysis.analysis.AnalyzingHiC3DeFDR`\n - `hic3defdr.analysis.simulation.SimulatingHiC3DeFDR`\n - `hic3defdr.analysis.plotting.PlottingHiC3DeFDR`\n\nWe recommend that most users simply import the HiC3DeFDR class and interact with\nthis package through that interface, but the functions defined in\n`hic3efdr.util` and `hic3defdr.plotting` may also be useful to some users and\nare designed to be somewhat re-usable.\n\nThe complete layout of the package is summarized below:\n\n```\nhic3defdr/                      # package root\n\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac _version.py                 # version configuration\n\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac analysis/                   # HiC3DeFDR class and alternatives\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac alternatives.py         # defines alternative analysis models\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac analysis.py             # HiC3DeFDR's pipeline methods\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac constructor.py          # HiC3DeFDR's class definition and constructor\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac core.py                 # HiC3DeFDR's core save/load methods\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac plotting.py             # HiC3DeFDR's plotting methods\n\u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac simulation.py           # HiC3DeFDR's simulation/evaluation methods\n\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac plotting/                   # library of plotting functions\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac dispersion.py           # dispersion/variance fit visualizations\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac distance_bias.py        # distance bias comparison barplots\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac distance_dependence.py  # distance dependence curve comparison\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac fdr.py                  # FDR control curve plotting\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac fn_vs_fp.py             # FN vs FP tradeoff barplots\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac grid.py                 # \"pixel detail grid\" combination visualization\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac heatmap.py              # simple contact matrix heatmap plotting\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac histograms.py           # p-value/q-value histograms\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ma.py                   # MA plots\n\u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac roc.py                  # ROC curve plots\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac util/                       # library of utility functions \n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac binning.py              # creating groups of points\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac balancing.py            # KR matrix balancing\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac banded_matrix.py        # BandedMatrix class (used for filtering)\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac classification.py       # classifying differential loop pixels\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac cluster_table.py        # creating tables summarizing cluster info\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac clusters.py             # interacting with called loop clusters\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac demo_data.py            # utilities for downloading the demo dataset\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac dispersion.py           # estimating dispersions in NB data\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac evaluation.py           # evaluating results of simulations\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac filtering.py            # filtering (applied before balancing)\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac lowess.py               # lowess fitting\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac lrt.py                  # NB likelihood ratio testing\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac matrices.py             # interacting with sparse matrices\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac parallelization.py      # parallelizing work across cores\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac printing.py             # printing updates and info to the console\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac progress.py             # showing progress bars\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac scaled_nb.py            # dealing with scaling factors in NB\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac scaling.py              # scaling reps to account for sequencing depth\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac simulation.py           # simulating pseudoreplicates\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac thresholding.py         # thresholding differential pixels/clusters\n```\n\nAdditional options\n------------------\n\nAdditional options are exposed as kwargs on the functions in this library. Use\n`help(<function>)` to get detailed information about the options available for\nany function and what these options may be used for.\n\nTesting\n-------\n\nWe run our tests with [tox](https://tox.readthedocs.io). To execute tests,\ninstall tox (`pip install tox`) and then run `tox` to run all tests or\n`tox -e <testenv>` to run a specific test environment. See `tox.ini` for the\nfull specification of all test environments.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://bitbucket.org/creminslab/hic3defdr", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "hic3defdr", "package_url": "https://pypi.org/project/hic3defdr/", "platform": "", "project_url": "https://pypi.org/project/hic3defdr/", "project_urls": {"Homepage": "https://bitbucket.org/creminslab/hic3defdr"}, "release_url": "https://pypi.org/project/hic3defdr/0.2.1/", "requires_dist": ["numpy (>=1.14.0)", "scipy (>=1.2.0)", "matplotlib (>=2.1.1)", "mpl-scatter-density (>=0.6)", "seaborn (>=0.8.0)", "pandas (>=0.21.0)", "lib5c (>=0.6.0)", "dill (>=0.2.9)", "importlib-metadata (>=1.5.0) ; python_version < \"3.8\"", "Sphinx (>=1.8.5) ; extra == 'complete'", "doctest-ignore-unicode (>=0.1.2) ; extra == 'complete'", "flake8 (>=3.4.1) ; extra == 'complete'", "m2r (>=0.2.1) ; extra == 'complete'", "nose-exclude (>=0.5.0) ; extra == 'complete'", "nose (>=1.3.7) ; extra == 'complete'", "scikit-learn (>=0.20.3) ; extra == 'complete'", "sphinx-rtd-theme (>=0.4.3) ; extra == 'complete'", "sphinxcontrib-apidoc (>=0.3.0) ; extra == 'complete'", "tqdm (>=4.32.2) ; extra == 'complete'", "Sphinx (>=1.8.5) ; extra == 'docs'", "sphinx-rtd-theme (>=0.4.3) ; extra == 'docs'", "sphinxcontrib-apidoc (>=0.3.0) ; extra == 'docs'", "m2r (>=0.2.1) ; extra == 'docs'", "scikit-learn (>=0.20.3) ; extra == 'evaluation'", "tqdm (>=4.32.2) ; extra == 'progress'", "nose (>=1.3.7) ; extra == 'test'", "nose-exclude (>=0.5.0) ; extra == 'test'", "doctest-ignore-unicode (>=0.1.2) ; extra == 'test'", "flake8 (>=3.4.1) ; extra == 'test'"], "requires_python": "", "summary": "a genome-scale differential loop finder", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>hic3defdr</h1>\n<p><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/91b4802af89343f2a95ba6563149409b0f3ccff2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6869633364656664722e737667\">\n<img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/97eae6c83330313a3a23b2f5af3b0c9672b51e08/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f686963336465666472\">\n<a href=\"https://pypi.org/project/hic3defdr\" rel=\"nofollow\"><img alt=\"PyPI - Wheel\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/629f9793836c931f19748959b6f719c775ff9ea8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f776865656c2f6869633364656664722e737667\"></a>\n<a href=\"https://pypi.org/project/hic3defdr\" rel=\"nofollow\"><img alt=\"PyPI - Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9be465458209f35d789543f3a15920743ba21f5f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6869633364656664722e737667\"></a>\n<a href=\"https://bitbucket.org/creminslab/3defdr-hic/addon/pipelines/home\" rel=\"nofollow\"><img alt=\"Bitbucket Pipelines\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eb0351b46ec2b86778213c8c6c7091718aace085/68747470733a2f2f696d672e736869656c64732e696f2f6269746275636b65742f706970656c696e65732f6372656d696e736c61622f3364656664722d6869632e737667\"></a>\n<a href=\"https://hic3defdr.readthedocs.io/en/stable\" rel=\"nofollow\"><img alt=\"Read the Docs (version)\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/36fc80f035b11969ad69f1c6d4b83917c0205440/68747470733a2f2f696d672e736869656c64732e696f2f72656164746865646f63732f6869633364656664722f737461626c652e737667\"></a></p>\n<p>A genome-scale differential loop finder.</p>\n<p>For the latest source, discussion, etc, please visit the Bitbucket repository at\n<a href=\"https://bitbucket.org/creminslab/hic3defdr\" rel=\"nofollow\">https://bitbucket.org/creminslab/hic3defdr</a></p>\n<h2>Installation</h2>\n<p>We require Python 2.7.11+ or 3.6+ and the dependencies listed in <code>setup.py</code>.</p>\n<p>A typical quick install process should be:</p>\n<pre><code>$ virtualenv venv\n$ source venv/bin/activate\n(venv)$ pip install hic3defdr\n</code></pre>\n<p>A typical dev-mode install process should be:</p>\n<pre><code>$ git clone https://bitbucket.org/creminslab/hic3defdr.git\n$ cd hic3defdr\n$ virtualenv venv\n$ source venv/bin/activate\n(venv)$ pip install -e .\n</code></pre>\n<p>If installation succeeded then <code>hic3defdr.HiC3DeFDR</code> should be importable from\nan interactive shell started in some other directory:</p>\n<pre><code>(venv)$ cd &lt;some other directory&gt;\n(venv)$ python\n&gt;&gt;&gt; from hic3defdr import HiC3DeFDR\n</code></pre>\n<h3>Optional dependencies</h3>\n<p>Evaluating simulations requires scikit-learn:</p>\n<pre><code>(venv)$ pip install scikit-learn\n</code></pre>\n<p>To display progress bars during selected steps of the analysis, install <a href=\"https://github.com/tqdm/tqdm\" rel=\"nofollow\">tqdm</a>:</p>\n<pre><code>(venv)$ pip install tqdm\n</code></pre>\n<h2>Basic walkthrough</h2>\n<p>Before we start, we'll seed numpy's random number generator for reproducibility:</p>\n<pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; np.random.seed(42)\n</code></pre>\n<p>To analyze the ES_1, ES_3, NPC_1, and NPC_2 reps of the dataset dataset from\n<a href=\"https://www.ncbi.nlm.nih.gov/pubmed/29053968\" rel=\"nofollow\">Bonev et al. 2017</a> with default\nparameters, we would first describe the dataset in terms of replicate names,\nchromosome names, and a design matrix. We will just analyze chromosomes 18 and\n19 here for illustrative purposes.</p>\n<pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt;\n&gt;&gt;&gt; repnames = ['ES_1', 'ES_3', 'NPC_1', 'NPC_2']\n&gt;&gt;&gt; #chroms = ['chr%i' % i for i in range(1, 20)] + ['chrX']\n&gt;&gt;&gt; chroms = ['chr18', 'chr19']\n&gt;&gt;&gt; design = pd.DataFrame({'ES': [1, 1, 0, 0], 'NPC': [0, 0, 1, 1]},\n...                       dtype=bool, index=repnames)\n</code></pre>\n<p>If you're following along, you can download the data like this:</p>\n<pre><code>$ python -m hic3defdr.util.demo_data\n</code></pre>\n<p>or from inside an interactive shell:</p>\n<pre><code>&gt;&gt;&gt; from hic3defdr.util.demo_data import ensure_demo_data\n&gt;&gt;&gt; ensure_demo_data()\n</code></pre>\n<p>The data will be downloaded to a folder called <code>hic3defdr-demo-data</code> under your\nhome directory.</p>\n<p>The required input files consist of:</p>\n<ul>\n<li>upper triangular, raw contact matrices in <code>scipy.sparse</code> NPZ format,</li>\n<li>bias vectors in plain-text <code>np.savetxt()</code> format, and</li>\n<li>loop cluster files in sparse JSON format (see below for more details),\nspecifying the locations of loops present in each condition</li>\n</ul>\n<p>TODO: explain how to import data from common Hi-C analysis tools into this\nformat</p>\n<p>We would next describe the location of the input data files and use those to\nconstruct a <code>HiC3DeFDR</code> object:</p>\n<pre><code>&gt;&gt;&gt; import os.path\n&gt;&gt;&gt; from hic3defdr import HiC3DeFDR\n&gt;&gt;&gt;\n&gt;&gt;&gt; base_path = os.path.expanduser('~/hic3defdr-demo-data/')\n&gt;&gt;&gt; h = HiC3DeFDR(\n...     raw_npz_patterns=[base_path + '&lt;rep&gt;/&lt;chrom&gt;_raw.npz'.replace('&lt;rep&gt;', repname) for repname in repnames],\n...     bias_patterns=[base_path + '&lt;rep&gt;/&lt;chrom&gt;_kr.bias'.replace('&lt;rep&gt;', repname) for repname in repnames],\n...     chroms=chroms,\n...     design=design,\n...     outdir='output',\n...     loop_patterns={c: base_path + 'clusters/%s_&lt;chrom&gt;_clusters.json' % c for c in ['ES', 'NPC']},\n...     res=10000\n... )\ncreating directory output\n</code></pre>\n<p>This object saves itself to disk, so it can be re-loaded at any time:</p>\n<pre><code>&gt;&gt;&gt; h = HiC3DeFDR.load('output')\n</code></pre>\n<p>To run the analysis for all chromosomes through q-values, run:</p>\n<pre><code>&gt;&gt;&gt; h.run_to_qvalues()\n</code></pre>\n<p>To threshold, cluster, and classify the significantly differential loops, and\ncollect all the results into a single TSV output file, run:</p>\n<pre><code>&gt;&gt;&gt; h.collect()\n</code></pre>\n<p>The output file will be written to <code>output/results_0.01_3.tsv</code>, where \"output\"\nrefers to the <code>outdir</code> we passed when constructing the <code>HiC3DeFDR</code> object,\n\"0.01\" refers to the default FDR of 1%, and \"3\" refers to the default cluster\nsize threshold of 3.</p>\n<pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; pd.read_csv('output/results_0.05_3.tsv', sep='\\t', index_col=0).head()\n                                            us_chrom  ...  classification\nloop_id                                               ...                \nchr18:3480000-3500000_chr18:4680000-4710000    chr18  ...    constitutive\nchr18:3490000-3510000_chr18:3790000-3810000    chr18  ...              ES\nchr18:3490000-3510000_chr18:3970000-3990000    chr18  ...    constitutive\nchr18:3490000-3510000_chr18:4170000-4200000    chr18  ...    constitutive\nchr18:3490000-3520000_chr18:4120000-4150000    chr18  ...    constitutive\n&lt;BLANKLINE&gt;\n[5 rows x 9 columns]\n</code></pre>\n<p>See the section \"TSV output format\" below for more details about the output\nformat.</p>\n<h2>Step-by-step walkthrough</h2>\n<p>Calling <code>h.run_to_qvalues()</code> runs the four main steps of the analysis in\nsequence. These four steps are described in further detail below. Any kwargs\npassed to <code>h.run_to_qvalues()</code> will be passed along to the appropriate step; see\n<code>help(HiC3DeFDR.run_to_qvalues)</code> for details.</p>\n<h3>Step 1: Preparing input data</h3>\n<p>The function call <code>h.prepare_data()</code> prepares the input raw contact matrices and\nbias vectors specified by <code>h.raw_npz_patterns</code> and <code>h.bias_patterns</code> for all\nchromosomes specified in <code>h.chroms</code>, performs library size normalization, and\ndetermines what points should be considered for dispersion estimation. This\ncreates intermediate files in the output directory <code>h.outdir</code> that represent the\nraw and scaled values, as well as the estimated size factors, and a boolean\nvector <code>disp_idx</code> indicating which points will be used for dispersion\nestimation. If <code>loop_patterns</code> was passed to the constructor, an additional\nboolean vector <code>loop_idx</code> is created to mark which points that pass <code>disp_idx</code>\nlie within looping interactions specified by <code>h.loop_patterns</code>. The raw and\nscaled data are stored in a rectangular matrix format where each row is a pixel\nof the contact matrix and each column is a replicate. If the size factors are\nestimated as a function of distance, the estimated size factors are also stored\nin this format. Two separate vectors called <code>row</code> and <code>col</code> are used to store\nthe row and column index of the pixel represented by each row of the rectangular\nmatrices. Together, the <code>row</code> and <code>col</code> vectors plus any of the rectangular\nmatrices represent a generalization of a COO format sparse matrix to multiple\nreplicates (in the standard COO format the <code>row</code> and <code>col</code> vectors are\ncomplemented by a single <code>value</code> vector).</p>\n<p>The size factors can be estimated with a variety of methods defined in the\n<code>hic3defdr.scaling</code> module. The method to use is specified by the <code>norm</code> kwarg\npassed to <code>h.prepare_data()</code>. Some of these methods estimate size factors as a\nfunction of interaction distance, instead of simply estimating one size factor\nfor each replicate as is common in RNA-seq differential expression analysis.\nWhen these methods are used, the number of bins to use when binning distances\nfor distance-based estimation of the size factors can be specified with the\n<code>n_bins</code> kwarg. The defaults for this function use the conditional median of\nratios approach (<code>hic3defdr.scaling.conditional_mor</code>) and an\nautomatically-selected number of bins.</p>\n<h3>Step 2: Estimating dispersions</h3>\n<p>The function call <code>h.estimate_disp()</code> estimates the dispersion parameters at\neach distance scale in the data and fits a lowess curve through the graph of\ndistance versus dispersion to obtain final smoothed dispersion estimates for\neach pixel.</p>\n<p>The <code>estimator</code> kwarg on <code>h.estimate_disp()</code> specifies which dispersion\nestimation method to use, out of a selection of options defined in the\n<code>hic3defdr.dispersion</code> module. The default is to use quantile-adjusted\nconditional maximum likelihood (qCML).</p>\n<h3>Step 3: Likelihood ratio test</h3>\n<p>The function call <code>h.lrt()</code> performs a likelihood ratio test (LRT) for each\npixel. This LRT compares a null model of no differential expression (fitting one\ntrue mean parameter shared by all replicates irrespective of condition) to an\nalternative model in which the two conditions have different true mean\nparameters.</p>\n<h3>Step 4: False discovery rate (FDR) control</h3>\n<p>The function call <code>h.bh()</code> performs Benjamini-Hochberg FDR correction on the\np-values called via the LRT in the previous step, considering only a subset of\npixels that are involved in looping interactions (as specified by\n<code>h.loop_patterns</code>; if <code>loop_patterns</code> was not passed to the constructor then all\npixels are included in the BH-FDR correction). This results in final q-values\nfor each loop pixel.</p>\n<h3>Thresholding, clustering, and classification</h3>\n<p>We can threshold, cluster, classify, and collect the significantly differential\nloops:</p>\n<pre><code>&gt;&gt;&gt; h.collect(fdr=0.05, cluster_size=3)\n</code></pre>\n<p>We can also sweep across FDR and/or cluster size thresholds:</p>\n<pre><code>&gt;&gt;&gt; h.collect(fdr=[0.01, 0.05], cluster_size=[3, 4])\n</code></pre>\n<p>The final output file for each combination of thresholding parameters will be\nwritten to <code>&lt;h.outdir&gt;/results_&lt;fdr&gt;_&lt;cluster_size&gt;.tsv</code>.</p>\n<p>This example walkthrough should take less than 5 minutes for the two chromosomes\nincluded in the demo data. Run time for a whole-genome analysis will depend on\nparallelization as discussed in the next section.</p>\n<h2>Parallelization</h2>\n<p>The functions <code>run_to_qvalues()</code>, <code>prepare_data()</code>, <code>lrt()</code>, <code>threshold()</code>,\n<code>classify()</code>, and <code>simulate()</code> operate in a per-chromosome manner. By default,\neach chromosome in the dataset will be processed in series. If multiple cores\nand sufficient memory are available, you can use the <code>n_threads</code> kwarg on these\nfunctions to use multiple subprocesses to process multiple chromosomes in\nparallel. Pass either a desired number of subprocesses to use, or pass\n<code>n_threads=-1</code> to use all available cores. The output logged to stderr will be\ntruncated to reduce clutter from multiple subprocesses printing to stderr at the\nsame time. This truncation is controlled by the <code>verbose</code> kwarg which is\navailable on some of these parallelized functions.</p>\n<p>The function <code>estimate_disp()</code> also accepts an <code>n_threads</code> kwarg, using it to\nparallelize itself across distance scales.</p>\n<p>The function <code>run_to_qvalues()</code> passes the <code>n_threads</code> kwarg through to all the\nsteps it calls.</p>\n<h2>Intermediates and final output files</h2>\n<p>All intermediates used in the computation will be saved to the disk inside the\n<code>outdir</code> folder as <code>&lt;intermediate&gt;_&lt;chrom&gt;.npy</code> (most intermediates),\n<code>&lt;intermediate&gt;_&lt;chrom&gt;.json</code>/<code>&lt;intermediate&gt;_&lt;chrom&gt;.tsv</code> (thresholded or\nclassified clusters).</p>\n<p>Two intermediates are not generated per chromosome. These are\n<code>disp_fn_&lt;c&gt;.pickle</code> (dispersion function estimated across all chromosomes for\ncondition <code>&lt;c&gt;</code>) and <code>results_&lt;f&gt;_&lt;s&gt;.tsv</code> (final combined results from all\nchromosomes).</p>\n<table>\n<thead>\n<tr>\n<th>Step</th>\n<th>Intermediate</th>\n<th>Shape</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>row</code></td>\n<td><code>(n_pixels,)</code></td>\n<td>Top-level row index</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>col</code></td>\n<td><code>(n_pixels,)</code></td>\n<td>Top-level column index</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>bias</code></td>\n<td><code>(n_bins, n_reps)</code></td>\n<td>Bias vectors</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>raw</code></td>\n<td><code>(n_pixels, n_reps)</code></td>\n<td>Raw count values</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>size_factors</code></td>\n<td><code>(n_reps,)</code> or <code>(n_pixels, n_reps)</code></td>\n<td>Size factors</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>scaled</code></td>\n<td><code>(n_pixels, n_reps)</code></td>\n<td>Normalized count values</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>disp_idx</code></td>\n<td><code>(n_pixels,)</code></td>\n<td>Marks pixels for which dispersion is fitted</td>\n</tr>\n<tr>\n<td><code>prepare_data()</code></td>\n<td><code>loop_idx</code></td>\n<td><code>(disp_idx.sum(),)</code></td>\n<td>Marks pixels which lie in loops</td>\n</tr>\n<tr>\n<td><code>estimate_disp()</code></td>\n<td><code>cov_per_bin</code></td>\n<td><code>(n_bins, n_conds)</code></td>\n<td>Average mean count or distance in each bin</td>\n</tr>\n<tr>\n<td><code>estimate_disp()</code></td>\n<td><code>disp_per_bin</code></td>\n<td><code>(n_bins, n_conds)</code></td>\n<td>Pooled dispersion estimates in each bin</td>\n</tr>\n<tr>\n<td><code>estimate_disp()</code></td>\n<td><code>disp_fn_&lt;c&gt;</code></td>\n<td>pickled function</td>\n<td>Fitted dispersion function</td>\n</tr>\n<tr>\n<td><code>estimate_disp()</code></td>\n<td><code>disp</code></td>\n<td><code>(disp_idx.sum(), n_conds)</code></td>\n<td>Smoothed dispersion estimates</td>\n</tr>\n<tr>\n<td><code>lrt()</code></td>\n<td><code>mu_hat_null</code></td>\n<td><code>(disp_idx.sum(),)</code></td>\n<td>Null model mean parameters</td>\n</tr>\n<tr>\n<td><code>lrt()</code></td>\n<td><code>mu_hat_alt</code></td>\n<td><code>(disp_idx.sum(), n_conds)</code></td>\n<td>Alternative model mean parameters</td>\n</tr>\n<tr>\n<td><code>lrt()</code></td>\n<td><code>llr</code></td>\n<td><code>(disp_idx.sum(),)</code></td>\n<td>Log-likelihood ratio</td>\n</tr>\n<tr>\n<td><code>lrt()</code></td>\n<td><code>pvalues</code></td>\n<td><code>(disp_idx.sum(),)</code></td>\n<td>LRT-based p-value</td>\n</tr>\n<tr>\n<td><code>bh()</code></td>\n<td><code>qvalues</code></td>\n<td><code>(loop_idx.sum(),)</code></td>\n<td>BH-corrected q-values</td>\n</tr>\n<tr>\n<td><code>threshold()</code></td>\n<td><code>sig_&lt;f&gt;_&lt;s&gt;</code></td>\n<td>JSON/TSV</td>\n<td>Significantly differential clusters</td>\n</tr>\n<tr>\n<td><code>threshold()</code></td>\n<td><code>insig_&lt;f&gt;_&lt;s&gt;</code></td>\n<td>JSON/TSV</td>\n<td>Constitutive clusters</td>\n</tr>\n<tr>\n<td><code>classify()</code></td>\n<td><code>&lt;c&gt;_&lt;f&gt;_&lt;s&gt;</code></td>\n<td>JSON/TSV</td>\n<td>Classified differential clusters</td>\n</tr>\n<tr>\n<td><code>collect()</code></td>\n<td><code>results_&lt;f&gt;_&lt;s&gt;</code></td>\n<td>TSV</td>\n<td>Final results table</td>\n</tr></tbody></table>\n<p>The table uses these abbreviations to refer to variable parts of certain\nintermediate names:</p>\n<ul>\n<li><code>&lt;f&gt;</code>: FDR threshold</li>\n<li><code>&lt;s&gt;</code>: cluster size threshold</li>\n<li><code>&lt;c&gt;</code>: condition/class label</li>\n</ul>\n<h2>Sparse JSON cluster format</h2>\n<p>This is the format used both for supplying pre-identified, per-condition loop\nclusters as input to HiC3DeFDR as well as the format in which differential and\nconstitutive interaction clusters are reported as output.</p>\n<p>The format describes the clusters on each chromosome in a separate JSON file.\nThis JSON file contains a single JSON object, which is a list of list of list of\nintegers. The inner lists are all of length 2 and represent specific pixels of\nthe heatmap for that chromosome in terms of there row and column coordinates in\nzero-indexed bin units. The outer middle lists can be of any length and\nrepresent groups of pixels that belong to the same cluster. The length of the\nouter list corresponds to the number of clusters on that chromosome.</p>\n<p>These clusters can be loaded into and written from the corresponding plain\nPython objects using <code>hic3defdr.clusters.load_clusters()</code> and\n<code>hic3defdr.clusters.save_clusters()</code>, respectively. The plain Python objects can\nbe converted to and from scipy sparse matrix objects using\n<code>hic3defdr.clusters.clusters_to_coo()</code> and\n<code>hic3defdr.clusters.convert_cluster_array_to_sparse()</code>, respectively.</p>\n<h2>TSV output format</h2>\n<p>The final TSV output file <code>results_&lt;f&gt;_&lt;s&gt;.tsv</code> has as its first column a\n<code>loop_id</code>, a string of the form\n<code>&lt;us_chrom&gt;:&lt;us_start&gt;-&lt;us_end&gt;_&lt;ds_chrom&gt;:&lt;ds_start&gt;-&lt;ds_end&gt;</code> specifying a\nrectangle that surrounds the cluster of pixels that make up the loop. The next\nsix columns are the six individual pieces of this <code>loop_id</code>. This is followed\nby:</p>\n<ul>\n<li><code>cluster_size</code>: the number of pixels in the cluster</li>\n<li><code>cluster</code>: a list of the exact (row, col) indices of the pixels in the\ncluster</li>\n<li><code>classification</code>: this will be \"constitutive\" if the loop is not\ndifferential, or the name of the condition the loop is specific to (i.e.,\nstrongest in) if it is differential</li>\n</ul>\n<h2>Visualizations</h2>\n<p>The <code>HiC3DeFDR</code> object can be used to draw visualizations of the analysis.</p>\n<p>The visualization functions are wrapped with the <a href=\"https://lib5c.readthedocs.io/en/latest/plotting/\" rel=\"nofollow\">@plotter decorator</a>\nand therefore all support the convenience kwargs provided by that decorator\n(such as <code>outfile</code>).</p>\n<h3>Distance dependence curves before and after scaling</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_dd_curves('chr18', outfile='images/dd.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4375c5b26a77c145dd58ae8cf925b5fc04f392a5/696d616765732f64642e706e67\"></p>\n<h3>Simple heatmap plotting</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_heatmap('chr18', slice(1000, 1100), slice(1000, 1100), rep='ES_1',\n...                    outfile='images/heatmap.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a1fb98b9e753405b3517133327f89fab060f7566/696d616765732f686561746d61702e706e67\"></p>\n<p>By default, this plots data at the \"scaled\" stage (normalized for bias and\nsequencing depth differences), but you can plot any stage of the data by passing\na <code>stage</code> kwarg.</p>\n<h3>Condition-average heatmap plotting</h3>\n<p>To plot a within-condition average heatmap, pass a <code>stage</code> name with a '_mean'\nsuffix appended and <code>cond</code> to specify the condition to average within:</p>\n<pre><code>&gt;&gt;&gt; _ = h.plot_heatmap('chr18', slice(1000, 1100), slice(1000, 1100),\n...                    stage='scaled_mean', cond='ES',\n...                    outfile='images/heatmap_mean.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d9c6400b3de5360af61b47c508c67ae75100b2e9/696d616765732f686561746d61705f6d65616e2e706e67\"></p>\n<h3>Loop zoomin heatmap plotting</h3>\n<p>We can combine <code>h.plot_heatmap()</code> with the <code>load_clusters()</code> and\n<code>cluster_to_slices()</code> utility functions in <code>hic3defdr.util.clusters</code> to plot\nzoomins around specific loops:</p>\n<pre><code>&gt;&gt;&gt; from hic3defdr.util.clusters import load_clusters, cluster_to_slices\n&gt;&gt;&gt; chrom = 'chr18'\n&gt;&gt;&gt; clusters = load_clusters(h.loop_patterns['ES'].replace('&lt;chrom&gt;', chrom))\n&gt;&gt;&gt; slices = cluster_to_slices(clusters[23])\n&gt;&gt;&gt; _ = h.plot_heatmap(chrom, *slices, rep='ES_1', outfile='images/zoomin.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c474beff4e537b91ec87241ccd67da6d0216d541/696d616765732f7a6f6f6d696e2e706e67\"></p>\n<h3>Per-pixel significance plotting</h3>\n<p>We can pass <code>stage='qvalues'</code> to <code>h.plot_heatmap()</code> to draw heatmaps showing the\nsignificance of each pixel:</p>\n<pre><code>&gt;&gt;&gt; _ = h.plot_heatmap('chr18', slice(1310, 1370), slice(1310, 1370),\n...                    stage='qvalues', cmap='bwr_r', vmin=0.099, vmax=0.101,\n...                    outfile='images/heatmap_sig.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f6d17ba0ac205e2f3b7f64b35b7edc620d5cf00b/696d616765732f686561746d61705f7369672e706e67\"></p>\n<p>By passing <code>cmap='bwr_r'</code> we ensure that significant, low q-value pixels will be\nred while insignificant, high q-value pixels will be blue. By passing\n<code>vmin=0.099, vmax=0.101</code>, we ensure that the colorbar is focused on a narrow\nrange around an FDR threshold of 10%, allowing us to more easily tell the\ndifference between significant and insignificant pixels.</p>\n<h3>Correlation matrices</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_correlation_matrix(outfile='images/correlation.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/775fdcbe110181db7d0ff4258f908197c0b95616/696d616765732f636f7272656c6174696f6e2e706e67\"></p>\n<h3>Dispersion fitting</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_dispersion_fit('ES', outfile='images/ddr.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d1a7f2575f76aa7b99a6d1ee9678956c8740a4cb/696d616765732f6464722e706e67\"></p>\n<p>It's possible to use the the one-dimensional distance dependence curve to\nconvert distances to means. Doing so allows plotting the y-axis in terms of\nvariance. You can do this by passing <code>yaxis='var'</code>:</p>\n<pre><code>&gt;&gt;&gt; _ = h.plot_dispersion_fit('ES', yaxis='var', outfile='images/dvr.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/835a28e1e843fb7a9e92d7266f2182022b6c8615/696d616765732f6476722e706e67\"></p>\n<p>Using the same trick, you can plot the x-axis in terms of mean by passing\n<code>xaxis='mean'</code>:</p>\n<pre><code>&gt;&gt;&gt; _ = h.plot_dispersion_fit('ES', xaxis='mean', yaxis='var',\n...                           outfile='images/mvr.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cc6b6ab335fd40e3d42f603aa849ccfe6f1d33f8/696d616765732f6d76722e706e67\"></p>\n<p>At low mean and high distance, the distance dependence curve flattens out and\nthe data become more noisy, making this conversion unreliable.</p>\n<p>It's also possible to show the dispersion fitted at just one distance scale,\noverlaying the sample mean and sample variance across replicates for each pixel\nas a blue hexbin plot:</p>\n<pre><code>&gt;&gt;&gt; _ = h.plot_dispersion_fit('ES', distance=25, hexbin=True, xaxis='mean',\n...                           yaxis='var', logx=True, logy=True,\n...                           outfile='images/mvr_25.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/be2d6340e479ce871001580e31c34156f5fff131/696d616765732f6d76725f32352e706e67\"></p>\n<p>If dispersion was fitted against distance rather than mean, pass <code>xaxis='dist'</code>\nto plot dispersion/variance versus distance.</p>\n<h3>Comparing dispersion fits</h3>\n<p>It's possible to compare different dispersion fits using the function\n<code>compare_disp_fits()</code> as shown here:</p>\n<pre><code>&gt;&gt;&gt; from hic3defdr import compare_disp_fits\n&gt;&gt;&gt;\n&gt;&gt;&gt; _ = compare_disp_fits(\n...     [h.load_disp_fn(cond) for cond in h.design.columns],\n...     h.design.columns,\n...     max_dist=100,\n...     outfile='images/disp_comparison.png'\n... )\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e99ed65492fc0b7087d07f2384436826b9880d1e/696d616765732f646973705f636f6d70617269736f6e2e706e67\"></p>\n<h3>P-value distribution</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_pvalue_distribution(outfile='images/pvalue_dist.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d06724304bd7ae4d48947e629ad35fd4bf8e38d5/696d616765732f7076616c75655f646973742e706e67\"></p>\n<p>By default, this plots the p-value distribution over all pixels for which\ndispersion was estimated. To plot the p-value distribution only over points in\nloops, pass <code>idx='loop'</code>.</p>\n<h3>Q-value distribution</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_qvalue_distribution(outfile='images/qvalue_dist.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57fe852dcb05310b67f8d526e65e0f279d087fd5/696d616765732f7176616c75655f646973742e706e67\"></p>\n<h3>MA plot</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_ma(outfile='images/ma.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ed5c51c634fb40332ca7e2f8ed2cef42946f22ee/696d616765732f6d612e706e67\"></p>\n<h3>Pixel detail grid</h3>\n<pre><code>&gt;&gt;&gt; _ = h.plot_grid('chr18', 2218, 2236, 20, outfile='images/grid.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7d656516bb222d815112bb7a170fa51c3755e480/696d616765732f677269642e706e67\"></p>\n<p>The upper right heatmaps show the balanced and scaled values in each replicate,\nwith each condition on its own row.</p>\n<p>The upper left heatmaps show the alternative model mean parameter estimates for\neach condition. Significantly differential clusters are purple while\nconstitutive ones are gray.</p>\n<p>The lower left heatmap shows the q-values. Significantly differential clusters\nare orange while constitutive ones are gray.</p>\n<p>The stripplots in the lower left show details information about the specific\npixel in the center of the heatmaps (in this example <code>(2218, 2236)</code>). The dots\nshow the values at that pixel for each replicate in normalized and raw space,\nrepsectively. The solid and dashed lines represent the mean parameters under the\nalt and null models, repsectively.</p>\n<p>Green points in the heatmaps represent points that have been filtered out. For\nthe per-replicate heatmaps in the upper right of the grid, the only filters\napplied are the zero filter, bias filter, and distance filter. For the alt model\nmean heatmaps in the upper left, this additionally includes the dispersion\nfilter. For the q-value heatmap in the lower left, it additionally includes the\nloop filter if loop locations were supplied.</p>\n<h3>Interactive thresholding</h3>\n<p>In a Jupyter notebook environment with <code>ipywidgets</code> installed, you can play with\nthresholds on a live-updating plot by running:</p>\n<pre><code>%matplotlib notebook\n\nfrom ipywidgets import interact\nfrom hic3defdr import HiC3DeFDR\n\nh = HiC3DeFDR.load('output')\n_, _, outline_clusters = h.plot_grid('chr18', 2218, 2236, 50)\n_ = interact(outline_clusters, fdr=[0.01, 0.05, 0.1, 0.2],\n             cluster_size=[3, 4])\n</code></pre>\n<h2>Simulation</h2>\n<p>After the <code>estimate_disp()</code> step has been run, a HiC3DeFDR object can be used to\ngenerate simulations of differential looping.</p>\n<h3>Generating simulations</h3>\n<p>To create an ES-based simulation over all chromosomes listed in <code>h.chroms</code>, we\nrun</p>\n<pre><code>&gt;&gt;&gt; from hic3defdr import HiC3DeFDR\n&gt;&gt;&gt;\n&gt;&gt;&gt; h = HiC3DeFDR.load('output')\n&gt;&gt;&gt; h.simulate('ES')\n</code></pre>\n<p>If we passed <code>trend='dist'</code> to <code>h.estimate_disp()</code>, we need to pass it to\n<code>h.simulate()</code> as well to ensure that the simulation function knows to treat the\npreviously-fitted dispersion function as a function of distance.</p>\n<p>This takes the mean of the real scaled data across the ES replicates and\nperturbs the loops specified in <code>h.loop_patterns['ES']</code> up or down at random to\ngenerate two new conditions called \"A\" and \"B\". The scaled mean matrices for\nthese conditions are then biased and scaled by the bias vectors and size factors\ntaken from the real experimental replicates, and the ES dispersion function\nfitted to the real ES data is applied to the biased and scaled means to obtain\ndispersion values. These means and dispersions are used to draw an NB random\nvariable for each pixel of each simulated replicate. The number of replicates in\neach of the simulated conditions \"A\" and \"B\" will match the design of the real\nanalysis.</p>\n<p>The simulated raw contact matrices will be written to disk in CSR format as\n<code>&lt;cond&gt;&lt;rep&gt;_&lt;chrom&gt;_raw.npz</code> where <code>&lt;cond&gt;</code> is \"A\" or \"B\" and <code>&lt;rep&gt;</code> is the\nrep number within the condition. The design matrix will also be written to disk\nas <code>design.csv</code>.</p>\n<p>The true labels used to perturb the loops will also be written to disk as\n<code>labels_&lt;chrom&gt;.txt</code>. This file contains as many lines as there are clusters in\n<code>h.loop_patterns['ES']</code>, with the <code>i</code>th line providing the label for the <code>i</code>th\ncluster. This file can be loaded with <code>np.loadtxt(..., dtype='|S7')</code>.</p>\n<h3>Evaluating simulations</h3>\n<p>After generating simulated data, HiC3DeFDR can be run on the simulated data.\nThen, the true labels can be used to evaluate the performance of HiC3DeFDR on\nthe simulated data.</p>\n<p>Evaluation of simulated data requires scikit-learn. To install this package, run</p>\n<pre><code>(venv)$ pip install scikit-learn\n</code></pre>\n<p>In order to run HiC3DeFDR on the simulated data, we first need to balance the\nsimulated raw contact matrices to obtain bias vectors for each simulated\nreplicate and chromosome. We will assume are saved next to the raw contact\nmatrices and named <code>&lt;rep&gt;_&lt;chrom&gt;_kr.bias</code>. One example of how this can be done\nis shown in the following script:</p>\n<pre><code>&gt;&gt;&gt; import sys\n&gt;&gt;&gt;\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scipy.sparse as sparse\n&gt;&gt;&gt;\n&gt;&gt;&gt; from hic3defdr.util.filtering import filter_sparse_rows_count\n&gt;&gt;&gt; from hic3defdr.util.balancing import kr_balance\n&gt;&gt;&gt; from hic3defdr.util.printing import eprint\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; infile_pattern = 'sim/&lt;rep&gt;_&lt;chrom&gt;_raw.npz'\n&gt;&gt;&gt; repnames = ['A1', 'A2', 'B1', 'B2']\n&gt;&gt;&gt; chroms = ['chr18', 'chr19']\n&gt;&gt;&gt;\n&gt;&gt;&gt; for repname in repnames:\n...     for chrom in chroms:\n...         eprint('balancing rep %s chrom %s' % (repname, chrom))\n...         infile = infile_pattern.replace('&lt;rep&gt;', repname)\\\n...             .replace('&lt;chrom&gt;', chrom)\n...         outfile = infile.replace('_raw.npz', '_kr.bias')\n...         _, bias, _ = kr_balance(\n...             filter_sparse_rows_count(sparse.load_npz(infile)), fl=0)\n...         np.savetxt(outfile, bias)\n</code></pre>\n<p>Next, we create a new HiC3DeFDR object to analyze the simulated data and run the\nanalysis through to q-values:</p>\n<pre><code>&gt;&gt;&gt; import os.path\n&gt;&gt;&gt; from hic3defdr import HiC3DeFDR\n&gt;&gt;&gt;\n&gt;&gt;&gt; repnames = ['A1', 'A2', 'B1', 'B2']\n&gt;&gt;&gt; chroms = ['chr18', 'chr19']\n&gt;&gt;&gt; sim_path = 'sim/'\n&gt;&gt;&gt; base_path = os.path.expanduser('~/hic3defdr-demo-data/')\n&gt;&gt;&gt; h_sim = HiC3DeFDR(\n...     raw_npz_patterns=[sim_path + '&lt;rep&gt;_&lt;chrom&gt;_raw.npz'.replace('&lt;rep&gt;', repname) for repname in repnames],\n...     bias_patterns=[sim_path + '&lt;rep&gt;_&lt;chrom&gt;_kr.bias'.replace('&lt;rep&gt;', repname) for repname in repnames],\n...     chroms=chroms,\n...     design=sim_path + 'design.csv',\n...     outdir='output-sim',\n...     loop_patterns={'ES': base_path + 'clusters/ES_&lt;chrom&gt;_clusters.json'}\n... )\ncreating directory output-sim\n&gt;&gt;&gt; h_sim.run_to_qvalues()\n</code></pre>\n<p>Next, we can evaluate the simulation against the clusters in\n<code>h_sim.loop_patterns['ES']</code> with true labels from <code>sim/labels_&lt;chrom&gt;.txt</code>:</p>\n<pre><code>&gt;&gt;&gt; h_sim.evaluate('ES', 'sim/labels_&lt;chrom&gt;.txt')\n</code></pre>\n<p>This writes a file in <code>h_sim</code>'s output directory called <code>eval.npz</code>. This file\ncan be loaded with <code>np.load()</code> and has four keys whose values are all one\ndimensional vectors:</p>\n<ul>\n<li><code>'thresh'</code>: the thresholds (in <code>1 - qvalue</code> space) which make up the convex\nedge of the ROC curve; all other vectors are parallel to this one</li>\n<li><code>'fdr'</code>: the observed false discovery rate at each threshold</li>\n<li><code>'tpr'</code>: the observed true positive rate at each threshold</li>\n<li><code>'fpr'</code>: the observed false positive rate at each threshold</li>\n</ul>\n<p><code>eval.npz</code> files (possibly across many runs) can be visualized as ROC curves and\nFDR control curves by running:</p>\n<pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from hic3defdr import plot_roc, plot_fdr\n&gt;&gt;&gt;\n&gt;&gt;&gt; _ = plot_roc([np.load('output-sim/eval.npz')], ['hic3defdr'], outfile='images/roc.png')\n&gt;&gt;&gt; _ = plot_fdr([np.load('output-sim/eval.npz')], ['hic3defdr'], outfile='images/fdr.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/18c474bcd14244086e0ead8e0e0d4baa6cb73132/696d616765732f726f632e706e67\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e8fa08a4d992a0d55398adafc37a44f355e0a461/696d616765732f6664722e706e67\"></p>\n<p>Multiple <code>eval.npz</code> files can be compared in the same plot by simply adding\nelements to the lists in these function calls.</p>\n<p>The ROC plot shows FPR versus TPR, with the gray diagonal line representing the\nperformance of random guessing. The AUROC for each curve is shown in the legend.\nIf only one curve is plotted, selected thresholds (in units of FDR threshold)\nare annotated with black arrows.</p>\n<p>The FDR control plot shows the observed FDR as a function of the FDR threshold.\nPoints below the gray diagonal line represent points at which FDR is\nsuccessfully controlled.</p>\n<p>As an added bonus, it's also possible to evaluate the performance on specific\nsubsets of distance scales by using the <code>min_dist</code> and <code>max_dist</code> kwargs on\n<code>HiC3DeFDR.evaluate()</code> as illustrated below:</p>\n<pre><code>&gt;&gt;&gt; dist_bins = [\n...    ('short', (None, 15)),  # distances in bin units\n...    ('mid', (16, 30)),\n...    ('long', (31, None))\n... ]\n&gt;&gt;&gt; for _, (min_dist, max_dist) in dist_bins:\n...     h_sim.evaluate('ES', 'sim/labels_&lt;chrom&gt;.txt', min_dist=min_dist,\n...                    max_dist=max_dist)\n&gt;&gt;&gt; _ = plot_roc([np.load('output-sim/eval_%s_%s.npz' % (min_dist, max_dist))\n...               for _, (min_dist, max_dist) in dist_bins],\n...              [label for label, _ in dist_bins],\n...              outfile='images/roc_by_dist.png')\n&gt;&gt;&gt; _ = plot_fdr([np.load('output-sim/eval_%s_%s.npz' % (min_dist, max_dist))\n...               for _, (min_dist, max_dist) in dist_bins],\n...              [label for label, _ in dist_bins],\n...              outfile='images/fdr_by_dist.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e592f8f99c132c2de5dbdbf224f74d2cb580366c/696d616765732f726f635f62795f646973742e706e67\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9fb2fa55a48e166f6c800caa93d8680ca04b4951/696d616765732f6664725f62795f646973742e706e67\"></p>\n<p>It's also possible to compare the FPR and FNR at the different subsets:</p>\n<pre><code>&gt;&gt;&gt; from hic3defdr import plot_fn_vs_fp\n&gt;&gt;&gt;\n&gt;&gt;&gt; _ = plot_fn_vs_fp([np.load('output-sim/eval_%s_%s.npz' % (min_dist, max_dist))\n...                    for _, (min_dist, max_dist) in dist_bins],\n...                   [label for label, _ in dist_bins], xlabel='distance subset',\n...                   outfile='images/fn_vs_fp.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ee5fa2185fe1600e85a6b47e39423809cc8bab58/696d616765732f666e5f76735f66702e706e67\"></p>\n<h2>Other visualizations</h2>\n<h3>Distance bias</h3>\n<p>We can visualize and compare the distance bias of different simulations (the\ndegree to which low p-values are enriched or depleted in different distance\nscales) using the <code>plot_distance_bias()</code> function as shown below:</p>\n<pre><code>&gt;&gt;&gt; from hic3defdr import plot_distance_bias\n&gt;&gt;&gt;\n&gt;&gt;&gt; dist_bins = [\n...    ('short', (None, 15)),  # distances in bin units\n...    ('mid', (16, 30)),\n...    ('long', (31, None))\n... ]\n&gt;&gt;&gt; _ = plot_distance_bias([h, h_sim], [b for _, b in dist_bins], labels=['real', 'sim'], outfile='images/distance_bias.png')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6893e3e6d431674fe1d36002ba3b96d131ce19e1/696d616765732f64697374616e63655f626961732e706e67\"></p>\n<h2>Package structure</h2>\n<p>The <code>hic3defdr</code> package is layed out in three parts:</p>\n<ol>\n<li><code>hic3defdr.util</code>: library of re-usable functions for performing computations\nrelated to differential loop calling</li>\n<li><code>hic3defdr.plotting</code>: library of re-usable functions to plotting\nvisualizations related to differential loop calling</li>\n<li><code>hic3defdr.analysis</code>: a module that defines the HiC3DeFDR class, which\nprovides an implementation of stitching together all the computational steps\nand visualizations in an easy-to-use way</li>\n</ol>\n<p>The HiC3DeFDR class includes many methods, so to keep things organized these\nmethods are defined in four separate mixin classes which are combined to form\nthe full HiC3DeFDR class in <code>hic3defdr/analysis/constructor.py</code>:</p>\n<ul>\n<li><code>hic3defdr.analysis.core.CoreHiC3DeFDR</code></li>\n<li><code>hic3defdr.analysis.analysis.AnalyzingHiC3DeFDR</code></li>\n<li><code>hic3defdr.analysis.simulation.SimulatingHiC3DeFDR</code></li>\n<li><code>hic3defdr.analysis.plotting.PlottingHiC3DeFDR</code></li>\n</ul>\n<p>We recommend that most users simply import the HiC3DeFDR class and interact with\nthis package through that interface, but the functions defined in\n<code>hic3efdr.util</code> and <code>hic3defdr.plotting</code> may also be useful to some users and\nare designed to be somewhat re-usable.</p>\n<p>The complete layout of the package is summarized below:</p>\n<pre><code>hic3defdr/                      # package root\n\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac _version.py                 # version configuration\n\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac analysis/                   # HiC3DeFDR class and alternatives\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac alternatives.py         # defines alternative analysis models\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac analysis.py             # HiC3DeFDR's pipeline methods\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac constructor.py          # HiC3DeFDR's class definition and constructor\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac core.py                 # HiC3DeFDR's core save/load methods\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac plotting.py             # HiC3DeFDR's plotting methods\n\u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac simulation.py           # HiC3DeFDR's simulation/evaluation methods\n\u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac plotting/                   # library of plotting functions\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac dispersion.py           # dispersion/variance fit visualizations\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac distance_bias.py        # distance bias comparison barplots\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac distance_dependence.py  # distance dependence curve comparison\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac fdr.py                  # FDR control curve plotting\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac fn_vs_fp.py             # FN vs FP tradeoff barplots\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac grid.py                 # \"pixel detail grid\" combination visualization\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac heatmap.py              # simple contact matrix heatmap plotting\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac histograms.py           # p-value/q-value histograms\n\u00e2\u201d\u201a   \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac ma.py                   # MA plots\n\u00e2\u201d\u201a   \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac roc.py                  # ROC curve plots\n\u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac util/                       # library of utility functions \n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac binning.py              # creating groups of points\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac balancing.py            # KR matrix balancing\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac banded_matrix.py        # BandedMatrix class (used for filtering)\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac classification.py       # classifying differential loop pixels\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac cluster_table.py        # creating tables summarizing cluster info\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac clusters.py             # interacting with called loop clusters\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac demo_data.py            # utilities for downloading the demo dataset\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac dispersion.py           # estimating dispersions in NB data\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac evaluation.py           # evaluating results of simulations\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac filtering.py            # filtering (applied before balancing)\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac lowess.py               # lowess fitting\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac lrt.py                  # NB likelihood ratio testing\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac matrices.py             # interacting with sparse matrices\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac parallelization.py      # parallelizing work across cores\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac printing.py             # printing updates and info to the console\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac progress.py             # showing progress bars\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac scaled_nb.py            # dealing with scaling factors in NB\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac scaling.py              # scaling reps to account for sequencing depth\n    \u00e2\u201d\u0153\u00e2\u201d\u20ac\u00e2\u201d\u20ac simulation.py           # simulating pseudoreplicates\n    \u00e2\u201d\u201d\u00e2\u201d\u20ac\u00e2\u201d\u20ac thresholding.py         # thresholding differential pixels/clusters\n</code></pre>\n<h2>Additional options</h2>\n<p>Additional options are exposed as kwargs on the functions in this library. Use\n<code>help(&lt;function&gt;)</code> to get detailed information about the options available for\nany function and what these options may be used for.</p>\n<h2>Testing</h2>\n<p>We run our tests with <a href=\"https://tox.readthedocs.io\" rel=\"nofollow\">tox</a>. To execute tests,\ninstall tox (<code>pip install tox</code>) and then run <code>tox</code> to run all tests or\n<code>tox -e &lt;testenv&gt;</code> to run a specific test environment. See <code>tox.ini</code> for the\nfull specification of all test environments.</p>\n\n          </div>"}, "last_serial": 7160150, "releases": {"0.0.9": [{"comment_text": "", "digests": {"md5": "783017a83eb4ad66e901907f79aae87f", "sha256": "b9ec820d73a386055af9ac399684dc90a9a20dd982168dc6f63c620345fef791"}, "downloads": -1, "filename": "hic3defdr-0.0.9-py2-none-any.whl", "has_sig": false, "md5_digest": "783017a83eb4ad66e901907f79aae87f", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 88872, "upload_time": "2020-02-12T06:25:38", "upload_time_iso_8601": "2020-02-12T06:25:38.150256Z", "url": "https://files.pythonhosted.org/packages/f8/c9/da6db7682c60b7ee7517460c53b07507e31b3e3e64cd4098cd9fb3df94d3/hic3defdr-0.0.9-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3a11dc7c61ceb0dbb245afd609fb1ec8", "sha256": "fba2ae4a800b6ea254dc2734205aa24f8398d64deadb460500bbeb6a944976c7"}, "downloads": -1, "filename": "hic3defdr-0.0.9.tar.gz", "has_sig": false, "md5_digest": "3a11dc7c61ceb0dbb245afd609fb1ec8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79084, "upload_time": "2020-02-12T06:25:36", "upload_time_iso_8601": "2020-02-12T06:25:36.003059Z", "url": "https://files.pythonhosted.org/packages/7c/e9/d537834f33596b360e8c1c3f88533bfb6e1b01db3c6689481fe76f97a72d/hic3defdr-0.0.9.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "b69c2b4439af59d90682b107bbad47b2", "sha256": "835c3793ef01e7a4bd2165d3756506c477fdf2ad1433dae74c7669397effb2c9"}, "downloads": -1, "filename": "hic3defdr-0.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "b69c2b4439af59d90682b107bbad47b2", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 103676, "upload_time": "2020-02-12T06:36:41", "upload_time_iso_8601": "2020-02-12T06:36:41.928856Z", "url": "https://files.pythonhosted.org/packages/f4/d1/82c0156223ee30bb55c7273229daa58ee36e23064b236b0a21cc52e28639/hic3defdr-0.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f6be1b9dc0be1c13d7829e86e299cf1a", "sha256": "3bed47c5e14f1681298aa5c22490bb45d31c8c641588f77cf685f346c6779a2c"}, "downloads": -1, "filename": "hic3defdr-0.1.0.tar.gz", "has_sig": false, "md5_digest": "f6be1b9dc0be1c13d7829e86e299cf1a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 98568, "upload_time": "2020-02-12T06:36:43", "upload_time_iso_8601": "2020-02-12T06:36:43.436993Z", "url": "https://files.pythonhosted.org/packages/1f/79/9894960a4a64825123ad1d2cd572539bd2e38a95f6e4c5a2df616b6d5982/hic3defdr-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "59dffd8a4f32f687b62a29e94ae844e8", "sha256": "65e668036dd8e6f223d524f064bab213ca516509118f16cf0d878373359483f9"}, "downloads": -1, "filename": "hic3defdr-0.1.1-py2-none-any.whl", "has_sig": false, "md5_digest": "59dffd8a4f32f687b62a29e94ae844e8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 79369, "upload_time": "2020-03-13T10:49:12", "upload_time_iso_8601": "2020-03-13T10:49:12.587240Z", "url": "https://files.pythonhosted.org/packages/4e/55/aa4b7a4aaa494adcc48c69da88d865347d37dfe9d64ef4afe28aa67c48fa/hic3defdr-0.1.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b4234e73991ba8d4cac66ab85afae52c", "sha256": "a65a119d7c97e8f3f036175b6c2c61c26388fc28e27ea806e2da69596abf8ae4"}, "downloads": -1, "filename": "hic3defdr-0.1.1.tar.gz", "has_sig": false, "md5_digest": "b4234e73991ba8d4cac66ab85afae52c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 790818, "upload_time": "2020-03-13T10:49:14", "upload_time_iso_8601": "2020-03-13T10:49:14.412893Z", "url": "https://files.pythonhosted.org/packages/2f/2d/37ccc0804499e4e8b84a06f5b92f8c9c0956d1344fbdd1735548d3c6fb71/hic3defdr-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "a2efa67727451661bf44f18a4de43bf5", "sha256": "d1e3d1a8b73b6acf8133a46ae2c757f6c155c86dc49e9af33c3cba3f9e491542"}, "downloads": -1, "filename": "hic3defdr-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a2efa67727451661bf44f18a4de43bf5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 91590, "upload_time": "2020-03-13T12:42:11", "upload_time_iso_8601": "2020-03-13T12:42:11.546833Z", "url": "https://files.pythonhosted.org/packages/b5/9f/b255b422f93228de8c04a2543b234265698bc52027b11b9004d9e37d67fc/hic3defdr-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0b71a9f3e227bbc2be3ed4c103e57657", "sha256": "9bd6a00d90a0119deaca945476686a719742761668499803b84843eec6a009b2"}, "downloads": -1, "filename": "hic3defdr-0.2.0.tar.gz", "has_sig": false, "md5_digest": "0b71a9f3e227bbc2be3ed4c103e57657", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 98056, "upload_time": "2020-03-13T12:42:13", "upload_time_iso_8601": "2020-03-13T12:42:13.096900Z", "url": "https://files.pythonhosted.org/packages/50/82/809c66918ee620690b24083c7dadf9ca8962e6f5b629c2680f3b4ab3cad2/hic3defdr-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "e69ea9870212c7c440301b65a793c65f", "sha256": "c906d2d498084d46dbd3a5389221f550964dd861624c1394384bac1c98ba1fee"}, "downloads": -1, "filename": "hic3defdr-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e69ea9870212c7c440301b65a793c65f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 93614, "upload_time": "2020-05-03T22:32:35", "upload_time_iso_8601": "2020-05-03T22:32:35.663703Z", "url": "https://files.pythonhosted.org/packages/ee/98/074ce2f9c2bf28d0a6c4bfec41eff8d56a947b38cebf67eed595ec0c2e92/hic3defdr-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c566c807417b32fde9770f865b59d24a", "sha256": "c4bd76a7cfbcbe5276d75cc909db6d670e2d77982262ed1b459a5a0bd32d53d6"}, "downloads": -1, "filename": "hic3defdr-0.2.1.tar.gz", "has_sig": false, "md5_digest": "c566c807417b32fde9770f865b59d24a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 100176, "upload_time": "2020-05-03T22:32:37", "upload_time_iso_8601": "2020-05-03T22:32:37.133330Z", "url": "https://files.pythonhosted.org/packages/5e/27/6c7ea268af925eb6a2647848bab92c47a34480de1605de351f147cbe3090/hic3defdr-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e69ea9870212c7c440301b65a793c65f", "sha256": "c906d2d498084d46dbd3a5389221f550964dd861624c1394384bac1c98ba1fee"}, "downloads": -1, "filename": "hic3defdr-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e69ea9870212c7c440301b65a793c65f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 93614, "upload_time": "2020-05-03T22:32:35", "upload_time_iso_8601": "2020-05-03T22:32:35.663703Z", "url": "https://files.pythonhosted.org/packages/ee/98/074ce2f9c2bf28d0a6c4bfec41eff8d56a947b38cebf67eed595ec0c2e92/hic3defdr-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c566c807417b32fde9770f865b59d24a", "sha256": "c4bd76a7cfbcbe5276d75cc909db6d670e2d77982262ed1b459a5a0bd32d53d6"}, "downloads": -1, "filename": "hic3defdr-0.2.1.tar.gz", "has_sig": false, "md5_digest": "c566c807417b32fde9770f865b59d24a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 100176, "upload_time": "2020-05-03T22:32:37", "upload_time_iso_8601": "2020-05-03T22:32:37.133330Z", "url": "https://files.pythonhosted.org/packages/5e/27/6c7ea268af925eb6a2647848bab92c47a34480de1605de351f147cbe3090/hic3defdr-0.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:18 2020"}