{"info": {"author": "Kumar Nityan Suman", "author_email": "nityan.suman@gmail.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.1", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "<p align=\"center\"><img src=\"data/logo.png?raw=true\" alt=\"LOGO\"/></p>\n\n<img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/tensorhub.svg?color=blue&style=flat\"> <img alt=\"PyPI - Python Version\" src=\"https://img.shields.io/pypi/pyversions/tensorhub.svg?style=flat\">  <img alt=\"GitHub code size in bytes\" src=\"https://img.shields.io/github/languages/code-size/nityansuman/tensorhub.svg?color=blue&style=flat\"> <img alt=\"PyPI - License\" src=\"https://img.shields.io/pypi/l/tensorhub.svg?style=flat\"> [![Codacy Badge](https://api.codacy.com/project/badge/Grade/d1e35c252db741b28144f5b7b9ffd7d2)](https://www.codacy.com/app/nityansuman/tensorhub?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=nityansuman/tensorhub&amp;utm_campaign=Badge_Grade)\n\n\n## You have just found TensorHub.\n\nThe open source library to help you develop and train ML models, easy and fast as never before with `TensorFlow 2.0`.\n`TensorHub` is a global collection of `building blocks` and `ready to serve models`.\n\nIt is a wrapper library of deep learning models and neural lego blocks designed to make deep learning more accessible and accelerate ML research.\n\nUse `TensorHub` if you need a deep learning library that:\n\n+ **Reproducibility** - Reproduce the results of existing pre-training models (such as Google BERT, XLNet)\n\n+ **Model modularity** - TensorHub divided into multiple components: ready-to-serve models, layers, neural-blocks etc. Ample modules are implemented in each component. Clear and robust interface allows users to combine modules with as few restrictions as possible.\n\n+ **Prototyping** - Code less build more. Apply `TensorHub` to create fast prototypes with the help of modulear blocks, custom layers, custom activation support.\n\n+ **Platform Independent** - Supports both `Keras` and `TensorFlow 2.0`. Run your model on CPU, single GPU or using a distributed training strategy.\n\n------------------\n\n\n## Getting started: 30 seconds to TensorHub\n\n**Here is the `Sequential` model for `Image Classification`:**\n\n```python\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense\n\n# Use Tensorhub to accelerate your prototyping\nfrom tensorhub.layers import InceptionV1 # Custom Inception Layer\nfrom tensorhub.models.image.classifiers import CNNClassifier, VGG16 # Cooked Models\nfrom tensorhub.utilities.activations import gelu, softmax # Custom Activations Supported\n\n## Initiate a sequential model\nmodel = Sequential()\n\n## Stacking layers is as easy as `.add()`\nmodel.add(Conv2D(32, (3, 3), activation=gelu, input_shape=(100, 100, 3)))\nmodel.add(Conv2D(32, (3, 3), activation=gelu))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n## Add custom layer like any other standard layer\nmodel.add(InceptionV1(32)) \n\nmodel.add(Dense(units=64, activation=gelu, input_dim=100))\nmodel.add(Dense(units=10, activation=softmax))\n\n# Or\n## Use one of our pre-cooked models\nmodel = VGG16(n_classes=10, num_nodes=64, img_height=100, img_width=100)\n\n## Once your model looks good, configure its learning process with `.compile()`\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer='sgd',\n    metrics=['accuracy']\n)\n\n## Alternatively, if you need to, you can further configure your compile configuration\nmodel.compile(\n    loss=tensorflow.keras.losses.categorical_crossentropy,\n    optimizer=tensorflow.keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True),\n    metrics=['acc']\n)\n\n## You can now iterate on your training data in batches\n\n## x_train and y_train are Numpy arrays\nmodel.fit(x_train, y_train, epochs=5, batch_size=32)\n\n## Alternatively, you can feed batches to your model manually\nmodel.train_on_batch(x_batch, y_batch)\n\n## Evaluate your performance in one line:\nloss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n\n## Or generate predictions on new data\nclasses = model.predict(x_test, batch_size=128)\n```\n\nBuilding a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?\n\nFor a more in-depth tutorial about Keras, you can check out:\n\n+ [Getting started with Text Classification](https://github.com/nityansuman/tensorhub/tree/master/examples/training-a-text-classifier-using-tensorhub-models.ipynb)\n+ [Getting started with Custom Layers](https://github.com/nityansuman/tensorhub/tree/master/examples/creating-custom-models.ipynb)\n\nIn the [examples folder](https://github.com/nityansuman/tensorhub/tree/master/examples) of this repository, you will find much more advanced examples coming your way very soon.\n\n------------------\n\n\n## What's coming in V1.0\n+ Cooked Models\n    + Image Classification (Supports Transfer Learning with ImageNet Weights)\n        + Xception\n        + VGG16\n        + VGG19\n        + ResNet50\n        + InceptionV3\n        + InceptionResNetV2\n        + MobileNet\n        + DenseNet\n        + NASNet\n        + SqueezeNet (Without Transfer Learning) *\n\n    + Text Classification\n        + RNN Model\n        + LSTM Model\n        + GRU Model\n        + Text-CNN\n\n    + Neural Machine Translation *\n        + Encoder-Decoder Sequence Translation Model\n        + Translation with Attention\n\n    + Text Generation *\n        + RNN, LSTM, GRU Based Model\n\n    + Named Entity Recogniton *\n        + RNN, LSTM, GRU Based Model\n\n+ Custom Modules/Layers\n    + Standard Layers\n        + Linear\n        + Inception V1 Layer\n        + Inception V1 with Reduction Layer\n        + Inception V2 Layer *\n        + Inception V3 Layer *\n    + Attention layers\n        + Bahdanau Attention\n        + Luong Attention\n        + Self-Attention *\n\n+ Utilities\n    + Text\n        + Custom Word and Character Tokenizer\n        + Load Pre-trained Embeddings\n        + Create Vocabulary Matrix\n    + Image *\n        + Image Augmentation\n    + Activations\n        + RELU\n        + SELU\n        + GELU\n        + ELU\n        + Tanh\n        + Sigmoid\n        + Hard Sigmoid\n        + Softmax\n        + Softplus\n        + Softsign\n        + Exponential\n        + Linear\n    + Trainer (Generic TF2.0 train and validation pipelines) *\n\nNote: `*` - Support coming soon\n\n------------------\n\n\n## Installation\n\nBefore installing `TensorHub`, please install its backend engines: TensorFlow (*TensorFlow 2.0 is Recommended*).\n\n+ [Install TensorFlow and Get Started!](https://www.tensorflow.org/install)\n\n+ [Build, deploy, and experiment easily with TensorFlow](https://www.tensorflow.org/)\n\nYou may also consider installing the following **optional dependencies**:\n\n+ [cuDNN](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/) (*Recommended if you plan on running Keras on GPU*).\n+ HDF5 and [h5py](http://docs.h5py.org/en/latest/build.html) (*Required if you plan on saving Keras models to disk*).\n\nThen, you can install TensorHub itself.\n\n```sh\nsudo pip install tensorhub==1.0.0a3\n```\n\nIf you are using a virtualenv, you may want to avoid using sudo:\n\n```sh\npip install tensorhub==1.0.0a3\n```\n\n+ **Alternatively: Install TensorHub from the GitHub source:**\n\nFirst, clone TensorHub using `git`:\n\n```sh\ngit clone https://github.com/nityansuman/tensorhub.git\n```\n\nThen, `cd` to the TensroHub folder and run the install command:\n```sh\ncd tensorhub\nsudo python setup.py install\n```\n\n------------------\n\n\n## Support\n\nYou can also post **bug reports and feature requests** (only) in [GitHub issues](https://github.com/nityansuman/tensorhub/issues). Make sure to read [our guidelines](https://github.com/nityansuman/tensorhub/blob/master/CONTRIBUTING.md) first.\n\nWe are eager to collaborate with you. Feel free to open an issue on or send along a pull request.\nIf you like the work, show your appreciation by \"FORK\", \"STAR\", or \"SHARE\".\n\n[![Love](https://forthebadge.com/images/badges/built-with-love.svg)](https://GitHub.com/nityansuman/tensorhub/)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/nityansuman/tensorhub", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "tensorhub", "package_url": "https://pypi.org/project/tensorhub/", "platform": "", "project_url": "https://pypi.org/project/tensorhub/", "project_urls": {"Homepage": "https://github.com/nityansuman/tensorhub"}, "release_url": "https://pypi.org/project/tensorhub/1.0.0a4/", "requires_dist": ["numpy (>=1.16)", "tensorflow (>=2.0.0a0)"], "requires_python": "", "summary": "Deep Learning for Everybody.", "version": "1.0.0a4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\"><img alt=\"LOGO\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dd7a00de3810148e02aa1f6d494501c9c5e3a5c0/646174612f6c6f676f2e706e673f7261773d74727565\"></p>\n<p><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e1fbc2216df3153f3afad081e3d30373c9f25ac6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f74656e736f726875622e7376673f636f6c6f723d626c7565267374796c653d666c6174\"> <img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ad507fde82dd007ddd1a6b7506b13ee717d08f36/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f74656e736f726875622e7376673f7374796c653d666c6174\">  <img alt=\"GitHub code size in bytes\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f753b7267e72bed13a984a49f845e1d2fc910b4d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c616e6775616765732f636f64652d73697a652f6e697479616e73756d616e2f74656e736f726875622e7376673f636f6c6f723d626c7565267374796c653d666c6174\"> <img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b6ae2727494383b712782ee68f533c2dd4df4473/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f74656e736f726875622e7376673f7374796c653d666c6174\"> <a href=\"https://www.codacy.com/app/nityansuman/tensorhub?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=nityansuman/tensorhub&amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/97b1df3862f505cd74dfe895f59cd67750e982c3/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6431653335633235326462373431623238313434663562376239666664376432\"></a></p>\n<h2>You have just found TensorHub.</h2>\n<p>The open source library to help you develop and train ML models, easy and fast as never before with <code>TensorFlow 2.0</code>.\n<code>TensorHub</code> is a global collection of <code>building blocks</code> and <code>ready to serve models</code>.</p>\n<p>It is a wrapper library of deep learning models and neural lego blocks designed to make deep learning more accessible and accelerate ML research.</p>\n<p>Use <code>TensorHub</code> if you need a deep learning library that:</p>\n<ul>\n<li>\n<p><strong>Reproducibility</strong> - Reproduce the results of existing pre-training models (such as Google BERT, XLNet)</p>\n</li>\n<li>\n<p><strong>Model modularity</strong> - TensorHub divided into multiple components: ready-to-serve models, layers, neural-blocks etc. Ample modules are implemented in each component. Clear and robust interface allows users to combine modules with as few restrictions as possible.</p>\n</li>\n<li>\n<p><strong>Prototyping</strong> - Code less build more. Apply <code>TensorHub</code> to create fast prototypes with the help of modulear blocks, custom layers, custom activation support.</p>\n</li>\n<li>\n<p><strong>Platform Independent</strong> - Supports both <code>Keras</code> and <code>TensorFlow 2.0</code>. Run your model on CPU, single GPU or using a distributed training strategy.</p>\n</li>\n</ul>\n<hr>\n<h2>Getting started: 30 seconds to TensorHub</h2>\n<p><strong>Here is the <code>Sequential</code> model for <code>Image Classification</code>:</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">tensorflow.keras.models</span> <span class=\"kn\">import</span> <span class=\"n\">Sequential</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tensorflow.keras.layers</span> <span class=\"kn\">import</span> <span class=\"n\">Conv2D</span><span class=\"p\">,</span> <span class=\"n\">Dense</span>\n\n<span class=\"c1\"># Use Tensorhub to accelerate your prototyping</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tensorhub.layers</span> <span class=\"kn\">import</span> <span class=\"n\">InceptionV1</span> <span class=\"c1\"># Custom Inception Layer</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tensorhub.models.image.classifiers</span> <span class=\"kn\">import</span> <span class=\"n\">CNNClassifier</span><span class=\"p\">,</span> <span class=\"n\">VGG16</span> <span class=\"c1\"># Cooked Models</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tensorhub.utilities.activations</span> <span class=\"kn\">import</span> <span class=\"n\">gelu</span><span class=\"p\">,</span> <span class=\"n\">softmax</span> <span class=\"c1\"># Custom Activations Supported</span>\n\n<span class=\"c1\">## Initiate a sequential model</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Sequential</span><span class=\"p\">()</span>\n\n<span class=\"c1\">## Stacking layers is as easy as `.add()`</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Conv2D</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">gelu</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)))</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Conv2D</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">gelu</span><span class=\"p\">))</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">MaxPooling2D</span><span class=\"p\">(</span><span class=\"n\">pool_size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)))</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dropout</span><span class=\"p\">(</span><span class=\"mf\">0.25</span><span class=\"p\">))</span>\n\n<span class=\"c1\">## Add custom layer like any other standard layer</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">InceptionV1</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">))</span> \n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">units</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">gelu</span><span class=\"p\">,</span> <span class=\"n\">input_dim</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">))</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">units</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"n\">softmax</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Or</span>\n<span class=\"c1\">## Use one of our pre-cooked models</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">VGG16</span><span class=\"p\">(</span><span class=\"n\">n_classes</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">num_nodes</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">img_height</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">img_width</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## Once your model looks good, configure its learning process with `.compile()`</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span>\n    <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s1\">'categorical_crossentropy'</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s1\">'sgd'</span><span class=\"p\">,</span>\n    <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'accuracy'</span><span class=\"p\">]</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\">## Alternatively, if you need to, you can further configure your compile configuration</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span>\n    <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"n\">tensorflow</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">losses</span><span class=\"o\">.</span><span class=\"n\">categorical_crossentropy</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tensorflow</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">momentum</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">,</span> <span class=\"n\">nesterov</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n    <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'acc'</span><span class=\"p\">]</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\">## You can now iterate on your training data in batches</span>\n\n<span class=\"c1\">## x_train and y_train are Numpy arrays</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## Alternatively, you can feed batches to your model manually</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train_on_batch</span><span class=\"p\">(</span><span class=\"n\">x_batch</span><span class=\"p\">,</span> <span class=\"n\">y_batch</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## Evaluate your performance in one line:</span>\n<span class=\"n\">loss_and_metrics</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## Or generate predictions on new data</span>\n<span class=\"n\">classes</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">)</span>\n</pre>\n<p>Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?</p>\n<p>For a more in-depth tutorial about Keras, you can check out:</p>\n<ul>\n<li><a href=\"https://github.com/nityansuman/tensorhub/tree/master/examples/training-a-text-classifier-using-tensorhub-models.ipynb\" rel=\"nofollow\">Getting started with Text Classification</a></li>\n<li><a href=\"https://github.com/nityansuman/tensorhub/tree/master/examples/creating-custom-models.ipynb\" rel=\"nofollow\">Getting started with Custom Layers</a></li>\n</ul>\n<p>In the <a href=\"https://github.com/nityansuman/tensorhub/tree/master/examples\" rel=\"nofollow\">examples folder</a> of this repository, you will find much more advanced examples coming your way very soon.</p>\n<hr>\n<h2>What's coming in V1.0</h2>\n<ul>\n<li>\n<p>Cooked Models</p>\n<ul>\n<li>\n<p>Image Classification (Supports Transfer Learning with ImageNet Weights)</p>\n<ul>\n<li>Xception</li>\n<li>VGG16</li>\n<li>VGG19</li>\n<li>ResNet50</li>\n<li>InceptionV3</li>\n<li>InceptionResNetV2</li>\n<li>MobileNet</li>\n<li>DenseNet</li>\n<li>NASNet</li>\n<li>SqueezeNet (Without Transfer Learning) *</li>\n</ul>\n</li>\n<li>\n<p>Text Classification</p>\n<ul>\n<li>RNN Model</li>\n<li>LSTM Model</li>\n<li>GRU Model</li>\n<li>Text-CNN</li>\n</ul>\n</li>\n<li>\n<p>Neural Machine Translation *</p>\n<ul>\n<li>Encoder-Decoder Sequence Translation Model</li>\n<li>Translation with Attention</li>\n</ul>\n</li>\n<li>\n<p>Text Generation *</p>\n<ul>\n<li>RNN, LSTM, GRU Based Model</li>\n</ul>\n</li>\n<li>\n<p>Named Entity Recogniton *</p>\n<ul>\n<li>RNN, LSTM, GRU Based Model</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Custom Modules/Layers</p>\n<ul>\n<li>Standard Layers\n<ul>\n<li>Linear</li>\n<li>Inception V1 Layer</li>\n<li>Inception V1 with Reduction Layer</li>\n<li>Inception V2 Layer *</li>\n<li>Inception V3 Layer *</li>\n</ul>\n</li>\n<li>Attention layers\n<ul>\n<li>Bahdanau Attention</li>\n<li>Luong Attention</li>\n<li>Self-Attention *</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Utilities</p>\n<ul>\n<li>Text\n<ul>\n<li>Custom Word and Character Tokenizer</li>\n<li>Load Pre-trained Embeddings</li>\n<li>Create Vocabulary Matrix</li>\n</ul>\n</li>\n<li>Image *\n<ul>\n<li>Image Augmentation</li>\n</ul>\n</li>\n<li>Activations\n<ul>\n<li>RELU</li>\n<li>SELU</li>\n<li>GELU</li>\n<li>ELU</li>\n<li>Tanh</li>\n<li>Sigmoid</li>\n<li>Hard Sigmoid</li>\n<li>Softmax</li>\n<li>Softplus</li>\n<li>Softsign</li>\n<li>Exponential</li>\n<li>Linear</li>\n</ul>\n</li>\n<li>Trainer (Generic TF2.0 train and validation pipelines) *</li>\n</ul>\n</li>\n</ul>\n<p>Note: <code>*</code> - Support coming soon</p>\n<hr>\n<h2>Installation</h2>\n<p>Before installing <code>TensorHub</code>, please install its backend engines: TensorFlow (<em>TensorFlow 2.0 is Recommended</em>).</p>\n<ul>\n<li>\n<p><a href=\"https://www.tensorflow.org/install\" rel=\"nofollow\">Install TensorFlow and Get Started!</a></p>\n</li>\n<li>\n<p><a href=\"https://www.tensorflow.org/\" rel=\"nofollow\">Build, deploy, and experiment easily with TensorFlow</a></p>\n</li>\n</ul>\n<p>You may also consider installing the following <strong>optional dependencies</strong>:</p>\n<ul>\n<li><a href=\"https://docs.nvidia.com/deeplearning/sdk/cudnn-install/\" rel=\"nofollow\">cuDNN</a> (<em>Recommended if you plan on running Keras on GPU</em>).</li>\n<li>HDF5 and <a href=\"http://docs.h5py.org/en/latest/build.html\" rel=\"nofollow\">h5py</a> (<em>Required if you plan on saving Keras models to disk</em>).</li>\n</ul>\n<p>Then, you can install TensorHub itself.</p>\n<pre>sudo pip install <span class=\"nv\">tensorhub</span><span class=\"o\">==</span><span class=\"m\">1</span>.0.0a3\n</pre>\n<p>If you are using a virtualenv, you may want to avoid using sudo:</p>\n<pre>pip install <span class=\"nv\">tensorhub</span><span class=\"o\">==</span><span class=\"m\">1</span>.0.0a3\n</pre>\n<ul>\n<li><strong>Alternatively: Install TensorHub from the GitHub source:</strong></li>\n</ul>\n<p>First, clone TensorHub using <code>git</code>:</p>\n<pre>git clone https://github.com/nityansuman/tensorhub.git\n</pre>\n<p>Then, <code>cd</code> to the TensroHub folder and run the install command:</p>\n<pre><span class=\"nb\">cd</span> tensorhub\nsudo python setup.py install\n</pre>\n<hr>\n<h2>Support</h2>\n<p>You can also post <strong>bug reports and feature requests</strong> (only) in <a href=\"https://github.com/nityansuman/tensorhub/issues\" rel=\"nofollow\">GitHub issues</a>. Make sure to read <a href=\"https://github.com/nityansuman/tensorhub/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">our guidelines</a> first.</p>\n<p>We are eager to collaborate with you. Feel free to open an issue on or send along a pull request.\nIf you like the work, show your appreciation by \"FORK\", \"STAR\", or \"SHARE\".</p>\n<p><a href=\"https://GitHub.com/nityansuman/tensorhub/\" rel=\"nofollow\"><img alt=\"Love\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ac6b7ad4667b75b14e3f997600dcc279b9534c6b/68747470733a2f2f666f7274686562616467652e636f6d2f696d616765732f6261646765732f6275696c742d776974682d6c6f76652e737667\"></a></p>\n\n          </div>"}, "last_serial": 5539848, "releases": {"1.0.0a3": [{"comment_text": "", "digests": {"md5": "87036ef7dfe5f3538ef402025e3e0509", "sha256": "7acb8e31a966b89c0707e7b9699d202955d8ed25714fdbce5cd424b6e6d0578b"}, "downloads": -1, "filename": "tensorhub-1.0.0a3-py3-none-any.whl", "has_sig": false, "md5_digest": "87036ef7dfe5f3538ef402025e3e0509", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28913, "upload_time": "2019-07-16T09:33:57", "upload_time_iso_8601": "2019-07-16T09:33:57.872411Z", "url": "https://files.pythonhosted.org/packages/25/e5/3bf94866fd38836bce65797ec26b842eaa9180d98d7da5779537c4b1134b/tensorhub-1.0.0a3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a97b25bd59cd405acc513cc851340fa8", "sha256": "948b4fb7a3c18251bc03c56ed175f60b4d3e7f2d921c0e8f22348e63b3f54bc5"}, "downloads": -1, "filename": "tensorhub-1.0.0a3.tar.gz", "has_sig": false, "md5_digest": "a97b25bd59cd405acc513cc851340fa8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17984, "upload_time": "2019-07-16T09:33:59", "upload_time_iso_8601": "2019-07-16T09:33:59.288266Z", "url": "https://files.pythonhosted.org/packages/3b/92/4e3fa5a4493a03372f5a222c9a822e9d93c7da17ab8f625d4943c3c4a46f/tensorhub-1.0.0a3.tar.gz", "yanked": false}], "1.0.0a4": [{"comment_text": "", "digests": {"md5": "952bd9633a984a0bbb592ecf7334b10b", "sha256": "bf134b7639623a4ef0c099cb8ff724842588a41c355766f43b6945f55b72cc15"}, "downloads": -1, "filename": "tensorhub-1.0.0a4-py3-none-any.whl", "has_sig": false, "md5_digest": "952bd9633a984a0bbb592ecf7334b10b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28894, "upload_time": "2019-07-16T10:54:26", "upload_time_iso_8601": "2019-07-16T10:54:26.403507Z", "url": "https://files.pythonhosted.org/packages/2d/80/8bcaba192572e9993d991cf3198c4850d9dab5fae820dd3ce33a8f7a083c/tensorhub-1.0.0a4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3874e7cc5168a0b7b3ca722aa51140ca", "sha256": "4f9504ac6a2ba7d7f8b0d6034b3705950ed1817f38f4f942a3c115072ec5b3e3"}, "downloads": -1, "filename": "tensorhub-1.0.0a4.tar.gz", "has_sig": false, "md5_digest": "3874e7cc5168a0b7b3ca722aa51140ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17944, "upload_time": "2019-07-16T10:54:29", "upload_time_iso_8601": "2019-07-16T10:54:29.483170Z", "url": "https://files.pythonhosted.org/packages/5d/36/58ccb672937c2916fb0dcbb424cc281f2ffa443c71df047534cda6ffa0b7/tensorhub-1.0.0a4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "952bd9633a984a0bbb592ecf7334b10b", "sha256": "bf134b7639623a4ef0c099cb8ff724842588a41c355766f43b6945f55b72cc15"}, "downloads": -1, "filename": "tensorhub-1.0.0a4-py3-none-any.whl", "has_sig": false, "md5_digest": "952bd9633a984a0bbb592ecf7334b10b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28894, "upload_time": "2019-07-16T10:54:26", "upload_time_iso_8601": "2019-07-16T10:54:26.403507Z", "url": "https://files.pythonhosted.org/packages/2d/80/8bcaba192572e9993d991cf3198c4850d9dab5fae820dd3ce33a8f7a083c/tensorhub-1.0.0a4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3874e7cc5168a0b7b3ca722aa51140ca", "sha256": "4f9504ac6a2ba7d7f8b0d6034b3705950ed1817f38f4f942a3c115072ec5b3e3"}, "downloads": -1, "filename": "tensorhub-1.0.0a4.tar.gz", "has_sig": false, "md5_digest": "3874e7cc5168a0b7b3ca722aa51140ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17944, "upload_time": "2019-07-16T10:54:29", "upload_time_iso_8601": "2019-07-16T10:54:29.483170Z", "url": "https://files.pythonhosted.org/packages/5d/36/58ccb672937c2916fb0dcbb424cc281f2ffa443c71df047534cda6ffa0b7/tensorhub-1.0.0a4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:05 2020"}