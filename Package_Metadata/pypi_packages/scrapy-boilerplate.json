{"info": {"author": "Rolando Espinoza La fuente", "author_email": "darkrho@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Programming Language :: Python"], "description": "==================\nscrapy-boilerplate\n==================\n\n`scrapy-boilerplate` is a small set of utilities for `Scrapy`_ to simplify\nwriting low-complexity spiders that are very common in small and one-off projects.\n\nIt requires `Scrapy`_ `(>= 0.16)` and has been tested using `python 2.7`.\nAdditionally, `PyQuery`_ is required to run the scripts in the `examples`_\ndirectory.\n\n.. note::\n\n  The code is experimental, includes some magic under the hood and might be\n  hard to debug. If you are new to `Scrapy`_, don't use this code unless\n  you are ready to debug errors that nobody have seen before.\n\n\n-----------\nUsage Guide\n-----------\n\nItems\n=====\n\nStandard item definition:\n\n.. code:: python\n\n  from scrapy.item import Item, Field\n\n  class BaseItem(Item):\n      url = Field()\n      crawled = Field()\n\n  class UserItem(BaseItem):\n      name = Field()\n      about = Field()\n      location = Field()\n\n  class StoryItem(BaseItem):\n      title = Field()\n      body = Field()\n      user = Field()\n\nBecomes:\n\n.. code:: python\n\n  from scrapy_boilerplate import NewItem\n\n  BaseItem = NewItem('url crawled')\n\n  UserItem = NewItem('name about location', base_cls=BaseItem)\n\n  StoryItem = NewItem('title body user', base_cls=BaseItem)\n\n\nBaseSpider\n==========\n\nStandard spider definition:\n\n.. code:: python\n\n  from scrapy.spider import BaseSpider\n\n  class MySpider(BaseSpider):\n      name = 'my_spider'\n      start_urls = ['http://example.com/latest']\n\n      def parse(self, response):\n          # do stuff\n\n\nBecomes:\n\n.. code:: python\n\n  from scrapy_boilerplate import NewSpider\n\n  MySpider = NewSpider('my_spider')\n\n  @MySpider.scrape('http://example.com/latest')\n  def parse(spider, response):\n      # do stuff\n\n\nCrawlSpider\n===========\n\nStandard crawl-spider definition:\n\n.. code:: python\n\n  from scrapy.contrib.spiders import CrawlSpider, Rule\n  from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor\n\n\n  class MySpider(CrawlSpider):\n      name = 'my_spider'\n      start_urls = ['http://example.com']\n\n      rules = (\n          Rule(SgmlLinkExtractor('category\\.php'), follow=True),\n          Rule(SgmlLinkExtractor('item\\.php'), callback='parse_item'),\n      )\n\n      def parse_item(self, response):\n          # do stuff\n\n\nBecomes:\n\n.. code:: python\n\n  from scrapy_boilerplate import NewCrawlSpider\n\n  MySpider = NewCrawlSpider('my_spider')\n  MySpider.follow('category\\.php')\n\n  @MySpider.rule('item\\.php')\n  def parse_item(spider, response):\n      # do stuff\n\n\nRunning Helpers\n===============\n\nSingle-spider running script:\n\n.. code:: python\n\n  # file: my-spider.py\n  # imports omitted ...\n\n  class MySpider(BaseSpider):\n      # spider code ...\n\n  if __name__ == '__main__':\n      from scrapy_boilerplate import run_spider\n      custom_settings = {\n          # ...\n      }\n      spider = MySpider()\n\n      run_spider(spider, custom_settings)\n\n\nMulti-spider script with standard crawl command line options:\n\n.. code:: python\n\n  # file: my-crawler.py\n  # imports omitted ...\n\n\n  class MySpider(BaseSpider):\n      name = 'my_spider'\n      # spider code ...\n\n\n  class OtherSpider(CrawlSpider):\n      name = 'other_spider'\n      # spider code ...\n\n\n  if __name__ == '__main__':\n      from scrapy_boilerplate import run_crawler, SpiderManager\n      custom_settings = {\n          # ...\n      }\n\n      SpiderManager.register(MySpider)\n      SpiderManager.register(OtherSpider)\n\n      run_crawler(custom_settings)\n\n\n.. note:: See the `examples`_ directory for working code examples.\n\n\n.. _`Scrapy`: http://www.scrapy.org\n.. _`PyQuery`: http://pypi.python.org/pypi/pyquery\n.. _`examples`: https://github.com/darkrho/scrapy-boilerplate/tree/master/examples", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/darkrho/scrapy-boilerplate", "keywords": null, "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "scrapy-boilerplate", "package_url": "https://pypi.org/project/scrapy-boilerplate/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/scrapy-boilerplate/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/darkrho/scrapy-boilerplate"}, "release_url": "https://pypi.org/project/scrapy-boilerplate/0.2.1/", "requires_dist": null, "requires_python": null, "summary": "Small set of utilities to simplify writing Scrapy spiders.", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><cite>scrapy-boilerplate</cite> is a small set of utilities for <a href=\"http://www.scrapy.org\" rel=\"nofollow\">Scrapy</a> to simplify\nwriting low-complexity spiders that are very common in small and one-off projects.</p>\n<p>It requires <a href=\"http://www.scrapy.org\" rel=\"nofollow\">Scrapy</a> <cite>(&gt;= 0.16)</cite> and has been tested using <cite>python 2.7</cite>.\nAdditionally, <a href=\"http://pypi.python.org/pypi/pyquery\" rel=\"nofollow\">PyQuery</a> is required to run the scripts in the <a href=\"https://github.com/darkrho/scrapy-boilerplate/tree/master/examples\" rel=\"nofollow\">examples</a>\ndirectory.</p>\n<div>\n<p>Note</p>\n<p>The code is experimental, includes some magic under the hood and might be\nhard to debug. If you are new to <a href=\"http://www.scrapy.org\" rel=\"nofollow\">Scrapy</a>, don\u2019t use this code unless\nyou are ready to debug errors that nobody have seen before.</p>\n</div>\n<div id=\"usage-guide\">\n<h2>Usage Guide</h2>\n<div id=\"items\">\n<h3>Items</h3>\n<p>Standard item definition:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy.item</span> <span class=\"kn\">import</span> <span class=\"n\">Item</span><span class=\"p\">,</span> <span class=\"n\">Field</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">BaseItem</span><span class=\"p\">(</span><span class=\"n\">Item</span><span class=\"p\">):</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">crawled</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">UserItem</span><span class=\"p\">(</span><span class=\"n\">BaseItem</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">about</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">location</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">StoryItem</span><span class=\"p\">(</span><span class=\"n\">BaseItem</span><span class=\"p\">):</span>\n    <span class=\"n\">title</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">body</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n    <span class=\"n\">user</span> <span class=\"o\">=</span> <span class=\"n\">Field</span><span class=\"p\">()</span>\n</pre>\n<p>Becomes:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy_boilerplate</span> <span class=\"kn\">import</span> <span class=\"n\">NewItem</span>\n\n<span class=\"n\">BaseItem</span> <span class=\"o\">=</span> <span class=\"n\">NewItem</span><span class=\"p\">(</span><span class=\"s1\">'url crawled'</span><span class=\"p\">)</span>\n\n<span class=\"n\">UserItem</span> <span class=\"o\">=</span> <span class=\"n\">NewItem</span><span class=\"p\">(</span><span class=\"s1\">'name about location'</span><span class=\"p\">,</span> <span class=\"n\">base_cls</span><span class=\"o\">=</span><span class=\"n\">BaseItem</span><span class=\"p\">)</span>\n\n<span class=\"n\">StoryItem</span> <span class=\"o\">=</span> <span class=\"n\">NewItem</span><span class=\"p\">(</span><span class=\"s1\">'title body user'</span><span class=\"p\">,</span> <span class=\"n\">base_cls</span><span class=\"o\">=</span><span class=\"n\">BaseItem</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"basespider\">\n<h3>BaseSpider</h3>\n<p>Standard spider definition:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spider</span> <span class=\"kn\">import</span> <span class=\"n\">BaseSpider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">BaseSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'my_spider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com/latest'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># do stuff</span>\n</pre>\n<p>Becomes:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy_boilerplate</span> <span class=\"kn\">import</span> <span class=\"n\">NewSpider</span>\n\n<span class=\"n\">MySpider</span> <span class=\"o\">=</span> <span class=\"n\">NewSpider</span><span class=\"p\">(</span><span class=\"s1\">'my_spider'</span><span class=\"p\">)</span>\n\n<span class=\"nd\">@MySpider</span><span class=\"o\">.</span><span class=\"n\">scrape</span><span class=\"p\">(</span><span class=\"s1\">'http://example.com/latest'</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># do stuff</span>\n</pre>\n</div>\n<div id=\"crawlspider\">\n<h3>CrawlSpider</h3>\n<p>Standard crawl-spider definition:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy.contrib.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlSpider</span><span class=\"p\">,</span> <span class=\"n\">Rule</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy.contrib.linkextractors.sgml</span> <span class=\"kn\">import</span> <span class=\"n\">SgmlLinkExtractor</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'my_spider'</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">rules</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">SgmlLinkExtractor</span><span class=\"p\">(</span><span class=\"s1\">'category\\.php'</span><span class=\"p\">),</span> <span class=\"n\">follow</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n        <span class=\"n\">Rule</span><span class=\"p\">(</span><span class=\"n\">SgmlLinkExtractor</span><span class=\"p\">(</span><span class=\"s1\">'item\\.php'</span><span class=\"p\">),</span> <span class=\"n\">callback</span><span class=\"o\">=</span><span class=\"s1\">'parse_item'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># do stuff</span>\n</pre>\n<p>Becomes:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy_boilerplate</span> <span class=\"kn\">import</span> <span class=\"n\">NewCrawlSpider</span>\n\n<span class=\"n\">MySpider</span> <span class=\"o\">=</span> <span class=\"n\">NewCrawlSpider</span><span class=\"p\">(</span><span class=\"s1\">'my_spider'</span><span class=\"p\">)</span>\n<span class=\"n\">MySpider</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"s1\">'category\\.php'</span><span class=\"p\">)</span>\n\n<span class=\"nd\">@MySpider</span><span class=\"o\">.</span><span class=\"n\">rule</span><span class=\"p\">(</span><span class=\"s1\">'item\\.php'</span><span class=\"p\">)</span>\n<span class=\"k\">def</span> <span class=\"nf\">parse_item</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n    <span class=\"c1\"># do stuff</span>\n</pre>\n</div>\n<div id=\"running-helpers\">\n<h3>Running Helpers</h3>\n<p>Single-spider running script:</p>\n<pre><span class=\"c1\"># file: my-spider.py</span>\n<span class=\"c1\"># imports omitted ...</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">BaseSpider</span><span class=\"p\">):</span>\n    <span class=\"c1\"># spider code ...</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">scrapy_boilerplate</span> <span class=\"kn\">import</span> <span class=\"n\">run_spider</span>\n    <span class=\"n\">custom_settings</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"c1\"># ...</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">spider</span> <span class=\"o\">=</span> <span class=\"n\">MySpider</span><span class=\"p\">()</span>\n\n    <span class=\"n\">run_spider</span><span class=\"p\">(</span><span class=\"n\">spider</span><span class=\"p\">,</span> <span class=\"n\">custom_settings</span><span class=\"p\">)</span>\n</pre>\n<p>Multi-spider script with standard crawl command line options:</p>\n<pre><span class=\"c1\"># file: my-crawler.py</span>\n<span class=\"c1\"># imports omitted ...</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">BaseSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'my_spider'</span>\n    <span class=\"c1\"># spider code ...</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">OtherSpider</span><span class=\"p\">(</span><span class=\"n\">CrawlSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'other_spider'</span>\n    <span class=\"c1\"># spider code ...</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"kn\">from</span> <span class=\"nn\">scrapy_boilerplate</span> <span class=\"kn\">import</span> <span class=\"n\">run_crawler</span><span class=\"p\">,</span> <span class=\"n\">SpiderManager</span>\n    <span class=\"n\">custom_settings</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"c1\"># ...</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"n\">SpiderManager</span><span class=\"o\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">MySpider</span><span class=\"p\">)</span>\n    <span class=\"n\">SpiderManager</span><span class=\"o\">.</span><span class=\"n\">register</span><span class=\"p\">(</span><span class=\"n\">OtherSpider</span><span class=\"p\">)</span>\n\n    <span class=\"n\">run_crawler</span><span class=\"p\">(</span><span class=\"n\">custom_settings</span><span class=\"p\">)</span>\n</pre>\n<div>\n<p>Note</p>\n<p>See the <a href=\"https://github.com/darkrho/scrapy-boilerplate/tree/master/examples\" rel=\"nofollow\">examples</a> directory for working code examples.</p>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 799334, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "54919d0fb266a77ae3a8c937b8d56680", "sha256": "3395311d878896461fff35213557021d006b9735cd33005b0c7f52a818b62588"}, "downloads": -1, "filename": "scrapy-boilerplate-0.1.tar.gz", "has_sig": false, "md5_digest": "54919d0fb266a77ae3a8c937b8d56680", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2955, "upload_time": "2013-02-02T05:57:07", "upload_time_iso_8601": "2013-02-02T05:57:07.297136Z", "url": "https://files.pythonhosted.org/packages/be/fa/e46ff635fb15d20c8d47844fed2430064aea9ce7f73c627d1419f24343b9/scrapy-boilerplate-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "c3609d87735c4b74494e44bad3ffd589", "sha256": "92561779cfe6600c5cafabe340aa7d65a99788ca25bbcb7f6819b55aab10e76c"}, "downloads": -1, "filename": "scrapy-boilerplate-0.2.tar.gz", "has_sig": false, "md5_digest": "c3609d87735c4b74494e44bad3ffd589", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4991, "upload_time": "2013-02-04T00:34:16", "upload_time_iso_8601": "2013-02-04T00:34:16.776257Z", "url": "https://files.pythonhosted.org/packages/17/48/2ad787186949f8f51ed032593a64cb32cab68b7b743c4da4160ca04e8eb9/scrapy-boilerplate-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "9c484b430d39ae2298acfb275f9ebcf7", "sha256": "49860bcb31ad8d7516e9f322b89b34ae708b4f373b588477cbb65eee3a273078"}, "downloads": -1, "filename": "scrapy-boilerplate-0.2.1.tar.gz", "has_sig": false, "md5_digest": "9c484b430d39ae2298acfb275f9ebcf7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4993, "upload_time": "2013-02-04T00:35:17", "upload_time_iso_8601": "2013-02-04T00:35:17.427350Z", "url": "https://files.pythonhosted.org/packages/65/4f/8901d1fc946dc6bc27e8abe472d298db36da18db3e63793938383499dd6a/scrapy-boilerplate-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9c484b430d39ae2298acfb275f9ebcf7", "sha256": "49860bcb31ad8d7516e9f322b89b34ae708b4f373b588477cbb65eee3a273078"}, "downloads": -1, "filename": "scrapy-boilerplate-0.2.1.tar.gz", "has_sig": false, "md5_digest": "9c484b430d39ae2298acfb275f9ebcf7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4993, "upload_time": "2013-02-04T00:35:17", "upload_time_iso_8601": "2013-02-04T00:35:17.427350Z", "url": "https://files.pythonhosted.org/packages/65/4f/8901d1fc946dc6bc27e8abe472d298db36da18db3e63793938383499dd6a/scrapy-boilerplate-0.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:50 2020"}