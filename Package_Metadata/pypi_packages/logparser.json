{"info": {"author": "my8100", "author_email": "my8100@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# LogParser: A tool for parsing Scrapy log files periodically and incrementally, designed for [*ScrapydWeb*](https://github.com/my8100/scrapydweb).\n\n[![PyPI - logparser Version](https://img.shields.io/pypi/v/logparser.svg)](https://pypi.org/project/logparser/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/logparser.svg)](https://pypi.org/project/logparser/)\n[![CircleCI](https://circleci.com/gh/my8100/logparser/tree/master.svg?style=shield)](https://circleci.com/gh/my8100/logparser/tree/master)\n[![codecov](https://codecov.io/gh/my8100/logparser/branch/master/graph/badge.svg)](https://codecov.io/gh/my8100/logparser)\n[![Coverage Status](https://coveralls.io/repos/github/my8100/logparser/badge.svg?branch=master)](https://coveralls.io/github/my8100/logparser?branch=master)\n[![Downloads - total](https://pepy.tech/badge/logparser)](https://pepy.tech/project/logparser)\n[![GitHub license](https://img.shields.io/github/license/my8100/logparser.svg)](https://github.com/my8100/logparser/blob/master/LICENSE)\n\n\n## Installation\n- Use pip:\n```bash\npip install logparser\n```\nNote that you may need to execute `python -m pip install --upgrade pip` first in order to get the latest version of logparser, or download the tar.gz file from https://pypi.org/project/logparser/#files and get it installed via `pip install logparser-x.x.x.tar.gz`\n\n- Use git:\n```bash\npip install --upgrade git+https://github.com/my8100/logparser.git\n```\nOr:\n```bash\ngit clone https://github.com/my8100/logparser.git\ncd logparser\npython setup.py install\n```\n\n## Usage\n### To use in Python\n<details>\n<summary>View codes</summary>\n\n```python\nIn [1]: from logparser import parse\n\nIn [2]: log = \"\"\"2018-10-23 18:28:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: demo)\n   ...: 2018-10-23 18:29:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n   ...: {'downloader/exception_count': 3,\n   ...:  'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,\n   ...:  'downloader/request_bytes': 1336,\n   ...:  'downloader/request_count': 7,\n   ...:  'downloader/request_method_count/GET': 7,\n   ...:  'downloader/response_bytes': 1669,\n   ...:  'downloader/response_count': 4,\n   ...:  'downloader/response_status_count/200': 2,\n   ...:  'downloader/response_status_count/302': 1,\n   ...:  'downloader/response_status_count/404': 1,\n   ...:  'dupefilter/filtered': 1,\n   ...:  'finish_reason': 'finished',\n   ...:  'finish_time': datetime.datetime(2018, 10, 23, 10, 29, 41, 174719),\n   ...:  'httperror/response_ignored_count': 1,\n   ...:  'httperror/response_ignored_status_count/404': 1,\n   ...:  'item_scraped_count': 2,\n   ...:  'log_count/CRITICAL': 5,\n   ...:  'log_count/DEBUG': 14,\n   ...:  'log_count/ERROR': 5,\n   ...:  'log_count/INFO': 75,\n   ...:  'log_count/WARNING': 3,\n   ...:  'offsite/domains': 1,\n   ...:  'offsite/filtered': 1,\n   ...:  'request_depth_max': 1,\n   ...:  'response_received_count': 3,\n   ...:  'retry/count': 2,\n   ...:  'retry/max_reached': 1,\n   ...:  'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,\n   ...:  'scheduler/dequeued': 7,\n   ...:  'scheduler/dequeued/memory': 7,\n   ...:  'scheduler/enqueued': 7,\n   ...:  'scheduler/enqueued/memory': 7,\n   ...:  'start_time': datetime.datetime(2018, 10, 23, 10, 28, 35, 70938)}\n   ...: 2018-10-23 18:29:42 [scrapy.core.engine] INFO: Spider closed (finished)\"\"\"\n\nIn [3]: odict = parse(log, headlines=1, taillines=1)\n\nIn [4]: odict\nOut[4]:\nOrderedDict([('head',\n              '2018-10-23 18:28:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: demo)'),\n             ('tail',\n              '2018-10-23 18:29:42 [scrapy.core.engine] INFO: Spider closed (finished)'),\n             ('first_log_time', '2018-10-23 18:28:34'),\n             ('latest_log_time', '2018-10-23 18:29:42'),\n             ('runtime', '0:01:08'),\n             ('first_log_timestamp', 1540290514),\n             ('latest_log_timestamp', 1540290582),\n             ('datas', []),\n             ('pages', 3),\n             ('items', 2),\n             ('latest_matches',\n              {'telnet_console': '',\n               'resuming_crawl': '',\n               'latest_offsite': '',\n               'latest_duplicate': '',\n               'latest_crawl': '',\n               'latest_scrape': '',\n               'latest_item': '',\n               'latest_stat': ''}),\n             ('latest_crawl_timestamp', 0),\n             ('latest_scrape_timestamp', 0),\n             ('log_categories',\n              {'critical_logs': {'count': 5, 'details': []},\n               'error_logs': {'count': 5, 'details': []},\n               'warning_logs': {'count': 3, 'details': []},\n               'redirect_logs': {'count': 1, 'details': []},\n               'retry_logs': {'count': 2, 'details': []},\n               'ignore_logs': {'count': 1, 'details': []}}),\n             ('shutdown_reason', 'N/A'),\n             ('finish_reason', 'finished'),\n             ('crawler_stats',\n              OrderedDict([('source', 'log'),\n                           ('last_update_time', '2018-10-23 18:29:41'),\n                           ('last_update_timestamp', 1540290581),\n                           ('downloader/exception_count', 3),\n                           ('downloader/exception_type_count/twisted.internet.error.TCPTimedOutError',\n                            3),\n                           ('downloader/request_bytes', 1336),\n                           ('downloader/request_count', 7),\n                           ('downloader/request_method_count/GET', 7),\n                           ('downloader/response_bytes', 1669),\n                           ('downloader/response_count', 4),\n                           ('downloader/response_status_count/200', 2),\n                           ('downloader/response_status_count/302', 1),\n                           ('downloader/response_status_count/404', 1),\n                           ('dupefilter/filtered', 1),\n                           ('finish_reason', 'finished'),\n                           ('finish_time',\n                            'datetime.datetime(2018, 10, 23, 10, 29, 41, 174719)'),\n                           ('httperror/response_ignored_count', 1),\n                           ('httperror/response_ignored_status_count/404', 1),\n                           ('item_scraped_count', 2),\n                           ('log_count/CRITICAL', 5),\n                           ('log_count/DEBUG', 14),\n                           ('log_count/ERROR', 5),\n                           ('log_count/INFO', 75),\n                           ('log_count/WARNING', 3),\n                           ('offsite/domains', 1),\n                           ('offsite/filtered', 1),\n                           ('request_depth_max', 1),\n                           ('response_received_count', 3),\n                           ('retry/count', 2),\n                           ('retry/max_reached', 1),\n                           ('retry/reason_count/twisted.internet.error.TCPTimedOutError',\n                            2),\n                           ('scheduler/dequeued', 7),\n                           ('scheduler/dequeued/memory', 7),\n                           ('scheduler/enqueued', 7),\n                           ('scheduler/enqueued/memory', 7),\n                           ('start_time',\n                            'datetime.datetime(2018, 10, 23, 10, 28, 35, 70938)')])),\n             ('last_update_time', '2019-03-08 16:53:50'),\n             ('last_update_timestamp', 1552035230),\n             ('logparser_version', '0.8.1')])\n\nIn [5]: odict['runtime']\nOut[5]: '0:01:08'\n\nIn [6]: odict['pages']\nOut[6]: 3\n\nIn [7]: odict['items']\nOut[7]: 2\n\nIn [8]: odict['finish_reason']\nOut[8]: 'finished'\n```\n\n</details>\n\n### To run as a service\n1. **Make sure that [*Scrapyd*](https://github.com/scrapy/scrapyd) has been installed and started on the current host.**\n2. Start ***LogParser*** via command `logparser`\n3. Visit http://127.0.0.1:6800/logs/stats.json **(Assuming the Scrapyd service runs on port 6800.)**\n4. Visit http://127.0.0.1:6800/logs/projectname/spidername/jobid.json to get stats of a job in details.\n\n### To work with *ScrapydWeb* for visualization\nCheck out https://github.com/my8100/scrapydweb for more info.\n\n![stats](https://raw.githubusercontent.com/my8100/files/master/scrapydweb/screenshots/stats.gif)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/my8100/logparser", "keywords": "", "license": "GNU General Public License v3.0", "maintainer": "", "maintainer_email": "", "name": "logparser", "package_url": "https://pypi.org/project/logparser/", "platform": "", "project_url": "https://pypi.org/project/logparser/", "project_urls": {"Homepage": "https://github.com/my8100/logparser"}, "release_url": "https://pypi.org/project/logparser/0.8.2/", "requires_dist": ["pexpect (>=4.7.0)", "six (>=1.12.0)"], "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "summary": "A tool for parsing Scrapy log files periodically and incrementally, designed for ScrapydWeb.", "version": "0.8.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>LogParser: A tool for parsing Scrapy log files periodically and incrementally, designed for <a href=\"https://github.com/my8100/scrapydweb\" rel=\"nofollow\"><em>ScrapydWeb</em></a>.</h1>\n<p><a href=\"https://pypi.org/project/logparser/\" rel=\"nofollow\"><img alt=\"PyPI - logparser Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b437d34ebc4f931aaa70bbce3c0fb088ca2ec52f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6f677061727365722e737667\"></a>\n<a href=\"https://pypi.org/project/logparser/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ab4e60c0718f1669bc2cf203f6aa90a69c1bfa17/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6c6f677061727365722e737667\"></a>\n<a href=\"https://circleci.com/gh/my8100/logparser/tree/master\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0c752e0695339a3ce2a15f93a4ac255adb52153a/68747470733a2f2f636972636c6563692e636f6d2f67682f6d79383130302f6c6f677061727365722f747265652f6d61737465722e7376673f7374796c653d736869656c64\"></a>\n<a href=\"https://codecov.io/gh/my8100/logparser\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1bb762368d78588e130635d368d55328847c4163/68747470733a2f2f636f6465636f762e696f2f67682f6d79383130302f6c6f677061727365722f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://coveralls.io/github/my8100/logparser?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/68d7afa9b81f50143f38092f949886e0737a7edd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6d79383130302f6c6f677061727365722f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pepy.tech/project/logparser\" rel=\"nofollow\"><img alt=\"Downloads - total\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ca8c22b42b863b0aaf9f20c9d5c086e54b7ea4e8/68747470733a2f2f706570792e746563682f62616467652f6c6f67706172736572\"></a>\n<a href=\"https://github.com/my8100/logparser/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"GitHub license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d9bbbc792b6d0e5fcffd95433b690e305e4dc735/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d79383130302f6c6f677061727365722e737667\"></a></p>\n<h2>Installation</h2>\n<ul>\n<li>Use pip:</li>\n</ul>\n<pre>pip install logparser\n</pre>\n<p>Note that you may need to execute <code>python -m pip install --upgrade pip</code> first in order to get the latest version of logparser, or download the tar.gz file from <a href=\"https://pypi.org/project/logparser/#files\" rel=\"nofollow\">https://pypi.org/project/logparser/#files</a> and get it installed via <code>pip install logparser-x.x.x.tar.gz</code></p>\n<ul>\n<li>Use git:</li>\n</ul>\n<pre>pip install --upgrade git+https://github.com/my8100/logparser.git\n</pre>\n<p>Or:</p>\n<pre>git clone https://github.com/my8100/logparser.git\n<span class=\"nb\">cd</span> logparser\npython setup.py install\n</pre>\n<h2>Usage</h2>\n<h3>To use in Python</h3>\n<details>\n<summary>View codes</summary>\n<pre><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]:</span> <span class=\"kn\">from</span> <span class=\"nn\">logparser</span> <span class=\"kn\">import</span> <span class=\"n\">parse</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"n\">log</span> <span class=\"o\">=</span> <span class=\"s2\">\"\"\"2018-10-23 18:28:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: demo)</span>\n<span class=\"s2\">   ...: 2018-10-23 18:29:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span>\n<span class=\"s2\">   ...: {'downloader/exception_count': 3,</span>\n<span class=\"s2\">   ...:  'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,</span>\n<span class=\"s2\">   ...:  'downloader/request_bytes': 1336,</span>\n<span class=\"s2\">   ...:  'downloader/request_count': 7,</span>\n<span class=\"s2\">   ...:  'downloader/request_method_count/GET': 7,</span>\n<span class=\"s2\">   ...:  'downloader/response_bytes': 1669,</span>\n<span class=\"s2\">   ...:  'downloader/response_count': 4,</span>\n<span class=\"s2\">   ...:  'downloader/response_status_count/200': 2,</span>\n<span class=\"s2\">   ...:  'downloader/response_status_count/302': 1,</span>\n<span class=\"s2\">   ...:  'downloader/response_status_count/404': 1,</span>\n<span class=\"s2\">   ...:  'dupefilter/filtered': 1,</span>\n<span class=\"s2\">   ...:  'finish_reason': 'finished',</span>\n<span class=\"s2\">   ...:  'finish_time': datetime.datetime(2018, 10, 23, 10, 29, 41, 174719),</span>\n<span class=\"s2\">   ...:  'httperror/response_ignored_count': 1,</span>\n<span class=\"s2\">   ...:  'httperror/response_ignored_status_count/404': 1,</span>\n<span class=\"s2\">   ...:  'item_scraped_count': 2,</span>\n<span class=\"s2\">   ...:  'log_count/CRITICAL': 5,</span>\n<span class=\"s2\">   ...:  'log_count/DEBUG': 14,</span>\n<span class=\"s2\">   ...:  'log_count/ERROR': 5,</span>\n<span class=\"s2\">   ...:  'log_count/INFO': 75,</span>\n<span class=\"s2\">   ...:  'log_count/WARNING': 3,</span>\n<span class=\"s2\">   ...:  'offsite/domains': 1,</span>\n<span class=\"s2\">   ...:  'offsite/filtered': 1,</span>\n<span class=\"s2\">   ...:  'request_depth_max': 1,</span>\n<span class=\"s2\">   ...:  'response_received_count': 3,</span>\n<span class=\"s2\">   ...:  'retry/count': 2,</span>\n<span class=\"s2\">   ...:  'retry/max_reached': 1,</span>\n<span class=\"s2\">   ...:  'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,</span>\n<span class=\"s2\">   ...:  'scheduler/dequeued': 7,</span>\n<span class=\"s2\">   ...:  'scheduler/dequeued/memory': 7,</span>\n<span class=\"s2\">   ...:  'scheduler/enqueued': 7,</span>\n<span class=\"s2\">   ...:  'scheduler/enqueued/memory': 7,</span>\n<span class=\"s2\">   ...:  'start_time': datetime.datetime(2018, 10, 23, 10, 28, 35, 70938)}</span>\n<span class=\"s2\">   ...: 2018-10-23 18:29:42 [scrapy.core.engine] INFO: Spider closed (finished)\"\"\"</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"n\">odict</span> <span class=\"o\">=</span> <span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">headlines</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">taillines</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"n\">odict</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span>\n<span class=\"n\">OrderedDict</span><span class=\"p\">([(</span><span class=\"s1\">'head'</span><span class=\"p\">,</span>\n              <span class=\"s1\">'2018-10-23 18:28:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: demo)'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'tail'</span><span class=\"p\">,</span>\n              <span class=\"s1\">'2018-10-23 18:29:42 [scrapy.core.engine] INFO: Spider closed (finished)'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'first_log_time'</span><span class=\"p\">,</span> <span class=\"s1\">'2018-10-23 18:28:34'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'latest_log_time'</span><span class=\"p\">,</span> <span class=\"s1\">'2018-10-23 18:29:42'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'runtime'</span><span class=\"p\">,</span> <span class=\"s1\">'0:01:08'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'first_log_timestamp'</span><span class=\"p\">,</span> <span class=\"mi\">1540290514</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'latest_log_timestamp'</span><span class=\"p\">,</span> <span class=\"mi\">1540290582</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'datas'</span><span class=\"p\">,</span> <span class=\"p\">[]),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'pages'</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'items'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'latest_matches'</span><span class=\"p\">,</span>\n              <span class=\"p\">{</span><span class=\"s1\">'telnet_console'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'resuming_crawl'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'latest_offsite'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'latest_duplicate'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'latest_crawl'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'latest_scrape'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'latest_item'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n               <span class=\"s1\">'latest_stat'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">}),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'latest_crawl_timestamp'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'latest_scrape_timestamp'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'log_categories'</span><span class=\"p\">,</span>\n              <span class=\"p\">{</span><span class=\"s1\">'critical_logs'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'count'</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"s1\">'details'</span><span class=\"p\">:</span> <span class=\"p\">[]},</span>\n               <span class=\"s1\">'error_logs'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'count'</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"s1\">'details'</span><span class=\"p\">:</span> <span class=\"p\">[]},</span>\n               <span class=\"s1\">'warning_logs'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'count'</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"s1\">'details'</span><span class=\"p\">:</span> <span class=\"p\">[]},</span>\n               <span class=\"s1\">'redirect_logs'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'count'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'details'</span><span class=\"p\">:</span> <span class=\"p\">[]},</span>\n               <span class=\"s1\">'retry_logs'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'count'</span><span class=\"p\">:</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"s1\">'details'</span><span class=\"p\">:</span> <span class=\"p\">[]},</span>\n               <span class=\"s1\">'ignore_logs'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'count'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'details'</span><span class=\"p\">:</span> <span class=\"p\">[]}}),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'shutdown_reason'</span><span class=\"p\">,</span> <span class=\"s1\">'N/A'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'finish_reason'</span><span class=\"p\">,</span> <span class=\"s1\">'finished'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'crawler_stats'</span><span class=\"p\">,</span>\n              <span class=\"n\">OrderedDict</span><span class=\"p\">([(</span><span class=\"s1\">'source'</span><span class=\"p\">,</span> <span class=\"s1\">'log'</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'last_update_time'</span><span class=\"p\">,</span> <span class=\"s1\">'2018-10-23 18:29:41'</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'last_update_timestamp'</span><span class=\"p\">,</span> <span class=\"mi\">1540290581</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/exception_count'</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError'</span><span class=\"p\">,</span>\n                            <span class=\"mi\">3</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/request_bytes'</span><span class=\"p\">,</span> <span class=\"mi\">1336</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/request_count'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/request_method_count/GET'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/response_bytes'</span><span class=\"p\">,</span> <span class=\"mi\">1669</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/response_count'</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/response_status_count/200'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/response_status_count/302'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'downloader/response_status_count/404'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'dupefilter/filtered'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'finish_reason'</span><span class=\"p\">,</span> <span class=\"s1\">'finished'</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'finish_time'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'datetime.datetime(2018, 10, 23, 10, 29, 41, 174719)'</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'httperror/response_ignored_count'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'httperror/response_ignored_status_count/404'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'item_scraped_count'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'log_count/CRITICAL'</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'log_count/DEBUG'</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'log_count/ERROR'</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'log_count/INFO'</span><span class=\"p\">,</span> <span class=\"mi\">75</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'log_count/WARNING'</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'offsite/domains'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'offsite/filtered'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'request_depth_max'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'response_received_count'</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'retry/count'</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'retry/max_reached'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'retry/reason_count/twisted.internet.error.TCPTimedOutError'</span><span class=\"p\">,</span>\n                            <span class=\"mi\">2</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'scheduler/dequeued'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'scheduler/dequeued/memory'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'scheduler/enqueued'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'scheduler/enqueued/memory'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">),</span>\n                           <span class=\"p\">(</span><span class=\"s1\">'start_time'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'datetime.datetime(2018, 10, 23, 10, 28, 35, 70938)'</span><span class=\"p\">)])),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'last_update_time'</span><span class=\"p\">,</span> <span class=\"s1\">'2019-03-08 16:53:50'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'last_update_timestamp'</span><span class=\"p\">,</span> <span class=\"mi\">1552035230</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'logparser_version'</span><span class=\"p\">,</span> <span class=\"s1\">'0.8.1'</span><span class=\"p\">)])</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"n\">odict</span><span class=\"p\">[</span><span class=\"s1\">'runtime'</span><span class=\"p\">]</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"s1\">'0:01:08'</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"n\">odict</span><span class=\"p\">[</span><span class=\"s1\">'pages'</span><span class=\"p\">]</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"mi\">3</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"n\">odict</span><span class=\"p\">[</span><span class=\"s1\">'items'</span><span class=\"p\">]</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"mi\">2</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]:</span> <span class=\"n\">odict</span><span class=\"p\">[</span><span class=\"s1\">'finish_reason'</span><span class=\"p\">]</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]:</span> <span class=\"s1\">'finished'</span>\n</pre>\n</details>\n<h3>To run as a service</h3>\n<ol>\n<li><strong>Make sure that <a href=\"https://github.com/scrapy/scrapyd\" rel=\"nofollow\"><em>Scrapyd</em></a> has been installed and started on the current host.</strong></li>\n<li>Start <em><strong>LogParser</strong></em> via command <code>logparser</code></li>\n<li>Visit <a href=\"http://127.0.0.1:6800/logs/stats.json\" rel=\"nofollow\">http://127.0.0.1:6800/logs/stats.json</a> <strong>(Assuming the Scrapyd service runs on port 6800.)</strong></li>\n<li>Visit <a href=\"http://127.0.0.1:6800/logs/projectname/spidername/jobid.json\" rel=\"nofollow\">http://127.0.0.1:6800/logs/projectname/spidername/jobid.json</a> to get stats of a job in details.</li>\n</ol>\n<h3>To work with <em>ScrapydWeb</em> for visualization</h3>\n<p>Check out <a href=\"https://github.com/my8100/scrapydweb\" rel=\"nofollow\">https://github.com/my8100/scrapydweb</a> for more info.</p>\n<p><img alt=\"stats\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c31c4c25e64862107ba9dd62077a8b2818ed6ac4/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d79383130302f66696c65732f6d61737465722f736372617079647765622f73637265656e73686f74732f73746174732e676966\"></p>\n\n          </div>"}, "last_serial": 5630865, "releases": {"0.8.0": [{"comment_text": "", "digests": {"md5": "5875b553e01e39ef843b72a0a8c3fe97", "sha256": "620f5fd7755baeb94e59de973b96af1e00aadf17ebe6b39441def77c88f54c57"}, "downloads": -1, "filename": "logparser-0.8.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5875b553e01e39ef843b72a0a8c3fe97", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 30314, "upload_time": "2019-01-20T16:29:55", "upload_time_iso_8601": "2019-01-20T16:29:55.759025Z", "url": "https://files.pythonhosted.org/packages/da/aa/302d0d52f57fb53323375360ef9805e6c25b7a293050ddb04e095c6e9d13/logparser-0.8.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ff95d41b77b1fe070b29d66e94fa17f0", "sha256": "840bcc27a5c9d10bb5a0e5f322e0b19f17fd6d4e9af70c984f88b87fe6c80215"}, "downloads": -1, "filename": "logparser-0.8.0.tar.gz", "has_sig": false, "md5_digest": "ff95d41b77b1fe070b29d66e94fa17f0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 16738, "upload_time": "2019-01-20T16:29:59", "upload_time_iso_8601": "2019-01-20T16:29:59.031596Z", "url": "https://files.pythonhosted.org/packages/f3/b2/ef1157ceaa534b174c0ca5e8d5cd2098b39ed83d299870e497e098a6ccbf/logparser-0.8.0.tar.gz", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "d48431484021f7b3fd274e8779fcbf52", "sha256": "b427adddb893df09fad301c905cd7bea8ff5a7ebe10dd8083ed292ad757f2943"}, "downloads": -1, "filename": "logparser-0.8.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d48431484021f7b3fd274e8779fcbf52", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 34343, "upload_time": "2019-03-12T09:56:01", "upload_time_iso_8601": "2019-03-12T09:56:01.432541Z", "url": "https://files.pythonhosted.org/packages/21/84/f81d5af38b742814802773032997c5e08556f2cd4d0f215b4c3c873e576a/logparser-0.8.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e6f7aa916dc7583089ff1f651c797f10", "sha256": "71e40609614a860b5b8187f7aab67419136c9d92832dbbd346ad3aba1c36b4c4"}, "downloads": -1, "filename": "logparser-0.8.1.tar.gz", "has_sig": false, "md5_digest": "e6f7aa916dc7583089ff1f651c797f10", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 20818, "upload_time": "2019-03-12T09:58:39", "upload_time_iso_8601": "2019-03-12T09:58:39.020564Z", "url": "https://files.pythonhosted.org/packages/3f/08/420f7447f106d01586b0f22e3a4c3b5f845d78e050ac4a907d7e4525f602/logparser-0.8.1.tar.gz", "yanked": false}], "0.8.2": [{"comment_text": "", "digests": {"md5": "ef00fab72ff523182c5d58e0096a9cb0", "sha256": "9d34701ff8ae22596a987eb10defd81c86003860a9289e74f72ee185f7c01db8"}, "downloads": -1, "filename": "logparser-0.8.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ef00fab72ff523182c5d58e0096a9cb0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 37312, "upload_time": "2019-08-04T15:19:19", "upload_time_iso_8601": "2019-08-04T15:19:19.652311Z", "url": "https://files.pythonhosted.org/packages/d6/7e/528828509144799c08e903e0f49cbc037cec4128286eaafa19e312263651/logparser-0.8.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "11bed4a1de8927840325600137aa6be4", "sha256": "b1720067ba267f13a4c1b08cfdcad5b9ed7e0db95817a46a946de83a5b18f227"}, "downloads": -1, "filename": "logparser-0.8.2.tar.gz", "has_sig": false, "md5_digest": "11bed4a1de8927840325600137aa6be4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 23568, "upload_time": "2019-08-04T15:19:21", "upload_time_iso_8601": "2019-08-04T15:19:21.653652Z", "url": "https://files.pythonhosted.org/packages/0e/e1/c2679116e29ff09cb5018635297fbe59ab371eae1d9b913b0e9e22a6e974/logparser-0.8.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ef00fab72ff523182c5d58e0096a9cb0", "sha256": "9d34701ff8ae22596a987eb10defd81c86003860a9289e74f72ee185f7c01db8"}, "downloads": -1, "filename": "logparser-0.8.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ef00fab72ff523182c5d58e0096a9cb0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 37312, "upload_time": "2019-08-04T15:19:19", "upload_time_iso_8601": "2019-08-04T15:19:19.652311Z", "url": "https://files.pythonhosted.org/packages/d6/7e/528828509144799c08e903e0f49cbc037cec4128286eaafa19e312263651/logparser-0.8.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "11bed4a1de8927840325600137aa6be4", "sha256": "b1720067ba267f13a4c1b08cfdcad5b9ed7e0db95817a46a946de83a5b18f227"}, "downloads": -1, "filename": "logparser-0.8.2.tar.gz", "has_sig": false, "md5_digest": "11bed4a1de8927840325600137aa6be4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*", "size": 23568, "upload_time": "2019-08-04T15:19:21", "upload_time_iso_8601": "2019-08-04T15:19:21.653652Z", "url": "https://files.pythonhosted.org/packages/0e/e1/c2679116e29ff09cb5018635297fbe59ab371eae1d9b913b0e9e22a6e974/logparser-0.8.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:09 2020"}