{"info": {"author": "yilei.wang", "author_email": "stevewyl@163.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# nlp_toolkit\n\n\u4e2d\u6587NLP\u57fa\u7840\u5de5\u5177\u7bb1\uff0c\u5305\u62ec\u4ee5\u4e0b\u4efb\u52a1\uff1a\u4f8b\u5982\u6587\u672c\u5206\u7c7b\u3001\u5e8f\u5217\u6807\u6ce8\u7b49\u3002\n\n\u672c\u4ed3\u5e93\u590d\u73b0\u4e86\u4e00\u4e9b\u8fd1\u51e0\u5e74\u6bd4\u8f83\u706b\u7684nlp\u8bba\u6587\u3002\u6240\u6709\u7684\u4ee3\u7801\u662f\u57fa\u4e8ekeras\u5f00\u53d1\u7684\u3002\n\n\u4e0d\u523010\u884c\u4ee3\u7801\uff0c\u4f60\u5c31\u53ef\u4ee5\u5feb\u901f\u8bad\u7ec3\u4e00\u4e2a\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff08\u6682\u65f6\u4e0d\u652f\u6301\u591a\u6807\u7b7e\u4efb\u52a1\uff09\u6216\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\uff0c\u6216\u8005\u53ef\u4ee5\u4f53\u9a8c\u57fa\u4e8e\u540d\u8bcd\u77ed\u8bed\u5207\u5206\u7684\u5206\u8bcd\u5668\n\n## \u76f4\u63a5\u5b89\u88c5\n\n```bash\npip install nlp_toolkit\n\n# \u4f7f\u7528GPU\npip install tensorflow-gpu, GPUtil\n```\n\n## \u624b\u52a8\u5b89\u88c5\n\n```bash\ngit clone https://github.com/stevewyl/nlp_toolkit\ncd nlp_toolkit\n\n# \u53ea\u4f7f\u7528CPU\npip install -r requirements.txt\n\n# \u4f7f\u7528GPU\npip install -r requirements-gpu.txt\n\n# \u5982\u679ckeras_contrib\u5b89\u88c5\u5931\u8d25\npip install git+https://www.github.com/keras-team/keras-contrib.git\n```\n\n### \u5b89\u88c5\u9519\u8bef\n\n1. ImportError: cannot import name 'normalize_data_format'\n\n    ```bash\n    pip install -U keras\n    ```\n\n## \u4f7f\u7528\u65b9\u6cd5\n\n\u672c\u4ed3\u5e93\u7684\u6846\u67b6\u56fe\uff1a\n\n![framework](./images/framework.jpg)\n\n\u4e3b\u8981\u7531\u4ee5\u4e0b\u51e0\u5927\u6a21\u5757\u7ec4\u6210\uff1a\n\n1. Dataset\uff1a\u5904\u7406\u6587\u672c\u548c\u6807\u7b7e\u6570\u636e\u4e3a\u9002\u5408\u6a21\u578b\u8f93\u5165\u7684\u683c\u5f0f\uff0c\u4e3b\u8981\u8fdb\u884c\u7684\u5904\u7406\u64cd\u4f5c\u6709\u6e05\u7406\u3001\u5206\u8bcd\u3001index\u5316\n\n2. Model Zoo & Layer\uff1a\u8fd1\u51e0\u5e74\u5728\u8be5\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u6a21\u578b\u6c47\u603b\u53ca\u4e00\u4e9bKeras\u7684\u81ea\u5b9a\u4e49\u5c42\n\n   \u76ee\u524d\u652f\u6301\u7684\u81ea\u5b9a\u4e49\u5c42\u6709\u5982\u4e0b\uff1a\n\n   * 1D\u6ce8\u610f\u529b\u5c42 \ud83c\udd97\n   * 2D\u6ce8\u610f\u529b\u5c42 \ud83c\udd97\n   * \u591a\u5934\u6ce8\u610f\u529b\u5c42 \ud83c\udd97\n   * \u4f4d\u7f6e\u5d4c\u5165\u5c42 \ud83c\udd97\n   * K-max\u6c60\u5316\u5c42\n\n3. Trainer\uff1a\u5b9a\u4e49\u6a21\u578b\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u652f\u6301bucket\u5e8f\u5217\u3001\u81ea\u5b9a\u4e49callbacks\u548cN\u6298\u4ea4\u53c9\u9a8c\u8bc1\n\n    * bucket\u5e8f\u5217\uff1a\u901a\u8fc7\u5c06\u76f8\u4f3c\u957f\u5ea6\u7684\u6587\u672c\u653e\u5165\u540c\u4e00batch\u6765\u51cf\u5c0fpadding\u7684\u591a\u4f59\u8ba1\u7b97\u6765\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u7684\u52a0\u901f\uff0c\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u80fd\u591f\u5bf9RNN\u7f51\u7edc\u63d0\u901f2\u500d\u4ee5\u4e0a\uff08**\u6682\u65f6\u4e0d\u652f\u6301\u542b\u6709Flatten\u5c42\u7684\u7f51\u7edc**\uff09\n  \n    * callbacks\uff1a\u901a\u8fc7\u81ea\u5b9a\u4e49\u56de\u8c03\u5668\u6765\u63a7\u5236\u8bad\u7ec3\u6d41\u7a0b\uff0c\u76ee\u524d\u9884\u8bbe\u7684\u56de\u8c03\u5668\u6709\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\uff0c\u5b66\u4e60\u7387\u81ea\u52a8\u53d8\u5316\uff0c\u66f4\u4e30\u5bcc\u7684\u8bc4\u4f30\u51fd\u6570\u7b49\n\n    * N\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff1a\u652f\u6301\u4ea4\u53c9\u9a8c\u8bc1\u6765\u8003\u9a8c\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b\n\n4. Classifier & Sequence Labeler\uff1a\u5c01\u88c5\u7c7b\uff0c\u652f\u6301\u4e0d\u540c\u7684\u8bad\u7ec3\u4efb\u52a1\n\n5. Application\uff1a\u76ee\u524d\u5de5\u5177\u7bb1\u5185\u5c01\u88c5\u4e86\u57fa\u4e8ejieba\u7684\u540d\u8bcd\u77ed\u8bed\u5206\u8bcd\u5668 Chunk_Segmentor (\u5982\u9700\u6a21\u578b\u6587\u4ef6\uff0c\u53ef\u4ee5\u90ae\u4ef6\u8054\u7cfb\u6211)\n\n\u7b80\u5355\u7684\u7528\u6cd5\u5982\u4e0b\uff1a\n\n```python\nfrom nlp_toolkit import Dataset, Classifier, Labeler\nimport yaml\n\nconfig = yaml.load(open('your_config.yaml'))\n\n# \u5206\u7c7b\u4efb\u52a1\ndataset = Dataset(fname='your_data.txt', task_type='classification', mode='train', config=config)\ntext_classifier = Classifier('multi_head_self_att', dataset)\ntrained_model = text_classifier.train()\n\n# \u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\ndataset = Dataset(fname='your_data.txt', task_type='sequence_labeling', mode='train', config=config)\nseq_labeler = Labeler('word_rnn', dataset)\ntrained_model = seq_labeler.train()\n\n# \u9884\u6d4b\uff08\u4ee5\u6587\u672c\u5206\u7c7b\u4e3a\u4f8b\uff09\ndataset = Dataset(fname='your_data.txt', task_type='classification', mode='predict', tran_fname='your_transformer.h5')\ntext_classifier = Classifier('bi_lstm_att', dataset)\ntext_classifier.load(weight_fname='your_model_weights.h5', para_fname='your_model_parameters.json')\ny_pred = text_classifier.predict(dataset.texts)\n\n# chunk\u5206\u8bcd\n# \u7b2c\u4e00\u6b21import\u7684\u65f6\u5019\uff0c\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u6a21\u578b\u548c\u5b57\u5178\u6570\u636e\n# \u652f\u6301\u5355\u53e5\u548c\u591a\u53e5\u6587\u672c\u7684\u8f93\u5165\u683c\u5f0f\uff0c\u5efa\u8bae\u4ee5\u5217\u8868\u7684\u5f62\u5f0f\u4f20\u5165\u5206\u8bcd\u5668\n# \u6e90\u4ee3\u7801\u4e2d\u5df2\u7565\u53bb\u76f8\u5173\u6570\u636e\u7684\u4e0b\u8f7d\u8def\u5f84\uff0c\u6709\u9700\u8981\u7684\u8bf7\u90ae\u4ef6\u8054\u7cfb\nfrom nlp_toolkit.chunk_segmentor import Chunk_Segmentor\ncutter = Chunk_Segmentor()\ns = '\u8fd9\u662f\u4e00\u4e2a\u80fd\u591f\u8f93\u51fa\u540d\u8bcd\u77ed\u8bed\u7684\u5206\u8bcd\u5668\uff0c\u6b22\u8fce\u8bd5\u7528\uff01'\nres = [item for item in cutter.cut([s] * 10000)] # 1080ti\u4e0a\u8017\u65f68s\n# \u63d0\u4f9b\u4e24\u4e2a\u7248\u672c\uff0caccurate\u4e3a\u7cbe\u786e\u7248\uff0cfast\u4e3a\u5feb\u901f\u7248\u4f46\u53ec\u56de\u4f1a\u964d\u4f4e\u4e00\u4e9b\uff0c\u9ed8\u8ba4\u7cbe\u786e\u7248\ncutter = Chunk_Segmentor(mode='accurate')\ncutter = Chunk_Segmentor(mode='fast')\n# \u662f\u5426\u8f93\u51fa\u8bcd\u6027\uff0c \u9ed8\u8ba4\u5f00\u542f\ncutter.cut(s, pos=False)\n# \u662f\u5426\u5c06\u53ef\u5207\u5206\u7684\u540d\u8bcd\u77ed\u8bed\u5207\u5206\uff0c\u9ed8\u8ba4\u5173\u95ed\ncutter.cut(s, cut_all=True)\n# \u8f93\u51fa\u683c\u5f0f\uff08\u8bcd\u5217\u8868\uff0c\u8bcd\u6027\u5217\u8868\uff0c\u540d\u8bcd\u77ed\u8bed\u96c6\u5408\uff09\n[\n    (\n        ['\u8fd9', '\u662f', '\u4e00\u4e2a', '\u80fd\u591f', '\u8f93\u51fa', '\u540d\u8bcd_\u77ed\u8bed', '\u7684', '\u5206\u8bcd\u5668', ',', '\u6b22\u8fce', '\u8bd5\u7528', '!'],\n        ['r', 'v', 'mq', 'v', 'vn', 'np', 'ude1', 'np', 'w', 'v', 'v', 'w'],\n        ['\u5206\u8bcd\u5668', '\u540d\u8bcd_\u77ed\u8bed']\n    )\n    ...\n]\n```\n\n\u66f4\u591a\u4f7f\u7528\u7ec6\u8282\uff0c\u8bf7\u9605\u8bfb[**examples**](https://github.com/stevewyl/nlp_toolkit/tree/master/examples)\u6587\u4ef6\u5939\u4e2d\u7684Jupyter Notebook\u548cchunk_segmentor\u9875\u9762\u7684[**README**](https://github.com/stevewyl/nlp_toolkit/tree/master/nlp_toolkit/chunk_segmentor)\n\n### \u6570\u636e\u683c\u5f0f\n\n1. \u6587\u672c\u5206\u7c7b\uff1a\u6bcf\u4e00\u884c\u9884\u5148\u5206\u597d\u8bcd\u7684\u6587\u4ef6\uff0c\u6bcf\u4e00\u884c\u7684\u683c\u5f0f\u5982\u4e0b\uff1a\n\n    __label__\u6807\u7b7e1 __label__\u6807\u7b7e2 ... \u8bcd \u8bcd ... \u8bcd\\n\n\n    \u4f8b\u5982 \u201c__label__neg \u516c\u53f8 \u76ee\u524d \u5730\u7406 \u4f4d\u7f6e \u4e0d \u592a \u7406\u60f3 \uff0c \u79bb \u57ce\u5e02 \u4e2d\u5fc3 \u8f83 \u8fdc\u70b9 \u3002\u201d\n\n2. \u5e8f\u5217\u6807\u6ce8\uff1a\u6bcf\u4e00\u884c\u9884\u5148\u5206\u597d\u8bcd\u7684\u6587\u4ef6\uff0c\u652f\u6301\u4e24\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u6bcf\u4e00\u884c\u7684\u683c\u5f0f\u5982\u4e0b\uff1a\n\n    \u8bcd###\u6807\u7b7e [TAB] \u8bcd###\u6807\u7b7e [TAB] ... \\n\n\n    \u4f8b\u5982 \u201c\u76ee\u524d###O\\t\u516c\u53f8###O\\t\u5730\u7406###B-Chunk\\t\u4f4d\u7f6e###E-Chunk\\t\u4e0d###O\\t\u592a###O\\t\u7406\u60f3\\n\u201d\n\n    \u6216\u8005 CONLL\u7684\u6807\u51c6\u683c\u5f0f\n\n    \u8bcd [TAB] \u6807\u7b7e\n\n    \u8bcd [TAB] \u6807\u7b7e\n\n    ...\n\n    \u8bcd [TAB] \u6807\u7b7e\n\n    \u8bcd [TAB] \u6807\u7b7e\n\n    ...\n\n    \u4f8b\u5982\uff1a\n\n    \u76ee\u524d\\tO\n\n    \u516c\u53f8\\tO\n\n    ...\n\n    \u5730\u7406\\tB-Chunk\n\n    \u4f4d\u7f6e\\tE-Chunk\n\n    \u4e0d\\tO\n\n    \u592a\\tO\n\n    \u7406\u60f3\\tO\n\n    \u6807\u7b7e\u542b\u4e49\uff08\u8fd9\u91cc\u4ee5chunk\u4e3a\u4f8b\uff09\uff1a\n\n    * O\uff1a\u666e\u901a\u8bcd\n    * B-Chunk\uff1a\u8868\u793achunk\u8bcd\u7684\u5f00\u59cb\n    * I-Chunk\uff1a\u8868\u793achunk\u8bcd\u7684\u4e2d\u95f4\n    * E-Chunk\uff1a\u8868\u793achunk\u8bcd\u7684\u7ed3\u675f\n\n    \u5efa\u8bae\uff1a\u6587\u672c\u5e8f\u5217\u4ee5\u77ed\u53e5\u4e3a\u4e3b\uff0c\u9488\u5bf9\u6807\u6ce8\u5b9e\u4f53\u7684\u4efb\u52a1\uff0c\u6700\u597d\u4fdd\u8bc1\u6bcf\u884c\u6570\u636e\u4e2d\u6709\u5b9e\u4f53\u8bcd\uff08\u5373\u975e\u5168O\u7684\u5e8f\u5217\uff09\n\n    \u4f60\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4e92\u76f8\u8f6c\u6362\u4e24\u79cd\u6570\u636e\u683c\u5f0f\uff1a\n    ```python\n    from nlp_toolkit.utilities import convert_seq_format\n    # here we convert dataset from conll format to basic format\n    convert_seq_format(input_file, output_file, 'basic')\n    ```\n\n    ps: \u5177\u4f53\u53ef\u67e5\u770bdata\u6587\u4ef6\u5939\u4e2d\u5bf9\u5e94\u7684[**\u793a\u4f8b\u6570\u636e**](https://github.com/stevewyl/nlp_toolkit/tree/master/sample_data)\n\n3. \u9884\u6d4b\uff1a\u4e0d\u540c\u4efb\u52a1\u6bcf\u4e00\u884c\u5747\u4e3a\u9884\u5148\u5206\u597d\u8bcd\u7684\u6587\u672c\u5e8f\u5217\n\n4. \u652f\u6301\u7b80\u5355\u7684\u81ea\u5df1\u6dfb\u52a0\u6570\u636e\u7684\u65b9\u6cd5\n\n   ```python\n   dataset = Dataset(task_type='classification', mode='train', config=config)\n   # classification\n   dataset.add({'text': '\u6211 \u7231 \u673a\u5668 \u5b66\u4e60', 'label': 'pos'})\n   # sequence labeling\n   dataset.add({'text': '\u6211 \u7231 \u673a\u5668 \u5b66\u4e60', 'label': 'O O B-Chunk E-Chunk'})\n   # after you add all your data\n   dataset.fit()\n   ```\n\n### \u914d\u7f6e\u6587\u4ef6\n\nnlp_toolkit\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u6765\u521d\u59cb\u5316\u8bad\u7ec3\u4efb\u52a1\n\ntrain: \u8868\u793a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53c2\u6570\uff0c\u5305\u62ecbatch\u5927\u5c0f\uff0cepoch\u6570\u91cf\uff0c\u8bad\u7ec3\u6a21\u5f0f\u7b49\n\ndata: \u8868\u793a\u6570\u636e\u9884\u5904\u7406\u7684\u53c2\u6570\uff0c\u5305\u62ec\u6700\u5927\u8bcd\u6570\u548c\u5b57\u7b26\u6570\uff0c\u662f\u5426\u4f7f\u7528\u8bcd\u5185\u90e8\u5b57\u7b26\u5e8f\u5217\u7b49\n\nembed: \u8bcd\u5411\u91cf\uff0cpre\u8868\u793a\u662f\u5426\u4f7f\u7528\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\n\n\u5269\u4e0b\u7684\u6a21\u5757\u5bf9\u5e94\u4e0d\u540c\u7684\u6a21\u578b\u7684\u8d85\u53c2\u6570\n\n\u5177\u4f53\u7ec6\u8282\u53ef\u67e5\u770b\u4ed3\u5e93\u6839\u76ee\u5f55\u4e0b\u7684\u4e24\u4e2a**\u914d\u7f6e\u6587\u4ef6**\u6ce8\u91ca\n\n### \u53ef\u89c6\u5316\n\n1. attention\u6743\u91cd\u53ef\u89c6\u5316\n\n    ```python\n    # only support model bi_lstm_att currently\n    # first you need to get attention_weights from model predictions\n    # you can find the actual usage in examples/sentiment.ipynb\n    texts = '\u6709 \u80fd\u529b \u7684 \u4eba \u5c31 \u6709 \u5f88\u591a \u673a\u4f1a'\n    from nlp_toolkit import visualization as vs\n    vs.mk_html(texts, attention_weights)\n    ```\n\n    <span style=\"background-color: #FFFAFA\">\u6709</span> <span style=\"background-color: #FFB6B6\">\u80fd\u529b</span> <span style=\"background-color: #FFFBFB\">\u7684</span> <span style=\"background-color: #FFF8F8\">\u4eba</span> <span style=\"background-color: #FFEFEF\">\u5c31</span> <span style=\"background-color: #FFE3E3\">\u6709</span> <span style=\"background-color: #FFEFEF\">\u5f88\u591a</span> <span style=\"background-color: #FF9191\">\u673a\u4f1a</span>\n\n2. \u5b9e\u4f53\u9884\u6d4b\u7ed3\u679c\u53ef\u89c6\u5316\n\n   ```python\n   from nlp_toolkit import visualization as vs\n   vs.entity_visualization(dataset.texts, y_pred, output_fname='result.html')\n   ```\n\n3. acc/loss \u66f2\u7ebf\u53ef\u89c6\u5316\n\n   ```python\n   # after your have trained one model, you will also get a history object, which contains some loss and metrics info\n   from nlp_toolkit import visualization as vs\n   vs.plot_loss_acc(history, task='sequence_labeling')\n   ```\n\n### \u5176\u4ed6\n\n1. \u751f\u6210\u8bcd\u5411\u91cf\u5c0f\u6587\u4ef6\n\n    ```python\n    from nlp_toolkit.utilities import gen_small_embedding\n    gen_small_embedding(vocab_file, embed_file, output_file)\n    ```\n\n## \u6a21\u578b\n\n### \u6587\u672c\u5206\u7c7b\n\n1. \u53cc\u5c42\u53cc\u5411LSTM + Attention \ud83c\udd97\n\n    [DeepMoji](https://arxiv.org/abs/1708.00524)\u4e00\u6587\u4e2d\u6240\u91c7\u7528\u7684\u7684\u6a21\u578b\u6846\u67b6\uff0c\u672c\u4ed3\u5e93\u4e2d\u5bf9attention\u5c42\u4f5c\u4e86\u6269\u5c55\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1abi_lstm_att\n\n2. [Transformer](http://papers.nips.cc/paper/7181-attention-is-all-you-need) \ud83c\udd97\n\n    \u91c7\u7528Transformer\u4e2d\u7684\u591a\u5934\u81ea\u6ce8\u610f\u529b\u5c42\u6765\u8868\u5f81\u6587\u672c\u4fe1\u606f\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64[\u6587\u7ae0](https://kexue.fm/archives/4765)\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1amulti_head_self_att\n\n3. [TextCNN](https://arxiv.org/abs/1408.5882) \ud83c\udd97\n\n    CNN\u7f51\u7edc\u4e4b\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u5f00\u5c71\u4e4b\u4f5c\uff0c\u5728\u8fc7\u53bb\u51e0\u5e74\u4e2d\u7ecf\u5e38\u88ab\u7528\u4f5cbaseline\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64[\u6587\u7ae0](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1atext_cnn\n\n4. [DPCNN](http://www.aclweb.org/anthology/P17-1052) \ud83c\udd97\n\n    \u5728textCNN\u7684\u57fa\u7840\u4e0a\uff0cDPCNN\u4f7f\u7528\u6b8b\u5dee\u8fde\u63a5\u3001\u56fa\u5b9afeature map\u6570\u91cf\u548c1/2\u6c60\u5316\u5c42\u7b49\u6280\u5de7\u6765\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u6587\u672c\u8868\u793a\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64[\u6587\u7ae0](https://zhuanlan.zhihu.com/p/35457093)\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1adpcnn\n    \u6682\u65f6\u4e0d\u652f\u6301bucket\u5e8f\u5217\u5316\u7684\u6570\u636e\n\n5. [HAN](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf)\n\n    \u4f7f\u7528attention\u673a\u5236\u7684\u6587\u6863\u5206\u7c7b\u6a21\u578b\n\n### \u5e8f\u5217\u6807\u6ce8\n\n1. [WordRNN](https://arxiv.org/abs/1707.06799) \ud83c\udd97\n\n    Baseline\u6a21\u578b\uff0c\u6587\u672c\u5e8f\u5217\u7ecf\u8fc7\u53cc\u5411LSTM\u540e\uff0c\u7531CRF\u5c42\u7f16\u7801\u4f5c\u4e3a\u8f93\u51fa\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1aword_rnn\n\n2. [CharRNN](https://pdfs.semanticscholar.org/b944/5206f592423f0b2faf05f99de124ccc6aaa8.pdf) \ud83c\udd97\n\n    \u57fa\u4e8e\u6c49\u8bed\u7684\u7279\u70b9\uff0c\u5728\u5b57\u7b26\u7ea7\u522b\u7684LSTM\u4fe1\u606f\u5916\uff0c\u52a0\u5165\u504f\u65c1\u90e8\u9996\uff0c\u5206\u8bcd\uff0cNgram\u4fe1\u606f\n\n3. [InnerChar](https://arxiv.org/abs/1611.04361) \ud83c\udd97\n\n    \u57fa\u4e8e\u53e6\u5916\u4e00\u7bc7[\u8bba\u6587](https://arxiv.org/abs/1511.08308)\uff0c\u6269\u5c55\u4e86\u672c\u6587\u7684\u6a21\u578b\uff0c\u4f7f\u7528bi-lstm\u6216CNN\u5728\u8bcd\u5185\u90e8\u7684char\u7ea7\u522b\u8fdb\u884c\u4fe1\u606f\u7684\u62bd\u53d6\uff0c\u7136\u540e\u4e0e\u539f\u6765\u7684\u8bcd\u5411\u91cf\u8fdb\u884cconcat\u6216attention\u8ba1\u7b97\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1aword_rnn\uff0c\u5e76\u8bbe\u7f6e\u914d\u7f6e\u6587\u4ef6data\u6a21\u5757\u4e2d\u7684inner_char\u4e3aTrue\n\n4. [IDCNN](https://arxiv.org/abs/1702.02098) \ud83c\udd97\n\n    \u81a8\u80c0\u5377\u79ef\u7f51\u7edc\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u91cf\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u589e\u5927\u4e86\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64[\u6587\u7ae0](http://www.crownpku.com//2017/08/26/%E7%94%A8IDCNN%E5%92%8CCRF%E5%81%9A%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E4%B8%AD%E6%96%87%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.html)\n\n    \u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1aidcnn\n\n## \u6027\u80fd\n\n\u540e\u7eed\u52a0\u5165\u5bf9\u4e2d\u6587NLP\u7684\u6807\u51c6\u6570\u636e\u96c6\u7684\u6d4b\u8bd5\n\n### \u6587\u672c\u5206\u7c7b\n\n\u6d4b\u8bd5\u6570\u636e\u96c6\uff1a\n\n1. \u516c\u53f8\u4f18\u7f3a\u70b9\u8bc4\u4ef7\uff0c\u4e8c\u5206\u7c7b\uff0c\u6570\u636e\u89c4\u6a21\uff1a95K\n\n    Model                   | 10-fold_f1   | Model Size   | Time per epoch\n    ----------------------- | :------:     | :----------: | :-------------:\n    Bi-LSTM Attention       |              |              |\n    Transformer             |              | 7M           | 12s\n    TextCNN                 | 96.57        | 10M          | 19s\n    DPCNN                   | 93.35        | 9M           | 28s\n    HAN                     |              |              |\n\n### \u5e8f\u5217\u6807\u6ce8\n\n\u6d4b\u8bd5\u6570\u636e\u96c6\uff1a\n\n1. \u7b80\u5386\u5de5\u4f5c\u7ecf\u5386\uff0cchunk\uff0c\u6570\u636e\u89c4\u6a21\uff1a58K\n\n    Model                   | 10-fold_f1   | Model Size   | Time per epoch\n    ----------------------- | :------:     | :----------: | :-------------:\n    Baseline(WordRNN)       |              |              |\n    WordRNN + InnerChar     |              | 3M           | 165s\n    CharRNN(seg+radical)    |              |              |\n    IDCNN                   |              | 2.7M         | 43s\n\nps: \u6a21\u578b\u5927\u5c0f\u8868\u793a\u4e3a\u6a21\u578b\u7684\u53c2\u6570\u91cf\uff0c\u5176\u4e2dK\u8868\u793a\u5343\uff0cM\u8868\u793a\u767e\u4e07\uff1b\u6d4b\u8bd5\u8bbe\u5907\u4e3a1080ti+i7-6800K\n\n## To-Do\u5217\u8868\n\n1. \u52a0\u5165\u66f4\u591aSOTA\u7684\u6a21\u578b\u548c\u81ea\u5b9a\u4e49\u5c42\n\n2. \u4e0b\u4e00\u7248\u672c\u89c4\u5212\uff1a\u589e\u52a0\u62bd\u8c61\u7c7bSentence\n\n3. V2.0\u89c4\u5212\uff1a\u5207\u6362\u4e3atf.estimator\u548ctf.keras\u7684API\n\n## \u611f\u8c22\n\n* \u6570\u636e\u6d41\u6a21\u5757\u90e8\u5206\u4ee3\u7801\u501f\u9274\u4e8e\u6b64\uff1a https://github.com/Hironsan/anago/\n\n* \u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u7684\u8bc4\u4f30\u51fd\u6570\u6765\u6e90\u4e8e\u6b64\uff1a https://github.com/chakki-works/seqeval\n  \n* bucket\u5e8f\u5217\u5316\u4ee3\u7801\u6765\u81ea\uff1ahttps://github.com/tbennun/keras-bucketed-sequence\n\n* \u591a\u5934\u6ce8\u610f\u529b\u5c42\u548c\u4f4d\u7f6e\u5d4c\u5165\u5c42\u4ee3\u7801\u6765\u81ea\uff1ahttps://github.com/bojone/attention\n\n## \u8054\u7cfb\u65b9\u5f0f\n\n\u8054\u7cfb\u4eba\uff1a\u738b\u5955\u78ca\n\n\ud83d\udce7 \u90ae\u7bb1\uff1astevewyl@163.com\n\n\u5fae\u4fe1\uff1aSteve_1125", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/stevewyl/nlp_toolkit", "keywords": "nlp keras text classification sequence labeling", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "nlp-toolkit", "package_url": "https://pypi.org/project/nlp-toolkit/", "platform": "", "project_url": "https://pypi.org/project/nlp-toolkit/", "project_urls": {"Homepage": "https://github.com/stevewyl/nlp_toolkit"}, "release_url": "https://pypi.org/project/nlp-toolkit/1.3.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "NLP Toolkit with easy model training and applications", "version": "1.3.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>nlp_toolkit</h1>\n<p>\u4e2d\u6587NLP\u57fa\u7840\u5de5\u5177\u7bb1\uff0c\u5305\u62ec\u4ee5\u4e0b\u4efb\u52a1\uff1a\u4f8b\u5982\u6587\u672c\u5206\u7c7b\u3001\u5e8f\u5217\u6807\u6ce8\u7b49\u3002</p>\n<p>\u672c\u4ed3\u5e93\u590d\u73b0\u4e86\u4e00\u4e9b\u8fd1\u51e0\u5e74\u6bd4\u8f83\u706b\u7684nlp\u8bba\u6587\u3002\u6240\u6709\u7684\u4ee3\u7801\u662f\u57fa\u4e8ekeras\u5f00\u53d1\u7684\u3002</p>\n<p>\u4e0d\u523010\u884c\u4ee3\u7801\uff0c\u4f60\u5c31\u53ef\u4ee5\u5feb\u901f\u8bad\u7ec3\u4e00\u4e2a\u6587\u672c\u5206\u7c7b\u6a21\u578b\uff08\u6682\u65f6\u4e0d\u652f\u6301\u591a\u6807\u7b7e\u4efb\u52a1\uff09\u6216\u5e8f\u5217\u6807\u6ce8\u6a21\u578b\uff0c\u6216\u8005\u53ef\u4ee5\u4f53\u9a8c\u57fa\u4e8e\u540d\u8bcd\u77ed\u8bed\u5207\u5206\u7684\u5206\u8bcd\u5668</p>\n<h2>\u76f4\u63a5\u5b89\u88c5</h2>\n<pre>pip install nlp_toolkit\n\n<span class=\"c1\"># \u4f7f\u7528GPU</span>\npip install tensorflow-gpu, GPUtil\n</pre>\n<h2>\u624b\u52a8\u5b89\u88c5</h2>\n<pre>git clone https://github.com/stevewyl/nlp_toolkit\n<span class=\"nb\">cd</span> nlp_toolkit\n\n<span class=\"c1\"># \u53ea\u4f7f\u7528CPU</span>\npip install -r requirements.txt\n\n<span class=\"c1\"># \u4f7f\u7528GPU</span>\npip install -r requirements-gpu.txt\n\n<span class=\"c1\"># \u5982\u679ckeras_contrib\u5b89\u88c5\u5931\u8d25</span>\npip install git+https://www.github.com/keras-team/keras-contrib.git\n</pre>\n<h3>\u5b89\u88c5\u9519\u8bef</h3>\n<ol>\n<li>\n<p>ImportError: cannot import name 'normalize_data_format'</p>\n<pre>pip install -U keras\n</pre>\n</li>\n</ol>\n<h2>\u4f7f\u7528\u65b9\u6cd5</h2>\n<p>\u672c\u4ed3\u5e93\u7684\u6846\u67b6\u56fe\uff1a</p>\n<p><img alt=\"framework\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/26d6eec1e769e437b834268d0690d211cf2c76bd/2e2f696d616765732f6672616d65776f726b2e6a7067\"></p>\n<p>\u4e3b\u8981\u7531\u4ee5\u4e0b\u51e0\u5927\u6a21\u5757\u7ec4\u6210\uff1a</p>\n<ol>\n<li>\n<p>Dataset\uff1a\u5904\u7406\u6587\u672c\u548c\u6807\u7b7e\u6570\u636e\u4e3a\u9002\u5408\u6a21\u578b\u8f93\u5165\u7684\u683c\u5f0f\uff0c\u4e3b\u8981\u8fdb\u884c\u7684\u5904\u7406\u64cd\u4f5c\u6709\u6e05\u7406\u3001\u5206\u8bcd\u3001index\u5316</p>\n</li>\n<li>\n<p>Model Zoo &amp; Layer\uff1a\u8fd1\u51e0\u5e74\u5728\u8be5\u4efb\u52a1\u4e2d\u5e38\u7528\u7684\u6a21\u578b\u6c47\u603b\u53ca\u4e00\u4e9bKeras\u7684\u81ea\u5b9a\u4e49\u5c42</p>\n<p>\u76ee\u524d\u652f\u6301\u7684\u81ea\u5b9a\u4e49\u5c42\u6709\u5982\u4e0b\uff1a</p>\n<ul>\n<li>1D\u6ce8\u610f\u529b\u5c42 \ud83c\udd97</li>\n<li>2D\u6ce8\u610f\u529b\u5c42 \ud83c\udd97</li>\n<li>\u591a\u5934\u6ce8\u610f\u529b\u5c42 \ud83c\udd97</li>\n<li>\u4f4d\u7f6e\u5d4c\u5165\u5c42 \ud83c\udd97</li>\n<li>K-max\u6c60\u5316\u5c42</li>\n</ul>\n</li>\n<li>\n<p>Trainer\uff1a\u5b9a\u4e49\u6a21\u578b\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u652f\u6301bucket\u5e8f\u5217\u3001\u81ea\u5b9a\u4e49callbacks\u548cN\u6298\u4ea4\u53c9\u9a8c\u8bc1</p>\n<ul>\n<li>\n<p>bucket\u5e8f\u5217\uff1a\u901a\u8fc7\u5c06\u76f8\u4f3c\u957f\u5ea6\u7684\u6587\u672c\u653e\u5165\u540c\u4e00batch\u6765\u51cf\u5c0fpadding\u7684\u591a\u4f59\u8ba1\u7b97\u6765\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u7684\u52a0\u901f\uff0c\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u80fd\u591f\u5bf9RNN\u7f51\u7edc\u63d0\u901f2\u500d\u4ee5\u4e0a\uff08<strong>\u6682\u65f6\u4e0d\u652f\u6301\u542b\u6709Flatten\u5c42\u7684\u7f51\u7edc</strong>\uff09</p>\n</li>\n<li>\n<p>callbacks\uff1a\u901a\u8fc7\u81ea\u5b9a\u4e49\u56de\u8c03\u5668\u6765\u63a7\u5236\u8bad\u7ec3\u6d41\u7a0b\uff0c\u76ee\u524d\u9884\u8bbe\u7684\u56de\u8c03\u5668\u6709\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\uff0c\u5b66\u4e60\u7387\u81ea\u52a8\u53d8\u5316\uff0c\u66f4\u4e30\u5bcc\u7684\u8bc4\u4f30\u51fd\u6570\u7b49</p>\n</li>\n<li>\n<p>N\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff1a\u652f\u6301\u4ea4\u53c9\u9a8c\u8bc1\u6765\u8003\u9a8c\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b</p>\n</li>\n</ul>\n</li>\n<li>\n<p>Classifier &amp; Sequence Labeler\uff1a\u5c01\u88c5\u7c7b\uff0c\u652f\u6301\u4e0d\u540c\u7684\u8bad\u7ec3\u4efb\u52a1</p>\n</li>\n<li>\n<p>Application\uff1a\u76ee\u524d\u5de5\u5177\u7bb1\u5185\u5c01\u88c5\u4e86\u57fa\u4e8ejieba\u7684\u540d\u8bcd\u77ed\u8bed\u5206\u8bcd\u5668 Chunk_Segmentor (\u5982\u9700\u6a21\u578b\u6587\u4ef6\uff0c\u53ef\u4ee5\u90ae\u4ef6\u8054\u7cfb\u6211)</p>\n</li>\n</ol>\n<p>\u7b80\u5355\u7684\u7528\u6cd5\u5982\u4e0b\uff1a</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit</span> <span class=\"kn\">import</span> <span class=\"n\">Dataset</span><span class=\"p\">,</span> <span class=\"n\">Classifier</span><span class=\"p\">,</span> <span class=\"n\">Labeler</span>\n<span class=\"kn\">import</span> <span class=\"nn\">yaml</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'your_config.yaml'</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># \u5206\u7c7b\u4efb\u52a1</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"p\">(</span><span class=\"n\">fname</span><span class=\"o\">=</span><span class=\"s1\">'your_data.txt'</span><span class=\"p\">,</span> <span class=\"n\">task_type</span><span class=\"o\">=</span><span class=\"s1\">'classification'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'train'</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">text_classifier</span> <span class=\"o\">=</span> <span class=\"n\">Classifier</span><span class=\"p\">(</span><span class=\"s1\">'multi_head_self_att'</span><span class=\"p\">,</span> <span class=\"n\">dataset</span><span class=\"p\">)</span>\n<span class=\"n\">trained_model</span> <span class=\"o\">=</span> <span class=\"n\">text_classifier</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># \u5e8f\u5217\u6807\u6ce8\u4efb\u52a1</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"p\">(</span><span class=\"n\">fname</span><span class=\"o\">=</span><span class=\"s1\">'your_data.txt'</span><span class=\"p\">,</span> <span class=\"n\">task_type</span><span class=\"o\">=</span><span class=\"s1\">'sequence_labeling'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'train'</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">seq_labeler</span> <span class=\"o\">=</span> <span class=\"n\">Labeler</span><span class=\"p\">(</span><span class=\"s1\">'word_rnn'</span><span class=\"p\">,</span> <span class=\"n\">dataset</span><span class=\"p\">)</span>\n<span class=\"n\">trained_model</span> <span class=\"o\">=</span> <span class=\"n\">seq_labeler</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># \u9884\u6d4b\uff08\u4ee5\u6587\u672c\u5206\u7c7b\u4e3a\u4f8b\uff09</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"p\">(</span><span class=\"n\">fname</span><span class=\"o\">=</span><span class=\"s1\">'your_data.txt'</span><span class=\"p\">,</span> <span class=\"n\">task_type</span><span class=\"o\">=</span><span class=\"s1\">'classification'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'predict'</span><span class=\"p\">,</span> <span class=\"n\">tran_fname</span><span class=\"o\">=</span><span class=\"s1\">'your_transformer.h5'</span><span class=\"p\">)</span>\n<span class=\"n\">text_classifier</span> <span class=\"o\">=</span> <span class=\"n\">Classifier</span><span class=\"p\">(</span><span class=\"s1\">'bi_lstm_att'</span><span class=\"p\">,</span> <span class=\"n\">dataset</span><span class=\"p\">)</span>\n<span class=\"n\">text_classifier</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">weight_fname</span><span class=\"o\">=</span><span class=\"s1\">'your_model_weights.h5'</span><span class=\"p\">,</span> <span class=\"n\">para_fname</span><span class=\"o\">=</span><span class=\"s1\">'your_model_parameters.json'</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">text_classifier</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">texts</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># chunk\u5206\u8bcd</span>\n<span class=\"c1\"># \u7b2c\u4e00\u6b21import\u7684\u65f6\u5019\uff0c\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u6a21\u578b\u548c\u5b57\u5178\u6570\u636e</span>\n<span class=\"c1\"># \u652f\u6301\u5355\u53e5\u548c\u591a\u53e5\u6587\u672c\u7684\u8f93\u5165\u683c\u5f0f\uff0c\u5efa\u8bae\u4ee5\u5217\u8868\u7684\u5f62\u5f0f\u4f20\u5165\u5206\u8bcd\u5668</span>\n<span class=\"c1\"># \u6e90\u4ee3\u7801\u4e2d\u5df2\u7565\u53bb\u76f8\u5173\u6570\u636e\u7684\u4e0b\u8f7d\u8def\u5f84\uff0c\u6709\u9700\u8981\u7684\u8bf7\u90ae\u4ef6\u8054\u7cfb</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit.chunk_segmentor</span> <span class=\"kn\">import</span> <span class=\"n\">Chunk_Segmentor</span>\n<span class=\"n\">cutter</span> <span class=\"o\">=</span> <span class=\"n\">Chunk_Segmentor</span><span class=\"p\">()</span>\n<span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"s1\">'\u8fd9\u662f\u4e00\u4e2a\u80fd\u591f\u8f93\u51fa\u540d\u8bcd\u77ed\u8bed\u7684\u5206\u8bcd\u5668\uff0c\u6b22\u8fce\u8bd5\u7528\uff01'</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">item</span> <span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">cutter</span><span class=\"o\">.</span><span class=\"n\">cut</span><span class=\"p\">([</span><span class=\"n\">s</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"mi\">10000</span><span class=\"p\">)]</span> <span class=\"c1\"># 1080ti\u4e0a\u8017\u65f68s</span>\n<span class=\"c1\"># \u63d0\u4f9b\u4e24\u4e2a\u7248\u672c\uff0caccurate\u4e3a\u7cbe\u786e\u7248\uff0cfast\u4e3a\u5feb\u901f\u7248\u4f46\u53ec\u56de\u4f1a\u964d\u4f4e\u4e00\u4e9b\uff0c\u9ed8\u8ba4\u7cbe\u786e\u7248</span>\n<span class=\"n\">cutter</span> <span class=\"o\">=</span> <span class=\"n\">Chunk_Segmentor</span><span class=\"p\">(</span><span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'accurate'</span><span class=\"p\">)</span>\n<span class=\"n\">cutter</span> <span class=\"o\">=</span> <span class=\"n\">Chunk_Segmentor</span><span class=\"p\">(</span><span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'fast'</span><span class=\"p\">)</span>\n<span class=\"c1\"># \u662f\u5426\u8f93\u51fa\u8bcd\u6027\uff0c \u9ed8\u8ba4\u5f00\u542f</span>\n<span class=\"n\">cutter</span><span class=\"o\">.</span><span class=\"n\">cut</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">pos</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"c1\"># \u662f\u5426\u5c06\u53ef\u5207\u5206\u7684\u540d\u8bcd\u77ed\u8bed\u5207\u5206\uff0c\u9ed8\u8ba4\u5173\u95ed</span>\n<span class=\"n\">cutter</span><span class=\"o\">.</span><span class=\"n\">cut</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"n\">cut_all</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"c1\"># \u8f93\u51fa\u683c\u5f0f\uff08\u8bcd\u5217\u8868\uff0c\u8bcd\u6027\u5217\u8868\uff0c\u540d\u8bcd\u77ed\u8bed\u96c6\u5408\uff09</span>\n<span class=\"p\">[</span>\n    <span class=\"p\">(</span>\n        <span class=\"p\">[</span><span class=\"s1\">'\u8fd9'</span><span class=\"p\">,</span> <span class=\"s1\">'\u662f'</span><span class=\"p\">,</span> <span class=\"s1\">'\u4e00\u4e2a'</span><span class=\"p\">,</span> <span class=\"s1\">'\u80fd\u591f'</span><span class=\"p\">,</span> <span class=\"s1\">'\u8f93\u51fa'</span><span class=\"p\">,</span> <span class=\"s1\">'\u540d\u8bcd_\u77ed\u8bed'</span><span class=\"p\">,</span> <span class=\"s1\">'\u7684'</span><span class=\"p\">,</span> <span class=\"s1\">'\u5206\u8bcd\u5668'</span><span class=\"p\">,</span> <span class=\"s1\">','</span><span class=\"p\">,</span> <span class=\"s1\">'\u6b22\u8fce'</span><span class=\"p\">,</span> <span class=\"s1\">'\u8bd5\u7528'</span><span class=\"p\">,</span> <span class=\"s1\">'!'</span><span class=\"p\">],</span>\n        <span class=\"p\">[</span><span class=\"s1\">'r'</span><span class=\"p\">,</span> <span class=\"s1\">'v'</span><span class=\"p\">,</span> <span class=\"s1\">'mq'</span><span class=\"p\">,</span> <span class=\"s1\">'v'</span><span class=\"p\">,</span> <span class=\"s1\">'vn'</span><span class=\"p\">,</span> <span class=\"s1\">'np'</span><span class=\"p\">,</span> <span class=\"s1\">'ude1'</span><span class=\"p\">,</span> <span class=\"s1\">'np'</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">,</span> <span class=\"s1\">'v'</span><span class=\"p\">,</span> <span class=\"s1\">'v'</span><span class=\"p\">,</span> <span class=\"s1\">'w'</span><span class=\"p\">],</span>\n        <span class=\"p\">[</span><span class=\"s1\">'\u5206\u8bcd\u5668'</span><span class=\"p\">,</span> <span class=\"s1\">'\u540d\u8bcd_\u77ed\u8bed'</span><span class=\"p\">]</span>\n    <span class=\"p\">)</span>\n    <span class=\"o\">...</span>\n<span class=\"p\">]</span>\n</pre>\n<p>\u66f4\u591a\u4f7f\u7528\u7ec6\u8282\uff0c\u8bf7\u9605\u8bfb<a href=\"https://github.com/stevewyl/nlp_toolkit/tree/master/examples\" rel=\"nofollow\"><strong>examples</strong></a>\u6587\u4ef6\u5939\u4e2d\u7684Jupyter Notebook\u548cchunk_segmentor\u9875\u9762\u7684<a href=\"https://github.com/stevewyl/nlp_toolkit/tree/master/nlp_toolkit/chunk_segmentor\" rel=\"nofollow\"><strong>README</strong></a></p>\n<h3>\u6570\u636e\u683c\u5f0f</h3>\n<ol>\n<li>\n<p>\u6587\u672c\u5206\u7c7b\uff1a\u6bcf\u4e00\u884c\u9884\u5148\u5206\u597d\u8bcd\u7684\u6587\u4ef6\uff0c\u6bcf\u4e00\u884c\u7684\u683c\u5f0f\u5982\u4e0b\uff1a</p>\n<p>__label__\u6807\u7b7e1 __label__\u6807\u7b7e2 ... \u8bcd \u8bcd ... \u8bcd\\n</p>\n<p>\u4f8b\u5982 \u201c__label__neg \u516c\u53f8 \u76ee\u524d \u5730\u7406 \u4f4d\u7f6e \u4e0d \u592a \u7406\u60f3 \uff0c \u79bb \u57ce\u5e02 \u4e2d\u5fc3 \u8f83 \u8fdc\u70b9 \u3002\u201d</p>\n</li>\n<li>\n<p>\u5e8f\u5217\u6807\u6ce8\uff1a\u6bcf\u4e00\u884c\u9884\u5148\u5206\u597d\u8bcd\u7684\u6587\u4ef6\uff0c\u652f\u6301\u4e24\u79cd\u6570\u636e\u683c\u5f0f\uff0c\u6bcf\u4e00\u884c\u7684\u683c\u5f0f\u5982\u4e0b\uff1a</p>\n<p>\u8bcd###\u6807\u7b7e [TAB] \u8bcd###\u6807\u7b7e [TAB] ... \\n</p>\n<p>\u4f8b\u5982 \u201c\u76ee\u524d###O\\t\u516c\u53f8###O\\t\u5730\u7406###B-Chunk\\t\u4f4d\u7f6e###E-Chunk\\t\u4e0d###O\\t\u592a###O\\t\u7406\u60f3\\n\u201d</p>\n<p>\u6216\u8005 CONLL\u7684\u6807\u51c6\u683c\u5f0f</p>\n<p>\u8bcd [TAB] \u6807\u7b7e</p>\n<p>\u8bcd [TAB] \u6807\u7b7e</p>\n<p>...</p>\n<p>\u8bcd [TAB] \u6807\u7b7e</p>\n<p>\u8bcd [TAB] \u6807\u7b7e</p>\n<p>...</p>\n<p>\u4f8b\u5982\uff1a</p>\n<p>\u76ee\u524d\\tO</p>\n<p>\u516c\u53f8\\tO</p>\n<p>...</p>\n<p>\u5730\u7406\\tB-Chunk</p>\n<p>\u4f4d\u7f6e\\tE-Chunk</p>\n<p>\u4e0d\\tO</p>\n<p>\u592a\\tO</p>\n<p>\u7406\u60f3\\tO</p>\n<p>\u6807\u7b7e\u542b\u4e49\uff08\u8fd9\u91cc\u4ee5chunk\u4e3a\u4f8b\uff09\uff1a</p>\n<ul>\n<li>O\uff1a\u666e\u901a\u8bcd</li>\n<li>B-Chunk\uff1a\u8868\u793achunk\u8bcd\u7684\u5f00\u59cb</li>\n<li>I-Chunk\uff1a\u8868\u793achunk\u8bcd\u7684\u4e2d\u95f4</li>\n<li>E-Chunk\uff1a\u8868\u793achunk\u8bcd\u7684\u7ed3\u675f</li>\n</ul>\n<p>\u5efa\u8bae\uff1a\u6587\u672c\u5e8f\u5217\u4ee5\u77ed\u53e5\u4e3a\u4e3b\uff0c\u9488\u5bf9\u6807\u6ce8\u5b9e\u4f53\u7684\u4efb\u52a1\uff0c\u6700\u597d\u4fdd\u8bc1\u6bcf\u884c\u6570\u636e\u4e2d\u6709\u5b9e\u4f53\u8bcd\uff08\u5373\u975e\u5168O\u7684\u5e8f\u5217\uff09</p>\n<p>\u4f60\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4e92\u76f8\u8f6c\u6362\u4e24\u79cd\u6570\u636e\u683c\u5f0f\uff1a</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit.utilities</span> <span class=\"kn\">import</span> <span class=\"n\">convert_seq_format</span>\n<span class=\"c1\"># here we convert dataset from conll format to basic format</span>\n<span class=\"n\">convert_seq_format</span><span class=\"p\">(</span><span class=\"n\">input_file</span><span class=\"p\">,</span> <span class=\"n\">output_file</span><span class=\"p\">,</span> <span class=\"s1\">'basic'</span><span class=\"p\">)</span>\n</pre>\n<p>ps: \u5177\u4f53\u53ef\u67e5\u770bdata\u6587\u4ef6\u5939\u4e2d\u5bf9\u5e94\u7684<a href=\"https://github.com/stevewyl/nlp_toolkit/tree/master/sample_data\" rel=\"nofollow\"><strong>\u793a\u4f8b\u6570\u636e</strong></a></p>\n</li>\n<li>\n<p>\u9884\u6d4b\uff1a\u4e0d\u540c\u4efb\u52a1\u6bcf\u4e00\u884c\u5747\u4e3a\u9884\u5148\u5206\u597d\u8bcd\u7684\u6587\u672c\u5e8f\u5217</p>\n</li>\n<li>\n<p>\u652f\u6301\u7b80\u5355\u7684\u81ea\u5df1\u6dfb\u52a0\u6570\u636e\u7684\u65b9\u6cd5</p>\n<pre><span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">Dataset</span><span class=\"p\">(</span><span class=\"n\">task_type</span><span class=\"o\">=</span><span class=\"s1\">'classification'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'train'</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"c1\"># classification</span>\n<span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">({</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211 \u7231 \u673a\u5668 \u5b66\u4e60'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'pos'</span><span class=\"p\">})</span>\n<span class=\"c1\"># sequence labeling</span>\n<span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">({</span><span class=\"s1\">'text'</span><span class=\"p\">:</span> <span class=\"s1\">'\u6211 \u7231 \u673a\u5668 \u5b66\u4e60'</span><span class=\"p\">,</span> <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"s1\">'O O B-Chunk E-Chunk'</span><span class=\"p\">})</span>\n<span class=\"c1\"># after you add all your data</span>\n<span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">()</span>\n</pre>\n</li>\n</ol>\n<h3>\u914d\u7f6e\u6587\u4ef6</h3>\n<p>nlp_toolkit\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u6765\u521d\u59cb\u5316\u8bad\u7ec3\u4efb\u52a1</p>\n<p>train: \u8868\u793a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53c2\u6570\uff0c\u5305\u62ecbatch\u5927\u5c0f\uff0cepoch\u6570\u91cf\uff0c\u8bad\u7ec3\u6a21\u5f0f\u7b49</p>\n<p>data: \u8868\u793a\u6570\u636e\u9884\u5904\u7406\u7684\u53c2\u6570\uff0c\u5305\u62ec\u6700\u5927\u8bcd\u6570\u548c\u5b57\u7b26\u6570\uff0c\u662f\u5426\u4f7f\u7528\u8bcd\u5185\u90e8\u5b57\u7b26\u5e8f\u5217\u7b49</p>\n<p>embed: \u8bcd\u5411\u91cf\uff0cpre\u8868\u793a\u662f\u5426\u4f7f\u7528\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf</p>\n<p>\u5269\u4e0b\u7684\u6a21\u5757\u5bf9\u5e94\u4e0d\u540c\u7684\u6a21\u578b\u7684\u8d85\u53c2\u6570</p>\n<p>\u5177\u4f53\u7ec6\u8282\u53ef\u67e5\u770b\u4ed3\u5e93\u6839\u76ee\u5f55\u4e0b\u7684\u4e24\u4e2a<strong>\u914d\u7f6e\u6587\u4ef6</strong>\u6ce8\u91ca</p>\n<h3>\u53ef\u89c6\u5316</h3>\n<ol>\n<li>\n<p>attention\u6743\u91cd\u53ef\u89c6\u5316</p>\n<pre><span class=\"c1\"># only support model bi_lstm_att currently</span>\n<span class=\"c1\"># first you need to get attention_weights from model predictions</span>\n<span class=\"c1\"># you can find the actual usage in examples/sentiment.ipynb</span>\n<span class=\"n\">texts</span> <span class=\"o\">=</span> <span class=\"s1\">'\u6709 \u80fd\u529b \u7684 \u4eba \u5c31 \u6709 \u5f88\u591a \u673a\u4f1a'</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit</span> <span class=\"kn\">import</span> <span class=\"n\">visualization</span> <span class=\"k\">as</span> <span class=\"n\">vs</span>\n<span class=\"n\">vs</span><span class=\"o\">.</span><span class=\"n\">mk_html</span><span class=\"p\">(</span><span class=\"n\">texts</span><span class=\"p\">,</span> <span class=\"n\">attention_weights</span><span class=\"p\">)</span>\n</pre>\n<p><span>\u6709</span> <span>\u80fd\u529b</span> <span>\u7684</span> <span>\u4eba</span> <span>\u5c31</span> <span>\u6709</span> <span>\u5f88\u591a</span> <span>\u673a\u4f1a</span></p>\n</li>\n<li>\n<p>\u5b9e\u4f53\u9884\u6d4b\u7ed3\u679c\u53ef\u89c6\u5316</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit</span> <span class=\"kn\">import</span> <span class=\"n\">visualization</span> <span class=\"k\">as</span> <span class=\"n\">vs</span>\n<span class=\"n\">vs</span><span class=\"o\">.</span><span class=\"n\">entity_visualization</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">texts</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"n\">output_fname</span><span class=\"o\">=</span><span class=\"s1\">'result.html'</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li>\n<p>acc/loss \u66f2\u7ebf\u53ef\u89c6\u5316</p>\n<pre><span class=\"c1\"># after your have trained one model, you will also get a history object, which contains some loss and metrics info</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit</span> <span class=\"kn\">import</span> <span class=\"n\">visualization</span> <span class=\"k\">as</span> <span class=\"n\">vs</span>\n<span class=\"n\">vs</span><span class=\"o\">.</span><span class=\"n\">plot_loss_acc</span><span class=\"p\">(</span><span class=\"n\">history</span><span class=\"p\">,</span> <span class=\"n\">task</span><span class=\"o\">=</span><span class=\"s1\">'sequence_labeling'</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ol>\n<h3>\u5176\u4ed6</h3>\n<ol>\n<li>\n<p>\u751f\u6210\u8bcd\u5411\u91cf\u5c0f\u6587\u4ef6</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlp_toolkit.utilities</span> <span class=\"kn\">import</span> <span class=\"n\">gen_small_embedding</span>\n<span class=\"n\">gen_small_embedding</span><span class=\"p\">(</span><span class=\"n\">vocab_file</span><span class=\"p\">,</span> <span class=\"n\">embed_file</span><span class=\"p\">,</span> <span class=\"n\">output_file</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ol>\n<h2>\u6a21\u578b</h2>\n<h3>\u6587\u672c\u5206\u7c7b</h3>\n<ol>\n<li>\n<p>\u53cc\u5c42\u53cc\u5411LSTM + Attention \ud83c\udd97</p>\n<p><a href=\"https://arxiv.org/abs/1708.00524\" rel=\"nofollow\">DeepMoji</a>\u4e00\u6587\u4e2d\u6240\u91c7\u7528\u7684\u7684\u6a21\u578b\u6846\u67b6\uff0c\u672c\u4ed3\u5e93\u4e2d\u5bf9attention\u5c42\u4f5c\u4e86\u6269\u5c55</p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1abi_lstm_att</p>\n</li>\n<li>\n<p><a href=\"http://papers.nips.cc/paper/7181-attention-is-all-you-need\" rel=\"nofollow\">Transformer</a> \ud83c\udd97</p>\n<p>\u91c7\u7528Transformer\u4e2d\u7684\u591a\u5934\u81ea\u6ce8\u610f\u529b\u5c42\u6765\u8868\u5f81\u6587\u672c\u4fe1\u606f\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64<a href=\"https://kexue.fm/archives/4765\" rel=\"nofollow\">\u6587\u7ae0</a></p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1amulti_head_self_att</p>\n</li>\n<li>\n<p><a href=\"https://arxiv.org/abs/1408.5882\" rel=\"nofollow\">TextCNN</a> \ud83c\udd97</p>\n<p>CNN\u7f51\u7edc\u4e4b\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u5f00\u5c71\u4e4b\u4f5c\uff0c\u5728\u8fc7\u53bb\u51e0\u5e74\u4e2d\u7ecf\u5e38\u88ab\u7528\u4f5cbaseline\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64<a href=\"http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\" rel=\"nofollow\">\u6587\u7ae0</a></p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1atext_cnn</p>\n</li>\n<li>\n<p><a href=\"http://www.aclweb.org/anthology/P17-1052\" rel=\"nofollow\">DPCNN</a> \ud83c\udd97</p>\n<p>\u5728textCNN\u7684\u57fa\u7840\u4e0a\uff0cDPCNN\u4f7f\u7528\u6b8b\u5dee\u8fde\u63a5\u3001\u56fa\u5b9afeature map\u6570\u91cf\u548c1/2\u6c60\u5316\u5c42\u7b49\u6280\u5de7\u6765\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u6587\u672c\u8868\u793a\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64<a href=\"https://zhuanlan.zhihu.com/p/35457093\" rel=\"nofollow\">\u6587\u7ae0</a></p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1adpcnn\n\u6682\u65f6\u4e0d\u652f\u6301bucket\u5e8f\u5217\u5316\u7684\u6570\u636e</p>\n</li>\n<li>\n<p><a href=\"https://www.cs.cmu.edu/%7Ehovy/papers/16HLT-hierarchical-attention-networks.pdf\" rel=\"nofollow\">HAN</a></p>\n<p>\u4f7f\u7528attention\u673a\u5236\u7684\u6587\u6863\u5206\u7c7b\u6a21\u578b</p>\n</li>\n</ol>\n<h3>\u5e8f\u5217\u6807\u6ce8</h3>\n<ol>\n<li>\n<p><a href=\"https://arxiv.org/abs/1707.06799\" rel=\"nofollow\">WordRNN</a> \ud83c\udd97</p>\n<p>Baseline\u6a21\u578b\uff0c\u6587\u672c\u5e8f\u5217\u7ecf\u8fc7\u53cc\u5411LSTM\u540e\uff0c\u7531CRF\u5c42\u7f16\u7801\u4f5c\u4e3a\u8f93\u51fa</p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1aword_rnn</p>\n</li>\n<li>\n<p><a href=\"https://pdfs.semanticscholar.org/b944/5206f592423f0b2faf05f99de124ccc6aaa8.pdf\" rel=\"nofollow\">CharRNN</a> \ud83c\udd97</p>\n<p>\u57fa\u4e8e\u6c49\u8bed\u7684\u7279\u70b9\uff0c\u5728\u5b57\u7b26\u7ea7\u522b\u7684LSTM\u4fe1\u606f\u5916\uff0c\u52a0\u5165\u504f\u65c1\u90e8\u9996\uff0c\u5206\u8bcd\uff0cNgram\u4fe1\u606f</p>\n</li>\n<li>\n<p><a href=\"https://arxiv.org/abs/1611.04361\" rel=\"nofollow\">InnerChar</a> \ud83c\udd97</p>\n<p>\u57fa\u4e8e\u53e6\u5916\u4e00\u7bc7<a href=\"https://arxiv.org/abs/1511.08308\" rel=\"nofollow\">\u8bba\u6587</a>\uff0c\u6269\u5c55\u4e86\u672c\u6587\u7684\u6a21\u578b\uff0c\u4f7f\u7528bi-lstm\u6216CNN\u5728\u8bcd\u5185\u90e8\u7684char\u7ea7\u522b\u8fdb\u884c\u4fe1\u606f\u7684\u62bd\u53d6\uff0c\u7136\u540e\u4e0e\u539f\u6765\u7684\u8bcd\u5411\u91cf\u8fdb\u884cconcat\u6216attention\u8ba1\u7b97</p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1aword_rnn\uff0c\u5e76\u8bbe\u7f6e\u914d\u7f6e\u6587\u4ef6data\u6a21\u5757\u4e2d\u7684inner_char\u4e3aTrue</p>\n</li>\n<li>\n<p><a href=\"https://arxiv.org/abs/1702.02098\" rel=\"nofollow\">IDCNN</a> \ud83c\udd97</p>\n<p>\u81a8\u80c0\u5377\u79ef\u7f51\u7edc\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u91cf\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u589e\u5927\u4e86\u5377\u79ef\u6838\u7684\u611f\u53d7\u91ce\uff0c\u8be6\u7ec6\u7684\u7ec6\u8282\u53ef\u9605\u8bfb\u6b64<a href=\"http://www.crownpku.com//2017/08/26/%E7%94%A8IDCNN%E5%92%8CCRF%E5%81%9A%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E4%B8%AD%E6%96%87%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.html\" rel=\"nofollow\">\u6587\u7ae0</a></p>\n<p>\u5bf9\u5e94\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u540d\u79f0\uff1aidcnn</p>\n</li>\n</ol>\n<h2>\u6027\u80fd</h2>\n<p>\u540e\u7eed\u52a0\u5165\u5bf9\u4e2d\u6587NLP\u7684\u6807\u51c6\u6570\u636e\u96c6\u7684\u6d4b\u8bd5</p>\n<h3>\u6587\u672c\u5206\u7c7b</h3>\n<p>\u6d4b\u8bd5\u6570\u636e\u96c6\uff1a</p>\n<ol>\n<li>\n<p>\u516c\u53f8\u4f18\u7f3a\u70b9\u8bc4\u4ef7\uff0c\u4e8c\u5206\u7c7b\uff0c\u6570\u636e\u89c4\u6a21\uff1a95K</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">10-fold_f1</th>\n<th align=\"center\">Model Size</th>\n<th align=\"center\">Time per epoch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Bi-LSTM Attention</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>Transformer</td>\n<td align=\"center\"></td>\n<td align=\"center\">7M</td>\n<td align=\"center\">12s</td>\n</tr>\n<tr>\n<td>TextCNN</td>\n<td align=\"center\">96.57</td>\n<td align=\"center\">10M</td>\n<td align=\"center\">19s</td>\n</tr>\n<tr>\n<td>DPCNN</td>\n<td align=\"center\">93.35</td>\n<td align=\"center\">9M</td>\n<td align=\"center\">28s</td>\n</tr>\n<tr>\n<td>HAN</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr></tbody></table>\n</li>\n</ol>\n<h3>\u5e8f\u5217\u6807\u6ce8</h3>\n<p>\u6d4b\u8bd5\u6570\u636e\u96c6\uff1a</p>\n<ol>\n<li>\n<p>\u7b80\u5386\u5de5\u4f5c\u7ecf\u5386\uff0cchunk\uff0c\u6570\u636e\u89c4\u6a21\uff1a58K</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">10-fold_f1</th>\n<th align=\"center\">Model Size</th>\n<th align=\"center\">Time per epoch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Baseline(WordRNN)</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>WordRNN + InnerChar</td>\n<td align=\"center\"></td>\n<td align=\"center\">3M</td>\n<td align=\"center\">165s</td>\n</tr>\n<tr>\n<td>CharRNN(seg+radical)</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>IDCNN</td>\n<td align=\"center\"></td>\n<td align=\"center\">2.7M</td>\n<td align=\"center\">43s</td>\n</tr></tbody></table>\n</li>\n</ol>\n<p>ps: \u6a21\u578b\u5927\u5c0f\u8868\u793a\u4e3a\u6a21\u578b\u7684\u53c2\u6570\u91cf\uff0c\u5176\u4e2dK\u8868\u793a\u5343\uff0cM\u8868\u793a\u767e\u4e07\uff1b\u6d4b\u8bd5\u8bbe\u5907\u4e3a1080ti+i7-6800K</p>\n<h2>To-Do\u5217\u8868</h2>\n<ol>\n<li>\n<p>\u52a0\u5165\u66f4\u591aSOTA\u7684\u6a21\u578b\u548c\u81ea\u5b9a\u4e49\u5c42</p>\n</li>\n<li>\n<p>\u4e0b\u4e00\u7248\u672c\u89c4\u5212\uff1a\u589e\u52a0\u62bd\u8c61\u7c7bSentence</p>\n</li>\n<li>\n<p>V2.0\u89c4\u5212\uff1a\u5207\u6362\u4e3atf.estimator\u548ctf.keras\u7684API</p>\n</li>\n</ol>\n<h2>\u611f\u8c22</h2>\n<ul>\n<li>\n<p>\u6570\u636e\u6d41\u6a21\u5757\u90e8\u5206\u4ee3\u7801\u501f\u9274\u4e8e\u6b64\uff1a <a href=\"https://github.com/Hironsan/anago/\" rel=\"nofollow\">https://github.com/Hironsan/anago/</a></p>\n</li>\n<li>\n<p>\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u7684\u8bc4\u4f30\u51fd\u6570\u6765\u6e90\u4e8e\u6b64\uff1a <a href=\"https://github.com/chakki-works/seqeval\" rel=\"nofollow\">https://github.com/chakki-works/seqeval</a></p>\n</li>\n<li>\n<p>bucket\u5e8f\u5217\u5316\u4ee3\u7801\u6765\u81ea\uff1a<a href=\"https://github.com/tbennun/keras-bucketed-sequence\" rel=\"nofollow\">https://github.com/tbennun/keras-bucketed-sequence</a></p>\n</li>\n<li>\n<p>\u591a\u5934\u6ce8\u610f\u529b\u5c42\u548c\u4f4d\u7f6e\u5d4c\u5165\u5c42\u4ee3\u7801\u6765\u81ea\uff1a<a href=\"https://github.com/bojone/attention\" rel=\"nofollow\">https://github.com/bojone/attention</a></p>\n</li>\n</ul>\n<h2>\u8054\u7cfb\u65b9\u5f0f</h2>\n<p>\u8054\u7cfb\u4eba\uff1a\u738b\u5955\u78ca</p>\n<p>\ud83d\udce7 \u90ae\u7bb1\uff1a<a href=\"mailto:stevewyl@163.com\">stevewyl@163.com</a></p>\n<p>\u5fae\u4fe1\uff1aSteve_1125</p>\n\n          </div>"}, "last_serial": 5353464, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "12e5044da8d5c34939ee04b5889c2828", "sha256": "257a35ff5c20549095931c9aedf3720d6b68c14a9b13cdc52ef865a5a5482f94"}, "downloads": -1, "filename": "nlp_toolkit-1.0.tar.gz", "has_sig": false, "md5_digest": "12e5044da8d5c34939ee04b5889c2828", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 81085, "upload_time": "2018-11-22T09:41:11", "upload_time_iso_8601": "2018-11-22T09:41:11.752678Z", "url": "https://files.pythonhosted.org/packages/49/9e/203b33564730d4e05608867910c48b2f55edfe6b19148d8e08ceb106ed29/nlp_toolkit-1.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "31b3a9970b5a319cd9b7bf632d741d0d", "sha256": "b29c3d8d217ce4b6099c7526aacbe937f4bb3a0dde7a0542160b52ebf5194d81"}, "downloads": -1, "filename": "nlp_toolkit-1.0.1.tar.gz", "has_sig": false, "md5_digest": "31b3a9970b5a319cd9b7bf632d741d0d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 85926, "upload_time": "2018-11-22T10:08:44", "upload_time_iso_8601": "2018-11-22T10:08:44.310044Z", "url": "https://files.pythonhosted.org/packages/77/b7/cc0d65c210d601f91ccc386f3857f280ab066cd131f499eb990029d58c21/nlp_toolkit-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "7ba3ae4363f51b98cefbcbb33ed09ab3", "sha256": "db3fb7f6ae6818a428420f1ae96f8332b57d516fbca8198ee421a183b6b1f0a7"}, "downloads": -1, "filename": "nlp_toolkit-1.0.2.tar.gz", "has_sig": false, "md5_digest": "7ba3ae4363f51b98cefbcbb33ed09ab3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 86769, "upload_time": "2018-11-25T03:46:44", "upload_time_iso_8601": "2018-11-25T03:46:44.012787Z", "url": "https://files.pythonhosted.org/packages/aa/fd/cb4da238795781390afb7e9efe683dbad1d38a875ce87346a6c41f7ea739/nlp_toolkit-1.0.2.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "85d47dc8ca5d1612499e86b3f4ad84d9", "sha256": "d12c9b6c109bccb85eaebb96deac3d1c2c2eca8ca771e5a4319cd7eb4ac8e226"}, "downloads": -1, "filename": "nlp_toolkit-1.0.5.tar.gz", "has_sig": false, "md5_digest": "85d47dc8ca5d1612499e86b3f4ad84d9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 87402, "upload_time": "2018-11-30T07:47:38", "upload_time_iso_8601": "2018-11-30T07:47:38.588386Z", "url": "https://files.pythonhosted.org/packages/dc/b4/f6561837ff101256ed36c90c84df900b0da8003f8e392123361a744b9b12/nlp_toolkit-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "ce6d41b4db2127424317303024a78cd8", "sha256": "610721a2ad13ed2e403220396a7ca26cf45f09f3bc7abf4f8b20d3fee3923162"}, "downloads": -1, "filename": "nlp_toolkit-1.0.6.tar.gz", "has_sig": false, "md5_digest": "ce6d41b4db2127424317303024a78cd8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 87424, "upload_time": "2018-11-30T07:56:16", "upload_time_iso_8601": "2018-11-30T07:56:16.496921Z", "url": "https://files.pythonhosted.org/packages/f0/45/2d2d548f5dadebfead51f909ca29fec29ba279f2e93d487ca6cbc8d92daf/nlp_toolkit-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "c0a93a145f3ef13a8428bf44bdaeb14e", "sha256": "ee28b8bbd74370d09f47c25d32131b032b41ee2597a9ce63a4496458839231f0"}, "downloads": -1, "filename": "nlp_toolkit-1.0.7.tar.gz", "has_sig": false, "md5_digest": "c0a93a145f3ef13a8428bf44bdaeb14e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 87412, "upload_time": "2018-12-05T09:29:37", "upload_time_iso_8601": "2018-12-05T09:29:37.094042Z", "url": "https://files.pythonhosted.org/packages/50/12/577b94eb88c664eb5b491ba4cf20c2ba14281b09c13d9f9c352187ad58ba/nlp_toolkit-1.0.7.tar.gz", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "008bb8b556d385606e50ab25eb460a06", "sha256": "f2e24355c45c28f656d0fbefb142a0f6898c00a7536572ac7ae538f3a968e4ed"}, "downloads": -1, "filename": "nlp_toolkit-1.0.8.tar.gz", "has_sig": false, "md5_digest": "008bb8b556d385606e50ab25eb460a06", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 87466, "upload_time": "2018-12-05T12:26:10", "upload_time_iso_8601": "2018-12-05T12:26:10.442631Z", "url": "https://files.pythonhosted.org/packages/8f/4f/b3238ba120cd97b642989a3f08fec4a325eb9adb10dfd47b3466208c4ae9/nlp_toolkit-1.0.8.tar.gz", "yanked": false}], "1.0.9": [{"comment_text": "", "digests": {"md5": "7fcb5bf0bbcc173554a7ab47d03af089", "sha256": "f54861b08cd90497af73539dcdcfcc91bb5965ffce6a7e8ca31b61b43bdca91f"}, "downloads": -1, "filename": "nlp_toolkit-1.0.9.tar.gz", "has_sig": false, "md5_digest": "7fcb5bf0bbcc173554a7ab47d03af089", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 87684, "upload_time": "2018-12-06T06:34:01", "upload_time_iso_8601": "2018-12-06T06:34:01.107887Z", "url": "https://files.pythonhosted.org/packages/82/e1/f92a2261ef5186c5e4b974f341501eb65d860f2244e885ebfbb815759900/nlp_toolkit-1.0.9.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "03bda3431bd2609bf2e235d707da36cd", "sha256": "0e3fca723ef42bc56055f91b757cf6753368bdc71ea43e1f0af3cf6b3dd2beef"}, "downloads": -1, "filename": "nlp_toolkit-1.1.0.tar.gz", "has_sig": false, "md5_digest": "03bda3431bd2609bf2e235d707da36cd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 87933, "upload_time": "2018-12-07T07:36:17", "upload_time_iso_8601": "2018-12-07T07:36:17.285497Z", "url": "https://files.pythonhosted.org/packages/a0/bd/e853a9ae69f6e309289143340093437a4104b33309c7a021cee0e534938a/nlp_toolkit-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "b85880a4ab903ec80000a06cb2a2c91f", "sha256": "5b124cc56c8a45dde67f09b6ed24a308a548ce333e5b68b55dadb1d19232f843"}, "downloads": -1, "filename": "nlp_toolkit-1.1.1.tar.gz", "has_sig": false, "md5_digest": "b85880a4ab903ec80000a06cb2a2c91f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 88268, "upload_time": "2018-12-07T08:53:47", "upload_time_iso_8601": "2018-12-07T08:53:47.129973Z", "url": "https://files.pythonhosted.org/packages/19/da/a2b5f350d1ecd08f6ea405737f75c16230cf57fdc044919d578925b880de/nlp_toolkit-1.1.1.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "3aa0635b6a0aaf48bc6bc30643069242", "sha256": "56aa1f7208e193218ce6677c25d45be16ff3c4ba43946c4a8a8f52f6ac0a8b7c"}, "downloads": -1, "filename": "nlp_toolkit-1.2.0.tar.gz", "has_sig": false, "md5_digest": "3aa0635b6a0aaf48bc6bc30643069242", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 88469, "upload_time": "2018-12-14T02:02:27", "upload_time_iso_8601": "2018-12-14T02:02:27.763248Z", "url": "https://files.pythonhosted.org/packages/29/81/b1221f652f3c40f33571c6610ebba1b9f9b600cb4b73492ae1ceb3359c12/nlp_toolkit-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "7d4d7066ad7c9e62028fd9a8584c6f69", "sha256": "97c09d9fc874648a73c830766b321a2143e4b23326b4724f6b6f787e9db88093"}, "downloads": -1, "filename": "nlp_toolkit-1.2.1.tar.gz", "has_sig": false, "md5_digest": "7d4d7066ad7c9e62028fd9a8584c6f69", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 88484, "upload_time": "2018-12-14T02:40:40", "upload_time_iso_8601": "2018-12-14T02:40:40.437674Z", "url": "https://files.pythonhosted.org/packages/fa/c6/f6d252df4386cef21a9ec7a1e43e78ac46b57e15ba2988402a8401e03735/nlp_toolkit-1.2.1.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "68e41d0208ef58990cd1d210fa27f40b", "sha256": "9e789cd4f9e1d381f134bfbe72e38be49cb10399863710dfd3f1e321767926e5"}, "downloads": -1, "filename": "nlp_toolkit-1.2.2.tar.gz", "has_sig": false, "md5_digest": "68e41d0208ef58990cd1d210fa27f40b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 88475, "upload_time": "2018-12-14T02:47:21", "upload_time_iso_8601": "2018-12-14T02:47:21.859764Z", "url": "https://files.pythonhosted.org/packages/f0/97/cab8d2abad45e8904d151a120d918b71264fbe46ae229f9501211357ceab/nlp_toolkit-1.2.2.tar.gz", "yanked": false}], "1.2.3": [{"comment_text": "", "digests": {"md5": "7a63c9f9d72a24fd01b277d6922ab763", "sha256": "1deae43476819850269de80a55564a2cc38f56c9aebe7446158a75cad2111d52"}, "downloads": -1, "filename": "nlp_toolkit-1.2.3.tar.gz", "has_sig": false, "md5_digest": "7a63c9f9d72a24fd01b277d6922ab763", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 92277, "upload_time": "2018-12-14T03:26:38", "upload_time_iso_8601": "2018-12-14T03:26:38.948046Z", "url": "https://files.pythonhosted.org/packages/d7/88/c60a6811e2d7a34a9f55b1c47b2467f241bb37a74a006e10afd32de128b9/nlp_toolkit-1.2.3.tar.gz", "yanked": false}], "1.2.4": [{"comment_text": "", "digests": {"md5": "48d7de62cbef8e0ac88abefb16048688", "sha256": "fac055fc798fddbd95c4846569ddadf5807059e7976f542917cf06aaec102bb1"}, "downloads": -1, "filename": "nlp_toolkit-1.2.4.tar.gz", "has_sig": false, "md5_digest": "48d7de62cbef8e0ac88abefb16048688", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 92302, "upload_time": "2018-12-14T03:47:55", "upload_time_iso_8601": "2018-12-14T03:47:55.522752Z", "url": "https://files.pythonhosted.org/packages/38/25/212c72cc892dacccefb056f4eeb047972968f9332ff0d1d8f8db67f9517f/nlp_toolkit-1.2.4.tar.gz", "yanked": false}], "1.2.5": [{"comment_text": "", "digests": {"md5": "1b7857f4138e912f2df208aad10584be", "sha256": "aca506d1ca34919650b141aff04ed36085a504ca9dd35ca7fbaa4887eb430f1b"}, "downloads": -1, "filename": "nlp_toolkit-1.2.5.tar.gz", "has_sig": false, "md5_digest": "1b7857f4138e912f2df208aad10584be", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90554, "upload_time": "2018-12-14T07:15:26", "upload_time_iso_8601": "2018-12-14T07:15:26.398762Z", "url": "https://files.pythonhosted.org/packages/cb/4f/87068e1fbab6f4baa3eb45128c15c1c849ec016a07fc421670ad5586b14d/nlp_toolkit-1.2.5.tar.gz", "yanked": false}], "1.2.6": [{"comment_text": "", "digests": {"md5": "7ce4c1a2802ed00d847a86184dcd5f33", "sha256": "f24ab09c0eabe1e0f2bee9d57b865ba940ffe13e3d5d27c7bde688d8c631f373"}, "downloads": -1, "filename": "nlp_toolkit-1.2.6.tar.gz", "has_sig": false, "md5_digest": "7ce4c1a2802ed00d847a86184dcd5f33", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 92432, "upload_time": "2018-12-14T07:25:06", "upload_time_iso_8601": "2018-12-14T07:25:06.248543Z", "url": "https://files.pythonhosted.org/packages/68/b4/f8770e5147d6006daabd2e0f7ee18838402996d40176adbd6af94798e75f/nlp_toolkit-1.2.6.tar.gz", "yanked": false}], "1.2.7": [{"comment_text": "", "digests": {"md5": "c7883aca6e66b5eacd0b61d3e454ed4f", "sha256": "9dc32a8d08f77260107d0886669179279c67448852c8784ea3cf654ee0b98adc"}, "downloads": -1, "filename": "nlp_toolkit-1.2.7.tar.gz", "has_sig": false, "md5_digest": "c7883aca6e66b5eacd0b61d3e454ed4f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89650, "upload_time": "2018-12-14T08:40:30", "upload_time_iso_8601": "2018-12-14T08:40:30.556959Z", "url": "https://files.pythonhosted.org/packages/13/14/a8d70c83ddd8402b760d3b92443e0dbb9460c445270e6c4a00d3bd9219f2/nlp_toolkit-1.2.7.tar.gz", "yanked": false}], "1.2.8": [{"comment_text": "", "digests": {"md5": "7402a21e747a5ecdee999deec616431a", "sha256": "48afb52729998651b4a8a194c8d6170bb431d199617511f00ac01cf5189036a3"}, "downloads": -1, "filename": "nlp_toolkit-1.2.8.tar.gz", "has_sig": false, "md5_digest": "7402a21e747a5ecdee999deec616431a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89625, "upload_time": "2018-12-14T08:43:58", "upload_time_iso_8601": "2018-12-14T08:43:58.741975Z", "url": "https://files.pythonhosted.org/packages/36/e6/3b1149b2b43ecea4034d5b382519666e94313743ba833a8b11e0212c36ef/nlp_toolkit-1.2.8.tar.gz", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "90d8cd404a405ac4a297a3bee6845c43", "sha256": "a434851451372bd8e670671646ad9ca2151b04340c828c7887caf94e6de95b45"}, "downloads": -1, "filename": "nlp_toolkit-1.3.0.tar.gz", "has_sig": false, "md5_digest": "90d8cd404a405ac4a297a3bee6845c43", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90417, "upload_time": "2018-12-19T03:09:11", "upload_time_iso_8601": "2018-12-19T03:09:11.259971Z", "url": "https://files.pythonhosted.org/packages/c3/a8/ac1dc7f7d3e5ceaa17793d05a8502aa425925c83fe8f63d74544901a394d/nlp_toolkit-1.3.0.tar.gz", "yanked": false}], "1.3.1": [{"comment_text": "", "digests": {"md5": "55b9fa748e63cffd9ba216ff7ed2f7ba", "sha256": "52d17af7660a111ab26cdacd65e709b05f4668efbceb778a597551e8bec810bd"}, "downloads": -1, "filename": "nlp_toolkit-1.3.1.tar.gz", "has_sig": false, "md5_digest": "55b9fa748e63cffd9ba216ff7ed2f7ba", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90402, "upload_time": "2018-12-25T11:05:40", "upload_time_iso_8601": "2018-12-25T11:05:40.986510Z", "url": "https://files.pythonhosted.org/packages/e1/de/9aaebea2a029f887170b735204c35d71d58298aafc5f9bfe72f04b02bbe5/nlp_toolkit-1.3.1.tar.gz", "yanked": false}], "1.3.2": [{"comment_text": "", "digests": {"md5": "7c1d029e91b907f3e0dd1782576a57c9", "sha256": "c8701a0ae48732440131364107bbfb9aab0777c019616ef34df9c9fc7b21fb9d"}, "downloads": -1, "filename": "nlp_toolkit-1.3.2.tar.gz", "has_sig": false, "md5_digest": "7c1d029e91b907f3e0dd1782576a57c9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90916, "upload_time": "2019-06-03T16:24:59", "upload_time_iso_8601": "2019-06-03T16:24:59.830334Z", "url": "https://files.pythonhosted.org/packages/47/10/8aef64ab94a0332b08e99450c2fa7af2712d6ff40dcc27744db0d3c69851/nlp_toolkit-1.3.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7c1d029e91b907f3e0dd1782576a57c9", "sha256": "c8701a0ae48732440131364107bbfb9aab0777c019616ef34df9c9fc7b21fb9d"}, "downloads": -1, "filename": "nlp_toolkit-1.3.2.tar.gz", "has_sig": false, "md5_digest": "7c1d029e91b907f3e0dd1782576a57c9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90916, "upload_time": "2019-06-03T16:24:59", "upload_time_iso_8601": "2019-06-03T16:24:59.830334Z", "url": "https://files.pythonhosted.org/packages/47/10/8aef64ab94a0332b08e99450c2fa7af2712d6ff40dcc27744db0d3c69851/nlp_toolkit-1.3.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:10 2020"}