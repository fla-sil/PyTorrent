{"info": {"author": "Romain Picard", "author_email": "romain.picard@softathome.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "==================\nDeepSpeech Server\n==================\n\n.. image:: https://travis-ci.org/MainRo/deepspeech-server.svg?branch=master\n    :target: https://travis-ci.org/MainRo/deepspeech-server\n\n.. image:: https://badge.fury.io/py/deepspeech-server.svg\n    :target: https://badge.fury.io/py/deepspeech-server\n\nKey Features\n============\n\nThis is an http server that can be used to test the Mozilla DeepSpeech project.\nYou need an environment with DeepSpeech and a model to run this server.\n\nInstallation\n=============\n\nYou first need to install deepspeech. Depending on your system you can use the\nCPU package:\n\n.. code-block:: console\n\n    pip3 install deepspeech\n\nOr the GPU package:\n\n.. code-block:: console\n\n    pip3 install deepspeech-gpu\n\nThen you can install the deepspeech server:\n\n.. code-block:: console\n\n    python3 setup.py install\n\nThe server is also available on pypi, so you can install it with pip:\n\n.. code-block:: console\n\n    pip3 install deepspeech-server\n\nNote that python 3.5 is the minimum version required to run the server.\n\nStarting the server\n====================\n\n.. code-block:: console\n\n    deepspeech-server --config config.json\n\nYou can use deepspeech without training a model yourself. Pre-trained\nmodels are provided by Mozilla in the release page of the project (See the\nassets section of the release note):\n\nhttps://github.com/mozilla/DeepSpeech/releases\n\nOnce your downloaded a pre-trained model, you can untar it and directly use the\nsample configuration file:\n\n.. code-block:: console\n\n    cp config.sample.json config.json\n    deepspeech-server --config config.json\n\nServer configuration\n=====================\n\nThe configuration is done with a json file, provided with the \"--config\" argument.\nIts structure is the following one:\n\n.. code-block:: json\n\n    {\n      \"deepspeech\": {\n        \"model\" :\"models/output_graph.pb\",\n        \"lm\": \"models/lm.binary\",\n        \"trie\": \"models/trie\",\n        \"features\": {\n          \"beam_width\": 500, \n          \"lm_alpha\": 0.75,\n          \"lm_beta\": 1.85\n        }\n      },\n      \"server\": {\n        \"http\": {\n          \"host\": \"0.0.0.0\",\n          \"port\": 8080,\n          \"request_max_size\": 1048576\n        }\n      },\n      \"log\": {\n        \"level\": [\n          { \"logger\": \"deepspeech_server\", \"level\": \"DEBUG\"}\n        ]\n      }\n    }\n\nThe configuration file contains several sections and sub-sections.\n\ndeepspeech section configuration\n--------------------------------\n\nSection \"deepspeech\" contains configuration of the deepspeech engine:\n\n**model** is the protobuf model that was generated by deepspeech\n\n**lm** is the language model.\n\n**trie** is the trie file.\n\n**features** contains the features settings that have been used to train the \nmodel. This field can be set to null to keep the default settings.\n\nSection \"server\" contains configuration of the access part, with on subsection per protocol:\n\nhttp section configuration\n--------------------------\n\n**request_max_size** (default value: 1048576, i.e. 1MiB) is the maximum payload\nsize allowed by the server. A received payload size above this threshold will\nreturn a \"413: Request Entity Too Large\" error.\n\n**host**  (default value: \"0.0.0.0\") is the listen address of the http server.\n\n**port** (default value: 8080) is the listening port of the http server.\n\nlog section configuration\n-------------------------\n\nThe log section can be used to set the log levels of the server. This section\ncontains a list of log entries. Each log entry contains the name of a **logger** \nand its **level**. Both follow the convention of the python logging module.\n\n\nUsing the server\n================\n\nInference on the model is done via http post requests. For example with the\nfollowing curl command:\n\n.. code-block:: console\n\n     curl -X POST --data-binary @testfile.wav http://localhost:8080/stt", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MainRo/deepspeech-server.git", "keywords": "", "license": "MPL-2.0", "maintainer": "", "maintainer_email": "", "name": "deepspeech-server", "package_url": "https://pypi.org/project/deepspeech-server/", "platform": "any", "project_url": "https://pypi.org/project/deepspeech-server/", "project_urls": {"Homepage": "https://github.com/MainRo/deepspeech-server.git"}, "release_url": "https://pypi.org/project/deepspeech-server/2.0.0/", "requires_dist": null, "requires_python": "", "summary": "server for mozilla deepspeech", "version": "2.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/MainRo/deepspeech-server\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/MainRo/deepspeech-server.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5d72b778c25a081f65839bf7eaccb2b64a7b8a3c/68747470733a2f2f7472617669732d63692e6f72672f4d61696e526f2f646565707370656563682d7365727665722e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://badge.fury.io/py/deepspeech-server\" rel=\"nofollow\"><img alt=\"https://badge.fury.io/py/deepspeech-server.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/19031c95ee19e89de9886db3ce3274a6960a9558/68747470733a2f2f62616467652e667572792e696f2f70792f646565707370656563682d7365727665722e737667\"></a>\n<div id=\"key-features\">\n<h2>Key Features</h2>\n<p>This is an http server that can be used to test the Mozilla DeepSpeech project.\nYou need an environment with DeepSpeech and a model to run this server.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>You first need to install deepspeech. Depending on your system you can use the\nCPU package:</p>\n<pre><span class=\"go\">pip3 install deepspeech</span>\n</pre>\n<p>Or the GPU package:</p>\n<pre><span class=\"go\">pip3 install deepspeech-gpu</span>\n</pre>\n<p>Then you can install the deepspeech server:</p>\n<pre><span class=\"go\">python3 setup.py install</span>\n</pre>\n<p>The server is also available on pypi, so you can install it with pip:</p>\n<pre><span class=\"go\">pip3 install deepspeech-server</span>\n</pre>\n<p>Note that python 3.5 is the minimum version required to run the server.</p>\n</div>\n<div id=\"starting-the-server\">\n<h2>Starting the server</h2>\n<pre><span class=\"go\">deepspeech-server --config config.json</span>\n</pre>\n<p>You can use deepspeech without training a model yourself. Pre-trained\nmodels are provided by Mozilla in the release page of the project (See the\nassets section of the release note):</p>\n<p><a href=\"https://github.com/mozilla/DeepSpeech/releases\" rel=\"nofollow\">https://github.com/mozilla/DeepSpeech/releases</a></p>\n<p>Once your downloaded a pre-trained model, you can untar it and directly use the\nsample configuration file:</p>\n<pre><span class=\"go\">cp config.sample.json config.json\ndeepspeech-server --config config.json</span>\n</pre>\n</div>\n<div id=\"server-configuration\">\n<h2>Server configuration</h2>\n<p>The configuration is done with a json file, provided with the \u201c\u2013config\u201d argument.\nIts structure is the following one:</p>\n<pre><span class=\"p\">{</span>\n  <span class=\"nt\">\"deepspeech\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"model\"</span> <span class=\"p\">:</span><span class=\"s2\">\"models/output_graph.pb\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"lm\"</span><span class=\"p\">:</span> <span class=\"s2\">\"models/lm.binary\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"trie\"</span><span class=\"p\">:</span> <span class=\"s2\">\"models/trie\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"features\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"nt\">\"beam_width\"</span><span class=\"p\">:</span> <span class=\"mi\">500</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"lm_alpha\"</span><span class=\"p\">:</span> <span class=\"mf\">0.75</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"lm_beta\"</span><span class=\"p\">:</span> <span class=\"mf\">1.85</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">},</span>\n  <span class=\"nt\">\"server\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"http\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"nt\">\"host\"</span><span class=\"p\">:</span> <span class=\"s2\">\"0.0.0.0\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"port\"</span><span class=\"p\">:</span> <span class=\"mi\">8080</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"request_max_size\"</span><span class=\"p\">:</span> <span class=\"mi\">1048576</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">},</span>\n  <span class=\"nt\">\"log\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"level\"</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n      <span class=\"p\">{</span> <span class=\"nt\">\"logger\"</span><span class=\"p\">:</span> <span class=\"s2\">\"deepspeech_server\"</span><span class=\"p\">,</span> <span class=\"nt\">\"level\"</span><span class=\"p\">:</span> <span class=\"s2\">\"DEBUG\"</span><span class=\"p\">}</span>\n    <span class=\"p\">]</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</pre>\n<p>The configuration file contains several sections and sub-sections.</p>\n<div id=\"deepspeech-section-configuration\">\n<h3>deepspeech section configuration</h3>\n<p>Section \u201cdeepspeech\u201d contains configuration of the deepspeech engine:</p>\n<p><strong>model</strong> is the protobuf model that was generated by deepspeech</p>\n<p><strong>lm</strong> is the language model.</p>\n<p><strong>trie</strong> is the trie file.</p>\n<p><strong>features</strong> contains the features settings that have been used to train the\nmodel. This field can be set to null to keep the default settings.</p>\n<p>Section \u201cserver\u201d contains configuration of the access part, with on subsection per protocol:</p>\n</div>\n<div id=\"http-section-configuration\">\n<h3>http section configuration</h3>\n<p><strong>request_max_size</strong> (default value: 1048576, i.e. 1MiB) is the maximum payload\nsize allowed by the server. A received payload size above this threshold will\nreturn a \u201c413: Request Entity Too Large\u201d error.</p>\n<p><strong>host</strong>  (default value: \u201c0.0.0.0\u201d) is the listen address of the http server.</p>\n<p><strong>port</strong> (default value: 8080) is the listening port of the http server.</p>\n</div>\n<div id=\"log-section-configuration\">\n<h3>log section configuration</h3>\n<p>The log section can be used to set the log levels of the server. This section\ncontains a list of log entries. Each log entry contains the name of a <strong>logger</strong>\nand its <strong>level</strong>. Both follow the convention of the python logging module.</p>\n</div>\n</div>\n<div id=\"using-the-server\">\n<h2>Using the server</h2>\n<p>Inference on the model is done via http post requests. For example with the\nfollowing curl command:</p>\n<pre><span class=\"go\">curl -X POST --data-binary @testfile.wav http://localhost:8080/stt</span>\n</pre>\n</div>\n\n          </div>"}, "last_serial": 6546150, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "ffb8632a2f804c2f484ce55149b4af09", "sha256": "cc827360d5dd9a339485b713bb9b775353e3443067e1ef98058026632946f353"}, "downloads": -1, "filename": "deepspeech-server-0.2.0.zip", "has_sig": false, "md5_digest": "ffb8632a2f804c2f484ce55149b4af09", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9020, "upload_time": "2017-12-05T13:46:13", "upload_time_iso_8601": "2017-12-05T13:46:13.627524Z", "url": "https://files.pythonhosted.org/packages/01/3a/51c56c68258d87a2a2e42cf3cfcf51f1d872bc0ffcf3035adf9049302523/deepspeech-server-0.2.0.zip", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "8d14a97643695a71ceddf228899aeb35", "sha256": "4f977f296c740fa6363687ba8356d4d56285048463ee69681cecb248d5dbc8b9"}, "downloads": -1, "filename": "deepspeech-server-0.2.1.zip", "has_sig": false, "md5_digest": "8d14a97643695a71ceddf228899aeb35", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9023, "upload_time": "2017-12-05T14:59:12", "upload_time_iso_8601": "2017-12-05T14:59:12.766595Z", "url": "https://files.pythonhosted.org/packages/6a/78/59180bcb8af90413fba70da4e2a426c410c8b287e7b4b1d5d65c055feb2c/deepspeech-server-0.2.1.zip", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "8b21e77aaee10c9c0a04096c835d7682", "sha256": "fbf4b539178c2aa7b75e5143dda22354854189d797c3bdbfbbdff86f270e82c1"}, "downloads": -1, "filename": "deepspeech-server-0.3.0.zip", "has_sig": false, "md5_digest": "8b21e77aaee10c9c0a04096c835d7682", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10755, "upload_time": "2017-12-07T16:15:55", "upload_time_iso_8601": "2017-12-07T16:15:55.576955Z", "url": "https://files.pythonhosted.org/packages/e8/39/59a40c5101b52799931d887e51b8a1d05b4c41a5f7cdf36d8c24ce36409f/deepspeech-server-0.3.0.zip", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "e4a2e15fb38b195ec500ac0cad7eaef5", "sha256": "1352a5c04a3b0f1533424a8d4aaed5aecb585a9467521a28e9fd242c49cf0527"}, "downloads": -1, "filename": "deepspeech-server-0.4.0.zip", "has_sig": false, "md5_digest": "e4a2e15fb38b195ec500ac0cad7eaef5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12022, "upload_time": "2017-12-22T15:37:00", "upload_time_iso_8601": "2017-12-22T15:37:00.610706Z", "url": "https://files.pythonhosted.org/packages/0d/02/39370ce1f6e03ab3ea63b572883b6405786936eb07c2ee6b4d136eb8a972/deepspeech-server-0.4.0.zip", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "0d429e9123d0d1c7a53ef477fa6fbd37", "sha256": "b488e9a5ae7031bed5f4ff3cd0d9b4b88de4106f8d860d48130655e430a510d5"}, "downloads": -1, "filename": "deepspeech-server-0.4.1.zip", "has_sig": false, "md5_digest": "0d429e9123d0d1c7a53ef477fa6fbd37", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12218, "upload_time": "2018-02-27T16:55:36", "upload_time_iso_8601": "2018-02-27T16:55:36.605142Z", "url": "https://files.pythonhosted.org/packages/7b/74/cc72b29b2fe5ba5c5885cc3d33f044f29b39bdfa909b402ba5b09638c776/deepspeech-server-0.4.1.zip", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "25e3a612f9cab9415fbf7fd606e0f301", "sha256": "6a18dfbb19236009c596a1f81bc81094e53f702efbd08a8da9e8f6c2a55c4b73"}, "downloads": -1, "filename": "deepspeech-server-0.5.0.tar.gz", "has_sig": false, "md5_digest": "25e3a612f9cab9415fbf7fd606e0f301", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5205, "upload_time": "2018-08-27T20:52:09", "upload_time_iso_8601": "2018-08-27T20:52:09.604585Z", "url": "https://files.pythonhosted.org/packages/74/c8/209142919f8a2bd1f3e059ff9229f81dbeaf715c915afc5d40d2e27417e8/deepspeech-server-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "26b9b6eec0201dd4cafa753a03f0e5a4", "sha256": "48c679890dc4084230e9c5f09473fbd633514e15c457364a90491c25e3c2b6b7"}, "downloads": -1, "filename": "deepspeech-server-0.6.0.tar.gz", "has_sig": false, "md5_digest": "26b9b6eec0201dd4cafa753a03f0e5a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5587, "upload_time": "2018-09-03T21:59:34", "upload_time_iso_8601": "2018-09-03T21:59:34.401810Z", "url": "https://files.pythonhosted.org/packages/98/55/86fa5455f8dae007219b70bc163620b3e4a8f67fd73d2cd2d235f8685f4e/deepspeech-server-0.6.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "703642046b18c65ee14389a3e4d0d8a3", "sha256": "38f3b20dc43e092c630a7724776a413e8a39eb6641a7ee26fb01116d93df229a"}, "downloads": -1, "filename": "deepspeech-server-1.0.0.tar.gz", "has_sig": false, "md5_digest": "703642046b18c65ee14389a3e4d0d8a3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5790, "upload_time": "2018-09-26T21:16:11", "upload_time_iso_8601": "2018-09-26T21:16:11.376055Z", "url": "https://files.pythonhosted.org/packages/38/07/86495777749cc1c0a3266b3499288edc79b6fc7aa1328029af42f8d2b83e/deepspeech-server-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "2f9f778b3334270b2903fafd2c492c95", "sha256": "a223f6edd96ab3d2e6aea5e7a2f733f86ba7c4c5720c44ab6d885fc229bd426b"}, "downloads": -1, "filename": "deepspeech-server-1.1.0.tar.gz", "has_sig": false, "md5_digest": "2f9f778b3334270b2903fafd2c492c95", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5857, "upload_time": "2019-06-24T20:56:23", "upload_time_iso_8601": "2019-06-24T20:56:23.385614Z", "url": "https://files.pythonhosted.org/packages/3d/62/ec0c2066939dc252e857a6550f18123d68f1a98e2381a513a4f68105c632/deepspeech-server-1.1.0.tar.gz", "yanked": false}], "2.0.0": [{"comment_text": "", "digests": {"md5": "da03391dacd26d8ec26ffd3f0e82cbc9", "sha256": "452495225de8e244a4edc1052349edca8db60735f88cd3872ccf3226c801deb6"}, "downloads": -1, "filename": "deepspeech-server-2.0.0.tar.gz", "has_sig": false, "md5_digest": "da03391dacd26d8ec26ffd3f0e82cbc9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5666, "upload_time": "2020-01-30T22:52:33", "upload_time_iso_8601": "2020-01-30T22:52:33.774682Z", "url": "https://files.pythonhosted.org/packages/77/fa/a7286f58214d696f708d1ba7ca2954b25b86f37fa221fe7e981869fde48b/deepspeech-server-2.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "da03391dacd26d8ec26ffd3f0e82cbc9", "sha256": "452495225de8e244a4edc1052349edca8db60735f88cd3872ccf3226c801deb6"}, "downloads": -1, "filename": "deepspeech-server-2.0.0.tar.gz", "has_sig": false, "md5_digest": "da03391dacd26d8ec26ffd3f0e82cbc9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5666, "upload_time": "2020-01-30T22:52:33", "upload_time_iso_8601": "2020-01-30T22:52:33.774682Z", "url": "https://files.pythonhosted.org/packages/77/fa/a7286f58214d696f708d1ba7ca2954b25b86f37fa221fe7e981869fde48b/deepspeech-server-2.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:19 2020"}