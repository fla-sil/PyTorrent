{"info": {"author": "Joseph Moon", "author_email": "joseph@opendataframe.com", "bugtrack_url": null, "classifiers": [], "description": "<p align=\"center\">\n  <a href=\"https://dato.dtfr.me\">\n    <img src=\"https://github.com/dataframehq/dato/blob/master/docs/_static/img/dato.png?raw=true\">\n  </a>\n</p>\n\n---\n\n<a href=\"https://dato.dtfr.me\">\n  <b>Read our documentation!</b>\n</a>\n\n`dato` is an open source library that provides a **rapid, declarative ecosystem for reproducible data science** within python. `dato` accomplishes this by \\(1\\) enabling piping with `>>` and \\(2\\) unifying common data science libraries under a common syntax.\n\n```text\ndf >> GroupBy('country') >> Sum >> Hist('revenue', col='age')\n```\n\nDato has four major components:\n\n* **`dato.base.Pipeable`** Decorator that enables piping with `>>`.\n* **`dato.process`** Sub-module with pipe-compatible `pandas` operations.\n* **`dato.plot`** Sub-module with pipe-compatible plotting operations, following a consistent `pandas`-inspired syntax with `seaborn`-esque extended functionality.\n* **`dato.ml`**_\\(in development\\)_  Simplifies and standardizes syntax across popular ML libraries.\n\n\n## Installation\n\n```text\npip install dato\n```\n\n\n## Basic usage: the `Pipeable` class\n\n`dato` is meant to be flexible, and therefore can accept \\(almost\\) anything as input. Creating custom functions compatible with the `dato` framework is therefore quite easy. The class `dato.base.Pipeable` can wrap or decorate any method to enable compatibility with the `>>` operator. For example:\n\n```text\nfrom dato import Pipeable\n\n@Pipeable\ndef Func(*args, **kwargs):\n    return func(*args, **kwargs)\n```\n\nOr even more concisely, any existing function `func` that you'd like to use with `dato` can be trivially implemented as follows:\n\n```text\nFunc = Pipeable(func)\n```\n\nThe entire piping framework is incredibly simple \\(it only takes up around 40 lines of code\\), and can be found in `dato.base.Pipeable`. If you write a custom function, please consider making a pull request. _Happy piping!_\n\n## Some illustrative examples\n\nWe used this framework to implement data science-specific methods to improve QOL when performing repetitive data-related tasks \\(and to illustrate the potential of `dato`\\). Our biggest pain points in this domain have been:\n\n* Remembering pandas syntax and defaults.\n* Styling matplotlib/pandas/seaborn visualizations.\n* Remembering scikit-learn model creation syntax, best practices, and evaluation metrics.\n\nWe have therefore focused on wrapping and consolidating these libraries. **We provide a few examples for each of these use cases below, but for full functionality, see the documentation.**\n\nFull integration is currently still being built out, so contributions are very welcome. To contribute, please see the Contribution section of the docs.\n\n### More readable pandas\n\nA common pattern in exploratory analyses is to aggregate one value with respect to another. In pandas, this is typically accomplished as follows:\n\n```text\ndf['date'] = pd.to_datetime(df.date)\ngb = df.groupby('date').sum()['sale_value'].plot()\n```\n\nWhile `pandas` has already done an incredible amount of heavy lifting to make this aggregation syntactically quite simple, it still takes some thought, trial, and error to correctly write the above few commands. The same command in `dato` can be rewritten as follows:\n\n```text\nfrom dato import *\ndf >> ToDatetime('date') >> GroupBy('date') >> Sum('sale_value') >> Plot()\n```\n\n### Auto-styled matplotlib\n\n`matplotlib` is a staple in data visualization, primarily for its flexibility and speed. However, generating a presentation-ready plot takes an extraordinarily long time with substantial cognitive load, owing to library-specific syntax and an immense styling dictionary \\(`mpl.rcParams`\\). Below is an example from `./examples/sample.ipynb` here to illustrate how cumbersome this can be.\n\n```text\nplt.figure(figsize=(8.5,5.2))\nplt.scatter(a.lat, a.lng, alpha=0.5, s=100)\nplt.scatter(b.lat, b.lng, alpha=0.1, s=100)\nplt.scatter(c.lat, c.lng, alpha=0.1, s=100)\nplt.grid('on', linestyle=':')\nplt.rcParams.update({'font.size': 15})\n```\n\nWhile this script isn't particularly long, each argument \\(`s` for `scatter`, the `'on'` arg for `grid`, the keys for `rcParams`\\), in our experience, warrants a stackoverflow crawl. Even with almost a decade of experience using matplotlib, it still takes about 5 minutes to write up that snippet.\n\nWe therefore implement some improved basic styling to reduce the overhead of using matplotlib \\(granted, style is incredibly subjective, and you may find our decisions horrendous\\). At the least, we hope that this will improve the readability of your code, and at best, reduce the need to use any matplotlib styling.\n\n```text\nfrom dato import Scatter\n(a.lat, a.lng) >> Scatter\n(b.lat, b.lng) >> Scatter(alpha=0.1)\n(c.lat, c.lng) >> Scatter(alpha=0.1)\n```\n\n### Cleaner sklearn\n\nWe also provide limited, but ever-growing ML tooling, wrapping sklearn and xgboost. We do not intend this to replace existing libraries, but to more quickly test the feasibility of a model.\n\nA disclaimer regarding ML: while, in general, `dato` does not modify outputs, because of the complex, branching nature of machine-learning workflows \\(creating and holding onto a validation set, for example\\), we created a hidden `_ModelSpec` method that holds model-related information \\(the train and test sets\\). A `_ModelSpec` class object \\(here represented as `m`\\) contains the following attributes:\n\n* `m.train`: the training data.\n* `m.test`: the test data.\n* `m.estimator`: the underlying scikit-learn estimator.\n\nA typical full-on ML effort (without any hyperparameter tuning) can be condensed as follows:\n\n```text\nimport numpy as np\nimport sklearn\ndf = pd.merge(users, purchases, on='id_user')\nle = sklearn.preprocessing.LabelEncoder()\ndf['city'] = le.fit_transform(df.city)\ndf = df[['population', 'density', 'sale_value', 'city']]\nX = df[['population', 'density', 'city']]\ny = df['sale_value']\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)\nreg = sklearn.linear_model.LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\ny_train_pred = reg.predict(X_train)\nprint('Mean squared error:', sklearn.metrics.mean_squared_error(y_train, y_train_pred))\nprint('Mean absolute error:', sklearn.metrics.mean_absolute_error(y_train, y_train_pred))\nprint('Root mean squared error:', np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_train_pred)))\nprint('Mean squared error:', sklearn.metrics.mean_squared_error(y_test, y_pred))\nprint('Mean absolute error:', sklearn.metrics.mean_absolute_error(y_test, y_pred))\nprint('Root mean squared error:', np.sqrt(sklearn.metrics.mean_squared_error(y_test, y_pred)))\n```\n\nBut it's still clearly quite cumbersome, even without the imports. With `dato` tooling, this entire process can be condensed as follows:\n\n```text\nfrom dato import *\nmodelspec = (users, purchases) \\\n    >> Merge(on='id_user') \\\n    >> Select('population', 'density', 'sale_value', 'city') \\\n    >> InitModel(label='sale_value') \\\n    >> LabelEnc(columns=['city']) \\\n    >> TrainTestSplit \\\n    >> LinearReg\n```\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dataframehq/dato", "keywords": "pipe,declarative,python,data science", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "dato", "package_url": "https://pypi.org/project/dato/", "platform": "", "project_url": "https://pypi.org/project/dato/", "project_urls": {"Homepage": "https://github.com/dataframehq/dato"}, "release_url": "https://pypi.org/project/dato/0.0.1a3/", "requires_dist": null, "requires_python": "", "summary": "Declarative syntactic sugar for data piping.", "version": "0.0.1a3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\">\n  <a href=\"https://dato.dtfr.me\" rel=\"nofollow\">\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cd53bddb97dba59dcceb6cd6e0996616609beb6c/68747470733a2f2f6769746875622e636f6d2f646174616672616d6568712f6461746f2f626c6f622f6d61737465722f646f63732f5f7374617469632f696d672f6461746f2e706e673f7261773d74727565\">\n  </a>\n</p>\n<hr>\n<a href=\"https://dato.dtfr.me\" rel=\"nofollow\">\n  <b>Read our documentation!</b>\n</a>\n<p><code>dato</code> is an open source library that provides a <strong>rapid, declarative ecosystem for reproducible data science</strong> within python. <code>dato</code> accomplishes this by (1) enabling piping with <code>&gt;&gt;</code> and (2) unifying common data science libraries under a common syntax.</p>\n<pre>df &gt;&gt; GroupBy('country') &gt;&gt; Sum &gt;&gt; Hist('revenue', col='age')\n</pre>\n<p>Dato has four major components:</p>\n<ul>\n<li><strong><code>dato.base.Pipeable</code></strong> Decorator that enables piping with <code>&gt;&gt;</code>.</li>\n<li><strong><code>dato.process</code></strong> Sub-module with pipe-compatible <code>pandas</code> operations.</li>\n<li><strong><code>dato.plot</code></strong> Sub-module with pipe-compatible plotting operations, following a consistent <code>pandas</code>-inspired syntax with <code>seaborn</code>-esque extended functionality.</li>\n<li><strong><code>dato.ml</code></strong><em>(in development)</em>  Simplifies and standardizes syntax across popular ML libraries.</li>\n</ul>\n<h2>Installation</h2>\n<pre>pip install dato\n</pre>\n<h2>Basic usage: the <code>Pipeable</code> class</h2>\n<p><code>dato</code> is meant to be flexible, and therefore can accept (almost) anything as input. Creating custom functions compatible with the <code>dato</code> framework is therefore quite easy. The class <code>dato.base.Pipeable</code> can wrap or decorate any method to enable compatibility with the <code>&gt;&gt;</code> operator. For example:</p>\n<pre>from dato import Pipeable\n\n@Pipeable\ndef Func(*args, **kwargs):\n    return func(*args, **kwargs)\n</pre>\n<p>Or even more concisely, any existing function <code>func</code> that you'd like to use with <code>dato</code> can be trivially implemented as follows:</p>\n<pre>Func = Pipeable(func)\n</pre>\n<p>The entire piping framework is incredibly simple (it only takes up around 40 lines of code), and can be found in <code>dato.base.Pipeable</code>. If you write a custom function, please consider making a pull request. <em>Happy piping!</em></p>\n<h2>Some illustrative examples</h2>\n<p>We used this framework to implement data science-specific methods to improve QOL when performing repetitive data-related tasks (and to illustrate the potential of <code>dato</code>). Our biggest pain points in this domain have been:</p>\n<ul>\n<li>Remembering pandas syntax and defaults.</li>\n<li>Styling matplotlib/pandas/seaborn visualizations.</li>\n<li>Remembering scikit-learn model creation syntax, best practices, and evaluation metrics.</li>\n</ul>\n<p>We have therefore focused on wrapping and consolidating these libraries. <strong>We provide a few examples for each of these use cases below, but for full functionality, see the documentation.</strong></p>\n<p>Full integration is currently still being built out, so contributions are very welcome. To contribute, please see the Contribution section of the docs.</p>\n<h3>More readable pandas</h3>\n<p>A common pattern in exploratory analyses is to aggregate one value with respect to another. In pandas, this is typically accomplished as follows:</p>\n<pre>df['date'] = pd.to_datetime(df.date)\ngb = df.groupby('date').sum()['sale_value'].plot()\n</pre>\n<p>While <code>pandas</code> has already done an incredible amount of heavy lifting to make this aggregation syntactically quite simple, it still takes some thought, trial, and error to correctly write the above few commands. The same command in <code>dato</code> can be rewritten as follows:</p>\n<pre>from dato import *\ndf &gt;&gt; ToDatetime('date') &gt;&gt; GroupBy('date') &gt;&gt; Sum('sale_value') &gt;&gt; Plot()\n</pre>\n<h3>Auto-styled matplotlib</h3>\n<p><code>matplotlib</code> is a staple in data visualization, primarily for its flexibility and speed. However, generating a presentation-ready plot takes an extraordinarily long time with substantial cognitive load, owing to library-specific syntax and an immense styling dictionary (<code>mpl.rcParams</code>). Below is an example from <code>./examples/sample.ipynb</code> here to illustrate how cumbersome this can be.</p>\n<pre>plt.figure(figsize=(8.5,5.2))\nplt.scatter(a.lat, a.lng, alpha=0.5, s=100)\nplt.scatter(b.lat, b.lng, alpha=0.1, s=100)\nplt.scatter(c.lat, c.lng, alpha=0.1, s=100)\nplt.grid('on', linestyle=':')\nplt.rcParams.update({'font.size': 15})\n</pre>\n<p>While this script isn't particularly long, each argument (<code>s</code> for <code>scatter</code>, the <code>'on'</code> arg for <code>grid</code>, the keys for <code>rcParams</code>), in our experience, warrants a stackoverflow crawl. Even with almost a decade of experience using matplotlib, it still takes about 5 minutes to write up that snippet.</p>\n<p>We therefore implement some improved basic styling to reduce the overhead of using matplotlib (granted, style is incredibly subjective, and you may find our decisions horrendous). At the least, we hope that this will improve the readability of your code, and at best, reduce the need to use any matplotlib styling.</p>\n<pre>from dato import Scatter\n(a.lat, a.lng) &gt;&gt; Scatter\n(b.lat, b.lng) &gt;&gt; Scatter(alpha=0.1)\n(c.lat, c.lng) &gt;&gt; Scatter(alpha=0.1)\n</pre>\n<h3>Cleaner sklearn</h3>\n<p>We also provide limited, but ever-growing ML tooling, wrapping sklearn and xgboost. We do not intend this to replace existing libraries, but to more quickly test the feasibility of a model.</p>\n<p>A disclaimer regarding ML: while, in general, <code>dato</code> does not modify outputs, because of the complex, branching nature of machine-learning workflows (creating and holding onto a validation set, for example), we created a hidden <code>_ModelSpec</code> method that holds model-related information (the train and test sets). A <code>_ModelSpec</code> class object (here represented as <code>m</code>) contains the following attributes:</p>\n<ul>\n<li><code>m.train</code>: the training data.</li>\n<li><code>m.test</code>: the test data.</li>\n<li><code>m.estimator</code>: the underlying scikit-learn estimator.</li>\n</ul>\n<p>A typical full-on ML effort (without any hyperparameter tuning) can be condensed as follows:</p>\n<pre>import numpy as np\nimport sklearn\ndf = pd.merge(users, purchases, on='id_user')\nle = sklearn.preprocessing.LabelEncoder()\ndf['city'] = le.fit_transform(df.city)\ndf = df[['population', 'density', 'sale_value', 'city']]\nX = df[['population', 'density', 'city']]\ny = df['sale_value']\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)\nreg = sklearn.linear_model.LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\ny_train_pred = reg.predict(X_train)\nprint('Mean squared error:', sklearn.metrics.mean_squared_error(y_train, y_train_pred))\nprint('Mean absolute error:', sklearn.metrics.mean_absolute_error(y_train, y_train_pred))\nprint('Root mean squared error:', np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_train_pred)))\nprint('Mean squared error:', sklearn.metrics.mean_squared_error(y_test, y_pred))\nprint('Mean absolute error:', sklearn.metrics.mean_absolute_error(y_test, y_pred))\nprint('Root mean squared error:', np.sqrt(sklearn.metrics.mean_squared_error(y_test, y_pred)))\n</pre>\n<p>But it's still clearly quite cumbersome, even without the imports. With <code>dato</code> tooling, this entire process can be condensed as follows:</p>\n<pre>from dato import *\nmodelspec = (users, purchases) \\\n    &gt;&gt; Merge(on='id_user') \\\n    &gt;&gt; Select('population', 'density', 'sale_value', 'city') \\\n    &gt;&gt; InitModel(label='sale_value') \\\n    &gt;&gt; LabelEnc(columns=['city']) \\\n    &gt;&gt; TrainTestSplit \\\n    &gt;&gt; LinearReg\n</pre>\n\n          </div>"}, "last_serial": 6464270, "releases": {"0.0.1a1": [{"comment_text": "", "digests": {"md5": "b7d7374bba3471384d901f95bd90baf7", "sha256": "74551fd0b6b48181e2bf43b7cd76d607d132166af3b9173e9fcd707d242ab0e6"}, "downloads": -1, "filename": "dato-0.0.1a1-py3-none-any.whl", "has_sig": false, "md5_digest": "b7d7374bba3471384d901f95bd90baf7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35542, "upload_time": "2020-01-13T07:20:11", "upload_time_iso_8601": "2020-01-13T07:20:11.165030Z", "url": "https://files.pythonhosted.org/packages/8f/71/0b02af92fee7ab40c288fba114bd7e6d17ae172f1c70b0d376a0c175152f/dato-0.0.1a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "392106dbdcf5237a06ee7df73bea616d", "sha256": "27cfd8b0bc379a2baac30ca69e7bf1d98d3fb9dda299982ffa914ce50c72c359"}, "downloads": -1, "filename": "dato-0.0.1a1.tar.gz", "has_sig": false, "md5_digest": "392106dbdcf5237a06ee7df73bea616d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18632, "upload_time": "2020-01-13T07:20:13", "upload_time_iso_8601": "2020-01-13T07:20:13.529021Z", "url": "https://files.pythonhosted.org/packages/d6/ab/a14a383bff5cc0fd8147f947965bd6b1367b2febfb1f61ba6bc38656e333/dato-0.0.1a1.tar.gz", "yanked": false}], "0.0.1a2": [{"comment_text": "", "digests": {"md5": "f7ed880067c1871fb751be47cc3d76b1", "sha256": "8a72f68c012ceef145895ea381ba6fd94d9d5880a365477c74e47bb5a082cd3c"}, "downloads": -1, "filename": "dato-0.0.1a2-py3-none-any.whl", "has_sig": false, "md5_digest": "f7ed880067c1871fb751be47cc3d76b1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35355, "upload_time": "2020-01-14T15:43:29", "upload_time_iso_8601": "2020-01-14T15:43:29.674308Z", "url": "https://files.pythonhosted.org/packages/09/44/74ee68a2f056ad2660f4541041eb2c45e2cc7eaebf9445b2425cd0d59369/dato-0.0.1a2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5c7eb612977441ee9b31569114a501c2", "sha256": "870ed5a08bd0d5532b8e93e69f19c90481b56051c04540b2f2e25b5863a32e33"}, "downloads": -1, "filename": "dato-0.0.1a2.tar.gz", "has_sig": false, "md5_digest": "5c7eb612977441ee9b31569114a501c2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18519, "upload_time": "2020-01-14T15:43:31", "upload_time_iso_8601": "2020-01-14T15:43:31.174548Z", "url": "https://files.pythonhosted.org/packages/a7/17/f3319af0fa466d126975d9c222b711f9b7e8af17c4d5f5775d65abfa8eea/dato-0.0.1a2.tar.gz", "yanked": false}], "0.0.1a3": [{"comment_text": "", "digests": {"md5": "7d8362063b8ec9b117407933c11ed382", "sha256": "0965ad937e9bf2df7351cae7cd9a32f4c7f7514659dcfd70d1b1694c7d6d8d77"}, "downloads": -1, "filename": "dato-0.0.1a3-py3-none-any.whl", "has_sig": false, "md5_digest": "7d8362063b8ec9b117407933c11ed382", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35752, "upload_time": "2020-01-16T07:25:47", "upload_time_iso_8601": "2020-01-16T07:25:47.415816Z", "url": "https://files.pythonhosted.org/packages/5b/b3/2f7cfac427b05797774ec2221e7a19c69ae64ce31dc8c22b1d98370293e3/dato-0.0.1a3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1dfd967e5b757638ab70b84169ddf131", "sha256": "8e31e23446dc4d39c850b8f076285d484a9e0d935557acbd5bc78ead128c4ea4"}, "downloads": -1, "filename": "dato-0.0.1a3.tar.gz", "has_sig": false, "md5_digest": "1dfd967e5b757638ab70b84169ddf131", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18964, "upload_time": "2020-01-16T07:25:49", "upload_time_iso_8601": "2020-01-16T07:25:49.512878Z", "url": "https://files.pythonhosted.org/packages/82/56/5e57b9eee7b329df96e70aa96174ad16d769c3bd4512960ac195b7765827/dato-0.0.1a3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7d8362063b8ec9b117407933c11ed382", "sha256": "0965ad937e9bf2df7351cae7cd9a32f4c7f7514659dcfd70d1b1694c7d6d8d77"}, "downloads": -1, "filename": "dato-0.0.1a3-py3-none-any.whl", "has_sig": false, "md5_digest": "7d8362063b8ec9b117407933c11ed382", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35752, "upload_time": "2020-01-16T07:25:47", "upload_time_iso_8601": "2020-01-16T07:25:47.415816Z", "url": "https://files.pythonhosted.org/packages/5b/b3/2f7cfac427b05797774ec2221e7a19c69ae64ce31dc8c22b1d98370293e3/dato-0.0.1a3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1dfd967e5b757638ab70b84169ddf131", "sha256": "8e31e23446dc4d39c850b8f076285d484a9e0d935557acbd5bc78ead128c4ea4"}, "downloads": -1, "filename": "dato-0.0.1a3.tar.gz", "has_sig": false, "md5_digest": "1dfd967e5b757638ab70b84169ddf131", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18964, "upload_time": "2020-01-16T07:25:49", "upload_time_iso_8601": "2020-01-16T07:25:49.512878Z", "url": "https://files.pythonhosted.org/packages/82/56/5e57b9eee7b329df96e70aa96174ad16d769c3bd4512960ac195b7765827/dato-0.0.1a3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:03 2020"}