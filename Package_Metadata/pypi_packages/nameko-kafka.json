{"info": {"author": "Ketan Goyal", "author_email": "ketangoyal1988@gmail.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Internet", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Nameko-Kafka\n\nKafka extension for [Nameko](https://www.nameko.io/) microservice framework. \n\n## Introduction\n\nThis is a Nameko microservice framework [extension](https://nameko.readthedocs.io/en/stable/key_concepts.html) to support Kafka entrypoint and dependency. The motivation behind \ncreating this project is this issue [569](https://github.com/nameko/nameko/issues/569). Thus _nameko-kafka_ tries to provide \na simple implementation extension based on the approach explained by [calumpeterwebb](https://medium.com/@calumpeterwebb/nameko-tutorial-creating-a-kafka-consuming-microservice-c4a7adb804d0).\nOn topo of that a dependency provider is also included for publishing Kafka messages from within Nameko services.\n\n## Installation\n\nThe package is supports Python >= 3.5\n```bash\n$ pip install nameko-kafka\n```\n\n## Usage\n\nThe extension can be used for both, service dependency and entrypoint. Example usage for both the cases are shown below:\n\n## Dependency\n\nThis is basically a [python-kafka](https://github.com/dpkp/kafka-python) producer in the form of Nameko dependency. \nNameko uses dependency injection to initiate the producer. You just need to declare it in your service class:\n\n```python\nfrom nameko.rpc import rpc\nfrom nameko_kafka import KafkaProducer\n\n\nclass MyService:\n    \"\"\"\n        My microservice\n    \"\"\"\n    name = \"my-service\"\n    # Kafak dependency\n    producer = KafkaProducer(bootstrap_servers='localhost:1234')\n    \n    @rpc\n    def method(self):\n        # Publish message using dependency\n        self.producer.send(\"kafka-topic\", value=b\"my-message\", key=b\"my-key\")\n```\n\nHere `KafkaProducer` accepts all options valid for `python-kafka`'s [KafkaProducer](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html).\n\n### Entrypoint\n\nYou can use the `nameko_kafka.consume` decorator in your services which process Kafka messages:\n\n```python\nfrom nameko_kafka import consume\n\n\nclass MyService:\n    \"\"\"\n        My microservice \n    \"\"\"\n    name = \"my-service\"\n\n    @consume(\"kafka-topic\", group_id=\"my-group\", bootstrap_servers='localhost:1234')\n    def method(self, message):\n        # Your message handler\n        handle_message(message) \n```\n\nThe `consume` decorator accepts all the options valid for `python-kafka`'s [KafkaProducer](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html).\n\n## Configurations\n\nThe dependency configurations can be set in nameko [config.yaml]((https://docs.nameko.io/en/stable/cli.html)) file, or \nby environment variables.\n\n### Config File\n\n```yaml\n# Config for entrypoint\nKAFKA_CONSUMER:\n  bootstrap_servers: 'localhost:1234'\n  retry_backoff_ms: 100\n  ...\n\n# Config for dependency\nKAFKA_PRODUCER:\n  bootstrap_servers: 'localhost:1234'\n  retries: 3\n  ...\n```\n\n### Environment Variables\n\n```.env\n# Config for entrypoint\nKAFKA_CONSUMER='{\"bootstrap_servers\": \"localhost:1234\", \"retry_backoff_ms\": 100}'\n\n# Config for dependency\nKAFKA_PRODUCER='{\"bootstrap_servers\": \"localhost:1234\", \"retries\": 3}'\n```\n\n## Milestones\n\n[x] Kafka Entrypoint\n[x] Kafka Dependency\n[ ] Advanced feature select commit strategies: _ALMOST_ONCE_DELIVERY_, _AT_LEAST_ONCE_DELIVERY_, _EXACTLY_ONCE_DELIVERY_\n[ ] Commit storage for _EXACT_ONCE_DELIVERY_ strategy\n\n## Developers\n\nFor development a kafka broker is required. You can spawn one using the [docker-compose.yml](https://github.com/ketgo/nameko-kafka/blob/master/tests/conftest.py) \nfile in the `tests` folder:\n```bash\n$ cd tests\n$ docker-compose up -d \n```\n\nTo install all package dependencies:\n```bash\n$ pip install -r .[dev]\nor\n$ make deps\n```\n\nOther useful commands:\n```bash\n$ pytest --cov=nameko_kafka tests/\t\t\t# to get coverage report\nor\n$ make coverage\n\n$ pylint nameko_kafka       # to check code quality with PyLint\nor\n$ make lint\n```\n\n## Contributions\n\nPull requests always welcomed. Thanks!", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ketgo/nameko-kafka", "keywords": "nameko,kafka,microservice", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "nameko-kafka", "package_url": "https://pypi.org/project/nameko-kafka/", "platform": "", "project_url": "https://pypi.org/project/nameko-kafka/", "project_urls": {"Homepage": "https://github.com/ketgo/nameko-kafka"}, "release_url": "https://pypi.org/project/nameko-kafka/0.1.0/", "requires_dist": null, "requires_python": ">=3.4", "summary": "Kafka extension for Nameko microservice framework", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Nameko-Kafka</h1>\n<p>Kafka extension for <a href=\"https://www.nameko.io/\" rel=\"nofollow\">Nameko</a> microservice framework.</p>\n<h2>Introduction</h2>\n<p>This is a Nameko microservice framework <a href=\"https://nameko.readthedocs.io/en/stable/key_concepts.html\" rel=\"nofollow\">extension</a> to support Kafka entrypoint and dependency. The motivation behind\ncreating this project is this issue <a href=\"https://github.com/nameko/nameko/issues/569\" rel=\"nofollow\">569</a>. Thus <em>nameko-kafka</em> tries to provide\na simple implementation extension based on the approach explained by <a href=\"https://medium.com/@calumpeterwebb/nameko-tutorial-creating-a-kafka-consuming-microservice-c4a7adb804d0\" rel=\"nofollow\">calumpeterwebb</a>.\nOn topo of that a dependency provider is also included for publishing Kafka messages from within Nameko services.</p>\n<h2>Installation</h2>\n<p>The package is supports Python &gt;= 3.5</p>\n<pre>$ pip install nameko-kafka\n</pre>\n<h2>Usage</h2>\n<p>The extension can be used for both, service dependency and entrypoint. Example usage for both the cases are shown below:</p>\n<h2>Dependency</h2>\n<p>This is basically a <a href=\"https://github.com/dpkp/kafka-python\" rel=\"nofollow\">python-kafka</a> producer in the form of Nameko dependency.\nNameko uses dependency injection to initiate the producer. You just need to declare it in your service class:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nameko.rpc</span> <span class=\"kn\">import</span> <span class=\"n\">rpc</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nameko_kafka</span> <span class=\"kn\">import</span> <span class=\"n\">KafkaProducer</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MyService</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">        My microservice</span>\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"my-service\"</span>\n    <span class=\"c1\"># Kafak dependency</span>\n    <span class=\"n\">producer</span> <span class=\"o\">=</span> <span class=\"n\">KafkaProducer</span><span class=\"p\">(</span><span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s1\">'localhost:1234'</span><span class=\"p\">)</span>\n    \n    <span class=\"nd\">@rpc</span>\n    <span class=\"k\">def</span> <span class=\"nf\">method</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Publish message using dependency</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">producer</span><span class=\"o\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"s2\">\"kafka-topic\"</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"o\">=</span><span class=\"sa\">b</span><span class=\"s2\">\"my-message\"</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"sa\">b</span><span class=\"s2\">\"my-key\"</span><span class=\"p\">)</span>\n</pre>\n<p>Here <code>KafkaProducer</code> accepts all options valid for <code>python-kafka</code>'s <a href=\"https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html\" rel=\"nofollow\">KafkaProducer</a>.</p>\n<h3>Entrypoint</h3>\n<p>You can use the <code>nameko_kafka.consume</code> decorator in your services which process Kafka messages:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nameko_kafka</span> <span class=\"kn\">import</span> <span class=\"n\">consume</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MyService</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">        My microservice </span>\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"my-service\"</span>\n\n    <span class=\"nd\">@consume</span><span class=\"p\">(</span><span class=\"s2\">\"kafka-topic\"</span><span class=\"p\">,</span> <span class=\"n\">group_id</span><span class=\"o\">=</span><span class=\"s2\">\"my-group\"</span><span class=\"p\">,</span> <span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s1\">'localhost:1234'</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">method</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">message</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Your message handler</span>\n        <span class=\"n\">handle_message</span><span class=\"p\">(</span><span class=\"n\">message</span><span class=\"p\">)</span> \n</pre>\n<p>The <code>consume</code> decorator accepts all the options valid for <code>python-kafka</code>'s <a href=\"https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html\" rel=\"nofollow\">KafkaProducer</a>.</p>\n<h2>Configurations</h2>\n<p>The dependency configurations can be set in nameko <a href=\"(https://docs.nameko.io/en/stable/cli.html)\" rel=\"nofollow\">config.yaml</a> file, or\nby environment variables.</p>\n<h3>Config File</h3>\n<pre><span class=\"c1\"># Config for entrypoint</span>\n<span class=\"nt\">KAFKA_CONSUMER</span><span class=\"p\">:</span>\n  <span class=\"nt\">bootstrap_servers</span><span class=\"p\">:</span> <span class=\"s\">'localhost:1234'</span>\n  <span class=\"nt\">retry_backoff_ms</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">100</span>\n  <span class=\"l l-Scalar l-Scalar-Plain\">...</span>\n\n<span class=\"c1\"># Config for dependency</span>\n<span class=\"nt\">KAFKA_PRODUCER</span><span class=\"p\">:</span>\n  <span class=\"nt\">bootstrap_servers</span><span class=\"p\">:</span> <span class=\"s\">'localhost:1234'</span>\n  <span class=\"nt\">retries</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">3</span>\n  <span class=\"l l-Scalar l-Scalar-Plain\">...</span>\n</pre>\n<h3>Environment Variables</h3>\n<pre># Config for entrypoint\nKAFKA_CONSUMER='{\"bootstrap_servers\": \"localhost:1234\", \"retry_backoff_ms\": 100}'\n\n# Config for dependency\nKAFKA_PRODUCER='{\"bootstrap_servers\": \"localhost:1234\", \"retries\": 3}'\n</pre>\n<h2>Milestones</h2>\n<p>[x] Kafka Entrypoint\n[x] Kafka Dependency\n[ ] Advanced feature select commit strategies: <em>ALMOST_ONCE_DELIVERY</em>, <em>AT_LEAST_ONCE_DELIVERY</em>, <em>EXACTLY_ONCE_DELIVERY</em>\n[ ] Commit storage for <em>EXACT_ONCE_DELIVERY</em> strategy</p>\n<h2>Developers</h2>\n<p>For development a kafka broker is required. You can spawn one using the <a href=\"https://github.com/ketgo/nameko-kafka/blob/master/tests/conftest.py\" rel=\"nofollow\">docker-compose.yml</a>\nfile in the <code>tests</code> folder:</p>\n<pre>$ <span class=\"nb\">cd</span> tests\n$ docker-compose up -d \n</pre>\n<p>To install all package dependencies:</p>\n<pre>$ pip install -r .<span class=\"o\">[</span>dev<span class=\"o\">]</span>\nor\n$ make deps\n</pre>\n<p>Other useful commands:</p>\n<pre>$ pytest --cov<span class=\"o\">=</span>nameko_kafka tests/\t\t\t<span class=\"c1\"># to get coverage report</span>\nor\n$ make coverage\n\n$ pylint nameko_kafka       <span class=\"c1\"># to check code quality with PyLint</span>\nor\n$ make lint\n</pre>\n<h2>Contributions</h2>\n<p>Pull requests always welcomed. Thanks!</p>\n\n          </div>"}, "last_serial": 6900571, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "58fb14903982bf9ed454671668587953", "sha256": "d8de18aabf1bf85adb02e9a2b222a1f2177053fe0a868ded4504219befc9e9b7"}, "downloads": -1, "filename": "nameko_kafka-0.1.0.tar.gz", "has_sig": false, "md5_digest": "58fb14903982bf9ed454671668587953", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 4706, "upload_time": "2020-03-28T06:18:01", "upload_time_iso_8601": "2020-03-28T06:18:01.142857Z", "url": "https://files.pythonhosted.org/packages/1a/f5/a72b90390bceb1646d0168731137fbcaacefc272f9351d7b6f8b996483d9/nameko_kafka-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "58fb14903982bf9ed454671668587953", "sha256": "d8de18aabf1bf85adb02e9a2b222a1f2177053fe0a868ded4504219befc9e9b7"}, "downloads": -1, "filename": "nameko_kafka-0.1.0.tar.gz", "has_sig": false, "md5_digest": "58fb14903982bf9ed454671668587953", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 4706, "upload_time": "2020-03-28T06:18:01", "upload_time_iso_8601": "2020-03-28T06:18:01.142857Z", "url": "https://files.pythonhosted.org/packages/1a/f5/a72b90390bceb1646d0168731137fbcaacefc272f9351d7b6f8b996483d9/nameko_kafka-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:45 2020"}