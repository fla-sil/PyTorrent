{"info": {"author": "Ashton Sidhu", "author_email": "ashton.sidhu1994@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "[![PyPI version](https://badge.fury.io/py/py-automl.svg)](https://badge.fury.io/py/py-automl) [![CircleCI](https://circleci.com/gh/Ashton-Sidhu/py-automl/tree/develop.svg?style=svg)](https://circleci.com/gh/Ashton-Sidhu/py-automl/tree/develop) [![Documentation Status](https://readthedocs.org/projects/py-automl/badge/?version=latest)](https://py-automl.readthedocs.io/en/latest/?badge=latest) [![codecov](https://codecov.io/gh/Ashton-Sidhu/py-automl/branch/develop/graph/badge.svg)](https://codecov.io/gh/Ashton-Sidhu/py-automl)\n\n\n\n\n# py-automl\n\n<i>\"A collection of tools for Data Scientists and ML Engineers for them to focus less on how to do the analysis and instead worry about what are the best analytic tools that will help gain the most insights from their data.\"</i>\n\nTo track development of the project, you can view the [Trello board](https://trello.com/b/EZVs9Hxz/automated-ds-ml).\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n## Table of Contents\n\n- [Introduction](#introduction)\n- [Motivation](#motivation)\n- [Usage](#usage)\n- [Installation](#installation)\n- [Features](#features)\n- [Development Phases](#development-phases)\n- [Feedback](#feedback)\n- [Contributors](#contributors)\n- [Sponsors](#sponsors)\n- [Acknowledgments](#acknowledgments)\n- [For Developers](#for-developers)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## Introduction\n\nPy-automl is a library/platform that automates your data science and analytical tasks at any stage in the pipeline. Py-automl is, at its core, a wrapper that helps automate analytical techniques from various libaries such as pandas, sci-kit learn, gensim, etc. and tries to the bridge the gap \n\nPy-automl makes it easy to PoC, experiment and compare different techniques and models from various libraries. From cleaning your data, visualizing it and even applying feature engineering techniques from your favourite libraries - all done with a single, human readable, line of code!\n\nPy-automl utilizes other open source libraries to help enhance your analysis from enhanced stastical information, interactive visual plots or statistical tests and models - all your tools in one place, all accessible with one line of code or a click! See below in the [Acknowledgments](#acknowledgments) for the open source libraries being used in this project.\n\n## Motivation\n\nI created this library to help automate the data science/machine learning pipeline and have all the tools required for analysis in one place. I grew tired having to go back and look at code to find implementation for a certain type of analysis, googling for the implementation and converting PoCs to production level code or a microservice. I wanted to be able to focus more time on thinking about the analysis and the techniques to apply instead of worrying about developing them and finding implementations.\n\nSecondly there were alot of people that wanted to try data science that were in a different technical stream but and were blocked due to knowledge and technical barriers. My goal was to remove the technical barriers, so that as long as they understand the techniques at a high level, they can work with data scientists and help contribute to performing some analysis with just one line of code or a click of a button - allowing the data scientist or ML engineer to focus on interpreting/applying the results.\n\nFor more info see my [vision statememt](https://github.com/Ashton-Sidhu/py-automl/blob/develop/VISION.md).\n\n## Usage\nFor full documentation on all the techniques and models, click [here](https://py-automl.readthedocs.io/en/latest/?badge=latest) or [here](https://py-automl.readthedocs.io/en/latest/source/pyautoml.html#)\n\nExamples can be viewed [here](https://github.com/Ashton-Sidhu/py-automl/tree/develop/examples)\n\nTo start, we need to import the data science workflow stages as well as pandas.\n\nBefore that, we can create a full data science folder structure by running `pyautoml create` from the command line and follow the command prompts.\n\n#### General Use\nTo enable extensions, such as QGrid interactive filtering:\n\n```python\nimport pyautoml as py\npy.set_option('interactive_df', True)\npy.options.interactive_df = True\n```\n\n```python\nimport pyautoml as py\nimport pandas as pd\n\nx_train = pd.read_csv('data/train.csv') # load data into pandas\n\n# Initialize cleaning object with training data\n# By default, if no test data (x_test) is provided, then the data is split with 20% going to the test set\n# Specify predictor field as 'Survived'\n# Specify report name\nclean = py.Clean(x_train=x_train, target_field='Survived', report_name='Titanic')\n\nclean.x_train # View your training data\nclean.x_test # View your testing data\n\nclean # Glance at your training data\n\nclean[clean.Age > 25] # Filter the data\n\nclean['new_col'] = [1, 2]  # Add a new column to the data, based off the length of the data provided, it will add it to the train or test set.\n\nclean.x_train['new_col'] = [1,2] # This is the exact same as the either of code above\nclean.x_test['new_col'] = [1,2]\n\nclean.data_report(title='Titanic Summary', output_file='titanic_summary.html') # Automate EDA with pandas profiling with an autogenerated report\n\nclean.describe() # Display a high level view of your data using an extended version of pandas describe\n\nclean.describe_column('Fare') # Get indepth statistics about the 'Fare' column\n\nclean.mean() # Run pandas functions on the pyautoml objects\n\nclean.missing_data # View your missing data at anytime\n\nclean.correlation_matrix() # Generate a correlation matrix for your training data\n\nclean.pairplot() # Generate pairplots for your training data features at any time\n\nclean.checklist() # Will provide an iteractive checklist to keep track of your cleaning tasks\n```\n\n**NOTE:** One of the benefits of using `pyautoml` is that any method you apply on your train set, gets applied to your test dataset. For any method that requires fitting (replacing missing data with mean), the method is fit on the training data and then applied to the testing data to avoid data leakage.\n\n**NOTE:** If you are providing a list or a Series and your data is split into train and test, the new column is created in the dataset that matches the length of the data provided. If the length of the data provided matches both train and test data it is added to both. \n\n#### Cleaning \n\n```python\nclean.replace_missing_mostcommon('Fare', 'Embarked') # Replace missing values in the 'Fare' and 'Embarked' column with the most common values in each of the respective columns.\n\nrep_mcommon = clean.replace_missing_mostcommon('Fare', 'Embarked') # To create a \"checkpoint\" of your data (i.e. if you just want to test this analytical method), assign it to a variable\n\n# Now I can keep going with my analysis using the clean object and if something goes wrong when exploring this analysis path, I can pick right up from this point by using the `rep_mcommon` variable, without having to restart any kernels or reload any data.\n\nclean.replace_missing_random_discrete('Age') # Replace missing values in the 'Age' column with a random value that follows the probability distribution of the 'Age' column in the training set. \n\nclean.drop('Cabin') # Drop the cabin column\n\n# Columns can also be dropped by defining the columns you want to keep (drop all columns except the ones you want to keep) or by passing in a regex expressions and all columns that match the regex expression will be dropped.\n\n# As you've started to notice, alot of tasks to clean the data and to explore the data have been reduced down to one command, and are also customizable by providing the respective keyword arguments (see documentation).\n```\n\n#### Preprocessing and Feature Engineering\n\n```python\nclean.barplot(x='Age', y=['Survived'], method='mean', xlabel='Age') # Create a barblot of the mean surivial rate grouped by age.\n\nprep = py.Preprocess(clean) # To move onto preprocessing\n\nfeature = py.Feature(clean) # to move onto feature engineering\n\nfeature.onehot_encode('Person', 'Embarked', drop_col=True) # One hot encode these columns and then drop the original columns\n```\n\n#### Modelling\n\n```python\nmodel = py.Model(feature) # To move onto modelling\n\n# Models can be run in various ways\n\nmodel.logistic_regression(random_state=42, run=True) # Train a logistic regression model\nmodel.logistic_regression(gridsearch={'penalty': ['l1', 'l2']}, random_state=42, run=True) # Running gridsearch with the best params\n\nmodel.logistic_regression(cv=5, learning_curve=True) # Crossvalidates a logistic regression model and displays the scores and the learning curve\n\nmodel.logistic_regression(random_state=42, model_name='log_reg') # Adds a logistic regression model to the queue\nmodel.random_forest() # Adds a random forest model to the queue\nmodel.xgboost_classification() # Adds an xgboost classification model to the queue\n\nmodel.run_models() # This will run all queued models in parallel\nmodel.run_models(method='series') # Run each model one after the other\n\nmodel.compare_models() # This will display each model evaluated against every metric\n\n# Every model is accessed by a unique name that is assiged when you run the model.\n# Default model names can be seen in the function header of each model.\n\nmodel.log_reg.confusion_matrix() # Displays a confusion matrix for the logistic regression model\n\nmodel.rf_cls.confusion_matrix() # Displays a confusion matrix for the random forest model\n```\n\n**NOTE:** In pandas you'll often see `df = df.method(...)` or `df.method(..., inplace=True)` when transforming your data. Then depending on how you developed your analysis, when a mistake is made you either have to restart the kernel or reload your data entirely. In `pyautoml` most methods will change the data inplace (methods that have the keyword argument `new_col_name` will create a new column) without having to go `df = df.method(...)`. To create a \"checkpoint\" that creates a copy of your current state just assign the method to a variable, for example:\n\n## Installation\n\n`pip install py-automl`\n\nTo install associating corpora for nltk analysis:\n\n`pyautoml -ic` or `pyautoml --install-corpora`\n\nTo install and use the extensions such as `qgrid` for interactive filtering and analysis with DataFrames:\n\n`pyautoml -ie` or `pyautoml --install-extensions`\n\nCurrently working on condas implementation.\n\nTo create a Data Science project run:\n\n`pyautoml -c` or `pyautomal --create`\n\nThis will create a full folder strucuture for you to manage data, unit tests, experiments and source code.\n\n## Features\n\n- Python package that simplifies and automates cleaning, visualizing, preprocessing, feature engineering, and modelling techniques.\n- Report generation detailing exact steps how you transformed your dataset\n- If you are doing a PoC or experimenting the code will output in a `.ipynb` and a `.py` format. *\n- If the plan is to create a full pipeline the code will out a `.py` containing the full pipeline. *\n- Model Evaluation\n- Model Deployment *\n- Spark Integration *\n- Data visualizations\n- On prem deployment *\n- 3rd Party application integration (Azure, AWS, GC) *\n\n## Development Phases\n\n### Library\n#### Phase 1\n  - [x]\tData Processing techniques\n    - [x] Data Cleaning V1\n    - [x] Feature Engineering V1\n  - [x]\tReporting V1\n\n#### Phase 2\n  - [x]\tData visualizations\n  - [x]\tModels and Evaluation\n  - [x]\tReporting V2\n\n#### Phase 3\n  - [x] Quality of life/addons\n  - [ ] Parallelization\n\n#### Phase 4\n  - [ ]\tSpark\n  - [ ]\tCommunity centric optimization (making it easier to share techniques and models with other engineers).\n    \n#### Phase 5\n  - [ ]\tCloud computing\n  - [ ]\tDeep learning integration\n\n#### Phase 6\n  - [ ] Web App\n  - [ ] Code Generation\n  \nThese are subject to change.\n\n## Feedback\n\nI appreciate any feedback so if you have any feature requests or issues make an issue with the appropriate tag or futhermore, send me an email at ashton.sidhu1994@gmail.com\n\n## Contributors\n\nThis project follows the [all-contributors](https://github.com/kentcdodds/all-contributors) specification and is brought to you by these [awesome contributors](./CONTRIBUTORS.md).\n\n## Sponsors\n\nN/A\n\n## Acknowledgments\n\n[@mouradmourafiq](https://github.com/mouradmourafiq) for his [pandas-summary](https://github.com/mouradmourafiq/pandas-summary) library.\n\n[@PatrikHlobil](https://github.com/PatrikHlobil) for his [Pandas-Bokeh](https://github.com/PatrikHlobil/Pandas-Bokeh) library.\n\n[@pandas-profiling](https://github.com/pandas-profiling) for their automated [EDA report generation](https://github.com/pandas-profiling/pandas-profiling) library.\n\n[@slundberg](https://github.com/slundberg/) for his [shap](https://github.com/slundberg/shap) model explanation library.\n\n[@microsoft](https://github.com/microsoft/) for their [interpret](https://github.com/microsoft/interpret) model explanation library.\n\n[@DistrictDataLabs](https://github.com/DistrictDataLabs?type=source) for their [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick) visual analysis and model diagnostic tool.\n\n[@Quantopian](https://github.com/quantopian?type=source) for their interactive DataFrame library [qgrid](https://github.com/quantopian/qgrid).\n\n## For Developers\n\nFor python snippets to make deving new techniques either, message me and I can send them.\n\nTo install packages `pip3 install -r requirements.txt`\n\nTo run tests `python3 -m unittest discover pyautoml/`", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Ashton-Sidhu/py-automl", "keywords": "datascience,machinelearning,automation,analysis", "license": "GPL-3.0", "maintainer": "", "maintainer_email": "", "name": "py-automl", "package_url": "https://pypi.org/project/py-automl/", "platform": "", "project_url": "https://pypi.org/project/py-automl/", "project_urls": {"Homepage": "https://github.com/Ashton-Sidhu/py-automl"}, "release_url": "https://pypi.org/project/py-automl/0.7.0/", "requires_dist": null, "requires_python": ">= 3.6", "summary": "A library of data science and machine learning techniques to help automate your workflow.", "version": "0.7.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://badge.fury.io/py/py-automl\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/266ecd3117d9846c50fcd0b3a0e4891ecdb7b61c/68747470733a2f2f62616467652e667572792e696f2f70792f70792d6175746f6d6c2e737667\"></a> <a href=\"https://circleci.com/gh/Ashton-Sidhu/py-automl/tree/develop\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/921fd27d104ce8bbcfa5da92990fca4ac107753b/68747470733a2f2f636972636c6563692e636f6d2f67682f417368746f6e2d53696468752f70792d6175746f6d6c2f747265652f646576656c6f702e7376673f7374796c653d737667\"></a> <a href=\"https://py-automl.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d74db3f1751696911d2aabea7f1ad64a3106edcc/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f70792d6175746f6d6c2f62616467652f3f76657273696f6e3d6c6174657374\"></a> <a href=\"https://codecov.io/gh/Ashton-Sidhu/py-automl\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/94b0dd1a0b32438f51b063b934df05ac043bee7c/68747470733a2f2f636f6465636f762e696f2f67682f417368746f6e2d53696468752f70792d6175746f6d6c2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\"></a></p>\n<h1>py-automl</h1>\n<p><i>\"A collection of tools for Data Scientists and ML Engineers for them to focus less on how to do the analysis and instead worry about what are the best analytic tools that will help gain the most insights from their data.\"</i></p>\n<p>To track development of the project, you can view the <a href=\"https://trello.com/b/EZVs9Hxz/automated-ds-ml\" rel=\"nofollow\">Trello board</a>.</p>\n\n\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#introduction\" rel=\"nofollow\">Introduction</a></li>\n<li><a href=\"#motivation\" rel=\"nofollow\">Motivation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#features\" rel=\"nofollow\">Features</a></li>\n<li><a href=\"#development-phases\" rel=\"nofollow\">Development Phases</a></li>\n<li><a href=\"#feedback\" rel=\"nofollow\">Feedback</a></li>\n<li><a href=\"#contributors\" rel=\"nofollow\">Contributors</a></li>\n<li><a href=\"#sponsors\" rel=\"nofollow\">Sponsors</a></li>\n<li><a href=\"#acknowledgments\" rel=\"nofollow\">Acknowledgments</a></li>\n<li><a href=\"#for-developers\" rel=\"nofollow\">For Developers</a></li>\n</ul>\n\n<h2>Introduction</h2>\n<p>Py-automl is a library/platform that automates your data science and analytical tasks at any stage in the pipeline. Py-automl is, at its core, a wrapper that helps automate analytical techniques from various libaries such as pandas, sci-kit learn, gensim, etc. and tries to the bridge the gap</p>\n<p>Py-automl makes it easy to PoC, experiment and compare different techniques and models from various libraries. From cleaning your data, visualizing it and even applying feature engineering techniques from your favourite libraries - all done with a single, human readable, line of code!</p>\n<p>Py-automl utilizes other open source libraries to help enhance your analysis from enhanced stastical information, interactive visual plots or statistical tests and models - all your tools in one place, all accessible with one line of code or a click! See below in the <a href=\"#acknowledgments\" rel=\"nofollow\">Acknowledgments</a> for the open source libraries being used in this project.</p>\n<h2>Motivation</h2>\n<p>I created this library to help automate the data science/machine learning pipeline and have all the tools required for analysis in one place. I grew tired having to go back and look at code to find implementation for a certain type of analysis, googling for the implementation and converting PoCs to production level code or a microservice. I wanted to be able to focus more time on thinking about the analysis and the techniques to apply instead of worrying about developing them and finding implementations.</p>\n<p>Secondly there were alot of people that wanted to try data science that were in a different technical stream but and were blocked due to knowledge and technical barriers. My goal was to remove the technical barriers, so that as long as they understand the techniques at a high level, they can work with data scientists and help contribute to performing some analysis with just one line of code or a click of a button - allowing the data scientist or ML engineer to focus on interpreting/applying the results.</p>\n<p>For more info see my <a href=\"https://github.com/Ashton-Sidhu/py-automl/blob/develop/VISION.md\" rel=\"nofollow\">vision statememt</a>.</p>\n<h2>Usage</h2>\n<p>For full documentation on all the techniques and models, click <a href=\"https://py-automl.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\">here</a> or <a href=\"https://py-automl.readthedocs.io/en/latest/source/pyautoml.html#\" rel=\"nofollow\">here</a></p>\n<p>Examples can be viewed <a href=\"https://github.com/Ashton-Sidhu/py-automl/tree/develop/examples\" rel=\"nofollow\">here</a></p>\n<p>To start, we need to import the data science workflow stages as well as pandas.</p>\n<p>Before that, we can create a full data science folder structure by running <code>pyautoml create</code> from the command line and follow the command prompts.</p>\n<h4>General Use</h4>\n<p>To enable extensions, such as QGrid interactive filtering:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pyautoml</span> <span class=\"k\">as</span> <span class=\"nn\">py</span>\n<span class=\"n\">py</span><span class=\"o\">.</span><span class=\"n\">set_option</span><span class=\"p\">(</span><span class=\"s1\">'interactive_df'</span><span class=\"p\">,</span> <span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">py</span><span class=\"o\">.</span><span class=\"n\">options</span><span class=\"o\">.</span><span class=\"n\">interactive_df</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n</pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pyautoml</span> <span class=\"k\">as</span> <span class=\"nn\">py</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"n\">x_train</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'data/train.csv'</span><span class=\"p\">)</span> <span class=\"c1\"># load data into pandas</span>\n\n<span class=\"c1\"># Initialize cleaning object with training data</span>\n<span class=\"c1\"># By default, if no test data (x_test) is provided, then the data is split with 20% going to the test set</span>\n<span class=\"c1\"># Specify predictor field as 'Survived'</span>\n<span class=\"c1\"># Specify report name</span>\n<span class=\"n\">clean</span> <span class=\"o\">=</span> <span class=\"n\">py</span><span class=\"o\">.</span><span class=\"n\">Clean</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"o\">=</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">target_field</span><span class=\"o\">=</span><span class=\"s1\">'Survived'</span><span class=\"p\">,</span> <span class=\"n\">report_name</span><span class=\"o\">=</span><span class=\"s1\">'Titanic'</span><span class=\"p\">)</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">x_train</span> <span class=\"c1\"># View your training data</span>\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">x_test</span> <span class=\"c1\"># View your testing data</span>\n\n<span class=\"n\">clean</span> <span class=\"c1\"># Glance at your training data</span>\n\n<span class=\"n\">clean</span><span class=\"p\">[</span><span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">Age</span> <span class=\"o\">&gt;</span> <span class=\"mi\">25</span><span class=\"p\">]</span> <span class=\"c1\"># Filter the data</span>\n\n<span class=\"n\">clean</span><span class=\"p\">[</span><span class=\"s1\">'new_col'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]</span>  <span class=\"c1\"># Add a new column to the data, based off the length of the data provided, it will add it to the train or test set.</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">x_train</span><span class=\"p\">[</span><span class=\"s1\">'new_col'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"c1\"># This is the exact same as the either of code above</span>\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">x_test</span><span class=\"p\">[</span><span class=\"s1\">'new_col'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">]</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">data_report</span><span class=\"p\">(</span><span class=\"n\">title</span><span class=\"o\">=</span><span class=\"s1\">'Titanic Summary'</span><span class=\"p\">,</span> <span class=\"n\">output_file</span><span class=\"o\">=</span><span class=\"s1\">'titanic_summary.html'</span><span class=\"p\">)</span> <span class=\"c1\"># Automate EDA with pandas profiling with an autogenerated report</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">describe</span><span class=\"p\">()</span> <span class=\"c1\"># Display a high level view of your data using an extended version of pandas describe</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">describe_column</span><span class=\"p\">(</span><span class=\"s1\">'Fare'</span><span class=\"p\">)</span> <span class=\"c1\"># Get indepth statistics about the 'Fare' column</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span> <span class=\"c1\"># Run pandas functions on the pyautoml objects</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">missing_data</span> <span class=\"c1\"># View your missing data at anytime</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">correlation_matrix</span><span class=\"p\">()</span> <span class=\"c1\"># Generate a correlation matrix for your training data</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">pairplot</span><span class=\"p\">()</span> <span class=\"c1\"># Generate pairplots for your training data features at any time</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">checklist</span><span class=\"p\">()</span> <span class=\"c1\"># Will provide an iteractive checklist to keep track of your cleaning tasks</span>\n</pre>\n<p><strong>NOTE:</strong> One of the benefits of using <code>pyautoml</code> is that any method you apply on your train set, gets applied to your test dataset. For any method that requires fitting (replacing missing data with mean), the method is fit on the training data and then applied to the testing data to avoid data leakage.</p>\n<p><strong>NOTE:</strong> If you are providing a list or a Series and your data is split into train and test, the new column is created in the dataset that matches the length of the data provided. If the length of the data provided matches both train and test data it is added to both.</p>\n<h4>Cleaning</h4>\n<pre><span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">replace_missing_mostcommon</span><span class=\"p\">(</span><span class=\"s1\">'Fare'</span><span class=\"p\">,</span> <span class=\"s1\">'Embarked'</span><span class=\"p\">)</span> <span class=\"c1\"># Replace missing values in the 'Fare' and 'Embarked' column with the most common values in each of the respective columns.</span>\n\n<span class=\"n\">rep_mcommon</span> <span class=\"o\">=</span> <span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">replace_missing_mostcommon</span><span class=\"p\">(</span><span class=\"s1\">'Fare'</span><span class=\"p\">,</span> <span class=\"s1\">'Embarked'</span><span class=\"p\">)</span> <span class=\"c1\"># To create a \"checkpoint\" of your data (i.e. if you just want to test this analytical method), assign it to a variable</span>\n\n<span class=\"c1\"># Now I can keep going with my analysis using the clean object and if something goes wrong when exploring this analysis path, I can pick right up from this point by using the `rep_mcommon` variable, without having to restart any kernels or reload any data.</span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">replace_missing_random_discrete</span><span class=\"p\">(</span><span class=\"s1\">'Age'</span><span class=\"p\">)</span> <span class=\"c1\"># Replace missing values in the 'Age' column with a random value that follows the probability distribution of the 'Age' column in the training set. </span>\n\n<span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">'Cabin'</span><span class=\"p\">)</span> <span class=\"c1\"># Drop the cabin column</span>\n\n<span class=\"c1\"># Columns can also be dropped by defining the columns you want to keep (drop all columns except the ones you want to keep) or by passing in a regex expressions and all columns that match the regex expression will be dropped.</span>\n\n<span class=\"c1\"># As you've started to notice, alot of tasks to clean the data and to explore the data have been reduced down to one command, and are also customizable by providing the respective keyword arguments (see documentation).</span>\n</pre>\n<h4>Preprocessing and Feature Engineering</h4>\n<pre><span class=\"n\">clean</span><span class=\"o\">.</span><span class=\"n\">barplot</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"s1\">'Age'</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'Survived'</span><span class=\"p\">],</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s1\">'mean'</span><span class=\"p\">,</span> <span class=\"n\">xlabel</span><span class=\"o\">=</span><span class=\"s1\">'Age'</span><span class=\"p\">)</span> <span class=\"c1\"># Create a barblot of the mean surivial rate grouped by age.</span>\n\n<span class=\"n\">prep</span> <span class=\"o\">=</span> <span class=\"n\">py</span><span class=\"o\">.</span><span class=\"n\">Preprocess</span><span class=\"p\">(</span><span class=\"n\">clean</span><span class=\"p\">)</span> <span class=\"c1\"># To move onto preprocessing</span>\n\n<span class=\"n\">feature</span> <span class=\"o\">=</span> <span class=\"n\">py</span><span class=\"o\">.</span><span class=\"n\">Feature</span><span class=\"p\">(</span><span class=\"n\">clean</span><span class=\"p\">)</span> <span class=\"c1\"># to move onto feature engineering</span>\n\n<span class=\"n\">feature</span><span class=\"o\">.</span><span class=\"n\">onehot_encode</span><span class=\"p\">(</span><span class=\"s1\">'Person'</span><span class=\"p\">,</span> <span class=\"s1\">'Embarked'</span><span class=\"p\">,</span> <span class=\"n\">drop_col</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># One hot encode these columns and then drop the original columns</span>\n</pre>\n<h4>Modelling</h4>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">py</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">feature</span><span class=\"p\">)</span> <span class=\"c1\"># To move onto modelling</span>\n\n<span class=\"c1\"># Models can be run in various ways</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">logistic_regression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"n\">run</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># Train a logistic regression model</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">logistic_regression</span><span class=\"p\">(</span><span class=\"n\">gridsearch</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'penalty'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'l1'</span><span class=\"p\">,</span> <span class=\"s1\">'l2'</span><span class=\"p\">]},</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"n\">run</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># Running gridsearch with the best params</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">logistic_regression</span><span class=\"p\">(</span><span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">learning_curve</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"c1\"># Crossvalidates a logistic regression model and displays the scores and the learning curve</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">logistic_regression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'log_reg'</span><span class=\"p\">)</span> <span class=\"c1\"># Adds a logistic regression model to the queue</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">random_forest</span><span class=\"p\">()</span> <span class=\"c1\"># Adds a random forest model to the queue</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">xgboost_classification</span><span class=\"p\">()</span> <span class=\"c1\"># Adds an xgboost classification model to the queue</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">run_models</span><span class=\"p\">()</span> <span class=\"c1\"># This will run all queued models in parallel</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">run_models</span><span class=\"p\">(</span><span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s1\">'series'</span><span class=\"p\">)</span> <span class=\"c1\"># Run each model one after the other</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compare_models</span><span class=\"p\">()</span> <span class=\"c1\"># This will display each model evaluated against every metric</span>\n\n<span class=\"c1\"># Every model is accessed by a unique name that is assiged when you run the model.</span>\n<span class=\"c1\"># Default model names can be seen in the function header of each model.</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">log_reg</span><span class=\"o\">.</span><span class=\"n\">confusion_matrix</span><span class=\"p\">()</span> <span class=\"c1\"># Displays a confusion matrix for the logistic regression model</span>\n\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">rf_cls</span><span class=\"o\">.</span><span class=\"n\">confusion_matrix</span><span class=\"p\">()</span> <span class=\"c1\"># Displays a confusion matrix for the random forest model</span>\n</pre>\n<p><strong>NOTE:</strong> In pandas you'll often see <code>df = df.method(...)</code> or <code>df.method(..., inplace=True)</code> when transforming your data. Then depending on how you developed your analysis, when a mistake is made you either have to restart the kernel or reload your data entirely. In <code>pyautoml</code> most methods will change the data inplace (methods that have the keyword argument <code>new_col_name</code> will create a new column) without having to go <code>df = df.method(...)</code>. To create a \"checkpoint\" that creates a copy of your current state just assign the method to a variable, for example:</p>\n<h2>Installation</h2>\n<p><code>pip install py-automl</code></p>\n<p>To install associating corpora for nltk analysis:</p>\n<p><code>pyautoml -ic</code> or <code>pyautoml --install-corpora</code></p>\n<p>To install and use the extensions such as <code>qgrid</code> for interactive filtering and analysis with DataFrames:</p>\n<p><code>pyautoml -ie</code> or <code>pyautoml --install-extensions</code></p>\n<p>Currently working on condas implementation.</p>\n<p>To create a Data Science project run:</p>\n<p><code>pyautoml -c</code> or <code>pyautomal --create</code></p>\n<p>This will create a full folder strucuture for you to manage data, unit tests, experiments and source code.</p>\n<h2>Features</h2>\n<ul>\n<li>Python package that simplifies and automates cleaning, visualizing, preprocessing, feature engineering, and modelling techniques.</li>\n<li>Report generation detailing exact steps how you transformed your dataset</li>\n<li>If you are doing a PoC or experimenting the code will output in a <code>.ipynb</code> and a <code>.py</code> format. *</li>\n<li>If the plan is to create a full pipeline the code will out a <code>.py</code> containing the full pipeline. *</li>\n<li>Model Evaluation</li>\n<li>Model Deployment *</li>\n<li>Spark Integration *</li>\n<li>Data visualizations</li>\n<li>On prem deployment *</li>\n<li>3rd Party application integration (Azure, AWS, GC) *</li>\n</ul>\n<h2>Development Phases</h2>\n<h3>Library</h3>\n<h4>Phase 1</h4>\n<ul>\n<li>[x]\tData Processing techniques\n<ul>\n<li>[x] Data Cleaning V1</li>\n<li>[x] Feature Engineering V1</li>\n</ul>\n</li>\n<li>[x]\tReporting V1</li>\n</ul>\n<h4>Phase 2</h4>\n<ul>\n<li>[x]\tData visualizations</li>\n<li>[x]\tModels and Evaluation</li>\n<li>[x]\tReporting V2</li>\n</ul>\n<h4>Phase 3</h4>\n<ul>\n<li>[x] Quality of life/addons</li>\n<li>[ ] Parallelization</li>\n</ul>\n<h4>Phase 4</h4>\n<ul>\n<li>[ ]\tSpark</li>\n<li>[ ]\tCommunity centric optimization (making it easier to share techniques and models with other engineers).</li>\n</ul>\n<h4>Phase 5</h4>\n<ul>\n<li>[ ]\tCloud computing</li>\n<li>[ ]\tDeep learning integration</li>\n</ul>\n<h4>Phase 6</h4>\n<ul>\n<li>[ ] Web App</li>\n<li>[ ] Code Generation</li>\n</ul>\n<p>These are subject to change.</p>\n<h2>Feedback</h2>\n<p>I appreciate any feedback so if you have any feature requests or issues make an issue with the appropriate tag or futhermore, send me an email at <a href=\"mailto:ashton.sidhu1994@gmail.com\">ashton.sidhu1994@gmail.com</a></p>\n<h2>Contributors</h2>\n<p>This project follows the <a href=\"https://github.com/kentcdodds/all-contributors\" rel=\"nofollow\">all-contributors</a> specification and is brought to you by these <a href=\"./CONTRIBUTORS.md\" rel=\"nofollow\">awesome contributors</a>.</p>\n<h2>Sponsors</h2>\n<p>N/A</p>\n<h2>Acknowledgments</h2>\n<p><a href=\"https://github.com/mouradmourafiq\" rel=\"nofollow\">@mouradmourafiq</a> for his <a href=\"https://github.com/mouradmourafiq/pandas-summary\" rel=\"nofollow\">pandas-summary</a> library.</p>\n<p><a href=\"https://github.com/PatrikHlobil\" rel=\"nofollow\">@PatrikHlobil</a> for his <a href=\"https://github.com/PatrikHlobil/Pandas-Bokeh\" rel=\"nofollow\">Pandas-Bokeh</a> library.</p>\n<p><a href=\"https://github.com/pandas-profiling\" rel=\"nofollow\">@pandas-profiling</a> for their automated <a href=\"https://github.com/pandas-profiling/pandas-profiling\" rel=\"nofollow\">EDA report generation</a> library.</p>\n<p><a href=\"https://github.com/slundberg/\" rel=\"nofollow\">@slundberg</a> for his <a href=\"https://github.com/slundberg/shap\" rel=\"nofollow\">shap</a> model explanation library.</p>\n<p><a href=\"https://github.com/microsoft/\" rel=\"nofollow\">@microsoft</a> for their <a href=\"https://github.com/microsoft/interpret\" rel=\"nofollow\">interpret</a> model explanation library.</p>\n<p><a href=\"https://github.com/DistrictDataLabs?type=source\" rel=\"nofollow\">@DistrictDataLabs</a> for their <a href=\"https://github.com/DistrictDataLabs/yellowbrick\" rel=\"nofollow\">yellowbrick</a> visual analysis and model diagnostic tool.</p>\n<p><a href=\"https://github.com/quantopian?type=source\" rel=\"nofollow\">@Quantopian</a> for their interactive DataFrame library <a href=\"https://github.com/quantopian/qgrid\" rel=\"nofollow\">qgrid</a>.</p>\n<h2>For Developers</h2>\n<p>For python snippets to make deving new techniques either, message me and I can send them.</p>\n<p>To install packages <code>pip3 install -r requirements.txt</code></p>\n<p>To run tests <code>python3 -m unittest discover pyautoml/</code></p>\n\n          </div>"}, "last_serial": 6219765, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "71bed797571350ed34d65aaa5ba09216", "sha256": "e1474de5c414afb1950114cff2d960874a98630cf09fecba57efd05d71fb5bc0"}, "downloads": -1, "filename": "py_automl-0.1.0-py3.6.egg", "has_sig": false, "md5_digest": "71bed797571350ed34d65aaa5ba09216", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 61787, "upload_time": "2019-07-14T02:51:25", "upload_time_iso_8601": "2019-07-14T02:51:25.021650Z", "url": "https://files.pythonhosted.org/packages/9c/93/d936654f507e1e716065d92778f4872072ebe57c68b47bb1e1d3ad70bf2f/py_automl-0.1.0-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "67b08c97d269d49a7971fb8c085f3d67", "sha256": "de9a20d67eff1009757523bcb947f2ec09f2812614ba72642872ec31a4acad61"}, "downloads": -1, "filename": "py_automl-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "67b08c97d269d49a7971fb8c085f3d67", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25099, "upload_time": "2019-07-11T05:34:29", "upload_time_iso_8601": "2019-07-11T05:34:29.205760Z", "url": "https://files.pythonhosted.org/packages/57/26/574125b5a5058c69290faa6806a40d4bdc9dab81e39754091858f620099e/py_automl-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "50642389e673050d33d5b900154ed2db", "sha256": "d3769ffd2d6c68f2364cda19c134c082f2d69bd1f69f575fd6e3a613141fc798"}, "downloads": -1, "filename": "py-automl-0.1.0.tar.gz", "has_sig": false, "md5_digest": "50642389e673050d33d5b900154ed2db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17015, "upload_time": "2019-07-11T05:34:31", "upload_time_iso_8601": "2019-07-11T05:34:31.471899Z", "url": "https://files.pythonhosted.org/packages/c0/c3/1465cf7c6145d4685470fc5e53bf81de0973312d54e89f2497a00ace90c4/py-automl-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "8a2289ad40e01dad32d5cb8c0a52f8c4", "sha256": "4d8aae015fce2489e512f81a87080ff3b602826938349407ea52e1f4d4de55ee"}, "downloads": -1, "filename": "py-automl-0.1.1.tar.gz", "has_sig": false, "md5_digest": "8a2289ad40e01dad32d5cb8c0a52f8c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19287, "upload_time": "2019-07-14T02:58:51", "upload_time_iso_8601": "2019-07-14T02:58:51.699024Z", "url": "https://files.pythonhosted.org/packages/42/af/efcf7d723db214905db56080dc86782fc13eed8c1a3066d15d66887489f1/py-automl-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "6d53979e67ac18a1fd4bcb9f7b58788b", "sha256": "4adbb9a8ad0e4e0497c4f57d87ad9ace1d7651a1561226a2d809fa11befc553d"}, "downloads": -1, "filename": "py_automl-0.1.2-py3.7.egg", "has_sig": false, "md5_digest": "6d53979e67ac18a1fd4bcb9f7b58788b", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 70835, "upload_time": "2019-08-19T01:40:40", "upload_time_iso_8601": "2019-08-19T01:40:40.660683Z", "url": "https://files.pythonhosted.org/packages/b1/92/e1e33891215d8091a0d11167a15f2155071d2b5b2a0cb6c8b4410522f400/py_automl-0.1.2-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "d99833beeef7e783f39800297160e8e7", "sha256": "9829d3df398294c514b25b5d32b58246278796122d399fea9020f4366fd64f3f"}, "downloads": -1, "filename": "py-automl-0.1.2.tar.gz", "has_sig": false, "md5_digest": "d99833beeef7e783f39800297160e8e7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21300, "upload_time": "2019-08-10T06:32:44", "upload_time_iso_8601": "2019-08-10T06:32:44.318531Z", "url": "https://files.pythonhosted.org/packages/c1/c3/7a09bdd36d5c388fc09e260e237c8d883f4c20c8fa02e7039be1ff999f11/py-automl-0.1.2.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "546665ecdfcaa3ceb261ae22ea53cc28", "sha256": "6bca11ef4a0d2fed7ddc102edd117f14ff7dd0abc37db5a161e2beaa0705c1f7"}, "downloads": -1, "filename": "py_automl-0.2.0-py3.7.egg", "has_sig": false, "md5_digest": "546665ecdfcaa3ceb261ae22ea53cc28", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 74379, "upload_time": "2019-08-22T01:40:13", "upload_time_iso_8601": "2019-08-22T01:40:13.481831Z", "url": "https://files.pythonhosted.org/packages/aa/30/a1d423e9e4effb118e9d527b5907d701304aaa2bcb1419609fe5ca110804/py_automl-0.2.0-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6d64b726f197f1e365af405c59fb4da", "sha256": "230b6ef94b4bfb9166fe31263e6f2b9b15ffe25482a37dce7640aad4712d6ca7"}, "downloads": -1, "filename": "py-automl-0.2.0.tar.gz", "has_sig": false, "md5_digest": "a6d64b726f197f1e365af405c59fb4da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20637, "upload_time": "2019-08-19T01:40:39", "upload_time_iso_8601": "2019-08-19T01:40:39.037585Z", "url": "https://files.pythonhosted.org/packages/ca/78/34dfd41544f8eb183b09f817a73d05801de374d7297760d35a0394f14372/py-automl-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "8c86cffb91ec9126986ca7c3a3e76be9", "sha256": "ccccfa816e4c1266647d01a565c13cefa6144338842ed54ece45dbda563370b9"}, "downloads": -1, "filename": "py_automl-0.2.1-py3.7.egg", "has_sig": false, "md5_digest": "8c86cffb91ec9126986ca7c3a3e76be9", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 79914, "upload_time": "2019-08-22T04:36:18", "upload_time_iso_8601": "2019-08-22T04:36:18.429207Z", "url": "https://files.pythonhosted.org/packages/d3/08/2f3fb139fde6031b0bb8139e2e01864cdad5795229c63dfe7183a3567955/py_automl-0.2.1-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "9e87b447052ef80061da7522de8cd6fa", "sha256": "24e3df75a943ce1d674827f273d2d29663a2b9996a4b821128ba1e142222d6e7"}, "downloads": -1, "filename": "py-automl-0.2.1.tar.gz", "has_sig": false, "md5_digest": "9e87b447052ef80061da7522de8cd6fa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23023, "upload_time": "2019-08-22T01:40:15", "upload_time_iso_8601": "2019-08-22T01:40:15.786275Z", "url": "https://files.pythonhosted.org/packages/6d/f7/61dd3fa2afe04bb0f49edadb324f6c1daca11bdd38401b952356af52dd0f/py-automl-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "a795ac2c98cbe35ff7918e3d7bf3d481", "sha256": "013c55ea15c8e24f408cdd6632de8384e42d26755f181a525af8c3ca2a0fc889"}, "downloads": -1, "filename": "py-automl-0.2.2.tar.gz", "has_sig": false, "md5_digest": "a795ac2c98cbe35ff7918e3d7bf3d481", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23506, "upload_time": "2019-08-22T04:39:08", "upload_time_iso_8601": "2019-08-22T04:39:08.703705Z", "url": "https://files.pythonhosted.org/packages/14/3d/6efda2d44e5fc7879c36fafe809990008856c6eccd5390046fe5cee65736/py-automl-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "971a5f6da8df102d137d4b78cff8e2b1", "sha256": "9a2ef61b766fd9a0033cd6ac66858038ede6faddea3f8b479403a3863d7c30b4"}, "downloads": -1, "filename": "py-automl-0.2.3.tar.gz", "has_sig": false, "md5_digest": "971a5f6da8df102d137d4b78cff8e2b1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23652, "upload_time": "2019-08-23T06:23:35", "upload_time_iso_8601": "2019-08-23T06:23:35.760284Z", "url": "https://files.pythonhosted.org/packages/73/ab/bf36509ccb479d68a918af18f733437676a71ffe9010cb1d6481a46f363e/py-automl-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "1acd4922bfd435f6f89273c29ee5e999", "sha256": "161908f1d27486b6fadf4a6590b685570ce47e901d7f1b80425b05edd28a2f9c"}, "downloads": -1, "filename": "py-automl-0.2.4.tar.gz", "has_sig": false, "md5_digest": "1acd4922bfd435f6f89273c29ee5e999", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23956, "upload_time": "2019-08-23T07:22:46", "upload_time_iso_8601": "2019-08-23T07:22:46.725981Z", "url": "https://files.pythonhosted.org/packages/1d/64/8f826868844384b68bfddf03bdc875a1a59384091eb4efc7d8c7b0c58fdc/py-automl-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "9aaab03c4cb9df5b80d9670e9e626108", "sha256": "5f238a1842447271da723076932ac449e4991c84b0a88d0d78d04d55398657a0"}, "downloads": -1, "filename": "py-automl-0.2.5.tar.gz", "has_sig": false, "md5_digest": "9aaab03c4cb9df5b80d9670e9e626108", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25069, "upload_time": "2019-08-27T06:36:03", "upload_time_iso_8601": "2019-08-27T06:36:03.599524Z", "url": "https://files.pythonhosted.org/packages/8b/ec/3f5a3395506b69cc23e6c520a91f19678d9af52fd78eb4bb5d99512da12c/py-automl-0.2.5.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "47425cc6e0b021217923de11dc7b8081", "sha256": "dc7be9af3beba3e41d48143d6976a75968b1ee599e8dee2055699edcb85e880c"}, "downloads": -1, "filename": "py-automl-0.3.0.tar.gz", "has_sig": false, "md5_digest": "47425cc6e0b021217923de11dc7b8081", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141530, "upload_time": "2019-08-28T22:07:55", "upload_time_iso_8601": "2019-08-28T22:07:55.447559Z", "url": "https://files.pythonhosted.org/packages/27/c5/b30e199a121ed46ed5da445855391b354afd8c84e773887301661661c382/py-automl-0.3.0.tar.gz", "yanked": false}], "0.3.0.1": [{"comment_text": "", "digests": {"md5": "04f706ea3d6744c1d01cd21351a1ad1b", "sha256": "78cb490073fc59b962fe0b44cd3d11ab5411c8c97a2919d5120a91eab289c686"}, "downloads": -1, "filename": "py_automl-0.3.0.1-py3.6.egg", "has_sig": false, "md5_digest": "04f706ea3d6744c1d01cd21351a1ad1b", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 93369, "upload_time": "2019-08-30T17:24:27", "upload_time_iso_8601": "2019-08-30T17:24:27.658054Z", "url": "https://files.pythonhosted.org/packages/62/9d/a9bf7d70483e6282abeaeef6c6c8d17741fca192950c9de36d4f9d4c86ea/py_automl-0.3.0.1-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d4b654e7f6ac6a53565d34d5f01e199", "sha256": "85313075f787c589bc5d51060bf3892f5ac193abc08b7f2da8f502b34c905a70"}, "downloads": -1, "filename": "py-automl-0.3.0.1.tar.gz", "has_sig": false, "md5_digest": "0d4b654e7f6ac6a53565d34d5f01e199", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141545, "upload_time": "2019-08-28T22:10:53", "upload_time_iso_8601": "2019-08-28T22:10:53.545430Z", "url": "https://files.pythonhosted.org/packages/a1/1c/27fbf857ba30a26ba38b197c8af74d566dcbf5c85c1a5e2c2b6c6900ee53/py-automl-0.3.0.1.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "c903a61de338fcf8ce371bf15bd53dfd", "sha256": "b136db8a367197fbd23f5daa4f5a648ec05c667bc8b3be63f72693e081af1178"}, "downloads": -1, "filename": "py-automl-0.3.1.linux-x86_64.tar.gz", "has_sig": false, "md5_digest": "c903a61de338fcf8ce371bf15bd53dfd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 65746, "upload_time": "2019-08-30T08:03:05", "upload_time_iso_8601": "2019-08-30T08:03:05.129945Z", "url": "https://files.pythonhosted.org/packages/ad/3b/1e7a8ec2c4b037a1f9337ca4bc0d3b2225ea1d716c5344f7b3bbcfe9ca6c/py-automl-0.3.1.linux-x86_64.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "ba21067e68c609cd736624eebee14d8f", "sha256": "ea7a4925db622825b83432e2fdac4260fe3618e1c6bbdf9472c93e2306fda00b"}, "downloads": -1, "filename": "py-automl-0.3.2.tar.gz", "has_sig": false, "md5_digest": "ba21067e68c609cd736624eebee14d8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141813, "upload_time": "2019-08-30T17:51:49", "upload_time_iso_8601": "2019-08-30T17:51:49.542265Z", "url": "https://files.pythonhosted.org/packages/e6/28/727e63e38abe4ad45a35b8d72a9fafeb33d00db8849572f3b0ddd2320828/py-automl-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "7b5e12fe6db9f5347edaff3430e0333e", "sha256": "195786cf9d37ddaae11c9d3e4aaaa17e4c8ebafd233f3d2b79410d4d289e8a84"}, "downloads": -1, "filename": "py-automl-0.3.3.tar.gz", "has_sig": false, "md5_digest": "7b5e12fe6db9f5347edaff3430e0333e", "packagetype": "sdist", "python_version": "source", "requires_python": "> 3.5", "size": 30477, "upload_time": "2019-09-01T09:43:44", "upload_time_iso_8601": "2019-09-01T09:43:44.099295Z", "url": "https://files.pythonhosted.org/packages/6c/ef/ea769c0fadce16e4fab28e06ebdc0ee39bbe4a0d09e1aa27cb13e82fae5f/py-automl-0.3.3.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "77e55ef49df2744c1edad55dc1d0d972", "sha256": "b72a8b2a3efe72aca8d65ba3ef746e29240559bb7d382fc0e0bd592f385ebfd5"}, "downloads": -1, "filename": "py-automl-0.4.0.tar.gz", "has_sig": false, "md5_digest": "77e55ef49df2744c1edad55dc1d0d972", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.5", "size": 56098, "upload_time": "2019-09-18T21:37:26", "upload_time_iso_8601": "2019-09-18T21:37:26.754186Z", "url": "https://files.pythonhosted.org/packages/5f/b3/e4319c38f79f1637da6a366493257f09bb43de7d77f76d9a7b695afcdc91/py-automl-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "471316f178afbe2381555f9c5c50c642", "sha256": "5754be29b7a7dcde6a7b7666b9678af8036df0e95220f871b880e6ab6dc7ee89"}, "downloads": -1, "filename": "py-automl-0.4.1.tar.gz", "has_sig": false, "md5_digest": "471316f178afbe2381555f9c5c50c642", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.5", "size": 50909, "upload_time": "2019-09-18T22:03:55", "upload_time_iso_8601": "2019-09-18T22:03:55.923976Z", "url": "https://files.pythonhosted.org/packages/ad/ee/fc5f0e5220c537f2acc227dbe1bc01bb85ec6d173a67251b83d79c172d5f/py-automl-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "465fb557ca33ae314bc59ff88107f3da", "sha256": "8eebfb81bcc7060a148e24f16f7f32696fee0be38f8b32fe372d771a8efd67c5"}, "downloads": -1, "filename": "py-automl-0.4.2.tar.gz", "has_sig": false, "md5_digest": "465fb557ca33ae314bc59ff88107f3da", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.5", "size": 55318, "upload_time": "2019-09-18T22:27:15", "upload_time_iso_8601": "2019-09-18T22:27:15.350963Z", "url": "https://files.pythonhosted.org/packages/a1/96/160707d32a4fda3aa23dde1eecfece9832a84972893a387ed03720006076/py-automl-0.4.2.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "16e30589431c5a9b88f329fe3824581a", "sha256": "835d44f4830ea7cd79cffcaf35e57d735e0980d1565e39ea6fb8569e9b149558"}, "downloads": -1, "filename": "py-automl-0.5.0.tar.gz", "has_sig": false, "md5_digest": "16e30589431c5a9b88f329fe3824581a", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.5", "size": 68114, "upload_time": "2019-10-06T21:13:20", "upload_time_iso_8601": "2019-10-06T21:13:20.724184Z", "url": "https://files.pythonhosted.org/packages/3a/46/9eeb9c26e0c6febe730d4df6f85c15a2e4e2914792044b3630f6082378bd/py-automl-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "79034afa2965a56bdc015ba0c1d4a83a", "sha256": "d6cad121fbb064150bcd94ad3c0433f7aec8050fc2879daebeccb8facc2cbcdc"}, "downloads": -1, "filename": "py-automl-0.6.0.tar.gz", "has_sig": false, "md5_digest": "79034afa2965a56bdc015ba0c1d4a83a", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.5", "size": 102208, "upload_time": "2019-10-27T07:18:18", "upload_time_iso_8601": "2019-10-27T07:18:18.119674Z", "url": "https://files.pythonhosted.org/packages/3d/ea/df4008c6eeeaaba11b65775634265027ea37ffa7bb7e480da64d2b712447/py-automl-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "07810b827a9daed6614ffbdd7fcba6a5", "sha256": "8a9b8820b9b1dbec579258292a554023b82b32b46e51e2207c8d6a2d8e062e7c"}, "downloads": -1, "filename": "py-automl-0.6.1.tar.gz", "has_sig": false, "md5_digest": "07810b827a9daed6614ffbdd7fcba6a5", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 108108, "upload_time": "2019-11-02T07:37:10", "upload_time_iso_8601": "2019-11-02T07:37:10.858963Z", "url": "https://files.pythonhosted.org/packages/aa/62/8783784b1c0d05c61fa4da0abc614f0e4416aa819ba9f1f3d09218d67a15/py-automl-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "c04da288d2592df5f1cf47b957627c3f", "sha256": "3aa915c202705aa6413f935fe22d0fd6d51bc340592a9f28fce88943e79af8fe"}, "downloads": -1, "filename": "py-automl-0.6.2.tar.gz", "has_sig": false, "md5_digest": "c04da288d2592df5f1cf47b957627c3f", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 117975, "upload_time": "2019-11-09T06:41:03", "upload_time_iso_8601": "2019-11-09T06:41:03.217232Z", "url": "https://files.pythonhosted.org/packages/f6/23/ea6ace3f3bc4f104c0196edc6576f9568c795c52599ea4256da5c068be53/py-automl-0.6.2.tar.gz", "yanked": false}], "0.6.3": [{"comment_text": "", "digests": {"md5": "7d325b27aa6a5e66eea06979eedc935c", "sha256": "452e81aa8f03f3c65364eb8287caf922c2128aeb1f58bf6cbdf9af0d8cc1a21f"}, "downloads": -1, "filename": "py-automl-0.6.3.tar.gz", "has_sig": false, "md5_digest": "7d325b27aa6a5e66eea06979eedc935c", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 112666, "upload_time": "2019-11-16T05:07:22", "upload_time_iso_8601": "2019-11-16T05:07:22.149705Z", "url": "https://files.pythonhosted.org/packages/b5/1b/248ba0bc0457d0ed0535b01738b1cab0a027502f02fc7128fbead909feef/py-automl-0.6.3.tar.gz", "yanked": false}], "0.6.4": [{"comment_text": "", "digests": {"md5": "b2e765fda50fee269f839d857242194f", "sha256": "4d6c889a13def2123ea80f30e354291e47819930f933ed535ec5522888c1b254"}, "downloads": -1, "filename": "py-automl-0.6.4.tar.gz", "has_sig": false, "md5_digest": "b2e765fda50fee269f839d857242194f", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 117042, "upload_time": "2019-11-22T02:29:27", "upload_time_iso_8601": "2019-11-22T02:29:27.652215Z", "url": "https://files.pythonhosted.org/packages/30/09/7b24c12fbb035666641c4b0eb40547054aa1b31cd5837c36f936e63a4a37/py-automl-0.6.4.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "051c6c4147980b94bf8be655384adf8c", "sha256": "55736475d923f949561093db83eec1685b5f62a387b01aaf14f93b67689bcd98"}, "downloads": -1, "filename": "py-automl-0.7.0.tar.gz", "has_sig": false, "md5_digest": "051c6c4147980b94bf8be655384adf8c", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 117140, "upload_time": "2019-11-29T21:15:26", "upload_time_iso_8601": "2019-11-29T21:15:26.881699Z", "url": "https://files.pythonhosted.org/packages/dc/65/04582a1d6ca1de3dda7ec82bd8565e72472d47628701188db795bad28b63/py-automl-0.7.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "051c6c4147980b94bf8be655384adf8c", "sha256": "55736475d923f949561093db83eec1685b5f62a387b01aaf14f93b67689bcd98"}, "downloads": -1, "filename": "py-automl-0.7.0.tar.gz", "has_sig": false, "md5_digest": "051c6c4147980b94bf8be655384adf8c", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 3.6", "size": 117140, "upload_time": "2019-11-29T21:15:26", "upload_time_iso_8601": "2019-11-29T21:15:26.881699Z", "url": "https://files.pythonhosted.org/packages/dc/65/04582a1d6ca1de3dda7ec82bd8565e72472d47628701188db795bad28b63/py-automl-0.7.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:09:33 2020"}