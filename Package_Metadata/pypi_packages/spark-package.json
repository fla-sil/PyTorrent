{"info": {"author": "Burak Yavuz", "author_email": "feedback@spark-packages.org", "bugtrack_url": null, "classifiers": [], "description": "spark-package Command Line Tool\n===============================\n\nCommand Line Tool for working with `Spark Packages`_\n\n.. _Spark Packages: https://spark-packages.org\n\n**Please upgrade to latest version as spark-packages now supports SSL**\n`pip install --upgrade spark-package`\n\nUsage\n-----\n\nThe `spark-package` command line tool is your helper when developing new `Spark Packages`.\n\nThe tool provides two methods: `init` and `zip`. Use `spark-package -h` to see the list of available\ncommands and options.\n\ninit\n----\n\nInitializes an empty project. Sets up the recommended directory layout and provides templates for\nrequired files. The tool will prompt the user to select a license, but users may skip this process\nby selecting the value for `other license (decide later)`.\n\nA name must be supplied with the flag `-n` or `--name`. The name must match the name of the github\nrepository of the package. The layout for python can be generated with the flag `-p` or `--python`,\ndirectories can be generated for R using `--R` or `-r`, directories and files for scala can \nbe generated with `-s` or `--scala` and java folders can be generated with `-j` or `--java`.\n\nAn output directory for the package can be supplied with `-o` or `--out`. The default for the output\npath is the current working directory.\nExample usage:\n\nGenerate a folder called \"package\" in the current directory setup with all files regarding to scala.\n\n```\nspark-package init -n \"test/package\"\n```\n\nGenerate a folder called \"package\" in $PACKAGE_PATH setup with all files regarding to scala and python.\n\n```\nspark-package init -s -p -n \"test/package\" -o $PACKAGE_PATH\n```\n\nzip\n---\n\nCreates a zip file for distribution on the Spark Packages website. If your package has java or\nscala code, use the `sbt-spark-package` plugin as it is more advanced. If your package is comprised\nof just python code, use this command.\n\nThe package name must be supplied with `-n` or `--name`. In addition, the root directory of the\npackage must be supplied with `-f` or `--folder`. In addition, users must supply the version of the\nrelease they want to distribute with the flag `-v` or `--version`. The output directory of the\nzip file can be configured through `-o` or `--out`. The default path is the current working directory.\n\nExample Usage:\n\nGenerate a zip file for distribution on the Spark Packages website with release version 0.2.1.\n\n```\nspark-package zip -f $PACKAGE_PATH -n \"test/package\" -v \"0.2.1\"\n```\n\nregister\n--------\n\nRegister your package on the Spark Packages website. Requires that you login to the Spark Packages\nwebsite at least once. In addition, a Github Personal Access Token with \"read:org\" permissions must be\nsupplied as a password. The credentials can be supplied through a file using `-c` or `--cred`. The\nformat of the file must be:\n\n```\nuser= $USERNAME\npassword= $TOKEN\n```\n\n*Note: If there are multiple user, passwords, the last ones in the file will be used*\n\nFor more information on Github Personal Access Tokens, please read the `Github documentation`_.\n\n.. _Github documentation: http://help.github.com/articles/creating-an-access-token-for-command-line-use/\n\nThen you will be asked to enter a short description of your package, a long description, and the\nhomepage of your package, which is by default the github repository of the package. The descriptions\ncan be provided through files. Simply provide the relative path to the file once you are prompted.\n\nExample usage:\n```\nspark-package register -c $CREDS_FILE -n \"test/package\"\n# or\nspark-package register -u $GITHUB_USERNAME -p $GITHUB_PASSWORD -n \"test/package\"\n```\n\npublish\n-------\n\nPublishes a new release on the Spark packages website. Like the `register` command, requires credentials (see above).\nRequires either the path to the package with `-f` or the zip archive of the release artifact with `-z`.\n\nExample usage:\n```\nspark-package publish -c $CREDS_FILE -f PACKAGE_PATH -n \"test/package\" -v \"0.2.1\"\n# or\nspark-package publish -c $CREDS_FILE -z $ZIP_FILE -n \"test/package\" -v \"0.2.1\"\n```\n\nContributions\n-------------\nIf you encounter bugs or want to contribute, feel free to submit an issue or pull request.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/databricks/spark-package-cmd-tool", "keywords": null, "license": "Apache-2.0", "maintainer": null, "maintainer_email": null, "name": "spark-package", "package_url": "https://pypi.org/project/spark-package/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/spark-package/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/databricks/spark-package-cmd-tool"}, "release_url": "https://pypi.org/project/spark-package/0.4.1/", "requires_dist": null, "requires_python": null, "summary": "A command line tool for creating Spark Packages and generating release distributions", "version": "0.4.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Command Line Tool for working with <a href=\"https://spark-packages.org\" rel=\"nofollow\">Spark Packages</a></p>\n<p><strong>Please upgrade to latest version as spark-packages now supports SSL</strong>\n<cite>pip install \u2013upgrade spark-package</cite></p>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>The <cite>spark-package</cite> command line tool is your helper when developing new <cite>Spark Packages</cite>.</p>\n<p>The tool provides two methods: <cite>init</cite> and <cite>zip</cite>. Use <cite>spark-package -h</cite> to see the list of available\ncommands and options.</p>\n</div>\n<div id=\"init\">\n<h2>init</h2>\n<p>Initializes an empty project. Sets up the recommended directory layout and provides templates for\nrequired files. The tool will prompt the user to select a license, but users may skip this process\nby selecting the value for <cite>other license (decide later)</cite>.</p>\n<p>A name must be supplied with the flag <cite>-n</cite> or <cite>\u2013name</cite>. The name must match the name of the github\nrepository of the package. The layout for python can be generated with the flag <cite>-p</cite> or <cite>\u2013python</cite>,\ndirectories can be generated for R using <cite>\u2013R</cite> or <cite>-r</cite>, directories and files for scala can\nbe generated with <cite>-s</cite> or <cite>\u2013scala</cite> and java folders can be generated with <cite>-j</cite> or <cite>\u2013java</cite>.</p>\n<p>An output directory for the package can be supplied with <cite>-o</cite> or <cite>\u2013out</cite>. The default for the output\npath is the current working directory.\nExample usage:</p>\n<p>Generate a folder called \u201cpackage\u201d in the current directory setup with all files regarding to scala.</p>\n<p><tt>`\n<span class=\"pre\">spark-package</span> init <span class=\"pre\">-n</span> \"test/package\"\n`</tt></p>\n<p>Generate a folder called \u201cpackage\u201d in $PACKAGE_PATH setup with all files regarding to scala and python.</p>\n<p><tt>`\n<span class=\"pre\">spark-package</span> init <span class=\"pre\">-s</span> <span class=\"pre\">-p</span> <span class=\"pre\">-n</span> \"test/package\" <span class=\"pre\">-o</span> $PACKAGE_PATH\n`</tt></p>\n</div>\n<div id=\"zip\">\n<h2>zip</h2>\n<p>Creates a zip file for distribution on the Spark Packages website. If your package has java or\nscala code, use the <cite>sbt-spark-package</cite> plugin as it is more advanced. If your package is comprised\nof just python code, use this command.</p>\n<p>The package name must be supplied with <cite>-n</cite> or <cite>\u2013name</cite>. In addition, the root directory of the\npackage must be supplied with <cite>-f</cite> or <cite>\u2013folder</cite>. In addition, users must supply the version of the\nrelease they want to distribute with the flag <cite>-v</cite> or <cite>\u2013version</cite>. The output directory of the\nzip file can be configured through <cite>-o</cite> or <cite>\u2013out</cite>. The default path is the current working directory.</p>\n<p>Example Usage:</p>\n<p>Generate a zip file for distribution on the Spark Packages website with release version 0.2.1.</p>\n<p><tt>`\n<span class=\"pre\">spark-package</span> zip <span class=\"pre\">-f</span> $PACKAGE_PATH <span class=\"pre\">-n</span> \"test/package\" <span class=\"pre\">-v</span> \"0.2.1\"\n`</tt></p>\n</div>\n<div id=\"register\">\n<h2>register</h2>\n<p>Register your package on the Spark Packages website. Requires that you login to the Spark Packages\nwebsite at least once. In addition, a Github Personal Access Token with \u201cread:org\u201d permissions must be\nsupplied as a password. The credentials can be supplied through a file using <cite>-c</cite> or <cite>\u2013cred</cite>. The\nformat of the file must be:</p>\n<p><tt>`\nuser= $USERNAME\npassword= $TOKEN\n`</tt></p>\n<p><em>Note: If there are multiple user, passwords, the last ones in the file will be used</em></p>\n<p>For more information on Github Personal Access Tokens, please read the <a href=\"http://help.github.com/articles/creating-an-access-token-for-command-line-use/\" rel=\"nofollow\">Github documentation</a>.</p>\n<p>Then you will be asked to enter a short description of your package, a long description, and the\nhomepage of your package, which is by default the github repository of the package. The descriptions\ncan be provided through files. Simply provide the relative path to the file once you are prompted.</p>\n<p>Example usage:\n<tt>`\n<span class=\"pre\">spark-package</span> register <span class=\"pre\">-c</span> $CREDS_FILE <span class=\"pre\">-n</span> \"test/package\"\n# or\n<span class=\"pre\">spark-package</span> register <span class=\"pre\">-u</span> $GITHUB_USERNAME <span class=\"pre\">-p</span> $GITHUB_PASSWORD <span class=\"pre\">-n</span> \"test/package\"\n`</tt></p>\n</div>\n<div id=\"publish\">\n<h2>publish</h2>\n<p>Publishes a new release on the Spark packages website. Like the <cite>register</cite> command, requires credentials (see above).\nRequires either the path to the package with <cite>-f</cite> or the zip archive of the release artifact with <cite>-z</cite>.</p>\n<p>Example usage:\n<tt>`\n<span class=\"pre\">spark-package</span> publish <span class=\"pre\">-c</span> $CREDS_FILE <span class=\"pre\">-f</span> PACKAGE_PATH <span class=\"pre\">-n</span> \"test/package\" <span class=\"pre\">-v</span> \"0.2.1\"\n# or\n<span class=\"pre\">spark-package</span> publish <span class=\"pre\">-c</span> $CREDS_FILE <span class=\"pre\">-z</span> $ZIP_FILE <span class=\"pre\">-n</span> \"test/package\" <span class=\"pre\">-v</span> \"0.2.1\"\n`</tt></p>\n</div>\n<div id=\"contributions\">\n<h2>Contributions</h2>\n<p>If you encounter bugs or want to contribute, feel free to submit an issue or pull request.</p>\n</div>\n\n          </div>"}, "last_serial": 2137610, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "ffa48bac79631c007b87147e5df13307", "sha256": "3bdde351d6e67ef255161f19a76b3b9e251fd4ae6e8c86b52eb923b7aa09f983"}, "downloads": -1, "filename": "spark_package-0.1-py2.7.egg", "has_sig": false, "md5_digest": "ffa48bac79631c007b87147e5df13307", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 70989, "upload_time": "2015-02-24T07:21:15", "upload_time_iso_8601": "2015-02-24T07:21:15.123292Z", "url": "https://files.pythonhosted.org/packages/3a/07/ff7e30f7f117fe08b23bba298e89fa1864dd2c43c231502749e153430b7d/spark_package-0.1-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "c2b497f801ff378ddf1617d61bfa84da", "sha256": "4e69106a4e9ae9f89cb655d237524d974754ab32b5acc2df188691be1e28923a"}, "downloads": -1, "filename": "spark-package-0.1.tar.gz", "has_sig": false, "md5_digest": "c2b497f801ff378ddf1617d61bfa84da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49620, "upload_time": "2015-02-24T07:21:10", "upload_time_iso_8601": "2015-02-24T07:21:10.834416Z", "url": "https://files.pythonhosted.org/packages/80/10/1e4b8edc4ee1cb0289e992e328470f7395c0546554af6c6230edc07ca6db/spark-package-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "43ffff80d5b055dcf5dee2de2236ee22", "sha256": "669bfbc1f0e6f29dedeff9908091df1d8a63b7024fd14f7a21f4f92104c6cf67"}, "downloads": -1, "filename": "spark_package-0.2-py2.7.egg", "has_sig": false, "md5_digest": "43ffff80d5b055dcf5dee2de2236ee22", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 71423, "upload_time": "2015-02-28T21:31:08", "upload_time_iso_8601": "2015-02-28T21:31:08.579883Z", "url": "https://files.pythonhosted.org/packages/40/7c/c81f592d27349d156e34eac408c9e28e0828867be8e02c4c8143d56fc99e/spark_package-0.2-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "b447a84aa8c7c741568b406e40e3161f", "sha256": "de2606f52af6d9d104daed82bee233115eca31c5bc457b2d22a95993d09b2d30"}, "downloads": -1, "filename": "spark-package-0.2.tar.gz", "has_sig": false, "md5_digest": "b447a84aa8c7c741568b406e40e3161f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49893, "upload_time": "2015-02-28T21:31:05", "upload_time_iso_8601": "2015-02-28T21:31:05.368319Z", "url": "https://files.pythonhosted.org/packages/07/5d/bc93dbd16f4d367704a13cde02f458557b9debd242f8c46ec35df0a10353/spark-package-0.2.tar.gz", "yanked": false}], "0.2.1": [], "0.2.3": [{"comment_text": "", "digests": {"md5": "463743d1acb9217c3396871525068d9c", "sha256": "1d9e844e79c9b1ce42fe0fc4862b0454b6f0b0c91226403e8ac0756ba27eaa99"}, "downloads": -1, "filename": "spark_package-0.2.3-py2.7.egg", "has_sig": false, "md5_digest": "463743d1acb9217c3396871525068d9c", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 71097, "upload_time": "2015-03-02T19:12:08", "upload_time_iso_8601": "2015-03-02T19:12:08.491602Z", "url": "https://files.pythonhosted.org/packages/fd/ce/85e0ce8593bc293843c66875217acb768ab1287eed56c908494de3c16b9f/spark_package-0.2.3-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef4f9d5ce8cbf471715a42c4867a65d1", "sha256": "1b6eeef5a8fdb1904ea32842bfcdb96d5f7ff82fc56fc8400b446154addb3746"}, "downloads": -1, "filename": "spark-package-0.2.3.tar.gz", "has_sig": false, "md5_digest": "ef4f9d5ce8cbf471715a42c4867a65d1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49833, "upload_time": "2015-03-02T19:12:05", "upload_time_iso_8601": "2015-03-02T19:12:05.338555Z", "url": "https://files.pythonhosted.org/packages/3c/fa/f2ec587123e819e437742c1737ad4722d2f37638ce68795a5dcd68df8116/spark-package-0.2.3.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "852634a4da00a87219239ed87b0352f2", "sha256": "6ab2cb9099557122aad7382c5a6ca9441c875516b14f1db687fafda730c3f61b"}, "downloads": -1, "filename": "spark_package-0.3.0-py2.7.egg", "has_sig": false, "md5_digest": "852634a4da00a87219239ed87b0352f2", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 76519, "upload_time": "2015-03-17T22:00:02", "upload_time_iso_8601": "2015-03-17T22:00:02.262526Z", "url": "https://files.pythonhosted.org/packages/2d/e6/37dcadfe469df2365721f0967e4a5c37fa0934c6f4abad6a8d063a0d73d1/spark_package-0.3.0-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "4aa56f33595ca7368eacb32adf04a48b", "sha256": "bda8231d52324337fed91abf581c2f1804dbf803996a09ad8e0de0a23824ed48"}, "downloads": -1, "filename": "spark-package-0.3.0.tar.gz", "has_sig": false, "md5_digest": "4aa56f33595ca7368eacb32adf04a48b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52816, "upload_time": "2015-03-17T21:59:58", "upload_time_iso_8601": "2015-03-17T21:59:58.565298Z", "url": "https://files.pythonhosted.org/packages/f4/24/cd2b951f1089cbd03142fc08294b5253cd50c8ebc0be6289f98bd3912dad/spark-package-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "93407655f3793ab42848d426cfa8829b", "sha256": "838fb7a912a9e4c890180b85154966fb79489ba14b7fc4c2081d0ce656dc9231"}, "downloads": -1, "filename": "spark-package-0.3.1.tar.gz", "has_sig": false, "md5_digest": "93407655f3793ab42848d426cfa8829b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52784, "upload_time": "2015-06-24T00:23:32", "upload_time_iso_8601": "2015-06-24T00:23:32.587416Z", "url": "https://files.pythonhosted.org/packages/20/ca/39234f89097df349d0408b38ad9ecfbf0b97ca5dcd20a75ccd1969f82f97/spark-package-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "acd56574e13618d2f6f4350c2ed28709", "sha256": "1afbce8463273a261ac0ad64c11cf62c0675c7557c4a4b58063bdda6972e5dfc"}, "downloads": -1, "filename": "spark-package-0.3.2.tar.gz", "has_sig": false, "md5_digest": "acd56574e13618d2f6f4350c2ed28709", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53765, "upload_time": "2015-08-24T05:17:31", "upload_time_iso_8601": "2015-08-24T05:17:31.671257Z", "url": "https://files.pythonhosted.org/packages/98/14/2fbc55cce98d6e398a4a0c0f26725a2d5d5c954afaf6ae40df42786c7227/spark-package-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "7969cf64af8e11276cb5684d9608ec9b", "sha256": "0fe1b182eb036785a94a501e95ff5b86b11172e5ab4968e52a796087f1e29181"}, "downloads": -1, "filename": "spark-package-0.3.3.tar.gz", "has_sig": false, "md5_digest": "7969cf64af8e11276cb5684d9608ec9b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53808, "upload_time": "2015-08-24T05:24:45", "upload_time_iso_8601": "2015-08-24T05:24:45.208278Z", "url": "https://files.pythonhosted.org/packages/f2/45/3e6548c9fbe40275d4821704ed09d7e2106c88fa0815fa74307ecc52f0a4/spark-package-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "304b71804d7e438f134cf8aa2974c076", "sha256": "624cd8551eca9c5b690fc6ab838534ebd576c27b0ac7cfa3291051f451372df2"}, "downloads": -1, "filename": "spark-package-0.3.4.tar.gz", "has_sig": false, "md5_digest": "304b71804d7e438f134cf8aa2974c076", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53899, "upload_time": "2015-08-25T18:54:08", "upload_time_iso_8601": "2015-08-25T18:54:08.655235Z", "url": "https://files.pythonhosted.org/packages/ee/d4/857effa462f50b8d58194ef8ecdaa7fa49372b36deac528389ec75aa5776/spark-package-0.3.4.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "720036dfaabbe0d95c26ebc46e622a74", "sha256": "ed87f7e58a72e7dc3b3af8bd502a1d16844703bba80d7cd9d29319c393582825"}, "downloads": -1, "filename": "spark-package-0.4.0.tar.gz", "has_sig": false, "md5_digest": "720036dfaabbe0d95c26ebc46e622a74", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 53896, "upload_time": "2015-09-30T20:19:00", "upload_time_iso_8601": "2015-09-30T20:19:00.768247Z", "url": "https://files.pythonhosted.org/packages/9b/cd/5ddfd7405a01bbdaf49a318b8a4ccd013348e10282cacc7b737b09f19e5f/spark-package-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "6671b4f8e183b18859627f680c96ad1f", "sha256": "e5b4c4805203da458b588ba64092ca275c9c14acc845422bfe24baea395cc31f"}, "downloads": -1, "filename": "spark-package-0.4.1.tar.gz", "has_sig": false, "md5_digest": "6671b4f8e183b18859627f680c96ad1f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54007, "upload_time": "2016-05-27T22:46:00", "upload_time_iso_8601": "2016-05-27T22:46:00.935942Z", "url": "https://files.pythonhosted.org/packages/86/b3/f644eb00e0bae3e2059c234ee7c3c4539dfedd93c9abede4bd17e7ace5b3/spark-package-0.4.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6671b4f8e183b18859627f680c96ad1f", "sha256": "e5b4c4805203da458b588ba64092ca275c9c14acc845422bfe24baea395cc31f"}, "downloads": -1, "filename": "spark-package-0.4.1.tar.gz", "has_sig": false, "md5_digest": "6671b4f8e183b18859627f680c96ad1f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54007, "upload_time": "2016-05-27T22:46:00", "upload_time_iso_8601": "2016-05-27T22:46:00.935942Z", "url": "https://files.pythonhosted.org/packages/86/b3/f644eb00e0bae3e2059c234ee7c3c4539dfedd93c9abede4bd17e7ace5b3/spark-package-0.4.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:54 2020"}