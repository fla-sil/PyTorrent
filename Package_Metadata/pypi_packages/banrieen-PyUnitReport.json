{"info": {"author": "Ordanis Sanchez Suero, Leo Lee, banrieen", "author_email": "ban.rieen@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6"], "description": "# PyUnitReport\n\nbanrieen_PyUnitReport modified from PyUnitReport is a unittest test runner that save test results in Html files, for human readable presentation of results.\n\n## Installation\n\n```bash\n$ pip install banrieen_PyUnitReport\n```\n\n## Usage\n\n### testcase\n\n```python\nfrom pyunitreport import HTMLTestRunner\nimport unittest\n\nclass TestStringMethods(unittest.TestCase):\n    \"\"\" Example test for HtmlRunner. \"\"\"\n\n    def test_upper(self):\n        self.assertEqual('foo'.upper(), 'FOO')\n\n    def test_isupper(self):\n        self.assertTrue('FOO'.isupper())\n        self.assertFalse('Foo'.isupper())\n\n    def test_split(self):\n        s = 'hello world'\n        self.assertEqual(s.split(), ['hello', 'world'])\n        # check that s.split fails when the separator is not a string\n        with self.assertRaises(TypeError):\n            s.split(2)\n\n    def test_error(self):\n        \"\"\" This test should be marked as error one. \"\"\"\n        raise ValueError\n\n    def test_fail(self):\n        \"\"\" This test should fail. \"\"\"\n        self.assertEqual(1, 2)\n\n    @unittest.skip(\"This is a skipped test.\")\n    def test_skip(self):\n        \"\"\" This test should be skipped. \"\"\"\n        pass\n\nif __name__ == '__main__':\n    unittest.main(testRunner=HTMLTestRunner(output='example_dir'))\n```\n\nIn most cases, you can use `PyUnitReport` with `unittest.main`, just pass it with the `testRunner` keyword.\n\nFor `HTMLTestRunner`, the only parameter you must pass in is `output`, which specifies the directory of your generated report. Also, if you want to specify the report name, you can use the `report_name` parameter, otherwise the report name will be the datetime you run test. And if you want to run testcases in `failfast` mode, you can pass in a `failfast` parameter and assign it to be True.\n\nHere is another way to run the testcases.\n\n```python\nfrom pyunitreport import HTMLTestRunner\n\nkwargs = {\n    \"output\": output_folder_name,\n    \"report_name\": report_name,\n    \"failfast\": True\n}\nresult = HTMLTestRunner(**kwargs).run(task_suite)\n```\n\n### testsuite\n\nFor those who have `test suites` it works too, just create a runner instance and call the run method with your suite.\n\nHere is an example:\n\n```python\nfrom unittest import TestLoader, TestSuite\nfrom pyunitreport import HTMLTestRunner\nimport ExampleTest\nimport Example2Test\n\nexample_tests = TestLoader().loadTestsFromTestCase(ExampleTests)\nexample2_tests = TestLoader().loadTestsFromTestCase(Example2Test)\n\nsuite = TestSuite([example_tests, example2_tests])\nkwargs = {\n    \"output\": output_folder_name,\n    \"report_name\": report_name,\n    \"failfast\": True\n}\nrunner = HTMLTestRunner(**kwargs)\nrunner.run(suite)\n```\n\n## Output\n\n### Console output\n\nThis is an example of what you got in the console.\n\n```text\n$ python examples/testcase.py\n\nRunning tests...\n----------------------------------------------------------------------\n This test should be marked as error one. ... ERROR (0.000575)s\n This test should fail. ... FAIL (0.000564)s\n test_isupper (__main__.TestStringMethods) ... OK (0.000149)s\n This test should be skipped. ... SKIP (0.000067)s\n test_split (__main__.TestStringMethods) ... OK (0.000167)s\n test_upper (__main__.TestStringMethods) ... OK (0.000134)s\n\n======================================================================\nERROR [0.000575s]: This test should be marked as error one.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"examples/testcase.py\", line 23, in test_error\n    raise ValueError\nValueError\n\n======================================================================\nFAIL [0.000564s]: This test should fail.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"examples/testcase.py\", line 27, in test_fail\n    self.assertEqual(1, 2)\nAssertionError: 1 != 2\n\n----------------------------------------------------------------------\nRan 6 tests in 0.002s\n\nFAILED\n (Failures=1, Errors=1, Skipped=1)\n\nGenerating HTML reports...\nTemplate is not specified, load default template instead.\nReports generated: /Users/Leo/MyProjects/ApiTestEngine/src/pyunitreport/reports/example_dir/2017-07-26-23-33-49.html\n```\n\n### Html Output\n\n![html output](resources/html_output.gif)\n\n![html output](resources/html_output.png)\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/banrieen/PyUnitReport.git", "keywords": "HtmlTestRunner TestRunner pyUnit Html Reports", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "banrieen-PyUnitReport", "package_url": "https://pypi.org/project/banrieen-PyUnitReport/", "platform": "", "project_url": "https://pypi.org/project/banrieen-PyUnitReport/", "project_urls": {"Homepage": "https://github.com/banrieen/PyUnitReport.git"}, "release_url": "https://pypi.org/project/banrieen-PyUnitReport/0.1.4/", "requires_dist": ["jinja2"], "requires_python": "", "summary": "A unit test runner for Python, and generate HTML reports.", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            # PyUnitReport<br><br>banrieen_PyUnitReport modified from PyUnitReport is a unittest test runner that save test results in Html files, for human readable presentation of results.<br><br>## Installation<br><br>```bash<br>$ pip install banrieen_PyUnitReport<br>```<br><br>## Usage<br><br>### testcase<br><br>```python<br>from pyunitreport import HTMLTestRunner<br>import unittest<br><br>class TestStringMethods(unittest.TestCase):<br>    \"\"\" Example test for HtmlRunner. \"\"\"<br><br>    def test_upper(self):<br>        self.assertEqual('foo'.upper(), 'FOO')<br><br>    def test_isupper(self):<br>        self.assertTrue('FOO'.isupper())<br>        self.assertFalse('Foo'.isupper())<br><br>    def test_split(self):<br>        s = 'hello world'<br>        self.assertEqual(s.split(), ['hello', 'world'])<br>        # check that s.split fails when the separator is not a string<br>        with self.assertRaises(TypeError):<br>            s.split(2)<br><br>    def test_error(self):<br>        \"\"\" This test should be marked as error one. \"\"\"<br>        raise ValueError<br><br>    def test_fail(self):<br>        \"\"\" This test should fail. \"\"\"<br>        self.assertEqual(1, 2)<br><br>    @unittest.skip(\"This is a skipped test.\")<br>    def test_skip(self):<br>        \"\"\" This test should be skipped. \"\"\"<br>        pass<br><br>if __name__ == '__main__':<br>    unittest.main(testRunner=HTMLTestRunner(output='example_dir'))<br>```<br><br>In most cases, you can use `PyUnitReport` with `unittest.main`, just pass it with the `testRunner` keyword.<br><br>For `HTMLTestRunner`, the only parameter you must pass in is `output`, which specifies the directory of your generated report. Also, if you want to specify the report name, you can use the `report_name` parameter, otherwise the report name will be the datetime you run test. And if you want to run testcases in `failfast` mode, you can pass in a `failfast` parameter and assign it to be True.<br><br>Here is another way to run the testcases.<br><br>```python<br>from pyunitreport import HTMLTestRunner<br><br>kwargs = {<br>    \"output\": output_folder_name,<br>    \"report_name\": report_name,<br>    \"failfast\": True<br>}<br>result = HTMLTestRunner(**kwargs).run(task_suite)<br>```<br><br>### testsuite<br><br>For those who have `test suites` it works too, just create a runner instance and call the run method with your suite.<br><br>Here is an example:<br><br>```python<br>from unittest import TestLoader, TestSuite<br>from pyunitreport import HTMLTestRunner<br>import ExampleTest<br>import Example2Test<br><br>example_tests = TestLoader().loadTestsFromTestCase(ExampleTests)<br>example2_tests = TestLoader().loadTestsFromTestCase(Example2Test)<br><br>suite = TestSuite([example_tests, example2_tests])<br>kwargs = {<br>    \"output\": output_folder_name,<br>    \"report_name\": report_name,<br>    \"failfast\": True<br>}<br>runner = HTMLTestRunner(**kwargs)<br>runner.run(suite)<br>```<br><br>## Output<br><br>### Console output<br><br>This is an example of what you got in the console.<br><br>```text<br>$ python examples/testcase.py<br><br>Running tests...<br>----------------------------------------------------------------------<br> This test should be marked as error one. ... ERROR (0.000575)s<br> This test should fail. ... FAIL (0.000564)s<br> test_isupper (__main__.TestStringMethods) ... OK (0.000149)s<br> This test should be skipped. ... SKIP (0.000067)s<br> test_split (__main__.TestStringMethods) ... OK (0.000167)s<br> test_upper (__main__.TestStringMethods) ... OK (0.000134)s<br><br>======================================================================<br>ERROR [0.000575s]: This test should be marked as error one.<br>----------------------------------------------------------------------<br>Traceback (most recent call last):<br>  File \"examples/testcase.py\", line 23, in test_error<br>    raise ValueError<br>ValueError<br><br>======================================================================<br>FAIL [0.000564s]: This test should fail.<br>----------------------------------------------------------------------<br>Traceback (most recent call last):<br>  File \"examples/testcase.py\", line 27, in test_fail<br>    self.assertEqual(1, 2)<br>AssertionError: 1 != 2<br><br>----------------------------------------------------------------------<br>Ran 6 tests in 0.002s<br><br>FAILED<br> (Failures=1, Errors=1, Skipped=1)<br><br>Generating HTML reports...<br>Template is not specified, load default template instead.<br>Reports generated: /Users/Leo/MyProjects/ApiTestEngine/src/pyunitreport/reports/example_dir/2017-07-26-23-33-49.html<br>```<br><br>### Html Output<br><br>![html output](resources/html_output.gif)<br><br>![html output](resources/html_output.png)<br><br><br>\n          </div>"}, "last_serial": 3751118, "releases": {"0.1.4": [{"comment_text": "", "digests": {"md5": "119dcc9ce514896a12ab291cf47ebeb6", "sha256": "59a4b0823d79fcd1949770352873255c72def95a6f584038f36b3110bb4c7ffe"}, "downloads": -1, "filename": "banrieen_PyUnitReport-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "119dcc9ce514896a12ab291cf47ebeb6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13282, "upload_time": "2018-04-10T08:08:14", "upload_time_iso_8601": "2018-04-10T08:08:14.174264Z", "url": "https://files.pythonhosted.org/packages/1d/ae/002494878496f18feca009f88f3f370c61042d1bf81458eee028e43f20a2/banrieen_PyUnitReport-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e3c9bd796668f866e1ff9f725dcafc9b", "sha256": "bda7494ac2d25a0f5b0f11087f16dcf82f9c104a8de314f1712202c917e05aa2"}, "downloads": -1, "filename": "banrieen_PyUnitReport-0.1.4.tar.gz", "has_sig": false, "md5_digest": "e3c9bd796668f866e1ff9f725dcafc9b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11153, "upload_time": "2018-04-10T08:08:15", "upload_time_iso_8601": "2018-04-10T08:08:15.487587Z", "url": "https://files.pythonhosted.org/packages/50/0a/33534ef14aa95458512cd0906c2a9b22f470c58cce4e7e01db866b206c2d/banrieen_PyUnitReport-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "119dcc9ce514896a12ab291cf47ebeb6", "sha256": "59a4b0823d79fcd1949770352873255c72def95a6f584038f36b3110bb4c7ffe"}, "downloads": -1, "filename": "banrieen_PyUnitReport-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "119dcc9ce514896a12ab291cf47ebeb6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13282, "upload_time": "2018-04-10T08:08:14", "upload_time_iso_8601": "2018-04-10T08:08:14.174264Z", "url": "https://files.pythonhosted.org/packages/1d/ae/002494878496f18feca009f88f3f370c61042d1bf81458eee028e43f20a2/banrieen_PyUnitReport-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e3c9bd796668f866e1ff9f725dcafc9b", "sha256": "bda7494ac2d25a0f5b0f11087f16dcf82f9c104a8de314f1712202c917e05aa2"}, "downloads": -1, "filename": "banrieen_PyUnitReport-0.1.4.tar.gz", "has_sig": false, "md5_digest": "e3c9bd796668f866e1ff9f725dcafc9b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11153, "upload_time": "2018-04-10T08:08:15", "upload_time_iso_8601": "2018-04-10T08:08:15.487587Z", "url": "https://files.pythonhosted.org/packages/50/0a/33534ef14aa95458512cd0906c2a9b22f470c58cce4e7e01db866b206c2d/banrieen_PyUnitReport-0.1.4.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:14:54 2020"}