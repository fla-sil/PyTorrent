{"info": {"author": "Christopher Brown", "author_email": "io@henrian.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Topic :: Text Processing :: General"], "description": "twilight\n========\n\nTools for accessing the `Twitter API\nv1.1 <https://dev.twitter.com/docs/api/1.1/overview>`__ with paranoid\ntimeouts and de-pagination.\n\nNode.js\n\n-  ``twitter-curl`` for querying the streaming API (``/sample.json`` and\n   ``/filter.json``).\n-  ``rtcount`` for pulling out the retweets from a stream of JSON\n   tweets, and counting them.\n\nPython\n\n-  ``json2ttv2`` converts directories full of Twitter ``.json`` files\n   into ``.ttv2`` files, bzip2'ing them, and ensuring that the result is\n   within a reasonable size of the source (greater than 2%, but less\n   than 6%) before deleting the original json.\n-  ``twitter-user`` pulls down the ~3,200 (max) tweets that are\n   accessible for a given user (also depends on the ``~/.twitter`` auth\n   file).\n\nCrawling quickstart\n===================\n\nInstall from ``npm``:\n\n::\n\n    npm install -g twilight\n\nOr github (to make sure you're getting the most up-to-date version):\n\n::\n\n    npm install -g git://github.com/chbrown/twilight\n\nAuthenticate\n------------\n\nThis app uses only OAuth 1.0A, which is mandatory. As of June 11, 2013,\n`basic HTTP authentication is\ndisabled <https://dev.twitter.com/docs/faq#17750>`__ in the Twitter\nStreaming API. So get some OAuth credentials together `real\nquick <https://github.com/chbrown/autoauth>`__ and make a csv file that\nlooks like this:\n\n+-----------------+--------------------+-----------------+-------------------------+\n| consumer\\_key   | consumer\\_secret   | access\\_token   | access\\_token\\_secret   |\n+=================+====================+=================+=========================+\n| ziurk0An7...    | VKmTsGrk2JjH...    | 91505165...     | VcLOIzA0mkiCSbU...      |\n+-----------------+--------------------+-----------------+-------------------------+\n| 63Yp9EG4t...    | DhrlIQBMUaoL...    | 91401882...     | XJa4HQKMgqfd7ee...      |\n+-----------------+--------------------+-----------------+-------------------------+\n| ...             | ...                | ...             | ...                     |\n+-----------------+--------------------+-----------------+-------------------------+\n\nThere **must** be a header line with *exactly* the following values:\n\n-  consumer\\_key\n-  consumer\\_secret\n-  access\\_token\n-  access\\_token\\_secret\n\nTab / space seperated is fine, and any other columns will simply be\nignored, e.g., if you want to record the ``screen_name`` of each\naccount. Also, order doesn't matter -- your headers just have to line up\nwith their values.\n\nThe ``twitter-curl`` script expects to find this file at ``~/.twitter``,\nbut you can specify a different path with the ``--accounts`` command\nline argument.\n\nFrom my ``/etc/supervisor/conf.d/*``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n(See http://supervisord.org/ to get that all set up.)\n\n.. code:: bash\n\n    [program:justinnnnnn]\n    user=chbrown\n    command=twitter-curl\n        --filter \"track=loveyabiebs,belieber,bietastrophe\"\n        --file /data/twitter/justin_TIMESTAMP.json\n        --timeout 86400\n        --interval 3600\n        --ttv2\n\n``twitter-curl`` options\n------------------------\n\n-  ``--accounts`` should point to a file with OAuth Twitter account\n   credentials. Currently, the script will simply use a random row from\n   this file.\n-  ``--filter`` can be any ``track=whatever`` or\n   ``locations=-18,14,68,44`` etc. A ``querystring``-parsable string. If\n   no filter is specified, it will use the spritzer at ``/sample.json``\n-  ``--file`` shouldn't require creating any directions, and the\n   TIMESTAMP bit will be replaced by a filesystem-friendly iso\n   representation of whenever the program is started.\n\n.. code:: javascript\n\n    // Specifically:\n    var stamp = new Date().toISOString().replace(/:/g, '-').replace(/\\..+/, '');\n    // stamp == '2013-06-07T15-47-49'\n\n-  ``--timeout`` (seconds) the program will die with error code 1 after\n   this amount of time. Don't specify a timeout if you don't want this.\n-  ``--interval`` (seconds) the amount of time to allow for silence from\n   Twitter before dying. Also exits with code 1. Defaults to 600 (10\n   minutes).\n-  ``--ttv2`` (boolean) output TTV2 normalized flat tweets instead of\n   full JSON.\n\nBecause in most cases of error the script simply dies, this approach\nonly really makes sense if you're putting it behind some process\nmonitor. (By the way, I've tried most of them: monitd, daemontools's\nsvc, god, bluepill, node-forever---and supervisord is by far the best.)\n\nThe script does not abide by any Twitter backoff requirement, but I've\nnever had any trouble with backoff being enforced by Twitter. It's more\nthan curl, though, because it checks that it's receiving data. Often,\nwith ``curl`` and ``PycURL``, my connection would be dropped by Twitter,\nbut no end signal would be sent. My crawler would simply hang, expecting\ndata, but would not try to reconnect.\n\nBut beyond that, without ``--ttv2``, it doesn't provide anything more\nthan ``curl``.\n\nTTV2\n----\n\nTTV2 is the Tweet tab-separated format version 2, the specification is\nbelow. Fields are 1-indexed for easy AWKing (see Markdown source for\n0-indexing).\n\n0.  tweet\\_id\n1.  created\\_at parsed into YYYYMMDDTHHMMSS, implicitly UTC\n2.  text, newlines and tabs converted to spaces, html entities replaced,\n    t.co urls resolved\n3.  lon,lat\n4.  place\\_id\n5.  place\\_str\n6.  in\\_reply\\_to\\_status\\_id\n7.  in\\_reply\\_to\\_screen\\_name\n8.  retweet\\_id id of the original tweet\n9.  retweet\\_count\n10. user.screen\\_name\n11. user.id\n12. user.created\\_at parsed into YYYYMMDDTHHMMSS\n13. user.name\n14. user.description\n15. user.location\n16. user.url\n17. user.statuses\\_count\n18. user.followers\\_count\n19. user.friends\\_count\n20. user.favourites\\_count\n21. user.geo\\_enabled\n22. user.default\\_profile\n23. user.time\\_zone\n24. user.lang\n25. user.utc\\_offset\n\nThis format is not the default, and will be the output only when you use\nthe ``--ttv2`` option.\n\nExamples\n--------\n\nInstall `json <https://github.com/zpoley/json-command>`__ first:\n``npm install json``. It's awesome.\n\n::\n\n    twitter-curl --filter 'track=bootstrap' | json -C text\n    twitter-curl --filter 'track=bootstrap' | json -C user.screen_name text\n    twitter-curl --filter 'track=\u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a' | json -C text\n    twitter-curl --filter 'track=sarcmark,%F0%9F%91%8F' | json -C text\n\nIt supports unicode: \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a is Arabic for \"elections,\" and\n``decodeURIComponent('%F0%9F%91%8F')`` is the `\"CLAPPING HANDS\"\n(U+1F44F) <http://www.fileformat.info/info/unicode/char/1f44f/index.htm>`__\ncharacter.\n\nIf you use a filter with url-escaped characters in supervisord, note\nthat supervisord Python-interpolates strings, so you'll need to escape\nthe percent signs, e.g.:\n\n::\n\n    [program:slowclap]\n    command=twitter-curl --filter \"track=%%F0%%9F%%91%%8F\" --file /tmp/slowclap.json\n\nTTV2 Example\n~~~~~~~~~~~~\n\nInstead of JSON, you can use AWK to look at the TTV2:\n\n::\n\n    twitter-curl --filter 'track=data,science' --ttv2 | awk 'BEGIN{FS=\"\\t\"}{print $4,$3}'\n\nStats\n-----\n\n-  RSS usage per-process is between 20-40MB.\n-  VSZ on a machine running six of these crawlers is 80-90MB.\n\nPython contents vs. Javascript contents\n---------------------------------------\n\n::\n\n    easy_install -U twilight\n\nThe Python and Javascript components are mostly complementary. The\nJavascript offers crawlers, Python provides post-processing.\n\nTesting with Travis CI\n----------------------\n\nThe tested CLI commands now check for OAuth in specific environment\nvariables before reading the given ``--accounts`` file or the default\none (``~/.twitter``).\n\nTo get tests to run on Travis CI, we can use ``travis`` command line\ntool to encrypt a quad of valid Twitter OAuth credentials so that only\nTravis CI can see them.\n\nPut together a file that looks like this (call it ``twilight.env``):\n\n::\n\n    consumer_key=bepLTQD5ftZCjqhXgkuJW\n    consumer_secret=jZ4HEYgNRKwJykbh5ptmcqV7v0o2WODdiMTF1fl6B9X\n    access_token=167246169-e1XTUxZqLnRaEyBF8KwOJtbID26gifMpAjukN5vz\n    access_token_secret=OVm7fJt8oY0C9kBsvych6Duq5pNIUxwagG143HdR\n\nAnd then, from within the root directory of this git repository, run the\nfollowing sequence:\n\n::\n\n    gem install travis\n    travis encrypt -s -a < twilight.env\n\n``.travis.yml`` should now have those variables, but encrypted with\nTravis CI's public key.\n\nLicense\n-------\n\nCopyright \u00a9 2011\u20132013 Christopher Brown. `MIT\nLicensed <https://github.com/chbrown/twilight/blob/master/LICENSE>`__.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/chbrown/twilight", "keywords": "twilight oauth crawling bot", "license": "Copyright (c) 2011-2013 Christopher Brown\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.", "maintainer": null, "maintainer_email": null, "name": "twilight", "package_url": "https://pypi.org/project/twilight/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/twilight/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://github.com/chbrown/twilight"}, "release_url": "https://pypi.org/project/twilight/0.3.10/", "requires_dist": null, "requires_python": null, "summary": "Twitter (crawling) tools.", "version": "0.3.10", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"twilight\">\n<h2>twilight</h2>\n<p>Tools for accessing the <a href=\"https://dev.twitter.com/docs/api/1.1/overview\" rel=\"nofollow\">Twitter API\nv1.1</a> with paranoid\ntimeouts and de-pagination.</p>\n<p>Node.js</p>\n<ul>\n<li><tt><span class=\"pre\">twitter-curl</span></tt> for querying the streaming API (<tt>/sample.json</tt> and\n<tt>/filter.json</tt>).</li>\n<li><tt>rtcount</tt> for pulling out the retweets from a stream of JSON\ntweets, and counting them.</li>\n</ul>\n<p>Python</p>\n<ul>\n<li><tt>json2ttv2</tt> converts directories full of Twitter <tt>.json</tt> files\ninto <tt>.ttv2</tt> files, bzip2\u2019ing them, and ensuring that the result is\nwithin a reasonable size of the source (greater than 2%, but less\nthan 6%) before deleting the original json.</li>\n<li><tt><span class=\"pre\">twitter-user</span></tt> pulls down the ~3,200 (max) tweets that are\naccessible for a given user (also depends on the <tt><span class=\"pre\">~/.twitter</span></tt> auth\nfile).</li>\n</ul>\n</div>\n<div id=\"crawling-quickstart\">\n<h2>Crawling quickstart</h2>\n<p>Install from <tt>npm</tt>:</p>\n<pre>npm install -g twilight\n</pre>\n<p>Or github (to make sure you\u2019re getting the most up-to-date version):</p>\n<pre>npm install -g git://github.com/chbrown/twilight\n</pre>\n<div id=\"authenticate\">\n<h3>Authenticate</h3>\n<p>This app uses only OAuth 1.0A, which is mandatory. As of June 11, 2013,\n<a href=\"https://dev.twitter.com/docs/faq#17750\" rel=\"nofollow\">basic HTTP authentication is\ndisabled</a> in the Twitter\nStreaming API. So get some OAuth credentials together <a href=\"https://github.com/chbrown/autoauth\" rel=\"nofollow\">real\nquick</a> and make a csv file that\nlooks like this:</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>consumer_key</th>\n<th>consumer_secret</th>\n<th>access_token</th>\n<th>access_token_secret</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>ziurk0An7\u2026</td>\n<td>VKmTsGrk2JjH\u2026</td>\n<td>91505165\u2026</td>\n<td>VcLOIzA0mkiCSbU\u2026</td>\n</tr>\n<tr><td>63Yp9EG4t\u2026</td>\n<td>DhrlIQBMUaoL\u2026</td>\n<td>91401882\u2026</td>\n<td>XJa4HQKMgqfd7ee\u2026</td>\n</tr>\n<tr><td>\u2026</td>\n<td>\u2026</td>\n<td>\u2026</td>\n<td>\u2026</td>\n</tr>\n</tbody>\n</table>\n<p>There <strong>must</strong> be a header line with <em>exactly</em> the following values:</p>\n<ul>\n<li>consumer_key</li>\n<li>consumer_secret</li>\n<li>access_token</li>\n<li>access_token_secret</li>\n</ul>\n<p>Tab / space seperated is fine, and any other columns will simply be\nignored, e.g., if you want to record the <tt>screen_name</tt> of each\naccount. Also, order doesn\u2019t matter \u2013 your headers just have to line up\nwith their values.</p>\n<p>The <tt><span class=\"pre\">twitter-curl</span></tt> script expects to find this file at <tt><span class=\"pre\">~/.twitter</span></tt>,\nbut you can specify a different path with the <tt><span class=\"pre\">--accounts</span></tt> command\nline argument.</p>\n<div id=\"from-my-etc-supervisor-conf-d\">\n<h4>From my <tt>/etc/supervisor/conf.d/*</tt></h4>\n<p>(See <a href=\"http://supervisord.org/\" rel=\"nofollow\">http://supervisord.org/</a> to get that all set up.)</p>\n<pre><span class=\"o\">[</span>program:justinnnnnn<span class=\"o\">]</span>\n<span class=\"nv\">user</span><span class=\"o\">=</span>chbrown\n<span class=\"nv\">command</span><span class=\"o\">=</span>twitter-curl\n    --filter <span class=\"s2\">\"track=loveyabiebs,belieber,bietastrophe\"</span>\n    --file /data/twitter/justin_TIMESTAMP.json\n    --timeout <span class=\"m\">86400</span>\n    --interval <span class=\"m\">3600</span>\n    --ttv2\n</pre>\n</div>\n</div>\n<div id=\"twitter-curl-options\">\n<h3><tt><span class=\"pre\">twitter-curl</span></tt> options</h3>\n<ul>\n<li><tt><span class=\"pre\">--accounts</span></tt> should point to a file with OAuth Twitter account\ncredentials. Currently, the script will simply use a random row from\nthis file.</li>\n<li><tt><span class=\"pre\">--filter</span></tt> can be any <tt>track=whatever</tt> or\n<tt><span class=\"pre\">locations=-18,14,68,44</span></tt> etc. A <tt>querystring</tt>-parsable string. If\nno filter is specified, it will use the spritzer at <tt>/sample.json</tt></li>\n<li><tt><span class=\"pre\">--file</span></tt> shouldn\u2019t require creating any directions, and the\nTIMESTAMP bit will be replaced by a filesystem-friendly iso\nrepresentation of whenever the program is started.</li>\n</ul>\n<pre><span class=\"c1\">// Specifically:\n</span><span class=\"kd\">var</span> <span class=\"nx\">stamp</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nb\">Date</span><span class=\"p\">().</span><span class=\"nx\">toISOString</span><span class=\"p\">().</span><span class=\"nx\">replace</span><span class=\"p\">(</span><span class=\"sr\">/:/g</span><span class=\"p\">,</span> <span class=\"s1\">'-'</span><span class=\"p\">).</span><span class=\"nx\">replace</span><span class=\"p\">(</span><span class=\"sr\">/\\..+/</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"p\">);</span>\n<span class=\"c1\">// stamp == '2013-06-07T15-47-49'</span>\n</pre>\n<ul>\n<li><tt><span class=\"pre\">--timeout</span></tt> (seconds) the program will die with error code 1 after\nthis amount of time. Don\u2019t specify a timeout if you don\u2019t want this.</li>\n<li><tt><span class=\"pre\">--interval</span></tt> (seconds) the amount of time to allow for silence from\nTwitter before dying. Also exits with code 1. Defaults to 600 (10\nminutes).</li>\n<li><tt><span class=\"pre\">--ttv2</span></tt> (boolean) output TTV2 normalized flat tweets instead of\nfull JSON.</li>\n</ul>\n<p>Because in most cases of error the script simply dies, this approach\nonly really makes sense if you\u2019re putting it behind some process\nmonitor. (By the way, I\u2019ve tried most of them: monitd, daemontools\u2019s\nsvc, god, bluepill, node-forever\u2014and supervisord is by far the best.)</p>\n<p>The script does not abide by any Twitter backoff requirement, but I\u2019ve\nnever had any trouble with backoff being enforced by Twitter. It\u2019s more\nthan curl, though, because it checks that it\u2019s receiving data. Often,\nwith <tt>curl</tt> and <tt>PycURL</tt>, my connection would be dropped by Twitter,\nbut no end signal would be sent. My crawler would simply hang, expecting\ndata, but would not try to reconnect.</p>\n<p>But beyond that, without <tt><span class=\"pre\">--ttv2</span></tt>, it doesn\u2019t provide anything more\nthan <tt>curl</tt>.</p>\n</div>\n<div id=\"ttv2\">\n<h3>TTV2</h3>\n<p>TTV2 is the Tweet tab-separated format version 2, the specification is\nbelow. Fields are 1-indexed for easy AWKing (see Markdown source for\n0-indexing).</p>\n<ol>\n<li>tweet_id</li>\n<li>created_at parsed into YYYYMMDDTHHMMSS, implicitly UTC</li>\n<li>text, newlines and tabs converted to spaces, html entities replaced,\nt.co urls resolved</li>\n<li>lon,lat</li>\n<li>place_id</li>\n<li>place_str</li>\n<li>in_reply_to_status_id</li>\n<li>in_reply_to_screen_name</li>\n<li>retweet_id id of the original tweet</li>\n<li>retweet_count</li>\n<li>user.screen_name</li>\n<li>user.id</li>\n<li>user.created_at parsed into YYYYMMDDTHHMMSS</li>\n<li>user.name</li>\n<li>user.description</li>\n<li>user.location</li>\n<li>user.url</li>\n<li>user.statuses_count</li>\n<li>user.followers_count</li>\n<li>user.friends_count</li>\n<li>user.favourites_count</li>\n<li>user.geo_enabled</li>\n<li>user.default_profile</li>\n<li>user.time_zone</li>\n<li>user.lang</li>\n<li>user.utc_offset</li>\n</ol>\n<p>This format is not the default, and will be the output only when you use\nthe <tt><span class=\"pre\">--ttv2</span></tt> option.</p>\n</div>\n<div id=\"examples\">\n<h3>Examples</h3>\n<p>Install <a href=\"https://github.com/zpoley/json-command\" rel=\"nofollow\">json</a> first:\n<tt>npm install json</tt>. It\u2019s awesome.</p>\n<pre>twitter-curl --filter 'track=bootstrap' | json -C text\ntwitter-curl --filter 'track=bootstrap' | json -C user.screen_name text\ntwitter-curl --filter 'track=\u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a' | json -C text\ntwitter-curl --filter 'track=sarcmark,%F0%9F%91%8F' | json -C text\n</pre>\n<p>It supports unicode: \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a is Arabic for \u201celections,\u201d and\n<tt><span class=\"pre\">decodeURIComponent('%F0%9F%91%8F')</span></tt> is the <a href=\"http://www.fileformat.info/info/unicode/char/1f44f/index.htm\" rel=\"nofollow\">\u201cCLAPPING HANDS\u201d\n(U+1F44F)</a>\ncharacter.</p>\n<p>If you use a filter with url-escaped characters in supervisord, note\nthat supervisord Python-interpolates strings, so you\u2019ll need to escape\nthe percent signs, e.g.:</p>\n<pre>[program:slowclap]\ncommand=twitter-curl --filter \"track=%%F0%%9F%%91%%8F\" --file /tmp/slowclap.json\n</pre>\n<div id=\"ttv2-example\">\n<h4>TTV2 Example</h4>\n<p>Instead of JSON, you can use AWK to look at the TTV2:</p>\n<pre>twitter-curl --filter 'track=data,science' --ttv2 | awk 'BEGIN{FS=\"\\t\"}{print $4,$3}'\n</pre>\n</div>\n</div>\n<div id=\"stats\">\n<h3>Stats</h3>\n<ul>\n<li>RSS usage per-process is between 20-40MB.</li>\n<li>VSZ on a machine running six of these crawlers is 80-90MB.</li>\n</ul>\n</div>\n<div id=\"python-contents-vs-javascript-contents\">\n<h3>Python contents vs. Javascript contents</h3>\n<pre>easy_install -U twilight\n</pre>\n<p>The Python and Javascript components are mostly complementary. The\nJavascript offers crawlers, Python provides post-processing.</p>\n</div>\n<div id=\"testing-with-travis-ci\">\n<h3>Testing with Travis CI</h3>\n<p>The tested CLI commands now check for OAuth in specific environment\nvariables before reading the given <tt><span class=\"pre\">--accounts</span></tt> file or the default\none (<tt><span class=\"pre\">~/.twitter</span></tt>).</p>\n<p>To get tests to run on Travis CI, we can use <tt>travis</tt> command line\ntool to encrypt a quad of valid Twitter OAuth credentials so that only\nTravis CI can see them.</p>\n<p>Put together a file that looks like this (call it <tt>twilight.env</tt>):</p>\n<pre>consumer_key=bepLTQD5ftZCjqhXgkuJW\nconsumer_secret=jZ4HEYgNRKwJykbh5ptmcqV7v0o2WODdiMTF1fl6B9X\naccess_token=167246169-e1XTUxZqLnRaEyBF8KwOJtbID26gifMpAjukN5vz\naccess_token_secret=OVm7fJt8oY0C9kBsvych6Duq5pNIUxwagG143HdR\n</pre>\n<p>And then, from within the root directory of this git repository, run the\nfollowing sequence:</p>\n<pre>gem install travis\ntravis encrypt -s -a &lt; twilight.env\n</pre>\n<p><tt>.travis.yml</tt> should now have those variables, but encrypted with\nTravis CI\u2019s public key.</p>\n</div>\n<div id=\"license\">\n<h3>License</h3>\n<p>Copyright \u00a9 2011\u20132013 Christopher Brown. <a href=\"https://github.com/chbrown/twilight/blob/master/LICENSE\" rel=\"nofollow\">MIT\nLicensed</a>.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 1081458, "releases": {"0.2.6": [{"comment_text": "", "digests": {"md5": "02db2a788462f152df90750d451049b7", "sha256": "ba1094fd20f84ce9b15b48e94d4cc829409a484670103009b4fa477b47c4a5e5"}, "downloads": -1, "filename": "twilight-0.2.6.tar.gz", "has_sig": false, "md5_digest": "02db2a788462f152df90750d451049b7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9751, "upload_time": "2013-06-14T06:05:11", "upload_time_iso_8601": "2013-06-14T06:05:11.291046Z", "url": "https://files.pythonhosted.org/packages/82/6e/7e244016ad957eea765c5a9ce6d5320510313ca93dc27f78043d7b209105/twilight-0.2.6.tar.gz", "yanked": false}], "0.3.10": [{"comment_text": "", "digests": {"md5": "427246beb946545654a899627b1f7c3e", "sha256": "334738263b19d022233d3ee58caeecdefffc3587fdc25d1247228853c04225ee"}, "downloads": -1, "filename": "twilight-0.3.10.tar.gz", "has_sig": false, "md5_digest": "427246beb946545654a899627b1f7c3e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19839, "upload_time": "2014-05-05T14:59:31", "upload_time_iso_8601": "2014-05-05T14:59:31.133199Z", "url": "https://files.pythonhosted.org/packages/ea/3f/7a338c4ed1594e0e60cefbc9cbd77270e98e5bb7c042e03672e363fafa6f/twilight-0.3.10.tar.gz", "yanked": false}], "0.3.5": [{"comment_text": "", "digests": {"md5": "3f4a776583d3981c710e85d1b5cfe391", "sha256": "fe01e08c54b47a025391f4f52ff7c59284da09b47314504d0943ff314b03f955"}, "downloads": -1, "filename": "twilight-0.3.5.tar.gz", "has_sig": false, "md5_digest": "3f4a776583d3981c710e85d1b5cfe391", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11147, "upload_time": "2013-11-27T04:36:24", "upload_time_iso_8601": "2013-11-27T04:36:24.587175Z", "url": "https://files.pythonhosted.org/packages/5a/45/a337a2ad2f53a11ca510efebf9c563d5426d5dc30a2b7ba2061764182f01/twilight-0.3.5.tar.gz", "yanked": false}], "0.3.6": [{"comment_text": "", "digests": {"md5": "e8a032493aa52de91a3d45a2a5f4092e", "sha256": "08fda772f3baeab3c64844e7cef6363104e3a433b832daa468386804d3abf686"}, "downloads": -1, "filename": "twilight-0.3.6.tar.gz", "has_sig": false, "md5_digest": "e8a032493aa52de91a3d45a2a5f4092e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20867, "upload_time": "2013-11-27T07:32:45", "upload_time_iso_8601": "2013-11-27T07:32:45.430983Z", "url": "https://files.pythonhosted.org/packages/40/ef/f9e3c69d72f2d9247c27bec68c175fca8d5a4bf418f5641abdd91ecc5aa2/twilight-0.3.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "427246beb946545654a899627b1f7c3e", "sha256": "334738263b19d022233d3ee58caeecdefffc3587fdc25d1247228853c04225ee"}, "downloads": -1, "filename": "twilight-0.3.10.tar.gz", "has_sig": false, "md5_digest": "427246beb946545654a899627b1f7c3e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19839, "upload_time": "2014-05-05T14:59:31", "upload_time_iso_8601": "2014-05-05T14:59:31.133199Z", "url": "https://files.pythonhosted.org/packages/ea/3f/7a338c4ed1594e0e60cefbc9cbd77270e98e5bb7c042e03672e363fafa6f/twilight-0.3.10.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:43:59 2020"}