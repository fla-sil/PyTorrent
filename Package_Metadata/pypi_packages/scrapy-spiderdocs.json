{"info": {"author": "Oleksandr Polieno", "author_email": "polyenoom@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "Scrapy spiderdocs command\n=========================\n\nUsage example\n-------------\n\n.. code-block:: bash\n\n    pip install scrapy-spiderdocs\n    scrapy spiderdocs <module.name>\n\nExample project\n---------------\n\nSee ``documented`` project for example.\n\n.. code-block:: python\n\n    # -*- coding: utf-8 -*-\n    import scrapy\n\n\n    class ExampleSpider(scrapy.Spider):\n        \"\"\"Some text.\n        Hi!\n\n        ; Note\n\n        Some note.\n\n        ; Output\n\n        {\n            \"1\": 1\n        }\n        \"\"\"\n\n        name = 'example'\n        allowed_domains = ('example.com',)\n        start_urls = ('http://example.com/',)\n\n        def parse(self, response):\n            yield {\n                'body_length': len(response.body)\n            }\n\n\n    class ExampleSpider2(scrapy.Spider):\n        \"\"\"Some text.\n        Hi!\n\n        ; Info\n\n        Some info.\n        \"\"\"\n\n        name = 'example2'\n        allowed_domains = ('example.com',)\n        start_urls = ('http://example.com/',)\n\n        def parse(self, response):\n            yield {'success': True}\n\n\nSettings:\n\n.. code-block:: python\n\n    SPIDERDOCS_SECTION_PROCESSORS = {\n        'output': lambda name, content: '### {name}\\n\\n```json\\n{content}\\n```'.format(name=name, content=content),\n        'info': lambda name, content: '{content}'.format(content=content)\n    }\n\nExecute the command:\n\n.. code-block:: bash\n\n    scrapy spiderdocs documented.spiders\n\nOutput:\n\n.. code-block::\n\n    # documented.spiders spiders\n\n    ## example2 [documented.spiders.example.ExampleSpider2]\n\n    Some info.\n\n    ## example [documented.spiders.example.ExampleSpider]\n\n    ### Note\n\n    Some note.\n\n    ### Output\n\n    ```json\n    {\n        \"1\": 1\n    }\n    ```\n\nOutput options\n--------------\n\nstdout\n~~~~~~\n\n.. code-block:: bash\n\n    scrapy spiderdocs <module.name> > somefile.md\n\n`-o` (`--output`) option\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n    scrapy spiderdocs <module.name> -o somefile.md\n\nSettings\n~~~~~~~~\n\n.. code-block:: python\n\n    SPIDERDOCS_LOCATIONS = {\n        'module.name': \"somefile.md\"\n    }\n\nThe setting used if no module specified.\n\n.. code-block:: bash\n\n    scrapy spiderdocs\n\nDocstring syntax\n----------------\n\nUse ``;`` to create sections. For example:\n\n.. code-block::\n\n    ; Section 1\n\n    Some text ...\n\n    ; Section 2\n\n    Some text ...\n\nUse ``; end`` to close a section:\n\n.. code-block::\n\n    This text will not be added to the documentation.\n\n    ; Section 1\n\n    Some text ...\n\n    ; end\n\n    And this text also will be skipped.\n\nSection processors\n~~~~~~~~~~~~~~~~~~\n\nAn example:\n\n.. code-block:: python\n\n    SPIDERDOCS_SECTION_PROCESSORS = {\n        'output': lambda name, content: '### {name}\\n\\n```json\\n{content}\\n```'.format(name=name, content=content)\n    }\n\n.. code-block:: bash\n\n    ; Output\n    \n    {\n        \"attr\": \"value\"\n    }\n\nwill be translated into:\n\n.. code-block::\n\n    ### Output\n    \n    ```json\n    {\n        \"attr\": \"value\"\n    }\n    ```\n\nScrapy settings\n---------------\n\n``SPIDERDOCS_LOCATIONS: {<module>: <destination>}``, default: ``{}``.\n\n``SPIDERDOCS_SECTION_PROCESSORS: {<section_name>: <function(name, content) -> str>}``, default: ``{}``.\n\nSee usage examples above.\n\nDevelopment\n-----------\n\n.. code-block:: bash\n\n    git clone git@github.com:nanvel/scrapy-spiderdocs.git\n    cd scrapy-spiderdocs\n    virtualenv .env --no-site-packages -p /usr/local/bin/python3\n    source .env/bin/activate\n    pip install scrapy\n    scrapy crawl example\n    scrapy spiderdocs documented.spiders\n    python -m unittest documented.tests\n\nTODO\n----\n\nunittests (is there is no docstring, ...)\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/nanvel/scrapy-spiderdocs", "keywords": "scrapy,spiders,documentation", "license": "The MIT License", "maintainer": null, "maintainer_email": null, "name": "scrapy-spiderdocs", "package_url": "https://pypi.org/project/scrapy-spiderdocs/", "platform": "OS Independent", "project_url": "https://pypi.org/project/scrapy-spiderdocs/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/nanvel/scrapy-spiderdocs"}, "release_url": "https://pypi.org/project/scrapy-spiderdocs/0.1.2/", "requires_dist": null, "requires_python": null, "summary": "Generate spiders md documentation based on spider docstrings.", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"usage-example\">\n<h2>Usage example</h2>\n<pre>pip install scrapy-spiderdocs\nscrapy spiderdocs &lt;module.name&gt;\n</pre>\n</div>\n<div id=\"example-project\">\n<h2>Example project</h2>\n<p>See <tt>documented</tt> project for example.</p>\n<pre><span class=\"c1\"># -*- coding: utf-8 -*-</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\"Some text.\n    Hi!\n\n    ; Note\n\n    Some note.\n\n    ; Output\n\n    {\n        \"1\": 1\n    }\n    \"\"\"</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'example.com'</span><span class=\"p\">,)</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'http://example.com/'</span><span class=\"p\">,)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'body_length'</span><span class=\"p\">:</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">body</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleSpider2</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\"Some text.\n    Hi!\n\n    ; Info\n\n    Some info.\n    \"\"\"</span>\n\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'example2'</span>\n    <span class=\"n\">allowed_domains</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'example.com'</span><span class=\"p\">,)</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'http://example.com/'</span><span class=\"p\">,)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s1\">'success'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">}</span>\n</pre>\n<p>Settings:</p>\n<pre><span class=\"n\">SPIDERDOCS_SECTION_PROCESSORS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'output'</span><span class=\"p\">:</span> <span class=\"k\">lambda</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"p\">:</span> <span class=\"s1\">'### </span><span class=\"si\">{name}</span><span class=\"se\">\\n\\n</span><span class=\"s1\">```json</span><span class=\"se\">\\n</span><span class=\"si\">{content}</span><span class=\"se\">\\n</span><span class=\"s1\">```'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"o\">=</span><span class=\"n\">content</span><span class=\"p\">),</span>\n    <span class=\"s1\">'info'</span><span class=\"p\">:</span> <span class=\"k\">lambda</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"p\">:</span> <span class=\"s1\">'</span><span class=\"si\">{content}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">content</span><span class=\"o\">=</span><span class=\"n\">content</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</pre>\n<p>Execute the command:</p>\n<pre>scrapy spiderdocs documented.spiders\n</pre>\n<p>Output:</p>\n<pre># documented.spiders spiders\n\n## example2 [documented.spiders.example.ExampleSpider2]\n\nSome info.\n\n## example [documented.spiders.example.ExampleSpider]\n\n### Note\n\nSome note.\n\n### Output\n\n```json\n{\n    \"1\": 1\n}\n```\n</pre>\n</div>\n<div id=\"output-options\">\n<h2>Output options</h2>\n<div id=\"stdout\">\n<h3>stdout</h3>\n<pre>scrapy spiderdocs &lt;module.name&gt; &gt; somefile.md\n</pre>\n</div>\n<div id=\"o-output-option\">\n<h3><cite>-o</cite> (<cite>\u2013output</cite>) option</h3>\n<pre>scrapy spiderdocs &lt;module.name&gt; -o somefile.md\n</pre>\n</div>\n<div id=\"settings\">\n<h3>Settings</h3>\n<pre><span class=\"n\">SPIDERDOCS_LOCATIONS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'module.name'</span><span class=\"p\">:</span> <span class=\"s2\">\"somefile.md\"</span>\n<span class=\"p\">}</span>\n</pre>\n<p>The setting used if no module specified.</p>\n<pre>scrapy spiderdocs\n</pre>\n</div>\n</div>\n<div id=\"docstring-syntax\">\n<h2>Docstring syntax</h2>\n<p>Use <tt>;</tt> to create sections. For example:</p>\n<pre>; Section 1\n\nSome text ...\n\n; Section 2\n\nSome text ...\n</pre>\n<p>Use <tt>; end</tt> to close a section:</p>\n<pre>This text will not be added to the documentation.\n\n; Section 1\n\nSome text ...\n\n; end\n\nAnd this text also will be skipped.\n</pre>\n<div id=\"section-processors\">\n<h3>Section processors</h3>\n<p>An example:</p>\n<pre><span class=\"n\">SPIDERDOCS_SECTION_PROCESSORS</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'output'</span><span class=\"p\">:</span> <span class=\"k\">lambda</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"p\">:</span> <span class=\"s1\">'### </span><span class=\"si\">{name}</span><span class=\"se\">\\n\\n</span><span class=\"s1\">```json</span><span class=\"se\">\\n</span><span class=\"si\">{content}</span><span class=\"se\">\\n</span><span class=\"s1\">```'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">content</span><span class=\"o\">=</span><span class=\"n\">content</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</pre>\n<pre><span class=\"p\">;</span> Output\n\n<span class=\"o\">{</span>\n    <span class=\"s2\">\"attr\"</span>: <span class=\"s2\">\"value\"</span>\n<span class=\"o\">}</span>\n</pre>\n<p>will be translated into:</p>\n<pre>### Output\n\n```json\n{\n    \"attr\": \"value\"\n}\n```\n</pre>\n</div>\n</div>\n<div id=\"scrapy-settings\">\n<h2>Scrapy settings</h2>\n<p><tt>SPIDERDOCS_LOCATIONS: {&lt;module&gt;: &lt;destination&gt;}</tt>, default: <tt>{}</tt>.</p>\n<p><tt>SPIDERDOCS_SECTION_PROCESSORS: {&lt;section_name&gt;: &lt;function(name, content) <span class=\"pre\">-&gt;</span> str&gt;}</tt>, default: <tt>{}</tt>.</p>\n<p>See usage examples above.</p>\n</div>\n<div id=\"development\">\n<h2>Development</h2>\n<pre>git clone git@github.com:nanvel/scrapy-spiderdocs.git\n<span class=\"nb\">cd</span> scrapy-spiderdocs\nvirtualenv .env --no-site-packages -p /usr/local/bin/python3\n<span class=\"nb\">source</span> .env/bin/activate\npip install scrapy\nscrapy crawl example\nscrapy spiderdocs documented.spiders\npython -m unittest documented.tests\n</pre>\n</div>\n<div id=\"todo\">\n<h2>TODO</h2>\n<p>unittests (is there is no docstring, \u2026)</p>\n</div>\n\n          </div>"}, "last_serial": 2566252, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "688c6fdd5ca71beb0eb43ba6cd2f237d", "sha256": "22eef9fd2b75574f1ef93db279099b62e8d1e8220a370993fd5906134487d743"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.0.1.tar.gz", "has_sig": false, "md5_digest": "688c6fdd5ca71beb0eb43ba6cd2f237d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4522, "upload_time": "2017-01-08T08:27:25", "upload_time_iso_8601": "2017-01-08T08:27:25.520961Z", "url": "https://files.pythonhosted.org/packages/32/7a/a1f5168513afe2df067ab74c4ee181429007676d405ba721ac8a642063e6/scrapy-spiderdocs-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "2d8a390a927b722eba0232b6dd968a5a", "sha256": "6d89ccbba08d85bb5810e1b6bc4fbba34fb25ad392043833d004c70ff7ba483c"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.0.2.tar.gz", "has_sig": false, "md5_digest": "2d8a390a927b722eba0232b6dd968a5a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5419, "upload_time": "2017-01-08T08:34:05", "upload_time_iso_8601": "2017-01-08T08:34:05.797508Z", "url": "https://files.pythonhosted.org/packages/25/74/a6e897fa514817e96ea7b9e2ac7c849b368d2e7752db44c697d2fcb5c822/scrapy-spiderdocs-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "24a5bc684c9cfea30e301e6e0b65309d", "sha256": "9f030433cd05e8b3527dec53617a20d646c19d95a98ec6784d5baf8334354d1e"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.0.3.tar.gz", "has_sig": false, "md5_digest": "24a5bc684c9cfea30e301e6e0b65309d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5402, "upload_time": "2017-01-08T08:45:49", "upload_time_iso_8601": "2017-01-08T08:45:49.945294Z", "url": "https://files.pythonhosted.org/packages/18/da/b2f48940aeaa668ae4c31718af705663be945280e6ebf01b4d79586a21bf/scrapy-spiderdocs-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "fe23d5e37e858b8b8ac8d44d0884edc4", "sha256": "22ff30d30c771c94a8e2f7acac05a4a54a8f622cc42e701b307605f301923a83"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.0.4.tar.gz", "has_sig": false, "md5_digest": "fe23d5e37e858b8b8ac8d44d0884edc4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5388, "upload_time": "2017-01-08T08:53:03", "upload_time_iso_8601": "2017-01-08T08:53:03.236532Z", "url": "https://files.pythonhosted.org/packages/df/c8/80ed59ebc4334c8a00f2448b2656fe5ef1323d734be90e553625bbf4bde3/scrapy-spiderdocs-0.0.4.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "b79468d97361b9b889707105cff3177d", "sha256": "75c2dfe3c07a668f34e8624c1961ccbd6a6ad47a8667a513b7142573173cb511"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.1.0.tar.gz", "has_sig": false, "md5_digest": "b79468d97361b9b889707105cff3177d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5565, "upload_time": "2017-01-10T03:41:22", "upload_time_iso_8601": "2017-01-10T03:41:22.287842Z", "url": "https://files.pythonhosted.org/packages/a8/51/c8964a589b65468233217fadab258a833131a23bc914662de995b510d3d3/scrapy-spiderdocs-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "94a59e884d5b4d4199b024ede0d1f628", "sha256": "104d4113bc6c2699f2c15ef75e5aa66bfc225b83ce2297016f2155de19a0427f"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.1.1.tar.gz", "has_sig": false, "md5_digest": "94a59e884d5b4d4199b024ede0d1f628", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5599, "upload_time": "2017-01-10T04:13:46", "upload_time_iso_8601": "2017-01-10T04:13:46.202360Z", "url": "https://files.pythonhosted.org/packages/6a/72/f0890b3e396515c955a07924bde8fb41c49f711900e96224d7ecb6a3e327/scrapy-spiderdocs-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "a17a8544b3dbbb6677ca306331f08331", "sha256": "4c7625f4446e2d09887b9216b618a43fe519cdea8267488dd3ae7e37fb75640c"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.1.2.tar.gz", "has_sig": false, "md5_digest": "a17a8544b3dbbb6677ca306331f08331", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5666, "upload_time": "2017-01-11T02:59:01", "upload_time_iso_8601": "2017-01-11T02:59:01.300965Z", "url": "https://files.pythonhosted.org/packages/f6/f1/a0b49a10cb8877f8ab13e2206ad55e4f9101b19fa8adb07bea855bffbc27/scrapy-spiderdocs-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a17a8544b3dbbb6677ca306331f08331", "sha256": "4c7625f4446e2d09887b9216b618a43fe519cdea8267488dd3ae7e37fb75640c"}, "downloads": -1, "filename": "scrapy-spiderdocs-0.1.2.tar.gz", "has_sig": false, "md5_digest": "a17a8544b3dbbb6677ca306331f08331", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5666, "upload_time": "2017-01-11T02:59:01", "upload_time_iso_8601": "2017-01-11T02:59:01.300965Z", "url": "https://files.pythonhosted.org/packages/f6/f1/a0b49a10cb8877f8ab13e2206ad55e4f9101b19fa8adb07bea855bffbc27/scrapy-spiderdocs-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:40 2020"}