{"info": {"author": "Fatih Cagatay Akyon", "author_email": "", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "[![PyPI version](https://badge.fury.io/py/deeptext.svg)](https://badge.fury.io/py/deeptext)\n[![Conda version](https://anaconda.org/fcakyon/deeptext/badges/version.svg)](https://anaconda.org/fcakyon/deeptext)\n[![CI](https://github.com/fcakyon/deeptext/workflows/CI/badge.svg)](https://github.com/fcakyon/deeptext/actions?query=event%3Apush+branch%3Amaster+is%3Acompleted+workflow%3ACI)\n\n# deeptext\nA cross-platform framework for deep learning based text detection, recoginition and parsing\n\n\n## Getting started\n### Installation\n- Install using conda for Linux, Mac and Windows (preferred):\n```console\nconda install -c fcakyon deeptext\n```\n- Install using pip for Linux and Mac:\n```console\npip install deeptext\n```\nInstall [teserract-ocr](https://tesseract-ocr.github.io/tessdoc/Home.html) for text recognition.\n\n### Basic Usage\n```python\n# import package\nimport deeptext\n\n# set image path and export folder directory\nimage_path = 'idcard.png'\noutput_dir = 'outputs/'\n\n# apply text detection and export detected regions to output directory\ndetection_result = deeptext.detect_text(image_path, output_dir)\n\n# apply text recognition to detected texts\nrecognition_result = deeptext.recognize_text(image_path=detection_result[\"text_crop_paths\"])\n```\n\n### Advanced Usage\nYou can pass filter parameters if you want to scrap texts from image by predefined regions.\n```python\n# import package\nimport deeptext\n\n# set image path and export folder directory\nimage_path = 'idcard.png'\noutput_dir = 'outputs/'\n\n# define regions that you want to scrap, by quad (box) points\nfilter_params = {\"type\": \"box\"\n                 \"boxes\": [[[0.1460 , 0.0395],\n                            [0.8417, 0.0535],\n                            [0.8412, 0.1099],\n                            [0.1455, 0.0959]],\n                           [[0.3467, 0.3398],\n                            [0.5417, 0.3535],\n                            [0.5412, 0.4099],\n                            [0.3455, 0.3959]]],\n                 \"marigin_x\": 0.05,\n                 \"marigin_y\": 0.05,\n                 \"min_intersection_ratio\": 0.9}\n\n# or define regions that you want to scrap, by centroids\nfilter_params = {\"type\":\"centroid\",\n                 \"centers\": [[0.44, 0.49],[0.49, 0.08]],\n                 \"marigin_x\": 0.03,\n                 \"marigin_y\": 0.05}\n\n# apply craft text detection in predefined regions and export detected regions to output directory\ndetection_result = deeptext.detect_text(image_path,\n                                         output_dir,\n                                         detector=\"craft\",\n                                         filter_params=filter_params)\n\n# apply tesseract (eng) text recognition to detected texts\nrecognition_result = deeptext.recognize_text(image_path=detection_result[\"text_crop_paths\"],\n                                             recognizer=\"tesseract-eng\")\n```\n\n## Updates\n**6 April, 2020**: Conda package release\n\n**3 April, 2020**: Tesseract text recoginition and positional text scraping support\n\n**30 March, 2020**: Craft text detector support\n\n## TODO\n- [X] Craft text detection (inference)\n- [ ] Ctpn text detection (inference)\n- [ ] Psenet text detection (inference)\n- [X] Tesseract text recoginition (inference)\n- [ ] Aster text recognition (training and inference)\n- [ ] Moran text recognition (training and inference)\n- [X] Positional text scraping\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/fcakyon/deeptext", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "deeptext", "package_url": "https://pypi.org/project/deeptext/", "platform": "", "project_url": "https://pypi.org/project/deeptext/", "project_urls": {"Homepage": "https://github.com/fcakyon/deeptext"}, "release_url": "https://pypi.org/project/deeptext/0.1.3/", "requires_dist": ["craft-text-detector (==0.1.8)", "Shapely (==1.7.0)", "pytesseract (==0.3.3)"], "requires_python": ">=3.5", "summary": "A cross-platform framework for deep learning based text detection, recoginition and parsing", "version": "0.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://badge.fury.io/py/deeptext\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a1dbe085cc9ab050c3fdc0108cf1f1aafc966b25/68747470733a2f2f62616467652e667572792e696f2f70792f64656570746578742e737667\"></a>\n<a href=\"https://anaconda.org/fcakyon/deeptext\" rel=\"nofollow\"><img alt=\"Conda version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9900cff8abc5b92966ffff3c06de140afde09ca3/68747470733a2f2f616e61636f6e64612e6f72672f6663616b796f6e2f64656570746578742f6261646765732f76657273696f6e2e737667\"></a>\n<a href=\"https://github.com/fcakyon/deeptext/actions?query=event%3Apush+branch%3Amaster+is%3Acompleted+workflow%3ACI\" rel=\"nofollow\"><img alt=\"CI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f592c5feef0a15bdcbc3ec11808168a364eade42/68747470733a2f2f6769746875622e636f6d2f6663616b796f6e2f64656570746578742f776f726b666c6f77732f43492f62616467652e737667\"></a></p>\n<h1>deeptext</h1>\n<p>A cross-platform framework for deep learning based text detection, recoginition and parsing</p>\n<h2>Getting started</h2>\n<h3>Installation</h3>\n<ul>\n<li>Install using conda for Linux, Mac and Windows (preferred):</li>\n</ul>\n<pre><span class=\"go\">conda install -c fcakyon deeptext</span>\n</pre>\n<ul>\n<li>Install using pip for Linux and Mac:</li>\n</ul>\n<pre><span class=\"go\">pip install deeptext</span>\n</pre>\n<p>Install <a href=\"https://tesseract-ocr.github.io/tessdoc/Home.html\" rel=\"nofollow\">teserract-ocr</a> for text recognition.</p>\n<h3>Basic Usage</h3>\n<pre><span class=\"c1\"># import package</span>\n<span class=\"kn\">import</span> <span class=\"nn\">deeptext</span>\n\n<span class=\"c1\"># set image path and export folder directory</span>\n<span class=\"n\">image_path</span> <span class=\"o\">=</span> <span class=\"s1\">'idcard.png'</span>\n<span class=\"n\">output_dir</span> <span class=\"o\">=</span> <span class=\"s1\">'outputs/'</span>\n\n<span class=\"c1\"># apply text detection and export detected regions to output directory</span>\n<span class=\"n\">detection_result</span> <span class=\"o\">=</span> <span class=\"n\">deeptext</span><span class=\"o\">.</span><span class=\"n\">detect_text</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">,</span> <span class=\"n\">output_dir</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># apply text recognition to detected texts</span>\n<span class=\"n\">recognition_result</span> <span class=\"o\">=</span> <span class=\"n\">deeptext</span><span class=\"o\">.</span><span class=\"n\">recognize_text</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"o\">=</span><span class=\"n\">detection_result</span><span class=\"p\">[</span><span class=\"s2\">\"text_crop_paths\"</span><span class=\"p\">])</span>\n</pre>\n<h3>Advanced Usage</h3>\n<p>You can pass filter parameters if you want to scrap texts from image by predefined regions.</p>\n<pre><span class=\"c1\"># import package</span>\n<span class=\"kn\">import</span> <span class=\"nn\">deeptext</span>\n\n<span class=\"c1\"># set image path and export folder directory</span>\n<span class=\"n\">image_path</span> <span class=\"o\">=</span> <span class=\"s1\">'idcard.png'</span>\n<span class=\"n\">output_dir</span> <span class=\"o\">=</span> <span class=\"s1\">'outputs/'</span>\n\n<span class=\"c1\"># define regions that you want to scrap, by quad (box) points</span>\n<span class=\"n\">filter_params</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"box\"</span>\n                 <span class=\"s2\">\"boxes\"</span><span class=\"p\">:</span> <span class=\"p\">[[[</span><span class=\"mf\">0.1460</span> <span class=\"p\">,</span> <span class=\"mf\">0.0395</span><span class=\"p\">],</span>\n                            <span class=\"p\">[</span><span class=\"mf\">0.8417</span><span class=\"p\">,</span> <span class=\"mf\">0.0535</span><span class=\"p\">],</span>\n                            <span class=\"p\">[</span><span class=\"mf\">0.8412</span><span class=\"p\">,</span> <span class=\"mf\">0.1099</span><span class=\"p\">],</span>\n                            <span class=\"p\">[</span><span class=\"mf\">0.1455</span><span class=\"p\">,</span> <span class=\"mf\">0.0959</span><span class=\"p\">]],</span>\n                           <span class=\"p\">[[</span><span class=\"mf\">0.3467</span><span class=\"p\">,</span> <span class=\"mf\">0.3398</span><span class=\"p\">],</span>\n                            <span class=\"p\">[</span><span class=\"mf\">0.5417</span><span class=\"p\">,</span> <span class=\"mf\">0.3535</span><span class=\"p\">],</span>\n                            <span class=\"p\">[</span><span class=\"mf\">0.5412</span><span class=\"p\">,</span> <span class=\"mf\">0.4099</span><span class=\"p\">],</span>\n                            <span class=\"p\">[</span><span class=\"mf\">0.3455</span><span class=\"p\">,</span> <span class=\"mf\">0.3959</span><span class=\"p\">]]],</span>\n                 <span class=\"s2\">\"marigin_x\"</span><span class=\"p\">:</span> <span class=\"mf\">0.05</span><span class=\"p\">,</span>\n                 <span class=\"s2\">\"marigin_y\"</span><span class=\"p\">:</span> <span class=\"mf\">0.05</span><span class=\"p\">,</span>\n                 <span class=\"s2\">\"min_intersection_ratio\"</span><span class=\"p\">:</span> <span class=\"mf\">0.9</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># or define regions that you want to scrap, by centroids</span>\n<span class=\"n\">filter_params</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"centroid\"</span><span class=\"p\">,</span>\n                 <span class=\"s2\">\"centers\"</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"mf\">0.44</span><span class=\"p\">,</span> <span class=\"mf\">0.49</span><span class=\"p\">],[</span><span class=\"mf\">0.49</span><span class=\"p\">,</span> <span class=\"mf\">0.08</span><span class=\"p\">]],</span>\n                 <span class=\"s2\">\"marigin_x\"</span><span class=\"p\">:</span> <span class=\"mf\">0.03</span><span class=\"p\">,</span>\n                 <span class=\"s2\">\"marigin_y\"</span><span class=\"p\">:</span> <span class=\"mf\">0.05</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># apply craft text detection in predefined regions and export detected regions to output directory</span>\n<span class=\"n\">detection_result</span> <span class=\"o\">=</span> <span class=\"n\">deeptext</span><span class=\"o\">.</span><span class=\"n\">detect_text</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">,</span>\n                                         <span class=\"n\">output_dir</span><span class=\"p\">,</span>\n                                         <span class=\"n\">detector</span><span class=\"o\">=</span><span class=\"s2\">\"craft\"</span><span class=\"p\">,</span>\n                                         <span class=\"n\">filter_params</span><span class=\"o\">=</span><span class=\"n\">filter_params</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># apply tesseract (eng) text recognition to detected texts</span>\n<span class=\"n\">recognition_result</span> <span class=\"o\">=</span> <span class=\"n\">deeptext</span><span class=\"o\">.</span><span class=\"n\">recognize_text</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"o\">=</span><span class=\"n\">detection_result</span><span class=\"p\">[</span><span class=\"s2\">\"text_crop_paths\"</span><span class=\"p\">],</span>\n                                             <span class=\"n\">recognizer</span><span class=\"o\">=</span><span class=\"s2\">\"tesseract-eng\"</span><span class=\"p\">)</span>\n</pre>\n<h2>Updates</h2>\n<p><strong>6 April, 2020</strong>: Conda package release</p>\n<p><strong>3 April, 2020</strong>: Tesseract text recoginition and positional text scraping support</p>\n<p><strong>30 March, 2020</strong>: Craft text detector support</p>\n<h2>TODO</h2>\n<ul>\n<li>[X] Craft text detection (inference)</li>\n<li>[ ] Ctpn text detection (inference)</li>\n<li>[ ] Psenet text detection (inference)</li>\n<li>[X] Tesseract text recoginition (inference)</li>\n<li>[ ] Aster text recognition (training and inference)</li>\n<li>[ ] Moran text recognition (training and inference)</li>\n<li>[X] Positional text scraping</li>\n</ul>\n\n          </div>"}, "last_serial": 6969293, "releases": {"0.1.3": [{"comment_text": "", "digests": {"md5": "a98e238c4cbc20f7102fec5541571998", "sha256": "db13ef88fecfff2f29f00077c3197b8d6a44c7b88d1b19c425fff5b384e40c6c"}, "downloads": -1, "filename": "deeptext-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a98e238c4cbc20f7102fec5541571998", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 7107, "upload_time": "2020-04-05T21:48:04", "upload_time_iso_8601": "2020-04-05T21:48:04.765264Z", "url": "https://files.pythonhosted.org/packages/47/17/7900bb796b0ecbbb115ef4c33c047da5ac365d01f23b6bf9172417904c36/deeptext-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "439cc1503baacd8d57746a0fe09b0d0a", "sha256": "42a1f8a878264b5acf7df1739f3ac22a20394e052d71d5a68cd608e9a3262f14"}, "downloads": -1, "filename": "deeptext-0.1.3.tar.gz", "has_sig": false, "md5_digest": "439cc1503baacd8d57746a0fe09b0d0a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 6363, "upload_time": "2020-04-05T21:48:05", "upload_time_iso_8601": "2020-04-05T21:48:05.750099Z", "url": "https://files.pythonhosted.org/packages/a2/aa/24c6db61bef1018c4dd165444ed095693dbcf3c71db480013db7061d7dda/deeptext-0.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a98e238c4cbc20f7102fec5541571998", "sha256": "db13ef88fecfff2f29f00077c3197b8d6a44c7b88d1b19c425fff5b384e40c6c"}, "downloads": -1, "filename": "deeptext-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a98e238c4cbc20f7102fec5541571998", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 7107, "upload_time": "2020-04-05T21:48:04", "upload_time_iso_8601": "2020-04-05T21:48:04.765264Z", "url": "https://files.pythonhosted.org/packages/47/17/7900bb796b0ecbbb115ef4c33c047da5ac365d01f23b6bf9172417904c36/deeptext-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "439cc1503baacd8d57746a0fe09b0d0a", "sha256": "42a1f8a878264b5acf7df1739f3ac22a20394e052d71d5a68cd608e9a3262f14"}, "downloads": -1, "filename": "deeptext-0.1.3.tar.gz", "has_sig": false, "md5_digest": "439cc1503baacd8d57746a0fe09b0d0a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 6363, "upload_time": "2020-04-05T21:48:05", "upload_time_iso_8601": "2020-04-05T21:48:05.750099Z", "url": "https://files.pythonhosted.org/packages/a2/aa/24c6db61bef1018c4dd165444ed095693dbcf3c71db480013db7061d7dda/deeptext-0.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:19 2020"}