{"info": {"author": "Jacob Ferriero", "author_email": "jferriero@google.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Internet"], "description": "# BigQuery Pipeline\n\nUtility class for building data pipelines in BigQuery.\n\nProvides methods for query, copy table, delete table and export to GCS.\n\nSupports Jinja2 templated SQL.\n\n# Getting Started\n[Check out the codelab!](https://codinginadtech.com/ox-bqpipeline/codelab/index.html#0)\n\n## Usage\n\nCreate an instance of BQPipeline. By setting `query_project`, `default_project` and `default_dataset`, you can omit project and dataset from table references in your SQL statements.\n\n`default_project` is the project used when a tablespec does not specify a project.\n\n`default_dataset` is the dataset used when a tablespec does not specify project or dataset.\n\nPlace files containing a single BigQuery Standard SQL statement per file.\n\nNote that if you reference a project with a '-' in the name, you must backtick the tablespec in your SQL: `` `my-project.dataset_id.table_id` ``\n\n### Writing scripts to be easily portable between environments\n- Use `{{ project }}` in all your sql queries\n- In your replacements dictionary, set `'project'` to the value of `BQPipeline.infer_project()`\nthis will infer the project from the credentials. This means in your local shell it will use\n`GOOGLE_APPLICATION_DEFAULT` and on the cron box it will use project of the CronBox's Service Account.\n\n```\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom ox_bqpipeline.bqpipeline import BQPipeline\n\nbq = BQPipeline(job_name='myjob',\n                default_dataset='mydataset',\n                json_credentials_path='credentials.json')\n\nreplacements = {\n    'project': bq.infer_project(),\n    'dataset': 'mydataset'\n}\n\nbq.copy_table('source_table', 'dest_table')\n\nbq.run_queries(['../sql/q1.sql', ('../sql/q2.sql', 'tmp_table_1')], **replacements)\n\nbq.export_csv_to_gcs('tmp_table_2', 'gs://my-bucket/path/to/tmp_table_2-*.csv')\n\nbq.delete_tables(['tmp_table_1', 'tmp_table_2'])\n```\n\nNote, that the `run_queries` method provided this utility can alternatively take a list of tuples where the first entry is the sql path, and the second is a destination table. You can see an example of this in [`example_pipeline.py`](/example_pipeline.py).\n\nFor detailed documentation about the methods provided by this utility class see [docs.md](docs.md).\n\n### Writing scripts with parameterized queries\n\nBigquery standard sql provides support for [parameterized queries](https://cloud.google.com/bigquery/docs/parameterized-queries#top_of_page).\n\nTo run parameterized queries using the bqpipeline from commandline, use the following syntax:\n\n```bash\npython3 ox_bqpipeline/bqpipeline.py --query_file query.sql --gcs_destination gs://bucket_path --query_params '{\"int_param\": 1, \"str_param\": \"one\"}'\n```\n\nIn order to invoke the BQPipelines.run_queries method from within your python\nmodule, use the following pattern.\n\n```python\n        bqp = bqpipeline.BQPipeline(\n            job_name='testjob', default_project='project_name',\n            default_dataset='dataset_name')\n        qj_list = bqp.run_queries(\n            [(<query1_path>, <table_or_gcs_dest>, {'query1_params key,val'}),\n             (<query2_path>, <table_or_gcs_dest>, {'query2_params key,val'}),\n            ],\n            batch=False, overwrite=False,\n            dry_run=False)\n```\n\n### Creating Service Account JSON Credentials\n\n1. Visit the [Service Account Console](https://console.cloud.google.com/iam-admin/serviceaccounts)\n2. Select a service account\n3. Select \"Create Key\"\n4. Select \"JSON\"\n5. Click \"Create\" to download the file\n\n\n## Installation\n\n### Optional: Install in virtualenv\n\n```\npython3 -m virtualenv venv\nsource venv/bin/activate\n```\n\n### Install with pip\n\n```bash\npipenv install --python 3\n```\n\n### Install with pipenv\n\n```bash\npython3 -m pip install -r requirements.txt\n```\n\nor\n\n```bash\npip3 install -r requirements.txt\n```\n\n### Run test suite\n\n```bash\npython3 -m unittest discover\n```\n\n### Run test suite using pipenv\n\n```bash\npipenv run python -m unittest discover\n```\n\n\n## Requirements\n\nYou'll need to [download Python 3.4 or later](https://www.python.org/downloads/)\n\n[Google Cloud Python Client](https://github.com/googleapis/google-cloud-python)\n\n\n## Disclaimer\n\nThis is not an official Google project.\n\n\n## References\n\n[Python Example Code](https://github.com/GoogleCloudPlatform/python-docs-samples)\n[google-cloud-bigquery](https://pypi.org/project/google-cloud-bigquery/)\n[Jinja2](http://jinja.pocoo.org/docs/2.10/)\n[ox_bqpipeline Reference](docs.md)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/openx/ox-bqpipeline/archive/v0.0.4.zip", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/openx/ox-bqpipeline", "keywords": "", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "ox-bqpipeline", "package_url": "https://pypi.org/project/ox-bqpipeline/", "platform": "Posix; MacOS X; Windows", "project_url": "https://pypi.org/project/ox-bqpipeline/", "project_urls": {"Download": "https://github.com/openx/ox-bqpipeline/archive/v0.0.4.zip", "Homepage": "https://github.com/openx/ox-bqpipeline"}, "release_url": "https://pypi.org/project/ox-bqpipeline/0.0.4/", "requires_dist": ["google-cloud (>=0.34.0)", "google-api-python-client (>=1.7.8)", "google-cloud-bigquery (>=1.9.0)", "Jinja2 (>=2.10)", "j2cli (>=0.3.8)", "sqlparse (>=0.3.0)", "pylint (>=1.9.4)"], "requires_python": ">=3.4", "summary": "Utility class for building data pipelines in BigQuery", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>BigQuery Pipeline</h1>\n<p>Utility class for building data pipelines in BigQuery.</p>\n<p>Provides methods for query, copy table, delete table and export to GCS.</p>\n<p>Supports Jinja2 templated SQL.</p>\n<h1>Getting Started</h1>\n<p><a href=\"https://codinginadtech.com/ox-bqpipeline/codelab/index.html#0\" rel=\"nofollow\">Check out the codelab!</a></p>\n<h2>Usage</h2>\n<p>Create an instance of BQPipeline. By setting <code>query_project</code>, <code>default_project</code> and <code>default_dataset</code>, you can omit project and dataset from table references in your SQL statements.</p>\n<p><code>default_project</code> is the project used when a tablespec does not specify a project.</p>\n<p><code>default_dataset</code> is the dataset used when a tablespec does not specify project or dataset.</p>\n<p>Place files containing a single BigQuery Standard SQL statement per file.</p>\n<p>Note that if you reference a project with a '-' in the name, you must backtick the tablespec in your SQL: <code>`my-project.dataset_id.table_id`</code></p>\n<h3>Writing scripts to be easily portable between environments</h3>\n<ul>\n<li>Use <code>{{ project }}</code> in all your sql queries</li>\n<li>In your replacements dictionary, set <code>'project'</code> to the value of <code>BQPipeline.infer_project()</code>\nthis will infer the project from the credentials. This means in your local shell it will use\n<code>GOOGLE_APPLICATION_DEFAULT</code> and on the cron box it will use project of the CronBox's Service Account.</li>\n</ul>\n<pre><code>#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom ox_bqpipeline.bqpipeline import BQPipeline\n\nbq = BQPipeline(job_name='myjob',\n                default_dataset='mydataset',\n                json_credentials_path='credentials.json')\n\nreplacements = {\n    'project': bq.infer_project(),\n    'dataset': 'mydataset'\n}\n\nbq.copy_table('source_table', 'dest_table')\n\nbq.run_queries(['../sql/q1.sql', ('../sql/q2.sql', 'tmp_table_1')], **replacements)\n\nbq.export_csv_to_gcs('tmp_table_2', 'gs://my-bucket/path/to/tmp_table_2-*.csv')\n\nbq.delete_tables(['tmp_table_1', 'tmp_table_2'])\n</code></pre>\n<p>Note, that the <code>run_queries</code> method provided this utility can alternatively take a list of tuples where the first entry is the sql path, and the second is a destination table. You can see an example of this in <a href=\"/example_pipeline.py\" rel=\"nofollow\"><code>example_pipeline.py</code></a>.</p>\n<p>For detailed documentation about the methods provided by this utility class see <a href=\"docs.md\" rel=\"nofollow\">docs.md</a>.</p>\n<h3>Writing scripts with parameterized queries</h3>\n<p>Bigquery standard sql provides support for <a href=\"https://cloud.google.com/bigquery/docs/parameterized-queries#top_of_page\" rel=\"nofollow\">parameterized queries</a>.</p>\n<p>To run parameterized queries using the bqpipeline from commandline, use the following syntax:</p>\n<pre>python3 ox_bqpipeline/bqpipeline.py --query_file query.sql --gcs_destination gs://bucket_path --query_params <span class=\"s1\">'{\"int_param\": 1, \"str_param\": \"one\"}'</span>\n</pre>\n<p>In order to invoke the BQPipelines.run_queries method from within your python\nmodule, use the following pattern.</p>\n<pre>        <span class=\"n\">bqp</span> <span class=\"o\">=</span> <span class=\"n\">bqpipeline</span><span class=\"o\">.</span><span class=\"n\">BQPipeline</span><span class=\"p\">(</span>\n            <span class=\"n\">job_name</span><span class=\"o\">=</span><span class=\"s1\">'testjob'</span><span class=\"p\">,</span> <span class=\"n\">default_project</span><span class=\"o\">=</span><span class=\"s1\">'project_name'</span><span class=\"p\">,</span>\n            <span class=\"n\">default_dataset</span><span class=\"o\">=</span><span class=\"s1\">'dataset_name'</span><span class=\"p\">)</span>\n        <span class=\"n\">qj_list</span> <span class=\"o\">=</span> <span class=\"n\">bqp</span><span class=\"o\">.</span><span class=\"n\">run_queries</span><span class=\"p\">(</span>\n            <span class=\"p\">[(</span><span class=\"o\">&lt;</span><span class=\"n\">query1_path</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"o\">&lt;</span><span class=\"n\">table_or_gcs_dest</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s1\">'query1_params key,val'</span><span class=\"p\">}),</span>\n             <span class=\"p\">(</span><span class=\"o\">&lt;</span><span class=\"n\">query2_path</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"o\">&lt;</span><span class=\"n\">table_or_gcs_dest</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s1\">'query2_params key,val'</span><span class=\"p\">}),</span>\n            <span class=\"p\">],</span>\n            <span class=\"n\">batch</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">overwrite</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n            <span class=\"n\">dry_run</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<h3>Creating Service Account JSON Credentials</h3>\n<ol>\n<li>Visit the <a href=\"https://console.cloud.google.com/iam-admin/serviceaccounts\" rel=\"nofollow\">Service Account Console</a></li>\n<li>Select a service account</li>\n<li>Select \"Create Key\"</li>\n<li>Select \"JSON\"</li>\n<li>Click \"Create\" to download the file</li>\n</ol>\n<h2>Installation</h2>\n<h3>Optional: Install in virtualenv</h3>\n<pre><code>python3 -m virtualenv venv\nsource venv/bin/activate\n</code></pre>\n<h3>Install with pip</h3>\n<pre>pipenv install --python <span class=\"m\">3</span>\n</pre>\n<h3>Install with pipenv</h3>\n<pre>python3 -m pip install -r requirements.txt\n</pre>\n<p>or</p>\n<pre>pip3 install -r requirements.txt\n</pre>\n<h3>Run test suite</h3>\n<pre>python3 -m unittest discover\n</pre>\n<h3>Run test suite using pipenv</h3>\n<pre>pipenv run python -m unittest discover\n</pre>\n<h2>Requirements</h2>\n<p>You'll need to <a href=\"https://www.python.org/downloads/\" rel=\"nofollow\">download Python 3.4 or later</a></p>\n<p><a href=\"https://github.com/googleapis/google-cloud-python\" rel=\"nofollow\">Google Cloud Python Client</a></p>\n<h2>Disclaimer</h2>\n<p>This is not an official Google project.</p>\n<h2>References</h2>\n<p><a href=\"https://github.com/GoogleCloudPlatform/python-docs-samples\" rel=\"nofollow\">Python Example Code</a>\n<a href=\"https://pypi.org/project/google-cloud-bigquery/\" rel=\"nofollow\">google-cloud-bigquery</a>\n<a href=\"http://jinja.pocoo.org/docs/2.10/\" rel=\"nofollow\">Jinja2</a>\n<a href=\"docs.md\" rel=\"nofollow\">ox_bqpipeline Reference</a></p>\n\n          </div>"}, "last_serial": 6460251, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "4a82b2d5c916a6fae6e6f5a68fadd421", "sha256": "09db3aab5f921982f2b1a330ff373a6be353ac5e05f73ed6c056baf0eaa7fe86"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.1.tar.gz", "has_sig": false, "md5_digest": "4a82b2d5c916a6fae6e6f5a68fadd421", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 10173, "upload_time": "2019-06-14T02:19:00", "upload_time_iso_8601": "2019-06-14T02:19:00.239700Z", "url": "https://files.pythonhosted.org/packages/77/eb/6b0ab400e3e27f9bae066ea381156c76b795690c04f4bcee831f56138196/ox_bqpipeline-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "2e8487d619a29a96dd1206ae4ce622d6", "sha256": "82afeaa8ee739e9e22cd26d54996068c97858c0fb9fc45054b681cb2822e808c"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.2.tar.gz", "has_sig": false, "md5_digest": "2e8487d619a29a96dd1206ae4ce622d6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 10152, "upload_time": "2019-06-14T03:04:41", "upload_time_iso_8601": "2019-06-14T03:04:41.977803Z", "url": "https://files.pythonhosted.org/packages/5d/6f/ff05daa338acfd8ef1484b992720a22b167e2693462a39f5dd61001ae672/ox_bqpipeline-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "4e274c113c1c2bb8e0b750e56e7582b1", "sha256": "3611413d4ea6b022e27a9068494a880570f442c7efb673bdba8a36bb4bcad2fd"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.3.tar.gz", "has_sig": false, "md5_digest": "4e274c113c1c2bb8e0b750e56e7582b1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 10740, "upload_time": "2019-07-03T21:20:40", "upload_time_iso_8601": "2019-07-03T21:20:40.427570Z", "url": "https://files.pythonhosted.org/packages/3f/ea/6b15019a5ec4cea1d5b952ec62cf1a85b9b2961333ad87b8cde34d8b56fa/ox_bqpipeline-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "78500b2fa87c9faae4ebf7a032aebcd5", "sha256": "1c24d99d98471cefdebdcaeb5b5dd803091f8191c9ebfa4d25ce8077f272ee88"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "78500b2fa87c9faae4ebf7a032aebcd5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4", "size": 13960, "upload_time": "2020-01-15T17:14:08", "upload_time_iso_8601": "2020-01-15T17:14:08.468321Z", "url": "https://files.pythonhosted.org/packages/04/6c/108df2bbe1e287ae26a21f7d4b41979302088a9adcc387f02e835e8249fb/ox_bqpipeline-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "68c5b25d32461110e37fdd6893998b46", "sha256": "b60706616981076cb429e507a88171c3c30877557b80e3132fa643f93c0d0c71"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.4.tar.gz", "has_sig": false, "md5_digest": "68c5b25d32461110e37fdd6893998b46", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 12088, "upload_time": "2020-01-15T17:14:10", "upload_time_iso_8601": "2020-01-15T17:14:10.183361Z", "url": "https://files.pythonhosted.org/packages/bb/b8/d1c8e793f3c80418aa8379263e04cd50431e263ebaeb396555b09d2b8efd/ox_bqpipeline-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "78500b2fa87c9faae4ebf7a032aebcd5", "sha256": "1c24d99d98471cefdebdcaeb5b5dd803091f8191c9ebfa4d25ce8077f272ee88"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "78500b2fa87c9faae4ebf7a032aebcd5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4", "size": 13960, "upload_time": "2020-01-15T17:14:08", "upload_time_iso_8601": "2020-01-15T17:14:08.468321Z", "url": "https://files.pythonhosted.org/packages/04/6c/108df2bbe1e287ae26a21f7d4b41979302088a9adcc387f02e835e8249fb/ox_bqpipeline-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "68c5b25d32461110e37fdd6893998b46", "sha256": "b60706616981076cb429e507a88171c3c30877557b80e3132fa643f93c0d0c71"}, "downloads": -1, "filename": "ox_bqpipeline-0.0.4.tar.gz", "has_sig": false, "md5_digest": "68c5b25d32461110e37fdd6893998b46", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 12088, "upload_time": "2020-01-15T17:14:10", "upload_time_iso_8601": "2020-01-15T17:14:10.183361Z", "url": "https://files.pythonhosted.org/packages/bb/b8/d1c8e793f3c80418aa8379263e04cd50431e263ebaeb396555b09d2b8efd/ox_bqpipeline-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:00:28 2020"}