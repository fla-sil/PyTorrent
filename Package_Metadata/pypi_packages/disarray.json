{"info": {"author": "Kevin Arvai", "author_email": "arvkevi@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "# disarray\n[![Build Status](https://travis-ci.com/arvkevi/disarray.svg?branch=master)](https://travis-ci.com/arvkevi/disarray)\n[![codecov](https://codecov.io/gh/arvkevi/disarray/branch/master/graph/badge.svg)](https://codecov.io/gh/arvkevi/disarray)\n\nThis package calculates metrics derived from a confusion matrix and makes them directly accessible from a pandas \nDataFrame. Simply install and import `disarray`. \n\n**Why disarray?**  \nWorking with a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) is an everyday occurrence for most \ndata science projects. Sometimes, a data scientist is responsible for generating a confusion matrix using machine \nlearning libraries like [scikit-learn](https://scikit-learn.org/stable/). But it's not uncommon to work with confusion \nmatrices directly as [pandas](https://pandas.pydata.org/) DataFrames. \n\nSince `pandas` version `0.23.0`, users can easily\n[register custom accessors](https://pandas.pydata.org/pandas-docs/stable/development/extending.html#extending-pandas),\n which is how `disarray` is implemented. This makes accessing confusion matrix metrics as easy as:  \n ```python\n>>> import pandas as pd\n>>> df = pd.DataFrame([[18, 1], [0, 1]])\n>>> import disarray\n>>> df.da.sensitivity\n0    0.947368\n1    1.000000\ndtype: float64\n```\n\n## Table of contents\n- [Installation](#installation)\n- [Usage](#usage)\n    * [sample counts](#sample-counts)\n    * [export metrics](#export-metrics)\n    * [multi-class classification](#multi-class-classification)\n    * [supported metrics](#supported-metrics)\n- [Contributing](#contributing)\n\n## Installation\n**Install using pip**\n```bash\n$ pip install disarray\n```\n\n**Clone from GitHub**\n```bash\n$ git clone https://github.com/arvkevi/disarray.git\n$ python setup.py install\n```\n\n## Usage\nThe `disarray` package is intended to be used similar to a `pandas` attribute or method. `disarray` is registered as \na `pandas` extension under `da`. For a DataFrame named `df`, access the library using `df.da.`.\n\nTo understand the input and usage for `disarray`, build an example confusion matrix for a **binary classification**\n problem from scratch with `scikit-learn`.   \n(You can install the packages you need to run the demo with: `pip install -r requirements.demo.txt`)\n\n```python\nfrom sklearn import svm, datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n# Generate a random binary classification dataset\nX, y = datasets.make_classification(n_classes=2, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n# fit and predict an SVM\nclassifier = svm.SVC(kernel='linear', C=0.01)\ny_pred = classifier.fit(X_train, y_train).predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n[[13  2]\n [ 0 10]]\n```\n\nUsing `disarray` is as easy as importing it and instantiating a DataFrame object from a **square** array of **positive** \nintegers.\n\n```python\nimport disarray\nimport pandas as pd\n\ndf = pd.DataFrame(cm)\nprint(df.da.sensitivity)\n0    0.866667\n1    1.000000\n```\n\n### Sample Counts\n`disarray` stores per-class sample counts of true positives, false positives, false negatives, and true negatives. \nEach of these are stored as capitalized abbreviations, `TP`, `FP`, `FN`, and `TN`.\n\n```python\ndf.da.TP\n```\n```python\n0    13\n1    10\ndtype: int64\n```\n\n### Export Metrics\nUse `df.da.export_metrics()` to store and/or visualize many common performance metrics in a new `pandas` DataFrame \nobject. Use the `metrics_to_include=` argument to pass a list of metrics defined in `disarray/metrics.py` (default is \nto use `__all_metrics__`).\n\n```python\ndf.da.export_metrics(metrics_to_include=['precision', 'recall', 'f1'])\n```\n|           |        0 |        1 |   micro-average |\n|-----------|----------|----------|-----------------|\n| precision | 1        | 0.833333 |            0.92 |\n| recall    | 0.866667 | 1        |            0.92 |\n| f1        | 0.928571 | 0.909091 |            0.92 |\n\n\n\n### Multi-Class Classification\n`disarray` works with multi-class classification confusion matrices also. Try it out on the iris dataset. Notice, the\n DataFrame is instantiated with an `index` and `columns` here, but it is not required.\n\n```python\n# load the iris dataset\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\nclass_names = iris.target_names\n# split the training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n# train and fit a SVM\nclassifier = svm.SVC(kernel='linear', C=0.01)\ny_pred = classifier.fit(X_train, y_train).predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\n\n# Instantiate the confusion matrix DataFrame with index and columns\ndf = pd.DataFrame(cm, index=class_names, columns=class_names)\nprint(df)\n```\n|            |   setosa |   versicolor |   virginica |\n|------------|----------|--------------|-------------|\n| setosa     |       13 |            0 |           0 |\n| versicolor |        0 |           10 |           6 |\n| virginica  |        0 |            0 |           9 |\n\n`disarray` can provide per-class metrics:\n\n```python\ndf.da.sensitivity\n```\n```python\nsetosa        1.000\nversicolor    0.625\nvirginica     1.000\ndtype: float64\n```\nIn a familiar fashion, one of the classes can be accessed with bracket indexing.\n\n```python\ndf.da.sensitivity['setosa']\n```\n```python\n1.0\n```\nCurrently, a [micro-average](https://datascience.stackexchange.com/a/24051/16855) is supported for both binary and\n multi-class classification confusion matrices. (Although it only makes sense in the multi-class case).\n```python\ndf.da.micro_sensitivity\n```\n```python\n0.8421052631578947\n```\nFinally, a DataFrame can be exported with selected metrics.\n```python\ndf.da.export_metrics(metrics_to_include=['sensitivity', 'specificity', 'f1'])\n```\n\n|             |   setosa |   versicolor |   virginica |   micro-average |\n|-------------|----------|--------------|-------------|-----------------|\n| sensitivity |        1 |     0.625    |    1        |        0.842105 |\n| specificity |        1 |     1        |    0.793103 |        0.921053 |\n| f1          |        1 |     0.769231 |    0.75     |        0.842105 |\n\n### Supported Metrics\n```python\n'accuracy',\n'f1',\n'false_discovery_rate',\n'false_negative_rate',\n'false_positive_rate',\n'negative_predictive_value',\n'positive_predictive_value',\n'precision',\n'recall',\n'sensitivity',\n'specificity',\n'true_negative_rate',\n'true_positive_rate',\n```\nAs well as micro-averages for each of these, accessible via `df.da.micro_recall`, for example.\n\n## Contributing\n\nContributions are welcome, please refer to [CONTRIBUTING](https://github.com/arvkevi/disarray/blob/master/CONTRIBUTING.md) \nto learn more about how to contribute.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/arvkevi/disarray/tarball/0.1.0", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/arvkevi/disarray", "keywords": "machine learning-supervised learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "disarray", "package_url": "https://pypi.org/project/disarray/", "platform": "", "project_url": "https://pypi.org/project/disarray/", "project_urls": {"Download": "https://github.com/arvkevi/disarray/tarball/0.1.0", "Homepage": "https://github.com/arvkevi/disarray"}, "release_url": "https://pypi.org/project/disarray/0.1.0/", "requires_dist": ["pandas (>=0.23.0)", "numpy (>=0.14.2)"], "requires_python": "", "summary": "Calculate confusion matrix metrics from your pandas DataFrame", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>disarray</h1>\n<p><a href=\"https://travis-ci.com/arvkevi/disarray\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c4e36ca575125b4e8cc44ab4cf1ebb47ac93dada/68747470733a2f2f7472617669732d63692e636f6d2f6172766b6576692f64697361727261792e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/arvkevi/disarray\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9d325dbc81a3ee01205f7aa84e7b3ab51c722891/68747470733a2f2f636f6465636f762e696f2f67682f6172766b6576692f64697361727261792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<p>This package calculates metrics derived from a confusion matrix and makes them directly accessible from a pandas\nDataFrame. Simply install and import <code>disarray</code>.</p>\n<p><strong>Why disarray?</strong><br>\nWorking with a <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\" rel=\"nofollow\">confusion matrix</a> is an everyday occurrence for most\ndata science projects. Sometimes, a data scientist is responsible for generating a confusion matrix using machine\nlearning libraries like <a href=\"https://scikit-learn.org/stable/\" rel=\"nofollow\">scikit-learn</a>. But it's not uncommon to work with confusion\nmatrices directly as <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">pandas</a> DataFrames.</p>\n<p>Since <code>pandas</code> version <code>0.23.0</code>, users can easily\n<a href=\"https://pandas.pydata.org/pandas-docs/stable/development/extending.html#extending-pandas\" rel=\"nofollow\">register custom accessors</a>,\nwhich is how <code>disarray</code> is implemented. This makes accessing confusion matrix metrics as easy as:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">([[</span><span class=\"mi\">18</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">disarray</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">sensitivity</span>\n<span class=\"mi\">0</span>    <span class=\"mf\">0.947368</span>\n<span class=\"mi\">1</span>    <span class=\"mf\">1.000000</span>\n<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">float64</span>\n</pre>\n<h2>Table of contents</h2>\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#sample-counts\" rel=\"nofollow\">sample counts</a></li>\n<li><a href=\"#export-metrics\" rel=\"nofollow\">export metrics</a></li>\n<li><a href=\"#multi-class-classification\" rel=\"nofollow\">multi-class classification</a></li>\n<li><a href=\"#supported-metrics\" rel=\"nofollow\">supported metrics</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n</ul>\n<h2>Installation</h2>\n<p><strong>Install using pip</strong></p>\n<pre>$ pip install disarray\n</pre>\n<p><strong>Clone from GitHub</strong></p>\n<pre>$ git clone https://github.com/arvkevi/disarray.git\n$ python setup.py install\n</pre>\n<h2>Usage</h2>\n<p>The <code>disarray</code> package is intended to be used similar to a <code>pandas</code> attribute or method. <code>disarray</code> is registered as\na <code>pandas</code> extension under <code>da</code>. For a DataFrame named <code>df</code>, access the library using <code>df.da.</code>.</p>\n<p>To understand the input and usage for <code>disarray</code>, build an example confusion matrix for a <strong>binary classification</strong>\nproblem from scratch with <code>scikit-learn</code>.<br>\n(You can install the packages you need to run the demo with: <code>pip install -r requirements.demo.txt</code>)</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">svm</span><span class=\"p\">,</span> <span class=\"n\">datasets</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">confusion_matrix</span>\n<span class=\"c1\"># Generate a random binary classification dataset</span>\n<span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">make_classification</span><span class=\"p\">(</span><span class=\"n\">n_classes</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n<span class=\"c1\"># fit and predict an SVM</span>\n<span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">svm</span><span class=\"o\">.</span><span class=\"n\">SVC</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"o\">=</span><span class=\"s1\">'linear'</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n\n<span class=\"n\">cm</span> <span class=\"o\">=</span> <span class=\"n\">confusion_matrix</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">cm</span><span class=\"p\">)</span>\n<span class=\"p\">[[</span><span class=\"mi\">13</span>  <span class=\"mi\">2</span><span class=\"p\">]</span>\n <span class=\"p\">[</span> <span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"p\">]]</span>\n</pre>\n<p>Using <code>disarray</code> is as easy as importing it and instantiating a DataFrame object from a <strong>square</strong> array of <strong>positive</strong>\nintegers.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">disarray</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">cm</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">sensitivity</span><span class=\"p\">)</span>\n<span class=\"mi\">0</span>    <span class=\"mf\">0.866667</span>\n<span class=\"mi\">1</span>    <span class=\"mf\">1.000000</span>\n</pre>\n<h3>Sample Counts</h3>\n<p><code>disarray</code> stores per-class sample counts of true positives, false positives, false negatives, and true negatives.\nEach of these are stored as capitalized abbreviations, <code>TP</code>, <code>FP</code>, <code>FN</code>, and <code>TN</code>.</p>\n<pre><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">TP</span>\n</pre>\n<pre><span class=\"mi\">0</span>    <span class=\"mi\">13</span>\n<span class=\"mi\">1</span>    <span class=\"mi\">10</span>\n<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">int64</span>\n</pre>\n<h3>Export Metrics</h3>\n<p>Use <code>df.da.export_metrics()</code> to store and/or visualize many common performance metrics in a new <code>pandas</code> DataFrame\nobject. Use the <code>metrics_to_include=</code> argument to pass a list of metrics defined in <code>disarray/metrics.py</code> (default is\nto use <code>__all_metrics__</code>).</p>\n<pre><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">export_metrics</span><span class=\"p\">(</span><span class=\"n\">metrics_to_include</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'precision'</span><span class=\"p\">,</span> <span class=\"s1\">'recall'</span><span class=\"p\">,</span> <span class=\"s1\">'f1'</span><span class=\"p\">])</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>0</th>\n<th>1</th>\n<th>micro-average</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>precision</td>\n<td>1</td>\n<td>0.833333</td>\n<td>0.92</td>\n</tr>\n<tr>\n<td>recall</td>\n<td>0.866667</td>\n<td>1</td>\n<td>0.92</td>\n</tr>\n<tr>\n<td>f1</td>\n<td>0.928571</td>\n<td>0.909091</td>\n<td>0.92</td>\n</tr></tbody></table>\n<h3>Multi-Class Classification</h3>\n<p><code>disarray</code> works with multi-class classification confusion matrices also. Try it out on the iris dataset. Notice, the\nDataFrame is instantiated with an <code>index</code> and <code>columns</code> here, but it is not required.</p>\n<pre><span class=\"c1\"># load the iris dataset</span>\n<span class=\"n\">iris</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_iris</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"o\">.</span><span class=\"n\">data</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"o\">.</span><span class=\"n\">target</span>\n<span class=\"n\">class_names</span> <span class=\"o\">=</span> <span class=\"n\">iris</span><span class=\"o\">.</span><span class=\"n\">target_names</span>\n<span class=\"c1\"># split the training and testing data</span>\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"c1\"># train and fit a SVM</span>\n<span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">svm</span><span class=\"o\">.</span><span class=\"n\">SVC</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"o\">=</span><span class=\"s1\">'linear'</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n<span class=\"n\">cm</span> <span class=\"o\">=</span> <span class=\"n\">confusion_matrix</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Instantiate the confusion matrix DataFrame with index and columns</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">cm</span><span class=\"p\">,</span> <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"n\">class_names</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">class_names</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>setosa</th>\n<th>versicolor</th>\n<th>virginica</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>setosa</td>\n<td>13</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>versicolor</td>\n<td>0</td>\n<td>10</td>\n<td>6</td>\n</tr>\n<tr>\n<td>virginica</td>\n<td>0</td>\n<td>0</td>\n<td>9</td>\n</tr></tbody></table>\n<p><code>disarray</code> can provide per-class metrics:</p>\n<pre><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">sensitivity</span>\n</pre>\n<pre><span class=\"n\">setosa</span>        <span class=\"mf\">1.000</span>\n<span class=\"n\">versicolor</span>    <span class=\"mf\">0.625</span>\n<span class=\"n\">virginica</span>     <span class=\"mf\">1.000</span>\n<span class=\"n\">dtype</span><span class=\"p\">:</span> <span class=\"n\">float64</span>\n</pre>\n<p>In a familiar fashion, one of the classes can be accessed with bracket indexing.</p>\n<pre><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">sensitivity</span><span class=\"p\">[</span><span class=\"s1\">'setosa'</span><span class=\"p\">]</span>\n</pre>\n<pre><span class=\"mf\">1.0</span>\n</pre>\n<p>Currently, a <a href=\"https://datascience.stackexchange.com/a/24051/16855\" rel=\"nofollow\">micro-average</a> is supported for both binary and\nmulti-class classification confusion matrices. (Although it only makes sense in the multi-class case).</p>\n<pre><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">micro_sensitivity</span>\n</pre>\n<pre><span class=\"mf\">0.8421052631578947</span>\n</pre>\n<p>Finally, a DataFrame can be exported with selected metrics.</p>\n<pre><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">da</span><span class=\"o\">.</span><span class=\"n\">export_metrics</span><span class=\"p\">(</span><span class=\"n\">metrics_to_include</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'sensitivity'</span><span class=\"p\">,</span> <span class=\"s1\">'specificity'</span><span class=\"p\">,</span> <span class=\"s1\">'f1'</span><span class=\"p\">])</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>setosa</th>\n<th>versicolor</th>\n<th>virginica</th>\n<th>micro-average</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>sensitivity</td>\n<td>1</td>\n<td>0.625</td>\n<td>1</td>\n<td>0.842105</td>\n</tr>\n<tr>\n<td>specificity</td>\n<td>1</td>\n<td>1</td>\n<td>0.793103</td>\n<td>0.921053</td>\n</tr>\n<tr>\n<td>f1</td>\n<td>1</td>\n<td>0.769231</td>\n<td>0.75</td>\n<td>0.842105</td>\n</tr></tbody></table>\n<h3>Supported Metrics</h3>\n<pre><span class=\"s1\">'accuracy'</span><span class=\"p\">,</span>\n<span class=\"s1\">'f1'</span><span class=\"p\">,</span>\n<span class=\"s1\">'false_discovery_rate'</span><span class=\"p\">,</span>\n<span class=\"s1\">'false_negative_rate'</span><span class=\"p\">,</span>\n<span class=\"s1\">'false_positive_rate'</span><span class=\"p\">,</span>\n<span class=\"s1\">'negative_predictive_value'</span><span class=\"p\">,</span>\n<span class=\"s1\">'positive_predictive_value'</span><span class=\"p\">,</span>\n<span class=\"s1\">'precision'</span><span class=\"p\">,</span>\n<span class=\"s1\">'recall'</span><span class=\"p\">,</span>\n<span class=\"s1\">'sensitivity'</span><span class=\"p\">,</span>\n<span class=\"s1\">'specificity'</span><span class=\"p\">,</span>\n<span class=\"s1\">'true_negative_rate'</span><span class=\"p\">,</span>\n<span class=\"s1\">'true_positive_rate'</span><span class=\"p\">,</span>\n</pre>\n<p>As well as micro-averages for each of these, accessible via <code>df.da.micro_recall</code>, for example.</p>\n<h2>Contributing</h2>\n<p>Contributions are welcome, please refer to <a href=\"https://github.com/arvkevi/disarray/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">CONTRIBUTING</a>\nto learn more about how to contribute.</p>\n\n          </div>"}, "last_serial": 5936592, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "9aa7f07d3fce28b82cda8405a66d2905", "sha256": "806f4826bf33a2e3d115737c08355ee6fc34041f438ebf41ec34e1113b9f46d3"}, "downloads": -1, "filename": "disarray-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9aa7f07d3fce28b82cda8405a66d2905", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6674, "upload_time": "2019-10-07T01:50:29", "upload_time_iso_8601": "2019-10-07T01:50:29.899802Z", "url": "https://files.pythonhosted.org/packages/0c/c1/9468fddcc25f930c7300dc45bd2f2bead83504ff62719ad7c5f41898aa0d/disarray-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "377df996739c5aa0d8bfaa0ee98d2034", "sha256": "397588be2d493b68b0c438dd0bd85a0fe7207870877281e2905963123a2c7817"}, "downloads": -1, "filename": "disarray-0.1.0.tar.gz", "has_sig": false, "md5_digest": "377df996739c5aa0d8bfaa0ee98d2034", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6117, "upload_time": "2019-10-07T01:50:32", "upload_time_iso_8601": "2019-10-07T01:50:32.390724Z", "url": "https://files.pythonhosted.org/packages/8a/fb/6fec6dfaed0fa749e2c46467abf46604c2ee4e1ed4787f9c26d98cc2a1e6/disarray-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9aa7f07d3fce28b82cda8405a66d2905", "sha256": "806f4826bf33a2e3d115737c08355ee6fc34041f438ebf41ec34e1113b9f46d3"}, "downloads": -1, "filename": "disarray-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9aa7f07d3fce28b82cda8405a66d2905", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6674, "upload_time": "2019-10-07T01:50:29", "upload_time_iso_8601": "2019-10-07T01:50:29.899802Z", "url": "https://files.pythonhosted.org/packages/0c/c1/9468fddcc25f930c7300dc45bd2f2bead83504ff62719ad7c5f41898aa0d/disarray-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "377df996739c5aa0d8bfaa0ee98d2034", "sha256": "397588be2d493b68b0c438dd0bd85a0fe7207870877281e2905963123a2c7817"}, "downloads": -1, "filename": "disarray-0.1.0.tar.gz", "has_sig": false, "md5_digest": "377df996739c5aa0d8bfaa0ee98d2034", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6117, "upload_time": "2019-10-07T01:50:32", "upload_time_iso_8601": "2019-10-07T01:50:32.390724Z", "url": "https://files.pythonhosted.org/packages/8a/fb/6fec6dfaed0fa749e2c46467abf46604c2ee4e1ed4787f9c26d98cc2a1e6/disarray-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:38:14 2020"}