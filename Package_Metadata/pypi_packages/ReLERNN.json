{"info": {"author": "Jeffrey Adrion, Jared Galloway, Andrew Kern", "author_email": "jeffreyadrion@gmail.com, jaredgalloway07@gmail.com, adk@uoregon.edu", "bugtrack_url": null, "classifiers": [], "description": "# *ReLERNN*\n## *Recombination Landscape Estimation using Recurrent Neural Networks*\n====================================================================\n\nReLERNN uses deep learning to infer the genome-wide landscape of recombination from as few as four individually sequenced chromosomes, or from allele frequencies inferred by pooled sequencing.\nThis repository contains the code and instructions required to run ReLERNN, and includes example files to ensure everything is working properly. The current manuscript detailing ReLERNN can be found [here](https://www.biorxiv.org/content/biorxiv/early/2019/08/16/662247.full.pdf).\n\n## Recommended installation on linux\nInstall `tensorflow 2` on your system. Directions can be found [here](https://www.tensorflow.org/install). You will need to install the CUDA toolkit and CuDNN as well.\n\nFurther dependencies for ReLERNN can be installed with pip.\nThis is done with the following commands:\n\n```\n$ git clone https://github.com/kern-lab/ReLERNN.git\n$ cd ReLERNN\n$ pip install -r requirements.txt\n$ python setup.py install\n```\n\nIt should be as simple as that.\n\n## Testing ReLERNN\nAn example VCF file (5 contigs; 10 haploid chromosomes) and a shell script for running ReLERNN's four modules is located in `$/ReLERNN/examples`.\nTo test the functionality of ReLERNN simply use the following commands:\n\n```\n$ cd examples\n$ ./example_pipeline.sh\n```\n\nProvided everything worked as planned, `$ReLERNN/examples/example_output/` should be populated with a few directories along with the files: `example.PREDICT.txt` and `example.PREDICT.BSCORRECT.txt`.\nThe latter is the finalized output file with your recombination rate predictions and estimates of uncertainty.\n\nThe above example took 57 seconds to complete on a Xeon machine using four CPUs and one NVIDIA 2070 GPU.\nNote that the parameters used for this example were designed only to test the success of the installation, not to make accurate predictions.\nPlease use the guidelines below for the best results when analyzing real data.\nReLERNN requires the use of a CUDA-Enabled NVIDIA GPU.\n\nYou can now test the functionality of ReLERNN for use with pool-seq data by using the following commands:\n\n```\n$ cd examples\n$ ./example_pipeline_pool.sh\n```\n\n## Estimating a recombination landscape from individually sequenced chromosomes\n\nThe ReLERNN pipeline is executed using four commands: `ReLERNN_SIMULATE`, `ReLERNN_TRAIN`, `ReLERNN_PREDICT`, and the optional `ReLERNN_BSCORRECT` (see the [Method flow diagram](./methodFlow.png)).\n\n### Before running ReLERNN\nReLERNN takes as input a VCF file of biallelic variants. Users should use appropriate QC techniques (filtering low-quality variants, etc.) and remove non-biallelic variants before running ReLERNN. Small contigs (<< 250 SNPs) should not be included in the genome file `--genome`, though these do not need to be removed from the VCF. \nReLERNN also requires that the number of sampled chromosomes is identical across all contigs, and VCFs should be filtered accordingly. Hemizygous chromosomes or haploid samples in an otherwise diploid dataset \nshould ideally be run separately using a separate VCF. It is possible to treat hemizygous chromosomes as \"diploids with missing data\" using the `--forceDiploid` option, however this is not recommended. \nIt is now possible to run ReLERNN on VCFs with missing genotypes (coded as a `.`).\n\nIf you want to make predictions based on equilibrium simulations, you can skip ahead to executing `ReLERNN_SIMULATE`.\nWhile ReLERNN is generally robust to demographic model misspecification, prediction accuracy may potentially be improved by simulating the training set under a demographic history that accurately matches that of your sample. ReLERNN optionally takes the raw output files from three popular demographic history inference programs ([stairwayplot_v1](https://sites.google.com/site/jpopgen/stairway-plot), [SMC++](https://github.com/popgenmethods/smcpp), and [MSMC](https://github.com/stschiff/msmc)), and simulates a training set under these histories. It is up to the user to perform the proper due diligence to ensure that the population size histories reported by these programs are sound. In our opinion, unless you know exactly how these programs work and you expect your data to represent a history dramatically different from equilibrium, you are better off skipping this step and training ReLERNN on equilibrium simulations. Once you have run one of the demographic history inference programs listed above, you simply provide the raw output file from that program to ReLERNN_SIMULATE using the `--demographicHistory` option.\n\n\n### Step 1) ReLERNN_SIMULATE\n`ReLERNN_SIMULATE` reads your VCF file and splits it by chromosome. The chromosomes to be evaluated must be specified by providing a BED file of said positions using the `--genome` argument. A BED-formatted accessibility mask (with non-overlapping ascending windows) may be optionally provided using the `--mask` option. Use the `--phased` or `--unphased` flag to train using phased or unphased genotypes (the default is unphased). It is required that the VCF file use the extension `.vcf`. The prefix of that file will serve as the prefix used for all output files (e.g. running ReLERNN on the file `population7.vcf` will generate the result file `population7.PREDICT.txt`). It is strongly recommended that you use the default setting for `--maxWinSize`, larger values can cause training to fail and smaller values can result in lower accuracy. Users are required to provide an estimate of the per-base mutation rate for your sample, along with an estimate for generation time (in years). If you previously ran one of the demographic history inference programs listed above, just use the same values that you used for them. This is also where you will point to the output from said program, using `--demographicHistory`. If you are not simulating under an inferred history, simply do not include this option. Importantly, you can also set a value for the maximum recombination rate to be simulated using `--upperRhoThetaRatio`. If you have an a priori estimate for an upper bound to the ratio of rho to theta go ahead and set this here. Keep in mind that higher values will dramatically slow the coalescent simulations. We recommend using the default number of train/test/validation simulation examples, but if you want to simulate more examples, go right ahead. `ReLERNN_SIMULATE` then uses msprime to simulate 100k training examples and 1k validation and test examples. All output files will be generated in subdirectories within the path provided to `--projectDir`. It is required that you use the same projectDir for all four ReLERNN commands. If you want to run ReLERNN of multiple populations/taxa, you can run them independently using a unique projectDir for each. This step is simulation heavy and runtimes will strongly depend on the inferred population size.\n\nThe complete list of arguments used in `ReLERNN_SIMULATE` is found below:\n```\nReLERNN_SIMULATE -h\n\nusage: ReLERNN_SIMULATE [-h] [-v VCF] [-g GENOME] [-m MASK] [-d OUTDIR]\n                        [-n DEM] [-u MU] [-l GENTIME] [-r UPRTR] [-t NCPU]\n                        [--phased] [--unphased] [--forceDiploid] [--phaseError PHASEERROR]\n                        [--maxWinSize WINSIZEMX] [--maskThresh MASKTHRESH]\n                        [--nTrain NTRAIN] [--nVali NVALI] [--nTest NTEST]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v VCF, --vcf VCF     Filtered and QC-checked VCF file. Important: Every row\n                        must correspond to a biallelic SNP with no missing\n                        data!\n  -g GENOME, --genome GENOME\n                        BED-formatted (i.e. zero-based) file corresponding to\n                        chromosomes and positions to consider\n  -m MASK, --mask MASK  BED-formatted file corresponding to inaccessible bases\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -n DEM, --demographicHistory DEM\n                        Output file from either stairwayplot, SMC++, or MSMC\n  -u MU, --assumedMu MU\n                        Assumed per-base mutation rate\n  -l GENTIME, --assumedGenTime GENTIME\n                        Assumed generation time (in years)\n  -r UPRTR, --upperRhoThetaRatio UPRTR\n                        Assumed upper bound for the ratio of rho to theta\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --phased              VCF file is phased\n  --unphased            VCF file is unphased\n  --forceDiploid        Treats all samples as diploids\n                        with missing data (bad idea; see README)\n  --phaseError PHASEERROR\n                        Fraction of bases simulated with incorrect phasing\n  --maxWinSize WINSIZEMX\n                        Max number of sites per window to train on. Important:\n                        too many sites causes problems in training\n  --maskThresh MASKTHRESH\n                        Discard windows where >= maskThresh percent of sites\n                        are inaccessible\n  --nTrain NTRAIN       Number of training examples to simulate\n  --nVali NVALI         Number of validation examples to simulate\n  --nTest NTEST         Number of test examples to simulate\n```\n\n\n### Step 2) ReLERNN_TRAIN\n`ReLERNN_TRAIN` takes the simulations created by `ReLERNN_SIMULATE` and uses them to train a recurrent neural network. Again, we recommend using the defaults for `--nEpochs` and `--nValSteps`, but if you would like to do more training, feel free. To set the GPU to be used for machines with multiple dedicated GPUs use `--gpuID` (e.g. if running an analysis on two populations simultaneously, set `--gpuID 0` for the first population and `--gpuID 1` for the second). `ReLERNN_TRAIN` outputs some basic metrics of the training results for you, generating the figure `$/projectDir/networks/vcfprefix.pdf`.\n\nThe complete list of arguments used in `ReLERNN_TRAIN` is found below:\n```\nReLERNN_TRAIN -h\n\nusage: ReLERNN_TRAIN [-h] [-d OUTDIR] [--nEpochs NEPOCHS]\n                     [--nValSteps NVALSTEPS] [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --nEpochs NEPOCHS     Number of epochs to train over\n  --nValSteps NVALSTEPS\n                        Number of validation steps\n  --gpuID GPUID         Identifier specifying which GPU to use\n```\n\n\n\n### Step 3) ReLERNN_PREDICT\n`ReLERNN_PREDICT` now takes the same VCF file you used in `ReLERNN_SIMULATE` and predicts per-base recombination rates in non-overlapping windows across the genome. The output file of predictions will be created as `$/projectDir/vcfprefix.PREDICT.txt`. It is important to note that the window size used for predictions might be different for different chromosomes. A complete list of the window sizes used for each chromosome can be found in third column of `$/projectDir/networks/windowSizes.txt`. Use the optional `--minSites` argument to exclude windows with fewer than the desired number of SNPs. If you are not interested in estimating confidence intervals around the predictions, your ReLERNN analysis is now finished.\n\n\nThe complete list of arguments used in `ReLERNN_PREDICT` is found below:\n```\nReLERNN_PREDICT -h\n\nusage: ReLERNN_PREDICT [-h] [-v VCF] [-d OUTDIR] [--minSites MINS]\n                       [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v VCF, --vcf VCF     Filtered and QC-checked VCF file. Important: Every row\n                        must correspond to a biallelic SNP with no missing\n                        data!\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --minSites MINS       Minimum number of SNPs in a genomic window required to\n                        return a prediction\n  --gpuID GPUID         Identifier specifying which GPU to use\n```\n\n### Optional Step 4) ReLERNN_BSCORRECT\nHowever, you might want to have an idea of the uncertainty around your predictions. This is where `ReLERNN_BSCORRECT` comes in. `ReLERNN_BSCORRECT` generates 95% confidence intervals around each prediction, and additionally attempts to correct for systematic bias ([see Materials and Methods](https://www.biorxiv.org/content/biorxiv/early/2019/08/16/662247.full.pdf)). It does this by simulated a set of `--nReps` examples at each of `nSlice` recombination rate bins. It then uses the network that was trained in `ReLERNN_TRAIN` and estimates the distribution of predictions around each know recombination rate. The result is both an estimate of uncertainty, and a prediction that has been slightly corrected to account for biases in how the network predicts in this area of parameter space. The resulting file is created as `$/projectDir/vcfprefix.PREDICT.BSCORRECT.txt`, and is formatted similarly to `$/projectDir/vcfprefix.PREDICT.txt`, with the addition of columns for the low and high 95CI bounds. Note that this step is simulation heavy and runtimes can be slow.\n\nThe complete list of arguments used in `ReLERNN_BSCORRECT` is found below:\n```\nReLERNN_BSCORRECT -h\n\nusage: ReLERNN_BSCORRECT [-h] [-d OUTDIR] [-t NCPU] [--gpuID GPUID]\n                         [--nSlice NSLICE] [--nReps NREPS]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --gpuID GPUID         Identifier specifying which GPU to use\n  --nSlice NSLICE       Number of recombination rate bins to simulate over\n  --nReps NREPS         Number of simulations per step\n```\n\n## Estimating a recombination landscape from pool-seq data\n\nSimilar to the directions above, the ReLERNN pipeline for pool-seq data is executed using four commands: `ReLERNN_SIMULATE_POOL`, `ReLERNN_TRAIN_POOL`, `ReLERNN_PREDICT_POOL`, and the optional `ReLERNN_BSCORRECT`.\n\n### Before running ReLERNN\nReLERNN for pool-seq analyses takes as input a file of genomic positions and allele frequencies (herein a 'POOLFILE'; see example file).\n\nSimilar to ReLERNN for individually sequenced chromosomes, if you want to make predictions based on equilibrium simulations, you can skip ahead to executing `ReLERNN_SIMULATE_POOL`.\nWhile ReLERNN is generally robust to demographic model misspecification, prediction accuracy may potentially be improved by simulating the training set under a demographic history that accurately matches that of your sample. ReLERNN optionally takes the raw output files from three popular demographic history inference programs ([stairwayplot_v1](https://sites.google.com/site/jpopgen/stairway-plot), [SMC++](https://github.com/popgenmethods/smcpp), and [MSMC](https://github.com/stschiff/msmc)), and simulates a training set under these histories. It is up to the user to perform the proper due diligence to ensure that the population size histories reported by these programs are sound. In our opinion, unless you know exactly how these programs work and you expect your data to represent a history dramatically different from equilibrium, you are better off skipping this step and training ReLERNN on equilibrium simulations. Once you have run one of the demographic history inference programs listed above, you simply provide the raw output file from that program to ReLERNN_SIMULATE_POOL using the `--demographicHistory` option.\n\n\n### Step 1) ReLERNN_SIMULATE_POOL\n`ReLERNN_SIMULATE_POOL` reads your POOLFILE and splits it by chromosome. The number of chromosomes in the pool must be specified using the `--sampleDepth` argument. The genomic chromosomes to be evaluated must be specified by providing a BED file of said positions using the `--genome` argument. A BED-formatted accessibility mask (with non-overlapping ascending windows) may be optionally provided using the `--mask` option. It is required that the POOLFILE use the extension `.pool`. The prefix of that file will serve as the prefix used for all output files (e.g. running ReLERNN on the file `population7.pool` will generate the result file `population7.PREDICT.txt`). It is strongly recommended that you use the default setting for `--maxSites`, larger values can cause training to fail and smaller values can result in lower accuracy. Users are required to provide an estimate of the per-base mutation rate for your sample, along with an estimate for generation time (in years). If you previously ran one of the demographic history inference programs listed above, just use the same values that you used for them. This is also where you will point to the output from said program, using `--demographicHistory`. If you are not simulating under an inferred history, simply do not include this option. Importantly, you can also set a value for the maximum recombination rate to be simulated using `--upperRhoThetaRatio`. If you have an a priori estimate for an upper bound to the ratio of rho to theta go ahead and set this here. Keep in mind that higher values will dramatically slow the coalescent simulations. We recommend using the default number of train/test/validation simulation examples, but if you want to simulate more examples, go right ahead. `ReLERNN_SIMULATE_POOL` then uses msprime to simulate 100k training examples and 1k validation and test examples. All output files will be generated in subdirectories within the path provided to `--projectDir`. It is required that you use the same projectDir for all four ReLERNN commands. If you want to run ReLERNN of multiple populations/taxa, you can run them independently using a unique projectDir for each. This step is simulation heavy and runtimes will strongly depend on the inferred population size.\n\nThe complete list of arguments used in `ReLERNN_SIMULATE_POOL` is found below:\n```\nReLERNN_SIMULATE_POOL -h\n\nusage: ReLERNN_SIMULATE_POOL [-h] [-p POOL] [--sampleDepth SAMD] [-g GENOME] [-m MASK] [-d OUTDIR]\n                        [-n DEM] [-u MU] [-l GENTIME] [-r UPRTR] [-t NCPU]\n                        [--maxSites WINSIZEMX] [--maskThresh MASKTHRESH]\n                        [--nTrain NTRAIN] [--nVali NVALI] [--nTest NTEST]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -p POOL, --pool POOL     Filtered and QC-checked POOL file.\n  --sampleDepth SAMD    Number of chromosomes in pool\n  -g GENOME, --genome GENOME\n                        BED-formatted (i.e. zero-based) file corresponding to\n                        chromosomes and positions to consider\n  -m MASK, --mask MASK  BED-formatted file corresponding to inaccessible bases\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -n DEM, --demographicHistory DEM\n                        Output file from either stairwayplot, SMC++, or MSMC\n  -u MU, --assumedMu MU\n                        Assumed per-base mutation rate\n  -l GENTIME, --assumedGenTime GENTIME\n                        Assumed generation time (in years)\n  -r UPRTR, --upperRhoThetaRatio UPRTR\n                        Assumed upper bound for the ratio of rho to theta\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --maxSites WINSIZEMX\n                        Max number of sites per window to train on. Important:\n                        too many sites causes problems in training\n  --maskThresh MASKTHRESH\n                        Discard windows where >= maskThresh percent of sites\n                        are inaccessible\n  --nTrain NTRAIN       Number of training examples to simulate\n  --nVali NVALI         Number of validation examples to simulate\n  --nTest NTEST         Number of test examples to simulate\n```\n\n\n### Step 2) ReLERNN_TRAIN_POOL\n`ReLERNN_TRAIN_POOL` takes the simulations created by `ReLERNN_SIMULATE_POOL` and uses them to train a recurrent neural network. The only difference here is that the mean read depth of the pool must be specified using the `--readDepth` argument. You can also specify a minor allele frequency threshold (`--maf`), if a similar threshold was used to generate your POOLFILE. Again, we recommend using the defaults for `--nEpochs` and `--nValSteps`, but if you would like to do more training, feel free. To set the GPU to be used for machines with multiple dedicated GPUs use `--gpuID` (e.g. if running an analysis on two populations simultaneously, set `--gpuID 0` for the first population and `--gpuID 1` for the second). `ReLERNN_TRAIN_POOL` outputs some basic metrics of the training results for you, generating the figure `$/projectDir/networks/poolprefix.pdf`.\n\nThe complete list of arguments used in `ReLERNN_TRAIN_POOL` is found below:\n```\nReLERNN_TRAIN_POOL -h\n\nusage: ReLERNN_TRAIN_POOL [-h] [-d OUTDIR] [--readDepth SEQD] [--maf MAF] [--nEpochs NEPOCHS]\n                     [--nValSteps NVALSTEPS] [-t NCPU] [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --readDepth SEQD     Mean read depth of the pool\n  --maf MAF     discard simulated sites with allele frequencies < maf\n  --nEpochs NEPOCHS     Number of epochs to train over\n  --nValSteps NVALSTEPS\n                        Number of validation steps\n  -t NCPU, --nCPU NCPU           Number of CPUs to use\n  --gpuID GPUID         Identifier specifying which GPU to use\n```\n\n\n\n### Step 3) ReLERNN_PREDICT_POOL\n`ReLERNN_PREDICT_POOL` now takes the same POOL file you used in `ReLERNN_SIMULATE_POOL` and predicts per-base recombination rates in non-overlapping windows across the genome. The output file of predictions will be created as `$/projectDir/poolprefix.PREDICT.txt`. It is important to note that the window size used for predictions might be different for different chromosomes. A complete list of the window sizes used for each chromosome can be found in third column of `$/projectDir/networks/windowSizes.txt`. Use the optional `--minSites` argument to exclude windows with fewer than the desired number of SNPs. If you are not interested in estimating confidence intervals around the predictions, your ReLERNN analysis is now finished.\n\n\nThe complete list of arguments used in `ReLERNN_PREDICT_POOL` is found below:\n```\nReLERNN_PREDICT_POOL -h\n\nusage: ReLERNN_PREDICT [-h] [-p POOL] [-d OUTDIR] [--minSites MINS]\n                       [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -p POOL, --pool POOL     Filtered and QC-checked POOL file.\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --minSites MINS       Minimum number of SNPs in a genomic window required to\n                        return a prediction\n  --gpuID GPUID         Identifier specifying which GPU to use\n```\n\n### Optional Step 4) ReLERNN_BSCORRECT\nThis step is exactly the same as in ReLERNN for individually sequenced chromosomes (above).\n\nThe complete list of arguments used in `ReLERNN_BSCORRECT` is found below:\n```\nReLERNN_BSCORRECT -h\n\nusage: ReLERNN_BSCORRECT [-h] [-d OUTDIR] [-t NCPU] [--gpuID GPUID]\n                         [--nSlice NSLICE] [--nReps NREPS]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --gpuID GPUID         Identifier specifying which GPU to use\n  --nSlice NSLICE       Number of recombination rate bins to simulate over\n  --nReps NREPS         Number of simulations per step\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kern-lab/ReLERNN/", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "ReLERNN", "package_url": "https://pypi.org/project/ReLERNN/", "platform": "", "project_url": "https://pypi.org/project/ReLERNN/", "project_urls": {"Homepage": "https://github.com/kern-lab/ReLERNN/"}, "release_url": "https://pypi.org/project/ReLERNN/0.2/", "requires_dist": ["msprime (>=0.7.4)", "scikit-learn (>=0.22.1)", "matplotlib (>=3.1.3)", "scikit-allel (>=1.2.1)"], "requires_python": "", "summary": "ReLERNN: Recombination Landscape Estimation using Recurrent Neural Networks", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1><em>ReLERNN</em></h1>\n<h2><em>Recombination Landscape Estimation using Recurrent Neural Networks</em></h2>\n<p>====================================================================</p>\n<p>ReLERNN uses deep learning to infer the genome-wide landscape of recombination from as few as four individually sequenced chromosomes, or from allele frequencies inferred by pooled sequencing.\nThis repository contains the code and instructions required to run ReLERNN, and includes example files to ensure everything is working properly. The current manuscript detailing ReLERNN can be found <a href=\"https://www.biorxiv.org/content/biorxiv/early/2019/08/16/662247.full.pdf\" rel=\"nofollow\">here</a>.</p>\n<h2>Recommended installation on linux</h2>\n<p>Install <code>tensorflow 2</code> on your system. Directions can be found <a href=\"https://www.tensorflow.org/install\" rel=\"nofollow\">here</a>. You will need to install the CUDA toolkit and CuDNN as well.</p>\n<p>Further dependencies for ReLERNN can be installed with pip.\nThis is done with the following commands:</p>\n<pre><code>$ git clone https://github.com/kern-lab/ReLERNN.git\n$ cd ReLERNN\n$ pip install -r requirements.txt\n$ python setup.py install\n</code></pre>\n<p>It should be as simple as that.</p>\n<h2>Testing ReLERNN</h2>\n<p>An example VCF file (5 contigs; 10 haploid chromosomes) and a shell script for running ReLERNN's four modules is located in <code>$/ReLERNN/examples</code>.\nTo test the functionality of ReLERNN simply use the following commands:</p>\n<pre><code>$ cd examples\n$ ./example_pipeline.sh\n</code></pre>\n<p>Provided everything worked as planned, <code>$ReLERNN/examples/example_output/</code> should be populated with a few directories along with the files: <code>example.PREDICT.txt</code> and <code>example.PREDICT.BSCORRECT.txt</code>.\nThe latter is the finalized output file with your recombination rate predictions and estimates of uncertainty.</p>\n<p>The above example took 57 seconds to complete on a Xeon machine using four CPUs and one NVIDIA 2070 GPU.\nNote that the parameters used for this example were designed only to test the success of the installation, not to make accurate predictions.\nPlease use the guidelines below for the best results when analyzing real data.\nReLERNN requires the use of a CUDA-Enabled NVIDIA GPU.</p>\n<p>You can now test the functionality of ReLERNN for use with pool-seq data by using the following commands:</p>\n<pre><code>$ cd examples\n$ ./example_pipeline_pool.sh\n</code></pre>\n<h2>Estimating a recombination landscape from individually sequenced chromosomes</h2>\n<p>The ReLERNN pipeline is executed using four commands: <code>ReLERNN_SIMULATE</code>, <code>ReLERNN_TRAIN</code>, <code>ReLERNN_PREDICT</code>, and the optional <code>ReLERNN_BSCORRECT</code> (see the <a href=\"./methodFlow.png\" rel=\"nofollow\">Method flow diagram</a>).</p>\n<h3>Before running ReLERNN</h3>\n<p>ReLERNN takes as input a VCF file of biallelic variants. Users should use appropriate QC techniques (filtering low-quality variants, etc.) and remove non-biallelic variants before running ReLERNN. Small contigs (&lt;&lt; 250 SNPs) should not be included in the genome file <code>--genome</code>, though these do not need to be removed from the VCF.\nReLERNN also requires that the number of sampled chromosomes is identical across all contigs, and VCFs should be filtered accordingly. Hemizygous chromosomes or haploid samples in an otherwise diploid dataset\nshould ideally be run separately using a separate VCF. It is possible to treat hemizygous chromosomes as \"diploids with missing data\" using the <code>--forceDiploid</code> option, however this is not recommended.\nIt is now possible to run ReLERNN on VCFs with missing genotypes (coded as a <code>.</code>).</p>\n<p>If you want to make predictions based on equilibrium simulations, you can skip ahead to executing <code>ReLERNN_SIMULATE</code>.\nWhile ReLERNN is generally robust to demographic model misspecification, prediction accuracy may potentially be improved by simulating the training set under a demographic history that accurately matches that of your sample. ReLERNN optionally takes the raw output files from three popular demographic history inference programs (<a href=\"https://sites.google.com/site/jpopgen/stairway-plot\" rel=\"nofollow\">stairwayplot_v1</a>, <a href=\"https://github.com/popgenmethods/smcpp\" rel=\"nofollow\">SMC++</a>, and <a href=\"https://github.com/stschiff/msmc\" rel=\"nofollow\">MSMC</a>), and simulates a training set under these histories. It is up to the user to perform the proper due diligence to ensure that the population size histories reported by these programs are sound. In our opinion, unless you know exactly how these programs work and you expect your data to represent a history dramatically different from equilibrium, you are better off skipping this step and training ReLERNN on equilibrium simulations. Once you have run one of the demographic history inference programs listed above, you simply provide the raw output file from that program to ReLERNN_SIMULATE using the <code>--demographicHistory</code> option.</p>\n<h3>Step 1) ReLERNN_SIMULATE</h3>\n<p><code>ReLERNN_SIMULATE</code> reads your VCF file and splits it by chromosome. The chromosomes to be evaluated must be specified by providing a BED file of said positions using the <code>--genome</code> argument. A BED-formatted accessibility mask (with non-overlapping ascending windows) may be optionally provided using the <code>--mask</code> option. Use the <code>--phased</code> or <code>--unphased</code> flag to train using phased or unphased genotypes (the default is unphased). It is required that the VCF file use the extension <code>.vcf</code>. The prefix of that file will serve as the prefix used for all output files (e.g. running ReLERNN on the file <code>population7.vcf</code> will generate the result file <code>population7.PREDICT.txt</code>). It is strongly recommended that you use the default setting for <code>--maxWinSize</code>, larger values can cause training to fail and smaller values can result in lower accuracy. Users are required to provide an estimate of the per-base mutation rate for your sample, along with an estimate for generation time (in years). If you previously ran one of the demographic history inference programs listed above, just use the same values that you used for them. This is also where you will point to the output from said program, using <code>--demographicHistory</code>. If you are not simulating under an inferred history, simply do not include this option. Importantly, you can also set a value for the maximum recombination rate to be simulated using <code>--upperRhoThetaRatio</code>. If you have an a priori estimate for an upper bound to the ratio of rho to theta go ahead and set this here. Keep in mind that higher values will dramatically slow the coalescent simulations. We recommend using the default number of train/test/validation simulation examples, but if you want to simulate more examples, go right ahead. <code>ReLERNN_SIMULATE</code> then uses msprime to simulate 100k training examples and 1k validation and test examples. All output files will be generated in subdirectories within the path provided to <code>--projectDir</code>. It is required that you use the same projectDir for all four ReLERNN commands. If you want to run ReLERNN of multiple populations/taxa, you can run them independently using a unique projectDir for each. This step is simulation heavy and runtimes will strongly depend on the inferred population size.</p>\n<p>The complete list of arguments used in <code>ReLERNN_SIMULATE</code> is found below:</p>\n<pre><code>ReLERNN_SIMULATE -h\n\nusage: ReLERNN_SIMULATE [-h] [-v VCF] [-g GENOME] [-m MASK] [-d OUTDIR]\n                        [-n DEM] [-u MU] [-l GENTIME] [-r UPRTR] [-t NCPU]\n                        [--phased] [--unphased] [--forceDiploid] [--phaseError PHASEERROR]\n                        [--maxWinSize WINSIZEMX] [--maskThresh MASKTHRESH]\n                        [--nTrain NTRAIN] [--nVali NVALI] [--nTest NTEST]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v VCF, --vcf VCF     Filtered and QC-checked VCF file. Important: Every row\n                        must correspond to a biallelic SNP with no missing\n                        data!\n  -g GENOME, --genome GENOME\n                        BED-formatted (i.e. zero-based) file corresponding to\n                        chromosomes and positions to consider\n  -m MASK, --mask MASK  BED-formatted file corresponding to inaccessible bases\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -n DEM, --demographicHistory DEM\n                        Output file from either stairwayplot, SMC++, or MSMC\n  -u MU, --assumedMu MU\n                        Assumed per-base mutation rate\n  -l GENTIME, --assumedGenTime GENTIME\n                        Assumed generation time (in years)\n  -r UPRTR, --upperRhoThetaRatio UPRTR\n                        Assumed upper bound for the ratio of rho to theta\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --phased              VCF file is phased\n  --unphased            VCF file is unphased\n  --forceDiploid        Treats all samples as diploids\n                        with missing data (bad idea; see README)\n  --phaseError PHASEERROR\n                        Fraction of bases simulated with incorrect phasing\n  --maxWinSize WINSIZEMX\n                        Max number of sites per window to train on. Important:\n                        too many sites causes problems in training\n  --maskThresh MASKTHRESH\n                        Discard windows where &gt;= maskThresh percent of sites\n                        are inaccessible\n  --nTrain NTRAIN       Number of training examples to simulate\n  --nVali NVALI         Number of validation examples to simulate\n  --nTest NTEST         Number of test examples to simulate\n</code></pre>\n<h3>Step 2) ReLERNN_TRAIN</h3>\n<p><code>ReLERNN_TRAIN</code> takes the simulations created by <code>ReLERNN_SIMULATE</code> and uses them to train a recurrent neural network. Again, we recommend using the defaults for <code>--nEpochs</code> and <code>--nValSteps</code>, but if you would like to do more training, feel free. To set the GPU to be used for machines with multiple dedicated GPUs use <code>--gpuID</code> (e.g. if running an analysis on two populations simultaneously, set <code>--gpuID 0</code> for the first population and <code>--gpuID 1</code> for the second). <code>ReLERNN_TRAIN</code> outputs some basic metrics of the training results for you, generating the figure <code>$/projectDir/networks/vcfprefix.pdf</code>.</p>\n<p>The complete list of arguments used in <code>ReLERNN_TRAIN</code> is found below:</p>\n<pre><code>ReLERNN_TRAIN -h\n\nusage: ReLERNN_TRAIN [-h] [-d OUTDIR] [--nEpochs NEPOCHS]\n                     [--nValSteps NVALSTEPS] [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --nEpochs NEPOCHS     Number of epochs to train over\n  --nValSteps NVALSTEPS\n                        Number of validation steps\n  --gpuID GPUID         Identifier specifying which GPU to use\n</code></pre>\n<h3>Step 3) ReLERNN_PREDICT</h3>\n<p><code>ReLERNN_PREDICT</code> now takes the same VCF file you used in <code>ReLERNN_SIMULATE</code> and predicts per-base recombination rates in non-overlapping windows across the genome. The output file of predictions will be created as <code>$/projectDir/vcfprefix.PREDICT.txt</code>. It is important to note that the window size used for predictions might be different for different chromosomes. A complete list of the window sizes used for each chromosome can be found in third column of <code>$/projectDir/networks/windowSizes.txt</code>. Use the optional <code>--minSites</code> argument to exclude windows with fewer than the desired number of SNPs. If you are not interested in estimating confidence intervals around the predictions, your ReLERNN analysis is now finished.</p>\n<p>The complete list of arguments used in <code>ReLERNN_PREDICT</code> is found below:</p>\n<pre><code>ReLERNN_PREDICT -h\n\nusage: ReLERNN_PREDICT [-h] [-v VCF] [-d OUTDIR] [--minSites MINS]\n                       [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v VCF, --vcf VCF     Filtered and QC-checked VCF file. Important: Every row\n                        must correspond to a biallelic SNP with no missing\n                        data!\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --minSites MINS       Minimum number of SNPs in a genomic window required to\n                        return a prediction\n  --gpuID GPUID         Identifier specifying which GPU to use\n</code></pre>\n<h3>Optional Step 4) ReLERNN_BSCORRECT</h3>\n<p>However, you might want to have an idea of the uncertainty around your predictions. This is where <code>ReLERNN_BSCORRECT</code> comes in. <code>ReLERNN_BSCORRECT</code> generates 95% confidence intervals around each prediction, and additionally attempts to correct for systematic bias (<a href=\"https://www.biorxiv.org/content/biorxiv/early/2019/08/16/662247.full.pdf\" rel=\"nofollow\">see Materials and Methods</a>). It does this by simulated a set of <code>--nReps</code> examples at each of <code>nSlice</code> recombination rate bins. It then uses the network that was trained in <code>ReLERNN_TRAIN</code> and estimates the distribution of predictions around each know recombination rate. The result is both an estimate of uncertainty, and a prediction that has been slightly corrected to account for biases in how the network predicts in this area of parameter space. The resulting file is created as <code>$/projectDir/vcfprefix.PREDICT.BSCORRECT.txt</code>, and is formatted similarly to <code>$/projectDir/vcfprefix.PREDICT.txt</code>, with the addition of columns for the low and high 95CI bounds. Note that this step is simulation heavy and runtimes can be slow.</p>\n<p>The complete list of arguments used in <code>ReLERNN_BSCORRECT</code> is found below:</p>\n<pre><code>ReLERNN_BSCORRECT -h\n\nusage: ReLERNN_BSCORRECT [-h] [-d OUTDIR] [-t NCPU] [--gpuID GPUID]\n                         [--nSlice NSLICE] [--nReps NREPS]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --gpuID GPUID         Identifier specifying which GPU to use\n  --nSlice NSLICE       Number of recombination rate bins to simulate over\n  --nReps NREPS         Number of simulations per step\n</code></pre>\n<h2>Estimating a recombination landscape from pool-seq data</h2>\n<p>Similar to the directions above, the ReLERNN pipeline for pool-seq data is executed using four commands: <code>ReLERNN_SIMULATE_POOL</code>, <code>ReLERNN_TRAIN_POOL</code>, <code>ReLERNN_PREDICT_POOL</code>, and the optional <code>ReLERNN_BSCORRECT</code>.</p>\n<h3>Before running ReLERNN</h3>\n<p>ReLERNN for pool-seq analyses takes as input a file of genomic positions and allele frequencies (herein a 'POOLFILE'; see example file).</p>\n<p>Similar to ReLERNN for individually sequenced chromosomes, if you want to make predictions based on equilibrium simulations, you can skip ahead to executing <code>ReLERNN_SIMULATE_POOL</code>.\nWhile ReLERNN is generally robust to demographic model misspecification, prediction accuracy may potentially be improved by simulating the training set under a demographic history that accurately matches that of your sample. ReLERNN optionally takes the raw output files from three popular demographic history inference programs (<a href=\"https://sites.google.com/site/jpopgen/stairway-plot\" rel=\"nofollow\">stairwayplot_v1</a>, <a href=\"https://github.com/popgenmethods/smcpp\" rel=\"nofollow\">SMC++</a>, and <a href=\"https://github.com/stschiff/msmc\" rel=\"nofollow\">MSMC</a>), and simulates a training set under these histories. It is up to the user to perform the proper due diligence to ensure that the population size histories reported by these programs are sound. In our opinion, unless you know exactly how these programs work and you expect your data to represent a history dramatically different from equilibrium, you are better off skipping this step and training ReLERNN on equilibrium simulations. Once you have run one of the demographic history inference programs listed above, you simply provide the raw output file from that program to ReLERNN_SIMULATE_POOL using the <code>--demographicHistory</code> option.</p>\n<h3>Step 1) ReLERNN_SIMULATE_POOL</h3>\n<p><code>ReLERNN_SIMULATE_POOL</code> reads your POOLFILE and splits it by chromosome. The number of chromosomes in the pool must be specified using the <code>--sampleDepth</code> argument. The genomic chromosomes to be evaluated must be specified by providing a BED file of said positions using the <code>--genome</code> argument. A BED-formatted accessibility mask (with non-overlapping ascending windows) may be optionally provided using the <code>--mask</code> option. It is required that the POOLFILE use the extension <code>.pool</code>. The prefix of that file will serve as the prefix used for all output files (e.g. running ReLERNN on the file <code>population7.pool</code> will generate the result file <code>population7.PREDICT.txt</code>). It is strongly recommended that you use the default setting for <code>--maxSites</code>, larger values can cause training to fail and smaller values can result in lower accuracy. Users are required to provide an estimate of the per-base mutation rate for your sample, along with an estimate for generation time (in years). If you previously ran one of the demographic history inference programs listed above, just use the same values that you used for them. This is also where you will point to the output from said program, using <code>--demographicHistory</code>. If you are not simulating under an inferred history, simply do not include this option. Importantly, you can also set a value for the maximum recombination rate to be simulated using <code>--upperRhoThetaRatio</code>. If you have an a priori estimate for an upper bound to the ratio of rho to theta go ahead and set this here. Keep in mind that higher values will dramatically slow the coalescent simulations. We recommend using the default number of train/test/validation simulation examples, but if you want to simulate more examples, go right ahead. <code>ReLERNN_SIMULATE_POOL</code> then uses msprime to simulate 100k training examples and 1k validation and test examples. All output files will be generated in subdirectories within the path provided to <code>--projectDir</code>. It is required that you use the same projectDir for all four ReLERNN commands. If you want to run ReLERNN of multiple populations/taxa, you can run them independently using a unique projectDir for each. This step is simulation heavy and runtimes will strongly depend on the inferred population size.</p>\n<p>The complete list of arguments used in <code>ReLERNN_SIMULATE_POOL</code> is found below:</p>\n<pre><code>ReLERNN_SIMULATE_POOL -h\n\nusage: ReLERNN_SIMULATE_POOL [-h] [-p POOL] [--sampleDepth SAMD] [-g GENOME] [-m MASK] [-d OUTDIR]\n                        [-n DEM] [-u MU] [-l GENTIME] [-r UPRTR] [-t NCPU]\n                        [--maxSites WINSIZEMX] [--maskThresh MASKTHRESH]\n                        [--nTrain NTRAIN] [--nVali NVALI] [--nTest NTEST]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -p POOL, --pool POOL     Filtered and QC-checked POOL file.\n  --sampleDepth SAMD    Number of chromosomes in pool\n  -g GENOME, --genome GENOME\n                        BED-formatted (i.e. zero-based) file corresponding to\n                        chromosomes and positions to consider\n  -m MASK, --mask MASK  BED-formatted file corresponding to inaccessible bases\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -n DEM, --demographicHistory DEM\n                        Output file from either stairwayplot, SMC++, or MSMC\n  -u MU, --assumedMu MU\n                        Assumed per-base mutation rate\n  -l GENTIME, --assumedGenTime GENTIME\n                        Assumed generation time (in years)\n  -r UPRTR, --upperRhoThetaRatio UPRTR\n                        Assumed upper bound for the ratio of rho to theta\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --maxSites WINSIZEMX\n                        Max number of sites per window to train on. Important:\n                        too many sites causes problems in training\n  --maskThresh MASKTHRESH\n                        Discard windows where &gt;= maskThresh percent of sites\n                        are inaccessible\n  --nTrain NTRAIN       Number of training examples to simulate\n  --nVali NVALI         Number of validation examples to simulate\n  --nTest NTEST         Number of test examples to simulate\n</code></pre>\n<h3>Step 2) ReLERNN_TRAIN_POOL</h3>\n<p><code>ReLERNN_TRAIN_POOL</code> takes the simulations created by <code>ReLERNN_SIMULATE_POOL</code> and uses them to train a recurrent neural network. The only difference here is that the mean read depth of the pool must be specified using the <code>--readDepth</code> argument. You can also specify a minor allele frequency threshold (<code>--maf</code>), if a similar threshold was used to generate your POOLFILE. Again, we recommend using the defaults for <code>--nEpochs</code> and <code>--nValSteps</code>, but if you would like to do more training, feel free. To set the GPU to be used for machines with multiple dedicated GPUs use <code>--gpuID</code> (e.g. if running an analysis on two populations simultaneously, set <code>--gpuID 0</code> for the first population and <code>--gpuID 1</code> for the second). <code>ReLERNN_TRAIN_POOL</code> outputs some basic metrics of the training results for you, generating the figure <code>$/projectDir/networks/poolprefix.pdf</code>.</p>\n<p>The complete list of arguments used in <code>ReLERNN_TRAIN_POOL</code> is found below:</p>\n<pre><code>ReLERNN_TRAIN_POOL -h\n\nusage: ReLERNN_TRAIN_POOL [-h] [-d OUTDIR] [--readDepth SEQD] [--maf MAF] [--nEpochs NEPOCHS]\n                     [--nValSteps NVALSTEPS] [-t NCPU] [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --readDepth SEQD     Mean read depth of the pool\n  --maf MAF     discard simulated sites with allele frequencies &lt; maf\n  --nEpochs NEPOCHS     Number of epochs to train over\n  --nValSteps NVALSTEPS\n                        Number of validation steps\n  -t NCPU, --nCPU NCPU           Number of CPUs to use\n  --gpuID GPUID         Identifier specifying which GPU to use\n</code></pre>\n<h3>Step 3) ReLERNN_PREDICT_POOL</h3>\n<p><code>ReLERNN_PREDICT_POOL</code> now takes the same POOL file you used in <code>ReLERNN_SIMULATE_POOL</code> and predicts per-base recombination rates in non-overlapping windows across the genome. The output file of predictions will be created as <code>$/projectDir/poolprefix.PREDICT.txt</code>. It is important to note that the window size used for predictions might be different for different chromosomes. A complete list of the window sizes used for each chromosome can be found in third column of <code>$/projectDir/networks/windowSizes.txt</code>. Use the optional <code>--minSites</code> argument to exclude windows with fewer than the desired number of SNPs. If you are not interested in estimating confidence intervals around the predictions, your ReLERNN analysis is now finished.</p>\n<p>The complete list of arguments used in <code>ReLERNN_PREDICT_POOL</code> is found below:</p>\n<pre><code>ReLERNN_PREDICT_POOL -h\n\nusage: ReLERNN_PREDICT [-h] [-p POOL] [-d OUTDIR] [--minSites MINS]\n                       [--gpuID GPUID]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -p POOL, --pool POOL     Filtered and QC-checked POOL file.\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  --minSites MINS       Minimum number of SNPs in a genomic window required to\n                        return a prediction\n  --gpuID GPUID         Identifier specifying which GPU to use\n</code></pre>\n<h3>Optional Step 4) ReLERNN_BSCORRECT</h3>\n<p>This step is exactly the same as in ReLERNN for individually sequenced chromosomes (above).</p>\n<p>The complete list of arguments used in <code>ReLERNN_BSCORRECT</code> is found below:</p>\n<pre><code>ReLERNN_BSCORRECT -h\n\nusage: ReLERNN_BSCORRECT [-h] [-d OUTDIR] [-t NCPU] [--gpuID GPUID]\n                         [--nSlice NSLICE] [--nReps NREPS]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d OUTDIR, --projectDir OUTDIR\n                        Directory for all project output. NOTE: the same\n                        projectDir must be used for all functions of ReLERNN\n  -t NCPU, --nCPU NCPU  Number of CPUs to use\n  --gpuID GPUID         Identifier specifying which GPU to use\n  --nSlice NSLICE       Number of recombination rate bins to simulate over\n  --nReps NREPS         Number of simulations per step\n</code></pre>\n\n          </div>"}, "last_serial": 6620419, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "40fd81f23915f663ba44b5f7ebee4a31", "sha256": "33052ae91d6f810bcded96a9c1e7a5601be86b08680b3a79322bab1632d305c6"}, "downloads": -1, "filename": "ReLERNN-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "40fd81f23915f663ba44b5f7ebee4a31", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23420, "upload_time": "2019-05-22T22:00:30", "upload_time_iso_8601": "2019-05-22T22:00:30.215440Z", "url": "https://files.pythonhosted.org/packages/5b/2d/8ee4712e79732828b6a7c9722930339c99ec02928a94c0fe5a78e5d7dc7a/ReLERNN-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b30c78722064a2c11148b177c528647a", "sha256": "75a7ba22e0305d97fa54ff8ebe850d3d6f997839ccd00497959d7974a967ca49"}, "downloads": -1, "filename": "ReLERNN-0.1.tar.gz", "has_sig": false, "md5_digest": "b30c78722064a2c11148b177c528647a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17501, "upload_time": "2019-05-22T22:00:32", "upload_time_iso_8601": "2019-05-22T22:00:32.283406Z", "url": "https://files.pythonhosted.org/packages/88/7a/8fa27c4e94805aa71fa8cde73ab9b7ed3cd8453586a7eeb96a9a25d84a60/ReLERNN-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "90d9fefe5251a8b8d078dd74701be6dc", "sha256": "ef1c6681ef6c0549d319bad739810b5d6c1ff091d31c34a78a5ae92dfc04c581"}, "downloads": -1, "filename": "ReLERNN-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "90d9fefe5251a8b8d078dd74701be6dc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 49487, "upload_time": "2020-02-13T00:56:16", "upload_time_iso_8601": "2020-02-13T00:56:16.781850Z", "url": "https://files.pythonhosted.org/packages/84/fd/3718125a59b9a90a53f19ce0af572aa57973f212e5896892c07f28568121/ReLERNN-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aaf31ffbb103ba2aa3c90c4e2bf462eb", "sha256": "3134c70973add65e93baee6486418f12a80bf6f67f3d1d2f6e8639e8883eeebd"}, "downloads": -1, "filename": "ReLERNN-0.2.tar.gz", "has_sig": false, "md5_digest": "aaf31ffbb103ba2aa3c90c4e2bf462eb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36351, "upload_time": "2020-02-13T00:56:18", "upload_time_iso_8601": "2020-02-13T00:56:18.129353Z", "url": "https://files.pythonhosted.org/packages/e5/3c/db92b7d6135237bb98293abbe25b80ace422cf773e0c221a54707f347ded/ReLERNN-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "90d9fefe5251a8b8d078dd74701be6dc", "sha256": "ef1c6681ef6c0549d319bad739810b5d6c1ff091d31c34a78a5ae92dfc04c581"}, "downloads": -1, "filename": "ReLERNN-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "90d9fefe5251a8b8d078dd74701be6dc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 49487, "upload_time": "2020-02-13T00:56:16", "upload_time_iso_8601": "2020-02-13T00:56:16.781850Z", "url": "https://files.pythonhosted.org/packages/84/fd/3718125a59b9a90a53f19ce0af572aa57973f212e5896892c07f28568121/ReLERNN-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aaf31ffbb103ba2aa3c90c4e2bf462eb", "sha256": "3134c70973add65e93baee6486418f12a80bf6f67f3d1d2f6e8639e8883eeebd"}, "downloads": -1, "filename": "ReLERNN-0.2.tar.gz", "has_sig": false, "md5_digest": "aaf31ffbb103ba2aa3c90c4e2bf462eb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36351, "upload_time": "2020-02-13T00:56:18", "upload_time_iso_8601": "2020-02-13T00:56:18.129353Z", "url": "https://files.pythonhosted.org/packages/e5/3c/db92b7d6135237bb98293abbe25b80ace422cf773e0c221a54707f347ded/ReLERNN-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:00 2020"}