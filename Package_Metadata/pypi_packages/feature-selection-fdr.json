{"info": {"author": "Mehdi Rostami", "author_email": "mehdi.rostamiforooshani@mail.utoronto.ca", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7"], "description": ">>> import numpy as np \n>>> from fs_fdr import barber_candes_selection, knockoff_features_construction, utils\n>>> \n>>> from sklearn.ensemble import GradientBoostingClassifier\n>>> #######################################################################################\n>>> #### Simulate data to check the performance of the methods.\n>>> #######################################################################################\n>>> \n>>> \n>>> type = \"classification\"\n>>> # First simulate some data\n>>> n, p, p1 = 1000, 50, 20\n>>> rho = 0.\n>>> mean = 0.\n>>> sd = 1.\n>>> error_std = 1.\n>>> r = [\"uniform\", .0, .5]\n>>> x = mean + sd * np.random.normal(0., 1., size=(n, p))\n>>> true_w = np.random.uniform(r[1], r[2], size=(p1, 1))\n>>> negate = np.random.binomial(n=1, p=.5, size=(p1, 1))\n>>> negate[np.where(negate==0.), :] = -1\n>>> true_w = true_w * negate\n>>> true_index = np.random.choice(np.arange(p), size = p1, replace=False)\n>>> true_index = np.sort(true_index)\n>>> xbeta = np.dot(x[:, true_index], true_w)\n>>> pr = 1/(1+np.exp(-xbeta))\n>>> t = (pr > .5) + 0.\n>>> \n>>> q = .1\n>>> # Step 2: Create knockoff features using the knockoff_method library \n>>> \n>>> # Set parameters\n>>> \n>>> selection_method = \"knockoff-MX\"\n>>> optimization = [\"ASDP\", \"selfblocks\", 50, 50]\n>>> \n>>> VI_stat = \"Diff\"\n>>> \n>>> \n>>> myknockoff = knockoff_features_construction.Knockoff(x, selection_method, optimization)\n>>> knockoff_attrs = myknockoff.knockoff_features()\n>>> x, x_tilda = knockoff_attrs.X, knockoff_attrs.X_tilde\n>>> \n>>> \n>>> \n>>> modeling = {\"model\":\"gradient boosting\", \"params\":\"classification fi\"}\n>>> \n>>> \n>>> data = [x, x_tilda, t] \n>>> knockoff_selection = barber_candes_selection.BarberCandesSelection(data, modeling, selection_method,q=q, VI_stat=VI_stat).selection()\n>>> \n>>> S_knock = knockoff_selection.S\n>>> FDR_UB = knockoff_selection.FDR_UB\n>>> \n>>> \n>>> \n>>> fdr_knock = 100*utils.FDR(S_knock, true_index)\n>>> power_knock = 100*utils.power(S_knock, true_index)\n>>> fnp_knock = 100*utils.FNP(S_knock, true_index, p)\n>>> print('------------Knockoff ({})-------------'.format(modeling[\"model\"]))\n>>> print(\"Empirical FDR: \" + str(100*np.round(FDR_UB, 2)) + \"%\")\n>>> print(\"FDR:  \" +str(fdr_knock) + \"%\")\n>>> print(\"power:  \"+str(power_knock) + \"%\") \n>>> print(\"FNP:  \"+str(fnp_knock) + \"%\")\n>>> \n>>> \n>>> ##########DSS\n>>> \n>>> \n>>> modeling = {\"model\":\"gradient boosting\", \"params\":\"classification fi\"}\n>>> selection_method = \"DSS\"\n>>> data = [x, t] \n>>> split_type = [\"sampling\", 5, 5]\n>>> prob = .7\n>>> DSS_selection = barber_candes_selection.BarberCandesSelection(data, modeling, selection_method,q=q).selection()\n>>> \n>>> S_dss = DSS_selection.S\n>>> FDR_UB = DSS_selection.FDR_UB\n>>> \n>>> \n>>> \n>>> fdr_dss = 100*utils.FDR(S_dss, true_index)\n>>> power_dss = 100*utils.power(S_dss, true_index)\n>>> fnp_dss = 100*utils.FNP(S_dss, true_index, p)\n>>> print('------------DSS ({})-------------'.format(modeling[\"model\"]))\n>>> print(\"Empirical FDR: \" + str(100*np.round(FDR_UB, 2)) + \"%\")\n>>> print(\"FDR:  \" +str(fdr_dss) + \"%\")\n>>> print(\"power:  \"+str(power_dss) + \"%\") \n>>> print(\"FNP:  \"+str(fnp_dss) + \"%\")\n>>> \n>>> \n>>> \n>>> ############### SVM\n>>> \n>>> modeling = {\"model\": \"not specified\", \"params\":\"given\"}\n>>> \n>>> from sklearn.svm import SVC\n>>> \n>>> svm = SVC(C=1., kernel=\"linear\")\n>>> svm_w = svm.fit(np.hstack((x, x_tilda)), t.ravel()).coef_\n>>> \n>>> selection_method = \"knockoff\" \n>>> knockoff_selection = barber_candes_selection.BarberCandesSelection(modeling=modeling, selection_method=selection_method, w = svm_w).selection()\n>>> \n>>> S_knock = knockoff_selection.S\n>>> FDR_UB = knockoff_selection.FDR_UB\n>>> print(\"empirical FDR: \" + str(100*np.round(FDR_UB, 2)))\n>>> \n>>> fdr_knock = 100*utils.FDR(S_knock, true_index)\n>>> power_knock = 100*utils.power(S_knock, true_index)\n>>> fnp_knock = 100*utils.FNP(S_knock, true_index, p)\n>>> print('------------Knockoff ({})-------------'.format(modeling[\"model\"]))\n>>> print(\"Empirical FDR: \" + str(100*np.round(FDR_UB, 2)) + \"%\")\n>>> print(\"FDR:  \" +str(fdr_knock) + \"%\")\n>>> print(\"power:  \"+str(power_knock) + \"%\") \n>>> print(\"FNP:  \"+str(fnp_knock) + \"%\")", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mehdirostami/feature_selection_fdr", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "feature-selection-fdr", "package_url": "https://pypi.org/project/feature-selection-fdr/", "platform": "", "project_url": "https://pypi.org/project/feature-selection-fdr/", "project_urls": {"Homepage": "https://github.com/mehdirostami/feature_selection_fdr"}, "release_url": "https://pypi.org/project/feature-selection-fdr/0.1/", "requires_dist": null, "requires_python": "", "summary": "Feature selection with FDR control.", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <pre>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from fs_fdr import barber_candes_selection, knockoff_features_construction, utils\n&gt;&gt;&gt;\n&gt;&gt;&gt; from sklearn.ensemble import GradientBoostingClassifier\n&gt;&gt;&gt; #######################################################################################\n&gt;&gt;&gt; #### Simulate data to check the performance of the methods.\n&gt;&gt;&gt; #######################################################################################\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; type = \"classification\"\n&gt;&gt;&gt; # First simulate some data\n&gt;&gt;&gt; n, p, p1 = 1000, 50, 20\n&gt;&gt;&gt; rho = 0.\n&gt;&gt;&gt; mean = 0.\n&gt;&gt;&gt; sd = 1.\n&gt;&gt;&gt; error_std = 1.\n&gt;&gt;&gt; r = [\"uniform\", .0, .5]\n&gt;&gt;&gt; x = mean + sd * np.random.normal(0., 1., size=(n, p))\n&gt;&gt;&gt; true_w = np.random.uniform(r[1], r[2], size=(p1, 1))\n&gt;&gt;&gt; negate = np.random.binomial(n=1, p=.5, size=(p1, 1))\n&gt;&gt;&gt; negate[np.where(negate==0.), :] = -1\n&gt;&gt;&gt; true_w = true_w * negate\n&gt;&gt;&gt; true_index = np.random.choice(np.arange(p), size = p1, replace=False)\n&gt;&gt;&gt; true_index = np.sort(true_index)\n&gt;&gt;&gt; xbeta = np.dot(x[:, true_index], true_w)\n&gt;&gt;&gt; pr = 1/(1+np.exp(-xbeta))\n&gt;&gt;&gt; t = (pr &gt; .5) + 0.\n&gt;&gt;&gt;\n&gt;&gt;&gt; q = .1\n&gt;&gt;&gt; # Step 2: Create knockoff features using the knockoff_method library\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Set parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; selection_method = \"knockoff-MX\"\n&gt;&gt;&gt; optimization = [\"ASDP\", \"selfblocks\", 50, 50]\n&gt;&gt;&gt;\n&gt;&gt;&gt; VI_stat = \"Diff\"\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; myknockoff = knockoff_features_construction.Knockoff(x, selection_method, optimization)\n&gt;&gt;&gt; knockoff_attrs = myknockoff.knockoff_features()\n&gt;&gt;&gt; x, x_tilda = knockoff_attrs.X, knockoff_attrs.X_tilde\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; modeling = {\"model\":\"gradient boosting\", \"params\":\"classification fi\"}\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = [x, x_tilda, t]\n&gt;&gt;&gt; knockoff_selection = barber_candes_selection.BarberCandesSelection(data, modeling, selection_method,q=q, VI_stat=VI_stat).selection()\n&gt;&gt;&gt;\n&gt;&gt;&gt; S_knock = knockoff_selection.S\n&gt;&gt;&gt; FDR_UB = knockoff_selection.FDR_UB\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; fdr_knock = 100*utils.FDR(S_knock, true_index)\n&gt;&gt;&gt; power_knock = 100*utils.power(S_knock, true_index)\n&gt;&gt;&gt; fnp_knock = 100*utils.FNP(S_knock, true_index, p)\n&gt;&gt;&gt; print('------------Knockoff ({})-------------'.format(modeling[\"model\"]))\n&gt;&gt;&gt; print(\"Empirical FDR: \" + str(100*np.round(FDR_UB, 2)) + \"%\")\n&gt;&gt;&gt; print(\"FDR:  \" +str(fdr_knock) + \"%\")\n&gt;&gt;&gt; print(\"power:  \"+str(power_knock) + \"%\")\n&gt;&gt;&gt; print(\"FNP:  \"+str(fnp_knock) + \"%\")\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ##########DSS\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; modeling = {\"model\":\"gradient boosting\", \"params\":\"classification fi\"}\n&gt;&gt;&gt; selection_method = \"DSS\"\n&gt;&gt;&gt; data = [x, t]\n&gt;&gt;&gt; split_type = [\"sampling\", 5, 5]\n&gt;&gt;&gt; prob = .7\n&gt;&gt;&gt; DSS_selection = barber_candes_selection.BarberCandesSelection(data, modeling, selection_method,q=q).selection()\n&gt;&gt;&gt;\n&gt;&gt;&gt; S_dss = DSS_selection.S\n&gt;&gt;&gt; FDR_UB = DSS_selection.FDR_UB\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; fdr_dss = 100*utils.FDR(S_dss, true_index)\n&gt;&gt;&gt; power_dss = 100*utils.power(S_dss, true_index)\n&gt;&gt;&gt; fnp_dss = 100*utils.FNP(S_dss, true_index, p)\n&gt;&gt;&gt; print('------------DSS ({})-------------'.format(modeling[\"model\"]))\n&gt;&gt;&gt; print(\"Empirical FDR: \" + str(100*np.round(FDR_UB, 2)) + \"%\")\n&gt;&gt;&gt; print(\"FDR:  \" +str(fdr_dss) + \"%\")\n&gt;&gt;&gt; print(\"power:  \"+str(power_dss) + \"%\")\n&gt;&gt;&gt; print(\"FNP:  \"+str(fnp_dss) + \"%\")\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ############### SVM\n&gt;&gt;&gt;\n&gt;&gt;&gt; modeling = {\"model\": \"not specified\", \"params\":\"given\"}\n&gt;&gt;&gt;\n&gt;&gt;&gt; from sklearn.svm import SVC\n&gt;&gt;&gt;\n&gt;&gt;&gt; svm = SVC(C=1., kernel=\"linear\")\n&gt;&gt;&gt; svm_w = svm.fit(np.hstack((x, x_tilda)), t.ravel()).coef_\n&gt;&gt;&gt;\n&gt;&gt;&gt; selection_method = \"knockoff\"\n&gt;&gt;&gt; knockoff_selection = barber_candes_selection.BarberCandesSelection(modeling=modeling, selection_method=selection_method, w = svm_w).selection()\n&gt;&gt;&gt;\n&gt;&gt;&gt; S_knock = knockoff_selection.S\n&gt;&gt;&gt; FDR_UB = knockoff_selection.FDR_UB\n&gt;&gt;&gt; print(\"empirical FDR: \" + str(100*np.round(FDR_UB, 2)))\n&gt;&gt;&gt;\n&gt;&gt;&gt; fdr_knock = 100*utils.FDR(S_knock, true_index)\n&gt;&gt;&gt; power_knock = 100*utils.power(S_knock, true_index)\n&gt;&gt;&gt; fnp_knock = 100*utils.FNP(S_knock, true_index, p)\n&gt;&gt;&gt; print('------------Knockoff ({})-------------'.format(modeling[\"model\"]))\n&gt;&gt;&gt; print(\"Empirical FDR: \" + str(100*np.round(FDR_UB, 2)) + \"%\")\n&gt;&gt;&gt; print(\"FDR:  \" +str(fdr_knock) + \"%\")\n&gt;&gt;&gt; print(\"power:  \"+str(power_knock) + \"%\")\n&gt;&gt;&gt; print(\"FNP:  \"+str(fnp_knock) + \"%\")\n</pre>\n\n          </div>"}, "last_serial": 4233278, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "8f1b5b71cdfc781cb88e01e924bb3b67", "sha256": "e2519eccd4d28dfbb268f86712bbe9d4366d914381c9ab4aad4580e38b77394c"}, "downloads": -1, "filename": "feature_selection_fdr-0.1.tar.gz", "has_sig": false, "md5_digest": "8f1b5b71cdfc781cb88e01e924bb3b67", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18751, "upload_time": "2018-09-03T04:53:00", "upload_time_iso_8601": "2018-09-03T04:53:00.681818Z", "url": "https://files.pythonhosted.org/packages/cf/75/9816ba7f8d872646b8a00294fc16b506812a6d1c38d66ce87d89103b6a73/feature_selection_fdr-0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8f1b5b71cdfc781cb88e01e924bb3b67", "sha256": "e2519eccd4d28dfbb268f86712bbe9d4366d914381c9ab4aad4580e38b77394c"}, "downloads": -1, "filename": "feature_selection_fdr-0.1.tar.gz", "has_sig": false, "md5_digest": "8f1b5b71cdfc781cb88e01e924bb3b67", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18751, "upload_time": "2018-09-03T04:53:00", "upload_time_iso_8601": "2018-09-03T04:53:00.681818Z", "url": "https://files.pythonhosted.org/packages/cf/75/9816ba7f8d872646b8a00294fc16b506812a6d1c38d66ce87d89103b6a73/feature_selection_fdr-0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:06 2020"}