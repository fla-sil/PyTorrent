{"info": {"author": "ProGamerGov", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: End Users/Desktop", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: Artistic Software", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# neural-dream\n\nThis is a PyTorch implementation of DeepDream. The code is based on [neural-style-pt](https://github.com/ProGamerGov/neural-style-pt).\n\n<div align=\"center\">\n <img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/places365_big.png\" width=\"710px\">\n</div>\n\nHere we DeepDream a photograph of the Golden Gate Bridge with a variety of settings:\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/inputs/golden_gate.jpg\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/goldengate_3a_5x5_reduce.png\" height=\"250px\">\n\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/places205_4b_pool_proj.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/places365_inception_4a_pool_proj.png\" height=\"250px\">\n\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/goldengate_4d_5x5_s10.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/goldengate_4d_3x3_reduce_avg10_lp4.png\" height=\"250px\">\n</div>\n\n\n### Specific Channel Selection\n\nYou can select individual or specific combinations of channels.\n\nClockwise from upper left: 119, 1, 29, and all channels of the `inception_4d_3x3_reduce` layer\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c119.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c1.png\" height=\"250px\">\n\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_4d_3x3_reduce_call.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c29.png\" height=\"250px\">\n\n</div>\n\nClockwise from upper left: 25, 108, 25 & 108, and 25 & 119 from the `inception_4d_3x3_reduce` layer\n\n<div align=\"center\"> \n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c25.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c108.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c25_119.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_c25_108.png\" height=\"250px\">\n</div>\n\n### Channel Selection Based On Activation Strength\n\nYou can select channels automatically based on their activation strength.\n\nClockwise from upper left: The top 10 weakest channels, the 10 most average channels,\nthe top 10 strongest channels, and all channels of the `inception_4e_3x3_reduce` layer\n\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_w10.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_avg10.png\" height=\"250px\">\n\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_4e_3x3_reduce_all.png\" height=\"250px\">\n<img src=\"https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/tubingen_s10.png\" height=\"250px\">\n\n</div>\n\n\n## Setup:\n\n\nWhile you can use Python 2's pip, it's recommended that you use Python 3's pip:\n\n```\n# in a terminal, run the command\npip3 install neural-dream\n```\n\n\nAfter installing neural-dream, you'll need to run the following script to download BVLC GoogleNet and NIN models:\n\n\n```\nneural-style -download_models\n```\n\nBy default the models are downloaded to your home directory, but you can specify a download location with:\n\n```\nneural-dream -download_models -download_path <download_path>\n```\n\nThis will download the original [BVLC GoogleNet model](https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet).\n\nIf you have a smaller memory GPU then using the NIN Imagenet model could be an alternative to the BVLC GoogleNet model, though it's DeepDream quality is nowhere near that of the other models. You can get the details on the model from [BVLC Caffe ModelZoo](https://github.com/BVLC/caffe/wiki/Model-Zoo). The NIN model is downloaded when you run `neural-dream -download_models`.\n\nTo download most of the compatible models, run the following command:\n\n```\nneural-dream -download_models all\n```\n\nTo download all Caffe GoogleNet models, run the following command:\n\n```\nneural-dream -download_models all-caffe-googlenet\n```\n\n## Usage\nBasic usage:\n```\nneural-dream -content_image <image.jpg>\n```\n\ncuDNN usage with NIN Model:\n```\nneural-dream -content_image examples/inputs/brad_pitt.jpg -output_image pitt_nin_cudnn.png -model_file models/nin_imagenet.pth -gpu 0 -backend cudnn -num_iterations 10 -seed 876 -dream_layers relu0,relu3,relu7,relu12 -dream_weight 10 -image_size 512 -optimizer adam -learning_rate 0.1\n```\n\n![cuDNN NIN Model Picasso Brad Pitt](https://raw.githubusercontent.com/ProGamerGov/neural-dream/master/examples/outputs/pitt_nin_cudnn.png)\n\n\nNote that paths to images should not contain the `~` character to represent your home directory; you should instead use a relative\npath or a full absolute path.\n\n**Options**:\n* `-image_size`: Maximum side length (in pixels) of the generated image. Default is 512.\n* `-gpu`: Zero-indexed ID of the GPU to use; for CPU mode set `-gpu` to `c`.\n\n**Optimization options**:\n* `-dream_weight`: How much to weight DeepDream. Default is `1e3`.\n* `-tv_weight`: Weight of total-variation (TV) regularization; this helps to smooth the image.\n  Default is set to `0` to disable total-variation (TV) regularization.\n* `-l2_weight`: Weight of latent state regularization.\n  Default is set to `0` to disable latent state regularization.\n* `-num_iterations`: Default is `10`.\n* `-init`: Method for generating the generated image; one of `random` or `image`.\n  Default is `image` which initializes with the content image; `random` uses random noise to initialize the input image.\n* `-jitter`: Apply jitter to image. Default is `32`. Set to `0` to disable jitter.\n* `-layer_sigma`: Apply gaussian blur to image. Default is set to `0` to disable the gaussian blur layer.\n* `-optimizer`: The optimization algorithm to use; either `lbfgs` or `adam`; default is `adam`.\n  Adam tends to perform the best for DeepDream. L-BFGS tends to give worse results and it uses more memory; when using L-BFGS you will probably need to play with other parameters to get good results, especially the learning rate.\n* `-learning_rate`: Learning rate to use with the ADAM and L-BFGS optimizers. Default is `1.5`. On other DeepDream projects this parameter is commonly called 'step size'.\n* `-normalize_weights`: If this flag is present, dream weights will be divided by the number of channels for each layer. Idea from [PytorchNeuralStyleTransfer](https://github.com/leongatys/PytorchNeuralStyleTransfer).\n* `-loss_mode`: The DeepDream loss mode; `bce`, `mse`, `mean`, `norm`, or `l2`; default is `l2`.\n\n**Output options**:\n* `-output_image`: Name of the output image. Default is `out.png`.\n* `-output_start_num`: The number to start output image names at. Default is set to `1`.\n* `-print_iter`: Print progress every `print_iter` iterations. Set to `0` to disable printing.\n* `-print_octave_iter`: Print octave progress every `print_octave_iter` iterations. Default is set to `0` to disable printing. If tiling is enabled, then octave progress will be printed every `print_octave_iter` octaves.\n* `-save_iter`: Save the image every `save_iter` iterations. Set to `0` to disable saving intermediate results.\n* `-save_octave_iter`: Save the image every `save_octave_iter` iterations. Default is set to `0` to disable saving intermediate results. If tiling is enabled, then octaves will be saved every `save_octave_iter` octaves.\n\n**Layer options**:\n* `-dream_layers`: Comma-separated list of layer names to use for DeepDream reconstruction.\n\n**Channel options:**\n* `-channels`: Comma-separated list of channels to use for DeepDream. If `-channel_mode` is set to a value other than `all` or `ignore`, only the first value in the list will be used.\n* `-channel_mode`: The DeepDream channel selection mode; `all`, `strong`, `avg`, `weak`, or `ignore`; default is `all`. The `strong` option will select the strongest channels, while `weak` will do the same with the weakest channels. The `avg` option will select the most average channels instead of the strongest or weakest. The number of channels selected by `strong`, `avg`, or `weak` is based on the first value for the `-channels` parameter. The `ignore` option will omit any specified channels.\n* `-channel_capture`: How often to select channels based on activation strength; either `once` or `octave_iter`; default is `once`. The `once` option will select channels once at the start, while the `octave_iter` will select potentially new channels every octave iteration. This parameter only comes into play if `-channel_mode` is not set to `all` or `ignore`.\n\n**Octave options:**\n* `-num_octaves`: Number of octaves per iteration. Default is `4`.\n* `-octave_scale`: Value for resizing the image by. Default is `0.6`.\n* `-octave_iter`: Number of iterations per octave. Default is `50`. On other DeepDream projects this parameter is commonly called 'steps'.\n* `-octave_mode`: The octave size calculation mode; `normal`, `advanced`, `manual_max`, `manual_min`, or `manual`. Default is `normal`. If set to `manual_max` or `manual_min`, then `-octave_scale` takes a comma separated list of image sizes for the largest or smallest image dimension for `num_octaves` minus 1 octaves. If set `manual` then `-octave_scale` takes a comma separated list of image size pairs for  `num_octaves` minus 1 octaves, in the form of `<Height>,<Width>`.\n\n**Laplacian Pyramid options:**\n* `-lap_scale`: The number of layers in a layer's laplacian pyramid. Default is set to `0` to disable laplacian pyramids.\n* `-sigma`: The strength of gaussian blur to use in laplacian pyramids. Default is `1`. By default, unless a second sigma value is provided with a comma to separate it from the first, the high gaussian layers will use sigma `sigma` * `lap_scale`.\n\n**Zoom options:**\n* `-zoom`: The amount to zoom in on the image.\n* `-zoom_mode`: Whether to read the zoom value as a percentage or pixel value; one of `percentage` or `pixel`. Default is `percentage`.\n\n**FFT options:**\n* `-use_fft`: Whether to enable Fast Fourier transform (FFT) decorrelation.\n* `-fft_block`: The size of your FFT frequency filtering block. Default is `25`.\n\n**Tiling options:**\n* `-tile_size`: The desired tile size to use. Default is set to `0` to disable tiling.\n* `-overlap_percent`: The percentage of overlap to use for the tiles. Default is `50`.\n* `-print_tile`: Print the current tile being processed every `print_tile` tiles without any other information. Default is set to `0` to disable printing.\n* `-print_tile_iter`: Print tile progress every `print_tile_iter` iterations. Default is set to `0` to disable printing.\n* `-image_capture_size`: The image size to use for the initial full image capture and optional `-classify` parameter. Default is set to `0` to disable it and `image_size` is used instead.\n\n**GIF options:**\n* `-create_gif`: Whether to create a GIF from the output images after all iterations have been completed.\n* `-frame_duration`: The duration for each GIF frame in milliseconds. Default is `100`.\n\n**Help options:**\n* `-print_layers`: Pass this flag to print the names of all usable layers for the selected model.\n* `-print_channels`: Pass this flag to print all the selected channels.\n\n**Other options**:\n* `-original_colors`: If you set this to `1`, then the output image will keep the colors of the content image.\n* `-model_file`: Path to the `.pth` file for the VGG Caffe model. Default is the original VGG-19 model; you can also try the original VGG-16 model.\n* `-model_type`: Whether the model was trained using Caffe, PyTorch, or Keras preprocessing; `caffe`, `pytorch`, `keras`, or `auto`; default is `auto`.\n* `-model_mean`: A comma separated list of 3 numbers for the model's mean; default is `auto`.\n* `-pooling`: The type of pooling layers to use for VGG and NIN models; one of `max` or `avg`. Default is `max`. VGG models seem to create better results with average pooling.\n* `-seed`: An integer value that you can specify for repeatable results. By default this value is random for each run.\n* `-multidevice_strategy`: A comma-separated list of layer indices at which to split the network when using multiple devices. See [Multi-GPU scaling](https://github.com/ProGamerGov/neural-dream#multi-gpu-scaling) for more details. Currently this feature only works for VGG and NIN models.\n* `-backend`: `nn`, `cudnn`, `openmp`, or `mkl`. Default is `nn`. `mkl` requires Intel's MKL backend.\n* `-cudnn_autotune`: When using the cuDNN backend, pass this flag to use the built-in cuDNN autotuner to select\n  the best convolution algorithms for your architecture. This will make the first iteration a bit slower and can\n  take a bit more memory, but may significantly speed up the cuDNN backend.\n* `-clamp`: If this flag is enabled, every iteration will clamp the output image so that it is within the model's input range.\n* `-adjust_contrast`: A value between `0` and `100.0` for altering the image's contrast (ex: `99.98`). Default is set to 0 to disable contrast adjustments.\n* `-label_file`:  Path to the `.txt` category list file for classification and channel selection. \n* `-random_transforms`: Whether to use random transforms on the image; either `none`, `rotate`, `flip`, or `all`; default is `none`.\n* `-classify`: Display what the model thinks an image contains. Integer for the number of choices ranked by how likely each is.\n\n**Download options**:\n* `-download_path`: Path to where the VGG-19, VGG-16, and NIN models will be downloaded to. If no path is specified, the models will be downloaded to your home directory.\n* `-download_models`: Comma separated list of which models to download. Choose from almost any combination of: `all`, `caffe-vgg16`, `caffe-vgg19`, `caffe-nin`, `caffe-googlenet-places205`, `caffe-googlenet-places365`, `caffe-googlenet-bvlc`, `caffe-googlenet-cars`, `caffe-googlenet-sos`, `caffe-resnet-opennsfw`, `pytorch-vgg16`, `pytorch-vgg19`, `pytorch-googlenet`, `pytorch-inceptionv3`, `tensorflow-inception5h`, `keras-inceptionv3`, `all-caffe`, `all-caffe-googlenet`. Default is `caffe-googlenet-bvlc,caffe-nin`.\n\n## Frequently Asked Questions\n\n**Problem:** The program runs out of memory and dies\n\n**Solution:** Try reducing the image size: `-image_size 512` (or lower). Note that different image sizes will likely\nrequire non-default values for `-octave_scale` and `-num_octaves` for optimal results.\nIf you are running on a GPU, you can also try running with `-backend cudnn` to reduce memory usage.\n\n**Problem:** `-backend cudnn` is slower than default NN backend\n\n**Solution:** Add the flag `-cudnn_autotune`; this will use the built-in cuDNN autotuner to select the best convolution algorithms.\n\n**Problem:** Get the following error message:\n\n`Missing key(s) in state_dict: \"classifier.0.bias\", \"classifier.0.weight\", \"classifier.3.bias\", \"classifier.3.weight\".\n        Unexpected key(s) in state_dict: \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\".`\n\n**Solution:** Due to a mix up with layer locations, older models require a fix to be compatible with newer versions of PyTorch. The included [`donwload_models.py`](https://github.com/ProGamerGov/neural-dream/blob/master/models/download_models.py) script will automatically perform these fixes after downloading the models.\n\n**Problem:** Get the following error message: \n\n`Given input size: (...). Calculated output size: (...). Output size is too small`\n\n**Solution:** Use a larger `-image_size` value and/or adjust the octave parameters so that the smallest octave size is larger. \n\n## Memory Usage\nBy default, `neural-dream` uses the `nn` backend for convolutions and Adam for optimization. These give good results, but can both use a lot of memory. You can reduce memory usage with the following:\n\n* **Use cuDNN**: Add the flag `-backend cudnn` to use the cuDNN backend. This will only work in GPU mode.\n* **Reduce image size**: You can reduce the size of the generated image to lower memory usage;\n  pass the flag `-image_size 256` to generate an image at half the default size.\n\nWith the default settings, neural-dream uses about 1.3 GB of GPU memory on my system; switching to cuDNN reduces the GPU memory footprint to about 1 GB.\n\n\n## Multi-GPU scaling\nYou can use multiple CPU and GPU devices to process images at higher resolutions; different layers of the network will be\ncomputed on different devices. You can control which GPU and CPU devices are used with the `-gpu` flag, and you can control\nhow to split layers across devices using the `-multidevice_strategy` flag.\n\nFor example in a server with four GPUs, you can give the flag `-gpu 0,1,2,3` to process on GPUs 0, 1, 2, and 3 in that order; by also giving the flag `-multidevice_strategy 3,6,12` you indicate that the first two layers should be computed on GPU 0, layers 3 to 5 should be computed on GPU 1, layers 6 to 11 should be computed on GPU 2, and the remaining layers should be computed on GPU 3. You will need to tune the `-multidevice_strategy` for your setup in order to achieve maximal resolution.\n\nWe can achieve very high quality results at high resolution by combining multi-GPU processing with multiscale\ngeneration as described in the paper\n<a href=\"https://arxiv.org/abs/1611.07865\">**Controlling Perceptual Factors in Neural Style Transfer**</a> by Leon A. Gatys,\nAlexander S. Ecker, Matthias Bethge, Aaron Hertzmann and Eli Shechtman.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ProGamerGov/neural-dream/tree/pip-master/", "keywords": "neural artistic neural-dream dream pytorch caffe neuralart neural-art hallucinations visualization feature-visualization mlart machine-learning-art aiart ai-art deepdream neuraldream pytorch-deepdream deepdream-pytorch tiling googlenet inception resnet vgg vgg16 vgg19 nin tensorflow keras inceptionv3 inception-v3", "license": "", "maintainer": "", "maintainer_email": "", "name": "neural-dream", "package_url": "https://pypi.org/project/neural-dream/", "platform": "", "project_url": "https://pypi.org/project/neural-dream/", "project_urls": {"Homepage": "https://github.com/ProGamerGov/neural-dream/tree/pip-master/"}, "release_url": "https://pypi.org/project/neural-dream/0.0.4/", "requires_dist": ["torch", "torchvision", "pillow"], "requires_python": "", "summary": "A PyTorch implementation of DeepDream", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>neural-dream</h1>\n<p>This is a PyTorch implementation of DeepDream. The code is based on <a href=\"https://github.com/ProGamerGov/neural-style-pt\" rel=\"nofollow\">neural-style-pt</a>.</p>\n<div>\n <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/246f315bedea3353bec62ca2c18436286444921b/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f706c616365733336355f6269672e706e67\" width=\"710px\">\n</div>\n<p>Here we DeepDream a photograph of the Golden Gate Bridge with a variety of settings:</p>\n<div>\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1009fe5fb0fa49c337b9e93fd08aa739d560f819/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f696e707574732f676f6c64656e5f676174652e6a7067\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5cb8a3daf7c3811d50a592c4015b5fb004c1f162/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f676f6c64656e676174655f33615f3578355f7265647563652e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ec6505facd37c0c94c07ea8855802e510194f327/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f706c616365733230355f34625f706f6f6c5f70726f6a2e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5afc152414c03241525b8670c06b2813a2239d6b/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f706c616365733336355f696e63657074696f6e5f34615f706f6f6c5f70726f6a2e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ff6b0da234e9af463c857d11ad969fab4ae88175/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f676f6c64656e676174655f34645f3578355f7331302e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b12a4996e5ddb896816af2896395122a4163a9dd/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f676f6c64656e676174655f34645f3378335f7265647563655f61766731305f6c70342e706e67\">\n</div>\n<h3>Specific Channel Selection</h3>\n<p>You can select individual or specific combinations of channels.</p>\n<p>Clockwise from upper left: 119, 1, 29, and all channels of the <code>inception_4d_3x3_reduce</code> layer</p>\n<div>\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/00e285d9b6c1cfe361d104836d0302632c5de7b7/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f633131392e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dba3998451ee2cfe07bf377d6dfaf9024113b66f/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f63312e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d811c099ad564ba3841be08dc2e12275b98632ae/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f34645f3378335f7265647563655f63616c6c2e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/903c67a3b4a5bd0f0a80396cd1f613d1fb3119e5/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f6332392e706e67\">\n</div>\n<p>Clockwise from upper left: 25, 108, 25 &amp; 108, and 25 &amp; 119 from the <code>inception_4d_3x3_reduce</code> layer</p>\n<div> \n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/377a64b067b6fb776986bf7a24c10901537ec9be/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f6332352e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bce09117a984d03cceae37e8240a9e0aae37c14c/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f633130382e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7c33c6142f4ad9743e39d080860c6e38e6fbf70d/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f6332355f3131392e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e22327350c90889ba52409cb759fcda81d6af02c/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f6332355f3130382e706e67\">\n</div>\n<h3>Channel Selection Based On Activation Strength</h3>\n<p>You can select channels automatically based on their activation strength.</p>\n<p>Clockwise from upper left: The top 10 weakest channels, the 10 most average channels,\nthe top 10 strongest channels, and all channels of the <code>inception_4e_3x3_reduce</code> layer</p>\n<div>\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80a0893fe1b24d6fee94f688802bac1c43fa7219/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f7731302e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5034ba04cd42702220d88fdfaa23bfdf1a65ef14/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f61766731302e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7f1f608dcad4ec111d79e163edcadcb3b7eee16b/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f34655f3378335f7265647563655f616c6c2e706e67\">\n<img height=\"250px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ac0ea6a23d234b269412ba42894d127e5a693e49/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f747562696e67656e5f7331302e706e67\">\n</div>\n<h2>Setup:</h2>\n<p>While you can use Python 2's pip, it's recommended that you use Python 3's pip:</p>\n<pre><code># in a terminal, run the command\npip3 install neural-dream\n</code></pre>\n<p>After installing neural-dream, you'll need to run the following script to download BVLC GoogleNet and NIN models:</p>\n<pre><code>neural-style -download_models\n</code></pre>\n<p>By default the models are downloaded to your home directory, but you can specify a download location with:</p>\n<pre><code>neural-dream -download_models -download_path &lt;download_path&gt;\n</code></pre>\n<p>This will download the original <a href=\"https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet\" rel=\"nofollow\">BVLC GoogleNet model</a>.</p>\n<p>If you have a smaller memory GPU then using the NIN Imagenet model could be an alternative to the BVLC GoogleNet model, though it's DeepDream quality is nowhere near that of the other models. You can get the details on the model from <a href=\"https://github.com/BVLC/caffe/wiki/Model-Zoo\" rel=\"nofollow\">BVLC Caffe ModelZoo</a>. The NIN model is downloaded when you run <code>neural-dream -download_models</code>.</p>\n<p>To download most of the compatible models, run the following command:</p>\n<pre><code>neural-dream -download_models all\n</code></pre>\n<p>To download all Caffe GoogleNet models, run the following command:</p>\n<pre><code>neural-dream -download_models all-caffe-googlenet\n</code></pre>\n<h2>Usage</h2>\n<p>Basic usage:</p>\n<pre><code>neural-dream -content_image &lt;image.jpg&gt;\n</code></pre>\n<p>cuDNN usage with NIN Model:</p>\n<pre><code>neural-dream -content_image examples/inputs/brad_pitt.jpg -output_image pitt_nin_cudnn.png -model_file models/nin_imagenet.pth -gpu 0 -backend cudnn -num_iterations 10 -seed 876 -dream_layers relu0,relu3,relu7,relu12 -dream_weight 10 -image_size 512 -optimizer adam -learning_rate 0.1\n</code></pre>\n<p><img alt=\"cuDNN NIN Model Picasso Brad Pitt\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4d6c5e129720f8bf80d8fd4edaf19c544d93ed84/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f50726f47616d6572476f762f6e657572616c2d647265616d2f6d61737465722f6578616d706c65732f6f7574707574732f706974745f6e696e5f6375646e6e2e706e67\"></p>\n<p>Note that paths to images should not contain the <code>~</code> character to represent your home directory; you should instead use a relative\npath or a full absolute path.</p>\n<p><strong>Options</strong>:</p>\n<ul>\n<li><code>-image_size</code>: Maximum side length (in pixels) of the generated image. Default is 512.</li>\n<li><code>-gpu</code>: Zero-indexed ID of the GPU to use; for CPU mode set <code>-gpu</code> to <code>c</code>.</li>\n</ul>\n<p><strong>Optimization options</strong>:</p>\n<ul>\n<li><code>-dream_weight</code>: How much to weight DeepDream. Default is <code>1e3</code>.</li>\n<li><code>-tv_weight</code>: Weight of total-variation (TV) regularization; this helps to smooth the image.\nDefault is set to <code>0</code> to disable total-variation (TV) regularization.</li>\n<li><code>-l2_weight</code>: Weight of latent state regularization.\nDefault is set to <code>0</code> to disable latent state regularization.</li>\n<li><code>-num_iterations</code>: Default is <code>10</code>.</li>\n<li><code>-init</code>: Method for generating the generated image; one of <code>random</code> or <code>image</code>.\nDefault is <code>image</code> which initializes with the content image; <code>random</code> uses random noise to initialize the input image.</li>\n<li><code>-jitter</code>: Apply jitter to image. Default is <code>32</code>. Set to <code>0</code> to disable jitter.</li>\n<li><code>-layer_sigma</code>: Apply gaussian blur to image. Default is set to <code>0</code> to disable the gaussian blur layer.</li>\n<li><code>-optimizer</code>: The optimization algorithm to use; either <code>lbfgs</code> or <code>adam</code>; default is <code>adam</code>.\nAdam tends to perform the best for DeepDream. L-BFGS tends to give worse results and it uses more memory; when using L-BFGS you will probably need to play with other parameters to get good results, especially the learning rate.</li>\n<li><code>-learning_rate</code>: Learning rate to use with the ADAM and L-BFGS optimizers. Default is <code>1.5</code>. On other DeepDream projects this parameter is commonly called 'step size'.</li>\n<li><code>-normalize_weights</code>: If this flag is present, dream weights will be divided by the number of channels for each layer. Idea from <a href=\"https://github.com/leongatys/PytorchNeuralStyleTransfer\" rel=\"nofollow\">PytorchNeuralStyleTransfer</a>.</li>\n<li><code>-loss_mode</code>: The DeepDream loss mode; <code>bce</code>, <code>mse</code>, <code>mean</code>, <code>norm</code>, or <code>l2</code>; default is <code>l2</code>.</li>\n</ul>\n<p><strong>Output options</strong>:</p>\n<ul>\n<li><code>-output_image</code>: Name of the output image. Default is <code>out.png</code>.</li>\n<li><code>-output_start_num</code>: The number to start output image names at. Default is set to <code>1</code>.</li>\n<li><code>-print_iter</code>: Print progress every <code>print_iter</code> iterations. Set to <code>0</code> to disable printing.</li>\n<li><code>-print_octave_iter</code>: Print octave progress every <code>print_octave_iter</code> iterations. Default is set to <code>0</code> to disable printing. If tiling is enabled, then octave progress will be printed every <code>print_octave_iter</code> octaves.</li>\n<li><code>-save_iter</code>: Save the image every <code>save_iter</code> iterations. Set to <code>0</code> to disable saving intermediate results.</li>\n<li><code>-save_octave_iter</code>: Save the image every <code>save_octave_iter</code> iterations. Default is set to <code>0</code> to disable saving intermediate results. If tiling is enabled, then octaves will be saved every <code>save_octave_iter</code> octaves.</li>\n</ul>\n<p><strong>Layer options</strong>:</p>\n<ul>\n<li><code>-dream_layers</code>: Comma-separated list of layer names to use for DeepDream reconstruction.</li>\n</ul>\n<p><strong>Channel options:</strong></p>\n<ul>\n<li><code>-channels</code>: Comma-separated list of channels to use for DeepDream. If <code>-channel_mode</code> is set to a value other than <code>all</code> or <code>ignore</code>, only the first value in the list will be used.</li>\n<li><code>-channel_mode</code>: The DeepDream channel selection mode; <code>all</code>, <code>strong</code>, <code>avg</code>, <code>weak</code>, or <code>ignore</code>; default is <code>all</code>. The <code>strong</code> option will select the strongest channels, while <code>weak</code> will do the same with the weakest channels. The <code>avg</code> option will select the most average channels instead of the strongest or weakest. The number of channels selected by <code>strong</code>, <code>avg</code>, or <code>weak</code> is based on the first value for the <code>-channels</code> parameter. The <code>ignore</code> option will omit any specified channels.</li>\n<li><code>-channel_capture</code>: How often to select channels based on activation strength; either <code>once</code> or <code>octave_iter</code>; default is <code>once</code>. The <code>once</code> option will select channels once at the start, while the <code>octave_iter</code> will select potentially new channels every octave iteration. This parameter only comes into play if <code>-channel_mode</code> is not set to <code>all</code> or <code>ignore</code>.</li>\n</ul>\n<p><strong>Octave options:</strong></p>\n<ul>\n<li><code>-num_octaves</code>: Number of octaves per iteration. Default is <code>4</code>.</li>\n<li><code>-octave_scale</code>: Value for resizing the image by. Default is <code>0.6</code>.</li>\n<li><code>-octave_iter</code>: Number of iterations per octave. Default is <code>50</code>. On other DeepDream projects this parameter is commonly called 'steps'.</li>\n<li><code>-octave_mode</code>: The octave size calculation mode; <code>normal</code>, <code>advanced</code>, <code>manual_max</code>, <code>manual_min</code>, or <code>manual</code>. Default is <code>normal</code>. If set to <code>manual_max</code> or <code>manual_min</code>, then <code>-octave_scale</code> takes a comma separated list of image sizes for the largest or smallest image dimension for <code>num_octaves</code> minus 1 octaves. If set <code>manual</code> then <code>-octave_scale</code> takes a comma separated list of image size pairs for  <code>num_octaves</code> minus 1 octaves, in the form of <code>&lt;Height&gt;,&lt;Width&gt;</code>.</li>\n</ul>\n<p><strong>Laplacian Pyramid options:</strong></p>\n<ul>\n<li><code>-lap_scale</code>: The number of layers in a layer's laplacian pyramid. Default is set to <code>0</code> to disable laplacian pyramids.</li>\n<li><code>-sigma</code>: The strength of gaussian blur to use in laplacian pyramids. Default is <code>1</code>. By default, unless a second sigma value is provided with a comma to separate it from the first, the high gaussian layers will use sigma <code>sigma</code> * <code>lap_scale</code>.</li>\n</ul>\n<p><strong>Zoom options:</strong></p>\n<ul>\n<li><code>-zoom</code>: The amount to zoom in on the image.</li>\n<li><code>-zoom_mode</code>: Whether to read the zoom value as a percentage or pixel value; one of <code>percentage</code> or <code>pixel</code>. Default is <code>percentage</code>.</li>\n</ul>\n<p><strong>FFT options:</strong></p>\n<ul>\n<li><code>-use_fft</code>: Whether to enable Fast Fourier transform (FFT) decorrelation.</li>\n<li><code>-fft_block</code>: The size of your FFT frequency filtering block. Default is <code>25</code>.</li>\n</ul>\n<p><strong>Tiling options:</strong></p>\n<ul>\n<li><code>-tile_size</code>: The desired tile size to use. Default is set to <code>0</code> to disable tiling.</li>\n<li><code>-overlap_percent</code>: The percentage of overlap to use for the tiles. Default is <code>50</code>.</li>\n<li><code>-print_tile</code>: Print the current tile being processed every <code>print_tile</code> tiles without any other information. Default is set to <code>0</code> to disable printing.</li>\n<li><code>-print_tile_iter</code>: Print tile progress every <code>print_tile_iter</code> iterations. Default is set to <code>0</code> to disable printing.</li>\n<li><code>-image_capture_size</code>: The image size to use for the initial full image capture and optional <code>-classify</code> parameter. Default is set to <code>0</code> to disable it and <code>image_size</code> is used instead.</li>\n</ul>\n<p><strong>GIF options:</strong></p>\n<ul>\n<li><code>-create_gif</code>: Whether to create a GIF from the output images after all iterations have been completed.</li>\n<li><code>-frame_duration</code>: The duration for each GIF frame in milliseconds. Default is <code>100</code>.</li>\n</ul>\n<p><strong>Help options:</strong></p>\n<ul>\n<li><code>-print_layers</code>: Pass this flag to print the names of all usable layers for the selected model.</li>\n<li><code>-print_channels</code>: Pass this flag to print all the selected channels.</li>\n</ul>\n<p><strong>Other options</strong>:</p>\n<ul>\n<li><code>-original_colors</code>: If you set this to <code>1</code>, then the output image will keep the colors of the content image.</li>\n<li><code>-model_file</code>: Path to the <code>.pth</code> file for the VGG Caffe model. Default is the original VGG-19 model; you can also try the original VGG-16 model.</li>\n<li><code>-model_type</code>: Whether the model was trained using Caffe, PyTorch, or Keras preprocessing; <code>caffe</code>, <code>pytorch</code>, <code>keras</code>, or <code>auto</code>; default is <code>auto</code>.</li>\n<li><code>-model_mean</code>: A comma separated list of 3 numbers for the model's mean; default is <code>auto</code>.</li>\n<li><code>-pooling</code>: The type of pooling layers to use for VGG and NIN models; one of <code>max</code> or <code>avg</code>. Default is <code>max</code>. VGG models seem to create better results with average pooling.</li>\n<li><code>-seed</code>: An integer value that you can specify for repeatable results. By default this value is random for each run.</li>\n<li><code>-multidevice_strategy</code>: A comma-separated list of layer indices at which to split the network when using multiple devices. See <a href=\"https://github.com/ProGamerGov/neural-dream#multi-gpu-scaling\" rel=\"nofollow\">Multi-GPU scaling</a> for more details. Currently this feature only works for VGG and NIN models.</li>\n<li><code>-backend</code>: <code>nn</code>, <code>cudnn</code>, <code>openmp</code>, or <code>mkl</code>. Default is <code>nn</code>. <code>mkl</code> requires Intel's MKL backend.</li>\n<li><code>-cudnn_autotune</code>: When using the cuDNN backend, pass this flag to use the built-in cuDNN autotuner to select\nthe best convolution algorithms for your architecture. This will make the first iteration a bit slower and can\ntake a bit more memory, but may significantly speed up the cuDNN backend.</li>\n<li><code>-clamp</code>: If this flag is enabled, every iteration will clamp the output image so that it is within the model's input range.</li>\n<li><code>-adjust_contrast</code>: A value between <code>0</code> and <code>100.0</code> for altering the image's contrast (ex: <code>99.98</code>). Default is set to 0 to disable contrast adjustments.</li>\n<li><code>-label_file</code>:  Path to the <code>.txt</code> category list file for classification and channel selection.</li>\n<li><code>-random_transforms</code>: Whether to use random transforms on the image; either <code>none</code>, <code>rotate</code>, <code>flip</code>, or <code>all</code>; default is <code>none</code>.</li>\n<li><code>-classify</code>: Display what the model thinks an image contains. Integer for the number of choices ranked by how likely each is.</li>\n</ul>\n<p><strong>Download options</strong>:</p>\n<ul>\n<li><code>-download_path</code>: Path to where the VGG-19, VGG-16, and NIN models will be downloaded to. If no path is specified, the models will be downloaded to your home directory.</li>\n<li><code>-download_models</code>: Comma separated list of which models to download. Choose from almost any combination of: <code>all</code>, <code>caffe-vgg16</code>, <code>caffe-vgg19</code>, <code>caffe-nin</code>, <code>caffe-googlenet-places205</code>, <code>caffe-googlenet-places365</code>, <code>caffe-googlenet-bvlc</code>, <code>caffe-googlenet-cars</code>, <code>caffe-googlenet-sos</code>, <code>caffe-resnet-opennsfw</code>, <code>pytorch-vgg16</code>, <code>pytorch-vgg19</code>, <code>pytorch-googlenet</code>, <code>pytorch-inceptionv3</code>, <code>tensorflow-inception5h</code>, <code>keras-inceptionv3</code>, <code>all-caffe</code>, <code>all-caffe-googlenet</code>. Default is <code>caffe-googlenet-bvlc,caffe-nin</code>.</li>\n</ul>\n<h2>Frequently Asked Questions</h2>\n<p><strong>Problem:</strong> The program runs out of memory and dies</p>\n<p><strong>Solution:</strong> Try reducing the image size: <code>-image_size 512</code> (or lower). Note that different image sizes will likely\nrequire non-default values for <code>-octave_scale</code> and <code>-num_octaves</code> for optimal results.\nIf you are running on a GPU, you can also try running with <code>-backend cudnn</code> to reduce memory usage.</p>\n<p><strong>Problem:</strong> <code>-backend cudnn</code> is slower than default NN backend</p>\n<p><strong>Solution:</strong> Add the flag <code>-cudnn_autotune</code>; this will use the built-in cuDNN autotuner to select the best convolution algorithms.</p>\n<p><strong>Problem:</strong> Get the following error message:</p>\n<p><code>Missing key(s) in state_dict: \"classifier.0.bias\", \"classifier.0.weight\", \"classifier.3.bias\", \"classifier.3.weight\". Unexpected key(s) in state_dict: \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\".</code></p>\n<p><strong>Solution:</strong> Due to a mix up with layer locations, older models require a fix to be compatible with newer versions of PyTorch. The included <a href=\"https://github.com/ProGamerGov/neural-dream/blob/master/models/download_models.py\" rel=\"nofollow\"><code>donwload_models.py</code></a> script will automatically perform these fixes after downloading the models.</p>\n<p><strong>Problem:</strong> Get the following error message:</p>\n<p><code>Given input size: (...). Calculated output size: (...). Output size is too small</code></p>\n<p><strong>Solution:</strong> Use a larger <code>-image_size</code> value and/or adjust the octave parameters so that the smallest octave size is larger.</p>\n<h2>Memory Usage</h2>\n<p>By default, <code>neural-dream</code> uses the <code>nn</code> backend for convolutions and Adam for optimization. These give good results, but can both use a lot of memory. You can reduce memory usage with the following:</p>\n<ul>\n<li><strong>Use cuDNN</strong>: Add the flag <code>-backend cudnn</code> to use the cuDNN backend. This will only work in GPU mode.</li>\n<li><strong>Reduce image size</strong>: You can reduce the size of the generated image to lower memory usage;\npass the flag <code>-image_size 256</code> to generate an image at half the default size.</li>\n</ul>\n<p>With the default settings, neural-dream uses about 1.3 GB of GPU memory on my system; switching to cuDNN reduces the GPU memory footprint to about 1 GB.</p>\n<h2>Multi-GPU scaling</h2>\n<p>You can use multiple CPU and GPU devices to process images at higher resolutions; different layers of the network will be\ncomputed on different devices. You can control which GPU and CPU devices are used with the <code>-gpu</code> flag, and you can control\nhow to split layers across devices using the <code>-multidevice_strategy</code> flag.</p>\n<p>For example in a server with four GPUs, you can give the flag <code>-gpu 0,1,2,3</code> to process on GPUs 0, 1, 2, and 3 in that order; by also giving the flag <code>-multidevice_strategy 3,6,12</code> you indicate that the first two layers should be computed on GPU 0, layers 3 to 5 should be computed on GPU 1, layers 6 to 11 should be computed on GPU 2, and the remaining layers should be computed on GPU 3. You will need to tune the <code>-multidevice_strategy</code> for your setup in order to achieve maximal resolution.</p>\n<p>We can achieve very high quality results at high resolution by combining multi-GPU processing with multiscale\ngeneration as described in the paper\n<a href=\"https://arxiv.org/abs/1611.07865\" rel=\"nofollow\"><strong>Controlling Perceptual Factors in Neural Style Transfer</strong></a> by Leon A. Gatys,\nAlexander S. Ecker, Matthias Bethge, Aaron Hertzmann and Eli Shechtman.</p>\n\n          </div>"}, "last_serial": 7054392, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "f312e9f863066f8c3d37c8971707b588", "sha256": "c6d8361dfa56faeb5d23b8ddff4f58a1c1d28e52bf57a75d861b090827a577f0"}, "downloads": -1, "filename": "neural_dream-0.0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "f312e9f863066f8c3d37c8971707b588", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 53309, "upload_time": "2020-03-16T18:18:32", "upload_time_iso_8601": "2020-03-16T18:18:32.975868Z", "url": "https://files.pythonhosted.org/packages/66/bb/3bc12f191ead8967c5b604978b14f492f1df92081e6df391086ab51e62c8/neural_dream-0.0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0082ff7b61a8433c46e7e93c4b1213c4", "sha256": "70eff9d925f0692d5c4983a75c0c4f7ba9a60ca21ea117e72169e904ece90851"}, "downloads": -1, "filename": "neural_dream-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0082ff7b61a8433c46e7e93c4b1213c4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 53315, "upload_time": "2020-03-16T18:18:34", "upload_time_iso_8601": "2020-03-16T18:18:34.192235Z", "url": "https://files.pythonhosted.org/packages/54/be/50d2e8f11c5826f6e89d6c7e80916fc07fe6d803717df57ed49f3a338b6e/neural_dream-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "725dddab63ca217b1c11abfea35649ad", "sha256": "eef6a798604cb1c0967fd4581e066e9a84f313b339d117666b92f149c37d8311"}, "downloads": -1, "filename": "neural_dream-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "725dddab63ca217b1c11abfea35649ad", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 53310, "upload_time": "2020-03-16T18:17:53", "upload_time_iso_8601": "2020-03-16T18:17:53.557146Z", "url": "https://files.pythonhosted.org/packages/17/40/f1483a6941317fdb8bb71afbf90a9b8b64c771a5442636435bde1dbf6e82/neural_dream-0.0.1-py3-none-any.whl", "yanked": false}], "0.0.1.dev0": [{"comment_text": "", "digests": {"md5": "14fc8ae86d29772b262150ff3650aacb", "sha256": "ce334bf9e57286bad0abda5d4e6c753565a6993b446e2d3a0cbe80b4b17b8c07"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev0-py3-none-any.whl", "has_sig": false, "md5_digest": "14fc8ae86d29772b262150ff3650aacb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16828, "upload_time": "2020-01-11T17:40:06", "upload_time_iso_8601": "2020-01-11T17:40:06.656334Z", "url": "https://files.pythonhosted.org/packages/d7/c7/bc27021f9151ed81dfb93a4b4cea831cf6774650de2233614ba582759d21/neural_dream-0.0.1.dev0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9be15fe31d19f5644b5a6aa968187732", "sha256": "c6a1372b4a13d5b0617a283ddd97707e1203f12e549f805875367bba3f4573fb"}, "downloads": -1, "filename": "neural-dream-0.0.1.dev0.tar.gz", "has_sig": false, "md5_digest": "9be15fe31d19f5644b5a6aa968187732", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19985, "upload_time": "2020-01-11T17:40:09", "upload_time_iso_8601": "2020-01-11T17:40:09.210829Z", "url": "https://files.pythonhosted.org/packages/ff/b1/c381ec1b0908ad4a19bc757c9bbaae906d397c2c8a23f696b7ebee56d0a6/neural-dream-0.0.1.dev0.tar.gz", "yanked": false}], "0.0.1.dev1": [{"comment_text": "", "digests": {"md5": "e611de774600c9ce5430ddb33e57c94a", "sha256": "a2d58327f68e4f136d34b7a4995c8215b8ab14936f9de1426f02a7a2830c316e"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev1-py3-none-any.whl", "has_sig": false, "md5_digest": "e611de774600c9ce5430ddb33e57c94a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 52895, "upload_time": "2020-03-16T00:21:26", "upload_time_iso_8601": "2020-03-16T00:21:26.778440Z", "url": "https://files.pythonhosted.org/packages/71/96/81c391d2bdd409e05efc58e1ce628b9532b728e9f1e51c381fee78093363/neural_dream-0.0.1.dev1-py3-none-any.whl", "yanked": false}], "0.0.1.dev2": [{"comment_text": "", "digests": {"md5": "e3e99a8a03e131d7cb4bf05c1552af58", "sha256": "b870870366289ece78f60655ae5d97106c5b459f62745af87b9e1c1c0e72f293"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev2-py3-none-any.whl", "has_sig": false, "md5_digest": "e3e99a8a03e131d7cb4bf05c1552af58", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 89631, "upload_time": "2020-03-16T00:34:46", "upload_time_iso_8601": "2020-03-16T00:34:46.357839Z", "url": "https://files.pythonhosted.org/packages/e4/45/87f37fd8dc6f2b230adccfcd31df88b588a092d6685fadf1d6cfccaad916/neural_dream-0.0.1.dev2-py3-none-any.whl", "yanked": false}], "0.0.1.dev3": [{"comment_text": "", "digests": {"md5": "94ee30a9068eca9fde572058d5495262", "sha256": "64d23de6642f7e0e8ac15513a0265c8be98adc377709e5f4f28720df014a6278"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev3-py3-none-any.whl", "has_sig": false, "md5_digest": "94ee30a9068eca9fde572058d5495262", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 89630, "upload_time": "2020-03-16T00:42:01", "upload_time_iso_8601": "2020-03-16T00:42:01.678483Z", "url": "https://files.pythonhosted.org/packages/77/ab/1d255fddd5fe8b56956e0860665ca4df7e40f96801d1af70d435f7a61666/neural_dream-0.0.1.dev3-py3-none-any.whl", "yanked": false}], "0.0.1.dev4": [{"comment_text": "", "digests": {"md5": "f446ae568031b3bc005644023037b7a8", "sha256": "5c16f594fb47cf8da50809525a532bf92bfc399dccb048a6db7b70a518cb8aae"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev4-py3-none-any.whl", "has_sig": false, "md5_digest": "f446ae568031b3bc005644023037b7a8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 89666, "upload_time": "2020-03-16T00:45:57", "upload_time_iso_8601": "2020-03-16T00:45:57.499005Z", "url": "https://files.pythonhosted.org/packages/12/5e/5b3d30d63c7c05df752403510949463e2d8aea648db96e7e2f7b2171b3a4/neural_dream-0.0.1.dev4-py3-none-any.whl", "yanked": false}], "0.0.1.dev5": [{"comment_text": "", "digests": {"md5": "18de09998c9073ea300f4e77f228e375", "sha256": "289deb8aca397d60dd0d019cf03e870a3feee8514ba94ec904aaa8dd070bf174"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev5-py3-none-any.whl", "has_sig": false, "md5_digest": "18de09998c9073ea300f4e77f228e375", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 53193, "upload_time": "2020-03-16T00:56:30", "upload_time_iso_8601": "2020-03-16T00:56:30.387254Z", "url": "https://files.pythonhosted.org/packages/67/ee/96b2eedcdac8be906c0e12dc490a97c6bbc262b8be0e84aea40ac1767951/neural_dream-0.0.1.dev5-py3-none-any.whl", "yanked": false}], "0.0.1.dev6": [{"comment_text": "", "digests": {"md5": "283f6ed6d869538339dcb8cde86ffa37", "sha256": "3b96889b5cdb13773f8c14ceae18fb6b4d2c516d212d0a750ffbe4a6f611acb5"}, "downloads": -1, "filename": "neural_dream-0.0.1.dev6-py3-none-any.whl", "has_sig": false, "md5_digest": "283f6ed6d869538339dcb8cde86ffa37", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 53200, "upload_time": "2020-03-16T01:05:34", "upload_time_iso_8601": "2020-03-16T01:05:34.729791Z", "url": "https://files.pythonhosted.org/packages/25/be/10d2cad29a73f68fd5e90afa1a071e109adaf2d8cb94b8dc777cc70c7df4/neural_dream-0.0.1.dev6-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "7c563ce35a462bf9bafe7ae248dc36b7", "sha256": "aaa78a982af275b78d6fba941f5da7a62f9bcb96e9924e4f68601f2d4255e891"}, "downloads": -1, "filename": "neural_dream-0.0.2-py2-none-any.whl", "has_sig": false, "md5_digest": "7c563ce35a462bf9bafe7ae248dc36b7", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 57112, "upload_time": "2020-03-29T19:54:54", "upload_time_iso_8601": "2020-03-29T19:54:54.593190Z", "url": "https://files.pythonhosted.org/packages/17/45/d912dd5dc30ea1d8465bfedc5eeeb9716e8663db5244b1b9f686afcae438/neural_dream-0.0.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eee3a0949b4fbd435b3792617e6f6679", "sha256": "8dafc6f93a54727f7cec1414814ee43b53bf5a87fcea437591303b467a7e38bc"}, "downloads": -1, "filename": "neural_dream-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "eee3a0949b4fbd435b3792617e6f6679", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 57118, "upload_time": "2020-03-29T19:53:01", "upload_time_iso_8601": "2020-03-29T19:53:01.372450Z", "url": "https://files.pythonhosted.org/packages/80/8d/faa3e367c500998bbcad94aefa707ca920853f558ab855a3084193a2e32b/neural_dream-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a436c4567169ccd98428b2ec5dd55f8b", "sha256": "ca852d5df7143639f6a94aaf0d6c96b36b1c03b84be78a24759565784ec39a46"}, "downloads": -1, "filename": "neural_dream-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "a436c4567169ccd98428b2ec5dd55f8b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 57111, "upload_time": "2020-03-29T19:46:26", "upload_time_iso_8601": "2020-03-29T19:46:26.898781Z", "url": "https://files.pythonhosted.org/packages/5e/79/fd58f2f0b0b9ca831710ac050f4b15e5c8e646ba6c12f644243133d8dea2/neural_dream-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ad44a2f946865464ed3d065dcc8eaee8", "sha256": "20ea584050ad5e120d1add2881cd040a1f79b6e72bf9ba33a2271c97161e9a99"}, "downloads": -1, "filename": "neural-dream-0.0.2.tar.gz", "has_sig": false, "md5_digest": "ad44a2f946865464ed3d065dcc8eaee8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43233, "upload_time": "2020-03-29T19:53:03", "upload_time_iso_8601": "2020-03-29T19:53:03.052241Z", "url": "https://files.pythonhosted.org/packages/a9/8a/3766232c0ffd96425dec2c00c5d4b927e2aad8a18080391de79eabee68f1/neural-dream-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "0c1f30be906e884dbd2c0fc89e39e735", "sha256": "16220dc62d628d475b9d6d72cad54004ed78d074b3662ad76ccbbada7d857b2b"}, "downloads": -1, "filename": "neural_dream-0.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0c1f30be906e884dbd2c0fc89e39e735", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 65692, "upload_time": "2020-04-19T15:21:05", "upload_time_iso_8601": "2020-04-19T15:21:05.933845Z", "url": "https://files.pythonhosted.org/packages/05/1a/e4ecf2df324aa1236cb273e0b87ad299796998ecd7727f5bfefe15f9dc95/neural_dream-0.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "845a7aa785fbe8e98c9d81f033772f03", "sha256": "9c67e0ccea63d8479576e4af2c89aefa3b569b3ed287d6651c1e572266c8620c"}, "downloads": -1, "filename": "neural_dream-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "845a7aa785fbe8e98c9d81f033772f03", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 65687, "upload_time": "2020-04-19T15:17:04", "upload_time_iso_8601": "2020-04-19T15:17:04.441340Z", "url": "https://files.pythonhosted.org/packages/d3/e7/f11af7c33ebe83bb4fa8f23926e3573455d92bd8dce8ad745897b4ce56c2/neural_dream-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b1b733d075685fc9c9817d3daa0d103c", "sha256": "62d814b8b6e1a2afce046a4f789d056e277ced41c59d94c86d17f468b8e5b38f"}, "downloads": -1, "filename": "neural-dream-0.0.4.tar.gz", "has_sig": false, "md5_digest": "b1b733d075685fc9c9817d3daa0d103c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52012, "upload_time": "2020-04-19T15:21:07", "upload_time_iso_8601": "2020-04-19T15:21:07.156456Z", "url": "https://files.pythonhosted.org/packages/1f/e5/770f7d227398973c8cd819f6213c345a633c05ec36e12287ee52e3d5edb6/neural-dream-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0c1f30be906e884dbd2c0fc89e39e735", "sha256": "16220dc62d628d475b9d6d72cad54004ed78d074b3662ad76ccbbada7d857b2b"}, "downloads": -1, "filename": "neural_dream-0.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0c1f30be906e884dbd2c0fc89e39e735", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 65692, "upload_time": "2020-04-19T15:21:05", "upload_time_iso_8601": "2020-04-19T15:21:05.933845Z", "url": "https://files.pythonhosted.org/packages/05/1a/e4ecf2df324aa1236cb273e0b87ad299796998ecd7727f5bfefe15f9dc95/neural_dream-0.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "845a7aa785fbe8e98c9d81f033772f03", "sha256": "9c67e0ccea63d8479576e4af2c89aefa3b569b3ed287d6651c1e572266c8620c"}, "downloads": -1, "filename": "neural_dream-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "845a7aa785fbe8e98c9d81f033772f03", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 65687, "upload_time": "2020-04-19T15:17:04", "upload_time_iso_8601": "2020-04-19T15:17:04.441340Z", "url": "https://files.pythonhosted.org/packages/d3/e7/f11af7c33ebe83bb4fa8f23926e3573455d92bd8dce8ad745897b4ce56c2/neural_dream-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b1b733d075685fc9c9817d3daa0d103c", "sha256": "62d814b8b6e1a2afce046a4f789d056e277ced41c59d94c86d17f468b8e5b38f"}, "downloads": -1, "filename": "neural-dream-0.0.4.tar.gz", "has_sig": false, "md5_digest": "b1b733d075685fc9c9817d3daa0d103c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52012, "upload_time": "2020-04-19T15:21:07", "upload_time_iso_8601": "2020-04-19T15:21:07.156456Z", "url": "https://files.pythonhosted.org/packages/1f/e5/770f7d227398973c8cd819f6213c345a633c05ec36e12287ee52e3d5edb6/neural-dream-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:48 2020"}