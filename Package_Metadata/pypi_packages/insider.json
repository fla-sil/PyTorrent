{"info": {"author": "W. Trevor King", "author_email": "wking@drexel.edu", "bugtrack_url": null, "classifiers": ["Environment :: Web Environment", "Framework :: Django", "Intended Audience :: Developers", "License :: OSI Approved :: GNU General Public License (GPL)", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Internet :: WWW/HTTP", "Topic :: Software Development :: Libraries"], "description": "Insider is a transaction-tracking application written in Python_ using\nthe Django_ framework.\n\nInstall\n=======\n\nDownload\n--------\n\nInsider is published as a Git_ repository.  See `insider's web\ninterface`__ for more information.\n\n__ insider_\n\nDependencies\n------------\n\nOutside of Django_ and the Python_ standard libraries, the only\nrequired dependency is `django-tables2`_ (docs__).  For some of the\nscraping libraries (`insider/scrape/*`), you'll also need\nBeautifulSoup_.\n\n__ dt2-docs_\n\nQuick-start\n===========\n\nIf you don't have a Django project and you just want to run insider as\na stand-alone service, you can use the example project written up in\n`example`.  Set up the project (once)::\n\n  $ python example/manage.py syncdb\n\nSee the `Django documentation`_ for more details.\n\nRun\n===\n\nRun the app on your local host (as many times as you like)::\n\n  $ python example/manage.py runserver\n\nYou may need to add the current directory to `PYTHONPATH` so `python`\ncan find the `insider` package.  If you're running `bash`, that will\nlook like\n\n  $ PYTHONPATH=\".:$PYTHONPATH\" python example/manage.py runserver\n\nScraping\n========\n\nEntering transaction data by hand can be tedious and error prone.  To\nautomate the task, you should write scrapers to look up and enter\ntransaction data automatically.  To get you started, I've written\n`insider/scrape/nasdaq.py`, which scrapes `NASDAQ's interface`__ to\n`EDGAR`_\\'s data.  Use the scraper with something like::\n\n  $ export PYTHONPATH='.'\n  $ export DJANGO_SETTINGS_MODULE='example.settings'\n  $ python insider/scrape/nasdaq.py NYSE:RHT NASDAQ:GOOG\n\n__ NASDAQ_\n\nIf the scraper doesn't extract company names (`nasdaq.py` does not),\nit's probably a good idea to add the relevant `Company` and `Ticker`\nto the database before running the scraper.  Otherwise you may get\ntickers from several echanges all pointing to the company `UNKNOWN`.\n\nHacking\n=======\n\nThis project was largely build following the `Django tutorial`_.\nThat's a good place to start if you're new to Django.\n\n.. _Python: http://www.python.org/\n.. _Django: https://www.djangoproject.com/\n.. _Git: http://git-scm.com/\n.. _insider: http://git.tremily.us/?p=insider.git\n.. _django-tables2: https://github.com/bradleyayers/django-tables2/\n.. _dt2-docs: http://django-tables2.readthedocs.org/en/latest/\n.. _BeautifulSoup: http://www.crummy.com/software/BeautifulSoup/\n.. _Django documentation: https://docs.djangoproject.com/\n.. _NASDAQ: http://www.nasdaq.com/reference/ownership.stm\n.. _EDGAR: http://www.edgar-online.com/\n.. _Django tutorial: https://docs.djangoproject.com/en/1.3/intro/tutorial01/", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://blog.tremily.us/posts/insider/", "keywords": null, "license": "GPL", "maintainer": null, "maintainer_email": null, "name": "insider", "package_url": "https://pypi.org/project/insider/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/insider/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://blog.tremily.us/posts/insider/"}, "release_url": "https://pypi.org/project/insider/0.1/", "requires_dist": null, "requires_python": null, "summary": "Transaction-tracking application for Django", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Insider is a transaction-tracking application written in <a href=\"http://www.python.org/\" rel=\"nofollow\">Python</a> using\nthe <a href=\"https://www.djangoproject.com/\" rel=\"nofollow\">Django</a> framework.</p>\n<div id=\"install\">\n<h2>Install</h2>\n<div id=\"download\">\n<h3>Download</h3>\n<p>Insider is published as a <a href=\"http://git-scm.com/\" rel=\"nofollow\">Git</a> repository.  See <a href=\"http://git.tremily.us/?p=insider.git\" rel=\"nofollow\">insider\u2019s web\ninterface</a> for more information.</p>\n</div>\n<div id=\"dependencies\">\n<h3>Dependencies</h3>\n<p>Outside of <a href=\"https://www.djangoproject.com/\" rel=\"nofollow\">Django</a> and the <a href=\"http://www.python.org/\" rel=\"nofollow\">Python</a> standard libraries, the only\nrequired dependency is <a href=\"https://github.com/bradleyayers/django-tables2/\" rel=\"nofollow\">django-tables2</a> (<a href=\"http://django-tables2.readthedocs.org/en/latest/\" rel=\"nofollow\">docs</a>).  For some of the\nscraping libraries (<cite>insider/scrape/*</cite>), you\u2019ll also need\n<a href=\"http://www.crummy.com/software/BeautifulSoup/\" rel=\"nofollow\">BeautifulSoup</a>.</p>\n</div>\n</div>\n<div id=\"quick-start\">\n<h2>Quick-start</h2>\n<p>If you don\u2019t have a Django project and you just want to run insider as\na stand-alone service, you can use the example project written up in\n<cite>example</cite>.  Set up the project (once):</p>\n<pre>$ python example/manage.py syncdb\n</pre>\n<p>See the <a href=\"https://docs.djangoproject.com/\" rel=\"nofollow\">Django documentation</a> for more details.</p>\n</div>\n<div id=\"run\">\n<h2>Run</h2>\n<p>Run the app on your local host (as many times as you like):</p>\n<pre>$ python example/manage.py runserver\n</pre>\n<p>You may need to add the current directory to <cite>PYTHONPATH</cite> so <cite>python</cite>\ncan find the <cite>insider</cite> package.  If you\u2019re running <cite>bash</cite>, that will\nlook like</p>\n<blockquote>\n$ PYTHONPATH=\u201d.:$PYTHONPATH\u201d python example/manage.py runserver</blockquote>\n</div>\n<div id=\"scraping\">\n<h2>Scraping</h2>\n<p>Entering transaction data by hand can be tedious and error prone.  To\nautomate the task, you should write scrapers to look up and enter\ntransaction data automatically.  To get you started, I\u2019ve written\n<cite>insider/scrape/nasdaq.py</cite>, which scrapes <a href=\"http://www.nasdaq.com/reference/ownership.stm\" rel=\"nofollow\">NASDAQ\u2019s interface</a> to\n<a href=\"http://www.edgar-online.com/\" rel=\"nofollow\">EDGAR</a>\u2019s data.  Use the scraper with something like:</p>\n<pre>$ export PYTHONPATH='.'\n$ export DJANGO_SETTINGS_MODULE='example.settings'\n$ python insider/scrape/nasdaq.py NYSE:RHT NASDAQ:GOOG\n</pre>\n<p>If the scraper doesn\u2019t extract company names (<cite>nasdaq.py</cite> does not),\nit\u2019s probably a good idea to add the relevant <cite>Company</cite> and <cite>Ticker</cite>\nto the database before running the scraper.  Otherwise you may get\ntickers from several echanges all pointing to the company <cite>UNKNOWN</cite>.</p>\n</div>\n<div id=\"hacking\">\n<h2>Hacking</h2>\n<p>This project was largely build following the <a href=\"https://docs.djangoproject.com/en/1.3/intro/tutorial01/\" rel=\"nofollow\">Django tutorial</a>.\nThat\u2019s a good place to start if you\u2019re new to Django.</p>\n</div>\n\n          </div>"}, "last_serial": 383798, "releases": {"0.1": []}, "urls": [], "timestamp": "Fri May  8 00:55:49 2020"}