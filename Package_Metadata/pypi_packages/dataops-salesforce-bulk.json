{"info": {"author": "Scott Persinger", "author_email": "scottp@heroku.com", "bugtrack_url": null, "classifiers": [], "description": "DataOps Salesforce Bulk\n===============\n**This library was forked from the salesforce-bulk library. It adds a feature\nfor dealing with pk chunking from Salesforce. Author credit is given to\nthe author of the original salesforce-bulk library (https://pypi.org/project/salesforce-bulk/)**\n\nPython client library for accessing the asynchronous Salesforce.com Bulk\nAPI.\n\nInstallation\n------------\n\n```\npip install dataops-salesforce-bulk\n```\n\nAuthentication\n--------------\n\nTo access the Bulk API you need to authenticate a user into Salesforce.\nThe easiest way to do this is just to supply ``username``, ``password``\nand ``security_token``. This library will use the ``simple-salesforce``\npackage to handle password based authentication.\n\n::\n\n    from salesforce_bulk import SalesforceBulk\n\n    bulk = SalesforceBulk(username=username, password=password, security_token=security_token)\n    ...\n\nAlternatively if you run have access to a session ID and instance\\_url\nyou can use those directly:\n\n::\n\n    from urlparse import urlparse\n    from salesforce_bulk import SalesforceBulk\n\n    bulk = SalesforceBulk(sessionId=sessionId, host=urlparse(instance_url).hostname)\n    ...\n\nOperations\n----------\n\nThe basic sequence for driving the Bulk API is:\n\n1. Create a new job\n2. Add one or more batches to the job\n3. Close the job\n4. Wait for each batch to finish\n\nBulk Query\n----------\n\n``bulk.create_query_job(object_name, contentType='JSON')``\n\nUsing API v39.0 or higher, you can also use the queryAll operation:\n\n``bulk.create_queryall_job(object_name, contentType='JSON')``\n\nExample\n\n::\n\n    from salesforce_bulk.util import IteratorBytesIO\n    import json\n    job = bulk.create_query_job(\"Contact\", contentType='JSON')\n    batch = bulk.query(job, \"select Id,LastName from Contact\")\n    bulk.close_job(job)\n    while not bulk.is_batch_done(batch):\n        sleep(10)\n\n    for result in bulk.get_all_results_for_query_batch(batch):\n        result = json.load(IteratorBytesIO(result))\n        for row in result:\n            print row # dictionary rows\n\nSame example but for CSV:\n\n::\n\n    import unicodecsv\n    job = bulk.create_query_job(\"Contact\", contentType='CSV')\n    batch = bulk.query(job, \"select Id,LastName from Contact\")\n    bulk.close_job(job)\n    while not bulk.is_batch_done(batch):\n        sleep(10)\n\n    for result in bulk.get_all_results_for_query_batch(batch):\n        reader = unicodecsv.DictReader(result, encoding='utf-8')\n        for row in reader:\n            print row # dictionary rows\n\nNote that while CSV is the default for historical reasons, JSON should\nbe prefered since CSV has some drawbacks including its handling of NULL\nvs empty string.\n\nPK Chunk Header\n^^^^^^^^^^^^^^^\n\nIf you are querying a large number of records you probably want to turn on `PK Chunking\n<https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/async_api_headers_enable_pk_chunking.htm>`_:\n\n``bulk.create_query_job(object_name, contentType='CSV', pk_chunking=True)``\n\nThat will use the default setting for chunk size. You can use a different chunk size by providing a\nnumber of records per chunk:\n\n``bulk.create_query_job(object_name, contentType='CSV', pk_chunking=100000)``\n\nAdditionally if you want to do something more sophisticated you can provide a header value:\n\n``bulk.create_query_job(object_name, contentType='CSV', pk_chunking='chunkSize=50000; startRow=00130000000xEftMGH')``\n\nBulk Insert, Update, Delete\n---------------------------\n\nAll Bulk upload operations work the same. You set the operation when you\ncreate the job. Then you submit one or more documents that specify\nrecords with columns to insert/update/delete. When deleting you should\nonly submit the Id for each record.\n\nFor efficiency you should use the ``post_batch`` method to post each\nbatch of data. (Note that a batch can have a maximum 10,000 records and\nbe 1GB in size.) You pass a generator or iterator into this function and\nit will stream data via POST to Salesforce. For help sending CSV\nformatted data you can use the salesforce\\_bulk.CsvDictsAdapter class.\nIt takes an iterator returning dictionaries and returns an iterator\nwhich produces CSV data.\n\nFull example:\n\n::\n\n    from salesforce_bulk import CsvDictsAdapter\n\n    job = bulk.create_insert_job(\"Account\", contentType='CSV')\n    accounts = [dict(Name=\"Account%d\" % idx) for idx in xrange(5)]\n    csv_iter = CsvDictsAdapter(iter(accounts))\n    batch = bulk.post_batch(job, csv_iter)\n    bulk.wait_for_batch(job, batch)\n    bulk.close_job(job)\n    print \"Done. Accounts uploaded.\"\n\nConcurrency mode\n^^^^^^^^^^^^^^^^\n\nWhen creating the job, pass ``concurrency='Serial'`` or\n``concurrency='Parallel'`` to set the concurrency mode for the job.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/puppetlabs/salesforce-bulk", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dataops-salesforce-bulk", "package_url": "https://pypi.org/project/dataops-salesforce-bulk/", "platform": "", "project_url": "https://pypi.org/project/dataops-salesforce-bulk/", "project_urls": {"Homepage": "https://github.com/puppetlabs/salesforce-bulk"}, "release_url": "https://pypi.org/project/dataops-salesforce-bulk/0.0.7/", "requires_dist": ["six", "requests (>=2.2.1)", "unicodecsv (>=0.14.1)", "simple-salesforce (>=0.69)"], "requires_python": "", "summary": "Python interface to the Salesforce.com Bulk API.", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DataOps Salesforce Bulk</h1>\n<p><strong>This library was forked from the salesforce-bulk library. It adds a feature\nfor dealing with pk chunking from Salesforce. Author credit is given to\nthe author of the original salesforce-bulk library (<a href=\"https://pypi.org/project/salesforce-bulk/\" rel=\"nofollow\">https://pypi.org/project/salesforce-bulk/</a>)</strong></p>\n<p>Python client library for accessing the asynchronous Salesforce.com Bulk\nAPI.</p>\n<h2>Installation</h2>\n<pre><code>pip install dataops-salesforce-bulk\n</code></pre>\n<h2>Authentication</h2>\n<p>To access the Bulk API you need to authenticate a user into Salesforce.\nThe easiest way to do this is just to supply <code>username</code>, <code>password</code>\nand <code>security_token</code>. This library will use the <code>simple-salesforce</code>\npackage to handle password based authentication.</p>\n<p>::</p>\n<pre><code>from salesforce_bulk import SalesforceBulk\n\nbulk = SalesforceBulk(username=username, password=password, security_token=security_token)\n...\n</code></pre>\n<p>Alternatively if you run have access to a session ID and instance_url\nyou can use those directly:</p>\n<p>::</p>\n<pre><code>from urlparse import urlparse\nfrom salesforce_bulk import SalesforceBulk\n\nbulk = SalesforceBulk(sessionId=sessionId, host=urlparse(instance_url).hostname)\n...\n</code></pre>\n<h2>Operations</h2>\n<p>The basic sequence for driving the Bulk API is:</p>\n<ol>\n<li>Create a new job</li>\n<li>Add one or more batches to the job</li>\n<li>Close the job</li>\n<li>Wait for each batch to finish</li>\n</ol>\n<h2>Bulk Query</h2>\n<p><code>bulk.create_query_job(object_name, contentType='JSON')</code></p>\n<p>Using API v39.0 or higher, you can also use the queryAll operation:</p>\n<p><code>bulk.create_queryall_job(object_name, contentType='JSON')</code></p>\n<p>Example</p>\n<p>::</p>\n<pre><code>from salesforce_bulk.util import IteratorBytesIO\nimport json\njob = bulk.create_query_job(\"Contact\", contentType='JSON')\nbatch = bulk.query(job, \"select Id,LastName from Contact\")\nbulk.close_job(job)\nwhile not bulk.is_batch_done(batch):\n    sleep(10)\n\nfor result in bulk.get_all_results_for_query_batch(batch):\n    result = json.load(IteratorBytesIO(result))\n    for row in result:\n        print row # dictionary rows\n</code></pre>\n<p>Same example but for CSV:</p>\n<p>::</p>\n<pre><code>import unicodecsv\njob = bulk.create_query_job(\"Contact\", contentType='CSV')\nbatch = bulk.query(job, \"select Id,LastName from Contact\")\nbulk.close_job(job)\nwhile not bulk.is_batch_done(batch):\n    sleep(10)\n\nfor result in bulk.get_all_results_for_query_batch(batch):\n    reader = unicodecsv.DictReader(result, encoding='utf-8')\n    for row in reader:\n        print row # dictionary rows\n</code></pre>\n<p>Note that while CSV is the default for historical reasons, JSON should\nbe prefered since CSV has some drawbacks including its handling of NULL\nvs empty string.</p>\n<p>PK Chunk Header\n^^^^^^^^^^^^^^^</p>\n<p>If you are querying a large number of records you probably want to turn on <code>PK Chunking &lt;https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/async_api_headers_enable_pk_chunking.htm&gt;</code>_:</p>\n<p><code>bulk.create_query_job(object_name, contentType='CSV', pk_chunking=True)</code></p>\n<p>That will use the default setting for chunk size. You can use a different chunk size by providing a\nnumber of records per chunk:</p>\n<p><code>bulk.create_query_job(object_name, contentType='CSV', pk_chunking=100000)</code></p>\n<p>Additionally if you want to do something more sophisticated you can provide a header value:</p>\n<p><code>bulk.create_query_job(object_name, contentType='CSV', pk_chunking='chunkSize=50000; startRow=00130000000xEftMGH')</code></p>\n<h2>Bulk Insert, Update, Delete</h2>\n<p>All Bulk upload operations work the same. You set the operation when you\ncreate the job. Then you submit one or more documents that specify\nrecords with columns to insert/update/delete. When deleting you should\nonly submit the Id for each record.</p>\n<p>For efficiency you should use the <code>post_batch</code> method to post each\nbatch of data. (Note that a batch can have a maximum 10,000 records and\nbe 1GB in size.) You pass a generator or iterator into this function and\nit will stream data via POST to Salesforce. For help sending CSV\nformatted data you can use the salesforce_bulk.CsvDictsAdapter class.\nIt takes an iterator returning dictionaries and returns an iterator\nwhich produces CSV data.</p>\n<p>Full example:</p>\n<p>::</p>\n<pre><code>from salesforce_bulk import CsvDictsAdapter\n\njob = bulk.create_insert_job(\"Account\", contentType='CSV')\naccounts = [dict(Name=\"Account%d\" % idx) for idx in xrange(5)]\ncsv_iter = CsvDictsAdapter(iter(accounts))\nbatch = bulk.post_batch(job, csv_iter)\nbulk.wait_for_batch(job, batch)\nbulk.close_job(job)\nprint \"Done. Accounts uploaded.\"\n</code></pre>\n<p>Concurrency mode\n^^^^^^^^^^^^^^^^</p>\n<p>When creating the job, pass <code>concurrency='Serial'</code> or\n<code>concurrency='Parallel'</code> to set the concurrency mode for the job.</p>\n\n          </div>"}, "last_serial": 6605617, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "2fe2522902d6360ab2e5c603c812e59e", "sha256": "50c1fca489243c2dba6aaaaa68dd6da0a6536ec2024cff72f73bf661bc2f272f"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2fe2522902d6360ab2e5c603c812e59e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10251, "upload_time": "2020-02-10T16:53:00", "upload_time_iso_8601": "2020-02-10T16:53:00.330627Z", "url": "https://files.pythonhosted.org/packages/a1/51/f9b373a03b8c21bf36513bf4920a75a1d237e2b290f58b9be1f8b666f491/dataops_salesforce_bulk-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "11949828957367f8d51b75574a4b5713", "sha256": "08381dbb36b82abc88c3057a0fa478fe43fdf3a1a25e8e019d5d865d9e4db4c9"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.1.tar.gz", "has_sig": false, "md5_digest": "11949828957367f8d51b75574a4b5713", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8220, "upload_time": "2020-02-10T16:53:02", "upload_time_iso_8601": "2020-02-10T16:53:02.443375Z", "url": "https://files.pythonhosted.org/packages/92/59/3e07ceb142df467f9f8d3620f794dfb64f75264542b8152afa277cdea8d8/dataops-salesforce-bulk-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "043c38e3df5f39a5e75ca1c507029ef7", "sha256": "e2bd2eb0a8d3d9f5f5da2604cc6d9ebbb71d408a9f1282b7cfde0edce0e7b7a2"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "043c38e3df5f39a5e75ca1c507029ef7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10250, "upload_time": "2020-02-10T16:58:51", "upload_time_iso_8601": "2020-02-10T16:58:51.454013Z", "url": "https://files.pythonhosted.org/packages/5e/48/4bad10bda0a7dc88e76e1b627577c1a04cdeddf3626672b02bc5a7a098fc/dataops_salesforce_bulk-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e71b941481917f935f1606ed0d542b45", "sha256": "6be398b299cc50a3b14886bd88cbfa885f58a7a60d5d8cdd5fe573a100bdf2ba"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.2.tar.gz", "has_sig": false, "md5_digest": "e71b941481917f935f1606ed0d542b45", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8212, "upload_time": "2020-02-10T16:58:52", "upload_time_iso_8601": "2020-02-10T16:58:52.264392Z", "url": "https://files.pythonhosted.org/packages/d9/07/08b1388a5186ef5cc29405a95b7a644456ba3ce61a3b1b7817a523d658e7/dataops-salesforce-bulk-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "dbb02091e9b6251386aea7fb4f78155d", "sha256": "2a91fef6b06201ce10d6d00e5f39c6ab0e36cebe498ef6c263ce2031a7804c4c"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "dbb02091e9b6251386aea7fb4f78155d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10333, "upload_time": "2020-02-10T17:08:34", "upload_time_iso_8601": "2020-02-10T17:08:34.170343Z", "url": "https://files.pythonhosted.org/packages/13/6b/45a70397147fe74447ef8a2b214d59848e525c275485b40a0018e38efcd7/dataops_salesforce_bulk-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8e5048ad2a358507f5c2eed95bd53bbd", "sha256": "9274a94c0bc62140c9c5f4c77ff22fc432cda19f8a2fe2c620b3819faa6f2d08"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.3.tar.gz", "has_sig": false, "md5_digest": "8e5048ad2a358507f5c2eed95bd53bbd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8324, "upload_time": "2020-02-10T17:08:35", "upload_time_iso_8601": "2020-02-10T17:08:35.250584Z", "url": "https://files.pythonhosted.org/packages/7a/24/928f57550621fe31c53ad030c74310a7711af50ce77b6a4ae3b6a5d2ef85/dataops-salesforce-bulk-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "98702eb0031374302dece79c071f50fc", "sha256": "6670b478079e86a159a15238b560e6b3a09f2b44a4c4a28ce9b5dab74b349a7f"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "98702eb0031374302dece79c071f50fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10356, "upload_time": "2020-02-10T17:10:40", "upload_time_iso_8601": "2020-02-10T17:10:40.055184Z", "url": "https://files.pythonhosted.org/packages/67/a6/1ed1228de4322a801d99c6f31be0b551b1bfa65d4a96bc98669d76907d34/dataops_salesforce_bulk-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4fcbcb094a70f2f90dbf2cec0896b8be", "sha256": "fca5752f21d61f56bb2a5d85025e02ab1a2e84858fefd0ffc26528e24591f2c8"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.4.tar.gz", "has_sig": false, "md5_digest": "4fcbcb094a70f2f90dbf2cec0896b8be", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8352, "upload_time": "2020-02-10T17:10:41", "upload_time_iso_8601": "2020-02-10T17:10:41.243324Z", "url": "https://files.pythonhosted.org/packages/d1/58/786024310378e04fa0bf6b9be44c8a445a54868cd18e034c7e16f675ff90/dataops-salesforce-bulk-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "c32c87c6e9a3b4b8613a0e1a5eb60a8d", "sha256": "5aa8931fe7f4725e40984d26842b04fb1c52ee31aa40f4fd75c490b1c4fd6f45"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "c32c87c6e9a3b4b8613a0e1a5eb60a8d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10359, "upload_time": "2020-02-10T22:02:58", "upload_time_iso_8601": "2020-02-10T22:02:58.127324Z", "url": "https://files.pythonhosted.org/packages/71/e0/f98af87677538f03c48416467d8ef00e426534576eefb75fad87e310af64/dataops_salesforce_bulk-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "80f1acf2352b13e65216299f70b110e5", "sha256": "b75e0f6b14dd14d7211d4e9fb7a7dae8aee8ce8b9c46c1cfe73c0d80513c75b1"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.5.tar.gz", "has_sig": false, "md5_digest": "80f1acf2352b13e65216299f70b110e5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8361, "upload_time": "2020-02-10T22:02:59", "upload_time_iso_8601": "2020-02-10T22:02:59.125539Z", "url": "https://files.pythonhosted.org/packages/e9/4f/a37fb0a90f84ca145ea3c2675f1f9b551e5c4517759c6009e27c8d9ecdd9/dataops-salesforce-bulk-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "9fdb023cc8caff347e3311bb060896b4", "sha256": "8dccd7d3a91c13c6f3cb42f6d016fe326f6e6a63cde72a7d13f0fde9ac75d47e"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "9fdb023cc8caff347e3311bb060896b4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10351, "upload_time": "2020-02-10T22:10:33", "upload_time_iso_8601": "2020-02-10T22:10:33.770569Z", "url": "https://files.pythonhosted.org/packages/e3/4a/7fbf19211766e78073c541ac83ac95607e77abebc2d969d3ed237d666906/dataops_salesforce_bulk-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "806707d9015f255e1721530246bde8a4", "sha256": "d3637194cd16a9e8abd85522abcda8b74da63d80ba8c0fd5a0d22f22536f5f7e"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.6.tar.gz", "has_sig": false, "md5_digest": "806707d9015f255e1721530246bde8a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8375, "upload_time": "2020-02-10T22:10:35", "upload_time_iso_8601": "2020-02-10T22:10:35.018174Z", "url": "https://files.pythonhosted.org/packages/33/d7/9432603cc1486455244f82c3bc77d0779a5c64cb4a458ebeeff95ca592ee/dataops-salesforce-bulk-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "9ea53b63e427360b2a8c7920f2dacf57", "sha256": "6f8e6a6e139bf731c892ffbeb0814970db3e79ad37a9b281f6df7d5a5ca57758"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "9ea53b63e427360b2a8c7920f2dacf57", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10352, "upload_time": "2020-02-10T22:23:43", "upload_time_iso_8601": "2020-02-10T22:23:43.913310Z", "url": "https://files.pythonhosted.org/packages/a5/ab/642e315a5d1795392bbea9da0ab99336ba227a5c6585f3bab78c0a2dba5d/dataops_salesforce_bulk-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "84debb0347ac7171ec041c8688eb497b", "sha256": "db1f22a5b4b9c68a65fe53cf77cf663b836b22a23b1dbf8afc5aa1436b89be2b"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.7.tar.gz", "has_sig": false, "md5_digest": "84debb0347ac7171ec041c8688eb497b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8368, "upload_time": "2020-02-10T22:23:44", "upload_time_iso_8601": "2020-02-10T22:23:44.802774Z", "url": "https://files.pythonhosted.org/packages/50/3a/fa1616150d426ea19d96a2a548fbf2c6a63dba2a229385a327f98d8e269d/dataops-salesforce-bulk-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9ea53b63e427360b2a8c7920f2dacf57", "sha256": "6f8e6a6e139bf731c892ffbeb0814970db3e79ad37a9b281f6df7d5a5ca57758"}, "downloads": -1, "filename": "dataops_salesforce_bulk-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "9ea53b63e427360b2a8c7920f2dacf57", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10352, "upload_time": "2020-02-10T22:23:43", "upload_time_iso_8601": "2020-02-10T22:23:43.913310Z", "url": "https://files.pythonhosted.org/packages/a5/ab/642e315a5d1795392bbea9da0ab99336ba227a5c6585f3bab78c0a2dba5d/dataops_salesforce_bulk-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "84debb0347ac7171ec041c8688eb497b", "sha256": "db1f22a5b4b9c68a65fe53cf77cf663b836b22a23b1dbf8afc5aa1436b89be2b"}, "downloads": -1, "filename": "dataops-salesforce-bulk-0.0.7.tar.gz", "has_sig": false, "md5_digest": "84debb0347ac7171ec041c8688eb497b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8368, "upload_time": "2020-02-10T22:23:44", "upload_time_iso_8601": "2020-02-10T22:23:44.802774Z", "url": "https://files.pythonhosted.org/packages/50/3a/fa1616150d426ea19d96a2a548fbf2c6a63dba2a229385a327f98d8e269d/dataops-salesforce-bulk-0.0.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:18 2020"}