{"info": {"author": "Ivan Georgiev", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# pyspark-me\nPyspark and Databricks tools for everyday life\n\n## Synopsis\n\n### Create Databricks connection\n\n```python\n# Get Databricks workspace connection\ndbc = pysparkme.databricks.connect(\n        bearer_token='dapixyzabcd09rasdf',\n        url='https://westeurope.azuredatabricks.net')\n```\n\n### DBFS\n\n```python\n# Get list of items at path /FileStore\ndbc.dbfs.ls('/FileStore')\n\n# Check if file or directory exists\ndbc.dbfs.exists('/path/to/heaven')\n\n# Make a directory and it's parents\ndbc.dbfs.mkdirs('/path/to/heaven')\n\n# Delete a directory recusively\ndbc.dbfs.rm('/path', recursive=True)\n\n# Download file block starting 1024 with size 2048\ndbc.dbfs.read('/data/movies.csv', 1024, 2048)\n\n# Download entire file\ndbc.dbfs.read_all('/data/movies.csv')\n```\n\n### Databricks workspace\n\n```python\n# List root workspace directory\ndbc.workspace.ls('/')\n\n# Check if workspace item exists\ndbc.workspace.exists('/explore')\n\n# Check if workspace item is a directory\ndbc.workspace.is_directory('/')\n\n# Export notebook in default (SOURCE) format\ndbc.workspace.export('/my_notebook')\n\n# Export notebook in HTML format\ndbc.workspace.export('/my_notebook', 'HTML')\n```\n\n## Databricks CLI\n\nGet CLI help\n```bash\npython -m pysparkme.databricks.cli --help\n```\n\nExport the whole Databricks workspace into a directory `explore/export`.\nDatabricks token is taken from `DATABRICKS_BEARER_TOKEN`  environment variable.\n\n```\npython -m pysparkme.databricks.cli workspace export -o explore/export ''\n```\n### DBFS\n\n```bash\n# List items on DBFS\npython -m pysparkme.databricks.cli dbfs ls --json-indent 2 ''\n```\n\n```bash\n# Download a file and print to STDOUT\npython -m pysparkme.databricks.cli dbfs get ml-latest-small/movies.csv\n```\n\n```bash\n# Download recursively entire directory and store locally\npython -m pysparkme.databricks.cli dbfs get -o ml-local ml-latest-small\n```\n\n## Build and publish\n\n```bash\npython setup.py sdist bdist_wheel\npython -m twine upload dist/*\n```\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ivangeorgiev/pyspark-me", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pyspark-me", "package_url": "https://pypi.org/project/pyspark-me/", "platform": "", "project_url": "https://pypi.org/project/pyspark-me/", "project_urls": {"Homepage": "https://github.com/ivangeorgiev/pyspark-me"}, "release_url": "https://pypi.org/project/pyspark-me/0.0.5/", "requires_dist": ["click", "requests"], "requires_python": ">=3.6", "summary": "Pyspark tools for everyday use", "version": "0.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pyspark-me</h1>\n<p>Pyspark and Databricks tools for everyday life</p>\n<h2>Synopsis</h2>\n<h3>Create Databricks connection</h3>\n<pre><span class=\"c1\"># Get Databricks workspace connection</span>\n<span class=\"n\">dbc</span> <span class=\"o\">=</span> <span class=\"n\">pysparkme</span><span class=\"o\">.</span><span class=\"n\">databricks</span><span class=\"o\">.</span><span class=\"n\">connect</span><span class=\"p\">(</span>\n        <span class=\"n\">bearer_token</span><span class=\"o\">=</span><span class=\"s1\">'dapixyzabcd09rasdf'</span><span class=\"p\">,</span>\n        <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'https://westeurope.azuredatabricks.net'</span><span class=\"p\">)</span>\n</pre>\n<h3>DBFS</h3>\n<pre><span class=\"c1\"># Get list of items at path /FileStore</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">dbfs</span><span class=\"o\">.</span><span class=\"n\">ls</span><span class=\"p\">(</span><span class=\"s1\">'/FileStore'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Check if file or directory exists</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">dbfs</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/heaven'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Make a directory and it's parents</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">dbfs</span><span class=\"o\">.</span><span class=\"n\">mkdirs</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/heaven'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Delete a directory recusively</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">dbfs</span><span class=\"o\">.</span><span class=\"n\">rm</span><span class=\"p\">(</span><span class=\"s1\">'/path'</span><span class=\"p\">,</span> <span class=\"n\">recursive</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Download file block starting 1024 with size 2048</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">dbfs</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"s1\">'/data/movies.csv'</span><span class=\"p\">,</span> <span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"mi\">2048</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Download entire file</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">dbfs</span><span class=\"o\">.</span><span class=\"n\">read_all</span><span class=\"p\">(</span><span class=\"s1\">'/data/movies.csv'</span><span class=\"p\">)</span>\n</pre>\n<h3>Databricks workspace</h3>\n<pre><span class=\"c1\"># List root workspace directory</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">workspace</span><span class=\"o\">.</span><span class=\"n\">ls</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Check if workspace item exists</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">workspace</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"s1\">'/explore'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Check if workspace item is a directory</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">workspace</span><span class=\"o\">.</span><span class=\"n\">is_directory</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Export notebook in default (SOURCE) format</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">workspace</span><span class=\"o\">.</span><span class=\"n\">export</span><span class=\"p\">(</span><span class=\"s1\">'/my_notebook'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Export notebook in HTML format</span>\n<span class=\"n\">dbc</span><span class=\"o\">.</span><span class=\"n\">workspace</span><span class=\"o\">.</span><span class=\"n\">export</span><span class=\"p\">(</span><span class=\"s1\">'/my_notebook'</span><span class=\"p\">,</span> <span class=\"s1\">'HTML'</span><span class=\"p\">)</span>\n</pre>\n<h2>Databricks CLI</h2>\n<p>Get CLI help</p>\n<pre>python -m pysparkme.databricks.cli --help\n</pre>\n<p>Export the whole Databricks workspace into a directory <code>explore/export</code>.\nDatabricks token is taken from <code>DATABRICKS_BEARER_TOKEN</code>  environment variable.</p>\n<pre><code>python -m pysparkme.databricks.cli workspace export -o explore/export ''\n</code></pre>\n<h3>DBFS</h3>\n<pre><span class=\"c1\"># List items on DBFS</span>\npython -m pysparkme.databricks.cli dbfs ls --json-indent <span class=\"m\">2</span> <span class=\"s1\">''</span>\n</pre>\n<pre><span class=\"c1\"># Download a file and print to STDOUT</span>\npython -m pysparkme.databricks.cli dbfs get ml-latest-small/movies.csv\n</pre>\n<pre><span class=\"c1\"># Download recursively entire directory and store locally</span>\npython -m pysparkme.databricks.cli dbfs get -o ml-local ml-latest-small\n</pre>\n<h2>Build and publish</h2>\n<pre>python setup.py sdist bdist_wheel\npython -m twine upload dist/*\n</pre>\n\n          </div>"}, "last_serial": 7191967, "releases": {"0.0.4": [{"comment_text": "", "digests": {"md5": "36ddeff0629f770782b2295d075fdfd5", "sha256": "0688b7ceebf2c1505d7126595a04a527d01056be9ad0b1ee5f1690d7bbd9f1b1"}, "downloads": -1, "filename": "pyspark_me-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "36ddeff0629f770782b2295d075fdfd5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 18947, "upload_time": "2020-05-07T16:30:12", "upload_time_iso_8601": "2020-05-07T16:30:12.769671Z", "url": "https://files.pythonhosted.org/packages/66/a5/05a2d1def183cb985a62d24f1dacbc03cb3e0ba6585c9e5e4f6358687583/pyspark_me-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "009b4280452666ba0d9c2a7418f16793", "sha256": "c1d51837c07b25d3846db604c5b5d6d2846f42906ebf7fa49d7a0b69beb6e733"}, "downloads": -1, "filename": "pyspark-me-0.0.4.tar.gz", "has_sig": false, "md5_digest": "009b4280452666ba0d9c2a7418f16793", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7586, "upload_time": "2020-05-07T16:30:14", "upload_time_iso_8601": "2020-05-07T16:30:14.014622Z", "url": "https://files.pythonhosted.org/packages/61/3f/69a593e45a9ea062f6f8c3efab21c9de3ce86ec50f80b88fbd0ab4abda87/pyspark-me-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "fb36649e95d215288907aaff86bb3a62", "sha256": "feb3a0913626c12a5d0a58ac126698fb0e5f28d4b03ed657d27c0f4f9301b272"}, "downloads": -1, "filename": "pyspark_me-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "fb36649e95d215288907aaff86bb3a62", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 19930, "upload_time": "2020-05-07T21:27:01", "upload_time_iso_8601": "2020-05-07T21:27:01.308132Z", "url": "https://files.pythonhosted.org/packages/77/c5/a1340daf66f8ef1491576445042d9d765546d0d57181ba9873336ab11cd0/pyspark_me-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b0ec5f52f31f0279fe5cf82fb6eca4c", "sha256": "d3c2ae5a10654ce2682ddc5ff579285d188ec9605875a5f918384e77f71c9e3e"}, "downloads": -1, "filename": "pyspark-me-0.0.5.tar.gz", "has_sig": false, "md5_digest": "8b0ec5f52f31f0279fe5cf82fb6eca4c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8565, "upload_time": "2020-05-07T21:27:02", "upload_time_iso_8601": "2020-05-07T21:27:02.458779Z", "url": "https://files.pythonhosted.org/packages/de/37/240c101668eda0967b53586d8653a54cac963d4ca95c90ec6fc62a131e63/pyspark-me-0.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fb36649e95d215288907aaff86bb3a62", "sha256": "feb3a0913626c12a5d0a58ac126698fb0e5f28d4b03ed657d27c0f4f9301b272"}, "downloads": -1, "filename": "pyspark_me-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "fb36649e95d215288907aaff86bb3a62", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 19930, "upload_time": "2020-05-07T21:27:01", "upload_time_iso_8601": "2020-05-07T21:27:01.308132Z", "url": "https://files.pythonhosted.org/packages/77/c5/a1340daf66f8ef1491576445042d9d765546d0d57181ba9873336ab11cd0/pyspark_me-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b0ec5f52f31f0279fe5cf82fb6eca4c", "sha256": "d3c2ae5a10654ce2682ddc5ff579285d188ec9605875a5f918384e77f71c9e3e"}, "downloads": -1, "filename": "pyspark-me-0.0.5.tar.gz", "has_sig": false, "md5_digest": "8b0ec5f52f31f0279fe5cf82fb6eca4c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8565, "upload_time": "2020-05-07T21:27:02", "upload_time_iso_8601": "2020-05-07T21:27:02.458779Z", "url": "https://files.pythonhosted.org/packages/de/37/240c101668eda0967b53586d8653a54cac963d4ca95c90ec6fc62a131e63/pyspark-me-0.0.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:18 2020"}