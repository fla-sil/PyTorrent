{"info": {"author": "Mike Phillipson", "author_email": "MICHAEL_PHILLIPSON1@homedepot.com", "bugtrack_url": null, "classifiers": [], "description": "# metREx\n\nSQL query and monitoring system metrics exporter for [Prometheus](https://prometheus.io/). A product of **Reliability Engineering** at [The Home Depot](https://www.homedepot.com/).\n\nSupported database engines include:\n- [DB2](https://www.ibm.com/products/db2-database) / [Informix](https://www.ibm.com/products/informix)\n- [Google BigQuery](https://cloud.google.com/bigquery)\n- [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/default.aspx)\n- [MySQL](https://www.mysql.com/)\n- [Oracle](https://www.oracle.com/database)\n- [PostgreSQL](https://www.postgresql.org/)\n\nPrometheus metrics can be generated from the following monitoring systems:\n- [AppDynamics](https://www.appdynamics.com/)\n- [ExtraHop](https://www.extrahop.com/)\n\n## Table of Contents\n\n* [Installation](#installation)\n  * [Database Engines](#database-engines)\n* [Local Environment Setup](#local-environment-setup)\n  * [ENV Variables](#env-variables)\n* [Configuration: Services](#configuration-services)\n  * [Database Connection Parameters](#database-connection-parameters)\n  * [API Connection Parameters](#api-connection-parameters)\n  * [Encrypting Credentials](#encrypting-credentials)\n* [Configuration: Jobs](#configuration-jobs)\n  * [Defining Jobs as Services](#defining-jobs-as-services)\n  * [Defining Jobs in a GitHub Repository](#defining-jobs-in-a-github-repository)\n  * [Job Parameters](#job-parameters)\n  * [About Aggregation](#about-aggregation)\n* [Exposing Metrics to a Pushgateway](#exposing-metrics-to-a-pushgateway)\n* [Running the Application](#running-the-application)\n* [Running in Docker](#running-in-docker)\n* [Swagger](#swagger)\n* [Testing](#testing)\n* [License](#license)\n\n## Installation\n\n```shell\n$ pip install metREx\n```\n\n### Database Engines\n\nThe [SQLAlchemy](https://www.sqlalchemy.org/) package used by this application enables connectivity to a variety of database engines. However, additional packages may need to be installed, depending on which engines are used.\n\nA variation on the above `pip install` command can be used to include specific SQLAlchemy driver packages as needed.*\n\nIn the following example, the dialect identifiers `mysql` and `postgres`, supplied in brackets, will install the `pymysql` and `pg8000` driver packages for MySQL and PostgreSQL database connectivity, respectively:\n\n```shell\n$ pip install metREx[mysql,postgresql]\n```\n\nFor convenience, a selection of predefined dialects are available for commonly used SQLAlchemy driver packages:*\n\n| Dialect      | Driver       |\n| :---         | :---         |\n| `bigquery`   | `pybigquery` |\n| `db2`        | `ibm_db_sa`  |\n| `mssql`      | `pymssql`    |\n| `mysql`      | `pymysql`    |\n| `oracle`     | `cx_oracle`  |\n| `postgresql` | `pg8000`     |\n\nTo install any combination of these SQLAlchemy drivers, substitute their dialect identifiers, delimited by commas, within the brackets shown in the previous example *(see [Supported Drivers](http://docs.sqlalchemy.org/en/latest/core/engines.html#supported-databases) for details about other SQLAlchemy drivers not mapped to the predefined dialects above)*.\n\n*NOTE: Additional client software may also be required for certain database engines. Installation steps will vary depending on the host operating system.\n\n## Local Environment Setup\n\nA `.env` file can optionally be used to define environment variables available to the application at runtime. This can be useful when running in a local development environment.\n\nThe `.env` file should be placed in the installed package root. Any of the `.env.*` files included in the `examples` folder can be renamed to `.env`, as shown below:\n\n```shell\n$ cp examples/.env.macos-oracle metREx/.env\n```\n\n### ENV Variables\n\nThe following ENV variables can be used to configure various application behaviors:\n- **BOILERPLATE_ENV**: (Default: `dev`) The configuration profile applied to running app instances. Possible values: `dev`, `test`, or `prod`.\n- **DEBUG**: (Default: `true` if **BOILERPLATE_ENV** is `dev`, or false otherwise) Whether debug mode is enabled.\n- **IP_ADDRESS**: (Default: `127.0.0.1`) The internal IP address of the running app instance. \n- **PORT**: (Default: `5000`) The port on which the application listens for requests.\n- **LD_LIBRARY_PATH**: (Linux) A colon-separated list of the directories containing required database client libraries. Required for some SQLAlchemy drivers.\n- **DYLD_LIBRARY_PATH**: (macOS) A colon-separated list of the directories containing required database client libraries. Required for some SQLAlchemy drivers.\n- **GOOGLE_APPLICATION_CREDENTIALS**: The full path to the Google service account credentials JSON file to use as the default for BigQuery connections.\n- **SECRET_KEY**: The secret used to unlock encrypted credentials. May optionally be substituted with the path to a secret key file *(see **SECRET_PATH** below)*.\n- **SECRET_PATH**: (Default: `secrets.yml`) The location of the secret key file used to unlock encrypted service credentials. Can be used when the secret is not explicitly defined via an environment variable *(see **SECRET_KEY** above)*.\n- **SERVICES_PATH**: (Non-CF environments; default: `env/services.yml`) The location of a file containing the list of service connections (and optionally, metric exporter job definitions) available to the application at runtime.\n- **API_PREFIX**: (Default: `METREX_API_`) The prefix required for services containing API connection details.\n- **DB_PREFIX**: (Default: `METREX_DB_`) The prefix required for services containing database connection details.\n- **JOB_PREFIX**: (Default: `METREX_JOB_`) The prefix required for services containing metric exporter job details (not applicable to jobs defined in a GitHub repository).\n- **ERROR_INCLUDE_MESSAGE**: (Default: `true`) Whether to include detailed error messages in API responses. A generic \"Internal Server Error\" message will be returned on failure when `false`.\n- **SUSPEND_JOB_ON_FAILURE**: (Default: `false`) Whether to suspend metric exporter jobs immediately on failure. Suspended jobs may be resumed manually via the Scheduler API or by restarting the application.\n- **APIALCHEMY_APPD_SSL_VERIFY**: (Default: `true`) Whether to perform certificate verification for AppDynamics API connections.\n- **APIALCHEMY_EXTRAHOP_SSL_VERIFY**: (Default: `true`) Whether to perform certificate verification for ExtraHop API connections.\n- **APIALCHEMY_GITHUB_SSL_VERIFY**: (Default: `true`) Whether to perform certificate verification for GitHub API connections.\n- **APIALCHEMY_PUSHGATEWAY_SSL_VERIFY**: (Default: `true`) Whether to perform certificate verification for Pushgateway API connections.\n- **DB_DEFAULT_LOCAL_TZ**: (Default: `UTC`) The localized timezone applied by default to \"naive\" (non-TZ-aware) `timestamp_column` values* if defined in database-sourced metric exporter jobs (consult the [Time Zone Database](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) for a complete list of supported TZ names).\n- **JOBS_SOURCE_SERVICE**: The name of the service containing GitHub API connection details.\n- **JOBS_SOURCE_ORG**: The name of the GitHub org in which job definitions are hosted.\n- **JOBS_SOURCE_REPO**: The name of the GitHub repository in which job definitions are hosted.\n- **JOBS_SOURCE_BRANCH**: (Default: `master`) The branch name of the GitHub-hosted job definitions.\n- **JOBS_SOURCE_PATH**: The relative file path to GitHub-hosted job definitions.\n- **JOBS_SOURCE_REFRESH_INTERVAL**: (Default: `60`) An integer value representing the polling interval, expressed in minutes, for checking a GitHub-hosted job repository for changes to job definitions.\n- **PUSHGATEWAY_SERVICES**: The name(s) of the service(s) containing Pushgateway API connection details (comma-delimited, if more than one).\n- **MISFIRE_GRACE_TIME**: (Default: `5`) The seconds after the designated runtime that a metric exporter job is still allowed to be run.\n- **THREADPOOL_MAX_WORKERS**: (Default: `20`) The maximum number of spawned threads for the default metric exporter job executor.\n- **PROCESSPOOL_MAX_WORKERS**: (Default: `10`) The maximum number of spawned processes for the default metric exporter job executor.\n\n*Does not apply to `timestamp_column` values that contain timezone information; can be overridden on a per-service basis with the `timezone` option.\n\n## Configuration: Services\n\nThis application was originally designed to run on [Cloud Foundry (CF)](https://github.com/cloudfoundry). However, it can also be configured for other environments.\n\nWhen running in Cloud Foundry, the connection parameters used by metric exporter \"jobs\" are defined via [user-provided service instances](https://docs.cloudfoundry.org/devguide/services/user-provided.html).\n\nIn non-CF environments, services can be defined via a YAML configuration file (default: `env/services.yml`), as shown in the following example:\n\n```yaml\n---\nMETREX_DB_MYSQL_EXAMPLE:\n  name: database_name\n  hostname: mysql.mydomain.com\n  port: 3306\n  username: user\n  password: password\n  encrypted: false\n  dialect: mysql\n  driver: pymysql\nMETREX_DB_BIGQUERY_EXAMPLE:\n  project: gcp-project-name\n  location: US\n  credentials_path: /path/to/service/account/credentials.json\n  dialect: bigquery\n  driver: pybigquery\nMETREX_API_APPD:\n  hostname: appdynamics.mydomain.com\n  username: user\n  password: password\n  encrypted: false\n  vendor: appdynamics\nMETREX_API_EXTRAHOP:\n  hostname: extrahop.mydomain.com\n  apikey: extrahop_apikey\n  encrypted: false\n  vendor: extrahop\nMETREX_API_GITHUB:\n  hostname: github.com\n  apikey: github_apikey\n  encrypted: false\n  vendor: github\n```\n\n### Database Connection Parameters\n\nThe names assigned to services containing database connection details must begin with the prefix `METREX_DB_` (or the value of the **DB_PREFIX** environment variable). The text that appears after this prefix will be prepended to the names of all Prometheus metrics generated from this service.\n\nFor database connections (except BigQuery), the following parameters must be included:\n- `name`: Database or service name\n- `hostname`: Server name or IP address\n- `port`: Port number\n- `username`: User name\n- `password`: Password\n- `encrypted`: \"true\" (recommended) if `password` value is encrypted or \"false\" if it is not.\n- `dialect`: Dialect identifier *(refer to table of Dialect/Driver mappings in [Database Engines](#database-engines) section above)*\n- `driver`: SQLAlchemy driver *(refer to table of Dialect/Driver mappings in [Database Engines](#database-engines) section above)*\n- `timezone`: Localized [database timezone](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) to apply to \"naive\" (non-TZ-aware) `timestamp_column` values returned by metric exporter jobs (optional, to override the **DB_DEFAULT_LOCAL_TZ** env variable)\n\nFor BigQuery connections, the following parameters are used:\n- `project`: Name of the GCP project (defaults to the project specified in the credentials JSON file)\n- `location`: Specifies the dataset location (optional)\n- `credentials_path`: Full path to the service account credentials JSON file (optional)*\n- `credentials_info`: Contents of the service account credentials JSON file (optional)*\n- `encrypted`: \"true\" (recommended) if the `credentials_info` value is encrypted or \"false\" if it is not (optional, for use only with `credentials_info`)\n- `dialect`: \"bigquery\"\n- `driver`: \"pybigquery\"\n\n*NOTE: Either `credentials_path` or `credentials_info` can be used instead of or to override the **GOOGLE_APPLICATION_CREDENTIALS** ENV variable on a per-service basis. `credentials_path` takes precedence if provided in combination with **GOOGLE_APPLICATION_CREDENTIALS** or `credentials_info`.\n\n### API Connection Parameters\n\nThe names assigned to services containing API connection details must begin with the prefix `METREX_API_` (or the value of the **API_PREFIX** environment variable). Presently, connectivity to the following APIs is supported:\n- [AppDynamics](https://docs.appdynamics.com/display/PRO43/Metric+and+Snapshot+API)\n- [ExtraHop](https://docs.extrahop.com/7.9/rest-extract-metrics)\n- [GitHub](https://developer.github.com/v3/)*\n- [Prometheus Pushgateway](https://github.com/prometheus/pushgateway)**\n\n*GitHub connectivity is provided only as a means to access metric exporter job definitions in a source repository *(see [Defining Jobs in a GitHub Repository](#defining-jobs-in-a-github-repository) section below)*. It cannot be used as a `service` parameter in individual exporter job definitions.\n\n**Pushgateway connectivity is provided to allow exporter job metrics to be forwarded to a Prometheus Pushgateway server *(see [Exposing Metrics to a Pushgateway](#exposing-metrics-to-a-pushgateway) section below)*. It cannot be used as a `service` parameter in individual exporter job definitions.\n\nThe parameters to be included for each API connection type are shown below.\n\nAppDynamics API connections:\n- `hostname`: AppD controller server name or IP address\n- `port`: Port number (optional)\n- `username`: User name\n- `password`: Password\n- `encrypted`: \"true\" (recommended) if `password` value is encrypted or \"false\" if it is not\n- `vendor`: \"appdynamics\"\n\nExtraHop API connections:\n- `hostname`: ExtraHop server name or IP address\n- `port`: Port number (optional)\n- `apikey`: ExtraHop API key\n- `encrypted`: \"true\" (recommended) if `apikey` value is encrypted or \"false\" if it is not\n- `vendor`: \"extrahop\"\n\nGitHub API connections:\n- `hostname`: GitHub server name or IP address\n- `port`: Port number (optional)\n- `apikey`: GitHub API key\n- `encrypted`: \"true\" (recommended) if `apikey` value is encrypted or \"false\" if it is not\n- `vendor`: \"github\"\n\nPushgateway API connections:\n- `hostname`: Pushgateway server name or IP address (include \"https://\" for secure server connections)\n- `port`: Port number (optional)\n- `username`: User name (optional, for connections requiring Basic auth)\n- `password`: Password (optional, for connections requiring Basic auth)\n- `encrypted`: \"true\" (recommended) if `password` value is encrypted or \"false\" if it is not (optional, for connections requiring Basic auth)\n- `vendor`: \"pushgateway\"\n\n### Encrypting Credentials\n\nFor security purposes, it is recommended that database passwords and API keys be encrypted, especially when stored in CF. This application supports the decryption of credentials encrypted via the [cryptofy](https://github.com/homedepot/cryptofy) package.\n\nTo configure the application to decrypt a password or API key for a given connection at runtime, set the `encrypted` property to \"true\", as shown in the following example:\n\n```yaml\nMETREX_DB_MYSQL_EXAMPLE:\n  name: database_name\n  hostname: mysql.mydomain.com\n  port: 3306\n  username: user\n  password: Zq4B/mjYV9a4sVBzWiCxz5+tjcXHK2yc4UDVhWJLP2g=\n  encrypted: true\n  dialect: mysql\n  driver: pymysql\nMETREX_API_EXTRAHOP:\n  hostname: extrahop.mydomain.com\n  apikey: V37REDWZithWkr9Qu2d/p6uurhpj6kShcYjX0Y6yBWI=\n  encrypted: true\n  vendor: extrahop\n```\n\nA \"secret\" must be supplied to the application in order to unlock encrypted credentials at runtime. This secret must be the same one that was used to encrypt each of the passwords/API keys *(refer to the cryptofy documentation for instructions on generating secrets and encrypting credentials)*.\n\nSecrets may be supplied either by means of the **SECRET_KEY** environment variable or via a YAML-formatted file, the location of which is referenced in the ENV variable **SECRET_PATH**.*\n\n**Method 1**: Environment variable\n\n```dotenv\nSECRET_KEY=my_secret\n```\n\n**Method 2**: Secrets file (with file path environment variable)\n\nENV variable:\n\n```dotenv\nSECRET_PATH=secrets.yml\n```\n\nContents of `secrets.yml`:\n\n```yaml\nsecret-key: my_secret\n```\n\n*WARNING: Due to their sensitive nature, care should be taken to protect secret keys from being exposed. If defined via an ENV variable, make sure it is not visible to others; else if it is supplied as a secrets file, do NOT store the file in source code!\n\n## Configuration: Jobs\n\nMetric exporter jobs can be defined via:\n- [Service definitions](#defining-jobs-as-services) (user-provided services in CF or the services file)\n- [GitHub repository](#defining-jobs-in-a-github-repository)\n\n### Defining Jobs as Services\n\nIf running in Cloud Foundry, metric exporter jobs can be defined as user-provided services. All user-provided services containing exporter job definitions must begin with the prefix `METREX_JOB_` (or the value of the **JOB_PREFIX** environment variable).\n\nIn non-CF environments, jobs can be added to the same YAML-formatted configuration file containing the connection services, as shown below:\n\n```yaml\nMETREX_JOB_QUERY_EXAMPLE:\n  services:\n    - METREX_DB_MYSQL_EXAMPLE\n  interval_minutes: 5\n  statement: SELECT col1, col2, col3 FROM my_table\n  value_columns: col1, col2\n  static_labels: name:value\nMETREX_JOB_APPD_EXAMPLE:\n  services:\n    - METREX_API_APPD\n  interval_minutes: 15\n  application: Application_Name\n  metric_path: Business Transaction Performance|Business Transactions|*|*|*\nMETREX_JOB_EXTRAHOP_EXAMPLE:\n  services:\n    - METREX_API_EXTRAHOP\n  interval_minutes: 60\n  metric_params:\n    cycle: auto\n    object_type: device\n    object_ids:\n      - 9363\n    metric_category: http_client\n    metric_specs:\n      - req\n  aggregation:\n    funcs:\n      - count\n      - sum\n      - 95\n    threshold:\n      operator: \">\"\n      value: 10\n  static_labels: name:value\n```\n\n### Defining Jobs in a GitHub Repository\n\nMetric exporter jobs can also be defined via a YAML-formatted config file hosted in GitHub like the one shown below:\n\n```yaml\n---\nQUERY_EXAMPLE:\n  services:\n    - METREX_DB_MYSQL_EXAMPLE\n  interval_minutes: 5\n  statement: SELECT col1, col2, col3 FROM my_table\n  value_columns: col1, col2\n  static_labels: name:value\nAPPD_EXAMPLE:\n  services:\n    - METREX_API_APPD\n  interval_minutes: 15\n  application: Application_Name\n  metric_path: Business Transaction Performance|Business Transactions|*|*|*\nEXTRAHOP_EXAMPLE:\n  services:\n    - METREX_API_EXTRAHOP\n  interval_minutes: 60\n  metric_params:\n    cycle: auto\n    object_type: device\n    object_ids:\n      - 9363\n    metric_category: http_client\n    metric_specs:\n      - req\n  aggregation:\n    funcs:\n      - count\n      - sum\n      - 95\n    threshold:\n      operator: \">\"\n      value: 10\n  static_labels: name:value\n```\n\nThere is no prefix requirement for GitHub-hosted job names. However, the name referenced in the job's `service` parameter must match the full service name (prefix included) defined in CF.\n\nIn order for jobs defined in a GitHub repository to be consumed, the following environment variables must be provided:\n\n```dotenv\nJOBS_SOURCE_SERVICE=METREX_API_GITHUB\nJOBS_SOURCE_ORG=org_name\nJOBS_SOURCE_REPO=repo_name\nJOBS_SOURCE_PATH=path/to/jobs.yml\nJOBS_SOURCE_REFRESH_INTERVAL=30\n```\n\nChanges to the jobs config file referenced by these env variables will be picked up every *x* minutes, per the value assigned to **JOBS_SOURCE_REFRESH_INTERVAL**, and incorporated into the job scheduler. Unlike changes to services, no restart of the application is required for GitHub-hosted job file changes to take effect.\n\n### Job Parameters\n\nThe parameters to be included for each metric exporter job type are shown below.\n\nDatabase queries:\n- `services`: A list of one or more service names containing the database connection details, from which job metrics will be exported\n- `interval_minutes`: The interval (in minutes) to wait between each execution of the job\n- `statement`: SELECT query\n- `value_columns`: A comma-delimited list of one or more column names representing numeric metric values (any columns returned via the query which do not match the names in this list will be used as metric \"labels\")\n- `static_labels`: (optional) A comma-delimited list of `label:value` pairs to apply as static labels for all metrics\n- `timestamp_column`: (optional) The name of a column returned by the SQL query to use as the metric timestamp (ignored when metrics are exposed via Pushgateway)\n\nAppDynamics metrics:\n- `services`: A list of one or more service names containing the API connection details, from which job metrics will be exported*\n- `interval_minutes`: The interval (in minutes) to wait between each execution of the job\n- `application`: The Application name as it appears in AppD (for Database metrics, value is always \"Database Monitoring\")\n- `metric_path`: The AppD metrics path. May include wildcards (`*`).\n- `static_labels`: (optional) A comma-delimited list of `label:value` pairs to apply as static labels for all metrics\n\nExtraHop metrics:\n- `services`: A list of one or more service names containing the API connection details, from which job metrics will be exported*\n- `interval_minutes`: The interval (in minutes) to wait between each execution of the job\n- `metric_params`: The list of parameters passed to the ExtraHop `/metrics` API endpoint\n- `metric_name`: The identifier to be used in the Prometheus metric collector name.\n- `aggregation`: The list of parameters used to aggregate the values returned from the ExtraHop API *(see [About Aggregation](#about-aggregation) below)*\n- `static_labels`: (optional) A comma-delimited list of `label:value` pairs to apply as static labels for all metrics\n\n*NOTE: All names listed in the `services` parameter for a given API job must reference the same vendor.\n\n### About Aggregation\n\nCertain job types *(see \"ExtraHop metrics\" above)* provide the ability to define aggregation functions to produce metrics from the result data returned by the API.\n\nThe `aggregation` parameter group consists of two subgroups: `funcs` and `threshold` *(see example in [Defining Jobs as Services](#defining-jobs-as-services) above)*\n\nThe `funcs` subgroup accepts any combination of the following aggregation functions:\n- `avg`\n- `count` (default)\n- `min`\n- `max`\n- `sum`\n\nIt can also take integer values between 0 and 100, representing the nth percentile.\n\nThe optional `threshold` subgroup works much in the same way as a `HAVING` clause in a SQL `GROUP BY`: it filters by values matching defined criteria.*  Here, the criteria are expressed via the `operator` and `value` params.\n\nSupported `operator` values are:\n- `>`\n- `<`\n- `>=`\n- `<=`\n- `=`\n- `<>`\n- `!=`\n\nThe `value` param must be an integer.\n\nExample: Match all values greater than 10\n\n```yaml\nJOB_EXAMPLE:\n  aggregation:\n    threshold:\n      operator: \">\"\n      value: 10\n```\n\n*NOTE: If no `threshold` is specified, the aggregation function will include all returned values.\n\n## Exposing Metrics to a Pushgateway\n\nEach metric exporter job exposes its own registry endpoint by default at `/metrics/<job_id>`, which can be scraped by a Prometheus process.\n\nExporter job metrics can optionally be exposed to one or more [Prometheus Pushgateway](https://github.com/prometheus/pushgateway) services, which may simplify the process of managing jobs in Prometheus. If a Pushgateway service is defined, all new exporter jobs will automatically be exposed to it, and the metrics will in turn be available in Prometheus by means of scraping the Pushgateway.\n\nIn order to activate this feature, one or more Pushgateway services must be registered *(see example below)* and referenced (comma-delimited, if more than one) by the **PUSHGATEWAY_SERVICES** env variable.\n\nPushgateway service definition:\n\n```yaml\nMETREX_API_PUSHGATEWAY:\n  hostname: https://pushgateway.mydomain.com\n  vendor: pushgateway\n```\n\nENV variable:\n\n```dotenv\nPUSHGATEWAY_SERVICES=METREX_API_PUSHGATEWAY\n```\n\n## Running the Application\n\nExecute the following command:\n\n```shell\n$ python manage.py run\n```\n\nAlternately, the application can be started with the shortcut:\n\n```shell\n$ metrex\n```\n\n## Running in Docker\n\nThis application can be run inside a [Docker](https://www.docker.com/) container. A prepackaged image is available on [Docker Hub](https://hub.docker.com/r/homedepottech/metrex).\n\nIt was built with support for the following databases:\n- [Google BigQuery](https://cloud.google.com/bigquery)\n- [MySQL](https://www.mysql.com/)\n- [PostgreSQL](https://www.postgresql.org/)\n\nSample `docker-compose.yml` file:\n\n```yaml\nversion: \"3.7\"\n\nservices:\n  metrex:\n    image: homedepottech/metrex:latest\n    ports:\n      - 5000:5000\n    environment:\n      SECRET_PATH: /secrets.yml\n      SERVICES_PATH: /services.yml\n      GOOGLE_APPLICATION_CREDENTIALS: /gcp_credentials.json\n    volumes:\n      - /path/to/services.yml:/services.yml\n      - /path/to/secrets.yml:/secrets.yml\n      - /path/to/gcp_credentials.json:/gcp_credentials.json\n```\n\nCreate and start the Docker container:\n\n```shell\n$ docker-compose up -d metrex\n```\n\n## Swagger\n\nOpen the URL shown in the resulting output following application startup (default: http://127.0.0.1:5000) to access the Swagger UI.\n\n## Testing\n\nExecute the following command from the top-level directory of the cloned repository:\n\n```shell\n$ python setup.py test\n```\n\n## License\n\nDistributed under the [Apache, version 2.0 license](https://opensource.org/licenses/Apache-2.0).", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/homedepot/metREx", "keywords": "prometheus exporter prometheus-exporter metrics metrics-exporter query-exporter sql sql-exporter appd appd-exporter appdynamics appdynamics-exporter extrahop extrahop-exporter", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "metREx", "package_url": "https://pypi.org/project/metREx/", "platform": "", "project_url": "https://pypi.org/project/metREx/", "project_urls": {"Homepage": "https://github.com/homedepot/metREx"}, "release_url": "https://pypi.org/project/metREx/0.2.0.post3/", "requires_dist": null, "requires_python": ">=3.6", "summary": "SQL query and monitoring system metrics exporter for Prometheus", "version": "0.2.0.post3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>metREx</h1>\n<p>SQL query and monitoring system metrics exporter for <a href=\"https://prometheus.io/\" rel=\"nofollow\">Prometheus</a>. A product of <strong>Reliability Engineering</strong> at <a href=\"https://www.homedepot.com/\" rel=\"nofollow\">The Home Depot</a>.</p>\n<p>Supported database engines include:</p>\n<ul>\n<li><a href=\"https://www.ibm.com/products/db2-database\" rel=\"nofollow\">DB2</a> / <a href=\"https://www.ibm.com/products/informix\" rel=\"nofollow\">Informix</a></li>\n<li><a href=\"https://cloud.google.com/bigquery\" rel=\"nofollow\">Google BigQuery</a></li>\n<li><a href=\"https://www.microsoft.com/en-us/sql-server/default.aspx\" rel=\"nofollow\">Microsoft SQL Server</a></li>\n<li><a href=\"https://www.mysql.com/\" rel=\"nofollow\">MySQL</a></li>\n<li><a href=\"https://www.oracle.com/database\" rel=\"nofollow\">Oracle</a></li>\n<li><a href=\"https://www.postgresql.org/\" rel=\"nofollow\">PostgreSQL</a></li>\n</ul>\n<p>Prometheus metrics can be generated from the following monitoring systems:</p>\n<ul>\n<li><a href=\"https://www.appdynamics.com/\" rel=\"nofollow\">AppDynamics</a></li>\n<li><a href=\"https://www.extrahop.com/\" rel=\"nofollow\">ExtraHop</a></li>\n</ul>\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a>\n<ul>\n<li><a href=\"#database-engines\" rel=\"nofollow\">Database Engines</a></li>\n</ul>\n</li>\n<li><a href=\"#local-environment-setup\" rel=\"nofollow\">Local Environment Setup</a>\n<ul>\n<li><a href=\"#env-variables\" rel=\"nofollow\">ENV Variables</a></li>\n</ul>\n</li>\n<li><a href=\"#configuration-services\" rel=\"nofollow\">Configuration: Services</a>\n<ul>\n<li><a href=\"#database-connection-parameters\" rel=\"nofollow\">Database Connection Parameters</a></li>\n<li><a href=\"#api-connection-parameters\" rel=\"nofollow\">API Connection Parameters</a></li>\n<li><a href=\"#encrypting-credentials\" rel=\"nofollow\">Encrypting Credentials</a></li>\n</ul>\n</li>\n<li><a href=\"#configuration-jobs\" rel=\"nofollow\">Configuration: Jobs</a>\n<ul>\n<li><a href=\"#defining-jobs-as-services\" rel=\"nofollow\">Defining Jobs as Services</a></li>\n<li><a href=\"#defining-jobs-in-a-github-repository\" rel=\"nofollow\">Defining Jobs in a GitHub Repository</a></li>\n<li><a href=\"#job-parameters\" rel=\"nofollow\">Job Parameters</a></li>\n<li><a href=\"#about-aggregation\" rel=\"nofollow\">About Aggregation</a></li>\n</ul>\n</li>\n<li><a href=\"#exposing-metrics-to-a-pushgateway\" rel=\"nofollow\">Exposing Metrics to a Pushgateway</a></li>\n<li><a href=\"#running-the-application\" rel=\"nofollow\">Running the Application</a></li>\n<li><a href=\"#running-in-docker\" rel=\"nofollow\">Running in Docker</a></li>\n<li><a href=\"#swagger\" rel=\"nofollow\">Swagger</a></li>\n<li><a href=\"#testing\" rel=\"nofollow\">Testing</a></li>\n<li><a href=\"#license\" rel=\"nofollow\">License</a></li>\n</ul>\n<h2>Installation</h2>\n<pre>$ pip install metREx\n</pre>\n<h3>Database Engines</h3>\n<p>The <a href=\"https://www.sqlalchemy.org/\" rel=\"nofollow\">SQLAlchemy</a> package used by this application enables connectivity to a variety of database engines. However, additional packages may need to be installed, depending on which engines are used.</p>\n<p>A variation on the above <code>pip install</code> command can be used to include specific SQLAlchemy driver packages as needed.*</p>\n<p>In the following example, the dialect identifiers <code>mysql</code> and <code>postgres</code>, supplied in brackets, will install the <code>pymysql</code> and <code>pg8000</code> driver packages for MySQL and PostgreSQL database connectivity, respectively:</p>\n<pre>$ pip install metREx<span class=\"o\">[</span>mysql,postgresql<span class=\"o\">]</span>\n</pre>\n<p>For convenience, a selection of predefined dialects are available for commonly used SQLAlchemy driver packages:*</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Dialect</th>\n<th align=\"left\">Driver</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><code>bigquery</code></td>\n<td align=\"left\"><code>pybigquery</code></td>\n</tr>\n<tr>\n<td align=\"left\"><code>db2</code></td>\n<td align=\"left\"><code>ibm_db_sa</code></td>\n</tr>\n<tr>\n<td align=\"left\"><code>mssql</code></td>\n<td align=\"left\"><code>pymssql</code></td>\n</tr>\n<tr>\n<td align=\"left\"><code>mysql</code></td>\n<td align=\"left\"><code>pymysql</code></td>\n</tr>\n<tr>\n<td align=\"left\"><code>oracle</code></td>\n<td align=\"left\"><code>cx_oracle</code></td>\n</tr>\n<tr>\n<td align=\"left\"><code>postgresql</code></td>\n<td align=\"left\"><code>pg8000</code></td>\n</tr></tbody></table>\n<p>To install any combination of these SQLAlchemy drivers, substitute their dialect identifiers, delimited by commas, within the brackets shown in the previous example <em>(see <a href=\"http://docs.sqlalchemy.org/en/latest/core/engines.html#supported-databases\" rel=\"nofollow\">Supported Drivers</a> for details about other SQLAlchemy drivers not mapped to the predefined dialects above)</em>.</p>\n<p>*NOTE: Additional client software may also be required for certain database engines. Installation steps will vary depending on the host operating system.</p>\n<h2>Local Environment Setup</h2>\n<p>A <code>.env</code> file can optionally be used to define environment variables available to the application at runtime. This can be useful when running in a local development environment.</p>\n<p>The <code>.env</code> file should be placed in the installed package root. Any of the <code>.env.*</code> files included in the <code>examples</code> folder can be renamed to <code>.env</code>, as shown below:</p>\n<pre>$ cp examples/.env.macos-oracle metREx/.env\n</pre>\n<h3>ENV Variables</h3>\n<p>The following ENV variables can be used to configure various application behaviors:</p>\n<ul>\n<li><strong>BOILERPLATE_ENV</strong>: (Default: <code>dev</code>) The configuration profile applied to running app instances. Possible values: <code>dev</code>, <code>test</code>, or <code>prod</code>.</li>\n<li><strong>DEBUG</strong>: (Default: <code>true</code> if <strong>BOILERPLATE_ENV</strong> is <code>dev</code>, or false otherwise) Whether debug mode is enabled.</li>\n<li><strong>IP_ADDRESS</strong>: (Default: <code>127.0.0.1</code>) The internal IP address of the running app instance.</li>\n<li><strong>PORT</strong>: (Default: <code>5000</code>) The port on which the application listens for requests.</li>\n<li><strong>LD_LIBRARY_PATH</strong>: (Linux) A colon-separated list of the directories containing required database client libraries. Required for some SQLAlchemy drivers.</li>\n<li><strong>DYLD_LIBRARY_PATH</strong>: (macOS) A colon-separated list of the directories containing required database client libraries. Required for some SQLAlchemy drivers.</li>\n<li><strong>GOOGLE_APPLICATION_CREDENTIALS</strong>: The full path to the Google service account credentials JSON file to use as the default for BigQuery connections.</li>\n<li><strong>SECRET_KEY</strong>: The secret used to unlock encrypted credentials. May optionally be substituted with the path to a secret key file <em>(see <strong>SECRET_PATH</strong> below)</em>.</li>\n<li><strong>SECRET_PATH</strong>: (Default: <code>secrets.yml</code>) The location of the secret key file used to unlock encrypted service credentials. Can be used when the secret is not explicitly defined via an environment variable <em>(see <strong>SECRET_KEY</strong> above)</em>.</li>\n<li><strong>SERVICES_PATH</strong>: (Non-CF environments; default: <code>env/services.yml</code>) The location of a file containing the list of service connections (and optionally, metric exporter job definitions) available to the application at runtime.</li>\n<li><strong>API_PREFIX</strong>: (Default: <code>METREX_API_</code>) The prefix required for services containing API connection details.</li>\n<li><strong>DB_PREFIX</strong>: (Default: <code>METREX_DB_</code>) The prefix required for services containing database connection details.</li>\n<li><strong>JOB_PREFIX</strong>: (Default: <code>METREX_JOB_</code>) The prefix required for services containing metric exporter job details (not applicable to jobs defined in a GitHub repository).</li>\n<li><strong>ERROR_INCLUDE_MESSAGE</strong>: (Default: <code>true</code>) Whether to include detailed error messages in API responses. A generic \"Internal Server Error\" message will be returned on failure when <code>false</code>.</li>\n<li><strong>SUSPEND_JOB_ON_FAILURE</strong>: (Default: <code>false</code>) Whether to suspend metric exporter jobs immediately on failure. Suspended jobs may be resumed manually via the Scheduler API or by restarting the application.</li>\n<li><strong>APIALCHEMY_APPD_SSL_VERIFY</strong>: (Default: <code>true</code>) Whether to perform certificate verification for AppDynamics API connections.</li>\n<li><strong>APIALCHEMY_EXTRAHOP_SSL_VERIFY</strong>: (Default: <code>true</code>) Whether to perform certificate verification for ExtraHop API connections.</li>\n<li><strong>APIALCHEMY_GITHUB_SSL_VERIFY</strong>: (Default: <code>true</code>) Whether to perform certificate verification for GitHub API connections.</li>\n<li><strong>APIALCHEMY_PUSHGATEWAY_SSL_VERIFY</strong>: (Default: <code>true</code>) Whether to perform certificate verification for Pushgateway API connections.</li>\n<li><strong>DB_DEFAULT_LOCAL_TZ</strong>: (Default: <code>UTC</code>) The localized timezone applied by default to \"naive\" (non-TZ-aware) <code>timestamp_column</code> values* if defined in database-sourced metric exporter jobs (consult the <a href=\"https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\" rel=\"nofollow\">Time Zone Database</a> for a complete list of supported TZ names).</li>\n<li><strong>JOBS_SOURCE_SERVICE</strong>: The name of the service containing GitHub API connection details.</li>\n<li><strong>JOBS_SOURCE_ORG</strong>: The name of the GitHub org in which job definitions are hosted.</li>\n<li><strong>JOBS_SOURCE_REPO</strong>: The name of the GitHub repository in which job definitions are hosted.</li>\n<li><strong>JOBS_SOURCE_BRANCH</strong>: (Default: <code>master</code>) The branch name of the GitHub-hosted job definitions.</li>\n<li><strong>JOBS_SOURCE_PATH</strong>: The relative file path to GitHub-hosted job definitions.</li>\n<li><strong>JOBS_SOURCE_REFRESH_INTERVAL</strong>: (Default: <code>60</code>) An integer value representing the polling interval, expressed in minutes, for checking a GitHub-hosted job repository for changes to job definitions.</li>\n<li><strong>PUSHGATEWAY_SERVICES</strong>: The name(s) of the service(s) containing Pushgateway API connection details (comma-delimited, if more than one).</li>\n<li><strong>MISFIRE_GRACE_TIME</strong>: (Default: <code>5</code>) The seconds after the designated runtime that a metric exporter job is still allowed to be run.</li>\n<li><strong>THREADPOOL_MAX_WORKERS</strong>: (Default: <code>20</code>) The maximum number of spawned threads for the default metric exporter job executor.</li>\n<li><strong>PROCESSPOOL_MAX_WORKERS</strong>: (Default: <code>10</code>) The maximum number of spawned processes for the default metric exporter job executor.</li>\n</ul>\n<p>*Does not apply to <code>timestamp_column</code> values that contain timezone information; can be overridden on a per-service basis with the <code>timezone</code> option.</p>\n<h2>Configuration: Services</h2>\n<p>This application was originally designed to run on <a href=\"https://github.com/cloudfoundry\" rel=\"nofollow\">Cloud Foundry (CF)</a>. However, it can also be configured for other environments.</p>\n<p>When running in Cloud Foundry, the connection parameters used by metric exporter \"jobs\" are defined via <a href=\"https://docs.cloudfoundry.org/devguide/services/user-provided.html\" rel=\"nofollow\">user-provided service instances</a>.</p>\n<p>In non-CF environments, services can be defined via a YAML configuration file (default: <code>env/services.yml</code>), as shown in the following example:</p>\n<pre><span class=\"nn\">---</span>\n<span class=\"nt\">METREX_DB_MYSQL_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">name</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">database_name</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">mysql.mydomain.com</span>\n  <span class=\"nt\">port</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">3306</span>\n  <span class=\"nt\">username</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">user</span>\n  <span class=\"nt\">password</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">password</span>\n  <span class=\"nt\">encrypted</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">false</span>\n  <span class=\"nt\">dialect</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">mysql</span>\n  <span class=\"nt\">driver</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">pymysql</span>\n<span class=\"nt\">METREX_DB_BIGQUERY_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">project</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">gcp-project-name</span>\n  <span class=\"nt\">location</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">US</span>\n  <span class=\"nt\">credentials_path</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">/path/to/service/account/credentials.json</span>\n  <span class=\"nt\">dialect</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">bigquery</span>\n  <span class=\"nt\">driver</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">pybigquery</span>\n<span class=\"nt\">METREX_API_APPD</span><span class=\"p\">:</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">appdynamics.mydomain.com</span>\n  <span class=\"nt\">username</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">user</span>\n  <span class=\"nt\">password</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">password</span>\n  <span class=\"nt\">encrypted</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">false</span>\n  <span class=\"nt\">vendor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">appdynamics</span>\n<span class=\"nt\">METREX_API_EXTRAHOP</span><span class=\"p\">:</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">extrahop.mydomain.com</span>\n  <span class=\"nt\">apikey</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">extrahop_apikey</span>\n  <span class=\"nt\">encrypted</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">false</span>\n  <span class=\"nt\">vendor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">extrahop</span>\n<span class=\"nt\">METREX_API_GITHUB</span><span class=\"p\">:</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">github.com</span>\n  <span class=\"nt\">apikey</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">github_apikey</span>\n  <span class=\"nt\">encrypted</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">false</span>\n  <span class=\"nt\">vendor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">github</span>\n</pre>\n<h3>Database Connection Parameters</h3>\n<p>The names assigned to services containing database connection details must begin with the prefix <code>METREX_DB_</code> (or the value of the <strong>DB_PREFIX</strong> environment variable). The text that appears after this prefix will be prepended to the names of all Prometheus metrics generated from this service.</p>\n<p>For database connections (except BigQuery), the following parameters must be included:</p>\n<ul>\n<li><code>name</code>: Database or service name</li>\n<li><code>hostname</code>: Server name or IP address</li>\n<li><code>port</code>: Port number</li>\n<li><code>username</code>: User name</li>\n<li><code>password</code>: Password</li>\n<li><code>encrypted</code>: \"true\" (recommended) if <code>password</code> value is encrypted or \"false\" if it is not.</li>\n<li><code>dialect</code>: Dialect identifier <em>(refer to table of Dialect/Driver mappings in <a href=\"#database-engines\" rel=\"nofollow\">Database Engines</a> section above)</em></li>\n<li><code>driver</code>: SQLAlchemy driver <em>(refer to table of Dialect/Driver mappings in <a href=\"#database-engines\" rel=\"nofollow\">Database Engines</a> section above)</em></li>\n<li><code>timezone</code>: Localized <a href=\"https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\" rel=\"nofollow\">database timezone</a> to apply to \"naive\" (non-TZ-aware) <code>timestamp_column</code> values returned by metric exporter jobs (optional, to override the <strong>DB_DEFAULT_LOCAL_TZ</strong> env variable)</li>\n</ul>\n<p>For BigQuery connections, the following parameters are used:</p>\n<ul>\n<li><code>project</code>: Name of the GCP project (defaults to the project specified in the credentials JSON file)</li>\n<li><code>location</code>: Specifies the dataset location (optional)</li>\n<li><code>credentials_path</code>: Full path to the service account credentials JSON file (optional)*</li>\n<li><code>credentials_info</code>: Contents of the service account credentials JSON file (optional)*</li>\n<li><code>encrypted</code>: \"true\" (recommended) if the <code>credentials_info</code> value is encrypted or \"false\" if it is not (optional, for use only with <code>credentials_info</code>)</li>\n<li><code>dialect</code>: \"bigquery\"</li>\n<li><code>driver</code>: \"pybigquery\"</li>\n</ul>\n<p>*NOTE: Either <code>credentials_path</code> or <code>credentials_info</code> can be used instead of or to override the <strong>GOOGLE_APPLICATION_CREDENTIALS</strong> ENV variable on a per-service basis. <code>credentials_path</code> takes precedence if provided in combination with <strong>GOOGLE_APPLICATION_CREDENTIALS</strong> or <code>credentials_info</code>.</p>\n<h3>API Connection Parameters</h3>\n<p>The names assigned to services containing API connection details must begin with the prefix <code>METREX_API_</code> (or the value of the <strong>API_PREFIX</strong> environment variable). Presently, connectivity to the following APIs is supported:</p>\n<ul>\n<li><a href=\"https://docs.appdynamics.com/display/PRO43/Metric+and+Snapshot+API\" rel=\"nofollow\">AppDynamics</a></li>\n<li><a href=\"https://docs.extrahop.com/7.9/rest-extract-metrics\" rel=\"nofollow\">ExtraHop</a></li>\n<li><a href=\"https://developer.github.com/v3/\" rel=\"nofollow\">GitHub</a>*</li>\n<li><a href=\"https://github.com/prometheus/pushgateway\" rel=\"nofollow\">Prometheus Pushgateway</a>**</li>\n</ul>\n<p>*GitHub connectivity is provided only as a means to access metric exporter job definitions in a source repository <em>(see <a href=\"#defining-jobs-in-a-github-repository\" rel=\"nofollow\">Defining Jobs in a GitHub Repository</a> section below)</em>. It cannot be used as a <code>service</code> parameter in individual exporter job definitions.</p>\n<p>**Pushgateway connectivity is provided to allow exporter job metrics to be forwarded to a Prometheus Pushgateway server <em>(see <a href=\"#exposing-metrics-to-a-pushgateway\" rel=\"nofollow\">Exposing Metrics to a Pushgateway</a> section below)</em>. It cannot be used as a <code>service</code> parameter in individual exporter job definitions.</p>\n<p>The parameters to be included for each API connection type are shown below.</p>\n<p>AppDynamics API connections:</p>\n<ul>\n<li><code>hostname</code>: AppD controller server name or IP address</li>\n<li><code>port</code>: Port number (optional)</li>\n<li><code>username</code>: User name</li>\n<li><code>password</code>: Password</li>\n<li><code>encrypted</code>: \"true\" (recommended) if <code>password</code> value is encrypted or \"false\" if it is not</li>\n<li><code>vendor</code>: \"appdynamics\"</li>\n</ul>\n<p>ExtraHop API connections:</p>\n<ul>\n<li><code>hostname</code>: ExtraHop server name or IP address</li>\n<li><code>port</code>: Port number (optional)</li>\n<li><code>apikey</code>: ExtraHop API key</li>\n<li><code>encrypted</code>: \"true\" (recommended) if <code>apikey</code> value is encrypted or \"false\" if it is not</li>\n<li><code>vendor</code>: \"extrahop\"</li>\n</ul>\n<p>GitHub API connections:</p>\n<ul>\n<li><code>hostname</code>: GitHub server name or IP address</li>\n<li><code>port</code>: Port number (optional)</li>\n<li><code>apikey</code>: GitHub API key</li>\n<li><code>encrypted</code>: \"true\" (recommended) if <code>apikey</code> value is encrypted or \"false\" if it is not</li>\n<li><code>vendor</code>: \"github\"</li>\n</ul>\n<p>Pushgateway API connections:</p>\n<ul>\n<li><code>hostname</code>: Pushgateway server name or IP address (include \"https://\" for secure server connections)</li>\n<li><code>port</code>: Port number (optional)</li>\n<li><code>username</code>: User name (optional, for connections requiring Basic auth)</li>\n<li><code>password</code>: Password (optional, for connections requiring Basic auth)</li>\n<li><code>encrypted</code>: \"true\" (recommended) if <code>password</code> value is encrypted or \"false\" if it is not (optional, for connections requiring Basic auth)</li>\n<li><code>vendor</code>: \"pushgateway\"</li>\n</ul>\n<h3>Encrypting Credentials</h3>\n<p>For security purposes, it is recommended that database passwords and API keys be encrypted, especially when stored in CF. This application supports the decryption of credentials encrypted via the <a href=\"https://github.com/homedepot/cryptofy\" rel=\"nofollow\">cryptofy</a> package.</p>\n<p>To configure the application to decrypt a password or API key for a given connection at runtime, set the <code>encrypted</code> property to \"true\", as shown in the following example:</p>\n<pre><span class=\"nt\">METREX_DB_MYSQL_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">name</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">database_name</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">mysql.mydomain.com</span>\n  <span class=\"nt\">port</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">3306</span>\n  <span class=\"nt\">username</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">user</span>\n  <span class=\"nt\">password</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Zq4B/mjYV9a4sVBzWiCxz5+tjcXHK2yc4UDVhWJLP2g=</span>\n  <span class=\"nt\">encrypted</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>\n  <span class=\"nt\">dialect</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">mysql</span>\n  <span class=\"nt\">driver</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">pymysql</span>\n<span class=\"nt\">METREX_API_EXTRAHOP</span><span class=\"p\">:</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">extrahop.mydomain.com</span>\n  <span class=\"nt\">apikey</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">V37REDWZithWkr9Qu2d/p6uurhpj6kShcYjX0Y6yBWI=</span>\n  <span class=\"nt\">encrypted</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>\n  <span class=\"nt\">vendor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">extrahop</span>\n</pre>\n<p>A \"secret\" must be supplied to the application in order to unlock encrypted credentials at runtime. This secret must be the same one that was used to encrypt each of the passwords/API keys <em>(refer to the cryptofy documentation for instructions on generating secrets and encrypting credentials)</em>.</p>\n<p>Secrets may be supplied either by means of the <strong>SECRET_KEY</strong> environment variable or via a YAML-formatted file, the location of which is referenced in the ENV variable <strong>SECRET_PATH</strong>.*</p>\n<p><strong>Method 1</strong>: Environment variable</p>\n<pre>SECRET_KEY=my_secret\n</pre>\n<p><strong>Method 2</strong>: Secrets file (with file path environment variable)</p>\n<p>ENV variable:</p>\n<pre>SECRET_PATH=secrets.yml\n</pre>\n<p>Contents of <code>secrets.yml</code>:</p>\n<pre><span class=\"nt\">secret-key</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">my_secret</span>\n</pre>\n<p>*WARNING: Due to their sensitive nature, care should be taken to protect secret keys from being exposed. If defined via an ENV variable, make sure it is not visible to others; else if it is supplied as a secrets file, do NOT store the file in source code!</p>\n<h2>Configuration: Jobs</h2>\n<p>Metric exporter jobs can be defined via:</p>\n<ul>\n<li><a href=\"#defining-jobs-as-services\" rel=\"nofollow\">Service definitions</a> (user-provided services in CF or the services file)</li>\n<li><a href=\"#defining-jobs-in-a-github-repository\" rel=\"nofollow\">GitHub repository</a></li>\n</ul>\n<h3>Defining Jobs as Services</h3>\n<p>If running in Cloud Foundry, metric exporter jobs can be defined as user-provided services. All user-provided services containing exporter job definitions must begin with the prefix <code>METREX_JOB_</code> (or the value of the <strong>JOB_PREFIX</strong> environment variable).</p>\n<p>In non-CF environments, jobs can be added to the same YAML-formatted configuration file containing the connection services, as shown below:</p>\n<pre><span class=\"nt\">METREX_JOB_QUERY_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">services</span><span class=\"p\">:</span>\n    <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">METREX_DB_MYSQL_EXAMPLE</span>\n  <span class=\"nt\">interval_minutes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">5</span>\n  <span class=\"nt\">statement</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">SELECT col1, col2, col3 FROM my_table</span>\n  <span class=\"nt\">value_columns</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">col1, col2</span>\n  <span class=\"nt\">static_labels</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">name:value</span>\n<span class=\"nt\">METREX_JOB_APPD_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">services</span><span class=\"p\">:</span>\n    <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">METREX_API_APPD</span>\n  <span class=\"nt\">interval_minutes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">15</span>\n  <span class=\"nt\">application</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Application_Name</span>\n  <span class=\"nt\">metric_path</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Business Transaction Performance|Business Transactions|*|*|*</span>\n<span class=\"nt\">METREX_JOB_EXTRAHOP_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">services</span><span class=\"p\">:</span>\n    <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">METREX_API_EXTRAHOP</span>\n  <span class=\"nt\">interval_minutes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">60</span>\n  <span class=\"nt\">metric_params</span><span class=\"p\">:</span>\n    <span class=\"nt\">cycle</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">auto</span>\n    <span class=\"nt\">object_type</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">device</span>\n    <span class=\"nt\">object_ids</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">9363</span>\n    <span class=\"nt\">metric_category</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">http_client</span>\n    <span class=\"nt\">metric_specs</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">req</span>\n  <span class=\"nt\">aggregation</span><span class=\"p\">:</span>\n    <span class=\"nt\">funcs</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">count</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">sum</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">95</span>\n    <span class=\"nt\">threshold</span><span class=\"p\">:</span>\n      <span class=\"nt\">operator</span><span class=\"p\">:</span> <span class=\"s\">\"&gt;\"</span>\n      <span class=\"nt\">value</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">10</span>\n  <span class=\"nt\">static_labels</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">name:value</span>\n</pre>\n<h3>Defining Jobs in a GitHub Repository</h3>\n<p>Metric exporter jobs can also be defined via a YAML-formatted config file hosted in GitHub like the one shown below:</p>\n<pre><span class=\"nn\">---</span>\n<span class=\"nt\">QUERY_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">services</span><span class=\"p\">:</span>\n    <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">METREX_DB_MYSQL_EXAMPLE</span>\n  <span class=\"nt\">interval_minutes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">5</span>\n  <span class=\"nt\">statement</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">SELECT col1, col2, col3 FROM my_table</span>\n  <span class=\"nt\">value_columns</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">col1, col2</span>\n  <span class=\"nt\">static_labels</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">name:value</span>\n<span class=\"nt\">APPD_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">services</span><span class=\"p\">:</span>\n    <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">METREX_API_APPD</span>\n  <span class=\"nt\">interval_minutes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">15</span>\n  <span class=\"nt\">application</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Application_Name</span>\n  <span class=\"nt\">metric_path</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Business Transaction Performance|Business Transactions|*|*|*</span>\n<span class=\"nt\">EXTRAHOP_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">services</span><span class=\"p\">:</span>\n    <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">METREX_API_EXTRAHOP</span>\n  <span class=\"nt\">interval_minutes</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">60</span>\n  <span class=\"nt\">metric_params</span><span class=\"p\">:</span>\n    <span class=\"nt\">cycle</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">auto</span>\n    <span class=\"nt\">object_type</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">device</span>\n    <span class=\"nt\">object_ids</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">9363</span>\n    <span class=\"nt\">metric_category</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">http_client</span>\n    <span class=\"nt\">metric_specs</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">req</span>\n  <span class=\"nt\">aggregation</span><span class=\"p\">:</span>\n    <span class=\"nt\">funcs</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">count</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">sum</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">95</span>\n    <span class=\"nt\">threshold</span><span class=\"p\">:</span>\n      <span class=\"nt\">operator</span><span class=\"p\">:</span> <span class=\"s\">\"&gt;\"</span>\n      <span class=\"nt\">value</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">10</span>\n  <span class=\"nt\">static_labels</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">name:value</span>\n</pre>\n<p>There is no prefix requirement for GitHub-hosted job names. However, the name referenced in the job's <code>service</code> parameter must match the full service name (prefix included) defined in CF.</p>\n<p>In order for jobs defined in a GitHub repository to be consumed, the following environment variables must be provided:</p>\n<pre>JOBS_SOURCE_SERVICE=METREX_API_GITHUB\nJOBS_SOURCE_ORG=org_name\nJOBS_SOURCE_REPO=repo_name\nJOBS_SOURCE_PATH=path/to/jobs.yml\nJOBS_SOURCE_REFRESH_INTERVAL=30\n</pre>\n<p>Changes to the jobs config file referenced by these env variables will be picked up every <em>x</em> minutes, per the value assigned to <strong>JOBS_SOURCE_REFRESH_INTERVAL</strong>, and incorporated into the job scheduler. Unlike changes to services, no restart of the application is required for GitHub-hosted job file changes to take effect.</p>\n<h3>Job Parameters</h3>\n<p>The parameters to be included for each metric exporter job type are shown below.</p>\n<p>Database queries:</p>\n<ul>\n<li><code>services</code>: A list of one or more service names containing the database connection details, from which job metrics will be exported</li>\n<li><code>interval_minutes</code>: The interval (in minutes) to wait between each execution of the job</li>\n<li><code>statement</code>: SELECT query</li>\n<li><code>value_columns</code>: A comma-delimited list of one or more column names representing numeric metric values (any columns returned via the query which do not match the names in this list will be used as metric \"labels\")</li>\n<li><code>static_labels</code>: (optional) A comma-delimited list of <code>label:value</code> pairs to apply as static labels for all metrics</li>\n<li><code>timestamp_column</code>: (optional) The name of a column returned by the SQL query to use as the metric timestamp (ignored when metrics are exposed via Pushgateway)</li>\n</ul>\n<p>AppDynamics metrics:</p>\n<ul>\n<li><code>services</code>: A list of one or more service names containing the API connection details, from which job metrics will be exported*</li>\n<li><code>interval_minutes</code>: The interval (in minutes) to wait between each execution of the job</li>\n<li><code>application</code>: The Application name as it appears in AppD (for Database metrics, value is always \"Database Monitoring\")</li>\n<li><code>metric_path</code>: The AppD metrics path. May include wildcards (<code>*</code>).</li>\n<li><code>static_labels</code>: (optional) A comma-delimited list of <code>label:value</code> pairs to apply as static labels for all metrics</li>\n</ul>\n<p>ExtraHop metrics:</p>\n<ul>\n<li><code>services</code>: A list of one or more service names containing the API connection details, from which job metrics will be exported*</li>\n<li><code>interval_minutes</code>: The interval (in minutes) to wait between each execution of the job</li>\n<li><code>metric_params</code>: The list of parameters passed to the ExtraHop <code>/metrics</code> API endpoint</li>\n<li><code>metric_name</code>: The identifier to be used in the Prometheus metric collector name.</li>\n<li><code>aggregation</code>: The list of parameters used to aggregate the values returned from the ExtraHop API <em>(see <a href=\"#about-aggregation\" rel=\"nofollow\">About Aggregation</a> below)</em></li>\n<li><code>static_labels</code>: (optional) A comma-delimited list of <code>label:value</code> pairs to apply as static labels for all metrics</li>\n</ul>\n<p>*NOTE: All names listed in the <code>services</code> parameter for a given API job must reference the same vendor.</p>\n<h3>About Aggregation</h3>\n<p>Certain job types <em>(see \"ExtraHop metrics\" above)</em> provide the ability to define aggregation functions to produce metrics from the result data returned by the API.</p>\n<p>The <code>aggregation</code> parameter group consists of two subgroups: <code>funcs</code> and <code>threshold</code> <em>(see example in <a href=\"#defining-jobs-as-services\" rel=\"nofollow\">Defining Jobs as Services</a> above)</em></p>\n<p>The <code>funcs</code> subgroup accepts any combination of the following aggregation functions:</p>\n<ul>\n<li><code>avg</code></li>\n<li><code>count</code> (default)</li>\n<li><code>min</code></li>\n<li><code>max</code></li>\n<li><code>sum</code></li>\n</ul>\n<p>It can also take integer values between 0 and 100, representing the nth percentile.</p>\n<p>The optional <code>threshold</code> subgroup works much in the same way as a <code>HAVING</code> clause in a SQL <code>GROUP BY</code>: it filters by values matching defined criteria.*  Here, the criteria are expressed via the <code>operator</code> and <code>value</code> params.</p>\n<p>Supported <code>operator</code> values are:</p>\n<ul>\n<li><code>&gt;</code></li>\n<li><code>&lt;</code></li>\n<li><code>&gt;=</code></li>\n<li><code>&lt;=</code></li>\n<li><code>=</code></li>\n<li><code>&lt;&gt;</code></li>\n<li><code>!=</code></li>\n</ul>\n<p>The <code>value</code> param must be an integer.</p>\n<p>Example: Match all values greater than 10</p>\n<pre><span class=\"nt\">JOB_EXAMPLE</span><span class=\"p\">:</span>\n  <span class=\"nt\">aggregation</span><span class=\"p\">:</span>\n    <span class=\"nt\">threshold</span><span class=\"p\">:</span>\n      <span class=\"nt\">operator</span><span class=\"p\">:</span> <span class=\"s\">\"&gt;\"</span>\n      <span class=\"nt\">value</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">10</span>\n</pre>\n<p>*NOTE: If no <code>threshold</code> is specified, the aggregation function will include all returned values.</p>\n<h2>Exposing Metrics to a Pushgateway</h2>\n<p>Each metric exporter job exposes its own registry endpoint by default at <code>/metrics/&lt;job_id&gt;</code>, which can be scraped by a Prometheus process.</p>\n<p>Exporter job metrics can optionally be exposed to one or more <a href=\"https://github.com/prometheus/pushgateway\" rel=\"nofollow\">Prometheus Pushgateway</a> services, which may simplify the process of managing jobs in Prometheus. If a Pushgateway service is defined, all new exporter jobs will automatically be exposed to it, and the metrics will in turn be available in Prometheus by means of scraping the Pushgateway.</p>\n<p>In order to activate this feature, one or more Pushgateway services must be registered <em>(see example below)</em> and referenced (comma-delimited, if more than one) by the <strong>PUSHGATEWAY_SERVICES</strong> env variable.</p>\n<p>Pushgateway service definition:</p>\n<pre><span class=\"nt\">METREX_API_PUSHGATEWAY</span><span class=\"p\">:</span>\n  <span class=\"nt\">hostname</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">https://pushgateway.mydomain.com</span>\n  <span class=\"nt\">vendor</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">pushgateway</span>\n</pre>\n<p>ENV variable:</p>\n<pre>PUSHGATEWAY_SERVICES=METREX_API_PUSHGATEWAY\n</pre>\n<h2>Running the Application</h2>\n<p>Execute the following command:</p>\n<pre>$ python manage.py run\n</pre>\n<p>Alternately, the application can be started with the shortcut:</p>\n<pre>$ metrex\n</pre>\n<h2>Running in Docker</h2>\n<p>This application can be run inside a <a href=\"https://www.docker.com/\" rel=\"nofollow\">Docker</a> container. A prepackaged image is available on <a href=\"https://hub.docker.com/r/homedepottech/metrex\" rel=\"nofollow\">Docker Hub</a>.</p>\n<p>It was built with support for the following databases:</p>\n<ul>\n<li><a href=\"https://cloud.google.com/bigquery\" rel=\"nofollow\">Google BigQuery</a></li>\n<li><a href=\"https://www.mysql.com/\" rel=\"nofollow\">MySQL</a></li>\n<li><a href=\"https://www.postgresql.org/\" rel=\"nofollow\">PostgreSQL</a></li>\n</ul>\n<p>Sample <code>docker-compose.yml</code> file:</p>\n<pre><span class=\"nt\">version</span><span class=\"p\">:</span> <span class=\"s\">\"3.7\"</span>\n\n<span class=\"nt\">services</span><span class=\"p\">:</span>\n  <span class=\"nt\">metrex</span><span class=\"p\">:</span>\n    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">homedepottech/metrex:latest</span>\n    <span class=\"nt\">ports</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">5000:5000</span>\n    <span class=\"nt\">environment</span><span class=\"p\">:</span>\n      <span class=\"nt\">SECRET_PATH</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">/secrets.yml</span>\n      <span class=\"nt\">SERVICES_PATH</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">/services.yml</span>\n      <span class=\"nt\">GOOGLE_APPLICATION_CREDENTIALS</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">/gcp_credentials.json</span>\n    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">/path/to/services.yml:/services.yml</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">/path/to/secrets.yml:/secrets.yml</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">/path/to/gcp_credentials.json:/gcp_credentials.json</span>\n</pre>\n<p>Create and start the Docker container:</p>\n<pre>$ docker-compose up -d metrex\n</pre>\n<h2>Swagger</h2>\n<p>Open the URL shown in the resulting output following application startup (default: <a href=\"http://127.0.0.1:5000\" rel=\"nofollow\">http://127.0.0.1:5000</a>) to access the Swagger UI.</p>\n<h2>Testing</h2>\n<p>Execute the following command from the top-level directory of the cloned repository:</p>\n<pre>$ python setup.py <span class=\"nb\">test</span>\n</pre>\n<h2>License</h2>\n<p>Distributed under the <a href=\"https://opensource.org/licenses/Apache-2.0\" rel=\"nofollow\">Apache, version 2.0 license</a>.</p>\n\n          </div>"}, "last_serial": 7166743, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "b1fbebcca2ec23f4820a427d396f855f", "sha256": "3645149f3b3ba601a29f7b4cb30fbc35177207579f118a8ee32f9d4677516c8d"}, "downloads": -1, "filename": "metREx-0.1.0.tar.gz", "has_sig": false, "md5_digest": "b1fbebcca2ec23f4820a427d396f855f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 31960, "upload_time": "2020-03-13T02:43:54", "upload_time_iso_8601": "2020-03-13T02:43:54.508061Z", "url": "https://files.pythonhosted.org/packages/dc/8e/4e41f75fc4c7fb32de92980fc14d2371128c30e8dce3f30fbb56c04968c3/metREx-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "759605c7962917e726a1edcaee1f0172", "sha256": "ccc6428d0db27fe024ecaed3f57fa54746d412cb1181e6f4ab980b934c6826a4"}, "downloads": -1, "filename": "metREx-0.2.0.tar.gz", "has_sig": false, "md5_digest": "759605c7962917e726a1edcaee1f0172", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33797, "upload_time": "2020-04-22T01:58:50", "upload_time_iso_8601": "2020-04-22T01:58:50.548437Z", "url": "https://files.pythonhosted.org/packages/01/cf/a06ad2227738d09aeaa449fbbc048941e66a5a998266457d972ffb0efbbd/metREx-0.2.0.tar.gz", "yanked": true}], "0.2.0.post1": [{"comment_text": "", "digests": {"md5": "3ee7d8fe9f73bc620f028a4d0045f21d", "sha256": "0ff00a4a6675571f98ae7b9aa453d64edc2e9eba37085145e86ce92fc909b07d"}, "downloads": -1, "filename": "metREx-0.2.0.post1.tar.gz", "has_sig": false, "md5_digest": "3ee7d8fe9f73bc620f028a4d0045f21d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33818, "upload_time": "2020-04-22T03:49:36", "upload_time_iso_8601": "2020-04-22T03:49:36.679919Z", "url": "https://files.pythonhosted.org/packages/9d/f6/36606f8aea88093ac931d7e91209b27e829368546e04936c2042d8d4b980/metREx-0.2.0.post1.tar.gz", "yanked": true}], "0.2.0.post2": [{"comment_text": "", "digests": {"md5": "6aed4925627a0630cc84a92af1d4668f", "sha256": "bb78c6a4d79f01dcf193342e6225fa32db800bbbe6c5b38da275089b6448c59d"}, "downloads": -1, "filename": "metREx-0.2.0.post2.tar.gz", "has_sig": false, "md5_digest": "6aed4925627a0630cc84a92af1d4668f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33811, "upload_time": "2020-04-22T04:01:24", "upload_time_iso_8601": "2020-04-22T04:01:24.552432Z", "url": "https://files.pythonhosted.org/packages/a3/71/d4b166832ca3b0b227a902766ea5744bd5efa6828c6018e4340aae9d31ff/metREx-0.2.0.post2.tar.gz", "yanked": true}], "0.2.0.post3": [{"comment_text": "", "digests": {"md5": "98ac7ed5bed82fae605c1ddfaac9c20e", "sha256": "2350df035b3a6473539fd4ae201b49295ff17e63b5ee6927214baa41b2cddbd5"}, "downloads": -1, "filename": "metREx-0.2.0.post3.tar.gz", "has_sig": false, "md5_digest": "98ac7ed5bed82fae605c1ddfaac9c20e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33812, "upload_time": "2020-04-22T18:00:08", "upload_time_iso_8601": "2020-04-22T18:00:08.021663Z", "url": "https://files.pythonhosted.org/packages/82/ad/a748fa7b1b5b7892d00bb9ca60849d7675ac3ed39dddbd8b3b3d46b5b9a0/metREx-0.2.0.post3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "98ac7ed5bed82fae605c1ddfaac9c20e", "sha256": "2350df035b3a6473539fd4ae201b49295ff17e63b5ee6927214baa41b2cddbd5"}, "downloads": -1, "filename": "metREx-0.2.0.post3.tar.gz", "has_sig": false, "md5_digest": "98ac7ed5bed82fae605c1ddfaac9c20e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33812, "upload_time": "2020-04-22T18:00:08", "upload_time_iso_8601": "2020-04-22T18:00:08.021663Z", "url": "https://files.pythonhosted.org/packages/82/ad/a748fa7b1b5b7892d00bb9ca60849d7675ac3ed39dddbd8b3b3d46b5b9a0/metREx-0.2.0.post3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:55:40 2020"}