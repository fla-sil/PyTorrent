{"info": {"author": "Piotr Zielinski", "author_email": "piotr_zielinski@g.pl", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# PyTransdec\n\n**PyTransdec** is a Python library prepared for controlling [**TransdecEnvironment**](https://github.com/PiotrJZielinski/TransdecEnvironment) by PWr Diving Crew (KN Robocik) at Wroc\u0139\u201aaw University of Science and Technology.\n\nIt wraps [Unity ML-Agents library](https://github.com/Unity-Technologies/ml-agents/tree/master/ml-agents).\n\nThe project is maintained by Pwr Diving Crew software team members (Unity3D section).\n\n[KN Robocik website](http://www.robocik.pwr.edu.pl/)\n\nShould any issues be noticed, please submit a **New issue** on GitHub.\n\n## Installation\n\n### Python\n\nTo use Python API **Python 3.6** is required. On Windows it is recommended to use Anaconda ([64-bit](https://repo.continuum.io/archive/Anaconda3-5.1.0-Windows-x86_64.exe) or [32-bit](https://repo.continuum.io/archive/Anaconda3-5.1.0-Windows-x86.exe), but you can use your own preferred Python installation.\n\nFor Anaconda use default installation settings. After installation open **Anaconda Navigator** to finish the setup.\n\n![image](https://user-images.githubusercontent.com/23311513/53694120-659c7d80-3daa-11e9-967d-adccde7ca095.png)\n\nIn case environment variables were not created, you will see error `conda is not recognized as internal or external command` when you type `conda` into command line. To solve this problem set the environment variables: open `Edit environment variables for your account`, click `Environment Variables` button, then double click `Path under` under `System variable`. Add the following paths using `New` button:\n\n```\n%UserProfile%\\Anaconda3\\Scripts\n%UserProfile%\\Anaconda3\\Scripts\\conda.exe\n%UserProfile%\\Anaconda3\n%UserProfile%\\Anaconda3\\python.exe\n```\n![image](https://user-images.githubusercontent.com/23311513/53694104-371ea280-3daa-11e9-8351-23eba97e3793.png)\n\nBefore proceeding check your installation by executing `python --version`, which should output something like this:\n\n```\nPython 3.6.x :: ...\n```\n\nYou also need **pip** (which is installed by default in Anaconda). Check if it is correctly installed by executing `pip --version`. The output should look like this:\n\n```\npip x.x...\n```\n\nIf any error occurred, please check your installation.\n\n### PyTransdec package\n\nTo use the package install it using pip (it is recommended to use a **virtual environment** such as [**Pipenv**](https://pipenv.readthedocs.io/en/latest/) (preferred), [**conda env**](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) or [**virtualenv**](https://virtualenv.pypa.io/en/latest/).\n\nInstallation command:\n\n```\npip install git+https://github.com/PiotrJZielinski/PyTransdec\n```\n\nPyTransdec package automatically installs all required dependencies.\n\n## Usage\n\nPyTransdec package contains `TransdecCommunication([file_name, worker_id])` class, which can be used to communicate with TransdecEnvironment. To import the package use following Python script:\n\n```python\nfrom pytransdec import TransdecCommunication\n```\n\nYou can then apply it using `with` statement:\n\n```python\nwith TransdecCommunication() as tc:\n  ...\n```\n\n#### Parameters:\n  * `file_name`: `str`, *optional* - Unity Environment file to operate on; defaults to `None` (connect to Unity Editor)\n  * `worker_id`: `int`, *optional* - for more than 1 parallel workers - port incremental to be used for connection; defaults to `0`\n\n\n### Methods\n|method/property|description|\n|---|---|\n|`tc.reset([message, training])`|Reset the environment with reset `message`; update observations|\n|`tc.step([action])`|Make a step in the environment (specified with `action`); update observations|\n|`tc.reward`|Current reward value|\n|`tc.vector`|Current vector observations dictionary|\n|`tc.visual`|Current visual observations list|\n|`tc.collect_data(positive, add_noise, add_background, n_images[, save_dir, start_num, annotation_margin, used_observations, object_number, show_img, draw_annotations, print_annotations, progress_bar])`|Automatically collect data from Transdec Environment|\n\n|**`tc.reset(self, message={}, training=True)`**|[*[source]*](https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L65)|\n|---|---|\n\nReset the environment with reset `message` and update observations.\n\n#### Parameters:\n  * `message`: `Dict[str, int]`, *optional* - a dictionary specifying TransdecEnvironment reset settings; defaults to empty `Dict`; available keys:\n    * `'CollectData'`: if `0` - navigation mode; if `1` - data collection mode\n    * `'EnableNoise'`: has effect only when `'CollectData' == 1`; if `0` - no noise added; if `1` - noise objects added on the image\n    * `'Positive'`: has effect only when `'CollectData' == 1`; if `0` - collect negative examples (target object hidden); if `1` - collect positive examples (target object visible)\n    * `FocusedObject` - has effect only when `'CollectData' == 1`; specify which object is focused on collecting data (input: object number from `Data collection settings`)\n    * `EnableBackgroundImage` - has effect only when `'CollectData' == 1`; if `0` - transdec is background; if `1` - random images is background\n    * `ForceToSaveAsNegative` - focus to save image as negative example, even if `Postive` is set to `True`\n    * `'AgentMaxSteps'`: after how many steps is the agent reset; if `0` - never\n  * `training`: `bool`, *optional* - use TransdecEnvironment in training mode (if `True`) or in inference mode (if `False`); defaults to `true`\n\n|**`tc.step(action=[0.0, 0.0, 0.0, 0.0])`**|[*[source]*](https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L76)|\n|---|---|\n\nMake a step in the environment (specified with `action`) and update observations.\n\n#### Parameters:\n  * `action`: `Tuple[float, float, float, float]`, *optional* - movement settings for the robot in range `[-1, 1]`; defaults to `[0.0, 0.0, 0.0, 0.0]`; action sequence:\n    * longitudinal movement (`1.0`: max forward, `-1.0`: max backward)\n    * lateral movement (`1.0`: max right, `-1.0`: max left)\n    * vertical movement (`1.0`: max upward, `-1.0`: max downward)\n    * yaw rotation (`1.0`: max right turn, `-1.0`: max left turn)\n    * camera focus (`0`: front camera, `1`: bottom camera)\n\n|**`tc.reward`**|[*[source]*](https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L87)|\n|---|---|\n\nGet current reward value.\n\n#### Returns:\n  * `float` representing current reward value calculated inside TransdecEnvironment\n\n|**`tc.vector`**|[*[source]*](https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L117)|\n|---|---|\n\nGet current vector observations dictionary.\n\n#### Returns:\n  * The dictionary of observations with keys:\n    * `'acceleration_x'` - linear acceleration value in all axes,\n    * `'acceleration_y'`,\n    * `'acceleration_z'`,\n    * `'angular_acceleration_x'` - angular acceleration value in all axes,\n    * `'angular_acceleration_y'`,\n    * `'angular_acceleration_z'`,\n    * `'rotation_x'` - rotation position value in all axes,\n    * `'rotation_y'`,\n    * `'rotation_z'`,\n    * `'depth'` - robot's depth measured from water surface,\n    * `'bounding_box_x'` - bounding box parameters (central point coordinates, width and height),\n    * `'bounding_box_y'`,\n    * `'bounding_box_w'`,\n    * `'bounding_box_h'`,\n    * `'bounding_box_p'` - probability of containing target (`1` or `0`),\n    * `'relative_x'` - robot's position relative to target in all axes,\n    * `'relative_y'`,\n    * `'relative_z'`,\n    * `'relative_yaw'` - robot's orientation relative to target in vertical axis\n\n|**`tc.visual`**|[*[source]*](https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L131)|\n|---|---|\n\nGet current visual observations list.\n\n#### Returns:\n  * `List` of all available visual observations as Numpy arrays in range `[0, 255]`\n\n|**`tc.collect_data(positive, add_noise, n_images, save_dir='collected_data', start_num=1, annotation_margin=5, used_observations=('x', 'y', 'w', 'h', 'p'), show_img=False, draw_annotations=False, print_annotations=False, progress_bar=True)`**|[*[source]*](https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L146)|\n|---|---|\n\nAutomatically collect data from Transdec Environment, saving images to `save_dir`, together with `annotations.csv` of preset content.\n\n#### Parameters:\n  * `positive`: `bool` - if `True` collect positive examples (target object visible), else collect negative examples (target object hidden)\n  * `add_noise`: `bool` - if `True add noise objects on the image, else do not\n  * `n_images`: `int` - number of images to be saved\n  * `save_dir`: `str`, *optional* - folder to put images and annotations file; defaults to `'collected_data'`\n  * `start_num`: `int`, *optional* - starting number to for image filename; defaults to `1`\n  * `annotation_margin`: `int`, *optional* - value added to all bounding box' dimensions; defaults to `5`\n  * `used_observations`: `Union[str, Tuple[str, ...]]`, *optional* - which of the observations should be saved to `annotations.csv` file; if `all` save all vector observations; defaults to `('x', 'y', 'w', 'h', 'p')`; available keys:\n    * `'a_x'` - linear acceleration value in all axes,\n    * `'a_y'`,\n    * `'a_z'`,\n    * `'eps_x'` - angular acceleration value in all axes,\n    * `'eps_y'`,\n    * `'eps_z'`,\n    * `'phi_x'` - rotation position value in all axes,\n    * `'phi_y'`,\n    * `'phi_z'`,\n    * `'d'` - robot's depth measured from water surface,\n    * `'x'` - bounding box parameters (central point coordinates, width and height),\n    * `'y'`,\n    * `'w'`,\n    * `'h'`,\n    * `'p'` - probability of containing target (`1` or `0`),\n    * `'relative_x'` - robot's position relative to target in all axes,\n    * `'relative_y'`,\n    * `'relative_z'`,\n    * `'relative_yaw'` - robot's orientation relative to target in vertical axis\n  * `show_img`: `bool`, *optional* - show each collected image; defaults to `False`\n  * `draw_annotations`: `bool`, *optional* - draw annotations on each showed image; has effect only when `show_img==True`; defaults to `False`\n  * `print_annotations`: `bool`, *optional* - print each annotation in console; defaults to `False`\n  * `progress_bar`: `bool`, *optional* - show neat progressbar for data collection; defaults to `True`\n\n### Example code for data collection\n\n```python\nwith TransdecCommunication() as tc:\n        # collect 1000 positive examples with noise of object 0\n        tc.collect_data(positive=True, add_noise=True, add_background=False, n_images=1000, save_dir='collected_data/{}/train'.format(0),\n                        used_observations='all', object_number=0, show_img=True, draw_annotations=True)\n        # collect 1000 positive examples with custom backgrount of object 0\n        tc.collect_data(positive=True, add_noise=False, add_background=True, n_images=1000, save_dir='collected_data/{}/train'.format(0),\n                        used_observations='all', object_number=0, show_img=True, draw_annotations=True) \n        # collect 1000 negative examples with noise of object 0\n        tc.collect_data(positive=False, add_noise=True, add_background=False, n_images=1000, save_dir='collected_data/{}/train'.format(0),\n                        used_observations='all', object_number=0, show_img=True, draw_annotations=True)\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/pwrdc/PyTransdec", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "PyTransdec", "package_url": "https://pypi.org/project/PyTransdec/", "platform": "", "project_url": "https://pypi.org/project/PyTransdec/", "project_urls": {"Homepage": "https://github.com/pwrdc/PyTransdec"}, "release_url": "https://pypi.org/project/PyTransdec/0.2.1/", "requires_dist": ["numpy", "pandas", "tqdm", "opencv-python", "mlagents (==0.7.0)"], "requires_python": "", "summary": "Transdec environment https://github.com/pwrdc/TransdecEnvironment controlling with Python", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PyTransdec</h1>\n<p><strong>PyTransdec</strong> is a Python library prepared for controlling <a href=\"https://github.com/PiotrJZielinski/TransdecEnvironment\" rel=\"nofollow\"><strong>TransdecEnvironment</strong></a> by PWr Diving Crew (KN Robocik) at Wroc\u0139\u201aaw University of Science and Technology.</p>\n<p>It wraps <a href=\"https://github.com/Unity-Technologies/ml-agents/tree/master/ml-agents\" rel=\"nofollow\">Unity ML-Agents library</a>.</p>\n<p>The project is maintained by Pwr Diving Crew software team members (Unity3D section).</p>\n<p><a href=\"http://www.robocik.pwr.edu.pl/\" rel=\"nofollow\">KN Robocik website</a></p>\n<p>Should any issues be noticed, please submit a <strong>New issue</strong> on GitHub.</p>\n<h2>Installation</h2>\n<h3>Python</h3>\n<p>To use Python API <strong>Python 3.6</strong> is required. On Windows it is recommended to use Anaconda (<a href=\"https://repo.continuum.io/archive/Anaconda3-5.1.0-Windows-x86_64.exe\" rel=\"nofollow\">64-bit</a> or <a href=\"https://repo.continuum.io/archive/Anaconda3-5.1.0-Windows-x86.exe\" rel=\"nofollow\">32-bit</a>, but you can use your own preferred Python installation.</p>\n<p>For Anaconda use default installation settings. After installation open <strong>Anaconda Navigator</strong> to finish the setup.</p>\n<p><img alt=\"image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6c62fb5492d339c30530e011a5acc7f46cfeb567/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f32333331313531332f35333639343132302d36353963376438302d336461612d313165392d393637642d6164636364653763613039352e706e67\"></p>\n<p>In case environment variables were not created, you will see error <code>conda is not recognized as internal or external command</code> when you type <code>conda</code> into command line. To solve this problem set the environment variables: open <code>Edit environment variables for your account</code>, click <code>Environment Variables</code> button, then double click <code>Path under</code> under <code>System variable</code>. Add the following paths using <code>New</code> button:</p>\n<pre><code>%UserProfile%\\Anaconda3\\Scripts\n%UserProfile%\\Anaconda3\\Scripts\\conda.exe\n%UserProfile%\\Anaconda3\n%UserProfile%\\Anaconda3\\python.exe\n</code></pre>\n<p><img alt=\"image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d3a83b371f552e9deb3563993c2f454d4d5e6b4d/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f32333331313531332f35333639343130342d33373165613238302d336461612d313165392d383335312d3233656261393765333739332e706e67\"></p>\n<p>Before proceeding check your installation by executing <code>python --version</code>, which should output something like this:</p>\n<pre><code>Python 3.6.x :: ...\n</code></pre>\n<p>You also need <strong>pip</strong> (which is installed by default in Anaconda). Check if it is correctly installed by executing <code>pip --version</code>. The output should look like this:</p>\n<pre><code>pip x.x...\n</code></pre>\n<p>If any error occurred, please check your installation.</p>\n<h3>PyTransdec package</h3>\n<p>To use the package install it using pip (it is recommended to use a <strong>virtual environment</strong> such as <a href=\"https://pipenv.readthedocs.io/en/latest/\" rel=\"nofollow\"><strong>Pipenv</strong></a> (preferred), <a href=\"https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\" rel=\"nofollow\"><strong>conda env</strong></a> or <a href=\"https://virtualenv.pypa.io/en/latest/\" rel=\"nofollow\"><strong>virtualenv</strong></a>.</p>\n<p>Installation command:</p>\n<pre><code>pip install git+https://github.com/PiotrJZielinski/PyTransdec\n</code></pre>\n<p>PyTransdec package automatically installs all required dependencies.</p>\n<h2>Usage</h2>\n<p>PyTransdec package contains <code>TransdecCommunication([file_name, worker_id])</code> class, which can be used to communicate with TransdecEnvironment. To import the package use following Python script:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pytransdec</span> <span class=\"kn\">import</span> <span class=\"n\">TransdecCommunication</span>\n</pre>\n<p>You can then apply it using <code>with</code> statement:</p>\n<pre><span class=\"k\">with</span> <span class=\"n\">TransdecCommunication</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">tc</span><span class=\"p\">:</span>\n  <span class=\"o\">...</span>\n</pre>\n<h4>Parameters:</h4>\n<ul>\n<li><code>file_name</code>: <code>str</code>, <em>optional</em> - Unity Environment file to operate on; defaults to <code>None</code> (connect to Unity Editor)</li>\n<li><code>worker_id</code>: <code>int</code>, <em>optional</em> - for more than 1 parallel workers - port incremental to be used for connection; defaults to <code>0</code></li>\n</ul>\n<h3>Methods</h3>\n<table>\n<thead>\n<tr>\n<th>method/property</th>\n<th>description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>tc.reset([message, training])</code></td>\n<td>Reset the environment with reset <code>message</code>; update observations</td>\n</tr>\n<tr>\n<td><code>tc.step([action])</code></td>\n<td>Make a step in the environment (specified with <code>action</code>); update observations</td>\n</tr>\n<tr>\n<td><code>tc.reward</code></td>\n<td>Current reward value</td>\n</tr>\n<tr>\n<td><code>tc.vector</code></td>\n<td>Current vector observations dictionary</td>\n</tr>\n<tr>\n<td><code>tc.visual</code></td>\n<td>Current visual observations list</td>\n</tr>\n<tr>\n<td><code>tc.collect_data(positive, add_noise, add_background, n_images[, save_dir, start_num, annotation_margin, used_observations, object_number, show_img, draw_annotations, print_annotations, progress_bar])</code></td>\n<td>Automatically collect data from Transdec Environment</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th><strong><code>tc.reset(self, message={}, training=True)</code></strong></th>\n<th><a href=\"https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L65\" rel=\"nofollow\"><em>[source]</em></a></th>\n</tr>\n</thead></table>\n<p>Reset the environment with reset <code>message</code> and update observations.</p>\n<h4>Parameters:</h4>\n<ul>\n<li><code>message</code>: <code>Dict[str, int]</code>, <em>optional</em> - a dictionary specifying TransdecEnvironment reset settings; defaults to empty <code>Dict</code>; available keys:\n<ul>\n<li><code>'CollectData'</code>: if <code>0</code> - navigation mode; if <code>1</code> - data collection mode</li>\n<li><code>'EnableNoise'</code>: has effect only when <code>'CollectData' == 1</code>; if <code>0</code> - no noise added; if <code>1</code> - noise objects added on the image</li>\n<li><code>'Positive'</code>: has effect only when <code>'CollectData' == 1</code>; if <code>0</code> - collect negative examples (target object hidden); if <code>1</code> - collect positive examples (target object visible)</li>\n<li><code>FocusedObject</code> - has effect only when <code>'CollectData' == 1</code>; specify which object is focused on collecting data (input: object number from <code>Data collection settings</code>)</li>\n<li><code>EnableBackgroundImage</code> - has effect only when <code>'CollectData' == 1</code>; if <code>0</code> - transdec is background; if <code>1</code> - random images is background</li>\n<li><code>ForceToSaveAsNegative</code> - focus to save image as negative example, even if <code>Postive</code> is set to <code>True</code></li>\n<li><code>'AgentMaxSteps'</code>: after how many steps is the agent reset; if <code>0</code> - never</li>\n</ul>\n</li>\n<li><code>training</code>: <code>bool</code>, <em>optional</em> - use TransdecEnvironment in training mode (if <code>True</code>) or in inference mode (if <code>False</code>); defaults to <code>true</code></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><code>tc.step(action=[0.0, 0.0, 0.0, 0.0])</code></strong></th>\n<th><a href=\"https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L76\" rel=\"nofollow\"><em>[source]</em></a></th>\n</tr>\n</thead></table>\n<p>Make a step in the environment (specified with <code>action</code>) and update observations.</p>\n<h4>Parameters:</h4>\n<ul>\n<li><code>action</code>: <code>Tuple[float, float, float, float]</code>, <em>optional</em> - movement settings for the robot in range <code>[-1, 1]</code>; defaults to <code>[0.0, 0.0, 0.0, 0.0]</code>; action sequence:\n<ul>\n<li>longitudinal movement (<code>1.0</code>: max forward, <code>-1.0</code>: max backward)</li>\n<li>lateral movement (<code>1.0</code>: max right, <code>-1.0</code>: max left)</li>\n<li>vertical movement (<code>1.0</code>: max upward, <code>-1.0</code>: max downward)</li>\n<li>yaw rotation (<code>1.0</code>: max right turn, <code>-1.0</code>: max left turn)</li>\n<li>camera focus (<code>0</code>: front camera, <code>1</code>: bottom camera)</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><code>tc.reward</code></strong></th>\n<th><a href=\"https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L87\" rel=\"nofollow\"><em>[source]</em></a></th>\n</tr>\n</thead></table>\n<p>Get current reward value.</p>\n<h4>Returns:</h4>\n<ul>\n<li><code>float</code> representing current reward value calculated inside TransdecEnvironment</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><code>tc.vector</code></strong></th>\n<th><a href=\"https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L117\" rel=\"nofollow\"><em>[source]</em></a></th>\n</tr>\n</thead></table>\n<p>Get current vector observations dictionary.</p>\n<h4>Returns:</h4>\n<ul>\n<li>The dictionary of observations with keys:\n<ul>\n<li><code>'acceleration_x'</code> - linear acceleration value in all axes,</li>\n<li><code>'acceleration_y'</code>,</li>\n<li><code>'acceleration_z'</code>,</li>\n<li><code>'angular_acceleration_x'</code> - angular acceleration value in all axes,</li>\n<li><code>'angular_acceleration_y'</code>,</li>\n<li><code>'angular_acceleration_z'</code>,</li>\n<li><code>'rotation_x'</code> - rotation position value in all axes,</li>\n<li><code>'rotation_y'</code>,</li>\n<li><code>'rotation_z'</code>,</li>\n<li><code>'depth'</code> - robot's depth measured from water surface,</li>\n<li><code>'bounding_box_x'</code> - bounding box parameters (central point coordinates, width and height),</li>\n<li><code>'bounding_box_y'</code>,</li>\n<li><code>'bounding_box_w'</code>,</li>\n<li><code>'bounding_box_h'</code>,</li>\n<li><code>'bounding_box_p'</code> - probability of containing target (<code>1</code> or <code>0</code>),</li>\n<li><code>'relative_x'</code> - robot's position relative to target in all axes,</li>\n<li><code>'relative_y'</code>,</li>\n<li><code>'relative_z'</code>,</li>\n<li><code>'relative_yaw'</code> - robot's orientation relative to target in vertical axis</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><code>tc.visual</code></strong></th>\n<th><a href=\"https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L131\" rel=\"nofollow\"><em>[source]</em></a></th>\n</tr>\n</thead></table>\n<p>Get current visual observations list.</p>\n<h4>Returns:</h4>\n<ul>\n<li><code>List</code> of all available visual observations as Numpy arrays in range <code>[0, 255]</code></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><code>tc.collect_data(positive, add_noise, n_images, save_dir='collected_data', start_num=1, annotation_margin=5, used_observations=('x', 'y', 'w', 'h', 'p'), show_img=False, draw_annotations=False, print_annotations=False, progress_bar=True)</code></strong></th>\n<th><a href=\"https://github.com/PiotrJZielinski/PyTransdec/blob/b915c1b25653386024066c6c9f099181498fe5de/pytransdec/communication.py#L146\" rel=\"nofollow\"><em>[source]</em></a></th>\n</tr>\n</thead></table>\n<p>Automatically collect data from Transdec Environment, saving images to <code>save_dir</code>, together with <code>annotations.csv</code> of preset content.</p>\n<h4>Parameters:</h4>\n<ul>\n<li><code>positive</code>: <code>bool</code> - if <code>True</code> collect positive examples (target object visible), else collect negative examples (target object hidden)</li>\n<li><code>add_noise</code>: <code>bool</code> - if `True add noise objects on the image, else do not</li>\n<li><code>n_images</code>: <code>int</code> - number of images to be saved</li>\n<li><code>save_dir</code>: <code>str</code>, <em>optional</em> - folder to put images and annotations file; defaults to <code>'collected_data'</code></li>\n<li><code>start_num</code>: <code>int</code>, <em>optional</em> - starting number to for image filename; defaults to <code>1</code></li>\n<li><code>annotation_margin</code>: <code>int</code>, <em>optional</em> - value added to all bounding box' dimensions; defaults to <code>5</code></li>\n<li><code>used_observations</code>: <code>Union[str, Tuple[str, ...]]</code>, <em>optional</em> - which of the observations should be saved to <code>annotations.csv</code> file; if <code>all</code> save all vector observations; defaults to <code>('x', 'y', 'w', 'h', 'p')</code>; available keys:\n<ul>\n<li><code>'a_x'</code> - linear acceleration value in all axes,</li>\n<li><code>'a_y'</code>,</li>\n<li><code>'a_z'</code>,</li>\n<li><code>'eps_x'</code> - angular acceleration value in all axes,</li>\n<li><code>'eps_y'</code>,</li>\n<li><code>'eps_z'</code>,</li>\n<li><code>'phi_x'</code> - rotation position value in all axes,</li>\n<li><code>'phi_y'</code>,</li>\n<li><code>'phi_z'</code>,</li>\n<li><code>'d'</code> - robot's depth measured from water surface,</li>\n<li><code>'x'</code> - bounding box parameters (central point coordinates, width and height),</li>\n<li><code>'y'</code>,</li>\n<li><code>'w'</code>,</li>\n<li><code>'h'</code>,</li>\n<li><code>'p'</code> - probability of containing target (<code>1</code> or <code>0</code>),</li>\n<li><code>'relative_x'</code> - robot's position relative to target in all axes,</li>\n<li><code>'relative_y'</code>,</li>\n<li><code>'relative_z'</code>,</li>\n<li><code>'relative_yaw'</code> - robot's orientation relative to target in vertical axis</li>\n</ul>\n</li>\n<li><code>show_img</code>: <code>bool</code>, <em>optional</em> - show each collected image; defaults to <code>False</code></li>\n<li><code>draw_annotations</code>: <code>bool</code>, <em>optional</em> - draw annotations on each showed image; has effect only when <code>show_img==True</code>; defaults to <code>False</code></li>\n<li><code>print_annotations</code>: <code>bool</code>, <em>optional</em> - print each annotation in console; defaults to <code>False</code></li>\n<li><code>progress_bar</code>: <code>bool</code>, <em>optional</em> - show neat progressbar for data collection; defaults to <code>True</code></li>\n</ul>\n<h3>Example code for data collection</h3>\n<pre><span class=\"k\">with</span> <span class=\"n\">TransdecCommunication</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">tc</span><span class=\"p\">:</span>\n        <span class=\"c1\"># collect 1000 positive examples with noise of object 0</span>\n        <span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">collect_data</span><span class=\"p\">(</span><span class=\"n\">positive</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">add_noise</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">add_background</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">n_images</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">save_dir</span><span class=\"o\">=</span><span class=\"s1\">'collected_data/</span><span class=\"si\">{}</span><span class=\"s1\">/train'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span>\n                        <span class=\"n\">used_observations</span><span class=\"o\">=</span><span class=\"s1\">'all'</span><span class=\"p\">,</span> <span class=\"n\">object_number</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">show_img</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">draw_annotations</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n        <span class=\"c1\"># collect 1000 positive examples with custom backgrount of object 0</span>\n        <span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">collect_data</span><span class=\"p\">(</span><span class=\"n\">positive</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">add_noise</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">add_background</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">n_images</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">save_dir</span><span class=\"o\">=</span><span class=\"s1\">'collected_data/</span><span class=\"si\">{}</span><span class=\"s1\">/train'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span>\n                        <span class=\"n\">used_observations</span><span class=\"o\">=</span><span class=\"s1\">'all'</span><span class=\"p\">,</span> <span class=\"n\">object_number</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">show_img</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">draw_annotations</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> \n        <span class=\"c1\"># collect 1000 negative examples with noise of object 0</span>\n        <span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">collect_data</span><span class=\"p\">(</span><span class=\"n\">positive</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">add_noise</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">add_background</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">n_images</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">save_dir</span><span class=\"o\">=</span><span class=\"s1\">'collected_data/</span><span class=\"si\">{}</span><span class=\"s1\">/train'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span>\n                        <span class=\"n\">used_observations</span><span class=\"o\">=</span><span class=\"s1\">'all'</span><span class=\"p\">,</span> <span class=\"n\">object_number</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">show_img</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">draw_annotations</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 6769663, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "5372b4512b31d6f8844a39db2b315966", "sha256": "e268c5b8ea6b21cb9644fdbff309f09539fe306ec8cd622f7859c42577b7bf5a"}, "downloads": -1, "filename": "PyTransdec-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5372b4512b31d6f8844a39db2b315966", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11286, "upload_time": "2020-03-07T19:33:33", "upload_time_iso_8601": "2020-03-07T19:33:33.717563Z", "url": "https://files.pythonhosted.org/packages/b1/0c/eeac9eb4986724f65b8dc6eb7699d13af8134ef738bd11ec1717eb087c54/PyTransdec-0.1.0-py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "5b1c6946096d439044991c9cd6a4e1ad", "sha256": "d9f6076b0782693efe477af63d566a604b70180b7cbc22247a5c56c2aa537031"}, "downloads": -1, "filename": "PyTransdec-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5b1c6946096d439044991c9cd6a4e1ad", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11294, "upload_time": "2020-03-07T19:33:36", "upload_time_iso_8601": "2020-03-07T19:33:36.446510Z", "url": "https://files.pythonhosted.org/packages/ba/49/af2601642ec46aedd2e65f76af680e236f950e08b597f45996d56889266c/PyTransdec-0.2.0-py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "8d15d9b1e41cf6f343f937d09ffb1e52", "sha256": "79d22f8c732e830c7bd1c63c6f065ad2b655d2638df9c007195cd80b1ef4ba37"}, "downloads": -1, "filename": "PyTransdec-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "8d15d9b1e41cf6f343f937d09ffb1e52", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11308, "upload_time": "2020-03-07T22:19:30", "upload_time_iso_8601": "2020-03-07T22:19:30.722079Z", "url": "https://files.pythonhosted.org/packages/53/1d/b3dd097ec974d75310af49770fc6971d41a2aaa796ee2cd9e1dd9853cc51/PyTransdec-0.2.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8d15d9b1e41cf6f343f937d09ffb1e52", "sha256": "79d22f8c732e830c7bd1c63c6f065ad2b655d2638df9c007195cd80b1ef4ba37"}, "downloads": -1, "filename": "PyTransdec-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "8d15d9b1e41cf6f343f937d09ffb1e52", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11308, "upload_time": "2020-03-07T22:19:30", "upload_time_iso_8601": "2020-03-07T22:19:30.722079Z", "url": "https://files.pythonhosted.org/packages/53/1d/b3dd097ec974d75310af49770fc6971d41a2aaa796ee2cd9e1dd9853cc51/PyTransdec-0.2.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:13:21 2020"}