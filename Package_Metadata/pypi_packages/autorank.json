{"info": {"author": "sherbold", "author_email": "herbold@cs.uni.goettingen.de", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering"], "description": "# Autorank\n\n[![Actions Status](https://github.com/sherbold/autorank/workflows/Build/badge.svg)](https://github.com/sherbold/autorank/actions)\n[![codecov](https://codecov.io/gh/sherbold/autorank/branch/master/graph/badge.svg)](https://codecov.io/gh/sherbold/autorank)\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/sherbold/autorank.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/sherbold/autorank/alerts/)\n[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/sherbold/autorank.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/sherbold/autorank/context:python)\n\n## Summary\n\nAutorank is a simple Python package with one task: simplify the comparison between (multiple) paired populations. This\nis, for example, required if the performance different machine learning algorithms or simulations should be compared on\nmultiple data sets. The performance measures on each data set are then the paired samples, the difference in the central\ntendency (e.g., the mean or median) can be used to rank the different algorithms. This problem is not new and how such\ntests could be done was already described in 2006  in the well-known article _Janez Dem\u0161ar. 2006. Statistical Comparisons\nof Classifiers over Multiple Data Sets. J. Mach. Learn. Res. 7 (December 2006), 1\u201330_. \n\nRegardless, the correct use of Dem\u0161ar guidelines is hard for non-experts in statistics. Correct use of the guidelines\nrequires the decision of whether a paired t-test, a Wilcoxon's rank sum test, repeated measures ANOVA with Tukey's HSD \nas post-hoc test, or Friedman's tests and Nemenyi's post-hoc test to determine an answer to the question if there are\ndifferences. For this, the distribution of the populations must be analyzed with the Shapiro-Wilk test for normality\nand, depending on the normality with Levene's test or Bartlett's tests for homogeneity of the data. All this is already\nquite complex. This does not yet account for the adjustment of the significance level in case of repeated tests to\nachieve the desired family-wise significance. Additionally, not only the tests should be conducted, but good reporting\nof the results also include confidence intervals, effect sizes, and the decision of whether it is appropriate to report\nthe mean value and standard deviation, or whether the median value and the median absolute deviation is more\nappropriate.   \n\nThe goal of Autorank is to simplify the statistical analysis for non-experts. Autorank takes care of all of the above\nwith a single function call. Additional functions allow the generation of appropriate plots, result tables, and even of\na complete latex document. All that is required is the data about the populations is in a \n[Pandas](https://pandas.pydata.org/) dataframe.   \n\n\n## Installation\n\nAutorank is available on PyPi and can be installed using pip.\n\n```\npip install autorank\n```\n\nYou can also clone this repository and install the latest development version (requires git and setuptools).\n```\ngit clone https://github.com/sherbold/autorank\ncd autorank\npython setup.py install\n```\n\n## API Documentation\n\nYou can find the API documentation of the current master of Autorank\n[online](https://sherbold.github.io/autorank/autorank/).\n\n## Description\n\nThe following flow chart summarizes the decisions made by Autorank.\n\n![CD Diagram](flowchart.png)\n\nAutorank uses the following strategy for the statistical comparison of paired populations:\n- First all populations are checked with the Shapiro-Wilk test for normality. We use Bonferoni correction for these\n  tests, i.e., alpha/#populations.\n- If all columns are normal, we use Bartlett's test for homogeneity, otherwise we use Levene's test.\n- Based on the normality and the homogeneity, we select appropriate tests, effect sizes, and methods for determining\n  the confidence intervals of the central tendency.\n\nIf all columns are normal, we calculate:\n- The mean value as central tendency.\n- The empirical standard deviation as measure for the variance.\n- The confidence interval for the mean value.\n- The effect size in comparison to the highest mean value using Cohen's d.\n\nIf at least one column is not normal, we calculate:\n- The median as central tendency.\n- The median absolute deviation from the median as measure for the variance.\n- The confidence interval for the median.\n- The effect size in comparison to the highest ranking approach using Cliff's delta.\n\nFor the statistical tests, there are four variants:\n- If there are two populations and both populations are normal, we use the paired t-test.\n- If there are two populations and at least one populations is not normal, we use Wilcoxon's signed rank test.\n- If there are more than two populations and all populations are normal and homoscedastic, we use repeated measures\n  ANOVA with Tukey's HSD as post-hoc test.\n- If there are more than two populations and at least one populations is not normal or the populations are\n  heteroscedastic, we use Friedman's test with the Nemenyi post-hoc test.\n\nWe use the paired t-test, the Wilcoxon signed rank test, and the Friedman test from [scipy](https://www.scipy.org/). The\nrepeated measures ANOVA and Tukey's HSD test (including the calculation of the confidence intervals) are used from\n[statsmodels](statsmodels). We use own implementations for the calculation of critical distance of the Nemenyi test,\nthe calculation of the effect sizes, and the calculation of the confidence intervals (with the exception of Tukey's\nHSD).\n\n\n## Usage Example\n\nThe following example shows the usage of `autorank`. First, we import the functions from autorank and create some data. \n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom autorank import autorank, plot_stats, create_report, latex_table\n\nnp.random.seed(42)\npd.set_option('display.max_columns', 7)\nstd = 0.3\nmeans = [0.2, 0.3, 0.5, 0.8, 0.85, 0.9]\nsample_size = 50\ndata = pd.DataFrame()\nfor i, mean in enumerate(means):\n    data['pop_%i' % i] = np.random.normal(mean, std, sample_size).clip(0, 1)\n```\n\nThe statistical analysis of the data only requires a single command. As a result, you get a named tuple with all\nrelevant information from the statistical analysis conducted.  \n```python\nresult = autorank(data, alpha=0.05, verbose=False)\nprint(result)\n``` \nOutput: \n```\nRankResult(rankdf=\n       meanrank    median       mad  ci_lower  ci_upper  effect_size    mangitude\npop_5      2.18  0.912005  0.130461  0.692127         1  2.66454e-17   negligible\npop_4      2.29  0.910437  0.132786  0.654001         1       -0.024   negligible\npop_3      2.47  0.858091  0.210394  0.573879         1       0.1364   negligible\npop_2      3.95  0.505057  0.333594  0.227184   0.72558       0.6424        large\npop_1      4.71  0.313824  0.247339  0.149473  0.546571       0.8516        large\npop_0      5.40  0.129756  0.192377         0  0.349014       0.9192        large\npvalue=2.3412212612346733e-28,\ncd=1.0662484349869374,\nomnibus='friedman',\nposthoc='nemenyi',\nall_normal=False,\npvals_shapiro=[1.646607051952742e-05, 0.0605173334479332, 0.13884511590003967, 0.00010030837438534945,\n               2.066387423838023e-06, 1.5319776593969436e-06],\nhomoscedastic=True,\npval_homogeneity=0.2663177301695518,\nhomogeneity_test='levene')\nalpha=0.05, \nalpha_normality=0.008333333333333333, \nnum_samples=50)\n```\n\nYou can go ahead and use this tuple to create your own report about the statistical analysis. Alternatively, you can use\nautorank for this task.  \n```python\ncreate_report(result)\n```\nOutput:\n```\nThe statistical analysis was conducted for 6 populations with 50 paired samples.\nThe family-wise significance level of the tests is alpha=0.050.\nWe rejected the null hypothesis that the population is normal for the populations pop_5 (p=0.000), pop_2 (p=0.000), \npop_1 (p=0.000), and pop_0 (p=0.000). Therefore, we assume that not all populations are normal.\nBecause we have more than two populations and the populations and some of them are not normal, we use the \nnon-parametric Friedman test as omnibus test to determine if there are any significant differences between the \nmedian values of the populations. We use the post-hoc Nemenyi test to infer which differences are significant. We report\nthe median (MD), the median absolute deviation (MAD) and the mean rank (MR) among all populations over the samples. \nDifferences between populations are significant, if the difference of the mean rank is greater than the critical \ndistance CD=1.066 of the Nemenyi test.\nWe reject the null hypothesis (p=0.000) of the Friedman test that there is no difference in the central tendency of \nthe populations pop_5 (MD=0.912+-0.154, MAD=0.130, MR=2.180), pop_4 (MD=0.910+-0.173, MAD=0.133, MR=2.290), pop_3 \n(MD=0.858+-0.213, MAD=0.210, MR=2.470), pop_2 (MD=0.505+-0.249, MAD=0.334, MR=3.950), pop_1 (MD=0.314+-0.199, \nMAD=0.247, MR=4.710), and pop_0 (MD=0.130+-0.175, MAD=0.192, MR=5.400). Therefore, we assume that there is a \nstatistically significant difference between the median values of the populations.\nBased on the post-hoc Nemenyi test, we assume that there are no significant differences within the following groups: \npop_5, pop_4, and pop_3; pop_2 and pop_1; pop_1 and pop_0. All other differences are significant.\n```\nOur you could use Autorank to generate a plot that visualizes the statistical analysis. Autorank creates plots of the\nconfidence interval in case of the paired t-test and repeated measures ANOVA and a critical distance diagram for the\npost-hoc Nemenyi test. \n\n```python\nplot_stats(result)\nplt.show()\n```\n\nFor the above example, the following plot is created:\n\n![CD Diagram](examples/cd_diagram.png)\n\nTo further support reporting in scholarly article, Autorank can also generate a latex table with the relevant results. \n```python\nlatex_table(result)\n```\nOutput:\n```\n\\begin{table}[h]\n\\centering\n\\begin{tabular}{lrlllll}\n\\toprule\n{} &    MR &   MED &   MAD &              CI & $\\delta$ &   Magnitude \\\\\n\\midrule\npop\\_5 & 2.180 & 0.912 & 0.130 &  [0.692, 1.000] &     0.000 &  negligible \\\\\npop\\_4 & 2.290 & 0.910 & 0.133 &  [0.654, 1.000] &    -0.024 &  negligible \\\\\npop\\_3 & 2.470 & 0.858 & 0.210 &  [0.574, 1.000] &     0.136 &  negligible \\\\\npop\\_2 & 3.950 & 0.505 & 0.334 &  [0.227, 0.726] &     0.642 &       large \\\\\npop\\_1 & 4.710 & 0.314 & 0.247 &  [0.149, 0.547] &     0.852 &       large \\\\\npop\\_0 & 5.400 & 0.130 & 0.192 &  [0.000, 0.349] &     0.919 &       large \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Summary of populations}\n\\label{tbl:stat_results}\n\\end{table}\n```\n\nThe rendered table looks like this (may change depending on the class of the document).\n\n![Table](examples/table.png)\n\n## Creating a Local Developer Environment\n\nIf you want to modify the code of autorank, we recommend that you setup a local development environment with a \nvirtual environment as follows. \n\n```\ngit clone https://github.com/sherbold/autorank\ncd autorank\npython3 -m venv .\nsource bin/activate\npip install .\n```\n\nYou can run the tests to check if everything works. \n\n```\npython -m unittest\n```\n\n## Contributing\n\nContributions to Autorank are welcome.\n\n- Just file an [Issue]() to ask questions, report bugs, or request new features. \n- Pull requests via GitHub are also welcome.\n\nPotential contributions include more detailed report generation or the extension of Autorank to more types of data,\ne.g., independent populations, or paired populations with unequal sample sizes.   \n\n\n## License\n\nAutorank is published under the Apache 2.0 Licence.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/sherbold/autorank/zipball/master", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sherbold/autorank", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "autorank", "package_url": "https://pypi.org/project/autorank/", "platform": "", "project_url": "https://pypi.org/project/autorank/", "project_urls": {"Download": "https://github.com/sherbold/autorank/zipball/master", "Homepage": "https://github.com/sherbold/autorank"}, "release_url": "https://pypi.org/project/autorank/1.0.1/", "requires_dist": ["numpy", "pandas (>=0.25.0)", "statsmodels (>=0.10.0)", "scipy (>=1.3.0)", "matplotlib (>=3.1.3)"], "requires_python": "", "summary": "Automated ranking of populations in a repeated measures experiment, e.g., to rank different machine learning approaches tested on the same data.", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Autorank</h1>\n<p><a href=\"https://github.com/sherbold/autorank/actions\" rel=\"nofollow\"><img alt=\"Actions Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5df86b62f8a313819d6f0877aab0317e473e26a0/68747470733a2f2f6769746875622e636f6d2f73686572626f6c642f6175746f72616e6b2f776f726b666c6f77732f4275696c642f62616467652e737667\"></a>\n<a href=\"https://codecov.io/gh/sherbold/autorank\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8239f2674e2208153ae4e92943fb840db5534c84/68747470733a2f2f636f6465636f762e696f2f67682f73686572626f6c642f6175746f72616e6b2f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://lgtm.com/projects/g/sherbold/autorank/alerts/\" rel=\"nofollow\"><img alt=\"Total alerts\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4928af4a41518e6282a8a833749b4d2fbe844a9d/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f73686572626f6c642f6175746f72616e6b2e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138\"></a>\n<a href=\"https://lgtm.com/projects/g/sherbold/autorank/context:python\" rel=\"nofollow\"><img alt=\"Language grade: Python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c29bba3e9f65736ab9a8b45cb4de36ea2b72f82f/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f73686572626f6c642f6175746f72616e6b2e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138\"></a></p>\n<h2>Summary</h2>\n<p>Autorank is a simple Python package with one task: simplify the comparison between (multiple) paired populations. This\nis, for example, required if the performance different machine learning algorithms or simulations should be compared on\nmultiple data sets. The performance measures on each data set are then the paired samples, the difference in the central\ntendency (e.g., the mean or median) can be used to rank the different algorithms. This problem is not new and how such\ntests could be done was already described in 2006  in the well-known article <em>Janez Dem\u0161ar. 2006. Statistical Comparisons\nof Classifiers over Multiple Data Sets. J. Mach. Learn. Res. 7 (December 2006), 1\u201330</em>.</p>\n<p>Regardless, the correct use of Dem\u0161ar guidelines is hard for non-experts in statistics. Correct use of the guidelines\nrequires the decision of whether a paired t-test, a Wilcoxon's rank sum test, repeated measures ANOVA with Tukey's HSD\nas post-hoc test, or Friedman's tests and Nemenyi's post-hoc test to determine an answer to the question if there are\ndifferences. For this, the distribution of the populations must be analyzed with the Shapiro-Wilk test for normality\nand, depending on the normality with Levene's test or Bartlett's tests for homogeneity of the data. All this is already\nquite complex. This does not yet account for the adjustment of the significance level in case of repeated tests to\nachieve the desired family-wise significance. Additionally, not only the tests should be conducted, but good reporting\nof the results also include confidence intervals, effect sizes, and the decision of whether it is appropriate to report\nthe mean value and standard deviation, or whether the median value and the median absolute deviation is more\nappropriate.</p>\n<p>The goal of Autorank is to simplify the statistical analysis for non-experts. Autorank takes care of all of the above\nwith a single function call. Additional functions allow the generation of appropriate plots, result tables, and even of\na complete latex document. All that is required is the data about the populations is in a\n<a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">Pandas</a> dataframe.</p>\n<h2>Installation</h2>\n<p>Autorank is available on PyPi and can be installed using pip.</p>\n<pre><code>pip install autorank\n</code></pre>\n<p>You can also clone this repository and install the latest development version (requires git and setuptools).</p>\n<pre><code>git clone https://github.com/sherbold/autorank\ncd autorank\npython setup.py install\n</code></pre>\n<h2>API Documentation</h2>\n<p>You can find the API documentation of the current master of Autorank\n<a href=\"https://sherbold.github.io/autorank/autorank/\" rel=\"nofollow\">online</a>.</p>\n<h2>Description</h2>\n<p>The following flow chart summarizes the decisions made by Autorank.</p>\n<p><img alt=\"CD Diagram\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6b7e66c648b07b523ac6ad541a5939245916d495/666c6f7763686172742e706e67\"></p>\n<p>Autorank uses the following strategy for the statistical comparison of paired populations:</p>\n<ul>\n<li>First all populations are checked with the Shapiro-Wilk test for normality. We use Bonferoni correction for these\ntests, i.e., alpha/#populations.</li>\n<li>If all columns are normal, we use Bartlett's test for homogeneity, otherwise we use Levene's test.</li>\n<li>Based on the normality and the homogeneity, we select appropriate tests, effect sizes, and methods for determining\nthe confidence intervals of the central tendency.</li>\n</ul>\n<p>If all columns are normal, we calculate:</p>\n<ul>\n<li>The mean value as central tendency.</li>\n<li>The empirical standard deviation as measure for the variance.</li>\n<li>The confidence interval for the mean value.</li>\n<li>The effect size in comparison to the highest mean value using Cohen's d.</li>\n</ul>\n<p>If at least one column is not normal, we calculate:</p>\n<ul>\n<li>The median as central tendency.</li>\n<li>The median absolute deviation from the median as measure for the variance.</li>\n<li>The confidence interval for the median.</li>\n<li>The effect size in comparison to the highest ranking approach using Cliff's delta.</li>\n</ul>\n<p>For the statistical tests, there are four variants:</p>\n<ul>\n<li>If there are two populations and both populations are normal, we use the paired t-test.</li>\n<li>If there are two populations and at least one populations is not normal, we use Wilcoxon's signed rank test.</li>\n<li>If there are more than two populations and all populations are normal and homoscedastic, we use repeated measures\nANOVA with Tukey's HSD as post-hoc test.</li>\n<li>If there are more than two populations and at least one populations is not normal or the populations are\nheteroscedastic, we use Friedman's test with the Nemenyi post-hoc test.</li>\n</ul>\n<p>We use the paired t-test, the Wilcoxon signed rank test, and the Friedman test from <a href=\"https://www.scipy.org/\" rel=\"nofollow\">scipy</a>. The\nrepeated measures ANOVA and Tukey's HSD test (including the calculation of the confidence intervals) are used from\n<a href=\"statsmodels\" rel=\"nofollow\">statsmodels</a>. We use own implementations for the calculation of critical distance of the Nemenyi test,\nthe calculation of the effect sizes, and the calculation of the confidence intervals (with the exception of Tukey's\nHSD).</p>\n<h2>Usage Example</h2>\n<p>The following example shows the usage of <code>autorank</code>. First, we import the functions from autorank and create some data.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">from</span> <span class=\"nn\">autorank</span> <span class=\"kn\">import</span> <span class=\"n\">autorank</span><span class=\"p\">,</span> <span class=\"n\">plot_stats</span><span class=\"p\">,</span> <span class=\"n\">create_report</span><span class=\"p\">,</span> <span class=\"n\">latex_table</span>\n\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n<span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">set_option</span><span class=\"p\">(</span><span class=\"s1\">'display.max_columns'</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">)</span>\n<span class=\"n\">std</span> <span class=\"o\">=</span> <span class=\"mf\">0.3</span>\n<span class=\"n\">means</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">0.2</span><span class=\"p\">,</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"mf\">0.85</span><span class=\"p\">,</span> <span class=\"mf\">0.9</span><span class=\"p\">]</span>\n<span class=\"n\">sample_size</span> <span class=\"o\">=</span> <span class=\"mi\">50</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">mean</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">means</span><span class=\"p\">):</span>\n    <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"s1\">'pop_</span><span class=\"si\">%i</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">std</span><span class=\"p\">,</span> <span class=\"n\">sample_size</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">clip</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<p>The statistical analysis of the data only requires a single command. As a result, you get a named tuple with all\nrelevant information from the statistical analysis conducted.</p>\n<pre><span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">autorank</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.05</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>RankResult(rankdf=\n       meanrank    median       mad  ci_lower  ci_upper  effect_size    mangitude\npop_5      2.18  0.912005  0.130461  0.692127         1  2.66454e-17   negligible\npop_4      2.29  0.910437  0.132786  0.654001         1       -0.024   negligible\npop_3      2.47  0.858091  0.210394  0.573879         1       0.1364   negligible\npop_2      3.95  0.505057  0.333594  0.227184   0.72558       0.6424        large\npop_1      4.71  0.313824  0.247339  0.149473  0.546571       0.8516        large\npop_0      5.40  0.129756  0.192377         0  0.349014       0.9192        large\npvalue=2.3412212612346733e-28,\ncd=1.0662484349869374,\nomnibus='friedman',\nposthoc='nemenyi',\nall_normal=False,\npvals_shapiro=[1.646607051952742e-05, 0.0605173334479332, 0.13884511590003967, 0.00010030837438534945,\n               2.066387423838023e-06, 1.5319776593969436e-06],\nhomoscedastic=True,\npval_homogeneity=0.2663177301695518,\nhomogeneity_test='levene')\nalpha=0.05, \nalpha_normality=0.008333333333333333, \nnum_samples=50)\n</code></pre>\n<p>You can go ahead and use this tuple to create your own report about the statistical analysis. Alternatively, you can use\nautorank for this task.</p>\n<pre><span class=\"n\">create_report</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>The statistical analysis was conducted for 6 populations with 50 paired samples.\nThe family-wise significance level of the tests is alpha=0.050.\nWe rejected the null hypothesis that the population is normal for the populations pop_5 (p=0.000), pop_2 (p=0.000), \npop_1 (p=0.000), and pop_0 (p=0.000). Therefore, we assume that not all populations are normal.\nBecause we have more than two populations and the populations and some of them are not normal, we use the \nnon-parametric Friedman test as omnibus test to determine if there are any significant differences between the \nmedian values of the populations. We use the post-hoc Nemenyi test to infer which differences are significant. We report\nthe median (MD), the median absolute deviation (MAD) and the mean rank (MR) among all populations over the samples. \nDifferences between populations are significant, if the difference of the mean rank is greater than the critical \ndistance CD=1.066 of the Nemenyi test.\nWe reject the null hypothesis (p=0.000) of the Friedman test that there is no difference in the central tendency of \nthe populations pop_5 (MD=0.912+-0.154, MAD=0.130, MR=2.180), pop_4 (MD=0.910+-0.173, MAD=0.133, MR=2.290), pop_3 \n(MD=0.858+-0.213, MAD=0.210, MR=2.470), pop_2 (MD=0.505+-0.249, MAD=0.334, MR=3.950), pop_1 (MD=0.314+-0.199, \nMAD=0.247, MR=4.710), and pop_0 (MD=0.130+-0.175, MAD=0.192, MR=5.400). Therefore, we assume that there is a \nstatistically significant difference between the median values of the populations.\nBased on the post-hoc Nemenyi test, we assume that there are no significant differences within the following groups: \npop_5, pop_4, and pop_3; pop_2 and pop_1; pop_1 and pop_0. All other differences are significant.\n</code></pre>\n<p>Our you could use Autorank to generate a plot that visualizes the statistical analysis. Autorank creates plots of the\nconfidence interval in case of the paired t-test and repeated measures ANOVA and a critical distance diagram for the\npost-hoc Nemenyi test.</p>\n<pre><span class=\"n\">plot_stats</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<p>For the above example, the following plot is created:</p>\n<p><img alt=\"CD Diagram\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5f27269d99f7a8950fcbd6ceb0e0c85a0efdcb43/6578616d706c65732f63645f6469616772616d2e706e67\"></p>\n<p>To further support reporting in scholarly article, Autorank can also generate a latex table with the relevant results.</p>\n<pre><span class=\"n\">latex_table</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>\\begin{table}[h]\n\\centering\n\\begin{tabular}{lrlllll}\n\\toprule\n{} &amp;    MR &amp;   MED &amp;   MAD &amp;              CI &amp; $\\delta$ &amp;   Magnitude \\\\\n\\midrule\npop\\_5 &amp; 2.180 &amp; 0.912 &amp; 0.130 &amp;  [0.692, 1.000] &amp;     0.000 &amp;  negligible \\\\\npop\\_4 &amp; 2.290 &amp; 0.910 &amp; 0.133 &amp;  [0.654, 1.000] &amp;    -0.024 &amp;  negligible \\\\\npop\\_3 &amp; 2.470 &amp; 0.858 &amp; 0.210 &amp;  [0.574, 1.000] &amp;     0.136 &amp;  negligible \\\\\npop\\_2 &amp; 3.950 &amp; 0.505 &amp; 0.334 &amp;  [0.227, 0.726] &amp;     0.642 &amp;       large \\\\\npop\\_1 &amp; 4.710 &amp; 0.314 &amp; 0.247 &amp;  [0.149, 0.547] &amp;     0.852 &amp;       large \\\\\npop\\_0 &amp; 5.400 &amp; 0.130 &amp; 0.192 &amp;  [0.000, 0.349] &amp;     0.919 &amp;       large \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Summary of populations}\n\\label{tbl:stat_results}\n\\end{table}\n</code></pre>\n<p>The rendered table looks like this (may change depending on the class of the document).</p>\n<p><img alt=\"Table\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/780f8f8d3697fe464b523c9f0072b81b57c88ae0/6578616d706c65732f7461626c652e706e67\"></p>\n<h2>Creating a Local Developer Environment</h2>\n<p>If you want to modify the code of autorank, we recommend that you setup a local development environment with a\nvirtual environment as follows.</p>\n<pre><code>git clone https://github.com/sherbold/autorank\ncd autorank\npython3 -m venv .\nsource bin/activate\npip install .\n</code></pre>\n<p>You can run the tests to check if everything works.</p>\n<pre><code>python -m unittest\n</code></pre>\n<h2>Contributing</h2>\n<p>Contributions to Autorank are welcome.</p>\n<ul>\n<li>Just file an <a href=\"\" rel=\"nofollow\">Issue</a> to ask questions, report bugs, or request new features.</li>\n<li>Pull requests via GitHub are also welcome.</li>\n</ul>\n<p>Potential contributions include more detailed report generation or the extension of Autorank to more types of data,\ne.g., independent populations, or paired populations with unequal sample sizes.</p>\n<h2>License</h2>\n<p>Autorank is published under the Apache 2.0 Licence.</p>\n\n          </div>"}, "last_serial": 7017282, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "0dd7f6a6001ecd0b95f7c7fdb20a58c1", "sha256": "f78af165fd3b72177fe84ade4658c77130d9ec272524b02f19396cafddc9d6f8"}, "downloads": -1, "filename": "autorank-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0dd7f6a6001ecd0b95f7c7fdb20a58c1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10935, "upload_time": "2020-01-06T09:07:05", "upload_time_iso_8601": "2020-01-06T09:07:05.075940Z", "url": "https://files.pythonhosted.org/packages/24/43/7ca3197baae4bf2a863bc36257d2698091c79fee0668e4e07f0d4ae2959d/autorank-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "337f537eb7ca9d8cdf9a964602d6c815", "sha256": "bfcecb64d1199dadcf9429ff064488064a5d30a4f3390b5f0d02789f774ee6bc"}, "downloads": -1, "filename": "autorank-0.1.0.tar.gz", "has_sig": false, "md5_digest": "337f537eb7ca9d8cdf9a964602d6c815", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7254, "upload_time": "2020-01-06T09:07:07", "upload_time_iso_8601": "2020-01-06T09:07:07.366987Z", "url": "https://files.pythonhosted.org/packages/4f/fa/9a064749d4e9513fba70f63cd0d0b0cc4abaad514f125ee80bc27a54feaf/autorank-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "06c3d375b0d1910034ff2b77d142064f", "sha256": "4d5af9634f9e267714bc117716a662829e2f31dbed1f6731baa9df5a316761f9"}, "downloads": -1, "filename": "autorank-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "06c3d375b0d1910034ff2b77d142064f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15023, "upload_time": "2020-01-10T15:34:01", "upload_time_iso_8601": "2020-01-10T15:34:01.671268Z", "url": "https://files.pythonhosted.org/packages/ea/73/8bf0732e3dae47e2e64ad286b5ce9f7eb1cbee38cc88db2df997a79bebc5/autorank-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c345d742979d011f1bafe57e48f3b7b0", "sha256": "13dcd2d0f91b06af91788b13e149b31be1619af9fa77673705a1834ffe35acd1"}, "downloads": -1, "filename": "autorank-0.2.0.tar.gz", "has_sig": false, "md5_digest": "c345d742979d011f1bafe57e48f3b7b0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12007, "upload_time": "2020-01-10T15:34:03", "upload_time_iso_8601": "2020-01-10T15:34:03.055845Z", "url": "https://files.pythonhosted.org/packages/a5/88/c4c193f6cb6dd661397e35087a9bb4d6c946ebb2e830f9e0820e4256b080/autorank-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "56a51c3e49c53788b6c563384b1432f6", "sha256": "b06b28cf32fa0f38bf17a0a9fb27525e423839ec2ee0cad0189fa58c175e9b6c"}, "downloads": -1, "filename": "autorank-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "56a51c3e49c53788b6c563384b1432f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 21935, "upload_time": "2020-01-18T20:30:11", "upload_time_iso_8601": "2020-01-18T20:30:11.046428Z", "url": "https://files.pythonhosted.org/packages/58/a7/4bb7be33cd6a1f855b094a91d6a21903d58cba78736af239f9f17f5c1787/autorank-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8aa85bb88a7de385e004af2b137f4857", "sha256": "14b844da53ebc137614a20728e4a6588fe9b5467ad2e6d02db2adaca1eb7998d"}, "downloads": -1, "filename": "autorank-0.3.0.tar.gz", "has_sig": false, "md5_digest": "8aa85bb88a7de385e004af2b137f4857", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16809, "upload_time": "2020-01-18T20:30:12", "upload_time_iso_8601": "2020-01-18T20:30:12.452114Z", "url": "https://files.pythonhosted.org/packages/cc/81/015541f78758a66a536778f9e5b418c8ef72b2e62290fd0e3d8fb7f72a0e/autorank-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "442514b6b3b70fc73c39d93d8e79ec4e", "sha256": "89449725d9e88a403ddff1e5918af5b7f85db60b49c43a2cdb625d1c30fe8de4"}, "downloads": -1, "filename": "autorank-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "442514b6b3b70fc73c39d93d8e79ec4e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22826, "upload_time": "2020-01-20T08:43:52", "upload_time_iso_8601": "2020-01-20T08:43:52.917641Z", "url": "https://files.pythonhosted.org/packages/0c/7e/df050710c58dcbe35bd986260c02693e1d7aa1c28b0d559a7e986f6eff62/autorank-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d159b12735eb319a3621a1f3787835b", "sha256": "fb2cc453ca30e632dd048b7edb53443521792f1b6941f8fbd5c7b0ae12443238"}, "downloads": -1, "filename": "autorank-0.3.1.tar.gz", "has_sig": false, "md5_digest": "3d159b12735eb319a3621a1f3787835b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21603, "upload_time": "2020-01-20T08:43:54", "upload_time_iso_8601": "2020-01-20T08:43:54.062783Z", "url": "https://files.pythonhosted.org/packages/f1/f8/0342ae3573548ea7856186c2e675758105202e0e00681e98f19ef990329e/autorank-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "f3a1ba585e2e6372a12ad602be0e37f7", "sha256": "d4b8e5baca8420436607cf51aea83091224f3e426c1bb8804acf39d5fd04dce3"}, "downloads": -1, "filename": "autorank-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f3a1ba585e2e6372a12ad602be0e37f7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23189, "upload_time": "2020-02-05T15:13:25", "upload_time_iso_8601": "2020-02-05T15:13:25.620283Z", "url": "https://files.pythonhosted.org/packages/da/d0/e07e979ce990b11b084d30f15782aaa55879e6d4cd02acb5eb55aa9fcee7/autorank-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6682265567fa81abf4d3a0510dce07e", "sha256": "8aa5a1b922f26a8b3c2fc3621dbfa4914da9b26865c0ac8283cb493541c6a1b1"}, "downloads": -1, "filename": "autorank-0.3.2.tar.gz", "has_sig": false, "md5_digest": "a6682265567fa81abf4d3a0510dce07e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24719, "upload_time": "2020-02-05T15:13:26", "upload_time_iso_8601": "2020-02-05T15:13:26.665980Z", "url": "https://files.pythonhosted.org/packages/66/f4/dcf291b476aafdb67c2e5bfd09d7cb9714b15da2bd8c9d6b70e59a043003/autorank-0.3.2.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "4c35c02c2a3b4f2219a039688b08396f", "sha256": "6ae2627e8df4c942a5f81dd5f3d8f0084a90ce8311d92cfd76166848a7008b8f"}, "downloads": -1, "filename": "autorank-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "4c35c02c2a3b4f2219a039688b08396f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23187, "upload_time": "2020-02-17T13:46:39", "upload_time_iso_8601": "2020-02-17T13:46:39.320623Z", "url": "https://files.pythonhosted.org/packages/41/6f/a33f71c6fc26b874c30011bfd390d9345b8395f4824929f833728d831f9e/autorank-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bcb638737594b66f1fc0f90f8befca1e", "sha256": "1c524dc8faf150cc19711ebb7d215085280cbe5ecfa96638faf0a889c1c89498"}, "downloads": -1, "filename": "autorank-1.0.0.tar.gz", "has_sig": false, "md5_digest": "bcb638737594b66f1fc0f90f8befca1e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18081, "upload_time": "2020-02-17T13:46:40", "upload_time_iso_8601": "2020-02-17T13:46:40.349894Z", "url": "https://files.pythonhosted.org/packages/c8/34/85cc97b008b92239f4af6b63ca9db912830974a30598a9f8bbd2bec813a3/autorank-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "2874ba88f53b90fa9ae1e66e74d276b6", "sha256": "e55416350762769780e4248b193972d28bd5a700622b3772630d6c5ec6fb2602"}, "downloads": -1, "filename": "autorank-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2874ba88f53b90fa9ae1e66e74d276b6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23750, "upload_time": "2020-04-14T13:52:46", "upload_time_iso_8601": "2020-04-14T13:52:46.351150Z", "url": "https://files.pythonhosted.org/packages/92/8b/0104e5c37e5f5b2c569272d9bcae30efcbfdb3c0875937a251486cd98eb6/autorank-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "89d2b3e8ccae90169c4651395b6c6b9e", "sha256": "fa6611c26631e2ad9f136c4d56355b83da140aa705085d6277282c44e504a6cd"}, "downloads": -1, "filename": "autorank-1.0.1.tar.gz", "has_sig": false, "md5_digest": "89d2b3e8ccae90169c4651395b6c6b9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18128, "upload_time": "2020-04-14T13:52:47", "upload_time_iso_8601": "2020-04-14T13:52:47.258299Z", "url": "https://files.pythonhosted.org/packages/ff/c9/01911212ab84d4ab94ad5bc4b90b29bb932141784cca1432c95add03f4f1/autorank-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2874ba88f53b90fa9ae1e66e74d276b6", "sha256": "e55416350762769780e4248b193972d28bd5a700622b3772630d6c5ec6fb2602"}, "downloads": -1, "filename": "autorank-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2874ba88f53b90fa9ae1e66e74d276b6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23750, "upload_time": "2020-04-14T13:52:46", "upload_time_iso_8601": "2020-04-14T13:52:46.351150Z", "url": "https://files.pythonhosted.org/packages/92/8b/0104e5c37e5f5b2c569272d9bcae30efcbfdb3c0875937a251486cd98eb6/autorank-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "89d2b3e8ccae90169c4651395b6c6b9e", "sha256": "fa6611c26631e2ad9f136c4d56355b83da140aa705085d6277282c44e504a6cd"}, "downloads": -1, "filename": "autorank-1.0.1.tar.gz", "has_sig": false, "md5_digest": "89d2b3e8ccae90169c4651395b6c6b9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18128, "upload_time": "2020-04-14T13:52:47", "upload_time_iso_8601": "2020-04-14T13:52:47.258299Z", "url": "https://files.pythonhosted.org/packages/ff/c9/01911212ab84d4ab94ad5bc4b90b29bb932141784cca1432c95add03f4f1/autorank-1.0.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:10 2020"}