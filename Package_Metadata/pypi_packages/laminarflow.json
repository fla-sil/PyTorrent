{"info": {"author": "Elliot Waite", "author_email": "elliot@elliotwaite.com", "bugtrack_url": null, "classifiers": ["Development Status :: 1 - Planning", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# LaminarFlow\n\nStreamline your TensorFlow workflow.\n\n## Installation\n\n```\npip install laminarflow\n```\n\n## Usage\n\n#### TFRecord Datasets\n\nLaminarFlow has two classes for writing to and reading from TFRecord datasets, `DatasetWriter` and `DatasetReader`.\n\nWhen creating your datasets with `DatasetWriter`, you can pass in raw Python or Numpy data, and it will automatically get converted into TensorFlow Examples or SequenceExamples and be written to a TFRecord file.\n\nThen when reading from the TFRecord file, `DatasetReader` takes care of creating the input pipeline that will parse your stored Examples or SequenceExamples, prepare them as needed (batching, padding, shuffling, etc.), then pass them to your TensorFlow Estimator, implementing the recommended best practices as outlined in TensorFlow's [Input Pipline Performance Guide](https://www.tensorflow.org/performance/datasets_performance).\n\nTo demonstrate, we'll create some datasets.\n\n```python\nimport laminarflow as lf\n\ntrain_writer = lf.DatasetWriter('data/train.tfrecord')\ntest_writer = lf.DatasetWriter('data/test.tfrecord')\n\ntrain_writer.write({\n  'input': [3.1, 4.1, 5.9],\n  'label': 2\n})\n\ntrain_writer.write({\n  'input': [2.7, 1.8, 2.8],\n  'label': 1\n})\n\ntest_writer.write({\n  'input': [0.1, 1.2, 3.5],\n  'label': 8\n})\n\ntrain_writer.close()\ntest_writer.close()\n```\nWe create a `DatasetWriter`, then call the `write` method on it for each TensorFlow Example or SequenceExample we want to add to the dataset. When we call the `write` method, we pass in a dictionary where the keys are the feature names and the values are the feature values. The values can be Numpy arrays or any values that can be converted into Numpy arrays, such as Python ints, floats, or lists of ints or floats. The shape of the values can be multidimensional, but must be the same between Examples. Creating SequenceExamples, which support variable length data, is discussed below.\n\nWhen we are done writing data with a Writer, we call the `close()` method on it.\n\nThe data will be written to a TFRecord file and the shapes and data types of your features will be stored in a separate metadata JSON file, which will have the same filename as the TFRecord file, except the extension will be changed to '.json'.\n\n```\ndata/\n\u251c\u2500\u2500 test.json\n\u251c\u2500\u2500 test.tfrecord\n\u251c\u2500\u2500 train.json\n\u2514\u2500\u2500 train.tfrecord\n```\n\nWe can then train a model on our datasets.\n\n```python\ntrain_dataset = lf.DatasetReader('data/train.tfrecord')\ntest_dataset = lf.DatasetReader('data/test.tfrecord')\n\nestimator = tf.estimator.Estimator(\n  model_fn=model_fn,\n  model_dir=MODEL_DIR,\n  params=PARAMS)\n\ntrain_spec = tf.estimator.TrainSpec(\n    input_fn=train_dataset.input_fn,\n    max_steps=1000)\n\neval_spec = tf.estimator.EvalSpec(\n    input_fn=test_dataset.input_fn)\n\ntf.estimator.train_and_evaluate(\n    estimator=estimator,\n    train_spec=train_spec,\n    eval_spec=eval_spec)\n```\n\nCalling `lf.DatasetReader('data/train.tfrecord')` creates a dataset using the TFRecord file and its corresponding metadata JSON file. The path to the metadata JSON file `data/train.json` is inferred from the TFRecord path.\n\nThe created dataset has an `input_fn` method that you can pass in as the input function to a TensorFlow Estimator. The `input_fn` method automatically creates the input pipeline for your dataset.\n\nFor a more complete example of creating datasets, training a model, and making predictions with that model, check out: [xor.py](examples/xor.py)\n\n#### Using a `with` Statement\n\nA `DatasetWriter` can also be created using a `with` statement, in which case the `close()` method does not need to be called.\n\n```python\nwith lf.DatasetWriter('data/train.tfrecord') as train_writer:\n  train_writer.write({\n    'input': [1.4, 1.4, 2.1],\n    'label': 3\n  })\n```\n\n#### SequenceExamples\n\nThe default behavior of the `write` method is to write a TensorFlow Example. To write a SequenceExample, instead of passing in features to the first parameter of the `write` method, pass in features using the `context_features` and `sequence_features` parameters.\n\n```python\ntrain_writer.write(\n  context_features={\n    'category': 7\n  },\n  sequence_features={\n    'inputs': [[1.4, 0.0], [1.4, 0.0], [1.4, 0.0]],\n    'labels': [3, 5, 3]\n  })\n\ntrain_writer.write(\n  context_features={\n    'category': 5\n  },\n  sequence_features={\n    'inputs': [[1.4, 0.0], [1.4, 0.0]],\n    'labels': [3, 5]\n  })\n```\n\nPassing in `context_features` is optional, but if used, their values must have the same shape between SequenceExamples, similar to Example features.\n\nThe shape of the `sequence_features` values must have a rank of at least 1. The length of the first dimension must be the same for all `sequence_features` within a SequenceExample, but can vary between SequenceExamples. And the lengths of the rest of the dimensions can vary between features, but must be the same between SequenceExamples.\n\nWhen a batch of SequenceExamples is created, any sequences that are shorter than the longest sequence will be padded with zeros.\n\nThe length of each sequence will be extracted from the data as one of the steps in the input pipeline when reading from the dataset. The lengths of the sequences will be made available as one of the feature values passed into the model_fn, `features['lengths']`. It will be a batch size length list of ints, that are the lengths of each of the sequences in the batch before that sequence was possibly padded with zeros.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/elliotwaite/laminarflow", "keywords": "laminarflow laminar tensorflow tensor tfrecord tfrecords ml machine learning ai artificial intelligence deep neural network networks", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "laminarflow", "package_url": "https://pypi.org/project/laminarflow/", "platform": "", "project_url": "https://pypi.org/project/laminarflow/", "project_urls": {"Homepage": "https://github.com/elliotwaite/laminarflow"}, "release_url": "https://pypi.org/project/laminarflow/0.0.7/", "requires_dist": ["numpy (>=1.13.3)", "tensorflow (>=1.7.0)"], "requires_python": "", "summary": "Streamline your TensorFlow workflow.", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>LaminarFlow</h1>\n<p>Streamline your TensorFlow workflow.</p>\n<h2>Installation</h2>\n<pre><code>pip install laminarflow\n</code></pre>\n<h2>Usage</h2>\n<h4>TFRecord Datasets</h4>\n<p>LaminarFlow has two classes for writing to and reading from TFRecord datasets, <code>DatasetWriter</code> and <code>DatasetReader</code>.</p>\n<p>When creating your datasets with <code>DatasetWriter</code>, you can pass in raw Python or Numpy data, and it will automatically get converted into TensorFlow Examples or SequenceExamples and be written to a TFRecord file.</p>\n<p>Then when reading from the TFRecord file, <code>DatasetReader</code> takes care of creating the input pipeline that will parse your stored Examples or SequenceExamples, prepare them as needed (batching, padding, shuffling, etc.), then pass them to your TensorFlow Estimator, implementing the recommended best practices as outlined in TensorFlow's <a href=\"https://www.tensorflow.org/performance/datasets_performance\" rel=\"nofollow\">Input Pipline Performance Guide</a>.</p>\n<p>To demonstrate, we'll create some datasets.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">laminarflow</span> <span class=\"k\">as</span> <span class=\"nn\">lf</span>\n\n<span class=\"n\">train_writer</span> <span class=\"o\">=</span> <span class=\"n\">lf</span><span class=\"o\">.</span><span class=\"n\">DatasetWriter</span><span class=\"p\">(</span><span class=\"s1\">'data/train.tfrecord'</span><span class=\"p\">)</span>\n<span class=\"n\">test_writer</span> <span class=\"o\">=</span> <span class=\"n\">lf</span><span class=\"o\">.</span><span class=\"n\">DatasetWriter</span><span class=\"p\">(</span><span class=\"s1\">'data/test.tfrecord'</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">({</span>\n  <span class=\"s1\">'input'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">3.1</span><span class=\"p\">,</span> <span class=\"mf\">4.1</span><span class=\"p\">,</span> <span class=\"mf\">5.9</span><span class=\"p\">],</span>\n  <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"mi\">2</span>\n<span class=\"p\">})</span>\n\n<span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">({</span>\n  <span class=\"s1\">'input'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">2.7</span><span class=\"p\">,</span> <span class=\"mf\">1.8</span><span class=\"p\">,</span> <span class=\"mf\">2.8</span><span class=\"p\">],</span>\n  <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"mi\">1</span>\n<span class=\"p\">})</span>\n\n<span class=\"n\">test_writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">({</span>\n  <span class=\"s1\">'input'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"mf\">1.2</span><span class=\"p\">,</span> <span class=\"mf\">3.5</span><span class=\"p\">],</span>\n  <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"mi\">8</span>\n<span class=\"p\">})</span>\n\n<span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n<span class=\"n\">test_writer</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n</pre>\n<p>We create a <code>DatasetWriter</code>, then call the <code>write</code> method on it for each TensorFlow Example or SequenceExample we want to add to the dataset. When we call the <code>write</code> method, we pass in a dictionary where the keys are the feature names and the values are the feature values. The values can be Numpy arrays or any values that can be converted into Numpy arrays, such as Python ints, floats, or lists of ints or floats. The shape of the values can be multidimensional, but must be the same between Examples. Creating SequenceExamples, which support variable length data, is discussed below.</p>\n<p>When we are done writing data with a Writer, we call the <code>close()</code> method on it.</p>\n<p>The data will be written to a TFRecord file and the shapes and data types of your features will be stored in a separate metadata JSON file, which will have the same filename as the TFRecord file, except the extension will be changed to '.json'.</p>\n<pre><code>data/\n\u251c\u2500\u2500 test.json\n\u251c\u2500\u2500 test.tfrecord\n\u251c\u2500\u2500 train.json\n\u2514\u2500\u2500 train.tfrecord\n</code></pre>\n<p>We can then train a model on our datasets.</p>\n<pre><span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">lf</span><span class=\"o\">.</span><span class=\"n\">DatasetReader</span><span class=\"p\">(</span><span class=\"s1\">'data/train.tfrecord'</span><span class=\"p\">)</span>\n<span class=\"n\">test_dataset</span> <span class=\"o\">=</span> <span class=\"n\">lf</span><span class=\"o\">.</span><span class=\"n\">DatasetReader</span><span class=\"p\">(</span><span class=\"s1\">'data/test.tfrecord'</span><span class=\"p\">)</span>\n\n<span class=\"n\">estimator</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">estimator</span><span class=\"o\">.</span><span class=\"n\">Estimator</span><span class=\"p\">(</span>\n  <span class=\"n\">model_fn</span><span class=\"o\">=</span><span class=\"n\">model_fn</span><span class=\"p\">,</span>\n  <span class=\"n\">model_dir</span><span class=\"o\">=</span><span class=\"n\">MODEL_DIR</span><span class=\"p\">,</span>\n  <span class=\"n\">params</span><span class=\"o\">=</span><span class=\"n\">PARAMS</span><span class=\"p\">)</span>\n\n<span class=\"n\">train_spec</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">estimator</span><span class=\"o\">.</span><span class=\"n\">TrainSpec</span><span class=\"p\">(</span>\n    <span class=\"n\">input_fn</span><span class=\"o\">=</span><span class=\"n\">train_dataset</span><span class=\"o\">.</span><span class=\"n\">input_fn</span><span class=\"p\">,</span>\n    <span class=\"n\">max_steps</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n\n<span class=\"n\">eval_spec</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">estimator</span><span class=\"o\">.</span><span class=\"n\">EvalSpec</span><span class=\"p\">(</span>\n    <span class=\"n\">input_fn</span><span class=\"o\">=</span><span class=\"n\">test_dataset</span><span class=\"o\">.</span><span class=\"n\">input_fn</span><span class=\"p\">)</span>\n\n<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">estimator</span><span class=\"o\">.</span><span class=\"n\">train_and_evaluate</span><span class=\"p\">(</span>\n    <span class=\"n\">estimator</span><span class=\"o\">=</span><span class=\"n\">estimator</span><span class=\"p\">,</span>\n    <span class=\"n\">train_spec</span><span class=\"o\">=</span><span class=\"n\">train_spec</span><span class=\"p\">,</span>\n    <span class=\"n\">eval_spec</span><span class=\"o\">=</span><span class=\"n\">eval_spec</span><span class=\"p\">)</span>\n</pre>\n<p>Calling <code>lf.DatasetReader('data/train.tfrecord')</code> creates a dataset using the TFRecord file and its corresponding metadata JSON file. The path to the metadata JSON file <code>data/train.json</code> is inferred from the TFRecord path.</p>\n<p>The created dataset has an <code>input_fn</code> method that you can pass in as the input function to a TensorFlow Estimator. The <code>input_fn</code> method automatically creates the input pipeline for your dataset.</p>\n<p>For a more complete example of creating datasets, training a model, and making predictions with that model, check out: <a href=\"examples/xor.py\" rel=\"nofollow\">xor.py</a></p>\n<h4>Using a <code>with</code> Statement</h4>\n<p>A <code>DatasetWriter</code> can also be created using a <code>with</code> statement, in which case the <code>close()</code> method does not need to be called.</p>\n<pre><span class=\"k\">with</span> <span class=\"n\">lf</span><span class=\"o\">.</span><span class=\"n\">DatasetWriter</span><span class=\"p\">(</span><span class=\"s1\">'data/train.tfrecord'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">train_writer</span><span class=\"p\">:</span>\n  <span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">({</span>\n    <span class=\"s1\">'input'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">2.1</span><span class=\"p\">],</span>\n    <span class=\"s1\">'label'</span><span class=\"p\">:</span> <span class=\"mi\">3</span>\n  <span class=\"p\">})</span>\n</pre>\n<h4>SequenceExamples</h4>\n<p>The default behavior of the <code>write</code> method is to write a TensorFlow Example. To write a SequenceExample, instead of passing in features to the first parameter of the <code>write</code> method, pass in features using the <code>context_features</code> and <code>sequence_features</code> parameters.</p>\n<pre><span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span>\n  <span class=\"n\">context_features</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'category'</span><span class=\"p\">:</span> <span class=\"mi\">7</span>\n  <span class=\"p\">},</span>\n  <span class=\"n\">sequence_features</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'inputs'</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">]],</span>\n    <span class=\"s1\">'labels'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">]</span>\n  <span class=\"p\">})</span>\n\n<span class=\"n\">train_writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span>\n  <span class=\"n\">context_features</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'category'</span><span class=\"p\">:</span> <span class=\"mi\">5</span>\n  <span class=\"p\">},</span>\n  <span class=\"n\">sequence_features</span><span class=\"o\">=</span><span class=\"p\">{</span>\n    <span class=\"s1\">'inputs'</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mf\">1.4</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">]],</span>\n    <span class=\"s1\">'labels'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">]</span>\n  <span class=\"p\">})</span>\n</pre>\n<p>Passing in <code>context_features</code> is optional, but if used, their values must have the same shape between SequenceExamples, similar to Example features.</p>\n<p>The shape of the <code>sequence_features</code> values must have a rank of at least 1. The length of the first dimension must be the same for all <code>sequence_features</code> within a SequenceExample, but can vary between SequenceExamples. And the lengths of the rest of the dimensions can vary between features, but must be the same between SequenceExamples.</p>\n<p>When a batch of SequenceExamples is created, any sequences that are shorter than the longest sequence will be padded with zeros.</p>\n<p>The length of each sequence will be extracted from the data as one of the steps in the input pipeline when reading from the dataset. The lengths of the sequences will be made available as one of the feature values passed into the model_fn, <code>features['lengths']</code>. It will be a batch size length list of ints, that are the lengths of each of the sequences in the batch before that sequence was possibly padded with zeros.</p>\n\n          </div>"}, "last_serial": 4006048, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "6752fe7513df45899be92fb87b099b3b", "sha256": "8e37d968c5103920a5c3dbdb82f5ad4801e84afcb710589da215b8c8e45bbc87"}, "downloads": -1, "filename": "laminarflow-0.0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "6752fe7513df45899be92fb87b099b3b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 1579, "upload_time": "2018-06-22T10:57:39", "upload_time_iso_8601": "2018-06-22T10:57:39.327240Z", "url": "https://files.pythonhosted.org/packages/a2/bc/5e7f771165044f3fcb3ec6b576f50b2e85423a70b126b91221283d406a48/laminarflow-0.0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "acf490c48af763be2252e0dd73e77084", "sha256": "3069c1c3b3a507c6b63e7238cde82ab5464b07fa287e0f29bc47341b7e06b413"}, "downloads": -1, "filename": "laminarflow-0.0.1.tar.gz", "has_sig": false, "md5_digest": "acf490c48af763be2252e0dd73e77084", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1260, "upload_time": "2018-06-22T10:57:40", "upload_time_iso_8601": "2018-06-22T10:57:40.433877Z", "url": "https://files.pythonhosted.org/packages/bd/f3/fd1cb3a95b3a13191b974f427f31a0f3a0a633ec169c52f498a591dec30b/laminarflow-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "533763a9723650267c11f90fa3a65d84", "sha256": "06316d3c614a60c86b74142be48c9537b846f7ad8a320877a3675744edbd5b1e"}, "downloads": -1, "filename": "laminarflow-0.0.2-py2-none-any.whl", "has_sig": false, "md5_digest": "533763a9723650267c11f90fa3a65d84", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 1585, "upload_time": "2018-06-22T11:05:47", "upload_time_iso_8601": "2018-06-22T11:05:47.118508Z", "url": "https://files.pythonhosted.org/packages/74/77/ae8d20d458e7eba40102404686e64d844dd95da839d76293160f67e6d707/laminarflow-0.0.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4261d6dac7c66d34faad701f51c22916", "sha256": "4c2ec53149b6157cbdf14b1edffc1cb87a73eca0cf024eab32a3f06bcb1c2ea5"}, "downloads": -1, "filename": "laminarflow-0.0.2.tar.gz", "has_sig": false, "md5_digest": "4261d6dac7c66d34faad701f51c22916", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1268, "upload_time": "2018-06-22T11:05:47", "upload_time_iso_8601": "2018-06-22T11:05:47.954290Z", "url": "https://files.pythonhosted.org/packages/66/90/61174e02dbf7f40deaf1b6178184898a58378b3f519a150a8fb5e3d75175/laminarflow-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "1b1bc67598cb32757716cb9530a6f5d3", "sha256": "a4e7b6957749528c9ee0c590d4844af631904dce370484bbe76c976c00b7931d"}, "downloads": -1, "filename": "laminarflow-0.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1b1bc67598cb32757716cb9530a6f5d3", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6966, "upload_time": "2018-06-24T11:30:59", "upload_time_iso_8601": "2018-06-24T11:30:59.206533Z", "url": "https://files.pythonhosted.org/packages/ac/9c/281311cf023ff46b0afc4d6637407e87593b0fb4325eab5c02e36bf79b5b/laminarflow-0.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "22ac46296d34c78d09efac4c1e3117be", "sha256": "47477ff8281232b96eff81c0b1c399e6b73df6cb7134ab37f9dab8f2f2ce41ab"}, "downloads": -1, "filename": "laminarflow-0.0.3.tar.gz", "has_sig": false, "md5_digest": "22ac46296d34c78d09efac4c1e3117be", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6824, "upload_time": "2018-06-24T11:31:00", "upload_time_iso_8601": "2018-06-24T11:31:00.685948Z", "url": "https://files.pythonhosted.org/packages/28/58/8794d559b7dca3345f709714e2cba888bc7a3927f68d02c7910241f384fe/laminarflow-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "b7d87e717c9ae7b8145abefa04cf740f", "sha256": "197fda2c1a9ff31954a1cbfa8a51c1aa74480681695d986181b97424675156ac"}, "downloads": -1, "filename": "laminarflow-0.0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b7d87e717c9ae7b8145abefa04cf740f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 3344, "upload_time": "2018-06-27T04:36:00", "upload_time_iso_8601": "2018-06-27T04:36:00.529056Z", "url": "https://files.pythonhosted.org/packages/c4/9d/90680b088f91f5c1fed9ffa217fc90142084392de9e8aaf4e40493cd043b/laminarflow-0.0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "809913e1559d5ac8554f5817b56b952c", "sha256": "9f985930482b66101a9e62dd736fc92470c0c9b6aad79eb0dc35b2fe1c82a506"}, "downloads": -1, "filename": "laminarflow-0.0.4.tar.gz", "has_sig": false, "md5_digest": "809913e1559d5ac8554f5817b56b952c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3019, "upload_time": "2018-06-27T04:36:01", "upload_time_iso_8601": "2018-06-27T04:36:01.828957Z", "url": "https://files.pythonhosted.org/packages/26/fa/40f65bc8e5ca19c7e849527d624e5d36877c77626543d465de8d709c7dbb/laminarflow-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "bb8486b9eab724ba8f479227d3ccb6f2", "sha256": "4a12e64d32d4fea0fa435d14235f4994bf258d354a9b0a441540afc9520d7094"}, "downloads": -1, "filename": "laminarflow-0.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bb8486b9eab724ba8f479227d3ccb6f2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7576, "upload_time": "2018-06-27T04:56:21", "upload_time_iso_8601": "2018-06-27T04:56:21.054489Z", "url": "https://files.pythonhosted.org/packages/04/2d/4829f2fc1f5833c5b9785ffe1a69697f01af2f20566a05f05d5e497b4920/laminarflow-0.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "41c19bdad8c1d46c55d6144ba4a9ee83", "sha256": "7ca63657f1b5ae8c546870be432b77030639f7c9025fff7358493b38fc8e2a45"}, "downloads": -1, "filename": "laminarflow-0.0.5.tar.gz", "has_sig": false, "md5_digest": "41c19bdad8c1d46c55d6144ba4a9ee83", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7519, "upload_time": "2018-06-27T04:56:22", "upload_time_iso_8601": "2018-06-27T04:56:22.404289Z", "url": "https://files.pythonhosted.org/packages/a2/05/7b90e3a3e7a7588fb7e660a848972f476b2c8fb3c1c40096f72cd4943bc6/laminarflow-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "4827926b9128ad45433fd5f62b1e0a5a", "sha256": "c3a256baf7e5779d1272317e1e0c7c69e62dad33ee649f517adc33d50f9717c9"}, "downloads": -1, "filename": "laminarflow-0.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4827926b9128ad45433fd5f62b1e0a5a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7576, "upload_time": "2018-06-27T05:00:30", "upload_time_iso_8601": "2018-06-27T05:00:30.747504Z", "url": "https://files.pythonhosted.org/packages/fa/ae/03dc0a96226b57f0a2c6184679d4bdbddf6664efc6c443fc862db7608e5a/laminarflow-0.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "30b0644b56d95265f0f90056512df4aa", "sha256": "c28a98e7696f708df239aebf8be071e79d1d58f006d9438111c3cf53143cbc3e"}, "downloads": -1, "filename": "laminarflow-0.0.6.tar.gz", "has_sig": false, "md5_digest": "30b0644b56d95265f0f90056512df4aa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7502, "upload_time": "2018-06-27T05:00:32", "upload_time_iso_8601": "2018-06-27T05:00:32.218180Z", "url": "https://files.pythonhosted.org/packages/67/8b/2d5af7c5e3981883724f89339b54e1d16f058673f5939697f4a0f3ff2207/laminarflow-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "c9bf1dda4a33957acd6d28cd098eb8fb", "sha256": "4a0347eab9c67fb426e6b8439e00d5bbaa1c4fb851edb50afccdf4e44da0fc9f"}, "downloads": -1, "filename": "laminarflow-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c9bf1dda4a33957acd6d28cd098eb8fb", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7575, "upload_time": "2018-06-27T05:04:31", "upload_time_iso_8601": "2018-06-27T05:04:31.803288Z", "url": "https://files.pythonhosted.org/packages/54/80/7da0d5f5731a5e13dcdd394c57b7656dc3422d62590e161677f30e6477e3/laminarflow-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0b980a73981897c1275b7a6f0ce3011b", "sha256": "4358074a1df00c78bce151a3a7f54bdd04702f9ede1d757b419c311810273ba4"}, "downloads": -1, "filename": "laminarflow-0.0.7.tar.gz", "has_sig": false, "md5_digest": "0b980a73981897c1275b7a6f0ce3011b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7497, "upload_time": "2018-06-27T05:04:33", "upload_time_iso_8601": "2018-06-27T05:04:33.277406Z", "url": "https://files.pythonhosted.org/packages/4f/96/67e6a1a4ee55ec7bcc2f41509a500a6af5905d964762881f357929dd0f6f/laminarflow-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c9bf1dda4a33957acd6d28cd098eb8fb", "sha256": "4a0347eab9c67fb426e6b8439e00d5bbaa1c4fb851edb50afccdf4e44da0fc9f"}, "downloads": -1, "filename": "laminarflow-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c9bf1dda4a33957acd6d28cd098eb8fb", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 7575, "upload_time": "2018-06-27T05:04:31", "upload_time_iso_8601": "2018-06-27T05:04:31.803288Z", "url": "https://files.pythonhosted.org/packages/54/80/7da0d5f5731a5e13dcdd394c57b7656dc3422d62590e161677f30e6477e3/laminarflow-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0b980a73981897c1275b7a6f0ce3011b", "sha256": "4358074a1df00c78bce151a3a7f54bdd04702f9ede1d757b419c311810273ba4"}, "downloads": -1, "filename": "laminarflow-0.0.7.tar.gz", "has_sig": false, "md5_digest": "0b980a73981897c1275b7a6f0ce3011b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7497, "upload_time": "2018-06-27T05:04:33", "upload_time_iso_8601": "2018-06-27T05:04:33.277406Z", "url": "https://files.pythonhosted.org/packages/4f/96/67e6a1a4ee55ec7bcc2f41509a500a6af5905d964762881f357929dd0f6f/laminarflow-0.0.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:48:01 2020"}