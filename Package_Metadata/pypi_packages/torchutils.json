{"info": {"author": "Anjandeep Singh Sahni", "author_email": "sahni.anjandeep@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "==========\nTorchUtils\n==========\n\n.. image:: https://img.shields.io/pypi/v/torchutils?color=success\n    :target: https://img.shields.io/pypi/v/torchutils\n    :alt: PyPI\n\n.. image:: https://travis-ci.org/anjandeepsahni/torchutils.svg?branch=master\n    :target: https://travis-ci.org/anjandeepsahni/torchutils\n    :alt: Build Status\n\n.. image:: https://codecov.io/gh/anjandeepsahni/torchutils/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/anjandeepsahni/torchutils\n    :alt: Code Coverage\n\n.. image:: https://img.shields.io/github/release-date/anjandeepsahni/torchutils?color=informational&label=release%20date\n    :target: https://img.shields.io/github/release-date/anjandeepsahni/torchutils\n    :alt: Release Date\n\n.. image:: https://img.shields.io/github/license/anjandeepsahni/torchutils?color=informational\n    :target: https://img.shields.io/github/license/anjandeepsahni/torchutils\n    :alt: License\n\n.. image:: https://pepy.tech/badge/torchutils\n    :target: https://pepy.tech/badge/torchutils\n    :alt: Downloads\n\n|\n\n**TorchUtils** is a Python package providing helpful utility APIs for your\nPyTorch projects.\n\nFeatures\n--------\n\n* Save/load checkpoints_.\n* Calculate dataset statistics_ (mean, std, var). Also calculate and track running statistics of data.\n* Get/set `learning rate`_.\n* Track `evaluation metrics`_ such as accuracy, running loss, hamming loss.\n* Print `model summary`_. Supports: Linear/MLP, Convolution Network, Recurrent Network (RNN/LSTM/GRU), Recursive Network.\n* Calculate `model FLOPs`_.\n* Calculate total `model parameters`_.\n* Set `random seed`_.\n* Visualize `gradient flow`_ in your network.\n\nRequirements\n------------\n\n* PyTorch >= 1.0.0\n* Numpy >= 1.16.2\n* Matplotlib >= 3.0.3\n\nInstallation\n------------\n\nPyPi::\n\n    $ pip install torchutils\n\nConda::\n\n    $ conda install -c sahni torchutils\n\nDocumentation\n-------------\nDetailed API documentation is available here_.\n\n.. _here: https://anjandeepsahni.github.io/torchutils/readme.html\n\nExamples\n--------\n\n.. _checkpoints:\n\nCheckpoint:\n^^^^^^^^^^^\n\n.. code:: python\n\n    import torchvision\n    import torchutils as tu\n    import torch.optim as optim\n\n    model = torchvision.models.alexnet()\n    optimizer = optim.Adam(model.parameters())\n    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.1)\n    print('Original learning rate:', tu.get_lr(optimizer))\n\n    # load checkpoint\n    start_epoch = tu.load_checkpoint(model_path='.',\n                            ckpt_name='model_20190814-212442_e0_0.7531.pt',\n                            model=model, optimizer=optimizer,\n                            scheduler=scheduler)\n\n    print('Checkpoint learning rate:', tu.get_lr(optimizer))\n    print('Start from epoch:', start_epoch)\n\nOutput ::\n\n    Original learning rate: 0.001\n    Checkpoint learning rate: 0.1234\n    Start epoch: 1\n\n.. _statistics:\n\nStatistics:\n^^^^^^^^^^^\n\n.. code:: python\n\n    import torch\n    import torchutils as tu\n\n    # define your dataset and dataloader\n    dataset = MyDataset()\n    trainloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n                                              num_workers=1,\n                                              shuffle=False)\n\n    # get statistics\n    stats = tu.get_dataset_stats(trainloader, verbose=True)\n    print('Mean:', stats['mean'])\n    print('Std:', stats['std'])\n\nOutput ::\n\n    Calculating dataset stats...\n    Batch 100/100\n    Mean: tensor([10000.0098,  9999.9795,  9999.9893])\n    Std: tensor([0.9969, 1.0003, 0.9972])\n\n.. _`learning rate`:\n\nLearning Rate:\n^^^^^^^^^^^^^^\n\n.. code:: python\n\n    import torchvision\n    import torchutils as tu\n    import torch.optim as optim\n\n    model = torchvision.models.alexnet()\n    optimizer = optim.Adam(model.parameters())\n\n    # get learning rate\n    current_lr = tu.get_lr(optimizer)\n    print('Current learning rate:', current_lr)\n\n    # set learning rate\n    optimizer = tu.set_lr(optimizer, current_lr*0.1)\n    revised_lr = tu.get_lr(optimizer)\n    print('Revised learning rate:', revised_lr)\n\nOutput ::\n\n    Current learning rate: 0.001\n    Revised learning rate: 0.0001\n\n.. _`evaluation metrics`:\n\nEvaluation Metrics:\n^^^^^^^^^^^^^^^^^^^\n\n.. code:: python\n\n    import torch\n    import torch.nn as nn\n    import torch.optim as optim\n    import torchvision\n    import torchvision.transforms as transforms\n    import torchutils as tu\n\n    # define your network\n    model = MyNet()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters())\n    trainset = torchvision.datasets.MNIST(root='./data/', train=True,\n                                        download=True,\n                                        transform=transforms.ToTensor())\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=60,\n                                            shuffle=True, num_workers=2,\n                                            drop_last=True)\n    n_epochs = 1\n    model.train()\n    for epoch in range(n_epochs):\n        print('Epoch: %d/%d' % (epoch + 1, n_epochs))\n        # define loss tracker\n        loss_tracker = tu.RunningLoss()\n        for batch_idx, (data, target) in enumerate(trainloader):\n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = criterion(outputs, target)\n            # update loss tracker with latest loss\n            loss_tracker.update(loss.item())\n            loss.backward()\n            optimizer.step()\n            if batch_idx % 100 == 0:\n                # easily print latest and average loss\n                print(loss_tracker)\n\nOutput ::\n\n    Epoch: 1/1\n    Loss - Val: 2.2921 Avg: 2.2921\n    Loss - Val: 0.5084 Avg: 0.9639\n    Loss - Val: 0.6027 Avg: 0.6588\n    Loss - Val: 0.1817 Avg: 0.5255\n    Loss - Val: 0.1005 Avg: 0.4493\n    Loss - Val: 0.2982 Avg: 0.3984\n    Loss - Val: 0.3103 Avg: 0.3615\n    Loss - Val: 0.0940 Avg: 0.3296\n    Loss - Val: 0.0957 Avg: 0.3071\n    Loss - Val: 0.0229 Avg: 0.2875\n\n.. _`model summary`:\n\nModel Summary:\n^^^^^^^^^^^^^^\n\n.. code:: python\n\n    import torch\n    import torchvision\n    import torchutils as tu\n\n    model = torchvision.models.alexnet()\n    # easily print model summary\n    tu.get_model_summary(model, torch.rand((1, 3, 224, 224)))\n\nOutput ::\n\n    =========================================================================================\n    Layer                           Kernel             Output          Params           FLOPs\n    =========================================================================================\n    0_features.Conv2d_0         [3, 64, 11, 11]    [1, 64, 55, 55]       23,296    70,470,400\n    1_features.ReLU_1                         -    [1, 64, 55, 55]            0             0\n    2_features.MaxPool2d_2                    -    [1, 64, 27, 27]            0             0\n    3_features.Conv2d_3         [64, 192, 5, 5]   [1, 192, 27, 27]      307,392   224,088,768\n    4_features.ReLU_4                         -   [1, 192, 27, 27]            0             0\n    5_features.MaxPool2d_5                    -   [1, 192, 13, 13]            0             0\n    6_features.Conv2d_6        [192, 384, 3, 3]   [1, 384, 13, 13]      663,936   112,205,184\n    7_features.ReLU_7                         -   [1, 384, 13, 13]            0             0\n    8_features.Conv2d_8        [384, 256, 3, 3]   [1, 256, 13, 13]      884,992   149,563,648\n    9_features.ReLU_9                         -   [1, 256, 13, 13]            0             0\n    10_features.Conv2d_10      [256, 256, 3, 3]   [1, 256, 13, 13]      590,080    99,723,520\n    11_features.ReLU_11                       -   [1, 256, 13, 13]            0             0\n    12_features.MaxPool2d_12                  -     [1, 256, 6, 6]            0             0\n    13_classifier.Dropout_0                   -          [1, 9216]            0             0\n    14_classifier.Linear_1         [9216, 4096]          [1, 4096]   37,752,832    75,493,376\n    15_classifier.ReLU_2                      -          [1, 4096]            0             0\n    16_classifier.Dropout_3                   -          [1, 4096]            0             0\n    17_classifier.Linear_4         [4096, 4096]          [1, 4096]   16,781,312    33,550,336\n    18_classifier.ReLU_5                      -          [1, 4096]            0             0\n    19_classifier.Linear_6         [4096, 1000]          [1, 1000]    4,097,000     8,191,000\n    =========================================================================================\n    Total params: 61,100,840\n    Trainable params: 61,100,840\n    Non-trainable params: 0\n    Total FLOPs: 773,286,232 / 773.29 MFLOPs\n    -----------------------------------------------------------------------------------------\n    Input size (MB): 0.57\n    Forward/backward pass size (MB): 8.31\n    Params size (MB): 233.08\n    Estimated Total Size (MB): 241.96\n    =========================================================================================\n\n.. _`model FLOPs`:\n\nModel FLOPs:\n^^^^^^^^^^^^\n\n.. code:: python\n\n    import torch\n    import torchvision\n    import torchutils as tu\n\n    model = torchvision.models.alexnet()\n    # calculate model FLOPs\n    total_flops = tu.get_model_flops(model, torch.rand((1, 3, 224, 224)))\n    print('Total model FLOPs: {:,}'.format(total_flops))\n\nOutput ::\n\n    Total model FLOPs: 773,304,664\n\n.. _`model parameters`:\n\nModel Parameters:\n^^^^^^^^^^^^^^^^^\n\n.. code:: python\n\n    import torchvision\n    import torchutils as tu\n\n    model = torchvision.models.alexnet()\n    # calculate total model parameters\n    total_params = tu.get_model_param_count(model)\n    print('Total model params: {:,}'.format(total_params))\n\nOutput ::\n\n    Total model params: 61,100,840\n\n.. _`random seed`:\n\nRandom Seed:\n^^^^^^^^^^^^\n\n.. code:: python\n\n    import torchutils as tu\n\n    # set numpy, torch and cuda seed\n    tu.set_random_seed(2222)\n\n.. _`gradient flow`:\n\nGradient Flow:\n^^^^^^^^^^^^^^\n\n.. code:: python\n\n    import torch\n    import torchvision\n    import torchutils as tu\n\n    criterion = torch.nn.CrossEntropyLoss()\n    net = torchvision.models.alexnet(num_classes=10)\n    out = net(torch.rand(1, 3, 224, 224))\n    ground_truth = torch.randint(0, 10, (1, ))\n    loss = criterion(out, ground_truth)\n    loss.backward()\n\n    # save model gradient flow to image\n    tu.plot_gradients(net, './grad_figures/grad_01.png', plot_type='line')\n\nSaved File\n\n.. image:: https://raw.githubusercontent.com/anjandeepsahni/torchutils/master/docs/_static/example_gradient_flow.png\n    :alt: Example Gradient Flow \n\nLicense\n-------\nTorchUtils is distributed under the MIT license, see LICENSE.\n\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/anjandeepsahni/torchutils.git", "keywords": "machine-learning deep-learning pytorch neuralnetwork", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torchutils", "package_url": "https://pypi.org/project/torchutils/", "platform": "", "project_url": "https://pypi.org/project/torchutils/", "project_urls": {"Homepage": "https://github.com/anjandeepsahni/torchutils.git"}, "release_url": "https://pypi.org/project/torchutils/0.0.4/", "requires_dist": ["torch (>=1.0.0)", "numpy (>=1.16.2)", "matplotlib (>=3.0.3)"], "requires_python": "", "summary": "PyTorch utility APIs.", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://img.shields.io/pypi/v/torchutils\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1b422f3c90c4625c9378b076e24697dc24aa017d/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f746f7263687574696c733f636f6c6f723d73756363657373\"></a>\n<a href=\"https://travis-ci.org/anjandeepsahni/torchutils\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5370b31e1a57143d7e8ed98512de411bb63d9d56/68747470733a2f2f7472617669732d63692e6f72672f616e6a616e646565707361686e692f746f7263687574696c732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/anjandeepsahni/torchutils\" rel=\"nofollow\"><img alt=\"Code Coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d614046595dc0013fcd73fc592dc1ac7dcd5069c/68747470733a2f2f636f6465636f762e696f2f67682f616e6a616e646565707361686e692f746f7263687574696c732f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://img.shields.io/github/release-date/anjandeepsahni/torchutils\" rel=\"nofollow\"><img alt=\"Release Date\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dc1308258d7fd0a92a66d93f714b7d37d6821797/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652d646174652f616e6a616e646565707361686e692f746f7263687574696c733f636f6c6f723d696e666f726d6174696f6e616c266c6162656c3d72656c6561736525323064617465\"></a>\n<a href=\"https://img.shields.io/github/license/anjandeepsahni/torchutils\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5824e2f6f9021006fcfce83f426f74fc224e165e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616e6a616e646565707361686e692f746f7263687574696c733f636f6c6f723d696e666f726d6174696f6e616c\"></a>\n<a href=\"https://pepy.tech/badge/torchutils\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3320c83ee3ba8844a3b0fb569ca1dbd1b7c25381/68747470733a2f2f706570792e746563682f62616467652f746f7263687574696c73\"></a>\n<div>\n<div><br></div>\n</div>\n<p><strong>TorchUtils</strong> is a Python package providing helpful utility APIs for your\nPyTorch projects.</p>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>Save/load <a href=\"#checkpoints\" rel=\"nofollow\">checkpoints</a>.</li>\n<li>Calculate dataset <a href=\"#statistics\" rel=\"nofollow\">statistics</a> (mean, std, var). Also calculate and track running statistics of data.</li>\n<li>Get/set <a href=\"#learning-rate\" rel=\"nofollow\">learning rate</a>.</li>\n<li>Track <a href=\"#evaluation-metrics\" rel=\"nofollow\">evaluation metrics</a> such as accuracy, running loss, hamming loss.</li>\n<li>Print <a href=\"#model-summary\" rel=\"nofollow\">model summary</a>. Supports: Linear/MLP, Convolution Network, Recurrent Network (RNN/LSTM/GRU), Recursive Network.</li>\n<li>Calculate <a href=\"#model-flops\" rel=\"nofollow\">model FLOPs</a>.</li>\n<li>Calculate total <a href=\"#model-parameters\" rel=\"nofollow\">model parameters</a>.</li>\n<li>Set <a href=\"#random-seed\" rel=\"nofollow\">random seed</a>.</li>\n<li>Visualize <a href=\"#gradient-flow\" rel=\"nofollow\">gradient flow</a> in your network.</li>\n</ul>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<ul>\n<li>PyTorch &gt;= 1.0.0</li>\n<li>Numpy &gt;= 1.16.2</li>\n<li>Matplotlib &gt;= 3.0.3</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>PyPi:</p>\n<pre>$ pip install torchutils\n</pre>\n<p>Conda:</p>\n<pre>$ conda install -c sahni torchutils\n</pre>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>Detailed API documentation is available <a href=\"https://anjandeepsahni.github.io/torchutils/readme.html\" rel=\"nofollow\">here</a>.</p>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<div id=\"checkpoint\">\n<span id=\"checkpoints\"></span><h3>Checkpoint:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.optim</span> <span class=\"k\">as</span> <span class=\"nn\">optim</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">alexnet</span><span class=\"p\">()</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n<span class=\"n\">scheduler</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">lr_scheduler</span><span class=\"o\">.</span><span class=\"n\">ExponentialLR</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"mf\">0.1</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Original learning rate:'</span><span class=\"p\">,</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_lr</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># load checkpoint</span>\n<span class=\"n\">start_epoch</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">load_checkpoint</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"o\">=</span><span class=\"s1\">'.'</span><span class=\"p\">,</span>\n                        <span class=\"n\">ckpt_name</span><span class=\"o\">=</span><span class=\"s1\">'model_20190814-212442_e0_0.7531.pt'</span><span class=\"p\">,</span>\n                        <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">optimizer</span><span class=\"p\">,</span>\n                        <span class=\"n\">scheduler</span><span class=\"o\">=</span><span class=\"n\">scheduler</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Checkpoint learning rate:'</span><span class=\"p\">,</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_lr</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Start from epoch:'</span><span class=\"p\">,</span> <span class=\"n\">start_epoch</span><span class=\"p\">)</span>\n</pre>\n<p>Output</p>\n<pre>Original learning rate: 0.001\nCheckpoint learning rate: 0.1234\nStart epoch: 1\n</pre>\n</div>\n<div id=\"id1\">\n<span id=\"statistics\"></span><h3>Statistics:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"c1\"># define your dataset and dataloader</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">MyDataset</span><span class=\"p\">()</span>\n<span class=\"n\">trainloader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n                                          <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n                                          <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># get statistics</span>\n<span class=\"n\">stats</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_dataset_stats</span><span class=\"p\">(</span><span class=\"n\">trainloader</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Mean:'</span><span class=\"p\">,</span> <span class=\"n\">stats</span><span class=\"p\">[</span><span class=\"s1\">'mean'</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Std:'</span><span class=\"p\">,</span> <span class=\"n\">stats</span><span class=\"p\">[</span><span class=\"s1\">'std'</span><span class=\"p\">])</span>\n</pre>\n<p>Output</p>\n<pre>Calculating dataset stats...\nBatch 100/100\nMean: tensor([10000.0098,  9999.9795,  9999.9893])\nStd: tensor([0.9969, 1.0003, 0.9972])\n</pre>\n</div>\n<div id=\"id2\">\n<span id=\"learning-rate\"></span><h3>Learning Rate:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.optim</span> <span class=\"k\">as</span> <span class=\"nn\">optim</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">alexnet</span><span class=\"p\">()</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># get learning rate</span>\n<span class=\"n\">current_lr</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_lr</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Current learning rate:'</span><span class=\"p\">,</span> <span class=\"n\">current_lr</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># set learning rate</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">set_lr</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">current_lr</span><span class=\"o\">*</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n<span class=\"n\">revised_lr</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_lr</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Revised learning rate:'</span><span class=\"p\">,</span> <span class=\"n\">revised_lr</span><span class=\"p\">)</span>\n</pre>\n<p>Output</p>\n<pre>Current learning rate: 0.001\nRevised learning rate: 0.0001\n</pre>\n</div>\n<div id=\"id3\">\n<span id=\"evaluation-metrics\"></span><h3>Evaluation Metrics:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.optim</span> <span class=\"k\">as</span> <span class=\"nn\">optim</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"k\">as</span> <span class=\"nn\">transforms</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"c1\"># define your network</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MyNet</span><span class=\"p\">()</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n<span class=\"n\">trainset</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">MNIST</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s1\">'./data/'</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n                                    <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n                                    <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">())</span>\n<span class=\"n\">trainloader</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">trainset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">60</span><span class=\"p\">,</span>\n                                        <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n                                        <span class=\"n\">drop_last</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">n_epochs</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_epochs</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Epoch: </span><span class=\"si\">%d</span><span class=\"s1\">/</span><span class=\"si\">%d</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">epoch</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">n_epochs</span><span class=\"p\">))</span>\n    <span class=\"c1\"># define loss tracker</span>\n    <span class=\"n\">loss_tracker</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">RunningLoss</span><span class=\"p\">()</span>\n    <span class=\"k\">for</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">trainloader</span><span class=\"p\">):</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n        <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n        <span class=\"c1\"># update loss tracker with latest loss</span>\n        <span class=\"n\">loss_tracker</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">())</span>\n        <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n        <span class=\"k\">if</span> <span class=\"n\">batch_idx</span> <span class=\"o\">%</span> <span class=\"mi\">100</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"c1\"># easily print latest and average loss</span>\n            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">loss_tracker</span><span class=\"p\">)</span>\n</pre>\n<p>Output</p>\n<pre>Epoch: 1/1\nLoss - Val: 2.2921 Avg: 2.2921\nLoss - Val: 0.5084 Avg: 0.9639\nLoss - Val: 0.6027 Avg: 0.6588\nLoss - Val: 0.1817 Avg: 0.5255\nLoss - Val: 0.1005 Avg: 0.4493\nLoss - Val: 0.2982 Avg: 0.3984\nLoss - Val: 0.3103 Avg: 0.3615\nLoss - Val: 0.0940 Avg: 0.3296\nLoss - Val: 0.0957 Avg: 0.3071\nLoss - Val: 0.0229 Avg: 0.2875\n</pre>\n</div>\n<div id=\"id4\">\n<span id=\"model-summary\"></span><h3>Model Summary:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">alexnet</span><span class=\"p\">()</span>\n<span class=\"c1\"># easily print model summary</span>\n<span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_model_summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">)))</span>\n</pre>\n<p>Output</p>\n<pre>=========================================================================================\nLayer                           Kernel             Output          Params           FLOPs\n=========================================================================================\n0_features.Conv2d_0         [3, 64, 11, 11]    [1, 64, 55, 55]       23,296    70,470,400\n1_features.ReLU_1                         -    [1, 64, 55, 55]            0             0\n2_features.MaxPool2d_2                    -    [1, 64, 27, 27]            0             0\n3_features.Conv2d_3         [64, 192, 5, 5]   [1, 192, 27, 27]      307,392   224,088,768\n4_features.ReLU_4                         -   [1, 192, 27, 27]            0             0\n5_features.MaxPool2d_5                    -   [1, 192, 13, 13]            0             0\n6_features.Conv2d_6        [192, 384, 3, 3]   [1, 384, 13, 13]      663,936   112,205,184\n7_features.ReLU_7                         -   [1, 384, 13, 13]            0             0\n8_features.Conv2d_8        [384, 256, 3, 3]   [1, 256, 13, 13]      884,992   149,563,648\n9_features.ReLU_9                         -   [1, 256, 13, 13]            0             0\n10_features.Conv2d_10      [256, 256, 3, 3]   [1, 256, 13, 13]      590,080    99,723,520\n11_features.ReLU_11                       -   [1, 256, 13, 13]            0             0\n12_features.MaxPool2d_12                  -     [1, 256, 6, 6]            0             0\n13_classifier.Dropout_0                   -          [1, 9216]            0             0\n14_classifier.Linear_1         [9216, 4096]          [1, 4096]   37,752,832    75,493,376\n15_classifier.ReLU_2                      -          [1, 4096]            0             0\n16_classifier.Dropout_3                   -          [1, 4096]            0             0\n17_classifier.Linear_4         [4096, 4096]          [1, 4096]   16,781,312    33,550,336\n18_classifier.ReLU_5                      -          [1, 4096]            0             0\n19_classifier.Linear_6         [4096, 1000]          [1, 1000]    4,097,000     8,191,000\n=========================================================================================\nTotal params: 61,100,840\nTrainable params: 61,100,840\nNon-trainable params: 0\nTotal FLOPs: 773,286,232 / 773.29 MFLOPs\n-----------------------------------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 8.31\nParams size (MB): 233.08\nEstimated Total Size (MB): 241.96\n=========================================================================================\n</pre>\n</div>\n<div id=\"id5\">\n<span id=\"model-flops\"></span><h3>Model FLOPs:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">alexnet</span><span class=\"p\">()</span>\n<span class=\"c1\"># calculate model FLOPs</span>\n<span class=\"n\">total_flops</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_model_flops</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">)))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Total model FLOPs: </span><span class=\"si\">{:,}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">total_flops</span><span class=\"p\">))</span>\n</pre>\n<p>Output</p>\n<pre>Total model FLOPs: 773,304,664\n</pre>\n</div>\n<div id=\"id6\">\n<span id=\"model-parameters\"></span><h3>Model Parameters:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">alexnet</span><span class=\"p\">()</span>\n<span class=\"c1\"># calculate total model parameters</span>\n<span class=\"n\">total_params</span> <span class=\"o\">=</span> <span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">get_model_param_count</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Total model params: </span><span class=\"si\">{:,}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">total_params</span><span class=\"p\">))</span>\n</pre>\n<p>Output</p>\n<pre>Total model params: 61,100,840\n</pre>\n</div>\n<div id=\"id7\">\n<span id=\"random-seed\"></span><h3>Random Seed:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"c1\"># set numpy, torch and cuda seed</span>\n<span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">set_random_seed</span><span class=\"p\">(</span><span class=\"mi\">2222</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"id8\">\n<span id=\"gradient-flow\"></span><h3>Gradient Flow:</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchutils</span> <span class=\"k\">as</span> <span class=\"nn\">tu</span>\n\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">alexnet</span><span class=\"p\">(</span><span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">))</span>\n<span class=\"n\">ground_truth</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">))</span>\n<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">ground_truth</span><span class=\"p\">)</span>\n<span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># save model gradient flow to image</span>\n<span class=\"n\">tu</span><span class=\"o\">.</span><span class=\"n\">plot_gradients</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">,</span> <span class=\"s1\">'./grad_figures/grad_01.png'</span><span class=\"p\">,</span> <span class=\"n\">plot_type</span><span class=\"o\">=</span><span class=\"s1\">'line'</span><span class=\"p\">)</span>\n</pre>\n<p>Saved File</p>\n<img alt=\"Example Gradient Flow\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/17ae3d2c8993fe7e3d3a80fb937c010e4d747214/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616e6a616e646565707361686e692f746f7263687574696c732f6d61737465722f646f63732f5f7374617469632f6578616d706c655f6772616469656e745f666c6f772e706e67\">\n</div>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>TorchUtils is distributed under the MIT license, see LICENSE.</p>\n</div>\n\n          </div>"}, "last_serial": 6506884, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "965275ca87e9bdad0d7eb17e5df13509", "sha256": "6447289cc9c630f393f4368536698cb41a3c9e86fbbedae6e4445dc7ecd67995"}, "downloads": -1, "filename": "torchutils-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "965275ca87e9bdad0d7eb17e5df13509", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4687, "upload_time": "2019-07-20T00:47:48", "upload_time_iso_8601": "2019-07-20T00:47:48.228099Z", "url": "https://files.pythonhosted.org/packages/da/81/e089225a52737e7f3551946d47ed7259e393dfcdf9121f74424caa6d7e3e/torchutils-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c59384fb8e0243c9b1b8263840eef6aa", "sha256": "3118932cb9f854dc6b0591e9c17a856a7f390530ca1cb94eb51373dc7fe7dbc3"}, "downloads": -1, "filename": "torchutils-0.0.1.tar.gz", "has_sig": false, "md5_digest": "c59384fb8e0243c9b1b8263840eef6aa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2587, "upload_time": "2019-07-20T00:47:50", "upload_time_iso_8601": "2019-07-20T00:47:50.472722Z", "url": "https://files.pythonhosted.org/packages/66/30/3f2412f104da2d654a29ba536f758592202c3bb5d780d6730047cb1bea47/torchutils-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "ba08ab71d6ec36c04b4750f5176216d1", "sha256": "c6bfac7a2a0c7d44982b6c946c4df5f778a99f560fef73ec4cd1980b7294501c"}, "downloads": -1, "filename": "torchutils-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ba08ab71d6ec36c04b4750f5176216d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 14275, "upload_time": "2019-08-25T03:38:19", "upload_time_iso_8601": "2019-08-25T03:38:19.255086Z", "url": "https://files.pythonhosted.org/packages/56/49/e3ca846d4c7862d79200dd9a03fee40a023e1c83f7bb73aa1fde1ec46920/torchutils-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aef54b6816e4190ca828153f52b7ae97", "sha256": "fb63a2f4fa98ddda5efe267d9cba934dd1121e8d6acf95518fd7f8bf3bc5ca37"}, "downloads": -1, "filename": "torchutils-0.0.2.tar.gz", "has_sig": false, "md5_digest": "aef54b6816e4190ca828153f52b7ae97", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10532, "upload_time": "2019-08-25T03:38:21", "upload_time_iso_8601": "2019-08-25T03:38:21.796466Z", "url": "https://files.pythonhosted.org/packages/39/18/44bf3e2ca4011aae3487ca1bbad3f580db74e462da28e8fbe91060f13749/torchutils-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "edad126d5cd3d5a551309296d27c5c8d", "sha256": "f222898b7c6e940dfca939468b752699ed20e9d704ba71458be2fe8f5776d3d0"}, "downloads": -1, "filename": "torchutils-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "edad126d5cd3d5a551309296d27c5c8d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20532, "upload_time": "2020-01-20T20:34:05", "upload_time_iso_8601": "2020-01-20T20:34:05.654979Z", "url": "https://files.pythonhosted.org/packages/1e/64/4976e99710312e1e39992fc539e2e9e034c9185f080c56a0758f88148357/torchutils-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "53325485d1de4df5735a98b9828d43f1", "sha256": "dd286afa211a63e1642bc214f955696a4109e3659896e978622b15f461574cdd"}, "downloads": -1, "filename": "torchutils-0.0.3.tar.gz", "has_sig": false, "md5_digest": "53325485d1de4df5735a98b9828d43f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18904, "upload_time": "2020-01-20T20:34:07", "upload_time_iso_8601": "2020-01-20T20:34:07.799778Z", "url": "https://files.pythonhosted.org/packages/5d/e3/7db4187e12c0b19b03648784b14669d0e0f2bb79114c45d4e846661874cd/torchutils-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "e87eff6f26ed2281a046dc26baec17b0", "sha256": "95cda304172e39d5861b0c2ad0689fe6d53a7bf198fc64fe74a50640f822d176"}, "downloads": -1, "filename": "torchutils-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "e87eff6f26ed2281a046dc26baec17b0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20792, "upload_time": "2020-01-23T14:36:19", "upload_time_iso_8601": "2020-01-23T14:36:19.823998Z", "url": "https://files.pythonhosted.org/packages/13/df/9aeb5d58faec3f07f6babe54eaa51dbd8ded4c267976c9ce95889b085e4d/torchutils-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e2dfa9a888c6af88ead7dcc07cd57bf5", "sha256": "3bfa65c0c6a22a8ae39c96d8e1c9252b6fb5a64a8f24f66d9e6cefb92783cb07"}, "downloads": -1, "filename": "torchutils-0.0.4.tar.gz", "has_sig": false, "md5_digest": "e2dfa9a888c6af88ead7dcc07cd57bf5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19616, "upload_time": "2020-01-23T14:36:21", "upload_time_iso_8601": "2020-01-23T14:36:21.766399Z", "url": "https://files.pythonhosted.org/packages/75/a3/9a89e6bd461929c92b46a5f27f7603ed84c4e41a0d0cdb2c6ee42324fe95/torchutils-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e87eff6f26ed2281a046dc26baec17b0", "sha256": "95cda304172e39d5861b0c2ad0689fe6d53a7bf198fc64fe74a50640f822d176"}, "downloads": -1, "filename": "torchutils-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "e87eff6f26ed2281a046dc26baec17b0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20792, "upload_time": "2020-01-23T14:36:19", "upload_time_iso_8601": "2020-01-23T14:36:19.823998Z", "url": "https://files.pythonhosted.org/packages/13/df/9aeb5d58faec3f07f6babe54eaa51dbd8ded4c267976c9ce95889b085e4d/torchutils-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e2dfa9a888c6af88ead7dcc07cd57bf5", "sha256": "3bfa65c0c6a22a8ae39c96d8e1c9252b6fb5a64a8f24f66d9e6cefb92783cb07"}, "downloads": -1, "filename": "torchutils-0.0.4.tar.gz", "has_sig": false, "md5_digest": "e2dfa9a888c6af88ead7dcc07cd57bf5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19616, "upload_time": "2020-01-23T14:36:21", "upload_time_iso_8601": "2020-01-23T14:36:21.766399Z", "url": "https://files.pythonhosted.org/packages/75/a3/9a89e6bd461929c92b46a5f27f7603ed84c4e41a0d0cdb2c6ee42324fe95/torchutils-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:04 2020"}