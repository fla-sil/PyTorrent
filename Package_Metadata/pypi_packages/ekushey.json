{"info": {"author": "Karigor", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Ekushey\n\n\"Ekushey\" is the First Structured and Cost-Effective Bangla Natural Language Processing Toolkit\n\n\n\n## Current Modules\n- [Feature Extraction](#feature-extraction)\n```\nfeature_extraction is a Bangla Natural Language Processing based feature extractor\n```\n\n### Feature Extraction\n\n  1. [CountVectorizer](#1-countvectorizer)\n  2. [HashVectorizer](#2-hashvectorizer)\n  3. [TfIdf](#3-tfidf)\n  4. [Word Embedding](#4-word-embedding)\n      * [Word2Vec](#word2vec)\n      * [FastText](#fasttext)\n\n## Installation\n```\npip install ekushey\n```\n## Example\n### 1. CountVectorizer\n  - Fit n Transform\n  - Transform\n  - Get Wordset\n\n**Fit n Transform**\n```py\nfrom ekushey.feature_extraction import CountVectorizer\nct = CountVectorizer()\nX = ct.fit_transform(X) # X is the word features\n```\nOutput:\n```\nthe countVectorized matrix form of given features\n```\n\n**Transform**\n```py\nfrom ekushey.feature_extraction import CountVectorizer\nct = CountVectorizer()\nget_mat = ct.transform(\"\u09b0\u09be\u09b9\u09be\u09a4\")\n```\nOutput:\n```\nthe countVectorized matrix form of given word\n```\n\n**Get Wordset**\n```py\nfrom ekushey.feature_extraction import CountVectorizer\nct = CountVectorizer()\nct.get_wordSet()\n```\nOutput:\n```\nget the raw wordset used in training model\n```\n\n### 2. HashVectorizer\n  - Fit n Transform\n  - Transform\n```py\nfrom ekushey.feature_extraction import HashVectorizer\ncorpus = [\n'\u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09a6\u09c7\u09b6 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6', '\u0986\u09ae\u09be\u09b0 \u09ac\u09be\u0982\u09b2\u09be'\n]\nVectorizer = HashVectorizer()\nn_features = 8\nX = Vectorizer.fit_transform(corpus, n_features)\ncorpus_t = [\"\u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09a6\u09c7\u09b6 \u0985\u09a8\u09c7\u0995 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0\"]\nXf = Vectorizer.transform(corpus_t)\n\nprint(X.shape, Xf.shape)\nprint(\"=====================================\")\nprint(X)\nprint(\"=====================================\")\nprint(Xf)\n```\nOutput:\n```\n(2, 8) (1, 8)\n=====================================\n  (0, 7)\t-1.0\n  (1, 7)\t-1.0\n=====================================\n  (0, 0)\t0.5773502691896258\n  (0, 2)\t0.5773502691896258\n  (0, 7)\t-0.5773502691896258\n```\n\n**Get Wordset**\n\n\n### 3. TfIdf\n  - Fit n Transform\n  - Transform\n  - Coefficients\n\n **Fit n Transform**\n```py\nfrom ekushey.feature_extraction import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\", \"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"]\nmatrix1 = k.fit_transform(doc)\nprint(matrix1)\n```\nOutput:\n```\n[[0.150515 0.150515 0.       0.      ]\n [0.       0.       0.150515 0.150515]]\n\n```\n\n**Transform**\n```py\nfrom ekushey.feature_extraction import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0986\u09b9\u09ae\u09c7\u09a6 \u09b8\u09c1\u09ae\u09a8\", \"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0995\u09b0\u09bf\u09ae\"]\nmatrix2 = k.transform(doc)\nprint(matrix2)\n```\nOutput: \n```\n[[0.150515 0.       0.       0.      ]\n [0.       0.150515 0.       0.      ]]\n```\n**Coefficients**\n```py\nfrom ekushey.feature_extraction import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\", \"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"]\nk.fit_transform(doc)\nwordset, idf = k.coefficients()\nprint(wordset)\n#Output: ['\u0986\u09b9\u09ae\u09c7\u09a6', '\u0995\u09be\u0993\u099b\u09be\u09b0', '\u09b9\u09be\u0987\u09a6\u09be\u09b0', '\u09b6\u09c1\u09ad']\n\nprint(idf)\n'''\nOutput: \n{'\u0986\u09b9\u09ae\u09c7\u09a6': 0.3010299956639812, '\u0995\u09be\u0993\u099b\u09be\u09b0': 0.3010299956639812, '\u09b9\u09be\u0987\u09a6\u09be\u09b0': 0.3010299956639812, '\u09b6\u09c1\u09ad': 0.3010299956639812}\n'''\n\n```\n\n### 4. Word Embedding\n- ### Word2Vec\n    - Training\n    - Get Word Vector\n    - Get Similarity\n    - Get n Similar Words\n    - Get Middle Word\n    - Get Odd Words\n    - Get Similarity Plot\n\n**Training**\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec\n#Training Against Sentences\nw2v = BN_Word2Vec(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be']])\nw2v.train_Word2Vec()\n\n#Training Against one Dataset\nw2v = BN_Word2Vec(corpus_file=\"path to data or txt file\")\nw2v.train_Word2Vec()\n\n#Training Against Multiple Dataset\n'''\n    path\n      ->data\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nw2v = BN_Word2Vec(corpus_path=\"path/data\")\nw2v.train_Word2Vec(epochs=25)\n```\nAfter training is done the model \"w2v_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you use any pretrained model, specify it while initializing BN_Word2Vec() . Otherwise no model_name is needed.**\n\n**Get Word Vector**\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_wordVector('\u0986\u09ae\u09be\u09b0')\n```\n\n**Get Similarity**\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_similarity('\u09a2\u09be\u0995\u09be', '\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0')\n```\nOutput: \n```\n67.457879\n```\n\n**Get n Similar Words**\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n```\nOutput: \n```\n[('\u09b8\u09c7\u09a4\u09c1\u09b0', 0.5857524275779724),\n ('\u09ae\u09c1\u09b2\u09ab\u09ce\u0997\u099e\u09cd\u099c', 0.5773632526397705),\n ('\u09ae\u09b9\u09be\u09a8\u09a8\u09cd\u09a6\u09be', 0.5634652376174927),\n (\"'\u09aa\u09a6\u09cd\u09ae\u09be\", 0.5617109537124634),\n ('\u0997\u09cb\u09ae\u09a4\u09c0', 0.5605217218399048),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.5547558069229126),\n ('\u09a4\u09c1\u09b2\u09b8\u09c0\u0997\u0999\u09cd\u0997\u09be', 0.5274507999420166),\n ('\u09a8\u09a6\u09c0\u09b0', 0.5232067704200745),\n ('\u09b8\u09c7\u09a4\u09c1', 0.5225246548652649),\n ('\u09b8\u09c7\u09a4\u09c1\u09a4\u09c7', 0.5192927718162537)]\n```\n\n**Get Middle Word**\n\nGet the probability distribution of the center word given words list.\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_outputWord(['\u09a2\u09be\u0995\u09be\u09df', '\u09ae\u09c3\u09a4\u09cd\u09af\u09c1'], n=2)\n```\nOutput:\n```\n[(\"\u09b9\u09df\u09c7\u099b\u09c7\u0964',\", 0.05880642), ('\u09b6\u09cd\u09b0\u09ae\u09bf\u0995\u09c7\u09b0', 0.05639163)]\n```\n\n**Get Odd Words**\n\nGet the most unmatched word out from given words list\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n```\nOutput: \n```\n'\u0986\u0995\u09be\u09b6' \n```\n\n**Get Similarity Plot**\n\nCreates a barplot of similar words with their probability \n\n```py\nfrom ekushey.feature_extraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_similarity_plot('\u099a\u09be\u0989\u09b2', 5)\n```\n\n- ### FastText\n    - Training\n    - Get Word Vector\n    - Get Similarity\n    - Get n Similar Words\n    - Get Middle Word\n    - Get Odd Words\n\n\n**Training**\n```py\nfrom ekushey.feature_extraction import BN_FastText\n#Training Against Sentences\nft = FastText(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be']])\nft.train_fasttext()\n\n#Training Against one Dataset\nft = FastText(corpus_file=\"path to data or txt file\")\nft.train_fasttext()\n\n#Training Against Multiple Dataset\n'''\n    path\n      ->data\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nft = FastText(corpus_path=\"path/data\")\nft.train_fasttext(epochs=25)\n```\nAfter training is done the model \"ft_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you use any pretrained model, specify it while initializing BN_FastText() . Otherwise no model_name is needed.**\n\n**Get Word Vector**\n```py\nfrom ekushey.feature_extraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_wordVector('\u0986\u09ae\u09be\u09b0')\n```\n\n**Get Similarity**\n```py\nfrom ekushey.feature_extraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_similarity('\u09a2\u09be\u0995\u09be', '\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0')\n```\nOutput:\n```\n70.56821120\n```\n\n**Get n Similar Words**\n```py\nfrom ekushey.feature_extraction\" import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n```\n\nOutput: \n```\n[('\u09aa\u09a6\u09cd\u09ae\u09be\u09df', 0.8103810548782349),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.794012725353241),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09a8\u09a6\u09c0\u09b0', 0.7747839689254761),\n ('\u09aa\u09a6\u09cd\u09ae\u09be-\u09ae\u09c7\u0998\u09a8\u09be\u09b0', 0.7573559284210205),\n ('\u09aa\u09a6\u09cd\u09ae\u09be.', 0.7470568418502808),\n ('\u2018\u09aa\u09a6\u09cd\u09ae\u09be', 0.7413997650146484),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b8\u09c7\u09a4\u09c1\u09b0', 0.716225266456604),\n ('\u09aa\u09a6\u09cd\u09ae', 0.7154797315597534),\n ('\u09aa\u09a6\u09cd\u09ae\u09b9\u09c7\u09ae', 0.6881639361381531),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09ac\u09a4', 0.6682782173156738)]\n```\n\n**Get Odd Words**\n\nGet the most unmatched word out from given words list\n```py\nfrom \"package_name\" import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n```\nOutput:\n```\n'\u0986\u0995\u09be\u09b6' \n```\n\n**Get Similarity Plot**\n\nCreates a barplot of similar words with their probability \n\n```py\nfrom ekushey.feature_extraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_similarity_plot('\u099a\u09be\u0989\u09b2', 5)\n```\n\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "ekushey", "package_url": "https://pypi.org/project/ekushey/", "platform": "", "project_url": "https://pypi.org/project/ekushey/", "project_urls": {"Homepage": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction"}, "release_url": "https://pypi.org/project/ekushey/0.4/", "requires_dist": ["scipy", "gensim", "numpy", "matplotlib", "scikit-learn"], "requires_python": "", "summary": "", "version": "0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Ekushey</h1>\n<p>\"Ekushey\" is the First Structured and Cost-Effective Bangla Natural Language Processing Toolkit</p>\n<h2>Current Modules</h2>\n<ul>\n<li><a href=\"#feature-extraction\" rel=\"nofollow\">Feature Extraction</a></li>\n</ul>\n<pre><code>feature_extraction is a Bangla Natural Language Processing based feature extractor\n</code></pre>\n<h3>Feature Extraction</h3>\n<ol>\n<li><a href=\"#1-countvectorizer\" rel=\"nofollow\">CountVectorizer</a></li>\n<li><a href=\"#2-hashvectorizer\" rel=\"nofollow\">HashVectorizer</a></li>\n<li><a href=\"#3-tfidf\" rel=\"nofollow\">TfIdf</a></li>\n<li><a href=\"#4-word-embedding\" rel=\"nofollow\">Word Embedding</a>\n<ul>\n<li><a href=\"#word2vec\" rel=\"nofollow\">Word2Vec</a></li>\n<li><a href=\"#fasttext\" rel=\"nofollow\">FastText</a></li>\n</ul>\n</li>\n</ol>\n<h2>Installation</h2>\n<pre><code>pip install ekushey\n</code></pre>\n<h2>Example</h2>\n<h3>1. CountVectorizer</h3>\n<ul>\n<li>Fit n Transform</li>\n<li>Transform</li>\n<li>Get Wordset</li>\n</ul>\n<p><strong>Fit n Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"n\">ct</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span> <span class=\"c1\"># X is the word features</span>\n</pre>\n<p>Output:</p>\n<pre><code>the countVectorized matrix form of given features\n</code></pre>\n<p><strong>Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"n\">ct</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">get_mat</span> <span class=\"o\">=</span> <span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"s2\">\"\u09b0\u09be\u09b9\u09be\u09a4\"</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>the countVectorized matrix form of given word\n</code></pre>\n<p><strong>Get Wordset</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"n\">ct</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">get_wordSet</span><span class=\"p\">()</span>\n</pre>\n<p>Output:</p>\n<pre><code>get the raw wordset used in training model\n</code></pre>\n<h3>2. HashVectorizer</h3>\n<ul>\n<li>Fit n Transform</li>\n<li>Transform</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">HashVectorizer</span>\n<span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n<span class=\"s1\">'\u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09a6\u09c7\u09b6 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0 \u09ac\u09be\u0982\u09b2\u09be'</span>\n<span class=\"p\">]</span>\n<span class=\"n\">Vectorizer</span> <span class=\"o\">=</span> <span class=\"n\">HashVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">n_features</span> <span class=\"o\">=</span> <span class=\"mi\">8</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">Vectorizer</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">corpus</span><span class=\"p\">,</span> <span class=\"n\">n_features</span><span class=\"p\">)</span>\n<span class=\"n\">corpus_t</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09a6\u09c7\u09b6 \u0985\u09a8\u09c7\u0995 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0\"</span><span class=\"p\">]</span>\n<span class=\"n\">Xf</span> <span class=\"o\">=</span> <span class=\"n\">Vectorizer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">corpus_t</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">,</span> <span class=\"n\">Xf</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"=====================================\"</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"=====================================\"</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">Xf</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>(2, 8) (1, 8)\n=====================================\n  (0, 7)\t-1.0\n  (1, 7)\t-1.0\n=====================================\n  (0, 0)\t0.5773502691896258\n  (0, 2)\t0.5773502691896258\n  (0, 7)\t-0.5773502691896258\n</code></pre>\n<p><strong>Get Wordset</strong></p>\n<h3>3. TfIdf</h3>\n<ul>\n<li>Fit n Transform</li>\n<li>Transform</li>\n<li>Coefficients</li>\n</ul>\n<p><strong>Fit n Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">TfIdfVectorizer</span>\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">TfIdfVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"</span><span class=\"p\">]</span>\n<span class=\"n\">matrix1</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">matrix1</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>[[0.150515 0.150515 0.       0.      ]\n [0.       0.       0.150515 0.150515]]\n\n</code></pre>\n<p><strong>Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">TfIdfVectorizer</span>\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">TfIdfVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0986\u09b9\u09ae\u09c7\u09a6 \u09b8\u09c1\u09ae\u09a8\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0995\u09b0\u09bf\u09ae\"</span><span class=\"p\">]</span>\n<span class=\"n\">matrix2</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">matrix2</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>[[0.150515 0.       0.       0.      ]\n [0.       0.150515 0.       0.      ]]\n</code></pre>\n<p><strong>Coefficients</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">TfIdfVectorizer</span>\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">TfIdfVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"</span><span class=\"p\">]</span>\n<span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n<span class=\"n\">wordset</span><span class=\"p\">,</span> <span class=\"n\">idf</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">coefficients</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">wordset</span><span class=\"p\">)</span>\n<span class=\"c1\">#Output: ['\u0986\u09b9\u09ae\u09c7\u09a6', '\u0995\u09be\u0993\u099b\u09be\u09b0', '\u09b9\u09be\u0987\u09a6\u09be\u09b0', '\u09b6\u09c1\u09ad']</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">idf</span><span class=\"p\">)</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">Output: </span>\n<span class=\"sd\">{'\u0986\u09b9\u09ae\u09c7\u09a6': 0.3010299956639812, '\u0995\u09be\u0993\u099b\u09be\u09b0': 0.3010299956639812, '\u09b9\u09be\u0987\u09a6\u09be\u09b0': 0.3010299956639812, '\u09b6\u09c1\u09ad': 0.3010299956639812}</span>\n<span class=\"sd\">'''</span>\n</pre>\n<h3>4. Word Embedding</h3>\n<ul>\n<li>\n<h3>Word2Vec</h3>\n<ul>\n<li>Training</li>\n<li>Get Word Vector</li>\n<li>Get Similarity</li>\n<li>Get n Similar Words</li>\n<li>Get Middle Word</li>\n<li>Get Odd Words</li>\n<li>Get Similarity Plot</li>\n</ul>\n</li>\n</ul>\n<p><strong>Training</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span>\n<span class=\"c1\">#Training Against Sentences</span>\n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"o\">=</span><span class=\"p\">[[</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09aa\u09cd\u09b0\u09bf\u09df'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'\u09ac\u09be\u0982\u09b2\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'</span><span class=\"p\">]])</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">train_Word2Vec</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against one Dataset</span>\n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">corpus_file</span><span class=\"o\">=</span><span class=\"s2\">\"path to data or txt file\"</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">train_Word2Vec</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against Multiple Dataset</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">    path</span>\n<span class=\"sd\">      -&gt;data</span>\n<span class=\"sd\">        -&gt;1.txt</span>\n<span class=\"sd\">        -&gt;2.txt</span>\n<span class=\"sd\">        -&gt;3.txt</span>\n<span class=\"sd\">'''</span>\n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">corpus_path</span><span class=\"o\">=</span><span class=\"s2\">\"path/data\"</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">train_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">)</span>\n</pre>\n<p>After training is done the model \"w2v_model\"  along with it's supportive vector files will be saved to current directory.</p>\n<p><strong>If you use any pretrained model, specify it while initializing BN_Word2Vec() . Otherwise no model_name is needed.</strong></p>\n<p><strong>Get Word Vector</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_wordVector</span><span class=\"p\">(</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">)</span>\n</pre>\n<p><strong>Get Similarity</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_similarity</span><span class=\"p\">(</span><span class=\"s1\">'\u09a2\u09be\u0995\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0'</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>67.457879\n</code></pre>\n<p><strong>Get n Similar Words</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_n_similarWord</span><span class=\"p\">([</span><span class=\"s1\">'\u09aa\u09a6\u09cd\u09ae\u09be'</span><span class=\"p\">],</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>[('\u09b8\u09c7\u09a4\u09c1\u09b0', 0.5857524275779724),\n ('\u09ae\u09c1\u09b2\u09ab\u09ce\u0997\u099e\u09cd\u099c', 0.5773632526397705),\n ('\u09ae\u09b9\u09be\u09a8\u09a8\u09cd\u09a6\u09be', 0.5634652376174927),\n (\"'\u09aa\u09a6\u09cd\u09ae\u09be\", 0.5617109537124634),\n ('\u0997\u09cb\u09ae\u09a4\u09c0', 0.5605217218399048),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.5547558069229126),\n ('\u09a4\u09c1\u09b2\u09b8\u09c0\u0997\u0999\u09cd\u0997\u09be', 0.5274507999420166),\n ('\u09a8\u09a6\u09c0\u09b0', 0.5232067704200745),\n ('\u09b8\u09c7\u09a4\u09c1', 0.5225246548652649),\n ('\u09b8\u09c7\u09a4\u09c1\u09a4\u09c7', 0.5192927718162537)]\n</code></pre>\n<p><strong>Get Middle Word</strong></p>\n<p>Get the probability distribution of the center word given words list.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_outputWord</span><span class=\"p\">([</span><span class=\"s1\">'\u09a2\u09be\u0995\u09be\u09df'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09ae\u09c3\u09a4\u09cd\u09af\u09c1'</span><span class=\"p\">],</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>[(\"\u09b9\u09df\u09c7\u099b\u09c7\u0964',\", 0.05880642), ('\u09b6\u09cd\u09b0\u09ae\u09bf\u0995\u09c7\u09b0', 0.05639163)]\n</code></pre>\n<p><strong>Get Odd Words</strong></p>\n<p>Get the most unmatched word out from given words list</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_oddWords</span><span class=\"p\">([</span><span class=\"s1\">'\u099a\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09a1\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099a\u09bf\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u0995\u09be\u09b6'</span><span class=\"p\">])</span>\n</pre>\n<p>Output:</p>\n<pre><code>'\u0986\u0995\u09be\u09b6' \n</code></pre>\n<p><strong>Get Similarity Plot</strong></p>\n<p>Creates a barplot of similar words with their probability</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_similarity_plot</span><span class=\"p\">(</span><span class=\"s1\">'\u099a\u09be\u0989\u09b2'</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>\n<h3>FastText</h3>\n<ul>\n<li>Training</li>\n<li>Get Word Vector</li>\n<li>Get Similarity</li>\n<li>Get n Similar Words</li>\n<li>Get Middle Word</li>\n<li>Get Odd Words</li>\n</ul>\n</li>\n</ul>\n<p><strong>Training</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span>\n<span class=\"c1\">#Training Against Sentences</span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">FastText</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"o\">=</span><span class=\"p\">[[</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09aa\u09cd\u09b0\u09bf\u09df'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'\u09ac\u09be\u0982\u09b2\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'</span><span class=\"p\">]])</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against one Dataset</span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">FastText</span><span class=\"p\">(</span><span class=\"n\">corpus_file</span><span class=\"o\">=</span><span class=\"s2\">\"path to data or txt file\"</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against Multiple Dataset</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">    path</span>\n<span class=\"sd\">      -&gt;data</span>\n<span class=\"sd\">        -&gt;1.txt</span>\n<span class=\"sd\">        -&gt;2.txt</span>\n<span class=\"sd\">        -&gt;3.txt</span>\n<span class=\"sd\">'''</span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">FastText</span><span class=\"p\">(</span><span class=\"n\">corpus_path</span><span class=\"o\">=</span><span class=\"s2\">\"path/data\"</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">(</span><span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">)</span>\n</pre>\n<p>After training is done the model \"ft_model\"  along with it's supportive vector files will be saved to current directory.</p>\n<p><strong>If you use any pretrained model, specify it while initializing BN_FastText() . Otherwise no model_name is needed.</strong></p>\n<p><strong>Get Word Vector</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_wordVector</span><span class=\"p\">(</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">)</span>\n</pre>\n<p><strong>Get Similarity</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_similarity</span><span class=\"p\">(</span><span class=\"s1\">'\u09a2\u09be\u0995\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0'</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>70.56821120\n</code></pre>\n<p><strong>Get n Similar Words</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span><span class=\"s2\">\" import BN_FastText </span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_n_similarWord</span><span class=\"p\">([</span><span class=\"s1\">'\u09aa\u09a6\u09cd\u09ae\u09be'</span><span class=\"p\">],</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>Output:</p>\n<pre><code>[('\u09aa\u09a6\u09cd\u09ae\u09be\u09df', 0.8103810548782349),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.794012725353241),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09a8\u09a6\u09c0\u09b0', 0.7747839689254761),\n ('\u09aa\u09a6\u09cd\u09ae\u09be-\u09ae\u09c7\u0998\u09a8\u09be\u09b0', 0.7573559284210205),\n ('\u09aa\u09a6\u09cd\u09ae\u09be.', 0.7470568418502808),\n ('\u2018\u09aa\u09a6\u09cd\u09ae\u09be', 0.7413997650146484),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b8\u09c7\u09a4\u09c1\u09b0', 0.716225266456604),\n ('\u09aa\u09a6\u09cd\u09ae', 0.7154797315597534),\n ('\u09aa\u09a6\u09cd\u09ae\u09b9\u09c7\u09ae', 0.6881639361381531),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09ac\u09a4', 0.6682782173156738)]\n</code></pre>\n<p><strong>Get Odd Words</strong></p>\n<p>Get the most unmatched word out from given words list</p>\n<pre><span class=\"kn\">from</span> <span class=\"s2\">\"package_name\"</span> <span class=\"kn\">import</span> <span class=\"nn\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_oddWords</span><span class=\"p\">([</span><span class=\"s1\">'\u099a\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09a1\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099a\u09bf\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u0995\u09be\u09b6'</span><span class=\"p\">])</span>\n</pre>\n<p>Output:</p>\n<pre><code>'\u0986\u0995\u09be\u09b6' \n</code></pre>\n<p><strong>Get Similarity Plot</strong></p>\n<p>Creates a barplot of similar words with their probability</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ekushey.feature_extraction</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_similarity_plot</span><span class=\"p\">(</span><span class=\"s1\">'\u099a\u09be\u0989\u09b2'</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 7042661, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "ef78ee7bd41f9dfa0eecd0d0521c8bb9", "sha256": "1fbfe877d152b93f8c43ec6658231f4593c5efd3bbf3142cd2f537b385285793"}, "downloads": -1, "filename": "ekushey-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ef78ee7bd41f9dfa0eecd0d0521c8bb9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2629, "upload_time": "2020-04-06T18:26:50", "upload_time_iso_8601": "2020-04-06T18:26:50.920983Z", "url": "https://files.pythonhosted.org/packages/41/38/bd4cd2a8ea5dade77b2a1b76c1bd8d97ea3469761d817c0e5cc73f22dda5/ekushey-0.1-py3-none-any.whl", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "ea5699efc6b66fc2a280c3413a74ed00", "sha256": "037cbcfec7b5e1524293b040420521d700e73890b714afc1962b213ead0a16c6"}, "downloads": -1, "filename": "ekushey-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ea5699efc6b66fc2a280c3413a74ed00", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8990, "upload_time": "2020-04-17T18:29:43", "upload_time_iso_8601": "2020-04-17T18:29:43.371590Z", "url": "https://files.pythonhosted.org/packages/46/09/cdc67858a43a8718929b0c3e546ca4ca1cfa8a21ccd286b2abb202b78e76/ekushey-0.2-py3-none-any.whl", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "8a3d2fded4eb41621dc23a1ec9877079", "sha256": "00f5ec85380fac9c82fc249945657d7aa946b25b090fbe2f78cf0786f6fa2fae"}, "downloads": -1, "filename": "ekushey-0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "8a3d2fded4eb41621dc23a1ec9877079", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8994, "upload_time": "2020-04-17T18:36:42", "upload_time_iso_8601": "2020-04-17T18:36:42.859706Z", "url": "https://files.pythonhosted.org/packages/6b/f8/10dd297b125507e92b8c8debc283db26788774bebc0d26c5b7328af2a43e/ekushey-0.3-py3-none-any.whl", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "37f80fea0575383df9612aef6f53949b", "sha256": "cdbc99f1b1237937cab48c3201e090fba8955c8dbf7e8886b7a441a26028d900"}, "downloads": -1, "filename": "ekushey-0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "37f80fea0575383df9612aef6f53949b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8980, "upload_time": "2020-04-17T19:12:08", "upload_time_iso_8601": "2020-04-17T19:12:08.857646Z", "url": "https://files.pythonhosted.org/packages/97/9b/eef725c8267adb8757fefe4e81994ab7ac47f398136fe41d637d6f7add1f/ekushey-0.4-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "37f80fea0575383df9612aef6f53949b", "sha256": "cdbc99f1b1237937cab48c3201e090fba8955c8dbf7e8886b7a441a26028d900"}, "downloads": -1, "filename": "ekushey-0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "37f80fea0575383df9612aef6f53949b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8980, "upload_time": "2020-04-17T19:12:08", "upload_time_iso_8601": "2020-04-17T19:12:08.857646Z", "url": "https://files.pythonhosted.org/packages/97/9b/eef725c8267adb8757fefe4e81994ab7ac47f398136fe41d637d6f7add1f/ekushey-0.4-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:47:10 2020"}