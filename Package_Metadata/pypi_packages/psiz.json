{"info": {"author": "Brett D. Roads", "author_email": "brett.roads@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3"], "description": "# PsiZ: A Psychological Embedding Package\n\n## Purpose\nPsiZ provides the computational tools to infer a continuous, multivariate stimulus representation using ordinal similarity relations. It integrates well-established cognitive theory with contemporary computational methods. The companion Open Access article is available at https://link.springer.com/article/10.3758/s13428-019-01285-3.\n\n## Installation\nThe best way to install PsiZ is by cloning from GitHub and installing the local repo using pip.\n1. Use git to clone the latest version: `git clone https://github.com/roads/psiz.git`\n2. Install the cloned repo using pip: `pip install /local/path/to/psiz`\n\nThe repository can also be cloned by:\n    * Manually download the latest version at https://github.com/roads/psiz.git\n    * Use git to clone a specific release, for example: `git clone https://github.com/roads/psiz.git --branch v0.2.2`\nAlternatively, but not recommended, you can install from PyPI using ``pip install psiz``. The versions available through PyPI lag behind the GitHub version.\n\n**Note:** PsiZ also requires TensorFlow. The current `setup.py` file fulfills this dependency by downloading the `tensorflow` package using `pip`.\n\n## Quick Start\nThere are four predefined embedding models to choose from:\n\n1. Inverse\n2. Exponential\n3. HeavyTailed\n4. StudentsT\n\nOnce you have selected an embedding model, you must provide two pieces of information in order to infer an embedding.\n\n1. The similarity judgment observations (often abbreviated as *obs*).\n2. The number of unique stimuli that will be in your embedding.\n\n```python\nimport psiz\n\n# Load some observations (i.e., judged trials).\n(obs, catalog) = psiz.datasets.load('birds-16')\n# Initialize an embedding model.\nemb = psiz.models.Exponential(catalog.n_stimuli)\n# Fit the embedding model using similarity judgment observations.\nemb.fit(obs)\n# Optionally save the fitted model.\nemb.save('my_embedding.h5')\n```\n\n## Trials and Observations\nInference is performed by fitting a model to a set of observations. In this package, a single observation is comprised of trial where multiple stimuli that have been judged by an agent (human or machine) based on their similarity. \n\nIn the simplest case, an observation is obtained from a trial consisting of three stimuli: a *query* stimulus (*q*) and two *reference* stimuli (*a* and *b*). An agent selects the reference stimulus that they believe is more similar to the query stimulus. For this simple trial, there are two possible outcomes. If the agent selected reference *a*, then the observation for the *i*th trial would be recorded as the vector: \n\nD<sub>*i*</sub> = [*q* *a* *b*]\n\nAlternatively, if the agent had selected reference *b*, the observation would be recorded as:\n\nD<sub>*i*</sub> = [*q* *b* *a*]\n\nIn addition to a simple *triplet* trial, this package is designed to handle a number of different trial configurations. A trial may have 2-8 reference stimuli and an agent may be required to select and rank more than one reference stimulus. \n\n## Using Your Own Data\n\nTo use your own data, you should place your data in a `psiz.trials.Observations` object. Once the Observations object has been created, you can save it to disk by calling its `save` method. It can be loaded later using the function `psiz.trials.load(filepath)`. Consider the following example that uses randomly generated data:\n\n```python\nimport numpy as np\nimport psiz.trials\n\n# Let's assume that we have 10 unique stimuli.\nstimuli_list = np.arange(0, 10, dtype=int)\n\n# Let's create 100 trials, where each trial is composed of a query and\n# four references. We will also assume that participants selected two\n# references (in order of their similarity to the query.)\nn_trial = 100\nn_reference = 4\nresponse_set = np.empty([n_trial, n_reference + 1], dtype=int)\nn_select = 2 * np.ones((n_trial), dtype=int)\nfor i_trial in range(n_trial):\n    # Randomly selected stimuli and randomly simulate behavior for each\n    # trial (one query, four references).\n    response_set[i_trial, :] = np.random.choice(\n        stimuli_list, n_reference + 1, replace=False\n    )\n\n# Create the observations object and save it to disk.\nobs = psiz.trials.Observations(response_set, n_select=n_select)\nobs.save('path/to/obs.hdf5')\n\n# Load the observations from disk.\nobs = psiz.trials.load('path/to/obs.hdf5')\n```\nNote that the values in `response_set` are assumed to be contiguous integers [0, N[, where N is the number of unique stimuli. Their order is also important. The query is listed in the first column, an agent's selected references are listed second (in order of selection if the trial is ranked) and then any remaining unselected references are listed (in any order).\n\n## Common Use Cases\n\n### Selecting the Dimensionality.\nBy default, an embedding will be inferred using two dimensions. Typically you will want to set the dimensionality to something else. This can easily be done using the keyword `n_dim` during embedding initialization. The dimensionality can also be determined using a cross-validation procedure `psiz.dimensionality.search`.\n```python\nn_stimuli = 100\n\nmodel_spec = {\n    'model': psiz.models.Exponential,\n    'n_stimuli': n_stimuli,\n    'n_group': 1,\n    'modifier': None\n}\n\nsearch_summary = psiz.dimensionality.search(obs, model_spec)\nn_dim = search_summary['dim_best']\n\nemb = psiz.models.Exponential(n_stimuli, n_dim=4)\nemb.fit(obs)\n```\n\n### Multiple Groups\nBy default, the embedding will be inferred assuming that all observations were obtained from a single population or group. If you would like to infer an embedding with multiple group-level parameters, use the `n_group` keyword during embedding initialization. When you create your `psiz.trials.observations` object you will also need to set the `group_id` attribute to indicate the group-membership of each trial.\n```python\nn_stimuli = 100\nemb = psiz.models.Exponential(n_stimuli, n_dim=4, n_group=2)\nemb.fit(obs)\n```\n\n### Fixing Free Parameters\nIf you know some of the free parameters already, you can set them to the desired value and then make those parameters untrainable.\n```python\nn_stimuli = 100\nemb = psiz.models.Exponential(n_stimuli, n_dim=2)\nemb.rho = 2.0\nemb.tau = 1.0\nemb.trainable({'rho': False, 'tau': False})\nemb.fit(obs)\n```\n\nIf you are also performing a dimensionality search, these constraints can be passed in using a post-initialization `modifier` function.\n```python\nn_stimuli = 100\n\ndef modifier_func(emb):\n    emb.rho = 2.0\n    emb.tau = 1.0\n    emb.trainable({'rho': False, 'tau': False})\n    return emb\n\nmodel_spec = {\n    'model': psiz.models.Exponential,\n    'n_stimuli': n_stimuli,\n    'n_group': 1,\n    'modifier': modifier_func\n}\n\nsearch_summary = psiz.dimensionality.search(obs, model_spec)\nn_dim = search_summary['dim_best']\n```\n\n## Modules\n* `catalog` - Class for storing stimulus information.\n* `datasets` - Functions for loading some pre-defined catalogs and observations.\n* `dimensionality` - Routine for selecting the dimensionality of the embedding.\n* `generator` - Generate new trials randomly or using active selection.\n* `models` - A set of pre-defined pscyhological embedding models.\n* `preprocess` - Functions for preprocessing observations.\n* `simulate` - Simulate an agent making similarity judgments.\n* `trials` - Classes and functions for creating and managing observations.\n* `utils` - Utility functions.\n* `visualize` - Functions for visualizing embeddings.\n\n## Authors\n* Brett D. Roads\n* Michael C. Mozer\n* See also the list of contributors who participated in this project.\n\n## What's in a name?\nThe name PsiZ (pronounced *sigh zeee*) is meant to serve as shorthand for the term *psychological embedding*. The greek letter Psi is often used to represent the field of psychology and the matrix variable **Z** is often used in machine learning to denote a latent feature space.\n\n## Licence\nThis project is licensed under the Apache Licence 2.0 - see the LICENSE.txt file for details.\n\n### References\n* van der Maaten, L., & Weinberger, K. (2012, Sept). Stochastic triplet\n   embedding. In Machine learning for signal processing (mlsp), 2012 IEEE\n   international workshop on (p. 1-6). doi:10.1109/MLSP.2012.6349720\n* Roads, B. D., & Mozer, M. C. (2019). Obtaining psychological\n   embeddings through joint kernel and metric learning. Behavior Research\n   Methods. 51(5), 2180-2193. doi:10.3758/s13428-019-01285-3\n* Wah, C., Branson, S., Welinder, P., Perona, P., & Belongie, S. (2011). The\n   Caltech-UCSD Birds-200-2011 Dataset (Tech. Rep. No. CNS-TR-2011-001).\n   California Institute of Technology.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/roads/psiz/archive/v0.3.0.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/roads/psiz", "keywords": "", "license": "Apache Licence 2.0", "maintainer": "", "maintainer_email": "", "name": "psiz", "package_url": "https://pypi.org/project/psiz/", "platform": "", "project_url": "https://pypi.org/project/psiz/", "project_urls": {"Download": "https://github.com/roads/psiz/archive/v0.3.0.tar.gz", "Homepage": "https://github.com/roads/psiz"}, "release_url": "https://pypi.org/project/psiz/0.3.0/", "requires_dist": ["tensorflow (>=2)", "scipy", "pandas", "scikit-learn", "matplotlib", "tensorflow-probability", "numexpr", "pillow"], "requires_python": ">=3, <3.8", "summary": "Toolbox for inferring psychological embeddings.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PsiZ: A Psychological Embedding Package</h1>\n<h2>Purpose</h2>\n<p>PsiZ provides the computational tools to infer a continuous, multivariate stimulus representation using ordinal similarity relations. It integrates well-established cognitive theory with contemporary computational methods. The companion Open Access article is available at <a href=\"https://link.springer.com/article/10.3758/s13428-019-01285-3\" rel=\"nofollow\">https://link.springer.com/article/10.3758/s13428-019-01285-3</a>.</p>\n<h2>Installation</h2>\n<p>The best way to install PsiZ is by cloning from GitHub and installing the local repo using pip.</p>\n<ol>\n<li>Use git to clone the latest version: <code>git clone https://github.com/roads/psiz.git</code></li>\n<li>Install the cloned repo using pip: <code>pip install /local/path/to/psiz</code></li>\n</ol>\n<p>The repository can also be cloned by:\n* Manually download the latest version at <a href=\"https://github.com/roads/psiz.git\" rel=\"nofollow\">https://github.com/roads/psiz.git</a>\n* Use git to clone a specific release, for example: <code>git clone https://github.com/roads/psiz.git --branch v0.2.2</code>\nAlternatively, but not recommended, you can install from PyPI using <code>pip install psiz</code>. The versions available through PyPI lag behind the GitHub version.</p>\n<p><strong>Note:</strong> PsiZ also requires TensorFlow. The current <code>setup.py</code> file fulfills this dependency by downloading the <code>tensorflow</code> package using <code>pip</code>.</p>\n<h2>Quick Start</h2>\n<p>There are four predefined embedding models to choose from:</p>\n<ol>\n<li>Inverse</li>\n<li>Exponential</li>\n<li>HeavyTailed</li>\n<li>StudentsT</li>\n</ol>\n<p>Once you have selected an embedding model, you must provide two pieces of information in order to infer an embedding.</p>\n<ol>\n<li>The similarity judgment observations (often abbreviated as <em>obs</em>).</li>\n<li>The number of unique stimuli that will be in your embedding.</li>\n</ol>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">psiz</span>\n\n<span class=\"c1\"># Load some observations (i.e., judged trials).</span>\n<span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">,</span> <span class=\"n\">catalog</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'birds-16'</span><span class=\"p\">)</span>\n<span class=\"c1\"># Initialize an embedding model.</span>\n<span class=\"n\">emb</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Exponential</span><span class=\"p\">(</span><span class=\"n\">catalog</span><span class=\"o\">.</span><span class=\"n\">n_stimuli</span><span class=\"p\">)</span>\n<span class=\"c1\"># Fit the embedding model using similarity judgment observations.</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">)</span>\n<span class=\"c1\"># Optionally save the fitted model.</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'my_embedding.h5'</span><span class=\"p\">)</span>\n</pre>\n<h2>Trials and Observations</h2>\n<p>Inference is performed by fitting a model to a set of observations. In this package, a single observation is comprised of trial where multiple stimuli that have been judged by an agent (human or machine) based on their similarity.</p>\n<p>In the simplest case, an observation is obtained from a trial consisting of three stimuli: a <em>query</em> stimulus (<em>q</em>) and two <em>reference</em> stimuli (<em>a</em> and <em>b</em>). An agent selects the reference stimulus that they believe is more similar to the query stimulus. For this simple trial, there are two possible outcomes. If the agent selected reference <em>a</em>, then the observation for the <em>i</em>th trial would be recorded as the vector:</p>\n<p>D<sub><em>i</em></sub> = [<em>q</em> <em>a</em> <em>b</em>]</p>\n<p>Alternatively, if the agent had selected reference <em>b</em>, the observation would be recorded as:</p>\n<p>D<sub><em>i</em></sub> = [<em>q</em> <em>b</em> <em>a</em>]</p>\n<p>In addition to a simple <em>triplet</em> trial, this package is designed to handle a number of different trial configurations. A trial may have 2-8 reference stimuli and an agent may be required to select and rank more than one reference stimulus.</p>\n<h2>Using Your Own Data</h2>\n<p>To use your own data, you should place your data in a <code>psiz.trials.Observations</code> object. Once the Observations object has been created, you can save it to disk by calling its <code>save</code> method. It can be loaded later using the function <code>psiz.trials.load(filepath)</code>. Consider the following example that uses randomly generated data:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">psiz.trials</span>\n\n<span class=\"c1\"># Let's assume that we have 10 unique stimuli.</span>\n<span class=\"n\">stimuli_list</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"nb\">int</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Let's create 100 trials, where each trial is composed of a query and</span>\n<span class=\"c1\"># four references. We will also assume that participants selected two</span>\n<span class=\"c1\"># references (in order of their similarity to the query.)</span>\n<span class=\"n\">n_trial</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"n\">n_reference</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>\n<span class=\"n\">response_set</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">([</span><span class=\"n\">n_trial</span><span class=\"p\">,</span> <span class=\"n\">n_reference</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"nb\">int</span><span class=\"p\">)</span>\n<span class=\"n\">n_select</span> <span class=\"o\">=</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"n\">n_trial</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"nb\">int</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">i_trial</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n_trial</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Randomly selected stimuli and randomly simulate behavior for each</span>\n    <span class=\"c1\"># trial (one query, four references).</span>\n    <span class=\"n\">response_set</span><span class=\"p\">[</span><span class=\"n\">i_trial</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span>\n        <span class=\"n\">stimuli_list</span><span class=\"p\">,</span> <span class=\"n\">n_reference</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">replace</span><span class=\"o\">=</span><span class=\"kc\">False</span>\n    <span class=\"p\">)</span>\n\n<span class=\"c1\"># Create the observations object and save it to disk.</span>\n<span class=\"n\">obs</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">trials</span><span class=\"o\">.</span><span class=\"n\">Observations</span><span class=\"p\">(</span><span class=\"n\">response_set</span><span class=\"p\">,</span> <span class=\"n\">n_select</span><span class=\"o\">=</span><span class=\"n\">n_select</span><span class=\"p\">)</span>\n<span class=\"n\">obs</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'path/to/obs.hdf5'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Load the observations from disk.</span>\n<span class=\"n\">obs</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">trials</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'path/to/obs.hdf5'</span><span class=\"p\">)</span>\n</pre>\n<p>Note that the values in <code>response_set</code> are assumed to be contiguous integers [0, N[, where N is the number of unique stimuli. Their order is also important. The query is listed in the first column, an agent's selected references are listed second (in order of selection if the trial is ranked) and then any remaining unselected references are listed (in any order).</p>\n<h2>Common Use Cases</h2>\n<h3>Selecting the Dimensionality.</h3>\n<p>By default, an embedding will be inferred using two dimensions. Typically you will want to set the dimensionality to something else. This can easily be done using the keyword <code>n_dim</code> during embedding initialization. The dimensionality can also be determined using a cross-validation procedure <code>psiz.dimensionality.search</code>.</p>\n<pre><span class=\"n\">n_stimuli</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n\n<span class=\"n\">model_spec</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'model'</span><span class=\"p\">:</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Exponential</span><span class=\"p\">,</span>\n    <span class=\"s1\">'n_stimuli'</span><span class=\"p\">:</span> <span class=\"n\">n_stimuli</span><span class=\"p\">,</span>\n    <span class=\"s1\">'n_group'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"s1\">'modifier'</span><span class=\"p\">:</span> <span class=\"kc\">None</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">search_summary</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">dimensionality</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">,</span> <span class=\"n\">model_spec</span><span class=\"p\">)</span>\n<span class=\"n\">n_dim</span> <span class=\"o\">=</span> <span class=\"n\">search_summary</span><span class=\"p\">[</span><span class=\"s1\">'dim_best'</span><span class=\"p\">]</span>\n\n<span class=\"n\">emb</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Exponential</span><span class=\"p\">(</span><span class=\"n\">n_stimuli</span><span class=\"p\">,</span> <span class=\"n\">n_dim</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">)</span>\n</pre>\n<h3>Multiple Groups</h3>\n<p>By default, the embedding will be inferred assuming that all observations were obtained from a single population or group. If you would like to infer an embedding with multiple group-level parameters, use the <code>n_group</code> keyword during embedding initialization. When you create your <code>psiz.trials.observations</code> object you will also need to set the <code>group_id</code> attribute to indicate the group-membership of each trial.</p>\n<pre><span class=\"n\">n_stimuli</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"n\">emb</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Exponential</span><span class=\"p\">(</span><span class=\"n\">n_stimuli</span><span class=\"p\">,</span> <span class=\"n\">n_dim</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">n_group</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">)</span>\n</pre>\n<h3>Fixing Free Parameters</h3>\n<p>If you know some of the free parameters already, you can set them to the desired value and then make those parameters untrainable.</p>\n<pre><span class=\"n\">n_stimuli</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"n\">emb</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Exponential</span><span class=\"p\">(</span><span class=\"n\">n_stimuli</span><span class=\"p\">,</span> <span class=\"n\">n_dim</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">rho</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">tau</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">trainable</span><span class=\"p\">({</span><span class=\"s1\">'rho'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"s1\">'tau'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">})</span>\n<span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">)</span>\n</pre>\n<p>If you are also performing a dimensionality search, these constraints can be passed in using a post-initialization <code>modifier</code> function.</p>\n<pre><span class=\"n\">n_stimuli</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">modifier_func</span><span class=\"p\">(</span><span class=\"n\">emb</span><span class=\"p\">):</span>\n    <span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">rho</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span>\n    <span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">tau</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>\n    <span class=\"n\">emb</span><span class=\"o\">.</span><span class=\"n\">trainable</span><span class=\"p\">({</span><span class=\"s1\">'rho'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"s1\">'tau'</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">})</span>\n    <span class=\"k\">return</span> <span class=\"n\">emb</span>\n\n<span class=\"n\">model_spec</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'model'</span><span class=\"p\">:</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Exponential</span><span class=\"p\">,</span>\n    <span class=\"s1\">'n_stimuli'</span><span class=\"p\">:</span> <span class=\"n\">n_stimuli</span><span class=\"p\">,</span>\n    <span class=\"s1\">'n_group'</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"s1\">'modifier'</span><span class=\"p\">:</span> <span class=\"n\">modifier_func</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">search_summary</span> <span class=\"o\">=</span> <span class=\"n\">psiz</span><span class=\"o\">.</span><span class=\"n\">dimensionality</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">obs</span><span class=\"p\">,</span> <span class=\"n\">model_spec</span><span class=\"p\">)</span>\n<span class=\"n\">n_dim</span> <span class=\"o\">=</span> <span class=\"n\">search_summary</span><span class=\"p\">[</span><span class=\"s1\">'dim_best'</span><span class=\"p\">]</span>\n</pre>\n<h2>Modules</h2>\n<ul>\n<li><code>catalog</code> - Class for storing stimulus information.</li>\n<li><code>datasets</code> - Functions for loading some pre-defined catalogs and observations.</li>\n<li><code>dimensionality</code> - Routine for selecting the dimensionality of the embedding.</li>\n<li><code>generator</code> - Generate new trials randomly or using active selection.</li>\n<li><code>models</code> - A set of pre-defined pscyhological embedding models.</li>\n<li><code>preprocess</code> - Functions for preprocessing observations.</li>\n<li><code>simulate</code> - Simulate an agent making similarity judgments.</li>\n<li><code>trials</code> - Classes and functions for creating and managing observations.</li>\n<li><code>utils</code> - Utility functions.</li>\n<li><code>visualize</code> - Functions for visualizing embeddings.</li>\n</ul>\n<h2>Authors</h2>\n<ul>\n<li>Brett D. Roads</li>\n<li>Michael C. Mozer</li>\n<li>See also the list of contributors who participated in this project.</li>\n</ul>\n<h2>What's in a name?</h2>\n<p>The name PsiZ (pronounced <em>sigh zeee</em>) is meant to serve as shorthand for the term <em>psychological embedding</em>. The greek letter Psi is often used to represent the field of psychology and the matrix variable <strong>Z</strong> is often used in machine learning to denote a latent feature space.</p>\n<h2>Licence</h2>\n<p>This project is licensed under the Apache Licence 2.0 - see the LICENSE.txt file for details.</p>\n<h3>References</h3>\n<ul>\n<li>van der Maaten, L., &amp; Weinberger, K. (2012, Sept). Stochastic triplet\nembedding. In Machine learning for signal processing (mlsp), 2012 IEEE\ninternational workshop on (p. 1-6). doi:10.1109/MLSP.2012.6349720</li>\n<li>Roads, B. D., &amp; Mozer, M. C. (2019). Obtaining psychological\nembeddings through joint kernel and metric learning. Behavior Research\nMethods. 51(5), 2180-2193. doi:10.3758/s13428-019-01285-3</li>\n<li>Wah, C., Branson, S., Welinder, P., Perona, P., &amp; Belongie, S. (2011). The\nCaltech-UCSD Birds-200-2011 Dataset (Tech. Rep. No. CNS-TR-2011-001).\nCalifornia Institute of Technology.</li>\n</ul>\n\n          </div>"}, "last_serial": 7128887, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "deab9d0a14da1509537a9d37287d0e66", "sha256": "cd958af0a4250dbb11327349e5e978d1d2e170e6400846dd2bad6c9363eeb810"}, "downloads": -1, "filename": "psiz-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "deab9d0a14da1509537a9d37287d0e66", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 60393, "upload_time": "2019-07-19T14:06:34", "upload_time_iso_8601": "2019-07-19T14:06:34.758019Z", "url": "https://files.pythonhosted.org/packages/7c/c7/e263c2184ea4c3308a99f451ef9eeca71f4a92a1324462cb8b7f190b367b/psiz-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "67af24f68ca857b1621ede60d011fecc", "sha256": "9c3a3a56063c29fe03bcf8c3dd9fa6645a054ae89dabe93ea086d43ec31fca0c"}, "downloads": -1, "filename": "psiz-0.1.0.tar.gz", "has_sig": false, "md5_digest": "67af24f68ca857b1621ede60d011fecc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56057, "upload_time": "2019-07-19T14:06:37", "upload_time_iso_8601": "2019-07-19T14:06:37.727750Z", "url": "https://files.pythonhosted.org/packages/15/fe/608242b8d5fd4323cfc9cbe484d0f3c0f8d44e3307df12245873f65fbdfb/psiz-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "f2917d968402e858988ac34df17c6201", "sha256": "f7609dcf49d54343244187a060e9a3688ab10c19b4dd8c74740080417da267e2"}, "downloads": -1, "filename": "psiz-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f2917d968402e858988ac34df17c6201", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58557, "upload_time": "2019-07-29T10:15:39", "upload_time_iso_8601": "2019-07-29T10:15:39.785873Z", "url": "https://files.pythonhosted.org/packages/7f/b5/108138e29d74df765fb309167883a02bf1d69aaab3bac9dfcbc43e57c3e2/psiz-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "45191ff66ad57d8d403383fb175de422", "sha256": "9e0f27a918b0c63fbe898925dc150c53f00c6287664610451cf26cc611dccc9d"}, "downloads": -1, "filename": "psiz-0.2.0.tar.gz", "has_sig": false, "md5_digest": "45191ff66ad57d8d403383fb175de422", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54092, "upload_time": "2019-07-29T10:15:41", "upload_time_iso_8601": "2019-07-29T10:15:41.900753Z", "url": "https://files.pythonhosted.org/packages/77/18/b97568ba654b2382a3107e81866aa6d854d15914e2e1f0fc26fd4732f2a1/psiz-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "88219a0eca384e6e1ffa38a9108b1fed", "sha256": "bac3f7d5ac90eb901acd80ebc1bbd78f0da02aca9f5b314ec3cb7ccf89b12291"}, "downloads": -1, "filename": "psiz-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "88219a0eca384e6e1ffa38a9108b1fed", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58564, "upload_time": "2019-07-29T11:20:32", "upload_time_iso_8601": "2019-07-29T11:20:32.524944Z", "url": "https://files.pythonhosted.org/packages/01/11/732695e5443b5d1735c886842543707036d9f9f853e6c287f924f9dfd0e8/psiz-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1af0901598d4b6fedcabc59d719cca56", "sha256": "71ffdf131b09c78efc61ae80ce7f48c2ccb8bfdf8cddc1156d385ab91a64c1b2"}, "downloads": -1, "filename": "psiz-0.2.1.tar.gz", "has_sig": false, "md5_digest": "1af0901598d4b6fedcabc59d719cca56", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 54152, "upload_time": "2019-07-29T11:20:35", "upload_time_iso_8601": "2019-07-29T11:20:35.979379Z", "url": "https://files.pythonhosted.org/packages/86/5e/f8b58a54f6845ae7063050d5dd28ed0f63080beca6b36c2eafc557df7f16/psiz-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "50a80414e2cd265d099f46aa130ab1a2", "sha256": "5c1caeaff823a34a2c643c25b5fb75fa64abce35e52e633d49c21b73abee0491"}, "downloads": -1, "filename": "psiz-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "50a80414e2cd265d099f46aa130ab1a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 62441, "upload_time": "2019-08-15T17:11:36", "upload_time_iso_8601": "2019-08-15T17:11:36.883806Z", "url": "https://files.pythonhosted.org/packages/69/dc/e768f1ac6a2f45659ed72b7fcefa21ccc4cdc7775fed23eb99cfe93f250c/psiz-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4fbe5cff5def7e778c758a0eb9dac258", "sha256": "56c0c6a24db3488607fee3779f12ae4e080cd5b6ce2e72750214b287ce3b01a6"}, "downloads": -1, "filename": "psiz-0.2.2.tar.gz", "has_sig": false, "md5_digest": "4fbe5cff5def7e778c758a0eb9dac258", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58262, "upload_time": "2019-08-15T17:11:42", "upload_time_iso_8601": "2019-08-15T17:11:42.425414Z", "url": "https://files.pythonhosted.org/packages/b7/7a/99175f83c4bc0f7f77459311a7d32f8ea817d668634f973636bb7b27b6d6/psiz-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "ab3c1edba1aae7e555172a2d3c3d22d4", "sha256": "77e7e0d77fd747b56ade3c8589660acdcae91a6c8827d094cd6b308123befa5d"}, "downloads": -1, "filename": "psiz-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ab3c1edba1aae7e555172a2d3c3d22d4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <3.8", "size": 69367, "upload_time": "2020-04-29T13:28:05", "upload_time_iso_8601": "2020-04-29T13:28:05.025454Z", "url": "https://files.pythonhosted.org/packages/80/96/ee706a3e1bc1720bc1e7387d57554de88a1aef2aee9659b93fe85a99992b/psiz-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2303a3302848e2a069e45bcf3fa96f48", "sha256": "415188dd3f297b15ba2d85e3ddf7b05a6f1999e2bc0e646e5a2ed101d4151f74"}, "downloads": -1, "filename": "psiz-0.3.0.tar.gz", "has_sig": false, "md5_digest": "2303a3302848e2a069e45bcf3fa96f48", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <3.8", "size": 61582, "upload_time": "2020-04-29T13:28:09", "upload_time_iso_8601": "2020-04-29T13:28:09.510638Z", "url": "https://files.pythonhosted.org/packages/7c/6b/12710917dd983ac95ecca3a91c88ec01eb4c8be7f26750d52aed5fd9011e/psiz-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ab3c1edba1aae7e555172a2d3c3d22d4", "sha256": "77e7e0d77fd747b56ade3c8589660acdcae91a6c8827d094cd6b308123befa5d"}, "downloads": -1, "filename": "psiz-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ab3c1edba1aae7e555172a2d3c3d22d4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3, <3.8", "size": 69367, "upload_time": "2020-04-29T13:28:05", "upload_time_iso_8601": "2020-04-29T13:28:05.025454Z", "url": "https://files.pythonhosted.org/packages/80/96/ee706a3e1bc1720bc1e7387d57554de88a1aef2aee9659b93fe85a99992b/psiz-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2303a3302848e2a069e45bcf3fa96f48", "sha256": "415188dd3f297b15ba2d85e3ddf7b05a6f1999e2bc0e646e5a2ed101d4151f74"}, "downloads": -1, "filename": "psiz-0.3.0.tar.gz", "has_sig": false, "md5_digest": "2303a3302848e2a069e45bcf3fa96f48", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3, <3.8", "size": 61582, "upload_time": "2020-04-29T13:28:09", "upload_time_iso_8601": "2020-04-29T13:28:09.510638Z", "url": "https://files.pythonhosted.org/packages/7c/6b/12710917dd983ac95ecca3a91c88ec01eb4c8be7f26750d52aed5fd9011e/psiz-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:15:54 2020"}