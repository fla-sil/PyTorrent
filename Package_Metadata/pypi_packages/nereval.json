{"info": {"author": "Jan Trienes", "author_email": "jan.trienes@googlemail.com", "bugtrack_url": null, "classifiers": [], "description": "nereval\n=======\n.. image:: https://travis-ci.org/jantrienes/nereval.svg?branch=master\n    :target: https://travis-ci.org/jantrienes/nereval\n\nEvaluation script for named entity recognition (NER) systems based on entity-level F1 score.\n\nDefinition\n----------\nThe metric as implemented here has been described by Nadeau and Sekine (2007) and was widely used as part of the Message Understanding Conferences (Grishman and Sundheim, 1996). It evaluates an NER system according to two axes: whether it is able to assign the right type to an entity, and whether it finds the exact entity boundaries. For both axes, the number of correct predictions (COR), the number of actual predictions (ACT) and the number of possible predictions (POS) are computed. From these statistics, precision and recall can be derived:\n\n::\n\n  precision = COR/ACT\n  recall = COR/POS\n\n\nThe final score is the micro-averaged F1 measure of precision and recall of both type and boundary axes.\n\nInstallation\n------------\n.. code-block:: bash\n\n  pip install nereval\n\n\nUsage\n-----\nThe script can either be used from within Python or from the command line when classification results have been written to a JSON file.\n\nUsage from Command Line\n~~~~~~~~~~~~~~~~~~~~~~~\nAssume we have the following classification results in ``input.json``:\n\n.. code-block:: json\n\n  [\n    {\n      \"text\": \"CILINDRISCHE PLUG\",\n      \"true\": [\n        {\n          \"text\": \"CILINDRISCHE PLUG\",\n          \"type\": \"Productname\",\n          \"start\": 0\n        }\n      ],\n      \"predicted\": [\n        {\n          \"text\": \"CILINDRISCHE\",\n          \"type\": \"Productname\",\n          \"start\": 0\n        },\n        {\n          \"text\": \"PLUG\",\n          \"type\": \"Productname\",\n          \"start\": 13\n        }\n      ]\n    }\n  ]\n\n\nThen the script can be executed as follows:\n\n.. code-block:: bash\n\n  python nereval.py input.json\n  F1-score: 0.33\n\n\nUsage from Python\n~~~~~~~~~~~~~~~~~\nAlternatively, the evaluation metric can be directly invoked from within python. Example:\n\n.. code-block:: python\n\n  import nereval\n  from nereval import Entity\n\n  # Ground-truth:\n  # CILINDRISCHE PLUG\n  # B_PROD       I_PROD\n  y_true = [\n      Entity('CILINDRISCHE PLUG', 'Productname', 0)\n  ]\n\n  # Prediction:\n  # CILINDRISCHE PLUG\n  # B_PROD       B_PROD\n  y_pred = [\n      # correct type, wrong text\n      Entity('CILINDRISCHE', 'Productname', 0),\n      # correct type, wrong text\n      Entity('PLUG', 'Productname', 13)\n  ]\n\n  score = nereval.evaluate([y_true], [y_pred])\n  print('F1-score: %.2f' % score)\n  F1-score: 0.33\n\n\nNote on Symmetry\n----------------\nThe metric itself is not symmetric due to the inherent problem of word overlaps in NER. So ``evaluate(y_true, y_pred) != evaluate(y_pred, y_true)``. This comes apparent if we consider the following example (tagger uses an BIO scheme):\n\n.. code-block:: bash\n\n  # Example 1:\n  Input:     CILINDRISCHE PLUG     DIN908  M10X1   Foo\n  Truth:     B_PROD       I_PROD   B_PROD  B_DIM   O\n  Predicted: B_PROD       B_PROD   B_PROD  B_PROD  B_PROD\n\n  Correct Text: 2\n  Correct Type: 2\n\n  # Example 2 (inversed):\n  Input:     CILINDRISCHE PLUG     DIN908  M10X1   Foo\n  Truth:     B_PROD       B_PROD   B_PROD  B_PROD  B_PROD\n  Predicted: B_PROD       I_PROD   B_PROD  B_DIM   O\n\n  Correct Text: 2\n  Correct Type: 3\n\n\nNotes and References\n--------------------\nUsed in a student research project on natural language processing at `University of Twente, Netherlands <https://www.utwente.nl>`_.\n\n**References**\n\n* Grishman, R., & Sundheim, B. (1996). `Message understanding conference-6: A brief history <http://www.aclweb.org/anthology/C96-1079>`_. *In COLING 1996 Volume 1: The 16th International Conference on Computational Linguistics* (Vol. 1).\n* Nadeau, D., & Sekine, S. (2007). `A survey of named entity recognition and classification <http://www.jbe-platform.com/content/journals/10.1075/li.30.1.03nad>`_. *Lingvisticae Investigationes*, 30(1), 3-26.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jantrienes/nereval", "keywords": "ner,nlp,evaluation,f1_score,f1,linguistics,machine_learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "nereval", "package_url": "https://pypi.org/project/nereval/", "platform": "", "project_url": "https://pypi.org/project/nereval/", "project_urls": {"Homepage": "https://github.com/jantrienes/nereval"}, "release_url": "https://pypi.org/project/nereval/0.2.5/", "requires_dist": null, "requires_python": "", "summary": "Evaluation script for named entity recognition systems based on F1 score.", "version": "0.2.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/jantrienes/nereval\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/jantrienes/nereval.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0a5d750fca2b8deeab3547a33cf3e84e2c1cd597/68747470733a2f2f7472617669732d63692e6f72672f6a616e747269656e65732f6e65726576616c2e7376673f6272616e63683d6d6173746572\"></a>\n<p>Evaluation script for named entity recognition (NER) systems based on entity-level F1 score.</p>\n<div id=\"definition\">\n<h2>Definition</h2>\n<p>The metric as implemented here has been described by Nadeau and Sekine (2007) and was widely used as part of the Message Understanding Conferences (Grishman and Sundheim, 1996). It evaluates an NER system according to two axes: whether it is able to assign the right type to an entity, and whether it finds the exact entity boundaries. For both axes, the number of correct predictions (COR), the number of actual predictions (ACT) and the number of possible predictions (POS) are computed. From these statistics, precision and recall can be derived:</p>\n<pre>precision = COR/ACT\nrecall = COR/POS\n</pre>\n<p>The final score is the micro-averaged F1 measure of precision and recall of both type and boundary axes.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install nereval\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>The script can either be used from within Python or from the command line when classification results have been written to a JSON file.</p>\n<div id=\"usage-from-command-line\">\n<h3>Usage from Command Line</h3>\n<p>Assume we have the following classification results in <tt>input.json</tt>:</p>\n<pre><span class=\"p\">[</span>\n  <span class=\"p\">{</span>\n    <span class=\"nt\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"CILINDRISCHE PLUG\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"true\"</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n      <span class=\"p\">{</span>\n        <span class=\"nt\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"CILINDRISCHE PLUG\"</span><span class=\"p\">,</span>\n        <span class=\"nt\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Productname\"</span><span class=\"p\">,</span>\n        <span class=\"nt\">\"start\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">],</span>\n    <span class=\"nt\">\"predicted\"</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n      <span class=\"p\">{</span>\n        <span class=\"nt\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"CILINDRISCHE\"</span><span class=\"p\">,</span>\n        <span class=\"nt\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Productname\"</span><span class=\"p\">,</span>\n        <span class=\"nt\">\"start\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span>\n      <span class=\"p\">},</span>\n      <span class=\"p\">{</span>\n        <span class=\"nt\">\"text\"</span><span class=\"p\">:</span> <span class=\"s2\">\"PLUG\"</span><span class=\"p\">,</span>\n        <span class=\"nt\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Productname\"</span><span class=\"p\">,</span>\n        <span class=\"nt\">\"start\"</span><span class=\"p\">:</span> <span class=\"mi\">13</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">]</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">]</span>\n</pre>\n<p>Then the script can be executed as follows:</p>\n<pre>python nereval.py input.json\nF1-score: <span class=\"m\">0</span>.33\n</pre>\n</div>\n<div id=\"usage-from-python\">\n<h3>Usage from Python</h3>\n<p>Alternatively, the evaluation metric can be directly invoked from within python. Example:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">nereval</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nereval</span> <span class=\"kn\">import</span> <span class=\"n\">Entity</span>\n\n<span class=\"c1\"># Ground-truth:</span>\n<span class=\"c1\"># CILINDRISCHE PLUG</span>\n<span class=\"c1\"># B_PROD       I_PROD</span>\n<span class=\"n\">y_true</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"n\">Entity</span><span class=\"p\">(</span><span class=\"s1\">'CILINDRISCHE PLUG'</span><span class=\"p\">,</span> <span class=\"s1\">'Productname'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"p\">]</span>\n\n<span class=\"c1\"># Prediction:</span>\n<span class=\"c1\"># CILINDRISCHE PLUG</span>\n<span class=\"c1\"># B_PROD       B_PROD</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"c1\"># correct type, wrong text</span>\n    <span class=\"n\">Entity</span><span class=\"p\">(</span><span class=\"s1\">'CILINDRISCHE'</span><span class=\"p\">,</span> <span class=\"s1\">'Productname'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span>\n    <span class=\"c1\"># correct type, wrong text</span>\n    <span class=\"n\">Entity</span><span class=\"p\">(</span><span class=\"s1\">'PLUG'</span><span class=\"p\">,</span> <span class=\"s1\">'Productname'</span><span class=\"p\">,</span> <span class=\"mi\">13</span><span class=\"p\">)</span>\n<span class=\"p\">]</span>\n\n<span class=\"n\">score</span> <span class=\"o\">=</span> <span class=\"n\">nereval</span><span class=\"o\">.</span><span class=\"n\">evaluate</span><span class=\"p\">([</span><span class=\"n\">y_true</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"n\">y_pred</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'F1-score: </span><span class=\"si\">%.2f</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"n\">score</span><span class=\"p\">)</span>\n<span class=\"n\">F1</span><span class=\"o\">-</span><span class=\"n\">score</span><span class=\"p\">:</span> <span class=\"mf\">0.33</span>\n</pre>\n</div>\n</div>\n<div id=\"note-on-symmetry\">\n<h2>Note on Symmetry</h2>\n<p>The metric itself is not symmetric due to the inherent problem of word overlaps in NER. So <tt>evaluate(y_true, y_pred) != evaluate(y_pred, y_true)</tt>. This comes apparent if we consider the following example (tagger uses an BIO scheme):</p>\n<pre><span class=\"c1\"># Example 1:\n</span>Input:     CILINDRISCHE PLUG     DIN908  M10X1   Foo\nTruth:     B_PROD       I_PROD   B_PROD  B_DIM   O\nPredicted: B_PROD       B_PROD   B_PROD  B_PROD  B_PROD\n\nCorrect Text: <span class=\"m\">2</span>\nCorrect Type: <span class=\"m\">2</span>\n\n<span class=\"c1\"># Example 2 (inversed):\n</span>Input:     CILINDRISCHE PLUG     DIN908  M10X1   Foo\nTruth:     B_PROD       B_PROD   B_PROD  B_PROD  B_PROD\nPredicted: B_PROD       I_PROD   B_PROD  B_DIM   O\n\nCorrect Text: <span class=\"m\">2</span>\nCorrect Type: <span class=\"m\">3</span>\n</pre>\n</div>\n<div id=\"notes-and-references\">\n<h2>Notes and References</h2>\n<p>Used in a student research project on natural language processing at <a href=\"https://www.utwente.nl\" rel=\"nofollow\">University of Twente, Netherlands</a>.</p>\n<p><strong>References</strong></p>\n<ul>\n<li>Grishman, R., &amp; Sundheim, B. (1996). <a href=\"http://www.aclweb.org/anthology/C96-1079\" rel=\"nofollow\">Message understanding conference-6: A brief history</a>. <em>In COLING 1996 Volume 1: The 16th International Conference on Computational Linguistics</em> (Vol. 1).</li>\n<li>Nadeau, D., &amp; Sekine, S. (2007). <a href=\"http://www.jbe-platform.com/content/journals/10.1075/li.30.1.03nad\" rel=\"nofollow\">A survey of named entity recognition and classification</a>. <em>Lingvisticae Investigationes</em>, 30(1), 3-26.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 3935935, "releases": {"0.2.3": [{"comment_text": "", "digests": {"md5": "d26b33f69f9be5f0e1cb3d0cd4983db2", "sha256": "9b29cea49d623fa6d0454305d31b9ad240c957b4ffaa288fe6f673e508893cd3"}, "downloads": -1, "filename": "nereval-0.2.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d26b33f69f9be5f0e1cb3d0cd4983db2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6894, "upload_time": "2018-01-31T15:32:19", "upload_time_iso_8601": "2018-01-31T15:32:19.666839Z", "url": "https://files.pythonhosted.org/packages/9b/5d/cfac32b02180b1e623fceb3b34c986528544a8cf6655c37157ca5a109539/nereval-0.2.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0c9b1fd7629d06afd70abf3b6ce621d9", "sha256": "ad5f271e62e632eb5de0d0e1b1ce45710f3ce8383a32706f4871fdd6b4527317"}, "downloads": -1, "filename": "nereval-0.2.3.tar.gz", "has_sig": false, "md5_digest": "0c9b1fd7629d06afd70abf3b6ce621d9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4443, "upload_time": "2018-01-31T15:32:20", "upload_time_iso_8601": "2018-01-31T15:32:20.990040Z", "url": "https://files.pythonhosted.org/packages/0a/ab/c501e46a56d42d6aa387f3312972018047fa700b42a758b6f53aace49d1c/nereval-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "04a0ec45cc25a19fc81dde25d98d1fad", "sha256": "067cc1f40d0593c07a2d3ddaba003840544f99967aee76eafef6ed3a9c27a929"}, "downloads": -1, "filename": "nereval-0.2.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "04a0ec45cc25a19fc81dde25d98d1fad", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 6851, "upload_time": "2018-01-31T15:48:16", "upload_time_iso_8601": "2018-01-31T15:48:16.939563Z", "url": "https://files.pythonhosted.org/packages/8b/ea/9a84698ef1dff6310a43f52849db230ad29dabdd0ca80c718218f57533fc/nereval-0.2.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "88152be829f6be3bb99b6af7a9067ca1", "sha256": "f8cf5b524e105920bcd654b19bc20fe749127588163c08f13c6907ffb415a635"}, "downloads": -1, "filename": "nereval-0.2.4.tar.gz", "has_sig": false, "md5_digest": "88152be829f6be3bb99b6af7a9067ca1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4413, "upload_time": "2018-01-31T15:48:18", "upload_time_iso_8601": "2018-01-31T15:48:18.372487Z", "url": "https://files.pythonhosted.org/packages/7e/c1/d8e3a722f0139eb2f23b2914620739e66e293e2e2a66dffecefe636607cc/nereval-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "ae64ddf52fd3ebbc71bb4a66d813eb5b", "sha256": "b1c8dbc9851746405c8ca57397b8b70e23661e347acb0058d095bc405590637b"}, "downloads": -1, "filename": "nereval-0.2.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ae64ddf52fd3ebbc71bb4a66d813eb5b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4397, "upload_time": "2018-06-06T13:15:50", "upload_time_iso_8601": "2018-06-06T13:15:50.794223Z", "url": "https://files.pythonhosted.org/packages/7e/c1/2964c11404decf05adf677890c741a65f54c4954f3b441b79a7db241430b/nereval-0.2.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "61bf21a95eef5a44767422f8cec4ca4f", "sha256": "0815d461c0ae9cb0aef74f63554d940f203eb7ce7fc68edd3f0c92babf431349"}, "downloads": -1, "filename": "nereval-0.2.5.tar.gz", "has_sig": false, "md5_digest": "61bf21a95eef5a44767422f8cec4ca4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4405, "upload_time": "2018-06-06T13:15:52", "upload_time_iso_8601": "2018-06-06T13:15:52.274620Z", "url": "https://files.pythonhosted.org/packages/73/fc/63f506f1a8cc796428c04bcbaf3ef1c5287e7df031053f21e7fec2675239/nereval-0.2.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ae64ddf52fd3ebbc71bb4a66d813eb5b", "sha256": "b1c8dbc9851746405c8ca57397b8b70e23661e347acb0058d095bc405590637b"}, "downloads": -1, "filename": "nereval-0.2.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ae64ddf52fd3ebbc71bb4a66d813eb5b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4397, "upload_time": "2018-06-06T13:15:50", "upload_time_iso_8601": "2018-06-06T13:15:50.794223Z", "url": "https://files.pythonhosted.org/packages/7e/c1/2964c11404decf05adf677890c741a65f54c4954f3b441b79a7db241430b/nereval-0.2.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "61bf21a95eef5a44767422f8cec4ca4f", "sha256": "0815d461c0ae9cb0aef74f63554d940f203eb7ce7fc68edd3f0c92babf431349"}, "downloads": -1, "filename": "nereval-0.2.5.tar.gz", "has_sig": false, "md5_digest": "61bf21a95eef5a44767422f8cec4ca4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4405, "upload_time": "2018-06-06T13:15:52", "upload_time_iso_8601": "2018-06-06T13:15:52.274620Z", "url": "https://files.pythonhosted.org/packages/73/fc/63f506f1a8cc796428c04bcbaf3ef1c5287e7df031053f21e7fec2675239/nereval-0.2.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:25 2020"}