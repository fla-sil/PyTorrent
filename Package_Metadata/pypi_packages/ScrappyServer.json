{"info": {"author": "Chanticleer", "author_email": "dmkitui@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "=======\nScrappyServer\n=======\n.. image:: https://travis-ci.org/kirankoduru/arachne.svg\n    :target: https://travis-ci.org/kirankoduru/arachne\n\n.. image:: https://coveralls.io/repos/kirankoduru/arachne/badge.svg?branch=master&service=github\n    :target: https://coveralls.io/github/kirankoduru/arachne?branch=master\n\nScrappyServer provides a wrapper around your scrapy ``Spider`` object to run them through a flask app. All you have to do is customize ``SPIDER_SETTINGS`` in the settings file.\n\n\nInstallation\n============\nYou can install **Arachne** from pip \n\n\tpip install Arachne\n\n\nSample settings\n===============\nThis is sample settings file for spiders in your project. The settings file should be called **settings.py** for **Arachne** to find it and looks like this::\n\n\t# settings.py file\n\tSPIDER_SETTINGS = [\n\t\t{\n\t\t\t'endpoint': 'dmoz',\n\t\t\t'location': 'spiders.DmozSpider',\n\t\t\t'spider': 'DmozSpider'    \n\t\t}\n\t]\n\nUsage\n=====\nIt looks very similar to a flask app but since **Scrapy** depends on the python **twisted** package, we need to run our flask app with **twisted**::\n\n\tfrom twisted.web.wsgi import WSGIResource\n\tfrom twisted.web.server import Site\n\tfrom twisted.internet import reactor\n\tfrom arachne import ScrappyServer\n\n\tapp = Arachne(__name__)\n\n\tresource = WSGIResource(reactor, reactor.getThreadPool(), app)\n\tsite = Site(resource)\n\treactor.listenTCP(8080, site)\n\n\tif __name__ == '__main__':\n\t\treactor.run()\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dmkitui/arachne", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "ScrappyServer", "package_url": "https://pypi.org/project/ScrappyServer/", "platform": "", "project_url": "https://pypi.org/project/ScrappyServer/", "project_urls": {"Homepage": "https://github.com/dmkitui/arachne"}, "release_url": "https://pypi.org/project/ScrappyServer/0.0.0.1/", "requires_dist": null, "requires_python": "", "summary": "API for Scrapy spiders", "version": "0.0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            =======<br>ScrappyServer<br>=======<br>.. image:: https://travis-ci.org/kirankoduru/arachne.svg<br>    :target: https://travis-ci.org/kirankoduru/arachne<br><br>.. image:: https://coveralls.io/repos/kirankoduru/arachne/badge.svg?branch=master&amp;service=github<br>    :target: https://coveralls.io/github/kirankoduru/arachne?branch=master<br><br>ScrappyServer provides a wrapper around your scrapy ``Spider`` object to run them through a flask app. All you have to do is customize ``SPIDER_SETTINGS`` in the settings file.<br><br><br>Installation<br>============<br>You can install **Arachne** from pip <br><br>\tpip install Arachne<br><br><br>Sample settings<br>===============<br>This is sample settings file for spiders in your project. The settings file should be called **settings.py** for **Arachne** to find it and looks like this::<br><br>\t# settings.py file<br>\tSPIDER_SETTINGS = [<br>\t\t{<br>\t\t\t'endpoint': 'dmoz',<br>\t\t\t'location': 'spiders.DmozSpider',<br>\t\t\t'spider': 'DmozSpider'    <br>\t\t}<br>\t]<br><br>Usage<br>=====<br>It looks very similar to a flask app but since **Scrapy** depends on the python **twisted** package, we need to run our flask app with **twisted**::<br><br>\tfrom twisted.web.wsgi import WSGIResource<br>\tfrom twisted.web.server import Site<br>\tfrom twisted.internet import reactor<br>\tfrom arachne import ScrappyServer<br><br>\tapp = Arachne(__name__)<br><br>\tresource = WSGIResource(reactor, reactor.getThreadPool(), app)<br>\tsite = Site(resource)<br>\treactor.listenTCP(8080, site)<br><br>\tif __name__ == '__main__':<br>\t\treactor.run()<br><br>\n          </div>"}, "last_serial": 4033599, "releases": {"0.0.0.1": [{"comment_text": "", "digests": {"md5": "71ed54b4c54e08857218d99874a5141d", "sha256": "f6a91a587bdcd9c52982992efd569638da998504ac4fef0e62269e074b822fed"}, "downloads": -1, "filename": "ScrappyServer-0.0.0.1.tar.gz", "has_sig": false, "md5_digest": "71ed54b4c54e08857218d99874a5141d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10677, "upload_time": "2018-07-05T15:10:15", "upload_time_iso_8601": "2018-07-05T15:10:15.377249Z", "url": "https://files.pythonhosted.org/packages/ef/05/0db4054cc9f27f948dfbd6634cf36e23e886c2720253dc5874505120159f/ScrappyServer-0.0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "71ed54b4c54e08857218d99874a5141d", "sha256": "f6a91a587bdcd9c52982992efd569638da998504ac4fef0e62269e074b822fed"}, "downloads": -1, "filename": "ScrappyServer-0.0.0.1.tar.gz", "has_sig": false, "md5_digest": "71ed54b4c54e08857218d99874a5141d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10677, "upload_time": "2018-07-05T15:10:15", "upload_time_iso_8601": "2018-07-05T15:10:15.377249Z", "url": "https://files.pythonhosted.org/packages/ef/05/0db4054cc9f27f948dfbd6634cf36e23e886c2720253dc5874505120159f/ScrappyServer-0.0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:51 2020"}