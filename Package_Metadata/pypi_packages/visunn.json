{"info": {"author": "Vincent Liu", "author_email": "vliu15@stanford.edu", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Visunn: Aesthetic Visualizations of Neural Networks for Deep Learning\nVisunn is a visualization tool that leverages functional and modular visualizations to provide an visual understanding of neural network architectures. Currently, `torch>=1.4.0` backend is supported.\n\n<img src=\"files/demo.gif\" alt=\"demo gif\">\n\n## Setup\nThe backend and user API is in Python (all `pip` dependencies can be found in `requirements.txt`) and serves a frontend consisting of a fusion of React and Three.js (all `npm` dependencies can be found in `visunn/frontend/package.json`).\n\n## Usage\nThe following examples will use the model `models/ThreeLayerMLP`.\n\n### To pip install\n1. Install python package\n```bash\npip install visunn\n```\n2. Initialize `Visu` in Python script\n```python\nfrom visunn import Visu\nvisu = Visu(model, dataloader, logdir='logs', name='ThreeLayerMLP')\n```\n3. Launch web app\n```bash\nvisu -l logs -n ThreeLayerMLP -p 5000\n```\n### To use source\n1. Build frontend (requires `npm`)\n```bash\nsh build.sh\n```\n2. Initialize `Visu`\n```bash\npython samples/train.py -l logs -n ThreeLayerMLP\n```\n3. Launch web app\n```\npython samples/serve.py -l logs -n ThreeLayerMLP -p 5000\n```\n\n## Metrics\nBelow are time and space metrics for a few sample models, averaged over 5 runs. These can be obtained by running `python samples/debug.py`, which prints metrics of the 5 steps required to create a modularized topology (run on CIFAR-10):\n > Step 1 is the largest bottlenecks in the algorithm.\n1. Convert model to protobuf (built in Pytorch function)\n2. Convert protobuf to dict\n3. Prune trivial nodes\n4. Prune trivial modules\n5. Build modularized topology\n\n| Model              | Step 1   | Step 2  | Step 3  | Step 4  | Step 5  | Space     |\n|--------------------|----------|---------|---------|---------|---------|-----------|\n| ThreeLayerMLP      |  0.042 s | 0.001 s | 0.000 s | 0.000 s | 0.000 s |  32.37 kb |\n| ThreeLayerConvNet  |  0.051 s | 0.002 s | 0.000 s | 0.000 s | 0.000 s |  35.33 kb |\n| resnet18           |  1.282 s | 0.016 s | 0.002 s | 0.001 s | 0.002 s | 335.40 kb |\n| resnet152          |  6.819 s | 0.115 s | 0.065 s | 0.005 s | 0.013 s |   2.14 Mb |\n| densenet121        |  4.143 s | 0.103 s | 0.045 s | 0.008 s | 0.017 s |   1.94 Mb |\n| densenet201        |  7.528 s | 0.174 s | 0.125 s | 0.015 s | 0.034 s |   3.56 Mb |\n| googlenet          |  2.241 s | 0.046 s | 0.011 s | 0.001 s | 0.011 s | 941.52 kb |\n| shufflenet_v2_x2_0 |  2.289 s | 0.070 s | 0.023 s | 0.007 s | 0.010 s |   1.07 Mb |\n| mobilenet_v2       |  1.685 s | 0.045 s | 0.009 s | 0.003 s | 0.005 s | 674.06 kb |\n| resnext101_32x8d   | 11.744 s | 0.085 s | 0.033 s | 0.004 s | 0.009 s |   1.35 Mb |\n| wide_resnet101_2   | 13.495 s | 0.002 s | 0.165 s | 0.007 s | 0.054 s |   1.10 Mb |\n| mnasnet1_3         |  1.562 s | 0.042 s | 0.008 s | 0.003 s | 0.005 s | 658.74 kb |\n\n## Notes\nThis section is dedicated to address nuances that come with the Pytorch backend.\n\n### Recycled Layers\nThis problem is exemplified with the following following variation of `ThreeLayerMLP`:\n```python\nclass Model(nn.Module):\n    def __init__(self, num_classes=10, **kwargs):\n        self.flatten = nn.Flatten(1, -1)\n        self.linear1 = nn.Linear(32*32*3, 1024, bias=True)\n        self.linear2 = nn.Linear(1024, 256, bias=True)\n        self.linear3 = nn.Linear(256, num_classes, bias=True)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.linear2(x)\n        x = self.relu(x)\n        x = self.linear3(x)\n        return x\n```\nNote how `self.relu = nn.ReLU()` is reused multiple times. While this is not incorrect in any way. However, from a graph perspective, there is one `self.relu = ReLU()` node, which has multiple input and output nodes. Rendering this topology declaration will show cycles in the graph due to the multiple passes through the recycled node. A potential solution would be to split all nodes that consist of >1 unconnected graph.\n\n### Weights and Biases\nWith how `torch>=1.4.0` constructs the graph protobuf, it is not possible to acquire the `_output_shapes` attribute from the weights and biases nodes (recoverable for all other nodes). Those fields empty when aggregating attributes.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/vliu15/visunn", "keywords": "deep learning visualization neural networks pytorch torch", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "visunn", "package_url": "https://pypi.org/project/visunn/", "platform": "", "project_url": "https://pypi.org/project/visunn/", "project_urls": {"Homepage": "https://github.com/vliu15/visunn"}, "release_url": "https://pypi.org/project/visunn/0.1.1/", "requires_dist": ["torch (>=1.4.0)", "numpy (>=1.15.1)", "pydot (>=1.4.1)", "networkx (>=2.4)", "protobuf (>=3.11.3)", "flask (>=1.1.1)", "flask-cors (>=3.0.8)", "gevent (>=20.4.0)"], "requires_python": ">=3.5", "summary": "visunn: aesthetic visualization of neural networks", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Visunn: Aesthetic Visualizations of Neural Networks for Deep Learning</h1>\n<p>Visunn is a visualization tool that leverages functional and modular visualizations to provide an visual understanding of neural network architectures. Currently, <code>torch&gt;=1.4.0</code> backend is supported.</p>\n<img alt=\"demo gif\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ddf507e8130af2978f85f2a3eb2aae63d4feaee/66696c65732f64656d6f2e676966\">\n<h2>Setup</h2>\n<p>The backend and user API is in Python (all <code>pip</code> dependencies can be found in <code>requirements.txt</code>) and serves a frontend consisting of a fusion of React and Three.js (all <code>npm</code> dependencies can be found in <code>visunn/frontend/package.json</code>).</p>\n<h2>Usage</h2>\n<p>The following examples will use the model <code>models/ThreeLayerMLP</code>.</p>\n<h3>To pip install</h3>\n<ol>\n<li>Install python package</li>\n</ol>\n<pre>pip install visunn\n</pre>\n<ol>\n<li>Initialize <code>Visu</code> in Python script</li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">visunn</span> <span class=\"kn\">import</span> <span class=\"n\">Visu</span>\n<span class=\"n\">visu</span> <span class=\"o\">=</span> <span class=\"n\">Visu</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">dataloader</span><span class=\"p\">,</span> <span class=\"n\">logdir</span><span class=\"o\">=</span><span class=\"s1\">'logs'</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'ThreeLayerMLP'</span><span class=\"p\">)</span>\n</pre>\n<ol>\n<li>Launch web app</li>\n</ol>\n<pre>visu -l logs -n ThreeLayerMLP -p <span class=\"m\">5000</span>\n</pre>\n<h3>To use source</h3>\n<ol>\n<li>Build frontend (requires <code>npm</code>)</li>\n</ol>\n<pre>sh build.sh\n</pre>\n<ol>\n<li>Initialize <code>Visu</code></li>\n</ol>\n<pre>python samples/train.py -l logs -n ThreeLayerMLP\n</pre>\n<ol>\n<li>Launch web app</li>\n</ol>\n<pre><code>python samples/serve.py -l logs -n ThreeLayerMLP -p 5000\n</code></pre>\n<h2>Metrics</h2>\n<p>Below are time and space metrics for a few sample models, averaged over 5 runs. These can be obtained by running <code>python samples/debug.py</code>, which prints metrics of the 5 steps required to create a modularized topology (run on CIFAR-10):</p>\n<blockquote>\n<p>Step 1 is the largest bottlenecks in the algorithm.</p>\n</blockquote>\n<ol>\n<li>Convert model to protobuf (built in Pytorch function)</li>\n<li>Convert protobuf to dict</li>\n<li>Prune trivial nodes</li>\n<li>Prune trivial modules</li>\n<li>Build modularized topology</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Step 1</th>\n<th>Step 2</th>\n<th>Step 3</th>\n<th>Step 4</th>\n<th>Step 5</th>\n<th>Space</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ThreeLayerMLP</td>\n<td>0.042 s</td>\n<td>0.001 s</td>\n<td>0.000 s</td>\n<td>0.000 s</td>\n<td>0.000 s</td>\n<td>32.37 kb</td>\n</tr>\n<tr>\n<td>ThreeLayerConvNet</td>\n<td>0.051 s</td>\n<td>0.002 s</td>\n<td>0.000 s</td>\n<td>0.000 s</td>\n<td>0.000 s</td>\n<td>35.33 kb</td>\n</tr>\n<tr>\n<td>resnet18</td>\n<td>1.282 s</td>\n<td>0.016 s</td>\n<td>0.002 s</td>\n<td>0.001 s</td>\n<td>0.002 s</td>\n<td>335.40 kb</td>\n</tr>\n<tr>\n<td>resnet152</td>\n<td>6.819 s</td>\n<td>0.115 s</td>\n<td>0.065 s</td>\n<td>0.005 s</td>\n<td>0.013 s</td>\n<td>2.14 Mb</td>\n</tr>\n<tr>\n<td>densenet121</td>\n<td>4.143 s</td>\n<td>0.103 s</td>\n<td>0.045 s</td>\n<td>0.008 s</td>\n<td>0.017 s</td>\n<td>1.94 Mb</td>\n</tr>\n<tr>\n<td>densenet201</td>\n<td>7.528 s</td>\n<td>0.174 s</td>\n<td>0.125 s</td>\n<td>0.015 s</td>\n<td>0.034 s</td>\n<td>3.56 Mb</td>\n</tr>\n<tr>\n<td>googlenet</td>\n<td>2.241 s</td>\n<td>0.046 s</td>\n<td>0.011 s</td>\n<td>0.001 s</td>\n<td>0.011 s</td>\n<td>941.52 kb</td>\n</tr>\n<tr>\n<td>shufflenet_v2_x2_0</td>\n<td>2.289 s</td>\n<td>0.070 s</td>\n<td>0.023 s</td>\n<td>0.007 s</td>\n<td>0.010 s</td>\n<td>1.07 Mb</td>\n</tr>\n<tr>\n<td>mobilenet_v2</td>\n<td>1.685 s</td>\n<td>0.045 s</td>\n<td>0.009 s</td>\n<td>0.003 s</td>\n<td>0.005 s</td>\n<td>674.06 kb</td>\n</tr>\n<tr>\n<td>resnext101_32x8d</td>\n<td>11.744 s</td>\n<td>0.085 s</td>\n<td>0.033 s</td>\n<td>0.004 s</td>\n<td>0.009 s</td>\n<td>1.35 Mb</td>\n</tr>\n<tr>\n<td>wide_resnet101_2</td>\n<td>13.495 s</td>\n<td>0.002 s</td>\n<td>0.165 s</td>\n<td>0.007 s</td>\n<td>0.054 s</td>\n<td>1.10 Mb</td>\n</tr>\n<tr>\n<td>mnasnet1_3</td>\n<td>1.562 s</td>\n<td>0.042 s</td>\n<td>0.008 s</td>\n<td>0.003 s</td>\n<td>0.005 s</td>\n<td>658.74 kb</td>\n</tr></tbody></table>\n<h2>Notes</h2>\n<p>This section is dedicated to address nuances that come with the Pytorch backend.</p>\n<h3>Recycled Layers</h3>\n<p>This problem is exemplified with the following following variation of <code>ThreeLayerMLP</code>:</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">Model</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">flatten</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Flatten</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"o\">*</span><span class=\"mi\">32</span><span class=\"o\">*</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear3</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">relu</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">flatten</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear3</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">x</span>\n</pre>\n<p>Note how <code>self.relu = nn.ReLU()</code> is reused multiple times. While this is not incorrect in any way. However, from a graph perspective, there is one <code>self.relu = ReLU()</code> node, which has multiple input and output nodes. Rendering this topology declaration will show cycles in the graph due to the multiple passes through the recycled node. A potential solution would be to split all nodes that consist of &gt;1 unconnected graph.</p>\n<h3>Weights and Biases</h3>\n<p>With how <code>torch&gt;=1.4.0</code> constructs the graph protobuf, it is not possible to acquire the <code>_output_shapes</code> attribute from the weights and biases nodes (recoverable for all other nodes). Those fields empty when aggregating attributes.</p>\n\n          </div>"}, "last_serial": 7149871, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "b8a35f34d91e635687e229245aff822d", "sha256": "3e1a115fbac77a18d95e8c95f80753ef08f39170a349b055a15adfc111c92b6f"}, "downloads": -1, "filename": "visunn-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b8a35f34d91e635687e229245aff822d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 1015190, "upload_time": "2020-04-24T19:27:20", "upload_time_iso_8601": "2020-04-24T19:27:20.730616Z", "url": "https://files.pythonhosted.org/packages/c1/e0/c7880ef848ac4ca1e0cd4ab7d4ec6a730e744123b46f9d0932884231ca76/visunn-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "741fc6cc2a22896b8bd0db3388930824", "sha256": "5b1b2ad96ead96378f490d9b7bdd852d1351e93beadaf94c8c3fa209149d6343"}, "downloads": -1, "filename": "visunn-0.1.0.tar.gz", "has_sig": false, "md5_digest": "741fc6cc2a22896b8bd0db3388930824", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 1006896, "upload_time": "2020-04-24T19:27:24", "upload_time_iso_8601": "2020-04-24T19:27:24.346248Z", "url": "https://files.pythonhosted.org/packages/a8/ea/9dfa704685009950b8f89264bdf905fa3c1480520f39540fefa1ad279580/visunn-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "44d653ad9dfc22457771877677c05652", "sha256": "8c1393e8051598b3a10223a61ee2ad65f27ad56b9e51d3f83b9a202c59010e9e"}, "downloads": -1, "filename": "visunn-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "44d653ad9dfc22457771877677c05652", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 1033477, "upload_time": "2020-05-02T05:29:40", "upload_time_iso_8601": "2020-05-02T05:29:40.132151Z", "url": "https://files.pythonhosted.org/packages/26/a4/550e41ffc59acd859fe07f3ce0255c0c3c2353eca00afd76c16e46814208/visunn-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef0354991b49e8802a5d5aec1d0d4ad4", "sha256": "e44755e3ed0e68e93dbdce9e97d178cd28d035a8ee06ec53f7155e175ae6c9d2"}, "downloads": -1, "filename": "visunn-0.1.1.tar.gz", "has_sig": false, "md5_digest": "ef0354991b49e8802a5d5aec1d0d4ad4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 1020676, "upload_time": "2020-05-02T05:29:43", "upload_time_iso_8601": "2020-05-02T05:29:43.310622Z", "url": "https://files.pythonhosted.org/packages/7a/40/b957d9d1b3a1f8ad1a5eee40f6acc6d4c1ac41194580afc596888b5ba12e/visunn-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "44d653ad9dfc22457771877677c05652", "sha256": "8c1393e8051598b3a10223a61ee2ad65f27ad56b9e51d3f83b9a202c59010e9e"}, "downloads": -1, "filename": "visunn-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "44d653ad9dfc22457771877677c05652", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 1033477, "upload_time": "2020-05-02T05:29:40", "upload_time_iso_8601": "2020-05-02T05:29:40.132151Z", "url": "https://files.pythonhosted.org/packages/26/a4/550e41ffc59acd859fe07f3ce0255c0c3c2353eca00afd76c16e46814208/visunn-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef0354991b49e8802a5d5aec1d0d4ad4", "sha256": "e44755e3ed0e68e93dbdce9e97d178cd28d035a8ee06ec53f7155e175ae6c9d2"}, "downloads": -1, "filename": "visunn-0.1.1.tar.gz", "has_sig": false, "md5_digest": "ef0354991b49e8802a5d5aec1d0d4ad4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 1020676, "upload_time": "2020-05-02T05:29:43", "upload_time_iso_8601": "2020-05-02T05:29:43.310622Z", "url": "https://files.pythonhosted.org/packages/7a/40/b957d9d1b3a1f8ad1a5eee40f6acc6d4c1ac41194580afc596888b5ba12e/visunn-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:35:09 2020"}