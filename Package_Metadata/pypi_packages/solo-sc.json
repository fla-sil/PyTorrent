{"info": {"author": "David Kelley, Nick Bernstein", "author_email": "nicholas@calicolabs.com", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Intended Audience :: Science/Research", "Topic :: Scientific/Engineering :: Bio-Informatics"], "description": "# solo\n### Why\nCells subjected to single cell RNA-seq have been through a lot, and they'd really just like to be alone now, please. If they cannot escape the cell social scene, you end up sequencing RNA from more than one cell to a barcode, creating a *doublet* when you expected single cell profiles. https://www.biorxiv.org/content/10.1101/841981v1\n\n**_solo_** is a neural network framework to classify doublets, so that you can remove them from your data and clean your single cell profile.\n\n### Quick set up\nRun the following to clone and set up ve.\n`git clone git@github.com:calico/solo.git && cd solo && conda create -n solo python=3.6 && conda activate solo && pip install -e .`\n\nOr install via pip\n`conda create -n solo python=3.6 && conda activate solo && pip install -e solo-sc`\n\nSolo currently is only known to work with python 3.6.\n\nIf you don't have conda follow the instructions here: https://docs.conda.io/projects/conda/en/latest/user-guide/install/\n\n### How to solo\n```\nusage: solo [-h] [-d DOUBLET_DEPTH] [-g] [-o OUT_DIR] [-r DOUBLET_RATIO]\n            [-s SEED] [-k KNOWN_DOUBLETS] [-t {multinomial,average,sum}]\n            [-e EXPECTED_NUMBER_OF_DOUBLETS] [-p]\n            model_json_file data_file\n\npositional arguments:\n  model_json_file       json file to pass VAE parameters\n  data_file             h5ad file containing cell by genes counts\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d DOUBLET_DEPTH      Depth multiplier for a doublet relative to the average\n                        of its constituents (default: 2.0)\n  -g                    Run on GPU (default: True)\n  -o OUT_DIR\n  -r DOUBLET_RATIO      Ratio of doublets to true cells (default: 2.0)\n  -s SEED               Path to previous solo output directory. Seed VAE\n                        models with previously trained solo model. Directory\n                        structure is assumed to be the same as solo output\n                        directory structure. should at least have a vae.pt a\n                        pickled object of vae weights and a latent.npy an\n                        np.ndarray of the latents of your cells. (default:\n                        None)\n  -k KNOWN_DOUBLETS     Experimentally defined doublets tsv file. Should be a\n                        single column of True/False. True indicates the cell\n                        is a doublet. No header. (default: None)\n  -t {multinomial,average,sum}\n                        Please enter multinomial, average, or sum (default:\n                        multinomial)\n  -e EXPECTED_NUMBER_OF_DOUBLETS\n                        Experimentally expected number of doublets (default:\n                        None)\n  -p                    Plot outputs (default: True)\n```\n\nmodel_json example:\n```\n{\n  \"n_hidden\": 384,\n  \"n_latent\": 64,\n  \"n_layers\": 1,\n  \"cl_hidden\": 128,\n  \"cl_layers\": 1,\n  \"dropout_rate\": 0.2,\n  \"learning_rate\": 0.001,\n  \"valid_pct\": 0.10\n}\n```\n\nOutputs:\n* `is_doublet.npy`  np boolean array, true if a cell is a doublet, differs from `preds.npy` if `-e expected_number_of_doublets` parameter was used\n* `vae.pt` scVI weights for vae\n* `classifier.pt` scVI weights for classifier\n* `latent.npy` latent embedding for each cell             \n* `preds.npy` doublet predictions\n* `softmax_scores.npy`\tsoftmax of doublet scores\n* `logit_scores.npy`\tlogit of doublet scores\n* `real_cells_dist.pdf` histogram of distribution of doublet scores\n*  `accuracy.pdf` accuracy plot test vs train\n*  `train_v_test_dist.pdf` doublet scores of test vs train\n*  `roc.pdf`\troc of test vs train\n*  `softmax_scores_sim.npy` see above but for simulated doublets\n*  `logit_scores_sim.npy` see above but for simulated doublets\n*  `preds_sim.npy`\tsee above but for simulated doublets\n*  `is_doublet_sim.npy` see above but for simulated doublets\n\nFor a dataset (2c from Kang et al. 2018) with `n_obs \u00d7 n_vars = 14619 \u00d7 13649`\nwe get the following amount of usage on a 4GB instance on a GTX 1080 Ti.\n```\nCPU Utilized: 00:08:19\nCPU Efficiency: 94.87% of 00:08:46 core-walltime\nJob Wall-clock time: 00:08:46\nMemory Utilized: 3.95 GB\nMemory Efficiency: 98.86% of 4.00 GB\n```\n\n### How to demultiplex cell hashing data using HashSolo CLI\n\nDemultiplexing takes as input an h5ad file with only hashing counts. Counts can be obtained from your fastqs by using kite. See tutorial here: https://github.com/pachterlab/kite\n\n```\nusage: hashsolo [-h] [-j MODEL_JSON_FILE] [-o OUT_DIR] [-c CLUSTERING_DATA]\n                [-p PRE_EXISTING_CLUSTERS] [-q PLOT_NAME]\n                [-n NUMBER_OF_NOISE_BARCODES]\n                data_file\n\npositional arguments:\n  data_file             h5ad file containing cell hashing counts\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -j MODEL_JSON_FILE    json file to pass optional arguments (default: None)\n  -o OUT_DIR            Output directory for results (default:\n                        hashsolo_output)\n  -c CLUSTERING_DATA    h5ad file with count transcriptional data to perform\n                        clustering on (default: None)\n  -p PRE_EXISTING_CLUSTERS\n                        column in cell_hashing_data_file.obs to specifying\n                        different cell types or clusters (default: None)\n  -q PLOT_NAME          name of plot to output (default: hashing_qc_plots.pdf)\n  -n NUMBER_OF_NOISE_BARCODES\n                        Number of barcodes to use to create noise distribution\n                        (default: None)\n```\n\nmodel_json example:\n```\n{\n  \"priors\": [0.01, 0.5, 0.49]\n}\n```\n\nPriors is a list of the probability of the three hypotheses, negative, singlet,\nor doublet that we test when demultiplexing cell hashing data. A negative cell's barcodes\ndoesn't have enough signal to identify its sample of origin. A singlet has\nenough signal from single hashing barcode to associate the cell with ins\noriginating sample. A doublet is a cell barcode which has signal for more than one hashing barcode.\nDepending on how you processed your cell hashing matrix before hand you may\nwant to set different priors. Under the assumption that you have subset your cell\nbarcodes using typical QC on your cell by genes matrix, e.g. min UMI counts,\npercent mitochondrial reads, etc. We found the above setting of prior performed\nwell (see paper). If you have only done relatively light QC in transcriptome space\n I'd suggest an even prior, e.g. `[1./3., 1./3., 1./3.]`.\n\n\nOutputs:\n*  `hashsoloed.h5ad` anndata with demultiplexing information in .obs\n*  `hashing_qc_plots.png` plots of probabilites for each cell\n\n\n### How to demultiplex cell hashing data using HashSolo in line\n\n```\n>>> from solo import hashsolo\n>>> import anndata\n>>> cell_hashing_data = anndata.read(\"cell_hashing_counts.h5ad\")\n>>> hashsolo.hashsolo(cell_hashing_data)\n>>> cell_hashing_data.obs.head()\n                  most_likeli_hypothesis  cluster_feature  negative_hypothesis_probability  singlet_hypothesis_probability  doublet_hypothesis_probability         Classification\nindex                                                                                                                                                                            \nCCTTTCTGTCCGAACC                       2                0                     1.203673e-16                        0.000002                        0.999998                Doublet\nCTGATAGGTGACTCAT                       1                0                     1.370633e-09                        0.999920                        0.000080  BatchF-GTGTGACGTATT_x\nAGCTCTCGTTGTCTTT                       1                0                     2.369380e-13                        0.996992                        0.003008  BatchE-GAGGCTGAGCTA_x\nGTGCGGTAGCGATGAC                       1                0                     1.579405e-09                        0.999879                        0.000121  BatchB-ACATGTTACCGT_x\nAAATGCCTCTAACCGA                       1                0                     1.867626e-13                        0.999707                        0.000293  BatchB-ACATGTTACCGT_x\n>>> demultiplex.plot_qc_checks_cell_hashing(cell_hashing_data)\n```\n\n\n* `most_likeli_hypothesis` 0 == Negative, 1 == Singlet, 2 == Doublet\n* `cluster_feature` how the cell hashing data was divided if specified or done automatically by giving a cell by genes anndata object to the `cluster_data` argument when calling `demultiplex_cell_hashing`\n* `negative_hypothesis_probability`  \n* `singlet_hypothesis_probability`  \n* `doublet_hypothesis_probability`         \n* `Classification` The sample of origin for the cell or whether it was a negative or doublet cell.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/calico/solo/archive/0.1.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/calico/solo", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "solo-sc", "package_url": "https://pypi.org/project/solo-sc/", "platform": "", "project_url": "https://pypi.org/project/solo-sc/", "project_urls": {"Download": "https://github.com/calico/solo/archive/0.1.tar.gz", "Homepage": "http://github.com/calico/solo"}, "release_url": "https://pypi.org/project/solo-sc/0.3/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Neural network classifiers for doublets", "version": "0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>solo</h1>\n<h3>Why</h3>\n<p>Cells subjected to single cell RNA-seq have been through a lot, and they'd really just like to be alone now, please. If they cannot escape the cell social scene, you end up sequencing RNA from more than one cell to a barcode, creating a <em>doublet</em> when you expected single cell profiles. <a href=\"https://www.biorxiv.org/content/10.1101/841981v1\" rel=\"nofollow\">https://www.biorxiv.org/content/10.1101/841981v1</a></p>\n<p><strong><em>solo</em></strong> is a neural network framework to classify doublets, so that you can remove them from your data and clean your single cell profile.</p>\n<h3>Quick set up</h3>\n<p>Run the following to clone and set up ve.\n<code>git clone git@github.com:calico/solo.git &amp;&amp; cd solo &amp;&amp; conda create -n solo python=3.6 &amp;&amp; conda activate solo &amp;&amp; pip install -e .</code></p>\n<p>Or install via pip\n<code>conda create -n solo python=3.6 &amp;&amp; conda activate solo &amp;&amp; pip install -e solo-sc</code></p>\n<p>Solo currently is only known to work with python 3.6.</p>\n<p>If you don't have conda follow the instructions here: <a href=\"https://docs.conda.io/projects/conda/en/latest/user-guide/install/\" rel=\"nofollow\">https://docs.conda.io/projects/conda/en/latest/user-guide/install/</a></p>\n<h3>How to solo</h3>\n<pre><code>usage: solo [-h] [-d DOUBLET_DEPTH] [-g] [-o OUT_DIR] [-r DOUBLET_RATIO]\n            [-s SEED] [-k KNOWN_DOUBLETS] [-t {multinomial,average,sum}]\n            [-e EXPECTED_NUMBER_OF_DOUBLETS] [-p]\n            model_json_file data_file\n\npositional arguments:\n  model_json_file       json file to pass VAE parameters\n  data_file             h5ad file containing cell by genes counts\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d DOUBLET_DEPTH      Depth multiplier for a doublet relative to the average\n                        of its constituents (default: 2.0)\n  -g                    Run on GPU (default: True)\n  -o OUT_DIR\n  -r DOUBLET_RATIO      Ratio of doublets to true cells (default: 2.0)\n  -s SEED               Path to previous solo output directory. Seed VAE\n                        models with previously trained solo model. Directory\n                        structure is assumed to be the same as solo output\n                        directory structure. should at least have a vae.pt a\n                        pickled object of vae weights and a latent.npy an\n                        np.ndarray of the latents of your cells. (default:\n                        None)\n  -k KNOWN_DOUBLETS     Experimentally defined doublets tsv file. Should be a\n                        single column of True/False. True indicates the cell\n                        is a doublet. No header. (default: None)\n  -t {multinomial,average,sum}\n                        Please enter multinomial, average, or sum (default:\n                        multinomial)\n  -e EXPECTED_NUMBER_OF_DOUBLETS\n                        Experimentally expected number of doublets (default:\n                        None)\n  -p                    Plot outputs (default: True)\n</code></pre>\n<p>model_json example:</p>\n<pre><code>{\n  \"n_hidden\": 384,\n  \"n_latent\": 64,\n  \"n_layers\": 1,\n  \"cl_hidden\": 128,\n  \"cl_layers\": 1,\n  \"dropout_rate\": 0.2,\n  \"learning_rate\": 0.001,\n  \"valid_pct\": 0.10\n}\n</code></pre>\n<p>Outputs:</p>\n<ul>\n<li><code>is_doublet.npy</code>  np boolean array, true if a cell is a doublet, differs from <code>preds.npy</code> if <code>-e expected_number_of_doublets</code> parameter was used</li>\n<li><code>vae.pt</code> scVI weights for vae</li>\n<li><code>classifier.pt</code> scVI weights for classifier</li>\n<li><code>latent.npy</code> latent embedding for each cell</li>\n<li><code>preds.npy</code> doublet predictions</li>\n<li><code>softmax_scores.npy</code>\tsoftmax of doublet scores</li>\n<li><code>logit_scores.npy</code>\tlogit of doublet scores</li>\n<li><code>real_cells_dist.pdf</code> histogram of distribution of doublet scores</li>\n<li><code>accuracy.pdf</code> accuracy plot test vs train</li>\n<li><code>train_v_test_dist.pdf</code> doublet scores of test vs train</li>\n<li><code>roc.pdf</code>\troc of test vs train</li>\n<li><code>softmax_scores_sim.npy</code> see above but for simulated doublets</li>\n<li><code>logit_scores_sim.npy</code> see above but for simulated doublets</li>\n<li><code>preds_sim.npy</code>\tsee above but for simulated doublets</li>\n<li><code>is_doublet_sim.npy</code> see above but for simulated doublets</li>\n</ul>\n<p>For a dataset (2c from Kang et al. 2018) with <code>n_obs \u00d7 n_vars = 14619 \u00d7 13649</code>\nwe get the following amount of usage on a 4GB instance on a GTX 1080 Ti.</p>\n<pre><code>CPU Utilized: 00:08:19\nCPU Efficiency: 94.87% of 00:08:46 core-walltime\nJob Wall-clock time: 00:08:46\nMemory Utilized: 3.95 GB\nMemory Efficiency: 98.86% of 4.00 GB\n</code></pre>\n<h3>How to demultiplex cell hashing data using HashSolo CLI</h3>\n<p>Demultiplexing takes as input an h5ad file with only hashing counts. Counts can be obtained from your fastqs by using kite. See tutorial here: <a href=\"https://github.com/pachterlab/kite\" rel=\"nofollow\">https://github.com/pachterlab/kite</a></p>\n<pre><code>usage: hashsolo [-h] [-j MODEL_JSON_FILE] [-o OUT_DIR] [-c CLUSTERING_DATA]\n                [-p PRE_EXISTING_CLUSTERS] [-q PLOT_NAME]\n                [-n NUMBER_OF_NOISE_BARCODES]\n                data_file\n\npositional arguments:\n  data_file             h5ad file containing cell hashing counts\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -j MODEL_JSON_FILE    json file to pass optional arguments (default: None)\n  -o OUT_DIR            Output directory for results (default:\n                        hashsolo_output)\n  -c CLUSTERING_DATA    h5ad file with count transcriptional data to perform\n                        clustering on (default: None)\n  -p PRE_EXISTING_CLUSTERS\n                        column in cell_hashing_data_file.obs to specifying\n                        different cell types or clusters (default: None)\n  -q PLOT_NAME          name of plot to output (default: hashing_qc_plots.pdf)\n  -n NUMBER_OF_NOISE_BARCODES\n                        Number of barcodes to use to create noise distribution\n                        (default: None)\n</code></pre>\n<p>model_json example:</p>\n<pre><code>{\n  \"priors\": [0.01, 0.5, 0.49]\n}\n</code></pre>\n<p>Priors is a list of the probability of the three hypotheses, negative, singlet,\nor doublet that we test when demultiplexing cell hashing data. A negative cell's barcodes\ndoesn't have enough signal to identify its sample of origin. A singlet has\nenough signal from single hashing barcode to associate the cell with ins\noriginating sample. A doublet is a cell barcode which has signal for more than one hashing barcode.\nDepending on how you processed your cell hashing matrix before hand you may\nwant to set different priors. Under the assumption that you have subset your cell\nbarcodes using typical QC on your cell by genes matrix, e.g. min UMI counts,\npercent mitochondrial reads, etc. We found the above setting of prior performed\nwell (see paper). If you have only done relatively light QC in transcriptome space\nI'd suggest an even prior, e.g. <code>[1./3., 1./3., 1./3.]</code>.</p>\n<p>Outputs:</p>\n<ul>\n<li><code>hashsoloed.h5ad</code> anndata with demultiplexing information in .obs</li>\n<li><code>hashing_qc_plots.png</code> plots of probabilites for each cell</li>\n</ul>\n<h3>How to demultiplex cell hashing data using HashSolo in line</h3>\n<pre><code>&gt;&gt;&gt; from solo import hashsolo\n&gt;&gt;&gt; import anndata\n&gt;&gt;&gt; cell_hashing_data = anndata.read(\"cell_hashing_counts.h5ad\")\n&gt;&gt;&gt; hashsolo.hashsolo(cell_hashing_data)\n&gt;&gt;&gt; cell_hashing_data.obs.head()\n                  most_likeli_hypothesis  cluster_feature  negative_hypothesis_probability  singlet_hypothesis_probability  doublet_hypothesis_probability         Classification\nindex                                                                                                                                                                            \nCCTTTCTGTCCGAACC                       2                0                     1.203673e-16                        0.000002                        0.999998                Doublet\nCTGATAGGTGACTCAT                       1                0                     1.370633e-09                        0.999920                        0.000080  BatchF-GTGTGACGTATT_x\nAGCTCTCGTTGTCTTT                       1                0                     2.369380e-13                        0.996992                        0.003008  BatchE-GAGGCTGAGCTA_x\nGTGCGGTAGCGATGAC                       1                0                     1.579405e-09                        0.999879                        0.000121  BatchB-ACATGTTACCGT_x\nAAATGCCTCTAACCGA                       1                0                     1.867626e-13                        0.999707                        0.000293  BatchB-ACATGTTACCGT_x\n&gt;&gt;&gt; demultiplex.plot_qc_checks_cell_hashing(cell_hashing_data)\n</code></pre>\n<ul>\n<li><code>most_likeli_hypothesis</code> 0 == Negative, 1 == Singlet, 2 == Doublet</li>\n<li><code>cluster_feature</code> how the cell hashing data was divided if specified or done automatically by giving a cell by genes anndata object to the <code>cluster_data</code> argument when calling <code>demultiplex_cell_hashing</code></li>\n<li><code>negative_hypothesis_probability</code></li>\n<li><code>singlet_hypothesis_probability</code></li>\n<li><code>doublet_hypothesis_probability</code></li>\n<li><code>Classification</code> The sample of origin for the cell or whether it was a negative or doublet cell.</li>\n</ul>\n\n          </div>"}, "last_serial": 6979448, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "2e2654d77c092a09e676f6da74645df5", "sha256": "04198c6a1cdd5e607fb878ae8fd2e79fa90b13a5f383213e0a0d1c0cf9c834ef"}, "downloads": -1, "filename": "solo-sc-0.2.tar.gz", "has_sig": false, "md5_digest": "2e2654d77c092a09e676f6da74645df5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17294, "upload_time": "2020-01-15T01:00:22", "upload_time_iso_8601": "2020-01-15T01:00:22.596179Z", "url": "https://files.pythonhosted.org/packages/3b/99/a6d2ba4cfa09eeb618044f91ba0ea903e30a87a09bdf1936c6de2cbdbd09/solo-sc-0.2.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "7715a64946c2efcb8150e7b30905d170", "sha256": "f9710918cb928b72d2431b5f04aa7193e427f28feb7f3c6fd1ceb8585ee600c6"}, "downloads": -1, "filename": "solo-sc-0.3.tar.gz", "has_sig": false, "md5_digest": "7715a64946c2efcb8150e7b30905d170", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 21110, "upload_time": "2020-04-08T17:34:29", "upload_time_iso_8601": "2020-04-08T17:34:29.336462Z", "url": "https://files.pythonhosted.org/packages/63/e9/42a025a8da48083221fb35da2124e44af817f61284993f174c228049ec1d/solo-sc-0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7715a64946c2efcb8150e7b30905d170", "sha256": "f9710918cb928b72d2431b5f04aa7193e427f28feb7f3c6fd1ceb8585ee600c6"}, "downloads": -1, "filename": "solo-sc-0.3.tar.gz", "has_sig": false, "md5_digest": "7715a64946c2efcb8150e7b30905d170", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 21110, "upload_time": "2020-04-08T17:34:29", "upload_time_iso_8601": "2020-04-08T17:34:29.336462Z", "url": "https://files.pythonhosted.org/packages/63/e9/42a025a8da48083221fb35da2124e44af817f61284993f174c228049ec1d/solo-sc-0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:46 2020"}