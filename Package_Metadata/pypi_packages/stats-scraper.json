{"info": {"author": "Joseph Jung", "author_email": "josephjung12@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "stats_scraper\n=============\nA simple CLI python web scraper that scrapes NBA\nplayer data from basketball-reference.org and\nallows players to be sorted by points, rebounds, and\nassists and displayed.\n\nInstallation\n------------\nSave the .py files under Stats-Scraper and run it with python3. See requirements.txt for any module requirements and install them with pip\n\nOr use pip to install stats_scraper directly\n\n::\n\n    pip install stats_scraper\n\nUsage\n-----\nCode excerpt from __main__.py\n::\n\n    from stats_scraper.scraper import Scraper\n\n    scraper = Scraper()\n\n    result = scraper.find_player_by_name(\"Ivica Zubac\")\n    print(\"Printing result\\n\")\n    for p in result:\n        print(p)\n\n    sorted_points = scraper.sort_by_points(\"SG\")\n    print(\"========Printing top scorers========\\n\")\n    for scores in sorted_points:\n        print(scores[0], scores[1])\n\n    sorted_assists = scraper.sort_by_assists(\"PF\")\n    print(\"\\n\\n\\n=========Printing top 10 assisters========\\n\")\n    count = 0\n    for assists in sorted_assists:\n        if(count >= 10):\n            break\n        print(assists[0], assists[1])\n        count += 1\n\n    sorted_rebounds = scraper.sort_by_rebounds(\"PG\", \"SG\")\n    print(\"\\n\\n\\n=========Printing top 20 rebounders========\\n\")\n    count = 0\n    for rebounds in sorted_rebounds:\n        if(count >= 20):\n            break\n        print(rebounds[0], rebounds[1])\n        count += 1\n\nAcknowledgment\n--------------\nThank you to Oscar Sanchez's article \"Web Scraping NBA Stats\"\nfor part of the scraping code\n\nLicense\n-------\n`MIT\n<https://choosealicense.com/licenses/mit/>`_\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/JosephJ12/stats_scraper2", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "stats-scraper", "package_url": "https://pypi.org/project/stats-scraper/", "platform": "", "project_url": "https://pypi.org/project/stats-scraper/", "project_urls": {"Homepage": "https://github.com/JosephJ12/stats_scraper2"}, "release_url": "https://pypi.org/project/stats-scraper/1.0.0/", "requires_dist": ["requests", "contextlib2", "bs4"], "requires_python": "", "summary": "Scrapes NBA player data from basketball-reference.com and has few methods to sort the data", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A simple CLI python web scraper that scrapes NBA\nplayer data from basketball-reference.org and\nallows players to be sorted by points, rebounds, and\nassists and displayed.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Save the .py files under Stats-Scraper and run it with python3. See requirements.txt for any module requirements and install them with pip</p>\n<p>Or use pip to install stats_scraper directly</p>\n<pre>pip install stats_scraper\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Code excerpt from __main__.py</p>\n<pre>from stats_scraper.scraper import Scraper\n\nscraper = Scraper()\n\nresult = scraper.find_player_by_name(\"Ivica Zubac\")\nprint(\"Printing result\\n\")\nfor p in result:\n    print(p)\n\nsorted_points = scraper.sort_by_points(\"SG\")\nprint(\"========Printing top scorers========\\n\")\nfor scores in sorted_points:\n    print(scores[0], scores[1])\n\nsorted_assists = scraper.sort_by_assists(\"PF\")\nprint(\"\\n\\n\\n=========Printing top 10 assisters========\\n\")\ncount = 0\nfor assists in sorted_assists:\n    if(count &gt;= 10):\n        break\n    print(assists[0], assists[1])\n    count += 1\n\nsorted_rebounds = scraper.sort_by_rebounds(\"PG\", \"SG\")\nprint(\"\\n\\n\\n=========Printing top 20 rebounders========\\n\")\ncount = 0\nfor rebounds in sorted_rebounds:\n    if(count &gt;= 20):\n        break\n    print(rebounds[0], rebounds[1])\n    count += 1\n</pre>\n</div>\n<div id=\"acknowledgment\">\n<h2>Acknowledgment</h2>\n<p>Thank you to Oscar Sanchez\u2019s article \u201cWeb Scraping NBA Stats\u201d\nfor part of the scraping code</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p><a href=\"https://choosealicense.com/licenses/mit/\" rel=\"nofollow\">MIT</a></p>\n</div>\n\n          </div>"}, "last_serial": 5185774, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "987b37763c6329681f636a6ff13d5613", "sha256": "1659eea94aa583eb5c3672fa90f21c4a82a51d023e899a68c3374d14203699ed"}, "downloads": -1, "filename": "stats_scraper-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "987b37763c6329681f636a6ff13d5613", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4943, "upload_time": "2019-04-25T02:42:09", "upload_time_iso_8601": "2019-04-25T02:42:09.898778Z", "url": "https://files.pythonhosted.org/packages/3b/85/1175ee750b7282e41b798cc8253883fc4945529c237296ad66933dfcc4e9/stats_scraper-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c44d27161c9d044bd77fb3e01758306", "sha256": "43c284426fb45b09d28a452a16d40ec9ad67a9e9128e1b7ad8fd0ea992cc54a2"}, "downloads": -1, "filename": "stats_scraper-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7c44d27161c9d044bd77fb3e01758306", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3934, "upload_time": "2019-04-25T02:42:14", "upload_time_iso_8601": "2019-04-25T02:42:14.058288Z", "url": "https://files.pythonhosted.org/packages/cd/9f/7ca636f80d89e391eec20fb7bba823dbfdc6326cc6bd083d022aa19cda7a/stats_scraper-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "987b37763c6329681f636a6ff13d5613", "sha256": "1659eea94aa583eb5c3672fa90f21c4a82a51d023e899a68c3374d14203699ed"}, "downloads": -1, "filename": "stats_scraper-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "987b37763c6329681f636a6ff13d5613", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4943, "upload_time": "2019-04-25T02:42:09", "upload_time_iso_8601": "2019-04-25T02:42:09.898778Z", "url": "https://files.pythonhosted.org/packages/3b/85/1175ee750b7282e41b798cc8253883fc4945529c237296ad66933dfcc4e9/stats_scraper-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c44d27161c9d044bd77fb3e01758306", "sha256": "43c284426fb45b09d28a452a16d40ec9ad67a9e9128e1b7ad8fd0ea992cc54a2"}, "downloads": -1, "filename": "stats_scraper-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7c44d27161c9d044bd77fb3e01758306", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3934, "upload_time": "2019-04-25T02:42:14", "upload_time_iso_8601": "2019-04-25T02:42:14.058288Z", "url": "https://files.pythonhosted.org/packages/cd/9f/7ca636f80d89e391eec20fb7bba823dbfdc6326cc6bd083d022aa19cda7a/stats_scraper-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:21 2020"}