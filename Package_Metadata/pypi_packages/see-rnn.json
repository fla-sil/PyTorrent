{"info": {"author": "OverLordGoldDragon", "author_email": "16495490+OverLordGoldDragon@users.noreply.github.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Software Development", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Utilities"], "description": "# See RNN\n\n[![Build Status](https://travis-ci.com/OverLordGoldDragon/see-rnn.svg?token=dGKzzAxzJjaRLzddNsCd&branch=master)](https://travis-ci.com/OverLordGoldDragon/see-rnn)\n[![Coverage Status](https://coveralls.io/repos/github/OverLordGoldDragon/see-rnn/badge.svg?branch=master&service=github&kill_cache=1)](https://coveralls.io/github/OverLordGoldDragon/see-rnn?branch=master)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/e15b1b772c3f4dc9ba7988784a2b9bf6)](https://www.codacy.com/manual/OverLordGoldDragon/see-rnn?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=OverLordGoldDragon/see-rnn&amp;utm_campaign=Badge_Grade)\n[![PyPI version](https://badge.fury.io/py/see-rnn.svg)](https://badge.fury.io/py/see-rnn)\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)\n\n![](https://img.shields.io/badge/keras-tensorflow-blue.svg)\n![](https://img.shields.io/badge/keras-tf.keras-blue.svg)\n![](https://img.shields.io/badge/keras-tf.keras/eager-blue.svg)\n![](https://img.shields.io/badge/keras-tf.keras/2.0-blue.svg)\n\nRNN weights, gradients, &amp; activations visualization in Keras &amp; TensorFlow (LSTM, GRU, SimpleRNN, CuDNN, & all others)\n\n<img src=\"https://user-images.githubusercontent.com/16495490/70570599-a6d18180-1bb5-11ea-8a0d-9c4ef43c69b1.png\" width=\"900\">\n<img src=\"https://user-images.githubusercontent.com/16495490/69359963-133a1e80-0ca3-11ea-9c9a-2c59baa112dd.png\" width=\"850\">\n\n## Features\n  - **Weights, gradients, activations** visualization\n  - **Kernel visuals**: kernel, recurrent kernel, and bias shown explicitly\n  - **Gate visuals**: gates in gated architectures (LSTM, GRU) shown explicitly\n  - **Channel visuals**: cell units (feature extractors) shown explicitly\n  - **General visuals**: methods also applicable to CNNs & others\n  - **Weight norm tracking**: useful for analyzing weight decay\n\n\n## Why use?\n\nIntrospection is a powerful tool for debugging, regularizing, and understanding neural networks; this repo's methods enable:\n\n - Monitoring **weights & activations progression** - how each changes epoch-to-epoch, iteration-to-iteration\n - Evaluating **learning effectiveness** - how well gradient backpropagates layer-to-layer, timestep-to-timestep\n - Assessing **layer health** - what percentage of neurons are \"dead\" or \"exploding\"\n - Tracking **weight decay** - how various schemes (e.g. l2 penalty) affect weight norms\n\nIt enables answering questions such as:\n - Is my RNN learning **long-term dependencies**? >> Monitor gradients: if a non-zero gradient flows through every timestep, then _every timestep contributes to learning_ - i.e., resultant gradients stem from accounting for every input timestep, so the _entire sequence influences weight updates_. Hence, an RNN _no longer ignores portions of long sequences_, and is forced to _learn from them_\n - Is my RNN learning **independent representations**? >> Monitor activations: if each channel's outputs are distinct and decorrelated, then the RNN extracts richly diverse features.\n - Why do I have **validation loss spikes**? >> Monitor all: val. spikes may stem from sharp changes in layer weights due to large gradients, which will visibly alter activation patterns; seeing the details can help inform a correction\n - Is my **weight decay excessive** or insufficient? >> Monitor weight norms: if values slash to many times less their usual values, decay might be excessive - or, if no effect is seen, increase decay\n\nFor further info on potential uses, see [this SO](https://stackoverflow.com/questions/48714407/rnn-regularization-which-component-to-regularize/58868383#58868383).\n\n## Installation\n\n`pip install see-rnn` or clone repository\n\n## To-do\n\nWill possibly implement:\n\n - [x] Weight norm inspection (all layers); see [here](https://stackoverflow.com/q/61481921/10133797)\n - [ ] Pytorch support\n - [ ] Interpretability visuals (e.g. saliency maps, adversarial attacks)\n - [ ] Tools for better probing backprop of `return_sequences=False`\n\n## Examples\n\n```python\n# for all examples\ngrads = get_gradients(model, 1, x, y)  # return_sequences=True,  layer index 1\ngrads = get_gradients(model, 2, x, y)  # return_sequences=False, layer index 2\nouts  = get_outputs(model, 1, x)       # return_sequences=True,  layer index 1\n# all examples use timesteps=100\n# NOTE: `title_mode` kwarg below was omitted for simplicity; for Gradient visuals, would set to 'grads'\n```\n\n<hr>\n\n**EX 1: bi-LSTM, 32 units** - activations, `activation='relu'`<br>\n`features_1D(outs[:1], share_xy=False)`<br>\n`features_1D(outs[:1], share_xy=True, y_zero=True)`\n\n - Each subplot is an independent RNN channel's output (`return_sequences=True`)\n - In this example, each channel/filter appears to extract complex independent features of varying bias, frequency, and probabilistic distribution\n - Note that `share_xy=False` better pronounces features' _shape_, whereas `=True` allows for an even comparison - but may greatly 'shrink' waveforms to appear flatlined (not shown here)\n\n<img src=\"https://i.stack.imgur.com/k7RrD.png\" width=\"800\">\n\n<img src=\"https://i.stack.imgur.com/HF8gH.png\" width=\"800\">\n\n<hr>\n\n**EX 2: one sample, uni-LSTM, 6 units** - gradients, `return_sequences=True`, trained for 20 iterations <br>\n`features_1D(grads[:1], n_rows=2)`\n\n - _Note_: gradients are to be read _right-to-left_, as they're computed (from last timestep to first)\n - Rightmost (latest) timesteps consistently have a higher gradient\n - **Vanishing gradient**: ~75% of leftmost timesteps have a zero gradient, indicating poor time dependency learning\n\n[![enter image description here][1]][1]\n\n<hr>\n\n**EX 3: all (16) samples, uni-LSTM, 6 units** -- `return_sequences=True`, trained for 20 iterations <br>\n`features_1D(grads, n_rows=2)`<br>\n`features_2D(grads, n_rows=4, norm=(-.01, .01))`\n\n - Each sample shown in a different color (but same color per sample across channels)\n - Some samples perform better than one shown above, but not by much\n - The heatmap plots channels (y-axis) vs. timesteps (x-axis); blue=-0.01, red=0.01, white=0 (gradient values)\n\n[![enter image description here][2]][2]\n[![enter image description here][3]][3]\n\n<hr>\n\n**EX 4: all (16) samples, uni-LSTM, 6 units** -- `return_sequences=True`, trained for 200 iterations <br>\n`features_1D(grads, n_rows=2)`<br>\n`features_2D(grads, n_rows=4, norm=(-.01, .01))`\n\n - Both plots show the LSTM performing clearly better after 180 additional iterations\n - Gradient still vanishes for about half the timesteps\n - All LSTM units better capture time dependencies of one particular sample (blue curve, first plot) - which we can tell from the heatmap to be the first sample. We can plot that sample vs. other samples to try to understand the difference\n\n[![enter image description here][4]][4]\n[![enter image description here][5]][5]\n\n<hr>\n\n**EX 5: 2D vs. 1D, uni-LSTM**: 256 units, `return_sequences=True`, trained for 200 iterations <br>\n`features_1D(grads[0, :, :])`<br>\n`features_2D(grads[:, :, 0], norm=(-.0001, .0001))`\n\n - 2D is better suited for comparing many channels across few samples\n - 1D is better suited for comparing many samples across a few channels\n\n[![enter image description here][6]][6]\n\n<hr>\n\n**EX 6: bi-GRU, 256 units (512 total)** -- `return_sequences=True`, trained for 400 iterations <br>\n`features_2D(grads[0], norm=(-.0001, .0001), reflect_half=True)`\n\n - Backward layer's gradients are flipped for consistency w.r.t. time axis\n - Plot reveals a lesser-known advantage of Bi-RNNs - _information utility_: the collective gradient covers about twice the data. _However_, this isn't free lunch: each layer is an independent feature extractor, so learning isn't really complemented\n - Lower `norm` for more units is expected, as approx. the same loss-derived gradient is being distributed across more parameters (hence the squared numeric average is less)\n\n<img src=\"https://i.stack.imgur.com/ueGVB.png\" width=\"420\">\n\n<hr>\n\n**EX 7: 0D, all (16) samples, uni-LSTM, 6 units** -- `return_sequences=False`, trained for 200 iterations<br>\n`features_0D(grads)`\n\n - `return_sequences=False` utilizes only the last timestep's gradient (which is still derived from all timesteps, unless using truncated BPTT), requiring a new approach\n - Plot color-codes each RNN unit consistently across samples for comparison (can use one color instead)\n - Evaluating gradient flow is less direct and more theoretically involved. One simple approach is to compare distributions at beginning vs. later in training: if the difference isn't significant, the RNN does poorly in learning long-term dependencies\n\n<img src=\"https://i.stack.imgur.com/693EO.png\" width=\"560\">\n\n<hr>\n\n**EX 8: LSTM vs. GRU vs. SimpleRNN, unidir, 256 units** -- `return_sequences=True`, trained for 250 iterations<br>\n`features_2D(grads, n_rows=8, norm=(-.0001, .0001), xy_ticks=[0,0], title_mode=False)`\n\n - _Note_: the comparison isn't very meaningful; each network thrives w/ different hyperparameters, whereas same ones were used for all. LSTM, for one, bears the most parameters per unit, drowning out SimpleRNN\n - In this setup, LSTM definitively stomps GRU and SimpleRNN\n\n[![enter image description here][7]][7]\n\n<hr>\n\n\n**EX 9: uni-LSTM, 256 units, weights** -- `batch_shape = (16, 100, 20)` (input)<br>\n`rnn_histogram(model, 'lstm', equate_axes=False, bias=False)`<br>\n`rnn_histogram(model, 'lstm', equate_axes=True,  bias=False)`<br>\n`rnn_heatmap(model, 'lstm')`\n\n - Top plot is a histogram subplot grid, showing weight distributions per kernel, and within each kernel, per gate\n - Second plot sets `equate_axes=True` for an even comparison across kernels and gates, improving quality of comparison, but potentially degrading visual appeal\n - Last plot is a heatmap of the same weights, with gate separations marked by vertical lines, and bias weights also included\n - Unlike histograms, the heatmap _preserves channel/context information_: input-to-hidden and hidden-to-hidden transforming matrices can be clearly distinguished\n - Note the large concentration of maximal values at the Forget gate; as trivia, in Keras (and usually), bias gates are all initialized to zeros, except the Forget bias, which is initialized to ones\n\n\n\n<img src=\"https://i.stack.imgur.com/1Deh4.png\" width=\"600\">\n\n<img src=\"https://i.stack.imgur.com/IZN6k.png\" width=\"600\">\n\n<img src=\"https://i.stack.imgur.com/E9GkQ.png\" width=\"620\">\n\n\n<hr>\n\n**EX 10: bi-CuDNNLSTM, 256 units, weights** -- `batch_shape = (16, 100, 16)` (input)<br>\n`rnn_histogram(model, 'bidir', equate_axes=2)`<br>\n`rnn_heatmap(model, 'bidir', norm=(-.8, .8))`\n\n - Bidirectional is supported by both; biases included in this example for histograms\n - Note again the bias heatmaps; they no longer appear to reside in the same locality as in EX 1. Indeed, `CuDNNLSTM` (and `CuDNNGRU`) biases are defined and initialized differently - something that can't be inferred from histograms\n\n<img src=\"https://i.stack.imgur.com/vkGiF.png\" width=\"900\">\n\n<img src=\"https://i.stack.imgur.com/gEjp0.png\" width=\"900\">\n\n<hr>\n\n**EX 11: uni-CuDNNGRU, 64 units, weights gradients** -- `batch_shape = (16, 100, 16)` (input)<br>\n`rnn_heatmap(model, 'gru', mode='grads', input_data=x, labels=y, cmap=None, absolute_value=True)`\n\n - We may wish to visualize _gradient intensity_, which can be done via `absolute_value=True` and a greyscale colormap\n - Gate separations are apparent even without explicit separating lines in this example:\n   - `New` is the most active kernel gate (input-to-hidden), suggesting more error correction on _permitting information flow_\n   - `Reset` is the least active recurrent gate (hidden-to-hidden), suggesting least error correction on memory-keeping\n\n<img src=\"https://i.stack.imgur.com/cwiAS.png\" width=\"600\">\n\n<hr>\n\n**EX 12: NaN detection: LSTM, 512 units, weights** -- `batch_shape = (16, 100, 16)` (input)\n\n - Both the heatmap and the histogram come with built-in NaN detection - kernel-, gate-, and direction-wise\n - Heatmap will print NaNs to console, whereas histogram will mark them directly on the plot\n - Both will set NaN values to zero before plotting; in example below, all related non-NaN weights were already zero\n\n<img src=\"https://i.stack.imgur.com/T6ZAa.png\" width=\"600\">\n\n<hr>\n\n**EX 13: Sparse Conv1D autoencoder weights** -- `w = layer.get_weights()[0]; w.shape == (16, 64, 128)`<br>\n`features_2D(w, n_rows=16, norm=(-.1, .1), tight=True, borderwidth=1, title_mode=title)`<br>\n`# title = \"((Layer Channels vs. Kernels) vs. Weights) vs. Input Channels -- norm = (-0.1, 0.1)\"`\n\n - One of stacked `Conv1D` sparse autoencoder layers; network trained with `Dropout(0.5, noise_shape=(batch_size, 1, channels))` (Spatial Dropout), encouraging sparse features which may benefit classification\n - Weights are seen to be 'sparse'; some are uniformly low, others uniformly large, others have bands of large weights among lows\n\n <img src=\"https://user-images.githubusercontent.com/16495490/74095140-fd9bfe80-4b05-11ea-9b86-20e918b91a4b.png\" width=\"600\">\n\n## Usage \n\n**QUICKSTART**: run [sandbox.py](https://github.com/OverLordGoldDragon/see-rnn/blob/master/sandbox.py), which includes all major examples and allows easy exploration of various plot configs.\n\n_Note_: if using `tensorflow.keras` imports, set `import os; os.environ[\"TF_KERAS\"]='1'`. Minimal example below.\n\n[visuals_gen.py](https://github.com/OverLordGoldDragon/see-rnn/blob/master/see_rnn/visuals_gen.py) functions can also be used to visualize `Conv1D` activations, gradients, or any other meaningfully-compatible data formats. Likewise, [inspect_gen.py](https://github.com/OverLordGoldDragon/see-rnn/blob/master/see_rnn/inspect_gen.py) also works for non-RNN layers.\n\n```python\nimport numpy as np\nfrom keras.layers import Input, LSTM\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom see_rnn import get_gradients, features_0D, features_1D, features_2D\n\ndef make_model(rnn_layer, batch_shape, units):\n    ipt = Input(batch_shape=batch_shape)\n    x   = rnn_layer(units, activation='tanh', return_sequences=True)(ipt)\n    out = rnn_layer(units, activation='tanh', return_sequences=False)(x)\n    model = Model(ipt, out)\n    model.compile(Adam(4e-3), 'mse')\n    return model\n\ndef make_data(batch_shape):\n    return np.random.randn(*batch_shape), \\\n           np.random.uniform(-1, 1, (batch_shape[0], units))\n\ndef train_model(model, iterations, batch_shape):\n    x, y = make_data(batch_shape)\n    for i in range(iterations):\n        model.train_on_batch(x, y)\n        print(end='.')  # progbar\n        if i % 40 == 0:\n            x, y = make_data(batch_shape)\n\nunits = 6\nbatch_shape = (16, 100, 2*units)\n\nmodel = make_model(LSTM, batch_shape, units)\ntrain_model(model, 300, batch_shape)\n\nx, y  = make_data(batch_shape)\ngrads_all  = get_gradients(model, 1, x, y)  # return_sequences=True,  layer index 1\ngrads_last = get_gradients(model, 2, x, y)  # return_sequences=False, layer index 2\n\nfeatures_1D(grads_all, n_rows=2, xy_ticks=[1,1])\nfeatures_2D(grads_all, n_rows=8, xy_ticks=[1,1], norm=(-.01, .01))\nfeatures_0D(grads_last)\n```\n\n\n\n  [1]: https://i.stack.imgur.com/PVoU0.png\n  [2]: https://i.stack.imgur.com/OaX6I.png\n  [3]: https://i.stack.imgur.com/RW24R.png\n  [4]: https://i.stack.imgur.com/SUIN3.png\n  [5]: https://i.stack.imgur.com/nsNR1.png\n  [6]: https://i.stack.imgur.com/Ci2AP.png\n  [7]: https://i.stack.imgur.com/vWgc8.png\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/OverLordGoldDragon/see-rnn", "keywords": "rnn tensorflow keras visualization deep-learning lstm gru", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "see-rnn", "package_url": "https://pypi.org/project/see-rnn/", "platform": "", "project_url": "https://pypi.org/project/see-rnn/", "project_urls": {"Homepage": "https://github.com/OverLordGoldDragon/see-rnn"}, "release_url": "https://pypi.org/project/see-rnn/1.13.1/", "requires_dist": ["numpy", "matplotlib", "tensorflow"], "requires_python": "", "summary": "RNN weights, gradients, & activations visualization in Keras & TensorFlow", "version": "1.13.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>See RNN</h1>\n<p><a href=\"https://travis-ci.com/OverLordGoldDragon/see-rnn\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/130254f192350d73f5e44e04096218e067950366/68747470733a2f2f7472617669732d63692e636f6d2f4f7665724c6f7264476f6c64447261676f6e2f7365652d726e6e2e7376673f746f6b656e3d64474b7a7a41787a4a6a61524c7a64644e734364266272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/github/OverLordGoldDragon/see-rnn?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/41968aebdb507cee23fe091e75d1a5a15d80fe00/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4f7665724c6f7264476f6c64447261676f6e2f7365652d726e6e2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562266b696c6c5f63616368653d31\"></a>\n<a href=\"https://www.codacy.com/manual/OverLordGoldDragon/see-rnn?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=OverLordGoldDragon/see-rnn&amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bb831c1445d9a8aae3dc66961e190ea8e98a8e21/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6531356231623737326333663464633962613739383837383461326239626636\"></a>\n<a href=\"https://badge.fury.io/py/see-rnn\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f50c2d12e5341055bb1e76fa38809669ab965ae2/68747470733a2f2f62616467652e667572792e696f2f70792f7365652d726e6e2e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5aab1d039acf22567ba072834df6bce204ac48ad/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d677265656e2e737667\"></a></p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e393eea6bde0401d67d8c1037f20197db5f67415/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6b657261732d74656e736f72666c6f772d626c75652e737667\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/10bcc5d5c79439ea8a8eed66fab216ba966761df/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6b657261732d74662e6b657261732d626c75652e737667\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/512a2743e8eb70e905cd9c53156b1207e6478fb0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6b657261732d74662e6b657261732f65616765722d626c75652e737667\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8c1a68578f6a20362355750942edb5bd69d0add/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6b657261732d74662e6b657261732f322e302d626c75652e737667\"></p>\n<p>RNN weights, gradients, &amp; activations visualization in Keras &amp; TensorFlow (LSTM, GRU, SimpleRNN, CuDNN, &amp; all others)</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b245099eb8514b1a56cbf9553a68c100167d9560/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31363439353439302f37303537303539392d61366431383138302d316262352d313165612d386130642d3963346566343363363962312e706e67\" width=\"900\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/011b9d4d4bce16cb68e92a04f4605d8086a3aab7/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31363439353439302f36393335393936332d31333361316538302d306361332d313165612d396339612d3263353962616131313264642e706e67\" width=\"850\">\n<h2>Features</h2>\n<ul>\n<li><strong>Weights, gradients, activations</strong> visualization</li>\n<li><strong>Kernel visuals</strong>: kernel, recurrent kernel, and bias shown explicitly</li>\n<li><strong>Gate visuals</strong>: gates in gated architectures (LSTM, GRU) shown explicitly</li>\n<li><strong>Channel visuals</strong>: cell units (feature extractors) shown explicitly</li>\n<li><strong>General visuals</strong>: methods also applicable to CNNs &amp; others</li>\n<li><strong>Weight norm tracking</strong>: useful for analyzing weight decay</li>\n</ul>\n<h2>Why use?</h2>\n<p>Introspection is a powerful tool for debugging, regularizing, and understanding neural networks; this repo's methods enable:</p>\n<ul>\n<li>Monitoring <strong>weights &amp; activations progression</strong> - how each changes epoch-to-epoch, iteration-to-iteration</li>\n<li>Evaluating <strong>learning effectiveness</strong> - how well gradient backpropagates layer-to-layer, timestep-to-timestep</li>\n<li>Assessing <strong>layer health</strong> - what percentage of neurons are \"dead\" or \"exploding\"</li>\n<li>Tracking <strong>weight decay</strong> - how various schemes (e.g. l2 penalty) affect weight norms</li>\n</ul>\n<p>It enables answering questions such as:</p>\n<ul>\n<li>Is my RNN learning <strong>long-term dependencies</strong>? &gt;&gt; Monitor gradients: if a non-zero gradient flows through every timestep, then <em>every timestep contributes to learning</em> - i.e., resultant gradients stem from accounting for every input timestep, so the <em>entire sequence influences weight updates</em>. Hence, an RNN <em>no longer ignores portions of long sequences</em>, and is forced to <em>learn from them</em></li>\n<li>Is my RNN learning <strong>independent representations</strong>? &gt;&gt; Monitor activations: if each channel's outputs are distinct and decorrelated, then the RNN extracts richly diverse features.</li>\n<li>Why do I have <strong>validation loss spikes</strong>? &gt;&gt; Monitor all: val. spikes may stem from sharp changes in layer weights due to large gradients, which will visibly alter activation patterns; seeing the details can help inform a correction</li>\n<li>Is my <strong>weight decay excessive</strong> or insufficient? &gt;&gt; Monitor weight norms: if values slash to many times less their usual values, decay might be excessive - or, if no effect is seen, increase decay</li>\n</ul>\n<p>For further info on potential uses, see <a href=\"https://stackoverflow.com/questions/48714407/rnn-regularization-which-component-to-regularize/58868383#58868383\" rel=\"nofollow\">this SO</a>.</p>\n<h2>Installation</h2>\n<p><code>pip install see-rnn</code> or clone repository</p>\n<h2>To-do</h2>\n<p>Will possibly implement:</p>\n<ul>\n<li>[x] Weight norm inspection (all layers); see <a href=\"https://stackoverflow.com/q/61481921/10133797\" rel=\"nofollow\">here</a></li>\n<li>[ ] Pytorch support</li>\n<li>[ ] Interpretability visuals (e.g. saliency maps, adversarial attacks)</li>\n<li>[ ] Tools for better probing backprop of <code>return_sequences=False</code></li>\n</ul>\n<h2>Examples</h2>\n<pre><span class=\"c1\"># for all examples</span>\n<span class=\"n\">grads</span> <span class=\"o\">=</span> <span class=\"n\">get_gradients</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  <span class=\"c1\"># return_sequences=True,  layer index 1</span>\n<span class=\"n\">grads</span> <span class=\"o\">=</span> <span class=\"n\">get_gradients</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  <span class=\"c1\"># return_sequences=False, layer index 2</span>\n<span class=\"n\">outs</span>  <span class=\"o\">=</span> <span class=\"n\">get_outputs</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">)</span>       <span class=\"c1\"># return_sequences=True,  layer index 1</span>\n<span class=\"c1\"># all examples use timesteps=100</span>\n<span class=\"c1\"># NOTE: `title_mode` kwarg below was omitted for simplicity; for Gradient visuals, would set to 'grads'</span>\n</pre>\n<hr>\n<p><strong>EX 1: bi-LSTM, 32 units</strong> - activations, <code>activation='relu'</code><br>\n<code>features_1D(outs[:1], share_xy=False)</code><br>\n<code>features_1D(outs[:1], share_xy=True, y_zero=True)</code></p>\n<ul>\n<li>Each subplot is an independent RNN channel's output (<code>return_sequences=True</code>)</li>\n<li>In this example, each channel/filter appears to extract complex independent features of varying bias, frequency, and probabilistic distribution</li>\n<li>Note that <code>share_xy=False</code> better pronounces features' <em>shape</em>, whereas <code>=True</code> allows for an even comparison - but may greatly 'shrink' waveforms to appear flatlined (not shown here)</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/579f167f1c0ddc74d44616fee29c736212b3a58a/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f6b375272442e706e67\" width=\"800\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/11678cf9329761152a32b887f541113010cb0c10/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f48463867482e706e67\" width=\"800\">\n<hr>\n<p><strong>EX 2: one sample, uni-LSTM, 6 units</strong> - gradients, <code>return_sequences=True</code>, trained for 20 iterations <br>\n<code>features_1D(grads[:1], n_rows=2)</code></p>\n<ul>\n<li><em>Note</em>: gradients are to be read <em>right-to-left</em>, as they're computed (from last timestep to first)</li>\n<li>Rightmost (latest) timesteps consistently have a higher gradient</li>\n<li><strong>Vanishing gradient</strong>: ~75% of leftmost timesteps have a zero gradient, indicating poor time dependency learning</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/PVoU0.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c84fa5f9744244354fa2aa3fc81c2a98c9751cfb/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f50566f55302e706e67\"></a></p>\n<hr>\n<p><strong>EX 3: all (16) samples, uni-LSTM, 6 units</strong> -- <code>return_sequences=True</code>, trained for 20 iterations <br>\n<code>features_1D(grads, n_rows=2)</code><br>\n<code>features_2D(grads, n_rows=4, norm=(-.01, .01))</code></p>\n<ul>\n<li>Each sample shown in a different color (but same color per sample across channels)</li>\n<li>Some samples perform better than one shown above, but not by much</li>\n<li>The heatmap plots channels (y-axis) vs. timesteps (x-axis); blue=-0.01, red=0.01, white=0 (gradient values)</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/OaX6I.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/37c5d2905184d6172c1b0070101bf151f5999d38/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f4f615836492e706e67\"></a>\n<a href=\"https://i.stack.imgur.com/RW24R.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1fed5cd3e504ec5544940154c8ee6f51ef5b633c/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f52573234522e706e67\"></a></p>\n<hr>\n<p><strong>EX 4: all (16) samples, uni-LSTM, 6 units</strong> -- <code>return_sequences=True</code>, trained for 200 iterations <br>\n<code>features_1D(grads, n_rows=2)</code><br>\n<code>features_2D(grads, n_rows=4, norm=(-.01, .01))</code></p>\n<ul>\n<li>Both plots show the LSTM performing clearly better after 180 additional iterations</li>\n<li>Gradient still vanishes for about half the timesteps</li>\n<li>All LSTM units better capture time dependencies of one particular sample (blue curve, first plot) - which we can tell from the heatmap to be the first sample. We can plot that sample vs. other samples to try to understand the difference</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/SUIN3.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80981385f2266562373d09269e444e8e3f5817bd/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f5355494e332e706e67\"></a>\n<a href=\"https://i.stack.imgur.com/nsNR1.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fee766fb82812f60e024f042466698b4a620eaa0/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f6e734e52312e706e67\"></a></p>\n<hr>\n<p><strong>EX 5: 2D vs. 1D, uni-LSTM</strong>: 256 units, <code>return_sequences=True</code>, trained for 200 iterations <br>\n<code>features_1D(grads[0, :, :])</code><br>\n<code>features_2D(grads[:, :, 0], norm=(-.0001, .0001))</code></p>\n<ul>\n<li>2D is better suited for comparing many channels across few samples</li>\n<li>1D is better suited for comparing many samples across a few channels</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/Ci2AP.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d5e7dda4ebcdb5578c2c7b5d449e32337fb2e518/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f43693241502e706e67\"></a></p>\n<hr>\n<p><strong>EX 6: bi-GRU, 256 units (512 total)</strong> -- <code>return_sequences=True</code>, trained for 400 iterations <br>\n<code>features_2D(grads[0], norm=(-.0001, .0001), reflect_half=True)</code></p>\n<ul>\n<li>Backward layer's gradients are flipped for consistency w.r.t. time axis</li>\n<li>Plot reveals a lesser-known advantage of Bi-RNNs - <em>information utility</em>: the collective gradient covers about twice the data. <em>However</em>, this isn't free lunch: each layer is an independent feature extractor, so learning isn't really complemented</li>\n<li>Lower <code>norm</code> for more units is expected, as approx. the same loss-derived gradient is being distributed across more parameters (hence the squared numeric average is less)</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4ddbb3926ce0bcfa7137c00db7393df3353d18b2/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f75654756422e706e67\" width=\"420\">\n<hr>\n<p><strong>EX 7: 0D, all (16) samples, uni-LSTM, 6 units</strong> -- <code>return_sequences=False</code>, trained for 200 iterations<br>\n<code>features_0D(grads)</code></p>\n<ul>\n<li><code>return_sequences=False</code> utilizes only the last timestep's gradient (which is still derived from all timesteps, unless using truncated BPTT), requiring a new approach</li>\n<li>Plot color-codes each RNN unit consistently across samples for comparison (can use one color instead)</li>\n<li>Evaluating gradient flow is less direct and more theoretically involved. One simple approach is to compare distributions at beginning vs. later in training: if the difference isn't significant, the RNN does poorly in learning long-term dependencies</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f83a254ad38be80e73bfbb7bfa7cc2c2f5bf6161/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f363933454f2e706e67\" width=\"560\">\n<hr>\n<p><strong>EX 8: LSTM vs. GRU vs. SimpleRNN, unidir, 256 units</strong> -- <code>return_sequences=True</code>, trained for 250 iterations<br>\n<code>features_2D(grads, n_rows=8, norm=(-.0001, .0001), xy_ticks=[0,0], title_mode=False)</code></p>\n<ul>\n<li><em>Note</em>: the comparison isn't very meaningful; each network thrives w/ different hyperparameters, whereas same ones were used for all. LSTM, for one, bears the most parameters per unit, drowning out SimpleRNN</li>\n<li>In this setup, LSTM definitively stomps GRU and SimpleRNN</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/vWgc8.png\" rel=\"nofollow\"><img alt=\"enter image description here\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b417e2b925b3eba5c66406d6266fef6d2bfbd105/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f76576763382e706e67\"></a></p>\n<hr>\n<p><strong>EX 9: uni-LSTM, 256 units, weights</strong> -- <code>batch_shape = (16, 100, 20)</code> (input)<br>\n<code>rnn_histogram(model, 'lstm', equate_axes=False, bias=False)</code><br>\n<code>rnn_histogram(model, 'lstm', equate_axes=True, bias=False)</code><br>\n<code>rnn_heatmap(model, 'lstm')</code></p>\n<ul>\n<li>Top plot is a histogram subplot grid, showing weight distributions per kernel, and within each kernel, per gate</li>\n<li>Second plot sets <code>equate_axes=True</code> for an even comparison across kernels and gates, improving quality of comparison, but potentially degrading visual appeal</li>\n<li>Last plot is a heatmap of the same weights, with gate separations marked by vertical lines, and bias weights also included</li>\n<li>Unlike histograms, the heatmap <em>preserves channel/context information</em>: input-to-hidden and hidden-to-hidden transforming matrices can be clearly distinguished</li>\n<li>Note the large concentration of maximal values at the Forget gate; as trivia, in Keras (and usually), bias gates are all initialized to zeros, except the Forget bias, which is initialized to ones</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9847f7fa0ded59a4c1038f37ebb9fc3c4567336c/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f31446568342e706e67\" width=\"600\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ca69d9c22cc30e579e4ec34c1773340b84f44a57/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f495a4e366b2e706e67\" width=\"600\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/29aa6b02e7219435460492cf3911b0457e789e6d/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f4539476b512e706e67\" width=\"620\">\n<hr>\n<p><strong>EX 10: bi-CuDNNLSTM, 256 units, weights</strong> -- <code>batch_shape = (16, 100, 16)</code> (input)<br>\n<code>rnn_histogram(model, 'bidir', equate_axes=2)</code><br>\n<code>rnn_heatmap(model, 'bidir', norm=(-.8, .8))</code></p>\n<ul>\n<li>Bidirectional is supported by both; biases included in this example for histograms</li>\n<li>Note again the bias heatmaps; they no longer appear to reside in the same locality as in EX 1. Indeed, <code>CuDNNLSTM</code> (and <code>CuDNNGRU</code>) biases are defined and initialized differently - something that can't be inferred from histograms</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4805955e0dce87c0f5ff770f6e53784c24904a31/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f766b4769462e706e67\" width=\"900\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/08a264fb810afae9c806be01b7ecb7536332927d/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f67456a70302e706e67\" width=\"900\">\n<hr>\n<p><strong>EX 11: uni-CuDNNGRU, 64 units, weights gradients</strong> -- <code>batch_shape = (16, 100, 16)</code> (input)<br>\n<code>rnn_heatmap(model, 'gru', mode='grads', input_data=x, labels=y, cmap=None, absolute_value=True)</code></p>\n<ul>\n<li>We may wish to visualize <em>gradient intensity</em>, which can be done via <code>absolute_value=True</code> and a greyscale colormap</li>\n<li>Gate separations are apparent even without explicit separating lines in this example:\n<ul>\n<li><code>New</code> is the most active kernel gate (input-to-hidden), suggesting more error correction on <em>permitting information flow</em></li>\n<li><code>Reset</code> is the least active recurrent gate (hidden-to-hidden), suggesting least error correction on memory-keeping</li>\n</ul>\n</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/da04b5c40eb04924b2383114222689dcbfdc1bd8/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f63776941532e706e67\" width=\"600\">\n<hr>\n<p><strong>EX 12: NaN detection: LSTM, 512 units, weights</strong> -- <code>batch_shape = (16, 100, 16)</code> (input)</p>\n<ul>\n<li>Both the heatmap and the histogram come with built-in NaN detection - kernel-, gate-, and direction-wise</li>\n<li>Heatmap will print NaNs to console, whereas histogram will mark them directly on the plot</li>\n<li>Both will set NaN values to zero before plotting; in example below, all related non-NaN weights were already zero</li>\n</ul>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d7e6023c77cf38f5354213dab5312eff8dd38195/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f54365a41612e706e67\" width=\"600\">\n<hr>\n<p><strong>EX 13: Sparse Conv1D autoencoder weights</strong> -- <code>w = layer.get_weights()[0]; w.shape == (16, 64, 128)</code><br>\n<code>features_2D(w, n_rows=16, norm=(-.1, .1), tight=True, borderwidth=1, title_mode=title)</code><br>\n<code># title = \"((Layer Channels vs. Kernels) vs. Weights) vs. Input Channels -- norm = (-0.1, 0.1)\"</code></p>\n<ul>\n<li>One of stacked <code>Conv1D</code> sparse autoencoder layers; network trained with <code>Dropout(0.5, noise_shape=(batch_size, 1, channels))</code> (Spatial Dropout), encouraging sparse features which may benefit classification</li>\n<li>Weights are seen to be 'sparse'; some are uniformly low, others uniformly large, others have bands of large weights among lows</li>\n</ul>\n <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9eab0ae22f52ea62d39afbba7933911e78a1a302/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31363439353439302f37343039353134302d66643962666538302d346230352d313165612d396238362d3230653931386239316134622e706e67\" width=\"600\">\n<h2>Usage</h2>\n<p><strong>QUICKSTART</strong>: run <a href=\"https://github.com/OverLordGoldDragon/see-rnn/blob/master/sandbox.py\" rel=\"nofollow\">sandbox.py</a>, which includes all major examples and allows easy exploration of various plot configs.</p>\n<p><em>Note</em>: if using <code>tensorflow.keras</code> imports, set <code>import os; os.environ[\"TF_KERAS\"]='1'</code>. Minimal example below.</p>\n<p><a href=\"https://github.com/OverLordGoldDragon/see-rnn/blob/master/see_rnn/visuals_gen.py\" rel=\"nofollow\">visuals_gen.py</a> functions can also be used to visualize <code>Conv1D</code> activations, gradients, or any other meaningfully-compatible data formats. Likewise, <a href=\"https://github.com/OverLordGoldDragon/see-rnn/blob/master/see_rnn/inspect_gen.py\" rel=\"nofollow\">inspect_gen.py</a> also works for non-RNN layers.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.layers</span> <span class=\"kn\">import</span> <span class=\"n\">Input</span><span class=\"p\">,</span> <span class=\"n\">LSTM</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.models</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.optimizers</span> <span class=\"kn\">import</span> <span class=\"n\">Adam</span>\n<span class=\"kn\">from</span> <span class=\"nn\">see_rnn</span> <span class=\"kn\">import</span> <span class=\"n\">get_gradients</span><span class=\"p\">,</span> <span class=\"n\">features_0D</span><span class=\"p\">,</span> <span class=\"n\">features_1D</span><span class=\"p\">,</span> <span class=\"n\">features_2D</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">make_model</span><span class=\"p\">(</span><span class=\"n\">rnn_layer</span><span class=\"p\">,</span> <span class=\"n\">batch_shape</span><span class=\"p\">,</span> <span class=\"n\">units</span><span class=\"p\">):</span>\n    <span class=\"n\">ipt</span> <span class=\"o\">=</span> <span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">batch_shape</span><span class=\"o\">=</span><span class=\"n\">batch_shape</span><span class=\"p\">)</span>\n    <span class=\"n\">x</span>   <span class=\"o\">=</span> <span class=\"n\">rnn_layer</span><span class=\"p\">(</span><span class=\"n\">units</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'tanh'</span><span class=\"p\">,</span> <span class=\"n\">return_sequences</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)(</span><span class=\"n\">ipt</span><span class=\"p\">)</span>\n    <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">rnn_layer</span><span class=\"p\">(</span><span class=\"n\">units</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'tanh'</span><span class=\"p\">,</span> <span class=\"n\">return_sequences</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">ipt</span><span class=\"p\">,</span> <span class=\"n\">out</span><span class=\"p\">)</span>\n    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"mf\">4e-3</span><span class=\"p\">),</span> <span class=\"s1\">'mse'</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">model</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">make_data</span><span class=\"p\">(</span><span class=\"n\">batch_shape</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">batch_shape</span><span class=\"p\">),</span> \\\n           <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">uniform</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">batch_shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">units</span><span class=\"p\">))</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">train_model</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">iterations</span><span class=\"p\">,</span> <span class=\"n\">batch_shape</span><span class=\"p\">):</span>\n    <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">make_data</span><span class=\"p\">(</span><span class=\"n\">batch_shape</span><span class=\"p\">)</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">iterations</span><span class=\"p\">):</span>\n        <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train_on_batch</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s1\">'.'</span><span class=\"p\">)</span>  <span class=\"c1\"># progbar</span>\n        <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">%</span> <span class=\"mi\">40</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n            <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">make_data</span><span class=\"p\">(</span><span class=\"n\">batch_shape</span><span class=\"p\">)</span>\n\n<span class=\"n\">units</span> <span class=\"o\">=</span> <span class=\"mi\">6</span>\n<span class=\"n\">batch_shape</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"n\">units</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">make_model</span><span class=\"p\">(</span><span class=\"n\">LSTM</span><span class=\"p\">,</span> <span class=\"n\">batch_shape</span><span class=\"p\">,</span> <span class=\"n\">units</span><span class=\"p\">)</span>\n<span class=\"n\">train_model</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"n\">batch_shape</span><span class=\"p\">)</span>\n\n<span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span>  <span class=\"o\">=</span> <span class=\"n\">make_data</span><span class=\"p\">(</span><span class=\"n\">batch_shape</span><span class=\"p\">)</span>\n<span class=\"n\">grads_all</span>  <span class=\"o\">=</span> <span class=\"n\">get_gradients</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  <span class=\"c1\"># return_sequences=True,  layer index 1</span>\n<span class=\"n\">grads_last</span> <span class=\"o\">=</span> <span class=\"n\">get_gradients</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>  <span class=\"c1\"># return_sequences=False, layer index 2</span>\n\n<span class=\"n\">features_1D</span><span class=\"p\">(</span><span class=\"n\">grads_all</span><span class=\"p\">,</span> <span class=\"n\">n_rows</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">xy_ticks</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n<span class=\"n\">features_2D</span><span class=\"p\">(</span><span class=\"n\">grads_all</span><span class=\"p\">,</span> <span class=\"n\">n_rows</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">xy_ticks</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">norm</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"o\">-.</span><span class=\"mi\">01</span><span class=\"p\">,</span> <span class=\"o\">.</span><span class=\"mi\">01</span><span class=\"p\">))</span>\n<span class=\"n\">features_0D</span><span class=\"p\">(</span><span class=\"n\">grads_last</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 7192751, "releases": {"1.1": [{"comment_text": "", "digests": {"md5": "69089f2d181f005c0ac6c5d9df3ee123", "sha256": "72f69e83c5b5733a6cde3e969e82a688ca67af3dbf9daf1d4bd056d7a4f6a0f6"}, "downloads": -1, "filename": "see_rnn-1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "69089f2d181f005c0ac6c5d9df3ee123", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 29431, "upload_time": "2020-04-28T14:13:33", "upload_time_iso_8601": "2020-04-28T14:13:33.430111Z", "url": "https://files.pythonhosted.org/packages/e8/e2/0565170530bb682fdf3ec905f138edfea774f6f8672bbacea78ce75f24a2/see_rnn-1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ccea5a21faf673c47b6bc6001fd98488", "sha256": "239862cfd11991d774b066d74c9906c07908724790dc637716c4ddd0f519574a"}, "downloads": -1, "filename": "see-rnn-1.1.tar.gz", "has_sig": false, "md5_digest": "ccea5a21faf673c47b6bc6001fd98488", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33043, "upload_time": "2020-04-28T14:13:35", "upload_time_iso_8601": "2020-04-28T14:13:35.765506Z", "url": "https://files.pythonhosted.org/packages/d5/52/508f62b842d0d77be607e27e7b564478b103dab4987d74a5651f9610e964/see-rnn-1.1.tar.gz", "yanked": false}], "1.11": [{"comment_text": "", "digests": {"md5": "6c8c0d41e4a724aab2783b86f5fd965a", "sha256": "28fd39c82460b0da8ea9625be06bd48803a28652e06e77ad44c499cea18c3ce8"}, "downloads": -1, "filename": "see_rnn-1.11-py3-none-any.whl", "has_sig": false, "md5_digest": "6c8c0d41e4a724aab2783b86f5fd965a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 29725, "upload_time": "2020-04-30T17:12:57", "upload_time_iso_8601": "2020-04-30T17:12:57.480273Z", "url": "https://files.pythonhosted.org/packages/16/cc/380fd5db7200737c743c91c9912c6db5a1f030371618bb5fd83b70bd7774/see_rnn-1.11-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc4e6c5d43055031431ecd912fc50127", "sha256": "0f34507c2d7d9bb7ed7315cd3a257cec5511605a65a95e6abe54a69d52e1e7a8"}, "downloads": -1, "filename": "see-rnn-1.11.tar.gz", "has_sig": false, "md5_digest": "fc4e6c5d43055031431ecd912fc50127", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33373, "upload_time": "2020-04-30T17:12:58", "upload_time_iso_8601": "2020-04-30T17:12:58.840715Z", "url": "https://files.pythonhosted.org/packages/67/98/06cad59e79ed304ba08d62ce27e0767e3082904d6f0381bd9d3cfd687289/see-rnn-1.11.tar.gz", "yanked": false}], "1.12": [{"comment_text": "", "digests": {"md5": "f230798762a7e59a48b5326aa4f55898", "sha256": "eaa8513ae459b24b04a4d490076b81febb7f3b0576b381f3528395503c2cbb5a"}, "downloads": -1, "filename": "see_rnn-1.12-py3-none-any.whl", "has_sig": false, "md5_digest": "f230798762a7e59a48b5326aa4f55898", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 30498, "upload_time": "2020-05-03T04:46:56", "upload_time_iso_8601": "2020-05-03T04:46:56.396662Z", "url": "https://files.pythonhosted.org/packages/a6/47/f13eaa1dd3da46bd59202796c765391f7a6fc7c88d163bf2bf7a67135d38/see_rnn-1.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f0d234105d050fc45e457b1447f7c2de", "sha256": "0a90c9263d8a83fc99957e802184f5f4de1b7155e2a4a7739eef7484150f39ff"}, "downloads": -1, "filename": "see-rnn-1.12.tar.gz", "has_sig": false, "md5_digest": "f0d234105d050fc45e457b1447f7c2de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34178, "upload_time": "2020-05-03T04:46:57", "upload_time_iso_8601": "2020-05-03T04:46:57.642378Z", "url": "https://files.pythonhosted.org/packages/a3/98/df9a8c5846c7373f7210b946e72ab93a49562ef97af54ed57fd0b908ceb8/see-rnn-1.12.tar.gz", "yanked": false}], "1.13": [{"comment_text": "", "digests": {"md5": "1b36394e652e80ea6312d01303ec8345", "sha256": "4d850789f706a40e9ea19fc12d8ad8705c86b9c5e65ddc9883fd73025a1b24f7"}, "downloads": -1, "filename": "see_rnn-1.13-py3-none-any.whl", "has_sig": false, "md5_digest": "1b36394e652e80ea6312d01303ec8345", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31962, "upload_time": "2020-05-07T20:22:38", "upload_time_iso_8601": "2020-05-07T20:22:38.145186Z", "url": "https://files.pythonhosted.org/packages/53/fd/b302a0b32a18a8d0802def91ae375fd72458ec83b9c33abbb67b04f2fbf8/see_rnn-1.13-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c6c38617b077267d77b81de4eb53b435", "sha256": "643b34147b180b816220e1688c92c0a7f35f54e4b61696ae68ec683deef49dfe"}, "downloads": -1, "filename": "see-rnn-1.13.tar.gz", "has_sig": false, "md5_digest": "c6c38617b077267d77b81de4eb53b435", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35505, "upload_time": "2020-05-07T20:22:39", "upload_time_iso_8601": "2020-05-07T20:22:39.843620Z", "url": "https://files.pythonhosted.org/packages/af/5f/db1a8011a3ee885e45a189a71d373fe052a8e448d6f82a34e3f0a3f8f828/see-rnn-1.13.tar.gz", "yanked": false}], "1.13.1": [{"comment_text": "", "digests": {"md5": "48859ec8aa758d83be1a80a5c38f9f29", "sha256": "c82a6e4fd98ba66abe46553a595e7326df111e8852f8c3a1c37fee864cd16f84"}, "downloads": -1, "filename": "see_rnn-1.13.1-py3-none-any.whl", "has_sig": false, "md5_digest": "48859ec8aa758d83be1a80a5c38f9f29", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31991, "upload_time": "2020-05-07T22:38:44", "upload_time_iso_8601": "2020-05-07T22:38:44.237318Z", "url": "https://files.pythonhosted.org/packages/09/0c/f46a7b8db7fba9327f0859a723628dd6258d2672c9310f1c8a4f50559e74/see_rnn-1.13.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "78769cdc69a73feebbb83cf10065cd82", "sha256": "1443a515e531a1fe1c4cf38f48a4cb3cb766acbeae1d45151ac47f878b514255"}, "downloads": -1, "filename": "see-rnn-1.13.1.tar.gz", "has_sig": false, "md5_digest": "78769cdc69a73feebbb83cf10065cd82", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35519, "upload_time": "2020-05-07T22:38:45", "upload_time_iso_8601": "2020-05-07T22:38:45.570910Z", "url": "https://files.pythonhosted.org/packages/d5/ad/449da6226b772f0278c6fbca2d331b18bb9e051c76504208fa53761ac6cc/see-rnn-1.13.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "48859ec8aa758d83be1a80a5c38f9f29", "sha256": "c82a6e4fd98ba66abe46553a595e7326df111e8852f8c3a1c37fee864cd16f84"}, "downloads": -1, "filename": "see_rnn-1.13.1-py3-none-any.whl", "has_sig": false, "md5_digest": "48859ec8aa758d83be1a80a5c38f9f29", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 31991, "upload_time": "2020-05-07T22:38:44", "upload_time_iso_8601": "2020-05-07T22:38:44.237318Z", "url": "https://files.pythonhosted.org/packages/09/0c/f46a7b8db7fba9327f0859a723628dd6258d2672c9310f1c8a4f50559e74/see_rnn-1.13.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "78769cdc69a73feebbb83cf10065cd82", "sha256": "1443a515e531a1fe1c4cf38f48a4cb3cb766acbeae1d45151ac47f878b514255"}, "downloads": -1, "filename": "see-rnn-1.13.1.tar.gz", "has_sig": false, "md5_digest": "78769cdc69a73feebbb83cf10065cd82", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35519, "upload_time": "2020-05-07T22:38:45", "upload_time_iso_8601": "2020-05-07T22:38:45.570910Z", "url": "https://files.pythonhosted.org/packages/d5/ad/449da6226b772f0278c6fbca2d331b18bb9e051c76504208fa53761ac6cc/see-rnn-1.13.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:46 2020"}