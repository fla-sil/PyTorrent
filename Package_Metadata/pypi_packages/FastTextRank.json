{"info": {"author": "Edward", "author_email": "artistscript@outlook.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation", "Topic :: Software Development :: Libraries"], "description": "# FastTextRank\nExtract abstracts and keywords from Chinese text, use *optimized iterative algorithms* to improve running **speed**, and *selectively use word vectors* to improve **accuracy**.\n## PageRank\nPageRank is a website page ranking algorithm from Google.<br/>\nPageRank was originally used to calculate the importance of web pages. The entire www can be seen as a directed graph, and the node is a web page.<br/>\nThis algorithm can caculate all node's importance by their connections.<br/>\n* My algorithm changed the iterative algorithm to make the algorithm much faster, it costs 10ms per article, on the mean while TextRank4ZH costs 80ms on my data.<br/>\n* My algorithm also use word2vec to make the abstract more accurate, but it will cost more time to run the algorithm. Using word2vec costs 40ms per article on the same traning data.\n\n## W2VTextRank4Sentence\n### Introduction\n1. Cut article into sentence\n2. Calculate similarity between sentences:\n   * Using word vectors' cosine similarity\n   * Using two sentences' common words\n3. Build a graph by sentences' similarity\n4. Caculate the importance of each sentence by improved iterative algorithm\n5. Get the abstract\n### API\n* use_stopword: boolean, default True\n* stop_words_file: str, default None.\nThe stop words file you want to use. If it is None, you will use this package's stop words.\n* use_w2v: boolean, default False\nIf it is True, you must input passing dict_path parameter.\n* dict_path: str, default None.\n* max_iter:maximum iteration round\n* tol: maximum tolerance error\n\n## W2VTextRank4Word\n\n### Introduction\n1. Cut artile into word\n2. Calculate similarity between word: \n   If two words are all in window distance, then the graph's side of this two word add 1.0. Window is set by user.\n3. Build a graph by word' similarity\n4. Caculate the importance of each word by improved iterative algorithm\n5. Get the key word\n\n### API\n* use_stopword=boolean, default True\n* stop_words_file=str, default None.\nThe stop words file you want to use. If it is None, you will use this package's stop words.\n* max_iter=maximum iteration round\n* tol=maximum tolerance error\n* window=int, default 2\nThe window to determine if two words are related", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ArtistScript/FastTextRank", "keywords": "", "license": "BSD License", "maintainer": "", "maintainer_email": "", "name": "FastTextRank", "package_url": "https://pypi.org/project/FastTextRank/", "platform": "all", "project_url": "https://pypi.org/project/FastTextRank/", "project_urls": {"Homepage": "https://github.com/ArtistScript/FastTextRank"}, "release_url": "https://pypi.org/project/FastTextRank/1.4/", "requires_dist": null, "requires_python": "", "summary": "Extract abstracts and keywords from Chinese text", "version": "1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            # FastTextRank<br>Extract abstracts and keywords from Chinese text, use *optimized iterative algorithms* to improve running **speed**, and *selectively use word vectors* to improve **accuracy**.<br>## PageRank<br>PageRank is a website page ranking algorithm from Google.&lt;br/&gt;<br>PageRank was originally used to calculate the importance of web pages. The entire www can be seen as a directed graph, and the node is a web page.&lt;br/&gt;<br>This algorithm can caculate all node's importance by their connections.&lt;br/&gt;<br>* My algorithm changed the iterative algorithm to make the algorithm much faster, it costs 10ms per article, on the mean while TextRank4ZH costs 80ms on my data.&lt;br/&gt;<br>* My algorithm also use word2vec to make the abstract more accurate, but it will cost more time to run the algorithm. Using word2vec costs 40ms per article on the same traning data.<br><br>## W2VTextRank4Sentence<br>### Introduction<br>1. Cut article into sentence<br>2. Calculate similarity between sentences:<br>   * Using word vectors' cosine similarity<br>   * Using two sentences' common words<br>3. Build a graph by sentences' similarity<br>4. Caculate the importance of each sentence by improved iterative algorithm<br>5. Get the abstract<br>### API<br>* use_stopword: boolean, default True<br>* stop_words_file: str, default None.<br>The stop words file you want to use. If it is None, you will use this package's stop words.<br>* use_w2v: boolean, default False<br>If it is True, you must input passing dict_path parameter.<br>* dict_path: str, default None.<br>* max_iter:maximum iteration round<br>* tol: maximum tolerance error<br><br>## W2VTextRank4Word<br><br>### Introduction<br>1. Cut artile into word<br>2. Calculate similarity between word: <br>   If two words are all in window distance, then the graph's side of this two word add 1.0. Window is set by user.<br>3. Build a graph by word' similarity<br>4. Caculate the importance of each word by improved iterative algorithm<br>5. Get the key word<br><br>### API<br>* use_stopword=boolean, default True<br>* stop_words_file=str, default None.<br>The stop words file you want to use. If it is None, you will use this package's stop words.<br>* max_iter=maximum iteration round<br>* tol=maximum tolerance error<br>* window=int, default 2<br>The window to determine if two words are related\n          </div>"}, "last_serial": 4750110, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "1405618c237435a87e79b76da69d0e09", "sha256": "e2adc7d116ac1230a0b77456f724493deb643c5f1ecaf7bd30d7a3753bda1e7b"}, "downloads": -1, "filename": "FastTextRank-1.0.tar.gz", "has_sig": false, "md5_digest": "1405618c237435a87e79b76da69d0e09", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6236, "upload_time": "2018-08-03T09:44:26", "upload_time_iso_8601": "2018-08-03T09:44:26.240690Z", "url": "https://files.pythonhosted.org/packages/3b/c4/8138fbae7a8e3bdfd2735e97509057df23dd8fa3c345e17389c3b778d82b/FastTextRank-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "5fad7f580ed3fc55785bb44589e76b8f", "sha256": "13a75d3a934abf9569b037ab64f484a92fb4be6efb345d35baada1e3fd349af2"}, "downloads": -1, "filename": "FastTextRank-1.1.tar.gz", "has_sig": false, "md5_digest": "5fad7f580ed3fc55785bb44589e76b8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6241, "upload_time": "2018-12-19T08:53:20", "upload_time_iso_8601": "2018-12-19T08:53:20.845364Z", "url": "https://files.pythonhosted.org/packages/1e/bf/faa0024fd4bb665fbdad0f4c8d5eba6e66aa8d522cf767c1a80095169169/FastTextRank-1.1.tar.gz", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "13217a30f9ae56e849886000124e0fe9", "sha256": "48484dbc2d2c50b8b84b3daf0fe4d869a448b7f13519fd3e4ad09ab42e2dfb0d"}, "downloads": -1, "filename": "FastTextRank-1.2.zip", "has_sig": false, "md5_digest": "13217a30f9ae56e849886000124e0fe9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11325, "upload_time": "2019-01-28T12:51:29", "upload_time_iso_8601": "2019-01-28T12:51:29.059465Z", "url": "https://files.pythonhosted.org/packages/a8/af/c679149c11b504f125e8381da17988bff702e21d5f97b461bbdd63743249/FastTextRank-1.2.zip", "yanked": false}], "1.3": [{"comment_text": "", "digests": {"md5": "3e2f82ad116eb3038ff69bfba2bb4a97", "sha256": "44ff5d7c5f2b70625e8c99957cb988c14faeb1c3de16804eae0de1aaae364c29"}, "downloads": -1, "filename": "FastTextRank-1.3.zip", "has_sig": false, "md5_digest": "3e2f82ad116eb3038ff69bfba2bb4a97", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11323, "upload_time": "2019-01-28T12:55:55", "upload_time_iso_8601": "2019-01-28T12:55:55.341253Z", "url": "https://files.pythonhosted.org/packages/a0/e1/f48434b849a53cfe82f1632b95b8e14fed7de27b41cfbb6294997b32322b/FastTextRank-1.3.zip", "yanked": false}], "1.4": [{"comment_text": "", "digests": {"md5": "c885aaa71181778c3b25a2625c7f9baf", "sha256": "b90ab8b86bcf47807e6fcae38c524cca5a0e139c634afb23e20c831fdfb6e021"}, "downloads": -1, "filename": "FastTextRank-1.4.zip", "has_sig": false, "md5_digest": "c885aaa71181778c3b25a2625c7f9baf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11328, "upload_time": "2019-01-28T13:00:40", "upload_time_iso_8601": "2019-01-28T13:00:40.998805Z", "url": "https://files.pythonhosted.org/packages/d9/09/b384301bcf578f718d622630a5529dfe863ae546a522c99bac26ab65b2dd/FastTextRank-1.4.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c885aaa71181778c3b25a2625c7f9baf", "sha256": "b90ab8b86bcf47807e6fcae38c524cca5a0e139c634afb23e20c831fdfb6e021"}, "downloads": -1, "filename": "FastTextRank-1.4.zip", "has_sig": false, "md5_digest": "c885aaa71181778c3b25a2625c7f9baf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11328, "upload_time": "2019-01-28T13:00:40", "upload_time_iso_8601": "2019-01-28T13:00:40.998805Z", "url": "https://files.pythonhosted.org/packages/d9/09/b384301bcf578f718d622630a5529dfe863ae546a522c99bac26ab65b2dd/FastTextRank-1.4.zip", "yanked": false}], "timestamp": "Fri May  8 00:43:23 2020"}