{"info": {"author": "Avishek Das", "author_email": "avishek.das.ayan@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Bangla Feature Extractor(BFE)\n\nBFE is a Bangla Natural Language Processing based feature extractor.\n\n\n## Current Features\n\n  1. [CountVectorizer](#1-countvectorizer)\n  2. [TfIdf](#2-tfidf)\n  3. [Word Embedding](#3-word-embedding)\n      * [Word2Vec](#word2vec)\n      * [FastText](#fasttext)\n\n## Installation\n```\npip install bfe\n```\n## Example\n### 1. CountVectorizer\n  - Fit n Transform\n  - Transform\n  - Get Wordset\n\n**Fit n Transform**\n```py\nfrom bfe import CountVectorizer\nct = CountVectorizer()\nX = ct.fit_transform(X) # X is the word features\n#Output: the countVectorized matrix form of given features\n```\n\n**Transform**\n```py\nfrom bfe import CountVectorizer\nct = CountVectorizer()\nget_mat = ct.transform(\"\u09b0\u09be\u09b9\u09be\u09a4\")\n#Output: the countVectorized matrix form of given word\n```\n\n**Get Wordset**\n```py\nfrom bfe import CountVectorizer\nct = CountVectorizer()\nct.get_wordSet()\n#Output: get the raw wordset used in training model\n```\n\n### 2. TfIdf\n  - Fit n Transform\n  - Transform\n  - Coefficients\n\n **Fit n Transform**\n```py\nfrom bfe import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\", \"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"]\nmatrix1 = k.fit_transform(doc)\nprint(matrix1)\n\n'''\nOutput: \n[[0.150515 0.150515 0.       0.      ]\n [0.       0.       0.150515 0.150515]]\n'''\n```\n**Transform**\n```py\nfrom bfe import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0986\u09b9\u09ae\u09c7\u09a6 \u09b8\u09c1\u09ae\u09a8\", \"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0995\u09b0\u09bf\u09ae\"]\nmatrix2 = k.transform(doc)\nprint(matrix2)\n\n'''\nOutput: \n[[0.150515 0.       0.       0.      ]\n [0.       0.150515 0.       0.      ]]\n'''\n```\n**Coefficients**\n```py\nfrom bfe import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\", \"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"]\nk.fit_transform(doc)\nwordset, idf = k.coefficients()\nprint(wordset)\n#Output: ['\u0986\u09b9\u09ae\u09c7\u09a6', '\u0995\u09be\u0993\u099b\u09be\u09b0', '\u09b9\u09be\u0987\u09a6\u09be\u09b0', '\u09b6\u09c1\u09ad']\n\nprint(idf)\n'''\nOutput: \n{'\u0986\u09b9\u09ae\u09c7\u09a6': 0.3010299956639812, '\u0995\u09be\u0993\u099b\u09be\u09b0': 0.3010299956639812, '\u09b9\u09be\u0987\u09a6\u09be\u09b0': 0.3010299956639812, '\u09b6\u09c1\u09ad': 0.3010299956639812}\n'''\n\n```\n\n### 3. Word Embedding\n- ### Word2Vec\n    - Training\n    - Get Word Vector\n    - Get Similarity\n    - Get n Similar Words\n    - Get Middle Word\n    - Get Odd Words\n    - Get Similarity Plot\n\n**Training**\n```py\nfrom bfe import BN_Word2Vec\n#Training Against Sentences\nw2v = BN_Word2Vec(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be']])\nw2v.train_Word2Vec()\n\n#Training Against one Dataset\nw2v = BN_Word2Vec(corpus_file=\"path to data or txt file\")\nw2v.train_Word2Vec()\n\n#Training Against Multiple Dataset\n'''\n    path\n      ->data\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nw2v = BN_Word2Vec(corpus_path=\"path/data\")\nw2v.train_Word2Vec(epochs=25)\n```\nAfter training is done the model \"w2v_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you use any pretrained model, specify it while initializing BN_Word2Vec() . Otherwise no model_name is needed.**\n\n**Get Word Vector**\n```py\nfrom bfe import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_wordVector('\u0986\u09ae\u09be\u09b0')\n```\n\n**Get Similarity**\n```py\nfrom bfe import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_similarity('\u09a2\u09be\u0995\u09be', '\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0')\n\n#Output: 67.457879\n```\n\n**Get n Similar Words**\n```py\nfrom bfe import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n#Output: \n'''\n[('\u09b8\u09c7\u09a4\u09c1\u09b0', 0.5857524275779724),\n ('\u09ae\u09c1\u09b2\u09ab\u09ce\u0997\u099e\u09cd\u099c', 0.5773632526397705),\n ('\u09ae\u09b9\u09be\u09a8\u09a8\u09cd\u09a6\u09be', 0.5634652376174927),\n (\"'\u09aa\u09a6\u09cd\u09ae\u09be\", 0.5617109537124634),\n ('\u0997\u09cb\u09ae\u09a4\u09c0', 0.5605217218399048),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.5547558069229126),\n ('\u09a4\u09c1\u09b2\u09b8\u09c0\u0997\u0999\u09cd\u0997\u09be', 0.5274507999420166),\n ('\u09a8\u09a6\u09c0\u09b0', 0.5232067704200745),\n ('\u09b8\u09c7\u09a4\u09c1', 0.5225246548652649),\n ('\u09b8\u09c7\u09a4\u09c1\u09a4\u09c7', 0.5192927718162537)]\n'''\n```\n\n**Get Middle Word**\n\n    Get the probability distribution of the center word given words list.\n```py\nfrom bfe import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_outputWord(['\u09a2\u09be\u0995\u09be\u09df', '\u09ae\u09c3\u09a4\u09cd\u09af\u09c1'], n=2)\n\n#Output:  [(\"\u09b9\u09df\u09c7\u099b\u09c7\u0964',\", 0.05880642), ('\u09b6\u09cd\u09b0\u09ae\u09bf\u0995\u09c7\u09b0', 0.05639163)]\n```\n\n**Get Odd Words**\n\n    Get the most unmatched word out from given words list\n```py\nfrom bfe import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n\n#Output: '\u0986\u0995\u09be\u09b6' \n```\n\n**Get Similarity Plot**\n\n    Creates a barplot of similar words with their probability \n\n```py\nfrom bfe import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n```\n\n- ### FastText\n    - Training\n    - Get Word Vector\n    - Get Similarity\n    - Get n Similar Words\n    - Get Middle Word\n    - Get Odd Words\n\n\n**Training**\n```py\nfrom bfe import BN_FastText\n#Training Against Sentences\nft = FastText(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be']])\nft.train_fasttext()\n\n#Training Against one Dataset\nft = FastText(corpus_file=\"path to data or txt file\")\nft.train_fasttext()\n\n#Training Against Multiple Dataset\n'''\n    path\n      ->data\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nft = FastText(corpus_path=\"path/data\")\nft.train_fasttext(epochs=25)\n```\nAfter training is done the model \"ft_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you use any pretrained model, specify it while initializing BN_FastText() . Otherwise no model_name is needed.**\n\n**Get Word Vector**\n```py\nfrom bfe import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_wordVector('\u0986\u09ae\u09be\u09b0')\n```\n\n**Get Similarity**\n```py\nfrom bfe import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_similarity('\u09a2\u09be\u0995\u09be', '\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0')\n\n#Output: 70.56821120\n```\n\n**Get n Similar Words**\n```py\nfrom bfe\" import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n#Output: \n'''\n[('\u09aa\u09a6\u09cd\u09ae\u09be\u09df', 0.8103810548782349),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.794012725353241),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09a8\u09a6\u09c0\u09b0', 0.7747839689254761),\n ('\u09aa\u09a6\u09cd\u09ae\u09be-\u09ae\u09c7\u0998\u09a8\u09be\u09b0', 0.7573559284210205),\n ('\u09aa\u09a6\u09cd\u09ae\u09be.', 0.7470568418502808),\n ('\u2018\u09aa\u09a6\u09cd\u09ae\u09be', 0.7413997650146484),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b8\u09c7\u09a4\u09c1\u09b0', 0.716225266456604),\n ('\u09aa\u09a6\u09cd\u09ae', 0.7154797315597534),\n ('\u09aa\u09a6\u09cd\u09ae\u09b9\u09c7\u09ae', 0.6881639361381531),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09ac\u09a4', 0.6682782173156738)]\n'''\n```\n\n**Get Odd Words**\n\n    Get the most unmatched word out from given words list\n```py\nfrom \"package_name\" import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n\n#Output: '\u0986\u0995\u09be\u09b6' \n```\n\n**Get Similarity Plot**\n\n    Creates a barplot of similar words with their probability \n\n```py\nfrom bfe import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n```\n\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "test-mark", "package_url": "https://pypi.org/project/test-mark/", "platform": "", "project_url": "https://pypi.org/project/test-mark/", "project_urls": null, "release_url": "https://pypi.org/project/test-mark/0.1/", "requires_dist": ["markdown", "bre"], "requires_python": "", "summary": "A simple function for mathematical operations", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Bangla Feature Extractor(BFE)</h1>\n<p>BFE is a Bangla Natural Language Processing based feature extractor.</p>\n<h2>Current Features</h2>\n<ol>\n<li><a href=\"#1-countvectorizer\" rel=\"nofollow\">CountVectorizer</a></li>\n<li><a href=\"#2-tfidf\" rel=\"nofollow\">TfIdf</a></li>\n<li><a href=\"#3-word-embedding\" rel=\"nofollow\">Word Embedding</a>\n<ul>\n<li><a href=\"#word2vec\" rel=\"nofollow\">Word2Vec</a></li>\n<li><a href=\"#fasttext\" rel=\"nofollow\">FastText</a></li>\n</ul>\n</li>\n</ol>\n<h2>Installation</h2>\n<pre><code>pip install bfe\n</code></pre>\n<h2>Example</h2>\n<h3>1. CountVectorizer</h3>\n<ul>\n<li>Fit n Transform</li>\n<li>Transform</li>\n<li>Get Wordset</li>\n</ul>\n<p><strong>Fit n Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"n\">ct</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span> <span class=\"c1\"># X is the word features</span>\n<span class=\"c1\">#Output: the countVectorized matrix form of given features</span>\n</pre>\n<p><strong>Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"n\">ct</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">get_mat</span> <span class=\"o\">=</span> <span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"s2\">\"\u09b0\u09be\u09b9\u09be\u09a4\"</span><span class=\"p\">)</span>\n<span class=\"c1\">#Output: the countVectorized matrix form of given word</span>\n</pre>\n<p><strong>Get Wordset</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">CountVectorizer</span>\n<span class=\"n\">ct</span> <span class=\"o\">=</span> <span class=\"n\">CountVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">ct</span><span class=\"o\">.</span><span class=\"n\">get_wordSet</span><span class=\"p\">()</span>\n<span class=\"c1\">#Output: get the raw wordset used in training model</span>\n</pre>\n<h3>2. TfIdf</h3>\n<ul>\n<li>Fit n Transform</li>\n<li>Transform</li>\n<li>Coefficients</li>\n</ul>\n<p><strong>Fit n Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">TfIdfVectorizer</span>\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">TfIdfVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"</span><span class=\"p\">]</span>\n<span class=\"n\">matrix1</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">matrix1</span><span class=\"p\">)</span>\n\n<span class=\"sd\">'''</span>\n<span class=\"sd\">Output: </span>\n<span class=\"sd\">[[0.150515 0.150515 0.       0.      ]</span>\n<span class=\"sd\"> [0.       0.       0.150515 0.150515]]</span>\n<span class=\"sd\">'''</span>\n</pre>\n<p><strong>Transform</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">TfIdfVectorizer</span>\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">TfIdfVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0986\u09b9\u09ae\u09c7\u09a6 \u09b8\u09c1\u09ae\u09a8\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0995\u09b0\u09bf\u09ae\"</span><span class=\"p\">]</span>\n<span class=\"n\">matrix2</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">matrix2</span><span class=\"p\">)</span>\n\n<span class=\"sd\">'''</span>\n<span class=\"sd\">Output: </span>\n<span class=\"sd\">[[0.150515 0.       0.       0.      ]</span>\n<span class=\"sd\"> [0.       0.150515 0.       0.      ]]</span>\n<span class=\"sd\">'''</span>\n</pre>\n<p><strong>Coefficients</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">TfIdfVectorizer</span>\n<span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">TfIdfVectorizer</span><span class=\"p\">()</span>\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\"</span><span class=\"p\">,</span> <span class=\"s2\">\"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"</span><span class=\"p\">]</span>\n<span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n<span class=\"n\">wordset</span><span class=\"p\">,</span> <span class=\"n\">idf</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">coefficients</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">wordset</span><span class=\"p\">)</span>\n<span class=\"c1\">#Output: ['\u0986\u09b9\u09ae\u09c7\u09a6', '\u0995\u09be\u0993\u099b\u09be\u09b0', '\u09b9\u09be\u0987\u09a6\u09be\u09b0', '\u09b6\u09c1\u09ad']</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">idf</span><span class=\"p\">)</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">Output: </span>\n<span class=\"sd\">{'\u0986\u09b9\u09ae\u09c7\u09a6': 0.3010299956639812, '\u0995\u09be\u0993\u099b\u09be\u09b0': 0.3010299956639812, '\u09b9\u09be\u0987\u09a6\u09be\u09b0': 0.3010299956639812, '\u09b6\u09c1\u09ad': 0.3010299956639812}</span>\n<span class=\"sd\">'''</span>\n</pre>\n<h3>3. Word Embedding</h3>\n<ul>\n<li>\n<h3>Word2Vec</h3>\n<ul>\n<li>Training</li>\n<li>Get Word Vector</li>\n<li>Get Similarity</li>\n<li>Get n Similar Words</li>\n<li>Get Middle Word</li>\n<li>Get Odd Words</li>\n<li>Get Similarity Plot</li>\n</ul>\n</li>\n</ul>\n<p><strong>Training</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span>\n<span class=\"c1\">#Training Against Sentences</span>\n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"o\">=</span><span class=\"p\">[[</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09aa\u09cd\u09b0\u09bf\u09df'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'\u09ac\u09be\u0982\u09b2\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'</span><span class=\"p\">]])</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">train_Word2Vec</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against one Dataset</span>\n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">corpus_file</span><span class=\"o\">=</span><span class=\"s2\">\"path to data or txt file\"</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">train_Word2Vec</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against Multiple Dataset</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">    path</span>\n<span class=\"sd\">      -&gt;data</span>\n<span class=\"sd\">        -&gt;1.txt</span>\n<span class=\"sd\">        -&gt;2.txt</span>\n<span class=\"sd\">        -&gt;3.txt</span>\n<span class=\"sd\">'''</span>\n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">corpus_path</span><span class=\"o\">=</span><span class=\"s2\">\"path/data\"</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">train_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">)</span>\n</pre>\n<p>After training is done the model \"w2v_model\"  along with it's supportive vector files will be saved to current directory.</p>\n<p><strong>If you use any pretrained model, specify it while initializing BN_Word2Vec() . Otherwise no model_name is needed.</strong></p>\n<p><strong>Get Word Vector</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_wordVector</span><span class=\"p\">(</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">)</span>\n</pre>\n<p><strong>Get Similarity</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_similarity</span><span class=\"p\">(</span><span class=\"s1\">'\u09a2\u09be\u0995\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0'</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#Output: 67.457879</span>\n</pre>\n<p><strong>Get n Similar Words</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_n_similarWord</span><span class=\"p\">([</span><span class=\"s1\">'\u09aa\u09a6\u09cd\u09ae\u09be'</span><span class=\"p\">],</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"c1\">#Output: </span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">[('\u09b8\u09c7\u09a4\u09c1\u09b0', 0.5857524275779724),</span>\n<span class=\"sd\"> ('\u09ae\u09c1\u09b2\u09ab\u09ce\u0997\u099e\u09cd\u099c', 0.5773632526397705),</span>\n<span class=\"sd\"> ('\u09ae\u09b9\u09be\u09a8\u09a8\u09cd\u09a6\u09be', 0.5634652376174927),</span>\n<span class=\"sd\"> (\"'\u09aa\u09a6\u09cd\u09ae\u09be\", 0.5617109537124634),</span>\n<span class=\"sd\"> ('\u0997\u09cb\u09ae\u09a4\u09c0', 0.5605217218399048),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.5547558069229126),</span>\n<span class=\"sd\"> ('\u09a4\u09c1\u09b2\u09b8\u09c0\u0997\u0999\u09cd\u0997\u09be', 0.5274507999420166),</span>\n<span class=\"sd\"> ('\u09a8\u09a6\u09c0\u09b0', 0.5232067704200745),</span>\n<span class=\"sd\"> ('\u09b8\u09c7\u09a4\u09c1', 0.5225246548652649),</span>\n<span class=\"sd\"> ('\u09b8\u09c7\u09a4\u09c1\u09a4\u09c7', 0.5192927718162537)]</span>\n<span class=\"sd\">'''</span>\n</pre>\n<p><strong>Get Middle Word</strong></p>\n<pre><code>Get the probability distribution of the center word given words list.\n</code></pre>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_outputWord</span><span class=\"p\">([</span><span class=\"s1\">'\u09a2\u09be\u0995\u09be\u09df'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09ae\u09c3\u09a4\u09cd\u09af\u09c1'</span><span class=\"p\">],</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#Output:  [(\"\u09b9\u09df\u09c7\u099b\u09c7\u0964',\", 0.05880642), ('\u09b6\u09cd\u09b0\u09ae\u09bf\u0995\u09c7\u09b0', 0.05639163)]</span>\n</pre>\n<p><strong>Get Odd Words</strong></p>\n<pre><code>Get the most unmatched word out from given words list\n</code></pre>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_oddWords</span><span class=\"p\">([</span><span class=\"s1\">'\u099a\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09a1\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099a\u09bf\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u0995\u09be\u09b6'</span><span class=\"p\">])</span>\n\n<span class=\"c1\">#Output: '\u0986\u0995\u09be\u09b6' </span>\n</pre>\n<p><strong>Get Similarity Plot</strong></p>\n<pre><code>Creates a barplot of similar words with their probability \n</code></pre>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Word2Vec</span> \n<span class=\"n\">w2v</span> <span class=\"o\">=</span> <span class=\"n\">BN_Word2Vec</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">w2v</span><span class=\"o\">.</span><span class=\"n\">get_oddWords</span><span class=\"p\">([</span><span class=\"s1\">'\u099a\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09a1\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099a\u09bf\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u0995\u09be\u09b6'</span><span class=\"p\">])</span>\n</pre>\n<ul>\n<li>\n<h3>FastText</h3>\n<ul>\n<li>Training</li>\n<li>Get Word Vector</li>\n<li>Get Similarity</li>\n<li>Get n Similar Words</li>\n<li>Get Middle Word</li>\n<li>Get Odd Words</li>\n</ul>\n</li>\n</ul>\n<p><strong>Training</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span>\n<span class=\"c1\">#Training Against Sentences</span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">FastText</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"o\">=</span><span class=\"p\">[[</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09aa\u09cd\u09b0\u09bf\u09df'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'\u09ac\u09be\u0982\u09b2\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'</span><span class=\"p\">]])</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against one Dataset</span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">FastText</span><span class=\"p\">(</span><span class=\"n\">corpus_file</span><span class=\"o\">=</span><span class=\"s2\">\"path to data or txt file\"</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">()</span>\n\n<span class=\"c1\">#Training Against Multiple Dataset</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">    path</span>\n<span class=\"sd\">      -&gt;data</span>\n<span class=\"sd\">        -&gt;1.txt</span>\n<span class=\"sd\">        -&gt;2.txt</span>\n<span class=\"sd\">        -&gt;3.txt</span>\n<span class=\"sd\">'''</span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">FastText</span><span class=\"p\">(</span><span class=\"n\">corpus_path</span><span class=\"o\">=</span><span class=\"s2\">\"path/data\"</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">(</span><span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">)</span>\n</pre>\n<p>After training is done the model \"ft_model\"  along with it's supportive vector files will be saved to current directory.</p>\n<p><strong>If you use any pretrained model, specify it while initializing BN_FastText() . Otherwise no model_name is needed.</strong></p>\n<p><strong>Get Word Vector</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_wordVector</span><span class=\"p\">(</span><span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span><span class=\"p\">)</span>\n</pre>\n<p><strong>Get Similarity</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_similarity</span><span class=\"p\">(</span><span class=\"s1\">'\u09a2\u09be\u0995\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0'</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#Output: 70.56821120</span>\n</pre>\n<p><strong>Get n Similar Words</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span><span class=\"s2\">\" import BN_FastText </span>\n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_n_similarWord</span><span class=\"p\">([</span><span class=\"s1\">'\u09aa\u09a6\u09cd\u09ae\u09be'</span><span class=\"p\">],</span> <span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"c1\">#Output: </span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">[('\u09aa\u09a6\u09cd\u09ae\u09be\u09df', 0.8103810548782349),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.794012725353241),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be\u09a8\u09a6\u09c0\u09b0', 0.7747839689254761),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be-\u09ae\u09c7\u0998\u09a8\u09be\u09b0', 0.7573559284210205),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be.', 0.7470568418502808),</span>\n<span class=\"sd\"> ('\u2018\u09aa\u09a6\u09cd\u09ae\u09be', 0.7413997650146484),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b8\u09c7\u09a4\u09c1\u09b0', 0.716225266456604),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae', 0.7154797315597534),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09b9\u09c7\u09ae', 0.6881639361381531),</span>\n<span class=\"sd\"> ('\u09aa\u09a6\u09cd\u09ae\u09be\u09ac\u09a4', 0.6682782173156738)]</span>\n<span class=\"sd\">'''</span>\n</pre>\n<p><strong>Get Odd Words</strong></p>\n<pre><code>Get the most unmatched word out from given words list\n</code></pre>\n<pre><span class=\"kn\">from</span> <span class=\"s2\">\"package_name\"</span> <span class=\"kn\">import</span> <span class=\"nn\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_oddWords</span><span class=\"p\">([</span><span class=\"s1\">'\u099a\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09a1\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099a\u09bf\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u0995\u09be\u09b6'</span><span class=\"p\">])</span>\n\n<span class=\"c1\">#Output: '\u0986\u0995\u09be\u09b6' </span>\n</pre>\n<p><strong>Get Similarity Plot</strong></p>\n<pre><code>Creates a barplot of similar words with their probability \n</code></pre>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bfe</span> <span class=\"kn\">import</span> <span class=\"n\">BN_FastText</span> \n<span class=\"n\">ft</span> <span class=\"o\">=</span> <span class=\"n\">BN_FastText</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s1\">'give the model name here'</span><span class=\"p\">)</span>\n<span class=\"n\">ft</span><span class=\"o\">.</span><span class=\"n\">get_oddWords</span><span class=\"p\">([</span><span class=\"s1\">'\u099a\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u09a1\u09be\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'\u099a\u09bf\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'\u0986\u0995\u09be\u09b6'</span><span class=\"p\">])</span>\n</pre>\n\n          </div>"}, "last_serial": 7041780, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "0ab201eb75343413d3595f8a03b850db", "sha256": "1e7f75691ea94a0530489efd8b7cccb9dcda4f2864b66fd1122b6417413888d0"}, "downloads": -1, "filename": "test_mark-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0ab201eb75343413d3595f8a03b850db", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4494, "upload_time": "2020-04-17T17:05:26", "upload_time_iso_8601": "2020-04-17T17:05:26.501132Z", "url": "https://files.pythonhosted.org/packages/62/18/322898fdd5ac334632316ee87cf2672075f5c53ba54ea883627817ca8fc6/test_mark-0.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0ab201eb75343413d3595f8a03b850db", "sha256": "1e7f75691ea94a0530489efd8b7cccb9dcda4f2864b66fd1122b6417413888d0"}, "downloads": -1, "filename": "test_mark-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0ab201eb75343413d3595f8a03b850db", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4494, "upload_time": "2020-04-17T17:05:26", "upload_time_iso_8601": "2020-04-17T17:05:26.501132Z", "url": "https://files.pythonhosted.org/packages/62/18/322898fdd5ac334632316ee87cf2672075f5c53ba54ea883627817ca8fc6/test_mark-0.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 02:55:24 2020"}