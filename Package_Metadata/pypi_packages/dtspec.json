{"info": {"author": "Sterling Paramore", "author_email": "sterling.paramore@insidetrack.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Data Transform Spec\n\ndtspec is an API for specifying and testing data transformations.\n\n## Introduction\n\nTesting data transformations is hard.  So hard that a lot of ETL/ELT\nprocesses have little or (more often) no automated tests.\ndtspec aims to make it easier to write and run tests for very complicated\ndata transformations typically encountered in ETL/ELT.\n\nWith dtspec, we imagine a data transformation process that takes a set of\ndata **sources** and transforms them into a set of data **targets**.  dtspec\nis primarily concerned with structured data sources, like Pandas\ndataframes or database tables.  A user of dtspec defines data **factories** that\ngenerate source data, and a set of **expectations** that describe how the data\nshould look after it's been transformed.\n\nWhile dtspec is written in Python, it is intended to be used as more of a\nlanguage-agnostic API.  A dtspec user writes a test **spec**, which is then passed\nto dtspec.  dtspec processes that spec and then returns to the user test data for\nall of the source specific in the spec.  The user then feeds that test data into\ntheir data transformation system, collects the output, and sends it back to dtspec.\ndtspec compares the actual results of the data transformations with the expected\nresults specific in the spec and reports on any discrepancies.\n\n\n## Tutorial\n\nLet's see this all at work with some examples.\n\n\n### Hello World!\n\nLet's suppose we have a dataset containing student records.  Our data\ntransformation simply reads in that data, and returns a new dataframe\nwith a \"Hello <student>\" salutation.  We want to test that it says\n\"hello\" to everyone.  For the purposes of our tutorial, the data\ntransformation will be written in Pandas as\n\n````python\ndef hello_world_transformer(raw_students):\n    salutations_df = raw_students.copy()\n    salutations_df[\"salutation\"] = salutations_df['name'].apply(lambda v: 'Hello ' + v)\n\n    return {\"salutations\": salutations_df}\n\n````\n\ndtspec is an API that accepts a JSON blob for the transformation spec.  However, I strongly\nprefer to write specs in YAML and then convert them into JSON before passing them\non to dtspec.  To begin writing our transform spec, we define the dtspec `version`, a `description`\nof the transform spec, and then list out the `sources` and `targets`:\n\n````yaml\n---\nversion: '0.1'\ndescription: HelloWorld - Simplest example of running dtspec\n\n# The names of sources and targets is arbitrary, but it's up to the user to determine\n# how they get mapped to/from their data transformation system.\nsources:\n  - source: raw_students\n\ntargets:\n  - target: salutations\n````\n\nThese define our inputs and outputs.  But we also need to define how to generate\ndata for the input(s).  For that, we define a **factory**:\n\n````yaml\nfactories:\n  - factory: SomeStudents\n    description: Minimal example of what some student records may look like\n\n    data:\n      - source: raw_students\n        # Tables written as a markdown table\n        table: |\n          | id | name   |\n          | -  | -      |\n          | 1  | Buffy  |\n          | 2  | Willow |\n````\n\nLastly, we need to describe how we expect the data to look after it has been transformed.\nTo do this, we define **scenarios** and **cases**.  Scenarios are collections of cases\nthat share some common data factory or describe similar situations.  For now, our\ntransform spec will just contain a single scenario and a single case:\n\n````yaml\nscenarios:\n  - scenario: Hello World\n    description: The simplest scenario\n    # All cases in this scenario will use this factory (which may be modified on case-by-case basis)\n    factory:\n        parents:\n          - SomeStudents\n\n    cases:\n      - case: HelloGang\n        description: Make sure we say hello to everyone\n        expected:\n          data:\n            - target: salutations\n              # The actual output may also contain the \"name\" field, but the expectation\n              # will ignore comparing any fields not listed in the expected table.\n              table: |\n                | id | salutation   |\n                | -  | -            |\n                | 1  | Hello Buffy  |\n                | 2  | Hello Willow |\n````\n\nThat's it. See also the [full YAML spec](tests/hello_world.yml).\n\nNow that we've described the full transform spec, we need to use it.  The first step is to\nparse the YAML file, send it to the dtspec api, and have dtspec generate source data:\n\n````python\nimport dtspec\nimport yaml\n\nspec = yaml.safe_load(open(\"tests/hello_world.yml\"))\napi = dtspec.api.Api(spec)\napi.generate_sources()\n````\n\nThe specific steps taken at this point are going to be sensitive to the data transformation\nenvironment being used, but we'll stick with our Pandas transformations for the sake of this\ntutorial.  Given this, we can define a simple function that converts the source data returned\nfrom dtspec into Pandas dataframes:\n\n````python\nimport pandas as pd\n\ndef parse_sources(sources):\n    \"Converts test data returned from dtspec api into Pandas dataframes\"\n\n    return {\n        source_name: pd.DataFrame.from_records(data.serialize())\n        for source_name, data in sources.items()\n    }\n````\n\nWe can then run those test Pandas dataframes through our data transformation function.\n\n````python\nsources_data = parse_sources(api.spec[\"sources\"])\nactual_data = hello_world_transformer(**sources_data)\n````\n\nNext, we need to convert the output dataframes of the transformations, `actual_data`,\nback into a format that can be loaded into dtspec for comparison.  For Pandas,\nthis function is:\n\n````python\ndef serialize_actuals(actuals):\n    \"Converts Pandas dataframe results into form needed to load dtspec api actuals\"\n\n    return {\n        target_name: json.loads(dataframe.astype(str).to_json(orient=\"records\"))\n        for target_name, dataframe in actuals.items()\n    }\n````\n\nIt is loaded into dtspec using:\n\n````python\nserialized_actuals = serialize_actuals(actual_data)\napi.load_actuals(serialized_actuals)\n````\n\nFinally, dtspec can be called to run all of the expectations:\n\n````python\napi.assert_expectations()\n````\n\nPutting all of this together:\n````python\nspec = yaml.safe_load(open(\"tests/hello_world.yml\"))\napi = dtspec.api.Api(spec)\napi.generate_sources()\n\nsources_data = parse_sources(api.spec[\"sources\"])\nactual_data = hello_world_transformer(**sources_data)\nserialized_actuals = serialize_actuals(actual_data)\napi.load_actuals(serialized_actuals)\n````\n\nTry running the above code and changing either the YAML spec or the `hello_world_transformer`\nfunction and see how dtspec responds.\n\n### Hello World With Multiple Test Cases\n\nRunning tests with multiple cases that reference the same data sources\nintroduces a complicating factor. One of the reasons that makes\nit hard to build tests for ETL/ELT is the fact that many data\ntransformation systems in use today have a high latency for even very\nsmall transformations.  For example, Redshift is a distributed RDBMS\nthat can process billions of rows in minutes, millions of rows in\nseconds, thousands of rows in seconds, or 10s of rows in, well,\nseconds.  Given these latency issues, we don't want to have to rely on\nloading data into our system, running a test, clearing out the data,\nloading some more, running the next test, and so on as is often\ndone when testing ORM-based applications like Rails or Django.\n\ndtspec seeks to minimize the number of requests on the data\ntransformation system in order to deal with these latency issues.\nIt does this by \"stacking\" the test data generated in each case\nand delivering back to the user all of this stacked data.  The user\nthen loads this stacked data into their data transformation system\n**once**, runs the data transformations **once**, and then collects\nthe resulting output **once**.\n\nLet's see how dtspec handles this in action.\n\nFirst, let's change our hello world data transformation a bit.  Instead of\njust saying hello to our heroes, let's say goodbye to any villians (as\nidentified by a `clique` data field).\n\n````python\ndef hello_world_multiple_transformer(raw_students):\n    def salutation(row):\n        if row[\"clique\"] == \"Scooby Gang\":\n            return \"Hello {}\".format(row[\"name\"])\n        return \"Goodbye {}\".format(row[\"name\"])\n\n    salutations_df = raw_students.copy()\n    salutations_df[\"salutation\"] = salutations_df.apply(salutation, axis=1)\n\n    return {\"salutations\": salutations_df}\n````\n\nWhile it would be possible to test saying hello or goodbye in a single\ncase just by adding more records to the source data, we'll split it\ninto two to demonstrate how multiple cases work.  Here's how the YAML would look:\n\n````yaml\nscenarios:\n  - scenario: Hello World With Multiple Cases\n    description: The simplest scenario\n    factory:\n      parents:\n        - SomeStudents\n\n    cases:\n      - case: HelloGang\n        description: Make sure we say hello to everyone\n        expected:\n          data:\n            - target: salutations\n              table: |\n                | id | name   | clique      | salutation   |\n                | -  | -      | -           | -            |\n                | 1  | Buffy  | Scooby Gang | Hello Buffy  |\n                | 2  | Willow | Scooby Gang | Hello Willow |\n\n      - case: GoodbyeVillians\n        description: Say goodbye to villians\n        # For this case, we tweak the factory defined for the scenario.\n        factory:\n          # The ids here might be the same as above.  However, these are just named\n          # references and get translated into unique ids when the source data\n          # is generated.\n          data:\n            - source: raw_students\n              table: |\n                | id | name     |\n                | -  | -        |\n                | 1  | Drusilla |\n                | 2  | Harmony  |\n              # Use values to populate a constant over all records\n              values:\n                - column: clique\n                  value: Vampires\n\n        expected:\n          data:\n            # Again, the ids here are not the actual ids sent to dtspec after performing\n            # the transformations.  They are just named references and dtspec\n            # keeps track of the relationship between the actual ids and the named ones.\n            - target: salutations\n              table: |\n                | id | name     | clique   | salutation       |\n                | -  | -        | -        | -                |\n                | 1  | Drusilla | Vampires | Goodbye Drusilla |\n                | 2  | Harmony  | Vampires | Goodbye Harmony  |\n\n````\n\nThis won't quite work as is, because we're missing something.  We have\ntwo cases that describe variations on the source data `raw_students`\nand the output `salutations`.  dtspec collects the source data\ndefinitions from each case and stacks them into a single data source.\nThe user then runs the transformations on that source and generates a\nsingle target to provide back to dtspec.  But dtspec has to know which record\nbelongs to which case.  To do this, we have to define an\n**identifier** that tells dtspec which columns should be used to identify\na record as belonging to a case.  A good identifier is often a primary\nkey that uniquely defines a record, but it is not strictly required to\nbe unique across all records.\n\nFor this example, we'll define an identifier called \"students\" with a single\n**identifier attribute** called `id` that is a unique integer:\n\n````yaml\nidentifiers:\n  - identifier: students\n    attributes:\n      - field: id\n        generator: unique_integer\n````\n\nWe tell dtspec that this identifier is associated with the `id` columns of both\nthe source and the target via:\n\n````yaml\nsources:\n  - source: raw_students\n    identifier_map:\n      - column: id\n        identifier:\n          name: students\n          attribute: id\n\n\ntargets:\n  - target: salutations\n    identifier_map:\n      - column: id\n        identifier:\n          name: students\n          attribute: id\n````\n\nWith the sources and targets with identifiers, the values we see in\nthe source factories and target expectations are not the values that\nare actually used in the data.  Instead, they are simply **named\nrefereces**.  For example, in the \"HelloGang\" case, `id=1` belongs to\nBuffy and `id=2` belongs to Willow.  But when dtspec generates the source\ndata, the actual values may be 3 and 9, or 4 and 7, or something else.\nUnique values are not generated in any deterministic manner -- each\nrun of dtspec can give a diferent set.  dtspec only guarantees that the\neach named reference will be a unique integer (via the `generator`\ndefined in the `identifier` section).\n\nFuthermore, in the second case called \"GoodbyeVillians\", we see that\n`id=1` belongs to Drusilla and `id=2` belongs to Harmony.  dtspec will\ngenerate unique values for this case as well, and they **will not**\nconflict with the values generated for the first case.  So dtspec will pass\nback to the user 4 total records (Buffy, Willow, Drusilla, Harmony) with 4\ndifferent ids\n\nWith the [full YAML spec](tests/hello_world_multiple_cases.yml) defined, we can\nrun the assertions in the same fashion as the the earlier example\n\n````python\nspec = yaml.safe_load(open(\"tests/hello_world_multiple_cases.yml\"))\napi = dtspec.api.Api(spec)\napi.generate_sources()\n\nsources_data = parse_sources(api.spec[\"sources\"])\nactual_data = hello_world_multiple_transformer(**sources_data)\nserialized_actuals = serialize_actuals(actual_data)\napi.load_actuals(serialized_actuals)\n\napi.assert_expectations()\n````\n\n#### Embedded Identifiers\n\nIt is also possible to embed identifiers in the value of a particular column.\nFor example, suppose our `salutation` column said hello to the `id` instead\nof the name of the person.  To make this work, we have to put a particular\nstring pattern in the column that indicates the name of the identifier, the\nattribute, and the named id - `{identifier.attribute[named_id]}`.  The\nyaml spec would look like:\n\n````yaml\n      - case: HelloGang\n        description: Make sure we say hello to everyone\n        expected:\n          data:\n            - target: salutations\n              table: |\n                | id | name   | clique      | salutation             |\n                | -  | -      | -           | -                      |\n                | 1  | Buffy  | Scooby Gang | Hello {students.id[1]} |\n                | 2  | Willow | Scooby Gang | Hello {students.id[2]} |\n````\nThe [realistic example](tests/realistic.yml) discussed below has another example\nof using embedded identifiers.\n\n**Note** that embedded identifiers cannot be used to associate records\nwith cases.  A target must have at least one column listed in the\n`identifier_map` section.\n\n### A More Realistic Example\n\nFinally, let's example a more realistic example that one might\nencounter when building a data warehouse.  In these situations, we'll\nhave multiple sources, targets, scenarios, and cases.  Now suppose we\nhave a students table, where every student belongs to a school and\ntakes 0 to many classes.  Our goal is to create one denormalized table\nthat combines all of these data sources into one table.  Additionally,\nwe want to create a table that aggregates all of our students to give\na count of the students per school.  In Pandas, the data transformation\nmight look like:\n\n````python\ndef realistic_transformer(raw_students, raw_schools, raw_classes, dim_date):\n\n    student_schools = raw_students.rename(\n        columns={\"id\": \"student_id\", \"external_id\": \"card_id\"}\n    ).merge(\n        raw_schools.rename(columns={\"id\": \"school_id\", \"name\": \"school_name\"}),\n        how=\"inner\",\n        on=\"school_id\",\n    )\n\n    student_classes = student_schools.merge(\n        raw_classes.rename(columns={\"name\": \"class_name\"}),\n        how=\"inner\",\n        on=\"student_id\",\n    ).merge(\n        dim_date.rename(columns={\"date\": \"start_date\"}), how=\"left\", on=\"start_date\"\n    )\n\n    student_classes[\"student_class_id\"] = student_classes.apply(\n        lambda row: \"-\".join([str(row[\"card_id\"]), str(row[\"class_name\"])]), axis=1\n    )\n\n    students_per_school = (\n        student_schools.groupby([\"school_name\"])\n        .size()\n        .to_frame(name=\"number_of_students\")\n        .reset_index()\n    )\n\n    return {\n        \"student_classes\": student_classes,\n        \"students_per_school\": students_per_school,\n    }\n````\n\nGiven the [full YAML spec](tests/realistic.yml) defined, we can again run\nthe data assertions using a familiar pattern:\n\n````python\nspec = yaml.safe_load(open(\"tests/realistic.yml\"))\napi = dtspec.api.Api(spec)\napi.generate_sources()\n\nsources_data = parse_sources(api.spec[\"sources\"])\nactual_data = hello_world_multiple_transformer(**sources_data)\nserialized_actuals = serialize_actuals(actual_data)\napi.load_actuals(serialized_actuals)\n\napi.assert_expectations()\n````\n\n\n\n## Additional notes about dtspec\n\n* At the moment, all source data values are generated as strings.  It\n  is up to the the user to enforce data types suitable to their data\n  transformation system.\n* Additionally, data expectations are stringified prior to running assertions.\n\n## Contributing\n\nWe welcome contributors!  Please submit any suggests or pull requests in Github.\n\n### Developer setup\n\nCreate an appropriate python environment.  I like [miniconda](https://conda.io/miniconda.html),\nbut use whatever you like:\n\n    conda create --name dtspec python=3.6\n    conda activate dtspec\n\nThen install pip packages\n\n    pip install pip-tools\n    pip install --ignore-installed -r requirements.txt\n\nrun tests via\n\n    inv test\n\nand the linter via\n\n    inv lint", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/inside-track/dtspec", "keywords": "etl elt data testing", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dtspec", "package_url": "https://pypi.org/project/dtspec/", "platform": "", "project_url": "https://pypi.org/project/dtspec/", "project_urls": {"Homepage": "https://github.com/inside-track/dtspec"}, "release_url": "https://pypi.org/project/dtspec/0.6.3/", "requires_dist": null, "requires_python": ">=3", "summary": "dtspec - Data Test Spec", "version": "0.6.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Data Transform Spec</h1>\n<p>dtspec is an API for specifying and testing data transformations.</p>\n<h2>Introduction</h2>\n<p>Testing data transformations is hard.  So hard that a lot of ETL/ELT\nprocesses have little or (more often) no automated tests.\ndtspec aims to make it easier to write and run tests for very complicated\ndata transformations typically encountered in ETL/ELT.</p>\n<p>With dtspec, we imagine a data transformation process that takes a set of\ndata <strong>sources</strong> and transforms them into a set of data <strong>targets</strong>.  dtspec\nis primarily concerned with structured data sources, like Pandas\ndataframes or database tables.  A user of dtspec defines data <strong>factories</strong> that\ngenerate source data, and a set of <strong>expectations</strong> that describe how the data\nshould look after it's been transformed.</p>\n<p>While dtspec is written in Python, it is intended to be used as more of a\nlanguage-agnostic API.  A dtspec user writes a test <strong>spec</strong>, which is then passed\nto dtspec.  dtspec processes that spec and then returns to the user test data for\nall of the source specific in the spec.  The user then feeds that test data into\ntheir data transformation system, collects the output, and sends it back to dtspec.\ndtspec compares the actual results of the data transformations with the expected\nresults specific in the spec and reports on any discrepancies.</p>\n<h2>Tutorial</h2>\n<p>Let's see this all at work with some examples.</p>\n<h3>Hello World!</h3>\n<p>Let's suppose we have a dataset containing student records.  Our data\ntransformation simply reads in that data, and returns a new dataframe\nwith a \"Hello &lt;student&gt;\" salutation.  We want to test that it says\n\"hello\" to everyone.  For the purposes of our tutorial, the data\ntransformation will be written in Pandas as</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">hello_world_transformer</span><span class=\"p\">(</span><span class=\"n\">raw_students</span><span class=\"p\">):</span>\n    <span class=\"n\">salutations_df</span> <span class=\"o\">=</span> <span class=\"n\">raw_students</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>\n    <span class=\"n\">salutations_df</span><span class=\"p\">[</span><span class=\"s2\">\"salutation\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">salutations_df</span><span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">v</span><span class=\"p\">:</span> <span class=\"s1\">'Hello '</span> <span class=\"o\">+</span> <span class=\"n\">v</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"salutations\"</span><span class=\"p\">:</span> <span class=\"n\">salutations_df</span><span class=\"p\">}</span>\n</pre>\n<p>dtspec is an API that accepts a JSON blob for the transformation spec.  However, I strongly\nprefer to write specs in YAML and then convert them into JSON before passing them\non to dtspec.  To begin writing our transform spec, we define the dtspec <code>version</code>, a <code>description</code>\nof the transform spec, and then list out the <code>sources</code> and <code>targets</code>:</p>\n<pre><span class=\"nn\">---</span>\n<span class=\"nt\">version</span><span class=\"p\">:</span> <span class=\"s\">'0.1'</span>\n<span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">HelloWorld - Simplest example of running dtspec</span>\n\n<span class=\"c1\"># The names of sources and targets is arbitrary, but it's up to the user to determine</span>\n<span class=\"c1\"># how they get mapped to/from their data transformation system.</span>\n<span class=\"nt\">sources</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">source</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">raw_students</span>\n\n<span class=\"nt\">targets</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">target</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">salutations</span>\n</pre>\n<p>These define our inputs and outputs.  But we also need to define how to generate\ndata for the input(s).  For that, we define a <strong>factory</strong>:</p>\n<pre><span class=\"nt\">factories</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">factory</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">SomeStudents</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Minimal example of what some student records may look like</span>\n\n    <span class=\"nt\">data</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">source</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">raw_students</span>\n        <span class=\"c1\"># Tables written as a markdown table</span>\n        <span class=\"nt\">table</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">|</span>\n          <span class=\"no\">| id | name   |</span>\n          <span class=\"no\">| -  | -      |</span>\n          <span class=\"no\">| 1  | Buffy  |</span>\n          <span class=\"no\">| 2  | Willow |</span>\n</pre>\n<p>Lastly, we need to describe how we expect the data to look after it has been transformed.\nTo do this, we define <strong>scenarios</strong> and <strong>cases</strong>.  Scenarios are collections of cases\nthat share some common data factory or describe similar situations.  For now, our\ntransform spec will just contain a single scenario and a single case:</p>\n<pre><span class=\"nt\">scenarios</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">scenario</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Hello World</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">The simplest scenario</span>\n    <span class=\"c1\"># All cases in this scenario will use this factory (which may be modified on case-by-case basis)</span>\n    <span class=\"nt\">factory</span><span class=\"p\">:</span>\n        <span class=\"nt\">parents</span><span class=\"p\">:</span>\n          <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">SomeStudents</span>\n\n    <span class=\"nt\">cases</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">case</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">HelloGang</span>\n        <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Make sure we say hello to everyone</span>\n        <span class=\"nt\">expected</span><span class=\"p\">:</span>\n          <span class=\"nt\">data</span><span class=\"p\">:</span>\n            <span class=\"p p-Indicator\">-</span> <span class=\"nt\">target</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">salutations</span>\n              <span class=\"c1\"># The actual output may also contain the \"name\" field, but the expectation</span>\n              <span class=\"c1\"># will ignore comparing any fields not listed in the expected table.</span>\n              <span class=\"nt\">table</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">|</span>\n                <span class=\"no\">| id | salutation   |</span>\n                <span class=\"no\">| -  | -            |</span>\n                <span class=\"no\">| 1  | Hello Buffy  |</span>\n                <span class=\"no\">| 2  | Hello Willow |</span>\n</pre>\n<p>That's it. See also the <a href=\"tests/hello_world.yml\" rel=\"nofollow\">full YAML spec</a>.</p>\n<p>Now that we've described the full transform spec, we need to use it.  The first step is to\nparse the YAML file, send it to the dtspec api, and have dtspec generate source data:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">dtspec</span>\n<span class=\"kn\">import</span> <span class=\"nn\">yaml</span>\n\n<span class=\"n\">spec</span> <span class=\"o\">=</span> <span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">safe_load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"tests/hello_world.yml\"</span><span class=\"p\">))</span>\n<span class=\"n\">api</span> <span class=\"o\">=</span> <span class=\"n\">dtspec</span><span class=\"o\">.</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Api</span><span class=\"p\">(</span><span class=\"n\">spec</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">generate_sources</span><span class=\"p\">()</span>\n</pre>\n<p>The specific steps taken at this point are going to be sensitive to the data transformation\nenvironment being used, but we'll stick with our Pandas transformations for the sake of this\ntutorial.  Given this, we can define a simple function that converts the source data returned\nfrom dtspec into Pandas dataframes:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">parse_sources</span><span class=\"p\">(</span><span class=\"n\">sources</span><span class=\"p\">):</span>\n    <span class=\"s2\">\"Converts test data returned from dtspec api into Pandas dataframes\"</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span>\n        <span class=\"n\">source_name</span><span class=\"p\">:</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">.</span><span class=\"n\">from_records</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">serialize</span><span class=\"p\">())</span>\n        <span class=\"k\">for</span> <span class=\"n\">source_name</span><span class=\"p\">,</span> <span class=\"n\">data</span> <span class=\"ow\">in</span> <span class=\"n\">sources</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n</pre>\n<p>We can then run those test Pandas dataframes through our data transformation function.</p>\n<pre><span class=\"n\">sources_data</span> <span class=\"o\">=</span> <span class=\"n\">parse_sources</span><span class=\"p\">(</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">spec</span><span class=\"p\">[</span><span class=\"s2\">\"sources\"</span><span class=\"p\">])</span>\n<span class=\"n\">actual_data</span> <span class=\"o\">=</span> <span class=\"n\">hello_world_transformer</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">sources_data</span><span class=\"p\">)</span>\n</pre>\n<p>Next, we need to convert the output dataframes of the transformations, <code>actual_data</code>,\nback into a format that can be loaded into dtspec for comparison.  For Pandas,\nthis function is:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">serialize_actuals</span><span class=\"p\">(</span><span class=\"n\">actuals</span><span class=\"p\">):</span>\n    <span class=\"s2\">\"Converts Pandas dataframe results into form needed to load dtspec api actuals\"</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span>\n        <span class=\"n\">target_name</span><span class=\"p\">:</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to_json</span><span class=\"p\">(</span><span class=\"n\">orient</span><span class=\"o\">=</span><span class=\"s2\">\"records\"</span><span class=\"p\">))</span>\n        <span class=\"k\">for</span> <span class=\"n\">target_name</span><span class=\"p\">,</span> <span class=\"n\">dataframe</span> <span class=\"ow\">in</span> <span class=\"n\">actuals</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n</pre>\n<p>It is loaded into dtspec using:</p>\n<pre><span class=\"n\">serialized_actuals</span> <span class=\"o\">=</span> <span class=\"n\">serialize_actuals</span><span class=\"p\">(</span><span class=\"n\">actual_data</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">load_actuals</span><span class=\"p\">(</span><span class=\"n\">serialized_actuals</span><span class=\"p\">)</span>\n</pre>\n<p>Finally, dtspec can be called to run all of the expectations:</p>\n<pre><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">assert_expectations</span><span class=\"p\">()</span>\n</pre>\n<p>Putting all of this together:</p>\n<pre><span class=\"n\">spec</span> <span class=\"o\">=</span> <span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">safe_load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"tests/hello_world.yml\"</span><span class=\"p\">))</span>\n<span class=\"n\">api</span> <span class=\"o\">=</span> <span class=\"n\">dtspec</span><span class=\"o\">.</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Api</span><span class=\"p\">(</span><span class=\"n\">spec</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">generate_sources</span><span class=\"p\">()</span>\n\n<span class=\"n\">sources_data</span> <span class=\"o\">=</span> <span class=\"n\">parse_sources</span><span class=\"p\">(</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">spec</span><span class=\"p\">[</span><span class=\"s2\">\"sources\"</span><span class=\"p\">])</span>\n<span class=\"n\">actual_data</span> <span class=\"o\">=</span> <span class=\"n\">hello_world_transformer</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">sources_data</span><span class=\"p\">)</span>\n<span class=\"n\">serialized_actuals</span> <span class=\"o\">=</span> <span class=\"n\">serialize_actuals</span><span class=\"p\">(</span><span class=\"n\">actual_data</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">load_actuals</span><span class=\"p\">(</span><span class=\"n\">serialized_actuals</span><span class=\"p\">)</span>\n</pre>\n<p>Try running the above code and changing either the YAML spec or the <code>hello_world_transformer</code>\nfunction and see how dtspec responds.</p>\n<h3>Hello World With Multiple Test Cases</h3>\n<p>Running tests with multiple cases that reference the same data sources\nintroduces a complicating factor. One of the reasons that makes\nit hard to build tests for ETL/ELT is the fact that many data\ntransformation systems in use today have a high latency for even very\nsmall transformations.  For example, Redshift is a distributed RDBMS\nthat can process billions of rows in minutes, millions of rows in\nseconds, thousands of rows in seconds, or 10s of rows in, well,\nseconds.  Given these latency issues, we don't want to have to rely on\nloading data into our system, running a test, clearing out the data,\nloading some more, running the next test, and so on as is often\ndone when testing ORM-based applications like Rails or Django.</p>\n<p>dtspec seeks to minimize the number of requests on the data\ntransformation system in order to deal with these latency issues.\nIt does this by \"stacking\" the test data generated in each case\nand delivering back to the user all of this stacked data.  The user\nthen loads this stacked data into their data transformation system\n<strong>once</strong>, runs the data transformations <strong>once</strong>, and then collects\nthe resulting output <strong>once</strong>.</p>\n<p>Let's see how dtspec handles this in action.</p>\n<p>First, let's change our hello world data transformation a bit.  Instead of\njust saying hello to our heroes, let's say goodbye to any villians (as\nidentified by a <code>clique</code> data field).</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">hello_world_multiple_transformer</span><span class=\"p\">(</span><span class=\"n\">raw_students</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"nf\">salutation</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s2\">\"clique\"</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s2\">\"Scooby Gang\"</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"s2\">\"Hello </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s2\">\"name\"</span><span class=\"p\">])</span>\n        <span class=\"k\">return</span> <span class=\"s2\">\"Goodbye </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s2\">\"name\"</span><span class=\"p\">])</span>\n\n    <span class=\"n\">salutations_df</span> <span class=\"o\">=</span> <span class=\"n\">raw_students</span><span class=\"o\">.</span><span class=\"n\">copy</span><span class=\"p\">()</span>\n    <span class=\"n\">salutations_df</span><span class=\"p\">[</span><span class=\"s2\">\"salutation\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">salutations_df</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"n\">salutation</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"salutations\"</span><span class=\"p\">:</span> <span class=\"n\">salutations_df</span><span class=\"p\">}</span>\n</pre>\n<p>While it would be possible to test saying hello or goodbye in a single\ncase just by adding more records to the source data, we'll split it\ninto two to demonstrate how multiple cases work.  Here's how the YAML would look:</p>\n<pre><span class=\"nt\">scenarios</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">scenario</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Hello World With Multiple Cases</span>\n    <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">The simplest scenario</span>\n    <span class=\"nt\">factory</span><span class=\"p\">:</span>\n      <span class=\"nt\">parents</span><span class=\"p\">:</span>\n        <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">SomeStudents</span>\n\n    <span class=\"nt\">cases</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">case</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">HelloGang</span>\n        <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Make sure we say hello to everyone</span>\n        <span class=\"nt\">expected</span><span class=\"p\">:</span>\n          <span class=\"nt\">data</span><span class=\"p\">:</span>\n            <span class=\"p p-Indicator\">-</span> <span class=\"nt\">target</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">salutations</span>\n              <span class=\"nt\">table</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">|</span>\n                <span class=\"no\">| id | name   | clique      | salutation   |</span>\n                <span class=\"no\">| -  | -      | -           | -            |</span>\n                <span class=\"no\">| 1  | Buffy  | Scooby Gang | Hello Buffy  |</span>\n                <span class=\"no\">| 2  | Willow | Scooby Gang | Hello Willow |</span>\n\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">case</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">GoodbyeVillians</span>\n        <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Say goodbye to villians</span>\n        <span class=\"c1\"># For this case, we tweak the factory defined for the scenario.</span>\n        <span class=\"nt\">factory</span><span class=\"p\">:</span>\n          <span class=\"c1\"># The ids here might be the same as above.  However, these are just named</span>\n          <span class=\"c1\"># references and get translated into unique ids when the source data</span>\n          <span class=\"c1\"># is generated.</span>\n          <span class=\"nt\">data</span><span class=\"p\">:</span>\n            <span class=\"p p-Indicator\">-</span> <span class=\"nt\">source</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">raw_students</span>\n              <span class=\"nt\">table</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">|</span>\n                <span class=\"no\">| id | name     |</span>\n                <span class=\"no\">| -  | -        |</span>\n                <span class=\"no\">| 1  | Drusilla |</span>\n                <span class=\"no\">| 2  | Harmony  |</span>\n              <span class=\"c1\"># Use values to populate a constant over all records</span>\n              <span class=\"nt\">values</span><span class=\"p\">:</span>\n                <span class=\"p p-Indicator\">-</span> <span class=\"nt\">column</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">clique</span>\n                  <span class=\"nt\">value</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Vampires</span>\n\n        <span class=\"nt\">expected</span><span class=\"p\">:</span>\n          <span class=\"nt\">data</span><span class=\"p\">:</span>\n            <span class=\"c1\"># Again, the ids here are not the actual ids sent to dtspec after performing</span>\n            <span class=\"c1\"># the transformations.  They are just named references and dtspec</span>\n            <span class=\"c1\"># keeps track of the relationship between the actual ids and the named ones.</span>\n            <span class=\"p p-Indicator\">-</span> <span class=\"nt\">target</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">salutations</span>\n              <span class=\"nt\">table</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">|</span>\n                <span class=\"no\">| id | name     | clique   | salutation       |</span>\n                <span class=\"no\">| -  | -        | -        | -                |</span>\n                <span class=\"no\">| 1  | Drusilla | Vampires | Goodbye Drusilla |</span>\n                <span class=\"no\">| 2  | Harmony  | Vampires | Goodbye Harmony  |</span>\n</pre>\n<p>This won't quite work as is, because we're missing something.  We have\ntwo cases that describe variations on the source data <code>raw_students</code>\nand the output <code>salutations</code>.  dtspec collects the source data\ndefinitions from each case and stacks them into a single data source.\nThe user then runs the transformations on that source and generates a\nsingle target to provide back to dtspec.  But dtspec has to know which record\nbelongs to which case.  To do this, we have to define an\n<strong>identifier</strong> that tells dtspec which columns should be used to identify\na record as belonging to a case.  A good identifier is often a primary\nkey that uniquely defines a record, but it is not strictly required to\nbe unique across all records.</p>\n<p>For this example, we'll define an identifier called \"students\" with a single\n<strong>identifier attribute</strong> called <code>id</code> that is a unique integer:</p>\n<pre><span class=\"nt\">identifiers</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">identifier</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">students</span>\n    <span class=\"nt\">attributes</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">field</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">id</span>\n        <span class=\"nt\">generator</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">unique_integer</span>\n</pre>\n<p>We tell dtspec that this identifier is associated with the <code>id</code> columns of both\nthe source and the target via:</p>\n<pre><span class=\"nt\">sources</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">source</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">raw_students</span>\n    <span class=\"nt\">identifier_map</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">column</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">id</span>\n        <span class=\"nt\">identifier</span><span class=\"p\">:</span>\n          <span class=\"nt\">name</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">students</span>\n          <span class=\"nt\">attribute</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">id</span>\n\n\n<span class=\"nt\">targets</span><span class=\"p\">:</span>\n  <span class=\"p p-Indicator\">-</span> <span class=\"nt\">target</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">salutations</span>\n    <span class=\"nt\">identifier_map</span><span class=\"p\">:</span>\n      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">column</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">id</span>\n        <span class=\"nt\">identifier</span><span class=\"p\">:</span>\n          <span class=\"nt\">name</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">students</span>\n          <span class=\"nt\">attribute</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">id</span>\n</pre>\n<p>With the sources and targets with identifiers, the values we see in\nthe source factories and target expectations are not the values that\nare actually used in the data.  Instead, they are simply <strong>named\nrefereces</strong>.  For example, in the \"HelloGang\" case, <code>id=1</code> belongs to\nBuffy and <code>id=2</code> belongs to Willow.  But when dtspec generates the source\ndata, the actual values may be 3 and 9, or 4 and 7, or something else.\nUnique values are not generated in any deterministic manner -- each\nrun of dtspec can give a diferent set.  dtspec only guarantees that the\neach named reference will be a unique integer (via the <code>generator</code>\ndefined in the <code>identifier</code> section).</p>\n<p>Futhermore, in the second case called \"GoodbyeVillians\", we see that\n<code>id=1</code> belongs to Drusilla and <code>id=2</code> belongs to Harmony.  dtspec will\ngenerate unique values for this case as well, and they <strong>will not</strong>\nconflict with the values generated for the first case.  So dtspec will pass\nback to the user 4 total records (Buffy, Willow, Drusilla, Harmony) with 4\ndifferent ids</p>\n<p>With the <a href=\"tests/hello_world_multiple_cases.yml\" rel=\"nofollow\">full YAML spec</a> defined, we can\nrun the assertions in the same fashion as the the earlier example</p>\n<pre><span class=\"n\">spec</span> <span class=\"o\">=</span> <span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">safe_load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"tests/hello_world_multiple_cases.yml\"</span><span class=\"p\">))</span>\n<span class=\"n\">api</span> <span class=\"o\">=</span> <span class=\"n\">dtspec</span><span class=\"o\">.</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Api</span><span class=\"p\">(</span><span class=\"n\">spec</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">generate_sources</span><span class=\"p\">()</span>\n\n<span class=\"n\">sources_data</span> <span class=\"o\">=</span> <span class=\"n\">parse_sources</span><span class=\"p\">(</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">spec</span><span class=\"p\">[</span><span class=\"s2\">\"sources\"</span><span class=\"p\">])</span>\n<span class=\"n\">actual_data</span> <span class=\"o\">=</span> <span class=\"n\">hello_world_multiple_transformer</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">sources_data</span><span class=\"p\">)</span>\n<span class=\"n\">serialized_actuals</span> <span class=\"o\">=</span> <span class=\"n\">serialize_actuals</span><span class=\"p\">(</span><span class=\"n\">actual_data</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">load_actuals</span><span class=\"p\">(</span><span class=\"n\">serialized_actuals</span><span class=\"p\">)</span>\n\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">assert_expectations</span><span class=\"p\">()</span>\n</pre>\n<h4>Embedded Identifiers</h4>\n<p>It is also possible to embed identifiers in the value of a particular column.\nFor example, suppose our <code>salutation</code> column said hello to the <code>id</code> instead\nof the name of the person.  To make this work, we have to put a particular\nstring pattern in the column that indicates the name of the identifier, the\nattribute, and the named id - <code>{identifier.attribute[named_id]}</code>.  The\nyaml spec would look like:</p>\n<pre>      <span class=\"p p-Indicator\">-</span> <span class=\"nt\">case</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">HelloGang</span>\n        <span class=\"nt\">description</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Make sure we say hello to everyone</span>\n        <span class=\"nt\">expected</span><span class=\"p\">:</span>\n          <span class=\"nt\">data</span><span class=\"p\">:</span>\n            <span class=\"p p-Indicator\">-</span> <span class=\"nt\">target</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">salutations</span>\n              <span class=\"nt\">table</span><span class=\"p\">:</span> <span class=\"p p-Indicator\">|</span>\n                <span class=\"no\">| id | name   | clique      | salutation             |</span>\n                <span class=\"no\">| -  | -      | -           | -                      |</span>\n                <span class=\"no\">| 1  | Buffy  | Scooby Gang | Hello {students.id[1]} |</span>\n                <span class=\"no\">| 2  | Willow | Scooby Gang | Hello {students.id[2]} |</span>\n</pre>\n<p>The <a href=\"tests/realistic.yml\" rel=\"nofollow\">realistic example</a> discussed below has another example\nof using embedded identifiers.</p>\n<p><strong>Note</strong> that embedded identifiers cannot be used to associate records\nwith cases.  A target must have at least one column listed in the\n<code>identifier_map</code> section.</p>\n<h3>A More Realistic Example</h3>\n<p>Finally, let's example a more realistic example that one might\nencounter when building a data warehouse.  In these situations, we'll\nhave multiple sources, targets, scenarios, and cases.  Now suppose we\nhave a students table, where every student belongs to a school and\ntakes 0 to many classes.  Our goal is to create one denormalized table\nthat combines all of these data sources into one table.  Additionally,\nwe want to create a table that aggregates all of our students to give\na count of the students per school.  In Pandas, the data transformation\nmight look like:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">realistic_transformer</span><span class=\"p\">(</span><span class=\"n\">raw_students</span><span class=\"p\">,</span> <span class=\"n\">raw_schools</span><span class=\"p\">,</span> <span class=\"n\">raw_classes</span><span class=\"p\">,</span> <span class=\"n\">dim_date</span><span class=\"p\">):</span>\n\n    <span class=\"n\">student_schools</span> <span class=\"o\">=</span> <span class=\"n\">raw_students</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">(</span>\n        <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"id\"</span><span class=\"p\">:</span> <span class=\"s2\">\"student_id\"</span><span class=\"p\">,</span> <span class=\"s2\">\"external_id\"</span><span class=\"p\">:</span> <span class=\"s2\">\"card_id\"</span><span class=\"p\">}</span>\n    <span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span>\n        <span class=\"n\">raw_schools</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">(</span><span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"id\"</span><span class=\"p\">:</span> <span class=\"s2\">\"school_id\"</span><span class=\"p\">,</span> <span class=\"s2\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"school_name\"</span><span class=\"p\">}),</span>\n        <span class=\"n\">how</span><span class=\"o\">=</span><span class=\"s2\">\"inner\"</span><span class=\"p\">,</span>\n        <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s2\">\"school_id\"</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">student_classes</span> <span class=\"o\">=</span> <span class=\"n\">student_schools</span><span class=\"o\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span>\n        <span class=\"n\">raw_classes</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">(</span><span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"class_name\"</span><span class=\"p\">}),</span>\n        <span class=\"n\">how</span><span class=\"o\">=</span><span class=\"s2\">\"inner\"</span><span class=\"p\">,</span>\n        <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s2\">\"student_id\"</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span>\n        <span class=\"n\">dim_date</span><span class=\"o\">.</span><span class=\"n\">rename</span><span class=\"p\">(</span><span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"date\"</span><span class=\"p\">:</span> <span class=\"s2\">\"start_date\"</span><span class=\"p\">}),</span> <span class=\"n\">how</span><span class=\"o\">=</span><span class=\"s2\">\"left\"</span><span class=\"p\">,</span> <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s2\">\"start_date\"</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">student_classes</span><span class=\"p\">[</span><span class=\"s2\">\"student_class_id\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">student_classes</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span>\n        <span class=\"k\">lambda</span> <span class=\"n\">row</span><span class=\"p\">:</span> <span class=\"s2\">\"-\"</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">([</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s2\">\"card_id\"</span><span class=\"p\">]),</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s2\">\"class_name\"</span><span class=\"p\">])]),</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"n\">students_per_school</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n        <span class=\"n\">student_schools</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">([</span><span class=\"s2\">\"school_name\"</span><span class=\"p\">])</span>\n        <span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n        <span class=\"o\">.</span><span class=\"n\">to_frame</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"number_of_students\"</span><span class=\"p\">)</span>\n        <span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">{</span>\n        <span class=\"s2\">\"student_classes\"</span><span class=\"p\">:</span> <span class=\"n\">student_classes</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"students_per_school\"</span><span class=\"p\">:</span> <span class=\"n\">students_per_school</span><span class=\"p\">,</span>\n    <span class=\"p\">}</span>\n</pre>\n<p>Given the <a href=\"tests/realistic.yml\" rel=\"nofollow\">full YAML spec</a> defined, we can again run\nthe data assertions using a familiar pattern:</p>\n<pre><span class=\"n\">spec</span> <span class=\"o\">=</span> <span class=\"n\">yaml</span><span class=\"o\">.</span><span class=\"n\">safe_load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s2\">\"tests/realistic.yml\"</span><span class=\"p\">))</span>\n<span class=\"n\">api</span> <span class=\"o\">=</span> <span class=\"n\">dtspec</span><span class=\"o\">.</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">Api</span><span class=\"p\">(</span><span class=\"n\">spec</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">generate_sources</span><span class=\"p\">()</span>\n\n<span class=\"n\">sources_data</span> <span class=\"o\">=</span> <span class=\"n\">parse_sources</span><span class=\"p\">(</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">spec</span><span class=\"p\">[</span><span class=\"s2\">\"sources\"</span><span class=\"p\">])</span>\n<span class=\"n\">actual_data</span> <span class=\"o\">=</span> <span class=\"n\">hello_world_multiple_transformer</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">sources_data</span><span class=\"p\">)</span>\n<span class=\"n\">serialized_actuals</span> <span class=\"o\">=</span> <span class=\"n\">serialize_actuals</span><span class=\"p\">(</span><span class=\"n\">actual_data</span><span class=\"p\">)</span>\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">load_actuals</span><span class=\"p\">(</span><span class=\"n\">serialized_actuals</span><span class=\"p\">)</span>\n\n<span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">assert_expectations</span><span class=\"p\">()</span>\n</pre>\n<h2>Additional notes about dtspec</h2>\n<ul>\n<li>At the moment, all source data values are generated as strings.  It\nis up to the the user to enforce data types suitable to their data\ntransformation system.</li>\n<li>Additionally, data expectations are stringified prior to running assertions.</li>\n</ul>\n<h2>Contributing</h2>\n<p>We welcome contributors!  Please submit any suggests or pull requests in Github.</p>\n<h3>Developer setup</h3>\n<p>Create an appropriate python environment.  I like <a href=\"https://conda.io/miniconda.html\" rel=\"nofollow\">miniconda</a>,\nbut use whatever you like:</p>\n<pre><code>conda create --name dtspec python=3.6\nconda activate dtspec\n</code></pre>\n<p>Then install pip packages</p>\n<pre><code>pip install pip-tools\npip install --ignore-installed -r requirements.txt\n</code></pre>\n<p>run tests via</p>\n<pre><code>inv test\n</code></pre>\n<p>and the linter via</p>\n<pre><code>inv lint\n</code></pre>\n\n          </div>"}, "last_serial": 7011498, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "349de548be91ed8ea42e496bfc88628e", "sha256": "4b769cfa263ccdef7100994497f55241128d6e96b20b2dfcf6b7b58a632be7e1"}, "downloads": -1, "filename": "dtspec-0.1.0.tar.gz", "has_sig": false, "md5_digest": "349de548be91ed8ea42e496bfc88628e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 15407, "upload_time": "2019-09-24T18:38:29", "upload_time_iso_8601": "2019-09-24T18:38:29.225137Z", "url": "https://files.pythonhosted.org/packages/de/0f/c4a6fab0dee8d1f5888301f6728914acd503a15885206f76bcbc77b8f823/dtspec-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "fefbadac1ad520f334d3fd26b9d71e12", "sha256": "e0a058cf7a49d9f26e542b3517f172415345f6e87e66c2b63394849a35cd2a71"}, "downloads": -1, "filename": "dtspec-0.1.1.tar.gz", "has_sig": false, "md5_digest": "fefbadac1ad520f334d3fd26b9d71e12", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 16117, "upload_time": "2019-09-26T00:30:35", "upload_time_iso_8601": "2019-09-26T00:30:35.842779Z", "url": "https://files.pythonhosted.org/packages/1c/c1/106fc42af0dd73996374024fb7fe7532942d14fb2aeb756c538789409470/dtspec-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "8d2408693688207f4ee8a7288decf896", "sha256": "1b9247a4d3576f091405b3df9e4613c6f3bca1821c6a770f7a23bad4e4443918"}, "downloads": -1, "filename": "dtspec-0.2.0.tar.gz", "has_sig": false, "md5_digest": "8d2408693688207f4ee8a7288decf896", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 16218, "upload_time": "2019-10-01T00:12:38", "upload_time_iso_8601": "2019-10-01T00:12:38.127133Z", "url": "https://files.pythonhosted.org/packages/f2/02/571590d31b66983c10c09ce57ba386327bf04deebd526257b3057d3f2192/dtspec-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "e353af2e52884e4cdd92c0ac8c741e20", "sha256": "0ef674377d036f4c8590f8ca20861bdb341dc7fa18798d7437d4c3deb5d6d486"}, "downloads": -1, "filename": "dtspec-0.3.0.tar.gz", "has_sig": false, "md5_digest": "e353af2e52884e4cdd92c0ac8c741e20", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 17179, "upload_time": "2019-10-09T18:55:20", "upload_time_iso_8601": "2019-10-09T18:55:20.684475Z", "url": "https://files.pythonhosted.org/packages/7e/18/fe67c614ec1f12ece4817338937a32d57010e27cd33fec53f1a9a971290f/dtspec-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "9394c9270c39e2174c117bcabee1c6c8", "sha256": "63cfda9022a3e42ad2312978fabfaa35c27d3d34f536a222cf3ddd9301f7615c"}, "downloads": -1, "filename": "dtspec-0.4.0.tar.gz", "has_sig": false, "md5_digest": "9394c9270c39e2174c117bcabee1c6c8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 17544, "upload_time": "2019-10-30T23:55:06", "upload_time_iso_8601": "2019-10-30T23:55:06.905416Z", "url": "https://files.pythonhosted.org/packages/c7/27/0d14dbafda7f0cd25fd2245eaa1dadd6e2b0cb5d7cd6ca270cba469979e0/dtspec-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "c59ac73467f5d515f694e2f4cb4939ee", "sha256": "d42b93931680a55a9a32a6e4b4a25795a3537f74f7a3a2ee7be63093badb2ff2"}, "downloads": -1, "filename": "dtspec-0.5.0.tar.gz", "has_sig": false, "md5_digest": "c59ac73467f5d515f694e2f4cb4939ee", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 17913, "upload_time": "2019-11-04T23:44:56", "upload_time_iso_8601": "2019-11-04T23:44:56.779636Z", "url": "https://files.pythonhosted.org/packages/a0/a5/3b0039fd7237c0414794cd5ec35851c8399a0514b533ba332bf51535d106/dtspec-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "0d272bd5f7dc5b32197e25cb40873c20", "sha256": "4f3d2758af9c2deca43d873c2725a0a2b0ccf6b03668d924a73fbe7dbb6c6516"}, "downloads": -1, "filename": "dtspec-0.6.0.tar.gz", "has_sig": false, "md5_digest": "0d272bd5f7dc5b32197e25cb40873c20", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 18849, "upload_time": "2019-11-06T23:11:05", "upload_time_iso_8601": "2019-11-06T23:11:05.457716Z", "url": "https://files.pythonhosted.org/packages/84/4e/764c8f9b6b3efd080d510aca66f082fd2e33c6e1a578502b147b19f617de/dtspec-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "555713cad27452a6922b9487dab4d21d", "sha256": "e8f4c32cb7c04cd42202c59b49a3749092060a2e5fb7bc0e21593f1004ae82bf"}, "downloads": -1, "filename": "dtspec-0.6.1.tar.gz", "has_sig": false, "md5_digest": "555713cad27452a6922b9487dab4d21d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 18893, "upload_time": "2019-11-07T22:35:55", "upload_time_iso_8601": "2019-11-07T22:35:55.787412Z", "url": "https://files.pythonhosted.org/packages/d8/65/5d0a0f8ea68e6574e3b3f07ca14f7b0f318b7d5810cefb113651c0cc2c05/dtspec-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "fac0120611353d6424de2cfa7c5ae5a3", "sha256": "34c1ac6a2770dafdbe65fad4a743523477f150284dae45494f322d2690bde384"}, "downloads": -1, "filename": "dtspec-0.6.2.tar.gz", "has_sig": false, "md5_digest": "fac0120611353d6424de2cfa7c5ae5a3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 19071, "upload_time": "2019-11-08T17:15:18", "upload_time_iso_8601": "2019-11-08T17:15:18.016152Z", "url": "https://files.pythonhosted.org/packages/b8/44/a52277df6ecdd7acb7e3ad7858da5938441d06974c94573cbd9fdb2eb3eb/dtspec-0.6.2.tar.gz", "yanked": false}], "0.6.3": [{"comment_text": "", "digests": {"md5": "06b8e2b402f35aa3eb21ddadb1def9fe", "sha256": "84a786772c74d822bf6392c923b439a1787600340426ad2ec85ed2eb8cb51b6b"}, "downloads": -1, "filename": "dtspec-0.6.3.tar.gz", "has_sig": false, "md5_digest": "06b8e2b402f35aa3eb21ddadb1def9fe", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 19059, "upload_time": "2020-04-13T17:23:21", "upload_time_iso_8601": "2020-04-13T17:23:21.132531Z", "url": "https://files.pythonhosted.org/packages/b0/55/bb29c5e7b3cbcab3a1666f922e2dcef7e23f822a5f5169239921045e1594/dtspec-0.6.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "06b8e2b402f35aa3eb21ddadb1def9fe", "sha256": "84a786772c74d822bf6392c923b439a1787600340426ad2ec85ed2eb8cb51b6b"}, "downloads": -1, "filename": "dtspec-0.6.3.tar.gz", "has_sig": false, "md5_digest": "06b8e2b402f35aa3eb21ddadb1def9fe", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 19059, "upload_time": "2020-04-13T17:23:21", "upload_time_iso_8601": "2020-04-13T17:23:21.132531Z", "url": "https://files.pythonhosted.org/packages/b0/55/bb29c5e7b3cbcab3a1666f922e2dcef7e23f822a5f5169239921045e1594/dtspec-0.6.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:11 2020"}