{"info": {"author": "Yue Zhao", "author_email": "zhaoy@cmu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Financial and Insurance Industry", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "combo: A Python Toolbox for Machine Learning Model Combination\n==============================================================\n\n\n**Deployment & Documentation & Stats**\n\n.. image:: https://img.shields.io/pypi/v/combo.svg?color=brightgreen\n   :target: https://pypi.org/project/combo/\n   :alt: PyPI version\n\n\n.. image:: https://readthedocs.org/projects/pycombo/badge/?version=latest\n   :target: https://pycombo.readthedocs.io/en/latest/?badge=latest\n   :alt: Documentation Status\n\n\n.. image:: https://mybinder.org/badge_logo.svg\n   :target: https://mybinder.org/v2/gh/yzhao062/combo/master\n   :alt: Binder\n\n\n.. image:: https://img.shields.io/github/stars/yzhao062/combo.svg\n   :target: https://github.com/yzhao062/combo/stargazers\n   :alt: GitHub stars\n\n\n.. image:: https://img.shields.io/github/forks/yzhao062/combo.svg?color=blue\n   :target: https://github.com/yzhao062/combo/network\n   :alt: GitHub forks\n\n\n.. image:: https://pepy.tech/badge/combo\n   :target: https://pepy.tech/project/combo\n   :alt: Downloads\n\n\n.. image:: https://pepy.tech/badge/combo/month\n   :target: https://pepy.tech/project/combo\n   :alt: Downloads\n\n\n----\n\n\n**Build Status & Coverage & Maintainability & License**\n\n\n.. image:: https://travis-ci.org/yzhao062/combo.svg?branch=master\n   :target: https://travis-ci.org/yzhao062/combo\n   :alt: Build Status\n\n\n.. image:: https://circleci.com/gh/yzhao062/combo.svg?style=svg\n   :target: https://circleci.com/gh/yzhao062/combo\n   :alt: Circle CI\n\n\n.. image:: https://ci.appveyor.com/api/projects/status/te7uieha87305ike/branch/master?svg=true\n   :target: https://ci.appveyor.com/project/yzhao062/combo/branch/master\n   :alt: Build status\n\n\n.. image:: https://coveralls.io/repos/github/yzhao062/combo/badge.svg\n   :target: https://coveralls.io/github/yzhao062/combo\n   :alt: Coverage Status\n\n\n.. image:: https://api.codeclimate.com/v1/badges/465ebba81e990abb357b/maintainability\n   :target: https://codeclimate.com/github/yzhao062/combo/maintainability\n   :alt: Maintainability\n\n\n.. image:: https://img.shields.io/github/license/yzhao062/combo.svg\n   :target: https://github.com/yzhao062/combo/blob/master/LICENSE\n   :alt: License\n\n\n----\n\n\n**combo** is a comprehensive Python toolbox for **combining machine learning (ML) models and scores**.\n**Model combination** can be considered as a subtask of `ensemble learning <https://en.wikipedia.org/wiki/Ensemble_learning>`_,\nand has been widely used in real-world tasks and data science competitions like Kaggle [#Bell2007Lessons]_.\n**combo** has been used/introduced in various research works since its inception [#Raschka2020Machine]_ [#Zhao2019PyOD]_.\n\n**combo** library supports the combination of models and score from\nkey ML libraries such as `scikit-learn <https://scikit-learn.org/stable/index.html>`_,\n`xgboost <https://xgboost.ai/>`_, and `LightGBM <https://github.com/microsoft/LightGBM>`_,\nfor crucial tasks including classification, clustering, anomaly detection.\nSee figure below for some representative combination approaches.\n\n.. image:: https://raw.githubusercontent.com/yzhao062/combo/master/docs/figs/framework_demo.png\n   :target: https://raw.githubusercontent.com/yzhao062/combo/master/docs/figs/framework_demo.png\n   :alt: Combination Framework Demo\n\n\n**combo** is featured for:\n\n* **Unified APIs, detailed documentation, and interactive examples** across various algorithms.\n* **Advanced and latest models**, such as Stacking/DCS/DES/EAC/LSCP.\n* **Comprehensive coverage** for classification, clustering, anomaly detection, and raw score.\n* **Optimized performance with JIT and parallelization** when possible, using `numba <https://github.com/numba/numba>`_ and `joblib <https://github.com/joblib/joblib>`_.\n\n\n**API Demo**\\ :\n\n.. code-block:: python\n\n\n   from combo.models.classifier_stacking import Stacking\n   # initialize a group of base classifiers\n   classifiers = [DecisionTreeClassifier(), LogisticRegression(),\n                  KNeighborsClassifier(), RandomForestClassifier(),\n                  GradientBoostingClassifier()]\n\n   clf = Stacking(base_estimators=classifiers) # initialize a Stacking model\n   clf.fit(X_train, y_train) # fit the model\n\n   # predict on unseen data\n   y_test_labels = clf.predict(X_test)  # label prediction\n   y_test_proba = clf.predict_proba(X_test)  # probability prediction\n\n\n**Citing combo**\\ :\n\n`combo paper <http://www.andrew.cmu.edu/user/yuezhao2/papers/20-aaai-combo.pdf>`_ is published in\n`AAAI 2020 <https://aaai.org/Conferences/AAAI-20/>`_ (demo track).\nIf you use combo in a scientific publication, we would appreciate citations to the following paper::\n\n    @inproceedings{zhao2020combo,\n      title={Combining Machine Learning Models and Scores using combo library},\n      author={Zhao, Yue and Wang, Xuejian and Cheng, Cheng and Ding, Xueying},\n      booktitle={Thirty-Fourth AAAI Conference on Artificial Intelligence},\n      month = {Feb},\n      year={2020},\n      address = {New York, USA}\n    }\n\nor::\n\n    Zhao, Y., Wang, X., Cheng, C. and Ding, X., 2020. Combining Machine Learning Models and Scores using combo library. Thirty-Fourth AAAI Conference on Artificial Intelligence.\n\n\n**Key Links and Resources**\\ :\n\n\n* `awesome-ensemble-learning <https://github.com/yzhao062/awesome-ensemble-learning>`_ (ensemble learning related books, papers, and more)\n* `View the latest codes on Github <https://github.com/yzhao062/combo>`_\n* `View the documentation & API <https://pycombo.readthedocs.io/>`_\n* `View all examples <https://github.com/yzhao062/combo/tree/master/examples>`_\n* `View the demo video for AAAI 2020 <https://youtu.be/PaSJ49Ij7w4>`_\n* `Execute Interactive Jupyter Notebooks <https://mybinder.org/v2/gh/yzhao062/combo/master>`_\n\n\n**Table of Contents**\\ :\n\n\n* `Installation <#installation>`_\n* `API Cheatsheet & Reference <#api-cheatsheet--reference>`_\n* `Implemented Algorithms <#implemented-algorithms>`_\n* `Example 1: Classifier Combination with Stacking/DCS/DES <#example-of-stackingdcsdes>`_\n* `Example 2: Simple Classifier Combination <#example-of-classifier-combination>`_\n* `Example 3: Clustering Combination <#example-of-clustering-combination>`_\n* `Example 4: Outlier Detector Combination <#example-of-outlier-detector-combination>`_\n* `Development Status <#development-status>`_\n* `Inclusion Criteria <#inclusion-criteria>`_\n\n\n----\n\n\n\nInstallation\n^^^^^^^^^^^^\n\nIt is recommended to use **pip** for installation. Please make sure\n**the latest version** is installed, as combo is updated frequently:\n\n.. code-block:: bash\n\n   pip install combo            # normal install\n   pip install --upgrade combo  # or update if needed\n   pip install --pre combo      # or include pre-release version for new features\n\nAlternatively, you could clone and run setup.py file:\n\n.. code-block:: bash\n\n   git clone https://github.com/yzhao062/combo.git\n   cd combo\n   pip install .\n\n\n**Required Dependencies**\\ :\n\n\n* Python 3.5, 3.6, or 3.7\n* joblib\n* matplotlib (**optional for running examples**)\n* numpy>=1.13\n* numba>=0.35\n* pyod\n* scipy>=0.19.1\n* scikit_learn>=0.20\n\n\n**Note on Python 2**\\ :\nThe maintenance of Python 2.7 will be stopped by January 1, 2020 (see `official announcement <https://github.com/python/devguide/pull/344>`_).\nTo be consistent with the Python change and combo's dependent libraries, e.g., scikit-learn,\n**combo only supports Python 3.5+** and we encourage you to use\nPython 3.5 or newer for the latest functions and bug fixes. More information can\nbe found at `Moving to require Python 3 <https://python3statement.org/>`_.\n\n\n----\n\n\nAPI Cheatsheet & Reference\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFull API Reference: (https://pycombo.readthedocs.io/en/latest/api.html).\nThe following APIs are consistent for most of the models\n(API Cheatsheet: https://pycombo.readthedocs.io/en/latest/api_cc.html).\n\n* **fit(X, y)**\\ : Fit estimator. y is optional for unsupervised methods.\n* **predict(X)**\\ : Predict on a particular sample once the estimator is fitted.\n* **predict_proba(X)**\\ : Predict the probability of a sample belonging to each class once the estimator is fitted.\n* **fit_predict(X, y)**\\ : Fit estimator and predict on X. y is optional for unsupervised methods.\n\nFor raw score combination (after the score matrix is generated),\nuse individual methods from\n`\"score_comb.py\" <https://github.com/yzhao062/combo/blob/master/combo/models/score_comb.py>`_ directly.\nRaw score combination API: (https://pycombo.readthedocs.io/en/latest/api.html#score-combination).\n\n\n----\n\n\nImplemented Algorithms\n^^^^^^^^^^^^^^^^^^^^^^\n\n**combo** groups combination frameworks by tasks. General purpose methods are\nfundamental ones which can be applied to various tasks.\n\n===================  ======================================================================================================  =====  ===========================================\nTask                 Algorithm                                                                                               Year   Ref\n===================  ======================================================================================================  =====  ===========================================\nGeneral Purpose      Average & Weighted Average: average across all scores/prediction results, maybe with weights            N/A    [#Zhou2012Ensemble]_\nGeneral Purpose      Maximization: simple combination by taking the maximum scores                                           N/A    [#Zhou2012Ensemble]_\nGeneral Purpose      Median: take the median value across all scores/prediction results                                      N/A    [#Zhou2012Ensemble]_\nGeneral Purpose      Majority Vote & Weighted Majority Vote                                                                  N/A    [#Zhou2012Ensemble]_\nClassification       SimpleClassifierAggregator: combining classifiers by general purpose methods above                      N/A    N/A\nClassification       DCS: Dynamic Classifier Selection (Combination of multiple classifiers using local accuracy estimates)  1997   [#Woods1997Combination]_\nClassification       DES: Dynamic Ensemble Selection (From dynamic classifier selection to dynamic ensemble selection)       2008   [#Ko2008From]_\nClassification       Stacking (meta ensembling): use a meta learner to learn the base classifier results                     N/A    [#Gorman2016Kaggle]_\nClustering           Clusterer Ensemble: combine the results of multiple clustering results by relabeling                    2006   [#Zhou2006Clusterer]_\nClustering           Combining multiple clusterings using evidence accumulation (EAC)                                        2002   [#Fred2005Combining]_\nAnomaly Detection    SimpleDetectorCombination: combining outlier detectors by general purpose methods above                 N/A    [#Aggarwal2017Outlier]_\nAnomaly Detection    Average of Maximum (AOM): divide base detectors into subgroups to take the maximum, and then average    2015   [#Aggarwal2015Theoretical]_\nAnomaly Detection    Maximum of Average (MOA): divide base detectors into subgroups to take the average, and then maximize   2015   [#Aggarwal2015Theoretical]_\nAnomaly Detection    XGBOD: a semi-supervised combination framework for outlier detection                                    2018   [#Zhao2018XGBOD]_\nAnomaly Detection    Locally Selective Combination (LSCP)                                                                    2019   [#Zhao2019LSCP]_\n===================  ======================================================================================================  =====  ===========================================\n\n\n**The comparison among selected implemented models** is made available below\n(\\ `Figure <https://raw.githubusercontent.com/yzhao062/combo/master/examples/compare_selected_classifiers.png>`_\\ ,\n`compare_selected_classifiers.py <https://github.com/yzhao062/combo/blob/master/examples/compare_selected_classifiers.py>`_\\, `Interactive Jupyter Notebooks <https://mybinder.org/v2/gh/yzhao062/combo/master>`_\\ ).\nFor Jupyter Notebooks, please navigate to **\"/notebooks/compare_selected_classifiers.ipynb\"**.\n\n\n.. image:: https://raw.githubusercontent.com/yzhao062/combo/master/examples/compare_selected_classifiers.png\n   :target: https://raw.githubusercontent.com/yzhao062/combo/master/examples/compare_selected_classifiers.png\n   :alt: Comparison of Selected Models\n\n\n----\n\n\n**All implemented modes** are associated with examples, check\n`\"combo examples\" <https://github.com/yzhao062/combo/blob/master/examples>`_\nfor more information.\n\n\nExample of Stacking/DCS/DES\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n`\"examples/classifier_stacking_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/classifier_stacking_example.py>`_\ndemonstrates the basic API of stacking (meta ensembling). `\"examples/classifier_dcs_la_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/classifier_dcs_la_example.py>`_\ndemonstrates the basic API of Dynamic Classifier Selection by Local Accuracy. `\"examples/classifier_des_la_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/classifier_des_la_example.py>`_\ndemonstrates the basic API of Dynamic Ensemble Selection by Local Accuracy.\n\nIt is noted **the basic API is consistent across all these models**.\n\n\n#. Initialize a group of classifiers as base estimators\n\n   .. code-block:: python\n\n\n      # initialize a group of classifiers\n      classifiers = [DecisionTreeClassifier(random_state=random_state),\n                     LogisticRegression(random_state=random_state),\n                     KNeighborsClassifier(),\n                     RandomForestClassifier(random_state=random_state),\n                     GradientBoostingClassifier(random_state=random_state)]\n\n\n#. Initialize, fit, predict, and evaluate with Stacking\n\n   .. code-block:: python\n\n\n      from combo.models.classifier_stacking import Stacking\n\n      clf = Stacking(base_estimators=classifiers, n_folds=4, shuffle_data=False,\n                   keep_original=True, use_proba=False, random_state=random_state)\n\n      clf.fit(X_train, y_train)\n      y_test_predict = clf.predict(X_test)\n      evaluate_print('Stacking | ', y_test, y_test_predict)\n\n\n#. See a sample output of classifier_stacking_example.py\n\n   .. code-block:: bash\n\n\n      Decision Tree        | Accuracy:0.9386, ROC:0.9383, F1:0.9521\n      Logistic Regression  | Accuracy:0.9649, ROC:0.9615, F1:0.973\n      K Neighbors          | Accuracy:0.9561, ROC:0.9519, F1:0.9662\n      Gradient Boosting    | Accuracy:0.9605, ROC:0.9524, F1:0.9699\n      Random Forest        | Accuracy:0.9605, ROC:0.961, F1:0.9693\n\n      Stacking             | Accuracy:0.9868, ROC:0.9841, F1:0.9899\n\n\n----\n\n\nExample of Classifier Combination\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n`\"examples/classifier_comb_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/classifier_comb_example.py>`_\ndemonstrates the basic API of predicting with multiple classifiers. **It is noted that the API across all other algorithms are consistent/similar**.\n\n#. Initialize a group of classifiers as base estimators\n\n   .. code-block:: python\n\n\n      # initialize a group of classifiers\n      classifiers = [DecisionTreeClassifier(random_state=random_state),\n                     LogisticRegression(random_state=random_state),\n                     KNeighborsClassifier(),\n                     RandomForestClassifier(random_state=random_state),\n                     GradientBoostingClassifier(random_state=random_state)]\n\n\n#. Initialize, fit, predict, and evaluate with a simple aggregator (average)\n\n   .. code-block:: python\n\n\n      from combo.models.classifier_comb import SimpleClassifierAggregator\n\n      clf = SimpleClassifierAggregator(classifiers, method='average')\n      clf.fit(X_train, y_train)\n      y_test_predicted = clf.predict(X_test)\n      evaluate_print('Combination by avg   |', y_test, y_test_predicted)\n\n\n\n#. See a sample output of classifier_comb_example.py\n\n   .. code-block:: bash\n\n\n      Decision Tree        | Accuracy:0.9386, ROC:0.9383, F1:0.9521\n      Logistic Regression  | Accuracy:0.9649, ROC:0.9615, F1:0.973\n      K Neighbors          | Accuracy:0.9561, ROC:0.9519, F1:0.9662\n      Gradient Boosting    | Accuracy:0.9605, ROC:0.9524, F1:0.9699\n      Random Forest        | Accuracy:0.9605, ROC:0.961, F1:0.9693\n\n      Combination by avg   | Accuracy:0.9693, ROC:0.9677, F1:0.9763\n      Combination by w_avg | Accuracy:0.9781, ROC:0.9716, F1:0.9833\n      Combination by max   | Accuracy:0.9518, ROC:0.9312, F1:0.9642\n      Combination by w_vote| Accuracy:0.9649, ROC:0.9644, F1:0.9728\n      Combination by median| Accuracy:0.9693, ROC:0.9677, F1:0.9763\n\n\n----\n\n\nExample of Clustering Combination\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n`\"examples/cluster_comb_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/cluster_comb_example.py>`_\ndemonstrates the basic API of combining multiple base clustering estimators. `\"examples/cluster_eac_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/cluster_eac_example.py>`_\ndemonstrates the basic API of Combining multiple clusterings using evidence accumulation (EAC).\n\n#. Initialize a group of clustering methods as base estimators\n\n   .. code-block:: python\n\n\n      # Initialize a set of estimators\n      estimators = [KMeans(n_clusters=n_clusters),\n                    MiniBatchKMeans(n_clusters=n_clusters),\n                    AgglomerativeClustering(n_clusters=n_clusters)]\n\n\n#. Initialize a Clusterer Ensemble class and fit the model\n\n   .. code-block:: python\n\n\n      from combo.models.cluster_comb import ClustererEnsemble\n      # combine by Clusterer Ensemble\n      clf = ClustererEnsemble(estimators, n_clusters=n_clusters)\n      clf.fit(X)\n\n\n#. Get the aligned results\n\n   .. code-block:: python\n\n\n      # generate the labels on X\n      aligned_labels = clf.aligned_labels_\n      predicted_labels = clf.labels_\n\n\n\nExample of Outlier Detector Combination\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n`\"examples/detector_comb_example.py\" <https://github.com/yzhao062/combo/blob/master/examples/detector_comb_example.py>`_\ndemonstrates the basic API of combining multiple base outlier detectors.\n\n#. Initialize a group of outlier detection methods as base estimators\n\n   .. code-block:: python\n\n\n      # Initialize a set of estimators\n      detectors = [KNN(), LOF(), OCSVM()]\n\n\n#. Initialize a simple averaging aggregator, fit the model, and make\n   the prediction.\n\n   .. code-block:: python\n\n\n      from combo.models.detector combination import SimpleDetectorAggregator\n      clf = SimpleDetectorAggregator(base_estimators=detectors)\n      clf_name = 'Aggregation by Averaging'\n      clf.fit(X_train)\n\n      y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n      y_train_scores = clf.decision_scores_  # raw outlier scores\n\n      # get the prediction on the test data\n      y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n      y_test_scores = clf.decision_function(X_test)  # outlier scores\n\n\n#. Evaluate the prediction using ROC and Precision @ Rank n.\n\n   .. code-block:: python\n\n      # evaluate and print the results\n      print(\"\\nOn Training Data:\")\n      evaluate_print(clf_name, y_train, y_train_scores)\n      print(\"\\nOn Test Data:\")\n      evaluate_print(clf_name, y_test, y_test_scores)\n\n#. See sample outputs on both training and test data.\n\n   .. code-block:: bash\n\n      On Training Data:\n      Aggregation by Averaging ROC:0.9994, precision @ rank n:0.95\n\n      On Test Data:\n      Aggregation by Averaging ROC:1.0, precision @ rank n:1.0\n\n\n----\n\n\nDevelopment Status\n^^^^^^^^^^^^^^^^^^\n\n**combo** is currently **under development** as of July 30, 2019. A concrete plan has\nbeen laid out and will be implemented in the next few months.\n\nSimilar to other libraries built by us, e.g., Python Outlier Detection Toolbox\n(`pyod <https://github.com/yzhao062/pyod>`_),\n**combo** is also targeted to be published in *Journal of Machine Learning Research (JMLR)*,\n`open-source software track <http://www.jmlr.org/mloss/>`_. A demo paper to\n*AAAI* or *IJCAI* may be submitted soon for progress update.\n\n**Watch & Star** to get the latest update! Also feel free to send me an email (zhaoy@cmu.edu)\nfor suggestions and ideas.\n\n\n----\n\n\nInclusion Criteria\n^^^^^^^^^^^^^^^^^^\n\nSimilarly to scikit-learn, We mainly consider well-established algorithms for inclusion.\nA rule of thumb is at least two years since publication, 50+ citations, and usefulness.\n\nHowever, we encourage the author(s) of newly proposed models to share and add your implementation into combo\nfor boosting ML accessibility and reproducibility.\nThis exception only applies if you could commit to the maintenance of your model for at least two year period.\n\n\n----\n\n\nReference\n^^^^^^^^^\n\n.. [#Aggarwal2015Theoretical] Aggarwal, C.C. and Sathe, S., 2015. Theoretical foundations and algorithms for outlier ensembles. *ACM SIGKDD Explorations Newsletter*, 17(1), pp.24-47.\n\n.. [#Aggarwal2017Outlier] Aggarwal, C.C. and Sathe, S., 2017. Outlier ensembles: An introduction. Springer.\n\n.. [#Bell2007Lessons] Bell, R.M. and Koren, Y., 2007. Lessons from the Netflix prize challenge. *SIGKDD Explorations*, 9(2), pp.75-79.\n\n.. [#Gorman2016Kaggle] Gorman, B. (2016). A Kaggler's Guide to Model Stacking in Practice. [online] The Official Blog of Kaggle.com. Available at: http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice [Accessed 26 Jul. 2019].\n\n.. [#Ko2008From] Ko, A.H., Sabourin, R. and Britto Jr, A.S., 2008. From dynamic classifier selection to dynamic ensemble selection. *Pattern recognition*, 41(5), pp.1718-1731.\n\n.. [#Fred2005Combining] Fred, A. L. N., & Jain, A. K. (2005). Combining multiple clusterings using evidence accumulation. *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 27(6), 835\u2013850. https://doi.org/10.1109/TPAMI.2005.113\n\n.. [#Raschka2020Machine] Raschka, S., Patterson, J. and Nolet, C., 2020. Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence. arXiv preprint arXiv:2002.04803.\n\n.. [#Woods1997Combination] Woods, K., Kegelmeyer, W.P. and Bowyer, K., 1997. Combination of multiple classifiers using local accuracy estimates. *IEEE transactions on pattern analysis and machine intelligence*, 19(4), pp.405-410.\n\n.. [#Zhao2018XGBOD] Zhao, Y. and Hryniewicki, M.K. XGBOD: Improving Supervised Outlier Detection with Unsupervised Representation Learning. *IEEE International Joint Conference on Neural Networks*, 2018.\n\n.. [#Zhao2019LSCP] Zhao, Y., Nasrullah, Z., Hryniewicki, M.K. and Li, Z., 2019, May. LSCP: Locally selective combination in parallel outlier ensembles. In *Proceedings of the 2019 SIAM International Conference on Data Mining (SDM)*, pp. 585-593. Society for Industrial and Applied Mathematics.\n\n.. [#Zhao2019PyOD] Zhao, Y., Nasrullah, Z. and Li, Z., 2019. PyOD: A Python Toolbox for Scalable Outlier Detection. *Journal of Machine Learning Research*, 20, pp.1-7.\n\n.. [#Zhou2006Clusterer] Zhou, Z.H. and Tang, W., 2006. Clusterer ensemble. *Knowledge-Based Systems*, 19(1), pp.77-83.\n\n.. [#Zhou2012Ensemble] Zhou, Z.H., 2012. Ensemble methods: foundations and algorithms. Chapman and Hall/CRC.", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "https://github.com/yzhao062/combo/archive/master.zip", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/yzhao062/combo", "keywords": "ensemble learning,model combination,outlier ensembles,data mining,machine learning,clustering,python", "license": "", "maintainer": "", "maintainer_email": "", "name": "combo", "package_url": "https://pypi.org/project/combo/", "platform": "", "project_url": "https://pypi.org/project/combo/", "project_urls": {"Download": "https://github.com/yzhao062/combo/archive/master.zip", "Homepage": "https://github.com/yzhao062/combo"}, "release_url": "https://pypi.org/project/combo/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "A Python Toolbox for Machine Learning Model Combination", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><strong>Deployment &amp; Documentation &amp; Stats</strong></p>\n<a href=\"https://pypi.org/project/combo/\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4ae0cbf69120531bd07c50594570f4c2ee99c0f4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f636f6d626f2e7376673f636f6c6f723d627269676874677265656e\"></a>\n<a href=\"https://pycombo.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a66d02f88fdc7f58d852cace0cef0d3f69de9e14/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7079636f6d626f2f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://mybinder.org/v2/gh/yzhao062/combo/master\" rel=\"nofollow\"><img alt=\"Binder\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85e91bbb928104e4ce317951541520c6b9c170e1/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667\"></a>\n<a href=\"https://github.com/yzhao062/combo/stargazers\" rel=\"nofollow\"><img alt=\"GitHub stars\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f92d2b13342ad654bc5eaf8c376367bf16d494e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f797a68616f3036322f636f6d626f2e737667\"></a>\n<a href=\"https://github.com/yzhao062/combo/network\" rel=\"nofollow\"><img alt=\"GitHub forks\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c7b5d4a479eafdaab9213bf3e8ff309491b2d869/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f797a68616f3036322f636f6d626f2e7376673f636f6c6f723d626c7565\"></a>\n<a href=\"https://pepy.tech/project/combo\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b79ca29174e998b839b158950c6f8980b0835365/68747470733a2f2f706570792e746563682f62616467652f636f6d626f\"></a>\n<a href=\"https://pepy.tech/project/combo\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4b768027929deb7beca5dd1afc3cba39ade95915/68747470733a2f2f706570792e746563682f62616467652f636f6d626f2f6d6f6e7468\"></a>\n<hr class=\"docutils\">\n<p><strong>Build Status &amp; Coverage &amp; Maintainability &amp; License</strong></p>\n<a href=\"https://travis-ci.org/yzhao062/combo\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8a101f7b47108f14537b65579d5a42e7f8f988d/68747470733a2f2f7472617669732d63692e6f72672f797a68616f3036322f636f6d626f2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://circleci.com/gh/yzhao062/combo\" rel=\"nofollow\"><img alt=\"Circle CI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/94bbe0e7d665c164dba5562080409fece9232f90/68747470733a2f2f636972636c6563692e636f6d2f67682f797a68616f3036322f636f6d626f2e7376673f7374796c653d737667\"></a>\n<a href=\"https://ci.appveyor.com/project/yzhao062/combo/branch/master\" rel=\"nofollow\"><img alt=\"Build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f6a00b887321461930922ebc754040e5308adf73/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f74653775696568613837333035696b652f6272616e63682f6d61737465723f7376673d74727565\"></a>\n<a href=\"https://coveralls.io/github/yzhao062/combo\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9f2c7ecb4ed1cf74e225bd6947028341643916e4/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f797a68616f3036322f636f6d626f2f62616467652e737667\"></a>\n<a href=\"https://codeclimate.com/github/yzhao062/combo/maintainability\" rel=\"nofollow\"><img alt=\"Maintainability\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3d287e64d6f330d1c95ffaad5cb59e3bfbbbb301/68747470733a2f2f6170692e636f6465636c696d6174652e636f6d2f76312f6261646765732f34363565626261383165393930616262333537622f6d61696e7461696e6162696c697479\"></a>\n<a href=\"https://github.com/yzhao062/combo/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2442e2861b3bdf9b6a6d065aaa6d17326ed13c54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f797a68616f3036322f636f6d626f2e737667\"></a>\n<hr class=\"docutils\">\n<p><strong>combo</strong> is a comprehensive Python toolbox for <strong>combining machine learning (ML) models and scores</strong>.\n<strong>Model combination</strong> can be considered as a subtask of <a href=\"https://en.wikipedia.org/wiki/Ensemble_learning\" rel=\"nofollow\">ensemble learning</a>,\nand has been widely used in real-world tasks and data science competitions like Kaggle <a href=\"#bell2007lessons\" id=\"id1\" rel=\"nofollow\">[3]</a>.\n<strong>combo</strong> has been used/introduced in various research works since its inception <a href=\"#raschka2020machine\" id=\"id2\" rel=\"nofollow\">[7]</a> <a href=\"#zhao2019pyod\" id=\"id3\" rel=\"nofollow\">[11]</a>.</p>\n<p><strong>combo</strong> library supports the combination of models and score from\nkey ML libraries such as <a href=\"https://scikit-learn.org/stable/index.html\" rel=\"nofollow\">scikit-learn</a>,\n<a href=\"https://xgboost.ai/\" rel=\"nofollow\">xgboost</a>, and <a href=\"https://github.com/microsoft/LightGBM\" rel=\"nofollow\">LightGBM</a>,\nfor crucial tasks including classification, clustering, anomaly detection.\nSee figure below for some representative combination approaches.</p>\n<a href=\"https://raw.githubusercontent.com/yzhao062/combo/master/docs/figs/framework_demo.png\" rel=\"nofollow\"><img alt=\"Combination Framework Demo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57235e0669be6319ba7aa24a7ab258f6b5d2cdac/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f797a68616f3036322f636f6d626f2f6d61737465722f646f63732f666967732f6672616d65776f726b5f64656d6f2e706e67\"></a>\n<p><strong>combo</strong> is featured for:</p>\n<ul>\n<li><strong>Unified APIs, detailed documentation, and interactive examples</strong> across various algorithms.</li>\n<li><strong>Advanced and latest models</strong>, such as Stacking/DCS/DES/EAC/LSCP.</li>\n<li><strong>Comprehensive coverage</strong> for classification, clustering, anomaly detection, and raw score.</li>\n<li><strong>Optimized performance with JIT and parallelization</strong> when possible, using <a href=\"https://github.com/numba/numba\" rel=\"nofollow\">numba</a> and <a href=\"https://github.com/joblib/joblib\" rel=\"nofollow\">joblib</a>.</li>\n</ul>\n<p><strong>API Demo</strong>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">combo.models.classifier_stacking</span> <span class=\"kn\">import</span> <span class=\"n\">Stacking</span>\n<span class=\"c1\"># initialize a group of base classifiers</span>\n<span class=\"n\">classifiers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">DecisionTreeClassifier</span><span class=\"p\">(),</span> <span class=\"n\">LogisticRegression</span><span class=\"p\">(),</span>\n               <span class=\"n\">KNeighborsClassifier</span><span class=\"p\">(),</span> <span class=\"n\">RandomForestClassifier</span><span class=\"p\">(),</span>\n               <span class=\"n\">GradientBoostingClassifier</span><span class=\"p\">()]</span>\n\n<span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">Stacking</span><span class=\"p\">(</span><span class=\"n\">base_estimators</span><span class=\"o\">=</span><span class=\"n\">classifiers</span><span class=\"p\">)</span> <span class=\"c1\"># initialize a Stacking model</span>\n<span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span> <span class=\"c1\"># fit the model</span>\n\n<span class=\"c1\"># predict on unseen data</span>\n<span class=\"n\">y_test_labels</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>  <span class=\"c1\"># label prediction</span>\n<span class=\"n\">y_test_proba</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">predict_proba</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>  <span class=\"c1\"># probability prediction</span>\n</pre>\n<p><strong>Citing combo</strong>:</p>\n<p><a href=\"http://www.andrew.cmu.edu/user/yuezhao2/papers/20-aaai-combo.pdf\" rel=\"nofollow\">combo paper</a> is published in\n<a href=\"https://aaai.org/Conferences/AAAI-20/\" rel=\"nofollow\">AAAI 2020</a> (demo track).\nIf you use combo in a scientific publication, we would appreciate citations to the following paper:</p>\n<pre>@inproceedings{zhao2020combo,\n  title={Combining Machine Learning Models and Scores using combo library},\n  author={Zhao, Yue and Wang, Xuejian and Cheng, Cheng and Ding, Xueying},\n  booktitle={Thirty-Fourth AAAI Conference on Artificial Intelligence},\n  month = {Feb},\n  year={2020},\n  address = {New York, USA}\n}\n</pre>\n<p>or:</p>\n<pre>Zhao, Y., Wang, X., Cheng, C. and Ding, X., 2020. Combining Machine Learning Models and Scores using combo library. Thirty-Fourth AAAI Conference on Artificial Intelligence.\n</pre>\n<p><strong>Key Links and Resources</strong>:</p>\n<ul>\n<li><a href=\"https://github.com/yzhao062/awesome-ensemble-learning\" rel=\"nofollow\">awesome-ensemble-learning</a> (ensemble learning related books, papers, and more)</li>\n<li><a href=\"https://github.com/yzhao062/combo\" rel=\"nofollow\">View the latest codes on Github</a></li>\n<li><a href=\"https://pycombo.readthedocs.io/\" rel=\"nofollow\">View the documentation &amp; API</a></li>\n<li><a href=\"https://github.com/yzhao062/combo/tree/master/examples\" rel=\"nofollow\">View all examples</a></li>\n<li><a href=\"https://youtu.be/PaSJ49Ij7w4\" rel=\"nofollow\">View the demo video for AAAI 2020</a></li>\n<li><a href=\"https://mybinder.org/v2/gh/yzhao062/combo/master\" rel=\"nofollow\">Execute Interactive Jupyter Notebooks</a></li>\n</ul>\n<p><strong>Table of Contents</strong>:</p>\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#api-cheatsheet--reference\" rel=\"nofollow\">API Cheatsheet &amp; Reference</a></li>\n<li><a href=\"#implemented-algorithms\" rel=\"nofollow\">Implemented Algorithms</a></li>\n<li><a href=\"#example-of-stackingdcsdes\" rel=\"nofollow\">Example 1: Classifier Combination with Stacking/DCS/DES</a></li>\n<li><a href=\"#example-of-classifier-combination\" rel=\"nofollow\">Example 2: Simple Classifier Combination</a></li>\n<li><a href=\"#example-of-clustering-combination\" rel=\"nofollow\">Example 3: Clustering Combination</a></li>\n<li><a href=\"#example-of-outlier-detector-combination\" rel=\"nofollow\">Example 4: Outlier Detector Combination</a></li>\n<li><a href=\"#development-status\" rel=\"nofollow\">Development Status</a></li>\n<li><a href=\"#inclusion-criteria\" rel=\"nofollow\">Inclusion Criteria</a></li>\n</ul>\n<hr class=\"docutils\">\n<div id=\"id4\">\n<h2>Installation</h2>\n<p>It is recommended to use <strong>pip</strong> for installation. Please make sure\n<strong>the latest version</strong> is installed, as combo is updated frequently:</p>\n<pre>pip install combo            <span class=\"c1\"># normal install\n</span>pip install --upgrade combo  <span class=\"c1\"># or update if needed\n</span>pip install --pre combo      <span class=\"c1\"># or include pre-release version for new features</span>\n</pre>\n<p>Alternatively, you could clone and run setup.py file:</p>\n<pre>git clone https://github.com/yzhao062/combo.git\n<span class=\"nb\">cd</span> combo\npip install .\n</pre>\n<p><strong>Required Dependencies</strong>:</p>\n<ul>\n<li>Python 3.5, 3.6, or 3.7</li>\n<li>joblib</li>\n<li>matplotlib (<strong>optional for running examples</strong>)</li>\n<li>numpy&gt;=1.13</li>\n<li>numba&gt;=0.35</li>\n<li>pyod</li>\n<li>scipy&gt;=0.19.1</li>\n<li>scikit_learn&gt;=0.20</li>\n</ul>\n<p><strong>Note on Python 2</strong>:\nThe maintenance of Python 2.7 will be stopped by January 1, 2020 (see <a href=\"https://github.com/python/devguide/pull/344\" rel=\"nofollow\">official announcement</a>).\nTo be consistent with the Python change and combo\u2019s dependent libraries, e.g., scikit-learn,\n<strong>combo only supports Python 3.5+</strong> and we encourage you to use\nPython 3.5 or newer for the latest functions and bug fixes. More information can\nbe found at <a href=\"https://python3statement.org/\" rel=\"nofollow\">Moving to require Python 3</a>.</p>\n</div>\n<hr class=\"docutils\">\n<div id=\"id5\">\n<h2>API Cheatsheet &amp; Reference</h2>\n<p>Full API Reference: (<a href=\"https://pycombo.readthedocs.io/en/latest/api.html\" rel=\"nofollow\">https://pycombo.readthedocs.io/en/latest/api.html</a>).\nThe following APIs are consistent for most of the models\n(API Cheatsheet: <a href=\"https://pycombo.readthedocs.io/en/latest/api_cc.html\" rel=\"nofollow\">https://pycombo.readthedocs.io/en/latest/api_cc.html</a>).</p>\n<ul>\n<li><strong>fit(X, y)</strong>: Fit estimator. y is optional for unsupervised methods.</li>\n<li><strong>predict(X)</strong>: Predict on a particular sample once the estimator is fitted.</li>\n<li><strong>predict_proba(X)</strong>: Predict the probability of a sample belonging to each class once the estimator is fitted.</li>\n<li><strong>fit_predict(X, y)</strong>: Fit estimator and predict on X. y is optional for unsupervised methods.</li>\n</ul>\n<p>For raw score combination (after the score matrix is generated),\nuse individual methods from\n<a href=\"https://github.com/yzhao062/combo/blob/master/combo/models/score_comb.py\" rel=\"nofollow\">\u201cscore_comb.py\u201d</a> directly.\nRaw score combination API: (<a href=\"https://pycombo.readthedocs.io/en/latest/api.html#score-combination\" rel=\"nofollow\">https://pycombo.readthedocs.io/en/latest/api.html#score-combination</a>).</p>\n</div>\n<hr class=\"docutils\">\n<div id=\"id6\">\n<h2>Implemented Algorithms</h2>\n<p><strong>combo</strong> groups combination frameworks by tasks. General purpose methods are\nfundamental ones which can be applied to various tasks.</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Task</th>\n<th>Algorithm</th>\n<th>Year</th>\n<th>Ref</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>General Purpose</td>\n<td>Average &amp; Weighted Average: average across all scores/prediction results, maybe with weights</td>\n<td>N/A</td>\n<td><a href=\"#zhou2012ensemble\" id=\"id7\" rel=\"nofollow\">[13]</a></td>\n</tr>\n<tr><td>General Purpose</td>\n<td>Maximization: simple combination by taking the maximum scores</td>\n<td>N/A</td>\n<td><a href=\"#zhou2012ensemble\" id=\"id8\" rel=\"nofollow\">[13]</a></td>\n</tr>\n<tr><td>General Purpose</td>\n<td>Median: take the median value across all scores/prediction results</td>\n<td>N/A</td>\n<td><a href=\"#zhou2012ensemble\" id=\"id9\" rel=\"nofollow\">[13]</a></td>\n</tr>\n<tr><td>General Purpose</td>\n<td>Majority Vote &amp; Weighted Majority Vote</td>\n<td>N/A</td>\n<td><a href=\"#zhou2012ensemble\" id=\"id10\" rel=\"nofollow\">[13]</a></td>\n</tr>\n<tr><td>Classification</td>\n<td>SimpleClassifierAggregator: combining classifiers by general purpose methods above</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr><td>Classification</td>\n<td>DCS: Dynamic Classifier Selection (Combination of multiple classifiers using local accuracy estimates)</td>\n<td>1997</td>\n<td><a href=\"#woods1997combination\" id=\"id11\" rel=\"nofollow\">[8]</a></td>\n</tr>\n<tr><td>Classification</td>\n<td>DES: Dynamic Ensemble Selection (From dynamic classifier selection to dynamic ensemble selection)</td>\n<td>2008</td>\n<td><a href=\"#ko2008from\" id=\"id12\" rel=\"nofollow\">[5]</a></td>\n</tr>\n<tr><td>Classification</td>\n<td>Stacking (meta ensembling): use a meta learner to learn the base classifier results</td>\n<td>N/A</td>\n<td><a href=\"#gorman2016kaggle\" id=\"id13\" rel=\"nofollow\">[4]</a></td>\n</tr>\n<tr><td>Clustering</td>\n<td>Clusterer Ensemble: combine the results of multiple clustering results by relabeling</td>\n<td>2006</td>\n<td><a href=\"#zhou2006clusterer\" id=\"id14\" rel=\"nofollow\">[12]</a></td>\n</tr>\n<tr><td>Clustering</td>\n<td>Combining multiple clusterings using evidence accumulation (EAC)</td>\n<td>2002</td>\n<td><a href=\"#fred2005combining\" id=\"id15\" rel=\"nofollow\">[6]</a></td>\n</tr>\n<tr><td>Anomaly Detection</td>\n<td>SimpleDetectorCombination: combining outlier detectors by general purpose methods above</td>\n<td>N/A</td>\n<td><a href=\"#aggarwal2017outlier\" id=\"id16\" rel=\"nofollow\">[2]</a></td>\n</tr>\n<tr><td>Anomaly Detection</td>\n<td>Average of Maximum (AOM): divide base detectors into subgroups to take the maximum, and then average</td>\n<td>2015</td>\n<td><a href=\"#aggarwal2015theoretical\" id=\"id17\" rel=\"nofollow\">[1]</a></td>\n</tr>\n<tr><td>Anomaly Detection</td>\n<td>Maximum of Average (MOA): divide base detectors into subgroups to take the average, and then maximize</td>\n<td>2015</td>\n<td><a href=\"#aggarwal2015theoretical\" id=\"id18\" rel=\"nofollow\">[1]</a></td>\n</tr>\n<tr><td>Anomaly Detection</td>\n<td>XGBOD: a semi-supervised combination framework for outlier detection</td>\n<td>2018</td>\n<td><a href=\"#zhao2018xgbod\" id=\"id19\" rel=\"nofollow\">[9]</a></td>\n</tr>\n<tr><td>Anomaly Detection</td>\n<td>Locally Selective Combination (LSCP)</td>\n<td>2019</td>\n<td><a href=\"#zhao2019lscp\" id=\"id20\" rel=\"nofollow\">[10]</a></td>\n</tr>\n</tbody>\n</table>\n<p><strong>The comparison among selected implemented models</strong> is made available below\n(<a href=\"https://raw.githubusercontent.com/yzhao062/combo/master/examples/compare_selected_classifiers.png\" rel=\"nofollow\">Figure</a>,\n<a href=\"https://github.com/yzhao062/combo/blob/master/examples/compare_selected_classifiers.py\" rel=\"nofollow\">compare_selected_classifiers.py</a>, <a href=\"https://mybinder.org/v2/gh/yzhao062/combo/master\" rel=\"nofollow\">Interactive Jupyter Notebooks</a>).\nFor Jupyter Notebooks, please navigate to <strong>\u201c/notebooks/compare_selected_classifiers.ipynb\u201d</strong>.</p>\n<a href=\"https://raw.githubusercontent.com/yzhao062/combo/master/examples/compare_selected_classifiers.png\" rel=\"nofollow\"><img alt=\"Comparison of Selected Models\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/99fbbc3ef0b3ba6c6dd78596c170664215fa70c0/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f797a68616f3036322f636f6d626f2f6d61737465722f6578616d706c65732f636f6d706172655f73656c65637465645f636c6173736966696572732e706e67\"></a>\n<hr class=\"docutils\">\n<p><strong>All implemented modes</strong> are associated with examples, check\n<a href=\"https://github.com/yzhao062/combo/blob/master/examples\" rel=\"nofollow\">\u201ccombo examples\u201d</a>\nfor more information.</p>\n</div>\n<div id=\"example-of-stacking-dcs-des\">\n<h2>Example of Stacking/DCS/DES</h2>\n<p><a href=\"https://github.com/yzhao062/combo/blob/master/examples/classifier_stacking_example.py\" rel=\"nofollow\">\u201cexamples/classifier_stacking_example.py\u201d</a>\ndemonstrates the basic API of stacking (meta ensembling). <a href=\"https://github.com/yzhao062/combo/blob/master/examples/classifier_dcs_la_example.py\" rel=\"nofollow\">\u201cexamples/classifier_dcs_la_example.py\u201d</a>\ndemonstrates the basic API of Dynamic Classifier Selection by Local Accuracy. <a href=\"https://github.com/yzhao062/combo/blob/master/examples/classifier_des_la_example.py\" rel=\"nofollow\">\u201cexamples/classifier_des_la_example.py\u201d</a>\ndemonstrates the basic API of Dynamic Ensemble Selection by Local Accuracy.</p>\n<p>It is noted <strong>the basic API is consistent across all these models</strong>.</p>\n<ol>\n<li><p>Initialize a group of classifiers as base estimators</p>\n<pre><span class=\"c1\"># initialize a group of classifiers</span>\n<span class=\"n\">classifiers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">DecisionTreeClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">),</span>\n               <span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">),</span>\n               <span class=\"n\">KNeighborsClassifier</span><span class=\"p\">(),</span>\n               <span class=\"n\">RandomForestClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">),</span>\n               <span class=\"n\">GradientBoostingClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">)]</span>\n</pre>\n</li>\n<li><p>Initialize, fit, predict, and evaluate with Stacking</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">combo.models.classifier_stacking</span> <span class=\"kn\">import</span> <span class=\"n\">Stacking</span>\n\n<span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">Stacking</span><span class=\"p\">(</span><span class=\"n\">base_estimators</span><span class=\"o\">=</span><span class=\"n\">classifiers</span><span class=\"p\">,</span> <span class=\"n\">n_folds</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">shuffle_data</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n             <span class=\"n\">keep_original</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">use_proba</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">)</span>\n\n<span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">y_test_predict</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n<span class=\"n\">evaluate_print</span><span class=\"p\">(</span><span class=\"s1\">'Stacking | '</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_test_predict</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li><p>See a sample output of classifier_stacking_example.py</p>\n<pre>Decision Tree        <span class=\"p\">|</span> Accuracy:0.9386, ROC:0.9383, F1:0.9521\nLogistic Regression  <span class=\"p\">|</span> Accuracy:0.9649, ROC:0.9615, F1:0.973\nK Neighbors          <span class=\"p\">|</span> Accuracy:0.9561, ROC:0.9519, F1:0.9662\nGradient Boosting    <span class=\"p\">|</span> Accuracy:0.9605, ROC:0.9524, F1:0.9699\nRandom Forest        <span class=\"p\">|</span> Accuracy:0.9605, ROC:0.961, F1:0.9693\n\nStacking             <span class=\"p\">|</span> Accuracy:0.9868, ROC:0.9841, F1:0.9899\n</pre>\n</li>\n</ol>\n</div>\n<hr class=\"docutils\">\n<div id=\"example-of-classifier-combination\">\n<h2>Example of Classifier Combination</h2>\n<p><a href=\"https://github.com/yzhao062/combo/blob/master/examples/classifier_comb_example.py\" rel=\"nofollow\">\u201cexamples/classifier_comb_example.py\u201d</a>\ndemonstrates the basic API of predicting with multiple classifiers. <strong>It is noted that the API across all other algorithms are consistent/similar</strong>.</p>\n<ol>\n<li><p>Initialize a group of classifiers as base estimators</p>\n<pre><span class=\"c1\"># initialize a group of classifiers</span>\n<span class=\"n\">classifiers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">DecisionTreeClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">),</span>\n               <span class=\"n\">LogisticRegression</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">),</span>\n               <span class=\"n\">KNeighborsClassifier</span><span class=\"p\">(),</span>\n               <span class=\"n\">RandomForestClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">),</span>\n               <span class=\"n\">GradientBoostingClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">)]</span>\n</pre>\n</li>\n<li><p>Initialize, fit, predict, and evaluate with a simple aggregator (average)</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">combo.models.classifier_comb</span> <span class=\"kn\">import</span> <span class=\"n\">SimpleClassifierAggregator</span>\n\n<span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">SimpleClassifierAggregator</span><span class=\"p\">(</span><span class=\"n\">classifiers</span><span class=\"p\">,</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s1\">'average'</span><span class=\"p\">)</span>\n<span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">y_test_predicted</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n<span class=\"n\">evaluate_print</span><span class=\"p\">(</span><span class=\"s1\">'Combination by avg   |'</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_test_predicted</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li><p>See a sample output of classifier_comb_example.py</p>\n<pre>Decision Tree        <span class=\"p\">|</span> Accuracy:0.9386, ROC:0.9383, F1:0.9521\nLogistic Regression  <span class=\"p\">|</span> Accuracy:0.9649, ROC:0.9615, F1:0.973\nK Neighbors          <span class=\"p\">|</span> Accuracy:0.9561, ROC:0.9519, F1:0.9662\nGradient Boosting    <span class=\"p\">|</span> Accuracy:0.9605, ROC:0.9524, F1:0.9699\nRandom Forest        <span class=\"p\">|</span> Accuracy:0.9605, ROC:0.961, F1:0.9693\n\nCombination by avg   <span class=\"p\">|</span> Accuracy:0.9693, ROC:0.9677, F1:0.9763\nCombination by w_avg <span class=\"p\">|</span> Accuracy:0.9781, ROC:0.9716, F1:0.9833\nCombination by max   <span class=\"p\">|</span> Accuracy:0.9518, ROC:0.9312, F1:0.9642\nCombination by w_vote<span class=\"p\">|</span> Accuracy:0.9649, ROC:0.9644, F1:0.9728\nCombination by median<span class=\"p\">|</span> Accuracy:0.9693, ROC:0.9677, F1:0.9763\n</pre>\n</li>\n</ol>\n</div>\n<hr class=\"docutils\">\n<div id=\"example-of-clustering-combination\">\n<h2>Example of Clustering Combination</h2>\n<p><a href=\"https://github.com/yzhao062/combo/blob/master/examples/cluster_comb_example.py\" rel=\"nofollow\">\u201cexamples/cluster_comb_example.py\u201d</a>\ndemonstrates the basic API of combining multiple base clustering estimators. <a href=\"https://github.com/yzhao062/combo/blob/master/examples/cluster_eac_example.py\" rel=\"nofollow\">\u201cexamples/cluster_eac_example.py\u201d</a>\ndemonstrates the basic API of Combining multiple clusterings using evidence accumulation (EAC).</p>\n<ol>\n<li><p>Initialize a group of clustering methods as base estimators</p>\n<pre><span class=\"c1\"># Initialize a set of estimators</span>\n<span class=\"n\">estimators</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">KMeans</span><span class=\"p\">(</span><span class=\"n\">n_clusters</span><span class=\"o\">=</span><span class=\"n\">n_clusters</span><span class=\"p\">),</span>\n              <span class=\"n\">MiniBatchKMeans</span><span class=\"p\">(</span><span class=\"n\">n_clusters</span><span class=\"o\">=</span><span class=\"n\">n_clusters</span><span class=\"p\">),</span>\n              <span class=\"n\">AgglomerativeClustering</span><span class=\"p\">(</span><span class=\"n\">n_clusters</span><span class=\"o\">=</span><span class=\"n\">n_clusters</span><span class=\"p\">)]</span>\n</pre>\n</li>\n<li><p>Initialize a Clusterer Ensemble class and fit the model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">combo.models.cluster_comb</span> <span class=\"kn\">import</span> <span class=\"n\">ClustererEnsemble</span>\n<span class=\"c1\"># combine by Clusterer Ensemble</span>\n<span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">ClustererEnsemble</span><span class=\"p\">(</span><span class=\"n\">estimators</span><span class=\"p\">,</span> <span class=\"n\">n_clusters</span><span class=\"o\">=</span><span class=\"n\">n_clusters</span><span class=\"p\">)</span>\n<span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li><p>Get the aligned results</p>\n<pre><span class=\"c1\"># generate the labels on X</span>\n<span class=\"n\">aligned_labels</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">aligned_labels_</span>\n<span class=\"n\">predicted_labels</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">labels_</span>\n</pre>\n</li>\n</ol>\n</div>\n<div id=\"example-of-outlier-detector-combination\">\n<h2>Example of Outlier Detector Combination</h2>\n<p><a href=\"https://github.com/yzhao062/combo/blob/master/examples/detector_comb_example.py\" rel=\"nofollow\">\u201cexamples/detector_comb_example.py\u201d</a>\ndemonstrates the basic API of combining multiple base outlier detectors.</p>\n<ol>\n<li><p>Initialize a group of outlier detection methods as base estimators</p>\n<pre><span class=\"c1\"># Initialize a set of estimators</span>\n<span class=\"n\">detectors</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">KNN</span><span class=\"p\">(),</span> <span class=\"n\">LOF</span><span class=\"p\">(),</span> <span class=\"n\">OCSVM</span><span class=\"p\">()]</span>\n</pre>\n</li>\n<li><p>Initialize a simple averaging aggregator, fit the model, and make\nthe prediction.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">combo.models.detector</span> <span class=\"n\">combination</span> <span class=\"kn\">import</span> <span class=\"nn\">SimpleDetectorAggregator</span>\n<span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">SimpleDetectorAggregator</span><span class=\"p\">(</span><span class=\"n\">base_estimators</span><span class=\"o\">=</span><span class=\"n\">detectors</span><span class=\"p\">)</span>\n<span class=\"n\">clf_name</span> <span class=\"o\">=</span> <span class=\"s1\">'Aggregation by Averaging'</span>\n<span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">)</span>\n\n<span class=\"n\">y_train_pred</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">labels_</span>  <span class=\"c1\"># binary labels (0: inliers, 1: outliers)</span>\n<span class=\"n\">y_train_scores</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">decision_scores_</span>  <span class=\"c1\"># raw outlier scores</span>\n\n<span class=\"c1\"># get the prediction on the test data</span>\n<span class=\"n\">y_test_pred</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>  <span class=\"c1\"># outlier labels (0 or 1)</span>\n<span class=\"n\">y_test_scores</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">decision_function</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>  <span class=\"c1\"># outlier scores</span>\n</pre>\n</li>\n<li><p>Evaluate the prediction using ROC and Precision @ Rank n.</p>\n<pre><span class=\"c1\"># evaluate and print the results</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"</span><span class=\"se\">\\n</span><span class=\"s2\">On Training Data:\"</span><span class=\"p\">)</span>\n<span class=\"n\">evaluate_print</span><span class=\"p\">(</span><span class=\"n\">clf_name</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_train_scores</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"</span><span class=\"se\">\\n</span><span class=\"s2\">On Test Data:\"</span><span class=\"p\">)</span>\n<span class=\"n\">evaluate_print</span><span class=\"p\">(</span><span class=\"n\">clf_name</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_test_scores</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li><p>See sample outputs on both training and test data.</p>\n<pre>On Training Data:\nAggregation by Averaging ROC:0.9994, precision @ rank n:0.95\n\nOn Test Data:\nAggregation by Averaging ROC:1.0, precision @ rank n:1.0\n</pre>\n</li>\n</ol>\n</div>\n<hr class=\"docutils\">\n<div id=\"id21\">\n<h2>Development Status</h2>\n<p><strong>combo</strong> is currently <strong>under development</strong> as of July 30, 2019. A concrete plan has\nbeen laid out and will be implemented in the next few months.</p>\n<p>Similar to other libraries built by us, e.g., Python Outlier Detection Toolbox\n(<a href=\"https://github.com/yzhao062/pyod\" rel=\"nofollow\">pyod</a>),\n<strong>combo</strong> is also targeted to be published in <em>Journal of Machine Learning Research (JMLR)</em>,\n<a href=\"http://www.jmlr.org/mloss/\" rel=\"nofollow\">open-source software track</a>. A demo paper to\n<em>AAAI</em> or <em>IJCAI</em> may be submitted soon for progress update.</p>\n<p><strong>Watch &amp; Star</strong> to get the latest update! Also feel free to send me an email (<a href=\"mailto:zhaoy%40cmu.edu\">zhaoy<span>@</span>cmu<span>.</span>edu</a>)\nfor suggestions and ideas.</p>\n</div>\n<hr class=\"docutils\">\n<div id=\"id22\">\n<h2>Inclusion Criteria</h2>\n<p>Similarly to scikit-learn, We mainly consider well-established algorithms for inclusion.\nA rule of thumb is at least two years since publication, 50+ citations, and usefulness.</p>\n<p>However, we encourage the author(s) of newly proposed models to share and add your implementation into combo\nfor boosting ML accessibility and reproducibility.\nThis exception only applies if you could commit to the maintenance of your model for at least two year period.</p>\n</div>\n<hr class=\"docutils\">\n<div id=\"reference\">\n<h2>Reference</h2>\n<table id=\"aggarwal2015theoretical\">\n<col><col>\n<tbody>\n<tr><td>[1]</td><td><em>(<a href=\"#id17\" rel=\"nofollow\">1</a>, <a href=\"#id18\" rel=\"nofollow\">2</a>)</em> Aggarwal, C.C. and Sathe, S., 2015. Theoretical foundations and algorithms for outlier ensembles. <em>ACM SIGKDD Explorations Newsletter</em>, 17(1), pp.24-47.</td></tr>\n</tbody>\n</table>\n<table id=\"aggarwal2017outlier\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id16\" rel=\"nofollow\">[2]</a></td><td>Aggarwal, C.C. and Sathe, S., 2017. Outlier ensembles: An introduction. Springer.</td></tr>\n</tbody>\n</table>\n<table id=\"bell2007lessons\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id1\" rel=\"nofollow\">[3]</a></td><td>Bell, R.M. and Koren, Y., 2007. Lessons from the Netflix prize challenge. <em>SIGKDD Explorations</em>, 9(2), pp.75-79.</td></tr>\n</tbody>\n</table>\n<table id=\"gorman2016kaggle\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id13\" rel=\"nofollow\">[4]</a></td><td>Gorman, B. (2016). A Kaggler\u2019s Guide to Model Stacking in Practice. [online] The Official Blog of Kaggle.com. Available at: <a href=\"http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice\" rel=\"nofollow\">http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice</a> [Accessed 26 Jul. 2019].</td></tr>\n</tbody>\n</table>\n<table id=\"ko2008from\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id12\" rel=\"nofollow\">[5]</a></td><td>Ko, A.H., Sabourin, R. and Britto Jr, A.S., 2008. From dynamic classifier selection to dynamic ensemble selection. <em>Pattern recognition</em>, 41(5), pp.1718-1731.</td></tr>\n</tbody>\n</table>\n<table id=\"fred2005combining\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id15\" rel=\"nofollow\">[6]</a></td><td>Fred, A. L. N., &amp; Jain, A. K. (2005). Combining multiple clusterings using evidence accumulation. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 27(6), 835\u2013850. <a href=\"https://doi.org/10.1109/TPAMI.2005.113\" rel=\"nofollow\">https://doi.org/10.1109/TPAMI.2005.113</a></td></tr>\n</tbody>\n</table>\n<table id=\"raschka2020machine\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id2\" rel=\"nofollow\">[7]</a></td><td>Raschka, S., Patterson, J. and Nolet, C., 2020. Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence. arXiv preprint arXiv:2002.04803.</td></tr>\n</tbody>\n</table>\n<table id=\"woods1997combination\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id11\" rel=\"nofollow\">[8]</a></td><td>Woods, K., Kegelmeyer, W.P. and Bowyer, K., 1997. Combination of multiple classifiers using local accuracy estimates. <em>IEEE transactions on pattern analysis and machine intelligence</em>, 19(4), pp.405-410.</td></tr>\n</tbody>\n</table>\n<table id=\"zhao2018xgbod\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id19\" rel=\"nofollow\">[9]</a></td><td>Zhao, Y. and Hryniewicki, M.K. XGBOD: Improving Supervised Outlier Detection with Unsupervised Representation Learning. <em>IEEE International Joint Conference on Neural Networks</em>, 2018.</td></tr>\n</tbody>\n</table>\n<table id=\"zhao2019lscp\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id20\" rel=\"nofollow\">[10]</a></td><td>Zhao, Y., Nasrullah, Z., Hryniewicki, M.K. and Li, Z., 2019, May. LSCP: Locally selective combination in parallel outlier ensembles. In <em>Proceedings of the 2019 SIAM International Conference on Data Mining (SDM)</em>, pp. 585-593. Society for Industrial and Applied Mathematics.</td></tr>\n</tbody>\n</table>\n<table id=\"zhao2019pyod\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id3\" rel=\"nofollow\">[11]</a></td><td>Zhao, Y., Nasrullah, Z. and Li, Z., 2019. PyOD: A Python Toolbox for Scalable Outlier Detection. <em>Journal of Machine Learning Research</em>, 20, pp.1-7.</td></tr>\n</tbody>\n</table>\n<table id=\"zhou2006clusterer\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id14\" rel=\"nofollow\">[12]</a></td><td>Zhou, Z.H. and Tang, W., 2006. Clusterer ensemble. <em>Knowledge-Based Systems</em>, 19(1), pp.77-83.</td></tr>\n</tbody>\n</table>\n<table id=\"zhou2012ensemble\">\n<col><col>\n<tbody>\n<tr><td>[13]</td><td><em>(<a href=\"#id7\" rel=\"nofollow\">1</a>, <a href=\"#id8\" rel=\"nofollow\">2</a>, <a href=\"#id9\" rel=\"nofollow\">3</a>, <a href=\"#id10\" rel=\"nofollow\">4</a>)</em> Zhou, Z.H., 2012. Ensemble methods: foundations and algorithms. Chapman and Hall/CRC.</td></tr>\n</tbody>\n</table>\n</div>\n\n          </div>"}, "last_serial": 6657746, "releases": {"0.0.0": [{"comment_text": "", "digests": {"md5": "e0b56c23313d704caf3d34ec6fe39307", "sha256": "e6b6757dbd119fb818b699450492a6f3efbc8437234d50a4ef4df38aa3c2bd7c"}, "downloads": -1, "filename": "combo-0.0.0.tar.gz", "has_sig": false, "md5_digest": "e0b56c23313d704caf3d34ec6fe39307", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2459, "upload_time": "2019-07-14T09:24:03", "upload_time_iso_8601": "2019-07-14T09:24:03.807903Z", "url": "https://files.pythonhosted.org/packages/d7/ec/bc1857121703dec2614620f299dcaa67196555c78ca37756bbefc5dbb9ff/combo-0.0.0.tar.gz", "yanked": false}], "0.0.1": [{"comment_text": "", "digests": {"md5": "e4b5335be7359c3e74b391a3cb04b0cf", "sha256": "26999596c621ceb4b41adadde4eb60e9725d2756f7d245cd20fa229bcd8e14fb"}, "downloads": -1, "filename": "combo-0.0.1.tar.gz", "has_sig": false, "md5_digest": "e4b5335be7359c3e74b391a3cb04b0cf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4674, "upload_time": "2019-07-15T15:22:57", "upload_time_iso_8601": "2019-07-15T15:22:57.353316Z", "url": "https://files.pythonhosted.org/packages/dc/c5/90bc5e1c1ae5183722236b7a108bd9db35d8ff6ebbe3f17c5ff7234b0e48/combo-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "f27daef3308c7eda48963bd1dea70fcc", "sha256": "71104f113ef88661f63c1d790973eb5ac6d73a182849233229a7da26484cc2f6"}, "downloads": -1, "filename": "combo-0.0.2.tar.gz", "has_sig": false, "md5_digest": "f27daef3308c7eda48963bd1dea70fcc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18398, "upload_time": "2019-07-15T16:03:59", "upload_time_iso_8601": "2019-07-15T16:03:59.519077Z", "url": "https://files.pythonhosted.org/packages/fb/f0/7b094afd01dadf19b0b32a4834c10ce4a57cec802ef953736131f8d161e9/combo-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "9d8bb3fd1101a2fdad2bd0a33d1402e1", "sha256": "7385b286d8aec0bca78997527eb6ffd3baa515475d20b5e8bb5321479621d420"}, "downloads": -1, "filename": "combo-0.0.3.tar.gz", "has_sig": false, "md5_digest": "9d8bb3fd1101a2fdad2bd0a33d1402e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20034, "upload_time": "2019-07-17T16:28:25", "upload_time_iso_8601": "2019-07-17T16:28:25.180653Z", "url": "https://files.pythonhosted.org/packages/64/7c/f5502043dc482948ba7f1295b2dbefc6ebe74c1031d462da384df7945cb1/combo-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "07061e93760b7d6d9dc3af34c7abd31d", "sha256": "e93aec2059af29121b98e7cc57913432d21b69d033750b4b6c23c98da2780efa"}, "downloads": -1, "filename": "combo-0.0.4.tar.gz", "has_sig": false, "md5_digest": "07061e93760b7d6d9dc3af34c7abd31d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21568, "upload_time": "2019-07-21T03:04:19", "upload_time_iso_8601": "2019-07-21T03:04:19.434795Z", "url": "https://files.pythonhosted.org/packages/ab/a1/da97b4fdf6f1e18c1b9d7fb1f30486fae06f24049bc1d5505e84e7e28fa5/combo-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "6fe1e83a6bb8cba0ecb010e1d19486e7", "sha256": "1299dc3f9a9068ebdb8a2aeaa4aadb5a088643ae275e8e4458bf24f3187fd14c"}, "downloads": -1, "filename": "combo-0.0.5.tar.gz", "has_sig": false, "md5_digest": "6fe1e83a6bb8cba0ecb010e1d19486e7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25715, "upload_time": "2019-07-28T16:12:09", "upload_time_iso_8601": "2019-07-28T16:12:09.845122Z", "url": "https://files.pythonhosted.org/packages/af/ba/c7065e7f0d295b2e59e3625611c55e809e975ee5da36f3ff37ea32777bb4/combo-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "de1db05b3738910bd753247c9c4e89ac", "sha256": "8df840734e1e5a96bf3780e967ca13ba4b0072b8185ef8d0eb03ce2cb261d457"}, "downloads": -1, "filename": "combo-0.0.6.tar.gz", "has_sig": false, "md5_digest": "de1db05b3738910bd753247c9c4e89ac", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31374, "upload_time": "2019-07-30T05:04:53", "upload_time_iso_8601": "2019-07-30T05:04:53.306998Z", "url": "https://files.pythonhosted.org/packages/33/f6/d2ac7be51b4cfb94ab1bbc845a4a40a541eabbc1a01c4df08b8705754a65/combo-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "57e10d506aacb46149c89fcb502cf936", "sha256": "58b027544a4749ac837427a680298ed788417882a7245e20c762dca8cbaa0cd6"}, "downloads": -1, "filename": "combo-0.0.7.tar.gz", "has_sig": false, "md5_digest": "57e10d506aacb46149c89fcb502cf936", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34037, "upload_time": "2019-08-04T15:25:02", "upload_time_iso_8601": "2019-08-04T15:25:02.067104Z", "url": "https://files.pythonhosted.org/packages/ac/b9/4c9995e7f4e2d0c376e10803940d981e32ec6b2b29097bc46c1e638be93e/combo-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "def7c9d222e0703c9014e2f68bb46fb7", "sha256": "321dcfd8fe37c15b515c8aaca8abfcbc38e28d718c89dfa5c7db963bcbe7da69"}, "downloads": -1, "filename": "combo-0.0.8.tar.gz", "has_sig": false, "md5_digest": "def7c9d222e0703c9014e2f68bb46fb7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35889, "upload_time": "2019-08-08T00:43:31", "upload_time_iso_8601": "2019-08-08T00:43:31.480179Z", "url": "https://files.pythonhosted.org/packages/8e/4e/9ab16d4aa21da464903bd5630b28b36c65298fd74639308089b2d173d5a7/combo-0.0.8.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "9d8639851c7951b961da4d25a745341f", "sha256": "3c5da2b8af17e03146ce382d10150373a260ce64565963f7c0b0cecfc7d093be"}, "downloads": -1, "filename": "combo-0.1.0.tar.gz", "has_sig": false, "md5_digest": "9d8639851c7951b961da4d25a745341f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37173, "upload_time": "2020-02-19T02:10:17", "upload_time_iso_8601": "2020-02-19T02:10:17.599313Z", "url": "https://files.pythonhosted.org/packages/78/52/e880bd923eba122515307d29ab43c1c356bad60610c27bed2cdec25d0240/combo-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9d8639851c7951b961da4d25a745341f", "sha256": "3c5da2b8af17e03146ce382d10150373a260ce64565963f7c0b0cecfc7d093be"}, "downloads": -1, "filename": "combo-0.1.0.tar.gz", "has_sig": false, "md5_digest": "9d8639851c7951b961da4d25a745341f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37173, "upload_time": "2020-02-19T02:10:17", "upload_time_iso_8601": "2020-02-19T02:10:17.599313Z", "url": "https://files.pythonhosted.org/packages/78/52/e880bd923eba122515307d29ab43c1c356bad60610c27bed2cdec25d0240/combo-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:29 2020"}