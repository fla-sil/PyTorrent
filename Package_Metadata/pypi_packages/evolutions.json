{"info": {"author": "Adrian Robert", "author_email": "arobert@interstitiality.net", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: System Administrators", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3", "Topic :: Database"], "description": "\n# Evolutions\n\nThe evolutions package provides a facility similar to\n[play-evolutions](https://www.playframework.com/documentation/2.7.x/Evolutions)\n([source](https://github.com/playframework/playframework/tree/master/persistence/play-jdbc-evolutions/src/main/scala/play/api/db/evolutions))\nfor use with Python.  It differs from other similar tools in its simple,\nlightweight philosophy and its pure SQL orientation.  It enforces a linear\nhistory in schema development with no branching or dependencies.  Migrations\nare contained in SQL files and run automatically as needed, with no code\nembedding or hand-tuned invocations needed.  Evolutions plays well with source\ncontrol as well as differences between development and production\nenvironments.  Finally, it's not tied to any application framework so can be\nused anywhere that Python 3 and the target database are available, regardless\nof whether the using application is itself implemented in Python.\n\n## Ups\n\nThe basic idea is that, as the database schema is developed incrementally, the\nchanges are placed in *ups* files named `1.sql` (the original schema),\n`2.sql`, `3.sql`, etc..  When the tool is invoked (usually just before the app\nstarts up, see Usage), a table is checked in the database to see which\nof these scripts have been run, and any missing are run in sequence.  The\nscripts should contain both schema changes and data migration.  This way, the\napp and the schema can be developed together, without worrying about manual\ndatabase updates, legacy data support, or schema-code synchronization.\n\n### Example\n\nAn application is deployed with its schema in a file `1.sql`,\ncontaining a lot of `CREATE TABLE` statements.  Some development is done and\n`2.sql` with some `ALTER TABLE` statements is written.  When this is deployed\nand the evolutions tool run before application startup, it detects that\n`1.sql` has already been run, but `2.sql` has not, so it runs that.  Later on,\n`3.sql` and `4.sql` are developed but reach deployment together.  When the\nevolutions tool is run, it runs first `3.sql` then `4.sql` in sequence.\n\n## Downs\n\nIn addition to the *ups*, a set of corresponding *downs* files `1-downs.sql`,\n`2-downs.sql`, `3-downs.sql` are created during development, which undo the\neffects of the corresponding ups files.  If the tool detects that a change has\nbeen made to an ups file, then it will rerun it.  However, its former version,\nas well as any later ups that have been run \"on top\" of it, must be undone\nfirst.  So the tool first runs these in reverse, using versions cached in the\ndatabase itself in case *those* have changed as well, then runs back up the\nsequence starting from the first modified file.  This process allows tweaking\nchanges during development, without needing to manually adjust the database\neach time.  It also enables collaboration, so that, for example, a single\n`#.sql` file can be used by everyone for an entire sprint (merging in changes\nto a shared git branch).\n\n### Example\n\nThe application in the first example continues being developed. In addition to\nthe ups files mentioned earlier, `1-downs.sql` (a bunch of `DROP TABLE`\nstatements), `2-downs.sql` (`ALTER TABLE` statements undoing the alterations\nin `2.sql`), `3-downs.sql`, and `4-downs.sql` were all written.  At one point,\nsomeone realizes there was a mistake in `3.sql` and it should be fixed.  They\nmodify this file, as well as `3-downs.sql`, then deploy the application.\n\nWhen the evolutions tool runs, it detects that `3.sql` has changed.  It then\nruns `4-downs.sql` and `3-downs.sql` (in that order) to get to a point where\nit can correctly apply the new version of `3.sql`.  Then it runs that script,\nand finally `4.sql` to bring the database fully up to date.\n\n## Production\n\nIn general, although running downs will ensure a consistent database schema,\nsome data loss is often unavoidable, simply because elements of the schema are\nlost through downgrade, meaning the data cannot be preserved.  **For this\nreason, you should not run downs in production. Ever.** Once you deploy an\nevolution stage to production, you should freeze it, so evolutions will not\nrun it again.  In addition, you can and should enable a safety check by adding\nthe `--prod` switch when invoking (see Usage).  If the tool encounters an ups\nscript change when this switch is active, it will abort rather than run any\ndowns, so you can address the situation manually.\n\nIn this case, you will end up in a situation where the database is out of sync\nwith the evolutions scripts.  This can also occur if evolutions is only taken\ninto use.  This can be remedied by using the `--skip=<indices>` switch to the\ntool, which will cause the tool to assume the scripts with the given\ncomma-separated indices have already been run, and mark them so in the\ndatabase, without actually running them.\n\n### Example\n\nThe deployment mentioned in the preceding examples as assumed to be on a\ndevelopment environment, where it's OK to lose data in the case *downs*\nscripts need to be run.  However, in the production deployment, the evolutions\ntool is invoked with the `--prod` argument.  Hence, in the situation described\nin the previous example where `3.sql` has changed, it will abort and return an\nerror code.  The user will then need to address the situation manually.\nPossibly they will apply the new change needed from `3.sql` manually, taking\ncare to preserve data.\n\nThen they can invoke the tool using `--skip=3`.  This will cause it to mark\n`3.sql` has having been \"run\" in its new modified version, *without actually\nrunning it*.  Then, after noting that `4.sql` has not changed, the database is\nnow considered to be up to date.  (Subsequent invocations do not need the\n`--skip` argument and will not trigger an abort, unless there has been a new,\ndifferent change of an already-run script.)\n\n\n# Database Support\n\nMySQL, PostgreSQL, and Sqlite are supported.  The database is accessed through\na combination of the command line clients and\n[DB-API2](https://www.python.org/dev/peps/pep-0249/), using\n[mysql-connector-python](https://dev.mysql.com/doc/connector-python/en/),\n[PsycoPg2](http://initd.org/psycopg/docs/), and\n[sqlite3](https://docs.python.org/3.8/library/sqlite3.html).  (These are not\nlisted as dependencies of this package, so you should install the one needed\nfor your own case yourself.)\n\n\n## Transactions\n\nThe evolutions scripts themselves are run by invoking the command line client\nfor the database being used (e.g., `psql` for Postgres).  Transactionality is\ntherefore under control of the script itself.\n\nWhen using MySQL or PostgreSQL (but not Sqlite), the evolutions table is\nlocked when the script starts, so any parallel instances of the script started\nup will wait until the first one completes, and then will find the evolutions\nalready run and do nothing.\n\n\n# Install\n\n    pip3 install evolutions\n\n-or- to get development version:\n\n    pip3 install https://github.com/arobertn/evolutions/archive/master.tar.gz\n\n\n# Usage\n\nThe tool is invoked via a Python 3 command line script, and should be called\njust before or as part of starting the application, or, in an auto-deploy\nenvironment, whenever the schema files have been changed.\n\n    ./evolutions.py <db_url> <db_user> <db_pass> <evolutions_dir> [--skip=<stages>] [--prod]\n        --skip=<stages> = comma-separated indices to assume already run\n        --prod          = abort if downs need to be run (for production)\n\n- *db\\_url:* e.g.: `mysql://localhost:3306/dbname`,\n                 `postgresql://localhost:5432/dbname`,\n                 `sqlite:/absolute/path/to/database.db`\n- *db\\_user, db\\_pass:* db\\_pass is ignored for Postgres (must use .pgpass\n  file), and both db\\_user and db\\_pass are ignored for Sqlite; pass empty\n  strings (\"\")\n- *evolutions_dir:* directory containing the #.sql/#-downs.sql files; can be\n  relative or absolute path\n- *--skip:* comma-separated list of stage indices to skip running if you have\n  a database which has already had one or more of the #.sql files run on it;\n  will insert rows to the `evolutions` table to make it up to date, but will\n  not actually run the scripts\n- *--prod:* if given, tool will abort immediately if it determines any downs would\n  need to be run; database is not touched\n\n\n# Implementation\n\nThe evolutions tool operates by collecting the SHA1 hash of each ups and downs\nscript in the evolutions directory, and storing these values, together with\nthe script contents themselves, in a dedicated table (named `evolutions`) in\nthe database.  Decisions on which ups and downs scripts to run are made by\ncomparing the database record and the scripts found in the directory, and\nupdates are made according to the runs.\n\n\n# Development\n\nOn [GitHub](https://github.com/arobertn/evolutions).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/arobertn/evolutions", "keywords": "database migration sql python python3 evolutions", "license": "BSD-3-Clause", "maintainer": "", "maintainer_email": "", "name": "evolutions", "package_url": "https://pypi.org/project/evolutions/", "platform": "any", "project_url": "https://pypi.org/project/evolutions/", "project_urls": {"Homepage": "https://github.com/arobertn/evolutions"}, "release_url": "https://pypi.org/project/evolutions/0.8.2/", "requires_dist": null, "requires_python": ">=3", "summary": "App framework agnostic pure SQL incremental database migrations tool modeled after play-evolutions", "version": "0.8.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Evolutions</h1>\n<p>The evolutions package provides a facility similar to\n<a href=\"https://www.playframework.com/documentation/2.7.x/Evolutions\" rel=\"nofollow\">play-evolutions</a>\n(<a href=\"https://github.com/playframework/playframework/tree/master/persistence/play-jdbc-evolutions/src/main/scala/play/api/db/evolutions\" rel=\"nofollow\">source</a>)\nfor use with Python.  It differs from other similar tools in its simple,\nlightweight philosophy and its pure SQL orientation.  It enforces a linear\nhistory in schema development with no branching or dependencies.  Migrations\nare contained in SQL files and run automatically as needed, with no code\nembedding or hand-tuned invocations needed.  Evolutions plays well with source\ncontrol as well as differences between development and production\nenvironments.  Finally, it's not tied to any application framework so can be\nused anywhere that Python 3 and the target database are available, regardless\nof whether the using application is itself implemented in Python.</p>\n<h2>Ups</h2>\n<p>The basic idea is that, as the database schema is developed incrementally, the\nchanges are placed in <em>ups</em> files named <code>1.sql</code> (the original schema),\n<code>2.sql</code>, <code>3.sql</code>, etc..  When the tool is invoked (usually just before the app\nstarts up, see Usage), a table is checked in the database to see which\nof these scripts have been run, and any missing are run in sequence.  The\nscripts should contain both schema changes and data migration.  This way, the\napp and the schema can be developed together, without worrying about manual\ndatabase updates, legacy data support, or schema-code synchronization.</p>\n<h3>Example</h3>\n<p>An application is deployed with its schema in a file <code>1.sql</code>,\ncontaining a lot of <code>CREATE TABLE</code> statements.  Some development is done and\n<code>2.sql</code> with some <code>ALTER TABLE</code> statements is written.  When this is deployed\nand the evolutions tool run before application startup, it detects that\n<code>1.sql</code> has already been run, but <code>2.sql</code> has not, so it runs that.  Later on,\n<code>3.sql</code> and <code>4.sql</code> are developed but reach deployment together.  When the\nevolutions tool is run, it runs first <code>3.sql</code> then <code>4.sql</code> in sequence.</p>\n<h2>Downs</h2>\n<p>In addition to the <em>ups</em>, a set of corresponding <em>downs</em> files <code>1-downs.sql</code>,\n<code>2-downs.sql</code>, <code>3-downs.sql</code> are created during development, which undo the\neffects of the corresponding ups files.  If the tool detects that a change has\nbeen made to an ups file, then it will rerun it.  However, its former version,\nas well as any later ups that have been run \"on top\" of it, must be undone\nfirst.  So the tool first runs these in reverse, using versions cached in the\ndatabase itself in case <em>those</em> have changed as well, then runs back up the\nsequence starting from the first modified file.  This process allows tweaking\nchanges during development, without needing to manually adjust the database\neach time.  It also enables collaboration, so that, for example, a single\n<code>#.sql</code> file can be used by everyone for an entire sprint (merging in changes\nto a shared git branch).</p>\n<h3>Example</h3>\n<p>The application in the first example continues being developed. In addition to\nthe ups files mentioned earlier, <code>1-downs.sql</code> (a bunch of <code>DROP TABLE</code>\nstatements), <code>2-downs.sql</code> (<code>ALTER TABLE</code> statements undoing the alterations\nin <code>2.sql</code>), <code>3-downs.sql</code>, and <code>4-downs.sql</code> were all written.  At one point,\nsomeone realizes there was a mistake in <code>3.sql</code> and it should be fixed.  They\nmodify this file, as well as <code>3-downs.sql</code>, then deploy the application.</p>\n<p>When the evolutions tool runs, it detects that <code>3.sql</code> has changed.  It then\nruns <code>4-downs.sql</code> and <code>3-downs.sql</code> (in that order) to get to a point where\nit can correctly apply the new version of <code>3.sql</code>.  Then it runs that script,\nand finally <code>4.sql</code> to bring the database fully up to date.</p>\n<h2>Production</h2>\n<p>In general, although running downs will ensure a consistent database schema,\nsome data loss is often unavoidable, simply because elements of the schema are\nlost through downgrade, meaning the data cannot be preserved.  <strong>For this\nreason, you should not run downs in production. Ever.</strong> Once you deploy an\nevolution stage to production, you should freeze it, so evolutions will not\nrun it again.  In addition, you can and should enable a safety check by adding\nthe <code>--prod</code> switch when invoking (see Usage).  If the tool encounters an ups\nscript change when this switch is active, it will abort rather than run any\ndowns, so you can address the situation manually.</p>\n<p>In this case, you will end up in a situation where the database is out of sync\nwith the evolutions scripts.  This can also occur if evolutions is only taken\ninto use.  This can be remedied by using the <code>--skip=&lt;indices&gt;</code> switch to the\ntool, which will cause the tool to assume the scripts with the given\ncomma-separated indices have already been run, and mark them so in the\ndatabase, without actually running them.</p>\n<h3>Example</h3>\n<p>The deployment mentioned in the preceding examples as assumed to be on a\ndevelopment environment, where it's OK to lose data in the case <em>downs</em>\nscripts need to be run.  However, in the production deployment, the evolutions\ntool is invoked with the <code>--prod</code> argument.  Hence, in the situation described\nin the previous example where <code>3.sql</code> has changed, it will abort and return an\nerror code.  The user will then need to address the situation manually.\nPossibly they will apply the new change needed from <code>3.sql</code> manually, taking\ncare to preserve data.</p>\n<p>Then they can invoke the tool using <code>--skip=3</code>.  This will cause it to mark\n<code>3.sql</code> has having been \"run\" in its new modified version, <em>without actually\nrunning it</em>.  Then, after noting that <code>4.sql</code> has not changed, the database is\nnow considered to be up to date.  (Subsequent invocations do not need the\n<code>--skip</code> argument and will not trigger an abort, unless there has been a new,\ndifferent change of an already-run script.)</p>\n<h1>Database Support</h1>\n<p>MySQL, PostgreSQL, and Sqlite are supported.  The database is accessed through\na combination of the command line clients and\n<a href=\"https://www.python.org/dev/peps/pep-0249/\" rel=\"nofollow\">DB-API2</a>, using\n<a href=\"https://dev.mysql.com/doc/connector-python/en/\" rel=\"nofollow\">mysql-connector-python</a>,\n<a href=\"http://initd.org/psycopg/docs/\" rel=\"nofollow\">PsycoPg2</a>, and\n<a href=\"https://docs.python.org/3.8/library/sqlite3.html\" rel=\"nofollow\">sqlite3</a>.  (These are not\nlisted as dependencies of this package, so you should install the one needed\nfor your own case yourself.)</p>\n<h2>Transactions</h2>\n<p>The evolutions scripts themselves are run by invoking the command line client\nfor the database being used (e.g., <code>psql</code> for Postgres).  Transactionality is\ntherefore under control of the script itself.</p>\n<p>When using MySQL or PostgreSQL (but not Sqlite), the evolutions table is\nlocked when the script starts, so any parallel instances of the script started\nup will wait until the first one completes, and then will find the evolutions\nalready run and do nothing.</p>\n<h1>Install</h1>\n<pre><code>pip3 install evolutions\n</code></pre>\n<p>-or- to get development version:</p>\n<pre><code>pip3 install https://github.com/arobertn/evolutions/archive/master.tar.gz\n</code></pre>\n<h1>Usage</h1>\n<p>The tool is invoked via a Python 3 command line script, and should be called\njust before or as part of starting the application, or, in an auto-deploy\nenvironment, whenever the schema files have been changed.</p>\n<pre><code>./evolutions.py &lt;db_url&gt; &lt;db_user&gt; &lt;db_pass&gt; &lt;evolutions_dir&gt; [--skip=&lt;stages&gt;] [--prod]\n    --skip=&lt;stages&gt; = comma-separated indices to assume already run\n    --prod          = abort if downs need to be run (for production)\n</code></pre>\n<ul>\n<li><em>db_url:</em> e.g.: <code>mysql://localhost:3306/dbname</code>,\n<code>postgresql://localhost:5432/dbname</code>,\n<code>sqlite:/absolute/path/to/database.db</code></li>\n<li><em>db_user, db_pass:</em> db_pass is ignored for Postgres (must use .pgpass\nfile), and both db_user and db_pass are ignored for Sqlite; pass empty\nstrings (\"\")</li>\n<li><em>evolutions_dir:</em> directory containing the #.sql/#-downs.sql files; can be\nrelative or absolute path</li>\n<li><em>--skip:</em> comma-separated list of stage indices to skip running if you have\na database which has already had one or more of the #.sql files run on it;\nwill insert rows to the <code>evolutions</code> table to make it up to date, but will\nnot actually run the scripts</li>\n<li><em>--prod:</em> if given, tool will abort immediately if it determines any downs would\nneed to be run; database is not touched</li>\n</ul>\n<h1>Implementation</h1>\n<p>The evolutions tool operates by collecting the SHA1 hash of each ups and downs\nscript in the evolutions directory, and storing these values, together with\nthe script contents themselves, in a dedicated table (named <code>evolutions</code>) in\nthe database.  Decisions on which ups and downs scripts to run are made by\ncomparing the database record and the scripts found in the directory, and\nupdates are made according to the runs.</p>\n<h1>Development</h1>\n<p>On <a href=\"https://github.com/arobertn/evolutions\" rel=\"nofollow\">GitHub</a>.</p>\n\n          </div>"}, "last_serial": 6203171, "releases": {"0.8": [{"comment_text": "", "digests": {"md5": "0b30b43538a181eb41efd8e0a4b6d512", "sha256": "623862b9ac8dbe05b125d1c698dd25b57af18160eb4504d6beeeb390af46671c"}, "downloads": -1, "filename": "evolutions-0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "0b30b43538a181eb41efd8e0a4b6d512", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10851, "upload_time": "2019-11-22T18:36:03", "upload_time_iso_8601": "2019-11-22T18:36:03.100501Z", "url": "https://files.pythonhosted.org/packages/f9/25/b4801c6dce6532b5d8281fc810b2e75d1b4218e4ee0ba44a21441e404f21/evolutions-0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1a2ca9f087c667f984f5c0a3edb03f9e", "sha256": "fcd0c19a7093f2e31053be67804bafd0e445b229028d40826657b38de586c9d3"}, "downloads": -1, "filename": "evolutions-0.8.tar.gz", "has_sig": false, "md5_digest": "1a2ca9f087c667f984f5c0a3edb03f9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8631, "upload_time": "2019-11-22T18:36:05", "upload_time_iso_8601": "2019-11-22T18:36:05.685403Z", "url": "https://files.pythonhosted.org/packages/96/4e/ae3505532c55d960e949240f292afd7da94633e8b1b43ecd685dcd83eb90/evolutions-0.8.tar.gz", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "b755ffa730191ad42fd0fb65fa88a143", "sha256": "f10dcd821da82a17ad3ff474b00ee9431479da9c606d3b5310d95d2d4407e98a"}, "downloads": -1, "filename": "evolutions-0.8.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b755ffa730191ad42fd0fb65fa88a143", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 14269, "upload_time": "2019-11-23T10:52:22", "upload_time_iso_8601": "2019-11-23T10:52:22.446342Z", "url": "https://files.pythonhosted.org/packages/57/52/27752685212577ade1511cd1488dcf87dfa5e4d98686ab4345b54105f2c0/evolutions-0.8.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "75d7ed6c6b402c87b4dbc5b130516c71", "sha256": "bb73e2634d1c64d1ea29550e9a5c52883e57e1251bfebc4189aa37893e417030"}, "downloads": -1, "filename": "evolutions-0.8.1.tar.gz", "has_sig": false, "md5_digest": "75d7ed6c6b402c87b4dbc5b130516c71", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10314, "upload_time": "2019-11-23T10:52:24", "upload_time_iso_8601": "2019-11-23T10:52:24.094468Z", "url": "https://files.pythonhosted.org/packages/23/35/cb6f4d5d0fd72af58c2a74ee3d4c2afdb12f09c05acf9bd4337234ef2a86/evolutions-0.8.1.tar.gz", "yanked": false}], "0.8.2": [{"comment_text": "", "digests": {"md5": "0f6f73c90096d16fb0e6c62cf04c6fca", "sha256": "ed0b3cd7204041a53656fc787b9334d99dcd64d57531ad9bee44b6de77d3038c"}, "downloads": -1, "filename": "evolutions-0.8.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0f6f73c90096d16fb0e6c62cf04c6fca", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 14744, "upload_time": "2019-11-26T18:58:11", "upload_time_iso_8601": "2019-11-26T18:58:11.313389Z", "url": "https://files.pythonhosted.org/packages/d7/71/6b9bf247cfaf906c11e5e87c649d41e2134f2bb1ef03018de609cd6444a5/evolutions-0.8.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9edda20dfff864ee79f2cb3cd3010765", "sha256": "c658ebdd0a8b396cc3954a45424836f4058a29c1ccefe53e6d3211542e641d45"}, "downloads": -1, "filename": "evolutions-0.8.2.tar.gz", "has_sig": false, "md5_digest": "9edda20dfff864ee79f2cb3cd3010765", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 10653, "upload_time": "2019-11-26T18:58:12", "upload_time_iso_8601": "2019-11-26T18:58:12.661880Z", "url": "https://files.pythonhosted.org/packages/4e/08/d8f2edd15aedebbe350f137a632dcd8182553683fb0ed1e637ddc5dafb9b/evolutions-0.8.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0f6f73c90096d16fb0e6c62cf04c6fca", "sha256": "ed0b3cd7204041a53656fc787b9334d99dcd64d57531ad9bee44b6de77d3038c"}, "downloads": -1, "filename": "evolutions-0.8.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0f6f73c90096d16fb0e6c62cf04c6fca", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 14744, "upload_time": "2019-11-26T18:58:11", "upload_time_iso_8601": "2019-11-26T18:58:11.313389Z", "url": "https://files.pythonhosted.org/packages/d7/71/6b9bf247cfaf906c11e5e87c649d41e2134f2bb1ef03018de609cd6444a5/evolutions-0.8.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9edda20dfff864ee79f2cb3cd3010765", "sha256": "c658ebdd0a8b396cc3954a45424836f4058a29c1ccefe53e6d3211542e641d45"}, "downloads": -1, "filename": "evolutions-0.8.2.tar.gz", "has_sig": false, "md5_digest": "9edda20dfff864ee79f2cb3cd3010765", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 10653, "upload_time": "2019-11-26T18:58:12", "upload_time_iso_8601": "2019-11-26T18:58:12.661880Z", "url": "https://files.pythonhosted.org/packages/4e/08/d8f2edd15aedebbe350f137a632dcd8182553683fb0ed1e637ddc5dafb9b/evolutions-0.8.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:05 2020"}