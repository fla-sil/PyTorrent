{"info": {"author": "Ryan Spangler", "author_email": "ryan.spangler@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# gaia python client\n\n## running\n\nTo connect to a running Gaia server, find the host (open an ssh tunnel to it if needed) and do the following\n(optionally passing in a `config` like `{'gaia_host': 'localhost:24442'}`):\n\n```\nimport gaia\nflow = gaia.Gaia()\n```\n\nNow that we have a client object `flow`, we can call these methods:\n\n* workflows - list current workflows with summary information about each one\n* upload - upload a new workflow (properties, Commands, and Steps)\n* command - see what Commands are available and add new Commands to a new or existing workflow\n* merge - update or add new Steps to a new or existing workflow\n* halt - stop a running workflow\n* run - resume running a workflow\n* status - get information about a workflow\n* expire - run the Steps needed to (re)-output the given files and/or Steps as well as their dependent Steps\n\n### workflows\n\nTo list current workflows with summary info on each one:\n\n```python\nflow.workflows()\n```\n\n### upload\n\nTo get something running, upload a demo workflow:\n\n```\nimport json\ncommands = json.load('../../resources/test/demo-commands.json')\nsteps = json.load('../../resources/test/demo-processes.json')\nflow.upload('crick_demo_20191130.121500', {'owner': 'crick'}, commands, steps)\n```\n\nEach workflow needs a unique name. The standard practice is to construct a name in the\nform `owner_program_datetime`, e.g. `crick_DemoWorkflow_20191209.133734`.\nThis aids sorting and filtering workflows.\n\nYou will also need to launch some sisyphus workers. To do that\n[NOTE: This part is in flux]:\n\n```\nflow.launch(['a', 'b'])\n```\n\nLaunch more if you want : ) Give each a unique name.\nThey will deallocate 5 minutes after finishing their last Steps.\n\n\n### command\n\nCommands are the base level operations that can be run, specifically: command line programs in a given docker container image. Once defined, a Command can be invoked any number of times with a new set of vars, inputs, and outputs.\n\nIf you call this method with an empty or absent array argument, it will return all Commands in the named workflow.\n\n```\nflow.command('biostream')\n# [{'name': 'ls', 'image': 'ubuntu', ...}, ...]\n```\n\nA Command is expressed as a dictionary with the following keys:\n\n* name - the Command name\n* image - docker image to run in\n* command - array of shell tokens to execute\n* inputs - map of storage keys to internal paths inside the docker container where the Command's input files will be placed\n* outputs - map of storage keys to internal paths inside the docker container where the Command's output files will be retrieved after the Command has run\n* vars - map of var keys to string values to insert into Command tokens\n\nThey may also have an optional `stdout` key which specifies what path to place stdout output (so that stdout can be used as one of the outputs of the command).\n\n```\nflow.command('biostream', [...])\n```\n\nIf `flow.command()` is called with an array of Command entries it will merge the given Commands into the workflow, thus adding and/or replacing Commands and triggering the recomputation of any Steps that refer to these Commands.\n\n### merge\n\nOnce some Commands exist in the workflow you can start merging in Steps to run. Every Step names a Command and sets the Command's vars, inputs, and outputs. Inputs and outputs refer to paths in the data store. Vars are strings that can be spliced into various parts of the Command's shell tokens.\n\nCommands and Steps are kept in *workflows* which are entirely encapsulated from one another. Each workflow has its own data space with its own set of names and values.\n\nTo call the `merge` method, provide a workflow name and an array of Steps:\n\n```\nflow.merge('biostream', [{'name': 'ls-home', 'command': 'ls', 'inputs': {...}, ...}, ...])\n```\n\nEach Step is a dictionary with the following keys:\n\n* name - the Step name\n* command - name of the Command to invoke\n* inputs - map of input keys defined by the Command to keys in the data store to read the input files\n* outputs - map of output keys from the Command to keys in the data store to write the output files after successfully invoking the Command\n* vars - map of var keys to values. If this is an array it will create a Step for each element in the array with the given value\n* timeout - number of seconds to allow the Step to run\n\nIf this is a Step with a name that hasn't been seen before, it will create the Step entry and trigger the computation of outputs if the required inputs are available in the data store.  If the `name` of the Step being merged already exists in the workflow, that Step will be updated and recomputed, along with all Steps that depend on outputs from the updated Step in that workflow.\n\n### run\n\nThe `run` method simply triggers the computation in the provided workflow if it is not already running:\n\n```\nflow.run('biostream')\n```\n\n### halt\n\nThe `halt` method will immediately cancel all running tasks and stop the computation in the given workflow:\n\n```\nflow.halt('biostream')\n```\n\n### status\n\nThe `status` method provides information about a workflow, formatted as a\ndictionary with these keys:\n\n* state - a string representing the state of the overall workflow. Possible values are 'initialized', 'running', 'complete', 'halted', and 'error'.\n* commands - a list of the workflow's Commands\n* waiting-inputs - a list of the data inputs (file and directory paths) that Steps are waiting on\n\n```\nflow.status('biostream')\n```\n\nOr to include internal debugging details from the Gaia server:\n\n```\nflow.status('biostream', debug=True)\n```\n\n### expire\n\nThe `expire` method accepts a workflow and a list of Steps names and storage paths (storage keys). It makes those Steps and their dependent Steps have to run again.\n\n```\nflow.expire('biostream', ['ls-home', 'genomes', \u2026])\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/prismofeverything/gaia", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "gaia", "package_url": "https://pypi.org/project/gaia/", "platform": "", "project_url": "https://pypi.org/project/gaia/", "project_urls": {"Homepage": "https://github.com/prismofeverything/gaia"}, "release_url": "https://pypi.org/project/gaia/0.0.9/", "requires_dist": ["requests", "pyyaml"], "requires_python": "", "summary": "", "version": "0.0.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>gaia python client</h1>\n<h2>running</h2>\n<p>To connect to a running Gaia server, find the host (open an ssh tunnel to it if needed) and do the following\n(optionally passing in a <code>config</code> like <code>{'gaia_host': 'localhost:24442'}</code>):</p>\n<pre><code>import gaia\nflow = gaia.Gaia()\n</code></pre>\n<p>Now that we have a client object <code>flow</code>, we can call these methods:</p>\n<ul>\n<li>workflows - list current workflows with summary information about each one</li>\n<li>upload - upload a new workflow (properties, Commands, and Steps)</li>\n<li>command - see what Commands are available and add new Commands to a new or existing workflow</li>\n<li>merge - update or add new Steps to a new or existing workflow</li>\n<li>halt - stop a running workflow</li>\n<li>run - resume running a workflow</li>\n<li>status - get information about a workflow</li>\n<li>expire - run the Steps needed to (re)-output the given files and/or Steps as well as their dependent Steps</li>\n</ul>\n<h3>workflows</h3>\n<p>To list current workflows with summary info on each one:</p>\n<pre><span class=\"n\">flow</span><span class=\"o\">.</span><span class=\"n\">workflows</span><span class=\"p\">()</span>\n</pre>\n<h3>upload</h3>\n<p>To get something running, upload a demo workflow:</p>\n<pre><code>import json\ncommands = json.load('../../resources/test/demo-commands.json')\nsteps = json.load('../../resources/test/demo-processes.json')\nflow.upload('crick_demo_20191130.121500', {'owner': 'crick'}, commands, steps)\n</code></pre>\n<p>Each workflow needs a unique name. The standard practice is to construct a name in the\nform <code>owner_program_datetime</code>, e.g. <code>crick_DemoWorkflow_20191209.133734</code>.\nThis aids sorting and filtering workflows.</p>\n<p>You will also need to launch some sisyphus workers. To do that\n[NOTE: This part is in flux]:</p>\n<pre><code>flow.launch(['a', 'b'])\n</code></pre>\n<p>Launch more if you want : ) Give each a unique name.\nThey will deallocate 5 minutes after finishing their last Steps.</p>\n<h3>command</h3>\n<p>Commands are the base level operations that can be run, specifically: command line programs in a given docker container image. Once defined, a Command can be invoked any number of times with a new set of vars, inputs, and outputs.</p>\n<p>If you call this method with an empty or absent array argument, it will return all Commands in the named workflow.</p>\n<pre><code>flow.command('biostream')\n# [{'name': 'ls', 'image': 'ubuntu', ...}, ...]\n</code></pre>\n<p>A Command is expressed as a dictionary with the following keys:</p>\n<ul>\n<li>name - the Command name</li>\n<li>image - docker image to run in</li>\n<li>command - array of shell tokens to execute</li>\n<li>inputs - map of storage keys to internal paths inside the docker container where the Command's input files will be placed</li>\n<li>outputs - map of storage keys to internal paths inside the docker container where the Command's output files will be retrieved after the Command has run</li>\n<li>vars - map of var keys to string values to insert into Command tokens</li>\n</ul>\n<p>They may also have an optional <code>stdout</code> key which specifies what path to place stdout output (so that stdout can be used as one of the outputs of the command).</p>\n<pre><code>flow.command('biostream', [...])\n</code></pre>\n<p>If <code>flow.command()</code> is called with an array of Command entries it will merge the given Commands into the workflow, thus adding and/or replacing Commands and triggering the recomputation of any Steps that refer to these Commands.</p>\n<h3>merge</h3>\n<p>Once some Commands exist in the workflow you can start merging in Steps to run. Every Step names a Command and sets the Command's vars, inputs, and outputs. Inputs and outputs refer to paths in the data store. Vars are strings that can be spliced into various parts of the Command's shell tokens.</p>\n<p>Commands and Steps are kept in <em>workflows</em> which are entirely encapsulated from one another. Each workflow has its own data space with its own set of names and values.</p>\n<p>To call the <code>merge</code> method, provide a workflow name and an array of Steps:</p>\n<pre><code>flow.merge('biostream', [{'name': 'ls-home', 'command': 'ls', 'inputs': {...}, ...}, ...])\n</code></pre>\n<p>Each Step is a dictionary with the following keys:</p>\n<ul>\n<li>name - the Step name</li>\n<li>command - name of the Command to invoke</li>\n<li>inputs - map of input keys defined by the Command to keys in the data store to read the input files</li>\n<li>outputs - map of output keys from the Command to keys in the data store to write the output files after successfully invoking the Command</li>\n<li>vars - map of var keys to values. If this is an array it will create a Step for each element in the array with the given value</li>\n<li>timeout - number of seconds to allow the Step to run</li>\n</ul>\n<p>If this is a Step with a name that hasn't been seen before, it will create the Step entry and trigger the computation of outputs if the required inputs are available in the data store.  If the <code>name</code> of the Step being merged already exists in the workflow, that Step will be updated and recomputed, along with all Steps that depend on outputs from the updated Step in that workflow.</p>\n<h3>run</h3>\n<p>The <code>run</code> method simply triggers the computation in the provided workflow if it is not already running:</p>\n<pre><code>flow.run('biostream')\n</code></pre>\n<h3>halt</h3>\n<p>The <code>halt</code> method will immediately cancel all running tasks and stop the computation in the given workflow:</p>\n<pre><code>flow.halt('biostream')\n</code></pre>\n<h3>status</h3>\n<p>The <code>status</code> method provides information about a workflow, formatted as a\ndictionary with these keys:</p>\n<ul>\n<li>state - a string representing the state of the overall workflow. Possible values are 'initialized', 'running', 'complete', 'halted', and 'error'.</li>\n<li>commands - a list of the workflow's Commands</li>\n<li>waiting-inputs - a list of the data inputs (file and directory paths) that Steps are waiting on</li>\n</ul>\n<pre><code>flow.status('biostream')\n</code></pre>\n<p>Or to include internal debugging details from the Gaia server:</p>\n<pre><code>flow.status('biostream', debug=True)\n</code></pre>\n<h3>expire</h3>\n<p>The <code>expire</code> method accepts a workflow and a list of Steps names and storage paths (storage keys). It makes those Steps and their dependent Steps have to run again.</p>\n<pre><code>flow.expire('biostream', ['ls-home', 'genomes', \u2026])\n</code></pre>\n\n          </div>"}, "last_serial": 6269809, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "7fe0330864f3920a412dbfeaba68ff43", "sha256": "585b8217c4741d10b558cceb54786e8dd6289fb76dea2faa760959d220f7b94a"}, "downloads": -1, "filename": "gaia-0.0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "7fe0330864f3920a412dbfeaba68ff43", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 4928, "upload_time": "2019-07-02T17:50:44", "upload_time_iso_8601": "2019-07-02T17:50:44.816459Z", "url": "https://files.pythonhosted.org/packages/87/cf/166e9a0ac12b59c02edc649036a726d2377733aab5840d8ffa116cfae572/gaia-0.0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bad713e5e86bb54522f859805106cd3e", "sha256": "a576201fe80b222028aa06c202102955931147740065e8da0a3804411c842e34"}, "downloads": -1, "filename": "gaia-0.0.1.tar.gz", "has_sig": false, "md5_digest": "bad713e5e86bb54522f859805106cd3e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4932, "upload_time": "2019-07-02T17:50:47", "upload_time_iso_8601": "2019-07-02T17:50:47.325639Z", "url": "https://files.pythonhosted.org/packages/35/7d/39f903195990b3ae1dd8d6a5c81098488637f509db98e3fc1a12623f4870/gaia-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "279843c9e85ca0968ed78c2a07937001", "sha256": "773490acb7209699d036fb125d1a4ec8ed37e83bbdcac14155ca9bbee7e377bb"}, "downloads": -1, "filename": "gaia-0.0.2-py2-none-any.whl", "has_sig": false, "md5_digest": "279843c9e85ca0968ed78c2a07937001", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5609, "upload_time": "2019-07-11T23:41:55", "upload_time_iso_8601": "2019-07-11T23:41:55.132382Z", "url": "https://files.pythonhosted.org/packages/f8/ca/d6110896803ea2417adcffcfed18d510a5ddfefae510f16410b04025da8f/gaia-0.0.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1dfc68ea6a3311ce37fcc8fce55961a9", "sha256": "4e1d2ba7829ac511efea24dce85919ccbdee9380b3f097061268f97b030e7094"}, "downloads": -1, "filename": "gaia-0.0.2.tar.gz", "has_sig": false, "md5_digest": "1dfc68ea6a3311ce37fcc8fce55961a9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5396, "upload_time": "2019-07-11T23:41:57", "upload_time_iso_8601": "2019-07-11T23:41:57.888112Z", "url": "https://files.pythonhosted.org/packages/bd/00/dcfb448ff15bb9012afd6868c82570ca716677d86159fec9bc4615c3cada/gaia-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "e4d2094bbc7b9fa3ccb06c0390e42bce", "sha256": "0a011372654a616271e4ca5eda52435f6566b72b3b01c4defdd877700c71120d"}, "downloads": -1, "filename": "gaia-0.0.4-py2-none-any.whl", "has_sig": false, "md5_digest": "e4d2094bbc7b9fa3ccb06c0390e42bce", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5054, "upload_time": "2019-07-18T19:58:17", "upload_time_iso_8601": "2019-07-18T19:58:17.386784Z", "url": "https://files.pythonhosted.org/packages/e7/34/766145cc6229b13051985e947ea78aca5e7bc06cf518d5a6173577c80a4c/gaia-0.0.4-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "41b9116d29d94d89eba4b592b2802798", "sha256": "c2e12706a5c9e369005d733046bcdc3f004411dffa76f1ac494e89625e1bacd0"}, "downloads": -1, "filename": "gaia-0.0.4.tar.gz", "has_sig": false, "md5_digest": "41b9116d29d94d89eba4b592b2802798", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4855, "upload_time": "2019-07-18T19:58:20", "upload_time_iso_8601": "2019-07-18T19:58:20.210652Z", "url": "https://files.pythonhosted.org/packages/01/46/a8fee48a7fb9a6fbc6980378592fb26520b914c3e8efb383aee31ed1c6e3/gaia-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "e573ecf942c460ee6d94000aa8611a85", "sha256": "514cec311a4d332d12e2d9618e8578447ab7037d82cf4410808433237768ac3f"}, "downloads": -1, "filename": "gaia-0.0.5-py2-none-any.whl", "has_sig": false, "md5_digest": "e573ecf942c460ee6d94000aa8611a85", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5047, "upload_time": "2019-07-19T17:19:59", "upload_time_iso_8601": "2019-07-19T17:19:59.463631Z", "url": "https://files.pythonhosted.org/packages/30/72/a78cdd13991b09d2c568febf93dfcf75663838f7373177fbbf289603c1d0/gaia-0.0.5-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "57b586dfc1a89f4e293f4240cc82a202", "sha256": "7934dfa8728c3863bef0b675fc32c694f6ecd6d8266bcd12baf934acd8f0d541"}, "downloads": -1, "filename": "gaia-0.0.5.tar.gz", "has_sig": false, "md5_digest": "57b586dfc1a89f4e293f4240cc82a202", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4857, "upload_time": "2019-07-19T17:20:00", "upload_time_iso_8601": "2019-07-19T17:20:00.516335Z", "url": "https://files.pythonhosted.org/packages/9c/aa/54722cf2dc3c18340251bc78a528c5283999c190a95ae26530a7c104d2ac/gaia-0.0.5.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "19f7e29e9100c4bfd7072323f3e78015", "sha256": "7e3d0b24e918d8553d74ebe748a79dfa27f3bc2efbad2c20119e59e19e6db274"}, "downloads": -1, "filename": "gaia-0.0.7-py2-none-any.whl", "has_sig": false, "md5_digest": "19f7e29e9100c4bfd7072323f3e78015", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5261, "upload_time": "2019-07-24T00:21:48", "upload_time_iso_8601": "2019-07-24T00:21:48.601593Z", "url": "https://files.pythonhosted.org/packages/7e/f5/5ebe1f1f63e87cea4f432767d0c1238540b79bb548dd2e6d95777c164558/gaia-0.0.7-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e77fbfe09772cff03123949c8ab60f76", "sha256": "7e8ed77818d5fb6517023bbf41b0f9df1336789b754a2363c83cdb64062c111a"}, "downloads": -1, "filename": "gaia-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e77fbfe09772cff03123949c8ab60f76", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4987, "upload_time": "2019-07-24T00:21:50", "upload_time_iso_8601": "2019-07-24T00:21:50.039961Z", "url": "https://files.pythonhosted.org/packages/e9/0b/bcb9cf60ce0de4fa90fb7243d31a3d0bcf5f2fa8b2ce347c2bb65bde541b/gaia-0.0.7.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "0588ce77c11659e7c0c9ce1900b9cc63", "sha256": "1958bc725de1113f59fbbef888cf0f339faab9f647f5910de273688db265a650"}, "downloads": -1, "filename": "gaia-0.0.9-py2-none-any.whl", "has_sig": false, "md5_digest": "0588ce77c11659e7c0c9ce1900b9cc63", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7244, "upload_time": "2019-12-09T23:14:25", "upload_time_iso_8601": "2019-12-09T23:14:25.233681Z", "url": "https://files.pythonhosted.org/packages/46/b0/dab64d100bcfd19be408d6f398045187d65f0da290baf241470e11c948f0/gaia-0.0.9-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5c633588222eef3c12234f2391e77cde", "sha256": "c879346a79b7c9add718c3a5cba06f847ed04564dbf22fbdb663a736dd00d75c"}, "downloads": -1, "filename": "gaia-0.0.9.tar.gz", "has_sig": false, "md5_digest": "5c633588222eef3c12234f2391e77cde", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6981, "upload_time": "2019-12-09T23:14:26", "upload_time_iso_8601": "2019-12-09T23:14:26.762632Z", "url": "https://files.pythonhosted.org/packages/f1/d8/35a61de9bded59285631995ab885dc34d37b4458e1a5b15dc6252047a47e/gaia-0.0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0588ce77c11659e7c0c9ce1900b9cc63", "sha256": "1958bc725de1113f59fbbef888cf0f339faab9f647f5910de273688db265a650"}, "downloads": -1, "filename": "gaia-0.0.9-py2-none-any.whl", "has_sig": false, "md5_digest": "0588ce77c11659e7c0c9ce1900b9cc63", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7244, "upload_time": "2019-12-09T23:14:25", "upload_time_iso_8601": "2019-12-09T23:14:25.233681Z", "url": "https://files.pythonhosted.org/packages/46/b0/dab64d100bcfd19be408d6f398045187d65f0da290baf241470e11c948f0/gaia-0.0.9-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5c633588222eef3c12234f2391e77cde", "sha256": "c879346a79b7c9add718c3a5cba06f847ed04564dbf22fbdb663a736dd00d75c"}, "downloads": -1, "filename": "gaia-0.0.9.tar.gz", "has_sig": false, "md5_digest": "5c633588222eef3c12234f2391e77cde", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6981, "upload_time": "2019-12-09T23:14:26", "upload_time_iso_8601": "2019-12-09T23:14:26.762632Z", "url": "https://files.pythonhosted.org/packages/f1/d8/35a61de9bded59285631995ab885dc34d37b4458e1a5b15dc6252047a47e/gaia-0.0.9.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:59:21 2020"}