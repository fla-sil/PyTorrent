{"info": {"author": "Olivier Grisel", "author_email": "olivier.grisel@ensta.org", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering"], "description": "# pygbm [![Build Status](https://travis-ci.org/ogrisel/pygbm.svg?branch=master)](https://travis-ci.org/ogrisel/pygbm) [![codecov](https://codecov.io/gh/ogrisel/pygbm/branch/master/graph/badge.svg)](https://codecov.io/gh/ogrisel/pygbm) [![python versions](https://img.shields.io/badge/python-3.6+-blue.svg)](https://github.com/ogrisel/pygbm)\n\n\n\nExperimental Gradient Boosting Machines in Python.\n\nThe goal of this project is to evaluate whether it's possible to implement a\npure Python yet efficient version histogram-binning of Gradient Boosting\nTrees (possibly with all the LightGBM optimizations) while staying in pure\nPython 3.6+ using the [numba](http://numba.pydata.org/) jit compiler.\n\npygbm provides a set of scikit-learn compatible estimator classes that\nshould play well with the scikit-learn `Pipeline` and model selection tools\n(grid search and randomized hyperparameter search).\n\nLonger term plans include integration with dask and dask-ml for\nout-of-core and distributed fitting on a cluster.\n\n## Installation\n\nThe project is available on PyPI and can be installed with `pip`:\n\n    pip install pygbm\n\nYou'll need Python 3.6 at least.\n\n## Documentation\n\nThe API documentation is available at:\n\nhttps://pygbm.readthedocs.io/\n\nYou might also want to have a look at the `examples/` folder of this repo.\n\n## Status\n\nThe project is experimental. The API is subject to change without deprecation notice. Use at your own risk.\n\nWe welcome any feedback in the github issue tracker:\n\nhttps://github.com/ogrisel/pygbm/issues\n\n## Running the development version\n\nUse pip to install in \"editable\" mode:\n\n    git clone https://github.com/ogrisel/pygbm.git\n    cd pygbm\n    pip install -r requirements.txt\n    pip install --editable .\n\nRun the tests with pytest:\n\n    pip install -r requirements.txt\n    pytest\n\n## Benchmarking\n\nThe `benchmarks` folder contains some scripts to evaluate the computation\nperformance of various parts of pygbm. Keep in mind that numba's JIT\ncompilation [takes\ntime](http://numba.pydata.org/numba-doc/latest/user/5minguide.html#how-to-measure-the-performance-of-numba)!\n\n### Profiling\n\nTo profile the benchmarks, you can use\n[snakeviz](https://jiffyclub.github.io/snakeviz/) to get an interactive\nHTML report:\n\n    pip install snakeviz\n    python -m cProfile -o bench_higgs_boson.prof benchmarks/bench_higgs_boson.py\n    snakeviz bench_higgs_boson.prof\n\n### Debugging numba type inference\n\nTo introspect the results of type inference steps in the numba sections\ncalled by a given benchmarking script:\n\n    numba --annotate-html bench_higgs_boson.html benchmarks/bench_higgs_boson.py\n\nIn particular it is interesting to check that the numerical variables in\nthe hot loops highlighted by the snakeviz profiling report have the\nexpected precision level (e.g. `float32` for loss computation, `uint8`\nfor binned feature values, ...).\n\n### Impact of thread-based parallelism\n\nSome benchmarks can call numba functions that leverage the built-in\nthread-based parallelism with `@njit(parallel=True)` and `prange` loops.\nOn a multicore machine you can evaluate how the thread-based parallelism\nscales by explicitly setting the `NUMBA_NUM_THREAD` environment\nvariable. For instance try:\n\n    NUMBA_NUM_THREADS=1 python benchmarks/bench_binning.py\n\nvs:\n\n    NUMBA_NUM_THREADS=4 python benchmarks/bench_binning.py\n\n\n## Acknowledgements\n\nThe work from Nicolas Hug is supported by the National Science Foundation\nunder Grant No. 1740305 and by DARPA under Grant No. DARPA-BAA-16-51\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ogrisel/pygbm/", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pygbm", "package_url": "https://pypi.org/project/pygbm/", "platform": "any", "project_url": "https://pypi.org/project/pygbm/", "project_urls": {"Homepage": "https://github.com/ogrisel/pygbm/"}, "release_url": "https://pypi.org/project/pygbm/0.1.0/", "requires_dist": ["numpy", "scipy", "scikit-learn", "numba"], "requires_python": ">=3.6", "summary": "Experimental, numba-based Gradient Boosting Machines", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pygbm <a href=\"https://travis-ci.org/ogrisel/pygbm\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/22db6c5828117e91fadc1ec6d4356c782cd31d0e/68747470733a2f2f7472617669732d63692e6f72672f6f67726973656c2f707967626d2e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://codecov.io/gh/ogrisel/pygbm\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1394ec213a1bb8e90b0169a295eb7fa3698e6357/68747470733a2f2f636f6465636f762e696f2f67682f6f67726973656c2f707967626d2f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a> <a href=\"https://github.com/ogrisel/pygbm\" rel=\"nofollow\"><img alt=\"python versions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6a042d910c74fbce532a01da853019c164ef42a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362b2d626c75652e737667\"></a></h1>\n<p>Experimental Gradient Boosting Machines in Python.</p>\n<p>The goal of this project is to evaluate whether it's possible to implement a\npure Python yet efficient version histogram-binning of Gradient Boosting\nTrees (possibly with all the LightGBM optimizations) while staying in pure\nPython 3.6+ using the <a href=\"http://numba.pydata.org/\" rel=\"nofollow\">numba</a> jit compiler.</p>\n<p>pygbm provides a set of scikit-learn compatible estimator classes that\nshould play well with the scikit-learn <code>Pipeline</code> and model selection tools\n(grid search and randomized hyperparameter search).</p>\n<p>Longer term plans include integration with dask and dask-ml for\nout-of-core and distributed fitting on a cluster.</p>\n<h2>Installation</h2>\n<p>The project is available on PyPI and can be installed with <code>pip</code>:</p>\n<pre><code>pip install pygbm\n</code></pre>\n<p>You'll need Python 3.6 at least.</p>\n<h2>Documentation</h2>\n<p>The API documentation is available at:</p>\n<p><a href=\"https://pygbm.readthedocs.io/\" rel=\"nofollow\">https://pygbm.readthedocs.io/</a></p>\n<p>You might also want to have a look at the <code>examples/</code> folder of this repo.</p>\n<h2>Status</h2>\n<p>The project is experimental. The API is subject to change without deprecation notice. Use at your own risk.</p>\n<p>We welcome any feedback in the github issue tracker:</p>\n<p><a href=\"https://github.com/ogrisel/pygbm/issues\" rel=\"nofollow\">https://github.com/ogrisel/pygbm/issues</a></p>\n<h2>Running the development version</h2>\n<p>Use pip to install in \"editable\" mode:</p>\n<pre><code>git clone https://github.com/ogrisel/pygbm.git\ncd pygbm\npip install -r requirements.txt\npip install --editable .\n</code></pre>\n<p>Run the tests with pytest:</p>\n<pre><code>pip install -r requirements.txt\npytest\n</code></pre>\n<h2>Benchmarking</h2>\n<p>The <code>benchmarks</code> folder contains some scripts to evaluate the computation\nperformance of various parts of pygbm. Keep in mind that numba's JIT\ncompilation <a href=\"http://numba.pydata.org/numba-doc/latest/user/5minguide.html#how-to-measure-the-performance-of-numba\" rel=\"nofollow\">takes\ntime</a>!</p>\n<h3>Profiling</h3>\n<p>To profile the benchmarks, you can use\n<a href=\"https://jiffyclub.github.io/snakeviz/\" rel=\"nofollow\">snakeviz</a> to get an interactive\nHTML report:</p>\n<pre><code>pip install snakeviz\npython -m cProfile -o bench_higgs_boson.prof benchmarks/bench_higgs_boson.py\nsnakeviz bench_higgs_boson.prof\n</code></pre>\n<h3>Debugging numba type inference</h3>\n<p>To introspect the results of type inference steps in the numba sections\ncalled by a given benchmarking script:</p>\n<pre><code>numba --annotate-html bench_higgs_boson.html benchmarks/bench_higgs_boson.py\n</code></pre>\n<p>In particular it is interesting to check that the numerical variables in\nthe hot loops highlighted by the snakeviz profiling report have the\nexpected precision level (e.g. <code>float32</code> for loss computation, <code>uint8</code>\nfor binned feature values, ...).</p>\n<h3>Impact of thread-based parallelism</h3>\n<p>Some benchmarks can call numba functions that leverage the built-in\nthread-based parallelism with <code>@njit(parallel=True)</code> and <code>prange</code> loops.\nOn a multicore machine you can evaluate how the thread-based parallelism\nscales by explicitly setting the <code>NUMBA_NUM_THREAD</code> environment\nvariable. For instance try:</p>\n<pre><code>NUMBA_NUM_THREADS=1 python benchmarks/bench_binning.py\n</code></pre>\n<p>vs:</p>\n<pre><code>NUMBA_NUM_THREADS=4 python benchmarks/bench_binning.py\n</code></pre>\n<h2>Acknowledgements</h2>\n<p>The work from Nicolas Hug is supported by the National Science Foundation\nunder Grant No. 1740305 and by DARPA under Grant No. DARPA-BAA-16-51</p>\n\n          </div>"}, "last_serial": 4601194, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "9f94c5795c1ff5b3ec767261cc4fedba", "sha256": "563184b56759daafcb9f4b81ac1ad264307aecb636cb1f9fc5c99876feed753c"}, "downloads": -1, "filename": "pygbm-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9f94c5795c1ff5b3ec767261cc4fedba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32499, "upload_time": "2018-12-14T23:59:56", "upload_time_iso_8601": "2018-12-14T23:59:56.432693Z", "url": "https://files.pythonhosted.org/packages/da/d1/b71d06888f0c6a6f45f0592f90ed1c07e7041a99ba2fc389d59302958862/pygbm-0.1.0-py3-none-any.whl", "yanked": false}], "0.1.0.dev0": [{"comment_text": "", "digests": {"md5": "c667eea6fa7ef78317153cd913fd612d", "sha256": "1821a7a37c1a0734652ada697a52e003fd261d0adc230c11c102808e4babcce8"}, "downloads": -1, "filename": "pygbm-0.1.0.dev0-py3-none-any.whl", "has_sig": false, "md5_digest": "c667eea6fa7ef78317153cd913fd612d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32475, "upload_time": "2018-12-14T21:15:52", "upload_time_iso_8601": "2018-12-14T21:15:52.054016Z", "url": "https://files.pythonhosted.org/packages/bd/cf/5324cc2fc954a95d232ec1eba7f20a2119337eb77d9a0fb01c465567caef/pygbm-0.1.0.dev0-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9f94c5795c1ff5b3ec767261cc4fedba", "sha256": "563184b56759daafcb9f4b81ac1ad264307aecb636cb1f9fc5c99876feed753c"}, "downloads": -1, "filename": "pygbm-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9f94c5795c1ff5b3ec767261cc4fedba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32499, "upload_time": "2018-12-14T23:59:56", "upload_time_iso_8601": "2018-12-14T23:59:56.432693Z", "url": "https://files.pythonhosted.org/packages/da/d1/b71d06888f0c6a6f45f0592f90ed1c07e7041a99ba2fc389d59302958862/pygbm-0.1.0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:05:15 2020"}