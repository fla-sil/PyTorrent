{"info": {"author": "Diane Napolitano", "author_email": "dmnapolitano@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Operating System :: Unix", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Topic :: Text Processing"], "description": "match\n=====\n\n|Build Status|\n\n|Latest Version|\\ |Downloads|\n\nThe purpose of the module ``Match`` is to get the offsets (as well as\nthe string between those offsets, for debugging) of a cleaned-up,\ntokenized string from its original, untokenized source. \u201cBig deal,\u201d you\nmight say, but this is actually a pretty difficult task if the original\ntext is sufficiently messy, not to mention rife with Unicode characters.\n\nConsider some text, stored in a variable ``original_text``, like:\n\n::\n\n   I   am writing a letter !  Sometimes,I forget to put spaces (and do weird stuff with punctuation)  ?  J'aurai une pomme, s'il vous pl\u00e2it !\n\nThis will/should/might be properly tokenized as:\n\n.. code:: python\n\n   [['I', 'am', 'writing', 'a', 'letter', '!'],\n    ['Sometimes', ',', 'I', 'forget', 'to', 'put', 'spaces', '-LRB-', 'and', 'do', 'weird', 'stuff', 'with', 'punctuation', '-RRB-', '?'],\n    [\"J'aurai\", 'une', 'pomme', ',', \"s'il\", 'vous', 'pl\u00e2it', '!']]\n\nNow:\n\n.. code:: python\n\n   In [2]: import match\n\n   In [3]: match.match(original_text, ['-LRB-', 'and', 'do', 'weird', 'stuff', 'with', 'punctuation', '-RRB-'])\n   Out[3]: [(60, 97, '(and do weird stuff with punctuation)')]\n\n   In [4]: match.match(original_text, ['I', 'am', 'writing', 'a', 'letter', '!'])\n   Out[4]: [(0, 25, 'I   am writing a letter !')]\n\n   In [5]: match.match(original_text, [\"s'il\", 'vous', 'pl\u00e2it', '!'])\n   Out[5]: [(121, 138, \"s'il vous pl\u00e2it !\")]\n\nThe return type from ``match()`` is a ``list`` because it will return\n*all* occurrences of the argument, be it a ``list`` of tokens or a\nsingle ``string`` (word):\n\n.. code:: python\n\n   In [6]: match.match(original_text, \"I\")\n   Out[6]: [(0, 1, 'I'), (37, 38, 'I')]\n\nWhen passing in a single ``string``, ``match()`` is expecting that\n``string`` to be a single word or token. Thus:\n\n.. code:: python\n\n   In [7]: match.match(\"****because,the****\", \"because , the\")\n   Out[7]: []\n\nTry passing in ``\"because , the\".split(' ')`` instead, or better yet,\nthe output from a proper tokenizer.\n\nFor convenience, a function called ``match_lines()`` is provided:\n\n.. code:: python\n\n   In [8]: match.match_lines(original_text, [ \n      ...: ['-LRB-', 'and', 'do', 'weird', 'stuff', 'with', 'punctuation', '-RRB-'], \n      ...: ['I', 'am', 'writing', 'a', 'letter', '!'], \n      ...: \"I\" \n      ...: ])\n   Out[8]:\n   [(0, 1, 'I'),\n    (0, 25, 'I   am writing a letter !'),\n    (37, 38, 'I'),\n    (60, 97, '(and do weird stuff with punctuation)')]\n\nThe values returned will always be sorted by their offsets.\n\nInstallation\n------------\n\n``pip install match``, or for Mac OS X and 64-bit Linux:\n\n::\n\n   $ conda install -c dmnapolitano match\n\nRequirements\n------------\n\n-  Python >= 3.4\n-  `nltk <http://www.nltk.org>`__\n-  `regex <https://pypi.python.org/pypi/regex>`__\n\nDocumentation\n-------------\n\n`Here! <match>`__.\n\n.. |Build Status| image:: https://travis-ci.org/EducationalTestingService/match.svg?branch=master\n   :target: https://travis-ci.org/EducationalTestingService/match\n.. |Latest Version| image:: https://img.shields.io/pypi/v/match.svg\n   :target: https://pypi.python.org/pypi/match/\n.. |Downloads| image:: https://img.shields.io/pypi/dm/match.svg\n   :target: https://pypi.python.org/pypi/match/", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/EducationalTestingService/match", "keywords": "tokenization", "license": "", "maintainer": "", "maintainer_email": "", "name": "match", "package_url": "https://pypi.org/project/match/", "platform": "", "project_url": "https://pypi.org/project/match/", "project_urls": {"Homepage": "https://github.com/EducationalTestingService/match"}, "release_url": "https://pypi.org/project/match/0.3.0/", "requires_dist": null, "requires_python": "", "summary": "", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/EducationalTestingService/match\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/996f5a7ed622169f23147ace6b5fe3451131769b/68747470733a2f2f7472617669732d63692e6f72672f456475636174696f6e616c54657374696e67536572766963652f6d617463682e7376673f6272616e63683d6d6173746572\"></a></p>\n<p><a href=\"https://pypi.python.org/pypi/match/\" rel=\"nofollow\"><img alt=\"Latest Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7f7c8f9ea5dbd4525dee5145666d753ac480bc8a/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d617463682e737667\"></a><a href=\"https://pypi.python.org/pypi/match/\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/34c0a180e2f20626babb952ae2de63657a2a72be/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6d617463682e737667\"></a></p>\n<p>The purpose of the module <tt>Match</tt> is to get the offsets (as well as\nthe string between those offsets, for debugging) of a cleaned-up,\ntokenized string from its original, untokenized source. \u201cBig deal,\u201d you\nmight say, but this is actually a pretty difficult task if the original\ntext is sufficiently messy, not to mention rife with Unicode characters.</p>\n<p>Consider some text, stored in a variable <tt>original_text</tt>, like:</p>\n<pre>I   am writing a letter !  Sometimes,I forget to put spaces (and do weird stuff with punctuation)  ?  J'aurai une pomme, s'il vous pl\u00e2it !\n</pre>\n<p>This will/should/might be properly tokenized as:</p>\n<pre><span class=\"p\">[[</span><span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'am'</span><span class=\"p\">,</span> <span class=\"s1\">'writing'</span><span class=\"p\">,</span> <span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'letter'</span><span class=\"p\">,</span> <span class=\"s1\">'!'</span><span class=\"p\">],</span>\n <span class=\"p\">[</span><span class=\"s1\">'Sometimes'</span><span class=\"p\">,</span> <span class=\"s1\">','</span><span class=\"p\">,</span> <span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'forget'</span><span class=\"p\">,</span> <span class=\"s1\">'to'</span><span class=\"p\">,</span> <span class=\"s1\">'put'</span><span class=\"p\">,</span> <span class=\"s1\">'spaces'</span><span class=\"p\">,</span> <span class=\"s1\">'-LRB-'</span><span class=\"p\">,</span> <span class=\"s1\">'and'</span><span class=\"p\">,</span> <span class=\"s1\">'do'</span><span class=\"p\">,</span> <span class=\"s1\">'weird'</span><span class=\"p\">,</span> <span class=\"s1\">'stuff'</span><span class=\"p\">,</span> <span class=\"s1\">'with'</span><span class=\"p\">,</span> <span class=\"s1\">'punctuation'</span><span class=\"p\">,</span> <span class=\"s1\">'-RRB-'</span><span class=\"p\">,</span> <span class=\"s1\">'?'</span><span class=\"p\">],</span>\n <span class=\"p\">[</span><span class=\"s2\">\"J'aurai\"</span><span class=\"p\">,</span> <span class=\"s1\">'une'</span><span class=\"p\">,</span> <span class=\"s1\">'pomme'</span><span class=\"p\">,</span> <span class=\"s1\">','</span><span class=\"p\">,</span> <span class=\"s2\">\"s'il\"</span><span class=\"p\">,</span> <span class=\"s1\">'vous'</span><span class=\"p\">,</span> <span class=\"s1\">'pl\u00e2it'</span><span class=\"p\">,</span> <span class=\"s1\">'!'</span><span class=\"p\">]]</span>\n</pre>\n<p>Now:</p>\n<pre><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]:</span> <span class=\"kn\">import</span> <span class=\"nn\">match</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"n\">match</span><span class=\"o\">.</span><span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">original_text</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'-LRB-'</span><span class=\"p\">,</span> <span class=\"s1\">'and'</span><span class=\"p\">,</span> <span class=\"s1\">'do'</span><span class=\"p\">,</span> <span class=\"s1\">'weird'</span><span class=\"p\">,</span> <span class=\"s1\">'stuff'</span><span class=\"p\">,</span> <span class=\"s1\">'with'</span><span class=\"p\">,</span> <span class=\"s1\">'punctuation'</span><span class=\"p\">,</span> <span class=\"s1\">'-RRB-'</span><span class=\"p\">])</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">]:</span> <span class=\"p\">[(</span><span class=\"mi\">60</span><span class=\"p\">,</span> <span class=\"mi\">97</span><span class=\"p\">,</span> <span class=\"s1\">'(and do weird stuff with punctuation)'</span><span class=\"p\">)]</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"n\">match</span><span class=\"o\">.</span><span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">original_text</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'am'</span><span class=\"p\">,</span> <span class=\"s1\">'writing'</span><span class=\"p\">,</span> <span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'letter'</span><span class=\"p\">,</span> <span class=\"s1\">'!'</span><span class=\"p\">])</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">]:</span> <span class=\"p\">[(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">25</span><span class=\"p\">,</span> <span class=\"s1\">'I   am writing a letter !'</span><span class=\"p\">)]</span>\n\n<span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"n\">match</span><span class=\"o\">.</span><span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">original_text</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"s'il\"</span><span class=\"p\">,</span> <span class=\"s1\">'vous'</span><span class=\"p\">,</span> <span class=\"s1\">'pl\u00e2it'</span><span class=\"p\">,</span> <span class=\"s1\">'!'</span><span class=\"p\">])</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">]:</span> <span class=\"p\">[(</span><span class=\"mi\">121</span><span class=\"p\">,</span> <span class=\"mi\">138</span><span class=\"p\">,</span> <span class=\"s2\">\"s'il vous pl\u00e2it !\"</span><span class=\"p\">)]</span>\n</pre>\n<p>The return type from <tt>match()</tt> is a <tt>list</tt> because it will return\n<em>all</em> occurrences of the argument, be it a <tt>list</tt> of tokens or a\nsingle <tt>string</tt> (word):</p>\n<pre><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"n\">match</span><span class=\"o\">.</span><span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">original_text</span><span class=\"p\">,</span> <span class=\"s2\">\"I\"</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]:</span> <span class=\"p\">[(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'I'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">37</span><span class=\"p\">,</span> <span class=\"mi\">38</span><span class=\"p\">,</span> <span class=\"s1\">'I'</span><span class=\"p\">)]</span>\n</pre>\n<p>When passing in a single <tt>string</tt>, <tt>match()</tt> is expecting that\n<tt>string</tt> to be a single word or token. Thus:</p>\n<pre><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"n\">match</span><span class=\"o\">.</span><span class=\"n\">match</span><span class=\"p\">(</span><span class=\"s2\">\"****because,the****\"</span><span class=\"p\">,</span> <span class=\"s2\">\"because , the\"</span><span class=\"p\">)</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">7</span><span class=\"p\">]:</span> <span class=\"p\">[]</span>\n</pre>\n<p>Try passing in <tt>\"because , <span class=\"pre\">the\".split('</span> ')</tt> instead, or better yet,\nthe output from a proper tokenizer.</p>\n<p>For convenience, a function called <tt>match_lines()</tt> is provided:</p>\n<pre><span class=\"n\">In</span> <span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]:</span> <span class=\"n\">match</span><span class=\"o\">.</span><span class=\"n\">match_lines</span><span class=\"p\">(</span><span class=\"n\">original_text</span><span class=\"p\">,</span> <span class=\"p\">[</span>\n   <span class=\"o\">...</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'-LRB-'</span><span class=\"p\">,</span> <span class=\"s1\">'and'</span><span class=\"p\">,</span> <span class=\"s1\">'do'</span><span class=\"p\">,</span> <span class=\"s1\">'weird'</span><span class=\"p\">,</span> <span class=\"s1\">'stuff'</span><span class=\"p\">,</span> <span class=\"s1\">'with'</span><span class=\"p\">,</span> <span class=\"s1\">'punctuation'</span><span class=\"p\">,</span> <span class=\"s1\">'-RRB-'</span><span class=\"p\">],</span>\n   <span class=\"o\">...</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'I'</span><span class=\"p\">,</span> <span class=\"s1\">'am'</span><span class=\"p\">,</span> <span class=\"s1\">'writing'</span><span class=\"p\">,</span> <span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'letter'</span><span class=\"p\">,</span> <span class=\"s1\">'!'</span><span class=\"p\">],</span>\n   <span class=\"o\">...</span><span class=\"p\">:</span> <span class=\"s2\">\"I\"</span>\n   <span class=\"o\">...</span><span class=\"p\">:</span> <span class=\"p\">])</span>\n<span class=\"n\">Out</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">]:</span>\n<span class=\"p\">[(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"s1\">'I'</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">25</span><span class=\"p\">,</span> <span class=\"s1\">'I   am writing a letter !'</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"mi\">37</span><span class=\"p\">,</span> <span class=\"mi\">38</span><span class=\"p\">,</span> <span class=\"s1\">'I'</span><span class=\"p\">),</span>\n <span class=\"p\">(</span><span class=\"mi\">60</span><span class=\"p\">,</span> <span class=\"mi\">97</span><span class=\"p\">,</span> <span class=\"s1\">'(and do weird stuff with punctuation)'</span><span class=\"p\">)]</span>\n</pre>\n<p>The values returned will always be sorted by their offsets.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p><tt>pip install match</tt>, or for Mac OS X and 64-bit Linux:</p>\n<pre>$ conda install -c dmnapolitano match\n</pre>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<ul>\n<li>Python &gt;= 3.4</li>\n<li><a href=\"http://www.nltk.org\" rel=\"nofollow\">nltk</a></li>\n<li><a href=\"https://pypi.python.org/pypi/regex\" rel=\"nofollow\">regex</a></li>\n</ul>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p><a href=\"match\" rel=\"nofollow\">Here!</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 6366212, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "629a697dab4ee59b0a4fda3f73eec268", "sha256": "63384f638e15070d57f1cbefabac7b08a4bab0184f166f31a7df0693d6e0a072"}, "downloads": -1, "filename": "match-0.2.tar.gz", "has_sig": false, "md5_digest": "629a697dab4ee59b0a4fda3f73eec268", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5784, "upload_time": "2014-11-23T17:13:51", "upload_time_iso_8601": "2014-11-23T17:13:51.647074Z", "url": "https://files.pythonhosted.org/packages/78/57/c8ff77083b1cd22fb26a3939789cdbc973086952cddb601ae247eec23a77/match-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "44d267c2e2e2a05a073224812fc1ca16", "sha256": "7e326974e16226daa8cdcec83168dd9e443e2d3844de472ebd0b750bd37e991e"}, "downloads": -1, "filename": "match-0.2.1.tar.gz", "has_sig": false, "md5_digest": "44d267c2e2e2a05a073224812fc1ca16", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5826, "upload_time": "2015-05-20T14:42:15", "upload_time_iso_8601": "2015-05-20T14:42:15.591106Z", "url": "https://files.pythonhosted.org/packages/90/9e/eaa7c8814a3ff7f95c84b385cf888ed14768a5745729933c85782627940a/match-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "cc66e80944ea8c3b0df8ae3f0be293c3", "sha256": "52f61683fb76343a6e2a61fc402cad50ba056a9ca1fd6a0792a19d4b339cfc44"}, "downloads": -1, "filename": "match-0.2.2.tar.gz", "has_sig": false, "md5_digest": "cc66e80944ea8c3b0df8ae3f0be293c3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5914, "upload_time": "2015-10-15T20:47:22", "upload_time_iso_8601": "2015-10-15T20:47:22.946651Z", "url": "https://files.pythonhosted.org/packages/56/a2/7bacc7bdcffabff610c50862aeb33921a25a00f912003f29e9d0a71bb5ba/match-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "f33325207ec4725b3c048346334b1c73", "sha256": "d4d4c773091cfda63706fab4d9466464a6e6a241c20b2376ab2ea0bedb596964"}, "downloads": -1, "filename": "match-0.3.0.tar.gz", "has_sig": false, "md5_digest": "f33325207ec4725b3c048346334b1c73", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4950, "upload_time": "2019-12-27T17:37:03", "upload_time_iso_8601": "2019-12-27T17:37:03.866082Z", "url": "https://files.pythonhosted.org/packages/b1/18/3e158b8694e9589e1587815175e5c2a0e78eb86b9462f702d797a93d7f7e/match-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f33325207ec4725b3c048346334b1c73", "sha256": "d4d4c773091cfda63706fab4d9466464a6e6a241c20b2376ab2ea0bedb596964"}, "downloads": -1, "filename": "match-0.3.0.tar.gz", "has_sig": false, "md5_digest": "f33325207ec4725b3c048346334b1c73", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4950, "upload_time": "2019-12-27T17:37:03", "upload_time_iso_8601": "2019-12-27T17:37:03.866082Z", "url": "https://files.pythonhosted.org/packages/b1/18/3e158b8694e9589e1587815175e5c2a0e78eb86b9462f702d797a93d7f7e/match-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:57:25 2020"}