{"info": {"author": "Paul Michel", "author_email": "", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Text Processing"], "description": "<img align=\"left\" height=\"64\" src=\"teapot.gif\" alt=\"teapot\"/>\n\n# TEAPOT\n\nTEAPOT (**T**ool for **E**valuating **A**dversarial **P**erturbations **O**n **T**ext) is a toolkit to evaluate the effectiveness of adversarial perturbations on NLP systems by taking into account the preservation of meaning in the source.\n\nAdversarial perturbations (perturbations to the input of a model that elicit large changes in the output), have been shown to be an effective way of assessing the robustness of machine models.\nHowever, these perturbations only indicate weaknesses in the model if they do not change the input so significantly that it legitimately result in changes in the expected output. While this is easy to control when the input is real-valued (images for example), the situation is more problematic on discrete data such as natural language.\n\nTEAPOT is an implementation of the evaluation framework described in the NAACL 2019 paper [On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models](https://arxiv.org/abs/1903.06620), wherein an adversarial attack is evaluated using two quantities:\n\n- `s_src(x, x')`: a measure of the semantic similarity between the original input `x` and its adversarial perturbation `x'`.\n- `d_tgt(y(x),y(x'),y*)`: a measure of how much the output similarity `s_tgt` (w.r.t. the reference `y*`) decreases when the model is ran on the adversarial input (giving output `y(x')`) instead of the original input (giving `y(x)`). Specifically `d_tgt(y(x),y(x'),y*)` is defined as `0` if `s_tgt(y,y*) < s_tgt(y',y*)` and `(s_tgt(y,y*) - s_tgt(y',y*)) / s_tgt(y,y*)` otherwise.\n\nAn attack is declared **successful** on `x,y` when `s_src(x,x') + d_tgt(y(x),y(x'),y*) > 1`, in other words, *an adversarial attack changing `x` to `x'` is successful if it destroys the target more than it destroys the source*.\n\nWith TEAPOT, you can compute `s_src`, `d_tgt` and the success rate of an attack easily using proxy metrics for the source and target similarity (`chrF` by default).\n\n\n\n## Getting started\n\n### Installation and Requirements\n\nTEAPOT works with python>=3.6. The only required non-standard dependency for teapot is [sacrebleu](https://github.com/mjpost/sacreBLEU) (a neat tool for computing BLEU and chrF on detokenized text). You can install with `python setup.py install` from the root of the repo, or simply `pip install teapot-nlp` from anywhere you want.\n\n### Basic Usage (sequence-to-sequence)\n\nGiven the original input `examples/MT/src.fr`, adversarial input `examples/MT/adv.charswap.fr`, reference output `examples/MT/ref.en`, original output (output of the model on the original input) `examples/MT/base.en` and adversarial output (output of the model on the adversarial input) `examples/MT/adv.charswap.en`, running:\n\n```bash\nteapot \\\n  --src examples/MT/src.fr \\\n  --adv-src examples/MT/adv.charswap.fr \\\n  --out examples/MT/base.en \\\n  --adv-out examples/MT/adv.charswap.en \\\n  --ref examples/MT/ref.en\n```\n\nwill output:\n\n```\nSource side preservation (ChrF):\nMean:   86.908\nStd:    11.622\n5%-95%: 64.109-97.683\n--------------------------------------------------------------------------------\nTarget side degradation (ChrF):\nMean:   21.085\nStd:    22.106\n5%-95%: 0.000-67.162\n--------------------------------------------------------------------------------\nSuccess percentage: 65.20 %\n```\n\nAlternatively you can specify only `--src` and `--adv-src` (for source side evaluation) *or* only `--out`,`--adv-out` and `--ref` (for target side evaluation).\n\nYou can learn more about the command line options by running `teapot -h`. Notably you can specify which score to use with `--s-src` and `--s-tgt` (refer to the command line help for the list of scores implemented in your version).\n\n### Basic Usage (other tasks)\n\nWhile the default settings are geared towards evaluating attacks on sequence-to-sequence models, teapot can be used to evaluate attacks on otjer types of NLP models. For example, for a text classification model we might use the zero-one loss as `s_tgt` (`1` if the output label is the same as the reference, `0` otherwise). Here is an example with an attack on a sentiment classification model trained on [SST](https://nlp.stanford.edu/sentiment/):\n\n```bash\nteapot \\\n  --src examples/sentiment/src.txt \\\n  --adv-src examples/sentiment/adv_src.txt \\\n  --out examples/sentiment/out.txt \\\n  --adv-out examples/sentiment/adv_out.txt \\\n  --ref examples/sentiment/ref.txt \\\n  --s-tgt zero_one \\\n  --success-threshold 1.8\n```\n\nNotice that we specified `--success-threshold 1.8`, which means that an attack will be considered successful only when `s_src(x,x') + d_tgt(y(x),y(x'),y*) > 1.8`. While using `1` as a threshold makes sense when `s_src` and `s_tgt` are the same, when `s_tgt` is the zero-one loss this is a poor choice, as any attack that flips the label will be successful regardless of `s_src`. By upping the threshold to `1.8` we enforce that `s_src` (here chrF) should be at least `0.8` for an attack to be successful.\n\n## Advanced usage\n\n### Custom scorers\n\nTEAPOT comes with predefined scores to compute the source and target side similarity. However, in some cases you might want to define you own score. Fortunately this can be done in a few steps if you are familiar with python:\n\n1. Write your own `teapot.Scorer` subclass in a python source file (there are examples in [examples/custom_scorers.py]()). This is the hard part.\n2. Call teapot with the arguments `--custom-scores-source path/to/your/scorer.py` and `--score [score_key]` where `[score_key]` is the shorthand you have defined for your scorer with `teapot.register_scorer` (again, see the examples in [examples/custom_scorers.py]() for a walkthrough)\n3. If your scorer works fine, and it doesn't rely on heavy dependencies, consider contributing it to TEAPOT by\n    1. Adding the class to [teapot/scorers.py]()\n    2. Adding a simple unit test to [tests/test_scorers.py]()\n\nHere is an example where `s_tgt` is the `f1` score defined in [examples/custom_scorers.py]():\n\n```bash\nteapot \\\n  --src examples/MT/src.fr \\\n  --adv-src examples/MT/adv.charswap.fr \\\n  --out examples/MT/base.en \\\n  --adv-out examples/MT/adv.charswap.en \\\n  --ref examples/MT/ref.en \\\n  --custom-scores-source examples/custom_scorers.py \\\n  --s-tgt f1\n```\n\nOr when `s_src` is the `constant` score (with auxiliary argument `--value`)\n\n```bash\nteapot \\\n  --src examples/MT/src.fr \\\n  --adv-src examples/MT/adv.charswap.fr \\\n  --out examples/MT/base.en \\\n  --adv-out examples/MT/adv.charswap.en \\\n  --ref examples/MT/ref.en \\\n  --custom-scores-source examples/custom_scorers.py \\\n  --s-src constant \\\n  --value 0.3\n```\n\n\n### METEOR\n\nYou can use the [METEOR](http://www.cs.cmu.edu/~alavie/METEOR/) metric by specifying `--{s-src,s-tgt} meteor`, however this will require you to have java installed and METEOR somewhere on your machine and specify the path to the `.jar` with `--meteor-jar`. This is only tested for METEOR-1.5 on linux.\n\nYou can get METEOR by downloading it from the [website](http://www.cs.cmu.edu/~alavie/METEOR/) or in the command line:\n\n```bash\nwget http://www.cs.cmu.edu/\\\\\\~alavie/METEOR/download/meteor-1.5.tar.gz\n# This will put the jar at ./meteor-1.5/meteor-1.5.jar\ntar xvzf meteor-1.5.tar.gz\n```\n\nTEAPOT will run the jar from python. You can specify the java command to run the jar with `--java-command` (default `java -Xmx2G -jar`)\n\n### Programmatic Usage\n\nHere is an example of how to use TEAPOT in your own code:\n\n```python\nimport teapot\n# Instantiate the scorer of your choice\nchrf_scorer = teapot.ChrF()\nbleu_scorer = teapot.BLEU()\nmeteor_scorer = teapot.METEOR(\"path/to/meteor.jar\", java_command=\"java -Xmx2G -jar\")\n# Compute s_src for example\n# This will return a list of chrf scores\ns_src = chrf_scorer.score(adv_inputs, original_inputs)\n# Compute d_tgt\n# This will return a list of relative difference in scores (clamped to positive values)\nd_tgt = chrf_scorer.rd_score(adv_outputs, original_outputs, reference_outputs)\n```\n\n## Reference-less evaluation\n\nIn the case where no target reference `y*` is available, one can treat as one the output `y(x)=y*`.\nWe can then use:\n\n- `s_src(x, x')`: a measure of the semantic similarity between the original input `x` and its adversarial perturbation `x'`.\n- `s_tgt(y(x), y(x'))`: a measure of the semantic similarity between the respective outputs.\n\nSetting `y* := y(x)` (we are interested in how well the model deviates from its own predictions), the original criterion for success:\n```s_src(x,x') + d_tgt(y(x),y(x'),y*) > 1```\nbecomes\n```s_src(x,x') + 1 - s_tgt(y(x),y(x')) > 1```\nwhich is equivalent to\n```s_src(x,x') / s_tgt(y(x),y(x')) > 1.```\nThe intuition here is slightly different: now, a *successful* attack has caused the system to magnify the source-side adversarial noise.\n\nSimply run the same commands without providing a reference file, for reference-less evaluation.\nFor example:\n\n```\nteapot --src examples/MT/src.fr \\\n      --adv-src examples/MT/adv.charswap.fr \\\n      --out examples/MT/base.en \\\n      --adv-out examples/MT/adv.charswap.en\n```\nwill print\n```\nNo reference file provided. We will use the reference-less criterion.\nSource side preservation (ChrF):\nMean: 86.908\nStd:  11.622\n5%-95%: 64.109-97.683\n--------------------------------------------------------------------------------\nTarget side preservation (ChrF):\nMean: 62.733\nStd:  21.529\n5%-95%: 16.650-90.555\n--------------------------------------------------------------------------------\nSuccess percentage: 97.60 %\n```\n\n## License\n\nThe code is released under the [MIT License](LICENSE). Credits to [@eseniko](https://giphy.com/eseniko) for the image.\n\n\n## Citing\n\nIf you use this software in your own research, consider citing the following paper:\n\n```\n@InProceedings{michel2019onevaluation,\n  author    = {Michel, Paul  and  Neubig, Graham and Li, Xian and Pino, Juan Miguel},\n  title     = {On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models},\n  year      = {2019},\n  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)}\n}\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/pmichel31415/teapot-nlp", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "teapot-nlp", "package_url": "https://pypi.org/project/teapot-nlp/", "platform": "", "project_url": "https://pypi.org/project/teapot-nlp/", "project_urls": {"Homepage": "https://github.com/pmichel31415/teapot-nlp"}, "release_url": "https://pypi.org/project/teapot-nlp/0.2.1/", "requires_dist": null, "requires_python": "", "summary": "Source and target side evaluation of adversarial attacks on NLP models", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img align=\"left\" alt=\"teapot\" height=\"64\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fabb2a2cf0e98c023d02db32fe082e671f7246c2/746561706f742e676966\">\n<h1>TEAPOT</h1>\n<p>TEAPOT (<strong>T</strong>ool for <strong>E</strong>valuating <strong>A</strong>dversarial <strong>P</strong>erturbations <strong>O</strong>n <strong>T</strong>ext) is a toolkit to evaluate the effectiveness of adversarial perturbations on NLP systems by taking into account the preservation of meaning in the source.</p>\n<p>Adversarial perturbations (perturbations to the input of a model that elicit large changes in the output), have been shown to be an effective way of assessing the robustness of machine models.\nHowever, these perturbations only indicate weaknesses in the model if they do not change the input so significantly that it legitimately result in changes in the expected output. While this is easy to control when the input is real-valued (images for example), the situation is more problematic on discrete data such as natural language.</p>\n<p>TEAPOT is an implementation of the evaluation framework described in the NAACL 2019 paper <a href=\"https://arxiv.org/abs/1903.06620\" rel=\"nofollow\">On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models</a>, wherein an adversarial attack is evaluated using two quantities:</p>\n<ul>\n<li><code>s_src(x, x')</code>: a measure of the semantic similarity between the original input <code>x</code> and its adversarial perturbation <code>x'</code>.</li>\n<li><code>d_tgt(y(x),y(x'),y*)</code>: a measure of how much the output similarity <code>s_tgt</code> (w.r.t. the reference <code>y*</code>) decreases when the model is ran on the adversarial input (giving output <code>y(x')</code>) instead of the original input (giving <code>y(x)</code>). Specifically <code>d_tgt(y(x),y(x'),y*)</code> is defined as <code>0</code> if <code>s_tgt(y,y*) &lt; s_tgt(y',y*)</code> and <code>(s_tgt(y,y*) - s_tgt(y',y*)) / s_tgt(y,y*)</code> otherwise.</li>\n</ul>\n<p>An attack is declared <strong>successful</strong> on <code>x,y</code> when <code>s_src(x,x') + d_tgt(y(x),y(x'),y*) &gt; 1</code>, in other words, <em>an adversarial attack changing <code>x</code> to <code>x'</code> is successful if it destroys the target more than it destroys the source</em>.</p>\n<p>With TEAPOT, you can compute <code>s_src</code>, <code>d_tgt</code> and the success rate of an attack easily using proxy metrics for the source and target similarity (<code>chrF</code> by default).</p>\n<h2>Getting started</h2>\n<h3>Installation and Requirements</h3>\n<p>TEAPOT works with python&gt;=3.6. The only required non-standard dependency for teapot is <a href=\"https://github.com/mjpost/sacreBLEU\" rel=\"nofollow\">sacrebleu</a> (a neat tool for computing BLEU and chrF on detokenized text). You can install with <code>python setup.py install</code> from the root of the repo, or simply <code>pip install teapot-nlp</code> from anywhere you want.</p>\n<h3>Basic Usage (sequence-to-sequence)</h3>\n<p>Given the original input <code>examples/MT/src.fr</code>, adversarial input <code>examples/MT/adv.charswap.fr</code>, reference output <code>examples/MT/ref.en</code>, original output (output of the model on the original input) <code>examples/MT/base.en</code> and adversarial output (output of the model on the adversarial input) <code>examples/MT/adv.charswap.en</code>, running:</p>\n<pre>teapot <span class=\"se\">\\</span>\n  --src examples/MT/src.fr <span class=\"se\">\\</span>\n  --adv-src examples/MT/adv.charswap.fr <span class=\"se\">\\</span>\n  --out examples/MT/base.en <span class=\"se\">\\</span>\n  --adv-out examples/MT/adv.charswap.en <span class=\"se\">\\</span>\n  --ref examples/MT/ref.en\n</pre>\n<p>will output:</p>\n<pre><code>Source side preservation (ChrF):\nMean:   86.908\nStd:    11.622\n5%-95%: 64.109-97.683\n--------------------------------------------------------------------------------\nTarget side degradation (ChrF):\nMean:   21.085\nStd:    22.106\n5%-95%: 0.000-67.162\n--------------------------------------------------------------------------------\nSuccess percentage: 65.20 %\n</code></pre>\n<p>Alternatively you can specify only <code>--src</code> and <code>--adv-src</code> (for source side evaluation) <em>or</em> only <code>--out</code>,<code>--adv-out</code> and <code>--ref</code> (for target side evaluation).</p>\n<p>You can learn more about the command line options by running <code>teapot -h</code>. Notably you can specify which score to use with <code>--s-src</code> and <code>--s-tgt</code> (refer to the command line help for the list of scores implemented in your version).</p>\n<h3>Basic Usage (other tasks)</h3>\n<p>While the default settings are geared towards evaluating attacks on sequence-to-sequence models, teapot can be used to evaluate attacks on otjer types of NLP models. For example, for a text classification model we might use the zero-one loss as <code>s_tgt</code> (<code>1</code> if the output label is the same as the reference, <code>0</code> otherwise). Here is an example with an attack on a sentiment classification model trained on <a href=\"https://nlp.stanford.edu/sentiment/\" rel=\"nofollow\">SST</a>:</p>\n<pre>teapot <span class=\"se\">\\</span>\n  --src examples/sentiment/src.txt <span class=\"se\">\\</span>\n  --adv-src examples/sentiment/adv_src.txt <span class=\"se\">\\</span>\n  --out examples/sentiment/out.txt <span class=\"se\">\\</span>\n  --adv-out examples/sentiment/adv_out.txt <span class=\"se\">\\</span>\n  --ref examples/sentiment/ref.txt <span class=\"se\">\\</span>\n  --s-tgt zero_one <span class=\"se\">\\</span>\n  --success-threshold <span class=\"m\">1</span>.8\n</pre>\n<p>Notice that we specified <code>--success-threshold 1.8</code>, which means that an attack will be considered successful only when <code>s_src(x,x') + d_tgt(y(x),y(x'),y*) &gt; 1.8</code>. While using <code>1</code> as a threshold makes sense when <code>s_src</code> and <code>s_tgt</code> are the same, when <code>s_tgt</code> is the zero-one loss this is a poor choice, as any attack that flips the label will be successful regardless of <code>s_src</code>. By upping the threshold to <code>1.8</code> we enforce that <code>s_src</code> (here chrF) should be at least <code>0.8</code> for an attack to be successful.</p>\n<h2>Advanced usage</h2>\n<h3>Custom scorers</h3>\n<p>TEAPOT comes with predefined scores to compute the source and target side similarity. However, in some cases you might want to define you own score. Fortunately this can be done in a few steps if you are familiar with python:</p>\n<ol>\n<li>Write your own <code>teapot.Scorer</code> subclass in a python source file (there are examples in <a href=\"\" rel=\"nofollow\">examples/custom_scorers.py</a>). This is the hard part.</li>\n<li>Call teapot with the arguments <code>--custom-scores-source path/to/your/scorer.py</code> and <code>--score [score_key]</code> where <code>[score_key]</code> is the shorthand you have defined for your scorer with <code>teapot.register_scorer</code> (again, see the examples in <a href=\"\" rel=\"nofollow\">examples/custom_scorers.py</a> for a walkthrough)</li>\n<li>If your scorer works fine, and it doesn't rely on heavy dependencies, consider contributing it to TEAPOT by\n<ol>\n<li>Adding the class to <a href=\"\" rel=\"nofollow\">teapot/scorers.py</a></li>\n<li>Adding a simple unit test to <a href=\"\" rel=\"nofollow\">tests/test_scorers.py</a></li>\n</ol>\n</li>\n</ol>\n<p>Here is an example where <code>s_tgt</code> is the <code>f1</code> score defined in <a href=\"\" rel=\"nofollow\">examples/custom_scorers.py</a>:</p>\n<pre>teapot <span class=\"se\">\\</span>\n  --src examples/MT/src.fr <span class=\"se\">\\</span>\n  --adv-src examples/MT/adv.charswap.fr <span class=\"se\">\\</span>\n  --out examples/MT/base.en <span class=\"se\">\\</span>\n  --adv-out examples/MT/adv.charswap.en <span class=\"se\">\\</span>\n  --ref examples/MT/ref.en <span class=\"se\">\\</span>\n  --custom-scores-source examples/custom_scorers.py <span class=\"se\">\\</span>\n  --s-tgt f1\n</pre>\n<p>Or when <code>s_src</code> is the <code>constant</code> score (with auxiliary argument <code>--value</code>)</p>\n<pre>teapot <span class=\"se\">\\</span>\n  --src examples/MT/src.fr <span class=\"se\">\\</span>\n  --adv-src examples/MT/adv.charswap.fr <span class=\"se\">\\</span>\n  --out examples/MT/base.en <span class=\"se\">\\</span>\n  --adv-out examples/MT/adv.charswap.en <span class=\"se\">\\</span>\n  --ref examples/MT/ref.en <span class=\"se\">\\</span>\n  --custom-scores-source examples/custom_scorers.py <span class=\"se\">\\</span>\n  --s-src constant <span class=\"se\">\\</span>\n  --value <span class=\"m\">0</span>.3\n</pre>\n<h3>METEOR</h3>\n<p>You can use the <a href=\"http://www.cs.cmu.edu/%7Ealavie/METEOR/\" rel=\"nofollow\">METEOR</a> metric by specifying <code>--{s-src,s-tgt} meteor</code>, however this will require you to have java installed and METEOR somewhere on your machine and specify the path to the <code>.jar</code> with <code>--meteor-jar</code>. This is only tested for METEOR-1.5 on linux.</p>\n<p>You can get METEOR by downloading it from the <a href=\"http://www.cs.cmu.edu/%7Ealavie/METEOR/\" rel=\"nofollow\">website</a> or in the command line:</p>\n<pre>wget http://www.cs.cmu.edu/<span class=\"se\">\\\\\\~</span>alavie/METEOR/download/meteor-1.5.tar.gz\n<span class=\"c1\"># This will put the jar at ./meteor-1.5/meteor-1.5.jar</span>\ntar xvzf meteor-1.5.tar.gz\n</pre>\n<p>TEAPOT will run the jar from python. You can specify the java command to run the jar with <code>--java-command</code> (default <code>java -Xmx2G -jar</code>)</p>\n<h3>Programmatic Usage</h3>\n<p>Here is an example of how to use TEAPOT in your own code:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">teapot</span>\n<span class=\"c1\"># Instantiate the scorer of your choice</span>\n<span class=\"n\">chrf_scorer</span> <span class=\"o\">=</span> <span class=\"n\">teapot</span><span class=\"o\">.</span><span class=\"n\">ChrF</span><span class=\"p\">()</span>\n<span class=\"n\">bleu_scorer</span> <span class=\"o\">=</span> <span class=\"n\">teapot</span><span class=\"o\">.</span><span class=\"n\">BLEU</span><span class=\"p\">()</span>\n<span class=\"n\">meteor_scorer</span> <span class=\"o\">=</span> <span class=\"n\">teapot</span><span class=\"o\">.</span><span class=\"n\">METEOR</span><span class=\"p\">(</span><span class=\"s2\">\"path/to/meteor.jar\"</span><span class=\"p\">,</span> <span class=\"n\">java_command</span><span class=\"o\">=</span><span class=\"s2\">\"java -Xmx2G -jar\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># Compute s_src for example</span>\n<span class=\"c1\"># This will return a list of chrf scores</span>\n<span class=\"n\">s_src</span> <span class=\"o\">=</span> <span class=\"n\">chrf_scorer</span><span class=\"o\">.</span><span class=\"n\">score</span><span class=\"p\">(</span><span class=\"n\">adv_inputs</span><span class=\"p\">,</span> <span class=\"n\">original_inputs</span><span class=\"p\">)</span>\n<span class=\"c1\"># Compute d_tgt</span>\n<span class=\"c1\"># This will return a list of relative difference in scores (clamped to positive values)</span>\n<span class=\"n\">d_tgt</span> <span class=\"o\">=</span> <span class=\"n\">chrf_scorer</span><span class=\"o\">.</span><span class=\"n\">rd_score</span><span class=\"p\">(</span><span class=\"n\">adv_outputs</span><span class=\"p\">,</span> <span class=\"n\">original_outputs</span><span class=\"p\">,</span> <span class=\"n\">reference_outputs</span><span class=\"p\">)</span>\n</pre>\n<h2>Reference-less evaluation</h2>\n<p>In the case where no target reference <code>y*</code> is available, one can treat as one the output <code>y(x)=y*</code>.\nWe can then use:</p>\n<ul>\n<li><code>s_src(x, x')</code>: a measure of the semantic similarity between the original input <code>x</code> and its adversarial perturbation <code>x'</code>.</li>\n<li><code>s_tgt(y(x), y(x'))</code>: a measure of the semantic similarity between the respective outputs.</li>\n</ul>\n<p>Setting <code>y* := y(x)</code> (we are interested in how well the model deviates from its own predictions), the original criterion for success:\n<code>s_src(x,x') + d_tgt(y(x),y(x'),y*) &gt; 1</code>\nbecomes\n<code>s_src(x,x') + 1 - s_tgt(y(x),y(x')) &gt; 1</code>\nwhich is equivalent to\n<code>s_src(x,x') / s_tgt(y(x),y(x')) &gt; 1.</code>\nThe intuition here is slightly different: now, a <em>successful</em> attack has caused the system to magnify the source-side adversarial noise.</p>\n<p>Simply run the same commands without providing a reference file, for reference-less evaluation.\nFor example:</p>\n<pre><code>teapot --src examples/MT/src.fr \\\n      --adv-src examples/MT/adv.charswap.fr \\\n      --out examples/MT/base.en \\\n      --adv-out examples/MT/adv.charswap.en\n</code></pre>\n<p>will print</p>\n<pre><code>No reference file provided. We will use the reference-less criterion.\nSource side preservation (ChrF):\nMean: 86.908\nStd:  11.622\n5%-95%: 64.109-97.683\n--------------------------------------------------------------------------------\nTarget side preservation (ChrF):\nMean: 62.733\nStd:  21.529\n5%-95%: 16.650-90.555\n--------------------------------------------------------------------------------\nSuccess percentage: 97.60 %\n</code></pre>\n<h2>License</h2>\n<p>The code is released under the <a href=\"LICENSE\" rel=\"nofollow\">MIT License</a>. Credits to <a href=\"https://giphy.com/eseniko\" rel=\"nofollow\">@eseniko</a> for the image.</p>\n<h2>Citing</h2>\n<p>If you use this software in your own research, consider citing the following paper:</p>\n<pre><code>@InProceedings{michel2019onevaluation,\n  author    = {Michel, Paul  and  Neubig, Graham and Li, Xian and Pino, Juan Miguel},\n  title     = {On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models},\n  year      = {2019},\n  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)}\n}\n</code></pre>\n\n          </div>"}, "last_serial": 5097604, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "c584b97ef9cb53059d9c9cb6e6e8bfd5", "sha256": "ff0388d8b274517db20f338930b6f0f9d94a697ec2f4768f21a1382631dc0ec6"}, "downloads": -1, "filename": "teapot-nlp-0.1.tar.gz", "has_sig": false, "md5_digest": "c584b97ef9cb53059d9c9cb6e6e8bfd5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12275, "upload_time": "2019-03-13T22:30:47", "upload_time_iso_8601": "2019-03-13T22:30:47.642825Z", "url": "https://files.pythonhosted.org/packages/d7/2a/d990a38de3dd88b4148db22e945d88163d4936013389b796f8a0edfa63c3/teapot-nlp-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "ae9acc6868a689462d1c1ed2bda3ce37", "sha256": "f80b34d14359208ee37868925ba2f00728932e4d6ae933283c22b2560cf28340"}, "downloads": -1, "filename": "teapot-nlp-0.2.tar.gz", "has_sig": false, "md5_digest": "ae9acc6868a689462d1c1ed2bda3ce37", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12449, "upload_time": "2019-03-18T22:08:19", "upload_time_iso_8601": "2019-03-18T22:08:19.206543Z", "url": "https://files.pythonhosted.org/packages/4c/db/3010a267871293ed7115ff253ba33ed7c1a239a3dd4eb2b1cc4bb14c0b01/teapot-nlp-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "f8cfeffdc6df6cb15fe4fbbf2f8c7d04", "sha256": "4453c5a007dd4cd6cfa54ef49d34d6a23d1b7969e5be514961f6a3bc68a82714"}, "downloads": -1, "filename": "teapot-nlp-0.2.1.tar.gz", "has_sig": false, "md5_digest": "f8cfeffdc6df6cb15fe4fbbf2f8c7d04", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13599, "upload_time": "2019-04-04T14:20:41", "upload_time_iso_8601": "2019-04-04T14:20:41.495023Z", "url": "https://files.pythonhosted.org/packages/d5/e0/49677535a248972396964013aa5eccc4e5855c39e683e18cded36e2dbd73/teapot-nlp-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f8cfeffdc6df6cb15fe4fbbf2f8c7d04", "sha256": "4453c5a007dd4cd6cfa54ef49d34d6a23d1b7969e5be514961f6a3bc68a82714"}, "downloads": -1, "filename": "teapot-nlp-0.2.1.tar.gz", "has_sig": false, "md5_digest": "f8cfeffdc6df6cb15fe4fbbf2f8c7d04", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13599, "upload_time": "2019-04-04T14:20:41", "upload_time_iso_8601": "2019-04-04T14:20:41.495023Z", "url": "https://files.pythonhosted.org/packages/d5/e0/49677535a248972396964013aa5eccc4e5855c39e683e18cded36e2dbd73/teapot-nlp-0.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:57:05 2020"}