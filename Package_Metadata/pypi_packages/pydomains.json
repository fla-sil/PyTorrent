{"info": {"author": "Suriyan Laohaprapanon, Gaurav Sood", "author_email": "suriyant@gmail.com, gsood07@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Utilities"], "description": "PyDomains: Classifying the Content of Domains\n------------------------------------------------\n\n.. image:: https://travis-ci.org/themains/pydomains.svg?branch=master\n    :target: https://travis-ci.org/themains/pydomains\n.. image:: https://ci.appveyor.com/api/projects/status/qfvbu8h99ymtw2ub?svg=true\n    :target: https://ci.appveyor.com/project/themains/pydomains\n.. image:: https://img.shields.io/pypi/v/pydomains.svg\n    :target: https://pypi.python.org/pypi/pydomains\n.. image:: https://readthedocs.org/projects/pydomains/badge/?version=latest\n    :target: http://pydomains.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n.. image:: https://pepy.tech/badge/pydomains\n    :target: https://pepy.tech/project/pydomains\n\nThe package provides two broad ways of learning about the kind of content hosted \non a domain. First, it provides convenient access to curated lists of domain content\nlike the Shallalist, DMOZ, PhishTank, and such. Second, it exposes models built on top of \nthese large labeled datasets; the models estimate the relationship between sequence of \ncharacters in the domain name and the kind of content hosted by the domain. \n\nQuick Start\n------------\n\n::\n\n    import pandas as pd\n    from pydomains import *\n\n    # Get help\n    help(dmoz_cat)\n\n    # Load data\n    df = pd.read_csv('./pydomains/examples/input-header.csv')\n\n    #  df\n    #       label                                url\n    #   0   test1                        topshop.com\n    #   1   test2                   beyondrelief.com\n\n    # Get the Content Category from DMOZ, phishtank\n    df_dmoz  = dmoz_cat(df, domain_names = 'url')\n    df_phish = phish_cat(df, domain_names = 'url')\n\n    # Predicted category from shallalist, toulouse\n    df_shalla   = pred_shalla(df, domain_names = 'url')\n    df_toulouse = pred_toulouse(df, domain_names = 'url')\n\n\nInstallation\n--------------\n\nInstallation is as easy as typing in:\n\n::\n\n    pip install pydomains\n\nAPI\n~~~~~~~~~~\n\n1. **dmoz\\_cat**, **shalla\\_cat**, and **phish\\_cat**: When the domain\n   is in the DMOZ, Shallalist, and Phishtank data, the functions give the\n   category of the domain according to the respective list. (Phishtank just\n   gives whether or not the domain has been implicated in phishing.) Otherwise,\n   the function returns an empty string.\n\n   -  **Arguments:**\n\n      -  ``df``: pandas dataframe. No default.\n      -  ``domain_names``: column with the domain names/URLs. \n         Default is ``domain_names``\n      -  ``year``. Specify the year from which you want to use the data.\n         Currently only DMOZ data from 2016, and Shallalist and Phishtank\n         data from 2017 is available.\n      -  ``latest``. Boolean. Default is ``False``. If ``True``, the\n         function checks if a local file exists and if it exists, if the\n         local file is the latest. If it isn't, it downloads the latest\n         file from the GitHub link and overwrites the local file.\n\n   -  **Functionality:**\n\n      -  converts domain name to lower case, strips ``http://``.\n      -  Looks for ``dmoz_YYYY.csv``, ``shalla_YYYY.csv``, or\n         ``phish_YYYY.csv`` respectively in the local folder. If it\n         doesn't find it, it downloads the latest DMOZ, Shallalist, or\n         Phishtank file from\n         `pydomains/data/dmoz_YYYY.csv.bz2 <pydomains/data/dmoz_YYYY.csv.bz2>`__,\n         `pydomains/data/shalla_YYYY.csv.bz2 <pydomains/data/shalla_YYYY.csv.bz2>`__,\n         or\n         `pydomains/data/phish_YYYY.csv.bz2 <pydomains/data/phish_YYYY.csv.bz2>`__\\ respectively.\n      -  If the ``latest`` flag is planted, it checks if the\n         local file is older than the remote file. If it is,\n         it overwrites the local file with the newer remote file.\n\n   -  **Output:**\n\n      -  Appends the category to the CSV. By default it creates a column\n         (dmoz\\_year\\_cat or shalla\\_year\\_cat or phish\\_year\\_cat).\n      -  If no match is found, it returns nothing.\n      -  DMOZ sometimes has multiple categories per domain. The\n         categories are appended together with a semi-colon.\n\n   -  **Examples:**\n\n      ::\n\n          import pandas as pd\n\n          df = pd.DataFrame([{'domain_names': 'http://www.google.com'}])\n\n          dmoz_cat(df)\n          shalla_cat(df)\n          phish_cat(df)\n\n2. **pred\\_shalla**: We use data from Shallalist to train a \n   `LSTM model <pydomains/models/shalla_pred_2017_others.ipynb>`__. The function\n   uses the trained model to predict the category of the domain based on \n   the domain name.\n\n   -  **Arguments:**\n\n      -  ``df``: pandas dataframe. No default.\n      -  ``domain_names``: column with the domain names/URLs. \n         Default is ``domain_names``\n      -  ``year``. Year of the model. Default is 2017. Currently only\n         a model based on data from 2017 is available.\n      -  ``latest``. Boolean. Default is ``False``. If ``True``, the\n         function checks if a local model file exists and if it exists, is it\n         older than what is on the website. If it isn't, it downloads the latest\n         file from the GitHub link and overwrites the local file.\n\n   -  **Functionality:**\n\n      -  converts domain name to lower case, strips ``http://``.\n      -  Uses the model to predict the probability of content being from\n         various categories.\n\n   -  **Output**\n\n      -  Appends a column carrying the label of the category with the \n         highest probability (``pred_shalla_year_lab``) and a series of \n         columns with probabilities for each category \n         (``pred_shalla_year_prob_catname``).\n\n   -  **Examples:**\n\n      ::\n\n          pred_shalla(df)\n\n3. **pred\\_toulouse**: We use data from http://dsi.ut-capitole.fr/blacklists/ to \n   train a `LSTM model <pydomains/models/toulouse_pred_2017_others.ipynb>`__ that predicts\n   the category of content hosted by the domain. The function uses the trained \n   model to predict the category of the domain based on the domain name.\n\n   -  **Arguments:**\n\n      -  ``df``: pandas dataframe. No default.\n      -  ``domain_names``: column with the domain names/URLs. \n         Default is ``domain_names``\n      -  ``year``. Year of the model. Default is 2017. Currently only\n         a model based on data from 2017 is available.\n      -  ``latest``. Boolean. Default is ``False``. If ``True``, the\n         function checks if a local model file exists and if it exists, is it\n         older than what is on the website. If it isn't, it downloads the latest\n         file from the GitHub link and overwrites the local file.\n\n   -  **Functionality:**\n\n      -  converts domain name to lower case, strips ``http://``.\n      -  Uses the model to predict the probability of it being a domain\n         implicated in distributing malware.\n\n   -  **Output:**\n\n      -  Appends a column carrying the label of the category with the \n         highest probability (``pred_toulouse_year_lab``) and a series of \n         columns with probabilities for each category \n         (``pred_toulouse_year_prob_catname``).\n\n   - **Examples:**\n\n      ::\n\n          pred_malware(df)\n\n4. **pred\\_phish**: Given the importance, we devote special care to try\n   to predict domains involved in phishing well. To do that, we use data\n   from `PhishTank <https://www.phishtank.com/>`__ and combine it with\n   data from http://s3.amazonaws.com/alexa-static/top-1m.csv.zip, and train a `LSTM\n   model <pydomains/models/phish_pred_2017.ipynb>`__. The function gives the \n   predicted probability based on the LSTM model.\n\n   -  **Arguments:**\n\n      -  ``df``: pandas dataframe. No default.\n      -  ``domain_names``: column with the domain names/URLs. \n         Default is ``domain_names``\n      -  ``year``. Year of the model. Default is 2017. Currently only\n         a model based on data from 2017 is available.\n      -  ``latest``. Boolean. Default is ``False``. If ``True``, the\n         function checks if a local model file exists and if it exists, is it\n         older than what is on the website. If it isn't, it downloads the latest\n         file from the GitHub link and overwrites the local file.\n\n   -  **Functionality:**\n\n      -  converts domain name to lower case, strips ``http://``.\n      -  Uses the model to predict the probability of it being a domain\n         implicated in phishing.\n\n   -  **Output:**\n\n      -  Appends column `pred_phish_year_lab` which contains the most probable\n         label, and a column indicating the probability that the domain \n         is involved in distributing malware (`pred_phish_year_prob`).\n\n   -  **Examples:**\n\n      ::\n\n          pred_phish(df)\n\n5. **pred\\_malware**: Once again, given the importance of flagging domains\n   that carry malware, we again devote extra care to try to predict domains \n   involved in distributing malware well. We combine data on malware \n   domains http://mirror1.malwaredomains.com/ with data from \n   http://s3.amazonaws.com/alexa-static/top-1m.csv.zip, and train a \n   `LSTM model <pydomains/models/malware_pred_2017.ipynb>`__. The function gives \n   the predicted probability based on the LSTM model.\n\n   -  **Arguments:**\n\n      -  ``df``: pandas dataframe. No default.\n      -  ``domain_names``: column with the domain names/URLs. \n         Default is ``domain_names``\n      -  ``year``. Year of the model. Default is 2017. Currently only\n         a model based on data from 2017 is available.\n      -  ``latest``. Boolean. Default is ``False``. If ``True``, the\n         function checks if a local model file exists and if it exists, is it\n         older than what is on the website. If it isn't, it downloads the latest\n         file from the GitHub link and overwrites the local file.\n\n   -  **Functionality:**\n\n      -  converts domain name to lower case, strips ``http://``.\n      -  Uses the model to predict the probability of it being a domain\n         implicated in distributing malware.\n\n   -  **Output:**\n\n      -  Appends column `pred_malware_year_lab` and a column indicating the \n         probability that the domain is involved in distributing malware \n         (`pred_malware_year_prob`).\n\n   - **Examples:**\n\n      ::\n\n          pred_malware(df)\n\nUsing pydomains\n~~~~~~~~~~~~~~~~\n\n::\n\n    >>> import pandas as pd\n    >>> from pydomains import *\n    Using TensorFlow backend.\n\n    >>> # Get help of the function\n    ... help(dmoz_cat)\n    Help on function dmoz_cat in module pydomains.dmoz_cat:\n\n    dmoz_cat(df, domain_names='domain_names', year=2016, latest=False)\n        Appends DMOZ domain categories to the DataFrame.\n\n        The function extracts the domain name along with the subdomain\n        from the specified column and appends the category (dmoz_cat)\n        to the DataFrame. If DMOZ file is not available locally or\n        latest is set to True, it downloads the file. The function\n        looks for category of the domain name in the DMOZ file\n        for each domain. When no match is found, it returns an\n        empty string.\n\n        Args:\n            df (:obj:`DataFrame`): Pandas DataFrame. No default value.\n            domain_names (str): Column name of the domain in DataFrame.\n                Default in `domain_names`.\n            year (int): DMOZ data year. Only 2016 data is available.\n                Default is 2016.\n            latest (Boolean): Whether or not to download latest\n                data available from GitHub. Default is False.\n\n        Returns:\n            DataFrame: Pandas DataFrame with two additional columns:\n                'dmoz_year_domain' and 'dmoz_year_cat'\n\n\n    >>> # Load an example input with columns header\n    ... df = pd.read_csv('./pydomains/examples/input-header.csv')\n\n    >>> df\n        label                                url\n    0   test1                        topshop.com\n    1   test2                   beyondrelief.com\n    2   test3                golf-tours.com/test\n    3   test4                    thegayhotel.com\n    4   test5  https://zonasequravlabcp.com/bcp/\n    5   test6                http://privatix.xyz\n    6   test7              adultfriendfinder.com\n    7   test8            giftregistrylocator.com\n    8   test9                 bangbrosonline.com\n    9  test10                scotland-info.co.uk\n\n    >>> # Get the Content Category from DMOZ\n    ... df = dmoz_cat(df, domain_names='url')\n    Loading DMOZ data file...\n\n    >>> df\n        label                                url         dmoz_2016_domain  \\\n    0   test1                        topshop.com              topshop.com\n    1   test2                   beyondrelief.com         beyondrelief.com\n    2   test3                golf-tours.com/test           golf-tours.com\n    3   test4                    thegayhotel.com          thegayhotel.com\n    4   test5  https://zonasequravlabcp.com/bcp/     zonasequravlabcp.com\n    5   test6                http://privatix.xyz             privatix.xyz\n    6   test7              adultfriendfinder.com    adultfriendfinder.com\n    7   test8            giftregistrylocator.com  giftregistrylocator.com\n    8   test9                 bangbrosonline.com       bangbrosonline.com\n    9  test10                scotland-info.co.uk      scotland-info.co.uk\n\n                                        dmoz_2016_cat\n    0  Top/Regional/Europe/United_Kingdom/Business_an...\n    1                                                NaN\n    2                                                NaN\n    3                                                NaN\n    4                                                NaN\n    5                                                NaN\n    6                                                NaN\n    7                                                NaN\n    8                                                NaN\n    9  Top/Regional/Europe/United_Kingdom/Scotland/Tr...\n    >>> # Predict Content Category Using the Toulouse Model\n    ... df = pred_toulouse(df, domain_names='url')\n    Loading Toulouse model, vocab and names data file...\n\n    >>> df\n        label                                url         dmoz_2016_domain  \\\n    0   test1                        topshop.com              topshop.com\n    1   test2                   beyondrelief.com         beyondrelief.com\n    2   test3                golf-tours.com/test           golf-tours.com\n    3   test4                    thegayhotel.com          thegayhotel.com\n    4   test5  https://zonasequravlabcp.com/bcp/     zonasequravlabcp.com\n    5   test6                http://privatix.xyz             privatix.xyz\n    6   test7              adultfriendfinder.com    adultfriendfinder.com\n    7   test8            giftregistrylocator.com  giftregistrylocator.com\n    8   test9                 bangbrosonline.com       bangbrosonline.com\n    9  test10                scotland-info.co.uk      scotland-info.co.uk\n\n                                        dmoz_2016_cat  \\\n    0  Top/Regional/Europe/United_Kingdom/Business_an...\n    1                                                NaN\n    2                                                NaN\n    3                                                NaN\n    4                                                NaN\n    5                                                NaN\n    6                                                NaN\n    7                                                NaN\n    8                                                NaN\n    9  Top/Regional/Europe/United_Kingdom/Scotland/Tr...\n\n    pred_toulouse_2017_domain pred_toulouse_2017_lab  \\\n    0               topshop.com               shopping\n    1          beyondrelief.com                  adult\n    2            golf-tours.com               shopping\n    3           thegayhotel.com                  adult\n    4      zonasequravlabcp.com               phishing\n    5              privatix.xyz                  adult\n    6     adultfriendfinder.com                  adult\n    7   giftregistrylocator.com               shopping\n    8        bangbrosonline.com                  adult\n    9       scotland-info.co.uk               shopping\n\n    pred_toulouse_2017_prob_adult  pred_toulouse_2017_prob_audio-video  \\\n    0                       0.133953                             0.003793\n    1                       0.521590                             0.016359\n    2                       0.186083                             0.008208\n    3                       0.971451                             0.001080\n    4                       0.065503                             0.001063\n    5                       0.986328                             0.002241\n    6                       0.939441                             0.000211\n    7                       0.014645                             0.000570\n    8                       0.945490                             0.004017\n    9                       0.256270                             0.003745\n\n    pred_toulouse_2017_prob_bank  pred_toulouse_2017_prob_gambling  \\\n    0                  1.161209e-04                      2.911613e-04\n    1                  3.912278e-03                      6.484169e-03\n    2                  1.783388e-03                      8.022175e-04\n    3                  8.920387e-05                      6.256429e-05\n    4                  6.226773e-04                      1.073759e-04\n    5                  6.823016e-07                      1.969112e-06\n    6                  1.742063e-07                      6.485808e-08\n    7                  3.973934e-04                      1.019526e-05\n    8                  9.122109e-05                      1.142884e-04\n    9                  3.962536e-04                      4.977396e-04\n\n    pred_toulouse_2017_prob_games  pred_toulouse_2017_prob_malware  \\\n    0                       0.002073                         0.003976\n    1                       0.022408                         0.018371\n    2                       0.013352                         0.006392\n    3                       0.000713                         0.000934\n    4                       0.012431                         0.077391\n    5                       0.001021                         0.004949\n    6                       0.000044                         0.000059\n    7                       0.004112                         0.016339\n    8                       0.002216                         0.000422\n    9                       0.014452                         0.006615\n\n    pred_toulouse_2017_prob_others  pred_toulouse_2017_prob_phishing  \\\n    0                        0.014862                          0.112132\n    1                        0.046011                          0.172208\n    2                        0.021287                          0.060633\n    3                        0.005018                          0.017201\n    4                        0.031691                          0.416989\n    5                        0.003069                          0.002094\n    6                        0.001674                          0.058497\n    7                        0.015631                          0.131174\n    8                        0.017964                          0.012574\n    9                        0.057622                          0.111698\n\n    pred_toulouse_2017_prob_press  pred_toulouse_2017_prob_publicite  \\\n    0                   8.404775e-04                           0.000761\n    1                   2.525988e-02                           0.002821\n    2                   1.853482e-02                           0.000990\n    3                   2.208834e-04                           0.000135\n    4                   2.796387e-03                           0.000284\n    5                   4.559151e-06                           0.000252\n    6                   1.133891e-07                           0.000007\n    7                   1.115335e-02                           0.000436\n    8                   5.098383e-04                           0.000785\n    9                   7.331154e-04                           0.000168\n\n    pred_toulouse_2017_prob_shopping\n    0                          0.727203\n    1                          0.164577\n    2                          0.681934\n    3                          0.003094\n    4                          0.391121\n    5                          0.000038\n    6                          0.000066\n    7                          0.805531\n    8                          0.015817\n    9                          0.547802\n\nModels\n~~~~~~~~~~~~~~~~\n\nFor more information about the models, including the decisions we made around\ncurtailing the number of categories, see `here <./pydomains/models/>`__\n\nUnderlying Data\n~~~~~~~~~~~~~~~~\n\nWe use data from DMOZ, Shallalist, PhishTank, and a prominent Blacklist aggregator.\nFor more details about how the underlying data, see `here <./pydomains/data/>`__\n\nValidation\n~~~~~~~~~~~~~~~~~\n\nWe compare content categories according to the `TrustedSource API <https://www.trustedsource.org>`__ \nwith content category from Shallalist and the Shallalist model for all the unique domains in the \ncomScore 2004 data: \n\n1. `comScore 2004 Trusted API results <http://dx.doi.org/10.7910/DVN/BPS1OK>`__\n\n2. `comScore 2004 categories from pydomains <./pydomains/app/comscore-2004.ipynb>`__\n\n3. `comparison between TrustedSource and Shallalist and shallalist model <./pydomains/app/comscore-2004-eval.ipynb>`__\n\nLearning Browsing Behavior Using pydomains\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo make it easier to learn browsing behavior of people, we obtained the type of content\nhosted by a domain using all the functions in pydomains for all the unique domains in all \nthe comScore data from 2002 to 2016 (there are some missing years). We have posted the data\n`here <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DXSNFA>`__  \n\nNotes and Caveats\n~~~~~~~~~~~~~~~~~~~\n\n-  The DMOZ categorization system at tier 1 is bad. The category names\n   are vague. They have a lot of subcategories that could easily belong\n   to other tier 1 categories. That means a) it would likely be hard to\n   classify well at tier 1 and b) not very valuable. So we choose not to\n   predict tier 1 DMOZ categories.\n\n-  The association between patterns in domain names and the kind of\n   content they host may change over time. It may change as new domains\n   come online and as older domains are repurposed. All this likely\n   happens slowly. But, to be careful, we add a ``year`` variable in our\n   functions. Each list and each model is for a particular year.\n\n-  Imputing the kind of content hosted by a domain may suggest to some\n   that domains carry only one kind of content. Many domains don't. And\n   even when they do, the quality varies immensely. (See more `here \n   <https://themains.github.io/index.html#domain_classifier>`__.) There is \n   much less heterogeneity at the URL level. And we plan to look into \n   predicting at URL level. See `TODO <TODO>`__ for our plans.\n\n-  There are a lot of categories where we do not expect domain names to\n   have any systematic patterns. Rather than make noisy predictions\n   using just the domain names (the data that our current set of \n   classifiers use), we plan to tackle this prediction task with \n   some additional data. See `TODO <TODO>`__ for our plans.\n\nDocumentation\n-------------\n\nFor more information, please see `project documentation <http://pydomains.readthedocs.io/en/latest/>`__.\n\nAuthors\n~~~~~~~~\n\nSuriyan Laohaprapanon and Gaurav Sood\n\nContributor Code of Conduct\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe project welcomes contributions from everyone! In fact, it depends on\nit. To maintain this welcoming atmosphere, and to collaborate in a fun\nand productive way, we expect contributors to the project to abide by\nthe `Contributor Code of\nConduct <http://contributor-covenant.org/version/1/0/0/>`__\n\nLicense\n~~~~~~~\n\nThe package is released under the `MIT\nLicense <https://opensource.org/licenses/MIT>`__.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/themains/pydomains", "keywords": "domain dmoz shalla phishing malware lstm", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pydomains", "package_url": "https://pypi.org/project/pydomains/", "platform": "", "project_url": "https://pypi.org/project/pydomains/", "project_urls": {"Homepage": "https://github.com/themains/pydomains"}, "release_url": "https://pypi.org/project/pydomains/0.2.0/", "requires_dist": ["pandas", "tldextract", "requests", "tqdm", "h5py", "keras", "tensorflow", "check-manifest ; extra == 'dev'", "coverage ; extra == 'test'"], "requires_python": "", "summary": "Classifying the Content of Domains", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"pydomains-classifying-the-content-of-domains\">\n<h2>PyDomains: Classifying the Content of Domains</h2>\n<a href=\"https://travis-ci.org/themains/pydomains\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/themains/pydomains.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6b15bf66c2453258477d2fec711c3d6180165ae2/68747470733a2f2f7472617669732d63692e6f72672f7468656d61696e732f7079646f6d61696e732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://ci.appveyor.com/project/themains/pydomains\" rel=\"nofollow\"><img alt=\"https://ci.appveyor.com/api/projects/status/qfvbu8h99ymtw2ub?svg=true\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bce08691d618cdfda6e1824ce0f5cf16eb72a9b3/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f716676627538683939796d74773275623f7376673d74727565\"></a>\n<a href=\"https://pypi.python.org/pypi/pydomains\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/pydomains.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88a6160289da733ef2036d486f397156e9ffdf4e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7079646f6d61696e732e737667\"></a>\n<a href=\"http://pydomains.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ddd706c4aa8071a2bee735fc59a797bf44c08db5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7079646f6d61696e732f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://pepy.tech/project/pydomains\" rel=\"nofollow\"><img alt=\"https://pepy.tech/badge/pydomains\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/56692e84f695984aff76bd9ef5205a595c5708a7/68747470733a2f2f706570792e746563682f62616467652f7079646f6d61696e73\"></a>\n<p>The package provides two broad ways of learning about the kind of content hosted\non a domain. First, it provides convenient access to curated lists of domain content\nlike the Shallalist, DMOZ, PhishTank, and such. Second, it exposes models built on top of\nthese large labeled datasets; the models estimate the relationship between sequence of\ncharacters in the domain name and the kind of content hosted by the domain.</p>\n</div>\n<div id=\"quick-start\">\n<h2>Quick Start</h2>\n<pre>import pandas as pd\nfrom pydomains import *\n\n# Get help\nhelp(dmoz_cat)\n\n# Load data\ndf = pd.read_csv('./pydomains/examples/input-header.csv')\n\n#  df\n#       label                                url\n#   0   test1                        topshop.com\n#   1   test2                   beyondrelief.com\n\n# Get the Content Category from DMOZ, phishtank\ndf_dmoz  = dmoz_cat(df, domain_names = 'url')\ndf_phish = phish_cat(df, domain_names = 'url')\n\n# Predicted category from shallalist, toulouse\ndf_shalla   = pred_shalla(df, domain_names = 'url')\ndf_toulouse = pred_toulouse(df, domain_names = 'url')\n</pre>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Installation is as easy as typing in:</p>\n<pre>pip install pydomains\n</pre>\n<div id=\"api\">\n<h3>API</h3>\n<ol>\n<li><p><strong>dmoz_cat</strong>, <strong>shalla_cat</strong>, and <strong>phish_cat</strong>: When the domain\nis in the DMOZ, Shallalist, and Phishtank data, the functions give the\ncategory of the domain according to the respective list. (Phishtank just\ngives whether or not the domain has been implicated in phishing.) Otherwise,\nthe function returns an empty string.</p>\n<ul>\n<li><p><strong>Arguments:</strong></p>\n<ul>\n<li><tt>df</tt>: pandas dataframe. No default.</li>\n<li><tt>domain_names</tt>: column with the domain names/URLs.\nDefault is <tt>domain_names</tt></li>\n<li><tt>year</tt>. Specify the year from which you want to use the data.\nCurrently only DMOZ data from 2016, and Shallalist and Phishtank\ndata from 2017 is available.</li>\n<li><tt>latest</tt>. Boolean. Default is <tt>False</tt>. If <tt>True</tt>, the\nfunction checks if a local file exists and if it exists, if the\nlocal file is the latest. If it isn\u2019t, it downloads the latest\nfile from the GitHub link and overwrites the local file.</li>\n</ul>\n</li>\n<li><p><strong>Functionality:</strong></p>\n<ul>\n<li>converts domain name to lower case, strips <tt><span class=\"pre\">http://</span></tt>.</li>\n<li>Looks for <tt>dmoz_YYYY.csv</tt>, <tt>shalla_YYYY.csv</tt>, or\n<tt>phish_YYYY.csv</tt> respectively in the local folder. If it\ndoesn\u2019t find it, it downloads the latest DMOZ, Shallalist, or\nPhishtank file from\n<a href=\"pydomains/data/dmoz_YYYY.csv.bz2\" rel=\"nofollow\">pydomains/data/dmoz_YYYY.csv.bz2</a>,\n<a href=\"pydomains/data/shalla_YYYY.csv.bz2\" rel=\"nofollow\">pydomains/data/shalla_YYYY.csv.bz2</a>,\nor\n<a href=\"pydomains/data/phish_YYYY.csv.bz2\" rel=\"nofollow\">pydomains/data/phish_YYYY.csv.bz2</a>respectively.</li>\n<li>If the <tt>latest</tt> flag is planted, it checks if the\nlocal file is older than the remote file. If it is,\nit overwrites the local file with the newer remote file.</li>\n</ul>\n</li>\n<li><p><strong>Output:</strong></p>\n<ul>\n<li>Appends the category to the CSV. By default it creates a column\n(dmoz_year_cat or shalla_year_cat or phish_year_cat).</li>\n<li>If no match is found, it returns nothing.</li>\n<li>DMOZ sometimes has multiple categories per domain. The\ncategories are appended together with a semi-colon.</li>\n</ul>\n</li>\n<li><p><strong>Examples:</strong></p>\n<pre>import pandas as pd\n\ndf = pd.DataFrame([{'domain_names': 'http://www.google.com'}])\n\ndmoz_cat(df)\nshalla_cat(df)\nphish_cat(df)\n</pre>\n</li>\n</ul>\n</li>\n<li><p><strong>pred_shalla</strong>: We use data from Shallalist to train a\n<a href=\"pydomains/models/shalla_pred_2017_others.ipynb\" rel=\"nofollow\">LSTM model</a>. The function\nuses the trained model to predict the category of the domain based on\nthe domain name.</p>\n<ul>\n<li><p><strong>Arguments:</strong></p>\n<ul>\n<li><tt>df</tt>: pandas dataframe. No default.</li>\n<li><tt>domain_names</tt>: column with the domain names/URLs.\nDefault is <tt>domain_names</tt></li>\n<li><tt>year</tt>. Year of the model. Default is 2017. Currently only\na model based on data from 2017 is available.</li>\n<li><tt>latest</tt>. Boolean. Default is <tt>False</tt>. If <tt>True</tt>, the\nfunction checks if a local model file exists and if it exists, is it\nolder than what is on the website. If it isn\u2019t, it downloads the latest\nfile from the GitHub link and overwrites the local file.</li>\n</ul>\n</li>\n<li><p><strong>Functionality:</strong></p>\n<ul>\n<li>converts domain name to lower case, strips <tt><span class=\"pre\">http://</span></tt>.</li>\n<li>Uses the model to predict the probability of content being from\nvarious categories.</li>\n</ul>\n</li>\n<li><p><strong>Output</strong></p>\n<ul>\n<li>Appends a column carrying the label of the category with the\nhighest probability (<tt>pred_shalla_year_lab</tt>) and a series of\ncolumns with probabilities for each category\n(<tt>pred_shalla_year_prob_catname</tt>).</li>\n</ul>\n</li>\n<li><p><strong>Examples:</strong></p>\n<pre>pred_shalla(df)\n</pre>\n</li>\n</ul>\n</li>\n<li><p><strong>pred_toulouse</strong>: We use data from <a href=\"http://dsi.ut-capitole.fr/blacklists/\" rel=\"nofollow\">http://dsi.ut-capitole.fr/blacklists/</a> to\ntrain a <a href=\"pydomains/models/toulouse_pred_2017_others.ipynb\" rel=\"nofollow\">LSTM model</a> that predicts\nthe category of content hosted by the domain. The function uses the trained\nmodel to predict the category of the domain based on the domain name.</p>\n<ul>\n<li><p><strong>Arguments:</strong></p>\n<ul>\n<li><tt>df</tt>: pandas dataframe. No default.</li>\n<li><tt>domain_names</tt>: column with the domain names/URLs.\nDefault is <tt>domain_names</tt></li>\n<li><tt>year</tt>. Year of the model. Default is 2017. Currently only\na model based on data from 2017 is available.</li>\n<li><tt>latest</tt>. Boolean. Default is <tt>False</tt>. If <tt>True</tt>, the\nfunction checks if a local model file exists and if it exists, is it\nolder than what is on the website. If it isn\u2019t, it downloads the latest\nfile from the GitHub link and overwrites the local file.</li>\n</ul>\n</li>\n<li><p><strong>Functionality:</strong></p>\n<ul>\n<li>converts domain name to lower case, strips <tt><span class=\"pre\">http://</span></tt>.</li>\n<li>Uses the model to predict the probability of it being a domain\nimplicated in distributing malware.</li>\n</ul>\n</li>\n<li><p><strong>Output:</strong></p>\n<ul>\n<li>Appends a column carrying the label of the category with the\nhighest probability (<tt>pred_toulouse_year_lab</tt>) and a series of\ncolumns with probabilities for each category\n(<tt>pred_toulouse_year_prob_catname</tt>).</li>\n</ul>\n</li>\n<li><p><strong>Examples:</strong></p>\n<blockquote>\n<pre>pred_malware(df)\n</pre>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><p><strong>pred_phish</strong>: Given the importance, we devote special care to try\nto predict domains involved in phishing well. To do that, we use data\nfrom <a href=\"https://www.phishtank.com/\" rel=\"nofollow\">PhishTank</a> and combine it with\ndata from <a href=\"http://s3.amazonaws.com/alexa-static/top-1m.csv.zip\" rel=\"nofollow\">http://s3.amazonaws.com/alexa-static/top-1m.csv.zip</a>, and train a <a href=\"pydomains/models/phish_pred_2017.ipynb\" rel=\"nofollow\">LSTM\nmodel</a>. The function gives the\npredicted probability based on the LSTM model.</p>\n<ul>\n<li><p><strong>Arguments:</strong></p>\n<ul>\n<li><tt>df</tt>: pandas dataframe. No default.</li>\n<li><tt>domain_names</tt>: column with the domain names/URLs.\nDefault is <tt>domain_names</tt></li>\n<li><tt>year</tt>. Year of the model. Default is 2017. Currently only\na model based on data from 2017 is available.</li>\n<li><tt>latest</tt>. Boolean. Default is <tt>False</tt>. If <tt>True</tt>, the\nfunction checks if a local model file exists and if it exists, is it\nolder than what is on the website. If it isn\u2019t, it downloads the latest\nfile from the GitHub link and overwrites the local file.</li>\n</ul>\n</li>\n<li><p><strong>Functionality:</strong></p>\n<ul>\n<li>converts domain name to lower case, strips <tt><span class=\"pre\">http://</span></tt>.</li>\n<li>Uses the model to predict the probability of it being a domain\nimplicated in phishing.</li>\n</ul>\n</li>\n<li><p><strong>Output:</strong></p>\n<ul>\n<li>Appends column <cite>pred_phish_year_lab</cite> which contains the most probable\nlabel, and a column indicating the probability that the domain\nis involved in distributing malware (<cite>pred_phish_year_prob</cite>).</li>\n</ul>\n</li>\n<li><p><strong>Examples:</strong></p>\n<pre>pred_phish(df)\n</pre>\n</li>\n</ul>\n</li>\n<li><p><strong>pred_malware</strong>: Once again, given the importance of flagging domains\nthat carry malware, we again devote extra care to try to predict domains\ninvolved in distributing malware well. We combine data on malware\ndomains <a href=\"http://mirror1.malwaredomains.com/\" rel=\"nofollow\">http://mirror1.malwaredomains.com/</a> with data from\n<a href=\"http://s3.amazonaws.com/alexa-static/top-1m.csv.zip\" rel=\"nofollow\">http://s3.amazonaws.com/alexa-static/top-1m.csv.zip</a>, and train a\n<a href=\"pydomains/models/malware_pred_2017.ipynb\" rel=\"nofollow\">LSTM model</a>. The function gives\nthe predicted probability based on the LSTM model.</p>\n<ul>\n<li><p><strong>Arguments:</strong></p>\n<ul>\n<li><tt>df</tt>: pandas dataframe. No default.</li>\n<li><tt>domain_names</tt>: column with the domain names/URLs.\nDefault is <tt>domain_names</tt></li>\n<li><tt>year</tt>. Year of the model. Default is 2017. Currently only\na model based on data from 2017 is available.</li>\n<li><tt>latest</tt>. Boolean. Default is <tt>False</tt>. If <tt>True</tt>, the\nfunction checks if a local model file exists and if it exists, is it\nolder than what is on the website. If it isn\u2019t, it downloads the latest\nfile from the GitHub link and overwrites the local file.</li>\n</ul>\n</li>\n<li><p><strong>Functionality:</strong></p>\n<ul>\n<li>converts domain name to lower case, strips <tt><span class=\"pre\">http://</span></tt>.</li>\n<li>Uses the model to predict the probability of it being a domain\nimplicated in distributing malware.</li>\n</ul>\n</li>\n<li><p><strong>Output:</strong></p>\n<ul>\n<li>Appends column <cite>pred_malware_year_lab</cite> and a column indicating the\nprobability that the domain is involved in distributing malware\n(<cite>pred_malware_year_prob</cite>).</li>\n</ul>\n</li>\n<li><p><strong>Examples:</strong></p>\n<blockquote>\n<pre>pred_malware(df)\n</pre>\n</blockquote>\n</li>\n</ul>\n</li>\n</ol>\n</div>\n<div id=\"using-pydomains\">\n<h3>Using pydomains</h3>\n<pre>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from pydomains import *\nUsing TensorFlow backend.\n\n&gt;&gt;&gt; # Get help of the function\n... help(dmoz_cat)\nHelp on function dmoz_cat in module pydomains.dmoz_cat:\n\ndmoz_cat(df, domain_names='domain_names', year=2016, latest=False)\n    Appends DMOZ domain categories to the DataFrame.\n\n    The function extracts the domain name along with the subdomain\n    from the specified column and appends the category (dmoz_cat)\n    to the DataFrame. If DMOZ file is not available locally or\n    latest is set to True, it downloads the file. The function\n    looks for category of the domain name in the DMOZ file\n    for each domain. When no match is found, it returns an\n    empty string.\n\n    Args:\n        df (:obj:`DataFrame`): Pandas DataFrame. No default value.\n        domain_names (str): Column name of the domain in DataFrame.\n            Default in `domain_names`.\n        year (int): DMOZ data year. Only 2016 data is available.\n            Default is 2016.\n        latest (Boolean): Whether or not to download latest\n            data available from GitHub. Default is False.\n\n    Returns:\n        DataFrame: Pandas DataFrame with two additional columns:\n            'dmoz_year_domain' and 'dmoz_year_cat'\n\n\n&gt;&gt;&gt; # Load an example input with columns header\n... df = pd.read_csv('./pydomains/examples/input-header.csv')\n\n&gt;&gt;&gt; df\n    label                                url\n0   test1                        topshop.com\n1   test2                   beyondrelief.com\n2   test3                golf-tours.com/test\n3   test4                    thegayhotel.com\n4   test5  https://zonasequravlabcp.com/bcp/\n5   test6                http://privatix.xyz\n6   test7              adultfriendfinder.com\n7   test8            giftregistrylocator.com\n8   test9                 bangbrosonline.com\n9  test10                scotland-info.co.uk\n\n&gt;&gt;&gt; # Get the Content Category from DMOZ\n... df = dmoz_cat(df, domain_names='url')\nLoading DMOZ data file...\n\n&gt;&gt;&gt; df\n    label                                url         dmoz_2016_domain  \\\n0   test1                        topshop.com              topshop.com\n1   test2                   beyondrelief.com         beyondrelief.com\n2   test3                golf-tours.com/test           golf-tours.com\n3   test4                    thegayhotel.com          thegayhotel.com\n4   test5  https://zonasequravlabcp.com/bcp/     zonasequravlabcp.com\n5   test6                http://privatix.xyz             privatix.xyz\n6   test7              adultfriendfinder.com    adultfriendfinder.com\n7   test8            giftregistrylocator.com  giftregistrylocator.com\n8   test9                 bangbrosonline.com       bangbrosonline.com\n9  test10                scotland-info.co.uk      scotland-info.co.uk\n\n                                    dmoz_2016_cat\n0  Top/Regional/Europe/United_Kingdom/Business_an...\n1                                                NaN\n2                                                NaN\n3                                                NaN\n4                                                NaN\n5                                                NaN\n6                                                NaN\n7                                                NaN\n8                                                NaN\n9  Top/Regional/Europe/United_Kingdom/Scotland/Tr...\n&gt;&gt;&gt; # Predict Content Category Using the Toulouse Model\n... df = pred_toulouse(df, domain_names='url')\nLoading Toulouse model, vocab and names data file...\n\n&gt;&gt;&gt; df\n    label                                url         dmoz_2016_domain  \\\n0   test1                        topshop.com              topshop.com\n1   test2                   beyondrelief.com         beyondrelief.com\n2   test3                golf-tours.com/test           golf-tours.com\n3   test4                    thegayhotel.com          thegayhotel.com\n4   test5  https://zonasequravlabcp.com/bcp/     zonasequravlabcp.com\n5   test6                http://privatix.xyz             privatix.xyz\n6   test7              adultfriendfinder.com    adultfriendfinder.com\n7   test8            giftregistrylocator.com  giftregistrylocator.com\n8   test9                 bangbrosonline.com       bangbrosonline.com\n9  test10                scotland-info.co.uk      scotland-info.co.uk\n\n                                    dmoz_2016_cat  \\\n0  Top/Regional/Europe/United_Kingdom/Business_an...\n1                                                NaN\n2                                                NaN\n3                                                NaN\n4                                                NaN\n5                                                NaN\n6                                                NaN\n7                                                NaN\n8                                                NaN\n9  Top/Regional/Europe/United_Kingdom/Scotland/Tr...\n\npred_toulouse_2017_domain pred_toulouse_2017_lab  \\\n0               topshop.com               shopping\n1          beyondrelief.com                  adult\n2            golf-tours.com               shopping\n3           thegayhotel.com                  adult\n4      zonasequravlabcp.com               phishing\n5              privatix.xyz                  adult\n6     adultfriendfinder.com                  adult\n7   giftregistrylocator.com               shopping\n8        bangbrosonline.com                  adult\n9       scotland-info.co.uk               shopping\n\npred_toulouse_2017_prob_adult  pred_toulouse_2017_prob_audio-video  \\\n0                       0.133953                             0.003793\n1                       0.521590                             0.016359\n2                       0.186083                             0.008208\n3                       0.971451                             0.001080\n4                       0.065503                             0.001063\n5                       0.986328                             0.002241\n6                       0.939441                             0.000211\n7                       0.014645                             0.000570\n8                       0.945490                             0.004017\n9                       0.256270                             0.003745\n\npred_toulouse_2017_prob_bank  pred_toulouse_2017_prob_gambling  \\\n0                  1.161209e-04                      2.911613e-04\n1                  3.912278e-03                      6.484169e-03\n2                  1.783388e-03                      8.022175e-04\n3                  8.920387e-05                      6.256429e-05\n4                  6.226773e-04                      1.073759e-04\n5                  6.823016e-07                      1.969112e-06\n6                  1.742063e-07                      6.485808e-08\n7                  3.973934e-04                      1.019526e-05\n8                  9.122109e-05                      1.142884e-04\n9                  3.962536e-04                      4.977396e-04\n\npred_toulouse_2017_prob_games  pred_toulouse_2017_prob_malware  \\\n0                       0.002073                         0.003976\n1                       0.022408                         0.018371\n2                       0.013352                         0.006392\n3                       0.000713                         0.000934\n4                       0.012431                         0.077391\n5                       0.001021                         0.004949\n6                       0.000044                         0.000059\n7                       0.004112                         0.016339\n8                       0.002216                         0.000422\n9                       0.014452                         0.006615\n\npred_toulouse_2017_prob_others  pred_toulouse_2017_prob_phishing  \\\n0                        0.014862                          0.112132\n1                        0.046011                          0.172208\n2                        0.021287                          0.060633\n3                        0.005018                          0.017201\n4                        0.031691                          0.416989\n5                        0.003069                          0.002094\n6                        0.001674                          0.058497\n7                        0.015631                          0.131174\n8                        0.017964                          0.012574\n9                        0.057622                          0.111698\n\npred_toulouse_2017_prob_press  pred_toulouse_2017_prob_publicite  \\\n0                   8.404775e-04                           0.000761\n1                   2.525988e-02                           0.002821\n2                   1.853482e-02                           0.000990\n3                   2.208834e-04                           0.000135\n4                   2.796387e-03                           0.000284\n5                   4.559151e-06                           0.000252\n6                   1.133891e-07                           0.000007\n7                   1.115335e-02                           0.000436\n8                   5.098383e-04                           0.000785\n9                   7.331154e-04                           0.000168\n\npred_toulouse_2017_prob_shopping\n0                          0.727203\n1                          0.164577\n2                          0.681934\n3                          0.003094\n4                          0.391121\n5                          0.000038\n6                          0.000066\n7                          0.805531\n8                          0.015817\n9                          0.547802\n</pre>\n</div>\n<div id=\"models\">\n<h3>Models</h3>\n<p>For more information about the models, including the decisions we made around\ncurtailing the number of categories, see <a href=\"./pydomains/models/\" rel=\"nofollow\">here</a></p>\n</div>\n<div id=\"underlying-data\">\n<h3>Underlying Data</h3>\n<p>We use data from DMOZ, Shallalist, PhishTank, and a prominent Blacklist aggregator.\nFor more details about how the underlying data, see <a href=\"./pydomains/data/\" rel=\"nofollow\">here</a></p>\n</div>\n<div id=\"validation\">\n<h3>Validation</h3>\n<p>We compare content categories according to the <a href=\"https://www.trustedsource.org\" rel=\"nofollow\">TrustedSource API</a>\nwith content category from Shallalist and the Shallalist model for all the unique domains in the\ncomScore 2004 data:</p>\n<ol>\n<li><a href=\"http://dx.doi.org/10.7910/DVN/BPS1OK\" rel=\"nofollow\">comScore 2004 Trusted API results</a></li>\n<li><a href=\"./pydomains/app/comscore-2004.ipynb\" rel=\"nofollow\">comScore 2004 categories from pydomains</a></li>\n<li><a href=\"./pydomains/app/comscore-2004-eval.ipynb\" rel=\"nofollow\">comparison between TrustedSource and Shallalist and shallalist model</a></li>\n</ol>\n</div>\n<div id=\"learning-browsing-behavior-using-pydomains\">\n<h3>Learning Browsing Behavior Using pydomains</h3>\n<p>To make it easier to learn browsing behavior of people, we obtained the type of content\nhosted by a domain using all the functions in pydomains for all the unique domains in all\nthe comScore data from 2002 to 2016 (there are some missing years). We have posted the data\n<a href=\"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DXSNFA\" rel=\"nofollow\">here</a></p>\n</div>\n<div id=\"notes-and-caveats\">\n<h3>Notes and Caveats</h3>\n<ul>\n<li>The DMOZ categorization system at tier 1 is bad. The category names\nare vague. They have a lot of subcategories that could easily belong\nto other tier 1 categories. That means a) it would likely be hard to\nclassify well at tier 1 and b) not very valuable. So we choose not to\npredict tier 1 DMOZ categories.</li>\n<li>The association between patterns in domain names and the kind of\ncontent they host may change over time. It may change as new domains\ncome online and as older domains are repurposed. All this likely\nhappens slowly. But, to be careful, we add a <tt>year</tt> variable in our\nfunctions. Each list and each model is for a particular year.</li>\n<li>Imputing the kind of content hosted by a domain may suggest to some\nthat domains carry only one kind of content. Many domains don\u2019t. And\neven when they do, the quality varies immensely. (See more <a href=\"https://themains.github.io/index.html#domain_classifier\" rel=\"nofollow\">here</a>.) There is\nmuch less heterogeneity at the URL level. And we plan to look into\npredicting at URL level. See <a href=\"TODO\" rel=\"nofollow\">TODO</a> for our plans.</li>\n<li>There are a lot of categories where we do not expect domain names to\nhave any systematic patterns. Rather than make noisy predictions\nusing just the domain names (the data that our current set of\nclassifiers use), we plan to tackle this prediction task with\nsome additional data. See <a href=\"TODO\" rel=\"nofollow\">TODO</a> for our plans.</li>\n</ul>\n</div>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>For more information, please see <a href=\"http://pydomains.readthedocs.io/en/latest/\" rel=\"nofollow\">project documentation</a>.</p>\n<div id=\"authors\">\n<h3>Authors</h3>\n<p>Suriyan Laohaprapanon and Gaurav Sood</p>\n</div>\n<div id=\"contributor-code-of-conduct\">\n<h3>Contributor Code of Conduct</h3>\n<p>The project welcomes contributions from everyone! In fact, it depends on\nit. To maintain this welcoming atmosphere, and to collaborate in a fun\nand productive way, we expect contributors to the project to abide by\nthe <a href=\"http://contributor-covenant.org/version/1/0/0/\" rel=\"nofollow\">Contributor Code of\nConduct</a></p>\n</div>\n<div id=\"license\">\n<h3>License</h3>\n<p>The package is released under the <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\">MIT\nLicense</a>.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 7178732, "releases": {"0.1.14": [{"comment_text": "", "digests": {"md5": "1f7892f47ba70501f5c651672b3f7763", "sha256": "8aec09be05783f5a80af55147901b48b52629ee4b3a991b50b3df7b4848dbbb2"}, "downloads": -1, "filename": "pydomains-0.1.14.tar.gz", "has_sig": false, "md5_digest": "1f7892f47ba70501f5c651672b3f7763", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22553, "upload_time": "2018-06-21T03:59:09", "upload_time_iso_8601": "2018-06-21T03:59:09.632354Z", "url": "https://files.pythonhosted.org/packages/95/29/253358e98f0db5923b841912223eee654181ce26a82e72d3e04459581f36/pydomains-0.1.14.tar.gz", "yanked": false}], "0.1.15": [{"comment_text": "", "digests": {"md5": "dd753cf8e322d50cb6b43b8101da827b", "sha256": "55ec568b0a2ab5d7b0be3f8ea0b0b02f3ed8ba2cd54e840a84a7f991c6aa7cf4"}, "downloads": -1, "filename": "pydomains-0.1.15.tar.gz", "has_sig": false, "md5_digest": "dd753cf8e322d50cb6b43b8101da827b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22562, "upload_time": "2018-06-23T05:52:15", "upload_time_iso_8601": "2018-06-23T05:52:15.338068Z", "url": "https://files.pythonhosted.org/packages/80/4d/de33cd7435b94bf031b01b29c103c5fae8028cfe2c5b6e443aaba8cc2ea4/pydomains-0.1.15.tar.gz", "yanked": false}], "0.1.16": [{"comment_text": "", "digests": {"md5": "31ca9824b6940722f697a17cf6967867", "sha256": "dd3a6a4c70ff8a00bdfb9142ce8adc4ec7f2b0e36d64cb5bbfea04c80f9c0199"}, "downloads": -1, "filename": "pydomains-0.1.16.tar.gz", "has_sig": false, "md5_digest": "31ca9824b6940722f697a17cf6967867", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22557, "upload_time": "2018-11-07T22:19:49", "upload_time_iso_8601": "2018-11-07T22:19:49.788258Z", "url": "https://files.pythonhosted.org/packages/c6/68/b84f859046ab52b2eb1c91a35804d29338a63acf159bef6485a9a48377cc/pydomains-0.1.16.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "1a362370669cf27bd6c0fc63579fa32b", "sha256": "3fa8ab4e576e1b9861d18350929f8038d1c7636d26df85e515007cac564c4a1b"}, "downloads": -1, "filename": "pydomains-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1a362370669cf27bd6c0fc63579fa32b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22406, "upload_time": "2020-05-06T08:57:03", "upload_time_iso_8601": "2020-05-06T08:57:03.133332Z", "url": "https://files.pythonhosted.org/packages/ad/03/50411babda1b8b7a9936dbbfd7c6e55d5e9e9f81408d3c2bf61680c2aa45/pydomains-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8d2619b875883757997b542508ceb950", "sha256": "44b1220d661d065315a2a106ada6c49836f95ee5d45ecd5f748fc198776aee5c"}, "downloads": -1, "filename": "pydomains-0.2.0.tar.gz", "has_sig": false, "md5_digest": "8d2619b875883757997b542508ceb950", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21742, "upload_time": "2020-05-06T08:57:04", "upload_time_iso_8601": "2020-05-06T08:57:04.264498Z", "url": "https://files.pythonhosted.org/packages/f4/90/6728026463a5e786d60c92dd6fa43bc6b62f6b432ed638c318bb601b42d6/pydomains-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1a362370669cf27bd6c0fc63579fa32b", "sha256": "3fa8ab4e576e1b9861d18350929f8038d1c7636d26df85e515007cac564c4a1b"}, "downloads": -1, "filename": "pydomains-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1a362370669cf27bd6c0fc63579fa32b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22406, "upload_time": "2020-05-06T08:57:03", "upload_time_iso_8601": "2020-05-06T08:57:03.133332Z", "url": "https://files.pythonhosted.org/packages/ad/03/50411babda1b8b7a9936dbbfd7c6e55d5e9e9f81408d3c2bf61680c2aa45/pydomains-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8d2619b875883757997b542508ceb950", "sha256": "44b1220d661d065315a2a106ada6c49836f95ee5d45ecd5f748fc198776aee5c"}, "downloads": -1, "filename": "pydomains-0.2.0.tar.gz", "has_sig": false, "md5_digest": "8d2619b875883757997b542508ceb950", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21742, "upload_time": "2020-05-06T08:57:04", "upload_time_iso_8601": "2020-05-06T08:57:04.264498Z", "url": "https://files.pythonhosted.org/packages/f4/90/6728026463a5e786d60c92dd6fa43bc6b62f6b432ed638c318bb601b42d6/pydomains-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:51 2020"}