{"info": {"author": "Victor Otavio Andrade das Neves", "author_email": "victorneves478@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "License :: OSI Approved :: MIT License"], "description": "snake-on-pygame\n=================\n\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/Neves4/snake-rl/graphs/commit-activity) [![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/) [![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/) [![Ask Me Anything !](https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg)](https://GitHub.com/Neves4/ama)\n\n<p align=\"center\">\n    <img src = \"resources/images/snake_logo.png\"/>\n</p>\n\nSnake game that can be controlled by human input and AI agents (DQN). Who's best? :snake: :robot:\n\nTable of Contents\n=================\n\n* [1. Getting Started (for human players)](#getting_started-human)\n    * [1.1. Prerequisites](#pre-req-human)\n    * [1.2. Installing](#installing-human)\n    * [1.3. Playing](#playing-human)\n* [2. Getting Started (using AI agents)](#getting_started-ai)\n    * [2.1. Available methods to integrate with any agent](#available-method)\n        * [2.1.1. Methods](#methods)\n        * [2.1.2. Example usage](#example-usage)\n    * [2.2. Using colab-rl](#using-colab-rl)\n* [3. Contributing](#contributing)\n* [4. License](#license)\n* [5. Acknowledgments](#acknowledgments)\n\n## 1. Getting Started (for human players) <a name=\"getting-started-human\"></a>\n\nLet's get the game up and running on your computer, with the instructions below.\nYou can play the game and compare to the repos benchmark, which includes AI and\nhumans (you can include yourself by a pull request to the file [scores.json](resources/scores.json)).\n\n### 1.1. Prerequisites <a name=\"pre-req-human\"></a>\n\nTo play the game you need Python 3.4+. If you installed [Anaconda](https://www.anaconda.com/) the only package\nyou need to download is pygame. Before installing it, make sure your Anaconda\ninstallation is up-to-date using the command (conda update conda anaconda)and\nupdating all packages (conda update --all). To install pygame, use:\n\n```\n$ conda install -c cogsci pygame\n\n```\nIt's highly recommended to use Anaconda to manage your Python packages and environments.\nIf you chose not to, make sure you run requirements_human.txt, using:\n\n```\n$ python install setup.py\n```\n\nor\n\n```\n$ python3 install setup.py\n```\n\n### 1.2. Installing <a name=\"installing-human\"></a>\n\nYou can download download the source code or clone the repository to your computer.\n\nTo clone the repository, open bash or command prompt, cd to the chosen directory\nand run the following code:\n\n```\n$ git clone https://github.com/Neves4/SnakeAI.git\n```\n\nTo download the repo, just follow along the gif (click 'Clone or Download' and\nthen 'Download ZIP').\n\n![Download repo](/resources/gifs/download_repo.gif)\n\n### 1.3. Playing <a name=\"playing-human\"></a>\n\nThe GUI allows you to choose between single games and the benchmark mode. It's\nalso possible to choose between difficulty levels.\n\nIf using the repository files, change directory to the root, then to the game folder\nand use:\n\n```\n$ python snake.py [-h]\n```\n\nAn example gameplay for a single player match is shown below.\n\n<p align=\"center\">\n    <img src = \"/resources/gifs/gameplay.gif\"/>\n</p>\n\nIn the benchmark mode, you will play through 10 games and your mean score/steps\nare going to be recorded and you can add to the leaderboards. Pull request\nchanging the benchmark file ([located in here](resources/scores.json)) or open an issue with your score.\n\n## 2. Getting Started (using AI agents) <a name=\"getting-started-ai\"></a>\n\nThis game uses similar usage structure and methods to [OpenAI's gym](https://github.com/openai/gym) and you\ncan easily integrate it with any agent, written in Pytorch, Tensorflow, Theano or Keras.\n\nIt's recommended that you use [colab-rl](https://github.com/Neves4/colab-rl), a repository that integrates\nstate-of-the-art algorithms with games, because it already implements the agents\nand the game, making the process of quick prototyping much easier.\n\n### 2.1. Available methods to integrate with any agent <a name=\"available-methods\"></a>\n\nIn this section, we're going to show the useful methods and properties and also\ndemonstrate how to use in a real case\n\n#### 2.1.1. Methods and useful properties <a name=\"methods\"></a>\n\nBelow are listed some useful properties of the game class.\n\n```\n>>> print(game.nb_actions)\n5 # number of actions.\n\n>>> print(game.food_pos)\n(6, 5) # current position of food.\n\n>>> print(game.steps)\n10 # current number of steps in a given episode.\n\n>>> print(game.snake.length)\n4 # current length of the snake in a given episode.\n```\n\nThe methods you could use to integrate with any AI agent are:\n\n```\n>>> state = game.reset()\n  # Reset the game and returns the game state right after resetting.\n\n>>> state = game.state()\n  # Get the current game state.\n\n>>> game.food_pos = game.generate_food()\n  # Update the food position.\n\n>>> state, reward, done, info = game.step(numerical_action)\n  # Play a numerical_action, obtaining state, reward, over and info.\n\n>>> game.render()\n  # Render the game in a pygame window.\n```\n\n#### 2.1.2. Example usage <a name=\"example-usage\"></a>\n\nTo use with AI agents, you need to integrate the game with the AI agent. An\nexample usage is:\n\n```\nfrom snake-on-pygame import Game\nfrom ai_agent import your_model # import your AI agent of choice\n\ngame = Game(player = \"ROBOT\",\n                board_size = board_size,\n                local_state = local_state,\n                relative_pos = RELATIVE_POS)\nstate = game.reset()\n\nmodel = your_model()\n\nwhile not game.game_over:  # Main loop, until game_over\n    game.food_pos = game.generate_food()\n\n    model.choose_action(state)   # CHOOSE ACTION BASED ON MODEL/AI AGENT\n    state, reward, done, info = game.step(action)\n\n    mode.train(state, reward, game_over, done)\n    print(info)\n\nmodel.test()\n```\n\nThe above code is an example usage for one episode. If you want more episodes,\nwrap the while loop in a loop for nb_epochs (you choose).\n\n### 2.2. Using with colab-rl <a name=\"using-colab-rl\"></a>\n\nUsing snake-on-pygame with [colab-rl (click here)](https://github.com/Neves4/colab-rl) is very straightforward\nand you can also experiment with hyperparameters on state-of-the-art algorithms.\n\nA detailed usage is described on the repo's main README, but for short, after\ncloning it you can just execute the run_dqn.py script with:\n\n```\n$ python run_dqn.py [-h]\n```\n\nAnd you can read more about all the possible arguments in the file/repo. An\ntrained DQN model, on a 10 x 10 board with no customization is represented on the\nbelow GIF.\n\n<p align=\"center\">\n    <img src = \"/resources/gifs/dqn_gameplay.gif\"/>\n</p>\n\n## 3. Contributing <a name=\"contributing\"></a>\n\nPlease read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on this repo's code of conduct, and the process for submitting pull requests.\n\n## 4. License <a name=\"license\"></a>\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## 5. Acknowledgments <a name=\"acknowledgments\"></a>\n\n* @farizrahman4u - For his [qlearning4k](https://github.com/farizrahman4u/qlearning4k) snake code, I used it as the base of this repo's code.\n\n* @chuyangliu - Also for his snake code, which implemented the relative actions.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/neves4/snake-on-pygame/", "keywords": "snake pygame reinforcement-learning AI python", "license": "", "maintainer": "", "maintainer_email": "", "name": "snake-on-pygame", "package_url": "https://pypi.org/project/snake-on-pygame/", "platform": "", "project_url": "https://pypi.org/project/snake-on-pygame/", "project_urls": {"Homepage": "https://github.com/neves4/snake-on-pygame/", "Source": "https://github.com/neves4/snake-on-pygame/"}, "release_url": "https://pypi.org/project/snake-on-pygame/1.0/", "requires_dist": null, "requires_python": ">=2.7", "summary": "Snake implemented on pygame meant to be used by human and AI agents", "version": "1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>snake-on-pygame</h1>\n<p><a href=\"https://github.com/Neves4/snake-rl/graphs/commit-activity\" rel=\"nofollow\"><img alt=\"Maintenance\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/90bf1b2a4d99698c4dffbc494b9734690a777fec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d61696e7461696e65642533462d7965732d677265656e2e737667\"></a> <a href=\"https://www.python.org/\" rel=\"nofollow\"><img alt=\"made-with-python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/68a99107ffdf24c5fb2cc4bca38b7b662e501b97/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d616465253230776974682d507974686f6e2d3166343235662e737667\"></a> <a href=\"https://lbesson.mit-license.org/\" rel=\"nofollow\"><img alt=\"MIT license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4150014b4dfdd7b565fa18de88e9bb1b8ccd7c08/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667\"></a> <a href=\"https://GitHub.com/Neves4/ama\" rel=\"nofollow\"><img alt=\"Ask Me Anything !\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3e0b9eb17e703b59a8d52789d632dbbd15dbaca1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f41736b2532306d652d616e797468696e672d3161626339632e737667\"></a></p>\n<p align=\"center\">\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8c2f9eab6392a681450a51c29a39d1f6e2e87146/7265736f75726365732f696d616765732f736e616b655f6c6f676f2e706e67\">\n</p>\n<p>Snake game that can be controlled by human input and AI agents (DQN). Who's best? :snake: :robot:</p>\n<h1>Table of Contents</h1>\n<ul>\n<li><a href=\"#getting_started-human\" rel=\"nofollow\">1. Getting Started (for human players)</a>\n<ul>\n<li><a href=\"#pre-req-human\" rel=\"nofollow\">1.1. Prerequisites</a></li>\n<li><a href=\"#installing-human\" rel=\"nofollow\">1.2. Installing</a></li>\n<li><a href=\"#playing-human\" rel=\"nofollow\">1.3. Playing</a></li>\n</ul>\n</li>\n<li><a href=\"#getting_started-ai\" rel=\"nofollow\">2. Getting Started (using AI agents)</a>\n<ul>\n<li><a href=\"#available-method\" rel=\"nofollow\">2.1. Available methods to integrate with any agent</a>\n<ul>\n<li><a href=\"#methods\" rel=\"nofollow\">2.1.1. Methods</a></li>\n<li><a href=\"#example-usage\" rel=\"nofollow\">2.1.2. Example usage</a></li>\n</ul>\n</li>\n<li><a href=\"#using-colab-rl\" rel=\"nofollow\">2.2. Using colab-rl</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">3. Contributing</a></li>\n<li><a href=\"#license\" rel=\"nofollow\">4. License</a></li>\n<li><a href=\"#acknowledgments\" rel=\"nofollow\">5. Acknowledgments</a></li>\n</ul>\n<h2>1. Getting Started (for human players) <a></a></h2>\n<p>Let's get the game up and running on your computer, with the instructions below.\nYou can play the game and compare to the repos benchmark, which includes AI and\nhumans (you can include yourself by a pull request to the file <a href=\"resources/scores.json\" rel=\"nofollow\">scores.json</a>).</p>\n<h3>1.1. Prerequisites <a></a></h3>\n<p>To play the game you need Python 3.4+. If you installed <a href=\"https://www.anaconda.com/\" rel=\"nofollow\">Anaconda</a> the only package\nyou need to download is pygame. Before installing it, make sure your Anaconda\ninstallation is up-to-date using the command (conda update conda anaconda)and\nupdating all packages (conda update --all). To install pygame, use:</p>\n<pre><code>$ conda install -c cogsci pygame\n\n</code></pre>\n<p>It's highly recommended to use Anaconda to manage your Python packages and environments.\nIf you chose not to, make sure you run requirements_human.txt, using:</p>\n<pre><code>$ python install setup.py\n</code></pre>\n<p>or</p>\n<pre><code>$ python3 install setup.py\n</code></pre>\n<h3>1.2. Installing <a></a></h3>\n<p>You can download download the source code or clone the repository to your computer.</p>\n<p>To clone the repository, open bash or command prompt, cd to the chosen directory\nand run the following code:</p>\n<pre><code>$ git clone https://github.com/Neves4/SnakeAI.git\n</code></pre>\n<p>To download the repo, just follow along the gif (click 'Clone or Download' and\nthen 'Download ZIP').</p>\n<p><img alt=\"Download repo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a939ebd3df46655d2aa29ce074a1e449c9f6f487/2f7265736f75726365732f676966732f646f776e6c6f61645f7265706f2e676966\"></p>\n<h3>1.3. Playing <a></a></h3>\n<p>The GUI allows you to choose between single games and the benchmark mode. It's\nalso possible to choose between difficulty levels.</p>\n<p>If using the repository files, change directory to the root, then to the game folder\nand use:</p>\n<pre><code>$ python snake.py [-h]\n</code></pre>\n<p>An example gameplay for a single player match is shown below.</p>\n<p align=\"center\">\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85f2bf68320ce6e0cbe4631b59e2aabd897688ca/2f7265736f75726365732f676966732f67616d65706c61792e676966\">\n</p>\n<p>In the benchmark mode, you will play through 10 games and your mean score/steps\nare going to be recorded and you can add to the leaderboards. Pull request\nchanging the benchmark file (<a href=\"resources/scores.json\" rel=\"nofollow\">located in here</a>) or open an issue with your score.</p>\n<h2>2. Getting Started (using AI agents) <a></a></h2>\n<p>This game uses similar usage structure and methods to <a href=\"https://github.com/openai/gym\" rel=\"nofollow\">OpenAI's gym</a> and you\ncan easily integrate it with any agent, written in Pytorch, Tensorflow, Theano or Keras.</p>\n<p>It's recommended that you use <a href=\"https://github.com/Neves4/colab-rl\" rel=\"nofollow\">colab-rl</a>, a repository that integrates\nstate-of-the-art algorithms with games, because it already implements the agents\nand the game, making the process of quick prototyping much easier.</p>\n<h3>2.1. Available methods to integrate with any agent <a></a></h3>\n<p>In this section, we're going to show the useful methods and properties and also\ndemonstrate how to use in a real case</p>\n<h4>2.1.1. Methods and useful properties <a></a></h4>\n<p>Below are listed some useful properties of the game class.</p>\n<pre><code>&gt;&gt;&gt; print(game.nb_actions)\n5 # number of actions.\n\n&gt;&gt;&gt; print(game.food_pos)\n(6, 5) # current position of food.\n\n&gt;&gt;&gt; print(game.steps)\n10 # current number of steps in a given episode.\n\n&gt;&gt;&gt; print(game.snake.length)\n4 # current length of the snake in a given episode.\n</code></pre>\n<p>The methods you could use to integrate with any AI agent are:</p>\n<pre><code>&gt;&gt;&gt; state = game.reset()\n  # Reset the game and returns the game state right after resetting.\n\n&gt;&gt;&gt; state = game.state()\n  # Get the current game state.\n\n&gt;&gt;&gt; game.food_pos = game.generate_food()\n  # Update the food position.\n\n&gt;&gt;&gt; state, reward, done, info = game.step(numerical_action)\n  # Play a numerical_action, obtaining state, reward, over and info.\n\n&gt;&gt;&gt; game.render()\n  # Render the game in a pygame window.\n</code></pre>\n<h4>2.1.2. Example usage <a></a></h4>\n<p>To use with AI agents, you need to integrate the game with the AI agent. An\nexample usage is:</p>\n<pre><code>from snake-on-pygame import Game\nfrom ai_agent import your_model # import your AI agent of choice\n\ngame = Game(player = \"ROBOT\",\n                board_size = board_size,\n                local_state = local_state,\n                relative_pos = RELATIVE_POS)\nstate = game.reset()\n\nmodel = your_model()\n\nwhile not game.game_over:  # Main loop, until game_over\n    game.food_pos = game.generate_food()\n\n    model.choose_action(state)   # CHOOSE ACTION BASED ON MODEL/AI AGENT\n    state, reward, done, info = game.step(action)\n\n    mode.train(state, reward, game_over, done)\n    print(info)\n\nmodel.test()\n</code></pre>\n<p>The above code is an example usage for one episode. If you want more episodes,\nwrap the while loop in a loop for nb_epochs (you choose).</p>\n<h3>2.2. Using with colab-rl <a></a></h3>\n<p>Using snake-on-pygame with <a href=\"https://github.com/Neves4/colab-rl\" rel=\"nofollow\">colab-rl (click here)</a> is very straightforward\nand you can also experiment with hyperparameters on state-of-the-art algorithms.</p>\n<p>A detailed usage is described on the repo's main README, but for short, after\ncloning it you can just execute the run_dqn.py script with:</p>\n<pre><code>$ python run_dqn.py [-h]\n</code></pre>\n<p>And you can read more about all the possible arguments in the file/repo. An\ntrained DQN model, on a 10 x 10 board with no customization is represented on the\nbelow GIF.</p>\n<p align=\"center\">\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0ad83a2cecf7541f9fdd6c4302b00fe902ff8f2f/2f7265736f75726365732f676966732f64716e5f67616d65706c61792e676966\">\n</p>\n<h2>3. Contributing <a></a></h2>\n<p>Please read <a href=\"https://gist.github.com/PurpleBooth/b24679402957c63ec426\" rel=\"nofollow\">CONTRIBUTING.md</a> for details on this repo's code of conduct, and the process for submitting pull requests.</p>\n<h2>4. License <a></a></h2>\n<p>This project is licensed under the MIT License - see the <a href=\"LICENSE\" rel=\"nofollow\">LICENSE</a> file for details.</p>\n<h2>5. Acknowledgments <a></a></h2>\n<ul>\n<li>\n<p>@farizrahman4u - For his <a href=\"https://github.com/farizrahman4u/qlearning4k\" rel=\"nofollow\">qlearning4k</a> snake code, I used it as the base of this repo's code.</p>\n</li>\n<li>\n<p>@chuyangliu - Also for his snake code, which implemented the relative actions.</p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 5918967, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "69553cbb17878aac014672298775d8d7", "sha256": "0d214cd77aa1626c52f151de1cf2c19f45304701ae0c8b4032dd725173fe9050"}, "downloads": -1, "filename": "snake-on-pygame-1.0.tar.gz", "has_sig": false, "md5_digest": "69553cbb17878aac014672298775d8d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 8208, "upload_time": "2019-10-02T16:49:07", "upload_time_iso_8601": "2019-10-02T16:49:07.971584Z", "url": "https://files.pythonhosted.org/packages/39/c0/afcd3c5f450ce2f519f687c98aa940ed751f575f6e108fededa83f9dbae9/snake-on-pygame-1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "69553cbb17878aac014672298775d8d7", "sha256": "0d214cd77aa1626c52f151de1cf2c19f45304701ae0c8b4032dd725173fe9050"}, "downloads": -1, "filename": "snake-on-pygame-1.0.tar.gz", "has_sig": false, "md5_digest": "69553cbb17878aac014672298775d8d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 8208, "upload_time": "2019-10-02T16:49:07", "upload_time_iso_8601": "2019-10-02T16:49:07.971584Z", "url": "https://files.pythonhosted.org/packages/39/c0/afcd3c5f450ce2f519f687c98aa940ed751f575f6e108fededa83f9dbae9/snake-on-pygame-1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:07:37 2020"}