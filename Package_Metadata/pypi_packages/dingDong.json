{"info": {"author": "BiSkilled", "author_email": "Tal@BiSkilled.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Information Technology", "Intended Audience :: System Administrators", "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)", "Natural Language :: English", "Operating System :: POSIX", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: System :: Systems Administration", "Topic :: Utilities"], "description": "|PyPI version| |Docs badge| |License|\n\n*********\nDing Dong\n*********\n\nDing-Dong created for modeling developing and maintaining complex data integration projects - relational database\nor cloud APIs integration, data cleansing or modeling algorithms.\n\nThe project is currently supporting batch loading from diverse RMDBs. we do plan to extend it for full support\nin REST and WebSocket as well. The project if fully developer in python, we do use Node for our REST integration.\n\nDing-Dong developed to use as a glue between diverse data storage types using each component best of practice.\nfor example, there is no JOIN or UNION implementation because usually this functionality is used in much efficient way at the connectors.\nwe focus on managing the meta-data correctly and helping to create fast and easy to manage data workflows.\n\nUsing the native capabilities of existing connectors with Ding-Dong allow us to create robust data project using the\nadvantages of all the components\n\nDing-Dong has two main modules:\n\n- DING - create and manage overall meta-data structure for all object listed in the work-flow\n    - creating new objects\n    - modify an existing object by using backpropagation mechanism\n    - update data into new object\n    - store old structure\n    - (Todo) --> truck all work-flow changes as part of full CI/CD methodology\n\n- DONG - extract and load data from diverse connectors\n    - extract data - support multithreading for extracting massive data volume\n    - transfer     - enable to add a custom function on existing columns\n                   - enable to add custom calculated fields\n    - merge        - merging source with target data can be done if the source and merge located at the same connector\n    - exec         - enable to execute PL/SQL or stored procedure command as part of the whole data workflow\n\nRead more about Ding-Dong at http://www.biSkilled.com (marketing) or at `Ding-Dong documentation <https://dingdong.readthedocs.io/en/latest>`_\n\nInstallation\n============\n`download from GitHub <https://github.com/biskilled/dingDong>`_ or install by using ``pip``::\n\n    pip install dingDong\n\nSamples\n=======\ndownload samples CSV files DATAELEMENTDESCRIPTION.csv, DEMOGRAPHICS.csv, MEASURESOFBIRTHANDDEATH.csv\nlocated at `samples/sampleHealthCare/csvData <samples/sampleHealthCare/csvData/>`_ folder.\nIn this sample, we use **C:\\\\dingDong** as our main folder for all source CSV files and dingDong logs.\n\nFull code sample **extractCsvToSqlLite.py** located at `samples/sampleHealthCare/ <samples/sampleHealthCare/>`_ folder\n\nthe sample demonstrates how to load three CSV files into SqlLite, create a simple query-based\non those tables and send the result into a new CSV file.\n\n1. load module and basic configuration\n\n* Config.CONN_URL   -> set connection URL into all connectors\n    * key   -> general connection name or connection type (sql, oracle, file .. )\n    * value -> can be string or dictionary\n      * String     --> Connection string URL (key defined connection type: sql, oracle, mySql....)\n      * Dictionary --> must have 'conn' (connection type) and 'url' (connection string).\n      available connection can be found at dingDong.misc.enumsJson.eConn\n* Config.LOGS_DEBUG  -> set logging level (logging.DEBUG, logging.WARNING...)\n* Config.LOGS_DIR    -> set logs directory for creating logs files\n\nconfiguration properties can be found at `dingDong documentation <https://dingdong.readthedocs.io/en/latest>`_\n\n::\n\n    import logging\n    from dingDong import DingDong\n    from dingDong import Config\n\n    \"\"\" set log level: logging.INFO, logging.DEBUG, logging.ERROR \"\"\"\n    Config.LOGS_DEBUG = logging.DEBUG\n\n    Config.CONN_URL = {\n        'sampleSql': {'conn': 'sql',\"url\": \"<Sql server connection string>;UID=USER;PWD=PWD;\"},\n        'file': \"C:\\\\dingDong\\\\\",\n        'sqlite': \"C:\\\\dingDong\\\\sqlLiteDB.db\"}\n\n2. Creating work flow can be done as JSON format or python dictionaries\n   In this followed sample we will use python dictionary the sample work flow contain\n\n* mapping and loading CSV file named DATAELEMENTDESCRIPTION into SqlLite table named dateElements_Desc\n* mapping and loading CSV file named DEMOGRAPHICS into SqlLite table named demographics\n* mapping and loading CSV file named MEASURESOFBIRTHANDDEATH into SqlLite table named birthDate\n* create a new query based on demographics and birthDate  into new table named Final\n* Update sample field at Final table by using direct PL/SQL query\n* Extract Final table data into a CSV file.\n  We use VARCHAR(200) as default CSV column data type. configuration can be found at DEFAULTS under dingDong.conn.baseBatch\n\n::\n\n    nodesToLoad = [\n        {\"source\": [\"file\", \"DATAELEMENTDESCRIPTION.csv\"],\n         \"target\": [\"sqlite\", \"dateElements_Desc\"]},\n\n        {\"source\": [\"file\", \"DEMOGRAPHICS.csv\"],\n         \"target\": [\"sqlite\", \"demographics\"]},\n\n        {\"source\": [\"file\", \"MEASURESOFBIRTHANDDEATH.csv\"],\n         \"target\": [\"sqlite\", \"birthDate\"]},\n\n        {\"query\": [\"sqlite\", \"\"\"   Select d.[State_FIPS_Code] AS A, d.[County_FIPS_Code] AS B, d.[County_FIPS_Code] AS G,d.[County_FIPS_Code], d.[CHSI_County_Name], d.[CHSI_State_Name],[Population_Size],[Total_Births],[Total_Deaths]\n                                        From demographics d INNER JOIN birthDate b ON d.[County_FIPS_Code] = b.[County_FIPS_Code] AND d.[State_FIPS_Code] = b.[State_FIPS_Code]\"\"\"],\n         \"target\": [\"sqlite\", \"Finall\", 2]},\n\n        {\"myexec\": [\"sqlite\", \"Update dateElements_Desc Set [Data_Type] = 'dingDong';\"]},\n\n        {\"source\": [\"sqlite\", \"Finall\"],\n         \"target\": [\"file\", \"finall.csv\"]}\n    ]\n\n3. Init class dingDong\n\n* dicObj      -> loading dictionary as a work flow\n* dirData     -> loading JSON files in this folder\n* includeFiles-> FILTER files to load in dirData folder\n* notIncldeFiles-> Ignoring files to load in dirData folder\n* connDict    -> equal to Config.CONN_URL, st connection Urls\n* processes   -> number of parallel processing, used only for loading data (DONG module)\n\n::\n\n    m = DingDong(dicObj=nodesToLoad,\n                 filePath=None,\n                 dirData=None,\n                 includeFiles=None,\n                 notIncludeFiles=None,\n                 connDict=None,\n                 processes=1)\n\n4. DING\n\n* creating dateElements_Desc, demographics and birthDate tables based on CSV files\n* creating Final table based on the defined query\n\n if the table exists and structure changed - Ding module will track changes by a duplicate object with data and create new object schema\n\n::\n\n    m.ding()\n\n5.  DONG - Extracting data from CSV files into SQLite table. default loading is truncate-> insert method\n    Extract data from a query into the Final table (truncate-> insert )\n\n* if object structure changed and mode 2 (like at the sample)\n  * history table will be created\n  * new object will be created and will be populated with data from history table (identical column name)\n\n::\n\n        m.dong()\n\nFull sample code::\n\n    from dingDong import DingDong\n    from dingDong import Config\n\n    Config.CONN_URL = {\n        'x1'    : {'conn':'sql',\"url\":\"DRIVER={SQL Server};SERVER=CPX-VLQ5GA42TW2\\SQLEXPRESS;DATABASE=ContosoRetailDW;UID=bpmk;PWD=bpmk;\"},\n        'x2'    : {'conn':'sql',\"url\":\"DRIVER={SQL Server};SERVER=CPX-VLQ5GA42TW2\\SQLEXPRESS;DATABASE=ContosoRetailDW;UID=bpmk;PWD=bpmk;\"},\n        'file'  : \"C:\\\\dingDong\\\\\",\n        'sqlite': \"C:\\\\dingDong\\\\sqlLiteDB.db\"}\n    Config.LOGS_DEBUG = logging.DEBUG\n    Config.LOGS_DIR = \"C:\\\\dingDong\"\n\n    nodesToLoad = [\n            {   \"source\":[\"file\",\"DATAELEMENTDESCRIPTION.csv\"],\n                \"target\":[\"sqlite\",\"dateElements_Desc\"]},\n\n            {   \"source\":[\"file\",\"DEMOGRAPHICS.csv\"],\n                \"target\":[\"sqlite\",\"demographics\"]},\n\n            {   \"source\":[\"file\",\"MEASURESOFBIRTHANDDEATH.csv\"],\n                \"target\":[\"sqlite\",\"birthDate\"]},\n\n            {   \"query\":[\"sqlite\",\"\"\"   Select d.[State_FIPS_Code] AS A, d.[County_FIPS_Code] AS B, d.[County_FIPS_Code] AS G,d.[County_FIPS_Code], d.[CHSI_County_Name], d.[CHSI_State_Name],[Population_Size],[Total_Births],[Total_Deaths]\n                                        From demographics d INNER JOIN birthDate b ON d.[County_FIPS_Code] = b.[County_FIPS_Code] AND d.[State_FIPS_Code] = b.[State_FIPS_Code]\"\"\"],\n                \"target\":[\"sqlite\",\"Final\", 2]},\n\n            {   \"myexec\":[\"sqlite\",\"Update dateElements_Desc Set [Data_Type] = 'dingDong';\"]},\n\n            {   \"source\":[\"sqlite\",\"Final\"],\n                \"target\":[\"file\",\"final.csv\"]}\n          ]\n\n    m = DingDong(dicObj=nodesToLoad,\n                 filePath=None,\n                 dirData=None,\n                 includeFiles=None,\n                 notIncludeFiles=None,\n                 connDict=None,\n                 processes=1)\n    m.ding()\n    m.dong()\n\nRoad map\n========\n\nWe would like to create a platform that will enable to design, implement and maintenance and data integration project such as:\n\n*  Any REST API connectivity from any API to any API using simple JSON mapping\n*  Any Relational database connectivity using JSON mapping\n*  Any Non-relational storage\n*  Main platform for any middleware business logic - from sample if-than-else up to statistics algorithms using ML and DL algorithms\n*  Enable Real-time and scheduled integration\n\nWe will extend our connectors and Meta-data manager accordingly.\n\nBATCH supported connectors\n==========================\n\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| connectors Type   | python module    | checked version  | dev status  | notes                                    |\n+===================+==================+==================+=============+==========================================+\n| sql               |  pyOdbc          | 4.0.23           | tested, prod| slow to extract, massive data volume     |\n|                   |                  |                  |             | preferred using ceODBC                   |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| sql               | ceODBC           | 2.0.1            | tested, prod| sql server conn for massive data loading |\n|                   |                  |                  |             | installed manually from 3rdPart folder   |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| access            | pyOdbc           | 4.0.23           | tested, prod|                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| oracle            | cx-oracle        | 6.1              | tested, prod|                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| CSV / text files  | CSV / CSV23      | 0.1.5            | tested, prod|                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| mysql             | pyMySql          | 0.6.3rc1         | dev         |                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| vertica           | vertica-python   | 0.9.1            | dev         |                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| sqllite           | sqllite3         | 6.1              | tested, prod|                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| mongoDb           | pyMongo          | 3.7.2            | dev         |                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| salesforce        | simple_salesforce| 3.7.2            | dev         |                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n| haddop/Hive       | .                | .                | dev         |                                          |\n+-------------------+------------------+------------------+-------------+------------------------------------------+\n\nAuthors\n=======\n\ndingDong was created by `Tal Shany <http://www.biskilled.com>`_\n(tal@biSkilled.com)\nWe are looking for contributions !!!\n\nLicense\n=======\n\nGNU General Public License v3.0\n\nSee `COPYING <COPYING>`_ to see the full text.\n\n.. |PyPI version| image:: https://img.shields.io/pypi/v/dingDong.svg\n   :target: https://github.com/biskilled/dingDong\n.. |Docs badge| image:: https://img.shields.io/badge/docs-latest-brightgreen.svg\n   :target: https://readthedocs.org/projects/dingDong/\n.. |License| image:: https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg\n   :target: COPYING\n   :alt: Repository License", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/biskilled/dingDong", "keywords": "ETL,Data modeling,Python,Integration,Mapping", "license": "GPLv3+", "maintainer": "", "maintainer_email": "", "name": "dingDong", "package_url": "https://pypi.org/project/dingDong/", "platform": "", "project_url": "https://pypi.org/project/dingDong/", "project_urls": {"Homepage": "https://github.com/biskilled/dingDong"}, "release_url": "https://pypi.org/project/dingDong/1.0.13/", "requires_dist": null, "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "summary": "Data modeling managing and transforming data", "version": "1.0.13", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://github.com/biskilled/dingDong\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/40f23f68255b702fadc2a7ff39d33c110df95336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f64696e67446f6e672e737667\"></a> <a href=\"https://readthedocs.org/projects/dingDong/\" rel=\"nofollow\"><img alt=\"Docs badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f2379b41b2809fb0ad4959e1f0113f57abc80a64/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d627269676874677265656e2e737667\"></a> <a href=\"COPYING\" rel=\"nofollow\"><img alt=\"Repository License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd7443d0d7bf01f6f527b81fbcc044db8bcecae5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c25323076332e302d627269676874677265656e2e737667\"></a></p>\n<div id=\"ding-dong\">\n<h2>Ding Dong</h2>\n<p>Ding-Dong created for modeling developing and maintaining complex data integration projects - relational database\nor cloud APIs integration, data cleansing or modeling algorithms.</p>\n<p>The project is currently supporting batch loading from diverse RMDBs. we do plan to extend it for full support\nin REST and WebSocket as well. The project if fully developer in python, we do use Node for our REST integration.</p>\n<p>Ding-Dong developed to use as a glue between diverse data storage types using each component best of practice.\nfor example, there is no JOIN or UNION implementation because usually this functionality is used in much efficient way at the connectors.\nwe focus on managing the meta-data correctly and helping to create fast and easy to manage data workflows.</p>\n<p>Using the native capabilities of existing connectors with Ding-Dong allow us to create robust data project using the\nadvantages of all the components</p>\n<p>Ding-Dong has two main modules:</p>\n<ul>\n<li><dl>\n<dt>DING - create and manage overall meta-data structure for all object listed in the work-flow</dt>\n<dd><ul>\n<li>creating new objects</li>\n<li>modify an existing object by using backpropagation mechanism</li>\n<li>update data into new object</li>\n<li>store old structure</li>\n<li>(Todo) \u2013&gt; truck all work-flow changes as part of full CI/CD methodology</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>DONG - extract and load data from diverse connectors</dt>\n<dd><ul>\n<li>extract data - support multithreading for extracting massive data volume</li>\n<li><dl>\n<dt>transfer     - enable to add a custom function on existing columns</dt>\n<dd><ul>\n<li>enable to add custom calculated fields</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li>merge        - merging source with target data can be done if the source and merge located at the same connector</li>\n<li>exec         - enable to execute PL/SQL or stored procedure command as part of the whole data workflow</li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n<p>Read more about Ding-Dong at <a href=\"http://www.biSkilled.com\" rel=\"nofollow\">http://www.biSkilled.com</a> (marketing) or at <a href=\"https://dingdong.readthedocs.io/en/latest\" rel=\"nofollow\">Ding-Dong documentation</a></p>\n<div id=\"installation\">\n<h3>Installation</h3>\n<p><a href=\"https://github.com/biskilled/dingDong\" rel=\"nofollow\">download from GitHub</a> or install by using <tt>pip</tt>:</p>\n<pre>pip install dingDong\n</pre>\n</div>\n<div id=\"samples\">\n<h3>Samples</h3>\n<p>download samples CSV files DATAELEMENTDESCRIPTION.csv, DEMOGRAPHICS.csv, MEASURESOFBIRTHANDDEATH.csv\nlocated at <a href=\"samples/sampleHealthCare/csvData/\" rel=\"nofollow\">samples/sampleHealthCare/csvData</a> folder.\nIn this sample, we use <strong>C:\\dingDong</strong> as our main folder for all source CSV files and dingDong logs.</p>\n<p>Full code sample <strong>extractCsvToSqlLite.py</strong> located at <a href=\"samples/sampleHealthCare/\" rel=\"nofollow\">samples/sampleHealthCare/</a> folder</p>\n<p>the sample demonstrates how to load three CSV files into SqlLite, create a simple query-based\non those tables and send the result into a new CSV file.</p>\n<ol>\n<li>load module and basic configuration</li>\n</ol>\n<ul>\n<li><dl>\n<dt>Config.CONN_URL   -&gt; set connection URL into all connectors</dt>\n<dd><ul>\n<li>key   -&gt; general connection name or connection type (sql, oracle, file .. )</li>\n<li>value -&gt; can be string or dictionary\n* String     \u2013&gt; Connection string URL (key defined connection type: sql, oracle, mySql\u2026.)\n* Dictionary \u2013&gt; must have \u2018conn\u2019 (connection type) and \u2018url\u2019 (connection string).\navailable connection can be found at dingDong.misc.enumsJson.eConn</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li>Config.LOGS_DEBUG  -&gt; set logging level (logging.DEBUG, logging.WARNING\u2026)</li>\n<li>Config.LOGS_DIR    -&gt; set logs directory for creating logs files</li>\n</ul>\n<p>configuration properties can be found at <a href=\"https://dingdong.readthedocs.io/en/latest\" rel=\"nofollow\">dingDong documentation</a></p>\n<pre>import logging\nfrom dingDong import DingDong\nfrom dingDong import Config\n\n\"\"\" set log level: logging.INFO, logging.DEBUG, logging.ERROR \"\"\"\nConfig.LOGS_DEBUG = logging.DEBUG\n\nConfig.CONN_URL = {\n    'sampleSql': {'conn': 'sql',\"url\": \"&lt;Sql server connection string&gt;;UID=USER;PWD=PWD;\"},\n    'file': \"C:\\\\dingDong\\\\\",\n    'sqlite': \"C:\\\\dingDong\\\\sqlLiteDB.db\"}\n</pre>\n<ol>\n<li>Creating work flow can be done as JSON format or python dictionaries\nIn this followed sample we will use python dictionary the sample work flow contain</li>\n</ol>\n<ul>\n<li>mapping and loading CSV file named DATAELEMENTDESCRIPTION into SqlLite table named dateElements_Desc</li>\n<li>mapping and loading CSV file named DEMOGRAPHICS into SqlLite table named demographics</li>\n<li>mapping and loading CSV file named MEASURESOFBIRTHANDDEATH into SqlLite table named birthDate</li>\n<li>create a new query based on demographics and birthDate  into new table named Final</li>\n<li>Update sample field at Final table by using direct PL/SQL query</li>\n<li>Extract Final table data into a CSV file.\nWe use VARCHAR(200) as default CSV column data type. configuration can be found at DEFAULTS under dingDong.conn.baseBatch</li>\n</ul>\n<pre>nodesToLoad = [\n    {\"source\": [\"file\", \"DATAELEMENTDESCRIPTION.csv\"],\n     \"target\": [\"sqlite\", \"dateElements_Desc\"]},\n\n    {\"source\": [\"file\", \"DEMOGRAPHICS.csv\"],\n     \"target\": [\"sqlite\", \"demographics\"]},\n\n    {\"source\": [\"file\", \"MEASURESOFBIRTHANDDEATH.csv\"],\n     \"target\": [\"sqlite\", \"birthDate\"]},\n\n    {\"query\": [\"sqlite\", \"\"\"   Select d.[State_FIPS_Code] AS A, d.[County_FIPS_Code] AS B, d.[County_FIPS_Code] AS G,d.[County_FIPS_Code], d.[CHSI_County_Name], d.[CHSI_State_Name],[Population_Size],[Total_Births],[Total_Deaths]\n                                    From demographics d INNER JOIN birthDate b ON d.[County_FIPS_Code] = b.[County_FIPS_Code] AND d.[State_FIPS_Code] = b.[State_FIPS_Code]\"\"\"],\n     \"target\": [\"sqlite\", \"Finall\", 2]},\n\n    {\"myexec\": [\"sqlite\", \"Update dateElements_Desc Set [Data_Type] = 'dingDong';\"]},\n\n    {\"source\": [\"sqlite\", \"Finall\"],\n     \"target\": [\"file\", \"finall.csv\"]}\n]\n</pre>\n<ol>\n<li>Init class dingDong</li>\n</ol>\n<ul>\n<li>dicObj      -&gt; loading dictionary as a work flow</li>\n<li>dirData     -&gt; loading JSON files in this folder</li>\n<li>includeFiles-&gt; FILTER files to load in dirData folder</li>\n<li>notIncldeFiles-&gt; Ignoring files to load in dirData folder</li>\n<li>connDict    -&gt; equal to Config.CONN_URL, st connection Urls</li>\n<li>processes   -&gt; number of parallel processing, used only for loading data (DONG module)</li>\n</ul>\n<pre>m = DingDong(dicObj=nodesToLoad,\n             filePath=None,\n             dirData=None,\n             includeFiles=None,\n             notIncludeFiles=None,\n             connDict=None,\n             processes=1)\n</pre>\n<ol>\n<li>DING</li>\n</ol>\n<ul>\n<li>creating dateElements_Desc, demographics and birthDate tables based on CSV files</li>\n<li>creating Final table based on the defined query</li>\n</ul>\n<blockquote>\nif the table exists and structure changed - Ding module will track changes by a duplicate object with data and create new object schema</blockquote>\n<pre>m.ding()\n</pre>\n<ol>\n<li>DONG - Extracting data from CSV files into SQLite table. default loading is truncate-&gt; insert method\nExtract data from a query into the Final table (truncate-&gt; insert )</li>\n</ol>\n<ul>\n<li>if object structure changed and mode 2 (like at the sample)\n* history table will be created\n* new object will be created and will be populated with data from history table (identical column name)</li>\n</ul>\n<pre>m.dong()\n</pre>\n<p>Full sample code:</p>\n<pre>from dingDong import DingDong\nfrom dingDong import Config\n\nConfig.CONN_URL = {\n    'x1'    : {'conn':'sql',\"url\":\"DRIVER={SQL Server};SERVER=CPX-VLQ5GA42TW2\\SQLEXPRESS;DATABASE=ContosoRetailDW;UID=bpmk;PWD=bpmk;\"},\n    'x2'    : {'conn':'sql',\"url\":\"DRIVER={SQL Server};SERVER=CPX-VLQ5GA42TW2\\SQLEXPRESS;DATABASE=ContosoRetailDW;UID=bpmk;PWD=bpmk;\"},\n    'file'  : \"C:\\\\dingDong\\\\\",\n    'sqlite': \"C:\\\\dingDong\\\\sqlLiteDB.db\"}\nConfig.LOGS_DEBUG = logging.DEBUG\nConfig.LOGS_DIR = \"C:\\\\dingDong\"\n\nnodesToLoad = [\n        {   \"source\":[\"file\",\"DATAELEMENTDESCRIPTION.csv\"],\n            \"target\":[\"sqlite\",\"dateElements_Desc\"]},\n\n        {   \"source\":[\"file\",\"DEMOGRAPHICS.csv\"],\n            \"target\":[\"sqlite\",\"demographics\"]},\n\n        {   \"source\":[\"file\",\"MEASURESOFBIRTHANDDEATH.csv\"],\n            \"target\":[\"sqlite\",\"birthDate\"]},\n\n        {   \"query\":[\"sqlite\",\"\"\"   Select d.[State_FIPS_Code] AS A, d.[County_FIPS_Code] AS B, d.[County_FIPS_Code] AS G,d.[County_FIPS_Code], d.[CHSI_County_Name], d.[CHSI_State_Name],[Population_Size],[Total_Births],[Total_Deaths]\n                                    From demographics d INNER JOIN birthDate b ON d.[County_FIPS_Code] = b.[County_FIPS_Code] AND d.[State_FIPS_Code] = b.[State_FIPS_Code]\"\"\"],\n            \"target\":[\"sqlite\",\"Final\", 2]},\n\n        {   \"myexec\":[\"sqlite\",\"Update dateElements_Desc Set [Data_Type] = 'dingDong';\"]},\n\n        {   \"source\":[\"sqlite\",\"Final\"],\n            \"target\":[\"file\",\"final.csv\"]}\n      ]\n\nm = DingDong(dicObj=nodesToLoad,\n             filePath=None,\n             dirData=None,\n             includeFiles=None,\n             notIncludeFiles=None,\n             connDict=None,\n             processes=1)\nm.ding()\nm.dong()\n</pre>\n</div>\n<div id=\"road-map\">\n<h3>Road map</h3>\n<p>We would like to create a platform that will enable to design, implement and maintenance and data integration project such as:</p>\n<ul>\n<li>Any REST API connectivity from any API to any API using simple JSON mapping</li>\n<li>Any Relational database connectivity using JSON mapping</li>\n<li>Any Non-relational storage</li>\n<li>Main platform for any middleware business logic - from sample if-than-else up to statistics algorithms using ML and DL algorithms</li>\n<li>Enable Real-time and scheduled integration</li>\n</ul>\n<p>We will extend our connectors and Meta-data manager accordingly.</p>\n</div>\n<div id=\"batch-supported-connectors\">\n<h3>BATCH supported connectors</h3>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>connectors Type</th>\n<th>python module</th>\n<th>checked version</th>\n<th>dev status</th>\n<th>notes</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>sql</td>\n<td>pyOdbc</td>\n<td>4.0.23</td>\n<td>tested, prod</td>\n<td>slow to extract, massive data volume\npreferred using ceODBC</td>\n</tr>\n<tr><td>sql</td>\n<td>ceODBC</td>\n<td>2.0.1</td>\n<td>tested, prod</td>\n<td>sql server conn for massive data loading\ninstalled manually from 3rdPart folder</td>\n</tr>\n<tr><td>access</td>\n<td>pyOdbc</td>\n<td>4.0.23</td>\n<td>tested, prod</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>oracle</td>\n<td>cx-oracle</td>\n<td>6.1</td>\n<td>tested, prod</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>CSV / text files</td>\n<td>CSV / CSV23</td>\n<td>0.1.5</td>\n<td>tested, prod</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>mysql</td>\n<td>pyMySql</td>\n<td>0.6.3rc1</td>\n<td>dev</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>vertica</td>\n<td>vertica-python</td>\n<td>0.9.1</td>\n<td>dev</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>sqllite</td>\n<td>sqllite3</td>\n<td>6.1</td>\n<td>tested, prod</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>mongoDb</td>\n<td>pyMongo</td>\n<td>3.7.2</td>\n<td>dev</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>salesforce</td>\n<td>simple_salesforce</td>\n<td>3.7.2</td>\n<td>dev</td>\n<td>\u00a0</td>\n</tr>\n<tr><td>haddop/Hive</td>\n<td>.</td>\n<td>.</td>\n<td>dev</td>\n<td>\u00a0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"authors\">\n<h3>Authors</h3>\n<p>dingDong was created by <a href=\"http://www.biskilled.com\" rel=\"nofollow\">Tal Shany</a>\n(<a href=\"mailto:tal%40biSkilled.com\">tal<span>@</span>biSkilled<span>.</span>com</a>)\nWe are looking for contributions !!!</p>\n</div>\n<div id=\"license\">\n<h3>License</h3>\n<p>GNU General Public License v3.0</p>\n<p>See <a href=\"COPYING\" rel=\"nofollow\">COPYING</a> to see the full text.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5727885, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "ba8deb2d84595f54bb029240550a54d6", "sha256": "6ab12154a182a50efa101e347bb5816bae4f60cd60bab779041edbc14dcbc13a"}, "downloads": -1, "filename": "dingDong-1.0.1.tar.gz", "has_sig": false, "md5_digest": "ba8deb2d84595f54bb029240550a54d6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 336338, "upload_time": "2019-07-05T22:51:24", "upload_time_iso_8601": "2019-07-05T22:51:24.181880Z", "url": "https://files.pythonhosted.org/packages/ed/85/1441a557ee5fd54308557215c0c8da605000894a02406f36766662433e2c/dingDong-1.0.1.tar.gz", "yanked": false}], "1.0.10": [{"comment_text": "", "digests": {"md5": "72a20dc21051f5b4b793d610dbc6f301", "sha256": "cec6cdee0be077cfca002af61aa26d8ffee0922c943747aaf036644d52b7b111"}, "downloads": -1, "filename": "dingDong-1.0.10.tar.gz", "has_sig": false, "md5_digest": "72a20dc21051f5b4b793d610dbc6f301", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306518, "upload_time": "2019-08-20T08:58:58", "upload_time_iso_8601": "2019-08-20T08:58:58.110307Z", "url": "https://files.pythonhosted.org/packages/31/85/1b0a76cafa29e5fd906716ac41dd05b183cfacbff704e08b4f49a30dcdf2/dingDong-1.0.10.tar.gz", "yanked": false}], "1.0.11": [{"comment_text": "", "digests": {"md5": "68f53b8aaa2764d3c978a814ab00f5db", "sha256": "51cad50c86c4f4946047be4d38c95b83a71dca65ebfcee442345bd071f9a6d12"}, "downloads": -1, "filename": "dingDong-1.0.11.tar.gz", "has_sig": false, "md5_digest": "68f53b8aaa2764d3c978a814ab00f5db", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306552, "upload_time": "2019-08-20T09:02:49", "upload_time_iso_8601": "2019-08-20T09:02:49.336635Z", "url": "https://files.pythonhosted.org/packages/c2/55/45946be8fa6ca9a49bab661448fc26e423d051dad683187ae340e0ecea4a/dingDong-1.0.11.tar.gz", "yanked": false}], "1.0.12": [{"comment_text": "", "digests": {"md5": "74ffb2a28910c643216eccdd1387272e", "sha256": "cc493bda105432b13876fa61b0fb11ba75d72a252417e2a2026fae7c4ffb9e8f"}, "downloads": -1, "filename": "dingDong-1.0.12.tar.gz", "has_sig": false, "md5_digest": "74ffb2a28910c643216eccdd1387272e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306913, "upload_time": "2019-08-22T11:11:55", "upload_time_iso_8601": "2019-08-22T11:11:55.132490Z", "url": "https://files.pythonhosted.org/packages/85/eb/9ed1fb8f992d9a078157ad4934b7cb791d6bc147b0ff8a7837c9ab940494/dingDong-1.0.12.tar.gz", "yanked": false}], "1.0.13": [{"comment_text": "", "digests": {"md5": "14fa8e6b966ba04aadf29546c0a282e7", "sha256": "27ed1b744adc882ffcbcd1ebd2ceb5f90ec64e58fd7c96fc0dab34f78d42c9d7"}, "downloads": -1, "filename": "dingDong-1.0.13.tar.gz", "has_sig": false, "md5_digest": "14fa8e6b966ba04aadf29546c0a282e7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 307123, "upload_time": "2019-08-25T20:08:18", "upload_time_iso_8601": "2019-08-25T20:08:18.570273Z", "url": "https://files.pythonhosted.org/packages/d9/ec/21b2176d684c324474e6bad8d791bd9e2bb8276c48946ec0b44d34125b4f/dingDong-1.0.13.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "2c1d6cb4098ac23ba450856cf68b9306", "sha256": "1b564e4dd4fc59bc5d0034808a1be69bc6beb7c07de3eb45bbd675479c8ad183"}, "downloads": -1, "filename": "dingDong-1.0.2.tar.gz", "has_sig": false, "md5_digest": "2c1d6cb4098ac23ba450856cf68b9306", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 301849, "upload_time": "2019-08-10T18:32:44", "upload_time_iso_8601": "2019-08-10T18:32:44.007768Z", "url": "https://files.pythonhosted.org/packages/90/09/f8a70143d5e5e16fba0e632793575739fd5f2f9d31966789adb5d32383cb/dingDong-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "e7611566c2430bd81f716d776a85202f", "sha256": "3fa664dca67153fbeb60f59e194c95f4cdcd1b4ad8a69f379a6e96d685402725"}, "downloads": -1, "filename": "dingDong-1.0.3.tar.gz", "has_sig": false, "md5_digest": "e7611566c2430bd81f716d776a85202f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 301680, "upload_time": "2019-08-10T19:10:43", "upload_time_iso_8601": "2019-08-10T19:10:43.927594Z", "url": "https://files.pythonhosted.org/packages/78/ef/825aefb9cf06b121b78f76ee6d30e39f9c74981bc8036640ea93887c7427/dingDong-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "e2ea6ad9ec0fb37ba0416f4a91daab0a", "sha256": "ac392f4e91e23a34f4534fb39e025a1119e09dc5993824326e1b47e67b246200"}, "downloads": -1, "filename": "dingDong-1.0.4.tar.gz", "has_sig": false, "md5_digest": "e2ea6ad9ec0fb37ba0416f4a91daab0a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306603, "upload_time": "2019-08-19T20:45:45", "upload_time_iso_8601": "2019-08-19T20:45:45.199894Z", "url": "https://files.pythonhosted.org/packages/a7/45/d923294e1dc3a2f385414626e09133ec7ff716cde359c0b97532676fb2a6/dingDong-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "c5831c788d09d85c8d4e2ab4ea6742d9", "sha256": "2d991d9a477a5c652cc4126354fd10076a485048f2542ca84ea7b218be2ec855"}, "downloads": -1, "filename": "dingDong-1.0.5.tar.gz", "has_sig": false, "md5_digest": "c5831c788d09d85c8d4e2ab4ea6742d9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306620, "upload_time": "2019-08-20T08:01:00", "upload_time_iso_8601": "2019-08-20T08:01:00.144457Z", "url": "https://files.pythonhosted.org/packages/0e/7e/dd76936449fa6300607752f0b3f84f36c84dd8fd9ef6baa297619bf77420/dingDong-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "e9d87e90a203f3c9fc16ca6f09b7f33a", "sha256": "d9b502e41e748febbf98b4bc4cb11d2c916afa18ed9a285d873da1753294b817"}, "downloads": -1, "filename": "dingDong-1.0.6.tar.gz", "has_sig": false, "md5_digest": "e9d87e90a203f3c9fc16ca6f09b7f33a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306482, "upload_time": "2019-08-20T08:06:15", "upload_time_iso_8601": "2019-08-20T08:06:15.308875Z", "url": "https://files.pythonhosted.org/packages/1a/c9/30433d1b9579b78a7c231f12696d401c0a1ee4c49529a7ac620ba168cac9/dingDong-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "e48cd0dfe090a72e6b05bd7ec42985de", "sha256": "2b4b208c3d89d7f9e605635fa0b27c340d393bd1efba3226f94d7a051d21eb4f"}, "downloads": -1, "filename": "dingDong-1.0.7.tar.gz", "has_sig": false, "md5_digest": "e48cd0dfe090a72e6b05bd7ec42985de", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306481, "upload_time": "2019-08-20T08:22:46", "upload_time_iso_8601": "2019-08-20T08:22:46.163208Z", "url": "https://files.pythonhosted.org/packages/a8/c5/83dd765ef0665281d8801b68d1888d1a733fe946831fd86a1c050ea6117f/dingDong-1.0.7.tar.gz", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "94b74f140d124e1f064cbaa089af4d35", "sha256": "1f5808c73c11d3800ac5a22839c8a956d2412b426d53b82503d4781c75b6f85f"}, "downloads": -1, "filename": "dingDong-1.0.8.tar.gz", "has_sig": false, "md5_digest": "94b74f140d124e1f064cbaa089af4d35", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 306478, "upload_time": "2019-08-20T08:25:46", "upload_time_iso_8601": "2019-08-20T08:25:46.978134Z", "url": "https://files.pythonhosted.org/packages/b0/78/47d96c2c3207b69d51d7681decc0125760a7a485571a91a41b48ef2b316f/dingDong-1.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "14fa8e6b966ba04aadf29546c0a282e7", "sha256": "27ed1b744adc882ffcbcd1ebd2ceb5f90ec64e58fd7c96fc0dab34f78d42c9d7"}, "downloads": -1, "filename": "dingDong-1.0.13.tar.gz", "has_sig": false, "md5_digest": "14fa8e6b966ba04aadf29546c0a282e7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*", "size": 307123, "upload_time": "2019-08-25T20:08:18", "upload_time_iso_8601": "2019-08-25T20:08:18.570273Z", "url": "https://files.pythonhosted.org/packages/d9/ec/21b2176d684c324474e6bad8d791bd9e2bb8276c48946ec0b44d34125b4f/dingDong-1.0.13.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:38:20 2020"}