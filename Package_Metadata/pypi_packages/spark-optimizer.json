{"info": {"author": "Josip Delic", "author_email": "delijati@gmx.net", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6"], "description": "# Spark-optimizer\n\n[![Build Status](https://api.travis-ci.org/delijati/spark-optimizer.svg?branch=master)](https://travis-ci.org/delijati/spark-optimizer)\n\nOptimize spark settings (for cluster aka yarn run)\n\nOriginal source: http://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/\n\n## Usage\n\nInstall:\n\n    $ virtualenv env\n    $ env/bin/pip install spark-optimizer\n\nDev install:\n\n    $ virtualenv env\n    $ env/bin/pip install -e .\n\n\nGenerate settings for `c4.4xlarge` with `4` nodes:\n\n    $ env/bin/spark-optimizer c4.4xlarge 4\n    Optimal numPartitions: 162 \n    {'spark.default.parallelism': '108',\n     'spark.driver.cores': '2',\n     'spark.driver.maxResultSize': '3481m',\n     'spark.driver.memory': '3481m',\n     'spark.driver.memoryOverhead': '614m',\n     'spark.executor.cores': '2',\n     'spark.executor.instances': '27',\n     'spark.executor.memory': '3481m',\n     'spark.executor.memoryOverhead': '614m'}\n\nUpdate instance info:\n\n    $ env/bin/python spark_optimizer/emr_update.py\n\n\n# CHANGES\n\n0.1.8 (2020-02-14)\n------------------\n\n- add calculation for `numPartitions`\n- dropping pypy and python3.4\n\n\n0.1.7 (2019-12-09)\n------------------\n\n- set `long_description_content_type=\"text/markdown\"`\n\n\n0.1.6 (2019-12-09)\n------------------\n\n- fix docs\n\n\n0.1.5 (2019-12-09)\n------------------\n\n- update ``emr_instance.yaml``\n\n\n0.1.4 (2019-03-10)\n------------------\n\n- add ec2 and emr cost to yaml\n\n\n0.1.3 (2019-03-08)\n------------------\n\n- add emr cost to yaml\n- export load yaml file\n- make ``memory_overhead_coefficient`` editable\n\n\n0.1.2 (2019-02-20)\n------------------\n\n- unpin the versions\n- rename cli from _ to -\n\n\n0.1.1 (2018-09-12)\n------------------\n\n- fix email\n\n\n0.1.0 (2018-09-12)\n\n- initial release", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/delijati/spark-optimizer", "keywords": "spark emr aws cluster yarn", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "spark-optimizer", "package_url": "https://pypi.org/project/spark-optimizer/", "platform": "", "project_url": "https://pypi.org/project/spark-optimizer/", "project_urls": {"Homepage": "https://github.com/delijati/spark-optimizer"}, "release_url": "https://pypi.org/project/spark-optimizer/0.1.8/", "requires_dist": null, "requires_python": "", "summary": "Optimize AWS EMR spark settings (spark-config-cheatsheet)", "version": "0.1.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Spark-optimizer</h1>\n<p><a href=\"https://travis-ci.org/delijati/spark-optimizer\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2aa02e32479e3291ada97cf21c3c339572239355/68747470733a2f2f6170692e7472617669732d63692e6f72672f64656c696a6174692f737061726b2d6f7074696d697a65722e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>Optimize spark settings (for cluster aka yarn run)</p>\n<p>Original source: <a href=\"http://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/\" rel=\"nofollow\">http://c2fo.io/c2fo/spark/aws/emr/2016/07/06/apache-spark-config-cheatsheet/</a></p>\n<h2>Usage</h2>\n<p>Install:</p>\n<pre><code>$ virtualenv env\n$ env/bin/pip install spark-optimizer\n</code></pre>\n<p>Dev install:</p>\n<pre><code>$ virtualenv env\n$ env/bin/pip install -e .\n</code></pre>\n<p>Generate settings for <code>c4.4xlarge</code> with <code>4</code> nodes:</p>\n<pre><code>$ env/bin/spark-optimizer c4.4xlarge 4\nOptimal numPartitions: 162 \n{'spark.default.parallelism': '108',\n 'spark.driver.cores': '2',\n 'spark.driver.maxResultSize': '3481m',\n 'spark.driver.memory': '3481m',\n 'spark.driver.memoryOverhead': '614m',\n 'spark.executor.cores': '2',\n 'spark.executor.instances': '27',\n 'spark.executor.memory': '3481m',\n 'spark.executor.memoryOverhead': '614m'}\n</code></pre>\n<p>Update instance info:</p>\n<pre><code>$ env/bin/python spark_optimizer/emr_update.py\n</code></pre>\n<h1>CHANGES</h1>\n<h2>0.1.8 (2020-02-14)</h2>\n<ul>\n<li>add calculation for <code>numPartitions</code></li>\n<li>dropping pypy and python3.4</li>\n</ul>\n<h2>0.1.7 (2019-12-09)</h2>\n<ul>\n<li>set <code>long_description_content_type=\"text/markdown\"</code></li>\n</ul>\n<h2>0.1.6 (2019-12-09)</h2>\n<ul>\n<li>fix docs</li>\n</ul>\n<h2>0.1.5 (2019-12-09)</h2>\n<ul>\n<li>update <code>emr_instance.yaml</code></li>\n</ul>\n<h2>0.1.4 (2019-03-10)</h2>\n<ul>\n<li>add ec2 and emr cost to yaml</li>\n</ul>\n<h2>0.1.3 (2019-03-08)</h2>\n<ul>\n<li>add emr cost to yaml</li>\n<li>export load yaml file</li>\n<li>make <code>memory_overhead_coefficient</code> editable</li>\n</ul>\n<h2>0.1.2 (2019-02-20)</h2>\n<ul>\n<li>unpin the versions</li>\n<li>rename cli from _ to -</li>\n</ul>\n<h2>0.1.1 (2018-09-12)</h2>\n<ul>\n<li>fix email</li>\n</ul>\n<p>0.1.0 (2018-09-12)</p>\n<ul>\n<li>initial release</li>\n</ul>\n\n          </div>"}, "last_serial": 6631907, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "1655012e509f8577a9c75f43d7a11ba7", "sha256": "543d90082a72f0a859dac735a633a652c270b137c8a80bd0eaf40ede24878dec"}, "downloads": -1, "filename": "spark_optimizer-0.1.1.tar.gz", "has_sig": false, "md5_digest": "1655012e509f8577a9c75f43d7a11ba7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5682, "upload_time": "2018-09-12T20:51:36", "upload_time_iso_8601": "2018-09-12T20:51:36.361682Z", "url": "https://files.pythonhosted.org/packages/51/88/12d5651c9d6475351488298df01a5630908fab68bba58d4ecd48935adaf2/spark_optimizer-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "c05e38fdb70e866f6786066335105167", "sha256": "f4e71c8738ce803ee0220cad78a5be848caa503dbd2049f96d06ea2158f3169d"}, "downloads": -1, "filename": "spark_optimizer-0.1.2.tar.gz", "has_sig": false, "md5_digest": "c05e38fdb70e866f6786066335105167", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5657, "upload_time": "2019-02-20T14:54:14", "upload_time_iso_8601": "2019-02-20T14:54:14.079496Z", "url": "https://files.pythonhosted.org/packages/6f/09/758e5df2d05af93c8d8b8cfc4b1018ea88628fcd88ca9cca12fddd56a756/spark_optimizer-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "83426c8a46f8c422e08d27981204f872", "sha256": "bdacc0639c9ac219e03697597c5d5aaa40f6cac0bac23a0207821aaf3b64c2f0"}, "downloads": -1, "filename": "spark_optimizer-0.1.3.tar.gz", "has_sig": false, "md5_digest": "83426c8a46f8c422e08d27981204f872", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10520, "upload_time": "2019-03-08T09:37:12", "upload_time_iso_8601": "2019-03-08T09:37:12.770737Z", "url": "https://files.pythonhosted.org/packages/70/6f/969c1283caea9b1a01973383aa181d57c308c9ccdf3f1481bf5347c9452a/spark_optimizer-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "fb66580a36a99d82c60f5814963e6f52", "sha256": "cab8b14280bc791ee1a9b3a2ffa24d794fc48e13b94a64e139a8ea95c7f51ed2"}, "downloads": -1, "filename": "spark_optimizer-0.1.4.tar.gz", "has_sig": false, "md5_digest": "fb66580a36a99d82c60f5814963e6f52", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13339, "upload_time": "2019-03-10T08:57:22", "upload_time_iso_8601": "2019-03-10T08:57:22.402324Z", "url": "https://files.pythonhosted.org/packages/36/13/6d542bc4c9ccc9bceeabb3bde61f0c63bc6b586c4255ded2bb9f13967588/spark_optimizer-0.1.4.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "efb0f9badab7d413b4fe3c202c4b28c4", "sha256": "f6408800d73ec3662829d231e3c40e5c93051e42d56db3acd7db2d5d5ad9b20c"}, "downloads": -1, "filename": "spark_optimizer-0.1.7.tar.gz", "has_sig": false, "md5_digest": "efb0f9badab7d413b4fe3c202c4b28c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15302, "upload_time": "2019-12-09T20:22:08", "upload_time_iso_8601": "2019-12-09T20:22:08.512183Z", "url": "https://files.pythonhosted.org/packages/e5/e0/ea04bec2b763edd1ceccbe743c14d39b5dbc53dbe74383ddd7bddc95a214/spark_optimizer-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "baf0f94cfdc81375d91296b52113b672", "sha256": "15c1580b2b6d388ad2871ad7e63f36c0f75c6a11a0cd757f455cb3a7209cfe1a"}, "downloads": -1, "filename": "spark_optimizer-0.1.8.tar.gz", "has_sig": false, "md5_digest": "baf0f94cfdc81375d91296b52113b672", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17829, "upload_time": "2020-02-14T15:18:50", "upload_time_iso_8601": "2020-02-14T15:18:50.617006Z", "url": "https://files.pythonhosted.org/packages/52/11/67b11e28b2276cc6a195a3ef62a02d3fa5ee1519c671a32a24a9bee1d985/spark_optimizer-0.1.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "baf0f94cfdc81375d91296b52113b672", "sha256": "15c1580b2b6d388ad2871ad7e63f36c0f75c6a11a0cd757f455cb3a7209cfe1a"}, "downloads": -1, "filename": "spark_optimizer-0.1.8.tar.gz", "has_sig": false, "md5_digest": "baf0f94cfdc81375d91296b52113b672", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17829, "upload_time": "2020-02-14T15:18:50", "upload_time_iso_8601": "2020-02-14T15:18:50.617006Z", "url": "https://files.pythonhosted.org/packages/52/11/67b11e28b2276cc6a195a3ef62a02d3fa5ee1519c671a32a24a9bee1d985/spark_optimizer-0.1.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:54 2020"}