{"info": {"author": "Marek Rudnicki", "author_email": "marek.rudnicki@tum.de", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)", "Operating System :: MacOS :: MacOS X", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Programming Language :: C", "Programming Language :: Cython", "Programming Language :: Python", "Programming Language :: Python :: 2.7"], "description": "cochlea\n=======\n\n*cochlea* is a collection of inner ear models.  All models are easily\naccessible as Python functions.  They take sound signal as input and\nreturn `spike trains`_ of the auditory nerve fibers::\n\n\n\n                           +-----------+     __|______|______|____\n   .-.     .-.     .-.     |           |-->  _|________|______|___\n  /   \\   /   \\   /   \\ -->|  Cochlea  |-->  ___|______|____|_____\n       '-'     '-'         |           |-->  __|______|______|____\n                           +-----------+\n            Sound                               Spike Trains\n                                              (Auditory Nerve)\n\n\n\nThe package contains state-of-the-art biophysical models, which give\nrealistic approximation of the auditory nerve activity.\n\nThe models are implemented using the original code from their authors\nwhenever possible.  Therefore, they return the same results as the\noriginal models.  We made an effort to verify it with unit testing\n(see tests directory for details).\n\nThe implementation is also fast.  It is easy to generate responses of\nhundreds or even thousands of auditory nerve fibers (ANFs).  It is\npossible, for example, to generate responses of the whole human\nauditory nerve (around 30,000 ANFs).  We usually tested the models\nwith sounds up to 1 second in duration.\n\nI developed *cochlea* during my PhD in the group of Werner Hemmert\n(`Bio-Inspired Information Processing`_) at the TUM.  It went through\nseveral versions and rewrites.  Now, it is quite stable and we decided\nto release it for the community.\n\n.. _`spike trains`: https://en.wikipedia.org/wiki/Spike_train\n.. _`Bio-Inspired Information Processing`: https://www.ei.tum.de/en/bai/home/\n\n\n\nFeatures\n--------\n\n- State of the art inner ear models accessible from Python.\n- Contains full biophysical inner ear models: sound in, spikes out.\n- Fast; can generate thousands of spike trains.\n- Interoperability with neuron simulation software such as NEURON_ and Brian_.\n\n.. _NEURON: http://www.neuron.yale.edu/neuron/\n.. _Brian: http://briansimulator.org/\n\n\n\nImplemented Models\n------------------\n\n- Holmberg, M. (2007). Speech Encoding in the Human Auditory\n  Periphery: Modeling and Quantitative Assessment by Means of\n  Automatic Speech Recognition. PhD thesis, Technical University\n  Darmstadt.\n- Zilany, M. S., Bruce, I. C., Nelson, P. C., &\n  Carney, L. H. (2009). A phenomenological model of the synapse\n  between the inner hair cell and auditory nerve: long-term adaptation\n  with power-law dynamics. The Journal of the Acoustical Society of\n  America, 126(5), 2390-2412.\n- Zilany, M. S., Bruce, I. C., & Carney, L. H. (2014). Updated\n  parameters and expanded simulation options for a model of the\n  auditory periphery. The Journal of the Acoustical Society of\n  America, 135(1), 283-286.\n- `MATLAB Auditory Periphery`_ by Meddis et al. (external model, not\n  implemented in the package, but easily accessible through\n  matlab_wrapper_).\n\n\n.. _`MATLAB Auditory Periphery`: http://www.essexpsychology.macmate.me/HearingLab/modelling.html\n.. _matlab_wrapper: https://github.com/mrkrd/matlab_wrapper\n\n\n\n\nUsage\n-----\n\nCheck our online DEMO_ and examples_ (probably the easiest is to start\nwith `run_zilany2014.py`_).\n\n\nInitialize the modules::\n\n  import cochlea\n  import thorns as th\n  import thorns.waves as wv\n\n\nGenerate sound::\n\n  fs = 100e3\n  sound = wv.ramped_tone(\n      fs=fs,\n      freq=1000,\n      duration=0.1,\n      dbspl=50\n  )\n\n\nRun the model (responses of 200 cat HSR fibers)::\n\n  anf_trains = cochlea.run_zilany2014(\n      sound,\n      fs,\n      anf_num=(200,0,0),\n      cf=1000,\n      seed=0,\n      species='cat'\n  )\n\n\nPlot the results::\n\n  th.plot_raster(anf_trains)\n  th.show()\n\n\nYou can browse through the API documentation at:\nhttps://pythonhosted.org/cochlea/\n\n\n.. _DEMO: https://github.com/mrkrd/cochlea/tree/master/examples/cochlea_demo.ipynb\n.. _examples: https://github.com/mrkrd/cochlea/tree/master/examples\n.. _`run_zilany2014.py`: https://github.com/mrkrd/cochlea/blob/master/examples/run_zilany2014.py\n\n\n\n\n\nInstallation\n------------\n\n::\n\n  pip install cochlea\n\nCheck INSTALL.rst_ for details.\n\n.. _INSTALL.rst: INSTALL.rst\n\n\n\n\n\n\nSpike Train Format\n------------------\n\nSpike train data format is based on a standard DataFrame_ format from\nthe excellent pandas_ library.  Spike trains and their meta data are\nstored in DataFrame_, where each row corresponds to a single neuron:\n\n=====  ========  ====  ====  =================================================\nindex  duration  type    cf                                             spikes\n=====  ========  ====  ====  =================================================\n0          0.15   hsr  8000  [0.00243, 0.00414, 0.00715, 0.01089, 0.01358, ...\n1          0.15   hsr  8000  [0.00325, 0.01234, 0.0203, 0.02295, 0.0268, 0....\n2          0.15   hsr  8000  [0.00277, 0.00594, 0.01104, 0.01387, 0.0234, 0...\n3          0.15   hsr  8000  [0.00311, 0.00563, 0.00971, 0.0133, 0.0177, 0....\n4          0.15   hsr  8000  [0.00283, 0.00469, 0.00929, 0.01099, 0.01779, ...\n5          0.15   hsr  8000  [0.00352, 0.00781, 0.01138, 0.02166, 0.02575, ...\n6          0.15   hsr  8000  [0.00395, 0.00651, 0.00984, 0.0157, 0.02209, 0...\n7          0.15   hsr  8000  [0.00385, 0.009, 0.01537, 0.02114, 0.02377, 0....\n=====  ========  ====  ====  =================================================\n\nThe column 'spikes' is the most important and stores an array with\nspike times (time stamps) in seconds for every action potential.  The\ncolumn 'duration' is the duration of the sound.  The column 'cf' is\nthe characteristic frequency (CF) of the fiber.  The column 'type'\ntells us what auditory nerve fiber generated the spike train.  'hsr'\nis for high-spontaneous rate fiber, 'msr' and 'lsr' for medium- and\nlow-spontaneous rate fibers.\n\nAdvantages of the format:\n\n- easy addition of new meta data,\n- efficient grouping and filtering of trains using DataFrame_\n  functionality,\n- export to MATLAB struct array through mat files::\n\n    scipy.io.savemat(\n        \"spikes.mat\",\n        {'spike_trains': spike_trains.to_records()}\n    )\n\nThe library thorns_ has more information and functions to manipulate\nspike trains.\n\n\n.. _DataFrame: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n.. _pandas: http://pandas.pydata.org/\n.. _thorns: https://github.com/mrkrd/thorns\n\n\n\nContribute & Support\n--------------------\n\n- Open tasks: TODO.org_ (best viewed in Emacs org-mode)\n- Issue Tracker: https://github.com/mrkrd/cochlea/issues\n- Source Code: https://github.com/mrkrd/cochlea\n\n.. _TODO.org: TODO.org\n\n\n\nSimilar Projects\n----------------\n\n- `Carney Lab`_\n- `Matlab Auditory Periphery`_\n- DSAM_\n- `Brian Hears`_\n- `The Auditory Modeling Toolbox`_\n\n.. _`Carney Lab`: http://www.urmc.rochester.edu/labs/Carney-Lab/publications/auditory-models.cfm\n.. _DSAM: http://dsam.org.uk/\n.. _`Matlab Auditory Periphery`: http://www.essexpsychology.macmate.me/HearingLab/modelling.html\n.. _`Brian Hears`: http://www.briansimulator.org/docs/hears.html\n.. _`The Auditory Modeling Toolbox`: http://amtoolbox.sourceforge.net/\n\n\n\nCiting\n------\n\nRudnicki M., Schoppe O., Isik M., V\u00f6lk F. and\nHemmert W. (2015). *Modeling auditory coding: from sound to spikes*.\nCell and Tissue Research, Springer Nature, 361, pp. 159\u2014175.\ndoi:10.1007/s00441-015-2202-z\nhttps://link.springer.com/article/10.1007/s00441-015-2202-z\n\n\nBibTeX entry::\n\n  @Article{Rudnicki2015,\n    author    = {Marek Rudnicki and Oliver Schoppe and Michael Isik and Florian V\u00f6lk and Werner Hemmert},\n    title     = {Modeling auditory coding: from sound to spikes},\n    journal   = {Cell and Tissue Research},\n    year      = {2015},\n    volume    = {361},\n    number    = {1},\n    pages     = {159--175},\n    month     = {jun},\n    doi       = {10.1007/s00441-015-2202-z},\n    publisher = {Springer Nature},\n  }\n\n\nDo not forget to cite the original authors of the models as listed in\nImplemented Models.\n\n\n\nAcknowledgments\n---------------\n\nWe would like to thank Muhammad S.A. Zilany, Ian C. Bruce and\nLaurel H. Carney for developing inner ear models and allowing us to\nuse their code in *cochlea*.\n\nThanks goes to Marcus Holmberg, who developed the traveling wave based\nmodel.  His work was supported by the General Federal Ministry of\nEducation and Research within the Munich Bernstein Center for\nComputational Neuroscience (reference No. 01GQ0441, 01GQ0443 and\n01GQ1004B).\n\nWe are grateful to Ray Meddis for support with the Matlab Auditory\nPeriphery model.\n\nAnd last, but not least, I would like to thank Werner Hemmert for\nsupervising my PhD.  The thesis entitled *Computer models of\nacoustical and electrical stimulation of neurons in the auditory\nsystem* can be found at https://mediatum.ub.tum.de/1445042\n\nThis work was supported by the General Federal Ministry of Education\nand Research within the Munich Bernstein Center for Computational\nNeuroscience (reference No. 01GQ0441 and 01GQ1004B) and the German\nResearch Foundation Foundation's Priority Program PP 1608 *Ultrafast\nand temporally precise information processing: Normal and\ndysfunctional hearing*.\n\n\nLicense\n-------\n\nThe project is licensed under the GNU General Public License v3 or\nlater (GPLv3+).", "description_content_type": "", "docs_url": "https://pythonhosted.org/cochlea/", "download_url": "https://github.com/mrkrd/cochlea/tarball/master", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mrkrd/cochlea", "keywords": "", "license": "GPLv3+", "maintainer": "", "maintainer_email": "", "name": "cochlea", "package_url": "https://pypi.org/project/cochlea/", "platform": "Linux", "project_url": "https://pypi.org/project/cochlea/", "project_urls": {"Download": "https://github.com/mrkrd/cochlea/tarball/master", "Homepage": "https://github.com/mrkrd/cochlea"}, "release_url": "https://pypi.org/project/cochlea/2/", "requires_dist": null, "requires_python": "", "summary": "Inner ear models in Python", "version": "2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><em>cochlea</em> is a collection of inner ear models.  All models are easily\naccessible as Python functions.  They take sound signal as input and\nreturn <a href=\"https://en.wikipedia.org/wiki/Spike_train\" rel=\"nofollow\">spike trains</a> of the auditory nerve fibers:</p>\n<pre>                         +-----------+     __|______|______|____\n .-.     .-.     .-.     |           |--&gt;  _|________|______|___\n/   \\   /   \\   /   \\ --&gt;|  Cochlea  |--&gt;  ___|______|____|_____\n     '-'     '-'         |           |--&gt;  __|______|______|____\n                         +-----------+\n          Sound                               Spike Trains\n                                            (Auditory Nerve)\n</pre>\n<p>The package contains state-of-the-art biophysical models, which give\nrealistic approximation of the auditory nerve activity.</p>\n<p>The models are implemented using the original code from their authors\nwhenever possible.  Therefore, they return the same results as the\noriginal models.  We made an effort to verify it with unit testing\n(see tests directory for details).</p>\n<p>The implementation is also fast.  It is easy to generate responses of\nhundreds or even thousands of auditory nerve fibers (ANFs).  It is\npossible, for example, to generate responses of the whole human\nauditory nerve (around 30,000 ANFs).  We usually tested the models\nwith sounds up to 1 second in duration.</p>\n<p>I developed <em>cochlea</em> during my PhD in the group of Werner Hemmert\n(<a href=\"https://www.ei.tum.de/en/bai/home/\" rel=\"nofollow\">Bio-Inspired Information Processing</a>) at the TUM.  It went through\nseveral versions and rewrites.  Now, it is quite stable and we decided\nto release it for the community.</p>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>State of the art inner ear models accessible from Python.</li>\n<li>Contains full biophysical inner ear models: sound in, spikes out.</li>\n<li>Fast; can generate thousands of spike trains.</li>\n<li>Interoperability with neuron simulation software such as <a href=\"http://www.neuron.yale.edu/neuron/\" rel=\"nofollow\">NEURON</a> and <a href=\"http://briansimulator.org/\" rel=\"nofollow\">Brian</a>.</li>\n</ul>\n</div>\n<div id=\"implemented-models\">\n<h2>Implemented Models</h2>\n<ul>\n<li>Holmberg, M. (2007). Speech Encoding in the Human Auditory\nPeriphery: Modeling and Quantitative Assessment by Means of\nAutomatic Speech Recognition. PhD thesis, Technical University\nDarmstadt.</li>\n<li>Zilany, M. S., Bruce, I. C., Nelson, P. C., &amp;\nCarney, L. H. (2009). A phenomenological model of the synapse\nbetween the inner hair cell and auditory nerve: long-term adaptation\nwith power-law dynamics. The Journal of the Acoustical Society of\nAmerica, 126(5), 2390-2412.</li>\n<li>Zilany, M. S., Bruce, I. C., &amp; Carney, L. H. (2014). Updated\nparameters and expanded simulation options for a model of the\nauditory periphery. The Journal of the Acoustical Society of\nAmerica, 135(1), 283-286.</li>\n<li><a href=\"http://www.essexpsychology.macmate.me/HearingLab/modelling.html\" rel=\"nofollow\">MATLAB Auditory Periphery</a> by Meddis et al. (external model, not\nimplemented in the package, but easily accessible through\n<a href=\"https://github.com/mrkrd/matlab_wrapper\" rel=\"nofollow\">matlab_wrapper</a>).</li>\n</ul>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Check our online <a href=\"https://github.com/mrkrd/cochlea/tree/master/examples/cochlea_demo.ipynb\" rel=\"nofollow\">DEMO</a> and <a href=\"https://github.com/mrkrd/cochlea/tree/master/examples\" rel=\"nofollow\">examples</a> (probably the easiest is to start\nwith <a href=\"https://github.com/mrkrd/cochlea/blob/master/examples/run_zilany2014.py\" rel=\"nofollow\">run_zilany2014.py</a>).</p>\n<p>Initialize the modules:</p>\n<pre>import cochlea\nimport thorns as th\nimport thorns.waves as wv\n</pre>\n<p>Generate sound:</p>\n<pre>fs = 100e3\nsound = wv.ramped_tone(\n    fs=fs,\n    freq=1000,\n    duration=0.1,\n    dbspl=50\n)\n</pre>\n<p>Run the model (responses of 200 cat HSR fibers):</p>\n<pre>anf_trains = cochlea.run_zilany2014(\n    sound,\n    fs,\n    anf_num=(200,0,0),\n    cf=1000,\n    seed=0,\n    species='cat'\n)\n</pre>\n<p>Plot the results:</p>\n<pre>th.plot_raster(anf_trains)\nth.show()\n</pre>\n<p>You can browse through the API documentation at:\n<a href=\"https://pythonhosted.org/cochlea/\" rel=\"nofollow\">https://pythonhosted.org/cochlea/</a></p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install cochlea\n</pre>\n<p>Check <a href=\"INSTALL.rst\" rel=\"nofollow\">INSTALL.rst</a> for details.</p>\n</div>\n<div id=\"spike-train-format\">\n<h2>Spike Train Format</h2>\n<p>Spike train data format is based on a standard <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\" rel=\"nofollow\">DataFrame</a> format from\nthe excellent <a href=\"http://pandas.pydata.org/\" rel=\"nofollow\">pandas</a> library.  Spike trains and their meta data are\nstored in <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\" rel=\"nofollow\">DataFrame</a>, where each row corresponds to a single neuron:</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>index</th>\n<th>duration</th>\n<th>type</th>\n<th>cf</th>\n<th>spikes</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>0</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00243, 0.00414, 0.00715, 0.01089, 0.01358, \u2026</td>\n</tr>\n<tr><td>1</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00325, 0.01234, 0.0203, 0.02295, 0.0268, 0\u2026.</td>\n</tr>\n<tr><td>2</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00277, 0.00594, 0.01104, 0.01387, 0.0234, 0\u2026</td>\n</tr>\n<tr><td>3</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00311, 0.00563, 0.00971, 0.0133, 0.0177, 0\u2026.</td>\n</tr>\n<tr><td>4</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00283, 0.00469, 0.00929, 0.01099, 0.01779, \u2026</td>\n</tr>\n<tr><td>5</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00352, 0.00781, 0.01138, 0.02166, 0.02575, \u2026</td>\n</tr>\n<tr><td>6</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00395, 0.00651, 0.00984, 0.0157, 0.02209, 0\u2026</td>\n</tr>\n<tr><td>7</td>\n<td>0.15</td>\n<td>hsr</td>\n<td>8000</td>\n<td>[0.00385, 0.009, 0.01537, 0.02114, 0.02377, 0\u2026.</td>\n</tr>\n</tbody>\n</table>\n<p>The column \u2018spikes\u2019 is the most important and stores an array with\nspike times (time stamps) in seconds for every action potential.  The\ncolumn \u2018duration\u2019 is the duration of the sound.  The column \u2018cf\u2019 is\nthe characteristic frequency (CF) of the fiber.  The column \u2018type\u2019\ntells us what auditory nerve fiber generated the spike train.  \u2018hsr\u2019\nis for high-spontaneous rate fiber, \u2018msr\u2019 and \u2018lsr\u2019 for medium- and\nlow-spontaneous rate fibers.</p>\n<p>Advantages of the format:</p>\n<ul>\n<li><p>easy addition of new meta data,</p>\n</li>\n<li><p>efficient grouping and filtering of trains using <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\" rel=\"nofollow\">DataFrame</a>\nfunctionality,</p>\n</li>\n<li><p>export to MATLAB struct array through mat files:</p>\n<pre>scipy.io.savemat(\n    \"spikes.mat\",\n    {'spike_trains': spike_trains.to_records()}\n)\n</pre>\n</li>\n</ul>\n<p>The library <a href=\"https://github.com/mrkrd/thorns\" rel=\"nofollow\">thorns</a> has more information and functions to manipulate\nspike trains.</p>\n</div>\n<div id=\"contribute-support\">\n<h2>Contribute &amp; Support</h2>\n<ul>\n<li>Open tasks: <a href=\"TODO.org\" rel=\"nofollow\">TODO.org</a> (best viewed in Emacs org-mode)</li>\n<li>Issue Tracker: <a href=\"https://github.com/mrkrd/cochlea/issues\" rel=\"nofollow\">https://github.com/mrkrd/cochlea/issues</a></li>\n<li>Source Code: <a href=\"https://github.com/mrkrd/cochlea\" rel=\"nofollow\">https://github.com/mrkrd/cochlea</a></li>\n</ul>\n</div>\n<div id=\"similar-projects\">\n<h2>Similar Projects</h2>\n<ul>\n<li><a href=\"http://www.urmc.rochester.edu/labs/Carney-Lab/publications/auditory-models.cfm\" rel=\"nofollow\">Carney Lab</a></li>\n<li><a href=\"http://www.essexpsychology.macmate.me/HearingLab/modelling.html\" rel=\"nofollow\">Matlab Auditory Periphery</a></li>\n<li><a href=\"http://dsam.org.uk/\" rel=\"nofollow\">DSAM</a></li>\n<li><a href=\"http://www.briansimulator.org/docs/hears.html\" rel=\"nofollow\">Brian Hears</a></li>\n<li><a href=\"http://amtoolbox.sourceforge.net/\" rel=\"nofollow\">The Auditory Modeling Toolbox</a></li>\n</ul>\n</div>\n<div id=\"citing\">\n<h2>Citing</h2>\n<p>Rudnicki M., Schoppe O., Isik M., V\u00f6lk F. and\nHemmert W. (2015). <em>Modeling auditory coding: from sound to spikes</em>.\nCell and Tissue Research, Springer Nature, 361, pp. 159\u2014175.\ndoi:10.1007/s00441-015-2202-z\nhttps://link.springer.com/article/10.1007/s00441-015-2202-z</p>\n<p>BibTeX entry:</p>\n<pre>@Article{Rudnicki2015,\n  author    = {Marek Rudnicki and Oliver Schoppe and Michael Isik and Florian V\u00f6lk and Werner Hemmert},\n  title     = {Modeling auditory coding: from sound to spikes},\n  journal   = {Cell and Tissue Research},\n  year      = {2015},\n  volume    = {361},\n  number    = {1},\n  pages     = {159--175},\n  month     = {jun},\n  doi       = {10.1007/s00441-015-2202-z},\n  publisher = {Springer Nature},\n}\n</pre>\n<p>Do not forget to cite the original authors of the models as listed in\nImplemented Models.</p>\n</div>\n<div id=\"acknowledgments\">\n<h2>Acknowledgments</h2>\n<p>We would like to thank Muhammad S.A. Zilany, Ian C. Bruce and\nLaurel H. Carney for developing inner ear models and allowing us to\nuse their code in <em>cochlea</em>.</p>\n<p>Thanks goes to Marcus Holmberg, who developed the traveling wave based\nmodel.  His work was supported by the General Federal Ministry of\nEducation and Research within the Munich Bernstein Center for\nComputational Neuroscience (reference No. 01GQ0441, 01GQ0443 and\n01GQ1004B).</p>\n<p>We are grateful to Ray Meddis for support with the Matlab Auditory\nPeriphery model.</p>\n<p>And last, but not least, I would like to thank Werner Hemmert for\nsupervising my PhD.  The thesis entitled <em>Computer models of\nacoustical and electrical stimulation of neurons in the auditory\nsystem</em> can be found at <a href=\"https://mediatum.ub.tum.de/1445042\" rel=\"nofollow\">https://mediatum.ub.tum.de/1445042</a></p>\n<p>This work was supported by the General Federal Ministry of Education\nand Research within the Munich Bernstein Center for Computational\nNeuroscience (reference No. 01GQ0441 and 01GQ1004B) and the German\nResearch Foundation Foundation\u2019s Priority Program PP 1608 <em>Ultrafast\nand temporally precise information processing: Normal and\ndysfunctional hearing</em>.</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>The project is licensed under the GNU General Public License v3 or\nlater (GPLv3+).</p>\n</div>\n\n          </div>"}, "last_serial": 5166026, "releases": {"1.1": [{"comment_text": "", "digests": {"md5": "6c3ddbc9ab53f3874d3d7dd1d5d2cf03", "sha256": "e20b6af8e05d06d113ccfdd9fc5f39304f4460afe3970b07e3a612754eb1e979"}, "downloads": -1, "filename": "cochlea-1.1-cp27-none-win_amd64.whl", "has_sig": false, "md5_digest": "6c3ddbc9ab53f3874d3d7dd1d5d2cf03", "packagetype": "bdist_wheel", "python_version": "cp27", "requires_python": null, "size": 225632, "upload_time": "2014-07-04T22:05:59", "upload_time_iso_8601": "2014-07-04T22:05:59.969123Z", "url": "https://files.pythonhosted.org/packages/15/61/0150d902da86482dcc23f35d00c60fe286a57ad4368168d1ef1beb75d0c6/cochlea-1.1-cp27-none-win_amd64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7905c90659e86c859f2c97bbb3503b86", "sha256": "8ed79428b22f285367ae335c200d501072da84fb63a8928242a804b2cf663756"}, "downloads": -1, "filename": "cochlea-1.1.tar.gz", "has_sig": false, "md5_digest": "7905c90659e86c859f2c97bbb3503b86", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 291902, "upload_time": "2014-07-04T21:59:04", "upload_time_iso_8601": "2014-07-04T21:59:04.417982Z", "url": "https://files.pythonhosted.org/packages/21/48/3dc5d790a45a397cd426f008cc608d866b5ed43f1e7dc6275630c6811bf6/cochlea-1.1.tar.gz", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "0c4d80464f8a441eb7c412e64664e807", "sha256": "c381b61fc656102907399e233b1e740af5ef62c74e26ac6cd67a7c83f0c711de"}, "downloads": -1, "filename": "cochlea-1.2-cp27-none-win_amd64.whl", "has_sig": false, "md5_digest": "0c4d80464f8a441eb7c412e64664e807", "packagetype": "bdist_wheel", "python_version": "cp27", "requires_python": null, "size": 224928, "upload_time": "2014-08-14T12:37:39", "upload_time_iso_8601": "2014-08-14T12:37:39.163783Z", "url": "https://files.pythonhosted.org/packages/99/0f/3a6a031959cdc327f6689da51d4456bc1c26cc32b0c3fdb1e136e206b238/cochlea-1.2-cp27-none-win_amd64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a8b24f1b3648d10aa3092eeb83db7794", "sha256": "fb06867041dcac0868b21f4bb46e6985152523be5a3ce16d2ccb8aaee8551b94"}, "downloads": -1, "filename": "cochlea-1.2.tar.gz", "has_sig": false, "md5_digest": "a8b24f1b3648d10aa3092eeb83db7794", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 293040, "upload_time": "2014-08-14T12:37:29", "upload_time_iso_8601": "2014-08-14T12:37:29.824186Z", "url": "https://files.pythonhosted.org/packages/d2/3b/bc5710506fac0621ec749294f22f9699a124ea7715e4354a63f041bfdb95/cochlea-1.2.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "f369fb0166fd4742dd9c7600ef318dd4", "sha256": "076d519051232a6f7145ba03818b47c9261df5211668e714814166a77dcea232"}, "downloads": -1, "filename": "cochlea-1.2.2.tar.gz", "has_sig": true, "md5_digest": "f369fb0166fd4742dd9c7600ef318dd4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 303060, "upload_time": "2016-07-21T08:18:49", "upload_time_iso_8601": "2016-07-21T08:18:49.706876Z", "url": "https://files.pythonhosted.org/packages/c7/83/d1b6c47c26e4631f8b1f02749b0e2619081d2aeb49ea612af45a082d54d9/cochlea-1.2.2.tar.gz", "yanked": false}], "1.4": [{"comment_text": "", "digests": {"md5": "abe05fe5ee0560d499d32cc024b77af4", "sha256": "838f5cdbafac12aae6926b824c0a5558d2ebb8ecd704f9ead0d66f13d68c9b50"}, "downloads": -1, "filename": "cochlea-1.4.tar.gz", "has_sig": true, "md5_digest": "abe05fe5ee0560d499d32cc024b77af4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 701651, "upload_time": "2017-12-08T13:45:58", "upload_time_iso_8601": "2017-12-08T13:45:58.184311Z", "url": "https://files.pythonhosted.org/packages/56/47/b72afb2785dde1a8ecf5ff7b38e1192030114eb567fc52f60c33063948e7/cochlea-1.4.tar.gz", "yanked": false}], "2": [{"comment_text": "", "digests": {"md5": "77fcb175caed93ad410fe1b3d2645a16", "sha256": "11aff75b69b853ce284341154f90894cd10f2b35110daef266cb4865fa0e9c87"}, "downloads": -1, "filename": "cochlea-2.tar.gz", "has_sig": true, "md5_digest": "77fcb175caed93ad410fe1b3d2645a16", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 681239, "upload_time": "2019-04-19T20:17:52", "upload_time_iso_8601": "2019-04-19T20:17:52.917731Z", "url": "https://files.pythonhosted.org/packages/2d/e1/6db5737d90d17354be5e4a13225ffc2264cc8ca142e672e552be2967d3e1/cochlea-2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "77fcb175caed93ad410fe1b3d2645a16", "sha256": "11aff75b69b853ce284341154f90894cd10f2b35110daef266cb4865fa0e9c87"}, "downloads": -1, "filename": "cochlea-2.tar.gz", "has_sig": true, "md5_digest": "77fcb175caed93ad410fe1b3d2645a16", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 681239, "upload_time": "2019-04-19T20:17:52", "upload_time_iso_8601": "2019-04-19T20:17:52.917731Z", "url": "https://files.pythonhosted.org/packages/2d/e1/6db5737d90d17354be5e4a13225ffc2264cc8ca142e672e552be2967d3e1/cochlea-2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:21 2020"}