{"info": {"author": "Abhishek Singh", "author_email": "aosingh@asu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Financial and Insurance Industry", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX :: Linux", "Operating System :: Unix", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Office/Business :: Financial", "Topic :: Text Processing :: Markup :: HTML"], "description": "# NASDAQ Options chain Scraper\n\nPython Options Chain scraper for the old NASDAQ website : https://old.nasdaq.com\n\n## Install \n\n```bash\npip install options-scraper\n```\n\n## API\n\nUse the API if you want to access the scraped data records ( as python objects ) directly.\n\n### Usage\n\n```python\n\nfrom options_scraper.scraper import NASDAQOptionsScraper\nfrom options_scraper.utils import batched\n\nscraper = NASDAQOptionsScraper()\nticker_symbol = 'XOM'\nkwargs = { \"money\": 'all',\n           \"expir\": 'week',\n           \"excode\": None,\n           \"callput\": None\n         }\n\nrecords_generator = scraper(ticker_symbol, **kwargs)\n\n# Either access each record individually as shown below\nfor item in records_generator:\n    print(item)\n\n# Or use the batched util to get a list of items\nfor items in batched(records_generator, batch_size=100):\n    print(items)\n\n```\n\n### Output\n\nEach scraped record will have the following structure\n\n\n```python\n\n{'Ask': '23.20',\n 'Bid': '18.50',\n 'Calls': 'Apr 24, 2020',\n 'Chg': '',\n 'Last': '19.40',\n 'Open Int': '15',\n 'Puts': 'Apr 24, 2020',\n 'Root': 'XOM',\n 'Strike': '60',\n 'Vol': '0'}\n\n{'Ask': '28.20',\n 'Bid': '23.50',\n 'Calls': 'Apr 24, 2020',\n 'Chg': '',\n 'Last': '29.67',\n 'Open Int': '3',\n 'Puts': 'Apr 24, 2020',\n 'Root': 'XOM',\n 'Strike': '65',\n 'Vol': '0'}\n\n```\n\n## Console Script\n\nUse this script to scrape records and save them either in CSV or JSON format.\n\n```bash\noptions-scraper --help\n```\n\n```text\nusage: options-scraper [-h]\n                       [-l {CRITICAL,FATAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}]\n                       [-t TICKER] \n                       [-o ODIR] \n                       [-b BATCH_SIZE] \n                       [-c {call,put}]\n                       [-m {all,in,out,near}] \n                       [-e EXCODE]\n                       [-x {week,stan,quart,cebo}] \n                       [-s {json,csv}]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -l {CRITICAL,FATAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}, --log-level {CRITICAL,FATAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}\n  -t TICKER, --ticker TICKER Ticker Symbol\n  -o ODIR, --odir ODIR  Output directory\n  -b BATCH_SIZE, --batch_size BATCH_SIZE Batch Size\n  -c {call,put}, --callput {call,put}\n  -m {all,in,out,near}, --money {all,in,out,near}\n  -e EXCODE, --excode EXCODE excode\n  -x {week,stan,quart,cebo}, --expir {week,stan,quart,cebo}\n  -s {json,csv}, --serialize {json,csv} Serialization format\n```\n\n\n#### Serialization format (-s)\nYou have an option to output the data either in a CSV file or a JSON file.\nDefault format is CSV.\n\n#### Batch Size (-b)\nDefine how many records each csv or json file should have.\n\n\n### Examples\n1. To get all the option chain for XOM in a batch_size of 1000 and `csv` file format.\nThis will make sure that each CSV file has 1000 records in it.\nThe last file will have the remaining records\n\n```bash\noptions-scraper -t XOM -o /Users/abhishek/options_data -b 1000 -s csv\n```\n\n\n2. To get all option chain data for MSFT in a batch_size of 10 and `json` file format.\n```bash\noptions-scraper -t MSFT -o /Users/abhishek/options_data -b 10 -s json\n```\n\n3. To get all `put` options with weekly expiry.\n```bash\noptions-scraper -t XOM -e cbo -c put -x week -o /Users/abhishek/options_data\n```\n\n4. To get all `call` options with `cebo` expiry.\n```bash\noptions-scraper -t XOM -c call -x cebo -o /Users/abhishek/options_data\n```\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/aosingh/options_scraper", "keywords": "nasdaq options chain scraper", "license": "GNU GPLv3", "maintainer": "Abhishek Singh", "maintainer_email": "aosingh@asu.edu", "name": "options-scraper", "package_url": "https://pypi.org/project/options-scraper/", "platform": "", "project_url": "https://pypi.org/project/options-scraper/", "project_urls": {"Homepage": "https://github.com/aosingh/options_scraper"}, "release_url": "https://pypi.org/project/options-scraper/0.9.90/", "requires_dist": ["lxml", "requests", "urllib3"], "requires_python": "", "summary": "NASDAQ Options chain scraper for https://old.nasdaq.com", "version": "0.9.90", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>NASDAQ Options chain Scraper</h1>\n<p>Python Options Chain scraper for the old NASDAQ website : <a href=\"https://old.nasdaq.com\" rel=\"nofollow\">https://old.nasdaq.com</a></p>\n<h2>Install</h2>\n<pre>pip install options-scraper\n</pre>\n<h2>API</h2>\n<p>Use the API if you want to access the scraped data records ( as python objects ) directly.</p>\n<h3>Usage</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">options_scraper.scraper</span> <span class=\"kn\">import</span> <span class=\"n\">NASDAQOptionsScraper</span>\n<span class=\"kn\">from</span> <span class=\"nn\">options_scraper.utils</span> <span class=\"kn\">import</span> <span class=\"n\">batched</span>\n\n<span class=\"n\">scraper</span> <span class=\"o\">=</span> <span class=\"n\">NASDAQOptionsScraper</span><span class=\"p\">()</span>\n<span class=\"n\">ticker_symbol</span> <span class=\"o\">=</span> <span class=\"s1\">'XOM'</span>\n<span class=\"n\">kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span> <span class=\"s2\">\"money\"</span><span class=\"p\">:</span> <span class=\"s1\">'all'</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"expir\"</span><span class=\"p\">:</span> <span class=\"s1\">'week'</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"excode\"</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"callput\"</span><span class=\"p\">:</span> <span class=\"kc\">None</span>\n         <span class=\"p\">}</span>\n\n<span class=\"n\">records_generator</span> <span class=\"o\">=</span> <span class=\"n\">scraper</span><span class=\"p\">(</span><span class=\"n\">ticker_symbol</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Either access each record individually as shown below</span>\n<span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">records_generator</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Or use the batched util to get a list of items</span>\n<span class=\"k\">for</span> <span class=\"n\">items</span> <span class=\"ow\">in</span> <span class=\"n\">batched</span><span class=\"p\">(</span><span class=\"n\">records_generator</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">items</span><span class=\"p\">)</span>\n</pre>\n<h3>Output</h3>\n<p>Each scraped record will have the following structure</p>\n<pre><span class=\"p\">{</span><span class=\"s1\">'Ask'</span><span class=\"p\">:</span> <span class=\"s1\">'23.20'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Bid'</span><span class=\"p\">:</span> <span class=\"s1\">'18.50'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Calls'</span><span class=\"p\">:</span> <span class=\"s1\">'Apr 24, 2020'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Chg'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n <span class=\"s1\">'Last'</span><span class=\"p\">:</span> <span class=\"s1\">'19.40'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Open Int'</span><span class=\"p\">:</span> <span class=\"s1\">'15'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Puts'</span><span class=\"p\">:</span> <span class=\"s1\">'Apr 24, 2020'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Root'</span><span class=\"p\">:</span> <span class=\"s1\">'XOM'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Strike'</span><span class=\"p\">:</span> <span class=\"s1\">'60'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Vol'</span><span class=\"p\">:</span> <span class=\"s1\">'0'</span><span class=\"p\">}</span>\n\n<span class=\"p\">{</span><span class=\"s1\">'Ask'</span><span class=\"p\">:</span> <span class=\"s1\">'28.20'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Bid'</span><span class=\"p\">:</span> <span class=\"s1\">'23.50'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Calls'</span><span class=\"p\">:</span> <span class=\"s1\">'Apr 24, 2020'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Chg'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span>\n <span class=\"s1\">'Last'</span><span class=\"p\">:</span> <span class=\"s1\">'29.67'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Open Int'</span><span class=\"p\">:</span> <span class=\"s1\">'3'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Puts'</span><span class=\"p\">:</span> <span class=\"s1\">'Apr 24, 2020'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Root'</span><span class=\"p\">:</span> <span class=\"s1\">'XOM'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Strike'</span><span class=\"p\">:</span> <span class=\"s1\">'65'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Vol'</span><span class=\"p\">:</span> <span class=\"s1\">'0'</span><span class=\"p\">}</span>\n</pre>\n<h2>Console Script</h2>\n<p>Use this script to scrape records and save them either in CSV or JSON format.</p>\n<pre>options-scraper --help\n</pre>\n<pre>usage: options-scraper [-h]\n                       [-l {CRITICAL,FATAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}]\n                       [-t TICKER] \n                       [-o ODIR] \n                       [-b BATCH_SIZE] \n                       [-c {call,put}]\n                       [-m {all,in,out,near}] \n                       [-e EXCODE]\n                       [-x {week,stan,quart,cebo}] \n                       [-s {json,csv}]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -l {CRITICAL,FATAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}, --log-level {CRITICAL,FATAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}\n  -t TICKER, --ticker TICKER Ticker Symbol\n  -o ODIR, --odir ODIR  Output directory\n  -b BATCH_SIZE, --batch_size BATCH_SIZE Batch Size\n  -c {call,put}, --callput {call,put}\n  -m {all,in,out,near}, --money {all,in,out,near}\n  -e EXCODE, --excode EXCODE excode\n  -x {week,stan,quart,cebo}, --expir {week,stan,quart,cebo}\n  -s {json,csv}, --serialize {json,csv} Serialization format\n</pre>\n<h4>Serialization format (-s)</h4>\n<p>You have an option to output the data either in a CSV file or a JSON file.\nDefault format is CSV.</p>\n<h4>Batch Size (-b)</h4>\n<p>Define how many records each csv or json file should have.</p>\n<h3>Examples</h3>\n<ol>\n<li>To get all the option chain for XOM in a batch_size of 1000 and <code>csv</code> file format.\nThis will make sure that each CSV file has 1000 records in it.\nThe last file will have the remaining records</li>\n</ol>\n<pre>options-scraper -t XOM -o /Users/abhishek/options_data -b <span class=\"m\">1000</span> -s csv\n</pre>\n<ol>\n<li>To get all option chain data for MSFT in a batch_size of 10 and <code>json</code> file format.</li>\n</ol>\n<pre>options-scraper -t MSFT -o /Users/abhishek/options_data -b <span class=\"m\">10</span> -s json\n</pre>\n<ol>\n<li>To get all <code>put</code> options with weekly expiry.</li>\n</ol>\n<pre>options-scraper -t XOM -e cbo -c put -x week -o /Users/abhishek/options_data\n</pre>\n<ol>\n<li>To get all <code>call</code> options with <code>cebo</code> expiry.</li>\n</ol>\n<pre>options-scraper -t XOM -c call -x cebo -o /Users/abhishek/options_data\n</pre>\n\n          </div>"}, "last_serial": 6952865, "releases": {"0.9.80": [{"comment_text": "", "digests": {"md5": "7d0f200a0c7e8eafc277f7d8ecc6e8a4", "sha256": "530480ac9b669666aa495fea026a0c99eb4a08c5a12f05c3b344b3b72f2c89e9"}, "downloads": -1, "filename": "options_scraper-0.9.80-py3-none-any.whl", "has_sig": false, "md5_digest": "7d0f200a0c7e8eafc277f7d8ecc6e8a4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6079, "upload_time": "2020-04-04T18:58:16", "upload_time_iso_8601": "2020-04-04T18:58:16.717496Z", "url": "https://files.pythonhosted.org/packages/5d/2c/02416aba1c25d7701ff7c285ee0187e967033f6c04a3de501edf71863f78/options_scraper-0.9.80-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "692e9a0d5ed98c15b9225761e3c6ff00", "sha256": "5a0e2fb9b103f4057cca2fbefdef77a7793410ca70dd75221c368a6410ff426a"}, "downloads": -1, "filename": "options_scraper-0.9.80.tar.gz", "has_sig": false, "md5_digest": "692e9a0d5ed98c15b9225761e3c6ff00", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5591, "upload_time": "2020-04-04T18:58:19", "upload_time_iso_8601": "2020-04-04T18:58:19.007227Z", "url": "https://files.pythonhosted.org/packages/56/65/8ba02eb37751f1c896c408bd08971565baa3f9f955ad644c318b418b98b5/options_scraper-0.9.80.tar.gz", "yanked": false}], "0.9.90": [{"comment_text": "", "digests": {"md5": "f6e193c86c60f93913668ecb2b6271c7", "sha256": "311d1b86cf03b90e32eefa860d24a4d120edfb348839e934d0db9421dcbdb824"}, "downloads": -1, "filename": "options_scraper-0.9.90-py3-none-any.whl", "has_sig": false, "md5_digest": "f6e193c86c60f93913668ecb2b6271c7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6606, "upload_time": "2020-04-04T21:34:33", "upload_time_iso_8601": "2020-04-04T21:34:33.243958Z", "url": "https://files.pythonhosted.org/packages/20/51/a217a2c4aae36828fb480eed37467867468907834d806adee2f461423c54/options_scraper-0.9.90-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d3b919e0ed195422f92b8c1f50b8bd97", "sha256": "22b6e58f37e5858a9c4e9120041dfeb5ac254ad302cbb612784a36c6d62cf435"}, "downloads": -1, "filename": "options_scraper-0.9.90.tar.gz", "has_sig": false, "md5_digest": "d3b919e0ed195422f92b8c1f50b8bd97", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6207, "upload_time": "2020-04-04T21:34:34", "upload_time_iso_8601": "2020-04-04T21:34:34.650529Z", "url": "https://files.pythonhosted.org/packages/09/06/5ad3e77bb73e0caf40362e0ae45feb3c106698e2acc510115443b513e380/options_scraper-0.9.90.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f6e193c86c60f93913668ecb2b6271c7", "sha256": "311d1b86cf03b90e32eefa860d24a4d120edfb348839e934d0db9421dcbdb824"}, "downloads": -1, "filename": "options_scraper-0.9.90-py3-none-any.whl", "has_sig": false, "md5_digest": "f6e193c86c60f93913668ecb2b6271c7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6606, "upload_time": "2020-04-04T21:34:33", "upload_time_iso_8601": "2020-04-04T21:34:33.243958Z", "url": "https://files.pythonhosted.org/packages/20/51/a217a2c4aae36828fb480eed37467867468907834d806adee2f461423c54/options_scraper-0.9.90-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d3b919e0ed195422f92b8c1f50b8bd97", "sha256": "22b6e58f37e5858a9c4e9120041dfeb5ac254ad302cbb612784a36c6d62cf435"}, "downloads": -1, "filename": "options_scraper-0.9.90.tar.gz", "has_sig": false, "md5_digest": "d3b919e0ed195422f92b8c1f50b8bd97", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6207, "upload_time": "2020-04-04T21:34:34", "upload_time_iso_8601": "2020-04-04T21:34:34.650529Z", "url": "https://files.pythonhosted.org/packages/09/06/5ad3e77bb73e0caf40362e0ae45feb3c106698e2acc510115443b513e380/options_scraper-0.9.90.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:01:59 2020"}