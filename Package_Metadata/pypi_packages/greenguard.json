{"info": {"author": "MIT Data To AI Lab", "author_email": "dailabmit@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "<p align=\"left\">\n<img width=15% src=\"https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png\" alt=\"DAI\" />\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n\n<p align=\"left\">\n<img width=20% src=\"https://dai.lids.mit.edu/wp-content/uploads/2019/03/GreenGuard.png\" alt=\"GreenGuard\" />\n</p>\n\n<p align=\"left\">\nAutoML for Renewable Energy Industries.\n</p>\n\n\n[![PyPI Shield](https://img.shields.io/pypi/v/greenguard.svg)](https://pypi.python.org/pypi/greenguard)\n[![Travis CI Shield](https://travis-ci.org/D3-AI/GreenGuard.svg?branch=master)](https://travis-ci.org/D3-AI/GreenGuard)\n[![Downloads](https://pepy.tech/badge/greenguard)](https://pepy.tech/project/greenguard)\n<!--\n[![Coverage Status](https://codecov.io/gh/D3-AI/GreenGuard/branch/master/graph/badge.svg)](https://codecov.io/gh/D3-AI/GreenGuard)\n-->\n\n# GreenGuard\n\n- License: [MIT](https://github.com/D3-AI/GreenGuard/blob/master/LICENSE)\n- Documentation: https://D3-AI.github.io/GreenGuard\n- Homepage: https://github.com/D3-AI/GreenGuard\n\n# Overview\n\nThe GreenGuard project is a collection of end-to-end solutions for machine learning problems\ncommonly found in monitoring wind energy production systems. Most tasks utilize sensor data\nemanating from monitoring systems. We utilize the foundational innovations developed for\nautomation of machine Learning at Data to AI Lab at MIT.\n\nThe salient aspects of this customized project are:\n\n* A set of ready to use, well tested pipelines for different machine learning tasks. These are\n  vetted through testing across multiple publicly available datasets for the same task.\n* An easy interface to specify the task, pipeline, and generate results and summarize them.\n* A production ready, deployable pipeline.\n* An easy interface to ``tune`` pipelines using Bayesian Tuning and Bandits library.\n* A community oriented infrastructure to incorporate new pipelines.\n* A robust continuous integration and testing infrastructure.\n* A ``learning database`` recording all past outcomes --> tasks, pipelines, outcomes.\n\n# Install\n\n## Requirements\n\n**GreenGuard** has been developed and runs on Python 3.6 and 3.7.\n\nAlso, although it is not strictly required, the usage of a [virtualenv](\nhttps://virtualenv.pypa.io/en/latest/) is highly recommended in order to avoid interfering\nwith other software installed in the system where you are trying to run **GreenGuard**.\n\n## Download and Install\n\n**GreenGuard** can be installed locally using [pip](https://pip.pypa.io/en/stable/) with\nthe following command:\n\n```bash\npip install greenguard\n```\n\nThis will pull and install the latest stable release from [PyPi](https://pypi.org/).\n\nIf you want to install from source or contribute to the project please read the\n[Contributing Guide](https://d3-ai.github.io/GreenGuard/contributing.html#get-started).\n\n## Docker usage\n\nAlternatively, **GreenGuard** is prepared to be run inside a docker environment using\n`docker-compose`.\n\nFor this, make sure to have both [docker](https://docs.docker.com/install/) and [docker-compose](\nhttps://docs.docker.com/compose/install/) installed on your system and then follow these steps:\n\n1. Clone this repository and go into the `GreenGuard` folder:\n\n```bash\ngit clone git@github.com:D3-AI/GreenGuard.git\ncd GreenGuard\n```\n\n2. Start a Jupyter Notebook inside a docker container.\n\n```bash\ndocker-compose up --build\n```\n\n3. Point your browser at http://127.0.0.1:8888\n\n# Data Format\n\nThe minimum input expected by the **GreenGuard** system consists of the following two elements,\nwhich need to be passed as `pandas.DataFrame` objects:\n\n## Target Times\n\nA table containing the specification of the problem that we are solving, which has three\ncolumns:\n\n* `turbine_id`: Unique identifier of the turbine which this label corresponds to.\n* `cutoff_time`: Time associated with this target\n* `target`: The value that we want to predict. This can either be a numerical value or a\n  categorical label. This column can also be skipped when preparing data that will be used\n  only to make predictions and not to fit any pipeline.\n\n|    | turbine_id   | cutoff_time         |   target |\n|----|--------------|---------------------|----------|\n|  0 | T1           | 2001-01-02 00:00:00 |        0 |\n|  1 | T1           | 2001-01-03 00:00:00 |        1 |\n|  2 | T2           | 2001-01-04 00:00:00 |        0 |\n\n## Readings\n\nA table containing the signal data from the different sensors, with the following columns:\n\n  * `turbine_id`: Unique identifier of the turbine which this reading comes from.\n  * `signal_id`: Unique identifier of the signal which this reading comes from.\n  * `timestamp (datetime)`: Time where the reading took place, as a datetime.\n  * `value (float)`: Numeric value of this reading.\n\n|    | turbine_id   | signal_id   | timestamp           |   value |\n|----|--------------|-------------|---------------------|---------|\n|  0 | T1           | S1          | 2001-01-01 00:00:00 |       1 |\n|  1 | T1           | S1          | 2001-01-01 12:00:00 |       2 |\n|  2 | T1           | S1          | 2001-01-02 00:00:00 |       3 |\n|  3 | T1           | S1          | 2001-01-02 12:00:00 |       4 |\n|  4 | T1           | S1          | 2001-01-03 00:00:00 |       5 |\n|  5 | T1           | S1          | 2001-01-03 12:00:00 |       6 |\n|  6 | T1           | S2          | 2001-01-01 00:00:00 |       7 |\n|  7 | T1           | S2          | 2001-01-01 12:00:00 |       8 |\n|  8 | T1           | S2          | 2001-01-02 00:00:00 |       9 |\n|  9 | T1           | S2          | 2001-01-02 12:00:00 |      10 |\n| 10 | T1           | S2          | 2001-01-03 00:00:00 |      11 |\n| 11 | T1           | S2          | 2001-01-03 12:00:00 |      12 |\n\n## Turbines\n\nOptionally, a third table can be added containing metadata about the turbines.\nThe only requirement for this table is to have a `turbine_id` field, and it can have\nan arbitraty number of additional fields.\n\n|    | turbine_id   | manufacturer   | ...   | ...   | ...   |\n|----|--------------|----------------|-------|-------|-------|\n|  0 | T1           | Siemens        | ...   | ...   | ...   |\n|  1 | T2           | Siemens        | ...   | ...   | ...   |\n\n## CSV Format\n\nA part from the in-memory data format explained above, which is limited by the memory\nallocation capabilities of the system where it is run, **GreenGuard** is also prepared to\nload and work with data stored as a collection of CSV files, drastically increasing the amount\nof data which it can work with. Further details about this format can be found in the\n[project documentation site](https://d3-ai.github.io/GreenGuard/advanced_usage/csv.html).\n\n# Quickstart\n\nIn this example we will load some demo data and classify it using a **GreenGuard Pipeline**.\n\n## 1. Load and split the demo data\n\nThe first step is to load the demo data.\n\nFor this, we will import and call the `greenguard.demo.load_demo` function without any arguments:\n\n```python3\nfrom greenguard.demo import load_demo\n\ntarget_times, readings = load_demo()\n```\n\nThe returned objects are:\n\n*  ``target_times``: A ``pandas.DataFrame`` with the ``target_times`` table data:\n\n   ```\n     turbine_id cutoff_time  target\n   0       T001  2013-01-12       0\n   1       T001  2013-01-13       0\n   2       T001  2013-01-14       0\n   3       T001  2013-01-15       1\n   4       T001  2013-01-16       0\n   ```\n\n* ``readings``: A ``pandas.DataFrame`` containing the time series data in the format explained above.\n\n   ```\n     turbine_id signal_id  timestamp  value\n   0       T001       S01 2013-01-10  323.0\n   1       T001       S02 2013-01-10  320.0\n   2       T001       S03 2013-01-10  284.0\n   3       T001       S04 2013-01-10  348.0\n   4       T001       S05 2013-01-10  273.0\n   ```\n\nOnce we have loaded the `target_times` and before proceeding to training any Machine Learning\nPipeline, we will have split them in 2 partitions for training and testing.\n\nIn this case, we will split them using the [train_test_split function from scikit-learn](\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html),\nbut it can be done with any other suitable tool.\n\n```python3\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(target_times, test_size=0.25, random_state=0)\n```\n\nNotice how we are only splitting the `target_times` data and not the `readings`.\nThis is because the pipelines will later on take care of selecting the parts of the\n`readings` table needed for the training based on the information found inside\nthe `train` and `test` inputs.\n\nAdditionally, if we want to calculate a goodness-of-fit score later on, we can separate the\ntesting target values from the `test` table by popping them from it:\n\n```python3\ntest_targets = test.pop('target')\n```\n\n## 2. Exploring the available Pipelines\n\nOnce we have the data ready, we need to find a suitable pipeline.\n\nThe list of available GreenGuard Pipelines can be obtained using the `greenguard.get_pipelines`\nfunction.\n\n```python3\nfrom greenguard import get_pipelines\n\npipelines = get_pipelines()\n```\n\nThe returned `pipeline` variable will be `list` containing the names of all the pipelines\navailable in the GreenGuard system:\n\n```\n['resample_600s_normalize_dfs_1d_xgb_classifier',\n 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier',\n 'resample_600s_unstack_double_144_lstm_timeseries_classifier',\n 'resample_3600s_unstack_24_lstm_timeseries_classifier',\n 'resample_3600s_unstack_double_24_lstm_timeseries_classifier',\n 'resample_600s_unstack_dfs_1d_xgb_classifier',\n 'resample_600s_unstack_144_lstm_timeseries_classifier']\n```\n\nFor the rest of this tutorial, we will select and use the pipeline\n`resample_600s_unstack_normalize_dfs_1d_xgb_classifier` as our template.\n\n```python3\npipeline_name = 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier'\n```\n\n## 3. Fitting the Pipeline\n\nOnce we have loaded the data and selected the pipeline that we will use, we have to\nfit it.\n\nFor this, we will create an instance of a `GreenGuardPipeline` object passing the name\nof the pipeline that we want to use:\n\n```python3\nfrom greenguard.pipeline import GreenGuardPipeline\n\npipeline = GreenGuardPipeline(pipeline_name)\n```\n\nAnd then we can directly fit it to our data by calling its `fit` method and passing in the\ntraining `target_times` and the complete `readings` table:\n\n```python3\npipeline.fit(train, readings)\n```\n\n## 4. Make predictions\n\nAfter fitting the pipeline, we are ready to make predictions on new data by calling the\n`pipeline.predict` method passing the testing `target_times` and, again, the complete\n`readings` table.\n\n```python3\npredictions = pipeline.predict(test, readings)\n```\n\n## 5. Evaluate the goodness-of-fit\n\nFinally, after making predictions we can evaluate how good the prediction was\nusing any suitable metric.\n\n```python3\nfrom sklearn.metrics import f1_score\n\nf1_score(test_targets, predictions)\n```\n\n## What's next?\n\nFor more details about **GreenGuard** and all its possibilities and features, please check the\n[project documentation site](https://D3-AI.github.io/GreenGuard/)\nAlso do not forget to have a look at the [notebook tutorials](\nhttps://github.com/D3-AI/GreenGuard/tree/master/notebooks)!\n\n\n# History\n\n## 0.2.0 - 2020-02-14\n\nFirst stable release:\n\n* efficient data loading and preprocessing\n* initial collection of dfs and lstm based pipelines\n* optimized pipeline tuning\n* documentation and tutorials\n\n## 0.1.0\n\n* First release on PyPI\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/D3-AI/GreenGuard", "keywords": "wind machine learning greenguard", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "greenguard", "package_url": "https://pypi.org/project/greenguard/", "platform": "", "project_url": "https://pypi.org/project/greenguard/", "project_urls": {"Homepage": "https://github.com/D3-AI/GreenGuard"}, "release_url": "https://pypi.org/project/greenguard/0.2.0/", "requires_dist": ["mlblocks (<0.4,>=0.3.4)", "mlprimitives (<0.3,>=0.2.4)", "baytune (<0.3,>=0.2.3)", "numpy (<1.17,>=1.15.4)", "pymongo (<4,>=3.7.2)", "scikit-learn (<0.21,>=0.20.1)", "dask (<3,>=2.6.0)", "bumpversion (>=0.5.3) ; extra == 'dev'", "pip (>=9.0.1) ; extra == 'dev'", "watchdog (>=0.8.3) ; extra == 'dev'", "m2r (>=0.2.0) ; extra == 'dev'", "Sphinx (<2.4,>=1.7.1) ; extra == 'dev'", "sphinx-rtd-theme (>=0.2.4) ; extra == 'dev'", "autodocsumm (>=0.1.10) ; extra == 'dev'", "flake8 (>=3.7.7) ; extra == 'dev'", "isort (>=4.3.4) ; extra == 'dev'", "autoflake (>=1.2) ; extra == 'dev'", "autopep8 (>=1.4.3) ; extra == 'dev'", "twine (>=1.10.0) ; extra == 'dev'", "wheel (>=0.30.0) ; extra == 'dev'", "coverage (>=4.5.1) ; extra == 'dev'", "tox (>=2.9.1) ; extra == 'dev'", "jupyter (>=1.0.0) ; extra == 'dev'", "pytest (>=3.4.2) ; extra == 'dev'", "pytest-cov (>=2.6.0) ; extra == 'dev'", "rundoc (>=0.4.3) ; extra == 'dev'", "pytest (>=3.4.2) ; extra == 'test'", "pytest-cov (>=2.6.0) ; extra == 'test'", "rundoc (>=0.4.3) ; extra == 'test'"], "requires_python": ">=3.5", "summary": "AutoML for Renewable Energy Industries.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"left\">\n<img alt=\"DAI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80df0970db0e9e95cce463bc9fa595caf90dd1c7/68747470733a2f2f6461692e6c6964732e6d69742e6564752f77702d636f6e74656e742f75706c6f6164732f323031382f30362f4c6f676f5f4441495f686967687265732e706e67\" width=\"15%\">\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n<p align=\"left\">\n<img alt=\"GreenGuard\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/29a61ae5d4f93c00252f366785ea2513a395720f/68747470733a2f2f6461692e6c6964732e6d69742e6564752f77702d636f6e74656e742f75706c6f6164732f323031392f30332f477265656e47756172642e706e67\" width=\"20%\">\n</p>\n<p align=\"left\">\nAutoML for Renewable Energy Industries.\n</p>\n<p><a href=\"https://pypi.python.org/pypi/greenguard\" rel=\"nofollow\"><img alt=\"PyPI Shield\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dda7db2ca99c8b70dec07c7d91d11b4a02482f1f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f677265656e67756172642e737667\"></a>\n<a href=\"https://travis-ci.org/D3-AI/GreenGuard\" rel=\"nofollow\"><img alt=\"Travis CI Shield\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/888ddc21309addcd6dfc29fd5d9e6eacda66db08/68747470733a2f2f7472617669732d63692e6f72672f44332d41492f477265656e47756172642e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pepy.tech/project/greenguard\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b808640eb651b7e0063e485a1d3e4fb4e8b95543/68747470733a2f2f706570792e746563682f62616467652f677265656e6775617264\"></a></p>\n\n<h1>GreenGuard</h1>\n<ul>\n<li>License: <a href=\"https://github.com/D3-AI/GreenGuard/blob/master/LICENSE\" rel=\"nofollow\">MIT</a></li>\n<li>Documentation: <a href=\"https://D3-AI.github.io/GreenGuard\" rel=\"nofollow\">https://D3-AI.github.io/GreenGuard</a></li>\n<li>Homepage: <a href=\"https://github.com/D3-AI/GreenGuard\" rel=\"nofollow\">https://github.com/D3-AI/GreenGuard</a></li>\n</ul>\n<h1>Overview</h1>\n<p>The GreenGuard project is a collection of end-to-end solutions for machine learning problems\ncommonly found in monitoring wind energy production systems. Most tasks utilize sensor data\nemanating from monitoring systems. We utilize the foundational innovations developed for\nautomation of machine Learning at Data to AI Lab at MIT.</p>\n<p>The salient aspects of this customized project are:</p>\n<ul>\n<li>A set of ready to use, well tested pipelines for different machine learning tasks. These are\nvetted through testing across multiple publicly available datasets for the same task.</li>\n<li>An easy interface to specify the task, pipeline, and generate results and summarize them.</li>\n<li>A production ready, deployable pipeline.</li>\n<li>An easy interface to <code>tune</code> pipelines using Bayesian Tuning and Bandits library.</li>\n<li>A community oriented infrastructure to incorporate new pipelines.</li>\n<li>A robust continuous integration and testing infrastructure.</li>\n<li>A <code>learning database</code> recording all past outcomes --&gt; tasks, pipelines, outcomes.</li>\n</ul>\n<h1>Install</h1>\n<h2>Requirements</h2>\n<p><strong>GreenGuard</strong> has been developed and runs on Python 3.6 and 3.7.</p>\n<p>Also, although it is not strictly required, the usage of a <a href=\"https://virtualenv.pypa.io/en/latest/\" rel=\"nofollow\">virtualenv</a> is highly recommended in order to avoid interfering\nwith other software installed in the system where you are trying to run <strong>GreenGuard</strong>.</p>\n<h2>Download and Install</h2>\n<p><strong>GreenGuard</strong> can be installed locally using <a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip</a> with\nthe following command:</p>\n<pre>pip install greenguard\n</pre>\n<p>This will pull and install the latest stable release from <a href=\"https://pypi.org/\" rel=\"nofollow\">PyPi</a>.</p>\n<p>If you want to install from source or contribute to the project please read the\n<a href=\"https://d3-ai.github.io/GreenGuard/contributing.html#get-started\" rel=\"nofollow\">Contributing Guide</a>.</p>\n<h2>Docker usage</h2>\n<p>Alternatively, <strong>GreenGuard</strong> is prepared to be run inside a docker environment using\n<code>docker-compose</code>.</p>\n<p>For this, make sure to have both <a href=\"https://docs.docker.com/install/\" rel=\"nofollow\">docker</a> and <a href=\"https://docs.docker.com/compose/install/\" rel=\"nofollow\">docker-compose</a> installed on your system and then follow these steps:</p>\n<ol>\n<li>Clone this repository and go into the <code>GreenGuard</code> folder:</li>\n</ol>\n<pre>git clone git@github.com:D3-AI/GreenGuard.git\n<span class=\"nb\">cd</span> GreenGuard\n</pre>\n<ol>\n<li>Start a Jupyter Notebook inside a docker container.</li>\n</ol>\n<pre>docker-compose up --build\n</pre>\n<ol>\n<li>Point your browser at <a href=\"http://127.0.0.1:8888\" rel=\"nofollow\">http://127.0.0.1:8888</a></li>\n</ol>\n<h1>Data Format</h1>\n<p>The minimum input expected by the <strong>GreenGuard</strong> system consists of the following two elements,\nwhich need to be passed as <code>pandas.DataFrame</code> objects:</p>\n<h2>Target Times</h2>\n<p>A table containing the specification of the problem that we are solving, which has three\ncolumns:</p>\n<ul>\n<li><code>turbine_id</code>: Unique identifier of the turbine which this label corresponds to.</li>\n<li><code>cutoff_time</code>: Time associated with this target</li>\n<li><code>target</code>: The value that we want to predict. This can either be a numerical value or a\ncategorical label. This column can also be skipped when preparing data that will be used\nonly to make predictions and not to fit any pipeline.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>turbine_id</th>\n<th>cutoff_time</th>\n<th>target</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>T1</td>\n<td>2001-01-02 00:00:00</td>\n<td>0</td>\n</tr>\n<tr>\n<td>1</td>\n<td>T1</td>\n<td>2001-01-03 00:00:00</td>\n<td>1</td>\n</tr>\n<tr>\n<td>2</td>\n<td>T2</td>\n<td>2001-01-04 00:00:00</td>\n<td>0</td>\n</tr></tbody></table>\n<h2>Readings</h2>\n<p>A table containing the signal data from the different sensors, with the following columns:</p>\n<ul>\n<li><code>turbine_id</code>: Unique identifier of the turbine which this reading comes from.</li>\n<li><code>signal_id</code>: Unique identifier of the signal which this reading comes from.</li>\n<li><code>timestamp (datetime)</code>: Time where the reading took place, as a datetime.</li>\n<li><code>value (float)</code>: Numeric value of this reading.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>turbine_id</th>\n<th>signal_id</th>\n<th>timestamp</th>\n<th>value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>T1</td>\n<td>S1</td>\n<td>2001-01-01 00:00:00</td>\n<td>1</td>\n</tr>\n<tr>\n<td>1</td>\n<td>T1</td>\n<td>S1</td>\n<td>2001-01-01 12:00:00</td>\n<td>2</td>\n</tr>\n<tr>\n<td>2</td>\n<td>T1</td>\n<td>S1</td>\n<td>2001-01-02 00:00:00</td>\n<td>3</td>\n</tr>\n<tr>\n<td>3</td>\n<td>T1</td>\n<td>S1</td>\n<td>2001-01-02 12:00:00</td>\n<td>4</td>\n</tr>\n<tr>\n<td>4</td>\n<td>T1</td>\n<td>S1</td>\n<td>2001-01-03 00:00:00</td>\n<td>5</td>\n</tr>\n<tr>\n<td>5</td>\n<td>T1</td>\n<td>S1</td>\n<td>2001-01-03 12:00:00</td>\n<td>6</td>\n</tr>\n<tr>\n<td>6</td>\n<td>T1</td>\n<td>S2</td>\n<td>2001-01-01 00:00:00</td>\n<td>7</td>\n</tr>\n<tr>\n<td>7</td>\n<td>T1</td>\n<td>S2</td>\n<td>2001-01-01 12:00:00</td>\n<td>8</td>\n</tr>\n<tr>\n<td>8</td>\n<td>T1</td>\n<td>S2</td>\n<td>2001-01-02 00:00:00</td>\n<td>9</td>\n</tr>\n<tr>\n<td>9</td>\n<td>T1</td>\n<td>S2</td>\n<td>2001-01-02 12:00:00</td>\n<td>10</td>\n</tr>\n<tr>\n<td>10</td>\n<td>T1</td>\n<td>S2</td>\n<td>2001-01-03 00:00:00</td>\n<td>11</td>\n</tr>\n<tr>\n<td>11</td>\n<td>T1</td>\n<td>S2</td>\n<td>2001-01-03 12:00:00</td>\n<td>12</td>\n</tr></tbody></table>\n<h2>Turbines</h2>\n<p>Optionally, a third table can be added containing metadata about the turbines.\nThe only requirement for this table is to have a <code>turbine_id</code> field, and it can have\nan arbitraty number of additional fields.</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>turbine_id</th>\n<th>manufacturer</th>\n<th>...</th>\n<th>...</th>\n<th>...</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>T1</td>\n<td>Siemens</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n</tr>\n<tr>\n<td>1</td>\n<td>T2</td>\n<td>Siemens</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n</tr></tbody></table>\n<h2>CSV Format</h2>\n<p>A part from the in-memory data format explained above, which is limited by the memory\nallocation capabilities of the system where it is run, <strong>GreenGuard</strong> is also prepared to\nload and work with data stored as a collection of CSV files, drastically increasing the amount\nof data which it can work with. Further details about this format can be found in the\n<a href=\"https://d3-ai.github.io/GreenGuard/advanced_usage/csv.html\" rel=\"nofollow\">project documentation site</a>.</p>\n<h1>Quickstart</h1>\n<p>In this example we will load some demo data and classify it using a <strong>GreenGuard Pipeline</strong>.</p>\n<h2>1. Load and split the demo data</h2>\n<p>The first step is to load the demo data.</p>\n<p>For this, we will import and call the <code>greenguard.demo.load_demo</code> function without any arguments:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">greenguard.demo</span> <span class=\"kn\">import</span> <span class=\"n\">load_demo</span>\n\n<span class=\"n\">target_times</span><span class=\"p\">,</span> <span class=\"n\">readings</span> <span class=\"o\">=</span> <span class=\"n\">load_demo</span><span class=\"p\">()</span>\n</pre>\n<p>The returned objects are:</p>\n<ul>\n<li>\n<p><code>target_times</code>: A <code>pandas.DataFrame</code> with the <code>target_times</code> table data:</p>\n<pre><code>  turbine_id cutoff_time  target\n0       T001  2013-01-12       0\n1       T001  2013-01-13       0\n2       T001  2013-01-14       0\n3       T001  2013-01-15       1\n4       T001  2013-01-16       0\n</code></pre>\n</li>\n<li>\n<p><code>readings</code>: A <code>pandas.DataFrame</code> containing the time series data in the format explained above.</p>\n<pre><code>  turbine_id signal_id  timestamp  value\n0       T001       S01 2013-01-10  323.0\n1       T001       S02 2013-01-10  320.0\n2       T001       S03 2013-01-10  284.0\n3       T001       S04 2013-01-10  348.0\n4       T001       S05 2013-01-10  273.0\n</code></pre>\n</li>\n</ul>\n<p>Once we have loaded the <code>target_times</code> and before proceeding to training any Machine Learning\nPipeline, we will have split them in 2 partitions for training and testing.</p>\n<p>In this case, we will split them using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" rel=\"nofollow\">train_test_split function from scikit-learn</a>,\nbut it can be done with any other suitable tool.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n\n<span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">target_times</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.25</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Notice how we are only splitting the <code>target_times</code> data and not the <code>readings</code>.\nThis is because the pipelines will later on take care of selecting the parts of the\n<code>readings</code> table needed for the training based on the information found inside\nthe <code>train</code> and <code>test</code> inputs.</p>\n<p>Additionally, if we want to calculate a goodness-of-fit score later on, we can separate the\ntesting target values from the <code>test</code> table by popping them from it:</p>\n<pre><span class=\"n\">test_targets</span> <span class=\"o\">=</span> <span class=\"n\">test</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span><span class=\"s1\">'target'</span><span class=\"p\">)</span>\n</pre>\n<h2>2. Exploring the available Pipelines</h2>\n<p>Once we have the data ready, we need to find a suitable pipeline.</p>\n<p>The list of available GreenGuard Pipelines can be obtained using the <code>greenguard.get_pipelines</code>\nfunction.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">greenguard</span> <span class=\"kn\">import</span> <span class=\"n\">get_pipelines</span>\n\n<span class=\"n\">pipelines</span> <span class=\"o\">=</span> <span class=\"n\">get_pipelines</span><span class=\"p\">()</span>\n</pre>\n<p>The returned <code>pipeline</code> variable will be <code>list</code> containing the names of all the pipelines\navailable in the GreenGuard system:</p>\n<pre><code>['resample_600s_normalize_dfs_1d_xgb_classifier',\n 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier',\n 'resample_600s_unstack_double_144_lstm_timeseries_classifier',\n 'resample_3600s_unstack_24_lstm_timeseries_classifier',\n 'resample_3600s_unstack_double_24_lstm_timeseries_classifier',\n 'resample_600s_unstack_dfs_1d_xgb_classifier',\n 'resample_600s_unstack_144_lstm_timeseries_classifier']\n</code></pre>\n<p>For the rest of this tutorial, we will select and use the pipeline\n<code>resample_600s_unstack_normalize_dfs_1d_xgb_classifier</code> as our template.</p>\n<pre><span class=\"n\">pipeline_name</span> <span class=\"o\">=</span> <span class=\"s1\">'resample_600s_unstack_normalize_dfs_1d_xgb_classifier'</span>\n</pre>\n<h2>3. Fitting the Pipeline</h2>\n<p>Once we have loaded the data and selected the pipeline that we will use, we have to\nfit it.</p>\n<p>For this, we will create an instance of a <code>GreenGuardPipeline</code> object passing the name\nof the pipeline that we want to use:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">greenguard.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">GreenGuardPipeline</span>\n\n<span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">GreenGuardPipeline</span><span class=\"p\">(</span><span class=\"n\">pipeline_name</span><span class=\"p\">)</span>\n</pre>\n<p>And then we can directly fit it to our data by calling its <code>fit</code> method and passing in the\ntraining <code>target_times</code> and the complete <code>readings</code> table:</p>\n<pre><span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">readings</span><span class=\"p\">)</span>\n</pre>\n<h2>4. Make predictions</h2>\n<p>After fitting the pipeline, we are ready to make predictions on new data by calling the\n<code>pipeline.predict</code> method passing the testing <code>target_times</code> and, again, the complete\n<code>readings</code> table.</p>\n<pre><span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">test</span><span class=\"p\">,</span> <span class=\"n\">readings</span><span class=\"p\">)</span>\n</pre>\n<h2>5. Evaluate the goodness-of-fit</h2>\n<p>Finally, after making predictions we can evaluate how good the prediction was\nusing any suitable metric.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">f1_score</span>\n\n<span class=\"n\">f1_score</span><span class=\"p\">(</span><span class=\"n\">test_targets</span><span class=\"p\">,</span> <span class=\"n\">predictions</span><span class=\"p\">)</span>\n</pre>\n<h2>What's next?</h2>\n<p>For more details about <strong>GreenGuard</strong> and all its possibilities and features, please check the\n<a href=\"https://D3-AI.github.io/GreenGuard/\" rel=\"nofollow\">project documentation site</a>\nAlso do not forget to have a look at the <a href=\"https://github.com/D3-AI/GreenGuard/tree/master/notebooks\" rel=\"nofollow\">notebook tutorials</a>!</p>\n<h1>History</h1>\n<h2>0.2.0 - 2020-02-14</h2>\n<p>First stable release:</p>\n<ul>\n<li>efficient data loading and preprocessing</li>\n<li>initial collection of dfs and lstm based pipelines</li>\n<li>optimized pipeline tuning</li>\n<li>documentation and tutorials</li>\n</ul>\n<h2>0.1.0</h2>\n<ul>\n<li>First release on PyPI</li>\n</ul>\n\n          </div>"}, "last_serial": 6631783, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "eec5c940cc930b9337d5cc0dabc71d14", "sha256": "b4d7e3a29b2dcfafe1683f1b76b5f57d5e8da1b635202765f2c6aeec641b4aa1"}, "downloads": -1, "filename": "greenguard-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "eec5c940cc930b9337d5cc0dabc71d14", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5", "size": 15207, "upload_time": "2019-04-12T08:57:24", "upload_time_iso_8601": "2019-04-12T08:57:24.358645Z", "url": "https://files.pythonhosted.org/packages/f8/cf/4c2949e4c264cf00e7cd2818f2db11dd450ccaa7ac843fac69fcaf2cb622/greenguard-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9821d5a7b0700488710f463e967fa236", "sha256": "2adf28804a2ee36b0aa07e887e8ed69d12698bf8c074414eea49f0f4074a39a3"}, "downloads": -1, "filename": "greenguard-0.1.0.tar.gz", "has_sig": false, "md5_digest": "9821d5a7b0700488710f463e967fa236", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 33734, "upload_time": "2019-04-12T08:57:27", "upload_time_iso_8601": "2019-04-12T08:57:27.646056Z", "url": "https://files.pythonhosted.org/packages/e1/5f/56cd7e3ac0c898c8e7fe36dcc1eec0167e00e9177eaaf9eea5f48feda1a7/greenguard-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "bb09feb32aada89cfd5e9509a8349543", "sha256": "a4c653944e320d82cbb083d0dc262b47930b134c7ad18ad55ff8b8cd91583ec7"}, "downloads": -1, "filename": "greenguard-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bb09feb32aada89cfd5e9509a8349543", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5", "size": 20272, "upload_time": "2020-02-14T14:54:15", "upload_time_iso_8601": "2020-02-14T14:54:15.337316Z", "url": "https://files.pythonhosted.org/packages/43/b3/30036b5700261ce38ccbe6ca35342c03d99ce05e616cb04bfe37ce77c7c4/greenguard-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ed01a54e2365ea231e3f46c9ad6b7852", "sha256": "925652eeaeb849abee56a3e5e8790b5825afb66ede6216bc2bad9077d616b494"}, "downloads": -1, "filename": "greenguard-0.2.0.tar.gz", "has_sig": false, "md5_digest": "ed01a54e2365ea231e3f46c9ad6b7852", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 899570, "upload_time": "2020-02-14T14:54:17", "upload_time_iso_8601": "2020-02-14T14:54:17.752878Z", "url": "https://files.pythonhosted.org/packages/21/a1/b9cf46f816bddc538c9fc9cac6310993e69888b799a9e1d216be059ec6b8/greenguard-0.2.0.tar.gz", "yanked": false}], "0.2.0.dev0": [{"comment_text": "", "digests": {"md5": "f398b5e3b4290d2e9da1857693d40c41", "sha256": "08245b983cbde18410b22e729dbe8526eee1bdf4b6a9c9e521877c8b66ab8818"}, "downloads": -1, "filename": "greenguard-0.2.0.dev0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f398b5e3b4290d2e9da1857693d40c41", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5", "size": 20072, "upload_time": "2020-02-11T15:57:12", "upload_time_iso_8601": "2020-02-11T15:57:12.995084Z", "url": "https://files.pythonhosted.org/packages/57/5b/289342d7a40c44ac60f25dd060aafbe2f812116fc406eebc55e74682ab1c/greenguard-0.2.0.dev0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a53378c60771686be6c5d85dc4281693", "sha256": "6e2e5ff2584cc9327da906afe752b227e38ac907fb6360528111acabfc6b1435"}, "downloads": -1, "filename": "greenguard-0.2.0.dev0.tar.gz", "has_sig": false, "md5_digest": "a53378c60771686be6c5d85dc4281693", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 899068, "upload_time": "2020-02-11T15:57:15", "upload_time_iso_8601": "2020-02-11T15:57:15.401183Z", "url": "https://files.pythonhosted.org/packages/ac/77/c59875ce1c47026caccaaa163e8be8d63c49fe7406ce8647a9d0db28432a/greenguard-0.2.0.dev0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bb09feb32aada89cfd5e9509a8349543", "sha256": "a4c653944e320d82cbb083d0dc262b47930b134c7ad18ad55ff8b8cd91583ec7"}, "downloads": -1, "filename": "greenguard-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bb09feb32aada89cfd5e9509a8349543", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5", "size": 20272, "upload_time": "2020-02-14T14:54:15", "upload_time_iso_8601": "2020-02-14T14:54:15.337316Z", "url": "https://files.pythonhosted.org/packages/43/b3/30036b5700261ce38ccbe6ca35342c03d99ce05e616cb04bfe37ce77c7c4/greenguard-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ed01a54e2365ea231e3f46c9ad6b7852", "sha256": "925652eeaeb849abee56a3e5e8790b5825afb66ede6216bc2bad9077d616b494"}, "downloads": -1, "filename": "greenguard-0.2.0.tar.gz", "has_sig": false, "md5_digest": "ed01a54e2365ea231e3f46c9ad6b7852", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 899570, "upload_time": "2020-02-14T14:54:17", "upload_time_iso_8601": "2020-02-14T14:54:17.752878Z", "url": "https://files.pythonhosted.org/packages/21/a1/b9cf46f816bddc538c9fc9cac6310993e69888b799a9e1d216be059ec6b8/greenguard-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:54:20 2020"}