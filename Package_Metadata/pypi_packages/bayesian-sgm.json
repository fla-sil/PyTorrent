{"info": {"author": "Abner", "author_email": "abnersousanascimento@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Natural Language :: Portuguese (Brazilian)", "Operating System :: OS Independent", "Programming Language :: Python :: 3.0", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Image Recognition"], "description": "# Segmenta\u00e7\u00e3o Bayesiana de Cores em Imagens\n\n\n![PyPI](https://img.shields.io/pypi/v/nine.svg?style=flat-square)\n![GitHub release](https://img.shields.io/github/release/abnersn/bayesian_sgm.svg?style=flat-square)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/Django.svg?style=flat-square)\n[![Twitter Follow](https://img.shields.io/twitter/follow/asnasc.svg?style=flat-square&label=Follow)](https://twitter.com/asnasc) \n\n\nEste trabalho prop\u00f5e o uso de um classificador Naive Bayes para a tarefa de segmenta\u00e7\u00e3o de imagens por cor, empregando duas classes de dados em seu modelo estat\u00edstico: pele e n\u00e3o-pele. Busca-se assim, obter um algoritmo de segmenta\u00e7\u00e3o por cor dotado de bons n\u00edveis de precis\u00e3o e velocidade suficiente para ser aplicado em filmagens em tempo real em um computador pessoal.\n\n## Pr\u00e9-requisitos\n* Python 3.5.5\n* OpenCV 3.1.0 ou superior\n* Numpy 1.14.3 ou superior\n\n## Instala\u00e7\u00e3o\nAp\u00f3s a instala\u00e7\u00e3o dos pr\u00e9-requisitos, \u00e9 poss\u00edvel instalar o segmentador pelo reposit\u00f3rio de pacotes do python com o comando:\n```\n$ sudo pip install bayesian_sgm\n```\n## Exemplo\nAs imagens de treino e as respectivas vers\u00f5es bin\u00e1rias devem ser organizadas com o mesmo nome de arquivo, por\u00e9m em pastas diferentes. No exemplo abaixo, as imagens coloridas est\u00e3o na pasta `n_dataset`, e a classifica\u00e7\u00e3o bin\u00e1ria em `c_dataset`.\n```\n.\n\u251c\u2500\u2500 datasets\n\u2502   \u251c\u2500\u2500 c_dataset\n\u2502   \u2502   \u251c\u2500\u2500 treino1.jpg\n\u2502   \u2502   \u251c\u2500\u2500 treino2.jpg\n\u2502   \u2502   \u251c\u2500\u2500 treino3.jpg\n\u2502   \u2502   \u251c\u2500\u2500 treino4.jpg\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 n_dataset\n\u2502       \u251c\u2500\u2500 treino1.jpg\n\u2502       \u251c\u2500\u2500 treino2.jpg\n\u2502       \u251c\u2500\u2500 treino3.jpg\n\u2502       \u251c\u2500\u2500 treino4.jpg\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 script.py\n```\nO arquivo `script.py` realiza o treinamento com base no dataset fornecido e aplica o segmentador no v\u00eddeo capturado pela webcam.\n```python\nimport cv2\nimport numpy as np\nimport bayesian_sgm\n\nseg = bayesian_sgm.BayesianColorSGM()\nseg.learn_from_dirs(\"datasets/c_dataset\", \"datasets/n_dataset\")\n\ncap = cv2.VideoCapture(0)\nwhile(True):\n    ret, img = cap.read()\n    bin = seg.apply(img)\n    cv2.imshow(\"frame\", img)\n    cv2.imshow(\"binary\", bin)\n    k = cv2.waitKey(30) & 0xFF\n    if k == 27:\n        break\n```\n\n## Fundamenta\u00e7\u00e3o Te\u00f3rica\n\n### Introdu\u00e7\u00e3o\n\nA separa\u00e7\u00e3o de regi\u00f5es correspondentes \u00e0 pele humana em imagens digitais possui fundamental import\u00e2ncia para a solu\u00e7\u00e3o de problemas relacionados \u00e0 vis\u00e3o computacional, como detec\u00e7\u00e3o de face, detec\u00e7\u00e3o de gestos e classifica\u00e7\u00e3o de conte\u00fado. Tais aplica\u00e7\u00f5es empregam algoritmos de segmenta\u00e7\u00e3o com o objetivo de delimitar \u00e1reas de interesse nas imagens, de modo a reduzir o escopo de informa\u00e7\u00f5es a serem processadas e obter ganhos de desempenho.\n\nDiversas s\u00e3o as t\u00e9cnicas envolvidas na tarefa de segmenta\u00e7\u00e3o de imagens, como k-means e outras formas de reconhecimento de padr\u00f5es. Por\u00e9m, devido \u00e0s suas propriedades f\u00edsicas e forma peculiar de interagir com a luz, a pele humana possui caracter\u00edsticas visuais que a diferenciam de elementos inorg\u00e2nicos, o que traz vantagem a abordagens baseadas na cor. De fato, o espectro de tonalidades da pele humana \u00e9 relativamente limitado, mesmo levando em considera\u00e7\u00e3o varia\u00e7\u00f5es \u00e9tnicas.\n\nO problema resume-se, ent\u00e3o, a determinar se um dado conjunto de pixels pertence ou n\u00e3o a uma regi\u00e3o de pele humana com base em sua cor. Nesse contexto, a escolha do espa\u00e7o de cores mais adequado aos matizes da pele humana, bem como o emprego de um modelo estat\u00edstico que permita analisar um conjunto previamente classificado de imagens pode ser uma solu\u00e7\u00e3o eficaz. Tais escolhas est\u00e3o intrinsecamente relacionadas \u00e0 sensibilidade dos algoritmos de segmenta\u00e7\u00e3o a problemas como condi\u00e7\u00f5es de ilumina\u00e7\u00e3o desfavor\u00e1veis e oclus\u00e3o.\n\n### Metodologia\n\nO teorema de Bayes, nomeado em homenagem a seu idealizador, Thomas Bayes (1701-1761), estabelece uma rela\u00e7\u00e3o matem\u00e1tica para as probabilidades de eventos condicionados a evid\u00eancias pr\u00e9vias. A probabilidade de um evento A, dado que houve a observa\u00e7\u00e3o de uma evid\u00eancia B \u00e9 descrita por:\n\n![](https://latex.codecogs.com/gif.latex?P%28A%7CB%29%3D%5Cfrac%7BP%28B%7CA%29%5Ctimes%7BP%28A%29%7D%7D%7BP%28B%29%7D).\n\nEste princ\u00edpio possui diversas aplica\u00e7\u00f5es no campo da infer\u00eancia estat\u00edstica, em problemas que demandam a dedu\u00e7\u00e3o de informa\u00e7\u00f5es a partir da an\u00e1lise de um conjunto de amostras. Filtros de spam, por exemplo, analisam o texto de diversos emails classificados pelos usu\u00e1rios como spam e n\u00e3o-spam e determinam a classe na qual se enquadra uma nova amostra com base na equa\u00e7\u00e3o acima.\n\nClassificadores Naive Bayes consideram que as caracter\u00edsticas analisadas s\u00e3o independentes entre si. Isto \u00e9, para um conjunto ![](https://latex.codecogs.com/gif.latex?A%3D%7BA_1%2CA_2%2C%5Ccdots%2CA_n%7D) de caracter\u00edsticas condicionadas a uma evid\u00eancia ![](https://latex.codecogs.com/gif.latex?B), tem-se o produt\u00f3rio:\n\n![](https://latex.codecogs.com/gif.latex?P%28A_1%2CA_2%2C%5Ccdots%2CA_n%7CB%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bn%7D%20P%28A_i%7CB%29.)\n\nTal pressuposto, embora possa comprometer a coer\u00eancia entre o modelo e a rela\u00e7\u00e3o que de fato ocorre entre os dados, \u00e9 capaz de classificar as amostras com n\u00edveis de erro pr\u00f3ximos aos de m\u00e9todos mais robustos.\n\nEsta modelagem matem\u00e1tica pode ser aplicada para a segmenta\u00e7\u00e3o de imagens como uma t\u00e9cnica de classifica\u00e7\u00e3o de pixels em duas classes: pele e n\u00e3o-pele. Para imagens representadas em espa\u00e7os de cor de 3 canais, por exemplo, considera-se que o evento A representa o fato de um pixel pertencer a uma regi\u00e3o de pele. B corresponde ao valor num\u00e9rico que um pixel assume em determinado canal. Logo, primeiramente \u00e9 necess\u00e1rio obter ![](https://latex.codecogs.com/gif.latex?P%28A%29), ![](https://latex.codecogs.com/gif.latex?P%28B%7CA%29) e ![](https://latex.codecogs.com/gif.latex?P%28B%29), conhecidos como probabilidades *a priori*. De forma intuitiva, tem-se, pois:\n\n-   ![](https://latex.codecogs.com/gif.latex?P%28B%7CA%29) = probabilidade de dada cor ser pele;\n\n-   ![](https://latex.codecogs.com/gif.latex?P%28A%29) = probabilidade de encontrar dada cor;\n\n-   ![](https://latex.codecogs.com/gif.latex?P%28B%29) = probabilidade de encontrar pele.\n\n<p align=\"center\">\n<img width=\"200\" src=\"https://s3-sa-east-1.amazonaws.com/abnersn/github/bayesian-segmentator/demo.jpg\">\n<br>\n<strong>Figura 1:</strong> Exemplo de imagem do conjunto classificado manualmente.\n</p>\n\nA partir de um conjunto de imagens como a Figura 1, \u00e9 poss\u00edvel calcular as probabilidades *a priori* necess\u00e1rias para a aplica\u00e7\u00e3o do teorema de Bayes. Ap\u00f3s a an\u00e1lise de todas as imagens em um conjunto pr\u00e9 classificado com a ajuda de um editor de imagens, os valores obtidos das probabilidades para cada canal s\u00e3o armazenados em uma tabela de refer\u00eancia.\n\nAo receber uma imagem in\u00e9dita, o algoritmo busca, para cada pixel, uma probabilidade correspondente na tabela, de acordo com os valores de seus canais, isto \u00e9, sua cor. Em seguida os valores obtidos s\u00e3o multiplicados, conforme, para obter a classifica\u00e7\u00e3o final. Dessa forma, a imagem se torna uma matriz de probabilidades inferidas, com valores entre 0 e 1. Determina-se, ent\u00e3o, um limiar ![](https://latex.codecogs.com/gif.latex?%5Clambda), de modo que:\n\n![](https://latex.codecogs.com/gif.latex?C_A%28p_%7Bi%7D%29%20%3D%20%5Cleft%5C%7B%20%5Cbegin%7Barray%7D%7Bll%7D%200%20%26%20%5Cquad%20p_i%20%5Cleq%20%5Clambda%20%5C%5C%201%20%26%20%5Cquad%20p_i%20%3E%20%5Clambda%20%5Cend%7Barray%7D%20%5Cright.).\n\nOnde ![](https://latex.codecogs.com/gif.latex?p_i) \u00e9 a probabilidade inferida e ![](https://latex.codecogs.com/gif.latex?C_A) corresponde \u00e0 classe atribu\u00edda ao pixel, isto \u00e9, 0 para n\u00e3o-pele e 1 para pele.\n\nPara avaliar a capacidade de acerto do algoritmo, as probabilidades inferidas s\u00e3o comparadas com a classifica\u00e7\u00e3o realizada manualmente. Considerando ![](https://latex.codecogs.com/gif.latex?%5Cepsilon) o erro quadr\u00e1tico m\u00e9dio do algoritmo aplicado em uma imagem composta por ![](https://latex.codecogs.com/gif.latex?n) pixels, obt\u00e9m-se:\n\n![](https://latex.codecogs.com/gif.latex?%5Cepsilon%3D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%5Cfrac%7B%28p_i%20-%20C_i%29%5E2%7D%7Bn%7D%7D),\n\nonde ![](https://latex.codecogs.com/gif.latex?C_i) representa o valor atribu\u00eddo ao ![](https://latex.codecogs.com/gif.latex?i)-\u00e9simo pixel na classifica\u00e7\u00e3o manual.\n\n### Resultados\n\nA Figura 2 mostra o resultado obtido pelo classificador Naive-Bayes para diferentes espa\u00e7os de cor, nomeadamente, HSV, YCrCb e RGB, bem como as respectivas taxas de erro quadr\u00e1tico m\u00e9dio. As imagens originais est\u00e3o dispon\u00edveis no banco de imagens Wikimedia Commons e foram classificadas manualmente com o aux\u00edlio do editor de imagens GIMP. Neste trabalho, para a obten\u00e7\u00e3o das probabilidades *a priori* foram empregadas 13 imagens, tomando a diversidade \u00e9tnica como crit\u00e9rio para sua escolha. As taxas de acerto obtidas variam, pois, de 88,4\\% para o espa\u00e7o RGB a 90,6\\% no espa\u00e7o YCrCb.\n\n<p align=\"center\">\n<img width=\"500\" src=\"https://s3-sa-east-1.amazonaws.com/abnersn/github/bayesian-segmentator/result.png\">\n<br>\n<strong>Figura 2:</strong> Comparativo de desempenho e taxas de erro em diferentes espa\u00e7os de cor.\n</p>\n\n## Refer\u00eancias\n\n* *Ion Androutsopoulos, John Koutsias, Konstantinos V Chandrinos, GeorgePaliouras, and Constantine D Spyropoulos*. **An evaluation of naive bayesiananti-spam filtering.** arXiv preprint cs/0006013, 2000.\n\n* *James C Bezdek, LO Hall, and LP Clarke*. **Review of mr image segmen-tation techniques using pattern recognition.** Medical physics, 20(4):1033\u20131048, 1992.\n\n* *Margaret M Fleck, David A Forsyth, and Chris Bregler*. **Finding naked people**. Em: European Conference on Computer Vision, pages 593\u2013602. Springer, 1996.\n\n* *Rein-Lien Hsu, M. Abdel-Mottaleb, and A. K. Jain*. **Face detection in color images**. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(5):696\u2013706, Maio de 2002.\n\n* *Son Lam Phung, Abdesselam Bouzerdoum, and Douglas Chai*. **Skin segmentation using color pixel classification: analysis and comparison**. IEEEtransactions on pattern analysis and machine intelligence, 27(1):148\u2013154, 2005.\n\n## Autor\n* Abner Nascimento - [Universidade Federal do Cear\u00e1](http://www.ec.ufc.br/).\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/abnersn/bayesian_sgm", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "bayesian-sgm", "package_url": "https://pypi.org/project/bayesian-sgm/", "platform": "", "project_url": "https://pypi.org/project/bayesian-sgm/", "project_urls": {"Homepage": "https://github.com/abnersn/bayesian_sgm"}, "release_url": "https://pypi.org/project/bayesian-sgm/1.0.0/", "requires_dist": ["opencv-python (>=3.1.0)", "numpy (>=1.14.3)"], "requires_python": "", "summary": "Um segmentador de cores bayesiano para a OpenCV.", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Segmenta\u00e7\u00e3o Bayesiana de Cores em Imagens</h1>\n<p><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/411721a182a09fa1e694f7ade5f9e3bb474a69e0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6e696e652e7376673f7374796c653d666c61742d737175617265\">\n<img alt=\"GitHub release\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c32f89394fdf96cef39b560b1dd58be68535ddce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f61626e6572736e2f626179657369616e5f73676d2e7376673f7374796c653d666c61742d737175617265\">\n<img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/56aeb86c8c393a4aba3ed8a1d604666adc76455f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f446a616e676f2e7376673f7374796c653d666c61742d737175617265\">\n<a href=\"https://twitter.com/asnasc\" rel=\"nofollow\"><img alt=\"Twitter Follow\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b5b68b593a647f9a6e572a75ffec954d04068c3d/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f61736e6173632e7376673f7374796c653d666c61742d737175617265266c6162656c3d466f6c6c6f77\"></a></p>\n<p>Este trabalho prop\u00f5e o uso de um classificador Naive Bayes para a tarefa de segmenta\u00e7\u00e3o de imagens por cor, empregando duas classes de dados em seu modelo estat\u00edstico: pele e n\u00e3o-pele. Busca-se assim, obter um algoritmo de segmenta\u00e7\u00e3o por cor dotado de bons n\u00edveis de precis\u00e3o e velocidade suficiente para ser aplicado em filmagens em tempo real em um computador pessoal.</p>\n<h2>Pr\u00e9-requisitos</h2>\n<ul>\n<li>Python 3.5.5</li>\n<li>OpenCV 3.1.0 ou superior</li>\n<li>Numpy 1.14.3 ou superior</li>\n</ul>\n<h2>Instala\u00e7\u00e3o</h2>\n<p>Ap\u00f3s a instala\u00e7\u00e3o dos pr\u00e9-requisitos, \u00e9 poss\u00edvel instalar o segmentador pelo reposit\u00f3rio de pacotes do python com o comando:</p>\n<pre><code>$ sudo pip install bayesian_sgm\n</code></pre>\n<h2>Exemplo</h2>\n<p>As imagens de treino e as respectivas vers\u00f5es bin\u00e1rias devem ser organizadas com o mesmo nome de arquivo, por\u00e9m em pastas diferentes. No exemplo abaixo, as imagens coloridas est\u00e3o na pasta <code>n_dataset</code>, e a classifica\u00e7\u00e3o bin\u00e1ria em <code>c_dataset</code>.</p>\n<pre><code>.\n\u251c\u2500\u2500 datasets\n\u2502   \u251c\u2500\u2500 c_dataset\n\u2502   \u2502   \u251c\u2500\u2500 treino1.jpg\n\u2502   \u2502   \u251c\u2500\u2500 treino2.jpg\n\u2502   \u2502   \u251c\u2500\u2500 treino3.jpg\n\u2502   \u2502   \u251c\u2500\u2500 treino4.jpg\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 n_dataset\n\u2502       \u251c\u2500\u2500 treino1.jpg\n\u2502       \u251c\u2500\u2500 treino2.jpg\n\u2502       \u251c\u2500\u2500 treino3.jpg\n\u2502       \u251c\u2500\u2500 treino4.jpg\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 script.py\n</code></pre>\n<p>O arquivo <code>script.py</code> realiza o treinamento com base no dataset fornecido e aplica o segmentador no v\u00eddeo capturado pela webcam.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">cv2</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">bayesian_sgm</span>\n\n<span class=\"n\">seg</span> <span class=\"o\">=</span> <span class=\"n\">bayesian_sgm</span><span class=\"o\">.</span><span class=\"n\">BayesianColorSGM</span><span class=\"p\">()</span>\n<span class=\"n\">seg</span><span class=\"o\">.</span><span class=\"n\">learn_from_dirs</span><span class=\"p\">(</span><span class=\"s2\">\"datasets/c_dataset\"</span><span class=\"p\">,</span> <span class=\"s2\">\"datasets/n_dataset\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">cap</span> <span class=\"o\">=</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">VideoCapture</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n    <span class=\"n\">ret</span><span class=\"p\">,</span> <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">cap</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n    <span class=\"nb\">bin</span> <span class=\"o\">=</span> <span class=\"n\">seg</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n    <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s2\">\"frame\"</span><span class=\"p\">,</span> <span class=\"n\">img</span><span class=\"p\">)</span>\n    <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"s2\">\"binary\"</span><span class=\"p\">,</span> <span class=\"nb\">bin</span><span class=\"p\">)</span>\n    <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">waitKey</span><span class=\"p\">(</span><span class=\"mi\">30</span><span class=\"p\">)</span> <span class=\"o\">&amp;</span> <span class=\"mh\">0xFF</span>\n    <span class=\"k\">if</span> <span class=\"n\">k</span> <span class=\"o\">==</span> <span class=\"mi\">27</span><span class=\"p\">:</span>\n        <span class=\"k\">break</span>\n</pre>\n<h2>Fundamenta\u00e7\u00e3o Te\u00f3rica</h2>\n<h3>Introdu\u00e7\u00e3o</h3>\n<p>A separa\u00e7\u00e3o de regi\u00f5es correspondentes \u00e0 pele humana em imagens digitais possui fundamental import\u00e2ncia para a solu\u00e7\u00e3o de problemas relacionados \u00e0 vis\u00e3o computacional, como detec\u00e7\u00e3o de face, detec\u00e7\u00e3o de gestos e classifica\u00e7\u00e3o de conte\u00fado. Tais aplica\u00e7\u00f5es empregam algoritmos de segmenta\u00e7\u00e3o com o objetivo de delimitar \u00e1reas de interesse nas imagens, de modo a reduzir o escopo de informa\u00e7\u00f5es a serem processadas e obter ganhos de desempenho.</p>\n<p>Diversas s\u00e3o as t\u00e9cnicas envolvidas na tarefa de segmenta\u00e7\u00e3o de imagens, como k-means e outras formas de reconhecimento de padr\u00f5es. Por\u00e9m, devido \u00e0s suas propriedades f\u00edsicas e forma peculiar de interagir com a luz, a pele humana possui caracter\u00edsticas visuais que a diferenciam de elementos inorg\u00e2nicos, o que traz vantagem a abordagens baseadas na cor. De fato, o espectro de tonalidades da pele humana \u00e9 relativamente limitado, mesmo levando em considera\u00e7\u00e3o varia\u00e7\u00f5es \u00e9tnicas.</p>\n<p>O problema resume-se, ent\u00e3o, a determinar se um dado conjunto de pixels pertence ou n\u00e3o a uma regi\u00e3o de pele humana com base em sua cor. Nesse contexto, a escolha do espa\u00e7o de cores mais adequado aos matizes da pele humana, bem como o emprego de um modelo estat\u00edstico que permita analisar um conjunto previamente classificado de imagens pode ser uma solu\u00e7\u00e3o eficaz. Tais escolhas est\u00e3o intrinsecamente relacionadas \u00e0 sensibilidade dos algoritmos de segmenta\u00e7\u00e3o a problemas como condi\u00e7\u00f5es de ilumina\u00e7\u00e3o desfavor\u00e1veis e oclus\u00e3o.</p>\n<h3>Metodologia</h3>\n<p>O teorema de Bayes, nomeado em homenagem a seu idealizador, Thomas Bayes (1701-1761), estabelece uma rela\u00e7\u00e3o matem\u00e1tica para as probabilidades de eventos condicionados a evid\u00eancias pr\u00e9vias. A probabilidade de um evento A, dado que houve a observa\u00e7\u00e3o de uma evid\u00eancia B \u00e9 descrita por:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/917c4009cb64f54d7ba5830b7b26a39ff998c07f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5025323841253743422532392533442535436672616325374250253238422537434125323925354374696d657325374250253238412532392537442537442537425025323842253239253744\">.</p>\n<p>Este princ\u00edpio possui diversas aplica\u00e7\u00f5es no campo da infer\u00eancia estat\u00edstica, em problemas que demandam a dedu\u00e7\u00e3o de informa\u00e7\u00f5es a partir da an\u00e1lise de um conjunto de amostras. Filtros de spam, por exemplo, analisam o texto de diversos emails classificados pelos usu\u00e1rios como spam e n\u00e3o-spam e determinam a classe na qual se enquadra uma nova amostra com base na equa\u00e7\u00e3o acima.</p>\n<p>Classificadores Naive Bayes consideram que as caracter\u00edsticas analisadas s\u00e3o independentes entre si. Isto \u00e9, para um conjunto <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/00e43f72cca9a73a00bfc09938669111a0bbf3ff/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f41253344253742415f31253243415f3225324325354363646f7473253243415f6e253744\"> de caracter\u00edsticas condicionadas a uma evid\u00eancia <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d0171a6ffa68c54b96138299b14707a38607711e/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f42\">, tem-se o produt\u00f3rio:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5a2fe1455ad1bb54189895e17b8d5e861c935d49/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f50253238415f31253243415f3225324325354363646f7473253243415f6e2537434225323925334425354370726f645f25374269253344312537442535452537426e25374425323050253238415f69253743422532392e\"></p>\n<p>Tal pressuposto, embora possa comprometer a coer\u00eancia entre o modelo e a rela\u00e7\u00e3o que de fato ocorre entre os dados, \u00e9 capaz de classificar as amostras com n\u00edveis de erro pr\u00f3ximos aos de m\u00e9todos mais robustos.</p>\n<p>Esta modelagem matem\u00e1tica pode ser aplicada para a segmenta\u00e7\u00e3o de imagens como uma t\u00e9cnica de classifica\u00e7\u00e3o de pixels em duas classes: pele e n\u00e3o-pele. Para imagens representadas em espa\u00e7os de cor de 3 canais, por exemplo, considera-se que o evento A representa o fato de um pixel pertencer a uma regi\u00e3o de pele. B corresponde ao valor num\u00e9rico que um pixel assume em determinado canal. Logo, primeiramente \u00e9 necess\u00e1rio obter <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e0ec9f9ca18c8f87fe9269e4bdfb0800f1690b9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5025323841253239\">, <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a429fcbc89d905f346da79b3848e3db90c1f8553/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f502532384225374341253239\"> e <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/700166f515b6e071a2efbdc673d3a4b703e71f67/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5025323842253239\">, conhecidos como probabilidades <em>a priori</em>. De forma intuitiva, tem-se, pois:</p>\n<ul>\n<li>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a429fcbc89d905f346da79b3848e3db90c1f8553/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f502532384225374341253239\"> = probabilidade de dada cor ser pele;</p>\n</li>\n<li>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e0ec9f9ca18c8f87fe9269e4bdfb0800f1690b9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5025323841253239\"> = probabilidade de encontrar dada cor;</p>\n</li>\n<li>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/700166f515b6e071a2efbdc673d3a4b703e71f67/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5025323842253239\"> = probabilidade de encontrar pele.</p>\n</li>\n</ul>\n<p align=\"center\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/70e7cda9e56365cc0a7c1d3a3d62fd70a32a385f/68747470733a2f2f73332d73612d656173742d312e616d617a6f6e6177732e636f6d2f61626e6572736e2f6769746875622f626179657369616e2d7365676d656e7461746f722f64656d6f2e6a7067\" width=\"200\">\n<br>\n<strong>Figura 1:</strong> Exemplo de imagem do conjunto classificado manualmente.\n</p>\n<p>A partir de um conjunto de imagens como a Figura 1, \u00e9 poss\u00edvel calcular as probabilidades <em>a priori</em> necess\u00e1rias para a aplica\u00e7\u00e3o do teorema de Bayes. Ap\u00f3s a an\u00e1lise de todas as imagens em um conjunto pr\u00e9 classificado com a ajuda de um editor de imagens, os valores obtidos das probabilidades para cada canal s\u00e3o armazenados em uma tabela de refer\u00eancia.</p>\n<p>Ao receber uma imagem in\u00e9dita, o algoritmo busca, para cada pixel, uma probabilidade correspondente na tabela, de acordo com os valores de seus canais, isto \u00e9, sua cor. Em seguida os valores obtidos s\u00e3o multiplicados, conforme, para obter a classifica\u00e7\u00e3o final. Dessa forma, a imagem se torna uma matriz de probabilidades inferidas, com valores entre 0 e 1. Determina-se, ent\u00e3o, um limiar <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/303814263551805d34b30145072d117f4ca20edc/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f2535436c616d626461\">, de modo que:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b80027e7aacbecbf5bef4272529fb6ccace92815/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f435f41253238705f253742692537442532392532302533442532302535436c656674253543253742253230253543626567696e25374261727261792537442537426c6c2537442532303025323025323625323025354371756164253230705f692532302535436c65712532302535436c616d6264612532302535432535432532303125323025323625323025354371756164253230705f692532302533452532302535436c616d626461253230253543656e64253742617272617925374425323025354372696768742e\">.</p>\n<p>Onde <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3ad3d0996c2901e01db1ac6dd82a72170872ab77/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f705f69\"> \u00e9 a probabilidade inferida e <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/72bb5740f0722661d8ee6d7b9f99949a2837c0ed/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f435f41\"> corresponde \u00e0 classe atribu\u00edda ao pixel, isto \u00e9, 0 para n\u00e3o-pele e 1 para pele.</p>\n<p>Para avaliar a capacidade de acerto do algoritmo, as probabilidades inferidas s\u00e3o comparadas com a classifica\u00e7\u00e3o realizada manualmente. Considerando <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/269c2bb923fce320a524be3cc37d30213596ac92/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253543657073696c6f6e\"> o erro quadr\u00e1tico m\u00e9dio do algoritmo aplicado em uma imagem composta por <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f4d9126f45a5573e08974b36a048e706430d2030/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6e\"> pixels, obt\u00e9m-se:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eee4c78f752b18b45a7a7fca51e597f79ad16f77/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253543657073696c6f6e25334425354373756d5f25374269253344312537442535452537426e25374425374225354366726163253742253238705f692532302d253230435f69253239253545322537442537426e253744253744\">,</p>\n<p>onde <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/20f05b92076a08c64b61e5c4badcb61b67b9c95e/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f435f69\"> representa o valor atribu\u00eddo ao <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5035dc5a8ff5c0fcfffafd56cc73fd43c676782f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f69\">-\u00e9simo pixel na classifica\u00e7\u00e3o manual.</p>\n<h3>Resultados</h3>\n<p>A Figura 2 mostra o resultado obtido pelo classificador Naive-Bayes para diferentes espa\u00e7os de cor, nomeadamente, HSV, YCrCb e RGB, bem como as respectivas taxas de erro quadr\u00e1tico m\u00e9dio. As imagens originais est\u00e3o dispon\u00edveis no banco de imagens Wikimedia Commons e foram classificadas manualmente com o aux\u00edlio do editor de imagens GIMP. Neste trabalho, para a obten\u00e7\u00e3o das probabilidades <em>a priori</em> foram empregadas 13 imagens, tomando a diversidade \u00e9tnica como crit\u00e9rio para sua escolha. As taxas de acerto obtidas variam, pois, de 88,4% para o espa\u00e7o RGB a 90,6% no espa\u00e7o YCrCb.</p>\n<p align=\"center\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/958597d00c11e04fbac31b6efa95c1bd32171c59/68747470733a2f2f73332d73612d656173742d312e616d617a6f6e6177732e636f6d2f61626e6572736e2f6769746875622f626179657369616e2d7365676d656e7461746f722f726573756c742e706e67\" width=\"500\">\n<br>\n<strong>Figura 2:</strong> Comparativo de desempenho e taxas de erro em diferentes espa\u00e7os de cor.\n</p>\n<h2>Refer\u00eancias</h2>\n<ul>\n<li>\n<p><em>Ion Androutsopoulos, John Koutsias, Konstantinos V Chandrinos, GeorgePaliouras, and Constantine D Spyropoulos</em>. <strong>An evaluation of naive bayesiananti-spam filtering.</strong> arXiv preprint cs/0006013, 2000.</p>\n</li>\n<li>\n<p><em>James C Bezdek, LO Hall, and LP Clarke</em>. <strong>Review of mr image segmen-tation techniques using pattern recognition.</strong> Medical physics, 20(4):1033\u20131048, 1992.</p>\n</li>\n<li>\n<p><em>Margaret M Fleck, David A Forsyth, and Chris Bregler</em>. <strong>Finding naked people</strong>. Em: European Conference on Computer Vision, pages 593\u2013602. Springer, 1996.</p>\n</li>\n<li>\n<p><em>Rein-Lien Hsu, M. Abdel-Mottaleb, and A. K. Jain</em>. <strong>Face detection in color images</strong>. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(5):696\u2013706, Maio de 2002.</p>\n</li>\n<li>\n<p><em>Son Lam Phung, Abdesselam Bouzerdoum, and Douglas Chai</em>. <strong>Skin segmentation using color pixel classification: analysis and comparison</strong>. IEEEtransactions on pattern analysis and machine intelligence, 27(1):148\u2013154, 2005.</p>\n</li>\n</ul>\n<h2>Autor</h2>\n<ul>\n<li>Abner Nascimento - <a href=\"http://www.ec.ufc.br/\" rel=\"nofollow\">Universidade Federal do Cear\u00e1</a>.</li>\n</ul>\n\n          </div>"}, "last_serial": 4323779, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "31270ed46052730e55566fc4a0139dea", "sha256": "732fb1811d015118e7d4052d6250c25772172be8a63fb2bf7c49e79399d54865"}, "downloads": -1, "filename": "bayesian_sgm-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "31270ed46052730e55566fc4a0139dea", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 19776, "upload_time": "2018-09-29T23:54:23", "upload_time_iso_8601": "2018-09-29T23:54:23.087236Z", "url": "https://files.pythonhosted.org/packages/b2/bf/8768b850457e0ec72e425e48511987d76b159566cd58077d24793334c8fc/bayesian_sgm-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "35064a4b45c9dbe473bd75b7788337d2", "sha256": "c065d19d28cc3e9bc6c22562840f2c2d72b06bd478250077f9e9d2e910a56cbe"}, "downloads": -1, "filename": "bayesian_sgm-1.0.0.tar.gz", "has_sig": false, "md5_digest": "35064a4b45c9dbe473bd75b7788337d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7997, "upload_time": "2018-09-29T23:54:24", "upload_time_iso_8601": "2018-09-29T23:54:24.522136Z", "url": "https://files.pythonhosted.org/packages/8a/a6/866511fed7851049988fda9127937df59df9760561bf510b18f7cb0e7125/bayesian_sgm-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "31270ed46052730e55566fc4a0139dea", "sha256": "732fb1811d015118e7d4052d6250c25772172be8a63fb2bf7c49e79399d54865"}, "downloads": -1, "filename": "bayesian_sgm-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "31270ed46052730e55566fc4a0139dea", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 19776, "upload_time": "2018-09-29T23:54:23", "upload_time_iso_8601": "2018-09-29T23:54:23.087236Z", "url": "https://files.pythonhosted.org/packages/b2/bf/8768b850457e0ec72e425e48511987d76b159566cd58077d24793334c8fc/bayesian_sgm-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "35064a4b45c9dbe473bd75b7788337d2", "sha256": "c065d19d28cc3e9bc6c22562840f2c2d72b06bd478250077f9e9d2e910a56cbe"}, "downloads": -1, "filename": "bayesian_sgm-1.0.0.tar.gz", "has_sig": false, "md5_digest": "35064a4b45c9dbe473bd75b7788337d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7997, "upload_time": "2018-09-29T23:54:24", "upload_time_iso_8601": "2018-09-29T23:54:24.522136Z", "url": "https://files.pythonhosted.org/packages/8a/a6/866511fed7851049988fda9127937df59df9760561bf510b18f7cb0e7125/bayesian_sgm-1.0.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:14:42 2020"}