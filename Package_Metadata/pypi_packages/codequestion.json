{"info": {"author": "NeuML", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Software Development", "Topic :: Text Processing :: Indexing", "Topic :: Utilities"], "description": "codequestion: Ask coding questions directly from the terminal\n======\n\ncodequestion is a Python terminal program that allows an user to ask coding questions directly from the terminal. Many developers will have a web browser window open while they develop and run web searches as questions arise. codequestion attempts to make that process faster so you can focus on development.\n\nThe default model for codequestion is built off the [Stack Exchange Dumps on archive.org](https://archive.org/details/stackexchange). codequestion runs locally against a pre-trained model using data from Stack Exchange. No network connection is required once installed. The model executes similarity queries to find similar questions to the input query. \n\nAn example of how codequestion works is shown below:\n\n![demo](https://raw.githubusercontent.com/neuml/codequestion/master/demo.gif)\n\n### Installation\nThe easiest way to install is via pip and PyPI\n\n    pip install codequestion\n\nYou can also use Git to clone the repository from GitHub and install it manually:\n\n    git clone https://github.com/neuml/codequestion.git\n    cd codequestion\n    pip install .\n\nPython 3.5+ is supported\n\n### Downloading a model\n\nOnce codequestion is installed, a model needs to be downloaded.\n\n    python -m codequestion.download\n\nThe model will be stored in ~/.codequestion/\n\nThe model can also be manually installed if the machine doesn't have direct internet access. Pre-trained models are pulled from the [github release page](https://github.com/neuml/codequestion/releases)\n\n    unzip cqmodel.zip ~/.codequestion\n\nIt is possible for codequestion to be customized to run against a custom question-answer repository and more will come on that in the future. At this time, only the Stack Exchange model is supported. \n\n### Running queries\n\nThe fastest way to run queries is to start a codequestion shell\n\n    codequestion\n\nA prompt will come up. Queries can be typed directly into the console.\n\n### Technical overview\nThe full source code for codequestion is available on github. Code is licensed under the MIT license.\n\n    git clone https://github.com/neuml/codequestion.git\n    cd codequestion\n\nThe following is an overview of how this project works. \n\n#### Processing the raw data dumps\nThe raw 7z XML dumps from Stack Exchange are processed through a series of steps. Only highly scored questions with answers are retrieved for storage in the model. Questions and answers are consolidated into a single SQLite file called questions.db. The schema for questions.db is below.\n\n*questions.db schema*\n\n    Id INTEGER PRIMARY KEY\n    Source TEXT\n    SourceId INTEGER\n    Date DATETIME\n    Tags TEXT\n    Question TEXT\n    QuestionUser TEXT\n    Answer TEXT\n    AnswerUser TEXT\n    Reference TEXT\n\n#### Indexing\ncodequestion builds a sentence embeddings index for questions.db. Each question in the questions.db schema is tokenized and resolved to a word embedding. The word embedding model is a custom fastText model built on questions.db. Once each token is converted to word embeddings, a weighted sentence embedding is created. Word embeddings are weighed using a BM25 index over all the tokens in the repository, with one modification. Tags are used to boost the weights of tag tokens.\n\nOnce questions.db is converted to a collection of sentence embeddings, they are normalized and stored in faiss, which allows for fast similarity searches.\n\n#### Querying\ncodequestion tokenizes each query using the same method as during indexing. Those tokens are used to build a sentence embedding. That embedding is queried against the faiss index to find the most similar questions. \n\n#### Model accuracy\nThe following sections show test results for various word vector/scoring combinations. SE 300d word vectors with BM25 scoring does the best against this dataset. Even with the reduced vocabulary of < 1M Stack Exchange questions, SE 300d - BM25 does reasonably well against the STS Benchmark.\n\n**StackExchange Query**\n\nModels scored using Mean Reciprocal Rank (MRR)\n\n| Model           | MRR   | \n| --------------- | :---: |\n| SE 300d - BM25  | 76.3  |\n| ParaNMT - BM25  | 67.4  |\n| FastText - BM25 | 66.1  |\n| BM25            | 49.5  |\n| TF-IDF          | 45.9  |\n\n**STS Benchmark**\n\nModels scored using Pearson Correlation\n\n| Model           | Supervision   | Dev   | Test  |\n| --------------- | :-----------: | :---: | :---: |\n| ParaNMT - BM25  | Train         | 82.6  | 78.1  |\n| FastText - BM25 | Train         | 79.8  | 72.7  |\n| SE 300d - BM25  | Train         | 77.0  | 69.1  |\n\n### Testing\nTo reproduce the tests above, you need to download the test data into ~/.codequestion/test\n\n    mkdir -p ~/.codequestion/test/stackexchange\n    wget https://raw.githubusercontent.com/neuml/codequestion/master/test/stackexchange/query.txt -P ~/.codequestion/test/stackexchange\n    wget http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n    tar -C ~/.codequestion/test -xvzf Stsbenchmark.tar.gz\n    python -m codequestion.evaluate\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://pypi.org/project/codequestion/", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/neuml/codequestion", "keywords": "python search embedding machine-learning", "license": "MIT License: http://opensource.org/licenses/MIT", "maintainer": "", "maintainer_email": "", "name": "codequestion", "package_url": "https://pypi.org/project/codequestion/", "platform": "", "project_url": "https://pypi.org/project/codequestion/", "project_urls": {"Documentation": "https://github.com/neuml/codequestion", "Download": "https://pypi.org/project/codequestion/", "Homepage": "https://github.com/neuml/codequestion", "Issue Tracker": "https://github.com/neuml/codequestion/issues", "Source Code": "https://github.com/neuml/codequestion"}, "release_url": "https://pypi.org/project/codequestion/1.0.0/", "requires_dist": ["faiss-gpu (>=1.6.1)", "fasttext (>=0.9.1)", "html2text (>=2019.9.26)", "mdv (>=1.7.4)", "numpy (>=1.17.4)", "pymagnitude (>=0.1.120)", "scikit-learn (>=0.22.1)", "scipy (>=1.4.1)", "tqdm (==4.40.2)"], "requires_python": ">=3.5", "summary": "Ask coding questions directly from the terminal", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>codequestion: Ask coding questions directly from the terminal</h1>\n<p>codequestion is a Python terminal program that allows an user to ask coding questions directly from the terminal. Many developers will have a web browser window open while they develop and run web searches as questions arise. codequestion attempts to make that process faster so you can focus on development.</p>\n<p>The default model for codequestion is built off the <a href=\"https://archive.org/details/stackexchange\" rel=\"nofollow\">Stack Exchange Dumps on archive.org</a>. codequestion runs locally against a pre-trained model using data from Stack Exchange. No network connection is required once installed. The model executes similarity queries to find similar questions to the input query.</p>\n<p>An example of how codequestion works is shown below:</p>\n<p><img alt=\"demo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1752334a91d2a053bc8b7ef810443180296a1d87/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6e65756d6c2f636f64657175657374696f6e2f6d61737465722f64656d6f2e676966\"></p>\n<h3>Installation</h3>\n<p>The easiest way to install is via pip and PyPI</p>\n<pre><code>pip install codequestion\n</code></pre>\n<p>You can also use Git to clone the repository from GitHub and install it manually:</p>\n<pre><code>git clone https://github.com/neuml/codequestion.git\ncd codequestion\npip install .\n</code></pre>\n<p>Python 3.5+ is supported</p>\n<h3>Downloading a model</h3>\n<p>Once codequestion is installed, a model needs to be downloaded.</p>\n<pre><code>python -m codequestion.download\n</code></pre>\n<p>The model will be stored in ~/.codequestion/</p>\n<p>The model can also be manually installed if the machine doesn't have direct internet access. Pre-trained models are pulled from the <a href=\"https://github.com/neuml/codequestion/releases\" rel=\"nofollow\">github release page</a></p>\n<pre><code>unzip cqmodel.zip ~/.codequestion\n</code></pre>\n<p>It is possible for codequestion to be customized to run against a custom question-answer repository and more will come on that in the future. At this time, only the Stack Exchange model is supported.</p>\n<h3>Running queries</h3>\n<p>The fastest way to run queries is to start a codequestion shell</p>\n<pre><code>codequestion\n</code></pre>\n<p>A prompt will come up. Queries can be typed directly into the console.</p>\n<h3>Technical overview</h3>\n<p>The full source code for codequestion is available on github. Code is licensed under the MIT license.</p>\n<pre><code>git clone https://github.com/neuml/codequestion.git\ncd codequestion\n</code></pre>\n<p>The following is an overview of how this project works.</p>\n<h4>Processing the raw data dumps</h4>\n<p>The raw 7z XML dumps from Stack Exchange are processed through a series of steps. Only highly scored questions with answers are retrieved for storage in the model. Questions and answers are consolidated into a single SQLite file called questions.db. The schema for questions.db is below.</p>\n<p><em>questions.db schema</em></p>\n<pre><code>Id INTEGER PRIMARY KEY\nSource TEXT\nSourceId INTEGER\nDate DATETIME\nTags TEXT\nQuestion TEXT\nQuestionUser TEXT\nAnswer TEXT\nAnswerUser TEXT\nReference TEXT\n</code></pre>\n<h4>Indexing</h4>\n<p>codequestion builds a sentence embeddings index for questions.db. Each question in the questions.db schema is tokenized and resolved to a word embedding. The word embedding model is a custom fastText model built on questions.db. Once each token is converted to word embeddings, a weighted sentence embedding is created. Word embeddings are weighed using a BM25 index over all the tokens in the repository, with one modification. Tags are used to boost the weights of tag tokens.</p>\n<p>Once questions.db is converted to a collection of sentence embeddings, they are normalized and stored in faiss, which allows for fast similarity searches.</p>\n<h4>Querying</h4>\n<p>codequestion tokenizes each query using the same method as during indexing. Those tokens are used to build a sentence embedding. That embedding is queried against the faiss index to find the most similar questions.</p>\n<h4>Model accuracy</h4>\n<p>The following sections show test results for various word vector/scoring combinations. SE 300d word vectors with BM25 scoring does the best against this dataset. Even with the reduced vocabulary of &lt; 1M Stack Exchange questions, SE 300d - BM25 does reasonably well against the STS Benchmark.</p>\n<p><strong>StackExchange Query</strong></p>\n<p>Models scored using Mean Reciprocal Rank (MRR)</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">MRR</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>SE 300d - BM25</td>\n<td align=\"center\">76.3</td>\n</tr>\n<tr>\n<td>ParaNMT - BM25</td>\n<td align=\"center\">67.4</td>\n</tr>\n<tr>\n<td>FastText - BM25</td>\n<td align=\"center\">66.1</td>\n</tr>\n<tr>\n<td>BM25</td>\n<td align=\"center\">49.5</td>\n</tr>\n<tr>\n<td>TF-IDF</td>\n<td align=\"center\">45.9</td>\n</tr></tbody></table>\n<p><strong>STS Benchmark</strong></p>\n<p>Models scored using Pearson Correlation</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">Supervision</th>\n<th align=\"center\">Dev</th>\n<th align=\"center\">Test</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ParaNMT - BM25</td>\n<td align=\"center\">Train</td>\n<td align=\"center\">82.6</td>\n<td align=\"center\">78.1</td>\n</tr>\n<tr>\n<td>FastText - BM25</td>\n<td align=\"center\">Train</td>\n<td align=\"center\">79.8</td>\n<td align=\"center\">72.7</td>\n</tr>\n<tr>\n<td>SE 300d - BM25</td>\n<td align=\"center\">Train</td>\n<td align=\"center\">77.0</td>\n<td align=\"center\">69.1</td>\n</tr></tbody></table>\n<h3>Testing</h3>\n<p>To reproduce the tests above, you need to download the test data into ~/.codequestion/test</p>\n<pre><code>mkdir -p ~/.codequestion/test/stackexchange\nwget https://raw.githubusercontent.com/neuml/codequestion/master/test/stackexchange/query.txt -P ~/.codequestion/test/stackexchange\nwget http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\ntar -C ~/.codequestion/test -xvzf Stsbenchmark.tar.gz\npython -m codequestion.evaluate\n</code></pre>\n\n          </div>"}, "last_serial": 6460980, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "72ea214632fc3e5361e9022f6c24e510", "sha256": "b872a549b18245721d1344d39a4d869935ca8d45f89633baac93e6225b8f930c"}, "downloads": -1, "filename": "codequestion-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "72ea214632fc3e5361e9022f6c24e510", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 19895, "upload_time": "2020-01-15T20:07:32", "upload_time_iso_8601": "2020-01-15T20:07:32.572081Z", "url": "https://files.pythonhosted.org/packages/a4/dc/a299524b3c4effdba04c09dc2132e450dc443cddbd61294d84770900b9b9/codequestion-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "04aec942784c1312214e9afa9650b6eb", "sha256": "0e91c09800cd1b8da2361d9c8f80bb6c5e0c8b1dee7df36ee97541f8fbe69308"}, "downloads": -1, "filename": "codequestion-1.0.0.tar.gz", "has_sig": false, "md5_digest": "04aec942784c1312214e9afa9650b6eb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16913, "upload_time": "2020-01-15T20:07:34", "upload_time_iso_8601": "2020-01-15T20:07:34.845240Z", "url": "https://files.pythonhosted.org/packages/d2/4d/7c58b19980089cfe8412035d7ced73a08437fa5c3923cd2e8079b0c86a79/codequestion-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "72ea214632fc3e5361e9022f6c24e510", "sha256": "b872a549b18245721d1344d39a4d869935ca8d45f89633baac93e6225b8f930c"}, "downloads": -1, "filename": "codequestion-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "72ea214632fc3e5361e9022f6c24e510", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 19895, "upload_time": "2020-01-15T20:07:32", "upload_time_iso_8601": "2020-01-15T20:07:32.572081Z", "url": "https://files.pythonhosted.org/packages/a4/dc/a299524b3c4effdba04c09dc2132e450dc443cddbd61294d84770900b9b9/codequestion-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "04aec942784c1312214e9afa9650b6eb", "sha256": "0e91c09800cd1b8da2361d9c8f80bb6c5e0c8b1dee7df36ee97541f8fbe69308"}, "downloads": -1, "filename": "codequestion-1.0.0.tar.gz", "has_sig": false, "md5_digest": "04aec942784c1312214e9afa9650b6eb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16913, "upload_time": "2020-01-15T20:07:34", "upload_time_iso_8601": "2020-01-15T20:07:34.845240Z", "url": "https://files.pythonhosted.org/packages/d2/4d/7c58b19980089cfe8412035d7ced73a08437fa5c3923cd2e8079b0c86a79/codequestion-1.0.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:14 2020"}