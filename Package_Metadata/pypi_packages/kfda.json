{"info": {"author": "Kawin Nikomborirak", "author_email": "concavemail@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Kernel FDA\n\n[![PyPI version](https://badge.fury.io/py/kfda.svg)](https://badge.fury.io/py/kfda)\n\nThis repository implements Kernel Fisher Discriminant Analysis (Kernel FDA) as described in [https://arxiv.org/abs/1906.09436](https://arxiv.org/abs/1906.09436).\nFDA, equivalent to Linear Discriminant Analysis (LDA), is a classification method that projects vectors onto a smaller subspace.\nThis subspace is optimized to maximize between-class scatter and minimize within class scatter, making it an effective classification method.\nKernel FDA improves on regular FDA by enabling nonlinear subspaces using the [kernel trick](https://en.wikipedia.org/wiki/Kernel_method).\n\nFDA and Kernel FDA classify vectors by comparing their projection in the fisher subspace to class centroids, adding a new class is just a matter of adding a new centroid.\nThus, this model is implemented here with the hope of using Kernel FDA as a oneshot learning algorithm.\n\n## Usage\n`Kfda` uses `scikit-learn`'s interface.\n\n- Initializing: `cls = Kfda(n_components=2, kernel='linear')` for a classifier that a linear kernel with 2 components.\n  For kernel of degree 2, use `Kfda(n_components=2, kernel='poly', degree=2)` for a polynomial kernel of degree 2.\n  See https://scikit-learn.org/stable/modules/metrics.html#polynomial-kernel for a list of kernels and their parameters, or the [source code docstrings](https://github.com/concavegit/kfda/blob/master/kfda/kfda.py) for a complete description of the parameters.\n\n- Fitting: `cls.fit(X, y)`\n\n- Prediction: `cls.predict(X)`\n\n- Scoring: `cls.score(X, y)`\n\n## Examples\nSee [`examples`](https://github.com/concavegit/kfda/tree/master/examples) for examples on MNIST, faces, and oneshot learning.\n\nAfter running them, you can plug corresponding pairs of generated\n`*embeddings.tsv` and `*labels.tsv` into Tensorflow's\n[Embedding Projector](https://projector.tensorflow.org/)\nto visualize the embeddings.\nFor example, running `mnist.py` and then loading\n`mnist_test_embeddings.tsv` and `mnist_test_labels.tsv` shows the\nfollowing using the UMAP visualizer:\n\n![MNIST Kernel FDA embeddings](https://github.com/concavegit/kfda/blob/master/img/mnist.png?raw=true)\n\n## Notebook\nAnother place to see example usage is the\n[Colab Notebook](https://colab.research.google.com/drive/1nnVphyZ_0QKYZbmdJaIBjm-zYO4xwF0b).\n\n## Caveats\nSimilar to SVM, the most glaring constraint of KFDA is the memory limit in training.\nTraining a Kernel FDA classifier requires creating matrices that are `n_samples` by `n_samples` large, meaning the memory requirement grows with respect to `O(n_samples^2)`.\n\nThe accuracy, while high (0.97 on MNIST), seems to be limited by the training set size.\nWith a training size of 10000 and a testing size of 60000, performance on MNIST averages around 0.97 accuracy using 9 fisher directions and the RBF kernel:\n\n```python\ncls = Kfda(kernel='rbf', n_components=9)\n```\n\nThis may be due to the constrained training size.\nAccuracy can be improved without increasing training size by implementing invariant kernels that would implicitly handle scale and rotation without requiring an extended dataset.\n\n## Oneshot Learning\nOneshot learning means that an algorithm can learn a new class with as little as one sample.\nThis is possible for Kernel FDA because it finds a subspace that purposefully spreads out distinct classes.\nIntroducing a new label involves simply adding another centroid for use in prediction.\nSee the\n[Colab Notebook](https://colab.research.google.com/drive/1nnVphyZ_0QKYZbmdJaIBjm-zYO4xwF0b).\nor the\n[example](https://github.com/concavegit/kfda/blob/master/examples/mnist_oneshot.py) for examples.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/concavegit/kfda", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "kfda", "package_url": "https://pypi.org/project/kfda/", "platform": "", "project_url": "https://pypi.org/project/kfda/", "project_urls": {"Homepage": "https://github.com/concavegit/kfda"}, "release_url": "https://pypi.org/project/kfda/0.1.1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Kernel FDA implementation described in https://arxiv.org/abs/1906.09436", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Kernel FDA</h1>\n<p><a href=\"https://badge.fury.io/py/kfda\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57d6ec25856455e35fd49117019e9e55848aa799/68747470733a2f2f62616467652e667572792e696f2f70792f6b6664612e737667\"></a></p>\n<p>This repository implements Kernel Fisher Discriminant Analysis (Kernel FDA) as described in <a href=\"https://arxiv.org/abs/1906.09436\" rel=\"nofollow\">https://arxiv.org/abs/1906.09436</a>.\nFDA, equivalent to Linear Discriminant Analysis (LDA), is a classification method that projects vectors onto a smaller subspace.\nThis subspace is optimized to maximize between-class scatter and minimize within class scatter, making it an effective classification method.\nKernel FDA improves on regular FDA by enabling nonlinear subspaces using the <a href=\"https://en.wikipedia.org/wiki/Kernel_method\" rel=\"nofollow\">kernel trick</a>.</p>\n<p>FDA and Kernel FDA classify vectors by comparing their projection in the fisher subspace to class centroids, adding a new class is just a matter of adding a new centroid.\nThus, this model is implemented here with the hope of using Kernel FDA as a oneshot learning algorithm.</p>\n<h2>Usage</h2>\n<p><code>Kfda</code> uses <code>scikit-learn</code>'s interface.</p>\n<ul>\n<li>\n<p>Initializing: <code>cls = Kfda(n_components=2, kernel='linear')</code> for a classifier that a linear kernel with 2 components.\nFor kernel of degree 2, use <code>Kfda(n_components=2, kernel='poly', degree=2)</code> for a polynomial kernel of degree 2.\nSee <a href=\"https://scikit-learn.org/stable/modules/metrics.html#polynomial-kernel\" rel=\"nofollow\">https://scikit-learn.org/stable/modules/metrics.html#polynomial-kernel</a> for a list of kernels and their parameters, or the <a href=\"https://github.com/concavegit/kfda/blob/master/kfda/kfda.py\" rel=\"nofollow\">source code docstrings</a> for a complete description of the parameters.</p>\n</li>\n<li>\n<p>Fitting: <code>cls.fit(X, y)</code></p>\n</li>\n<li>\n<p>Prediction: <code>cls.predict(X)</code></p>\n</li>\n<li>\n<p>Scoring: <code>cls.score(X, y)</code></p>\n</li>\n</ul>\n<h2>Examples</h2>\n<p>See <a href=\"https://github.com/concavegit/kfda/tree/master/examples\" rel=\"nofollow\"><code>examples</code></a> for examples on MNIST, faces, and oneshot learning.</p>\n<p>After running them, you can plug corresponding pairs of generated\n<code>*embeddings.tsv</code> and <code>*labels.tsv</code> into Tensorflow's\n<a href=\"https://projector.tensorflow.org/\" rel=\"nofollow\">Embedding Projector</a>\nto visualize the embeddings.\nFor example, running <code>mnist.py</code> and then loading\n<code>mnist_test_embeddings.tsv</code> and <code>mnist_test_labels.tsv</code> shows the\nfollowing using the UMAP visualizer:</p>\n<p><img alt=\"MNIST Kernel FDA embeddings\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d0e57c6231142878f8d97bb3ef49afc39b1fdc43/68747470733a2f2f6769746875622e636f6d2f636f6e636176656769742f6b6664612f626c6f622f6d61737465722f696d672f6d6e6973742e706e673f7261773d74727565\"></p>\n<h2>Notebook</h2>\n<p>Another place to see example usage is the\n<a href=\"https://colab.research.google.com/drive/1nnVphyZ_0QKYZbmdJaIBjm-zYO4xwF0b\" rel=\"nofollow\">Colab Notebook</a>.</p>\n<h2>Caveats</h2>\n<p>Similar to SVM, the most glaring constraint of KFDA is the memory limit in training.\nTraining a Kernel FDA classifier requires creating matrices that are <code>n_samples</code> by <code>n_samples</code> large, meaning the memory requirement grows with respect to <code>O(n_samples^2)</code>.</p>\n<p>The accuracy, while high (0.97 on MNIST), seems to be limited by the training set size.\nWith a training size of 10000 and a testing size of 60000, performance on MNIST averages around 0.97 accuracy using 9 fisher directions and the RBF kernel:</p>\n<pre><span class=\"bp\">cls</span> <span class=\"o\">=</span> <span class=\"n\">Kfda</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"o\">=</span><span class=\"s1\">'rbf'</span><span class=\"p\">,</span> <span class=\"n\">n_components</span><span class=\"o\">=</span><span class=\"mi\">9</span><span class=\"p\">)</span>\n</pre>\n<p>This may be due to the constrained training size.\nAccuracy can be improved without increasing training size by implementing invariant kernels that would implicitly handle scale and rotation without requiring an extended dataset.</p>\n<h2>Oneshot Learning</h2>\n<p>Oneshot learning means that an algorithm can learn a new class with as little as one sample.\nThis is possible for Kernel FDA because it finds a subspace that purposefully spreads out distinct classes.\nIntroducing a new label involves simply adding another centroid for use in prediction.\nSee the\n<a href=\"https://colab.research.google.com/drive/1nnVphyZ_0QKYZbmdJaIBjm-zYO4xwF0b\" rel=\"nofollow\">Colab Notebook</a>.\nor the\n<a href=\"https://github.com/concavegit/kfda/blob/master/examples/mnist_oneshot.py\" rel=\"nofollow\">example</a> for examples.</p>\n\n          </div>"}, "last_serial": 7153687, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "1c543cfc89cae6efe77f1abb892a5beb", "sha256": "ad66d53a3cdf867bb0468392a1fd66449ab6117f7d454e22d19b50c1bfada963"}, "downloads": -1, "filename": "kfda-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1c543cfc89cae6efe77f1abb892a5beb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 4809, "upload_time": "2020-05-01T23:24:37", "upload_time_iso_8601": "2020-05-01T23:24:37.437154Z", "url": "https://files.pythonhosted.org/packages/0c/6c/97268ec65e9029e3da07097df27386db713f457bbc24d10779c5545bb05f/kfda-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a8352c33812e7a8be4b2e58a47ffbb96", "sha256": "1a3701faf2098c891d9267af6caa3bb6b08048d90c0ecf8ac816a5fe79b60910"}, "downloads": -1, "filename": "kfda-0.1.0.tar.gz", "has_sig": false, "md5_digest": "a8352c33812e7a8be4b2e58a47ffbb96", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3868, "upload_time": "2020-05-01T23:24:40", "upload_time_iso_8601": "2020-05-01T23:24:40.476765Z", "url": "https://files.pythonhosted.org/packages/e0/aa/1719acf6f0ce1607da948d72bc5d5c88801acec1d022538c4828596a0eee/kfda-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "9a2dc7965308087c536e7483f5835799", "sha256": "9ddcab446b25dc0ac0770979aca7473f10db0e16951dafaa7e90d51297683ae9"}, "downloads": -1, "filename": "kfda-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9a2dc7965308087c536e7483f5835799", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 6399, "upload_time": "2020-05-02T22:05:30", "upload_time_iso_8601": "2020-05-02T22:05:30.804384Z", "url": "https://files.pythonhosted.org/packages/58/6a/74ff6846b076c1181aae42c6965241621cda616d9228d8b88ae8f4917741/kfda-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82a0f43355599bb6b60b9a1d99c81ce7", "sha256": "122224712f8e9f06e96cc9129d4832871d4a855b13c0b7e4a20b6271740d2ee0"}, "downloads": -1, "filename": "kfda-0.1.1.tar.gz", "has_sig": false, "md5_digest": "82a0f43355599bb6b60b9a1d99c81ce7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 5310, "upload_time": "2020-05-02T22:05:32", "upload_time_iso_8601": "2020-05-02T22:05:32.022689Z", "url": "https://files.pythonhosted.org/packages/8f/e5/a4b327665038c3aa0f4966d3ab60fe5bcb59eaa63d832858b976d07d2db8/kfda-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9a2dc7965308087c536e7483f5835799", "sha256": "9ddcab446b25dc0ac0770979aca7473f10db0e16951dafaa7e90d51297683ae9"}, "downloads": -1, "filename": "kfda-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9a2dc7965308087c536e7483f5835799", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 6399, "upload_time": "2020-05-02T22:05:30", "upload_time_iso_8601": "2020-05-02T22:05:30.804384Z", "url": "https://files.pythonhosted.org/packages/58/6a/74ff6846b076c1181aae42c6965241621cda616d9228d8b88ae8f4917741/kfda-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82a0f43355599bb6b60b9a1d99c81ce7", "sha256": "122224712f8e9f06e96cc9129d4832871d4a855b13c0b7e4a20b6271740d2ee0"}, "downloads": -1, "filename": "kfda-0.1.1.tar.gz", "has_sig": false, "md5_digest": "82a0f43355599bb6b60b9a1d99c81ce7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 5310, "upload_time": "2020-05-02T22:05:32", "upload_time_iso_8601": "2020-05-02T22:05:32.022689Z", "url": "https://files.pythonhosted.org/packages/8f/e5/a4b327665038c3aa0f4966d3ab60fe5bcb59eaa63d832858b976d07d2db8/kfda-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:54 2020"}