{"info": {"author": "Applied Brain Research", "author_email": "info@appliedbrainresearch.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Framework :: Nengo", "Intended Audience :: Science/Research", "License :: Free for non-commercial use", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX :: Linux", "Programming Language :: Python", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": ".. image:: https://img.shields.io/pypi/v/nengo-dl.svg\n  :target: https://pypi.org/project/nengo-dl\n  :alt: Latest PyPI version\n\n.. image:: https://img.shields.io/travis/nengo/nengo-dl/master.svg\n  :target: https://travis-ci.org/nengo/nengo-dl\n  :alt: Travis-CI build status\n\n.. image:: https://ci.appveyor.com/api/projects/status/github/nengo/nengo-dl?branch=master&svg=true\n  :target: https://ci.appveyor.com/project/nengo/nengo-dl\n  :alt: AppVeyor build status\n\n.. image:: https://img.shields.io/codecov/c/github/nengo/nengo-dl/master.svg\n  :target: https://codecov.io/gh/nengo/nengo-dl\n  :alt: Test coverage\n\n|\n\n.. image:: https://www.nengo.ai/design/_images/nengo-dl-full-light.svg\n  :target: https://www.nengo.ai/nengo-dl\n  :alt: NengoDL\n  :width: 400px\n\n***********************************\nDeep learning integration for Nengo\n***********************************\n\nNengoDL is a simulator for `Nengo <https://www.nengo.ai/nengo/>`_ models.\nThat means it takes a Nengo network as input, and allows the user to simulate\nthat network using some underlying computational framework (in this case,\n`TensorFlow <https://www.tensorflow.org/>`_).\n\nIn practice, what that means is that the code for constructing a Nengo model\nis exactly the same as it would be for the standard Nengo simulator.  All that\nchanges is that we use a different Simulator class to execute the\nmodel.\n\nFor example:\n\n.. code-block:: python\n\n    import nengo\n    import nengo_dl\n    import numpy as np\n\n    with nengo.Network() as net:\n        inp = nengo.Node(output=np.sin)\n        ens = nengo.Ensemble(50, 1, neuron_type=nengo.LIF())\n        nengo.Connection(inp, ens, synapse=0.1)\n        p = nengo.Probe(ens)\n\n    with nengo_dl.Simulator(net) as sim: # this is the only line that changes\n        sim.run(1.0)\n\n    print(sim.data[p])\n\nHowever, NengoDL is not simply a duplicate of the Nengo simulator.  It also\nadds a number of unique features, such as:\n\n- optimizing the parameters of a model through deep learning\n  training methods (using the Keras API)\n- faster simulation speed, on both CPU and GPU\n- automatic conversion from Keras models to Nengo networks\n- inserting  TensorFlow code (individual functions or whole\n  network architectures) directly into a Nengo model\n\n**Documentation**\n\nCheck out the `documentation <https://www.nengo.ai/nengo-dl/>`_ for\n\n- `Installation instructions\n  <https://www.nengo.ai/nengo-dl/installation.html>`_\n- `Details on the unique features of NengoDL\n  <https://www.nengo.ai/nengo-dl/user-guide.html>`_\n- `Tutorial for new users with a TensorFlow background\n  <https://www.nengo.ai/nengo-dl/examples/from-tensorflow.html>`_\n- `Tutorial for new users with a Nengo background\n  <https://www.nengo.ai/nengo-dl/examples/from-nengo.html>`_\n- `More in-depth examples <https://www.nengo.ai/nengo-dl/examples.html>`_\n- `API reference <https://www.nengo.ai/nengo-dl/reference.html>`_\n\nRelease history\n===============\n\n.. Changelog entries should follow this format:\n\n   version (release date)\n   ----------------------\n\n   **section**\n\n   - One-line description of change (link to GitHub issue/PR)\n\n.. Changes should be organized in one of several sections:\n\n   - Added\n   - Changed\n   - Fixed\n   - Deprecated\n   - Removed\n\n3.2.0 (April 2, 2020)\n---------------------\n\n**Added**\n\n- Added ``nengo_dl.LeakyReLU`` and ``nengo_dl.SpikingLeakyReLU`` neuron models.\n  (`#126`_)\n- Added support for leaky ReLU Keras layers to ``nengo_dl.Converter``. (`#126`_)\n- Added a new ``remove_reset_incs`` graph simplification step. (`#129`_)\n- Added support for UpSampling layers to ``nengo_dl.Converter``. (`#130`_)\n- Added tolerance parameters to ``nengo_dl.Converter.verify``. (`#130`_)\n- Added ``scale_firing_rates`` option to ``nengo_dl.Converter``. (`#134`_)\n- Added ``Converter.layers`` attribute which will map Keras layers/tensors to\n  the converted Nengo objects, to make it easier to access converted components.\n  (`#134`_)\n- Compatible with TensorFlow 2.2.0. (`#140`_)\n- Added a new ``synapse`` argument to the Converter, which can be used to automatically\n  add synaptic filters on the output of neural layers during the conversion process.\n  (`#141`_)\n- Added a `new example <https://www.nengo.ai/nengo-dl/examples/keras-to-snn.html>`__\n  demonstrating how to use the NengoDL Converter to convert a Keras model to a spiking\n  Nengo network. (`#141`_)\n\n**Changed**\n\n- Re-enabled the ``remove_constant_copies`` graph simplification by default. (`#129`_)\n- Reduced the amount of state that needs to be stored in the simulation. (`#129`_)\n- Added more information to the error message when loading saved parameters that\n  don't match the current model. (`#129`_)\n- More efficient implementation of convolutional biases in the Converter. (`#130`_)\n- Saved simulator state will no longer be included in ``Simulator.keras_model.weights``.\n  This means that ``Simulator.keras_model.save/load_weights`` will not include the\n  saved simulator state, making it easier to reuse weights between models (as long as\n  the models have the same weights, they do not need to have the same state variables).\n  ``Simulator.save/load_params(..., include_state=True)`` can be used to explicitly\n  save the simulator state, if desired. (`#140`_)\n- Model parameters (e.g., connection weights) that are not trainable (because they've\n  been marked non-trainable by user or targeted by an online learning rule) will now\n  be treated separately from simulator state. For example,\n  ``Simulator.save_params(..., include_state=False)`` will still include those\n  parameters, and the results of any online learning will persist between calls even\n  with ``stateful=False``. (`#140`_)\n- Added ``include_probes``, ``include_trainable``, and ``include_processes`` arguments\n  to ``Simulator.reset`` to provide more fine-grained control over Simulator\n  resetting. This replicates the previous functionality in ``Simulator.soft_reset``.\n  (`#139`_)\n- More informative error messages when accessing invalid Simulator functionality after\n  the Simulator has been closed. (`#139`_)\n- A warning is now raised when the number of input data items passed to the simulator\n  does not match the number of input nodes, to help avoid unintentionally passing\n  data to the wrong input node. This warning can be avoided by passing data for\n  all nodes, or using the dictionary input style if you want to only pass data for\n  a specific node. (`#139`_)\n- Dictionaries returned by ``sim.predict/evaluate`` will now be ordered. (`#141`_)\n\n**Fixed**\n\n- Fixed bug in error message when passing data with batch size less than Simulator\n  minibatch size. (`#139`_)\n- More informative error message when ``validation_split`` does not result in batch\n  sizes evenly divisible by minibatch size. (`#139`_)\n- Added ``tensorflow-cpu`` distributions to installation checks (so Nengo DL will\n  not attempt to reinstall TensorFlow if ``tensorflow-cpu`` is already installed).\n  (`#142`_)\n- Fixed bug when applying the Converter to Keras models that re-use intermediate\n  layers as output layers. (`#137`_)\n- Fixed bug in conversion of Keras Dense layers with non-native activation functions.\n  (`#144`_)\n\n**Deprecated**\n\n- Renamed ``Simulator.save/load_params`` ``include_non_trainable`` parameter to\n  ``include_state``. (`#140`_)\n- ``Simulator.soft_reset`` has been deprecated. Use\n  ``Simulator.reset(include_probes=False, include_trainable=False,\n  include_processes=False)`` instead. (`#139`_)\n\n.. _#126: https://github.com/nengo/nengo-dl/pull/126\n.. _#129: https://github.com/nengo/nengo-dl/pull/129\n.. _#130: https://github.com/nengo/nengo-dl/pull/130\n.. _#134: https://github.com/nengo/nengo-dl/pull/134\n.. _#137: https://github.com/nengo/nengo-dl/pull/137\n.. _#139: https://github.com/nengo/nengo-dl/pull/139\n.. _#140: https://github.com/nengo/nengo-dl/pull/140\n.. _#141: https://github.com/nengo/nengo-dl/pull/141\n.. _#142: https://github.com/nengo/nengo-dl/pull/142\n.. _#144: https://github.com/nengo/nengo-dl/pull/144\n\n3.1.0 (March 4, 2020)\n---------------------\n\n**Added**\n\n- Added ``inference_only=True`` option to the Converter, which will allow some\n  Layers/parameters that cannot be fully converted to native Nengo objects to be\n  converted in a way that only matches the inference behaviour of the source Keras model\n  (not the training behaviour). (`#119`_)\n\n**Changed**\n\n- Improved build time of networks containing lots of ``TensorNodes``. (`#119`_)\n- Improved memory usage of build process. (`#119`_)\n- Saved simulation state may now be placed on GPU (this should improve the speed of\n  state updates, but may slightly increase GPU memory usage). (`#119`_)\n- Changed Converter ``freeze_batchnorm=True`` option to ``inference_only=True``\n  (effect of the parameter is the same on BatchNormalization layers, but also has\n  broader effects). (`#119`_)\n- The precision of the Nengo core build process will now be set based on the\n  ``nengo_dl.configure_settings(dtype=...)`` config option. Note that this will\n  override the default precision set in ``nengo.rc``. (`#119`_)\n- Minimum Numpy version is now 1.16.0 (required by TensorFlow). (`#119`_)\n- Added support for the new ``transform=None`` default in Nengo connections\n  (see `Nengo#1591`_). Note that this may change the number of trainable\n  parameters in a network as the scalar default ``transform=1`` weights on\n  non-Ensemble connections will no longer be present. (`#128`_)\n\n**Fixed**\n\n- Provide a more informative error message if Layer ``shape_in``/``shape_out`` contains\n  undefined (``None``) elements. (`#119`_)\n- Fixed bug in ``Converter`` when source model contains duplicate nodes. (`#119`_)\n- Fixed bug in ``Converter`` for ``Concatenate`` layers with ``axis != 1``. (`#119`_)\n- Fixed bug in ``Converter`` for models containing passthrough ``Input`` layers inside\n  submodels. (`#119`_)\n- Keras Layers inside TensorNodes will be called with the ``training`` argument set\n  correctly (previously it was always set to the default value). (`#119`_)\n- Fixed compatibility with ``progressbar2`` version 3.50.0. (`#136`_)\n\n.. _#119: https://github.com/nengo/nengo-dl/pull/119\n.. _#128: https://github.com/nengo/nengo-dl/pull/128\n.. _#136: https://github.com/nengo/nengo-dl/pull/136\n.. _Nengo#1591: https://github.com/nengo/nengo/pull/1591\n\n3.0.0 (December 17, 2019)\n-------------------------\n\nThere are a lot of **breaking changes** in NengoDL 3.0. See the `migration guide\n<https://www.nengo.ai/nengo-dl/migration-guide.html#nengodl-2-to-3>`_ for all the\ndetails.\n\n**Added**\n\n- Keras ``Layer`` classes can now be used with ``nengo_dl.Layer/tensor_layer``.\n- ``TensorGraph`` can now be used as a Keras ``Layer``.\n- Added ``Simulator.predict/evaluate/fit`` functions, which\n  implement the Keras\n  `Model API <https://www.tensorflow.org/api_docs/python/tf/keras/Model>`_.\n- Added a warning that changing the TensorFlow seed (e.g. on ``Simulator.reset``) will\n  not affect any existing TensorFlow operations (this was always true in TensorFlow,\n  the warning is just to help avoid confusion).\n- Added ``TensorGraph.build_inputs``, which will return a set of Keras ``Input`` layers\n  that can be used as input to the TensorGraph layer itself.\n- Added ``nengo_dl.callbacks.TensorBoard``. This is identical to\n  ``tf.keras.callbacks.TensorBoard``, except it will also perform profiling during\n  inference (rather than only during training).\n- Added ``stateful`` option to ``Simulator.run`` which can be set to False to avoid\n  updating the saved simulation state at the end of a run.\n- Added ``nengo_dl.configure_settings(stateful=False)`` option to avoid building the\n  parts of the model responsible for preserving state between executions (this will\n  override any ``stateful=True`` arguments in individual functions).\n- Added ``nengo_dl.configure_settings(use_loop=False)`` option to avoid building the\n  simulation inside a symbolic TensorFlow loop. This may improve simulation speed,\n  but the simulation can only run for exactly ``unroll_simulation`` timesteps.\n- NengoDL now requires ``jinja2`` (used to template some of the docstrings).\n- Added an ``inputs`` argument to ``Simulator.check_gradients``, which can be used to\n  control the initial value of input Nodes during the gradient calculations.\n- Added ``nengo_dl.Converter`` for automatically converting Keras models to native\n  Nengo networks.  See `the documentation\n  <https://www.nengo.ai/nengo-dl/converter.html>`__ for more details.\n- Added `Legendre Memory Unit RNN example\n  <https://www.nengo.ai/nengo-dl/examples/lmu.html>`_.\n\n**Changed**\n\n- Minimum TensorFlow version is now 2.0.0.\n- ``Simulator.save/load_params`` now uses a single\n  ``include_non_trainable=True/False`` (equivalent to the previous\n  ``include_local``). Trainable parameters will always be saved, so the\n  ``include_global`` argument is removed.\n- Standardized all signals/operations in a simulation to be batch-first.\n- The `dtype option <https://www.nengo.ai/nengo-dl/config.html#dtype>`_ is now specified\n  as a string (e.g. ``\"float32\"`` rather than ``tf.float32``).\n- If the requested number of simulation steps is not evenly divisible by\n  ``Simulator.unroll_simulation`` then probe values and ``sim.time/n_steps`` will be\n  updated based on the number of steps actually run (rather than the requested\n  number of steps).  Note that these extra steps were also run previously, but their\n  results were hidden from the user.\n- Renamed ``TensorGraph.input_ph`` to ``TensorGraph.node_inputs``.\n- ``Simulator.time/n_steps`` are now read-only.\n- ``Simulator.n_steps/time`` are now managed as part of the op graph, rather than\n  manually in the Simulator.\n- Renamed ``nengo_dl.objectives`` to ``nengo_dl.losses`` (to align with ``tf.losses``).\n- ``nengo_dl.objectives.Regularize`` now takes two arguments (``y_true`` and ``y_pred``)\n  in order to be compatible with the ``tf.losses.Loss`` API (``y_true`` is ignored).\n- The `remove_constant_copies\n  <https://www.nengo.ai/nengo-dl/reference.html#nengo_dl.graph_optimizer.remove_constant_copies>`_\n  simplification step is now disabled by default.\n  In certain situations this could be an unsafe manipulation (specifically,\n  when using ``Simulator.save/load_params`` it could change which parameters are saved).\n  It can be manually re-enabled through the\n  `simplifications <https://www.nengo.ai/nengo-dl/config.html#simplifications>`_\n  configuration option.\n- ``Simulator.check_gradients`` now only accepts an optional list of Probes (no longer\n  accepts arbitrary Tensors).\n- Eager execution is no longer disabled on import (it is still disabled within the\n  Simulator context, for performance reasons; see\n  https://github.com/tensorflow/tensorflow/issues/33052).\n- ``nengo_dl.tensor_layer(x, func, ...)`` now passes any extra kwargs to the\n  ``nengo_dl.TensorNode`` constructor (rather than to ``func``). If you need to pass\n  information to ``func`` consider using partial functions (e.g.\n  ``tensor_layer(functools.partial(x, func, arg=5), ...)`` or a callable class\n  (e.g., ``tensor_layer(x, MyFunc(arg=5), ...))``. When using Keras Layers with\n  ``nengo_dl.tensor_layer``, a fully instantiated Layer\n  object should be passed rather than a Layer class (e.g., use\n  ``tensor_layer(x, tf.keras.layers.Dense(units=10), ...)`` instead of\n  ``tensor_layer(x, tf.keras.layers.Dense, units=10)``).\n- ``benchmarks.run_profile`` now uses the TensorBoard format when profiling,\n  see `the documentation\n  <https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras>`_ for\n  instructions on how to view this information (the information is the same, it is\n  just accessed through TensorBoard rather than requiring that it be loaded directly\n  in a Chrome browser).\n- ``nengo_dl.TensorNode`` now takes ``shape_in`` and ``shape_out`` arguments (which\n  specify a possibly multidimensional shape), rather\n  than the scalar ``size_in`` and ``size_out``.\n- ``TensorNode`` functions no longer use the ``pre_build``/``post_build`` functionality.\n  If you need to implement more complex behaviour in a TensorNode, use a\n  custom Keras Layer subclass instead.  For example, TensorNodes Layers can create new\n  parameter Variables inside the Layer ``build`` method.\n- ``TensorNode`` now has an optional ``pass_time`` parameter which can be set to\n  ``False`` to disable passing the current simulation time to the TensorNode function.\n- Added ``nengo_dl.Layer``. Similar to the old ``nengo_dl.tensor_layer``, this is a\n  wrapper for constructing TensorNodes, but it mimics the new ``tf.keras.layers.Layer``\n  API rather than the old ``tf.layers``.\n- TensorFlow's \"control flow v2\" is disabled on import, for performance reasons; see\n  https://github.com/tensorflow/tensorflow/issues/33052.\n- Renamed ``nengo_dl.objectives.mse`` to ``nengo_dl.losses.nan_mse`` (to emphasize\n  the special logic it provides for ``nan`` targets).\n- Connections created by ``nengo_dl.Layer/tensor_layer`` will be marked as\n  non-trainable by default.\n- Updated all documentation and examples for the new syntax (in particular, see the\n  updated `Coming from TensorFlow\n  <https://www.nengo.ai/nengo-dl/examples/from-tensorflow.html#>`_ tutorial and\n  `TensorFlow/Keras integration\n  <https://www.nengo.ai/nengo-dl/examples/tensorflow-models.html>`_ example, and the\n  new `Tips and tricks <https://www.nengo.ai/nengo-dl/tips.html>`_ page).\n- The training/inference build logic (e.g., swapping spiking neurons with rate\n  implementations) can be overridden by setting the global Keras learning phase\n  (``tf.keras.backend.set_learning_phase``) before the Simulator is constructed.\n- Increased minimum Nengo core version to 3.0.0.\n- Reduced size of TensorFlow constants created by Reset ops.\n- DotInc operators with different signal sizes will no longer be merged (these\n  merged operators had to use a less efficient sparse matrix multiplication, and in\n  general this cost outweighed the benefit of merging).\n- Trainability can now be configured in the config of subnetworks. This replaces\n  the ability to mark Networks as (non)trainable. See the `updated documentation\n  <https://www.nengo.ai/nengo-dl/config.html#trainable>`__ for details.\n- Training/evaluation target data can now have a different number of timesteps than\n  input data (as long as it aligns with the number of timesteps expected by the\n  loss function).\n- Whether or not to display progress bars in ``Simulator.run`` and\n  ``Simulator.run_steps`` now defaults to the value of\n  ``Simulator(..., progress_bar=x)``.\n\n**Fixed**\n\n- Fixed bug due to non-determinism of Process state ordering in Python 3.5.\n- Nested Keras layers passed to TensorNode will be rebuilt correctly if necessary.\n\n**Deprecated**\n\n- ``nengo_dl.tensor_layer`` has been deprecated. Use ``nengo_dl.Layer`` instead;\n  ``tensor_layer(x, func, **kwargs)`` is equivalent to ``Layer(func)(x, **kwargs)``.\n\n**Removed**\n\n- Removed the `session_config\n  <https://www.nengo.ai/nengo-dl/v2.2.1/config.html#session-config>`_ configuration\n  option. Use the `updated TensorFlow config system\n  <https://www.tensorflow.org/api_docs/python/tf/config>`_ instead.\n- Removed the deprecated ``nengo_dl.Simulator(..., dtype=...)`` argument. Use\n  ``nengo_dl.configure_settings(dtype=...)`` instead.\n- Removed the deprecated ``Simulator.run(..., input_feeds=...)`` argument. Use\n  ``Simulator.run(..., data=...)`` instead.\n- Removed the ``Simulator.sess`` attribute (Sessions are no longer used in\n  TensorFlow 2.0).  The underlying Keras model (``Simulator.keras_model``) should be\n  used as the entrypoint into the engine underlying a Simulator instead.\n- Removed the ``Simulator.loss`` function (use ``Simulator.compile`` and\n  ``Simulator.evaluate`` to compute loss values instead).\n- Removed the ``Simulator.train`` function (use ``Simulator.compile`` and\n  ``Simulator.fit`` to optimize a network instead).\n- Removed the ``nengo_dl.objectives.Regularize(weight=x, ...)`` argument. Use the\n  ``Simulator.compile(loss_weights=...)`` functionality instead.\n- Removed the ``Simulator.run(..., extra_feeds=...)`` argument. TensorFlow 2.0 no longer\n  uses the Session/feed execution model.\n- Removed ``Simulator.run_batch``. This functionality is now managed by the underlying\n  ``Simulator.keras_model``.\n- Removed ``TensorGraph.training_step``. The training step is now managed by Keras.\n- Removed ``TensorGraph.build_outputs`` and ``TensorGraph.build_optimizer_func``.\n  Building loss functions/optimizers is now managed by Keras.\n- Removed ``nengo_dl.utils.find_non_differentiable`` (this no longer works in TF2.0's\n  eager mode).\n- Removed ``Simulator(..., tensorboard=...)`` argument. Use the Keras TensorBoard\n  callback approach for TensorBoard logging instead (see\n  ``tf.keras.callbacks.TensorBoard`` or ``nengo_dl.callbacks.NengoSummaries``).\n- NengoDL will no longer monkeypatch fix the ``tf.dynamic_stitch`` gradients on import.\n  The gradients are still incorrect (see\n  https://github.com/tensorflow/tensorflow/issues/7397), but we no longer use this\n  operation within NengoDL so we leave it up to the user to fix it in their own code\n  if needed.\n- Removed ``benchmarks.matmul_vs_reduce``. We use matmul for everything now, so this\n  comparison is no longer necessary.\n- Removed ``utils.minibatch_generator`` (training/inference loops are now managed\n  by Keras).\n\n2.2.2 (November 20, 2019)\n-------------------------\n\n**Fixed**\n\n- Compatibility with Nengo 3.0 release\n\n2.2.1 (October 2, 2019)\n-----------------------\n\n**Changed**\n\n- Update testing framework to use new nengo pytest ecosystem (``pytest-rng``,\n  ``pytest-allclose``, and ``pytest-nengo``)\n- Disable TensorFlow 2.0 behaviour (e.g. control flow v2) by default.  This will be\n  re-enabled when full TensorFlow 2.0 support is added.\n\n**Fixed**\n\n- Fixed ``tensorflow-gpu`` installation check in pep517-style isolated build\n  environments.\n\n2.2.0 (July 24, 2019)\n---------------------\n\n**Added**\n\n- Added a\n  `new example <https://www.nengo.ai/nengo-dl/examples/tensorflow-models>`_\n  demonstrating how to integrate a Keras model with NengoDL (thanks to new\n  contributor `@NickleDave <https://github.com/NickleDave>`_).\n- Added support for TensorFlow 2.0 (pre-release).\n- Added support for sparse transforms\n  (see https://github.com/nengo/nengo/pull/1532).\n- Added support for stateful Processes\n  (see https://github.com/nengo/nengo/pull/1387).\n\n**Changed**\n\n- The default session will now be set to the NengoDL session before calling\n  TensorNodes' ``post_build`` function.\n- Renamed the pytest ``unroll_simulation`` argument to ``unroll-simulation``.\n- Switched to nengo-bones templating system for TravisCI config/scripts.\n- NengoDL will disable eager execution on import (and will probably not\n  work properly if it is manually re-enabled).\n- Increased minimum numpy version to 1.14.5 (required by TensorFlow 1.14).\n- Minimum Nengo version is now 2.8.0.\n- Update LinearFilter synapse implementation to match recent changes in\n  Nengo core (see https://github.com/nengo/nengo/pull/1535).\n\n**Fixed**\n\n- Fixed TensorFlow seeding so that randomness can be reliably controlled by\n  setting the Simulator seed.\n- Improved robustness of ``tensorflow-gpu`` installation check (in particular,\n  it will now correctly detect GPU dists installed through ``conda``).\n- Fixed inspection of ``TensorNode.tensor_func`` arguments for partial\n  functions.\n- Simulator seed will now be deterministic for a given top-level Network seed.\n- Raise a more informative error if user attempts to pickle a Simulator\n  (this is not possible to do with TensorFlow sessions; see\n  `the documentation\n  <https://www.nengo.ai/nengo-dl/simulator.html#saving-and-loading-parameters>`__\n  for other methods of saving/loading a NengoDL model).\n\n**Removed**\n\n- NengoDL no longer supports Python 3.4 (official support for 3.4 ended in\n  March 2019).\n\n\n2.1.1 (January 11, 2019)\n------------------------\n\n**Added**\n\n- Added ``nengo_dl.obj`` as a shortcut alias for ``nengo_dl.objectives``.\n- Added tutorial for `Nengo users coming to NengoDL\n  <https://www.nengo.ai/nengo-dl/examples/from-nengo.html>`_\n- Added tutorial for `TensorFlow users coming to NengoDL\n  <https://www.nengo.ai/nengo-dl/examples/from-tensorflow.html>`_\n\n**Changed**\n\n- Increased minimum ``progressbar2`` version to 3.39.0.\n- We now only provide ``sdist`` releases, not ``bdist_wheel``. Due to the way\n  the TensorFlow packages are organized, ``bdist_wheel``  forces any existing\n  TensorFlow installations (e.g. ``tensorflow-gpu`` or ``tf-nightly``)\n  to be overwritten by ``tensorflow``, which we don't want to do.\n\n**Removed**\n\n- Removed the ``nef-init`` tutorial (replaced by the new ``from-nengo``\n  tutorial).\n\n2.1.0 (December 5, 2018)\n------------------------\n\n**Added**\n\n- Added a built-in objective to assist in applying regularization during\n  training.\n- Added `keep_history config option\n  <https://www.nengo.ai/nengo-dl/config.html#keep-history>`_, which can be set\n  to ``False`` on Probes if only the data from the most recent simulation step\n  is desired (as opposed to the default behaviour of keeping the data from\n  all steps).\n\n**Changed**\n\n- Moved ``utils.mse`` to ``objectives.mse``.\n- ``sim.loss`` will now apply ``nengo_dl.objectives.mse`` to all probes in\n  ``data`` if no explicit ``objective`` is given (mirroring the default\n  behaviour in ``sim.train``).\n- The Spaun benchmark network will now be installed through pip rather than\n  manually cloning and importing the repo.\n\n**Fixed**\n\n- Fixed objective argument parsing if objective is a callable class or method.\n- Fixed bug in ``sim.train`` 1-step synapse warning when explicitly specifying\n  ``n_steps`` (rather than passing in ``data``).\n\n**Deprecated**\n\n- Passing ``\"mse\"`` as the objective in ``sim.train``/``sim.loss`` is no longer\n  supported.  Use the function ``nengo_dl.objectives.mse`` instead.\n\n2.0.0 (November 23, 2018)\n-------------------------\n\n**Breaking API changes**\n\n- ``sim.train`` and ``sim.loss`` now accept a single ``data`` argument, which\n  combines the previous ``inputs`` and ``targets`` arguments. For example,\n\n  .. code-block:: python\n\n    sim.train({my_node: x}, {my_probe: y}, ...)\n\n  is now equivalent to\n\n  .. code-block:: python\n\n    sim.train({my_node: x, my_probe: y}, ...)\n\n  The motivation for this change is that not all objective functions require\n  target values. Switching to the more generic ``data`` argument simplifies\n  the API and makes it more flexible, allowing users to specify whatever\n  training/loss data is actually required.\n- The ``objective`` argument in ``sim.train``/``sim.loss`` is now always\n  specified as a dictionary mapping probes to objective functions.  Note that\n  this was available but optional previously; it was also possible to pass\n  a single value for the objective function, which would be applied to all\n  probes in ``targets``.  The latter is no longer supported.  For example,\n\n  .. code-block:: python\n\n    sim.train(..., objective=\"mse\")\n\n  must now be explicitly specified as\n\n  .. code-block:: python\n\n    sim.train(..., objective={my_probe: \"mse\"})\n\n  The motivation for this change is that, especially with the other new\n  features introduced in the 2.0 update, there were a lot of different ways to\n  specify the ``objective`` argument.  This made it somewhat unclear how\n  exactly this argument worked, and the automatic \"broadcasting\" was also\n  ambiguous (e.g., should the single objective be applied to each probe\n  individually, or to all of them together?).  Making the argument explicit\n  helps clarify the mental model.\n\n**Added**\n\n- An integer number of steps can now be passed for the\n  ``sim.loss``/``sim.train`` data argument, if no input/target data is\n  required.\n- The ``objective`` dict in ``sim.train``/``sim.loss`` can now contain\n  tuples of probes as the keys, in which case the objective function will be\n  called with a corresponding tuple of probe/target values as each argument.\n- Added the ``sim.run_batch`` function.  This exposes all the functionality\n  that the ``sim.run``/``sim.train``/``sim.loss`` functions are based on,\n  allowing advanced users full control over how to run a NengoDL simulation.\n- Added option to disable progress bar in ``sim.train`` and ``sim.loss``.\n- Added ``training`` argument to ``sim.loss`` to control whether the loss\n  is evaluated in training or inference mode.\n- Added support for the new Nengo ``Transform`` API (see\n  https://github.com/nengo/nengo/pull/1481).\n\n**Changed**\n\n- Custom objective functions passed to ``sim.train``/``sim.loss`` can now\n  accept a single argument (``my_objective(outputs): ...`` instead of\n  ``my_objective(outputs, targets): ...``) if no target values are required.\n- ``utils.minibatch_generator`` now accepts a single ``data`` argument rather\n  than ``inputs`` and ``targets`` (see discussion in \"Breaking API changes\").\n- ``sim.training_step`` is now the same as\n  ``tf.train.get_or_create_global_step()``.\n- Switched documentation to new\n  `nengo-sphinx-theme <https://github.com/nengo/nengo-sphinx-theme>`_.\n- Reorganized documentation into \"User guide\" and \"API reference\" sections.\n- Improve build speed of models with large constants\n  (`#69 <https://github.com/nengo/nengo-dl/pull/69>`_)\n- Moved op-specific merge logic into the ``OpBuilder`` classes.\n\n**Fixed**\n\n- Ensure that training step is always updated before TensorBoard events are\n  added (previously it could update before or after depending on the platform).\n\n**Deprecated**\n\n- The ``sim.run`` ``input_feeds`` argument has been renamed to ``data`` (for\n  consistency with other simulator functions).\n\n**Removed**\n\n- NengoDL no longer supports Python 2 (see https://python3statement.org/ for\n  more information)\n\n1.2.1 (November 2, 2018)\n------------------------\n\n**Added**\n\n- Added a warning if users run one-timestep training with a network containing\n  synaptic filters.\n\n**Changed**\n\n- Test Simulator parameters are now controlled through pytest arguments,\n  rather than environment variables.\n- Disable INFO-level TensorFlow logging (from C side) on import.  Added a\n  NengoDL log message indicating the device the simulation will run on, as\n  a more concise replacement.\n- Boolean signals are now supported\n  (`#61 <https://github.com/nengo/nengo-dl/issues/61>`_)\n\n**Fixed**\n\n- Avoid backpropagating NaN gradients from spiking neurons.\n- Fixed an error that was thrown when calling ``get_tensor`` on a ``Signal``\n  that was first initialized inside the Simulation while loop\n  (`#56 <https://github.com/nengo/nengo-dl/issues/56>`_)\n- Allow TensorNodes to run in Nengo GUI.\n- Avoid bug in TensorFlow 1.11.0 that prevents certain models from\n  running (see https://github.com/tensorflow/tensorflow/issues/23383). Note\n  that this doesn't prevent this from occurring in user models, as we cannot\n  control the model structure there. If your model hangs indefinitely when\n  you call ``sim.train``, try downgrading to TensorFlow 1.10.0.\n- Ensure that ``sim.training_step`` is always updated after the optimization\n  step (in certain race conditions it would sometimes update part-way through\n  the optimization step).\n\n1.2.0 (September 5, 2018)\n-------------------------\n\n**Added**\n\n- NengoDL will now automatically use a rate-based approximation to compute the\n  gradient for spiking neuron types, if one is known (no more need to manually\n  swap neuron types for training and inference).\n- Added ``nengo_dl.configure_settings(inference_only=True)`` option, which will\n  build the network in inference-only mode.  This will slightly improve the\n  inference speed of the simulation, but the network will not be trainable.\n- Added ``nengo_dl.configure_settings(lif_smoothing=x)`` option, which will\n  control how much smoothing is applied to the LIF function during gradient\n  calculations (if any).\n- Added `documentation <https://www.nengo.ai/nengo-dl/config.html>`__ on the\n  various NengoDL config options.\n- Added better validation for TensorNode output when ``size_out != None``\n  (`#51 <https://github.com/nengo/nengo-dl/issues/51>`_)\n\n**Changed**\n\n- More informative error message if the user tries to pass target values for\n  a probe that isn't used in the objective function.\n- Switched to ADD_N gradient accumulation (from TREE); this will increase\n  the memory usage during training, but improve performance.\n- Revert to ``Timeline`` profiling method. ``tf.profiler`` can produce\n  incorrect output, and isn't maintained any more\n  (https://github.com/tensorflow/tensorflow/issues/15214#issuecomment-382442357)\n- Reduce memory usage during training by caching temporary variables used\n  when computing ``ScatterUpdate`` gradient.\n- Increase minimum TensorFlow version to 1.4.0.\n- Increased minimum NumPy version to 1.12.1 (required by TensorFlow)\n- Sort write signals as well as reads during graph optimization (encourages\n  tighter partitioning, which can improve training/inference speed).\n- Moved ``configure_settings`` from ``utils.py`` to ``config.py``.\n\n**Fixed**\n\n- Fixed a bug where\n  ``nengo_dl.dists.VarianceScaling(..., distribution=\"normal\")`` did not\n  respect the seed if one was given.\n\n**Deprecated**\n\n- The ``Simulator(dtype=...)`` argument has been deprecated; use\n  ``nengo_dl.configure_settings(dtype=...)`` instead.  Will be removed in\n  1.3.0.\n\n1.1.0 (July 24, 2018)\n---------------------\n\n**Added**\n\n- The default TensorFlow Session is now set to the underlying Simulator session\n  within the Simulator context.\n- Added CLI for benchmarks.py\n- Added ``sim.freeze_params`` tool, to more easily extract model parameters for\n  reuse in different Simulators.\n- Added `documentation on saving and loading model parameters\n  <https://www.nengo.ai/nengo-dl/simulator.html#saving-and-loading-parameters>`_.\n- Added `Spaun <https://science.sciencemag.org/content/338/6111/1202.full>`_\n  example in ``benchmarks.py``\n\n**Changed**\n\n- Move ``tensorflow-gpu`` installation check to Simulator init, and only apply\n  if ``device=None``.\n- Switched to ``pylint`` for style checks.\n- TensorFlow INFO-level log messages are now disabled by default on import\n- All previous releases now tracked in documentation\n- Updated spiking MNIST example to simplify and improve performance.\n- Passing unknown configuration options to ``nengo_dl.configure_settings``\n  will now give a more explicit error message.\n- Improved speed of parameter fetching though ``get_nengo_params``\n- Raise a warning if user tries to train a network with non-differentiable\n  elements (requires ``tensorflow>=1.9.0``)\n- Improved accuracy of ``SoftLIFRate`` implementation for small values (`#45\n  <https://github.com/nengo/nengo-dl/pull/45>`_)\n- Simplified how ``TensorSignals`` are loaded into the TensorFlow graph\n\n**Fixed**\n\n- Better handling of Simulator errors not associated with a specific op (fixes\n  `#41 <https://github.com/nengo/nengo-dl/issues/41>`_)\n- Fixed node outputs changing after simulator is built (fixes `#4\n  <https://github.com/nengo/nengo-dl/issues/4>`__)\n- Fixed some broken cross references in the documentation\n- Fixed several edge cases for ``get_nengo_params``; don't use trained gains\n  for direct neuron connections, error raised if ``get_nengo_params`` applied\n  to an Ensemble with Direct neurons\n- Compatible with ``tensorflow==1.9.0`` release\n- Fixed bug in ``nengo_dl.configure_settings(session_config=...)`` when passing\n  a pre-build model to the Simulator instead of a Network\n- Fixed TensorFlow version comparisons for 1.10.0\n\n**Deprecated**\n\n- ``Simulator.trange`` argument ``dt`` has been deprecated (replaced with\n  ``sample_every``, see https://github.com/nengo/nengo/pull/1384)\n\n**Removed**\n\n- Removed ``nengo_dl.DATA_DIR`` constant\n- Removed ``benchmarks.compare_backends`` (use\n  ``whitepaper2018_plots.py:compare_backends`` instead)\n- Removed ``ghp-import`` dependency\n\n\n1.0.0 (May 30, 2018)\n--------------------\n\n**Added**\n\n- User can now directly specify the output error gradient, rather than using\n  targets/objective (useful for when you have some external process for\n  computing error that is not easy to implement as an objective function).\n  See `the documentation\n  <https://www.nengo.ai/nengo-dl/v1.0.0/training.html#objective>`__ for details.\n- Added `NengoDL white paper <https://arxiv.org/abs/1805.11144>`_\n\n**Changed**\n\n- Extra requirements for documentation/testing are now stored in ``setup.py``'s\n  ``extra_requires`` instead of ``requirements-*.txt``.  For example, instead\n  of doing ``pip install -r requirements-test.txt``, instead use\n  ``pip install nengo-dl[tests]`` (or ``pip install -e .[tests]`` for a\n  developer installation).\n- Improved efficiency of PES implementation\n\n**Removed**\n\n- Removed ``sphinxcontrib-versioning`` dependency for building documentation\n\n0.6.2 (May 4, 2018)\n-------------------\n\n**Added**\n\n- Added ``sim.get_nengo_params`` function to more easily extract\n  model parameters for reuse when building different models.\n- Added ``Simulator(..., progress_bar=False)`` option to disable the progress\n  information printed to console when the network is building.\n- TensorFlow session config options can now be set using\n  ``nengo_dl.configure_settings`` (e.g.,\n  ``nengo_dl.configure_settings(session_config={\"gpu_options.allow_growth\": True})``)\n- The signal sorting/graph simplificaton functions can now be configured\n  through ``nengo_dl.configure_settings``\n- Added ``extra_feeds`` parameter to ``sim.run/train/loss``, which can be\n  used to feed Tensor values directly into the TensorFlow session\n\n**Changed**\n\n- Improved speed of PES implementation by adding a custom operator.\n- Renamed project from ``nengo_dl`` to ``nengo-dl`` (to be more consistent with\n  standard conventions).  This only affects the display name of the project\n  on PyPI/GitHub, and the documentation now resides at\n  https://www.nengo.ai/nengo-dl/; there are no functional changes to user code.\n- Minor efficiency improvements to graph planner\n- Avoid using ``tf.constant``, to get around TensorFlow's 2GB limit on graph\n  size when building large models\n\n**Fixed**\n\n- Checking ``nengo_dl`` version without ``nengo`` installed will no longer\n  result in an error.\n- Updated progress bar to work with ``progressbar2>=3.37.0``\n- Updated PES implementation to work with generic synapse types\n  (see https://github.com/nengo/nengo/pull/1095)\n- Fixed installation to work with ``pip>=10.0``\n- Fixed bug when using a TensorNode with a ``pre_build`` function and\n  ``size_in==0``\n\n0.6.1 (March 7, 2018)\n---------------------\n\n**Added**\n\n- Added TensorFlow implementation for ``nengo.SpikingRectifiedLinear`` neuron\n  type.\n\n**Changed**\n\n- Optimizer variables (e.g., momentum values) will only be initialized the\n  first time that optimizer is passed to ``sim.train``.  Subsequent calls to\n  ``sim.train`` will resume with the values from the previous call.\n- Low-level simulation input/output formats have been reworked to make them\n  slightly easier to use (for users who want to bypass ``sim.run`` or\n  ``sim.train`` and access the TensorFlow session directly).\n- Batch dimension will always be first (if present) when checking model\n  parameters via ``sim.data``.\n- TensorFlow ops created within the Simulator context will now default to\n  the same device as the Simulator.\n- Update minimum Nengo version to 2.7.0\n\n**Fixed**\n\n- Better error message if training data has incorrect rank\n- Avoid reinstalling TensorFlow if one of the nightly build packages is already\n  installed\n- Lowpass synapse can now be applied to multidimensional inputs\n- TensorNodes will no longer be built into the default graph when checking\n  their output dimensionality.\n\n**Removed**\n\n- Removed ``utils.cast_dtype`` function\n\n0.6.0 (December 13, 2017)\n-------------------------\n\n**Added**\n\n- The ``SoftLIFRate`` neuron type now has an ``amplitude`` parameter, which\n  scales the output in the same way as the new ``amplitude`` parameter in\n  ``LIF``/``LIFRate`` (see `Nengo PR #1325\n  <https://github.com/nengo/nengo/pull/1325>`_).\n- Added ``progress_bar=False`` option to ``sim.run``, which will disable the\n  information about the simulation status printed to standard output (`#17\n  <https://github.com/nengo/nengo-dl/issues/17>`_).\n- Added progress bars for the build/simulation process.\n- Added truncated backpropagation option to ``sim.train`` (useful for reducing\n  memory usage during training).  See `the documentation for details\n  <https://www.nengo.ai/nengo-dl/v0.6.0/training.html#truncation>`__.\n\n**Changed**\n\n- Changed the default ``tensorboard`` argument in ``Simulator`` from ``False``\n  to ``None``\n- Use the new `tf.profiler\n  <https://github.com/tensorflow/docs/blob/r1.14/site/en/api_docs/python/tf/profiler/profile.md>`_\n  tool to collect profiling data in ``sim.run_steps`` and ``sim.train`` when\n  ``profile=True``.\n- Minor improvements to efficiency of build process.\n- Minor improvements to simulation efficiency targeting small ops\n  (``tf.reshape/identity/constant``).\n- Process inputs are now reseeded for each input when batch processing (if seed\n  is not manually set).\n- Users can pass a dict of config options for the ``profile`` argument in\n  ``run_steps``/``train``, which will be passed on to the TensorFlow\n  profiler; see the ``tf.profiler`` documentation for the `available options\n  <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/options.md>`_.\n\n**Removed**\n\n- Removed ``backports.print_function`` dependency\n\n**Fixed**\n\n- Fixed a bug where input nodes that were only read as a view were not\n  feedable\n- Updated ``tensorflow-gpu`` installation check\n- Improved numerical stability of ``LIFRate`` gradients  (`#26\n  <https://github.com/nengo/nengo-dl/issues/26>`_)\n- Added more informative error message when data is provided with fewer items\n  than ``sim.minibatch_size`` (`#30 <https://github.com/nengo/nengo-dl/issues/30>`_)\n\n0.5.2 (October 11, 2017)\n------------------------\n\n**Added**\n\n- TensorNode outputs can now define a ``post_build`` function that will be\n  executed after the simulation is initialized (see the `TensorNode\n  documentation for details\n  <https://www.nengo.ai/nengo-dl/tensor_node.html>`_).\n- Added functionality for outputting summary data during the training process\n  that can be viewed in TensorBoard (see the `sim.train documentation\n  <https://www.nengo.ai/nengo-dl/v0.5.2/training.html#summaries>`__).\n- Added some examples demonstrating how to use Nengo DL in a more complicated\n  task using semantic pointers to encode/retrieve information\n- Added ``sim.training_step`` variable which will track the current training\n  iteration (can be used, e.g., for TensorFlow's variable learning rate\n  operations).\n- Users can manually create ``tf.summary`` ops and pass them to ``sim.train``\n  summaries\n- The Simulator context will now also set the default TensorFlow graph to the\n  one associated with the Simulator (so any TensorFlow ops created within the\n  Simulator context will automatically be added to the correct graph)\n- Users can now specify a different objective for each output probe during\n  training/loss calculation (see the `sim.train documentation\n  <https://www.nengo.ai/nengo-dl/v0.5.2/training.html#objective>`__).\n\n**Changed**\n\n- Resetting the simulator now only rebuilds the necessary components in the\n  graph (as opposed to rebuilding the whole graph)\n- The default ``\"mse\"`` loss implementation will now automatically convert\n  ``np.nan`` values in the target to zero error\n- If there are multiple target probes given to ``sim.train``/``sim.loss`` the\n  total error will now be summed across probes (instead of averaged)\n\n**Fixed**\n\n- ``sim.data`` now implements the full ``collections.Mapping`` interface\n- Fixed bug where signal order was non-deterministic for Networks containing\n  objects with duplicate names\n  (`#9 <https://github.com/nengo/nengo-dl/issues/9>`_)\n- Fixed bug where non-slot optimizer variables were not initialized\n  (`#11 <https://github.com/nengo/nengo-dl/issues/11>`_)\n- Implemented a modified PES builder in order to avoid slicing encoders on\n  non-decoded PES connections\n- TensorBoard output directory will be automatically created if it doesn't\n  exist\n\n0.5.1 (August 28, 2017)\n-----------------------\n\n**Changed**\n\n- ``sim.data[obj]`` will now return live parameter values from the simulation,\n  rather than initial values from the build process.  That means that it can\n  be used to get the values of object parameters after training, e.g.\n  ``sim.data[my_conn].weights``.\n- Increased minimum Nengo version to 2.5.0.\n- Increased minimum TensorFlow version to 1.3.0.\n\n0.5.0 (July 11, 2017)\n---------------------\n\n**Added**\n\n- Added ``nengo_dl.tensor_layer`` to help with the construction of\n  layer-style TensorNodes (see the `TensorNode documentation\n  <https://www.nengo.ai/nengo-dl/tensor_node.html>`_)\n- Added an example demonstrating `how to train a neural network\n  that can run in spiking neurons\n  <https://www.nengo.ai/nengo-dl/examples/spiking_mnist.html>`_\n- Added some distributions for weight initialization to ``nengo_dl.dists``\n- Added ``sim.train(..., profile=True)`` option to collect profiling\n  information during training\n- Added new methods to simplify the Nengo operation graph, resulting in faster\n  simulation/training speed\n- The default graph planner can now be modified by setting the ``planner``\n  attribute on the top-level Network config\n- Added TensorFlow implementation for general linear synapses\n- Added ``backports.tempfile`` and ``backports.print_function`` requirement for\n  Python 2.7 systems\n\n**Changed**\n\n- Increased minimum TensorFlow version to 1.2.0\n- Improved error checking for input/target data\n- Improved efficiency of stateful gradient operations, resulting in faster\n  training speed\n- The functionality for ``nengo_dl.configure_trainable`` has been subsumed into\n  the more general ``nengo_dl.configure_settings(trainable=x)``.  This has\n  resulted in some small changes to how trainability is controlled within\n  subnetworks; see the `updated documentation\n  <https://www.nengo.ai/nengo-dl/simulator.html#choosing-which-elements-to-optimize>`_\n  for details.\n- Calling ``Simulator.train``/``Simulator.loss`` no longer resets the internal\n  state of the simulation (so they can be safely intermixed with calls to\n  ``Simulator.run``)\n\n**Deprecated**\n\n- The old ``step_blocks``/``unroll_simulation`` syntax has been fully\n  deprecated, and will result in errors if used\n\n**Fixed**\n\n- Fixed bug related to changing the output of a Node after the model is\n  constructed (`#4 <https://github.com/nengo/nengo-dl/issues/4>`_)\n- Order of variable creation is now deterministic (helps make saving/loading\n  parameters more reliable)\n- Configuring whether or not a model element is trainable does not affect\n  whether or not that element is minibatched\n- Correctly reuse variables created inside a TensorNode when\n  ``unroll_simulation`` > 1\n- Correctly handle probes that aren't connected to any ops\n- Swapped ``fan_in``/``fan_out`` in ``dists.VarianceScaling`` to align with\n  the standard definitions\n- Temporary patch to fix memory leak in TensorFlow (see\n  `#11273 <https://github.com/tensorflow/tensorflow/issues/11273>`_)\n- Fixed bug related to nodes that had matching output functions but different\n  size_out\n- Fixed bug related to probes that do not contain any data yet\n\n0.4.0 (June 8, 2017)\n--------------------\n\n**Added**\n\n- Added ability to manually specify which parts of a model are trainable\n  (see the `sim.train documentation\n  <https://www.nengo.ai/nengo-dl/v0.4.0/training.html>`_)\n- Added some code examples (see the ``docs/examples`` directory, or the\n  `pre-built examples in the documentation\n  <https://www.nengo.ai/nengo-dl/examples.html>`_)\n- Added the SoftLIFRate neuron type for training LIF networks (based on\n  `this paper <https://arxiv.org/abs/1510.08829>`_)\n\n**Changed**\n\n- Updated TensorFuncParam to new Nengo Param syntax\n- The interface for Simulator ``step_blocks``/``unroll_simulation`` has been\n  changed.  Now ``unroll_simulation`` takes an integer as argument which is\n  equivalent to the old ``step_blocks`` value, and ``unroll_simulation=1`` is\n  equivalent to the old ``unroll_simulation=False``.  For example,\n  ``Simulator(..., unroll_simulation=True, step_blocks=10)`` is now equivalent\n  to ``Simulator(..., unroll_simulation=10)``.\n- Simulator.train/Simulator.loss no longer require ``step_blocks`` (or the new\n  ``unroll_simulation``) to be specified; the number of steps to train across\n  will now be inferred from the input data.\n\n\n0.3.1 (May 12, 2017)\n--------------------\n\n**Added**\n\n- Added more documentation on Simulator arguments\n\n**Changed**\n\n- Improved efficiency of tree_planner, made it the new default planner\n\n**Fixed**\n\n- Correctly handle input feeds when n_steps > step_blocks\n- Detect cycles in transitive planner\n- Fix bug in uneven step_blocks rounding\n- Fix bug in Simulator.print_params\n- Fix bug related to merging of learning rule with different dimensionality\n- Use tf.Session instead of tf.InteractiveSession, to avoid strange side\n  effects if the simulator isn't closed properly\n\n\n0.3.0 (April 25, 2017)\n----------------------\n\n**Added**\n\n- Use logger for debug/builder output\n- Implemented TensorFlow gradients for sparse Variable update Ops, to allow\n  models with those elements to be trained\n- Added tutorial/examples on using ``Simulator.train``\n- Added support for training models when ``unroll_simulation=False``\n- Compatibility changes for Nengo 2.4.0\n- Added a new graph planner algorithm, which can improve simulation speed at\n  the cost of build time\n\n**Changed**\n\n- Significant improvements to simulation speed\n\n  - Use sparse Variable updates for signals.scatter/gather\n  - Improved graph optimizer memory organization\n  - Implemented sparse matrix multiplication op, to allow more aggressive\n    merging of DotInc operators\n\n- Significant improvements to build speed\n\n  - Added early termination to graph optimization\n  - Algorithmic improvements to graph optimization functions\n\n- Reorganized documentation to more clearly direct new users to relevant\n  material\n\n**Fixed**\n\n- Fix bug where passing a built model to the Simulator more than once would\n  result in an error\n- Cache result of calls to ``tensor_graph.build_loss/build_optimizer``, so that\n  we don't unnecessarily create duplicate elements in the graph on repeated\n  calls\n- Fix support for Variables on GPU when ``unroll_simulation=False``\n- SimPyFunc operators will always be assigned to CPU, even when\n  ``device=\"/gpu:0\"``, since there is no GPU kernel\n- Fix bug where ``Simulator.loss`` was not being computed correctly for\n  models with internal state\n- Data/targets passed to ``Simulator.train`` will be truncated if not evenly\n  divisible by the specified minibatch size\n- Fixed bug where in some cases Nodes with side effects would not be run if\n  their output was not used in the simulation\n- Fixed bug where strided reads that cover a full array would be interpreted as\n  non-strided reads of the full array\n\n\n0.2.0 (March 13, 2017)\n----------------------\n\nInitial release of TensorFlow-based NengoDL\n\n\n0.1.0 (June 12, 2016)\n---------------------\n\nInitial release of Lasagne-based NengoDL", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://www.nengo.ai/nengo-dl", "keywords": "", "license": "Free for non-commercial use", "maintainer": "", "maintainer_email": "", "name": "nengo-dl", "package_url": "https://pypi.org/project/nengo-dl/", "platform": "", "project_url": "https://pypi.org/project/nengo-dl/", "project_urls": {"Homepage": "https://www.nengo.ai/nengo-dl"}, "release_url": "https://pypi.org/project/nengo-dl/3.2.0/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Deep learning integration for Nengo", "version": "3.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.org/project/nengo-dl\" rel=\"nofollow\"><img alt=\"Latest PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2a32d6af32d384c9fb30240dbb6c66b9c97092c8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6e656e676f2d646c2e737667\"></a>\n<a href=\"https://travis-ci.org/nengo/nengo-dl\" rel=\"nofollow\"><img alt=\"Travis-CI build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3bfd6d0b7fa2099e1f817b4ec417598c3b9be719/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f6e656e676f2f6e656e676f2d646c2f6d61737465722e737667\"></a>\n<a href=\"https://ci.appveyor.com/project/nengo/nengo-dl\" rel=\"nofollow\"><img alt=\"AppVeyor build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/256b2ae618b6b80aced1d21a3dc2f017eb3357e5/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6e656e676f2f6e656e676f2d646c3f6272616e63683d6d6173746572267376673d74727565\"></a>\n<a href=\"https://codecov.io/gh/nengo/nengo-dl\" rel=\"nofollow\"><img alt=\"Test coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4a91dbe87cb3a4c5f39234b7069ea99e6c3ea9fa/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f6e656e676f2f6e656e676f2d646c2f6d61737465722e737667\"></a>\n<div>\n<div><br></div>\n</div>\n<a href=\"https://www.nengo.ai/nengo-dl\" rel=\"nofollow\"><img alt=\"NengoDL\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f57db6f0ec86546605ed7f588234e6e3b8272351/68747470733a2f2f7777772e6e656e676f2e61692f64657369676e2f5f696d616765732f6e656e676f2d646c2d66756c6c2d6c696768742e737667\" width=\"400px\"></a>\n<div id=\"deep-learning-integration-for-nengo\">\n<h2>Deep learning integration for Nengo</h2>\n<p>NengoDL is a simulator for <a href=\"https://www.nengo.ai/nengo/\" rel=\"nofollow\">Nengo</a> models.\nThat means it takes a Nengo network as input, and allows the user to simulate\nthat network using some underlying computational framework (in this case,\n<a href=\"https://www.tensorflow.org/\" rel=\"nofollow\">TensorFlow</a>).</p>\n<p>In practice, what that means is that the code for constructing a Nengo model\nis exactly the same as it would be for the standard Nengo simulator.  All that\nchanges is that we use a different Simulator class to execute the\nmodel.</p>\n<p>For example:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">nengo</span>\n<span class=\"kn\">import</span> <span class=\"nn\">nengo_dl</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n\n<span class=\"k\">with</span> <span class=\"n\">nengo</span><span class=\"o\">.</span><span class=\"n\">Network</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">net</span><span class=\"p\">:</span>\n    <span class=\"n\">inp</span> <span class=\"o\">=</span> <span class=\"n\">nengo</span><span class=\"o\">.</span><span class=\"n\">Node</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sin</span><span class=\"p\">)</span>\n    <span class=\"n\">ens</span> <span class=\"o\">=</span> <span class=\"n\">nengo</span><span class=\"o\">.</span><span class=\"n\">Ensemble</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">neuron_type</span><span class=\"o\">=</span><span class=\"n\">nengo</span><span class=\"o\">.</span><span class=\"n\">LIF</span><span class=\"p\">())</span>\n    <span class=\"n\">nengo</span><span class=\"o\">.</span><span class=\"n\">Connection</span><span class=\"p\">(</span><span class=\"n\">inp</span><span class=\"p\">,</span> <span class=\"n\">ens</span><span class=\"p\">,</span> <span class=\"n\">synapse</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n    <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">nengo</span><span class=\"o\">.</span><span class=\"n\">Probe</span><span class=\"p\">(</span><span class=\"n\">ens</span><span class=\"p\">)</span>\n\n<span class=\"k\">with</span> <span class=\"n\">nengo_dl</span><span class=\"o\">.</span><span class=\"n\">Simulator</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">sim</span><span class=\"p\">:</span> <span class=\"c1\"># this is the only line that changes</span>\n    <span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">])</span>\n</pre>\n<p>However, NengoDL is not simply a duplicate of the Nengo simulator.  It also\nadds a number of unique features, such as:</p>\n<ul>\n<li>optimizing the parameters of a model through deep learning\ntraining methods (using the Keras API)</li>\n<li>faster simulation speed, on both CPU and GPU</li>\n<li>automatic conversion from Keras models to Nengo networks</li>\n<li>inserting  TensorFlow code (individual functions or whole\nnetwork architectures) directly into a Nengo model</li>\n</ul>\n<p><strong>Documentation</strong></p>\n<p>Check out the <a href=\"https://www.nengo.ai/nengo-dl/\" rel=\"nofollow\">documentation</a> for</p>\n<ul>\n<li><a href=\"https://www.nengo.ai/nengo-dl/installation.html\" rel=\"nofollow\">Installation instructions</a></li>\n<li><a href=\"https://www.nengo.ai/nengo-dl/user-guide.html\" rel=\"nofollow\">Details on the unique features of NengoDL</a></li>\n<li><a href=\"https://www.nengo.ai/nengo-dl/examples/from-tensorflow.html\" rel=\"nofollow\">Tutorial for new users with a TensorFlow background</a></li>\n<li><a href=\"https://www.nengo.ai/nengo-dl/examples/from-nengo.html\" rel=\"nofollow\">Tutorial for new users with a Nengo background</a></li>\n<li><a href=\"https://www.nengo.ai/nengo-dl/examples.html\" rel=\"nofollow\">More in-depth examples</a></li>\n<li><a href=\"https://www.nengo.ai/nengo-dl/reference.html\" rel=\"nofollow\">API reference</a></li>\n</ul>\n<div id=\"release-history\">\n<h3>Release history</h3>\n<div id=\"april-2-2020\">\n<h4>3.2.0 (April 2, 2020)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added <tt>nengo_dl.LeakyReLU</tt> and <tt>nengo_dl.SpikingLeakyReLU</tt> neuron models.\n(<a href=\"https://github.com/nengo/nengo-dl/pull/126\" rel=\"nofollow\">#126</a>)</li>\n<li>Added support for leaky ReLU Keras layers to <tt>nengo_dl.Converter</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/126\" rel=\"nofollow\">#126</a>)</li>\n<li>Added a new <tt>remove_reset_incs</tt> graph simplification step. (<a href=\"https://github.com/nengo/nengo-dl/pull/129\" rel=\"nofollow\">#129</a>)</li>\n<li>Added support for UpSampling layers to <tt>nengo_dl.Converter</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/130\" rel=\"nofollow\">#130</a>)</li>\n<li>Added tolerance parameters to <tt>nengo_dl.Converter.verify</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/130\" rel=\"nofollow\">#130</a>)</li>\n<li>Added <tt>scale_firing_rates</tt> option to <tt>nengo_dl.Converter</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/134\" rel=\"nofollow\">#134</a>)</li>\n<li>Added <tt>Converter.layers</tt> attribute which will map Keras layers/tensors to\nthe converted Nengo objects, to make it easier to access converted components.\n(<a href=\"https://github.com/nengo/nengo-dl/pull/134\" rel=\"nofollow\">#134</a>)</li>\n<li>Compatible with TensorFlow 2.2.0. (<a href=\"https://github.com/nengo/nengo-dl/pull/140\" rel=\"nofollow\">#140</a>)</li>\n<li>Added a new <tt>synapse</tt> argument to the Converter, which can be used to automatically\nadd synaptic filters on the output of neural layers during the conversion process.\n(<a href=\"https://github.com/nengo/nengo-dl/pull/141\" rel=\"nofollow\">#141</a>)</li>\n<li>Added a <a href=\"https://www.nengo.ai/nengo-dl/examples/keras-to-snn.html\" rel=\"nofollow\">new example</a>\ndemonstrating how to use the NengoDL Converter to convert a Keras model to a spiking\nNengo network. (<a href=\"https://github.com/nengo/nengo-dl/pull/141\" rel=\"nofollow\">#141</a>)</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Re-enabled the <tt>remove_constant_copies</tt> graph simplification by default. (<a href=\"https://github.com/nengo/nengo-dl/pull/129\" rel=\"nofollow\">#129</a>)</li>\n<li>Reduced the amount of state that needs to be stored in the simulation. (<a href=\"https://github.com/nengo/nengo-dl/pull/129\" rel=\"nofollow\">#129</a>)</li>\n<li>Added more information to the error message when loading saved parameters that\ndon\u2019t match the current model. (<a href=\"https://github.com/nengo/nengo-dl/pull/129\" rel=\"nofollow\">#129</a>)</li>\n<li>More efficient implementation of convolutional biases in the Converter. (<a href=\"https://github.com/nengo/nengo-dl/pull/130\" rel=\"nofollow\">#130</a>)</li>\n<li>Saved simulator state will no longer be included in <tt>Simulator.keras_model.weights</tt>.\nThis means that <tt>Simulator.keras_model.save/load_weights</tt> will not include the\nsaved simulator state, making it easier to reuse weights between models (as long as\nthe models have the same weights, they do not need to have the same state variables).\n<tt><span class=\"pre\">Simulator.save/load_params(...,</span> include_state=True)</tt> can be used to explicitly\nsave the simulator state, if desired. (<a href=\"https://github.com/nengo/nengo-dl/pull/140\" rel=\"nofollow\">#140</a>)</li>\n<li>Model parameters (e.g., connection weights) that are not trainable (because they\u2019ve\nbeen marked non-trainable by user or targeted by an online learning rule) will now\nbe treated separately from simulator state. For example,\n<tt><span class=\"pre\">Simulator.save_params(...,</span> include_state=False)</tt> will still include those\nparameters, and the results of any online learning will persist between calls even\nwith <tt>stateful=False</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/140\" rel=\"nofollow\">#140</a>)</li>\n<li>Added <tt>include_probes</tt>, <tt>include_trainable</tt>, and <tt>include_processes</tt> arguments\nto <tt>Simulator.reset</tt> to provide more fine-grained control over Simulator\nresetting. This replicates the previous functionality in <tt>Simulator.soft_reset</tt>.\n(<a href=\"https://github.com/nengo/nengo-dl/pull/139\" rel=\"nofollow\">#139</a>)</li>\n<li>More informative error messages when accessing invalid Simulator functionality after\nthe Simulator has been closed. (<a href=\"https://github.com/nengo/nengo-dl/pull/139\" rel=\"nofollow\">#139</a>)</li>\n<li>A warning is now raised when the number of input data items passed to the simulator\ndoes not match the number of input nodes, to help avoid unintentionally passing\ndata to the wrong input node. This warning can be avoided by passing data for\nall nodes, or using the dictionary input style if you want to only pass data for\na specific node. (<a href=\"https://github.com/nengo/nengo-dl/pull/139\" rel=\"nofollow\">#139</a>)</li>\n<li>Dictionaries returned by <tt>sim.predict/evaluate</tt> will now be ordered. (<a href=\"https://github.com/nengo/nengo-dl/pull/141\" rel=\"nofollow\">#141</a>)</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed bug in error message when passing data with batch size less than Simulator\nminibatch size. (<a href=\"https://github.com/nengo/nengo-dl/pull/139\" rel=\"nofollow\">#139</a>)</li>\n<li>More informative error message when <tt>validation_split</tt> does not result in batch\nsizes evenly divisible by minibatch size. (<a href=\"https://github.com/nengo/nengo-dl/pull/139\" rel=\"nofollow\">#139</a>)</li>\n<li>Added <tt><span class=\"pre\">tensorflow-cpu</span></tt> distributions to installation checks (so Nengo DL will\nnot attempt to reinstall TensorFlow if <tt><span class=\"pre\">tensorflow-cpu</span></tt> is already installed).\n(<a href=\"https://github.com/nengo/nengo-dl/pull/142\" rel=\"nofollow\">#142</a>)</li>\n<li>Fixed bug when applying the Converter to Keras models that re-use intermediate\nlayers as output layers. (<a href=\"https://github.com/nengo/nengo-dl/pull/137\" rel=\"nofollow\">#137</a>)</li>\n<li>Fixed bug in conversion of Keras Dense layers with non-native activation functions.\n(<a href=\"https://github.com/nengo/nengo-dl/pull/144\" rel=\"nofollow\">#144</a>)</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li>Renamed <tt>Simulator.save/load_params</tt> <tt>include_non_trainable</tt> parameter to\n<tt>include_state</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/140\" rel=\"nofollow\">#140</a>)</li>\n<li><tt>Simulator.soft_reset</tt> has been deprecated. Use\n<tt>Simulator.reset(include_probes=False, include_trainable=False,\ninclude_processes=False)</tt> instead. (<a href=\"https://github.com/nengo/nengo-dl/pull/139\" rel=\"nofollow\">#139</a>)</li>\n</ul>\n</div>\n<div id=\"march-4-2020\">\n<h4>3.1.0 (March 4, 2020)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added <tt>inference_only=True</tt> option to the Converter, which will allow some\nLayers/parameters that cannot be fully converted to native Nengo objects to be\nconverted in a way that only matches the inference behaviour of the source Keras model\n(not the training behaviour). (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Improved build time of networks containing lots of <tt>TensorNodes</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Improved memory usage of build process. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Saved simulation state may now be placed on GPU (this should improve the speed of\nstate updates, but may slightly increase GPU memory usage). (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Changed Converter <tt>freeze_batchnorm=True</tt> option to <tt>inference_only=True</tt>\n(effect of the parameter is the same on BatchNormalization layers, but also has\nbroader effects). (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>The precision of the Nengo core build process will now be set based on the\n<tt><span class=\"pre\">nengo_dl.configure_settings(dtype=...)</span></tt> config option. Note that this will\noverride the default precision set in <tt>nengo.rc</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Minimum Numpy version is now 1.16.0 (required by TensorFlow). (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Added support for the new <tt>transform=None</tt> default in Nengo connections\n(see <a href=\"https://github.com/nengo/nengo/pull/1591\" rel=\"nofollow\">Nengo#1591</a>). Note that this may change the number of trainable\nparameters in a network as the scalar default <tt>transform=1</tt> weights on\nnon-Ensemble connections will no longer be present. (<a href=\"https://github.com/nengo/nengo-dl/pull/128\" rel=\"nofollow\">#128</a>)</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Provide a more informative error message if Layer <tt>shape_in</tt>/<tt>shape_out</tt> contains\nundefined (<tt>None</tt>) elements. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Fixed bug in <tt>Converter</tt> when source model contains duplicate nodes. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Fixed bug in <tt>Converter</tt> for <tt>Concatenate</tt> layers with <tt>axis != 1</tt>. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Fixed bug in <tt>Converter</tt> for models containing passthrough <tt>Input</tt> layers inside\nsubmodels. (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Keras Layers inside TensorNodes will be called with the <tt>training</tt> argument set\ncorrectly (previously it was always set to the default value). (<a href=\"https://github.com/nengo/nengo-dl/pull/119\" rel=\"nofollow\">#119</a>)</li>\n<li>Fixed compatibility with <tt>progressbar2</tt> version 3.50.0. (<a href=\"https://github.com/nengo/nengo-dl/pull/136\" rel=\"nofollow\">#136</a>)</li>\n</ul>\n</div>\n<div id=\"december-17-2019\">\n<h4>3.0.0 (December 17, 2019)</h4>\n<p>There are a lot of <strong>breaking changes</strong> in NengoDL 3.0. See the <a href=\"https://www.nengo.ai/nengo-dl/migration-guide.html#nengodl-2-to-3\" rel=\"nofollow\">migration guide</a> for all the\ndetails.</p>\n<p><strong>Added</strong></p>\n<ul>\n<li>Keras <tt>Layer</tt> classes can now be used with <tt>nengo_dl.Layer/tensor_layer</tt>.</li>\n<li><tt>TensorGraph</tt> can now be used as a Keras <tt>Layer</tt>.</li>\n<li>Added <tt>Simulator.predict/evaluate/fit</tt> functions, which\nimplement the Keras\n<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model\" rel=\"nofollow\">Model API</a>.</li>\n<li>Added a warning that changing the TensorFlow seed (e.g. on <tt>Simulator.reset</tt>) will\nnot affect any existing TensorFlow operations (this was always true in TensorFlow,\nthe warning is just to help avoid confusion).</li>\n<li>Added <tt>TensorGraph.build_inputs</tt>, which will return a set of Keras <tt>Input</tt> layers\nthat can be used as input to the TensorGraph layer itself.</li>\n<li>Added <tt>nengo_dl.callbacks.TensorBoard</tt>. This is identical to\n<tt>tf.keras.callbacks.TensorBoard</tt>, except it will also perform profiling during\ninference (rather than only during training).</li>\n<li>Added <tt>stateful</tt> option to <tt>Simulator.run</tt> which can be set to False to avoid\nupdating the saved simulation state at the end of a run.</li>\n<li>Added <tt>nengo_dl.configure_settings(stateful=False)</tt> option to avoid building the\nparts of the model responsible for preserving state between executions (this will\noverride any <tt>stateful=True</tt> arguments in individual functions).</li>\n<li>Added <tt>nengo_dl.configure_settings(use_loop=False)</tt> option to avoid building the\nsimulation inside a symbolic TensorFlow loop. This may improve simulation speed,\nbut the simulation can only run for exactly <tt>unroll_simulation</tt> timesteps.</li>\n<li>NengoDL now requires <tt>jinja2</tt> (used to template some of the docstrings).</li>\n<li>Added an <tt>inputs</tt> argument to <tt>Simulator.check_gradients</tt>, which can be used to\ncontrol the initial value of input Nodes during the gradient calculations.</li>\n<li>Added <tt>nengo_dl.Converter</tt> for automatically converting Keras models to native\nNengo networks.  See <a href=\"https://www.nengo.ai/nengo-dl/converter.html\" rel=\"nofollow\">the documentation</a> for more details.</li>\n<li>Added <a href=\"https://www.nengo.ai/nengo-dl/examples/lmu.html\" rel=\"nofollow\">Legendre Memory Unit RNN example</a>.</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Minimum TensorFlow version is now 2.0.0.</li>\n<li><tt>Simulator.save/load_params</tt> now uses a single\n<tt>include_non_trainable=True/False</tt> (equivalent to the previous\n<tt>include_local</tt>). Trainable parameters will always be saved, so the\n<tt>include_global</tt> argument is removed.</li>\n<li>Standardized all signals/operations in a simulation to be batch-first.</li>\n<li>The <a href=\"https://www.nengo.ai/nengo-dl/config.html#dtype\" rel=\"nofollow\">dtype option</a> is now specified\nas a string (e.g. <tt>\"float32\"</tt> rather than <tt>tf.float32</tt>).</li>\n<li>If the requested number of simulation steps is not evenly divisible by\n<tt>Simulator.unroll_simulation</tt> then probe values and <tt>sim.time/n_steps</tt> will be\nupdated based on the number of steps actually run (rather than the requested\nnumber of steps).  Note that these extra steps were also run previously, but their\nresults were hidden from the user.</li>\n<li>Renamed <tt>TensorGraph.input_ph</tt> to <tt>TensorGraph.node_inputs</tt>.</li>\n<li><tt>Simulator.time/n_steps</tt> are now read-only.</li>\n<li><tt>Simulator.n_steps/time</tt> are now managed as part of the op graph, rather than\nmanually in the Simulator.</li>\n<li>Renamed <tt>nengo_dl.objectives</tt> to <tt>nengo_dl.losses</tt> (to align with <tt>tf.losses</tt>).</li>\n<li><tt>nengo_dl.objectives.Regularize</tt> now takes two arguments (<tt>y_true</tt> and <tt>y_pred</tt>)\nin order to be compatible with the <tt>tf.losses.Loss</tt> API (<tt>y_true</tt> is ignored).</li>\n<li>The <a href=\"https://www.nengo.ai/nengo-dl/reference.html#nengo_dl.graph_optimizer.remove_constant_copies\" rel=\"nofollow\">remove_constant_copies</a>\nsimplification step is now disabled by default.\nIn certain situations this could be an unsafe manipulation (specifically,\nwhen using <tt>Simulator.save/load_params</tt> it could change which parameters are saved).\nIt can be manually re-enabled through the\n<a href=\"https://www.nengo.ai/nengo-dl/config.html#simplifications\" rel=\"nofollow\">simplifications</a>\nconfiguration option.</li>\n<li><tt>Simulator.check_gradients</tt> now only accepts an optional list of Probes (no longer\naccepts arbitrary Tensors).</li>\n<li>Eager execution is no longer disabled on import (it is still disabled within the\nSimulator context, for performance reasons; see\n<a href=\"https://github.com/tensorflow/tensorflow/issues/33052\" rel=\"nofollow\">https://github.com/tensorflow/tensorflow/issues/33052</a>).</li>\n<li><tt>nengo_dl.tensor_layer(x, func, <span class=\"pre\">...)</span></tt> now passes any extra kwargs to the\n<tt>nengo_dl.TensorNode</tt> constructor (rather than to <tt>func</tt>). If you need to pass\ninformation to <tt>func</tt> consider using partial functions (e.g.\n<tt>tensor_layer(functools.partial(x, func, arg=5), <span class=\"pre\">...)</span></tt> or a callable class\n(e.g., <tt>tensor_layer(x, MyFunc(arg=5), <span class=\"pre\">...))</span></tt>. When using Keras Layers with\n<tt>nengo_dl.tensor_layer</tt>, a fully instantiated Layer\nobject should be passed rather than a Layer class (e.g., use\n<tt>tensor_layer(x, tf.keras.layers.Dense(units=10), <span class=\"pre\">...)</span></tt> instead of\n<tt>tensor_layer(x, tf.keras.layers.Dense, units=10)</tt>).</li>\n<li><tt>benchmarks.run_profile</tt> now uses the TensorBoard format when profiling,\nsee <a href=\"https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras\" rel=\"nofollow\">the documentation</a> for\ninstructions on how to view this information (the information is the same, it is\njust accessed through TensorBoard rather than requiring that it be loaded directly\nin a Chrome browser).</li>\n<li><tt>nengo_dl.TensorNode</tt> now takes <tt>shape_in</tt> and <tt>shape_out</tt> arguments (which\nspecify a possibly multidimensional shape), rather\nthan the scalar <tt>size_in</tt> and <tt>size_out</tt>.</li>\n<li><tt>TensorNode</tt> functions no longer use the <tt>pre_build</tt>/<tt>post_build</tt> functionality.\nIf you need to implement more complex behaviour in a TensorNode, use a\ncustom Keras Layer subclass instead.  For example, TensorNodes Layers can create new\nparameter Variables inside the Layer <tt>build</tt> method.</li>\n<li><tt>TensorNode</tt> now has an optional <tt>pass_time</tt> parameter which can be set to\n<tt>False</tt> to disable passing the current simulation time to the TensorNode function.</li>\n<li>Added <tt>nengo_dl.Layer</tt>. Similar to the old <tt>nengo_dl.tensor_layer</tt>, this is a\nwrapper for constructing TensorNodes, but it mimics the new <tt>tf.keras.layers.Layer</tt>\nAPI rather than the old <tt>tf.layers</tt>.</li>\n<li>TensorFlow\u2019s \u201ccontrol flow v2\u201d is disabled on import, for performance reasons; see\n<a href=\"https://github.com/tensorflow/tensorflow/issues/33052\" rel=\"nofollow\">https://github.com/tensorflow/tensorflow/issues/33052</a>.</li>\n<li>Renamed <tt>nengo_dl.objectives.mse</tt> to <tt>nengo_dl.losses.nan_mse</tt> (to emphasize\nthe special logic it provides for <tt>nan</tt> targets).</li>\n<li>Connections created by <tt>nengo_dl.Layer/tensor_layer</tt> will be marked as\nnon-trainable by default.</li>\n<li>Updated all documentation and examples for the new syntax (in particular, see the\nupdated <a href=\"https://www.nengo.ai/nengo-dl/examples/from-tensorflow.html#\" rel=\"nofollow\">Coming from TensorFlow</a> tutorial and\n<a href=\"https://www.nengo.ai/nengo-dl/examples/tensorflow-models.html\" rel=\"nofollow\">TensorFlow/Keras integration</a> example, and the\nnew <a href=\"https://www.nengo.ai/nengo-dl/tips.html\" rel=\"nofollow\">Tips and tricks</a> page).</li>\n<li>The training/inference build logic (e.g., swapping spiking neurons with rate\nimplementations) can be overridden by setting the global Keras learning phase\n(<tt>tf.keras.backend.set_learning_phase</tt>) before the Simulator is constructed.</li>\n<li>Increased minimum Nengo core version to 3.0.0.</li>\n<li>Reduced size of TensorFlow constants created by Reset ops.</li>\n<li>DotInc operators with different signal sizes will no longer be merged (these\nmerged operators had to use a less efficient sparse matrix multiplication, and in\ngeneral this cost outweighed the benefit of merging).</li>\n<li>Trainability can now be configured in the config of subnetworks. This replaces\nthe ability to mark Networks as (non)trainable. See the <a href=\"https://www.nengo.ai/nengo-dl/config.html#trainable\" rel=\"nofollow\">updated documentation</a> for details.</li>\n<li>Training/evaluation target data can now have a different number of timesteps than\ninput data (as long as it aligns with the number of timesteps expected by the\nloss function).</li>\n<li>Whether or not to display progress bars in <tt>Simulator.run</tt> and\n<tt>Simulator.run_steps</tt> now defaults to the value of\n<tt><span class=\"pre\">Simulator(...,</span> progress_bar=x)</tt>.</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed bug due to non-determinism of Process state ordering in Python 3.5.</li>\n<li>Nested Keras layers passed to TensorNode will be rebuilt correctly if necessary.</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li><tt>nengo_dl.tensor_layer</tt> has been deprecated. Use <tt>nengo_dl.Layer</tt> instead;\n<tt>tensor_layer(x, func, **kwargs)</tt> is equivalent to <tt><span class=\"pre\">Layer(func)(x,</span> **kwargs)</tt>.</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>Removed the <a href=\"https://www.nengo.ai/nengo-dl/v2.2.1/config.html#session-config\" rel=\"nofollow\">session_config</a> configuration\noption. Use the <a href=\"https://www.tensorflow.org/api_docs/python/tf/config\" rel=\"nofollow\">updated TensorFlow config system</a> instead.</li>\n<li>Removed the deprecated <tt><span class=\"pre\">nengo_dl.Simulator(...,</span> <span class=\"pre\">dtype=...)</span></tt> argument. Use\n<tt><span class=\"pre\">nengo_dl.configure_settings(dtype=...)</span></tt> instead.</li>\n<li>Removed the deprecated <tt><span class=\"pre\">Simulator.run(...,</span> <span class=\"pre\">input_feeds=...)</span></tt> argument. Use\n<tt><span class=\"pre\">Simulator.run(...,</span> <span class=\"pre\">data=...)</span></tt> instead.</li>\n<li>Removed the <tt>Simulator.sess</tt> attribute (Sessions are no longer used in\nTensorFlow 2.0).  The underlying Keras model (<tt>Simulator.keras_model</tt>) should be\nused as the entrypoint into the engine underlying a Simulator instead.</li>\n<li>Removed the <tt>Simulator.loss</tt> function (use <tt>Simulator.compile</tt> and\n<tt>Simulator.evaluate</tt> to compute loss values instead).</li>\n<li>Removed the <tt>Simulator.train</tt> function (use <tt>Simulator.compile</tt> and\n<tt>Simulator.fit</tt> to optimize a network instead).</li>\n<li>Removed the <tt>nengo_dl.objectives.Regularize(weight=x, <span class=\"pre\">...)</span></tt> argument. Use the\n<tt><span class=\"pre\">Simulator.compile(loss_weights=...)</span></tt> functionality instead.</li>\n<li>Removed the <tt><span class=\"pre\">Simulator.run(...,</span> <span class=\"pre\">extra_feeds=...)</span></tt> argument. TensorFlow 2.0 no longer\nuses the Session/feed execution model.</li>\n<li>Removed <tt>Simulator.run_batch</tt>. This functionality is now managed by the underlying\n<tt>Simulator.keras_model</tt>.</li>\n<li>Removed <tt>TensorGraph.training_step</tt>. The training step is now managed by Keras.</li>\n<li>Removed <tt>TensorGraph.build_outputs</tt> and <tt>TensorGraph.build_optimizer_func</tt>.\nBuilding loss functions/optimizers is now managed by Keras.</li>\n<li>Removed <tt>nengo_dl.utils.find_non_differentiable</tt> (this no longer works in TF2.0\u2019s\neager mode).</li>\n<li>Removed <tt><span class=\"pre\">Simulator(...,</span> <span class=\"pre\">tensorboard=...)</span></tt> argument. Use the Keras TensorBoard\ncallback approach for TensorBoard logging instead (see\n<tt>tf.keras.callbacks.TensorBoard</tt> or <tt>nengo_dl.callbacks.NengoSummaries</tt>).</li>\n<li>NengoDL will no longer monkeypatch fix the <tt>tf.dynamic_stitch</tt> gradients on import.\nThe gradients are still incorrect (see\n<a href=\"https://github.com/tensorflow/tensorflow/issues/7397\" rel=\"nofollow\">https://github.com/tensorflow/tensorflow/issues/7397</a>), but we no longer use this\noperation within NengoDL so we leave it up to the user to fix it in their own code\nif needed.</li>\n<li>Removed <tt>benchmarks.matmul_vs_reduce</tt>. We use matmul for everything now, so this\ncomparison is no longer necessary.</li>\n<li>Removed <tt>utils.minibatch_generator</tt> (training/inference loops are now managed\nby Keras).</li>\n</ul>\n</div>\n<div id=\"november-20-2019\">\n<h4>2.2.2 (November 20, 2019)</h4>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Compatibility with Nengo 3.0 release</li>\n</ul>\n</div>\n<div id=\"october-2-2019\">\n<h4>2.2.1 (October 2, 2019)</h4>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Update testing framework to use new nengo pytest ecosystem (<tt><span class=\"pre\">pytest-rng</span></tt>,\n<tt><span class=\"pre\">pytest-allclose</span></tt>, and <tt><span class=\"pre\">pytest-nengo</span></tt>)</li>\n<li>Disable TensorFlow 2.0 behaviour (e.g. control flow v2) by default.  This will be\nre-enabled when full TensorFlow 2.0 support is added.</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed <tt><span class=\"pre\">tensorflow-gpu</span></tt> installation check in pep517-style isolated build\nenvironments.</li>\n</ul>\n</div>\n<div id=\"july-24-2019\">\n<h4>2.2.0 (July 24, 2019)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added a\n<a href=\"https://www.nengo.ai/nengo-dl/examples/tensorflow-models\" rel=\"nofollow\">new example</a>\ndemonstrating how to integrate a Keras model with NengoDL (thanks to new\ncontributor <a href=\"https://github.com/NickleDave\" rel=\"nofollow\">@NickleDave</a>).</li>\n<li>Added support for TensorFlow 2.0 (pre-release).</li>\n<li>Added support for sparse transforms\n(see <a href=\"https://github.com/nengo/nengo/pull/1532\" rel=\"nofollow\">https://github.com/nengo/nengo/pull/1532</a>).</li>\n<li>Added support for stateful Processes\n(see <a href=\"https://github.com/nengo/nengo/pull/1387\" rel=\"nofollow\">https://github.com/nengo/nengo/pull/1387</a>).</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>The default session will now be set to the NengoDL session before calling\nTensorNodes\u2019 <tt>post_build</tt> function.</li>\n<li>Renamed the pytest <tt>unroll_simulation</tt> argument to <tt><span class=\"pre\">unroll-simulation</span></tt>.</li>\n<li>Switched to nengo-bones templating system for TravisCI config/scripts.</li>\n<li>NengoDL will disable eager execution on import (and will probably not\nwork properly if it is manually re-enabled).</li>\n<li>Increased minimum numpy version to 1.14.5 (required by TensorFlow 1.14).</li>\n<li>Minimum Nengo version is now 2.8.0.</li>\n<li>Update LinearFilter synapse implementation to match recent changes in\nNengo core (see <a href=\"https://github.com/nengo/nengo/pull/1535\" rel=\"nofollow\">https://github.com/nengo/nengo/pull/1535</a>).</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed TensorFlow seeding so that randomness can be reliably controlled by\nsetting the Simulator seed.</li>\n<li>Improved robustness of <tt><span class=\"pre\">tensorflow-gpu</span></tt> installation check (in particular,\nit will now correctly detect GPU dists installed through <tt>conda</tt>).</li>\n<li>Fixed inspection of <tt>TensorNode.tensor_func</tt> arguments for partial\nfunctions.</li>\n<li>Simulator seed will now be deterministic for a given top-level Network seed.</li>\n<li>Raise a more informative error if user attempts to pickle a Simulator\n(this is not possible to do with TensorFlow sessions; see\n<a href=\"https://www.nengo.ai/nengo-dl/simulator.html#saving-and-loading-parameters\" rel=\"nofollow\">the documentation</a>\nfor other methods of saving/loading a NengoDL model).</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>NengoDL no longer supports Python 3.4 (official support for 3.4 ended in\nMarch 2019).</li>\n</ul>\n</div>\n<div id=\"january-11-2019\">\n<h4>2.1.1 (January 11, 2019)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added <tt>nengo_dl.obj</tt> as a shortcut alias for <tt>nengo_dl.objectives</tt>.</li>\n<li>Added tutorial for <a href=\"https://www.nengo.ai/nengo-dl/examples/from-nengo.html\" rel=\"nofollow\">Nengo users coming to NengoDL</a></li>\n<li>Added tutorial for <a href=\"https://www.nengo.ai/nengo-dl/examples/from-tensorflow.html\" rel=\"nofollow\">TensorFlow users coming to NengoDL</a></li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Increased minimum <tt>progressbar2</tt> version to 3.39.0.</li>\n<li>We now only provide <tt>sdist</tt> releases, not <tt>bdist_wheel</tt>. Due to the way\nthe TensorFlow packages are organized, <tt>bdist_wheel</tt>  forces any existing\nTensorFlow installations (e.g. <tt><span class=\"pre\">tensorflow-gpu</span></tt> or <tt><span class=\"pre\">tf-nightly</span></tt>)\nto be overwritten by <tt>tensorflow</tt>, which we don\u2019t want to do.</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>Removed the <tt><span class=\"pre\">nef-init</span></tt> tutorial (replaced by the new <tt><span class=\"pre\">from-nengo</span></tt>\ntutorial).</li>\n</ul>\n</div>\n<div id=\"december-5-2018\">\n<h4>2.1.0 (December 5, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added a built-in objective to assist in applying regularization during\ntraining.</li>\n<li>Added <a href=\"https://www.nengo.ai/nengo-dl/config.html#keep-history\" rel=\"nofollow\">keep_history config option</a>, which can be set\nto <tt>False</tt> on Probes if only the data from the most recent simulation step\nis desired (as opposed to the default behaviour of keeping the data from\nall steps).</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Moved <tt>utils.mse</tt> to <tt>objectives.mse</tt>.</li>\n<li><tt>sim.loss</tt> will now apply <tt>nengo_dl.objectives.mse</tt> to all probes in\n<tt>data</tt> if no explicit <tt>objective</tt> is given (mirroring the default\nbehaviour in <tt>sim.train</tt>).</li>\n<li>The Spaun benchmark network will now be installed through pip rather than\nmanually cloning and importing the repo.</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed objective argument parsing if objective is a callable class or method.</li>\n<li>Fixed bug in <tt>sim.train</tt> 1-step synapse warning when explicitly specifying\n<tt>n_steps</tt> (rather than passing in <tt>data</tt>).</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li>Passing <tt>\"mse\"</tt> as the objective in <tt>sim.train</tt>/<tt>sim.loss</tt> is no longer\nsupported.  Use the function <tt>nengo_dl.objectives.mse</tt> instead.</li>\n</ul>\n</div>\n<div id=\"november-23-2018\">\n<h4>2.0.0 (November 23, 2018)</h4>\n<p><strong>Breaking API changes</strong></p>\n<ul>\n<li><p><tt>sim.train</tt> and <tt>sim.loss</tt> now accept a single <tt>data</tt> argument, which\ncombines the previous <tt>inputs</tt> and <tt>targets</tt> arguments. For example,</p>\n<pre><span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">({</span><span class=\"n\">my_node</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"n\">my_probe</span><span class=\"p\">:</span> <span class=\"n\">y</span><span class=\"p\">},</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<p>is now equivalent to</p>\n<pre><span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">({</span><span class=\"n\">my_node</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">my_probe</span><span class=\"p\">:</span> <span class=\"n\">y</span><span class=\"p\">},</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<p>The motivation for this change is that not all objective functions require\ntarget values. Switching to the more generic <tt>data</tt> argument simplifies\nthe API and makes it more flexible, allowing users to specify whatever\ntraining/loss data is actually required.</p>\n</li>\n<li><p>The <tt>objective</tt> argument in <tt>sim.train</tt>/<tt>sim.loss</tt> is now always\nspecified as a dictionary mapping probes to objective functions.  Note that\nthis was available but optional previously; it was also possible to pass\na single value for the objective function, which would be applied to all\nprobes in <tt>targets</tt>.  The latter is no longer supported.  For example,</p>\n<pre><span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"n\">objective</span><span class=\"o\">=</span><span class=\"s2\">\"mse\"</span><span class=\"p\">)</span>\n</pre>\n<p>must now be explicitly specified as</p>\n<pre><span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"n\">objective</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"n\">my_probe</span><span class=\"p\">:</span> <span class=\"s2\">\"mse\"</span><span class=\"p\">})</span>\n</pre>\n<p>The motivation for this change is that, especially with the other new\nfeatures introduced in the 2.0 update, there were a lot of different ways to\nspecify the <tt>objective</tt> argument.  This made it somewhat unclear how\nexactly this argument worked, and the automatic \u201cbroadcasting\u201d was also\nambiguous (e.g., should the single objective be applied to each probe\nindividually, or to all of them together?).  Making the argument explicit\nhelps clarify the mental model.</p>\n</li>\n</ul>\n<p><strong>Added</strong></p>\n<ul>\n<li>An integer number of steps can now be passed for the\n<tt>sim.loss</tt>/<tt>sim.train</tt> data argument, if no input/target data is\nrequired.</li>\n<li>The <tt>objective</tt> dict in <tt>sim.train</tt>/<tt>sim.loss</tt> can now contain\ntuples of probes as the keys, in which case the objective function will be\ncalled with a corresponding tuple of probe/target values as each argument.</li>\n<li>Added the <tt>sim.run_batch</tt> function.  This exposes all the functionality\nthat the <tt>sim.run</tt>/<tt>sim.train</tt>/<tt>sim.loss</tt> functions are based on,\nallowing advanced users full control over how to run a NengoDL simulation.</li>\n<li>Added option to disable progress bar in <tt>sim.train</tt> and <tt>sim.loss</tt>.</li>\n<li>Added <tt>training</tt> argument to <tt>sim.loss</tt> to control whether the loss\nis evaluated in training or inference mode.</li>\n<li>Added support for the new Nengo <tt>Transform</tt> API (see\n<a href=\"https://github.com/nengo/nengo/pull/1481\" rel=\"nofollow\">https://github.com/nengo/nengo/pull/1481</a>).</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Custom objective functions passed to <tt>sim.train</tt>/<tt>sim.loss</tt> can now\naccept a single argument (<tt>my_objective(outputs): ...</tt> instead of\n<tt>my_objective(outputs, targets): ...</tt>) if no target values are required.</li>\n<li><tt>utils.minibatch_generator</tt> now accepts a single <tt>data</tt> argument rather\nthan <tt>inputs</tt> and <tt>targets</tt> (see discussion in \u201cBreaking API changes\u201d).</li>\n<li><tt>sim.training_step</tt> is now the same as\n<tt>tf.train.get_or_create_global_step()</tt>.</li>\n<li>Switched documentation to new\n<a href=\"https://github.com/nengo/nengo-sphinx-theme\" rel=\"nofollow\">nengo-sphinx-theme</a>.</li>\n<li>Reorganized documentation into \u201cUser guide\u201d and \u201cAPI reference\u201d sections.</li>\n<li>Improve build speed of models with large constants\n(<a href=\"https://github.com/nengo/nengo-dl/pull/69\" rel=\"nofollow\">#69</a>)</li>\n<li>Moved op-specific merge logic into the <tt>OpBuilder</tt> classes.</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Ensure that training step is always updated before TensorBoard events are\nadded (previously it could update before or after depending on the platform).</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li>The <tt>sim.run</tt> <tt>input_feeds</tt> argument has been renamed to <tt>data</tt> (for\nconsistency with other simulator functions).</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>NengoDL no longer supports Python 2 (see <a href=\"https://python3statement.org/\" rel=\"nofollow\">https://python3statement.org/</a> for\nmore information)</li>\n</ul>\n</div>\n<div id=\"november-2-2018\">\n<h4>1.2.1 (November 2, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added a warning if users run one-timestep training with a network containing\nsynaptic filters.</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Test Simulator parameters are now controlled through pytest arguments,\nrather than environment variables.</li>\n<li>Disable INFO-level TensorFlow logging (from C side) on import.  Added a\nNengoDL log message indicating the device the simulation will run on, as\na more concise replacement.</li>\n<li>Boolean signals are now supported\n(<a href=\"https://github.com/nengo/nengo-dl/issues/61\" rel=\"nofollow\">#61</a>)</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Avoid backpropagating NaN gradients from spiking neurons.</li>\n<li>Fixed an error that was thrown when calling <tt>get_tensor</tt> on a <tt>Signal</tt>\nthat was first initialized inside the Simulation while loop\n(<a href=\"https://github.com/nengo/nengo-dl/issues/56\" rel=\"nofollow\">#56</a>)</li>\n<li>Allow TensorNodes to run in Nengo GUI.</li>\n<li>Avoid bug in TensorFlow 1.11.0 that prevents certain models from\nrunning (see <a href=\"https://github.com/tensorflow/tensorflow/issues/23383\" rel=\"nofollow\">https://github.com/tensorflow/tensorflow/issues/23383</a>). Note\nthat this doesn\u2019t prevent this from occurring in user models, as we cannot\ncontrol the model structure there. If your model hangs indefinitely when\nyou call <tt>sim.train</tt>, try downgrading to TensorFlow 1.10.0.</li>\n<li>Ensure that <tt>sim.training_step</tt> is always updated after the optimization\nstep (in certain race conditions it would sometimes update part-way through\nthe optimization step).</li>\n</ul>\n</div>\n<div id=\"september-5-2018\">\n<h4>1.2.0 (September 5, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>NengoDL will now automatically use a rate-based approximation to compute the\ngradient for spiking neuron types, if one is known (no more need to manually\nswap neuron types for training and inference).</li>\n<li>Added <tt>nengo_dl.configure_settings(inference_only=True)</tt> option, which will\nbuild the network in inference-only mode.  This will slightly improve the\ninference speed of the simulation, but the network will not be trainable.</li>\n<li>Added <tt>nengo_dl.configure_settings(lif_smoothing=x)</tt> option, which will\ncontrol how much smoothing is applied to the LIF function during gradient\ncalculations (if any).</li>\n<li>Added <a href=\"https://www.nengo.ai/nengo-dl/config.html\" rel=\"nofollow\">documentation</a> on the\nvarious NengoDL config options.</li>\n<li>Added better validation for TensorNode output when <tt>size_out != None</tt>\n(<a href=\"https://github.com/nengo/nengo-dl/issues/51\" rel=\"nofollow\">#51</a>)</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>More informative error message if the user tries to pass target values for\na probe that isn\u2019t used in the objective function.</li>\n<li>Switched to ADD_N gradient accumulation (from TREE); this will increase\nthe memory usage during training, but improve performance.</li>\n<li>Revert to <tt>Timeline</tt> profiling method. <tt>tf.profiler</tt> can produce\nincorrect output, and isn\u2019t maintained any more\n(<a href=\"https://github.com/tensorflow/tensorflow/issues/15214#issuecomment-382442357\" rel=\"nofollow\">https://github.com/tensorflow/tensorflow/issues/15214#issuecomment-382442357</a>)</li>\n<li>Reduce memory usage during training by caching temporary variables used\nwhen computing <tt>ScatterUpdate</tt> gradient.</li>\n<li>Increase minimum TensorFlow version to 1.4.0.</li>\n<li>Increased minimum NumPy version to 1.12.1 (required by TensorFlow)</li>\n<li>Sort write signals as well as reads during graph optimization (encourages\ntighter partitioning, which can improve training/inference speed).</li>\n<li>Moved <tt>configure_settings</tt> from <tt>utils.py</tt> to <tt>config.py</tt>.</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed a bug where\n<tt><span class=\"pre\">nengo_dl.dists.VarianceScaling(...,</span> <span class=\"pre\">distribution=\"normal\")</span></tt> did not\nrespect the seed if one was given.</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li>The <tt><span class=\"pre\">Simulator(dtype=...)</span></tt> argument has been deprecated; use\n<tt><span class=\"pre\">nengo_dl.configure_settings(dtype=...)</span></tt> instead.  Will be removed in\n1.3.0.</li>\n</ul>\n</div>\n<div id=\"july-24-2018\">\n<h4>1.1.0 (July 24, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>The default TensorFlow Session is now set to the underlying Simulator session\nwithin the Simulator context.</li>\n<li>Added CLI for benchmarks.py</li>\n<li>Added <tt>sim.freeze_params</tt> tool, to more easily extract model parameters for\nreuse in different Simulators.</li>\n<li>Added <a href=\"https://www.nengo.ai/nengo-dl/simulator.html#saving-and-loading-parameters\" rel=\"nofollow\">documentation on saving and loading model parameters</a>.</li>\n<li>Added <a href=\"https://science.sciencemag.org/content/338/6111/1202.full\" rel=\"nofollow\">Spaun</a>\nexample in <tt>benchmarks.py</tt></li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Move <tt><span class=\"pre\">tensorflow-gpu</span></tt> installation check to Simulator init, and only apply\nif <tt>device=None</tt>.</li>\n<li>Switched to <tt>pylint</tt> for style checks.</li>\n<li>TensorFlow INFO-level log messages are now disabled by default on import</li>\n<li>All previous releases now tracked in documentation</li>\n<li>Updated spiking MNIST example to simplify and improve performance.</li>\n<li>Passing unknown configuration options to <tt>nengo_dl.configure_settings</tt>\nwill now give a more explicit error message.</li>\n<li>Improved speed of parameter fetching though <tt>get_nengo_params</tt></li>\n<li>Raise a warning if user tries to train a network with non-differentiable\nelements (requires <tt><span class=\"pre\">tensorflow&gt;=1.9.0</span></tt>)</li>\n<li>Improved accuracy of <tt>SoftLIFRate</tt> implementation for small values (<a href=\"https://github.com/nengo/nengo-dl/pull/45\" rel=\"nofollow\">#45</a>)</li>\n<li>Simplified how <tt>TensorSignals</tt> are loaded into the TensorFlow graph</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Better handling of Simulator errors not associated with a specific op (fixes\n<a href=\"https://github.com/nengo/nengo-dl/issues/41\" rel=\"nofollow\">#41</a>)</li>\n<li>Fixed node outputs changing after simulator is built (fixes <a href=\"https://github.com/nengo/nengo-dl/issues/4\" rel=\"nofollow\">#4</a>)</li>\n<li>Fixed some broken cross references in the documentation</li>\n<li>Fixed several edge cases for <tt>get_nengo_params</tt>; don\u2019t use trained gains\nfor direct neuron connections, error raised if <tt>get_nengo_params</tt> applied\nto an Ensemble with Direct neurons</li>\n<li>Compatible with <tt><span class=\"pre\">tensorflow==1.9.0</span></tt> release</li>\n<li>Fixed bug in <tt><span class=\"pre\">nengo_dl.configure_settings(session_config=...)</span></tt> when passing\na pre-build model to the Simulator instead of a Network</li>\n<li>Fixed TensorFlow version comparisons for 1.10.0</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li><tt>Simulator.trange</tt> argument <tt>dt</tt> has been deprecated (replaced with\n<tt>sample_every</tt>, see <a href=\"https://github.com/nengo/nengo/pull/1384\" rel=\"nofollow\">https://github.com/nengo/nengo/pull/1384</a>)</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>Removed <tt>nengo_dl.DATA_DIR</tt> constant</li>\n<li>Removed <tt>benchmarks.compare_backends</tt> (use\n<tt>whitepaper2018_plots.py:compare_backends</tt> instead)</li>\n<li>Removed <tt><span class=\"pre\">ghp-import</span></tt> dependency</li>\n</ul>\n</div>\n<div id=\"may-30-2018\">\n<h4>1.0.0 (May 30, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>User can now directly specify the output error gradient, rather than using\ntargets/objective (useful for when you have some external process for\ncomputing error that is not easy to implement as an objective function).\nSee <a href=\"https://www.nengo.ai/nengo-dl/v1.0.0/training.html#objective\" rel=\"nofollow\">the documentation</a> for details.</li>\n<li>Added <a href=\"https://arxiv.org/abs/1805.11144\" rel=\"nofollow\">NengoDL white paper</a></li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Extra requirements for documentation/testing are now stored in <tt>setup.py</tt>\u2019s\n<tt>extra_requires</tt> instead of <tt><span class=\"pre\">requirements-*.txt</span></tt>.  For example, instead\nof doing <tt>pip install <span class=\"pre\">-r</span> <span class=\"pre\">requirements-test.txt</span></tt>, instead use\n<tt>pip install <span class=\"pre\">nengo-dl[tests]</span></tt> (or <tt>pip install <span class=\"pre\">-e</span> .[tests]</tt> for a\ndeveloper installation).</li>\n<li>Improved efficiency of PES implementation</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>Removed <tt><span class=\"pre\">sphinxcontrib-versioning</span></tt> dependency for building documentation</li>\n</ul>\n</div>\n<div id=\"may-4-2018\">\n<h4>0.6.2 (May 4, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added <tt>sim.get_nengo_params</tt> function to more easily extract\nmodel parameters for reuse when building different models.</li>\n<li>Added <tt><span class=\"pre\">Simulator(...,</span> progress_bar=False)</tt> option to disable the progress\ninformation printed to console when the network is building.</li>\n<li>TensorFlow session config options can now be set using\n<tt>nengo_dl.configure_settings</tt> (e.g.,\n<tt><span class=\"pre\">nengo_dl.configure_settings(session_config={\"gpu_options.allow_growth\":</span> True})</tt>)</li>\n<li>The signal sorting/graph simplificaton functions can now be configured\nthrough <tt>nengo_dl.configure_settings</tt></li>\n<li>Added <tt>extra_feeds</tt> parameter to <tt>sim.run/train/loss</tt>, which can be\nused to feed Tensor values directly into the TensorFlow session</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Improved speed of PES implementation by adding a custom operator.</li>\n<li>Renamed project from <tt>nengo_dl</tt> to <tt><span class=\"pre\">nengo-dl</span></tt> (to be more consistent with\nstandard conventions).  This only affects the display name of the project\non PyPI/GitHub, and the documentation now resides at\n<a href=\"https://www.nengo.ai/nengo-dl/\" rel=\"nofollow\">https://www.nengo.ai/nengo-dl/</a>; there are no functional changes to user code.</li>\n<li>Minor efficiency improvements to graph planner</li>\n<li>Avoid using <tt>tf.constant</tt>, to get around TensorFlow\u2019s 2GB limit on graph\nsize when building large models</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Checking <tt>nengo_dl</tt> version without <tt>nengo</tt> installed will no longer\nresult in an error.</li>\n<li>Updated progress bar to work with <tt><span class=\"pre\">progressbar2&gt;=3.37.0</span></tt></li>\n<li>Updated PES implementation to work with generic synapse types\n(see <a href=\"https://github.com/nengo/nengo/pull/1095\" rel=\"nofollow\">https://github.com/nengo/nengo/pull/1095</a>)</li>\n<li>Fixed installation to work with <tt><span class=\"pre\">pip&gt;=10.0</span></tt></li>\n<li>Fixed bug when using a TensorNode with a <tt>pre_build</tt> function and\n<tt><span class=\"pre\">size_in==0</span></tt></li>\n</ul>\n</div>\n<div id=\"march-7-2018\">\n<h4>0.6.1 (March 7, 2018)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added TensorFlow implementation for <tt>nengo.SpikingRectifiedLinear</tt> neuron\ntype.</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Optimizer variables (e.g., momentum values) will only be initialized the\nfirst time that optimizer is passed to <tt>sim.train</tt>.  Subsequent calls to\n<tt>sim.train</tt> will resume with the values from the previous call.</li>\n<li>Low-level simulation input/output formats have been reworked to make them\nslightly easier to use (for users who want to bypass <tt>sim.run</tt> or\n<tt>sim.train</tt> and access the TensorFlow session directly).</li>\n<li>Batch dimension will always be first (if present) when checking model\nparameters via <tt>sim.data</tt>.</li>\n<li>TensorFlow ops created within the Simulator context will now default to\nthe same device as the Simulator.</li>\n<li>Update minimum Nengo version to 2.7.0</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Better error message if training data has incorrect rank</li>\n<li>Avoid reinstalling TensorFlow if one of the nightly build packages is already\ninstalled</li>\n<li>Lowpass synapse can now be applied to multidimensional inputs</li>\n<li>TensorNodes will no longer be built into the default graph when checking\ntheir output dimensionality.</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>Removed <tt>utils.cast_dtype</tt> function</li>\n</ul>\n</div>\n<div id=\"december-13-2017\">\n<h4>0.6.0 (December 13, 2017)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>The <tt>SoftLIFRate</tt> neuron type now has an <tt>amplitude</tt> parameter, which\nscales the output in the same way as the new <tt>amplitude</tt> parameter in\n<tt>LIF</tt>/<tt>LIFRate</tt> (see <a href=\"https://github.com/nengo/nengo/pull/1325\" rel=\"nofollow\">Nengo PR #1325</a>).</li>\n<li>Added <tt>progress_bar=False</tt> option to <tt>sim.run</tt>, which will disable the\ninformation about the simulation status printed to standard output (<a href=\"https://github.com/nengo/nengo-dl/issues/17\" rel=\"nofollow\">#17</a>).</li>\n<li>Added progress bars for the build/simulation process.</li>\n<li>Added truncated backpropagation option to <tt>sim.train</tt> (useful for reducing\nmemory usage during training).  See <a href=\"https://www.nengo.ai/nengo-dl/v0.6.0/training.html#truncation\" rel=\"nofollow\">the documentation for details</a>.</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Changed the default <tt>tensorboard</tt> argument in <tt>Simulator</tt> from <tt>False</tt>\nto <tt>None</tt></li>\n<li>Use the new <a href=\"https://github.com/tensorflow/docs/blob/r1.14/site/en/api_docs/python/tf/profiler/profile.md\" rel=\"nofollow\">tf.profiler</a>\ntool to collect profiling data in <tt>sim.run_steps</tt> and <tt>sim.train</tt> when\n<tt>profile=True</tt>.</li>\n<li>Minor improvements to efficiency of build process.</li>\n<li>Minor improvements to simulation efficiency targeting small ops\n(<tt>tf.reshape/identity/constant</tt>).</li>\n<li>Process inputs are now reseeded for each input when batch processing (if seed\nis not manually set).</li>\n<li>Users can pass a dict of config options for the <tt>profile</tt> argument in\n<tt>run_steps</tt>/<tt>train</tt>, which will be passed on to the TensorFlow\nprofiler; see the <tt>tf.profiler</tt> documentation for the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/options.md\" rel=\"nofollow\">available options</a>.</li>\n</ul>\n<p><strong>Removed</strong></p>\n<ul>\n<li>Removed <tt>backports.print_function</tt> dependency</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed a bug where input nodes that were only read as a view were not\nfeedable</li>\n<li>Updated <tt><span class=\"pre\">tensorflow-gpu</span></tt> installation check</li>\n<li>Improved numerical stability of <tt>LIFRate</tt> gradients  (<a href=\"https://github.com/nengo/nengo-dl/issues/26\" rel=\"nofollow\">#26</a>)</li>\n<li>Added more informative error message when data is provided with fewer items\nthan <tt>sim.minibatch_size</tt> (<a href=\"https://github.com/nengo/nengo-dl/issues/30\" rel=\"nofollow\">#30</a>)</li>\n</ul>\n</div>\n<div id=\"october-11-2017\">\n<h4>0.5.2 (October 11, 2017)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>TensorNode outputs can now define a <tt>post_build</tt> function that will be\nexecuted after the simulation is initialized (see the <a href=\"https://www.nengo.ai/nengo-dl/tensor_node.html\" rel=\"nofollow\">TensorNode\ndocumentation for details</a>).</li>\n<li>Added functionality for outputting summary data during the training process\nthat can be viewed in TensorBoard (see the <a href=\"https://www.nengo.ai/nengo-dl/v0.5.2/training.html#summaries\" rel=\"nofollow\">sim.train documentation</a>).</li>\n<li>Added some examples demonstrating how to use Nengo DL in a more complicated\ntask using semantic pointers to encode/retrieve information</li>\n<li>Added <tt>sim.training_step</tt> variable which will track the current training\niteration (can be used, e.g., for TensorFlow\u2019s variable learning rate\noperations).</li>\n<li>Users can manually create <tt>tf.summary</tt> ops and pass them to <tt>sim.train</tt>\nsummaries</li>\n<li>The Simulator context will now also set the default TensorFlow graph to the\none associated with the Simulator (so any TensorFlow ops created within the\nSimulator context will automatically be added to the correct graph)</li>\n<li>Users can now specify a different objective for each output probe during\ntraining/loss calculation (see the <a href=\"https://www.nengo.ai/nengo-dl/v0.5.2/training.html#objective\" rel=\"nofollow\">sim.train documentation</a>).</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Resetting the simulator now only rebuilds the necessary components in the\ngraph (as opposed to rebuilding the whole graph)</li>\n<li>The default <tt>\"mse\"</tt> loss implementation will now automatically convert\n<tt>np.nan</tt> values in the target to zero error</li>\n<li>If there are multiple target probes given to <tt>sim.train</tt>/<tt>sim.loss</tt> the\ntotal error will now be summed across probes (instead of averaged)</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li><tt>sim.data</tt> now implements the full <tt>collections.Mapping</tt> interface</li>\n<li>Fixed bug where signal order was non-deterministic for Networks containing\nobjects with duplicate names\n(<a href=\"https://github.com/nengo/nengo-dl/issues/9\" rel=\"nofollow\">#9</a>)</li>\n<li>Fixed bug where non-slot optimizer variables were not initialized\n(<a href=\"https://github.com/nengo/nengo-dl/issues/11\" rel=\"nofollow\">#11</a>)</li>\n<li>Implemented a modified PES builder in order to avoid slicing encoders on\nnon-decoded PES connections</li>\n<li>TensorBoard output directory will be automatically created if it doesn\u2019t\nexist</li>\n</ul>\n</div>\n<div id=\"august-28-2017\">\n<h4>0.5.1 (August 28, 2017)</h4>\n<p><strong>Changed</strong></p>\n<ul>\n<li><tt>sim.data[obj]</tt> will now return live parameter values from the simulation,\nrather than initial values from the build process.  That means that it can\nbe used to get the values of object parameters after training, e.g.\n<tt><span class=\"pre\">sim.data[my_conn].weights</span></tt>.</li>\n<li>Increased minimum Nengo version to 2.5.0.</li>\n<li>Increased minimum TensorFlow version to 1.3.0.</li>\n</ul>\n</div>\n<div id=\"july-11-2017\">\n<h4>0.5.0 (July 11, 2017)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added <tt>nengo_dl.tensor_layer</tt> to help with the construction of\nlayer-style TensorNodes (see the <a href=\"https://www.nengo.ai/nengo-dl/tensor_node.html\" rel=\"nofollow\">TensorNode documentation</a>)</li>\n<li>Added an example demonstrating <a href=\"https://www.nengo.ai/nengo-dl/examples/spiking_mnist.html\" rel=\"nofollow\">how to train a neural network\nthat can run in spiking neurons</a></li>\n<li>Added some distributions for weight initialization to <tt>nengo_dl.dists</tt></li>\n<li>Added <tt><span class=\"pre\">sim.train(...,</span> profile=True)</tt> option to collect profiling\ninformation during training</li>\n<li>Added new methods to simplify the Nengo operation graph, resulting in faster\nsimulation/training speed</li>\n<li>The default graph planner can now be modified by setting the <tt>planner</tt>\nattribute on the top-level Network config</li>\n<li>Added TensorFlow implementation for general linear synapses</li>\n<li>Added <tt>backports.tempfile</tt> and <tt>backports.print_function</tt> requirement for\nPython 2.7 systems</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Increased minimum TensorFlow version to 1.2.0</li>\n<li>Improved error checking for input/target data</li>\n<li>Improved efficiency of stateful gradient operations, resulting in faster\ntraining speed</li>\n<li>The functionality for <tt>nengo_dl.configure_trainable</tt> has been subsumed into\nthe more general <tt>nengo_dl.configure_settings(trainable=x)</tt>.  This has\nresulted in some small changes to how trainability is controlled within\nsubnetworks; see the <a href=\"https://www.nengo.ai/nengo-dl/simulator.html#choosing-which-elements-to-optimize\" rel=\"nofollow\">updated documentation</a>\nfor details.</li>\n<li>Calling <tt>Simulator.train</tt>/<tt>Simulator.loss</tt> no longer resets the internal\nstate of the simulation (so they can be safely intermixed with calls to\n<tt>Simulator.run</tt>)</li>\n</ul>\n<p><strong>Deprecated</strong></p>\n<ul>\n<li>The old <tt>step_blocks</tt>/<tt>unroll_simulation</tt> syntax has been fully\ndeprecated, and will result in errors if used</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fixed bug related to changing the output of a Node after the model is\nconstructed (<a href=\"https://github.com/nengo/nengo-dl/issues/4\" rel=\"nofollow\">#4</a>)</li>\n<li>Order of variable creation is now deterministic (helps make saving/loading\nparameters more reliable)</li>\n<li>Configuring whether or not a model element is trainable does not affect\nwhether or not that element is minibatched</li>\n<li>Correctly reuse variables created inside a TensorNode when\n<tt>unroll_simulation</tt> &gt; 1</li>\n<li>Correctly handle probes that aren\u2019t connected to any ops</li>\n<li>Swapped <tt>fan_in</tt>/<tt>fan_out</tt> in <tt>dists.VarianceScaling</tt> to align with\nthe standard definitions</li>\n<li>Temporary patch to fix memory leak in TensorFlow (see\n<a href=\"https://github.com/tensorflow/tensorflow/issues/11273\" rel=\"nofollow\">#11273</a>)</li>\n<li>Fixed bug related to nodes that had matching output functions but different\nsize_out</li>\n<li>Fixed bug related to probes that do not contain any data yet</li>\n</ul>\n</div>\n<div id=\"june-8-2017\">\n<h4>0.4.0 (June 8, 2017)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added ability to manually specify which parts of a model are trainable\n(see the <a href=\"https://www.nengo.ai/nengo-dl/v0.4.0/training.html\" rel=\"nofollow\">sim.train documentation</a>)</li>\n<li>Added some code examples (see the <tt>docs/examples</tt> directory, or the\n<a href=\"https://www.nengo.ai/nengo-dl/examples.html\" rel=\"nofollow\">pre-built examples in the documentation</a>)</li>\n<li>Added the SoftLIFRate neuron type for training LIF networks (based on\n<a href=\"https://arxiv.org/abs/1510.08829\" rel=\"nofollow\">this paper</a>)</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Updated TensorFuncParam to new Nengo Param syntax</li>\n<li>The interface for Simulator <tt>step_blocks</tt>/<tt>unroll_simulation</tt> has been\nchanged.  Now <tt>unroll_simulation</tt> takes an integer as argument which is\nequivalent to the old <tt>step_blocks</tt> value, and <tt>unroll_simulation=1</tt> is\nequivalent to the old <tt>unroll_simulation=False</tt>.  For example,\n<tt><span class=\"pre\">Simulator(...,</span> unroll_simulation=True, step_blocks=10)</tt> is now equivalent\nto <tt><span class=\"pre\">Simulator(...,</span> unroll_simulation=10)</tt>.</li>\n<li>Simulator.train/Simulator.loss no longer require <tt>step_blocks</tt> (or the new\n<tt>unroll_simulation</tt>) to be specified; the number of steps to train across\nwill now be inferred from the input data.</li>\n</ul>\n</div>\n<div id=\"may-12-2017\">\n<h4>0.3.1 (May 12, 2017)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Added more documentation on Simulator arguments</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Improved efficiency of tree_planner, made it the new default planner</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Correctly handle input feeds when n_steps &gt; step_blocks</li>\n<li>Detect cycles in transitive planner</li>\n<li>Fix bug in uneven step_blocks rounding</li>\n<li>Fix bug in Simulator.print_params</li>\n<li>Fix bug related to merging of learning rule with different dimensionality</li>\n<li>Use tf.Session instead of tf.InteractiveSession, to avoid strange side\neffects if the simulator isn\u2019t closed properly</li>\n</ul>\n</div>\n<div id=\"april-25-2017\">\n<h4>0.3.0 (April 25, 2017)</h4>\n<p><strong>Added</strong></p>\n<ul>\n<li>Use logger for debug/builder output</li>\n<li>Implemented TensorFlow gradients for sparse Variable update Ops, to allow\nmodels with those elements to be trained</li>\n<li>Added tutorial/examples on using <tt>Simulator.train</tt></li>\n<li>Added support for training models when <tt>unroll_simulation=False</tt></li>\n<li>Compatibility changes for Nengo 2.4.0</li>\n<li>Added a new graph planner algorithm, which can improve simulation speed at\nthe cost of build time</li>\n</ul>\n<p><strong>Changed</strong></p>\n<ul>\n<li>Significant improvements to simulation speed<ul>\n<li>Use sparse Variable updates for signals.scatter/gather</li>\n<li>Improved graph optimizer memory organization</li>\n<li>Implemented sparse matrix multiplication op, to allow more aggressive\nmerging of DotInc operators</li>\n</ul>\n</li>\n<li>Significant improvements to build speed<ul>\n<li>Added early termination to graph optimization</li>\n<li>Algorithmic improvements to graph optimization functions</li>\n</ul>\n</li>\n<li>Reorganized documentation to more clearly direct new users to relevant\nmaterial</li>\n</ul>\n<p><strong>Fixed</strong></p>\n<ul>\n<li>Fix bug where passing a built model to the Simulator more than once would\nresult in an error</li>\n<li>Cache result of calls to <tt>tensor_graph.build_loss/build_optimizer</tt>, so that\nwe don\u2019t unnecessarily create duplicate elements in the graph on repeated\ncalls</li>\n<li>Fix support for Variables on GPU when <tt>unroll_simulation=False</tt></li>\n<li>SimPyFunc operators will always be assigned to CPU, even when\n<tt><span class=\"pre\">device=\"/gpu:0\"</span></tt>, since there is no GPU kernel</li>\n<li>Fix bug where <tt>Simulator.loss</tt> was not being computed correctly for\nmodels with internal state</li>\n<li>Data/targets passed to <tt>Simulator.train</tt> will be truncated if not evenly\ndivisible by the specified minibatch size</li>\n<li>Fixed bug where in some cases Nodes with side effects would not be run if\ntheir output was not used in the simulation</li>\n<li>Fixed bug where strided reads that cover a full array would be interpreted as\nnon-strided reads of the full array</li>\n</ul>\n</div>\n<div id=\"march-13-2017\">\n<h4>0.2.0 (March 13, 2017)</h4>\n<p>Initial release of TensorFlow-based NengoDL</p>\n</div>\n<div id=\"june-12-2016\">\n<h4>0.1.0 (June 12, 2016)</h4>\n<p>Initial release of Lasagne-based NengoDL</p>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6936401, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "f243977b6eaf373ab777333dd9f6bd6a", "sha256": "e732f1e1baf5c09061c6a2ec0236e41f6db9dbad03010bafb3a3f9cd770dc015"}, "downloads": -1, "filename": "nengo-dl-0.2.0.tar.gz", "has_sig": false, "md5_digest": "f243977b6eaf373ab777333dd9f6bd6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 110901, "upload_time": "2018-03-29T15:52:01", "upload_time_iso_8601": "2018-03-29T15:52:01.751599Z", "url": "https://files.pythonhosted.org/packages/4c/45/b8f935b6f1a37fb31991786704048dfcc7b99191f07f7177c2a833bbc1c3/nengo-dl-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "178f4b6d60d5e3cf70d30f02966eaaa6", "sha256": "47b29c82bddc540ce7c7e9287e31617c35d70bb1b112536af3eb8d25dd666d68"}, "downloads": -1, "filename": "nengo_dl-0.3.0-1-py3-none-any.whl", "has_sig": false, "md5_digest": "178f4b6d60d5e3cf70d30f02966eaaa6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 97505, "upload_time": "2018-03-29T15:53:25", "upload_time_iso_8601": "2018-03-29T15:53:25.173781Z", "url": "https://files.pythonhosted.org/packages/d2/d0/d8bae1dc2394e8efc4fa26edf26e1d9eedf010fcf562f488b58666a3fa4a/nengo_dl-0.3.0-1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7087923a7c4be8c4cc261bca488b7ef7", "sha256": "c000ca5812d50df6046fad42acf3c598984eb09ce89ea754f89b2a17d8b6ac21"}, "downloads": -1, "filename": "nengo-dl-0.3.0.tar.gz", "has_sig": false, "md5_digest": "7087923a7c4be8c4cc261bca488b7ef7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 123176, "upload_time": "2018-03-29T15:52:43", "upload_time_iso_8601": "2018-03-29T15:52:43.341778Z", "url": "https://files.pythonhosted.org/packages/50/29/c6f647d4400ecffb2b8955f9872f31e397caaaf8c9b718971f1f07f33ca7/nengo-dl-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "981c0a855407b3c34ea2de386c739bf2", "sha256": "7f3a8b3f3c53eecbf2eb9012d89ab4bf2d969d2c9f90a5c6d9414106f5eb68a0"}, "downloads": -1, "filename": "nengo_dl-0.3.1-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "981c0a855407b3c34ea2de386c739bf2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 99901, "upload_time": "2018-03-29T15:54:25", "upload_time_iso_8601": "2018-03-29T15:54:25.153762Z", "url": "https://files.pythonhosted.org/packages/97/c2/7ffd6ffe175fdac09f97fe56ac97c0038b2ec48417804b5aa8919da11596/nengo_dl-0.3.1-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ffbc63a901d25e8b04d7cf57782668da", "sha256": "8ba225dab36604f21b6386e4892c913d3a2ce93113a9830051fb128815a3cab5"}, "downloads": -1, "filename": "nengo-dl-0.3.1.tar.gz", "has_sig": false, "md5_digest": "ffbc63a901d25e8b04d7cf57782668da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79266, "upload_time": "2018-03-29T15:53:35", "upload_time_iso_8601": "2018-03-29T15:53:35.660156Z", "url": "https://files.pythonhosted.org/packages/73/66/de2acf7637a28608d7b386fa26d355732673cb0a9e54a1e5bf4cfee18589/nengo-dl-0.3.1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "b40dcb82fcd7f65d35c6fd8b6f319df4", "sha256": "360d1867cda6f453b9b5eae4a4d31e900a8dc1a03d154a6ea3796f7bb838a57a"}, "downloads": -1, "filename": "nengo_dl-0.4.0-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b40dcb82fcd7f65d35c6fd8b6f319df4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 102734, "upload_time": "2018-03-29T15:54:51", "upload_time_iso_8601": "2018-03-29T15:54:51.797532Z", "url": "https://files.pythonhosted.org/packages/b4/8e/8b71f85d86e2b5139e6599e14106b128ff7536bcebf16a23710b3d49c362/nengo_dl-0.4.0-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "652d5899afc3e6b25e4d4c7c8728d98f", "sha256": "db30f554ab5c1dd7f4d01c0305d7018ed7ef7882d603346bccae6d0fcba76585"}, "downloads": -1, "filename": "nengo-dl-0.4.0.tar.gz", "has_sig": false, "md5_digest": "652d5899afc3e6b25e4d4c7c8728d98f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 88797, "upload_time": "2018-03-29T15:54:41", "upload_time_iso_8601": "2018-03-29T15:54:41.071046Z", "url": "https://files.pythonhosted.org/packages/f1/e9/bf0c9662cc0839d3433e763c211719fb0944e5581794435633016fe12d6c/nengo-dl-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "3ef7fbdf7b0902e6f2feb95f9efeb92c", "sha256": "f600f245e1c37421fc5066253aa9983b49d70f8283b67ba0235d3f223efe3c0e"}, "downloads": -1, "filename": "nengo_dl-0.5.0-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3ef7fbdf7b0902e6f2feb95f9efeb92c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 111901, "upload_time": "2018-03-29T15:55:10", "upload_time_iso_8601": "2018-03-29T15:55:10.027549Z", "url": "https://files.pythonhosted.org/packages/a5/30/5ba3ed7de39b204c67ca2bbfcf13ee85ecf4122ab70f7e3ab91329e2002b/nengo_dl-0.5.0-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e195e533ea3b00475346b89337ee9fc5", "sha256": "9be1a9093fcd2658ba642194a5b7827a4fc61f6e7a04f0b39a7c636b6c418fa7"}, "downloads": -1, "filename": "nengo-dl-0.5.0.tar.gz", "has_sig": false, "md5_digest": "e195e533ea3b00475346b89337ee9fc5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 115762, "upload_time": "2018-03-29T15:55:00", "upload_time_iso_8601": "2018-03-29T15:55:00.570859Z", "url": "https://files.pythonhosted.org/packages/ec/4d/a1768da7ff78c28248b639ae949b193f41c5ec528ea00b924be8fd275864/nengo-dl-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "b42a791735d61830757a6d55c8dfc61d", "sha256": "b150c5bbd9e6d3d646049b99609a63d18f7dad0268e9775e12520072c814451b"}, "downloads": -1, "filename": "nengo_dl-0.5.1-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b42a791735d61830757a6d55c8dfc61d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 113259, "upload_time": "2018-03-29T15:55:24", "upload_time_iso_8601": "2018-03-29T15:55:24.694912Z", "url": "https://files.pythonhosted.org/packages/70/22/978c7f49bfbb7a889db4ff2ce95f83f862b7fc2458df210b89af7e00612f/nengo_dl-0.5.1-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5eea8305ebea545ffc56c7971e9057b6", "sha256": "586f559f1e086d5a39e33144e61add7bed9142dd0a13a4ec07f636626d8287d0"}, "downloads": -1, "filename": "nengo-dl-0.5.1.tar.gz", "has_sig": false, "md5_digest": "5eea8305ebea545ffc56c7971e9057b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 118061, "upload_time": "2018-03-29T15:55:17", "upload_time_iso_8601": "2018-03-29T15:55:17.560310Z", "url": "https://files.pythonhosted.org/packages/ac/85/8e9cf239e655c744b896d71831b8021066b749e814559ba6f39f5cfcc03b/nengo-dl-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "5283d88122b6941dd8002eb609f2b888", "sha256": "a91f81aab3d22ff654ec0f462e53ba8297c1ec169e675b81723145a69fb93da7"}, "downloads": -1, "filename": "nengo_dl-0.5.2-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5283d88122b6941dd8002eb609f2b888", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 119195, "upload_time": "2018-03-29T15:55:40", "upload_time_iso_8601": "2018-03-29T15:55:40.400577Z", "url": "https://files.pythonhosted.org/packages/2f/ba/39a8f22c72444d3a4b1bb359e02ab2dea70050b28f95eec8720239a2e1bf/nengo_dl-0.5.2-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23195c64a9621b799de014e0a97e6c7f", "sha256": "847dcd66bb1850ed2fa3fa9e66af73ab83d845b9f41319c76d8640ce4c038733"}, "downloads": -1, "filename": "nengo-dl-0.5.2.tar.gz", "has_sig": false, "md5_digest": "23195c64a9621b799de014e0a97e6c7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 132902, "upload_time": "2018-03-29T15:55:32", "upload_time_iso_8601": "2018-03-29T15:55:32.320771Z", "url": "https://files.pythonhosted.org/packages/a7/15/0d5f899018fd33bfb3af2d355ce6b051229f8abce8939c539814840e0963/nengo-dl-0.5.2.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "398d1a2ceb35a7e3d590d6290117dadb", "sha256": "c2325487c21368049868457a84fed0a1dbd8d74412af45f657824dafbd64fb8a"}, "downloads": -1, "filename": "nengo_dl-0.6.0-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "398d1a2ceb35a7e3d590d6290117dadb", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 125651, "upload_time": "2018-03-29T15:56:07", "upload_time_iso_8601": "2018-03-29T15:56:07.395769Z", "url": "https://files.pythonhosted.org/packages/cf/23/c29beb00fa18583df44a9bb0b20037258b8d9592f63c3cd11795bf074b12/nengo_dl-0.6.0-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bb98156b93bfeae43c7f79678963e88c", "sha256": "c70ab9daf67528046b6ae2ded5a6d0d2ed863c8fc829f3569bfacafea5348dcc"}, "downloads": -1, "filename": "nengo-dl-0.6.0.tar.gz", "has_sig": false, "md5_digest": "bb98156b93bfeae43c7f79678963e88c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 139756, "upload_time": "2018-03-29T15:55:58", "upload_time_iso_8601": "2018-03-29T15:55:58.381029Z", "url": "https://files.pythonhosted.org/packages/84/7c/1299e04d01640281ac7b18b8ce95127001dcc57239862a5c00b6df72eed9/nengo-dl-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "48f7385adcd575299d51c2df23aa3c20", "sha256": "037172c38b5e75fd186f773c731d685defff71166d4053ff0fcdfcab445e14d9"}, "downloads": -1, "filename": "nengo_dl-0.6.1-1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "48f7385adcd575299d51c2df23aa3c20", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 126644, "upload_time": "2018-03-29T15:56:20", "upload_time_iso_8601": "2018-03-29T15:56:20.719537Z", "url": "https://files.pythonhosted.org/packages/71/57/56405632666add906e9381dbfd434fd3ad65c815baf050dc74ca295a1308/nengo_dl-0.6.1-1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb52a8b5c103ff50caa66d5172dbafc7", "sha256": "395f0c11b066f9f4670fc34d8d9ff5c7e05f41bfe4cc35eaa5d780d7e5be3ca4"}, "downloads": -1, "filename": "nengo-dl-0.6.1.tar.gz", "has_sig": false, "md5_digest": "cb52a8b5c103ff50caa66d5172dbafc7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 141023, "upload_time": "2018-03-29T15:56:13", "upload_time_iso_8601": "2018-03-29T15:56:13.268489Z", "url": "https://files.pythonhosted.org/packages/cc/35/5ef2fd6d16440335654872094efb8f8ebba7a9eb27feb7d693753e7226c1/nengo-dl-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "4393cfe4e51c501d83b0f3981783510d", "sha256": "5bca9cc0818c476934e337de7d43f0e7d7f2dfaa2699a722d7e56da0a819f99b"}, "downloads": -1, "filename": "nengo_dl-0.6.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4393cfe4e51c501d83b0f3981783510d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 133670, "upload_time": "2018-05-04T18:45:24", "upload_time_iso_8601": "2018-05-04T18:45:24.823916Z", "url": "https://files.pythonhosted.org/packages/6f/0b/618e07c5c33838579a68c94d91f7785dcd68119b0347334705efd186ec2d/nengo_dl-0.6.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f66e9980d4fc6bfcf3324966089d710", "sha256": "743ecde245c1689a9902380f08ef4af3392fdc5d94232cdc761b6077c2822cd7"}, "downloads": -1, "filename": "nengo-dl-0.6.2.tar.gz", "has_sig": false, "md5_digest": "7f66e9980d4fc6bfcf3324966089d710", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 146930, "upload_time": "2018-05-04T18:44:47", "upload_time_iso_8601": "2018-05-04T18:44:47.558559Z", "url": "https://files.pythonhosted.org/packages/44/81/0af751ce40e06bfafe7cf674764b1b6d431bc3cb5bed49646b8a60eef642/nengo-dl-0.6.2.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "8578e3e29a12e7a8377c2e7c32800402", "sha256": "7055d42448226a1c445d2144d936ec8e8a05de7773d9e640d20ea9593d9904d1"}, "downloads": -1, "filename": "nengo_dl-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8578e3e29a12e7a8377c2e7c32800402", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 126641, "upload_time": "2018-05-30T19:38:12", "upload_time_iso_8601": "2018-05-30T19:38:12.618404Z", "url": "https://files.pythonhosted.org/packages/b7/31/2b5ab76f066bc23721b3684bf3ccfefac4c3680ea930360b5d81098d4158/nengo_dl-1.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a997bea6cd265b4efdbcaebf0c23693d", "sha256": "4c94bb2dd2652377317ec784b1f6ab996b5a5679ebe41abf51bed8c49d03394e"}, "downloads": -1, "filename": "nengo-dl-1.0.0.tar.gz", "has_sig": false, "md5_digest": "a997bea6cd265b4efdbcaebf0c23693d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 149500, "upload_time": "2018-05-30T19:37:15", "upload_time_iso_8601": "2018-05-30T19:37:15.624477Z", "url": "https://files.pythonhosted.org/packages/ba/17/26b9566c5c4e428721d419bb0a5299e95f0f1eff25771cb26122bbf1ac96/nengo-dl-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "4b831c454c1148ce9bcde90b422104fe", "sha256": "ace92b768b7e52302d8ea87785ca7c0bead781a7efb5dd8a04a042a97ebe2435"}, "downloads": -1, "filename": "nengo_dl-1.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4b831c454c1148ce9bcde90b422104fe", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 134676, "upload_time": "2018-07-24T21:40:55", "upload_time_iso_8601": "2018-07-24T21:40:55.087966Z", "url": "https://files.pythonhosted.org/packages/02/b0/72cd10c299eb577db629129b8297154f3d9f6b43ffc74a688a231ba66273/nengo_dl-1.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1ce88cd9af60ef18b8f8b92f96ae146a", "sha256": "4e9b355ba82b33e9eb13481eb514319592d783abf9047eef83d667f73daace92"}, "downloads": -1, "filename": "nengo-dl-1.1.0.tar.gz", "has_sig": false, "md5_digest": "1ce88cd9af60ef18b8f8b92f96ae146a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 164245, "upload_time": "2018-07-24T21:40:37", "upload_time_iso_8601": "2018-07-24T21:40:37.612385Z", "url": "https://files.pythonhosted.org/packages/ae/21/6b5b891905b191f1f7b42c6ae8d4fa189af05ac75f4766be1af9ce63508c/nengo-dl-1.1.0.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "c1684d48c20917e542b89bd8a447e053", "sha256": "b5d2d7e0e20d698b7e739c1bf756933ff728489cc643f6a504a52aa5b2760d6a"}, "downloads": -1, "filename": "nengo_dl-1.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c1684d48c20917e542b89bd8a447e053", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 140411, "upload_time": "2018-09-05T12:18:34", "upload_time_iso_8601": "2018-09-05T12:18:34.441536Z", "url": "https://files.pythonhosted.org/packages/64/45/38ab20122ea77df7d763428777029df55b4ea048454e281b4eed5c0488d1/nengo_dl-1.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "297c7d7f918025bfbdb3d5cd5f0ad13a", "sha256": "0b549f7aa3432c663009ab7351ab5e9038efa6f2e60983601681628cee800f6a"}, "downloads": -1, "filename": "nengo-dl-1.2.0.tar.gz", "has_sig": false, "md5_digest": "297c7d7f918025bfbdb3d5cd5f0ad13a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 171073, "upload_time": "2018-09-05T12:18:10", "upload_time_iso_8601": "2018-09-05T12:18:10.316210Z", "url": "https://files.pythonhosted.org/packages/b5/c9/856a4b5253649ac0d3657c23f889520e2ae8220388cc7e092e4db353c8ab/nengo-dl-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "b2d7dccacf43188eefa609a62f480040", "sha256": "42d23b4557f35f5780fd5df02191ee2b2aea9bba1b77b474bf90a935e63e7b13"}, "downloads": -1, "filename": "nengo_dl-1.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b2d7dccacf43188eefa609a62f480040", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 131529, "upload_time": "2018-11-02T20:42:01", "upload_time_iso_8601": "2018-11-02T20:42:01.837041Z", "url": "https://files.pythonhosted.org/packages/8d/35/5e92e7bce9fd3ad37f026fdbf438ca7df9572f44a1e875b5b6dbcd93ddc2/nengo_dl-1.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b4237a123d345b72df0ba41326afc4f2", "sha256": "b12755f2425e189bb241732ea6a20d2704b72c768e25f024c05162be66047532"}, "downloads": -1, "filename": "nengo-dl-1.2.1.tar.gz", "has_sig": false, "md5_digest": "b4237a123d345b72df0ba41326afc4f2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 173119, "upload_time": "2018-11-02T20:42:03", "upload_time_iso_8601": "2018-11-02T20:42:03.496854Z", "url": "https://files.pythonhosted.org/packages/08/ad/59414ffaca6e3155e2bd2be41040eaee80bc11a9c0a9b25c321472399afe/nengo-dl-1.2.1.tar.gz", "yanked": false}], "2.0.0": [{"comment_text": "", "digests": {"md5": "3f4bc7346a608619e7b097cb9570c72c", "sha256": "9ec157e5f44ba8cce66f98980b77faaaf8b63cf20a5496b442eca786fd8b42c3"}, "downloads": -1, "filename": "nengo_dl-2.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3f4bc7346a608619e7b097cb9570c72c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4", "size": 142937, "upload_time": "2018-11-26T17:55:18", "upload_time_iso_8601": "2018-11-26T17:55:18.881518Z", "url": "https://files.pythonhosted.org/packages/11/de/c1cd91515b8ae3aeca99ac0f1d95022bdb5dd4ddfb024b1d660c4dc4cec9/nengo_dl-2.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "66bc81bacbdecc60320d15e05058bea2", "sha256": "88e532a814bebccf3957d123014a13ddfa2c6076caa432d5a6ada03dcf049ba8"}, "downloads": -1, "filename": "nengo-dl-2.0.0.tar.gz", "has_sig": false, "md5_digest": "66bc81bacbdecc60320d15e05058bea2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 186673, "upload_time": "2018-11-26T17:55:21", "upload_time_iso_8601": "2018-11-26T17:55:21.265183Z", "url": "https://files.pythonhosted.org/packages/20/d8/ca65b5ff2dca1ba6bb74245da6ccd2f289186255bf561102b366efffd8cb/nengo-dl-2.0.0.tar.gz", "yanked": false}], "2.1.0": [{"comment_text": "", "digests": {"md5": "e0ac4e431661ae49099ccc49477559a7", "sha256": "1bf8ceb7e8977b49e284de15d3b3cea9b936a5a93f9ae895e92d50c41acce47a"}, "downloads": -1, "filename": "nengo_dl-2.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "e0ac4e431661ae49099ccc49477559a7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4", "size": 146238, "upload_time": "2018-12-05T15:29:13", "upload_time_iso_8601": "2018-12-05T15:29:13.472250Z", "url": "https://files.pythonhosted.org/packages/21/79/f50cdbebe73816400957ac7f48b58dfa701528df29bfbe80a3ad1a1c46cd/nengo_dl-2.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aa9e89a76c19738ef453b20256f31a6f", "sha256": "b997ed2d6e4b5fe382ef8c703c536ea22ea3caad19c17cbcce70acb935124696"}, "downloads": -1, "filename": "nengo-dl-2.1.0.tar.gz", "has_sig": false, "md5_digest": "aa9e89a76c19738ef453b20256f31a6f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 185476, "upload_time": "2018-12-05T15:29:15", "upload_time_iso_8601": "2018-12-05T15:29:15.252474Z", "url": "https://files.pythonhosted.org/packages/84/45/664cf8dd2beb8265da15bfb46f5abdd4e72c245b6e6c656eec80c07cfdcb/nengo-dl-2.1.0.tar.gz", "yanked": false}], "2.1.1": [{"comment_text": "", "digests": {"md5": "e0843e2305e4e6e3a34b134485e5c417", "sha256": "3dd831b1d9f3378666c6cf34e26d784e6c68be5590b4a22ee04e844515677e0f"}, "downloads": -1, "filename": "nengo-dl-2.1.1.tar.gz", "has_sig": false, "md5_digest": "e0843e2305e4e6e3a34b134485e5c417", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 198639, "upload_time": "2019-01-12T01:02:26", "upload_time_iso_8601": "2019-01-12T01:02:26.334816Z", "url": "https://files.pythonhosted.org/packages/e0/3d/657cdc1cfc5964a2635c26cc1f21857d51a1b065a12136cead36e9b7b599/nengo-dl-2.1.1.tar.gz", "yanked": false}], "2.2.0": [{"comment_text": "", "digests": {"md5": "6a8a8c1f223753fea379550e30461190", "sha256": "aabcb4d8383ec6c406c67a5eb91438166738f3a10469a6feb79770cc79ae298f"}, "downloads": -1, "filename": "nengo-dl-2.2.0.tar.gz", "has_sig": false, "md5_digest": "6a8a8c1f223753fea379550e30461190", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 211466, "upload_time": "2019-07-24T18:43:06", "upload_time_iso_8601": "2019-07-24T18:43:06.683816Z", "url": "https://files.pythonhosted.org/packages/54/f9/e8f3774db104c8eccc89281e8d2a200cc9af9f503edb41c0d1a4b2351ed8/nengo-dl-2.2.0.tar.gz", "yanked": false}], "2.2.1": [{"comment_text": "", "digests": {"md5": "0809cdaa28fdfdc0af706d91ae8d1c7b", "sha256": "4f14320bb364a2024bd1c47292748f1b6eabfa90cb8fdda3c7fa98cff64d6397"}, "downloads": -1, "filename": "nengo-dl-2.2.1.tar.gz", "has_sig": false, "md5_digest": "0809cdaa28fdfdc0af706d91ae8d1c7b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 213233, "upload_time": "2019-10-02T18:57:10", "upload_time_iso_8601": "2019-10-02T18:57:10.284891Z", "url": "https://files.pythonhosted.org/packages/3b/c1/df0bc5745f8a26266632157782ba17728a49bda39cbae21a449fa66b0ffa/nengo-dl-2.2.1.tar.gz", "yanked": false}], "2.2.2": [{"comment_text": "", "digests": {"md5": "c251f097fbd36c36b7ca1be3ffc60e46", "sha256": "01afb7263c151d6310b7ab9b09d9646a9a87e38f423521d8f4bde6f3256949e3"}, "downloads": -1, "filename": "nengo-dl-2.2.2.tar.gz", "has_sig": false, "md5_digest": "c251f097fbd36c36b7ca1be3ffc60e46", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 212881, "upload_time": "2019-11-22T18:34:31", "upload_time_iso_8601": "2019-11-22T18:34:31.027764Z", "url": "https://files.pythonhosted.org/packages/06/dd/b6a2a9a61972b5cfba76e7977d46200ac698e29d74caf5a837dcf2247511/nengo-dl-2.2.2.tar.gz", "yanked": false}], "3.0.0": [{"comment_text": "", "digests": {"md5": "e9cfa8aea5b05d8b7079773d57791415", "sha256": "943a5ac144366ce454b6a0d984cccc58f027aada9d2605c59db25b0a7790eb21"}, "downloads": -1, "filename": "nengo-dl-3.0.0.tar.gz", "has_sig": false, "md5_digest": "e9cfa8aea5b05d8b7079773d57791415", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 242730, "upload_time": "2019-12-17T18:41:01", "upload_time_iso_8601": "2019-12-17T18:41:01.477384Z", "url": "https://files.pythonhosted.org/packages/86/96/dc713167846cf97e3f72cec8b1413e50a21c2206fad8ced911945ed2dcfd/nengo-dl-3.0.0.tar.gz", "yanked": false}], "3.1.0": [{"comment_text": "", "digests": {"md5": "ae123c4e60bc869e620e9731787ebfa7", "sha256": "39743f4fcae7d038451518f0bc71947036c379969894e7159a53edd0e42f4136"}, "downloads": -1, "filename": "nengo-dl-3.1.0.tar.gz", "has_sig": false, "md5_digest": "ae123c4e60bc869e620e9731787ebfa7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 247986, "upload_time": "2020-03-04T23:23:11", "upload_time_iso_8601": "2020-03-04T23:23:11.938563Z", "url": "https://files.pythonhosted.org/packages/6d/7e/cf94d615635e841e03d5bd1df96b03acbc47633c0d82d7a2354ac0c01c75/nengo-dl-3.1.0.tar.gz", "yanked": false}], "3.2.0": [{"comment_text": "", "digests": {"md5": "ed9611059a865989fc5eb4a4ada81796", "sha256": "c19f06a1dd806fa4e275b21d6b96d2811b069ae41a6e365b302578f2260fad96"}, "downloads": -1, "filename": "nengo-dl-3.2.0.tar.gz", "has_sig": false, "md5_digest": "ed9611059a865989fc5eb4a4ada81796", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 268087, "upload_time": "2020-04-02T15:21:45", "upload_time_iso_8601": "2020-04-02T15:21:45.943196Z", "url": "https://files.pythonhosted.org/packages/3e/e9/a79263bbf153f11dafffa8c78dbdc5f6eae9f08b8d53ecc67e23ba003a99/nengo-dl-3.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ed9611059a865989fc5eb4a4ada81796", "sha256": "c19f06a1dd806fa4e275b21d6b96d2811b069ae41a6e365b302578f2260fad96"}, "downloads": -1, "filename": "nengo-dl-3.2.0.tar.gz", "has_sig": false, "md5_digest": "ed9611059a865989fc5eb4a4ada81796", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 268087, "upload_time": "2020-04-02T15:21:45", "upload_time_iso_8601": "2020-04-02T15:21:45.943196Z", "url": "https://files.pythonhosted.org/packages/3e/e9/a79263bbf153f11dafffa8c78dbdc5f6eae9f08b8d53ecc67e23ba003a99/nengo-dl-3.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:32 2020"}