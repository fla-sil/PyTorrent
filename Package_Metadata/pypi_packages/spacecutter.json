{"info": {"author": "Ethan Rosenthal", "author_email": "ethanrosenthal@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "# spacecutter\n\n`spacecutter` is a library for implementing ordinal regression models in PyTorch. The library consists of models and loss functions. It is recommended to use [skorch](http://skorch.readthedocs.io/) to wrap the models to make them compatible with scikit-learn.\n\n## Installation\n\nInstall locally via\n\n```bash\npip install -e .\n```\n\n## Usage\n\n### Models\n\nDefine any PyTorch model you want that generates a single, scalar prediction value. This will be our `predictor` model. This model can then be wrapped with `spacecutter.models.OrdinalLogisticModel` which will convert the output of the `predictor` from a single number to an array of ordinal class probabilities. The following example shows how to do this for a two layer neural network `predictor` for a problem with three ordinal classes.\n\n```python\nimport numpy as np\nimport torch\nfrom torch import nn\n\nfrom spacecutter.models import OrdinalLogisticModel\n\n\nX = np.array([[0.5, 0.1, -0.1],\n              [1.0, 0.2, 0.6],\n              [-2.0, 0.4, 0.8]],\n             dtype=np.float32)\n\ny = np.array([0, 1, 2]).reshape(-1, 1)\n\nnum_features = X.shape[1]\nnum_classes = len(np.unique(y))\n\npredictor = nn.Sequential(\n    nn.Linear(num_features, num_features),\n    nn.ReLU(),\n    nn.Linear(num_features, 1)\n)\n\nmodel = OrdinalLogisticModel(predictor, num_classes)\n\ny_pred = model(torch.as_tensor(X))\n\nprint(y_pred)\n\n# tensor([[0.2325, 0.2191, 0.5485],\n#         [0.2324, 0.2191, 0.5485],\n#         [0.2607, 0.2287, 0.5106]], grad_fn=<CatBackward>)\n\n```\n\n### Training\n\nIt is recommended to use [skorch](http://skorch.readthedocs.io/) to train `spacecutter` models. The following shows how to train the model from the previous section using cumulative link loss with `skorch`:\n\n```python\nfrom skorch import NeuralNet\n\nfrom spacecutter.callbacks import AscensionCallback\nfrom spacecutter.losses import CumulativeLinkLoss\n\nskorch_model = NeuralNet(\n    module=OrdinalLogisticModel,\n    module__predictor=predictor,\n    module__num_classes=num_classes,\n    criterion=CumulativeLinkLoss,\n    train_split=None,\n    callbacks=[\n        ('ascension', AscensionCallback()),\n    ],\n)\n\nskorch_model.fit(X, y)\n\n```\n\nNote that we must add the `AscensionCallback`. This ensures that the ordinal cutpoints stay in ascending order. While ideally this constraint would be factored directly into the model optimization, `spacecutter` currently hacks an SGD-compatible solution by utilizing a post-backwards-pass callback to clip the cutpoint values.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/EthanRosenthal/spacecutter", "keywords": "machine learning statistics", "license": "", "maintainer": "", "maintainer_email": "", "name": "spacecutter", "package_url": "https://pypi.org/project/spacecutter/", "platform": "", "project_url": "https://pypi.org/project/spacecutter/", "project_urls": {"Homepage": "https://github.com/EthanRosenthal/spacecutter"}, "release_url": "https://pypi.org/project/spacecutter/0.1.0/", "requires_dist": ["numpy (==1.15.4)", "torch (==0.4.1)", "flake8 (==3.6.0) ; extra == 'test'", "pytest (==4.0.1) ; extra == 'test'", "pytest-cov (==2.6.0) ; extra == 'test'", "skorch (==0.4.0) ; extra == 'test'"], "requires_python": "", "summary": "Ordinal regression models in PyTorch", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>spacecutter</h1>\n<p><code>spacecutter</code> is a library for implementing ordinal regression models in PyTorch. The library consists of models and loss functions. It is recommended to use <a href=\"http://skorch.readthedocs.io/\" rel=\"nofollow\">skorch</a> to wrap the models to make them compatible with scikit-learn.</p>\n<h2>Installation</h2>\n<p>Install locally via</p>\n<pre>pip install -e .\n</pre>\n<h2>Usage</h2>\n<h3>Models</h3>\n<p>Define any PyTorch model you want that generates a single, scalar prediction value. This will be our <code>predictor</code> model. This model can then be wrapped with <code>spacecutter.models.OrdinalLogisticModel</code> which will convert the output of the <code>predictor</code> from a single number to an array of ordinal class probabilities. The following example shows how to do this for a two layer neural network <code>predictor</code> for a problem with three ordinal classes.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spacecutter.models</span> <span class=\"kn\">import</span> <span class=\"n\">OrdinalLogisticModel</span>\n\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([[</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.1</span><span class=\"p\">],</span>\n              <span class=\"p\">[</span><span class=\"mf\">1.0</span><span class=\"p\">,</span> <span class=\"mf\">0.2</span><span class=\"p\">,</span> <span class=\"mf\">0.6</span><span class=\"p\">],</span>\n              <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mf\">2.0</span><span class=\"p\">,</span> <span class=\"mf\">0.4</span><span class=\"p\">,</span> <span class=\"mf\">0.8</span><span class=\"p\">]],</span>\n             <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">num_features</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">num_classes</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">unique</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">))</span>\n\n<span class=\"n\">predictor</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">num_features</span><span class=\"p\">,</span> <span class=\"n\">num_features</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">num_features</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">OrdinalLogisticModel</span><span class=\"p\">(</span><span class=\"n\">predictor</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">)</span>\n\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">as_tensor</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">))</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># tensor([[0.2325, 0.2191, 0.5485],</span>\n<span class=\"c1\">#         [0.2324, 0.2191, 0.5485],</span>\n<span class=\"c1\">#         [0.2607, 0.2287, 0.5106]], grad_fn=&lt;CatBackward&gt;)</span>\n</pre>\n<h3>Training</h3>\n<p>It is recommended to use <a href=\"http://skorch.readthedocs.io/\" rel=\"nofollow\">skorch</a> to train <code>spacecutter</code> models. The following shows how to train the model from the previous section using cumulative link loss with <code>skorch</code>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">skorch</span> <span class=\"kn\">import</span> <span class=\"n\">NeuralNet</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spacecutter.callbacks</span> <span class=\"kn\">import</span> <span class=\"n\">AscensionCallback</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacecutter.losses</span> <span class=\"kn\">import</span> <span class=\"n\">CumulativeLinkLoss</span>\n\n<span class=\"n\">skorch_model</span> <span class=\"o\">=</span> <span class=\"n\">NeuralNet</span><span class=\"p\">(</span>\n    <span class=\"n\">module</span><span class=\"o\">=</span><span class=\"n\">OrdinalLogisticModel</span><span class=\"p\">,</span>\n    <span class=\"n\">module__predictor</span><span class=\"o\">=</span><span class=\"n\">predictor</span><span class=\"p\">,</span>\n    <span class=\"n\">module__num_classes</span><span class=\"o\">=</span><span class=\"n\">num_classes</span><span class=\"p\">,</span>\n    <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">CumulativeLinkLoss</span><span class=\"p\">,</span>\n    <span class=\"n\">train_split</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"n\">callbacks</span><span class=\"o\">=</span><span class=\"p\">[</span>\n        <span class=\"p\">(</span><span class=\"s1\">'ascension'</span><span class=\"p\">,</span> <span class=\"n\">AscensionCallback</span><span class=\"p\">()),</span>\n    <span class=\"p\">],</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">skorch_model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n</pre>\n<p>Note that we must add the <code>AscensionCallback</code>. This ensures that the ordinal cutpoints stay in ascending order. While ideally this constraint would be factored directly into the model optimization, <code>spacecutter</code> currently hacks an SGD-compatible solution by utilizing a post-backwards-pass callback to clip the cutpoint values.</p>\n\n          </div>"}, "last_serial": 4566504, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "fde883705f4d890cdf96d78041f059bd", "sha256": "3caa618fe3ff7b8f4dcb470a262cc52e5e10705472496f1eb8516a7cb009f4b1"}, "downloads": -1, "filename": "spacecutter-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fde883705f4d890cdf96d78041f059bd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6654, "upload_time": "2018-12-06T05:03:50", "upload_time_iso_8601": "2018-12-06T05:03:50.449385Z", "url": "https://files.pythonhosted.org/packages/1a/30/224d5e6733a35603171a56ca717487ebf42f8d62f5e84b9a9d772a2cfa80/spacecutter-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fe6f56caee5baad7f1328a76472266af", "sha256": "b9e5d2e20951652d90253d2406abaa514ca8c50297a65498d5590987b4e8339f"}, "downloads": -1, "filename": "spacecutter-0.1.0.tar.gz", "has_sig": false, "md5_digest": "fe6f56caee5baad7f1328a76472266af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5001, "upload_time": "2018-12-06T05:03:52", "upload_time_iso_8601": "2018-12-06T05:03:52.486294Z", "url": "https://files.pythonhosted.org/packages/1b/8a/ebaf3ab290ae6207b556cf7bb969c73dd04c5e99a9403fd41ed5b401d1f8/spacecutter-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fde883705f4d890cdf96d78041f059bd", "sha256": "3caa618fe3ff7b8f4dcb470a262cc52e5e10705472496f1eb8516a7cb009f4b1"}, "downloads": -1, "filename": "spacecutter-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fde883705f4d890cdf96d78041f059bd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6654, "upload_time": "2018-12-06T05:03:50", "upload_time_iso_8601": "2018-12-06T05:03:50.449385Z", "url": "https://files.pythonhosted.org/packages/1a/30/224d5e6733a35603171a56ca717487ebf42f8d62f5e84b9a9d772a2cfa80/spacecutter-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fe6f56caee5baad7f1328a76472266af", "sha256": "b9e5d2e20951652d90253d2406abaa514ca8c50297a65498d5590987b4e8339f"}, "downloads": -1, "filename": "spacecutter-0.1.0.tar.gz", "has_sig": false, "md5_digest": "fe6f56caee5baad7f1328a76472266af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5001, "upload_time": "2018-12-06T05:03:52", "upload_time_iso_8601": "2018-12-06T05:03:52.486294Z", "url": "https://files.pythonhosted.org/packages/1b/8a/ebaf3ab290ae6207b556cf7bb969c73dd04c5e99a9403fd41ed5b401d1f8/spacecutter-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:11 2020"}