{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": ["Framework :: Django :: 1.10", "Framework :: Django :: 1.11", "Framework :: Django :: 1.9", "Framework :: Django :: 2.0", "Framework :: Django :: 2.1"], "description": "Django ReDo\n=============\n\nEasy use!\n\n**Django ReDo** is a very lightweight django library which allows to easily add asynchronous\ntasks execution functionality. Library requires configured Redis server.\n\n\nInstallation\n------------\n\n    pip install Django-ReDo\n\n\n**Usage**\n\n    from django_redo import task\n    \n    # Registering new task\n    @task.define()\n    def some_async_function(hello):\n        # some code...\n        print(f'Hello {hello}')\n    \n    # This operation will schedule task to execute this function.\n    some_async_function('world')\n    \n    # Or to run it directly without scheduling\n    some_async_function.call('world')\n    \nThen we need to run worker, which will execute scheduled tasks.\n\n    python manage.py redo\n    \nDjango ReDo completely compatible with the **@staticmethods** and **functions**. It's\nuseful, when you need to group some async tasks into class.\n\n\n**Configuring django**\n\nSimply add django_redo to installed apps of your django project settings.\n\n    INSTALLED_APPS = [\n        ...\n        'django_redo',\n        ...\n    ]\n    \nThen configure specific settings for django redo:\n\n\n|OPTION|TYPE|DEFAULT|COMMENT|\n|---|---|---|---|\n|REDO_QUEUE_POLL|Float|0.05|Interval to poll redis tasks queue|\n|REDO_QUEUE_THREADS|Int|1|How much queue worker threads should be registered|\n|REDO_QUEUE_DBS|Dict|{}|*Redis server settings|\n\n*Redis server settings can be specified in two ways:\n\n**IPv Connection:**\n\n    REDO_QUEUE_DBS = {\n        \"default\": {\n            \"DB\": 0,\n            \"PASSWORD\": \"******\",\n            \"HOST\": \"127.0.0.1\",\n            \"PORT\": 6379,\n            \"THREADS\": 1\n        }\n    }\n    \n**UNIX-Socket Connection:**\n\n    REDO_QUEUE_DBS = {\n        \"default\": {\n            \"DB\": 0,\n            \"PASSWORD\": \"******\",\n            \"USOCK\": \"/tmp/redis.sock\",\n            \"THREADS\": 1\n        }\n    }\n    \nUsing different queues\n----------------------\n\nDjango ReDo allows you to use as many queues as you want. To make it possible, you need\nto configure few more queues at **REDO_QUEUE_DBS**.\n\n**For example**\n\n    REDO_QUEUE_DBS = {\n        \"fast\": {\n            \"DB\": 0,\n            \"PASSWORD\": \"******\",\n            \"USOCK\": \"/tmp/redis.sock\",\n            \"THREADS\": 1\n        },\n        \"long\": {\n            \"DB\": 1,\n            \"PASSWORD\": \"******\",\n            \"USOCK\": \"/tmp/redis.sock\",\n            \"THREADS\": 2\n        },\n        \"default\": {\n            \"DB\": 0,\n            \"PASSWORD\": \"******\",\n            \"HOST\": \"127.0.0.1\",\n            \"PORT\": 6379,\n            \"THREADS\": 1\n        }\n    }\n    \nAs you understand, you need to run specific workers for each queue.\n\n    python manage.py redo --thread 1 --queue long\n    python manage.py redo --thread 2 --queue long\n    python manage.py redo --thread 1 --queue fast\n    python manage.py redo --thread 1\n    \nLast row runs default queue worker. And to schedule any task to specific queue - \nsimply provide it to **define** decorator:\n\n    from django_redo import task\n    \n    # Registering new task to specific queue\n    @task.define('long')\n    def some_async_function(hello):\n        # some code...\n        print(f'Hello {hello}')\n        \n        \nMulti-threads example\n---------------------\n\nIf you have a lot of heavy tasks which will be scheduled and should be executed as parallel\nas it's possible - you just need to update **THREADS** option for your specific redis database\nand run same number of workers.\n\n    REDO_QUEUE_DBS = {\n        \"default\": {\n            \"DB\": 0,\n            \"PASSWORD\": \"******\",\n            \"HOST\": \"127.0.0.1\",\n            \"PORT\": 6379,\n            \"THREADS\": 4\n        }\n    }\n\nAnd 4 workers for the 4 threads:\n\n    python manage.py redo --thread 1 --queue default\n    python manage.py redo --thread 2 --queue default\n    python manage.py redo --thread 3 --queue default\n    python manage.py redo --thread 4 --queue default", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/duverse/django-redo", "keywords": "", "license": "General Public License v3.0", "maintainer": "", "maintainer_email": "", "name": "Django-ReDo", "package_url": "https://pypi.org/project/Django-ReDo/", "platform": "", "project_url": "https://pypi.org/project/Django-ReDo/", "project_urls": {"Homepage": "https://github.com/duverse/django-redo"}, "release_url": "https://pypi.org/project/Django-ReDo/0.2/", "requires_dist": null, "requires_python": "", "summary": "Easy to use django-redis asynchronous task manager.", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Django ReDo</h1>\n<p>Easy use!</p>\n<p><strong>Django ReDo</strong> is a very lightweight django library which allows to easily add asynchronous\ntasks execution functionality. Library requires configured Redis server.</p>\n<h2>Installation</h2>\n<pre><code>pip install Django-ReDo\n</code></pre>\n<p><strong>Usage</strong></p>\n<pre><code>from django_redo import task\n\n# Registering new task\n@task.define()\ndef some_async_function(hello):\n    # some code...\n    print(f'Hello {hello}')\n\n# This operation will schedule task to execute this function.\nsome_async_function('world')\n\n# Or to run it directly without scheduling\nsome_async_function.call('world')\n</code></pre>\n<p>Then we need to run worker, which will execute scheduled tasks.</p>\n<pre><code>python manage.py redo\n</code></pre>\n<p>Django ReDo completely compatible with the <strong>@staticmethods</strong> and <strong>functions</strong>. It's\nuseful, when you need to group some async tasks into class.</p>\n<p><strong>Configuring django</strong></p>\n<p>Simply add django_redo to installed apps of your django project settings.</p>\n<pre><code>INSTALLED_APPS = [\n    ...\n    'django_redo',\n    ...\n]\n</code></pre>\n<p>Then configure specific settings for django redo:</p>\n<table>\n<thead>\n<tr>\n<th>OPTION</th>\n<th>TYPE</th>\n<th>DEFAULT</th>\n<th>COMMENT</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>REDO_QUEUE_POLL</td>\n<td>Float</td>\n<td>0.05</td>\n<td>Interval to poll redis tasks queue</td>\n</tr>\n<tr>\n<td>REDO_QUEUE_THREADS</td>\n<td>Int</td>\n<td>1</td>\n<td>How much queue worker threads should be registered</td>\n</tr>\n<tr>\n<td>REDO_QUEUE_DBS</td>\n<td>Dict</td>\n<td>{}</td>\n<td>*Redis server settings</td>\n</tr></tbody></table>\n<p>*Redis server settings can be specified in two ways:</p>\n<p><strong>IPv Connection:</strong></p>\n<pre><code>REDO_QUEUE_DBS = {\n    \"default\": {\n        \"DB\": 0,\n        \"PASSWORD\": \"******\",\n        \"HOST\": \"127.0.0.1\",\n        \"PORT\": 6379,\n        \"THREADS\": 1\n    }\n}\n</code></pre>\n<p><strong>UNIX-Socket Connection:</strong></p>\n<pre><code>REDO_QUEUE_DBS = {\n    \"default\": {\n        \"DB\": 0,\n        \"PASSWORD\": \"******\",\n        \"USOCK\": \"/tmp/redis.sock\",\n        \"THREADS\": 1\n    }\n}\n</code></pre>\n<h2>Using different queues</h2>\n<p>Django ReDo allows you to use as many queues as you want. To make it possible, you need\nto configure few more queues at <strong>REDO_QUEUE_DBS</strong>.</p>\n<p><strong>For example</strong></p>\n<pre><code>REDO_QUEUE_DBS = {\n    \"fast\": {\n        \"DB\": 0,\n        \"PASSWORD\": \"******\",\n        \"USOCK\": \"/tmp/redis.sock\",\n        \"THREADS\": 1\n    },\n    \"long\": {\n        \"DB\": 1,\n        \"PASSWORD\": \"******\",\n        \"USOCK\": \"/tmp/redis.sock\",\n        \"THREADS\": 2\n    },\n    \"default\": {\n        \"DB\": 0,\n        \"PASSWORD\": \"******\",\n        \"HOST\": \"127.0.0.1\",\n        \"PORT\": 6379,\n        \"THREADS\": 1\n    }\n}\n</code></pre>\n<p>As you understand, you need to run specific workers for each queue.</p>\n<pre><code>python manage.py redo --thread 1 --queue long\npython manage.py redo --thread 2 --queue long\npython manage.py redo --thread 1 --queue fast\npython manage.py redo --thread 1\n</code></pre>\n<p>Last row runs default queue worker. And to schedule any task to specific queue -\nsimply provide it to <strong>define</strong> decorator:</p>\n<pre><code>from django_redo import task\n\n# Registering new task to specific queue\n@task.define('long')\ndef some_async_function(hello):\n    # some code...\n    print(f'Hello {hello}')\n</code></pre>\n<h2>Multi-threads example</h2>\n<p>If you have a lot of heavy tasks which will be scheduled and should be executed as parallel\nas it's possible - you just need to update <strong>THREADS</strong> option for your specific redis database\nand run same number of workers.</p>\n<pre><code>REDO_QUEUE_DBS = {\n    \"default\": {\n        \"DB\": 0,\n        \"PASSWORD\": \"******\",\n        \"HOST\": \"127.0.0.1\",\n        \"PORT\": 6379,\n        \"THREADS\": 4\n    }\n}\n</code></pre>\n<p>And 4 workers for the 4 threads:</p>\n<pre><code>python manage.py redo --thread 1 --queue default\npython manage.py redo --thread 2 --queue default\npython manage.py redo --thread 3 --queue default\npython manage.py redo --thread 4 --queue default\n</code></pre>\n\n          </div>"}, "last_serial": 4343388, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "7292220460d7a0072dec395b4b5af984", "sha256": "86b5fafcbe6784a15a55edf9da8f2e17cc209d5dd1bc1119a048ff6236b7bb14"}, "downloads": -1, "filename": "Django ReDo-0.1.linux-x86_64.tar.gz", "has_sig": false, "md5_digest": "7292220460d7a0072dec395b4b5af984", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8899, "upload_time": "2018-10-05T09:05:46", "upload_time_iso_8601": "2018-10-05T09:05:46.318445Z", "url": "https://files.pythonhosted.org/packages/bf/5f/dbb25bf8f8d44cbb6950a09f20515dfdc7c5981608b0ada5126f590915cd/Django%20ReDo-0.1.linux-x86_64.tar.gz", "yanked": false}], "0.1a0": [{"comment_text": "", "digests": {"md5": "f356fa9b865b8982f3821d7986cfe110", "sha256": "9111c7b6caff848db20c8b97869552afb2193e118e169b71564db3ab6c22e657"}, "downloads": -1, "filename": "Django ReDo-0.1a0.linux-x86_64.tar.gz", "has_sig": false, "md5_digest": "f356fa9b865b8982f3821d7986cfe110", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8891, "upload_time": "2018-10-05T08:56:58", "upload_time_iso_8601": "2018-10-05T08:56:58.349504Z", "url": "https://files.pythonhosted.org/packages/e1/01/10660ec0976044f5bf0022c90813ca92a5a14f160486f37d5119d9765c8c/Django%20ReDo-0.1a0.linux-x86_64.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "dad89363a9aa3733adacc1d39956d1e0", "sha256": "2279095ca7b2743b41bea9fb28da00a0f8bc8c31aa4fe5564259165a2579dc96"}, "downloads": -1, "filename": "Django ReDo-0.2.linux-x86_64.tar.gz", "has_sig": false, "md5_digest": "dad89363a9aa3733adacc1d39956d1e0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8986, "upload_time": "2018-10-05T09:10:32", "upload_time_iso_8601": "2018-10-05T09:10:32.015967Z", "url": "https://files.pythonhosted.org/packages/d4/e8/ff3644b6abd4e4d49961dc7c565aced692084549a939c27b1e8c04fe4a94/Django%20ReDo-0.2.linux-x86_64.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dad89363a9aa3733adacc1d39956d1e0", "sha256": "2279095ca7b2743b41bea9fb28da00a0f8bc8c31aa4fe5564259165a2579dc96"}, "downloads": -1, "filename": "Django ReDo-0.2.linux-x86_64.tar.gz", "has_sig": false, "md5_digest": "dad89363a9aa3733adacc1d39956d1e0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8986, "upload_time": "2018-10-05T09:10:32", "upload_time_iso_8601": "2018-10-05T09:10:32.015967Z", "url": "https://files.pythonhosted.org/packages/d4/e8/ff3644b6abd4e4d49961dc7c565aced692084549a939c27b1e8c04fe4a94/Django%20ReDo-0.2.linux-x86_64.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:54:20 2020"}