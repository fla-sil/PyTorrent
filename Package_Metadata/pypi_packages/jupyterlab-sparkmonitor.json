{"info": {"author": "Krishnan R", "author_email": "krishnanr1997@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Spark Monitor - An extension for Jupyter Lab\n\nThis project was originally written by krishnan-r as a Google Summer of Code project for Jupyter Notebook. [Check his website out here.](https://krishnan-r.github.io/sparkmonitor/) \n\nAs a part of my internship as a Software Engineer at Yelp, I created this fork to update the extension to be compatible with JupyterLab - Yelp's choice for sharing and collaborating on notebooks.\n\n## About\n\n<table>\n<tr>\n<td><a href=\"http://jupyter.org/\"><img src=\"https://user-images.githubusercontent.com/6822941/29750386-872556fe-8b5c-11e7-95e1-42b12d709017.png\" height=\"50\"/></a></td>\n<td><b>+</b></td>\n<td><a href=\"https://spark.apache.org/\"><img src=\"https://user-images.githubusercontent.com/6822941/29750352-e9807b36-8b5b-11e7-929a-249f56c7cf79.png\" height=\"80\"/></a></td>\n<td><b>=</b></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601568-d5e42934-87f9-11e7-9780-3cd3a0d8d86b.png\" title=\"The SparkMonitor Extension.\"><img src=\"https://user-images.githubusercontent.com/6822941/29601568-d5e42934-87f9-11e7-9780-3cd3a0d8d86b.png\" height=\"80\"/></a></td>\n</tr>\n</table>\nSparkMonitor is an extension for Jupyter Lab that enables the live monitoring of Apache Spark Jobs spawned from a notebook. The extension provides several features to monitor and debug a Spark job from within the notebook interface itself. <br>\n\n---\n\n![jobdisplay](https://user-images.githubusercontent.com/6822941/29753710-ff8849b6-8b94-11e7-8f9c-bdc59bf72143.gif)\n\n## Features\n\n- Automatically displays a live monitoring tool below cells that run Spark jobs in a Jupyter notebook\n- A table of jobs and stages with progressbars\n- A timeline which shows jobs, stages, and tasks\n- A graph showing number of active tasks & executor cores vs time\n- A notebook server extension that proxies the Spark UI and displays it in an iframe popup for more details\n- For a detailed list of features see the use case [notebooks](https://krishnan-r.github.io/sparkmonitor/#common-use-cases-and-tests)\n- [How it Works](https://krishnan-r.github.io/sparkmonitor/how.html)\n\n<table>\n<tr>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601990-d6256a1e-87fb-11e7-94cb-b4418c61d221.png\" title=\"Jobs and stages started from a cell.\"><img src=\"https://user-images.githubusercontent.com/6822941/29601990-d6256a1e-87fb-11e7-94cb-b4418c61d221.png\"></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601769-d8e82a26-87fa-11e7-9b0e-91b1414e7821.png\" title=\"A graph of the number of active tasks and available executor cores.\"><img src=\"https://user-images.githubusercontent.com/6822941/29601769-d8e82a26-87fa-11e7-9b0e-91b1414e7821.png\" ></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601776-d919dae4-87fa-11e7-8939-a6c0d0072d90.png\" title=\"An event timeline with jobs, stages and tasks across various executors. The tasks are split into various coloured phases, providing insight into the nature of computation.\"><img src=\"https://user-images.githubusercontent.com/6822941/29601776-d919dae4-87fa-11e7-8939-a6c0d0072d90.png\"></a></td>\n</tr>\n<tr>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29750236-be1f6b0c-8b59-11e7-9a36-92e04e3bf05b.png\" title=\"The Spark web UI as a popup within the notebook interface.\"><img src=\"https://user-images.githubusercontent.com/6822941/29750236-be1f6b0c-8b59-11e7-9a36-92e04e3bf05b.png\" ></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29750177-ea2c18b8-8b58-11e7-955e-69ecf33a6284.png\" title=\"Details of a task.\"><img src=\"https://user-images.githubusercontent.com/6822941/29750177-ea2c18b8-8b58-11e7-955e-69ecf33a6284.png\" ></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601997-d6533840-87fb-11e7-90ce-daa0fe73b9e5.png\" title=\"An event timeline.\"><img src=\"https://user-images.githubusercontent.com/6822941/29601997-d6533840-87fb-11e7-90ce-daa0fe73b9e5.png\"></a></td>\n</tr>\n</table>\n\n## Quick Start\n\n### To do a quick test of the extension\nThis docker image has pyspark and several other related packages installed alongside the sparkmonitor extension.\n```bash\ndocker run -it -p 8888:8888 itsjafer/sparkmonitor\n```\n\n### Setting up the extension \n```bash\njupyter labextension install jupyterlab_sparkmonitor # install the jupyterlab extension\npip install jupyterlab-sparkmonitor # install the server/kernel extension\njupyter serverextension enable --py sparkmonitor\n\n# set up ipython profile and add our kernel extension to it\nipython profile create --ipython-dir=.ipython\necho \"c.InteractiveShellApp.extensions.append('sparkmonitor.kernelextension')\" >>  .ipython/profile_default/ipython_config.py\n\n# run jupyter lab\nIPYTHONDIR=.ipython jupyter lab --watch \n```\n\nWith the extension installed, a SparkConf object called `conf` will be usable from your notebooks. You can use it as follows:\n\n```python\nfrom pyspark import SparkContext\n\n# start the spark context using the SparkConf the extension inserted\nsc=SparkContext.getOrCreate(conf=conf) #Start the spark context\n\n# Monitor should spawn under the cell with 4 jobs\nsc.parallelize(range(0,100)).count()\nsc.parallelize(range(0,100)).count()\nsc.parallelize(range(0,100)).count()\nsc.parallelize(range(0,100)).count()\n```\n\nIf you already have your own spark configuration, you will need to set `spark.extraListeners` to `sparkmonitor.listener.JupyterSparkMonitorListener` and `spark.driver.extraClassPath` to the path to the sparkmonitor python package `path/to/package/sparkmonitor/listener.jar`\n```python\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder\\\n        .config('spark.extraListeners', 'sparkmonitor.listener.JupyterSparkMonitorListener')\\\n        .config('spark.driver.extraClassPath', 'venv/lib/python3.7/site-packages/sparkmonitor/listener.jar')\\\n        .getOrCreate()\n\n# should spawn 4 jobs in a monitor bnelow the cell\nspark.sparkContext.parallelize(range(0,100)).count()\nspark.sparkContext.parallelize(range(0,100)).count()\nspark.sparkContext.parallelize(range(0,100)).count()\nspark.sparkContext.parallelize(range(0,100)).count()\n```\n\n\n## Development\n\nIf you'd like to develop the extension:\n\n```bash\nmake venv # Creates a virtual environment using tox \nsource venv/bin/activate # Make sure we're using the virtual environment\nmake build # Build the extension\nmake develop # Run a local jupyterlab with the extension installed\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/itsjafer/jupyterlab-sparkmonitor", "keywords": "", "license": "", "maintainer": "itsjafer", "maintainer_email": "itsjafer@gmail.com", "name": "jupyterlab-sparkmonitor", "package_url": "https://pypi.org/project/jupyterlab-sparkmonitor/", "platform": "", "project_url": "https://pypi.org/project/jupyterlab-sparkmonitor/", "project_urls": {"Homepage": "https://github.com/itsjafer/jupyterlab-sparkmonitor"}, "release_url": "https://pypi.org/project/jupyterlab-sparkmonitor/1.1.0/", "requires_dist": null, "requires_python": "", "summary": "Spark Monitor Extension for Jupyter Lab", "version": "1.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Spark Monitor - An extension for Jupyter Lab</h1>\n<p>This project was originally written by krishnan-r as a Google Summer of Code project for Jupyter Notebook. <a href=\"https://krishnan-r.github.io/sparkmonitor/\" rel=\"nofollow\">Check his website out here.</a></p>\n<p>As a part of my internship as a Software Engineer at Yelp, I created this fork to update the extension to be compatible with JupyterLab - Yelp's choice for sharing and collaborating on notebooks.</p>\n<h2>About</h2>\n<table>\n<tr>\n<td><a href=\"http://jupyter.org/\" rel=\"nofollow\"><img height=\"50\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ee64ad27ed0e6343b35c2fe63c46e717642a3366/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393735303338362d38373235353666652d386235632d313165372d393565312d3432623132643730393031372e706e67\"></a></td>\n<td><b>+</b></td>\n<td><a href=\"https://spark.apache.org/\" rel=\"nofollow\"><img height=\"80\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/be91f66ff42658b9a0a91ddedf5b83cdb2a316de/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393735303335322d65393830376233362d386235622d313165372d393239612d3234396635366337636637392e706e67\"></a></td>\n<td><b>=</b></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601568-d5e42934-87f9-11e7-9780-3cd3a0d8d86b.png\" rel=\"nofollow\" title=\"The SparkMonitor Extension.\"><img height=\"80\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/81ea4ac26e392056e8252dd7101ecb0eaecc3df9/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393630313536382d64356534323933342d383766392d313165372d393738302d3363643361306438643836622e706e67\"></a></td>\n</tr>\n</table>\nSparkMonitor is an extension for Jupyter Lab that enables the live monitoring of Apache Spark Jobs spawned from a notebook. The extension provides several features to monitor and debug a Spark job from within the notebook interface itself. <br>\n<hr>\n<p><img alt=\"jobdisplay\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/336a622f7044906c0958c0d341f72b90c18b9600/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393735333731302d66663838343962362d386239342d313165372d386639632d6264633539626637323134332e676966\"></p>\n<h2>Features</h2>\n<ul>\n<li>Automatically displays a live monitoring tool below cells that run Spark jobs in a Jupyter notebook</li>\n<li>A table of jobs and stages with progressbars</li>\n<li>A timeline which shows jobs, stages, and tasks</li>\n<li>A graph showing number of active tasks &amp; executor cores vs time</li>\n<li>A notebook server extension that proxies the Spark UI and displays it in an iframe popup for more details</li>\n<li>For a detailed list of features see the use case <a href=\"https://krishnan-r.github.io/sparkmonitor/#common-use-cases-and-tests\" rel=\"nofollow\">notebooks</a></li>\n<li><a href=\"https://krishnan-r.github.io/sparkmonitor/how.html\" rel=\"nofollow\">How it Works</a></li>\n</ul>\n<table>\n<tr>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601990-d6256a1e-87fb-11e7-94cb-b4418c61d221.png\" rel=\"nofollow\" title=\"Jobs and stages started from a cell.\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b5dae3ddcee4e20252e014f74a0811995fe64843/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393630313939302d64363235366131652d383766622d313165372d393463622d6234343138633631643232312e706e67\"></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601769-d8e82a26-87fa-11e7-9b0e-91b1414e7821.png\" rel=\"nofollow\" title=\"A graph of the number of active tasks and available executor cores.\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/45c001b70704c4e421bdb5e27f9cd952b2e79c32/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393630313736392d64386538326132362d383766612d313165372d396230652d3931623134313465373832312e706e67\"></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601776-d919dae4-87fa-11e7-8939-a6c0d0072d90.png\" rel=\"nofollow\" title=\"An event timeline with jobs, stages and tasks across various executors. The tasks are split into various coloured phases, providing insight into the nature of computation.\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/338c8289c89cd7f69dbb002914f8130c78927c88/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393630313737362d64393139646165342d383766612d313165372d383933392d6136633064303037326439302e706e67\"></a></td>\n</tr>\n<tr>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29750236-be1f6b0c-8b59-11e7-9a36-92e04e3bf05b.png\" rel=\"nofollow\" title=\"The Spark web UI as a popup within the notebook interface.\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e27c58ea5c85699906d6826581a2f63f62e302c1/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393735303233362d62653166366230632d386235392d313165372d396133362d3932653034653362663035622e706e67\"></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29750177-ea2c18b8-8b58-11e7-955e-69ecf33a6284.png\" rel=\"nofollow\" title=\"Details of a task.\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/97e9435b9b7b0861441790ed111e57534f55b155/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393735303137372d65613263313862382d386235382d313165372d393535652d3639656366333361363238342e706e67\"></a></td>\n<td><a href=\"https://user-images.githubusercontent.com/6822941/29601997-d6533840-87fb-11e7-90ce-daa0fe73b9e5.png\" rel=\"nofollow\" title=\"An event timeline.\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d8c44ffccd379748de99ece4b6fedb028e7a7cca/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363832323934312f32393630313939372d64363533333834302d383766622d313165372d393063652d6461613066653733623965352e706e67\"></a></td>\n</tr>\n</table>\n<h2>Quick Start</h2>\n<h3>To do a quick test of the extension</h3>\n<p>This docker image has pyspark and several other related packages installed alongside the sparkmonitor extension.</p>\n<pre>docker run -it -p <span class=\"m\">8888</span>:8888 itsjafer/sparkmonitor\n</pre>\n<h3>Setting up the extension</h3>\n<pre>jupyter labextension install jupyterlab_sparkmonitor <span class=\"c1\"># install the jupyterlab extension</span>\npip install jupyterlab-sparkmonitor <span class=\"c1\"># install the server/kernel extension</span>\njupyter serverextension <span class=\"nb\">enable</span> --py sparkmonitor\n\n<span class=\"c1\"># set up ipython profile and add our kernel extension to it</span>\nipython profile create --ipython-dir<span class=\"o\">=</span>.ipython\n<span class=\"nb\">echo</span> <span class=\"s2\">\"c.InteractiveShellApp.extensions.append('sparkmonitor.kernelextension')\"</span> &gt;&gt;  .ipython/profile_default/ipython_config.py\n\n<span class=\"c1\"># run jupyter lab</span>\n<span class=\"nv\">IPYTHONDIR</span><span class=\"o\">=</span>.ipython jupyter lab --watch \n</pre>\n<p>With the extension installed, a SparkConf object called <code>conf</code> will be usable from your notebooks. You can use it as follows:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pyspark</span> <span class=\"kn\">import</span> <span class=\"n\">SparkContext</span>\n\n<span class=\"c1\"># start the spark context using the SparkConf the extension inserted</span>\n<span class=\"n\">sc</span><span class=\"o\">=</span><span class=\"n\">SparkContext</span><span class=\"o\">.</span><span class=\"n\">getOrCreate</span><span class=\"p\">(</span><span class=\"n\">conf</span><span class=\"o\">=</span><span class=\"n\">conf</span><span class=\"p\">)</span> <span class=\"c1\">#Start the spark context</span>\n\n<span class=\"c1\"># Monitor should spawn under the cell with 4 jobs</span>\n<span class=\"n\">sc</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n<span class=\"n\">sc</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n<span class=\"n\">sc</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n<span class=\"n\">sc</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n</pre>\n<p>If you already have your own spark configuration, you will need to set <code>spark.extraListeners</code> to <code>sparkmonitor.listener.JupyterSparkMonitorListener</code> and <code>spark.driver.extraClassPath</code> to the path to the sparkmonitor python package <code>path/to/package/sparkmonitor/listener.jar</code></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pyspark.sql</span> <span class=\"kn\">import</span> <span class=\"n\">SparkSession</span>\n<span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">SparkSession</span><span class=\"o\">.</span><span class=\"n\">builder</span>\\\n        <span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">(</span><span class=\"s1\">'spark.extraListeners'</span><span class=\"p\">,</span> <span class=\"s1\">'sparkmonitor.listener.JupyterSparkMonitorListener'</span><span class=\"p\">)</span>\\\n        <span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">(</span><span class=\"s1\">'spark.driver.extraClassPath'</span><span class=\"p\">,</span> <span class=\"s1\">'venv/lib/python3.7/site-packages/sparkmonitor/listener.jar'</span><span class=\"p\">)</span>\\\n        <span class=\"o\">.</span><span class=\"n\">getOrCreate</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># should spawn 4 jobs in a monitor bnelow the cell</span>\n<span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">sparkContext</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n<span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">sparkContext</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n<span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">sparkContext</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n<span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">sparkContext</span><span class=\"o\">.</span><span class=\"n\">parallelize</span><span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">()</span>\n</pre>\n<h2>Development</h2>\n<p>If you'd like to develop the extension:</p>\n<pre>make venv <span class=\"c1\"># Creates a virtual environment using tox </span>\n<span class=\"nb\">source</span> venv/bin/activate <span class=\"c1\"># Make sure we're using the virtual environment</span>\nmake build <span class=\"c1\"># Build the extension</span>\nmake develop <span class=\"c1\"># Run a local jupyterlab with the extension installed</span>\n</pre>\n\n          </div>"}, "last_serial": 7126065, "releases": {"0.0.4": [{"comment_text": "", "digests": {"md5": "b4afb460cea23a5983abf0b00ab278dc", "sha256": "0ea194dc6994decb0682feec16f57c4f2dd4793c7bcbde944686df17ee01f11a"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-0.0.4.tar.gz", "has_sig": false, "md5_digest": "b4afb460cea23a5983abf0b00ab278dc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4422683, "upload_time": "2020-04-21T21:03:57", "upload_time_iso_8601": "2020-04-21T21:03:57.675154Z", "url": "https://files.pythonhosted.org/packages/80/04/9b7ba7f572e0844bb29574803a67490d8aa0cff8a66eeae2d733a315a119/jupyterlab-sparkmonitor-0.0.4.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "abef8a05862e1d58d112ad27d1d0f887", "sha256": "963eb798ef04584c53b8be60957f9c93aa308dddd84d53d62db599cada08fe41"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.0.0.tar.gz", "has_sig": false, "md5_digest": "abef8a05862e1d58d112ad27d1d0f887", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 181632, "upload_time": "2020-04-22T02:07:38", "upload_time_iso_8601": "2020-04-22T02:07:38.432507Z", "url": "https://files.pythonhosted.org/packages/ff/27/1689fb21e2b6105e7d295b4c13473e8b414051fe01a435cf7d95d1f034f7/jupyterlab-sparkmonitor-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "6180655d63b86c114d22a6f00a993a19", "sha256": "25fba6d44d259726bec8c57999a2741af6c1929b107b5b82d81369e4559e2537"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.0.1.tar.gz", "has_sig": false, "md5_digest": "6180655d63b86c114d22a6f00a993a19", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 181622, "upload_time": "2020-04-22T02:42:28", "upload_time_iso_8601": "2020-04-22T02:42:28.774078Z", "url": "https://files.pythonhosted.org/packages/4d/a5/47f3907d38408fe61f2bed81865b79fb962bfd83a2e1e1677f5881df3016/jupyterlab-sparkmonitor-1.0.1.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "e12d97451ce8d2041d869af6ac09d0b0", "sha256": "dad6f7308eaca7cd8711329b759c45fab07eef9e14d37eda8cb49585d8a5837a"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.0.3.tar.gz", "has_sig": false, "md5_digest": "e12d97451ce8d2041d869af6ac09d0b0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 184602, "upload_time": "2020-04-24T09:52:38", "upload_time_iso_8601": "2020-04-24T09:52:38.206695Z", "url": "https://files.pythonhosted.org/packages/28/bf/cfb6e92116c534e34dc19ca907d8dabd4cdfe1296eaed64aabe3a36caa66/jupyterlab-sparkmonitor-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "7aed58fbde92aa6100a43926092f1354", "sha256": "88c801bfc5b3bda7a9209f01433a2c155e12bc0fb38a49a859d42d7bed638174"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.0.4.tar.gz", "has_sig": false, "md5_digest": "7aed58fbde92aa6100a43926092f1354", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 185195, "upload_time": "2020-04-24T09:55:04", "upload_time_iso_8601": "2020-04-24T09:55:04.708458Z", "url": "https://files.pythonhosted.org/packages/b2/7c/8c672a15470a93864a946d87d61410e8e1787283d823f657b162b6e45410/jupyterlab-sparkmonitor-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "1f72f5a3b31e3a20b57b66cec293c4c1", "sha256": "b82131651f9faae134f6db29797438197a76e71bdf7beb1873f2f8725a8b8afe"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.0.5.tar.gz", "has_sig": false, "md5_digest": "1f72f5a3b31e3a20b57b66cec293c4c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 185193, "upload_time": "2020-04-24T09:57:50", "upload_time_iso_8601": "2020-04-24T09:57:50.072032Z", "url": "https://files.pythonhosted.org/packages/17/e3/38d17cc4a3a79264fbe7a50609b3ef5bb4cd69fb758f78d956a919a62f6b/jupyterlab-sparkmonitor-1.0.5.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "67aef289ee22dba47c4675b5972710ff", "sha256": "fe3a27a8c1fb92adb4db0235890ada4d700e3d9edb4a168e6d6e09570c56ab6f"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.1.0.tar.gz", "has_sig": false, "md5_digest": "67aef289ee22dba47c4675b5972710ff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 185192, "upload_time": "2020-04-29T05:23:29", "upload_time_iso_8601": "2020-04-29T05:23:29.432918Z", "url": "https://files.pythonhosted.org/packages/8d/24/0966b836f89651a60537a6aa0207a4817fce56ef46992e867bed7c8b8b1b/jupyterlab-sparkmonitor-1.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "67aef289ee22dba47c4675b5972710ff", "sha256": "fe3a27a8c1fb92adb4db0235890ada4d700e3d9edb4a168e6d6e09570c56ab6f"}, "downloads": -1, "filename": "jupyterlab-sparkmonitor-1.1.0.tar.gz", "has_sig": false, "md5_digest": "67aef289ee22dba47c4675b5972710ff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 185192, "upload_time": "2020-04-29T05:23:29", "upload_time_iso_8601": "2020-04-29T05:23:29.432918Z", "url": "https://files.pythonhosted.org/packages/8d/24/0966b836f89651a60537a6aa0207a4817fce56ef46992e867bed7c8b8b1b/jupyterlab-sparkmonitor-1.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:11 2020"}