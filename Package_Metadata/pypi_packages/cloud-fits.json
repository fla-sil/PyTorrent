{"info": {"author": "Joe Curtin <42@jbcurtin.io", "author_email": "cloud-fits@jbcurtin.io", "bugtrack_url": null, "classifiers": ["Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3 :: Only"], "description": "# Cloud Optimized Fits\n\n`cloud-fits` provides the means to index large FITS files and have them served over HTTP for efficient access. A \nscientist or team can index the FITS file-directory, then upload the file-directory to A Static Cloud Provider. Static\nCloud Providers are Amazon WebServices, Google Cloud, Digital Ocean Spaces, or Microsoft Blob Storage. The FITS Cloud\nIndex can than be checked into a Github Repository, shared, or uploaded to a Static Cloud Provider\n\n`cloud-fits` returns Astropy Datatypes as much as possible\n\n\n## Lets index a few FITS files and extract Metadata from them\n\n### Accessing Data\nRegistry of Open Data on AWS provides a bucket called `stpubdata`. It contains data uploaded from the [Transiting \nExoplanet Survey Satellite](https://tess.mit.edu/). The type of data files we'll be working with in this tutorial are\nabout 44GB. It'll cost about $1.05 to download and index one of these 352 files from the Registry. To save time and\nmoney, we'll only download one and index it\n\n### Prerequisite\n\nBefore we can download data off the Registry. Setup an AWS account and configure your credentials file. Then install\n`aws-cli`\n\n* https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/\n* https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\n* https://pypi.org/project/awscli/\n\n### Tutorial\n\nLets create our environment and download one data-file from the Registry\n\n```\n$ mkdir -p /tmp/tess-data\n$ cd /tmp/tess-data\n$ aws s3 cp s3://stpubdata/tess/public/mast/ . --recursive --exclude \"*\" --include \"tess-s0022-4-4-cube.fits\" --request-payer\n```\n\nWith our data downloaded, its time to create a bucket that'll hold our FITS Cloud Index. In some cases, we might not\nhave write access to the data we're indexing. In this case, we want to generate the index from a public data-set. Then\nwell store the index in a Static Cloud Provider of our choosing. `cloud-fits` can then provide a Pythonic API\naugmenting this abstraction\n\nLets create a bucket on AWS S3 and upload the index there\n\n```\n$ AWS_DEFAULT_REGION=us-east-1 aws s3api create-bucket --bucket tess-fits-cloud-index\n$ pip install cloud-fits -U\n$ cloud-fits-index --index-bucket-name tess-fits-cloud-index --fits-files-directory /tmp/tess-data/ --data-bucket-path s3://stpubdata/tess/public/mast\n```\n\nThe arguments `--index-bucket-name` and `--fits-file-directory` are intended to be straight forward with the naming. \n`--data-bucket-path` is used to arugment the file-structure difference between `--fits-file-directory` and `--data-bucket-path`. \nFor example, the data-cubes are located in `tess/public/mast`, but this data isn't captured in `--fits-file-directory`. So,\n`--data-bucket-path` was introduced to augment the paths used to download sections of the file\n\nOkay, great. We have everything we need. Now lets do some science. Start python and enter the following,\n\n```\nfrom cloud_fits.bucket_operations import download_index\nfrom cloud_fits.datatypes import FitsCloudIndex\n\nfrom pprint import pprint\n\nBUCKET_NAME: str = 'tess-fits-cloud-index'\n\nindex: FitsCloudIndex = download_index(BUCKET_NAME)\nbintable_index = index.headers[2]\nprint(bintable_index[0, 10])\n```\n\n### Feature Map\n\n* Amazon Web Services S3\n* Pythonic API Refinement ( Planned Update )\n* Remote Indexing for all Static Cloud Providers ( Planned Support )\n* Digital Ocean Spaces ( Planned Support )\n* Google Object Storage ( Planned Support )\n* Microsoft Azure ( Planned Support )\n\n\n## Development and Deployment\n\n### Building Docs Locally\n\n`build.sh` has a script that'll generate docs locally into `/tmp/docs`. The static HTML files can then be served from\nthat directory using these commands\n\n```\n$ bash build.sh docs\n$ cd /tmp/docs\n$ python3 -m http.server\n```\n\n### PYPI Automation\n\n`build.sh` has a script that'll generate the python wheel, sdist, and associated files. Then it'll upload it to\nPYPI or PYPI-Test according to how you invoke the `build.sh` file\n\n```\n$ bash build.sh publish-test\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jbcurtin/cloud-fits", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "cloud-fits", "package_url": "https://pypi.org/project/cloud-fits/", "platform": "", "project_url": "https://pypi.org/project/cloud-fits/", "project_urls": {"Homepage": "https://github.com/jbcurtin/cloud-fits"}, "release_url": "https://pypi.org/project/cloud-fits/0.1.0/", "requires_dist": ["requests (==2.23.0)", "PyYAML (==5.1.2)", "numpy (==1.18.2)", "astropy (==4.0.1.post1)"], "requires_python": ">=3.6", "summary": "Cloud Optimized Fits", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Cloud Optimized Fits</h1>\n<p><code>cloud-fits</code> provides the means to index large FITS files and have them served over HTTP for efficient access. A\nscientist or team can index the FITS file-directory, then upload the file-directory to A Static Cloud Provider. Static\nCloud Providers are Amazon WebServices, Google Cloud, Digital Ocean Spaces, or Microsoft Blob Storage. The FITS Cloud\nIndex can than be checked into a Github Repository, shared, or uploaded to a Static Cloud Provider</p>\n<p><code>cloud-fits</code> returns Astropy Datatypes as much as possible</p>\n<h2>Lets index a few FITS files and extract Metadata from them</h2>\n<h3>Accessing Data</h3>\n<p>Registry of Open Data on AWS provides a bucket called <code>stpubdata</code>. It contains data uploaded from the <a href=\"https://tess.mit.edu/\" rel=\"nofollow\">Transiting\nExoplanet Survey Satellite</a>. The type of data files we'll be working with in this tutorial are\nabout 44GB. It'll cost about $1.05 to download and index one of these 352 files from the Registry. To save time and\nmoney, we'll only download one and index it</p>\n<h3>Prerequisite</h3>\n<p>Before we can download data off the Registry. Setup an AWS account and configure your credentials file. Then install\n<code>aws-cli</code></p>\n<ul>\n<li><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/\" rel=\"nofollow\">https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/</a></li>\n<li><a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\" rel=\"nofollow\">https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html</a></li>\n<li><a href=\"https://pypi.org/project/awscli/\" rel=\"nofollow\">https://pypi.org/project/awscli/</a></li>\n</ul>\n<h3>Tutorial</h3>\n<p>Lets create our environment and download one data-file from the Registry</p>\n<pre><code>$ mkdir -p /tmp/tess-data\n$ cd /tmp/tess-data\n$ aws s3 cp s3://stpubdata/tess/public/mast/ . --recursive --exclude \"*\" --include \"tess-s0022-4-4-cube.fits\" --request-payer\n</code></pre>\n<p>With our data downloaded, its time to create a bucket that'll hold our FITS Cloud Index. In some cases, we might not\nhave write access to the data we're indexing. In this case, we want to generate the index from a public data-set. Then\nwell store the index in a Static Cloud Provider of our choosing. <code>cloud-fits</code> can then provide a Pythonic API\naugmenting this abstraction</p>\n<p>Lets create a bucket on AWS S3 and upload the index there</p>\n<pre><code>$ AWS_DEFAULT_REGION=us-east-1 aws s3api create-bucket --bucket tess-fits-cloud-index\n$ pip install cloud-fits -U\n$ cloud-fits-index --index-bucket-name tess-fits-cloud-index --fits-files-directory /tmp/tess-data/ --data-bucket-path s3://stpubdata/tess/public/mast\n</code></pre>\n<p>The arguments <code>--index-bucket-name</code> and <code>--fits-file-directory</code> are intended to be straight forward with the naming.\n<code>--data-bucket-path</code> is used to arugment the file-structure difference between <code>--fits-file-directory</code> and <code>--data-bucket-path</code>.\nFor example, the data-cubes are located in <code>tess/public/mast</code>, but this data isn't captured in <code>--fits-file-directory</code>. So,\n<code>--data-bucket-path</code> was introduced to augment the paths used to download sections of the file</p>\n<p>Okay, great. We have everything we need. Now lets do some science. Start python and enter the following,</p>\n<pre><code>from cloud_fits.bucket_operations import download_index\nfrom cloud_fits.datatypes import FitsCloudIndex\n\nfrom pprint import pprint\n\nBUCKET_NAME: str = 'tess-fits-cloud-index'\n\nindex: FitsCloudIndex = download_index(BUCKET_NAME)\nbintable_index = index.headers[2]\nprint(bintable_index[0, 10])\n</code></pre>\n<h3>Feature Map</h3>\n<ul>\n<li>Amazon Web Services S3</li>\n<li>Pythonic API Refinement ( Planned Update )</li>\n<li>Remote Indexing for all Static Cloud Providers ( Planned Support )</li>\n<li>Digital Ocean Spaces ( Planned Support )</li>\n<li>Google Object Storage ( Planned Support )</li>\n<li>Microsoft Azure ( Planned Support )</li>\n</ul>\n<h2>Development and Deployment</h2>\n<h3>Building Docs Locally</h3>\n<p><code>build.sh</code> has a script that'll generate docs locally into <code>/tmp/docs</code>. The static HTML files can then be served from\nthat directory using these commands</p>\n<pre><code>$ bash build.sh docs\n$ cd /tmp/docs\n$ python3 -m http.server\n</code></pre>\n<h3>PYPI Automation</h3>\n<p><code>build.sh</code> has a script that'll generate the python wheel, sdist, and associated files. Then it'll upload it to\nPYPI or PYPI-Test according to how you invoke the <code>build.sh</code> file</p>\n<pre><code>$ bash build.sh publish-test\n</code></pre>\n\n          </div>"}, "last_serial": 7050162, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "9a3c80669db16da9b40963345f441377", "sha256": "a34c1c7e0eef4c4e7f415a0fbde3fe3c3c80330740792805348131bbf36249ad"}, "downloads": -1, "filename": "cloud_fits-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9a3c80669db16da9b40963345f441377", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 12837, "upload_time": "2020-04-18T21:12:05", "upload_time_iso_8601": "2020-04-18T21:12:05.954064Z", "url": "https://files.pythonhosted.org/packages/76/b3/515d702560046eb78a74c1f01b27621a856765ea6ba14581bcce03183298/cloud_fits-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8fe1fcc1741f9b0a7e6d126b231877da", "sha256": "f3d74a72bc945e1e8d480bed095d73d67b2caa3bfe5c7ed99ac2931057382fde"}, "downloads": -1, "filename": "cloud-fits-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8fe1fcc1741f9b0a7e6d126b231877da", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15473, "upload_time": "2020-04-18T21:12:08", "upload_time_iso_8601": "2020-04-18T21:12:08.300664Z", "url": "https://files.pythonhosted.org/packages/1b/30/0e33fc911f67c3a7b6176783133b332d8d41a01bdeb4134986c6a00cc034/cloud-fits-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9a3c80669db16da9b40963345f441377", "sha256": "a34c1c7e0eef4c4e7f415a0fbde3fe3c3c80330740792805348131bbf36249ad"}, "downloads": -1, "filename": "cloud_fits-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9a3c80669db16da9b40963345f441377", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6", "size": 12837, "upload_time": "2020-04-18T21:12:05", "upload_time_iso_8601": "2020-04-18T21:12:05.954064Z", "url": "https://files.pythonhosted.org/packages/76/b3/515d702560046eb78a74c1f01b27621a856765ea6ba14581bcce03183298/cloud_fits-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8fe1fcc1741f9b0a7e6d126b231877da", "sha256": "f3d74a72bc945e1e8d480bed095d73d67b2caa3bfe5c7ed99ac2931057382fde"}, "downloads": -1, "filename": "cloud-fits-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8fe1fcc1741f9b0a7e6d126b231877da", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15473, "upload_time": "2020-04-18T21:12:08", "upload_time_iso_8601": "2020-04-18T21:12:08.300664Z", "url": "https://files.pythonhosted.org/packages/1b/30/0e33fc911f67c3a7b6176783133b332d8d41a01bdeb4134986c6a00cc034/cloud-fits-0.1.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:51 2020"}