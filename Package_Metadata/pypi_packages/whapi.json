{"info": {"author": "killhamster", "author_email": "killhamster@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# WHAPI\n\nThe MediaWiki API is complicated and arcane, and can require esoteric knowledge of the MediaWiki software to use it effectively. Worse still, it's mostly obscured on WikiHow, and it's likely they'd rather you didn't know it was there altogether. WikiHow API (WHAPI) aims to simplify this to some degree, providing a Python-based interface to perform some useful functions, such as retrieving article intros, steps, and info. One can use the resulting data to build an app on top of WikiHow, or just to find random useful (or useless, more likely) information on how to do things.\n\nObviously for a lot of these functions you could just go to the website, but what if you need to do weird stuff with the data and don't want to write your own webscraper?\n\n- [Installation](#install)\n- [Usage](#usage)\n  * [Article ID](#article-id)\n  * [Random HowTo](#random-howto)\n  * [Article Details](#article-details)\n  * [Images](#images)\n  * [Search](#search)\n  * [Parsing](#parsing)\n    - [HTML](#html)\n    - [Intro](#intro)\n    - [Steps](#steps)\n- [ToDo](#todo)\n\n\n## Installation\n```bash\npip install whapi\n```\n\n## Usage\n\n### Article ID\n\nEverything useful relies on a numeric article ID. You don't have to see this, but be aware that it's important. If you only have a URL, you can use get_id() to convert it to an article ID that can be passed to other functions.\n\n```python\nfrom whapi import get_id\n\narticle_id = get_id('https://www.wikihow.com/Chug-Water')\n```\n\n### Random HowTo\n\nLearn random stuff! Retuns a random WikiHow article. Sometimes they're weird. Sometimes they're really weird. random_article() returns a randomized article ID that can then be passed to other functions.\n\n```python\nfrom whapi import random_article\n\nrandom_howto = random_article()\n```\n\n### Article Details\n\nUses the article ID to return a URL and title for an article. In addition, it returns whether an article is considered a stub or \"low quality\".\n\n```python\nfrom whapi import return_details\n\narticle_info = return_details(635542)\n```\n\n### Images\n\nRetrieves a list of all images included in an article as URLs.\n\n```python\nfrom whapi import get_images\n\nimage_list = get_images(1097122)\n```\n\n### Search\n\nSearches WikiHow for the a string and returns a list containing dict objects that contain article IDs, titles, and URLs. The default max results is 10, but this can be changed. MediaWiki's limit for this is 500. As for WikiHow, I don't know. You shouldn't need 500 search results anyway.\n\n```python\nfrom whapi import search\n\nsearch_results = search('goth', 5)\n```\n\n### Parsing\n\n#### HTML\n\nAll the parsing functions rely on get_html() to obtain some data to parse and package for you. It uses the article ID to retrieve information.\n\n```python\nfrom whapi import get_html\n\nhtml = get_html(1632)\n```\n\n#### Intro\n\nEvery WikiHow article has an introductory paragraph or two. If you want this, use the parse_intro() function.\n\n```python\nfrom whapi import get_html, parse_intro\n\nhtml = get_html(1946507)\nintro_text = parse_intro(html)\n```\n\n#### Steps\n\nEvery WikiHow article also has a list of steps, and they're chock full of really great stuff. Use parse_steps() to get a dict object that contains dict objects containing the step number, summary, and details.\n\n```python\nfrom whapi import get_html, parse_steps\n\nhtml = get_html(680027)\nsteps = parse_steps(html)\n```\n\n## ToDo\n\n- Many WikiHow articles also contain \"Methods\" which break down further into sub-steps. Write a function to parse these additional divisions.\n- Add parser for tips\n- Add parser for warnings\n- I have code to rotate proxies and user agent strings, but since this no longer scrapes pages, this probably isn't necessary\n- Unordered lists in steps break the parse_steps() function. For now they're ignored, but it would be nice to have them parsed and inserted into the correct step\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/killhamster/WHAPI", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "whapi", "package_url": "https://pypi.org/project/whapi/", "platform": "", "project_url": "https://pypi.org/project/whapi/", "project_urls": {"Homepage": "https://github.com/killhamster/WHAPI"}, "release_url": "https://pypi.org/project/whapi/0.6.2/", "requires_dist": ["requests", "bs4"], "requires_python": "", "summary": "An unofficial WikiHow API wrapper", "version": "0.6.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>WHAPI</h1>\n<p>The MediaWiki API is complicated and arcane, and can require esoteric knowledge of the MediaWiki software to use it effectively. Worse still, it's mostly obscured on WikiHow, and it's likely they'd rather you didn't know it was there altogether. WikiHow API (WHAPI) aims to simplify this to some degree, providing a Python-based interface to perform some useful functions, such as retrieving article intros, steps, and info. One can use the resulting data to build an app on top of WikiHow, or just to find random useful (or useless, more likely) information on how to do things.</p>\n<p>Obviously for a lot of these functions you could just go to the website, but what if you need to do weird stuff with the data and don't want to write your own webscraper?</p>\n<ul>\n<li><a href=\"#install\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#article-id\" rel=\"nofollow\">Article ID</a></li>\n<li><a href=\"#random-howto\" rel=\"nofollow\">Random HowTo</a></li>\n<li><a href=\"#article-details\" rel=\"nofollow\">Article Details</a></li>\n<li><a href=\"#images\" rel=\"nofollow\">Images</a></li>\n<li><a href=\"#search\" rel=\"nofollow\">Search</a></li>\n<li><a href=\"#parsing\" rel=\"nofollow\">Parsing</a>\n<ul>\n<li><a href=\"#html\" rel=\"nofollow\">HTML</a></li>\n<li><a href=\"#intro\" rel=\"nofollow\">Intro</a></li>\n<li><a href=\"#steps\" rel=\"nofollow\">Steps</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#todo\" rel=\"nofollow\">ToDo</a></li>\n</ul>\n<h2>Installation</h2>\n<pre>pip install whapi\n</pre>\n<h2>Usage</h2>\n<h3>Article ID</h3>\n<p>Everything useful relies on a numeric article ID. You don't have to see this, but be aware that it's important. If you only have a URL, you can use get_id() to convert it to an article ID that can be passed to other functions.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">get_id</span>\n\n<span class=\"n\">article_id</span> <span class=\"o\">=</span> <span class=\"n\">get_id</span><span class=\"p\">(</span><span class=\"s1\">'https://www.wikihow.com/Chug-Water'</span><span class=\"p\">)</span>\n</pre>\n<h3>Random HowTo</h3>\n<p>Learn random stuff! Retuns a random WikiHow article. Sometimes they're weird. Sometimes they're really weird. random_article() returns a randomized article ID that can then be passed to other functions.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">random_article</span>\n\n<span class=\"n\">random_howto</span> <span class=\"o\">=</span> <span class=\"n\">random_article</span><span class=\"p\">()</span>\n</pre>\n<h3>Article Details</h3>\n<p>Uses the article ID to return a URL and title for an article. In addition, it returns whether an article is considered a stub or \"low quality\".</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">return_details</span>\n\n<span class=\"n\">article_info</span> <span class=\"o\">=</span> <span class=\"n\">return_details</span><span class=\"p\">(</span><span class=\"mi\">635542</span><span class=\"p\">)</span>\n</pre>\n<h3>Images</h3>\n<p>Retrieves a list of all images included in an article as URLs.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">get_images</span>\n\n<span class=\"n\">image_list</span> <span class=\"o\">=</span> <span class=\"n\">get_images</span><span class=\"p\">(</span><span class=\"mi\">1097122</span><span class=\"p\">)</span>\n</pre>\n<h3>Search</h3>\n<p>Searches WikiHow for the a string and returns a list containing dict objects that contain article IDs, titles, and URLs. The default max results is 10, but this can be changed. MediaWiki's limit for this is 500. As for WikiHow, I don't know. You shouldn't need 500 search results anyway.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">search</span>\n\n<span class=\"n\">search_results</span> <span class=\"o\">=</span> <span class=\"n\">search</span><span class=\"p\">(</span><span class=\"s1\">'goth'</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<h3>Parsing</h3>\n<h4>HTML</h4>\n<p>All the parsing functions rely on get_html() to obtain some data to parse and package for you. It uses the article ID to retrieve information.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">get_html</span>\n\n<span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">get_html</span><span class=\"p\">(</span><span class=\"mi\">1632</span><span class=\"p\">)</span>\n</pre>\n<h4>Intro</h4>\n<p>Every WikiHow article has an introductory paragraph or two. If you want this, use the parse_intro() function.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">get_html</span><span class=\"p\">,</span> <span class=\"n\">parse_intro</span>\n\n<span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">get_html</span><span class=\"p\">(</span><span class=\"mi\">1946507</span><span class=\"p\">)</span>\n<span class=\"n\">intro_text</span> <span class=\"o\">=</span> <span class=\"n\">parse_intro</span><span class=\"p\">(</span><span class=\"n\">html</span><span class=\"p\">)</span>\n</pre>\n<h4>Steps</h4>\n<p>Every WikiHow article also has a list of steps, and they're chock full of really great stuff. Use parse_steps() to get a dict object that contains dict objects containing the step number, summary, and details.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">whapi</span> <span class=\"kn\">import</span> <span class=\"n\">get_html</span><span class=\"p\">,</span> <span class=\"n\">parse_steps</span>\n\n<span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">get_html</span><span class=\"p\">(</span><span class=\"mi\">680027</span><span class=\"p\">)</span>\n<span class=\"n\">steps</span> <span class=\"o\">=</span> <span class=\"n\">parse_steps</span><span class=\"p\">(</span><span class=\"n\">html</span><span class=\"p\">)</span>\n</pre>\n<h2>ToDo</h2>\n<ul>\n<li>Many WikiHow articles also contain \"Methods\" which break down further into sub-steps. Write a function to parse these additional divisions.</li>\n<li>Add parser for tips</li>\n<li>Add parser for warnings</li>\n<li>I have code to rotate proxies and user agent strings, but since this no longer scrapes pages, this probably isn't necessary</li>\n<li>Unordered lists in steps break the parse_steps() function. For now they're ignored, but it would be nice to have them parsed and inserted into the correct step</li>\n</ul>\n\n          </div>"}, "last_serial": 7021082, "releases": {"0.5.3": [{"comment_text": "", "digests": {"md5": "28db917719d7cf5376a1bb41f10664d1", "sha256": "cb288103d497044787845a3fb0e20933dfea210fb2b390656e7a6a729621bb9e"}, "downloads": -1, "filename": "whapi-0.5.3-py3-none-any.whl", "has_sig": false, "md5_digest": "28db917719d7cf5376a1bb41f10664d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4801, "upload_time": "2020-03-26T05:49:44", "upload_time_iso_8601": "2020-03-26T05:49:44.693643Z", "url": "https://files.pythonhosted.org/packages/7c/09/cf7a1c21e95da9ae941789718feb04d3ec927cf0d560f5b5f786e5fa2364/whapi-0.5.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5bd00b1645cb51c6e51203cccd31be4b", "sha256": "db3c5474faeb28e87c5a852a3371340a52f91c66f395bf11baf3b442df14ee48"}, "downloads": -1, "filename": "whapi-0.5.3.tar.gz", "has_sig": false, "md5_digest": "5bd00b1645cb51c6e51203cccd31be4b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3678, "upload_time": "2020-03-26T05:49:46", "upload_time_iso_8601": "2020-03-26T05:49:46.910684Z", "url": "https://files.pythonhosted.org/packages/48/ac/15e6815331f13910defb0a4bdd73df031a854e520b223f023da169aec0a8/whapi-0.5.3.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "10217e77bfadf6f3521986f850251b9c", "sha256": "c9b1db6260532b90fa3828b767405b5df23d219ed509ae51bd8e2ac96e345a3d"}, "downloads": -1, "filename": "whapi-0.6.0-py3-none-any.whl", "has_sig": false, "md5_digest": "10217e77bfadf6f3521986f850251b9c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5401, "upload_time": "2020-04-10T01:14:39", "upload_time_iso_8601": "2020-04-10T01:14:39.517717Z", "url": "https://files.pythonhosted.org/packages/94/10/22a8221b931198542162dbcc22d6ea98584a37da405f95f1991965f0077b/whapi-0.6.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f306c870214d7191297490e47b6e3c16", "sha256": "59ea6fdd8ee168757dac4c9064a9bd3a4dd70f4b1aadc3ca1e3f62a87cf5f035"}, "downloads": -1, "filename": "whapi-0.6.0.tar.gz", "has_sig": false, "md5_digest": "f306c870214d7191297490e47b6e3c16", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4386, "upload_time": "2020-04-10T01:14:40", "upload_time_iso_8601": "2020-04-10T01:14:40.874842Z", "url": "https://files.pythonhosted.org/packages/ef/77/8e06c6dd771e14e2ecaf65fbc1d4e03adb4aab802efd4f09c42086370f4f/whapi-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "b3d92d619d0ec0964f7cfe1ba430b31c", "sha256": "b22958db9b6b4c9c399799e538e15240114c2d7cca54772b3b38319be5ae4690"}, "downloads": -1, "filename": "whapi-0.6.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b3d92d619d0ec0964f7cfe1ba430b31c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5335, "upload_time": "2020-04-10T08:57:26", "upload_time_iso_8601": "2020-04-10T08:57:26.204289Z", "url": "https://files.pythonhosted.org/packages/1b/e9/bd5465ac0bb1fa6b2a4965013d3e2b05dd9ebc6b4bbaeb4bba6b57575b54/whapi-0.6.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5ff198ef7ee1b8b9ddc569d425c5cf3f", "sha256": "85881811e37161112cdf0ffe69a5b71d74f306a080207df1faa0b777d6e77824"}, "downloads": -1, "filename": "whapi-0.6.1.tar.gz", "has_sig": false, "md5_digest": "5ff198ef7ee1b8b9ddc569d425c5cf3f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4322, "upload_time": "2020-04-10T08:57:27", "upload_time_iso_8601": "2020-04-10T08:57:27.254529Z", "url": "https://files.pythonhosted.org/packages/41/f7/a1a5d03d56b48a1e40b8686143dd23fd8e0d23b1cc43ef5b08a1d1000a29/whapi-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "0d732fd054051a5a1f2191e4c4770413", "sha256": "f91bcae2efba7ddf35ef93e5eba9c16e383f6b1980949a294ac2e8114304419a"}, "downloads": -1, "filename": "whapi-0.6.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0d732fd054051a5a1f2191e4c4770413", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5830, "upload_time": "2020-04-15T00:00:27", "upload_time_iso_8601": "2020-04-15T00:00:27.158178Z", "url": "https://files.pythonhosted.org/packages/03/6e/8ef8d8623efcb55385bbf20327939f40377b510b2be8ab5076414619a22b/whapi-0.6.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7b93baa2aa2ff3800bc582482283717b", "sha256": "f3a8bd0d3a6d29bd7114ed8603c91d54a853d4ccb900c84e40e8089ef3a360d0"}, "downloads": -1, "filename": "whapi-0.6.2.tar.gz", "has_sig": false, "md5_digest": "7b93baa2aa2ff3800bc582482283717b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4811, "upload_time": "2020-04-15T00:00:29", "upload_time_iso_8601": "2020-04-15T00:00:29.142428Z", "url": "https://files.pythonhosted.org/packages/ec/66/58755119aee14b2c671211b3ccd0a43ba22d30f7a5d33c658db3ca08332a/whapi-0.6.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0d732fd054051a5a1f2191e4c4770413", "sha256": "f91bcae2efba7ddf35ef93e5eba9c16e383f6b1980949a294ac2e8114304419a"}, "downloads": -1, "filename": "whapi-0.6.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0d732fd054051a5a1f2191e4c4770413", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5830, "upload_time": "2020-04-15T00:00:27", "upload_time_iso_8601": "2020-04-15T00:00:27.158178Z", "url": "https://files.pythonhosted.org/packages/03/6e/8ef8d8623efcb55385bbf20327939f40377b510b2be8ab5076414619a22b/whapi-0.6.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7b93baa2aa2ff3800bc582482283717b", "sha256": "f3a8bd0d3a6d29bd7114ed8603c91d54a853d4ccb900c84e40e8089ef3a360d0"}, "downloads": -1, "filename": "whapi-0.6.2.tar.gz", "has_sig": false, "md5_digest": "7b93baa2aa2ff3800bc582482283717b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4811, "upload_time": "2020-04-15T00:00:29", "upload_time_iso_8601": "2020-04-15T00:00:29.142428Z", "url": "https://files.pythonhosted.org/packages/ec/66/58755119aee14b2c671211b3ccd0a43ba22d30f7a5d33c658db3ca08332a/whapi-0.6.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:29:59 2020"}