{"info": {"author": "Yang Lu", "author_email": "luyanger1799@outlook.com", "bugtrack_url": null, "classifiers": [], "description": "# Amazing-Semantic-Segmentation\n[![python](https://img.shields.io/badge/Python-3.x-ff69b4.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n[![tensorflow](https://img.shields.io/badge/Tensorflow-1.1x%7C2.0-brightgreen.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n[![OpenCV](https://img.shields.io/badge/OpenCV-3.x%7C4.x-orange.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n[![Apache](https://img.shields.io/badge/Apache-2.0-blue.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n\n>Amazing Semantic Segmentation on Tensorflow && Keras (include FCN, UNet, SegNet, PSPNet, PAN, RefineNet, DeepLabV3, DeepLabV3+, DenseASPP, BiSegNet ...)\n***\n## Models\nThe project supports these semantic segmentation models as follows:\n\n>1. FCN-8s/16s/32s - [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/pdf/1411.4038.pdf)\n>2. UNet - [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)\n>3. SegNet - [SegNet:A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/pdf/1511.00561.pdf)\n>4. Bayesian-SegNet - [Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding](https://arxiv.org/pdf/1511.02680v2.pdf)\n>5. PSPNet - [Pyramid Scene Parsing Network](https://arxiv.org/pdf/1612.01105.pdf)\n>6. RefineNet - [RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation](https://arxiv.org/pdf/1611.06612.pdf)\n>7. PAN - [Pyramid Attention Network for Semantic Segmentation](https://arxiv.org/pdf/1805.10180.pdf)\n>8. DeepLabV3 - [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1706.05587.pdf)\n>9. DeepLabV3Plus - [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n>10. DenseASPP - [DenseASPP for Semantic Segmentation in Street Scenes](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf)\n>11. BiSegNet - [BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation](https://arxiv.org/pdf/1808.00897.pdf)\n\n\n***\n## Base Models\nThe project supports these backbone models as follows, and your can choose suitable base model according to your needs.\n\n>1. VGG16/19 - [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/pdf/1409.1556.pdf)\n>2. ResNet50/101/152 - [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n>3. DenseNet121/169/201/264 - [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)\n>4. MobileNetV1 - [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf)\n>5. MobileNetV2 - [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf)\n>6. Xception - [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/pdf/1610.02357.pdf)\n>7. Xception-DeepLab - [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n\n\n\n***\n## Dataset Setting\nThe folds of your dataset must satisfy the following structures:\n```buildoutcfg\n|-- dataset\n|  |-- train\n|  |  |-- images\n|  |  |-- labels\n|  |-- valid\n|  |  |-- images\n|  |  |-- labels\n|  |-- test\n|  |  |-- images\n|  |  |-- labels\n```\n***\n## Installation\n- Numpy `pip install numpy`\n- Pillow `pip install pillow`\n- OpenCV `pip install opencv-python`\n- Tensorflow `pip install tensorflow-gpu`  \n\n**Note:** The recommended version of tensorflow-gpu is 1.14 or 2.0. And if your tensorflow version is lower, you \nneed to modify some API or upgrade your tensorflow. \n***\n## Usage\n**Download:**\nYou can download the project through this command:  \n`git clone git@github.com:luyanger1799/Amazing-Semantic-Segmentation.git`  \n\n**Training:** \nThe project contains complete codes for training, testing and predicting. \nAnd you can perform a simple command as this to build a model on your dataset:\n```buildoutcfg\npython train.py --model FCN-8s --base_model ResNet50 --dataset \"dataset_path\" --num_classes \"num_classes\"\n```\nThe detailed command line parameters are as follows:\n```buildoutcfg\nusage: train.py [-h] --model MODEL [--base_model BASE_MODEL] --dataset DATASET\n                --num_classes NUM_CLASSES [--random_crop RANDOM_CROP]\n                [--crop_height CROP_HEIGHT] [--crop_width CROP_WIDTH]\n                [--batch_size BATCH_SIZE]\n                [--valid_batch_size VALID_BATCH_SIZE]\n                [--num_epochs NUM_EPOCHS] [--initial_epoch INITIAL_EPOCH]\n                [--h_flip H_FLIP] [--v_flip V_FLIP]\n                [--brightness BRIGHTNESS [BRIGHTNESS ...]]\n                [--rotation ROTATION]\n                [--zoom_range ZOOM_RANGE [ZOOM_RANGE ...]]\n                [--channel_shift CHANNEL_SHIFT]\n                [--data_aug_rate DATA_AUG_RATE]\n                [--checkpoint_freq CHECKPOINT_FREQ]\n                [--validation_freq VALIDATION_FREQ]\n                [--num_valid_images NUM_VALID_IMAGES]\n                [--data_shuffle DATA_SHUFFLE] [--random_seed RANDOM_SEED]\n                [--weights WEIGHTS]\n\n```\n```buildoutcfg\noptional arguments:\n  -h, --help            show this help message and exit\n  --model MODEL         Choose the semantic segmentation methods.\n  --base_model BASE_MODEL\n                        Choose the backbone model.\n  --dataset DATASET     The path of the dataset.\n  --num_classes NUM_CLASSES\n                        The number of classes to be segmented.\n  --random_crop RANDOM_CROP\n                        Whether to randomly crop the image.\n  --crop_height CROP_HEIGHT\n                        The height to crop the image.\n  --crop_width CROP_WIDTH\n                        The width to crop the image.\n  --batch_size BATCH_SIZE\n                        The training batch size.\n  --valid_batch_size VALID_BATCH_SIZE\n                        The validation batch size.\n  --num_epochs NUM_EPOCHS\n                        The number of epochs to train for.\n  --initial_epoch INITIAL_EPOCH\n                        The initial epoch of training.\n  --h_flip H_FLIP       Whether to randomly flip the image horizontally.\n  --v_flip V_FLIP       Whether to randomly flip the image vertically.\n  --brightness BRIGHTNESS [BRIGHTNESS ...]\n                        Randomly change the brightness (list).\n  --rotation ROTATION   The angle to randomly rotate the image.\n  --zoom_range ZOOM_RANGE [ZOOM_RANGE ...]\n                        The times for zooming the image.\n  --channel_shift CHANNEL_SHIFT\n                        The channel shift range.\n  --data_aug_rate DATA_AUG_RATE\n                        The rate of data augmentation.\n  --checkpoint_freq CHECKPOINT_FREQ\n                        How often to save a checkpoint.\n  --validation_freq VALIDATION_FREQ\n                        How often to perform validation.\n  --num_valid_images NUM_VALID_IMAGES\n                        The number of images used for validation.\n  --data_shuffle DATA_SHUFFLE\n                        Whether to shuffle the data.\n  --random_seed RANDOM_SEED\n                        The random shuffle seed.\n  --weights WEIGHTS     The path of weights to be loaded.\n\n```\nIf you only want to use the model in your own training code, you can do as this:\n```buildoutcfg\nfrom builders.model_builder import builder\n\nmodel, base_model = builder(num_classes, input_size, model='SegNet', base_model=None)\n```\n**Note:** If you don't give the parameter \"base_model\", the default backbone will be used.\n\n**Testing:** \nSimilarly, you can evaluate the model on your own dataset:\n```buildoutcfg\npython test.py --model FCN-8s --base_model ResNet50 --dataset \"dataset_path\" --num_classes \"num_classes\" --weights \"weights_path\"\n```\n**Note:** If the parameter \"weights\" is None, the weigths saved in default path will be loaded.  \n\n**Predicting:** \nYou can get the prediction of a single RGB image as this:\n```buildoutcfg\npython predict.py --model FCN-8s --base_model ResNet50 --num_classes \"num_classes\" --weights \"weights_path\" --image_path \"image_path\"\n``` \n***\n## PyPI\nAlternatively, you can install the project through PyPI.\n```\npip install semantic-segmentation\n```\nAnd you can use model_builders to build different models or directly call the class of semantic segmentation.\n```\nfrom semantic_segmentation import model_builders\nnet, base_net = model_builders(num_classes, input_size, model='SegNet', base_model=None)\n```\nor\n```\nfrom semantic_segmentation import models\nnet = models.FCN(num_classes, version='FCN-8s')(input_size=input_size)\n```\n***\n## Pre-trained\nDue to my limited computing resources, there is no pre-training model yet. And maybe it will be added in the future.\n***\n## Feedback\nIf you like this work, please give me a star! And if you find\nany errors or have any suggestions, please contact me.  \n\n**GitHub:** `luyanger1799`\\\n**Email:** `luyanger1799@outlook.com`", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git", "keywords": "", "license": "Apache 2,0 License", "maintainer": "", "maintainer_email": "", "name": "semantic-segmentation", "package_url": "https://pypi.org/project/semantic-segmentation/", "platform": "all", "project_url": "https://pypi.org/project/semantic-segmentation/", "project_urls": {"Homepage": "https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git"}, "release_url": "https://pypi.org/project/semantic-segmentation/0.1.0/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Semantic Segmentation on Tensorflow && Keras", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Amazing-Semantic-Segmentation</h1>\n<p><a href=\"https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git\" rel=\"nofollow\"><img alt=\"python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d0e4eeefcd4cae210e3f9480a262d4fccfe6d6ee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e782d6666363962342e737667\"></a>\n<a href=\"https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git\" rel=\"nofollow\"><img alt=\"tensorflow\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/002da4887eaf423450cd13194479bf065bc85c53/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f54656e736f72666c6f772d312e3178253743322e302d627269676874677265656e2e737667\"></a>\n<a href=\"https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git\" rel=\"nofollow\"><img alt=\"OpenCV\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fc0574b1b3e6956c41684c152ffeb54d3070b054/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4f70656e43562d332e78253743342e782d6f72616e67652e737667\"></a>\n<a href=\"https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git\" rel=\"nofollow\"><img alt=\"Apache\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c127e957a209a3b6ebc6603feccac5927bfcf8b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4170616368652d322e302d626c75652e737667\"></a></p>\n<blockquote>\n<p>Amazing Semantic Segmentation on Tensorflow &amp;&amp; Keras (include FCN, UNet, SegNet, PSPNet, PAN, RefineNet, DeepLabV3, DeepLabV3+, DenseASPP, BiSegNet ...)</p>\n</blockquote>\n<hr>\n<h2>Models</h2>\n<p>The project supports these semantic segmentation models as follows:</p>\n<blockquote>\n<ol>\n<li>FCN-8s/16s/32s - <a href=\"https://arxiv.org/pdf/1411.4038.pdf\" rel=\"nofollow\">Fully Convolutional Networks for Semantic Segmentation</a></li>\n<li>UNet - <a href=\"https://arxiv.org/pdf/1505.04597.pdf\" rel=\"nofollow\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></li>\n<li>SegNet - <a href=\"https://arxiv.org/pdf/1511.00561.pdf\" rel=\"nofollow\">SegNet:A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</a></li>\n<li>Bayesian-SegNet - <a href=\"https://arxiv.org/pdf/1511.02680v2.pdf\" rel=\"nofollow\">Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding</a></li>\n<li>PSPNet - <a href=\"https://arxiv.org/pdf/1612.01105.pdf\" rel=\"nofollow\">Pyramid Scene Parsing Network</a></li>\n<li>RefineNet - <a href=\"https://arxiv.org/pdf/1611.06612.pdf\" rel=\"nofollow\">RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</a></li>\n<li>PAN - <a href=\"https://arxiv.org/pdf/1805.10180.pdf\" rel=\"nofollow\">Pyramid Attention Network for Semantic Segmentation</a></li>\n<li>DeepLabV3 - <a href=\"https://arxiv.org/pdf/1706.05587.pdf\" rel=\"nofollow\">Rethinking Atrous Convolution for Semantic Image Segmentation</a></li>\n<li>DeepLabV3Plus - <a href=\"https://arxiv.org/pdf/1802.02611.pdf\" rel=\"nofollow\">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a></li>\n<li>DenseASPP - <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf\" rel=\"nofollow\">DenseASPP for Semantic Segmentation in Street Scenes</a></li>\n<li>BiSegNet - <a href=\"https://arxiv.org/pdf/1808.00897.pdf\" rel=\"nofollow\">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li>\n</ol>\n</blockquote>\n<hr>\n<h2>Base Models</h2>\n<p>The project supports these backbone models as follows, and your can choose suitable base model according to your needs.</p>\n<blockquote>\n<ol>\n<li>VGG16/19 - <a href=\"https://arxiv.org/pdf/1409.1556.pdf\" rel=\"nofollow\">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li>\n<li>ResNet50/101/152 - <a href=\"https://arxiv.org/pdf/1512.03385.pdf\" rel=\"nofollow\">Deep Residual Learning for Image Recognition</a></li>\n<li>DenseNet121/169/201/264 - <a href=\"https://arxiv.org/pdf/1608.06993.pdf\" rel=\"nofollow\">Densely Connected Convolutional Networks</a></li>\n<li>MobileNetV1 - <a href=\"https://arxiv.org/pdf/1704.04861.pdf\" rel=\"nofollow\">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>\n<li>MobileNetV2 - <a href=\"https://arxiv.org/pdf/1801.04381.pdf\" rel=\"nofollow\">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li>\n<li>Xception - <a href=\"https://arxiv.org/pdf/1610.02357.pdf\" rel=\"nofollow\">Xception: Deep Learning with Depthwise Separable Convolutions</a></li>\n<li>Xception-DeepLab - <a href=\"https://arxiv.org/pdf/1802.02611.pdf\" rel=\"nofollow\">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a></li>\n</ol>\n</blockquote>\n<hr>\n<h2>Dataset Setting</h2>\n<p>The folds of your dataset must satisfy the following structures:</p>\n<pre>|-- dataset\n|  |-- train\n|  |  |-- images\n|  |  |-- labels\n|  |-- valid\n|  |  |-- images\n|  |  |-- labels\n|  |-- test\n|  |  |-- images\n|  |  |-- labels\n</pre>\n<hr>\n<h2>Installation</h2>\n<ul>\n<li>Numpy <code>pip install numpy</code></li>\n<li>Pillow <code>pip install pillow</code></li>\n<li>OpenCV <code>pip install opencv-python</code></li>\n<li>Tensorflow <code>pip install tensorflow-gpu</code></li>\n</ul>\n<p><strong>Note:</strong> The recommended version of tensorflow-gpu is 1.14 or 2.0. And if your tensorflow version is lower, you\nneed to modify some API or upgrade your tensorflow.</p>\n<hr>\n<h2>Usage</h2>\n<p><strong>Download:</strong>\nYou can download the project through this command:<br>\n<code>git clone git@github.com:luyanger1799/Amazing-Semantic-Segmentation.git</code></p>\n<p><strong>Training:</strong>\nThe project contains complete codes for training, testing and predicting.\nAnd you can perform a simple command as this to build a model on your dataset:</p>\n<pre>python train.py --model FCN-8s --base_model ResNet50 --dataset \"dataset_path\" --num_classes \"num_classes\"\n</pre>\n<p>The detailed command line parameters are as follows:</p>\n<pre>usage: train.py [-h] --model MODEL [--base_model BASE_MODEL] --dataset DATASET\n                --num_classes NUM_CLASSES [--random_crop RANDOM_CROP]\n                [--crop_height CROP_HEIGHT] [--crop_width CROP_WIDTH]\n                [--batch_size BATCH_SIZE]\n                [--valid_batch_size VALID_BATCH_SIZE]\n                [--num_epochs NUM_EPOCHS] [--initial_epoch INITIAL_EPOCH]\n                [--h_flip H_FLIP] [--v_flip V_FLIP]\n                [--brightness BRIGHTNESS [BRIGHTNESS ...]]\n                [--rotation ROTATION]\n                [--zoom_range ZOOM_RANGE [ZOOM_RANGE ...]]\n                [--channel_shift CHANNEL_SHIFT]\n                [--data_aug_rate DATA_AUG_RATE]\n                [--checkpoint_freq CHECKPOINT_FREQ]\n                [--validation_freq VALIDATION_FREQ]\n                [--num_valid_images NUM_VALID_IMAGES]\n                [--data_shuffle DATA_SHUFFLE] [--random_seed RANDOM_SEED]\n                [--weights WEIGHTS]\n</pre>\n<pre>optional arguments:\n  -h, --help            show this help message and exit\n  --model MODEL         Choose the semantic segmentation methods.\n  --base_model BASE_MODEL\n                        Choose the backbone model.\n  --dataset DATASET     The path of the dataset.\n  --num_classes NUM_CLASSES\n                        The number of classes to be segmented.\n  --random_crop RANDOM_CROP\n                        Whether to randomly crop the image.\n  --crop_height CROP_HEIGHT\n                        The height to crop the image.\n  --crop_width CROP_WIDTH\n                        The width to crop the image.\n  --batch_size BATCH_SIZE\n                        The training batch size.\n  --valid_batch_size VALID_BATCH_SIZE\n                        The validation batch size.\n  --num_epochs NUM_EPOCHS\n                        The number of epochs to train for.\n  --initial_epoch INITIAL_EPOCH\n                        The initial epoch of training.\n  --h_flip H_FLIP       Whether to randomly flip the image horizontally.\n  --v_flip V_FLIP       Whether to randomly flip the image vertically.\n  --brightness BRIGHTNESS [BRIGHTNESS ...]\n                        Randomly change the brightness (list).\n  --rotation ROTATION   The angle to randomly rotate the image.\n  --zoom_range ZOOM_RANGE [ZOOM_RANGE ...]\n                        The times for zooming the image.\n  --channel_shift CHANNEL_SHIFT\n                        The channel shift range.\n  --data_aug_rate DATA_AUG_RATE\n                        The rate of data augmentation.\n  --checkpoint_freq CHECKPOINT_FREQ\n                        How often to save a checkpoint.\n  --validation_freq VALIDATION_FREQ\n                        How often to perform validation.\n  --num_valid_images NUM_VALID_IMAGES\n                        The number of images used for validation.\n  --data_shuffle DATA_SHUFFLE\n                        Whether to shuffle the data.\n  --random_seed RANDOM_SEED\n                        The random shuffle seed.\n  --weights WEIGHTS     The path of weights to be loaded.\n</pre>\n<p>If you only want to use the model in your own training code, you can do as this:</p>\n<pre>from builders.model_builder import builder\n\nmodel, base_model = builder(num_classes, input_size, model='SegNet', base_model=None)\n</pre>\n<p><strong>Note:</strong> If you don't give the parameter \"base_model\", the default backbone will be used.</p>\n<p><strong>Testing:</strong>\nSimilarly, you can evaluate the model on your own dataset:</p>\n<pre>python test.py --model FCN-8s --base_model ResNet50 --dataset \"dataset_path\" --num_classes \"num_classes\" --weights \"weights_path\"\n</pre>\n<p><strong>Note:</strong> If the parameter \"weights\" is None, the weigths saved in default path will be loaded.</p>\n<p><strong>Predicting:</strong>\nYou can get the prediction of a single RGB image as this:</p>\n<pre>python predict.py --model FCN-8s --base_model ResNet50 --num_classes \"num_classes\" --weights \"weights_path\" --image_path \"image_path\"\n</pre>\n<hr>\n<h2>PyPI</h2>\n<p>Alternatively, you can install the project through PyPI.</p>\n<pre><code>pip install semantic-segmentation\n</code></pre>\n<p>And you can use model_builders to build different models or directly call the class of semantic segmentation.</p>\n<pre><code>from semantic_segmentation import model_builders\nnet, base_net = model_builders(num_classes, input_size, model='SegNet', base_model=None)\n</code></pre>\n<p>or</p>\n<pre><code>from semantic_segmentation import models\nnet = models.FCN(num_classes, version='FCN-8s')(input_size=input_size)\n</code></pre>\n<hr>\n<h2>Pre-trained</h2>\n<p>Due to my limited computing resources, there is no pre-training model yet. And maybe it will be added in the future.</p>\n<hr>\n<h2>Feedback</h2>\n<p>If you like this work, please give me a star! And if you find\nany errors or have any suggestions, please contact me.</p>\n<p><strong>GitHub:</strong> <code>luyanger1799</code><br>\n<strong>Email:</strong> <code>luyanger1799@outlook.com</code></p>\n\n          </div>"}, "last_serial": 5740393, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "acd564bc1e2d9d819cbfd38ce67b7238", "sha256": "77760a65577a7c0ffbeb271e06a7d71d04b5a749fe6ddeb12d8254491d5f77b1"}, "downloads": -1, "filename": "semantic_segmentation-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "acd564bc1e2d9d819cbfd38ce67b7238", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 39730, "upload_time": "2019-07-25T16:01:57", "upload_time_iso_8601": "2019-07-25T16:01:57.423699Z", "url": "https://files.pythonhosted.org/packages/ca/43/ebfc16eb1c6c5628ee53cb095cb3517da3987750228474fbbadfaa5e7cd9/semantic_segmentation-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a450a384dc1a3a0d3c02ace2ca57b9d3", "sha256": "03eafff6a9d4b84b1d9b3661ce3b1e6b6916f6dc7180871559da9a18f4370b7c"}, "downloads": -1, "filename": "semantic_segmentation-0.0.2.tar.gz", "has_sig": false, "md5_digest": "a450a384dc1a3a0d3c02ace2ca57b9d3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 21915, "upload_time": "2019-07-25T16:02:00", "upload_time_iso_8601": "2019-07-25T16:02:00.816489Z", "url": "https://files.pythonhosted.org/packages/8d/bb/64c75581ed5be1fdc844ccb6d5e5e24d579b5f51a2537dcf464d456798db/semantic_segmentation-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "ae04f20090121fdf58c2192f6e4a86db", "sha256": "b8e9c4ee93f91071326b69f73097ae58b7214c7ff992659115fc77e72c071b67"}, "downloads": -1, "filename": "semantic_segmentation-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "ae04f20090121fdf58c2192f6e4a86db", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 39887, "upload_time": "2019-07-25T16:29:50", "upload_time_iso_8601": "2019-07-25T16:29:50.831227Z", "url": "https://files.pythonhosted.org/packages/d8/2b/5b630318fa9a6d65b362e263966d55c6662f3e3a03155c7d1153fb1caade/semantic_segmentation-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a801d2b8985bd7ce1170c6b0d8dca353", "sha256": "743aa74d9e41efd4d576f2771a8dd667f1d76c9078b96aba56ad18d9ccf5f1c3"}, "downloads": -1, "filename": "semantic_segmentation-0.0.3.tar.gz", "has_sig": false, "md5_digest": "a801d2b8985bd7ce1170c6b0d8dca353", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 22222, "upload_time": "2019-07-25T16:29:53", "upload_time_iso_8601": "2019-07-25T16:29:53.014579Z", "url": "https://files.pythonhosted.org/packages/0b/f6/ca0e85ce4ff325ae8c50ba61ef685817489b1164a70bc5e1b874c7239116/semantic_segmentation-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "3182e7b91cb887537ae49e6c8c4ae545", "sha256": "5e402b87316d11aa02e9510827ede0d8c84418e3cbc963c746524706acf1d419"}, "downloads": -1, "filename": "semantic_segmentation-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "3182e7b91cb887537ae49e6c8c4ae545", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 39952, "upload_time": "2019-07-28T02:46:35", "upload_time_iso_8601": "2019-07-28T02:46:35.724522Z", "url": "https://files.pythonhosted.org/packages/d9/71/95f9482769a22d940f93de419fa3c70df33f856d5498780697c4b87d1857/semantic_segmentation-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "206ae5c867085692453bc75e38a1096b", "sha256": "baab5980a0264a6fb1802afdc0fe3648606e2a625ef73cd6b5b747d33ded75e8"}, "downloads": -1, "filename": "semantic_segmentation-0.0.4.tar.gz", "has_sig": false, "md5_digest": "206ae5c867085692453bc75e38a1096b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 22448, "upload_time": "2019-07-28T02:46:37", "upload_time_iso_8601": "2019-07-28T02:46:37.768026Z", "url": "https://files.pythonhosted.org/packages/60/33/107850a361934fbbfa18afc8422eaa1a8313c9bd07d2964f6195420fe12d/semantic_segmentation-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "01a227a6063e9898b2c1b97e7ad45b0a", "sha256": "56c52489c6633d985670150301b9890e2f56cc03f3d9f306d9a772390c13a060"}, "downloads": -1, "filename": "semantic_segmentation-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "01a227a6063e9898b2c1b97e7ad45b0a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 40211, "upload_time": "2019-08-26T02:44:27", "upload_time_iso_8601": "2019-08-26T02:44:27.015107Z", "url": "https://files.pythonhosted.org/packages/44/d0/eb92ecea05dd7d4972280b382a595603722d8e7e229cfea68a9d0c441a56/semantic_segmentation-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1972aea8b62dd0b7cd5bf7b14d081616", "sha256": "b8f5a097fa65ef5e8e29e58786a9f218063471847fed3af703ecf7961dfd6451"}, "downloads": -1, "filename": "semantic_segmentation-0.0.5.tar.gz", "has_sig": false, "md5_digest": "1972aea8b62dd0b7cd5bf7b14d081616", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 22687, "upload_time": "2019-08-26T02:44:29", "upload_time_iso_8601": "2019-08-26T02:44:29.270780Z", "url": "https://files.pythonhosted.org/packages/60/bf/5a8443077e8bdff2df83c440c70f2bd4a4ba67f60db1a01ffb4f9dc90c81/semantic_segmentation-0.0.5.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "b7b05fb8186c66c2d08e46115deeff48", "sha256": "a25412f79c962c9d2ef429b114778f896604c8e823c1d1a42de65f8f262767ef"}, "downloads": -1, "filename": "semantic_segmentation-0.1.0.tar.gz", "has_sig": false, "md5_digest": "b7b05fb8186c66c2d08e46115deeff48", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 22736, "upload_time": "2019-08-28T02:51:25", "upload_time_iso_8601": "2019-08-28T02:51:25.173698Z", "url": "https://files.pythonhosted.org/packages/d9/84/2c71e0c4901f61012919f2dbb64ce23d709a20425f3cffbcd9e497b0361a/semantic_segmentation-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b7b05fb8186c66c2d08e46115deeff48", "sha256": "a25412f79c962c9d2ef429b114778f896604c8e823c1d1a42de65f8f262767ef"}, "downloads": -1, "filename": "semantic_segmentation-0.1.0.tar.gz", "has_sig": false, "md5_digest": "b7b05fb8186c66c2d08e46115deeff48", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 22736, "upload_time": "2019-08-28T02:51:25", "upload_time_iso_8601": "2019-08-28T02:51:25.173698Z", "url": "https://files.pythonhosted.org/packages/d9/84/2c71e0c4901f61012919f2dbb64ce23d709a20425f3cffbcd9e497b0361a/semantic_segmentation-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:24 2020"}