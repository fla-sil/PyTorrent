{"info": {"author": "Carles R. Riera Molina", "author_email": "carlesrieramolina@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "==============\nLinked Neurons\n==============\n\n\n.. image:: https://img.shields.io/pypi/v/linked_neurons.svg\n        :target: https://pypi.python.org/pypi/linked_neurons\n\n.. image:: https://img.shields.io/travis/blauigris/linked_neurons.svg\n        :target: https://travis-ci.org/blauigris/linked_neurons\n\n.. image:: https://readthedocs.org/projects/linked-neurons/badge/?version=latest\n        :target: https://linked-neurons.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n.. image:: https://pyup.io/repos/github/blauigris/linked_neurons/shield.svg\n     :target: https://pyup.io/repos/github/blauigris/linked_neurons/\n     :alt: Updates\n\n\nKeras implementation of the article \"Solving internal covariate shift in deep learning with linked neurons\"\n\nLinked neurons is a deep learning framework where two or more activations are coupled in order to have gradient in\nall input space. This improves covariate shift robustness and enables to forfeit other techniques such Batch Normalization\nwhich incur in additional computational cost. More info in the arxiv paper HERE.\n\n\n* Free software: MIT license\n* Documentation: https://linked-neurons.readthedocs.io.\n\n\nFeatures\n--------\n\n* 200% faster than Batchnorm.\n* 40% faster than SELU.\n* Use your favorite activation function without worrying about covariate shift.\n\nQuickStart\n----------\n\nInstall using pip::\n\n    pip install linked_neurons\n\nImport Linked Neurons in a project::\n\n    import linked_neurons\n\nInside there are the implementations as a keras layer.Layer subclasses.\nFor the moment being there are LK-ReLU, LK-PReLU, LK-SELU and LK-Swish available.\n\n\nExample using Sequential::\n\n    model = Sequential()\n    (x_train, y_train), (x_test, y_test) = load_mnist()\n    model.add(Conv2D(32, kernel_size=(3, 3), activation=None, input_shape=x_train.shape[1:]))\n    model.add(LKReLU())\n    model.add(Conv2D(64, (3, 3), activation=None))\n    model.add(LKReLU())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation=None))\n    model.add(LKReLU())\n    model.add(Dense(10, activation='softmax'))\n\nExample using functional api::\n\n    (x_train, y_train), (x_test, y_test) = load_mnist()\n    img_input = Input(shape=x_train.shape[1:])\n    x = Conv2D(width, (7, 7), strides=(2, 2), padding='same', name='convfirst')(img_input)\n    x = LKReLU()(x)\n    x = Conv2D(width, (3, 3), padding='same')(x)\n    x = LKReLU()(x)\n    x = Flatten()(x)\n    x = Dense(classes, activation='softmax', name='fc')(x)\n    model = Model(inputs, x)\n\nFor more examples see the tests or keras documentation.\n\n\nReplicating results\n===================\n\nReproducibility is of paramount importance in science, so we provide all the code needed to replicate our results.\n\nRunning the experiments\n-----------------------\n\nIn order to replicate the results displayed in the paper and the paper itself first download the entire repo so\nthe scripts used to generate them are also included::\n\n    git clone git@github.com:blauigris/linked_neurons.git\n\nEach of the experiments are implemented separately using nosetests for ease of use. They are located inside tests/test_article\nIn order to run them, just call::\n\n    nosetests test_<experiment>\n\nFor instance, for the entire depth experiment one may use::\n\n    nosetests test_depth.py\n\nor if only one activation is required::\n\n    nosetests test_depth:TestDepth.test_lkrelu\n\nIt will store the results in form of tensorboard summaries at tests/test_article/summaries and the checkpoints\nin tests/test_article/checkpoints in some cases.\n\nIn case one might want to play with the hyperparameters, they are set into the setUp method of each test.\n\nThe experiments are quite fast to run especially the ones from the sections of covariate shift, depth and width.\nAllcnn* and resnet50 take a day using a GTX 1080Ti.\n\n\nGenerating the tables\n---------------------\n\nOnce run, the scripts\nfor creating the tables used in the paper are in tests/test_article/test_table. Each of the tests generates a table.\nFor instance, in order to generate the table of the depth experiment::\n\n    nosetests test_table:TestTable.test_depth\n\nThis will create a .tex file containing the table at docs/article/tables. This table is included into paper.tex, so\nrecompiling it should update the paper with the new results.\n\n\nCredits\n---------\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n\n\n\n=======\nHistory\n=======\n\n0.1.0 (2017-12-01)\n------------------\n\n* First release on PyPI.\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/blauigris/linked_neurons", "keywords": "linked_neurons deep-learning machine-learning neural-networks", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "linked-neurons", "package_url": "https://pypi.org/project/linked-neurons/", "platform": "", "project_url": "https://pypi.org/project/linked-neurons/", "project_urls": {"Homepage": "https://github.com/blauigris/linked_neurons"}, "release_url": "https://pypi.org/project/linked-neurons/0.1.0/", "requires_dist": ["keras (>=2.0)", "tensorflow (>=1.4)"], "requires_python": ">=3", "summary": "Keras implementation of the article \"Solving internal covariate shift in deep learning with linked neurons\"", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"linked-neurons\">\n<h2>Linked Neurons</h2>\n<a href=\"https://pypi.python.org/pypi/linked_neurons\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/linked_neurons.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd66468a31ae118c2b655f2547f587095cddf0ce/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c696e6b65645f6e6575726f6e732e737667\"></a>\n<a href=\"https://travis-ci.org/blauigris/linked_neurons\" rel=\"nofollow\"><img alt=\"https://img.shields.io/travis/blauigris/linked_neurons.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/39134edbcb087f5c1a088d57f0ea20eb72a02afe/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f626c617569677269732f6c696e6b65645f6e6575726f6e732e737667\"></a>\n<a href=\"https://linked-neurons.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/99684893fd0f4d12cf490ebb6fd3b32fc6601216/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6c696e6b65642d6e6575726f6e732f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://pyup.io/repos/github/blauigris/linked_neurons/\" rel=\"nofollow\"><img alt=\"Updates\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5bffaa1ef9dc6336967fbe3135c29737e0f85fdd/68747470733a2f2f707975702e696f2f7265706f732f6769746875622f626c617569677269732f6c696e6b65645f6e6575726f6e732f736869656c642e737667\"></a>\n<p>Keras implementation of the article \u201cSolving internal covariate shift in deep learning with linked neurons\u201d</p>\n<p>Linked neurons is a deep learning framework where two or more activations are coupled in order to have gradient in\nall input space. This improves covariate shift robustness and enables to forfeit other techniques such Batch Normalization\nwhich incur in additional computational cost. More info in the arxiv paper HERE.</p>\n<ul>\n<li>Free software: MIT license</li>\n<li>Documentation: <a href=\"https://linked-neurons.readthedocs.io\" rel=\"nofollow\">https://linked-neurons.readthedocs.io</a>.</li>\n</ul>\n<div id=\"features\">\n<h3>Features</h3>\n<ul>\n<li>200% faster than Batchnorm.</li>\n<li>40% faster than SELU.</li>\n<li>Use your favorite activation function without worrying about covariate shift.</li>\n</ul>\n</div>\n<div id=\"quickstart\">\n<h3>QuickStart</h3>\n<p>Install using pip:</p>\n<pre>pip install linked_neurons\n</pre>\n<p>Import Linked Neurons in a project:</p>\n<pre>import linked_neurons\n</pre>\n<p>Inside there are the implementations as a keras layer.Layer subclasses.\nFor the moment being there are LK-ReLU, LK-PReLU, LK-SELU and LK-Swish available.</p>\n<p>Example using Sequential:</p>\n<pre>model = Sequential()\n(x_train, y_train), (x_test, y_test) = load_mnist()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation=None, input_shape=x_train.shape[1:]))\nmodel.add(LKReLU())\nmodel.add(Conv2D(64, (3, 3), activation=None))\nmodel.add(LKReLU())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=None))\nmodel.add(LKReLU())\nmodel.add(Dense(10, activation='softmax'))\n</pre>\n<p>Example using functional api:</p>\n<pre>(x_train, y_train), (x_test, y_test) = load_mnist()\nimg_input = Input(shape=x_train.shape[1:])\nx = Conv2D(width, (7, 7), strides=(2, 2), padding='same', name='convfirst')(img_input)\nx = LKReLU()(x)\nx = Conv2D(width, (3, 3), padding='same')(x)\nx = LKReLU()(x)\nx = Flatten()(x)\nx = Dense(classes, activation='softmax', name='fc')(x)\nmodel = Model(inputs, x)\n</pre>\n<p>For more examples see the tests or keras documentation.</p>\n<div id=\"replicating-results\">\n<h4>Replicating results</h4>\n<p>Reproducibility is of paramount importance in science, so we provide all the code needed to replicate our results.</p>\n</div>\n</div>\n<div id=\"running-the-experiments\">\n<h3>Running the experiments</h3>\n<p>In order to replicate the results displayed in the paper and the paper itself first download the entire repo so\nthe scripts used to generate them are also included:</p>\n<pre>git clone git@github.com:blauigris/linked_neurons.git\n</pre>\n<p>Each of the experiments are implemented separately using nosetests for ease of use. They are located inside tests/test_article\nIn order to run them, just call:</p>\n<pre>nosetests test_&lt;experiment&gt;\n</pre>\n<p>For instance, for the entire depth experiment one may use:</p>\n<pre>nosetests test_depth.py\n</pre>\n<p>or if only one activation is required:</p>\n<pre>nosetests test_depth:TestDepth.test_lkrelu\n</pre>\n<p>It will store the results in form of tensorboard summaries at tests/test_article/summaries and the checkpoints\nin tests/test_article/checkpoints in some cases.</p>\n<p>In case one might want to play with the hyperparameters, they are set into the setUp method of each test.</p>\n<p>The experiments are quite fast to run especially the ones from the sections of covariate shift, depth and width.\nAllcnn* and resnet50 take a day using a GTX 1080Ti.</p>\n</div>\n<div id=\"generating-the-tables\">\n<h3>Generating the tables</h3>\n<p>Once run, the scripts\nfor creating the tables used in the paper are in tests/test_article/test_table. Each of the tests generates a table.\nFor instance, in order to generate the table of the depth experiment:</p>\n<pre>nosetests test_table:TestTable.test_depth\n</pre>\n<p>This will create a .tex file containing the table at docs/article/tables. This table is included into paper.tex, so\nrecompiling it should update the paper with the new results.</p>\n</div>\n<div id=\"credits\">\n<h3>Credits</h3>\n<p>This package was created with <a href=\"https://github.com/audreyr/cookiecutter\" rel=\"nofollow\">Cookiecutter</a> and the <a href=\"https://github.com/audreyr/cookiecutter-pypackage\" rel=\"nofollow\">audreyr/cookiecutter-pypackage</a> project template.</p>\n</div>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<h2 id=\"id1\"><span class=\"section-subtitle\">0.1.0 (2017-12-01)</span></h2>\n<ul>\n<li>First release on PyPI.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 3401547, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "c4448ed3a95d897255357f34a3fab92c", "sha256": "0be0a672bd4564f41f9c8a428f6b1fb71cf9fa465b1703d383da2469a04f2df2"}, "downloads": -1, "filename": "linked_neurons-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c4448ed3a95d897255357f34a3fab92c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3", "size": 7265, "upload_time": "2017-12-08T17:30:20", "upload_time_iso_8601": "2017-12-08T17:30:20.898350Z", "url": "https://files.pythonhosted.org/packages/cc/b9/4989356cd58a38a1c74a0c0e062e8bd1cc75234d3e22f0f5edb9bad2e7fc/linked_neurons-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "62b83bd002d9edb3ea7031739ba199f7", "sha256": "d76baa01dee9d3e388e07a3c0ac54f6ebd417a2e473007b4ac067bb3a2c61a55"}, "downloads": -1, "filename": "linked_neurons-0.1.0.tar.gz", "has_sig": false, "md5_digest": "62b83bd002d9edb3ea7031739ba199f7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 43244, "upload_time": "2017-12-08T17:30:23", "upload_time_iso_8601": "2017-12-08T17:30:23.508619Z", "url": "https://files.pythonhosted.org/packages/ec/06/ff2c3feb19a3a7d93665987747cc4f2551083a4524ea84cf853b697b2986/linked_neurons-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c4448ed3a95d897255357f34a3fab92c", "sha256": "0be0a672bd4564f41f9c8a428f6b1fb71cf9fa465b1703d383da2469a04f2df2"}, "downloads": -1, "filename": "linked_neurons-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c4448ed3a95d897255357f34a3fab92c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3", "size": 7265, "upload_time": "2017-12-08T17:30:20", "upload_time_iso_8601": "2017-12-08T17:30:20.898350Z", "url": "https://files.pythonhosted.org/packages/cc/b9/4989356cd58a38a1c74a0c0e062e8bd1cc75234d3e22f0f5edb9bad2e7fc/linked_neurons-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "62b83bd002d9edb3ea7031739ba199f7", "sha256": "d76baa01dee9d3e388e07a3c0ac54f6ebd417a2e473007b4ac067bb3a2c61a55"}, "downloads": -1, "filename": "linked_neurons-0.1.0.tar.gz", "has_sig": false, "md5_digest": "62b83bd002d9edb3ea7031739ba199f7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 43244, "upload_time": "2017-12-08T17:30:23", "upload_time_iso_8601": "2017-12-08T17:30:23.508619Z", "url": "https://files.pythonhosted.org/packages/ec/06/ff2c3feb19a3a7d93665987747cc4f2551083a4524ea84cf853b697b2986/linked_neurons-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:38 2020"}