{"info": {"author": "Graham Bell", "author_email": "g.bell@eaobservatory.org", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)", "Programming Language :: Python", "Topic :: System :: Monitoring"], "description": "Crab\n====\n\n.. startcrabintro\n\nCrab is a dashboard system for monitoring cron jobs, or other scheduled\ntasks.  The Crab server receives messages when tasks start or finish,\nand displays the status of all of the tasks via a web interface.  It\ncan also send notifications by email, for example to warn if a task\nfails, is missed or does not complete within its time-out period.\n\nTasks communicate with the Crab server by JSON messages sent by HTTP\nPUT requests.  The finish message includes the status of the job,\nand any output from it.  Further messages are used to import and\nexport the client's crontab, which the server uses to determine the\nintended schedule.\n\n.. endcrabintro\n.. startcrabinstall\n\nRequirements\n------------\n\nPackages\n~~~~~~~~\n\n* `crontab`_ (0.15 or newer)\n* `CherryPy`_ (`PyPI entry <http://pypi.python.org/pypi/CherryPy>`__)\n* `Mako`_ (`PyPI entry <http://pypi.python.org/pypi/Mako/>`__)\n* `jQuery`_\n* `PyRSS2Gen`_ (optional)\n* `Font Awesome`_ (optional)\n* `ansi_up`_ (optional)\n* `MySQL Connector`_ (needed only if using a MySQL database)\n\n.. _`crontab`: http://pypi.python.org/pypi/crontab/\n.. _`CherryPy`: http://www.cherrypy.org/\n.. _`Mako`: http://www.makotemplates.org/\n.. _`jQuery`: http://jquery.com/\n.. _`PyRSS2Gen`: http://pypi.python.org/pypi/PyRSS2Gen/\n.. _`Font Awesome`: http://fortawesome.github.com/Font-Awesome\n.. _`ansi_up`: https://github.com/drudru/ansi_up\n.. _`MySQL Connector`: http://dev.mysql.com/downloads/connector/python/\n\nPython Version\n~~~~~~~~~~~~~~\n\nCrab server\n  Has been tested on Python 2.6, 2.7 and 3.2.\n\nClient library and utilities\n  Works with Python 2.4 in addition to the above versions (but\n  may require the ``pytz`` and ``simplejson`` packages also to be\n  installed).\n\nInstallation\n------------\n\nThe Crab server, clients and libraries can be installed as follows::\n\n    python setup.py install\n\nIf necessary, the ``--install-data`` option can be used to configure\nthe location in which the templates (``templ``), resources (``res``)\nand example files (``doc``) should be installed.\n\nTo run Crab without installing it, and if any of the Python dependencies\nlisted above can not be installed, they can be symlinked into the ``lib``\ndirectory in the following locations::\n\n    lib/PyRSS2Gen.py\n    lib/cherrypy\n    lib/crontab\n    lib/mako\n\nThe jQuery JavaScript library should be copied or symlinked into\nCrab's ``res`` directory as::\n\n    res/jquery.js\n\nTo use Font Awesome icons, copy or symlink its ``fonts`` directory into\nCrab's ``res`` directory, and also place its stylesheet inside\nthat subdirectory, giving::\n\n    res/fonts/font-awesome.css\n    res/fonts/fontawesome-webfont.*\n\nNote that Font Awesome is not backward compatible between major\nversion numbers.  Crab now uses version 4 of Font Awesome.\n\nTo use ansi_up to interpret ANSI color commands in cron job output,\ncopy or symlink the ``ansi_up.js`` file into Crab's ``res`` directory::\n\n    res/ansi_up.js\n\n.. endcrabinstall\n\nThe Crab Server\n---------------\n\n.. startcrabserver\n\nDatabase Creation\n~~~~~~~~~~~~~~~~~\n\nA SQLite database file can be prepared for Crab using the\nschema provided::\n\n    % sqlite3 crab.db < doc/schema.sql\n\nAlternatively if you are going to be using MySQL for your\nCrab database, create the database::\n\n    % mysqladmin -u root -p create crab\n\nand create a user account for crab, changing the password\n(the \"identified by\" clause) to something suitable::\n\n    % mysql -u root -p mysql\n    > create user 'crab'@'localhost' identified by 'crab';\n    > grant all on crab.* to 'crab'@'localhost';\n    > flush privileges;\n\nYou can prepare a table creation script suitable for MySQL\nusing the Makefile in the `doc` directory of the source package::\n\n    % make -C doc schema_mysql.sql\n    % mysql -u crab -p crab < doc/schema_mysql.sql\n\nConfiguration\n~~~~~~~~~~~~~\n\nThe Crab server is configured by a ``crabd.ini`` file which can\nbe placed either in ``/etc/crab/`` or ``~/.crab/``.  Note that this\nis a CherryPy configuration file, which is read slightly differently to\ntypical ``.ini`` files which use Python's ConfigParser. ::\n\n    % cp doc/crabd.ini ~/.crab/\n\nThe example ``crabd.ini`` file should be edited to uncomment the\n``[crab]`` and ``[store]`` sections.  The ``home`` and ``file`` entries\nmust point to the location of Crab's data files and the database file\njust created.  By default the data files are installed in ``share/crab``\nrelative to the Python system prefix (``sys.prefix``).\n\nThere is also an ``[outputstore]`` section in the server configuration\nfile.  This allows the output from cron jobs and raw crontab files\nto be stored separately, and can be used to prevent the main\ndatabase from becoming excessively large.\n\nIf you would like to have Crab delete the history of job events over\na certain age, you can have it run a cleaning service by enabling the\n``[clean]`` section of the server configuration file.  Here you can\nselect the cleaning schedule and length of history to keep.  A fairly\nfrequent cleaning schedule is recommended to avoid the accumulation\nof a large number of old events so that each cleaning operation does\nnot take long.  If the file output store is being used, the cleaning\nservice will remove only the event records and not the output\ntext.  You can remove old output text separately, for example by running\nin your output store directory::\n\n    % find output -type f -mtime +90 -delete\n    % find output -type d -empty -delete\n\nRunning\n~~~~~~~\n\nThe Crab server is run as ``crabd``.  When the server\nis executed directly, it will stay in the foreground::\n\n    % crabd\n\nIt can also be run in the background with the ``crabd-check`` script,\nwhich checks that it is not still running from a previous invocation of\n``crabd-check``.  Therefore this is suitable for running from cron\nto keep the server running::\n\n    PYTHONPATH=/path/to/crab/lib\n    PATH=/path/to/crab/scripts:/bin:/usr/bin\n    7-57/10 * * * * CRABIGNORE=yes crabd-check\n\nWith the server running, the Crab dashboard should be visible from\na web browser, by default on port 8000.  The Crab clients will use this\nsame web service to communicate with the server.\n\nMigrating Job Information\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe Crab server has the ability to export and import cron job information,\nincluding:\n\n* The list of cron jobs.\n* The configuration and notifications attached to each job.\n* General host/user-based notifications.\n* Raw crontabs.\n\nYou can write this information to a JSON file using the ``--export``\noption::\n\n    % crabd --export job_information.json\n\nSimilarly you can read information with the ``--import`` option::\n\n    % crabd --import job_information.json\n\nThis merges the information from the file with the server's existing\nconfiguration.  You can also give a file name of ``-`` to export\nto standard output or read from standard input.\n\n.. endcrabserver\n\nMonitoring Cron Jobs\n--------------------\n\n.. startcrabclient\n\nThere are two Crab client commands: the ``crab`` utility, and\nthe ``crabsh`` wrapper shell.  Cron jobs can either be run under\n``crabsh``, or they can be updated to report their own status\nto the Crab server.\n\nConfiguration\n~~~~~~~~~~~~~\n\nThe Crab clients are configured by a ``crab.ini`` file which can\nbe placed either in ``/etc/crab/`` or ``~/.crab/``.  The file\nspecifies how to contact the Crab server, and the username and\nhostname which the client will use to report cron jobs. ::\n\n    % cp doc/crab.ini ~/.crab/\n\nThe configuration can be checked with the ``crab info`` command.\nThis reports the settings, and indicates which configuration\nfiles were read.  It is a useful way to check that everything\nis in order before importing a crontab.\n\nThe ``crabsh`` Wrapper\n~~~~~~~~~~~~~~~~~~~~~~\n\n``crabsh`` is a wrapper script designed to act like a shell.  It can\ntherefore be invoked by cron via the ``SHELL`` variable, for example::\n\n    PYTHONPATH=/path/to/crab/lib\n    SHELL=/path/to/crab/scripts/crabsh\n    0 10 * * 1-5 CRABID=test echo \"Test cron job\"\n\nWhere the rules following the ``SHELL`` assignment will be run with the\nwrapper.  The ``PYTHONPATH`` will need to be set if Crab is not installed\nwhere the system can find it.  Cron requires the full path when\nspecifying the ``SHELL``. The ``CRABID`` parameter is used to\ngive the cron job a convenient and unique name.  This is optional,\nunless there are multiple jobs with the same command,\nin which case they would otherwise be indistinguishable.\nHowever if it specified, then it must be unique for a given\nhost and user, as the Crab server will use it in preference\nto the command string to identify cron job reports.\n\n``crabsh`` will notify the server when the job starts, and when it finishes,\nassuming it succeeded if the exit status was zero.\n\nCrab-aware Cron Jobs\n~~~~~~~~~~~~~~~~~~~~\n\nAlternatively a cron job can report its own status to the Crab server.\nThe most straightforward way to do this is to execute the ``crab``\nutility.  So a cron job written as a shell script could include\ncommands such as::\n\n   % crab start -c \"$0\"\n   % crab finish -c \"$0\"\n   % crab fail -c \"$0\"\n\nIn this way you can also report a warning with ``crab warning`` or an\nunknown status with ``crab unknown``.\n\nPython\n    If the cron job is written in Python, it could import ``crab.client``\n    directly and make use of the ``CrabClient`` class.\n\nPerl\n    A Perl module `WWW::Crab::Client`_ is also available.\n\n.. _`WWW::Crab::Client`: http://search.cpan.org/perldoc?WWW::Crab::Client\n\nOther languages\n    Other language libraries could be written.  They would need to make\n    HTTP PUT requests with an appropriate JSON message.\n\nManaging the Cron Job List\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe Crab server needs to be given the schedule for each job so that it\ncan detect when a job is late or missed.  This is done by \"importing\"\na user's crontab file::\n\n    % crab import\n\nThe database entries can then be checked by \"exporting\" them,\nagain using the ``crab`` utility::\n\n    % crab export\n    > CRON_TZ=Pacific/Honolulu\n    > 0 10 * * 1-5 CRABID=test echo \"Test cron job\"\n\nThe output is a set of crontab-style lines representing the entries\nfrom the database.  The crontab can be retrieved exactly as last imported\n(from a separate database table containing the raw crontab) by giving\nthe ``--raw`` option as follows::\n\n    % crab export --raw\n\nThis is useful as a backup in case a crontab is accidentally lost.\nHowever it will not contain any new jobs which have been added automatically\nby the Crab server since the last import.\n\nCron Job Parameters\n~~~~~~~~~~~~~~~~~~~\n\nIn order to specify the Crab specific parameters of a cron job,\nBourne-style shell variables at the start of a command are used.\nThe syntax for each cron job is as follows::\n\n    <schedule> [CRABIGNORE=yes] [CRABID=<identifier>] <command string>\n\nA command starting with CRABIGNORE set to a value other than\n0/no/off/false will be ignored when importing a crontab,\nand ``crabsh`` will not report its status to the Crab server.\n\nA CRABID specification will override any CRABID environment variable\nin effect, and is a better way of specifying the identifier as it\ncan not apply to more than one cron job.  There should not be multiple\njobs with the same identifier for any user and host.\n\nThe Crab parameters can be placed in any order before the remainder of the\ncommand string, but they must precede any other variables.\n\nEnvironment Variables\n~~~~~~~~~~~~~~~~~~~~~\n\nCRABECHO\n    If present and not set to 0/no/off/false then ``crabsh`` will print out\n    the standard output and standard error it receives from the cron job.\n    This allows the output to be sent by email via cron's default\n    behavior as well as being captured by the Crab system.\n\nCRABHOME\n    If present overrides the Crab server home directory, where the\n    ``res`` and ``templ`` directories are to be found.\n\nCRABHOST\n    Specifies the Crab server to which clients should connect, overriding\n    the setting in the configuration file.\n\nCRABID\n    Specifies the job identifier which ``crabsh`` will use to file reports\n    if there is no ``CRABID=`` variable at the start of the cron command.\n    This should be used with caution to avoid specifying the same\n    identifier for multiple cron jobs.\n\nCRABIGNORE\n    Prevents Crab from acting on specific cron jobs.  Jobs imported\n    with this value present and not set to 0/no/off/false will not\n    be entered into the database.  Additionally if the ``crabsh``\n    wrapper script is used to run such a job, it will not report its\n    status to the Crab server.\n\nCRABPIDFILE\n    Gives the path to a PID file which ``crabsh`` should use to control\n    the execution of a cron job.  When this parameter is set, it will\n    use the file to try not to run multiple copies of the job at the\n    same time.  Each job should have a separate PID file, so this\n    parameter is most conveniently given at the start of a command string.\n\nCRABPORT\n    Specifies the port on the Crab server, overriding the setting in the\n    configuration file.\n\nCRABSHELL\n    The shell which ``crabsh`` will use to invoke the cron job command.\n    Defaults to ``/bin/sh`` regardless of the user's shell to replicate\n    cron's behavior.\n\nCRABSYSCONFIG\n    The directory to be searched for system-level configuration files.\n    If not set, then /etc/crab will be used.\n\nCRABUSERCONFIG\n    A directory to search for user-level configuration files.  If not\n    set then ~/.crab will be used.\n\nCRON_TZ\n    Cron reads this variable to know in which timezone to interpret\n    the crontab schedule.  When the server receives a crontab,\n    it will check for this timezone and use it to override the\n    general timezone which the ``crab`` utility will send with\n    the crontab (if it is able to determine it).\n\nMAILTO\n    Configures the email address to which cron sends email.  This is\n    useful when ``CRABECHO`` is on, or if ``crabsh`` needs to report\n    a failure to contact the Crab server.\n\nSHELL\n    Cron uses this variable to select the shell which will be used\n    to execute the cron jobs.  The full path must be specified.\n    Crab does not use this variable itself.\n\nTZ\n    This can be set to the system timezone, in which case ``crab import``\n    will use it as the default timezone for the crontab.\n\n\n.. endcrabclient\n.. startcrabweb\n\nThe Web Interface\n-----------------\n\nThe Crab dashboard allows the status of the jobs to be monitored.\nOn this page, the job status column will change color to indicate\nthe status, and it will flash while the job is running.  Clicking\non the status will lead to the most recent output recorded for\nthe job.\n\nThe host and user columns contain links leading to a summary page\nof the cron jobs for a given user or host.  From this page,\nthe links below each table can be used to show deleted jobs,\nand to display the raw crontab as last imported.\n\nClicking on a job ID or command link leads to the job information\npage, giving a summary of the job's parameters and a table of the\nmost recent events.  Clicking the status of any job finish\nevent leads to the corresponding output.\n\nJob Configuration\n~~~~~~~~~~~~~~~~~\n\nBelow the summary on the job information page, there is a link\nallowing the job's configuration to be edited.\nIf a job is deleted, then its configuration is considered to be\norphaned.  In this case, when configuring a job for which\nno configuration exists, the system will offer a list of\norphaned configurations for re-linking.  This should be used\nwhen the job is actually the continuation of a previous job.\nNote that notifications which are attached to specific jobs\nare linked via the configuration.  Therefore re-linking the\nconfiguration will re-attach all associated notifications.\n\nHowever this problem can generally be avoided by giving the jobs\nsuitable names via the ``CRABID`` parameter.  Crab will then be able\nto recognize jobs by name even if the command string changes.\n\nThe grace period\nspecifies how close to the scheduled time the job must start\nin order not to be considered missed.  The time-out is the\nmaximum expected duration of the job.  If it runs for longer\nthan this, it will be marked as stopped with timed-out (error) status.\nNote that the job may actually still be running when this status is\ndisplayed.  If the job is restarted, or reported as already running,\nduring the time-out period, then the time-out is reset.\nIf either of these timing parameters are left blank then the default\nvalues of 2 minutes grace period and 5 minutes time-out will be used.\n\nRegular expression patterns used to determine success or failure\nand to identify warnings can be given.  These patterns are compared\nto the standard output and standard error of the job when it finishes,\nbut do not override a more severe status.  For example if a job is reported\nas finishing with failure, then it will be logged as such even\nif the success or warning patterns match.  If none of the patterns\nmatch then the status is logged as it was reported, unless a\nsuccess pattern was defined.  If the success pattern does not match\nthen the status will be failure if the was no failure pattern\nor unknown if there was a failure pattern which did not match.\n\nThe \"Inhibit execution\" checkbox can be use to temporarily\nrequest that a job not be run.  This setting is stored in\nthe Crab server and passed to the client when it reports\nthat a job is being started.  Note that there is no guarantee\nthat the job will not be run while this option is selected: the\nclient could fail to connect to the server before\nstarting the job, or it could choose to ignore the\ninhibit setting.  The ``crabsh`` wrapper shell reads a\nconfiguration parameter ``allow_inhibit`` from the ``crabsh``\nsection of the ``cran.ini`` file to determine whether\ninhibit requests should be honored.  (The default value\nis true, i.e. it will not run the job if it receives the\ninhibit flag in response to its job starting message.)\n\nThe job configuration page also allows jobs to be marked as deleted.\nNormally this would be done by importing a new crontab without that\njob in it, but having this available on the web interface is useful\nin situations such as the host being inaccessible.  Note that\nif a start or finish event is received from the job, but the\nCrab server is still able to identify it, then the job\nshould be automatically marked as not deleted.\n\nThere is also the option to alter the job identifier.  However\ncare must be taken to also update it in the job itself, for\nexample via the ``CRABID`` parameter in the crontab.  If the\nidentifier is changed via the web server but not in the job,\nthen the Crab server will identify it as a new job the next time it\nreceives a start or finish report from it.\n\nNotifications\n~~~~~~~~~~~~~\n\nCrab includes a configurable notifications system, which currently\nsupports sending notification messages by email.  Notifications\ncan either be attached to a specific job, or configured\nby host name and/or by user name.\n\nA link below the summary on the job information page allows\nnotifications to be attached to that job.  Check-boxes\nfor each notification can be used to select which\nseverity of events should be featured, and whether the job\noutput should be included.  The schedule box should contain\na cron-style schedule specification (e.g. ``0 12 * * *``),\nand if left blank, will default to the value given in the\n``crabd.ini`` file, allowing all notification schedules to be\nmanaged in one place.  Notifications will only be sent if there\nare relevant events, so it is possible to request\nalmost-immediate error warnings by including a schedule of\n``* * * * *`` and selecting errors only.\n\nThe add and delete links can be used to\nadd and remove notifications, but the changes are not saved\nuntil the ``Configure`` button is clicked.\n\nThe drop-down menu which appears when the mouse is positioned\nover the Crab heading at the top of each page includes a link to\nthe main notifications page.  This allows notifications to be\nconfigured by host name and/or by user name.  Notifications\nwill include any jobs where the host and user match the specified\nvalues, but if either is left blank, then it will match all entries.\n\nAdditional Job Actions\n~~~~~~~~~~~~~~~~~~~~~~\n\nDepending on the state of a job, additional links may appear\nbelow the summary on the job information page.\nThese are:\n\n* \"Clear status\": this appears when the job is in a warning or\n  error state.\n  Selecting this option sets the job state to \"Cleared\",\n  which you can use to acknowledge the problem.\n  The job's status will then be shown in green on the dashboard.\n\n* \"Resume inhibited job\": this appears when the inhibit setting\n  has been selected on the job configuration page.\n  The link provides a convenient means of removing the\n  inhibit setting.\n\n.. endcrabweb\n\nScreenshots\n~~~~~~~~~~~\n\n* The dashboard page:\n\n    .. image:: http://grahambell.github.io/crab/img/screenshot-dashboard.png\n\n* View of cron jobs by host:\n\n    .. image:: http://grahambell.github.io/crab/img/screenshot-host.png\n\n* Information page for a cron job:\n\n    .. image:: http://grahambell.github.io/crab/img/screenshot-job.png\n\nCopyright\n---------\n\n| Copyright (C) 2012-2014 Science and Technology Facilities Council.\n| Copyright (C) 2015-2016 East Asian Observatory.\n\nCrab is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with Crab.  If not, see <http://www.gnu.org/licenses/>.\n\nAdditional Links\n----------------\n\n* `Crab entry on PyPI <https://pypi.python.org/pypi/crab>`_\n* `Documentation at Read the Docs <http://crab.readthedocs.org/en/latest/>`_\n* `Repository at GitHub <https://github.com/grahambell/crab>`_\n* `ADASS article about Crab <http://www.aspbooks.org/a/volumes/article_details/?paper_id=35592>`_", "description_content_type": null, "docs_url": null, "download_url": null, "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/grahambell/crab", "keywords": null, "license": "UNKNOWN", "maintainer": null, "maintainer_email": null, "name": "crab", "package_url": "https://pypi.org/project/crab/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/crab/", "project_urls": {"Homepage": "http://github.com/grahambell/crab"}, "release_url": "https://pypi.org/project/crab/0.5.0/", "requires_dist": null, "requires_python": null, "summary": "Cron alert board", "version": "0.5.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Crab is a dashboard system for monitoring cron jobs, or other scheduled\ntasks.  The Crab server receives messages when tasks start or finish,\nand displays the status of all of the tasks via a web interface.  It\ncan also send notifications by email, for example to warn if a task\nfails, is missed or does not complete within its time-out period.</p>\n<p>Tasks communicate with the Crab server by JSON messages sent by HTTP\nPUT requests.  The finish message includes the status of the job,\nand any output from it.  Further messages are used to import and\nexport the client\u2019s crontab, which the server uses to determine the\nintended schedule.</p>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<div id=\"packages\">\n<h3>Packages</h3>\n<ul>\n<li><a href=\"http://pypi.python.org/pypi/crontab/\" rel=\"nofollow\">crontab</a> (0.15 or newer)</li>\n<li><a href=\"http://www.cherrypy.org/\" rel=\"nofollow\">CherryPy</a> (<a href=\"http://pypi.python.org/pypi/CherryPy\" rel=\"nofollow\">PyPI entry</a>)</li>\n<li><a href=\"http://www.makotemplates.org/\" rel=\"nofollow\">Mako</a> (<a href=\"http://pypi.python.org/pypi/Mako/\" rel=\"nofollow\">PyPI entry</a>)</li>\n<li><a href=\"http://jquery.com/\" rel=\"nofollow\">jQuery</a></li>\n<li><a href=\"http://pypi.python.org/pypi/PyRSS2Gen/\" rel=\"nofollow\">PyRSS2Gen</a> (optional)</li>\n<li><a href=\"http://fortawesome.github.com/Font-Awesome\" rel=\"nofollow\">Font Awesome</a> (optional)</li>\n<li><a href=\"https://github.com/drudru/ansi_up\" rel=\"nofollow\">ansi_up</a> (optional)</li>\n<li><a href=\"http://dev.mysql.com/downloads/connector/python/\" rel=\"nofollow\">MySQL Connector</a> (needed only if using a MySQL database)</li>\n</ul>\n</div>\n<div id=\"python-version\">\n<h3>Python Version</h3>\n<dl>\n<dt>Crab server</dt>\n<dd>Has been tested on Python 2.6, 2.7 and 3.2.</dd>\n<dt>Client library and utilities</dt>\n<dd>Works with Python 2.4 in addition to the above versions (but\nmay require the <tt>pytz</tt> and <tt>simplejson</tt> packages also to be\ninstalled).</dd>\n</dl>\n</div>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>The Crab server, clients and libraries can be installed as follows:</p>\n<pre>python setup.py install\n</pre>\n<p>If necessary, the <tt><span class=\"pre\">--install-data</span></tt> option can be used to configure\nthe location in which the templates (<tt>templ</tt>), resources (<tt>res</tt>)\nand example files (<tt>doc</tt>) should be installed.</p>\n<p>To run Crab without installing it, and if any of the Python dependencies\nlisted above can not be installed, they can be symlinked into the <tt>lib</tt>\ndirectory in the following locations:</p>\n<pre>lib/PyRSS2Gen.py\nlib/cherrypy\nlib/crontab\nlib/mako\n</pre>\n<p>The jQuery JavaScript library should be copied or symlinked into\nCrab\u2019s <tt>res</tt> directory as:</p>\n<pre>res/jquery.js\n</pre>\n<p>To use Font Awesome icons, copy or symlink its <tt>fonts</tt> directory into\nCrab\u2019s <tt>res</tt> directory, and also place its stylesheet inside\nthat subdirectory, giving:</p>\n<pre>res/fonts/font-awesome.css\nres/fonts/fontawesome-webfont.*\n</pre>\n<p>Note that Font Awesome is not backward compatible between major\nversion numbers.  Crab now uses version 4 of Font Awesome.</p>\n<p>To use ansi_up to interpret ANSI color commands in cron job output,\ncopy or symlink the <tt>ansi_up.js</tt> file into Crab\u2019s <tt>res</tt> directory:</p>\n<pre>res/ansi_up.js\n</pre>\n</div>\n<div id=\"the-crab-server\">\n<h2>The Crab Server</h2>\n<div id=\"database-creation\">\n<h3>Database Creation</h3>\n<p>A SQLite database file can be prepared for Crab using the\nschema provided:</p>\n<pre>% sqlite3 crab.db &lt; doc/schema.sql\n</pre>\n<p>Alternatively if you are going to be using MySQL for your\nCrab database, create the database:</p>\n<pre>% mysqladmin -u root -p create crab\n</pre>\n<p>and create a user account for crab, changing the password\n(the \u201cidentified by\u201d clause) to something suitable:</p>\n<pre>% mysql -u root -p mysql\n&gt; create user 'crab'@'localhost' identified by 'crab';\n&gt; grant all on crab.* to 'crab'@'localhost';\n&gt; flush privileges;\n</pre>\n<p>You can prepare a table creation script suitable for MySQL\nusing the Makefile in the <cite>doc</cite> directory of the source package:</p>\n<pre>% make -C doc schema_mysql.sql\n% mysql -u crab -p crab &lt; doc/schema_mysql.sql\n</pre>\n</div>\n<div id=\"configuration\">\n<h3>Configuration</h3>\n<p>The Crab server is configured by a <tt>crabd.ini</tt> file which can\nbe placed either in <tt>/etc/crab/</tt> or <tt><span class=\"pre\">~/.crab/</span></tt>.  Note that this\nis a CherryPy configuration file, which is read slightly differently to\ntypical <tt>.ini</tt> files which use Python\u2019s ConfigParser.</p>\n<pre>% cp doc/crabd.ini ~/.crab/\n</pre>\n<p>The example <tt>crabd.ini</tt> file should be edited to uncomment the\n<tt>[crab]</tt> and <tt>[store]</tt> sections.  The <tt>home</tt> and <tt>file</tt> entries\nmust point to the location of Crab\u2019s data files and the database file\njust created.  By default the data files are installed in <tt>share/crab</tt>\nrelative to the Python system prefix (<tt>sys.prefix</tt>).</p>\n<p>There is also an <tt>[outputstore]</tt> section in the server configuration\nfile.  This allows the output from cron jobs and raw crontab files\nto be stored separately, and can be used to prevent the main\ndatabase from becoming excessively large.</p>\n<p>If you would like to have Crab delete the history of job events over\na certain age, you can have it run a cleaning service by enabling the\n<tt>[clean]</tt> section of the server configuration file.  Here you can\nselect the cleaning schedule and length of history to keep.  A fairly\nfrequent cleaning schedule is recommended to avoid the accumulation\nof a large number of old events so that each cleaning operation does\nnot take long.  If the file output store is being used, the cleaning\nservice will remove only the event records and not the output\ntext.  You can remove old output text separately, for example by running\nin your output store directory:</p>\n<pre>% find output -type f -mtime +90 -delete\n% find output -type d -empty -delete\n</pre>\n</div>\n<div id=\"running\">\n<h3>Running</h3>\n<p>The Crab server is run as <tt>crabd</tt>.  When the server\nis executed directly, it will stay in the foreground:</p>\n<pre>% crabd\n</pre>\n<p>It can also be run in the background with the <tt><span class=\"pre\">crabd-check</span></tt> script,\nwhich checks that it is not still running from a previous invocation of\n<tt><span class=\"pre\">crabd-check</span></tt>.  Therefore this is suitable for running from cron\nto keep the server running:</p>\n<pre>PYTHONPATH=/path/to/crab/lib\nPATH=/path/to/crab/scripts:/bin:/usr/bin\n7-57/10 * * * * CRABIGNORE=yes crabd-check\n</pre>\n<p>With the server running, the Crab dashboard should be visible from\na web browser, by default on port 8000.  The Crab clients will use this\nsame web service to communicate with the server.</p>\n</div>\n<div id=\"migrating-job-information\">\n<h3>Migrating Job Information</h3>\n<p>The Crab server has the ability to export and import cron job information,\nincluding:</p>\n<ul>\n<li>The list of cron jobs.</li>\n<li>The configuration and notifications attached to each job.</li>\n<li>General host/user-based notifications.</li>\n<li>Raw crontabs.</li>\n</ul>\n<p>You can write this information to a JSON file using the <tt><span class=\"pre\">--export</span></tt>\noption:</p>\n<pre>% crabd --export job_information.json\n</pre>\n<p>Similarly you can read information with the <tt><span class=\"pre\">--import</span></tt> option:</p>\n<pre>% crabd --import job_information.json\n</pre>\n<p>This merges the information from the file with the server\u2019s existing\nconfiguration.  You can also give a file name of <tt>-</tt> to export\nto standard output or read from standard input.</p>\n</div>\n</div>\n<div id=\"monitoring-cron-jobs\">\n<h2>Monitoring Cron Jobs</h2>\n<p>There are two Crab client commands: the <tt>crab</tt> utility, and\nthe <tt>crabsh</tt> wrapper shell.  Cron jobs can either be run under\n<tt>crabsh</tt>, or they can be updated to report their own status\nto the Crab server.</p>\n<div id=\"id1\">\n<h3>Configuration</h3>\n<p>The Crab clients are configured by a <tt>crab.ini</tt> file which can\nbe placed either in <tt>/etc/crab/</tt> or <tt><span class=\"pre\">~/.crab/</span></tt>.  The file\nspecifies how to contact the Crab server, and the username and\nhostname which the client will use to report cron jobs.</p>\n<pre>% cp doc/crab.ini ~/.crab/\n</pre>\n<p>The configuration can be checked with the <tt>crab info</tt> command.\nThis reports the settings, and indicates which configuration\nfiles were read.  It is a useful way to check that everything\nis in order before importing a crontab.</p>\n</div>\n<div id=\"the-crabsh-wrapper\">\n<h3>The <tt>crabsh</tt> Wrapper</h3>\n<p><tt>crabsh</tt> is a wrapper script designed to act like a shell.  It can\ntherefore be invoked by cron via the <tt>SHELL</tt> variable, for example:</p>\n<pre>PYTHONPATH=/path/to/crab/lib\nSHELL=/path/to/crab/scripts/crabsh\n0 10 * * 1-5 CRABID=test echo \"Test cron job\"\n</pre>\n<p>Where the rules following the <tt>SHELL</tt> assignment will be run with the\nwrapper.  The <tt>PYTHONPATH</tt> will need to be set if Crab is not installed\nwhere the system can find it.  Cron requires the full path when\nspecifying the <tt>SHELL</tt>. The <tt>CRABID</tt> parameter is used to\ngive the cron job a convenient and unique name.  This is optional,\nunless there are multiple jobs with the same command,\nin which case they would otherwise be indistinguishable.\nHowever if it specified, then it must be unique for a given\nhost and user, as the Crab server will use it in preference\nto the command string to identify cron job reports.</p>\n<p><tt>crabsh</tt> will notify the server when the job starts, and when it finishes,\nassuming it succeeded if the exit status was zero.</p>\n</div>\n<div id=\"crab-aware-cron-jobs\">\n<h3>Crab-aware Cron Jobs</h3>\n<p>Alternatively a cron job can report its own status to the Crab server.\nThe most straightforward way to do this is to execute the <tt>crab</tt>\nutility.  So a cron job written as a shell script could include\ncommands such as:</p>\n<pre>% crab start -c \"$0\"\n% crab finish -c \"$0\"\n% crab fail -c \"$0\"\n</pre>\n<p>In this way you can also report a warning with <tt>crab warning</tt> or an\nunknown status with <tt>crab unknown</tt>.</p>\n<dl>\n<dt>Python</dt>\n<dd>If the cron job is written in Python, it could import <tt>crab.client</tt>\ndirectly and make use of the <tt>CrabClient</tt> class.</dd>\n<dt>Perl</dt>\n<dd>A Perl module <a href=\"http://search.cpan.org/perldoc?WWW::Crab::Client\" rel=\"nofollow\">WWW::Crab::Client</a> is also available.</dd>\n</dl>\n<dl>\n<dt>Other languages</dt>\n<dd>Other language libraries could be written.  They would need to make\nHTTP PUT requests with an appropriate JSON message.</dd>\n</dl>\n</div>\n<div id=\"managing-the-cron-job-list\">\n<h3>Managing the Cron Job List</h3>\n<p>The Crab server needs to be given the schedule for each job so that it\ncan detect when a job is late or missed.  This is done by \u201cimporting\u201d\na user\u2019s crontab file:</p>\n<pre>% crab import\n</pre>\n<p>The database entries can then be checked by \u201cexporting\u201d them,\nagain using the <tt>crab</tt> utility:</p>\n<pre>% crab export\n&gt; CRON_TZ=Pacific/Honolulu\n&gt; 0 10 * * 1-5 CRABID=test echo \"Test cron job\"\n</pre>\n<p>The output is a set of crontab-style lines representing the entries\nfrom the database.  The crontab can be retrieved exactly as last imported\n(from a separate database table containing the raw crontab) by giving\nthe <tt><span class=\"pre\">--raw</span></tt> option as follows:</p>\n<pre>% crab export --raw\n</pre>\n<p>This is useful as a backup in case a crontab is accidentally lost.\nHowever it will not contain any new jobs which have been added automatically\nby the Crab server since the last import.</p>\n</div>\n<div id=\"cron-job-parameters\">\n<h3>Cron Job Parameters</h3>\n<p>In order to specify the Crab specific parameters of a cron job,\nBourne-style shell variables at the start of a command are used.\nThe syntax for each cron job is as follows:</p>\n<pre>&lt;schedule&gt; [CRABIGNORE=yes] [CRABID=&lt;identifier&gt;] &lt;command string&gt;\n</pre>\n<p>A command starting with CRABIGNORE set to a value other than\n0/no/off/false will be ignored when importing a crontab,\nand <tt>crabsh</tt> will not report its status to the Crab server.</p>\n<p>A CRABID specification will override any CRABID environment variable\nin effect, and is a better way of specifying the identifier as it\ncan not apply to more than one cron job.  There should not be multiple\njobs with the same identifier for any user and host.</p>\n<p>The Crab parameters can be placed in any order before the remainder of the\ncommand string, but they must precede any other variables.</p>\n</div>\n<div id=\"environment-variables\">\n<h3>Environment Variables</h3>\n<dl>\n<dt>CRABECHO</dt>\n<dd>If present and not set to 0/no/off/false then <tt>crabsh</tt> will print out\nthe standard output and standard error it receives from the cron job.\nThis allows the output to be sent by email via cron\u2019s default\nbehavior as well as being captured by the Crab system.</dd>\n<dt>CRABHOME</dt>\n<dd>If present overrides the Crab server home directory, where the\n<tt>res</tt> and <tt>templ</tt> directories are to be found.</dd>\n<dt>CRABHOST</dt>\n<dd>Specifies the Crab server to which clients should connect, overriding\nthe setting in the configuration file.</dd>\n<dt>CRABID</dt>\n<dd>Specifies the job identifier which <tt>crabsh</tt> will use to file reports\nif there is no <tt>CRABID=</tt> variable at the start of the cron command.\nThis should be used with caution to avoid specifying the same\nidentifier for multiple cron jobs.</dd>\n<dt>CRABIGNORE</dt>\n<dd>Prevents Crab from acting on specific cron jobs.  Jobs imported\nwith this value present and not set to 0/no/off/false will not\nbe entered into the database.  Additionally if the <tt>crabsh</tt>\nwrapper script is used to run such a job, it will not report its\nstatus to the Crab server.</dd>\n<dt>CRABPIDFILE</dt>\n<dd>Gives the path to a PID file which <tt>crabsh</tt> should use to control\nthe execution of a cron job.  When this parameter is set, it will\nuse the file to try not to run multiple copies of the job at the\nsame time.  Each job should have a separate PID file, so this\nparameter is most conveniently given at the start of a command string.</dd>\n<dt>CRABPORT</dt>\n<dd>Specifies the port on the Crab server, overriding the setting in the\nconfiguration file.</dd>\n<dt>CRABSHELL</dt>\n<dd>The shell which <tt>crabsh</tt> will use to invoke the cron job command.\nDefaults to <tt>/bin/sh</tt> regardless of the user\u2019s shell to replicate\ncron\u2019s behavior.</dd>\n<dt>CRABSYSCONFIG</dt>\n<dd>The directory to be searched for system-level configuration files.\nIf not set, then /etc/crab will be used.</dd>\n<dt>CRABUSERCONFIG</dt>\n<dd>A directory to search for user-level configuration files.  If not\nset then ~/.crab will be used.</dd>\n<dt>CRON_TZ</dt>\n<dd>Cron reads this variable to know in which timezone to interpret\nthe crontab schedule.  When the server receives a crontab,\nit will check for this timezone and use it to override the\ngeneral timezone which the <tt>crab</tt> utility will send with\nthe crontab (if it is able to determine it).</dd>\n<dt>MAILTO</dt>\n<dd>Configures the email address to which cron sends email.  This is\nuseful when <tt>CRABECHO</tt> is on, or if <tt>crabsh</tt> needs to report\na failure to contact the Crab server.</dd>\n<dt>SHELL</dt>\n<dd>Cron uses this variable to select the shell which will be used\nto execute the cron jobs.  The full path must be specified.\nCrab does not use this variable itself.</dd>\n<dt>TZ</dt>\n<dd>This can be set to the system timezone, in which case <tt>crab import</tt>\nwill use it as the default timezone for the crontab.</dd>\n</dl>\n</div>\n</div>\n<div id=\"the-web-interface\">\n<h2>The Web Interface</h2>\n<p>The Crab dashboard allows the status of the jobs to be monitored.\nOn this page, the job status column will change color to indicate\nthe status, and it will flash while the job is running.  Clicking\non the status will lead to the most recent output recorded for\nthe job.</p>\n<p>The host and user columns contain links leading to a summary page\nof the cron jobs for a given user or host.  From this page,\nthe links below each table can be used to show deleted jobs,\nand to display the raw crontab as last imported.</p>\n<p>Clicking on a job ID or command link leads to the job information\npage, giving a summary of the job\u2019s parameters and a table of the\nmost recent events.  Clicking the status of any job finish\nevent leads to the corresponding output.</p>\n<div id=\"job-configuration\">\n<h3>Job Configuration</h3>\n<p>Below the summary on the job information page, there is a link\nallowing the job\u2019s configuration to be edited.\nIf a job is deleted, then its configuration is considered to be\norphaned.  In this case, when configuring a job for which\nno configuration exists, the system will offer a list of\norphaned configurations for re-linking.  This should be used\nwhen the job is actually the continuation of a previous job.\nNote that notifications which are attached to specific jobs\nare linked via the configuration.  Therefore re-linking the\nconfiguration will re-attach all associated notifications.</p>\n<p>However this problem can generally be avoided by giving the jobs\nsuitable names via the <tt>CRABID</tt> parameter.  Crab will then be able\nto recognize jobs by name even if the command string changes.</p>\n<p>The grace period\nspecifies how close to the scheduled time the job must start\nin order not to be considered missed.  The time-out is the\nmaximum expected duration of the job.  If it runs for longer\nthan this, it will be marked as stopped with timed-out (error) status.\nNote that the job may actually still be running when this status is\ndisplayed.  If the job is restarted, or reported as already running,\nduring the time-out period, then the time-out is reset.\nIf either of these timing parameters are left blank then the default\nvalues of 2 minutes grace period and 5 minutes time-out will be used.</p>\n<p>Regular expression patterns used to determine success or failure\nand to identify warnings can be given.  These patterns are compared\nto the standard output and standard error of the job when it finishes,\nbut do not override a more severe status.  For example if a job is reported\nas finishing with failure, then it will be logged as such even\nif the success or warning patterns match.  If none of the patterns\nmatch then the status is logged as it was reported, unless a\nsuccess pattern was defined.  If the success pattern does not match\nthen the status will be failure if the was no failure pattern\nor unknown if there was a failure pattern which did not match.</p>\n<p>The \u201cInhibit execution\u201d checkbox can be use to temporarily\nrequest that a job not be run.  This setting is stored in\nthe Crab server and passed to the client when it reports\nthat a job is being started.  Note that there is no guarantee\nthat the job will not be run while this option is selected: the\nclient could fail to connect to the server before\nstarting the job, or it could choose to ignore the\ninhibit setting.  The <tt>crabsh</tt> wrapper shell reads a\nconfiguration parameter <tt>allow_inhibit</tt> from the <tt>crabsh</tt>\nsection of the <tt>cran.ini</tt> file to determine whether\ninhibit requests should be honored.  (The default value\nis true, i.e. it will not run the job if it receives the\ninhibit flag in response to its job starting message.)</p>\n<p>The job configuration page also allows jobs to be marked as deleted.\nNormally this would be done by importing a new crontab without that\njob in it, but having this available on the web interface is useful\nin situations such as the host being inaccessible.  Note that\nif a start or finish event is received from the job, but the\nCrab server is still able to identify it, then the job\nshould be automatically marked as not deleted.</p>\n<p>There is also the option to alter the job identifier.  However\ncare must be taken to also update it in the job itself, for\nexample via the <tt>CRABID</tt> parameter in the crontab.  If the\nidentifier is changed via the web server but not in the job,\nthen the Crab server will identify it as a new job the next time it\nreceives a start or finish report from it.</p>\n</div>\n<div id=\"notifications\">\n<h3>Notifications</h3>\n<p>Crab includes a configurable notifications system, which currently\nsupports sending notification messages by email.  Notifications\ncan either be attached to a specific job, or configured\nby host name and/or by user name.</p>\n<p>A link below the summary on the job information page allows\nnotifications to be attached to that job.  Check-boxes\nfor each notification can be used to select which\nseverity of events should be featured, and whether the job\noutput should be included.  The schedule box should contain\na cron-style schedule specification (e.g. <tt>0 12 * * *</tt>),\nand if left blank, will default to the value given in the\n<tt>crabd.ini</tt> file, allowing all notification schedules to be\nmanaged in one place.  Notifications will only be sent if there\nare relevant events, so it is possible to request\nalmost-immediate error warnings by including a schedule of\n<tt>* * * * *</tt> and selecting errors only.</p>\n<p>The add and delete links can be used to\nadd and remove notifications, but the changes are not saved\nuntil the <tt>Configure</tt> button is clicked.</p>\n<p>The drop-down menu which appears when the mouse is positioned\nover the Crab heading at the top of each page includes a link to\nthe main notifications page.  This allows notifications to be\nconfigured by host name and/or by user name.  Notifications\nwill include any jobs where the host and user match the specified\nvalues, but if either is left blank, then it will match all entries.</p>\n</div>\n<div id=\"additional-job-actions\">\n<h3>Additional Job Actions</h3>\n<p>Depending on the state of a job, additional links may appear\nbelow the summary on the job information page.\nThese are:</p>\n<ul>\n<li>\u201cClear status\u201d: this appears when the job is in a warning or\nerror state.\nSelecting this option sets the job state to \u201cCleared\u201d,\nwhich you can use to acknowledge the problem.\nThe job\u2019s status will then be shown in green on the dashboard.</li>\n<li>\u201cResume inhibited job\u201d: this appears when the inhibit setting\nhas been selected on the job configuration page.\nThe link provides a convenient means of removing the\ninhibit setting.</li>\n</ul>\n</div>\n<div id=\"screenshots\">\n<h3>Screenshots</h3>\n<ul>\n<li><p>The dashboard page:</p>\n<blockquote>\n<img alt=\"http://grahambell.github.io/crab/img/screenshot-dashboard.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7de9a66a591a46a1f8350ed18855f6e755b2c0e8/687474703a2f2f67726168616d62656c6c2e6769746875622e696f2f637261622f696d672f73637265656e73686f742d64617368626f6172642e706e67\">\n</blockquote>\n</li>\n<li><p>View of cron jobs by host:</p>\n<blockquote>\n<img alt=\"http://grahambell.github.io/crab/img/screenshot-host.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/69af2094fac149bfe0e11875f6dcf4b122772c3b/687474703a2f2f67726168616d62656c6c2e6769746875622e696f2f637261622f696d672f73637265656e73686f742d686f73742e706e67\">\n</blockquote>\n</li>\n<li><p>Information page for a cron job:</p>\n<blockquote>\n<img alt=\"http://grahambell.github.io/crab/img/screenshot-job.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/598ff2c491c1c067736d7b4223dcda3548943ad3/687474703a2f2f67726168616d62656c6c2e6769746875622e696f2f637261622f696d672f73637265656e73686f742d6a6f622e706e67\">\n</blockquote>\n</li>\n</ul>\n</div>\n</div>\n<div id=\"copyright\">\n<h2>Copyright</h2>\n<div>\n<div>Copyright (C) 2012-2014 Science and Technology Facilities Council.</div>\n<div>Copyright (C) 2015-2016 East Asian Observatory.</div>\n</div>\n<p>Crab is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.</p>\n<p>This program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.</p>\n<p>You should have received a copy of the GNU General Public License\nalong with Crab.  If not, see &lt;<a href=\"http://www.gnu.org/licenses/\" rel=\"nofollow\">http://www.gnu.org/licenses/</a>&gt;.</p>\n</div>\n<div id=\"additional-links\">\n<h2>Additional Links</h2>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/crab\" rel=\"nofollow\">Crab entry on PyPI</a></li>\n<li><a href=\"http://crab.readthedocs.org/en/latest/\" rel=\"nofollow\">Documentation at Read the Docs</a></li>\n<li><a href=\"https://github.com/grahambell/crab\" rel=\"nofollow\">Repository at GitHub</a></li>\n<li><a href=\"http://www.aspbooks.org/a/volumes/article_details/?paper_id=35592\" rel=\"nofollow\">ADASS article about Crab</a></li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 2015108, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "93c35f382daeb548bd5b7586487c4bd7", "sha256": "e36a3e0bd04f0548a5f6a6c4e8a2275214add985e5f0b50b3ce74b57e56f4619"}, "downloads": -1, "filename": "crab-0.1.0.tar.gz", "has_sig": false, "md5_digest": "93c35f382daeb548bd5b7586487c4bd7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56669, "upload_time": "2012-10-05T18:54:59", "upload_time_iso_8601": "2012-10-05T18:54:59.673106Z", "url": "https://files.pythonhosted.org/packages/1a/18/8f99c9be524b0498d05c6691a25128ef265f2caea116b76c1085bd76e088/crab-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "f72e5014602cd60d00a93dd1c0edad79", "sha256": "9a044fadaf704efa831102e29c0aefb300194afe853ae94ab3ad1c212687476d"}, "downloads": -1, "filename": "crab-0.2.0.tar.gz", "has_sig": false, "md5_digest": "f72e5014602cd60d00a93dd1c0edad79", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 60690, "upload_time": "2012-10-17T22:42:03", "upload_time_iso_8601": "2012-10-17T22:42:03.732350Z", "url": "https://files.pythonhosted.org/packages/56/d7/efcd07c5da3106ff4432fd234909569954f66eec1e8e2f2e32d05aaf7776/crab-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "4cf07bf8e602d60f37229acf57b5bdf0", "sha256": "43562052806414c9d37d1d380b4ad0c20491260b978eda51142bee24b9b289f2"}, "downloads": -1, "filename": "crab-0.3.0.tar.gz", "has_sig": false, "md5_digest": "4cf07bf8e602d60f37229acf57b5bdf0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63793, "upload_time": "2013-03-29T01:01:50", "upload_time_iso_8601": "2013-03-29T01:01:50.693920Z", "url": "https://files.pythonhosted.org/packages/87/8e/dd3bb52bc359178276c9bf3b3d08f19e55e8dda35171cad736e1868f250e/crab-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "791207a10076ddbb0be04e144219143a", "sha256": "fc4e27b09228e4c756c32f474000263071da67b68daacd93d947814011cc6487"}, "downloads": -1, "filename": "crab-0.4.0.tar.gz", "has_sig": false, "md5_digest": "791207a10076ddbb0be04e144219143a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66509, "upload_time": "2013-08-30T00:30:16", "upload_time_iso_8601": "2013-08-30T00:30:16.006505Z", "url": "https://files.pythonhosted.org/packages/e8/58/3a0be4f4ef4cf7568307d0b9634ffca1bb70e2f1ad96f37145d6853043dd/crab-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "be261eb1e59723ba5f25edf41feb89c4", "sha256": "6a33514ca61c18fd547bbe5687cd636f58f2d214a698fbe91cac2c10cef68a0b"}, "downloads": -1, "filename": "crab-0.4.1.tar.gz", "has_sig": false, "md5_digest": "be261eb1e59723ba5f25edf41feb89c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66571, "upload_time": "2013-09-04T19:48:51", "upload_time_iso_8601": "2013-09-04T19:48:51.397464Z", "url": "https://files.pythonhosted.org/packages/e1/61/1c54830e1cb4aee169bf439b57881f9fb3b41f450137b707a79e03704bdb/crab-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "a3283eb90d02cf80006177fd4f070c66", "sha256": "246a36cc22da843e76a1fdf1955c48d3acfc5e18e94c7a9317e9a42f28a6fc91"}, "downloads": -1, "filename": "crab-0.4.2.tar.gz", "has_sig": false, "md5_digest": "a3283eb90d02cf80006177fd4f070c66", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 67500, "upload_time": "2014-02-22T01:11:54", "upload_time_iso_8601": "2014-02-22T01:11:54.020685Z", "url": "https://files.pythonhosted.org/packages/79/22/3177eb5468bcbb42d0427f6bc83ee90b8a678fcb9789d09ec7925a5946a5/crab-0.4.2.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "5ba9929c3803768d4ce66c5962d9486b", "sha256": "6471f9963e61e2d67b7e1f4dff60dbdf5199a83ebbd3951782be32f413695c57"}, "downloads": -1, "filename": "crab-0.5.0.tar.gz", "has_sig": false, "md5_digest": "5ba9929c3803768d4ce66c5962d9486b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 80877, "upload_time": "2016-01-27T21:50:15", "upload_time_iso_8601": "2016-01-27T21:50:15.006646Z", "url": "https://files.pythonhosted.org/packages/3d/22/b86638693dd458b0e19243cd2d1180045ef88d3838d8353226afa2c6115e/crab-0.5.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5ba9929c3803768d4ce66c5962d9486b", "sha256": "6471f9963e61e2d67b7e1f4dff60dbdf5199a83ebbd3951782be32f413695c57"}, "downloads": -1, "filename": "crab-0.5.0.tar.gz", "has_sig": false, "md5_digest": "5ba9929c3803768d4ce66c5962d9486b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 80877, "upload_time": "2016-01-27T21:50:15", "upload_time_iso_8601": "2016-01-27T21:50:15.006646Z", "url": "https://files.pythonhosted.org/packages/3d/22/b86638693dd458b0e19243cd2d1180045ef88d3838d8353226afa2c6115e/crab-0.5.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:31 2020"}