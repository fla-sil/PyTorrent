{"info": {"author": "Carlos E. Rodriguez", "author_email": "crodriguez1a@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "Interview Alexa\n===============\n\nA Python Testing Framework for Alexa using ASK CLI\n\nTypical usage:\n\n    import unittest\n    from interview_alexa import say\n\n\n    class TestingAllTheThings(unittest.TestCase):\n\n        @say('open my skill')\n        def test_launch_intent(self, result):\n            self.assertEqual(result, 'My expected result')\n\n\tif __name__ == '__main__':\n    unittest.main()\n\nPrerequisites\n=============\n\n* Install ``node``\n  * <https://nodejs.org/en/download/package-manager/>\n\n* Install and initialize ``ask-cli``\n\t* <https://developer.amazon.com/docs/smapi/quick-start-alexa-skills-kit-command-line-interface.html>\n\n    \tnpm install -g ask-cli\n    \task init\n\n* Follow the ``ask-cli`` prompts\n\n* Export environment variables:\n\n    \texport SKILL_ID=amzn1.ask.skill.12345\n    \texport ASK_DEFAULT_DEVICE_LOCALE=en-US\n\n* Clone your existing Alexa skill:\n\n    \task clone echo SKILL_ID\n\n\n\nUsage\n=====\n\nInside the directory of your cloned skill, create a file called ``tests.py``\n\n\n\t\tproject\n\t\t\u2502\n\t\t\u2514\u2500\u2500\u2500My_Cloned_Skill\n\t\t\t\u2502\n\t\t\t\u2514\u2500\u2500\u2500tests.py\n\n\n**Writing Tests:**\n\n\n\t\timport unittest\n\t\tfrom interview_alexa import say\n\n\n\t\tclass TestingAllTheThings(unittest.TestCase):\n\n\t\t    @say('open my skill')\n\t\t    def test_launch_intent(self, result):\n\t\t        self.assertEqual(result, \"My expected result\")\n\n\n\t\tif __name__ == '__main__':\n\t\t    unittest.main()\n\n\n**Options:**\n\n- **`debug=True`**\n\n\t\t@say('open my skill', debug=True)\n\t\tdef test_launch_intent(self, result):\n\t\t    self.assertEqual(result, \"My expected result\")\n\n\t\t    # => will produce a verbose output from ask-cli\n\n\n**Simple Testing**:\n\n\n\t\tcd My_Skill\n\t\tpython tests.py\n\n--\n\n\t\tA passing test would output something like:\n\n\t\t\u2713 Simulation created for simulation id: 1234-5679-910112-abc-123\n\t\t\u25e0 Waiting for simulation response.\n\t\t----------------------------------------------------------------------\n\t\tRan 1 test in 5.848s\n\n\t\tOK\n\n**Dialog Testing**\n\nSince the Python test runner executes tests alphabetical by test name, you'll want to ensure that any tests that simulate dialog are named alphabetically.\n\n\t\t@say('open my skill')\n\t\tdef test_aa__begin_dialog(self, result):\n\t\t    self.assertEqual(result, \"My expected result\")\n\n\t\t@say('do something with my skill')\n\t\tdef test_ab__continue_dialog(self, result):\n\t\t    self.assertEqual(result, \"My expected result\")\n\n\nIf the expected result is a delegated dialog, your response may not include any output speech. In that case, you may want to ``pass``:\n\n\t\t@say('do something with my skill')\n\t\tdef test_ac__delegated_dialog(self, result):\n\t\t    pass\n\n\n**Local Testing**\n\nThis package takes advantage of a another great package called ``python-lambda-local`` to run tests locally.\n\nIn order to do so, we use ``ask-cli`` to record your request events, and ``python-lambda-local`` to test against recorded events.\n\nFirst, make sure to import the record and localize functions. Then run record in your tests module's ``setUp`` method:\n\n    import unittest\n    from interview_alexa import say, record, localize\n\n\n    class TestingAllTheThings(unittest.TestCase):\n\n        def setUp(self):\n        record(self)\n\n        @say('open my skill')\n        def test_aa__launch_intent(self, result):\n            self.assertEqual(result, 'My expected result')\n\n        ...\n\nOnce you've run your test with **record mode** on, you should see a ``tmp`` folder in your working directory with some JSON files with the same names as your tests.\n\n\n\t\tproject\n\t\t\u2502\n\t\t\u2514\u2500\u2500\u2500My_Cloned_Skill\n\t\t\t\u2502\n\t\t\t\u2514\u2500\u2500\u2500tests.py\n\t\t\t\u2502\n\t\t\t\u2514\u2500\u2500\u2500tmp\n\t\t\t  \u2502\n\t\t\t  \u2514\u2500\u2500\u2500__main__.TestingAllTheThings.test_aa.json\n\n\n\nNow that you have some events recorded locally, you can run your tests in **localize mode**, and run your tests again with ``python tests.py`` as you normally would.\n\n\n    import unittest\n    from interview_alexa import say, record, localize\n\n\n    class TestingAllTheThings(unittest.TestCase):\n\n        def setUp(self):\n            # record(self)\n            localize(self)\n\n        ...\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://pypi.python.org/pypi/InterviewAlexa/", "keywords": "alexa aws aws-cli lambda lex", "license": "LICENSE.txt", "maintainer": "", "maintainer_email": "", "name": "InterviewAlexa", "package_url": "https://pypi.org/project/InterviewAlexa/", "platform": "", "project_url": "https://pypi.org/project/InterviewAlexa/", "project_urls": {"Homepage": "http://pypi.python.org/pypi/InterviewAlexa/"}, "release_url": "https://pypi.org/project/InterviewAlexa/0.1.0/", "requires_dist": ["python-lambda-local (>=0.1.5)"], "requires_python": "", "summary": "A Python Testing Framework for Alexa using ASK CLI", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            Interview Alexa<br>===============<br><br>A Python Testing Framework for Alexa using ASK CLI<br><br>Typical usage:<br><br>    import unittest<br>    from interview_alexa import say<br><br><br>    class TestingAllTheThings(unittest.TestCase):<br><br>        @say('open my skill')<br>        def test_launch_intent(self, result):<br>            self.assertEqual(result, 'My expected result')<br><br>\tif __name__ == '__main__':<br>    unittest.main()<br><br>Prerequisites<br>=============<br><br>* Install ``node``<br>  * &lt;https://nodejs.org/en/download/package-manager/&gt;<br><br>* Install and initialize ``ask-cli``<br>\t* &lt;https://developer.amazon.com/docs/smapi/quick-start-alexa-skills-kit-command-line-interface.html&gt;<br><br>    \tnpm install -g ask-cli<br>    \task init<br><br>* Follow the ``ask-cli`` prompts<br><br>* Export environment variables:<br><br>    \texport SKILL_ID=amzn1.ask.skill.12345<br>    \texport ASK_DEFAULT_DEVICE_LOCALE=en-US<br><br>* Clone your existing Alexa skill:<br><br>    \task clone echo SKILL_ID<br><br><br><br>Usage<br>=====<br><br>Inside the directory of your cloned skill, create a file called ``tests.py``<br><br><br>\t\tproject<br>\t\t\u2502<br>\t\t\u2514\u2500\u2500\u2500My_Cloned_Skill<br>\t\t\t\u2502<br>\t\t\t\u2514\u2500\u2500\u2500tests.py<br><br><br>**Writing Tests:**<br><br><br>\t\timport unittest<br>\t\tfrom interview_alexa import say<br><br><br>\t\tclass TestingAllTheThings(unittest.TestCase):<br><br>\t\t    @say('open my skill')<br>\t\t    def test_launch_intent(self, result):<br>\t\t        self.assertEqual(result, \"My expected result\")<br><br><br>\t\tif __name__ == '__main__':<br>\t\t    unittest.main()<br><br><br>**Options:**<br><br>- **`debug=True`**<br><br>\t\t@say('open my skill', debug=True)<br>\t\tdef test_launch_intent(self, result):<br>\t\t    self.assertEqual(result, \"My expected result\")<br><br>\t\t    # =&gt; will produce a verbose output from ask-cli<br><br><br>**Simple Testing**:<br><br><br>\t\tcd My_Skill<br>\t\tpython tests.py<br><br>--<br><br>\t\tA passing test would output something like:<br><br>\t\t\u2713 Simulation created for simulation id: 1234-5679-910112-abc-123<br>\t\t\u25e0 Waiting for simulation response.<br>\t\t----------------------------------------------------------------------<br>\t\tRan 1 test in 5.848s<br><br>\t\tOK<br><br>**Dialog Testing**<br><br>Since the Python test runner executes tests alphabetical by test name, you'll want to ensure that any tests that simulate dialog are named alphabetically.<br><br>\t\t@say('open my skill')<br>\t\tdef test_aa__begin_dialog(self, result):<br>\t\t    self.assertEqual(result, \"My expected result\")<br><br>\t\t@say('do something with my skill')<br>\t\tdef test_ab__continue_dialog(self, result):<br>\t\t    self.assertEqual(result, \"My expected result\")<br><br><br>If the expected result is a delegated dialog, your response may not include any output speech. In that case, you may want to ``pass``:<br><br>\t\t@say('do something with my skill')<br>\t\tdef test_ac__delegated_dialog(self, result):<br>\t\t    pass<br><br><br>**Local Testing**<br><br>This package takes advantage of a another great package called ``python-lambda-local`` to run tests locally.<br><br>In order to do so, we use ``ask-cli`` to record your request events, and ``python-lambda-local`` to test against recorded events.<br><br>First, make sure to import the record and localize functions. Then run record in your tests module's ``setUp`` method:<br><br>    import unittest<br>    from interview_alexa import say, record, localize<br><br><br>    class TestingAllTheThings(unittest.TestCase):<br><br>        def setUp(self):<br>        record(self)<br><br>        @say('open my skill')<br>        def test_aa__launch_intent(self, result):<br>            self.assertEqual(result, 'My expected result')<br><br>        ...<br><br>Once you've run your test with **record mode** on, you should see a ``tmp`` folder in your working directory with some JSON files with the same names as your tests.<br><br><br>\t\tproject<br>\t\t\u2502<br>\t\t\u2514\u2500\u2500\u2500My_Cloned_Skill<br>\t\t\t\u2502<br>\t\t\t\u2514\u2500\u2500\u2500tests.py<br>\t\t\t\u2502<br>\t\t\t\u2514\u2500\u2500\u2500tmp<br>\t\t\t  \u2502<br>\t\t\t  \u2514\u2500\u2500\u2500__main__.TestingAllTheThings.test_aa.json<br><br><br><br>Now that you have some events recorded locally, you can run your tests in **localize mode**, and run your tests again with ``python tests.py`` as you normally would.<br><br><br>    import unittest<br>    from interview_alexa import say, record, localize<br><br><br>    class TestingAllTheThings(unittest.TestCase):<br><br>        def setUp(self):<br>            # record(self)<br>            localize(self)<br><br>        ...<br><br><br>\n          </div>"}, "last_serial": 3719757, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "aeed780dc1f9ccf051902888d6247567", "sha256": "69b1b6ce1cf23ba2e70dc0558bc839f251d0404ef4033ee35f461ae8a3a0bf60"}, "downloads": -1, "filename": "InterviewAlexa-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "aeed780dc1f9ccf051902888d6247567", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7659, "upload_time": "2018-03-30T13:35:11", "upload_time_iso_8601": "2018-03-30T13:35:11.524192Z", "url": "https://files.pythonhosted.org/packages/95/db/4186bd1d681b5fda05ee7c9ffeed28b8936686fc2ba501f2611400fa92ca/InterviewAlexa-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8f25af01e67eaca8b90d0cc26ac2f868", "sha256": "ff61387683d16e95ad0baef1a5fd0cd9b22661d95c4db10609e0b51344112643"}, "downloads": -1, "filename": "InterviewAlexa-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8f25af01e67eaca8b90d0cc26ac2f868", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5227, "upload_time": "2018-03-30T13:35:13", "upload_time_iso_8601": "2018-03-30T13:35:13.474945Z", "url": "https://files.pythonhosted.org/packages/bc/17/6bc1108c9d1441b384480fba5f0818546af43171b953143067921b78e680/InterviewAlexa-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "aeed780dc1f9ccf051902888d6247567", "sha256": "69b1b6ce1cf23ba2e70dc0558bc839f251d0404ef4033ee35f461ae8a3a0bf60"}, "downloads": -1, "filename": "InterviewAlexa-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "aeed780dc1f9ccf051902888d6247567", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7659, "upload_time": "2018-03-30T13:35:11", "upload_time_iso_8601": "2018-03-30T13:35:11.524192Z", "url": "https://files.pythonhosted.org/packages/95/db/4186bd1d681b5fda05ee7c9ffeed28b8936686fc2ba501f2611400fa92ca/InterviewAlexa-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8f25af01e67eaca8b90d0cc26ac2f868", "sha256": "ff61387683d16e95ad0baef1a5fd0cd9b22661d95c4db10609e0b51344112643"}, "downloads": -1, "filename": "InterviewAlexa-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8f25af01e67eaca8b90d0cc26ac2f868", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5227, "upload_time": "2018-03-30T13:35:13", "upload_time_iso_8601": "2018-03-30T13:35:13.474945Z", "url": "https://files.pythonhosted.org/packages/bc/17/6bc1108c9d1441b384480fba5f0818546af43171b953143067921b78e680/InterviewAlexa-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:55:24 2020"}