{"info": {"author": "Idan Morad", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Framework :: tox", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# Data Science Utils: Frequently Used Methods for Data Science\n[![License: MIT](https://img.shields.io/github/license/idanmoradarthas/DataScienceUtils)](https://opensource.org/licenses/MIT)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/idanmoradarthas/DataScienceUtils)\n[![GitHub issues](https://img.shields.io/github/issues/idanmoradarthas/DataScienceUtils)](https://github.com/idanmoradarthas/DataScienceUtils/issues)\n[![Documentation Status](https://readthedocs.org/projects/datascienceutils/badge/?version=latest)](https://datascienceutils.readthedocs.io/en/latest/?badge=latest)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/data-science-utils)\n![PyPI - Wheel](https://img.shields.io/pypi/wheel/data-science-utils)\n[![PyPI version](https://badge.fury.io/py/data-science-utils.svg)](https://badge.fury.io/py/data-science-utils)\n[![Anaconda-Server Badge](https://anaconda.org/idanmorad/data-science-utils/badges/version.svg)](https://anaconda.org/idanmorad/data-science-utils)\n[![Build Status](https://travis-ci.org/idanmoradarthas/DataScienceUtils.svg?branch=master)](https://travis-ci.org/idanmoradarthas/DataScienceUtils)\n[![Coverage Status](https://coveralls.io/repos/github/idanmoradarthas/DataScienceUtils/badge.svg?branch=master)](https://coveralls.io/github/idanmoradarthas/DataScienceUtils?branch=master)\n\n\nData Science Utils extends the Scikit-Learn API and Matplotlib API to provide simple methods that simplify task and \nvisualization over data. \n\n# Code Examples and Documentation\n**Let's see some code examples and outputs.** \n\n**You can read the full documentation with all the code examples from:\n[https://datascienceutils.readthedocs.io/en/latest/](https://datascienceutils.readthedocs.io/en/latest/)**\n\nIn the documentation you can find more methods and more examples.\n\n## Plot Confusion Matrix\nIn following example we are going to use the iris dataset from scikit-learn. so firstly let's import it:\n```python\nimport numpy\nfrom sklearn import datasets\n\nIRIS = datasets.load_iris()\nRANDOM_STATE = numpy.random.RandomState(0)\n```\nLet's train a SVM classifier on all the target labels and plot confusion matrix:\n```python\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn import svm\n\nfrom ds_utils.metrics import plot_confusion_matrix\n\n\nx = IRIS.data\ny = IRIS.target\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.5, random_state=RANDOM_STATE)\n\n# Create a simple classifier\nclassifier = OneVsRestClassifier(svm.LinearSVC(random_state=RANDOM_STATE))\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)\n\nplot_confusion_matrix(y_test, y_pred, [0, 1, 2])\npyplot.show()\n```\nAnd the following image will be shown:\n\n![multi label classification confusion matrix](https://raw.githubusercontent.com/idanmoradarthas/DataScienceUtils/master/tests/baseline_images/test_metrics/test_print_confusion_matrix.png)\n## Generate Decision Paths\nWe'll create a simple decision tree classifier and print it:\n```python\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom ds_utils.visualization_aids import generate_decision_paths\n\nx = IRIS.data\ny = IRIS.target\n\n# Create decision tree classifier object\nclf = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=3)\n\n# Train model\nclf.fit(x, y)\nprint(generate_decision_paths(clf, iris.feature_names, iris.target_names.tolist(),\n                         \"iris_tree\"))\n```\nThe following text will be printed:\n```\ndef iris_tree(petal width (cm), petal length (cm)):\n    if petal width (cm) <= 0.8000:\n        # return class setosa with probability 0.9804\n        return (\"setosa\", 0.9804)\n    else:  # if petal width (cm) > 0.8000\n        if petal width (cm) <= 1.7500:\n            if petal length (cm) <= 4.9500:\n                # return class versicolor with probability 0.9792\n                return (\"versicolor\", 0.9792)\n            else:  # if petal length (cm) > 4.9500\n                # return class virginica with probability 0.6667\n                return (\"virginica\", 0.6667)\n        else:  # if petal width (cm) > 1.7500\n            if petal length (cm) <= 4.8500:\n                # return class virginica with probability 0.6667\n                return (\"virginica\", 0.6667)\n            else:  # if petal length (cm) > 4.8500\n                # return class virginica with probability 0.9773\n                return (\"virginica\", 0.9773)\n```\n\n## Extract Significant Terms from Subset\nThis method will help extract the significant terms that will differentiate between subset of documents from the full \ncorpus. Based on the [elasticsearch significant_text aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-significantterms-aggregation.html#_scripted).\n\n```python\nimport pandas\n\nfrom ds_utils.strings import extract_significant_terms_from_subset\n\ncorpus = ['This is the first document.', 'This document is the second document.',\n          'And this is the third one.', 'Is this the first document?']\ndata_frame = pandas.DataFrame(corpus, columns=[\"content\"])\n# Let's differentiate between the last two documents from the full corpus\nsubset_data_frame = data_frame[data_frame.index > 1]\nterms = extract_significant_terms_from_subset(data_frame, subset_data_frame, \n                                               \"content\")\n\n```\nAnd the following table will be the output for ``terms``:\n\n|third|one|and|this|the |is  |first|document|second|\n|-----|---|---|----|----|----|-----|--------|------|\n|1.0  |1.0|1.0|0.67|0.67|0.67|0.5  |0.25    |0.0   |\n\nExcited?\n\nRead about all the modules here and see more methods and abilities (such as drawing a decision tree and more): \n* [Metrics](https://datascienceutils.readthedocs.io/en/latest/metrics.html) - The module of metrics contains methods that help to calculate and/or visualize evaluation performance of an algorithm.\n* [Preprocess](https://datascienceutils.readthedocs.io/en/latest/preprocess.html) - The module of preprocess contains methods that are processes that could be made to data before training.\n* [Strings](https://datascienceutils.readthedocs.io/en/latest/strings.html) - The module of strings contains methods that help manipulate and process strings in a dataframe.\n* [Visualization Aids](https://datascienceutils.readthedocs.io/en/latest/visualization_aids.html) - The module of visualization aids contains methods that visualize by drawing or printing ML output.\n\n## Contributing\nInterested in contributing to Data Science Utils? Great! You're welcome,  and we would love to have you. We follow \nthe [Python Software Foundation Code of Conduct](http://www.python.org/psf/codeofconduct/) and \n[Matplotlib Usage Guide](https://matplotlib.org/tutorials/introductory/usage.html#coding-styles).\n\nNo matter your level of technical skill, you can be helpful. We appreciate bug reports, user testing, feature \nrequests, bug fixes, product enhancements, and documentation improvements.\n\nThank you for your contributions!\n\n## Find a Bug?\nCheck if there's already an open [issue](https://github.com/idanmoradarthas/DataScienceUtils/issues) on the topic. If \nneeded, file an issue.\n\n## Open Source\nData Science Utils license is [MIT License](https://opensource.org/licenses/MIT). \n\n## Installing Data Science Utils\nData Science Utils is compatible with Python 3.6 or later. The simplest way to install Data Science Utils and its \ndependencies is from PyPI with pip, Python's preferred package installer:\n```bash\npip install data-science-utils\n```\nNote that this package is an active project and routinely publishes new releases with more methods.  In order to \nupgrade Data Science Utils to the latest version, use pip as follows:\n```bash\npip install -U data-science-utils\n```\nAlternatively you can install from source by cloning the repo and running:\n```bash\ngit clone https://github.com/idanmoradarthas/DataScienceUtils.git\ncd DataScienceUtils\npython setup.py install\n```\nOr install using pip from source:\n```bash\npip install git+https://github.com/idanmoradarthas/DataScienceUtils.git\n```\nIf you're using Anaconda, you can install using conda:\n```bash\nconda install -c idanmorad data-science-utils\n```\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/idanmoradarthas/DataScienceUtils/releases/download/1.5/data_science_utils-1.5.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://datascienceutils.readthedocs.io/en/latest/", "keywords": "data-science utilities python machine-learning scikit-learn matplotlib", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "data-science-utils", "package_url": "https://pypi.org/project/data-science-utils/", "platform": "", "project_url": "https://pypi.org/project/data-science-utils/", "project_urls": {"Download": "https://github.com/idanmoradarthas/DataScienceUtils/releases/download/1.5/data_science_utils-1.5.tar.gz", "Homepage": "https://datascienceutils.readthedocs.io/en/latest/"}, "release_url": "https://pypi.org/project/data-science-utils/1.5/", "requires_dist": ["numpy (>=1.3)", "pandas (>=0.23.0)", "matplotlib (<=3.0.3,>2.02)", "seaborn (>=0.8.0)", "scikit-learn (>=0.19.0)", "pydotplus (>=2.0.2)", "joblib (>=0.12)"], "requires_python": ">=3.6", "summary": "This project is an ensemble of methods which are frequently used in python Data Science projects.", "version": "1.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Data Science Utils: Frequently Used Methods for Data Science</h1>\n<p><a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/db4865eca8e6d5d9af4271768fec17e4e611f5c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6964616e6d6f7261646172746861732f44617461536369656e63655574696c73\"></a>\n<img alt=\"GitHub release (latest SemVer)\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/19c6f19fba201b404b68c36f059069b3337e443b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6964616e6d6f7261646172746861732f44617461536369656e63655574696c73\">\n<a href=\"https://github.com/idanmoradarthas/DataScienceUtils/issues\" rel=\"nofollow\"><img alt=\"GitHub issues\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/42a74851c2e42da8b089bb074cb36c4e1ccac6e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6964616e6d6f7261646172746861732f44617461536369656e63655574696c73\"></a>\n<a href=\"https://datascienceutils.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f028806ca62fd6a02dac6ec54da44a1cd9865e37/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f64617461736369656e63657574696c732f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c5464ffc03eb90c1f0730742a8f99c8910543995/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f646174612d736369656e63652d7574696c73\">\n<img alt=\"PyPI - Wheel\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bf6a4a6e8a2917f73e5a6986df40fde4b34499c8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f776865656c2f646174612d736369656e63652d7574696c73\">\n<a href=\"https://badge.fury.io/py/data-science-utils\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/183ffec0143a5fbbfb187c41dc19f84e7a3b3517/68747470733a2f2f62616467652e667572792e696f2f70792f646174612d736369656e63652d7574696c732e737667\"></a>\n<a href=\"https://anaconda.org/idanmorad/data-science-utils\" rel=\"nofollow\"><img alt=\"Anaconda-Server Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bdc0966f1a94e460817705cd798d2290e4d6315e/68747470733a2f2f616e61636f6e64612e6f72672f6964616e6d6f7261642f646174612d736369656e63652d7574696c732f6261646765732f76657273696f6e2e737667\"></a>\n<a href=\"https://travis-ci.org/idanmoradarthas/DataScienceUtils\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/33711613400465302859d8f6b0223f54e56d3c5f/68747470733a2f2f7472617669732d63692e6f72672f6964616e6d6f7261646172746861732f44617461536369656e63655574696c732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/github/idanmoradarthas/DataScienceUtils?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/78533a5f06fb3518b45b8ae9482f87420195a6bc/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6964616e6d6f7261646172746861732f44617461536369656e63655574696c732f62616467652e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>Data Science Utils extends the Scikit-Learn API and Matplotlib API to provide simple methods that simplify task and\nvisualization over data.</p>\n<h1>Code Examples and Documentation</h1>\n<p><strong>Let's see some code examples and outputs.</strong></p>\n<p><strong>You can read the full documentation with all the code examples from:\n<a href=\"https://datascienceutils.readthedocs.io/en/latest/\" rel=\"nofollow\">https://datascienceutils.readthedocs.io/en/latest/</a></strong></p>\n<p>In the documentation you can find more methods and more examples.</p>\n<h2>Plot Confusion Matrix</h2>\n<p>In following example we are going to use the iris dataset from scikit-learn. so firstly let's import it:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">datasets</span>\n\n<span class=\"n\">IRIS</span> <span class=\"o\">=</span> <span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">load_iris</span><span class=\"p\">()</span>\n<span class=\"n\">RANDOM_STATE</span> <span class=\"o\">=</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">RandomState</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Let's train a SVM classifier on all the target labels and plot confusion matrix:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">matplotlib</span> <span class=\"kn\">import</span> <span class=\"n\">pyplot</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.multiclass</span> <span class=\"kn\">import</span> <span class=\"n\">OneVsRestClassifier</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn</span> <span class=\"kn\">import</span> <span class=\"n\">svm</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">ds_utils.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">plot_confusion_matrix</span>\n\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">IRIS</span><span class=\"o\">.</span><span class=\"n\">data</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">IRIS</span><span class=\"o\">.</span><span class=\"n\">target</span>\n\n<span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=.</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">RANDOM_STATE</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Create a simple classifier</span>\n<span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">OneVsRestClassifier</span><span class=\"p\">(</span><span class=\"n\">svm</span><span class=\"o\">.</span><span class=\"n\">LinearSVC</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">RANDOM_STATE</span><span class=\"p\">))</span>\n<span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">classifier</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">)</span>\n\n<span class=\"n\">plot_confusion_matrix</span><span class=\"p\">(</span><span class=\"n\">y_test</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n<span class=\"n\">pyplot</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<p>And the following image will be shown:</p>\n<p><img alt=\"multi label classification confusion matrix\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ad661032f2ae12a1580e0f53065129d03b578b4f/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6964616e6d6f7261646172746861732f44617461536369656e63655574696c732f6d61737465722f74657374732f626173656c696e655f696d616765732f746573745f6d6574726963732f746573745f7072696e745f636f6e667573696f6e5f6d61747269782e706e67\"></p>\n<h2>Generate Decision Paths</h2>\n<p>We'll create a simple decision tree classifier and print it:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.tree</span> <span class=\"kn\">import</span> <span class=\"n\">DecisionTreeClassifier</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">ds_utils.visualization_aids</span> <span class=\"kn\">import</span> <span class=\"n\">generate_decision_paths</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">IRIS</span><span class=\"o\">.</span><span class=\"n\">data</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">IRIS</span><span class=\"o\">.</span><span class=\"n\">target</span>\n\n<span class=\"c1\"># Create decision tree classifier object</span>\n<span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">DecisionTreeClassifier</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">RANDOM_STATE</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Train model</span>\n<span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">generate_decision_paths</span><span class=\"p\">(</span><span class=\"n\">clf</span><span class=\"p\">,</span> <span class=\"n\">iris</span><span class=\"o\">.</span><span class=\"n\">feature_names</span><span class=\"p\">,</span> <span class=\"n\">iris</span><span class=\"o\">.</span><span class=\"n\">target_names</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">(),</span>\n                         <span class=\"s2\">\"iris_tree\"</span><span class=\"p\">))</span>\n</pre>\n<p>The following text will be printed:</p>\n<pre><code>def iris_tree(petal width (cm), petal length (cm)):\n    if petal width (cm) &lt;= 0.8000:\n        # return class setosa with probability 0.9804\n        return (\"setosa\", 0.9804)\n    else:  # if petal width (cm) &gt; 0.8000\n        if petal width (cm) &lt;= 1.7500:\n            if petal length (cm) &lt;= 4.9500:\n                # return class versicolor with probability 0.9792\n                return (\"versicolor\", 0.9792)\n            else:  # if petal length (cm) &gt; 4.9500\n                # return class virginica with probability 0.6667\n                return (\"virginica\", 0.6667)\n        else:  # if petal width (cm) &gt; 1.7500\n            if petal length (cm) &lt;= 4.8500:\n                # return class virginica with probability 0.6667\n                return (\"virginica\", 0.6667)\n            else:  # if petal length (cm) &gt; 4.8500\n                # return class virginica with probability 0.9773\n                return (\"virginica\", 0.9773)\n</code></pre>\n<h2>Extract Significant Terms from Subset</h2>\n<p>This method will help extract the significant terms that will differentiate between subset of documents from the full\ncorpus. Based on the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-significantterms-aggregation.html#_scripted\" rel=\"nofollow\">elasticsearch significant_text aggregation</a>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">ds_utils.strings</span> <span class=\"kn\">import</span> <span class=\"n\">extract_significant_terms_from_subset</span>\n\n<span class=\"n\">corpus</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'This is the first document.'</span><span class=\"p\">,</span> <span class=\"s1\">'This document is the second document.'</span><span class=\"p\">,</span>\n          <span class=\"s1\">'And this is the third one.'</span><span class=\"p\">,</span> <span class=\"s1\">'Is this the first document?'</span><span class=\"p\">]</span>\n<span class=\"n\">data_frame</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">corpus</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"content\"</span><span class=\"p\">])</span>\n<span class=\"c1\"># Let's differentiate between the last two documents from the full corpus</span>\n<span class=\"n\">subset_data_frame</span> <span class=\"o\">=</span> <span class=\"n\">data_frame</span><span class=\"p\">[</span><span class=\"n\">data_frame</span><span class=\"o\">.</span><span class=\"n\">index</span> <span class=\"o\">&gt;</span> <span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">terms</span> <span class=\"o\">=</span> <span class=\"n\">extract_significant_terms_from_subset</span><span class=\"p\">(</span><span class=\"n\">data_frame</span><span class=\"p\">,</span> <span class=\"n\">subset_data_frame</span><span class=\"p\">,</span> \n                                               <span class=\"s2\">\"content\"</span><span class=\"p\">)</span>\n</pre>\n<p>And the following table will be the output for <code>terms</code>:</p>\n<table>\n<thead>\n<tr>\n<th>third</th>\n<th>one</th>\n<th>and</th>\n<th>this</th>\n<th>the</th>\n<th>is</th>\n<th>first</th>\n<th>document</th>\n<th>second</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>0.67</td>\n<td>0.67</td>\n<td>0.67</td>\n<td>0.5</td>\n<td>0.25</td>\n<td>0.0</td>\n</tr></tbody></table>\n<p>Excited?</p>\n<p>Read about all the modules here and see more methods and abilities (such as drawing a decision tree and more):</p>\n<ul>\n<li><a href=\"https://datascienceutils.readthedocs.io/en/latest/metrics.html\" rel=\"nofollow\">Metrics</a> - The module of metrics contains methods that help to calculate and/or visualize evaluation performance of an algorithm.</li>\n<li><a href=\"https://datascienceutils.readthedocs.io/en/latest/preprocess.html\" rel=\"nofollow\">Preprocess</a> - The module of preprocess contains methods that are processes that could be made to data before training.</li>\n<li><a href=\"https://datascienceutils.readthedocs.io/en/latest/strings.html\" rel=\"nofollow\">Strings</a> - The module of strings contains methods that help manipulate and process strings in a dataframe.</li>\n<li><a href=\"https://datascienceutils.readthedocs.io/en/latest/visualization_aids.html\" rel=\"nofollow\">Visualization Aids</a> - The module of visualization aids contains methods that visualize by drawing or printing ML output.</li>\n</ul>\n<h2>Contributing</h2>\n<p>Interested in contributing to Data Science Utils? Great! You're welcome,  and we would love to have you. We follow\nthe <a href=\"http://www.python.org/psf/codeofconduct/\" rel=\"nofollow\">Python Software Foundation Code of Conduct</a> and\n<a href=\"https://matplotlib.org/tutorials/introductory/usage.html#coding-styles\" rel=\"nofollow\">Matplotlib Usage Guide</a>.</p>\n<p>No matter your level of technical skill, you can be helpful. We appreciate bug reports, user testing, feature\nrequests, bug fixes, product enhancements, and documentation improvements.</p>\n<p>Thank you for your contributions!</p>\n<h2>Find a Bug?</h2>\n<p>Check if there's already an open <a href=\"https://github.com/idanmoradarthas/DataScienceUtils/issues\" rel=\"nofollow\">issue</a> on the topic. If\nneeded, file an issue.</p>\n<h2>Open Source</h2>\n<p>Data Science Utils license is <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\">MIT License</a>.</p>\n<h2>Installing Data Science Utils</h2>\n<p>Data Science Utils is compatible with Python 3.6 or later. The simplest way to install Data Science Utils and its\ndependencies is from PyPI with pip, Python's preferred package installer:</p>\n<pre>pip install data-science-utils\n</pre>\n<p>Note that this package is an active project and routinely publishes new releases with more methods.  In order to\nupgrade Data Science Utils to the latest version, use pip as follows:</p>\n<pre>pip install -U data-science-utils\n</pre>\n<p>Alternatively you can install from source by cloning the repo and running:</p>\n<pre>git clone https://github.com/idanmoradarthas/DataScienceUtils.git\n<span class=\"nb\">cd</span> DataScienceUtils\npython setup.py install\n</pre>\n<p>Or install using pip from source:</p>\n<pre>pip install git+https://github.com/idanmoradarthas/DataScienceUtils.git\n</pre>\n<p>If you're using Anaconda, you can install using conda:</p>\n<pre>conda install -c idanmorad data-science-utils\n</pre>\n\n          </div>"}, "last_serial": 6414056, "releases": {"1.4": [{"comment_text": "", "digests": {"md5": "47a54729b4f7c7b44d96f33c98052c13", "sha256": "681610e3d53d0c0ad289f9ee1fc4b416e2e52a5102ef6cc4a30dbcdba2ec8aa5"}, "downloads": -1, "filename": "data_science_utils-1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "47a54729b4f7c7b44d96f33c98052c13", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10731, "upload_time": "2019-12-26T12:39:42", "upload_time_iso_8601": "2019-12-26T12:39:42.573658Z", "url": "https://files.pythonhosted.org/packages/bc/2f/0037e5479a389b34f9842fd4b307691bc13c0132837b609c040d7ccdcf6e/data_science_utils-1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "25a09a9f163cf6b4127fe5fc94097858", "sha256": "a1096843688568a591f6c4138e8c5acd53e53a7b3bb5a45bcac513afeb73ba09"}, "downloads": -1, "filename": "data_science_utils-1.4.tar.gz", "has_sig": false, "md5_digest": "25a09a9f163cf6b4127fe5fc94097858", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10866, "upload_time": "2019-12-26T12:39:45", "upload_time_iso_8601": "2019-12-26T12:39:45.238023Z", "url": "https://files.pythonhosted.org/packages/b3/b6/8d9f154db43047734d7f2d2190927f94981ff906c9e8f9b03b275d4802b8/data_science_utils-1.4.tar.gz", "yanked": false}], "1.4.1": [{"comment_text": "", "digests": {"md5": "c962b94dc4bfc4b186b00b2c870c8aab", "sha256": "841389c400d94c3be6b8fd314c22228c4345ea3dcb94effb61ced7eb2d0d4009"}, "downloads": -1, "filename": "data_science_utils-1.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c962b94dc4bfc4b186b00b2c870c8aab", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10815, "upload_time": "2019-12-26T12:57:04", "upload_time_iso_8601": "2019-12-26T12:57:04.661333Z", "url": "https://files.pythonhosted.org/packages/45/e6/d5e3008cae6339f49941bb156db52126ee44a5338e28bfde2f1c3d9a1972/data_science_utils-1.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "abd474cf65c9f06630cee0edcb0188dc", "sha256": "cd1df35e6456262981200a1bd59e5c13d00ae55efe3f2f6eb358adac8555b59b"}, "downloads": -1, "filename": "data_science_utils-1.4.1.tar.gz", "has_sig": false, "md5_digest": "abd474cf65c9f06630cee0edcb0188dc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 11012, "upload_time": "2019-12-26T12:57:06", "upload_time_iso_8601": "2019-12-26T12:57:06.590829Z", "url": "https://files.pythonhosted.org/packages/6e/5b/7b4e74081978bbd89e3cf7dd5d39e37a0131d2a7be35ecebe067bc2b075b/data_science_utils-1.4.1.tar.gz", "yanked": false}], "1.5": [{"comment_text": "", "digests": {"md5": "d60d5dbf777cf5ce623ad392d7f2bd53", "sha256": "2b014e618a545689d2fad45a28ee56158f66cc5f9a138b24cd5ba14e0a22e25d"}, "downloads": -1, "filename": "data_science_utils-1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "d60d5dbf777cf5ce623ad392d7f2bd53", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13531, "upload_time": "2020-01-08T08:30:09", "upload_time_iso_8601": "2020-01-08T08:30:09.393913Z", "url": "https://files.pythonhosted.org/packages/fa/ea/3baefd84972f333b723dc4197a65ee6936d1a77209ca07819e2e88542e23/data_science_utils-1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e83c4b10364841869d20e0421764a121", "sha256": "345325b895a47ab93e2d9bf6bad394bfffa0e0bf0027ca459dcfee0cc48de172"}, "downloads": -1, "filename": "data_science_utils-1.5.tar.gz", "has_sig": false, "md5_digest": "e83c4b10364841869d20e0421764a121", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15394, "upload_time": "2020-01-08T08:30:10", "upload_time_iso_8601": "2020-01-08T08:30:10.773462Z", "url": "https://files.pythonhosted.org/packages/ed/46/008ee34d6a4d1140152b7a5c8ffc2f7427b54e2c2ac5c0631040c9f01146/data_science_utils-1.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d60d5dbf777cf5ce623ad392d7f2bd53", "sha256": "2b014e618a545689d2fad45a28ee56158f66cc5f9a138b24cd5ba14e0a22e25d"}, "downloads": -1, "filename": "data_science_utils-1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "d60d5dbf777cf5ce623ad392d7f2bd53", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13531, "upload_time": "2020-01-08T08:30:09", "upload_time_iso_8601": "2020-01-08T08:30:09.393913Z", "url": "https://files.pythonhosted.org/packages/fa/ea/3baefd84972f333b723dc4197a65ee6936d1a77209ca07819e2e88542e23/data_science_utils-1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e83c4b10364841869d20e0421764a121", "sha256": "345325b895a47ab93e2d9bf6bad394bfffa0e0bf0027ca459dcfee0cc48de172"}, "downloads": -1, "filename": "data_science_utils-1.5.tar.gz", "has_sig": false, "md5_digest": "e83c4b10364841869d20e0421764a121", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15394, "upload_time": "2020-01-08T08:30:10", "upload_time_iso_8601": "2020-01-08T08:30:10.773462Z", "url": "https://files.pythonhosted.org/packages/ed/46/008ee34d6a4d1140152b7a5c8ffc2f7427b54e2c2ac5c0631040c9f01146/data_science_utils-1.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:13 2020"}