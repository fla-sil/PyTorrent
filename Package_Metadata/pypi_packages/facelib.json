{"info": {"author": "Kutay YILDIZ", "author_email": "kkutayyildiz@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Build Tools"], "description": "# facelib\n\nFace recognition python library(tensorflow, opencv).\n\n## Usage (console)\n\ntry `facelib --help` to discover more\n\n### Train\n\n```bash\nfoo@bar:~$ python3 -m facelib train train_images/ lotr\nCurrent pipeline: ssd_int8_cpu, mobilenetv2_fp32_cpu, densenet_fp32_cpu\nClassifier named `lotr` succesfully trained and saved.\n```\n\n* Folder structure:  \ntrain_images/  \n\u251c\u2500\u2500\u2500elijah_wood/  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25000.jpg  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25001.jpg  \n\u251c\u2500\u2500\u2500liv_tyler/  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25000.jpg  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25001.jpg  \n...  \n\n| Image Name                      | Image                                                                                                                               |\n| ------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| train_images/ian_mckellen/0.jpg | <img src=https://github.com/kutayyildiz/facelib/raw/master/facelib/_demo/lotr/train_images/ian_mckellen/0.jpg width=200 height=100> |\n| train_images/seanastin/0.jpg    | ![seanastin](https://github.com/kutayyildiz/facelib/raw/master/facelib/_demo/lotr/train_images/sean_astin/0.jpg)                    |\n\n### Predict\n\n```bash\nfoo@bar:~$ python3 -m facelib predict test_images/ -clf lotr -c -p\nCurrent pipeline: ssd_int8_cpu, mobilenetv2_fp32_cpu, densenet_fp32_cpu\n1.jpg\n\u251c\u2500\u2500\u250010 faces detected\n\u251c\u2500\u2500\u2500['billy_boyd', 'sean_astin', 'viggo_mortensen', 'elijah_wood', 'liv_tyler', 'dominic_monaghan', 'sean_bean', 'ian_mckellen', 'peter_jackson', 'orlando_bloom']\n2.jpg\n\u251c\u2500\u2500\u25005 faces detected\n\u251c\u2500\u2500\u2500['dominic_monaghan', 'billy_boyd', 'elijah_wood', 'sean_astin', 'peter_jackson']\n3.jpg\n\u251c\u2500\u2500\u25006 faces detected\n\u251c\u2500\u2500\u2500['orlando_bloom', 'dominic_monaghan', 'john_rhys_davies', 'sean_astin', 'elijah_wood', 'billy_boyd']\n0.jpeg\n\u251c\u2500\u2500\u25005 faces detected\n\u251c\u2500\u2500\u2500['dominic_monaghan', 'orlando_bloom', 'elijah_wood', 'liv_tyler', 'billy_boyd']\n```\n\n* Folder structure:  \ntest_images/  \n\u251c\u2500\u25000.jpeg  \n\u251c\u2500\u25001.jpg  \n\u251c\u2500\u25002.jpg  \n\u251c\u2500\u25003.jpg  \n\n* Generated folders/files:  \ntest_images_facelib_cropped/  \n\u251c\u2500\u2500\u2500elijah_wood/  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25002_2.jpg  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25003_1.jpg  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25004_3.jpg  \n\u251c\u2500\u2500\u2500liv_tyler/  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25003_0.jpg  \n\u251c\u2500\u2500\u2500\u251c\u2500\u25004_1.jpg  \n...\n\n| Image Name                                      | Image                                                                                                                               |\n| ----------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n| test_images_facelib_cropped/billy_boyd/0_1.jpg  | ![billyboyd](https://github.com/kutayyildiz/facelib/raw/master/facelib/_demo/lotr/test_images_facelib_cropped/billy_boyd/0_1.jpg)   |\n| test_images_facelib_cropped/liv_tyler/4_1.jpg   | ![livtyler](https://github.com/kutayyildiz/facelib/raw/master/facelib/_demo/lotr/test_images_facelib_cropped/liv_tyler/4_1.jpg)     |\n| test_images_facelib_cropped/elijah_wood/3_1.jpg | ![elijahwood](https://github.com/kutayyildiz/facelib/raw/master/facelib/_demo/lotr/test_images_facelib_cropped/elijah_wood/3_1.jpg) |\n| test_images_facelib_plotted/1.jpg               | ![1](https://github.com/kutayyildiz/facelib/raw/master/facelib/_demo/lotr/test_images_facelib_plotted/1.jpg)                        |\n\n## Usage (python)\n\n```python\nfrom facelib import facerec\nimport cv2\n# You can use face_detector, landmark_detector or feature_extractor individually using .predict method. e.g.(bboxes = facedetector.predict(img))\nface_detector = facerec.SSDFaceDetector()\nlandmark_detector = facerec.LandmarkDetector()\nfeature_extractor = facerec.FeatureExtractor()\n\npipeline = facerec.Pipeline(face_detector, landmark_detector, feature_extractor)\npath_img = './path_to_some_image.jpg'\nimg = cv2.imread(path_img)\nimg = img[...,::-1] # cv2 returns bgr format but every method inside this package takes rgb format\nbboxes, landmarks, features = pipeline.predict(img)\n# Note that values returned (bboxes and landmarks) are in fraction.[0,1]\n```\n\n## Installation\n\n### Pip installation\n\n```bash\npip3 install facelib\n```\n\n### TFLite runtime installation\n\nTo use facelib.facerec package use the following bash command to install tflite-runtime pip package.\n\n```bash\npython3 -m facelib --install-tflite\n```\n\nor you can install from [tensorflow.org](https://www.tensorflow.org/lite/guide/python)\n\n### Dev package\n\nTensorflow is required for facelib.dev package. If you wish you can download facelib with tensorflow using the following command.\n\n```bash\npip3 install facelib[dev]\n```\n\n## Info\n\n### Dataset\n\nFeature extraction models are trained using insightfaces [MS1M-Arcface.](https://github.com/deepinsight/insightface/wiki/Dataset-Zoo)  \nLandmark Detection models are trained using [VggFace2.](http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/)\n\n## Contents\n\n### Image Augmentation\n\n- [x] Random augmentation for landmark detection\n\n### Layers\n\n- [x] DisturbLabel\n\n### Face Alignment\n\n- [x] Insightface\n- [x] GoldenRatio\n- [x] Custom Implementations\n\n### TFRecords\n\n- [ ] Widerface to TFRecords converter\n- [ ] VggFace2 to TFRecords converter\n- [ ] COFW to TFRecords converter\n\n### Loss Functions\n\n#### Feature Extraction\n\n- [x] ArcFace\n- [x] CombinedMargin\n- [x] SphereFace(A-Softmax)\n- [ ] Center\n- [x] CosFace\n\n#### Landmark Detection\n\n- [x] EuclideanDistance(with different norms)\n\n### Pretrained Models\n\n#### Face Detection\n\n- [x] SSD\n- [ ] MTCNN\n\n#### Face Feature Extraction\n\n- [x] MobileFaceNet\n- [x] SqueezeNet\n- [x] MobileNet\n- [x] MobileNetV2\n- [x] DenseNet\n- [x] NasNetMobile\n\n#### Scripts\n\n- [ ] Feature extraction model training\n- [ ] Landmark detection model training\n- [ ] Chokepoint test on pipeline\n\n#### Facial Landmark Detection\n\n- [ ] SqueezeNet\n- [x] MobileNet\n- [x] MobileNetV2\n- [ ] DenseNet\n\n## References\n\n|                              |                                                                                                                                                                                                                                            |\n| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| WiderFace                    | Yang, Shuo, Ping Luo, Chen Change Loy, and Xiaoou Tang. \u201cWIDER FACE: A Face Detection Benchmark.\u201d ArXiv:1511.06523 [Cs], November 20, 2015. <https://arxiv.org/abs/1511.06523>                                                             |\n| ArcFace                      | Deng, Jiankang, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. \u201cArcFace: Additive Angular Margin Loss for Deep Face Recognition.\u201d ArXiv:1801.07698 [Cs], January 23, 2018. <https://arxiv.org/abs/1801.07698>                               |\n| MobileFaceNet                | Chen, Sheng, Yang Liu, Xiang Gao, and Zhen Han. \u201cMobileFaceNets: Efficient CNNs for Accurate Real-Time Face Verification on Mobile Devices.\u201d CoRR abs/1804.07573 (2018). <http://arxiv.org/abs/1804.07573>                                 |\n| VggFace2                     | Cao, Qiong, Li Shen, Weidi Xie, Omkar M. Parkhi, and Andrew Zisserman. \u201cVGGFace2: A Dataset for Recognising Faces across Pose and Age.\u201d ArXiv:1710.08092 [Cs], October 23, 2017. <http://arxiv.org/abs/1710.08092>                         |\n| DenseNet                     | G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger, \u201cDensely Connected Convolutional Networks,\u201d arXiv:1608.06993 [cs], Jan. 2018. <http://arxiv.org/abs/1608.06993>                                                                 |\n| GoldenRatio (face alignment) | M. Hassaballah, K. Murakami, and S. Ido, \u201cFace detection evaluation: a new approach based on the golden ratio,\u201d SIViP, vol. 7, no. 2, pp. 307\u2013316, Mar. 2013. <http://link.springer.com/10.1007/s11760-011-0239-3>                         |\n| SqueezeNet                   | F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer, \u201cSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,\u201d arXiv:1602.07360 [cs], Feb. 2016.  <http://arxiv.org/abs/1602.07360> |\n| MobileNet                    | A. G. Howard et al., \u201cMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,\u201d arXiv:1704.04861 [cs], Apr. 2017. <http://arxiv.org/abs/1704.04861>                                                             |\n| MobileNetV2                  | M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, \u201cMobileNetV2: Inverted Residuals and Linear Bottlenecks,\u201d arXiv:1801.04381 [cs], Jan. 2018. <http://arxiv.org/abs/1801.04381>                                                 |\n| CosFace                      | H. Wang et al., \u201cCosFace: Large Margin Cosine Loss for Deep Face Recognition,\u201d arXiv:1801.09414 [cs], Jan. 2018. <http://arxiv.org/abs/1801.09414>                                                                                         |\n| SphereFace                   | W. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song, \u201cSphereFace: Deep Hypersphere Embedding for Face Recognition,\u201d arXiv:1704.08063 [cs], Apr. 2017. <http://arxiv.org/abs/1704.08063>                                                      |\n| Bottleneck Layer             | K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep Residual Learning for Image Recognition,\u201d arXiv:1512.03385 [cs], Dec. 2015. <http://arxiv.org/abs/1512.03385>                                                                                   |\n| MS-Celeb-1M                  | Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao, \u201cMS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition,\u201d arXiv:1607.08221 [cs], Jul. 2016. <http://arxiv.org/abs/1607.08221>                                                   |\n| DisturbLabel                 | arXiv:1605.00055 [cs.CV]                                                                                                                                                                                                                   |\n| Single Shot Detector         | [1]W. Liu et al., \u201cSSD: Single Shot MultiBox Detector,\u201d arXiv:1512.02325 [cs], Dec. 2016. <https://arxiv.org/abs/1512.02325>                                                                                                               |\n\n## Links\n\n|                        |                                                                                                           |\n| ---------------------- | --------------------------------------------------------------------------------------------------------- |\n| Insightface            | <https://github.com/deepinsight/insightface>                                                              |\n| Tensorflow             | <https://github.com/tensorflow/tensorflow>                                                                |\n| Tensorflow-Addons      | <https://github.com/tensorflow/addons>                                                                    |\n| Insightface-DatasetZoo | <https://github.com/deepinsight/insightface/wiki/Dataset-Zoo>                                             |\n| Tensorflow-ModelZoo    | <https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md> |\n| Cascade Data           | <https://github.com/opencv/opencv/tree/master/data>                                                       |\n| TFLite Python          | <https://www.tensorflow.org/lite/guide/python>                                                            |\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kutayyildiz/facelib", "keywords": "face,recognition,detection,tensorflow,lite,keras,loss,layer,edgetpu", "license": "", "maintainer": "", "maintainer_email": "", "name": "facelib", "package_url": "https://pypi.org/project/facelib/", "platform": "", "project_url": "https://pypi.org/project/facelib/", "project_urls": {"Homepage": "https://github.com/kutayyildiz/facelib", "Source": "https://github.com/kutayyildiz/facelib"}, "release_url": "https://pypi.org/project/facelib/1.2.1/", "requires_dist": ["joblib", "opencv-python", "numpy", "scikit-image", "scikit-learn", "tensorflow ; extra == 'dev'"], "requires_python": ">=3.5, <3.8", "summary": "Face Recognition (train/test/deploy)(tensorflow/tflite/keras/edgetpu)", "version": "1.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>facelib</h1>\n<p>Face recognition python library(tensorflow, opencv).</p>\n<h2>Usage (console)</h2>\n<p>try <code>facelib --help</code> to discover more</p>\n<h3>Train</h3>\n<pre>foo@bar:~$ python3 -m facelib train train_images/ lotr\nCurrent pipeline: ssd_int8_cpu, mobilenetv2_fp32_cpu, densenet_fp32_cpu\nClassifier named <span class=\"sb\">`</span>lotr<span class=\"sb\">`</span> succesfully trained and saved.\n</pre>\n<ul>\n<li>Folder structure:<br>\ntrain_images/<br>\n\u251c\u2500\u2500\u2500elijah_wood/<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25000.jpg<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25001.jpg<br>\n\u251c\u2500\u2500\u2500liv_tyler/<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25000.jpg<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25001.jpg<br>\n...</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Image Name</th>\n<th>Image</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>train_images/ian_mckellen/0.jpg</td>\n<td><img height=\"100\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/784ef316935eec72eac67f02772a8b8f521ff995/68747470733a2f2f6769746875622e636f6d2f6b7574617979696c64697a2f666163656c69622f7261772f6d61737465722f666163656c69622f5f64656d6f2f6c6f74722f747261696e5f696d616765732f69616e5f6d636b656c6c656e2f302e6a7067\" width=\"200\"></td>\n</tr>\n<tr>\n<td>train_images/seanastin/0.jpg</td>\n<td><img alt=\"seanastin\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2d7b696a4c8331c182975cf2c30ab251a1750a0d/68747470733a2f2f6769746875622e636f6d2f6b7574617979696c64697a2f666163656c69622f7261772f6d61737465722f666163656c69622f5f64656d6f2f6c6f74722f747261696e5f696d616765732f7365616e5f617374696e2f302e6a7067\"></td>\n</tr></tbody></table>\n<h3>Predict</h3>\n<pre>foo@bar:~$ python3 -m facelib predict test_images/ -clf lotr -c -p\nCurrent pipeline: ssd_int8_cpu, mobilenetv2_fp32_cpu, densenet_fp32_cpu\n<span class=\"m\">1</span>.jpg\n\u251c\u2500\u2500\u250010 faces detected\n\u251c\u2500\u2500\u2500<span class=\"o\">[</span><span class=\"s1\">'billy_boyd'</span>, <span class=\"s1\">'sean_astin'</span>, <span class=\"s1\">'viggo_mortensen'</span>, <span class=\"s1\">'elijah_wood'</span>, <span class=\"s1\">'liv_tyler'</span>, <span class=\"s1\">'dominic_monaghan'</span>, <span class=\"s1\">'sean_bean'</span>, <span class=\"s1\">'ian_mckellen'</span>, <span class=\"s1\">'peter_jackson'</span>, <span class=\"s1\">'orlando_bloom'</span><span class=\"o\">]</span>\n<span class=\"m\">2</span>.jpg\n\u251c\u2500\u2500\u25005 faces detected\n\u251c\u2500\u2500\u2500<span class=\"o\">[</span><span class=\"s1\">'dominic_monaghan'</span>, <span class=\"s1\">'billy_boyd'</span>, <span class=\"s1\">'elijah_wood'</span>, <span class=\"s1\">'sean_astin'</span>, <span class=\"s1\">'peter_jackson'</span><span class=\"o\">]</span>\n<span class=\"m\">3</span>.jpg\n\u251c\u2500\u2500\u25006 faces detected\n\u251c\u2500\u2500\u2500<span class=\"o\">[</span><span class=\"s1\">'orlando_bloom'</span>, <span class=\"s1\">'dominic_monaghan'</span>, <span class=\"s1\">'john_rhys_davies'</span>, <span class=\"s1\">'sean_astin'</span>, <span class=\"s1\">'elijah_wood'</span>, <span class=\"s1\">'billy_boyd'</span><span class=\"o\">]</span>\n<span class=\"m\">0</span>.jpeg\n\u251c\u2500\u2500\u25005 faces detected\n\u251c\u2500\u2500\u2500<span class=\"o\">[</span><span class=\"s1\">'dominic_monaghan'</span>, <span class=\"s1\">'orlando_bloom'</span>, <span class=\"s1\">'elijah_wood'</span>, <span class=\"s1\">'liv_tyler'</span>, <span class=\"s1\">'billy_boyd'</span><span class=\"o\">]</span>\n</pre>\n<ul>\n<li>\n<p>Folder structure:<br>\ntest_images/<br>\n\u251c\u2500\u25000.jpeg<br>\n\u251c\u2500\u25001.jpg<br>\n\u251c\u2500\u25002.jpg<br>\n\u251c\u2500\u25003.jpg</p>\n</li>\n<li>\n<p>Generated folders/files:<br>\ntest_images_facelib_cropped/<br>\n\u251c\u2500\u2500\u2500elijah_wood/<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25002_2.jpg<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25003_1.jpg<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25004_3.jpg<br>\n\u251c\u2500\u2500\u2500liv_tyler/<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25003_0.jpg<br>\n\u251c\u2500\u2500\u2500\u251c\u2500\u25004_1.jpg<br>\n...</p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Image Name</th>\n<th>Image</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>test_images_facelib_cropped/billy_boyd/0_1.jpg</td>\n<td><img alt=\"billyboyd\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bb46dcd052a68802af1bf21fc7e67504d96a4089/68747470733a2f2f6769746875622e636f6d2f6b7574617979696c64697a2f666163656c69622f7261772f6d61737465722f666163656c69622f5f64656d6f2f6c6f74722f746573745f696d616765735f666163656c69625f63726f707065642f62696c6c795f626f79642f305f312e6a7067\"></td>\n</tr>\n<tr>\n<td>test_images_facelib_cropped/liv_tyler/4_1.jpg</td>\n<td><img alt=\"livtyler\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/69eb604337062691f874aaeea5b8a711c0805fd3/68747470733a2f2f6769746875622e636f6d2f6b7574617979696c64697a2f666163656c69622f7261772f6d61737465722f666163656c69622f5f64656d6f2f6c6f74722f746573745f696d616765735f666163656c69625f63726f707065642f6c69765f74796c65722f345f312e6a7067\"></td>\n</tr>\n<tr>\n<td>test_images_facelib_cropped/elijah_wood/3_1.jpg</td>\n<td><img alt=\"elijahwood\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0932134100a219499ff0ded9f2e0c3d1cdd9a48a/68747470733a2f2f6769746875622e636f6d2f6b7574617979696c64697a2f666163656c69622f7261772f6d61737465722f666163656c69622f5f64656d6f2f6c6f74722f746573745f696d616765735f666163656c69625f63726f707065642f656c696a61685f776f6f642f335f312e6a7067\"></td>\n</tr>\n<tr>\n<td>test_images_facelib_plotted/1.jpg</td>\n<td><img alt=\"1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/933c0d2a1ae7e378b5415e0d4e2f5d80e5b33f4f/68747470733a2f2f6769746875622e636f6d2f6b7574617979696c64697a2f666163656c69622f7261772f6d61737465722f666163656c69622f5f64656d6f2f6c6f74722f746573745f696d616765735f666163656c69625f706c6f747465642f312e6a7067\"></td>\n</tr></tbody></table>\n<h2>Usage (python)</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">facelib</span> <span class=\"kn\">import</span> <span class=\"n\">facerec</span>\n<span class=\"kn\">import</span> <span class=\"nn\">cv2</span>\n<span class=\"c1\"># You can use face_detector, landmark_detector or feature_extractor individually using .predict method. e.g.(bboxes = facedetector.predict(img))</span>\n<span class=\"n\">face_detector</span> <span class=\"o\">=</span> <span class=\"n\">facerec</span><span class=\"o\">.</span><span class=\"n\">SSDFaceDetector</span><span class=\"p\">()</span>\n<span class=\"n\">landmark_detector</span> <span class=\"o\">=</span> <span class=\"n\">facerec</span><span class=\"o\">.</span><span class=\"n\">LandmarkDetector</span><span class=\"p\">()</span>\n<span class=\"n\">feature_extractor</span> <span class=\"o\">=</span> <span class=\"n\">facerec</span><span class=\"o\">.</span><span class=\"n\">FeatureExtractor</span><span class=\"p\">()</span>\n\n<span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">facerec</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">face_detector</span><span class=\"p\">,</span> <span class=\"n\">landmark_detector</span><span class=\"p\">,</span> <span class=\"n\">feature_extractor</span><span class=\"p\">)</span>\n<span class=\"n\">path_img</span> <span class=\"o\">=</span> <span class=\"s1\">'./path_to_some_image.jpg'</span>\n<span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">cv2</span><span class=\"o\">.</span><span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"n\">path_img</span><span class=\"p\">)</span>\n<span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">img</span><span class=\"p\">[</span><span class=\"o\">...</span><span class=\"p\">,::</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"c1\"># cv2 returns bgr format but every method inside this package takes rgb format</span>\n<span class=\"n\">bboxes</span><span class=\"p\">,</span> <span class=\"n\">landmarks</span><span class=\"p\">,</span> <span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n<span class=\"c1\"># Note that values returned (bboxes and landmarks) are in fraction.[0,1]</span>\n</pre>\n<h2>Installation</h2>\n<h3>Pip installation</h3>\n<pre>pip3 install facelib\n</pre>\n<h3>TFLite runtime installation</h3>\n<p>To use facelib.facerec package use the following bash command to install tflite-runtime pip package.</p>\n<pre>python3 -m facelib --install-tflite\n</pre>\n<p>or you can install from <a href=\"https://www.tensorflow.org/lite/guide/python\" rel=\"nofollow\">tensorflow.org</a></p>\n<h3>Dev package</h3>\n<p>Tensorflow is required for facelib.dev package. If you wish you can download facelib with tensorflow using the following command.</p>\n<pre>pip3 install facelib<span class=\"o\">[</span>dev<span class=\"o\">]</span>\n</pre>\n<h2>Info</h2>\n<h3>Dataset</h3>\n<p>Feature extraction models are trained using insightfaces <a href=\"https://github.com/deepinsight/insightface/wiki/Dataset-Zoo\" rel=\"nofollow\">MS1M-Arcface.</a><br>\nLandmark Detection models are trained using <a href=\"http://www.robots.ox.ac.uk/%7Evgg/data/vgg_face2/\" rel=\"nofollow\">VggFace2.</a></p>\n<h2>Contents</h2>\n<h3>Image Augmentation</h3>\n<ul>\n<li>[x] Random augmentation for landmark detection</li>\n</ul>\n<h3>Layers</h3>\n<ul>\n<li>[x] DisturbLabel</li>\n</ul>\n<h3>Face Alignment</h3>\n<ul>\n<li>[x] Insightface</li>\n<li>[x] GoldenRatio</li>\n<li>[x] Custom Implementations</li>\n</ul>\n<h3>TFRecords</h3>\n<ul>\n<li>[ ] Widerface to TFRecords converter</li>\n<li>[ ] VggFace2 to TFRecords converter</li>\n<li>[ ] COFW to TFRecords converter</li>\n</ul>\n<h3>Loss Functions</h3>\n<h4>Feature Extraction</h4>\n<ul>\n<li>[x] ArcFace</li>\n<li>[x] CombinedMargin</li>\n<li>[x] SphereFace(A-Softmax)</li>\n<li>[ ] Center</li>\n<li>[x] CosFace</li>\n</ul>\n<h4>Landmark Detection</h4>\n<ul>\n<li>[x] EuclideanDistance(with different norms)</li>\n</ul>\n<h3>Pretrained Models</h3>\n<h4>Face Detection</h4>\n<ul>\n<li>[x] SSD</li>\n<li>[ ] MTCNN</li>\n</ul>\n<h4>Face Feature Extraction</h4>\n<ul>\n<li>[x] MobileFaceNet</li>\n<li>[x] SqueezeNet</li>\n<li>[x] MobileNet</li>\n<li>[x] MobileNetV2</li>\n<li>[x] DenseNet</li>\n<li>[x] NasNetMobile</li>\n</ul>\n<h4>Scripts</h4>\n<ul>\n<li>[ ] Feature extraction model training</li>\n<li>[ ] Landmark detection model training</li>\n<li>[ ] Chokepoint test on pipeline</li>\n</ul>\n<h4>Facial Landmark Detection</h4>\n<ul>\n<li>[ ] SqueezeNet</li>\n<li>[x] MobileNet</li>\n<li>[x] MobileNetV2</li>\n<li>[ ] DenseNet</li>\n</ul>\n<h2>References</h2>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>WiderFace</td>\n<td>Yang, Shuo, Ping Luo, Chen Change Loy, and Xiaoou Tang. \u201cWIDER FACE: A Face Detection Benchmark.\u201d ArXiv:1511.06523 [Cs], November 20, 2015. <a href=\"https://arxiv.org/abs/1511.06523\" rel=\"nofollow\">https://arxiv.org/abs/1511.06523</a></td>\n</tr>\n<tr>\n<td>ArcFace</td>\n<td>Deng, Jiankang, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. \u201cArcFace: Additive Angular Margin Loss for Deep Face Recognition.\u201d ArXiv:1801.07698 [Cs], January 23, 2018. <a href=\"https://arxiv.org/abs/1801.07698\" rel=\"nofollow\">https://arxiv.org/abs/1801.07698</a></td>\n</tr>\n<tr>\n<td>MobileFaceNet</td>\n<td>Chen, Sheng, Yang Liu, Xiang Gao, and Zhen Han. \u201cMobileFaceNets: Efficient CNNs for Accurate Real-Time Face Verification on Mobile Devices.\u201d CoRR abs/1804.07573 (2018). <a href=\"http://arxiv.org/abs/1804.07573\" rel=\"nofollow\">http://arxiv.org/abs/1804.07573</a></td>\n</tr>\n<tr>\n<td>VggFace2</td>\n<td>Cao, Qiong, Li Shen, Weidi Xie, Omkar M. Parkhi, and Andrew Zisserman. \u201cVGGFace2: A Dataset for Recognising Faces across Pose and Age.\u201d ArXiv:1710.08092 [Cs], October 23, 2017. <a href=\"http://arxiv.org/abs/1710.08092\" rel=\"nofollow\">http://arxiv.org/abs/1710.08092</a></td>\n</tr>\n<tr>\n<td>DenseNet</td>\n<td>G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger, \u201cDensely Connected Convolutional Networks,\u201d arXiv:1608.06993 [cs], Jan. 2018. <a href=\"http://arxiv.org/abs/1608.06993\" rel=\"nofollow\">http://arxiv.org/abs/1608.06993</a></td>\n</tr>\n<tr>\n<td>GoldenRatio (face alignment)</td>\n<td>M. Hassaballah, K. Murakami, and S. Ido, \u201cFace detection evaluation: a new approach based on the golden ratio,\u201d SIViP, vol. 7, no. 2, pp. 307\u2013316, Mar. 2013. <a href=\"http://link.springer.com/10.1007/s11760-011-0239-3\" rel=\"nofollow\">http://link.springer.com/10.1007/s11760-011-0239-3</a></td>\n</tr>\n<tr>\n<td>SqueezeNet</td>\n<td>F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer, \u201cSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size,\u201d arXiv:1602.07360 [cs], Feb. 2016.  <a href=\"http://arxiv.org/abs/1602.07360\" rel=\"nofollow\">http://arxiv.org/abs/1602.07360</a></td>\n</tr>\n<tr>\n<td>MobileNet</td>\n<td>A. G. Howard et al., \u201cMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,\u201d arXiv:1704.04861 [cs], Apr. 2017. <a href=\"http://arxiv.org/abs/1704.04861\" rel=\"nofollow\">http://arxiv.org/abs/1704.04861</a></td>\n</tr>\n<tr>\n<td>MobileNetV2</td>\n<td>M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, \u201cMobileNetV2: Inverted Residuals and Linear Bottlenecks,\u201d arXiv:1801.04381 [cs], Jan. 2018. <a href=\"http://arxiv.org/abs/1801.04381\" rel=\"nofollow\">http://arxiv.org/abs/1801.04381</a></td>\n</tr>\n<tr>\n<td>CosFace</td>\n<td>H. Wang et al., \u201cCosFace: Large Margin Cosine Loss for Deep Face Recognition,\u201d arXiv:1801.09414 [cs], Jan. 2018. <a href=\"http://arxiv.org/abs/1801.09414\" rel=\"nofollow\">http://arxiv.org/abs/1801.09414</a></td>\n</tr>\n<tr>\n<td>SphereFace</td>\n<td>W. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song, \u201cSphereFace: Deep Hypersphere Embedding for Face Recognition,\u201d arXiv:1704.08063 [cs], Apr. 2017. <a href=\"http://arxiv.org/abs/1704.08063\" rel=\"nofollow\">http://arxiv.org/abs/1704.08063</a></td>\n</tr>\n<tr>\n<td>Bottleneck Layer</td>\n<td>K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep Residual Learning for Image Recognition,\u201d arXiv:1512.03385 [cs], Dec. 2015. <a href=\"http://arxiv.org/abs/1512.03385\" rel=\"nofollow\">http://arxiv.org/abs/1512.03385</a></td>\n</tr>\n<tr>\n<td>MS-Celeb-1M</td>\n<td>Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao, \u201cMS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition,\u201d arXiv:1607.08221 [cs], Jul. 2016. <a href=\"http://arxiv.org/abs/1607.08221\" rel=\"nofollow\">http://arxiv.org/abs/1607.08221</a></td>\n</tr>\n<tr>\n<td>DisturbLabel</td>\n<td>arXiv:1605.00055 [cs.CV]</td>\n</tr>\n<tr>\n<td>Single Shot Detector</td>\n<td>[1]W. Liu et al., \u201cSSD: Single Shot MultiBox Detector,\u201d arXiv:1512.02325 [cs], Dec. 2016. <a href=\"https://arxiv.org/abs/1512.02325\" rel=\"nofollow\">https://arxiv.org/abs/1512.02325</a></td>\n</tr></tbody></table>\n<h2>Links</h2>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Insightface</td>\n<td><a href=\"https://github.com/deepinsight/insightface\" rel=\"nofollow\">https://github.com/deepinsight/insightface</a></td>\n</tr>\n<tr>\n<td>Tensorflow</td>\n<td><a href=\"https://github.com/tensorflow/tensorflow\" rel=\"nofollow\">https://github.com/tensorflow/tensorflow</a></td>\n</tr>\n<tr>\n<td>Tensorflow-Addons</td>\n<td><a href=\"https://github.com/tensorflow/addons\" rel=\"nofollow\">https://github.com/tensorflow/addons</a></td>\n</tr>\n<tr>\n<td>Insightface-DatasetZoo</td>\n<td><a href=\"https://github.com/deepinsight/insightface/wiki/Dataset-Zoo\" rel=\"nofollow\">https://github.com/deepinsight/insightface/wiki/Dataset-Zoo</a></td>\n</tr>\n<tr>\n<td>Tensorflow-ModelZoo</td>\n<td><a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\" rel=\"nofollow\">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md</a></td>\n</tr>\n<tr>\n<td>Cascade Data</td>\n<td><a href=\"https://github.com/opencv/opencv/tree/master/data\" rel=\"nofollow\">https://github.com/opencv/opencv/tree/master/data</a></td>\n</tr>\n<tr>\n<td>TFLite Python</td>\n<td><a href=\"https://www.tensorflow.org/lite/guide/python\" rel=\"nofollow\">https://www.tensorflow.org/lite/guide/python</a></td>\n</tr></tbody></table>\n\n          </div>"}, "last_serial": 6872626, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "e57df02b86d71a5788c7a5be0e65a4c3", "sha256": "aa0991953677244e622e1cf38d438c1390058caac1a31f9fd665ea9d19619646"}, "downloads": -1, "filename": "facelib-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "e57df02b86d71a5788c7a5be0e65a4c3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, <3.8", "size": 42241656, "upload_time": "2020-03-16T14:14:59", "upload_time_iso_8601": "2020-03-16T14:14:59.472111Z", "url": "https://files.pythonhosted.org/packages/38/bf/eb72fb64cdd03d2d748aaabfcd4f7343e66115278dc9057b192c6ed6acc8/facelib-1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f978e23c5804a2098acd07fb2d3ce363", "sha256": "91536b0e224e00842b0922754c8fe6d446e6ea84ae467641bfcdd54af8062757"}, "downloads": -1, "filename": "facelib-1.0.tar.gz", "has_sig": false, "md5_digest": "f978e23c5804a2098acd07fb2d3ce363", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5, <3.8", "size": 42184058, "upload_time": "2020-03-16T14:16:14", "upload_time_iso_8601": "2020-03-16T14:16:14.708408Z", "url": "https://files.pythonhosted.org/packages/11/4c/8d574e838a1041fcc8b4cdcd4743c4a202e79b756eb52d263eab62adf467/facelib-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "b61576688bb9f3f27e2c73230cf907e5", "sha256": "3aa7cc0e50d3d41a110d29441e00ba620854c93f6864bf892423380ba83cf222"}, "downloads": -1, "filename": "facelib-1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "b61576688bb9f3f27e2c73230cf907e5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, <3.8", "size": 29614, "upload_time": "2020-03-24T12:00:10", "upload_time_iso_8601": "2020-03-24T12:00:10.776853Z", "url": "https://files.pythonhosted.org/packages/d9/a0/8168643280de7759374f95a968d3ee1f191f7ba89fb238d64c50aa2ca107/facelib-1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a1a07a3fc35a9f85ed45a506da23899", "sha256": "d5b2ac11fddd8454097e8df5ba0f4c6327668d0e8f30681d4c6d6cee437718ea"}, "downloads": -1, "filename": "facelib-1.1.tar.gz", "has_sig": false, "md5_digest": "0a1a07a3fc35a9f85ed45a506da23899", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5, <3.8", "size": 22093, "upload_time": "2020-03-24T12:00:12", "upload_time_iso_8601": "2020-03-24T12:00:12.456910Z", "url": "https://files.pythonhosted.org/packages/5d/4b/09599856329ae838e57329b3208078daa64e529db7e8c5afd914d1130da5/facelib-1.1.tar.gz", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "fef6a10d1af275fe7e32b3903fdedaac", "sha256": "9f5317a1ed294b69932b39a6d91f4415a9e8da50a252bad19e29cad3460ccc73"}, "downloads": -1, "filename": "facelib-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "fef6a10d1af275fe7e32b3903fdedaac", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, <3.8", "size": 29588, "upload_time": "2020-03-24T12:11:35", "upload_time_iso_8601": "2020-03-24T12:11:35.230047Z", "url": "https://files.pythonhosted.org/packages/8a/33/9f21d16d2ece4269389bf570bde15c52a9424ecc5b7445aba8141bdce3db/facelib-1.2-py3-none-any.whl", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "fa2682683490f60553f925c5de215138", "sha256": "a3c85fd5b053bc84656e610d8cb763fdc3cc770eb3811d6d5aeee92676753a05"}, "downloads": -1, "filename": "facelib-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "fa2682683490f60553f925c5de215138", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, <3.8", "size": 29631, "upload_time": "2020-03-24T12:22:16", "upload_time_iso_8601": "2020-03-24T12:22:16.726451Z", "url": "https://files.pythonhosted.org/packages/07/d8/6b2d301cb6c4a21026ee6ff0fbdc819fcc1e9baa630ef2a74d8b614afcce/facelib-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ca68ef808c36da63de927cdc82d3557", "sha256": "7265f8db27b09b17fdeceffa17ef5cf5dc03924c11fe18451afbc0a77623dd25"}, "downloads": -1, "filename": "facelib-1.2.1.tar.gz", "has_sig": false, "md5_digest": "3ca68ef808c36da63de927cdc82d3557", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5, <3.8", "size": 22095, "upload_time": "2020-03-24T12:22:18", "upload_time_iso_8601": "2020-03-24T12:22:18.024788Z", "url": "https://files.pythonhosted.org/packages/c2/23/cea6cf7ae5196070a4540a14f2c01ad2ce69d6c0544ba68754cf6f6ac195/facelib-1.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fa2682683490f60553f925c5de215138", "sha256": "a3c85fd5b053bc84656e610d8cb763fdc3cc770eb3811d6d5aeee92676753a05"}, "downloads": -1, "filename": "facelib-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "fa2682683490f60553f925c5de215138", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, <3.8", "size": 29631, "upload_time": "2020-03-24T12:22:16", "upload_time_iso_8601": "2020-03-24T12:22:16.726451Z", "url": "https://files.pythonhosted.org/packages/07/d8/6b2d301cb6c4a21026ee6ff0fbdc819fcc1e9baa630ef2a74d8b614afcce/facelib-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ca68ef808c36da63de927cdc82d3557", "sha256": "7265f8db27b09b17fdeceffa17ef5cf5dc03924c11fe18451afbc0a77623dd25"}, "downloads": -1, "filename": "facelib-1.2.1.tar.gz", "has_sig": false, "md5_digest": "3ca68ef808c36da63de927cdc82d3557", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5, <3.8", "size": 22095, "upload_time": "2020-03-24T12:22:18", "upload_time_iso_8601": "2020-03-24T12:22:18.024788Z", "url": "https://files.pythonhosted.org/packages/c2/23/cea6cf7ae5196070a4540a14f2c01ad2ce69d6c0544ba68754cf6f6ac195/facelib-1.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:07 2020"}