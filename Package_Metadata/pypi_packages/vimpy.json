{"info": {"author": "Brian Williamson", "author_email": "brianw26@uw.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3"], "description": "# vimpy: nonparametric variable importance assessment in python\n\n[![PyPI version](https://badge.fury.io/py/vimpy.svg)](https://badge.fury.io/py/vimpy)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n\n**Software author:** [Brian Williamson](https://bdwilliamson.github.io/)\n\n**Methodology authors:** [Brian Williamson](https://bdwilliamson.github.io/), [Peter Gilbert](https://www.fredhutch.org/en/faculty-lab-directory/gilbert-peter.html), [Noah Simon](http://faculty.washington.edu/nrsimon/), [Marco Carone](http://faculty.washington.edu/mcarone/about.html)\n\n## Introduction\n\nIn predictive modeling applications, it is often of interest to determine the relative contribution of subsets of features in explaining an outcome; this is often called variable importance. It is useful to consider variable importance as a function of the unknown, underlying data-generating mechanism rather than the specific predictive algorithm used to fit the data. This package provides functions that, given fitted values from predictive algorithms, compute nonparametric estimates of variable importance based on $R^2$, deviance, classification accuracy, and area under the receiver operating characteristic curve, along with asymptotically valid confidence intervals for the true importance.\n\nFor more details, please see the accompanying manuscripts \"Nonparametric variable importance assessment using machine learning techniques\" by Williamson, Gilbert, Carone, and Simon (*Biometrics*, 2020) and [\"A unified approach for inference on algorithm-agnostic variable importance\"](https://arxiv.org/abs/2004.03683) by Williamson, Gilbert, Simon, and Carone (*arXiv*, 2020).\n\n## Installation\n\nYou may install a stable release of `vimpy` using `pip` by running `python pip install vimpy` from a Terminal window. Alternatively, you may install within a `virtualenv` environment.\n\nYou may install the current dev release of `vimpy` by downloading this repository directly.\n\n## Issues\n\nIf you encounter any bugs or have any specific feature requests, please [file an issue](https://github.com/bdwilliamson/vimpy/issues).\n\n## Example\n\nThis example shows how to use `vimpy` in a simple setting with simulated data and using a single regression function. For more examples and detailed explanation, please see the [`R` vignette](https://github.com/bdwilliamson/vimp/blob/master/vignettes/introduction_to_vimp.Rmd).\n\n```python\n## load required libraries\nimport numpy as np\nimport vimpy\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n## -------------------------------------------------------------\n## problem setup\n## -------------------------------------------------------------\n## define a function for the conditional mean of Y given X\ndef cond_mean(x = None):\n    f1 = np.where(np.logical_and(-2 <= x[:, 0], x[:, 0] < 2), np.floor(x[:, 0]), 0)\n    f2 = np.where(x[:, 1] <= 0, 1, 0)\n    f3 = np.where(x[:, 2] > 0, 1, 0)\n\n    f6 = np.absolute(x[:, 5]/4) ** 3\n    f7 = np.absolute(x[:, 6]/4) ** 5\n\n    f11 = (7./3)*np.cos(x[:, 10]/2)\n\n    ret = f1 + f2 + f3 + f6 + f7 + f11\n\n    return ret\n\n## create data\nnp.random.seed(4747)\nn = 100\np = 15\ns = 1 # importance desired for X_1\nx = np.zeros((n, p))\nfor i in range(0, x.shape[1]) :\n    x[:,i] = np.random.normal(0, 2, n)\n\ny = cond_mean(x) + np.random.normal(0, 1, n)\n\n## -------------------------------------------------------------\n## preliminary step: get regression estimators\n## -------------------------------------------------------------\n## use grid search to get optimal number of trees and learning rate\nntrees = np.arange(100, 3500, 500)\nlr = np.arange(.01, .5, .05)\n\nparam_grid = [{'n_estimators':ntrees, 'learning_rate':lr}]\n\n## set up cv objects\ncv_full = GridSearchCV(GradientBoostingRegressor(loss = 'ls', max_depth = 1), param_grid = param_grid, cv = 5)\ncv_small = GridSearchCV(GradientBoostingRegressor(loss = 'ls', max_depth = 1), param_grid = param_grid, cv = 5)\n\n## fit the full regression\ncv_full.fit(x, y)\nfull_fit = cv_full.best_estimator_.predict(x)\n\n## fit the reduced regression\nx_small = np.delete(x, s, 1) # delete the columns in s\ncv_small.fit(x_small, full_fit)\nsmall_fit = cv_small.best_estimator_.predict(x_small)\n\n## -------------------------------------------------------------\n## get variable importance estimates\n## -------------------------------------------------------------\n## set up the vimp object\nvimp = vimpy.vim(y = y, x = x, s = 1, pred_func = cv_full, measure_type = \"r_squared\")\n## get the point estimate of variable importance\nvimp.get_point_est()\n## get the influence function estimate\nvimp.get_influence_function()\n## get a standard error\nvimp.get_se()\n## get a confidence interval\nvimp.get_ci()\n## do a hypothesis test, compute p-value\nvimp.hypothesis_test(alpha = 0.05, delta = 0)\n## display the estimates, etc.\nvimp.vimp_\nvimp.se_\nvimp.ci_\nvimp.p_value_\nvimp.hyp_test_\n\n## -------------------------------------------------------------\n## get variable importance estimates using cross-validation\n## -------------------------------------------------------------\n## set up the vimp object\nvimp_cv = vimp.cv_vim(y = y, x = x, s = 1, pred_func = cv_full, V = 5, measure_type = \"r_squared\")\n## get the point estimate\nvimp_cv.get_point_est()\n## get the standard error\nvimp_cv.get_influence_function()\nvimp_cv.get_se()\n## get a confidence interval\nvimp_cv.get_ci()\n## do a hypothesis test, compute p-value\nvimp_cv.hypothesis_test(alpha = 0.05, delta = 0)\n## display estimates, etc.\nvimp_cv.vimp_\nvimp_cv.se_\nvimp_cv.ci_\nvimp_cv.p_value_\nvimp_cv.hyp_test_\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/bdwilliamson/vimpy", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "vimpy", "package_url": "https://pypi.org/project/vimpy/", "platform": "", "project_url": "https://pypi.org/project/vimpy/", "project_urls": {"Homepage": "https://github.com/bdwilliamson/vimpy"}, "release_url": "https://pypi.org/project/vimpy/2.0.1/", "requires_dist": null, "requires_python": "", "summary": "vimpy: nonparametric variable importance assessment in python", "version": "2.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>vimpy: nonparametric variable importance assessment in python</h1>\n<p><a href=\"https://badge.fury.io/py/vimpy\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f4bc1ee7032b4ee36992be1b5f36b3c46d4de22a/68747470733a2f2f62616467652e667572792e696f2f70792f76696d70792e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a></p>\n<p><strong>Software author:</strong> <a href=\"https://bdwilliamson.github.io/\" rel=\"nofollow\">Brian Williamson</a></p>\n<p><strong>Methodology authors:</strong> <a href=\"https://bdwilliamson.github.io/\" rel=\"nofollow\">Brian Williamson</a>, <a href=\"https://www.fredhutch.org/en/faculty-lab-directory/gilbert-peter.html\" rel=\"nofollow\">Peter Gilbert</a>, <a href=\"http://faculty.washington.edu/nrsimon/\" rel=\"nofollow\">Noah Simon</a>, <a href=\"http://faculty.washington.edu/mcarone/about.html\" rel=\"nofollow\">Marco Carone</a></p>\n<h2>Introduction</h2>\n<p>In predictive modeling applications, it is often of interest to determine the relative contribution of subsets of features in explaining an outcome; this is often called variable importance. It is useful to consider variable importance as a function of the unknown, underlying data-generating mechanism rather than the specific predictive algorithm used to fit the data. This package provides functions that, given fitted values from predictive algorithms, compute nonparametric estimates of variable importance based on $R^2$, deviance, classification accuracy, and area under the receiver operating characteristic curve, along with asymptotically valid confidence intervals for the true importance.</p>\n<p>For more details, please see the accompanying manuscripts \"Nonparametric variable importance assessment using machine learning techniques\" by Williamson, Gilbert, Carone, and Simon (<em>Biometrics</em>, 2020) and <a href=\"https://arxiv.org/abs/2004.03683\" rel=\"nofollow\">\"A unified approach for inference on algorithm-agnostic variable importance\"</a> by Williamson, Gilbert, Simon, and Carone (<em>arXiv</em>, 2020).</p>\n<h2>Installation</h2>\n<p>You may install a stable release of <code>vimpy</code> using <code>pip</code> by running <code>python pip install vimpy</code> from a Terminal window. Alternatively, you may install within a <code>virtualenv</code> environment.</p>\n<p>You may install the current dev release of <code>vimpy</code> by downloading this repository directly.</p>\n<h2>Issues</h2>\n<p>If you encounter any bugs or have any specific feature requests, please <a href=\"https://github.com/bdwilliamson/vimpy/issues\" rel=\"nofollow\">file an issue</a>.</p>\n<h2>Example</h2>\n<p>This example shows how to use <code>vimpy</code> in a simple setting with simulated data and using a single regression function. For more examples and detailed explanation, please see the <a href=\"https://github.com/bdwilliamson/vimp/blob/master/vignettes/introduction_to_vimp.Rmd\" rel=\"nofollow\"><code>R</code> vignette</a>.</p>\n<pre><span class=\"c1\">## load required libraries</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">vimpy</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.ensemble</span> <span class=\"kn\">import</span> <span class=\"n\">GradientBoostingRegressor</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">GridSearchCV</span>\n\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## problem setup</span>\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## define a function for the conditional mean of Y given X</span>\n<span class=\"k\">def</span> <span class=\"nf\">cond_mean</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"n\">f1</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">logical_and</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">2</span> <span class=\"o\">&lt;=</span> <span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">floor</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"n\">f2</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">&lt;=</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"n\">f3</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">where</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n\n    <span class=\"n\">f6</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">absolute</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">5</span><span class=\"p\">]</span><span class=\"o\">/</span><span class=\"mi\">4</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">3</span>\n    <span class=\"n\">f7</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">absolute</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">6</span><span class=\"p\">]</span><span class=\"o\">/</span><span class=\"mi\">4</span><span class=\"p\">)</span> <span class=\"o\">**</span> <span class=\"mi\">5</span>\n\n    <span class=\"n\">f11</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mf\">7.</span><span class=\"o\">/</span><span class=\"mi\">3</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">cos</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[:,</span> <span class=\"mi\">10</span><span class=\"p\">]</span><span class=\"o\">/</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n\n    <span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"n\">f1</span> <span class=\"o\">+</span> <span class=\"n\">f2</span> <span class=\"o\">+</span> <span class=\"n\">f3</span> <span class=\"o\">+</span> <span class=\"n\">f6</span> <span class=\"o\">+</span> <span class=\"n\">f7</span> <span class=\"o\">+</span> <span class=\"n\">f11</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">ret</span>\n\n<span class=\"c1\">## create data</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">4747</span><span class=\"p\">)</span>\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"mi\">15</span>\n<span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"c1\"># importance desired for X_1</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">((</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">))</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"p\">:</span>\n    <span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">)</span>\n\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">cond_mean</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## preliminary step: get regression estimators</span>\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## use grid search to get optimal number of trees and learning rate</span>\n<span class=\"n\">ntrees</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">3500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">)</span>\n<span class=\"n\">lr</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"o\">.</span><span class=\"mi\">01</span><span class=\"p\">,</span> <span class=\"o\">.</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"o\">.</span><span class=\"mi\">05</span><span class=\"p\">)</span>\n\n<span class=\"n\">param_grid</span> <span class=\"o\">=</span> <span class=\"p\">[{</span><span class=\"s1\">'n_estimators'</span><span class=\"p\">:</span><span class=\"n\">ntrees</span><span class=\"p\">,</span> <span class=\"s1\">'learning_rate'</span><span class=\"p\">:</span><span class=\"n\">lr</span><span class=\"p\">}]</span>\n\n<span class=\"c1\">## set up cv objects</span>\n<span class=\"n\">cv_full</span> <span class=\"o\">=</span> <span class=\"n\">GridSearchCV</span><span class=\"p\">(</span><span class=\"n\">GradientBoostingRegressor</span><span class=\"p\">(</span><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"s1\">'ls'</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">param_grid</span> <span class=\"o\">=</span> <span class=\"n\">param_grid</span><span class=\"p\">,</span> <span class=\"n\">cv</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">cv_small</span> <span class=\"o\">=</span> <span class=\"n\">GridSearchCV</span><span class=\"p\">(</span><span class=\"n\">GradientBoostingRegressor</span><span class=\"p\">(</span><span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"s1\">'ls'</span><span class=\"p\">,</span> <span class=\"n\">max_depth</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"n\">param_grid</span> <span class=\"o\">=</span> <span class=\"n\">param_grid</span><span class=\"p\">,</span> <span class=\"n\">cv</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## fit the full regression</span>\n<span class=\"n\">cv_full</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"n\">full_fit</span> <span class=\"o\">=</span> <span class=\"n\">cv_full</span><span class=\"o\">.</span><span class=\"n\">best_estimator_</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## fit the reduced regression</span>\n<span class=\"n\">x_small</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">s</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\"># delete the columns in s</span>\n<span class=\"n\">cv_small</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x_small</span><span class=\"p\">,</span> <span class=\"n\">full_fit</span><span class=\"p\">)</span>\n<span class=\"n\">small_fit</span> <span class=\"o\">=</span> <span class=\"n\">cv_small</span><span class=\"o\">.</span><span class=\"n\">best_estimator_</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x_small</span><span class=\"p\">)</span>\n\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## get variable importance estimates</span>\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## set up the vimp object</span>\n<span class=\"n\">vimp</span> <span class=\"o\">=</span> <span class=\"n\">vimpy</span><span class=\"o\">.</span><span class=\"n\">vim</span><span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">pred_func</span> <span class=\"o\">=</span> <span class=\"n\">cv_full</span><span class=\"p\">,</span> <span class=\"n\">measure_type</span> <span class=\"o\">=</span> <span class=\"s2\">\"r_squared\"</span><span class=\"p\">)</span>\n<span class=\"c1\">## get the point estimate of variable importance</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">get_point_est</span><span class=\"p\">()</span>\n<span class=\"c1\">## get the influence function estimate</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">get_influence_function</span><span class=\"p\">()</span>\n<span class=\"c1\">## get a standard error</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">get_se</span><span class=\"p\">()</span>\n<span class=\"c1\">## get a confidence interval</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">get_ci</span><span class=\"p\">()</span>\n<span class=\"c1\">## do a hypothesis test, compute p-value</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">hypothesis_test</span><span class=\"p\">(</span><span class=\"n\">alpha</span> <span class=\"o\">=</span> <span class=\"mf\">0.05</span><span class=\"p\">,</span> <span class=\"n\">delta</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"c1\">## display the estimates, etc.</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">vimp_</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">se_</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">ci_</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">p_value_</span>\n<span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">hyp_test_</span>\n\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## get variable importance estimates using cross-validation</span>\n<span class=\"c1\">## -------------------------------------------------------------</span>\n<span class=\"c1\">## set up the vimp object</span>\n<span class=\"n\">vimp_cv</span> <span class=\"o\">=</span> <span class=\"n\">vimp</span><span class=\"o\">.</span><span class=\"n\">cv_vim</span><span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">pred_func</span> <span class=\"o\">=</span> <span class=\"n\">cv_full</span><span class=\"p\">,</span> <span class=\"n\">V</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">measure_type</span> <span class=\"o\">=</span> <span class=\"s2\">\"r_squared\"</span><span class=\"p\">)</span>\n<span class=\"c1\">## get the point estimate</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">get_point_est</span><span class=\"p\">()</span>\n<span class=\"c1\">## get the standard error</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">get_influence_function</span><span class=\"p\">()</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">get_se</span><span class=\"p\">()</span>\n<span class=\"c1\">## get a confidence interval</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">get_ci</span><span class=\"p\">()</span>\n<span class=\"c1\">## do a hypothesis test, compute p-value</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">hypothesis_test</span><span class=\"p\">(</span><span class=\"n\">alpha</span> <span class=\"o\">=</span> <span class=\"mf\">0.05</span><span class=\"p\">,</span> <span class=\"n\">delta</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"c1\">## display estimates, etc.</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">vimp_</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">se_</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">ci_</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">p_value_</span>\n<span class=\"n\">vimp_cv</span><span class=\"o\">.</span><span class=\"n\">hyp_test_</span>\n</pre>\n\n          </div>"}, "last_serial": 6988074, "releases": {"0.0.10": [{"comment_text": "", "digests": {"md5": "1068b3395e7df5035510f0213323c720", "sha256": "a4f8191b722f25452aa1096209be0b9f950f6823e99073f55fe645cee659d94d"}, "downloads": -1, "filename": "vimpy-0.0.10-py2-none-any.whl", "has_sig": false, "md5_digest": "1068b3395e7df5035510f0213323c720", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5327, "upload_time": "2018-06-20T21:22:45", "upload_time_iso_8601": "2018-06-20T21:22:45.566138Z", "url": "https://files.pythonhosted.org/packages/5c/56/31a983a5f11bdc1eeef090e17f20a206ffa4efd6a4bf8e9ea1b130ef2571/vimpy-0.0.10-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f390203a8654a098917af25f06d69a32", "sha256": "8335bd5fdea1e93210ac12f4a86183be73e59c5c912b0489c13d85949864e705"}, "downloads": -1, "filename": "vimpy-0.0.10.tar.gz", "has_sig": false, "md5_digest": "f390203a8654a098917af25f06d69a32", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4325, "upload_time": "2018-06-20T21:22:46", "upload_time_iso_8601": "2018-06-20T21:22:46.643434Z", "url": "https://files.pythonhosted.org/packages/37/39/4ef83238c7228d46c57adde85ada9db13396159a1b74960bf2655ad8e431/vimpy-0.0.10.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "fca093e553a585a052d423ef4993b15b", "sha256": "5600873157a1ae96136cdfe50e0880f97395ded8887e48ef3bc2ed5379f034e4"}, "downloads": -1, "filename": "vimpy-0.0.3-py2-none-any.whl", "has_sig": false, "md5_digest": "fca093e553a585a052d423ef4993b15b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 1636, "upload_time": "2018-06-15T20:10:37", "upload_time_iso_8601": "2018-06-15T20:10:37.725834Z", "url": "https://files.pythonhosted.org/packages/73/2e/839065471ab96309238fe8168da12427771faf0b17f1da10a171f43e9553/vimpy-0.0.3-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aa48b742fd06509f203b8f195abe50b9", "sha256": "e8a883204bfd8613947701af5bd2adda80221c7ada70615cd62db0fe255c85ce"}, "downloads": -1, "filename": "vimpy-0.0.3.tar.gz", "has_sig": false, "md5_digest": "aa48b742fd06509f203b8f195abe50b9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1491, "upload_time": "2018-06-15T20:10:38", "upload_time_iso_8601": "2018-06-15T20:10:38.833737Z", "url": "https://files.pythonhosted.org/packages/b7/73/3da61bd95bb489f7f163df595f58ef2f12968d1c98f7286ceabf99f7ef92/vimpy-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "226fa9655736c627da185600d62d97f2", "sha256": "c83844fa6b3ab86bf83b53c4b62e4db211b79b43872a154f892f8c20b4d5ca22"}, "downloads": -1, "filename": "vimpy-0.0.4-py2-none-any.whl", "has_sig": false, "md5_digest": "226fa9655736c627da185600d62d97f2", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 2665, "upload_time": "2018-06-15T20:36:43", "upload_time_iso_8601": "2018-06-15T20:36:43.570562Z", "url": "https://files.pythonhosted.org/packages/5c/89/8fc9384b3c7047fa58e5e891bf5141104388a9391b7ab74b064091f81e30/vimpy-0.0.4-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fad96b249ea322d96fadbdeab18e37d8", "sha256": "307b131d8091538769f8e17acdebd6912c5c21eac695c87aebd8e881ef22bb73"}, "downloads": -1, "filename": "vimpy-0.0.4.tar.gz", "has_sig": false, "md5_digest": "fad96b249ea322d96fadbdeab18e37d8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2828, "upload_time": "2018-06-15T20:36:44", "upload_time_iso_8601": "2018-06-15T20:36:44.334450Z", "url": "https://files.pythonhosted.org/packages/b8/16/88a7847f8c66b4949517b2667197c79768c0e50f0acae08e9cc07b84b0d4/vimpy-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "75db7c9e963f42cb63c812e2d26dca36", "sha256": "835023c5c9cfd2423f4dc4b0fdb06733066a8f1e2f2f4e15bddaefd62aabbb07"}, "downloads": -1, "filename": "vimpy-0.0.5-py2-none-any.whl", "has_sig": false, "md5_digest": "75db7c9e963f42cb63c812e2d26dca36", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 2665, "upload_time": "2018-06-19T17:58:12", "upload_time_iso_8601": "2018-06-19T17:58:12.401371Z", "url": "https://files.pythonhosted.org/packages/88/41/7264fcf02ac301b7f31b4b5891ca6e065ca1a71172475b95feb406a4b58a/vimpy-0.0.5-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "50bdbd1093f88fe1256f84c01995aa15", "sha256": "8f942ec8ce302264a74dde876c17f52bbff06a14fcdb0b745fafe91b472c4aa1"}, "downloads": -1, "filename": "vimpy-0.0.5.tar.gz", "has_sig": false, "md5_digest": "50bdbd1093f88fe1256f84c01995aa15", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2830, "upload_time": "2018-06-19T17:58:13", "upload_time_iso_8601": "2018-06-19T17:58:13.552845Z", "url": "https://files.pythonhosted.org/packages/5e/4b/186aba5e20e133055108d44618699356cddd0cd8d95773c537a92b84c653/vimpy-0.0.5.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "0078e489c0f93087b45939862795f24a", "sha256": "028004c63eacbd78145f04b4e0825fd66bd269944461db65002933c408250442"}, "downloads": -1, "filename": "vimpy-0.0.9-py2-none-any.whl", "has_sig": false, "md5_digest": "0078e489c0f93087b45939862795f24a", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5323, "upload_time": "2018-06-20T20:29:57", "upload_time_iso_8601": "2018-06-20T20:29:57.455241Z", "url": "https://files.pythonhosted.org/packages/ba/25/62bd194731a06bbeff8762823e93c20c120920ea2075d87f348a46a3b2c3/vimpy-0.0.9-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a92e7d7def571e17c6afafe2a0331f18", "sha256": "6cfd437c7584e01c2cfdd2424aea9aa687b32b2d261cde2be4d6753003ec1e37"}, "downloads": -1, "filename": "vimpy-0.0.9.tar.gz", "has_sig": false, "md5_digest": "a92e7d7def571e17c6afafe2a0331f18", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4324, "upload_time": "2018-06-20T20:29:58", "upload_time_iso_8601": "2018-06-20T20:29:58.758567Z", "url": "https://files.pythonhosted.org/packages/d3/52/9acc45faad3cd65aaf3a27ecc6c4d58eea67917f004b2237b090f3dcb451/vimpy-0.0.9.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "6c5983826249c920ee58520543c576b9", "sha256": "040e5bf5c1782a15daf3c62ab895b892e2497aef101b8e5393a5b86d4922c535"}, "downloads": -1, "filename": "vimpy-1.0.0-py2-none-any.whl", "has_sig": false, "md5_digest": "6c5983826249c920ee58520543c576b9", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 6880, "upload_time": "2018-10-28T17:37:26", "upload_time_iso_8601": "2018-10-28T17:37:26.929819Z", "url": "https://files.pythonhosted.org/packages/38/46/3ddcfa54ce80f05f91d8c2cfb057a05df573e0a930578b566f365786b9e7/vimpy-1.0.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0486431ffdae309b8cbea51a3f343f9a", "sha256": "340989839b1e648d6f7b3c2301ab8263b9465fe5267b3f3b9c981d143fd9b124"}, "downloads": -1, "filename": "vimpy-1.0.0.tar.gz", "has_sig": false, "md5_digest": "0486431ffdae309b8cbea51a3f343f9a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4970, "upload_time": "2018-10-28T17:37:28", "upload_time_iso_8601": "2018-10-28T17:37:28.344827Z", "url": "https://files.pythonhosted.org/packages/be/c1/73654fa26d68f3b3cd7e2aa6a4932e7b4a04b8208b0e0eb5d8b9de9d5a70/vimpy-1.0.0.tar.gz", "yanked": false}], "2.0.1": [{"comment_text": "", "digests": {"md5": "da3948faa7ea2dc3e49c77a5bb9b3f13", "sha256": "774e20464156829ccf693611f9759d5dd2cff7f30c5a2f762e9ae0c714908537"}, "downloads": -1, "filename": "vimpy-2.0.1.tar.gz", "has_sig": false, "md5_digest": "da3948faa7ea2dc3e49c77a5bb9b3f13", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10831, "upload_time": "2020-04-09T17:31:40", "upload_time_iso_8601": "2020-04-09T17:31:40.355668Z", "url": "https://files.pythonhosted.org/packages/ea/ac/92bebc3a82f827d1b663ee34f143499b38a81a1deb662047efe3cdbd03a6/vimpy-2.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "da3948faa7ea2dc3e49c77a5bb9b3f13", "sha256": "774e20464156829ccf693611f9759d5dd2cff7f30c5a2f762e9ae0c714908537"}, "downloads": -1, "filename": "vimpy-2.0.1.tar.gz", "has_sig": false, "md5_digest": "da3948faa7ea2dc3e49c77a5bb9b3f13", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10831, "upload_time": "2020-04-09T17:31:40", "upload_time_iso_8601": "2020-04-09T17:31:40.355668Z", "url": "https://files.pythonhosted.org/packages/ea/ac/92bebc3a82f827d1b663ee34f143499b38a81a1deb662047efe3cdbd03a6/vimpy-2.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:35:59 2020"}