{"info": {"author": "Renos Zabounidis", "author_email": "rzabounidis@cs.umass.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# NoX - Normalizing Flows using JAX\n\n## What is NoX?\nNoX is a library for building Normalizing Flows using JAX.\n\n## What are Normalizing Flows?\nNormalizng Flows (http://proceedings.mlr.press/v37/rezende15.pdf) are a probabilistic modeling tool learn maximum likelihood models using invertible neural networks.  Given learn a transformation, ![f_{\\theta}: \\mathbb{R}^N \\to \\mathbb{R}^N](https://render.githubusercontent.com/render/math?math=f_%7B%5Ctheta%7D%3A%20%5Cmathbb%7BR%7D%5EN%20%5Cto%20%5Cmathbb%7BR%7D%5EN) between a nice latent variable, say ![z\\sim N(0,I)](https://render.githubusercontent.com/render/math?math=z%5Csim%20N(0%2CI)), and data from an unknown probability distribution, ![x\\sim p(x)](https://render.githubusercontent.com/render/math?math=x%5Csim%20p(x)) such that ![p(f(z)) \\approx p(x)](https://render.githubusercontent.com/render/math?math=p(f(z))%20%5Capprox%20p(x)).  We do this using the probability change of variable formula ![p(x)=p(z)|\\frac{dz}{dx}|](https://render.githubusercontent.com/render/math?math=p(x)%3Dp(z)%7C%5Cfrac%7Bdz%7D%7Bdx%7D%7C).  Properties of the Jacobian and determinant let us compose multiple functions, ![f_1, \\dots, f_K](https://render.githubusercontent.com/render/math?math=f_1%2C%20%5Cdots%2C%20f_K), who are all easily invertible and have an easy to calculate Jacobian determinant, in order to build expressive transformations.\n\n## Why use NoX?\nNox provides a simple interface for building normalizing flows.\n\n```python\nfrom jax import random, jit, value_and_grad\nfrom normalizing_flows import sequential_flow, MAF, Reverse, UnitGaussianPrior\nfrom util import TEST, TRAIN\n\n# Build a dummy dataset\nx_train, x_test = np.ones((70, 3)), np.ones((30, 3))\n\n# Build a normalizing flow with 2 Masked Auto-Regressive Flows\nflow = sequential_flow(MAF([1024], keep_prob=0.7), Reverse(), MAF([1024], keep_prob=0.7), UnitGaussianPrior())\n\n# Initialize the flow.  This example will not condition on a variable.\nkey = random.PRNGKey(0)\nnames, output_shape, params, state = init_fun(key, input_shape=x.shape[-1], condition_shape=())\n\n# Create the loss function and its gradients\ndef nll(params, state, x, **kwargs):\n    log_px, z, updated_state = forward(params, state, np.zeros(x.shape[0]), x, cond=(), **kwargs)\n    return -np.mean(log_px), updated_state\nvalgrad = jit(value_and_grad(nll, has_aux=True))\n\n# Create the optimizer\nopt_init, opt_update, get_params = optimizers.adam(0.001)\nopt_state = opt_init(params)\n\n# Train the flow\nfor i in range(100):\n    key, *keys = random.split(key, 3)\n    params = get_params(opt_state)\n    (loss, state), grad = valgrad(params, state, x_train, key=keys[1], test=TRAIN)\n    opt_state = opt_update(i, grad, opt_state)\n\n# Generate samples from the model\nz = random.normal(keys[1], (10, x.shape[-1]))\nlog_pfz, fz, _ = inverse(params, state, np.zeros(z.shape[0]), z, cond, key=keys[1], test=TEST)\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Information-Fusion-Lab-Umass/NoX", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "nux", "package_url": "https://pypi.org/project/nux/", "platform": "", "project_url": "https://pypi.org/project/nux/", "project_urls": {"Homepage": "https://github.com/Information-Fusion-Lab-Umass/NoX"}, "release_url": "https://pypi.org/project/nux/0.0.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Normalizing Flows with JaX", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>NoX - Normalizing Flows using JAX</h1>\n<h2>What is NoX?</h2>\n<p>NoX is a library for building Normalizing Flows using JAX.</p>\n<h2>What are Normalizing Flows?</h2>\n<p>Normalizng Flows (<a href=\"http://proceedings.mlr.press/v37/rezende15.pdf\" rel=\"nofollow\">http://proceedings.mlr.press/v37/rezende15.pdf</a>) are a probabilistic modeling tool learn maximum likelihood models using invertible neural networks.  Given learn a transformation, <img alt=\"f_{\\theta}: \\mathbb{R}^N \\to \\mathbb{R}^N\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/03b8399dd10ff2a502305e9a254cc106bab89e42/68747470733a2f2f72656e6465722e67697468756275736572636f6e74656e742e636f6d2f72656e6465722f6d6174683f6d6174683d665f25374225354374686574612537442533412532302535436d6174686262253742522537442535454e253230253543746f2532302535436d6174686262253742522537442535454e\"> between a nice latent variable, say <img alt=\"z\\sim N(0,I)\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cbfea218fa3fd37a3b1c2e282d304f78874ef934/68747470733a2f2f72656e6465722e67697468756275736572636f6e74656e742e636f6d2f72656e6465722f6d6174683f6d6174683d7a25354373696d2532304e28302532434929\">, and data from an unknown probability distribution, <img alt=\"x\\sim p(x)\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fae298c4a9e9bc94eae32cc8a9fc21794db55492/68747470733a2f2f72656e6465722e67697468756275736572636f6e74656e742e636f6d2f72656e6465722f6d6174683f6d6174683d7825354373696d25323070287829\"> such that <img alt=\"p(f(z)) \\approx p(x)\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/02f26a409cd18fad4af79e9570e2d48e90c37c11/68747470733a2f2f72656e6465722e67697468756275736572636f6e74656e742e636f6d2f72656e6465722f6d6174683f6d6174683d702866287a2929253230253543617070726f7825323070287829\">.  We do this using the probability change of variable formula <img alt=\"p(x)=p(z)|\\frac{dz}{dx}|\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7467f60f4efc5d6202be2107df0bcb58e54a62a9/68747470733a2f2f72656e6465722e67697468756275736572636f6e74656e742e636f6d2f72656e6465722f6d6174683f6d6174683d7028782925334470287a2925374325354366726163253742647a2537442537426478253744253743\">.  Properties of the Jacobian and determinant let us compose multiple functions, <img alt=\"f_1, \\dots, f_K\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/711a9e8af368b3a611127ff2e672148e60502753/68747470733a2f2f72656e6465722e67697468756275736572636f6e74656e742e636f6d2f72656e6465722f6d6174683f6d6174683d665f31253243253230253543646f7473253243253230665f4b\">, who are all easily invertible and have an easy to calculate Jacobian determinant, in order to build expressive transformations.</p>\n<h2>Why use NoX?</h2>\n<p>Nox provides a simple interface for building normalizing flows.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">jax</span> <span class=\"kn\">import</span> <span class=\"n\">random</span><span class=\"p\">,</span> <span class=\"n\">jit</span><span class=\"p\">,</span> <span class=\"n\">value_and_grad</span>\n<span class=\"kn\">from</span> <span class=\"nn\">normalizing_flows</span> <span class=\"kn\">import</span> <span class=\"n\">sequential_flow</span><span class=\"p\">,</span> <span class=\"n\">MAF</span><span class=\"p\">,</span> <span class=\"n\">Reverse</span><span class=\"p\">,</span> <span class=\"n\">UnitGaussianPrior</span>\n<span class=\"kn\">from</span> <span class=\"nn\">util</span> <span class=\"kn\">import</span> <span class=\"n\">TEST</span><span class=\"p\">,</span> <span class=\"n\">TRAIN</span>\n\n<span class=\"c1\"># Build a dummy dataset</span>\n<span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">x_test</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"mi\">70</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Build a normalizing flow with 2 Masked Auto-Regressive Flows</span>\n<span class=\"n\">flow</span> <span class=\"o\">=</span> <span class=\"n\">sequential_flow</span><span class=\"p\">(</span><span class=\"n\">MAF</span><span class=\"p\">([</span><span class=\"mi\">1024</span><span class=\"p\">],</span> <span class=\"n\">keep_prob</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">),</span> <span class=\"n\">Reverse</span><span class=\"p\">(),</span> <span class=\"n\">MAF</span><span class=\"p\">([</span><span class=\"mi\">1024</span><span class=\"p\">],</span> <span class=\"n\">keep_prob</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">),</span> <span class=\"n\">UnitGaussianPrior</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># Initialize the flow.  This example will not condition on a variable.</span>\n<span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">PRNGKey</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">names</span><span class=\"p\">,</span> <span class=\"n\">output_shape</span><span class=\"p\">,</span> <span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"n\">init_fun</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">condition_shape</span><span class=\"o\">=</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># Create the loss function and its gradients</span>\n<span class=\"k\">def</span> <span class=\"nf\">nll</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n    <span class=\"n\">log_px</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">updated_state</span> <span class=\"o\">=</span> <span class=\"n\">forward</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">cond</span><span class=\"o\">=</span><span class=\"p\">(),</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"o\">-</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">log_px</span><span class=\"p\">),</span> <span class=\"n\">updated_state</span>\n<span class=\"n\">valgrad</span> <span class=\"o\">=</span> <span class=\"n\">jit</span><span class=\"p\">(</span><span class=\"n\">value_and_grad</span><span class=\"p\">(</span><span class=\"n\">nll</span><span class=\"p\">,</span> <span class=\"n\">has_aux</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Create the optimizer</span>\n<span class=\"n\">opt_init</span><span class=\"p\">,</span> <span class=\"n\">opt_update</span><span class=\"p\">,</span> <span class=\"n\">get_params</span> <span class=\"o\">=</span> <span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">adam</span><span class=\"p\">(</span><span class=\"mf\">0.001</span><span class=\"p\">)</span>\n<span class=\"n\">opt_state</span> <span class=\"o\">=</span> <span class=\"n\">opt_init</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Train the flow</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">):</span>\n    <span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">keys</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)</span>\n    <span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">get_params</span><span class=\"p\">(</span><span class=\"n\">opt_state</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">),</span> <span class=\"n\">grad</span> <span class=\"o\">=</span> <span class=\"n\">valgrad</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">,</span> <span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"n\">keys</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">test</span><span class=\"o\">=</span><span class=\"n\">TRAIN</span><span class=\"p\">)</span>\n    <span class=\"n\">opt_state</span> <span class=\"o\">=</span> <span class=\"n\">opt_update</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">grad</span><span class=\"p\">,</span> <span class=\"n\">opt_state</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Generate samples from the model</span>\n<span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">keys</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]))</span>\n<span class=\"n\">log_pfz</span><span class=\"p\">,</span> <span class=\"n\">fz</span><span class=\"p\">,</span> <span class=\"n\">_</span> <span class=\"o\">=</span> <span class=\"n\">inverse</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"n\">z</span><span class=\"p\">,</span> <span class=\"n\">cond</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"n\">keys</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">test</span><span class=\"o\">=</span><span class=\"n\">TEST</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 7102358, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "eb9714db895b6e2761b79cb843371b7f", "sha256": "f795d75ac5fab81ce9538243539f71f3652e75045e68b581fca6529e2ca764d9"}, "downloads": -1, "filename": "nux-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "eb9714db895b6e2761b79cb843371b7f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32726, "upload_time": "2020-04-26T02:38:11", "upload_time_iso_8601": "2020-04-26T02:38:11.949580Z", "url": "https://files.pythonhosted.org/packages/e8/6b/e66e873578fbd73fdd930dc89f3d41dbd304f0a5cf9a78a030245485c851/nux-0.0.1-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "e7678c021b43b4f9ac0980096e2849b5", "sha256": "1aae24b87cefd60fe75c1a3db5b6337271fd6a5e9037ff5e10fa9114731828b6"}, "downloads": -1, "filename": "nux-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "e7678c021b43b4f9ac0980096e2849b5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32728, "upload_time": "2020-04-26T02:39:47", "upload_time_iso_8601": "2020-04-26T02:39:47.893570Z", "url": "https://files.pythonhosted.org/packages/61/91/b2a6b4021d0a80598c040ad2d1228d6476964306789f0abf3736700ca6e5/nux-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d4211f9f7bc74e3ee1b46b32d7fc261b", "sha256": "ce98b62fd8b9e5ada6993afcdcabf6f79c76195fcf5bb4dfc25f271b6069dc62"}, "downloads": -1, "filename": "nux-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d4211f9f7bc74e3ee1b46b32d7fc261b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 30173, "upload_time": "2020-04-26T02:39:49", "upload_time_iso_8601": "2020-04-26T02:39:49.034137Z", "url": "https://files.pythonhosted.org/packages/6d/f8/7181563d2f242c5eae8c8bef457058ba9b1f74ab45064db8c5f9ca42bed9/nux-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e7678c021b43b4f9ac0980096e2849b5", "sha256": "1aae24b87cefd60fe75c1a3db5b6337271fd6a5e9037ff5e10fa9114731828b6"}, "downloads": -1, "filename": "nux-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "e7678c021b43b4f9ac0980096e2849b5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32728, "upload_time": "2020-04-26T02:39:47", "upload_time_iso_8601": "2020-04-26T02:39:47.893570Z", "url": "https://files.pythonhosted.org/packages/61/91/b2a6b4021d0a80598c040ad2d1228d6476964306789f0abf3736700ca6e5/nux-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d4211f9f7bc74e3ee1b46b32d7fc261b", "sha256": "ce98b62fd8b9e5ada6993afcdcabf6f79c76195fcf5bb4dfc25f271b6069dc62"}, "downloads": -1, "filename": "nux-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d4211f9f7bc74e3ee1b46b32d7fc261b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 30173, "upload_time": "2020-04-26T02:39:49", "upload_time_iso_8601": "2020-04-26T02:39:49.034137Z", "url": "https://files.pythonhosted.org/packages/6d/f8/7181563d2f242c5eae8c8bef457058ba9b1f74ab45064db8c5f9ca42bed9/nux-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:05 2020"}