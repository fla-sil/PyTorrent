{"info": {"author": "Victor Popov", "author_email": "victorvtf@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Topic :: Software Development :: Build Tools"], "description": "This module provides a handful of functions to simplify the typical data processing operations and simplifying data verification procedures.\n\n# Dependencies\n* `numpy 1.17.1`\n* `pandas 0.25.1`\n\n# Installation Guide\n\n* `pip install helper-funcs`\n\n# Usage\n\nImport class \"HF\" from module \"helper_funcs\":\n\n* `from helper_funcs import HF`\n\nAnd then call any of the methods described below.\n\n# Methods\n\n---\n\n* `df_preview(df, n_samples)`\n\n    ***Description***\n    \n    Creates a nice summary table of your DataFrame.\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame you want to create a preview for.\n           \n    * **`n_samples`: int, optional (default = 2)**\n    \n        Number of unique values from each column to be displayed.\n    \n    ***Returns***\n    \n    * pandas.DataFrame containing the summary information about the passed DataFrame.\n    \n---\n    \n* `rename_col(df, old_name, new_name)`\n\n    ***Description***\n    \n    Renames the specified column.\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame you want to create a preview for.\n           \n    * **`old_name`: str**\n    \n        Name of existing `df` column to be renamed.\n        \n    * **`new_name`: str**\n    \n        Name which will replace the `old_name` column name.\n    \n    ***Returns***\n    \n    * pandas.DataFrame with the renamed column.\n    \n---\n    \n* `columns_mismatch(col_1, col_2)`\n\n    ***Description***\n    \n    Extracts values that are present in `col_1`, but not in `col_2`.\n    \n    ***Parameters***\n    \n    * **`col_1`: pandas.Series**\n    \n        The Series you want to subtract values from.\n           \n    * **`col_2`: pandas.Series**\n    \n        The Series which is subtracted from `col_1`.\n        \n    Note: The word \"subtract\" is used not in arithmetical sense, but in a set difference sense.\n    \n    ***Returns***\n    \n    * Set with values which `col_1` contains and `col_2` does not contain.\n    \n---\n\n* `df_difference(df_1, df_2)`\n\n    ***Description***\n    \n    Extracts rows that are present in `df_1`, but not in `df_2`. \n    \n    Note: `df_1` and `df_2` can have different column names, but number of columns should match.\n    \n    ***Parameters***\n    \n    * **`df_1`: pandas.DataFrame**\n    \n        The DataFrame you want to subtract values from.\n           \n    * **`df_2`: pandas.DataFrame**\n    \n        The DataFrame which is subtracted from `df_1`.\n        \n    Note: The word \"subtract\" is used not in arithmetical sense, but in a set difference sense.\n    \n    ***Returns***\n    \n    * pandas.DataFrame with rows which `df_1` contains and `df_2` does not contain.\n    \n---\n    \n* `verify_dates_integity(df, date_col)`\n\n    ***Description***\n    \n    Checks whether there are any missing dates between earliest and latest dates from `df[date_col]`\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame which after selecting values from `date_col` will be verified for integrity\n           \n    * **`date_col`: str**\n    \n        Name of `df` column that will be verified for integrity\n        \n---\n       \n* `duplicate(df, how, n_times)`\n\n    ***Description***\n    \n    Extends the specified DataFrame by repeating its rows.\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame which rows you want to repeat\n           \n    * **`how`: str**\n    \n        Strategy for repeating. Should be either 'whole' (then [1,2] -> [1,2,1,2]) or\n        'element_wise' (then [1,2] -> [1,1,2,2])\n        \n    * **`n_times`: int**\n    \n        Number of repetitions of each row\n    \n    ***Returns***\n    \n    * Extended pandas.DataFrame with repeated rows\n    \n---\n    \n* `groupby_to_list(df, by_cols, col_to_list)`\n\n    ***Description***\n    \n    Extracts values of `col_to_list` column that correspond to the same values in \n    `by_cols` column(s) and put them to list.\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame which you want to use\n           \n    * **`by_cols`: list of str**\n    \n        Column names that will be used as keys in `df`\n        \n    * **`col_to_list`: str**\n    \n        Column name which values will be put to lists\n    \n    ***Returns***\n    \n    * pandas.DataFrame with columns [`by_cols`, `col_to_list`] so that all the values in `col_to_list` column are lists.\n    \n---\n    \n* `chunkenize(data_to_split, num_chunks, df_indices, copy)`\n\n    ***Description***\n    \n    Splits the `data_to_split` into list with `num_chunks` chunks. Can be helpful when preparing \n    data for parallel processing.\n    \n    ***Parameters***\n    \n    * **`data_to_split`: pandas.DataFrame or list**\n    \n        The DataFrame which you want to split in chunks\n        \n    * **`num_chunks`: int**\n    \n        Number of chunks that your data will be split in\n        \n    * **`df_indices`: list of str, optional (default = [])**\n    \n        This can be used when `data_to_split` is pandas.DataFrame. These column will be used\n        as DataFrame index before splitting and will be reset afterwards.\n        \n    * **`copy`: bool, optional (default = True)**\n    \n        Determines whether you want to perform splitting on a copy of `data_to_split`.\n    \n    ***Returns***\n    \n    * List of `num_chunks` chunks that have same type as `data_to_split`.\n    \n---\n\n* `filter_df(df, col_name, l_bound, r_bound, inclusive)`\n\n    ***Description***\n    \n    Filters the `df` DataFrame `col_name` column so that it contains only records\n    that corresponds to `df`[`col_name`] values in the range between `l_bound` and `r_bound`.\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame which column `col_name` you want to filter\n           \n    * **`col_name`: str**\n    \n        Column name from `df` which values you want to filter `df` on\n        \n    * **`l_bound`: same type as values of `df`[`col_name`]**\n    \n        Left bound of the filtered values range. Can be omitted if `r_bound` is specified\n        \n    * **`r_bound`: same type as values of `df`[`col_name`]**\n    \n        Right bound of the filtered values range. Can be omitted if `l_bound` is specified\n        \n    * **`inclusive`: bool, optional (default = True)**\n    \n        Determines whether you want range to be inclusive (True) or exclusive (False)\n    \n    ***Returns***\n    \n    * Filtered pandas.DataFrame\n        \n---\n\n* `prepare_str_cols(df, make_uppercase)`\n\n    ***Description***\n    \n    Strips leading and trailing spaces in str columns of `df` and makes those values to either upper-case or lower-case.\n    \n    ***Parameters***\n    \n    * **`df`: pandas.DataFrame**\n    \n        The DataFrame you want to prepare str columns for.\n           \n    * **`make_uppercase`: bool**\n    \n        Determines whether you want str values to be upper-cased or lower-cased.\n    \n    ***Returns***\n    \n    * pandas.DataFrame where all strings are either upper-cased or lower-cased with all leading and trailing spaces removed.\n---", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/v-popov/helper_funcs/archive/v_0_1_35.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/v-popov/helper_funcs", "keywords": "Helper,Functions,Data Science", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "helper-funcs", "package_url": "https://pypi.org/project/helper-funcs/", "platform": "", "project_url": "https://pypi.org/project/helper-funcs/", "project_urls": {"Download": "https://github.com/v-popov/helper_funcs/archive/v_0_1_35.tar.gz", "Homepage": "https://github.com/v-popov/helper_funcs"}, "release_url": "https://pypi.org/project/helper-funcs/0.1.35/", "requires_dist": null, "requires_python": "", "summary": "This module provides a handful of functions to simplify the typical data processing operations and simplifying data verification procedures.", "version": "0.1.35", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This module provides a handful of functions to simplify the typical data processing operations and simplifying data verification procedures.</p>\n<h1>Dependencies</h1>\n<ul>\n<li><code>numpy 1.17.1</code></li>\n<li><code>pandas 0.25.1</code></li>\n</ul>\n<h1>Installation Guide</h1>\n<ul>\n<li><code>pip install helper-funcs</code></li>\n</ul>\n<h1>Usage</h1>\n<p>Import class \"HF\" from module \"helper_funcs\":</p>\n<ul>\n<li><code>from helper_funcs import HF</code></li>\n</ul>\n<p>And then call any of the methods described below.</p>\n<h1>Methods</h1>\n<hr>\n<ul>\n<li>\n<p><code>df_preview(df, n_samples)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Creates a nice summary table of your DataFrame.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame you want to create a preview for.</p>\n</li>\n<li>\n<p><strong><code>n_samples</code>: int, optional (default = 2)</strong></p>\n<p>Number of unique values from each column to be displayed.</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>pandas.DataFrame containing the summary information about the passed DataFrame.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>rename_col(df, old_name, new_name)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Renames the specified column.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame you want to create a preview for.</p>\n</li>\n<li>\n<p><strong><code>old_name</code>: str</strong></p>\n<p>Name of existing <code>df</code> column to be renamed.</p>\n</li>\n<li>\n<p><strong><code>new_name</code>: str</strong></p>\n<p>Name which will replace the <code>old_name</code> column name.</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>pandas.DataFrame with the renamed column.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>columns_mismatch(col_1, col_2)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Extracts values that are present in <code>col_1</code>, but not in <code>col_2</code>.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>col_1</code>: pandas.Series</strong></p>\n<p>The Series you want to subtract values from.</p>\n</li>\n<li>\n<p><strong><code>col_2</code>: pandas.Series</strong></p>\n<p>The Series which is subtracted from <code>col_1</code>.</p>\n</li>\n</ul>\n<p>Note: The word \"subtract\" is used not in arithmetical sense, but in a set difference sense.</p>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>Set with values which <code>col_1</code> contains and <code>col_2</code> does not contain.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>df_difference(df_1, df_2)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Extracts rows that are present in <code>df_1</code>, but not in <code>df_2</code>.</p>\n<p>Note: <code>df_1</code> and <code>df_2</code> can have different column names, but number of columns should match.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df_1</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame you want to subtract values from.</p>\n</li>\n<li>\n<p><strong><code>df_2</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame which is subtracted from <code>df_1</code>.</p>\n</li>\n</ul>\n<p>Note: The word \"subtract\" is used not in arithmetical sense, but in a set difference sense.</p>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>pandas.DataFrame with rows which <code>df_1</code> contains and <code>df_2</code> does not contain.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>verify_dates_integity(df, date_col)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Checks whether there are any missing dates between earliest and latest dates from <code>df[date_col]</code></p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame which after selecting values from <code>date_col</code> will be verified for integrity</p>\n</li>\n<li>\n<p><strong><code>date_col</code>: str</strong></p>\n<p>Name of <code>df</code> column that will be verified for integrity</p>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>duplicate(df, how, n_times)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Extends the specified DataFrame by repeating its rows.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame which rows you want to repeat</p>\n</li>\n<li>\n<p><strong><code>how</code>: str</strong></p>\n<p>Strategy for repeating. Should be either 'whole' (then [1,2] -&gt; [1,2,1,2]) or\n'element_wise' (then [1,2] -&gt; [1,1,2,2])</p>\n</li>\n<li>\n<p><strong><code>n_times</code>: int</strong></p>\n<p>Number of repetitions of each row</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>Extended pandas.DataFrame with repeated rows</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>groupby_to_list(df, by_cols, col_to_list)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Extracts values of <code>col_to_list</code> column that correspond to the same values in\n<code>by_cols</code> column(s) and put them to list.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame which you want to use</p>\n</li>\n<li>\n<p><strong><code>by_cols</code>: list of str</strong></p>\n<p>Column names that will be used as keys in <code>df</code></p>\n</li>\n<li>\n<p><strong><code>col_to_list</code>: str</strong></p>\n<p>Column name which values will be put to lists</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>pandas.DataFrame with columns [<code>by_cols</code>, <code>col_to_list</code>] so that all the values in <code>col_to_list</code> column are lists.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>chunkenize(data_to_split, num_chunks, df_indices, copy)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Splits the <code>data_to_split</code> into list with <code>num_chunks</code> chunks. Can be helpful when preparing\ndata for parallel processing.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>data_to_split</code>: pandas.DataFrame or list</strong></p>\n<p>The DataFrame which you want to split in chunks</p>\n</li>\n<li>\n<p><strong><code>num_chunks</code>: int</strong></p>\n<p>Number of chunks that your data will be split in</p>\n</li>\n<li>\n<p><strong><code>df_indices</code>: list of str, optional (default = [])</strong></p>\n<p>This can be used when <code>data_to_split</code> is pandas.DataFrame. These column will be used\nas DataFrame index before splitting and will be reset afterwards.</p>\n</li>\n<li>\n<p><strong><code>copy</code>: bool, optional (default = True)</strong></p>\n<p>Determines whether you want to perform splitting on a copy of <code>data_to_split</code>.</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>List of <code>num_chunks</code> chunks that have same type as <code>data_to_split</code>.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>filter_df(df, col_name, l_bound, r_bound, inclusive)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Filters the <code>df</code> DataFrame <code>col_name</code> column so that it contains only records\nthat corresponds to <code>df</code>[<code>col_name</code>] values in the range between <code>l_bound</code> and <code>r_bound</code>.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame which column <code>col_name</code> you want to filter</p>\n</li>\n<li>\n<p><strong><code>col_name</code>: str</strong></p>\n<p>Column name from <code>df</code> which values you want to filter <code>df</code> on</p>\n</li>\n<li>\n<p><strong><code>l_bound</code>: same type as values of <code>df</code>[<code>col_name</code>]</strong></p>\n<p>Left bound of the filtered values range. Can be omitted if <code>r_bound</code> is specified</p>\n</li>\n<li>\n<p><strong><code>r_bound</code>: same type as values of <code>df</code>[<code>col_name</code>]</strong></p>\n<p>Right bound of the filtered values range. Can be omitted if <code>l_bound</code> is specified</p>\n</li>\n<li>\n<p><strong><code>inclusive</code>: bool, optional (default = True)</strong></p>\n<p>Determines whether you want range to be inclusive (True) or exclusive (False)</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>Filtered pandas.DataFrame</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><code>prepare_str_cols(df, make_uppercase)</code></p>\n<p><em><strong>Description</strong></em></p>\n<p>Strips leading and trailing spaces in str columns of <code>df</code> and makes those values to either upper-case or lower-case.</p>\n<p><em><strong>Parameters</strong></em></p>\n<ul>\n<li>\n<p><strong><code>df</code>: pandas.DataFrame</strong></p>\n<p>The DataFrame you want to prepare str columns for.</p>\n</li>\n<li>\n<p><strong><code>make_uppercase</code>: bool</strong></p>\n<p>Determines whether you want str values to be upper-cased or lower-cased.</p>\n</li>\n</ul>\n<p><em><strong>Returns</strong></em></p>\n<ul>\n<li>pandas.DataFrame where all strings are either upper-cased or lower-cased with all leading and trailing spaces removed.</li>\n</ul>\n</li>\n</ul>\n<hr>\n\n          </div>"}, "last_serial": 6110240, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "9ef8678f1c9fdd9ca10b229474e0850d", "sha256": "21cb15db4502587e57be106dce19db8d6160c685fbdeaf12f6e5c05c6c938680"}, "downloads": -1, "filename": "helper_funcs-0.1.tar.gz", "has_sig": false, "md5_digest": "9ef8678f1c9fdd9ca10b229474e0850d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4911, "upload_time": "2019-10-19T02:50:33", "upload_time_iso_8601": "2019-10-19T02:50:33.982439Z", "url": "https://files.pythonhosted.org/packages/83/99/ce61ee9c1311b20fd8f761df9f9daba4db060880909f7398cd8a2a5f3065/helper_funcs-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "0e483fc193aeb43d4f2257efb27599dc", "sha256": "d074eb09d38b201311cb254103cea5d3762f528fa8e1800470887766dadbc80f"}, "downloads": -1, "filename": "helper_funcs-0.1.1.tar.gz", "has_sig": false, "md5_digest": "0e483fc193aeb43d4f2257efb27599dc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5782, "upload_time": "2019-10-19T03:26:22", "upload_time_iso_8601": "2019-10-19T03:26:22.985930Z", "url": "https://files.pythonhosted.org/packages/d0/a4/9df495b01f9a48d1354192e8695c380d6150512aff2bc64e8d4291eb56e9/helper_funcs-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "9b7b42479261d396f8beaffd8f704c71", "sha256": "5758b7a1f0dffae39da187b02acea01ed713f025f21ed4bb4b1a3c47a5e6ba57"}, "downloads": -1, "filename": "helper_funcs-0.1.2.tar.gz", "has_sig": false, "md5_digest": "9b7b42479261d396f8beaffd8f704c71", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5706, "upload_time": "2019-10-19T03:33:35", "upload_time_iso_8601": "2019-10-19T03:33:35.687462Z", "url": "https://files.pythonhosted.org/packages/bc/8d/14814514539fdb7d10c34f65164f1e6d87a76560121293783c9707471048/helper_funcs-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "8d20a39f5c65b682f9b15ea701a6ed6c", "sha256": "0a47bfcba6ed200dfbfdd9fe6854d269432d1eb3e1bf45200fbdde9e9d4e5741"}, "downloads": -1, "filename": "helper_funcs-0.1.3.tar.gz", "has_sig": false, "md5_digest": "8d20a39f5c65b682f9b15ea701a6ed6c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5683, "upload_time": "2019-10-19T03:35:02", "upload_time_iso_8601": "2019-10-19T03:35:02.089082Z", "url": "https://files.pythonhosted.org/packages/b5/08/6d02c21c0d345dc48656eb8ea9a0fae2232059f12505a5f0ee1b89d6ad76/helper_funcs-0.1.3.tar.gz", "yanked": false}], "0.1.32": [{"comment_text": "", "digests": {"md5": "7c734c04947b8f3d2d52af5692936822", "sha256": "e733c873ad64859d3b5a7b9c60efd8a04fb54129c4fc2b64261d6af846c9abf2"}, "downloads": -1, "filename": "helper_funcs-0.1.32.tar.gz", "has_sig": false, "md5_digest": "7c734c04947b8f3d2d52af5692936822", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5774, "upload_time": "2019-10-19T04:16:10", "upload_time_iso_8601": "2019-10-19T04:16:10.040636Z", "url": "https://files.pythonhosted.org/packages/b8/31/2f8d1e5bf522da91033f8755d2d8a8854df011279ec6b853251220ea7c19/helper_funcs-0.1.32.tar.gz", "yanked": false}], "0.1.33": [{"comment_text": "", "digests": {"md5": "6f2f4dc25412e37a36a119296502432e", "sha256": "f747fff601f42344a3769b2c4e3cb305fdc1fafa0bc7c90ad72943d8cfae3924"}, "downloads": -1, "filename": "helper_funcs-0.1.33.tar.gz", "has_sig": false, "md5_digest": "6f2f4dc25412e37a36a119296502432e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5882, "upload_time": "2019-10-19T04:22:42", "upload_time_iso_8601": "2019-10-19T04:22:42.000604Z", "url": "https://files.pythonhosted.org/packages/88/5c/3e402ed46459b3e29c6ee13255520f6dabfc746f9330f35d30673eea93ce/helper_funcs-0.1.33.tar.gz", "yanked": false}], "0.1.34": [{"comment_text": "", "digests": {"md5": "2ef82d25020cf76c0ca1a1348a97990c", "sha256": "f60bdde745292d4161ad6edf8ed1bc63f916f79b4488524e4ce9fd90efa195a6"}, "downloads": -1, "filename": "helper_funcs-0.1.34.tar.gz", "has_sig": false, "md5_digest": "2ef82d25020cf76c0ca1a1348a97990c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5974, "upload_time": "2019-10-29T04:24:27", "upload_time_iso_8601": "2019-10-29T04:24:27.362837Z", "url": "https://files.pythonhosted.org/packages/ab/f0/02af290c0bcd6221a68032f0f358e4bab7e32a26e1c9e064c9a915b95e8f/helper_funcs-0.1.34.tar.gz", "yanked": false}], "0.1.35": [{"comment_text": "", "digests": {"md5": "0b4e21ad861731706994faee99d0e016", "sha256": "97dd1fb9d2189e30eb248947f0b47c6def7159706c21ed1d8bbc925ff23f1c44"}, "downloads": -1, "filename": "helper_funcs-0.1.35.tar.gz", "has_sig": false, "md5_digest": "0b4e21ad861731706994faee99d0e016", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6323, "upload_time": "2019-11-10T01:38:16", "upload_time_iso_8601": "2019-11-10T01:38:16.015100Z", "url": "https://files.pythonhosted.org/packages/d2/dd/ca0024e52c183bb43d91c1fafef30323bd35d46026624fc57c0611b2fa2c/helper_funcs-0.1.35.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "bdbceba60c0134deaa1a78d527833c93", "sha256": "4ca3683e53ad016653b16d65fc1c2495c7ea7d42317af06dc0119e91571b7598"}, "downloads": -1, "filename": "helper_funcs-0.1.4.tar.gz", "has_sig": false, "md5_digest": "bdbceba60c0134deaa1a78d527833c93", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5970, "upload_time": "2019-10-29T04:22:15", "upload_time_iso_8601": "2019-10-29T04:22:15.474248Z", "url": "https://files.pythonhosted.org/packages/8b/72/75858d7daad1162b5cbb94df61f835b94e89cc7a3a6d4999fa820a21baf3/helper_funcs-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0b4e21ad861731706994faee99d0e016", "sha256": "97dd1fb9d2189e30eb248947f0b47c6def7159706c21ed1d8bbc925ff23f1c44"}, "downloads": -1, "filename": "helper_funcs-0.1.35.tar.gz", "has_sig": false, "md5_digest": "0b4e21ad861731706994faee99d0e016", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6323, "upload_time": "2019-11-10T01:38:16", "upload_time_iso_8601": "2019-11-10T01:38:16.015100Z", "url": "https://files.pythonhosted.org/packages/d2/dd/ca0024e52c183bb43d91c1fafef30323bd35d46026624fc57c0611b2fa2c/helper_funcs-0.1.35.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:39 2020"}