{"info": {"author": "Matthew Muckley", "author_email": "Matthew.Muckley@nyulangone.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Scientific/Engineering :: Medical Science Apps.", "Topic :: Scientific/Engineering :: Physics"], "description": "# Torch KB-NUFFT\n\n[API](https://torchkbnufft.readthedocs.io) | [GitHub](https://github.com/mmuckley/torchkbnufft) | [Notebook Examples](https://github.com/mmuckley/torchkbnufft/tree/master/notebooks) | [Sedona Workshop Demo](https://github.com/mmuckley/torchkbnufft_demo)\n\nSimple installation from PyPI:\n\n```bash\npip install torchkbnufft\n```\n\n## About\n\nTorch KB-NUFFT implements a non-uniform Fast Fourier Transform [1, 2] with Kaiser-Bessel gridding in PyTorch. The implementation is completely in Python, facilitating robustness and flexible deployment in human-readable code. NUFFT functions are each wrapped as a ```torch.autograd.Function```, allowing backpropagation through NUFFT operators for training neural networks.\n\nThis package was inspired in large part by the implementation of NUFFT operations in the Matlab version of the Michigan Image Reconstruction Toolbox, available at <https://web.eecs.umich.edu/~fessler/code/index.html>.\n\n### Operation Modes and Stages\n\nThe package has three major classes of NUFFT operation mode: table-based NUFFT interpolation, sparse matrix-based NUFFT interpolation, and forward/backward operators with Toeplitz-embedded FFTs [3]. In most cases, computation speed follows\n\ntable < sparse matrix < Toeplitz embedding,\n\nbut better computation speed can require increased memory usage.\n\nIn addition to the three main operation modes, the package separates SENSE-NUFFT operations into three stages that can be used individually as PyTorch modules: interpolation (```torchkbnufft.KbInterp```), NUFFT (```torchkbnufft.KbNufft```), and SENSE-NUFFT (```torchkbnufft.MriSenseNufft```). The interpolation modules only apply interpolation (without scaling coefficients). The NUFFT applies the full the NUFFT for a single image into non-Cartesian k-space, including scaling coefficients. The SENSE-NUFFT can be used to include sensitivity coil multiplications, which by default at a lower level will use PyTorch broadcasting backends that enable faster multiplications across the coils.\n\nWhere appropriate, each of the NUFFT stages can be used with each NUFFT operation mode. Simple examples follow.\n\n## Documentation\n\nMost files are accompanied with docstrings that can be read with ```help``` while running IPython. Example:\n\n```python\nfrom torchkbnufft import KbNufft\n\nhelp(KbNufft)\n```\n\nBehavior can also be inferred by inspecting the source code [here](https://github.com/mmuckley/torchkbnufft). An html-based API reference is [here](https://torchkbnufft.readthedocs.io).\n\n## Examples\n\n### Simple Forward NUFFT\n\nJupyter notebook examples are in the ```notebooks/``` folder. The following minimalist code loads a Shepp-Logan phantom and computes a single radial spoke of k-space data:\n\n```python\nimport torch\nimport numpy as np\nfrom torchkbnufft import KbNufft\nfrom skimage.data import shepp_logan_phantom\n\nx = shepp_logan_phantom().astype(np.complex)\nim_size = x.shape\nx = np.stack((np.real(x), np.imag(x)))\n# convert to tensor, unsqueeze batch and coil dimension\n# output size: (1, 1, 2, ny, nx)\nx = torch.tensor(x).unsqueeze(0).unsqueeze(0)\n\nklength = 64\nktraj = np.stack(\n    (np.zeros(64), np.linspace(-np.pi, np.pi, klength))\n)\n# convert to tensor, unsqueeze batch dimension\n# output size: (1, 2, klength)\nktraj = torch.tensor(ktraj).unsqueeze(0)\n\nnufft_ob = KbNufft(im_size=im_size)\n# outputs a (1, 1, 2, klength) vector of k-space data\nkdata = nufft_ob(x, ktraj)\n```\n\nA detailed example of basic NUFFT usage is [here](https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/Basic%20Example.ipynb).\n\n### SENSE-NUFFT\n\nThe package also includes utilities for working with SENSE-NUFFT operators. The above code can be modified to replace the ```nufft_ob``` with the following ```sensenufft_ob```:\n\n```python\nfrom torchkbnufft import MriSenseNufft\n\nsmap = torch.rand(1, 8, 2, 400, 400)\nsensenufft_ob = MriSenseNufft(im_size=im_size, smap=smap)\nsense_data = sensenufft_ob(x, ktraj)\n```\n\nApplication of the object in place of ```nufft_ob``` above would first multiply by the sensitivity coils in ```smap```, then compute a 64-length radial spoke for each coil. All operations are broadcast across coils, which minimizes interaction with the Python interpreter, helping computation speed.\n\nA detailed example of SENSE-NUFFT usage is [here](https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/SENSE%20Example.ipynb).\n\n### Sparse Matrix Precomputation\n\nSparse matrices are a fast operation mode on the CPU and for large problems at the cost of more memory usage. The following code calculates sparse interpolation matrices and uses them to compute a single radial spoke of k-space data:\n\n```python\nfrom torchkbnufft import AdjKbNufft\nfrom torchkbnufft.nufft.sparse_interp_mat import precomp_sparse_mats\n\nadjnufft_ob = AdjKbNufft(im_size=im_size)\n\n# precompute the sparse interpolation matrices\nreal_mat, imag_mat = precomp_sparse_mats(ktraj, adjnufft_ob)\ninterp_mats = {\n    'real_interp_mats': real_mat,\n    'imag_interp_mats': imag_mat\n}\n\n# use sparse matrices in adjoint\nimage = adjnufft_ob(kdata, ktraj, interp_mats)\n```\n\nA detailed example of sparse matrix precomputation usage is [here](https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/Sparse%20Matrix%20Example.ipynb).\n\n### Toeplitz Embedding\n\nThe package includes routines for calculating embedded Toeplitz kernels and using them as FFT filters for the forward/backward NUFFT operations [3]. This is very useful for gradient descent algorithms that must use the forward/backward ops in calculating the gradient. The following minimalist code shows an example:\n\n```python\nfrom torchkbnufft import AdjKbNufft, ToepNufft\nfrom torchkbnufft.nufft.toep_functions import calc_toep_kernel\n\nadjnufft_ob = AdjKbNufft(im_size=im_size)\ntoep_ob = ToepNufft()\n\n# precompute the embedded Toeplitz FFT kernel\nkern = calc_toep_kernel(adjnufft_ob, ktraj)\n\n# use FFT kernel from embedded Toeplitz matrix\nimage = toep_ob(image, kern)\n```\n\nA detailed example of sparse matrix precomputation usage is included in [here](https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/Toeplitz%20Example.ipynb).\n\n### Running on the GPU\n\nAll of the examples included in this repository can be run on the GPU by sending the NUFFT object and data to the GPU prior to the function call, e.g.:\n\n```python\nadjnufft_ob = adjnufft_ob.to(torch.device('cuda'))\nkdata = kdata.to(torch.device('cuda'))\nktraj = ktraj.to(torch.device('cuda'))\n\nimage = adjnufft_ob(kdata, ktraj)\n```\n\nSimilar to programming low-level code, PyTorch will throw errors if the underlying ```dtype``` and ```device``` of all objects are not matching. Be sure to make sure your data and NUFFT objects are on the right device and in the right format to avoid these errors.\n\n## Computation Speed\n\nTorchKbNufft is first and foremost designed to be lightweight with minimal dependencies outside of PyTorch. Speed compared to other packages depends on problem size and usage mode - generally, favorable performance can be observed with large problems (2-3 times faster than some packages with 64 coils) when using spare matrices, whereas unfavorable performance occurs with small problems in table interpolation mode (2-3 times as slow as other packages).\n\nThe following computation times in seconds were observed on a workstation with a Xeon E5-1620 CPU and an Nvidia GTX 1080 GPU for a 15-coil, 405-spoke 2D radial problem. CPU computations were done with 64-bit floats, whereas GPU computations were done with 32-bit floats (v0.2.2).\n\n(n) = normal, (spm) = sparse matrix, (toep) = Toeplitz embedding, (f/b) = forward/backward combined\n\n| Operation      | CPU (n) | CPU (spm) | CPU (toep)  | GPU (n)  | GPU (spm) | GPU (toep)     |\n| -------------- | -------:| ---------:| -----------:| --------:| ---------:| --------------:|\n| Forward NUFFT  | 3.57    | 1.61      | 0.145 (f/b) | 1.00e-01 | 1.57e-01  | 5.16e-03 (f/b) |\n| Adjoint NUFFT  | 4.52    | 1.04      | N/A         | 1.06e-01 | 1.63e-01  | N/A            |\n\nProfiling for your machine can be done by running\n\n```python\npython profile_torchkbnufft.py\n```\n\n## Other Packages\n\nFor users interested in NUFFT implementations for other computing platforms, the following is a partial list of other projects:\n\n1. [TF KB-NUFFT](https://github.com/zaccharieramzi/tfkbnufft) (KB-NUFFT for TensorFlow)\n2. [SigPy](https://github.com/mikgroup/sigpy) (for Numpy arrays, Numba (for CPU) and CuPy (for GPU) backends)\n3. [FINUFFT](https://github.com/flatironinstitute/finufft) (for MATLAB, Python, Julia, C, etc., very efficient)\n4. [NFFT](https://github.com/NFFT/nfft) (for Julia)\n5. [PyNUFFT](https://github.com/jyhmiinlin/pynufft) (for Numpy, also has PyCUDA/PyOpenCL backends)\n\n## References\n\n1. Fessler, J. A., & Sutton, B. P. (2003). Nonuniform fast Fourier transforms using min-max interpolation. *IEEE transactions on signal processing*, 51(2), 560-574.\n\n2. Beatty, P. J., Nishimura, D. G., & Pauly, J. M. (2005). Rapid gridding reconstruction with a minimal oversampling ratio. *IEEE transactions on medical imaging*, 24(6), 799-808.\n\n3. Feichtinger, H. G., Gr, K., & Strohmer, T. (1995). Efficient numerical methods in non-uniform sampling theory. Numerische Mathematik, 69(4), 423-440.\n\n## Citation\n\nIf you want to cite the package, you can use any of the following:\n\n```bibtex\n@conference{muckley:20:tah,\n  author = {M. J. Muckley and R. Stern and T. Murrell and F. Knoll},\n  title = {{TorchKbNufft}: A High-Level, Hardware-Agnostic Non-Uniform Fast Fourier Transform},\n  booktitle = {ISMRM Workshop on Data Sampling \\& Image Reconstruction},\n  year = 2020\n}\n\n@misc{Muckley2019,\n  author = {Muckley, M.J. et al.},\n  title = {Torch KB-NUFFT},\n  year = {2019},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/mmuckley/torchkbnufft}}\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/mmuckley/torchkbnufft", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mmuckley/torchkbnufft", "keywords": "MRI,pytorch", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torchkbnufft", "package_url": "https://pypi.org/project/torchkbnufft/", "platform": "", "project_url": "https://pypi.org/project/torchkbnufft/", "project_urls": {"Download": "https://github.com/mmuckley/torchkbnufft", "Homepage": "https://github.com/mmuckley/torchkbnufft"}, "release_url": "https://pypi.org/project/torchkbnufft/0.3.2.post1/", "requires_dist": ["torch (>=1.0.1)", "numpy (>=1.14)", "scipy (>=1.1)"], "requires_python": ">=3.5", "summary": "A robust, easy-to-deploy non-uniform Fast Fourier Transform in PyTorch.", "version": "0.3.2.post1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Torch KB-NUFFT</h1>\n<p><a href=\"https://torchkbnufft.readthedocs.io\" rel=\"nofollow\">API</a> | <a href=\"https://github.com/mmuckley/torchkbnufft\" rel=\"nofollow\">GitHub</a> | <a href=\"https://github.com/mmuckley/torchkbnufft/tree/master/notebooks\" rel=\"nofollow\">Notebook Examples</a> | <a href=\"https://github.com/mmuckley/torchkbnufft_demo\" rel=\"nofollow\">Sedona Workshop Demo</a></p>\n<p>Simple installation from PyPI:</p>\n<pre>pip install torchkbnufft\n</pre>\n<h2>About</h2>\n<p>Torch KB-NUFFT implements a non-uniform Fast Fourier Transform [1, 2] with Kaiser-Bessel gridding in PyTorch. The implementation is completely in Python, facilitating robustness and flexible deployment in human-readable code. NUFFT functions are each wrapped as a <code>torch.autograd.Function</code>, allowing backpropagation through NUFFT operators for training neural networks.</p>\n<p>This package was inspired in large part by the implementation of NUFFT operations in the Matlab version of the Michigan Image Reconstruction Toolbox, available at <a href=\"https://web.eecs.umich.edu/%7Efessler/code/index.html\" rel=\"nofollow\">https://web.eecs.umich.edu/~fessler/code/index.html</a>.</p>\n<h3>Operation Modes and Stages</h3>\n<p>The package has three major classes of NUFFT operation mode: table-based NUFFT interpolation, sparse matrix-based NUFFT interpolation, and forward/backward operators with Toeplitz-embedded FFTs [3]. In most cases, computation speed follows</p>\n<p>table &lt; sparse matrix &lt; Toeplitz embedding,</p>\n<p>but better computation speed can require increased memory usage.</p>\n<p>In addition to the three main operation modes, the package separates SENSE-NUFFT operations into three stages that can be used individually as PyTorch modules: interpolation (<code>torchkbnufft.KbInterp</code>), NUFFT (<code>torchkbnufft.KbNufft</code>), and SENSE-NUFFT (<code>torchkbnufft.MriSenseNufft</code>). The interpolation modules only apply interpolation (without scaling coefficients). The NUFFT applies the full the NUFFT for a single image into non-Cartesian k-space, including scaling coefficients. The SENSE-NUFFT can be used to include sensitivity coil multiplications, which by default at a lower level will use PyTorch broadcasting backends that enable faster multiplications across the coils.</p>\n<p>Where appropriate, each of the NUFFT stages can be used with each NUFFT operation mode. Simple examples follow.</p>\n<h2>Documentation</h2>\n<p>Most files are accompanied with docstrings that can be read with <code>help</code> while running IPython. Example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft</span> <span class=\"kn\">import</span> <span class=\"n\">KbNufft</span>\n\n<span class=\"n\">help</span><span class=\"p\">(</span><span class=\"n\">KbNufft</span><span class=\"p\">)</span>\n</pre>\n<p>Behavior can also be inferred by inspecting the source code <a href=\"https://github.com/mmuckley/torchkbnufft\" rel=\"nofollow\">here</a>. An html-based API reference is <a href=\"https://torchkbnufft.readthedocs.io\" rel=\"nofollow\">here</a>.</p>\n<h2>Examples</h2>\n<h3>Simple Forward NUFFT</h3>\n<p>Jupyter notebook examples are in the <code>notebooks/</code> folder. The following minimalist code loads a Shepp-Logan phantom and computes a single radial spoke of k-space data:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft</span> <span class=\"kn\">import</span> <span class=\"n\">KbNufft</span>\n<span class=\"kn\">from</span> <span class=\"nn\">skimage.data</span> <span class=\"kn\">import</span> <span class=\"n\">shepp_logan_phantom</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">shepp_logan_phantom</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">complex</span><span class=\"p\">)</span>\n<span class=\"n\">im_size</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">((</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">real</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">imag</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)))</span>\n<span class=\"c1\"># convert to tensor, unsqueeze batch and coil dimension</span>\n<span class=\"c1\"># output size: (1, 1, 2, ny, nx)</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"n\">klength</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n<span class=\"n\">ktraj</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">(</span>\n    <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">linspace</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">pi</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">pi</span><span class=\"p\">,</span> <span class=\"n\">klength</span><span class=\"p\">))</span>\n<span class=\"p\">)</span>\n<span class=\"c1\"># convert to tensor, unsqueeze batch dimension</span>\n<span class=\"c1\"># output size: (1, 2, klength)</span>\n<span class=\"n\">ktraj</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">ktraj</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"n\">nufft_ob</span> <span class=\"o\">=</span> <span class=\"n\">KbNufft</span><span class=\"p\">(</span><span class=\"n\">im_size</span><span class=\"o\">=</span><span class=\"n\">im_size</span><span class=\"p\">)</span>\n<span class=\"c1\"># outputs a (1, 1, 2, klength) vector of k-space data</span>\n<span class=\"n\">kdata</span> <span class=\"o\">=</span> <span class=\"n\">nufft_ob</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">ktraj</span><span class=\"p\">)</span>\n</pre>\n<p>A detailed example of basic NUFFT usage is <a href=\"https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/Basic%20Example.ipynb\" rel=\"nofollow\">here</a>.</p>\n<h3>SENSE-NUFFT</h3>\n<p>The package also includes utilities for working with SENSE-NUFFT operators. The above code can be modified to replace the <code>nufft_ob</code> with the following <code>sensenufft_ob</code>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft</span> <span class=\"kn\">import</span> <span class=\"n\">MriSenseNufft</span>\n\n<span class=\"n\">smap</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">400</span><span class=\"p\">,</span> <span class=\"mi\">400</span><span class=\"p\">)</span>\n<span class=\"n\">sensenufft_ob</span> <span class=\"o\">=</span> <span class=\"n\">MriSenseNufft</span><span class=\"p\">(</span><span class=\"n\">im_size</span><span class=\"o\">=</span><span class=\"n\">im_size</span><span class=\"p\">,</span> <span class=\"n\">smap</span><span class=\"o\">=</span><span class=\"n\">smap</span><span class=\"p\">)</span>\n<span class=\"n\">sense_data</span> <span class=\"o\">=</span> <span class=\"n\">sensenufft_ob</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">ktraj</span><span class=\"p\">)</span>\n</pre>\n<p>Application of the object in place of <code>nufft_ob</code> above would first multiply by the sensitivity coils in <code>smap</code>, then compute a 64-length radial spoke for each coil. All operations are broadcast across coils, which minimizes interaction with the Python interpreter, helping computation speed.</p>\n<p>A detailed example of SENSE-NUFFT usage is <a href=\"https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/SENSE%20Example.ipynb\" rel=\"nofollow\">here</a>.</p>\n<h3>Sparse Matrix Precomputation</h3>\n<p>Sparse matrices are a fast operation mode on the CPU and for large problems at the cost of more memory usage. The following code calculates sparse interpolation matrices and uses them to compute a single radial spoke of k-space data:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft</span> <span class=\"kn\">import</span> <span class=\"n\">AdjKbNufft</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft.nufft.sparse_interp_mat</span> <span class=\"kn\">import</span> <span class=\"n\">precomp_sparse_mats</span>\n\n<span class=\"n\">adjnufft_ob</span> <span class=\"o\">=</span> <span class=\"n\">AdjKbNufft</span><span class=\"p\">(</span><span class=\"n\">im_size</span><span class=\"o\">=</span><span class=\"n\">im_size</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># precompute the sparse interpolation matrices</span>\n<span class=\"n\">real_mat</span><span class=\"p\">,</span> <span class=\"n\">imag_mat</span> <span class=\"o\">=</span> <span class=\"n\">precomp_sparse_mats</span><span class=\"p\">(</span><span class=\"n\">ktraj</span><span class=\"p\">,</span> <span class=\"n\">adjnufft_ob</span><span class=\"p\">)</span>\n<span class=\"n\">interp_mats</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'real_interp_mats'</span><span class=\"p\">:</span> <span class=\"n\">real_mat</span><span class=\"p\">,</span>\n    <span class=\"s1\">'imag_interp_mats'</span><span class=\"p\">:</span> <span class=\"n\">imag_mat</span>\n<span class=\"p\">}</span>\n\n<span class=\"c1\"># use sparse matrices in adjoint</span>\n<span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">adjnufft_ob</span><span class=\"p\">(</span><span class=\"n\">kdata</span><span class=\"p\">,</span> <span class=\"n\">ktraj</span><span class=\"p\">,</span> <span class=\"n\">interp_mats</span><span class=\"p\">)</span>\n</pre>\n<p>A detailed example of sparse matrix precomputation usage is <a href=\"https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/Sparse%20Matrix%20Example.ipynb\" rel=\"nofollow\">here</a>.</p>\n<h3>Toeplitz Embedding</h3>\n<p>The package includes routines for calculating embedded Toeplitz kernels and using them as FFT filters for the forward/backward NUFFT operations [3]. This is very useful for gradient descent algorithms that must use the forward/backward ops in calculating the gradient. The following minimalist code shows an example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft</span> <span class=\"kn\">import</span> <span class=\"n\">AdjKbNufft</span><span class=\"p\">,</span> <span class=\"n\">ToepNufft</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchkbnufft.nufft.toep_functions</span> <span class=\"kn\">import</span> <span class=\"n\">calc_toep_kernel</span>\n\n<span class=\"n\">adjnufft_ob</span> <span class=\"o\">=</span> <span class=\"n\">AdjKbNufft</span><span class=\"p\">(</span><span class=\"n\">im_size</span><span class=\"o\">=</span><span class=\"n\">im_size</span><span class=\"p\">)</span>\n<span class=\"n\">toep_ob</span> <span class=\"o\">=</span> <span class=\"n\">ToepNufft</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># precompute the embedded Toeplitz FFT kernel</span>\n<span class=\"n\">kern</span> <span class=\"o\">=</span> <span class=\"n\">calc_toep_kernel</span><span class=\"p\">(</span><span class=\"n\">adjnufft_ob</span><span class=\"p\">,</span> <span class=\"n\">ktraj</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># use FFT kernel from embedded Toeplitz matrix</span>\n<span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">toep_ob</span><span class=\"p\">(</span><span class=\"n\">image</span><span class=\"p\">,</span> <span class=\"n\">kern</span><span class=\"p\">)</span>\n</pre>\n<p>A detailed example of sparse matrix precomputation usage is included in <a href=\"https://github.com/mmuckley/torchkbnufft/blob/master/notebooks/Toeplitz%20Example.ipynb\" rel=\"nofollow\">here</a>.</p>\n<h3>Running on the GPU</h3>\n<p>All of the examples included in this repository can be run on the GPU by sending the NUFFT object and data to the GPU prior to the function call, e.g.:</p>\n<pre><span class=\"n\">adjnufft_ob</span> <span class=\"o\">=</span> <span class=\"n\">adjnufft_ob</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s1\">'cuda'</span><span class=\"p\">))</span>\n<span class=\"n\">kdata</span> <span class=\"o\">=</span> <span class=\"n\">kdata</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s1\">'cuda'</span><span class=\"p\">))</span>\n<span class=\"n\">ktraj</span> <span class=\"o\">=</span> <span class=\"n\">ktraj</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s1\">'cuda'</span><span class=\"p\">))</span>\n\n<span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">adjnufft_ob</span><span class=\"p\">(</span><span class=\"n\">kdata</span><span class=\"p\">,</span> <span class=\"n\">ktraj</span><span class=\"p\">)</span>\n</pre>\n<p>Similar to programming low-level code, PyTorch will throw errors if the underlying <code>dtype</code> and <code>device</code> of all objects are not matching. Be sure to make sure your data and NUFFT objects are on the right device and in the right format to avoid these errors.</p>\n<h2>Computation Speed</h2>\n<p>TorchKbNufft is first and foremost designed to be lightweight with minimal dependencies outside of PyTorch. Speed compared to other packages depends on problem size and usage mode - generally, favorable performance can be observed with large problems (2-3 times faster than some packages with 64 coils) when using spare matrices, whereas unfavorable performance occurs with small problems in table interpolation mode (2-3 times as slow as other packages).</p>\n<p>The following computation times in seconds were observed on a workstation with a Xeon E5-1620 CPU and an Nvidia GTX 1080 GPU for a 15-coil, 405-spoke 2D radial problem. CPU computations were done with 64-bit floats, whereas GPU computations were done with 32-bit floats (v0.2.2).</p>\n<p>(n) = normal, (spm) = sparse matrix, (toep) = Toeplitz embedding, (f/b) = forward/backward combined</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th align=\"right\">CPU (n)</th>\n<th align=\"right\">CPU (spm)</th>\n<th align=\"right\">CPU (toep)</th>\n<th align=\"right\">GPU (n)</th>\n<th align=\"right\">GPU (spm)</th>\n<th align=\"right\">GPU (toep)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Forward NUFFT</td>\n<td align=\"right\">3.57</td>\n<td align=\"right\">1.61</td>\n<td align=\"right\">0.145 (f/b)</td>\n<td align=\"right\">1.00e-01</td>\n<td align=\"right\">1.57e-01</td>\n<td align=\"right\">5.16e-03 (f/b)</td>\n</tr>\n<tr>\n<td>Adjoint NUFFT</td>\n<td align=\"right\">4.52</td>\n<td align=\"right\">1.04</td>\n<td align=\"right\">N/A</td>\n<td align=\"right\">1.06e-01</td>\n<td align=\"right\">1.63e-01</td>\n<td align=\"right\">N/A</td>\n</tr></tbody></table>\n<p>Profiling for your machine can be done by running</p>\n<pre><span class=\"n\">python</span> <span class=\"n\">profile_torchkbnufft</span><span class=\"o\">.</span><span class=\"n\">py</span>\n</pre>\n<h2>Other Packages</h2>\n<p>For users interested in NUFFT implementations for other computing platforms, the following is a partial list of other projects:</p>\n<ol>\n<li><a href=\"https://github.com/zaccharieramzi/tfkbnufft\" rel=\"nofollow\">TF KB-NUFFT</a> (KB-NUFFT for TensorFlow)</li>\n<li><a href=\"https://github.com/mikgroup/sigpy\" rel=\"nofollow\">SigPy</a> (for Numpy arrays, Numba (for CPU) and CuPy (for GPU) backends)</li>\n<li><a href=\"https://github.com/flatironinstitute/finufft\" rel=\"nofollow\">FINUFFT</a> (for MATLAB, Python, Julia, C, etc., very efficient)</li>\n<li><a href=\"https://github.com/NFFT/nfft\" rel=\"nofollow\">NFFT</a> (for Julia)</li>\n<li><a href=\"https://github.com/jyhmiinlin/pynufft\" rel=\"nofollow\">PyNUFFT</a> (for Numpy, also has PyCUDA/PyOpenCL backends)</li>\n</ol>\n<h2>References</h2>\n<ol>\n<li>\n<p>Fessler, J. A., &amp; Sutton, B. P. (2003). Nonuniform fast Fourier transforms using min-max interpolation. <em>IEEE transactions on signal processing</em>, 51(2), 560-574.</p>\n</li>\n<li>\n<p>Beatty, P. J., Nishimura, D. G., &amp; Pauly, J. M. (2005). Rapid gridding reconstruction with a minimal oversampling ratio. <em>IEEE transactions on medical imaging</em>, 24(6), 799-808.</p>\n</li>\n<li>\n<p>Feichtinger, H. G., Gr, K., &amp; Strohmer, T. (1995). Efficient numerical methods in non-uniform sampling theory. Numerische Mathematik, 69(4), 423-440.</p>\n</li>\n</ol>\n<h2>Citation</h2>\n<p>If you want to cite the package, you can use any of the following:</p>\n<pre><span class=\"nc\">@conference</span><span class=\"p\">{</span><span class=\"nl\">muckley:20:tah</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{M. J. Muckley and R. Stern and T. Murrell and F. Knoll}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{{TorchKbNufft}: A High-Level, Hardware-Agnostic Non-Uniform Fast Fourier Transform}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{ISMRM Workshop on Data Sampling \\&amp; Image Reconstruction}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"m\">2020</span>\n<span class=\"p\">}</span>\n\n<span class=\"nc\">@misc</span><span class=\"p\">{</span><span class=\"nl\">Muckley2019</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Muckley, M.J. et al.}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Torch KB-NUFFT}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2019}</span><span class=\"p\">,</span>\n  <span class=\"na\">publisher</span> <span class=\"p\">=</span> <span class=\"s\">{GitHub}</span><span class=\"p\">,</span>\n  <span class=\"na\">journal</span> <span class=\"p\">=</span> <span class=\"s\">{GitHub repository}</span><span class=\"p\">,</span>\n  <span class=\"na\">howpublished</span> <span class=\"p\">=</span> <span class=\"s\">{\\url{https://github.com/mmuckley/torchkbnufft}}</span>\n<span class=\"p\">}</span>\n</pre>\n\n          </div>"}, "last_serial": 6743015, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ab65e5f6a1b8780423e0b36f5e038833", "sha256": "5847dd8a006fad8c4224043c94a869512b4fe0ceb90c0f99e82715456370021f"}, "downloads": -1, "filename": "torchkbnufft-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ab65e5f6a1b8780423e0b36f5e038833", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 28587, "upload_time": "2019-11-11T20:59:45", "upload_time_iso_8601": "2019-11-11T20:59:45.196288Z", "url": "https://files.pythonhosted.org/packages/2f/3c/e66ebe286e92b576169164ba863aa95bb874f1d84ea5ad157e7cf8785c8b/torchkbnufft-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8eb48813e2fc2726451e8dc0bfb40e96", "sha256": "f2b209d28140a834a8c758b9590cd292c785ecc0cd9d506538a77379695e3300"}, "downloads": -1, "filename": "torchkbnufft-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8eb48813e2fc2726451e8dc0bfb40e96", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 20896, "upload_time": "2019-11-11T20:59:47", "upload_time_iso_8601": "2019-11-11T20:59:47.528204Z", "url": "https://files.pythonhosted.org/packages/b0/8f/4481cd0aa7e3b7fd95ccb5f15a85e3bd814a441f7e107154e38ff420918d/torchkbnufft-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "01d44ca1ca585d02da93fb41ed4c0140", "sha256": "bdda20b82120a7dbd1c402e3ae93bfe547c0507aa2b3a039d9e1ac5c908a7d37"}, "downloads": -1, "filename": "torchkbnufft-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "01d44ca1ca585d02da93fb41ed4c0140", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 29589, "upload_time": "2019-11-15T16:19:06", "upload_time_iso_8601": "2019-11-15T16:19:06.082040Z", "url": "https://files.pythonhosted.org/packages/9c/47/827a9ae79cf11c053d13d8894cb08b9c28d962e9c8504d78ec4d07444776/torchkbnufft-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "79683b59b242b67ccc5fa7603d7ac34e", "sha256": "eb12dd0102e4204219fc8e1224c1ce49839f35c8a962bce480238abb26c00db3"}, "downloads": -1, "filename": "torchkbnufft-0.1.1.tar.gz", "has_sig": false, "md5_digest": "79683b59b242b67ccc5fa7603d7ac34e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 20952, "upload_time": "2019-11-15T16:19:07", "upload_time_iso_8601": "2019-11-15T16:19:07.417171Z", "url": "https://files.pythonhosted.org/packages/04/13/011777f21256c76c0b3194a632f328da54ce52bf0072d1bf14a6fc1d7a47/torchkbnufft-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "6bfbb89ccb09ff406863ac81a891e020", "sha256": "f376608c79817fd0c37a2d36fff8b00e176c9ce38837b30022fdd70304025784"}, "downloads": -1, "filename": "torchkbnufft-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6bfbb89ccb09ff406863ac81a891e020", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 29168, "upload_time": "2019-11-21T20:36:21", "upload_time_iso_8601": "2019-11-21T20:36:21.109452Z", "url": "https://files.pythonhosted.org/packages/13/64/213b4d69aa2e1abe15d7b847b22a0a7abda1f931185bd672f03a5d3aee1d/torchkbnufft-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e2c9920b92012b9f86bdc2e4e47555d6", "sha256": "34408ae5fe284fe129f6010a1adffe26082d9e41c215c32b8634f19a90b34fb2"}, "downloads": -1, "filename": "torchkbnufft-0.2.0.tar.gz", "has_sig": false, "md5_digest": "e2c9920b92012b9f86bdc2e4e47555d6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 21167, "upload_time": "2019-11-21T20:36:22", "upload_time_iso_8601": "2019-11-21T20:36:22.699047Z", "url": "https://files.pythonhosted.org/packages/8f/6a/0c0d1c35a2cfbb2cab5d1595657c71db92fe3500cbea6b5d2cb5d011e6e1/torchkbnufft-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "a35656f5d0a03794482fceb9fd3da597", "sha256": "65b5174d26ee5bbcbb4402a4fe9c42129c34f4fe33c00b06dfe507183945f693"}, "downloads": -1, "filename": "torchkbnufft-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a35656f5d0a03794482fceb9fd3da597", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 31504, "upload_time": "2019-11-22T19:43:19", "upload_time_iso_8601": "2019-11-22T19:43:19.772350Z", "url": "https://files.pythonhosted.org/packages/8d/9b/81f6158b31c4038ff27935b40312e1f7294b7a33a66bbcbd4584f92c1a53/torchkbnufft-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3fa3335618be26fe72d13f3f39e69e6c", "sha256": "e964379f2eebae2a436529019ba39d40bbe9596573faf45bf501f7f01249eec4"}, "downloads": -1, "filename": "torchkbnufft-0.2.1.tar.gz", "has_sig": false, "md5_digest": "3fa3335618be26fe72d13f3f39e69e6c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 21225, "upload_time": "2019-11-22T19:43:22", "upload_time_iso_8601": "2019-11-22T19:43:22.230488Z", "url": "https://files.pythonhosted.org/packages/4e/de/4f696b52c825858d1f73cbc1371fcb3ff385900abef20dd806d9f5023703/torchkbnufft-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "cf0531258da2fdfab69d6dfbd158ef92", "sha256": "ebd16d2f271faa067877c5e08cdbed435af10a5cb5013a5f7752974eb0bfd073"}, "downloads": -1, "filename": "torchkbnufft-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "cf0531258da2fdfab69d6dfbd158ef92", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 37401, "upload_time": "2020-01-08T14:45:12", "upload_time_iso_8601": "2020-01-08T14:45:12.446499Z", "url": "https://files.pythonhosted.org/packages/ad/01/0f6c05668487a73fc14f365a7370366a5c75810932bec12d8dfa09c823f2/torchkbnufft-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e46d63a57673d2d44ede5b66bf3b95af", "sha256": "9cd110ffd04cb60c5eebfb8eed736266ec1732889f6c133d52209d44ddf9de8c"}, "downloads": -1, "filename": "torchkbnufft-0.3.0.tar.gz", "has_sig": false, "md5_digest": "e46d63a57673d2d44ede5b66bf3b95af", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 29038, "upload_time": "2020-01-08T14:45:13", "upload_time_iso_8601": "2020-01-08T14:45:13.861435Z", "url": "https://files.pythonhosted.org/packages/93/d6/695c79d4ea0594d60200ca98e8bc34a626170546414aa44529c238100703/torchkbnufft-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "d7c0a5f73373fb3796403e5e120eb53c", "sha256": "2e1582f9da0831b43a011a05f144c39331d7c8cc24a3a9e4ed4b3105fc98afd0"}, "downloads": -1, "filename": "torchkbnufft-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d7c0a5f73373fb3796403e5e120eb53c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 34385, "upload_time": "2020-01-08T15:02:17", "upload_time_iso_8601": "2020-01-08T15:02:17.849499Z", "url": "https://files.pythonhosted.org/packages/19/1d/79928f1c87686ef8a0be806b63b45b8576c9dfa84355ac933bc3b69f3039/torchkbnufft-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ecbb39c54921039cc381044126364c08", "sha256": "554062d5fc1773b988008d4b741abd895eb68ec0515391e40baa3aa5d64ab855"}, "downloads": -1, "filename": "torchkbnufft-0.3.1.tar.gz", "has_sig": false, "md5_digest": "ecbb39c54921039cc381044126364c08", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 29031, "upload_time": "2020-01-08T15:02:19", "upload_time_iso_8601": "2020-01-08T15:02:19.486104Z", "url": "https://files.pythonhosted.org/packages/29/8b/7aeea9f2c4895445c99f83e013b46f70936763504f6e7ec4b5e85931509e/torchkbnufft-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "0d1bcd59ee4d02df3bc75d3343f5bf15", "sha256": "2fadbec0ede804c6b976d754643a28720f7abd325fe3f67b9748bb73d2e0fb0a"}, "downloads": -1, "filename": "torchkbnufft-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0d1bcd59ee4d02df3bc75d3343f5bf15", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 34495, "upload_time": "2020-03-02T17:56:38", "upload_time_iso_8601": "2020-03-02T17:56:38.692408Z", "url": "https://files.pythonhosted.org/packages/2b/fe/18f74515f5dcd87ae0d6ac68eaf28454cc1200cb341063aceb1007e7d03d/torchkbnufft-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f2a52775e1f91ef8288fa754bafca9ec", "sha256": "6af87c33e5ed03ac2dc180d5c9f38873a589fd2fee4ba2555cf67ee6b7be865e"}, "downloads": -1, "filename": "torchkbnufft-0.3.2.tar.gz", "has_sig": false, "md5_digest": "f2a52775e1f91ef8288fa754bafca9ec", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 29072, "upload_time": "2020-03-02T17:56:40", "upload_time_iso_8601": "2020-03-02T17:56:40.412704Z", "url": "https://files.pythonhosted.org/packages/61/a7/a80e1dcaae6d6a84196fc2580a0e5e483142637677fd8452929e56ce3fa9/torchkbnufft-0.3.2.tar.gz", "yanked": false}], "0.3.2.post1": [{"comment_text": "", "digests": {"md5": "553f8274316fa7d7ea86d74ce8e506fc", "sha256": "1e004d5706b214eebb10dcb8c567fe6b624655821f0ffcc77c80f449d6bf4880"}, "downloads": -1, "filename": "torchkbnufft-0.3.2.post1-py3-none-any.whl", "has_sig": false, "md5_digest": "553f8274316fa7d7ea86d74ce8e506fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 34670, "upload_time": "2020-03-03T19:40:18", "upload_time_iso_8601": "2020-03-03T19:40:18.845726Z", "url": "https://files.pythonhosted.org/packages/1a/4f/8d6a611cbde0c3ac42e9322c1eebfb415ce37be49d1e0ef4ac474309f4d0/torchkbnufft-0.3.2.post1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0be680e3edcc97113a26698b3ca6fb92", "sha256": "9676298180aa924e49c815b99097c575919590d3668eda60c6f54879e339b7c2"}, "downloads": -1, "filename": "torchkbnufft-0.3.2.post1.tar.gz", "has_sig": false, "md5_digest": "0be680e3edcc97113a26698b3ca6fb92", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 29301, "upload_time": "2020-03-03T19:40:20", "upload_time_iso_8601": "2020-03-03T19:40:20.466821Z", "url": "https://files.pythonhosted.org/packages/e6/e3/74ad582f176e20af0042c3bc5e42fae753219b530d5cc010b30244b2cefb/torchkbnufft-0.3.2.post1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "553f8274316fa7d7ea86d74ce8e506fc", "sha256": "1e004d5706b214eebb10dcb8c567fe6b624655821f0ffcc77c80f449d6bf4880"}, "downloads": -1, "filename": "torchkbnufft-0.3.2.post1-py3-none-any.whl", "has_sig": false, "md5_digest": "553f8274316fa7d7ea86d74ce8e506fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 34670, "upload_time": "2020-03-03T19:40:18", "upload_time_iso_8601": "2020-03-03T19:40:18.845726Z", "url": "https://files.pythonhosted.org/packages/1a/4f/8d6a611cbde0c3ac42e9322c1eebfb415ce37be49d1e0ef4ac474309f4d0/torchkbnufft-0.3.2.post1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0be680e3edcc97113a26698b3ca6fb92", "sha256": "9676298180aa924e49c815b99097c575919590d3668eda60c6f54879e339b7c2"}, "downloads": -1, "filename": "torchkbnufft-0.3.2.post1.tar.gz", "has_sig": false, "md5_digest": "0be680e3edcc97113a26698b3ca6fb92", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 29301, "upload_time": "2020-03-03T19:40:20", "upload_time_iso_8601": "2020-03-03T19:40:20.466821Z", "url": "https://files.pythonhosted.org/packages/e6/e3/74ad582f176e20af0042c3bc5e42fae753219b530d5cc010b30244b2cefb/torchkbnufft-0.3.2.post1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:21 2020"}