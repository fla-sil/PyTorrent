{"info": {"author": "Mircea Ulinic", "author_email": "mircea.ulinic@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Operating System :: MacOS", "Operating System :: POSIX :: Linux", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: System :: Networking", "Topic :: Utilities"], "description": "# napalm-salt\nModules for Salt, to retrieve, control, enforce and update configuration of network devices\n\nSalt Basics\n===========\n\nNew to Salt? Check out [this document](https://docs.saltstack.com/en/latest/topics/tutorials/walkthrough.html) for a brief introduction to get up to speed on the basics.\n\nTest Environment\n================\n\nThroughout the rest of this document, we'll set up a test environment to run some salt commands against routers. This test environment uses a vagrant VM running Ubuntu 16.04, which acts as a salt-master as well as a proxy-master, which establishes and maintains connections to the routers in order to execute commands on them.\n\nInstall Salt\n============\n\nThe simplest way to install Salt is via [salt bootstrap](https://docs.saltstack.com/en/latest/topics/tutorials/salt_bootstrap.html). Here's an example of an installation:\n\n```bash\nwget -O bootstrap-salt.sh https://bootstrap.saltstack.com/develop\nsudo sh bootstrap-salt.sh\n```\n\nThis will install the `salt-minion` and `salt-proxy` only, but we also want this box to be the `salt-master`, so we'll install that:\n\n```bash\nsudo sh bootstrap-salt.sh -M\n```\n\nFor more specific installation instructions, see the [platform-specific instructions](https://docs.saltstack.com/en/latest/topics/installation/#platform-specific-installation-instructions) from the official Saltstack documentation.\nBe aware to install the master distribution **from the PPA repo**, as on the local server will run as Master, controlling the devices as Proxy minions.\n\nCentOS documentation can be found [here](centos_installation.md).\n\nInstall NAPALM\n==============\n\nIf NAPALM has never been installed on your system it will need to be before napalm-salt can work:\n```\nsudo apt-get install libffi-dev libssl-dev python-dev python-cffi libxslt1-dev python-pip\nsudo pip install --upgrade cffi\nsudo pip install napalm-junos napalm-iosxr napalm-ios\n```\n\nThe easy way: Salt users can install NAPALM through a single command, using the [napalm-install Saltstack formula](https://github.com/saltstack-formulas/napalm-install-formula). A more detailed usage example can be found at: https://mirceaulinic.net/2017-07-06-napalm-install-formula/.\n\nConfigure Salt Proxy (and Minion)\n=================================\n\nThe main configuration file needed to make Salt run as proxy-master is located at `/etc/salt/proxy`. This file should already exist, though you may need to create it. \n\nWe need to tell the proxy process that the local machine is the `salt-master`, and to turn off multiprocessing. You can add the following to the top of your `/etc/salt/proxy` file: \n\n```\nmaster: localhost\nmultiprocessing: false\nmine_enabled: true # not required, but nice to have\npki_dir: /etc/salt/pki/proxy # not required - this separates the proxy keys into a different directory\n```\n\nAdditionally, you may want to edit the `/etc/salt/minion` file to point the master location to itself. This is not necessary, but it allows you to target the VM as a minion, in addition to the routers. Add this to the top of `/etc/salt/minion`:\n\n```\nmaster: localhost\n```\n\nConfigure the connection with a device\n======================================\n\nThe `master` config file is expecting pillar to be in `/srv/pillar`, but this directory probably doesn't exist, so create it:\n```\nmkdir -p /srv/pillar\n```\n\nTo configure store the pillars in a different directory, see the [`pillar_roots`](https://docs.saltstack.com/en/latest/ref/configuration/master.html#pillar-roots) (and [`file_roots`](https://docs.saltstack.com/en/latest/ref/configuration/master.html#file-roots)) configuration options in the master configuration file (typically `/etc/salt/master` or `/srv/master` - depending on the operating system).\n\nNext, we need to create a `top.sls` file in that directory, which tells the salt-master which minions receive which pillar. Create and edit the `/srv/pillar/top.sls` file and make it look like this:\n\n```yaml\nbase:\n  [DEVICE_ID]:\n    - [DEVICE_SLS_FILENAME]\n```\n\nwhere:\n\n  - DEVICE_ID will be the name used to interact with the device, from the CLI of the server\n  - DEVICE_SLS_FILENAME is the name of the file containing the specifications of the device\n\nExample:\n\n```yaml\nbase:\n  router1:\n    - router1_pillar\n```\n\nwhere:\n\n  - router1 is the name used to interact with the device: `salt 'router1' test.ping`\n  - `/srv/pillar/router1_pillar.sls` is the file containing the specifications of this device\n\n**Pay attention to this structure**: Notice that the `- router1_pillar` portion of the `top.sls` file is missing the `.sls` extension, even though this line is expecting to see a file in the same directory called `router1_pillar.sls`. In addtion, note that there should not be dots used when referencing the `.sls` file, as this will be interpreted as a directory structure. For example, if you had the line configured as `- router1.pillar`, salt would look in the `/srv/pillar` directory for a folder called `router1`, and then for a file in that directory called `pillar.sls`. One last thing - I'm referring to the pillar file as `router1_pillar` in this example to make it explicitly clear that the last line is referencing a pillar file, but it is more common to call the pillar file the name of the device itself, so:\n\n```yaml\nbase:\n  router1:\n    - router1\n```    \nNow that we've referenced this `router1_pillar` file, we need to create it and add the pillar. Create and edit the `/srv/pillar/router1_pillar.sls` file and add the following:\n\n```yaml\nproxy:\n  proxytype: napalm\n  driver: [DRIVER]\n  host: [HOSTNAME]\n  username: [USERNAME]\n  passwd: [PASSWORD]\n```\n\nwhere:\n\n  - DRIVER is the driver to be used when connecting to the device. For the complete list of supported operating systems, please check the [NAPALM readthedocs page](https://napalm.readthedocs.io/en/latest/#supported-network-operating-systems)\n  - HOSTNAME, USERNAME, PASSWORD are the connection details\n\nExample ```router1_pillar.sls```:\n\n```yaml\nproxy:\n  proxytype: napalm\n  driver: iosxr\n  host: 192.168.128.128\n  username: my_username\n  passwd: my_password\n```\n\n*** NOTE: *** make sure the pillar is a valid YAML file!\n\nAlso, double check if you can connect to the device from the server, using the credentials provided in the pillar.\n\nIf the errors persist, run the following lines in a Python console and ask in the Slack channel [#saltstack](https://networktocode.slack.com/messages/saltstack/) in [network.toCode()](https://networktocode.herokuapp.com/):\n\n```python\n>>> from napalm_base import get_network_driver\n>>> d = get_network_driver('DRIVER')\n>>> e = d('HOSTNAME', 'USERNAME', 'PASSWORD', optional_args={'config_lock': False})\n>>> e.open()\n>>> e.get_facts()\n>>> e.close()\n```\n\nFor additional parameters, one can add them inside the `optional_args` field, e.g.:\n\n\n```yaml\nproxy:\n  proxytype: napalm\n  driver: ios\n  host: 192.168.128.128\n  username: my_username\n  passwd: ''\n  optional_args:\n    secret: sup3rsek3t\n    ssh_config_file: ~/custom_ssh_config_file\n```\n\nSee [the list of optional arguments per driver](http://napalm.readthedocs.io/en/develop/support/index.html#list-of-supported-optional-arguments).\n\nWhen authenticating using SSH key, the field `passwd` (or `password`, `pass`) can be blank, or can be removed from the pillar. However, note that not all drivers use SSH-based authentication. For example, Arista EOS and Cisco Nexus use HTTP-based APIs so the password is mandatory!\n\nFor more details regarding the pillar configuration see [the official documentation](https://docs.saltstack.com/en/develop/ref/proxy/all/salt.proxy.napalm.html) and [the network automation reference under Salt docs](https://docs.saltstack.com/en/develop/topics/network_automation/index.html#napalm).\n\n\nStart the Salt Services\n=======================\n\n```bash\nsystemctl start salt-master\nsystemctl restart salt-minion\n```\n\n\n\nRunning the proxy minion as a service\n=====================================\n\nTo configure the minion to run as a service create the file ```/etc/systemd/system/salt-proxy@.service``` with the following:\n\n```\n[Unit]\nDescription=Salt proxy minion\nAfter=network.target\n\n[Service]\nType=simple\nExecStart=/usr/bin/salt-proxy -l debug --proxyid=%i\nUser=root\nGroup=root\nRestart=always\nRestartPreventExitStatus=SIGHUP\nRestartSec=5\n\n[Install]\nWantedBy=default.target\n```\n\nDepending on how your salt master is installed the location of the ```salt-proxy``` binary may need to be changed. You can look up the location of the binary with the ```which salt-proxy``` command. Also the logging level is set to debug with the ```-l debug``` switch. This is useful for troubleshooting however you may want to remove this.\n\nOnce the file is created and populated ```systemd``` will need to be reloaded with a ```systemctl daemon-reload``` to pick up the new unit. Do note that there may be an impact to reloading ```systemd``` so be careful.\n\n\nStart the proxy minion for your device\n======================================\n\nStart with testing proxy minion:\n```bash\nsudo salt-proxy --proxyid=[DEVICE_ID] -l debug\n```\n\nOn the first connection attempt you will find the that minion cannot talk and is stuck with the following error message:\n```\n[ERROR   ] The Salt Master has cached the public key for this node, this salt minion will wait for 10 seconds before attempting to re-authenticate\n[INFO    ] Waiting 10 seconds before retry.\n```\nThis is normal and is due to the salt key from the minion not being accepted by the master. Quit the minion with <kbd>CTRL</kbd>+<kbd>C</kbd> and run ```sudo salt-key```. Under ```Unaccepted Keys:``` you should see your ```[DEVICE_ID]```. Accept the key with ```sudo salt-key -a [DEVICE_ID]```. Now rerun the minion debug and you should see the minion connecting to your device.\n\n\nTest your configuration\n=======================\n\nOnce the key has been accepted, restart the proxy in debug mode and start a separate terminal session.  In your new terminal, issue the following command:\n```\nsudo salt 'core01.nrt01' test.ping\n```\nSubstitute your DEVICE_ID for 'core01.nrt01'.  Output:\n```\ncore01.nrt01:\n    True\n```\nIt should return `True` if there are no problems.  If everything checks out, hit <kbd>CTRL</kbd>+<kbd>C</kbd> and restart salt-proxy as a daemon.\n```\nsudo salt-proxy --proxyid=[DEVICE_ID] -d\n```\nFinally, sync your packages:\n```\nsudo salt core01.nrt01 saltutil.sync_all\n```\nAs before, where 'core01.nrt01' is your DEVICE_ID.\n\n\nStart using Salt\n================\n\nEverything is setup now, you need just to start issuing commands to retieve/set properties.\n\nSyntax:\n\n```bash\nsalt [DEVICE_ID] [FUNCTION]\n```\n\nFor the updated list of functions, check the following resources:\n  - [net](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_network.html#module-salt.modules.napalm_network) module\n  - [ntp](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_ntp.html#module-salt.modules.napalm_ntp) module\n  - [bgp](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_bgp.html#module-salt.modules.napalm_bgp) module\n  - [snmp](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_snmp.html#module-salt.modules.napalm_snmp) module\n  - [route](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_route.html#module-salt.modules.napalm_route) module\n  - [users](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_users.html#module-salt.modules.napalm_users) module\n  - [probes](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_probes.html#module-salt.modules.napalm_probes) module\n\nFew examples:\n\n```bash\nsalt core01.nrt01 net.arp\nsalt core01.nrt01 net.mac\nsalt core01.nrt01 net.lldp\nsalt core01.nrt01 net.ipaddrs\nsalt core01.nrt01 net.interfaces\nsalt core01.nrt01 ntp.peers\nsalt core01.nrt01 ntp.set_peers 192.168.0.1 172.17.17.1 172.17.17.2\nsalt core01.nrt01 bgp.config  # returns the BGP configuration\nsalt core01.nrt01 bgp.neighbors  # provides statistics regarding the BGP sessions\nsalt core01.nrt01 snmp.config\nsalt core01.nrt01 route.show 1.2.3.4/24 bgp\nsalt core01.nrt01 probes.config\nsalt core01.nrt01 probes.results\nsalt core01.nrt01 net.commit\nsalt core01.nrt01 net.rollback\n```\n\nConfiguration enforcement\n=========================\n\nTo assure consistency across your network, [states](https://docs.saltstack.com/en/latest/topics/tutorials/starting_states.html) are your friend. To use a state is quite straight forwards when the module is already provided (examples in the next sections, for example [NTP](https://github.com/napalm-automation/napalm-salt#configuration-enforcement-for-ntp-peers-example)).\nThere are a couple of states already available, for:\n\n  - [NTP](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netntp.html)\n  - [SNMP](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netsnmp.html)\n  - [Users](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netusers.html)\n  - [Probes](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netntp.html)\n\n\nConfiguration enforcement for NTP peers (Example)\n=================================================\n\nIn the Pillar file of the device append the following lines:\n\n```yaml\nntp.peers:\n  - [PEER1]\n  - [PEER2]\n  - ...\n```\n\nExample:\n\n```yaml\nntp.peers:\n  - 192.168.0.1\n  - 172.17.17.1\n```\n\nNow, when running the command below, Salt will check if on your device the NTP peers are setup as specified in the Pillar file. If not, will add the missing NTP peers and will remove the excess. Thus, at the end of the operation, the list of NTP peers configured on the device will match NTP peers listed in the Pillar.\n\n```bash\nsalt core01.nrt01 state.sls router.ntp\n```\n\nConfiguration enforcement for SNMP (Example)\n============================================\n\nIn the pillar file of the device append the following lines:\n\n```yaml\nsnmp.config:\n  contact: <email addr>\n  location: <location>\n  community: <community name>\n```\n\nExample:\n\n```yaml\nsnmp.config:\n  contact: noc@yourcompany.com\n  location: San Jose, CA, US\n  community: super-safe\n```\n\nExecuting the state as following, will update the SNMP configuration on your device:\n\n```bash\nsalt core01.nrt01 state.sls router.snmp\n```\n\nScheduled states: maintaining configuration updated\n===================================================\n\nUsing the capabilities of the states and [the schedulers](https://docs.saltstack.com/en/latest/ref/states/all/salt.states.schedule.html#management-of-the-salt-scheduler) you can ensure the configuration on the device is consistent and up-to-date.\n\nYes, you don't need to jump in a box and manualluy execute a command or add aliases etc. 5 lines of config is all you need to write:\n\nExample:\n\nIn the master config file:\n\n```yaml\nschedule:\n  ntp_config:\n    function: state.sls\n    args: router.ntp\n    returner: smtp\n    days: 1\n```\n\nWhere:\n\n- ```ntp_config``` is just the name of the scheduled job - can be anything\n- ```function``` - this is how tell Salt that a state will be executed\n- ```args``` - specify the name of the state\n- ```returner``` (optional) - you can forward the output of the state to a different service. In this case SNMP - will send an email to a specific address with the summary of the state. There are [many other returners available](https://docs.saltstack.com/en/latest/ref/returners/#full-list-of-returners)\n- ```days``` - how often to check & update the config. Other options are: ```seconds```, ```minutes```, ```hours``` etc...\n\n\nOther modules:\n==============\n\nSalt comes with many flavours of modules - complete reference at [https://docs.saltstack.com/en/latest/ref/index.html](https://docs.saltstack.com/en/latest/ref/index.html).\n\nThere are few other features, such [reactor](https://docs.saltstack.com/en/latest/topics/reactor/). The reactor system allows you to execute commands after an event happened, based on its output.\n\nVagrant:\n========\nOne can use the included Vagrantfile and saltstack directory to automatically provision a development/testing environment containing a salt\nmaster/minion/proxy host and a vEOS switch.  To utilize, download the vEOS-lab-4.16.9M.box image from [www.arista.com](www.arista.com), import it, and start up:\n\n```bash\nvagrant box add --name vEOS-lab.4.16.9M vEOS-lab-4.16.9M.box\nvagrant up\n```\nThis will build an Ubuntu trusty image with salt-minion and salt-master built from latest git sources, install napalm and capirca, and configure the\nproxy correctly. From there, use `vagrant ssh master` to log into the master and run salt commands.  If desired, the Vagrantfile can be edited prior\nto running `vagrant up` to change the number of hosts created, or use a custom saltstack git repository to test new salt modules.\n\n\nLegacy NAPALM Salt Installation\n===============================\n\n*** NOTE: ***\nThis is for versions of salt older than `2016.11.0`. For more details, see: [https://mirceaulinic.net/2016-11-30-salt-carbon-released/](https://mirceaulinic.net/2016-11-30-salt-carbon-released/). If not sure, you can check the Salt version using: ```salt --versions-report```.\n\nStart by git cloning this repository and changing into the directory: ```git clone https://github.com/napalm-automation/napalm-salt.git && cd napalm-salt```.\n\nExtract the SPM archive using the command: ```tar xf napalm-2016.11.spm``` for Salt ```>=2016.3``` or ```tar xf napalm.spm``` for older releases. When unpacking, a directory called ```napalm``` will be created.\n\nCopy all its files and directories to the path specified as ```file_roots``` in the master config file (default is ```/etc/salt/states```), e.g. ```cp -r napalm/* /etc/salt/states```.\n\nAt the end, you should have a directory structure similar to the following under the ```file_roots``` directory (e.g.: ```/etc/salt/states```):\n\n```\n/etc/salt/states\n\u251c\u2500\u2500 top.sls\n\u251c\u2500\u2500 _proxy\n|   \u2514\u2500\u2500 napalm.py\n\u251c\u2500\u2500 _modules\n|   \u251c\u2500\u2500 napalm_network.py\n|   \u251c\u2500\u2500 napalm_ntp.py\n|   \u251c\u2500\u2500 napalm_users.py\n|   \u251c\u2500\u2500 napalm_bgp.py\n|   \u251c\u2500\u2500 napalm_route.py\n|   \u251c\u2500\u2500 napalm_snmp.py\n|   \u2514\u2500\u2500 napalm_probes.py\n\u251c\u2500\u2500 _grains\n|   \u2514\u2500\u2500 napalm.py\n\u251c\u2500\u2500 _states\n|   \u251c\u2500\u2500 netntp.py\n|   \u251c\u2500\u2500 netusers.py\n|   \u251c\u2500\u2500 netsnmp.py\n|   \u2514\u2500\u2500 probes.py\n\u251c\u2500\u2500 _runners\n|   \u2514\u2500\u2500 ntp.py\n\u251c\u2500\u2500 router\n    \u251c\u2500\u2500 init.sls\n    \u251c\u2500\u2500 ntp.sls\n    \u251c\u2500\u2500 users.sls\n    \u251c\u2500\u2500 snmp.sls\n    \u2514\u2500\u2500 probes.sls\n```\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/napalm-automation/napalm-salt", "keywords": "napalm,salt,network,automation,cli", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "salt-napalm", "package_url": "https://pypi.org/project/salt-napalm/", "platform": "", "project_url": "https://pypi.org/project/salt-napalm/", "project_urls": {"Homepage": "https://github.com/napalm-automation/napalm-salt"}, "release_url": "https://pypi.org/project/salt-napalm/2019.1.0a2/", "requires_dist": ["salt", "napalm"], "requires_python": "", "summary": "Salt plugin for interacting with network devices through NAPALM, without running Minions", "version": "2019.1.0a2", "yanked": false, "html_description": "<div class=\"project-description\">\n            # napalm-salt<br>Modules for Salt, to retrieve, control, enforce and update configuration of network devices<br><br>Salt Basics<br>===========<br><br>New to Salt? Check out [this document](https://docs.saltstack.com/en/latest/topics/tutorials/walkthrough.html) for a brief introduction to get up to speed on the basics.<br><br>Test Environment<br>================<br><br>Throughout the rest of this document, we'll set up a test environment to run some salt commands against routers. This test environment uses a vagrant VM running Ubuntu 16.04, which acts as a salt-master as well as a proxy-master, which establishes and maintains connections to the routers in order to execute commands on them.<br><br>Install Salt<br>============<br><br>The simplest way to install Salt is via [salt bootstrap](https://docs.saltstack.com/en/latest/topics/tutorials/salt_bootstrap.html). Here's an example of an installation:<br><br>```bash<br>wget -O bootstrap-salt.sh https://bootstrap.saltstack.com/develop<br>sudo sh bootstrap-salt.sh<br>```<br><br>This will install the `salt-minion` and `salt-proxy` only, but we also want this box to be the `salt-master`, so we'll install that:<br><br>```bash<br>sudo sh bootstrap-salt.sh -M<br>```<br><br>For more specific installation instructions, see the [platform-specific instructions](https://docs.saltstack.com/en/latest/topics/installation/#platform-specific-installation-instructions) from the official Saltstack documentation.<br>Be aware to install the master distribution **from the PPA repo**, as on the local server will run as Master, controlling the devices as Proxy minions.<br><br>CentOS documentation can be found [here](centos_installation.md).<br><br>Install NAPALM<br>==============<br><br>If NAPALM has never been installed on your system it will need to be before napalm-salt can work:<br>```<br>sudo apt-get install libffi-dev libssl-dev python-dev python-cffi libxslt1-dev python-pip<br>sudo pip install --upgrade cffi<br>sudo pip install napalm-junos napalm-iosxr napalm-ios<br>```<br><br>The easy way: Salt users can install NAPALM through a single command, using the [napalm-install Saltstack formula](https://github.com/saltstack-formulas/napalm-install-formula). A more detailed usage example can be found at: https://mirceaulinic.net/2017-07-06-napalm-install-formula/.<br><br>Configure Salt Proxy (and Minion)<br>=================================<br><br>The main configuration file needed to make Salt run as proxy-master is located at `/etc/salt/proxy`. This file should already exist, though you may need to create it. <br><br>We need to tell the proxy process that the local machine is the `salt-master`, and to turn off multiprocessing. You can add the following to the top of your `/etc/salt/proxy` file: <br><br>```<br>master: localhost<br>multiprocessing: false<br>mine_enabled: true # not required, but nice to have<br>pki_dir: /etc/salt/pki/proxy # not required - this separates the proxy keys into a different directory<br>```<br><br>Additionally, you may want to edit the `/etc/salt/minion` file to point the master location to itself. This is not necessary, but it allows you to target the VM as a minion, in addition to the routers. Add this to the top of `/etc/salt/minion`:<br><br>```<br>master: localhost<br>```<br><br>Configure the connection with a device<br>======================================<br><br>The `master` config file is expecting pillar to be in `/srv/pillar`, but this directory probably doesn't exist, so create it:<br>```<br>mkdir -p /srv/pillar<br>```<br><br>To configure store the pillars in a different directory, see the [`pillar_roots`](https://docs.saltstack.com/en/latest/ref/configuration/master.html#pillar-roots) (and [`file_roots`](https://docs.saltstack.com/en/latest/ref/configuration/master.html#file-roots)) configuration options in the master configuration file (typically `/etc/salt/master` or `/srv/master` - depending on the operating system).<br><br>Next, we need to create a `top.sls` file in that directory, which tells the salt-master which minions receive which pillar. Create and edit the `/srv/pillar/top.sls` file and make it look like this:<br><br>```yaml<br>base:<br>  [DEVICE_ID]:<br>    - [DEVICE_SLS_FILENAME]<br>```<br><br>where:<br><br>  - DEVICE_ID will be the name used to interact with the device, from the CLI of the server<br>  - DEVICE_SLS_FILENAME is the name of the file containing the specifications of the device<br><br>Example:<br><br>```yaml<br>base:<br>  router1:<br>    - router1_pillar<br>```<br><br>where:<br><br>  - router1 is the name used to interact with the device: `salt 'router1' test.ping`<br>  - `/srv/pillar/router1_pillar.sls` is the file containing the specifications of this device<br><br>**Pay attention to this structure**: Notice that the `- router1_pillar` portion of the `top.sls` file is missing the `.sls` extension, even though this line is expecting to see a file in the same directory called `router1_pillar.sls`. In addtion, note that there should not be dots used when referencing the `.sls` file, as this will be interpreted as a directory structure. For example, if you had the line configured as `- router1.pillar`, salt would look in the `/srv/pillar` directory for a folder called `router1`, and then for a file in that directory called `pillar.sls`. One last thing - I'm referring to the pillar file as `router1_pillar` in this example to make it explicitly clear that the last line is referencing a pillar file, but it is more common to call the pillar file the name of the device itself, so:<br><br>```yaml<br>base:<br>  router1:<br>    - router1<br>```    <br>Now that we've referenced this `router1_pillar` file, we need to create it and add the pillar. Create and edit the `/srv/pillar/router1_pillar.sls` file and add the following:<br><br>```yaml<br>proxy:<br>  proxytype: napalm<br>  driver: [DRIVER]<br>  host: [HOSTNAME]<br>  username: [USERNAME]<br>  passwd: [PASSWORD]<br>```<br><br>where:<br><br>  - DRIVER is the driver to be used when connecting to the device. For the complete list of supported operating systems, please check the [NAPALM readthedocs page](https://napalm.readthedocs.io/en/latest/#supported-network-operating-systems)<br>  - HOSTNAME, USERNAME, PASSWORD are the connection details<br><br>Example ```router1_pillar.sls```:<br><br>```yaml<br>proxy:<br>  proxytype: napalm<br>  driver: iosxr<br>  host: 192.168.128.128<br>  username: my_username<br>  passwd: my_password<br>```<br><br>*** NOTE: *** make sure the pillar is a valid YAML file!<br><br>Also, double check if you can connect to the device from the server, using the credentials provided in the pillar.<br><br>If the errors persist, run the following lines in a Python console and ask in the Slack channel [#saltstack](https://networktocode.slack.com/messages/saltstack/) in [network.toCode()](https://networktocode.herokuapp.com/):<br><br>```python<br>&gt;&gt;&gt; from napalm_base import get_network_driver<br>&gt;&gt;&gt; d = get_network_driver('DRIVER')<br>&gt;&gt;&gt; e = d('HOSTNAME', 'USERNAME', 'PASSWORD', optional_args={'config_lock': False})<br>&gt;&gt;&gt; e.open()<br>&gt;&gt;&gt; e.get_facts()<br>&gt;&gt;&gt; e.close()<br>```<br><br>For additional parameters, one can add them inside the `optional_args` field, e.g.:<br><br><br>```yaml<br>proxy:<br>  proxytype: napalm<br>  driver: ios<br>  host: 192.168.128.128<br>  username: my_username<br>  passwd: ''<br>  optional_args:<br>    secret: sup3rsek3t<br>    ssh_config_file: ~/custom_ssh_config_file<br>```<br><br>See [the list of optional arguments per driver](http://napalm.readthedocs.io/en/develop/support/index.html#list-of-supported-optional-arguments).<br><br>When authenticating using SSH key, the field `passwd` (or `password`, `pass`) can be blank, or can be removed from the pillar. However, note that not all drivers use SSH-based authentication. For example, Arista EOS and Cisco Nexus use HTTP-based APIs so the password is mandatory!<br><br>For more details regarding the pillar configuration see [the official documentation](https://docs.saltstack.com/en/develop/ref/proxy/all/salt.proxy.napalm.html) and [the network automation reference under Salt docs](https://docs.saltstack.com/en/develop/topics/network_automation/index.html#napalm).<br><br><br>Start the Salt Services<br>=======================<br><br>```bash<br>systemctl start salt-master<br>systemctl restart salt-minion<br>```<br><br><br><br>Running the proxy minion as a service<br>=====================================<br><br>To configure the minion to run as a service create the file ```/etc/systemd/system/salt-proxy@.service``` with the following:<br><br>```<br>[Unit]<br>Description=Salt proxy minion<br>After=network.target<br><br>[Service]<br>Type=simple<br>ExecStart=/usr/bin/salt-proxy -l debug --proxyid=%i<br>User=root<br>Group=root<br>Restart=always<br>RestartPreventExitStatus=SIGHUP<br>RestartSec=5<br><br>[Install]<br>WantedBy=default.target<br>```<br><br>Depending on how your salt master is installed the location of the ```salt-proxy``` binary may need to be changed. You can look up the location of the binary with the ```which salt-proxy``` command. Also the logging level is set to debug with the ```-l debug``` switch. This is useful for troubleshooting however you may want to remove this.<br><br>Once the file is created and populated ```systemd``` will need to be reloaded with a ```systemctl daemon-reload``` to pick up the new unit. Do note that there may be an impact to reloading ```systemd``` so be careful.<br><br><br>Start the proxy minion for your device<br>======================================<br><br>Start with testing proxy minion:<br>```bash<br>sudo salt-proxy --proxyid=[DEVICE_ID] -l debug<br>```<br><br>On the first connection attempt you will find the that minion cannot talk and is stuck with the following error message:<br>```<br>[ERROR   ] The Salt Master has cached the public key for this node, this salt minion will wait for 10 seconds before attempting to re-authenticate<br>[INFO    ] Waiting 10 seconds before retry.<br>```<br>This is normal and is due to the salt key from the minion not being accepted by the master. Quit the minion with &lt;kbd&gt;CTRL&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt; and run ```sudo salt-key```. Under ```Unaccepted Keys:``` you should see your ```[DEVICE_ID]```. Accept the key with ```sudo salt-key -a [DEVICE_ID]```. Now rerun the minion debug and you should see the minion connecting to your device.<br><br><br>Test your configuration<br>=======================<br><br>Once the key has been accepted, restart the proxy in debug mode and start a separate terminal session.  In your new terminal, issue the following command:<br>```<br>sudo salt 'core01.nrt01' test.ping<br>```<br>Substitute your DEVICE_ID for 'core01.nrt01'.  Output:<br>```<br>core01.nrt01:<br>    True<br>```<br>It should return `True` if there are no problems.  If everything checks out, hit &lt;kbd&gt;CTRL&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt; and restart salt-proxy as a daemon.<br>```<br>sudo salt-proxy --proxyid=[DEVICE_ID] -d<br>```<br>Finally, sync your packages:<br>```<br>sudo salt core01.nrt01 saltutil.sync_all<br>```<br>As before, where 'core01.nrt01' is your DEVICE_ID.<br><br><br>Start using Salt<br>================<br><br>Everything is setup now, you need just to start issuing commands to retieve/set properties.<br><br>Syntax:<br><br>```bash<br>salt [DEVICE_ID] [FUNCTION]<br>```<br><br>For the updated list of functions, check the following resources:<br>  - [net](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_network.html#module-salt.modules.napalm_network) module<br>  - [ntp](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_ntp.html#module-salt.modules.napalm_ntp) module<br>  - [bgp](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_bgp.html#module-salt.modules.napalm_bgp) module<br>  - [snmp](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_snmp.html#module-salt.modules.napalm_snmp) module<br>  - [route](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_route.html#module-salt.modules.napalm_route) module<br>  - [users](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_users.html#module-salt.modules.napalm_users) module<br>  - [probes](https://docs.saltstack.com/en/develop/ref/modules/all/salt.modules.napalm_probes.html#module-salt.modules.napalm_probes) module<br><br>Few examples:<br><br>```bash<br>salt core01.nrt01 net.arp<br>salt core01.nrt01 net.mac<br>salt core01.nrt01 net.lldp<br>salt core01.nrt01 net.ipaddrs<br>salt core01.nrt01 net.interfaces<br>salt core01.nrt01 ntp.peers<br>salt core01.nrt01 ntp.set_peers 192.168.0.1 172.17.17.1 172.17.17.2<br>salt core01.nrt01 bgp.config  # returns the BGP configuration<br>salt core01.nrt01 bgp.neighbors  # provides statistics regarding the BGP sessions<br>salt core01.nrt01 snmp.config<br>salt core01.nrt01 route.show 1.2.3.4/24 bgp<br>salt core01.nrt01 probes.config<br>salt core01.nrt01 probes.results<br>salt core01.nrt01 net.commit<br>salt core01.nrt01 net.rollback<br>```<br><br>Configuration enforcement<br>=========================<br><br>To assure consistency across your network, [states](https://docs.saltstack.com/en/latest/topics/tutorials/starting_states.html) are your friend. To use a state is quite straight forwards when the module is already provided (examples in the next sections, for example [NTP](https://github.com/napalm-automation/napalm-salt#configuration-enforcement-for-ntp-peers-example)).<br>There are a couple of states already available, for:<br><br>  - [NTP](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netntp.html)<br>  - [SNMP](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netsnmp.html)<br>  - [Users](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netusers.html)<br>  - [Probes](https://docs.saltstack.com/en/develop/ref/states/all/salt.states.netntp.html)<br><br><br>Configuration enforcement for NTP peers (Example)<br>=================================================<br><br>In the Pillar file of the device append the following lines:<br><br>```yaml<br>ntp.peers:<br>  - [PEER1]<br>  - [PEER2]<br>  - ...<br>```<br><br>Example:<br><br>```yaml<br>ntp.peers:<br>  - 192.168.0.1<br>  - 172.17.17.1<br>```<br><br>Now, when running the command below, Salt will check if on your device the NTP peers are setup as specified in the Pillar file. If not, will add the missing NTP peers and will remove the excess. Thus, at the end of the operation, the list of NTP peers configured on the device will match NTP peers listed in the Pillar.<br><br>```bash<br>salt core01.nrt01 state.sls router.ntp<br>```<br><br>Configuration enforcement for SNMP (Example)<br>============================================<br><br>In the pillar file of the device append the following lines:<br><br>```yaml<br>snmp.config:<br>  contact: &lt;email addr&gt;<br>  location: &lt;location&gt;<br>  community: &lt;community name&gt;<br>```<br><br>Example:<br><br>```yaml<br>snmp.config:<br>  contact: noc@yourcompany.com<br>  location: San Jose, CA, US<br>  community: super-safe<br>```<br><br>Executing the state as following, will update the SNMP configuration on your device:<br><br>```bash<br>salt core01.nrt01 state.sls router.snmp<br>```<br><br>Scheduled states: maintaining configuration updated<br>===================================================<br><br>Using the capabilities of the states and [the schedulers](https://docs.saltstack.com/en/latest/ref/states/all/salt.states.schedule.html#management-of-the-salt-scheduler) you can ensure the configuration on the device is consistent and up-to-date.<br><br>Yes, you don't need to jump in a box and manualluy execute a command or add aliases etc. 5 lines of config is all you need to write:<br><br>Example:<br><br>In the master config file:<br><br>```yaml<br>schedule:<br>  ntp_config:<br>    function: state.sls<br>    args: router.ntp<br>    returner: smtp<br>    days: 1<br>```<br><br>Where:<br><br>- ```ntp_config``` is just the name of the scheduled job - can be anything<br>- ```function``` - this is how tell Salt that a state will be executed<br>- ```args``` - specify the name of the state<br>- ```returner``` (optional) - you can forward the output of the state to a different service. In this case SNMP - will send an email to a specific address with the summary of the state. There are [many other returners available](https://docs.saltstack.com/en/latest/ref/returners/#full-list-of-returners)<br>- ```days``` - how often to check &amp; update the config. Other options are: ```seconds```, ```minutes```, ```hours``` etc...<br><br><br>Other modules:<br>==============<br><br>Salt comes with many flavours of modules - complete reference at [https://docs.saltstack.com/en/latest/ref/index.html](https://docs.saltstack.com/en/latest/ref/index.html).<br><br>There are few other features, such [reactor](https://docs.saltstack.com/en/latest/topics/reactor/). The reactor system allows you to execute commands after an event happened, based on its output.<br><br>Vagrant:<br>========<br>One can use the included Vagrantfile and saltstack directory to automatically provision a development/testing environment containing a salt<br>master/minion/proxy host and a vEOS switch.  To utilize, download the vEOS-lab-4.16.9M.box image from [www.arista.com](www.arista.com), import it, and start up:<br><br>```bash<br>vagrant box add --name vEOS-lab.4.16.9M vEOS-lab-4.16.9M.box<br>vagrant up<br>```<br>This will build an Ubuntu trusty image with salt-minion and salt-master built from latest git sources, install napalm and capirca, and configure the<br>proxy correctly. From there, use `vagrant ssh master` to log into the master and run salt commands.  If desired, the Vagrantfile can be edited prior<br>to running `vagrant up` to change the number of hosts created, or use a custom saltstack git repository to test new salt modules.<br><br><br>Legacy NAPALM Salt Installation<br>===============================<br><br>*** NOTE: ***<br>This is for versions of salt older than `2016.11.0`. For more details, see: [https://mirceaulinic.net/2016-11-30-salt-carbon-released/](https://mirceaulinic.net/2016-11-30-salt-carbon-released/). If not sure, you can check the Salt version using: ```salt --versions-report```.<br><br>Start by git cloning this repository and changing into the directory: ```git clone https://github.com/napalm-automation/napalm-salt.git &amp;&amp; cd napalm-salt```.<br><br>Extract the SPM archive using the command: ```tar xf napalm-2016.11.spm``` for Salt ```&gt;=2016.3``` or ```tar xf napalm.spm``` for older releases. When unpacking, a directory called ```napalm``` will be created.<br><br>Copy all its files and directories to the path specified as ```file_roots``` in the master config file (default is ```/etc/salt/states```), e.g. ```cp -r napalm/* /etc/salt/states```.<br><br>At the end, you should have a directory structure similar to the following under the ```file_roots``` directory (e.g.: ```/etc/salt/states```):<br><br>```<br>/etc/salt/states<br>\u251c\u2500\u2500 top.sls<br>\u251c\u2500\u2500 _proxy<br>|   \u2514\u2500\u2500 napalm.py<br>\u251c\u2500\u2500 _modules<br>|   \u251c\u2500\u2500 napalm_network.py<br>|   \u251c\u2500\u2500 napalm_ntp.py<br>|   \u251c\u2500\u2500 napalm_users.py<br>|   \u251c\u2500\u2500 napalm_bgp.py<br>|   \u251c\u2500\u2500 napalm_route.py<br>|   \u251c\u2500\u2500 napalm_snmp.py<br>|   \u2514\u2500\u2500 napalm_probes.py<br>\u251c\u2500\u2500 _grains<br>|   \u2514\u2500\u2500 napalm.py<br>\u251c\u2500\u2500 _states<br>|   \u251c\u2500\u2500 netntp.py<br>|   \u251c\u2500\u2500 netusers.py<br>|   \u251c\u2500\u2500 netsnmp.py<br>|   \u2514\u2500\u2500 probes.py<br>\u251c\u2500\u2500 _runners<br>|   \u2514\u2500\u2500 ntp.py<br>\u251c\u2500\u2500 router<br>    \u251c\u2500\u2500 init.sls<br>    \u251c\u2500\u2500 ntp.sls<br>    \u251c\u2500\u2500 users.sls<br>    \u251c\u2500\u2500 snmp.sls<br>    \u2514\u2500\u2500 probes.sls<br>```<br><br><br>\n          </div>"}, "last_serial": 4712319, "releases": {"2019.1.0a1": [{"comment_text": "", "digests": {"md5": "32c8587f03614e5ff95270beccd9d4e0", "sha256": "b45c42bc9c54eed6dc72e171c1ce3fe382de5f36ebdfe4db20e78167c350b368"}, "downloads": -1, "filename": "salt_napalm-2019.1.0a1-py2-none-any.whl", "has_sig": false, "md5_digest": "32c8587f03614e5ff95270beccd9d4e0", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 20203, "upload_time": "2019-01-17T16:04:38", "upload_time_iso_8601": "2019-01-17T16:04:38.801762Z", "url": "https://files.pythonhosted.org/packages/3b/bb/823482810ef22be2d046cccbaa08c3cd838d09d3002789e6770adb84aa29/salt_napalm-2019.1.0a1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ec93ed841858da2f60b47b9273785ad", "sha256": "d768498d1512c58926adc4c4ef87e51eff254defad4a0da5edbf00c836c77c58"}, "downloads": -1, "filename": "salt-napalm-2019.1.0a1.tar.gz", "has_sig": false, "md5_digest": "3ec93ed841858da2f60b47b9273785ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12781, "upload_time": "2019-01-17T16:04:40", "upload_time_iso_8601": "2019-01-17T16:04:40.671562Z", "url": "https://files.pythonhosted.org/packages/77/75/342a4ba4efcf2a20a6e6db3224f5b421c48bccb88eeb3caa8282db7ba576/salt-napalm-2019.1.0a1.tar.gz", "yanked": false}], "2019.1.0a2": [{"comment_text": "", "digests": {"md5": "cfce89aa34639707286170767a0991d6", "sha256": "28b00955ff9773da1e8c30f2c6d37703ca0a3c9bc526962903c9fc98a6b75500"}, "downloads": -1, "filename": "salt_napalm-2019.1.0a2-py2-none-any.whl", "has_sig": false, "md5_digest": "cfce89aa34639707286170767a0991d6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 41286, "upload_time": "2019-01-18T13:50:25", "upload_time_iso_8601": "2019-01-18T13:50:25.558305Z", "url": "https://files.pythonhosted.org/packages/11/85/9973ee4f15d0ea29624d27e7a3584fae19e0fc1834d6c6e09e079291ab52/salt_napalm-2019.1.0a2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e80b4b3f93e632185bb761ae43aa2707", "sha256": "de367733af4f867c7c5fdc7e05c3fb8183a4db9722bc66250bb09021c466f466"}, "downloads": -1, "filename": "salt-napalm-2019.1.0a2.tar.gz", "has_sig": false, "md5_digest": "e80b4b3f93e632185bb761ae43aa2707", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30045, "upload_time": "2019-01-18T13:50:27", "upload_time_iso_8601": "2019-01-18T13:50:27.887090Z", "url": "https://files.pythonhosted.org/packages/58/0c/a26d820503223f1adc46e28137b198d2e52dc2f045aee47678df257a2b36/salt-napalm-2019.1.0a2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cfce89aa34639707286170767a0991d6", "sha256": "28b00955ff9773da1e8c30f2c6d37703ca0a3c9bc526962903c9fc98a6b75500"}, "downloads": -1, "filename": "salt_napalm-2019.1.0a2-py2-none-any.whl", "has_sig": false, "md5_digest": "cfce89aa34639707286170767a0991d6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 41286, "upload_time": "2019-01-18T13:50:25", "upload_time_iso_8601": "2019-01-18T13:50:25.558305Z", "url": "https://files.pythonhosted.org/packages/11/85/9973ee4f15d0ea29624d27e7a3584fae19e0fc1834d6c6e09e079291ab52/salt_napalm-2019.1.0a2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e80b4b3f93e632185bb761ae43aa2707", "sha256": "de367733af4f867c7c5fdc7e05c3fb8183a4db9722bc66250bb09021c466f466"}, "downloads": -1, "filename": "salt-napalm-2019.1.0a2.tar.gz", "has_sig": false, "md5_digest": "e80b4b3f93e632185bb761ae43aa2707", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30045, "upload_time": "2019-01-18T13:50:27", "upload_time_iso_8601": "2019-01-18T13:50:27.887090Z", "url": "https://files.pythonhosted.org/packages/58/0c/a26d820503223f1adc46e28137b198d2e52dc2f045aee47678df257a2b36/salt-napalm-2019.1.0a2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:03 2020"}