{"info": {"author": "Maxim Bonnaerens", "author_email": "maxim@bonnaerens.be", "bugtrack_url": null, "classifiers": [], "description": "# Visual Wake Words Dataset\nPython library to work with the [Visual Wake Words Dataset](https://arxiv.org/abs/1906.05721), \ncomparable to [pycococools](https://github.com/cocodataset/cocoapi) for the COCO dataset.\n\n`pyvww.utils.VisualWakeWords` inherits from `pycocotools.coco.COCO` and can be used in an similar fashion.\n\n`pyvww.pytorch.VisualWakeWordsClassification` is a pytorch `Dataset` which can be used like any \nimage classification dataset.\n\n ---\n ### Installation\n The code is implemented in Python 3.7 and can be installed with pip:\n ```bash\n pip install pyvww\n ```\n\n ### Usage\n The Visual Wake Words Dataset is derived from the publicly available [COCO](cocodataset.org/#/home) dataset.\n To download the COCO dataset use the script `download_coco.sh`\n ```bash\nbash scripts/download_mscoco.sh path-to-COCO-dataset\n```\nThe Visual Wake Words Dataset evaluates the accuracy on the [minival image ids](https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_minival_ids.txt),\nand for training uses the remaining 115k images of the COCO training/validation dataset.\n\nTo create COCO annotation files that convert the 83K/41K split to the 115K/8K split use:\n`scripts/create_coco_train_minival_split.py`\n```bash\nTRAIN_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_train2014.json\"\nVAL_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_val2014.json\"\nDIR=\"path-to-mscoco-dataset/annotations/\"\npython scripts/create_coco_train_minival_split.py \\\n  --train_annotations_file=\"${TRAIN_ANNOTATIONS_FILE}\" \\\n  --val_annotations_file=\"${VAL_ANNOTATIONS_FILE}\" \\\n--output_dir=\"${DIR}\"\n```\n\nThe process of creating the Visual Wake Words dataset from COCO dataset is as follows.\nEach image is assigned a label 1 or 0. \nThe label 1 is assigned as long as it has at least one bounding box corresponding \nto the object of interest (e.g. person) with the box area greater than a certain threshold \n(e.g. 0.5% of the image area).\n\nTo generate the new annotations, use the script `scripts/create_visualwakewords_annotations.py`.\n```bash\nMAXITRAIN_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_maxitrain.json\"\nMINIVAL_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_minival.json\"\nVWW_OUTPUT_DIR=\"new-path-to-visualwakewords-dataset/annotations/\"\npython scripts/create_visualwakewords_annotations.py \\\n  --train_annotations_file=\"${MAXITRAIN_ANNOTATIONS_FILE}\" \\\n  --val_annotations_file=\"${MINIVAL_ANNOTATIONS_FILE}\" \\\n  --output_dir=\"${VWW_OUTPUT_DIR}\" \\\n  --threshold=0.005 \\\n  --foreground_class='person'\n```\n\nThe generated annotations follow the [COCO Data format](http://cocodataset.org/#format-data).\n```\n{\n  \"info\" : info, \n  \"images\" : [image], \n  \"annotations\" : [annotation], \n  \"licenses\" : [license],\n}\n\ninfo{\n  \"year\" : int, \n  \"version\" : str, \n  \"description\" : str, \n  \"url\" : str, \n}\n\nimage{\n  \"id\" : int, \n  \"width\" : int, \n  \"height\" : int, \n  \"file_name\" : str, \n  \"license\" : int, \n  \"flickr_url\" : str, \n  \"coco_url\" : str, \n  \"date_captured\" : datetime,\n}\n\nlicense{\n  \"id\" : int, \n  \"name\" : str, \n  \"url\" : str,\n}\n\nannotation{\n  \"id\" : int, \n  \"image_id\" : int, \n  \"category_id\" : int, \n  \"area\" : float, \n  \"bbox\" : [x,y,width,height], \n  \"iscrowd\" : 0 or 1,\n}\n```\n\n### Pytorch Dataset\n\nThe `pyvww.pytorch.VisualWakeWordsClassification` can be used in pytorch like any other pytorch image classification\ndataset such as MNIST or ImageNet.\n\nNote: If you used the script `create_coco_train_minival_split.py` to create the annotations for the 115k/8k split, \nyou need to move or copy the train2014 and val2014 directories to a shared directory. E.g.:\n```bash\ncd path-to-mscoco-dataset/\nmkdir all\ncp -a train2014/. all/\ncp -a val2014/. all/\n```\n```python\nimport torch\nimport pyvww\n\ntrain_dataset = pyvww.pytorch.VisualWakeWordsClassification(root=\"path-to-mscoco-dataset/all\", \n                    annFile=\".../visualwakewords/annotations/instances_train.json\")\n```\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Mxbonn/visualwakewords", "keywords": "", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "pyvww", "package_url": "https://pypi.org/project/pyvww/", "platform": "", "project_url": "https://pypi.org/project/pyvww/", "project_urls": {"Homepage": "https://github.com/Mxbonn/visualwakewords"}, "release_url": "https://pypi.org/project/pyvww/0.1.0/", "requires_dist": ["pycocotools"], "requires_python": "", "summary": "Python API to work with the Visual Wake Words Dataset.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Visual Wake Words Dataset</h1>\n<p>Python library to work with the <a href=\"https://arxiv.org/abs/1906.05721\" rel=\"nofollow\">Visual Wake Words Dataset</a>,\ncomparable to <a href=\"https://github.com/cocodataset/cocoapi\" rel=\"nofollow\">pycococools</a> for the COCO dataset.</p>\n<p><code>pyvww.utils.VisualWakeWords</code> inherits from <code>pycocotools.coco.COCO</code> and can be used in an similar fashion.</p>\n<p><code>pyvww.pytorch.VisualWakeWordsClassification</code> is a pytorch <code>Dataset</code> which can be used like any\nimage classification dataset.</p>\n<hr>\n<h3>Installation</h3>\n<p>The code is implemented in Python 3.7 and can be installed with pip:</p>\n<pre>pip install pyvww\n</pre>\n<h3>Usage</h3>\n<p>The Visual Wake Words Dataset is derived from the publicly available <a href=\"cocodataset.org/#/home\" rel=\"nofollow\">COCO</a> dataset.\nTo download the COCO dataset use the script <code>download_coco.sh</code></p>\n<pre>bash scripts/download_mscoco.sh path-to-COCO-dataset\n</pre>\n<p>The Visual Wake Words Dataset evaluates the accuracy on the <a href=\"https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_minival_ids.txt\" rel=\"nofollow\">minival image ids</a>,\nand for training uses the remaining 115k images of the COCO training/validation dataset.</p>\n<p>To create COCO annotation files that convert the 83K/41K split to the 115K/8K split use:\n<code>scripts/create_coco_train_minival_split.py</code></p>\n<pre><span class=\"nv\">TRAIN_ANNOTATIONS_FILE</span><span class=\"o\">=</span><span class=\"s2\">\"path-to-mscoco-dataset/annotations/instances_train2014.json\"</span>\n<span class=\"nv\">VAL_ANNOTATIONS_FILE</span><span class=\"o\">=</span><span class=\"s2\">\"path-to-mscoco-dataset/annotations/instances_val2014.json\"</span>\n<span class=\"nv\">DIR</span><span class=\"o\">=</span><span class=\"s2\">\"path-to-mscoco-dataset/annotations/\"</span>\npython scripts/create_coco_train_minival_split.py <span class=\"se\">\\</span>\n  --train_annotations_file<span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">TRAIN_ANNOTATIONS_FILE</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"se\">\\</span>\n  --val_annotations_file<span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">VAL_ANNOTATIONS_FILE</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"se\">\\</span>\n--output_dir<span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">DIR</span><span class=\"si\">}</span><span class=\"s2\">\"</span>\n</pre>\n<p>The process of creating the Visual Wake Words dataset from COCO dataset is as follows.\nEach image is assigned a label 1 or 0.\nThe label 1 is assigned as long as it has at least one bounding box corresponding\nto the object of interest (e.g. person) with the box area greater than a certain threshold\n(e.g. 0.5% of the image area).</p>\n<p>To generate the new annotations, use the script <code>scripts/create_visualwakewords_annotations.py</code>.</p>\n<pre><span class=\"nv\">MAXITRAIN_ANNOTATIONS_FILE</span><span class=\"o\">=</span><span class=\"s2\">\"path-to-mscoco-dataset/annotations/instances_maxitrain.json\"</span>\n<span class=\"nv\">MINIVAL_ANNOTATIONS_FILE</span><span class=\"o\">=</span><span class=\"s2\">\"path-to-mscoco-dataset/annotations/instances_minival.json\"</span>\n<span class=\"nv\">VWW_OUTPUT_DIR</span><span class=\"o\">=</span><span class=\"s2\">\"new-path-to-visualwakewords-dataset/annotations/\"</span>\npython scripts/create_visualwakewords_annotations.py <span class=\"se\">\\</span>\n  --train_annotations_file<span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">MAXITRAIN_ANNOTATIONS_FILE</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"se\">\\</span>\n  --val_annotations_file<span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">MINIVAL_ANNOTATIONS_FILE</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"se\">\\</span>\n  --output_dir<span class=\"o\">=</span><span class=\"s2\">\"</span><span class=\"si\">${</span><span class=\"nv\">VWW_OUTPUT_DIR</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"se\">\\</span>\n  --threshold<span class=\"o\">=</span><span class=\"m\">0</span>.005 <span class=\"se\">\\</span>\n  --foreground_class<span class=\"o\">=</span><span class=\"s1\">'person'</span>\n</pre>\n<p>The generated annotations follow the <a href=\"http://cocodataset.org/#format-data\" rel=\"nofollow\">COCO Data format</a>.</p>\n<pre><code>{\n  \"info\" : info, \n  \"images\" : [image], \n  \"annotations\" : [annotation], \n  \"licenses\" : [license],\n}\n\ninfo{\n  \"year\" : int, \n  \"version\" : str, \n  \"description\" : str, \n  \"url\" : str, \n}\n\nimage{\n  \"id\" : int, \n  \"width\" : int, \n  \"height\" : int, \n  \"file_name\" : str, \n  \"license\" : int, \n  \"flickr_url\" : str, \n  \"coco_url\" : str, \n  \"date_captured\" : datetime,\n}\n\nlicense{\n  \"id\" : int, \n  \"name\" : str, \n  \"url\" : str,\n}\n\nannotation{\n  \"id\" : int, \n  \"image_id\" : int, \n  \"category_id\" : int, \n  \"area\" : float, \n  \"bbox\" : [x,y,width,height], \n  \"iscrowd\" : 0 or 1,\n}\n</code></pre>\n<h3>Pytorch Dataset</h3>\n<p>The <code>pyvww.pytorch.VisualWakeWordsClassification</code> can be used in pytorch like any other pytorch image classification\ndataset such as MNIST or ImageNet.</p>\n<p>Note: If you used the script <code>create_coco_train_minival_split.py</code> to create the annotations for the 115k/8k split,\nyou need to move or copy the train2014 and val2014 directories to a shared directory. E.g.:</p>\n<pre><span class=\"nb\">cd</span> path-to-mscoco-dataset/\nmkdir all\ncp -a train2014/. all/\ncp -a val2014/. all/\n</pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pyvww</span>\n\n<span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">pyvww</span><span class=\"o\">.</span><span class=\"n\">pytorch</span><span class=\"o\">.</span><span class=\"n\">VisualWakeWordsClassification</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s2\">\"path-to-mscoco-dataset/all\"</span><span class=\"p\">,</span> \n                    <span class=\"n\">annFile</span><span class=\"o\">=</span><span class=\"s2\">\".../visualwakewords/annotations/instances_train.json\"</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 5505307, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "cf615e78ff992b51dae8f5ba136e6c7e", "sha256": "d1f827901e92b749558f0188b0d02473c822e39584dc1e33ec2a55204815bf41"}, "downloads": -1, "filename": "pyvww-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "cf615e78ff992b51dae8f5ba136e6c7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8964, "upload_time": "2019-07-09T07:36:54", "upload_time_iso_8601": "2019-07-09T07:36:54.496017Z", "url": "https://files.pythonhosted.org/packages/42/ae/ade768da67ab85065a01870a0d09c1615b27e63cd4f1b2135e401e365112/pyvww-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6933b140ca1114e4863ac58f0a11b87b", "sha256": "2ebed1557f5df29452ec4ff6ca1246060e2f447cc68e50abd81ea1ac0fa054ee"}, "downloads": -1, "filename": "pyvww-0.1.0.tar.gz", "has_sig": false, "md5_digest": "6933b140ca1114e4863ac58f0a11b87b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4162, "upload_time": "2019-07-09T07:36:56", "upload_time_iso_8601": "2019-07-09T07:36:56.799182Z", "url": "https://files.pythonhosted.org/packages/6a/f2/00167f36bee6989d2a321313467d2c2791f3c51938792bed91babf40f8d5/pyvww-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cf615e78ff992b51dae8f5ba136e6c7e", "sha256": "d1f827901e92b749558f0188b0d02473c822e39584dc1e33ec2a55204815bf41"}, "downloads": -1, "filename": "pyvww-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "cf615e78ff992b51dae8f5ba136e6c7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8964, "upload_time": "2019-07-09T07:36:54", "upload_time_iso_8601": "2019-07-09T07:36:54.496017Z", "url": "https://files.pythonhosted.org/packages/42/ae/ade768da67ab85065a01870a0d09c1615b27e63cd4f1b2135e401e365112/pyvww-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6933b140ca1114e4863ac58f0a11b87b", "sha256": "2ebed1557f5df29452ec4ff6ca1246060e2f447cc68e50abd81ea1ac0fa054ee"}, "downloads": -1, "filename": "pyvww-0.1.0.tar.gz", "has_sig": false, "md5_digest": "6933b140ca1114e4863ac58f0a11b87b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4162, "upload_time": "2019-07-09T07:36:56", "upload_time_iso_8601": "2019-07-09T07:36:56.799182Z", "url": "https://files.pythonhosted.org/packages/6a/f2/00167f36bee6989d2a321313467d2c2791f3c51938792bed91babf40f8d5/pyvww-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:11:46 2020"}