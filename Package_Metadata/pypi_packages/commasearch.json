{"info": {"author": "Thomas Levine", "author_email": "_@thomaslevine.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4"], "description": "When we search for ordinary written documents, we send words into a search\nengine and get pages of words back.\n\nWhat if we could search for spreadsheets\nby sending spreadsheets into a search engine and getting spreadsheets back?\nThe order of the results would be determined by various specialized statistics;\njust as we use PageRank to find relevant hypertext documents, we can develop\nother statistics that help us find relevant spreadsheets.\nRead more `here <http://dada.pink/dada/pagerank-for-spreadsheets>`_\n\nIndexing\n------------\nTo index a new spreadsheet, run this. ::\n\n    , --index [csv file]\n\nFor example, ::\n\n    , --index /home/tlevine/Math Scores 2009 Copy (1).csv \\\n      http://opendata.comune.bari.it/storage/f/2013-09-02T163858/2012_comune_assessori.csv\n\nCaches from the indexing process are stored in the ``~/.,`` directory.\n\nBy default, CSV files that have already been indexed will be skipped; to index\nthe same CSV file again, run with the ``--force`` or ``-f`` option. ::\n\n    , --index --force [csv file]\n\nOnce you have indexed a bunch of CSV files, you can search. ::\n\n    , [csv file]\n\nYou'll see a bunch of data tables as results. ::\n\n    $ , 'Math Scores 2009.csv'\n    /home/tlevine/math-scores-2010-gender.csv\n    /home/tlevine/Math Scores 2009.csv\n    /home/tlevine/Math Scores 2009 Copy (1).csv\n    /home/tlevine/math-scores-2009-ethnicity.csv\n    http://opendata.comune.bari.it/storage/f/2013-09-02T163858/2012_comune_assessori.csv\n    mysql://bob:password@localhost/schools\n\nTo do\n--------\n\n* Add non-exact column matches so that there can be more matches.\n* Store distributions of values (``collections.Counter`` objects) instead\n  of just distinct values (``set`` objects) so that I can run more interesting\n  comparisons.\n* Store a preview of the table in the db or load it from the cache so that\n  the web interface can show the preview.\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tlevine/commasearch", "keywords": null, "license": "AGPL", "maintainer": null, "maintainer_email": null, "name": "commasearch", "package_url": "https://pypi.org/project/commasearch/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/commasearch/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/tlevine/commasearch"}, "release_url": "https://pypi.org/project/commasearch/0.0.3/", "requires_dist": null, "requires_python": null, "summary": "Search for data tables.", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>When we search for ordinary written documents, we send words into a search\nengine and get pages of words back.</p>\n<p>What if we could search for spreadsheets\nby sending spreadsheets into a search engine and getting spreadsheets back?\nThe order of the results would be determined by various specialized statistics;\njust as we use PageRank to find relevant hypertext documents, we can develop\nother statistics that help us find relevant spreadsheets.\nRead more <a href=\"http://dada.pink/dada/pagerank-for-spreadsheets\" rel=\"nofollow\">here</a></p>\n<div id=\"indexing\">\n<h2>Indexing</h2>\n<p>To index a new spreadsheet, run this.</p>\n<pre>, --index [csv file]\n</pre>\n<p>For example,</p>\n<pre>, --index /home/tlevine/Math Scores 2009 Copy (1).csv \\\n  http://opendata.comune.bari.it/storage/f/2013-09-02T163858/2012_comune_assessori.csv\n</pre>\n<p>Caches from the indexing process are stored in the <tt><span class=\"pre\">~/.,</span></tt> directory.</p>\n<p>By default, CSV files that have already been indexed will be skipped; to index\nthe same CSV file again, run with the <tt><span class=\"pre\">--force</span></tt> or <tt><span class=\"pre\">-f</span></tt> option.</p>\n<pre>, --index --force [csv file]\n</pre>\n<p>Once you have indexed a bunch of CSV files, you can search.</p>\n<pre>, [csv file]\n</pre>\n<p>You\u2019ll see a bunch of data tables as results.</p>\n<pre>$ , 'Math Scores 2009.csv'\n/home/tlevine/math-scores-2010-gender.csv\n/home/tlevine/Math Scores 2009.csv\n/home/tlevine/Math Scores 2009 Copy (1).csv\n/home/tlevine/math-scores-2009-ethnicity.csv\nhttp://opendata.comune.bari.it/storage/f/2013-09-02T163858/2012_comune_assessori.csv\nmysql://bob:password@localhost/schools\n</pre>\n</div>\n<div id=\"to-do\">\n<h2>To do</h2>\n<ul>\n<li>Add non-exact column matches so that there can be more matches.</li>\n<li>Store distributions of values (<tt>collections.Counter</tt> objects) instead\nof just distinct values (<tt>set</tt> objects) so that I can run more interesting\ncomparisons.</li>\n<li>Store a preview of the table in the db or load it from the cache so that\nthe web interface can show the preview.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 1115674, "releases": {"0.0.1": [], "0.0.2": [{"comment_text": "", "digests": {"md5": "81a9715d6473189b125bd0bee6781167", "sha256": "2112987dbf014358cb96356a28c1807a507ceaf5acc614b0cf221f865b256529"}, "downloads": -1, "filename": "commasearch-0.0.2.tar.gz", "has_sig": false, "md5_digest": "81a9715d6473189b125bd0bee6781167", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3326, "upload_time": "2014-05-18T23:32:30", "upload_time_iso_8601": "2014-05-18T23:32:30.220216Z", "url": "https://files.pythonhosted.org/packages/b1/9a/cf60dbb12a676d3a26f23f92e66199b6857f79fb7ebd424c467685a965ca/commasearch-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "4381eb40a7ae11e14cab138fddcf6b72", "sha256": "0acbb776bce8a31c5dd55c3f8b79aadff76336778710cf34c3f248872134e4d1"}, "downloads": -1, "filename": "commasearch-0.0.3.tar.gz", "has_sig": false, "md5_digest": "4381eb40a7ae11e14cab138fddcf6b72", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5178, "upload_time": "2014-06-05T15:49:42", "upload_time_iso_8601": "2014-06-05T15:49:42.163252Z", "url": "https://files.pythonhosted.org/packages/f9/a7/05e44ce79a21031234fc3aff18e2ffcfa62fe996378abe1694c8f9bdbd1c/commasearch-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4381eb40a7ae11e14cab138fddcf6b72", "sha256": "0acbb776bce8a31c5dd55c3f8b79aadff76336778710cf34c3f248872134e4d1"}, "downloads": -1, "filename": "commasearch-0.0.3.tar.gz", "has_sig": false, "md5_digest": "4381eb40a7ae11e14cab138fddcf6b72", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5178, "upload_time": "2014-06-05T15:49:42", "upload_time_iso_8601": "2014-06-05T15:49:42.163252Z", "url": "https://files.pythonhosted.org/packages/f9/a7/05e44ce79a21031234fc3aff18e2ffcfa62fe996378abe1694c8f9bdbd1c/commasearch-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:23 2020"}