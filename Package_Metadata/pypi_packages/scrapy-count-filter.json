{"info": {"author": "Cristi Constantin", "author_email": "cristi.constantin@speedpost.net", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Framework :: Scrapy", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only", "Topic :: Software Development"], "description": "# Scrapy-count-filter\n\n  [![Python ver][python-image]][python-url]\n  [![Build Status][build-image]][build-url]\n  [![Code coverage][cover-image]][cover-url]\n  [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\nTwo Downloader Middlewares that allows a [Scrapy Spider](https://scrapy.readthedocs.io/en/latest/topics/spiders.html) to stop requests after a number of pages, or items are scraped.\nThere is a similar functionality in the [CloseSpider extension](https://scrapy.readthedocs.io/en/latest/topics/extensions.html#module-scrapy.extensions.closespider) that stops spiders after a number of pages, items, or errors, but this middleware allows defining counters per domain, and define them as spider arguments instead of project settings.\n\n\n## Install\n\nThis project requires [Python 3.6+](https://www.python.org/) and [pip](https://pip.pypa.io/). Using a [virtual environment](https://virtualenv.pypa.io/) is strongly encouraged.\n\n```sh\n$ pip install scrapy-count-filter\n```\n\n\n## Usage\n\nFor the middlewares to be enabled, they must be added in the project `settings.py`:\n\n```\nDOWNLOADER_MIDDLEWARES = {\n    # maybe other Downloader Middlewares ...\n    # it's suggested to have the Count Filters after all the default middlewares\n    'scrapy_count_filter.middleware.GlobalCountFilterMiddleware': 995,\n    'scrapy_count_filter.middleware.HostsCountFilterMiddleware': 996,\n}\n```\n\nYou can use one, or the other, or both middlewares.\n\nThe counter limits must be defined in the spider instance, in a `spider.count_limits` dict.\n\nThe possible fields are:\n* `page_count` and `item_count` - are used by the GlobalCountFilterMiddleware to stop the spider, if the number of requests, or items scraped is larger than the value provided\n* `page_host_count` and `item_host_count` - are used by the HostsCountFilterMiddleware to start ignoring requests, if the number of requests, or items scraped *per host* is larger than the value provided\n\nAll field values must be integers.\n\nNote that the Spider stops when **any of the counters** overflow.\n\n\nExample when the count of requests, and items scraped are active:\n\n```py\nfrom scrapy.spiders import Spider\n\nclass MySpider(Spider):\n    count_limits = {\"page_count\": 99, \"item_count\": 10}\n```\n\n-----\n\n## License\n\n[BSD3](LICENSE) \u00a9 Cristi Constantin.\n\n\n[build-image]: https://github.com/croqaz/scrapy-count-filter/workflows/Python/badge.svg\n[build-url]: https://github.com/croqaz/scrapy-count-filter/actions\n[cover-image]: https://codecov.io/gh/croqaz/scrapy-count-filter/branch/master/graph/badge.svg\n[cover-url]: https://codecov.io/gh/croqaz/scrapy-count-filter\n[python-image]: https://img.shields.io/badge/Python-3.6-blue.svg\n[python-url]: https://python.org\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/croqaz/scrapy-count-filter", "keywords": "scrapy counter filter", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "scrapy-count-filter", "package_url": "https://pypi.org/project/scrapy-count-filter/", "platform": "Any", "project_url": "https://pypi.org/project/scrapy-count-filter/", "project_urls": {"Homepage": "https://github.com/croqaz/scrapy-count-filter"}, "release_url": "https://pypi.org/project/scrapy-count-filter/0.2.0/", "requires_dist": null, "requires_python": ">=3.6.0", "summary": "Scrapy Middleware for limiting requests based on a counter.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Scrapy-count-filter</h1>\n<p><a href=\"https://python.org\" rel=\"nofollow\"><img alt=\"Python ver\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/03d2248f0737a4e1007a90c83c65c7e25ad6db61/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e362d626c75652e737667\"></a>\n<a href=\"https://github.com/croqaz/scrapy-count-filter/actions\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ccd3b41c0105cfcc11d9cbf0684fe07b3bb21e2d/68747470733a2f2f6769746875622e636f6d2f63726f71617a2f7363726170792d636f756e742d66696c7465722f776f726b666c6f77732f507974686f6e2f62616467652e737667\"></a>\n<a href=\"https://codecov.io/gh/croqaz/scrapy-count-filter\" rel=\"nofollow\"><img alt=\"Code coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cdb06ec92985916c38e3672055ee7b0f6a70fe60/68747470733a2f2f636f6465636f762e696f2f67682f63726f71617a2f7363726170792d636f756e742d66696c7465722f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://github.com/ambv/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<p>Two Downloader Middlewares that allows a <a href=\"https://scrapy.readthedocs.io/en/latest/topics/spiders.html\" rel=\"nofollow\">Scrapy Spider</a> to stop requests after a number of pages, or items are scraped.\nThere is a similar functionality in the <a href=\"https://scrapy.readthedocs.io/en/latest/topics/extensions.html#module-scrapy.extensions.closespider\" rel=\"nofollow\">CloseSpider extension</a> that stops spiders after a number of pages, items, or errors, but this middleware allows defining counters per domain, and define them as spider arguments instead of project settings.</p>\n<h2>Install</h2>\n<p>This project requires <a href=\"https://www.python.org/\" rel=\"nofollow\">Python 3.6+</a> and <a href=\"https://pip.pypa.io/\" rel=\"nofollow\">pip</a>. Using a <a href=\"https://virtualenv.pypa.io/\" rel=\"nofollow\">virtual environment</a> is strongly encouraged.</p>\n<pre>$ pip install scrapy-count-filter\n</pre>\n<h2>Usage</h2>\n<p>For the middlewares to be enabled, they must be added in the project <code>settings.py</code>:</p>\n<pre><code>DOWNLOADER_MIDDLEWARES = {\n    # maybe other Downloader Middlewares ...\n    # it's suggested to have the Count Filters after all the default middlewares\n    'scrapy_count_filter.middleware.GlobalCountFilterMiddleware': 995,\n    'scrapy_count_filter.middleware.HostsCountFilterMiddleware': 996,\n}\n</code></pre>\n<p>You can use one, or the other, or both middlewares.</p>\n<p>The counter limits must be defined in the spider instance, in a <code>spider.count_limits</code> dict.</p>\n<p>The possible fields are:</p>\n<ul>\n<li><code>page_count</code> and <code>item_count</code> - are used by the GlobalCountFilterMiddleware to stop the spider, if the number of requests, or items scraped is larger than the value provided</li>\n<li><code>page_host_count</code> and <code>item_host_count</code> - are used by the HostsCountFilterMiddleware to start ignoring requests, if the number of requests, or items scraped <em>per host</em> is larger than the value provided</li>\n</ul>\n<p>All field values must be integers.</p>\n<p>Note that the Spider stops when <strong>any of the counters</strong> overflow.</p>\n<p>Example when the count of requests, and items scraped are active:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">scrapy.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">Spider</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">count_limits</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"page_count\"</span><span class=\"p\">:</span> <span class=\"mi\">99</span><span class=\"p\">,</span> <span class=\"s2\">\"item_count\"</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">}</span>\n</pre>\n<hr>\n<h2>License</h2>\n<p><a href=\"LICENSE\" rel=\"nofollow\">BSD3</a> \u00a9 Cristi Constantin.</p>\n\n          </div>"}, "last_serial": 6285883, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "765b608b9380f035f4d8eb8e98e2c0db", "sha256": "3ef39f802139fa18f0b52255cb19327d41c64a6ee31fbeb877636f88e8cbd6af"}, "downloads": -1, "filename": "scrapy_count_filter-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "765b608b9380f035f4d8eb8e98e2c0db", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 4123, "upload_time": "2019-12-12T13:28:02", "upload_time_iso_8601": "2019-12-12T13:28:02.529104Z", "url": "https://files.pythonhosted.org/packages/35/a9/4d7adde0ed3741635cc03148afcebb70161ed4b4b44ba97fef8d0781269b/scrapy_count_filter-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "00f775e993e733d764d408c082c983e7", "sha256": "d18e8bc0f021bb83789e834a3c2a16a4c2c90fb594e437a77f1fcf3403a614c5"}, "downloads": -1, "filename": "scrapy-count-filter-0.1.0.tar.gz", "has_sig": false, "md5_digest": "00f775e993e733d764d408c082c983e7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 3869, "upload_time": "2019-12-12T13:28:04", "upload_time_iso_8601": "2019-12-12T13:28:04.684311Z", "url": "https://files.pythonhosted.org/packages/a9/f4/f0bb9011e6fd2909e2982ac068230298b50a35321be52a116e5eac571822/scrapy-count-filter-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "ad52cd1483e3c723a81fb80c9fc40158", "sha256": "5da87c45770d538d307982968bd96803765b3b8e1dd713df7d65423752d659fd"}, "downloads": -1, "filename": "scrapy_count_filter-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ad52cd1483e3c723a81fb80c9fc40158", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 6225, "upload_time": "2019-12-12T13:29:59", "upload_time_iso_8601": "2019-12-12T13:29:59.556650Z", "url": "https://files.pythonhosted.org/packages/ff/a8/4360acb72a5558ab65b8f09c613c28b49c46d52f18a921b48f158669db86/scrapy_count_filter-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "497e9aa5092bff1bff28c1c615bd549d", "sha256": "388bd4f78964f02f4f0557a3ee4f9df820a7e0c273f35183d537708fce494b30"}, "downloads": -1, "filename": "scrapy-count-filter-0.2.0.tar.gz", "has_sig": false, "md5_digest": "497e9aa5092bff1bff28c1c615bd549d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 5351, "upload_time": "2019-12-12T13:30:01", "upload_time_iso_8601": "2019-12-12T13:30:01.744666Z", "url": "https://files.pythonhosted.org/packages/6f/f9/f9a99b97df82439bfdba35b065c4efdc81967effc9d5993b5aa215172203/scrapy-count-filter-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ad52cd1483e3c723a81fb80c9fc40158", "sha256": "5da87c45770d538d307982968bd96803765b3b8e1dd713df7d65423752d659fd"}, "downloads": -1, "filename": "scrapy_count_filter-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ad52cd1483e3c723a81fb80c9fc40158", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 6225, "upload_time": "2019-12-12T13:29:59", "upload_time_iso_8601": "2019-12-12T13:29:59.556650Z", "url": "https://files.pythonhosted.org/packages/ff/a8/4360acb72a5558ab65b8f09c613c28b49c46d52f18a921b48f158669db86/scrapy_count_filter-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "497e9aa5092bff1bff28c1c615bd549d", "sha256": "388bd4f78964f02f4f0557a3ee4f9df820a7e0c273f35183d537708fce494b30"}, "downloads": -1, "filename": "scrapy-count-filter-0.2.0.tar.gz", "has_sig": false, "md5_digest": "497e9aa5092bff1bff28c1c615bd549d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 5351, "upload_time": "2019-12-12T13:30:01", "upload_time_iso_8601": "2019-12-12T13:30:01.744666Z", "url": "https://files.pythonhosted.org/packages/6f/f9/f9a99b97df82439bfdba35b065c4efdc81967effc9d5993b5aa215172203/scrapy-count-filter-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:49 2020"}