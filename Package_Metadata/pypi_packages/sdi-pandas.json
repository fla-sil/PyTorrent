{"info": {"author": "Thorsten Hapke", "author_email": "thorsten.hapke@sap.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# Pandas DataFrame Operators\nAre a set of operators that can be implemented on SAP Data Hub/SAP Data Intelligence. These operators \nhelp to create Pandas DataFrames from CSV-strings or byte-encoded data. \n\nExample graph with creating DataFrames, sampling, joining, selecting and creating CSV:\n![Example pipeline: Create POS](images/CreatePOS_pipeline.png)\n\nThe list of operators are constantly growing and will never be complete. In any case it should provide you the idea of how to develop quickly similar pandas operators that suits your requirements. At the end of the README.md you find a documention with common features and some practices of how it was developed. \n\nMore on the pandas project and the benefits it provides to high-performance data structures and analysis you find at [https://pandas.pydata.org](https://pandas.pydata.org).\n\nAll operators have been developed locally and tested both locally and on an SAP Data Intelligence instance. For more information of how I have done it you find at [sdi_utils](https://github.com/thhapke/sdi_utils) and my blog on SAP Community platform. \n\n## Requirements\n\nIn order to be able to deploy and run the examples, the following requirements need to be fulfilled:\n\n- SAP Data Hub 2.3 or later installed on a supported [platform](https://support.sap.com/content/dam/launchpad/en_us/pam/pam-essentials/SAP_Data_Hub_2_PAM.pdf) or SAP Data Hub, [trial edition 2.3](https://blogs.sap.com/2018/04/26/sap-data-hub-trial-edition/)\n- A docker-image with pandas package installed\n\n## Download and Installation\nIn the *solution*-folder you find the ready-to-import operators that will be stored under the path: \n\n- /files/vflow/subengines/com/sap/python36/operators/pandas\n\n\n## Examples\nIn the github folder *example-graphs* you find an example of how to use the operators.\n\n## Known Issues\n\nCurrently there are no known issues with the operators but nonetheless although all operators come with test cases and the code has limited complexities there might be errors that are not discovered yet. Notes of failing cases are well-appreciated. \n\n## How to get support\n\nIf you need help or in case you found a bug please open a [Github Issue](https://github.com/SAP/datahub-integration-examples/issues).\n\n## How to run\nImport lastest release in */solution/PandasDataFrameOperators-0.0.x.zip* via `SAP Data Hub System Management` -> `Files` -> `Import Solution`\n\n## License\n\nThis project is licensed under the [MIT License](src/LICENSE)\n\n\n## Documentation\nEach operator folder has a README that should describe the behaviour of the operator. \n\n### Local Development Support\nTo work with the IDE of your choice and to run unit tests, you may start the development locally and do the appropriate tests before deploying the scripts in a SAP Data Hub / SAP Data Intelligence cluster. For doing this for all scripts supporting features are provided. There is also a hint for a simulation of a pipeline. Examples are given in the folder of */pipelines*. \n\n\n### Basic Architecture\nThe communication is based on **message.DataFrame** where the body is linked to the DataFrame and the attributes provides some basic information like\n\n* number of columns\n* number of rows\n* index\n* column names\n* memory usage\n* data types of columns\n\nThe ports of communincating between **pandas** operators are type **message.DataFrame** to ensure a test of connecting operators on modeler level. \n\nIn addition there is a port 'log' that collects all logging statements and provided it as string. \n\n\n### Some common features \n#### Memory\nBecause memory usage for big data is critical, **fromCSV** supports to select columns and \nto downcast datatypes. Open is the implementation of datatype **category** to reduce the \nmemory of the extremely memory demanding strings. \nIt is assumed that all data processing with the pandas operators runs in the same container. For crossing pods a streaming needs to be implemented or an intermediate saving of the results in an object store or a database and then reading it from other pods. \n\n#### Communication between operators\nFor the communication the data type **message** is used where \n* **attributes** contains a basic profile of the DataFrame i(e.g. name, last_operator, number of rows and columns, message usage, data types, column names, ...). \n* **body** of the message contains the byte-encoded DataFrame. \n\nThe alternative of using a custom type was discarded because it is not supported within Python operators by providing and supporting the pre-defined structure. The only benefit is that in the Modeler the compatibility of the connections are checked. \n\nWithin a Python operator you can access the attributes of the message as a dictionary where as the body stores the pointer to the DataFrame. \n\nMost of the di_pandas operators have 1 input dataport and 2 outputdata ports. The nomenclature is **DataFrameMsg** for the data message and **Info** for channeling infos to a terminal or a logging file for monitoring the graph behaviour while developing.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/thhapke/sdi_pandas/", "keywords": "SAP Data Intelligence,pandas,operator", "license": "", "maintainer": "", "maintainer_email": "", "name": "sdi-pandas", "package_url": "https://pypi.org/project/sdi-pandas/", "platform": "", "project_url": "https://pypi.org/project/sdi-pandas/", "project_urls": {"Homepage": "https://github.com/thhapke/sdi_pandas/"}, "release_url": "https://pypi.org/project/sdi-pandas/0.0.37/", "requires_dist": null, "requires_python": "", "summary": "List of operators using the pandas module for processing the input", "version": "0.0.37", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pandas DataFrame Operators</h1>\n<p>Are a set of operators that can be implemented on SAP Data Hub/SAP Data Intelligence. These operators\nhelp to create Pandas DataFrames from CSV-strings or byte-encoded data.</p>\n<p>Example graph with creating DataFrames, sampling, joining, selecting and creating CSV:\n<img alt=\"Example pipeline: Create POS\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0e9a0a274ac6b6671731f4a189549a756964d5f7/696d616765732f437265617465504f535f706970656c696e652e706e67\"></p>\n<p>The list of operators are constantly growing and will never be complete. In any case it should provide you the idea of how to develop quickly similar pandas operators that suits your requirements. At the end of the README.md you find a documention with common features and some practices of how it was developed.</p>\n<p>More on the pandas project and the benefits it provides to high-performance data structures and analysis you find at <a href=\"https://pandas.pydata.org\" rel=\"nofollow\">https://pandas.pydata.org</a>.</p>\n<p>All operators have been developed locally and tested both locally and on an SAP Data Intelligence instance. For more information of how I have done it you find at <a href=\"https://github.com/thhapke/sdi_utils\" rel=\"nofollow\">sdi_utils</a> and my blog on SAP Community platform.</p>\n<h2>Requirements</h2>\n<p>In order to be able to deploy and run the examples, the following requirements need to be fulfilled:</p>\n<ul>\n<li>SAP Data Hub 2.3 or later installed on a supported <a href=\"https://support.sap.com/content/dam/launchpad/en_us/pam/pam-essentials/SAP_Data_Hub_2_PAM.pdf\" rel=\"nofollow\">platform</a> or SAP Data Hub, <a href=\"https://blogs.sap.com/2018/04/26/sap-data-hub-trial-edition/\" rel=\"nofollow\">trial edition 2.3</a></li>\n<li>A docker-image with pandas package installed</li>\n</ul>\n<h2>Download and Installation</h2>\n<p>In the <em>solution</em>-folder you find the ready-to-import operators that will be stored under the path:</p>\n<ul>\n<li>/files/vflow/subengines/com/sap/python36/operators/pandas</li>\n</ul>\n<h2>Examples</h2>\n<p>In the github folder <em>example-graphs</em> you find an example of how to use the operators.</p>\n<h2>Known Issues</h2>\n<p>Currently there are no known issues with the operators but nonetheless although all operators come with test cases and the code has limited complexities there might be errors that are not discovered yet. Notes of failing cases are well-appreciated.</p>\n<h2>How to get support</h2>\n<p>If you need help or in case you found a bug please open a <a href=\"https://github.com/SAP/datahub-integration-examples/issues\" rel=\"nofollow\">Github Issue</a>.</p>\n<h2>How to run</h2>\n<p>Import lastest release in <em>/solution/PandasDataFrameOperators-0.0.x.zip</em> via <code>SAP Data Hub System Management</code> -&gt; <code>Files</code> -&gt; <code>Import Solution</code></p>\n<h2>License</h2>\n<p>This project is licensed under the <a href=\"src/LICENSE\" rel=\"nofollow\">MIT License</a></p>\n<h2>Documentation</h2>\n<p>Each operator folder has a README that should describe the behaviour of the operator.</p>\n<h3>Local Development Support</h3>\n<p>To work with the IDE of your choice and to run unit tests, you may start the development locally and do the appropriate tests before deploying the scripts in a SAP Data Hub / SAP Data Intelligence cluster. For doing this for all scripts supporting features are provided. There is also a hint for a simulation of a pipeline. Examples are given in the folder of <em>/pipelines</em>.</p>\n<h3>Basic Architecture</h3>\n<p>The communication is based on <strong>message.DataFrame</strong> where the body is linked to the DataFrame and the attributes provides some basic information like</p>\n<ul>\n<li>number of columns</li>\n<li>number of rows</li>\n<li>index</li>\n<li>column names</li>\n<li>memory usage</li>\n<li>data types of columns</li>\n</ul>\n<p>The ports of communincating between <strong>pandas</strong> operators are type <strong>message.DataFrame</strong> to ensure a test of connecting operators on modeler level.</p>\n<p>In addition there is a port 'log' that collects all logging statements and provided it as string.</p>\n<h3>Some common features</h3>\n<h4>Memory</h4>\n<p>Because memory usage for big data is critical, <strong>fromCSV</strong> supports to select columns and\nto downcast datatypes. Open is the implementation of datatype <strong>category</strong> to reduce the\nmemory of the extremely memory demanding strings.\nIt is assumed that all data processing with the pandas operators runs in the same container. For crossing pods a streaming needs to be implemented or an intermediate saving of the results in an object store or a database and then reading it from other pods.</p>\n<h4>Communication between operators</h4>\n<p>For the communication the data type <strong>message</strong> is used where</p>\n<ul>\n<li><strong>attributes</strong> contains a basic profile of the DataFrame i(e.g. name, last_operator, number of rows and columns, message usage, data types, column names, ...).</li>\n<li><strong>body</strong> of the message contains the byte-encoded DataFrame.</li>\n</ul>\n<p>The alternative of using a custom type was discarded because it is not supported within Python operators by providing and supporting the pre-defined structure. The only benefit is that in the Modeler the compatibility of the connections are checked.</p>\n<p>Within a Python operator you can access the attributes of the message as a dictionary where as the body stores the pointer to the DataFrame.</p>\n<p>Most of the di_pandas operators have 1 input dataport and 2 outputdata ports. The nomenclature is <strong>DataFrameMsg</strong> for the data message and <strong>Info</strong> for channeling infos to a terminal or a logging file for monitoring the graph behaviour while developing.</p>\n\n          </div>"}, "last_serial": 6556969, "releases": {"0.0.11": [{"comment_text": "", "digests": {"md5": "c0366ba1853e6c334395c6d63000d183", "sha256": "3fef670b6cf7293a2ffad4b7d0c083cffad3721e51417a4d1f73b699c9d1fd1d"}, "downloads": -1, "filename": "sdi_pandas-0.0.11.tar.gz", "has_sig": false, "md5_digest": "c0366ba1853e6c334395c6d63000d183", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3734, "upload_time": "2019-12-13T13:32:16", "upload_time_iso_8601": "2019-12-13T13:32:16.323145Z", "url": "https://files.pythonhosted.org/packages/90/77/ebfad5f4a799210ae91b18536c7dc9ca17a8deee27d1cc3d516f00024a7e/sdi_pandas-0.0.11.tar.gz", "yanked": false}], "0.0.26": [{"comment_text": "", "digests": {"md5": "1d3f1dafd6d23e658de28269fab3fd1f", "sha256": "bac2f4dc8b26ad89881fad7d19c4bd53596cca769bc11f668c098c007b6c3ddc"}, "downloads": -1, "filename": "sdi_pandas-0.0.26.tar.gz", "has_sig": false, "md5_digest": "1d3f1dafd6d23e658de28269fab3fd1f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22513, "upload_time": "2020-01-14T09:24:12", "upload_time_iso_8601": "2020-01-14T09:24:12.175242Z", "url": "https://files.pythonhosted.org/packages/ed/48/3fd0e86345a59e418f7be241e28015113e7941d6c4116278b61e15a20642/sdi_pandas-0.0.26.tar.gz", "yanked": false}], "0.0.27": [{"comment_text": "", "digests": {"md5": "c364433f5d3bec2da5a3e7e85b50c7d2", "sha256": "a5302769c178e03b448871c4532af2e539b1e6b37f43392adf5a9195e1121c0b"}, "downloads": -1, "filename": "sdi_pandas-0.0.27.tar.gz", "has_sig": false, "md5_digest": "c364433f5d3bec2da5a3e7e85b50c7d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23756, "upload_time": "2020-01-14T12:33:54", "upload_time_iso_8601": "2020-01-14T12:33:54.745933Z", "url": "https://files.pythonhosted.org/packages/0e/19/ade9ab35eed1dd5a94defb3a6bbb9b383e9675ba5225554495e756f726b0/sdi_pandas-0.0.27.tar.gz", "yanked": false}], "0.0.28": [{"comment_text": "", "digests": {"md5": "bc3a34f52af8523bd094dffdd9383ea7", "sha256": "0dfa74bedcdf1deb8c302cef1367789fdd59e9665fff5eaf25e5b997ac08dc8b"}, "downloads": -1, "filename": "sdi_pandas-0.0.28.tar.gz", "has_sig": false, "md5_digest": "bc3a34f52af8523bd094dffdd9383ea7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28013, "upload_time": "2020-01-26T16:45:25", "upload_time_iso_8601": "2020-01-26T16:45:25.348390Z", "url": "https://files.pythonhosted.org/packages/5f/9f/fef3bb259390d8780166dde3f5bb391e531172b4368427f787bd56bee6d9/sdi_pandas-0.0.28.tar.gz", "yanked": false}], "0.0.29": [{"comment_text": "", "digests": {"md5": "86f57bdc8c88ed76d8173592d52572c1", "sha256": "8ddd7b20c5f79e7ae95a2e7ea35e04db8a4035a4387a77d9f38fea8e60da5db9"}, "downloads": -1, "filename": "sdi_pandas-0.0.29.tar.gz", "has_sig": false, "md5_digest": "86f57bdc8c88ed76d8173592d52572c1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27991, "upload_time": "2020-01-26T20:24:16", "upload_time_iso_8601": "2020-01-26T20:24:16.817075Z", "url": "https://files.pythonhosted.org/packages/a1/b5/653f42ddc16950eb6fd46130a3b991f067fc36a5d57757daf4048bf5f9a8/sdi_pandas-0.0.29.tar.gz", "yanked": false}], "0.0.33": [{"comment_text": "", "digests": {"md5": "c457637fc1a2a6aab82b411b39ed8b2e", "sha256": "5cc70ba20f1136d030a6a3042e3575b0bb22ff6c4ffb4341cf49bc3e8e3e6010"}, "downloads": -1, "filename": "sdi_pandas-0.0.33.tar.gz", "has_sig": false, "md5_digest": "c457637fc1a2a6aab82b411b39ed8b2e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28394, "upload_time": "2020-01-28T10:07:00", "upload_time_iso_8601": "2020-01-28T10:07:00.241956Z", "url": "https://files.pythonhosted.org/packages/6d/76/f72265cc275067f1a168dd80d8ceb9c409c6597dcd3723b6d78363b63491/sdi_pandas-0.0.33.tar.gz", "yanked": false}], "0.0.35": [{"comment_text": "", "digests": {"md5": "1180f4b8d37902faf563db3da8d15bf1", "sha256": "674c04953cb69f860898f4f15bc0b1f1dcecc854c7d5e2afbc09d81054d67255"}, "downloads": -1, "filename": "sdi_pandas-0.0.35.tar.gz", "has_sig": false, "md5_digest": "1180f4b8d37902faf563db3da8d15bf1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28733, "upload_time": "2020-01-30T13:05:46", "upload_time_iso_8601": "2020-01-30T13:05:46.953015Z", "url": "https://files.pythonhosted.org/packages/98/0a/35217ee29c1a6fabe7a1c22b146cebf735fec529a5d41738dcaef40904aa/sdi_pandas-0.0.35.tar.gz", "yanked": false}], "0.0.37": [{"comment_text": "", "digests": {"md5": "3fa58c685fcc82930520dc3dbc3b4504", "sha256": "ac594db7d928cee3f7bf93e6eb1c8bb082434d4c6433a4f8aaef68433505bb4b"}, "downloads": -1, "filename": "sdi_pandas-0.0.37.tar.gz", "has_sig": false, "md5_digest": "3fa58c685fcc82930520dc3dbc3b4504", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28588, "upload_time": "2020-02-02T06:22:42", "upload_time_iso_8601": "2020-02-02T06:22:42.843312Z", "url": "https://files.pythonhosted.org/packages/f1/44/689164c4c1f148c9adf41a316877f9d7f5baca3c73760a974abea94f2527/sdi_pandas-0.0.37.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3fa58c685fcc82930520dc3dbc3b4504", "sha256": "ac594db7d928cee3f7bf93e6eb1c8bb082434d4c6433a4f8aaef68433505bb4b"}, "downloads": -1, "filename": "sdi_pandas-0.0.37.tar.gz", "has_sig": false, "md5_digest": "3fa58c685fcc82930520dc3dbc3b4504", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28588, "upload_time": "2020-02-02T06:22:42", "upload_time_iso_8601": "2020-02-02T06:22:42.843312Z", "url": "https://files.pythonhosted.org/packages/f1/44/689164c4c1f148c9adf41a316877f9d7f5baca3c73760a974abea94f2527/sdi_pandas-0.0.37.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:17 2020"}