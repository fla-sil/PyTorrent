{"info": {"author": "Michael Petrochuk", "author_email": "petrochukm@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "<p align=\"center\"><img width=\"55%\" src=\"docs/_static/img/logo.svg\" /></p>\n\n<h3 align=\"center\">Basic Utilities for PyTorch NLP Software</h3>\n\nPyTorch-NLP, or `torchnlp` for short, is a library of basic utilities for PyTorch\nNatural Language Processing (NLP). `torchnlp` extends PyTorch to provide you with\nbasic text data processing functions.\n\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pytorch-nlp.svg?style=flat-square)\n[![Codecov](https://img.shields.io/codecov/c/github/PetrochukM/PyTorch-NLP/master.svg?style=flat-square)](https://codecov.io/gh/PetrochukM/PyTorch-NLP)\n[![Downloads](http://pepy.tech/badge/pytorch-nlp)](http://pepy.tech/project/pytorch-nlp)\n[![Documentation Status](https://img.shields.io/readthedocs/pytorchnlp/latest.svg?style=flat-square)](http://pytorchnlp.readthedocs.io/en/latest/?badge=latest&style=flat-square)\n[![Build Status](https://img.shields.io/travis/PetrochukM/PyTorch-NLP/master.svg?style=flat-square)](https://travis-ci.org/PetrochukM/PyTorch-NLP)\n[![Twitter: PetrochukM](https://img.shields.io/twitter/follow/MPetrochuk.svg?style=social)](https://twitter.com/MPetrochuk)\n\n_Logo by [Chloe Yeo](http://www.yeochloe.com/), Corporate Sponsorship by [WellSaid Labs](https://wellsaidlabs.com/)_\n\n## Installation \ud83d\udc3e\n\nMake sure you have Python 3.5+ and PyTorch 1.0+. You can then install `pytorch-nlp` using\npip:\n\n```python\npip install pytorch-nlp\n```\n\nOr to install the latest code via:\n\n```python\npip install git+https://github.com/PetrochukM/PyTorch-NLP.git\n```\n\n## Docs\n\nThe complete documentation for PyTorch-NLP is available\nvia [our ReadTheDocs website](https://pytorchnlp.readthedocs.io).\n\n## Get Started\n\nWithin an NLP data pipeline, you'll want to implement these basic steps:\n\n### Load Your Data \ud83d\udc3f\n\nLoad the IMDB dataset, for example:\n\n```python\nfrom torchnlp.datasets import imdb_dataset\n\n# Load the imdb training dataset\ntrain = imdb_dataset(train=True)\ntrain[0]  # RETURNS: {'text': 'For a movie that gets..', 'sentiment': 'pos'}\n```\n\nLoad a custom dataset, for example:\n\n```python\nfrom pathlib import Path\n\nfrom torchnlp.download import download_file_maybe_extract\n\ndirectory_path = Path('data/')\ntrain_file_path = Path('trees/train.txt')\n\ndownload_file_maybe_extract(\n    url='http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip',\n    directory=directory_path,\n    check_files=[train_file_path])\n\nopen(directory_path / train_file_path)\n```\n\nDon't worry we'll handle caching for you!\n\n### Text To Tensor\n\nTokenize and encode your text as a tensor. For example, a `WhitespaceEncoder` breaks\ntext into terms whenever it encounters a whitespace character.\n\n```python\nfrom torchnlp.encoders.text import WhitespaceEncoder\n\nloaded_data = [\"now this ain't funny\", \"so don't you dare laugh\"]\nencoder = WhitespaceEncoder(loaded_data)\nencoded_data = [encoder.encode(example) for example in loaded_data]\n```\n\n### Tensor To Batch\n\nWith your loaded and encoded data in hand, you'll want to batch your dataset.\n\n```python\nimport torch\nfrom torchnlp.samplers import BucketBatchSampler\nfrom torchnlp.utils import collate_tensors\nfrom torchnlp.encoders.text import stack_and_pad_tensors\n\nencoded_data = [torch.randn(2), torch.randn(3), torch.randn(4), torch.randn(5)]\n\ntrain_sampler = torch.utils.data.sampler.SequentialSampler(encoded_data)\ntrain_batch_sampler = BucketBatchSampler(\n    train_sampler, batch_size=2, drop_last=False, sort_key=lambda i: encoded_data[i].shape[0])\n\nbatches = [[encoded_data[i] for i in batch] for batch in train_batch_sampler]\nbatches = [collate_tensors(batch, stack_tensors=stack_and_pad_tensors) for batch in batches]\n```\n\nPyTorch-NLP builds on top of PyTorch's existing `torch.utils.data.sampler`, `torch.stack`\nand `default_collate` to support sequential inputs of varying lengths!\n\n### Your Good To Go!\n\nWith your batch in hand, you can use PyTorch to develop and train your model using gradient descent.\n\n### Last But Not Least\n\nPyTorch-NLP has a couple more NLP focused utility packages to support you! \ud83e\udd17\n\n#### Deterministic Functions\n\nNow you've setup your pipeline, you may want to ensure that some functions run deterministically.\nWrap any code that's random, with `fork_rng` and you'll be good to go, like so:\n\n```python\nimport random\nimport numpy\nimport torch\n\nfrom torchnlp.random import fork_rng\n\nwith fork_rng(seed=123):  # Ensure determinism\n    print('Random:', random.randint(1, 2**31))\n    print('Numpy:', numpy.random.randint(1, 2**31))\n    print('Torch:', int(torch.randint(1, 2**31, (1,))))\n```\n\nThis will always print:\n\n```text\nRandom: 224899943\nNumpy: 843828735\nTorch: 843828736\n```\n\n#### Pre-Trained Word Vectors\n\nNow that you've computed your vocabulary, you may want to make use of\npre-trained word vectors, like so:\n\n```python\nimport torch\nfrom torchnlp.encoders.text import WhitespaceEncoder\nfrom torchnlp.word_to_vector import GloVe\n\nencoder = WhitespaceEncoder([\"now this ain't funny\", \"so don't you dare laugh\"])\n\nvocab = set(encoder.vocab)\npretrained_embedding = GloVe(name='6B', dim=100, is_include=lambda w: w in vocab)\nembedding_weights = torch.Tensor(encoder.vocab_size, pretrained_embedding.dim)\nfor i, token in enumerate(encoder.vocab):\n    embedding_weights[i] = pretrained_embedding[token]\n```\n\n#### Neural Networks Layers\n\nFor example, from the neural network package, apply the state-of-the-art `LockedDropout`:\n\n```python\nimport torch\nfrom torchnlp.nn import LockedDropout\n\ninput_ = torch.randn(6, 3, 10)\ndropout = LockedDropout(0.5)\n\n# Apply a LockedDropout to `input_`\ndropout(input_) # RETURNS: torch.FloatTensor (6x3x10)\n```\n\n#### Metrics\n\nCompute common NLP metrics such as the BLEU score.\n\n```python\nfrom torchnlp.metrics import get_moses_multi_bleu\n\nhypotheses = [\"The brown fox jumps over the dog \u7b11\"]\nreferences = [\"The quick brown fox jumps over the lazy dog \u7b11\"]\n\n# Compute BLEU score with the official BLEU perl script\nget_moses_multi_bleu(hypotheses, references, lowercase=True)  # RETURNS: 47.9\n```\n\n### Help :question:\n\nMaybe looking at longer examples may help you at [`examples/`](examples/).\n\nNeed more help? We are happy to answer your questions via [Gitter Chat](https://gitter.im/PyTorch-NLP)\n\n## Contributing\n\nWe've released PyTorch-NLP because we found a lack of basic toolkits for NLP in PyTorch. We hope that other organizations can benefit from the project. We are thankful for any contributions from the community.\n\n### Contributing Guide\n\nRead our [contributing guide](https://github.com/PetrochukM/PyTorch-NLP/blob/master/CONTRIBUTING.md) to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes to PyTorch-NLP.\n\n## Related Work\n\n### [torchtext](https://github.com/pytorch/text)\n\ntorchtext and PyTorch-NLP differ in the architecture and feature set; otherwise, they are similar. torchtext and PyTorch-NLP provide pre-trained word vectors, datasets, iterators and text encoders. PyTorch-NLP also provides neural network modules and metrics. From an architecture standpoint, torchtext is object orientated with external coupling while PyTorch-NLP is object orientated with low coupling.\n\n### [AllenNLP](https://github.com/allenai/allennlp)\n\nAllenNLP is designed to be a platform for research. PyTorch-NLP is designed to be a lightweight toolkit.\n\n## Authors\n\n- [Michael Petrochuk](https://github.com/PetrochukM/) \u2014 Developer\n- [Chloe Yeo](http://www.yeochloe.com/) \u2014 Logo Design\n\n## Citing\n\nIf you find PyTorch-NLP useful for an academic publication, then please use the following BibTeX to cite it:\n\n```\n@misc{pytorch-nlp,\n  author = {Petrochuk, Michael},\n  title = {PyTorch-NLP: Rapid Prototyping with PyTorch Natural Language Processing (NLP) Tools},\n  year = {2018},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/PetrochukM/PyTorch-NLP}},\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/PetrochukM/PytorchNLP", "keywords": "pytorch nlp text torchtext torchnlp", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "pytorch-nlp", "package_url": "https://pypi.org/project/pytorch-nlp/", "platform": "", "project_url": "https://pypi.org/project/pytorch-nlp/", "project_urls": {"Homepage": "https://github.com/PetrochukM/PytorchNLP"}, "release_url": "https://pypi.org/project/pytorch-nlp/0.5.0/", "requires_dist": ["numpy", "tqdm"], "requires_python": ">=3.5", "summary": "Text utilities and datasets for PyTorch", "version": "0.5.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3506735704bfe638adfa37c2ebc2f441c2786bd9/646f63732f5f7374617469632f696d672f6c6f676f2e737667\" width=\"55%\"></p>\n<h3>Basic Utilities for PyTorch NLP Software</h3>\n<p>PyTorch-NLP, or <code>torchnlp</code> for short, is a library of basic utilities for PyTorch\nNatural Language Processing (NLP). <code>torchnlp</code> extends PyTorch to provide you with\nbasic text data processing functions.</p>\n<p><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9bfbf644201049bb2ea60b1dab908748ad060adc/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f7079746f7263682d6e6c702e7376673f7374796c653d666c61742d737175617265\">\n<a href=\"https://codecov.io/gh/PetrochukM/PyTorch-NLP\" rel=\"nofollow\"><img alt=\"Codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/583b2c44519e5795814b0f27b3e939cc10e66e3f/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f506574726f6368756b4d2f5079546f7263682d4e4c502f6d61737465722e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"http://pepy.tech/project/pytorch-nlp\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/92af536abd8cbcb5882291b752262064e15c7cde/687474703a2f2f706570792e746563682f62616467652f7079746f7263682d6e6c70\"></a>\n<a href=\"http://pytorchnlp.readthedocs.io/en/latest/?badge=latest&amp;style=flat-square\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/942df27da3bd63c8cf3d263e680f2730be7a412b/68747470733a2f2f696d672e736869656c64732e696f2f72656164746865646f63732f7079746f7263686e6c702f6c61746573742e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://travis-ci.org/PetrochukM/PyTorch-NLP\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/92aceefdf7bfdcefb3c160eb6508e39fbff499af/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f506574726f6368756b4d2f5079546f7263682d4e4c502f6d61737465722e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://twitter.com/MPetrochuk\" rel=\"nofollow\"><img alt=\"Twitter: PetrochukM\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/329c0f4ba2d063a873d98b7e152b3fa00621c89a/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f4d506574726f6368756b2e7376673f7374796c653d736f6369616c\"></a></p>\n<p><em>Logo by <a href=\"http://www.yeochloe.com/\" rel=\"nofollow\">Chloe Yeo</a>, Corporate Sponsorship by <a href=\"https://wellsaidlabs.com/\" rel=\"nofollow\">WellSaid Labs</a></em></p>\n<h2>Installation \ud83d\udc3e</h2>\n<p>Make sure you have Python 3.5+ and PyTorch 1.0+. You can then install <code>pytorch-nlp</code> using\npip:</p>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">pytorch</span><span class=\"o\">-</span><span class=\"n\">nlp</span>\n</pre>\n<p>Or to install the latest code via:</p>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">git</span><span class=\"o\">+</span><span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">github</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">PetrochukM</span><span class=\"o\">/</span><span class=\"n\">PyTorch</span><span class=\"o\">-</span><span class=\"n\">NLP</span><span class=\"o\">.</span><span class=\"n\">git</span>\n</pre>\n<h2>Docs</h2>\n<p>The complete documentation for PyTorch-NLP is available\nvia <a href=\"https://pytorchnlp.readthedocs.io\" rel=\"nofollow\">our ReadTheDocs website</a>.</p>\n<h2>Get Started</h2>\n<p>Within an NLP data pipeline, you'll want to implement these basic steps:</p>\n<h3>Load Your Data \ud83d\udc3f</h3>\n<p>Load the IMDB dataset, for example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchnlp.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">imdb_dataset</span>\n\n<span class=\"c1\"># Load the imdb training dataset</span>\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">imdb_dataset</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">train</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>  <span class=\"c1\"># RETURNS: {'text': 'For a movie that gets..', 'sentiment': 'pos'}</span>\n</pre>\n<p>Load a custom dataset, for example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pathlib</span> <span class=\"kn\">import</span> <span class=\"n\">Path</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.download</span> <span class=\"kn\">import</span> <span class=\"n\">download_file_maybe_extract</span>\n\n<span class=\"n\">directory_path</span> <span class=\"o\">=</span> <span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'data/'</span><span class=\"p\">)</span>\n<span class=\"n\">train_file_path</span> <span class=\"o\">=</span> <span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'trees/train.txt'</span><span class=\"p\">)</span>\n\n<span class=\"n\">download_file_maybe_extract</span><span class=\"p\">(</span>\n    <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip'</span><span class=\"p\">,</span>\n    <span class=\"n\">directory</span><span class=\"o\">=</span><span class=\"n\">directory_path</span><span class=\"p\">,</span>\n    <span class=\"n\">check_files</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">train_file_path</span><span class=\"p\">])</span>\n\n<span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">directory_path</span> <span class=\"o\">/</span> <span class=\"n\">train_file_path</span><span class=\"p\">)</span>\n</pre>\n<p>Don't worry we'll handle caching for you!</p>\n<h3>Text To Tensor</h3>\n<p>Tokenize and encode your text as a tensor. For example, a <code>WhitespaceEncoder</code> breaks\ntext into terms whenever it encounters a whitespace character.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchnlp.encoders.text</span> <span class=\"kn\">import</span> <span class=\"n\">WhitespaceEncoder</span>\n\n<span class=\"n\">loaded_data</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"now this ain't funny\"</span><span class=\"p\">,</span> <span class=\"s2\">\"so don't you dare laugh\"</span><span class=\"p\">]</span>\n<span class=\"n\">encoder</span> <span class=\"o\">=</span> <span class=\"n\">WhitespaceEncoder</span><span class=\"p\">(</span><span class=\"n\">loaded_data</span><span class=\"p\">)</span>\n<span class=\"n\">encoded_data</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">example</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">example</span> <span class=\"ow\">in</span> <span class=\"n\">loaded_data</span><span class=\"p\">]</span>\n</pre>\n<h3>Tensor To Batch</h3>\n<p>With your loaded and encoded data in hand, you'll want to batch your dataset.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.samplers</span> <span class=\"kn\">import</span> <span class=\"n\">BucketBatchSampler</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.utils</span> <span class=\"kn\">import</span> <span class=\"n\">collate_tensors</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.encoders.text</span> <span class=\"kn\">import</span> <span class=\"n\">stack_and_pad_tensors</span>\n\n<span class=\"n\">encoded_data</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)]</span>\n\n<span class=\"n\">train_sampler</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">sampler</span><span class=\"o\">.</span><span class=\"n\">SequentialSampler</span><span class=\"p\">(</span><span class=\"n\">encoded_data</span><span class=\"p\">)</span>\n<span class=\"n\">train_batch_sampler</span> <span class=\"o\">=</span> <span class=\"n\">BucketBatchSampler</span><span class=\"p\">(</span>\n    <span class=\"n\">train_sampler</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">drop_last</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">sort_key</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">i</span><span class=\"p\">:</span> <span class=\"n\">encoded_data</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"n\">batches</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"n\">encoded_data</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"n\">batch</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">train_batch_sampler</span><span class=\"p\">]</span>\n<span class=\"n\">batches</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">collate_tensors</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">stack_tensors</span><span class=\"o\">=</span><span class=\"n\">stack_and_pad_tensors</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">batches</span><span class=\"p\">]</span>\n</pre>\n<p>PyTorch-NLP builds on top of PyTorch's existing <code>torch.utils.data.sampler</code>, <code>torch.stack</code>\nand <code>default_collate</code> to support sequential inputs of varying lengths!</p>\n<h3>Your Good To Go!</h3>\n<p>With your batch in hand, you can use PyTorch to develop and train your model using gradient descent.</p>\n<h3>Last But Not Least</h3>\n<p>PyTorch-NLP has a couple more NLP focused utility packages to support you! \ud83e\udd17</p>\n<h4>Deterministic Functions</h4>\n<p>Now you've setup your pipeline, you may want to ensure that some functions run deterministically.\nWrap any code that's random, with <code>fork_rng</code> and you'll be good to go, like so:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">random</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.random</span> <span class=\"kn\">import</span> <span class=\"n\">fork_rng</span>\n\n<span class=\"k\">with</span> <span class=\"n\">fork_rng</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">123</span><span class=\"p\">):</span>  <span class=\"c1\"># Ensure determinism</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Random:'</span><span class=\"p\">,</span> <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"o\">**</span><span class=\"mi\">31</span><span class=\"p\">))</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Numpy:'</span><span class=\"p\">,</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"o\">**</span><span class=\"mi\">31</span><span class=\"p\">))</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Torch:'</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"o\">**</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,))))</span>\n</pre>\n<p>This will always print:</p>\n<pre>Random: 224899943\nNumpy: 843828735\nTorch: 843828736\n</pre>\n<h4>Pre-Trained Word Vectors</h4>\n<p>Now that you've computed your vocabulary, you may want to make use of\npre-trained word vectors, like so:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.encoders.text</span> <span class=\"kn\">import</span> <span class=\"n\">WhitespaceEncoder</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.word_to_vector</span> <span class=\"kn\">import</span> <span class=\"n\">GloVe</span>\n\n<span class=\"n\">encoder</span> <span class=\"o\">=</span> <span class=\"n\">WhitespaceEncoder</span><span class=\"p\">([</span><span class=\"s2\">\"now this ain't funny\"</span><span class=\"p\">,</span> <span class=\"s2\">\"so don't you dare laugh\"</span><span class=\"p\">])</span>\n\n<span class=\"n\">vocab</span> <span class=\"o\">=</span> <span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">)</span>\n<span class=\"n\">pretrained_embedding</span> <span class=\"o\">=</span> <span class=\"n\">GloVe</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'6B'</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">is_include</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">w</span><span class=\"p\">:</span> <span class=\"n\">w</span> <span class=\"ow\">in</span> <span class=\"n\">vocab</span><span class=\"p\">)</span>\n<span class=\"n\">embedding_weights</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">(</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">vocab_size</span><span class=\"p\">,</span> <span class=\"n\">pretrained_embedding</span><span class=\"o\">.</span><span class=\"n\">dim</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">token</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">encoder</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">):</span>\n    <span class=\"n\">embedding_weights</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">pretrained_embedding</span><span class=\"p\">[</span><span class=\"n\">token</span><span class=\"p\">]</span>\n</pre>\n<h4>Neural Networks Layers</h4>\n<p>For example, from the neural network package, apply the state-of-the-art <code>LockedDropout</code>:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchnlp.nn</span> <span class=\"kn\">import</span> <span class=\"n\">LockedDropout</span>\n\n<span class=\"n\">input_</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">dropout</span> <span class=\"o\">=</span> <span class=\"n\">LockedDropout</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Apply a LockedDropout to `input_`</span>\n<span class=\"n\">dropout</span><span class=\"p\">(</span><span class=\"n\">input_</span><span class=\"p\">)</span> <span class=\"c1\"># RETURNS: torch.FloatTensor (6x3x10)</span>\n</pre>\n<h4>Metrics</h4>\n<p>Compute common NLP metrics such as the BLEU score.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchnlp.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">get_moses_multi_bleu</span>\n\n<span class=\"n\">hypotheses</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"The brown fox jumps over the dog \u7b11\"</span><span class=\"p\">]</span>\n<span class=\"n\">references</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"The quick brown fox jumps over the lazy dog \u7b11\"</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># Compute BLEU score with the official BLEU perl script</span>\n<span class=\"n\">get_moses_multi_bleu</span><span class=\"p\">(</span><span class=\"n\">hypotheses</span><span class=\"p\">,</span> <span class=\"n\">references</span><span class=\"p\">,</span> <span class=\"n\">lowercase</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>  <span class=\"c1\"># RETURNS: 47.9</span>\n</pre>\n<h3>Help :question:</h3>\n<p>Maybe looking at longer examples may help you at <a href=\"examples/\" rel=\"nofollow\"><code>examples/</code></a>.</p>\n<p>Need more help? We are happy to answer your questions via <a href=\"https://gitter.im/PyTorch-NLP\" rel=\"nofollow\">Gitter Chat</a></p>\n<h2>Contributing</h2>\n<p>We've released PyTorch-NLP because we found a lack of basic toolkits for NLP in PyTorch. We hope that other organizations can benefit from the project. We are thankful for any contributions from the community.</p>\n<h3>Contributing Guide</h3>\n<p>Read our <a href=\"https://github.com/PetrochukM/PyTorch-NLP/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">contributing guide</a> to learn about our development process, how to propose bugfixes and improvements, and how to build and test your changes to PyTorch-NLP.</p>\n<h2>Related Work</h2>\n<h3><a href=\"https://github.com/pytorch/text\" rel=\"nofollow\">torchtext</a></h3>\n<p>torchtext and PyTorch-NLP differ in the architecture and feature set; otherwise, they are similar. torchtext and PyTorch-NLP provide pre-trained word vectors, datasets, iterators and text encoders. PyTorch-NLP also provides neural network modules and metrics. From an architecture standpoint, torchtext is object orientated with external coupling while PyTorch-NLP is object orientated with low coupling.</p>\n<h3><a href=\"https://github.com/allenai/allennlp\" rel=\"nofollow\">AllenNLP</a></h3>\n<p>AllenNLP is designed to be a platform for research. PyTorch-NLP is designed to be a lightweight toolkit.</p>\n<h2>Authors</h2>\n<ul>\n<li><a href=\"https://github.com/PetrochukM/\" rel=\"nofollow\">Michael Petrochuk</a> \u2014 Developer</li>\n<li><a href=\"http://www.yeochloe.com/\" rel=\"nofollow\">Chloe Yeo</a> \u2014 Logo Design</li>\n</ul>\n<h2>Citing</h2>\n<p>If you find PyTorch-NLP useful for an academic publication, then please use the following BibTeX to cite it:</p>\n<pre><code>@misc{pytorch-nlp,\n  author = {Petrochuk, Michael},\n  title = {PyTorch-NLP: Rapid Prototyping with PyTorch Natural Language Processing (NLP) Tools},\n  year = {2018},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/PetrochukM/PyTorch-NLP}},\n}\n</code></pre>\n\n          </div>"}, "last_serial": 6073086, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "58452c95f0df2e4f2378e2aa84def2d8", "sha256": "3eadd081db81d78c470093058e43472e9f0afb68b6e06b9c76130ac939d9830a"}, "downloads": -1, "filename": "pytorch_nlp-0.0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "58452c95f0df2e4f2378e2aa84def2d8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": ">=3.5", "size": 32848, "upload_time": "2018-03-01T01:46:44", "upload_time_iso_8601": "2018-03-01T01:46:44.555745Z", "url": "https://files.pythonhosted.org/packages/e3/90/69a6abf7d542bc61fe9d555c5315b39cf7cad8b67ff5b4359843d94c0f57/pytorch_nlp-0.0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c51aa532c29fb01087b3e04a8dff40fd", "sha256": "d01de66051e76ba334885bb92d45ebbf1d93d70a408bf2bf5ec80f8a0ac05e2d"}, "downloads": -1, "filename": "pytorch_nlp-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c51aa532c29fb01087b3e04a8dff40fd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 32849, "upload_time": "2018-03-01T01:46:46", "upload_time_iso_8601": "2018-03-01T01:46:46.261738Z", "url": "https://files.pythonhosted.org/packages/1f/32/0431c6ec90c3ae7d09cca13c2fffeb21dfd9afe008cb13d4ff45dc21cbe3/pytorch_nlp-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "31178c1e18510b87473faafbd7a37342", "sha256": "e11f3d80297242d01f438a0caaa53e53360f30c17e0db92f5fd32192e8366a7c"}, "downloads": -1, "filename": "pytorch-nlp-0.0.1.tar.gz", "has_sig": false, "md5_digest": "31178c1e18510b87473faafbd7a37342", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 20419, "upload_time": "2018-03-01T01:46:47", "upload_time_iso_8601": "2018-03-01T01:46:47.231259Z", "url": "https://files.pythonhosted.org/packages/89/7d/ebb7f28eb51f9bef06047a02d624ab36f13f7c38e5dc9dbd41796ff6ae88/pytorch-nlp-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "d4b1dadd7e6c9a51a41b1b871f383bb5", "sha256": "ad57eeada6923eb98dac77a0f10e82e9882a745f56932629a3765e36ce4e053f"}, "downloads": -1, "filename": "pytorch_nlp-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "d4b1dadd7e6c9a51a41b1b871f383bb5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 31574, "upload_time": "2018-03-01T02:02:29", "upload_time_iso_8601": "2018-03-01T02:02:29.514629Z", "url": "https://files.pythonhosted.org/packages/c7/c9/d7b1a2711bdfdce6361b911c29dcaf363b3f6f265d4b0f26cb42e7ef983e/pytorch_nlp-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "af39d4c5c6a31c441d0f87e5b150a35e", "sha256": "14bad3113cab6d602bb3d4f043a54c97bfe0ca694e51533f6d1fc36c85c5589e"}, "downloads": -1, "filename": "pytorch-nlp-0.0.2.tar.gz", "has_sig": false, "md5_digest": "af39d4c5c6a31c441d0f87e5b150a35e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 20256, "upload_time": "2018-03-01T02:02:31", "upload_time_iso_8601": "2018-03-01T02:02:31.046248Z", "url": "https://files.pythonhosted.org/packages/80/15/7ee545f1a37595fa250abbc4e62912a10c7b4964a9fb085cc4595163200b/pytorch-nlp-0.0.2.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "2e0a8d33577b24d0a8a55bde8582dc13", "sha256": "3f6e6d081613217e80fbb951d40b5aed4f204881ad780965c0d5fd51ec0387ad"}, "downloads": -1, "filename": "pytorch_nlp-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2e0a8d33577b24d0a8a55bde8582dc13", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 55448, "upload_time": "2018-03-16T15:12:36", "upload_time_iso_8601": "2018-03-16T15:12:36.244461Z", "url": "https://files.pythonhosted.org/packages/1d/e0/2a6ce11e1d47813295294707a2e08b6375884a4aa9b2cc0243304b17c02b/pytorch_nlp-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "913faf2c76300098910edd5081833fe8", "sha256": "7bab9ac1db6bcdded7b3b6857010d2cddf1ea3cf64738dc484d63ba6de49d7fc"}, "downloads": -1, "filename": "pytorch-nlp-0.1.0.tar.gz", "has_sig": false, "md5_digest": "913faf2c76300098910edd5081833fe8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 29514, "upload_time": "2018-03-16T15:12:38", "upload_time_iso_8601": "2018-03-16T15:12:38.159346Z", "url": "https://files.pythonhosted.org/packages/2c/bf/8ae80336e969968fa0ad7428837907a4c2075c54f255bd7687f409aa06bf/pytorch-nlp-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "756cb184a3365d870301d20b5ce8994f", "sha256": "66df3fc042c870e845054d4ea17afdd616e2b24f7405da682e9c5fa9b1263b1a"}, "downloads": -1, "filename": "pytorch_nlp-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "756cb184a3365d870301d20b5ce8994f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 91411, "upload_time": "2018-04-08T21:31:43", "upload_time_iso_8601": "2018-04-08T21:31:43.554277Z", "url": "https://files.pythonhosted.org/packages/72/d4/ce87eadb9f7f3c88503c52577aa7a27e6c90b3aa18688d612f5e3dbc4565/pytorch_nlp-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5d1fbd70d837e85ed0c9a3075c5aeb29", "sha256": "b755096e482cbd82f888a475a5d8c85e70a3ef6f45c9c5b04f2941bfdaf02471"}, "downloads": -1, "filename": "pytorch-nlp-0.2.0.tar.gz", "has_sig": false, "md5_digest": "5d1fbd70d837e85ed0c9a3075c5aeb29", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 47151, "upload_time": "2018-04-08T21:31:44", "upload_time_iso_8601": "2018-04-08T21:31:44.596456Z", "url": "https://files.pythonhosted.org/packages/5d/71/f23177d907319e2bc6740bcc91952deba7446f584e20267b4ec28b4f355c/pytorch-nlp-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "419d4e0ac59fd127c7ec7c57d8c9ce25", "sha256": "da6ff41abfee57dd58fe3834cacfc61368ea46f0e46a8c02d645cedba017c020"}, "downloads": -1, "filename": "pytorch_nlp-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "419d4e0ac59fd127c7ec7c57d8c9ce25", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 100284, "upload_time": "2018-05-06T18:51:12", "upload_time_iso_8601": "2018-05-06T18:51:12.461138Z", "url": "https://files.pythonhosted.org/packages/ba/b1/f90dfc5e37cffc3d64b2aa022e30fb0b56861c250b4c75c2912dca3cd7f5/pytorch_nlp-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "15a7a5eb58314acb86ab180f44248a76", "sha256": "6d265447e07728d478101720a23295821c8ce22ccdd9feba16c40fbbbcb0dd0e"}, "downloads": -1, "filename": "pytorch-nlp-0.3.0.tar.gz", "has_sig": false, "md5_digest": "15a7a5eb58314acb86ab180f44248a76", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51407, "upload_time": "2018-05-06T18:51:13", "upload_time_iso_8601": "2018-05-06T18:51:13.837197Z", "url": "https://files.pythonhosted.org/packages/26/ca/0b17e3f132f5d456c55bc415f1d1ff2a9bff45562008b2ae92720a9d5aeb/pytorch-nlp-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "385131f062e0cad8ed6a4a01b390cc31", "sha256": "e1decf43d7e460eaa68efb19c34fb75957d57d7d87cf6284df2441d6fb4f60c0"}, "downloads": -1, "filename": "pytorch_nlp-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "385131f062e0cad8ed6a4a01b390cc31", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 100285, "upload_time": "2018-05-06T19:20:01", "upload_time_iso_8601": "2018-05-06T19:20:01.347953Z", "url": "https://files.pythonhosted.org/packages/83/f2/ef3b06581b811bb7d18236e43f61a54a09b7dd8b4f431925e7bb13faed14/pytorch_nlp-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8e963b470d29fb9c7453994cb83c3779", "sha256": "ebe97fcde55c03dd236267c9c646937e627b49ca309ddcf6291323296716358c"}, "downloads": -1, "filename": "pytorch-nlp-0.3.1.tar.gz", "has_sig": false, "md5_digest": "8e963b470d29fb9c7453994cb83c3779", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51450, "upload_time": "2018-05-06T19:20:02", "upload_time_iso_8601": "2018-05-06T19:20:02.704670Z", "url": "https://files.pythonhosted.org/packages/34/9d/9d42c4c82d6aabdff464b836f3a088c2b972f4890ad4d5e4b1a97267321c/pytorch-nlp-0.3.1.tar.gz", "yanked": false}], "0.3.1a0": [{"comment_text": "", "digests": {"md5": "659573ddb6a4e648b611cad5bd4c8922", "sha256": "b79f9574f57b61db9f9129fc96f5cedbec72b9fa28604d5c377d112745681361"}, "downloads": -1, "filename": "pytorch_nlp-0.3.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "659573ddb6a4e648b611cad5bd4c8922", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 96654, "upload_time": "2018-05-06T19:25:47", "upload_time_iso_8601": "2018-05-06T19:25:47.215028Z", "url": "https://files.pythonhosted.org/packages/a0/f9/cda2482c585221ef967fd429d97c24a7522d8b14e246e818232245188ce9/pytorch_nlp-0.3.1a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "71b57f8ec5ab4066c3a53a912fdaed36", "sha256": "c17eca45a4cb447cb3926e2eb8b9cf6497647c5044b6ea2f3b587d1a3c39dfec"}, "downloads": -1, "filename": "pytorch-nlp-0.3.1a0.tar.gz", "has_sig": false, "md5_digest": "71b57f8ec5ab4066c3a53a912fdaed36", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51481, "upload_time": "2018-05-06T19:25:48", "upload_time_iso_8601": "2018-05-06T19:25:48.588396Z", "url": "https://files.pythonhosted.org/packages/c7/1e/8d1b3cec3798d9a6fb054343b83705a0d1511e3e678be86815f4b3ae2d5a/pytorch-nlp-0.3.1a0.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "50fb1938aa1d0ae5ad3232b033a99df2", "sha256": "ab8cbb51f489cd072a5f8bbb3ec0ea9c09bf5f8dab138a193a171b63ed68ffbd"}, "downloads": -1, "filename": "pytorch_nlp-0.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "50fb1938aa1d0ae5ad3232b033a99df2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 96626, "upload_time": "2018-05-06T19:27:27", "upload_time_iso_8601": "2018-05-06T19:27:27.461628Z", "url": "https://files.pythonhosted.org/packages/ef/67/8524c7473f87129521797bac49c24b87980d629e972267aa62dee2cc6266/pytorch_nlp-0.3.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ddbc0ba8546ac82c6f732c593440f97a", "sha256": "8f8fadcc1a991af145a808ae5e1be32c9e13eb142f3feed66f2b3ae6c0be91eb"}, "downloads": -1, "filename": "pytorch-nlp-0.3.2.tar.gz", "has_sig": false, "md5_digest": "ddbc0ba8546ac82c6f732c593440f97a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51487, "upload_time": "2018-05-06T19:27:28", "upload_time_iso_8601": "2018-05-06T19:27:28.972893Z", "url": "https://files.pythonhosted.org/packages/d1/f3/8cf77eed0ea90df4bf2467b71c36d6ca89c52a0593b6c5844b2705574949/pytorch-nlp-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "543dc9e61df2b78ddc1961c8fe03363a", "sha256": "1c92fce8156cb30257b772197e3ca91073aa01c0aba03a9127edafa1141de1a4"}, "downloads": -1, "filename": "pytorch_nlp-0.3.3-py3-none-any.whl", "has_sig": false, "md5_digest": "543dc9e61df2b78ddc1961c8fe03363a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 96639, "upload_time": "2018-05-06T19:31:39", "upload_time_iso_8601": "2018-05-06T19:31:39.061229Z", "url": "https://files.pythonhosted.org/packages/14/74/2da7a7c4036347ba17fa87345b0406e586b1b7aa83587d4465102d809ccf/pytorch_nlp-0.3.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f375a72bf22e95499d400393951264ce", "sha256": "67b8b177b733250cba80ac082d9f4c1ee558b0eee595785c10a67c19da03ed0b"}, "downloads": -1, "filename": "pytorch-nlp-0.3.3.tar.gz", "has_sig": false, "md5_digest": "f375a72bf22e95499d400393951264ce", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51474, "upload_time": "2018-05-06T19:31:40", "upload_time_iso_8601": "2018-05-06T19:31:40.678604Z", "url": "https://files.pythonhosted.org/packages/44/49/921e4b5a077be07bf34b9db9087bdc8eca659e9b35c712012a139936249d/pytorch-nlp-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "df0beee135ff287cd2ac6fb820d31ea9", "sha256": "670aef8f049783a5cd9df1259e8ebfc5098fa4021bcf0e1c9e4cb1bc9cfb6154"}, "downloads": -1, "filename": "pytorch_nlp-0.3.4-py3-none-any.whl", "has_sig": false, "md5_digest": "df0beee135ff287cd2ac6fb820d31ea9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 96639, "upload_time": "2018-05-06T19:33:57", "upload_time_iso_8601": "2018-05-06T19:33:57.359351Z", "url": "https://files.pythonhosted.org/packages/2c/2f/0c7cdddce18b890601cfb5c593c8ae6a218639febb1fb7eea48ddfc71590/pytorch_nlp-0.3.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8c126dba770ac38e1683013e8a0aa6aa", "sha256": "69d694f7e42efce6287b38d266d667d839606c86527093c4aacdc5ff56c8fbf4"}, "downloads": -1, "filename": "pytorch-nlp-0.3.4.tar.gz", "has_sig": false, "md5_digest": "8c126dba770ac38e1683013e8a0aa6aa", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51465, "upload_time": "2018-05-06T19:33:58", "upload_time_iso_8601": "2018-05-06T19:33:58.753384Z", "url": "https://files.pythonhosted.org/packages/e4/ee/8996efa2974bc517bd9d545f500282ab963c189576aa573d4550d55b6d7e/pytorch-nlp-0.3.4.tar.gz", "yanked": false}], "0.3.5": [{"comment_text": "", "digests": {"md5": "419e824149c7d0a1b1a37e78599b93a9", "sha256": "daa5d3dd5fcedb8192a07b6cf812df52ae7c88f51ce0593dd2450a4b5304ff9c"}, "downloads": -1, "filename": "pytorch_nlp-0.3.5-py3-none-any.whl", "has_sig": false, "md5_digest": "419e824149c7d0a1b1a37e78599b93a9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 96627, "upload_time": "2018-05-06T20:30:21", "upload_time_iso_8601": "2018-05-06T20:30:21.043481Z", "url": "https://files.pythonhosted.org/packages/11/6b/e7b42dca1f1fe69ffdcf5720eff18166a2713e3d4f5f219337b5a07500e6/pytorch_nlp-0.3.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c48ba05e9ebf9a4bbab2cb348512825e", "sha256": "c59db00ea0d7ede737095cc81fd4c316d2fbd3a3e195a6bc9b476d344fd1c1bb"}, "downloads": -1, "filename": "pytorch-nlp-0.3.5.tar.gz", "has_sig": false, "md5_digest": "c48ba05e9ebf9a4bbab2cb348512825e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 51442, "upload_time": "2018-05-06T20:30:22", "upload_time_iso_8601": "2018-05-06T20:30:22.694635Z", "url": "https://files.pythonhosted.org/packages/64/d7/14c3917de8c895cbf72d8102d5c450859971bdb1061a6e2940534bcf1933/pytorch-nlp-0.3.5.tar.gz", "yanked": false}], "0.3.6": [{"comment_text": "", "digests": {"md5": "fe8e0fd5714d57026306dce60670e807", "sha256": "b66d4935fb346ef7607fd5ed34dd2f5f9bddf78140a7f3399589996cb66d46d8"}, "downloads": -1, "filename": "pytorch_nlp-0.3.6-py3-none-any.whl", "has_sig": false, "md5_digest": "fe8e0fd5714d57026306dce60670e807", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 99605, "upload_time": "2018-11-29T21:15:43", "upload_time_iso_8601": "2018-11-29T21:15:43.540083Z", "url": "https://files.pythonhosted.org/packages/81/75/795ddc1655fbc4894eefdb1c0e5ab243d9ca7f2ea44521b37e0abd198b82/pytorch_nlp-0.3.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5cffca78fed201fcc0122605562f87de", "sha256": "78ef5f28707aa6434ae6c130ec8ee2ced4f5c944b5a6c72a57163371fbe19898"}, "downloads": -1, "filename": "pytorch-nlp-0.3.6.tar.gz", "has_sig": false, "md5_digest": "5cffca78fed201fcc0122605562f87de", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 52264, "upload_time": "2018-11-29T21:15:45", "upload_time_iso_8601": "2018-11-29T21:15:45.622347Z", "url": "https://files.pythonhosted.org/packages/82/69/99b233d5ba078e531ed4002de1f1a9faadc84d820ceb00833cd70ce67640/pytorch-nlp-0.3.6.tar.gz", "yanked": false}], "0.3.7": [{"comment_text": "", "digests": {"md5": "1931f5adf7751cc4aea6e4fed765a0f1", "sha256": "1f3d87463f14cc5b966d8f53d6036d08594b6b17dbc7c9b2f59b69b1c6c05048"}, "downloads": -1, "filename": "pytorch_nlp-0.3.7-py3-none-any.whl", "has_sig": false, "md5_digest": "1931f5adf7751cc4aea6e4fed765a0f1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 83712, "upload_time": "2018-11-29T21:39:17", "upload_time_iso_8601": "2018-11-29T21:39:17.237561Z", "url": "https://files.pythonhosted.org/packages/96/b6/172fd1e73a18e7d5ce0606cf8432d9b45ff34a1b0945b8888856b10e8463/pytorch_nlp-0.3.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f3148839bb2085e249e0b87853a0a18c", "sha256": "dc589c8dcc49937d006e9db80492b423fea82881347db8a97f78b66eeaeaa1ea"}, "downloads": -1, "filename": "pytorch-nlp-0.3.7.tar.gz", "has_sig": false, "md5_digest": "f3148839bb2085e249e0b87853a0a18c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 52262, "upload_time": "2018-11-29T21:39:18", "upload_time_iso_8601": "2018-11-29T21:39:18.983455Z", "url": "https://files.pythonhosted.org/packages/bb/74/9fedd0eeca3f8477d7fcbd903495a5d632c633b8c5e3de16989817dc466d/pytorch-nlp-0.3.7.tar.gz", "yanked": false}], "0.3.7.post1": [{"comment_text": "", "digests": {"md5": "cea23babb33079689c85c44fee8d397a", "sha256": "412ee5fa43dc635b350ad5d8774919bf867706920f47761ebdc3b7c9e1166091"}, "downloads": -1, "filename": "pytorch_nlp-0.3.7.post1-py3-none-any.whl", "has_sig": false, "md5_digest": "cea23babb33079689c85c44fee8d397a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 83790, "upload_time": "2018-11-29T22:24:47", "upload_time_iso_8601": "2018-11-29T22:24:47.749937Z", "url": "https://files.pythonhosted.org/packages/81/23/8f30a4032acc239d1f4452765f80eea2c3043b9ca33deb24a79afac354c1/pytorch_nlp-0.3.7.post1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b8604f9cd5747ed997ebc5793d49f760", "sha256": "6e3a0fe638eb99098069ff25d6de303ed54632caaf657f9703d90636d10aef3e"}, "downloads": -1, "filename": "pytorch-nlp-0.3.7.post1.tar.gz", "has_sig": false, "md5_digest": "b8604f9cd5747ed997ebc5793d49f760", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 52268, "upload_time": "2018-11-29T22:24:49", "upload_time_iso_8601": "2018-11-29T22:24:49.381473Z", "url": "https://files.pythonhosted.org/packages/e8/f8/07f2436cf33cab4df2a50413ef466eca067390c4e24f4d597ef049d8a7af/pytorch-nlp-0.3.7.post1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "3328486b64cab9744f35414612fa1a44", "sha256": "5843f6518a6c68e9786a939aeac49834aa69853a6a3ff0982ebda9d93be98873"}, "downloads": -1, "filename": "pytorch_nlp-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3328486b64cab9744f35414612fa1a44", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 82776, "upload_time": "2019-04-03T02:19:10", "upload_time_iso_8601": "2019-04-03T02:19:10.682241Z", "url": "https://files.pythonhosted.org/packages/f5/d0/476cea6e25c0be0884a7d173c81450cf0f8941e8df92d6800bed92d0a487/pytorch_nlp-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "997eff8541cc772d6b7c71233d3ece66", "sha256": "1a869eaf6549b75ccfa08088855bbdacc2322e0b6ca4305c681270d2ec517dd1"}, "downloads": -1, "filename": "pytorch-nlp-0.4.0.tar.gz", "has_sig": false, "md5_digest": "997eff8541cc772d6b7c71233d3ece66", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 48935, "upload_time": "2019-04-03T02:19:12", "upload_time_iso_8601": "2019-04-03T02:19:12.389622Z", "url": "https://files.pythonhosted.org/packages/eb/b7/489429e0c9c929d30bd2d44d88cd00c9b736fef2b2d68658b3d07e9a1c15/pytorch-nlp-0.4.0.tar.gz", "yanked": false}], "0.4.0.post1": [{"comment_text": "", "digests": {"md5": "486481ff4974e890dc67e40f6e9384db", "sha256": "6d3b763119af479828c07c8ec4248beb4d7b7a43712bf7a6f77896585cc43554"}, "downloads": -1, "filename": "pytorch_nlp-0.4.0.post1-py3-none-any.whl", "has_sig": false, "md5_digest": "486481ff4974e890dc67e40f6e9384db", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 83297, "upload_time": "2019-04-07T01:48:46", "upload_time_iso_8601": "2019-04-07T01:48:46.911235Z", "url": "https://files.pythonhosted.org/packages/c9/b4/3ec3a57ed1c4a1c43daf2a7bb8b5a378cfc7a709d906d475272b5076d3fa/pytorch_nlp-0.4.0.post1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3adc61b54e2b530e8dba42d6c589bea8", "sha256": "fa83d950a52223b011f7b7b4ad581eded44fdbc82d8dcf23a790c7d9f9a57de0"}, "downloads": -1, "filename": "pytorch-nlp-0.4.0.post1.tar.gz", "has_sig": false, "md5_digest": "3adc61b54e2b530e8dba42d6c589bea8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 49466, "upload_time": "2019-04-07T01:48:48", "upload_time_iso_8601": "2019-04-07T01:48:48.404347Z", "url": "https://files.pythonhosted.org/packages/72/6e/6a9c7867efeb0cef00845a3d86fbb17d324c2e3d18177626f64c8a0ad505/pytorch-nlp-0.4.0.post1.tar.gz", "yanked": false}], "0.4.0.post2": [{"comment_text": "", "digests": {"md5": "4a5c1bb0acf90ba1ca5423b4cc1c1d86", "sha256": "e51c097baf8c94c00960df1ea9bc327801e12cbae80852964a7023921e00bf32"}, "downloads": -1, "filename": "pytorch_nlp-0.4.0.post2-py3-none-any.whl", "has_sig": false, "md5_digest": "4a5c1bb0acf90ba1ca5423b4cc1c1d86", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 83328, "upload_time": "2019-04-08T23:38:29", "upload_time_iso_8601": "2019-04-08T23:38:29.976429Z", "url": "https://files.pythonhosted.org/packages/5b/3e/cb2663ea0837b04936a27c695af1947288e2189872f6e469181a94771a75/pytorch_nlp-0.4.0.post2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e6de0610413397f8665c18b6647b8d08", "sha256": "be7b982faf96728b6ada37216d3b1d619b3feae79b9d931ea6a38fe60a0594d4"}, "downloads": -1, "filename": "pytorch-nlp-0.4.0.post2.tar.gz", "has_sig": false, "md5_digest": "e6de0610413397f8665c18b6647b8d08", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 49492, "upload_time": "2019-04-08T23:38:31", "upload_time_iso_8601": "2019-04-08T23:38:31.900020Z", "url": "https://files.pythonhosted.org/packages/7b/c6/e6718e2c6f24d05590ff2548f6ed710ae98864e091b6a226414d1f289623/pytorch-nlp-0.4.0.post2.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "6e98b27c515cba2f27a181e1c672c574", "sha256": "03e13b01b875c8b4c4277a914a6dc1fdb5653459bccd4ab93a525e5cca7dd1f6"}, "downloads": -1, "filename": "pytorch_nlp-0.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "6e98b27c515cba2f27a181e1c672c574", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 82262, "upload_time": "2019-04-09T22:15:45", "upload_time_iso_8601": "2019-04-09T22:15:45.910258Z", "url": "https://files.pythonhosted.org/packages/df/ae/b6d18c3f37da5a78e83701469e6153811f4b0ecb3f9387bb3e9a65ca48ee/pytorch_nlp-0.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "30f10bd580e8e1e3e545e0eaf5c58dd3", "sha256": "bb99b7a5cb02cb8e0aac3e6685b5b96aa2c3746326decb6a52e8b8df3aec29e7"}, "downloads": -1, "filename": "pytorch-nlp-0.4.1.tar.gz", "has_sig": false, "md5_digest": "30f10bd580e8e1e3e545e0eaf5c58dd3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 49622, "upload_time": "2019-04-09T22:15:48", "upload_time_iso_8601": "2019-04-09T22:15:48.143487Z", "url": "https://files.pythonhosted.org/packages/b0/ae/24e0a9dab242747fc6bab8ca67967c8b0a8c564c05b6d9ffc66bf464820f/pytorch-nlp-0.4.1.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "44da919fb26f55b61fe48c34ac9c08ff", "sha256": "ddce6448819d1518d2694622573caff268a20c19832f55f7f5b672e2a64a400f"}, "downloads": -1, "filename": "pytorch_nlp-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "44da919fb26f55b61fe48c34ac9c08ff", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 90058, "upload_time": "2019-11-04T04:35:18", "upload_time_iso_8601": "2019-11-04T04:35:18.274041Z", "url": "https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dae243ec042562942306fb0b350e2e3f", "sha256": "aba7aecbc6f0952edde8bc067394c8d43b74a35c5949d6106666d01a64d9cfab"}, "downloads": -1, "filename": "pytorch-nlp-0.5.0.tar.gz", "has_sig": false, "md5_digest": "dae243ec042562942306fb0b350e2e3f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 53172, "upload_time": "2019-11-04T04:35:20", "upload_time_iso_8601": "2019-11-04T04:35:20.286774Z", "url": "https://files.pythonhosted.org/packages/2a/e7/e7921317e311f2dcbb8c93d7b0aace35ac7bf079a38bdccda8e8de7a27ea/pytorch-nlp-0.5.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "44da919fb26f55b61fe48c34ac9c08ff", "sha256": "ddce6448819d1518d2694622573caff268a20c19832f55f7f5b672e2a64a400f"}, "downloads": -1, "filename": "pytorch_nlp-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "44da919fb26f55b61fe48c34ac9c08ff", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 90058, "upload_time": "2019-11-04T04:35:18", "upload_time_iso_8601": "2019-11-04T04:35:18.274041Z", "url": "https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dae243ec042562942306fb0b350e2e3f", "sha256": "aba7aecbc6f0952edde8bc067394c8d43b74a35c5949d6106666d01a64d9cfab"}, "downloads": -1, "filename": "pytorch-nlp-0.5.0.tar.gz", "has_sig": false, "md5_digest": "dae243ec042562942306fb0b350e2e3f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 53172, "upload_time": "2019-11-04T04:35:20", "upload_time_iso_8601": "2019-11-04T04:35:20.286774Z", "url": "https://files.pythonhosted.org/packages/2a/e7/e7921317e311f2dcbb8c93d7b0aace35ac7bf079a38bdccda8e8de7a27ea/pytorch-nlp-0.5.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:47 2020"}