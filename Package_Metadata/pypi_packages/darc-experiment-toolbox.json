{"info": {"author": "Benjamin T. Vincent", "author_email": "b.t.vincent@dundee.ac.uk", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# The DARC Toolbox: automated, flexible, and efficient delayed and risky choice experiments using Bayesian adaptive design.\n\n[![PyPI](https://img.shields.io/pypi/v/darc_toolbox.svg?color=green)](https://pypi.org/project/darc_toolbox/)\n\nRun efficient Bayesian adaptive experiments using Python and the [PsychoPy](http://www.psychopy.org) experiment framework.\n\nThis code relates to the following pre-print. But, the pre-print is likely to appear in quite a different form when finally published.\n> Vincent, B. T., & Rainforth, T. (2017, October 20). The DARC Toolbox: automated, flexible, and efficient delayed and risky choice experiments using Bayesian adaptive design. Retrieved from psyarxiv.com/yehjb\n\n**Status:  \ud83d\udd25 Under active development \ud83d\udd25**\n\n# Features\n\n- Easily run a range of decision making experiments using PsychoPy. These include delayed decisions (inter-temporal choice), risky choice tasks, and combined delayed and risky choice tasks.\n- Get more accurate measures from fewer trials.\n- Rich exports: Get trial-level data, estimated parameters from your chosen decision making model(s), and visualisation of results.\n- Easy customisation of experiment details within PsychoPy.\n\nAdvanced features are available with some simple edits to the Python code:\n\n- Customise your prior beliefs over model parameters to fit your participant population.\n- Simultaneously fit mulitple models to an experimental participant.\n- Inject custom trials: if you have particular experimental needs, you can inject your own (manually specified) designs amongst automatically run trials.\n\n# Installation instructions (for most people)\n1. **Download PsychoPy:** The DARC Toolbox is built into PsychoPy (version 3.2.0 onwards). So go and [download PsychoPy](https://www.psychopy.org).\n2. **Unpack demos:** From the menu, choose `Demos > Unpack demos` to a location of your choosing.\n3. **Run demo:** Run one of the adpative demos, for example the `adaptive_decision_making_demo`.\n\n# Installation instructions (for developers)\nComing soon...\n\n# Adaptive Experiment = Experimental Design Space + Cognitive Model\nAn adaptive experiment is a combination of a set of allowable designs (questions) which we call the **design space** and a **cognitive model**. The Bayesian Adaptive Design methods select which design to present to participants on a trial-to-trial basis, in real time. The goal of this is to maximise the information we gain about our model parameters.\n\nA range of experimental designs and cognitive models are provided and are detailed below.\n\n## Experimental design paradigms\nOne of the core components of this package is to provide designs chosen through Bayesian Adaptive Design, as outlined in our prepint (Vincent & Rainforth, 2017). The core classes of design we focus on are:\n\n- **Delayed choice tasks (aka inter-temporal choice):** You can choose between various protocols such as: front-end delays, fixed delayed reward, fixed immediate reward, fixed delay, etc.\n- **Risky choice tasks:** Choose your range of reward probabilities. These can also be seen as a transformed version of odds against recieving a reward.\n- **Simultaneous delayed and risky choice tasks:** Again, you can customise the range of delays and reward probability (risk) levels used in your experiment.\n\nAll of these paradigms are available, and can be fine tuned, using our Bayesian Adaptive procedure.\n\nHowever we also provide the ability to run some other prominent experiment design procedures from the literature. These are:\n- The Kirby (2009) delay discounting procedure.\n- The 5 trial procedure outlined by Koffarnus & Bickel (2014).\n- The adaptive procedure from Du, Green & Myerson (2002) for delayed and risky choice tasks.\n- The 'delay slice' procecure from Frye et al (2016), closely related to the approach of Du, Green & Myerson (2002).\n- The delay and risky choice procedures from Griskevicius et al (2011).\n\n\n## DARC Cognitive models available\n\nYou can in run adaptive experiments to make very efficient inferences about the parameters for models of your choice. See below for a list of completed models. See the [model-related GitHub issues](https://github.com/drbenvincent/darc-experiments-python/issues?q=is%3Aissue+is%3Aopen+label%3Amodel) to see what is in progress. Feel free to impliment additional models or request one.\n\n### Delayed reward paradigm models\nModel | Info\n--- | ---\nExponential | Samuelson, P. A. (1937). A note on measurement of utility. The Review of Economic Studies, 4(2), 155. http://doi.org/10.2307/2967612\nHyperbolic | Mazur, J. E. (1987). An adjusting procedure for studying delayed reinforcement. In M. L. Commons, J. A. Nevin, & H. Rachlin (Eds.), Quantitative Analyses of Behavior (pp. 55\u201373). Hillsdale, NJ: Erlbaum.\nHyperbolicMagnitudeEffect | Vincent, B. T. (2016). Hierarchical Bayesian estimation and hypothesis testing for delay discounting tasks. Behavior Research Methods, 48(4), 1608\u20131620. http://doi.org/10.3758/s13428-015-0672-2\nExponentialMagnitudeEffect |\nModified Rachlin hyperboloid | Vincent, B. T., & Stewart, N. (2018, October 16). The case of muddled units in temporal discounting. https://doi.org/10.31234/osf.io/29sgd\nMyerson hyperboloid | Myerson, J. and Green, L. (1995). Discounting of delayed rewards: Models of individual choice. Journal of the experimental analysis of behavior, 64(3):263\u2013276.\n\n### Risky reward paradigm models\nModel | Info\n--- | ---\nHyperbolic |Hyperbolic discounting of odds against reward\nLinear in log odds | Gonzalez, R., & Wu, G. (1999). On the shape of the probability weighting function. Cognitive Psychology, 38(1), 129\u2013166. http://doi.org/10.1006/cogp.1998.0710\nProportional difference |Gonz\u00e1lez-Vallejo, C. (2002). Making trade-offs: A probabilistic and context-sensitive model of choice behavior. Psychological Review, 109(1), 137\u2013155. http://doi.org/10.1037//0033-295X.109.1.137\n\n### Delayed and risky reward paradigm models\nModel | Info\n--- | ---\nMultiplicativeHyperbolic | Vanderveldt, A., Green, L., & Myerson, J. (2015). Discounting of monetary rewards that are both delayed and probabilistic: delay and probability combine multiplicatively, not additively. Journal of Experimental Psychology: Learning, Memory, and Cognition, 41(1), 148\u2013162. http://doi.org/10.1037/xlm0000029\n\n\n# How to...\n\n(coming soon)\n\n\n# Other projects we rely upon\n\n- [PsychoPy](http://www.psychopy.org) as the experiment environment.\n\nVarious Python packages including:\n- [Numpy](http://www.numpy.org)\n- [Pandas](https://pandas.pydata.org)\n- [SciPy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html). We use the scipy distributions to represent our prior beliefs over model parameters, and to draw samples from those prior beliefs. See [the full list of distributions here](https://docs.scipy.org/doc/scipy/reference/stats.html)\n\n\n# References\n\n**NOTE:** This work is based on the pre-print below. This is not yet published and is likely to appear in a subtantially altered form.\n\n> Vincent, B. T., & Rainforth, T. (2017, October 20). The DARC Toolbox: automated, flexible, and efficient delayed and risky choice experiments using Bayesian adaptive design. Retrieved from [psyarxiv.com/yehjb](https://psyarxiv.com/yehjb)\n\nDu, W., Green, L., & Myerson, J. (2002). Cross-Cultural Comparisons of Discounting Delayed and Probabilistic Rewards. The Psychological Record, 52(4), 479\u2013492.\n\nFrye, C. C. J., Galizio, A., Friedel, J. E., DeHart, W. B., & Odum, A. L. (2016). Measuring Delay Discounting in Humans Using an Adjusting Amount Task. Journal of Visualized Experiments, (107), 1-8.\n\nGriskevicius, V., Tybur, J. M., Delton, A. W., & Robertson, T. E. (2011). The influence of mortality and socioeconomic status on risk and delayed rewards: A life history theory approach. Journal of Personality and Social Psychology, 100(6), 1015\u201326.\n\nKirby, K. N. (2009). One-year temporal stability of delay-discount rates. Psychonomic Bulletin & Review, 16(3):457\u2013462.\n\nKoffarnus, M. N., & Bickel, W. K. (2014). A 5-trial adjusting delay discounting task: Accurate discount rates in less than one minute. Experimental and Clinical Psychopharmacology, 22(3), 222-228.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/drbenvincent/darc_toolbox", "keywords": "delay discounting,risky choice,psychological experiments,bayesian,adaptive design,inference", "license": "", "maintainer": "", "maintainer_email": "", "name": "darc-experiment-toolbox", "package_url": "https://pypi.org/project/darc-experiment-toolbox/", "platform": "", "project_url": "https://pypi.org/project/darc-experiment-toolbox/", "project_urls": {"Homepage": "https://github.com/drbenvincent/darc_toolbox"}, "release_url": "https://pypi.org/project/darc-experiment-toolbox/0.0.1/", "requires_dist": ["badapted (>=0.0.2)", "matplotlib", "numpy", "pandas", "scipy"], "requires_python": "", "summary": "Delayed And Risky Choice Toolbox", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>The DARC Toolbox: automated, flexible, and efficient delayed and risky choice experiments using Bayesian adaptive design.</h1>\n<p><a href=\"https://pypi.org/project/darc_toolbox/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cae78c053d05954e1489f5590b4bf73b3a033256/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646172635f746f6f6c626f782e7376673f636f6c6f723d677265656e\"></a></p>\n<p>Run efficient Bayesian adaptive experiments using Python and the <a href=\"http://www.psychopy.org\" rel=\"nofollow\">PsychoPy</a> experiment framework.</p>\n<p>This code relates to the following pre-print. But, the pre-print is likely to appear in quite a different form when finally published.</p>\n<blockquote>\n<p>Vincent, B. T., &amp; Rainforth, T. (2017, October 20). The DARC Toolbox: automated, flexible, and efficient delayed and risky choice experiments using Bayesian adaptive design. Retrieved from psyarxiv.com/yehjb</p>\n</blockquote>\n<p><strong>Status:  \ud83d\udd25 Under active development \ud83d\udd25</strong></p>\n<h1>Features</h1>\n<ul>\n<li>Easily run a range of decision making experiments using PsychoPy. These include delayed decisions (inter-temporal choice), risky choice tasks, and combined delayed and risky choice tasks.</li>\n<li>Get more accurate measures from fewer trials.</li>\n<li>Rich exports: Get trial-level data, estimated parameters from your chosen decision making model(s), and visualisation of results.</li>\n<li>Easy customisation of experiment details within PsychoPy.</li>\n</ul>\n<p>Advanced features are available with some simple edits to the Python code:</p>\n<ul>\n<li>Customise your prior beliefs over model parameters to fit your participant population.</li>\n<li>Simultaneously fit mulitple models to an experimental participant.</li>\n<li>Inject custom trials: if you have particular experimental needs, you can inject your own (manually specified) designs amongst automatically run trials.</li>\n</ul>\n<h1>Installation instructions (for most people)</h1>\n<ol>\n<li><strong>Download PsychoPy:</strong> The DARC Toolbox is built into PsychoPy (version 3.2.0 onwards). So go and <a href=\"https://www.psychopy.org\" rel=\"nofollow\">download PsychoPy</a>.</li>\n<li><strong>Unpack demos:</strong> From the menu, choose <code>Demos &gt; Unpack demos</code> to a location of your choosing.</li>\n<li><strong>Run demo:</strong> Run one of the adpative demos, for example the <code>adaptive_decision_making_demo</code>.</li>\n</ol>\n<h1>Installation instructions (for developers)</h1>\n<p>Coming soon...</p>\n<h1>Adaptive Experiment = Experimental Design Space + Cognitive Model</h1>\n<p>An adaptive experiment is a combination of a set of allowable designs (questions) which we call the <strong>design space</strong> and a <strong>cognitive model</strong>. The Bayesian Adaptive Design methods select which design to present to participants on a trial-to-trial basis, in real time. The goal of this is to maximise the information we gain about our model parameters.</p>\n<p>A range of experimental designs and cognitive models are provided and are detailed below.</p>\n<h2>Experimental design paradigms</h2>\n<p>One of the core components of this package is to provide designs chosen through Bayesian Adaptive Design, as outlined in our prepint (Vincent &amp; Rainforth, 2017). The core classes of design we focus on are:</p>\n<ul>\n<li><strong>Delayed choice tasks (aka inter-temporal choice):</strong> You can choose between various protocols such as: front-end delays, fixed delayed reward, fixed immediate reward, fixed delay, etc.</li>\n<li><strong>Risky choice tasks:</strong> Choose your range of reward probabilities. These can also be seen as a transformed version of odds against recieving a reward.</li>\n<li><strong>Simultaneous delayed and risky choice tasks:</strong> Again, you can customise the range of delays and reward probability (risk) levels used in your experiment.</li>\n</ul>\n<p>All of these paradigms are available, and can be fine tuned, using our Bayesian Adaptive procedure.</p>\n<p>However we also provide the ability to run some other prominent experiment design procedures from the literature. These are:</p>\n<ul>\n<li>The Kirby (2009) delay discounting procedure.</li>\n<li>The 5 trial procedure outlined by Koffarnus &amp; Bickel (2014).</li>\n<li>The adaptive procedure from Du, Green &amp; Myerson (2002) for delayed and risky choice tasks.</li>\n<li>The 'delay slice' procecure from Frye et al (2016), closely related to the approach of Du, Green &amp; Myerson (2002).</li>\n<li>The delay and risky choice procedures from Griskevicius et al (2011).</li>\n</ul>\n<h2>DARC Cognitive models available</h2>\n<p>You can in run adaptive experiments to make very efficient inferences about the parameters for models of your choice. See below for a list of completed models. See the <a href=\"https://github.com/drbenvincent/darc-experiments-python/issues?q=is%3Aissue+is%3Aopen+label%3Amodel\" rel=\"nofollow\">model-related GitHub issues</a> to see what is in progress. Feel free to impliment additional models or request one.</p>\n<h3>Delayed reward paradigm models</h3>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Info</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Exponential</td>\n<td>Samuelson, P. A. (1937). A note on measurement of utility. The Review of Economic Studies, 4(2), 155. <a href=\"http://doi.org/10.2307/2967612\" rel=\"nofollow\">http://doi.org/10.2307/2967612</a></td>\n</tr>\n<tr>\n<td>Hyperbolic</td>\n<td>Mazur, J. E. (1987). An adjusting procedure for studying delayed reinforcement. In M. L. Commons, J. A. Nevin, &amp; H. Rachlin (Eds.), Quantitative Analyses of Behavior (pp. 55\u201373). Hillsdale, NJ: Erlbaum.</td>\n</tr>\n<tr>\n<td>HyperbolicMagnitudeEffect</td>\n<td>Vincent, B. T. (2016). Hierarchical Bayesian estimation and hypothesis testing for delay discounting tasks. Behavior Research Methods, 48(4), 1608\u20131620. <a href=\"http://doi.org/10.3758/s13428-015-0672-2\" rel=\"nofollow\">http://doi.org/10.3758/s13428-015-0672-2</a></td>\n</tr>\n<tr>\n<td>ExponentialMagnitudeEffect</td>\n<td></td>\n</tr>\n<tr>\n<td>Modified Rachlin hyperboloid</td>\n<td>Vincent, B. T., &amp; Stewart, N. (2018, October 16). The case of muddled units in temporal discounting. <a href=\"https://doi.org/10.31234/osf.io/29sgd\" rel=\"nofollow\">https://doi.org/10.31234/osf.io/29sgd</a></td>\n</tr>\n<tr>\n<td>Myerson hyperboloid</td>\n<td>Myerson, J. and Green, L. (1995). Discounting of delayed rewards: Models of individual choice. Journal of the experimental analysis of behavior, 64(3):263\u2013276.</td>\n</tr></tbody></table>\n<h3>Risky reward paradigm models</h3>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Info</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Hyperbolic</td>\n<td>Hyperbolic discounting of odds against reward</td>\n</tr>\n<tr>\n<td>Linear in log odds</td>\n<td>Gonzalez, R., &amp; Wu, G. (1999). On the shape of the probability weighting function. Cognitive Psychology, 38(1), 129\u2013166. <a href=\"http://doi.org/10.1006/cogp.1998.0710\" rel=\"nofollow\">http://doi.org/10.1006/cogp.1998.0710</a></td>\n</tr>\n<tr>\n<td>Proportional difference</td>\n<td>Gonz\u00e1lez-Vallejo, C. (2002). Making trade-offs: A probabilistic and context-sensitive model of choice behavior. Psychological Review, 109(1), 137\u2013155. <a href=\"http://doi.org/10.1037//0033-295X.109.1.137\" rel=\"nofollow\">http://doi.org/10.1037//0033-295X.109.1.137</a></td>\n</tr></tbody></table>\n<h3>Delayed and risky reward paradigm models</h3>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Info</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MultiplicativeHyperbolic</td>\n<td>Vanderveldt, A., Green, L., &amp; Myerson, J. (2015). Discounting of monetary rewards that are both delayed and probabilistic: delay and probability combine multiplicatively, not additively. Journal of Experimental Psychology: Learning, Memory, and Cognition, 41(1), 148\u2013162. <a href=\"http://doi.org/10.1037/xlm0000029\" rel=\"nofollow\">http://doi.org/10.1037/xlm0000029</a></td>\n</tr></tbody></table>\n<h1>How to...</h1>\n<p>(coming soon)</p>\n<h1>Other projects we rely upon</h1>\n<ul>\n<li><a href=\"http://www.psychopy.org\" rel=\"nofollow\">PsychoPy</a> as the experiment environment.</li>\n</ul>\n<p>Various Python packages including:</p>\n<ul>\n<li><a href=\"http://www.numpy.org\" rel=\"nofollow\">Numpy</a></li>\n<li><a href=\"https://pandas.pydata.org\" rel=\"nofollow\">Pandas</a></li>\n<li><a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html\" rel=\"nofollow\">SciPy.stats</a>. We use the scipy distributions to represent our prior beliefs over model parameters, and to draw samples from those prior beliefs. See <a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html\" rel=\"nofollow\">the full list of distributions here</a></li>\n</ul>\n<h1>References</h1>\n<p><strong>NOTE:</strong> This work is based on the pre-print below. This is not yet published and is likely to appear in a subtantially altered form.</p>\n<blockquote>\n<p>Vincent, B. T., &amp; Rainforth, T. (2017, October 20). The DARC Toolbox: automated, flexible, and efficient delayed and risky choice experiments using Bayesian adaptive design. Retrieved from <a href=\"https://psyarxiv.com/yehjb\" rel=\"nofollow\">psyarxiv.com/yehjb</a></p>\n</blockquote>\n<p>Du, W., Green, L., &amp; Myerson, J. (2002). Cross-Cultural Comparisons of Discounting Delayed and Probabilistic Rewards. The Psychological Record, 52(4), 479\u2013492.</p>\n<p>Frye, C. C. J., Galizio, A., Friedel, J. E., DeHart, W. B., &amp; Odum, A. L. (2016). Measuring Delay Discounting in Humans Using an Adjusting Amount Task. Journal of Visualized Experiments, (107), 1-8.</p>\n<p>Griskevicius, V., Tybur, J. M., Delton, A. W., &amp; Robertson, T. E. (2011). The influence of mortality and socioeconomic status on risk and delayed rewards: A life history theory approach. Journal of Personality and Social Psychology, 100(6), 1015\u201326.</p>\n<p>Kirby, K. N. (2009). One-year temporal stability of delay-discount rates. Psychonomic Bulletin &amp; Review, 16(3):457\u2013462.</p>\n<p>Koffarnus, M. N., &amp; Bickel, W. K. (2014). A 5-trial adjusting delay discounting task: Accurate discount rates in less than one minute. Experimental and Clinical Psychopharmacology, 22(3), 222-228.</p>\n\n          </div>"}, "last_serial": 5682790, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "5de25bf13f0249d8fb76da56ba18cb8e", "sha256": "56e07078b4aa2c14897b3808f921036c417e7f7cddf1bf296f4830f47cffa3cc"}, "downloads": -1, "filename": "darc_experiment_toolbox-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "5de25bf13f0249d8fb76da56ba18cb8e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 26701, "upload_time": "2019-08-15T15:36:27", "upload_time_iso_8601": "2019-08-15T15:36:27.273035Z", "url": "https://files.pythonhosted.org/packages/21/86/f959085a32620dfc00f0fdaf691a80f7db6ae1916b646af48841b423060a/darc_experiment_toolbox-0.0.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5de25bf13f0249d8fb76da56ba18cb8e", "sha256": "56e07078b4aa2c14897b3808f921036c417e7f7cddf1bf296f4830f47cffa3cc"}, "downloads": -1, "filename": "darc_experiment_toolbox-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "5de25bf13f0249d8fb76da56ba18cb8e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 26701, "upload_time": "2019-08-15T15:36:27", "upload_time_iso_8601": "2019-08-15T15:36:27.273035Z", "url": "https://files.pythonhosted.org/packages/21/86/f959085a32620dfc00f0fdaf691a80f7db6ae1916b646af48841b423060a/darc_experiment_toolbox-0.0.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:40:41 2020"}