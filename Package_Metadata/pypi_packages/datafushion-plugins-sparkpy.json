{"info": {"author": "\u8096\u6797\u670b", "author_email": "1553990434@qq.com", "bugtrack_url": null, "classifiers": [], "description": "# DataFushion_Plugins_SparkPy\u8bf4\u660e\n\n## 1.\u7b80\u4ecb\n\n\u9488\u5bf9Spark\u7684Python\u7248\u672c\u7b97\u6cd5(pyspark)\u5728DataFushion\u5e73\u53f0\u4f7f\u7528\u6240\u7ed9\u51fa\u7684\u63d2\u4ef6,\u4e3b\u8981\u7528\u4e8e\u89c4\u8303\u5316\u7b97\u6cd5\u7684\u8f93\u5165\u8f93\u51fa\n\n## 2.\u901a\u5e38\u7b97\u6cd5\u4f7f\u7528\n\n- [x] Step1:\u5f15\u5165datafushion_spark\u5305\u4e2d\u7684operation\u6a21\u5757\n- [x] Step2:\u4f7f\u7528\u8d44\u6e90\u7ba1\u7406\u5668\u8fdb\u884c\u6570\u636e\u62c6\u89e3\u5904\u7406,\u5e76\u5728\u5176\u4e2d\u5b9e\u73b0\u81ea\u5df1\u9700\u8981\u5b9e\u73b0\u7684\u4e1a\u52a1\u7b97\u6cd5\u903b\u8f91\n\n```python\nfrom datafushion_spark import operation, HandleDataFrameSet, HandleInputDataStruct, DataFrame, SparkSession, \\\n    FileExtractFormatEnum\n\n\nif __name__ == '__main__':\n    with operation(app_name=\"AvgWindPowerByStatus\", master=\"local\") as destruction:  # type:HandleDataFrameSet\n        input_data_struct_list = destruction.input_data_struct_list\n        mapping_flags = destruction.mapping_flags\n        param_map = destruction.param_map\n        spark = destruction.spark  # type:SparkSession\n\n        data_result = None  # type DataFrame\n\n        # \u7b97\u6cd5\u903b\u8f91\u90e8\u5206\n        for index, input_data_struct in enumerate(input_data_struct_list):  # type: HandleInputDataStruct\n            # \u6ce8\u610f:\u6b64\u65f6\u7684DataFrame\u7684\u5217\u540d\u5df2\u7ecf\u662f\u6620\u5c04\u8fc7\u7684\u5217\u540d,\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\n            data_list = input_data_struct.data_list  # type: DataFrame\n            data_list.show()\n            if index == 0:\n                data_result = data_list.groupby(\"status\").agg({\n                    \"power\": \"mean\"\n                }).withColumnRenamed(\"avg(power)\", \"powerAvg\")\n            else:\n                data_result = data_result.union(data_list.groupby(\"status\").agg({\n                    \"power\": \"mean\"\n                }).withColumnRenamed(\"avg(power)\", \"powerAvg\"))\n\n        # \u4fdd\u5b58\u6700\u7ec8\u7ed3\u679c\n        destruction.data_result = data_result\n        # \u4fdd\u5b58\u5b58\u50a8\u7684\u683c\u5f0f,\u9700\u8981\u4e0e\u6253\u5305\u7684\u914d\u7f6e\u6587\u4ef6\u5bf9\u5e94\n        destruction.output_type = FileExtractFormatEnum.JSON.value\n```\n\n\u6ce8\u610f:\n\n------\n\n\u5982\u679c\u662fWindows\u5f00\u53d1\u7684\u8bdd\u9700\u8981\u5728\u811a\u672c\u6587\u4ef6\u524d\u52a0\u5165\uff0cfindspark\u8bf7\u81ea\u884c\u4e0b\u8f7d\uff0c\u6ca1\u6709\u5728\u5305\u4e2d\u505a\u4f9d\u8d56\u7ba1\u7406\n\n```python\nimport findspark\n\n\nfindspark.init()\n```\n\n\n\n------\n\ndestruction\u4e3a\u89e3\u6784\u7684`HandleDataFrameSet`\u5b9e\u4f53\u7c7b\n\n------\n\ninput_data_struct_list\u4e2d\u5305\u542b\u4e86\u8f93\u5165\u6570\u636e\u7684\u5c01\u88c5,\u5176\u7c7b\u578b\u4e3aList\n\n\u5176\u5143\u7d20\u4e3a`HandleInputDataStruct`\u7c7b,\u5305\u542b\u7684\u5c5e\u6027\u4e3afile_type,file_path,file_input_mapping,data_list\n\n\u7b97\u6cd5\u9700\u8981\u4f7f\u7528\u7684\u662ffile_input_mapping\u548cdata_list\n\ndata_list\u662f\u8f93\u5165\u6570\u636e\u7684`DataFrame`\n\nfile_input_mapping\u4e3a\u8f93\u5165\u6570\u636e\u5b57\u6bb5\u7684\u6620\u5c04\n\nspark\u4e3asparkSession\u5bf9\u8c61\n\nmapping_flags\u4e3a\u6620\u5c04\u6807\u8bc6\u5b57\u5178\uff0ckey\u4e3a\u6bcf\u4e2a\u5355\u72ec\u8f93\u5165\u7684\u6620\u5c04\u6807\u8bc6\uff0ckey\u4e3a\u8f93\u5165\u6620\u5c04\n\n------\n\nparam_map\u4e3a\u7b97\u6cd5\u7684\u53c2\u6570\u5b57\u5178\n\n------\n\n\u5728\u5bf9\u6570\u636e\u8fdb\u884c\u4e1a\u52a1\u7b97\u6cd5\u5904\u7406\u5b8c\u6210\u540e,\u9700\u8981\u5c06\u62c6\u89e3\u7684destruction\u4e2d\u7684data_result\u5c5e\u6027\u8d4b\u503c\u4e3a\u4e1a\u52a1\u7b97\u6cd5\u7684\u6700\u7ec8\u6570\u636e\u7ed3\u679c\n\n------\n\n\u5728\u5bf9\u6570\u636e\u8fdb\u884c\u4e1a\u52a1\u7b97\u6cd5\u5904\u7406\u5b8c\u6210\u540e,\u9700\u8981\u5c06\u62c6\u89e3\u7684destruction\u4e2d\u7684output_type\u5c5e\u6027\u8d4b\u503c\u4e3a\u4e1a\u52a1\u7b97\u6cd5\u9700\u8981\u8f93\u51fa\u7684\u6587\u4ef6\u683c\u5f0f`FileExtractFormatEnum.JSON.value`\u4e2d\u63d0\u4f9b\u4e86`JSON,CSV,PARQUET,GENERAL`\u56db\u7c7b\u683c\u5f0f\n\n------\n\n\u76ee\u524d`PARQUET`\u7c7b\u7684\u8f93\u51fa\u683c\u5f0f\u53ea\u652f\u6301\u4f5c\u4e3aSpark\u7c7b\u578b\u7684\u7b97\u6cd5\u79ef\u6728\u4e2d\u7684\u8f93\u5165\n\n## 3.\u6a21\u578b\u8bad\u7ec3\u7b97\u6cd5\u4f7f\u7528\n\n- [x] Step1:\u5f15\u5165datafushion_spark\u5305\u4e2d\u7684operation\u6a21\u5757\n\n- [x] Step2:\u4f7f\u7528\u8d44\u6e90\u7ba1\u7406\u5668\u8fdb\u884c\u6570\u636e\u62c6\u89e3\u5904\u7406,\u5e76\u5728\u5176\u4e2d\u5b9e\u73b0\u81ea\u5df1\u9700\u8981\u5b9e\u73b0\u7684\u4e1a\u52a1\u7b97\u6cd5\u903b\u8f91\n\n  ***\u6b64\u5904\u4ee5\u9e22\u5c3e\u82b1\u8bad\u7ec3\u4e3a\u4f8b\u8fdb\u884c\u903b\u8f91\u56de\u5f52\u6a21\u578b\u8bad\u7ec3***\n\n  ```python\n  from datafushion_spark import operation, HandleDataFrameSet, HandleInputDataStruct, DataFrame, SparkSession, \\\n      FileExtractFormatEnum, TrainFiledEnum, TrainModelResult\n  from pyspark.ml.feature import VectorAssembler\n  from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n  from pyspark.ml import Pipeline, PipelineModel\n\n\n  if __name__ == '__main__':\n      with operation(app_name=\"IrisClassify\", mapping_data=False,\n                     master=\"local\") as destruction:  # type:HandleDataFrameSet\n          input_data_struct_list = destruction.input_data_struct_list\n          mapping_flags = destruction.mapping_flags  # type: dict\n          param_map = destruction.param_map\n          spark = destruction.spark  # type:SparkSession\n\n          algo_iter = param_map['iter']\n          algo_reg = param_map['reg']\n          algo_elastic_net = param_map['elasticNet']\n          mapping_list = []\n          for k, v in mapping_flags.items():\n              mapping_list.append(v)\n          data_result = None\n\n          # \u7b97\u6cd5\u903b\u8f91\u90e8\u5206\n          for index, input_data_struct in enumerate(input_data_struct_list):  # type: HandleInputDataStruct\n              # \u6ce8\u610f:\u6b64\u65f6\u7684DataFrame\u7684\u5217\u540d\u5df2\u7ecf\u662f\u6620\u5c04\u8fc7\u7684\u5217\u540d,\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\n              data = input_data_struct.data_list  # type: DataFrame\n              mapping = mapping_list[index]\n              feature_fields = mapping[TrainFiledEnum.FEATURE.value]\n              label_field = mapping[TrainFiledEnum.LABEL.value][0]\n              train_data = data.withColumnRenamed(label_field, TrainFiledEnum.LABEL.value)\n              featureAssembler = VectorAssembler().setInputCols(feature_fields).setOutputCol('features')\n              logistic_regression = LogisticRegression().setMaxIter(algo_iter).setRegParam(algo_reg).setElasticNetParam(\n                      algo_elastic_net)\n              pipeline_model: PipelineModel = Pipeline().setStages([featureAssembler, logistic_regression]).fit(\n                      train_data)\n              # \u5c06data_result\u5b9e\u4f8b\u5316\u4e3a\u4e00\u4e2aTrainModelResult\u5bf9\u8c61\n              data_result = TrainModelResult(train_data=train_data, pipeline_model=pipeline_model)\n              lg_model: LogisticRegressionModel = pipeline_model.stages[1]\n              for item in lg_model.summary.objectiveHistory:\n                  print(item)\n\n              # \u4fdd\u5b58\u6700\u7ec8\u7ed3\u679c\n          destruction.data_result = data_result\n          # \u4fdd\u5b58\u5b58\u50a8\u7684\u683c\u5f0f,\u9700\u8981\u4e0e\u6253\u5305\u7684\u914d\u7f6e\u6587\u4ef6\u5bf9\u5e94\n          destruction.output_type = FileExtractFormatEnum.MODEL.value\n  ```\n\n  \u6ce8\u610f:\n\n  ------\n\n  \u5982\u679c\u9700\u8981\u8bad\u7ec3\u6a21\u578b\u7684\u8bdd\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\n\n  1.\u5c06operation\u4e2d\u8bbe\u7f6e\u4e3amapping_data=False,\u56e0\u4e3a\u4e00\u822c\u6211\u4eec\u9700\u8981\u81ea\u5df1\u6839\u636e\u6807\u8bc6\u6765\u786e\u5b9a\u600e\u6837\u5904\u7406\u7279\u5f81\u6570\u636e\n\n  2.\u5c06data_result\u9700\u8981\u8bbe\u7f6e\u4e3aTrainModelResult\u5b9e\u4f8b\uff0c\u5176\u4e2dTrainModelResult\u5305\u62ec\u7684\u6570\u636e\u6709train_data\u548cpipeline_model\uff0c\u5373\u8bad\u7ec3\u6570\u636e\u548c\u7ba1\u9053\u6a21\u578b\n\n  3.\u6700\u540e\u9700\u8981\u8bbe\u7f6e\u89e3\u6784\u56de\u8c03\u5bf9\u8c61\u7684output_type\u4e3amodel\u683c\u5f0f`destruction.output_type = FileExtractFormatEnum.MODEL.value`\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "XiaoLinpeng Licence", "maintainer": "", "maintainer_email": "", "name": "datafushion-plugins-sparkpy", "package_url": "https://pypi.org/project/datafushion-plugins-sparkpy/", "platform": "any", "project_url": "https://pypi.org/project/datafushion-plugins-sparkpy/", "project_urls": null, "release_url": "https://pypi.org/project/datafushion-plugins-sparkpy/1.0.7/", "requires_dist": ["datafushion-plugins-python", "pyspark2pmml"], "requires_python": "", "summary": "DataFushion\u7684SparkPy\u7b97\u6cd5\u63d2\u4ef6", "version": "1.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DataFushion_Plugins_SparkPy\u8bf4\u660e</h1>\n<h2>1.\u7b80\u4ecb</h2>\n<p>\u9488\u5bf9Spark\u7684Python\u7248\u672c\u7b97\u6cd5(pyspark)\u5728DataFushion\u5e73\u53f0\u4f7f\u7528\u6240\u7ed9\u51fa\u7684\u63d2\u4ef6,\u4e3b\u8981\u7528\u4e8e\u89c4\u8303\u5316\u7b97\u6cd5\u7684\u8f93\u5165\u8f93\u51fa</p>\n<h2>2.\u901a\u5e38\u7b97\u6cd5\u4f7f\u7528</h2>\n<ul>\n<li>[x] Step1:\u5f15\u5165datafushion_spark\u5305\u4e2d\u7684operation\u6a21\u5757</li>\n<li>[x] Step2:\u4f7f\u7528\u8d44\u6e90\u7ba1\u7406\u5668\u8fdb\u884c\u6570\u636e\u62c6\u89e3\u5904\u7406,\u5e76\u5728\u5176\u4e2d\u5b9e\u73b0\u81ea\u5df1\u9700\u8981\u5b9e\u73b0\u7684\u4e1a\u52a1\u7b97\u6cd5\u903b\u8f91</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">datafushion_spark</span> <span class=\"kn\">import</span> <span class=\"n\">operation</span><span class=\"p\">,</span> <span class=\"n\">HandleDataFrameSet</span><span class=\"p\">,</span> <span class=\"n\">HandleInputDataStruct</span><span class=\"p\">,</span> <span class=\"n\">DataFrame</span><span class=\"p\">,</span> <span class=\"n\">SparkSession</span><span class=\"p\">,</span> \\\n    <span class=\"n\">FileExtractFormatEnum</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"k\">with</span> <span class=\"n\">operation</span><span class=\"p\">(</span><span class=\"n\">app_name</span><span class=\"o\">=</span><span class=\"s2\">\"AvgWindPowerByStatus\"</span><span class=\"p\">,</span> <span class=\"n\">master</span><span class=\"o\">=</span><span class=\"s2\">\"local\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">destruction</span><span class=\"p\">:</span>  <span class=\"c1\"># type:HandleDataFrameSet</span>\n        <span class=\"n\">input_data_struct_list</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">input_data_struct_list</span>\n        <span class=\"n\">mapping_flags</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">mapping_flags</span>\n        <span class=\"n\">param_map</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">param_map</span>\n        <span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">spark</span>  <span class=\"c1\"># type:SparkSession</span>\n\n        <span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>  <span class=\"c1\"># type DataFrame</span>\n\n        <span class=\"c1\"># \u7b97\u6cd5\u903b\u8f91\u90e8\u5206</span>\n        <span class=\"k\">for</span> <span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">input_data_struct</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">input_data_struct_list</span><span class=\"p\">):</span>  <span class=\"c1\"># type: HandleInputDataStruct</span>\n            <span class=\"c1\"># \u6ce8\u610f:\u6b64\u65f6\u7684DataFrame\u7684\u5217\u540d\u5df2\u7ecf\u662f\u6620\u5c04\u8fc7\u7684\u5217\u540d,\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528</span>\n            <span class=\"n\">data_list</span> <span class=\"o\">=</span> <span class=\"n\">input_data_struct</span><span class=\"o\">.</span><span class=\"n\">data_list</span>  <span class=\"c1\"># type: DataFrame</span>\n            <span class=\"n\">data_list</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n            <span class=\"k\">if</span> <span class=\"n\">index</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n                <span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"n\">data_list</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s2\">\"status\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">agg</span><span class=\"p\">({</span>\n                    <span class=\"s2\">\"power\"</span><span class=\"p\">:</span> <span class=\"s2\">\"mean\"</span>\n                <span class=\"p\">})</span><span class=\"o\">.</span><span class=\"n\">withColumnRenamed</span><span class=\"p\">(</span><span class=\"s2\">\"avg(power)\"</span><span class=\"p\">,</span> <span class=\"s2\">\"powerAvg\"</span><span class=\"p\">)</span>\n            <span class=\"k\">else</span><span class=\"p\">:</span>\n                <span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"n\">data_result</span><span class=\"o\">.</span><span class=\"n\">union</span><span class=\"p\">(</span><span class=\"n\">data_list</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s2\">\"status\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">agg</span><span class=\"p\">({</span>\n                    <span class=\"s2\">\"power\"</span><span class=\"p\">:</span> <span class=\"s2\">\"mean\"</span>\n                <span class=\"p\">})</span><span class=\"o\">.</span><span class=\"n\">withColumnRenamed</span><span class=\"p\">(</span><span class=\"s2\">\"avg(power)\"</span><span class=\"p\">,</span> <span class=\"s2\">\"powerAvg\"</span><span class=\"p\">))</span>\n\n        <span class=\"c1\"># \u4fdd\u5b58\u6700\u7ec8\u7ed3\u679c</span>\n        <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"n\">data_result</span>\n        <span class=\"c1\"># \u4fdd\u5b58\u5b58\u50a8\u7684\u683c\u5f0f,\u9700\u8981\u4e0e\u6253\u5305\u7684\u914d\u7f6e\u6587\u4ef6\u5bf9\u5e94</span>\n        <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">output_type</span> <span class=\"o\">=</span> <span class=\"n\">FileExtractFormatEnum</span><span class=\"o\">.</span><span class=\"n\">JSON</span><span class=\"o\">.</span><span class=\"n\">value</span>\n</pre>\n<p>\u6ce8\u610f:</p>\n<hr>\n<p>\u5982\u679c\u662fWindows\u5f00\u53d1\u7684\u8bdd\u9700\u8981\u5728\u811a\u672c\u6587\u4ef6\u524d\u52a0\u5165\uff0cfindspark\u8bf7\u81ea\u884c\u4e0b\u8f7d\uff0c\u6ca1\u6709\u5728\u5305\u4e2d\u505a\u4f9d\u8d56\u7ba1\u7406</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">findspark</span>\n\n\n<span class=\"n\">findspark</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">()</span>\n</pre>\n<hr>\n<p>destruction\u4e3a\u89e3\u6784\u7684<code>HandleDataFrameSet</code>\u5b9e\u4f53\u7c7b</p>\n<hr>\n<p>input_data_struct_list\u4e2d\u5305\u542b\u4e86\u8f93\u5165\u6570\u636e\u7684\u5c01\u88c5,\u5176\u7c7b\u578b\u4e3aList</p>\n<p>\u5176\u5143\u7d20\u4e3a<code>HandleInputDataStruct</code>\u7c7b,\u5305\u542b\u7684\u5c5e\u6027\u4e3afile_type,file_path,file_input_mapping,data_list</p>\n<p>\u7b97\u6cd5\u9700\u8981\u4f7f\u7528\u7684\u662ffile_input_mapping\u548cdata_list</p>\n<p>data_list\u662f\u8f93\u5165\u6570\u636e\u7684<code>DataFrame</code></p>\n<p>file_input_mapping\u4e3a\u8f93\u5165\u6570\u636e\u5b57\u6bb5\u7684\u6620\u5c04</p>\n<p>spark\u4e3asparkSession\u5bf9\u8c61</p>\n<p>mapping_flags\u4e3a\u6620\u5c04\u6807\u8bc6\u5b57\u5178\uff0ckey\u4e3a\u6bcf\u4e2a\u5355\u72ec\u8f93\u5165\u7684\u6620\u5c04\u6807\u8bc6\uff0ckey\u4e3a\u8f93\u5165\u6620\u5c04</p>\n<hr>\n<p>param_map\u4e3a\u7b97\u6cd5\u7684\u53c2\u6570\u5b57\u5178</p>\n<hr>\n<p>\u5728\u5bf9\u6570\u636e\u8fdb\u884c\u4e1a\u52a1\u7b97\u6cd5\u5904\u7406\u5b8c\u6210\u540e,\u9700\u8981\u5c06\u62c6\u89e3\u7684destruction\u4e2d\u7684data_result\u5c5e\u6027\u8d4b\u503c\u4e3a\u4e1a\u52a1\u7b97\u6cd5\u7684\u6700\u7ec8\u6570\u636e\u7ed3\u679c</p>\n<hr>\n<p>\u5728\u5bf9\u6570\u636e\u8fdb\u884c\u4e1a\u52a1\u7b97\u6cd5\u5904\u7406\u5b8c\u6210\u540e,\u9700\u8981\u5c06\u62c6\u89e3\u7684destruction\u4e2d\u7684output_type\u5c5e\u6027\u8d4b\u503c\u4e3a\u4e1a\u52a1\u7b97\u6cd5\u9700\u8981\u8f93\u51fa\u7684\u6587\u4ef6\u683c\u5f0f<code>FileExtractFormatEnum.JSON.value</code>\u4e2d\u63d0\u4f9b\u4e86<code>JSON,CSV,PARQUET,GENERAL</code>\u56db\u7c7b\u683c\u5f0f</p>\n<hr>\n<p>\u76ee\u524d<code>PARQUET</code>\u7c7b\u7684\u8f93\u51fa\u683c\u5f0f\u53ea\u652f\u6301\u4f5c\u4e3aSpark\u7c7b\u578b\u7684\u7b97\u6cd5\u79ef\u6728\u4e2d\u7684\u8f93\u5165</p>\n<h2>3.\u6a21\u578b\u8bad\u7ec3\u7b97\u6cd5\u4f7f\u7528</h2>\n<ul>\n<li>\n<p>[x] Step1:\u5f15\u5165datafushion_spark\u5305\u4e2d\u7684operation\u6a21\u5757</p>\n</li>\n<li>\n<p>[x] Step2:\u4f7f\u7528\u8d44\u6e90\u7ba1\u7406\u5668\u8fdb\u884c\u6570\u636e\u62c6\u89e3\u5904\u7406,\u5e76\u5728\u5176\u4e2d\u5b9e\u73b0\u81ea\u5df1\u9700\u8981\u5b9e\u73b0\u7684\u4e1a\u52a1\u7b97\u6cd5\u903b\u8f91</p>\n<p><em><strong>\u6b64\u5904\u4ee5\u9e22\u5c3e\u82b1\u8bad\u7ec3\u4e3a\u4f8b\u8fdb\u884c\u903b\u8f91\u56de\u5f52\u6a21\u578b\u8bad\u7ec3</strong></em></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">datafushion_spark</span> <span class=\"kn\">import</span> <span class=\"n\">operation</span><span class=\"p\">,</span> <span class=\"n\">HandleDataFrameSet</span><span class=\"p\">,</span> <span class=\"n\">HandleInputDataStruct</span><span class=\"p\">,</span> <span class=\"n\">DataFrame</span><span class=\"p\">,</span> <span class=\"n\">SparkSession</span><span class=\"p\">,</span> \\\n    <span class=\"n\">FileExtractFormatEnum</span><span class=\"p\">,</span> <span class=\"n\">TrainFiledEnum</span><span class=\"p\">,</span> <span class=\"n\">TrainModelResult</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.ml.feature</span> <span class=\"kn\">import</span> <span class=\"n\">VectorAssembler</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.ml.classification</span> <span class=\"kn\">import</span> <span class=\"n\">LogisticRegression</span><span class=\"p\">,</span> <span class=\"n\">LogisticRegressionModel</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.ml</span> <span class=\"kn\">import</span> <span class=\"n\">Pipeline</span><span class=\"p\">,</span> <span class=\"n\">PipelineModel</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"k\">with</span> <span class=\"n\">operation</span><span class=\"p\">(</span><span class=\"n\">app_name</span><span class=\"o\">=</span><span class=\"s2\">\"IrisClassify\"</span><span class=\"p\">,</span> <span class=\"n\">mapping_data</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n                   <span class=\"n\">master</span><span class=\"o\">=</span><span class=\"s2\">\"local\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">destruction</span><span class=\"p\">:</span>  <span class=\"c1\"># type:HandleDataFrameSet</span>\n        <span class=\"n\">input_data_struct_list</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">input_data_struct_list</span>\n        <span class=\"n\">mapping_flags</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">mapping_flags</span>  <span class=\"c1\"># type: dict</span>\n        <span class=\"n\">param_map</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">param_map</span>\n        <span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">spark</span>  <span class=\"c1\"># type:SparkSession</span>\n\n        <span class=\"n\">algo_iter</span> <span class=\"o\">=</span> <span class=\"n\">param_map</span><span class=\"p\">[</span><span class=\"s1\">'iter'</span><span class=\"p\">]</span>\n        <span class=\"n\">algo_reg</span> <span class=\"o\">=</span> <span class=\"n\">param_map</span><span class=\"p\">[</span><span class=\"s1\">'reg'</span><span class=\"p\">]</span>\n        <span class=\"n\">algo_elastic_net</span> <span class=\"o\">=</span> <span class=\"n\">param_map</span><span class=\"p\">[</span><span class=\"s1\">'elasticNet'</span><span class=\"p\">]</span>\n        <span class=\"n\">mapping_list</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"ow\">in</span> <span class=\"n\">mapping_flags</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">():</span>\n            <span class=\"n\">mapping_list</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">v</span><span class=\"p\">)</span>\n        <span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n\n        <span class=\"c1\"># \u7b97\u6cd5\u903b\u8f91\u90e8\u5206</span>\n        <span class=\"k\">for</span> <span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">input_data_struct</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">input_data_struct_list</span><span class=\"p\">):</span>  <span class=\"c1\"># type: HandleInputDataStruct</span>\n            <span class=\"c1\"># \u6ce8\u610f:\u6b64\u65f6\u7684DataFrame\u7684\u5217\u540d\u5df2\u7ecf\u662f\u6620\u5c04\u8fc7\u7684\u5217\u540d,\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528</span>\n            <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">input_data_struct</span><span class=\"o\">.</span><span class=\"n\">data_list</span>  <span class=\"c1\"># type: DataFrame</span>\n            <span class=\"n\">mapping</span> <span class=\"o\">=</span> <span class=\"n\">mapping_list</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">]</span>\n            <span class=\"n\">feature_fields</span> <span class=\"o\">=</span> <span class=\"n\">mapping</span><span class=\"p\">[</span><span class=\"n\">TrainFiledEnum</span><span class=\"o\">.</span><span class=\"n\">FEATURE</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">]</span>\n            <span class=\"n\">label_field</span> <span class=\"o\">=</span> <span class=\"n\">mapping</span><span class=\"p\">[</span><span class=\"n\">TrainFiledEnum</span><span class=\"o\">.</span><span class=\"n\">LABEL</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n            <span class=\"n\">train_data</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">withColumnRenamed</span><span class=\"p\">(</span><span class=\"n\">label_field</span><span class=\"p\">,</span> <span class=\"n\">TrainFiledEnum</span><span class=\"o\">.</span><span class=\"n\">LABEL</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">)</span>\n            <span class=\"n\">featureAssembler</span> <span class=\"o\">=</span> <span class=\"n\">VectorAssembler</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">setInputCols</span><span class=\"p\">(</span><span class=\"n\">feature_fields</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">setOutputCol</span><span class=\"p\">(</span><span class=\"s1\">'features'</span><span class=\"p\">)</span>\n            <span class=\"n\">logistic_regression</span> <span class=\"o\">=</span> <span class=\"n\">LogisticRegression</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">setMaxIter</span><span class=\"p\">(</span><span class=\"n\">algo_iter</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">setRegParam</span><span class=\"p\">(</span><span class=\"n\">algo_reg</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">setElasticNetParam</span><span class=\"p\">(</span>\n                    <span class=\"n\">algo_elastic_net</span><span class=\"p\">)</span>\n            <span class=\"n\">pipeline_model</span><span class=\"p\">:</span> <span class=\"n\">PipelineModel</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">setStages</span><span class=\"p\">([</span><span class=\"n\">featureAssembler</span><span class=\"p\">,</span> <span class=\"n\">logistic_regression</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span>\n                    <span class=\"n\">train_data</span><span class=\"p\">)</span>\n            <span class=\"c1\"># \u5c06data_result\u5b9e\u4f8b\u5316\u4e3a\u4e00\u4e2aTrainModelResult\u5bf9\u8c61</span>\n            <span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"n\">TrainModelResult</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"o\">=</span><span class=\"n\">train_data</span><span class=\"p\">,</span> <span class=\"n\">pipeline_model</span><span class=\"o\">=</span><span class=\"n\">pipeline_model</span><span class=\"p\">)</span>\n            <span class=\"n\">lg_model</span><span class=\"p\">:</span> <span class=\"n\">LogisticRegressionModel</span> <span class=\"o\">=</span> <span class=\"n\">pipeline_model</span><span class=\"o\">.</span><span class=\"n\">stages</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n            <span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">lg_model</span><span class=\"o\">.</span><span class=\"n\">summary</span><span class=\"o\">.</span><span class=\"n\">objectiveHistory</span><span class=\"p\">:</span>\n                <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n\n            <span class=\"c1\"># \u4fdd\u5b58\u6700\u7ec8\u7ed3\u679c</span>\n        <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">data_result</span> <span class=\"o\">=</span> <span class=\"n\">data_result</span>\n        <span class=\"c1\"># \u4fdd\u5b58\u5b58\u50a8\u7684\u683c\u5f0f,\u9700\u8981\u4e0e\u6253\u5305\u7684\u914d\u7f6e\u6587\u4ef6\u5bf9\u5e94</span>\n        <span class=\"n\">destruction</span><span class=\"o\">.</span><span class=\"n\">output_type</span> <span class=\"o\">=</span> <span class=\"n\">FileExtractFormatEnum</span><span class=\"o\">.</span><span class=\"n\">MODEL</span><span class=\"o\">.</span><span class=\"n\">value</span>\n</pre>\n<p>\u6ce8\u610f:</p>\n<hr>\n<p>\u5982\u679c\u9700\u8981\u8bad\u7ec3\u6a21\u578b\u7684\u8bdd\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b</p>\n<p>1.\u5c06operation\u4e2d\u8bbe\u7f6e\u4e3amapping_data=False,\u56e0\u4e3a\u4e00\u822c\u6211\u4eec\u9700\u8981\u81ea\u5df1\u6839\u636e\u6807\u8bc6\u6765\u786e\u5b9a\u600e\u6837\u5904\u7406\u7279\u5f81\u6570\u636e</p>\n<p>2.\u5c06data_result\u9700\u8981\u8bbe\u7f6e\u4e3aTrainModelResult\u5b9e\u4f8b\uff0c\u5176\u4e2dTrainModelResult\u5305\u62ec\u7684\u6570\u636e\u6709train_data\u548cpipeline_model\uff0c\u5373\u8bad\u7ec3\u6570\u636e\u548c\u7ba1\u9053\u6a21\u578b</p>\n<p>3.\u6700\u540e\u9700\u8981\u8bbe\u7f6e\u89e3\u6784\u56de\u8c03\u5bf9\u8c61\u7684output_type\u4e3amodel\u683c\u5f0f<code>destruction.output_type = FileExtractFormatEnum.MODEL.value</code></p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 7083102, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "67bae31bcece97e7081960216d021963", "sha256": "be4a21164fe973a876609e12de92470fb2ef227df4437744298bdb1b4759b9ab"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "67bae31bcece97e7081960216d021963", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7234, "upload_time": "2020-04-12T04:00:26", "upload_time_iso_8601": "2020-04-12T04:00:26.603044Z", "url": "https://files.pythonhosted.org/packages/aa/b3/3c92f7c58a3aa55a3479db41ce26030a1afebb00a582e0cc9928fb2895ee/datafushion_plugins_sparkpy-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6204dd8107f89532f93bfe5f718c17e7", "sha256": "3657ecc7eb0c385c185f509a9c86fbcfc64a60763908e5a28402986cc3f1ed90"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.0.tar.gz", "has_sig": false, "md5_digest": "6204dd8107f89532f93bfe5f718c17e7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4490, "upload_time": "2020-04-12T04:00:29", "upload_time_iso_8601": "2020-04-12T04:00:29.280646Z", "url": "https://files.pythonhosted.org/packages/4d/49/434df1769c01c2cbefd9e320215be8c070f6176b3ab537eab217c11a0ca3/datafushion_plugins_sparkpy-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "51940176016d6111cbc95a5463889061", "sha256": "4fba11ee483bb0b61dcc321546fb4b5c588de055d719f415650860ce954846db"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "51940176016d6111cbc95a5463889061", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7229, "upload_time": "2020-04-12T04:19:10", "upload_time_iso_8601": "2020-04-12T04:19:10.554725Z", "url": "https://files.pythonhosted.org/packages/5b/58/a97be553395f3760fec104ee034ea2ed105a917434400b73682561c19034/datafushion_plugins_sparkpy-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "722fa23fdcd48cf3fa442df8bb3219bc", "sha256": "ce8f4d19204d0fe7621af6086e6606ce442389ae78dc3b74785a0fcb18b54b6e"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.1.tar.gz", "has_sig": false, "md5_digest": "722fa23fdcd48cf3fa442df8bb3219bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4474, "upload_time": "2020-04-12T04:19:11", "upload_time_iso_8601": "2020-04-12T04:19:11.997538Z", "url": "https://files.pythonhosted.org/packages/8a/ff/a5419a99e65c0bfba436cb80d5a008ac636d4b405544cee76250c203bff9/datafushion_plugins_sparkpy-1.0.1.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "f6d437633832f43cee4ef7dd9699d58a", "sha256": "5b79f56a8fd68bd563b10a2557ed08b7f25f518a55d9b70ec26eccd685c51a36"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "f6d437633832f43cee4ef7dd9699d58a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7250, "upload_time": "2020-04-12T10:41:43", "upload_time_iso_8601": "2020-04-12T10:41:43.823565Z", "url": "https://files.pythonhosted.org/packages/a8/ea/a36d1076d1b7bb17e3c615acf52fabff2058680aa842518ccaf5714d2163/datafushion_plugins_sparkpy-1.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a50642583e6e792dbe85f4b998370a3c", "sha256": "926c89c8fd4c9985b4311848d516163e03a2c7cac847b3b1ba08a1d1e304a64e"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.3.tar.gz", "has_sig": false, "md5_digest": "a50642583e6e792dbe85f4b998370a3c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4476, "upload_time": "2020-04-12T10:41:45", "upload_time_iso_8601": "2020-04-12T10:41:45.530766Z", "url": "https://files.pythonhosted.org/packages/dc/a0/4bec173e46273fec2d0679a5b75034f173fa7d7fb29f28752fdf8e66fdaf/datafushion_plugins_sparkpy-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "87f603d1c7bdc019247500bec9a3ed3a", "sha256": "aacd9de60b9c7c0cf25a7810469337abb758df9c4b83fc46926b493ddb6f04b9"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "87f603d1c7bdc019247500bec9a3ed3a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7311, "upload_time": "2020-04-13T02:55:14", "upload_time_iso_8601": "2020-04-13T02:55:14.259701Z", "url": "https://files.pythonhosted.org/packages/cc/d1/ec31e3732f218c12bce7eee2f4f13a2db00e0286cff4a0ecf9382a20a505/datafushion_plugins_sparkpy-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fdc9e95d358dbfa2b3879b862f491326", "sha256": "f402aa4c8c10a1842944ccc6b005822795ee6a9bf0ba016d6735223c00584fd3"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.4.tar.gz", "has_sig": false, "md5_digest": "fdc9e95d358dbfa2b3879b862f491326", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4548, "upload_time": "2020-04-13T02:55:16", "upload_time_iso_8601": "2020-04-13T02:55:16.005882Z", "url": "https://files.pythonhosted.org/packages/3e/6e/b53e914634bc896da21b7b9526e0cd403f2540277422318f6c27fb33195a/datafushion_plugins_sparkpy-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "8e0a413674f1f703598cdb670a47b299", "sha256": "2441d97395163394cb24556eeb4613d2a348756517eea62c96fdc1fd6501899a"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "8e0a413674f1f703598cdb670a47b299", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7307, "upload_time": "2020-04-13T03:09:17", "upload_time_iso_8601": "2020-04-13T03:09:17.929088Z", "url": "https://files.pythonhosted.org/packages/9f/e7/20b860695ca14b70e46be9797a973ef6f6b0ce7fcfd4c1eb611680c5f4cd/datafushion_plugins_sparkpy-1.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "429ee69534b21526285f7a97a7d36d4f", "sha256": "51066d800b585c8e83541ca1c12f1eccf5cfef9c9747913c0a282e60595cd0c0"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.5.tar.gz", "has_sig": false, "md5_digest": "429ee69534b21526285f7a97a7d36d4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4543, "upload_time": "2020-04-13T03:09:21", "upload_time_iso_8601": "2020-04-13T03:09:21.400783Z", "url": "https://files.pythonhosted.org/packages/4a/38/b9f71784c2fa5267a65197e33c7806d7d1e80738dff837e0ada7fd6481d0/datafushion_plugins_sparkpy-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "c413ce9c418d9e6c36c84c8dc140fd4f", "sha256": "d8c3d6ae04d3c4accbdef212ba3d7ea03a65c08ebe13dc168f768ce9f3f2bb84"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "c413ce9c418d9e6c36c84c8dc140fd4f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7357, "upload_time": "2020-04-19T15:40:22", "upload_time_iso_8601": "2020-04-19T15:40:22.140377Z", "url": "https://files.pythonhosted.org/packages/9c/52/ff98aaddf8e1d9186d2671291c5ab7d28acd9066235667f2db786fe6ff2b/datafushion_plugins_sparkpy-1.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e5a32a7fb228dfaeff727ffb65fc0587", "sha256": "9d68be8c42ce9da06ec8b162e772e527db23f5f4a4a69dd1999c392225d2194c"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.6.tar.gz", "has_sig": false, "md5_digest": "e5a32a7fb228dfaeff727ffb65fc0587", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4589, "upload_time": "2020-04-19T15:40:32", "upload_time_iso_8601": "2020-04-19T15:40:32.377848Z", "url": "https://files.pythonhosted.org/packages/04/a2/0be7e2bcd8398c351a9fc86ea5774a168cc7d481c8ca77010e03e7fb9dbe/datafushion_plugins_sparkpy-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "d3d2a6d835e957f9acd29bba52040b95", "sha256": "6f43b9f3436017f9be8979d54182b01b0844fe2456074600b453591906f15dc7"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "d3d2a6d835e957f9acd29bba52040b95", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9920, "upload_time": "2020-04-23T09:32:17", "upload_time_iso_8601": "2020-04-23T09:32:17.004403Z", "url": "https://files.pythonhosted.org/packages/ea/65/f2e185bc550e3963936ee04618730ce039efff7bff23dc09e6c1bd20434c/datafushion_plugins_sparkpy-1.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0034d2f20909757be5d4a78c185837c0", "sha256": "568db029821b0956b6187127098096c54154de13f2085305365dc2282322b885"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.7.tar.gz", "has_sig": false, "md5_digest": "0034d2f20909757be5d4a78c185837c0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6282, "upload_time": "2020-04-23T09:32:18", "upload_time_iso_8601": "2020-04-23T09:32:18.428008Z", "url": "https://files.pythonhosted.org/packages/87/23/f15fd6a729dbf61acb1b77d6e27d182ad3f312d86d67c5a20656dac31d24/datafushion_plugins_sparkpy-1.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d3d2a6d835e957f9acd29bba52040b95", "sha256": "6f43b9f3436017f9be8979d54182b01b0844fe2456074600b453591906f15dc7"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "d3d2a6d835e957f9acd29bba52040b95", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9920, "upload_time": "2020-04-23T09:32:17", "upload_time_iso_8601": "2020-04-23T09:32:17.004403Z", "url": "https://files.pythonhosted.org/packages/ea/65/f2e185bc550e3963936ee04618730ce039efff7bff23dc09e6c1bd20434c/datafushion_plugins_sparkpy-1.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0034d2f20909757be5d4a78c185837c0", "sha256": "568db029821b0956b6187127098096c54154de13f2085305365dc2282322b885"}, "downloads": -1, "filename": "datafushion_plugins_sparkpy-1.0.7.tar.gz", "has_sig": false, "md5_digest": "0034d2f20909757be5d4a78c185837c0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6282, "upload_time": "2020-04-23T09:32:18", "upload_time_iso_8601": "2020-04-23T09:32:18.428008Z", "url": "https://files.pythonhosted.org/packages/87/23/f15fd6a729dbf61acb1b77d6e27d182ad3f312d86d67c5a20656dac31d24/datafushion_plugins_sparkpy-1.0.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:23 2020"}