{"info": {"author": "Jonathan Dunn", "author_email": "jdunn8@iit.edu", "bugtrack_url": null, "classifiers": [], "description": "\nc2xg 0.2\n=============\n\nComputational Construction Grammar, or c2xg, is two things: \n\n(1) A Python package for the unsupervised learning of CxG representations along with tools for vectorizing these representations for computational tasks\n\n(2) A discovery-device grammar that learns falsifiable and replicable CxGs from observed unannotated text data\n\nWhy CxGs? Constructions are grammatical entities that allow the straight-forward quantification of linguistic structure.\n\n\nInstallation\n--------------\n\n\t\tpip install c2xg\n\nor\n\n\t\tpip install <whl file>\n\n\nEnvironment and Dependencies\n----------------------------------\n\nThis package is meant to run in Python 3.5 with a number of dependencies. The easiest way to maintain the necessary environment is to use Anaconda Python: https://www.continuum.io/downloads\n\nThis makes it easier to maintain the necessary environment. The package works with the dependency versions listed below. It will likely work with older versions of some packages but has not been tested with them. For example, older versions of numexpr have been known to cause issues withs pandas and may lead to lost candidates.\n\nDependencies:\n\n\tPython 3.5\n\tcytoolz 0.7.4\n\tgensim 0.12.2\n\tmatplotlib 1.5.0\n\tnumexpr 2.5\n\tnumpy 1.10.4\n\tpandas 0.18.0\n\tscipy 0.16.0\n\tsklearn 0.17\n\nUsage\n=====\nC2xG has two main classes:\n\n\tc2xg.Parameters loads and initializes the settings needed for running C2xG; these values are set in a file\n\n\tc2xg.Grammar contains the grammar resources used across all stages of the package\n\nInitialize the package with the following commands:\n\n\timport c2xg\n\tParameters = c2xg.Parameters(\"filename\")\n\nThe parameters class takes as input a string indicating the name of the parameters file. Now, run the API using the following template, where Parameters is an initialized c2xg.Parameter object:\n\n\tc2xg.learn_c2xg(Parameters)\n\tc2xg.learn_idioms(Parameters)\n\nAll functions in the API take a c2xg.Parameters object as an argument. The c2xg.Grammar object can be passed to each function or, if not passed, loaded from file.\n\nAPI\n====\n\nEach function in the API takes a Parameters object and either creates the Grammar object or loads it from the file specified in the parameters.\n\nAutomate Pipeline\n------------------\n\nlearn_c2xg\t\t\t\n\n\t\tUmbrella function for entire learning pipeline (from learn_mwes to learn_constructions).\n\nIndividual Learning Functions\n------------------------------\n\nlearn_dictionary\t\t\n\n\t\tUse GenSim to create the dictionary of semantic representations needed for c2xg.\n\nlearn_rdrpos_model\t\t\n\n\t\tUse RDRPOS Tagger Dependency to learn a new pos-tagging model.\n\nlearn_idioms\t\t\t\t\n\n\t\tUse c2xg to learn a dictionary of idioms (lexical constructions).\n\nlearn_constituents\t \t\n\n\t\tUse c2xg to learn a constituency grammar.\n\nlearn_constructions \t\n\n\t\tUse c2xg to learn a full Construction Grammar with lexical, MWE, semantic, and constituent representations.\n\nlearn_usage\t\t\t\t\n\n\t\tPrepare to use TF-IDF weighting during feature extraction.\n\nlearn_association\n\n\t\tProduce a CSV file of association measures for sequences of a given length and types of representation\n\nHelper Functions\n-----------------\n\nannotate_pos\t\t\t\n\n\t\tTokenize, pos-tag, mark emojis, and convert to CoNLL format.\n\nget_indexes\t\t\t\t\n\n\t\tGet indexes of representation types.\n\nget_candidates\t\t\t\n\n\t\tGetcandidate sequences from input files (covers MWEs, Constituents, and Constructions).\n\nget_association\t\t\t\n\n\t\tGet vector of association values for each candidate.\n\nget_vectors\t\t\t\t\n\n\t\tGet vector of CxG usage for input files.\n\nEvaluation Functions\n----------------------\n\nexamples_constituents\t\n\n\t\tGet examples of predicted constituents by type. (*Not stable in v 0.2)\n\nexamples_constructions\t\n\n\t\tGet examples of each predicted construction. (*Not stable in v 0.2)\n\nCommand-Line Usage\n==================\n\n\t(1) Begin a Python interpreter\n\n\t(2) Import the package:\n\n\t\t\timport c2xg\n\n\t(3) Initialize the parameters object:\n\n\t\t\tParameters = c2xg.Parameters(\"filename\")\n\n\t(4a) Run the API, loading grammar objects from disk:\n\n\t\t\tc2xg.learn_constituents(Parameters)\n\n\t(4b) Run the API, initializing and then passing grammar objects:\n\n\t\t\tGrammar = c2xg.Grammar()\n\t\t\tc2xg.learn_constituents(Parameters, Grammar)\t\n\n\nInput Formats\n===================\n\nThis section describes the input formats for the different components.\n\n(1) Creating Semantic Dictionary\n\n\tInput: Unannotated text, one sentence per line. Tokenization and emoji identification are performed on each line.\n\n(2) Creating Models of Grammar and Usage\n\n\tInput: Annotated: CoNLL format of tab-separate fields [Word-Form, Lemma, POS, Index]. \n\tUse <s:ID> to assign ids to documents.\n\n\tInput: Unannotated: Plain text with line breaks for documents / sentences as desired. \n\t[In both cases, each line is assumed to be a \"text\" or the containing unit of analysis; instances can be separated by the \"|\" character for aggregation]\n\n(3) Extracting Feature Vectors\n\n\tInput with Meta-Data: \t\tField:Value,Field:Value\\tText\n\tInput without Meta-Data:\tPlain text with line breaks (\\n) for documents or sentences depending on the level of analysis.\n\n\nFeature Extraction\n=========================\n\nGiven a language-specific CxG, the get_vectors and learn_usage functions convert that grammar into a vector representation of texts or sentences (i.e., one unit per line in the input files). There are two modes and three quantification methods for creating vectors:\n\n\tvector_scope = \"CxG+Units\": Constructions and lexical / POS / semantic features\n\tvector_scope = \"Lexical\": Only lexical features\n\tvector_scope = \"CxG\": Only construction features\t\n\n\texpand_check == True: Allow complex constituents to fill slots in extracted features\n\trelative_freq == True: Quantify using the relative frequency of the feature in given sentence or text (as negative logarithms)\n\trelative_freq == False: Quantify using unadjusted raw frequency of the feature\n\tuse_centroid == True: Extract vectors with centriod normalization learned using learn_usage. This is functionally equivalent to TF-IDF scaling\n\n\tCentroid normalization first finds the probability of a given feature in the background corpus. This is stored after running learn_usage in separate centroid_df models for the full grammar and for the lexical-only features. During extraction, if centroids are used for representation, this is converted into negative logarithms of the inverted joint probability of each feature occuring as many times as it does in a document.\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://www.c2xg.io", "keywords": "grammar induction,unsupervised language processing,construction grammar,cognitive linguistics", "license": "LGPL 3.0", "maintainer": "", "maintainer_email": "", "name": "c2xg", "package_url": "https://pypi.org/project/c2xg/", "platform": "", "project_url": "https://pypi.org/project/c2xg/", "project_urls": {"Homepage": "http://www.c2xg.io"}, "release_url": "https://pypi.org/project/c2xg/0.22/", "requires_dist": ["cytoolz", "gensim", "matplotlib", "numexpr", "numpy", "pandas", "scipy", "seaborn", "sklearn"], "requires_python": "", "summary": "Learn, vectorize, and annotate Construction Grammars", "version": "0.22", "yanked": false, "html_description": "<div class=\"project-description\">\n            <br>c2xg 0.2<br>=============<br><br>Computational Construction Grammar, or c2xg, is two things: <br><br>(1) A Python package for the unsupervised learning of CxG representations along with tools for vectorizing these representations for computational tasks<br><br>(2) A discovery-device grammar that learns falsifiable and replicable CxGs from observed unannotated text data<br><br>Why CxGs? Constructions are grammatical entities that allow the straight-forward quantification of linguistic structure.<br><br><br>Installation<br>--------------<br><br>\t\tpip install c2xg<br><br>or<br><br>\t\tpip install &lt;whl file&gt;<br><br><br>Environment and Dependencies<br>----------------------------------<br><br>This package is meant to run in Python 3.5 with a number of dependencies. The easiest way to maintain the necessary environment is to use Anaconda Python: https://www.continuum.io/downloads<br><br>This makes it easier to maintain the necessary environment. The package works with the dependency versions listed below. It will likely work with older versions of some packages but has not been tested with them. For example, older versions of numexpr have been known to cause issues withs pandas and may lead to lost candidates.<br><br>Dependencies:<br><br>\tPython 3.5<br>\tcytoolz 0.7.4<br>\tgensim 0.12.2<br>\tmatplotlib 1.5.0<br>\tnumexpr 2.5<br>\tnumpy 1.10.4<br>\tpandas 0.18.0<br>\tscipy 0.16.0<br>\tsklearn 0.17<br><br>Usage<br>=====<br>C2xG has two main classes:<br><br>\tc2xg.Parameters loads and initializes the settings needed for running C2xG; these values are set in a file<br><br>\tc2xg.Grammar contains the grammar resources used across all stages of the package<br><br>Initialize the package with the following commands:<br><br>\timport c2xg<br>\tParameters = c2xg.Parameters(\"filename\")<br><br>The parameters class takes as input a string indicating the name of the parameters file. Now, run the API using the following template, where Parameters is an initialized c2xg.Parameter object:<br><br>\tc2xg.learn_c2xg(Parameters)<br>\tc2xg.learn_idioms(Parameters)<br><br>All functions in the API take a c2xg.Parameters object as an argument. The c2xg.Grammar object can be passed to each function or, if not passed, loaded from file.<br><br>API<br>====<br><br>Each function in the API takes a Parameters object and either creates the Grammar object or loads it from the file specified in the parameters.<br><br>Automate Pipeline<br>------------------<br><br>learn_c2xg\t\t\t<br><br>\t\tUmbrella function for entire learning pipeline (from learn_mwes to learn_constructions).<br><br>Individual Learning Functions<br>------------------------------<br><br>learn_dictionary\t\t<br><br>\t\tUse GenSim to create the dictionary of semantic representations needed for c2xg.<br><br>learn_rdrpos_model\t\t<br><br>\t\tUse RDRPOS Tagger Dependency to learn a new pos-tagging model.<br><br>learn_idioms\t\t\t\t<br><br>\t\tUse c2xg to learn a dictionary of idioms (lexical constructions).<br><br>learn_constituents\t \t<br><br>\t\tUse c2xg to learn a constituency grammar.<br><br>learn_constructions \t<br><br>\t\tUse c2xg to learn a full Construction Grammar with lexical, MWE, semantic, and constituent representations.<br><br>learn_usage\t\t\t\t<br><br>\t\tPrepare to use TF-IDF weighting during feature extraction.<br><br>learn_association<br><br>\t\tProduce a CSV file of association measures for sequences of a given length and types of representation<br><br>Helper Functions<br>-----------------<br><br>annotate_pos\t\t\t<br><br>\t\tTokenize, pos-tag, mark emojis, and convert to CoNLL format.<br><br>get_indexes\t\t\t\t<br><br>\t\tGet indexes of representation types.<br><br>get_candidates\t\t\t<br><br>\t\tGetcandidate sequences from input files (covers MWEs, Constituents, and Constructions).<br><br>get_association\t\t\t<br><br>\t\tGet vector of association values for each candidate.<br><br>get_vectors\t\t\t\t<br><br>\t\tGet vector of CxG usage for input files.<br><br>Evaluation Functions<br>----------------------<br><br>examples_constituents\t<br><br>\t\tGet examples of predicted constituents by type. (*Not stable in v 0.2)<br><br>examples_constructions\t<br><br>\t\tGet examples of each predicted construction. (*Not stable in v 0.2)<br><br>Command-Line Usage<br>==================<br><br>\t(1) Begin a Python interpreter<br><br>\t(2) Import the package:<br><br>\t\t\timport c2xg<br><br>\t(3) Initialize the parameters object:<br><br>\t\t\tParameters = c2xg.Parameters(\"filename\")<br><br>\t(4a) Run the API, loading grammar objects from disk:<br><br>\t\t\tc2xg.learn_constituents(Parameters)<br><br>\t(4b) Run the API, initializing and then passing grammar objects:<br><br>\t\t\tGrammar = c2xg.Grammar()<br>\t\t\tc2xg.learn_constituents(Parameters, Grammar)\t<br><br><br>Input Formats<br>===================<br><br>This section describes the input formats for the different components.<br><br>(1) Creating Semantic Dictionary<br><br>\tInput: Unannotated text, one sentence per line. Tokenization and emoji identification are performed on each line.<br><br>(2) Creating Models of Grammar and Usage<br><br>\tInput: Annotated: CoNLL format of tab-separate fields [Word-Form, Lemma, POS, Index]. <br>\tUse &lt;s:ID&gt; to assign ids to documents.<br><br>\tInput: Unannotated: Plain text with line breaks for documents / sentences as desired. <br>\t[In both cases, each line is assumed to be a \"text\" or the containing unit of analysis; instances can be separated by the \"|\" character for aggregation]<br><br>(3) Extracting Feature Vectors<br><br>\tInput with Meta-Data: \t\tField:Value,Field:Value\\tText<br>\tInput without Meta-Data:\tPlain text with line breaks (\\n) for documents or sentences depending on the level of analysis.<br><br><br>Feature Extraction<br>=========================<br><br>Given a language-specific CxG, the get_vectors and learn_usage functions convert that grammar into a vector representation of texts or sentences (i.e., one unit per line in the input files). There are two modes and three quantification methods for creating vectors:<br><br>\tvector_scope = \"CxG+Units\": Constructions and lexical / POS / semantic features<br>\tvector_scope = \"Lexical\": Only lexical features<br>\tvector_scope = \"CxG\": Only construction features\t<br><br>\texpand_check == True: Allow complex constituents to fill slots in extracted features<br>\trelative_freq == True: Quantify using the relative frequency of the feature in given sentence or text (as negative logarithms)<br>\trelative_freq == False: Quantify using unadjusted raw frequency of the feature<br>\tuse_centroid == True: Extract vectors with centriod normalization learned using learn_usage. This is functionally equivalent to TF-IDF scaling<br><br>\tCentroid normalization first finds the probability of a given feature in the background corpus. This is stored after running learn_usage in separate centroid_df models for the full grammar and for the lexical-only features. During extraction, if centroids are used for representation, this is converted into negative logarithms of the inverted joint probability of each feature occuring as many times as it does in a document.<br><br>\n          </div>"}, "last_serial": 2728765, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "f1638a0da94a59c941ea90a9df14cb97", "sha256": "0bb9dabfee576065b7e45421ace638f2ce059734c81ecc9c79fcc9d8756351c6"}, "downloads": -1, "filename": "c2xg-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f1638a0da94a59c941ea90a9df14cb97", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8385760, "upload_time": "2017-03-05T16:47:03", "upload_time_iso_8601": "2017-03-05T16:47:03.931804Z", "url": "https://files.pythonhosted.org/packages/92/11/c73ff29ddfa0eb3c35f156e93e24fdf834c4a437020f5f530d3b10c355c5/c2xg-0.2-py3-none-any.whl", "yanked": false}], "0.21": [{"comment_text": "", "digests": {"md5": "effa0dbfd9e588969800c0ef4562b0f2", "sha256": "40579bb62ba5643c9d6cf669461217d7f06339743c6cf9536777f783ca61fb51"}, "downloads": -1, "filename": "c2xg-0.21-py3-none-any.whl", "has_sig": false, "md5_digest": "effa0dbfd9e588969800c0ef4562b0f2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13555036, "upload_time": "2017-03-18T17:57:43", "upload_time_iso_8601": "2017-03-18T17:57:43.769852Z", "url": "https://files.pythonhosted.org/packages/eb/84/66a1287616def496f9729b5b743b9fb3d094e45992008db74c7806509452/c2xg-0.21-py3-none-any.whl", "yanked": false}], "0.22": [{"comment_text": "", "digests": {"md5": "66f2d205b2c0ca61d78f6b95a0c5390d", "sha256": "1b6feffccf62b409697a6b61834b6d358ae92dbd47b9886e3862541d92855f42"}, "downloads": -1, "filename": "c2xg-0.22-py3-none-any.whl", "has_sig": false, "md5_digest": "66f2d205b2c0ca61d78f6b95a0c5390d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13555212, "upload_time": "2017-03-24T17:13:08", "upload_time_iso_8601": "2017-03-24T17:13:08.914672Z", "url": "https://files.pythonhosted.org/packages/f9/d0/6af3818b211705279db062db9f082674e6aa4ef06866f0c317befcd608dc/c2xg-0.22-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "66f2d205b2c0ca61d78f6b95a0c5390d", "sha256": "1b6feffccf62b409697a6b61834b6d358ae92dbd47b9886e3862541d92855f42"}, "downloads": -1, "filename": "c2xg-0.22-py3-none-any.whl", "has_sig": false, "md5_digest": "66f2d205b2c0ca61d78f6b95a0c5390d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13555212, "upload_time": "2017-03-24T17:13:08", "upload_time_iso_8601": "2017-03-24T17:13:08.914672Z", "url": "https://files.pythonhosted.org/packages/f9/d0/6af3818b211705279db062db9f082674e6aa4ef06866f0c317befcd608dc/c2xg-0.22-py3-none-any.whl", "yanked": false}], "timestamp": "Thu May  7 22:35:46 2020"}