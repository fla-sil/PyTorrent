{"info": {"author": "Sam Harvey", "author_email": "samuel.robert.harvey@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "========================\nDatabricks API Utilities\n========================\n\n\n.. image:: https://img.shields.io/pypi/v/databricks_api_utils.svg\n        :target: https://pypi.python.org/pypi/databricks_api_utils\n\n.. image:: https://img.shields.io/travis/sam-harvey/databricks_api_utils.svg\n        :target: https://travis-ci.org/sam-harvey/databricks_api_utils\n\n.. image:: https://readthedocs.org/projects/databricks-api-utils/badge/?version=latest\n        :target: https://databricks-api-utils.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n\n\n\nHelper functions for working with the Databricks API\n\n\n* Free software: MIT license\n* Documentation: https://databricks-api-utils.readthedocs.io.\n\n\nFeatures\n--------\n\n* Import/Export a folder of files to/from Databricks in source format. Rather than only being able to import/export in binary DBC format.\n\nCredits\n-------\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n\n\n=======\nHistory\n=======\n\n0.1.0 (2019-11-05)\n------------------\n\n* First release on PyPI.", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sam-harvey/databricks_api_utils", "keywords": "databricks_api_utils", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "databricks-api-utils", "package_url": "https://pypi.org/project/databricks-api-utils/", "platform": "", "project_url": "https://pypi.org/project/databricks-api-utils/", "project_urls": {"Homepage": "https://github.com/sam-harvey/databricks_api_utils"}, "release_url": "https://pypi.org/project/databricks-api-utils/0.1.1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Helper functions for working with databricks-api", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"databricks-api-utilities\">\n<h2>Databricks API Utilities</h2>\n<a href=\"https://pypi.python.org/pypi/databricks_api_utils\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/databricks_api_utils.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/45be3da9080e437b2b3371799e22093c68677ec5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f64617461627269636b735f6170695f7574696c732e737667\"></a>\n<a href=\"https://travis-ci.org/sam-harvey/databricks_api_utils\" rel=\"nofollow\"><img alt=\"https://img.shields.io/travis/sam-harvey/databricks_api_utils.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e821259f943dfba10fb6e804fc81863b557bb30b/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f73616d2d6861727665792f64617461627269636b735f6170695f7574696c732e737667\"></a>\n<a href=\"https://databricks-api-utils.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ef6780085f2176d07a8f2c0b8e1a2343751a68bd/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f64617461627269636b732d6170692d7574696c732f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<p>Helper functions for working with the Databricks API</p>\n<ul>\n<li>Free software: MIT license</li>\n<li>Documentation: <a href=\"https://databricks-api-utils.readthedocs.io\" rel=\"nofollow\">https://databricks-api-utils.readthedocs.io</a>.</li>\n</ul>\n<div id=\"features\">\n<h3>Features</h3>\n<ul>\n<li>Import/Export a folder of files to/from Databricks in source format. Rather than only being able to import/export in binary DBC format.</li>\n</ul>\n</div>\n<div id=\"credits\">\n<h3>Credits</h3>\n<p>This package was created with <a href=\"https://github.com/audreyr/cookiecutter\" rel=\"nofollow\">Cookiecutter</a> and the <a href=\"https://github.com/audreyr/cookiecutter-pypackage\" rel=\"nofollow\">audreyr/cookiecutter-pypackage</a> project template.</p>\n</div>\n</div>\n<div id=\"history\">\n<h2>History</h2>\n<h2 id=\"id1\"><span class=\"section-subtitle\">0.1.0 (2019-11-05)</span></h2>\n<ul>\n<li>First release on PyPI.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 6797578, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "88a71a1ece3e0adf60e23df94b28ddab", "sha256": "f70b232e02e20c5ccde20290b111a5a23db4cf1e305d40b4bfd9794e68ca6576"}, "downloads": -1, "filename": "databricks_api_utils-0.1.1.tar.gz", "has_sig": false, "md5_digest": "88a71a1ece3e0adf60e23df94b28ddab", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 29691, "upload_time": "2020-03-12T06:52:59", "upload_time_iso_8601": "2020-03-12T06:52:59.081415Z", "url": "https://files.pythonhosted.org/packages/19/3e/5ee9555757c757a3bce04b9bc15a6a60ad93563f6c63c30bfc077574880c/databricks_api_utils-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "88a71a1ece3e0adf60e23df94b28ddab", "sha256": "f70b232e02e20c5ccde20290b111a5a23db4cf1e305d40b4bfd9794e68ca6576"}, "downloads": -1, "filename": "databricks_api_utils-0.1.1.tar.gz", "has_sig": false, "md5_digest": "88a71a1ece3e0adf60e23df94b28ddab", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 29691, "upload_time": "2020-03-12T06:52:59", "upload_time_iso_8601": "2020-03-12T06:52:59.081415Z", "url": "https://files.pythonhosted.org/packages/19/3e/5ee9555757c757a3bce04b9bc15a6a60ad93563f6c63c30bfc077574880c/databricks_api_utils-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:30 2020"}