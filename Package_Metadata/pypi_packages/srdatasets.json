{"info": {"author": "Cheng Guo", "author_email": "guocheng672@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License"], "description": "# Sequential Recommendation Datasets\n\nProvide a tool for helping dealing with some common sequential recommendation datasets\n\n[![Build Status](https://dev.azure.com/guocheng672/sequential-recommendation-datasets/_apis/build/status/guocheng2018.sequential-recommendation-datasets?branchName=master)](https://dev.azure.com/guocheng672/sequential-recommendation-datasets/_build/latest?definitionId=1&branchName=master)\n[![PyPI version](https://badge.fury.io/py/srdatasets.svg)](https://badge.fury.io/py/srdatasets)\n\n## Datasets\n\n- [Amazon-Books](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Electronics](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Movies](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-CDs](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Clothing](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Home](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Kindle](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Sports](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Phones](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Health](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Toys](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-VideoGames](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Tools](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Beauty](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Apps](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Office](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Pet](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Automotive](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Grocery](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Patio](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Baby](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-Music](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-MusicalInstruments](http://jmcauley.ucsd.edu/data/amazon/)\n- [Amazon-InstantVideo](http://jmcauley.ucsd.edu/data/amazon/)\n- [CiteULike](http://konect.cc/networks/citeulike-ut/)\n- [FourSquare-NYC](https://sites.google.com/site/yangdingqi/home/foursquare-dataset)\n- [FourSquare-Tokyo](https://sites.google.com/site/yangdingqi/home/foursquare-dataset)\n- [Gowalla](https://snap.stanford.edu/data/loc-Gowalla.html)\n- [Lastfm1K](http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html)\n- [MovieLens20M](https://grouplens.org/datasets/movielens/)\n- [Retailrocket](https://www.kaggle.com/retailrocket/ecommerce-dataset)\n- [TaFeng](https://stackoverflow.com/a/25460645/8810037)\n- [Taobao](https://tianchi.aliyun.com/dataset/dataDetail?dataId=649)\n- [Tmall](https://tianchi.aliyun.com/dataset/dataDetail?dataId=47)\n- [Yelp](https://www.yelp.com/dataset)\n\n## Install this tool\n\n```bash\npip install -U srdatasets \u2014-user\n```\n\n## Download datasets\n\nRun the command below to download datasets. As some datasets are not directly accessible, you'll be warned  to download them manually and place them somewhere it tells you.\n\n```bash\nsrdatasets download --dataset=[dataset_name]\n```\n\nTo get a view of downloaded and processed status of all datasets, run\n\n```bash\nsrdatasets info\n```\n\n## Process datasets\n\nThe generic processing command is\n\n```bash\nsrdatasets process --dataset=[dataset_name] [--options]\n```\n\n### Splitting options\n\nTwo dataset splitting methods are provided: **user-based** and **time-based**. User-based means that splitting is executed on every user behavior sequence given the ratio of validation set and test set, while time-based means that splitting is based on the date of user behaviors. After splitting some dataset, two processed datasets are generated, one for development, which uses the validation set as the test set, the other for test, which contains the full training set.\n\n```code\n--split-by     User or time (default: user)\n--test-split   Proportion of test set to full dataset (default: 0.2)\n--dev-split    Proportion of validation set to full training set (default: 0.1)\n```\n\n**NOTE**: time-based splitting need you to manually input days at console by tipping you total days of that dataset, since you may not know.\n\n### Task related options\n\nFor **short term** recommnedation task, you use previous `input-len` items to predict next `target-len` items. To make user interests more focused, user behavior sequences can also be cut into multiple sessions if `session-interval` is given. If the number of previous items is smaller than `input-len`, 0 is padded to the left.\n\nFor **long and short term** recommendation task, you use `pre-sessions` previous sessions and current session to predict `target-len` items. The target items are picked randomly or lastly from current session. So the length of current session is `max-session-len` - `target-len` while the length of any previous session is `max-session-len`. If any previous session or current session is shorter than the preset length, 0 is padded to the left.\n\n```code\n--task              Short or long-short (default: short)\n--input-len         Number of previous items (default: 5)\n--target-len        Number of target items (default: 1)\n--pre-sessions      Number of previous sessions (default: 10)\n--pick-targets      Randomly or lastly pick items from current session (default: random)\n--session-interval  Session splitting interval (minutes)  (default: 0)\n--min-session-len   Sessions less than this in length will be dropped  (default: 2)\n--max-session-len   Sessions greater than this in length will be cut  (default: 20)\n```\n\n### Common options\n\n```code\n--min-freq-item        Items less than this in frequency will be dropped (default: 5)\n--min-freq-user        Users less than this in frequency will be dropped (default: 5)\n--no-augment           Do not use data augmentation (default: False)\n--remove-duplicates    Remove duplicated items in user sequence or user session (if splitted) (default: False)\n```\n\n### Dataset related options\n\n```code\n--rating-threshold  Interactions with rating less than this will be dropped (Amazon, Movielens, Yelp) (default: 4)\n--item-type         Recommend artists or songs (Lastfm) (default: song)\n```\n\n### Version\n\nBy using different options, a dataset will have many processed versions. You can run the command below to get configurations and statistics of all processed versions of some dataset. The `config id` shown in output is a required argument of `DataLoader`.\n\n```bash\nsrdatasets info --dataset=[dataset_name]\n```\n\n## DataLoader\n\nDataLoader is a built-in class that makes loading processed datasets easy. Practically, once initialized a dataloder by passing the dataset name, processed version (config id), batch_size and a flag to load training data or test data, you can then loop it to get batch data. Considering that some models use rank-based learning, negative sampling is intergrated into DataLoader. The negatives are sampled from all items except items in current data according to popularity. By default it (`negatives_per_target`) is turned off. Also, the time of user behaviors is sometimes an important feature, you can include it into batch data by setting `include_timestmap` to True.\n\n### Arguments\n\n- `dataset_name`: dataset name (case insensitive)\n- `config_id`: configuration id\n- `batch_size`: batch size (default: 1)\n- `train`: load training dataset (default: True)\n- `development`: load the dataset aiming for development (default: False)\n- `negatives_per_target`: number of negative samples per target (default: 0)\n- `include_timestamp`: add timestamps to batch data (default: False)\n- `drop_last`: drop last incomplete batch (default: False)\n\n### Initialization example\n\n```python\nfrom srdatasets.dataloader import DataLoader\n\ntrainloader = DataLoader(\"amazon-books\", \"c1574673118829\", batch_size=32, train=True, negatives_per_target=5, include_timestamp=True)\ntestloader = DataLoader(\"amazon-books\", \"c1574673118829\", batch_size=32, train=False, include_timestamp=True)\n```\n\nFor pytorch users, there is a wrapper implementation of `torch.utils.data.DataLoader`, you can then set keyword arguments like `num_workers` and `pin_memory` to speed up loading data\n\n```python\nfrom srdatasets.dataloader_pytorch import DataLoader\n\ntrainloader = DataLoader(\"amazon-books\", \"c1574673118829\", batch_size=32, train=True, negatives_per_target=5, include_timestamp=True, num_workers=8, pin_memory=True)\ntestloader = DataLoader(\"amazon-books\", \"c1574673118829\", batch_size=32, train=False, include_timestamp=True, num_workers=8, pin_memory=True)\n```\n\n### Iteration template\n\nFor short term recommendation task\n\n```python\nfor epoch in range(10):\n    # Train\n    for users, input_items, target_items, input_item_timestamps, target_item_timestamps, negative_samples in trainloader:\n        # Shape\n        #   users:                  (batch_size,)\n        #   input_items:            (batch_size, input_len)\n        #   target_items:           (batch_size, target_len)\n        #   input_item_timestamps:  (batch_size, input_len)\n        #   target_item_timestamps: (batch_size, target_len)\n        #   negative_samples:       (batch_size, target_len, negatives_per_target)\n        #\n        # DataType\n        #   numpy.ndarray or torch.LongTensor\n        pass\n\n    # Test\n    for users, input_items, target_items, input_item_timestamps, target_item_timestamps in testloader:\n        pass\n```\n\nFor long and short term recommendation task\n\n```python\nfor epoch in range(10):\n    # Train\n    for users, pre_sessions_items, cur_session_items, target_items, pre_sessions_item_timestamps, cur_session_item_timestamps, target_item_timestamps, negative_samples in trainloader:\n        # Shape\n        #   users:                          (batch_size,)\n        #   pre_sessions_items:             (batch_size, pre_sessions * max_session_len)\n        #   cur_session_items:              (batch_size, max_session_len - target_len)\n        #   target_items:                   (batch_size, target_len)\n        #   pre_sessions_item_timestamps:   (batch_size, pre_sessions * max_session_len)\n        #   cur_session_item_timestamps:    (batch_size, max_session_len - target_len)\n        #   target_item_timestamps:         (batch_size, target_len)\n        #   negative_samples:               (batch_size, target_len, negatives_per_target)\n        #\n        # DataType\n        #   numpy.ndarray or torch.LongTensor\n        pass\n\n    # Test\n    for users, pre_sessions_items, cur_session_items, target_items, pre_sessions_item_timestamps, cur_session_item_timestamps, target_item_timestamps in testloader:\n        pass\n```\n\n## Disclaimers\n\nThis repo does not host or distribute any of the datasets, it is your responsibility to determine whether you have permission to use the dataset under the dataset's license.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/guocheng2018/sequential-recommendation-datasets", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "srdatasets", "package_url": "https://pypi.org/project/srdatasets/", "platform": "", "project_url": "https://pypi.org/project/srdatasets/", "project_urls": {"Homepage": "https://github.com/guocheng2018/sequential-recommendation-datasets"}, "release_url": "https://pypi.org/project/srdatasets/0.1.4/", "requires_dist": ["pandas (>=0.25.0)", "tqdm (>=4.33.0)", "tabulate (>=0.8.5)", "numpy (>=1.16.4)"], "requires_python": ">=3.6", "summary": "A collection of research ready datasets for sequential recommendation", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Sequential Recommendation Datasets</h1>\n<p>Provide a tool for helping dealing with some common sequential recommendation datasets</p>\n<p><a href=\"https://dev.azure.com/guocheng672/sequential-recommendation-datasets/_build/latest?definitionId=1&amp;branchName=master\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f682a4f0c0ef458e5556aaea8e6957cd1ae233f7/68747470733a2f2f6465762e617a7572652e636f6d2f67756f6368656e673637322f73657175656e7469616c2d7265636f6d6d656e646174696f6e2d64617461736574732f5f617069732f6275696c642f7374617475732f67756f6368656e67323031382e73657175656e7469616c2d7265636f6d6d656e646174696f6e2d64617461736574733f6272616e63684e616d653d6d6173746572\"></a>\n<a href=\"https://badge.fury.io/py/srdatasets\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/938f28a6f268c67a55922ec750bd0d2ef0aff215/68747470733a2f2f62616467652e667572792e696f2f70792f737264617461736574732e737667\"></a></p>\n<h2>Datasets</h2>\n<ul>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Books</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Electronics</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Movies</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-CDs</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Clothing</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Home</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Kindle</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Sports</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Phones</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Health</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Toys</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-VideoGames</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Tools</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Beauty</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Apps</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Office</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Pet</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Automotive</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Grocery</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Patio</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Baby</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-Music</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-MusicalInstruments</a></li>\n<li><a href=\"http://jmcauley.ucsd.edu/data/amazon/\" rel=\"nofollow\">Amazon-InstantVideo</a></li>\n<li><a href=\"http://konect.cc/networks/citeulike-ut/\" rel=\"nofollow\">CiteULike</a></li>\n<li><a href=\"https://sites.google.com/site/yangdingqi/home/foursquare-dataset\" rel=\"nofollow\">FourSquare-NYC</a></li>\n<li><a href=\"https://sites.google.com/site/yangdingqi/home/foursquare-dataset\" rel=\"nofollow\">FourSquare-Tokyo</a></li>\n<li><a href=\"https://snap.stanford.edu/data/loc-Gowalla.html\" rel=\"nofollow\">Gowalla</a></li>\n<li><a href=\"http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html\" rel=\"nofollow\">Lastfm1K</a></li>\n<li><a href=\"https://grouplens.org/datasets/movielens/\" rel=\"nofollow\">MovieLens20M</a></li>\n<li><a href=\"https://www.kaggle.com/retailrocket/ecommerce-dataset\" rel=\"nofollow\">Retailrocket</a></li>\n<li><a href=\"https://stackoverflow.com/a/25460645/8810037\" rel=\"nofollow\">TaFeng</a></li>\n<li><a href=\"https://tianchi.aliyun.com/dataset/dataDetail?dataId=649\" rel=\"nofollow\">Taobao</a></li>\n<li><a href=\"https://tianchi.aliyun.com/dataset/dataDetail?dataId=47\" rel=\"nofollow\">Tmall</a></li>\n<li><a href=\"https://www.yelp.com/dataset\" rel=\"nofollow\">Yelp</a></li>\n</ul>\n<h2>Install this tool</h2>\n<pre>pip install -U srdatasets \u2014-user\n</pre>\n<h2>Download datasets</h2>\n<p>Run the command below to download datasets. As some datasets are not directly accessible, you'll be warned  to download them manually and place them somewhere it tells you.</p>\n<pre>srdatasets download --dataset<span class=\"o\">=[</span>dataset_name<span class=\"o\">]</span>\n</pre>\n<p>To get a view of downloaded and processed status of all datasets, run</p>\n<pre>srdatasets info\n</pre>\n<h2>Process datasets</h2>\n<p>The generic processing command is</p>\n<pre>srdatasets process --dataset<span class=\"o\">=[</span>dataset_name<span class=\"o\">]</span> <span class=\"o\">[</span>--options<span class=\"o\">]</span>\n</pre>\n<h3>Splitting options</h3>\n<p>Two dataset splitting methods are provided: <strong>user-based</strong> and <strong>time-based</strong>. User-based means that splitting is executed on every user behavior sequence given the ratio of validation set and test set, while time-based means that splitting is based on the date of user behaviors. After splitting some dataset, two processed datasets are generated, one for development, which uses the validation set as the test set, the other for test, which contains the full training set.</p>\n<pre>--split-by     User or time (default: user)\n--test-split   Proportion of test set to full dataset (default: 0.2)\n--dev-split    Proportion of validation set to full training set (default: 0.1)\n</pre>\n<p><strong>NOTE</strong>: time-based splitting need you to manually input days at console by tipping you total days of that dataset, since you may not know.</p>\n<h3>Task related options</h3>\n<p>For <strong>short term</strong> recommnedation task, you use previous <code>input-len</code> items to predict next <code>target-len</code> items. To make user interests more focused, user behavior sequences can also be cut into multiple sessions if <code>session-interval</code> is given. If the number of previous items is smaller than <code>input-len</code>, 0 is padded to the left.</p>\n<p>For <strong>long and short term</strong> recommendation task, you use <code>pre-sessions</code> previous sessions and current session to predict <code>target-len</code> items. The target items are picked randomly or lastly from current session. So the length of current session is <code>max-session-len</code> - <code>target-len</code> while the length of any previous session is <code>max-session-len</code>. If any previous session or current session is shorter than the preset length, 0 is padded to the left.</p>\n<pre>--task              Short or long-short (default: short)\n--input-len         Number of previous items (default: 5)\n--target-len        Number of target items (default: 1)\n--pre-sessions      Number of previous sessions (default: 10)\n--pick-targets      Randomly or lastly pick items from current session (default: random)\n--session-interval  Session splitting interval (minutes)  (default: 0)\n--min-session-len   Sessions less than this in length will be dropped  (default: 2)\n--max-session-len   Sessions greater than this in length will be cut  (default: 20)\n</pre>\n<h3>Common options</h3>\n<pre>--min-freq-item        Items less than this in frequency will be dropped (default: 5)\n--min-freq-user        Users less than this in frequency will be dropped (default: 5)\n--no-augment           Do not use data augmentation (default: False)\n--remove-duplicates    Remove duplicated items in user sequence or user session (if splitted) (default: False)\n</pre>\n<h3>Dataset related options</h3>\n<pre>--rating-threshold  Interactions with rating less than this will be dropped (Amazon, Movielens, Yelp) (default: 4)\n--item-type         Recommend artists or songs (Lastfm) (default: song)\n</pre>\n<h3>Version</h3>\n<p>By using different options, a dataset will have many processed versions. You can run the command below to get configurations and statistics of all processed versions of some dataset. The <code>config id</code> shown in output is a required argument of <code>DataLoader</code>.</p>\n<pre>srdatasets info --dataset<span class=\"o\">=[</span>dataset_name<span class=\"o\">]</span>\n</pre>\n<h2>DataLoader</h2>\n<p>DataLoader is a built-in class that makes loading processed datasets easy. Practically, once initialized a dataloder by passing the dataset name, processed version (config id), batch_size and a flag to load training data or test data, you can then loop it to get batch data. Considering that some models use rank-based learning, negative sampling is intergrated into DataLoader. The negatives are sampled from all items except items in current data according to popularity. By default it (<code>negatives_per_target</code>) is turned off. Also, the time of user behaviors is sometimes an important feature, you can include it into batch data by setting <code>include_timestmap</code> to True.</p>\n<h3>Arguments</h3>\n<ul>\n<li><code>dataset_name</code>: dataset name (case insensitive)</li>\n<li><code>config_id</code>: configuration id</li>\n<li><code>batch_size</code>: batch size (default: 1)</li>\n<li><code>train</code>: load training dataset (default: True)</li>\n<li><code>development</code>: load the dataset aiming for development (default: False)</li>\n<li><code>negatives_per_target</code>: number of negative samples per target (default: 0)</li>\n<li><code>include_timestamp</code>: add timestamps to batch data (default: False)</li>\n<li><code>drop_last</code>: drop last incomplete batch (default: False)</li>\n</ul>\n<h3>Initialization example</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">srdatasets.dataloader</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n\n<span class=\"n\">trainloader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"s2\">\"amazon-books\"</span><span class=\"p\">,</span> <span class=\"s2\">\"c1574673118829\"</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">negatives_per_target</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">include_timestamp</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">testloader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"s2\">\"amazon-books\"</span><span class=\"p\">,</span> <span class=\"s2\">\"c1574673118829\"</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">include_timestamp</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>For pytorch users, there is a wrapper implementation of <code>torch.utils.data.DataLoader</code>, you can then set keyword arguments like <code>num_workers</code> and <code>pin_memory</code> to speed up loading data</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">srdatasets.dataloader_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n\n<span class=\"n\">trainloader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"s2\">\"amazon-books\"</span><span class=\"p\">,</span> <span class=\"s2\">\"c1574673118829\"</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">negatives_per_target</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">include_timestamp</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">pin_memory</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">testloader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"s2\">\"amazon-books\"</span><span class=\"p\">,</span> <span class=\"s2\">\"c1574673118829\"</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">include_timestamp</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"n\">pin_memory</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<h3>Iteration template</h3>\n<p>For short term recommendation task</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Train</span>\n    <span class=\"k\">for</span> <span class=\"n\">users</span><span class=\"p\">,</span> <span class=\"n\">input_items</span><span class=\"p\">,</span> <span class=\"n\">target_items</span><span class=\"p\">,</span> <span class=\"n\">input_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">target_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">negative_samples</span> <span class=\"ow\">in</span> <span class=\"n\">trainloader</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Shape</span>\n        <span class=\"c1\">#   users:                  (batch_size,)</span>\n        <span class=\"c1\">#   input_items:            (batch_size, input_len)</span>\n        <span class=\"c1\">#   target_items:           (batch_size, target_len)</span>\n        <span class=\"c1\">#   input_item_timestamps:  (batch_size, input_len)</span>\n        <span class=\"c1\">#   target_item_timestamps: (batch_size, target_len)</span>\n        <span class=\"c1\">#   negative_samples:       (batch_size, target_len, negatives_per_target)</span>\n        <span class=\"c1\">#</span>\n        <span class=\"c1\"># DataType</span>\n        <span class=\"c1\">#   numpy.ndarray or torch.LongTensor</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"c1\"># Test</span>\n    <span class=\"k\">for</span> <span class=\"n\">users</span><span class=\"p\">,</span> <span class=\"n\">input_items</span><span class=\"p\">,</span> <span class=\"n\">target_items</span><span class=\"p\">,</span> <span class=\"n\">input_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">target_item_timestamps</span> <span class=\"ow\">in</span> <span class=\"n\">testloader</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n</pre>\n<p>For long and short term recommendation task</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Train</span>\n    <span class=\"k\">for</span> <span class=\"n\">users</span><span class=\"p\">,</span> <span class=\"n\">pre_sessions_items</span><span class=\"p\">,</span> <span class=\"n\">cur_session_items</span><span class=\"p\">,</span> <span class=\"n\">target_items</span><span class=\"p\">,</span> <span class=\"n\">pre_sessions_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">cur_session_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">target_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">negative_samples</span> <span class=\"ow\">in</span> <span class=\"n\">trainloader</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Shape</span>\n        <span class=\"c1\">#   users:                          (batch_size,)</span>\n        <span class=\"c1\">#   pre_sessions_items:             (batch_size, pre_sessions * max_session_len)</span>\n        <span class=\"c1\">#   cur_session_items:              (batch_size, max_session_len - target_len)</span>\n        <span class=\"c1\">#   target_items:                   (batch_size, target_len)</span>\n        <span class=\"c1\">#   pre_sessions_item_timestamps:   (batch_size, pre_sessions * max_session_len)</span>\n        <span class=\"c1\">#   cur_session_item_timestamps:    (batch_size, max_session_len - target_len)</span>\n        <span class=\"c1\">#   target_item_timestamps:         (batch_size, target_len)</span>\n        <span class=\"c1\">#   negative_samples:               (batch_size, target_len, negatives_per_target)</span>\n        <span class=\"c1\">#</span>\n        <span class=\"c1\"># DataType</span>\n        <span class=\"c1\">#   numpy.ndarray or torch.LongTensor</span>\n        <span class=\"k\">pass</span>\n\n    <span class=\"c1\"># Test</span>\n    <span class=\"k\">for</span> <span class=\"n\">users</span><span class=\"p\">,</span> <span class=\"n\">pre_sessions_items</span><span class=\"p\">,</span> <span class=\"n\">cur_session_items</span><span class=\"p\">,</span> <span class=\"n\">target_items</span><span class=\"p\">,</span> <span class=\"n\">pre_sessions_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">cur_session_item_timestamps</span><span class=\"p\">,</span> <span class=\"n\">target_item_timestamps</span> <span class=\"ow\">in</span> <span class=\"n\">testloader</span><span class=\"p\">:</span>\n        <span class=\"k\">pass</span>\n</pre>\n<h2>Disclaimers</h2>\n<p>This repo does not host or distribute any of the datasets, it is your responsibility to determine whether you have permission to use the dataset under the dataset's license.</p>\n\n          </div>"}, "last_serial": 6282433, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "6312c34705adae9f675613e12231fb15", "sha256": "ab727e5cb89f514454ad1a2460c86058763404772fe6c1664e3741428df724d6"}, "downloads": -1, "filename": "srdatasets-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "6312c34705adae9f675613e12231fb15", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 28717, "upload_time": "2019-11-26T15:41:03", "upload_time_iso_8601": "2019-11-26T15:41:03.749618Z", "url": "https://files.pythonhosted.org/packages/21/f8/6c445fa344bd5525a6082a41857c1b5a27fac7c96d62c05991928b767c55/srdatasets-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6cfae4f0b9f39c2cccb54efbd95751cc", "sha256": "9f053e1bb31239a917c788cb9b50d9987267f016da6f3df6f501e38824214176"}, "downloads": -1, "filename": "srdatasets-0.0.2.tar.gz", "has_sig": false, "md5_digest": "6cfae4f0b9f39c2cccb54efbd95751cc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 17176, "upload_time": "2019-11-26T15:41:05", "upload_time_iso_8601": "2019-11-26T15:41:05.730629Z", "url": "https://files.pythonhosted.org/packages/a6/18/9e4effda795c6a2e755fccdb3226f0917af1672ad1fe543a4c5edda4b371/srdatasets-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "b98d09eb64dbdc094902018f87abffda", "sha256": "232785b0b14c0e8fd204d6ab24d2ae459d655c8c1e2367cdfa4ccddbdd0e72d1"}, "downloads": -1, "filename": "srdatasets-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "b98d09eb64dbdc094902018f87abffda", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 28750, "upload_time": "2019-11-26T15:58:32", "upload_time_iso_8601": "2019-11-26T15:58:32.730789Z", "url": "https://files.pythonhosted.org/packages/33/9e/98d7d29291fb76f27773f3bf3c6fc2115b5d29249547e40efcd89c74527d/srdatasets-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4aca732ac2cf5ed35c9c9ff08b1db811", "sha256": "0ed2e598da1b2fa319c8d5f90251d541fb6a19fca0449d7fd46aff685c9d0f69"}, "downloads": -1, "filename": "srdatasets-0.0.3.tar.gz", "has_sig": false, "md5_digest": "4aca732ac2cf5ed35c9c9ff08b1db811", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 17191, "upload_time": "2019-11-26T15:58:34", "upload_time_iso_8601": "2019-11-26T15:58:34.726373Z", "url": "https://files.pythonhosted.org/packages/80/ea/d3c91c8c85e522e33bdcfd117fe807fcac90a17d064f5b1a5d8ef785babd/srdatasets-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "6d508c39f0db859b949ce6e5dd52388c", "sha256": "43cd1101f366bb4dda97dec5bf50356fa478e35565e27564b93e40d4dc7cbde8"}, "downloads": -1, "filename": "srdatasets-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "6d508c39f0db859b949ce6e5dd52388c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 28725, "upload_time": "2019-11-27T09:28:24", "upload_time_iso_8601": "2019-11-27T09:28:24.950144Z", "url": "https://files.pythonhosted.org/packages/ca/60/a8d4505900e8969773ec32cf83e5f0e473439968205308968a79ed04d736/srdatasets-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b4786855d80b39f8daa0139963495847", "sha256": "acae682cedce700479a9cec620e63decc95369aed08683f553f356ec780af1c4"}, "downloads": -1, "filename": "srdatasets-0.0.4.tar.gz", "has_sig": false, "md5_digest": "b4786855d80b39f8daa0139963495847", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18864, "upload_time": "2019-11-27T09:28:26", "upload_time_iso_8601": "2019-11-27T09:28:26.430430Z", "url": "https://files.pythonhosted.org/packages/91/a1/f3567ab4fedb7475e321b77b49fe4f5e41fc65f3b6e0fab0fb71fd2f901c/srdatasets-0.0.4.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "5c57eccd00d8eb1a058692e34d22e804", "sha256": "31fa609435396a9c1000719d45d53b9e47303a49efc0546cacb3d466fce518ac"}, "downloads": -1, "filename": "srdatasets-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "5c57eccd00d8eb1a058692e34d22e804", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 28725, "upload_time": "2019-11-27T09:33:25", "upload_time_iso_8601": "2019-11-27T09:33:25.798647Z", "url": "https://files.pythonhosted.org/packages/46/ce/f99e066163a09870d041f3d33d60ff2b1c571a122b758e1c42429621c6bf/srdatasets-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc72d01ec2efe36724a9a1647bc8affa", "sha256": "5b760931dc9cce3061f45b31a1bfadf924fe73f72c0768edecc7abddbf1f2aa3"}, "downloads": -1, "filename": "srdatasets-0.0.7.tar.gz", "has_sig": false, "md5_digest": "fc72d01ec2efe36724a9a1647bc8affa", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18867, "upload_time": "2019-11-27T09:33:26", "upload_time_iso_8601": "2019-11-27T09:33:26.833905Z", "url": "https://files.pythonhosted.org/packages/1c/21/802be785671e66cbb546a3347fc32a116e622794710ce3dbace84cbeb2f2/srdatasets-0.0.7.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "77a529d2bd104b4901ecf32c63517be2", "sha256": "d168014e06976996337b5f388248879084a67e197bd8679343b5fc110c8e395f"}, "downloads": -1, "filename": "srdatasets-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "77a529d2bd104b4901ecf32c63517be2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 29054, "upload_time": "2019-12-02T04:33:36", "upload_time_iso_8601": "2019-12-02T04:33:36.217600Z", "url": "https://files.pythonhosted.org/packages/4a/3e/da8c245ca64420ac3df59180f3816571a63b6a82b0a12112fd3e4e49d8eb/srdatasets-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ed4aa8d42a07f2ff9e90d4c3dc73ce7", "sha256": "492630e2b7646fe13e725c5b637fd7515006506b341f838d793fb95ae2177f5e"}, "downloads": -1, "filename": "srdatasets-0.1.1.tar.gz", "has_sig": false, "md5_digest": "9ed4aa8d42a07f2ff9e90d4c3dc73ce7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 23724, "upload_time": "2019-12-02T04:33:38", "upload_time_iso_8601": "2019-12-02T04:33:38.157225Z", "url": "https://files.pythonhosted.org/packages/37/cc/40575d53c7d50ece27eea00aac5cc4fc111941d3828ed7edbc3fb32c9efe/srdatasets-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "5b155ce911e77466c6d5762a46a8e0e2", "sha256": "dbd65794ca5e563677264a2a8af9b00ef89e2a0106f82f0c0bfdad10a1401b12"}, "downloads": -1, "filename": "srdatasets-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "5b155ce911e77466c6d5762a46a8e0e2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 29817, "upload_time": "2019-12-11T05:45:19", "upload_time_iso_8601": "2019-12-11T05:45:19.270061Z", "url": "https://files.pythonhosted.org/packages/a3/c8/67131ceec9994aba392ed8c24cecc5863e83b4151aeeaa8f504363c35cd7/srdatasets-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f19a39491699855460acbcc484d0bedf", "sha256": "ebf9fa1e845728b7ed1b2884a3785e5c290d619488d9d974f50a9fb7ee551584"}, "downloads": -1, "filename": "srdatasets-0.1.2.tar.gz", "has_sig": false, "md5_digest": "f19a39491699855460acbcc484d0bedf", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24351, "upload_time": "2019-12-11T05:45:20", "upload_time_iso_8601": "2019-12-11T05:45:20.722049Z", "url": "https://files.pythonhosted.org/packages/af/94/4352af6735324be3c430db1b050185abb5936e5946d60d85393d4cf9041f/srdatasets-0.1.2.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "84b9e41984b0668207915b86fbfb17ba", "sha256": "4959d5306f5797f8bf5a782b0079992a38d0400d3dce224b5e18eb44e59aab63"}, "downloads": -1, "filename": "srdatasets-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "84b9e41984b0668207915b86fbfb17ba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 30025, "upload_time": "2019-12-12T04:35:42", "upload_time_iso_8601": "2019-12-12T04:35:42.542956Z", "url": "https://files.pythonhosted.org/packages/6d/90/2513b635f71a70b23a3032847a5be2afd815bb1ebeecbc8eb440b14d00d5/srdatasets-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0259cccc2de02427bb24fc0dd088cbd4", "sha256": "5182045a2be305ed1ff17ebf3e92b92d5c0448b37130f0483d62d07cd03ddcbc"}, "downloads": -1, "filename": "srdatasets-0.1.4.tar.gz", "has_sig": false, "md5_digest": "0259cccc2de02427bb24fc0dd088cbd4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24501, "upload_time": "2019-12-12T04:35:44", "upload_time_iso_8601": "2019-12-12T04:35:44.010051Z", "url": "https://files.pythonhosted.org/packages/6d/a9/c9f91c0c8ccba293ed1af2a138125c978a34f60e61bb8e27cbb99cd9e135/srdatasets-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "84b9e41984b0668207915b86fbfb17ba", "sha256": "4959d5306f5797f8bf5a782b0079992a38d0400d3dce224b5e18eb44e59aab63"}, "downloads": -1, "filename": "srdatasets-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "84b9e41984b0668207915b86fbfb17ba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 30025, "upload_time": "2019-12-12T04:35:42", "upload_time_iso_8601": "2019-12-12T04:35:42.542956Z", "url": "https://files.pythonhosted.org/packages/6d/90/2513b635f71a70b23a3032847a5be2afd815bb1ebeecbc8eb440b14d00d5/srdatasets-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0259cccc2de02427bb24fc0dd088cbd4", "sha256": "5182045a2be305ed1ff17ebf3e92b92d5c0448b37130f0483d62d07cd03ddcbc"}, "downloads": -1, "filename": "srdatasets-0.1.4.tar.gz", "has_sig": false, "md5_digest": "0259cccc2de02427bb24fc0dd088cbd4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24501, "upload_time": "2019-12-12T04:35:44", "upload_time_iso_8601": "2019-12-12T04:35:44.010051Z", "url": "https://files.pythonhosted.org/packages/6d/a9/c9f91c0c8ccba293ed1af2a138125c978a34f60e61bb8e27cbb99cd9e135/srdatasets-0.1.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:03:21 2020"}