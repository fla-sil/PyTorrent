{"info": {"author": "Will Farmer, Ken Farmer", "author_email": "willzfarmer@gmail.com, kenfar@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Operating System :: POSIX", "Programming Language :: Python :: 2", "Topic :: Database", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "Hadoop\\_Inspector\n=================\n\nTo review our complete set of documentation please see our `wiki\npage <https://github.com/willzfarmer/HadoopInspector/wiki>`__\n\nBackground\n----------\n\nData quality problems have plagued analytical systems for twenty years:\ncontinually appearing in the top four reasons for project failure.\n\nIn this space data quality problems loom large - a small defect that\ncould be safely ignored or forgotten in the transactional world hamper\nqueries and cause users to question our credibility for months.\n\nThe advent and innovation in Big Data and Data Science has not\ndiminished this challenge. On Hadoop specifically: \\* Data generally\nlacks any enforced constraints to ensure data validity \\* Data is being\nadded faster than ever, with less time to research upstream and ETL\npipeline issues \\* We are building vast systems, sometimes with hundreds\nof thousands of tasks being defined \\* We often have democratized access\nto our clusters - with dozens of different people adding data.\n\nAdditionally, in these large clusters most teams struggle to comply with\npolicies and other requirements, whether regulatory, corporate or\ndefined by their own teams. These might define general data retention\nrequirements, or specific requirements for individual tables. They might\ndefine table naming conventions, security requirements, or stats aging &\ncollection requirements.\n\nObjective\n---------\n\nHadoop-Inspector was built to address the needs to manage data quality\nwithin large, complex, and constantly loaded clusters that were\nunfulfilled by simple QA testing during development. It offers a\nsolution more like an automobile assembly line: continuous quality\ncontrol (QC) that can account for changes to upstream systems,\naccidental changes to production, data migration errors, and ETL/Ingest\ndefects.\n\nCurrent Status\n--------------\n\nThe software consists primarily of three parts:\n\n-  hadoopinspector-runner.py - a test-runner that writes results to a\n   SQLite database and can produce a report of test results. This is the\n   primary and most updated component at this time.\n-  hapinsp\\_httpserver.py - serves the UI.\n-  hadoopinspector-demogen.py - which can generate 50,000+ check results\n   against a hypothetical user hadoop environment. This is used to\n   exercise the UI.\n\nMore info is on the\n`wiki <https://github.com/willzfarmer/HadoopInspector/wiki>`__\n\nInstallation\n------------\n\n-  pip install hadoopinspector\n-  requires python 2.7\n\nLicensing\n=========\n\nThis source code is protected by the BSD license. See the file \"LICENSE\"\nin the source code root directory for the full language or refer to it\nhere: http://opensource.org/licenses/BSD-3-Clause Copyright 2015, 2016\nWill Farmer and Ken Farmer\n\n\n0.1.6 - fix setup.py reference to github account\n\n0.1.5 - improve data start & stop timestamps\n\n-  make these reserved variables\n-  include them within basic runner reporting\n\n0.1.4 - remove inst & db from registry json files\n\n-  add minor fixes being used in prod\n-  add --ssl option to runner\n-  add --version option to runner\n-  heavy refactoring & housekeeping\n\n0.1.3 - add logging\n\n-  improve registry json validation & user error reporting\n-  fix test teardowns leaving behind some files\n-  fix tox errors\n-  fix misc minor defects\n\n0.1.2 - fix check display issues\n\n0.1.1 - remov runtests - unnecessary test bundle for pytests\n\n0.1.0 - update changelog & \\_version to reflect version.\n\n0.0.3 - refactor server to run on python2.7 - upgrade runner to run\nsetup checks to support incremental checks\n\n0.0.2 - heavy refactoring of runner, added a lot of testing\n\n0.0.1 - initial release - demo generator - simple reporting", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/willzfarmer/HadoopInspector", "keywords": "data quality management health", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "hadoop-inspector", "package_url": "https://pypi.org/project/hadoop-inspector/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/hadoop-inspector/", "project_urls": {"Homepage": "http://github.com/willzfarmer/HadoopInspector"}, "release_url": "https://pypi.org/project/hadoop-inspector/0.1.6/", "requires_dist": null, "requires_python": "", "summary": "A measurement and inspection tool to manage Hadoop data quality, manageability and health", "version": "0.1.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"hadoop-inspector\">\n<h2>Hadoop_Inspector</h2>\n<p>To review our complete set of documentation please see our <a href=\"https://github.com/willzfarmer/HadoopInspector/wiki\" rel=\"nofollow\">wiki\npage</a></p>\n<div id=\"background\">\n<h3>Background</h3>\n<p>Data quality problems have plagued analytical systems for twenty years:\ncontinually appearing in the top four reasons for project failure.</p>\n<p>In this space data quality problems loom large - a small defect that\ncould be safely ignored or forgotten in the transactional world hamper\nqueries and cause users to question our credibility for months.</p>\n<p>The advent and innovation in Big Data and Data Science has not\ndiminished this challenge. On Hadoop specifically: * Data generally\nlacks any enforced constraints to ensure data validity * Data is being\nadded faster than ever, with less time to research upstream and ETL\npipeline issues * We are building vast systems, sometimes with hundreds\nof thousands of tasks being defined * We often have democratized access\nto our clusters - with dozens of different people adding data.</p>\n<p>Additionally, in these large clusters most teams struggle to comply with\npolicies and other requirements, whether regulatory, corporate or\ndefined by their own teams. These might define general data retention\nrequirements, or specific requirements for individual tables. They might\ndefine table naming conventions, security requirements, or stats aging &amp;\ncollection requirements.</p>\n</div>\n<div id=\"objective\">\n<h3>Objective</h3>\n<p>Hadoop-Inspector was built to address the needs to manage data quality\nwithin large, complex, and constantly loaded clusters that were\nunfulfilled by simple QA testing during development. It offers a\nsolution more like an automobile assembly line: continuous quality\ncontrol (QC) that can account for changes to upstream systems,\naccidental changes to production, data migration errors, and ETL/Ingest\ndefects.</p>\n</div>\n<div id=\"current-status\">\n<h3>Current Status</h3>\n<p>The software consists primarily of three parts:</p>\n<ul>\n<li>hadoopinspector-runner.py - a test-runner that writes results to a\nSQLite database and can produce a report of test results. This is the\nprimary and most updated component at this time.</li>\n<li>hapinsp_httpserver.py - serves the UI.</li>\n<li>hadoopinspector-demogen.py - which can generate 50,000+ check results\nagainst a hypothetical user hadoop environment. This is used to\nexercise the UI.</li>\n</ul>\n<p>More info is on the\n<a href=\"https://github.com/willzfarmer/HadoopInspector/wiki\" rel=\"nofollow\">wiki</a></p>\n</div>\n<div id=\"installation\">\n<h3>Installation</h3>\n<ul>\n<li>pip install hadoopinspector</li>\n<li>requires python 2.7</li>\n</ul>\n</div>\n</div>\n<div id=\"licensing\">\n<h2>Licensing</h2>\n<p>This source code is protected by the BSD license. See the file \u201cLICENSE\u201d\nin the source code root directory for the full language or refer to it\nhere: <a href=\"http://opensource.org/licenses/BSD-3-Clause\" rel=\"nofollow\">http://opensource.org/licenses/BSD-3-Clause</a> Copyright 2015, 2016\nWill Farmer and Ken Farmer</p>\n<p>0.1.6 - fix setup.py reference to github account</p>\n<p>0.1.5 - improve data start &amp; stop timestamps</p>\n<ul>\n<li>make these reserved variables</li>\n<li>include them within basic runner reporting</li>\n</ul>\n<p>0.1.4 - remove inst &amp; db from registry json files</p>\n<ul>\n<li>add minor fixes being used in prod</li>\n<li>add \u2013ssl option to runner</li>\n<li>add \u2013version option to runner</li>\n<li>heavy refactoring &amp; housekeeping</li>\n</ul>\n<p>0.1.3 - add logging</p>\n<ul>\n<li>improve registry json validation &amp; user error reporting</li>\n<li>fix test teardowns leaving behind some files</li>\n<li>fix tox errors</li>\n<li>fix misc minor defects</li>\n</ul>\n<p>0.1.2 - fix check display issues</p>\n<p>0.1.1 - remov runtests - unnecessary test bundle for pytests</p>\n<p>0.1.0 - update changelog &amp; _version to reflect version.</p>\n<p>0.0.3 - refactor server to run on python2.7 - upgrade runner to run\nsetup checks to support incremental checks</p>\n<p>0.0.2 - heavy refactoring of runner, added a lot of testing</p>\n<p>0.0.1 - initial release - demo generator - simple reporting</p>\n</div>\n\n          </div>"}, "last_serial": 2216938, "releases": {"0.1.0": [], "0.1.1": [{"comment_text": "", "digests": {"md5": "4c068685a21765e80dac6442e4c982a6", "sha256": "5f4b99b9ed3ee80f5b08fdc394cd59f15cc1e1265605ee2ae2e83ff677ebc627"}, "downloads": -1, "filename": "hadoop-inspector-0.1.1.tar.gz", "has_sig": false, "md5_digest": "4c068685a21765e80dac6442e4c982a6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1853698, "upload_time": "2015-09-30T13:10:33", "upload_time_iso_8601": "2015-09-30T13:10:33.735185Z", "url": "https://files.pythonhosted.org/packages/e8/c9/ef7074980c399feeed3c17ac2bb88e1c1de7a3245b106a2e8e09c1c5b443/hadoop-inspector-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "2881ecbcbaa6869e489ff2a4d5c79048", "sha256": "6bc692cbcf486e405b904ccf00bba3500fdd3e39fcc3a0e007a29e454762679c"}, "downloads": -1, "filename": "hadoop-inspector-0.1.2.tar.gz", "has_sig": false, "md5_digest": "2881ecbcbaa6869e489ff2a4d5c79048", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1853840, "upload_time": "2015-09-30T14:58:36", "upload_time_iso_8601": "2015-09-30T14:58:36.998623Z", "url": "https://files.pythonhosted.org/packages/70/1e/1e92732e38bbb8ce35bf5babd457d2665d9509183a9f27913696abcb48a5/hadoop-inspector-0.1.2.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "51dbedc2eb61f02ba70377cc4e6c7c61", "sha256": "10e1be2020ed8e9e0e3fe767c470c15197ebc04d007943f5bc158b9857db63b8"}, "downloads": -1, "filename": "hadoop-inspector-0.1.4.tar.gz", "has_sig": false, "md5_digest": "51dbedc2eb61f02ba70377cc4e6c7c61", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1859039, "upload_time": "2016-06-27T14:39:06", "upload_time_iso_8601": "2016-06-27T14:39:06.463433Z", "url": "https://files.pythonhosted.org/packages/b2/67/9cb56e457aaaa0d8768064e00c4f4826e89ef303e525346a8d9b81deb2db/hadoop-inspector-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "837f7f0a15a6fb885317b677a8b64adc", "sha256": "8ed90ef72665486fe1e1e59a2707750597d94f803e0f3f37539111dfef6eca3c"}, "downloads": -1, "filename": "hadoop-inspector-0.1.5.tar.gz", "has_sig": false, "md5_digest": "837f7f0a15a6fb885317b677a8b64adc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1867840, "upload_time": "2016-07-12T15:36:26", "upload_time_iso_8601": "2016-07-12T15:36:26.302724Z", "url": "https://files.pythonhosted.org/packages/73/a1/dac5b7f4cd606f957979d9812cdf783de59660fee5a0c171fd7be1a42720/hadoop-inspector-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "26b879e1673d6ae17c4bcfd1414e0267", "sha256": "68f566711381e5805d0cca838af82f5815b79024766e3457021a434965f11446"}, "downloads": -1, "filename": "hadoop-inspector-0.1.6.tar.gz", "has_sig": false, "md5_digest": "26b879e1673d6ae17c4bcfd1414e0267", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1867898, "upload_time": "2016-07-12T15:46:14", "upload_time_iso_8601": "2016-07-12T15:46:14.457548Z", "url": "https://files.pythonhosted.org/packages/46/d7/2bd78f29f149e1af684d45a22cb571cc7790d247eeabe0a849cdfd7bddbe/hadoop-inspector-0.1.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "26b879e1673d6ae17c4bcfd1414e0267", "sha256": "68f566711381e5805d0cca838af82f5815b79024766e3457021a434965f11446"}, "downloads": -1, "filename": "hadoop-inspector-0.1.6.tar.gz", "has_sig": false, "md5_digest": "26b879e1673d6ae17c4bcfd1414e0267", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1867898, "upload_time": "2016-07-12T15:46:14", "upload_time_iso_8601": "2016-07-12T15:46:14.457548Z", "url": "https://files.pythonhosted.org/packages/46/d7/2bd78f29f149e1af684d45a22cb571cc7790d247eeabe0a849cdfd7bddbe/hadoop-inspector-0.1.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:46 2020"}