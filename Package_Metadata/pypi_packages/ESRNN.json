{"info": {"author": "Kin Gutierrez, Cristian Challu, Federico Garza", "author_email": "kin.gtz.olivares@gmail.com, cristianichallu@gmail.com, fede.garza.ramirez@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "[![Build](https://github.com/kdgutier/esrnn_torch/workflows/Python%20package/badge.svg?branch=pip)](https://github.com/kdgutier/esrnn_torch/tree/pip)\n[![PyPI version fury.io](https://badge.fury.io/py/ESRNN.svg)](https://pypi.python.org/pypi/ESRNN/)\n[![Downloads](https://pepy.tech/badge/esrnn)](https://pepy.tech/project/esrnn)\n[![Python 3.6+](https://img.shields.io/badge/python-3.6+-blue.svg)](https://www.python.org/downloads/release/python-360+/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/kdgutier/esrnn_torch/blob/master/LICENSE)\n\n\n# Pytorch Implementation of the ES-RNN\nIn this project we coded a pytorch class for the ES-RNN algorithm proposed by Smyl, winning submission of the M4 Forecasting Competition. The class wraps fit and predict methods to facilitate interaction with Machine Learning pipelines along with evaluation and data wrangling utility.\n\n## Installation Prerequisites\n* numpy==1.16.1\n* pandas==0.25.2\n* pytorch>=1.3.1\n\n## Installation\n\nThis code is a work in progress, any contributions or issues are welcome on\nGitHub at: https://github.com/kdgutier/esrnn_torch\n\nYou can install the *released version* of `ESRNN` from the [Python package index](https://pypi.org) with:\n\n```python\npip install ESRNN\n```\n\n## Usage Example\nMake sure on use of the model that the dataframes to fit satisfy being **balanced**,\nand there are **no zeros** at the beginning of the series, there are  **no negative values**, since that\nhas bad interactions with the multiplicative model.\n\n```python\nfrom ESRNN.m4_data import prepare_m4_data\nfrom ESRNN.utils_evaluation import evaluate_prediction_owa\n\nfrom ESRNN import ESRNN\n\nX_train_df, y_train_df, X_test_df, y_test_df = prepare_m4_data(dataset_name='Yearly',\n                                                               directory = './data',\n                                                               num_obs=1000)\n\n# Instantiate model\nmodel = ESRNN(max_epochs=25, freq_of_test=5, batch_size=4, learning_rate=1e-4,\n              per_series_lr_multip=0.8, lr_scheduler_step_size=10,\n              lr_decay=0.1, gradient_clipping_threshold=50,\n              rnn_weight_decay=0.0, level_variability_penalty=100,\n              testing_percentile=50, training_percentile=50,\n              ensemble=False, max_periods=25, seasonality=[],\n              input_size=4, output_size=6,\n              cell_type='LSTM', state_hsize=40,\n              dilations=[[1], [6]], add_nl_layer=False,\n              random_seed=1, device='cpu')\n\n# Fit model\n# If y_test_df is provided the model\n# will evaluate predictions on\n# this set every freq_test epochs\nmodel.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n\n# Predict on test set\ny_hat_df = model.predict(X_test_df)\n\n# Evaluate predictions\nfinal_owa, final_mase, final_smape = evaluate_prediction_owa(y_hat_df, y_train_df,\n                                                             X_test_df, y_test_df,\n                                                             naive2_seasonality=1)\n```\n## Overall Weighted Average\n\nA metric that is useful for quantifying the aggregate error of a specific model for various time series is the Overall Weighted Average (OWA) proposed for the M4 competition. This metric is calculated by obtaining the average of the symmetric mean absolute percentage error (sMAPE) and the mean absolute scaled error (MASE) for all the time series of the model and also calculating it for the Naive2 predictions. Both sMAPE and MASE are scale independent. These measurements are calculated as follows:\n\n![OWA](https://raw.githubusercontent.com/kdgutier/esrnn_torch/master/.github/images/metrics.png)\n\n\n\n## Current Results\nHere we used the model directly to compare to the original implementation. It is worth noticing that these results do not include the ensemble methods mentioned in the [ESRNN paper](https://www.sciencedirect.com/science/article/pii/S0169207019301153).<br/>\n[Results of the M4 competition](https://www.researchgate.net/publication/325901666_The_M4_Competition_Results_findings_conclusion_and_way_forward).\n<br/>\n\n| DATASET   | OUR OWA | M4 OWA (Smyl) |\n|-----------|:---------:|:--------:|\n| Yearly    | 0.785   | 0.778  |\n| Quarterly | 0.879   | 0.847  |\n| Monthly   | 0.872   | 0.836  |\n| Hourly    | 0.615   | 0.920  |\n| Weekly    | 0.952   | 0.920  |\n| Daily     | 0.968   | 0.920  |\n\n\n## Replicating M4 results\n\n\nReplicating the M4 results is as easy as running the following line of code (for each frequency) after installing the package via pip:\n\n```console\npython -m ESRNN.m4_run --dataset 'Yearly' --results_directory '/some/path' \\\n                       --gpu_id 0 --use_cpu 0\n```\n\nUse `--help` to get the description of each argument:\n\n```console\npython -m ESRNN.m4_run --help\n```\n\n## Authors\n* **Kin Gutierrez** - [kdgutier](https://github.com/kdgutier)\n* **Cristian Challu** - [cristianchallu](https://github.com/cristianchallu)\n* **Federico Garza** - [FedericoGarza](https://github.com/FedericoGarza)\n\n## License\nThis project is licensed under the MIT License - see the [LICENSE](https://github.com/kdgutier/esrnn_torch/blob/master/LICENSE) file for details.\n\n\n## REFERENCES\n1. [A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting](https://www.sciencedirect.com/science/article/pii/S0169207019301153)\n2. [The M4 Competition: Results, findings, conclusion and way forward](https://www.researchgate.net/publication/325901666_The_M4_Competition_Results_findings_conclusion_and_way_forward)\n3. [M4 Competition Data](https://github.com/M4Competition/M4-methods/tree/master/Dataset)\n4. [Dilated Recurrent Neural Networks](https://papers.nips.cc/paper/6613-dilated-recurrent-neural-networks.pdf)\n5. [Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech Recognition](https://arxiv.org/abs/1701.03360)\n6. [A Dual-Stage Attention-Based recurrent neural network for time series prediction](https://arxiv.org/abs/1704.02971)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kdgutier/esrnn_torch", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "ESRNN", "package_url": "https://pypi.org/project/ESRNN/", "platform": "", "project_url": "https://pypi.org/project/ESRNN/", "project_urls": {"Homepage": "https://github.com/kdgutier/esrnn_torch"}, "release_url": "https://pypi.org/project/ESRNN/0.1.2/", "requires_dist": ["numpy (==1.16.1)", "pandas (==0.25.2)", "torch (>=1.3.1)"], "requires_python": ">=3.6", "summary": "Pytorch implementation of the ESRNN", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://github.com/kdgutier/esrnn_torch/tree/pip\" rel=\"nofollow\"><img alt=\"Build\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/254910b4890fd46bf7d9aeb9029ed7c085af334d/68747470733a2f2f6769746875622e636f6d2f6b646775746965722f6573726e6e5f746f7263682f776f726b666c6f77732f507974686f6e2532307061636b6167652f62616467652e7376673f6272616e63683d706970\"></a>\n<a href=\"https://pypi.python.org/pypi/ESRNN/\" rel=\"nofollow\"><img alt=\"PyPI version fury.io\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/50fdacae688080234335b1301750802cdfe67dae/68747470733a2f2f62616467652e667572792e696f2f70792f4553524e4e2e737667\"></a>\n<a href=\"https://pepy.tech/project/esrnn\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a6b441ea2083234c0203d6ff8cc76f71e5315793/68747470733a2f2f706570792e746563682f62616467652f6573726e6e\"></a>\n<a href=\"https://www.python.org/downloads/release/python-360+/\" rel=\"nofollow\"><img alt=\"Python 3.6+\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6a042d910c74fbce532a01da853019c164ef42a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362b2d626c75652e737667\"></a>\n<a href=\"https://github.com/kdgutier/esrnn_torch/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5aab1d039acf22567ba072834df6bce204ac48ad/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d677265656e2e737667\"></a></p>\n<h1>Pytorch Implementation of the ES-RNN</h1>\n<p>In this project we coded a pytorch class for the ES-RNN algorithm proposed by Smyl, winning submission of the M4 Forecasting Competition. The class wraps fit and predict methods to facilitate interaction with Machine Learning pipelines along with evaluation and data wrangling utility.</p>\n<h2>Installation Prerequisites</h2>\n<ul>\n<li>numpy==1.16.1</li>\n<li>pandas==0.25.2</li>\n<li>pytorch&gt;=1.3.1</li>\n</ul>\n<h2>Installation</h2>\n<p>This code is a work in progress, any contributions or issues are welcome on\nGitHub at: <a href=\"https://github.com/kdgutier/esrnn_torch\" rel=\"nofollow\">https://github.com/kdgutier/esrnn_torch</a></p>\n<p>You can install the <em>released version</em> of <code>ESRNN</code> from the <a href=\"https://pypi.org\" rel=\"nofollow\">Python package index</a> with:</p>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">ESRNN</span>\n</pre>\n<h2>Usage Example</h2>\n<p>Make sure on use of the model that the dataframes to fit satisfy being <strong>balanced</strong>,\nand there are <strong>no zeros</strong> at the beginning of the series, there are  <strong>no negative values</strong>, since that\nhas bad interactions with the multiplicative model.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ESRNN.m4_data</span> <span class=\"kn\">import</span> <span class=\"n\">prepare_m4_data</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ESRNN.utils_evaluation</span> <span class=\"kn\">import</span> <span class=\"n\">evaluate_prediction_owa</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">ESRNN</span> <span class=\"kn\">import</span> <span class=\"n\">ESRNN</span>\n\n<span class=\"n\">X_train_df</span><span class=\"p\">,</span> <span class=\"n\">y_train_df</span><span class=\"p\">,</span> <span class=\"n\">X_test_df</span><span class=\"p\">,</span> <span class=\"n\">y_test_df</span> <span class=\"o\">=</span> <span class=\"n\">prepare_m4_data</span><span class=\"p\">(</span><span class=\"n\">dataset_name</span><span class=\"o\">=</span><span class=\"s1\">'Yearly'</span><span class=\"p\">,</span>\n                                                               <span class=\"n\">directory</span> <span class=\"o\">=</span> <span class=\"s1\">'./data'</span><span class=\"p\">,</span>\n                                                               <span class=\"n\">num_obs</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Instantiate model</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ESRNN</span><span class=\"p\">(</span><span class=\"n\">max_epochs</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">,</span> <span class=\"n\">freq_of_test</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">1e-4</span><span class=\"p\">,</span>\n              <span class=\"n\">per_series_lr_multip</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">lr_scheduler_step_size</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n              <span class=\"n\">lr_decay</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">gradient_clipping_threshold</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n              <span class=\"n\">rnn_weight_decay</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">level_variability_penalty</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n              <span class=\"n\">testing_percentile</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"n\">training_percentile</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n              <span class=\"n\">ensemble</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">max_periods</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">,</span> <span class=\"n\">seasonality</span><span class=\"o\">=</span><span class=\"p\">[],</span>\n              <span class=\"n\">input_size</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">output_size</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">,</span>\n              <span class=\"n\">cell_type</span><span class=\"o\">=</span><span class=\"s1\">'LSTM'</span><span class=\"p\">,</span> <span class=\"n\">state_hsize</span><span class=\"o\">=</span><span class=\"mi\">40</span><span class=\"p\">,</span>\n              <span class=\"n\">dilations</span><span class=\"o\">=</span><span class=\"p\">[[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">6</span><span class=\"p\">]],</span> <span class=\"n\">add_nl_layer</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n              <span class=\"n\">random_seed</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">'cpu'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Fit model</span>\n<span class=\"c1\"># If y_test_df is provided the model</span>\n<span class=\"c1\"># will evaluate predictions on</span>\n<span class=\"c1\"># this set every freq_test epochs</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train_df</span><span class=\"p\">,</span> <span class=\"n\">y_train_df</span><span class=\"p\">,</span> <span class=\"n\">X_test_df</span><span class=\"p\">,</span> <span class=\"n\">y_test_df</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Predict on test set</span>\n<span class=\"n\">y_hat_df</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test_df</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Evaluate predictions</span>\n<span class=\"n\">final_owa</span><span class=\"p\">,</span> <span class=\"n\">final_mase</span><span class=\"p\">,</span> <span class=\"n\">final_smape</span> <span class=\"o\">=</span> <span class=\"n\">evaluate_prediction_owa</span><span class=\"p\">(</span><span class=\"n\">y_hat_df</span><span class=\"p\">,</span> <span class=\"n\">y_train_df</span><span class=\"p\">,</span>\n                                                             <span class=\"n\">X_test_df</span><span class=\"p\">,</span> <span class=\"n\">y_test_df</span><span class=\"p\">,</span>\n                                                             <span class=\"n\">naive2_seasonality</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<h2>Overall Weighted Average</h2>\n<p>A metric that is useful for quantifying the aggregate error of a specific model for various time series is the Overall Weighted Average (OWA) proposed for the M4 competition. This metric is calculated by obtaining the average of the symmetric mean absolute percentage error (sMAPE) and the mean absolute scaled error (MASE) for all the time series of the model and also calculating it for the Naive2 predictions. Both sMAPE and MASE are scale independent. These measurements are calculated as follows:</p>\n<p><img alt=\"OWA\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9b5abe4225e5f080a5d2cd0456cae0e00114ed57/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6b646775746965722f6573726e6e5f746f7263682f6d61737465722f2e6769746875622f696d616765732f6d6574726963732e706e67\"></p>\n<h2>Current Results</h2>\n<p>Here we used the model directly to compare to the original implementation. It is worth noticing that these results do not include the ensemble methods mentioned in the <a href=\"https://www.sciencedirect.com/science/article/pii/S0169207019301153\" rel=\"nofollow\">ESRNN paper</a>.<br>\n<a href=\"https://www.researchgate.net/publication/325901666_The_M4_Competition_Results_findings_conclusion_and_way_forward\" rel=\"nofollow\">Results of the M4 competition</a>.\n<br></p>\n<table>\n<thead>\n<tr>\n<th>DATASET</th>\n<th align=\"center\">OUR OWA</th>\n<th align=\"center\">M4 OWA (Smyl)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Yearly</td>\n<td align=\"center\">0.785</td>\n<td align=\"center\">0.778</td>\n</tr>\n<tr>\n<td>Quarterly</td>\n<td align=\"center\">0.879</td>\n<td align=\"center\">0.847</td>\n</tr>\n<tr>\n<td>Monthly</td>\n<td align=\"center\">0.872</td>\n<td align=\"center\">0.836</td>\n</tr>\n<tr>\n<td>Hourly</td>\n<td align=\"center\">0.615</td>\n<td align=\"center\">0.920</td>\n</tr>\n<tr>\n<td>Weekly</td>\n<td align=\"center\">0.952</td>\n<td align=\"center\">0.920</td>\n</tr>\n<tr>\n<td>Daily</td>\n<td align=\"center\">0.968</td>\n<td align=\"center\">0.920</td>\n</tr></tbody></table>\n<h2>Replicating M4 results</h2>\n<p>Replicating the M4 results is as easy as running the following line of code (for each frequency) after installing the package via pip:</p>\n<pre><span class=\"go\">python -m ESRNN.m4_run --dataset 'Yearly' --results_directory '/some/path' \\</span>\n<span class=\"go\">                       --gpu_id 0 --use_cpu 0</span>\n</pre>\n<p>Use <code>--help</code> to get the description of each argument:</p>\n<pre><span class=\"go\">python -m ESRNN.m4_run --help</span>\n</pre>\n<h2>Authors</h2>\n<ul>\n<li><strong>Kin Gutierrez</strong> - <a href=\"https://github.com/kdgutier\" rel=\"nofollow\">kdgutier</a></li>\n<li><strong>Cristian Challu</strong> - <a href=\"https://github.com/cristianchallu\" rel=\"nofollow\">cristianchallu</a></li>\n<li><strong>Federico Garza</strong> - <a href=\"https://github.com/FedericoGarza\" rel=\"nofollow\">FedericoGarza</a></li>\n</ul>\n<h2>License</h2>\n<p>This project is licensed under the MIT License - see the <a href=\"https://github.com/kdgutier/esrnn_torch/blob/master/LICENSE\" rel=\"nofollow\">LICENSE</a> file for details.</p>\n<h2>REFERENCES</h2>\n<ol>\n<li><a href=\"https://www.sciencedirect.com/science/article/pii/S0169207019301153\" rel=\"nofollow\">A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting</a></li>\n<li><a href=\"https://www.researchgate.net/publication/325901666_The_M4_Competition_Results_findings_conclusion_and_way_forward\" rel=\"nofollow\">The M4 Competition: Results, findings, conclusion and way forward</a></li>\n<li><a href=\"https://github.com/M4Competition/M4-methods/tree/master/Dataset\" rel=\"nofollow\">M4 Competition Data</a></li>\n<li><a href=\"https://papers.nips.cc/paper/6613-dilated-recurrent-neural-networks.pdf\" rel=\"nofollow\">Dilated Recurrent Neural Networks</a></li>\n<li><a href=\"https://arxiv.org/abs/1701.03360\" rel=\"nofollow\">Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech Recognition</a></li>\n<li><a href=\"https://arxiv.org/abs/1704.02971\" rel=\"nofollow\">A Dual-Stage Attention-Based recurrent neural network for time series prediction</a></li>\n</ol>\n\n          </div>"}, "last_serial": 7078658, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "821d4b5c20cd2900c22e1c26fa4e4a05", "sha256": "0c097c2a6828240cb7c15091be07a74dfbc9a9c4c0927639e400829bbb6f7d6a"}, "downloads": -1, "filename": "ESRNN-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "821d4b5c20cd2900c22e1c26fa4e4a05", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32564, "upload_time": "2020-04-20T23:31:02", "upload_time_iso_8601": "2020-04-20T23:31:02.373825Z", "url": "https://files.pythonhosted.org/packages/0c/0c/4fde28ec0a55d4eb1972c6b33be94ac7805ad89c25ff3189ea8a94868869/ESRNN-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "51712c912e34ee62b1073de558f2ef90", "sha256": "260e236e937523e8a004bfdf5add5e2a049d9b11f3e4598e2e614fef4578586d"}, "downloads": -1, "filename": "ESRNN-0.1.0.tar.gz", "has_sig": false, "md5_digest": "51712c912e34ee62b1073de558f2ef90", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 27848, "upload_time": "2020-04-20T23:31:04", "upload_time_iso_8601": "2020-04-20T23:31:04.330898Z", "url": "https://files.pythonhosted.org/packages/56/bd/5b7e08ddf461d574b3fe992ac19da65e4546ae8f465e4d3d6e9156d2e244/ESRNN-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "157282304685575b6a61d407013aeb88", "sha256": "67aa99bcdfb1d18dbe105d849a97aa6d611dcceaddb9db95e09032a9ec334d09"}, "downloads": -1, "filename": "ESRNN-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "157282304685575b6a61d407013aeb88", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 32986, "upload_time": "2020-04-22T18:03:43", "upload_time_iso_8601": "2020-04-22T18:03:43.853139Z", "url": "https://files.pythonhosted.org/packages/26/32/7d509623f1b861cb9621a947dfde13f57a4d151a31124e87ff3763e58934/ESRNN-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a0d69c03a605e02b9faa3e4adf2a919e", "sha256": "bf1746a5d6bedfd35d7783d2ddc0ad6352a30680d039430767abf04a548cd037"}, "downloads": -1, "filename": "ESRNN-0.1.1.tar.gz", "has_sig": false, "md5_digest": "a0d69c03a605e02b9faa3e4adf2a919e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 77864, "upload_time": "2020-04-22T18:03:46", "upload_time_iso_8601": "2020-04-22T18:03:46.042181Z", "url": "https://files.pythonhosted.org/packages/14/71/2234df646020f12740330c09dc84b0d81c732da0932565d0ce207ca76105/ESRNN-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "f1589061009b5ee29aa65a08804ec193", "sha256": "77276150081641aa5376bc24398bafb1aba3c6e0791b2d660f2c59eb3e05ca36"}, "downloads": -1, "filename": "ESRNN-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f1589061009b5ee29aa65a08804ec193", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 33000, "upload_time": "2020-04-22T18:22:13", "upload_time_iso_8601": "2020-04-22T18:22:13.441069Z", "url": "https://files.pythonhosted.org/packages/c9/be/925acee62e223c081d05b4a76cbd1301a5a0472a4cf2665981c09d57a9c2/ESRNN-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e0398b00d5484903026e7bac284eddc5", "sha256": "1bf3446a942c148520315493837d93700d6042c30524fbbc7302cd116496eff8"}, "downloads": -1, "filename": "ESRNN-0.1.2.tar.gz", "has_sig": false, "md5_digest": "e0398b00d5484903026e7bac284eddc5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 77897, "upload_time": "2020-04-22T18:22:15", "upload_time_iso_8601": "2020-04-22T18:22:15.276655Z", "url": "https://files.pythonhosted.org/packages/e6/b9/616f154dcc3fc08f141bef2b795aef981d6a5913a2613f7dd6fe65422a82/ESRNN-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f1589061009b5ee29aa65a08804ec193", "sha256": "77276150081641aa5376bc24398bafb1aba3c6e0791b2d660f2c59eb3e05ca36"}, "downloads": -1, "filename": "ESRNN-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f1589061009b5ee29aa65a08804ec193", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 33000, "upload_time": "2020-04-22T18:22:13", "upload_time_iso_8601": "2020-04-22T18:22:13.441069Z", "url": "https://files.pythonhosted.org/packages/c9/be/925acee62e223c081d05b4a76cbd1301a5a0472a4cf2665981c09d57a9c2/ESRNN-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e0398b00d5484903026e7bac284eddc5", "sha256": "1bf3446a942c148520315493837d93700d6042c30524fbbc7302cd116496eff8"}, "downloads": -1, "filename": "ESRNN-0.1.2.tar.gz", "has_sig": false, "md5_digest": "e0398b00d5484903026e7bac284eddc5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 77897, "upload_time": "2020-04-22T18:22:15", "upload_time_iso_8601": "2020-04-22T18:22:15.276655Z", "url": "https://files.pythonhosted.org/packages/e6/b9/616f154dcc3fc08f141bef2b795aef981d6a5913a2613f7dd6fe65422a82/ESRNN-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:36 2020"}