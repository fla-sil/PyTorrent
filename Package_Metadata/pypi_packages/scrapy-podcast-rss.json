{"info": {"author": "Iacopo Garizio", "author_email": "info@iacopogarizio.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# scrapy-podcast-rss\n[![Build Status](https://travis-ci.org/igarizio/scrapy-podcast-rss.svg?branch=master)](https://travis-ci.org/igarizio/scrapy-podcast-rss)  \nThis package provides a Scrapy pipeline and items to generate a podcast RSS feed \nfrom scraped information. It also allows to save the content locally or in an S3 \nbucket. You can then point your podcast player to the URL of the file and \nlisten to its content.\n\n## Installation\nInstall scrapy-podcast-rss using ``pip``:\n```console\n$ pip install scrapy-podcast-rss\n```\n\n## Configuration\n1. You need to define ``OUTPUT_URI`` in your ``settings.py`` file, this will\ndetermine where your feed will be stored. For example:\n    ```python\n    OUTPUT_URI = './my-podcast.xml'  # Local file.\n    OUTPUT_URI = 's3://my-bucket/my-podcast.xml'  # S3 bucket (read note on S3 storage).\n    ```\n2. Add ``PodcastPipeline`` in ``ITEM_PIPELINES`` in your ``settings.py`` file:\n    ```python\n    ITEM_PIPELINES = {\n        'scrapy_podcast_rss.pipelines.PodcastPipeline': 300,\n    }\n    ```\n\n## Usage\nscrapy-podcast-rss defines two special items:\n* ``PodcastDataItem``: Stores information about the podcast.\n* ``PodcastEpisodeItem``: Stores information about each episode of the podcast.\n\nYou must yield one ``PodcastDataItem`` and one ``PodcastEpisodeItem`` for each\nepisode you want to export, before your spider closes.\n\nHere is the information you can currently store in each item (you need to use\nthe same names):\n* ``PodcastDataItem``:\n    * ``title``: Title of the podcast.\n    * ``description``: Description of the podcast.\n    * ``url``: URL referencing the podcast.\n    * ``image_url``: Main image of the podcast.\n* ``PodcastDataItem``:\n    * ``title``: Title of the episode.\n    * ``description``: Description of the episode.\n    * ``publication_date``: Date of publication (``datetime`` object with timezone).\n    * ``audio_url``: URL of the audio.\n    * ``guid``: Unique identifier of the episode.\n\n## Example\nYou can find a minimal example of a spider using this package here: \n[scrapy-podcast-rss-example](https://github.com/igarizio/scrapy-podcast-rss-example).  \nYou can also find an example of the package being used in an AWS Lambda function here: [scrapy-podcast-rss-serverless](https://github.com/igarizio/scrapy-podcast-rss-serverless).\n\n### Spider example\n```python\nimport datetime\nimport scrapy\nimport pytz\nfrom scrapy_podcast_rss import PodcastEpisodeItem, PodcastDataItem\n\n\nclass SimpleSpider(scrapy.Spider):\n    name = \"simple_spider\"\n    start_urls = ['http://example.com/']\n    custom_settings = {\n        'OUTPUT_URI': './my-podcast.xml',\n        'ITEM_PIPELINES': {'scrapy_podcast_rss.pipelines.PodcastPipeline': 300, }\n    }\n\n    def parse(self, response):\n        podcast_data_item = PodcastDataItem()\n        podcast_data_item['title'] = \"Podcast title\"\n        podcast_data_item['description'] = \"Description of the podcast.\"\n        podcast_data_item['url'] = \"Podcast's URL\"\n        podcast_data_item['image_url'] = \"https://live.staticflickr.com/4211/35400224382_9edcb984e5_c.jpg\"  # Sample image\n        yield podcast_data_item\n\n        episode_item = PodcastEpisodeItem()\n        episode_item['title'] = \"Episode title\"\n        episode_item['description'] = \"Episode description\"\n        pub_date_tz = datetime.datetime.strptime(\"01/01/2020\", \"%m/%d/%Y\").replace(tzinfo=pytz.UTC)\n        episode_item['publication_date'] = pub_date_tz  # Publication date NEEDS to have a TIME ZONE.\n        episode_item['guid'] = \"Episode guid\"  # Simulated identifier.\n        episode_item['audio_url'] = \"https://ia801803.us.archive.org/13/items/MOZARTSerenadeEineKleineNachtmusikK.\" \\\n                                    \"525-NEWTRANSFER01.I.Allegro/01.I.Allegro.mp3 \"  # Sample audio url.\n        yield episode_item\n```\n\n### Note on using S3 as storage\nTo use S3 storage locations, you can install scrapy-podcast-rss by doing:\n```console\n$ pip install scrapy-podcast-rss[s3_storage]\n```\nThis will simply include ``boto3`` in the dependencies.  \nOnce installed, you will need to have your credentials configured\n([boto3 quickstart guide](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html)).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/igarizio/scrapy-podcast-rss", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "scrapy-podcast-rss", "package_url": "https://pypi.org/project/scrapy-podcast-rss/", "platform": "", "project_url": "https://pypi.org/project/scrapy-podcast-rss/", "project_urls": {"Homepage": "https://github.com/igarizio/scrapy-podcast-rss"}, "release_url": "https://pypi.org/project/scrapy-podcast-rss/0.0.3/", "requires_dist": ["Scrapy (>=1.7.3)", "feedgen (==0.9.0)", "boto3; extra == 's3_storage'", "pytest (==5.2.4); extra == 'tests'"], "requires_python": "", "summary": "Scrapy pipeline and items to create and store RSS feeds for podcasts.", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>scrapy-podcast-rss</h1>\n<p><a href=\"https://travis-ci.org/igarizio/scrapy-podcast-rss\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c9e9f92cae6055ceabe9479ebec9efdb2d94b4bf/68747470733a2f2f7472617669732d63692e6f72672f69676172697a696f2f7363726170792d706f64636173742d7273732e7376673f6272616e63683d6d6173746572\"></a><br>\nThis package provides a Scrapy pipeline and items to generate a podcast RSS feed\nfrom scraped information. It also allows to save the content locally or in an S3\nbucket. You can then point your podcast player to the URL of the file and\nlisten to its content.</p>\n<h2>Installation</h2>\n<p>Install scrapy-podcast-rss using <code>pip</code>:</p>\n<pre><span class=\"gp\">$</span> pip install scrapy-podcast-rss\n</pre>\n<h2>Configuration</h2>\n<ol>\n<li>You need to define <code>OUTPUT_URI</code> in your <code>settings.py</code> file, this will\ndetermine where your feed will be stored. For example:\n<pre><span class=\"n\">OUTPUT_URI</span> <span class=\"o\">=</span> <span class=\"s1\">'./my-podcast.xml'</span>  <span class=\"c1\"># Local file.</span>\n<span class=\"n\">OUTPUT_URI</span> <span class=\"o\">=</span> <span class=\"s1\">'s3://my-bucket/my-podcast.xml'</span>  <span class=\"c1\"># S3 bucket (read note on S3 storage).</span>\n</pre>\n</li>\n<li>Add <code>PodcastPipeline</code> in <code>ITEM_PIPELINES</code> in your <code>settings.py</code> file:\n<pre><span class=\"n\">ITEM_PIPELINES</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'scrapy_podcast_rss.pipelines.PodcastPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre>\n</li>\n</ol>\n<h2>Usage</h2>\n<p>scrapy-podcast-rss defines two special items:</p>\n<ul>\n<li><code>PodcastDataItem</code>: Stores information about the podcast.</li>\n<li><code>PodcastEpisodeItem</code>: Stores information about each episode of the podcast.</li>\n</ul>\n<p>You must yield one <code>PodcastDataItem</code> and one <code>PodcastEpisodeItem</code> for each\nepisode you want to export, before your spider closes.</p>\n<p>Here is the information you can currently store in each item (you need to use\nthe same names):</p>\n<ul>\n<li><code>PodcastDataItem</code>:\n<ul>\n<li><code>title</code>: Title of the podcast.</li>\n<li><code>description</code>: Description of the podcast.</li>\n<li><code>url</code>: URL referencing the podcast.</li>\n<li><code>image_url</code>: Main image of the podcast.</li>\n</ul>\n</li>\n<li><code>PodcastDataItem</code>:\n<ul>\n<li><code>title</code>: Title of the episode.</li>\n<li><code>description</code>: Description of the episode.</li>\n<li><code>publication_date</code>: Date of publication (<code>datetime</code> object with timezone).</li>\n<li><code>audio_url</code>: URL of the audio.</li>\n<li><code>guid</code>: Unique identifier of the episode.</li>\n</ul>\n</li>\n</ul>\n<h2>Example</h2>\n<p>You can find a minimal example of a spider using this package here:\n<a href=\"https://github.com/igarizio/scrapy-podcast-rss-example\" rel=\"nofollow\">scrapy-podcast-rss-example</a>.<br>\nYou can also find an example of the package being used in an AWS Lambda function here: <a href=\"https://github.com/igarizio/scrapy-podcast-rss-serverless\" rel=\"nofollow\">scrapy-podcast-rss-serverless</a>.</p>\n<h3>Spider example</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">datetime</span>\n<span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pytz</span>\n<span class=\"kn\">from</span> <span class=\"nn\">scrapy_podcast_rss</span> <span class=\"kn\">import</span> <span class=\"n\">PodcastEpisodeItem</span><span class=\"p\">,</span> <span class=\"n\">PodcastDataItem</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">SimpleSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s2\">\"simple_spider\"</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'http://example.com/'</span><span class=\"p\">]</span>\n    <span class=\"n\">custom_settings</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n        <span class=\"s1\">'OUTPUT_URI'</span><span class=\"p\">:</span> <span class=\"s1\">'./my-podcast.xml'</span><span class=\"p\">,</span>\n        <span class=\"s1\">'ITEM_PIPELINES'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'scrapy_podcast_rss.pipelines.PodcastPipeline'</span><span class=\"p\">:</span> <span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"n\">podcast_data_item</span> <span class=\"o\">=</span> <span class=\"n\">PodcastDataItem</span><span class=\"p\">()</span>\n        <span class=\"n\">podcast_data_item</span><span class=\"p\">[</span><span class=\"s1\">'title'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"Podcast title\"</span>\n        <span class=\"n\">podcast_data_item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"Description of the podcast.\"</span>\n        <span class=\"n\">podcast_data_item</span><span class=\"p\">[</span><span class=\"s1\">'url'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"Podcast's URL\"</span>\n        <span class=\"n\">podcast_data_item</span><span class=\"p\">[</span><span class=\"s1\">'image_url'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"https://live.staticflickr.com/4211/35400224382_9edcb984e5_c.jpg\"</span>  <span class=\"c1\"># Sample image</span>\n        <span class=\"k\">yield</span> <span class=\"n\">podcast_data_item</span>\n\n        <span class=\"n\">episode_item</span> <span class=\"o\">=</span> <span class=\"n\">PodcastEpisodeItem</span><span class=\"p\">()</span>\n        <span class=\"n\">episode_item</span><span class=\"p\">[</span><span class=\"s1\">'title'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"Episode title\"</span>\n        <span class=\"n\">episode_item</span><span class=\"p\">[</span><span class=\"s1\">'description'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"Episode description\"</span>\n        <span class=\"n\">pub_date_tz</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">strptime</span><span class=\"p\">(</span><span class=\"s2\">\"01/01/2020\"</span><span class=\"p\">,</span> <span class=\"s2\">\"%m/</span><span class=\"si\">%d</span><span class=\"s2\">/%Y\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"n\">tzinfo</span><span class=\"o\">=</span><span class=\"n\">pytz</span><span class=\"o\">.</span><span class=\"n\">UTC</span><span class=\"p\">)</span>\n        <span class=\"n\">episode_item</span><span class=\"p\">[</span><span class=\"s1\">'publication_date'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">pub_date_tz</span>  <span class=\"c1\"># Publication date NEEDS to have a TIME ZONE.</span>\n        <span class=\"n\">episode_item</span><span class=\"p\">[</span><span class=\"s1\">'guid'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"Episode guid\"</span>  <span class=\"c1\"># Simulated identifier.</span>\n        <span class=\"n\">episode_item</span><span class=\"p\">[</span><span class=\"s1\">'audio_url'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">\"https://ia801803.us.archive.org/13/items/MOZARTSerenadeEineKleineNachtmusikK.\"</span> \\\n                                    <span class=\"s2\">\"525-NEWTRANSFER01.I.Allegro/01.I.Allegro.mp3 \"</span>  <span class=\"c1\"># Sample audio url.</span>\n        <span class=\"k\">yield</span> <span class=\"n\">episode_item</span>\n</pre>\n<h3>Note on using S3 as storage</h3>\n<p>To use S3 storage locations, you can install scrapy-podcast-rss by doing:</p>\n<pre><span class=\"gp\">$</span> pip install scrapy-podcast-rss<span class=\"o\">[</span>s3_storage<span class=\"o\">]</span>\n</pre>\n<p>This will simply include <code>boto3</code> in the dependencies.<br>\nOnce installed, you will need to have your credentials configured\n(<a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\" rel=\"nofollow\">boto3 quickstart guide</a>).</p>\n\n          </div>"}, "last_serial": 6953221, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "2ce742cbf9cff9a57156daddd1cac31d", "sha256": "18d7b9cfc85f16d03a2120cfb88becdf42265be5f9f28d4dc959cc34ecd5798e"}, "downloads": -1, "filename": "scrapy_podcast_rss-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2ce742cbf9cff9a57156daddd1cac31d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3204, "upload_time": "2020-03-30T08:55:56", "upload_time_iso_8601": "2020-03-30T08:55:56.713795Z", "url": "https://files.pythonhosted.org/packages/6b/0d/ec3efa735154dd25265a31b6b491a16956428a760a80454b7ee5acae16f6/scrapy_podcast_rss-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b6b3d8d84abb79f34b50408935254a2", "sha256": "f501ee579fc7e203ab8bfd2d17fa141d7cbb40e759cb54352cdd8eb38fbba7ef"}, "downloads": -1, "filename": "scrapy-podcast-rss-0.0.1.tar.gz", "has_sig": false, "md5_digest": "8b6b3d8d84abb79f34b50408935254a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5182, "upload_time": "2020-03-30T08:56:03", "upload_time_iso_8601": "2020-03-30T08:56:03.083353Z", "url": "https://files.pythonhosted.org/packages/6e/3f/2b670c1ba71d2bd3aad4dd3f4c7c6a64cd0d863bd9c6d768e9b568258d7d/scrapy-podcast-rss-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "c1ba988a897bda875d1517949d8b00b1", "sha256": "6d282beee5b9fce1c995e5f5dd3bbca5d8419d6759b940bab81868e4d22d759b"}, "downloads": -1, "filename": "scrapy_podcast_rss-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "c1ba988a897bda875d1517949d8b00b1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7674, "upload_time": "2020-03-30T10:19:18", "upload_time_iso_8601": "2020-03-30T10:19:18.431481Z", "url": "https://files.pythonhosted.org/packages/3e/4f/94ed0faeb52624fed72754ad3dc1bb37aacf7d88b354bb287b00a1442505/scrapy_podcast_rss-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5950f2f7e66df956e8038f649774857c", "sha256": "e3addcf7953f3b9a5093770bf97479dbd7977c869ccd87068149671686c762c1"}, "downloads": -1, "filename": "scrapy-podcast-rss-0.0.2.tar.gz", "has_sig": false, "md5_digest": "5950f2f7e66df956e8038f649774857c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5226, "upload_time": "2020-03-30T10:19:20", "upload_time_iso_8601": "2020-03-30T10:19:20.043353Z", "url": "https://files.pythonhosted.org/packages/c7/a0/aa0f29a6f7ec1ce93ec168594a6470c56750ae68ebe3c3d51a7efeaa72fe/scrapy-podcast-rss-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "6821cc51e69b781c3820635519ecff4b", "sha256": "b8e18238947384e73be32fe22b6761544749d9025ed2dfa7b3f350752e098c78"}, "downloads": -1, "filename": "scrapy_podcast_rss-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "6821cc51e69b781c3820635519ecff4b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7983, "upload_time": "2020-04-04T23:31:37", "upload_time_iso_8601": "2020-04-04T23:31:37.880670Z", "url": "https://files.pythonhosted.org/packages/ea/35/277216ff6924be5bebabcb6ea95d3547fbc8c93ab3298f32effbfde5bcc0/scrapy_podcast_rss-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "774878752055e03ac97c782316e22835", "sha256": "b358af013b2dcd7dbe6f91ff64ebe6ddb44919c90f57cc9754e7acd488beeda8"}, "downloads": -1, "filename": "scrapy-podcast-rss-0.0.3.tar.gz", "has_sig": false, "md5_digest": "774878752055e03ac97c782316e22835", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5687, "upload_time": "2020-04-04T23:31:39", "upload_time_iso_8601": "2020-04-04T23:31:39.189552Z", "url": "https://files.pythonhosted.org/packages/2f/c9/51072b304479d6debd68f2760e7017cb10d0f302d146555151e6fbdfd5d6/scrapy-podcast-rss-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6821cc51e69b781c3820635519ecff4b", "sha256": "b8e18238947384e73be32fe22b6761544749d9025ed2dfa7b3f350752e098c78"}, "downloads": -1, "filename": "scrapy_podcast_rss-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "6821cc51e69b781c3820635519ecff4b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7983, "upload_time": "2020-04-04T23:31:37", "upload_time_iso_8601": "2020-04-04T23:31:37.880670Z", "url": "https://files.pythonhosted.org/packages/ea/35/277216ff6924be5bebabcb6ea95d3547fbc8c93ab3298f32effbfde5bcc0/scrapy_podcast_rss-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "774878752055e03ac97c782316e22835", "sha256": "b358af013b2dcd7dbe6f91ff64ebe6ddb44919c90f57cc9754e7acd488beeda8"}, "downloads": -1, "filename": "scrapy-podcast-rss-0.0.3.tar.gz", "has_sig": false, "md5_digest": "774878752055e03ac97c782316e22835", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5687, "upload_time": "2020-04-04T23:31:39", "upload_time_iso_8601": "2020-04-04T23:31:39.189552Z", "url": "https://files.pythonhosted.org/packages/2f/c9/51072b304479d6debd68f2760e7017cb10d0f302d146555151e6fbdfd5d6/scrapy-podcast-rss-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:44 2020"}