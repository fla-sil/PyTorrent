{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Programming Language :: Python :: 3"], "description": "# TrollHunter\n\nTrollHunter is a Twitter Crawler & News Website Indexer.\nIt aims at finding Troll Farmers & Fake News on Twitter.\n\nIt composed of three parts:\n\n- Twint API to extract information about a tweet or a user\n- News Indexer which indexes all the articles of a website and extract its keywords\n- Analysis of the tweets and news\n\n## Installation\n\nYou can either run\n\n```Bash\npip3 install TrollHunter\n```\n\nor clone the project and run\n\n```Bash\npip3 install -r requirements.txt\n```\n\n### Docker\n\nTrollHunter requires many services to run\n\n- ELK ( Elastic Search, Logstash, Kibana)\n- InfluxDb & Grafana\n- RabbitMQ\n\nYou can either launch them individually if you already have them setup or use our `docker-compose.yml`\n\n- Install Docker\n- Run `docker-compose up -d`\n\n### Setup\nChange the `.env` with the required values\nExport the `.env` variables\n\n```Bash\nexport $(cat .env | sed 's/#.*//g' | xargs)\n```\n\n## Twitter crawler\n\n### Twint\n\nFor crawl tweets and extract user's information we use Twint wich allow us to get many information without\nusing Twitter api.\n\nSome of the benefits of using Twint vs Twitter API:\n\n- Can fetch almost all Tweets (Twitter API limits to last 3200 Tweets only);\n- Fast initial setup;\n- Can be used anonymously and without Twitter sign up;\n- No rate limitations.\n\nWhen we used twint, we encountered some problems:\n\n- Bad compatibility with windows and datetime\n- We can't set a limit on the recovery of tweets\n- Bug with some user-agent\n\nSo we decided to [fork](https://github.com/quentin-derosin/twint) the project.\n\nWith allow us to:\n\n- get tweets\n- get user information\n- get follow and follower\n- search tweet from hashtag or word\n\n### API\n\nFor this we use the open-source framework flask.\n\nFour endpoints are defined and their\n\n- ```/tweets/<string:user>```\n  - get all informations of a user (tweets, follow, interaction)\n\n- ```/search```\n  - crawl every 2 hours tweets corresponding to research\n\n- ```/stop```\n  - stop the search\n\n- ```/tweet/origin```\n  - retrieve the origin of a tweets\n\nSome query parameters are available:\n\n- ```tweet```:          set to 0 to avoid tweet (default: 1)\n- ```follow```:         set to 0 to avoid follow (default: 1)\n- ```limit```:          set the number of tweet to retrieve (Increments of 20, default: 100)\n- ```follow_limit```:   set the number of following and followers to  retrieve (default: 100)\n- ```since```:          date selector for tweets (Example: 2017-12-27)\n- ```until```:          date selector for tweets (Example: 2017-12-27)\n- ```retweet```:        set to 1 to retrieve retweet (default: 0)\n- ```search```:\n  - search terms format \"i search\"\n  - for hashtag : (#Hashtag)\n  - for multiple : (#Hashtag1 AND|OR #Hashtag2)\n- ```tweet_interact```: set to 1 to parse tweet interaction between users (default: 0)\n- ```depth```:          search tweet and info from list of follow\n\n### Twitter Storage\n\nInformation retrieve with twint is stored in elastic search, we do not use the default twint storage format as we want a stronger relationship parsing.\nThere is currently three index:\n\n- twitter_user\n- twitter_tweet\n- twitter_interaction\n\nThe first and second index are stored as in twitter. The third is build to store interaction from followers/following, conversation and retweet.\n\n![Twitter interaction](docs/images/twitter_interaction.png )\n\n## News Indexer\n\nThe second main part of the project is the crawler and indexer of news.\n\nFor this, we use the sitemap xml file of news websites to crawl all the articles. In a sitemap file, we extract the tag\n**sitemap** and **url**.\n\nThe **sitemap** tag is a link to a child sitemap xml file for a specific category of articles in the website.\n\nThe *url* tag represents an article/news of the website.  \n\nThe root url of a sitemap is stored in a postgres database with a trust level of the website (Oriented, Verified,\nFake News, ...) and headers. The headers are the tag we want to extract from the **url** tag which contains details about\nthe article (title, keywords, publication date, ...).\n\nThe headers are the list of fields use in the index pattern of ElasticSearch.\n\nIn crawling sitemaps, we insert the new child sitemap in the database with the last modification date or update it for\nthe ones already in the database. The last modification date is used to crawl only sitemaps which change since the\nlast crawling.\n\nThe data extracts from the *url* tags are built in a dataframe then sent in ElasticSearch for further utilisation with\nthe request in Twint API.\n\nIn the same time, some sitemaps don't provide the keywords for their articles. Hence, from ElasticSearch we retrieve the\nentries without keywords. Then, we download the content of the article and extract the keywords thanks to NLP. Finally,\nwe update the entries in ElasticSearch.\n\n### How it works\n- Insert a sitemap that you want to crawl with `insert_sitemap(loc, lastmod, url_headers, id_trust)`\n- Then run `scheduler_news()`which will retrieve all the sitemap that you have inserted in the database\n- You can also run `scheduler_keywords()` to extract the keywords that are missing from the url that have been fetched.\n- Every urls found are inserted in elastic.\n\n![](docs/images/elastic-news-crawler.png)\n\n\n### Run\nFor the crawler/indexer:\n\n```python\nfrom TrollHunter.news_crawler import scheduler_news\n\nscheduler_news(time_interval)\n```\n\nFor updating keywords:\n\n```python\nfrom TrollHunter.news_crawler import scheduler_keywords\n\nscheduler_keywords(time_interval, max_entry)\n```\n\nOr see with the [main](https://github.com/StanGirard/TrollHunter/tree/master/docker/news_crawler) use with docker.  \n\n## Grafana\n\nWe use grafana for visualizing and monitoring different events with the crawler/indexer as\nthe insertion of an url in ElasticSearch and the extraction of keywords in an article.\n\n![alt text](docs/images/grafana.png)\n\nCreate new events.\n\n- Use `TrollHunter.loggers.InfluxDBLog()`\n- Create a new dashboard in grafana, save as json and add it to `docker/grafana-provisioning/dashboards`\n\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/StanGirard/TrollHunter", "keywords": "", "license": "GPL", "maintainer": "", "maintainer_email": "", "name": "TrollHunter", "package_url": "https://pypi.org/project/TrollHunter/", "platform": "", "project_url": "https://pypi.org/project/TrollHunter/", "project_urls": {"Homepage": "https://github.com/StanGirard/TrollHunter"}, "release_url": "https://pypi.org/project/TrollHunter/0.3.5/", "requires_dist": ["aiodns (==2.0.0)", "aiofiles (==0.4.0)", "aiohttp (==3.6.2)", "aiohttp-socks (==0.3.4)", "amqp (==2.5.2)", "aniso8601 (==8.0.0)", "async-timeout (==3.0.1)", "attrs (==19.3.0)", "beautifulsoup4 (==4.8.2)", "billiard (==3.6.3.0)", "blinker (==1.4)", "cchardet (==2.1.5)", "celery (==4.4.1)", "certifi (==2019.11.28)", "cffi (==1.14.0)", "chardet (==3.0.4)", "Click (==7.0)", "elasticsearch (==7.5.1)", "fake-useragent (==0.1.11)", "Flask (==1.1.1)", "Flask-Jsonpify (==1.5.0)", "Flask-RESTful (==0.3.8)", "Flask-SQLAlchemy (==2.4.1)", "geographiclib (==1.50)", "geopy (==1.21.0)", "googletransx (==2.4.2)", "h11 (==0.9.0)", "h2 (==3.2.0)", "hpack (==3.0.0)", "hyperframe (==5.2.0)", "idna (==2.9)", "influxdb (==5.2.3)", "importlib-metadata (==1.5.0)", "itsdangerous (==1.1.0)", "Jinja2 (==2.11.1)", "kombu (==4.6.8)", "MarkupSafe (==1.1.1)", "multidict (==4.7.5)", "numpy (==1.18.1)", "pandas (==1.0.1)", "priority (==1.3.0)", "psycopg2-binary (==2.8.4)", "pycares (==3.1.1)", "pycparser (==2.19)", "PySocks (==1.7.1)", "python-dateutil (==2.8.1)", "python-dotenv (==0.12.0)", "pytz (==2019.3)", "requests (==2.23.0)", "schedule (==0.6.0)", "six (==1.14.0)", "soupsieve (==2.0)", "SQLAlchemy (==1.3.13)", "toml (==0.10.0)", "typing-extensions (==3.7.4.1)", "Unidecode (==1.1.1)", "urllib3 (==1.25.8)", "vine (==1.3.0)", "Werkzeug (==1.0.0)", "wsproto (==0.15.0)", "yarl (==1.4.2)", "zipp (==3.1.0)", "nltk (==3.4.5)", "rake-nltk (==1.0.4)"], "requires_python": "", "summary": "TrollHunter", "version": "0.3.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TrollHunter</h1>\n<p>TrollHunter is a Twitter Crawler &amp; News Website Indexer.\nIt aims at finding Troll Farmers &amp; Fake News on Twitter.</p>\n<p>It composed of three parts:</p>\n<ul>\n<li>Twint API to extract information about a tweet or a user</li>\n<li>News Indexer which indexes all the articles of a website and extract its keywords</li>\n<li>Analysis of the tweets and news</li>\n</ul>\n<h2>Installation</h2>\n<p>You can either run</p>\n<pre>pip3 install TrollHunter\n</pre>\n<p>or clone the project and run</p>\n<pre>pip3 install -r requirements.txt\n</pre>\n<h3>Docker</h3>\n<p>TrollHunter requires many services to run</p>\n<ul>\n<li>ELK ( Elastic Search, Logstash, Kibana)</li>\n<li>InfluxDb &amp; Grafana</li>\n<li>RabbitMQ</li>\n</ul>\n<p>You can either launch them individually if you already have them setup or use our <code>docker-compose.yml</code></p>\n<ul>\n<li>Install Docker</li>\n<li>Run <code>docker-compose up -d</code></li>\n</ul>\n<h3>Setup</h3>\n<p>Change the <code>.env</code> with the required values\nExport the <code>.env</code> variables</p>\n<pre><span class=\"nb\">export</span> <span class=\"k\">$(</span>cat .env <span class=\"p\">|</span> sed <span class=\"s1\">'s/#.*//g'</span> <span class=\"p\">|</span> xargs<span class=\"k\">)</span>\n</pre>\n<h2>Twitter crawler</h2>\n<h3>Twint</h3>\n<p>For crawl tweets and extract user's information we use Twint wich allow us to get many information without\nusing Twitter api.</p>\n<p>Some of the benefits of using Twint vs Twitter API:</p>\n<ul>\n<li>Can fetch almost all Tweets (Twitter API limits to last 3200 Tweets only);</li>\n<li>Fast initial setup;</li>\n<li>Can be used anonymously and without Twitter sign up;</li>\n<li>No rate limitations.</li>\n</ul>\n<p>When we used twint, we encountered some problems:</p>\n<ul>\n<li>Bad compatibility with windows and datetime</li>\n<li>We can't set a limit on the recovery of tweets</li>\n<li>Bug with some user-agent</li>\n</ul>\n<p>So we decided to <a href=\"https://github.com/quentin-derosin/twint\" rel=\"nofollow\">fork</a> the project.</p>\n<p>With allow us to:</p>\n<ul>\n<li>get tweets</li>\n<li>get user information</li>\n<li>get follow and follower</li>\n<li>search tweet from hashtag or word</li>\n</ul>\n<h3>API</h3>\n<p>For this we use the open-source framework flask.</p>\n<p>Four endpoints are defined and their</p>\n<ul>\n<li>\n<p><code>/tweets/&lt;string:user&gt;</code></p>\n<ul>\n<li>get all informations of a user (tweets, follow, interaction)</li>\n</ul>\n</li>\n<li>\n<p><code>/search</code></p>\n<ul>\n<li>crawl every 2 hours tweets corresponding to research</li>\n</ul>\n</li>\n<li>\n<p><code>/stop</code></p>\n<ul>\n<li>stop the search</li>\n</ul>\n</li>\n<li>\n<p><code>/tweet/origin</code></p>\n<ul>\n<li>retrieve the origin of a tweets</li>\n</ul>\n</li>\n</ul>\n<p>Some query parameters are available:</p>\n<ul>\n<li><code>tweet</code>:          set to 0 to avoid tweet (default: 1)</li>\n<li><code>follow</code>:         set to 0 to avoid follow (default: 1)</li>\n<li><code>limit</code>:          set the number of tweet to retrieve (Increments of 20, default: 100)</li>\n<li><code>follow_limit</code>:   set the number of following and followers to  retrieve (default: 100)</li>\n<li><code>since</code>:          date selector for tweets (Example: 2017-12-27)</li>\n<li><code>until</code>:          date selector for tweets (Example: 2017-12-27)</li>\n<li><code>retweet</code>:        set to 1 to retrieve retweet (default: 0)</li>\n<li><code>search</code>:\n<ul>\n<li>search terms format \"i search\"</li>\n<li>for hashtag : (#Hashtag)</li>\n<li>for multiple : (#Hashtag1 AND|OR #Hashtag2)</li>\n</ul>\n</li>\n<li><code>tweet_interact</code>: set to 1 to parse tweet interaction between users (default: 0)</li>\n<li><code>depth</code>:          search tweet and info from list of follow</li>\n</ul>\n<h3>Twitter Storage</h3>\n<p>Information retrieve with twint is stored in elastic search, we do not use the default twint storage format as we want a stronger relationship parsing.\nThere is currently three index:</p>\n<ul>\n<li>twitter_user</li>\n<li>twitter_tweet</li>\n<li>twitter_interaction</li>\n</ul>\n<p>The first and second index are stored as in twitter. The third is build to store interaction from followers/following, conversation and retweet.</p>\n<p><img alt=\"Twitter interaction\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/286dc2b86dc94099ed58fa3e27c63fb1675d59b1/646f63732f696d616765732f747769747465725f696e746572616374696f6e2e706e67\"></p>\n<h2>News Indexer</h2>\n<p>The second main part of the project is the crawler and indexer of news.</p>\n<p>For this, we use the sitemap xml file of news websites to crawl all the articles. In a sitemap file, we extract the tag\n<strong>sitemap</strong> and <strong>url</strong>.</p>\n<p>The <strong>sitemap</strong> tag is a link to a child sitemap xml file for a specific category of articles in the website.</p>\n<p>The <em>url</em> tag represents an article/news of the website.</p>\n<p>The root url of a sitemap is stored in a postgres database with a trust level of the website (Oriented, Verified,\nFake News, ...) and headers. The headers are the tag we want to extract from the <strong>url</strong> tag which contains details about\nthe article (title, keywords, publication date, ...).</p>\n<p>The headers are the list of fields use in the index pattern of ElasticSearch.</p>\n<p>In crawling sitemaps, we insert the new child sitemap in the database with the last modification date or update it for\nthe ones already in the database. The last modification date is used to crawl only sitemaps which change since the\nlast crawling.</p>\n<p>The data extracts from the <em>url</em> tags are built in a dataframe then sent in ElasticSearch for further utilisation with\nthe request in Twint API.</p>\n<p>In the same time, some sitemaps don't provide the keywords for their articles. Hence, from ElasticSearch we retrieve the\nentries without keywords. Then, we download the content of the article and extract the keywords thanks to NLP. Finally,\nwe update the entries in ElasticSearch.</p>\n<h3>How it works</h3>\n<ul>\n<li>Insert a sitemap that you want to crawl with <code>insert_sitemap(loc, lastmod, url_headers, id_trust)</code></li>\n<li>Then run <code>scheduler_news()</code>which will retrieve all the sitemap that you have inserted in the database</li>\n<li>You can also run <code>scheduler_keywords()</code> to extract the keywords that are missing from the url that have been fetched.</li>\n<li>Every urls found are inserted in elastic.</li>\n</ul>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bdd2e1e74aac78436b948ea0d75c73af143ba83c/646f63732f696d616765732f656c61737469632d6e6577732d637261776c65722e706e67\"></p>\n<h3>Run</h3>\n<p>For the crawler/indexer:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">TrollHunter.news_crawler</span> <span class=\"kn\">import</span> <span class=\"n\">scheduler_news</span>\n\n<span class=\"n\">scheduler_news</span><span class=\"p\">(</span><span class=\"n\">time_interval</span><span class=\"p\">)</span>\n</pre>\n<p>For updating keywords:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">TrollHunter.news_crawler</span> <span class=\"kn\">import</span> <span class=\"n\">scheduler_keywords</span>\n\n<span class=\"n\">scheduler_keywords</span><span class=\"p\">(</span><span class=\"n\">time_interval</span><span class=\"p\">,</span> <span class=\"n\">max_entry</span><span class=\"p\">)</span>\n</pre>\n<p>Or see with the <a href=\"https://github.com/StanGirard/TrollHunter/tree/master/docker/news_crawler\" rel=\"nofollow\">main</a> use with docker.</p>\n<h2>Grafana</h2>\n<p>We use grafana for visualizing and monitoring different events with the crawler/indexer as\nthe insertion of an url in ElasticSearch and the extraction of keywords in an article.</p>\n<p><img alt=\"alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ecd54b1a70d3a33de93b3b4b8ad926ee1dfddbd2/646f63732f696d616765732f67726166616e612e706e67\"></p>\n<p>Create new events.</p>\n<ul>\n<li>Use <code>TrollHunter.loggers.InfluxDBLog()</code></li>\n<li>Create a new dashboard in grafana, save as json and add it to <code>docker/grafana-provisioning/dashboards</code></li>\n</ul>\n\n          </div>"}, "last_serial": 6895801, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "0a4fa0c5df93a9cd6f8655d7b70b4775", "sha256": "c073c5ca099390f9b564b032c63755e1c72bb0594638ab4662b5e87f989c007b"}, "downloads": -1, "filename": "TrollHunter-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0a4fa0c5df93a9cd6f8655d7b70b4775", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 52300, "upload_time": "2020-03-10T16:01:51", "upload_time_iso_8601": "2020-03-10T16:01:51.968332Z", "url": "https://files.pythonhosted.org/packages/bc/8b/ed67ca48825bd9cebf13a688f1deafbe59ae83341f68a54629edf2146942/TrollHunter-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d59ef6e126379970910048e29af0b417", "sha256": "ad7e0bd4f7a6290bc79e672bb25e2a5f0adc53d0f430bed38f9ebef5b33ce231"}, "downloads": -1, "filename": "TrollHunter-0.2.tar.gz", "has_sig": false, "md5_digest": "d59ef6e126379970910048e29af0b417", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29282, "upload_time": "2020-03-10T16:01:54", "upload_time_iso_8601": "2020-03-10T16:01:54.038412Z", "url": "https://files.pythonhosted.org/packages/74/42/39a24152152076781dacb1c2c6f6ea9b82ce5ce35beff29495e7b99356e3/TrollHunter-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "2254e5e0760e215f108e797a29833315", "sha256": "27af98808e4a1f6213cf4c551cef18ae5b78f1ec35c64c3e54c3249fa5775bfe"}, "downloads": -1, "filename": "TrollHunter-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2254e5e0760e215f108e797a29833315", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 52305, "upload_time": "2020-03-10T16:19:37", "upload_time_iso_8601": "2020-03-10T16:19:37.505273Z", "url": "https://files.pythonhosted.org/packages/d9/51/c06f131332dc79016f404827e10e80455e8df8b58cb32e0b9def01b946d7/TrollHunter-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f019ee1f60c6bf2d78a159e16811e66b", "sha256": "2ec2064252ef919dc04fed698790712a8472efa2d60e59ce9440892546f6257d"}, "downloads": -1, "filename": "TrollHunter-0.2.1.tar.gz", "has_sig": false, "md5_digest": "f019ee1f60c6bf2d78a159e16811e66b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29244, "upload_time": "2020-03-10T16:19:38", "upload_time_iso_8601": "2020-03-10T16:19:38.454379Z", "url": "https://files.pythonhosted.org/packages/38/ce/7c3da7322a634c1e290d445eb74280568e49cb28eaf62c9ca2e5b9a5cb32/TrollHunter-0.2.1.tar.gz", "yanked": false}], "0.2.10": [{"comment_text": "", "digests": {"md5": "9c772be0e348cf828aecac65aa51ce7c", "sha256": "41596efc369a41dd9145dff0d8686bbc8ed445ecd0a7aba6709bd86163a3ec92"}, "downloads": -1, "filename": "TrollHunter-0.2.10-py3-none-any.whl", "has_sig": false, "md5_digest": "9c772be0e348cf828aecac65aa51ce7c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58123, "upload_time": "2020-03-13T12:03:44", "upload_time_iso_8601": "2020-03-13T12:03:44.815444Z", "url": "https://files.pythonhosted.org/packages/d2/77/96ef46444a67ae7cfbc8e08dd0a2b58814891953bdbba823ba596d9543a8/TrollHunter-0.2.10-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c663ce83d0016f32cb6b95e44a95d7d6", "sha256": "6a153cf473592a6cb40b1cf6891d5acb26a2fd6a76c1355eaed2ca7fe62d99d8"}, "downloads": -1, "filename": "TrollHunter-0.2.10.tar.gz", "has_sig": false, "md5_digest": "c663ce83d0016f32cb6b95e44a95d7d6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33630, "upload_time": "2020-03-13T12:03:46", "upload_time_iso_8601": "2020-03-13T12:03:46.018556Z", "url": "https://files.pythonhosted.org/packages/fb/6d/f91ee2453f1c246c661defa8cbe658367ae7a0bc489387682e759d753ef5/TrollHunter-0.2.10.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "d68d7c34cc579fba66d85a8aac0b8b67", "sha256": "9352267e985d9c377a8087d6e3df25f40dd7edb80801bc6f9251f5143606e0ad"}, "downloads": -1, "filename": "TrollHunter-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "d68d7c34cc579fba66d85a8aac0b8b67", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 52304, "upload_time": "2020-03-10T16:24:43", "upload_time_iso_8601": "2020-03-10T16:24:43.401933Z", "url": "https://files.pythonhosted.org/packages/b6/bb/cd58e4f43fc260e0b67d9e7c38df05f97b18f3392d377d81d9af3432e923/TrollHunter-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1e05dee38cdab749032b4e5ff0f0642f", "sha256": "5d025668fcffefbc9351553a1a150cbb3e0b864ecfee7dad82dee3d586521ac3"}, "downloads": -1, "filename": "TrollHunter-0.2.2.tar.gz", "has_sig": false, "md5_digest": "1e05dee38cdab749032b4e5ff0f0642f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29241, "upload_time": "2020-03-10T16:24:45", "upload_time_iso_8601": "2020-03-10T16:24:45.678778Z", "url": "https://files.pythonhosted.org/packages/aa/34/58ddad2b323bbd2e684a802e3d214221ded33f9f847bacb75d646cfefcfd/TrollHunter-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "31720c4ae9dc4b5dc5a8e26480029848", "sha256": "8c9cbd1c2d154ce197c227ecb4cba05f38c75ae204832398fef769e47f4dc6f6"}, "downloads": -1, "filename": "TrollHunter-0.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "31720c4ae9dc4b5dc5a8e26480029848", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 54065, "upload_time": "2020-03-11T11:31:10", "upload_time_iso_8601": "2020-03-11T11:31:10.506610Z", "url": "https://files.pythonhosted.org/packages/b7/a7/0614d8ee005f8e88ddde1d3e85b3c2e5438ed0158bd0df9ad8556cdc3735/TrollHunter-0.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d08743426f978201bcd926029c905a60", "sha256": "146a35f196b819c8bef24a85d4d5e844b9ebb20027d69183448074dc616571f4"}, "downloads": -1, "filename": "TrollHunter-0.2.3.tar.gz", "has_sig": false, "md5_digest": "d08743426f978201bcd926029c905a60", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30610, "upload_time": "2020-03-11T11:31:11", "upload_time_iso_8601": "2020-03-11T11:31:11.442003Z", "url": "https://files.pythonhosted.org/packages/d1/60/69b6ada4ef0e00fc32fec0eff144ed06d33d8d8c5bd737fe84067b076de0/TrollHunter-0.2.3.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "5221bd9c022c3c57709626d43c5e9657", "sha256": "be259e1b77fc8239919e0cf447fd53f2d25391ebd0f53a833aff87dae7190f45"}, "downloads": -1, "filename": "TrollHunter-0.2.5-py3-none-any.whl", "has_sig": false, "md5_digest": "5221bd9c022c3c57709626d43c5e9657", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 57376, "upload_time": "2020-03-12T10:45:52", "upload_time_iso_8601": "2020-03-12T10:45:52.669127Z", "url": "https://files.pythonhosted.org/packages/35/40/c81caea47ae5e22072f9275a223731366bba98f81c7771a7e9dc1f0a0a79/TrollHunter-0.2.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27817415e93cab6c63f828d22718c365", "sha256": "88e8a31a19ffd6b9e6dd06e6cb9bf13ec66fdf6f011b6574a16b46a445889df2"}, "downloads": -1, "filename": "TrollHunter-0.2.5.tar.gz", "has_sig": false, "md5_digest": "27817415e93cab6c63f828d22718c365", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33170, "upload_time": "2020-03-12T10:45:54", "upload_time_iso_8601": "2020-03-12T10:45:54.031072Z", "url": "https://files.pythonhosted.org/packages/89/c6/5e5f9ff97c93c74e0c9a59f45290fbcbcd090880a6715a828e0f1f5ee4b3/TrollHunter-0.2.5.tar.gz", "yanked": false}], "0.2.6": [{"comment_text": "", "digests": {"md5": "4869d8db4e4785aa43763d3e577e56dd", "sha256": "f056a7fe1e2b4579082d64229262b9f8ef80f908326324c7b48899bcce947730"}, "downloads": -1, "filename": "TrollHunter-0.2.6-py3-none-any.whl", "has_sig": false, "md5_digest": "4869d8db4e4785aa43763d3e577e56dd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58084, "upload_time": "2020-03-12T10:52:55", "upload_time_iso_8601": "2020-03-12T10:52:55.075796Z", "url": "https://files.pythonhosted.org/packages/65/36/c455e1ddd79f78797bea4b3ccb5ea36c3af248ffd2acc97db9ee8cb19bba/TrollHunter-0.2.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ca0b58c58cdb4483cffbef372d7a188f", "sha256": "616744429d72b133322f8e2754b96a981f9b8d33879d4e1af924578e0ff8f6cb"}, "downloads": -1, "filename": "TrollHunter-0.2.6.tar.gz", "has_sig": false, "md5_digest": "ca0b58c58cdb4483cffbef372d7a188f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33589, "upload_time": "2020-03-12T10:52:56", "upload_time_iso_8601": "2020-03-12T10:52:56.265966Z", "url": "https://files.pythonhosted.org/packages/78/18/b28e7b27b27674c6d56d4156ff69d938bb96ea366791e52631007ea8e35f/TrollHunter-0.2.6.tar.gz", "yanked": false}], "0.2.7": [{"comment_text": "", "digests": {"md5": "0b08e52094eec8ee07f2cda42f36c2f2", "sha256": "637716df681db6879f6eb858a8a3b0a13aa08f818d4712912a3003a5279e5d24"}, "downloads": -1, "filename": "TrollHunter-0.2.7-py3-none-any.whl", "has_sig": false, "md5_digest": "0b08e52094eec8ee07f2cda42f36c2f2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58089, "upload_time": "2020-03-12T11:10:00", "upload_time_iso_8601": "2020-03-12T11:10:00.466046Z", "url": "https://files.pythonhosted.org/packages/c2/3e/ee194cc00ffb0d8e687d7fbb9d17deaedb2f33b862fd9e80e897a59ba777/TrollHunter-0.2.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "81665c9050045651d0e9663f48f06dac", "sha256": "bbe32ef54251230a23854fffdef06cc31561724b1e9275f12524320cc80a75d7"}, "downloads": -1, "filename": "TrollHunter-0.2.7.tar.gz", "has_sig": false, "md5_digest": "81665c9050045651d0e9663f48f06dac", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33592, "upload_time": "2020-03-12T11:10:01", "upload_time_iso_8601": "2020-03-12T11:10:01.761899Z", "url": "https://files.pythonhosted.org/packages/61/63/1dbc047fadd8a8fa113dc15bd17ab7d3126bbd9f3e366fe6d5e69af4ae8d/TrollHunter-0.2.7.tar.gz", "yanked": false}], "0.2.8": [{"comment_text": "", "digests": {"md5": "13fb1b8f516a41376f7c611b027ac701", "sha256": "5d54ea0fb566219692dca89ca7b1aec4940f01053d24b70780bd0b5503b6f62c"}, "downloads": -1, "filename": "TrollHunter-0.2.8-py3-none-any.whl", "has_sig": false, "md5_digest": "13fb1b8f516a41376f7c611b027ac701", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58089, "upload_time": "2020-03-13T11:09:04", "upload_time_iso_8601": "2020-03-13T11:09:04.959149Z", "url": "https://files.pythonhosted.org/packages/75/47/5a252a7382001dd0a6fcbe4bdf22d7bf67c89cfe2f0fc19e7e97e1ce2900/TrollHunter-0.2.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "572a643514b9f9f9082a190503d8a77e", "sha256": "14a4a09c233378b1b9e853ec3349dbb883897c29f90cb417785a10ddb3def145"}, "downloads": -1, "filename": "TrollHunter-0.2.8.tar.gz", "has_sig": false, "md5_digest": "572a643514b9f9f9082a190503d8a77e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33599, "upload_time": "2020-03-13T11:09:06", "upload_time_iso_8601": "2020-03-13T11:09:06.124159Z", "url": "https://files.pythonhosted.org/packages/ab/9f/143f567389395f578fd6131732535bf7fc47759fd277210cf67d826a644e/TrollHunter-0.2.8.tar.gz", "yanked": false}], "0.2.9": [{"comment_text": "", "digests": {"md5": "f34805d4b926bd200ed8ad426dac3d32", "sha256": "41de7b6747e762922869b5e8aee2672d3d500c6da7e552abf970b05e566225b5"}, "downloads": -1, "filename": "TrollHunter-0.2.9-py3-none-any.whl", "has_sig": false, "md5_digest": "f34805d4b926bd200ed8ad426dac3d32", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 58103, "upload_time": "2020-03-13T11:38:27", "upload_time_iso_8601": "2020-03-13T11:38:27.847960Z", "url": "https://files.pythonhosted.org/packages/4f/12/e18659ceab814a3ab358f491f66f3c8593195efbadac251452b0bc03b7db/TrollHunter-0.2.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "08ae1082b79e77261b126743bc215d04", "sha256": "255e15a5c90daa54aafe8b02a10fbd064bf4824183cf2f35a471822332de41ac"}, "downloads": -1, "filename": "TrollHunter-0.2.9.tar.gz", "has_sig": false, "md5_digest": "08ae1082b79e77261b126743bc215d04", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33618, "upload_time": "2020-03-13T11:38:29", "upload_time_iso_8601": "2020-03-13T11:38:29.330962Z", "url": "https://files.pythonhosted.org/packages/eb/18/a15ada6eb1ac0a4864e52546e022fe6f8ada099ee617c5b81622ce33d9e9/TrollHunter-0.2.9.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "9ec66cd4a9b4b091f22dcd6c3e9fd549", "sha256": "0717d8ffe98b1d11412f315a1d46ed692d54cbd96308d4cbf1d232a59078ab5d"}, "downloads": -1, "filename": "TrollHunter-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9ec66cd4a9b4b091f22dcd6c3e9fd549", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 63147, "upload_time": "2020-03-26T12:43:25", "upload_time_iso_8601": "2020-03-26T12:43:25.867357Z", "url": "https://files.pythonhosted.org/packages/09/dc/4075a0cecf9e9d19011ef1a9d6a8ed781c2abc7bb37da7b3f797dc306a97/TrollHunter-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "78fcc1c2c95d350b9e5c7adc6fbd143e", "sha256": "9307912e6b2b030cdab56497efa21e8bcad1868f58f46cce2c1b27ba3ad2e371"}, "downloads": -1, "filename": "TrollHunter-0.3.0.tar.gz", "has_sig": false, "md5_digest": "78fcc1c2c95d350b9e5c7adc6fbd143e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37421, "upload_time": "2020-03-26T12:43:26", "upload_time_iso_8601": "2020-03-26T12:43:26.854789Z", "url": "https://files.pythonhosted.org/packages/5a/0e/79c9891fa4833daf96a437bf3248a7b29fea9c354da3721266a8ffac5ead/TrollHunter-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "733119fe314106fbe974fdf52eb7bdcb", "sha256": "4db2410dad199f5575f272e5101b799cde689fc18601921f04acb73e60899620"}, "downloads": -1, "filename": "TrollHunter-0.3.1-py3-none-any.whl", "has_sig": false, "md5_digest": "733119fe314106fbe974fdf52eb7bdcb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 64247, "upload_time": "2020-03-26T14:44:25", "upload_time_iso_8601": "2020-03-26T14:44:25.780231Z", "url": "https://files.pythonhosted.org/packages/31/dc/d42fe96115e4aedf6eee204ef4278a4d1061a02d9ec87e87f05dbbdc9247/TrollHunter-0.3.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6e5566b90a7126307d77a58ef1ed8f77", "sha256": "066fd8584b7bec277c9a9834ffe02e4ecea9091bd98c962ab8f7a38adb45db07"}, "downloads": -1, "filename": "TrollHunter-0.3.1.tar.gz", "has_sig": false, "md5_digest": "6e5566b90a7126307d77a58ef1ed8f77", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39070, "upload_time": "2020-03-26T14:44:27", "upload_time_iso_8601": "2020-03-26T14:44:27.099381Z", "url": "https://files.pythonhosted.org/packages/82/cc/e85c0b42c6b685c596b44058bec5caf910d49311f70e380cbd230ae4e105/TrollHunter-0.3.1.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "2f06ce159cbebfd635c8f3cbadbc677c", "sha256": "30eaffe437c7030bad721a19e22890da48ad3d9d306aa2568c042e340a6f3d42"}, "downloads": -1, "filename": "TrollHunter-0.3.3-py3-none-any.whl", "has_sig": false, "md5_digest": "2f06ce159cbebfd635c8f3cbadbc677c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 64526, "upload_time": "2020-03-26T15:42:54", "upload_time_iso_8601": "2020-03-26T15:42:54.941518Z", "url": "https://files.pythonhosted.org/packages/21/00/9b371164c9fd3c3af454bd073847a5059cb9223a5a6da989b79bcb7acade/TrollHunter-0.3.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f04628eb031539ca7029c196c4b123ce", "sha256": "27ee2b70c8745dae60de18233ff414a8266f9807702221605a68d91d65cacd87"}, "downloads": -1, "filename": "TrollHunter-0.3.3.tar.gz", "has_sig": false, "md5_digest": "f04628eb031539ca7029c196c4b123ce", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39705, "upload_time": "2020-03-26T15:43:05", "upload_time_iso_8601": "2020-03-26T15:43:05.193109Z", "url": "https://files.pythonhosted.org/packages/05/f4/daf476906614621f933cb629801ed583286d9a77016fa7d25b45012a5297/TrollHunter-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "d7be78a74859948a3ad34fe2411cdd02", "sha256": "a3888aba78a4fbc84c58a6d05207a05a293e66734ab611e1f8fd67be09c690a8"}, "downloads": -1, "filename": "TrollHunter-0.3.4-py3-none-any.whl", "has_sig": false, "md5_digest": "d7be78a74859948a3ad34fe2411cdd02", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 64588, "upload_time": "2020-03-26T16:56:15", "upload_time_iso_8601": "2020-03-26T16:56:15.114888Z", "url": "https://files.pythonhosted.org/packages/62/fe/ab0a4cd9f4989432b356a991610bc8c45b80db16e1a38b23676b512109e6/TrollHunter-0.3.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4728fdccf311626bc1d29cf6e944a470", "sha256": "24cbf38462b396628b4a6decca2c99dd4823bc20ac6cfb5a4946534924bda731"}, "downloads": -1, "filename": "TrollHunter-0.3.4.tar.gz", "has_sig": false, "md5_digest": "4728fdccf311626bc1d29cf6e944a470", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39813, "upload_time": "2020-03-26T16:56:16", "upload_time_iso_8601": "2020-03-26T16:56:16.624755Z", "url": "https://files.pythonhosted.org/packages/85/fb/66651d03a3f6f32338fc0939c255966ac5a626514aee4e7a21e2596ba96e/TrollHunter-0.3.4.tar.gz", "yanked": false}], "0.3.5": [{"comment_text": "", "digests": {"md5": "629ea12e5b3e3f056976ba9a3cca048d", "sha256": "24d77a4b5ed389b40f0dd7d808754bf216fc0f22bd0bc3d4abaaf946292b0bb5"}, "downloads": -1, "filename": "TrollHunter-0.3.5-py3-none-any.whl", "has_sig": false, "md5_digest": "629ea12e5b3e3f056976ba9a3cca048d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 68895, "upload_time": "2020-03-27T12:30:02", "upload_time_iso_8601": "2020-03-27T12:30:02.011326Z", "url": "https://files.pythonhosted.org/packages/0b/7a/5255aa4591a5d52d549bbf6dacf5d3ba52a6b65287b011048c744f8a3ef5/TrollHunter-0.3.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6d9258d252f19ac1aaccd46464bd9ea", "sha256": "5fce439c40aa4ba1cb2e59a155e38e1ad4f195b043de437f5dc83f2507747eaf"}, "downloads": -1, "filename": "TrollHunter-0.3.5.tar.gz", "has_sig": false, "md5_digest": "a6d9258d252f19ac1aaccd46464bd9ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 44943, "upload_time": "2020-03-27T12:30:07", "upload_time_iso_8601": "2020-03-27T12:30:07.503446Z", "url": "https://files.pythonhosted.org/packages/2e/c0/9fe8c6da3ac3e0dc35cb704b7c4957ac468df1c92c0c06088246eb3b3f5a/TrollHunter-0.3.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "629ea12e5b3e3f056976ba9a3cca048d", "sha256": "24d77a4b5ed389b40f0dd7d808754bf216fc0f22bd0bc3d4abaaf946292b0bb5"}, "downloads": -1, "filename": "TrollHunter-0.3.5-py3-none-any.whl", "has_sig": false, "md5_digest": "629ea12e5b3e3f056976ba9a3cca048d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 68895, "upload_time": "2020-03-27T12:30:02", "upload_time_iso_8601": "2020-03-27T12:30:02.011326Z", "url": "https://files.pythonhosted.org/packages/0b/7a/5255aa4591a5d52d549bbf6dacf5d3ba52a6b65287b011048c744f8a3ef5/TrollHunter-0.3.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6d9258d252f19ac1aaccd46464bd9ea", "sha256": "5fce439c40aa4ba1cb2e59a155e38e1ad4f195b043de437f5dc83f2507747eaf"}, "downloads": -1, "filename": "TrollHunter-0.3.5.tar.gz", "has_sig": false, "md5_digest": "a6d9258d252f19ac1aaccd46464bd9ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 44943, "upload_time": "2020-03-27T12:30:07", "upload_time_iso_8601": "2020-03-27T12:30:07.503446Z", "url": "https://files.pythonhosted.org/packages/2e/c0/9fe8c6da3ac3e0dc35cb704b7c4957ac468df1c92c0c06088246eb3b3f5a/TrollHunter-0.3.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:46:47 2020"}