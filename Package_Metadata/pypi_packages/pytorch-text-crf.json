{"info": {"author": "iamsimha", "author_email": "jayasimhatlr@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "# PyTorch Text CRF\nThis package contains a simple wrapper for using conditional random fields(CRF). This code is based on the excellent Allen NLP implementation of CRF.\n\n## Installation\n```\npip install pytorch-text-crf\n```\n\n## Usage\n\n```python\nfrom crf.crf import ConditionalRandomField\n\n# Initilization\ncrf = ConditionalRandomField(n_tags,\n                            label_encoding=\"BIO\",\n                            idx2tag={0:\"B-GEO\", 1:\"I-GEO\", 2:\"0\"} # Index to tag mapping\n                            )\n# Likelihood estimation\nlog_likelihood = crf(logits, tags, mask)\n\n# Decoding\nbest_tag_sequence = crf.best_viterbi_tag(logits, mask)\ntop_5_viterbi_tags = crf.viterbi_tags(logits, mask, top_k=5)\n```\n### LSTM CRF Implementation\nRefer to https://github.com/iamsimha/pytorch-text-crf/blob/master/examples/pos_tagging/train.ipynb for a complete working implementation.\n``` python\nfrom crf.crf import ConditionalRandomField\n\nclass LSTMCRF:\n    \"\"\"\n    An Example implementation for using a CRF model on top of LSTM.\n    \"\"\"\n    def __init__(self):\n        ...\n        ...\n        # Initilize the conditional CRF model\n        self.crf = ConditionalRandomField(\n            n_class, # Number of tags\n            label_encoding=\"BIO\", # Label encoding format\n            idx2tag=idx2tag # Dict mapping index to a tag\n        )\n\n    def forward(self, inputs, tags):\n        logits = self.lstm(inputs) # logits dim:(batch_size, seq_length, num_tags)\n        mask = inputs != \"<pad token>\" # mask for ignoring pad tokens. mask dim: (batch_size, seq_length)\n        log_likelihood = self.crf(logits, tags, mask)\n        loss = -log_likelihood # Log likelihood is not normalized (It is not divided by the batch size).\n\n        # To obtain the best sequence using viterbi decoding\n        best_tag_sequence = self.crf.best_viterbi_tag(logits, mask)\n\n        # To obtain output similar to the lstm prediction we can use the below code\n        class_probabilities = out * 0.0\n        for i, instance_tags in enumerate(best_tag_sequence):\n            for j, tag_id in enumerate(instance_tags[0][0]):\n                class_probabilities[i, j, int(tag_id)] = 1\n        return {\"loss\": loss, \"class_probabilities\": class_probabilities} \n\n # Training\n lstm_crf = LSTMCRF()\n output = lstm_crf(sentences, tags)\n loss = output[\"loss\"]\n loss.backward()\n optimizer.step()\n``` \n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/iamsimha/pytorch-text-crf", "keywords": "", "license": "Apache License, Version 2.0", "maintainer": "", "maintainer_email": "", "name": "pytorch-text-crf", "package_url": "https://pypi.org/project/pytorch-text-crf/", "platform": "", "project_url": "https://pypi.org/project/pytorch-text-crf/", "project_urls": {"Homepage": "https://github.com/iamsimha/pytorch-text-crf"}, "release_url": "https://pypi.org/project/pytorch-text-crf/0.1/", "requires_dist": ["torch"], "requires_python": "", "summary": "A simple crf module written in pytorch. The implementation is based                https://github.com/allenai/allennlp/blob/master/allennlp/modules/conditional_random_field.py", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PyTorch Text CRF</h1>\n<p>This package contains a simple wrapper for using conditional random fields(CRF). This code is based on the excellent Allen NLP implementation of CRF.</p>\n<h2>Installation</h2>\n<pre><code>pip install pytorch-text-crf\n</code></pre>\n<h2>Usage</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">crf.crf</span> <span class=\"kn\">import</span> <span class=\"n\">ConditionalRandomField</span>\n\n<span class=\"c1\"># Initilization</span>\n<span class=\"n\">crf</span> <span class=\"o\">=</span> <span class=\"n\">ConditionalRandomField</span><span class=\"p\">(</span><span class=\"n\">n_tags</span><span class=\"p\">,</span>\n                            <span class=\"n\">label_encoding</span><span class=\"o\">=</span><span class=\"s2\">\"BIO\"</span><span class=\"p\">,</span>\n                            <span class=\"n\">idx2tag</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"s2\">\"B-GEO\"</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">:</span><span class=\"s2\">\"I-GEO\"</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">:</span><span class=\"s2\">\"0\"</span><span class=\"p\">}</span> <span class=\"c1\"># Index to tag mapping</span>\n                            <span class=\"p\">)</span>\n<span class=\"c1\"># Likelihood estimation</span>\n<span class=\"n\">log_likelihood</span> <span class=\"o\">=</span> <span class=\"n\">crf</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Decoding</span>\n<span class=\"n\">best_tag_sequence</span> <span class=\"o\">=</span> <span class=\"n\">crf</span><span class=\"o\">.</span><span class=\"n\">best_viterbi_tag</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">)</span>\n<span class=\"n\">top_5_viterbi_tags</span> <span class=\"o\">=</span> <span class=\"n\">crf</span><span class=\"o\">.</span><span class=\"n\">viterbi_tags</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">,</span> <span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<h3>LSTM CRF Implementation</h3>\n<p>Refer to <a href=\"https://github.com/iamsimha/pytorch-text-crf/blob/master/examples/pos_tagging/train.ipynb\" rel=\"nofollow\">https://github.com/iamsimha/pytorch-text-crf/blob/master/examples/pos_tagging/train.ipynb</a> for a complete working implementation.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">crf.crf</span> <span class=\"kn\">import</span> <span class=\"n\">ConditionalRandomField</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">LSTMCRF</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">    An Example implementation for using a CRF model on top of LSTM.</span>\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"o\">...</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># Initilize the conditional CRF model</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crf</span> <span class=\"o\">=</span> <span class=\"n\">ConditionalRandomField</span><span class=\"p\">(</span>\n            <span class=\"n\">n_class</span><span class=\"p\">,</span> <span class=\"c1\"># Number of tags</span>\n            <span class=\"n\">label_encoding</span><span class=\"o\">=</span><span class=\"s2\">\"BIO\"</span><span class=\"p\">,</span> <span class=\"c1\"># Label encoding format</span>\n            <span class=\"n\">idx2tag</span><span class=\"o\">=</span><span class=\"n\">idx2tag</span> <span class=\"c1\"># Dict mapping index to a tag</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">inputs</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"p\">):</span>\n        <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">lstm</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">)</span> <span class=\"c1\"># logits dim:(batch_size, seq_length, num_tags)</span>\n        <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">inputs</span> <span class=\"o\">!=</span> <span class=\"s2\">\"&lt;pad token&gt;\"</span> <span class=\"c1\"># mask for ignoring pad tokens. mask dim: (batch_size, seq_length)</span>\n        <span class=\"n\">log_likelihood</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crf</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"n\">log_likelihood</span> <span class=\"c1\"># Log likelihood is not normalized (It is not divided by the batch size).</span>\n\n        <span class=\"c1\"># To obtain the best sequence using viterbi decoding</span>\n        <span class=\"n\">best_tag_sequence</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">crf</span><span class=\"o\">.</span><span class=\"n\">best_viterbi_tag</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">)</span>\n\n        <span class=\"c1\"># To obtain output similar to the lstm prediction we can use the below code</span>\n        <span class=\"n\">class_probabilities</span> <span class=\"o\">=</span> <span class=\"n\">out</span> <span class=\"o\">*</span> <span class=\"mf\">0.0</span>\n        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">instance_tags</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">best_tag_sequence</span><span class=\"p\">):</span>\n            <span class=\"k\">for</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">tag_id</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">instance_tags</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]):</span>\n                <span class=\"n\">class_probabilities</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">tag_id</span><span class=\"p\">)]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n        <span class=\"k\">return</span> <span class=\"p\">{</span><span class=\"s2\">\"loss\"</span><span class=\"p\">:</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"s2\">\"class_probabilities\"</span><span class=\"p\">:</span> <span class=\"n\">class_probabilities</span><span class=\"p\">}</span> \n\n <span class=\"c1\"># Training</span>\n <span class=\"n\">lstm_crf</span> <span class=\"o\">=</span> <span class=\"n\">LSTMCRF</span><span class=\"p\">()</span>\n <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">lstm_crf</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"p\">,</span> <span class=\"n\">tags</span><span class=\"p\">)</span>\n <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">output</span><span class=\"p\">[</span><span class=\"s2\">\"loss\"</span><span class=\"p\">]</span>\n <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n</pre>\n\n          </div>"}, "last_serial": 6137946, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "f1afca5693de15ae0a62b737dd1d1325", "sha256": "5000a5b68ed82fc8551362b6c0a6e25582553bccef4fe687e188de1b72ec7398"}, "downloads": -1, "filename": "pytorch_text_crf-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f1afca5693de15ae0a62b737dd1d1325", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13985, "upload_time": "2019-11-14T17:57:46", "upload_time_iso_8601": "2019-11-14T17:57:46.132727Z", "url": "https://files.pythonhosted.org/packages/17/ae/a8f42b712dc3d16953d088be32b5e8a5c1515acb5006a4509fb909f0344f/pytorch_text_crf-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d8847b47e2ae9a07cc6f1408b22aeb2", "sha256": "bab37a78d9d2c0f62c1ae82f3a8466af9c64df0d01bea0eb4f357c5b3e0ebdc7"}, "downloads": -1, "filename": "pytorch-text-crf-0.1.tar.gz", "has_sig": false, "md5_digest": "9d8847b47e2ae9a07cc6f1408b22aeb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9995, "upload_time": "2019-11-14T17:57:49", "upload_time_iso_8601": "2019-11-14T17:57:49.066136Z", "url": "https://files.pythonhosted.org/packages/df/65/1e6b577211ad2ffeee49352bf0b6b16ede29bae10c54f5a7f45aa423e958/pytorch-text-crf-0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f1afca5693de15ae0a62b737dd1d1325", "sha256": "5000a5b68ed82fc8551362b6c0a6e25582553bccef4fe687e188de1b72ec7398"}, "downloads": -1, "filename": "pytorch_text_crf-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f1afca5693de15ae0a62b737dd1d1325", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13985, "upload_time": "2019-11-14T17:57:46", "upload_time_iso_8601": "2019-11-14T17:57:46.132727Z", "url": "https://files.pythonhosted.org/packages/17/ae/a8f42b712dc3d16953d088be32b5e8a5c1515acb5006a4509fb909f0344f/pytorch_text_crf-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d8847b47e2ae9a07cc6f1408b22aeb2", "sha256": "bab37a78d9d2c0f62c1ae82f3a8466af9c64df0d01bea0eb4f357c5b3e0ebdc7"}, "downloads": -1, "filename": "pytorch-text-crf-0.1.tar.gz", "has_sig": false, "md5_digest": "9d8847b47e2ae9a07cc6f1408b22aeb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9995, "upload_time": "2019-11-14T17:57:49", "upload_time_iso_8601": "2019-11-14T17:57:49.066136Z", "url": "https://files.pythonhosted.org/packages/df/65/1e6b577211ad2ffeee49352bf0b6b16ede29bae10c54f5a7f45aa423e958/pytorch-text-crf-0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:43 2020"}