{"info": {"author": "Alexandre Gattiker", "author_email": "algattik@microsoft.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# databricks-client\n\n## About\n\nA REST client for the [Databricks REST API](https://docs.databricks.com/dev-tools/api/latest/index.html).\n\nThis module is a thin layer allowing to build HTTP [Requests](https://requests.readthedocs.io/en/master/).\nIt does not expose API operations as distinct methods, but rather exposes generic methods allowing\nto build API calls.\n\nThe Databricks API sometimes returns 200 error codes and HTML content when the request is not\nproperly authenticated. The client intercepts such occurrences (detecting non-JSON returned content)\nand wraps them into an exception.\n\n_This open-source project is not developed by nor affiliated with Databricks._\n\n## Installing\n\n```\npip install databricks-client\n```\n\n## Usage\n\n```python\nimport databricks_client\n\nclient = databricks_client.create(\"https://northeurope.azuredatabricks.net/api/2.0\")\nclient.auth_pat_token(pat_token)\nclient.ensure_available()\nclusters_list = client.get('clusters/list')\nfor cluster in clusters_list[\"clusters\"]:\n    print(cluster)\n```\n\n## Usage with a newly provisioned workspace\n\nIf using this module as part of a provisioning job, you need to call `client.ensure_available()`.\n\nWhen the first user logs it to a new Databricks workspace, workspace provisioning is triggered,\nand the API is not available until that job has completed (that usually takes under a minute,\nbut could take longer depending on the network configuration). In that case you would get an\nerror such as the following when calling the API:\n\n```\n\"Succeeded{\"error_code\":\"INVALID_PARAMETER_VALUE\",\"message\":\"Unknown worker environment WorkerEnvId(workerenv-4312344789891641)\"}\n```\n\nThe method `client.ensure_available(url=\"instance-pools/list\", retries=100, delay_seconds=6)`\nprevents this error by attempting to\nconnect to the provided URL and retries as long as the workspace is in provisioning\nstate, or until the given number of retries has elapsed.\n\n## Usage with Azure Active Directory\n\nNote: Azure AD authentication for Databricks is currently in preview.\n\nThe client generates short-lived Azure AD tokens. If you need to use your client for longer\nthan the lifetime (typically 30 minutes), rerun `client.auth_azuread` periodically.\n\n### Azure AD authentication with Azure CLI\n\n[Install the Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest).\n\n```\npip install databricks-client[azurecli]\naz login\n```\n\n```python\nimport databricks_client\n\nclient = databricks_client.create(\"https://northeurope.azuredatabricks.net/api/2.0\")\nclient.auth_azuread(\"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/my-rg/providers/Microsoft.Databricks/workspaces/my-workspace\")\n# or client.auth_azuread(resource_group=\"my-rg\", workspace_name=\"my-workspace\")\nclient.ensure_available()\nclusters_list = client.get('clusters/list')\nfor cluster in clusters_list[\"clusters\"]:\n    print(cluster)\n```\n\nThis is recommended with Azure DevOps Pipelines using the [Azure CLI task](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops).\n\n### Azure AD authentication with ADAL\n\n```\npip install databricks-client\npip install adal\n```\n\n```python\nimport databricks_client\nimport adal\n\nauthority_host_uri = 'https://login.microsoftonline.com'\nauthority_uri = authority_host_uri + '/' + tenant_id\ncontext = adal.AuthenticationContext(authority_uri)\n\ndef token_callback(resource):\n    return context.acquire_token_with_client_credentials(resource, client_id, client_secret)[\"accessToken\"]\n\nclient = databricks_client.create(\"https://northeurope.azuredatabricks.net/api/2.0\")\nclient.auth_azuread(\"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/my-rg/providers/Microsoft.Databricks/workspaces/my-workspace\", token_callback)\n# or client.auth_azuread(resource_group=\"my-rg\", workspace_name=\"my-workspace\", token_callback=token_callback)\nclient.ensure_available()\nclusters_list = client.get('clusters/list')\nfor cluster in clusters_list[\"clusters\"]:\n    print(cluster)\n```\n\n## Example usages\n\n### Generating a PAT token\n\n```python\nresponse = client.post(\n    'token/create',\n    json={\"lifetime_seconds\": 60, \"comment\": \"Unit Test Token\"}\n)\npat_token = response['token_value']\n```\n\n### Uploading a notebook\n\n```python\nimport base64\n\nwith open(notebook_file, \"rb\") as f:\n    file_content = f.read()\n\nclient.post(\n    'workspace/import',\n    json={\n        \"content\": base64.b64encode(file_content).decode('ascii'),\n        \"path\": notebook_path,\n        \"overwrite\": False,\n        \"language\": \"PYTHON\",\n        \"format\": \"SOURCE\"\n    }\n)\n```\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/microsoft/DataOps", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "databricks-client", "package_url": "https://pypi.org/project/databricks-client/", "platform": "", "project_url": "https://pypi.org/project/databricks-client/", "project_urls": {"Homepage": "https://github.com/microsoft/DataOps"}, "release_url": "https://pypi.org/project/databricks-client/0.0.3/", "requires_dist": ["requests", "azure-core ; extra == 'azurecli'"], "requires_python": "", "summary": "REST client for Databricks", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>databricks-client</h1>\n<h2>About</h2>\n<p>A REST client for the <a href=\"https://docs.databricks.com/dev-tools/api/latest/index.html\" rel=\"nofollow\">Databricks REST API</a>.</p>\n<p>This module is a thin layer allowing to build HTTP <a href=\"https://requests.readthedocs.io/en/master/\" rel=\"nofollow\">Requests</a>.\nIt does not expose API operations as distinct methods, but rather exposes generic methods allowing\nto build API calls.</p>\n<p>The Databricks API sometimes returns 200 error codes and HTML content when the request is not\nproperly authenticated. The client intercepts such occurrences (detecting non-JSON returned content)\nand wraps them into an exception.</p>\n<p><em>This open-source project is not developed by nor affiliated with Databricks.</em></p>\n<h2>Installing</h2>\n<pre><code>pip install databricks-client\n</code></pre>\n<h2>Usage</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">databricks_client</span>\n\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">databricks_client</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"s2\">\"https://northeurope.azuredatabricks.net/api/2.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">auth_pat_token</span><span class=\"p\">(</span><span class=\"n\">pat_token</span><span class=\"p\">)</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">ensure_available</span><span class=\"p\">()</span>\n<span class=\"n\">clusters_list</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'clusters/list'</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">cluster</span> <span class=\"ow\">in</span> <span class=\"n\">clusters_list</span><span class=\"p\">[</span><span class=\"s2\">\"clusters\"</span><span class=\"p\">]:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"p\">)</span>\n</pre>\n<h2>Usage with a newly provisioned workspace</h2>\n<p>If using this module as part of a provisioning job, you need to call <code>client.ensure_available()</code>.</p>\n<p>When the first user logs it to a new Databricks workspace, workspace provisioning is triggered,\nand the API is not available until that job has completed (that usually takes under a minute,\nbut could take longer depending on the network configuration). In that case you would get an\nerror such as the following when calling the API:</p>\n<pre><code>\"Succeeded{\"error_code\":\"INVALID_PARAMETER_VALUE\",\"message\":\"Unknown worker environment WorkerEnvId(workerenv-4312344789891641)\"}\n</code></pre>\n<p>The method <code>client.ensure_available(url=\"instance-pools/list\", retries=100, delay_seconds=6)</code>\nprevents this error by attempting to\nconnect to the provided URL and retries as long as the workspace is in provisioning\nstate, or until the given number of retries has elapsed.</p>\n<h2>Usage with Azure Active Directory</h2>\n<p>Note: Azure AD authentication for Databricks is currently in preview.</p>\n<p>The client generates short-lived Azure AD tokens. If you need to use your client for longer\nthan the lifetime (typically 30 minutes), rerun <code>client.auth_azuread</code> periodically.</p>\n<h3>Azure AD authentication with Azure CLI</h3>\n<p><a href=\"https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest\" rel=\"nofollow\">Install the Azure CLI</a>.</p>\n<pre><code>pip install databricks-client[azurecli]\naz login\n</code></pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">databricks_client</span>\n\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">databricks_client</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"s2\">\"https://northeurope.azuredatabricks.net/api/2.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">auth_azuread</span><span class=\"p\">(</span><span class=\"s2\">\"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/my-rg/providers/Microsoft.Databricks/workspaces/my-workspace\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># or client.auth_azuread(resource_group=\"my-rg\", workspace_name=\"my-workspace\")</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">ensure_available</span><span class=\"p\">()</span>\n<span class=\"n\">clusters_list</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'clusters/list'</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">cluster</span> <span class=\"ow\">in</span> <span class=\"n\">clusters_list</span><span class=\"p\">[</span><span class=\"s2\">\"clusters\"</span><span class=\"p\">]:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"p\">)</span>\n</pre>\n<p>This is recommended with Azure DevOps Pipelines using the <a href=\"https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops\" rel=\"nofollow\">Azure CLI task</a>.</p>\n<h3>Azure AD authentication with ADAL</h3>\n<pre><code>pip install databricks-client\npip install adal\n</code></pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">databricks_client</span>\n<span class=\"kn\">import</span> <span class=\"nn\">adal</span>\n\n<span class=\"n\">authority_host_uri</span> <span class=\"o\">=</span> <span class=\"s1\">'https://login.microsoftonline.com'</span>\n<span class=\"n\">authority_uri</span> <span class=\"o\">=</span> <span class=\"n\">authority_host_uri</span> <span class=\"o\">+</span> <span class=\"s1\">'/'</span> <span class=\"o\">+</span> <span class=\"n\">tenant_id</span>\n<span class=\"n\">context</span> <span class=\"o\">=</span> <span class=\"n\">adal</span><span class=\"o\">.</span><span class=\"n\">AuthenticationContext</span><span class=\"p\">(</span><span class=\"n\">authority_uri</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">token_callback</span><span class=\"p\">(</span><span class=\"n\">resource</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">context</span><span class=\"o\">.</span><span class=\"n\">acquire_token_with_client_credentials</span><span class=\"p\">(</span><span class=\"n\">resource</span><span class=\"p\">,</span> <span class=\"n\">client_id</span><span class=\"p\">,</span> <span class=\"n\">client_secret</span><span class=\"p\">)[</span><span class=\"s2\">\"accessToken\"</span><span class=\"p\">]</span>\n\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">databricks_client</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"s2\">\"https://northeurope.azuredatabricks.net/api/2.0\"</span><span class=\"p\">)</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">auth_azuread</span><span class=\"p\">(</span><span class=\"s2\">\"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/my-rg/providers/Microsoft.Databricks/workspaces/my-workspace\"</span><span class=\"p\">,</span> <span class=\"n\">token_callback</span><span class=\"p\">)</span>\n<span class=\"c1\"># or client.auth_azuread(resource_group=\"my-rg\", workspace_name=\"my-workspace\", token_callback=token_callback)</span>\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">ensure_available</span><span class=\"p\">()</span>\n<span class=\"n\">clusters_list</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'clusters/list'</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">cluster</span> <span class=\"ow\">in</span> <span class=\"n\">clusters_list</span><span class=\"p\">[</span><span class=\"s2\">\"clusters\"</span><span class=\"p\">]:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"p\">)</span>\n</pre>\n<h2>Example usages</h2>\n<h3>Generating a PAT token</h3>\n<pre><span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span>\n    <span class=\"s1\">'token/create'</span><span class=\"p\">,</span>\n    <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"lifetime_seconds\"</span><span class=\"p\">:</span> <span class=\"mi\">60</span><span class=\"p\">,</span> <span class=\"s2\">\"comment\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Unit Test Token\"</span><span class=\"p\">}</span>\n<span class=\"p\">)</span>\n<span class=\"n\">pat_token</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"p\">[</span><span class=\"s1\">'token_value'</span><span class=\"p\">]</span>\n</pre>\n<h3>Uploading a notebook</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">base64</span>\n\n<span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">notebook_file</span><span class=\"p\">,</span> <span class=\"s2\">\"rb\"</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n    <span class=\"n\">file_content</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n\n<span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span>\n    <span class=\"s1\">'workspace/import'</span><span class=\"p\">,</span>\n    <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span>\n        <span class=\"s2\">\"content\"</span><span class=\"p\">:</span> <span class=\"n\">base64</span><span class=\"o\">.</span><span class=\"n\">b64encode</span><span class=\"p\">(</span><span class=\"n\">file_content</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"s1\">'ascii'</span><span class=\"p\">),</span>\n        <span class=\"s2\">\"path\"</span><span class=\"p\">:</span> <span class=\"n\">notebook_path</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"overwrite\"</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"language\"</span><span class=\"p\">:</span> <span class=\"s2\">\"PYTHON\"</span><span class=\"p\">,</span>\n        <span class=\"s2\">\"format\"</span><span class=\"p\">:</span> <span class=\"s2\">\"SOURCE\"</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 6702392, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "d2a3ab25e61bbfb3acaa6c3ac033f0d3", "sha256": "f8b31e7663bfb11a8a2d46b5a29a35285d286b2ed3b7c52fe1ba441a5dda67f6"}, "downloads": -1, "filename": "databricks_client-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d2a3ab25e61bbfb3acaa6c3ac033f0d3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4430, "upload_time": "2020-01-18T08:29:23", "upload_time_iso_8601": "2020-01-18T08:29:23.928497Z", "url": "https://files.pythonhosted.org/packages/70/c5/c08beeb03179f2c261aaad5731ac07df29b59775fbd240acb54ae252b5d4/databricks_client-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "de84bf596c30ec232c91ad3838443df9", "sha256": "aea00bdfeada23548c7b7fa3becfc26e2e6e265d42b8a6e74b2d7e0bab845a91"}, "downloads": -1, "filename": "databricks_client-0.0.1.tar.gz", "has_sig": false, "md5_digest": "de84bf596c30ec232c91ad3838443df9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3350, "upload_time": "2020-01-18T08:24:20", "upload_time_iso_8601": "2020-01-18T08:24:20.271956Z", "url": "https://files.pythonhosted.org/packages/81/0e/58471c76de62d818e155c22aeb409057d8e5a0df2d28602618e87805fbd6/databricks_client-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "039629cf8c5761987aed8f6d7b4548c9", "sha256": "f847d9abde84c7532838130bf379025b31b2c8af94f128a98d529620b9f0f833"}, "downloads": -1, "filename": "databricks_client-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "039629cf8c5761987aed8f6d7b4548c9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4744, "upload_time": "2020-01-30T12:55:35", "upload_time_iso_8601": "2020-01-30T12:55:35.383935Z", "url": "https://files.pythonhosted.org/packages/ad/c3/cf0972f47927486a2669b5fa46d827e4c9e86634a478d72d8a222447dc04/databricks_client-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e215d06bc743746ad1ca140a83912c5d", "sha256": "421cbec138e8b929f69291e44fd4c260cbcb8c4028a375593dba7a0bb61d1fdb"}, "downloads": -1, "filename": "databricks_client-0.0.2.tar.gz", "has_sig": false, "md5_digest": "e215d06bc743746ad1ca140a83912c5d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4688, "upload_time": "2020-01-30T12:55:36", "upload_time_iso_8601": "2020-01-30T12:55:36.734273Z", "url": "https://files.pythonhosted.org/packages/bd/c0/ee5a6b8a28c2023815de5792df5ca55377313d9a1ea8586069c8eed5ee32/databricks_client-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "995e425131348edf43ba81d6146b9ec8", "sha256": "86262d9853644c282a7175e2a97597728838ba7760f77cc58882c23d8f03c4a4"}, "downloads": -1, "filename": "databricks_client-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "995e425131348edf43ba81d6146b9ec8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4893, "upload_time": "2020-02-26T09:51:25", "upload_time_iso_8601": "2020-02-26T09:51:25.966527Z", "url": "https://files.pythonhosted.org/packages/45/3f/5225615040e9d632e2ae9e355286b73f4125411e55300d0b00a70bd0a630/databricks_client-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef38fb080f27ae16e73da7f7098f4b4c", "sha256": "1cb4600ec562a78e4c4e601931d4e2a3722eff6a972a825e6016d063edce25cf"}, "downloads": -1, "filename": "databricks_client-0.0.3.tar.gz", "has_sig": false, "md5_digest": "ef38fb080f27ae16e73da7f7098f4b4c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4584, "upload_time": "2020-02-26T09:51:27", "upload_time_iso_8601": "2020-02-26T09:51:27.363195Z", "url": "https://files.pythonhosted.org/packages/d3/2d/ce9b221b49889d17ecac400ac54b7e434abec6176e42fecc7cde637ed5d0/databricks_client-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "995e425131348edf43ba81d6146b9ec8", "sha256": "86262d9853644c282a7175e2a97597728838ba7760f77cc58882c23d8f03c4a4"}, "downloads": -1, "filename": "databricks_client-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "995e425131348edf43ba81d6146b9ec8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4893, "upload_time": "2020-02-26T09:51:25", "upload_time_iso_8601": "2020-02-26T09:51:25.966527Z", "url": "https://files.pythonhosted.org/packages/45/3f/5225615040e9d632e2ae9e355286b73f4125411e55300d0b00a70bd0a630/databricks_client-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef38fb080f27ae16e73da7f7098f4b4c", "sha256": "1cb4600ec562a78e4c4e601931d4e2a3722eff6a972a825e6016d063edce25cf"}, "downloads": -1, "filename": "databricks_client-0.0.3.tar.gz", "has_sig": false, "md5_digest": "ef38fb080f27ae16e73da7f7098f4b4c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4584, "upload_time": "2020-02-26T09:51:27", "upload_time_iso_8601": "2020-02-26T09:51:27.363195Z", "url": "https://files.pythonhosted.org/packages/d3/2d/ce9b221b49889d17ecac400ac54b7e434abec6176e42fecc7cde637ed5d0/databricks_client-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:30 2020"}