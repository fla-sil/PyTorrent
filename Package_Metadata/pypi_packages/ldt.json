{"info": {"author": "Anna Rogers", "author_email": "anna_rogers@uml.edu", "bugtrack_url": null, "classifiers": ["Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Text Processing :: Linguistic"], "description": "====================================\nLinguistic Diagnostics Toolkit (LDT)\n====================================\n\n.. image:: https://travis-ci.com/annargrs/ldt.svg?branch=master\n   :target: https://travis-ci.com/annargrs/ldt\n   :alt: Build Status\n\n.. inclusion-marker-begin-do-not-remove\n\nLDT is a shiny new Python library for doing two things:\n\n* querying lots of dictionaries from a unified interface to perform **spelling normalization, lemmatization, morphological analysis, retrieving semantic relations from WordNet, Wiktionary, BabelNet**, and a lot more.\n\n* using the above to **explore and profile word embeddings**, i.e. the cool distributional representations of words as vectors.\n\nIf you have never heard about word embeddings -- you're missing out, here's `an introduction <https://www.shanelynn.ie/get-busy-with-word-embeddings-introduction/>`_.  If you have, head  over to the `project website <ldtoolkit.space>`_ for some new research results. And if you don't care about word embeddings, you can still just use LDT as a supplement to NLTK, SpaCy, and other great NLP tools.\n\n**Note:** LDT is in active development; all the dictionary functionality for English and scripts for running experiments are already available. Integration with `vecto library <vecto.space>`_ and optimization are coming in the nearest weeks; please update your installation often. You can also join the `discussion <https://groups.google.com/forum/#!forum/linguistic-diagnostics>`_ group to discuss your results and get notified about new releases!\n\n---------------------------------\nLDT for profiling word embeddings\n---------------------------------\n\n`Install and configure <https://ldt.readthedocs.io/Tutorial/installation.html>`_\nldt, and run this sample script (and/or change it to tweak the `resources <https://ldt.readthedocs.io/Tutorial/dicts/index.html>`_\nused for relation detection):\n\n::\n\n   python3 -m ldt.experiments.default_workflow\n\nThe output will be something like this:\n\n+-------------------+--------+--------+--------+\n| LD score          | CBOW   | GloVe  | SG     |\n+-------------------+--------+--------+--------+\n| SharedMorphForm   | 51.819 | 52.061 | 52.9   |\n+-------------------+--------+--------+--------+\n| SharedPOS         | 30.061 | 35.507 | 31.706 |\n+-------------------+--------+--------+--------+\n| SharedDerivation  | 4.468  | 3.938  | 5.084  |\n+-------------------+--------+--------+--------+\n| Synonyms          | 0.413  | 0.443  | 0.447  |\n+-------------------+--------+--------+--------+\n| Antonyms          | 0.128  | 0.133  | 0.144  |\n+-------------------+--------+--------+--------+\n| Hyponyms          | 0.035  | 0.035  | 0.038  |\n+-------------------+--------+--------+--------+\n| OtherRelations    | 0.013  | 0.013  | 0.013  |\n+-------------------+--------+--------+--------+\n| Misspellings      | 13.546 | 9.914  | 12.809 |\n+-------------------+--------+--------+--------+\n| ProperNouns       | 30.442 | 27.278 | 27.864 |\n+-------------------+--------+--------+--------+\n| CloseNeighbors    | 3.102  | 0.16   | 2.278  |\n+-------------------+--------+--------+--------+\n| FarNeighbors      | 25.209 | 49.934 | 21.41  |\n+-------------------+--------+--------+--------+\n\nThe numbers here indicate percentage of neighbor vectors that held the\nindicated relation with each target word in the sample. The information is\ncoming from a ton of dictionaries (see below), and you can fine-tune which\nones you want to use.\n\nLDT profile explains what kinds of information your embedding model\nactually captures. That can help you predict how your model will do on\na  particular task, and also give some ideas about how it can be improved.\nCheck out the `results of a large-scale experiment with 60 embeddings and 21\ndatasets. <http://ldtoolkit.space/analysis/correlation/>`_\n\nAnd yes, you heard it right, you can use your own vocabulary sample - the one\nthat actually makes sense for whatever  downstream task you're optimizing for!\n\nNote:\n\n   The current implementation queries online resources, so a large\n   experiment will take time. Stay tuned, we're working on making it faster.\n   The distribution analysis is currently provided only for embeddings\n   trained on    our `pre-processed Wikipedia dump <http://ldtoolkit.space/task_data/>`_,\n   which is also available in dependency-parsed version.\n   Functionality for computing distriburional information from any other\n   corpora is coming.\n\n-----------------------------------------\nLDT for detecting relations in word pairs\n-----------------------------------------\n\nThe main function of LDT is automatic detection of linguistic relations\nthat *could* possibly hold in a pair of words. This super-complicated\nprocedure can now be performed in one click:\n\n>>> relation_analyzer = ldt.relations.RelationsInPair()\n>>> relation_analyzer.analyze(\"black\", \"white\")\n{'Hyponyms': True,\n 'SharedMorphForm': True,\n 'SharedPOS': True,\n 'Synonyms': True,\n 'Antonyms': True,\n 'ShortestPath': 0.058823529411764705,\n 'Associations': True}\n\nIt goes without saying that *white* and *black* are not always antonyms.\nContext dependence is something we're thinking about, stay tuned for future\nwork.\n\n---------------------------------\nLDT for working with dictionaries\n---------------------------------\n\nThe above information comes from a ton of various dictionary resources. You\ncan access all combined information about any given word in one click:\n\n>>> encapsulation = ldt.Word(\"encapsulation\")\n>>> encapsulation.pp_info()\n======DERIVATIONAL INFO======\nStems :  capsulate, encapsulate, capsule\nSuffixes :  -ion, -ate\nPrefixes :  en-\nOtherDerivation :\nRelatedWords :  encapsulation, capsule review, glissonian capsule, capsular, capsulate\n======SEMANTIC INFO======\nSynonyms :  encapsulation\nAntonyms :\nMeronyms :\nHyponyms :\nHypernyms :  physical_process, status, condition, process\n======EXTRA WORD CLASSES======\nProperNouns :  False\nNoise :  False\nNumbers :  False\nURLs :  False\nHashtags :  False\nFilenames :  False\nForeignWords :  False\nMisspellings :  False\nMissing :  False\n\nTo provide this, LDT queries various old and new resources. Accordingly,\nthey are all now accessible from a unified Python interface,\nmaking LDT usable in other NLP research areas as a companions to NLTK.\n\nA few quick highlights of ldt resources:\n\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nRetrieving related words from WordNet, Wiktionary, Wiktionary Thesaurus and BabelNet:\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n>>> wiktionary = ldt.dicts.semantics.Wiktionary()\n>>> wiktionary.get_relation(\"white\", relation=\"synonyms\")\n['pale', 'fair']\n>>> wikisaurus = ldt.dicts.semantics.Wikisaurus()\n>>> wikisaurus.get_relations(\"cat\", relations=\"all\")\n{'synonyms': ['tabby', 'puss', 'cat', 'kitty', 'moggy', 'housecat', 'malkin', 'kitten', 'tom', 'grimalkin', 'pussy-cat', 'mouser', 'pussy', 'queen', 'tomcat', 'mog'],\n 'hyponyms': [],\n 'hypernyms': ['mammal', 'carnivore', 'vertebrate', 'feline', 'animal', 'creature'],\n 'antonyms': [],\n 'meronyms': []}\n>>> babelnet = ldt.dicts.semantics.BabelNet()\n>>> babelnet.get_relations(\"senator\", relations=(\"hypernyms\"))\n{'hypernyms': ['legislative_assembly', 'metropolitan_see_of_milan', 'poltician', 'legislative_seat', 'senator_of_rome', 'band', 'the_upper_house', 'polictian', 'patres_conscripti', 'musical_ensemble', 'presbytery', 'politician', 'pol', 'solo_project', 'policymaker', 'political_figure', 'politican', 'policymakers', 'archbishop_emeritus_of_milan', 'deliberative_assemblies', 'ensemble', 'career_politics', 'soloproject', 'list_of_musical_ensembles', 'legislative', 'roman_senators', 'archbishopric_of_milan', 'politicain', 'rock_bands', 'section_leader', 'musical_organisation', 'music_band', 'four-piece', 'roman_catholic_archdiocese_of_milan', 'upper_house', 'archdiocese_of_milan', 'band_man', 'milanese_apostolic_catholic_church', 'legistrative_branch', 'group', 'solo-project', 'music_ensemble', 'law-makers', 'roman_senator', 'legislative_arm_of_government', 'solo_act', 'patronage', 'roman_catholic_archbishop_of_milan', 'bar_band', 'senate_of_rome', 'deliberative_body', 'see_of_milan', 'legislative_fiat', 'musical_group', 'ambrosian_catholic_church', 'legislature_of_orissa', 'legislative_branch_of_government', 'list_of_politicians', 'senatorial_lieutenant', 'roman_catholic_archdiocese_of_milano', 'legislature_of_odisha', 'bandmember', 'assembly', 'archdiocese_of_milano', 'bishop_of_milan', 'ensemble_music', 'solo_musician', 'musical_duo', 'legislative_branch_of_goverment', 'first_chamber', 'politicians', 'legislative_bodies', 'political_leaders', 'politico', 'music_group', 'legislative_body', 'career_politician', 'legislature', 'rock_group', 'legislative_power', 'diocese_of_milan', 'musical_ensembles', 'musical_organization', 'revising_chamber', 'archbishops_of_milan', 'political_leader', 'deliberative_assembly', 'conscript_fathers', 'five-piece', 'catholic_archdiocese_of_milan', 'pop_rock_band', 'senatrix', 'deliberative_organ', 'polit.', 'roman_senate', 'legislative_politics', 'bishopric_of_milan', 'legislative_branch', 'musical_band', 'archbishop_of_milan', 'legislatures', 'general_assembly', 'musical_groups', 'instrumental_ensemble', 'politition', 'patres', 'upper_chamber', 'solo-act', 'conscripti', 'legislator']}\n\n++++++++++++++++++++++\nDerivational analysis:\n++++++++++++++++++++++\n\n>>> derivation_dict = ldt.dicts.derivation.DerivationAnalyzer()\n>>> derivation_dict.analyze(\"kindness\")\n{'original_word': ['kindness'],\n 'other': [],\n  'prefixes': [],\n  'related_words': ['kindhearted', 'kindly', 'in kind', 'kindliness', 'kinda', 'many-kinded', 'first-of-its-kind', 'kind of', 'kindful', 'kindless'],\n  'roots': ['kind'],\n  'suffixes': ['-ness']}\n\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nReliable lemmatization with productive rules and Wiktionary/BabelNet:\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\nWordNet lemmatizer is limited by the size of its lexical base, even when\nthe morphological pattern is straightforward.\n\n>>> morph_metadict = ldt.dicts.morphology.MorphMetaDict()\n>>> morph_metadict.lemmatize(\"GPUs\")\n['GPU']\n\n+++++++++++++++++++\nInput normalization\n+++++++++++++++++++\n\nVector neighborhoods are often full of pre-processing noise and misspellings. LDT does its best to clean up some straightforward cases:\n\n>>> analyzer = ldt.dicts.normalize.Normalization()\n>>> analyzer.normalize(\"%grammar\")\n{'lemmas': ['grammar'],\n 'found_in': ['wordnet'],\n 'word_categories': ['Misspellings'],\n 'pos': ['noun']}\n>>> analyzer.normalize(\"gram-mar\")\n{'found_in': ['wordnet'],\n 'lemmas': ['grammar'],\n 'word_categories': ['Misspellings'],\n 'pos': ['noun']}\n>>> analyzer.normalize(\"grammarlexicon\")\n{'found_in': ['wordnet'],\n'lemmas': ['grammar', \"lexicon],\n'word_categories': ['Misspellings'],\n'pos': ['noun']}\n\nLDT also provides the option of correction of frequent misspelling patterns\n(only for high-certainty cases):\n\n>>> spellchecker_en = ldt.dicts.spellcheck.SpellcheckerEn()\n>>> spellchecker_en.spelling_nazi(\"abritrary\")\n'arbitrary'\n\n.. inclusion-marker-end-do-not-remove\n\n-----------\nQuick links\n-----------\n\n * `Installation instructions <https://ldt.readthedocs.io/Tutorial/installation.html>`_\n * `Project website <http://ldtoolkit.space>`_\n * `Tutorial <https://ldt.readthedocs.io/Tutorial/index.html>`_\n * `API reference <https://ldt.readthedocs.io/genindex.html>`_.\n * `Published research results <http://aclweb.org/anthology/C18-1228>`_.\n * `Word embeddings leaderboard <http://ldtoolkit.space/leaderboard/>`_.\n * `Correlation of LD scores with downstream task performance <http://ldtoolkit.space/analysis/correlation/>`_.\n\n-------\nSupport\n-------\n\nIf something doesn't work, open an issue on GitHub.\n\n---------------\nMultilinguality\n---------------\n\nYes, LDT is multilingual! At least, as far as querying semantic relations\ngoes. LDT supports BabelNet, the largest multilingual dictionary resource available -\nso everything they have is retrievable. Many of the other LDT modules (particularly morphology)\nare language-specific, and only English is fully supported at\nthe moment. However, the infrastructure for adding other languages is already\nin place, so if you can find or create e.g. lists of affixes for your\nlanguage, development would be easy. Get in touch if you'd like to get\ninvolved.\n\nLegal caveat: LDT is open-source free software. No hamsters were harmed in its production,\nand no harm should come from its usage. However, no guarantees of any kind.\n\n\nv. 0.4.0, 2018-11-14\n\n* bug fixes\n\nv.0.3.9, 2018-11-04\n\n* multicore processing in annotation module\n* query timeout setting\n* optimized loading of cooccurrence data in ldt resources\n* corpus statistics now optional\n* minor fixes\n\nv. 0.3.0, 2018-10-08\n\n* experiments package:\n  - extracting vector neighborhoods with optional normalization\n  - annotating vector neighborhoods with linguistic relations\n  - analysing the results\n  - automatically logging metadata for all experiments\n* bug fixes\n\nv 0.2.1, 2018-09-25.\n\n* bug fixes.\n\nv 0.2.0, 2018-09-24.\n\n* Tutorial;\n* 19 LD variables, including ontology paths;\n* detection of antonymy with language-specific derivational patterns;\n* bug fixes.\n\nv 0.1.0, 2018-08-15 -- Initial release.\n\n* Retrieving lexicographic information from BabelNet, Wiktionary, Wikisaurus and English WordNet;\n* Retrieving morphological information from the same resources;\n* Lemmatization with WordNet and custom rules for English;\n* Custom rule-based analysis of productive suffixes and prefixes for English;\n* Parsing Wiktionary etymologies\n* Custom compound splitting routines with filtering by subword length;\n* 4 custom patterns for fixing frequent spelling mistakes.\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://ldtoolkit.space/", "keywords": "", "license": "Apache Software License", "maintainer": "", "maintainer_email": "", "name": "ldt", "package_url": "https://pypi.org/project/ldt/", "platform": "any", "project_url": "https://pypi.org/project/ldt/", "project_urls": {"Homepage": "http://ldtoolkit.space/"}, "release_url": "https://pypi.org/project/ldt/0.4.0/", "requires_dist": ["hurry.filesize", "inflect", "nltk", "outdated", "p-tqdm", "pandas", "pyenchant", "ruamel.yaml", "timeout-decorator", "vecto", "wiktionaryparser (==0.0.7)", "pytest; extra == 'testing'"], "requires_python": "", "summary": "Linguistic diagnostics for word embeddings", "version": "0.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            ====================================<br>Linguistic Diagnostics Toolkit (LDT)<br>====================================<br><br>.. image:: https://travis-ci.com/annargrs/ldt.svg?branch=master<br>   :target: https://travis-ci.com/annargrs/ldt<br>   :alt: Build Status<br><br>.. inclusion-marker-begin-do-not-remove<br><br>LDT is a shiny new Python library for doing two things:<br><br>* querying lots of dictionaries from a unified interface to perform **spelling normalization, lemmatization, morphological analysis, retrieving semantic relations from WordNet, Wiktionary, BabelNet**, and a lot more.<br><br>* using the above to **explore and profile word embeddings**, i.e. the cool distributional representations of words as vectors.<br><br>If you have never heard about word embeddings -- you're missing out, here's `an introduction &lt;https://www.shanelynn.ie/get-busy-with-word-embeddings-introduction/&gt;`_.  If you have, head  over to the `project website &lt;ldtoolkit.space&gt;`_ for some new research results. And if you don't care about word embeddings, you can still just use LDT as a supplement to NLTK, SpaCy, and other great NLP tools.<br><br>**Note:** LDT is in active development; all the dictionary functionality for English and scripts for running experiments are already available. Integration with `vecto library &lt;vecto.space&gt;`_ and optimization are coming in the nearest weeks; please update your installation often. You can also join the `discussion &lt;https://groups.google.com/forum/#!forum/linguistic-diagnostics&gt;`_ group to discuss your results and get notified about new releases!<br><br>---------------------------------<br>LDT for profiling word embeddings<br>---------------------------------<br><br>`Install and configure &lt;https://ldt.readthedocs.io/Tutorial/installation.html&gt;`_<br>ldt, and run this sample script (and/or change it to tweak the `resources &lt;https://ldt.readthedocs.io/Tutorial/dicts/index.html&gt;`_<br>used for relation detection):<br><br>::<br><br>   python3 -m ldt.experiments.default_workflow<br><br>The output will be something like this:<br><br>+-------------------+--------+--------+--------+<br>| LD score          | CBOW   | GloVe  | SG     |<br>+-------------------+--------+--------+--------+<br>| SharedMorphForm   | 51.819 | 52.061 | 52.9   |<br>+-------------------+--------+--------+--------+<br>| SharedPOS         | 30.061 | 35.507 | 31.706 |<br>+-------------------+--------+--------+--------+<br>| SharedDerivation  | 4.468  | 3.938  | 5.084  |<br>+-------------------+--------+--------+--------+<br>| Synonyms          | 0.413  | 0.443  | 0.447  |<br>+-------------------+--------+--------+--------+<br>| Antonyms          | 0.128  | 0.133  | 0.144  |<br>+-------------------+--------+--------+--------+<br>| Hyponyms          | 0.035  | 0.035  | 0.038  |<br>+-------------------+--------+--------+--------+<br>| OtherRelations    | 0.013  | 0.013  | 0.013  |<br>+-------------------+--------+--------+--------+<br>| Misspellings      | 13.546 | 9.914  | 12.809 |<br>+-------------------+--------+--------+--------+<br>| ProperNouns       | 30.442 | 27.278 | 27.864 |<br>+-------------------+--------+--------+--------+<br>| CloseNeighbors    | 3.102  | 0.16   | 2.278  |<br>+-------------------+--------+--------+--------+<br>| FarNeighbors      | 25.209 | 49.934 | 21.41  |<br>+-------------------+--------+--------+--------+<br><br>The numbers here indicate percentage of neighbor vectors that held the<br>indicated relation with each target word in the sample. The information is<br>coming from a ton of dictionaries (see below), and you can fine-tune which<br>ones you want to use.<br><br>LDT profile explains what kinds of information your embedding model<br>actually captures. That can help you predict how your model will do on<br>a  particular task, and also give some ideas about how it can be improved.<br>Check out the `results of a large-scale experiment with 60 embeddings and 21<br>datasets. &lt;http://ldtoolkit.space/analysis/correlation/&gt;`_<br><br>And yes, you heard it right, you can use your own vocabulary sample - the one<br>that actually makes sense for whatever  downstream task you're optimizing for!<br><br>Note:<br><br>   The current implementation queries online resources, so a large<br>   experiment will take time. Stay tuned, we're working on making it faster.<br>   The distribution analysis is currently provided only for embeddings<br>   trained on    our `pre-processed Wikipedia dump &lt;http://ldtoolkit.space/task_data/&gt;`_,<br>   which is also available in dependency-parsed version.<br>   Functionality for computing distriburional information from any other<br>   corpora is coming.<br><br>-----------------------------------------<br>LDT for detecting relations in word pairs<br>-----------------------------------------<br><br>The main function of LDT is automatic detection of linguistic relations<br>that *could* possibly hold in a pair of words. This super-complicated<br>procedure can now be performed in one click:<br><br>&gt;&gt;&gt; relation_analyzer = ldt.relations.RelationsInPair()<br>&gt;&gt;&gt; relation_analyzer.analyze(\"black\", \"white\")<br>{'Hyponyms': True,<br> 'SharedMorphForm': True,<br> 'SharedPOS': True,<br> 'Synonyms': True,<br> 'Antonyms': True,<br> 'ShortestPath': 0.058823529411764705,<br> 'Associations': True}<br><br>It goes without saying that *white* and *black* are not always antonyms.<br>Context dependence is something we're thinking about, stay tuned for future<br>work.<br><br>---------------------------------<br>LDT for working with dictionaries<br>---------------------------------<br><br>The above information comes from a ton of various dictionary resources. You<br>can access all combined information about any given word in one click:<br><br>&gt;&gt;&gt; encapsulation = ldt.Word(\"encapsulation\")<br>&gt;&gt;&gt; encapsulation.pp_info()<br>======DERIVATIONAL INFO======<br>Stems :  capsulate, encapsulate, capsule<br>Suffixes :  -ion, -ate<br>Prefixes :  en-<br>OtherDerivation :<br>RelatedWords :  encapsulation, capsule review, glissonian capsule, capsular, capsulate<br>======SEMANTIC INFO======<br>Synonyms :  encapsulation<br>Antonyms :<br>Meronyms :<br>Hyponyms :<br>Hypernyms :  physical_process, status, condition, process<br>======EXTRA WORD CLASSES======<br>ProperNouns :  False<br>Noise :  False<br>Numbers :  False<br>URLs :  False<br>Hashtags :  False<br>Filenames :  False<br>ForeignWords :  False<br>Misspellings :  False<br>Missing :  False<br><br>To provide this, LDT queries various old and new resources. Accordingly,<br>they are all now accessible from a unified Python interface,<br>making LDT usable in other NLP research areas as a companions to NLTK.<br><br>A few quick highlights of ldt resources:<br><br>+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br>Retrieving related words from WordNet, Wiktionary, Wiktionary Thesaurus and BabelNet:<br>+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br><br>&gt;&gt;&gt; wiktionary = ldt.dicts.semantics.Wiktionary()<br>&gt;&gt;&gt; wiktionary.get_relation(\"white\", relation=\"synonyms\")<br>['pale', 'fair']<br>&gt;&gt;&gt; wikisaurus = ldt.dicts.semantics.Wikisaurus()<br>&gt;&gt;&gt; wikisaurus.get_relations(\"cat\", relations=\"all\")<br>{'synonyms': ['tabby', 'puss', 'cat', 'kitty', 'moggy', 'housecat', 'malkin', 'kitten', 'tom', 'grimalkin', 'pussy-cat', 'mouser', 'pussy', 'queen', 'tomcat', 'mog'],<br> 'hyponyms': [],<br> 'hypernyms': ['mammal', 'carnivore', 'vertebrate', 'feline', 'animal', 'creature'],<br> 'antonyms': [],<br> 'meronyms': []}<br>&gt;&gt;&gt; babelnet = ldt.dicts.semantics.BabelNet()<br>&gt;&gt;&gt; babelnet.get_relations(\"senator\", relations=(\"hypernyms\"))<br>{'hypernyms': ['legislative_assembly', 'metropolitan_see_of_milan', 'poltician', 'legislative_seat', 'senator_of_rome', 'band', 'the_upper_house', 'polictian', 'patres_conscripti', 'musical_ensemble', 'presbytery', 'politician', 'pol', 'solo_project', 'policymaker', 'political_figure', 'politican', 'policymakers', 'archbishop_emeritus_of_milan', 'deliberative_assemblies', 'ensemble', 'career_politics', 'soloproject', 'list_of_musical_ensembles', 'legislative', 'roman_senators', 'archbishopric_of_milan', 'politicain', 'rock_bands', 'section_leader', 'musical_organisation', 'music_band', 'four-piece', 'roman_catholic_archdiocese_of_milan', 'upper_house', 'archdiocese_of_milan', 'band_man', 'milanese_apostolic_catholic_church', 'legistrative_branch', 'group', 'solo-project', 'music_ensemble', 'law-makers', 'roman_senator', 'legislative_arm_of_government', 'solo_act', 'patronage', 'roman_catholic_archbishop_of_milan', 'bar_band', 'senate_of_rome', 'deliberative_body', 'see_of_milan', 'legislative_fiat', 'musical_group', 'ambrosian_catholic_church', 'legislature_of_orissa', 'legislative_branch_of_government', 'list_of_politicians', 'senatorial_lieutenant', 'roman_catholic_archdiocese_of_milano', 'legislature_of_odisha', 'bandmember', 'assembly', 'archdiocese_of_milano', 'bishop_of_milan', 'ensemble_music', 'solo_musician', 'musical_duo', 'legislative_branch_of_goverment', 'first_chamber', 'politicians', 'legislative_bodies', 'political_leaders', 'politico', 'music_group', 'legislative_body', 'career_politician', 'legislature', 'rock_group', 'legislative_power', 'diocese_of_milan', 'musical_ensembles', 'musical_organization', 'revising_chamber', 'archbishops_of_milan', 'political_leader', 'deliberative_assembly', 'conscript_fathers', 'five-piece', 'catholic_archdiocese_of_milan', 'pop_rock_band', 'senatrix', 'deliberative_organ', 'polit.', 'roman_senate', 'legislative_politics', 'bishopric_of_milan', 'legislative_branch', 'musical_band', 'archbishop_of_milan', 'legislatures', 'general_assembly', 'musical_groups', 'instrumental_ensemble', 'politition', 'patres', 'upper_chamber', 'solo-act', 'conscripti', 'legislator']}<br><br>++++++++++++++++++++++<br>Derivational analysis:<br>++++++++++++++++++++++<br><br>&gt;&gt;&gt; derivation_dict = ldt.dicts.derivation.DerivationAnalyzer()<br>&gt;&gt;&gt; derivation_dict.analyze(\"kindness\")<br>{'original_word': ['kindness'],<br> 'other': [],<br>  'prefixes': [],<br>  'related_words': ['kindhearted', 'kindly', 'in kind', 'kindliness', 'kinda', 'many-kinded', 'first-of-its-kind', 'kind of', 'kindful', 'kindless'],<br>  'roots': ['kind'],<br>  'suffixes': ['-ness']}<br><br>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br>Reliable lemmatization with productive rules and Wiktionary/BabelNet:<br>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br><br>WordNet lemmatizer is limited by the size of its lexical base, even when<br>the morphological pattern is straightforward.<br><br>&gt;&gt;&gt; morph_metadict = ldt.dicts.morphology.MorphMetaDict()<br>&gt;&gt;&gt; morph_metadict.lemmatize(\"GPUs\")<br>['GPU']<br><br>+++++++++++++++++++<br>Input normalization<br>+++++++++++++++++++<br><br>Vector neighborhoods are often full of pre-processing noise and misspellings. LDT does its best to clean up some straightforward cases:<br><br>&gt;&gt;&gt; analyzer = ldt.dicts.normalize.Normalization()<br>&gt;&gt;&gt; analyzer.normalize(\"%grammar\")<br>{'lemmas': ['grammar'],<br> 'found_in': ['wordnet'],<br> 'word_categories': ['Misspellings'],<br> 'pos': ['noun']}<br>&gt;&gt;&gt; analyzer.normalize(\"gram-mar\")<br>{'found_in': ['wordnet'],<br> 'lemmas': ['grammar'],<br> 'word_categories': ['Misspellings'],<br> 'pos': ['noun']}<br>&gt;&gt;&gt; analyzer.normalize(\"grammarlexicon\")<br>{'found_in': ['wordnet'],<br>'lemmas': ['grammar', \"lexicon],<br>'word_categories': ['Misspellings'],<br>'pos': ['noun']}<br><br>LDT also provides the option of correction of frequent misspelling patterns<br>(only for high-certainty cases):<br><br>&gt;&gt;&gt; spellchecker_en = ldt.dicts.spellcheck.SpellcheckerEn()<br>&gt;&gt;&gt; spellchecker_en.spelling_nazi(\"abritrary\")<br>'arbitrary'<br><br>.. inclusion-marker-end-do-not-remove<br><br>-----------<br>Quick links<br>-----------<br><br> * `Installation instructions &lt;https://ldt.readthedocs.io/Tutorial/installation.html&gt;`_<br> * `Project website &lt;http://ldtoolkit.space&gt;`_<br> * `Tutorial &lt;https://ldt.readthedocs.io/Tutorial/index.html&gt;`_<br> * `API reference &lt;https://ldt.readthedocs.io/genindex.html&gt;`_.<br> * `Published research results &lt;http://aclweb.org/anthology/C18-1228&gt;`_.<br> * `Word embeddings leaderboard &lt;http://ldtoolkit.space/leaderboard/&gt;`_.<br> * `Correlation of LD scores with downstream task performance &lt;http://ldtoolkit.space/analysis/correlation/&gt;`_.<br><br>-------<br>Support<br>-------<br><br>If something doesn't work, open an issue on GitHub.<br><br>---------------<br>Multilinguality<br>---------------<br><br>Yes, LDT is multilingual! At least, as far as querying semantic relations<br>goes. LDT supports BabelNet, the largest multilingual dictionary resource available -<br>so everything they have is retrievable. Many of the other LDT modules (particularly morphology)<br>are language-specific, and only English is fully supported at<br>the moment. However, the infrastructure for adding other languages is already<br>in place, so if you can find or create e.g. lists of affixes for your<br>language, development would be easy. Get in touch if you'd like to get<br>involved.<br><br>Legal caveat: LDT is open-source free software. No hamsters were harmed in its production,<br>and no harm should come from its usage. However, no guarantees of any kind.<br><br><br>v. 0.4.0, 2018-11-14<br><br>* bug fixes<br><br>v.0.3.9, 2018-11-04<br><br>* multicore processing in annotation module<br>* query timeout setting<br>* optimized loading of cooccurrence data in ldt resources<br>* corpus statistics now optional<br>* minor fixes<br><br>v. 0.3.0, 2018-10-08<br><br>* experiments package:<br>  - extracting vector neighborhoods with optional normalization<br>  - annotating vector neighborhoods with linguistic relations<br>  - analysing the results<br>  - automatically logging metadata for all experiments<br>* bug fixes<br><br>v 0.2.1, 2018-09-25.<br><br>* bug fixes.<br><br>v 0.2.0, 2018-09-24.<br><br>* Tutorial;<br>* 19 LD variables, including ontology paths;<br>* detection of antonymy with language-specific derivational patterns;<br>* bug fixes.<br><br>v 0.1.0, 2018-08-15 -- Initial release.<br><br>* Retrieving lexicographic information from BabelNet, Wiktionary, Wikisaurus and English WordNet;<br>* Retrieving morphological information from the same resources;<br>* Lemmatization with WordNet and custom rules for English;<br>* Custom rule-based analysis of productive suffixes and prefixes for English;<br>* Parsing Wiktionary etymologies<br>* Custom compound splitting routines with filtering by subword length;<br>* 4 custom patterns for fixing frequent spelling mistakes.<br><br>\n          </div>"}, "last_serial": 4494139, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "9b70d03a5c60b012ac4b6df017a45201", "sha256": "9c97e40cddacbe75612c2eac32981401e3679a041622b7bec8e1422de49b3812"}, "downloads": -1, "filename": "ldt-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9b70d03a5c60b012ac4b6df017a45201", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3955824, "upload_time": "2018-09-26T17:42:24", "upload_time_iso_8601": "2018-09-26T17:42:24.448180Z", "url": "https://files.pythonhosted.org/packages/b6/98/f83444398d86505eefa8f9b481002e5dfc154945999d503d9c4b76815de7/ldt-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c0171e1b3e6ea85f8ea911b452ff57f1", "sha256": "b34fc27c34a6d0870ce814429361628a9b0bc400fdb5794a5fc8c15db3813db3"}, "downloads": -1, "filename": "ldt-0.1.0.tar.gz", "has_sig": false, "md5_digest": "c0171e1b3e6ea85f8ea911b452ff57f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3932192, "upload_time": "2018-09-26T17:42:31", "upload_time_iso_8601": "2018-09-26T17:42:31.954024Z", "url": "https://files.pythonhosted.org/packages/4c/c3/4fcd8774d189bbf4fbbc2f490a5065c83a142167f0e2ff90f3990e1e27d1/ldt-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "73c7a5200dfad2d252f61ef9d14068c8", "sha256": "aea304a6b1a5eb6898605321be554a904af49146910b25b75d0c35e233cfb738"}, "downloads": -1, "filename": "ldt-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "73c7a5200dfad2d252f61ef9d14068c8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3955827, "upload_time": "2018-09-26T17:49:22", "upload_time_iso_8601": "2018-09-26T17:49:22.490954Z", "url": "https://files.pythonhosted.org/packages/3a/2c/5dd9962f57c665b1b8a76cc279c684f869b20e03d736d9d7ca0a9f2ecb48/ldt-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23ee7607c0575db02c30118fbb14a5d6", "sha256": "9ced7d1a04b869ed023f44c962a7acada248add022aed307903f923a9590d98b"}, "downloads": -1, "filename": "ldt-0.2.0.tar.gz", "has_sig": false, "md5_digest": "23ee7607c0575db02c30118fbb14a5d6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3932196, "upload_time": "2018-09-26T17:49:36", "upload_time_iso_8601": "2018-09-26T17:49:36.238330Z", "url": "https://files.pythonhosted.org/packages/3c/d4/9569170f601588ef9a016a31ff13588621b076c4ef2b0ee4ef5c3b0dce66/ldt-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "841b45caef1cd50d512cc7bd4ec10092", "sha256": "e692ec57016247c99607abc1da5354861027e8fb976c35114c1858f1dffdb03b"}, "downloads": -1, "filename": "ldt-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "841b45caef1cd50d512cc7bd4ec10092", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4673296, "upload_time": "2018-09-27T01:47:36", "upload_time_iso_8601": "2018-09-27T01:47:36.103275Z", "url": "https://files.pythonhosted.org/packages/c1/b4/316da8d9962a66ff74cbfcaf4abb8ac20e0f4510ec342747f3e8c54ac31a/ldt-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "24aabbe18705119dad6852676511875a", "sha256": "b6e6c9ae39b9d06625de91ff42930047d18d77d10ba902ef01b632164a2b83ef"}, "downloads": -1, "filename": "ldt-0.2.1.tar.gz", "has_sig": false, "md5_digest": "24aabbe18705119dad6852676511875a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4619396, "upload_time": "2018-09-27T01:47:44", "upload_time_iso_8601": "2018-09-27T01:47:44.812739Z", "url": "https://files.pythonhosted.org/packages/39/4c/345f7eb8faf0f4515d563e5c5a0f5ddad1ee2cf47696ee3623c080bd337f/ldt-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "b910472f3e199cea99889796b60a6ccb", "sha256": "de084ccb37685c0170a6de21eb9f685a488c04b08bc8e6cbf316f3c3c66fd2a6"}, "downloads": -1, "filename": "ldt-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b910472f3e199cea99889796b60a6ccb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4710407, "upload_time": "2018-10-09T03:37:49", "upload_time_iso_8601": "2018-10-09T03:37:49.930448Z", "url": "https://files.pythonhosted.org/packages/0c/60/3fb31a0151ce792e853110a07913d6b7828eec7a38b63c9dd8ca176c29af/ldt-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f9c301a40be66981d68491e864de5ce", "sha256": "254b35ee0fff7cef216cf3df6af050cdec8416734c2335605e8eef5b8e6912ab"}, "downloads": -1, "filename": "ldt-0.3.0.tar.gz", "has_sig": false, "md5_digest": "7f9c301a40be66981d68491e864de5ce", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4638058, "upload_time": "2018-10-09T03:37:58", "upload_time_iso_8601": "2018-10-09T03:37:58.366479Z", "url": "https://files.pythonhosted.org/packages/50/a6/ae2731799d0124396e965c9a8ca7242f4f09c53efda22cbeab584595326a/ldt-0.3.0.tar.gz", "yanked": false}], "0.3.9": [{"comment_text": "", "digests": {"md5": "dd0054a63ecba9f353c7a752aae3a7f6", "sha256": "65710023a895433ef3afb9f658c5a8d1a25b7aa4c4edde7955e6e3f01670f017"}, "downloads": -1, "filename": "ldt-0.3.9-py3.6.egg", "has_sig": false, "md5_digest": "dd0054a63ecba9f353c7a752aae3a7f6", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 4722422, "upload_time": "2018-11-04T06:16:02", "upload_time_iso_8601": "2018-11-04T06:16:02.892493Z", "url": "https://files.pythonhosted.org/packages/39/8c/4e083457e510eabebf196638f073c815345d2eacddd1c653fcb9bbbb3746/ldt-0.3.9-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "cf82f187b976bbb1faeef0c007137684", "sha256": "02f689e5d098f4318bbe8ffd8687a740b46e26ec1cf0fee13630431cb83dcdf6"}, "downloads": -1, "filename": "ldt-0.3.9-py3-none-any.whl", "has_sig": false, "md5_digest": "cf82f187b976bbb1faeef0c007137684", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4727185, "upload_time": "2018-11-04T06:15:53", "upload_time_iso_8601": "2018-11-04T06:15:53.855315Z", "url": "https://files.pythonhosted.org/packages/c0/27/aef818e6e337d33a27b74c99fdfefc9e720d8859735573721888fe216d99/ldt-0.3.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ba6c0111fb5de0103fc958a4f05366c6", "sha256": "a9dbef69c52e47e7caecb40575d91342fe7a54ff33c383d53ea40097a0c640ab"}, "downloads": -1, "filename": "ldt-0.3.9.tar.gz", "has_sig": false, "md5_digest": "ba6c0111fb5de0103fc958a4f05366c6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4642597, "upload_time": "2018-11-04T06:16:11", "upload_time_iso_8601": "2018-11-04T06:16:11.454439Z", "url": "https://files.pythonhosted.org/packages/ea/28/305a215cfd3dc0553e84c0a7d2ca3be9c607850a6ee79c7fe80ac4e27329/ldt-0.3.9.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "fd04d1daef84317fdb3609f4084cef55", "sha256": "1a06abb9e27048e11bc3da3382cc7dff475bab59a79abc203b1f37a7b2719157"}, "downloads": -1, "filename": "ldt-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fd04d1daef84317fdb3609f4084cef55", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4730238, "upload_time": "2018-11-16T15:43:31", "upload_time_iso_8601": "2018-11-16T15:43:31.086277Z", "url": "https://files.pythonhosted.org/packages/10/ef/aa2e62719cc2baed67d48f44f83ef317705079b7cfec805795bfcdf9a9f2/ldt-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8cedf3a5bb33b0f349e24e3136aa90ea", "sha256": "a2a0dc60bda3f7d937ff4e48ff8e4e3cac9e3af749130f079ada78c40f6d3f40"}, "downloads": -1, "filename": "ldt-0.4.0.tar.gz", "has_sig": false, "md5_digest": "8cedf3a5bb33b0f349e24e3136aa90ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4642582, "upload_time": "2018-11-16T15:46:54", "upload_time_iso_8601": "2018-11-16T15:46:54.880129Z", "url": "https://files.pythonhosted.org/packages/08/b9/afdba60baeb9d7bc226b00676ff27f4c757979cc78b696ed6b594ca5e63e/ldt-0.4.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fd04d1daef84317fdb3609f4084cef55", "sha256": "1a06abb9e27048e11bc3da3382cc7dff475bab59a79abc203b1f37a7b2719157"}, "downloads": -1, "filename": "ldt-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fd04d1daef84317fdb3609f4084cef55", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4730238, "upload_time": "2018-11-16T15:43:31", "upload_time_iso_8601": "2018-11-16T15:43:31.086277Z", "url": "https://files.pythonhosted.org/packages/10/ef/aa2e62719cc2baed67d48f44f83ef317705079b7cfec805795bfcdf9a9f2/ldt-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8cedf3a5bb33b0f349e24e3136aa90ea", "sha256": "a2a0dc60bda3f7d937ff4e48ff8e4e3cac9e3af749130f079ada78c40f6d3f40"}, "downloads": -1, "filename": "ldt-0.4.0.tar.gz", "has_sig": false, "md5_digest": "8cedf3a5bb33b0f349e24e3136aa90ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4642582, "upload_time": "2018-11-16T15:46:54", "upload_time_iso_8601": "2018-11-16T15:46:54.880129Z", "url": "https://files.pythonhosted.org/packages/08/b9/afdba60baeb9d7bc226b00676ff27f4c757979cc78b696ed6b594ca5e63e/ldt-0.4.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:22 2020"}