{"info": {"author": "Robert Lujo", "author_email": "trebor74hr@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: End Users/Desktop", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Natural Language :: Croatian", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Topic :: Internet :: WWW/HTTP :: Indexing/Search", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Text Processing", "Topic :: Text Processing :: Indexing", "Topic :: Text Processing :: Linguistic"], "description": "Morphological/Inflection/Lemmatization Engine for Croatian language\n===================================================================\n\"text-hr\" is Morphological/Inflectional/Lemmatization Engine for Croatian\nlanguage written in Python programming language. Includes stopwords and\nPart-Of-Speech tagging engine (POS tagging) based on inverse inflection\nalgorithm for detection.\n\nSince API is not freezed, this project is still in alpha.\n\nTAGS \n----\n    Croatian language, lemmatization, stemming, inflection, python, natural\n    language processing (NLP), Part-of-speech (POS) tagging, stopwords, inverse\n    inflection, morphological lexicon\n\n\nOZNAKE\n------\n    Hrvatski jezik, lematizacija, Python biblioteka, morfologija, infleksija,\n    obrnuta infleksija, prepoznavanje vrsta rije\u010di, ra\u010dunalna obrada govornog\n    jezika, zaustavne rije\u010di, morfolo\u0161ki leksikon\n\nAUTHOR\n======\nRobert Lujo, Zagreb, Croatia, find mail address in LICENCE\n\n\nFEATURES\n========\nTo name the most important:\n - inflection system - for producing all forms of one word\n - detection of word types (POS tagging) - from existing list of word forms\n - list of stopwords\n\nSystem is based on unicode strings, default codepage to convert from and to \nstring is cp-1250.\n\nCheck `Getting started`_.\n\nINSTALLATION\n============\nInstallation instructions - if you have installed pip package \nhttp://pypi.python.org/pypi/pip::\n\n    pip install text-hr\n\nIf not, then do it old-fashioned way:\n    - download zip from http://pypi.python.org/pypi/text-hr/\n    - unzip\n    - open shell\n    - go to distribution directory\n    - python setup.py install\n\n\nGETTING STARTED\n===============\nThere are three important parts that this project provides:\n - `Inflection system`_ - for producing all forms of one word\n - `Detection of word types (POS tagging)`_ - from existing list of word forms\n - `List of stopwords`_\n\nInflection system\n-----------------\nUsage example - start python shell::\n\n    >>> from text_hr import Verb\n    >>> v = Verb(\"platiti\")\n    >>> for k in sorted(v.forms.keys()):\n    ...     print(k, v.forms[k])\n    ...\n    AOR/P/1 [u'platismo']\n    AOR/P/2 [u'platiste']\n    AOR/P/3 [u'plati\\u0161e']\n    AOR/S/1 [u'platih']\n    AOR/S/2 [u'plati']\n    AOR/S/3 [u'plati']\n    IMP/P/1 [u'platasmo', u'pla\\u0107asmo', u'platijasmo']\n    IMP/P/2 [u'plataste', u'pla\\u0107aste', u'platijaste']\n    IMP/P/3 [u'platahu', u'pla\\u0107ahu', u'platijahu']\n    ...\n    VA_PA//P_O+S+V+N [u'pla\\u0107eno']\n    X_INF// [u'platiti']\n    X_VAD_PAS// [u'plativ\\u0161i']\n    X_VAD_PRE// [u'plate\\u0107i']\n    X_VAD_PRE// [u'plate\\u0107i']\n\nDetection of word types (POS tagging)\n-------------------------------------\nTODO: to be done - check test_detect.txt for samples, and detect.py for the logic:\n\nFirst example in test_detect.txt::\n\n    >>> from text_hr.detect import WordTypeRecognizerExample\n    >>> def test_it(word_list, wt_filter=None, level=2):\n    ...     wdh = WordTypeRecognizerExample(word_list, silent=True)\n    ...     if not wt_filter is None:\n    ...         wdh.detect(wt_filter=wt_filter, level=level)  # e.g. wt_filter=[\"N\"]\n    ...     else:\n    ...         wdh.detect(level=level)  # all word types\n    ...     lines_file = LinesFile()\n    ...     wdh.dump_result(lines_file) # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    ...     print(\"\\n\".join(lines_file.lines))\n    ...     return wdh\n\n    >>> class LinesFile(object):\n    ...     def __init__(self):\n    ...         self.lines = []\n    ...     def write(self, s):\n    ...         self.lines.append(repr(s.rstrip()))\n\n    >>> word_list = [\n    ...   \"Broj    84\"\n    ... , \"broji   34\"\n    ... , \"Brojila  28\"\n    ... , \"broje   23\"\n    ... , \"broje\u0107i 22\"\n    ... , \"brojim   7\"\n    ... , \"brojimo  5\"\n    ... , \"broji\u0161   4\"\n    ... , \"brojahu  2\"\n    ... , \"broja\u0161e  1\"\n    ... , \"brojite  1\"\n    ... , \"-brijestovu 1\"\n    ... , \"brijestovi 1\"   #the only one checked with endswith, but all other will be checked with get_freq\n    ... , \"-brijestove 1\"\n    ... , \"-brijestova 1\"\n    ... ]\n\n    Lowest quality, but fastest\n    >>> wdh = test_it(word_list, level=4) # doctest: +ELLIPSIS\n    \" 10/  183 -> brojati              (u'V-XX_-_JATI-je\\\\u0107i-0') 84/broj,34/broji,23/broje,22/broje\\xe6i,7/brojim,5/brojimo,4/broji\\x9a,2/brojahu,1/brojite,1/broja\\x9ae\"\n\nList of stopwords\n-----------------\nIs located in std_words.txt, and you can read it directly from here\n\n    http://bitbucket.org/trebor74hr/text-hr/src/tip/text_hr/std_words.txt\n\nThe list can be updated like this::\n\n    >>> import text_hr\n    >>> text_hr.dump_all_std_words()\n    Totaly 2904 word forms dumped to r:\\hg-clones\\python\\text-hr\\text_hr\\std_words.txt in codepage utf8\n\nIteration over all words goes like this::\n\n    from text_hr import get_all_std_words\n\n    for word_base, l_key, cnt, _suff_id, wform_key, wform in get_all_std_words():\n        print(word_base, l_key, cnt, _suff_id, wform_key, wform)\n\n\nFurther\n-------\nSince there is currently no good documentation, the best source of \nfurther information is by reading tests inside of modules and\ntests in tests directory (dev version). More information in `Running tests`_.\nYou can allways read a source.\n\n\nDOCUMENTATION\n=============\nCurrently there is no documentation. In progress ...\n\n\nSUPPORT\n=======\nSince this project is limited by my free time, support is limited. \n\n\nREPORT BUG OR REQUEST FEATURE\n-----------------------------\nIf you encounter bug, the best is to report it to the bitbucket web page\nhttp://bitbucket.org/trebor74hr/text-hr.\n\nIf there will be an interest for development for other inflection rich\nlanguages, I'd be glad to decouple language specific code and create new\nproject that will be capable to deal with multiple languages.\n\nThe best way to contact me is by mail (find in LICENCE).\n\nTODO list is in readme.txt (dev version).\n\n\nCONTRIBUTION\n============\nSince this project is not currently in the stable API phase, contribution\nshould wait for a while.\n\n\nRUNNING TESTS\n=============\nAll tests are doctests (not unittests). There are three type of tests in the\npackage: \n\n    1. doctests in each module - e.g. in verbs.py\n    2. doctests in tests/test_*.txt - only development version\n    3. tests which are not automatically compared - i.e. in special call mode\n       detect.py can produce output file which needs to be compared \n       manually with some existing file. Such test(s) are very slow. This needs\n       to be changed to be automatic.\n\nRunning each module directly will run 1. and 2. if running from development\nversion. To get development version\nTo use development version (http://bitbucket.org/trebor74hr/text-hr)::\n\n hg clone https://bitbucket.org/trebor74hr/text-hr\n\n\ncreate text_hr.pth in python site-packages directory with path to text-hr e.g.::\n\n    r:\\hg-clones\\python\\text-hr\n\nTo run all tests:\n    - go to tests directory\n    - run tests.py like (with sample output)::\n\n        > python tests.py\n        testing module   __init__\n        testing module   adjectives\n        ...\n        testing textfile R:\\hg-clones\\python\\text-hr\\tests\\test_adj.txt\n        ...\n        testing textfile R:\\hg-clones\\python\\text-hr\\tests\\test_verbs_type.txt\n\nTo run tests for just one module:\n    - goto text_hr directory\n    - run tests by running module, e.g.::\n\n        > py pronouns.py\n        __main__: running doctests\n        ..\\tests\\test_pronouns.txt: running doctests\n\n    - in the case you're not running from dev version, you'll get output like\n      this::\n\n        > py pronouns.py\n        __main__: running doctests\n        ..\\tests\\test_pronouns.txt: Not found, skipping\n\nADDITIONAL\n==========\nMaster thesis pdf in Croatian (134 pages) with title::\n\n    Lociranje sli\u010dnih logi\u010dkih cjelina u tekstualnim \n    dokumentima na hrvatskome jeziku\n\ncan be found at:\n\n    http://bitbucket.org/trebor74hr/text-hr/downloads/magistarski-konacni.pdf\n\nTODO\n====\nvarious things, see readme.txt for details.\n\nCHANGES\n=======\n0.20\n----\nRL 200507\n    - migration to python 3+, tested on python 3.7, all tests pass\n\n0.18\n----\nRL 121210 \n    - fixed wrong readme on bitbucket homepage\n\n0.17 \n----\nRL 100617 \n    - utf-8 setup \n\n0.16 \n----\nRL 100617 \n    - master thesis pdf added to repository (in Croatian, 134 pages)\n\n0.15 \n----\nRL 100617 \n    - minor changes\n\n0.14 \n----\nRL 100617 \n    - beta release\n    - tags: lemmatization, stemming\n\n0.13 \n----\nRL 100610:\n    - text_hr package reorganized (__init__.py with __all__ and imports ...)\n    - word_types.py removed\n    - std_words.txt\n\n0.12 \n----\nRL 100608 :\n    - README\n    - enabled tests from tests.py for all \n    - enabled tests from directly from each modules\n\n0.11 \n----\nRL 100607:\n    - recreated repo at bitbucket\n    - no .suff_registry.pickle and testing_*.out put in zip\n\n0.10\n----\nRL 100605:\n    - first installable release\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://bitbucket.org/trebor74hr/text-hr/", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "text-hr", "package_url": "https://pypi.org/project/text-hr/", "platform": "", "project_url": "https://pypi.org/project/text-hr/", "project_urls": {"Homepage": "http://bitbucket.org/trebor74hr/text-hr/"}, "release_url": "https://pypi.org/project/text-hr/0.20/", "requires_dist": null, "requires_python": ">=3.3", "summary": "Morphological/Inflection/Lemmatization Engine for Croatian language, POS tagger, stopwords", "version": "0.20", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"morphological-inflection-lemmatization-engine-for-croatian-language\">\n<h2>Morphological/Inflection/Lemmatization Engine for Croatian language</h2>\n<p>\u201ctext-hr\u201d is Morphological/Inflectional/Lemmatization Engine for Croatian\nlanguage written in Python programming language. Includes stopwords and\nPart-Of-Speech tagging engine (POS tagging) based on inverse inflection\nalgorithm for detection.</p>\n<p>Since API is not freezed, this project is still in alpha.</p>\n<div id=\"tags\">\n<h3>TAGS</h3>\n<blockquote>\nCroatian language, lemmatization, stemming, inflection, python, natural\nlanguage processing (NLP), Part-of-speech (POS) tagging, stopwords, inverse\ninflection, morphological lexicon</blockquote>\n</div>\n<div id=\"oznake\">\n<h3>OZNAKE</h3>\n<blockquote>\nHrvatski jezik, lematizacija, Python biblioteka, morfologija, infleksija,\nobrnuta infleksija, prepoznavanje vrsta rije\u010di, ra\u010dunalna obrada govornog\njezika, zaustavne rije\u010di, morfolo\u0161ki leksikon</blockquote>\n</div>\n</div>\n<div id=\"author\">\n<h2>AUTHOR</h2>\n<p>Robert Lujo, Zagreb, Croatia, find mail address in LICENCE</p>\n</div>\n<div id=\"features\">\n<h2>FEATURES</h2>\n<dl>\n<dt>To name the most important:</dt>\n<dd><ul>\n<li>inflection system - for producing all forms of one word</li>\n<li>detection of word types (POS tagging) - from existing list of word forms</li>\n<li>list of stopwords</li>\n</ul>\n</dd>\n</dl>\n<p>System is based on unicode strings, default codepage to convert from and to\nstring is cp-1250.</p>\n<p>Check <a href=\"#getting-started\" rel=\"nofollow\">Getting started</a>.</p>\n</div>\n<div id=\"installation\">\n<h2>INSTALLATION</h2>\n<p>Installation instructions - if you have installed pip package\n<a href=\"http://pypi.python.org/pypi/pip\" rel=\"nofollow\">http://pypi.python.org/pypi/pip</a>:</p>\n<pre>pip install text-hr\n</pre>\n<dl>\n<dt>If not, then do it old-fashioned way:</dt>\n<dd><ul>\n<li>download zip from <a href=\"http://pypi.python.org/pypi/text-hr/\" rel=\"nofollow\">http://pypi.python.org/pypi/text-hr/</a></li>\n<li>unzip</li>\n<li>open shell</li>\n<li>go to distribution directory</li>\n<li>python setup.py install</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"getting-started\">\n<h2>GETTING STARTED</h2>\n<dl>\n<dt>There are three important parts that this project provides:</dt>\n<dd><ul>\n<li><a href=\"#inflection-system\" rel=\"nofollow\">Inflection system</a> - for producing all forms of one word</li>\n<li><a href=\"#detection-of-word-types-pos-tagging\" rel=\"nofollow\">Detection of word types (POS tagging)</a> - from existing list of word forms</li>\n<li><a href=\"#list-of-stopwords\" rel=\"nofollow\">List of stopwords</a></li>\n</ul>\n</dd>\n</dl>\n<div id=\"inflection-system\">\n<h3>Inflection system</h3>\n<p>Usage example - start python shell:</p>\n<pre>&gt;&gt;&gt; from text_hr import Verb\n&gt;&gt;&gt; v = Verb(\"platiti\")\n&gt;&gt;&gt; for k in sorted(v.forms.keys()):\n...     print(k, v.forms[k])\n...\nAOR/P/1 [u'platismo']\nAOR/P/2 [u'platiste']\nAOR/P/3 [u'plati\\u0161e']\nAOR/S/1 [u'platih']\nAOR/S/2 [u'plati']\nAOR/S/3 [u'plati']\nIMP/P/1 [u'platasmo', u'pla\\u0107asmo', u'platijasmo']\nIMP/P/2 [u'plataste', u'pla\\u0107aste', u'platijaste']\nIMP/P/3 [u'platahu', u'pla\\u0107ahu', u'platijahu']\n...\nVA_PA//P_O+S+V+N [u'pla\\u0107eno']\nX_INF// [u'platiti']\nX_VAD_PAS// [u'plativ\\u0161i']\nX_VAD_PRE// [u'plate\\u0107i']\nX_VAD_PRE// [u'plate\\u0107i']\n</pre>\n</div>\n<div id=\"detection-of-word-types-pos-tagging\">\n<h3>Detection of word types (POS tagging)</h3>\n<p>TODO: to be done - check test_detect.txt for samples, and detect.py for the logic:</p>\n<p>First example in test_detect.txt:</p>\n<pre>&gt;&gt;&gt; from text_hr.detect import WordTypeRecognizerExample\n&gt;&gt;&gt; def test_it(word_list, wt_filter=None, level=2):\n...     wdh = WordTypeRecognizerExample(word_list, silent=True)\n...     if not wt_filter is None:\n...         wdh.detect(wt_filter=wt_filter, level=level)  # e.g. wt_filter=[\"N\"]\n...     else:\n...         wdh.detect(level=level)  # all word types\n...     lines_file = LinesFile()\n...     wdh.dump_result(lines_file) # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n...     print(\"\\n\".join(lines_file.lines))\n...     return wdh\n\n&gt;&gt;&gt; class LinesFile(object):\n...     def __init__(self):\n...         self.lines = []\n...     def write(self, s):\n...         self.lines.append(repr(s.rstrip()))\n\n&gt;&gt;&gt; word_list = [\n...   \"Broj    84\"\n... , \"broji   34\"\n... , \"Brojila  28\"\n... , \"broje   23\"\n... , \"broje\u0107i 22\"\n... , \"brojim   7\"\n... , \"brojimo  5\"\n... , \"broji\u0161   4\"\n... , \"brojahu  2\"\n... , \"broja\u0161e  1\"\n... , \"brojite  1\"\n... , \"-brijestovu 1\"\n... , \"brijestovi 1\"   #the only one checked with endswith, but all other will be checked with get_freq\n... , \"-brijestove 1\"\n... , \"-brijestova 1\"\n... ]\n\nLowest quality, but fastest\n&gt;&gt;&gt; wdh = test_it(word_list, level=4) # doctest: +ELLIPSIS\n\" 10/  183 -&gt; brojati              (u'V-XX_-_JATI-je\\\\u0107i-0') 84/broj,34/broji,23/broje,22/broje\\xe6i,7/brojim,5/brojimo,4/broji\\x9a,2/brojahu,1/brojite,1/broja\\x9ae\"\n</pre>\n</div>\n<div id=\"list-of-stopwords\">\n<h3>List of stopwords</h3>\n<p>Is located in std_words.txt, and you can read it directly from here</p>\n<blockquote>\n<a href=\"http://bitbucket.org/trebor74hr/text-hr/src/tip/text_hr/std_words.txt\" rel=\"nofollow\">http://bitbucket.org/trebor74hr/text-hr/src/tip/text_hr/std_words.txt</a></blockquote>\n<p>The list can be updated like this:</p>\n<pre>&gt;&gt;&gt; import text_hr\n&gt;&gt;&gt; text_hr.dump_all_std_words()\nTotaly 2904 word forms dumped to r:\\hg-clones\\python\\text-hr\\text_hr\\std_words.txt in codepage utf8\n</pre>\n<p>Iteration over all words goes like this:</p>\n<pre>from text_hr import get_all_std_words\n\nfor word_base, l_key, cnt, _suff_id, wform_key, wform in get_all_std_words():\n    print(word_base, l_key, cnt, _suff_id, wform_key, wform)\n</pre>\n</div>\n<div id=\"further\">\n<h3>Further</h3>\n<p>Since there is currently no good documentation, the best source of\nfurther information is by reading tests inside of modules and\ntests in tests directory (dev version). More information in <a href=\"#running-tests\" rel=\"nofollow\">Running tests</a>.\nYou can allways read a source.</p>\n</div>\n</div>\n<div id=\"documentation\">\n<h2>DOCUMENTATION</h2>\n<p>Currently there is no documentation. In progress \u2026</p>\n</div>\n<div id=\"support\">\n<h2>SUPPORT</h2>\n<p>Since this project is limited by my free time, support is limited.</p>\n<div id=\"report-bug-or-request-feature\">\n<h3>REPORT BUG OR REQUEST FEATURE</h3>\n<p>If you encounter bug, the best is to report it to the bitbucket web page\n<a href=\"http://bitbucket.org/trebor74hr/text-hr\" rel=\"nofollow\">http://bitbucket.org/trebor74hr/text-hr</a>.</p>\n<p>If there will be an interest for development for other inflection rich\nlanguages, I\u2019d be glad to decouple language specific code and create new\nproject that will be capable to deal with multiple languages.</p>\n<p>The best way to contact me is by mail (find in LICENCE).</p>\n<p>TODO list is in readme.txt (dev version).</p>\n</div>\n</div>\n<div id=\"contribution\">\n<h2>CONTRIBUTION</h2>\n<p>Since this project is not currently in the stable API phase, contribution\nshould wait for a while.</p>\n</div>\n<div id=\"running-tests\">\n<h2>RUNNING TESTS</h2>\n<p>All tests are doctests (not unittests). There are three type of tests in the\npackage:</p>\n<blockquote>\n<ol>\n<li>doctests in each module - e.g. in verbs.py</li>\n<li>doctests in tests/test_*.txt - only development version</li>\n<li>tests which are not automatically compared - i.e. in special call mode\ndetect.py can produce output file which needs to be compared\nmanually with some existing file. Such test(s) are very slow. This needs\nto be changed to be automatic.</li>\n</ol>\n</blockquote>\n<p>Running each module directly will run 1. and 2. if running from development\nversion. To get development version\nTo use development version (<a href=\"http://bitbucket.org/trebor74hr/text-hr\" rel=\"nofollow\">http://bitbucket.org/trebor74hr/text-hr</a>):</p>\n<pre>hg clone https://bitbucket.org/trebor74hr/text-hr\n</pre>\n<p>create text_hr.pth in python site-packages directory with path to text-hr e.g.:</p>\n<pre>r:\\hg-clones\\python\\text-hr\n</pre>\n<dl>\n<dt>To run all tests:</dt>\n<dd><ul>\n<li><p>go to tests directory</p>\n</li>\n<li><p>run tests.py like (with sample output):</p>\n<pre>&gt; python tests.py\ntesting module   __init__\ntesting module   adjectives\n...\ntesting textfile R:\\hg-clones\\python\\text-hr\\tests\\test_adj.txt\n...\ntesting textfile R:\\hg-clones\\python\\text-hr\\tests\\test_verbs_type.txt\n</pre>\n</li>\n</ul>\n</dd>\n<dt>To run tests for just one module:</dt>\n<dd><ul>\n<li><p>goto text_hr directory</p>\n</li>\n<li><p>run tests by running module, e.g.:</p>\n<pre>&gt; py pronouns.py\n__main__: running doctests\n..\\tests\\test_pronouns.txt: running doctests\n</pre>\n</li>\n<li><p>in the case you\u2019re not running from dev version, you\u2019ll get output like\nthis:</p>\n<pre>&gt; py pronouns.py\n__main__: running doctests\n..\\tests\\test_pronouns.txt: Not found, skipping\n</pre>\n</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"additional\">\n<h2>ADDITIONAL</h2>\n<p>Master thesis pdf in Croatian (134 pages) with title:</p>\n<pre>Lociranje sli\u010dnih logi\u010dkih cjelina u tekstualnim\ndokumentima na hrvatskome jeziku\n</pre>\n<p>can be found at:</p>\n<blockquote>\n<a href=\"http://bitbucket.org/trebor74hr/text-hr/downloads/magistarski-konacni.pdf\" rel=\"nofollow\">http://bitbucket.org/trebor74hr/text-hr/downloads/magistarski-konacni.pdf</a></blockquote>\n</div>\n<div id=\"todo\">\n<h2>TODO</h2>\n<p>various things, see readme.txt for details.</p>\n</div>\n<div id=\"changes\">\n<h2>CHANGES</h2>\n<div id=\"id1\">\n<h3>0.20</h3>\n<dl>\n<dt>RL 200507</dt>\n<dd><ul>\n<li>migration to python 3+, tested on python 3.7, all tests pass</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id2\">\n<h3>0.18</h3>\n<dl>\n<dt>RL 121210</dt>\n<dd><ul>\n<li>fixed wrong readme on bitbucket homepage</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id3\">\n<h3>0.17</h3>\n<dl>\n<dt>RL 100617</dt>\n<dd><ul>\n<li>utf-8 setup</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id4\">\n<h3>0.16</h3>\n<dl>\n<dt>RL 100617</dt>\n<dd><ul>\n<li>master thesis pdf added to repository (in Croatian, 134 pages)</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id5\">\n<h3>0.15</h3>\n<dl>\n<dt>RL 100617</dt>\n<dd><ul>\n<li>minor changes</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id6\">\n<h3>0.14</h3>\n<dl>\n<dt>RL 100617</dt>\n<dd><ul>\n<li>beta release</li>\n<li>tags: lemmatization, stemming</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id7\">\n<h3>0.13</h3>\n<dl>\n<dt>RL 100610:</dt>\n<dd><ul>\n<li>text_hr package reorganized (__init__.py with __all__ and imports \u2026)</li>\n<li>word_types.py removed</li>\n<li>std_words.txt</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id8\">\n<h3>0.12</h3>\n<dl>\n<dt>RL 100608 :</dt>\n<dd><ul>\n<li>README</li>\n<li>enabled tests from tests.py for all</li>\n<li>enabled tests from directly from each modules</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id9\">\n<h3>0.11</h3>\n<dl>\n<dt>RL 100607:</dt>\n<dd><ul>\n<li>recreated repo at bitbucket</li>\n<li>no .suff_registry.pickle and testing_*.out put in zip</li>\n</ul>\n</dd>\n</dl>\n</div>\n<div id=\"id10\">\n<h3>0.10</h3>\n<dl>\n<dt>RL 100605:</dt>\n<dd><ul>\n<li>first installable release</li>\n</ul>\n</dd>\n</dl>\n</div>\n</div>\n\n          </div>"}, "last_serial": 7189783, "releases": {"0.10": [{"comment_text": "", "digests": {"md5": "4454894d19198511a825cac00f42d333", "sha256": "60a2ec92975c0804493fd2b1919d0e5d74a54bf9d2ee7dbb1f1c19ced6fcf9e5"}, "downloads": -1, "filename": "text-hr-0.10.zip", "has_sig": false, "md5_digest": "4454894d19198511a825cac00f42d333", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1009823, "upload_time": "2010-06-06T00:45:44", "upload_time_iso_8601": "2010-06-06T00:45:44.690495Z", "url": "https://files.pythonhosted.org/packages/45/08/b7ae73c261c29c4a9c95d76a648e1fb3473e4b6b7928010253f89df757d6/text-hr-0.10.zip", "yanked": false}], "0.11": [{"comment_text": "", "digests": {"md5": "cbba1a151713ee6205605f767abe6a99", "sha256": "d47d34af7b1238dd40124ce464f0e082ece8e07a3ef852d11f72917157b5b24f"}, "downloads": -1, "filename": "text-hr-0.11.zip", "has_sig": false, "md5_digest": "cbba1a151713ee6205605f767abe6a99", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 95695, "upload_time": "2010-06-07T21:30:55", "upload_time_iso_8601": "2010-06-07T21:30:55.196964Z", "url": "https://files.pythonhosted.org/packages/85/1e/cd88574ee78d7c99fbc6a799157fb1a50c020bc10318295de0c530116fe0/text-hr-0.11.zip", "yanked": false}], "0.12": [{"comment_text": "", "digests": {"md5": "8e1503a42ec900b48bd0534aae0434c8", "sha256": "845a15e8624f2dd50f224b810adfb8cf35489a56b712d0108b0e7bca447bd95e"}, "downloads": -1, "filename": "text-hr-0.12.zip", "has_sig": false, "md5_digest": "8e1503a42ec900b48bd0534aae0434c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 101489, "upload_time": "2010-06-08T02:24:20", "upload_time_iso_8601": "2010-06-08T02:24:20.129780Z", "url": "https://files.pythonhosted.org/packages/0e/8a/b401d758922aecce2d863873ae49ebbd49cdd77a45743dc7d74c5476efcb/text-hr-0.12.zip", "yanked": false}], "0.13": [{"comment_text": "", "digests": {"md5": "4c959a7e955a7dfb77a62e9dc57d42be", "sha256": "e6e99f5744f3408ef0d191d2a74a9508e6d9dc41784322928f9b398c0649bb95"}, "downloads": -1, "filename": "text-hr-0.13.zip", "has_sig": false, "md5_digest": "4c959a7e955a7dfb77a62e9dc57d42be", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 119060, "upload_time": "2010-06-10T01:13:40", "upload_time_iso_8601": "2010-06-10T01:13:40.429410Z", "url": "https://files.pythonhosted.org/packages/c6/ae/5d70a2b0af32f353d78c8245774a159ea1914aa5399c02e4dd8620cb43d5/text-hr-0.13.zip", "yanked": false}], "0.14": [{"comment_text": "", "digests": {"md5": "6ab862f7d0c0be33e3b657f6f93e1d30", "sha256": "4ed3f131037b67afa4ef6fc2fa8bc90f6e6b1320467a185e455b2f593d71738a"}, "downloads": -1, "filename": "text-hr-0.14.zip", "has_sig": false, "md5_digest": "6ab862f7d0c0be33e3b657f6f93e1d30", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 119182, "upload_time": "2010-06-17T19:03:01", "upload_time_iso_8601": "2010-06-17T19:03:01.844089Z", "url": "https://files.pythonhosted.org/packages/5a/20/d9a694c7df5919d68cc7f12ee1c85ee7c2048595b4882b9ec036b1af3542/text-hr-0.14.zip", "yanked": false}], "0.16": [{"comment_text": "", "digests": {"md5": "a81b76b04de73f71353d151dbc14bdb3", "sha256": "9daed73cba77d21db51fe792f4c8595465dd49678d923943ec9824cd56ef517b"}, "downloads": -1, "filename": "text-hr-0.16.zip", "has_sig": false, "md5_digest": "a81b76b04de73f71353d151dbc14bdb3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 119684, "upload_time": "2010-07-09T01:35:42", "upload_time_iso_8601": "2010-07-09T01:35:42.343238Z", "url": "https://files.pythonhosted.org/packages/3b/9d/a111f4c289ba785f01e30be55f69e23c527c2a038ca58059628c6a084396/text-hr-0.16.zip", "yanked": false}], "0.17": [{"comment_text": "", "digests": {"md5": "c5e00de08d0b465a1624028c17cc29d0", "sha256": "557b65b1c359aa468088e9b682ae133153a847aec39957025a941649e26fb51e"}, "downloads": -1, "filename": "text-hr-0.17.zip", "has_sig": false, "md5_digest": "c5e00de08d0b465a1624028c17cc29d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 119745, "upload_time": "2010-07-09T01:39:41", "upload_time_iso_8601": "2010-07-09T01:39:41.533892Z", "url": "https://files.pythonhosted.org/packages/b0/03/89535ded41e1e2b832e37dd949398f2e00d0befc9017e56c7dd492de89fd/text-hr-0.17.zip", "yanked": false}], "0.18": [{"comment_text": "", "digests": {"md5": "e14d9388a18ed36c4949257b4ccbcbf5", "sha256": "3fa7ecf6ec8b45ff2070e4e91c3d19f7dcbd68315a336e4d1b4f130a8c404475"}, "downloads": -1, "filename": "text-hr-0.18.tar.gz", "has_sig": false, "md5_digest": "e14d9388a18ed36c4949257b4ccbcbf5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 110116, "upload_time": "2012-12-10T21:46:15", "upload_time_iso_8601": "2012-12-10T21:46:15.876632Z", "url": "https://files.pythonhosted.org/packages/c1/bd/0a079a34e0ccf5dd4650ad5366a67f7530e379b84f667cc13569a91d4c65/text-hr-0.18.tar.gz", "yanked": false}], "0.20": [{"comment_text": "", "digests": {"md5": "8d28b766b613e43fac2e2260a299d55b", "sha256": "08056e732d21c269d1b77533314ef4d7c75c81bcaf63be55cc51194f19900689"}, "downloads": -1, "filename": "text_hr-0.20-py3-none-any.whl", "has_sig": false, "md5_digest": "8d28b766b613e43fac2e2260a299d55b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.3", "size": 97691, "upload_time": "2020-05-07T16:10:05", "upload_time_iso_8601": "2020-05-07T16:10:05.380803Z", "url": "https://files.pythonhosted.org/packages/6e/31/2bc50f65fc3dcb21622d93b4089f97be692dbdce7444bd253dcd46ea56d5/text_hr-0.20-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d4835cf646c68ea0619d28f6802ee86", "sha256": "ca1f236a9ded1b89f937308dc3084969bc972ff09b68be9e550700caa2cf536c"}, "downloads": -1, "filename": "text-hr-0.20.tar.gz", "has_sig": false, "md5_digest": "9d4835cf646c68ea0619d28f6802ee86", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.3", "size": 95995, "upload_time": "2020-05-07T16:10:06", "upload_time_iso_8601": "2020-05-07T16:10:06.758082Z", "url": "https://files.pythonhosted.org/packages/4a/0a/ef163de006a7f00f529a6e0ae58352d4fd85afa85092911195e19b234b0e/text-hr-0.20.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8d28b766b613e43fac2e2260a299d55b", "sha256": "08056e732d21c269d1b77533314ef4d7c75c81bcaf63be55cc51194f19900689"}, "downloads": -1, "filename": "text_hr-0.20-py3-none-any.whl", "has_sig": false, "md5_digest": "8d28b766b613e43fac2e2260a299d55b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.3", "size": 97691, "upload_time": "2020-05-07T16:10:05", "upload_time_iso_8601": "2020-05-07T16:10:05.380803Z", "url": "https://files.pythonhosted.org/packages/6e/31/2bc50f65fc3dcb21622d93b4089f97be692dbdce7444bd253dcd46ea56d5/text_hr-0.20-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d4835cf646c68ea0619d28f6802ee86", "sha256": "ca1f236a9ded1b89f937308dc3084969bc972ff09b68be9e550700caa2cf536c"}, "downloads": -1, "filename": "text-hr-0.20.tar.gz", "has_sig": false, "md5_digest": "9d4835cf646c68ea0619d28f6802ee86", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.3", "size": 95995, "upload_time": "2020-05-07T16:10:06", "upload_time_iso_8601": "2020-05-07T16:10:06.758082Z", "url": "https://files.pythonhosted.org/packages/4a/0a/ef163de006a7f00f529a6e0ae58352d4fd85afa85092911195e19b234b0e/text-hr-0.20.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:01 2020"}