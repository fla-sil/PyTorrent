{"info": {"author": "Irina Nicolae", "author_email": "irinutza.n@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Adversarial Robustness Toolbox (ART) v1.2\n<p align=\"center\">\n  <img src=\"docs/images/art_logo.png?raw=true\" width=\"200\" title=\"ART logo\">\n</p>\n<br />\n\n[![Build Status](https://travis-ci.org/IBM/adversarial-robustness-toolbox.svg?branch=master)](https://travis-ci.org/IBM/adversarial-robustness-toolbox)\n[![Documentation Status](https://readthedocs.org/projects/adversarial-robustness-toolbox/badge/?version=latest)](http://adversarial-robustness-toolbox.readthedocs.io/en/latest/?badge=latest)\n[![GitHub version](https://badge.fury.io/gh/IBM%2Fadversarial-robustness-toolbox.svg)](https://badge.fury.io/gh/IBM%2Fadversarial-robustness-toolbox)\n[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/IBM/adversarial-robustness-toolbox.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/IBM/adversarial-robustness-toolbox/context:python)\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/IBM/adversarial-robustness-toolbox.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/IBM/adversarial-robustness-toolbox/alerts/)\n[![codecov](https://codecov.io/gh/IBM/adversarial-robustness-toolbox/branch/master/graph/badge.svg)](https://codecov.io/gh/IBM/adversarial-robustness-toolbox)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/adversarial-robustness-toolbox)](https://pypi.org/project/adversarial-robustness-toolbox/)\n[![slack-img](https://img.shields.io/badge/chat-on%20slack-yellow.svg)](https://ibm-art.slack.com/)\n\n[\u4e2d\u6587README\u8bf7\u6309\u6b64\u5904](README-cn.md)\n\nAdversarial Robustness Toolbox (ART) is a Python library supporting developers and researchers in defending Machine \nLearning models (Deep Neural Networks, Gradient Boosted Decision Trees, Support Vector Machines, Random Forests, \nLogistic Regression, Gaussian Processes, Decision Trees, Scikit-learn Pipelines, etc.) against adversarial threats \n(including evasion, extraction and poisoning) and helps making AI systems more secure and trustworthy. Machine Learning \nmodels are vulnerable to adversarial examples, which are inputs (images, texts, tabular data, etc.) deliberately crafted \nto produce a desired response by the Machine Learning model. ART provides the tools to build and deploy defences and \ntest them with adversarial attacks. \n\nDefending Machine Learning models involves certifying and verifying model robustness and model hardening with \napproaches such as pre-processing inputs, augmenting training data with adversarial examples, and leveraging runtime \ndetection methods to flag any inputs that might have been modified by an adversary. ART includes attacks for testing \ndefenses with state-of-the-art threat models.\n\nDocumentation of ART: https://adversarial-robustness-toolbox.readthedocs.io\n\nGet started with [examples](examples/README.md) and [tutorials](notebooks/README.md)\n\nThe library is under continuous development. Feedback, bug reports and contributions are very welcome. \nGet in touch with us on [Slack](https://ibm-art.slack.com) (invite [here](https://join.slack.com/t/ibm-art/shared_invite/enQtMzkyOTkyODE4NzM4LTA4NGQ1OTMxMzFmY2Q1MzE1NWI2MmEzN2FjNGNjOGVlODVkZDE0MjA1NTA4OGVkMjVkNmQ4MTY1NmMyOGM5YTg))!\n\n## Supported Machine Learning Libraries and Applications\n* TensorFlow (v1 and v2) (www.tensorflow.org)\n* Keras (www.keras.io)\n* PyTorch (www.pytorch.org)\n* MXNet (https://mxnet.apache.org)\n* Scikit-learn (www.scikit-learn.org)\n* XGBoost (www.xgboost.ai)\n* LightGBM (https://lightgbm.readthedocs.io)\n* CatBoost (www.catboost.ai)\n* GPy (https://sheffieldml.github.io/GPy/)\n\n## Implemented Attacks, Defences, Detections, Metrics, Certifications and Verifications\n\n**Evasion Attacks:**\n* Threshold Attack ([Vargas et al., 2019](https://arxiv.org/abs/1906.06026))\n* Pixel Attack ([Vargas et al., 2019](https://arxiv.org/abs/1906.06026), [Su et al., 2019](https://ieeexplore.ieee.org/abstract/document/8601309/citations#citations))\n* HopSkipJump attack ([Chen et al., 2019](https://arxiv.org/abs/1904.02144))\n* High Confidence Low Uncertainty adversarial samples ([Grosse et al., 2018](https://arxiv.org/abs/1812.02606))\n* Projected gradient descent ([Madry et al., 2017](https://arxiv.org/abs/1706.06083))\n* NewtonFool ([Jang et al., 2017](http://doi.acm.org/10.1145/3134600.3134635))\n* Elastic net attack ([Chen et al., 2017](https://arxiv.org/abs/1709.04114))\n* Spatial transformation attack ([Engstrom et al., 2017](https://arxiv.org/abs/1712.02779))\n* Query-efficient black-box attack ([Ilyas et al., 2017](https://arxiv.org/abs/1712.07113))\n* Zeroth-order optimization attack ([Chen et al., 2017](https://arxiv.org/abs/1708.03999))\n* Decision-based attack / Boundary attack ([Brendel et al., 2018](https://arxiv.org/abs/1712.04248))\n* Adversarial patch ([Brown et al., 2017](https://arxiv.org/abs/1712.09665))\n* Decision tree attack ([Papernot et al., 2016](https://arxiv.org/abs/1605.07277))\n* Carlini & Wagner (C&W) `L_2` and `L_inf` attacks ([Carlini and Wagner, 2016](https://arxiv.org/abs/1608.04644))\n* Basic iterative method ([Kurakin et al., 2016](https://arxiv.org/abs/1607.02533))\n* Jacobian saliency map ([Papernot et al., 2016](https://arxiv.org/abs/1511.07528))\n* Universal perturbation ([Moosavi-Dezfooli et al., 2016](https://arxiv.org/abs/1610.08401))\n* DeepFool ([Moosavi-Dezfooli et al., 2015](https://arxiv.org/abs/1511.04599))\n* Virtual adversarial method ([Miyato et al., 2015](https://arxiv.org/abs/1507.00677))\n* Fast gradient method ([Goodfellow et al., 2014](https://arxiv.org/abs/1412.6572))\n\n**Extraction Attacks:**\n* Functionally Equivalent Extraction ([Jagielski et al., 2019](https://arxiv.org/abs/1909.01838))\n* Copycat CNN ([Correia-Silva et al., 2018](https://arxiv.org/abs/1806.05476))\n* KnockoffNets ([Orekondy et al., 2018](https://arxiv.org/abs/1812.02766))\n\n**Poisoning Attacks:**\n* Poisoning Attack on SVM ([Biggio et al., 2013](https://arxiv.org/abs/1206.6389))\n* Backdoor Attack ([Gu, et. al., 2017](https://arxiv.org/abs/1708.06733))\n\n**Defences - Preprocessor:**\n* Thermometer encoding ([Buckman et al., 2018](https://openreview.net/forum?id=S18Su--CW))\n* Total variance minimization ([Guo et al., 2018](https://openreview.net/forum?id=SyJ7ClWCb))\n* PixelDefend ([Song et al., 2017](https://arxiv.org/abs/1710.10766))\n* Gaussian data augmentation ([Zantedeschi et al., 2017](https://arxiv.org/abs/1707.06728))\n* Feature squeezing ([Xu et al., 2017](http://arxiv.org/abs/1704.01155))\n* Spatial smoothing ([Xu et al., 2017](http://arxiv.org/abs/1704.01155))\n* JPEG compression ([Dziugaite et al., 2016](https://arxiv.org/abs/1608.00853))\n* Label smoothing ([Warde-Farley and Goodfellow, 2016](https://pdfs.semanticscholar.org/b5ec/486044c6218dd41b17d8bba502b32a12b91a.pdf))\n* Virtual adversarial training ([Miyato et al., 2015](https://arxiv.org/abs/1507.00677))\n\n**Defences - Postprocessor:**\n* Reverse Sigmoid ([Lee et al., 2018](https://arxiv.org/abs/1806.00054))\n* Random Noise ([Chandrasekaranet al., 2018](https://arxiv.org/abs/1811.02054))\n* Class Labels ([Tramer et al., 2016](https://arxiv.org/abs/1609.02943), [Chandrasekaranet al., 2018](https://arxiv.org/abs/1811.02054))\n* High Confidence ([Tramer et al., 2016](https://arxiv.org/abs/1609.02943))\n* Rounding ([Tramer et al., 2016](https://arxiv.org/abs/1609.02943))\n\n**Defences - Trainer:**\n* Adversarial training ([Szegedy et al., 2013](http://arxiv.org/abs/1312.6199))\n* Adversarial training Madry PGD ([Madry et al., 2017](https://arxiv.org/abs/1706.06083))\n\n**Defences - Transformer:**\n* Defensive Distillation ([Papernot et al., 2015](https://arxiv.org/abs/1511.04508))\n\n**Robustness Metrics, Certifications and Verifications**:\n* Clique Method Robustness Verification ([Hongge et al., 2019](https://arxiv.org/abs/1906.03849))\n* Randomized Smoothing ([Cohen et al., 2019](https://arxiv.org/abs/1902.02918))\n* CLEVER ([Weng et al., 2018](https://arxiv.org/abs/1801.10578))\n* Loss sensitivity ([Arpit et al., 2017](https://arxiv.org/abs/1706.05394))\n* Empirical robustness ([Moosavi-Dezfooli et al., 2015](https://arxiv.org/abs/1511.04599))\n\n**Detection of Adversarial Examples:**\n* Basic detector based on inputs\n* Detector trained on the activations of a specific layer\n* Detector based on Fast Generalized Subset Scan ([Speakman et al., 2018](https://arxiv.org/pdf/1810.08676))\n\n**Detection of Poisoning Attacks:**\n* Detection based on activations analysis ([Chen et al., 2018](https://arxiv.org/abs/1811.03728))\n* Detection based on data provenance ([Baracaldo et al., 2018](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8473440))\n\n## Setup\n\n### Installation with `pip`\n\nThe toolbox is designed and tested to run with Python 3. \nART can be installed from the PyPi repository using `pip`:\n\n```bash\npip install adversarial-robustness-toolbox\n```\n\n### Manual installation\n\nThe most recent version of ART can be downloaded or cloned from this repository:\n\n```bash\ngit clone https://github.com/IBM/adversarial-robustness-toolbox\n```\n\nInstall ART with the following command from the project folder `adversarial-robustness-toolbox`:\n```bash\npip install .\n```\n\nART provides unit tests that can be run with the following command:\n\n```bash\nbash run_tests.sh\n```\n\n## Get Started with ART\n\nExamples of using ART can be found in `examples` and [examples/README.md](examples/README.md) provides an overview and \nadditional information. It contains a minimal example for each machine learning framework. All examples can be run with\nthe following command:\n```bash\npython examples/<example_name>.py\n```\n\nMore detailed examples and tutorials are located in `notebooks` and [notebooks/README.md](notebooks/README.md) provides \nand overview and more information. \n\n### Contributing\n\nAdding new features, improving documentation, fixing bugs, or writing tutorials are all examples of helpful \ncontributions. Furthermore, if you are publishing a new attack or defense, we strongly encourage you to add it to the \nAdversarial Robustness Toolbox so that others may evaluate it fairly in their own work.\n\nBug fixes can be initiated through GitHub pull requests. When making code contributions to the Adversarial Robustness \nToolbox, we ask that you follow the `PEP 8` coding standard and that you provide unit tests for the new features.\n\nThis project uses [DCO](https://developercertificate.org/). Be sure to sign off your commits using the `-s` flag or \nadding `Signed-off-By: Name<Email>` in the commit message.\n\n#### Example\n\n```bash\ngit commit -s -m 'Add new feature'\n```\n\n## Citing ART\n\nIf you use ART for research, please consider citing the following reference paper:\n```\n@article{art2018,\n    title = {Adversarial Robustness Toolbox v1.2.0},\n    author = {Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh~Ngoc and Buesser, Beat and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and Molloy, Ian and Edwards, Ben},\n    journal = {CoRR},\n    volume = {1807.01069},\n    year = {2018},\n    url = {https://arxiv.org/pdf/1807.01069}\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/IBM/adversarial-robustness-toolbox", "keywords": "", "license": "MIT", "maintainer": "Beat Buesser", "maintainer_email": "beat.buesser@ie.ibm.com", "name": "adversarial-robustness-toolbox", "package_url": "https://pypi.org/project/adversarial-robustness-toolbox/", "platform": "", "project_url": "https://pypi.org/project/adversarial-robustness-toolbox/", "project_urls": {"Homepage": "https://github.com/IBM/adversarial-robustness-toolbox"}, "release_url": "https://pypi.org/project/adversarial-robustness-toolbox/1.2.0/", "requires_dist": ["matplotlib", "numpy", "scipy", "six", "setuptools", "scikit-learn (==0.22.1)", "Pillow (==7.0.0)", "sphinx (>=1.4) ; extra == 'docs'", "sphinx-rtd-theme ; extra == 'docs'", "pytest-pep8 ; extra == 'tests'", "codecovh5py ; extra == 'tests'", "requests ; extra == 'tests'", "keras (>=2.2.5) ; extra == 'tests'", "mxnet ; extra == 'tests'", "torch (>=1.2.0) ; extra == 'tests'", "tensorflow (>=1.14.0) ; extra == 'tests'", "scikit-learn (==0.22.1) ; extra == 'tests'", "xgboost (==1.0.0) ; extra == 'tests'", "lightgbm (==2.3.1) ; extra == 'tests'", "GPy (==1.9.9) ; extra == 'tests'", "numpy (==1.18.1scipy==1.4.1) ; extra == 'tests'", "statsmodels (==0.11.0) ; extra == 'tests'", "cma (==2.7.0) ; extra == 'tests'"], "requires_python": "", "summary": "Toolbox for adversarial machine learning.", "version": "1.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Adversarial Robustness Toolbox (ART) v1.2</h1>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/76597ef2abebd514bb0b086dca2f06868b559a40/646f63732f696d616765732f6172745f6c6f676f2e706e673f7261773d74727565\" width=\"200\">\n</p>\n<br>\n<p><a href=\"https://travis-ci.org/IBM/adversarial-robustness-toolbox\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1c83daaeeca2d160e5a5b4be0b0c697f8c1b3be2/68747470733a2f2f7472617669732d63692e6f72672f49424d2f616476657273617269616c2d726f627573746e6573732d746f6f6c626f782e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"http://adversarial-robustness-toolbox.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6308a6f63ca5636d37177c82a85ff44aca38d303/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616476657273617269616c2d726f627573746e6573732d746f6f6c626f782f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://badge.fury.io/gh/IBM%2Fadversarial-robustness-toolbox\" rel=\"nofollow\"><img alt=\"GitHub version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/afe5c20bd0fb6bfffb1c7cf96119568ac71994ee/68747470733a2f2f62616467652e667572792e696f2f67682f49424d253246616476657273617269616c2d726f627573746e6573732d746f6f6c626f782e737667\"></a>\n<a href=\"https://lgtm.com/projects/g/IBM/adversarial-robustness-toolbox/context:python\" rel=\"nofollow\"><img alt=\"Language grade: Python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9a581db03b54a501cbb18b177a3ca4d3f575360f/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f707974686f6e2f672f49424d2f616476657273617269616c2d726f627573746e6573732d746f6f6c626f782e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138\"></a>\n<a href=\"https://lgtm.com/projects/g/IBM/adversarial-robustness-toolbox/alerts/\" rel=\"nofollow\"><img alt=\"Total alerts\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fc45cbc3c05a1c788800de9ba40b7df35fbe515d/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f616c657274732f672f49424d2f616476657273617269616c2d726f627573746e6573732d746f6f6c626f782e7376673f6c6f676f3d6c67746d266c6f676f57696474683d3138\"></a>\n<a href=\"https://codecov.io/gh/IBM/adversarial-robustness-toolbox\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f844e57e3f63281319951147b2329d933679ec76/68747470733a2f2f636f6465636f762e696f2f67682f49424d2f616476657273617269616c2d726f627573746e6573732d746f6f6c626f782f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://github.com/psf/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a>\n<a href=\"https://pypi.org/project/adversarial-robustness-toolbox/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f6ddbbd544d4ecb361d8f57b1ff8bc5527632a13/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f616476657273617269616c2d726f627573746e6573732d746f6f6c626f78\"></a>\n<a href=\"https://ibm-art.slack.com/\" rel=\"nofollow\"><img alt=\"slack-img\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/35a2c3a392dec7998b7bf10e28a70505ab7be500/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230736c61636b2d79656c6c6f772e737667\"></a></p>\n<p><a href=\"README-cn.md\" rel=\"nofollow\">\u4e2d\u6587README\u8bf7\u6309\u6b64\u5904</a></p>\n<p>Adversarial Robustness Toolbox (ART) is a Python library supporting developers and researchers in defending Machine\nLearning models (Deep Neural Networks, Gradient Boosted Decision Trees, Support Vector Machines, Random Forests,\nLogistic Regression, Gaussian Processes, Decision Trees, Scikit-learn Pipelines, etc.) against adversarial threats\n(including evasion, extraction and poisoning) and helps making AI systems more secure and trustworthy. Machine Learning\nmodels are vulnerable to adversarial examples, which are inputs (images, texts, tabular data, etc.) deliberately crafted\nto produce a desired response by the Machine Learning model. ART provides the tools to build and deploy defences and\ntest them with adversarial attacks.</p>\n<p>Defending Machine Learning models involves certifying and verifying model robustness and model hardening with\napproaches such as pre-processing inputs, augmenting training data with adversarial examples, and leveraging runtime\ndetection methods to flag any inputs that might have been modified by an adversary. ART includes attacks for testing\ndefenses with state-of-the-art threat models.</p>\n<p>Documentation of ART: <a href=\"https://adversarial-robustness-toolbox.readthedocs.io\" rel=\"nofollow\">https://adversarial-robustness-toolbox.readthedocs.io</a></p>\n<p>Get started with <a href=\"examples/README.md\" rel=\"nofollow\">examples</a> and <a href=\"notebooks/README.md\" rel=\"nofollow\">tutorials</a></p>\n<p>The library is under continuous development. Feedback, bug reports and contributions are very welcome.\nGet in touch with us on <a href=\"https://ibm-art.slack.com\" rel=\"nofollow\">Slack</a> (invite <a href=\"https://join.slack.com/t/ibm-art/shared_invite/enQtMzkyOTkyODE4NzM4LTA4NGQ1OTMxMzFmY2Q1MzE1NWI2MmEzN2FjNGNjOGVlODVkZDE0MjA1NTA4OGVkMjVkNmQ4MTY1NmMyOGM5YTg\" rel=\"nofollow\">here</a>)!</p>\n<h2>Supported Machine Learning Libraries and Applications</h2>\n<ul>\n<li>TensorFlow (v1 and v2) (<a href=\"http://www.tensorflow.org\" rel=\"nofollow\">www.tensorflow.org</a>)</li>\n<li>Keras (<a href=\"http://www.keras.io\" rel=\"nofollow\">www.keras.io</a>)</li>\n<li>PyTorch (<a href=\"http://www.pytorch.org\" rel=\"nofollow\">www.pytorch.org</a>)</li>\n<li>MXNet (<a href=\"https://mxnet.apache.org\" rel=\"nofollow\">https://mxnet.apache.org</a>)</li>\n<li>Scikit-learn (<a href=\"http://www.scikit-learn.org\" rel=\"nofollow\">www.scikit-learn.org</a>)</li>\n<li>XGBoost (<a href=\"http://www.xgboost.ai\" rel=\"nofollow\">www.xgboost.ai</a>)</li>\n<li>LightGBM (<a href=\"https://lightgbm.readthedocs.io\" rel=\"nofollow\">https://lightgbm.readthedocs.io</a>)</li>\n<li>CatBoost (<a href=\"http://www.catboost.ai\" rel=\"nofollow\">www.catboost.ai</a>)</li>\n<li>GPy (<a href=\"https://sheffieldml.github.io/GPy/\" rel=\"nofollow\">https://sheffieldml.github.io/GPy/</a>)</li>\n</ul>\n<h2>Implemented Attacks, Defences, Detections, Metrics, Certifications and Verifications</h2>\n<p><strong>Evasion Attacks:</strong></p>\n<ul>\n<li>Threshold Attack (<a href=\"https://arxiv.org/abs/1906.06026\" rel=\"nofollow\">Vargas et al., 2019</a>)</li>\n<li>Pixel Attack (<a href=\"https://arxiv.org/abs/1906.06026\" rel=\"nofollow\">Vargas et al., 2019</a>, <a href=\"https://ieeexplore.ieee.org/abstract/document/8601309/citations#citations\" rel=\"nofollow\">Su et al., 2019</a>)</li>\n<li>HopSkipJump attack (<a href=\"https://arxiv.org/abs/1904.02144\" rel=\"nofollow\">Chen et al., 2019</a>)</li>\n<li>High Confidence Low Uncertainty adversarial samples (<a href=\"https://arxiv.org/abs/1812.02606\" rel=\"nofollow\">Grosse et al., 2018</a>)</li>\n<li>Projected gradient descent (<a href=\"https://arxiv.org/abs/1706.06083\" rel=\"nofollow\">Madry et al., 2017</a>)</li>\n<li>NewtonFool (<a href=\"http://doi.acm.org/10.1145/3134600.3134635\" rel=\"nofollow\">Jang et al., 2017</a>)</li>\n<li>Elastic net attack (<a href=\"https://arxiv.org/abs/1709.04114\" rel=\"nofollow\">Chen et al., 2017</a>)</li>\n<li>Spatial transformation attack (<a href=\"https://arxiv.org/abs/1712.02779\" rel=\"nofollow\">Engstrom et al., 2017</a>)</li>\n<li>Query-efficient black-box attack (<a href=\"https://arxiv.org/abs/1712.07113\" rel=\"nofollow\">Ilyas et al., 2017</a>)</li>\n<li>Zeroth-order optimization attack (<a href=\"https://arxiv.org/abs/1708.03999\" rel=\"nofollow\">Chen et al., 2017</a>)</li>\n<li>Decision-based attack / Boundary attack (<a href=\"https://arxiv.org/abs/1712.04248\" rel=\"nofollow\">Brendel et al., 2018</a>)</li>\n<li>Adversarial patch (<a href=\"https://arxiv.org/abs/1712.09665\" rel=\"nofollow\">Brown et al., 2017</a>)</li>\n<li>Decision tree attack (<a href=\"https://arxiv.org/abs/1605.07277\" rel=\"nofollow\">Papernot et al., 2016</a>)</li>\n<li>Carlini &amp; Wagner (C&amp;W) <code>L_2</code> and <code>L_inf</code> attacks (<a href=\"https://arxiv.org/abs/1608.04644\" rel=\"nofollow\">Carlini and Wagner, 2016</a>)</li>\n<li>Basic iterative method (<a href=\"https://arxiv.org/abs/1607.02533\" rel=\"nofollow\">Kurakin et al., 2016</a>)</li>\n<li>Jacobian saliency map (<a href=\"https://arxiv.org/abs/1511.07528\" rel=\"nofollow\">Papernot et al., 2016</a>)</li>\n<li>Universal perturbation (<a href=\"https://arxiv.org/abs/1610.08401\" rel=\"nofollow\">Moosavi-Dezfooli et al., 2016</a>)</li>\n<li>DeepFool (<a href=\"https://arxiv.org/abs/1511.04599\" rel=\"nofollow\">Moosavi-Dezfooli et al., 2015</a>)</li>\n<li>Virtual adversarial method (<a href=\"https://arxiv.org/abs/1507.00677\" rel=\"nofollow\">Miyato et al., 2015</a>)</li>\n<li>Fast gradient method (<a href=\"https://arxiv.org/abs/1412.6572\" rel=\"nofollow\">Goodfellow et al., 2014</a>)</li>\n</ul>\n<p><strong>Extraction Attacks:</strong></p>\n<ul>\n<li>Functionally Equivalent Extraction (<a href=\"https://arxiv.org/abs/1909.01838\" rel=\"nofollow\">Jagielski et al., 2019</a>)</li>\n<li>Copycat CNN (<a href=\"https://arxiv.org/abs/1806.05476\" rel=\"nofollow\">Correia-Silva et al., 2018</a>)</li>\n<li>KnockoffNets (<a href=\"https://arxiv.org/abs/1812.02766\" rel=\"nofollow\">Orekondy et al., 2018</a>)</li>\n</ul>\n<p><strong>Poisoning Attacks:</strong></p>\n<ul>\n<li>Poisoning Attack on SVM (<a href=\"https://arxiv.org/abs/1206.6389\" rel=\"nofollow\">Biggio et al., 2013</a>)</li>\n<li>Backdoor Attack (<a href=\"https://arxiv.org/abs/1708.06733\" rel=\"nofollow\">Gu, et. al., 2017</a>)</li>\n</ul>\n<p><strong>Defences - Preprocessor:</strong></p>\n<ul>\n<li>Thermometer encoding (<a href=\"https://openreview.net/forum?id=S18Su--CW\" rel=\"nofollow\">Buckman et al., 2018</a>)</li>\n<li>Total variance minimization (<a href=\"https://openreview.net/forum?id=SyJ7ClWCb\" rel=\"nofollow\">Guo et al., 2018</a>)</li>\n<li>PixelDefend (<a href=\"https://arxiv.org/abs/1710.10766\" rel=\"nofollow\">Song et al., 2017</a>)</li>\n<li>Gaussian data augmentation (<a href=\"https://arxiv.org/abs/1707.06728\" rel=\"nofollow\">Zantedeschi et al., 2017</a>)</li>\n<li>Feature squeezing (<a href=\"http://arxiv.org/abs/1704.01155\" rel=\"nofollow\">Xu et al., 2017</a>)</li>\n<li>Spatial smoothing (<a href=\"http://arxiv.org/abs/1704.01155\" rel=\"nofollow\">Xu et al., 2017</a>)</li>\n<li>JPEG compression (<a href=\"https://arxiv.org/abs/1608.00853\" rel=\"nofollow\">Dziugaite et al., 2016</a>)</li>\n<li>Label smoothing (<a href=\"https://pdfs.semanticscholar.org/b5ec/486044c6218dd41b17d8bba502b32a12b91a.pdf\" rel=\"nofollow\">Warde-Farley and Goodfellow, 2016</a>)</li>\n<li>Virtual adversarial training (<a href=\"https://arxiv.org/abs/1507.00677\" rel=\"nofollow\">Miyato et al., 2015</a>)</li>\n</ul>\n<p><strong>Defences - Postprocessor:</strong></p>\n<ul>\n<li>Reverse Sigmoid (<a href=\"https://arxiv.org/abs/1806.00054\" rel=\"nofollow\">Lee et al., 2018</a>)</li>\n<li>Random Noise (<a href=\"https://arxiv.org/abs/1811.02054\" rel=\"nofollow\">Chandrasekaranet al., 2018</a>)</li>\n<li>Class Labels (<a href=\"https://arxiv.org/abs/1609.02943\" rel=\"nofollow\">Tramer et al., 2016</a>, <a href=\"https://arxiv.org/abs/1811.02054\" rel=\"nofollow\">Chandrasekaranet al., 2018</a>)</li>\n<li>High Confidence (<a href=\"https://arxiv.org/abs/1609.02943\" rel=\"nofollow\">Tramer et al., 2016</a>)</li>\n<li>Rounding (<a href=\"https://arxiv.org/abs/1609.02943\" rel=\"nofollow\">Tramer et al., 2016</a>)</li>\n</ul>\n<p><strong>Defences - Trainer:</strong></p>\n<ul>\n<li>Adversarial training (<a href=\"http://arxiv.org/abs/1312.6199\" rel=\"nofollow\">Szegedy et al., 2013</a>)</li>\n<li>Adversarial training Madry PGD (<a href=\"https://arxiv.org/abs/1706.06083\" rel=\"nofollow\">Madry et al., 2017</a>)</li>\n</ul>\n<p><strong>Defences - Transformer:</strong></p>\n<ul>\n<li>Defensive Distillation (<a href=\"https://arxiv.org/abs/1511.04508\" rel=\"nofollow\">Papernot et al., 2015</a>)</li>\n</ul>\n<p><strong>Robustness Metrics, Certifications and Verifications</strong>:</p>\n<ul>\n<li>Clique Method Robustness Verification (<a href=\"https://arxiv.org/abs/1906.03849\" rel=\"nofollow\">Hongge et al., 2019</a>)</li>\n<li>Randomized Smoothing (<a href=\"https://arxiv.org/abs/1902.02918\" rel=\"nofollow\">Cohen et al., 2019</a>)</li>\n<li>CLEVER (<a href=\"https://arxiv.org/abs/1801.10578\" rel=\"nofollow\">Weng et al., 2018</a>)</li>\n<li>Loss sensitivity (<a href=\"https://arxiv.org/abs/1706.05394\" rel=\"nofollow\">Arpit et al., 2017</a>)</li>\n<li>Empirical robustness (<a href=\"https://arxiv.org/abs/1511.04599\" rel=\"nofollow\">Moosavi-Dezfooli et al., 2015</a>)</li>\n</ul>\n<p><strong>Detection of Adversarial Examples:</strong></p>\n<ul>\n<li>Basic detector based on inputs</li>\n<li>Detector trained on the activations of a specific layer</li>\n<li>Detector based on Fast Generalized Subset Scan (<a href=\"https://arxiv.org/pdf/1810.08676\" rel=\"nofollow\">Speakman et al., 2018</a>)</li>\n</ul>\n<p><strong>Detection of Poisoning Attacks:</strong></p>\n<ul>\n<li>Detection based on activations analysis (<a href=\"https://arxiv.org/abs/1811.03728\" rel=\"nofollow\">Chen et al., 2018</a>)</li>\n<li>Detection based on data provenance (<a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8473440\" rel=\"nofollow\">Baracaldo et al., 2018</a>)</li>\n</ul>\n<h2>Setup</h2>\n<h3>Installation with <code>pip</code></h3>\n<p>The toolbox is designed and tested to run with Python 3.\nART can be installed from the PyPi repository using <code>pip</code>:</p>\n<pre>pip install adversarial-robustness-toolbox\n</pre>\n<h3>Manual installation</h3>\n<p>The most recent version of ART can be downloaded or cloned from this repository:</p>\n<pre>git clone https://github.com/IBM/adversarial-robustness-toolbox\n</pre>\n<p>Install ART with the following command from the project folder <code>adversarial-robustness-toolbox</code>:</p>\n<pre>pip install .\n</pre>\n<p>ART provides unit tests that can be run with the following command:</p>\n<pre>bash run_tests.sh\n</pre>\n<h2>Get Started with ART</h2>\n<p>Examples of using ART can be found in <code>examples</code> and <a href=\"examples/README.md\" rel=\"nofollow\">examples/README.md</a> provides an overview and\nadditional information. It contains a minimal example for each machine learning framework. All examples can be run with\nthe following command:</p>\n<pre>python examples/&lt;example_name&gt;.py\n</pre>\n<p>More detailed examples and tutorials are located in <code>notebooks</code> and <a href=\"notebooks/README.md\" rel=\"nofollow\">notebooks/README.md</a> provides\nand overview and more information.</p>\n<h3>Contributing</h3>\n<p>Adding new features, improving documentation, fixing bugs, or writing tutorials are all examples of helpful\ncontributions. Furthermore, if you are publishing a new attack or defense, we strongly encourage you to add it to the\nAdversarial Robustness Toolbox so that others may evaluate it fairly in their own work.</p>\n<p>Bug fixes can be initiated through GitHub pull requests. When making code contributions to the Adversarial Robustness\nToolbox, we ask that you follow the <code>PEP 8</code> coding standard and that you provide unit tests for the new features.</p>\n<p>This project uses <a href=\"https://developercertificate.org/\" rel=\"nofollow\">DCO</a>. Be sure to sign off your commits using the <code>-s</code> flag or\nadding <code>Signed-off-By: Name&lt;Email&gt;</code> in the commit message.</p>\n<h4>Example</h4>\n<pre>git commit -s -m <span class=\"s1\">'Add new feature'</span>\n</pre>\n<h2>Citing ART</h2>\n<p>If you use ART for research, please consider citing the following reference paper:</p>\n<pre><code>@article{art2018,\n    title = {Adversarial Robustness Toolbox v1.2.0},\n    author = {Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh~Ngoc and Buesser, Beat and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and Molloy, Ian and Edwards, Ben},\n    journal = {CoRR},\n    volume = {1807.01069},\n    year = {2018},\n    url = {https://arxiv.org/pdf/1807.01069}\n}\n</code></pre>\n\n          </div>"}, "last_serial": 6816826, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "0de89fbe91c5e5bc13e37cd7738af73c", "sha256": "a04e96f137ef5d28d0fc981c5726ff5fabd492543946200b455bf37902abac23"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0de89fbe91c5e5bc13e37cd7738af73c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 83803, "upload_time": "2018-04-25T21:56:10", "upload_time_iso_8601": "2018-04-25T21:56:10.374100Z", "url": "https://files.pythonhosted.org/packages/fd/db/4589a7715c8263f71b6dc6c713aca7f1a184111e6c8eafea52197f376aed/adversarial_robustness_toolbox-0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec9156ddbfad162dd817800e631b1027", "sha256": "dd149dfac0cd6a53872898cc70f82c98cb9d3209e729b762c2a8d1df73711c85"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ec9156ddbfad162dd817800e631b1027", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 83800, "upload_time": "2018-04-25T21:56:12", "upload_time_iso_8601": "2018-04-25T21:56:12.029745Z", "url": "https://files.pythonhosted.org/packages/b7/2e/891a71e30e4c1f6145ac552f58d8e6289b172cf8c34e2259a3b0588cdd78/adversarial_robustness_toolbox-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "95c914992fc20c26a46df9e623feeedb", "sha256": "c7cb1f21ba602e7a8a86cf53b7805f6486681ed4e65355bd91b1ad41866d58cf"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.1.tar.gz", "has_sig": false, "md5_digest": "95c914992fc20c26a46df9e623feeedb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37938, "upload_time": "2018-04-25T21:56:13", "upload_time_iso_8601": "2018-04-25T21:56:13.773628Z", "url": "https://files.pythonhosted.org/packages/79/e8/db3e4d0600f1a22a93c8130d11690c799042083943c2e183df8cec4d1e56/adversarial_robustness_toolbox-0.1.tar.gz", "yanked": false}], "0.10.0": [{"comment_text": "", "digests": {"md5": "4a0057d6c174647c761e9da44d6ed609", "sha256": "2e859ef58c1c4ce0f2967e2e18886ec82e1ce777285e5ea922bedc75550e3dc4"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.10.0-py3-none-any.whl", "has_sig": false, "md5_digest": "4a0057d6c174647c761e9da44d6ed609", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 280222, "upload_time": "2019-07-13T00:27:25", "upload_time_iso_8601": "2019-07-13T00:27:25.248411Z", "url": "https://files.pythonhosted.org/packages/d7/5d/b95885ef8e655696ae4090515b81a63bdedaee5723da42e8e92ef164fcb3/Adversarial_Robustness_Toolbox-0.10.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "22809203c1bc6c92d4fec90cd8ff3b74", "sha256": "f7d99be5ea5499aca23657427abb4344e9d71385aa615132ddb410188cb9060d"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.10.0.tar.gz", "has_sig": false, "md5_digest": "22809203c1bc6c92d4fec90cd8ff3b74", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 167542, "upload_time": "2019-07-13T00:27:30", "upload_time_iso_8601": "2019-07-13T00:27:30.588980Z", "url": "https://files.pythonhosted.org/packages/f3/90/752ce188042275601aa158c9123e12c692f829ad089ddee5ed403dbab72b/Adversarial%20Robustness%20Toolbox-0.10.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "bb842f4d7dbf24ab76b8c4a979cb1a25", "sha256": "f8ac62c54086fdc6f967cedb761cbccec4713245e456afbda4e4344430dae88d"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bb842f4d7dbf24ab76b8c4a979cb1a25", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 97079, "upload_time": "2018-06-19T16:00:58", "upload_time_iso_8601": "2018-06-19T16:00:58.647946Z", "url": "https://files.pythonhosted.org/packages/19/a9/4aa4049772be971fe6edce16daaaf457229b6dde660eef6d87b04faad364/adversarial_robustness_toolbox-0.2.0-py2.py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "63bd6410d5f8cb6c34b63fcb18384000", "sha256": "5b15216db1b78388b7ca6f46b07117d6f92de032e0ebfc28c9841a6c8f79406d"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "63bd6410d5f8cb6c34b63fcb18384000", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 97082, "upload_time": "2018-06-19T16:09:43", "upload_time_iso_8601": "2018-06-19T16:09:43.623564Z", "url": "https://files.pythonhosted.org/packages/97/1c/5628ccadad3fd44369cd8d1614903b688a20af4d67e8f7aabf85e0b77d27/adversarial_robustness_toolbox-0.2.1-py2.py3-none-any.whl", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "bea98fdbb27cf4cdda0272e104763215", "sha256": "b0b454d138a5572212ac8eafd1c1ffaa981f462dda45fcc7b931511179651551"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bea98fdbb27cf4cdda0272e104763215", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 97144, "upload_time": "2018-06-20T10:08:12", "upload_time_iso_8601": "2018-06-20T10:08:12.347887Z", "url": "https://files.pythonhosted.org/packages/7c/e1/2e7edec18816aab40347e59e69dcb8b57614ce488b0fd511523075736ccf/adversarial_robustness_toolbox-0.2.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e7bb9971b8c5b604724119e5c6a1bc8d", "sha256": "086b876dc3b9b30c408377f34a820afbc7e7320af4581ec21c6eca2138eed7f9"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-0.2.2.tar.gz", "has_sig": false, "md5_digest": "e7bb9971b8c5b604724119e5c6a1bc8d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52071, "upload_time": "2018-06-20T10:08:14", "upload_time_iso_8601": "2018-06-20T10:08:14.746368Z", "url": "https://files.pythonhosted.org/packages/d9/d0/52e674ba845020790f8c49c6968f15bd712f5967dbe3ad75d615d5327876/adversarial_robustness_toolbox-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "59b109834d726190655a10f907719278", "sha256": "468ab1e5ecfe382e2699a6903321d66c1a78dbfd8b42384157db4ee6b3a3caa5"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "59b109834d726190655a10f907719278", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 132428, "upload_time": "2018-09-19T10:02:19", "upload_time_iso_8601": "2018-09-19T10:02:19.280538Z", "url": "https://files.pythonhosted.org/packages/31/94/aabfafdf4ce5b0995a8a49765255886a798f663b4ee0b63e24b7e2c33b69/Adversarial_Robustness_Toolbox-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "638c1f2a3c5af0b94e0868c441746e49", "sha256": "baff214812e7584bdfaff6976d88020c0d40532a7fc9b10c8a09cc12970c6bd6"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.3.0.tar.gz", "has_sig": false, "md5_digest": "638c1f2a3c5af0b94e0868c441746e49", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 78564, "upload_time": "2018-09-19T10:02:21", "upload_time_iso_8601": "2018-09-19T10:02:21.782281Z", "url": "https://files.pythonhosted.org/packages/6d/57/ba51b81094fd2769bcd6978ebe9aed7363a4c31a081b64ee9482fde27cdd/Adversarial%20Robustness%20Toolbox-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "630d604aa298cc272cb6b94c2987adad", "sha256": "4a37491330b31d75d4bf867bf1df422ba6516de94a670711ecdb716a56dfd19b"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "630d604aa298cc272cb6b94c2987adad", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 197970, "upload_time": "2018-12-19T21:18:52", "upload_time_iso_8601": "2018-12-19T21:18:52.680934Z", "url": "https://files.pythonhosted.org/packages/f3/cb/fe672d7b44b6db1764c1ffff257dae95d7fa81c2a8ecef1900b6f022cc0d/Adversarial_Robustness_Toolbox-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cf53cc5d302e31b20f01344d70a36b00", "sha256": "540b59a57ce99eef9c1970fabaebf121f30ab018ac9a91e1bf0146a2666fdccb"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.4.0.tar.gz", "has_sig": false, "md5_digest": "cf53cc5d302e31b20f01344d70a36b00", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 107675, "upload_time": "2018-12-19T21:18:54", "upload_time_iso_8601": "2018-12-19T21:18:54.667014Z", "url": "https://files.pythonhosted.org/packages/73/24/f32685a06c795122f6c78ab9d977c92251a764e72ab02058417af805a62c/Adversarial%20Robustness%20Toolbox-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "d1d35678b42c7834ffe73490d5ae2062", "sha256": "32b4864fad35c1ac2580616d9640f03e5fb40800523a50a187aa3dcba56afee8"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d1d35678b42c7834ffe73490d5ae2062", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 204694, "upload_time": "2019-02-01T18:52:52", "upload_time_iso_8601": "2019-02-01T18:52:52.992360Z", "url": "https://files.pythonhosted.org/packages/25/57/b9acec5ee6b36550e1ed3ee21ae3259a75b069c4c6bc103447db153f088d/Adversarial_Robustness_Toolbox-0.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dcae818a9e8acce446d269537d571c6f", "sha256": "03154c0c68c72968b1604bc780aa153b343c563fde49bcb772616ceadddb5312"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.5.0.tar.gz", "has_sig": false, "md5_digest": "dcae818a9e8acce446d269537d571c6f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121724, "upload_time": "2019-02-01T18:52:55", "upload_time_iso_8601": "2019-02-01T18:52:55.141416Z", "url": "https://files.pythonhosted.org/packages/4c/ca/9455b08312fb0702cb8e7224366dc36803a1f98d497a4bf88713e43285ae/Adversarial%20Robustness%20Toolbox-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "a73b4636c8538e90e4183cd9e82ae3e6", "sha256": "9b7f7fb3c62752590b4b86a25db9dad586d0f3e8458fc9c3cad8a84c8fc91c5c"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.6.0-py3-none-any.whl", "has_sig": false, "md5_digest": "a73b4636c8538e90e4183cd9e82ae3e6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 241394, "upload_time": "2019-03-12T22:22:27", "upload_time_iso_8601": "2019-03-12T22:22:27.509875Z", "url": "https://files.pythonhosted.org/packages/3a/4f/8b1545bdf7e01be4a55139a1cf1ca8b3c6bb2f03d07b069c5685e7d3d3e2/Adversarial_Robustness_Toolbox-0.6.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "509faa4f54bec935585a004d28fcd911", "sha256": "4a841a88e4b0acd6a34603a4ce4b7294c929a9480d1daf01fe11af90b1fae821"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.6.0.tar.gz", "has_sig": false, "md5_digest": "509faa4f54bec935585a004d28fcd911", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 137280, "upload_time": "2019-03-12T22:22:29", "upload_time_iso_8601": "2019-03-12T22:22:29.355774Z", "url": "https://files.pythonhosted.org/packages/54/ed/3cfd92ec8f4110d01d36afdb916b9f4e010b9bb301885ea7e53c88d5fc4d/Adversarial%20Robustness%20Toolbox-0.6.0.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "3a502f519b152285e4cae6d91345ce45", "sha256": "c1023195085571af7de584d2c0dfd6400cdde7cfeaaf73e939f23cd27fcc4262"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.7.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3a502f519b152285e4cae6d91345ce45", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 214266, "upload_time": "2019-04-01T15:51:40", "upload_time_iso_8601": "2019-04-01T15:51:40.088720Z", "url": "https://files.pythonhosted.org/packages/ca/98/9b7de5636dc6681181f83b618ebcf5cce4563a5809a13a15e0dd10746965/Adversarial_Robustness_Toolbox-0.7.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "31e247723e16e5157ce4aaebfce789c4", "sha256": "1999a49c873e42718bfc5aa27bd9605be11aacf1b9180c093873551d77472d22"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.7.0.tar.gz", "has_sig": false, "md5_digest": "31e247723e16e5157ce4aaebfce789c4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 135060, "upload_time": "2019-04-01T15:51:43", "upload_time_iso_8601": "2019-04-01T15:51:43.410423Z", "url": "https://files.pythonhosted.org/packages/60/77/714cedd86ae584b2c65585d346de4b3b04e3c6e0149815f08a71a0aa70e8/Adversarial%20Robustness%20Toolbox-0.7.0.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "19653dccd7e18522fd7db94aa363a8ca", "sha256": "d63a3225f70f50a4f66cece1de049e73c08f404900b9e4cdda0712e5efe790f5"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.8.0-py3-none-any.whl", "has_sig": false, "md5_digest": "19653dccd7e18522fd7db94aa363a8ca", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 237739, "upload_time": "2019-04-30T21:26:13", "upload_time_iso_8601": "2019-04-30T21:26:13.415179Z", "url": "https://files.pythonhosted.org/packages/8f/4e/ef4a2319d0d22798d14e4e9911f174949feaa9c249a9765da9574c18aae8/Adversarial_Robustness_Toolbox-0.8.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7e1bbcf0254cc826dc35500c4344d110", "sha256": "f0490c81d55bfb949ecd6b131153941e4595568d98bad5e8490b9ff3df0d9c29"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.8.0.tar.gz", "has_sig": false, "md5_digest": "7e1bbcf0254cc826dc35500c4344d110", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 149785, "upload_time": "2019-04-30T21:26:17", "upload_time_iso_8601": "2019-04-30T21:26:17.086876Z", "url": "https://files.pythonhosted.org/packages/b7/90/0794e1721c5dfe489ae8bb4cbe12aecff0d325fe9f1546eda5250bd3dfd6/Adversarial%20Robustness%20Toolbox-0.8.0.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "a94d0d46cc420afe9766d751333fc0b6", "sha256": "58e5a6d734e7d33995e2663eb962ae3abbb5328c8f48475efa73ae1204481a22"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-0.9.0-py3-none-any.whl", "has_sig": false, "md5_digest": "a94d0d46cc420afe9766d751333fc0b6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 249858, "upload_time": "2019-05-20T15:13:00", "upload_time_iso_8601": "2019-05-20T15:13:00.355816Z", "url": "https://files.pythonhosted.org/packages/9a/71/63274ad0d24d7550477f4a593c5e0a29baa31b0bad4dc61b4e8d368d490a/Adversarial_Robustness_Toolbox-0.9.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "329a34d09947db95a3214ad787cc82b8", "sha256": "12d4c9ec8600ed63aaec0f32a7cdea79c5c29cba308fa086687b433515db8834"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-0.9.0.tar.gz", "has_sig": false, "md5_digest": "329a34d09947db95a3214ad787cc82b8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 153542, "upload_time": "2019-05-20T15:13:02", "upload_time_iso_8601": "2019-05-20T15:13:02.726781Z", "url": "https://files.pythonhosted.org/packages/71/f4/e4c14ee725c434d279e400db63d0c6aad8e30e5faf10fac9e64449804f85/Adversarial%20Robustness%20Toolbox-0.9.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "543adb3b65874547b875a54b71431aa5", "sha256": "d4cffd8bcfd1109e0b980217a1b3380405eb6ad125961ed8bd3d5187443ae429"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "543adb3b65874547b875a54b71431aa5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 374908, "upload_time": "2019-09-12T23:50:34", "upload_time_iso_8601": "2019-09-12T23:50:34.218840Z", "url": "https://files.pythonhosted.org/packages/fd/ed/f81e4ee7c0b1bea029f662ad9fd6ec6189dbf6041d00e669e4b0b62f8ed7/Adversarial_Robustness_Toolbox-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c2b1aa93b10ba4134cbdc8d0c7ab5193", "sha256": "c033cf0caf7bb2a62480feab864db52532bcbde453a8d38a205f8d58c109f86f"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-1.0.0.tar.gz", "has_sig": false, "md5_digest": "c2b1aa93b10ba4134cbdc8d0c7ab5193", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 232813, "upload_time": "2019-09-12T23:50:39", "upload_time_iso_8601": "2019-09-12T23:50:39.348086Z", "url": "https://files.pythonhosted.org/packages/2e/57/b851f090e82d2164659f7e18efe8a3b0435c93a8be27157e8f4dacf891cd/Adversarial%20Robustness%20Toolbox-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "e9f99f8ee6aa32bf0215f5a7b373e5fc", "sha256": "7460e261a8c0837afb7aab3147fdf5b736a914a26e29d956018d36120b9ee59f"}, "downloads": -1, "filename": "Adversarial_Robustness_Toolbox-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e9f99f8ee6aa32bf0215f5a7b373e5fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 375987, "upload_time": "2019-10-08T14:49:49", "upload_time_iso_8601": "2019-10-08T14:49:49.130784Z", "url": "https://files.pythonhosted.org/packages/a7/26/140791dead9918e3ce7a1d9ffed835606a5e2ec03dead859f1b96c023eac/Adversarial_Robustness_Toolbox-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7662b3f026a36a023da6496985958b94", "sha256": "47af9a24de377a66a20be83aa2ab6108b3d9ab0a9824c133198302f75325788e"}, "downloads": -1, "filename": "Adversarial Robustness Toolbox-1.0.1.tar.gz", "has_sig": false, "md5_digest": "7662b3f026a36a023da6496985958b94", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 233602, "upload_time": "2019-10-08T14:49:51", "upload_time_iso_8601": "2019-10-08T14:49:51.235904Z", "url": "https://files.pythonhosted.org/packages/60/3f/2cdc0a7bd97db6b6641bca0ef9c8d054603570d3cccd101fe49e8daa2ac1/Adversarial%20Robustness%20Toolbox-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "51d0df017e56b5d5d65f0b6646cdccef", "sha256": "6c615cc23e582155ba9b1e390d5eedc71bdaa460e4344220fbdc388727daa7ce"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "51d0df017e56b5d5d65f0b6646cdccef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 436698, "upload_time": "2020-01-08T01:07:41", "upload_time_iso_8601": "2020-01-08T01:07:41.228830Z", "url": "https://files.pythonhosted.org/packages/ba/c2/0d0e5887b76a506d3b805c6a9c3032a14b874b31a693fd30b0c7170f4ffc/adversarial_robustness_toolbox-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c6b11f1eca229e0713330d2715af78fc", "sha256": "2e31191c81c7468006b60fd753e190f0239b4d99042d389a06ed97502d704a43"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-1.1.0.tar.gz", "has_sig": false, "md5_digest": "c6b11f1eca229e0713330d2715af78fc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 268514, "upload_time": "2020-01-08T01:07:46", "upload_time_iso_8601": "2020-01-08T01:07:46.801467Z", "url": "https://files.pythonhosted.org/packages/91/1e/dbea0e0616d6c68c29e2fd648f3891d058a96f89694207dd8b44c6b41f44/adversarial_robustness_toolbox-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "d808ec6d4a4a96c45ec91d3c2023f8d8", "sha256": "c6e6ad11fe35d67db6805989a3f5174b72851d02e20b61a9a476ece45176aeda"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d808ec6d4a4a96c45ec91d3c2023f8d8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 436826, "upload_time": "2020-02-08T02:19:46", "upload_time_iso_8601": "2020-02-08T02:19:46.404790Z", "url": "https://files.pythonhosted.org/packages/30/80/443c8bec5502c6315c9d089d7c8b8050ea337a7da72a957c15e86f013bf8/adversarial_robustness_toolbox-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "01b106c74e3e870fb0fba4c24578378c", "sha256": "771d4eb55b928dff2c0d122c5610f094183692f63fb456f1b1a3096398429522"}, "downloads": -1, "filename": "adversarial-robustness-toolbox-1.1.1.tar.gz", "has_sig": false, "md5_digest": "01b106c74e3e870fb0fba4c24578378c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 268650, "upload_time": "2020-02-08T02:19:51", "upload_time_iso_8601": "2020-02-08T02:19:51.693385Z", "url": "https://files.pythonhosted.org/packages/93/9c/c2b72b08e71757513c717e0954b410aa227ae37c06d5b4a1a9930f15d802/adversarial-robustness-toolbox-1.1.1.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "39d6dc0c6a102bdedc1b62a827acfffa", "sha256": "c8b61beecc7a2d3d561f5708604e80bd35a7102c6053140ce3f767d77e72483e"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "39d6dc0c6a102bdedc1b62a827acfffa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 486107, "upload_time": "2020-03-15T19:39:15", "upload_time_iso_8601": "2020-03-15T19:39:15.335340Z", "url": "https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6f62c4154b81bcd8b53257afc3b00a68", "sha256": "103b2cc0f6c5482845b5ad991f53385e359cf32e51a18cffa650ccb6b6580e43"}, "downloads": -1, "filename": "adversarial-robustness-toolbox-1.2.0.tar.gz", "has_sig": false, "md5_digest": "6f62c4154b81bcd8b53257afc3b00a68", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 301902, "upload_time": "2020-03-15T19:39:20", "upload_time_iso_8601": "2020-03-15T19:39:20.662342Z", "url": "https://files.pythonhosted.org/packages/67/13/9c34b037d8509c22323a1bad579d79e31ae80e9d814fffa8579a9b0e0a41/adversarial-robustness-toolbox-1.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "39d6dc0c6a102bdedc1b62a827acfffa", "sha256": "c8b61beecc7a2d3d561f5708604e80bd35a7102c6053140ce3f767d77e72483e"}, "downloads": -1, "filename": "adversarial_robustness_toolbox-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "39d6dc0c6a102bdedc1b62a827acfffa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 486107, "upload_time": "2020-03-15T19:39:15", "upload_time_iso_8601": "2020-03-15T19:39:15.335340Z", "url": "https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6f62c4154b81bcd8b53257afc3b00a68", "sha256": "103b2cc0f6c5482845b5ad991f53385e359cf32e51a18cffa650ccb6b6580e43"}, "downloads": -1, "filename": "adversarial-robustness-toolbox-1.2.0.tar.gz", "has_sig": false, "md5_digest": "6f62c4154b81bcd8b53257afc3b00a68", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 301902, "upload_time": "2020-03-15T19:39:20", "upload_time_iso_8601": "2020-03-15T19:39:20.662342Z", "url": "https://files.pythonhosted.org/packages/67/13/9c34b037d8509c22323a1bad579d79e31ae80e9d814fffa8579a9b0e0a41/adversarial-robustness-toolbox-1.2.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:23:05 2020"}