{"info": {"author": "Welliton Souza", "author_email": "well309@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3"], "description": "# An automated tool for processing whole-exome sequencing data\n\nWhole-exome sequencing has been widely used in clinical applications for the identification of the genetic causes of several diseases.\n_HPexome_ automates many data processing tasks for exome-sequencing data analysis of large-scale cohorts.\nGiven ready-analysis alignment files it is capable of breaking input data into small genomic regions to efficiently process in parallel on cluster-computing environments.\nIt relies on Queue workflow execution engine and GATK variant calling tool and its best practices to output high-confident unified variant calling file.\nOur workflow is shipped as Python command line tool making it easy to install and use.\n\n``` bash\nhpexome [OPTIONS] [DESTINATION]\n```\n\n`OPTIONS`\n\n__Required arguments__\n\n- `-I, --bam` One or more sequence alignment files in BAM format _or_ directories containing `*.bam` files.\n- `-R, --genome` Reference genome in single FASTA file.\n- `--dbsnp` dbSNP file in VCF format. See [dbSNP FTP](ftp://ftp.ncbi.nih.gov/snp/).\n- `--sites` VCF files containing known polymorphic sites to skip over in the recalibration algorithm.\n\n__Optional arguments__\n\n- `--indels` Inputs the VCF file with known insertions and deletions (indels) to be used.\n- `-L, --intervals` One or more genomic intervals over which to operate.\n- `--unified_vcf` Unify VCF files into a single one.\n- `-O, --output_file_name` Output file name for unified VCF. Default is `unified.vcf`.\n- `--min_prunning` Minimum support to not prune paths in the graph. Default value is `2`.\n- `-stand_call_conf` Minimum phred-scaled confidence threshold at which variants should be called. Default is `30`.\n\n__Performance-specific arguments__\n\n- `-nt, --num_data_threads` Controls the number of data consecutive threads sent to the processor that are used in the parallelization process. It is used in the Realigner Target Creator, and may not be used together with the scattercount option. If not set, the walker will run in serial.\n- `-nct, --num_threads_per_data_thread` Controls the number of CPU threads allocated to each data thread. It is used with the Base Recalibrator and the Print Reads, and may not be used together with the `scattercount` option. If not set, the walkers will run in serial.\n- ` --job_runner` Job executor engine (eg. Lsf706, Grid, PbsEngine).\n- `--scatter_count` Controls the number of parts in which the genetic sequence will be divided when sent to be parallelized by the Job executor engine. It  is used in all walkers. It must be used with the `-jobRuner`  option, or else it will not use the GridEngine and the process will be run in serial.\n\n__System path to required software__\n\n- `--java_path` Path to java. Use this to pass JVM-specific arguments. Default is `java`.\n\n`DESTINATION` Sets the directory in which the outputs will be saved. If not set, the outputs will be saved in the directory in which the process is running.\n\n## Reproducible example\n\nIn this example we will download and process a [whole-exome sequence sample](https://www.internationalgenome.org/data-portal/sample/HG00114) from the 1000 Genomes Project and required reference files, as well as required software.\nLet's create a directory to write all files.\n\n```bash\nmkdir hpexome\ncd hpexome\n```\n\n**HPexome** only requires Python 3 and Java 8 to run, optionally DMRAA-supported batch processing system such as SGE.\nHowever, to create input data it is required to align raw sequencing reads to reference genome and sort those reads by coordinate.\nThe required software are: BWA to align reads, amtools to convert output to BAM, and Picard to sort reads and fix tags.\n\n```bash\n# HPexome\npip3 install hpexome\n\n# BWA\nwget https://github.com/lh3/bwa/releases/download/v0.7.17/bwa-0.7.17.tar.bz2\ntar xf bwa-0.7.17.tar.bz2 \nmake -C bwa-0.7.17 \n\n# Samtools\nwget https://github.com/samtools/samtools/releases/download/1.10/samtools-1.10.tar.bz2\ntar xf samtools-1.10.tar.bz2\nmake -C samtools-1.10\n\n# Picard\nwget https://github.com/broadinstitute/picard/releases/download/2.21.7/picard.jar\n```\n\nDownload raw sequencing data as FASTQ files.\n\n```bash\nwget \\\n    ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/NA12878/sequence_read/SRR098401_1.filt.fastq.gz \\\n    ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/NA12878/sequence_read/SRR098401_2.filt.fastq.gz\n```\n\nDownload required reference files.\n\n```bash\nwget \\\n    https://storage.googleapis.com/gatk-legacy-bundles/hg19/ucsc.hg19.fasta \\\n    https://storage.googleapis.com/gatk-legacy-bundles/hg19/ucsc.hg19.fasta.fai \\\n    https://storage.googleapis.com/gatk-legacy-bundles/hg19/ucsc.hg19.dict \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/dbsnp_138.hg19.vcf.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/dbsnp_138.hg19.vcf.idx.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.idx.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.snps.high_confidence.hg19.sites.vcf.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.snps.high_confidence.hg19.sites.vcf.idx.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_omni2.5.hg19.sites.vcf.gz \\\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_omni2.5.hg19.sites.vcf.idx.gz\n\ngunzip dbsnp_138.hg19.vcf.gz \\\n    dbsnp_138.hg19.vcf.idx.gz \\\n    Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz \\\n    Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz \\\n    1000G_phase1.indels.hg19.sites.vcf.gz \\\n    1000G_phase1.indels.hg19.sites.vcf.idx.gz \\\n    1000G_phase1.snps.high_confidence.hg19.sites.vcf.gz \\\n    1000G_phase1.snps.high_confidence.hg19.sites.vcf.idx.gz \\\n    1000G_omni2.5.hg19.sites.vcf.gz \\\n    1000G_omni2.5.hg19.sites.vcf.idx.gz\n```\n\nIndex reference genome.\n\n```bash\nbwa-0.7.17/bwa index ucsc.hg19.fasta\n```\n\nAlign raw sequencing reads to the human reference genome.\n\n```bash\nbwa-0.7.17/bwa mem \\\n    -K 100000000 -t 16 -Y ucsc.hg19.fasta \\\n    SRR098401_1.filt.fastq.gz SRR098401_2.filt.fastq.gz \\\n    | samtools-1.10/samtools view -1 - > NA12878.bam\n```\n\nSort aligned reads by genomic coordinates.\n\n```bash\njava -jar picard.jar SortSam \\\n    INPUT=NA12878.bam \\\n    OUTPUT=NA12878.sorted.bam \\\n    SORT_ORDER=coordinate \\\n    CREATE_INDEX=true\n```\n\nFix RG tags.\n\n```bash\njava -jar picard.jar AddOrReplaceReadGroups \\\n    I=NA12878.sorted.bam \\\n    O=NA12878.sorted.rgfix.bam \\\n    RGID=NA12878 \\\n    RGSM=NA12878 \\\n    RGLB=1kgenomes \\\n    RGPL=Illumina \\\n    PU=Unit1 \\\n    CREATE_INDEX=true\n```\n\nIn some computing setups it will require to set `SGE_ROOT` environment variable.\n\n```bash\nexport SGE_ROOT=/var/lib/gridengine\n```\n\nRun **HPexome**.\n\n```bash\nhpexome \\\n    --bam NA12878.sorted.rgfix.bam \\\n    --genome ucsc.hg19.fasta \\\n    --dbsnp dbsnp_138.hg19.vcf \\\n    --indels Mills_and_1000G_gold_standard.indels.hg19.sites.vcf \\\n    --indels 1000G_phase1.indels.hg19.sites.vcf \\\n    --sites 1000G_phase1.snps.high_confidence.hg19.sites.vcf \\\n    --sites 1000G_omni2.5.hg19.sites.vcf \\\n    --scatter_count 16 \\\n    --job_runner GridEngine \\\n    result_files\n```\n\nIt is expected the following files.\n\n    result_files/\n    \u251c\u2500\u2500 HPexome.jobreport.txt\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.HC.raw.vcf\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.HC.raw.vcf.idx\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.HC.raw.vcf.out\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.intervals\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.intervals.out\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.realn.bai\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.realn.bam\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.realn.bam.out\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.recal.bai\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.recal.bam\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.recal.bam.out\n    \u251c\u2500\u2500 NA12878.sorted.rgfix.recal.cvs\n    \u2514\u2500\u2500 NA12878.sorted.rgfix.recal.cvs.out\n\nSee [hpexome-paper repository](https://github.com/labbcb/hpexome-paper) for information about performance and validation tests.\n\n## Development\n\nClone git repository from GitHub.\n\n```bash\ngit clone https://github.com/labbcb/hpexome.git\ncd hpexome\n```\n\nCreate virtual environment and install development version.\n\n```bash\npython3 -m venv venv\nsource venv/bin/activate\npip install --requirement requirements.txt\n```\n\nPublish new hpexome version to Pypi.\n\n```bash\npip install setuptools wheel twine\npython setup.py sdist bdist_wheel\ntwine upload -u $PYPI_USER -p $PYPI_PASS dist/*\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://bcblab.org/hpexome", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "HPexome", "package_url": "https://pypi.org/project/HPexome/", "platform": "", "project_url": "https://pypi.org/project/HPexome/", "project_urls": {"Bug Tracker": "https://github.com/labbcb/hpexome/issues", "Homepage": "http://bcblab.org/hpexome", "Source Code": "https://github.com/labbcb/hpexome"}, "release_url": "https://pypi.org/project/HPexome/1.2.1/", "requires_dist": ["Click"], "requires_python": "", "summary": "An automated tool for processing whole-exome sequencing data", "version": "1.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>An automated tool for processing whole-exome sequencing data</h1>\n<p>Whole-exome sequencing has been widely used in clinical applications for the identification of the genetic causes of several diseases.\n<em>HPexome</em> automates many data processing tasks for exome-sequencing data analysis of large-scale cohorts.\nGiven ready-analysis alignment files it is capable of breaking input data into small genomic regions to efficiently process in parallel on cluster-computing environments.\nIt relies on Queue workflow execution engine and GATK variant calling tool and its best practices to output high-confident unified variant calling file.\nOur workflow is shipped as Python command line tool making it easy to install and use.</p>\n<pre>hpexome <span class=\"o\">[</span>OPTIONS<span class=\"o\">]</span> <span class=\"o\">[</span>DESTINATION<span class=\"o\">]</span>\n</pre>\n<p><code>OPTIONS</code></p>\n<p><strong>Required arguments</strong></p>\n<ul>\n<li><code>-I, --bam</code> One or more sequence alignment files in BAM format <em>or</em> directories containing <code>*.bam</code> files.</li>\n<li><code>-R, --genome</code> Reference genome in single FASTA file.</li>\n<li><code>--dbsnp</code> dbSNP file in VCF format. See <a>dbSNP FTP</a>.</li>\n<li><code>--sites</code> VCF files containing known polymorphic sites to skip over in the recalibration algorithm.</li>\n</ul>\n<p><strong>Optional arguments</strong></p>\n<ul>\n<li><code>--indels</code> Inputs the VCF file with known insertions and deletions (indels) to be used.</li>\n<li><code>-L, --intervals</code> One or more genomic intervals over which to operate.</li>\n<li><code>--unified_vcf</code> Unify VCF files into a single one.</li>\n<li><code>-O, --output_file_name</code> Output file name for unified VCF. Default is <code>unified.vcf</code>.</li>\n<li><code>--min_prunning</code> Minimum support to not prune paths in the graph. Default value is <code>2</code>.</li>\n<li><code>-stand_call_conf</code> Minimum phred-scaled confidence threshold at which variants should be called. Default is <code>30</code>.</li>\n</ul>\n<p><strong>Performance-specific arguments</strong></p>\n<ul>\n<li><code>-nt, --num_data_threads</code> Controls the number of data consecutive threads sent to the processor that are used in the parallelization process. It is used in the Realigner Target Creator, and may not be used together with the scattercount option. If not set, the walker will run in serial.</li>\n<li><code>-nct, --num_threads_per_data_thread</code> Controls the number of CPU threads allocated to each data thread. It is used with the Base Recalibrator and the Print Reads, and may not be used together with the <code>scattercount</code> option. If not set, the walkers will run in serial.</li>\n<li><code>--job_runner</code> Job executor engine (eg. Lsf706, Grid, PbsEngine).</li>\n<li><code>--scatter_count</code> Controls the number of parts in which the genetic sequence will be divided when sent to be parallelized by the Job executor engine. It  is used in all walkers. It must be used with the <code>-jobRuner</code>  option, or else it will not use the GridEngine and the process will be run in serial.</li>\n</ul>\n<p><strong>System path to required software</strong></p>\n<ul>\n<li><code>--java_path</code> Path to java. Use this to pass JVM-specific arguments. Default is <code>java</code>.</li>\n</ul>\n<p><code>DESTINATION</code> Sets the directory in which the outputs will be saved. If not set, the outputs will be saved in the directory in which the process is running.</p>\n<h2>Reproducible example</h2>\n<p>In this example we will download and process a <a href=\"https://www.internationalgenome.org/data-portal/sample/HG00114\" rel=\"nofollow\">whole-exome sequence sample</a> from the 1000 Genomes Project and required reference files, as well as required software.\nLet's create a directory to write all files.</p>\n<pre>mkdir hpexome\n<span class=\"nb\">cd</span> hpexome\n</pre>\n<p><strong>HPexome</strong> only requires Python 3 and Java 8 to run, optionally DMRAA-supported batch processing system such as SGE.\nHowever, to create input data it is required to align raw sequencing reads to reference genome and sort those reads by coordinate.\nThe required software are: BWA to align reads, amtools to convert output to BAM, and Picard to sort reads and fix tags.</p>\n<pre><span class=\"c1\"># HPexome</span>\npip3 install hpexome\n\n<span class=\"c1\"># BWA</span>\nwget https://github.com/lh3/bwa/releases/download/v0.7.17/bwa-0.7.17.tar.bz2\ntar xf bwa-0.7.17.tar.bz2 \nmake -C bwa-0.7.17 \n\n<span class=\"c1\"># Samtools</span>\nwget https://github.com/samtools/samtools/releases/download/1.10/samtools-1.10.tar.bz2\ntar xf samtools-1.10.tar.bz2\nmake -C samtools-1.10\n\n<span class=\"c1\"># Picard</span>\nwget https://github.com/broadinstitute/picard/releases/download/2.21.7/picard.jar\n</pre>\n<p>Download raw sequencing data as FASTQ files.</p>\n<pre>wget <span class=\"se\">\\</span>\n    ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/NA12878/sequence_read/SRR098401_1.filt.fastq.gz <span class=\"se\">\\</span>\n    ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/NA12878/sequence_read/SRR098401_2.filt.fastq.gz\n</pre>\n<p>Download required reference files.</p>\n<pre>wget <span class=\"se\">\\</span>\n    https://storage.googleapis.com/gatk-legacy-bundles/hg19/ucsc.hg19.fasta <span class=\"se\">\\</span>\n    https://storage.googleapis.com/gatk-legacy-bundles/hg19/ucsc.hg19.fasta.fai <span class=\"se\">\\</span>\n    https://storage.googleapis.com/gatk-legacy-bundles/hg19/ucsc.hg19.dict <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/dbsnp_138.hg19.vcf.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/dbsnp_138.hg19.vcf.idx.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.idx.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.snps.high_confidence.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.snps.high_confidence.hg19.sites.vcf.idx.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_omni2.5.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_omni2.5.hg19.sites.vcf.idx.gz\n\ngunzip dbsnp_138.hg19.vcf.gz <span class=\"se\">\\</span>\n    dbsnp_138.hg19.vcf.idx.gz <span class=\"se\">\\</span>\n    Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz <span class=\"se\">\\</span>\n    1000G_phase1.indels.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    1000G_phase1.indels.hg19.sites.vcf.idx.gz <span class=\"se\">\\</span>\n    1000G_phase1.snps.high_confidence.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    1000G_phase1.snps.high_confidence.hg19.sites.vcf.idx.gz <span class=\"se\">\\</span>\n    1000G_omni2.5.hg19.sites.vcf.gz <span class=\"se\">\\</span>\n    1000G_omni2.5.hg19.sites.vcf.idx.gz\n</pre>\n<p>Index reference genome.</p>\n<pre>bwa-0.7.17/bwa index ucsc.hg19.fasta\n</pre>\n<p>Align raw sequencing reads to the human reference genome.</p>\n<pre>bwa-0.7.17/bwa mem <span class=\"se\">\\</span>\n    -K <span class=\"m\">100000000</span> -t <span class=\"m\">16</span> -Y ucsc.hg19.fasta <span class=\"se\">\\</span>\n    SRR098401_1.filt.fastq.gz SRR098401_2.filt.fastq.gz <span class=\"se\">\\</span>\n    <span class=\"p\">|</span> samtools-1.10/samtools view -1 - &gt; NA12878.bam\n</pre>\n<p>Sort aligned reads by genomic coordinates.</p>\n<pre>java -jar picard.jar SortSam <span class=\"se\">\\</span>\n    <span class=\"nv\">INPUT</span><span class=\"o\">=</span>NA12878.bam <span class=\"se\">\\</span>\n    <span class=\"nv\">OUTPUT</span><span class=\"o\">=</span>NA12878.sorted.bam <span class=\"se\">\\</span>\n    <span class=\"nv\">SORT_ORDER</span><span class=\"o\">=</span>coordinate <span class=\"se\">\\</span>\n    <span class=\"nv\">CREATE_INDEX</span><span class=\"o\">=</span><span class=\"nb\">true</span>\n</pre>\n<p>Fix RG tags.</p>\n<pre>java -jar picard.jar AddOrReplaceReadGroups <span class=\"se\">\\</span>\n    <span class=\"nv\">I</span><span class=\"o\">=</span>NA12878.sorted.bam <span class=\"se\">\\</span>\n    <span class=\"nv\">O</span><span class=\"o\">=</span>NA12878.sorted.rgfix.bam <span class=\"se\">\\</span>\n    <span class=\"nv\">RGID</span><span class=\"o\">=</span>NA12878 <span class=\"se\">\\</span>\n    <span class=\"nv\">RGSM</span><span class=\"o\">=</span>NA12878 <span class=\"se\">\\</span>\n    <span class=\"nv\">RGLB</span><span class=\"o\">=</span>1kgenomes <span class=\"se\">\\</span>\n    <span class=\"nv\">RGPL</span><span class=\"o\">=</span>Illumina <span class=\"se\">\\</span>\n    <span class=\"nv\">PU</span><span class=\"o\">=</span>Unit1 <span class=\"se\">\\</span>\n    <span class=\"nv\">CREATE_INDEX</span><span class=\"o\">=</span><span class=\"nb\">true</span>\n</pre>\n<p>In some computing setups it will require to set <code>SGE_ROOT</code> environment variable.</p>\n<pre><span class=\"nb\">export</span> <span class=\"nv\">SGE_ROOT</span><span class=\"o\">=</span>/var/lib/gridengine\n</pre>\n<p>Run <strong>HPexome</strong>.</p>\n<pre>hpexome <span class=\"se\">\\</span>\n    --bam NA12878.sorted.rgfix.bam <span class=\"se\">\\</span>\n    --genome ucsc.hg19.fasta <span class=\"se\">\\</span>\n    --dbsnp dbsnp_138.hg19.vcf <span class=\"se\">\\</span>\n    --indels Mills_and_1000G_gold_standard.indels.hg19.sites.vcf <span class=\"se\">\\</span>\n    --indels 1000G_phase1.indels.hg19.sites.vcf <span class=\"se\">\\</span>\n    --sites 1000G_phase1.snps.high_confidence.hg19.sites.vcf <span class=\"se\">\\</span>\n    --sites 1000G_omni2.5.hg19.sites.vcf <span class=\"se\">\\</span>\n    --scatter_count <span class=\"m\">16</span> <span class=\"se\">\\</span>\n    --job_runner GridEngine <span class=\"se\">\\</span>\n    result_files\n</pre>\n<p>It is expected the following files.</p>\n<pre><code>result_files/\n\u251c\u2500\u2500 HPexome.jobreport.txt\n\u251c\u2500\u2500 NA12878.sorted.rgfix.HC.raw.vcf\n\u251c\u2500\u2500 NA12878.sorted.rgfix.HC.raw.vcf.idx\n\u251c\u2500\u2500 NA12878.sorted.rgfix.HC.raw.vcf.out\n\u251c\u2500\u2500 NA12878.sorted.rgfix.intervals\n\u251c\u2500\u2500 NA12878.sorted.rgfix.intervals.out\n\u251c\u2500\u2500 NA12878.sorted.rgfix.realn.bai\n\u251c\u2500\u2500 NA12878.sorted.rgfix.realn.bam\n\u251c\u2500\u2500 NA12878.sorted.rgfix.realn.bam.out\n\u251c\u2500\u2500 NA12878.sorted.rgfix.recal.bai\n\u251c\u2500\u2500 NA12878.sorted.rgfix.recal.bam\n\u251c\u2500\u2500 NA12878.sorted.rgfix.recal.bam.out\n\u251c\u2500\u2500 NA12878.sorted.rgfix.recal.cvs\n\u2514\u2500\u2500 NA12878.sorted.rgfix.recal.cvs.out\n</code></pre>\n<p>See <a href=\"https://github.com/labbcb/hpexome-paper\" rel=\"nofollow\">hpexome-paper repository</a> for information about performance and validation tests.</p>\n<h2>Development</h2>\n<p>Clone git repository from GitHub.</p>\n<pre>git clone https://github.com/labbcb/hpexome.git\n<span class=\"nb\">cd</span> hpexome\n</pre>\n<p>Create virtual environment and install development version.</p>\n<pre>python3 -m venv venv\n<span class=\"nb\">source</span> venv/bin/activate\npip install --requirement requirements.txt\n</pre>\n<p>Publish new hpexome version to Pypi.</p>\n<pre>pip install setuptools wheel twine\npython setup.py sdist bdist_wheel\ntwine upload -u <span class=\"nv\">$PYPI_USER</span> -p <span class=\"nv\">$PYPI_PASS</span> dist/*\n</pre>\n\n          </div>"}, "last_serial": 6544608, "releases": {"1.1.1": [{"comment_text": "", "digests": {"md5": "9ed206bbb0c017dc5d3c54ae9454adce", "sha256": "f19e8eac01f74128c777187308533385939584e2038bcc8a0e52f26061ecbe82"}, "downloads": -1, "filename": "HPexome-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9ed206bbb0c017dc5d3c54ae9454adce", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 19023, "upload_time": "2019-08-19T16:27:09", "upload_time_iso_8601": "2019-08-19T16:27:09.171472Z", "url": "https://files.pythonhosted.org/packages/bc/33/f8fed33247a98a0c7577bc030781b2cd9cc740709116a8f35a11fbdedbf6/HPexome-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d6a2b11d8bfe24c4f048f1ae00dd61c", "sha256": "c3ab4c7f0e74f0a935309be0000bedb78317d77e157eb86ede3160d1af745667"}, "downloads": -1, "filename": "HPexome-1.1.1.tar.gz", "has_sig": false, "md5_digest": "9d6a2b11d8bfe24c4f048f1ae00dd61c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5921, "upload_time": "2019-08-19T16:27:11", "upload_time_iso_8601": "2019-08-19T16:27:11.586451Z", "url": "https://files.pythonhosted.org/packages/0b/43/f31ba34b8324d4a380d707d91752e5e659006902b5f6e85337fb0ddb7d66/HPexome-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "a94fcfe3e5ec8ac7c27d1b1c3ad0f737", "sha256": "961f906562ce8b4cd583aa771dbd2df93bf71b0976b4dd09f778f909bcf6f8c7"}, "downloads": -1, "filename": "HPexome-1.1.2-py2-none-any.whl", "has_sig": false, "md5_digest": "a94fcfe3e5ec8ac7c27d1b1c3ad0f737", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19035, "upload_time": "2019-10-11T18:48:54", "upload_time_iso_8601": "2019-10-11T18:48:54.986788Z", "url": "https://files.pythonhosted.org/packages/42/70/8f4f507350060f332b8eb202c65b0bc8691ec2e51f1ce26840d1cb8f9a49/HPexome-1.1.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "13be2ec4d071d75782d3391e4f852e9a", "sha256": "80d94e639c5906cef3eb9da0eb2d8a851320e351c2634a3f344a726dcaf281d1"}, "downloads": -1, "filename": "HPexome-1.1.2.tar.gz", "has_sig": false, "md5_digest": "13be2ec4d071d75782d3391e4f852e9a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5955, "upload_time": "2019-10-11T18:48:56", "upload_time_iso_8601": "2019-10-11T18:48:56.405503Z", "url": "https://files.pythonhosted.org/packages/5a/04/9d708ba02d768be257d93349e03ce9ad1890669752ed2d14760c8d7bc9b5/HPexome-1.1.2.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "7df943d6160e225153631ab22d49283b", "sha256": "1469dde82dcdb2ab361f5ea6279a3a5ba2b1063de7c46baf929af2fc8e3bb4ae"}, "downloads": -1, "filename": "HPexome-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "7df943d6160e225153631ab22d49283b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 43773864, "upload_time": "2020-01-30T16:55:53", "upload_time_iso_8601": "2020-01-30T16:55:53.107763Z", "url": "https://files.pythonhosted.org/packages/b3/77/155edf425af115f89ebb73b1d6c84248929d9e795b723fef58741a7c339d/HPexome-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f99634472e6fb57381de8bf3565c7326", "sha256": "e880260c0234af6ee456a7bdf53ab42d2e6fdc2b970f27c11f2400f71db0939e"}, "downloads": -1, "filename": "HPexome-1.2.0.tar.gz", "has_sig": false, "md5_digest": "f99634472e6fb57381de8bf3565c7326", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43757998, "upload_time": "2020-01-30T16:56:02", "upload_time_iso_8601": "2020-01-30T16:56:02.032328Z", "url": "https://files.pythonhosted.org/packages/ec/3c/4896136d099a78e42d5e6390fd084654bd11cbd8374bb32d1a003e720293/HPexome-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "dae28fb4c099210a128bcfdaa31c75bb", "sha256": "1e8ffb335400e2c0015da4874d81ea11c781dda149c1a077ba519c7ce3631bc2"}, "downloads": -1, "filename": "HPexome-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "dae28fb4c099210a128bcfdaa31c75bb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 43774697, "upload_time": "2020-01-30T17:06:59", "upload_time_iso_8601": "2020-01-30T17:06:59.634094Z", "url": "https://files.pythonhosted.org/packages/cd/f7/7c68c2ccd373022791b3009273768a0077078cc80c89dbd58fcec3b36478/HPexome-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1db5ec5fa6518ec9e5782958fa07efb5", "sha256": "ff9eb138dff094f8e424575f8b0e98b9e3ec7add11c5a7551715c594efad9ae5"}, "downloads": -1, "filename": "HPexome-1.2.1.tar.gz", "has_sig": false, "md5_digest": "1db5ec5fa6518ec9e5782958fa07efb5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43758021, "upload_time": "2020-01-30T17:07:08", "upload_time_iso_8601": "2020-01-30T17:07:08.636306Z", "url": "https://files.pythonhosted.org/packages/e6/a8/f1e2c8a1b32ff5bb8e210d3d6390a97ce6b2ddfd1fd760097522cbe54016/HPexome-1.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dae28fb4c099210a128bcfdaa31c75bb", "sha256": "1e8ffb335400e2c0015da4874d81ea11c781dda149c1a077ba519c7ce3631bc2"}, "downloads": -1, "filename": "HPexome-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "dae28fb4c099210a128bcfdaa31c75bb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 43774697, "upload_time": "2020-01-30T17:06:59", "upload_time_iso_8601": "2020-01-30T17:06:59.634094Z", "url": "https://files.pythonhosted.org/packages/cd/f7/7c68c2ccd373022791b3009273768a0077078cc80c89dbd58fcec3b36478/HPexome-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1db5ec5fa6518ec9e5782958fa07efb5", "sha256": "ff9eb138dff094f8e424575f8b0e98b9e3ec7add11c5a7551715c594efad9ae5"}, "downloads": -1, "filename": "HPexome-1.2.1.tar.gz", "has_sig": false, "md5_digest": "1db5ec5fa6518ec9e5782958fa07efb5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43758021, "upload_time": "2020-01-30T17:07:08", "upload_time_iso_8601": "2020-01-30T17:07:08.636306Z", "url": "https://files.pythonhosted.org/packages/e6/a8/f1e2c8a1b32ff5bb8e210d3d6390a97ce6b2ddfd1fd760097522cbe54016/HPexome-1.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:27 2020"}