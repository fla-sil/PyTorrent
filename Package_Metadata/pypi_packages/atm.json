{"info": {"author": "MIT Data To AI Lab", "author_email": "dailabmit@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "<p align=\"left\">\n<img width=15% src=\"https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png\" alt=\u201cATM\u201d />\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n\n# ATM - Auto Tune Models\n\n\n[![CircleCI](https://circleci.com/gh/HDI-Project/ATM.svg?style=shield)](https://circleci.com/gh/HDI-Project/ATM)\n[![Travis](https://travis-ci.org/HDI-Project/ATM.svg?branch=master)](https://travis-ci.org/HDI-Project/ATM)\n[![PyPi Shield](https://img.shields.io/pypi/v/atm.svg)](https://pypi.python.org/pypi/atm)\n[![Coverage Status](https://codecov.io/gh/HDI-project/ATM/branch/master/graph/badge.svg)](https://codecov.io/gh/HDI-project/ATM)\n[![Downloads](https://pepy.tech/badge/atm)](https://pepy.tech/project/atm)\n\n\n\n\n- License: MIT\n- Documentation: https://HDI-Project.github.io/ATM/\n- Homepage: https://github.com/HDI-Project/ATM\n\n# Overview\n\nAuto Tune Models (ATM) is an AutoML system designed with ease of use in mind. In short, you give\nATM a classification problem and a dataset as a CSV file, and ATM will try to build the best model\nit can. ATM is based on a [paper](https://dai.lids.mit.edu/wp-content/uploads/2018/02/atm_IEEE_BIgData-9-1.pdf)\nof the same name, and the project is part of the [Human-Data Interaction (HDI) Project](https://hdi-dai.lids.mit.edu/) at MIT.\n\n\n# Install\n\n## Requirements\n\n**ATM** has been developed and tested on [Python 2.7, 3.5, and 3.6](https://www.python.org/downloads/)\n\nAlso, although it is not strictly required, the usage of a\n[virtualenv](https://virtualenv.pypa.io/en/latest/) is highly recommended in order to avoid\ninterfering with other software installed in the system where **ATM** is run.\n\nThese are the minimum commands needed to create a virtualenv using python3.6 for **ATM**:\n\n```bash\npip install virtualenv\nvirtualenv -p $(which python3.6) atm-venv\n```\n\nAfterwards, you have to execute this command to have the virtualenv activated:\n\n```bash\nsource atm-venv/bin/activate\n```\n\nRemember about executing it every time you start a new console to work on **ATM**!\n\n## Install with pip\n\nAfter creating the virtualenv and activating it, we recommend using\n[pip](https://pip.pypa.io/en/stable/) in order to install **ATM**:\n\n```bash\npip install atm\n```\n\nThis will pull and install the latest stable release from [PyPi](https://pypi.org/).\n\n## Install from source\n\nAlternatively, with your virtualenv activated, you can clone the repository and install it from\nsource by running `make install` on the `stable` branch:\n\n```bash\ngit clone git@github.com:HDI-Project/ATM.git\ncd ATM\ngit checkout stable\nmake install\n```\n\n## Install for Development\n\nIf you want to contribute to the project, a few more steps are required to make the project ready\nfor development.\n\nFirst, please head to [the GitHub page of the project](https://github.com/HDI-Project/ATM)\nand make a fork of the project under you own username by clicking on the **fork** button on the\nupper right corner of the page.\n\nAfterwards, clone your fork and create a branch from master with a descriptive name that includes\nthe number of the issue that you are going to work on:\n\n```bash\ngit clone git@github.com:{your username}/ATM.git\ncd ATM\ngit branch issue-xx-cool-new-feature master\ngit checkout issue-xx-cool-new-feature\n```\n\nFinally, install the project with the following command, which will install some additional\ndependencies for code linting and testing.\n\n```bash\nmake install-develop\n```\n\nMake sure to use them regularly while developing by running the commands `make lint` and `make test`.\n\n\n# Data Format\n\nATM input is always a CSV file with the following characteristics:\n\n* It uses a single comma, `,`, as the separator.\n* Its first row is a header that contains the names of the columns.\n* There is a column that contains the target variable that will need to be predicted.\n* The rest of the columns are all variables or features that will be used to predict the target column.\n* Each row corresponds to a single, complete, training sample.\n\nHere are the first 5 rows of a valid CSV with 4 features and one target column called `class` as an example:\n\n```\nfeature_01,feature_02,feature_03,feature_04,class\n5.1,3.5,1.4,0.2,Iris-setosa\n4.9,3.0,1.4,0.2,Iris-setosa\n4.7,3.2,1.3,0.2,Iris-setosa\n4.6,3.1,1.5,0.2,Iris-setosa\n```\n\nThis CSV can be passed to ATM as local filesystem path but also as a complete AWS S3 Bucket and\npath specification or as a URL.\n\nYou can find a collection of demo datasets in the [atm-data S3 Bucket in AWS](https://atm-data.s3.amazonaws.com/index.html).\n\n\n# Quickstart\n\nIn this short tutorial we will guide you through a series of steps that will help you getting\nstarted with **ATM** by exploring its Python API.\n\n## 1. Get the demo data\n\nThe first step in order to run **ATM** is to obtain the demo datasets that will be used in during\nthe rest of the tutorial.\n\nFor this demo we will be using the pollution csv from the atm-data bucket, which you can download with your browser\n[from here](https://atm-data.s3.amazonaws.com/pollution_1.csv), or using the following command:\n\n```bash\natm download_demo pollution_1.csv\n```\n\n## 2. Create an ATM instance\n\nThe first thing to do after obtaining the demo dataset is creating an ATM instance.\n\n```python\nfrom atm import ATM\n\natm = ATM()\n```\n\nBy default, if the ATM instance is without any arguments, it will create an SQLite database\ncalled `atm.db` in your current working directory.\n\nIf you want to connect to a SQL database instead, or change the location of your SQLite database,\nplease check the [API Reference](https://hdi-project.github.io/ATM/api/atm.core.html)\nfor the complete list of available options.\n\n## 3. Search for the best model\n\nOnce you have the **ATM** instance ready, you can use the method `atm.run` to start\nsearching for the model that better predicts the target column of your CSV file.\n\nThis function has to be given the path to your CSV file, which can be a local filesystem path, an URL to\nand HTTP or S3 resource.\n\nFor example, if we have previously downloaded the [pollution_1.csv](https://atm-data.s3.amazonaws.com/pollution_1.csv)\nfile inside our current working directory, we can call `run` like this:\n\n```python\nresults = atm.run(train_path='pollution_1.csv')\n```\n\nAlternatively, we can use the HTTPS URL of the file to have ATM download the CSV for us:\n\n```python\nresults = atm.run(train_path='https://atm-data.s3.amazonaws.com/pollution_1.csv')\n```\n\nAs the last option, if we have the file inside an S3 Bucket, we can download it by passing an URI\nin the `s3://{bucket}/{key}` format:\n\n```python\nresults = atm.run(train_path='s3://atm-data/pollution_1.csv')\n```\n\nIn order to make this work with a Private S3 Bucket, please make sure to having configured your\n[AWS credentials file](https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html),\nor to having created your `ATM` instance passing it the `access_key` and `secret_key` arguments.\n\nThis `run` call will start what is called a `Datarun`, and a progress bar will be displayed\nwhile the different models are tested and tuned.\n\n```python\nProcessing dataset demos/pollution_1.csv\n100%|##########################| 100/100 [00:10<00:00,  6.09it/s]\n```\n\nOnce this process has ended, a message will print that the `Datarun` has ended. Then we can\nexplore the `results` object.\n\n## 4. Explore the results\n\nOnce the Datarun has finished, we can explore the `results` object in several ways:\n\n**a. Get a summary of the Datarun**\n\nThe `describe` method will return us a summary of the Datarun execution:\n\n```python\nresults.describe()\n```\n\nThis will print a short description of this Datarun similar to this:\n\n```python\nDatarun 1 summary:\n    Dataset: 'demos/pollution_1.csv'\n    Column Name: 'class'\n    Judgment Metric: 'f1'\n    Classifiers Tested: 100\n    Elapsed Time: 0:00:07.638668\n```\n\n**b. Get a summary of the best classifier**\n\nThe `get_best_classifier` method will print information about the best classifier that was found\nduring this Datarun, including the method used and the best hyperparameters found:\n\n```python\nresults.get_best_classifier()\n```\n\nThe output will be similar to this:\n\n```python\nClassifier id: 94\nClassifier type: knn\nParams chosen:\n    n_neighbors: 13\n    leaf_size: 38\n    weights: uniform\n    algorithm: kd_tree\n    metric: manhattan\n    _scale: True\nCross Validation Score: 0.858 +- 0.096\nTest Score: 0.714\n```\n\n**c. Explore the scores**\n\nThe `get_scores` method will return a `pandas.DataFrame` with information about all the\nclassifiers tested during the Datarun, including their cross validation scores and\nthe location of their pickled models.\n\n```python\nscores = results.get_scores()\n```\n\nThe contents of the scores dataframe should be similar to these:\n\n```python\n  cv_judgment_metric cv_judgment_metric_stdev  id test_judgment_metric  rank\n0       0.8584126984             0.0960095737  94         0.7142857143   1.0\n1       0.8222222222             0.0623609564  12         0.6250000000   2.0\n2       0.8147619048             0.1117618135  64         0.8750000000   3.0\n3       0.8139393939             0.0588721670  68         0.6086956522   4.0\n4       0.8067754468             0.0875180564  50         0.6250000000   5.0\n...\n```\n\n## 5. Make predictions\n\nOnce we have found and explored the best classifier, we will want to make predictions with it.\n\nIn order to do this, we need to follow several steps:\n\n**a. Export the best classifier**\n\nThe `export_best_classifier` method can be used to serialize and save the best classifier model\nusing pickle in the desired location:\n\n```python\nresults.export_best_classifier('path/to/model.pkl')\n```\n\nIf the classifier has been saved correctly, a message will be printed indicating so:\n\n```python\nClassifier 94 saved as path/to/model.pkl\n```\n\nIf the path that you provide already exists, you can ovewrite it by adding the argument\n`force=True`.\n\n**b. Load the exported model**\n\nOnce it is exported you can load it back by calling the `load` method from the `atm.Model`\nclass and passing it the path where the model has been saved:\n\n```python\nfrom atm import Model\n\nmodel = Model.load('path/to/model.pkl')\n```\n\nOnce you have loaded your model, you can pass new data to its `predict` method to make\npredictions:\n\n```python\nimport pandas as pd\n\ndata = pd.read_csv(demo_datasets['pollution'])\n\npredictions = model.predict(data.head())\n```\n\n\n# What's next?\n\nFor more details about **ATM** and all its possibilities and features, please check the\n[documentation site](https://HDI-Project.github.io/ATM/).\n\nThere you can learn more about its [Command Line Interface](https://hdi-project.github.io/ATM/cli.html)\nand its [REST API](https://hdi-project.github.io/ATM/rest.html), as well as\n[how to contribute to ATM](https://HDI-Project.github.io/ATM/community/contributing.html)\nin order to help us developing new features or cool ideas.\n\n# Credits\n\nATM is an open source project from the Data to AI Lab at MIT which has been built and maintained\nover the years by the following team:\n\n* Bennett Cyphers <bcyphers@mit.edu>\n* Thomas Swearingen <swearin3@msu.edu>\n* Carles Sala <csala@csail.mit.edu>\n* Plamen Valentinov <plamen@pythiac.com>\n* Kalyan Veeramachaneni <kalyan@mit.edu>\n* Micah Smith <micahjsmith@gmail.com>\n* Laura Gustafson <lgustaf@mit.edu>\n* Kiran Karra <kiran.karra@gmail.com>\n* Max Kanter <kmax12@gmail.com>\n* Alfredo Cuesta-Infante <alfredo.cuesta@urjc.es>\n* Favio Andr\u00e9 V\u00e1zquez <favio.vazquezp@gmail.com>\n* Matteo Hoch <minime@hochweb.com>\n\n\n## Citing ATM\n\nIf you use ATM, please consider citing the following paper:\n\nThomas Swearingen, Will Drevo, Bennett Cyphers, Alfredo Cuesta-Infante, Arun Ross, Kalyan Veeramachaneni. [ATM: A distributed, collaborative, scalable system for automated machine learning.](https://cyphe.rs/static/atm.pdf) *IEEE BigData 2017*, 151-162\n\nBibTeX entry:\n\n```bibtex\n@inproceedings{DBLP:conf/bigdataconf/SwearingenDCCRV17,\n  author    = {Thomas Swearingen and\n               Will Drevo and\n               Bennett Cyphers and\n               Alfredo Cuesta{-}Infante and\n               Arun Ross and\n               Kalyan Veeramachaneni},\n  title     = {{ATM:} {A} distributed, collaborative, scalable system for automated\n               machine learning},\n  booktitle = {2017 {IEEE} International Conference on Big Data, BigData 2017, Boston,\n               MA, USA, December 11-14, 2017},\n  pages     = {151--162},\n  year      = {2017},\n  crossref  = {DBLP:conf/bigdataconf/2017},\n  url       = {https://doi.org/10.1109/BigData.2017.8257923},\n  doi       = {10.1109/BigData.2017.8257923},\n  timestamp = {Tue, 23 Jan 2018 12:40:42 +0100},\n  biburl    = {https://dblp.org/rec/bib/conf/bigdataconf/SwearingenDCCRV17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\n## Related Projects\n\n### BTB\n\n[BTB](https://github.com/hdi-project/btb), for Bayesian Tuning and Bandits, is the core AutoML\nlibrary in development under the HDI project. BTB exposes several methods for hyperparameter\nselection and tuning through a common API. It allows domain experts to extend existing methods\nand add new ones easily. BTB is a central part of ATM, and the two projects were developed in\ntandem, but it is designed to be implementation-agnostic and should be useful for a wide range\nof hyperparameter selection tasks.\n\n### Featuretools\n\n[Featuretools](https://github.com/featuretools/featuretools) is a python library for automated\nfeature engineering. It can be used to prepare raw transactional and relational datasets for ATM.\nIt is created and maintained by [Feature Labs](https://www.featurelabs.com) and is also a part\nof the [Human Data Interaction Project](https://hdi-dai.lids.mit.edu/).\n\n\n# History\n\n## 0.2.2 (2019-07-30)\n\n### New Features\n\n* Curate dependencies - [Issue #152](https://github.com/HDI-Project/ATM/issues/152) by @csala\n* POST request blocked by CORS policy - [Issue #151](https://github.com/HDI-Project/ATM/issues/151) by @pvk-developer\n\n## 0.2.1 (2019-06-24)\n\n### New Features\n\n* Rest API Cross-origin resource sharing (CORS) - [Issue #146](https://github.com/HDI-Project/ATM/issues/146) by @pvk-developer\n\n## 0.2.0 (2019-05-29)\n\nNew Python API\n\n### New Features\n\n* New API for ATM usage within Python - [Issue #142](https://github.com/HDI-Project/ATM/issues/142) by\n  @pvk-developer and @csala\n* Improved Documentation - [Issue #142](https://github.com/HDI-Project/ATM/issues/142) by\n  @pvk-developer and @csala\n* Code cleanup - [Issue #102](https://github.com/HDI-Project/ATM/issues/102) by\n  @csala\n* Ensure datasets can be downloaded from S3 - [Issue #137](https://github.com/HDI-Project/ATM/issues/137) by @pvk-developer\n* Change to PyMySQL to remove libmysqlclient-dev system dependency - [Issue #136](https://github.com/HDI-Project/ATM/issues/136) by @pvk-developer and @csala\n\n## 0.1.2 (2019-05-07)\n\nREST API and Cluster Management.\n\n### New Features\n\n* REST API Server - Issues [#82](https://github.com/HDI-Project/ATM/issues/82) and\n  [#132](https://github.com/HDI-Project/ATM/issues/132) by @RogerTangos, @pvk-developer and @csala\n* Add Cluster Management commands to start and stop the server and multiple workers\n  as background processes - [Issue #130](https://github.com/HDI-Project/ATM/issues/130) by\n  @pvk-developer and @csala\n* Add TravisCI and migrate docs to GitHub Pages - [Issue #129](https://github.com/HDI-Project/ATM/issues/129)\n  by @pvk-developer\n\n## 0.1.1 (2019-04-02)\n\nFirst Release on PyPi.\n\n### New Features\n\n* Upgrade to latest BTB.\n* New Command Line Interface.\n\n## 0.1.0 (2018-05-04)\n\n* First Release.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/HDI-project/ATM", "keywords": "machine learning hyperparameters tuning classification", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "atm", "package_url": "https://pypi.org/project/atm/", "platform": "", "project_url": "https://pypi.org/project/atm/", "project_urls": {"Homepage": "https://github.com/HDI-project/ATM"}, "release_url": "https://pypi.org/project/atm/0.2.2/", "requires_dist": ["baytune (<0.3,>=0.2.5)", "boto3 (<2,>=1.9.146)", "future (<0.18,>=0.16.0)", "pymysql (<0.10,>=0.9.3)", "numpy (<1.17,>=1.13.1)", "pandas (<0.25,>=0.22.0)", "psutil (<6,>=5.6.1)", "python-daemon (<3,>=2.2.3)", "requests (<3,>=2.18.4)", "scikit-learn (<0.22,>=0.18.2)", "scipy (<1.4,>=0.19.1)", "sqlalchemy (<1.4,>=1.1.14)", "flask (<2,>=1.0.2)", "flask-restless (<0.18,>=0.17.0)", "flask-sqlalchemy (<2.5,>=2.3.2)", "flask-restless-swagger-2 (==0.0.3)", "simplejson (<4,>=3.16.0)", "tqdm (<5,>=4.31.1)", "docutils (<0.15,>=0.10)", "bumpversion (>=0.5.3) ; extra == 'dev'", "pip (>=9.0.1) ; extra == 'dev'", "watchdog (>=0.8.3) ; extra == 'dev'", "m2r (>=0.2.0) ; extra == 'dev'", "Sphinx (>=1.7.1) ; extra == 'dev'", "sphinx-rtd-theme (>=0.2.4) ; extra == 'dev'", "autodocsumm (>=0.1.10) ; extra == 'dev'", "flake8 (>=3.7.7) ; extra == 'dev'", "isort (>=4.3.4) ; extra == 'dev'", "autoflake (>=1.1) ; extra == 'dev'", "autopep8 (>=1.4.3) ; extra == 'dev'", "twine (>=1.10.0) ; extra == 'dev'", "wheel (>=0.30.0) ; extra == 'dev'", "coverage (>=4.5.1) ; extra == 'dev'", "tox (>=2.9.1) ; extra == 'dev'", "mock (>=2.0.0) ; extra == 'dev'", "pytest-cov (>=2.5.1) ; extra == 'dev'", "pytest-runner (>=3.0) ; extra == 'dev'", "pytest-xdist (>=1.20.1) ; extra == 'dev'", "pytest (>=3.2.3) ; extra == 'dev'", "google-compute-engine (==2.8.12) ; extra == 'dev'", "mock (>=2.0.0) ; extra == 'tests'", "pytest-cov (>=2.5.1) ; extra == 'tests'", "pytest-runner (>=3.0) ; extra == 'tests'", "pytest-xdist (>=1.20.1) ; extra == 'tests'", "pytest (>=3.2.3) ; extra == 'tests'", "google-compute-engine (==2.8.12) ; extra == 'tests'"], "requires_python": "", "summary": "Auto Tune Models", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"left\">\n<img alt=\"\u201cATM\u201d\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80df0970db0e9e95cce463bc9fa595caf90dd1c7/68747470733a2f2f6461692e6c6964732e6d69742e6564752f77702d636f6e74656e742f75706c6f6164732f323031382f30362f4c6f676f5f4441495f686967687265732e706e67\" width=\"15%\">\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n<h1>ATM - Auto Tune Models</h1>\n<p><a href=\"https://circleci.com/gh/HDI-Project/ATM\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/05af8bbbd71b42a077469606faa6af43d928a4e9/68747470733a2f2f636972636c6563692e636f6d2f67682f4844492d50726f6a6563742f41544d2e7376673f7374796c653d736869656c64\"></a>\n<a href=\"https://travis-ci.org/HDI-Project/ATM\" rel=\"nofollow\"><img alt=\"Travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/50f295213a94b3dc0a3510e6fd41b46280fb8761/68747470733a2f2f7472617669732d63692e6f72672f4844492d50726f6a6563742f41544d2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pypi.python.org/pypi/atm\" rel=\"nofollow\"><img alt=\"PyPi Shield\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f1f5c13c664a961a7d66b4e80cebd43acdcc4a70/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f61746d2e737667\"></a>\n<a href=\"https://codecov.io/gh/HDI-project/ATM\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6d1d17c6cab38e9497b288149e3122c46be92717/68747470733a2f2f636f6465636f762e696f2f67682f4844492d70726f6a6563742f41544d2f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://pepy.tech/project/atm\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ca52840d74fcfab26bd666cda0bb2a537dcde7bd/68747470733a2f2f706570792e746563682f62616467652f61746d\"></a></p>\n<ul>\n<li>License: MIT</li>\n<li>Documentation: <a href=\"https://HDI-Project.github.io/ATM/\" rel=\"nofollow\">https://HDI-Project.github.io/ATM/</a></li>\n<li>Homepage: <a href=\"https://github.com/HDI-Project/ATM\" rel=\"nofollow\">https://github.com/HDI-Project/ATM</a></li>\n</ul>\n<h1>Overview</h1>\n<p>Auto Tune Models (ATM) is an AutoML system designed with ease of use in mind. In short, you give\nATM a classification problem and a dataset as a CSV file, and ATM will try to build the best model\nit can. ATM is based on a <a href=\"https://dai.lids.mit.edu/wp-content/uploads/2018/02/atm_IEEE_BIgData-9-1.pdf\" rel=\"nofollow\">paper</a>\nof the same name, and the project is part of the <a href=\"https://hdi-dai.lids.mit.edu/\" rel=\"nofollow\">Human-Data Interaction (HDI) Project</a> at MIT.</p>\n<h1>Install</h1>\n<h2>Requirements</h2>\n<p><strong>ATM</strong> has been developed and tested on <a href=\"https://www.python.org/downloads/\" rel=\"nofollow\">Python 2.7, 3.5, and 3.6</a></p>\n<p>Also, although it is not strictly required, the usage of a\n<a href=\"https://virtualenv.pypa.io/en/latest/\" rel=\"nofollow\">virtualenv</a> is highly recommended in order to avoid\ninterfering with other software installed in the system where <strong>ATM</strong> is run.</p>\n<p>These are the minimum commands needed to create a virtualenv using python3.6 for <strong>ATM</strong>:</p>\n<pre>pip install virtualenv\nvirtualenv -p <span class=\"k\">$(</span>which python3.6<span class=\"k\">)</span> atm-venv\n</pre>\n<p>Afterwards, you have to execute this command to have the virtualenv activated:</p>\n<pre><span class=\"nb\">source</span> atm-venv/bin/activate\n</pre>\n<p>Remember about executing it every time you start a new console to work on <strong>ATM</strong>!</p>\n<h2>Install with pip</h2>\n<p>After creating the virtualenv and activating it, we recommend using\n<a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip</a> in order to install <strong>ATM</strong>:</p>\n<pre>pip install atm\n</pre>\n<p>This will pull and install the latest stable release from <a href=\"https://pypi.org/\" rel=\"nofollow\">PyPi</a>.</p>\n<h2>Install from source</h2>\n<p>Alternatively, with your virtualenv activated, you can clone the repository and install it from\nsource by running <code>make install</code> on the <code>stable</code> branch:</p>\n<pre>git clone git@github.com:HDI-Project/ATM.git\n<span class=\"nb\">cd</span> ATM\ngit checkout stable\nmake install\n</pre>\n<h2>Install for Development</h2>\n<p>If you want to contribute to the project, a few more steps are required to make the project ready\nfor development.</p>\n<p>First, please head to <a href=\"https://github.com/HDI-Project/ATM\" rel=\"nofollow\">the GitHub page of the project</a>\nand make a fork of the project under you own username by clicking on the <strong>fork</strong> button on the\nupper right corner of the page.</p>\n<p>Afterwards, clone your fork and create a branch from master with a descriptive name that includes\nthe number of the issue that you are going to work on:</p>\n<pre>git clone git@github.com:<span class=\"o\">{</span>your username<span class=\"o\">}</span>/ATM.git\n<span class=\"nb\">cd</span> ATM\ngit branch issue-xx-cool-new-feature master\ngit checkout issue-xx-cool-new-feature\n</pre>\n<p>Finally, install the project with the following command, which will install some additional\ndependencies for code linting and testing.</p>\n<pre>make install-develop\n</pre>\n<p>Make sure to use them regularly while developing by running the commands <code>make lint</code> and <code>make test</code>.</p>\n<h1>Data Format</h1>\n<p>ATM input is always a CSV file with the following characteristics:</p>\n<ul>\n<li>It uses a single comma, <code>,</code>, as the separator.</li>\n<li>Its first row is a header that contains the names of the columns.</li>\n<li>There is a column that contains the target variable that will need to be predicted.</li>\n<li>The rest of the columns are all variables or features that will be used to predict the target column.</li>\n<li>Each row corresponds to a single, complete, training sample.</li>\n</ul>\n<p>Here are the first 5 rows of a valid CSV with 4 features and one target column called <code>class</code> as an example:</p>\n<pre><code>feature_01,feature_02,feature_03,feature_04,class\n5.1,3.5,1.4,0.2,Iris-setosa\n4.9,3.0,1.4,0.2,Iris-setosa\n4.7,3.2,1.3,0.2,Iris-setosa\n4.6,3.1,1.5,0.2,Iris-setosa\n</code></pre>\n<p>This CSV can be passed to ATM as local filesystem path but also as a complete AWS S3 Bucket and\npath specification or as a URL.</p>\n<p>You can find a collection of demo datasets in the <a href=\"https://atm-data.s3.amazonaws.com/index.html\" rel=\"nofollow\">atm-data S3 Bucket in AWS</a>.</p>\n<h1>Quickstart</h1>\n<p>In this short tutorial we will guide you through a series of steps that will help you getting\nstarted with <strong>ATM</strong> by exploring its Python API.</p>\n<h2>1. Get the demo data</h2>\n<p>The first step in order to run <strong>ATM</strong> is to obtain the demo datasets that will be used in during\nthe rest of the tutorial.</p>\n<p>For this demo we will be using the pollution csv from the atm-data bucket, which you can download with your browser\n<a href=\"https://atm-data.s3.amazonaws.com/pollution_1.csv\" rel=\"nofollow\">from here</a>, or using the following command:</p>\n<pre>atm download_demo pollution_1.csv\n</pre>\n<h2>2. Create an ATM instance</h2>\n<p>The first thing to do after obtaining the demo dataset is creating an ATM instance.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">atm</span> <span class=\"kn\">import</span> <span class=\"n\">ATM</span>\n\n<span class=\"n\">atm</span> <span class=\"o\">=</span> <span class=\"n\">ATM</span><span class=\"p\">()</span>\n</pre>\n<p>By default, if the ATM instance is without any arguments, it will create an SQLite database\ncalled <code>atm.db</code> in your current working directory.</p>\n<p>If you want to connect to a SQL database instead, or change the location of your SQLite database,\nplease check the <a href=\"https://hdi-project.github.io/ATM/api/atm.core.html\" rel=\"nofollow\">API Reference</a>\nfor the complete list of available options.</p>\n<h2>3. Search for the best model</h2>\n<p>Once you have the <strong>ATM</strong> instance ready, you can use the method <code>atm.run</code> to start\nsearching for the model that better predicts the target column of your CSV file.</p>\n<p>This function has to be given the path to your CSV file, which can be a local filesystem path, an URL to\nand HTTP or S3 resource.</p>\n<p>For example, if we have previously downloaded the <a href=\"https://atm-data.s3.amazonaws.com/pollution_1.csv\" rel=\"nofollow\">pollution_1.csv</a>\nfile inside our current working directory, we can call <code>run</code> like this:</p>\n<pre><span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">atm</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">train_path</span><span class=\"o\">=</span><span class=\"s1\">'pollution_1.csv'</span><span class=\"p\">)</span>\n</pre>\n<p>Alternatively, we can use the HTTPS URL of the file to have ATM download the CSV for us:</p>\n<pre><span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">atm</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">train_path</span><span class=\"o\">=</span><span class=\"s1\">'https://atm-data.s3.amazonaws.com/pollution_1.csv'</span><span class=\"p\">)</span>\n</pre>\n<p>As the last option, if we have the file inside an S3 Bucket, we can download it by passing an URI\nin the <code>s3://{bucket}/{key}</code> format:</p>\n<pre><span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">atm</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">train_path</span><span class=\"o\">=</span><span class=\"s1\">'s3://atm-data/pollution_1.csv'</span><span class=\"p\">)</span>\n</pre>\n<p>In order to make this work with a Private S3 Bucket, please make sure to having configured your\n<a href=\"https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html\" rel=\"nofollow\">AWS credentials file</a>,\nor to having created your <code>ATM</code> instance passing it the <code>access_key</code> and <code>secret_key</code> arguments.</p>\n<p>This <code>run</code> call will start what is called a <code>Datarun</code>, and a progress bar will be displayed\nwhile the different models are tested and tuned.</p>\n<pre><span class=\"n\">Processing</span> <span class=\"n\">dataset</span> <span class=\"n\">demos</span><span class=\"o\">/</span><span class=\"n\">pollution_1</span><span class=\"o\">.</span><span class=\"n\">csv</span>\n<span class=\"mi\">100</span><span class=\"o\">%|</span><span class=\"c1\">##########################| 100/100 [00:10&lt;00:00,  6.09it/s]</span>\n</pre>\n<p>Once this process has ended, a message will print that the <code>Datarun</code> has ended. Then we can\nexplore the <code>results</code> object.</p>\n<h2>4. Explore the results</h2>\n<p>Once the Datarun has finished, we can explore the <code>results</code> object in several ways:</p>\n<p><strong>a. Get a summary of the Datarun</strong></p>\n<p>The <code>describe</code> method will return us a summary of the Datarun execution:</p>\n<pre><span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">describe</span><span class=\"p\">()</span>\n</pre>\n<p>This will print a short description of this Datarun similar to this:</p>\n<pre><span class=\"n\">Datarun</span> <span class=\"mi\">1</span> <span class=\"n\">summary</span><span class=\"p\">:</span>\n    <span class=\"n\">Dataset</span><span class=\"p\">:</span> <span class=\"s1\">'demos/pollution_1.csv'</span>\n    <span class=\"n\">Column</span> <span class=\"n\">Name</span><span class=\"p\">:</span> <span class=\"s1\">'class'</span>\n    <span class=\"n\">Judgment</span> <span class=\"n\">Metric</span><span class=\"p\">:</span> <span class=\"s1\">'f1'</span>\n    <span class=\"n\">Classifiers</span> <span class=\"n\">Tested</span><span class=\"p\">:</span> <span class=\"mi\">100</span>\n    <span class=\"n\">Elapsed</span> <span class=\"n\">Time</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mf\">07.638668</span>\n</pre>\n<p><strong>b. Get a summary of the best classifier</strong></p>\n<p>The <code>get_best_classifier</code> method will print information about the best classifier that was found\nduring this Datarun, including the method used and the best hyperparameters found:</p>\n<pre><span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">get_best_classifier</span><span class=\"p\">()</span>\n</pre>\n<p>The output will be similar to this:</p>\n<pre><span class=\"n\">Classifier</span> <span class=\"nb\">id</span><span class=\"p\">:</span> <span class=\"mi\">94</span>\n<span class=\"n\">Classifier</span> <span class=\"nb\">type</span><span class=\"p\">:</span> <span class=\"n\">knn</span>\n<span class=\"n\">Params</span> <span class=\"n\">chosen</span><span class=\"p\">:</span>\n    <span class=\"n\">n_neighbors</span><span class=\"p\">:</span> <span class=\"mi\">13</span>\n    <span class=\"n\">leaf_size</span><span class=\"p\">:</span> <span class=\"mi\">38</span>\n    <span class=\"n\">weights</span><span class=\"p\">:</span> <span class=\"n\">uniform</span>\n    <span class=\"n\">algorithm</span><span class=\"p\">:</span> <span class=\"n\">kd_tree</span>\n    <span class=\"n\">metric</span><span class=\"p\">:</span> <span class=\"n\">manhattan</span>\n    <span class=\"n\">_scale</span><span class=\"p\">:</span> <span class=\"kc\">True</span>\n<span class=\"n\">Cross</span> <span class=\"n\">Validation</span> <span class=\"n\">Score</span><span class=\"p\">:</span> <span class=\"mf\">0.858</span> <span class=\"o\">+-</span> <span class=\"mf\">0.096</span>\n<span class=\"n\">Test</span> <span class=\"n\">Score</span><span class=\"p\">:</span> <span class=\"mf\">0.714</span>\n</pre>\n<p><strong>c. Explore the scores</strong></p>\n<p>The <code>get_scores</code> method will return a <code>pandas.DataFrame</code> with information about all the\nclassifiers tested during the Datarun, including their cross validation scores and\nthe location of their pickled models.</p>\n<pre><span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">get_scores</span><span class=\"p\">()</span>\n</pre>\n<p>The contents of the scores dataframe should be similar to these:</p>\n<pre>  <span class=\"n\">cv_judgment_metric</span> <span class=\"n\">cv_judgment_metric_stdev</span>  <span class=\"nb\">id</span> <span class=\"n\">test_judgment_metric</span>  <span class=\"n\">rank</span>\n<span class=\"mi\">0</span>       <span class=\"mf\">0.8584126984</span>             <span class=\"mf\">0.0960095737</span>  <span class=\"mi\">94</span>         <span class=\"mf\">0.7142857143</span>   <span class=\"mf\">1.0</span>\n<span class=\"mi\">1</span>       <span class=\"mf\">0.8222222222</span>             <span class=\"mf\">0.0623609564</span>  <span class=\"mi\">12</span>         <span class=\"mf\">0.6250000000</span>   <span class=\"mf\">2.0</span>\n<span class=\"mi\">2</span>       <span class=\"mf\">0.8147619048</span>             <span class=\"mf\">0.1117618135</span>  <span class=\"mi\">64</span>         <span class=\"mf\">0.8750000000</span>   <span class=\"mf\">3.0</span>\n<span class=\"mi\">3</span>       <span class=\"mf\">0.8139393939</span>             <span class=\"mf\">0.0588721670</span>  <span class=\"mi\">68</span>         <span class=\"mf\">0.6086956522</span>   <span class=\"mf\">4.0</span>\n<span class=\"mi\">4</span>       <span class=\"mf\">0.8067754468</span>             <span class=\"mf\">0.0875180564</span>  <span class=\"mi\">50</span>         <span class=\"mf\">0.6250000000</span>   <span class=\"mf\">5.0</span>\n<span class=\"o\">...</span>\n</pre>\n<h2>5. Make predictions</h2>\n<p>Once we have found and explored the best classifier, we will want to make predictions with it.</p>\n<p>In order to do this, we need to follow several steps:</p>\n<p><strong>a. Export the best classifier</strong></p>\n<p>The <code>export_best_classifier</code> method can be used to serialize and save the best classifier model\nusing pickle in the desired location:</p>\n<pre><span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">export_best_classifier</span><span class=\"p\">(</span><span class=\"s1\">'path/to/model.pkl'</span><span class=\"p\">)</span>\n</pre>\n<p>If the classifier has been saved correctly, a message will be printed indicating so:</p>\n<pre><span class=\"n\">Classifier</span> <span class=\"mi\">94</span> <span class=\"n\">saved</span> <span class=\"k\">as</span> <span class=\"n\">path</span><span class=\"o\">/</span><span class=\"n\">to</span><span class=\"o\">/</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">pkl</span>\n</pre>\n<p>If the path that you provide already exists, you can ovewrite it by adding the argument\n<code>force=True</code>.</p>\n<p><strong>b. Load the exported model</strong></p>\n<p>Once it is exported you can load it back by calling the <code>load</code> method from the <code>atm.Model</code>\nclass and passing it the path where the model has been saved:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">atm</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'path/to/model.pkl'</span><span class=\"p\">)</span>\n</pre>\n<p>Once you have loaded your model, you can pass new data to its <code>predict</code> method to make\npredictions:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"n\">demo_datasets</span><span class=\"p\">[</span><span class=\"s1\">'pollution'</span><span class=\"p\">])</span>\n\n<span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">())</span>\n</pre>\n<h1>What's next?</h1>\n<p>For more details about <strong>ATM</strong> and all its possibilities and features, please check the\n<a href=\"https://HDI-Project.github.io/ATM/\" rel=\"nofollow\">documentation site</a>.</p>\n<p>There you can learn more about its <a href=\"https://hdi-project.github.io/ATM/cli.html\" rel=\"nofollow\">Command Line Interface</a>\nand its <a href=\"https://hdi-project.github.io/ATM/rest.html\" rel=\"nofollow\">REST API</a>, as well as\n<a href=\"https://HDI-Project.github.io/ATM/community/contributing.html\" rel=\"nofollow\">how to contribute to ATM</a>\nin order to help us developing new features or cool ideas.</p>\n<h1>Credits</h1>\n<p>ATM is an open source project from the Data to AI Lab at MIT which has been built and maintained\nover the years by the following team:</p>\n<ul>\n<li>Bennett Cyphers <a href=\"mailto:bcyphers@mit.edu\">bcyphers@mit.edu</a></li>\n<li>Thomas Swearingen <a href=\"mailto:swearin3@msu.edu\">swearin3@msu.edu</a></li>\n<li>Carles Sala <a href=\"mailto:csala@csail.mit.edu\">csala@csail.mit.edu</a></li>\n<li>Plamen Valentinov <a href=\"mailto:plamen@pythiac.com\">plamen@pythiac.com</a></li>\n<li>Kalyan Veeramachaneni <a href=\"mailto:kalyan@mit.edu\">kalyan@mit.edu</a></li>\n<li>Micah Smith <a href=\"mailto:micahjsmith@gmail.com\">micahjsmith@gmail.com</a></li>\n<li>Laura Gustafson <a href=\"mailto:lgustaf@mit.edu\">lgustaf@mit.edu</a></li>\n<li>Kiran Karra <a href=\"mailto:kiran.karra@gmail.com\">kiran.karra@gmail.com</a></li>\n<li>Max Kanter <a href=\"mailto:kmax12@gmail.com\">kmax12@gmail.com</a></li>\n<li>Alfredo Cuesta-Infante <a href=\"mailto:alfredo.cuesta@urjc.es\">alfredo.cuesta@urjc.es</a></li>\n<li>Favio Andr\u00e9 V\u00e1zquez <a href=\"mailto:favio.vazquezp@gmail.com\">favio.vazquezp@gmail.com</a></li>\n<li>Matteo Hoch <a href=\"mailto:minime@hochweb.com\">minime@hochweb.com</a></li>\n</ul>\n<h2>Citing ATM</h2>\n<p>If you use ATM, please consider citing the following paper:</p>\n<p>Thomas Swearingen, Will Drevo, Bennett Cyphers, Alfredo Cuesta-Infante, Arun Ross, Kalyan Veeramachaneni. <a href=\"https://cyphe.rs/static/atm.pdf\" rel=\"nofollow\">ATM: A distributed, collaborative, scalable system for automated machine learning.</a> <em>IEEE BigData 2017</em>, 151-162</p>\n<p>BibTeX entry:</p>\n<pre><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">DBLP:conf/bigdataconf/SwearingenDCCRV17</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span>    <span class=\"p\">=</span> <span class=\"s\">{Thomas Swearingen and</span>\n<span class=\"s\">               Will Drevo and</span>\n<span class=\"s\">               Bennett Cyphers and</span>\n<span class=\"s\">               Alfredo Cuesta{-}Infante and</span>\n<span class=\"s\">               Arun Ross and</span>\n<span class=\"s\">               Kalyan Veeramachaneni}</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span>     <span class=\"p\">=</span> <span class=\"s\">{{ATM:} {A} distributed, collaborative, scalable system for automated</span>\n<span class=\"s\">               machine learning}</span><span class=\"p\">,</span>\n  <span class=\"na\">booktitle</span> <span class=\"p\">=</span> <span class=\"s\">{2017 {IEEE} International Conference on Big Data, BigData 2017, Boston,</span>\n<span class=\"s\">               MA, USA, December 11-14, 2017}</span><span class=\"p\">,</span>\n  <span class=\"na\">pages</span>     <span class=\"p\">=</span> <span class=\"s\">{151--162}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span>      <span class=\"p\">=</span> <span class=\"s\">{2017}</span><span class=\"p\">,</span>\n  <span class=\"na\">crossref</span>  <span class=\"p\">=</span> <span class=\"s\">{DBLP:conf/bigdataconf/2017}</span><span class=\"p\">,</span>\n  <span class=\"na\">url</span>       <span class=\"p\">=</span> <span class=\"s\">{https://doi.org/10.1109/BigData.2017.8257923}</span><span class=\"p\">,</span>\n  <span class=\"na\">doi</span>       <span class=\"p\">=</span> <span class=\"s\">{10.1109/BigData.2017.8257923}</span><span class=\"p\">,</span>\n  <span class=\"na\">timestamp</span> <span class=\"p\">=</span> <span class=\"s\">{Tue, 23 Jan 2018 12:40:42 +0100}</span><span class=\"p\">,</span>\n  <span class=\"na\">biburl</span>    <span class=\"p\">=</span> <span class=\"s\">{https://dblp.org/rec/bib/conf/bigdataconf/SwearingenDCCRV17}</span><span class=\"p\">,</span>\n  <span class=\"na\">bibsource</span> <span class=\"p\">=</span> <span class=\"s\">{dblp computer science bibliography, https://dblp.org}</span>\n<span class=\"p\">}</span>\n</pre>\n<h2>Related Projects</h2>\n<h3>BTB</h3>\n<p><a href=\"https://github.com/hdi-project/btb\" rel=\"nofollow\">BTB</a>, for Bayesian Tuning and Bandits, is the core AutoML\nlibrary in development under the HDI project. BTB exposes several methods for hyperparameter\nselection and tuning through a common API. It allows domain experts to extend existing methods\nand add new ones easily. BTB is a central part of ATM, and the two projects were developed in\ntandem, but it is designed to be implementation-agnostic and should be useful for a wide range\nof hyperparameter selection tasks.</p>\n<h3>Featuretools</h3>\n<p><a href=\"https://github.com/featuretools/featuretools\" rel=\"nofollow\">Featuretools</a> is a python library for automated\nfeature engineering. It can be used to prepare raw transactional and relational datasets for ATM.\nIt is created and maintained by <a href=\"https://www.featurelabs.com\" rel=\"nofollow\">Feature Labs</a> and is also a part\nof the <a href=\"https://hdi-dai.lids.mit.edu/\" rel=\"nofollow\">Human Data Interaction Project</a>.</p>\n<h1>History</h1>\n<h2>0.2.2 (2019-07-30)</h2>\n<h3>New Features</h3>\n<ul>\n<li>Curate dependencies - <a href=\"https://github.com/HDI-Project/ATM/issues/152\" rel=\"nofollow\">Issue #152</a> by @csala</li>\n<li>POST request blocked by CORS policy - <a href=\"https://github.com/HDI-Project/ATM/issues/151\" rel=\"nofollow\">Issue #151</a> by @pvk-developer</li>\n</ul>\n<h2>0.2.1 (2019-06-24)</h2>\n<h3>New Features</h3>\n<ul>\n<li>Rest API Cross-origin resource sharing (CORS) - <a href=\"https://github.com/HDI-Project/ATM/issues/146\" rel=\"nofollow\">Issue #146</a> by @pvk-developer</li>\n</ul>\n<h2>0.2.0 (2019-05-29)</h2>\n<p>New Python API</p>\n<h3>New Features</h3>\n<ul>\n<li>New API for ATM usage within Python - <a href=\"https://github.com/HDI-Project/ATM/issues/142\" rel=\"nofollow\">Issue #142</a> by\n@pvk-developer and @csala</li>\n<li>Improved Documentation - <a href=\"https://github.com/HDI-Project/ATM/issues/142\" rel=\"nofollow\">Issue #142</a> by\n@pvk-developer and @csala</li>\n<li>Code cleanup - <a href=\"https://github.com/HDI-Project/ATM/issues/102\" rel=\"nofollow\">Issue #102</a> by\n@csala</li>\n<li>Ensure datasets can be downloaded from S3 - <a href=\"https://github.com/HDI-Project/ATM/issues/137\" rel=\"nofollow\">Issue #137</a> by @pvk-developer</li>\n<li>Change to PyMySQL to remove libmysqlclient-dev system dependency - <a href=\"https://github.com/HDI-Project/ATM/issues/136\" rel=\"nofollow\">Issue #136</a> by @pvk-developer and @csala</li>\n</ul>\n<h2>0.1.2 (2019-05-07)</h2>\n<p>REST API and Cluster Management.</p>\n<h3>New Features</h3>\n<ul>\n<li>REST API Server - Issues <a href=\"https://github.com/HDI-Project/ATM/issues/82\" rel=\"nofollow\">#82</a> and\n<a href=\"https://github.com/HDI-Project/ATM/issues/132\" rel=\"nofollow\">#132</a> by @RogerTangos, @pvk-developer and @csala</li>\n<li>Add Cluster Management commands to start and stop the server and multiple workers\nas background processes - <a href=\"https://github.com/HDI-Project/ATM/issues/130\" rel=\"nofollow\">Issue #130</a> by\n@pvk-developer and @csala</li>\n<li>Add TravisCI and migrate docs to GitHub Pages - <a href=\"https://github.com/HDI-Project/ATM/issues/129\" rel=\"nofollow\">Issue #129</a>\nby @pvk-developer</li>\n</ul>\n<h2>0.1.1 (2019-04-02)</h2>\n<p>First Release on PyPi.</p>\n<h3>New Features</h3>\n<ul>\n<li>Upgrade to latest BTB.</li>\n<li>New Command Line Interface.</li>\n</ul>\n<h2>0.1.0 (2018-05-04)</h2>\n<ul>\n<li>First Release.</li>\n</ul>\n\n          </div>"}, "last_serial": 5606695, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "641f3b8c9f5d71cf9bb60cd6a60a0014", "sha256": "843a9d6c91992dee47a762ab68ffc6aa716c008386ba3d96e4b34e20f73cb6d4"}, "downloads": -1, "filename": "atm-0.0.1-py2.7.egg", "has_sig": false, "md5_digest": "641f3b8c9f5d71cf9bb60cd6a60a0014", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": ">=2.7", "size": 117883, "upload_time": "2018-04-20T17:41:31", "upload_time_iso_8601": "2018-04-20T17:41:31.587924Z", "url": "https://files.pythonhosted.org/packages/9c/7f/38ce6da9c6cea29a2509a5602dab927904b41e5ec47c45ec6a972493e2bd/atm-0.0.1-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "58cb1cbe99e88e7d8f5ea4f7cf1f5649", "sha256": "e40213239817c1b897f4b4e622cd1af9c0a56a40029ee199e9bba095cad107a7"}, "downloads": -1, "filename": "atm-0.0.1-py3.6.egg", "has_sig": false, "md5_digest": "58cb1cbe99e88e7d8f5ea4f7cf1f5649", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=2.7", "size": 117422, "upload_time": "2018-04-20T17:41:33", "upload_time_iso_8601": "2018-04-20T17:41:33.116042Z", "url": "https://files.pythonhosted.org/packages/dc/bc/9cb635fe117916c10195115b94b22aa21dbf615d274761fa0c50052494fa/atm-0.0.1-py3.6.egg", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "9de914cd1d12963de1b45051a68b60a4", "sha256": "3c50cf09ef56073a5aa423fcbe056cf840ec127634eb794460a00bcf14373770"}, "downloads": -1, "filename": "atm-0.0.9-py3-none-any.whl", "has_sig": false, "md5_digest": "9de914cd1d12963de1b45051a68b60a4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=2.7", "size": 54025, "upload_time": "2018-04-20T17:41:30", "upload_time_iso_8601": "2018-04-20T17:41:30.025974Z", "url": "https://files.pythonhosted.org/packages/69/9a/83b34f647fdf191ce2c1f41d6c8a07d76d68b607ac29de7e925e0d9f118f/atm-0.0.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "938c11b49bb69a46716321231ab9c839", "sha256": "a075677c024d10b9ff1f341cadb4022c5affde79afeed5100eca62234a810b2d"}, "downloads": -1, "filename": "atm-0.0.9.tar.gz", "has_sig": false, "md5_digest": "938c11b49bb69a46716321231ab9c839", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 49612, "upload_time": "2018-04-20T17:41:34", "upload_time_iso_8601": "2018-04-20T17:41:34.664885Z", "url": "https://files.pythonhosted.org/packages/0e/53/5ba64184135309312487c5157512886966109f344cc5fefd915ec88c26bc/atm-0.0.9.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "d1f4aa87d76d003877fb13b9c91df1a4", "sha256": "c35898955350af64740d78b2de578a26c008e6fadd1f960dfe26e8e20fe2808e"}, "downloads": -1, "filename": "atm-0.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d1f4aa87d76d003877fb13b9c91df1a4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 92580, "upload_time": "2019-04-02T11:31:20", "upload_time_iso_8601": "2019-04-02T11:31:20.618053Z", "url": "https://files.pythonhosted.org/packages/d1/57/09f9fa562afb251b7276a172beb84c5cb94a1ca0f34cdf06a41e932f23d1/atm-0.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6d3234f11219094b13ac5323aa5db48a", "sha256": "c9bbdc5db8176aa22e2f26d18cafdbaf60559d7558b80a02c8d05d1f72f04a77"}, "downloads": -1, "filename": "atm-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6d3234f11219094b13ac5323aa5db48a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 113502, "upload_time": "2019-04-02T11:31:22", "upload_time_iso_8601": "2019-04-02T11:31:22.387072Z", "url": "https://files.pythonhosted.org/packages/c6/4b/c131378ebfe2a9bca7f7ed888aae61cc9c9f8e2f7d4c527a33d5fa737671/atm-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "3fe855d896f1ab09936b8be4dd6b2bbf", "sha256": "ac723663ea21851806527ca4171bf88fbb0f8e3e9e1478c0aecf412944e8032b"}, "downloads": -1, "filename": "atm-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3fe855d896f1ab09936b8be4dd6b2bbf", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 97228, "upload_time": "2019-05-07T18:37:28", "upload_time_iso_8601": "2019-05-07T18:37:28.471102Z", "url": "https://files.pythonhosted.org/packages/18/b4/f45ec585453470a3ced9768ad7e9373959b24169e7a6f068944db0549763/atm-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4cb7ca2913d5f69ca979fd05dc2d3c06", "sha256": "036b73847ee6207072ef628eaf187835648ebc2c44ba9ead90edbcf7167f3fde"}, "downloads": -1, "filename": "atm-0.1.2.tar.gz", "has_sig": false, "md5_digest": "4cb7ca2913d5f69ca979fd05dc2d3c06", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 112911, "upload_time": "2019-05-07T18:37:32", "upload_time_iso_8601": "2019-05-07T18:37:32.192401Z", "url": "https://files.pythonhosted.org/packages/54/ec/c0dea70beb8c3db8b389de1c125b0b0ae3819cd6bb515e70a46dd5058625/atm-0.1.2.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "40d9c21385650af673e8bb555ec4d183", "sha256": "4a31b3c1cd995d93d664817da7f2015ad812eea42037d623036da75f5838baf9"}, "downloads": -1, "filename": "atm-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "40d9c21385650af673e8bb555ec4d183", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 60165, "upload_time": "2019-05-29T15:27:24", "upload_time_iso_8601": "2019-05-29T15:27:24.920558Z", "url": "https://files.pythonhosted.org/packages/90/dc/27ab8f755a757e46c2dacf50dfe6a2d996f9892c3ca6295f119257b58f21/atm-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e64af042e2ebfc6ff1d5e316376d0022", "sha256": "185ef65fed7b3f4e2b220f7b5c1369555ce5333fe657e7773012266b2aa3cf85"}, "downloads": -1, "filename": "atm-0.2.0.tar.gz", "has_sig": false, "md5_digest": "e64af042e2ebfc6ff1d5e316376d0022", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 122082, "upload_time": "2019-05-29T15:27:26", "upload_time_iso_8601": "2019-05-29T15:27:26.671039Z", "url": "https://files.pythonhosted.org/packages/a5/c6/85c0f983cda1509492ace524d5536e9132b02c74761d7d69af7396c24a51/atm-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "b801d5af9700b78bbe05287505023593", "sha256": "f96e60c41de22505be0cdf277345b001ac22c793be423562caa16af04de2fe77"}, "downloads": -1, "filename": "atm-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b801d5af9700b78bbe05287505023593", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 62762, "upload_time": "2019-06-24T13:31:28", "upload_time_iso_8601": "2019-06-24T13:31:28.216814Z", "url": "https://files.pythonhosted.org/packages/64/16/e4d8298503e999ad559dd6f28bbdd04bfbfd645a8205d86fc86dbb9e58a9/atm-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "04475b1f74b4fb5296222ea592f48de5", "sha256": "1eefd180985b717aa7b4cf9f44739ccf774575a683b069f51253288b2e04a465"}, "downloads": -1, "filename": "atm-0.2.1.tar.gz", "has_sig": false, "md5_digest": "04475b1f74b4fb5296222ea592f48de5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 125653, "upload_time": "2019-06-24T13:31:29", "upload_time_iso_8601": "2019-06-24T13:31:29.727254Z", "url": "https://files.pythonhosted.org/packages/f3/f5/c67824b62bae68f8849668fe91967484d18bb6151c63cf1b93a9f0eb0237/atm-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "81670be6eab3c2be495ec8c9ca5a4df0", "sha256": "805243fb6b1e3c990114f26a78f1373b56cb169a2dbf656cefc41c4348860d6c"}, "downloads": -1, "filename": "atm-0.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "81670be6eab3c2be495ec8c9ca5a4df0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 63401, "upload_time": "2019-07-30T09:25:11", "upload_time_iso_8601": "2019-07-30T09:25:11.443177Z", "url": "https://files.pythonhosted.org/packages/1a/23/4ff31ca9695473342140369274f5d11ed0fec8204dac3a6e469797ad046f/atm-0.2.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b9842eb23a4074495d3f138a232e5e59", "sha256": "9a5ab26f14bff3f08665b1d6ae0bfa5e8f0848860a3977664b362ea03ceb9352"}, "downloads": -1, "filename": "atm-0.2.2.tar.gz", "has_sig": false, "md5_digest": "b9842eb23a4074495d3f138a232e5e59", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127799, "upload_time": "2019-07-30T09:25:15", "upload_time_iso_8601": "2019-07-30T09:25:15.533980Z", "url": "https://files.pythonhosted.org/packages/5b/5b/77e50b27ef2b0b2f4be0c9dfe6f4cee9c37749a393e3e1c01c9aa33c892b/atm-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "81670be6eab3c2be495ec8c9ca5a4df0", "sha256": "805243fb6b1e3c990114f26a78f1373b56cb169a2dbf656cefc41c4348860d6c"}, "downloads": -1, "filename": "atm-0.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "81670be6eab3c2be495ec8c9ca5a4df0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 63401, "upload_time": "2019-07-30T09:25:11", "upload_time_iso_8601": "2019-07-30T09:25:11.443177Z", "url": "https://files.pythonhosted.org/packages/1a/23/4ff31ca9695473342140369274f5d11ed0fec8204dac3a6e469797ad046f/atm-0.2.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b9842eb23a4074495d3f138a232e5e59", "sha256": "9a5ab26f14bff3f08665b1d6ae0bfa5e8f0848860a3977664b362ea03ceb9352"}, "downloads": -1, "filename": "atm-0.2.2.tar.gz", "has_sig": false, "md5_digest": "b9842eb23a4074495d3f138a232e5e59", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 127799, "upload_time": "2019-07-30T09:25:15", "upload_time_iso_8601": "2019-07-30T09:25:15.533980Z", "url": "https://files.pythonhosted.org/packages/5b/5b/77e50b27ef2b0b2f4be0c9dfe6f4cee9c37749a393e3e1c01c9aa33c892b/atm-0.2.2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:34 2020"}