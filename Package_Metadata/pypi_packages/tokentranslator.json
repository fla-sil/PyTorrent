{"info": {"author": "tokentranslator-group", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# tokentranslator\nExperimental project. Can be used to create equations or proposals translators by defining replacers for each term (token) with use of gui web interface. Currently contain support for Wolfram->sympy (or cpp), Tex-> sympy (or cpp).\nAlso can extract arguments from equation/proposal. Has experimental sampling proposal generator i.e. for proposal can create subset of it's arguments at which this proposal is true.\n\n### Examples of translation:\n#### Tex to sympy (cpp):\n```\n   U'=a*(\\\\frac{d^2U}{dx^2}+ \\\\frac{d^2U}{dy^2})\n\ntranslated to:\n   (sympy)\n     sympy.diff(U(t), t)=a*(diff(U,x, 2)+diff(U,y, 2))\n\n   (cpp)\n     result[idx + 0]=params[0]*((DXM2 * (source[0][idx + 1 * Block0StrideX * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideX * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideX * Block0CELLSIZE + 0]))+(DYM2 * (source[0][idx + 1 * Block0StrideY * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideY * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideY * Block0CELLSIZE + 0])))\n\nU'=a*(\\\\frac{d^2U}{dx^2}+ \\\\frac{d^2U}{dy^2})+sin(x)+A.transpose().conj()\n\ntranslated to\n   (sympy)\n      sympy.diff(U(t), t)=a*(diff(U,x, 2)+diff(U,y, 2))+sympy.sin(x)+A.transpose().conj()\n\n   (cpp)\n      result[idx + 0]=params[0]*((DXM2 * (source[0][idx + 1 * Block0StrideX * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideX * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideX * Block0CELLSIZE + 0]))+(DYM2 * (source[0][idx + 1 * Block0StrideY * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideY * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideY * Block0CELLSIZE + 0])))+sin((Block0OffsetX+idxX*DX))+A.transpose().conj()\n```\n### requirements\n```\nlinux, python3\n\n```\n### installation and running\n```\nsource ~/anaconda3/bin/./activate parser_env \n~/anaconda3/envs/parser_env/bin/./pip install tokentranslator\n\n\n# for web interface:\n~/anaconda3/envs/parser_env/bin/./python3 -c \"import tokentranslator.gui.web.server.server_main as sm; sm.run()\"\n\n```\n\n### usage\n##### parsing equations (defalut from Wolfram)\n```\nfrom tokentranslator.gui.web.model.model_main import TokenizerDB\nfrom tokentranslator.env.equation_net.equation import Equation\n\nmodel = TokenizerDB()\n\neq = Equation(\"U'=a*(D[U,{x, 2}]+D[U,{y,2}])\", db=model)\neq.parser.parse()\n\n# set default params (like dimension, bounds type (Dirichlet or Neumann) an so on):\neq.replacer.cpp.editor.set_default()\neq.replacer.cpp.make_cpp()\n\nprint('\\noriginal:')\neq.show_original()\n\nprint(\"\\nparsed tree:\")\neq.show_cyk_out()\n\nprint('\\ncpp:')\neq.replacer.cpp.show_cpp()\n\nprint(\"\\nsympy:\")\neq.replacer.sympy.make_sympy()\neq.replacer.sympy.show_sympy()\n\n```\n##### parsing equations (from TeX)\n```\n# there is currently two dialect databases for equations:\n# 'env/equation_net/data/terms/input/tex_dialect.db' for tex\n# 'env/equation_net/data/terms/input/demo_dialect.db' for wolfram\n# default is wolfram\n\n# to change to tex use commands:\nmodel.save_path(\"eqs\", \"env/equation_net/data/terms/input/tex_dialect.db\")\nmodel.change_dialect_db(\"eqs\")\n# this change \"eqs\" path for all parsers wherever they run.\n# show current dialect.db path:\nmodel.get_path_of_dialect_db(\"eqs\")\n\n# if it's ended with tex_dialect.db then tex input used\n# remained is same as above:\n\neq = Equation(\"U'=a*(\\\\frac{d^2U}{dx^2}+ \\\\frac{d^2U}{dy^2})\", db=model)\neq.parser.show_patterns()\neq.parser.parse()\n\nprint('\\noriginal:')\neq.show_original()\n\nprint(\"\\nparsed tree:\")\neq.show_cyk_out()\n\nprint('\\ncpp:')\neq.replacer.cpp.show_cpp()\n\nprint(\"\\nsympy:\")\neq.replacer.sympy.make_sympy()\neq.replacer.sympy.show_sympy()\n\n\n```\n##### parsing proposals:\n```\nfrom tokentranslator.gui.web.model.model_main import TokenizerDB\nfrom tokentranslator.env.clause.clause_main import Clause\n\nmodel = TokenizerDB()\n\n# switch to clauses db:\nmodel.change_dialect_db(\"cs\")\n\nclause = Clause(\"abelian(G) \\\\and subgroup(H, G,) => abelian(H)\", db=model)\nclause.parser.parse()\n\n# there is currently no dialect to translate clause to, so just check it's generated tree:\nclause.show_cyk_out()\n# this tree will be used for proposal sampling.\n\n# !for equation parser to work don't forget change db back:\nmodel.change_dialect_db(\"eqs\")\n# even if You is in other session! \n```\n\n![alt tag](https://raw.githubusercontent.com/valdecar/Murka/master/screen_overview1.png)\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tokentranslator-group/tokentranslator", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "tokentranslator", "package_url": "https://pypi.org/project/tokentranslator/", "platform": "", "project_url": "https://pypi.org/project/tokentranslator/", "project_urls": {"Homepage": "https://github.com/tokentranslator-group/tokentranslator"}, "release_url": "https://pypi.org/project/tokentranslator/0.0.1.1.dev3/", "requires_dist": ["networkx (>=2.4)", "peewee (>2.10.2)", "sympy (>1.0)", "tornado (>4.4.2)"], "requires_python": "", "summary": "token translator framework", "version": "0.0.1.1.dev3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>tokentranslator</h1>\n<p>Experimental project. Can be used to create equations or proposals translators by defining replacers for each term (token) with use of gui web interface. Currently contain support for Wolfram-&gt;sympy (or cpp), Tex-&gt; sympy (or cpp).\nAlso can extract arguments from equation/proposal. Has experimental sampling proposal generator i.e. for proposal can create subset of it's arguments at which this proposal is true.</p>\n<h3>Examples of translation:</h3>\n<h4>Tex to sympy (cpp):</h4>\n<pre><code>   U'=a*(\\\\frac{d^2U}{dx^2}+ \\\\frac{d^2U}{dy^2})\n\ntranslated to:\n   (sympy)\n     sympy.diff(U(t), t)=a*(diff(U,x, 2)+diff(U,y, 2))\n\n   (cpp)\n     result[idx + 0]=params[0]*((DXM2 * (source[0][idx + 1 * Block0StrideX * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideX * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideX * Block0CELLSIZE + 0]))+(DYM2 * (source[0][idx + 1 * Block0StrideY * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideY * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideY * Block0CELLSIZE + 0])))\n\nU'=a*(\\\\frac{d^2U}{dx^2}+ \\\\frac{d^2U}{dy^2})+sin(x)+A.transpose().conj()\n\ntranslated to\n   (sympy)\n      sympy.diff(U(t), t)=a*(diff(U,x, 2)+diff(U,y, 2))+sympy.sin(x)+A.transpose().conj()\n\n   (cpp)\n      result[idx + 0]=params[0]*((DXM2 * (source[0][idx + 1 * Block0StrideX * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideX * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideX * Block0CELLSIZE + 0]))+(DYM2 * (source[0][idx + 1 * Block0StrideY * Block0CELLSIZE + 0] - 2.0 * source[0][idx + 0 * Block0StrideY * Block0CELLSIZE + 0] + source[0][idx-1 * Block0StrideY * Block0CELLSIZE + 0])))+sin((Block0OffsetX+idxX*DX))+A.transpose().conj()\n</code></pre>\n<h3>requirements</h3>\n<pre><code>linux, python3\n\n</code></pre>\n<h3>installation and running</h3>\n<pre><code>source ~/anaconda3/bin/./activate parser_env \n~/anaconda3/envs/parser_env/bin/./pip install tokentranslator\n\n\n# for web interface:\n~/anaconda3/envs/parser_env/bin/./python3 -c \"import tokentranslator.gui.web.server.server_main as sm; sm.run()\"\n\n</code></pre>\n<h3>usage</h3>\n<h5>parsing equations (defalut from Wolfram)</h5>\n<pre><code>from tokentranslator.gui.web.model.model_main import TokenizerDB\nfrom tokentranslator.env.equation_net.equation import Equation\n\nmodel = TokenizerDB()\n\neq = Equation(\"U'=a*(D[U,{x, 2}]+D[U,{y,2}])\", db=model)\neq.parser.parse()\n\n# set default params (like dimension, bounds type (Dirichlet or Neumann) an so on):\neq.replacer.cpp.editor.set_default()\neq.replacer.cpp.make_cpp()\n\nprint('\\noriginal:')\neq.show_original()\n\nprint(\"\\nparsed tree:\")\neq.show_cyk_out()\n\nprint('\\ncpp:')\neq.replacer.cpp.show_cpp()\n\nprint(\"\\nsympy:\")\neq.replacer.sympy.make_sympy()\neq.replacer.sympy.show_sympy()\n\n</code></pre>\n<h5>parsing equations (from TeX)</h5>\n<pre><code># there is currently two dialect databases for equations:\n# 'env/equation_net/data/terms/input/tex_dialect.db' for tex\n# 'env/equation_net/data/terms/input/demo_dialect.db' for wolfram\n# default is wolfram\n\n# to change to tex use commands:\nmodel.save_path(\"eqs\", \"env/equation_net/data/terms/input/tex_dialect.db\")\nmodel.change_dialect_db(\"eqs\")\n# this change \"eqs\" path for all parsers wherever they run.\n# show current dialect.db path:\nmodel.get_path_of_dialect_db(\"eqs\")\n\n# if it's ended with tex_dialect.db then tex input used\n# remained is same as above:\n\neq = Equation(\"U'=a*(\\\\frac{d^2U}{dx^2}+ \\\\frac{d^2U}{dy^2})\", db=model)\neq.parser.show_patterns()\neq.parser.parse()\n\nprint('\\noriginal:')\neq.show_original()\n\nprint(\"\\nparsed tree:\")\neq.show_cyk_out()\n\nprint('\\ncpp:')\neq.replacer.cpp.show_cpp()\n\nprint(\"\\nsympy:\")\neq.replacer.sympy.make_sympy()\neq.replacer.sympy.show_sympy()\n\n\n</code></pre>\n<h5>parsing proposals:</h5>\n<pre><code>from tokentranslator.gui.web.model.model_main import TokenizerDB\nfrom tokentranslator.env.clause.clause_main import Clause\n\nmodel = TokenizerDB()\n\n# switch to clauses db:\nmodel.change_dialect_db(\"cs\")\n\nclause = Clause(\"abelian(G) \\\\and subgroup(H, G,) =&gt; abelian(H)\", db=model)\nclause.parser.parse()\n\n# there is currently no dialect to translate clause to, so just check it's generated tree:\nclause.show_cyk_out()\n# this tree will be used for proposal sampling.\n\n# !for equation parser to work don't forget change db back:\nmodel.change_dialect_db(\"eqs\")\n# even if You is in other session! \n</code></pre>\n<p><img alt=\"alt tag\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/75e768777cae69ba136a70eac37eae57778dce5d/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f76616c64656361722f4d75726b612f6d61737465722f73637265656e5f6f76657276696577312e706e67\"></p>\n\n          </div>"}, "last_serial": 6848911, "releases": {"0.0.1.1.dev2": [{"comment_text": "", "digests": {"md5": "16acca43a36a96d7585c87325aadfa89", "sha256": "786eca465d4918d3e0cadedc1824e1eaa4c78d6951be7dc07965e185ad3ee3cc"}, "downloads": -1, "filename": "tokentranslator-0.0.1.1.dev2-py3-none-any.whl", "has_sig": false, "md5_digest": "16acca43a36a96d7585c87325aadfa89", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3946911, "upload_time": "2020-03-20T09:30:37", "upload_time_iso_8601": "2020-03-20T09:30:37.154243Z", "url": "https://files.pythonhosted.org/packages/96/0a/f615949cfd2b655f8b45d66c8b47ee75e2521aae4955e036c9122a33e67f/tokentranslator-0.0.1.1.dev2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d187f02de6c83ba5ed82a102b24bfaa3", "sha256": "b4b6f5312c267a0f21dc4513d915a55cb5d3c308a016f565d7c5f19bdf720e0b"}, "downloads": -1, "filename": "tokentranslator-0.0.1.1.dev2.tar.gz", "has_sig": false, "md5_digest": "d187f02de6c83ba5ed82a102b24bfaa3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3383860, "upload_time": "2020-03-20T09:30:41", "upload_time_iso_8601": "2020-03-20T09:30:41.381910Z", "url": "https://files.pythonhosted.org/packages/f6/65/b036dd46fe8181488903966dc7243c3bde81bf97ce8368648c66663a56b5/tokentranslator-0.0.1.1.dev2.tar.gz", "yanked": false}], "0.0.1.1.dev3": [{"comment_text": "", "digests": {"md5": "a6f05b93c2a9f2b86428a2e33f4db08a", "sha256": "c8d15fe77160651aa6e1a29def2cb7828425a135fc1f7bc9335138692cfb33dc"}, "downloads": -1, "filename": "tokentranslator-0.0.1.1.dev3-py3-none-any.whl", "has_sig": false, "md5_digest": "a6f05b93c2a9f2b86428a2e33f4db08a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3946920, "upload_time": "2020-03-20T10:26:46", "upload_time_iso_8601": "2020-03-20T10:26:46.186458Z", "url": "https://files.pythonhosted.org/packages/9e/88/5120a4aec13581ec6cef8448182b8a37ffcaf5f8e8e92de651aa10dd6478/tokentranslator-0.0.1.1.dev3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4c1ed98cefddf135f0bc6cb7135a874c", "sha256": "cd13ca5d53ff11243f53a072155e293ed4980be76df911d4bc144c6cf3cd354f"}, "downloads": -1, "filename": "tokentranslator-0.0.1.1.dev3.tar.gz", "has_sig": false, "md5_digest": "4c1ed98cefddf135f0bc6cb7135a874c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3383809, "upload_time": "2020-03-20T10:26:49", "upload_time_iso_8601": "2020-03-20T10:26:49.671840Z", "url": "https://files.pythonhosted.org/packages/ed/ed/6e4f4b616b0e41fa237f12879f88622edaf9a8459568dbcfb6f04be3f9d9/tokentranslator-0.0.1.1.dev3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a6f05b93c2a9f2b86428a2e33f4db08a", "sha256": "c8d15fe77160651aa6e1a29def2cb7828425a135fc1f7bc9335138692cfb33dc"}, "downloads": -1, "filename": "tokentranslator-0.0.1.1.dev3-py3-none-any.whl", "has_sig": false, "md5_digest": "a6f05b93c2a9f2b86428a2e33f4db08a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3946920, "upload_time": "2020-03-20T10:26:46", "upload_time_iso_8601": "2020-03-20T10:26:46.186458Z", "url": "https://files.pythonhosted.org/packages/9e/88/5120a4aec13581ec6cef8448182b8a37ffcaf5f8e8e92de651aa10dd6478/tokentranslator-0.0.1.1.dev3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4c1ed98cefddf135f0bc6cb7135a874c", "sha256": "cd13ca5d53ff11243f53a072155e293ed4980be76df911d4bc144c6cf3cd354f"}, "downloads": -1, "filename": "tokentranslator-0.0.1.1.dev3.tar.gz", "has_sig": false, "md5_digest": "4c1ed98cefddf135f0bc6cb7135a874c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3383809, "upload_time": "2020-03-20T10:26:49", "upload_time_iso_8601": "2020-03-20T10:26:49.671840Z", "url": "https://files.pythonhosted.org/packages/ed/ed/6e4f4b616b0e41fa237f12879f88622edaf9a8459568dbcfb6f04be3f9d9/tokentranslator-0.0.1.1.dev3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:51:23 2020"}