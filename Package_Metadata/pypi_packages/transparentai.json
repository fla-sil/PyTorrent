{"info": {"author": "Nathan LAUGA", "author_email": "nathan.lauga@protonmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# TransparentAI\n*A transparent AI from A to Z!*\n\n[![Documentation](https://readthedocs.org/projects/transparentai/badge/?version=latest)](http://transparentai.readthedocs.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/transparentai.svg)](https://badge.fury.io/py/transparentai)\n\nThis library is a toolbox so that you can create or inspect an AI on every step of the pipeline.\n\nThis is a new tool so if you found any bugs or other kind of problems please do not hesitate to report them on the\nissues GitHub page from the library here : https://github.com/Nathanlauga/transparentai/issues.\n\n![TransparentAI Pipeline](images/transparentai_pipeline.png)\n\nDocumentation is available here : [API Documentation](https://transparentai.readthedocs.io/en/latest/).\n\n## Installation\n\nYou can install it with [PyPI](https://pypi.org/project/transparentai/) :\n```\npip install transparentai\n```\n\nOr by cloning [GitHub repository](https://github.com/Nathanlauga/transparentai/)\n\n```\ngit clone https://github.com/Nathanlauga/transparentai.git\ncd transparentai\npython setup.py install\n```\n\n## Library tools\n\nSupported objects:\n\n| submodule   | object              | description                                                              |\n| ----------- | ------------------- | ------------------------------------------------------------------------ |\n| `datasets`  | StructuredDataset   | Can handle Structured dataset (tabular)                                  |\n| `models`    | ClassificationModel | Can handle classifier model with `predict` and `predict_proba` functions |\n| `models`    | RegressionModel     | Can handle regression model with a `predict` function                    |\n| `fairness`  | DatasetBiasMetric   | Can handle a dataset with a target column                                |\n| `fairness`  | ModelBiasMetric     | Can handle a dataset and predictions (Classification and regression)     |\n| `explainer` | ModelExplainer      | Can handle tree and linear model                                         |\n\n## How to use it\n\nTake a look on the [Getting started](https://transparentai.readthedocs.io/en/latest/getting-started.html) page of the documenation or you can search specific use cases \nin the [`notebooks/`](notebooks/) directory.\n\nHere is some example for the `StructuredDataset`, `DatasetBiasMetric`, `ClassificationModel` \nand `ModelExplainer`. But I take a look on the links above, there are a lot more to see!\n\n### StructuredDataset\n\nUsing the Adult dataset which is include in the library let's observe\nthe data with some graphics.\n\n```\nfrom transparentai.datasets import StructuredDataset, load_adult\nadult = load_adult()\n```\n\nCreate the StructuredDataset object :\n\n```\n# target is not mandatory it just split data in the graphics for each target value\ndataset = StructuredDataset(df=adult, target='income')\n```\n\nThen you can use differents plotting functions to have a better\nunderstanding of the dataset.\n\nTo start I recommend the following :\n\n```\ndataset.plot_dataset_overview() # Shows an overview of the data\ndataset.plot_missing_values() # Plots missing values\ndataset.plot_variables() # Plots each variable, one by one\ndataset.plot_numeric_var_relation() # Plots each numeric var pair\ndataset.plot_cat_and_num_variables() # Plots each numeric and categorical var pair\ndataset.plot_correlations() # Plots correlations\n```\n\nBut if you want to see a particular variable or variable combination\nyou can use the following line of codes :\n\n```\ndataset.plot_one_categorical_variable(var='income')\n```\n![](docs/images/income_variable_plot.png)\n\n```\ndataset.plot_two_numeric_variables(var1='education-num', var2='hours-per-week', nrows=10000)\n```\n\n![](docs/images/education-num_hours-per-week_variable_jointplot.png)\n\n```\ndataset.plot_one_cat_and_num_variables(var1='relationship', var2='age')\n```\n\n![](docs/images/relationship_age_variable_boxplot.png)\n\n```\ndataset.plot_one_cat_and_num_variables(var1='income', var2='age')\n```\n\n![](docs/images/income_age_variable_boxplot.png)\n\n\n### DatasetBiasMetric\n\nImport DatasetBiasMetric class.\n\n```\nfrom transparentai.fairness import DatasetBiasMetric\n```\n\nDefine privileged_groups\n\n```\nprivileged_groups = {\n    'marital-status': ['Married-civ-spouse','Married-AF-spouse'],\n    'race': ['White'],\n    'gender': ['Male']\n}\n```\n\nCreate the instance\n\n```\ndataset_bias = DatasetBiasMetric(dataset, privileged_groups, favorable_label='>50K')\n```\n\nRetrieve the bias metrics as a pandas DataFrame\n\n```\ndataset_bias.get_bias_metrics()\n \t\t                Disparate impact \tStatistical parity difference\nattr \t        index \t\t\nage category \t>50K \t0.257312 \t        -0.222479\nmarital-status \t>50K \t0.143299 \t        -0.382106\nrace \t        >50K \t0.600592 \t        -0.101445\ngender \t        >50K \t0.359655 \t        -0.194516\n```\n\nPlot one attribute bias.\n\n```\ndataset_bias.plot_bias(attr='gender')\n```\n\n![](docs/images/dataset_bias_metrics_plot.png)\n\n### ClassificationModel\n\n```\nfrom transparentai.models import ClassificationModel\n```\n\nYou need a trained classifier to use the ClassificationModel class.\nThen with compute_scores() function you will be able to access score.\n\n```\nmodel = ClassificationModel(model=clf)\nmodel.compute_scores(X=X_test, y=y_test, threshold=0.5)\n```\n\nShows classification scores :\n\n```\nmodel.plot_scores()\nOverall model performance\n\t    accuracy \tf1 \t        precision \trecall \t    roc_auc\nscore \t0.864313 \t0.860986 \t0.859721 \t0.864313 \t{0: 0.9104387547348203}\n```\n\n![](docs/images/classification_scores_plot.png)\n\n### ModelExplainer\n\nThis class is using [Shap](https://github.com/slundberg/shap/) library to get the feature importance.\n\n```\nfrom transparentai.explainer import ModelExplainer\nexplainer = ModelExplainer(model=clf, X=X_test, model_type='tree')\n```\n\nGet the global feature importance : \n\n```\n# I just take 100 rows for the example\nexplainer.explain_global(X_test.sample(100))\n{'age': 0.04400247162436626,\n 'workclass': 0.012615442187332302,\n 'fnlwgt': 0.011500706212146071,\n 'education': 0.014303318875909592,\n 'education-num': 0.06320364016403923,\n 'marital-status': 0.04457869696787154,\n 'occupation': 0.025353718692010623,\n 'relationship': 0.06538595560703962,\n 'race': 0.0030357403950878343,\n 'gender': 0.008150837046393543,\n 'capital-gain': 0.05191285416804516,\n 'capital-loss': 0.004889414454684037,\n 'hours-per-week': 0.03416860048567794,\n 'native-country': 0.003552990714228435,\n 'age category': 0.013148817808960036}\n```\n\nGlobal feature importance plot :\n\n```\nexplainer.plot_global_explain(top=10)\n```\n\n![](docs/images/global_feature_influence_plot.png)\n\nThe variable `feature_names` is a mapping dictionary so that categorical\nvariables that are encoded as number (e.g. 'gender': Male is 1 and Female 0)\ncan retrieve the original values.\n\n```\none_row = X.iloc[42]\nexplainer.explain_local(one_row, feature_classes=feature_names)\n{'age=36': 0.001512160581860371,\n 'workclass=Private': -0.001553052083354487,\n 'fnlwgt=465326': 0.014316324086275927,\n 'education=HS-grad': -0.008492161121589561,\n 'education-num=9': -0.06452835138642059,\n 'marital-status=Married-civ-spouse': 0.028260101147975548,\n 'occupation=Farming-fishing': -0.09721002961961403,\n 'relationship=Husband': 0.04156683952625826,\n 'race=White': -2.3502936087425042e-05,\n 'gender=Male': 0.002139375823244336,\n 'capital-gain=0': -0.044484324557015495,\n 'capital-loss=0': -0.007543452374593471,\n 'hours-per-week=40': -0.014963517277665232,\n 'native-country=United-States': -0.0014164286240020375,\n 'age category=Adult': 0.004620017927818481}\n```\n\nPlot local explanation :\n```\nexplainer.plot_local_explain(one_row, top=10, feature_classes=feature_names)\n```\n\n![](docs/images/local_feature_influence_plot.png)\n\n## Contributing\n\nSee the [contributing file](CONTRIBUTING.md).\n\n*PRs accepted.*\n\n## Credits and ressources\n\nSee the [ressources file](RESSOURCES.md) where I explain why I created this tool and mainly I quote my different inspirations and ressources.\n\n## Author\n\nThis work is led by [Nathan Lauga](https://github.com/nathanlauga/), french Data Scientist.\n\n## License\n\nThis project use a [MIT License](LICENSE).\n\n**Why ?**\n\nI believe that the code should be re-used for community projects and also inside private projects. \nAI transparency needs to be available for everyone even it's a private AI!", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Nathanlauga/transparentai", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "transparentai", "package_url": "https://pypi.org/project/transparentai/", "platform": "", "project_url": "https://pypi.org/project/transparentai/", "project_urls": {"Homepage": "https://github.com/Nathanlauga/transparentai"}, "release_url": "https://pypi.org/project/transparentai/0.1.3/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Python tool to create or inspect a transparent and ethical AI.", "version": "0.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TransparentAI</h1>\n<p><em>A transparent AI from A to Z!</em></p>\n<p><a href=\"http://transparentai.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e31d8b04bb0d566d5c83126fe1cc0ad5a6257bf2/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7472616e73706172656e7461692f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://badge.fury.io/py/transparentai\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/affaff53fa9487f25a375aeb61dcccc87ddec530/68747470733a2f2f62616467652e667572792e696f2f70792f7472616e73706172656e7461692e737667\"></a></p>\n<p>This library is a toolbox so that you can create or inspect an AI on every step of the pipeline.</p>\n<p>This is a new tool so if you found any bugs or other kind of problems please do not hesitate to report them on the\nissues GitHub page from the library here : <a href=\"https://github.com/Nathanlauga/transparentai/issues\" rel=\"nofollow\">https://github.com/Nathanlauga/transparentai/issues</a>.</p>\n<p><img alt=\"TransparentAI Pipeline\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0ff40f421d9de3dae7128ecddf0890e995eeb384/696d616765732f7472616e73706172656e7461695f706970656c696e652e706e67\"></p>\n<p>Documentation is available here : <a href=\"https://transparentai.readthedocs.io/en/latest/\" rel=\"nofollow\">API Documentation</a>.</p>\n<h2>Installation</h2>\n<p>You can install it with <a href=\"https://pypi.org/project/transparentai/\" rel=\"nofollow\">PyPI</a> :</p>\n<pre><code>pip install transparentai\n</code></pre>\n<p>Or by cloning <a href=\"https://github.com/Nathanlauga/transparentai/\" rel=\"nofollow\">GitHub repository</a></p>\n<pre><code>git clone https://github.com/Nathanlauga/transparentai.git\ncd transparentai\npython setup.py install\n</code></pre>\n<h2>Library tools</h2>\n<p>Supported objects:</p>\n<table>\n<thead>\n<tr>\n<th>submodule</th>\n<th>object</th>\n<th>description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>datasets</code></td>\n<td>StructuredDataset</td>\n<td>Can handle Structured dataset (tabular)</td>\n</tr>\n<tr>\n<td><code>models</code></td>\n<td>ClassificationModel</td>\n<td>Can handle classifier model with <code>predict</code> and <code>predict_proba</code> functions</td>\n</tr>\n<tr>\n<td><code>models</code></td>\n<td>RegressionModel</td>\n<td>Can handle regression model with a <code>predict</code> function</td>\n</tr>\n<tr>\n<td><code>fairness</code></td>\n<td>DatasetBiasMetric</td>\n<td>Can handle a dataset with a target column</td>\n</tr>\n<tr>\n<td><code>fairness</code></td>\n<td>ModelBiasMetric</td>\n<td>Can handle a dataset and predictions (Classification and regression)</td>\n</tr>\n<tr>\n<td><code>explainer</code></td>\n<td>ModelExplainer</td>\n<td>Can handle tree and linear model</td>\n</tr></tbody></table>\n<h2>How to use it</h2>\n<p>Take a look on the <a href=\"https://transparentai.readthedocs.io/en/latest/getting-started.html\" rel=\"nofollow\">Getting started</a> page of the documenation or you can search specific use cases\nin the <a href=\"notebooks/\" rel=\"nofollow\"><code>notebooks/</code></a> directory.</p>\n<p>Here is some example for the <code>StructuredDataset</code>, <code>DatasetBiasMetric</code>, <code>ClassificationModel</code>\nand <code>ModelExplainer</code>. But I take a look on the links above, there are a lot more to see!</p>\n<h3>StructuredDataset</h3>\n<p>Using the Adult dataset which is include in the library let's observe\nthe data with some graphics.</p>\n<pre><code>from transparentai.datasets import StructuredDataset, load_adult\nadult = load_adult()\n</code></pre>\n<p>Create the StructuredDataset object :</p>\n<pre><code># target is not mandatory it just split data in the graphics for each target value\ndataset = StructuredDataset(df=adult, target='income')\n</code></pre>\n<p>Then you can use differents plotting functions to have a better\nunderstanding of the dataset.</p>\n<p>To start I recommend the following :</p>\n<pre><code>dataset.plot_dataset_overview() # Shows an overview of the data\ndataset.plot_missing_values() # Plots missing values\ndataset.plot_variables() # Plots each variable, one by one\ndataset.plot_numeric_var_relation() # Plots each numeric var pair\ndataset.plot_cat_and_num_variables() # Plots each numeric and categorical var pair\ndataset.plot_correlations() # Plots correlations\n</code></pre>\n<p>But if you want to see a particular variable or variable combination\nyou can use the following line of codes :</p>\n<pre><code>dataset.plot_one_categorical_variable(var='income')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c3b47eb2bfcfdcc2eda6bfce00510251b811bd56/646f63732f696d616765732f696e636f6d655f7661726961626c655f706c6f742e706e67\"></p>\n<pre><code>dataset.plot_two_numeric_variables(var1='education-num', var2='hours-per-week', nrows=10000)\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2ded217757c7365cc9b99ddd4488b45674902864/646f63732f696d616765732f656475636174696f6e2d6e756d5f686f7572732d7065722d7765656b5f7661726961626c655f6a6f696e74706c6f742e706e67\"></p>\n<pre><code>dataset.plot_one_cat_and_num_variables(var1='relationship', var2='age')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/76b2e18d6ef7ec444f5895d8c598248a33157674/646f63732f696d616765732f72656c6174696f6e736869705f6167655f7661726961626c655f626f78706c6f742e706e67\"></p>\n<pre><code>dataset.plot_one_cat_and_num_variables(var1='income', var2='age')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0f73d0ceb68d9347049bfd90d2a0cffffa3dae59/646f63732f696d616765732f696e636f6d655f6167655f7661726961626c655f626f78706c6f742e706e67\"></p>\n<h3>DatasetBiasMetric</h3>\n<p>Import DatasetBiasMetric class.</p>\n<pre><code>from transparentai.fairness import DatasetBiasMetric\n</code></pre>\n<p>Define privileged_groups</p>\n<pre><code>privileged_groups = {\n    'marital-status': ['Married-civ-spouse','Married-AF-spouse'],\n    'race': ['White'],\n    'gender': ['Male']\n}\n</code></pre>\n<p>Create the instance</p>\n<pre><code>dataset_bias = DatasetBiasMetric(dataset, privileged_groups, favorable_label='&gt;50K')\n</code></pre>\n<p>Retrieve the bias metrics as a pandas DataFrame</p>\n<pre><code>dataset_bias.get_bias_metrics()\n \t\t                Disparate impact \tStatistical parity difference\nattr \t        index \t\t\nage category \t&gt;50K \t0.257312 \t        -0.222479\nmarital-status \t&gt;50K \t0.143299 \t        -0.382106\nrace \t        &gt;50K \t0.600592 \t        -0.101445\ngender \t        &gt;50K \t0.359655 \t        -0.194516\n</code></pre>\n<p>Plot one attribute bias.</p>\n<pre><code>dataset_bias.plot_bias(attr='gender')\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ea7945df57454a1359817176f98fa1b1cc851bed/646f63732f696d616765732f646174617365745f626961735f6d6574726963735f706c6f742e706e67\"></p>\n<h3>ClassificationModel</h3>\n<pre><code>from transparentai.models import ClassificationModel\n</code></pre>\n<p>You need a trained classifier to use the ClassificationModel class.\nThen with compute_scores() function you will be able to access score.</p>\n<pre><code>model = ClassificationModel(model=clf)\nmodel.compute_scores(X=X_test, y=y_test, threshold=0.5)\n</code></pre>\n<p>Shows classification scores :</p>\n<pre><code>model.plot_scores()\nOverall model performance\n\t    accuracy \tf1 \t        precision \trecall \t    roc_auc\nscore \t0.864313 \t0.860986 \t0.859721 \t0.864313 \t{0: 0.9104387547348203}\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e7dec1c4870affefbd96fcc20b3d3aa149bc0d5f/646f63732f696d616765732f636c617373696669636174696f6e5f73636f7265735f706c6f742e706e67\"></p>\n<h3>ModelExplainer</h3>\n<p>This class is using <a href=\"https://github.com/slundberg/shap/\" rel=\"nofollow\">Shap</a> library to get the feature importance.</p>\n<pre><code>from transparentai.explainer import ModelExplainer\nexplainer = ModelExplainer(model=clf, X=X_test, model_type='tree')\n</code></pre>\n<p>Get the global feature importance :</p>\n<pre><code># I just take 100 rows for the example\nexplainer.explain_global(X_test.sample(100))\n{'age': 0.04400247162436626,\n 'workclass': 0.012615442187332302,\n 'fnlwgt': 0.011500706212146071,\n 'education': 0.014303318875909592,\n 'education-num': 0.06320364016403923,\n 'marital-status': 0.04457869696787154,\n 'occupation': 0.025353718692010623,\n 'relationship': 0.06538595560703962,\n 'race': 0.0030357403950878343,\n 'gender': 0.008150837046393543,\n 'capital-gain': 0.05191285416804516,\n 'capital-loss': 0.004889414454684037,\n 'hours-per-week': 0.03416860048567794,\n 'native-country': 0.003552990714228435,\n 'age category': 0.013148817808960036}\n</code></pre>\n<p>Global feature importance plot :</p>\n<pre><code>explainer.plot_global_explain(top=10)\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eb13142f5606413a37a91efeffe2996b92260156/646f63732f696d616765732f676c6f62616c5f666561747572655f696e666c75656e63655f706c6f742e706e67\"></p>\n<p>The variable <code>feature_names</code> is a mapping dictionary so that categorical\nvariables that are encoded as number (e.g. 'gender': Male is 1 and Female 0)\ncan retrieve the original values.</p>\n<pre><code>one_row = X.iloc[42]\nexplainer.explain_local(one_row, feature_classes=feature_names)\n{'age=36': 0.001512160581860371,\n 'workclass=Private': -0.001553052083354487,\n 'fnlwgt=465326': 0.014316324086275927,\n 'education=HS-grad': -0.008492161121589561,\n 'education-num=9': -0.06452835138642059,\n 'marital-status=Married-civ-spouse': 0.028260101147975548,\n 'occupation=Farming-fishing': -0.09721002961961403,\n 'relationship=Husband': 0.04156683952625826,\n 'race=White': -2.3502936087425042e-05,\n 'gender=Male': 0.002139375823244336,\n 'capital-gain=0': -0.044484324557015495,\n 'capital-loss=0': -0.007543452374593471,\n 'hours-per-week=40': -0.014963517277665232,\n 'native-country=United-States': -0.0014164286240020375,\n 'age category=Adult': 0.004620017927818481}\n</code></pre>\n<p>Plot local explanation :</p>\n<pre><code>explainer.plot_local_explain(one_row, top=10, feature_classes=feature_names)\n</code></pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f229edd5698e613a8d6f461e5b8f2dd6f0643c73/646f63732f696d616765732f6c6f63616c5f666561747572655f696e666c75656e63655f706c6f742e706e67\"></p>\n<h2>Contributing</h2>\n<p>See the <a href=\"CONTRIBUTING.md\" rel=\"nofollow\">contributing file</a>.</p>\n<p><em>PRs accepted.</em></p>\n<h2>Credits and ressources</h2>\n<p>See the <a href=\"RESSOURCES.md\" rel=\"nofollow\">ressources file</a> where I explain why I created this tool and mainly I quote my different inspirations and ressources.</p>\n<h2>Author</h2>\n<p>This work is led by <a href=\"https://github.com/nathanlauga/\" rel=\"nofollow\">Nathan Lauga</a>, french Data Scientist.</p>\n<h2>License</h2>\n<p>This project use a <a href=\"LICENSE\" rel=\"nofollow\">MIT License</a>.</p>\n<p><strong>Why ?</strong></p>\n<p>I believe that the code should be re-used for community projects and also inside private projects.\nAI transparency needs to be available for everyone even it's a private AI!</p>\n\n          </div>"}, "last_serial": 6742733, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "08320df739c3d21ddb36d392b1d5c25f", "sha256": "0b69430e21906d730b6475ac3bbfa4440d8d7c8bf264459fda44726e950216c9"}, "downloads": -1, "filename": "transparentai-0.1.1.tar.gz", "has_sig": false, "md5_digest": "08320df739c3d21ddb36d392b1d5c25f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 679179, "upload_time": "2020-03-03T17:41:33", "upload_time_iso_8601": "2020-03-03T17:41:33.554963Z", "url": "https://files.pythonhosted.org/packages/86/3a/82b9694defea3c2b1b5364b3715f343ab189fa6376c7441a19b3802f7a72/transparentai-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "86430ee28627104aa2ff5979ae5b3406", "sha256": "a7e588ebd9049f2bf50d7d1a224fd2946b6dc1f71f15957c5e9f068ac86e9262"}, "downloads": -1, "filename": "transparentai-0.1.2.tar.gz", "has_sig": false, "md5_digest": "86430ee28627104aa2ff5979ae5b3406", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 679069, "upload_time": "2020-03-03T17:49:09", "upload_time_iso_8601": "2020-03-03T17:49:09.152683Z", "url": "https://files.pythonhosted.org/packages/8a/5c/071578ec59fd8c89fe123590bdd8b98531664cd5668d3f364def8c74f8b8/transparentai-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "c283ddd7c6f489833e32a68a41b41374", "sha256": "43c5b22322b693dfcfdc7af120bd53ad8fe37241da898b63248bf15b28e50d7f"}, "downloads": -1, "filename": "transparentai-0.1.3.tar.gz", "has_sig": false, "md5_digest": "c283ddd7c6f489833e32a68a41b41374", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 679274, "upload_time": "2020-03-03T18:50:50", "upload_time_iso_8601": "2020-03-03T18:50:50.159964Z", "url": "https://files.pythonhosted.org/packages/f7/7a/8f47519154e8acdbfc01893dcadd861b0a2d7bdf102c7ee105a6a4c9ba04/transparentai-0.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c283ddd7c6f489833e32a68a41b41374", "sha256": "43c5b22322b693dfcfdc7af120bd53ad8fe37241da898b63248bf15b28e50d7f"}, "downloads": -1, "filename": "transparentai-0.1.3.tar.gz", "has_sig": false, "md5_digest": "c283ddd7c6f489833e32a68a41b41374", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 679274, "upload_time": "2020-03-03T18:50:50", "upload_time_iso_8601": "2020-03-03T18:50:50.159964Z", "url": "https://files.pythonhosted.org/packages/f7/7a/8f47519154e8acdbfc01893dcadd861b0a2d7bdf102c7ee105a6a4c9ba04/transparentai-0.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:47:59 2020"}