{"info": {"author": "Neha Gupta", "author_email": "neha.r.gupta@duke.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "\n<!-- Comment hi.  -->\n# DAME (Dynamic Almost Matching Exactly) and FLAME (Fast Large-scale Almost Matching Exactly)\n--------------------------------------------------\n\n## Overview of the DAME and FLAME algorithms\n\nThe **FLAME** algorithm provides a fast and large-scale matching approach to causal inference. **FLAME** quickly creates matches that include as many covariates as possible by iteratively dropping covariates that are successively less useful for predicting outcomes based on matching quality. \n\nThe **DAME** algorithm provides high-quality interpretable matches in causal inference. **DAME** creates matches of units that include as many covariates as possible by creating a heirarchy of covariate combinations on which to match, in the process solving an optimization problem for each unit in order to construct optimal matches. \n\nBoth **DAME** and **FLAME** are available for categorical covariates only. \n\nA **Hybrid FLAME-DAME** algorithm will use FLAME to quickly remove less relevant features, and then switch to DAME for its high-quality interpretable matches. This is recommended for datasets with many features. It scales well, without noticable loss in the quality of matches. \n\nBoth algorithms work well for data that fits in memory, and have thus far been tested on data sized up to 30,000 rows and 15 columns, which takes roughly 30 seconds on `FLAME` and roughly 45 seconds on `DAME`. An implementation for extremely large data sets will be provided at a later time. This implementation does include a variety of options for missing data handling.\n\nFor more details about these algorithms, please refer to their papers: [FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference](https://arxiv.org/abs/1707.06315) and [Interpretable Almost-Exact Matching for Causal Inference](https://arxiv.org/abs/1806.06802)\n\nPlease reach out to let our team know if you're using this, or if you have any questions! Contact Neha Gupta at neha.r.gupta \"at\" duke \"dot\" edu \n\n## Installation\n\nFirst, download from PyPi via\n$ pip install dame-flame\n\n``` Python\n\n# import package\nimport dame_flame\n\n# Run DAME\nx = dame_flame.DAME_FLAME.DAME(input_data=r\"dame_flame/data/sample.csv\",treatment_column_name='treated', outcome_column_name='outcome', adaptive_weights='ridge', holdout_data=1.0)\n```\n\n## Required data format\n\nThe `DAME-FLAME` package requires input data to have specific format. The input data can be either a file, or a **Python Pandas Data Frame**. However, all covariates in the input data should be categorical covariates, represented as an *integer* data type. If there are continuous covariates, please consider regrouping. In addition to input data columns, the input data must contain (1) A column indicating the outcome variable as an *integer* or *float* data type, and (2) A column specifying whether a unit is treated or control (treated = 1, control = 0) as an *integer* data type. There are no requirements for input data column names or order of columns. Below is an example of input data with n units and m covariates.\n\n\n*Column-name / unit-id*  | x_1 | x_2 |...| x_m | outcome | treated\n--- | --- | --- | --- | --- | --- | --- |\n**1** | 2 | 3 | ... | 4 | 9 | 0\n**2** | 1 | 3 | ... | 3 | 5.5 | 1\n**3** | 1 | 4 | ... | 5 | -1 | 0\n... | ... | ... | ... | ... | ... | ...\n**n** | 0 | 5 | ... | 0 | 1 | 1\n*Data Type*| *integer* | *integer* | *integer* | *integer* |  *numeric* | *0 or 1* |\n\nThe holdout training set, if provided, should also follow the same format.\n\n\n## Other requirements\n\n1.  `DAME-FLAME` requires installation of python, specifically with at least python 3.* version. If your computer system does not have python 3.*, install from [here](https://www.python.org/downloads/).\n\n2. Dependencies on the following packages: Pandas, Scikit learn, Numpy. If your python version does not have these packages, install from [here](https://packaging.python.org/tutorials/installing-packages/)\n\n## Example\n\nWe run the DAME function with the following basic command. In this example, we provide only the basic inputs: (1) input data as a dataframe or file, (2) the name of the outcome column, and (3) the name of the treatment column.\n\nIn this example, because of the toy sized small dataset, we set the holdout dataset equal to the complete input dataset.\n```Python\nimport pandas as pd\nimport dame_flame\n\ndf = pd.read_csv(\"dame_flame/data/sample.csv\")\nresult = dame_flame.DAME_FLAME.DAME(input_data=df, treatment_column_name=\"treated\", outcome_column_name=\"outcome\", holdout_data=1.0)\nprint(result[0])\n#>    x1   x2   x3   x4\n#> 0   1   1    1    *\n#> 1   0   1    1    *\n#> 2   1   0    *    *\n#> 3   1   0    *    *\n```\nresult is a list, where the first element in the list is of type **Data Frame**. The dataframe contains all of the units that were matched, and the covariates and corresponding values, that it was matched on. The covariates that each unit was not matched on is denoted with a \" * \" character. The list 'result' will have additional values based on additional optional parameters, detailed in additional documentation below. \n\nTo find the main matched group of a particular unit after DAME has been run, use the function *mmg_of_unit*\n\n```Python\nmmg = dame_flame.DAME_FLAME.mmg_of_unit(return_df=result[0], unit_id=0, input_data=df)\nprint(mmg)\n\n#>    x1   x2    x3\n#> 0   0    1    1\n#> 1   0    1    1\n```\n\nTo find the treatment effect of a unit, use the function *te_of_unit*\n\n\n```Python\nte = dame_flame.DAME_FLAME.te_of_unit(return_df=result[0], unit_id=2, input_data=df, treatment_column_name='treated', outcome_column_name='outcome')\nprint(te)\n#> -1.0\n```\n\n\n## DAME and FLAME Parameters and Defaults\n\n```Python\nDAME(input_data, treatment_column_name='treated', weight_array=False,\n     outcome_column_name='outcome', adaptive_weights='ridge', alpha=0.1, \n     holdout_data=False, repeats=True, verbose=2, want_pe=False, \n     early_stop_iterations=False, stop_unmatched_c=False, \n     early_stop_un_c_frac=0.1, stop_unmatched_t=False, \n     early_stop_un_t_frac=0.1, early_stop_pe=False, \n     early_stop_pe_frac=0.01, want_bf=False, early_stop_bf=False, \n     early_stop_bf_frac=0.01, missing_indicator=numpy.nan, \n     missing_data_replace=0, missing_holdout_replace=0, \n     missing_holdout_imputations=10, missing_data_imputations=0)\n\nFLAME(input_data=False, treatment_column_name='treated',\n      outcome_column_name='outcome', adaptive_weights='ridge', alpha=0.1, \n      holdout_data=False, repeats=True, verbose=2, want_pe=False, \n      early_stop_iterations=False, stop_unmatched_c=False, \n      early_stop_un_c_frac=0.1, stop_unmatched_t=False, \n      early_stop_un_t_frac=0.1, early_stop_pe=False, \n      early_stop_pe_frac=0.01, want_bf=False, early_stop_bf=False, \n      early_stop_bf_frac=0.01, missing_indicator=numpy.nan, \n      missing_data_replace=0, missing_holdout_replace=0, \n      missing_holdout_imputations=10, missing_data_imputations=1, \n      pre_dame=False, C=0.1)\n```\n\n### Key parameters\n\n**input_data**: file, DataFrame, required\nThis is the data being matched. This is henceforth referred to as the matching data. \n\n**treatment_column_name**: string, optional (default=\"treated\")  \nThis is the name of the column with a binary indicator for whether a row is a treatment or control unit.\n\n**outcome_column_name**: string, optional (default=\"outcome\")  \nThis is the name of the column with the outcome variable of each unit. \n\n**adaptive_weights**: bool, \"ridge\", \"decision tree\", \"ridgeCV\", optional (default=\"ridge\")  \nThe method used to decide what covariate set should be dropped next.\n\n**weight_array**: array, optional  \nIf adaptive_weights = False, these are the weights to the covariates in **input_data**, for the non-adaptive version of DAME. Must sum to 1. In this case, we do not use machine learning for the weights, they are manually entered as **weight_array**.\n\n**alpha**: float, optional (default=0.1)  \nIf adaptive_weights is set to ridge, this is the alpha for ridge regression.\n\n**holdout_data**: file, DataFrame, float between 0 and 1, optional (Default = 0.1)\nIf doing an adaptive_weights version of DAME, this is used to decide what covariates to drop. The default is to use 10% of the **input_data** dataset. Users can specify a percentage of the matching data set to use as the holdout set, or use a different file. If using a different file, that file needs to have all of the same column labels, including treatment and outcome columns.\n\n**repeats**: Bool, optional (default=False)  \nWhether or not units for whom a main matched has been found can be used again, and placed in an auxiliary matched group. \n\n\n**verbose**: int 0,1,2,3 (default=2)  \nStyle of printout while algorithm runs.\nIf 0, no output \nIf 1, provides iteration number \nIf 2, provides iteration number and additional information on the progress of the matching at every 10th iteration\nIf 3, provides iteration number and additional information on the progress of the matching at every iteration\n\n\n**want_pe**: bool, optional (default=False)  \nIf true, the output of the algorithm will include the predictive error of the covariate sets used for matching in each iteration.\n\n\n**want_bf**: bool, optional (default=False)  \nIf true, the output will include the balancing factor for each iteration.\n\n#### FLAME-specific parameters\n\n**pre_dame**: bool, integer, optional (default=False)  \nThis will allow a user to run the Hybrid-FLAME-DAME algorithm. If an integer n is provided, then after n iterations of FLAME, the algorithm will switch to DAME. \n\n\n**C**: float, optional (default=0.1)\nThis is used in deciding the best covariate match during iterations of FLAME. Specifically, its the tradeoff parameter between balancing factor and predictive error. \n\n\n### Parameters related to missing data handling\n\nA variety of built-in options for missing data handling functionality is available to users.\n\nThe fastest option is to exclude missing values for each unit in the matching dataset, and drop missing units entirely from the holdout dataset.\nThe units with missing values would still be placed in a group, but the covariates for which they\nhave missing data wouldn't be used to find their group. Holdout missing data would\nbe dropped.  These are parameters missing_holdout_replace=1, missing_data_replace=2. \n\nIf missing data is detected, but the user has not specified a handling technique, then\n(does it quit?) \n\n**missing_indicator**: character, integer, numpy.nan, optional (default=numpy.nan)  \nThis is the indicator for missing data in the dataset. \n\n**missing_holdout_replace**: int 0,1,2, optional (default=0)  \nIf 0, assume no missing holdout data and proceed. \nIf 1, the algorithm excludes units with missing values from the holdout dataset. \nIf 2, do MICE on holdout dataset. If this option is selected, it will be done for a number of iterations equal to **missing_holdout_imputations**.\n\n**missing_data_replace**: int 0,1,2,3, optional, (default=0)  \nIf 0, assume no missing data in matching data and proceed. \nIf 1, the algorithm does not match on units that have missing values. \nIf 2, prevent all **missing_indicator** values from being matched on. \nIf 3, do MICE on matching dataset. This is not recommended. If this option is selected, it will be done for a number of iterations equal to **missing_data_imputations**.\n\n**missing_holdout_imputations**: int, optional (default=10)  \nIf missing_holdout_replace=2, the number of imputations.\n\n**missing_data_imputations**: int, optional (default=1)  \nIf missing_data_replace=3, the number of imputations. \n\n\n###  Parameters related to early stopping criteria\n\n\n**early_stop_iterations**: int, optional  (default=0)  \nIf provided, a number of iterations after which to hard stop the algorithm.\n\n**stop_unmatched_c**: bool, optional (default=False)  \nIf True, then the algorithm terminates when there are no more control units to match. \n\n**stop_unmatched_t**: bool, optional (default=True)  \nIf True, then the algorithm terminates when there are no more treatment units to match. \n\n**early_stop_un_c_frac**: float from 0.0 to 1.0, optional (default=0.1)  \nThis provides a fraction of unmatched control units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 control units, the algorithm will stop when 10 control units are unmatched and 90 are matched (or earlier, depending on other stopping conditions).\n\n**early_stop_un_t_frac**: float from 0.0 to 1.0, optional (default=0.1)\nThis provides a fraction of unmatched treatment units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 treatment units, the algorithm will stop when 10 control units are unmatched and 90 are matched  (or earlier, depending on other stopping conditions).\n\n**early_stop_pe**: bool, optional (default=False)  \nIf this is true, then if the covariate set chosen for matching has a predictive error higher than the parameter **early_stop_pe_frac**, the algorithm will stop.\n\n**early_stop_pe_frac**: float, optional (default=0.01)  \nIf **early_stop_pe** is true, then if the covariate set chosen for matching has a predictive error higher than this value, the algorithm will stop.\n\n**early_stop_bf**: bool, optional (default=False)  \nIf this is true, then if the covariate set chosen for matching has a balancing factor lower than early_stop_bf_frac, then the algorithm will stop.\n\n**early_stop_bf_frac**: float, optional (default=0.01)  \nIf early_stop_bf is true, then if the covariate set chosen for matching has a balancing factor lower than this value, then the algorithm will stop.\n\n## Additional Functions Available, and their parameters and defaults\n\nTo provide users with additional options in analyzing the output of DAME and FLAME, we provide a set of functions that can be used after running the match.\n\n```Python\n# The main matched group of a unit\nmmg_of_unit(return_df, unit_id, input_data, output_style=1)\n\n# The treatment effect of a unit\nte_of_unit(return_df, unit_id, input_data, treatment_column_name, outcome_column_name)\n\n# Both the main matched group and the treatment effect of a unit \nmmg_and_te_of_unit(return_df, unit_id, input_data, treatment_column_name, outcome_column_name, return_vals=0)\n```\n\n### Parameters \n\n**return_df**: Python Pandas Dataframe, required (no default).\nThis is the dataframe containing all of the matches, or the first and main output from `FLAME` or `DAME`\n\n**unit_id**: int, required (no default).\nThis is the unit for which the main matched group or treatment effect is being calculated\n\n**output_style**: int, optional (default=1):\nIn the mmg_of_unit function, if this is 1 then the main matched group will only display covariates that were used in matching for each unit. The output dataframe will have a ' * ' character in the column for each unit that was not matched on that covariate.\nIf this value is 2, then the dataframe will contain complete values and no ' * ' characters.\n\n**return_vals**: int, optional (default=0):\nIn mmg_and_te_of_unit, if this is 1 then the values will print in a pretty way rather than outputting. \n\n## Additional Technical Notes\n\n### Missing Data Handling\n\nFor details on the MICE algorithm, see : [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/)\nThe underlying MICE implementation is done using scikit learn's experimental IterativeImpute package, \nand relies on DecisionTreeRegressions in the imputation process, to ensure that the data generated\nis fit for unordered categorical data. In addition to this, users are welcome to pre-process their datsets with other data handling techniques\nprior to using MICE. It is not recommended to use MICE on the matching dataset, as this would be very slow.  \n\nOne option is to set the parameter missing_data_replace=2, where units that have missing values are still matched on, but the covariates they are missing are not used in computing their match. \nIn this option, the underlying algorithm works by replacing each missing value with a unique value, so that in the matching procedure, those covariates simply don't have a match because their\nvalues are not equl to any other values.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/almost-matching-exactly/DAME-Python-Package", "keywords": "Causal Inference Matching Covariates FLAME DAME", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dame-flame", "package_url": "https://pypi.org/project/dame-flame/", "platform": "", "project_url": "https://pypi.org/project/dame-flame/", "project_urls": {"Homepage": "https://github.com/almost-matching-exactly/DAME-Python-Package"}, "release_url": "https://pypi.org/project/dame-flame/0.2/", "requires_dist": ["scikit-learn (>=0.21.3)", "scipy (>=0.14)", "pandas (>=0.11.0)", "numpy (>=1.6.1)"], "requires_python": ">=3.6", "summary": "Causal Inference Covariate Matching", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DAME (Dynamic Almost Matching Exactly) and FLAME (Fast Large-scale Almost Matching Exactly)</h1>\n<hr>\n<h2>Overview of the DAME and FLAME algorithms</h2>\n<p>The <strong>FLAME</strong> algorithm provides a fast and large-scale matching approach to causal inference. <strong>FLAME</strong> quickly creates matches that include as many covariates as possible by iteratively dropping covariates that are successively less useful for predicting outcomes based on matching quality.</p>\n<p>The <strong>DAME</strong> algorithm provides high-quality interpretable matches in causal inference. <strong>DAME</strong> creates matches of units that include as many covariates as possible by creating a heirarchy of covariate combinations on which to match, in the process solving an optimization problem for each unit in order to construct optimal matches.</p>\n<p>Both <strong>DAME</strong> and <strong>FLAME</strong> are available for categorical covariates only.</p>\n<p>A <strong>Hybrid FLAME-DAME</strong> algorithm will use FLAME to quickly remove less relevant features, and then switch to DAME for its high-quality interpretable matches. This is recommended for datasets with many features. It scales well, without noticable loss in the quality of matches.</p>\n<p>Both algorithms work well for data that fits in memory, and have thus far been tested on data sized up to 30,000 rows and 15 columns, which takes roughly 30 seconds on <code>FLAME</code> and roughly 45 seconds on <code>DAME</code>. An implementation for extremely large data sets will be provided at a later time. This implementation does include a variety of options for missing data handling.</p>\n<p>For more details about these algorithms, please refer to their papers: <a href=\"https://arxiv.org/abs/1707.06315\" rel=\"nofollow\">FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference</a> and <a href=\"https://arxiv.org/abs/1806.06802\" rel=\"nofollow\">Interpretable Almost-Exact Matching for Causal Inference</a></p>\n<p>Please reach out to let our team know if you're using this, or if you have any questions! Contact Neha Gupta at neha.r.gupta \"at\" duke \"dot\" edu</p>\n<h2>Installation</h2>\n<p>First, download from PyPi via\n$ pip install dame-flame</p>\n<pre><span class=\"c1\"># import package</span>\n<span class=\"kn\">import</span> <span class=\"nn\">dame_flame</span>\n\n<span class=\"c1\"># Run DAME</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">dame_flame</span><span class=\"o\">.</span><span class=\"n\">DAME_FLAME</span><span class=\"o\">.</span><span class=\"n\">DAME</span><span class=\"p\">(</span><span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"sa\">r</span><span class=\"s2\">\"dame_flame/data/sample.csv\"</span><span class=\"p\">,</span><span class=\"n\">treatment_column_name</span><span class=\"o\">=</span><span class=\"s1\">'treated'</span><span class=\"p\">,</span> <span class=\"n\">outcome_column_name</span><span class=\"o\">=</span><span class=\"s1\">'outcome'</span><span class=\"p\">,</span> <span class=\"n\">adaptive_weights</span><span class=\"o\">=</span><span class=\"s1\">'ridge'</span><span class=\"p\">,</span> <span class=\"n\">holdout_data</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>\n</pre>\n<h2>Required data format</h2>\n<p>The <code>DAME-FLAME</code> package requires input data to have specific format. The input data can be either a file, or a <strong>Python Pandas Data Frame</strong>. However, all covariates in the input data should be categorical covariates, represented as an <em>integer</em> data type. If there are continuous covariates, please consider regrouping. In addition to input data columns, the input data must contain (1) A column indicating the outcome variable as an <em>integer</em> or <em>float</em> data type, and (2) A column specifying whether a unit is treated or control (treated = 1, control = 0) as an <em>integer</em> data type. There are no requirements for input data column names or order of columns. Below is an example of input data with n units and m covariates.</p>\n<table>\n<thead>\n<tr>\n<th><em>Column-name / unit-id</em></th>\n<th>x_1</th>\n<th>x_2</th>\n<th>...</th>\n<th>x_m</th>\n<th>outcome</th>\n<th>treated</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>1</strong></td>\n<td>2</td>\n<td>3</td>\n<td>...</td>\n<td>4</td>\n<td>9</td>\n<td>0</td>\n</tr>\n<tr>\n<td><strong>2</strong></td>\n<td>1</td>\n<td>3</td>\n<td>...</td>\n<td>3</td>\n<td>5.5</td>\n<td>1</td>\n</tr>\n<tr>\n<td><strong>3</strong></td>\n<td>1</td>\n<td>4</td>\n<td>...</td>\n<td>5</td>\n<td>-1</td>\n<td>0</td>\n</tr>\n<tr>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n</tr>\n<tr>\n<td><strong>n</strong></td>\n<td>0</td>\n<td>5</td>\n<td>...</td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n</tr>\n<tr>\n<td><em>Data Type</em></td>\n<td><em>integer</em></td>\n<td><em>integer</em></td>\n<td><em>integer</em></td>\n<td><em>integer</em></td>\n<td><em>numeric</em></td>\n<td><em>0 or 1</em></td>\n</tr></tbody></table>\n<p>The holdout training set, if provided, should also follow the same format.</p>\n<h2>Other requirements</h2>\n<ol>\n<li>\n<p><code>DAME-FLAME</code> requires installation of python, specifically with at least python 3.* version. If your computer system does not have python 3.*, install from <a href=\"https://www.python.org/downloads/\" rel=\"nofollow\">here</a>.</p>\n</li>\n<li>\n<p>Dependencies on the following packages: Pandas, Scikit learn, Numpy. If your python version does not have these packages, install from <a href=\"https://packaging.python.org/tutorials/installing-packages/\" rel=\"nofollow\">here</a></p>\n</li>\n</ol>\n<h2>Example</h2>\n<p>We run the DAME function with the following basic command. In this example, we provide only the basic inputs: (1) input data as a dataframe or file, (2) the name of the outcome column, and (3) the name of the treatment column.</p>\n<p>In this example, because of the toy sized small dataset, we set the holdout dataset equal to the complete input dataset.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">dame_flame</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s2\">\"dame_flame/data/sample.csv\"</span><span class=\"p\">)</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">dame_flame</span><span class=\"o\">.</span><span class=\"n\">DAME_FLAME</span><span class=\"o\">.</span><span class=\"n\">DAME</span><span class=\"p\">(</span><span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">treatment_column_name</span><span class=\"o\">=</span><span class=\"s2\">\"treated\"</span><span class=\"p\">,</span> <span class=\"n\">outcome_column_name</span><span class=\"o\">=</span><span class=\"s2\">\"outcome\"</span><span class=\"p\">,</span> <span class=\"n\">holdout_data</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"c1\">#&gt;    x1   x2   x3   x4</span>\n<span class=\"c1\">#&gt; 0   1   1    1    *</span>\n<span class=\"c1\">#&gt; 1   0   1    1    *</span>\n<span class=\"c1\">#&gt; 2   1   0    *    *</span>\n<span class=\"c1\">#&gt; 3   1   0    *    *</span>\n</pre>\n<p>result is a list, where the first element in the list is of type <strong>Data Frame</strong>. The dataframe contains all of the units that were matched, and the covariates and corresponding values, that it was matched on. The covariates that each unit was not matched on is denoted with a \" * \" character. The list 'result' will have additional values based on additional optional parameters, detailed in additional documentation below.</p>\n<p>To find the main matched group of a particular unit after DAME has been run, use the function <em>mmg_of_unit</em></p>\n<pre><span class=\"n\">mmg</span> <span class=\"o\">=</span> <span class=\"n\">dame_flame</span><span class=\"o\">.</span><span class=\"n\">DAME_FLAME</span><span class=\"o\">.</span><span class=\"n\">mmg_of_unit</span><span class=\"p\">(</span><span class=\"n\">return_df</span><span class=\"o\">=</span><span class=\"n\">result</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">unit_id</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">mmg</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#&gt;    x1   x2    x3</span>\n<span class=\"c1\">#&gt; 0   0    1    1</span>\n<span class=\"c1\">#&gt; 1   0    1    1</span>\n</pre>\n<p>To find the treatment effect of a unit, use the function <em>te_of_unit</em></p>\n<pre><span class=\"n\">te</span> <span class=\"o\">=</span> <span class=\"n\">dame_flame</span><span class=\"o\">.</span><span class=\"n\">DAME_FLAME</span><span class=\"o\">.</span><span class=\"n\">te_of_unit</span><span class=\"p\">(</span><span class=\"n\">return_df</span><span class=\"o\">=</span><span class=\"n\">result</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">unit_id</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">treatment_column_name</span><span class=\"o\">=</span><span class=\"s1\">'treated'</span><span class=\"p\">,</span> <span class=\"n\">outcome_column_name</span><span class=\"o\">=</span><span class=\"s1\">'outcome'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">te</span><span class=\"p\">)</span>\n<span class=\"c1\">#&gt; -1.0</span>\n</pre>\n<h2>DAME and FLAME Parameters and Defaults</h2>\n<pre><span class=\"n\">DAME</span><span class=\"p\">(</span><span class=\"n\">input_data</span><span class=\"p\">,</span> <span class=\"n\">treatment_column_name</span><span class=\"o\">=</span><span class=\"s1\">'treated'</span><span class=\"p\">,</span> <span class=\"n\">weight_array</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n     <span class=\"n\">outcome_column_name</span><span class=\"o\">=</span><span class=\"s1\">'outcome'</span><span class=\"p\">,</span> <span class=\"n\">adaptive_weights</span><span class=\"o\">=</span><span class=\"s1\">'ridge'</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> \n     <span class=\"n\">holdout_data</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">repeats</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">want_pe</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n     <span class=\"n\">early_stop_iterations</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">stop_unmatched_c</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n     <span class=\"n\">early_stop_un_c_frac</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">stop_unmatched_t</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n     <span class=\"n\">early_stop_un_t_frac</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">early_stop_pe</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n     <span class=\"n\">early_stop_pe_frac</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">want_bf</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">early_stop_bf</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n     <span class=\"n\">early_stop_bf_frac</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">missing_indicator</span><span class=\"o\">=</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">,</span> \n     <span class=\"n\">missing_data_replace</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">missing_holdout_replace</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> \n     <span class=\"n\">missing_holdout_imputations</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">missing_data_imputations</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"n\">FLAME</span><span class=\"p\">(</span><span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">treatment_column_name</span><span class=\"o\">=</span><span class=\"s1\">'treated'</span><span class=\"p\">,</span>\n      <span class=\"n\">outcome_column_name</span><span class=\"o\">=</span><span class=\"s1\">'outcome'</span><span class=\"p\">,</span> <span class=\"n\">adaptive_weights</span><span class=\"o\">=</span><span class=\"s1\">'ridge'</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> \n      <span class=\"n\">holdout_data</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">repeats</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">want_pe</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n      <span class=\"n\">early_stop_iterations</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">stop_unmatched_c</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n      <span class=\"n\">early_stop_un_c_frac</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">stop_unmatched_t</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n      <span class=\"n\">early_stop_un_t_frac</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">early_stop_pe</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n      <span class=\"n\">early_stop_pe_frac</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">want_bf</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">early_stop_bf</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> \n      <span class=\"n\">early_stop_bf_frac</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">,</span> <span class=\"n\">missing_indicator</span><span class=\"o\">=</span><span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">nan</span><span class=\"p\">,</span> \n      <span class=\"n\">missing_data_replace</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">missing_holdout_replace</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> \n      <span class=\"n\">missing_holdout_imputations</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">missing_data_imputations</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> \n      <span class=\"n\">pre_dame</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n</pre>\n<h3>Key parameters</h3>\n<p><strong>input_data</strong>: file, DataFrame, required\nThis is the data being matched. This is henceforth referred to as the matching data.</p>\n<p><strong>treatment_column_name</strong>: string, optional (default=\"treated\")<br>\nThis is the name of the column with a binary indicator for whether a row is a treatment or control unit.</p>\n<p><strong>outcome_column_name</strong>: string, optional (default=\"outcome\")<br>\nThis is the name of the column with the outcome variable of each unit.</p>\n<p><strong>adaptive_weights</strong>: bool, \"ridge\", \"decision tree\", \"ridgeCV\", optional (default=\"ridge\")<br>\nThe method used to decide what covariate set should be dropped next.</p>\n<p><strong>weight_array</strong>: array, optional<br>\nIf adaptive_weights = False, these are the weights to the covariates in <strong>input_data</strong>, for the non-adaptive version of DAME. Must sum to 1. In this case, we do not use machine learning for the weights, they are manually entered as <strong>weight_array</strong>.</p>\n<p><strong>alpha</strong>: float, optional (default=0.1)<br>\nIf adaptive_weights is set to ridge, this is the alpha for ridge regression.</p>\n<p><strong>holdout_data</strong>: file, DataFrame, float between 0 and 1, optional (Default = 0.1)\nIf doing an adaptive_weights version of DAME, this is used to decide what covariates to drop. The default is to use 10% of the <strong>input_data</strong> dataset. Users can specify a percentage of the matching data set to use as the holdout set, or use a different file. If using a different file, that file needs to have all of the same column labels, including treatment and outcome columns.</p>\n<p><strong>repeats</strong>: Bool, optional (default=False)<br>\nWhether or not units for whom a main matched has been found can be used again, and placed in an auxiliary matched group.</p>\n<p><strong>verbose</strong>: int 0,1,2,3 (default=2)<br>\nStyle of printout while algorithm runs.\nIf 0, no output\nIf 1, provides iteration number\nIf 2, provides iteration number and additional information on the progress of the matching at every 10th iteration\nIf 3, provides iteration number and additional information on the progress of the matching at every iteration</p>\n<p><strong>want_pe</strong>: bool, optional (default=False)<br>\nIf true, the output of the algorithm will include the predictive error of the covariate sets used for matching in each iteration.</p>\n<p><strong>want_bf</strong>: bool, optional (default=False)<br>\nIf true, the output will include the balancing factor for each iteration.</p>\n<h4>FLAME-specific parameters</h4>\n<p><strong>pre_dame</strong>: bool, integer, optional (default=False)<br>\nThis will allow a user to run the Hybrid-FLAME-DAME algorithm. If an integer n is provided, then after n iterations of FLAME, the algorithm will switch to DAME.</p>\n<p><strong>C</strong>: float, optional (default=0.1)\nThis is used in deciding the best covariate match during iterations of FLAME. Specifically, its the tradeoff parameter between balancing factor and predictive error.</p>\n<h3>Parameters related to missing data handling</h3>\n<p>A variety of built-in options for missing data handling functionality is available to users.</p>\n<p>The fastest option is to exclude missing values for each unit in the matching dataset, and drop missing units entirely from the holdout dataset.\nThe units with missing values would still be placed in a group, but the covariates for which they\nhave missing data wouldn't be used to find their group. Holdout missing data would\nbe dropped.  These are parameters missing_holdout_replace=1, missing_data_replace=2.</p>\n<p>If missing data is detected, but the user has not specified a handling technique, then\n(does it quit?)</p>\n<p><strong>missing_indicator</strong>: character, integer, numpy.nan, optional (default=numpy.nan)<br>\nThis is the indicator for missing data in the dataset.</p>\n<p><strong>missing_holdout_replace</strong>: int 0,1,2, optional (default=0)<br>\nIf 0, assume no missing holdout data and proceed.\nIf 1, the algorithm excludes units with missing values from the holdout dataset.\nIf 2, do MICE on holdout dataset. If this option is selected, it will be done for a number of iterations equal to <strong>missing_holdout_imputations</strong>.</p>\n<p><strong>missing_data_replace</strong>: int 0,1,2,3, optional, (default=0)<br>\nIf 0, assume no missing data in matching data and proceed.\nIf 1, the algorithm does not match on units that have missing values.\nIf 2, prevent all <strong>missing_indicator</strong> values from being matched on.\nIf 3, do MICE on matching dataset. This is not recommended. If this option is selected, it will be done for a number of iterations equal to <strong>missing_data_imputations</strong>.</p>\n<p><strong>missing_holdout_imputations</strong>: int, optional (default=10)<br>\nIf missing_holdout_replace=2, the number of imputations.</p>\n<p><strong>missing_data_imputations</strong>: int, optional (default=1)<br>\nIf missing_data_replace=3, the number of imputations.</p>\n<h3>Parameters related to early stopping criteria</h3>\n<p><strong>early_stop_iterations</strong>: int, optional  (default=0)<br>\nIf provided, a number of iterations after which to hard stop the algorithm.</p>\n<p><strong>stop_unmatched_c</strong>: bool, optional (default=False)<br>\nIf True, then the algorithm terminates when there are no more control units to match.</p>\n<p><strong>stop_unmatched_t</strong>: bool, optional (default=True)<br>\nIf True, then the algorithm terminates when there are no more treatment units to match.</p>\n<p><strong>early_stop_un_c_frac</strong>: float from 0.0 to 1.0, optional (default=0.1)<br>\nThis provides a fraction of unmatched control units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 control units, the algorithm will stop when 10 control units are unmatched and 90 are matched (or earlier, depending on other stopping conditions).</p>\n<p><strong>early_stop_un_t_frac</strong>: float from 0.0 to 1.0, optional (default=0.1)\nThis provides a fraction of unmatched treatment units. When the threshold is met, the algorithm will stop iterating. For example, using an input dataset with 100 treatment units, the algorithm will stop when 10 control units are unmatched and 90 are matched  (or earlier, depending on other stopping conditions).</p>\n<p><strong>early_stop_pe</strong>: bool, optional (default=False)<br>\nIf this is true, then if the covariate set chosen for matching has a predictive error higher than the parameter <strong>early_stop_pe_frac</strong>, the algorithm will stop.</p>\n<p><strong>early_stop_pe_frac</strong>: float, optional (default=0.01)<br>\nIf <strong>early_stop_pe</strong> is true, then if the covariate set chosen for matching has a predictive error higher than this value, the algorithm will stop.</p>\n<p><strong>early_stop_bf</strong>: bool, optional (default=False)<br>\nIf this is true, then if the covariate set chosen for matching has a balancing factor lower than early_stop_bf_frac, then the algorithm will stop.</p>\n<p><strong>early_stop_bf_frac</strong>: float, optional (default=0.01)<br>\nIf early_stop_bf is true, then if the covariate set chosen for matching has a balancing factor lower than this value, then the algorithm will stop.</p>\n<h2>Additional Functions Available, and their parameters and defaults</h2>\n<p>To provide users with additional options in analyzing the output of DAME and FLAME, we provide a set of functions that can be used after running the match.</p>\n<pre><span class=\"c1\"># The main matched group of a unit</span>\n<span class=\"n\">mmg_of_unit</span><span class=\"p\">(</span><span class=\"n\">return_df</span><span class=\"p\">,</span> <span class=\"n\">unit_id</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"p\">,</span> <span class=\"n\">output_style</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># The treatment effect of a unit</span>\n<span class=\"n\">te_of_unit</span><span class=\"p\">(</span><span class=\"n\">return_df</span><span class=\"p\">,</span> <span class=\"n\">unit_id</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"p\">,</span> <span class=\"n\">treatment_column_name</span><span class=\"p\">,</span> <span class=\"n\">outcome_column_name</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Both the main matched group and the treatment effect of a unit </span>\n<span class=\"n\">mmg_and_te_of_unit</span><span class=\"p\">(</span><span class=\"n\">return_df</span><span class=\"p\">,</span> <span class=\"n\">unit_id</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"p\">,</span> <span class=\"n\">treatment_column_name</span><span class=\"p\">,</span> <span class=\"n\">outcome_column_name</span><span class=\"p\">,</span> <span class=\"n\">return_vals</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<h3>Parameters</h3>\n<p><strong>return_df</strong>: Python Pandas Dataframe, required (no default).\nThis is the dataframe containing all of the matches, or the first and main output from <code>FLAME</code> or <code>DAME</code></p>\n<p><strong>unit_id</strong>: int, required (no default).\nThis is the unit for which the main matched group or treatment effect is being calculated</p>\n<p><strong>output_style</strong>: int, optional (default=1):\nIn the mmg_of_unit function, if this is 1 then the main matched group will only display covariates that were used in matching for each unit. The output dataframe will have a ' * ' character in the column for each unit that was not matched on that covariate.\nIf this value is 2, then the dataframe will contain complete values and no ' * ' characters.</p>\n<p><strong>return_vals</strong>: int, optional (default=0):\nIn mmg_and_te_of_unit, if this is 1 then the values will print in a pretty way rather than outputting.</p>\n<h2>Additional Technical Notes</h2>\n<h3>Missing Data Handling</h3>\n<p>For details on the MICE algorithm, see : <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/\" rel=\"nofollow\">this paper</a>\nThe underlying MICE implementation is done using scikit learn's experimental IterativeImpute package,\nand relies on DecisionTreeRegressions in the imputation process, to ensure that the data generated\nis fit for unordered categorical data. In addition to this, users are welcome to pre-process their datsets with other data handling techniques\nprior to using MICE. It is not recommended to use MICE on the matching dataset, as this would be very slow.</p>\n<p>One option is to set the parameter missing_data_replace=2, where units that have missing values are still matched on, but the covariates they are missing are not used in computing their match.\nIn this option, the underlying algorithm works by replacing each missing value with a unique value, so that in the matching procedure, those covariates simply don't have a match because their\nvalues are not equl to any other values.</p>\n\n          </div>"}, "last_serial": 7079962, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "4e181744fa527deac330968c101ace6b", "sha256": "0c97a1b84473fb8fd2efc8fbf33d7c88ad590049918a34f528f9938219449a5a"}, "downloads": -1, "filename": "dame_flame-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "4e181744fa527deac330968c101ace6b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 29278, "upload_time": "2020-04-07T04:53:14", "upload_time_iso_8601": "2020-04-07T04:53:14.730872Z", "url": "https://files.pythonhosted.org/packages/d2/bb/25f1887bb6849d9037ac884e43861e0c476dcae2f5505438268d10e9f7fa/dame_flame-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9949771ba9c192403be944ed798fd6a2", "sha256": "8fcd30f54c76e5086de1c6e09f8b6369bd9c406564d51a83f50a7f38d77a9e98"}, "downloads": -1, "filename": "dame_flame-0.1.tar.gz", "has_sig": false, "md5_digest": "9949771ba9c192403be944ed798fd6a2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24227, "upload_time": "2020-04-07T04:53:16", "upload_time_iso_8601": "2020-04-07T04:53:16.949520Z", "url": "https://files.pythonhosted.org/packages/d6/3a/e476db6fbd062baf633b786eae15596e027d7652001e8eb780ffbf58fe52/dame_flame-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "b6aa663eefc18bf0ef73322ae7824e9c", "sha256": "27b529de939a5778323117c471a70a15bcfc4f39dea77a1a804efffa3f51f6b0"}, "downloads": -1, "filename": "dame_flame-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "b6aa663eefc18bf0ef73322ae7824e9c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 29772, "upload_time": "2020-04-22T21:06:48", "upload_time_iso_8601": "2020-04-22T21:06:48.660990Z", "url": "https://files.pythonhosted.org/packages/00/73/7ca0ac1be0c7993172f86acf6ecd52f65168260e3bd4c79614faa8bc3710/dame_flame-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4933ae231ae35f3c9be48f3c2f5edc57", "sha256": "b5055538921c8947b2be30207caa2a441de08b608872d2cb6724bf4c326f569b"}, "downloads": -1, "filename": "dame_flame-0.2.tar.gz", "has_sig": false, "md5_digest": "4933ae231ae35f3c9be48f3c2f5edc57", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24672, "upload_time": "2020-04-22T21:06:49", "upload_time_iso_8601": "2020-04-22T21:06:49.917083Z", "url": "https://files.pythonhosted.org/packages/0c/9e/7c87796b1e18aac5348dfa05dcff03750326e8b8ad972b9d2bb86ed5cf01/dame_flame-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b6aa663eefc18bf0ef73322ae7824e9c", "sha256": "27b529de939a5778323117c471a70a15bcfc4f39dea77a1a804efffa3f51f6b0"}, "downloads": -1, "filename": "dame_flame-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "b6aa663eefc18bf0ef73322ae7824e9c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 29772, "upload_time": "2020-04-22T21:06:48", "upload_time_iso_8601": "2020-04-22T21:06:48.660990Z", "url": "https://files.pythonhosted.org/packages/00/73/7ca0ac1be0c7993172f86acf6ecd52f65168260e3bd4c79614faa8bc3710/dame_flame-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4933ae231ae35f3c9be48f3c2f5edc57", "sha256": "b5055538921c8947b2be30207caa2a441de08b608872d2cb6724bf4c326f569b"}, "downloads": -1, "filename": "dame_flame-0.2.tar.gz", "has_sig": false, "md5_digest": "4933ae231ae35f3c9be48f3c2f5edc57", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24672, "upload_time": "2020-04-22T21:06:49", "upload_time_iso_8601": "2020-04-22T21:06:49.917083Z", "url": "https://files.pythonhosted.org/packages/0c/9e/7c87796b1e18aac5348dfa05dcff03750326e8b8ad972b9d2bb86ed5cf01/dame_flame-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:45 2020"}