{"info": {"author": "hampsterx", "author_email": "tim.vdh@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# async-kinesis\n\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)\n\n\n## Features\n\n- uses queues for both producer and consumer\n  - producer flushes with put_records() if has enough to flush or after \"buffer_time\" reached\n  - consumer iterates over msg queue independent of shard readers\n- Configurable to handle Sharding limits but will throttle/retry if required\n  - ie multiple independent clients are saturating the Shards\n- Checkpointing with heartbeats\n  - deadlock + reallocation of shards if checkpoint fails to heartbeat within \"session_timeout\"\n\n## Consumer Design\n\n(Bears some explanation, kinda complex~)\n\n- fetch() gets called periodically (0.2 sec (ie max 5x per second as is the limit on shard get_records()))\n  - iterate over the list of shards (set on startup, does not currently detect resharding)\n    - assign shard if not in use and not at \"max_shard_consumers\" limit otherwise ignore/continue\n    - ignore/continue if this shard is still fetching\n    - process records if shard is done fetching\n        - put records on queue\n        - add checkpoint record to queue\n        - assign NextShardIterator\n    - create (get_records()) task again\n\nNote that get_records() is throttled via \"shard_fetch_rate=5\" (ie the same 0.2 sec/ 5x limit)\n\nThis pattern seemed like the easiest way to maintain a pool of consumers without needing to think too hard about starting it's next job or handling new shards etc.\n\n\n## Not Implemented\n\n- resharding\n- client rebalancing (ie share the shards between consumers)\n\nSee also\n\nhttps://aws.amazon.com/blogs/big-data/implementing-efficient-and-reliable-producers-with-the-amazon-kinesis-producer-library/\n\n\n## Producer\n    \n    async with Producer(stream_name=\"test\") as producer:\n        # Put item onto queue to be flushed via put_records()\n        await producer.put({'my': 'data'})\n\n\nOptions:\n\n(comments in quotes are Kinesis Limits as per AWS Docs)\n\n* region_name\n    > AWS Region\n\n* buffer_time=0.5\n    > Buffer time in seconds before auto flushing records\n    \n* put_rate_limit_per_shard=1000\n    > \"A single shard can ingest up to 1 MiB of data per second (including partition keys) or 1,000 records per second for writes\n\n* batch_size=500\n    > \"Each PutRecords request can support up to 500 records\"    \n\n* max_queue_size=10000\n   > put() method will block when queue is at max \n   \n* after_flush_fun\n   > async function to call after doing a flush (err put_records()) call\n                 \n\n## Consumer\n\n    async with Consumer(stream_name=\"test\") as consumer:\n        while True:\n            async for item in consumer:\n                print(item)\n            # caught up.. take a breather~\n\n\nOptions:\n\n(comments in quotes are Kinesis Limits as per AWS Docs)\n\n* region_name\n    > AWS Region\n\n* max_queue_size=1000\n    > the fetch() task shard \n\n* max_shard_consumers=None\n    > Max number of shards to use. None = all\n    \n* record_limit=10000\n    > Number of records to fetch with get_records()\n\n* sleep_time_no_records=2\n    > No of seconds to sleep when caught up\n    \n* iterator_type=\"TRIM_HORIZON\"\n    > Default shard iterator type for new/unknown shards (ie start from start of stream)\n    > Alternative is \"LATEST\" (ie end of stream)\n\n* shard_fetch_rate=5\n    > No of fetches per second (max = 5)           \n\n* checkpointer=None\n    > Checkpointer to use\n\n\n## Checkpointers\n\n- memory\n- redis\n\n\n## Yet another Python Kinesis Library?\n\nSadly I had issues with every other library I could find :(\n\n* https://github.com/NerdWalletOSS/kinesis-python\n    * pro:\n        * kinda works\n    * con\n        * threaded\n        * Outstanding PR to fix some issues\n        * checkpoints on every record on main thread\n\n* https://github.com/ungikim/kinsumer\n    * pro:\n        * handles shard changes\n        * no producer\n        * no redis checkpointer/heartbeat\n        * threaded/seems kinda complicated~\n    * con\n        * consumer only\n         \n* https://github.com/bufferapp/kiner\n    * pro:\n        * Batching\n    * con\n        * Producer only\n\n* https://github.com/niklio/aiokinesis\n    * pro:\n        * asyncio\n        * no checkpointing\n    * con\n        * limited to 1 shard / too simplistic\n\n* https://github.com/ticketea/pynesis\n    * pro:\n        * checkpoints\n    * con\n        * hasn't been updated for 1 year\n        * doesnt use put_records()\n        * single threaded / round robin reads shards\n\n* https://github.com/whale2/async-kinesis-client\n    * pro:\n        * checkpoints\n        * asyncio\n    * con\n        * ?\n\n(Actually I only found this one recently, might be ok alternative?)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/hampsterx/async-kinesis", "keywords": "", "license": "Apache2", "maintainer": "", "maintainer_email": "", "name": "py-kinesis", "package_url": "https://pypi.org/project/py-kinesis/", "platform": "", "project_url": "https://pypi.org/project/py-kinesis/", "project_urls": {"Homepage": "https://github.com/hampsterx/async-kinesis"}, "release_url": "https://pypi.org/project/py-kinesis/0.0.1/", "requires_dist": null, "requires_python": "", "summary": "AsyncIO Kinesis Library", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>async-kinesis</h1>\n<p><a href=\"https://github.com/python/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<h2>Features</h2>\n<ul>\n<li>uses queues for both producer and consumer\n<ul>\n<li>producer flushes with put_records() if has enough to flush or after \"buffer_time\" reached</li>\n<li>consumer iterates over msg queue independent of shard readers</li>\n</ul>\n</li>\n<li>Configurable to handle Sharding limits but will throttle/retry if required\n<ul>\n<li>ie multiple independent clients are saturating the Shards</li>\n</ul>\n</li>\n<li>Checkpointing with heartbeats\n<ul>\n<li>deadlock + reallocation of shards if checkpoint fails to heartbeat within \"session_timeout\"</li>\n</ul>\n</li>\n</ul>\n<h2>Consumer Design</h2>\n<p>(Bears some explanation, kinda complex~)</p>\n<ul>\n<li>fetch() gets called periodically (0.2 sec (ie max 5x per second as is the limit on shard get_records()))\n<ul>\n<li>iterate over the list of shards (set on startup, does not currently detect resharding)\n<ul>\n<li>assign shard if not in use and not at \"max_shard_consumers\" limit otherwise ignore/continue</li>\n<li>ignore/continue if this shard is still fetching</li>\n<li>process records if shard is done fetching\n<ul>\n<li>put records on queue</li>\n<li>add checkpoint record to queue</li>\n<li>assign NextShardIterator</li>\n</ul>\n</li>\n<li>create (get_records()) task again</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Note that get_records() is throttled via \"shard_fetch_rate=5\" (ie the same 0.2 sec/ 5x limit)</p>\n<p>This pattern seemed like the easiest way to maintain a pool of consumers without needing to think too hard about starting it's next job or handling new shards etc.</p>\n<h2>Not Implemented</h2>\n<ul>\n<li>resharding</li>\n<li>client rebalancing (ie share the shards between consumers)</li>\n</ul>\n<p>See also</p>\n<p><a href=\"https://aws.amazon.com/blogs/big-data/implementing-efficient-and-reliable-producers-with-the-amazon-kinesis-producer-library/\" rel=\"nofollow\">https://aws.amazon.com/blogs/big-data/implementing-efficient-and-reliable-producers-with-the-amazon-kinesis-producer-library/</a></p>\n<h2>Producer</h2>\n<pre><code>async with Producer(stream_name=\"test\") as producer:\n    # Put item onto queue to be flushed via put_records()\n    await producer.put({'my': 'data'})\n</code></pre>\n<p>Options:</p>\n<p>(comments in quotes are Kinesis Limits as per AWS Docs)</p>\n<ul>\n<li>\n<p>region_name</p>\n<blockquote>\n<p>AWS Region</p>\n</blockquote>\n</li>\n<li>\n<p>buffer_time=0.5</p>\n<blockquote>\n<p>Buffer time in seconds before auto flushing records</p>\n</blockquote>\n</li>\n<li>\n<p>put_rate_limit_per_shard=1000</p>\n<blockquote>\n<p>\"A single shard can ingest up to 1 MiB of data per second (including partition keys) or 1,000 records per second for writes</p>\n</blockquote>\n</li>\n<li>\n<p>batch_size=500</p>\n<blockquote>\n<p>\"Each PutRecords request can support up to 500 records\"</p>\n</blockquote>\n</li>\n<li>\n<p>max_queue_size=10000</p>\n<blockquote>\n<p>put() method will block when queue is at max</p>\n</blockquote>\n</li>\n<li>\n<p>after_flush_fun</p>\n<blockquote>\n<p>async function to call after doing a flush (err put_records()) call</p>\n</blockquote>\n</li>\n</ul>\n<h2>Consumer</h2>\n<pre><code>async with Consumer(stream_name=\"test\") as consumer:\n    while True:\n        async for item in consumer:\n            print(item)\n        # caught up.. take a breather~\n</code></pre>\n<p>Options:</p>\n<p>(comments in quotes are Kinesis Limits as per AWS Docs)</p>\n<ul>\n<li>\n<p>region_name</p>\n<blockquote>\n<p>AWS Region</p>\n</blockquote>\n</li>\n<li>\n<p>max_queue_size=1000</p>\n<blockquote>\n<p>the fetch() task shard</p>\n</blockquote>\n</li>\n<li>\n<p>max_shard_consumers=None</p>\n<blockquote>\n<p>Max number of shards to use. None = all</p>\n</blockquote>\n</li>\n<li>\n<p>record_limit=10000</p>\n<blockquote>\n<p>Number of records to fetch with get_records()</p>\n</blockquote>\n</li>\n<li>\n<p>sleep_time_no_records=2</p>\n<blockquote>\n<p>No of seconds to sleep when caught up</p>\n</blockquote>\n</li>\n<li>\n<p>iterator_type=\"TRIM_HORIZON\"</p>\n<blockquote>\n<p>Default shard iterator type for new/unknown shards (ie start from start of stream)\nAlternative is \"LATEST\" (ie end of stream)</p>\n</blockquote>\n</li>\n<li>\n<p>shard_fetch_rate=5</p>\n<blockquote>\n<p>No of fetches per second (max = 5)</p>\n</blockquote>\n</li>\n<li>\n<p>checkpointer=None</p>\n<blockquote>\n<p>Checkpointer to use</p>\n</blockquote>\n</li>\n</ul>\n<h2>Checkpointers</h2>\n<ul>\n<li>memory</li>\n<li>redis</li>\n</ul>\n<h2>Yet another Python Kinesis Library?</h2>\n<p>Sadly I had issues with every other library I could find :(</p>\n<ul>\n<li>\n<p><a href=\"https://github.com/NerdWalletOSS/kinesis-python\" rel=\"nofollow\">https://github.com/NerdWalletOSS/kinesis-python</a></p>\n<ul>\n<li>pro:\n<ul>\n<li>kinda works</li>\n</ul>\n</li>\n<li>con\n<ul>\n<li>threaded</li>\n<li>Outstanding PR to fix some issues</li>\n<li>checkpoints on every record on main thread</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/ungikim/kinsumer\" rel=\"nofollow\">https://github.com/ungikim/kinsumer</a></p>\n<ul>\n<li>pro:\n<ul>\n<li>handles shard changes</li>\n<li>no producer</li>\n<li>no redis checkpointer/heartbeat</li>\n<li>threaded/seems kinda complicated~</li>\n</ul>\n</li>\n<li>con\n<ul>\n<li>consumer only</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/bufferapp/kiner\" rel=\"nofollow\">https://github.com/bufferapp/kiner</a></p>\n<ul>\n<li>pro:\n<ul>\n<li>Batching</li>\n</ul>\n</li>\n<li>con\n<ul>\n<li>Producer only</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/niklio/aiokinesis\" rel=\"nofollow\">https://github.com/niklio/aiokinesis</a></p>\n<ul>\n<li>pro:\n<ul>\n<li>asyncio</li>\n<li>no checkpointing</li>\n</ul>\n</li>\n<li>con\n<ul>\n<li>limited to 1 shard / too simplistic</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/ticketea/pynesis\" rel=\"nofollow\">https://github.com/ticketea/pynesis</a></p>\n<ul>\n<li>pro:\n<ul>\n<li>checkpoints</li>\n</ul>\n</li>\n<li>con\n<ul>\n<li>hasn't been updated for 1 year</li>\n<li>doesnt use put_records()</li>\n<li>single threaded / round robin reads shards</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/whale2/async-kinesis-client\" rel=\"nofollow\">https://github.com/whale2/async-kinesis-client</a></p>\n<ul>\n<li>pro:\n<ul>\n<li>checkpoints</li>\n<li>asyncio</li>\n</ul>\n</li>\n<li>con\n<ul>\n<li>?</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>(Actually I only found this one recently, might be ok alternative?)</p>\n\n          </div>"}, "last_serial": 5294777, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "3aa4bf2a42be707a60004222ca7c6e29", "sha256": "8abdf988df8f6735c4d00c7aa106bd85f2423df74179cc7ddda2c9a48c8c948e"}, "downloads": -1, "filename": "py_kinesis-0.0.1-py3.7.egg", "has_sig": false, "md5_digest": "3aa4bf2a42be707a60004222ca7c6e29", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 22931, "upload_time": "2019-05-21T00:55:32", "upload_time_iso_8601": "2019-05-21T00:55:32.254047Z", "url": "https://files.pythonhosted.org/packages/9a/b1/972556f9a763de7c48d331d063fd62a899ef1294323b29d070f8c263bea0/py_kinesis-0.0.1-py3.7.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3aa4bf2a42be707a60004222ca7c6e29", "sha256": "8abdf988df8f6735c4d00c7aa106bd85f2423df74179cc7ddda2c9a48c8c948e"}, "downloads": -1, "filename": "py_kinesis-0.0.1-py3.7.egg", "has_sig": false, "md5_digest": "3aa4bf2a42be707a60004222ca7c6e29", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 22931, "upload_time": "2019-05-21T00:55:32", "upload_time_iso_8601": "2019-05-21T00:55:32.254047Z", "url": "https://files.pythonhosted.org/packages/9a/b1/972556f9a763de7c48d331d063fd62a899ef1294323b29d070f8c263bea0/py_kinesis-0.0.1-py3.7.egg", "yanked": false}], "timestamp": "Fri May  8 03:03:31 2020"}