{"info": {"author": "Neuraxio Inc.", "author_email": "guillaume.chevalier@neuraxio.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Financial and Insurance Industry", "Intended Audience :: Healthcare Industry", "Intended Audience :: Information Technology", "Intended Audience :: Manufacturing", "Intended Audience :: Science/Research", "Intended Audience :: System Administrators", "Intended Audience :: Telecommunications Industry", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Adaptive Technologies", "Topic :: Office/Business", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Artificial Life", "Topic :: Scientific/Engineering :: Bio-Informatics", "Topic :: Scientific/Engineering :: Image Recognition", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Scientific/Engineering :: Interface Engine/Protocol Translator", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Scientific/Engineering :: Medical Science Apps.", "Topic :: Scientific/Engineering :: Physics", "Topic :: Software Development", "Topic :: Software Development :: Assemblers", "Topic :: Software Development :: Build Tools", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Software Development :: Object Brokering", "Topic :: Software Development :: Pre-processors", "Topic :: Software Development :: Quality Assurance", "Topic :: Software Development :: Testing", "Topic :: System", "Topic :: System :: Clustering", "Topic :: System :: Distributed Computing", "Topic :: System :: Networking", "Topic :: Text Processing", "Topic :: Text Processing :: Filters", "Topic :: Text Processing :: Linguistic", "Topic :: Utilities", "Typing :: Typed"], "description": "Neuraxle Pipelines\n==================\n\n    Code Machine Learning Pipelines - The Right Way.\n\n.. image:: https://img.shields.io/github/workflow/status/Neuraxio/Neuraxle/Test%20Python%20Package/master?   :alt: Build\n    :target: https://github.com/Neuraxio/Neuraxle\n\n.. image:: https://img.shields.io/gitter/room/Neuraxio/Neuraxle?   :alt: Gitter\n    :target: https://gitter.im/Neuraxle/community\n\n.. image:: https://img.shields.io/pypi/l/neuraxle?   :alt: PyPI - License\n    :target: https://www.neuraxle.org/stable/Neuraxle/README.html#license\n\n.. image:: https://img.shields.io/pypi/dm/neuraxle?   :alt: PyPI - Downloads\n    :target: https://pypi.org/project/neuraxle/\n\n.. image:: https://img.shields.io/github/commit-activity/m/neuraxio/neuraxle?   :alt: GitHub commit activity\n    :target: https://github.com/Neuraxio/Neuraxle\n\n.. image:: https://img.shields.io/github/v/release/neuraxio/neuraxle?   :alt: GitHub release (latest by date)\n    :target: https://pypi.org/project/neuraxle/\n\n\nNeuraxle is a Machine Learning (ML) library for building neat pipelines,\nproviding the right abstractions to both ease research, development, and\ndeployment of your ML applications.\n\nInstallation\n------------\n\nSimply do:\n\n.. code:: bash\n\n    pip install neuraxle\n\n\nQuickstart\n----------\n\nOne of Neuraxle's most important goals is to make powerful machine\nlearning pipelines easy to build and deploy. Using Neuraxle should be\nlight, painless and obvious, yet without sacrificing powerfulness,\nperformance, nor possibilities.\n\nFor example, you can build a pipeline composed of multiple steps as\nsuch:\n\n.. code:: python\n\n    p = Pipeline([\n        # A Pipeline is composed of multiple chained steps. Steps\n        # can alter the data before passing it to the next steps.\n        AddFeatures([\n            # Add (concatenate) features in parallel, that are\n            # themselves derived of the existing features:\n            PCA(n_components=2),\n            FastICA(n_components=2),\n        ]),\n        RidgeModelStacking([\n            # Here is an ensemble of 4 models or feature extractors,\n            # That are themselves then fed to a ridge regression which\n            # will act as a judge to finalize the prediction.\n            LinearRegression(),\n            LogisticRegression(),\n            GradientBoostingRegressor(n_estimators=500),\n            GradientBoostingRegressor(max_depth=5),\n            KMeans(),\n        ])\n    ])\n    # Note: here all the steps were imported from scikit-learn,\n    # but the goal is that you can also define your own as needed.\n    # Also note that a pipeline is a step itself: you can nest them.\n\n    # The pipeline will learn on the data and acquire state.\n    p = p.fit(X_train, y_train)\n\n    # Once it learned, the pipeline can process new and\n    # unseen data for making predictions.\n    y_test_predicted = p.predict(X_test)\n\nVisit the\n`examples <https://www.neuraxle.org/stable/examples/index.html>`__\nto get more a feeling of how it works, and inspiration.\n\nDeep Learning Pipelines\n-----------------------\n\nHere is how to use deep learning algorithms within a Neuraxle Pipeline.\n\nDeep Learning Pipeline Definition\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nDefining a Deep Learning pipeline is more complex. \nIt needs a composition of many steps to: \n\n-  Loop on data for many epochs, but just during training.\n-  Shuffle the data, just during training.\n-  Use minibatches to process the data, which avoids to blow RAM. Your steps will fit incrementally.\n-  Process data that is 2D, 3D, 4D, or even 5D or ND, with transformers made for 2D data slices.\n-  Actually use your Deep Learning algorithm within your pipeline for it to learn and predict.\n\nBelow, we define a pipeline for time series classification using\na LSTM RNN. It includes data preprocessing steps as well as the\ndata flow management. `Time Series data is 3D <https://qr.ae/TZjoMb>`__.\n\n.. code:: python\n    \n    deep_learning_seq_classif_pipeline = EpochRepeater(Pipeline([\n        # X data shape: (batch, different_lengths, n_feature_columns)\n        # y data shape: (batch, different_lengths)\n        # Split X and Y into windows using \n        # an InputAndOutputTransformerMixin\n        # abstraction to transform y too:\n        SliceTimeSeries(window_size=128, last_label_as_seq_label=True),\n        # X data shape: (more_than_batch, 128, n_feature_columns)\n        # y data shape: (more_than_batch, 128)\n        TrainOnlyWrapper(DataShuffler(seed=42)),\n        MiniBatchSequentialPipeline([\n            # X data shape: (batch_size, 128, n_feature_columns)\n            # y data shape: (batch_size, 128)\n            # Loop on 2D slices of the batch's 3D time series\n            # data cube to apply 2D transformers:\n            ForEachDataInput(Pipeline([\n                # X data shape: (128, n_feature_columns)\n                # y data shape: (128)\n                # This step will load the lazy-loadable data\n                # into a brick:\n                ToNumpy(np_dtype=np.float32),\n                # Fill nan and inf values with 0:\n                DefaultValuesFiller(0.0),\n                # Transform the columns (that is the innermost\n                # axis/dim of data named `n_feature_columns`):\n                ColumnTransformer([\n                    # Columns 0, 1, 2, 3 and 4 needs to be\n                    # normalized by mean and variance (std):\n                    (range(0, 5), MeanVarianceNormalizer()),\n                    # Column 5 needs to have it's `log plus 1` \n                    # value taken before normalization.\n                    (5, Pipeline([\n                        Log1P(), \n                        MeanVarianceNormalizer()\n                    ]))\n                    # Note that omited columns are discarded. \n                    # Also, multiple transformers on a column will \n                    # concatenate the results. \n                ]),\n                # Transform the labels' indices to one-hot vectors.\n                OutputTransformerWrapper(\n                    OneHotEncoder(nb_columns=6, name='labels'))\n                # X data shape: (128, n_feature_columns)\n                # y data shape: (128, 6)\n            ])),\n            # X data shape: (batch_size, 128, n_feature_columns)\n            # y data shape: (batch_size, 128, 6)\n            # Classification with a deep neural network,\n            # using the Neuraxle-TensorFlow and/or\n            # Neuraxle-PyTorch extensions:\n            ClassificationLSTM(n_stacked=2, n_residual=3),\n            # X data shape: (batch_size, 128, 6)\n            # y data shape: (batch_size, 128, 6)\n        ], batch_size=32),\n        # X data shape: (batch_size, 128, 6)\n    ]), epochs=200, fit_only=True)\n\nDeep Learning Pipeline Training and Evaluation\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nHere we train and evaluate with a train-validation split. Note that\nautomatic hyperparameter tuning would require only a few more lines\nof code: see our\n`hyperparameter tuning example <https://www.neuraxle.org/stable/examples/boston_housing_meta_optimization.html#sphx-glr-examples-boston-housing-meta-optimization-py>`__.\n\n.. code:: python\n\n    # Wrap the pipeline by a validation strategy,\n    # this could have been Cross Validation as well:\n    training_pipeline = ValidationSplitWrapper(\n        deep_learning_seq_classif_pipeline,\n        val_size=0.1,\n        scoring_function=sklearn.metrics.accuracy_score\n    )\n\n    # Fitting and evaluating the pipeline.\n    # X_train data shape: (batch, different_lengths, n_feature_columns)\n    # y_train data shape: (batch, different_lengths)\n    training_pipeline.fit(X_train, y_train)\n    # Note that X_train and y_train can be lazy loaders.\n    print('Train accuracy: {}'.format(\n        training_pipeline.scores_train_mean))\n    print('Validation accuracy: {}'.format(\n        training_pipeline.scores_validation_mean))\n\n    # Recover the pipeline in test mode:\n    production_pipeline = training_pipeline.get_step()\n    production_pipeline.set_train(False)\n\nDeep Learning Production Pipeline\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nDeploying your deep learning app to a JSON REST API. Refer\nto `Flask's deployment documentation <https://flask.palletsprojects.com/en/1.1.x/tutorial/deploy/>`__\nfor more info on deployment servers and security.\n\n.. code:: python\n\n    # Will now serve the pipeline to a REST API as an example:\n    # Note that having saved the pipeline to disk\n    # (for reloading this in another file) would be easy, too, using savers.\n    app = FlaskRestApiWrapper(\n        json_decoder=YourCustomJSONDecoderFor2DArray(),\n        wrapped=production_pipeline,\n        json_encoder=YourCustomJSONEncoderOfOutputs()\n    ).get_app()\n    app.run(debug=False, port=5000)\n\nCalling a Deployed Pipeline\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis could be ran from another distant computer to call your app:\n\n.. code:: python\n\n    p = APICaller(\n        json_encoder=YourCustomJSONEncoderOfInputs(),\n        url=\"http://127.0.0.1:5000/\",\n        json_decoder=YourCustomJSONDecoderOfOutputs()\n    )\n    y_pred = p.predict(X_test)\n    print(y_pred)\n\nNote that we'll soon have better remote proxy design patterns for distant\npipelines, and distant parallel processing and distant parallel training.\n\nWhy Neuraxle?\n-------------\n\nProduction-ready\n~~~~~~~~~~~~~~~~\n\nMost research projects don't ever get to production. However, you want\nyour project to be production-ready and already adaptable (clean) by the\ntime you finish it. You also want things to be simple so that you can\nget started quickly.\n\nMost existing machine learning pipeline frameworks are either too simple\nor too complicated for medium-scale projects. Neuraxle is balanced for\nmedium-scale projects, providing simple, yet powerful abstractions that\nare ready to be used.\n\nCompatibility\n~~~~~~~~~~~~~\n\n    Neuraxle is built as a framework that enables you to define your own\n    pipeline steps.\n\nThis means that you can use\n`scikit-learn <https://arxiv.org/pdf/1201.0490v4.pdf>`__,\n`Keras <https://keras.io/>`__,\n`TensorFlow <https://arxiv.org/pdf/1603.04467v2.pdf>`__,\n`PyTorch <https://openreview.net/pdf?id=BJJsrmfCZ>`__,\n`Hyperopt <https://pdfs.semanticscholar.org/d4f4/9717c9adb46137f49606ebbdf17e3598b5a5.pdf>`__,\n`Ray <https://arxiv.org/pdf/1712.05889v2.pdf>`__ \nand/or **any other machine learning library** you like within and\nthroughout your Neuraxle pipelines.\n\nParallel Computing and Serialization\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNeuraxle offer multiple parallel processing features. One magical thing \nthat we did are Savers. Savers allow you to define how a step can be \nserialized. This way, it's possible to avoid Python's parallel \nprocessing limitations and pitfalls. \n\nLet's suppose that your pipeline has a step that imports code from\nanother library and that this code isn't serializable (e.g.: some\ncode written in C++ and interacting with the GPUs or anything funky).\nTo make this step serializable, just define a saver which will tell\nthe step how to dump itself to disk and reload itself. This will\nallow the step to be sent to a remote computer or to be threadable\nby reloading the save. The save can be dumped to a RAM disk for\nmore performance and avoid truly writing to disks.\n\nNeuraxle is compatible with most other ML and DL libraries. We're\ncurrently already writing savers for PyTorch and TensorFlow in the\n`Neuraxle-PyTorch <https://github.com/Neuraxio/Neuraxle-PyTorch>`__ \nand `Neuraxle-TensorFlow <https://github.com/Neuraxio/Neuraxle-TensorFlow>`__ \nextensions of this project.\n\nTime Series Processing\n~~~~~~~~~~~~~~~~~~~~~~\n\nAlthough Neuraxle is not limited to just time series processing\nprojects, it's especially good for those projects, as one of the goals\nof Neuraxle is to provides a few abstractions that are useful for time\nseries projects, as\n`Time Series data is often 3D <https://qr.ae/TZjoMb>`__ or even ND.\n\nWith the various abstractions that Neuraxle provides, it's easy to get\nstarted building a time-series processing project. Neuraxle is also the\nbackbone of `the Neuraxio Time Series\nproject <https://www.neuraxio.com/en/time-series-solution>`__, which is\na premium software package built on top of Neuraxle for business boost\ntheir time series machine learning projects by providing out-of-the-box\nspecialized pipeline steps. Some of those specialized steps are featured\nin the `Deep Learning Pipelines <#deep-learning-pipelines>`__ section above.\n\nNote: `the Neuraxio Time Series\nproject <https://www.neuraxio.com/en/time-series-solution>`__ is\ndifferent from the Neuraxle project, those are separate projects.\nNeuraxio is commited to build open-source software, and defines itself\nas an open-source company. Learn more on `Neuraxle's\nlicense <#license>`__. The Neuraxle library is free and will always stay\nfree, while Neuraxio Time Series is a premium add-on to Neuraxle.\n\nAutomatic Machine Learning\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOne of the core goal of this framework is to enable easy automatic\nmachine learning, and also meta-learning. It should be easy to train a\nmeta-optimizer on many different tasks: the optimizer is a model itself\nthat maps features of datasets and features of the hyperparameter space\nto a guessed performance score to predict the best hyperparameters.\nHyperparameter spaces are easily defined with a range, and are only\ncoupled to their respective pipeline steps, rather than being coupled to\nthe whole pipeline, which enable class reuse and more modularity.\n\nComparison to Other Machine Learning Pipeline Frameworks\n--------------------------------------------------------\n\nscikit-learn\n~~~~~~~~~~~~\n\nEverything that works in sklearn is also useable in Neuraxle. Neuraxle\nis built in a way that does not replace what already exists. Therefore,\nNeuraxle adds more power to scikit-lean by providing neat abstractions,\nand neuraxle is even retrocompatible with sklean if it ever needed to be\nincluded in an already-existing sklearn pipeline (you can do that by\nusing ``.tosklearn()`` on your Neuraxle pipeline). We believe that\nNeuraxle helps scikit-learn, and also scikit-learn will help Neuraxle.\nNeuraxle is best used with scikit-learn.\n\nAlso, the top core developers of scikit-learn, Andreas C. M\u00fcller, `gave\na talk <https://www.youtube.com/embed/Wy6EKjJT79M>`__ in which he lists\nthe elements that are yet to be done in scikit-learn. He refers to\nbuilding bigger pipelines with automatic machine learning, meta\nlearning, improving the abstractions of the search spaces, and he also\npoints out that it would be possible do achieve that in another library\nwhich could reuse scikit-learn. Neuraxle is here to solve those problems\nthat are actually shared by the open-source community in general. Let's\nmove forward with Neuraxle: join Neuraxle's `community <#community>`__.\n\nApache Beam\n~~~~~~~~~~~\n\nApache Beam is a big, multi-language project and hence is complicated.\nNeuraxle is pythonic and user-friendly: it's easy to get started.\n\nAlso, it seems that Apache Beam has GPL and MPL dependencies, which\nmeans Apache Beam might itself be copyleft (?). Neuraxle doesn't have\nsuch copyleft dependencies.\n\nspaCy\n~~~~~\n\nspaCy has copyleft dependencies or may download copyleft content, and it\nis built only for Natural Language Processing (NLP) projects. Neuraxle\nis open to any kind of machine learning projects and isn't an NLP-first\nproject.\n\nKubeflow\n~~~~~~~~\n\nKubeflow is cloud-first, using Kubernetes and is more oriented towards\ndevops. Neuraxle isn't built as a cloud-first solution and isn't tied to\nKubernetes. Neuraxle instead offers many parallel processing features,\nsuch as the ability to be scaled on many cores of a computer, and even\non a computer cluster (e.g.: in the cloud using any cloud provider) with\njoblib, using dask's distributed library as a joblib backend. A Neuraxle\nproject is best deployed as a microservice within your software\nenvironment, and you can fully control and customize how you deploy your\nproject (e.g.: coding yourself a pipeline step that does json conversion\nto accept http requests).\n\n\nCommunity\n---------\n\nJoin our `Slack\nworkspace <https://join.slack.com/t/neuraxio/shared_invite/zt-8lyw42c5-4PuWjTT8dQqeFK3at1s_dQ>`__ and our `Gitter <https://gitter.im/Neuraxle/community>`__!\nWe <3 collaborators. You can also subscribe to our `mailing list <https://www.neuraxio.com/en/blog/index.html>`__ where we will post updates and news. \n\nFor **technical questions**, we recommend posting them on\n`StackOverflow <https://stackoverflow.com/questions/tagged/machine-learning>`__\nfirst with ``neuraxle`` in the tags (amongst probably ``python`` and\n``machine-learning``), and *then* opening an\n`issue <https://github.com/Neuraxio/Neuraxle/issues>`__ to link to your\nStack Overflow question.\n\nFor **suggestions, comments, and issues**, don't hesitate to open an\n`issue <https://github.com/Neuraxio/Neuraxle/issues>`__.\n\nFor **contributors**, we recommend using the PyCharm code editor and to\nlet it manage the virtual environment, with the default code\nauto-formatter, and using pytest as a test runner. To contribute, first\nfork the project, then do your changes, and then open a pull request in\nthe main repository. Please make your pull request(s) editable, such as\nfor us to add you to the list of contributors if you didn't add the\nentry, for example. Ensure that all tests run before opening a pull\nrequest. You'll also agree that your contributions will be licensed\nunder the `Apache 2.0\nLicense <https://github.com/Neuraxio/Neuraxle/blob/master/LICENSE>`__,\nwhich is required for everyone to be able to use your open-source\ncontributions.\n\nLicense\n~~~~~~~\n\nNeuraxle is licensed under the `Apache License, Version\n2.0 <https://github.com/Neuraxio/Neuraxle/blob/master/LICENSE>`__.\n\nCitation\n~~~~~~~~~~~~\n\nYou may cite our `extended abstract <https://www.researchgate.net/publication/337002011_Neuraxle_-_A_Python_Framework_for_Neat_Machine_Learning_Pipelines>`__ that was presented at the Montreal Artificial Intelligence Symposium (MAIS) 2019. Here is the bibtex code to cite:\n\n.. code:: bibtex\n\n    @misc{neuraxle,\n    author = {Chevalier, Guillaume and Brillant, Alexandre and Hamel, Eric},\n    year = {2019},\n    month = {09},\n    pages = {},\n    title = {Neuraxle - A Python Framework for Neat Machine Learning Pipelines},\n    doi = {10.13140/RG.2.2.33135.59043}\n    }\n\nContributors\n~~~~~~~~~~~~\n\nThanks to everyone who contributed to the project:\n\n-  Guillaume Chevalier: https://github.com/guillaume-chevalier\n-  Alexandre Brillant: https://github.com/alexbrillant\n-  \u00c9ric Hamel: https://github.com/Eric2Hamel\n-  J\u00e9r\u00f4me Blanchet: https://github.com/JeromeBlanchet\n-  Micha\u00ebl L\u00e9vesque-Dion: https://github.com/mlevesquedion\n-  Philippe Racicot: https://github.com/Vaunorage\n\nSupported By\n~~~~~~~~~~~~\n\nWe thank these organisations for generously supporting the project:\n\n-  Neuraxio Inc.: https://github.com/Neuraxio\n-  Uman\u00e9o Technologies Inc.: https://www.umaneo.com/\n-  Solution Nexam Inc.: https://www.nexam.io/\n-  La Cit\u00e9, LP: http://www.lacitelp.com/", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/Neuraxio/Neuraxle/tarball/0.4.0", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Neuraxio/Neuraxle", "keywords": "pipeline pipelines data science machine learning deep learning", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "neuraxle", "package_url": "https://pypi.org/project/neuraxle/", "platform": "", "project_url": "https://pypi.org/project/neuraxle/", "project_urls": {"Download": "https://github.com/Neuraxio/Neuraxle/tarball/0.4.0", "Homepage": "https://github.com/Neuraxio/Neuraxle"}, "release_url": "https://pypi.org/project/neuraxle/0.4.0/", "requires_dist": null, "requires_python": "", "summary": "Neuraxle is a Machine Learning (ML) library for building neat pipelines, providing the right abstractions to both ease research, development, and deployment of your ML applications.", "version": "0.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <blockquote>\nCode Machine Learning Pipelines - The Right Way.</blockquote>\n<a href=\"https://github.com/Neuraxio/Neuraxle\" rel=\"nofollow\"><img alt=\"https://img.shields.io/github/workflow/status/Neuraxio/Neuraxle/Test%20Python%20Package/master?:alt:Build\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ff99d64b218b8ad1e30b2c11ba7487a1ae278b1b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f776f726b666c6f772f7374617475732f4e6575726178696f2f4e65757261786c652f54657374253230507974686f6e2532305061636b6167652f6d61737465723f3a616c743a4275696c64\"></a>\n<a href=\"https://gitter.im/Neuraxle/community\" rel=\"nofollow\"><img alt=\"https://img.shields.io/gitter/room/Neuraxio/Neuraxle?:alt:Gitter\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ea40b44f564f3e6f6b2bcbf4864c2998d219fbf9/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f4e6575726178696f2f4e65757261786c653f3a616c743a476974746572\"></a>\n<a href=\"https://www.neuraxle.org/stable/Neuraxle/README.html#license\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/l/neuraxle?:alt:PyPI-License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ef66cec8f123b00e3cea36a6973bf653f6de4664/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6e65757261786c653f3a616c743a507950492d4c6963656e7365\"></a>\n<a href=\"https://pypi.org/project/neuraxle/\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/dm/neuraxle?:alt:PyPI-Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1dc7cffcfa14c7aa556c0ad0096550de1e0415aa/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6e65757261786c653f3a616c743a507950492d446f776e6c6f616473\"></a>\n<a href=\"https://github.com/Neuraxio/Neuraxle\" rel=\"nofollow\"><img alt=\"https://img.shields.io/github/commit-activity/m/neuraxio/neuraxle?:alt:GitHubcommitactivity\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a2fbe3baa8a945965621bf476c4c1873ad4b08f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6e6575726178696f2f6e65757261786c653f3a616c743a476974487562636f6d6d69746163746976697479\"></a>\n<a href=\"https://pypi.org/project/neuraxle/\" rel=\"nofollow\"><img alt=\"https://img.shields.io/github/v/release/neuraxio/neuraxle?:alt:GitHubrelease(latestbydate)\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1dec8f68ae8104f989a22fb5e13af7e8751bef6e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6e6575726178696f2f6e65757261786c653f3a616c743a47697448756272656c65617365286c617465737462796461746529\"></a>\n<p>Neuraxle is a Machine Learning (ML) library for building neat pipelines,\nproviding the right abstractions to both ease research, development, and\ndeployment of your ML applications.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Simply do:</p>\n<pre>pip install neuraxle\n</pre>\n</div>\n<div id=\"quickstart\">\n<h2>Quickstart</h2>\n<p>One of Neuraxle\u2019s most important goals is to make powerful machine\nlearning pipelines easy to build and deploy. Using Neuraxle should be\nlight, painless and obvious, yet without sacrificing powerfulness,\nperformance, nor possibilities.</p>\n<p>For example, you can build a pipeline composed of multiple steps as\nsuch:</p>\n<pre><span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">([</span>\n    <span class=\"c1\"># A Pipeline is composed of multiple chained steps. Steps</span>\n    <span class=\"c1\"># can alter the data before passing it to the next steps.</span>\n    <span class=\"n\">AddFeatures</span><span class=\"p\">([</span>\n        <span class=\"c1\"># Add (concatenate) features in parallel, that are</span>\n        <span class=\"c1\"># themselves derived of the existing features:</span>\n        <span class=\"n\">PCA</span><span class=\"p\">(</span><span class=\"n\">n_components</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">),</span>\n        <span class=\"n\">FastICA</span><span class=\"p\">(</span><span class=\"n\">n_components</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">),</span>\n    <span class=\"p\">]),</span>\n    <span class=\"n\">RidgeModelStacking</span><span class=\"p\">([</span>\n        <span class=\"c1\"># Here is an ensemble of 4 models or feature extractors,</span>\n        <span class=\"c1\"># That are themselves then fed to a ridge regression which</span>\n        <span class=\"c1\"># will act as a judge to finalize the prediction.</span>\n        <span class=\"n\">LinearRegression</span><span class=\"p\">(),</span>\n        <span class=\"n\">LogisticRegression</span><span class=\"p\">(),</span>\n        <span class=\"n\">GradientBoostingRegressor</span><span class=\"p\">(</span><span class=\"n\">n_estimators</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">),</span>\n        <span class=\"n\">GradientBoostingRegressor</span><span class=\"p\">(</span><span class=\"n\">max_depth</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">),</span>\n        <span class=\"n\">KMeans</span><span class=\"p\">(),</span>\n    <span class=\"p\">])</span>\n<span class=\"p\">])</span>\n<span class=\"c1\"># Note: here all the steps were imported from scikit-learn,</span>\n<span class=\"c1\"># but the goal is that you can also define your own as needed.</span>\n<span class=\"c1\"># Also note that a pipeline is a step itself: you can nest them.</span>\n\n<span class=\"c1\"># The pipeline will learn on the data and acquire state.</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Once it learned, the pipeline can process new and</span>\n<span class=\"c1\"># unseen data for making predictions.</span>\n<span class=\"n\">y_test_predicted</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n</pre>\n<p>Visit the\n<a href=\"https://www.neuraxle.org/stable/examples/index.html\" rel=\"nofollow\">examples</a>\nto get more a feeling of how it works, and inspiration.</p>\n</div>\n<div id=\"deep-learning-pipelines\">\n<h2>Deep Learning Pipelines</h2>\n<p>Here is how to use deep learning algorithms within a Neuraxle Pipeline.</p>\n<div id=\"deep-learning-pipeline-definition\">\n<h3>Deep Learning Pipeline Definition</h3>\n<p>Defining a Deep Learning pipeline is more complex.\nIt needs a composition of many steps to:</p>\n<ul>\n<li>Loop on data for many epochs, but just during training.</li>\n<li>Shuffle the data, just during training.</li>\n<li>Use minibatches to process the data, which avoids to blow RAM. Your steps will fit incrementally.</li>\n<li>Process data that is 2D, 3D, 4D, or even 5D or ND, with transformers made for 2D data slices.</li>\n<li>Actually use your Deep Learning algorithm within your pipeline for it to learn and predict.</li>\n</ul>\n<p>Below, we define a pipeline for time series classification using\na LSTM RNN. It includes data preprocessing steps as well as the\ndata flow management. <a href=\"https://qr.ae/TZjoMb\" rel=\"nofollow\">Time Series data is 3D</a>.</p>\n<pre><span class=\"n\">deep_learning_seq_classif_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">EpochRepeater</span><span class=\"p\">(</span><span class=\"n\">Pipeline</span><span class=\"p\">([</span>\n    <span class=\"c1\"># X data shape: (batch, different_lengths, n_feature_columns)</span>\n    <span class=\"c1\"># y data shape: (batch, different_lengths)</span>\n    <span class=\"c1\"># Split X and Y into windows using</span>\n    <span class=\"c1\"># an InputAndOutputTransformerMixin</span>\n    <span class=\"c1\"># abstraction to transform y too:</span>\n    <span class=\"n\">SliceTimeSeries</span><span class=\"p\">(</span><span class=\"n\">window_size</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">last_label_as_seq_label</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n    <span class=\"c1\"># X data shape: (more_than_batch, 128, n_feature_columns)</span>\n    <span class=\"c1\"># y data shape: (more_than_batch, 128)</span>\n    <span class=\"n\">TrainOnlyWrapper</span><span class=\"p\">(</span><span class=\"n\">DataShuffler</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)),</span>\n    <span class=\"n\">MiniBatchSequentialPipeline</span><span class=\"p\">([</span>\n        <span class=\"c1\"># X data shape: (batch_size, 128, n_feature_columns)</span>\n        <span class=\"c1\"># y data shape: (batch_size, 128)</span>\n        <span class=\"c1\"># Loop on 2D slices of the batch's 3D time series</span>\n        <span class=\"c1\"># data cube to apply 2D transformers:</span>\n        <span class=\"n\">ForEachDataInput</span><span class=\"p\">(</span><span class=\"n\">Pipeline</span><span class=\"p\">([</span>\n            <span class=\"c1\"># X data shape: (128, n_feature_columns)</span>\n            <span class=\"c1\"># y data shape: (128)</span>\n            <span class=\"c1\"># This step will load the lazy-loadable data</span>\n            <span class=\"c1\"># into a brick:</span>\n            <span class=\"n\">ToNumpy</span><span class=\"p\">(</span><span class=\"n\">np_dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">),</span>\n            <span class=\"c1\"># Fill nan and inf values with 0:</span>\n            <span class=\"n\">DefaultValuesFiller</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">),</span>\n            <span class=\"c1\"># Transform the columns (that is the innermost</span>\n            <span class=\"c1\"># axis/dim of data named `n_feature_columns`):</span>\n            <span class=\"n\">ColumnTransformer</span><span class=\"p\">([</span>\n                <span class=\"c1\"># Columns 0, 1, 2, 3 and 4 needs to be</span>\n                <span class=\"c1\"># normalized by mean and variance (std):</span>\n                <span class=\"p\">(</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"n\">MeanVarianceNormalizer</span><span class=\"p\">()),</span>\n                <span class=\"c1\"># Column 5 needs to have it's `log plus 1`</span>\n                <span class=\"c1\"># value taken before normalization.</span>\n                <span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">Pipeline</span><span class=\"p\">([</span>\n                    <span class=\"n\">Log1P</span><span class=\"p\">(),</span>\n                    <span class=\"n\">MeanVarianceNormalizer</span><span class=\"p\">()</span>\n                <span class=\"p\">]))</span>\n                <span class=\"c1\"># Note that omited columns are discarded.</span>\n                <span class=\"c1\"># Also, multiple transformers on a column will</span>\n                <span class=\"c1\"># concatenate the results.</span>\n            <span class=\"p\">]),</span>\n            <span class=\"c1\"># Transform the labels' indices to one-hot vectors.</span>\n            <span class=\"n\">OutputTransformerWrapper</span><span class=\"p\">(</span>\n                <span class=\"n\">OneHotEncoder</span><span class=\"p\">(</span><span class=\"n\">nb_columns</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'labels'</span><span class=\"p\">))</span>\n            <span class=\"c1\"># X data shape: (128, n_feature_columns)</span>\n            <span class=\"c1\"># y data shape: (128, 6)</span>\n        <span class=\"p\">])),</span>\n        <span class=\"c1\"># X data shape: (batch_size, 128, n_feature_columns)</span>\n        <span class=\"c1\"># y data shape: (batch_size, 128, 6)</span>\n        <span class=\"c1\"># Classification with a deep neural network,</span>\n        <span class=\"c1\"># using the Neuraxle-TensorFlow and/or</span>\n        <span class=\"c1\"># Neuraxle-PyTorch extensions:</span>\n        <span class=\"n\">ClassificationLSTM</span><span class=\"p\">(</span><span class=\"n\">n_stacked</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n_residual</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">),</span>\n        <span class=\"c1\"># X data shape: (batch_size, 128, 6)</span>\n        <span class=\"c1\"># y data shape: (batch_size, 128, 6)</span>\n    <span class=\"p\">],</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">),</span>\n    <span class=\"c1\"># X data shape: (batch_size, 128, 6)</span>\n<span class=\"p\">]),</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">200</span><span class=\"p\">,</span> <span class=\"n\">fit_only</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"deep-learning-pipeline-training-and-evaluation\">\n<h3>Deep Learning Pipeline Training and Evaluation</h3>\n<p>Here we train and evaluate with a train-validation split. Note that\nautomatic hyperparameter tuning would require only a few more lines\nof code: see our\n<a href=\"https://www.neuraxle.org/stable/examples/boston_housing_meta_optimization.html#sphx-glr-examples-boston-housing-meta-optimization-py\" rel=\"nofollow\">hyperparameter tuning example</a>.</p>\n<pre><span class=\"c1\"># Wrap the pipeline by a validation strategy,</span>\n<span class=\"c1\"># this could have been Cross Validation as well:</span>\n<span class=\"n\">training_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">ValidationSplitWrapper</span><span class=\"p\">(</span>\n    <span class=\"n\">deep_learning_seq_classif_pipeline</span><span class=\"p\">,</span>\n    <span class=\"n\">val_size</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span>\n    <span class=\"n\">scoring_function</span><span class=\"o\">=</span><span class=\"n\">sklearn</span><span class=\"o\">.</span><span class=\"n\">metrics</span><span class=\"o\">.</span><span class=\"n\">accuracy_score</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Fitting and evaluating the pipeline.</span>\n<span class=\"c1\"># X_train data shape: (batch, different_lengths, n_feature_columns)</span>\n<span class=\"c1\"># y_train data shape: (batch, different_lengths)</span>\n<span class=\"n\">training_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n<span class=\"c1\"># Note that X_train and y_train can be lazy loaders.</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Train accuracy: </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span>\n    <span class=\"n\">training_pipeline</span><span class=\"o\">.</span><span class=\"n\">scores_train_mean</span><span class=\"p\">))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Validation accuracy: </span><span class=\"si\">{}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span>\n    <span class=\"n\">training_pipeline</span><span class=\"o\">.</span><span class=\"n\">scores_validation_mean</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># Recover the pipeline in test mode:</span>\n<span class=\"n\">production_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">training_pipeline</span><span class=\"o\">.</span><span class=\"n\">get_step</span><span class=\"p\">()</span>\n<span class=\"n\">production_pipeline</span><span class=\"o\">.</span><span class=\"n\">set_train</span><span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"deep-learning-production-pipeline\">\n<h3>Deep Learning Production Pipeline</h3>\n<p>Deploying your deep learning app to a JSON REST API. Refer\nto <a href=\"https://flask.palletsprojects.com/en/1.1.x/tutorial/deploy/\" rel=\"nofollow\">Flask\u2019s deployment documentation</a>\nfor more info on deployment servers and security.</p>\n<pre><span class=\"c1\"># Will now serve the pipeline to a REST API as an example:</span>\n<span class=\"c1\"># Note that having saved the pipeline to disk</span>\n<span class=\"c1\"># (for reloading this in another file) would be easy, too, using savers.</span>\n<span class=\"n\">app</span> <span class=\"o\">=</span> <span class=\"n\">FlaskRestApiWrapper</span><span class=\"p\">(</span>\n    <span class=\"n\">json_decoder</span><span class=\"o\">=</span><span class=\"n\">YourCustomJSONDecoderFor2DArray</span><span class=\"p\">(),</span>\n    <span class=\"n\">wrapped</span><span class=\"o\">=</span><span class=\"n\">production_pipeline</span><span class=\"p\">,</span>\n    <span class=\"n\">json_encoder</span><span class=\"o\">=</span><span class=\"n\">YourCustomJSONEncoderOfOutputs</span><span class=\"p\">()</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get_app</span><span class=\"p\">()</span>\n<span class=\"n\">app</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">debug</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">port</span><span class=\"o\">=</span><span class=\"mi\">5000</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"calling-a-deployed-pipeline\">\n<h3>Calling a Deployed Pipeline</h3>\n<p>This could be ran from another distant computer to call your app:</p>\n<pre><span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">APICaller</span><span class=\"p\">(</span>\n    <span class=\"n\">json_encoder</span><span class=\"o\">=</span><span class=\"n\">YourCustomJSONEncoderOfInputs</span><span class=\"p\">(),</span>\n    <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s2\">\"http://127.0.0.1:5000/\"</span><span class=\"p\">,</span>\n    <span class=\"n\">json_decoder</span><span class=\"o\">=</span><span class=\"n\">YourCustomJSONDecoderOfOutputs</span><span class=\"p\">()</span>\n<span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">)</span>\n</pre>\n<p>Note that we\u2019ll soon have better remote proxy design patterns for distant\npipelines, and distant parallel processing and distant parallel training.</p>\n</div>\n</div>\n<div id=\"why-neuraxle\">\n<h2>Why Neuraxle?</h2>\n<div id=\"production-ready\">\n<h3>Production-ready</h3>\n<p>Most research projects don\u2019t ever get to production. However, you want\nyour project to be production-ready and already adaptable (clean) by the\ntime you finish it. You also want things to be simple so that you can\nget started quickly.</p>\n<p>Most existing machine learning pipeline frameworks are either too simple\nor too complicated for medium-scale projects. Neuraxle is balanced for\nmedium-scale projects, providing simple, yet powerful abstractions that\nare ready to be used.</p>\n</div>\n<div id=\"compatibility\">\n<h3>Compatibility</h3>\n<blockquote>\nNeuraxle is built as a framework that enables you to define your own\npipeline steps.</blockquote>\n<p>This means that you can use\n<a href=\"https://arxiv.org/pdf/1201.0490v4.pdf\" rel=\"nofollow\">scikit-learn</a>,\n<a href=\"https://keras.io/\" rel=\"nofollow\">Keras</a>,\n<a href=\"https://arxiv.org/pdf/1603.04467v2.pdf\" rel=\"nofollow\">TensorFlow</a>,\n<a href=\"https://openreview.net/pdf?id=BJJsrmfCZ\" rel=\"nofollow\">PyTorch</a>,\n<a href=\"https://pdfs.semanticscholar.org/d4f4/9717c9adb46137f49606ebbdf17e3598b5a5.pdf\" rel=\"nofollow\">Hyperopt</a>,\n<a href=\"https://arxiv.org/pdf/1712.05889v2.pdf\" rel=\"nofollow\">Ray</a>\nand/or <strong>any other machine learning library</strong> you like within and\nthroughout your Neuraxle pipelines.</p>\n</div>\n<div id=\"parallel-computing-and-serialization\">\n<h3>Parallel Computing and Serialization</h3>\n<p>Neuraxle offer multiple parallel processing features. One magical thing\nthat we did are Savers. Savers allow you to define how a step can be\nserialized. This way, it\u2019s possible to avoid Python\u2019s parallel\nprocessing limitations and pitfalls.</p>\n<p>Let\u2019s suppose that your pipeline has a step that imports code from\nanother library and that this code isn\u2019t serializable (e.g.: some\ncode written in C++ and interacting with the GPUs or anything funky).\nTo make this step serializable, just define a saver which will tell\nthe step how to dump itself to disk and reload itself. This will\nallow the step to be sent to a remote computer or to be threadable\nby reloading the save. The save can be dumped to a RAM disk for\nmore performance and avoid truly writing to disks.</p>\n<p>Neuraxle is compatible with most other ML and DL libraries. We\u2019re\ncurrently already writing savers for PyTorch and TensorFlow in the\n<a href=\"https://github.com/Neuraxio/Neuraxle-PyTorch\" rel=\"nofollow\">Neuraxle-PyTorch</a>\nand <a href=\"https://github.com/Neuraxio/Neuraxle-TensorFlow\" rel=\"nofollow\">Neuraxle-TensorFlow</a>\nextensions of this project.</p>\n</div>\n<div id=\"time-series-processing\">\n<h3>Time Series Processing</h3>\n<p>Although Neuraxle is not limited to just time series processing\nprojects, it\u2019s especially good for those projects, as one of the goals\nof Neuraxle is to provides a few abstractions that are useful for time\nseries projects, as\n<a href=\"https://qr.ae/TZjoMb\" rel=\"nofollow\">Time Series data is often 3D</a> or even ND.</p>\n<p>With the various abstractions that Neuraxle provides, it\u2019s easy to get\nstarted building a time-series processing project. Neuraxle is also the\nbackbone of <a href=\"https://www.neuraxio.com/en/time-series-solution\" rel=\"nofollow\">the Neuraxio Time Series\nproject</a>, which is\na premium software package built on top of Neuraxle for business boost\ntheir time series machine learning projects by providing out-of-the-box\nspecialized pipeline steps. Some of those specialized steps are featured\nin the <a href=\"#deep-learning-pipelines\" rel=\"nofollow\">Deep Learning Pipelines</a> section above.</p>\n<p>Note: <a href=\"https://www.neuraxio.com/en/time-series-solution\" rel=\"nofollow\">the Neuraxio Time Series\nproject</a> is\ndifferent from the Neuraxle project, those are separate projects.\nNeuraxio is commited to build open-source software, and defines itself\nas an open-source company. Learn more on <a href=\"#license\" rel=\"nofollow\">Neuraxle\u2019s\nlicense</a>. The Neuraxle library is free and will always stay\nfree, while Neuraxio Time Series is a premium add-on to Neuraxle.</p>\n</div>\n<div id=\"automatic-machine-learning\">\n<h3>Automatic Machine Learning</h3>\n<p>One of the core goal of this framework is to enable easy automatic\nmachine learning, and also meta-learning. It should be easy to train a\nmeta-optimizer on many different tasks: the optimizer is a model itself\nthat maps features of datasets and features of the hyperparameter space\nto a guessed performance score to predict the best hyperparameters.\nHyperparameter spaces are easily defined with a range, and are only\ncoupled to their respective pipeline steps, rather than being coupled to\nthe whole pipeline, which enable class reuse and more modularity.</p>\n</div>\n</div>\n<div id=\"comparison-to-other-machine-learning-pipeline-frameworks\">\n<h2>Comparison to Other Machine Learning Pipeline Frameworks</h2>\n<div id=\"scikit-learn\">\n<h3>scikit-learn</h3>\n<p>Everything that works in sklearn is also useable in Neuraxle. Neuraxle\nis built in a way that does not replace what already exists. Therefore,\nNeuraxle adds more power to scikit-lean by providing neat abstractions,\nand neuraxle is even retrocompatible with sklean if it ever needed to be\nincluded in an already-existing sklearn pipeline (you can do that by\nusing <tt>.tosklearn()</tt> on your Neuraxle pipeline). We believe that\nNeuraxle helps scikit-learn, and also scikit-learn will help Neuraxle.\nNeuraxle is best used with scikit-learn.</p>\n<p>Also, the top core developers of scikit-learn, Andreas C. M\u00fcller, <a href=\"https://www.youtube.com/embed/Wy6EKjJT79M\" rel=\"nofollow\">gave\na talk</a> in which he lists\nthe elements that are yet to be done in scikit-learn. He refers to\nbuilding bigger pipelines with automatic machine learning, meta\nlearning, improving the abstractions of the search spaces, and he also\npoints out that it would be possible do achieve that in another library\nwhich could reuse scikit-learn. Neuraxle is here to solve those problems\nthat are actually shared by the open-source community in general. Let\u2019s\nmove forward with Neuraxle: join Neuraxle\u2019s <a href=\"#community\" rel=\"nofollow\">community</a>.</p>\n</div>\n<div id=\"apache-beam\">\n<h3>Apache Beam</h3>\n<p>Apache Beam is a big, multi-language project and hence is complicated.\nNeuraxle is pythonic and user-friendly: it\u2019s easy to get started.</p>\n<p>Also, it seems that Apache Beam has GPL and MPL dependencies, which\nmeans Apache Beam might itself be copyleft (?). Neuraxle doesn\u2019t have\nsuch copyleft dependencies.</p>\n</div>\n<div id=\"spacy\">\n<h3>spaCy</h3>\n<p>spaCy has copyleft dependencies or may download copyleft content, and it\nis built only for Natural Language Processing (NLP) projects. Neuraxle\nis open to any kind of machine learning projects and isn\u2019t an NLP-first\nproject.</p>\n</div>\n<div id=\"kubeflow\">\n<h3>Kubeflow</h3>\n<p>Kubeflow is cloud-first, using Kubernetes and is more oriented towards\ndevops. Neuraxle isn\u2019t built as a cloud-first solution and isn\u2019t tied to\nKubernetes. Neuraxle instead offers many parallel processing features,\nsuch as the ability to be scaled on many cores of a computer, and even\non a computer cluster (e.g.: in the cloud using any cloud provider) with\njoblib, using dask\u2019s distributed library as a joblib backend. A Neuraxle\nproject is best deployed as a microservice within your software\nenvironment, and you can fully control and customize how you deploy your\nproject (e.g.: coding yourself a pipeline step that does json conversion\nto accept http requests).</p>\n</div>\n</div>\n<div id=\"community\">\n<h2>Community</h2>\n<p>Join our <a href=\"https://join.slack.com/t/neuraxio/shared_invite/zt-8lyw42c5-4PuWjTT8dQqeFK3at1s_dQ\" rel=\"nofollow\">Slack\nworkspace</a> and our <a href=\"https://gitter.im/Neuraxle/community\" rel=\"nofollow\">Gitter</a>!\nWe &lt;3 collaborators. You can also subscribe to our <a href=\"https://www.neuraxio.com/en/blog/index.html\" rel=\"nofollow\">mailing list</a> where we will post updates and news.</p>\n<p>For <strong>technical questions</strong>, we recommend posting them on\n<a href=\"https://stackoverflow.com/questions/tagged/machine-learning\" rel=\"nofollow\">StackOverflow</a>\nfirst with <tt>neuraxle</tt> in the tags (amongst probably <tt>python</tt> and\n<tt><span class=\"pre\">machine-learning</span></tt>), and <em>then</em> opening an\n<a href=\"https://github.com/Neuraxio/Neuraxle/issues\" rel=\"nofollow\">issue</a> to link to your\nStack Overflow question.</p>\n<p>For <strong>suggestions, comments, and issues</strong>, don\u2019t hesitate to open an\n<a href=\"https://github.com/Neuraxio/Neuraxle/issues\" rel=\"nofollow\">issue</a>.</p>\n<p>For <strong>contributors</strong>, we recommend using the PyCharm code editor and to\nlet it manage the virtual environment, with the default code\nauto-formatter, and using pytest as a test runner. To contribute, first\nfork the project, then do your changes, and then open a pull request in\nthe main repository. Please make your pull request(s) editable, such as\nfor us to add you to the list of contributors if you didn\u2019t add the\nentry, for example. Ensure that all tests run before opening a pull\nrequest. You\u2019ll also agree that your contributions will be licensed\nunder the <a href=\"https://github.com/Neuraxio/Neuraxle/blob/master/LICENSE\" rel=\"nofollow\">Apache 2.0\nLicense</a>,\nwhich is required for everyone to be able to use your open-source\ncontributions.</p>\n<div id=\"license\">\n<h3>License</h3>\n<p>Neuraxle is licensed under the <a href=\"https://github.com/Neuraxio/Neuraxle/blob/master/LICENSE\" rel=\"nofollow\">Apache License, Version\n2.0</a>.</p>\n</div>\n<div id=\"citation\">\n<h3>Citation</h3>\n<p>You may cite our <a href=\"https://www.researchgate.net/publication/337002011_Neuraxle_-_A_Python_Framework_for_Neat_Machine_Learning_Pipelines\" rel=\"nofollow\">extended abstract</a> that was presented at the Montreal Artificial Intelligence Symposium (MAIS) 2019. Here is the bibtex code to cite:</p>\n<pre><span class=\"nc\">@misc</span><span class=\"p\">{</span><span class=\"nl\">neuraxle</span><span class=\"p\">,</span>\n<span class=\"na\">author</span> <span class=\"p\">=</span> <span class=\"s\">{Chevalier, Guillaume and Brillant, Alexandre and Hamel, Eric}</span><span class=\"p\">,</span>\n<span class=\"na\">year</span> <span class=\"p\">=</span> <span class=\"s\">{2019}</span><span class=\"p\">,</span>\n<span class=\"na\">month</span> <span class=\"p\">=</span> <span class=\"s\">{09}</span><span class=\"p\">,</span>\n<span class=\"na\">pages</span> <span class=\"p\">=</span> <span class=\"s\">{}</span><span class=\"p\">,</span>\n<span class=\"na\">title</span> <span class=\"p\">=</span> <span class=\"s\">{Neuraxle - A Python Framework for Neat Machine Learning Pipelines}</span><span class=\"p\">,</span>\n<span class=\"na\">doi</span> <span class=\"p\">=</span> <span class=\"s\">{10.13140/RG.2.2.33135.59043}</span>\n<span class=\"p\">}</span>\n</pre>\n</div>\n<div id=\"contributors\">\n<h3>Contributors</h3>\n<p>Thanks to everyone who contributed to the project:</p>\n<ul>\n<li>Guillaume Chevalier: <a href=\"https://github.com/guillaume-chevalier\" rel=\"nofollow\">https://github.com/guillaume-chevalier</a></li>\n<li>Alexandre Brillant: <a href=\"https://github.com/alexbrillant\" rel=\"nofollow\">https://github.com/alexbrillant</a></li>\n<li>\u00c9ric Hamel: <a href=\"https://github.com/Eric2Hamel\" rel=\"nofollow\">https://github.com/Eric2Hamel</a></li>\n<li>J\u00e9r\u00f4me Blanchet: <a href=\"https://github.com/JeromeBlanchet\" rel=\"nofollow\">https://github.com/JeromeBlanchet</a></li>\n<li>Micha\u00ebl L\u00e9vesque-Dion: <a href=\"https://github.com/mlevesquedion\" rel=\"nofollow\">https://github.com/mlevesquedion</a></li>\n<li>Philippe Racicot: <a href=\"https://github.com/Vaunorage\" rel=\"nofollow\">https://github.com/Vaunorage</a></li>\n</ul>\n</div>\n<div id=\"supported-by\">\n<h3>Supported By</h3>\n<p>We thank these organisations for generously supporting the project:</p>\n<ul>\n<li>Neuraxio Inc.: <a href=\"https://github.com/Neuraxio\" rel=\"nofollow\">https://github.com/Neuraxio</a></li>\n<li>Uman\u00e9o Technologies Inc.: <a href=\"https://www.umaneo.com/\" rel=\"nofollow\">https://www.umaneo.com/</a></li>\n<li>Solution Nexam Inc.: <a href=\"https://www.nexam.io/\" rel=\"nofollow\">https://www.nexam.io/</a></li>\n<li>La Cit\u00e9, LP: <a href=\"http://www.lacitelp.com/\" rel=\"nofollow\">http://www.lacitelp.com/</a></li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6956980, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "fffc65d4ef2e03c342c3dda915f752a2", "sha256": "a1e1b9a17e3dc6849a0bada341a9e06cee70d36b2c5e6533dd9b50063a173edf"}, "downloads": -1, "filename": "neuraxle-0.1.0.tar.gz", "has_sig": false, "md5_digest": "fffc65d4ef2e03c342c3dda915f752a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24949, "upload_time": "2019-06-27T04:59:39", "upload_time_iso_8601": "2019-06-27T04:59:39.637083Z", "url": "https://files.pythonhosted.org/packages/ad/9f/358766d7b10751a64b5b3dad2e662b3b95a9ae5a2efa5ccd5857ae9fd331/neuraxle-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "3e1703c5ac1af89b89cb8186dd1248a1", "sha256": "d8fe69b8a17739680e5867775fc0260bd0219e66009a9e786169bb1f1e323fe5"}, "downloads": -1, "filename": "neuraxle-0.1.1.tar.gz", "has_sig": false, "md5_digest": "3e1703c5ac1af89b89cb8186dd1248a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 827443, "upload_time": "2019-09-26T10:19:51", "upload_time_iso_8601": "2019-09-26T10:19:51.437037Z", "url": "https://files.pythonhosted.org/packages/0f/c2/bc11d7f3a93fb1390ba747e1f2af60d13f6cd4433fa8463b589c9712f080/neuraxle-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "9a4f81527ab0ab3d95e2e7609e8413af", "sha256": "65ecc99e81809c6a876591595156b7591a210f55dc16a78e5e03b9c01416f9d5"}, "downloads": -1, "filename": "neuraxle-0.2.0.tar.gz", "has_sig": false, "md5_digest": "9a4f81527ab0ab3d95e2e7609e8413af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1314982, "upload_time": "2019-10-24T07:02:38", "upload_time_iso_8601": "2019-10-24T07:02:38.509154Z", "url": "https://files.pythonhosted.org/packages/2e/0f/97692fc53a9f177e9399a00192ee6ed850947873c665d9f79ad612acc9fc/neuraxle-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "c75a7302b592b79348399f42fdf66cd4", "sha256": "d706e32a1bff59945a52bbd97b2f334132f6aa9487bbf6010d09756faf472c28"}, "downloads": -1, "filename": "neuraxle-0.2.1.tar.gz", "has_sig": false, "md5_digest": "c75a7302b592b79348399f42fdf66cd4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 48802, "upload_time": "2019-10-30T20:39:07", "upload_time_iso_8601": "2019-10-30T20:39:07.055392Z", "url": "https://files.pythonhosted.org/packages/43/70/fd09edae6e94d6a78149e890e0b2a04b02957e1693fab9082e44acdda005/neuraxle-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "614ab30cb42d13915102d96e64260d08", "sha256": "362081888c773a290d9a4c53186105e0ea6de306aaf54d5327922aff66523ab1"}, "downloads": -1, "filename": "neuraxle-0.2.2.tar.gz", "has_sig": false, "md5_digest": "614ab30cb42d13915102d96e64260d08", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 62868, "upload_time": "2019-12-19T17:29:30", "upload_time_iso_8601": "2019-12-19T17:29:30.608637Z", "url": "https://files.pythonhosted.org/packages/c7/d2/4c8aa38d3bf282e714bfb1b5267bd59c06f42fdf290972d87953e03001f6/neuraxle-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "d1c3f9e452ab7085294819bf79f4629b", "sha256": "148eefcf4e0b66cb1eca4be8bf5426e117fc1936e8b7ac1f2fe217295a9101ce"}, "downloads": -1, "filename": "neuraxle-0.3.0.tar.gz", "has_sig": false, "md5_digest": "d1c3f9e452ab7085294819bf79f4629b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66167, "upload_time": "2019-12-25T10:06:19", "upload_time_iso_8601": "2019-12-25T10:06:19.643709Z", "url": "https://files.pythonhosted.org/packages/7c/4f/6acce8b56844cc9638bcb7242ad11b66d95b246b37f951c02fd58faab640/neuraxle-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "424f2c514d3c439a8359e1a743ebb246", "sha256": "f6b6ce29bb6459dd85919c740f244568069f281a79ccc129b584a09a7f0484d6"}, "downloads": -1, "filename": "neuraxle-0.3.1.tar.gz", "has_sig": false, "md5_digest": "424f2c514d3c439a8359e1a743ebb246", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 73344, "upload_time": "2020-01-16T06:15:11", "upload_time_iso_8601": "2020-01-16T06:15:11.807301Z", "url": "https://files.pythonhosted.org/packages/a7/29/756172ef41771567276c93d89ffb1d3eb93990f345cc0a36db10fa182b8c/neuraxle-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "775a8ea2d8d8464dbd8cdb80ac6e9959", "sha256": "ece9e7b833037554f222d6360cb4317230f6957e042bb2383445a892e7b7ac11"}, "downloads": -1, "filename": "neuraxle-0.3.2.tar.gz", "has_sig": false, "md5_digest": "775a8ea2d8d8464dbd8cdb80ac6e9959", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 77639, "upload_time": "2020-02-19T14:06:19", "upload_time_iso_8601": "2020-02-19T14:06:19.759646Z", "url": "https://files.pythonhosted.org/packages/61/05/39f2ff30292db7f5b7a44ce586ca06d2380eaac56e7a06592b109f4b6115/neuraxle-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "2a06416f0c6846554e5013d7ff632a4f", "sha256": "f2bbba9a0177e5ea36f8164891f36fff3906f340d82827e79573fda4018dfc33"}, "downloads": -1, "filename": "neuraxle-0.3.3.tar.gz", "has_sig": false, "md5_digest": "2a06416f0c6846554e5013d7ff632a4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 88362, "upload_time": "2020-03-12T00:31:11", "upload_time_iso_8601": "2020-03-12T00:31:11.368513Z", "url": "https://files.pythonhosted.org/packages/3d/f3/63ca1f8b173013e7593d09fbb977a19dc49068073a8233065ad5a7247ee2/neuraxle-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "022115032c0ed62a70f1d4bee29d12eb", "sha256": "9487af36d0250db72a65ad835d123c286d1f61955968d19c25ae6d0aee9f0f8e"}, "downloads": -1, "filename": "neuraxle-0.3.4.tar.gz", "has_sig": false, "md5_digest": "022115032c0ed62a70f1d4bee29d12eb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 88703, "upload_time": "2020-03-12T08:46:57", "upload_time_iso_8601": "2020-03-12T08:46:57.122774Z", "url": "https://files.pythonhosted.org/packages/10/be/67b42b6bbe05733c1f9e45dc9ca00d5e5e96f041a62c8b91cb479677acee/neuraxle-0.3.4.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "77f088d3c570c7301663388fa39777f6", "sha256": "3fd1211daa36eb2cfe8c022ca9929da076989245615effb1640658100826e02d"}, "downloads": -1, "filename": "neuraxle-0.4.0.tar.gz", "has_sig": false, "md5_digest": "77f088d3c570c7301663388fa39777f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 94612, "upload_time": "2020-04-05T17:50:22", "upload_time_iso_8601": "2020-04-05T17:50:22.837580Z", "url": "https://files.pythonhosted.org/packages/e7/09/db8aec7d80bc4a482649abe9679c1a6645d84b81efa7b4a7f48ee27cf548/neuraxle-0.4.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "77f088d3c570c7301663388fa39777f6", "sha256": "3fd1211daa36eb2cfe8c022ca9929da076989245615effb1640658100826e02d"}, "downloads": -1, "filename": "neuraxle-0.4.0.tar.gz", "has_sig": false, "md5_digest": "77f088d3c570c7301663388fa39777f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 94612, "upload_time": "2020-04-05T17:50:22", "upload_time_iso_8601": "2020-04-05T17:50:22.837580Z", "url": "https://files.pythonhosted.org/packages/e7/09/db8aec7d80bc4a482649abe9679c1a6645d84b81efa7b4a7f48ee27cf548/neuraxle-0.4.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:47 2020"}