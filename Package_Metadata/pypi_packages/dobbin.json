{"info": {"author": "Malthe Borch", "author_email": "mborch@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Operating System :: POSIX", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.1", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Topic :: Database"], "description": "Overview\n========\n\nDobbin is a fast and convenient way to persist a Python object graph\non disk.\n\n  The object graph consists of *persistent nodes*, which are objects\n  that are based on one of the persistent base classes::\n\n    from dobbin.persistent import Persistent\n\n    foo = Persistent()\n    foo.bar = 'baz'\n\n  Each of these nodes can have arbitrary objects connected to it; the\n  only requirement is that Python's `pickle\n  <http://docs.python.org/library/pickle.html>`_ module can serialize\n  the objects.\n\n  Persistent objects are fully object-oriented::\n\n    class Frobnitz(Persistent):\n        ...\n\n  The object graph is built by object reference::\n\n    foo.frob = Frobnitz()\n\n  To commit changes to disk, we use the ``commit()`` method from the\n  `transaction <http://pypi.python.org/pypi/transaction>`_\n  module. Note that we must first elect a root object, thus connecting\n  the object graph to the database handle::\n\n    from dobbin.database import Database\n\n    jar = Database('data.fs')\n    jar.elect(foo)\n\n    transaction.commit()\n\n  Consequently, if we want to make changes to one or more objects in\n  the graph, we must first *check out* the objects in question::\n\n    from dobbin.persistent import checkout\n\n    checkout(foo)\n    foo.bar = 'boz'\n\n    transaction.commit()\n\n  The ``checkout(obj)`` function puts the object in *shared* state. It\n  only works on object that are persistent nodes.\n\nDobbin is available on Python 2.6 and up including Python 3.x.\n\nKey features:\n\n- 100% Python, fully compliant with `PEP8 <http://www.python.org/dev/peps/pep-0008/>`_\n- Threads share data when possible\n- Multi-threaded, multi-process `MVCC\n  <http://en.wikipedia.org/wiki/Multiversion_concurrency_control>`_\n  concurrency model\n- Efficient storage and streaming of binary blobs\n- Pluggable architecture\n\nGetting the code\n----------------\n\nYou can `download <http://pypi.python.org/pypi/Dobbin#downloads>`_ the\npackage from the Python package index or install the latest release\nusing setuptools or the newer `distribute\n<http://packages.python.org/distribute/>`_ (required for Python 3.x)::\n\n  $ easy_install dobbin\n\nNote that this will install the `transaction\n<http://pypi.python.org/pypi/transaction>`_ module as a package\ndependency.\n\nThe project is hosted in a `GitHub repository\n<http://github.com/malthe/dobbin>`_. Code contributions are\nwelcome. The easiest way is to use the `pull request\n<http://help.github.com/pull-requests/>`_ interface.\n\n\nAuthor and license\n------------------\n\nWritten by Malthe Borch <mborch@gmail.com>.\n\nThis software is made available under the BSD license.\n\n\nNotes\n=====\n\nFrequently asked questions\n--------------------------\n\nThis section lists frequently asked questions.\n\n#) How is Dobbin different from ZODB?\n\n   There are other object databases available for Python, most notably\n   `ZODB <http://www.zodb.org/>`_ from Zope Corporation.\n\n   Key differences:\n\n   - Dobbin is written 100% in Python. The persistence layer in ZODB\n     is written in C. ZODB also comes with support for B-Trees; this\n     is also written in C.\n\n   - Dobbin is available on Python 3 (but requires a POSIX-system).\n\n   - ZODB comes with support for B-Trees which allows processes to\n     load objects on demand (because of the implicit weak\n     reference). Dobbin currently loads all data at once and keeps it\n     in memory.\n\n   - Dobbin uses a persistence model that tries to share data in\n     active objects between threads, but relies on an explicit\n     operation to put an object in a mode that allows making changes\n     to it. ZODB shares only inactive object data.\n\n   - ZODB comes with ZEO, an enterprise-level network database layer\n     which allows processes on different machines to connect to the\n     same database.\n\n   - ZODB comes with a memory management system that evicts object\n     data from memory based on usage. Dobbin does not attempt to\n     manage memory consumption, but calls upon the virtual memory\n     manager to swap inactive object data to disk.\n\n#) What is the database file format?\n\n   The default storage option writes transactions sequentially to a\n   single file.\n\n   Each transaction consists of a number of records which consist of a\n   Python pickle and sometimes an attached payload of data (in which\n   case the pickle contains control information). Finally, the\n   transaction ends with a transaction record object, also a Python\n   pickle.\n\n#) Can I connect to a single database with multiple processes?\n\n   Yes.\n\n   The default storage option writes transactions to a single file,\n   which alone makes up the storage record. Multiple processes can\n   connect to the same file and share the same database,\n   concurrently. No further configuration is required; the database\n   uses POSIX file-locking to ensure exclusive write-access and\n   processes automatically stay synchronized.\n\n#) How can I limit memory consumption?\n\n   To avoid memory thrashing, limit the physical memory allowance of\n   your Python processes and make sure there is enough virtual memory\n   available (at least the size of your database) [#]_.\n\n   You may want to compile Python with the ``--without-pymalloc`` flag to\n   use native memory allocation. This may improve performance in\n   applications that connect to large databases due to better paging.\n\n.. [#] On UNIX the ``ulimit`` command can be used limit physical memory\n usage; this prevents thrashing when working with large databases.\n\n\n\nUser's guide\n============\n\nThis is the primary documentation for the database. It uses an\ninteractive narrative which doubles as a doctest. There's a suite of\nregression tests included in the distribution.\n\nYou can run the tests by issuing the following command at the\ncommand-line prompt::\n\n$ python setup.py test\n\nSetup\n-----\n\nThe default storage option writes transactions sequentially in a\nsingle file. It's optimized for long-running processes,\ne.g. application servers.\n\nThe first step is to initialize a database object. To configure it we\nprovide a path on the file system. The path needn't exist already.\n\n>>> from dobbin.database import Database\n>>> db = Database(database_path)\n\nThis particular path does not already exist. This is a new\ndatabase. We can verify it by using the ``len`` method to determine\nthe number of objects stored.\n\n>>> len(db)\n0\n\nThe database uses an object graph persistency model. Objects must be\ntransitively connected to the root node of the database (by Python\nreference).\n\nSince this is an empty database, there is no root object yet.\n\n>>> db.root is None\nTrue\n\nPersistent objects\n------------------\n\nAny persistent object can be elected as the database root\nobject. Persistent objects must inherit from the ``Persistent``\nclass. These objects form the basis of the concurrency model;\noverlapping transactions may write a disjoint set of objects (conflict\nresolution mechanisms are available to ease this requirement).\n\n>>> from dobbin.persistent import Persistent\n>>> obj = Persistent()\n\nPersistent objects begin life in *local* state. In this state we can\nboth read and write attributes. However, when we want to write to an\nobject which has previously been persisted in the database, we must\ncheck it out explicitly using the ``checkout`` method. We will see how\nthis works shortly.\n\n>>> obj.name = 'John'\n>>> obj.name\n'John'\n\nElecting a database root\n------------------------\n\nWe can elect this object as the root of the database.\n\n>>> db.elect(obj)\n>>> obj._p_jar is db\nTrue\n\nThe object is now the root of the object graph. To persist changes on\ndisk, we commit the transaction.\n\n>>> transaction.commit()\n\nAs expected, the database contains one object.\n\n>>> len(db)\n1\n\nThe ``tx_count`` attribute returns the number of transactions which\nhave been written to the database (successful and failed).\n\n>>> db.tx_count\n1\n\nChecking out objects\n--------------------\n\nThe object is now persisted in the database. This means that we must\nnow check it out before we are allowed to write to it.\n\n>>> obj.name = \"John\"\nTraceback (most recent call last):\n ...\nTypeError: Can't set attribute on shared object.\n\nWe use the ``checkout`` method on the object to change its state to\nlocal.\n\n>>> from dobbin.persistent import checkout\n>>> checkout(obj)\n\n.. warning:: Applications must check out already persisted objects before changing their state.\n\nThe ``checkout`` method does not have a return value; this is because\nthe object identity never actually changes. Instead custom attribute\naccessor and mutator methods are used to provide a thread-local object\nstate. This happens transparent to the user.\n\nAfter checking out the object, we can both read and write attributes.\n\n>>> obj.name = 'James'\n\nWhen an object is first checked out by some thread, a counter is set\nto keep track of how many threads have checked out the object. When it\nfalls to zero (always on a transaction boundary), it's retracted to\nthe previous shared state.\n\n>>> transaction.commit()\n\nThis increases the transaction count by one.\n\n>>> db.tx_count\n2\n\nConcurrency\n-----------\n\nThe object manager (which implements the low-level functionality) is\ninherently thread-safe; it uses the MMVC concurrency model.\n\nIt's up to the database which sits on top of the object manager to\nsupport concurrency between external processes sharing the same\ndatabase (the included database implementation uses a file-locking\nscheme to extend the MVCC concurrency model to external processes; no\nconfiguration is required).\n\nWe can demonstrate concurrency between two separate processes by\nrunning a second database instance in the same thread.\n\n>>> new_db = Database(database_path)\n>>> new_obj = new_db.root\n\nObjects from this database are disjoint from those of the first\ndatabase.\n\n>>> new_obj is obj\nFalse\n\nThe new database instance has already read the previously committed\ntransactions and applied them to its object graph.\n\n>>> new_obj.name\n'James'\n\nLet's examine this further. If we check out a persistent object from\nthe first database instance and commit the changes, that same object\nfrom the second database will be updated as soon as we begin a new\ntransaction.\n\n>>> checkout(obj)\n>>> obj.name = 'Jane'\n>>> transaction.commit()\n\nThe database has registered the transaction; the new instance hasn't.\n\n>>> db.tx_count - new_db.tx_count\n1\n\nThe object graphs are not synchronized.\n\n>>> new_obj.name\n'James'\n\nApplications must begin a new transaction to stay in sync.\n\n>>> tx = transaction.begin()\n>>> new_obj.name\n'Jane'\n\nConflicts\n---------\n\nWhen concurrent transactions attempt to modify the same objects, we\nget a write conflict in all but one (first to get the commit-lock wins\nthe transaction).\n\nObjects can provide conflict resolution capabilities such that two\nconcurrent transactions may update the same object.\n\n.. note:: There is no built-in conflict resolution in the persistent base class.\n\nAs an example, let's create a counter object; it could represent a\ncounter which keeps track of visitors on a website. To provide\nconflict resolution for instances of this class, we implement a\n``_p_resolve_conflict`` method.\n\n>>> class Counter(Persistent):\n...     def __init__(self):\n...         self.count = 0\n...\n...     def hit(self):\n...         self.count += 1\n...\n...     @staticmethod\n...     def _p_resolve_conflict(old_state, saved_state, new_state):\n...         saved_diff = saved_state['count'] - old_state['count']\n...         new_diff = new_state['count']- old_state['count']\n...         return {'count': old_state['count'] + saved_diff + new_diff}\n\nAs a doctest technicality, we set the class on the builtins-module\n(there's a difference here between Python 2.x and 3.x series, which\nexplains the fallback import location).\n\n>>> try:\n...     import __builtin__ as builtins\n... except ImportError:\n...     import builtins\n\n>>> builtins.Counter = Counter\n\nNext we instantiate a counter instance, then add it to object graph.\n\n>>> counter = Counter()\n>>> checkout(obj)\n>>> obj.counter = counter\n>>> transaction.commit()\n\nTo demonstrate the conflict resolution functionality of this class, we\nupdate the counter in two concurrent transactions. We will attempt one\nof the transactions in a separate thread.\n\n>>> from threading import Semaphore\n>>> flag = Semaphore()\n>>> flag.acquire()\nTrue\n\n>>> def run():\n...     counter = db.root.counter\n...     assert counter is not None\n...     checkout(counter)\n...     counter.hit()\n...     flag.acquire()\n...     try: transaction.commit()\n...     finally: flag.release()\n\n>>> from threading import Thread\n>>> thread = Thread(target=run)\n>>> thread.start()\n\nIn the main thread we check out the same object and assign a different\nattribute value.\n\n>>> checkout(counter)\n>>> counter.count\n0\n>>> counter.hit()\n\nReleasing the semaphore, the thread will commit the transaction.\n\n>>> flag.release()\n>>> thread.join()\n\nAs we commit the transaction running in the main thread, we expect the\ncounter to have been increased twice.\n\n>>> transaction.commit()\n>>> counter.count\n2\n\nMore objects\n------------\n\nPersistent objects must be connected to the object graph, before\nthey're persisted in the database. If we check out a persistent object\nand commit the transaction without adding it to the object graph, an\nexception is raised.\n\n>>> another = Persistent()\n>>> from dobbin.exc import ObjectGraphError\n>>> try:\n...     transaction.commit()\n... except ObjectGraphError as exc:\n...     print(str(exc))\n<dobbin.persistent.LocalPersistent object at ...> not connected to graph.\n\nWe abort the transaction and try again, this time connecting the\nobject using an attribute reference.\n\n>>> transaction.abort()\n>>> checkout(another)\n>>> another.name = 'Karla'\n>>> checkout(obj)\n>>> obj.another = another\n\nWe commit the transaction and observe that the object count has\ngrown. The new object has been assigned an oid as well (these are not\nin general predictable; they are assigned by the database on commit).\n\n>>> transaction.commit()\n>>> len(db)\n3\n\n>>> another._p_oid is not None\nTrue\n\nIf we begin a new transaction, the new object will propagate to the\nsecond database instance.\n\n>>> tx = transaction.begin()\n>>> new_obj.another.name\n'Karla'\n\nAs we check out the object that carries the reference and access any\nattribute, a deep-copy of the shared state is made behind the\nscenes. Persistent objects are never copied, however, which a simple\nidentity check will confirm.\n\n>>> checkout(obj)\n>>> obj.another is another\nTrue\n\nCircular references are permitted.\n\n>>> checkout(another)\n>>> another.another = obj\n>>> transaction.commit()\n\nAgain, we can verify the identity.\n\n>>> another.another is obj\nTrue\n\nStoring files\n-------------\n\nWe can persist open files (or any stream object) by enclosing them in\na *persistent file* wrapper. The wrapper is immutable; it's for single\nuse only.\n\n>>> from tempfile import TemporaryFile\n>>> file = TemporaryFile()\n>>> length = file.write(b'abc')\n>>> pos = file.seek(0)\n\nNote that the file is read from the current position and until the end\nof the file.\n\n>>> from dobbin.persistent import PersistentFile\n>>> pfile = PersistentFile(file)\n\nLet's store this persistent file as an attribute on our object.\n\n>>> checkout(obj)\n>>> obj.file = pfile\n>>> transaction.commit()\n\nNote that the persistent file has been given a new class. It's the\nsame object (in terms of object identity), but since it's now stored\nin the database and is only available as a file stream, we call it a\n*persistent stream*.\n\n>>> obj.file\n<dobbin.database.PersistentStream object at ...>\n\nWe must manually close the file we provided to the persistent wrapper\n(or let it fall out of scope).\n\n>>> file.close()\n>>> pfile.closed\nTrue\n\nUsing persistent streams\n------------------------\n\nThere are two ways to use persistent streams; either by iterating\nthrough it, in which case it automatically gets a file handle\n(implicitly closed when the iterator is garbage-collected), or through\na file-like API.\n\nWe use the ``open`` method to open the stream; this is always\nrequired when using the stream as a file.\n\n>>> obj.file.open()\n>>> print(obj.file.read().decode('ascii'))\nabc\n\nThe ``seek`` and ``tell`` methods work as expected.\n\n>>> int(obj.file.tell())\n3\n\nWe can seek to the beginning and repeat the exercise.\n\n>>> obj.file.seek(0)\n>>> print(obj.file.read().decode('ascii'))\nabc\n\nAs any file, we have to close it after use.\n\n>>> obj.file.close()\n\nIn addition we can use iteration to read the file; in this case, we\nneedn't bother opening or closing the file. This is automatically done\nfor us. Note that this makes persistent streams suitable as return\nvalues for WSGI applications.\n\n>>> print(\"\".join(thunk.decode('ascii') for thunk in obj.file))\nabc\n\nIteration is strictly independent from the other methods. We can\nobserve that the file remains closed.\n\n>>> obj.file.closed\nTrue\n\nStart a new transaction (to prompt database catch-up) and confirm that\nfile is available from second database.\n\n>>> tx = transaction.begin()\n>>> print(\"\".join(thunk.decode('ascii') for thunk in new_obj.file))\nabc\n\nPersistent dictionary\n---------------------\n\nIt's not advisable in general to use the built-in ``dict`` type to\nstore records in the database, in particular not if you expect\nfrequent minor changes. Instead the ``PersistentDict`` class should be\nused (directly, or subclassed).\n\nIt operates as a normal Python dictionary and provides the same\nmethods.\n\n>>> from dobbin.persistent import PersistentDict\n>>> pdict = PersistentDict()\n\nCheck out objects and connect to object graph.\n\n>>> checkout(obj)\n>>> obj.pdict = pdict\n\nYou can store any key/value combination that works with standard\ndictionaries.\n\n>>> pdict['obj'] = obj\n>>> pdict['obj'] is obj\nTrue\n\nThe ``PersistentDict`` stores attributes, too. Note that attributes\nand dictionary entries are independent from each other.\n\n>>> pdict.name = 'Bob'\n>>> pdict.name\n'Bob'\n\nCommitting the changes.\n\n>>> transaction.commit()\n>>> pdict['obj'] is obj\nTrue\n>>> pdict.name\n'Bob'\n\nSnapshots\n---------\n\nWe can use the ``snapshot`` method to merge all database transactions\nuntil a given timestamp and write the snapshot as a single transaction\nto a new database.\n\n>>> tmp_path = \"%s.tmp\" % database_path\n>>> tmp_db = Database(tmp_path)\n\nTo include all transactions (i.e. the current state), we just pass the\ntarget database.\n\n>>> db.snapshot(tmp_db)\n\nThe snapshot contains three objects.\n\n>>> len(tmp_db)\n4\n\nThey were persisted in a single transaction.\n\n>>> tmp_db.tx_count\n1\n\nWe can confirm that the state indeed matches that of the current\ndatabase.\n\n>>> tmp_obj = tmp_db.root\n\nThe object graph is equal to that of the original database.\n\n>>> tmp_obj.name\n'Jane'\n>>> tmp_obj.another.name\n'Karla'\n>>> tmp_obj.pdict['obj'] is tmp_obj\nTrue\n>>> tmp_obj.pdict.name\n'Bob'\n\nBinary streams are included in the snapshot, too.\n\n>>> print(\"\".join(thunk.decode('ascii') for thunk in tmp_obj.file))\nabc\n\nCleanup\n-------\n\n>>> transaction.commit()\n>>> db.close()\n>>> new_db.close()\n>>> tmp_db.close()\n\nThis concludes the narrative.\n\n\nChanges\n=======\n\n0.3 (2012-02-02)\n----------------\n\n- Add support for Python 3.\n\n- Use C-optimized pickle module when available.\n\n0.2 (2009-10-22)\n----------------\n\n- Subclasses may now override existing methods (e.g. ``__setattr__``)\n  and use ``super`` to get at the overriden method.\n\n- Transactions now see data in isolation.\n\n- When a persistent object is first created, its state is immediately\n  local. This allows an ``__init__`` method to initialize the object.\n\n- Added method to create a snapshot in time of an existing database.\n\n- Added ``PersistentDict`` class.\n\n- The ``Persistent`` class is now persisted as changesets rather than\n  complete object state.\n\n- Set up tests to run using the nose testrunner (or using setuptools).\n\n0.1 (2009-09-26)\n----------------\n\n- Initial public release.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "UNKNOWN", "keywords": "object database persistence", "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "dobbin", "package_url": "https://pypi.org/project/dobbin/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/dobbin/", "project_urls": {"Download": "UNKNOWN", "Homepage": "UNKNOWN"}, "release_url": "https://pypi.org/project/dobbin/0.3/", "requires_dist": null, "requires_python": null, "summary": "Transactional object database, implemented in pure Python.", "version": "0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"overview\">\n<h2>Overview</h2>\n<p>Dobbin is a fast and convenient way to persist a Python object graph\non disk.</p>\n<blockquote>\n<p>The object graph consists of <em>persistent nodes</em>, which are objects\nthat are based on one of the persistent base classes:</p>\n<pre>from dobbin.persistent import Persistent\n\nfoo = Persistent()\nfoo.bar = 'baz'\n</pre>\n<p>Each of these nodes can have arbitrary objects connected to it; the\nonly requirement is that Python\u2019s <a href=\"http://docs.python.org/library/pickle.html\" rel=\"nofollow\">pickle</a> module can serialize\nthe objects.</p>\n<p>Persistent objects are fully object-oriented:</p>\n<pre>class Frobnitz(Persistent):\n    ...\n</pre>\n<p>The object graph is built by object reference:</p>\n<pre>foo.frob = Frobnitz()\n</pre>\n<p>To commit changes to disk, we use the <tt>commit()</tt> method from the\n<a href=\"http://pypi.python.org/pypi/transaction\" rel=\"nofollow\">transaction</a>\nmodule. Note that we must first elect a root object, thus connecting\nthe object graph to the database handle:</p>\n<pre>from dobbin.database import Database\n\njar = Database('data.fs')\njar.elect(foo)\n\ntransaction.commit()\n</pre>\n<p>Consequently, if we want to make changes to one or more objects in\nthe graph, we must first <em>check out</em> the objects in question:</p>\n<pre>from dobbin.persistent import checkout\n\ncheckout(foo)\nfoo.bar = 'boz'\n\ntransaction.commit()\n</pre>\n<p>The <tt>checkout(obj)</tt> function puts the object in <em>shared</em> state. It\nonly works on object that are persistent nodes.</p>\n</blockquote>\n<p>Dobbin is available on Python 2.6 and up including Python 3.x.</p>\n<p>Key features:</p>\n<ul>\n<li>100% Python, fully compliant with <a href=\"http://www.python.org/dev/peps/pep-0008/\" rel=\"nofollow\">PEP8</a></li>\n<li>Threads share data when possible</li>\n<li>Multi-threaded, multi-process <a href=\"http://en.wikipedia.org/wiki/Multiversion_concurrency_control\" rel=\"nofollow\">MVCC</a>\nconcurrency model</li>\n<li>Efficient storage and streaming of binary blobs</li>\n<li>Pluggable architecture</li>\n</ul>\n<div id=\"getting-the-code\">\n<h3>Getting the code</h3>\n<p>You can <a href=\"http://pypi.python.org/pypi/Dobbin#downloads\" rel=\"nofollow\">download</a> the\npackage from the Python package index or install the latest release\nusing setuptools or the newer <a href=\"http://packages.python.org/distribute/\" rel=\"nofollow\">distribute</a> (required for Python 3.x):</p>\n<pre>$ easy_install dobbin\n</pre>\n<p>Note that this will install the <a href=\"http://pypi.python.org/pypi/transaction\" rel=\"nofollow\">transaction</a> module as a package\ndependency.</p>\n<p>The project is hosted in a <a href=\"http://github.com/malthe/dobbin\" rel=\"nofollow\">GitHub repository</a>. Code contributions are\nwelcome. The easiest way is to use the <a href=\"http://help.github.com/pull-requests/\" rel=\"nofollow\">pull request</a> interface.</p>\n</div>\n<div id=\"author-and-license\">\n<h3>Author and license</h3>\n<p>Written by Malthe Borch &lt;<a href=\"mailto:mborch%40gmail.com\">mborch<span>@</span>gmail<span>.</span>com</a>&gt;.</p>\n<p>This software is made available under the BSD license.</p>\n</div>\n</div>\n<div id=\"notes\">\n<h2>Notes</h2>\n<h2 id=\"frequently-asked-questions\"><span class=\"section-subtitle\">Frequently asked questions</span></h2>\n<p>This section lists frequently asked questions.</p>\n<ol>\n<li><p>How is Dobbin different from ZODB?</p>\n<p>There are other object databases available for Python, most notably\n<a href=\"http://www.zodb.org/\" rel=\"nofollow\">ZODB</a> from Zope Corporation.</p>\n<p>Key differences:</p>\n<ul>\n<li>Dobbin is written 100% in Python. The persistence layer in ZODB\nis written in C. ZODB also comes with support for B-Trees; this\nis also written in C.</li>\n<li>Dobbin is available on Python 3 (but requires a POSIX-system).</li>\n<li>ZODB comes with support for B-Trees which allows processes to\nload objects on demand (because of the implicit weak\nreference). Dobbin currently loads all data at once and keeps it\nin memory.</li>\n<li>Dobbin uses a persistence model that tries to share data in\nactive objects between threads, but relies on an explicit\noperation to put an object in a mode that allows making changes\nto it. ZODB shares only inactive object data.</li>\n<li>ZODB comes with ZEO, an enterprise-level network database layer\nwhich allows processes on different machines to connect to the\nsame database.</li>\n<li>ZODB comes with a memory management system that evicts object\ndata from memory based on usage. Dobbin does not attempt to\nmanage memory consumption, but calls upon the virtual memory\nmanager to swap inactive object data to disk.</li>\n</ul>\n</li>\n<li><p>What is the database file format?</p>\n<p>The default storage option writes transactions sequentially to a\nsingle file.</p>\n<p>Each transaction consists of a number of records which consist of a\nPython pickle and sometimes an attached payload of data (in which\ncase the pickle contains control information). Finally, the\ntransaction ends with a transaction record object, also a Python\npickle.</p>\n</li>\n<li><p>Can I connect to a single database with multiple processes?</p>\n<p>Yes.</p>\n<p>The default storage option writes transactions to a single file,\nwhich alone makes up the storage record. Multiple processes can\nconnect to the same file and share the same database,\nconcurrently. No further configuration is required; the database\nuses POSIX file-locking to ensure exclusive write-access and\nprocesses automatically stay synchronized.</p>\n</li>\n<li><p>How can I limit memory consumption?</p>\n<p>To avoid memory thrashing, limit the physical memory allowance of\nyour Python processes and make sure there is enough virtual memory\navailable (at least the size of your database) <a href=\"#id3\" id=\"id2\" rel=\"nofollow\">[1]</a>.</p>\n<p>You may want to compile Python with the <tt><span class=\"pre\">--without-pymalloc</span></tt> flag to\nuse native memory allocation. This may improve performance in\napplications that connect to large databases due to better paging.</p>\n</li>\n</ol>\n<table id=\"id3\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id2\" rel=\"nofollow\">[1]</a></td><td>On UNIX the <tt>ulimit</tt> command can be used limit physical memory\nusage; this prevents thrashing when working with large databases.</td></tr>\n</tbody>\n</table>\n</div>\n<div id=\"user-s-guide\">\n<h2>User\u2019s guide</h2>\n<p>This is the primary documentation for the database. It uses an\ninteractive narrative which doubles as a doctest. There\u2019s a suite of\nregression tests included in the distribution.</p>\n<p>You can run the tests by issuing the following command at the\ncommand-line prompt:</p>\n<pre>$ python setup.py test\n</pre>\n<div id=\"setup\">\n<h3>Setup</h3>\n<p>The default storage option writes transactions sequentially in a\nsingle file. It\u2019s optimized for long-running processes,\ne.g. application servers.</p>\n<p>The first step is to initialize a database object. To configure it we\nprovide a path on the file system. The path needn\u2019t exist already.</p>\n<pre>&gt;&gt;&gt; from dobbin.database import Database\n&gt;&gt;&gt; db = Database(database_path)\n</pre>\n<p>This particular path does not already exist. This is a new\ndatabase. We can verify it by using the <tt>len</tt> method to determine\nthe number of objects stored.</p>\n<pre>&gt;&gt;&gt; len(db)\n0\n</pre>\n<p>The database uses an object graph persistency model. Objects must be\ntransitively connected to the root node of the database (by Python\nreference).</p>\n<p>Since this is an empty database, there is no root object yet.</p>\n<pre>&gt;&gt;&gt; db.root is None\nTrue\n</pre>\n</div>\n<div id=\"persistent-objects\">\n<h3>Persistent objects</h3>\n<p>Any persistent object can be elected as the database root\nobject. Persistent objects must inherit from the <tt>Persistent</tt>\nclass. These objects form the basis of the concurrency model;\noverlapping transactions may write a disjoint set of objects (conflict\nresolution mechanisms are available to ease this requirement).</p>\n<pre>&gt;&gt;&gt; from dobbin.persistent import Persistent\n&gt;&gt;&gt; obj = Persistent()\n</pre>\n<p>Persistent objects begin life in <em>local</em> state. In this state we can\nboth read and write attributes. However, when we want to write to an\nobject which has previously been persisted in the database, we must\ncheck it out explicitly using the <tt>checkout</tt> method. We will see how\nthis works shortly.</p>\n<pre>&gt;&gt;&gt; obj.name = 'John'\n&gt;&gt;&gt; obj.name\n'John'\n</pre>\n</div>\n<div id=\"electing-a-database-root\">\n<h3>Electing a database root</h3>\n<p>We can elect this object as the root of the database.</p>\n<pre>&gt;&gt;&gt; db.elect(obj)\n&gt;&gt;&gt; obj._p_jar is db\nTrue\n</pre>\n<p>The object is now the root of the object graph. To persist changes on\ndisk, we commit the transaction.</p>\n<pre>&gt;&gt;&gt; transaction.commit()\n</pre>\n<p>As expected, the database contains one object.</p>\n<pre>&gt;&gt;&gt; len(db)\n1\n</pre>\n<p>The <tt>tx_count</tt> attribute returns the number of transactions which\nhave been written to the database (successful and failed).</p>\n<pre>&gt;&gt;&gt; db.tx_count\n1\n</pre>\n</div>\n<div id=\"checking-out-objects\">\n<h3>Checking out objects</h3>\n<p>The object is now persisted in the database. This means that we must\nnow check it out before we are allowed to write to it.</p>\n<pre>&gt;&gt;&gt; obj.name = \"John\"\nTraceback (most recent call last):\n ...\nTypeError: Can't set attribute on shared object.\n</pre>\n<p>We use the <tt>checkout</tt> method on the object to change its state to\nlocal.</p>\n<pre>&gt;&gt;&gt; from dobbin.persistent import checkout\n&gt;&gt;&gt; checkout(obj)\n</pre>\n<div>\n<p>Warning</p>\n<p>Applications must check out already persisted objects before changing their state.</p>\n</div>\n<p>The <tt>checkout</tt> method does not have a return value; this is because\nthe object identity never actually changes. Instead custom attribute\naccessor and mutator methods are used to provide a thread-local object\nstate. This happens transparent to the user.</p>\n<p>After checking out the object, we can both read and write attributes.</p>\n<pre>&gt;&gt;&gt; obj.name = 'James'\n</pre>\n<p>When an object is first checked out by some thread, a counter is set\nto keep track of how many threads have checked out the object. When it\nfalls to zero (always on a transaction boundary), it\u2019s retracted to\nthe previous shared state.</p>\n<pre>&gt;&gt;&gt; transaction.commit()\n</pre>\n<p>This increases the transaction count by one.</p>\n<pre>&gt;&gt;&gt; db.tx_count\n2\n</pre>\n</div>\n<div id=\"concurrency\">\n<h3>Concurrency</h3>\n<p>The object manager (which implements the low-level functionality) is\ninherently thread-safe; it uses the MMVC concurrency model.</p>\n<p>It\u2019s up to the database which sits on top of the object manager to\nsupport concurrency between external processes sharing the same\ndatabase (the included database implementation uses a file-locking\nscheme to extend the MVCC concurrency model to external processes; no\nconfiguration is required).</p>\n<p>We can demonstrate concurrency between two separate processes by\nrunning a second database instance in the same thread.</p>\n<pre>&gt;&gt;&gt; new_db = Database(database_path)\n&gt;&gt;&gt; new_obj = new_db.root\n</pre>\n<p>Objects from this database are disjoint from those of the first\ndatabase.</p>\n<pre>&gt;&gt;&gt; new_obj is obj\nFalse\n</pre>\n<p>The new database instance has already read the previously committed\ntransactions and applied them to its object graph.</p>\n<pre>&gt;&gt;&gt; new_obj.name\n'James'\n</pre>\n<p>Let\u2019s examine this further. If we check out a persistent object from\nthe first database instance and commit the changes, that same object\nfrom the second database will be updated as soon as we begin a new\ntransaction.</p>\n<pre>&gt;&gt;&gt; checkout(obj)\n&gt;&gt;&gt; obj.name = 'Jane'\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<p>The database has registered the transaction; the new instance hasn\u2019t.</p>\n<pre>&gt;&gt;&gt; db.tx_count - new_db.tx_count\n1\n</pre>\n<p>The object graphs are not synchronized.</p>\n<pre>&gt;&gt;&gt; new_obj.name\n'James'\n</pre>\n<p>Applications must begin a new transaction to stay in sync.</p>\n<pre>&gt;&gt;&gt; tx = transaction.begin()\n&gt;&gt;&gt; new_obj.name\n'Jane'\n</pre>\n</div>\n<div id=\"conflicts\">\n<h3>Conflicts</h3>\n<p>When concurrent transactions attempt to modify the same objects, we\nget a write conflict in all but one (first to get the commit-lock wins\nthe transaction).</p>\n<p>Objects can provide conflict resolution capabilities such that two\nconcurrent transactions may update the same object.</p>\n<div>\n<p>Note</p>\n<p>There is no built-in conflict resolution in the persistent base class.</p>\n</div>\n<p>As an example, let\u2019s create a counter object; it could represent a\ncounter which keeps track of visitors on a website. To provide\nconflict resolution for instances of this class, we implement a\n<tt>_p_resolve_conflict</tt> method.</p>\n<pre>&gt;&gt;&gt; class Counter(Persistent):\n...     def __init__(self):\n...         self.count = 0\n...\n...     def hit(self):\n...         self.count += 1\n...\n...     @staticmethod\n...     def _p_resolve_conflict(old_state, saved_state, new_state):\n...         saved_diff = saved_state['count'] - old_state['count']\n...         new_diff = new_state['count']- old_state['count']\n...         return {'count': old_state['count'] + saved_diff + new_diff}\n</pre>\n<p>As a doctest technicality, we set the class on the builtins-module\n(there\u2019s a difference here between Python 2.x and 3.x series, which\nexplains the fallback import location).</p>\n<pre>&gt;&gt;&gt; try:\n...     import __builtin__ as builtins\n... except ImportError:\n...     import builtins\n</pre>\n<pre>&gt;&gt;&gt; builtins.Counter = Counter\n</pre>\n<p>Next we instantiate a counter instance, then add it to object graph.</p>\n<pre>&gt;&gt;&gt; counter = Counter()\n&gt;&gt;&gt; checkout(obj)\n&gt;&gt;&gt; obj.counter = counter\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<p>To demonstrate the conflict resolution functionality of this class, we\nupdate the counter in two concurrent transactions. We will attempt one\nof the transactions in a separate thread.</p>\n<pre>&gt;&gt;&gt; from threading import Semaphore\n&gt;&gt;&gt; flag = Semaphore()\n&gt;&gt;&gt; flag.acquire()\nTrue\n</pre>\n<pre>&gt;&gt;&gt; def run():\n...     counter = db.root.counter\n...     assert counter is not None\n...     checkout(counter)\n...     counter.hit()\n...     flag.acquire()\n...     try: transaction.commit()\n...     finally: flag.release()\n</pre>\n<pre>&gt;&gt;&gt; from threading import Thread\n&gt;&gt;&gt; thread = Thread(target=run)\n&gt;&gt;&gt; thread.start()\n</pre>\n<p>In the main thread we check out the same object and assign a different\nattribute value.</p>\n<pre>&gt;&gt;&gt; checkout(counter)\n&gt;&gt;&gt; counter.count\n0\n&gt;&gt;&gt; counter.hit()\n</pre>\n<p>Releasing the semaphore, the thread will commit the transaction.</p>\n<pre>&gt;&gt;&gt; flag.release()\n&gt;&gt;&gt; thread.join()\n</pre>\n<p>As we commit the transaction running in the main thread, we expect the\ncounter to have been increased twice.</p>\n<pre>&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; counter.count\n2\n</pre>\n</div>\n<div id=\"more-objects\">\n<h3>More objects</h3>\n<p>Persistent objects must be connected to the object graph, before\nthey\u2019re persisted in the database. If we check out a persistent object\nand commit the transaction without adding it to the object graph, an\nexception is raised.</p>\n<pre>&gt;&gt;&gt; another = Persistent()\n&gt;&gt;&gt; from dobbin.exc import ObjectGraphError\n&gt;&gt;&gt; try:\n...     transaction.commit()\n... except ObjectGraphError as exc:\n...     print(str(exc))\n&lt;dobbin.persistent.LocalPersistent object at ...&gt; not connected to graph.\n</pre>\n<p>We abort the transaction and try again, this time connecting the\nobject using an attribute reference.</p>\n<pre>&gt;&gt;&gt; transaction.abort()\n&gt;&gt;&gt; checkout(another)\n&gt;&gt;&gt; another.name = 'Karla'\n&gt;&gt;&gt; checkout(obj)\n&gt;&gt;&gt; obj.another = another\n</pre>\n<p>We commit the transaction and observe that the object count has\ngrown. The new object has been assigned an oid as well (these are not\nin general predictable; they are assigned by the database on commit).</p>\n<pre>&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; len(db)\n3\n</pre>\n<pre>&gt;&gt;&gt; another._p_oid is not None\nTrue\n</pre>\n<p>If we begin a new transaction, the new object will propagate to the\nsecond database instance.</p>\n<pre>&gt;&gt;&gt; tx = transaction.begin()\n&gt;&gt;&gt; new_obj.another.name\n'Karla'\n</pre>\n<p>As we check out the object that carries the reference and access any\nattribute, a deep-copy of the shared state is made behind the\nscenes. Persistent objects are never copied, however, which a simple\nidentity check will confirm.</p>\n<pre>&gt;&gt;&gt; checkout(obj)\n&gt;&gt;&gt; obj.another is another\nTrue\n</pre>\n<p>Circular references are permitted.</p>\n<pre>&gt;&gt;&gt; checkout(another)\n&gt;&gt;&gt; another.another = obj\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<p>Again, we can verify the identity.</p>\n<pre>&gt;&gt;&gt; another.another is obj\nTrue\n</pre>\n</div>\n<div id=\"storing-files\">\n<h3>Storing files</h3>\n<p>We can persist open files (or any stream object) by enclosing them in\na <em>persistent file</em> wrapper. The wrapper is immutable; it\u2019s for single\nuse only.</p>\n<pre>&gt;&gt;&gt; from tempfile import TemporaryFile\n&gt;&gt;&gt; file = TemporaryFile()\n&gt;&gt;&gt; length = file.write(b'abc')\n&gt;&gt;&gt; pos = file.seek(0)\n</pre>\n<p>Note that the file is read from the current position and until the end\nof the file.</p>\n<pre>&gt;&gt;&gt; from dobbin.persistent import PersistentFile\n&gt;&gt;&gt; pfile = PersistentFile(file)\n</pre>\n<p>Let\u2019s store this persistent file as an attribute on our object.</p>\n<pre>&gt;&gt;&gt; checkout(obj)\n&gt;&gt;&gt; obj.file = pfile\n&gt;&gt;&gt; transaction.commit()\n</pre>\n<p>Note that the persistent file has been given a new class. It\u2019s the\nsame object (in terms of object identity), but since it\u2019s now stored\nin the database and is only available as a file stream, we call it a\n<em>persistent stream</em>.</p>\n<pre>&gt;&gt;&gt; obj.file\n&lt;dobbin.database.PersistentStream object at ...&gt;\n</pre>\n<p>We must manually close the file we provided to the persistent wrapper\n(or let it fall out of scope).</p>\n<pre>&gt;&gt;&gt; file.close()\n&gt;&gt;&gt; pfile.closed\nTrue\n</pre>\n</div>\n<div id=\"using-persistent-streams\">\n<h3>Using persistent streams</h3>\n<p>There are two ways to use persistent streams; either by iterating\nthrough it, in which case it automatically gets a file handle\n(implicitly closed when the iterator is garbage-collected), or through\na file-like API.</p>\n<p>We use the <tt>open</tt> method to open the stream; this is always\nrequired when using the stream as a file.</p>\n<pre>&gt;&gt;&gt; obj.file.open()\n&gt;&gt;&gt; print(obj.file.read().decode('ascii'))\nabc\n</pre>\n<p>The <tt>seek</tt> and <tt>tell</tt> methods work as expected.</p>\n<pre>&gt;&gt;&gt; int(obj.file.tell())\n3\n</pre>\n<p>We can seek to the beginning and repeat the exercise.</p>\n<pre>&gt;&gt;&gt; obj.file.seek(0)\n&gt;&gt;&gt; print(obj.file.read().decode('ascii'))\nabc\n</pre>\n<p>As any file, we have to close it after use.</p>\n<pre>&gt;&gt;&gt; obj.file.close()\n</pre>\n<p>In addition we can use iteration to read the file; in this case, we\nneedn\u2019t bother opening or closing the file. This is automatically done\nfor us. Note that this makes persistent streams suitable as return\nvalues for WSGI applications.</p>\n<pre>&gt;&gt;&gt; print(\"\".join(thunk.decode('ascii') for thunk in obj.file))\nabc\n</pre>\n<p>Iteration is strictly independent from the other methods. We can\nobserve that the file remains closed.</p>\n<pre>&gt;&gt;&gt; obj.file.closed\nTrue\n</pre>\n<p>Start a new transaction (to prompt database catch-up) and confirm that\nfile is available from second database.</p>\n<pre>&gt;&gt;&gt; tx = transaction.begin()\n&gt;&gt;&gt; print(\"\".join(thunk.decode('ascii') for thunk in new_obj.file))\nabc\n</pre>\n</div>\n<div id=\"persistent-dictionary\">\n<h3>Persistent dictionary</h3>\n<p>It\u2019s not advisable in general to use the built-in <tt>dict</tt> type to\nstore records in the database, in particular not if you expect\nfrequent minor changes. Instead the <tt>PersistentDict</tt> class should be\nused (directly, or subclassed).</p>\n<p>It operates as a normal Python dictionary and provides the same\nmethods.</p>\n<pre>&gt;&gt;&gt; from dobbin.persistent import PersistentDict\n&gt;&gt;&gt; pdict = PersistentDict()\n</pre>\n<p>Check out objects and connect to object graph.</p>\n<pre>&gt;&gt;&gt; checkout(obj)\n&gt;&gt;&gt; obj.pdict = pdict\n</pre>\n<p>You can store any key/value combination that works with standard\ndictionaries.</p>\n<pre>&gt;&gt;&gt; pdict['obj'] = obj\n&gt;&gt;&gt; pdict['obj'] is obj\nTrue\n</pre>\n<p>The <tt>PersistentDict</tt> stores attributes, too. Note that attributes\nand dictionary entries are independent from each other.</p>\n<pre>&gt;&gt;&gt; pdict.name = 'Bob'\n&gt;&gt;&gt; pdict.name\n'Bob'\n</pre>\n<p>Committing the changes.</p>\n<pre>&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; pdict['obj'] is obj\nTrue\n&gt;&gt;&gt; pdict.name\n'Bob'\n</pre>\n</div>\n<div id=\"snapshots\">\n<h3>Snapshots</h3>\n<p>We can use the <tt>snapshot</tt> method to merge all database transactions\nuntil a given timestamp and write the snapshot as a single transaction\nto a new database.</p>\n<pre>&gt;&gt;&gt; tmp_path = \"%s.tmp\" % database_path\n&gt;&gt;&gt; tmp_db = Database(tmp_path)\n</pre>\n<p>To include all transactions (i.e. the current state), we just pass the\ntarget database.</p>\n<pre>&gt;&gt;&gt; db.snapshot(tmp_db)\n</pre>\n<p>The snapshot contains three objects.</p>\n<pre>&gt;&gt;&gt; len(tmp_db)\n4\n</pre>\n<p>They were persisted in a single transaction.</p>\n<pre>&gt;&gt;&gt; tmp_db.tx_count\n1\n</pre>\n<p>We can confirm that the state indeed matches that of the current\ndatabase.</p>\n<pre>&gt;&gt;&gt; tmp_obj = tmp_db.root\n</pre>\n<p>The object graph is equal to that of the original database.</p>\n<pre>&gt;&gt;&gt; tmp_obj.name\n'Jane'\n&gt;&gt;&gt; tmp_obj.another.name\n'Karla'\n&gt;&gt;&gt; tmp_obj.pdict['obj'] is tmp_obj\nTrue\n&gt;&gt;&gt; tmp_obj.pdict.name\n'Bob'\n</pre>\n<p>Binary streams are included in the snapshot, too.</p>\n<pre>&gt;&gt;&gt; print(\"\".join(thunk.decode('ascii') for thunk in tmp_obj.file))\nabc\n</pre>\n</div>\n<div id=\"cleanup\">\n<h3>Cleanup</h3>\n<pre>&gt;&gt;&gt; transaction.commit()\n&gt;&gt;&gt; db.close()\n&gt;&gt;&gt; new_db.close()\n&gt;&gt;&gt; tmp_db.close()\n</pre>\n<p>This concludes the narrative.</p>\n</div>\n</div>\n<div id=\"changes\">\n<h2>Changes</h2>\n<div id=\"id4\">\n<h3>0.3 (2012-02-02)</h3>\n<ul>\n<li>Add support for Python 3.</li>\n<li>Use C-optimized pickle module when available.</li>\n</ul>\n</div>\n<div id=\"id5\">\n<h3>0.2 (2009-10-22)</h3>\n<ul>\n<li>Subclasses may now override existing methods (e.g. <tt>__setattr__</tt>)\nand use <tt>super</tt> to get at the overriden method.</li>\n<li>Transactions now see data in isolation.</li>\n<li>When a persistent object is first created, its state is immediately\nlocal. This allows an <tt>__init__</tt> method to initialize the object.</li>\n<li>Added method to create a snapshot in time of an existing database.</li>\n<li>Added <tt>PersistentDict</tt> class.</li>\n<li>The <tt>Persistent</tt> class is now persisted as changesets rather than\ncomplete object state.</li>\n<li>Set up tests to run using the nose testrunner (or using setuptools).</li>\n</ul>\n</div>\n<div id=\"id6\">\n<h3>0.1 (2009-09-26)</h3>\n<ul>\n<li>Initial public release.</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 791291, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "6c85529b28269d9ae01d7216e1f0b7e0", "sha256": "5d1e4c7f2335b5a70aed336ea94d8152f71678edff84dc031fad729d80d9be44"}, "downloads": -1, "filename": "dobbin-0.1.tar.gz", "has_sig": false, "md5_digest": "6c85529b28269d9ae01d7216e1f0b7e0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25140, "upload_time": "2009-09-26T14:03:30", "upload_time_iso_8601": "2009-09-26T14:03:30.334848Z", "url": "https://files.pythonhosted.org/packages/37/66/a66bf2408d51c509d8340bc785b79f7672d669b5663adbdbfa33da683b15/dobbin-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "c5f7611f62e61711440ffa9b835f26d0", "sha256": "b61c1357713f6fdc8a1dc148a784a332838b540182ef960f79d93d13ea1d7c35"}, "downloads": -1, "filename": "dobbin-0.2.tar.gz", "has_sig": false, "md5_digest": "c5f7611f62e61711440ffa9b835f26d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30622, "upload_time": "2009-10-22T11:04:28", "upload_time_iso_8601": "2009-10-22T11:04:28.886934Z", "url": "https://files.pythonhosted.org/packages/2e/1a/f6a4ab2f1ef3d2fb79c127b96a703fd2d55143da0259e69a89181cfe40b1/dobbin-0.2.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "737179c70f880b9463a1c996e36f6a50", "sha256": "f41ef2df958fa656e1d390adfac92373dec3385a0f05051c135499ba500a50fc"}, "downloads": -1, "filename": "dobbin-0.3.tar.gz", "has_sig": false, "md5_digest": "737179c70f880b9463a1c996e36f6a50", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27785, "upload_time": "2012-03-02T14:48:44", "upload_time_iso_8601": "2012-03-02T14:48:44.383056Z", "url": "https://files.pythonhosted.org/packages/50/93/4d898410e9dc15f3af40b16f85ce21440ea70723415b3356894bc78b55b4/dobbin-0.3.tar.gz", "yanked": false}], "0.3-dev": []}, "urls": [{"comment_text": "", "digests": {"md5": "737179c70f880b9463a1c996e36f6a50", "sha256": "f41ef2df958fa656e1d390adfac92373dec3385a0f05051c135499ba500a50fc"}, "downloads": -1, "filename": "dobbin-0.3.tar.gz", "has_sig": false, "md5_digest": "737179c70f880b9463a1c996e36f6a50", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27785, "upload_time": "2012-03-02T14:48:44", "upload_time_iso_8601": "2012-03-02T14:48:44.383056Z", "url": "https://files.pythonhosted.org/packages/50/93/4d898410e9dc15f3af40b16f85ce21440ea70723415b3356894bc78b55b4/dobbin-0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:03 2020"}