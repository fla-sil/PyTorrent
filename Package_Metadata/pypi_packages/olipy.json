{"info": {"author": "Leonard Richardson", "author_email": "leonardr@segfault.org", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Programming Language :: Python :: Implementation :: CPython", "Topic :: Artistic Software", "Topic :: Text Processing"], "description": "# Olipy\n\nOlipy is a Python library for artistic text generation. Unlike most\nsoftware packages, which have a single, unifying purpose. Olipy is\nmore like a set of art supplies. Each module is designed to help you\nachieve a different aesthetic effect.\n\n# Setup\n\nOlipy is distributed as the `olipy` package on PyPI. Here's how to\nquickly get started from a command line:\n\n```\n# Create a virtual environment.\nvirtualenv env\n\n# Activate the virtual environment.\nsource env/bin/activate\n\n# Install Olipy within the virtual envirionment.\npip install olipy\n\n# Run an example script.\nolipy.apollo\n```\n\nOlipy uses the [`TextBlob`](https://textblob.readthedocs.org/) library\nto parse text. Installing Olipy through `pip` will install\nTextBlob as a dependency, but `TextBlob` has extra dependencies (text corpora) which\nare _not_ installed by `pip`.  Instructions for installing the extra\ndependencies are on the `TextBlob` site, but they boil down to running\n[this Python\nscript](https://raw.github.com/sloria/TextBlob/master/download_corpora.py).\n\n# Example scripts\n\nOlipy is packaged with a number of  scripts which do fun things with\nthe data and algorithms. You can run any of these scripts from a\nvirtual environment that has the `olipy` package installed.\n\n* `olipy.apollo`: Generates dialogue between astronauts and Mission\n  Control. Demonstrates Queneau assembly on dialogue.\n* `olipy.board_games`: Generates board game names and\n  descriptions. Demonstrates complex Queneau assemblies.\n* `olipy.corrupt` \"Corrupts\" whatever text is typed in by adding\n  increasing numbers of diacritical marks. Demonstrates the\n  `gibberish.Corruptor` class.\n* `olipy.dinosaurs`: Generates dinosaur names. Demonstrates Queneau\n  assembly on parts of a word.\n* `olipy.ebooks`: Selects some lines from a public domain text using\n  the *_ebooks algorithm. Demonstrates the\n  `olipy.gutenberg.ProjectGutenbergText`\n  and `olipy.ebooks.EbooksQuotes` classes.\n* `olipy.gibberish`: Prints out 140-character string of aesthetically\n  pleasing(?) gibberish. Demonstrates the `gibberish.Gibberish` class.\n* `olipy.mashteroids`: Generates names and IAU citations for minor\n  planets. Demonstrates Queneau assembly on sentences.\n* `olipy.sonnet`: Generates Shakespearean sonnets using Queneau assembly.\n* `olipy.typewriter`: Retypes whatever you type into it, with added typoes.\n* `olipy.words`: Generates common-looking and obscure-looking English\n  words.\n\n# Module guide\n\n## alphabet.py\n\nA list of interesting groups of Unicode characters -- alphabets, shapes, and so on.\n\n```\nfrom olipy.alphabet import Alphabet\nprint(Alphabet.default().random_choice())\n# \ud835\udd04\ud835\udd05\u212d\ud835\udd07\ud835\udd08\ud835\udd09\ud835\udd0a\u210c\u2111\ud835\udd0d\ud835\udd0e\ud835\udd0f\ud835\udd10\ud835\udd11\ud835\udd12\ud835\udd13\ud835\udd14\u211c\ud835\udd16\ud835\udd17\ud835\udd18\ud835\udd19\ud835\udd1a\ud835\udd1b\ud835\udd1c\u2128\ud835\udd1e\ud835\udd1f\ud835\udd20\ud835\udd21\ud835\udd22\ud835\udd23\ud835\udd24\ud835\udd25\ud835\udd26\ud835\udd27\ud835\udd28\ud835\udd29\ud835\udd2a\ud835\udd2b\ud835\udd2c\ud835\udd2d\ud835\udd2e\ud835\udd2f\ud835\udd30\ud835\udd31\ud835\udd32\ud835\udd33\ud835\udd34\ud835\udd35\ud835\udd36\ud835\udd37\nprint(Alphabet.default().random_choice())\n# \u250c\u2510\u2514\u2518\u251c\u2524\u252c\u2534\u253c\u2550\u2551\u2552\u2553\u2554\u2555\u2556\u2557\u2558\u2559\u255a\u255b\u255c\u255d\u255e\u255f\u2560\u2561\u2562\u2563\u2564\u2565\u2566\u2567\u2568\u2569\u256a\u256b\u256c\u2574\u2575\u2576\u2577\n```\n\nThis module is used heavily by gibberish.py.\n\n# corpora.py\n\nThis module makes it easy to load datasets from Darius\nKazemi's [Corpora Project](https://github.com/dariusk/corpora), as\nwell as additional datasets specific to Olipy -- mostly large word\nlists which the Corpora Project considers out of scope. (These new\ndatasets are discussed at the end of this document.)\n\nOlipy is packaged with a complete copy of the data from the Corpora\nProject, so you don't have to install anything extra. However,\ninstalling the Corpora Project data some other way can give you\ndatasets created since the Olipy package was updated.\n\nThe interface of the `corpora` module is that used by Allison Parrish's\n[`pycorpora`](https://github.com/aparrish/pycorpora/) project. The\ndatasets show up as Python modules which contain Python data\nstructures:\n\n```\nfrom olipy import corpora\nfor city in corpora.geography.large_cities['cities']:\n    print(city)\n# Akron\n# Albequerque\n# Anchorage\n# ...\n```\n\nYou can use `from corpora import` ... to import a particular Corpora\nProject category:\n\n```\nfrom olipy.corpora import governments\nprint(governments.nsa_projects[\"codenames\"][0] # prints \"ARTIFICE\")\n\nfrom olipy.pycorpora import humans\nprint(humans.occupations[\"occupations\"][0] # prints \"accountant\")\n```\n\nAdditionally, corpora supports an API similar to that provided by the Corpora Project node package:\n\n```\nfrom olipy import corpora\n\n# get a list of all categories\ncorpora.get_categories() # [\"animals\", \"archetypes\"...]\n\n# get a list of subcategories for a particular category\ncorpora.get_categories(\"words\") # [\"literature\", \"word_clues\"...]\n\n# get a list of all files in a particular category\ncorpora.get_files(\"animals\") # [\"birds_antarctica\", \"birds_uk\", ...]\n\n# get data deserialized from the JSON data in a particular file\ncorpora.get_file(\"animals\", \"birds_antarctica\") # returns dict w/data\n\n# get file in a subcategory\ncorpora.get_file(\"words/literature\", \"shakespeare_words\")\n```\n\n## ebooks.py\n\nA module for incongruously sampling texts in the style of the infamous\n[https://twitter.com/horse_ebooks](@horse_ebooks). Based on the\n[https://twitter.com/zzt_ebooks](@zzt_ebooks) algorithm by Allison\nParrish.\n\n```\nfrom olipy.ebooks import EbooksQuotes\nfrom olipy import corpora\ndata = corpora.words.literature.fiction.pride_and_prejudice\nfor quote in EbooksQuotes().quotes_in(data['text']):\n    print(quote)\n# They attacked him  in various ways--with barefaced\n# An invitation to dinner\n# Mrs. Bennet\n# ...\n```\n\nExample scripts for ebooks.py:\n\n* example.ebooks.py: Selects some lines from a Project Gutenberg\n  text, with a bias towards the keywords you give it as command-line\n  arguments.\n\n## gibberish.py\n\nA module for those interested in the appearance of Unicode\nglyphs. Its main use is generating aesthetically pleasing gibberish\nusing selected combinations of Unicode code charts.\n\n```\nfrom olipy.gibberish import Gibberish\nprint(Gibberish.random().tweet().encode(\"utf8\"))\n# \u09e0\ud801\udca7\ud801\udc87\u09a6\ud801\udc94\ud801\udc9c\u09d7\ud801\udc83\ud801\udc9d\ud801\udc93\u0986\u09ed\u09ed\u0989\ud801\udc87\u09f6\u09e6\u09a7\u09aa\ud801\udca4\u09ef\u09f0\u09ea\u09a1\u09bc\u0990\u09ac\u09a8\u09a8\u09a4\u09f2\u09ab\u098c\ud801\udc93\u09f4\u09c4\u09c1\u09e6\u09c7\u098f\u09a0\u09f0\ud801\udc94\ud801\udca5\u0997\u09a8\u09bf\u09f6\u0998\ud801\udc8b\u0989\u0999\ud801\udca4\u0999\u099b\u09a4\u09be\u09c3\u09c0\u09ab\u09ee\u09ec\u09f8\u0989\u0995\u09ab\ud801\udc98\u0987\u09ae\u09a2\u09ed\u09c2\u09a3\u098c\u098a\ud801\udc87\ud801\udc8b\u09c0\u0981\u09bf\u09c3\ud801\udc8c\ud801\udc92\u09fa\ud801\udca4\u09fa\u09ad\ud801\udc96\u09ed\ud801\udca4\u09e1\u09f0\u09b2\ud801\udc8a\u09a2\u09bc\u09ce\ud801\udc85\u09af\u09a5\u0996\u09f1\u098c\n# \u0988\u0994\u09eb\u09bd\ud801\udc94\u09e9\u09bc\u09a6\ud801\udc8b\u09e0\u09b8\u09c1\u09af\u09bc\u098a\u09b6\ud801\udc86\ud801\udc96\ud801\udc81\u0994\u09f0\u09b8\u0988\ud801\udc86\u0985\ud801\udc8b\ud801\udc91\ud801\udca8\u09bc\u09a6\u09ef\u09c4\u09eb \ud83d\ude18\n```\n\n## gutenberg.py\n\nA module for dealing with texts from Project Gutenberg. Strips headers\nand footers, and parses the text.\n\n```\nfrom olipy import corpora\nfrom olipy.gutenberg import ProjectGutenbergText\ntext = corpora.words.literature.nonfiction.literary_shrines['text']\ntext = ProjectGutenbergText(text)\nprint(len(text.paragraphs))\n# 1258\n```\n\n## ia.py\n\nA module for dealing with texts from Internet Archive.\n\n```\nimport random\nfrom olipy.ia import Text\n\n# Print a URL to the web reader for a specific title in the IA collection.\nitem = Text(\"yorkchronicle1946poqu\")\nprint(item.reader_url(10))\n# https://archive.org/details/yorkchronicle1946poqu/page/n10\n\n# Pick a random page from a specific title, and print a URL to a\n# reusable image of that page.\nidentifier = \"TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150\"\nitem = Text(identifier)\npage = random.randint(0, item.pages-1)\nprint(item.image_url(page, scale=8))\n# https://ia600106.us.archive.org/BookReader/BookReaderImages.php?zip=/30/items/TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150/TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150_jp2.zip&file=TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150_jp2/TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150_0007.jp2&scale=8\n```\n\n## letterforms.py\n\nA module that knows things about the shapes of Unicode glyphs.\n\n`alternate_spelling` translates from letters of the English alphabet\nto similar-looking characters.\n\n```\nfrom olipy.letterforms import alternate_spelling\nprint(alternate_spelling(\"I love alternate letterforms.\"))\n# \u30f1 \ud835\udc73\ud835\uddae\u24cb\ud835\ude40 \ud835\ude8a\ud835\udcf5\u252f\u24a0\u250c\ud835\udc0d\uff41\u2aea\ud835\udd8a \ud835\udc0b\ud835\uddbe\u07d9\ud835\udcc9\u1971\ud835\ude67\u07d3\ud835\udd60\u250d\u1320\ud835\udc46.\n```\n\n## markov.py\n\nA module for generating new token lists from old token lists using a\nMarkov chain.\n\nOlipy's primary purpose is to promote alternatives to\nMarkov chains (such as Queneau assembly and the *_ebooks algorithm),\nbut sometimes you really do want a Markov chain. Queneau assembly is\nusually better than a Markov chain above the word level (constructing\nparagraphs from sentences) and below the word level (constructing\nwords from phonemes), but Markov chains are usually better when\nassembling sequences of words.\n\nmarkov.py was originally written by Allison \"A. A.\" Parrish.\n\n```\nfrom olipy.markov import MarkovGenerator\nfrom olipy import corpora\ntext = corpora.words.literature.nonfiction.literary_shrines['text']\ng = MarkovGenerator(order=1, max=100)\ng.add(text)\nprint(\" \".join(g.assemble()))\n# The Project Gutenberg-tm trademark.                    Canst thou, e'en thus, thy own savings, went as the gardens, the club. The quarrel occurred between\n# him and his essay on the tea-table. In these that, in Lamb's day, for a stray\n# relic or four years ago, taken with only Adam and _The\n# Corsair_. Writing to his home on his new purple and the young man you might\n# mean nothing on Christmas sports and art seriously instead of references to\n# the heart'--allowed--yet I got out and more convenient.... Mr.\n```\n\n## mosaic.py\n\nTiles Unicode characters together to create symmetrical mosaics.\ngibberish.py uses this module as one of its techniques. Includes\ninformation on Unicode characters whose glyphs appear to be mirror\nimages.\n\n```\nfrom olipy.mosaic import MirroredMosaicGibberish\nmosaic = MirroredMosaicGibberish()\nprint(mosaic.tweet())\n# \u259b\u259e\u2003\u2599\u259e\u2599\u259f\u259a\u259f\u2003\u259a\u259c\n# \u259b\u259e\u259e\u2003\u259e\u259b\u259c\u259a\u2003\u259a\u259a\u259c\n# \u2003\u259e\u2599\u2003\u2003\u259e\u259a\u2003\u2003\u259f\u259a\u2003\n# \u2599\u259a\u259a\u2003\u259a\u2599\u259f\u259e\u2003\u259e\u259e\u259f\n# \u2599\u259a\u2003\u259b\u259a\u259b\u259c\u259e\u259c\u2003\u259e\u259f\n\nprint(gibberish.tweet())\n# \ud83d\ude4c\ud83d\ude4c\ud83d\ude2f\ud83d\udcf6\ud83d\ude4c\ud83d\udc4d\ud83d\udc4d\ud83d\ude4c\ud83d\udcf6\ud83d\ude2f\ud83d\ude4c\ud83d\ude4c\n# \u2003\ud83d\udcf6\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udd60\ud83d\udd60\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udcf6\u2003\n# \ud83d\ude82\ud83d\udc88\ud83c\udf88\ud83d\udd12\ud83d\udeb2\ud83d\udd43\ud83d\udd43\ud83d\udeb2\ud83d\udd12\ud83c\udf88\ud83d\udc88\ud83d\ude82\n# \u2003\ud83d\udcf6\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udd60\ud83d\udd60\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udcf6\u2003\n# \ud83d\ude4c\ud83d\ude4c\ud83d\ude2f\ud83d\udcf6\ud83d\ude4c\ud83d\udc4d\ud83d\udc4d\ud83d\ude4c\ud83d\udcf6\ud83d\ude2f\ud83d\ude4c\ud83d\ude4c\n\n```\n\n## queneau.py\n\nA module for Queneau assembly, a technique pioneered by Raymond\nQueneau in his 1961 book \"Cent mille milliards de po\u00e8mes\" (\"One\nhundred million million poems\"). Queneau assembly randomly creates new\ntexts from a collection of existing texts with identical structure.\n\n```\nfrom olipy.queneau import WordAssembler\nfrom olipy.corpus import Corpus\nassembler = WordAssembler(Corpus.load(\"dinosaurs\"))\nprint(assembler.assemble_word())\n# Trilusmiasunaus\n```\n\n## randomness.py\n\nTechniques for generating random patterns that are more sophisticated\nthan `random.choice`.\n\n### `Gradient`\n\nThe `Gradient` class generates a string of random choices that are\nweighted towards one set of options near the start, and weighted\ntowards another set of options near the end.\n\nHere's a gradient from lowercase letters to uppercase letters:\n\n```\nfrom olipy.randomness import Gradient\nimport string\nprint(\"\".join(Gradient.gradient(string.lowercase, string.uppercase, 40)))\n# rkwyobijqQOzKfdcSHIhYINGrQkBRddEWPHYtORB\n```\n\n### `WanderingMonsterTable`\n\nThe `WanderingMonsterTable` class lets you make a weighted random selection from \none of four buckets. A random selection from the \"common\" bucket will show up 65% of the time, a \nselection from the \"uncommon\" bucket 20% of the time, \"rare\" 11% of the time, and \"very rare\" 4% of \nthe time. (It uses the same probabilities as the first edition of Advanced Dungeons & Dragons.)\n\n```\nfrom olipy.randomness import WanderingMonsterTable\n\nmonsters = WanderingMonsterTable(\n         common=[\"Giant rat\", \"Alligator\"],\n         uncommon=[\"Orc\", \"Hobgoblin\"],\n         rare=[\"Mind flayer\", \"Neo-otyugh\"],\n         very_rare=[\"Flumph\", \"Ygorl, Lord of Entropy\"],\n)\nfor i in range(5):\n    print monsters.choice()\n# Giant rat\n# Alligator\n# Alligator\n# Orc\n# Giant rat\n```\n\ntokenizer.py\n------------\n\nA word tokenizer that performs better than NLTK's default tokenizers\non some common types of English.\n\n```\nfrom nltk.tokenize.treebank import TreebankWordTokenizer\ns = '''Good muffins cost $3.88\\\\nin New York. Email: muffins@example.com'''\nTreebankWordTokenizer().tokenize(s)\n# ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Email', ':', 'muffins', '@', 'example.com']\nWordTokenizer().tokenize(s)\n# ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Email:', 'muffins@example.com']\n```\n\ntypewriter.py\n-------------\n\nSimulates the Adler Universal 39 typewriter used in _The Shining_ and\nthe sorts of typos that would be made on that typewriter. Originally\nwritten for [@a_dull_bot](https://botsin.space/@adullbot).\n\n```\nfrom olipy.typewriter import Typewriter\ntypewriter = Typewriter()\ntypewriter.type(\"All work and no play makes Jack a dull boy.\")\n# 'All work and no play makes Jack a dull bo6.'\n```\n\n# Extra corpora\n\nOlipy makes available several word lists and datasets that aren't in\nthe Corpora Project. These datasets (as well as the standard Corpora\nProject datasets) can be accessed through the `corpora` module. Just\nwrite code like this:\n\n```\nfrom olipy import corpora\nnouns = corpora.words.common_nouns['abstract_nouns']\n```\n\n### `corpora.geography.large_cities`\n\nNames of large U.S. and world cities.\n\n### `corpora.geography.us_states`\n\nThe fifty U.S. states.\n\n### `corpora.language.languages`\n\nNames of languages defined in ISO-639-1\n\n### `corpora.language.unicode_code_sheets`\n\nThe name of every Unicode code sheet, each with the characters found on that sheet.\n\n### `corpora.science.minor_planet_details`\n\n'name', 'number' and IAU 'citation' for named minor planets\n(e.g. asteroids) as of July 2013. The 'discovery' field contains\ndiscovery circumstances. The 'suggested_by' field, when present, has\nbeen split out from the end of the original IAU citation with a simple\nheuristic. The 'citation' field has then been tokenized into sentences\nusing NLTK's Punkt tokenizer and a set of custom abbreviations.\n\nData sources: \n http://www.minorplanetcenter.net/iau/lists/NumberedMPs.html\n http://ssd.jpl.nasa.gov/sbdb.cgi\n\nThis is more complete than the Corpora Project's `minor_planets`,\nwhich only lists the names of the first 1000 minor planets.\n\n### `corpora.words.adjectives`\n\nAbout 5000 English adjectives, sorted roughly by frequency of occurrence.\n\n### `corpora.words.common_nouns`\n\nLists of English nouns, sorted roughly by frequency of occurrence.\n\nIncludes:\n\n* `abstract_nouns` like \"work\" and \"love\".\n* `concrete_nouns` like \"face\" and \"house\".\n* `adjectival_nouns` -- nouns that can also act as adjectives -- like \"chance\" and \"light\".\n\n### `corpora.words.common_verbs`\n\nLists of English verbs, sorted roughly by frequency of occurrence.\n\n* `present_tense` verbs like \"get\" and \"want\".\n* `past_tense` verbs like \"said\" and \"found\".\n* `gerund` forms like \"holding\" and \"leaving\".\n\n### `corpora.words.english_words`\n\nA consolidated list of about 73,000 English words from the FRELI\nproject. (http://www.nkuitse.com/freli/)\n\n### `corpora.words.scribblenauts`\n\nThe top 4000 nouns that were 'concrete' enough to be summonable in the\n2009 game _Scribblenauts_. As always, this list is ordered with more common\nwords towards the front.\n\n### `corpora.words.literature.board_games`\n\nInformation about board games, collected from BoardGameGeek in July\n2013. One JSON object per line.\n\nData source:\n http://boardgamegeek.com/wiki/page/BGG_XML_API2\n\n\n### `corpora.words.literature.fiction.pride_and_prejudice`\n\nThe complete text of a public domain novel (\"Pride and Prejudice\"\nby Jane Austen).\n\n### `corpora.words.literature.nonfiction.apollo_11`\n\nTranscripts of the Apollo 11 mission, presented as dialogue, tokenized\ninto sentences using NLTK's Punkt tokenizer. One JSON object per line.\n\nData sources:\n The Apollo 11 Flight Journal: http://history.nasa.gov/ap11fj/\n The Apollo 11 Surface Journal: http://history.nasa.gov/alsj/\n \"Intended to be a resource for all those interested in the Apollo\n  program, whether in a passing or scholarly capacity.\"\n\n### `corpora.words.literature.nonfiction.literary_shrines`\n\nThe complete text of a public domain nonfiction book (\"Famous Houses\nand Literary Shrines of London\" by A. St. John Adcock).\n\n### `corpora.words.literature.gutenberg_id_mapping`\n\nMaps old-style (pre-2007) Project Gutenberg filenames to the new-style\nebook IDs. For example, \"/etext95/3boat10.zip\" is mapped to the\nnumber 308 (see http://www.gutenberg.org/ebooks/308). Pretty much\nnobody needs this.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/leonardr/olipy/", "keywords": "", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "olipy", "package_url": "https://pypi.org/project/olipy/", "platform": "", "project_url": "https://pypi.org/project/olipy/", "project_urls": {"Homepage": "https://github.com/leonardr/olipy/"}, "release_url": "https://pypi.org/project/olipy/1.0.4/", "requires_dist": ["textblob", "wordfilter", "internetarchive", "requests"], "requires_python": "", "summary": "Python library for artistic text generation", "version": "1.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Olipy</h1>\n<p>Olipy is a Python library for artistic text generation. Unlike most\nsoftware packages, which have a single, unifying purpose. Olipy is\nmore like a set of art supplies. Each module is designed to help you\nachieve a different aesthetic effect.</p>\n<h1>Setup</h1>\n<p>Olipy is distributed as the <code>olipy</code> package on PyPI. Here's how to\nquickly get started from a command line:</p>\n<pre><code># Create a virtual environment.\nvirtualenv env\n\n# Activate the virtual environment.\nsource env/bin/activate\n\n# Install Olipy within the virtual envirionment.\npip install olipy\n\n# Run an example script.\nolipy.apollo\n</code></pre>\n<p>Olipy uses the <a href=\"https://textblob.readthedocs.org/\" rel=\"nofollow\"><code>TextBlob</code></a> library\nto parse text. Installing Olipy through <code>pip</code> will install\nTextBlob as a dependency, but <code>TextBlob</code> has extra dependencies (text corpora) which\nare <em>not</em> installed by <code>pip</code>.  Instructions for installing the extra\ndependencies are on the <code>TextBlob</code> site, but they boil down to running\n<a href=\"https://raw.github.com/sloria/TextBlob/master/download_corpora.py\" rel=\"nofollow\">this Python\nscript</a>.</p>\n<h1>Example scripts</h1>\n<p>Olipy is packaged with a number of  scripts which do fun things with\nthe data and algorithms. You can run any of these scripts from a\nvirtual environment that has the <code>olipy</code> package installed.</p>\n<ul>\n<li><code>olipy.apollo</code>: Generates dialogue between astronauts and Mission\nControl. Demonstrates Queneau assembly on dialogue.</li>\n<li><code>olipy.board_games</code>: Generates board game names and\ndescriptions. Demonstrates complex Queneau assemblies.</li>\n<li><code>olipy.corrupt</code> \"Corrupts\" whatever text is typed in by adding\nincreasing numbers of diacritical marks. Demonstrates the\n<code>gibberish.Corruptor</code> class.</li>\n<li><code>olipy.dinosaurs</code>: Generates dinosaur names. Demonstrates Queneau\nassembly on parts of a word.</li>\n<li><code>olipy.ebooks</code>: Selects some lines from a public domain text using\nthe *_ebooks algorithm. Demonstrates the\n<code>olipy.gutenberg.ProjectGutenbergText</code>\nand <code>olipy.ebooks.EbooksQuotes</code> classes.</li>\n<li><code>olipy.gibberish</code>: Prints out 140-character string of aesthetically\npleasing(?) gibberish. Demonstrates the <code>gibberish.Gibberish</code> class.</li>\n<li><code>olipy.mashteroids</code>: Generates names and IAU citations for minor\nplanets. Demonstrates Queneau assembly on sentences.</li>\n<li><code>olipy.sonnet</code>: Generates Shakespearean sonnets using Queneau assembly.</li>\n<li><code>olipy.typewriter</code>: Retypes whatever you type into it, with added typoes.</li>\n<li><code>olipy.words</code>: Generates common-looking and obscure-looking English\nwords.</li>\n</ul>\n<h1>Module guide</h1>\n<h2>alphabet.py</h2>\n<p>A list of interesting groups of Unicode characters -- alphabets, shapes, and so on.</p>\n<pre><code>from olipy.alphabet import Alphabet\nprint(Alphabet.default().random_choice())\n# \ud835\udd04\ud835\udd05\u212d\ud835\udd07\ud835\udd08\ud835\udd09\ud835\udd0a\u210c\u2111\ud835\udd0d\ud835\udd0e\ud835\udd0f\ud835\udd10\ud835\udd11\ud835\udd12\ud835\udd13\ud835\udd14\u211c\ud835\udd16\ud835\udd17\ud835\udd18\ud835\udd19\ud835\udd1a\ud835\udd1b\ud835\udd1c\u2128\ud835\udd1e\ud835\udd1f\ud835\udd20\ud835\udd21\ud835\udd22\ud835\udd23\ud835\udd24\ud835\udd25\ud835\udd26\ud835\udd27\ud835\udd28\ud835\udd29\ud835\udd2a\ud835\udd2b\ud835\udd2c\ud835\udd2d\ud835\udd2e\ud835\udd2f\ud835\udd30\ud835\udd31\ud835\udd32\ud835\udd33\ud835\udd34\ud835\udd35\ud835\udd36\ud835\udd37\nprint(Alphabet.default().random_choice())\n# \u250c\u2510\u2514\u2518\u251c\u2524\u252c\u2534\u253c\u2550\u2551\u2552\u2553\u2554\u2555\u2556\u2557\u2558\u2559\u255a\u255b\u255c\u255d\u255e\u255f\u2560\u2561\u2562\u2563\u2564\u2565\u2566\u2567\u2568\u2569\u256a\u256b\u256c\u2574\u2575\u2576\u2577\n</code></pre>\n<p>This module is used heavily by gibberish.py.</p>\n<h1>corpora.py</h1>\n<p>This module makes it easy to load datasets from Darius\nKazemi's <a href=\"https://github.com/dariusk/corpora\" rel=\"nofollow\">Corpora Project</a>, as\nwell as additional datasets specific to Olipy -- mostly large word\nlists which the Corpora Project considers out of scope. (These new\ndatasets are discussed at the end of this document.)</p>\n<p>Olipy is packaged with a complete copy of the data from the Corpora\nProject, so you don't have to install anything extra. However,\ninstalling the Corpora Project data some other way can give you\ndatasets created since the Olipy package was updated.</p>\n<p>The interface of the <code>corpora</code> module is that used by Allison Parrish's\n<a href=\"https://github.com/aparrish/pycorpora/\" rel=\"nofollow\"><code>pycorpora</code></a> project. The\ndatasets show up as Python modules which contain Python data\nstructures:</p>\n<pre><code>from olipy import corpora\nfor city in corpora.geography.large_cities['cities']:\n    print(city)\n# Akron\n# Albequerque\n# Anchorage\n# ...\n</code></pre>\n<p>You can use <code>from corpora import</code> ... to import a particular Corpora\nProject category:</p>\n<pre><code>from olipy.corpora import governments\nprint(governments.nsa_projects[\"codenames\"][0] # prints \"ARTIFICE\")\n\nfrom olipy.pycorpora import humans\nprint(humans.occupations[\"occupations\"][0] # prints \"accountant\")\n</code></pre>\n<p>Additionally, corpora supports an API similar to that provided by the Corpora Project node package:</p>\n<pre><code>from olipy import corpora\n\n# get a list of all categories\ncorpora.get_categories() # [\"animals\", \"archetypes\"...]\n\n# get a list of subcategories for a particular category\ncorpora.get_categories(\"words\") # [\"literature\", \"word_clues\"...]\n\n# get a list of all files in a particular category\ncorpora.get_files(\"animals\") # [\"birds_antarctica\", \"birds_uk\", ...]\n\n# get data deserialized from the JSON data in a particular file\ncorpora.get_file(\"animals\", \"birds_antarctica\") # returns dict w/data\n\n# get file in a subcategory\ncorpora.get_file(\"words/literature\", \"shakespeare_words\")\n</code></pre>\n<h2>ebooks.py</h2>\n<p>A module for incongruously sampling texts in the style of the infamous\n<a href=\"@horse_ebooks\" rel=\"nofollow\">https://twitter.com/horse_ebooks</a>. Based on the\n<a href=\"@zzt_ebooks\" rel=\"nofollow\">https://twitter.com/zzt_ebooks</a> algorithm by Allison\nParrish.</p>\n<pre><code>from olipy.ebooks import EbooksQuotes\nfrom olipy import corpora\ndata = corpora.words.literature.fiction.pride_and_prejudice\nfor quote in EbooksQuotes().quotes_in(data['text']):\n    print(quote)\n# They attacked him  in various ways--with barefaced\n# An invitation to dinner\n# Mrs. Bennet\n# ...\n</code></pre>\n<p>Example scripts for ebooks.py:</p>\n<ul>\n<li>example.ebooks.py: Selects some lines from a Project Gutenberg\ntext, with a bias towards the keywords you give it as command-line\narguments.</li>\n</ul>\n<h2>gibberish.py</h2>\n<p>A module for those interested in the appearance of Unicode\nglyphs. Its main use is generating aesthetically pleasing gibberish\nusing selected combinations of Unicode code charts.</p>\n<pre><code>from olipy.gibberish import Gibberish\nprint(Gibberish.random().tweet().encode(\"utf8\"))\n# \u09e0\ud801\udca7\ud801\udc87\u09a6\ud801\udc94\ud801\udc9c\u09d7\ud801\udc83\ud801\udc9d\ud801\udc93\u0986\u09ed\u09ed\u0989\ud801\udc87\u09f6\u09e6\u09a7\u09aa\ud801\udca4\u09ef\u09f0\u09ea\u09a1\u09bc\u0990\u09ac\u09a8\u09a8\u09a4\u09f2\u09ab\u098c\ud801\udc93\u09f4\u09c4\u09c1\u09e6\u09c7\u098f\u09a0\u09f0\ud801\udc94\ud801\udca5\u0997\u09a8\u09bf\u09f6\u0998\ud801\udc8b\u0989\u0999\ud801\udca4\u0999\u099b\u09a4\u09be\u09c3\u09c0\u09ab\u09ee\u09ec\u09f8\u0989\u0995\u09ab\ud801\udc98\u0987\u09ae\u09a2\u09ed\u09c2\u09a3\u098c\u098a\ud801\udc87\ud801\udc8b\u09c0\u0981\u09bf\u09c3\ud801\udc8c\ud801\udc92\u09fa\ud801\udca4\u09fa\u09ad\ud801\udc96\u09ed\ud801\udca4\u09e1\u09f0\u09b2\ud801\udc8a\u09a2\u09bc\u09ce\ud801\udc85\u09af\u09a5\u0996\u09f1\u098c\n# \u0988\u0994\u09eb\u09bd\ud801\udc94\u09e9\u09bc\u09a6\ud801\udc8b\u09e0\u09b8\u09c1\u09af\u09bc\u098a\u09b6\ud801\udc86\ud801\udc96\ud801\udc81\u0994\u09f0\u09b8\u0988\ud801\udc86\u0985\ud801\udc8b\ud801\udc91\ud801\udca8\u09bc\u09a6\u09ef\u09c4\u09eb \ud83d\ude18\n</code></pre>\n<h2>gutenberg.py</h2>\n<p>A module for dealing with texts from Project Gutenberg. Strips headers\nand footers, and parses the text.</p>\n<pre><code>from olipy import corpora\nfrom olipy.gutenberg import ProjectGutenbergText\ntext = corpora.words.literature.nonfiction.literary_shrines['text']\ntext = ProjectGutenbergText(text)\nprint(len(text.paragraphs))\n# 1258\n</code></pre>\n<h2>ia.py</h2>\n<p>A module for dealing with texts from Internet Archive.</p>\n<pre><code>import random\nfrom olipy.ia import Text\n\n# Print a URL to the web reader for a specific title in the IA collection.\nitem = Text(\"yorkchronicle1946poqu\")\nprint(item.reader_url(10))\n# https://archive.org/details/yorkchronicle1946poqu/page/n10\n\n# Pick a random page from a specific title, and print a URL to a\n# reusable image of that page.\nidentifier = \"TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150\"\nitem = Text(identifier)\npage = random.randint(0, item.pages-1)\nprint(item.image_url(page, scale=8))\n# https://ia600106.us.archive.org/BookReader/BookReaderImages.php?zip=/30/items/TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150/TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150_jp2.zip&amp;file=TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150_jp2/TNM_Radio_equipment_catalog_fall__winter_1963_-_H_20180117_0150_0007.jp2&amp;scale=8\n</code></pre>\n<h2>letterforms.py</h2>\n<p>A module that knows things about the shapes of Unicode glyphs.</p>\n<p><code>alternate_spelling</code> translates from letters of the English alphabet\nto similar-looking characters.</p>\n<pre><code>from olipy.letterforms import alternate_spelling\nprint(alternate_spelling(\"I love alternate letterforms.\"))\n# \u30f1 \ud835\udc73\ud835\uddae\u24cb\ud835\ude40 \ud835\ude8a\ud835\udcf5\u252f\u24a0\u250c\ud835\udc0d\uff41\u2aea\ud835\udd8a \ud835\udc0b\ud835\uddbe\u07d9\ud835\udcc9\u1971\ud835\ude67\u07d3\ud835\udd60\u250d\u1320\ud835\udc46.\n</code></pre>\n<h2>markov.py</h2>\n<p>A module for generating new token lists from old token lists using a\nMarkov chain.</p>\n<p>Olipy's primary purpose is to promote alternatives to\nMarkov chains (such as Queneau assembly and the *_ebooks algorithm),\nbut sometimes you really do want a Markov chain. Queneau assembly is\nusually better than a Markov chain above the word level (constructing\nparagraphs from sentences) and below the word level (constructing\nwords from phonemes), but Markov chains are usually better when\nassembling sequences of words.</p>\n<p>markov.py was originally written by Allison \"A. A.\" Parrish.</p>\n<pre><code>from olipy.markov import MarkovGenerator\nfrom olipy import corpora\ntext = corpora.words.literature.nonfiction.literary_shrines['text']\ng = MarkovGenerator(order=1, max=100)\ng.add(text)\nprint(\" \".join(g.assemble()))\n# The Project Gutenberg-tm trademark.                    Canst thou, e'en thus, thy own savings, went as the gardens, the club. The quarrel occurred between\n# him and his essay on the tea-table. In these that, in Lamb's day, for a stray\n# relic or four years ago, taken with only Adam and _The\n# Corsair_. Writing to his home on his new purple and the young man you might\n# mean nothing on Christmas sports and art seriously instead of references to\n# the heart'--allowed--yet I got out and more convenient.... Mr.\n</code></pre>\n<h2>mosaic.py</h2>\n<p>Tiles Unicode characters together to create symmetrical mosaics.\ngibberish.py uses this module as one of its techniques. Includes\ninformation on Unicode characters whose glyphs appear to be mirror\nimages.</p>\n<pre><code>from olipy.mosaic import MirroredMosaicGibberish\nmosaic = MirroredMosaicGibberish()\nprint(mosaic.tweet())\n# \u259b\u259e\u2003\u2599\u259e\u2599\u259f\u259a\u259f\u2003\u259a\u259c\n# \u259b\u259e\u259e\u2003\u259e\u259b\u259c\u259a\u2003\u259a\u259a\u259c\n# \u2003\u259e\u2599\u2003\u2003\u259e\u259a\u2003\u2003\u259f\u259a\u2003\n# \u2599\u259a\u259a\u2003\u259a\u2599\u259f\u259e\u2003\u259e\u259e\u259f\n# \u2599\u259a\u2003\u259b\u259a\u259b\u259c\u259e\u259c\u2003\u259e\u259f\n\nprint(gibberish.tweet())\n# \ud83d\ude4c\ud83d\ude4c\ud83d\ude2f\ud83d\udcf6\ud83d\ude4c\ud83d\udc4d\ud83d\udc4d\ud83d\ude4c\ud83d\udcf6\ud83d\ude2f\ud83d\ude4c\ud83d\ude4c\n# \u2003\ud83d\udcf6\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udd60\ud83d\udd60\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udcf6\u2003\n# \ud83d\ude82\ud83d\udc88\ud83c\udf88\ud83d\udd12\ud83d\udeb2\ud83d\udd43\ud83d\udd43\ud83d\udeb2\ud83d\udd12\ud83c\udf88\ud83d\udc88\ud83d\ude82\n# \u2003\ud83d\udcf6\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udd60\ud83d\udd60\ud83d\ude4c\ud83d\ude2f\ud83d\ude4c\ud83d\udcf6\u2003\n# \ud83d\ude4c\ud83d\ude4c\ud83d\ude2f\ud83d\udcf6\ud83d\ude4c\ud83d\udc4d\ud83d\udc4d\ud83d\ude4c\ud83d\udcf6\ud83d\ude2f\ud83d\ude4c\ud83d\ude4c\n\n</code></pre>\n<h2>queneau.py</h2>\n<p>A module for Queneau assembly, a technique pioneered by Raymond\nQueneau in his 1961 book \"Cent mille milliards de po\u00e8mes\" (\"One\nhundred million million poems\"). Queneau assembly randomly creates new\ntexts from a collection of existing texts with identical structure.</p>\n<pre><code>from olipy.queneau import WordAssembler\nfrom olipy.corpus import Corpus\nassembler = WordAssembler(Corpus.load(\"dinosaurs\"))\nprint(assembler.assemble_word())\n# Trilusmiasunaus\n</code></pre>\n<h2>randomness.py</h2>\n<p>Techniques for generating random patterns that are more sophisticated\nthan <code>random.choice</code>.</p>\n<h3><code>Gradient</code></h3>\n<p>The <code>Gradient</code> class generates a string of random choices that are\nweighted towards one set of options near the start, and weighted\ntowards another set of options near the end.</p>\n<p>Here's a gradient from lowercase letters to uppercase letters:</p>\n<pre><code>from olipy.randomness import Gradient\nimport string\nprint(\"\".join(Gradient.gradient(string.lowercase, string.uppercase, 40)))\n# rkwyobijqQOzKfdcSHIhYINGrQkBRddEWPHYtORB\n</code></pre>\n<h3><code>WanderingMonsterTable</code></h3>\n<p>The <code>WanderingMonsterTable</code> class lets you make a weighted random selection from\none of four buckets. A random selection from the \"common\" bucket will show up 65% of the time, a\nselection from the \"uncommon\" bucket 20% of the time, \"rare\" 11% of the time, and \"very rare\" 4% of\nthe time. (It uses the same probabilities as the first edition of Advanced Dungeons &amp; Dragons.)</p>\n<pre><code>from olipy.randomness import WanderingMonsterTable\n\nmonsters = WanderingMonsterTable(\n         common=[\"Giant rat\", \"Alligator\"],\n         uncommon=[\"Orc\", \"Hobgoblin\"],\n         rare=[\"Mind flayer\", \"Neo-otyugh\"],\n         very_rare=[\"Flumph\", \"Ygorl, Lord of Entropy\"],\n)\nfor i in range(5):\n    print monsters.choice()\n# Giant rat\n# Alligator\n# Alligator\n# Orc\n# Giant rat\n</code></pre>\n<h2>tokenizer.py</h2>\n<p>A word tokenizer that performs better than NLTK's default tokenizers\non some common types of English.</p>\n<pre><code>from nltk.tokenize.treebank import TreebankWordTokenizer\ns = '''Good muffins cost $3.88\\\\nin New York. Email: muffins@example.com'''\nTreebankWordTokenizer().tokenize(s)\n# ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Email', ':', 'muffins', '@', 'example.com']\nWordTokenizer().tokenize(s)\n# ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York.', 'Email:', 'muffins@example.com']\n</code></pre>\n<h2>typewriter.py</h2>\n<p>Simulates the Adler Universal 39 typewriter used in <em>The Shining</em> and\nthe sorts of typos that would be made on that typewriter. Originally\nwritten for <a href=\"https://botsin.space/@adullbot\" rel=\"nofollow\">@a_dull_bot</a>.</p>\n<pre><code>from olipy.typewriter import Typewriter\ntypewriter = Typewriter()\ntypewriter.type(\"All work and no play makes Jack a dull boy.\")\n# 'All work and no play makes Jack a dull bo6.'\n</code></pre>\n<h1>Extra corpora</h1>\n<p>Olipy makes available several word lists and datasets that aren't in\nthe Corpora Project. These datasets (as well as the standard Corpora\nProject datasets) can be accessed through the <code>corpora</code> module. Just\nwrite code like this:</p>\n<pre><code>from olipy import corpora\nnouns = corpora.words.common_nouns['abstract_nouns']\n</code></pre>\n<h3><code>corpora.geography.large_cities</code></h3>\n<p>Names of large U.S. and world cities.</p>\n<h3><code>corpora.geography.us_states</code></h3>\n<p>The fifty U.S. states.</p>\n<h3><code>corpora.language.languages</code></h3>\n<p>Names of languages defined in ISO-639-1</p>\n<h3><code>corpora.language.unicode_code_sheets</code></h3>\n<p>The name of every Unicode code sheet, each with the characters found on that sheet.</p>\n<h3><code>corpora.science.minor_planet_details</code></h3>\n<p>'name', 'number' and IAU 'citation' for named minor planets\n(e.g. asteroids) as of July 2013. The 'discovery' field contains\ndiscovery circumstances. The 'suggested_by' field, when present, has\nbeen split out from the end of the original IAU citation with a simple\nheuristic. The 'citation' field has then been tokenized into sentences\nusing NLTK's Punkt tokenizer and a set of custom abbreviations.</p>\n<p>Data sources:\n<a href=\"http://www.minorplanetcenter.net/iau/lists/NumberedMPs.html\" rel=\"nofollow\">http://www.minorplanetcenter.net/iau/lists/NumberedMPs.html</a>\n<a href=\"http://ssd.jpl.nasa.gov/sbdb.cgi\" rel=\"nofollow\">http://ssd.jpl.nasa.gov/sbdb.cgi</a></p>\n<p>This is more complete than the Corpora Project's <code>minor_planets</code>,\nwhich only lists the names of the first 1000 minor planets.</p>\n<h3><code>corpora.words.adjectives</code></h3>\n<p>About 5000 English adjectives, sorted roughly by frequency of occurrence.</p>\n<h3><code>corpora.words.common_nouns</code></h3>\n<p>Lists of English nouns, sorted roughly by frequency of occurrence.</p>\n<p>Includes:</p>\n<ul>\n<li><code>abstract_nouns</code> like \"work\" and \"love\".</li>\n<li><code>concrete_nouns</code> like \"face\" and \"house\".</li>\n<li><code>adjectival_nouns</code> -- nouns that can also act as adjectives -- like \"chance\" and \"light\".</li>\n</ul>\n<h3><code>corpora.words.common_verbs</code></h3>\n<p>Lists of English verbs, sorted roughly by frequency of occurrence.</p>\n<ul>\n<li><code>present_tense</code> verbs like \"get\" and \"want\".</li>\n<li><code>past_tense</code> verbs like \"said\" and \"found\".</li>\n<li><code>gerund</code> forms like \"holding\" and \"leaving\".</li>\n</ul>\n<h3><code>corpora.words.english_words</code></h3>\n<p>A consolidated list of about 73,000 English words from the FRELI\nproject. (<a href=\"http://www.nkuitse.com/freli/\" rel=\"nofollow\">http://www.nkuitse.com/freli/</a>)</p>\n<h3><code>corpora.words.scribblenauts</code></h3>\n<p>The top 4000 nouns that were 'concrete' enough to be summonable in the\n2009 game <em>Scribblenauts</em>. As always, this list is ordered with more common\nwords towards the front.</p>\n<h3><code>corpora.words.literature.board_games</code></h3>\n<p>Information about board games, collected from BoardGameGeek in July\n2013. One JSON object per line.</p>\n<p>Data source:\n<a href=\"http://boardgamegeek.com/wiki/page/BGG_XML_API2\" rel=\"nofollow\">http://boardgamegeek.com/wiki/page/BGG_XML_API2</a></p>\n<h3><code>corpora.words.literature.fiction.pride_and_prejudice</code></h3>\n<p>The complete text of a public domain novel (\"Pride and Prejudice\"\nby Jane Austen).</p>\n<h3><code>corpora.words.literature.nonfiction.apollo_11</code></h3>\n<p>Transcripts of the Apollo 11 mission, presented as dialogue, tokenized\ninto sentences using NLTK's Punkt tokenizer. One JSON object per line.</p>\n<p>Data sources:\nThe Apollo 11 Flight Journal: <a href=\"http://history.nasa.gov/ap11fj/\" rel=\"nofollow\">http://history.nasa.gov/ap11fj/</a>\nThe Apollo 11 Surface Journal: <a href=\"http://history.nasa.gov/alsj/\" rel=\"nofollow\">http://history.nasa.gov/alsj/</a>\n\"Intended to be a resource for all those interested in the Apollo\nprogram, whether in a passing or scholarly capacity.\"</p>\n<h3><code>corpora.words.literature.nonfiction.literary_shrines</code></h3>\n<p>The complete text of a public domain nonfiction book (\"Famous Houses\nand Literary Shrines of London\" by A. St. John Adcock).</p>\n<h3><code>corpora.words.literature.gutenberg_id_mapping</code></h3>\n<p>Maps old-style (pre-2007) Project Gutenberg filenames to the new-style\nebook IDs. For example, \"/etext95/3boat10.zip\" is mapped to the\nnumber 308 (see <a href=\"http://www.gutenberg.org/ebooks/308\" rel=\"nofollow\">http://www.gutenberg.org/ebooks/308</a>). Pretty much\nnobody needs this.</p>\n\n          </div>"}, "last_serial": 6375672, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "6fe9efaabf16dd1a18b4e369f747c771", "sha256": "9f3aa9f0a1d884a4855a481e1536a6eac554e46b06857bdad5253152e9c4ba51"}, "downloads": -1, "filename": "olipy-1.0.0-py2-none-any.whl", "has_sig": false, "md5_digest": "6fe9efaabf16dd1a18b4e369f747c771", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 4594646, "upload_time": "2018-08-06T20:23:00", "upload_time_iso_8601": "2018-08-06T20:23:00.414397Z", "url": "https://files.pythonhosted.org/packages/4c/63/9e14c46fe2627975feb7bbb3b8676c84e724f3e479f27789ecaa64fd44de/olipy-1.0.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c1bb3a41d07b6c740c56aed062dc2f6", "sha256": "10f7dad52f6fd4d1614592415bd2f2167a4df044578e5e737d3bb17854466684"}, "downloads": -1, "filename": "olipy-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7c1bb3a41d07b6c740c56aed062dc2f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4500619, "upload_time": "2018-08-06T20:23:03", "upload_time_iso_8601": "2018-08-06T20:23:03.052123Z", "url": "https://files.pythonhosted.org/packages/4d/4d/e7d8ab6369dcc5833f941ce05c9773350fe2e871df7384a43a9080be2806/olipy-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "a32731a325fda6f0fa38ebaec7e970e5", "sha256": "60064759c15f4f9dec81de837ac00f94db857d6dcd69d985ebc0ac0180d79509"}, "downloads": -1, "filename": "olipy-1.0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "a32731a325fda6f0fa38ebaec7e970e5", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 4589153, "upload_time": "2018-08-08T11:13:59", "upload_time_iso_8601": "2018-08-08T11:13:59.037519Z", "url": "https://files.pythonhosted.org/packages/82/17/a1a0f1dc48faa2d8427dbad4ab3c17cfd15e158e4fe565fd9b585d70d4d9/olipy-1.0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f0218827d598df5adae8d336471724bb", "sha256": "dbbb658498925e7f7c554287e4e0b5b42c324230ce921468210e0c0b108d47f4"}, "downloads": -1, "filename": "olipy-1.0.1.tar.gz", "has_sig": false, "md5_digest": "f0218827d598df5adae8d336471724bb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4509370, "upload_time": "2018-08-08T11:14:04", "upload_time_iso_8601": "2018-08-08T11:14:04.742183Z", "url": "https://files.pythonhosted.org/packages/37/97/07580f262453fc4da169a94110bc582249a8b17607f05d671d13b8ae21b5/olipy-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "ed91680a168e26430a617efc7dfb7926", "sha256": "27c5c820651cff3adab2476c52b4089cbb0950eefd3f07d34d97405143974029"}, "downloads": -1, "filename": "olipy-1.0.2.tar.gz", "has_sig": false, "md5_digest": "ed91680a168e26430a617efc7dfb7926", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4512926, "upload_time": "2018-11-13T12:27:14", "upload_time_iso_8601": "2018-11-13T12:27:14.791151Z", "url": "https://files.pythonhosted.org/packages/37/b7/ad2add9845285073ce5e0355173df1d6d98e0ec1c4d4b3d7409c978a3227/olipy-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "bcb98e34f8038ea9fff57fc0ff69e421", "sha256": "b4974fee36d24e6d22505a783f78706e5d6824af2e321eefa3561fe913caa40c"}, "downloads": -1, "filename": "olipy-1.0.3-py2-none-any.whl", "has_sig": false, "md5_digest": "bcb98e34f8038ea9fff57fc0ff69e421", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 4724537, "upload_time": "2019-12-25T14:06:01", "upload_time_iso_8601": "2019-12-25T14:06:01.676584Z", "url": "https://files.pythonhosted.org/packages/f6/cf/117cd9c267409664bcd5de3d81c149288d0f6d8fee5adde67774dadffb77/olipy-1.0.3-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fc1bec310027cab263a588589f8efbd0", "sha256": "7404f3e110ae7f2e7f278aece439df7c94c11375ad2f30f2578fbe7858e2414d"}, "downloads": -1, "filename": "olipy-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "fc1bec310027cab263a588589f8efbd0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4736901, "upload_time": "2019-12-25T14:06:07", "upload_time_iso_8601": "2019-12-25T14:06:07.298813Z", "url": "https://files.pythonhosted.org/packages/b0/e9/bc3583a45ad7c119f2af68fb1458f0b796e4dc709e41a0d210dc94eb60aa/olipy-1.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "109be23b9c84dc2f8a7dd3324c1d0d89", "sha256": "76c650a517fb2c1dbf389cdee5b44ac2e2ae7cf56406c8c25425587f579f7d9c"}, "downloads": -1, "filename": "olipy-1.0.3.tar.gz", "has_sig": false, "md5_digest": "109be23b9c84dc2f8a7dd3324c1d0d89", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4632559, "upload_time": "2019-12-25T14:06:12", "upload_time_iso_8601": "2019-12-25T14:06:12.880594Z", "url": "https://files.pythonhosted.org/packages/cf/b1/4d664513a36fdf73772bf37558edf72e000cb75b55924ee8c16c39035c8b/olipy-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "633b76355a77d9fbf8dff8b9388ae5d6", "sha256": "637c72af90d14bbe7c06513415d533b4d3be5bfcc8dff3bc9293e62bf7b367a4"}, "downloads": -1, "filename": "olipy-1.0.4-py2-none-any.whl", "has_sig": false, "md5_digest": "633b76355a77d9fbf8dff8b9388ae5d6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 4724537, "upload_time": "2019-12-30T15:24:33", "upload_time_iso_8601": "2019-12-30T15:24:33.616573Z", "url": "https://files.pythonhosted.org/packages/82/cd/d35b3ddb045956401213d91af25741df65ed96459e395690cc9c1934038d/olipy-1.0.4-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "26230dbec52564cbfcf0c004a3e606f7", "sha256": "222ca05f5936426f69fc02722ef9e803fcda6e00ec8794d2713219a08fd85266"}, "downloads": -1, "filename": "olipy-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "26230dbec52564cbfcf0c004a3e606f7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4736898, "upload_time": "2019-12-30T15:24:39", "upload_time_iso_8601": "2019-12-30T15:24:39.407827Z", "url": "https://files.pythonhosted.org/packages/d8/83/218e06f92b42165690071858263a8f97ebbc3b95dc950e970281c26b0b8e/olipy-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "48b0a909632c2e8f21b91feab4d2220c", "sha256": "94048802d75943c7de92ea6b48e0f7ffdd1aeeea8a50b525508873bb6ae11aa8"}, "downloads": -1, "filename": "olipy-1.0.4.tar.gz", "has_sig": false, "md5_digest": "48b0a909632c2e8f21b91feab4d2220c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4632688, "upload_time": "2019-12-30T15:24:44", "upload_time_iso_8601": "2019-12-30T15:24:44.906210Z", "url": "https://files.pythonhosted.org/packages/f9/8d/4bd95ff09ac9851929477cf069e960ba0a06fa4e7ce0ee0286b39b8b2b89/olipy-1.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "633b76355a77d9fbf8dff8b9388ae5d6", "sha256": "637c72af90d14bbe7c06513415d533b4d3be5bfcc8dff3bc9293e62bf7b367a4"}, "downloads": -1, "filename": "olipy-1.0.4-py2-none-any.whl", "has_sig": false, "md5_digest": "633b76355a77d9fbf8dff8b9388ae5d6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 4724537, "upload_time": "2019-12-30T15:24:33", "upload_time_iso_8601": "2019-12-30T15:24:33.616573Z", "url": "https://files.pythonhosted.org/packages/82/cd/d35b3ddb045956401213d91af25741df65ed96459e395690cc9c1934038d/olipy-1.0.4-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "26230dbec52564cbfcf0c004a3e606f7", "sha256": "222ca05f5936426f69fc02722ef9e803fcda6e00ec8794d2713219a08fd85266"}, "downloads": -1, "filename": "olipy-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "26230dbec52564cbfcf0c004a3e606f7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4736898, "upload_time": "2019-12-30T15:24:39", "upload_time_iso_8601": "2019-12-30T15:24:39.407827Z", "url": "https://files.pythonhosted.org/packages/d8/83/218e06f92b42165690071858263a8f97ebbc3b95dc950e970281c26b0b8e/olipy-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "48b0a909632c2e8f21b91feab4d2220c", "sha256": "94048802d75943c7de92ea6b48e0f7ffdd1aeeea8a50b525508873bb6ae11aa8"}, "downloads": -1, "filename": "olipy-1.0.4.tar.gz", "has_sig": false, "md5_digest": "48b0a909632c2e8f21b91feab4d2220c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4632688, "upload_time": "2019-12-30T15:24:44", "upload_time_iso_8601": "2019-12-30T15:24:44.906210Z", "url": "https://files.pythonhosted.org/packages/f9/8d/4bd95ff09ac9851929477cf069e960ba0a06fa4e7ce0ee0286b39b8b2b89/olipy-1.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:04:39 2020"}