{"info": {"author": "Nicholas Robinson-Wall", "author_email": "nick@robinson-wall.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "Intended Audience :: System Administrators", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: System :: Logging"], "description": "logbeam - A python logging handler for CloudWatch Logs\n======================================================\n\nA standard Python logging handler using the event batching framework\nsupplied by the ``awscli-cwlogs`` package.\n\nLogs are submitted in batches to the CloudWatch API, with configurable\nlimits on the maximum age of messages before a partial batch is transmitted,\nand maximum batch sizes. These all match the same configuration options you'll\nfind for `configuring the cwlogs agent`__\n\n.. __: http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html\n\n\nInstallation\n------------\n\n::\n\n    pip install logbeam\n\n\nUsage\n-----\n\nHere's an example for setting up your root logging handler for use with\nlogbeam's ``CloudWatchLogsHandler``\n\n::\n\n    import logging\n    from logbeam import CloudWatchLogsHandler\n\n    cw_handler = CloudWatchLogsHandler(\n        log_group_name='my_log_group',\n        log_stream_name='my_log_stream',\n        buffer_duration=10000,\n        batch_count=10,\n        batch_size=1048576\n    )\n\n    # If you use the root logger instead of __name__ you will need to turn off\n    # propagation for loggers 'cwlogs' and 'botocore' or a cycle of logs about\n    # log message delivery will be created, causing the log handler never to\n    # exit and your program to hang.\n    logger = logging.getLogger(__name__)\n\n    logger.setLevel(logging.INFO)\n    logger.addHandler(cw_handler)\n\n    logger.info(\"Hello world!\")\n\nWarning: As mentioned in the snippet above, if you attach the handler to the root\nlogger (``logging.getLogger()``) you need to disable propagation for the\n``cwlogs`` and ``botocore`` loggers to prevent an infinite loop of logs. The\nfollowing example sends logs from these loggers to stderr instead:\n\n::\n\n    local_handler = logging.StreamHandler()\n\n    for logger_name in ('cwlogs', 'botocore'):\n        lg = logging.getLogger(logger_name)\n\n        # Don't propagate to the root handler if it has a CloudWatchLogsHandler\n        lg.propagate = False\n\n        # Write logs to stderr instead\n        lg.addHandler(local_handler)\n\n\nHandler arguments\n-----------------\n\nThe ``CloudWatchLogsHandler`` can be initialised with the following args\n\n- ``log_group_name`` - the destination CloudWatch log group name\n- ``log_stream_name`` - the destination CloudWatch log stream name\n- ``buffer_duration`` - (default 10000) maximum age in ms of the oldest log item in a batch before the batch must be transmitted to CloudWatch.\n- ``batch_count``- (default 10000) maximum number of log items in a batch before the batch must be transmitted to CloudWatch.\n- ``batch_size`` - (default 1024*1024) maximum size in bytes a batch of logs can reach before being transmitted to CloudWatch.\n- ``logs_client`` - (optional) an initialised boto3 ``CloudWatchLogs.Client``. if this isn't supplied the handler will initialise its own.\n\nIAM Permissions\n---------------\n\nHere is the minimum IAM policy required for logbeam\n\n::\n\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"logs:CreateLogGroup\",\n                    \"logs:DescribeLogStreams\"\n                ],\n                \"Resource\": [\n                    \"arn:aws:logs:<region>:<account_id>:log-group:<log_group>:log-stream:\"\n                ]\n            },\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"logs:CreateLogStream\",\n                    \"logs:PutLogEvents\"\n                ],\n                \"Resource\": [\n                    \"arn:aws:logs:<region>:<account_id>:log-group:<log_group>:log-stream:<log_stream>\"\n                ]\n            }\n        ]\n    }\n\n\n\nA word on batch settings\n------------------------\n\nLog records are buffered in memory for a short while before being sent to\nCloudWatch, meaning there is a small chance of losing log records in the event\nof some kind of apocalypse (e.g. unexpected process termination).\n\nUnder normal conditions the shutdown of the Python logging system when the\nprocess exits will instruct the CloudWatch threads created by the handler to\nflush their buffers and wait for them to exit.\n\nIf the process is forcefully terminated (e.g. SIGKILL) any logs that are in the\nbuffer and haven't been transmitted to CloudWatch yet will be lost. For this\nreason it is sensible to configure the ``buffer_duration`` to be relatively\nshort.\n\nThe buffer size (in bytes) and length (number of items) should not be set too\nlow, because of the CloudWatch Logs API limit of a maximum 5 PutLogEvents calls\nper second for a log stream. If these values are too low and you are emitting\nlots of log items each batch will queue up behind the last one for 0.2 seconds.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/osperlabs/logbeam", "keywords": null, "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "logbeam", "package_url": "https://pypi.org/project/logbeam/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/logbeam/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/osperlabs/logbeam"}, "release_url": "https://pypi.org/project/logbeam/1.0.1/", "requires_dist": null, "requires_python": null, "summary": "CloudWatch Logs - Python logging handler", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A standard Python logging handler using the event batching framework\nsupplied by the <tt><span class=\"pre\">awscli-cwlogs</span></tt> package.</p>\n<p>Logs are submitted in batches to the CloudWatch API, with configurable\nlimits on the maximum age of messages before a partial batch is transmitted,\nand maximum batch sizes. These all match the same configuration options you\u2019ll\nfind for <a href=\"http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html\" rel=\"nofollow\">configuring the cwlogs agent</a></p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install logbeam\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Here\u2019s an example for setting up your root logging handler for use with\nlogbeam\u2019s <tt>CloudWatchLogsHandler</tt></p>\n<pre>import logging\nfrom logbeam import CloudWatchLogsHandler\n\ncw_handler = CloudWatchLogsHandler(\n    log_group_name='my_log_group',\n    log_stream_name='my_log_stream',\n    buffer_duration=10000,\n    batch_count=10,\n    batch_size=1048576\n)\n\n# If you use the root logger instead of __name__ you will need to turn off\n# propagation for loggers 'cwlogs' and 'botocore' or a cycle of logs about\n# log message delivery will be created, causing the log handler never to\n# exit and your program to hang.\nlogger = logging.getLogger(__name__)\n\nlogger.setLevel(logging.INFO)\nlogger.addHandler(cw_handler)\n\nlogger.info(\"Hello world!\")\n</pre>\n<p>Warning: As mentioned in the snippet above, if you attach the handler to the root\nlogger (<tt>logging.getLogger()</tt>) you need to disable propagation for the\n<tt>cwlogs</tt> and <tt>botocore</tt> loggers to prevent an infinite loop of logs. The\nfollowing example sends logs from these loggers to stderr instead:</p>\n<pre>local_handler = logging.StreamHandler()\n\nfor logger_name in ('cwlogs', 'botocore'):\n    lg = logging.getLogger(logger_name)\n\n    # Don't propagate to the root handler if it has a CloudWatchLogsHandler\n    lg.propagate = False\n\n    # Write logs to stderr instead\n    lg.addHandler(local_handler)\n</pre>\n</div>\n<div id=\"handler-arguments\">\n<h2>Handler arguments</h2>\n<p>The <tt>CloudWatchLogsHandler</tt> can be initialised with the following args</p>\n<ul>\n<li><tt>log_group_name</tt> - the destination CloudWatch log group name</li>\n<li><tt>log_stream_name</tt> - the destination CloudWatch log stream name</li>\n<li><tt>buffer_duration</tt> - (default 10000) maximum age in ms of the oldest log item in a batch before the batch must be transmitted to CloudWatch.</li>\n<li><tt>batch_count</tt>- (default 10000) maximum number of log items in a batch before the batch must be transmitted to CloudWatch.</li>\n<li><tt>batch_size</tt> - (default 1024*1024) maximum size in bytes a batch of logs can reach before being transmitted to CloudWatch.</li>\n<li><tt>logs_client</tt> - (optional) an initialised boto3 <tt>CloudWatchLogs.Client</tt>. if this isn\u2019t supplied the handler will initialise its own.</li>\n</ul>\n</div>\n<div id=\"iam-permissions\">\n<h2>IAM Permissions</h2>\n<p>Here is the minimum IAM policy required for logbeam</p>\n<pre>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:CreateLogGroup\",\n                \"logs:DescribeLogStreams\"\n            ],\n            \"Resource\": [\n                \"arn:aws:logs:&lt;region&gt;:&lt;account_id&gt;:log-group:&lt;log_group&gt;:log-stream:\"\n            ]\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:CreateLogStream\",\n                \"logs:PutLogEvents\"\n            ],\n            \"Resource\": [\n                \"arn:aws:logs:&lt;region&gt;:&lt;account_id&gt;:log-group:&lt;log_group&gt;:log-stream:&lt;log_stream&gt;\"\n            ]\n        }\n    ]\n}\n</pre>\n</div>\n<div id=\"a-word-on-batch-settings\">\n<h2>A word on batch settings</h2>\n<p>Log records are buffered in memory for a short while before being sent to\nCloudWatch, meaning there is a small chance of losing log records in the event\nof some kind of apocalypse (e.g. unexpected process termination).</p>\n<p>Under normal conditions the shutdown of the Python logging system when the\nprocess exits will instruct the CloudWatch threads created by the handler to\nflush their buffers and wait for them to exit.</p>\n<p>If the process is forcefully terminated (e.g. SIGKILL) any logs that are in the\nbuffer and haven\u2019t been transmitted to CloudWatch yet will be lost. For this\nreason it is sensible to configure the <tt>buffer_duration</tt> to be relatively\nshort.</p>\n<p>The buffer size (in bytes) and length (number of items) should not be set too\nlow, because of the CloudWatch Logs API limit of a maximum 5 PutLogEvents calls\nper second for a log stream. If these values are too low and you are emitting\nlots of log items each batch will queue up behind the last one for 0.2 seconds.</p>\n</div>\n\n          </div>"}, "last_serial": 2847057, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "bdab557e16be1b03d1f504631d4806fc", "sha256": "cf1b6ebc8dcbc7437ce516d8f0a3f8ed0fdec6b26ba3f60ed06def4fb8282ef5"}, "downloads": -1, "filename": "logbeam-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bdab557e16be1b03d1f504631d4806fc", "packagetype": "bdist_wheel", "python_version": "3.4", "requires_python": null, "size": 8351, "upload_time": "2017-03-31T17:15:16", "upload_time_iso_8601": "2017-03-31T17:15:16.419642Z", "url": "https://files.pythonhosted.org/packages/57/ec/5887919e48e8f3aead6ec7ee4ea1bee997dae58c1c2d267ce4db0fbc8f6f/logbeam-1.0.0-py2.py3-none-any.whl", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "e766a321b94f72846605813992eada41", "sha256": "0d627e9883e849cdf77b920351e59759fdc360175e83f03e090c891a8207087c"}, "downloads": -1, "filename": "logbeam-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e766a321b94f72846605813992eada41", "packagetype": "bdist_wheel", "python_version": "3.4", "requires_python": null, "size": 9166, "upload_time": "2017-05-02T17:39:55", "upload_time_iso_8601": "2017-05-02T17:39:55.630990Z", "url": "https://files.pythonhosted.org/packages/e9/91/38a944f3aa2d199944799b43cbe27d74362b9558ad2cb3daf870ab3a4100/logbeam-1.0.1-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e766a321b94f72846605813992eada41", "sha256": "0d627e9883e849cdf77b920351e59759fdc360175e83f03e090c891a8207087c"}, "downloads": -1, "filename": "logbeam-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e766a321b94f72846605813992eada41", "packagetype": "bdist_wheel", "python_version": "3.4", "requires_python": null, "size": 9166, "upload_time": "2017-05-02T17:39:55", "upload_time_iso_8601": "2017-05-02T17:39:55.630990Z", "url": "https://files.pythonhosted.org/packages/e9/91/38a944f3aa2d199944799b43cbe27d74362b9558ad2cb3daf870ab3a4100/logbeam-1.0.1-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:44:26 2020"}