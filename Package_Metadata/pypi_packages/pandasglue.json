{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# DEPRECATION: This project was only created for a Proof of Concept purpose. The production ready version of this project received the name of **AWS Data Wrangler** (pip install awswrangler).\n### Please consider move forward to:\n* https://pypi.org/project/awswrangler/\n* https://github.com/awslabs/aws-data-wrangler\n\n\n------------------------------------------------------------------------------------------------------------\n\n\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\n# PandasGlue\n\n***A Python library for creating lite ETLs with the widely used Pandas library and the power of AWS Glue Catalog.***\n\n\nWith **PandasGLue** you will be able to write/read to/from an AWS Data Lake with one single line of code. With its minimalist nature **PandasGLue** has an interface with only 2 functions:\n\n\n|   function   \t|       From       \t|        To        \t|\n|:------------:\t|:----------------:\t|:----------------:\t|\n| write_glue() \t| Pandas DataFrame \t|  AWS Glue Table  \t|\n|  read_glue() \t|   AWS GlueTable  \t| Pandas DataFrame \t|\n\n\n\nOnce your data is mapped to [AWS Glue Catalog](https://aws.amazon.com/glue/) it will be accessible to many other tools like [AWS Redshift Spectrum](https://aws.amazon.com/redshift/), [AWS Athena](https://aws.amazon.com/athena/), [AWS Glue Jobs](https://aws.amazon.com/glue/), [AWS EMR](https://aws.amazon.com/emr/) ([Spark](https://spark.apache.org/), [Hive](https://hive.apache.org/), [PrestoDB](https://prestodb.github.io)), etc.\n\n[Amazon Glue](https://aws.amazon.com/glue/) is an [AWS](https://aws.amazon.com/) simple, flexible, and cost-effective ETL service and [Pandas](https://pandas.pydata.org/) is a Python library which provides high-performance, easy-to-use data structures and data analysis tools.\n\nThe goal of this package is help data engineers in the usage of cost efficient serverless compute services ([Lambda](https://aws.amazon.com/glue/), [Glue](https://aws.amazon.com/lambda/), [Athena](https://aws.amazon.com/athena/)) in order to provide an easy way to integrate Pandas with  AWS Glue,  allowing load (*appending, overwriting or only overwriting the partitions with data*) the content of a DataFrame (**Write function**) directly in a table (parquet/csv format) in the [Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html) and also execute Athena queries (**Read function**) returning the result directly in a Pandas DataFrame.\n\n## Use cases\n\nThis package is recommended for ETL purposes which loads and transforms small to medium size datasets without requiring to create Spark jobs, helping reduce infrastructure costs.\n\nIt could be used within [Lambda functions](https://docs.aws.amazon.com/lambda/latest/dg/lambda-introduction-function.html), [Glue scripts](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python.html), [EC2](https://aws.amazon.com/ec2/) instances or any other infrastucture resources.\n\n<p align=\"center\">\n  <img src=\"https://github.com/andresmao/test/blob/master/Pandas_glue_workflow2.png\" width=\"700\"  title=\"ETL Workflow\">\n</p>\n\n### Prerequisites\n\n* [Python 2.7, 3.6, 3.7](https://www.python.org/downloads/) \n\n```\npip install pandas\npip install boto3\npip install pyarrow \n```\n\n### Installing the package...\n\n```\npip install pandasglue\n```\n\nOr you can download direct the artifacts for [AWS Lambda Layer](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html) / [AWS Glue Job](https://docs.aws.amazon.com/glue/latest/dg/add-job-python.html) from our [release page](https://github.com/igorborgest/pandasglue/releases). Then you only will need to upload it in your AWS account.\n\n## Usage \n\n**Read method:**\n\n***read_glue()***\n\nTo retrieve the result of an Athena Query in a Pandas DataFrame.\n\nQuick example:\n\n```python\nimport pandas as pd\nimport pandasglue as pg\n\n#Parameters\nsql_query = \"SELECT * FROM table_name LIMIT 20\" \ndb_name = \"DB_NAME\"\ns3_output_bucket = \"s3://bucket-url/\"\n\ndf = pg.read_glue(sql_query,db_name,s3_output_bucket)\n\nprint(df)\n\n```\n***Parameters list:***\n\n* ***query:*** the SQL statement on Athena\n* ***db:*** database name.\n* ***s3_output:*** path of the S3 output folder (optional)\n* ***region:*** id of the AWS region, e.g: us-west-1 (optional)\n* ***key:*** AWS Access key (optional)\n* ***secret:*** AWS secret key (optional)\n* ***profile_name:*** AWS IAM profile (optional)\n\n<p>\n  <hr>\n</p>\n\n\n**Write method:**\n\n***write_glue()***\n\nConvert a given Pandas Dataframe to a Glue Parquet table.\n\nQuick example:\n\n```python\nimport pandas as pd\nimport pandasglue as pg\n\n#Parameters\ndatabase = \"DB_NAME\"\ntable_name = \"TB_NAME\"\ns3_path = \"s3://bucket-url/\"\n\n#Sample DF\nsource_data = {'name': ['Sarah', 'Renata', 'Erika', 'Fernanda', 'Diana'], \n        'city': ['Seattle', 'Sao Paulo', 'Seattle', 'Santiago', 'Lima'],\n         'test_score': [82, 52, 56, 234, 254]}\n\ndf = pd.DataFrame(source_data, columns = ['name', 'city', 'test_score'])\n\n\npg.write_glue(df, database, table_name, s3_path, partition_cols=['city'])\n```\n\n\n***Parameters list:***\n\n* ***df:*** variable containing the Pandas DataFrame\n* ***database:*** database name.\n* ***path:*** Path of the target S3 bucket\n* ***table:*** table name (optional)\n* ***partition_cols:*** list of columns to partition (optional)\n* ***preserve_index:*** boolean, if you want to preserve the index on the table (optional)\n* ***file_format:*** parquet|csv(optional)\n* ***mode:*** append|overwrite|overwrite_partitions(optional)\n* ***region:*** ID of the AWS region (optional)\n* ***key:*** AWS Access key (optional)\n* ***secret:*** AWS secret key (optional)\n* ***profile_name:*** AWS IAM profile (optional)\n\n\n## Built With\n\n* [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) - (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2.\n* [PyArrow](https://pypi.org/project/pyarrow/) - Python package to interoperate Arrow with Python allowing to convert text files format to parquet files among other functions.\n\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](https://gist.github.com/) for details on our code of conduct, and the process for submitting pull requests to us.\n\n## Authors\n\n* *Igor Tavares* - [Profile link](https://github.com/igorborgest)\n* *Ricardo Serafim* - [Profile link](https://github.com/rcserafim)\n* *Andres Palacios* - [Profile link](https://github.com/andresmao)\n\nSee also the list of [contributors](https://github.com/your/project/contributors) who participated in this project.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "pandasglue", "package_url": "https://pypi.org/project/pandasglue/", "platform": "", "project_url": "https://pypi.org/project/pandasglue/", "project_urls": null, "release_url": "https://pypi.org/project/pandasglue/0.0.3/", "requires_dist": ["pyarrow (==0.12.0)", "pandas (==0.24.1)", "boto3", "s3fs (==0.2.0)"], "requires_python": ">=2.7", "summary": "Productivity for your AWS Data Lake", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DEPRECATION: This project was only created for a Proof of Concept purpose. The production ready version of this project received the name of <strong>AWS Data Wrangler</strong> (pip install awswrangler).</h1>\n<h3>Please consider move forward to:</h3>\n<ul>\n<li><a href=\"https://pypi.org/project/awswrangler/\" rel=\"nofollow\">https://pypi.org/project/awswrangler/</a></li>\n<li><a href=\"https://github.com/awslabs/aws-data-wrangler\" rel=\"nofollow\">https://github.com/awslabs/aws-data-wrangler</a></li>\n</ul>\n<hr>\n<p><a href=\"https://github.com/ambv/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<h1>PandasGlue</h1>\n<p><em><strong>A Python library for creating lite ETLs with the widely used Pandas library and the power of AWS Glue Catalog.</strong></em></p>\n<p>With <strong>PandasGLue</strong> you will be able to write/read to/from an AWS Data Lake with one single line of code. With its minimalist nature <strong>PandasGLue</strong> has an interface with only 2 functions:</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">function</th>\n<th align=\"center\">From</th>\n<th align=\"center\">To</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">write_glue()</td>\n<td align=\"center\">Pandas DataFrame</td>\n<td align=\"center\">AWS Glue Table</td>\n</tr>\n<tr>\n<td align=\"center\">read_glue()</td>\n<td align=\"center\">AWS GlueTable</td>\n<td align=\"center\">Pandas DataFrame</td>\n</tr></tbody></table>\n<p>Once your data is mapped to <a href=\"https://aws.amazon.com/glue/\" rel=\"nofollow\">AWS Glue Catalog</a> it will be accessible to many other tools like <a href=\"https://aws.amazon.com/redshift/\" rel=\"nofollow\">AWS Redshift Spectrum</a>, <a href=\"https://aws.amazon.com/athena/\" rel=\"nofollow\">AWS Athena</a>, <a href=\"https://aws.amazon.com/glue/\" rel=\"nofollow\">AWS Glue Jobs</a>, <a href=\"https://aws.amazon.com/emr/\" rel=\"nofollow\">AWS EMR</a> (<a href=\"https://spark.apache.org/\" rel=\"nofollow\">Spark</a>, <a href=\"https://hive.apache.org/\" rel=\"nofollow\">Hive</a>, <a href=\"https://prestodb.github.io\" rel=\"nofollow\">PrestoDB</a>), etc.</p>\n<p><a href=\"https://aws.amazon.com/glue/\" rel=\"nofollow\">Amazon Glue</a> is an <a href=\"https://aws.amazon.com/\" rel=\"nofollow\">AWS</a> simple, flexible, and cost-effective ETL service and <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">Pandas</a> is a Python library which provides high-performance, easy-to-use data structures and data analysis tools.</p>\n<p>The goal of this package is help data engineers in the usage of cost efficient serverless compute services (<a href=\"https://aws.amazon.com/glue/\" rel=\"nofollow\">Lambda</a>, <a href=\"https://aws.amazon.com/lambda/\" rel=\"nofollow\">Glue</a>, <a href=\"https://aws.amazon.com/athena/\" rel=\"nofollow\">Athena</a>) in order to provide an easy way to integrate Pandas with  AWS Glue,  allowing load (<em>appending, overwriting or only overwriting the partitions with data</em>) the content of a DataFrame (<strong>Write function</strong>) directly in a table (parquet/csv format) in the <a href=\"https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html\" rel=\"nofollow\">Glue Data Catalog</a> and also execute Athena queries (<strong>Read function</strong>) returning the result directly in a Pandas DataFrame.</p>\n<h2>Use cases</h2>\n<p>This package is recommended for ETL purposes which loads and transforms small to medium size datasets without requiring to create Spark jobs, helping reduce infrastructure costs.</p>\n<p>It could be used within <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/lambda-introduction-function.html\" rel=\"nofollow\">Lambda functions</a>, <a href=\"https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python.html\" rel=\"nofollow\">Glue scripts</a>, <a href=\"https://aws.amazon.com/ec2/\" rel=\"nofollow\">EC2</a> instances or any other infrastucture resources.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/59ab792b6f54e15dfbb2e1154adaa59bdbfee39f/68747470733a2f2f6769746875622e636f6d2f616e647265736d616f2f746573742f626c6f622f6d61737465722f50616e6461735f676c75655f776f726b666c6f77322e706e67\" width=\"700\">\n</p>\n<h3>Prerequisites</h3>\n<ul>\n<li><a href=\"https://www.python.org/downloads/\" rel=\"nofollow\">Python 2.7, 3.6, 3.7</a></li>\n</ul>\n<pre><code>pip install pandas\npip install boto3\npip install pyarrow \n</code></pre>\n<h3>Installing the package...</h3>\n<pre><code>pip install pandasglue\n</code></pre>\n<p>Or you can download direct the artifacts for <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html\" rel=\"nofollow\">AWS Lambda Layer</a> / <a href=\"https://docs.aws.amazon.com/glue/latest/dg/add-job-python.html\" rel=\"nofollow\">AWS Glue Job</a> from our <a href=\"https://github.com/igorborgest/pandasglue/releases\" rel=\"nofollow\">release page</a>. Then you only will need to upload it in your AWS account.</p>\n<h2>Usage</h2>\n<p><strong>Read method:</strong></p>\n<p><em><strong>read_glue()</strong></em></p>\n<p>To retrieve the result of an Athena Query in a Pandas DataFrame.</p>\n<p>Quick example:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandasglue</span> <span class=\"k\">as</span> <span class=\"nn\">pg</span>\n\n<span class=\"c1\">#Parameters</span>\n<span class=\"n\">sql_query</span> <span class=\"o\">=</span> <span class=\"s2\">\"SELECT * FROM table_name LIMIT 20\"</span> \n<span class=\"n\">db_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"DB_NAME\"</span>\n<span class=\"n\">s3_output_bucket</span> <span class=\"o\">=</span> <span class=\"s2\">\"s3://bucket-url/\"</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pg</span><span class=\"o\">.</span><span class=\"n\">read_glue</span><span class=\"p\">(</span><span class=\"n\">sql_query</span><span class=\"p\">,</span><span class=\"n\">db_name</span><span class=\"p\">,</span><span class=\"n\">s3_output_bucket</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n</pre>\n<p><em><strong>Parameters list:</strong></em></p>\n<ul>\n<li><em><strong>query:</strong></em> the SQL statement on Athena</li>\n<li><em><strong>db:</strong></em> database name.</li>\n<li><em><strong>s3_output:</strong></em> path of the S3 output folder (optional)</li>\n<li><em><strong>region:</strong></em> id of the AWS region, e.g: us-west-1 (optional)</li>\n<li><em><strong>key:</strong></em> AWS Access key (optional)</li>\n<li><em><strong>secret:</strong></em> AWS secret key (optional)</li>\n<li><em><strong>profile_name:</strong></em> AWS IAM profile (optional)</li>\n</ul>\n<p>\n  </p><hr>\n<p></p>\n<p><strong>Write method:</strong></p>\n<p><em><strong>write_glue()</strong></em></p>\n<p>Convert a given Pandas Dataframe to a Glue Parquet table.</p>\n<p>Quick example:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandasglue</span> <span class=\"k\">as</span> <span class=\"nn\">pg</span>\n\n<span class=\"c1\">#Parameters</span>\n<span class=\"n\">database</span> <span class=\"o\">=</span> <span class=\"s2\">\"DB_NAME\"</span>\n<span class=\"n\">table_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"TB_NAME\"</span>\n<span class=\"n\">s3_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"s3://bucket-url/\"</span>\n\n<span class=\"c1\">#Sample DF</span>\n<span class=\"n\">source_data</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'Sarah'</span><span class=\"p\">,</span> <span class=\"s1\">'Renata'</span><span class=\"p\">,</span> <span class=\"s1\">'Erika'</span><span class=\"p\">,</span> <span class=\"s1\">'Fernanda'</span><span class=\"p\">,</span> <span class=\"s1\">'Diana'</span><span class=\"p\">],</span> \n        <span class=\"s1\">'city'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'Seattle'</span><span class=\"p\">,</span> <span class=\"s1\">'Sao Paulo'</span><span class=\"p\">,</span> <span class=\"s1\">'Seattle'</span><span class=\"p\">,</span> <span class=\"s1\">'Santiago'</span><span class=\"p\">,</span> <span class=\"s1\">'Lima'</span><span class=\"p\">],</span>\n         <span class=\"s1\">'test_score'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">82</span><span class=\"p\">,</span> <span class=\"mi\">52</span><span class=\"p\">,</span> <span class=\"mi\">56</span><span class=\"p\">,</span> <span class=\"mi\">234</span><span class=\"p\">,</span> <span class=\"mi\">254</span><span class=\"p\">]}</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">source_data</span><span class=\"p\">,</span> <span class=\"n\">columns</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'name'</span><span class=\"p\">,</span> <span class=\"s1\">'city'</span><span class=\"p\">,</span> <span class=\"s1\">'test_score'</span><span class=\"p\">])</span>\n\n\n<span class=\"n\">pg</span><span class=\"o\">.</span><span class=\"n\">write_glue</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">database</span><span class=\"p\">,</span> <span class=\"n\">table_name</span><span class=\"p\">,</span> <span class=\"n\">s3_path</span><span class=\"p\">,</span> <span class=\"n\">partition_cols</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'city'</span><span class=\"p\">])</span>\n</pre>\n<p><em><strong>Parameters list:</strong></em></p>\n<ul>\n<li><em><strong>df:</strong></em> variable containing the Pandas DataFrame</li>\n<li><em><strong>database:</strong></em> database name.</li>\n<li><em><strong>path:</strong></em> Path of the target S3 bucket</li>\n<li><em><strong>table:</strong></em> table name (optional)</li>\n<li><em><strong>partition_cols:</strong></em> list of columns to partition (optional)</li>\n<li><em><strong>preserve_index:</strong></em> boolean, if you want to preserve the index on the table (optional)</li>\n<li><em><strong>file_format:</strong></em> parquet|csv(optional)</li>\n<li><em><strong>mode:</strong></em> append|overwrite|overwrite_partitions(optional)</li>\n<li><em><strong>region:</strong></em> ID of the AWS region (optional)</li>\n<li><em><strong>key:</strong></em> AWS Access key (optional)</li>\n<li><em><strong>secret:</strong></em> AWS secret key (optional)</li>\n<li><em><strong>profile_name:</strong></em> AWS IAM profile (optional)</li>\n</ul>\n<h2>Built With</h2>\n<ul>\n<li><a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\" rel=\"nofollow\">Boto3</a> - (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2.</li>\n<li><a href=\"https://pypi.org/project/pyarrow/\" rel=\"nofollow\">PyArrow</a> - Python package to interoperate Arrow with Python allowing to convert text files format to parquet files among other functions.</li>\n</ul>\n<h2>Contributing</h2>\n<p>Please read <a href=\"https://gist.github.com/\" rel=\"nofollow\">CONTRIBUTING.md</a> for details on our code of conduct, and the process for submitting pull requests to us.</p>\n<h2>Authors</h2>\n<ul>\n<li><em>Igor Tavares</em> - <a href=\"https://github.com/igorborgest\" rel=\"nofollow\">Profile link</a></li>\n<li><em>Ricardo Serafim</em> - <a href=\"https://github.com/rcserafim\" rel=\"nofollow\">Profile link</a></li>\n<li><em>Andres Palacios</em> - <a href=\"https://github.com/andresmao\" rel=\"nofollow\">Profile link</a></li>\n</ul>\n<p>See also the list of <a href=\"https://github.com/your/project/contributors\" rel=\"nofollow\">contributors</a> who participated in this project.</p>\n<h2>License</h2>\n<p>This project is licensed under the MIT License - see the <a href=\"LICENSE.md\" rel=\"nofollow\">LICENSE.md</a> file for details</p>\n\n          </div>"}, "last_serial": 5687890, "releases": {"0.0.0": [{"comment_text": "", "digests": {"md5": "a65f9949bfb425452584740d1a7d553c", "sha256": "3c767b5d45f553019e11de66e4c4acb28efcf90fc045785894ae6ce74e232eec"}, "downloads": -1, "filename": "pandasglue-0.0.0-py27,py36,py37-none-any.whl", "has_sig": false, "md5_digest": "a65f9949bfb425452584740d1a7d553c", "packagetype": "bdist_wheel", "python_version": "py27,py36,py37", "requires_python": ">=2.7", "size": 11177, "upload_time": "2019-02-07T23:54:34", "upload_time_iso_8601": "2019-02-07T23:54:34.824563Z", "url": "https://files.pythonhosted.org/packages/8e/4a/c3767ee825024904491f4d717eb827b64978046c2e0e4a8246b9bbc4ab76/pandasglue-0.0.0-py27,py36,py37-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6ae473bd508bc7b9903e26c60806e47a", "sha256": "05567d282ce08589173df131072071b4ada528e51f0b2f3786969ac01a5eb88f"}, "downloads": -1, "filename": "pandasglue-0.0.0.tar.gz", "has_sig": false, "md5_digest": "6ae473bd508bc7b9903e26c60806e47a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 10262, "upload_time": "2019-02-07T23:54:37", "upload_time_iso_8601": "2019-02-07T23:54:37.205508Z", "url": "https://files.pythonhosted.org/packages/02/87/7bc82e71236ac63968e44ce55e21218e329c05fbb29e2e148014e4789ec4/pandasglue-0.0.0.tar.gz", "yanked": false}], "0.0.1": [{"comment_text": "", "digests": {"md5": "ff6875dc50ee48c3f6c9658569a6fc21", "sha256": "be534cfdc110fca8f642ecf19ab447137b9d7745787aa8f6a1e420e5b1ffd369"}, "downloads": -1, "filename": "pandasglue-0.0.1-py27,py36,py37-none-any.whl", "has_sig": false, "md5_digest": "ff6875dc50ee48c3f6c9658569a6fc21", "packagetype": "bdist_wheel", "python_version": "py27,py36,py37", "requires_python": ">=2.7", "size": 11346, "upload_time": "2019-02-08T14:28:46", "upload_time_iso_8601": "2019-02-08T14:28:46.690143Z", "url": "https://files.pythonhosted.org/packages/d2/3d/c527f2b854b6752ff8ebbf5e558a6e2214894b7ffef4fc8bf3f40caeb95c/pandasglue-0.0.1-py27,py36,py37-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f01b0f5abf0f19d3768775a556515e48", "sha256": "9312ef02e6b1432aa5a36aa219de2393378ca8049ba4d1662bc1c547e7b20689"}, "downloads": -1, "filename": "pandasglue-0.0.1.tar.gz", "has_sig": false, "md5_digest": "f01b0f5abf0f19d3768775a556515e48", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 10432, "upload_time": "2019-02-08T14:28:48", "upload_time_iso_8601": "2019-02-08T14:28:48.198177Z", "url": "https://files.pythonhosted.org/packages/cf/2f/87506a1e55f661123894d93b978e21de77f55065dae69abf98a647c6a59c/pandasglue-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "f1e42516575c03b1fdbcf74b9ce5dbce", "sha256": "b4971b4d21726f97e9a8638cd8eb8e6111442bc81095ad63631d789cfdcf0eea"}, "downloads": -1, "filename": "pandasglue-0.0.2-py27,py36,py37-none-any.whl", "has_sig": false, "md5_digest": "f1e42516575c03b1fdbcf74b9ce5dbce", "packagetype": "bdist_wheel", "python_version": "py27,py36,py37", "requires_python": ">=2.7", "size": 16796, "upload_time": "2019-02-12T16:42:34", "upload_time_iso_8601": "2019-02-12T16:42:34.121932Z", "url": "https://files.pythonhosted.org/packages/bd/fd/767e5ee8bb82d56ac935efa09561329fce47b59e4eb4733da6caf783933b/pandasglue-0.0.2-py27,py36,py37-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f7a7ecf482b39093e13d7c3a11d558e8", "sha256": "364d1b702b500d0143dcf7c436cb8a580da4461047dfa0b4ddb8f0bf0079d2bb"}, "downloads": -1, "filename": "pandasglue-0.0.2.tar.gz", "has_sig": false, "md5_digest": "f7a7ecf482b39093e13d7c3a11d558e8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 15671, "upload_time": "2019-02-12T16:42:36", "upload_time_iso_8601": "2019-02-12T16:42:36.378869Z", "url": "https://files.pythonhosted.org/packages/3e/37/616ac6288fd70272cede3dfb62f4e605dd93d6a1ffdf6894dc8c042ec12e/pandasglue-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "b8b692882e6edbd94bc143d6872d70ff", "sha256": "bfbbfeaa1b1d4e423f85ba44a6d79d40e0e160177d2cd12c08a7a64a8c2b37d0"}, "downloads": -1, "filename": "pandasglue-0.0.3-py27,py36,py37-none-any.whl", "has_sig": false, "md5_digest": "b8b692882e6edbd94bc143d6872d70ff", "packagetype": "bdist_wheel", "python_version": "py27,py36,py37", "requires_python": ">=2.7", "size": 17275, "upload_time": "2019-08-16T14:22:51", "upload_time_iso_8601": "2019-08-16T14:22:51.743193Z", "url": "https://files.pythonhosted.org/packages/ae/47/ace32b6ec156965d3b70ff0bc8b4137146b04460bc1ae6f769e2e414641f/pandasglue-0.0.3-py27,py36,py37-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "77183eb067a035b81c0062cb173921d8", "sha256": "eeafd88b193e87db8f68a4c9a7a06afa7ef8aac0b20875ec2dc34064d760a668"}, "downloads": -1, "filename": "pandasglue-0.0.3.tar.gz", "has_sig": false, "md5_digest": "77183eb067a035b81c0062cb173921d8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 15884, "upload_time": "2019-08-16T14:22:53", "upload_time_iso_8601": "2019-08-16T14:22:53.493404Z", "url": "https://files.pythonhosted.org/packages/1e/8c/41880fa896557d59e09dd1756c09e6e2794e7050e2b00176ab660fd54784/pandasglue-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b8b692882e6edbd94bc143d6872d70ff", "sha256": "bfbbfeaa1b1d4e423f85ba44a6d79d40e0e160177d2cd12c08a7a64a8c2b37d0"}, "downloads": -1, "filename": "pandasglue-0.0.3-py27,py36,py37-none-any.whl", "has_sig": false, "md5_digest": "b8b692882e6edbd94bc143d6872d70ff", "packagetype": "bdist_wheel", "python_version": "py27,py36,py37", "requires_python": ">=2.7", "size": 17275, "upload_time": "2019-08-16T14:22:51", "upload_time_iso_8601": "2019-08-16T14:22:51.743193Z", "url": "https://files.pythonhosted.org/packages/ae/47/ace32b6ec156965d3b70ff0bc8b4137146b04460bc1ae6f769e2e414641f/pandasglue-0.0.3-py27,py36,py37-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "77183eb067a035b81c0062cb173921d8", "sha256": "eeafd88b193e87db8f68a4c9a7a06afa7ef8aac0b20875ec2dc34064d760a668"}, "downloads": -1, "filename": "pandasglue-0.0.3.tar.gz", "has_sig": false, "md5_digest": "77183eb067a035b81c0062cb173921d8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=2.7", "size": 15884, "upload_time": "2019-08-16T14:22:53", "upload_time_iso_8601": "2019-08-16T14:22:53.493404Z", "url": "https://files.pythonhosted.org/packages/1e/8c/41880fa896557d59e09dd1756c09e6e2794e7050e2b00176ab660fd54784/pandasglue-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:31 2020"}