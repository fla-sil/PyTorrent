{"info": {"author": "Sanchit Latawa", "author_email": "slatawa@yahoo.in", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# autopredict\n\n[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)\n\n[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://github.com/slatawa/autopredict)\n\nAutopredict is a simple yet powerful library which can be used by Data Scientists to create multiple prediction (regression,classification) data models.Pass in the data to autopredict and sit back as it does all the work for you. It is very powerfull in creating intial baseline models and also has ready made tweaked parameters for multiple models to generate highly accurate predictions.\n\n  - Automate Model Selection\n  - Hyperparameter tuning \n  - Feature selection/ranking\n  - Feature Compression\n  - Stacked Ensemble Models\n\nThis software has been designed with much Joy,\nby Sanchit Latawa & is protected by The Apache Licensev2.0.\n\n# New Features!\n\n  - Added new classification Models\n  - Allow grid tuning parameters to be passed in as argument \n\n\n\n### Tech\n\n### Sample Usage\n```sh\n>> from autopredict.classification import autoClassify\n>> model =autoClassify(encoder='label',scaler='minmax',useGridtuning=False)\n>> model.train(X,y)\n>>print(model.getModelScores())  \n```\n\n### Output\n```sh\nmodelName                  score     roc_auc_score  f1_score\nLogisticRegression         0.927464   0.639570      0.000000\nDecisionTreeClassifier     0.937422   0.788967      0.285612\nGaussianNB                 0.935352   0.760670      0.203207\nRandomForestClassifier     0.937297   0.791552      0.248444\nGradientBoostingClassifier 0.937472   0.792435      0.257557\n```\n\n### Sample Run for Iris Dataset\n\nBelow shows sample code flow for using autopredict , you can get this sample file\nfrom -> */autopredict/tests/sample_iris_classification.py\n\n```sh\n# Loading Libraries\nimport pandas as pd\nfrom autopredict.classification import autoClassify\nfrom autopredict.features import rankFeatures,reduce_memory\n\n# Setting display options\npd.set_option('display.max_columns',50000)\npd.set_option('display.width', 500000)\n\n# Load the data into a dataframe\ndf = pd.read_csv('./tests/iris.csv')\n\n# St target and feature values\nX=df.drop('Species',axis=1)\ny=df['Species']\n\n# step 1  Feature Importance/Evaluation\n# rankFeatures is a function in autopredict which you can\n# use for feature evaluation it will give you the ranking of your features\n# based on importance , with the most important feature starting from 1\nprint(rankFeatures(X,y))\n## Sample Output - showing features along with their realtive rank  ########\n#     Column-name  Importance-Rank\n# 0   Petal.Width              1.0\n# 1  Petal.Length              1.5\n# 2  Sepal.Length              3.0\n# 3   Sepal.Width              3.0\n\n## Once you have the list of importance of the features\n## you can either drop or add some new features which \n## would be used in the prediction modeling\n\n## step 2 Train the model/evaluate\n\n################ sample usage 2.1 ########################\n# the below fit statement trains the model\nmodel = autoClassify(scaler='standard',useGridtuning=False,gridDict = None).fit(X,y)\n## get model scores \nprint(model.getModelScores())\n################ sample usage 2.2 ########################\n## the below fit statement would ask autopredict to perform\n## hyper parameter tuning using Gridsearch\nmodel = autoClassify(scaler='standard',useGridtuning=True,gridDict = None).fit(X,y)\n####### sample useage 2.3 ##################\n##### the below fit uses grid tuning to fit models but over-rides\n### auto-predict's base grid search parameters and models\n\n# Define the grid that you want to run \ngrid = {'LogisticRegression':{'penalty':['l2']\n                               ,'C':[0.001,0.1,1,10]}\n        ,'DecisionTreeClassifier': {'max_depth':[4,5,6,7,8,9,10]}\n        ,'RandomForestClassifier':{'n_estimators':[100,500,1000],\n                                   'max_depth':[4,5]}\n        ,'GradientBoostingClassifier':{'learning_rate':[0.01,0.1,0.2,0.3],\n                                      'n_estimaors':[1000]}\n                           }\n\n# train the model , passing useGridtuning as True which tells\n# the function to use Grid Tuning and pass the grid to be used\n# in case you pass gridDict as NUll default options set in autopredict\n# would be used\nmodel = autoClassify(scaler='standard',useGridtuning=True,gridDict = grid).fit(X,y)\n\n# Step 3 get the score board\nprint(model.getModelScores())\nprint(model._predict_df)\n\n# step 4 if you want to get a model object back to predict ouput\n# below gets the best model object based onb accuracy score \n# you can over-ride the default scoring mechanism by using \n# score paramter in the the getBestModel Function\nmodel_obj = model.getBestModel()\n\n# Step 4.1 In case you want to select any other model \n# the model Name is derived from the output \n# you get when you print print(model.getModelScores())\nmodel_obj = model.getModelObject('DecisionTreeClassifier')\n\n# Step 5 To predict using the model object use the below statement\ny_predict = model_obj.predict(validTestData)\n\n# Other Misc features\n\n# 1 If you want to compress memory usage of your datframe use the\n# reduce_memory utilty this will compress your feature set and display\n# the compress percentage \ndf = reduce_memory(df)\n\n# 2 Using stacked Ensemble models is only supported for\n# binary classification for now below is sample usage\n# where lgb and catboost are being used as base models\n# and then the output is consume by LR model to give final ouput\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom autopredict.stacking import stackClassify\nfrom catboost import CatBoostClassifier\n\n# LightGBM params\nlgb_params = {}\nlgb_params['learning_rate'] = 0.02\nlgb_params['n_estimators'] = 650\nlgb_params['max_bin'] = 10\nlgb_params['subsample'] = 0.8\nlgb_params['subsample_freq'] = 10\nlgb_params['colsample_bytree'] = 0.8\nlgb_params['min_child_samples'] = 500\nlgb_params['seed'] = 99\nlgmodel = LGBMClassifier(**lgb_params)\n\ncat_params = {}\ncat_params['iterations'] = 900\ncat_params['depth'] = 8\ncat_params['rsm'] = 0.95\ncat_params['learning_rate'] = 0.03\ncat_params['l2_leaf_reg'] = 3.5\ncat_params['border_count'] = 8\ncatmodel = CatBoostClassifier(**cat_params)\n\nlogmodel = LogisticRegression()\ntmp = stackClassify(splits=2,stackerModel=logmodel ,\n              models= [lgmodel,catmodel],score='roc_auc',seed=100)\n\ny_pred_prob = tmp.fit_predict(X=train,y=target_train,test=test)\n# y_pred_prob has the predict probability for True class\n\n```\n\n\n\n### Development\n\nWant to contribute? \nPlease reach out to me at slatawa@yahoo.in and we can go over the Queue items planned for \nthe next release \n\n### Todos\n\n - Write MORE Tests\n - Build catboost,LGB,XGB as a seperate feature\n\nLicense\n----\nApache v2.0\n\n\n**Free Software, Hell Yeah!**\n\n[//]: # (These are reference links used in the body of this note and get stripped out when the markdown processor does its job. There is no need to format nicely because it shouldn't be seen. Thanks SO - http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/slatawa/autopredict.git", "keywords": "", "license": "Apache Software License", "maintainer": "", "maintainer_email": "", "name": "autopredict", "package_url": "https://pypi.org/project/autopredict/", "platform": "", "project_url": "https://pypi.org/project/autopredict/", "project_urls": {"Homepage": "https://github.com/slatawa/autopredict.git"}, "release_url": "https://pypi.org/project/autopredict/1.0.9/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Autopredict is a package to automate Machine learning model selection/ feature selection tasks", "version": "1.0.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>autopredict</h1>\n<p><a href=\"https://nodesource.com/products/nsolid\" rel=\"nofollow\"><img alt=\"N|Solid\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eb14efebd90f02b8ed9e7d256d7b377b6d1ac114/68747470733a2f2f636c6475702e636f6d2f645478705069396c44662e7468756d622e706e67\"></a></p>\n<p><a href=\"https://github.com/slatawa/autopredict\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/46a86bdaceb13474da2f9cbfdb20be1bb45f5a01/68747470733a2f2f7472617669732d63692e6f72672f6a6f656d6363616e6e2f64696c6c696e6765722e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>Autopredict is a simple yet powerful library which can be used by Data Scientists to create multiple prediction (regression,classification) data models.Pass in the data to autopredict and sit back as it does all the work for you. It is very powerfull in creating intial baseline models and also has ready made tweaked parameters for multiple models to generate highly accurate predictions.</p>\n<ul>\n<li>Automate Model Selection</li>\n<li>Hyperparameter tuning</li>\n<li>Feature selection/ranking</li>\n<li>Feature Compression</li>\n<li>Stacked Ensemble Models</li>\n</ul>\n<p>This software has been designed with much Joy,\nby Sanchit Latawa &amp; is protected by The Apache Licensev2.0.</p>\n<h1>New Features!</h1>\n<ul>\n<li>Added new classification Models</li>\n<li>Allow grid tuning parameters to be passed in as argument</li>\n</ul>\n<h3>Tech</h3>\n<h3>Sample Usage</h3>\n<pre>&gt;&gt; from autopredict.classification import autoClassify\n&gt;&gt; <span class=\"nv\">model</span> <span class=\"o\">=</span>autoClassify<span class=\"o\">(</span><span class=\"nv\">encoder</span><span class=\"o\">=</span><span class=\"s1\">'label'</span>,scaler<span class=\"o\">=</span><span class=\"s1\">'minmax'</span>,useGridtuning<span class=\"o\">=</span>False<span class=\"o\">)</span>\n&gt;&gt; model.train<span class=\"o\">(</span>X,y<span class=\"o\">)</span>\n&gt;&gt;print<span class=\"o\">(</span>model.getModelScores<span class=\"o\">())</span>  \n</pre>\n<h3>Output</h3>\n<pre>modelName                  score     roc_auc_score  f1_score\nLogisticRegression         <span class=\"m\">0</span>.927464   <span class=\"m\">0</span>.639570      <span class=\"m\">0</span>.000000\nDecisionTreeClassifier     <span class=\"m\">0</span>.937422   <span class=\"m\">0</span>.788967      <span class=\"m\">0</span>.285612\nGaussianNB                 <span class=\"m\">0</span>.935352   <span class=\"m\">0</span>.760670      <span class=\"m\">0</span>.203207\nRandomForestClassifier     <span class=\"m\">0</span>.937297   <span class=\"m\">0</span>.791552      <span class=\"m\">0</span>.248444\nGradientBoostingClassifier <span class=\"m\">0</span>.937472   <span class=\"m\">0</span>.792435      <span class=\"m\">0</span>.257557\n</pre>\n<h3>Sample Run for Iris Dataset</h3>\n<p>Below shows sample code flow for using autopredict , you can get this sample file\nfrom -&gt; */autopredict/tests/sample_iris_classification.py</p>\n<pre><span class=\"c1\"># Loading Libraries</span>\nimport pandas as pd\nfrom autopredict.classification import autoClassify\nfrom autopredict.features import rankFeatures,reduce_memory\n\n<span class=\"c1\"># Setting display options</span>\npd.set_option<span class=\"o\">(</span><span class=\"s1\">'display.max_columns'</span>,50000<span class=\"o\">)</span>\npd.set_option<span class=\"o\">(</span><span class=\"s1\">'display.width'</span>, <span class=\"m\">500000</span><span class=\"o\">)</span>\n\n<span class=\"c1\"># Load the data into a dataframe</span>\n<span class=\"nv\">df</span> <span class=\"o\">=</span> pd.read_csv<span class=\"o\">(</span><span class=\"s1\">'./tests/iris.csv'</span><span class=\"o\">)</span>\n\n<span class=\"c1\"># St target and feature values</span>\n<span class=\"nv\">X</span><span class=\"o\">=</span>df.drop<span class=\"o\">(</span><span class=\"s1\">'Species'</span>,axis<span class=\"o\">=</span><span class=\"m\">1</span><span class=\"o\">)</span>\n<span class=\"nv\">y</span><span class=\"o\">=</span>df<span class=\"o\">[</span><span class=\"s1\">'Species'</span><span class=\"o\">]</span>\n\n<span class=\"c1\"># step 1  Feature Importance/Evaluation</span>\n<span class=\"c1\"># rankFeatures is a function in autopredict which you can</span>\n<span class=\"c1\"># use for feature evaluation it will give you the ranking of your features</span>\n<span class=\"c1\"># based on importance , with the most important feature starting from 1</span>\nprint<span class=\"o\">(</span>rankFeatures<span class=\"o\">(</span>X,y<span class=\"o\">))</span>\n<span class=\"c1\">## Sample Output - showing features along with their realtive rank  ########</span>\n<span class=\"c1\">#     Column-name  Importance-Rank</span>\n<span class=\"c1\"># 0   Petal.Width              1.0</span>\n<span class=\"c1\"># 1  Petal.Length              1.5</span>\n<span class=\"c1\"># 2  Sepal.Length              3.0</span>\n<span class=\"c1\"># 3   Sepal.Width              3.0</span>\n\n<span class=\"c1\">## Once you have the list of importance of the features</span>\n<span class=\"c1\">## you can either drop or add some new features which </span>\n<span class=\"c1\">## would be used in the prediction modeling</span>\n\n<span class=\"c1\">## step 2 Train the model/evaluate</span>\n\n<span class=\"c1\">################ sample usage 2.1 ########################</span>\n<span class=\"c1\"># the below fit statement trains the model</span>\n<span class=\"nv\">model</span> <span class=\"o\">=</span> autoClassify<span class=\"o\">(</span><span class=\"nv\">scaler</span><span class=\"o\">=</span><span class=\"s1\">'standard'</span>,useGridtuning<span class=\"o\">=</span>False,gridDict <span class=\"o\">=</span> None<span class=\"o\">)</span>.fit<span class=\"o\">(</span>X,y<span class=\"o\">)</span>\n<span class=\"c1\">## get model scores </span>\nprint<span class=\"o\">(</span>model.getModelScores<span class=\"o\">())</span>\n<span class=\"c1\">################ sample usage 2.2 ########################</span>\n<span class=\"c1\">## the below fit statement would ask autopredict to perform</span>\n<span class=\"c1\">## hyper parameter tuning using Gridsearch</span>\n<span class=\"nv\">model</span> <span class=\"o\">=</span> autoClassify<span class=\"o\">(</span><span class=\"nv\">scaler</span><span class=\"o\">=</span><span class=\"s1\">'standard'</span>,useGridtuning<span class=\"o\">=</span>True,gridDict <span class=\"o\">=</span> None<span class=\"o\">)</span>.fit<span class=\"o\">(</span>X,y<span class=\"o\">)</span>\n<span class=\"c1\">####### sample useage 2.3 ##################</span>\n<span class=\"c1\">##### the below fit uses grid tuning to fit models but over-rides</span>\n<span class=\"c1\">### auto-predict's base grid search parameters and models</span>\n\n<span class=\"c1\"># Define the grid that you want to run </span>\n<span class=\"nv\">grid</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"s1\">'LogisticRegression'</span>:<span class=\"o\">{</span><span class=\"s1\">'penalty'</span>:<span class=\"o\">[</span><span class=\"s1\">'l2'</span><span class=\"o\">]</span>\n                               ,<span class=\"s1\">'C'</span>:<span class=\"o\">[</span><span class=\"m\">0</span>.001,0.1,1,10<span class=\"o\">]}</span>\n        ,<span class=\"s1\">'DecisionTreeClassifier'</span>: <span class=\"o\">{</span><span class=\"s1\">'max_depth'</span>:<span class=\"o\">[</span><span class=\"m\">4</span>,5,6,7,8,9,10<span class=\"o\">]}</span>\n        ,<span class=\"s1\">'RandomForestClassifier'</span>:<span class=\"o\">{</span><span class=\"s1\">'n_estimators'</span>:<span class=\"o\">[</span><span class=\"m\">100</span>,500,1000<span class=\"o\">]</span>,\n                                   <span class=\"s1\">'max_depth'</span>:<span class=\"o\">[</span><span class=\"m\">4</span>,5<span class=\"o\">]}</span>\n        ,<span class=\"s1\">'GradientBoostingClassifier'</span>:<span class=\"o\">{</span><span class=\"s1\">'learning_rate'</span>:<span class=\"o\">[</span><span class=\"m\">0</span>.01,0.1,0.2,0.3<span class=\"o\">]</span>,\n                                      <span class=\"s1\">'n_estimaors'</span>:<span class=\"o\">[</span><span class=\"m\">1000</span><span class=\"o\">]}</span>\n                           <span class=\"o\">}</span>\n\n<span class=\"c1\"># train the model , passing useGridtuning as True which tells</span>\n<span class=\"c1\"># the function to use Grid Tuning and pass the grid to be used</span>\n<span class=\"c1\"># in case you pass gridDict as NUll default options set in autopredict</span>\n<span class=\"c1\"># would be used</span>\n<span class=\"nv\">model</span> <span class=\"o\">=</span> autoClassify<span class=\"o\">(</span><span class=\"nv\">scaler</span><span class=\"o\">=</span><span class=\"s1\">'standard'</span>,useGridtuning<span class=\"o\">=</span>True,gridDict <span class=\"o\">=</span> grid<span class=\"o\">)</span>.fit<span class=\"o\">(</span>X,y<span class=\"o\">)</span>\n\n<span class=\"c1\"># Step 3 get the score board</span>\nprint<span class=\"o\">(</span>model.getModelScores<span class=\"o\">())</span>\nprint<span class=\"o\">(</span>model._predict_df<span class=\"o\">)</span>\n\n<span class=\"c1\"># step 4 if you want to get a model object back to predict ouput</span>\n<span class=\"c1\"># below gets the best model object based onb accuracy score </span>\n<span class=\"c1\"># you can over-ride the default scoring mechanism by using </span>\n<span class=\"c1\"># score paramter in the the getBestModel Function</span>\n<span class=\"nv\">model_obj</span> <span class=\"o\">=</span> model.getBestModel<span class=\"o\">()</span>\n\n<span class=\"c1\"># Step 4.1 In case you want to select any other model </span>\n<span class=\"c1\"># the model Name is derived from the output </span>\n<span class=\"c1\"># you get when you print print(model.getModelScores())</span>\n<span class=\"nv\">model_obj</span> <span class=\"o\">=</span> model.getModelObject<span class=\"o\">(</span><span class=\"s1\">'DecisionTreeClassifier'</span><span class=\"o\">)</span>\n\n<span class=\"c1\"># Step 5 To predict using the model object use the below statement</span>\n<span class=\"nv\">y_predict</span> <span class=\"o\">=</span> model_obj.predict<span class=\"o\">(</span>validTestData<span class=\"o\">)</span>\n\n<span class=\"c1\"># Other Misc features</span>\n\n<span class=\"c1\"># 1 If you want to compress memory usage of your datframe use the</span>\n<span class=\"c1\"># reduce_memory utilty this will compress your feature set and display</span>\n<span class=\"c1\"># the compress percentage </span>\n<span class=\"nv\">df</span> <span class=\"o\">=</span> reduce_memory<span class=\"o\">(</span>df<span class=\"o\">)</span>\n\n<span class=\"c1\"># 2 Using stacked Ensemble models is only supported for</span>\n<span class=\"c1\"># binary classification for now below is sample usage</span>\n<span class=\"c1\"># where lgb and catboost are being used as base models</span>\n<span class=\"c1\"># and then the output is consume by LR model to give final ouput</span>\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom autopredict.stacking import stackClassify\nfrom catboost import CatBoostClassifier\n\n<span class=\"c1\"># LightGBM params</span>\n<span class=\"nv\">lgb_params</span> <span class=\"o\">=</span> <span class=\"o\">{}</span>\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'learning_rate'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">0</span>.02\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'n_estimators'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">650</span>\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'max_bin'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">10</span>\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'subsample'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">0</span>.8\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'subsample_freq'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">10</span>\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'colsample_bytree'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">0</span>.8\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'min_child_samples'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">500</span>\nlgb_params<span class=\"o\">[</span><span class=\"s1\">'seed'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">99</span>\n<span class=\"nv\">lgmodel</span> <span class=\"o\">=</span> LGBMClassifier<span class=\"o\">(</span>**lgb_params<span class=\"o\">)</span>\n\n<span class=\"nv\">cat_params</span> <span class=\"o\">=</span> <span class=\"o\">{}</span>\ncat_params<span class=\"o\">[</span><span class=\"s1\">'iterations'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">900</span>\ncat_params<span class=\"o\">[</span><span class=\"s1\">'depth'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">8</span>\ncat_params<span class=\"o\">[</span><span class=\"s1\">'rsm'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">0</span>.95\ncat_params<span class=\"o\">[</span><span class=\"s1\">'learning_rate'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">0</span>.03\ncat_params<span class=\"o\">[</span><span class=\"s1\">'l2_leaf_reg'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">3</span>.5\ncat_params<span class=\"o\">[</span><span class=\"s1\">'border_count'</span><span class=\"o\">]</span> <span class=\"o\">=</span> <span class=\"m\">8</span>\n<span class=\"nv\">catmodel</span> <span class=\"o\">=</span> CatBoostClassifier<span class=\"o\">(</span>**cat_params<span class=\"o\">)</span>\n\n<span class=\"nv\">logmodel</span> <span class=\"o\">=</span> LogisticRegression<span class=\"o\">()</span>\n<span class=\"nv\">tmp</span> <span class=\"o\">=</span> stackClassify<span class=\"o\">(</span><span class=\"nv\">splits</span><span class=\"o\">=</span><span class=\"m\">2</span>,stackerModel<span class=\"o\">=</span>logmodel ,\n              <span class=\"nv\">models</span><span class=\"o\">=</span> <span class=\"o\">[</span>lgmodel,catmodel<span class=\"o\">]</span>,score<span class=\"o\">=</span><span class=\"s1\">'roc_auc'</span>,seed<span class=\"o\">=</span><span class=\"m\">100</span><span class=\"o\">)</span>\n\n<span class=\"nv\">y_pred_prob</span> <span class=\"o\">=</span> tmp.fit_predict<span class=\"o\">(</span><span class=\"nv\">X</span><span class=\"o\">=</span>train,y<span class=\"o\">=</span>target_train,test<span class=\"o\">=</span><span class=\"nb\">test</span><span class=\"o\">)</span>\n<span class=\"c1\"># y_pred_prob has the predict probability for True class</span>\n</pre>\n<h3>Development</h3>\n<p>Want to contribute?\nPlease reach out to me at <a href=\"mailto:slatawa@yahoo.in\">slatawa@yahoo.in</a> and we can go over the Queue items planned for\nthe next release</p>\n<h3>Todos</h3>\n<ul>\n<li>Write MORE Tests</li>\n<li>Build catboost,LGB,XGB as a seperate feature</li>\n</ul>\n<h2>License</h2>\n<p>Apache v2.0</p>\n<p><strong>Free Software, Hell Yeah!</strong></p>\n\n          </div>"}, "last_serial": 6907442, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "cc6e533c279d269a4fe3d21df69e08b6", "sha256": "967b685ebc852b280132231b1cc2c3368c227309445323a1555b80cf9b19873b"}, "downloads": -1, "filename": "autopredict-0.0.1.tar.gz", "has_sig": false, "md5_digest": "cc6e533c279d269a4fe3d21df69e08b6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 1566, "upload_time": "2020-03-14T07:38:07", "upload_time_iso_8601": "2020-03-14T07:38:07.617194Z", "url": "https://files.pythonhosted.org/packages/ea/af/d9b06121cb1ad2d9a6b888da8c1816999f7ea69330f26d2e6091c79f7f78/autopredict-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "dff9a4f894892a309662295c5164a37e", "sha256": "5b318e039cd3cba499285d25a7c52f2379d3e5068e72a98b31c710df41de2e38"}, "downloads": -1, "filename": "autopredict-0.0.2.tar.gz", "has_sig": false, "md5_digest": "dff9a4f894892a309662295c5164a37e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 5488, "upload_time": "2020-03-14T18:09:18", "upload_time_iso_8601": "2020-03-14T18:09:18.148519Z", "url": "https://files.pythonhosted.org/packages/0c/1b/601494f1d81a3cc8d26e461d1edad71242c4c0a010322a2df139a58526ea/autopredict-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "f1ddcce26469bfb9c9dad655207fdf30", "sha256": "d93613177ce2437b09f5905c00661f3d11334eb350867045cb588e66b5e25ee7"}, "downloads": -1, "filename": "autopredict-0.0.3.tar.gz", "has_sig": false, "md5_digest": "f1ddcce26469bfb9c9dad655207fdf30", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 6170, "upload_time": "2020-03-14T19:32:40", "upload_time_iso_8601": "2020-03-14T19:32:40.524786Z", "url": "https://files.pythonhosted.org/packages/50/10/d41f85c858cfaad47bfa317e5279a5b6a86dcba1ea1652959ef7c64915ed/autopredict-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "0d6e3a93177dd8fff7db39cb62ce11b7", "sha256": "bd7174ce2d5f2b1f63401a7f84f6b2eb1994b5ec293e67f65890b02c60129a3b"}, "downloads": -1, "filename": "autopredict-0.0.4.tar.gz", "has_sig": false, "md5_digest": "0d6e3a93177dd8fff7db39cb62ce11b7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 6168, "upload_time": "2020-03-14T19:32:42", "upload_time_iso_8601": "2020-03-14T19:32:42.070649Z", "url": "https://files.pythonhosted.org/packages/84/dc/f27a34e6d1e984d308597261019bc1fa1ae1031e7e91ccc09cf6cf0ac693/autopredict-0.0.4.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "8cf1e7ac34884273792b2db65575858f", "sha256": "ccc69f90b04b016431fa8e326db07d1e25f5a0df6abd4f9afac54e7f6d106f0d"}, "downloads": -1, "filename": "autopredict-1.0.0.tar.gz", "has_sig": false, "md5_digest": "8cf1e7ac34884273792b2db65575858f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 6178, "upload_time": "2020-03-14T19:32:43", "upload_time_iso_8601": "2020-03-14T19:32:43.774660Z", "url": "https://files.pythonhosted.org/packages/6a/fa/b41e8573ee6ecdeb469d54e2a0c66286373c266def768fb6de31153da358/autopredict-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "61918939d037e049c49b8ed59ee4cf2c", "sha256": "87f25191d5ad0fadb1217c1eb6c0837c87f1f55c46dd726cc9cc7a840f99b0b7"}, "downloads": -1, "filename": "autopredict-1.0.1.tar.gz", "has_sig": false, "md5_digest": "61918939d037e049c49b8ed59ee4cf2c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 7344, "upload_time": "2020-03-15T12:34:34", "upload_time_iso_8601": "2020-03-15T12:34:34.716027Z", "url": "https://files.pythonhosted.org/packages/85/ae/273790e5eaf3b6e9fda55631610d56374b1a2a5cc92f96591067b92382f0/autopredict-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "66cd5b34cb86a1e4becf8eb8e350f85b", "sha256": "bcc05fa6e6a0ed6ae8fb06a3d843538063e4e9d02ef44fb0633a2aea90db447a"}, "downloads": -1, "filename": "autopredict-1.0.2.tar.gz", "has_sig": false, "md5_digest": "66cd5b34cb86a1e4becf8eb8e350f85b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 7337, "upload_time": "2020-03-15T12:34:35", "upload_time_iso_8601": "2020-03-15T12:34:35.997001Z", "url": "https://files.pythonhosted.org/packages/f6/32/c5fdc809adf290fe9fafdb170de4df7381d41c9bce822783e7ee7e333131/autopredict-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "aae8feceadb2d5e9ff34142965560d33", "sha256": "7c8521f53dfc8acf9696ec6d9ab299c743e24d6cc15da1cc679f82a1ebc3697f"}, "downloads": -1, "filename": "autopredict-1.0.3.tar.gz", "has_sig": false, "md5_digest": "aae8feceadb2d5e9ff34142965560d33", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 7347, "upload_time": "2020-03-15T12:34:37", "upload_time_iso_8601": "2020-03-15T12:34:37.257334Z", "url": "https://files.pythonhosted.org/packages/98/8f/e32aeefc961e3adcd3847f0ec9db6753088ded6184ea6ded28b46032668c/autopredict-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "9563a1cd4ea747b53ee987ea3c02b760", "sha256": "28745a618bf808fd9c651d7835d330ed16b5e46e421cfd31fdee5ea9494e5b44"}, "downloads": -1, "filename": "autopredict-1.0.4.tar.gz", "has_sig": false, "md5_digest": "9563a1cd4ea747b53ee987ea3c02b760", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 8984, "upload_time": "2020-03-15T13:07:23", "upload_time_iso_8601": "2020-03-15T13:07:23.612058Z", "url": "https://files.pythonhosted.org/packages/c7/0a/40b2bd1f498aba14d1acb980df70abb61056ae0ee221fc9c88f2dd9eca94/autopredict-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "f4945c176975b44723290bf0db28fae3", "sha256": "3a9c778f849367d09b3039e8c8b2199b19bb47e402bce8ec4cbd7a4ccf1ab98d"}, "downloads": -1, "filename": "autopredict-1.0.5.tar.gz", "has_sig": false, "md5_digest": "f4945c176975b44723290bf0db28fae3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 10707, "upload_time": "2020-03-18T08:07:01", "upload_time_iso_8601": "2020-03-18T08:07:01.751150Z", "url": "https://files.pythonhosted.org/packages/f9/09/d951c916a8799dad8a9c5f0a1f93108c5c07fba72c01902b0e6f9417c410/autopredict-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "a4e72107e6287373a3ebc43456106230", "sha256": "a3303cd93f5725938dad65339d4de4638a5a7d701dd0bc74efcbd80e5527eb7c"}, "downloads": -1, "filename": "autopredict-1.0.6.tar.gz", "has_sig": false, "md5_digest": "a4e72107e6287373a3ebc43456106230", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 9661, "upload_time": "2020-03-27T12:15:43", "upload_time_iso_8601": "2020-03-27T12:15:43.814250Z", "url": "https://files.pythonhosted.org/packages/35/45/94f04426c705cd5c275f7c5788cb13c6b5d098f86cfe5141d2bd77e457f2/autopredict-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "b9228f117bce63ae5f795453613854e8", "sha256": "818b743b12ac56b29193d39b730c65e221ed82463db1e62c49558a8d6aa2d59e"}, "downloads": -1, "filename": "autopredict-1.0.7.tar.gz", "has_sig": false, "md5_digest": "b9228f117bce63ae5f795453613854e8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 14030, "upload_time": "2020-03-28T13:31:49", "upload_time_iso_8601": "2020-03-28T13:31:49.977498Z", "url": "https://files.pythonhosted.org/packages/4e/a5/a47e1393c5975fe1c5cba83fada876950b9461653075958f8bfc2ea56fe3/autopredict-1.0.7.tar.gz", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "89da4742785b100ab6cee06f56ad7c9e", "sha256": "1d621ba7d47e806fbe0e1f25a52732d96740d1ab7b800487e63787bf2a7a2a42"}, "downloads": -1, "filename": "autopredict-1.0.8.tar.gz", "has_sig": false, "md5_digest": "89da4742785b100ab6cee06f56ad7c9e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 14156, "upload_time": "2020-03-28T13:56:35", "upload_time_iso_8601": "2020-03-28T13:56:35.582635Z", "url": "https://files.pythonhosted.org/packages/67/45/021c994499e106e9659aec08f05648669841089d0194212a14b261244eef/autopredict-1.0.8.tar.gz", "yanked": false}], "1.0.9": [{"comment_text": "", "digests": {"md5": "bf209f21c9ed4e12803e12f02b10dd6d", "sha256": "8d7d8d1270971df3b6d5db6890922aeff0cd3e4988648e3735d535ee0ce4c5c1"}, "downloads": -1, "filename": "autopredict-1.0.9.tar.gz", "has_sig": false, "md5_digest": "bf209f21c9ed4e12803e12f02b10dd6d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16377, "upload_time": "2020-03-29T16:31:33", "upload_time_iso_8601": "2020-03-29T16:31:33.505926Z", "url": "https://files.pythonhosted.org/packages/6f/d7/cb26ea7a70df3062bd3a415f466de395c3b5420beabb79f41e69fab6c3bf/autopredict-1.0.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bf209f21c9ed4e12803e12f02b10dd6d", "sha256": "8d7d8d1270971df3b6d5db6890922aeff0cd3e4988648e3735d535ee0ce4c5c1"}, "downloads": -1, "filename": "autopredict-1.0.9.tar.gz", "has_sig": false, "md5_digest": "bf209f21c9ed4e12803e12f02b10dd6d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16377, "upload_time": "2020-03-29T16:31:33", "upload_time_iso_8601": "2020-03-29T16:31:33.505926Z", "url": "https://files.pythonhosted.org/packages/6f/d7/cb26ea7a70df3062bd3a415f466de395c3b5420beabb79f41e69fab6c3bf/autopredict-1.0.9.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:11 2020"}