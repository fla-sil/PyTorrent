{"info": {"author": "Oslandia", "author_email": "info@oslandia.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "\nThis project aims at showcasing some Deep Learning use cases in terms of image\nanalysis, especially regarding semantic segmentation.\n\nIf you want to get more details on Oslandia activities around this topic, feel\nfree to visit our [blog](http://oslandia.com/en/blog/). You certainly want to\ndiscover some of our results in the\nassociated [web application](http://data.oslandia.io/deeposlandia):\n\n# Content\n\nThe project contains the following folders:\n\n+ [deeposlandia](./deeposlandia) contains the main Python modules to train and\n  test convolutional neural networks\n+ [docs](./docs) contains some markdown files for documentation purpose\n+ [examples](./examples) contains some Jupyter notebooks that aim at\n  describing data and building basic neural networks\n+ [images](./images) contains some example images to illustrate the Mapillary\n  dataset as well as some preprocessing analysis results\n+ [tests](./tests); `pytest` is used to launch several tests from this folder.\n\nAdditionally, running the code may generate extra subdirectories in the chosen\ndata repository.\n\n# Installation\n\n## Requirements\n\nThe code has been run with Python 3. The dependencies are specified in\n`setup.py` file, and additional dependencies for developing purpose are listed\nin `requirements-dev.txt`.\n\n### From source\n\n```\n$ git clone https://github.com/Oslandia/deeposlandia\n$ cd deeposlandia\n$ virtualenv -p /usr/bin/python3 venv\n$ source venv/bin/activate\n(venv)$ pip install -r requirements-dev.txt\n```\n\n### GDAL\n\nAs a particular case, GDAL is not included into the `setup.py` file.\n\nFor `Ubuntu` distributions, the following operations are needed to install this\nprogram:\n\n```\nsudo apt-get install libgdal-dev\nsudo apt-get install python3-gdal\n```\n\nThe `GDAL` version can be verified by:\n\n```\ngdal-config --version\n```\n\nAfter that, a simple `pip install GDAL` may be sufficient, however considering\nour own experience it is not the case on Ubuntu. One has to retrieve a `GDAL`\nfor Python that corresponds to the `GDAL` of system:\n\n```\npip install --global-option=build_ext --global-option=\"-I/usr/include/gdal\" GDAL==`gdal-config --version`\npython3 -c \"import osgeo;print(osgeo.__version__)\"\n```\n\nFor other OS, please visit the `GDAL` installation documentation.\n\n## Running the code\n\nA command-line interface is proposed with 4 available actions (`datagen`,\n`train`, `infer` and `postprocess`), callable as follows:\n\n```\ndeepo [command] --options\n```\n\nSome files document the command use:\n\n- [Preprocessed dataset generation](./docs/preprocessing.md)\n- [Train a model](./docs/training.md)\n- [Infer labels](./docs/inference.md)\n- [Postprocess results for geographic datasets](./docs/postprocess.md)\n- [Run your own web app instance](./docs/webapp.md)\n\n# Supported datasets\n\n## Mapillary\n\nIn this project we use a set of images provided\nby [Mapillary](https://www.mapillary.com/), in order to investigate on the\npresence of some typical street-scene objects (vehicles, roads,\npedestrians...). Mapillary released this dataset on July 2017, it\nis [available on its website](https://www.mapillary.com/dataset/vistas) and may\nbe downloaded freely for a research purpose.\n\nAs inputs, Mapillary provides a bunch of street scene images of various sizes\nin a `images` repository, and the same images after filtering process in\n`instances` and `labels` repositories.\n\nThere are 18000 images in the training set, 2000 images in the validation set,\nand 5000 images in the testing set. The testing set is proposed only for a\nmodel test purpose, it does not contain filtered versions of images. The raw\ndataset contains 66 labels, splitted into 13 categories. The following figure\ndepicts a prediction result over the 13-labelled dataset version.\n\n![Example of image, with labels and predictions](./images/mapillary_prediction_example.png)\n\n## AerialImage (Inria)\n\nIn the [Aerial image dataset](https://project.inria.fr/aerialimagelabeling/files/),\nthere are only 2 labels, i.e. `building` or `background` and consequently the\nmodel aims at answering one single question for each image pixel: does this\npixel belongs to a building?\n\nThe dataset contains 360 images, one half for training one half for\ntesting. Each of these images are 5000*5000 `tif` images. Amongst the 180\ntraining images, we assigned 15 training images to validation. One example of\nthis image from this dataset is depicted below.\n\n![Example of image, with labels and predictions](./images/aerial_prediction_example.png)\n\n## Open AI Tanzania\n\nThis dataset comes from\nthe\n[Tanzania challenge](https://blog.werobotics.org/2018/08/06/welcome-to-the-open-ai-tanzania-challenge/),\nthat took place at the autumn 2018. The dataset contains 13 labelled images (2\nof them were assigned to validation in this project), and 9 additional images\nfor testing purpose. The image resolution is very high (6~8 cm per pixel), that\nallowing a fine data preprocessing step.\n\nIn such a dataset, one tries to automatically detect building footprints by\ndistinguishing complete buildings, incomplete buildings and foudations.\n\n![Example of image, with labels and predictions](./images/tanzania_prediction_example.png)\n\n## Shapes\n\nTo complete the project, and make the test easier, a randomly-generated shape\nmodel is also available. In this dataset, some simple coloured geometric shapes\nare inserted into each picture, on a total random mode. There can be one\nrectangle, one circle and/or one triangle per image, or neither of them. Their\nlocation into each image is randomly generated (they just can't be too close to\nimage borders). The shape and background colors are randomly generated as well.\n\n## How to add a new dataset?\n\nIf you want to contribute to the repo by adding a new dataset, please consult the [following instructions](./docs/add_a_dataset.md).\n\n## Pre-trained models\n\nThis project implies non-commercial use of datasets, anyway we can work with\nthe dataset emitters to get commercial licences if it fits your demand. May you\nbe interested in any pre-trained models, please contact us at\ninfos+data@oslandia.com!\n\n# License\n\nThe program license is described in [LICENSE.md](./LICENSE.md).\n\n___\n\nOslandia, April 2018\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Oslandia/deeposlandia", "keywords": "deep learning,convolutional neural networks,image,Keras", "license": "MIT", "maintainer": "Oslandia", "maintainer_email": "", "name": "deeposlandia", "package_url": "https://pypi.org/project/deeposlandia/", "platform": "", "project_url": "https://pypi.org/project/deeposlandia/", "project_urls": {"Homepage": "https://github.com/Oslandia/deeposlandia"}, "release_url": "https://pypi.org/project/deeposlandia/0.6.1/", "requires_dist": ["tensorflow (==1.15.2)", "opencv-python (<=3.4.0.12)", "pillow (<=6.2.0)", "keras (<=2.2.4)", "daiquiri (<=1.5.0)", "Flask (<=1.0.2)", "seaborn (<=0.8.1)", "geopandas (<=0.4.0)", "rtree (<=0.8)"], "requires_python": ">=3", "summary": "Automatic detection and semantic image segmentation with deep learning", "version": "0.6.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This project aims at showcasing some Deep Learning use cases in terms of image\nanalysis, especially regarding semantic segmentation.</p>\n<p>If you want to get more details on Oslandia activities around this topic, feel\nfree to visit our [blog](<a href=\"http://oslandia.com/en/blog/\" rel=\"nofollow\">http://oslandia.com/en/blog/</a>). You certainly want to\ndiscover some of our results in the\nassociated [web application](<a href=\"http://data.oslandia.io/deeposlandia\" rel=\"nofollow\">http://data.oslandia.io/deeposlandia</a>):</p>\n<p># Content</p>\n<p>The project contains the following folders:</p>\n<ul>\n<li>[deeposlandia](./deeposlandia) contains the main Python modules to train and\ntest convolutional neural networks</li>\n<li>[docs](./docs) contains some markdown files for documentation purpose</li>\n<li>[examples](./examples) contains some Jupyter notebooks that aim at\ndescribing data and building basic neural networks</li>\n<li>[images](./images) contains some example images to illustrate the Mapillary\ndataset as well as some preprocessing analysis results</li>\n<li>[tests](./tests); <cite>pytest</cite> is used to launch several tests from this folder.</li>\n</ul>\n<p>Additionally, running the code may generate extra subdirectories in the chosen\ndata repository.</p>\n<p># Installation</p>\n<p>## Requirements</p>\n<p>The code has been run with Python 3. The dependencies are specified in\n<cite>setup.py</cite> file, and additional dependencies for developing purpose are listed\nin <cite>requirements-dev.txt</cite>.</p>\n<p>### From source</p>\n<p><tt>`\n$ git clone <span class=\"pre\">https://github.com/Oslandia/deeposlandia</span>\n$ cd deeposlandia\n$ virtualenv <span class=\"pre\">-p</span> /usr/bin/python3 venv\n$ source venv/bin/activate\n(venv)$ pip install <span class=\"pre\">-r</span> <span class=\"pre\">requirements-dev.txt</span>\n`</tt></p>\n<p>### GDAL</p>\n<p>As a particular case, GDAL is not included into the <cite>setup.py</cite> file.</p>\n<p>For <cite>Ubuntu</cite> distributions, the following operations are needed to install this\nprogram:</p>\n<p><tt>`\nsudo <span class=\"pre\">apt-get</span> install <span class=\"pre\">libgdal-dev</span>\nsudo <span class=\"pre\">apt-get</span> install <span class=\"pre\">python3-gdal</span>\n`</tt></p>\n<p>The <cite>GDAL</cite> version can be verified by:</p>\n<p><tt>`\n<span class=\"pre\">gdal-config</span> <span class=\"pre\">--version</span>\n`</tt></p>\n<p>After that, a simple <cite>pip install GDAL</cite> may be sufficient, however considering\nour own experience it is not the case on Ubuntu. One has to retrieve a <cite>GDAL</cite>\nfor Python that corresponds to the <cite>GDAL</cite> of system:</p>\n<p><tt>`\npip install <span class=\"pre\">--global-option=build_ext</span> <span class=\"pre\">--global-option=\"-I/usr/include/gdal\"</span> <span class=\"pre\">GDAL==`gdal-config</span> <span class=\"pre\">--version`</span>\npython3 <span class=\"pre\">-c</span> \"import osgeo;print(osgeo.__version__)\"\n`</tt></p>\n<p>For other OS, please visit the <cite>GDAL</cite> installation documentation.</p>\n<p>## Running the code</p>\n<p>A command-line interface is proposed with 4 available actions (<cite>datagen</cite>,\n<cite>train</cite>, <cite>infer</cite> and <cite>postprocess</cite>), callable as follows:</p>\n<p><tt>`\ndeepo [command] <span class=\"pre\">--options</span>\n`</tt></p>\n<p>Some files document the command use:</p>\n<ul>\n<li>[Preprocessed dataset generation](./docs/preprocessing.md)</li>\n<li>[Train a model](./docs/training.md)</li>\n<li>[Infer labels](./docs/inference.md)</li>\n<li>[Postprocess results for geographic datasets](./docs/postprocess.md)</li>\n<li>[Run your own web app instance](./docs/webapp.md)</li>\n</ul>\n<p># Supported datasets</p>\n<p>## Mapillary</p>\n<p>In this project we use a set of images provided\nby [Mapillary](<a href=\"https://www.mapillary.com/\" rel=\"nofollow\">https://www.mapillary.com/</a>), in order to investigate on the\npresence of some typical street-scene objects (vehicles, roads,\npedestrians\u2026). Mapillary released this dataset on July 2017, it\nis [available on its website](<a href=\"https://www.mapillary.com/dataset/vistas\" rel=\"nofollow\">https://www.mapillary.com/dataset/vistas</a>) and may\nbe downloaded freely for a research purpose.</p>\n<p>As inputs, Mapillary provides a bunch of street scene images of various sizes\nin a <cite>images</cite> repository, and the same images after filtering process in\n<cite>instances</cite> and <cite>labels</cite> repositories.</p>\n<p>There are 18000 images in the training set, 2000 images in the validation set,\nand 5000 images in the testing set. The testing set is proposed only for a\nmodel test purpose, it does not contain filtered versions of images. The raw\ndataset contains 66 labels, splitted into 13 categories. The following figure\ndepicts a prediction result over the 13-labelled dataset version.</p>\n<p>![Example of image, with labels and predictions](./images/mapillary_prediction_example.png)</p>\n<p>## AerialImage (Inria)</p>\n<p>In the [Aerial image dataset](<a href=\"https://project.inria.fr/aerialimagelabeling/files/\" rel=\"nofollow\">https://project.inria.fr/aerialimagelabeling/files/</a>),\nthere are only 2 labels, i.e. <cite>building</cite> or <cite>background</cite> and consequently the\nmodel aims at answering one single question for each image pixel: does this\npixel belongs to a building?</p>\n<p>The dataset contains 360 images, one half for training one half for\ntesting. Each of these images are 5000*5000 <cite>tif</cite> images. Amongst the 180\ntraining images, we assigned 15 training images to validation. One example of\nthis image from this dataset is depicted below.</p>\n<p>![Example of image, with labels and predictions](./images/aerial_prediction_example.png)</p>\n<p>## Open AI Tanzania</p>\n<p>This dataset comes from\nthe\n[Tanzania challenge](<a href=\"https://blog.werobotics.org/2018/08/06/welcome-to-the-open-ai-tanzania-challenge/\" rel=\"nofollow\">https://blog.werobotics.org/2018/08/06/welcome-to-the-open-ai-tanzania-challenge/</a>),\nthat took place at the autumn 2018. The dataset contains 13 labelled images (2\nof them were assigned to validation in this project), and 9 additional images\nfor testing purpose. The image resolution is very high (6~8 cm per pixel), that\nallowing a fine data preprocessing step.</p>\n<p>In such a dataset, one tries to automatically detect building footprints by\ndistinguishing complete buildings, incomplete buildings and foudations.</p>\n<p>![Example of image, with labels and predictions](./images/tanzania_prediction_example.png)</p>\n<p>## Shapes</p>\n<p>To complete the project, and make the test easier, a randomly-generated shape\nmodel is also available. In this dataset, some simple coloured geometric shapes\nare inserted into each picture, on a total random mode. There can be one\nrectangle, one circle and/or one triangle per image, or neither of them. Their\nlocation into each image is randomly generated (they just can\u2019t be too close to\nimage borders). The shape and background colors are randomly generated as well.</p>\n<p>## How to add a new dataset?</p>\n<p>If you want to contribute to the repo by adding a new dataset, please consult the [following instructions](./docs/add_a_dataset.md).</p>\n<p>## Pre-trained models</p>\n<p>This project implies non-commercial use of datasets, anyway we can work with\nthe dataset emitters to get commercial licences if it fits your demand. May you\nbe interested in any pre-trained models, please contact us at\n<a href=\"mailto:infos+data%40oslandia.com\">infos+data<span>@</span>oslandia<span>.</span>com</a>!</p>\n<p># License</p>\n<p>The program license is described in [LICENSE.md](./LICENSE.md).</p>\n<p>___</p>\n<p>Oslandia, April 2018</p>\n\n          </div>"}, "last_serial": 6927639, "releases": {"0.4": [{"comment_text": "", "digests": {"md5": "5afb878d7a24b105af8bb2ff3d705c33", "sha256": "5868af000702e640d85fa4689a105130838c5d5d03446899147e6df2091fc076"}, "downloads": -1, "filename": "deeposlandia-0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "5afb878d7a24b105af8bb2ff3d705c33", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 34431, "upload_time": "2018-05-03T16:26:30", "upload_time_iso_8601": "2018-05-03T16:26:30.150963Z", "url": "https://files.pythonhosted.org/packages/a1/06/ffb2331853fee4f106ee34c0f0745a5e8eff5f8d9dc9a726de14b558d33f/deeposlandia-0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0ef16adb6c5b18d84be24a0a4adf416b", "sha256": "f66af13b713149da2d8d1b74f687b78380df65c407127ae5033ea4a677ed6c21"}, "downloads": -1, "filename": "deeposlandia-0.4.tar.gz", "has_sig": false, "md5_digest": "0ef16adb6c5b18d84be24a0a4adf416b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 24269, "upload_time": "2018-05-03T16:26:31", "upload_time_iso_8601": "2018-05-03T16:26:31.557980Z", "url": "https://files.pythonhosted.org/packages/c7/ca/a02cc70bac6f00fb2fbcb7f7ae8f0ef45a8487a7ca6796989ae4d35f1975/deeposlandia-0.4.tar.gz", "yanked": false}], "0.5": [{"comment_text": "", "digests": {"md5": "df93087f555ae9029295ff85a0b33d5f", "sha256": "e5579b1b84691573b374e7ae1fcc3d305ced9c9a28bd52a40314961dae7f9863"}, "downloads": -1, "filename": "deeposlandia-0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "df93087f555ae9029295ff85a0b33d5f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 57165, "upload_time": "2020-04-01T12:21:07", "upload_time_iso_8601": "2020-04-01T12:21:07.264276Z", "url": "https://files.pythonhosted.org/packages/4e/d5/87f116aab58dfa1a507c70ad13e8d52cde3678bdbdbb2a06304716133fb3/deeposlandia-0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0f6fddce45844b794f9454c7936b695f", "sha256": "2f0aaed8c13157b8afc683921679866860489ec5b0d026935c5e4f83f4c1a4ce"}, "downloads": -1, "filename": "deeposlandia-0.5.tar.gz", "has_sig": false, "md5_digest": "0f6fddce45844b794f9454c7936b695f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 46006, "upload_time": "2020-04-01T12:21:09", "upload_time_iso_8601": "2020-04-01T12:21:09.313214Z", "url": "https://files.pythonhosted.org/packages/0c/bd/c8e148078e7d3aabd74f4603deca5737a6c3d2ceb09418cda6287f912da2/deeposlandia-0.5.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "e143bf30f8d62aee4c4a03596cee2d05", "sha256": "3c0e62d93f87bb8e7efb87f42b93dc49c9d3ea501111a195c3110708811346a4"}, "downloads": -1, "filename": "deeposlandia-0.6.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e143bf30f8d62aee4c4a03596cee2d05", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 57192, "upload_time": "2020-04-01T13:27:50", "upload_time_iso_8601": "2020-04-01T13:27:50.482091Z", "url": "https://files.pythonhosted.org/packages/00/30/5f2c783b12b0b178fdd42f482521e6392b91eb61ee3b194f0e6a8577cc60/deeposlandia-0.6.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "96bc4258516f22aa3001a88782465336", "sha256": "e813905481d4fc22db9dba1afe1e0bf654aa83b3531300f7bc075d0dafa069e2"}, "downloads": -1, "filename": "deeposlandia-0.6.1.tar.gz", "has_sig": false, "md5_digest": "96bc4258516f22aa3001a88782465336", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 46021, "upload_time": "2020-04-01T13:27:52", "upload_time_iso_8601": "2020-04-01T13:27:52.514164Z", "url": "https://files.pythonhosted.org/packages/5e/8f/bb253b94c656c771cf3829ba452c660967c2588eaf4ab7e61b04c307a130/deeposlandia-0.6.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e143bf30f8d62aee4c4a03596cee2d05", "sha256": "3c0e62d93f87bb8e7efb87f42b93dc49c9d3ea501111a195c3110708811346a4"}, "downloads": -1, "filename": "deeposlandia-0.6.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e143bf30f8d62aee4c4a03596cee2d05", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 57192, "upload_time": "2020-04-01T13:27:50", "upload_time_iso_8601": "2020-04-01T13:27:50.482091Z", "url": "https://files.pythonhosted.org/packages/00/30/5f2c783b12b0b178fdd42f482521e6392b91eb61ee3b194f0e6a8577cc60/deeposlandia-0.6.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "96bc4258516f22aa3001a88782465336", "sha256": "e813905481d4fc22db9dba1afe1e0bf654aa83b3531300f7bc075d0dafa069e2"}, "downloads": -1, "filename": "deeposlandia-0.6.1.tar.gz", "has_sig": false, "md5_digest": "96bc4258516f22aa3001a88782465336", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 46021, "upload_time": "2020-04-01T13:27:52", "upload_time_iso_8601": "2020-04-01T13:27:52.514164Z", "url": "https://files.pythonhosted.org/packages/5e/8f/bb253b94c656c771cf3829ba452c660967c2588eaf4ab7e61b04c307a130/deeposlandia-0.6.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:22 2020"}