{"info": {"author": "Francisco Aranda", "author_email": "francisco@recogn.ai", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Programming Language :: Python"], "description": "# spaCy WordNet\n\nspaCy Wordnet is a simple custom component for using [WordNet](https://wordnet.princeton.edu/), [MultiWordnet](http://multiwordnet.fbk.eu/english/home.php) and [WordNet domains](http://wndomains.fbk.eu/) with [spaCy](http://spacy.io).\n\nThe component combines the [NLTK wordnet interface](http://www.nltk.org/howto/wordnet.html) with WordNet domains to allow users to:\n\n* Get all synsets for a processed token. For example, getting all the synsets (word senses) of the word ``bank``.\n* Get and filter synsets by domain. For example, getting synonyms of the verb ``withdraw`` in the financial domain.\n\n \n## Getting started\nThe spaCy WordNet component can be easily integrated into spaCy pipelines. You just need the following:\n### Prerequisites\n\n* Python 3.X\n* spaCy\n\nYou also need to install the following NLTK wordnet data:\n\n````bash\npython -m nltk.downloader wordnet\npython -m nltk.downloader omw\n````\n### Install\n\n````bash\npip install spacy-wordnet\n````\n\n\n\n## Usage\n\n````python\n\nimport spacy\n\nfrom spacy_wordnet.wordnet_annotator import WordnetAnnotator \n\n# Load an spacy model (supported models are \"es\" and \"en\") \nnlp = spacy.load('en')\nnlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')\ntoken = nlp('prices')[0]\n\n# wordnet object link spacy token with nltk wordnet interface by giving acces to\n# synsets and lemmas \ntoken._.wordnet.synsets()\ntoken._.wordnet.lemmas()\n\n# And automatically tags with wordnet domains\ntoken._.wordnet.wordnet_domains()\n\n# Imagine we want to enrich the following sentence with synonyms\nsentence = nlp('I want to withdraw 5,000 euros')\n\n# spaCy WordNet lets you find synonyms by domain of interest\n# for example economy\neconomy_domains = ['finance', 'banking']\nenriched_sentence = []\n\n# For each token in the sentence\nfor token in sentence:\n    # We get those synsets within the desired domains\n    synsets = token._.wordnet.wordnet_synsets_for_domain(economy_domains)\n    if synsets:\n        lemmas_for_synset = []\n        for s in synsets:\n            # If we found a synset in the economy domains\n            # we get the variants and add them to the enriched sentence\n            lemmas_for_synset.extend(s.lemma_names())\n            enriched_sentence.append('({})'.format('|'.join(set(lemmas_for_synset))))\n    else:\n        enriched_sentence.append(token.text)\n\n# Let's see our enriched sentence\nprint(' '.join(enriched_sentence))\n# >> I (need|want|require) to (draw|withdraw|draw_off|take_out) 5,000 euros\n    \n````", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/recognai/spacy-wordnet", "keywords": "", "license": "mit", "maintainer": "", "maintainer_email": "", "name": "spacy-wordnet", "package_url": "https://pypi.org/project/spacy-wordnet/", "platform": "any", "project_url": "https://pypi.org/project/spacy-wordnet/", "project_urls": {"Homepage": "https://github.com/recognai/spacy-wordnet"}, "release_url": "https://pypi.org/project/spacy-wordnet/0.0.4/", "requires_dist": null, "requires_python": "", "summary": "Add a short description here!", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>spaCy WordNet</h1>\n<p>spaCy Wordnet is a simple custom component for using <a href=\"https://wordnet.princeton.edu/\" rel=\"nofollow\">WordNet</a>, <a href=\"http://multiwordnet.fbk.eu/english/home.php\" rel=\"nofollow\">MultiWordnet</a> and <a href=\"http://wndomains.fbk.eu/\" rel=\"nofollow\">WordNet domains</a> with <a href=\"http://spacy.io\" rel=\"nofollow\">spaCy</a>.</p>\n<p>The component combines the <a href=\"http://www.nltk.org/howto/wordnet.html\" rel=\"nofollow\">NLTK wordnet interface</a> with WordNet domains to allow users to:</p>\n<ul>\n<li>Get all synsets for a processed token. For example, getting all the synsets (word senses) of the word <code>bank</code>.</li>\n<li>Get and filter synsets by domain. For example, getting synonyms of the verb <code>withdraw</code> in the financial domain.</li>\n</ul>\n<h2>Getting started</h2>\n<p>The spaCy WordNet component can be easily integrated into spaCy pipelines. You just need the following:</p>\n<h3>Prerequisites</h3>\n<ul>\n<li>Python 3.X</li>\n<li>spaCy</li>\n</ul>\n<p>You also need to install the following NLTK wordnet data:</p>\n<pre>python -m nltk.downloader wordnet\npython -m nltk.downloader omw\n</pre>\n<h3>Install</h3>\n<pre>pip install spacy-wordnet\n</pre>\n<h2>Usage</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_wordnet.wordnet_annotator</span> <span class=\"kn\">import</span> <span class=\"n\">WordnetAnnotator</span> \n\n<span class=\"c1\"># Load an spacy model (supported models are \"es\" and \"en\") </span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'en'</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">WordnetAnnotator</span><span class=\"p\">(</span><span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">lang</span><span class=\"p\">),</span> <span class=\"n\">after</span><span class=\"o\">=</span><span class=\"s1\">'tagger'</span><span class=\"p\">)</span>\n<span class=\"n\">token</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s1\">'prices'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># wordnet object link spacy token with nltk wordnet interface by giving acces to</span>\n<span class=\"c1\"># synsets and lemmas </span>\n<span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">wordnet</span><span class=\"o\">.</span><span class=\"n\">synsets</span><span class=\"p\">()</span>\n<span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">wordnet</span><span class=\"o\">.</span><span class=\"n\">lemmas</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># And automatically tags with wordnet domains</span>\n<span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">wordnet</span><span class=\"o\">.</span><span class=\"n\">wordnet_domains</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Imagine we want to enrich the following sentence with synonyms</span>\n<span class=\"n\">sentence</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s1\">'I want to withdraw 5,000 euros'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># spaCy WordNet lets you find synonyms by domain of interest</span>\n<span class=\"c1\"># for example economy</span>\n<span class=\"n\">economy_domains</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'finance'</span><span class=\"p\">,</span> <span class=\"s1\">'banking'</span><span class=\"p\">]</span>\n<span class=\"n\">enriched_sentence</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"c1\"># For each token in the sentence</span>\n<span class=\"k\">for</span> <span class=\"n\">token</span> <span class=\"ow\">in</span> <span class=\"n\">sentence</span><span class=\"p\">:</span>\n    <span class=\"c1\"># We get those synsets within the desired domains</span>\n    <span class=\"n\">synsets</span> <span class=\"o\">=</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">_</span><span class=\"o\">.</span><span class=\"n\">wordnet</span><span class=\"o\">.</span><span class=\"n\">wordnet_synsets_for_domain</span><span class=\"p\">(</span><span class=\"n\">economy_domains</span><span class=\"p\">)</span>\n    <span class=\"k\">if</span> <span class=\"n\">synsets</span><span class=\"p\">:</span>\n        <span class=\"n\">lemmas_for_synset</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n        <span class=\"k\">for</span> <span class=\"n\">s</span> <span class=\"ow\">in</span> <span class=\"n\">synsets</span><span class=\"p\">:</span>\n            <span class=\"c1\"># If we found a synset in the economy domains</span>\n            <span class=\"c1\"># we get the variants and add them to the enriched sentence</span>\n            <span class=\"n\">lemmas_for_synset</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">lemma_names</span><span class=\"p\">())</span>\n            <span class=\"n\">enriched_sentence</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"s1\">'(</span><span class=\"si\">{}</span><span class=\"s1\">)'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"s1\">'|'</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"nb\">set</span><span class=\"p\">(</span><span class=\"n\">lemmas_for_synset</span><span class=\"p\">))))</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">enriched_sentence</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Let's see our enriched sentence</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">' '</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">enriched_sentence</span><span class=\"p\">))</span>\n<span class=\"c1\"># &gt;&gt; I (need|want|require) to (draw|withdraw|draw_off|take_out) 5,000 euros</span>\n    \n</pre>\n\n          </div>"}, "last_serial": 4608155, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "44b8fb5bcc9c8af9b229d9caeb5ea0f9", "sha256": "c30c70f3b01c013243ecf31cc80ffb6330bdadac5b82d53d65c701f8f28fae00"}, "downloads": -1, "filename": "spacy-wordnet-0.0.1.tar.gz", "has_sig": false, "md5_digest": "44b8fb5bcc9c8af9b229d9caeb5ea0f9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 83875, "upload_time": "2018-11-10T12:43:17", "upload_time_iso_8601": "2018-11-10T12:43:17.386778Z", "url": "https://files.pythonhosted.org/packages/f1/8e/e85da0ed4bdccfbb42234de6da25fec3ad4ac261ec5fe30d1d1804ba102e/spacy-wordnet-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "f0325e036108d1808eafbaaf9bb96dc8", "sha256": "b0914146d2fe0800453b84ca5ac7beffd5c7082880bc38a5f246abd5d53370fc"}, "downloads": -1, "filename": "spacy-wordnet-0.0.2.tar.gz", "has_sig": false, "md5_digest": "f0325e036108d1808eafbaaf9bb96dc8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 646615, "upload_time": "2018-11-11T14:06:15", "upload_time_iso_8601": "2018-11-11T14:06:15.378220Z", "url": "https://files.pythonhosted.org/packages/ff/ed/c75be0267fc48ce179fb96ec97eafb327b90a492b7a7b87d420371e68007/spacy-wordnet-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "342e40b2674132300bd7b6f8dd51db43", "sha256": "3c10815687cd7a7071a4d2d667765f63dbed437dd97bf3ba1dd46d741a238942"}, "downloads": -1, "filename": "spacy-wordnet-0.0.3.tar.gz", "has_sig": false, "md5_digest": "342e40b2674132300bd7b6f8dd51db43", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 646613, "upload_time": "2018-11-14T16:04:52", "upload_time_iso_8601": "2018-11-14T16:04:52.499010Z", "url": "https://files.pythonhosted.org/packages/ec/b2/e147b4565827e1c951bcdb3bfaffcbc40220b60ddae54ea0ce8146bc8d9c/spacy-wordnet-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "2b67a822abb576cfb39f86aa42e9848e", "sha256": "39b72d5929a2e06ba8ccb3800e70695fa88ed66fa3bc7f45171d7d6fa8fd59fa"}, "downloads": -1, "filename": "spacy-wordnet-0.0.4.tar.gz", "has_sig": false, "md5_digest": "2b67a822abb576cfb39f86aa42e9848e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 648169, "upload_time": "2018-12-17T14:07:58", "upload_time_iso_8601": "2018-12-17T14:07:58.505479Z", "url": "https://files.pythonhosted.org/packages/f7/f2/4d8070df0f7a7a9eeed74eb7e9ce3cf41349eb5e06b1e088de9eeca630e2/spacy-wordnet-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2b67a822abb576cfb39f86aa42e9848e", "sha256": "39b72d5929a2e06ba8ccb3800e70695fa88ed66fa3bc7f45171d7d6fa8fd59fa"}, "downloads": -1, "filename": "spacy-wordnet-0.0.4.tar.gz", "has_sig": false, "md5_digest": "2b67a822abb576cfb39f86aa42e9848e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 648169, "upload_time": "2018-12-17T14:07:58", "upload_time_iso_8601": "2018-12-17T14:07:58.505479Z", "url": "https://files.pythonhosted.org/packages/f7/f2/4d8070df0f7a7a9eeed74eb7e9ce3cf41349eb5e06b1e088de9eeca630e2/spacy-wordnet-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:02 2020"}