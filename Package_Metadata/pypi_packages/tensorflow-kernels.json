{"info": {"author": "Campese Stefano", "author_email": "stefano.campese.90@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics"], "description": "# Tensorflow-kernels\n\n![Logo](/doc/img/image.png)\n\nA package with Tensorflow (both CPU and GPU) implementation of most popular Kernels for kernels methods (SVM, MKL...).\n\nThose kernels works with tensor as inputs.\n\nThe main idea of this project is to exploit the powerfull of GPUs and modern CPUs on matrix and kernels elaborations.\nActually the implemented kernels are:\n\n+ Linear\n+ RBF\n+ Polynomial\n+ CosineSimilarity\n+ Fourier\n+ Spline\n\n**Attention:** Due to the GPUs usage the precision of decimal numbers may be different, and hence, the results may be slightly differs as well\n\n**Attention 2:** Due to exploit the power of GPUs it's strongly recommended to work with float32 or even in half precision float16.\n# Examples: \n\nA simple example with ```PolynomialKernel```\n```python\nimport numpy as np\nimport tensorflow as tf\nfrom kernels.polynomial_kernel import PolynomialKernel\nfrom kernels import array_to_tensor, tensor_to_array\n\nn = 2000\np = 1000\na = np.random.random((n, p)).astype(np.float32)\nb = np.random.random((n, p)).astype(np.float32)\n\nx = array_to_tensor(a, dtype=tf.float32)\ny = array_to_tensor(b, dtype=tf.float32)\n\n\npoly = PolynomialKernel(scale=1, bias=0, degree=4)\nkernel = poly.compute(x, y)\n\nprint(tensor_to_array(kernel, dtype=np.float32))\n\n\n```\n\nA simple example with ```PSpectrumKernel```. \n**Attention:** PSpectrum is still experimental and it exploits *eager computation* in order to work properly. \nFurthermore it maybe won't works with Tensorflow 2.0 since some packages have been removed.\n\n**Attention 2:** Due to the usage of the type ```tf.string``` computation will be shared between GPUs and CPUs.\n\n**Attention 3:** This kernel return tensor with type tf.int64.\n\n```python\nimport numpy as np\nimport tensorflow as tf\nfrom kernels.experimental.p_spectrum_kernel import PSpectrumKernel\nfrom kernels import array_to_tensor, tensor_to_array\n\na = np.array(['aaaaaaaa','bbbbbbb','ccccc','aaaaaaa','cccccc','bbbbbb'])\nb = np.array(['aaaaaaaa','bbbbbbb','aaaaaaa','cccccc'])\n\nx = array_to_tensor(a, dtype=tf.string)\ny = array_to_tensor(b, dtype=tf.string)\n\np_spectrum = PSpectrumKernel(p=3)\n\nkernel = p_spectrum.compute(x, y)\n\nprint(tensor_to_array(kernel, dtype=np.float32))\n\n```\n\n\n# Credits:\nThe idea was born by using methods available here: [https://github.com/gmum/pykernels](https://github.com/gmum/pykernels)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sirCamp/tensorflow-kernels", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "tensorflow-kernels", "package_url": "https://pypi.org/project/tensorflow-kernels/", "platform": "", "project_url": "https://pypi.org/project/tensorflow-kernels/", "project_urls": {"Homepage": "https://github.com/sirCamp/tensorflow-kernels"}, "release_url": "https://pypi.org/project/tensorflow-kernels/0.1.2/", "requires_dist": ["tensorflow", "numpy"], "requires_python": "", "summary": "A package with Tensorflow (both CPU and GPU) implementation of most popular Kernels for kernels methods (SVM, MKL...).", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Tensorflow-kernels</h1>\n<p><img alt=\"Logo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d9912bd8873f176043cf6916b0811171ad2343e3/2f646f632f696d672f696d6167652e706e67\"></p>\n<p>A package with Tensorflow (both CPU and GPU) implementation of most popular Kernels for kernels methods (SVM, MKL...).</p>\n<p>Those kernels works with tensor as inputs.</p>\n<p>The main idea of this project is to exploit the powerfull of GPUs and modern CPUs on matrix and kernels elaborations.\nActually the implemented kernels are:</p>\n<ul>\n<li>Linear</li>\n<li>RBF</li>\n<li>Polynomial</li>\n<li>CosineSimilarity</li>\n<li>Fourier</li>\n<li>Spline</li>\n</ul>\n<p><strong>Attention:</strong> Due to the GPUs usage the precision of decimal numbers may be different, and hence, the results may be slightly differs as well</p>\n<p><strong>Attention 2:</strong> Due to exploit the power of GPUs it's strongly recommended to work with float32 or even in half precision float16.</p>\n<h1>Examples:</h1>\n<p>A simple example with <code>PolynomialKernel</code></p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n<span class=\"kn\">from</span> <span class=\"nn\">kernels.polynomial_kernel</span> <span class=\"kn\">import</span> <span class=\"n\">PolynomialKernel</span>\n<span class=\"kn\">from</span> <span class=\"nn\">kernels</span> <span class=\"kn\">import</span> <span class=\"n\">array_to_tensor</span><span class=\"p\">,</span> <span class=\"n\">tensor_to_array</span>\n\n<span class=\"n\">n</span> <span class=\"o\">=</span> <span class=\"mi\">2000</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n<span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"p\">((</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">array_to_tensor</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">array_to_tensor</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">poly</span> <span class=\"o\">=</span> <span class=\"n\">PolynomialKernel</span><span class=\"p\">(</span><span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">degree</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">poly</span><span class=\"o\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tensor_to_array</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n</pre>\n<p>A simple example with <code>PSpectrumKernel</code>.\n<strong>Attention:</strong> PSpectrum is still experimental and it exploits <em>eager computation</em> in order to work properly.\nFurthermore it maybe won't works with Tensorflow 2.0 since some packages have been removed.</p>\n<p><strong>Attention 2:</strong> Due to the usage of the type <code>tf.string</code> computation will be shared between GPUs and CPUs.</p>\n<p><strong>Attention 3:</strong> This kernel return tensor with type tf.int64.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n<span class=\"kn\">from</span> <span class=\"nn\">kernels.experimental.p_spectrum_kernel</span> <span class=\"kn\">import</span> <span class=\"n\">PSpectrumKernel</span>\n<span class=\"kn\">from</span> <span class=\"nn\">kernels</span> <span class=\"kn\">import</span> <span class=\"n\">array_to_tensor</span><span class=\"p\">,</span> <span class=\"n\">tensor_to_array</span>\n\n<span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"s1\">'aaaaaaaa'</span><span class=\"p\">,</span><span class=\"s1\">'bbbbbbb'</span><span class=\"p\">,</span><span class=\"s1\">'ccccc'</span><span class=\"p\">,</span><span class=\"s1\">'aaaaaaa'</span><span class=\"p\">,</span><span class=\"s1\">'cccccc'</span><span class=\"p\">,</span><span class=\"s1\">'bbbbbb'</span><span class=\"p\">])</span>\n<span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"s1\">'aaaaaaaa'</span><span class=\"p\">,</span><span class=\"s1\">'bbbbbbb'</span><span class=\"p\">,</span><span class=\"s1\">'aaaaaaa'</span><span class=\"p\">,</span><span class=\"s1\">'cccccc'</span><span class=\"p\">])</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">array_to_tensor</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">string</span><span class=\"p\">)</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">array_to_tensor</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">string</span><span class=\"p\">)</span>\n\n<span class=\"n\">p_spectrum</span> <span class=\"o\">=</span> <span class=\"n\">PSpectrumKernel</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n\n<span class=\"n\">kernel</span> <span class=\"o\">=</span> <span class=\"n\">p_spectrum</span><span class=\"o\">.</span><span class=\"n\">compute</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tensor_to_array</span><span class=\"p\">(</span><span class=\"n\">kernel</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n</pre>\n<h1>Credits:</h1>\n<p>The idea was born by using methods available here: <a href=\"https://github.com/gmum/pykernels\" rel=\"nofollow\">https://github.com/gmum/pykernels</a></p>\n\n          </div>"}, "last_serial": 5356005, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "0f1279b9a4d8645302affac4b853645e", "sha256": "64ec69c8e908a5f94827e677ae0adc5e50b4d57cb37536ec960c83f4024ec3f1"}, "downloads": -1, "filename": "tensorflow_kernels-0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "0f1279b9a4d8645302affac4b853645e", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 10160, "upload_time": "2019-05-31T14:21:27", "upload_time_iso_8601": "2019-05-31T14:21:27.119160Z", "url": "https://files.pythonhosted.org/packages/3b/3f/dec0c46f994a9b436fd4e44656790e9e0d30a67e79589302bb378b788894/tensorflow_kernels-0.1-py2-none-any.whl", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "c655242dda9e63f7bcea9f9b413380e6", "sha256": "c176e63d55742426304d7251b37d39db32752e72caf460afe67f3f8d5186828d"}, "downloads": -1, "filename": "tensorflow_kernels-0.1.2-py2-none-any.whl", "has_sig": false, "md5_digest": "c655242dda9e63f7bcea9f9b413380e6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14203, "upload_time": "2019-06-04T07:21:30", "upload_time_iso_8601": "2019-06-04T07:21:30.365757Z", "url": "https://files.pythonhosted.org/packages/86/f2/40785f4f02373a3833984f5478dd375a3dae1e1dfceb442d824908d7b977/tensorflow_kernels-0.1.2-py2-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c655242dda9e63f7bcea9f9b413380e6", "sha256": "c176e63d55742426304d7251b37d39db32752e72caf460afe67f3f8d5186828d"}, "downloads": -1, "filename": "tensorflow_kernels-0.1.2-py2-none-any.whl", "has_sig": false, "md5_digest": "c655242dda9e63f7bcea9f9b413380e6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14203, "upload_time": "2019-06-04T07:21:30", "upload_time_iso_8601": "2019-06-04T07:21:30.365757Z", "url": "https://files.pythonhosted.org/packages/86/f2/40785f4f02373a3833984f5478dd375a3dae1e1dfceb442d824908d7b977/tensorflow_kernels-0.1.2-py2-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 02:56:09 2020"}