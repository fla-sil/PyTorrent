{"info": {"author": "Luke", "author_email": "lmelaskyriazi@college.harvard.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6"], "description": "# EfficientNet PyTorch\n\n\n_IMPORTANT NOTE_: In the latest update, I switched hosting providers for the pretrained models, as the previous models were becoming extremely expensive to host. This _will_ break old versions of the library. I apologize, but I cannot afford to keep serving the models on the old provider. Everything should work properly if you update the library: \n```\npip install --upgrade efficientnet-pytorch\n```\n\n### Update (January 23, 2020)\n\nThis update adds a new category of pre-trained model based on adversarial training, called _advprop_. It is important to note that the preprocessing required for the advprop pretrained models is slightly different from normal ImageNet preprocessing. As a result, by default, advprop models are not used. To load a model with advprop, use:\n```\nmodel = EfficientNet.from_pretrained(\"efficientnet-b0\", advprop=True)\n```\nThere is also a new, large `efficientnet-b8` pretrained model that is only available in advprop form. When using these models, replace ImageNet preprocessing code as follows:\n```\nif advprop:  # for models using advprop pretrained weights\n    normalize = transforms.Lambda(lambda img: img * 2.0 - 1.0)\nelse:\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                                     std=[0.229, 0.224, 0.225])\n\n```\nThis update also addresses multiple other issues ([#115](https://github.com/lukemelas/EfficientNet-PyTorch/issues/115), [#128](https://github.com/lukemelas/EfficientNet-PyTorch/issues/128)). \n\n### Update (October 15, 2019)\n\nThis update allows you to choose whether to use a memory-efficient Swish activation. The memory-efficient version is chosen by default, but it cannot be used when exporting using PyTorch JIT. For this purpose, we have also included a standard (export-friendly) swish activation function. To switch to the export-friendly version, simply call `model.set_swish(memory_efficient=False)` after loading your desired model. This update addresses issues [#88](https://github.com/lukemelas/EfficientNet-PyTorch/pull/88) and [#89](https://github.com/lukemelas/EfficientNet-PyTorch/pull/89).\n\n### Update (October 12, 2019)\n\nThis update makes the Swish activation function more memory-efficient. It also addresses pull requests [#72](https://github.com/lukemelas/EfficientNet-PyTorch/pull/72), [#73](https://github.com/lukemelas/EfficientNet-PyTorch/pull/73), [#85](https://github.com/lukemelas/EfficientNet-PyTorch/pull/85), and [#86](https://github.com/lukemelas/EfficientNet-PyTorch/pull/86). Thanks to the authors of all the pull requests! \n\n### Update (July 31, 2019)\n\n_Upgrade the pip package with_ `pip install --upgrade efficientnet-pytorch`\n\nThe B6 and B7 models are now available. Additionally, _all_ pretrained models have been updated to use AutoAugment preprocessing, which translates to better performance across the board. Usage is the same as before: \n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b7') \n```\n\n### Update (June 29, 2019)\n\nThis update adds easy model exporting ([#20](https://github.com/lukemelas/EfficientNet-PyTorch/issues/20)) and feature extraction ([#38](https://github.com/lukemelas/EfficientNet-PyTorch/issues/38)). \n\n * [Example: Export to ONNX](#example-export)\n * [Example: Extract features](#example-feature-extraction)\n * Also: fixed a CUDA/CPU bug ([#32](https://github.com/lukemelas/EfficientNet-PyTorch/issues/32))\n\nIt is also now incredibly simple to load a pretrained model with a new number of classes for transfer learning:\n```python\nmodel = EfficientNet.from_pretrained('efficientnet-b1', num_classes=23)\n``` \n\n\n### Update (June 23, 2019)\n\nThe B4 and B5 models are now available. Their usage is identical to the other models: \n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b4') \n```\n\n### Overview\nThis repository contains an op-for-op PyTorch reimplementation of [EfficientNet](https://arxiv.org/abs/1905.11946), along with pre-trained models and examples. \n\nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented. \n\nAt the moment, you can easily:  \n * Load pretrained EfficientNet models \n * Use EfficientNet models for classification or feature extraction \n * Evaluate EfficientNet models on ImageNet or your own images\n\n_Upcoming features_: In the next few days, you will be able to:\n * Train new models from scratch on ImageNet with a simple command \n * Quickly finetune an EfficientNet on your own dataset\n * Export EfficientNet models for production\n\n### Table of contents\n1. [About EfficientNet](#about-efficientnet)\n2. [About EfficientNet-PyTorch](#about-efficientnet-pytorch)\n3. [Installation](#installation)\n4. [Usage](#usage)\n    * [Load pretrained models](#loading-pretrained-models)\n    * [Example: Classify](#example-classification)\n    * [Example: Extract features](#example-feature-extraction)\n    * [Example: Export to ONNX](#example-export)\n6. [Contributing](#contributing) \n\n### About EfficientNet\n\nIf you're new to EfficientNets, here is an explanation straight from the official TensorFlow implementation: \n\nEfficientNets are a family of image classification models, which achieve state-of-the-art accuracy, yet being an order-of-magnitude smaller and faster than previous models. We develop EfficientNets based on AutoML and Compound Scaling. In particular, we first use [AutoML Mobile framework](https://ai.googleblog.com/2018/08/mnasnet-towards-automating-design-of.html) to develop a mobile-size baseline network, named as EfficientNet-B0; Then, we use the compound scaling method to scale up this baseline to obtain EfficientNet-B1 to B7.\n\n<table border=\"0\">\n<tr>\n    <td>\n    <img src=\"https://raw.githubusercontent.com/tensorflow/tpu/master/models/official/efficientnet/g3doc/params.png\" width=\"100%\" />\n    </td>\n    <td>\n    <img src=\"https://raw.githubusercontent.com/tensorflow/tpu/master/models/official/efficientnet/g3doc/flops.png\", width=\"90%\" />\n    </td>\n</tr>\n</table>\n\nEfficientNets achieve state-of-the-art accuracy on ImageNet with an order of magnitude better efficiency:\n\n\n* In high-accuracy regime, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet with 66M parameters and 37B FLOPS, being 8.4x smaller and 6.1x faster on CPU inference than previous best [Gpipe](https://arxiv.org/abs/1811.06965).\n\n* In middle-accuracy regime, our EfficientNet-B1 is 7.6x smaller and 5.7x faster on CPU inference than [ResNet-152](https://arxiv.org/abs/1512.03385), with similar ImageNet accuracy.\n\n* Compared with the widely used [ResNet-50](https://arxiv.org/abs/1512.03385), our EfficientNet-B4 improves the top-1 accuracy from 76.3% of ResNet-50 to 82.6% (+6.3%), under similar FLOPS constraint.\n\n### About EfficientNet PyTorch\n\nEfficientNet PyTorch is a PyTorch re-implementation of EfficientNet. It is consistent with the [original TensorFlow implementation](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet), such that it is easy to load weights from a TensorFlow checkpoint. At the same time, we aim to make our PyTorch implementation as simple, flexible, and extensible as possible.\n\nIf you have any feature requests or questions, feel free to leave them as GitHub issues!\n\n### Installation\n\nInstall via pip:\n```bash\npip install efficientnet_pytorch\n```\n\nOr install from source:\n```bash\ngit clone https://github.com/lukemelas/EfficientNet-PyTorch\ncd EfficientNet-Pytorch\npip install -e .\n``` \n\n### Usage\n\n#### Loading pretrained models\n\nLoad an EfficientNet:  \n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_name('efficientnet-b0')\n```\n\nLoad a pretrained EfficientNet: \n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n```\n\nNote that pretrained models have only been released for `N=0,1,2,3,4,5` at the current time, so `.from_pretrained` only supports `'efficientnet-b{N}'` for `N=0,1,2,3,4,5`. \n\nDetails about the models are below: \n\n|    *Name*         |*# Params*|*Top-1 Acc.*|*Pretrained?*|\n|:-----------------:|:--------:|:----------:|:-----------:|\n| `efficientnet-b0` |   5.3M   |    76.3    |      \u2713      |\n| `efficientnet-b1` |   7.8M   |    78.8    |      \u2713      |\n| `efficientnet-b2` |   9.2M   |    79.8    |      \u2713      |\n| `efficientnet-b3` |    12M   |    81.1    |      \u2713      |\n| `efficientnet-b4` |    19M   |    82.6    |      \u2713      |\n| `efficientnet-b5` |    30M   |    83.3    |      \u2713      |\n| `efficientnet-b6` |    43M   |    84.0    |      \u2713      |\n| `efficientnet-b7` |    66M   |    84.4    |      \u2713      |\n\n\n#### Example: Classification\n\nBelow is a simple, complete example. It may also be found as a jupyter notebook in `examples/simple` or as a [Colab Notebook](https://colab.research.google.com/drive/1Jw28xZ1NJq4Cja4jLe6tJ6_F5lCzElb4).\n\nWe assume that in your current directory, there is a `img.jpg` file and a `labels_map.txt` file (ImageNet class names). These are both included in `examples/simple`. \n\n```python\nimport json\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n\n# Preprocess image\ntfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\nimg = tfms(Image.open('img.jpg')).unsqueeze(0)\nprint(img.shape) # torch.Size([1, 3, 224, 224])\n\n# Load ImageNet class names\nlabels_map = json.load(open('labels_map.txt'))\nlabels_map = [labels_map[str(i)] for i in range(1000)]\n\n# Classify\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(img)\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(outputs, k=5).indices.squeeze(0).tolist():\n    prob = torch.softmax(outputs, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=labels_map[idx], p=prob*100))\n```\n\n#### Example: Feature Extraction \n\nYou can easily extract features with `model.extract_features`:\n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n\n# ... image preprocessing as in the classification example ...\nprint(img.shape) # torch.Size([1, 3, 224, 224])\n\nfeatures = model.extract_features(img)\nprint(features.shape) # torch.Size([1, 1280, 7, 7])\n```\n\n#### Example: Export to ONNX  \n\nExporting to ONNX for deploying to production is now simple: \n```python\nimport torch \nfrom efficientnet_pytorch import EfficientNet\n\nmodel = EfficientNet.from_pretrained('efficientnet-b1')\ndummy_input = torch.randn(10, 3, 240, 240)\n\ntorch.onnx.export(model, dummy_input, \"test-b1.onnx\", verbose=True)\n``` \n\n[Here](https://colab.research.google.com/drive/1rOAEXeXHaA8uo3aG2YcFDHItlRJMV0VP) is a Colab example. \n\n\n#### ImageNet\n\nSee `examples/imagenet` for details about evaluating on ImageNet.\n\n### Contributing\n\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.   \n\nI look forward to seeing what the community does with these models!", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/lukemelas/efficientnet_pytorch", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "efficientnet-pytorch", "package_url": "https://pypi.org/project/efficientnet-pytorch/", "platform": "", "project_url": "https://pypi.org/project/efficientnet-pytorch/", "project_urls": {"Homepage": "https://github.com/lukemelas/efficientnet_pytorch"}, "release_url": "https://pypi.org/project/efficientnet-pytorch/0.6.3/", "requires_dist": null, "requires_python": ">=3.5.0", "summary": "EfficientNet implemented in PyTorch.", "version": "0.6.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>EfficientNet PyTorch</h1>\n<p><em>IMPORTANT NOTE</em>: In the latest update, I switched hosting providers for the pretrained models, as the previous models were becoming extremely expensive to host. This <em>will</em> break old versions of the library. I apologize, but I cannot afford to keep serving the models on the old provider. Everything should work properly if you update the library:</p>\n<pre><code>pip install --upgrade efficientnet-pytorch\n</code></pre>\n<h3>Update (January 23, 2020)</h3>\n<p>This update adds a new category of pre-trained model based on adversarial training, called <em>advprop</em>. It is important to note that the preprocessing required for the advprop pretrained models is slightly different from normal ImageNet preprocessing. As a result, by default, advprop models are not used. To load a model with advprop, use:</p>\n<pre><code>model = EfficientNet.from_pretrained(\"efficientnet-b0\", advprop=True)\n</code></pre>\n<p>There is also a new, large <code>efficientnet-b8</code> pretrained model that is only available in advprop form. When using these models, replace ImageNet preprocessing code as follows:</p>\n<pre><code>if advprop:  # for models using advprop pretrained weights\n    normalize = transforms.Lambda(lambda img: img * 2.0 - 1.0)\nelse:\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                                     std=[0.229, 0.224, 0.225])\n\n</code></pre>\n<p>This update also addresses multiple other issues (<a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/issues/115\" rel=\"nofollow\">#115</a>, <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/issues/128\" rel=\"nofollow\">#128</a>).</p>\n<h3>Update (October 15, 2019)</h3>\n<p>This update allows you to choose whether to use a memory-efficient Swish activation. The memory-efficient version is chosen by default, but it cannot be used when exporting using PyTorch JIT. For this purpose, we have also included a standard (export-friendly) swish activation function. To switch to the export-friendly version, simply call <code>model.set_swish(memory_efficient=False)</code> after loading your desired model. This update addresses issues <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/pull/88\" rel=\"nofollow\">#88</a> and <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/pull/89\" rel=\"nofollow\">#89</a>.</p>\n<h3>Update (October 12, 2019)</h3>\n<p>This update makes the Swish activation function more memory-efficient. It also addresses pull requests <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/pull/72\" rel=\"nofollow\">#72</a>, <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/pull/73\" rel=\"nofollow\">#73</a>, <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/pull/85\" rel=\"nofollow\">#85</a>, and <a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/pull/86\" rel=\"nofollow\">#86</a>. Thanks to the authors of all the pull requests!</p>\n<h3>Update (July 31, 2019)</h3>\n<p><em>Upgrade the pip package with</em> <code>pip install --upgrade efficientnet-pytorch</code></p>\n<p>The B6 and B7 models are now available. Additionally, <em>all</em> pretrained models have been updated to use AutoAugment preprocessing, which translates to better performance across the board. Usage is the same as before:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b7'</span><span class=\"p\">)</span> \n</pre>\n<h3>Update (June 29, 2019)</h3>\n<p>This update adds easy model exporting (<a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/issues/20\" rel=\"nofollow\">#20</a>) and feature extraction (<a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/issues/38\" rel=\"nofollow\">#38</a>).</p>\n<ul>\n<li><a href=\"#example-export\" rel=\"nofollow\">Example: Export to ONNX</a></li>\n<li><a href=\"#example-feature-extraction\" rel=\"nofollow\">Example: Extract features</a></li>\n<li>Also: fixed a CUDA/CPU bug (<a href=\"https://github.com/lukemelas/EfficientNet-PyTorch/issues/32\" rel=\"nofollow\">#32</a>)</li>\n</ul>\n<p>It is also now incredibly simple to load a pretrained model with a new number of classes for transfer learning:</p>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b1'</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">23</span><span class=\"p\">)</span>\n</pre>\n<h3>Update (June 23, 2019)</h3>\n<p>The B4 and B5 models are now available. Their usage is identical to the other models:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b4'</span><span class=\"p\">)</span> \n</pre>\n<h3>Overview</h3>\n<p>This repository contains an op-for-op PyTorch reimplementation of <a href=\"https://arxiv.org/abs/1905.11946\" rel=\"nofollow\">EfficientNet</a>, along with pre-trained models and examples.</p>\n<p>The goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.</p>\n<p>At the moment, you can easily:</p>\n<ul>\n<li>Load pretrained EfficientNet models</li>\n<li>Use EfficientNet models for classification or feature extraction</li>\n<li>Evaluate EfficientNet models on ImageNet or your own images</li>\n</ul>\n<p><em>Upcoming features</em>: In the next few days, you will be able to:</p>\n<ul>\n<li>Train new models from scratch on ImageNet with a simple command</li>\n<li>Quickly finetune an EfficientNet on your own dataset</li>\n<li>Export EfficientNet models for production</li>\n</ul>\n<h3>Table of contents</h3>\n<ol>\n<li><a href=\"#about-efficientnet\" rel=\"nofollow\">About EfficientNet</a></li>\n<li><a href=\"#about-efficientnet-pytorch\" rel=\"nofollow\">About EfficientNet-PyTorch</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#loading-pretrained-models\" rel=\"nofollow\">Load pretrained models</a></li>\n<li><a href=\"#example-classification\" rel=\"nofollow\">Example: Classify</a></li>\n<li><a href=\"#example-feature-extraction\" rel=\"nofollow\">Example: Extract features</a></li>\n<li><a href=\"#example-export\" rel=\"nofollow\">Example: Export to ONNX</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n</ol>\n<h3>About EfficientNet</h3>\n<p>If you're new to EfficientNets, here is an explanation straight from the official TensorFlow implementation:</p>\n<p>EfficientNets are a family of image classification models, which achieve state-of-the-art accuracy, yet being an order-of-magnitude smaller and faster than previous models. We develop EfficientNets based on AutoML and Compound Scaling. In particular, we first use <a href=\"https://ai.googleblog.com/2018/08/mnasnet-towards-automating-design-of.html\" rel=\"nofollow\">AutoML Mobile framework</a> to develop a mobile-size baseline network, named as EfficientNet-B0; Then, we use the compound scaling method to scale up this baseline to obtain EfficientNet-B1 to B7.</p>\n<table>\n<tr>\n    <td>\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/acfb05f8a49eb76db65cf17ac4455aa800f1ab37/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f7470752f6d61737465722f6d6f64656c732f6f6666696369616c2f656666696369656e746e65742f6733646f632f706172616d732e706e67\" width=\"100%\">\n    </td>\n    <td>\n    <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/02731be4faa16b3d9288be054750067e2621f31a/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f7470752f6d61737465722f6d6f64656c732f6f6666696369616c2f656666696369656e746e65742f6733646f632f666c6f70732e706e67\" width=\"90%\">\n    </td>\n</tr>\n</table>\n<p>EfficientNets achieve state-of-the-art accuracy on ImageNet with an order of magnitude better efficiency:</p>\n<ul>\n<li>\n<p>In high-accuracy regime, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet with 66M parameters and 37B FLOPS, being 8.4x smaller and 6.1x faster on CPU inference than previous best <a href=\"https://arxiv.org/abs/1811.06965\" rel=\"nofollow\">Gpipe</a>.</p>\n</li>\n<li>\n<p>In middle-accuracy regime, our EfficientNet-B1 is 7.6x smaller and 5.7x faster on CPU inference than <a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">ResNet-152</a>, with similar ImageNet accuracy.</p>\n</li>\n<li>\n<p>Compared with the widely used <a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">ResNet-50</a>, our EfficientNet-B4 improves the top-1 accuracy from 76.3% of ResNet-50 to 82.6% (+6.3%), under similar FLOPS constraint.</p>\n</li>\n</ul>\n<h3>About EfficientNet PyTorch</h3>\n<p>EfficientNet PyTorch is a PyTorch re-implementation of EfficientNet. It is consistent with the <a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\" rel=\"nofollow\">original TensorFlow implementation</a>, such that it is easy to load weights from a TensorFlow checkpoint. At the same time, we aim to make our PyTorch implementation as simple, flexible, and extensible as possible.</p>\n<p>If you have any feature requests or questions, feel free to leave them as GitHub issues!</p>\n<h3>Installation</h3>\n<p>Install via pip:</p>\n<pre>pip install efficientnet_pytorch\n</pre>\n<p>Or install from source:</p>\n<pre>git clone https://github.com/lukemelas/EfficientNet-PyTorch\n<span class=\"nb\">cd</span> EfficientNet-Pytorch\npip install -e .\n</pre>\n<h3>Usage</h3>\n<h4>Loading pretrained models</h4>\n<p>Load an EfficientNet:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_name</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b0'</span><span class=\"p\">)</span>\n</pre>\n<p>Load a pretrained EfficientNet:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b0'</span><span class=\"p\">)</span>\n</pre>\n<p>Note that pretrained models have only been released for <code>N=0,1,2,3,4,5</code> at the current time, so <code>.from_pretrained</code> only supports <code>'efficientnet-b{N}'</code> for <code>N=0,1,2,3,4,5</code>.</p>\n<p>Details about the models are below:</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"><em>Name</em></th>\n<th align=\"center\"><em># Params</em></th>\n<th align=\"center\"><em>Top-1 Acc.</em></th>\n<th align=\"center\"><em>Pretrained?</em></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><code>efficientnet-b0</code></td>\n<td align=\"center\">5.3M</td>\n<td align=\"center\">76.3</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b1</code></td>\n<td align=\"center\">7.8M</td>\n<td align=\"center\">78.8</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b2</code></td>\n<td align=\"center\">9.2M</td>\n<td align=\"center\">79.8</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b3</code></td>\n<td align=\"center\">12M</td>\n<td align=\"center\">81.1</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b4</code></td>\n<td align=\"center\">19M</td>\n<td align=\"center\">82.6</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b5</code></td>\n<td align=\"center\">30M</td>\n<td align=\"center\">83.3</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b6</code></td>\n<td align=\"center\">43M</td>\n<td align=\"center\">84.0</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td align=\"center\"><code>efficientnet-b7</code></td>\n<td align=\"center\">66M</td>\n<td align=\"center\">84.4</td>\n<td align=\"center\">\u2713</td>\n</tr></tbody></table>\n<h4>Example: Classification</h4>\n<p>Below is a simple, complete example. It may also be found as a jupyter notebook in <code>examples/simple</code> or as a <a href=\"https://colab.research.google.com/drive/1Jw28xZ1NJq4Cja4jLe6tJ6_F5lCzElb4\" rel=\"nofollow\">Colab Notebook</a>.</p>\n<p>We assume that in your current directory, there is a <code>img.jpg</code> file and a <code>labels_map.txt</code> file (ImageNet class names). These are both included in <code>examples/simple</code>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"kn\">from</span> <span class=\"nn\">PIL</span> <span class=\"kn\">import</span> <span class=\"n\">Image</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision</span> <span class=\"kn\">import</span> <span class=\"n\">transforms</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b0'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Preprocess image</span>\n<span class=\"n\">tfms</span> <span class=\"o\">=</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">([</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Resize</span><span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">),</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">(),</span>\n    <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Normalize</span><span class=\"p\">([</span><span class=\"mf\">0.485</span><span class=\"p\">,</span> <span class=\"mf\">0.456</span><span class=\"p\">,</span> <span class=\"mf\">0.406</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mf\">0.229</span><span class=\"p\">,</span> <span class=\"mf\">0.224</span><span class=\"p\">,</span> <span class=\"mf\">0.225</span><span class=\"p\">]),])</span>\n<span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">tfms</span><span class=\"p\">(</span><span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'img.jpg'</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"c1\"># torch.Size([1, 3, 224, 224])</span>\n\n<span class=\"c1\"># Load ImageNet class names</span>\n<span class=\"n\">labels_map</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'labels_map.txt'</span><span class=\"p\">))</span>\n<span class=\"n\">labels_map</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">labels_map</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">)]</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">)]</span>\n\n<span class=\"c1\"># Classify</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Print predictions</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'-----'</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">idx</span> <span class=\"ow\">in</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">topk</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">indices</span><span class=\"o\">.</span><span class=\"n\">squeeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">():</span>\n    <span class=\"n\">prob</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">idx</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'</span><span class=\"si\">{label:&lt;75}</span><span class=\"s1\"> (</span><span class=\"si\">{p:.2f}</span><span class=\"s1\">%)'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">label</span><span class=\"o\">=</span><span class=\"n\">labels_map</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">],</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">prob</span><span class=\"o\">*</span><span class=\"mi\">100</span><span class=\"p\">))</span>\n</pre>\n<h4>Example: Feature Extraction</h4>\n<p>You can easily extract features with <code>model.extract_features</code>:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b0'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># ... image preprocessing as in the classification example ...</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"c1\"># torch.Size([1, 3, 224, 224])</span>\n\n<span class=\"n\">features</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">extract_features</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span> <span class=\"c1\"># torch.Size([1, 1280, 7, 7])</span>\n</pre>\n<h4>Example: Export to ONNX</h4>\n<p>Exporting to ONNX for deploying to production is now simple:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span> \n<span class=\"kn\">from</span> <span class=\"nn\">efficientnet_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">EfficientNet</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EfficientNet</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'efficientnet-b1'</span><span class=\"p\">)</span>\n<span class=\"n\">dummy_input</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">240</span><span class=\"p\">,</span> <span class=\"mi\">240</span><span class=\"p\">)</span>\n\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">onnx</span><span class=\"o\">.</span><span class=\"n\">export</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">dummy_input</span><span class=\"p\">,</span> <span class=\"s2\">\"test-b1.onnx\"</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p><a href=\"https://colab.research.google.com/drive/1rOAEXeXHaA8uo3aG2YcFDHItlRJMV0VP\" rel=\"nofollow\">Here</a> is a Colab example.</p>\n<h4>ImageNet</h4>\n<p>See <code>examples/imagenet</code> for details about evaluating on ImageNet.</p>\n<h3>Contributing</h3>\n<p>If you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.</p>\n<p>I look forward to seeing what the community does with these models!</p>\n\n          </div>"}, "last_serial": 6726937, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "2c86ab6caf28f44e4aeee1e3119860f5", "sha256": "15639201a27005af84034cf0114095d0be888649ba33b9d42512aaa167e324d9"}, "downloads": -1, "filename": "efficientnet_pytorch-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2c86ab6caf28f44e4aeee1e3119860f5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 14045, "upload_time": "2019-06-01T11:23:10", "upload_time_iso_8601": "2019-06-01T11:23:10.371767Z", "url": "https://files.pythonhosted.org/packages/06/ff/881afd965c46b11fc6f3c8316de9e08d37fc3b71056dbab861b76faee6ca/efficientnet_pytorch-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "34949aa0f1aa0fae7debc33648bfb1c9", "sha256": "efdb9ea0d524d5718e6641defcc416f4c789f19ca88c432e03f2ce9caa637be3"}, "downloads": -1, "filename": "efficientnet_pytorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "34949aa0f1aa0fae7debc33648bfb1c9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 12695, "upload_time": "2019-06-01T11:23:12", "upload_time_iso_8601": "2019-06-01T11:23:12.631092Z", "url": "https://files.pythonhosted.org/packages/e0/16/8802c6015a9bd40f3172473e958f5fafba3b8ffcbffbdd9c1fa9600d7887/efficientnet_pytorch-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "77a2a2cb5b64c64143409030768b1041", "sha256": "64f518cd8f21be6e9124b41660291d545c00531d0de5599f601d4a76502b96d7"}, "downloads": -1, "filename": "efficientnet_pytorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "77a2a2cb5b64c64143409030768b1041", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 11190, "upload_time": "2019-06-18T23:29:36", "upload_time_iso_8601": "2019-06-18T23:29:36.332527Z", "url": "https://files.pythonhosted.org/packages/72/a3/68e95f068658fd26ef2757980e7a177faf7678d1fd8d7f7306a75250145c/efficientnet_pytorch-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "d635f4e1ff3536adcbcb7a5da53d65c8", "sha256": "88e33cc90e45eb332f63013c295836d96edc39dd208cdb42b7002f40f8193e8e"}, "downloads": -1, "filename": "efficientnet_pytorch-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d635f4e1ff3536adcbcb7a5da53d65c8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 15181, "upload_time": "2019-06-29T23:52:38", "upload_time_iso_8601": "2019-06-29T23:52:38.215027Z", "url": "https://files.pythonhosted.org/packages/c9/e9/81aa23322344835403b8852e7c24938edf7945da729b653d4cfa779e7571/efficientnet_pytorch-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a092de34ffe67426622a8c24e92d2c50", "sha256": "bca16bc6fbb40b8afccb5801e78e01c022619dd29cde6ad2df0b66eb06034b4f"}, "downloads": -1, "filename": "efficientnet_pytorch-0.3.0.tar.gz", "has_sig": false, "md5_digest": "a092de34ffe67426622a8c24e92d2c50", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 14488, "upload_time": "2019-06-29T23:52:43", "upload_time_iso_8601": "2019-06-29T23:52:43.814701Z", "url": "https://files.pythonhosted.org/packages/cd/af/d17f7852a1fc69d347108200b1f24dd0b2dea55e50577dfb039dad626437/efficientnet_pytorch-0.3.0.tar.gz", "yanked": false}], "0.3.0.dev1": [{"comment_text": "", "digests": {"md5": "5c322755b93718394a12acd9b4dee0cd", "sha256": "4eb323a30f7d79d0cce7851536019263c8db8d9af5971e2d4d5a323c267303f5"}, "downloads": -1, "filename": "efficientnet_pytorch-0.3.0.dev1-py3-none-any.whl", "has_sig": false, "md5_digest": "5c322755b93718394a12acd9b4dee0cd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 15201, "upload_time": "2019-06-29T23:52:40", "upload_time_iso_8601": "2019-06-29T23:52:40.487899Z", "url": "https://files.pythonhosted.org/packages/a0/69/d42e3e2a9b3f2d818a98111f62fd8f1a712047b72ebbec1579b0b1aa0e5a/efficientnet_pytorch-0.3.0.dev1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "261d38ff86041764b9bd2cc0ac219b03", "sha256": "e7071b24877d06cf5a3135df9da00589d84b0f9326f9589917b0c37cc00c409d"}, "downloads": -1, "filename": "efficientnet_pytorch-0.3.0.dev1.tar.gz", "has_sig": false, "md5_digest": "261d38ff86041764b9bd2cc0ac219b03", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 14465, "upload_time": "2019-06-29T23:52:42", "upload_time_iso_8601": "2019-06-29T23:52:42.057298Z", "url": "https://files.pythonhosted.org/packages/5a/8d/a56f997b68ceb308c03d08f42a72c3f43cc28872154f184a428dac96f3bd/efficientnet_pytorch-0.3.0.dev1.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "6b0aa738d60e963a63784a702a90d1e1", "sha256": "60be7f742f3804a607db066cbbfb77ecc6ee0c28b2d0415e17a8b543db92257e"}, "downloads": -1, "filename": "efficientnet_pytorch-0.4.0.tar.gz", "has_sig": false, "md5_digest": "6b0aa738d60e963a63784a702a90d1e1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 11621, "upload_time": "2019-08-01T00:42:36", "upload_time_iso_8601": "2019-08-01T00:42:36.338961Z", "url": "https://files.pythonhosted.org/packages/12/f8/35453605c6c471fc406a137a894fb381b05ae9f174b2ca4956592512374e/efficientnet_pytorch-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "d8cde00be2dd7200bf661bea6385a58f", "sha256": "dd50d4f245cb911cfb6c26029ea7a213a1083623c8962aeb3ae61c1e497e4493"}, "downloads": -1, "filename": "efficientnet_pytorch-0.5.0.tar.gz", "has_sig": false, "md5_digest": "d8cde00be2dd7200bf661bea6385a58f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 11920, "upload_time": "2019-10-13T00:46:21", "upload_time_iso_8601": "2019-10-13T00:46:21.598779Z", "url": "https://files.pythonhosted.org/packages/96/81/01b9652ea7bcf8a46324bdf509423015a5e9fcbd88c83e9b5e10651e3a75/efficientnet_pytorch-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "97326150663bc3200a91dd8383f8254f", "sha256": "8c1d954c4b15a6574d81147215920db9b192f03e0e0360e2c0606ce3c219bb77"}, "downloads": -1, "filename": "efficientnet_pytorch-0.5.1.tar.gz", "has_sig": false, "md5_digest": "97326150663bc3200a91dd8383f8254f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 12292, "upload_time": "2019-10-15T04:41:05", "upload_time_iso_8601": "2019-10-15T04:41:05.496959Z", "url": "https://files.pythonhosted.org/packages/82/18/1c4d61eea11b78235ce270a528e099b19af2f1026aadf45e9c645cd75e2f/efficientnet_pytorch-0.5.1.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "0abed1a04d5ce71258d4585771e14e7c", "sha256": "092e9abd77734cd15e819291d466d2b4e75c3ddb807a39731066e71432c6b9a5"}, "downloads": -1, "filename": "efficientnet_pytorch-0.6.0.tar.gz", "has_sig": false, "md5_digest": "0abed1a04d5ce71258d4585771e14e7c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 16898, "upload_time": "2020-01-24T05:11:24", "upload_time_iso_8601": "2020-01-24T05:11:24.624025Z", "url": "https://files.pythonhosted.org/packages/fc/73/a1531f5a139b62fe9c0b28f9b493a78b915f09fcef81cb4c543a48abd684/efficientnet_pytorch-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "d593b3536b21c283ee7d5019e03d2a2d", "sha256": "10f400ab560599fd4ed8967a58b2774d326142d554e2e5dd1be591b38a708a63"}, "downloads": -1, "filename": "efficientnet_pytorch-0.6.1.tar.gz", "has_sig": false, "md5_digest": "d593b3536b21c283ee7d5019e03d2a2d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 16886, "upload_time": "2020-01-24T18:51:22", "upload_time_iso_8601": "2020-01-24T18:51:22.536625Z", "url": "https://files.pythonhosted.org/packages/e5/b7/c7cc9d8a95b7cfe4392c28fd5ff1854061aa75e81acf8d7539adb7612f20/efficientnet_pytorch-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "3d86f6b2f87f14f9ab4d853252c8619f", "sha256": "21d5d91a0931f19994644a6ffe05ac6c448544b26898fa4dce1054a0c89e7692"}, "downloads": -1, "filename": "efficientnet_pytorch-0.6.2.tar.gz", "has_sig": false, "md5_digest": "3d86f6b2f87f14f9ab4d853252c8619f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 16877, "upload_time": "2020-03-01T03:19:40", "upload_time_iso_8601": "2020-03-01T03:19:40.975275Z", "url": "https://files.pythonhosted.org/packages/e8/6e/e2bc5eeb162569b90e527e303d8fe0c2db2aab0a84fd4b5f87028fc11917/efficientnet_pytorch-0.6.2.tar.gz", "yanked": false}], "0.6.3": [{"comment_text": "", "digests": {"md5": "fe21a8085d1e1cc1375d2445552d8275", "sha256": "6667459336893e9bf6367de3788ba449fed97f65da3b6782bf2204b6273a319f"}, "downloads": -1, "filename": "efficientnet_pytorch-0.6.3.tar.gz", "has_sig": false, "md5_digest": "fe21a8085d1e1cc1375d2445552d8275", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 16855, "upload_time": "2020-03-01T03:32:59", "upload_time_iso_8601": "2020-03-01T03:32:59.283136Z", "url": "https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fe21a8085d1e1cc1375d2445552d8275", "sha256": "6667459336893e9bf6367de3788ba449fed97f65da3b6782bf2204b6273a319f"}, "downloads": -1, "filename": "efficientnet_pytorch-0.6.3.tar.gz", "has_sig": false, "md5_digest": "fe21a8085d1e1cc1375d2445552d8275", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 16855, "upload_time": "2020-03-01T03:32:59", "upload_time_iso_8601": "2020-03-01T03:32:59.283136Z", "url": "https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:21 2020"}