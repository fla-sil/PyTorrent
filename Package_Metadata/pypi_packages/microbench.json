{"info": {"author": "Alex Lubbock", "author_email": "code@alexlubbock.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python"], "description": "# Microbench\n\nMicrobench is a small Python package for benchmarking Python functions, and \noptionally capturing extra runtime/environment information. It is most useful in\nclustered/distributed environments, where the same function runs under different\nenvironments, and is designed to be extensible with new\nfunctionality. In addition to benchmarking, this can help reproducibility by\ne.g. logging the versions of key Python packages, or even all packages loaded\ninto the global environment.\n\n## Requirements\n\nMicrobench by default has no dependencies outside of the Python standard\nlibrary, although [pandas](https://pandas.pydata.org/) is recommended to\nexamine results. However, some mixins (extensions) have specific requirements:\n\n* The [line_profiler](https://github.com/rkern/line_profiler)\n  package needs to be installed for line-by-line code benchmarking.\n* `MBInstalledPackages` requires `setuptools`, which is not a part of the\n  standard library, but is usually available. \n* The CPU cores and total RAM extensions require\n  [psutil](https://pypi.org/project/psutil/).\n* The NVIDIA GPU plugin requires the\n  [nvidia-smi](https://developer.nvidia.com/nvidia-system-management-interface)\n  utility, which usually ships with the NVIDIA graphics card drivers. It needs\n  to be on your `PATH`.\n\n## Installation\n\nTo install using `pip`:\n\n```\npip install microbench\n```\n\n## Usage\n\nMicrobench is designed for benchmarking Python functions. These examples will\nassume you have already defined a Python function `myfunction` that you wish to\nbenchmark:\n\n```python\ndef myfunction(arg1, arg2, ...):\n    ...\n```\n\n### Minimal example\n\nFirst, create a benchmark suite, which specifies the configuration and\ninformation to capture.\n\nHere's a minimal, complete example:\n\n```python\nfrom microbench import MicroBench\n    \nbasic_bench = MicroBench()\n```\n\nTo attach the benchmark to your function, simply use `basic_bench` as a\ndecorator, like this:\n\n```python\n@basic_bench\ndef myfunction(arg1, arg2, ...):\n    ...\n```\n\nThat's it! Benchmark information will be appended to the file specified in\n`outfile`. This example captures the fields `start_time`, `finish_time` and\n`function_name`. See the **Examine results** section for further information.\n\n### Extended examples\n\nHere's a more complete example using mixins (the `MB` prefixed class \nnames) to extend functionality. Note that keyword arguments can be supplied\nto the constructor (in this case `some_info=123`) to specify additional\ninformation to capture. This example also specifies the `outfile` option,\nwhich writes conda\n\n```python\nfrom microbench import *\nimport numpy, pandas\n\nclass MyBench(MicroBench, MBFunctionCall, MBPythonVersion, MBHostInfo):\n    outfile = '/home/user/my-benchmarks'\n    capture_versions = (numpy, pandas)  # Or use MBGlobalPackages/MBInstalledPackages\n    env_vars = ('SLURM_ARRAY_TASK_ID', )\n    \nbenchmark = MyBench(some_info=123)\n```\n\nThe `env_vars` option from the example above specifies a list of environment\nvariables to capture as `env_<variable name>`. In this example,\nthe [slurm](https://slurm.schedmd.com) array task ID will be stored as\n`env_SLURM_ARRAY_TASK_ID`. Where the environment variable is not set, the\nvalue will be `null`.\n\nTo capture package versions, you can either specify them individually (as above), or you can capture the versions of\nevery package in the global environment. In the following example, we would capture the versions of `microbench`,\n`numpy`, and `pandas` automatically.\n\n```python\nfrom microbench import *\nimport numpy, pandas\n\nclass Bench2(MicroBench, MBGlobalPackages):\n    outfile = '/home/user/bench2'\n\nbench2 = Bench2()\n```\n\nIf you want to go even further, and capture the version of every package available for import, there's a\nmixin for that:\n\n```python\nfrom microbench import *\n\nclass Bench3(MicroBench, MBInstalledPackages):\n    pass\n    \nbench3 = Bench3()\n``` \n\n Mixin                 | Fields captured\n-----------------------|----------------\n*(default)*            | `start_time`<br>`finish_time`<br>`function_name`\nMBGlobalPackages       | `package_versions`, with entry for every package in the global environment\nMBInstalledPackages    | `package_versions`, with entry for every package available for import\nMBFunctionCall         | `args` (positional arguments)<br>`kwargs` (keyword arguments)\nMBPythonVersion        | `python_version` (e.g. 3.6.0) and `python_executable` (e.g. `/usr/bin/python`, which should indicate any active virtual environment)\nMBHostInfo             | `hostname`<br>`operating_system`\nMBHostCpuCores         | `cpu_cores_logical` (number of cores, requires `psutil`)\nMBHostRamTotal         | `ram_total` (total RAM in bytes, requires `psutil`)\nMBNvidiaSmi            | Various NVIDIA GPU fields, detailed in a later section\nMBLineProfiler         | `line_profiler` containing line-by-line profile (see section below)\n\n## Examine results\n\nEach result is a [JSON](https://en.wikipedia.org/wiki/JSON) object. When using\nthe `outfile` option, a JSON object for each `@benchmark` call is stored on a\nseparate line in the file. The output from the minimal example above for a\nsingle run will look similar to the following:\n\n```json\n{\"start_time\": \"2018-08-06T10:28:24.806493\", \"finish_time\": \"2018-08-06T10:28:24.867456\", \"function_name\": \"my_function\"}\n```\n\nThe simplest way to examine results in detail is to load them into a\n[pandas](https://pandas.pydata.org/) dataframe:\n\n```python\nimport pandas\nresults = pandas.read_json('/home/user/my-benchmarks', lines=True)\n```\n\nPandas has powerful data manipulation capabilities. For example, to calculate\nthe average runtime by Python version:\n\n```python\n# Calculate runtime for each run\nresults['runtime'] = results['finish_time'] - results['start_time']\n\n# Average runtime by Python version\nresults.groupby('python_version')['runtime'].mean()\n```\n\nMany more advanced operations are available. The\n[pandas tutorial](https://pandas.pydata.org/pandas-docs/stable/tutorials.html)\nis recommended.\n\n## Line profiler support\n\nMicrobench also has support for [line_profiler](https://github.com/rkern/line_profiler), which shows the execution time\nof each line of Python code. Note that this will slow down your code, so only use it if needed, but it's useful for\ndiscovering bottlenecks within a function. Requires the `line_profiler` package to be installed\n(e.g. `pip install line_profiler`).\n\n```python\nfrom microbench import MicroBench, MBLineProfiler\nimport pandas\n\n# Create our benchmark suite using the MBLineProfiler mixin\nclass LineProfilerBench(MicroBench, MBLineProfiler):\n    pass\n\nlpbench = LineProfilerBench()\n\n# Decorate our function with the benchmark suite\n@lpbench\ndef my_function():\n    \"\"\" Inefficient function for line profiler \"\"\"\n    acc = 0\n    for i in range(1000000):\n        acc += i\n\n    return acc\n\n# Call the function as normal\nmy_function()\n\n# Read the results into a Pandas DataFrame\nresults = pandas.read_json(lpbench.outfile.getvalue(), lines=True)\n\n# Get the line profiler report as an object\nlp = MBLineProfiler.decode_line_profile(results['line_profiler'][0])\n\n# Print the line profiler report\nMBLineProfiler.print_line_profile(results['line_profiler'][0])\n```\n\nThe last line of the previous example will print the line profiler report, showing the execution time of each line of\ncode. Example:\n\n```\nTimer unit: 1e-06 s\n\nTotal time: 0.476723 s\nFile: /home/user/my_test.py\nFunction: my_function at line 12\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    12                                               @lpbench\n    13                                               def my_function():\n    14                                                   \"\"\" Inefficient function for line profiler \"\"\"\n    15         1          2.0      2.0      0.0          acc = 0\n    16   1000001     217874.0      0.2     45.7          for i in range(1000000):\n    17   1000000     258846.0      0.3     54.3              acc += i\n    18\n    19         1          1.0      1.0      0.0          return acc\n```\n\n## NVIDIA GPU support\n\nAttributes about NVIDIA GPUs can be captured using the `MBNvidiaSmi` plugin.\nThis requires the `nvidia-smi` utility to be available in the current `PATH`.\n\nBy default, the `gpu_name` (model number) and `memory.total` attributes are\ncaptured. Extra attributes can be specified using the class or object-level\nvariable `nvidia_attributes`. To see which attributes are available, run\n`nvidia-smi --help-query-gpu`.\n\nBy default, all installed GPUs will be polled. To limit to a specific GPU,\nspecify the `nvidia_gpus` attribute as a tuple of GPU IDs, which can be\nzero-based GPU indexes (can change between reboots, not recommended),\nGPU UUIDs, or PCI bus IDs. You can find out GPU UUIDs by running\n`nvidia-smi -L`.\n\nHere's an example specifying the optional `nvidia_attributes` and\n`nvidia_gpus` fields:\n\n```python\nfrom microbench import MicroBench, MBNvidiaSmi\n\nclass GpuBench(MicroBench, MBNvidiaSmi):\n    outfile = '/home/user/gpu-benchmarks'\n    nvidia_attributes = ('gpu_name', 'memory.total', 'pcie.link.width.max')\n    nvidia_gpus = (0, )  # Usually better to specify GPU UUIDs here instead\n\ngpu_bench = GpuBench()\n```\n\n## Extending microbench\n\nMicrobench includes a few mixins for basic functionality as described in the\nextended example, above.\n\nYou can also add functions to your benchmark suite to capture\nextra information at runtime. These functions must be prefixed with `capture_`\nfor them to run automatically before the function starts. They take\na single argument, `bm_data`, a dictionary to be extended with extra data.\nCare should be taken to avoid overwriting existing key names.\n\nHere's an example to capture the machine type (`i386`, `x86_64` etc.):\n\n```python\nfrom microbench import MicroBench\nimport platform\n\nclass Bench(MicroBench):\n    outfile = '/home/user/my-benchmarks'\n\n    def capture_machine_platform(self, bm_data):\n        bm_data['platform'] = platform.machine()\n        \nbenchmark = Bench()\n```\n\n## Redis support\n\nBy default, microbench appends output to a file, but output can be directed\nelsewhere, e.g. [redis](https://redis.io) - an in-memory, networked data source.\nThis option is useful when a shared filesystem is not available.\n\nRedis support requires [redis-py](https://github.com/andymccurdy/redis-py).\n\nTo use this feature, inherit from `MicroBenchRedis` instead of `MicroBench`,\nand specify the redis connection and key name as in the following example:\n\n```python\nfrom microbench import MicroBenchRedis\n\nclass RedisBench(MicroBenchRedis):\n    # redis_connection contains arguments for redis.StrictClient()\n    redis_connection = {'host': 'localhost', 'port': 6379}\n    redis_key = 'microbench:mykey'\n\nbenchmark = RedisBench()\n```\n\nTo retrieve results, the `redis` package can be used directly:\n\n```python\nimport redis\nimport pandas\n\n# Establish the connection to redis\nrconn = redis.StrictRedis(host=..., port=...)\n\n# Read the redis data from 'myrediskey' into a list of byte arrays\nredis_data = redis.lrange('myrediskey', 0, -1)\n\n# Convert the list into a single string\njson_data = '\\n'.join(r.decode('utf8') for r in redis_data)\n\n# Read the string into a pandas dataframe\nresults = pandas.read_json(json_data, lines=True)\n```\n\n## Feedback\n\nPlease note this is a recently created, experimental package. Please let me know\nyour feedback or feature requests in Github issues.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/alubbock/microbench", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "microbench", "package_url": "https://pypi.org/project/microbench/", "platform": "", "project_url": "https://pypi.org/project/microbench/", "project_urls": {"Homepage": "https://github.com/alubbock/microbench"}, "release_url": "https://pypi.org/project/microbench/0.5/", "requires_dist": null, "requires_python": "", "summary": "Micro-benchmarking framework. Extensible, with distributed/cluster support.", "version": "0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Microbench</h1>\n<p>Microbench is a small Python package for benchmarking Python functions, and\noptionally capturing extra runtime/environment information. It is most useful in\nclustered/distributed environments, where the same function runs under different\nenvironments, and is designed to be extensible with new\nfunctionality. In addition to benchmarking, this can help reproducibility by\ne.g. logging the versions of key Python packages, or even all packages loaded\ninto the global environment.</p>\n<h2>Requirements</h2>\n<p>Microbench by default has no dependencies outside of the Python standard\nlibrary, although <a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">pandas</a> is recommended to\nexamine results. However, some mixins (extensions) have specific requirements:</p>\n<ul>\n<li>The <a href=\"https://github.com/rkern/line_profiler\" rel=\"nofollow\">line_profiler</a>\npackage needs to be installed for line-by-line code benchmarking.</li>\n<li><code>MBInstalledPackages</code> requires <code>setuptools</code>, which is not a part of the\nstandard library, but is usually available.</li>\n<li>The CPU cores and total RAM extensions require\n<a href=\"https://pypi.org/project/psutil/\" rel=\"nofollow\">psutil</a>.</li>\n<li>The NVIDIA GPU plugin requires the\n<a href=\"https://developer.nvidia.com/nvidia-system-management-interface\" rel=\"nofollow\">nvidia-smi</a>\nutility, which usually ships with the NVIDIA graphics card drivers. It needs\nto be on your <code>PATH</code>.</li>\n</ul>\n<h2>Installation</h2>\n<p>To install using <code>pip</code>:</p>\n<pre><code>pip install microbench\n</code></pre>\n<h2>Usage</h2>\n<p>Microbench is designed for benchmarking Python functions. These examples will\nassume you have already defined a Python function <code>myfunction</code> that you wish to\nbenchmark:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">myfunction</span><span class=\"p\">(</span><span class=\"n\">arg1</span><span class=\"p\">,</span> <span class=\"n\">arg2</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n</pre>\n<h3>Minimal example</h3>\n<p>First, create a benchmark suite, which specifies the configuration and\ninformation to capture.</p>\n<p>Here's a minimal, complete example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"n\">MicroBench</span>\n    \n<span class=\"n\">basic_bench</span> <span class=\"o\">=</span> <span class=\"n\">MicroBench</span><span class=\"p\">()</span>\n</pre>\n<p>To attach the benchmark to your function, simply use <code>basic_bench</code> as a\ndecorator, like this:</p>\n<pre><span class=\"nd\">@basic_bench</span>\n<span class=\"k\">def</span> <span class=\"nf\">myfunction</span><span class=\"p\">(</span><span class=\"n\">arg1</span><span class=\"p\">,</span> <span class=\"n\">arg2</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n</pre>\n<p>That's it! Benchmark information will be appended to the file specified in\n<code>outfile</code>. This example captures the fields <code>start_time</code>, <code>finish_time</code> and\n<code>function_name</code>. See the <strong>Examine results</strong> section for further information.</p>\n<h3>Extended examples</h3>\n<p>Here's a more complete example using mixins (the <code>MB</code> prefixed class\nnames) to extend functionality. Note that keyword arguments can be supplied\nto the constructor (in this case <code>some_info=123</code>) to specify additional\ninformation to capture. This example also specifies the <code>outfile</code> option,\nwhich writes conda</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span><span class=\"o\">,</span> <span class=\"nn\">pandas</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">MyBench</span><span class=\"p\">(</span><span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBFunctionCall</span><span class=\"p\">,</span> <span class=\"n\">MBPythonVersion</span><span class=\"p\">,</span> <span class=\"n\">MBHostInfo</span><span class=\"p\">):</span>\n    <span class=\"n\">outfile</span> <span class=\"o\">=</span> <span class=\"s1\">'/home/user/my-benchmarks'</span>\n    <span class=\"n\">capture_versions</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">numpy</span><span class=\"p\">,</span> <span class=\"n\">pandas</span><span class=\"p\">)</span>  <span class=\"c1\"># Or use MBGlobalPackages/MBInstalledPackages</span>\n    <span class=\"n\">env_vars</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'SLURM_ARRAY_TASK_ID'</span><span class=\"p\">,</span> <span class=\"p\">)</span>\n    \n<span class=\"n\">benchmark</span> <span class=\"o\">=</span> <span class=\"n\">MyBench</span><span class=\"p\">(</span><span class=\"n\">some_info</span><span class=\"o\">=</span><span class=\"mi\">123</span><span class=\"p\">)</span>\n</pre>\n<p>The <code>env_vars</code> option from the example above specifies a list of environment\nvariables to capture as <code>env_&lt;variable name&gt;</code>. In this example,\nthe <a href=\"https://slurm.schedmd.com\" rel=\"nofollow\">slurm</a> array task ID will be stored as\n<code>env_SLURM_ARRAY_TASK_ID</code>. Where the environment variable is not set, the\nvalue will be <code>null</code>.</p>\n<p>To capture package versions, you can either specify them individually (as above), or you can capture the versions of\nevery package in the global environment. In the following example, we would capture the versions of <code>microbench</code>,\n<code>numpy</code>, and <code>pandas</code> automatically.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span><span class=\"o\">,</span> <span class=\"nn\">pandas</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Bench2</span><span class=\"p\">(</span><span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBGlobalPackages</span><span class=\"p\">):</span>\n    <span class=\"n\">outfile</span> <span class=\"o\">=</span> <span class=\"s1\">'/home/user/bench2'</span>\n\n<span class=\"n\">bench2</span> <span class=\"o\">=</span> <span class=\"n\">Bench2</span><span class=\"p\">()</span>\n</pre>\n<p>If you want to go even further, and capture the version of every package available for import, there's a\nmixin for that:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Bench3</span><span class=\"p\">(</span><span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBInstalledPackages</span><span class=\"p\">):</span>\n    <span class=\"k\">pass</span>\n    \n<span class=\"n\">bench3</span> <span class=\"o\">=</span> <span class=\"n\">Bench3</span><span class=\"p\">()</span>\n</pre>\n<table>\n<thead>\n<tr>\n<th>Mixin</th>\n<th>Fields captured</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><em>(default)</em></td>\n<td><code>start_time</code><br><code>finish_time</code><br><code>function_name</code></td>\n</tr>\n<tr>\n<td>MBGlobalPackages</td>\n<td><code>package_versions</code>, with entry for every package in the global environment</td>\n</tr>\n<tr>\n<td>MBInstalledPackages</td>\n<td><code>package_versions</code>, with entry for every package available for import</td>\n</tr>\n<tr>\n<td>MBFunctionCall</td>\n<td><code>args</code> (positional arguments)<br><code>kwargs</code> (keyword arguments)</td>\n</tr>\n<tr>\n<td>MBPythonVersion</td>\n<td><code>python_version</code> (e.g. 3.6.0) and <code>python_executable</code> (e.g. <code>/usr/bin/python</code>, which should indicate any active virtual environment)</td>\n</tr>\n<tr>\n<td>MBHostInfo</td>\n<td><code>hostname</code><br><code>operating_system</code></td>\n</tr>\n<tr>\n<td>MBHostCpuCores</td>\n<td><code>cpu_cores_logical</code> (number of cores, requires <code>psutil</code>)</td>\n</tr>\n<tr>\n<td>MBHostRamTotal</td>\n<td><code>ram_total</code> (total RAM in bytes, requires <code>psutil</code>)</td>\n</tr>\n<tr>\n<td>MBNvidiaSmi</td>\n<td>Various NVIDIA GPU fields, detailed in a later section</td>\n</tr>\n<tr>\n<td>MBLineProfiler</td>\n<td><code>line_profiler</code> containing line-by-line profile (see section below)</td>\n</tr></tbody></table>\n<h2>Examine results</h2>\n<p>Each result is a <a href=\"https://en.wikipedia.org/wiki/JSON\" rel=\"nofollow\">JSON</a> object. When using\nthe <code>outfile</code> option, a JSON object for each <code>@benchmark</code> call is stored on a\nseparate line in the file. The output from the minimal example above for a\nsingle run will look similar to the following:</p>\n<pre><span class=\"p\">{</span><span class=\"nt\">\"start_time\"</span><span class=\"p\">:</span> <span class=\"s2\">\"2018-08-06T10:28:24.806493\"</span><span class=\"p\">,</span> <span class=\"nt\">\"finish_time\"</span><span class=\"p\">:</span> <span class=\"s2\">\"2018-08-06T10:28:24.867456\"</span><span class=\"p\">,</span> <span class=\"nt\">\"function_name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"my_function\"</span><span class=\"p\">}</span>\n</pre>\n<p>The simplest way to examine results in detail is to load them into a\n<a href=\"https://pandas.pydata.org/\" rel=\"nofollow\">pandas</a> dataframe:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">read_json</span><span class=\"p\">(</span><span class=\"s1\">'/home/user/my-benchmarks'</span><span class=\"p\">,</span> <span class=\"n\">lines</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>Pandas has powerful data manipulation capabilities. For example, to calculate\nthe average runtime by Python version:</p>\n<pre><span class=\"c1\"># Calculate runtime for each run</span>\n<span class=\"n\">results</span><span class=\"p\">[</span><span class=\"s1\">'runtime'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">results</span><span class=\"p\">[</span><span class=\"s1\">'finish_time'</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">results</span><span class=\"p\">[</span><span class=\"s1\">'start_time'</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># Average runtime by Python version</span>\n<span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s1\">'python_version'</span><span class=\"p\">)[</span><span class=\"s1\">'runtime'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</pre>\n<p>Many more advanced operations are available. The\n<a href=\"https://pandas.pydata.org/pandas-docs/stable/tutorials.html\" rel=\"nofollow\">pandas tutorial</a>\nis recommended.</p>\n<h2>Line profiler support</h2>\n<p>Microbench also has support for <a href=\"https://github.com/rkern/line_profiler\" rel=\"nofollow\">line_profiler</a>, which shows the execution time\nof each line of Python code. Note that this will slow down your code, so only use it if needed, but it's useful for\ndiscovering bottlenecks within a function. Requires the <code>line_profiler</code> package to be installed\n(e.g. <code>pip install line_profiler</code>).</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBLineProfiler</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span>\n\n<span class=\"c1\"># Create our benchmark suite using the MBLineProfiler mixin</span>\n<span class=\"k\">class</span> <span class=\"nc\">LineProfilerBench</span><span class=\"p\">(</span><span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBLineProfiler</span><span class=\"p\">):</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"n\">lpbench</span> <span class=\"o\">=</span> <span class=\"n\">LineProfilerBench</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Decorate our function with the benchmark suite</span>\n<span class=\"nd\">@lpbench</span>\n<span class=\"k\">def</span> <span class=\"nf\">my_function</span><span class=\"p\">():</span>\n    <span class=\"sd\">\"\"\" Inefficient function for line profiler \"\"\"</span>\n    <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000000</span><span class=\"p\">):</span>\n        <span class=\"n\">acc</span> <span class=\"o\">+=</span> <span class=\"n\">i</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">acc</span>\n\n<span class=\"c1\"># Call the function as normal</span>\n<span class=\"n\">my_function</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Read the results into a Pandas DataFrame</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">read_json</span><span class=\"p\">(</span><span class=\"n\">lpbench</span><span class=\"o\">.</span><span class=\"n\">outfile</span><span class=\"o\">.</span><span class=\"n\">getvalue</span><span class=\"p\">(),</span> <span class=\"n\">lines</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Get the line profiler report as an object</span>\n<span class=\"n\">lp</span> <span class=\"o\">=</span> <span class=\"n\">MBLineProfiler</span><span class=\"o\">.</span><span class=\"n\">decode_line_profile</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">[</span><span class=\"s1\">'line_profiler'</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Print the line profiler report</span>\n<span class=\"n\">MBLineProfiler</span><span class=\"o\">.</span><span class=\"n\">print_line_profile</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">[</span><span class=\"s1\">'line_profiler'</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n<p>The last line of the previous example will print the line profiler report, showing the execution time of each line of\ncode. Example:</p>\n<pre><code>Timer unit: 1e-06 s\n\nTotal time: 0.476723 s\nFile: /home/user/my_test.py\nFunction: my_function at line 12\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    12                                               @lpbench\n    13                                               def my_function():\n    14                                                   \"\"\" Inefficient function for line profiler \"\"\"\n    15         1          2.0      2.0      0.0          acc = 0\n    16   1000001     217874.0      0.2     45.7          for i in range(1000000):\n    17   1000000     258846.0      0.3     54.3              acc += i\n    18\n    19         1          1.0      1.0      0.0          return acc\n</code></pre>\n<h2>NVIDIA GPU support</h2>\n<p>Attributes about NVIDIA GPUs can be captured using the <code>MBNvidiaSmi</code> plugin.\nThis requires the <code>nvidia-smi</code> utility to be available in the current <code>PATH</code>.</p>\n<p>By default, the <code>gpu_name</code> (model number) and <code>memory.total</code> attributes are\ncaptured. Extra attributes can be specified using the class or object-level\nvariable <code>nvidia_attributes</code>. To see which attributes are available, run\n<code>nvidia-smi --help-query-gpu</code>.</p>\n<p>By default, all installed GPUs will be polled. To limit to a specific GPU,\nspecify the <code>nvidia_gpus</code> attribute as a tuple of GPU IDs, which can be\nzero-based GPU indexes (can change between reboots, not recommended),\nGPU UUIDs, or PCI bus IDs. You can find out GPU UUIDs by running\n<code>nvidia-smi -L</code>.</p>\n<p>Here's an example specifying the optional <code>nvidia_attributes</code> and\n<code>nvidia_gpus</code> fields:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBNvidiaSmi</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">GpuBench</span><span class=\"p\">(</span><span class=\"n\">MicroBench</span><span class=\"p\">,</span> <span class=\"n\">MBNvidiaSmi</span><span class=\"p\">):</span>\n    <span class=\"n\">outfile</span> <span class=\"o\">=</span> <span class=\"s1\">'/home/user/gpu-benchmarks'</span>\n    <span class=\"n\">nvidia_attributes</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'gpu_name'</span><span class=\"p\">,</span> <span class=\"s1\">'memory.total'</span><span class=\"p\">,</span> <span class=\"s1\">'pcie.link.width.max'</span><span class=\"p\">)</span>\n    <span class=\"n\">nvidia_gpus</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"p\">)</span>  <span class=\"c1\"># Usually better to specify GPU UUIDs here instead</span>\n\n<span class=\"n\">gpu_bench</span> <span class=\"o\">=</span> <span class=\"n\">GpuBench</span><span class=\"p\">()</span>\n</pre>\n<h2>Extending microbench</h2>\n<p>Microbench includes a few mixins for basic functionality as described in the\nextended example, above.</p>\n<p>You can also add functions to your benchmark suite to capture\nextra information at runtime. These functions must be prefixed with <code>capture_</code>\nfor them to run automatically before the function starts. They take\na single argument, <code>bm_data</code>, a dictionary to be extended with extra data.\nCare should be taken to avoid overwriting existing key names.</p>\n<p>Here's an example to capture the machine type (<code>i386</code>, <code>x86_64</code> etc.):</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"n\">MicroBench</span>\n<span class=\"kn\">import</span> <span class=\"nn\">platform</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Bench</span><span class=\"p\">(</span><span class=\"n\">MicroBench</span><span class=\"p\">):</span>\n    <span class=\"n\">outfile</span> <span class=\"o\">=</span> <span class=\"s1\">'/home/user/my-benchmarks'</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">capture_machine_platform</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">bm_data</span><span class=\"p\">):</span>\n        <span class=\"n\">bm_data</span><span class=\"p\">[</span><span class=\"s1\">'platform'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">platform</span><span class=\"o\">.</span><span class=\"n\">machine</span><span class=\"p\">()</span>\n        \n<span class=\"n\">benchmark</span> <span class=\"o\">=</span> <span class=\"n\">Bench</span><span class=\"p\">()</span>\n</pre>\n<h2>Redis support</h2>\n<p>By default, microbench appends output to a file, but output can be directed\nelsewhere, e.g. <a href=\"https://redis.io\" rel=\"nofollow\">redis</a> - an in-memory, networked data source.\nThis option is useful when a shared filesystem is not available.</p>\n<p>Redis support requires <a href=\"https://github.com/andymccurdy/redis-py\" rel=\"nofollow\">redis-py</a>.</p>\n<p>To use this feature, inherit from <code>MicroBenchRedis</code> instead of <code>MicroBench</code>,\nand specify the redis connection and key name as in the following example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">microbench</span> <span class=\"kn\">import</span> <span class=\"n\">MicroBenchRedis</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">RedisBench</span><span class=\"p\">(</span><span class=\"n\">MicroBenchRedis</span><span class=\"p\">):</span>\n    <span class=\"c1\"># redis_connection contains arguments for redis.StrictClient()</span>\n    <span class=\"n\">redis_connection</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'host'</span><span class=\"p\">:</span> <span class=\"s1\">'localhost'</span><span class=\"p\">,</span> <span class=\"s1\">'port'</span><span class=\"p\">:</span> <span class=\"mi\">6379</span><span class=\"p\">}</span>\n    <span class=\"n\">redis_key</span> <span class=\"o\">=</span> <span class=\"s1\">'microbench:mykey'</span>\n\n<span class=\"n\">benchmark</span> <span class=\"o\">=</span> <span class=\"n\">RedisBench</span><span class=\"p\">()</span>\n</pre>\n<p>To retrieve results, the <code>redis</code> package can be used directly:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">redis</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span>\n\n<span class=\"c1\"># Establish the connection to redis</span>\n<span class=\"n\">rconn</span> <span class=\"o\">=</span> <span class=\"n\">redis</span><span class=\"o\">.</span><span class=\"n\">StrictRedis</span><span class=\"p\">(</span><span class=\"n\">host</span><span class=\"o\">=...</span><span class=\"p\">,</span> <span class=\"n\">port</span><span class=\"o\">=...</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Read the redis data from 'myrediskey' into a list of byte arrays</span>\n<span class=\"n\">redis_data</span> <span class=\"o\">=</span> <span class=\"n\">redis</span><span class=\"o\">.</span><span class=\"n\">lrange</span><span class=\"p\">(</span><span class=\"s1\">'myrediskey'</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Convert the list into a single string</span>\n<span class=\"n\">json_data</span> <span class=\"o\">=</span> <span class=\"s1\">'</span><span class=\"se\">\\n</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"s1\">'utf8'</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">r</span> <span class=\"ow\">in</span> <span class=\"n\">redis_data</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Read the string into a pandas dataframe</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">read_json</span><span class=\"p\">(</span><span class=\"n\">json_data</span><span class=\"p\">,</span> <span class=\"n\">lines</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<h2>Feedback</h2>\n<p>Please note this is a recently created, experimental package. Please let me know\nyour feedback or feature requests in Github issues.</p>\n\n          </div>"}, "last_serial": 4941568, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "35183c81d2ecdb53aa999fcb72891168", "sha256": "462f81aad7e9f94e7f986da07c8042a03ccb39df8aed596e1abf4bd68a437533"}, "downloads": -1, "filename": "microbench-0.1.tar.gz", "has_sig": false, "md5_digest": "35183c81d2ecdb53aa999fcb72891168", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19282, "upload_time": "2018-08-02T22:54:14", "upload_time_iso_8601": "2018-08-02T22:54:14.602809Z", "url": "https://files.pythonhosted.org/packages/f3/2e/432b030d171e69b01caf1df57216ebad5fd9771cb0ab86c6f1afdb4a05c8/microbench-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "a946bbc9d0d9b20e39295b0956fb164f", "sha256": "a968f1951f3257b07e7e6820e571c0c2189eeb648b5832734dc49bb5899ed510"}, "downloads": -1, "filename": "microbench-0.2.tar.gz", "has_sig": false, "md5_digest": "a946bbc9d0d9b20e39295b0956fb164f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20114, "upload_time": "2018-08-03T18:58:58", "upload_time_iso_8601": "2018-08-03T18:58:58.063170Z", "url": "https://files.pythonhosted.org/packages/c6/aa/0ea8fabae331a4c5eeceaffcadae36cc4bdc8b2dc128824a1c67da474e58/microbench-0.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "152a559f242634e788b45c9c140f63ff", "sha256": "65ebb1c8023008d707b966c8884ee6e9c4845b9561f8e0aa09bc55e236a5ef21"}, "downloads": -1, "filename": "microbench-0.2.1.tar.gz", "has_sig": false, "md5_digest": "152a559f242634e788b45c9c140f63ff", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23728, "upload_time": "2018-08-03T22:41:28", "upload_time_iso_8601": "2018-08-03T22:41:28.886195Z", "url": "https://files.pythonhosted.org/packages/88/1a/1137ea6c03ee0a929e9acec0e0b4760590b4914100e5752614fd04e1b20c/microbench-0.2.1.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "73ef0cd5f78e510c8a7c4792a021a6d2", "sha256": "eafcbd3476c73ffa936d39237bb5b06ec55541cb4ed2d91e64318b2b1d627f1d"}, "downloads": -1, "filename": "microbench-0.3.tar.gz", "has_sig": false, "md5_digest": "73ef0cd5f78e510c8a7c4792a021a6d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24320, "upload_time": "2018-08-06T15:38:45", "upload_time_iso_8601": "2018-08-06T15:38:45.199382Z", "url": "https://files.pythonhosted.org/packages/e1/e6/cda6d93ba43ab31fec68baa2b209629223601d75c5d216837e5511f9d7fe/microbench-0.3.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "50f922e4687c7aa12221b1fcfc1fbbfb", "sha256": "87a1a6fc8d33e8a91feed051341b54761aca19fcc0503632ad59cbadb545a7b4"}, "downloads": -1, "filename": "microbench-0.4.1.tar.gz", "has_sig": false, "md5_digest": "50f922e4687c7aa12221b1fcfc1fbbfb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23768, "upload_time": "2019-03-06T00:08:41", "upload_time_iso_8601": "2019-03-06T00:08:41.780428Z", "url": "https://files.pythonhosted.org/packages/01/95/ae9f9cb7f748e47fedae2813332b65eb2201b880524bbbfb141c3b762135/microbench-0.4.1.tar.gz", "yanked": false}], "0.5": [{"comment_text": "", "digests": {"md5": "6674606e04c8be55e3c3b717a2136f9e", "sha256": "a4bd186b309f86668733168d69d484acff5a27ca69a8ee40e264701cacb6b299"}, "downloads": -1, "filename": "microbench-0.5.tar.gz", "has_sig": false, "md5_digest": "6674606e04c8be55e3c3b717a2136f9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25762, "upload_time": "2019-03-14T20:53:29", "upload_time_iso_8601": "2019-03-14T20:53:29.542781Z", "url": "https://files.pythonhosted.org/packages/0f/a1/2a679d7be2be0b8691926b9e6b122e6c386c2f92a1522c71243c1c7e789d/microbench-0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6674606e04c8be55e3c3b717a2136f9e", "sha256": "a4bd186b309f86668733168d69d484acff5a27ca69a8ee40e264701cacb6b299"}, "downloads": -1, "filename": "microbench-0.5.tar.gz", "has_sig": false, "md5_digest": "6674606e04c8be55e3c3b717a2136f9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25762, "upload_time": "2019-03-14T20:53:29", "upload_time_iso_8601": "2019-03-14T20:53:29.542781Z", "url": "https://files.pythonhosted.org/packages/0f/a1/2a679d7be2be0b8691926b9e6b122e6c386c2f92a1522c71243c1c7e789d/microbench-0.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:55:19 2020"}