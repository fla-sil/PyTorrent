{"info": {"author": "", "author_email": "aix360@us.ibm.com", "bugtrack_url": null, "classifiers": [], "description": "# AI Explainability 360 (v0.2.0)\n\n[![Build Status](https://travis-ci.com/IBM/AIX360.svg?branch=master)](https://travis-ci.com/IBM/AIX360)\n[![Documentation Status](https://readthedocs.org/projects/aix360/badge/?version=latest)](https://aix360.readthedocs.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/aix360.svg)](https://badge.fury.io/py/aix360)\n\nThe AI Explainability 360 toolkit is an open-source library that supports interpretability and explainability of datasets and machine learning models. The AI Explainability 360 Python package includes a comprehensive set of algorithms that cover different dimensions of explanations along with proxy explainability metrics. \n\nThe [AI Explainability 360 interactive experience](http://aix360.mybluemix.net/data) provides a gentle introduction to the concepts and capabilities by walking through an example use case for different consumer personas. The [tutorials and example notebooks](./examples) offer a deeper, data scientist-oriented introduction. The complete API is also available. \n\nThere is no single approach to explainability that works best. There are many ways to explain: data vs. model, directly interpretable vs. post hoc explanation, local vs. global, etc. It may therefore be confusing to figure out which algorithms are most appropriate for a given use case. To help, we have created some [guidance material](http://aix360.mybluemix.net/resources#guidance) and a [chart](./aix360/algorithms/README.md) that can be consulted. \n\nWe have developed the package with extensibility in mind. This library is still in development. We encourage the contribution of your explainability algorithms and metrics. To get started as a contributor, please join the [AI Explainability 360 Community on Slack](https://aix360.slack.com) by requesting an invitation [here](https://join.slack.com/t/aix360/shared_invite/enQtNzEyOTAwOTk1NzY2LTM1ZTMwM2M4OWQzNjhmNGRiZjg3MmJiYTAzNDU1MTRiYTIyMjFhZTI4ZDUwM2M1MGYyODkwNzQ2OWQzMThlN2Q). Please review the instructions to contribute code [here](CONTRIBUTING.md).\n\n## Supported explainability algorithms\n\n### Data explanation\n\n- ProtoDash ([Gurumoorthy et al., 2019](https://arxiv.org/abs/1707.01212))\n- Disentangled Inferred Prior VAE ([Kumar et al., 2018](https://openreview.net/forum?id=H1kG7GZAW))\n\n### Local post-hoc explanation \n\n- ProtoDash ([Gurumoorthy et al., 2019](https://arxiv.org/abs/1707.01212))\n- Contrastive Explanations Method ([Dhurandhar et al., 2018](https://papers.nips.cc/paper/7340-explanations-based-on-the-missing-towards-contrastive-explanations-with-pertinent-negatives))\n- Contrastive Explanations Method with Monotonic Attribute Functions ([Luss et al., 2019](https://arxiv.org/abs/1905.12698))\n- LIME ([Ribeiro et al. 2016](https://arxiv.org/abs/1602.04938),  [Github](https://github.com/marcotcr/lime))\n- SHAP ([Lundberg, et al. 2017](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions),  [Github](https://github.com/slundberg/shap))\n\n### Local direct explanation\n\n- Teaching AI to Explain its Decisions ([Hind et al., 2019](https://doi.org/10.1145/3306618.3314273)) \n\n### Global direct explanation\n\n- Boolean Decision Rules via Column Generation (Light Edition) ([Dash et al., 2018](https://papers.nips.cc/paper/7716-boolean-decision-rules-via-column-generation))\n- Generalized Linear Rule Models ([Wei et al., 2019](http://proceedings.mlr.press/v97/wei19a.html))\n\n### Global post-hoc explanation\u00a0\n\n- ProfWeight ([Dhurandhar et al., 2018](https://papers.nips.cc/paper/8231-improving-simple-models-with-confidence-profiles))\n\n\n## Supported explainability metrics\n- Faithfulness ([Alvarez-Melis and Jaakkola, 2018](https://papers.nips.cc/paper/8003-towards-robust-interpretability-with-self-explaining-neural-networks))\n- Monotonicity ([Luss et al., 2019](https://arxiv.org/abs/1905.12698))\n\n## Setup\n\nSupported Configurations:\n\n| OS      | Python version |\n| ------- | -------------- |\n| macOS   | 3.6  |\n| Ubuntu  | 3.6  |\n| Windows | 3.6  |\n\n\n### (Optional) Create a virtual environment\n\nAI Explainability 360 requires specific versions of many Python packages which may conflict\nwith other projects on your system. A virtual environment manager is strongly\nrecommended to ensure dependencies may be installed safely. If you have trouble installing the toolkit, try this first.\n\n#### Conda\n\nConda is recommended for all configurations though Virtualenv is generally\ninterchangeable for our purposes. Miniconda is sufficient (see [the difference between Anaconda and\nMiniconda](https://conda.io/docs/user-guide/install/download.html#anaconda-or-miniconda)\nif you are curious) and can be installed from\n[here](https://conda.io/miniconda.html) if you do not already have it.\n\nThen, to create a new Python 3.6 environment, run:\n\n```bash\nconda create --name aix360 python=3.6\nconda activate aix360\n```\n\nThe shell should now look like `(aix360) $`. To deactivate the environment, run:\n\n```bash\n(aix360)$ conda deactivate\n```\n\nThe prompt will return back to `$ ` or `(base)$`.\n\nNote: Older versions of conda may use `source activate aix360` and `source\ndeactivate` (`activate aix360` and `deactivate` on Windows).\n\n\n### Installation\n\nClone the latest version of this repository:\n\n```bash\n(aix360)$ git clone https://github.com/IBM/AIX360\n```\n\nIf you'd like to run the examples and tutorial notebooks, download the datasets now and place them in\ntheir respective folders as described in\n[aix360/data/README.md](aix360/data/README.md).\n\nThen, navigate to the root directory of the project which contains `setup.py` file and run:\n\n```bash\n(aix360)$ pip install -e .\n```\n\n## Using AI Explainability 360\n\nThe `examples` directory contains a diverse collection of jupyter notebooks\nthat use AI Explainability 360 in various ways. Both examples and tutorial notebooks illustrate\nworking code using the toolkit. Tutorials provide additional discussion that walks\nthe user through the various steps of the notebook. See the details about\ntutorials and examples [here](examples/README.md). \n\n## Citing AI Explainability 360\n\nA technical description of AI Explainability 360 is available in this\n[paper](https://arxiv.org/abs/1909.03012). Below is the bibtex entry for this\npaper.\n\n```\n@misc{aix360-sept-2019,\ntitle = \"One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques\",\nauthor = {Vijay Arya and Rachel K. E. Bellamy and Pin-Yu Chen and Amit Dhurandhar and Michael Hind\nand Samuel C. Hoffman and Stephanie Houde and Q. Vera Liao and Ronny Luss and Aleksandra Mojsilovi\\'c\nand Sami Mourad and Pablo Pedemonte and Ramya Raghavendra and John Richards and Prasanna Sattigeri\nand Karthikeyan Shanmugam and Moninder Singh and Kush R. Varshney and Dennis Wei and Yunfeng Zhang},\nmonth = sept,\nyear = {2019},\nurl = {https://arxiv.org/abs/1909.03012}\n}\n```\n\n## AIX360 Videos\n\n* Introductory [video](https://www.youtube.com/watch?v=Yn4yduyoQh4) to AI\n  Explainability 360 by Vijay Arya and Amit Dhurandhar, September 5, 2019 (35 mins)\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/IBM/AIX360", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "aix360", "package_url": "https://pypi.org/project/aix360/", "platform": "", "project_url": "https://pypi.org/project/aix360/", "project_urls": {"Homepage": "https://github.com/IBM/AIX360"}, "release_url": "https://pypi.org/project/aix360/0.2.0/", "requires_dist": ["joblib (>=0.11)", "scikit-learn (>=0.21.2)", "torch", "torchvision", "cvxpy", "cvxopt", "Image", "keras", "matplotlib", "numpy", "pandas", "scipy (>=0.17)", "tensorflow (==1.14)", "xport", "scikit-image", "requests", "lime", "shap", "xgboost", "bleach (>=2.1.0)", "docutils (>=0.13.1)", "Pygments"], "requires_python": "", "summary": "IBM AI Explainability 360", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>AI Explainability 360 (v0.2.0)</h1>\n<p><a href=\"https://travis-ci.com/IBM/AIX360\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a367fcbf20a4778a372e40c4df86aad913de59c5/68747470733a2f2f7472617669732d63692e636f6d2f49424d2f4149583336302e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://aix360.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4d38f4be93f6b7977c3432e6475295312bceb824/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6169783336302f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://badge.fury.io/py/aix360\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1e66fdc103050cbede516cbed4ab255e79bec149/68747470733a2f2f62616467652e667572792e696f2f70792f6169783336302e737667\"></a></p>\n<p>The AI Explainability 360 toolkit is an open-source library that supports interpretability and explainability of datasets and machine learning models. The AI Explainability 360 Python package includes a comprehensive set of algorithms that cover different dimensions of explanations along with proxy explainability metrics.</p>\n<p>The <a href=\"http://aix360.mybluemix.net/data\" rel=\"nofollow\">AI Explainability 360 interactive experience</a> provides a gentle introduction to the concepts and capabilities by walking through an example use case for different consumer personas. The <a href=\"./examples\" rel=\"nofollow\">tutorials and example notebooks</a> offer a deeper, data scientist-oriented introduction. The complete API is also available.</p>\n<p>There is no single approach to explainability that works best. There are many ways to explain: data vs. model, directly interpretable vs. post hoc explanation, local vs. global, etc. It may therefore be confusing to figure out which algorithms are most appropriate for a given use case. To help, we have created some <a href=\"http://aix360.mybluemix.net/resources#guidance\" rel=\"nofollow\">guidance material</a> and a <a href=\"./aix360/algorithms/README.md\" rel=\"nofollow\">chart</a> that can be consulted.</p>\n<p>We have developed the package with extensibility in mind. This library is still in development. We encourage the contribution of your explainability algorithms and metrics. To get started as a contributor, please join the <a href=\"https://aix360.slack.com\" rel=\"nofollow\">AI Explainability 360 Community on Slack</a> by requesting an invitation <a href=\"https://join.slack.com/t/aix360/shared_invite/enQtNzEyOTAwOTk1NzY2LTM1ZTMwM2M4OWQzNjhmNGRiZjg3MmJiYTAzNDU1MTRiYTIyMjFhZTI4ZDUwM2M1MGYyODkwNzQ2OWQzMThlN2Q\" rel=\"nofollow\">here</a>. Please review the instructions to contribute code <a href=\"CONTRIBUTING.md\" rel=\"nofollow\">here</a>.</p>\n<h2>Supported explainability algorithms</h2>\n<h3>Data explanation</h3>\n<ul>\n<li>ProtoDash (<a href=\"https://arxiv.org/abs/1707.01212\" rel=\"nofollow\">Gurumoorthy et al., 2019</a>)</li>\n<li>Disentangled Inferred Prior VAE (<a href=\"https://openreview.net/forum?id=H1kG7GZAW\" rel=\"nofollow\">Kumar et al., 2018</a>)</li>\n</ul>\n<h3>Local post-hoc explanation</h3>\n<ul>\n<li>ProtoDash (<a href=\"https://arxiv.org/abs/1707.01212\" rel=\"nofollow\">Gurumoorthy et al., 2019</a>)</li>\n<li>Contrastive Explanations Method (<a href=\"https://papers.nips.cc/paper/7340-explanations-based-on-the-missing-towards-contrastive-explanations-with-pertinent-negatives\" rel=\"nofollow\">Dhurandhar et al., 2018</a>)</li>\n<li>Contrastive Explanations Method with Monotonic Attribute Functions (<a href=\"https://arxiv.org/abs/1905.12698\" rel=\"nofollow\">Luss et al., 2019</a>)</li>\n<li>LIME (<a href=\"https://arxiv.org/abs/1602.04938\" rel=\"nofollow\">Ribeiro et al. 2016</a>,  <a href=\"https://github.com/marcotcr/lime\" rel=\"nofollow\">Github</a>)</li>\n<li>SHAP (<a href=\"http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions\" rel=\"nofollow\">Lundberg, et al. 2017</a>,  <a href=\"https://github.com/slundberg/shap\" rel=\"nofollow\">Github</a>)</li>\n</ul>\n<h3>Local direct explanation</h3>\n<ul>\n<li>Teaching AI to Explain its Decisions (<a href=\"https://doi.org/10.1145/3306618.3314273\" rel=\"nofollow\">Hind et al., 2019</a>)</li>\n</ul>\n<h3>Global direct explanation</h3>\n<ul>\n<li>Boolean Decision Rules via Column Generation (Light Edition) (<a href=\"https://papers.nips.cc/paper/7716-boolean-decision-rules-via-column-generation\" rel=\"nofollow\">Dash et al., 2018</a>)</li>\n<li>Generalized Linear Rule Models (<a href=\"http://proceedings.mlr.press/v97/wei19a.html\" rel=\"nofollow\">Wei et al., 2019</a>)</li>\n</ul>\n<h3>Global post-hoc explanation\u00a0</h3>\n<ul>\n<li>ProfWeight (<a href=\"https://papers.nips.cc/paper/8231-improving-simple-models-with-confidence-profiles\" rel=\"nofollow\">Dhurandhar et al., 2018</a>)</li>\n</ul>\n<h2>Supported explainability metrics</h2>\n<ul>\n<li>Faithfulness (<a href=\"https://papers.nips.cc/paper/8003-towards-robust-interpretability-with-self-explaining-neural-networks\" rel=\"nofollow\">Alvarez-Melis and Jaakkola, 2018</a>)</li>\n<li>Monotonicity (<a href=\"https://arxiv.org/abs/1905.12698\" rel=\"nofollow\">Luss et al., 2019</a>)</li>\n</ul>\n<h2>Setup</h2>\n<p>Supported Configurations:</p>\n<table>\n<thead>\n<tr>\n<th>OS</th>\n<th>Python version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>macOS</td>\n<td>3.6</td>\n</tr>\n<tr>\n<td>Ubuntu</td>\n<td>3.6</td>\n</tr>\n<tr>\n<td>Windows</td>\n<td>3.6</td>\n</tr></tbody></table>\n<h3>(Optional) Create a virtual environment</h3>\n<p>AI Explainability 360 requires specific versions of many Python packages which may conflict\nwith other projects on your system. A virtual environment manager is strongly\nrecommended to ensure dependencies may be installed safely. If you have trouble installing the toolkit, try this first.</p>\n<h4>Conda</h4>\n<p>Conda is recommended for all configurations though Virtualenv is generally\ninterchangeable for our purposes. Miniconda is sufficient (see <a href=\"https://conda.io/docs/user-guide/install/download.html#anaconda-or-miniconda\" rel=\"nofollow\">the difference between Anaconda and\nMiniconda</a>\nif you are curious) and can be installed from\n<a href=\"https://conda.io/miniconda.html\" rel=\"nofollow\">here</a> if you do not already have it.</p>\n<p>Then, to create a new Python 3.6 environment, run:</p>\n<pre>conda create --name aix360 <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">3</span>.6\nconda activate aix360\n</pre>\n<p>The shell should now look like <code>(aix360) $</code>. To deactivate the environment, run:</p>\n<pre><span class=\"o\">(</span>aix360<span class=\"o\">)</span>$ conda deactivate\n</pre>\n<p>The prompt will return back to <code>$</code> or <code>(base)$</code>.</p>\n<p>Note: Older versions of conda may use <code>source activate aix360</code> and <code>source deactivate</code> (<code>activate aix360</code> and <code>deactivate</code> on Windows).</p>\n<h3>Installation</h3>\n<p>Clone the latest version of this repository:</p>\n<pre><span class=\"o\">(</span>aix360<span class=\"o\">)</span>$ git clone https://github.com/IBM/AIX360\n</pre>\n<p>If you'd like to run the examples and tutorial notebooks, download the datasets now and place them in\ntheir respective folders as described in\n<a href=\"aix360/data/README.md\" rel=\"nofollow\">aix360/data/README.md</a>.</p>\n<p>Then, navigate to the root directory of the project which contains <code>setup.py</code> file and run:</p>\n<pre><span class=\"o\">(</span>aix360<span class=\"o\">)</span>$ pip install -e .\n</pre>\n<h2>Using AI Explainability 360</h2>\n<p>The <code>examples</code> directory contains a diverse collection of jupyter notebooks\nthat use AI Explainability 360 in various ways. Both examples and tutorial notebooks illustrate\nworking code using the toolkit. Tutorials provide additional discussion that walks\nthe user through the various steps of the notebook. See the details about\ntutorials and examples <a href=\"examples/README.md\" rel=\"nofollow\">here</a>.</p>\n<h2>Citing AI Explainability 360</h2>\n<p>A technical description of AI Explainability 360 is available in this\n<a href=\"https://arxiv.org/abs/1909.03012\" rel=\"nofollow\">paper</a>. Below is the bibtex entry for this\npaper.</p>\n<pre><code>@misc{aix360-sept-2019,\ntitle = \"One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques\",\nauthor = {Vijay Arya and Rachel K. E. Bellamy and Pin-Yu Chen and Amit Dhurandhar and Michael Hind\nand Samuel C. Hoffman and Stephanie Houde and Q. Vera Liao and Ronny Luss and Aleksandra Mojsilovi\\'c\nand Sami Mourad and Pablo Pedemonte and Ramya Raghavendra and John Richards and Prasanna Sattigeri\nand Karthikeyan Shanmugam and Moninder Singh and Kush R. Varshney and Dennis Wei and Yunfeng Zhang},\nmonth = sept,\nyear = {2019},\nurl = {https://arxiv.org/abs/1909.03012}\n}\n</code></pre>\n<h2>AIX360 Videos</h2>\n<ul>\n<li>Introductory <a href=\"https://www.youtube.com/watch?v=Yn4yduyoQh4\" rel=\"nofollow\">video</a> to AI\nExplainability 360 by Vijay Arya and Amit Dhurandhar, September 5, 2019 (35 mins)</li>\n</ul>\n\n          </div>"}, "last_serial": 6267230, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "137c427d0fbe0bd14a03c7b8e775dbc5", "sha256": "f9eeb056ecf88a33f35e927510960bcb7d565be927b3638eae7b67811662f236"}, "downloads": -1, "filename": "aix360-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "137c427d0fbe0bd14a03c7b8e775dbc5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10711893, "upload_time": "2019-08-08T10:38:41", "upload_time_iso_8601": "2019-08-08T10:38:41.888510Z", "url": "https://files.pythonhosted.org/packages/cd/37/079f748d0833a5180a744abba4c09a3544fa2b0a30de0f2f5d84b906cf6a/aix360-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b7615f58e8adc7361f6d42073c9c05f6", "sha256": "8de5be23c33fc4f0b2eaa93a4d0738e32bd9a2469ba9ba81adb549afed59f113"}, "downloads": -1, "filename": "aix360-0.1.0.tar.gz", "has_sig": false, "md5_digest": "b7615f58e8adc7361f6d42073c9c05f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68187, "upload_time": "2019-08-08T10:38:44", "upload_time_iso_8601": "2019-08-08T10:38:44.870777Z", "url": "https://files.pythonhosted.org/packages/28/a0/09fda99f8cf7f7b23b3b483073e2406eda4506f7efda2d2d60aeba3d02b9/aix360-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "0987f3d32b7e9136d5afdc3f6fb2d7c4", "sha256": "e5bd181fc8c97fcb9677c5aa2b6565eac49676a2358998ba191f9736acf55eee"}, "downloads": -1, "filename": "aix360-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0987f3d32b7e9136d5afdc3f6fb2d7c4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10722046, "upload_time": "2019-12-09T16:40:41", "upload_time_iso_8601": "2019-12-09T16:40:41.499911Z", "url": "https://files.pythonhosted.org/packages/ef/12/852179e4b02c27dd6d42c20c93b10debab9ad59b3685179cabf136052c31/aix360-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5fd8f30a7e8d4859436fd2f17438bc92", "sha256": "58cefb1bded179d0cbcf2be669072465de00372d27d345bc526138dbbc837fe7"}, "downloads": -1, "filename": "aix360-0.2.0.tar.gz", "has_sig": false, "md5_digest": "5fd8f30a7e8d4859436fd2f17438bc92", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79636, "upload_time": "2019-12-09T16:40:44", "upload_time_iso_8601": "2019-12-09T16:40:44.613361Z", "url": "https://files.pythonhosted.org/packages/74/f4/4898e224a7d9585107cbc255c1732702534d78e6cb26bbba2d27daa1cc7e/aix360-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0987f3d32b7e9136d5afdc3f6fb2d7c4", "sha256": "e5bd181fc8c97fcb9677c5aa2b6565eac49676a2358998ba191f9736acf55eee"}, "downloads": -1, "filename": "aix360-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0987f3d32b7e9136d5afdc3f6fb2d7c4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10722046, "upload_time": "2019-12-09T16:40:41", "upload_time_iso_8601": "2019-12-09T16:40:41.499911Z", "url": "https://files.pythonhosted.org/packages/ef/12/852179e4b02c27dd6d42c20c93b10debab9ad59b3685179cabf136052c31/aix360-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5fd8f30a7e8d4859436fd2f17438bc92", "sha256": "58cefb1bded179d0cbcf2be669072465de00372d27d345bc526138dbbc837fe7"}, "downloads": -1, "filename": "aix360-0.2.0.tar.gz", "has_sig": false, "md5_digest": "5fd8f30a7e8d4859436fd2f17438bc92", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 79636, "upload_time": "2019-12-09T16:40:44", "upload_time_iso_8601": "2019-12-09T16:40:44.613361Z", "url": "https://files.pythonhosted.org/packages/74/f4/4898e224a7d9585107cbc255c1732702534d78e6cb26bbba2d27daa1cc7e/aix360-0.2.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:20:18 2020"}