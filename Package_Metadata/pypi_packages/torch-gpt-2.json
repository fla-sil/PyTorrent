{"info": {"author": "CyberZHG", "author_email": "CyberZHG@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6"], "description": "# PyTorch GPT-2\n\n[![Travis](https://travis-ci.org/CyberZHG/torch-gpt-2.svg)](https://travis-ci.org/CyberZHG/torch-gpt-2)\n[![Coverage](https://coveralls.io/repos/github/CyberZHG/torch-gpt-2/badge.svg?branch=master)](https://coveralls.io/github/CyberZHG/torch-gpt-2)\n\n## Install\n\n```bash\npip install torch-gpt-2\n```\n\n## Demo\n\n```python\nimport os\nimport sys\nfrom torch_gpt_2 import load_trained_model_from_checkpoint, get_bpe_from_files, generate\n\n\nif len(sys.argv) != 2:\n    print('python3 demo.py MODEL_FOLDER')\n    sys.exit(-1)\n\n\nmodel_folder = sys.argv[1]\nconfig_path = os.path.join(model_folder, 'hparams.json')\ncheckpoint_path = os.path.join(model_folder, 'model.ckpt')\nencoder_path = os.path.join(model_folder, 'encoder.json')\nvocab_path = os.path.join(model_folder, 'vocab.bpe')\n\n\nprint('Load net from checkpoint...')\nnet = load_trained_model_from_checkpoint(config_path, checkpoint_path)\nprint('Load BPE from files...')\nbpe = get_bpe_from_files(encoder_path, vocab_path)\nprint('Generate text...')\noutput = generate(net, bpe, ['From the day forth, my arm'], length=20, top_k=1)\n\n# If you are using the 117M model and top_k equals to 1, then the result would be:\n# \"From the day forth, my arm was broken, and I was in a state of pain. I was in a state of pain,\"\nprint(output[0])\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/CyberZHG/torch-gpt-2", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torch-gpt-2", "package_url": "https://pypi.org/project/torch-gpt-2/", "platform": "", "project_url": "https://pypi.org/project/torch-gpt-2/", "project_urls": {"Homepage": "https://github.com/CyberZHG/torch-gpt-2"}, "release_url": "https://pypi.org/project/torch-gpt-2/0.3.0/", "requires_dist": null, "requires_python": "", "summary": "GPT-2 implemented in PyTorch", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PyTorch GPT-2</h1>\n<p><a href=\"https://travis-ci.org/CyberZHG/torch-gpt-2\" rel=\"nofollow\"><img alt=\"Travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9a3373aa738946371d3c33e340a67ab5c5777d15/68747470733a2f2f7472617669732d63692e6f72672f43796265725a48472f746f7263682d6770742d322e737667\"></a>\n<a href=\"https://coveralls.io/github/CyberZHG/torch-gpt-2\" rel=\"nofollow\"><img alt=\"Coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ff58a72e481e3c15b4f387b371eaa730c15307d6/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f43796265725a48472f746f7263682d6770742d322f62616467652e7376673f6272616e63683d6d6173746572\"></a></p>\n<h2>Install</h2>\n<pre>pip install torch-gpt-2\n</pre>\n<h2>Demo</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">sys</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch_gpt_2</span> <span class=\"kn\">import</span> <span class=\"n\">load_trained_model_from_checkpoint</span><span class=\"p\">,</span> <span class=\"n\">get_bpe_from_files</span><span class=\"p\">,</span> <span class=\"n\">generate</span>\n\n\n<span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">sys</span><span class=\"o\">.</span><span class=\"n\">argv</span><span class=\"p\">)</span> <span class=\"o\">!=</span> <span class=\"mi\">2</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'python3 demo.py MODEL_FOLDER'</span><span class=\"p\">)</span>\n    <span class=\"n\">sys</span><span class=\"o\">.</span><span class=\"n\">exit</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">model_folder</span> <span class=\"o\">=</span> <span class=\"n\">sys</span><span class=\"o\">.</span><span class=\"n\">argv</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">config_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">model_folder</span><span class=\"p\">,</span> <span class=\"s1\">'hparams.json'</span><span class=\"p\">)</span>\n<span class=\"n\">checkpoint_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">model_folder</span><span class=\"p\">,</span> <span class=\"s1\">'model.ckpt'</span><span class=\"p\">)</span>\n<span class=\"n\">encoder_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">model_folder</span><span class=\"p\">,</span> <span class=\"s1\">'encoder.json'</span><span class=\"p\">)</span>\n<span class=\"n\">vocab_path</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">model_folder</span><span class=\"p\">,</span> <span class=\"s1\">'vocab.bpe'</span><span class=\"p\">)</span>\n\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Load net from checkpoint...'</span><span class=\"p\">)</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">load_trained_model_from_checkpoint</span><span class=\"p\">(</span><span class=\"n\">config_path</span><span class=\"p\">,</span> <span class=\"n\">checkpoint_path</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Load BPE from files...'</span><span class=\"p\">)</span>\n<span class=\"n\">bpe</span> <span class=\"o\">=</span> <span class=\"n\">get_bpe_from_files</span><span class=\"p\">(</span><span class=\"n\">encoder_path</span><span class=\"p\">,</span> <span class=\"n\">vocab_path</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Generate text...'</span><span class=\"p\">)</span>\n<span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">generate</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">,</span> <span class=\"n\">bpe</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'From the day forth, my arm'</span><span class=\"p\">],</span> <span class=\"n\">length</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># If you are using the 117M model and top_k equals to 1, then the result would be:</span>\n<span class=\"c1\"># \"From the day forth, my arm was broken, and I was in a state of pain. I was in a state of pain,\"</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n</pre>\n\n          </div>"}, "last_serial": 4869210, "releases": {"0.3.0": [{"comment_text": "", "digests": {"md5": "47558bbd8c54c701218030e5d18d3a8f", "sha256": "36c99f38fb8a910a3a38f483f776d4f23c19ddfe46387145afda785cdaff2fd0"}, "downloads": -1, "filename": "torch-gpt-2-0.3.0.tar.gz", "has_sig": false, "md5_digest": "47558bbd8c54c701218030e5d18d3a8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5939, "upload_time": "2019-02-26T10:43:08", "upload_time_iso_8601": "2019-02-26T10:43:08.744410Z", "url": "https://files.pythonhosted.org/packages/7d/5c/d784bde9fc5c2ed4a2d2b0d731c2e361e4acfc3d6d141629d783898a16bb/torch-gpt-2-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "47558bbd8c54c701218030e5d18d3a8f", "sha256": "36c99f38fb8a910a3a38f483f776d4f23c19ddfe46387145afda785cdaff2fd0"}, "downloads": -1, "filename": "torch-gpt-2-0.3.0.tar.gz", "has_sig": false, "md5_digest": "47558bbd8c54c701218030e5d18d3a8f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5939, "upload_time": "2019-02-26T10:43:08", "upload_time_iso_8601": "2019-02-26T10:43:08.744410Z", "url": "https://files.pythonhosted.org/packages/7d/5c/d784bde9fc5c2ed4a2d2b0d731c2e361e4acfc3d6d141629d783898a16bb/torch-gpt-2-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:23 2020"}