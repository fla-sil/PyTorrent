{"info": {"author": "Maixent Chenebaux", "author_email": "max.chbx@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "# Voice Activity Detection with Python\n\n### Installing\n\n```\npip install vader\n```\n\n### Basic usage\n\n```python\nimport vader\n\n# use your own mono, preferably 16kHz .wav file\nfilename = \"audio.wav\"\n\n# returns segments of vocal activity (unit: seconds)\n# note: it uses a pre-trained logistic regression by default\nsegments = vader.vad(filename)\n\n# where to dump audio files\nout_folder = \"segments\"\n# write segments into .wav files\nvader.vad_to_files(segments, filename, out_folder)\n```\n\nYou can also use different pre-trained models by specifying the method parameter\n\n```python\n# logistic method\nsegments = vader.vad(filename, threshold=.1, window=20, method=\"logistic\")\n\n# multi-layer perceptron method\nsegments = vader.vad(filename, threshold=.1, window=20, method=\"nn\")\n\n# Naive Bayes method\nsegments = vader.vad(filename, threshold=.5, window=10, method=\"nb\")\n```\nThe `threshold` parameter is the ratio of voice frames above which a window of frames is counted as a voiced sample. The `window` parameter controls the number of frames considered, and thus the length of the voiced samples.\n\nYou can also train your own models:\n\n```python\nimport vader\nmodel = vader.train.logistic_regression(mfccs, activities)\nmodel = vader.train.random_forest_classifier(mfccs, activities)\nmodel = vader.train.NN(mfccs, activities)\nmodel = vader.train.NB(mfccs, activities)\n```\nThe variable `mfccs` is a list of varying length mfcc features (num_samples, *varying_lengths*, 13), while `activities` is a list of binary vectors whose lengths match those of the mfcc features (num_samples, *varying_lengths*), equal to 1 when a frame is voiced, and 0 otherwise.\n\n## Authors\n\nMaixent Chenebaux\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kerighan/vader", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "vader", "package_url": "https://pypi.org/project/vader/", "platform": "", "project_url": "https://pypi.org/project/vader/", "project_urls": {"Homepage": "https://github.com/kerighan/vader"}, "release_url": "https://pypi.org/project/vader/0.0.2/", "requires_dist": ["scikit-learn", "numpy", "scipy", "sonopy"], "requires_python": ">=3.5", "summary": "Fast voice activity detection with Python", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Voice Activity Detection with Python</h1>\n<h3>Installing</h3>\n<pre><code>pip install vader\n</code></pre>\n<h3>Basic usage</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">vader</span>\n\n<span class=\"c1\"># use your own mono, preferably 16kHz .wav file</span>\n<span class=\"n\">filename</span> <span class=\"o\">=</span> <span class=\"s2\">\"audio.wav\"</span>\n\n<span class=\"c1\"># returns segments of vocal activity (unit: seconds)</span>\n<span class=\"c1\"># note: it uses a pre-trained logistic regression by default</span>\n<span class=\"n\">segments</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">vad</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># where to dump audio files</span>\n<span class=\"n\">out_folder</span> <span class=\"o\">=</span> <span class=\"s2\">\"segments\"</span>\n<span class=\"c1\"># write segments into .wav files</span>\n<span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">vad_to_files</span><span class=\"p\">(</span><span class=\"n\">segments</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">out_folder</span><span class=\"p\">)</span>\n</pre>\n<p>You can also use different pre-trained models by specifying the method parameter</p>\n<pre><span class=\"c1\"># logistic method</span>\n<span class=\"n\">segments</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">vad</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">threshold</span><span class=\"o\">=.</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">window</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">\"logistic\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># multi-layer perceptron method</span>\n<span class=\"n\">segments</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">vad</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">threshold</span><span class=\"o\">=.</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">window</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">\"nn\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Naive Bayes method</span>\n<span class=\"n\">segments</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">vad</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">threshold</span><span class=\"o\">=.</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">window</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">\"nb\"</span><span class=\"p\">)</span>\n</pre>\n<p>The <code>threshold</code> parameter is the ratio of voice frames above which a window of frames is counted as a voiced sample. The <code>window</code> parameter controls the number of frames considered, and thus the length of the voiced samples.</p>\n<p>You can also train your own models:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">vader</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">logistic_regression</span><span class=\"p\">(</span><span class=\"n\">mfccs</span><span class=\"p\">,</span> <span class=\"n\">activities</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">random_forest_classifier</span><span class=\"p\">(</span><span class=\"n\">mfccs</span><span class=\"p\">,</span> <span class=\"n\">activities</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">NN</span><span class=\"p\">(</span><span class=\"n\">mfccs</span><span class=\"p\">,</span> <span class=\"n\">activities</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">vader</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">NB</span><span class=\"p\">(</span><span class=\"n\">mfccs</span><span class=\"p\">,</span> <span class=\"n\">activities</span><span class=\"p\">)</span>\n</pre>\n<p>The variable <code>mfccs</code> is a list of varying length mfcc features (num_samples, <em>varying_lengths</em>, 13), while <code>activities</code> is a list of binary vectors whose lengths match those of the mfcc features (num_samples, <em>varying_lengths</em>), equal to 1 when a frame is voiced, and 0 otherwise.</p>\n<h2>Authors</h2>\n<p>Maixent Chenebaux</p>\n\n          </div>"}, "last_serial": 6755127, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "db87168e88d9b47b25b874a113294c27", "sha256": "d2797969b3d2ff1ab17e5e1992864b6e6f4f84ec04a315ee10d391dfefb52e41"}, "downloads": -1, "filename": "vader-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "db87168e88d9b47b25b874a113294c27", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 46012, "upload_time": "2020-03-05T13:25:26", "upload_time_iso_8601": "2020-03-05T13:25:26.640941Z", "url": "https://files.pythonhosted.org/packages/75/32/283c8e102becc8bd8cb09c47d2834be984c8bd5c4d43495bd932035a2d39/vader-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a0f714e6874f9fc66bae31b0dcace15f", "sha256": "30f9ac441aa7b584a486a3d70430f7d25bae2b69a57a805920deeb0ddc5295bc"}, "downloads": -1, "filename": "vader-0.0.1.tar.gz", "has_sig": false, "md5_digest": "a0f714e6874f9fc66bae31b0dcace15f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 46929, "upload_time": "2020-03-05T13:25:29", "upload_time_iso_8601": "2020-03-05T13:25:29.968368Z", "url": "https://files.pythonhosted.org/packages/42/d7/a6bab2458a92fda4dfc773660abbdb163f7123ad7f37d2757411418c8e16/vader-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "8ff9fd176a01543f82ec1859d3d03cf9", "sha256": "92085c62d183316c72710c9ea51f74cf1da030f014df26728cbd53f9824bac1e"}, "downloads": -1, "filename": "vader-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "8ff9fd176a01543f82ec1859d3d03cf9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 45915, "upload_time": "2020-03-05T13:29:46", "upload_time_iso_8601": "2020-03-05T13:29:46.558542Z", "url": "https://files.pythonhosted.org/packages/be/0d/df60a0ae9ffb63c409849d2909883963855d10e2ee9a5a71c97be41da300/vader-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a453a5ac36787a312470d7d36dee8301", "sha256": "a6b6c26dbb9f2434a83d05d1daa488e09ec7fad01a144e9c78c9def0170aae20"}, "downloads": -1, "filename": "vader-0.0.2.tar.gz", "has_sig": false, "md5_digest": "a453a5ac36787a312470d7d36dee8301", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 46663, "upload_time": "2020-03-05T13:29:48", "upload_time_iso_8601": "2020-03-05T13:29:48.266146Z", "url": "https://files.pythonhosted.org/packages/f2/fe/3ceb70183cd6f724f77b3f0fcff8cfbff09d614e9f009fba5f807d53cf9d/vader-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8ff9fd176a01543f82ec1859d3d03cf9", "sha256": "92085c62d183316c72710c9ea51f74cf1da030f014df26728cbd53f9824bac1e"}, "downloads": -1, "filename": "vader-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "8ff9fd176a01543f82ec1859d3d03cf9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 45915, "upload_time": "2020-03-05T13:29:46", "upload_time_iso_8601": "2020-03-05T13:29:46.558542Z", "url": "https://files.pythonhosted.org/packages/be/0d/df60a0ae9ffb63c409849d2909883963855d10e2ee9a5a71c97be41da300/vader-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a453a5ac36787a312470d7d36dee8301", "sha256": "a6b6c26dbb9f2434a83d05d1daa488e09ec7fad01a144e9c78c9def0170aae20"}, "downloads": -1, "filename": "vader-0.0.2.tar.gz", "has_sig": false, "md5_digest": "a453a5ac36787a312470d7d36dee8301", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 46663, "upload_time": "2020-03-05T13:29:48", "upload_time_iso_8601": "2020-03-05T13:29:48.266146Z", "url": "https://files.pythonhosted.org/packages/f2/fe/3ceb70183cd6f724f77b3f0fcff8cfbff09d614e9f009fba5f807d53cf9d/vader-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:38:20 2020"}