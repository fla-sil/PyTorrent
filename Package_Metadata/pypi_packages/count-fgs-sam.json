{"info": {"author": "Tet Woo Lee", "author_email": "developer@twlee.nz", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# count_fgs_sam\n\nCount Functional Genomics Screen alignments in a SAM file with filtering options\n--------------------------------------------------------------------------------\n\nThis program will count the alignments in a SAM/BAM/CRAM file. The number of\nprimary alignments that are mapped to each reference sequence are counted. The\nalignments are filtered for various criteria before counting, and (optionally)\nadditional buckets of counts (for each reference) are produced.\n\nThis script uses the [pysam] module. It is designed for alignments produced by\n[Bowtie 2], and relies on the AS and XS score tags.\n\n[pysam]: https://github.com/pysam-developers/pysam\n[Bowtie 2]: http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml\n\nSee below for Bowtie 2 parameters to produce compatible alignments.\n\n### Command-line parameters\n\n```\nusage: count_fgs_sam [-h] [--version] [-r REFERENCEFILE] [-v]\n                     [-p PERFECTSCORE] [-l EXPECTEDLENGTH]\n                     [-a UNAMBIGUOUSDELTA] [-c ACCEPTABLESCORE]\n                     [-m ACCEPTABLEMINLENGTH] [-M ACCEPTABLEMAXLENGTH]\n                     [-o OUTPUTFILE] [--show-unacceptable] [--show-ambiguous]\n                     [--show-length] [-d]\n                     inputfile\n\npositional arguments:\n  inputfile             Input SAM/BAM/CRAM file, type determined by extension\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  -r REFERENCEFILE, --referencefile REFERENCEFILE\n                        For CRAM inputfile, path to FASTA reference file; if\n                        used, a FASTA index REFERENCEFILE.fai is needed and\n                        automatically generated if one doesn't already exist\n                        (default: None)\n  -v, --verbose         Increase logging verbosity, available levels 1 to 3\n                        with `-v` to `-vvv` (default: 0)\n  -p PERFECTSCORE, --perfectscore PERFECTSCORE\n                        Cutoff for perfect alignments, must have alignment\n                        score (AS) of at least this (AS>=cutoff) (default:\n                        200)\n  -l EXPECTEDLENGTH, --expectedlength EXPECTEDLENGTH\n                        Expected length of reads, reads filtered by this\n                        length (length==expectedlength) (default: 20)\n  -a UNAMBIGUOUSDELTA, --unambiguousdelta UNAMBIGUOUSDELTA\n                        Cutoff for unambiguous alignments, reads filtered for\n                        unambiguous alignments that have alignment score (AS)\n                        minus alternative score (XS) less than equal this (AS-\n                        XS<=cutoff), XS assumed to be 0 if not present for an\n                        alignment (default: 3)\n  -c ACCEPTABLESCORE, --acceptablescore ACCEPTABLESCORE\n                        Cutoff for acceptable alignments AS>=cutoff; if\n                        specified and different from --perfectscore, counts of\n                        acceptable reads are shown (default: None)\n  -m ACCEPTABLEMINLENGTH, --acceptableminlength ACCEPTABLEMINLENGTH\n                        Minimum length for acceptable alignments (length\n                        >=minlength); if specified and different from\n                        --expectedlength, counts of shorter reads are reported\n                        (default: None)\n  -M ACCEPTABLEMAXLENGTH, --acceptablemaxlength ACCEPTABLEMAXLENGTH\n                        Maximum length for acceptable alignments (length\n                        <=maxlength); if specified and different from\n                        --expectedlength, counts of longer reads are reported\n                        (default: None)\n\noptional output options:\n  Options to included additional count buckets in output\n\n  -o OUTPUTFILE, --outputfile OUTPUTFILE\n                        Output TSV file, output to stdout if absent (default:\n                        None)\n  --show-unacceptable   Show counts of ambiguous alignments (default: False)\n  --show-ambiguous      Show counts of unacceptable alignments (default:\n                        False)\n  --show-length         Show overall counts of reads by length classes, not\n                        filtered by any other criteria; counts outside\n                        specified lengths counted as 'length-out-of-range'\n                        (default: False)\n  -d, --detailed        Turn on all optional count buckets (--show* options\n                        enabled, as well as any buckets enabled with\n                        additional threshold parameters). Note that these\n                        optional count buckets may all be zero if\n                        corresponding parameters are not used. (default:\n                        False)\n```\n### Input file support\n\nThis script supports the input alignment formats supported by [pysam], i.e. SAM,\nBAM and CRAM. If using a reference-based CRAM file, [pysam] will attempt to read\nthe reference file according to the UR field in the CRAM file header. This can\nbe overridden using the `--referencefile` parameter. An indexed FASTA file is\nexpected as the reference file, and if no index is available then one will be\nautomatically generated. Reference-less CRAM files are supported by this script\nand may be preferred (they are generally smaller than BAM files, and about the\nsame size as reference-based CRAM files). The input SAM/BAM/CRAM itself file\ndoes not need to be sorted or indexed prior to use in this script.\n\n\n### Detail on scoring parameters\n\nThe following are parameters for scoring the alignments:\n\n  - Alignment score: The alignment score is read from the `AS` tag in the\n    alignment entry in the SAM/BAM file.\n\n  - Read length: The read length is inferred from the CIGAR alignment, or\n    if the read is unmapped, the read length is obtained from the sequence\n    in the SAM/BAM file.\n\n  - Alternative alignment score: The alternative alignment score is read from\n    the `XS` tag in the alignment entry in the SAM/BAM file.\n\n  - Alignment score delta: This is calculated as the alignment score (`AS`)\n    minus the alternative alignment score (`XS`) (i.e. `delta = AS-XS`). It\n    represents how much better the primary alignment is from the next best\n    alignment, i.e. a larger delta indicates the primary alignment is clearly\n    better than any alternatives, while a small delta may indicate that the\n    'best' alignment is ambiguous.\n\nThis script expects an input file consisting of unpaired reads aligned to the\nforward strand of the references and only primary alignments. Reads/alignments\nwith various SAM flags are processed as follows:\n\n  - Only primary alignments are processed by this script. All secondary or\n    supplementary alignments (SAM flags `0x100` or `0x800`)  are ignored, with a\n    warning produced by the script.  \n\n  - Any reads with the QC failed (`0x200`) or PCR/optical duplicate (`0x400`)\n    flags are ignored. No warning is produced but counts of these are logged.\n\n  - A warning is produced if paired reads (`0x1`) or alignments to the reverse\n    strand (`0x10`) are detected, although any such alignments are processed\n    normally.\n\n### Filtering criteria\n\nBased on the scoring parameters, the following filtering criteria are applied\nprior to counting the alignments:\n\n  - Perfect alignment score (`-p` or `--perfectscore`): Alignment score must be\n    at least (>=) this value for the alignment to be considered `perfect`. In\n    addition, an alignment must be of `expected-length` (below) to be considered\n    `perfect`. Therefore, any alignments with score >= this value that are not\n    of `expected-length` can be at best considered `acceptable` (below).  Any\n    read/alignment that is not `perfect` or `acceptable` is considered\n    `unacceptable`. This includes any unmapped reads. By default, only `perfect`\n    alignments are counted and reported.\n\n  - Expected length (`l` or `--expectedlength`): The read length must be equal\n    (==) to this length for an alignment resulting from the read to be\n    considered as being of `expected-length`. An alignment must be of\n    `expected-length` to be considered `perfect`, although an alignment that is\n    not of `expected-length` can still be considered to be `acceptable` if it\n    meets the `shorter` or `longer` criteria (below). Any alignment that is\n    outside expected or acceptable lengths is considered `unacceptable`. By\n    default, only alignments that are `perfect` and therefore of\n    `expected-length` are counted and reported.\n\n  - Unambiguous delta (`-a` or `--unambiguousdelta`): The alignment score delta\n    must be greater (>) than this value for the alignment to be considered\n    `unambiguous`. Any alignment with a delta less than or equal (<=) to this\n    value is considered `ambiguous`. By default, only alignments that are\n    `unambiguous` are counted and reported. Care should be used when choosing\n    this value based on the scoring scheme used. If set to too high, it is\n    possible that all alignments to certain references may be considered\n    ambiguous and not counted.  \n\n    If any reads with perfect alignments scores are found to be ambiguous, a\n    warning will be displayed since these will always be excluded from the\n    counts. It is likely that this is a configuration error. This may occur\n    if there are replicated sequences among the references (which should be\n    consolidated into a single reference sequence, and the reads realigned to\n    this new set of references), or the unambiguous delta is set too high.\n\n  - Acceptable alignment score (`-c` or `--acceptablescore`): Any non-`perfect`\n    alignments may be considered `acceptable` if their scores are at least (>=)\n    this value. By default, no `acceptable` are allowed. Providing an acceptable\n    alignment score will enable counting and reporting of `acceptable`\n    alignments, these still have to be of `expected-length` unless acceptable\n    minimum or maximum lengths are also provided.\n\n  - Acceptable minimum length (`-m` or `--acceptableminlength`): An alignment\n    from a read that is below (<) the expected length but greater than or equal\n    (>=) the acceptable minimum length will be considered `shorter`. Providing\n    an acceptable minimum length will enable counting and reporting of `shorter`\n    alignments. Alignments that are `shorter` will be considered `acceptable` if\n    they meet the acceptable alignment score threshold. If no acceptable\n    alignment score is provided, any `shorter` alignment that meets the perfect\n    score threshold will be considered `acceptable`, but in typical usage a\n    `shorter` alignment could not have a perfect alignment score and this option\n    should be combined with an acceptable alignment score.\n\n  - Acceptable maximum length (`-M` or `--acceptablemaxlength`): An alignment\n    from a read that is above (>) the expected length but less than or equal\n    (<=) the acceptable maximum length will be considered `longer`. Providing an\n    acceptable maximum length will enable counting and reporting of `longer`\n    alignments. Alignments that are `longer` will be considered `acceptable` if\n    they meet the acceptable alignment score threshold. If no acceptable\n    alignment score is provided, any `longer` alignment that meets the perfect\n    score threshold will be considered `acceptable`.\n\nThese filtering criteria determine which count buckets each read/alignment\ngoes into.\n\n### Count buckets\n\nVarious buckets of counts are produced for each reference sequence. Each\nreference sequence is a row in the output file, with the reference sequence name\n(`ref-name`) and length (`ref-length`) reported. The buckets in the output are\nthe columns (see further below for example output). In addition to the reference\nsequences, there are rows in the output file to count unmapped reads *if* they\nare included in the criteria for that count bucket (row has `ref-name` of\n`*unmapped`), the sum of all counted reads (including any counted unmapped\nreads; `**total_counted`), any excluded alignment/reads that don't meet the\nbucket criteria (`**excluded`), and the grand total of all reads\n(`***grand_total`). Note that for the `*unmapped` row, unmapped reads are\nautomatically considered unacceptable and therefore excluded for most buckets\n(i.e. only counted under `**excluded` rather than being counted under\n`*unmapped`), apart for `unacceptable` buckets. The buckets that can be produced\nare given below:\n\n  - `perfect/unambiguous/expected-length` (default)\n\n  - `acceptable/unambiguous/expected-length` (enabled if an acceptable alignment\n    score is provided)\n\n  - `acceptable/unambiguous/shorter` (enabled if an acceptable minimum length is\n    provided)\n\n  - `acceptable/unambiguous/longer` (enabled if an acceptable maximum length is\n    provided)\n\n  - `perfect/ambiguous/expected-length` (enabled with `--show-ambiguous`)\n\n  - `acceptable/ambiguous/expected-length` (enabled with `--show-ambiguous` and\n     if an acceptable alignment score is provided)\n\n  - `acceptable/ambiguous/shorter` (enabled with `--show-ambiguous` and\n     if an acceptable minimum length is provided)\n\n  - `acceptable/ambiguous/longer` (enabled with `--show-ambiguous` and\n     if an acceptable maximum length is provided)\n\n  - `unacceptable/expected-length` (enabled with `--show-unacceptable`)\n\n  - `unacceptable/shorter` (enabled with `--show-unacceptable` and\n     if an acceptable minimum length is provided)\n\n  - `unacceptable/longer` (enabled with `--show-unacceptable` and\n     if an acceptable maximum length is provided)\n\n  - `unacceptable/length-out-of-range` (enabled with `--show-unacceptable`)\n\nAll of the above buckets are mutually exclusive. A read cannot be in more than\none of the above buckets (excluding the total rows). This means, for example,\nthat downstream analyses should sum `perfect/unambiguous/expected-length` and\n`acceptable/unambiguous/expected-length` counts if both perfect and acceptable\ncounts are to be included. Buckets for ambiguous and unacceptable counts are\nprimarily meant to be used for diagnostic purposes.\n\nThe following buckets for overall (total) counts can also be produced:\n\n  - `expected-length`: counts all reads that are of `expected-length`,\n    regardless of score or delta criteria (enabled with `--show-length`)\n\n  - `shorter`: counts all reads that are `shorter`, regardless of score or\n    delta criteria (enabled with `--show-length` and if an acceptable minimum\n    length is provided)\n\n  - `longer`: counts all reads that are `longer`, regardless of score or\n    delta criteria (enabled with `--show-length` and if an acceptable maximum\n    length is provided)\n\n  - `length-out-of-range`: counts all reads that are not in any of the above\n    length categories, including any shorter/longer reads where acceptable\n    minimum or maximum lengths are not provided (enabled with `--show-length`)\n\n  - `any`: counts all reads regardless of score, delta or length criteria\n    (default)\n\nBy default, only `perfect/unambiguous/expected-length` and `any` counts are\nproduced.\n\n\n\nExample output (formatted with spaces for presentation, actual output is\ntab-separated):\n```\nref-name                ref-length  perfect/unambiguous/expected-length  any\nNon-Targeting___76442   20          21                                   25\nNon-Targeting___76443   20          22                                   22\n...\n*unmapped               nan         0                                    4803\n**total_counted         nan         17078                                23015\n**excluded              nan         5937                                 0\n***grand_total          nan         23015                                23015\n\n\n```\n### Suggested Bowtie 2 parameters\n\nThe suggested parameters for Bowtie 2 are as follows:\n\n`\nbowtie2 --ma=10 --mp=-4,-6 --np=-6 --rdg=0,1 --rfg=0,1 --score-min=C,150,0\n--n-ceil=C,2,0 --local --norc --gbar 1 -D 20 -R 1 -N 0 -L 10 -i L,1,0\n`\n\nThis uses local alignment with bonus scoring for matches (match bonus\n`--ma=10`), (lower) bonus scoring for mismatches/Ns (mismatch penalty\n`--mp=-4,-6`, N penalty `--np=-6`; negative values turn this into a bonus) and\nsmall gap penalties (read and reference gap penalties `--rdg=0,1 --rfg=0,1`;\ngaps at ends of the read are not penalised during local alignment, but all gaps\nare also penalised by a lack of match/mismatch bonus, i.e -10 compared to a\nmatch).\n\nThe minimum alignment score can be set leniently (`--score-min=C,150,0`) as this\nscript will do additional filtering of alignments prior to counting. The\nremaining options set a maximum of 2 Ns (`--n-ceil=C,2,0`) and the optimal\nparameters for producing to most mapped reads (determined mostly by trial and\nerror `--local --norc --gbar 1 -D 20 -R 1 -N 0 -L 10 -i L,1,0`).\n\nFor reads with length of 20 bp, these options will produce a perfect alignment\nscore of 200, and alignment score of at least 194 with one mismatch, and a score\nof 189 to 190 with one gap (depending of whether it is internal or at ends). For\nreads of 19 bp, a maximum score of 189 to 190 is possible for alignments with no\nmismatches depending on the position of the gap. For reads of 21 bp, a maximum\nscore of 200 is possible even with the additional unmatched nucleotide at the\nread ends. Ambiguous alignments can be detected based on the alternative\nalignment score, an additional mismatch will reduce the score by at least 4 and\nan additional gap will reduce the score by at least 10. Changes in the position\nof the gap or an character of a mismatch will alter score by only 0, -1 or -2.\n\nWith these Bowtie 2 parameters, a perfect alignment score of 200, expected\nlength of 20 and an unambiguous delta of 3 will count perfect, unambiguous\nalignments of the expected length (default parameters of `--perfectscore 200\n--expectedlength 20 --unambiguousdelta 3`). An acceptable alignment score of 194\ncan be used to count alignments with one mismatch (additional parameter\n`--acceptablescore 194`). An acceptable alignment score of 189, and acceptable\nminimum and maximum lengths of 19 and 21 can also be included to detect\nunambiguous alignments with one mismatch or one gap, including those from reads\n1 nucleotide shorter or longer than expected (additional parameters\n`--acceptablescore 189 --acceptableminlength 19 --acceptablemaxlength 21`).\n\n### Performance\n\nThis script is implemented in Python but has been through basic optimisations to\nincrease performance. On a 3.8 Ghz Ryzen 9, this script produces detailed counts\nfor about 6M reads in about 80 seconds. No multi-threading is implemented, but\nif multiple input files are to be processed, processing of each file could be\nperformed in parallel.\n\n-------------------------------------------------------------------------------\n\nAuthor        |Tet Woo Lee\n--------------|----------------------------\nCreated       | 2020-03-12\nCopyright     | \u00a9 2020 Tet Woo Lee\nLicense       | GPLv3\nDependencies  | pysam, tested with v0.15.4\n\n\n### Change log\n\n+ version 1.0.dev6 2020-03-29  \n  Improved support for CRAM files\n    - added `--referencefile` option\n    - mentioned CRAM files in docs\n    - added unit tests for CRAM files\n\n\n+ version 1.0.dev5 2020-03-29  \n  Fixed bug preventing output file being written when called as module\n\n\n+ version 1.0.dev4 2020-03-28  \n  Minor improvements & additional checks/tests\n   - added different levels of verbosity\n   - warnings now produced using Python warnings module\n   - added warning for length of reference(s) not equal expected length\n   - unit tests for warnings: reference length issues, ignored alignments,\n     ambiguous perfect alignments\n   - unit test input file now has alternative alignment scores\n   - added processing additional flags: warning if paired reads detected,\n     ignore/report QC fail or duplicates, warning if reverse alignments\n     detected\n   - specifying `--acceptablescore` to be the same as `--perfectscore`, and\n     `--acceptableminlength` or `--acceptablemaxlength` to be the same as\n     `--expectedlength` produces same results as not using these parameters\n\n\n+ version 1.0.dev3 2020-03-26  \n  First production version  \n   - added unit tests  \n   - PyPi and conda packaging  \n   - add additional output options  \n\n\n+ version 1.0.dev2 2020-03-17  \n  Modifications to improve performance, total 5.5x speedup:\n    - 468 s to 350 s (6.4M reads) by switching from Flag to IntFlag\n    - 350 s to 134 s by modifying to use int rather than IntFlag in add_counts\n    - 134 s to 85 s by modifying to use int with flag addition or operations\n    - Further improvements possible, e.g. 70 s possible by Cythonizing as-is\n      but current performance should suffice.\n\n\n+ version 1.0.dev1 2020-03-15  \n  First working version\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://gitlab.com/twlee79/count_fgs_sam", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "count-fgs-sam", "package_url": "https://pypi.org/project/count-fgs-sam/", "platform": "", "project_url": "https://pypi.org/project/count-fgs-sam/", "project_urls": {"Homepage": "https://gitlab.com/twlee79/count_fgs_sam"}, "release_url": "https://pypi.org/project/count-fgs-sam/1.0.dev6/", "requires_dist": ["pysam (>=v0.15.4)"], "requires_python": "", "summary": "Count Functional Genomics Screen alignments in a SAM file with filtering options", "version": "1.0.dev6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>count_fgs_sam</h1>\n<h2>Count Functional Genomics Screen alignments in a SAM file with filtering options</h2>\n<p>This program will count the alignments in a SAM/BAM/CRAM file. The number of\nprimary alignments that are mapped to each reference sequence are counted. The\nalignments are filtered for various criteria before counting, and (optionally)\nadditional buckets of counts (for each reference) are produced.</p>\n<p>This script uses the <a href=\"https://github.com/pysam-developers/pysam\" rel=\"nofollow\">pysam</a> module. It is designed for alignments produced by\n<a href=\"http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml\" rel=\"nofollow\">Bowtie 2</a>, and relies on the AS and XS score tags.</p>\n<p>See below for Bowtie 2 parameters to produce compatible alignments.</p>\n<h3>Command-line parameters</h3>\n<pre><code>usage: count_fgs_sam [-h] [--version] [-r REFERENCEFILE] [-v]\n                     [-p PERFECTSCORE] [-l EXPECTEDLENGTH]\n                     [-a UNAMBIGUOUSDELTA] [-c ACCEPTABLESCORE]\n                     [-m ACCEPTABLEMINLENGTH] [-M ACCEPTABLEMAXLENGTH]\n                     [-o OUTPUTFILE] [--show-unacceptable] [--show-ambiguous]\n                     [--show-length] [-d]\n                     inputfile\n\npositional arguments:\n  inputfile             Input SAM/BAM/CRAM file, type determined by extension\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --version             show program's version number and exit\n  -r REFERENCEFILE, --referencefile REFERENCEFILE\n                        For CRAM inputfile, path to FASTA reference file; if\n                        used, a FASTA index REFERENCEFILE.fai is needed and\n                        automatically generated if one doesn't already exist\n                        (default: None)\n  -v, --verbose         Increase logging verbosity, available levels 1 to 3\n                        with `-v` to `-vvv` (default: 0)\n  -p PERFECTSCORE, --perfectscore PERFECTSCORE\n                        Cutoff for perfect alignments, must have alignment\n                        score (AS) of at least this (AS&gt;=cutoff) (default:\n                        200)\n  -l EXPECTEDLENGTH, --expectedlength EXPECTEDLENGTH\n                        Expected length of reads, reads filtered by this\n                        length (length==expectedlength) (default: 20)\n  -a UNAMBIGUOUSDELTA, --unambiguousdelta UNAMBIGUOUSDELTA\n                        Cutoff for unambiguous alignments, reads filtered for\n                        unambiguous alignments that have alignment score (AS)\n                        minus alternative score (XS) less than equal this (AS-\n                        XS&lt;=cutoff), XS assumed to be 0 if not present for an\n                        alignment (default: 3)\n  -c ACCEPTABLESCORE, --acceptablescore ACCEPTABLESCORE\n                        Cutoff for acceptable alignments AS&gt;=cutoff; if\n                        specified and different from --perfectscore, counts of\n                        acceptable reads are shown (default: None)\n  -m ACCEPTABLEMINLENGTH, --acceptableminlength ACCEPTABLEMINLENGTH\n                        Minimum length for acceptable alignments (length\n                        &gt;=minlength); if specified and different from\n                        --expectedlength, counts of shorter reads are reported\n                        (default: None)\n  -M ACCEPTABLEMAXLENGTH, --acceptablemaxlength ACCEPTABLEMAXLENGTH\n                        Maximum length for acceptable alignments (length\n                        &lt;=maxlength); if specified and different from\n                        --expectedlength, counts of longer reads are reported\n                        (default: None)\n\noptional output options:\n  Options to included additional count buckets in output\n\n  -o OUTPUTFILE, --outputfile OUTPUTFILE\n                        Output TSV file, output to stdout if absent (default:\n                        None)\n  --show-unacceptable   Show counts of ambiguous alignments (default: False)\n  --show-ambiguous      Show counts of unacceptable alignments (default:\n                        False)\n  --show-length         Show overall counts of reads by length classes, not\n                        filtered by any other criteria; counts outside\n                        specified lengths counted as 'length-out-of-range'\n                        (default: False)\n  -d, --detailed        Turn on all optional count buckets (--show* options\n                        enabled, as well as any buckets enabled with\n                        additional threshold parameters). Note that these\n                        optional count buckets may all be zero if\n                        corresponding parameters are not used. (default:\n                        False)\n</code></pre>\n<h3>Input file support</h3>\n<p>This script supports the input alignment formats supported by <a href=\"https://github.com/pysam-developers/pysam\" rel=\"nofollow\">pysam</a>, i.e. SAM,\nBAM and CRAM. If using a reference-based CRAM file, <a href=\"https://github.com/pysam-developers/pysam\" rel=\"nofollow\">pysam</a> will attempt to read\nthe reference file according to the UR field in the CRAM file header. This can\nbe overridden using the <code>--referencefile</code> parameter. An indexed FASTA file is\nexpected as the reference file, and if no index is available then one will be\nautomatically generated. Reference-less CRAM files are supported by this script\nand may be preferred (they are generally smaller than BAM files, and about the\nsame size as reference-based CRAM files). The input SAM/BAM/CRAM itself file\ndoes not need to be sorted or indexed prior to use in this script.</p>\n<h3>Detail on scoring parameters</h3>\n<p>The following are parameters for scoring the alignments:</p>\n<ul>\n<li>\n<p>Alignment score: The alignment score is read from the <code>AS</code> tag in the\nalignment entry in the SAM/BAM file.</p>\n</li>\n<li>\n<p>Read length: The read length is inferred from the CIGAR alignment, or\nif the read is unmapped, the read length is obtained from the sequence\nin the SAM/BAM file.</p>\n</li>\n<li>\n<p>Alternative alignment score: The alternative alignment score is read from\nthe <code>XS</code> tag in the alignment entry in the SAM/BAM file.</p>\n</li>\n<li>\n<p>Alignment score delta: This is calculated as the alignment score (<code>AS</code>)\nminus the alternative alignment score (<code>XS</code>) (i.e. <code>delta = AS-XS</code>). It\nrepresents how much better the primary alignment is from the next best\nalignment, i.e. a larger delta indicates the primary alignment is clearly\nbetter than any alternatives, while a small delta may indicate that the\n'best' alignment is ambiguous.</p>\n</li>\n</ul>\n<p>This script expects an input file consisting of unpaired reads aligned to the\nforward strand of the references and only primary alignments. Reads/alignments\nwith various SAM flags are processed as follows:</p>\n<ul>\n<li>\n<p>Only primary alignments are processed by this script. All secondary or\nsupplementary alignments (SAM flags <code>0x100</code> or <code>0x800</code>)  are ignored, with a\nwarning produced by the script.</p>\n</li>\n<li>\n<p>Any reads with the QC failed (<code>0x200</code>) or PCR/optical duplicate (<code>0x400</code>)\nflags are ignored. No warning is produced but counts of these are logged.</p>\n</li>\n<li>\n<p>A warning is produced if paired reads (<code>0x1</code>) or alignments to the reverse\nstrand (<code>0x10</code>) are detected, although any such alignments are processed\nnormally.</p>\n</li>\n</ul>\n<h3>Filtering criteria</h3>\n<p>Based on the scoring parameters, the following filtering criteria are applied\nprior to counting the alignments:</p>\n<ul>\n<li>\n<p>Perfect alignment score (<code>-p</code> or <code>--perfectscore</code>): Alignment score must be\nat least (&gt;=) this value for the alignment to be considered <code>perfect</code>. In\naddition, an alignment must be of <code>expected-length</code> (below) to be considered\n<code>perfect</code>. Therefore, any alignments with score &gt;= this value that are not\nof <code>expected-length</code> can be at best considered <code>acceptable</code> (below).  Any\nread/alignment that is not <code>perfect</code> or <code>acceptable</code> is considered\n<code>unacceptable</code>. This includes any unmapped reads. By default, only <code>perfect</code>\nalignments are counted and reported.</p>\n</li>\n<li>\n<p>Expected length (<code>l</code> or <code>--expectedlength</code>): The read length must be equal\n(==) to this length for an alignment resulting from the read to be\nconsidered as being of <code>expected-length</code>. An alignment must be of\n<code>expected-length</code> to be considered <code>perfect</code>, although an alignment that is\nnot of <code>expected-length</code> can still be considered to be <code>acceptable</code> if it\nmeets the <code>shorter</code> or <code>longer</code> criteria (below). Any alignment that is\noutside expected or acceptable lengths is considered <code>unacceptable</code>. By\ndefault, only alignments that are <code>perfect</code> and therefore of\n<code>expected-length</code> are counted and reported.</p>\n</li>\n<li>\n<p>Unambiguous delta (<code>-a</code> or <code>--unambiguousdelta</code>): The alignment score delta\nmust be greater (&gt;) than this value for the alignment to be considered\n<code>unambiguous</code>. Any alignment with a delta less than or equal (&lt;=) to this\nvalue is considered <code>ambiguous</code>. By default, only alignments that are\n<code>unambiguous</code> are counted and reported. Care should be used when choosing\nthis value based on the scoring scheme used. If set to too high, it is\npossible that all alignments to certain references may be considered\nambiguous and not counted.</p>\n<p>If any reads with perfect alignments scores are found to be ambiguous, a\nwarning will be displayed since these will always be excluded from the\ncounts. It is likely that this is a configuration error. This may occur\nif there are replicated sequences among the references (which should be\nconsolidated into a single reference sequence, and the reads realigned to\nthis new set of references), or the unambiguous delta is set too high.</p>\n</li>\n<li>\n<p>Acceptable alignment score (<code>-c</code> or <code>--acceptablescore</code>): Any non-<code>perfect</code>\nalignments may be considered <code>acceptable</code> if their scores are at least (&gt;=)\nthis value. By default, no <code>acceptable</code> are allowed. Providing an acceptable\nalignment score will enable counting and reporting of <code>acceptable</code>\nalignments, these still have to be of <code>expected-length</code> unless acceptable\nminimum or maximum lengths are also provided.</p>\n</li>\n<li>\n<p>Acceptable minimum length (<code>-m</code> or <code>--acceptableminlength</code>): An alignment\nfrom a read that is below (&lt;) the expected length but greater than or equal\n(&gt;=) the acceptable minimum length will be considered <code>shorter</code>. Providing\nan acceptable minimum length will enable counting and reporting of <code>shorter</code>\nalignments. Alignments that are <code>shorter</code> will be considered <code>acceptable</code> if\nthey meet the acceptable alignment score threshold. If no acceptable\nalignment score is provided, any <code>shorter</code> alignment that meets the perfect\nscore threshold will be considered <code>acceptable</code>, but in typical usage a\n<code>shorter</code> alignment could not have a perfect alignment score and this option\nshould be combined with an acceptable alignment score.</p>\n</li>\n<li>\n<p>Acceptable maximum length (<code>-M</code> or <code>--acceptablemaxlength</code>): An alignment\nfrom a read that is above (&gt;) the expected length but less than or equal\n(&lt;=) the acceptable maximum length will be considered <code>longer</code>. Providing an\nacceptable maximum length will enable counting and reporting of <code>longer</code>\nalignments. Alignments that are <code>longer</code> will be considered <code>acceptable</code> if\nthey meet the acceptable alignment score threshold. If no acceptable\nalignment score is provided, any <code>longer</code> alignment that meets the perfect\nscore threshold will be considered <code>acceptable</code>.</p>\n</li>\n</ul>\n<p>These filtering criteria determine which count buckets each read/alignment\ngoes into.</p>\n<h3>Count buckets</h3>\n<p>Various buckets of counts are produced for each reference sequence. Each\nreference sequence is a row in the output file, with the reference sequence name\n(<code>ref-name</code>) and length (<code>ref-length</code>) reported. The buckets in the output are\nthe columns (see further below for example output). In addition to the reference\nsequences, there are rows in the output file to count unmapped reads <em>if</em> they\nare included in the criteria for that count bucket (row has <code>ref-name</code> of\n<code>*unmapped</code>), the sum of all counted reads (including any counted unmapped\nreads; <code>**total_counted</code>), any excluded alignment/reads that don't meet the\nbucket criteria (<code>**excluded</code>), and the grand total of all reads\n(<code>***grand_total</code>). Note that for the <code>*unmapped</code> row, unmapped reads are\nautomatically considered unacceptable and therefore excluded for most buckets\n(i.e. only counted under <code>**excluded</code> rather than being counted under\n<code>*unmapped</code>), apart for <code>unacceptable</code> buckets. The buckets that can be produced\nare given below:</p>\n<ul>\n<li>\n<p><code>perfect/unambiguous/expected-length</code> (default)</p>\n</li>\n<li>\n<p><code>acceptable/unambiguous/expected-length</code> (enabled if an acceptable alignment\nscore is provided)</p>\n</li>\n<li>\n<p><code>acceptable/unambiguous/shorter</code> (enabled if an acceptable minimum length is\nprovided)</p>\n</li>\n<li>\n<p><code>acceptable/unambiguous/longer</code> (enabled if an acceptable maximum length is\nprovided)</p>\n</li>\n<li>\n<p><code>perfect/ambiguous/expected-length</code> (enabled with <code>--show-ambiguous</code>)</p>\n</li>\n<li>\n<p><code>acceptable/ambiguous/expected-length</code> (enabled with <code>--show-ambiguous</code> and\nif an acceptable alignment score is provided)</p>\n</li>\n<li>\n<p><code>acceptable/ambiguous/shorter</code> (enabled with <code>--show-ambiguous</code> and\nif an acceptable minimum length is provided)</p>\n</li>\n<li>\n<p><code>acceptable/ambiguous/longer</code> (enabled with <code>--show-ambiguous</code> and\nif an acceptable maximum length is provided)</p>\n</li>\n<li>\n<p><code>unacceptable/expected-length</code> (enabled with <code>--show-unacceptable</code>)</p>\n</li>\n<li>\n<p><code>unacceptable/shorter</code> (enabled with <code>--show-unacceptable</code> and\nif an acceptable minimum length is provided)</p>\n</li>\n<li>\n<p><code>unacceptable/longer</code> (enabled with <code>--show-unacceptable</code> and\nif an acceptable maximum length is provided)</p>\n</li>\n<li>\n<p><code>unacceptable/length-out-of-range</code> (enabled with <code>--show-unacceptable</code>)</p>\n</li>\n</ul>\n<p>All of the above buckets are mutually exclusive. A read cannot be in more than\none of the above buckets (excluding the total rows). This means, for example,\nthat downstream analyses should sum <code>perfect/unambiguous/expected-length</code> and\n<code>acceptable/unambiguous/expected-length</code> counts if both perfect and acceptable\ncounts are to be included. Buckets for ambiguous and unacceptable counts are\nprimarily meant to be used for diagnostic purposes.</p>\n<p>The following buckets for overall (total) counts can also be produced:</p>\n<ul>\n<li>\n<p><code>expected-length</code>: counts all reads that are of <code>expected-length</code>,\nregardless of score or delta criteria (enabled with <code>--show-length</code>)</p>\n</li>\n<li>\n<p><code>shorter</code>: counts all reads that are <code>shorter</code>, regardless of score or\ndelta criteria (enabled with <code>--show-length</code> and if an acceptable minimum\nlength is provided)</p>\n</li>\n<li>\n<p><code>longer</code>: counts all reads that are <code>longer</code>, regardless of score or\ndelta criteria (enabled with <code>--show-length</code> and if an acceptable maximum\nlength is provided)</p>\n</li>\n<li>\n<p><code>length-out-of-range</code>: counts all reads that are not in any of the above\nlength categories, including any shorter/longer reads where acceptable\nminimum or maximum lengths are not provided (enabled with <code>--show-length</code>)</p>\n</li>\n<li>\n<p><code>any</code>: counts all reads regardless of score, delta or length criteria\n(default)</p>\n</li>\n</ul>\n<p>By default, only <code>perfect/unambiguous/expected-length</code> and <code>any</code> counts are\nproduced.</p>\n<p>Example output (formatted with spaces for presentation, actual output is\ntab-separated):</p>\n<pre><code>ref-name                ref-length  perfect/unambiguous/expected-length  any\nNon-Targeting___76442   20          21                                   25\nNon-Targeting___76443   20          22                                   22\n...\n*unmapped               nan         0                                    4803\n**total_counted         nan         17078                                23015\n**excluded              nan         5937                                 0\n***grand_total          nan         23015                                23015\n\n\n</code></pre>\n<h3>Suggested Bowtie 2 parameters</h3>\n<p>The suggested parameters for Bowtie 2 are as follows:</p>\n<p><code>bowtie2 --ma=10 --mp=-4,-6 --np=-6 --rdg=0,1 --rfg=0,1 --score-min=C,150,0 --n-ceil=C,2,0 --local --norc --gbar 1 -D 20 -R 1 -N 0 -L 10 -i L,1,0</code></p>\n<p>This uses local alignment with bonus scoring for matches (match bonus\n<code>--ma=10</code>), (lower) bonus scoring for mismatches/Ns (mismatch penalty\n<code>--mp=-4,-6</code>, N penalty <code>--np=-6</code>; negative values turn this into a bonus) and\nsmall gap penalties (read and reference gap penalties <code>--rdg=0,1 --rfg=0,1</code>;\ngaps at ends of the read are not penalised during local alignment, but all gaps\nare also penalised by a lack of match/mismatch bonus, i.e -10 compared to a\nmatch).</p>\n<p>The minimum alignment score can be set leniently (<code>--score-min=C,150,0</code>) as this\nscript will do additional filtering of alignments prior to counting. The\nremaining options set a maximum of 2 Ns (<code>--n-ceil=C,2,0</code>) and the optimal\nparameters for producing to most mapped reads (determined mostly by trial and\nerror <code>--local --norc --gbar 1 -D 20 -R 1 -N 0 -L 10 -i L,1,0</code>).</p>\n<p>For reads with length of 20 bp, these options will produce a perfect alignment\nscore of 200, and alignment score of at least 194 with one mismatch, and a score\nof 189 to 190 with one gap (depending of whether it is internal or at ends). For\nreads of 19 bp, a maximum score of 189 to 190 is possible for alignments with no\nmismatches depending on the position of the gap. For reads of 21 bp, a maximum\nscore of 200 is possible even with the additional unmatched nucleotide at the\nread ends. Ambiguous alignments can be detected based on the alternative\nalignment score, an additional mismatch will reduce the score by at least 4 and\nan additional gap will reduce the score by at least 10. Changes in the position\nof the gap or an character of a mismatch will alter score by only 0, -1 or -2.</p>\n<p>With these Bowtie 2 parameters, a perfect alignment score of 200, expected\nlength of 20 and an unambiguous delta of 3 will count perfect, unambiguous\nalignments of the expected length (default parameters of <code>--perfectscore 200 --expectedlength 20 --unambiguousdelta 3</code>). An acceptable alignment score of 194\ncan be used to count alignments with one mismatch (additional parameter\n<code>--acceptablescore 194</code>). An acceptable alignment score of 189, and acceptable\nminimum and maximum lengths of 19 and 21 can also be included to detect\nunambiguous alignments with one mismatch or one gap, including those from reads\n1 nucleotide shorter or longer than expected (additional parameters\n<code>--acceptablescore 189 --acceptableminlength 19 --acceptablemaxlength 21</code>).</p>\n<h3>Performance</h3>\n<p>This script is implemented in Python but has been through basic optimisations to\nincrease performance. On a 3.8 Ghz Ryzen 9, this script produces detailed counts\nfor about 6M reads in about 80 seconds. No multi-threading is implemented, but\nif multiple input files are to be processed, processing of each file could be\nperformed in parallel.</p>\n<hr>\n<table>\n<thead>\n<tr>\n<th>Author</th>\n<th>Tet Woo Lee</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Created</td>\n<td>2020-03-12</td>\n</tr>\n<tr>\n<td>Copyright</td>\n<td>\u00a9 2020 Tet Woo Lee</td>\n</tr>\n<tr>\n<td>License</td>\n<td>GPLv3</td>\n</tr>\n<tr>\n<td>Dependencies</td>\n<td>pysam, tested with v0.15.4</td>\n</tr></tbody></table>\n<h3>Change log</h3>\n<ul>\n<li>\n<p>version 1.0.dev6 2020-03-29<br>\nImproved support for CRAM files</p>\n<ul>\n<li>added <code>--referencefile</code> option</li>\n<li>mentioned CRAM files in docs</li>\n<li>added unit tests for CRAM files</li>\n</ul>\n</li>\n<li>\n<p>version 1.0.dev5 2020-03-29<br>\nFixed bug preventing output file being written when called as module</p>\n</li>\n<li>\n<p>version 1.0.dev4 2020-03-28<br>\nMinor improvements &amp; additional checks/tests</p>\n<ul>\n<li>added different levels of verbosity</li>\n<li>warnings now produced using Python warnings module</li>\n<li>added warning for length of reference(s) not equal expected length</li>\n<li>unit tests for warnings: reference length issues, ignored alignments,\nambiguous perfect alignments</li>\n<li>unit test input file now has alternative alignment scores</li>\n<li>added processing additional flags: warning if paired reads detected,\nignore/report QC fail or duplicates, warning if reverse alignments\ndetected</li>\n<li>specifying <code>--acceptablescore</code> to be the same as <code>--perfectscore</code>, and\n<code>--acceptableminlength</code> or <code>--acceptablemaxlength</code> to be the same as\n<code>--expectedlength</code> produces same results as not using these parameters</li>\n</ul>\n</li>\n<li>\n<p>version 1.0.dev3 2020-03-26<br>\nFirst production version</p>\n<ul>\n<li>added unit tests</li>\n<li>PyPi and conda packaging</li>\n<li>add additional output options</li>\n</ul>\n</li>\n<li>\n<p>version 1.0.dev2 2020-03-17<br>\nModifications to improve performance, total 5.5x speedup:</p>\n<ul>\n<li>468 s to 350 s (6.4M reads) by switching from Flag to IntFlag</li>\n<li>350 s to 134 s by modifying to use int rather than IntFlag in add_counts</li>\n<li>134 s to 85 s by modifying to use int with flag addition or operations</li>\n<li>Further improvements possible, e.g. 70 s possible by Cythonizing as-is\nbut current performance should suffice.</li>\n</ul>\n</li>\n<li>\n<p>version 1.0.dev1 2020-03-15<br>\nFirst working version</p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 6905169, "releases": {"1.0.dev3": [{"comment_text": "", "digests": {"md5": "82488279d53ba92eb59ca0cb7155540f", "sha256": "5bcdf4a6d0c57bb07157709912c2b09ebd6863cdd8c03bed51a702f274920c7b"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev3-py3-none-any.whl", "has_sig": false, "md5_digest": "82488279d53ba92eb59ca0cb7155540f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 597017, "upload_time": "2020-03-26T23:37:35", "upload_time_iso_8601": "2020-03-26T23:37:35.883109Z", "url": "https://files.pythonhosted.org/packages/ad/9b/fcd7f6adceee552d3a2e59b14191846c7d4583276afd7d3329d903ea8cf4/count_fgs_sam-1.0.dev3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0242603253b6780703a1f2584b83a8f1", "sha256": "380b0146fbffc5fc517c5f426ff4d9b82a332f0c066e470ea7543c118cfce4a6"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev3.tar.gz", "has_sig": false, "md5_digest": "0242603253b6780703a1f2584b83a8f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 576443, "upload_time": "2020-03-26T23:37:39", "upload_time_iso_8601": "2020-03-26T23:37:39.654133Z", "url": "https://files.pythonhosted.org/packages/e0/9c/16fa1588db1299752d0bdfcb969bf30144018b6244b9c3117ae1e48ab88b/count_fgs_sam-1.0.dev3.tar.gz", "yanked": false}], "1.0.dev4": [{"comment_text": "", "digests": {"md5": "dec28523c2675ad5da71f19a3c4c3903", "sha256": "e372297cdb91f503c50c0d1e091776e7989fdbbd1181f7f0309ed15e3d153c14"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev4-py3-none-any.whl", "has_sig": false, "md5_digest": "dec28523c2675ad5da71f19a3c4c3903", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3011137, "upload_time": "2020-03-28T10:03:40", "upload_time_iso_8601": "2020-03-28T10:03:40.339509Z", "url": "https://files.pythonhosted.org/packages/20/42/ae8bc5b34a0c1061e4a3249bf8e47213489d9012eb0f4a95ef5270ac48eb/count_fgs_sam-1.0.dev4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b968e807918eb579e38c159f3befacb1", "sha256": "6087b33d03f988bf62967411c16b06c2518169ab4f76e3bd4f4d9ce99516cd72"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev4.tar.gz", "has_sig": false, "md5_digest": "b968e807918eb579e38c159f3befacb1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3007068, "upload_time": "2020-03-28T10:03:58", "upload_time_iso_8601": "2020-03-28T10:03:58.336251Z", "url": "https://files.pythonhosted.org/packages/84/f8/635eb86a616e20ed109994dcfa3b16c12aa0a41e224ef8524cf9639cfcf5/count_fgs_sam-1.0.dev4.tar.gz", "yanked": false}], "1.0.dev5": [{"comment_text": "", "digests": {"md5": "f7e43085fa456b7b0d9d6cf143dd04b7", "sha256": "712e40342bfd73331362e48805601b21adf1c5f46b6355758818fdd1ae143725"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev5-py3-none-any.whl", "has_sig": false, "md5_digest": "f7e43085fa456b7b0d9d6cf143dd04b7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3011567, "upload_time": "2020-03-28T12:18:55", "upload_time_iso_8601": "2020-03-28T12:18:55.880457Z", "url": "https://files.pythonhosted.org/packages/8c/be/e23c6ecb2e0b121ccc5b57b6f5945b43d23b02bdb1b7338ef649f4cacc7b/count_fgs_sam-1.0.dev5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4bb3bf6073824c12234c641b52a2b41a", "sha256": "e48c2515b610f2f5dcaa63707f2e3bb124f1642630652920ee13b3633485c429"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev5.tar.gz", "has_sig": false, "md5_digest": "4bb3bf6073824c12234c641b52a2b41a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3007198, "upload_time": "2020-03-28T12:19:10", "upload_time_iso_8601": "2020-03-28T12:19:10.020730Z", "url": "https://files.pythonhosted.org/packages/d2/06/eefb047b9259a8f89a7236bba2b2955d2aac49b5aa2a3269638287c45d87/count_fgs_sam-1.0.dev5.tar.gz", "yanked": false}], "1.0.dev6": [{"comment_text": "", "digests": {"md5": "b18a992750a70516e04ca937dc88f54d", "sha256": "f7b2b97ce2ca948035a9ed6b878484bd0fcf305d48997ba665f3c7c2b47db964"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev6-py3-none-any.whl", "has_sig": false, "md5_digest": "b18a992750a70516e04ca937dc88f54d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3747100, "upload_time": "2020-03-29T06:02:05", "upload_time_iso_8601": "2020-03-29T06:02:05.346257Z", "url": "https://files.pythonhosted.org/packages/19/3a/f5ba9d6b57765247607f7a300afdc3e9bb417d0657104595a361b55252a0/count_fgs_sam-1.0.dev6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a5472e0d34938eb162a071d0068e8912", "sha256": "7db8972d873ba767b00520ae3a9feb8dbd958d784551695bd28f3c5a4c36c91e"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev6.tar.gz", "has_sig": false, "md5_digest": "a5472e0d34938eb162a071d0068e8912", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3745446, "upload_time": "2020-03-29T06:02:18", "upload_time_iso_8601": "2020-03-29T06:02:18.927620Z", "url": "https://files.pythonhosted.org/packages/d6/2e/9a6a3051522bf2666dab53d1cc556c5ad4b535f525a57331ec830d814dda/count_fgs_sam-1.0.dev6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b18a992750a70516e04ca937dc88f54d", "sha256": "f7b2b97ce2ca948035a9ed6b878484bd0fcf305d48997ba665f3c7c2b47db964"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev6-py3-none-any.whl", "has_sig": false, "md5_digest": "b18a992750a70516e04ca937dc88f54d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3747100, "upload_time": "2020-03-29T06:02:05", "upload_time_iso_8601": "2020-03-29T06:02:05.346257Z", "url": "https://files.pythonhosted.org/packages/19/3a/f5ba9d6b57765247607f7a300afdc3e9bb417d0657104595a361b55252a0/count_fgs_sam-1.0.dev6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a5472e0d34938eb162a071d0068e8912", "sha256": "7db8972d873ba767b00520ae3a9feb8dbd958d784551695bd28f3c5a4c36c91e"}, "downloads": -1, "filename": "count_fgs_sam-1.0.dev6.tar.gz", "has_sig": false, "md5_digest": "a5472e0d34938eb162a071d0068e8912", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3745446, "upload_time": "2020-03-29T06:02:18", "upload_time_iso_8601": "2020-03-29T06:02:18.927620Z", "url": "https://files.pythonhosted.org/packages/d6/2e/9a6a3051522bf2666dab53d1cc556c5ad4b535f525a57331ec830d814dda/count_fgs_sam-1.0.dev6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:53 2020"}