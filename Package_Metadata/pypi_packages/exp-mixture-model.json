{"info": {"author": "Makoto Okada, Kenji Yamanishi and Naoki Masuda", "author_email": "naoki.masuda@bristol.ac.uk", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development"], "description": "# exp_mixture_model\nMaximum likelihood estimation and model selection for the exponential mixture model (i.e., mixture of exponential distributions)\n\nWhen you use this code, please cite the following paper:\n\nMakoto Okada, Kenji Yamanishi, Naoki Masuda.\nLong-tailed distributions of inter-event times as mixtures of exponential distributions.\narXiv:19xx.xxxxx\n\n\n\n\n## Installation\n``exp_mixture_model`` is hosted on PyPI. So, one can install it by running\n```python\npip install exp_mixture_model\n```\nIf you want to install from source, clone the exp_mixture_model git repository by running\n```python\ngit clone https://github.com/naokimas/exp_mixture_model.git\n```\n\nThen, navigate to the top-level of the cloned directory and run\n```python\npython setup.py install\n```\n\nYou can test our code by running\n```python\npython setup.py test\n```\n\nIf you use Anaconda, you may install required packages by running\n```python\nconda install --file requirements.txt\n```\n\n## Quick Use\nFit an EMM to data stored in a file (e.g. sample.dat) by running\n```python\npython emmfit.py -f sample.dat -k 10\n```\n- '10' is the initial number of components. \n- 'sample.dat' is provided as part of this package. It is synthetic data that we generated by running\n```python\nfrom emm import generate_emm\nx = generate_emm(1000, 10)\n```\n\nTo select the best model among EMMs with different numbers of components, don't specify 'k' and instead specify the model selection criterion using '-c' as follows.\n```python\npython emmfit.py -f sample.dat -c DNML\n```\n- One can specify either 'marginal_log_likelihood', 'joint_log_likelihood', 'AIC', 'BIC', 'AIC_LVC', 'BIC_LVC', 'NML_LVC', or 'DNML' as the argument of '-c'.\n- Default is 'DNML'. \n\nCheck details of the usage by running\n```python\npython emmfit.py --help\n```\n\n## Usage\nFit an EMM to data by running\n```python\nfrom exp_mixture_model import EMM\nx = [1.5, 2.3, ...]  # data can be either a list or numpy array\n#\n# Alternatively, one can load data from a file using numpy as follows.\n#\n# import numpy as np\n# x = np.loadtxt(\"sample.dat\")\n#\nmodel = EMM()\npi, mu = model.fit(x)  # estimate the parameters\nmodel.print_result()  # print 'k_final' (i.e., the estimated effective number of components) and the estimated parameters\nmodel.plot_survival_probability()  # plot the survival probability (= cumulative complementary distribution function) for the estimated EMM and the given data 'x'.\n```\n\nSelect the number of components based on a model selection criterion by running\n```python\nfrom exp_mixture_model import EMMs\nx = [1.5, 2.3, ...]\nemms = EMMs()\nemms.fit(x)  # fit EMMs with different values of 'k', i.e., the number of components. The default uses 13 values of 'k'. This process is computationally heavy.\nbest_model = emms.select('DNML')  # select the best number of components under the 'DNML' criterion. One can specify either 'marginal_log_likelihood', 'joint_log_likelihood', 'AIC', 'BIC', 'AIC_LVC', 'BIC_LVC', 'NML_LVC', or 'DNML' as the argument of 'emms.select'.\nemms.print_result_table()  # print the values of 'k_final', likelihoods, and 'DNML' for each 'k' value\nbest_model.print_result() # print 'k_final' and the estimated parameter values of the selected EMM\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/naokimas/exp_mixture_model", "keywords": "exponential mixture model,model selection,normalized maximum likelihood", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "exp-mixture-model", "package_url": "https://pypi.org/project/exp-mixture-model/", "platform": "", "project_url": "https://pypi.org/project/exp-mixture-model/", "project_urls": {"Homepage": "https://github.com/naokimas/exp_mixture_model"}, "release_url": "https://pypi.org/project/exp-mixture-model/1.0.0/", "requires_dist": ["numpy", "scipy", "pandas", "matplotlib"], "requires_python": "", "summary": "Maximum likelihood estimation and model selection of EMMs", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>exp_mixture_model</h1>\n<p>Maximum likelihood estimation and model selection for the exponential mixture model (i.e., mixture of exponential distributions)</p>\n<p>When you use this code, please cite the following paper:</p>\n<p>Makoto Okada, Kenji Yamanishi, Naoki Masuda.\nLong-tailed distributions of inter-event times as mixtures of exponential distributions.\narXiv:19xx.xxxxx</p>\n<h2>Installation</h2>\n<p><code>exp_mixture_model</code> is hosted on PyPI. So, one can install it by running</p>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">exp_mixture_model</span>\n</pre>\n<p>If you want to install from source, clone the exp_mixture_model git repository by running</p>\n<pre><span class=\"n\">git</span> <span class=\"n\">clone</span> <span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">github</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">naokimas</span><span class=\"o\">/</span><span class=\"n\">exp_mixture_model</span><span class=\"o\">.</span><span class=\"n\">git</span>\n</pre>\n<p>Then, navigate to the top-level of the cloned directory and run</p>\n<pre><span class=\"n\">python</span> <span class=\"n\">setup</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"n\">install</span>\n</pre>\n<p>You can test our code by running</p>\n<pre><span class=\"n\">python</span> <span class=\"n\">setup</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"n\">test</span>\n</pre>\n<p>If you use Anaconda, you may install required packages by running</p>\n<pre><span class=\"n\">conda</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">file</span> <span class=\"n\">requirements</span><span class=\"o\">.</span><span class=\"n\">txt</span>\n</pre>\n<h2>Quick Use</h2>\n<p>Fit an EMM to data stored in a file (e.g. sample.dat) by running</p>\n<pre><span class=\"n\">python</span> <span class=\"n\">emmfit</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"o\">-</span><span class=\"n\">f</span> <span class=\"n\">sample</span><span class=\"o\">.</span><span class=\"n\">dat</span> <span class=\"o\">-</span><span class=\"n\">k</span> <span class=\"mi\">10</span>\n</pre>\n<ul>\n<li>'10' is the initial number of components.</li>\n<li>'sample.dat' is provided as part of this package. It is synthetic data that we generated by running</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">emm</span> <span class=\"kn\">import</span> <span class=\"n\">generate_emm</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">generate_emm</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<p>To select the best model among EMMs with different numbers of components, don't specify 'k' and instead specify the model selection criterion using '-c' as follows.</p>\n<pre><span class=\"n\">python</span> <span class=\"n\">emmfit</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"o\">-</span><span class=\"n\">f</span> <span class=\"n\">sample</span><span class=\"o\">.</span><span class=\"n\">dat</span> <span class=\"o\">-</span><span class=\"n\">c</span> <span class=\"n\">DNML</span>\n</pre>\n<ul>\n<li>One can specify either 'marginal_log_likelihood', 'joint_log_likelihood', 'AIC', 'BIC', 'AIC_LVC', 'BIC_LVC', 'NML_LVC', or 'DNML' as the argument of '-c'.</li>\n<li>Default is 'DNML'.</li>\n</ul>\n<p>Check details of the usage by running</p>\n<pre><span class=\"n\">python</span> <span class=\"n\">emmfit</span><span class=\"o\">.</span><span class=\"n\">py</span> <span class=\"o\">--</span><span class=\"n\">help</span>\n</pre>\n<h2>Usage</h2>\n<p>Fit an EMM to data by running</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">exp_mixture_model</span> <span class=\"kn\">import</span> <span class=\"n\">EMM</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">1.5</span><span class=\"p\">,</span> <span class=\"mf\">2.3</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">]</span>  <span class=\"c1\"># data can be either a list or numpy array</span>\n<span class=\"c1\">#</span>\n<span class=\"c1\"># Alternatively, one can load data from a file using numpy as follows.</span>\n<span class=\"c1\">#</span>\n<span class=\"c1\"># import numpy as np</span>\n<span class=\"c1\"># x = np.loadtxt(\"sample.dat\")</span>\n<span class=\"c1\">#</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">EMM</span><span class=\"p\">()</span>\n<span class=\"n\">pi</span><span class=\"p\">,</span> <span class=\"n\">mu</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># estimate the parameters</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">print_result</span><span class=\"p\">()</span>  <span class=\"c1\"># print 'k_final' (i.e., the estimated effective number of components) and the estimated parameters</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">plot_survival_probability</span><span class=\"p\">()</span>  <span class=\"c1\"># plot the survival probability (= cumulative complementary distribution function) for the estimated EMM and the given data 'x'.</span>\n</pre>\n<p>Select the number of components based on a model selection criterion by running</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">exp_mixture_model</span> <span class=\"kn\">import</span> <span class=\"n\">EMMs</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">1.5</span><span class=\"p\">,</span> <span class=\"mf\">2.3</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">]</span>\n<span class=\"n\">emms</span> <span class=\"o\">=</span> <span class=\"n\">EMMs</span><span class=\"p\">()</span>\n<span class=\"n\">emms</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># fit EMMs with different values of 'k', i.e., the number of components. The default uses 13 values of 'k'. This process is computationally heavy.</span>\n<span class=\"n\">best_model</span> <span class=\"o\">=</span> <span class=\"n\">emms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s1\">'DNML'</span><span class=\"p\">)</span>  <span class=\"c1\"># select the best number of components under the 'DNML' criterion. One can specify either 'marginal_log_likelihood', 'joint_log_likelihood', 'AIC', 'BIC', 'AIC_LVC', 'BIC_LVC', 'NML_LVC', or 'DNML' as the argument of 'emms.select'.</span>\n<span class=\"n\">emms</span><span class=\"o\">.</span><span class=\"n\">print_result_table</span><span class=\"p\">()</span>  <span class=\"c1\"># print the values of 'k_final', likelihoods, and 'DNML' for each 'k' value</span>\n<span class=\"n\">best_model</span><span class=\"o\">.</span><span class=\"n\">print_result</span><span class=\"p\">()</span> <span class=\"c1\"># print 'k_final' and the estimated parameter values of the selected EMM</span>\n</pre>\n\n          </div>"}, "last_serial": 4950418, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "459aa4e09e386940ac9cd064eea49035", "sha256": "304745fbe04a64158b0756c5879f673bb95f4c80ce22c71d5eefdbbac4cec1b5"}, "downloads": -1, "filename": "exp_mixture_model-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "459aa4e09e386940ac9cd064eea49035", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11245, "upload_time": "2019-03-17T14:42:19", "upload_time_iso_8601": "2019-03-17T14:42:19.457300Z", "url": "https://files.pythonhosted.org/packages/47/1c/6c1245beb4fae5b7ccb08f26099962e24537922ec3b430c6251ea86e12ce/exp_mixture_model-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c52161904b68b38531b49b839ac7fd6", "sha256": "2d43d96c70abe36be44e6c40d77f36459a79d9539bf02282c552c563b052f5f2"}, "downloads": -1, "filename": "exp_mixture_model-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7c52161904b68b38531b49b839ac7fd6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11135, "upload_time": "2019-03-17T14:42:21", "upload_time_iso_8601": "2019-03-17T14:42:21.779151Z", "url": "https://files.pythonhosted.org/packages/21/84/521daba1ccd2b357580b4bb5c730de54ee72780d3f61b9d854b01e4348f0/exp_mixture_model-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "459aa4e09e386940ac9cd064eea49035", "sha256": "304745fbe04a64158b0756c5879f673bb95f4c80ce22c71d5eefdbbac4cec1b5"}, "downloads": -1, "filename": "exp_mixture_model-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "459aa4e09e386940ac9cd064eea49035", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11245, "upload_time": "2019-03-17T14:42:19", "upload_time_iso_8601": "2019-03-17T14:42:19.457300Z", "url": "https://files.pythonhosted.org/packages/47/1c/6c1245beb4fae5b7ccb08f26099962e24537922ec3b430c6251ea86e12ce/exp_mixture_model-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c52161904b68b38531b49b839ac7fd6", "sha256": "2d43d96c70abe36be44e6c40d77f36459a79d9539bf02282c552c563b052f5f2"}, "downloads": -1, "filename": "exp_mixture_model-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7c52161904b68b38531b49b839ac7fd6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11135, "upload_time": "2019-03-17T14:42:21", "upload_time_iso_8601": "2019-03-17T14:42:21.779151Z", "url": "https://files.pythonhosted.org/packages/21/84/521daba1ccd2b357580b4bb5c730de54ee72780d3f61b9d854b01e4348f0/exp_mixture_model-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:37 2020"}