{"info": {"author": "Chang-Hung Liang", "author_email": "eliang.cs@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Financial and Insurance Industry", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Topic :: Internet :: WWW/HTTP", "Topic :: Office/Business :: Financial :: Investment", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "pystock-crawler\n===============\n\n.. image:: https://badge.fury.io/py/pystock-crawler.png\n    :target: http://badge.fury.io/py/pystock-crawler\n\n.. image:: https://travis-ci.org/eliangcs/pystock-crawler.png?branch=master\n    :target: https://travis-ci.org/eliangcs/pystock-crawler\n\n.. image:: https://coveralls.io/repos/eliangcs/pystock-crawler/badge.png?branch=master\n    :target: https://coveralls.io/r/eliangcs/pystock-crawler\n\n``pystock-crawler`` is a utility for crawling historical data of US stocks,\nincluding:\n\n* Ticker symbols listed in NYSE, NASDAQ or AMEX from `NASDAQ.com`_\n* Daily prices from `Yahoo Finance`_\n* Fundamentals from 10-Q and 10-K filings (XBRL) on `SEC EDGAR`_\n\n\nExample Output\n--------------\n\nNYSE ticker symbols::\n\n    DDD   3D Systems Corporation\n    MMM   3M Company\n    WBAI  500.com Limited\n    ...\n\nApple's daily prices::\n\n    symbol,date,open,high,low,close,volume,adj_close\n    AAPL,2014-04-28,572.80,595.75,572.55,594.09,23890900,594.09\n    AAPL,2014-04-25,564.53,571.99,563.96,571.94,13922800,571.94\n    AAPL,2014-04-24,568.21,570.00,560.73,567.77,27092600,567.77\n    ...\n\nGoogle's fundamentals::\n\n    symbol,end_date,amend,period_focus,fiscal_year,doc_type,revenues,op_income,net_income,eps_basic,eps_diluted,dividend,assets,cur_assets,cur_liab,cash,equity,cash_flow_op,cash_flow_inv,cash_flow_fin\n    GOOG,2009-06-30,False,Q2,2009,10-Q,5522897000.0,1873894000.0,1484545000.0,4.7,4.66,0.0,35158760000.0,23834853000.0,2000962000.0,11911351000.0,31594856000.0,3858684000.0,-635974000.0,46354000.0\n    GOOG,2009-09-30,False,Q3,2009,10-Q,5944851000.0,2073718000.0,1638975000.0,5.18,5.13,0.0,37702845000.0,26353544000.0,2321774000.0,12087115000.0,33721753000.0,6584667000.0,-3245963000.0,74851000.0\n    GOOG,2009-12-31,False,FY,2009,10-K,23650563000.0,8312186000.0,6520448000.0,20.62,20.41,0.0,40496778000.0,29166958000.0,2747467000.0,10197588000.0,36004224000.0,9316198000.0,-8019205000.0,233412000.0\n    ...\n\n\nInstallation\n------------\n\nPrerequisites:\n\n* Python 2.7\n\n``pystock-crawler`` is based on Scrapy_, so you will also need to install\nprerequisites such as lxml_ and libffi_ for Scrapy and its dependencies. On\nUbuntu, for example, you can install them like this::\n\n    sudo apt-get update\n    sudo apt-get install -y gcc python-dev libffi-dev libssl-dev libxml2-dev libxslt1-dev build-essential\n\nSee `Scrapy's installation guide`_ for more details.\n\nAfter installing prerequisites, you can then install ``pystock-crawler`` with\n``pip``::\n\n    (sudo) pip install pystock-crawler\n\n\nQuickstart\n----------\n\n**Example 1.** Fetch Google's and Yahoo's daily prices ordered by date::\n\n    pystock-crawler prices GOOG,YHOO -o out.csv --sort\n\n**Example 2.** Fetch daily prices of all companies listed in\n``./symbols.txt``::\n\n    pystock-crawler prices ./symbols.txt -o out.csv\n\n**Example 3.** Fetch Facebook's fundamentals during 2013::\n\n    pystock-crawler reports FB -o out.csv -s 20130101 -e 20131231\n\n**Example 4.** Fetch fundamentals of all companies in ``./nyse.txt`` and direct\nthe log to ``./crawling.log``::\n\n    pystock-crawler reports ./nyse.txt -o out.csv -l ./crawling.log\n\n**Example 5.** Fetch all ticker symbols in NYSE, NASDAQ and AMEX::\n\n    pystock-crawler symbols NYSE,NASDAQ,AMEX -o out.txt\n\n\nUsage\n-----\n\nType ``pystock-crawler -h`` to see command help::\n\n    Usage:\n      pystock-crawler symbols <exchanges> (-o OUTPUT) [-l LOGFILE] [-w WORKING_DIR]\n                                          [--sort]\n      pystock-crawler prices <symbols> (-o OUTPUT) [-s YYYYMMDD] [-e YYYYMMDD]\n                                       [-l LOGFILE] [-w WORKING_DIR] [--sort]\n      pystock-crawler reports <symbols> (-o OUTPUT) [-s YYYYMMDD] [-e YYYYMMDD]\n                                        [-l LOGFILE] [-w WORKING_DIR]\n                                        [-b BATCH_SIZE] [--sort]\n      pystock-crawler (-h | --help)\n      pystock-crawler (-v | --version)\n\n    Options:\n      -h --help       Show this screen\n      -o OUTPUT       Output file\n      -s YYYYMMDD     Start date [default: ]\n      -e YYYYMMDD     End date [default: ]\n      -l LOGFILE      Log output [default: ]\n      -w WORKING_DIR  Working directory [default: .]\n      -b BATCH_SIZE   Batch size [default: 500]\n      --sort          Sort the result\n\nThere are three commands available:\n\n* ``pystock-crawler symbols`` grabs ticker symbol lists\n* ``pystock-crawler prices`` grabs daily prices\n* ``pystock-crawler reports`` grabs fundamentals\n\n``<exchanges>`` is a comma-separated string that specifies the stock exchanges\nyou want to include. Current, NYSE, NASDAQ and AMEX are supported.\n\nThe output file of ``pystock-crawler symbols`` can be used for ``<symbols>``\nargument in ``pystock-crawler prices`` and ``pystock-crawler reports``\ncommands.\n\n``<symbols>`` can be an inline string separated with commas or a text file\nthat lists symbols line by line. For example, the inline string can be\nsomething like ``AAPL,GOOG,FB``. And the text file may look like this::\n\n    # This line is comment\n    AAPL    Put anything you want here\n    GOOG    Since the text here is ignored\n    FB\n\nUse ``-o`` to specify the output file. For ``pystock-crawler symbols``\ncommand, the output format is a simple text file. For\n``pystock-crawler prices`` and ``pystock-crawler reports`` the output format\nis CSV.\n\n``-l`` is where the crawling logs go to. If not specified, the logs go to\nstdout.\n\nBy default, the crawler uses the current directory as the working directory.\nIf you don't want to use the current directoy, you can specify it with ``-w``\noption. The crawler keeps HTTP cache in a directory named ``.scrapy`` under\nthe working directory. The cache can save your time by avoid downloading the\nsame web pages. However, the cache can be quite huge. If you don't need it,\njust delete the ``.scrapy`` directory after you've done crawling.\n\n``-b`` option is only available to ``pystock-crawler reports`` command. It\nallows you to split a large symbol list into smaller batches. This is actually\na workaround for an unresolved bug (#2). Normally you don't have to specify\nthis option. Default value (500) works just fine.\n\nThe rows in the output file are in an arbitrary order by default. Use\n``--sort`` option to sort them by symbols and dates. But if you have a large\noutput file, don't use --sort because it will be slow and eat a lot of memory.\n\n\nDeveloper Guide\n---------------\n\nInstalling Dependencies\n~~~~~~~~~~~~~~~~~~~~~~~\n::\n\n    pip install -r requirements.txt\n\n\nRunning Test\n~~~~~~~~~~~~\n\nInstall test requirements::\n\n    pip install -r requirements-test.txt\n\nThen run the test::\n\n    py.test\n\nThis will download the test data (a lot of XML/XBRL files) from from\n`SEC EDGAR`_ on the fly, so it will take some time and disk space. The test\ndata is saved to ``pystock_crawler/tests/sample_data`` directory. It can be\nreused on the next time you run the test. If you don't need them, just delete\nthe ``sample_data`` directory.\n\n\n.. _libffi: https://sourceware.org/libffi/\n.. _lxml: http://lxml.de/\n.. _NASDAQ.com: http://www.nasdaq.com/\n.. _Scrapy: http://scrapy.org/\n.. _Scrapy's installation guide: http://doc.scrapy.org/en/latest/intro/install.html\n.. _SEC EDGAR: http://www.sec.gov/edgar/searchedgar/companysearch.html\n.. _virtualenv: http://www.virtualenv.org/\n.. _virtualenvwrapper: http://virtualenvwrapper.readthedocs.org/\n.. _Yahoo Finance: http://finance.yahoo.com/", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/eliangcs/pystock-crawler", "keywords": null, "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "pystock-crawler", "package_url": "https://pypi.org/project/pystock-crawler/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/pystock-crawler/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/eliangcs/pystock-crawler"}, "release_url": "https://pypi.org/project/pystock-crawler/0.8.2/", "requires_dist": null, "requires_python": null, "summary": "Crawl and parse stock historical data", "version": "0.8.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"http://badge.fury.io/py/pystock-crawler\" rel=\"nofollow\"><img alt=\"https://badge.fury.io/py/pystock-crawler.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6d932271fa83e3eaff80676f36a7fa0c522ef273/68747470733a2f2f62616467652e667572792e696f2f70792f707973746f636b2d637261776c65722e706e67\"></a>\n<a href=\"https://travis-ci.org/eliangcs/pystock-crawler\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/eliangcs/pystock-crawler.png?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/82e9d170922e2185c6f53157f0a5492b744d1e07/68747470733a2f2f7472617669732d63692e6f72672f656c69616e6763732f707973746f636b2d637261776c65722e706e673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://coveralls.io/r/eliangcs/pystock-crawler\" rel=\"nofollow\"><img alt=\"https://coveralls.io/repos/eliangcs/pystock-crawler/badge.png?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/78bc42ca6f0f8ea7dd1ee0b4e489f837f721a116/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f656c69616e6763732f707973746f636b2d637261776c65722f62616467652e706e673f6272616e63683d6d6173746572\"></a>\n<p><tt><span class=\"pre\">pystock-crawler</span></tt> is a utility for crawling historical data of US stocks,\nincluding:</p>\n<ul>\n<li>Ticker symbols listed in NYSE, NASDAQ or AMEX from <a href=\"http://www.nasdaq.com/\" rel=\"nofollow\">NASDAQ.com</a></li>\n<li>Daily prices from <a href=\"http://finance.yahoo.com/\" rel=\"nofollow\">Yahoo Finance</a></li>\n<li>Fundamentals from 10-Q and 10-K filings (XBRL) on <a href=\"http://www.sec.gov/edgar/searchedgar/companysearch.html\" rel=\"nofollow\">SEC EDGAR</a></li>\n</ul>\n<div id=\"example-output\">\n<h2>Example Output</h2>\n<p>NYSE ticker symbols:</p>\n<pre>DDD   3D Systems Corporation\nMMM   3M Company\nWBAI  500.com Limited\n...\n</pre>\n<p>Apple\u2019s daily prices:</p>\n<pre>symbol,date,open,high,low,close,volume,adj_close\nAAPL,2014-04-28,572.80,595.75,572.55,594.09,23890900,594.09\nAAPL,2014-04-25,564.53,571.99,563.96,571.94,13922800,571.94\nAAPL,2014-04-24,568.21,570.00,560.73,567.77,27092600,567.77\n...\n</pre>\n<p>Google\u2019s fundamentals:</p>\n<pre>symbol,end_date,amend,period_focus,fiscal_year,doc_type,revenues,op_income,net_income,eps_basic,eps_diluted,dividend,assets,cur_assets,cur_liab,cash,equity,cash_flow_op,cash_flow_inv,cash_flow_fin\nGOOG,2009-06-30,False,Q2,2009,10-Q,5522897000.0,1873894000.0,1484545000.0,4.7,4.66,0.0,35158760000.0,23834853000.0,2000962000.0,11911351000.0,31594856000.0,3858684000.0,-635974000.0,46354000.0\nGOOG,2009-09-30,False,Q3,2009,10-Q,5944851000.0,2073718000.0,1638975000.0,5.18,5.13,0.0,37702845000.0,26353544000.0,2321774000.0,12087115000.0,33721753000.0,6584667000.0,-3245963000.0,74851000.0\nGOOG,2009-12-31,False,FY,2009,10-K,23650563000.0,8312186000.0,6520448000.0,20.62,20.41,0.0,40496778000.0,29166958000.0,2747467000.0,10197588000.0,36004224000.0,9316198000.0,-8019205000.0,233412000.0\n...\n</pre>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Prerequisites:</p>\n<ul>\n<li>Python 2.7</li>\n</ul>\n<p><tt><span class=\"pre\">pystock-crawler</span></tt> is based on <a href=\"http://scrapy.org/\" rel=\"nofollow\">Scrapy</a>, so you will also need to install\nprerequisites such as <a href=\"http://lxml.de/\" rel=\"nofollow\">lxml</a> and <a href=\"https://sourceware.org/libffi/\" rel=\"nofollow\">libffi</a> for Scrapy and its dependencies. On\nUbuntu, for example, you can install them like this:</p>\n<pre>sudo apt-get update\nsudo apt-get install -y gcc python-dev libffi-dev libssl-dev libxml2-dev libxslt1-dev build-essential\n</pre>\n<p>See <a href=\"http://doc.scrapy.org/en/latest/intro/install.html\" rel=\"nofollow\">Scrapy\u2019s installation guide</a> for more details.</p>\n<p>After installing prerequisites, you can then install <tt><span class=\"pre\">pystock-crawler</span></tt> with\n<tt>pip</tt>:</p>\n<pre>(sudo) pip install pystock-crawler\n</pre>\n</div>\n<div id=\"quickstart\">\n<h2>Quickstart</h2>\n<p><strong>Example 1.</strong> Fetch Google\u2019s and Yahoo\u2019s daily prices ordered by date:</p>\n<pre>pystock-crawler prices GOOG,YHOO -o out.csv --sort\n</pre>\n<p><strong>Example 2.</strong> Fetch daily prices of all companies listed in\n<tt>./symbols.txt</tt>:</p>\n<pre>pystock-crawler prices ./symbols.txt -o out.csv\n</pre>\n<p><strong>Example 3.</strong> Fetch Facebook\u2019s fundamentals during 2013:</p>\n<pre>pystock-crawler reports FB -o out.csv -s 20130101 -e 20131231\n</pre>\n<p><strong>Example 4.</strong> Fetch fundamentals of all companies in <tt>./nyse.txt</tt> and direct\nthe log to <tt>./crawling.log</tt>:</p>\n<pre>pystock-crawler reports ./nyse.txt -o out.csv -l ./crawling.log\n</pre>\n<p><strong>Example 5.</strong> Fetch all ticker symbols in NYSE, NASDAQ and AMEX:</p>\n<pre>pystock-crawler symbols NYSE,NASDAQ,AMEX -o out.txt\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Type <tt><span class=\"pre\">pystock-crawler</span> <span class=\"pre\">-h</span></tt> to see command help:</p>\n<pre>Usage:\n  pystock-crawler symbols &lt;exchanges&gt; (-o OUTPUT) [-l LOGFILE] [-w WORKING_DIR]\n                                      [--sort]\n  pystock-crawler prices &lt;symbols&gt; (-o OUTPUT) [-s YYYYMMDD] [-e YYYYMMDD]\n                                   [-l LOGFILE] [-w WORKING_DIR] [--sort]\n  pystock-crawler reports &lt;symbols&gt; (-o OUTPUT) [-s YYYYMMDD] [-e YYYYMMDD]\n                                    [-l LOGFILE] [-w WORKING_DIR]\n                                    [-b BATCH_SIZE] [--sort]\n  pystock-crawler (-h | --help)\n  pystock-crawler (-v | --version)\n\nOptions:\n  -h --help       Show this screen\n  -o OUTPUT       Output file\n  -s YYYYMMDD     Start date [default: ]\n  -e YYYYMMDD     End date [default: ]\n  -l LOGFILE      Log output [default: ]\n  -w WORKING_DIR  Working directory [default: .]\n  -b BATCH_SIZE   Batch size [default: 500]\n  --sort          Sort the result\n</pre>\n<p>There are three commands available:</p>\n<ul>\n<li><tt><span class=\"pre\">pystock-crawler</span> symbols</tt> grabs ticker symbol lists</li>\n<li><tt><span class=\"pre\">pystock-crawler</span> prices</tt> grabs daily prices</li>\n<li><tt><span class=\"pre\">pystock-crawler</span> reports</tt> grabs fundamentals</li>\n</ul>\n<p><tt>&lt;exchanges&gt;</tt> is a comma-separated string that specifies the stock exchanges\nyou want to include. Current, NYSE, NASDAQ and AMEX are supported.</p>\n<p>The output file of <tt><span class=\"pre\">pystock-crawler</span> symbols</tt> can be used for <tt>&lt;symbols&gt;</tt>\nargument in <tt><span class=\"pre\">pystock-crawler</span> prices</tt> and <tt><span class=\"pre\">pystock-crawler</span> reports</tt>\ncommands.</p>\n<p><tt>&lt;symbols&gt;</tt> can be an inline string separated with commas or a text file\nthat lists symbols line by line. For example, the inline string can be\nsomething like <tt>AAPL,GOOG,FB</tt>. And the text file may look like this:</p>\n<pre># This line is comment\nAAPL    Put anything you want here\nGOOG    Since the text here is ignored\nFB\n</pre>\n<p>Use <tt><span class=\"pre\">-o</span></tt> to specify the output file. For <tt><span class=\"pre\">pystock-crawler</span> symbols</tt>\ncommand, the output format is a simple text file. For\n<tt><span class=\"pre\">pystock-crawler</span> prices</tt> and <tt><span class=\"pre\">pystock-crawler</span> reports</tt> the output format\nis CSV.</p>\n<p><tt><span class=\"pre\">-l</span></tt> is where the crawling logs go to. If not specified, the logs go to\nstdout.</p>\n<p>By default, the crawler uses the current directory as the working directory.\nIf you don\u2019t want to use the current directoy, you can specify it with <tt><span class=\"pre\">-w</span></tt>\noption. The crawler keeps HTTP cache in a directory named <tt>.scrapy</tt> under\nthe working directory. The cache can save your time by avoid downloading the\nsame web pages. However, the cache can be quite huge. If you don\u2019t need it,\njust delete the <tt>.scrapy</tt> directory after you\u2019ve done crawling.</p>\n<p><tt><span class=\"pre\">-b</span></tt> option is only available to <tt><span class=\"pre\">pystock-crawler</span> reports</tt> command. It\nallows you to split a large symbol list into smaller batches. This is actually\na workaround for an unresolved bug (#2). Normally you don\u2019t have to specify\nthis option. Default value (500) works just fine.</p>\n<p>The rows in the output file are in an arbitrary order by default. Use\n<tt><span class=\"pre\">--sort</span></tt> option to sort them by symbols and dates. But if you have a large\noutput file, don\u2019t use \u2013sort because it will be slow and eat a lot of memory.</p>\n</div>\n<div id=\"developer-guide\">\n<h2>Developer Guide</h2>\n<div id=\"installing-dependencies\">\n<h3>Installing Dependencies</h3>\n<pre>pip install -r requirements.txt\n</pre>\n</div>\n<div id=\"running-test\">\n<h3>Running Test</h3>\n<p>Install test requirements:</p>\n<pre>pip install -r requirements-test.txt\n</pre>\n<p>Then run the test:</p>\n<pre>py.test\n</pre>\n<p>This will download the test data (a lot of XML/XBRL files) from from\n<a href=\"http://www.sec.gov/edgar/searchedgar/companysearch.html\" rel=\"nofollow\">SEC EDGAR</a> on the fly, so it will take some time and disk space. The test\ndata is saved to <tt>pystock_crawler/tests/sample_data</tt> directory. It can be\nreused on the next time you run the test. If you don\u2019t need them, just delete\nthe <tt>sample_data</tt> directory.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 1275502, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "2bfde0cfba309e2e42f341cf4d540bf9", "sha256": "313e9d37248d51810e00ad4c489c538b38548c8e95c9b4eda61c756c52a0fb94"}, "downloads": -1, "filename": "pystock-crawler-0.2.0.tar.gz", "has_sig": false, "md5_digest": "2bfde0cfba309e2e42f341cf4d540bf9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13949, "upload_time": "2014-03-15T18:13:30", "upload_time_iso_8601": "2014-03-15T18:13:30.930870Z", "url": "https://files.pythonhosted.org/packages/e2/f0/faadb6f7a72407184fd7deb9442106cb1023df170166e363954223a3f3ef/pystock-crawler-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "0a6a0a8b0794f874b7b839f056bff25a", "sha256": "24a5dd84c8f9a03aa77a43c1835a4752812453a94ebc5d9a6a97d0013ce118af"}, "downloads": -1, "filename": "pystock-crawler-0.3.0.tar.gz", "has_sig": false, "md5_digest": "0a6a0a8b0794f874b7b839f056bff25a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15354, "upload_time": "2014-03-18T15:30:24", "upload_time_iso_8601": "2014-03-18T15:30:24.318353Z", "url": "https://files.pythonhosted.org/packages/87/b0/3bfdc31a627754f93ecd7689a75847d64c95f42428d5197fa9df15749088/pystock-crawler-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "5a55c30bab2374e2bf89baf1f9a0ef7f", "sha256": "c93a9d319f6abdb6f33fb8940b871c7234ee597f6d319e89866deb4c2590ea5a"}, "downloads": -1, "filename": "pystock-crawler-0.3.1.tar.gz", "has_sig": false, "md5_digest": "5a55c30bab2374e2bf89baf1f9a0ef7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15368, "upload_time": "2014-03-18T16:31:58", "upload_time_iso_8601": "2014-03-18T16:31:58.480398Z", "url": "https://files.pythonhosted.org/packages/98/68/9581ec83b740f74b1a41adf18b0e9d8103809497698559e720eff731bd60/pystock-crawler-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "13dfc58690a77b3966032ef005a4abcd", "sha256": "361f5c7359f711c6873b6a73516e11a1202e84e9db3c895b3e59c46f9240a3b9"}, "downloads": -1, "filename": "pystock-crawler-0.3.2.tar.gz", "has_sig": false, "md5_digest": "13dfc58690a77b3966032ef005a4abcd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15388, "upload_time": "2014-03-25T12:48:52", "upload_time_iso_8601": "2014-03-25T12:48:52.274473Z", "url": "https://files.pythonhosted.org/packages/66/d4/34725c4476996d17a9a7f5e88f6491bb22945e5ee5df2b256fc63e63548f/pystock-crawler-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "95ac77acdd2b32f4c4743cd8acef4c12", "sha256": "7c9e355088da3fa58f4b3eaeb78d45dfcbaa740cfb380a97c03f841a6ddf3a03"}, "downloads": -1, "filename": "pystock-crawler-0.3.3.tar.gz", "has_sig": false, "md5_digest": "95ac77acdd2b32f4c4743cd8acef4c12", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15775, "upload_time": "2014-03-26T14:16:36", "upload_time_iso_8601": "2014-03-26T14:16:36.256407Z", "url": "https://files.pythonhosted.org/packages/7c/a6/e8b838d2115d095dd8c9744b565a2584daa071d7baf455095cb0616574a8/pystock-crawler-0.3.3.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "9abd6d6c58347846270f1e6452f0d8e1", "sha256": "24c0d1fdc30193a299992ecdccda19e5f1f934aad10439864cea960e362b77d2"}, "downloads": -1, "filename": "pystock-crawler-0.4.0.tar.gz", "has_sig": false, "md5_digest": "9abd6d6c58347846270f1e6452f0d8e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16924, "upload_time": "2014-04-29T16:38:52", "upload_time_iso_8601": "2014-04-29T16:38:52.927283Z", "url": "https://files.pythonhosted.org/packages/cf/38/fc0b02adb1b564b51adcfaa28f7f79a7d14fdc28400d328c15be6d3c7439/pystock-crawler-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "4147b832e449465cb7c40c02b0693169", "sha256": "37e4f911de419775acbde3ead494a9e7f7f5f7b0c030cb296752320f046249b5"}, "downloads": -1, "filename": "pystock-crawler-0.5.0.tar.gz", "has_sig": false, "md5_digest": "4147b832e449465cb7c40c02b0693169", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18125, "upload_time": "2014-05-12T13:27:55", "upload_time_iso_8601": "2014-05-12T13:27:55.631865Z", "url": "https://files.pythonhosted.org/packages/c2/75/8e4fe8c7492aebba7fc97a0b30a8cea556183996252d1f4dab44988f4833/pystock-crawler-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "403714baea758dd9560cfc1d11ac1ef6", "sha256": "8c6846bf0deb95289c9196a33b69b2af35c5f66f1280e6ac196d6bfdc2499018"}, "downloads": -1, "filename": "pystock_crawler-0.6.0-py2-none-any.whl", "has_sig": false, "md5_digest": "403714baea758dd9560cfc1d11ac1ef6", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 22224, "upload_time": "2014-06-28T17:52:33", "upload_time_iso_8601": "2014-06-28T17:52:33.414962Z", "url": "https://files.pythonhosted.org/packages/dd/d1/ad63eff36b24b9f7d7a40590529e641cc13160497da52a566dd4f974402c/pystock_crawler-0.6.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "62eb773e82e4c578162a520561de8bb0", "sha256": "c8380f0673e10875a49f22d40651a1b5d11fa6d9114b01735e5fd7e5728e82f1"}, "downloads": -1, "filename": "pystock-crawler-0.6.0.tar.gz", "has_sig": false, "md5_digest": "62eb773e82e4c578162a520561de8bb0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19419, "upload_time": "2014-06-28T17:52:29", "upload_time_iso_8601": "2014-06-28T17:52:29.616555Z", "url": "https://files.pythonhosted.org/packages/f1/64/1ebeb8ecd07322dc8b2d08ed222691c7de99fe0f43507e07f594ca11d48c/pystock-crawler-0.6.0.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "54037ac0219896f67e4b813ae223accc", "sha256": "36c072f2f837b4901059ebab313311e465f7aa6d6b818646d27b57205f4f07ec"}, "downloads": -1, "filename": "pystock_crawler-0.7.0-py2-none-any.whl", "has_sig": false, "md5_digest": "54037ac0219896f67e4b813ae223accc", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 22831, "upload_time": "2014-08-05T23:05:41", "upload_time_iso_8601": "2014-08-05T23:05:41.868164Z", "url": "https://files.pythonhosted.org/packages/01/ab/e674e2fb0a5bcd98fec2f747b918ffe3b3363de58d699c191930e92112f8/pystock_crawler-0.7.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2cfb3029913965197f2a2b8c8c3a4770", "sha256": "73b7fb16b21ba532d16e041294115daca66f2ddc1a40039586b3f5b0a4a35250"}, "downloads": -1, "filename": "pystock-crawler-0.7.0.tar.gz", "has_sig": false, "md5_digest": "2cfb3029913965197f2a2b8c8c3a4770", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20017, "upload_time": "2014-08-05T23:05:38", "upload_time_iso_8601": "2014-08-05T23:05:38.011230Z", "url": "https://files.pythonhosted.org/packages/70/0c/0afcb19f8c8b87c06ae43a420f5e5a46a66ececa4172f0cbde8e3c5580ae/pystock-crawler-0.7.0.tar.gz", "yanked": false}], "0.7.1": [{"comment_text": "", "digests": {"md5": "0259159264fd09ebb21999783c26eb2e", "sha256": "4a06cd77e29b0ceb9d2c86fe2722e5923c0e37ad289b1569f7f8b428655c711f"}, "downloads": -1, "filename": "pystock_crawler-0.7.1-py2-none-any.whl", "has_sig": false, "md5_digest": "0259159264fd09ebb21999783c26eb2e", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 22849, "upload_time": "2014-08-10T14:22:58", "upload_time_iso_8601": "2014-08-10T14:22:58.004224Z", "url": "https://files.pythonhosted.org/packages/a2/5f/cd5a5307f7935be99f296afdf304ab9e515624b8945244149be46bcc28ae/pystock_crawler-0.7.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a321ecfd35f94749ea9f44642153b19d", "sha256": "5c79b2556fe78e9093e62ba0647442dd86a30e06373b1d9005406a2afcde7763"}, "downloads": -1, "filename": "pystock-crawler-0.7.1.tar.gz", "has_sig": false, "md5_digest": "a321ecfd35f94749ea9f44642153b19d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20013, "upload_time": "2014-08-10T14:22:54", "upload_time_iso_8601": "2014-08-10T14:22:54.997250Z", "url": "https://files.pythonhosted.org/packages/a7/9b/6a881f7c0c84348093a57318eb99ba53a431c3f7f200386d076e7b4d295c/pystock-crawler-0.7.1.tar.gz", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "510b3619d603093cacb54e1d26a42ae0", "sha256": "53310cc881f61ff062e81ddf16aea97abcc8ceb3f2cfb81dae1990a09e2c503b"}, "downloads": -1, "filename": "pystock_crawler-0.7.2-py2-none-any.whl", "has_sig": false, "md5_digest": "510b3619d603093cacb54e1d26a42ae0", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 22851, "upload_time": "2014-08-19T14:10:04", "upload_time_iso_8601": "2014-08-19T14:10:04.239762Z", "url": "https://files.pythonhosted.org/packages/05/a5/f762f7c846186dad8aa2a1929956a9e5d1665926f3acaba9d4b69024f70b/pystock_crawler-0.7.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e5d61140eca3800dbcb36b73641d4ea0", "sha256": "51077b5c242e1c63847b96dad55bdf126877bad89348d96591d3b6c9046799f6"}, "downloads": -1, "filename": "pystock-crawler-0.7.2.tar.gz", "has_sig": false, "md5_digest": "e5d61140eca3800dbcb36b73641d4ea0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20025, "upload_time": "2014-08-19T14:10:00", "upload_time_iso_8601": "2014-08-19T14:10:00.473052Z", "url": "https://files.pythonhosted.org/packages/73/3d/7301955638e4c64b96d70590f99e387cd9b8dbeed00a4f1f2f356e573cad/pystock-crawler-0.7.2.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "8834157e895348efc23092ad6b167b4b", "sha256": "3b52146b115ec1cd7b807932fb1544d51976f2404f0d37559dcb9ce1ad21f6ec"}, "downloads": -1, "filename": "pystock_crawler-0.8.0-py2-none-any.whl", "has_sig": false, "md5_digest": "8834157e895348efc23092ad6b167b4b", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 24250, "upload_time": "2014-10-06T15:13:36", "upload_time_iso_8601": "2014-10-06T15:13:36.743065Z", "url": "https://files.pythonhosted.org/packages/43/05/1e97d23f32b8aa43158132761e37d57535191294c8ac075ed3ebc9017fb5/pystock_crawler-0.8.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0eb6059cd6a6a17456139e3124dd83c0", "sha256": "ac2a2badb24d82d1b7c7cf9ccf5c4ab12a7fc0bbd6549de8fc45a273022436db"}, "downloads": -1, "filename": "pystock-crawler-0.8.0.tar.gz", "has_sig": false, "md5_digest": "0eb6059cd6a6a17456139e3124dd83c0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21418, "upload_time": "2014-10-06T15:13:34", "upload_time_iso_8601": "2014-10-06T15:13:34.159426Z", "url": "https://files.pythonhosted.org/packages/9a/13/b2f098758e6c840f319ad3f7454005147de42f6c03c20f743f5ee653ba68/pystock-crawler-0.8.0.tar.gz", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "280590c0d3803b08e53385c36b18f26d", "sha256": "e569b8c260812e216453599926d69fb574085ce47d527d9da0de0789f0f22e5b"}, "downloads": -1, "filename": "pystock_crawler-0.8.1-py2-none-any.whl", "has_sig": false, "md5_digest": "280590c0d3803b08e53385c36b18f26d", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 24274, "upload_time": "2014-10-13T14:28:11", "upload_time_iso_8601": "2014-10-13T14:28:11.281102Z", "url": "https://files.pythonhosted.org/packages/a2/57/fa0595706771a7cecf4e5a188186555dfceec35c32f59f5abd1541580ea9/pystock_crawler-0.8.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d91f17c9c2c578beeddf1abe2a52c39e", "sha256": "7e7cf390241d6fa3e10825f5aa21405e89d5f8465c1df233f801171ee782d61c"}, "downloads": -1, "filename": "pystock-crawler-0.8.1.tar.gz", "has_sig": false, "md5_digest": "d91f17c9c2c578beeddf1abe2a52c39e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21442, "upload_time": "2014-10-13T14:28:07", "upload_time_iso_8601": "2014-10-13T14:28:07.273017Z", "url": "https://files.pythonhosted.org/packages/19/9a/ea381c6e99963fcba276cd7555ae4ad2ae83dd48c57b37e58eedb2bded63/pystock-crawler-0.8.1.tar.gz", "yanked": false}], "0.8.2": [{"comment_text": "", "digests": {"md5": "efefd670323bc63cc54e7923401db8b4", "sha256": "7692419d04665b033a011dc001d555f98270e21c10877a7f5152d85a5385f1dd"}, "downloads": -1, "filename": "pystock_crawler-0.8.2-py2-none-any.whl", "has_sig": false, "md5_digest": "efefd670323bc63cc54e7923401db8b4", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 24311, "upload_time": "2014-10-19T08:11:56", "upload_time_iso_8601": "2014-10-19T08:11:56.610841Z", "url": "https://files.pythonhosted.org/packages/9a/75/e96af5ce37ee9f6c35c76547b0ce5e3f99c0922433151e279d63dd64fe54/pystock_crawler-0.8.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c9b7739b3be1b6347a3ad42178b5984c", "sha256": "b4b4c504225d0b23f0964d6d4a9c5ea744994e19f01463ea00d9240942f8b4fc"}, "downloads": -1, "filename": "pystock-crawler-0.8.2.tar.gz", "has_sig": false, "md5_digest": "c9b7739b3be1b6347a3ad42178b5984c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21491, "upload_time": "2014-10-19T08:11:53", "upload_time_iso_8601": "2014-10-19T08:11:53.008041Z", "url": "https://files.pythonhosted.org/packages/a3/27/e36bd9d8e12894e44940dafbf7c4e0e67c7e60db48fa0fba5bdbecc75c3b/pystock-crawler-0.8.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "efefd670323bc63cc54e7923401db8b4", "sha256": "7692419d04665b033a011dc001d555f98270e21c10877a7f5152d85a5385f1dd"}, "downloads": -1, "filename": "pystock_crawler-0.8.2-py2-none-any.whl", "has_sig": false, "md5_digest": "efefd670323bc63cc54e7923401db8b4", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 24311, "upload_time": "2014-10-19T08:11:56", "upload_time_iso_8601": "2014-10-19T08:11:56.610841Z", "url": "https://files.pythonhosted.org/packages/9a/75/e96af5ce37ee9f6c35c76547b0ce5e3f99c0922433151e279d63dd64fe54/pystock_crawler-0.8.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c9b7739b3be1b6347a3ad42178b5984c", "sha256": "b4b4c504225d0b23f0964d6d4a9c5ea744994e19f01463ea00d9240942f8b4fc"}, "downloads": -1, "filename": "pystock-crawler-0.8.2.tar.gz", "has_sig": false, "md5_digest": "c9b7739b3be1b6347a3ad42178b5984c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21491, "upload_time": "2014-10-19T08:11:53", "upload_time_iso_8601": "2014-10-19T08:11:53.008041Z", "url": "https://files.pythonhosted.org/packages/a3/27/e36bd9d8e12894e44940dafbf7c4e0e67c7e60db48fa0fba5bdbecc75c3b/pystock-crawler-0.8.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:56 2020"}