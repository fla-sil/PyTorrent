{"info": {"author": "Arm Treasure Data", "author_email": "dev+pypi@treasure-data.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Getting Started: td-pyspark\n\n[Treasure Data](https://treasuredata.com) extension for using [pyspark](https://spark.apache.org/docs/latest/api/python/index.html).\n\n## Installation\n\nYou can install from PyPI by using `pip` as follows:\n\n```sh\n$ pip install td-pyspark\n```\n\nIf you want to install PySpark via PyPI, you can install as:\n\n```sh\n$ pip install td-pyspark[spark]\n```\n\n## Introduction\n\nFirst contact [support@treasure-data.com](mailto:support@treasure-data.com) to enable td-spark feature. This feature is disabled by default.\n\ntd-pyspark is a library to enable Python to access tables in Treasure Data.\nThe features of td_pyspark include:\n\n- Reading tables in Treasure Data as DataFrame\n- Writing DataFrames to Treasure Data\n- Submitting Presto queries and read the query results as DataFrames\n\nAs of June 2019, Spark 2.4.x + Scala 2.11 is supported. Spark 2.4.5 is preferred.\n\nFor more details, see also [td-spark FAQ](https://support.treasuredata.com/hc/en-us/articles/360001487167-Apache-Spark-Driver-td-spark-FAQs).\n\n### Quick Start with Docker\n\nYou can try td_pyspark using Docker without installing Spark nor Python.\n\nFirst create __td-spark.conf__ file and set your TD API KEY and site (us, jp, eu01, ap02) configurations:\n\n__td-spark.conf__\n```\nspark.td.apikey (Your TD API KEY)\nspark.td.site (Your site: us, jp, eu01, ap02)\nspark.serializer org.apache.spark.serializer.KryoSerializer\nspark.sql.execution.arrow.enabled true\n```\n\nLaunch pyspark Docker image. This image already has a pre-installed td_pyspark library:\n\n```shell\n$ docker run -it -e TD_SPARK_CONF=td-spark.conf -v $(pwd):/opt/spark/work armtd/td-spark-pyspark:latest_spark2.4.5\nPython 3.6.9 (default, Oct 17 2019, 11:10:22) \n[GCC 8.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n20/04/10 07:43:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n      /_/\n\nUsing Python version 3.6.9 (default, Oct 17 2019 11:10:22)\nSparkSession available as 'spark'.\n2020-04-10 07:44:03.181Z debug [spark] Loading com.treasuredata.spark package - (package.scala:23)\n2020-04-10 07:44:03.251Z  info [spark] td-spark version:20.4.0, revision:f6bdc8e, build_time:2020-04-10T07:03:29.264+0000 - (package.scala:24)\n2020-04-10 07:44:05.217Z  info [TDServiceConfig] td-spark site: us - (TDServiceConfig.scala:36)\n>>>\n```\n\nTry read a sample table by specifying a time range:\n\n```python\n>>> df = td.table(\"sample_datasets.www_access\").within(\"+2d/2014-10-04\").df()\n>>> df.show()\n2019-06-13 19:48:51.605Z  info [TDRelation] Fetching the partition list of sample_datasets.www_access within time range:[2014-10-04 00:00:00Z,2014-10-06 00:00:00Z) - (TDRelation.scala:170)\n2019-06-13 19:48:51.950Z  info [TDRelation] Retrieved 2 partition entries - (TDRelation.scala:176)\n+----+---------------+--------------------+--------------------+----+--------------------+----+------+----------+\n|user|           host|                path|             referer|code|               agent|size|method|      time|\n+----+---------------+--------------------+--------------------+----+--------------------+----+------+----------+\n|null|192.225.229.196|  /category/software|                   -| 200|Mozilla/5.0 (Maci...| 117|   GET|1412382292|\n|null|120.168.215.131|  /category/software|                   -| 200|Mozilla/5.0 (comp...|  53|   GET|1412382284|\n|null|180.198.173.136|/category/electro...| /category/computers| 200|Mozilla/5.0 (Wind...| 106|   GET|1412382275|\n|null| 140.168.145.49|   /item/garden/2832|      /item/toys/230| 200|Mozilla/5.0 (Maci...| 122|   GET|1412382267|\n|null|  52.168.78.222|/category/electro...|    /item/games/2532| 200|Mozilla/5.0 (comp...|  73|   GET|1412382259|\n|null|  32.42.160.165|   /category/cameras|/category/cameras...| 200|Mozilla/5.0 (Wind...| 117|   GET|1412382251|\n|null|   48.204.59.23|  /category/software|/search/?c=Electr...| 200|Mozilla/5.0 (Maci...|  52|   GET|1412382243|\n|null|136.207.150.227|/category/electro...|                   -| 200|Mozilla/5.0 (iPad...| 120|   GET|1412382234|\n|null| 204.21.174.187|   /category/jewelry|   /item/office/3462| 200|Mozilla/5.0 (Wind...|  59|   GET|1412382226|\n|null|  224.198.88.93|    /category/office|     /category/music| 200|Mozilla/4.0 (comp...|  46|   GET|1412382218|\n|null|   96.54.24.116|     /category/games|                   -| 200|Mozilla/5.0 (Wind...|  40|   GET|1412382210|\n|null| 184.42.224.210| /category/computers|                   -| 200|Mozilla/5.0 (Wind...|  95|   GET|1412382201|\n|null|  144.72.47.212|/item/giftcards/4684|    /item/books/1031| 200|Mozilla/5.0 (Wind...|  65|   GET|1412382193|\n|null| 40.213.111.170|     /item/toys/1085|   /category/cameras| 200|Mozilla/5.0 (Wind...|  65|   GET|1412382185|\n|null| 132.54.226.209|/item/electronics...|  /category/software| 200|Mozilla/5.0 (comp...| 121|   GET|1412382177|\n|null|  108.219.68.64|/category/cameras...|                   -| 200|Mozilla/5.0 (Maci...|  54|   GET|1412382168|\n|null| 168.66.149.218| /item/software/4343|  /category/software| 200|Mozilla/4.0 (comp...| 139|   GET|1412382160|\n|null|  80.66.118.103|  /category/software|                   -| 200|Mozilla/4.0 (comp...|  92|   GET|1412382152|\n|null|140.171.147.207|     /category/music|   /category/jewelry| 200|Mozilla/5.0 (Wind...| 119|   GET|1412382144|\n|null| 84.132.164.204| /item/software/4783|/category/electro...| 200|Mozilla/5.0 (Wind...| 137|   GET|1412382135|\n+----+---------------+--------------------+--------------------+----+--------------------+----+------+----------+\nonly showing top 20 rows\n>>>\n```\n\n\n## Usage\n\n_TDSparkContext_ is an entry point to access td_pyspark's functionalities. To create TDSparkContext, pass your SparkSession (spark) to TDSparkContext:\n\n```python\ntd = TDSparkContext(spark)\n```\n\n### Reading Tables as DataFrames\n\nTo read a table, use `td.table(table name)`:\n\n```python\ndf = td.table(\"sample_datasets.www_access\").df()\ndf.show()\n```\n\nTo change the context database, use `td.use(database_name)`:\n\n```python\ntd.use(\"sample_datasets\")\n# Accesses sample_datasets.www_access\ndf = td.table(\"www_access\").df()\n```\n\nBy calling `.df()` your table data will be read as Spark's DataFrame.\nThe usage of the DataFrame is the same with PySpark. See also [PySpark DataFrame documentation](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame).\n\n#### Specifying Time Ranges\n\nTreasure Data is a time series database, so reading recent data by specifying a time range is important to reduce the amount of data to be processed.\n`.within(...)` function can be used to specify a target time range in a concise syntax. \n`within` function accepts the same syntax used in [TD_INTERVAL function in Presto](https://support.treasuredata.com/hc/en-us/articles/360001450828-Supported-Presto-and-TD-Functions#TD_INTERVAL).\n\nFor example, to read the last 1 hour range of data, use `within(\"-1h\")`:\n\n```python\ntd.table(\"tbl\").within(\"-1h\").df()\n```\n\nYou can also read the last day's data:\n\n```python\ntd.table(\"tbl\").within(\"-1d\").df()\n```\n\nYou can also specify an _offset_ of the relative time range. This example reads the last days's data beginning from 7 days ago:\n\n```python\ntd.table(\"tbl\").within(\"-1d/-7d\").df()\n```\n\nIf you know an exact time range, `within(\"(start time)/(end time)\")` is useful:\n\n```python\n>>> df = td.table(\"sample_datasets.www_access\").within(\"2014-10-04/2014-10-05\").df()\n>>> df.show()\n2019-06-13 20:12:01.400Z  info [TDRelation] Fetching the partition list of sample_datasets.www_access within time range:[2014-10-04 00:00:00Z,2014-10-05 00:00:00Z) - (TDRelation.scala:170)\n...\n```\n\nSee [this doc](https://support.treasuredata.com/hc/en-us/articles/360001450828-Supported-Presto-and-TD-Functions#TD_INTERVAL) for more examples of interval strings. \n\n\n#### Submitting Presto Queries\n\nIf your Spark cluster is small, reading all of the data as in-memory DataFrame might be difficult.\nIn this case, you can utilize Presto, a distributed SQL query engine, to reduce the amount of data processing with PySpark:\n\n```python\n>>> q = td.presto(\"select code, * from sample_datasets.www_access\")\n>>> q.show()\n2019-06-13 20:09:13.245Z  info [TDPrestoJDBCRDD]  - (TDPrestoRelation.scala:106)\nSubmit Presto query:\nselect code, count(*) cnt from sample_datasets.www_access group by 1\n+----+----+\n|code| cnt|\n+----+----+\n| 200|4981|\n| 500|   2|\n| 404|  17|\n+----+----+\n```\n\nThe query result is represented as a DataFrame.\n\nTo run non query statements (e.g., INSERT INTO, CREATE TABLE, etc.) use `execute_presto(sql)`:\n\n```python\ntd.execute_presto(\"CREATE TABLE IF NOT EXISTS A(time bigint, id varchar)\")\n```\n\n#### Using SparkSQL\n\nTo use tables in Treaure Data inside Spark SQL, create a view with `df.createOrReplaceTempView(...)`:\n\n```python\n# Read TD table as a DataFrame\ndf = td.table(\"mydb.test1\").df()\n# Register the DataFrame as a view\ndf.createOrReplaceTempView(\"test1\")\n\nspark.sql(\"SELECT * FROM test1\").show()\n```\n\n### Create or Drop Databases and Tables\n\nCreate a new table or database:\n\n```python\ntd.create_database_if_not_exists(\"mydb\")\ntd.create_table_if_not_exists(\"mydb.test1\")\n```\n\nDelete unnecessary tables:\n\n```python\ntd.drop_table_if_exists(\"mydb.test1\")\ntd.drop_database_if_exists(\"mydb\")\n```\n\nYou can also check the presence of a table:\n\n```python\ntd.table(\"mydb.test1\").exists() # True if the table exists\n```\n\n### Create User-Defined Partition Tables\n\nUser-defined partitioning ([UDP](https://support.treasuredata.com/hc/en-us/articles/360009798714-User-Defined-Partitioning-for-Presto)) is useful if \nyou know a column in the table that has unique identifiers (e.g., IDs, category values).\n\nYou can create a UDP table partitioned by id (string type column) as follows: \n\n```python\ntd.create_udp_s(\"mydb.user_list\", \"id\")\n```\n\nTo create a UDP table, partitioned by Long (bigint) type column, use `td.create_udp_l`:\n\n```python\ntd.create_udp_l(\"mydb.departments\", \"dept_id\")\n```\n\n### Uploading DataFrames to Treasure Data\n\nTo save your local DataFrames as a table, `td.insert_into(df, table)` and `td.create_or_replace(df, table)` can be used:\n\n```python\n# Insert the records in the input DataFrame to the target table:\ntd.insert_into(df, \"mydb.tbl1\")\n\n# Create or replace the target table with the content of the input DataFrame:\ntd.create_or_replace(df, \"mydb.tbl2\")\n```\n\n## Using multiple TD accounts\n\nTo specify a new api key aside from the key that is configured in td-spark.conf, just use `td.with_apikey(apikey)`:\n\n```python\n# Returns a new TDSparkContext with the specified key\ntd2 = td.with_apikey(\"key2\")\n```\n\nFor reading tables or uploading DataFrames with the new key, use `td2`:\n\n```python\n# Read a table with key2\ndf = td2.table(\"sample_datasets.www_access\").df()\n...\n# Insert the records with key2\ntd2.insert_into(df, \"mydb.tbl1\")\n```\n\n### Running PySpark jobs with spark-submit\n\nTo submit your PySpark script to a Spark cluster, you will need the following files:\n\n- __td-spark.conf__ file that describes your TD API key and `spark.td.site` (See above).\n- __td_pyspark.py__ \n  - Check the file location using `pip show -f td-pyspark`, and copy td_pyspark.py to your favorite location\n- __td-spark-assembly.jar__\n  - Get the latest version from [Download](https://support.treasuredata.com/hc/en-us/articles/360000716627-TD-Spark-Driver-td-spark-) page.\n- Pre-build Spark \n  - [Download Spark 2.4.x](https://spark.apache.org/downloads.html) with Hadoop 2.7.x (built for Scala 2.11) \n  - Extract the downloaded archive. This folder location will be your `$SPARK_HOME`.\n\nHere is an example PySpark application code:\n__my_app.py__\n\n```python\nimport td_pyspark\nfrom pyspark.sql import SparkSession\n\n# Create a new SparkSession \nspark = SparkSession\\\n    .builder\\\n    .appName(\"myapp\")\\\n    .getOrCreate()\n\n# Create TDSparkContext\ntd = td_pyspark.TDSparkContext(spark)\n\n# Read the table data within -1d (yesterday) range as DataFrame\ndf = td.table(\"sample_datasets.www_access\").within(\"-1d\").df()\ndf.show()\n```\n\nTo run `my_app.py` use spark-submit by specifying the necessary files mentioned above:\n\n```bash\n# Launching PySpark with the local mode\n$ ${SPARK_HOME}/bin/spark-submit --master \"local[4]\"\\\n  --driver-class-path td-spark-assembly.jar\\\n  --properties-file=td-spark.conf\\\n  --py-files td_pyspark.py\\\n  my_app.py\n```\n\n`local[4]` means running a Spark cluster locally using 4 threads.\n\nTo use a remote Spark cluster, specify `master` address, e.g., `--master=spark://(master node IP address):7077`.\n\n### Using td-spark assembly included in the PyPI package.\n\nThe package contains pre-built binary of td-spark so that you can add it into the classpath as default.\n`TDSparkContextBuilder.default_jar_path()` returns the path to the default td-spark-assembly.jar file.\nPassing the path to `jars` method of TDSparkContextBuilder will automatically build the SparkSession including the default jar.\n\n```python\nimport td_pyspark\nfrom pyspark.sql import SparkSession\n\nbuilder = SparkSession\\\n    .builder\\\n    .appName(\"td-pyspark-app\")\n\ntd = td_pyspark.TDSparkContextBuilder(builder)\\\n    .apikey(\"XXXXXXXXXXXXXX\")\\\n    .jars(TDSparkContextBuilder.default_jar_path())\\\n    .build()\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://support.treasuredata.com/hc/en-us/sections/360000317028-Data-Science-and-SQL-Tools", "keywords": "Spark PySpark TreasureData", "license": "Apache 2", "maintainer": "", "maintainer_email": "", "name": "td-pyspark", "package_url": "https://pypi.org/project/td-pyspark/", "platform": "", "project_url": "https://pypi.org/project/td-pyspark/", "project_urls": {"Homepage": "https://support.treasuredata.com/hc/en-us/sections/360000317028-Data-Science-and-SQL-Tools"}, "release_url": "https://pypi.org/project/td-pyspark/20.4.0/", "requires_dist": ["sphinx (>=2.2.0) ; extra == 'docs'", "sphinx-rtd-theme (>=0.4.3) ; extra == 'docs'", "recommonmark ; extra == 'docs'", "pyspark (>=2.4.5) ; extra == 'spark'"], "requires_python": "", "summary": "Treasure Data extension for pyspark", "version": "20.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Getting Started: td-pyspark</h1>\n<p><a href=\"https://treasuredata.com\" rel=\"nofollow\">Treasure Data</a> extension for using <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\" rel=\"nofollow\">pyspark</a>.</p>\n<h2>Installation</h2>\n<p>You can install from PyPI by using <code>pip</code> as follows:</p>\n<pre>$ pip install td-pyspark\n</pre>\n<p>If you want to install PySpark via PyPI, you can install as:</p>\n<pre>$ pip install td-pyspark<span class=\"o\">[</span>spark<span class=\"o\">]</span>\n</pre>\n<h2>Introduction</h2>\n<p>First contact <a href=\"mailto:support@treasure-data.com\">support@treasure-data.com</a> to enable td-spark feature. This feature is disabled by default.</p>\n<p>td-pyspark is a library to enable Python to access tables in Treasure Data.\nThe features of td_pyspark include:</p>\n<ul>\n<li>Reading tables in Treasure Data as DataFrame</li>\n<li>Writing DataFrames to Treasure Data</li>\n<li>Submitting Presto queries and read the query results as DataFrames</li>\n</ul>\n<p>As of June 2019, Spark 2.4.x + Scala 2.11 is supported. Spark 2.4.5 is preferred.</p>\n<p>For more details, see also <a href=\"https://support.treasuredata.com/hc/en-us/articles/360001487167-Apache-Spark-Driver-td-spark-FAQs\" rel=\"nofollow\">td-spark FAQ</a>.</p>\n<h3>Quick Start with Docker</h3>\n<p>You can try td_pyspark using Docker without installing Spark nor Python.</p>\n<p>First create <strong>td-spark.conf</strong> file and set your TD API KEY and site (us, jp, eu01, ap02) configurations:</p>\n<p><strong>td-spark.conf</strong></p>\n<pre><code>spark.td.apikey (Your TD API KEY)\nspark.td.site (Your site: us, jp, eu01, ap02)\nspark.serializer org.apache.spark.serializer.KryoSerializer\nspark.sql.execution.arrow.enabled true\n</code></pre>\n<p>Launch pyspark Docker image. This image already has a pre-installed td_pyspark library:</p>\n<pre>$ docker run -it -e <span class=\"nv\">TD_SPARK_CONF</span><span class=\"o\">=</span>td-spark.conf -v <span class=\"k\">$(</span><span class=\"nb\">pwd</span><span class=\"k\">)</span>:/opt/spark/work armtd/td-spark-pyspark:latest_spark2.4.5\nPython <span class=\"m\">3</span>.6.9 <span class=\"o\">(</span>default, Oct <span class=\"m\">17</span> <span class=\"m\">2019</span>, <span class=\"m\">11</span>:10:22<span class=\"o\">)</span> \n<span class=\"o\">[</span>GCC <span class=\"m\">8</span>.3.0<span class=\"o\">]</span> on linux\nType <span class=\"s2\">\"help\"</span>, <span class=\"s2\">\"copyright\"</span>, <span class=\"s2\">\"credits\"</span> or <span class=\"s2\">\"license\"</span> <span class=\"k\">for</span> more information.\n<span class=\"m\">20</span>/04/10 <span class=\"m\">07</span>:43:59 WARN NativeCodeLoader: Unable to load native-hadoop library <span class=\"k\">for</span> your platform... using builtin-java classes where applicable\nUsing Spark<span class=\"s1\">'s default log4j profile: org/apache/spark/log4j-defaults.properties</span>\n<span class=\"s1\">Setting default log level to \"WARN\".</span>\n<span class=\"s1\">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span>\n<span class=\"s1\">Welcome to</span>\n<span class=\"s1\">      ____              __</span>\n<span class=\"s1\">     / __/__  ___ _____/ /__</span>\n<span class=\"s1\">    _\\ \\/ _ \\/ _ `/ __/  '</span>_/\n   /__ / .__/<span class=\"se\">\\_</span>,_/_/ /_/<span class=\"se\">\\_\\ </span>  version <span class=\"m\">2</span>.4.5\n      /_/\n\nUsing Python version <span class=\"m\">3</span>.6.9 <span class=\"o\">(</span>default, Oct <span class=\"m\">17</span> <span class=\"m\">2019</span> <span class=\"m\">11</span>:10:22<span class=\"o\">)</span>\nSparkSession available as <span class=\"s1\">'spark'</span>.\n<span class=\"m\">2020</span>-04-10 <span class=\"m\">07</span>:44:03.181Z debug <span class=\"o\">[</span>spark<span class=\"o\">]</span> Loading com.treasuredata.spark package - <span class=\"o\">(</span>package.scala:23<span class=\"o\">)</span>\n<span class=\"m\">2020</span>-04-10 <span class=\"m\">07</span>:44:03.251Z  info <span class=\"o\">[</span>spark<span class=\"o\">]</span> td-spark version:20.4.0, revision:f6bdc8e, build_time:2020-04-10T07:03:29.264+0000 - <span class=\"o\">(</span>package.scala:24<span class=\"o\">)</span>\n<span class=\"m\">2020</span>-04-10 <span class=\"m\">07</span>:44:05.217Z  info <span class=\"o\">[</span>TDServiceConfig<span class=\"o\">]</span> td-spark site: us - <span class=\"o\">(</span>TDServiceConfig.scala:36<span class=\"o\">)</span>\n&gt;&gt;&gt;\n</pre>\n<p>Try read a sample table by specifying a time range:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"sample_datasets.www_access\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">within</span><span class=\"p\">(</span><span class=\"s2\">\"+2d/2014-10-04\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n<span class=\"mi\">2019</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">19</span><span class=\"p\">:</span><span class=\"mi\">48</span><span class=\"p\">:</span><span class=\"mf\">51.605</span><span class=\"n\">Z</span>  <span class=\"n\">info</span> <span class=\"p\">[</span><span class=\"n\">TDRelation</span><span class=\"p\">]</span> <span class=\"n\">Fetching</span> <span class=\"n\">the</span> <span class=\"n\">partition</span> <span class=\"nb\">list</span> <span class=\"n\">of</span> <span class=\"n\">sample_datasets</span><span class=\"o\">.</span><span class=\"n\">www_access</span> <span class=\"n\">within</span> <span class=\"n\">time</span> <span class=\"nb\">range</span><span class=\"p\">:[</span><span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">04</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"n\">Z</span><span class=\"p\">,</span><span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">06</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"n\">Z</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">TDRelation</span><span class=\"o\">.</span><span class=\"n\">scala</span><span class=\"p\">:</span><span class=\"mi\">170</span><span class=\"p\">)</span>\n<span class=\"mi\">2019</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">19</span><span class=\"p\">:</span><span class=\"mi\">48</span><span class=\"p\">:</span><span class=\"mf\">51.950</span><span class=\"n\">Z</span>  <span class=\"n\">info</span> <span class=\"p\">[</span><span class=\"n\">TDRelation</span><span class=\"p\">]</span> <span class=\"n\">Retrieved</span> <span class=\"mi\">2</span> <span class=\"n\">partition</span> <span class=\"n\">entries</span> <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">TDRelation</span><span class=\"o\">.</span><span class=\"n\">scala</span><span class=\"p\">:</span><span class=\"mi\">176</span><span class=\"p\">)</span>\n<span class=\"o\">+----+---------------+--------------------+--------------------+----+--------------------+----+------+----------+</span>\n<span class=\"o\">|</span><span class=\"n\">user</span><span class=\"o\">|</span>           <span class=\"n\">host</span><span class=\"o\">|</span>                <span class=\"n\">path</span><span class=\"o\">|</span>             <span class=\"n\">referer</span><span class=\"o\">|</span><span class=\"n\">code</span><span class=\"o\">|</span>               <span class=\"n\">agent</span><span class=\"o\">|</span><span class=\"n\">size</span><span class=\"o\">|</span><span class=\"n\">method</span><span class=\"o\">|</span>      <span class=\"n\">time</span><span class=\"o\">|</span>\n<span class=\"o\">+----+---------------+--------------------+--------------------+----+--------------------+----+------+----------+</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span><span class=\"mf\">192.225</span><span class=\"o\">.</span><span class=\"mf\">229.196</span><span class=\"o\">|</span>  <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Maci</span><span class=\"o\">...|</span> <span class=\"mi\">117</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382292</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span><span class=\"mf\">120.168</span><span class=\"o\">.</span><span class=\"mf\">215.131</span><span class=\"o\">|</span>  <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">comp</span><span class=\"o\">...|</span>  <span class=\"mi\">53</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382284</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span><span class=\"mf\">180.198</span><span class=\"o\">.</span><span class=\"mf\">173.136</span><span class=\"o\">|/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">electro</span><span class=\"o\">...|</span> <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">computers</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span> <span class=\"mi\">106</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382275</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">140.168</span><span class=\"o\">.</span><span class=\"mf\">145.49</span><span class=\"o\">|</span>   <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">garden</span><span class=\"o\">/</span><span class=\"mi\">2832</span><span class=\"o\">|</span>      <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">toys</span><span class=\"o\">/</span><span class=\"mi\">230</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Maci</span><span class=\"o\">...|</span> <span class=\"mi\">122</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382267</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>  <span class=\"mf\">52.168</span><span class=\"o\">.</span><span class=\"mf\">78.222</span><span class=\"o\">|/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">electro</span><span class=\"o\">...|</span>    <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">games</span><span class=\"o\">/</span><span class=\"mi\">2532</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">comp</span><span class=\"o\">...|</span>  <span class=\"mi\">73</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382259</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>  <span class=\"mf\">32.42</span><span class=\"o\">.</span><span class=\"mf\">160.165</span><span class=\"o\">|</span>   <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">cameras</span><span class=\"o\">|/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">cameras</span><span class=\"o\">...|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span> <span class=\"mi\">117</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382251</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>   <span class=\"mf\">48.204</span><span class=\"o\">.</span><span class=\"mf\">59.23</span><span class=\"o\">|</span>  <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">|/</span><span class=\"n\">search</span><span class=\"o\">/</span><span class=\"err\">?</span><span class=\"n\">c</span><span class=\"o\">=</span><span class=\"n\">Electr</span><span class=\"o\">...|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Maci</span><span class=\"o\">...|</span>  <span class=\"mi\">52</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382243</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span><span class=\"mf\">136.207</span><span class=\"o\">.</span><span class=\"mf\">150.227</span><span class=\"o\">|/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">electro</span><span class=\"o\">...|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">iPad</span><span class=\"o\">...|</span> <span class=\"mi\">120</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382234</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">204.21</span><span class=\"o\">.</span><span class=\"mf\">174.187</span><span class=\"o\">|</span>   <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">jewelry</span><span class=\"o\">|</span>   <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">office</span><span class=\"o\">/</span><span class=\"mi\">3462</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span>  <span class=\"mi\">59</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382226</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>  <span class=\"mf\">224.198</span><span class=\"o\">.</span><span class=\"mf\">88.93</span><span class=\"o\">|</span>    <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">office</span><span class=\"o\">|</span>     <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">music</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">4.0</span> <span class=\"p\">(</span><span class=\"n\">comp</span><span class=\"o\">...|</span>  <span class=\"mi\">46</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382218</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>   <span class=\"mf\">96.54</span><span class=\"o\">.</span><span class=\"mf\">24.116</span><span class=\"o\">|</span>     <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">games</span><span class=\"o\">|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span>  <span class=\"mi\">40</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382210</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">184.42</span><span class=\"o\">.</span><span class=\"mf\">224.210</span><span class=\"o\">|</span> <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">computers</span><span class=\"o\">|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span>  <span class=\"mi\">95</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382201</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>  <span class=\"mf\">144.72</span><span class=\"o\">.</span><span class=\"mf\">47.212</span><span class=\"o\">|/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">giftcards</span><span class=\"o\">/</span><span class=\"mi\">4684</span><span class=\"o\">|</span>    <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">books</span><span class=\"o\">/</span><span class=\"mi\">1031</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span>  <span class=\"mi\">65</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382193</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">40.213</span><span class=\"o\">.</span><span class=\"mf\">111.170</span><span class=\"o\">|</span>     <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">toys</span><span class=\"o\">/</span><span class=\"mi\">1085</span><span class=\"o\">|</span>   <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">cameras</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span>  <span class=\"mi\">65</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382185</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">132.54</span><span class=\"o\">.</span><span class=\"mf\">226.209</span><span class=\"o\">|/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">electronics</span><span class=\"o\">...|</span>  <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">comp</span><span class=\"o\">...|</span> <span class=\"mi\">121</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382177</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>  <span class=\"mf\">108.219</span><span class=\"o\">.</span><span class=\"mf\">68.64</span><span class=\"o\">|/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">cameras</span><span class=\"o\">...|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Maci</span><span class=\"o\">...|</span>  <span class=\"mi\">54</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382168</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">168.66</span><span class=\"o\">.</span><span class=\"mf\">149.218</span><span class=\"o\">|</span> <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">/</span><span class=\"mi\">4343</span><span class=\"o\">|</span>  <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">4.0</span> <span class=\"p\">(</span><span class=\"n\">comp</span><span class=\"o\">...|</span> <span class=\"mi\">139</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382160</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span>  <span class=\"mf\">80.66</span><span class=\"o\">.</span><span class=\"mf\">118.103</span><span class=\"o\">|</span>  <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">|</span>                   <span class=\"o\">-|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">4.0</span> <span class=\"p\">(</span><span class=\"n\">comp</span><span class=\"o\">...|</span>  <span class=\"mi\">92</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382152</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span><span class=\"mf\">140.171</span><span class=\"o\">.</span><span class=\"mf\">147.207</span><span class=\"o\">|</span>     <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">music</span><span class=\"o\">|</span>   <span class=\"o\">/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">jewelry</span><span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span> <span class=\"mi\">119</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382144</span><span class=\"o\">|</span>\n<span class=\"o\">|</span><span class=\"n\">null</span><span class=\"o\">|</span> <span class=\"mf\">84.132</span><span class=\"o\">.</span><span class=\"mf\">164.204</span><span class=\"o\">|</span> <span class=\"o\">/</span><span class=\"n\">item</span><span class=\"o\">/</span><span class=\"n\">software</span><span class=\"o\">/</span><span class=\"mi\">4783</span><span class=\"o\">|/</span><span class=\"n\">category</span><span class=\"o\">/</span><span class=\"n\">electro</span><span class=\"o\">...|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"n\">Mozilla</span><span class=\"o\">/</span><span class=\"mf\">5.0</span> <span class=\"p\">(</span><span class=\"n\">Wind</span><span class=\"o\">...|</span> <span class=\"mi\">137</span><span class=\"o\">|</span>   <span class=\"n\">GET</span><span class=\"o\">|</span><span class=\"mi\">1412382135</span><span class=\"o\">|</span>\n<span class=\"o\">+----+---------------+--------------------+--------------------+----+--------------------+----+------+----------+</span>\n<span class=\"n\">only</span> <span class=\"n\">showing</span> <span class=\"n\">top</span> <span class=\"mi\">20</span> <span class=\"n\">rows</span>\n<span class=\"o\">&gt;&gt;&gt;</span>\n</pre>\n<h2>Usage</h2>\n<p><em>TDSparkContext</em> is an entry point to access td_pyspark's functionalities. To create TDSparkContext, pass your SparkSession (spark) to TDSparkContext:</p>\n<pre><span class=\"n\">td</span> <span class=\"o\">=</span> <span class=\"n\">TDSparkContext</span><span class=\"p\">(</span><span class=\"n\">spark</span><span class=\"p\">)</span>\n</pre>\n<h3>Reading Tables as DataFrames</h3>\n<p>To read a table, use <code>td.table(table name)</code>:</p>\n<pre><span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"sample_datasets.www_access\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<p>To change the context database, use <code>td.use(database_name)</code>:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">use</span><span class=\"p\">(</span><span class=\"s2\">\"sample_datasets\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># Accesses sample_datasets.www_access</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"www_access\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n</pre>\n<p>By calling <code>.df()</code> your table data will be read as Spark's DataFrame.\nThe usage of the DataFrame is the same with PySpark. See also <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\" rel=\"nofollow\">PySpark DataFrame documentation</a>.</p>\n<h4>Specifying Time Ranges</h4>\n<p>Treasure Data is a time series database, so reading recent data by specifying a time range is important to reduce the amount of data to be processed.\n<code>.within(...)</code> function can be used to specify a target time range in a concise syntax.\n<code>within</code> function accepts the same syntax used in <a href=\"https://support.treasuredata.com/hc/en-us/articles/360001450828-Supported-Presto-and-TD-Functions#TD_INTERVAL\" rel=\"nofollow\">TD_INTERVAL function in Presto</a>.</p>\n<p>For example, to read the last 1 hour range of data, use <code>within(\"-1h\")</code>:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"tbl\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">within</span><span class=\"p\">(</span><span class=\"s2\">\"-1h\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n</pre>\n<p>You can also read the last day's data:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"tbl\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">within</span><span class=\"p\">(</span><span class=\"s2\">\"-1d\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n</pre>\n<p>You can also specify an <em>offset</em> of the relative time range. This example reads the last days's data beginning from 7 days ago:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"tbl\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">within</span><span class=\"p\">(</span><span class=\"s2\">\"-1d/-7d\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n</pre>\n<p>If you know an exact time range, <code>within(\"(start time)/(end time)\")</code> is useful:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"sample_datasets.www_access\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">within</span><span class=\"p\">(</span><span class=\"s2\">\"2014-10-04/2014-10-05\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n<span class=\"mi\">2019</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">20</span><span class=\"p\">:</span><span class=\"mi\">12</span><span class=\"p\">:</span><span class=\"mf\">01.400</span><span class=\"n\">Z</span>  <span class=\"n\">info</span> <span class=\"p\">[</span><span class=\"n\">TDRelation</span><span class=\"p\">]</span> <span class=\"n\">Fetching</span> <span class=\"n\">the</span> <span class=\"n\">partition</span> <span class=\"nb\">list</span> <span class=\"n\">of</span> <span class=\"n\">sample_datasets</span><span class=\"o\">.</span><span class=\"n\">www_access</span> <span class=\"n\">within</span> <span class=\"n\">time</span> <span class=\"nb\">range</span><span class=\"p\">:[</span><span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">04</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"n\">Z</span><span class=\"p\">,</span><span class=\"mi\">2014</span><span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">05</span> <span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"p\">:</span><span class=\"mi\">00</span><span class=\"n\">Z</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">TDRelation</span><span class=\"o\">.</span><span class=\"n\">scala</span><span class=\"p\">:</span><span class=\"mi\">170</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre>\n<p>See <a href=\"https://support.treasuredata.com/hc/en-us/articles/360001450828-Supported-Presto-and-TD-Functions#TD_INTERVAL\" rel=\"nofollow\">this doc</a> for more examples of interval strings.</p>\n<h4>Submitting Presto Queries</h4>\n<p>If your Spark cluster is small, reading all of the data as in-memory DataFrame might be difficult.\nIn this case, you can utilize Presto, a distributed SQL query engine, to reduce the amount of data processing with PySpark:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">presto</span><span class=\"p\">(</span><span class=\"s2\">\"select code, * from sample_datasets.www_access\"</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">q</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n<span class=\"mi\">2019</span><span class=\"o\">-</span><span class=\"mi\">06</span><span class=\"o\">-</span><span class=\"mi\">13</span> <span class=\"mi\">20</span><span class=\"p\">:</span><span class=\"mi\">09</span><span class=\"p\">:</span><span class=\"mf\">13.245</span><span class=\"n\">Z</span>  <span class=\"n\">info</span> <span class=\"p\">[</span><span class=\"n\">TDPrestoJDBCRDD</span><span class=\"p\">]</span>  <span class=\"o\">-</span> <span class=\"p\">(</span><span class=\"n\">TDPrestoRelation</span><span class=\"o\">.</span><span class=\"n\">scala</span><span class=\"p\">:</span><span class=\"mi\">106</span><span class=\"p\">)</span>\n<span class=\"n\">Submit</span> <span class=\"n\">Presto</span> <span class=\"n\">query</span><span class=\"p\">:</span>\n<span class=\"n\">select</span> <span class=\"n\">code</span><span class=\"p\">,</span> <span class=\"n\">count</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"p\">)</span> <span class=\"n\">cnt</span> <span class=\"kn\">from</span> <span class=\"nn\">sample_datasets.www_access</span> <span class=\"n\">group</span> <span class=\"n\">by</span> <span class=\"mi\">1</span>\n<span class=\"o\">+----+----+</span>\n<span class=\"o\">|</span><span class=\"n\">code</span><span class=\"o\">|</span> <span class=\"n\">cnt</span><span class=\"o\">|</span>\n<span class=\"o\">+----+----+</span>\n<span class=\"o\">|</span> <span class=\"mi\">200</span><span class=\"o\">|</span><span class=\"mi\">4981</span><span class=\"o\">|</span>\n<span class=\"o\">|</span> <span class=\"mi\">500</span><span class=\"o\">|</span>   <span class=\"mi\">2</span><span class=\"o\">|</span>\n<span class=\"o\">|</span> <span class=\"mi\">404</span><span class=\"o\">|</span>  <span class=\"mi\">17</span><span class=\"o\">|</span>\n<span class=\"o\">+----+----+</span>\n</pre>\n<p>The query result is represented as a DataFrame.</p>\n<p>To run non query statements (e.g., INSERT INTO, CREATE TABLE, etc.) use <code>execute_presto(sql)</code>:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">execute_presto</span><span class=\"p\">(</span><span class=\"s2\">\"CREATE TABLE IF NOT EXISTS A(time bigint, id varchar)\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Using SparkSQL</h4>\n<p>To use tables in Treaure Data inside Spark SQL, create a view with <code>df.createOrReplaceTempView(...)</code>:</p>\n<pre><span class=\"c1\"># Read TD table as a DataFrame</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"mydb.test1\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n<span class=\"c1\"># Register the DataFrame as a view</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">createOrReplaceTempView</span><span class=\"p\">(</span><span class=\"s2\">\"test1\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"p\">(</span><span class=\"s2\">\"SELECT * FROM test1\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<h3>Create or Drop Databases and Tables</h3>\n<p>Create a new table or database:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">create_database_if_not_exists</span><span class=\"p\">(</span><span class=\"s2\">\"mydb\"</span><span class=\"p\">)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">create_table_if_not_exists</span><span class=\"p\">(</span><span class=\"s2\">\"mydb.test1\"</span><span class=\"p\">)</span>\n</pre>\n<p>Delete unnecessary tables:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">drop_table_if_exists</span><span class=\"p\">(</span><span class=\"s2\">\"mydb.test1\"</span><span class=\"p\">)</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">drop_database_if_exists</span><span class=\"p\">(</span><span class=\"s2\">\"mydb\"</span><span class=\"p\">)</span>\n</pre>\n<p>You can also check the presence of a table:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"mydb.test1\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">()</span> <span class=\"c1\"># True if the table exists</span>\n</pre>\n<h3>Create User-Defined Partition Tables</h3>\n<p>User-defined partitioning (<a href=\"https://support.treasuredata.com/hc/en-us/articles/360009798714-User-Defined-Partitioning-for-Presto\" rel=\"nofollow\">UDP</a>) is useful if\nyou know a column in the table that has unique identifiers (e.g., IDs, category values).</p>\n<p>You can create a UDP table partitioned by id (string type column) as follows:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">create_udp_s</span><span class=\"p\">(</span><span class=\"s2\">\"mydb.user_list\"</span><span class=\"p\">,</span> <span class=\"s2\">\"id\"</span><span class=\"p\">)</span>\n</pre>\n<p>To create a UDP table, partitioned by Long (bigint) type column, use <code>td.create_udp_l</code>:</p>\n<pre><span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">create_udp_l</span><span class=\"p\">(</span><span class=\"s2\">\"mydb.departments\"</span><span class=\"p\">,</span> <span class=\"s2\">\"dept_id\"</span><span class=\"p\">)</span>\n</pre>\n<h3>Uploading DataFrames to Treasure Data</h3>\n<p>To save your local DataFrames as a table, <code>td.insert_into(df, table)</code> and <code>td.create_or_replace(df, table)</code> can be used:</p>\n<pre><span class=\"c1\"># Insert the records in the input DataFrame to the target table:</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">insert_into</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s2\">\"mydb.tbl1\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Create or replace the target table with the content of the input DataFrame:</span>\n<span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">create_or_replace</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s2\">\"mydb.tbl2\"</span><span class=\"p\">)</span>\n</pre>\n<h2>Using multiple TD accounts</h2>\n<p>To specify a new api key aside from the key that is configured in td-spark.conf, just use <code>td.with_apikey(apikey)</code>:</p>\n<pre><span class=\"c1\"># Returns a new TDSparkContext with the specified key</span>\n<span class=\"n\">td2</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">with_apikey</span><span class=\"p\">(</span><span class=\"s2\">\"key2\"</span><span class=\"p\">)</span>\n</pre>\n<p>For reading tables or uploading DataFrames with the new key, use <code>td2</code>:</p>\n<pre><span class=\"c1\"># Read a table with key2</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td2</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"sample_datasets.www_access\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n<span class=\"o\">...</span>\n<span class=\"c1\"># Insert the records with key2</span>\n<span class=\"n\">td2</span><span class=\"o\">.</span><span class=\"n\">insert_into</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s2\">\"mydb.tbl1\"</span><span class=\"p\">)</span>\n</pre>\n<h3>Running PySpark jobs with spark-submit</h3>\n<p>To submit your PySpark script to a Spark cluster, you will need the following files:</p>\n<ul>\n<li><strong>td-spark.conf</strong> file that describes your TD API key and <code>spark.td.site</code> (See above).</li>\n<li><strong>td_pyspark.py</strong>\n<ul>\n<li>Check the file location using <code>pip show -f td-pyspark</code>, and copy td_pyspark.py to your favorite location</li>\n</ul>\n</li>\n<li><strong>td-spark-assembly.jar</strong>\n<ul>\n<li>Get the latest version from <a href=\"https://support.treasuredata.com/hc/en-us/articles/360000716627-TD-Spark-Driver-td-spark-\" rel=\"nofollow\">Download</a> page.</li>\n</ul>\n</li>\n<li>Pre-build Spark\n<ul>\n<li><a href=\"https://spark.apache.org/downloads.html\" rel=\"nofollow\">Download Spark 2.4.x</a> with Hadoop 2.7.x (built for Scala 2.11)</li>\n<li>Extract the downloaded archive. This folder location will be your <code>$SPARK_HOME</code>.</li>\n</ul>\n</li>\n</ul>\n<p>Here is an example PySpark application code:\n<strong>my_app.py</strong></p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">td_pyspark</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.sql</span> <span class=\"kn\">import</span> <span class=\"n\">SparkSession</span>\n\n<span class=\"c1\"># Create a new SparkSession </span>\n<span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">SparkSession</span>\\\n    <span class=\"o\">.</span><span class=\"n\">builder</span>\\\n    <span class=\"o\">.</span><span class=\"n\">appName</span><span class=\"p\">(</span><span class=\"s2\">\"myapp\"</span><span class=\"p\">)</span>\\\n    <span class=\"o\">.</span><span class=\"n\">getOrCreate</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Create TDSparkContext</span>\n<span class=\"n\">td</span> <span class=\"o\">=</span> <span class=\"n\">td_pyspark</span><span class=\"o\">.</span><span class=\"n\">TDSparkContext</span><span class=\"p\">(</span><span class=\"n\">spark</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Read the table data within -1d (yesterday) range as DataFrame</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">td</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">(</span><span class=\"s2\">\"sample_datasets.www_access\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">within</span><span class=\"p\">(</span><span class=\"s2\">\"-1d\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">df</span><span class=\"p\">()</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<p>To run <code>my_app.py</code> use spark-submit by specifying the necessary files mentioned above:</p>\n<pre><span class=\"c1\"># Launching PySpark with the local mode</span>\n$ <span class=\"si\">${</span><span class=\"nv\">SPARK_HOME</span><span class=\"si\">}</span>/bin/spark-submit --master <span class=\"s2\">\"local[4]\"</span><span class=\"se\">\\</span>\n  --driver-class-path td-spark-assembly.jar<span class=\"se\">\\</span>\n  --properties-file<span class=\"o\">=</span>td-spark.conf<span class=\"se\">\\</span>\n  --py-files td_pyspark.py<span class=\"se\">\\</span>\n  my_app.py\n</pre>\n<p><code>local[4]</code> means running a Spark cluster locally using 4 threads.</p>\n<p>To use a remote Spark cluster, specify <code>master</code> address, e.g., <code>--master=spark://(master node IP address):7077</code>.</p>\n<h3>Using td-spark assembly included in the PyPI package.</h3>\n<p>The package contains pre-built binary of td-spark so that you can add it into the classpath as default.\n<code>TDSparkContextBuilder.default_jar_path()</code> returns the path to the default td-spark-assembly.jar file.\nPassing the path to <code>jars</code> method of TDSparkContextBuilder will automatically build the SparkSession including the default jar.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">td_pyspark</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.sql</span> <span class=\"kn\">import</span> <span class=\"n\">SparkSession</span>\n\n<span class=\"n\">builder</span> <span class=\"o\">=</span> <span class=\"n\">SparkSession</span>\\\n    <span class=\"o\">.</span><span class=\"n\">builder</span>\\\n    <span class=\"o\">.</span><span class=\"n\">appName</span><span class=\"p\">(</span><span class=\"s2\">\"td-pyspark-app\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">td</span> <span class=\"o\">=</span> <span class=\"n\">td_pyspark</span><span class=\"o\">.</span><span class=\"n\">TDSparkContextBuilder</span><span class=\"p\">(</span><span class=\"n\">builder</span><span class=\"p\">)</span>\\\n    <span class=\"o\">.</span><span class=\"n\">apikey</span><span class=\"p\">(</span><span class=\"s2\">\"XXXXXXXXXXXXXX\"</span><span class=\"p\">)</span>\\\n    <span class=\"o\">.</span><span class=\"n\">jars</span><span class=\"p\">(</span><span class=\"n\">TDSparkContextBuilder</span><span class=\"o\">.</span><span class=\"n\">default_jar_path</span><span class=\"p\">())</span>\\\n    <span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">()</span>\n</pre>\n\n          </div>"}, "last_serial": 7009889, "releases": {"19.11.0": [{"comment_text": "", "digests": {"md5": "9a1c2cf5137df27ba0f35bd186d0b58c", "sha256": "40146018980ff7869ebd756dc4962816fd5a88560c2a1e6d5a6abfc33234ef3d"}, "downloads": -1, "filename": "td_pyspark-19.11.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9a1c2cf5137df27ba0f35bd186d0b58c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22856348, "upload_time": "2019-11-21T21:59:57", "upload_time_iso_8601": "2019-11-21T21:59:57.344411Z", "url": "https://files.pythonhosted.org/packages/69/fb/cede3be16d956a13237edeff5b36fc2b13f6201e7d24740d101f75f10dc9/td_pyspark-19.11.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d1217df4e4ad44003f9998b81795faf9", "sha256": "5fb30846af8f188788d63125ca86156d9ad69f1b6082a70be336f3f83e5c1d63"}, "downloads": -1, "filename": "td_pyspark-19.11.0.tar.gz", "has_sig": false, "md5_digest": "d1217df4e4ad44003f9998b81795faf9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22850607, "upload_time": "2019-11-21T22:00:49", "upload_time_iso_8601": "2019-11-21T22:00:49.017437Z", "url": "https://files.pythonhosted.org/packages/55/20/fc1e412dee4ff511e1258dac14e701b9b64f74b5ccd7553270c0f3d7f531/td_pyspark-19.11.0.tar.gz", "yanked": false}], "19.11.1": [{"comment_text": "", "digests": {"md5": "1763eb81c2e286c7de8466b891fcb3c6", "sha256": "b728c8c31031eb3436ccdef9e6d05d1d569645f986fe5d422792e4bc45359283"}, "downloads": -1, "filename": "td_pyspark-19.11.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1763eb81c2e286c7de8466b891fcb3c6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22856353, "upload_time": "2020-02-12T08:53:56", "upload_time_iso_8601": "2020-02-12T08:53:56.385482Z", "url": "https://files.pythonhosted.org/packages/7c/f8/d216b4e8f9d4b8e4e4a56c2a5496b9b27a345a6b1ae37bb3861e80a139c4/td_pyspark-19.11.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9785371a271b24128662c447e8d270a0", "sha256": "b8916165291f54e536a2ce6426b58f373b474de505e680b95d7249db86ee3aae"}, "downloads": -1, "filename": "td_pyspark-19.11.1.tar.gz", "has_sig": false, "md5_digest": "9785371a271b24128662c447e8d270a0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22851731, "upload_time": "2020-02-12T08:54:25", "upload_time_iso_8601": "2020-02-12T08:54:25.745126Z", "url": "https://files.pythonhosted.org/packages/c0/bf/6bf7ec3c68e66a2a05d743a78b38605de8d052f45b8d0060c118c317e85e/td_pyspark-19.11.1.tar.gz", "yanked": false}], "19.5.0": [{"comment_text": "", "digests": {"md5": "3dada29e9e97c137c5b15a0adfba0d6d", "sha256": "71ea79f6a84ae7cc32ba5923694366416254a87789b97e5c63cbe6b49aea0847"}, "downloads": -1, "filename": "td_pyspark-19.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3dada29e9e97c137c5b15a0adfba0d6d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 3474, "upload_time": "2019-06-10T04:40:01", "upload_time_iso_8601": "2019-06-10T04:40:01.666361Z", "url": "https://files.pythonhosted.org/packages/44/f6/7781921289bbb439c9784acd5af7098f1699b99b6a5a885e8357c2b405a1/td_pyspark-19.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1adec893a40645892f47687901c195f3", "sha256": "85c7b71746f600b21b62905625ff2808fe1b2dabf1c89fda29a7953c0f79e8b8"}, "downloads": -1, "filename": "td_pyspark-19.5.0.tar.gz", "has_sig": false, "md5_digest": "1adec893a40645892f47687901c195f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3229, "upload_time": "2019-06-10T04:40:03", "upload_time_iso_8601": "2019-06-10T04:40:03.998075Z", "url": "https://files.pythonhosted.org/packages/1e/ec/566cec7a476faa73812d592af32c3e72c9a272ae2fc5492bd4717876eeca/td_pyspark-19.5.0.tar.gz", "yanked": false}], "19.7.0": [{"comment_text": "", "digests": {"md5": "ba185616d590dc06aadd9758ce72cfae", "sha256": "f88b10f7b7bab8fc6d0afa0ba42ae6dc1081d631faaba683b53a6a255088d215"}, "downloads": -1, "filename": "td_pyspark-19.7.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ba185616d590dc06aadd9758ce72cfae", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 45597589, "upload_time": "2019-07-02T02:59:21", "upload_time_iso_8601": "2019-07-02T02:59:21.423705Z", "url": "https://files.pythonhosted.org/packages/85/c0/1257fac3ed8b1375554ecc2151e5efe73095693248630f140916bc66895e/td_pyspark-19.7.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e4710537c1503051c42396cf27a49279", "sha256": "629da3e4e6c03d9ca33c42c0bb0cdaf13d56693ee41d643211e9bfb98a1d7f2b"}, "downloads": -1, "filename": "td_pyspark-19.7.0.tar.gz", "has_sig": false, "md5_digest": "e4710537c1503051c42396cf27a49279", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22806668, "upload_time": "2019-07-02T02:59:34", "upload_time_iso_8601": "2019-07-02T02:59:34.960922Z", "url": "https://files.pythonhosted.org/packages/12/39/b66e20b65462fd702ef6d28d2c2248820c4de09e387187aa27f3f0d9328a/td_pyspark-19.7.0.tar.gz", "yanked": false}], "19.9.0": [{"comment_text": "", "digests": {"md5": "653929feccce51e5299258f71219f689", "sha256": "3bf6be6d89ea3284d21d4a24ae8e97e44bfbad989b459b046793e4106e2c1cd4"}, "downloads": -1, "filename": "td_pyspark-19.9.0-py3-none-any.whl", "has_sig": false, "md5_digest": "653929feccce51e5299258f71219f689", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 45820482, "upload_time": "2019-09-12T02:08:48", "upload_time_iso_8601": "2019-09-12T02:08:48.611759Z", "url": "https://files.pythonhosted.org/packages/aa/6e/3288fe1409f71204ee3b96382a4bcca900912dc77a5a0cef8b55fcab23ea/td_pyspark-19.9.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb042fa5e86d69452f5838d860b6b848", "sha256": "14d7dd49ecdb818d1579c63812729d5eed7393da50456004b3560061882fb795"}, "downloads": -1, "filename": "td_pyspark-19.9.0.tar.gz", "has_sig": false, "md5_digest": "cb042fa5e86d69452f5838d860b6b848", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23025434, "upload_time": "2019-09-12T02:08:55", "upload_time_iso_8601": "2019-09-12T02:08:55.598883Z", "url": "https://files.pythonhosted.org/packages/f4/fc/4e0149a6c44d58fbbd0c138f025c2966f209dd3bf4bd61443f1d3f3d3e28/td_pyspark-19.9.0.tar.gz", "yanked": false}], "20.2.0": [{"comment_text": "", "digests": {"md5": "314bc7e20ff777063fee8cea17e3c7c8", "sha256": "5977fddfc99827d85cf8a250e4b913229931415a0291083fa51dfdbdcfb7ef3b"}, "downloads": -1, "filename": "td_pyspark-20.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "314bc7e20ff777063fee8cea17e3c7c8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22856344, "upload_time": "2020-03-04T01:54:52", "upload_time_iso_8601": "2020-03-04T01:54:52.484706Z", "url": "https://files.pythonhosted.org/packages/ba/78/9f1b4967f6b5c57b3edf0d180cab41ba8ee4440643e3978b4598a0812263/td_pyspark-20.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cd5d3814b4013e64ad78ea040f00fb12", "sha256": "db526f7aaf9c0fc97458448946f9894f5b894177bd2981bbff66fef1a488330b"}, "downloads": -1, "filename": "td_pyspark-20.2.0.tar.gz", "has_sig": false, "md5_digest": "cd5d3814b4013e64ad78ea040f00fb12", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22851744, "upload_time": "2020-03-04T01:55:14", "upload_time_iso_8601": "2020-03-04T01:55:14.229792Z", "url": "https://files.pythonhosted.org/packages/60/ae/93b55e5807e10fea24582ec0439b23f8623ef9ae22aab9c4573d6d5f2902/td_pyspark-20.2.0.tar.gz", "yanked": false}], "20.4.0": [{"comment_text": "", "digests": {"md5": "bfa569c395283536b58bcc22f79dc0ef", "sha256": "1e1bb7406d73ad76e9400a865760f40b2a49d49deab6b3838e7141f814abf8b6"}, "downloads": -1, "filename": "td_pyspark-20.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "bfa569c395283536b58bcc22f79dc0ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22853595, "upload_time": "2020-04-13T13:26:24", "upload_time_iso_8601": "2020-04-13T13:26:24.912307Z", "url": "https://files.pythonhosted.org/packages/22/e0/c8fb3af5a09c2112d6104e4785dd056383442fb43f57c803ebb0909ffa61/td_pyspark-20.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8f5d74076809756edb83deda124e6e9", "sha256": "3d6c4147b089da5873dfd92dd1030c75f3a1063be1f800eb69a79c59e90b146b"}, "downloads": -1, "filename": "td_pyspark-20.4.0.tar.gz", "has_sig": false, "md5_digest": "e8f5d74076809756edb83deda124e6e9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22848906, "upload_time": "2020-04-13T13:26:43", "upload_time_iso_8601": "2020-04-13T13:26:43.875891Z", "url": "https://files.pythonhosted.org/packages/1f/85/309d5a9505f69af4cb15f75298666e83f98a7ecc82f2bd6a3752f06435fa/td_pyspark-20.4.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bfa569c395283536b58bcc22f79dc0ef", "sha256": "1e1bb7406d73ad76e9400a865760f40b2a49d49deab6b3838e7141f814abf8b6"}, "downloads": -1, "filename": "td_pyspark-20.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "bfa569c395283536b58bcc22f79dc0ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22853595, "upload_time": "2020-04-13T13:26:24", "upload_time_iso_8601": "2020-04-13T13:26:24.912307Z", "url": "https://files.pythonhosted.org/packages/22/e0/c8fb3af5a09c2112d6104e4785dd056383442fb43f57c803ebb0909ffa61/td_pyspark-20.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8f5d74076809756edb83deda124e6e9", "sha256": "3d6c4147b089da5873dfd92dd1030c75f3a1063be1f800eb69a79c59e90b146b"}, "downloads": -1, "filename": "td_pyspark-20.4.0.tar.gz", "has_sig": false, "md5_digest": "e8f5d74076809756edb83deda124e6e9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22848906, "upload_time": "2020-04-13T13:26:43", "upload_time_iso_8601": "2020-04-13T13:26:43.875891Z", "url": "https://files.pythonhosted.org/packages/1f/85/309d5a9505f69af4cb15f75298666e83f98a7ecc82f2bd6a3752f06435fa/td_pyspark-20.4.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:57:10 2020"}