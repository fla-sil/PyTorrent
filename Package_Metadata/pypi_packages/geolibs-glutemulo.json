{"info": {"author": "Geographica", "author_email": "hello@geographica.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# Glutemulo\n\nA HA geo socio demo data ingestor\n\n## Usage\n\nRead de [examples files](examples).\n\nWe use environ vars. See [Environ vars file example](.env.example) for complete list,\nand examples.\n\n### Using producer to upload data to kafka\n\nSee python examples bellow. You must produce a dict with column_mame:value\n\n### Using the ingestor consumer\nUse `gluto` docker and fill enviroment vars.\n\nSelect the backend using `GLUTEMULO_BACKEND` and specific vars for it (database, host, etc).\nYou can select 2 backends: `postgres` or `carto`\nSee [Environ vars file example](.env.example) for complete list.\n\nThen set:\n\n1. `GLUTEMULO_INGESTOR_DATASET`  \nTable to upload data\n2. `GLUTEMULO_INGESTOR_DATASET_COLUMNS`  \nComma separted list of column names\n\nNow, create the table on backend or set `GLUTEMULO_INGESTOR_DATASET_DDL` and `GLUTEMULO_INGESTOR_DATASET_AUTOCREATE=False`\n\nThen configure ingestor for kafka.\nFirst read the [python-kafka doc](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html)\nand then use the following vars:\n\n1. `GLUTEMULO_INGESTOR_TOPIC`  \nTopic to use\n2. `GLUTEMULO_INGESTOR_BOOTSTRAP_SERVERS`  \nList of servers to connect\n3. `GLUTEMULO_INGESTOR_GROUP_ID`  \nGroup id.\n4. `GLUTEMULO_INGESTOR_AUTO_OFFSET_RESET`  \nlatest or earliest.\n5. `GLUTEMULO_INGESTOR_MAX_POLL_RECORDS`  \nThe maximum number of records returned in a batch of messages\n6. `GLUTEMULO_INGESTOR_FETCH_MIN_BYTES`  \nMinimum amount of data the server should return for a fetch request, otherwise wait up to fetch_max_wait_ms for more data to accumulate. Default: 1\n\nFor the docker, we include a [example docker-compose file](docker-compose.yml).\nRemember you can scale with same group_id\n\n```bash\ndocker-compose scale gluto=3\n```\n\n## Run flask demo\n\n```bash\n$ FLASK_ENV=development flask run\n * Environment: development\n * Debug mode: on\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n * Restarting with stat\n * Debugger is active!\n * Debugger PIN: 194-409-049\n```\n\n## Test\n\n```bash\n$ http -j POST localhost:5000/v1/ uno=1 dos=2`\nHTTP/1.0 201 CREATED\nContent-Length: 13\nContent-Type: text/html; charset=utf-8\nDate: Thu, 02 May 2019 14:56:07 GMT\nServer: Werkzeug/0.15.2 Python/3.7.2\n\nDATA Received\n```\n\n## Producer / Consumer\n\n### Kafka + json\n\nAsync producer:\n\n```python\nfrom glutemulo.kafka.producer import JsonKafka\nproductor = JsonKafka(bootstrap_servers=\"localhost:9092\")\nfuture = productor.produce('simple-topic', dict(dos='BB'))\n```\n\nConsumer in batches:\n```python\nfrom glutemulo.kafka.consumer import JsonKafka\nconsumer = JsonKafka('simple-topic', bootstrap_servers=\"localhost:9092\")\nfor msg in consumer.consume():\n    for msg in messages:\n        print(msg)\n```\n\n### Kafka + Avro\n\nsync producer:\n\n```python\nSCHEMA = {\n    \"type\": \"record\",\n    \"name\": \"simpledata\",\n    \"doc\": \"This is a sample Avro schema to get you started.\",\n    \"fields\": [\n        {\"name\": \"name\", \"type\": \"string\"},\n        {\"name\": \"number1\", \"type\": \"int\"},\n    ],\n}\nSCHEMA_ID = 1\n```\n\n```python\nfrom glutemulo.kafka.producer import AvroKafka as Producer\nproductor = Producer(SCHEMA, SCHEMA_ID,bootstrap_servers=\"localhost:9092\")\nfuture = productor.produce('simple-topic-avro', dict(name='Un nombre', number1=10))\n```\n\nConsumer:\n```python\nfrom glutemulo.kafka.consumer import AvroKafka as Consumer\nconsumer = Consumer('simple-topic-avro', SCHEMA, SCHEMA_ID, bootstrap_servers=\"localhost:9092\")\nfor messages in consumer.consume():\n    for msg in messages:\n        print(msg)\n```\n\n## For testing\n\nYou can setup a Kafka Consumer using the kafka-console-consumer script that comes with Kafka.\n\n```bash\n$ bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.240:9092 --topic pylog --from-beginning\n\nthis is an awsome log\n```\n\n### Testing With KafkaCat\n\nYou ca use an application called KafkaCat.\n\nAfter the application is installed we will run it in consumer mode (which is the default).\n\n```bash\nkafkacat -b 192.168.240.41:9092 -t one-test\n```\n\nThis should not show anything yet because we haven't sent anything to our topic yet...\n\nTo send stuff we can copy any text file into our current directory and send it to our Kafka Topic. In another window, run the following command.\n\n```bash\n$ cat README | kafkacat -b 192.168.240.41 -t one-test\n```\nYou should see the output in the first window which has KafkaCat still running in consumer mode.\n\n\n## Links\n\n- [Zoonavigator](http://localhost:8004). Use 'zoo1' as connection string\n- [schema-registry-ui](http://localhost:8001)\n- [Rebrow](http://localhost:5001)\n- [kafka topics ui](http://localhost:8000)\n- [kafka rest proxy](http://localhost:8082)\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "MIT", "maintainer": "Geographica", "maintainer_email": "hello@geographica.com", "name": "geolibs-glutemulo", "package_url": "https://pypi.org/project/geolibs-glutemulo/", "platform": "", "project_url": "https://pypi.org/project/geolibs-glutemulo/", "project_urls": null, "release_url": "https://pypi.org/project/geolibs-glutemulo/0.1.3/", "requires_dist": ["kafka-python (>=1.4,<2.0)", "environs (>=4.1,<5.0)", "fastavro (>=0.21.23,<0.22.0)", "carto (>=1.4,<2.0); extra == \"carto\"", "psycopg2-binary (>=2.8,<3.0); extra == \"postgres\"", "redis (>=3.2,<4.0); extra == \"redis\"", "google-cloud-bigquery (>=1.21,<2.0)"], "requires_python": ">=3.6,<4.0", "summary": "GeoLibs data ingestor", "version": "0.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Glutemulo</h1>\n<p>A HA geo socio demo data ingestor</p>\n<h2>Usage</h2>\n<p>Read de <a href=\"examples\" rel=\"nofollow\">examples files</a>.</p>\n<p>We use environ vars. See <a href=\".env.example\" rel=\"nofollow\">Environ vars file example</a> for complete list,\nand examples.</p>\n<h3>Using producer to upload data to kafka</h3>\n<p>See python examples bellow. You must produce a dict with column_mame:value</p>\n<h3>Using the ingestor consumer</h3>\n<p>Use <code>gluto</code> docker and fill enviroment vars.</p>\n<p>Select the backend using <code>GLUTEMULO_BACKEND</code> and specific vars for it (database, host, etc).\nYou can select 2 backends: <code>postgres</code> or <code>carto</code>\nSee <a href=\".env.example\" rel=\"nofollow\">Environ vars file example</a> for complete list.</p>\n<p>Then set:</p>\n<ol>\n<li><code>GLUTEMULO_INGESTOR_DATASET</code><br>\nTable to upload data</li>\n<li><code>GLUTEMULO_INGESTOR_DATASET_COLUMNS</code><br>\nComma separted list of column names</li>\n</ol>\n<p>Now, create the table on backend or set <code>GLUTEMULO_INGESTOR_DATASET_DDL</code> and <code>GLUTEMULO_INGESTOR_DATASET_AUTOCREATE=False</code></p>\n<p>Then configure ingestor for kafka.\nFirst read the <a href=\"https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html\" rel=\"nofollow\">python-kafka doc</a>\nand then use the following vars:</p>\n<ol>\n<li><code>GLUTEMULO_INGESTOR_TOPIC</code><br>\nTopic to use</li>\n<li><code>GLUTEMULO_INGESTOR_BOOTSTRAP_SERVERS</code><br>\nList of servers to connect</li>\n<li><code>GLUTEMULO_INGESTOR_GROUP_ID</code><br>\nGroup id.</li>\n<li><code>GLUTEMULO_INGESTOR_AUTO_OFFSET_RESET</code><br>\nlatest or earliest.</li>\n<li><code>GLUTEMULO_INGESTOR_MAX_POLL_RECORDS</code><br>\nThe maximum number of records returned in a batch of messages</li>\n<li><code>GLUTEMULO_INGESTOR_FETCH_MIN_BYTES</code><br>\nMinimum amount of data the server should return for a fetch request, otherwise wait up to fetch_max_wait_ms for more data to accumulate. Default: 1</li>\n</ol>\n<p>For the docker, we include a <a href=\"docker-compose.yml\" rel=\"nofollow\">example docker-compose file</a>.\nRemember you can scale with same group_id</p>\n<pre>docker-compose scale <span class=\"nv\">gluto</span><span class=\"o\">=</span><span class=\"m\">3</span>\n</pre>\n<h2>Run flask demo</h2>\n<pre>$ <span class=\"nv\">FLASK_ENV</span><span class=\"o\">=</span>development flask run\n * Environment: development\n * Debug mode: on\n * Running on http://127.0.0.1:5000/ <span class=\"o\">(</span>Press CTRL+C to quit<span class=\"o\">)</span>\n * Restarting with stat\n * Debugger is active!\n * Debugger PIN: <span class=\"m\">194</span>-409-049\n</pre>\n<h2>Test</h2>\n<pre>$ http -j POST localhost:5000/v1/ <span class=\"nv\">uno</span><span class=\"o\">=</span><span class=\"m\">1</span> <span class=\"nv\">dos</span><span class=\"o\">=</span><span class=\"m\">2</span><span class=\"sb\">`</span>\nHTTP/1.0 <span class=\"m\">201</span> CREATED\nContent-Length: <span class=\"m\">13</span>\nContent-Type: text/html<span class=\"p\">;</span> <span class=\"nv\">charset</span><span class=\"o\">=</span>utf-8\nDate: Thu, <span class=\"m\">02</span> May <span class=\"m\">2019</span> <span class=\"m\">14</span>:56:07 GMT\nServer: Werkzeug/0.15.2 Python/3.7.2\n\nDATA Received\n</pre>\n<h2>Producer / Consumer</h2>\n<h3>Kafka + json</h3>\n<p>Async producer:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">glutemulo.kafka.producer</span> <span class=\"kn\">import</span> <span class=\"n\">JsonKafka</span>\n<span class=\"n\">productor</span> <span class=\"o\">=</span> <span class=\"n\">JsonKafka</span><span class=\"p\">(</span><span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s2\">\"localhost:9092\"</span><span class=\"p\">)</span>\n<span class=\"n\">future</span> <span class=\"o\">=</span> <span class=\"n\">productor</span><span class=\"o\">.</span><span class=\"n\">produce</span><span class=\"p\">(</span><span class=\"s1\">'simple-topic'</span><span class=\"p\">,</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">dos</span><span class=\"o\">=</span><span class=\"s1\">'BB'</span><span class=\"p\">))</span>\n</pre>\n<p>Consumer in batches:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">glutemulo.kafka.consumer</span> <span class=\"kn\">import</span> <span class=\"n\">JsonKafka</span>\n<span class=\"n\">consumer</span> <span class=\"o\">=</span> <span class=\"n\">JsonKafka</span><span class=\"p\">(</span><span class=\"s1\">'simple-topic'</span><span class=\"p\">,</span> <span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s2\">\"localhost:9092\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">msg</span> <span class=\"ow\">in</span> <span class=\"n\">consumer</span><span class=\"o\">.</span><span class=\"n\">consume</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">msg</span> <span class=\"ow\">in</span> <span class=\"n\">messages</span><span class=\"p\">:</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"p\">)</span>\n</pre>\n<h3>Kafka + Avro</h3>\n<p>sync producer:</p>\n<pre><span class=\"n\">SCHEMA</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"record\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"simpledata\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"doc\"</span><span class=\"p\">:</span> <span class=\"s2\">\"This is a sample Avro schema to get you started.\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"fields\"</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n        <span class=\"p\">{</span><span class=\"s2\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"name\"</span><span class=\"p\">,</span> <span class=\"s2\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"string\"</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"s2\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"number1\"</span><span class=\"p\">,</span> <span class=\"s2\">\"type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"int\"</span><span class=\"p\">},</span>\n    <span class=\"p\">],</span>\n<span class=\"p\">}</span>\n<span class=\"n\">SCHEMA_ID</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>\n</pre>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">glutemulo.kafka.producer</span> <span class=\"kn\">import</span> <span class=\"n\">AvroKafka</span> <span class=\"k\">as</span> <span class=\"n\">Producer</span>\n<span class=\"n\">productor</span> <span class=\"o\">=</span> <span class=\"n\">Producer</span><span class=\"p\">(</span><span class=\"n\">SCHEMA</span><span class=\"p\">,</span> <span class=\"n\">SCHEMA_ID</span><span class=\"p\">,</span><span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s2\">\"localhost:9092\"</span><span class=\"p\">)</span>\n<span class=\"n\">future</span> <span class=\"o\">=</span> <span class=\"n\">productor</span><span class=\"o\">.</span><span class=\"n\">produce</span><span class=\"p\">(</span><span class=\"s1\">'simple-topic-avro'</span><span class=\"p\">,</span> <span class=\"nb\">dict</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Un nombre'</span><span class=\"p\">,</span> <span class=\"n\">number1</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">))</span>\n</pre>\n<p>Consumer:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">glutemulo.kafka.consumer</span> <span class=\"kn\">import</span> <span class=\"n\">AvroKafka</span> <span class=\"k\">as</span> <span class=\"n\">Consumer</span>\n<span class=\"n\">consumer</span> <span class=\"o\">=</span> <span class=\"n\">Consumer</span><span class=\"p\">(</span><span class=\"s1\">'simple-topic-avro'</span><span class=\"p\">,</span> <span class=\"n\">SCHEMA</span><span class=\"p\">,</span> <span class=\"n\">SCHEMA_ID</span><span class=\"p\">,</span> <span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"s2\">\"localhost:9092\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">messages</span> <span class=\"ow\">in</span> <span class=\"n\">consumer</span><span class=\"o\">.</span><span class=\"n\">consume</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">msg</span> <span class=\"ow\">in</span> <span class=\"n\">messages</span><span class=\"p\">:</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"p\">)</span>\n</pre>\n<h2>For testing</h2>\n<p>You can setup a Kafka Consumer using the kafka-console-consumer script that comes with Kafka.</p>\n<pre>$ bin/kafka-console-consumer.sh --bootstrap-server <span class=\"m\">192</span>.168.1.240:9092 --topic pylog --from-beginning\n\nthis is an awsome log\n</pre>\n<h3>Testing With KafkaCat</h3>\n<p>You ca use an application called KafkaCat.</p>\n<p>After the application is installed we will run it in consumer mode (which is the default).</p>\n<pre>kafkacat -b <span class=\"m\">192</span>.168.240.41:9092 -t one-test\n</pre>\n<p>This should not show anything yet because we haven't sent anything to our topic yet...</p>\n<p>To send stuff we can copy any text file into our current directory and send it to our Kafka Topic. In another window, run the following command.</p>\n<pre>$ cat README <span class=\"p\">|</span> kafkacat -b <span class=\"m\">192</span>.168.240.41 -t one-test\n</pre>\n<p>You should see the output in the first window which has KafkaCat still running in consumer mode.</p>\n<h2>Links</h2>\n<ul>\n<li><a href=\"http://localhost:8004\" rel=\"nofollow\">Zoonavigator</a>. Use 'zoo1' as connection string</li>\n<li><a href=\"http://localhost:8001\" rel=\"nofollow\">schema-registry-ui</a></li>\n<li><a href=\"http://localhost:5001\" rel=\"nofollow\">Rebrow</a></li>\n<li><a href=\"http://localhost:8000\" rel=\"nofollow\">kafka topics ui</a></li>\n<li><a href=\"http://localhost:8082\" rel=\"nofollow\">kafka rest proxy</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6800482, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ae67af190b88ac94a37cfc87a05c271b", "sha256": "d21717bee5300791a0bd414b86a671485813f6f4896737445875b59dadcb5120"}, "downloads": -1, "filename": "geolibs_glutemulo-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ae67af190b88ac94a37cfc87a05c271b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13365, "upload_time": "2019-05-23T14:00:11", "upload_time_iso_8601": "2019-05-23T14:00:11.858615Z", "url": "https://files.pythonhosted.org/packages/15/a7/d2b9642bfa52b02138bb66f88c89c9036f38c7315f52c2cc1e4f3628551a/geolibs_glutemulo-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2185ff69f2a483d6d71d28638386cffa", "sha256": "5230221faedbbeffb1f949af15ec2ebac76736842a45133923812c7780e15ed3"}, "downloads": -1, "filename": "geolibs-glutemulo-0.1.0.tar.gz", "has_sig": false, "md5_digest": "2185ff69f2a483d6d71d28638386cffa", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 11669, "upload_time": "2019-05-23T14:00:09", "upload_time_iso_8601": "2019-05-23T14:00:09.534356Z", "url": "https://files.pythonhosted.org/packages/1a/5f/20afe441bdd9d9d5e0d88badd627744f332a7f39844164657a6a7a7d2916/geolibs-glutemulo-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "35077e8aa5b4ea501edb3a3d4f577949", "sha256": "3f55dd7dc7c9efc041b2f4c5a1aa0557a55aa34cf6334e415cff87ea6a033007"}, "downloads": -1, "filename": "geolibs_glutemulo-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "35077e8aa5b4ea501edb3a3d4f577949", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13450, "upload_time": "2019-05-24T08:31:26", "upload_time_iso_8601": "2019-05-24T08:31:26.922318Z", "url": "https://files.pythonhosted.org/packages/b4/3d/4bdedca535279d8c0c820675d2485ab92076d9cf6eb06cf0525810f421bf/geolibs_glutemulo-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "53cae36c67b52567c309a304f7bd1de2", "sha256": "c0e4cfcb2e15dc9607dedd56d06df7fecd42ac1731744a436ed830758b3dcc32"}, "downloads": -1, "filename": "geolibs-glutemulo-0.1.1.tar.gz", "has_sig": false, "md5_digest": "53cae36c67b52567c309a304f7bd1de2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 11721, "upload_time": "2019-05-24T08:31:25", "upload_time_iso_8601": "2019-05-24T08:31:25.728889Z", "url": "https://files.pythonhosted.org/packages/52/ee/a01dedc94a32d933bfc39317bd134765c65c792fcd0938685d9b455b0ba4/geolibs-glutemulo-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "d585be84442ac79f38124af3c8ad1417", "sha256": "7ea345257f9e869f71baddc9d6591d7869f0156a484598282be4a0b7ecdda24c"}, "downloads": -1, "filename": "geolibs_glutemulo-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "d585be84442ac79f38124af3c8ad1417", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 14920, "upload_time": "2019-08-26T09:28:51", "upload_time_iso_8601": "2019-08-26T09:28:51.132605Z", "url": "https://files.pythonhosted.org/packages/5a/05/92d5c4bfb1db18e9f96aa97e8cbc4c2845ed86ba9742fdfc046a9dfc2efb/geolibs_glutemulo-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e593d64161333806ab263e83ac41e064", "sha256": "7e5e20104f1d7907cc00d0df1d68af9ccbf91e066ca0b3d8f8d5f5774f27689a"}, "downloads": -1, "filename": "geolibs-glutemulo-0.1.2.tar.gz", "has_sig": false, "md5_digest": "e593d64161333806ab263e83ac41e064", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 12797, "upload_time": "2019-08-26T09:28:49", "upload_time_iso_8601": "2019-08-26T09:28:49.632436Z", "url": "https://files.pythonhosted.org/packages/a4/54/1bec341b5c16633f06cea8344377c2958bfb09c93bdcb2fa4870a07b2a86/geolibs-glutemulo-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "ef0878751a5e458c9f7769c04b7544f8", "sha256": "f84cf1230539ef4e9cf400a291da4c234bc6c7b42f42f16a65c196a551995716"}, "downloads": -1, "filename": "geolibs_glutemulo-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "ef0878751a5e458c9f7769c04b7544f8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 15522, "upload_time": "2019-11-06T10:28:35", "upload_time_iso_8601": "2019-11-06T10:28:35.146799Z", "url": "https://files.pythonhosted.org/packages/40/66/51e1e2f375bbd2e867329d69fa4f04fabea59bf043dde7b2da36589dab79/geolibs_glutemulo-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6d0ab80a5090e27d6711493b0e04bf6b", "sha256": "53af8d9eb0bef1756d63bca6ae51f02b4c4dd54e6b38e6bcdd9dd2e5d6faf5c6"}, "downloads": -1, "filename": "geolibs-glutemulo-0.1.3.tar.gz", "has_sig": false, "md5_digest": "6d0ab80a5090e27d6711493b0e04bf6b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 13158, "upload_time": "2019-11-06T10:28:33", "upload_time_iso_8601": "2019-11-06T10:28:33.455791Z", "url": "https://files.pythonhosted.org/packages/a3/9e/f94a2897eadc34f8345c3e37ac7289259e1e0578422064e062fba64b78ef/geolibs-glutemulo-0.1.3.tar.gz", "yanked": false}], "0.2.0.dev1": [{"comment_text": "", "digests": {"md5": "646d6762ec50909ffc40ca4586d72009", "sha256": "2f715a65767ece13078c5a200ab59bda70734038852ed6becd81998436dd2abc"}, "downloads": -1, "filename": "geolibs_glutemulo-0.2.0.dev1-py3-none-any.whl", "has_sig": false, "md5_digest": "646d6762ec50909ffc40ca4586d72009", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 16788, "upload_time": "2020-03-12T16:51:46", "upload_time_iso_8601": "2020-03-12T16:51:46.517607Z", "url": "https://files.pythonhosted.org/packages/1b/11/2e1ec4126c28ce118fdc7a63b536f631ef5a29aa3e7547f50ec847592a79/geolibs_glutemulo-0.2.0.dev1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cc050e43e3ef630de244c57907b39ed1", "sha256": "f8103a0766d5dc6dae3d37c257d2554e78c0def16599020e5bf011bcbc13db70"}, "downloads": -1, "filename": "geolibs-glutemulo-0.2.0.dev1.tar.gz", "has_sig": false, "md5_digest": "cc050e43e3ef630de244c57907b39ed1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 14002, "upload_time": "2020-03-12T16:51:44", "upload_time_iso_8601": "2020-03-12T16:51:44.690783Z", "url": "https://files.pythonhosted.org/packages/7a/5b/d399cbd87e2ae342e0d6c7fe2e6150624e1af516e8aa12fa638a73e0610e/geolibs-glutemulo-0.2.0.dev1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ef0878751a5e458c9f7769c04b7544f8", "sha256": "f84cf1230539ef4e9cf400a291da4c234bc6c7b42f42f16a65c196a551995716"}, "downloads": -1, "filename": "geolibs_glutemulo-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "ef0878751a5e458c9f7769c04b7544f8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 15522, "upload_time": "2019-11-06T10:28:35", "upload_time_iso_8601": "2019-11-06T10:28:35.146799Z", "url": "https://files.pythonhosted.org/packages/40/66/51e1e2f375bbd2e867329d69fa4f04fabea59bf043dde7b2da36589dab79/geolibs_glutemulo-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6d0ab80a5090e27d6711493b0e04bf6b", "sha256": "53af8d9eb0bef1756d63bca6ae51f02b4c4dd54e6b38e6bcdd9dd2e5d6faf5c6"}, "downloads": -1, "filename": "geolibs-glutemulo-0.1.3.tar.gz", "has_sig": false, "md5_digest": "6d0ab80a5090e27d6711493b0e04bf6b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 13158, "upload_time": "2019-11-06T10:28:33", "upload_time_iso_8601": "2019-11-06T10:28:33.455791Z", "url": "https://files.pythonhosted.org/packages/a3/9e/f94a2897eadc34f8345c3e37ac7289259e1e0578422064e062fba64b78ef/geolibs-glutemulo-0.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:58:03 2020"}