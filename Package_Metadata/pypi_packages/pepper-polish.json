{"info": {"author": "Kishwar Shafin", "author_email": "kishwar.shafin@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# P.E.P.P.E.R.\n###### Program for Evaluating Patterns in the Pileups of Erroneous Reads\n\n[![Build Status](https://travis-ci.com/kishwarshafin/pepper.svg?branch=master)](https://travis-ci.com/kishwarshafin/pepper)\n[![PyPI version](https://badge.fury.io/py/pepper-polish.svg)](https://badge.fury.io/py/pepper-polish)\n\n`P.E.P.P.E.R.` is a deep neural network based polisher designed to work with Oxford Nanopore Sequencing technology. `P.E.P.P.E.R.` uses a Recurrent Neural Network (RNN) based encoder-decoder model to call a consensus sequence from the summary statistics of each genomic position. The local realignment process using [SSW](https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library) is used and the module does not require any prior polishing with other tools (i.e. racon).\n\n\u00a9 2020 Kishwar Shafin, Trevor Pesout, Miten Jain, Benedict Paten. <br/>\nComputational Genomics Lab (CGL), University of California, Santa Cruz.\n\n## Workflow\n * Sequence a genome and get a basecalled reads file (`reads.fastq`).\n * Use an assembler to get an assembly from the basecalled data (`assembly.fa`).\n * Use [minimap2](https://github.com/lh3/minimap2) to map `reads.fastq` to `assembly.fa` and get a bam file (`reads_2_assembly.bam`).\n * Use `pepper polish` to polish a genome.\n <p align=\"center\">\n <img src=\"img/PEPPER_pipeline.svg\" alt=\"pipeline.svg\" height=\"640p\">\n </p>\n\n\n## Installation\nWe recommend using `Linux` environment to run `PEPPER`.\n\n### Install dependencies\n```bash\nsudo apt-get -y install cmake make git gcc g++ autoconf bzip2 lzma-dev zlib1g-dev \\\nlibcurl4-openssl-dev libpthread-stubs0-dev libbz2-dev \\\nliblzma-dev libhdf5-dev python3-pip python3-virtualenv\n```\n\n### <img src=\"img/pip_logo.svg\" alt=\"\" height=\"20p\"> Install using pip\n```bash\npython3 -m pip install pepper-polish\n# if you get permission error, then try:\npython3 -m pip install --user pepper-polish\n\npython3 -m pepper.pepper --help\npython3 -m pepper.pepper polish --help\n```\nIf you want to directly call `PEPPER`. You can do:\n```bash\necho 'export PATH=\"$(python3 -m site --user-base)/bin\":$PATH' >> ~/.bashrc\nsource ~/.bashrc\n\npepper --version\npepper --help\npepper polish --help\n```\n### <img src=\"img/terminal.svg\" alt=\"\" height=\"20p\"> Install from source\nWe recommend using `virtualenv` to run pepper:\n```bash\ngit clone https://github.com/kishwarshafin/pepper.git\ncd pepper\nmake install\n. ./vnev/bin/activate\n\npepper --help\npepper polish --help\n```\n\n## Usage\n\nPolishing involves three sub-processes `make_images`, `call_consensus`, `stitch`. You can run all three steps using `pepper polish` or run each step separately.\n\n###  Download models\nYou can download all available `PEPPER` models in one command.\n\n```bash\npepper download_models \\\n--output_dir </path/to/pepper_model_directory/>\n```\n###  One step polishing\n#### Case 1: CPU machine\nIf you are using a CPU-only machine you ca use the following command:\n```bash\npepper polish \\\n--bam </path/to/reads_2_draft_assembly.bam> \\\n--fasta <path/to/draft_assembly.fasta> \\\n--model_path <path/to/pepper/models/XXX.pkl> \\\n--output_file <path/to/output_polished_sequence/output_file_prefix> \\\n--threads <total_threads> \\\n--batch_size 128\n```\n\n#### Case 2: GPU machine\nYou can check your `CUDA` availability by running `pepper torch_stat`. If you have CUDA available and GPU devices on your machine, you can do:\n```bash\npepper polish \\\n--bam </path/to/reads_2_draft_assembly.bam> \\\n--fasta <path/to/draft_assembly.fasta> \\\n--model_path <path/to/pepper/models/XXX.pkl> \\\n--output_file <path/to/output_polished_sequence/output_file_prefix> \\\n--threads <number_of_threads> \\\n--batch_size 512 \\\n--gpu \\\n--num_workers <num_workers>\n```\nYou can select which `CUDA` devices to use with `--device_ids` parameter.\n\n```bash\nARGUMENT DETAILS:\n  -h, --help            show this help message and exit\n  -b BAM, --bam BAM     BAM file containing mapping between reads and the\n                        draft assembly.\n  -f FASTA, --fasta FASTA\n                        FASTA file containing the draft assembly.\n  -m MODEL_PATH, --model_path MODEL_PATH\n                        Path to a trained model.\n  -o OUTPUT_FILE, --output_file OUTPUT_FILE\n                        Path to output file with an expected prefix (i.e. -o\n                        ./outputs/polished_genome)\n  -t THREADS, --threads THREADS\n                        Number of threads to use. Default is 5.\n  -r REGION, --region REGION\n                        Region in [contig_name:start-end] format\n  -bs BATCH_SIZE, --batch_size BATCH_SIZE\n                        Batch size for testing, default is 100. Suggested\n                        values: 256/512/1024.\n  -g, --gpu             If set then PyTorch will use GPUs for inference. CUDA\n                        required.\n  -dx, --distributed_off\n                        Turn off distributed inference. This mode will disable\n                        the use of multiple callers.\n  -d_ids DEVICE_IDS, --device_ids DEVICE_IDS\n                        List of gpu device ids to use for inference. Only used\n                        in distributed setting. Example usage: --device_ids\n                        0,1,2 (this will create three callers in id 'cuda:0,\n                        cuda:1 and cuda:2' If none then it will use all\n                        available devices.\n  -w NUM_WORKERS, --num_workers NUM_WORKERS\n                        Number of workers for loading images. Default is 4.\n  -tpc THREADS_PER_CALLER, --threads_per_caller THREADS_PER_CALLER\n                        Total threads to be used per caller. A sane value\n                        would be num_callers * threads <= total_threads.\n  -c CALLERS, --callers CALLERS\n                        Total number of callers to spawn if doing CPU\n                        inference in distributed mode.\n```\n\n## Results\n\n#### PEPPER achieves lower error rate than ONT suggested pipeline.\nWe compared `PEPPER` against `Racon-Medaka` pipeline and we demonstrate significantly better results for microbial genomes. We used Staphylococcus Aureus samples to evaluate these two pipelines. The PEPPER microbial model was trained on samples excluding Staphylococcus Aureus. We used `r941_prom_high` model to run `Medaka`.\n<p align=\"center\">\n<img src=\"img/PEPPER_error_rate.png\" alt=\"PEPPER_error_rate.png\" height=\"420\">\n</p>\n\n#### New R10 chemistry shows further improvement in polishing results\nThe new `R10` data is now available for `MinION` and we polished the assembly generated with `R9` data using the `R10` reads. The R10 data provides significant improvement in overall quality of the genome.\n<p align=\"center\">\n<img src=\"img/PEPPER_chemistry.png\" alt=\"PEPPER_chemistry.png\" height=\"420p\">\n</p>\n\n## Acknowledgement\nWe are thankful to the developers of these packages: </br>\n* [Medaka](https://github.com/nanoporetech/medaka)\n* [htslib & samtools](http://www.htslib.org/)\n* [ssw library](https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library)\n* [hdf5 python (h5py)](https://www.h5py.org/)\n* [pytorch](https://pytorch.org/)\n\n## Fun Fact\n<img src=\"https://vignette.wikia.nocookie.net/marveldatabase/images/7/72/Anthony_Stark_%28Earth-616%29_from_Iron_Man_Vol_5_2_002.jpg/revision/latest?cb=20130407031815\" alt=\"guppy235\" width=\"240p\"> <br/>\n\nThe name \"P.E.P.P.E.R.\" is also inspired from an A.I. created by Tony Stark in the  Marvel Comics (Earth-616). PEPPER is named after Tony Stark's then friend and the CEO of Resilient, Pepper Potts.\n\n\n\u00a9 2020 Kishwar Shafin, Trevor Pesout, Miten Jain, Benedict Paten.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kishwarshafin/pepper", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pepper-polish", "package_url": "https://pypi.org/project/pepper-polish/", "platform": "", "project_url": "https://pypi.org/project/pepper-polish/", "project_urls": {"Homepage": "https://github.com/kishwarshafin/pepper"}, "release_url": "https://pypi.org/project/pepper-polish/0.0.6/", "requires_dist": ["h5py", "tqdm", "numpy", "wget", "torch", "torchvision", "torchnet", "pyyaml", "onnx", "onnxruntime", "hyperopt"], "requires_python": ">=3.5.*", "summary": "RNN based standalone assembly polisher.", "version": "0.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>P.E.P.P.E.R.</h1>\n<h6>Program for Evaluating Patterns in the Pileups of Erroneous Reads</h6>\n<p><a href=\"https://travis-ci.com/kishwarshafin/pepper\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9495994de2d1344146bfd39ae55d0279549dd0c5/68747470733a2f2f7472617669732d63692e636f6d2f6b69736877617273686166696e2f7065707065722e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://badge.fury.io/py/pepper-polish\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3419a76855b7fe59bef9e49c19511952c5aac7da/68747470733a2f2f62616467652e667572792e696f2f70792f7065707065722d706f6c6973682e737667\"></a></p>\n<p><code>P.E.P.P.E.R.</code> is a deep neural network based polisher designed to work with Oxford Nanopore Sequencing technology. <code>P.E.P.P.E.R.</code> uses a Recurrent Neural Network (RNN) based encoder-decoder model to call a consensus sequence from the summary statistics of each genomic position. The local realignment process using <a href=\"https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library\" rel=\"nofollow\">SSW</a> is used and the module does not require any prior polishing with other tools (i.e. racon).</p>\n<p>\u00a9 2020 Kishwar Shafin, Trevor Pesout, Miten Jain, Benedict Paten. <br>\nComputational Genomics Lab (CGL), University of California, Santa Cruz.</p>\n<h2>Workflow</h2>\n<ul>\n<li>Sequence a genome and get a basecalled reads file (<code>reads.fastq</code>).</li>\n<li>Use an assembler to get an assembly from the basecalled data (<code>assembly.fa</code>).</li>\n<li>Use <a href=\"https://github.com/lh3/minimap2\" rel=\"nofollow\">minimap2</a> to map <code>reads.fastq</code> to <code>assembly.fa</code> and get a bam file (<code>reads_2_assembly.bam</code>).</li>\n<li>Use <code>pepper polish</code> to polish a genome.</li>\n</ul>\n <p align=\"center\">\n <img alt=\"pipeline.svg\" height=\"640p\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/387024f4d1c4a68a0dad89cf4b91e76b4818f1d0/696d672f5045505045525f706970656c696e652e737667\">\n </p>\n<h2>Installation</h2>\n<p>We recommend using <code>Linux</code> environment to run <code>PEPPER</code>.</p>\n<h3>Install dependencies</h3>\n<pre>sudo apt-get -y install cmake make git gcc g++ autoconf bzip2 lzma-dev zlib1g-dev <span class=\"se\">\\</span>\nlibcurl4-openssl-dev libpthread-stubs0-dev libbz2-dev <span class=\"se\">\\</span>\nliblzma-dev libhdf5-dev python3-pip python3-virtualenv\n</pre>\n<h3><img alt=\"\" height=\"20p\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/db210ae95694522fe40a72c8da72e38950dba7b0/696d672f7069705f6c6f676f2e737667\"> Install using pip</h3>\n<pre>python3 -m pip install pepper-polish\n<span class=\"c1\"># if you get permission error, then try:</span>\npython3 -m pip install --user pepper-polish\n\npython3 -m pepper.pepper --help\npython3 -m pepper.pepper polish --help\n</pre>\n<p>If you want to directly call <code>PEPPER</code>. You can do:</p>\n<pre><span class=\"nb\">echo</span> <span class=\"s1\">'export PATH=\"$(python3 -m site --user-base)/bin\":$PATH'</span> &gt;&gt; ~/.bashrc\n<span class=\"nb\">source</span> ~/.bashrc\n\npepper --version\npepper --help\npepper polish --help\n</pre>\n<h3><img alt=\"\" height=\"20p\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/26de0a9872a1556b3f6f4d0839046a5b4438bd72/696d672f7465726d696e616c2e737667\"> Install from source</h3>\n<p>We recommend using <code>virtualenv</code> to run pepper:</p>\n<pre>git clone https://github.com/kishwarshafin/pepper.git\n<span class=\"nb\">cd</span> pepper\nmake install\n. ./vnev/bin/activate\n\npepper --help\npepper polish --help\n</pre>\n<h2>Usage</h2>\n<p>Polishing involves three sub-processes <code>make_images</code>, <code>call_consensus</code>, <code>stitch</code>. You can run all three steps using <code>pepper polish</code> or run each step separately.</p>\n<h3>Download models</h3>\n<p>You can download all available <code>PEPPER</code> models in one command.</p>\n<pre>pepper download_models <span class=\"se\">\\</span>\n--output_dir &lt;/path/to/pepper_model_directory/&gt;\n</pre>\n<h3>One step polishing</h3>\n<h4>Case 1: CPU machine</h4>\n<p>If you are using a CPU-only machine you ca use the following command:</p>\n<pre>pepper polish <span class=\"se\">\\</span>\n--bam &lt;/path/to/reads_2_draft_assembly.bam&gt; <span class=\"se\">\\</span>\n--fasta &lt;path/to/draft_assembly.fasta&gt; <span class=\"se\">\\</span>\n--model_path &lt;path/to/pepper/models/XXX.pkl&gt; <span class=\"se\">\\</span>\n--output_file &lt;path/to/output_polished_sequence/output_file_prefix&gt; <span class=\"se\">\\</span>\n--threads &lt;total_threads&gt; <span class=\"se\">\\</span>\n--batch_size <span class=\"m\">128</span>\n</pre>\n<h4>Case 2: GPU machine</h4>\n<p>You can check your <code>CUDA</code> availability by running <code>pepper torch_stat</code>. If you have CUDA available and GPU devices on your machine, you can do:</p>\n<pre>pepper polish <span class=\"se\">\\</span>\n--bam &lt;/path/to/reads_2_draft_assembly.bam&gt; <span class=\"se\">\\</span>\n--fasta &lt;path/to/draft_assembly.fasta&gt; <span class=\"se\">\\</span>\n--model_path &lt;path/to/pepper/models/XXX.pkl&gt; <span class=\"se\">\\</span>\n--output_file &lt;path/to/output_polished_sequence/output_file_prefix&gt; <span class=\"se\">\\</span>\n--threads &lt;number_of_threads&gt; <span class=\"se\">\\</span>\n--batch_size <span class=\"m\">512</span> <span class=\"se\">\\</span>\n--gpu <span class=\"se\">\\</span>\n--num_workers &lt;num_workers&gt;\n</pre>\n<p>You can select which <code>CUDA</code> devices to use with <code>--device_ids</code> parameter.</p>\n<pre>ARGUMENT DETAILS:\n  -h, --help            show this <span class=\"nb\">help</span> message and <span class=\"nb\">exit</span>\n  -b BAM, --bam BAM     BAM file containing mapping between reads and the\n                        draft assembly.\n  -f FASTA, --fasta FASTA\n                        FASTA file containing the draft assembly.\n  -m MODEL_PATH, --model_path MODEL_PATH\n                        Path to a trained model.\n  -o OUTPUT_FILE, --output_file OUTPUT_FILE\n                        Path to output file with an expected prefix <span class=\"o\">(</span>i.e. -o\n                        ./outputs/polished_genome<span class=\"o\">)</span>\n  -t THREADS, --threads THREADS\n                        Number of threads to use. Default is <span class=\"m\">5</span>.\n  -r REGION, --region REGION\n                        Region in <span class=\"o\">[</span>contig_name:start-end<span class=\"o\">]</span> format\n  -bs BATCH_SIZE, --batch_size BATCH_SIZE\n                        Batch size <span class=\"k\">for</span> testing, default is <span class=\"m\">100</span>. Suggested\n                        values: <span class=\"m\">256</span>/512/1024.\n  -g, --gpu             If <span class=\"nb\">set</span> <span class=\"k\">then</span> PyTorch will use GPUs <span class=\"k\">for</span> inference. CUDA\n                        required.\n  -dx, --distributed_off\n                        Turn off distributed inference. This mode will disable\n                        the use of multiple callers.\n  -d_ids DEVICE_IDS, --device_ids DEVICE_IDS\n                        List of gpu device ids to use <span class=\"k\">for</span> inference. Only used\n                        in distributed setting. Example usage: --device_ids\n                        <span class=\"m\">0</span>,1,2 <span class=\"o\">(</span>this will create three callers in id <span class=\"s1\">'cuda:0,</span>\n<span class=\"s1\">                        cuda:1 and cuda:2'</span> If none <span class=\"k\">then</span> it will use all\n                        available devices.\n  -w NUM_WORKERS, --num_workers NUM_WORKERS\n                        Number of workers <span class=\"k\">for</span> loading images. Default is <span class=\"m\">4</span>.\n  -tpc THREADS_PER_CALLER, --threads_per_caller THREADS_PER_CALLER\n                        Total threads to be used per caller. A sane value\n                        would be num_callers * threads &lt;<span class=\"o\">=</span> total_threads.\n  -c CALLERS, --callers CALLERS\n                        Total number of callers to spawn <span class=\"k\">if</span> doing CPU\n                        inference in distributed mode.\n</pre>\n<h2>Results</h2>\n<h4>PEPPER achieves lower error rate than ONT suggested pipeline.</h4>\n<p>We compared <code>PEPPER</code> against <code>Racon-Medaka</code> pipeline and we demonstrate significantly better results for microbial genomes. We used Staphylococcus Aureus samples to evaluate these two pipelines. The PEPPER microbial model was trained on samples excluding Staphylococcus Aureus. We used <code>r941_prom_high</code> model to run <code>Medaka</code>.</p>\n<p align=\"center\">\n<img alt=\"PEPPER_error_rate.png\" height=\"420\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c2eaba761027e959c267c797d80e278e1b05e5ff/696d672f5045505045525f6572726f725f726174652e706e67\">\n</p>\n<h4>New R10 chemistry shows further improvement in polishing results</h4>\n<p>The new <code>R10</code> data is now available for <code>MinION</code> and we polished the assembly generated with <code>R9</code> data using the <code>R10</code> reads. The R10 data provides significant improvement in overall quality of the genome.</p>\n<p align=\"center\">\n<img alt=\"PEPPER_chemistry.png\" height=\"420p\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/64a5f8c0376a3ade91f33151f58b8f39470355a5/696d672f5045505045525f6368656d69737472792e706e67\">\n</p>\n<h2>Acknowledgement</h2>\n<p>We are thankful to the developers of these packages: <br></p>\n<ul>\n<li><a href=\"https://github.com/nanoporetech/medaka\" rel=\"nofollow\">Medaka</a></li>\n<li><a href=\"http://www.htslib.org/\" rel=\"nofollow\">htslib &amp; samtools</a></li>\n<li><a href=\"https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library\" rel=\"nofollow\">ssw library</a></li>\n<li><a href=\"https://www.h5py.org/\" rel=\"nofollow\">hdf5 python (h5py)</a></li>\n<li><a href=\"https://pytorch.org/\" rel=\"nofollow\">pytorch</a></li>\n</ul>\n<h2>Fun Fact</h2>\n<p><img alt=\"guppy235\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4f2ae3c74d5973fee28a3eb739c2df4a56f27839/68747470733a2f2f7669676e657474652e77696b69612e6e6f636f6f6b69652e6e65742f6d617276656c64617461626173652f696d616765732f372f37322f416e74686f6e795f537461726b5f25323845617274682d3631362532395f66726f6d5f49726f6e5f4d616e5f566f6c5f355f325f3030322e6a70672f7265766973696f6e2f6c61746573743f63623d3230313330343037303331383135\" width=\"240p\"> <br></p>\n<p>The name \"P.E.P.P.E.R.\" is also inspired from an A.I. created by Tony Stark in the  Marvel Comics (Earth-616). PEPPER is named after Tony Stark's then friend and the CEO of Resilient, Pepper Potts.</p>\n<p>\u00a9 2020 Kishwar Shafin, Trevor Pesout, Miten Jain, Benedict Paten.</p>\n\n          </div>"}, "last_serial": 6748798, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "9b4954e0780b843e98f179d6bf9478db", "sha256": "3cb8d2af07a831ab9c86af2cf421aa85f7cde720d21323e3294473b17778e3e2"}, "downloads": -1, "filename": "pepper_polish-0.0.1-cp36-cp36m-macosx_10_9_x86_64.whl", "has_sig": false, "md5_digest": "9b4954e0780b843e98f179d6bf9478db", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.5.*", "size": 445591, "upload_time": "2020-02-23T17:25:39", "upload_time_iso_8601": "2020-02-23T17:25:39.882475Z", "url": "https://files.pythonhosted.org/packages/32/d0/7898e50a163fa91a2d11fa2faa3948cd2d599907543d59032c041ad4ee6d/pepper_polish-0.0.1-cp36-cp36m-macosx_10_9_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "996e66ebb316eb46ee6854c3d9779157", "sha256": "cb831728336c8dba6a6bc01d97cd6bc5580527cc02c7e60e730e0e15a2f5ebb1"}, "downloads": -1, "filename": "pepper_polish-0.0.1-py3.6-macosx-10.9-x86_64.egg", "has_sig": false, "md5_digest": "996e66ebb316eb46ee6854c3d9779157", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.5.*", "size": 520692, "upload_time": "2020-03-03T22:49:18", "upload_time_iso_8601": "2020-03-03T22:49:18.598417Z", "url": "https://files.pythonhosted.org/packages/53/00/dd2f471fbafb5bc7b77c4874a917378f69e29195b8f5b035ac5320f3c66b/pepper_polish-0.0.1-py3.6-macosx-10.9-x86_64.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "4ab82c697a9f5e1b1f2ece3fa808289d", "sha256": "6cd749364dfecff8986a9972fabe2f825a0047a0e8bc96853cc4747a6f6b0366"}, "downloads": -1, "filename": "pepper_polish-0.0.1.tar.gz", "has_sig": false, "md5_digest": "4ab82c697a9f5e1b1f2ece3fa808289d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.*", "size": 575696, "upload_time": "2020-02-23T17:25:48", "upload_time_iso_8601": "2020-02-23T17:25:48.801523Z", "url": "https://files.pythonhosted.org/packages/31/34/63b9f97acf36790039200752e50ab25ca6cf049f71a367d29c005cca30a9/pepper_polish-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "be430d21d5225efd3b1a6aaef9ff9952", "sha256": "28775f24dafc60d7bde68fd1ec5572a5079774fe14f2571c4a88f24aa5b3aef9"}, "downloads": -1, "filename": "pepper_polish-0.0.2-cp36-cp36m-macosx_10_9_x86_64.whl", "has_sig": false, "md5_digest": "be430d21d5225efd3b1a6aaef9ff9952", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.5.*", "size": 445833, "upload_time": "2020-03-03T22:49:17", "upload_time_iso_8601": "2020-03-03T22:49:17.482794Z", "url": "https://files.pythonhosted.org/packages/0a/8d/3b1018336bfe37ad5a4527606401dc934e7387feffa793d208b1cdb5c1e1/pepper_polish-0.0.2-cp36-cp36m-macosx_10_9_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ee96f962f262b62205354be289ad6af3", "sha256": "e8cdc8858ec4d1ed30ce5120f9c86426c9aa07ef4aea501ffaca4ddca7c551ab"}, "downloads": -1, "filename": "pepper_polish-0.0.2-py3.6-macosx-10.9-x86_64.egg", "has_sig": false, "md5_digest": "ee96f962f262b62205354be289ad6af3", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.5.*", "size": 520739, "upload_time": "2020-03-03T22:51:33", "upload_time_iso_8601": "2020-03-03T22:51:33.626163Z", "url": "https://files.pythonhosted.org/packages/5a/69/89972751a96086897bed240bfa37f697303a613a68db27ecee90720c35b9/pepper_polish-0.0.2-py3.6-macosx-10.9-x86_64.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "9c6bc4814283bd51e33548e90c87c0c6", "sha256": "21225b0768df4beac0a51bcc786b54a60592d71c479b5c9d98d5bd0aa8624028"}, "downloads": -1, "filename": "pepper_polish-0.0.2.tar.gz", "has_sig": false, "md5_digest": "9c6bc4814283bd51e33548e90c87c0c6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.*", "size": 536246, "upload_time": "2020-03-03T22:49:19", "upload_time_iso_8601": "2020-03-03T22:49:19.740847Z", "url": "https://files.pythonhosted.org/packages/53/c6/add741abe68f490cb0ac0e309c42cce3cd5d5d75f4512abf6a51d5e8f671/pepper_polish-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "4fd2aa4cf2aa6c880971367ad5f70005", "sha256": "1f3fefaf6b673f5c9632689fe1084ce9c1eef25d9525477b55cf9b4cdda9f3cf"}, "downloads": -1, "filename": "pepper_polish-0.0.3-cp36-cp36m-macosx_10_9_x86_64.whl", "has_sig": false, "md5_digest": "4fd2aa4cf2aa6c880971367ad5f70005", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.5.*", "size": 445836, "upload_time": "2020-03-03T22:54:15", "upload_time_iso_8601": "2020-03-03T22:54:15.852603Z", "url": "https://files.pythonhosted.org/packages/fa/66/31114d81f536d2aa6776b09277272d1ae2922864b415591a27337af7d12a/pepper_polish-0.0.3-cp36-cp36m-macosx_10_9_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f7798b6c36f4157f654e27fb81601016", "sha256": "9a7ac34b17ed96fa88db6160b2fb4f855fb1596c96d4a72832d0995616c4a5fb"}, "downloads": -1, "filename": "pepper_polish-0.0.3.tar.gz", "has_sig": false, "md5_digest": "f7798b6c36f4157f654e27fb81601016", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.*", "size": 536242, "upload_time": "2020-03-03T22:54:16", "upload_time_iso_8601": "2020-03-03T22:54:16.892794Z", "url": "https://files.pythonhosted.org/packages/e0/57/200f0e4930da9cb874f07764577a4b400dec32f59dc4694066fc6e40d56f/pepper_polish-0.0.3.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "d704a24c5c56c94bfbe392a9dc9f369d", "sha256": "03c30b6c9aadbd0de4e5ea95bcfd234a41722cab010142e38b9fcd94c3a9753f"}, "downloads": -1, "filename": "pepper_polish-0.0.5-cp36-cp36m-macosx_10_9_x86_64.whl", "has_sig": false, "md5_digest": "d704a24c5c56c94bfbe392a9dc9f369d", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.5.*", "size": 446470, "upload_time": "2020-03-04T15:57:14", "upload_time_iso_8601": "2020-03-04T15:57:14.791222Z", "url": "https://files.pythonhosted.org/packages/39/9a/1e149cbb0d3bba0b60e5b22fe2adba92d7af93d3239abb3708ce3a5dab2f/pepper_polish-0.0.5-cp36-cp36m-macosx_10_9_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "06e31f9ab973db0635dd59d29e5f9c51", "sha256": "571821525e6ef013cb400e427784eb7906fc712a187ec7da7e7afcf6c431061e"}, "downloads": -1, "filename": "pepper_polish-0.0.5-py3.6-macosx-10.9-x86_64.egg", "has_sig": false, "md5_digest": "06e31f9ab973db0635dd59d29e5f9c51", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": ">=3.5.*", "size": 521942, "upload_time": "2020-03-04T15:57:16", "upload_time_iso_8601": "2020-03-04T15:57:16.320431Z", "url": "https://files.pythonhosted.org/packages/c1/38/a981642b6bb43e45c058e128e870a00c7768e8e9ec200d50b58b528ec7a0/pepper_polish-0.0.5-py3.6-macosx-10.9-x86_64.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "52b2873d8b70c8dc15a4525c445f4090", "sha256": "90e76bf2c55294082c4a2579227f876a1ce82d56c05a7291d27ef82805ae9315"}, "downloads": -1, "filename": "pepper_polish-0.0.5.tar.gz", "has_sig": false, "md5_digest": "52b2873d8b70c8dc15a4525c445f4090", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.*", "size": 502060, "upload_time": "2020-03-04T15:57:17", "upload_time_iso_8601": "2020-03-04T15:57:17.518761Z", "url": "https://files.pythonhosted.org/packages/e9/b3/80becd6dc17b1feb9d97efc4abc916b5b0509a22eda6f355160e98e9d8e4/pepper_polish-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "29e2ab7c2331f83f9596d7a5c7445de1", "sha256": "b3bae82310c96fe8f456512743785cf949c59cb1d2d883fa3e4e670203402d2d"}, "downloads": -1, "filename": "pepper_polish-0.0.6-cp36-cp36m-macosx_10_9_x86_64.whl", "has_sig": false, "md5_digest": "29e2ab7c2331f83f9596d7a5c7445de1", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.5.*", "size": 446468, "upload_time": "2020-03-04T16:08:08", "upload_time_iso_8601": "2020-03-04T16:08:08.826010Z", "url": "https://files.pythonhosted.org/packages/20/13/9ff7ad3d6592d8898daba5907e4d13d709fcc4f779d29274c39d775b1ac4/pepper_polish-0.0.6-cp36-cp36m-macosx_10_9_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "76938f0969a50921aa31dcc167fc0cf1", "sha256": "434bd7cb63b8d581a442aedcfb3c7c9aaa17d01a5960a118079cd52d9a6e36d2"}, "downloads": -1, "filename": "pepper_polish-0.0.6.tar.gz", "has_sig": false, "md5_digest": "76938f0969a50921aa31dcc167fc0cf1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.*", "size": 535015, "upload_time": "2020-03-04T16:08:10", "upload_time_iso_8601": "2020-03-04T16:08:10.690785Z", "url": "https://files.pythonhosted.org/packages/79/f5/f193595dd7f6c66f3b8cd6d1695e2f4c646aa9ef0db0bc02f21a737d7f9c/pepper_polish-0.0.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "29e2ab7c2331f83f9596d7a5c7445de1", "sha256": "b3bae82310c96fe8f456512743785cf949c59cb1d2d883fa3e4e670203402d2d"}, "downloads": -1, "filename": "pepper_polish-0.0.6-cp36-cp36m-macosx_10_9_x86_64.whl", "has_sig": false, "md5_digest": "29e2ab7c2331f83f9596d7a5c7445de1", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.5.*", "size": 446468, "upload_time": "2020-03-04T16:08:08", "upload_time_iso_8601": "2020-03-04T16:08:08.826010Z", "url": "https://files.pythonhosted.org/packages/20/13/9ff7ad3d6592d8898daba5907e4d13d709fcc4f779d29274c39d775b1ac4/pepper_polish-0.0.6-cp36-cp36m-macosx_10_9_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "76938f0969a50921aa31dcc167fc0cf1", "sha256": "434bd7cb63b8d581a442aedcfb3c7c9aaa17d01a5960a118079cd52d9a6e36d2"}, "downloads": -1, "filename": "pepper_polish-0.0.6.tar.gz", "has_sig": false, "md5_digest": "76938f0969a50921aa31dcc167fc0cf1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.*", "size": 535015, "upload_time": "2020-03-04T16:08:10", "upload_time_iso_8601": "2020-03-04T16:08:10.690785Z", "url": "https://files.pythonhosted.org/packages/79/f5/f193595dd7f6c66f3b8cd6d1695e2f4c646aa9ef0db0bc02f21a737d7f9c/pepper_polish-0.0.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:24 2020"}