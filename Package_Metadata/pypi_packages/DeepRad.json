{"info": {"author": "MIMRTL Lab", "author_email": "mimrtl.uwmadison@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 3"], "description": "# DeepRad\n\nThis project is for the development of software related to medical imaging using deep learning. DeepRad has two different modes (quick use and developer mode), which are for different goals and researchers with different level of programming.\n\n\n\nDeepRad features large scale training with CNN, e.g. there are more than 10k volumes of scan. Loading these dataset directly into memory may cause out-of-memory (OOM) error. Hierarchical Data Format (HDF) is a collection of file formats (HDF4, HDF5) that is designed to store and organize large amounts of data. DeepRad provides **data management tool** to help users convert data to HDF5 file. During training process in DeepRad, only the batch of data will be loaded to memory from the hard driver where dataset is stored. Since all processes can be done in GUI, DeepRad is also friendly to people who are not familiar with coding.\n\n\n\nThis is the first version of the DeepRad. Currently we support the training process of 3D segmentation. We will add more features to make DeepRad more powerful.\n\n## Step 0. Installation of Dependency\npython 3.6 is recommended.\n\nChoose a method from (a) or (b) to install the dependent packages.\n### a. Install dependeny one by one\n```\n(for GPU user)\nconda install -c anaconda tensorflow-gpu\nconda install -c anaconda keras-gpu \n(for CPU user)\nconda install -c anaconda tensorflow \nconda install -c anaconda keras\n(common package)\nconda install -c conda-forge pillow \nconda install -c conda-forge opencv \nconda install -c conda-forge nibabel\nconda install -c conda-forge qimage2ndarray\nconda install -c simpleitk simpleitk\nconda install -c conda-forge nilearn\nconda install -c conda-forge pytables\nconda install -c anaconda nomkl\npip install git+https://www.github.com/farizrahman4u/keras-contrib.git\n```\n### b. Using the Installation.sh\nRun the installation.sh. It may take for a while (~15 min).\n```\nbash installation.sh\n```\n<!---\n<> **Directly use conda**\n<>tensorflow\n<>keras\n<>tensorflow-gpu\n<>pyqt\n<>opencv\n<>pillow\n<>#**Should refer to Anaconda Cloud** https://anaconda.org/anaconda/repo\n<>nibabel\n<>qimage2ndarray\n<>simpleitk\n<>nilearn\n<>**pip**\n<>tables\n### a. Create a new 'conda' virtual environment **(recommendation)**\n```\nconda env create --name DeepRad --file requirements.yml\n```\n-->\n\n## Step 1. Dataset Preparation\n### Folder constructure \nThere are several possible ways to construct folders.\n#### Folder Tree 1\n    .\n    \u251c\u2500\u2500 <data folder>\n    \u2502   \u251c\u2500\u2500 train                   # Data must be in a folder called \"train\" \n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # This is customized\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 <Modality M>    # This is customized\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 ...            \n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz OR truth.nii or truth.csv   # Labels must be named as \"truth\"\n    \u2502   \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n\nexample:\n\n    data_example\n    \u251c\u2500\u2500 type1\n    \u2502   \u251c\u2500\u2500 train\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n    \u2514\u2500\u2500 ...\n\n#### Folder Tree 2\n    .\n    \u251c\u2500\u2500 <data folder>\n    \u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # This is customized\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 <Modality M>    # This is customized\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 ...\n    \u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # The name shoule be the same as that in \"data\" folder\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz OR truth.nii or truth.csv   # Labels must be named as \"truth\"\n    \u2502   \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n\nexample:\n\n    data_example\n    \u251c\u2500\u2500 type2\n    \u2502   \u251c\u2500\u2500 data\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u251c\u2500\u2500 label\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 truth.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n    \u2502   \u2502   \u2502   \u2514\u2500\u2500 truth.nii.gz\n    \u2514\u2500\u2500 ...\n\n#### Folder Tree 3 (for synthesis)\n    .\n    \u251c\u2500\u2500 <data folder>\n    \u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # This is customized\n    \u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # The name shoule be the same as that in \"data\" folder\n    \u2514\u2500\u2500 ...\n\nexample:\n\n    data_example\n    \u251c\u2500\u2500 type3\n    \u2502   \u251c\u2500\u2500 data\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n    \u2502   \u251c\u2500\u2500 label\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n    \u2514\u2500\u2500 ...\n\n#### Folder Tree 4 (for classification)\n    .\n    \u251c\u2500\u2500 <data folder>\n    \u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # This is customized\n    \u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # The name shoule be the same as that in \"data\" folder\n    \u2514\u2500\u2500 ...\n\nexample:\n\n    data_example\n    \u251c\u2500\u2500 type4\n    \u2502   \u251c\u2500\u2500 data\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n    \u2502   \u251c\u2500\u2500 label\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.csv\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.csv\n    \u2514\u2500\u2500 ...\n\n#### Folder Tree 5 (for classification)\n    .\n    \u251c\u2500\u2500 <data folder>\n    \u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n    \u2502   \u2502   \u251c\u2500\u2500 <Volume N>          # This is customized\n    \u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n    \u2502   \u2502   \u251c\u2500\u2500 truth.csv           # The name shoule be \"truth.csv\"\n    \u2514\u2500\u2500 ...\n\nexample:\n\n    data_example\n    \u251c\u2500\u2500 type5\n    \u2502   \u251c\u2500\u2500 data\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n    \u2502   \u251c\u2500\u2500 label\n    \u2502   \u2502   \u251c\u2500\u2500 truth.csv\n    \u2514\u2500\u2500 ...\n\n### A tool of helping rename \"truth\"\nBecause **DeepRad** asks all labels named as \"truth\", a tool is provided to make it easier. Assume all folders are constucted as \"type1\" above.\n\n    .\n    \u251c\u2500\u2500 Data_folder                    # File name \"Data_folder\" is required.\n    \u2502   \u251c\u2500\u2500 train                      # File name \"train\" is required.\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 seg.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 seg.nii.gz\n    \u2514\u2500\u2500 ...\n\nHowever, there are like 100 volumes to be trained but all segmentation results are named as \"seg\". Now, run the following code in the root.\n```\npython rename.py --seg_name seg\n```\nThe parameter \"--seg_name\" is a common part of name in all files we want to change to \"truth\". After running this code, the folders will be like:\n\n    .\n    \u251c\u2500\u2500 Data_folder                    # File name \"Data_folder\" is required.\n    \u2502   \u251c\u2500\u2500 train                      # File name \"train\" is required.\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n    \u2514\u2500\u2500 ...\n### Converting data into hdf5 format.\n**DeepRad** provides a tool to load the dataset and convert it as .hdf5 files, for better compatibility for huge dataset. \nTo open **DeepRad**, follow **step 0** to install the dependent packages and run the following code in the **DeepRad** folder:\n```\npython main.py\n```\nThen we can see a main window. Now click \"Quick use\" and \"Menu\" in the top. Click \"Data Management Tool\" Assume we have the following folder constructure.\n\n    .\n    \u251c\u2500\u2500 Data_folder                    # File name \"Data_folder\" is required.\n    \u2502   \u251c\u2500\u2500 train                      # File name \"train\" is required.\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n    \u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n    \u2514\u2500\u2500 ...\n\nIn **Data Management Tool**, the data directory will be like: \n```\n ./DeepRad/Data_folder/train          # must be in \"train\" folder\n```\nAnd we can specify the output directory like:\n```\n ./DeepRad/Data_folder\n```\nAfter specifying the directories, we can move to **Normalized to**. Two modes of normalization is provided: Standard and Interval.\n1. Standard (Z-score)\n   - data = (data / mean) / std\n   - mean and std is calculated on all values, not only non-zeros values\n2. Interval\n   - data -= data_min\n   - data /= (data_max - data_min)/(MAX-MIN)\n   - data += MIN\n\n\n**Normalization Type** determines how mean/std or data_max/data_min is calcuated. Assume we have 100 volumes, in each volume we have for modalities \"t1\", \"t2\", \"t1ce\", \"flair\". Each modality has the shape (240, 240, 155).\n   - Global: parameters will be calculated among 100\\*4\\*(240, 240, 155) datasets\n   - Per volume: paremeters will be caculated only on each (240, 240, 155) dataset\n   - Per slice: paremeters will be calcuated only on each (240, 240) slice.\n\n**Image Shape** is the output dataset shape. Becasue we are using a 3D model to do it, we recommend:\n   - row: 64\n   - col: 64\n   - channel: 64\n\nThe right part is a preview tool to see our dataset. It can **only work** if we specify the volume path, like:\n```\n ./DeepRad/Data_folder/train/Brats18_2013_1_1\n```\n\nAfter setting parameters, click **Convert**. Attention: it may take a few minutes, don't click other things or there will be several unknow bugs. We can see a \"data.hdf5\" in our path, like:\n```\n ./DeepRad/Data_folder/train/data.hdf5\n```\n## Step 2. Main function (Take segmentation as an example)\n\nTesting environment: 16G memory and GTX 1080 GPU and test 5 volume of Brats 2018 dataset.\n\nBrats dataset: https://www.med.upenn.edu/sbia/brats2018/data.html\n\nClick **Segmentation** in main window. And we can see 5 steps here. Now we are sharing the recommendation setting, and use the default setting if not mentioned.\n\n### 1. Prepare Data\n    - Data folder: ./DeepRad/Data_folder/train/data.hdf5\n    - Validation data ratio: 0\n    - Resize image to:\n        - Row: 64\n        - Col: 64\n        - Channel: 64\n### 2. Choose Models\n    - isensee2017\n    - Image channel size: 64 \n    - Number of labels: 4\n### 3. Data Augmentatiton\n    - Enable: Not\n### 4. Training Configuration\n    - Batch size:\n        - Training data: 8\n    - Epoch: (We can fill as many as want)\n### 5. Output configuration\n    - Folder path: (The folder path we want to save the results)\n    - Configuration file only: Not (if clicks, only a configuration file will be saved)\n    - Training output:\n        - weights: Yes. (This is the real model)\n        - Tensorboard: Yes. (This is a tensorboard log)\n        - logs: Tes. (Settings)\n\nAfter that, click \"Start\" to train the model. And we can monitor the training progress.\n\n![Visualization](/tools/DeepRad.png)\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mimrtl/DeepRad", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "DeepRad", "package_url": "https://pypi.org/project/DeepRad/", "platform": "", "project_url": "https://pypi.org/project/DeepRad/", "project_urls": {"Homepage": "https://github.com/mimrtl/DeepRad"}, "release_url": "https://pypi.org/project/DeepRad/1.0.0/", "requires_dist": null, "requires_python": "", "summary": "A toolbox of Deep Learning in Medical Images", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DeepRad</h1>\n<p>This project is for the development of software related to medical imaging using deep learning. DeepRad has two different modes (quick use and developer mode), which are for different goals and researchers with different level of programming.</p>\n<p>DeepRad features large scale training with CNN, e.g. there are more than 10k volumes of scan. Loading these dataset directly into memory may cause out-of-memory (OOM) error. Hierarchical Data Format (HDF) is a collection of file formats (HDF4, HDF5) that is designed to store and organize large amounts of data. DeepRad provides <strong>data management tool</strong> to help users convert data to HDF5 file. During training process in DeepRad, only the batch of data will be loaded to memory from the hard driver where dataset is stored. Since all processes can be done in GUI, DeepRad is also friendly to people who are not familiar with coding.</p>\n<p>This is the first version of the DeepRad. Currently we support the training process of 3D segmentation. We will add more features to make DeepRad more powerful.</p>\n<h2>Step 0. Installation of Dependency</h2>\n<p>python 3.6 is recommended.</p>\n<p>Choose a method from (a) or (b) to install the dependent packages.</p>\n<h3>a. Install dependeny one by one</h3>\n<pre><code>(for GPU user)\nconda install -c anaconda tensorflow-gpu\nconda install -c anaconda keras-gpu \n(for CPU user)\nconda install -c anaconda tensorflow \nconda install -c anaconda keras\n(common package)\nconda install -c conda-forge pillow \nconda install -c conda-forge opencv \nconda install -c conda-forge nibabel\nconda install -c conda-forge qimage2ndarray\nconda install -c simpleitk simpleitk\nconda install -c conda-forge nilearn\nconda install -c conda-forge pytables\nconda install -c anaconda nomkl\npip install git+https://www.github.com/farizrahman4u/keras-contrib.git\n</code></pre>\n<h3>b. Using the Installation.sh</h3>\n<p>Run the installation.sh. It may take for a while (~15 min).</p>\n<pre><code>bash installation.sh\n</code></pre>\n\n<h2>Step 1. Dataset Preparation</h2>\n<h3>Folder constructure</h3>\n<p>There are several possible ways to construct folders.</p>\n<h4>Folder Tree 1</h4>\n<pre><code>.\n\u251c\u2500\u2500 &lt;data folder&gt;\n\u2502   \u251c\u2500\u2500 train                   # Data must be in a folder called \"train\" \n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # This is customized\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 &lt;Modality M&gt;    # This is customized\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ...            \n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz OR truth.nii or truth.csv   # Labels must be named as \"truth\"\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>example:</p>\n<pre><code>data_example\n\u251c\u2500\u2500 type1\n\u2502   \u251c\u2500\u2500 train\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n\u2514\u2500\u2500 ...\n</code></pre>\n<h4>Folder Tree 2</h4>\n<pre><code>.\n\u251c\u2500\u2500 &lt;data folder&gt;\n\u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # This is customized\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 &lt;Modality M&gt;    # This is customized\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # The name shoule be the same as that in \"data\" folder\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz OR truth.nii or truth.csv   # Labels must be named as \"truth\"\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>example:</p>\n<pre><code>data_example\n\u251c\u2500\u2500 type2\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u251c\u2500\u2500 label\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 truth.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 truth.nii.gz\n\u2514\u2500\u2500 ...\n</code></pre>\n<h4>Folder Tree 3 (for synthesis)</h4>\n<pre><code>.\n\u251c\u2500\u2500 &lt;data folder&gt;\n\u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # This is customized\n\u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # The name shoule be the same as that in \"data\" folder\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>example:</p>\n<pre><code>data_example\n\u251c\u2500\u2500 type3\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n\u2502   \u251c\u2500\u2500 label\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n\u2514\u2500\u2500 ...\n</code></pre>\n<h4>Folder Tree 4 (for classification)</h4>\n<pre><code>.\n\u251c\u2500\u2500 &lt;data folder&gt;\n\u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # This is customized\n\u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # The name shoule be the same as that in \"data\" folder\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>example:</p>\n<pre><code>data_example\n\u251c\u2500\u2500 type4\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n\u2502   \u251c\u2500\u2500 label\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.csv\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.csv\n\u2514\u2500\u2500 ...\n</code></pre>\n<h4>Folder Tree 5 (for classification)</h4>\n<pre><code>.\n\u251c\u2500\u2500 &lt;data folder&gt;\n\u2502   \u251c\u2500\u2500 data                    # Data must be in a folder called \"data\"\n\u2502   \u2502   \u251c\u2500\u2500 &lt;Volume N&gt;          # This is customized\n\u2502   \u251c\u2500\u2500 label                   # Data must be in a folder called \"label\"\n\u2502   \u2502   \u251c\u2500\u2500 truth.csv           # The name shoule be \"truth.csv\"\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>example:</p>\n<pre><code>data_example\n\u251c\u2500\u2500 type5\n\u2502   \u251c\u2500\u2500 data\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1.nii.gz\n\u2502   \u251c\u2500\u2500 label\n\u2502   \u2502   \u251c\u2500\u2500 truth.csv\n\u2514\u2500\u2500 ...\n</code></pre>\n<h3>A tool of helping rename \"truth\"</h3>\n<p>Because <strong>DeepRad</strong> asks all labels named as \"truth\", a tool is provided to make it easier. Assume all folders are constucted as \"type1\" above.</p>\n<pre><code>.\n\u251c\u2500\u2500 Data_folder                    # File name \"Data_folder\" is required.\n\u2502   \u251c\u2500\u2500 train                      # File name \"train\" is required.\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 seg.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 seg.nii.gz\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>However, there are like 100 volumes to be trained but all segmentation results are named as \"seg\". Now, run the following code in the root.</p>\n<pre><code>python rename.py --seg_name seg\n</code></pre>\n<p>The parameter \"--seg_name\" is a common part of name in all files we want to change to \"truth\". After running this code, the folders will be like:</p>\n<pre><code>.\n\u251c\u2500\u2500 Data_folder                    # File name \"Data_folder\" is required.\n\u2502   \u251c\u2500\u2500 train                      # File name \"train\" is required.\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n\u2514\u2500\u2500 ...\n</code></pre>\n<h3>Converting data into hdf5 format.</h3>\n<p><strong>DeepRad</strong> provides a tool to load the dataset and convert it as .hdf5 files, for better compatibility for huge dataset.\nTo open <strong>DeepRad</strong>, follow <strong>step 0</strong> to install the dependent packages and run the following code in the <strong>DeepRad</strong> folder:</p>\n<pre><code>python main.py\n</code></pre>\n<p>Then we can see a main window. Now click \"Quick use\" and \"Menu\" in the top. Click \"Data Management Tool\" Assume we have the following folder constructure.</p>\n<pre><code>.\n\u251c\u2500\u2500 Data_folder                    # File name \"Data_folder\" is required.\n\u2502   \u251c\u2500\u2500 train                      # File name \"train\" is required.\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_0_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n\u2502   \u2502   \u251c\u2500\u2500 Brats17_2013_15_1\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t1ce.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 t2.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 flair.nii.gz\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 truth.nii.gz\n\u2514\u2500\u2500 ...\n</code></pre>\n<p>In <strong>Data Management Tool</strong>, the data directory will be like:</p>\n<pre><code> ./DeepRad/Data_folder/train          # must be in \"train\" folder\n</code></pre>\n<p>And we can specify the output directory like:</p>\n<pre><code> ./DeepRad/Data_folder\n</code></pre>\n<p>After specifying the directories, we can move to <strong>Normalized to</strong>. Two modes of normalization is provided: Standard and Interval.</p>\n<ol>\n<li>Standard (Z-score)\n<ul>\n<li>data = (data / mean) / std</li>\n<li>mean and std is calculated on all values, not only non-zeros values</li>\n</ul>\n</li>\n<li>Interval\n<ul>\n<li>data -= data_min</li>\n<li>data /= (data_max - data_min)/(MAX-MIN)</li>\n<li>data += MIN</li>\n</ul>\n</li>\n</ol>\n<p><strong>Normalization Type</strong> determines how mean/std or data_max/data_min is calcuated. Assume we have 100 volumes, in each volume we have for modalities \"t1\", \"t2\", \"t1ce\", \"flair\". Each modality has the shape (240, 240, 155).</p>\n<ul>\n<li>Global: parameters will be calculated among 100*4*(240, 240, 155) datasets</li>\n<li>Per volume: paremeters will be caculated only on each (240, 240, 155) dataset</li>\n<li>Per slice: paremeters will be calcuated only on each (240, 240) slice.</li>\n</ul>\n<p><strong>Image Shape</strong> is the output dataset shape. Becasue we are using a 3D model to do it, we recommend:</p>\n<ul>\n<li>row: 64</li>\n<li>col: 64</li>\n<li>channel: 64</li>\n</ul>\n<p>The right part is a preview tool to see our dataset. It can <strong>only work</strong> if we specify the volume path, like:</p>\n<pre><code> ./DeepRad/Data_folder/train/Brats18_2013_1_1\n</code></pre>\n<p>After setting parameters, click <strong>Convert</strong>. Attention: it may take a few minutes, don't click other things or there will be several unknow bugs. We can see a \"data.hdf5\" in our path, like:</p>\n<pre><code> ./DeepRad/Data_folder/train/data.hdf5\n</code></pre>\n<h2>Step 2. Main function (Take segmentation as an example)</h2>\n<p>Testing environment: 16G memory and GTX 1080 GPU and test 5 volume of Brats 2018 dataset.</p>\n<p>Brats dataset: <a href=\"https://www.med.upenn.edu/sbia/brats2018/data.html\" rel=\"nofollow\">https://www.med.upenn.edu/sbia/brats2018/data.html</a></p>\n<p>Click <strong>Segmentation</strong> in main window. And we can see 5 steps here. Now we are sharing the recommendation setting, and use the default setting if not mentioned.</p>\n<h3>1. Prepare Data</h3>\n<pre><code>- Data folder: ./DeepRad/Data_folder/train/data.hdf5\n- Validation data ratio: 0\n- Resize image to:\n    - Row: 64\n    - Col: 64\n    - Channel: 64\n</code></pre>\n<h3>2. Choose Models</h3>\n<pre><code>- isensee2017\n- Image channel size: 64 \n- Number of labels: 4\n</code></pre>\n<h3>3. Data Augmentatiton</h3>\n<pre><code>- Enable: Not\n</code></pre>\n<h3>4. Training Configuration</h3>\n<pre><code>- Batch size:\n    - Training data: 8\n- Epoch: (We can fill as many as want)\n</code></pre>\n<h3>5. Output configuration</h3>\n<pre><code>- Folder path: (The folder path we want to save the results)\n- Configuration file only: Not (if clicks, only a configuration file will be saved)\n- Training output:\n    - weights: Yes. (This is the real model)\n    - Tensorboard: Yes. (This is a tensorboard log)\n    - logs: Tes. (Settings)\n</code></pre>\n<p>After that, click \"Start\" to train the model. And we can monitor the training progress.</p>\n<p><img alt=\"Visualization\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c4d82ac07060ab05ef9395ff459e0d9a2b28b43e/2f746f6f6c732f446565705261642e706e67\"></p>\n\n          </div>"}, "last_serial": 5334433, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "08e822732fc9d7386f40a75ad241092f", "sha256": "385be27a3d5634d084e0c35ccd14768c767fb2b94d094a955b834206b45c94a6"}, "downloads": -1, "filename": "DeepRad-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "08e822732fc9d7386f40a75ad241092f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9067, "upload_time": "2019-05-29T21:07:13", "upload_time_iso_8601": "2019-05-29T21:07:13.239903Z", "url": "https://files.pythonhosted.org/packages/ba/67/af8ab8fbbc344ca6458205e3da9533d30338ca39a137c9522281fa4c8842/DeepRad-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27cdece3fb96a2e0f3e5d46709888bcc", "sha256": "173c13df7013000e3d40bf6a3b53ba894763c1e3d807328237b9623e0127ad78"}, "downloads": -1, "filename": "DeepRad-1.0.0.tar.gz", "has_sig": false, "md5_digest": "27cdece3fb96a2e0f3e5d46709888bcc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5380, "upload_time": "2019-05-29T21:07:15", "upload_time_iso_8601": "2019-05-29T21:07:15.812207Z", "url": "https://files.pythonhosted.org/packages/94/16/91aef44e7bf445737a14d37bd5ac81c302b4496187cdd74413b1b654682f/DeepRad-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "08e822732fc9d7386f40a75ad241092f", "sha256": "385be27a3d5634d084e0c35ccd14768c767fb2b94d094a955b834206b45c94a6"}, "downloads": -1, "filename": "DeepRad-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "08e822732fc9d7386f40a75ad241092f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9067, "upload_time": "2019-05-29T21:07:13", "upload_time_iso_8601": "2019-05-29T21:07:13.239903Z", "url": "https://files.pythonhosted.org/packages/ba/67/af8ab8fbbc344ca6458205e3da9533d30338ca39a137c9522281fa4c8842/DeepRad-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27cdece3fb96a2e0f3e5d46709888bcc", "sha256": "173c13df7013000e3d40bf6a3b53ba894763c1e3d807328237b9623e0127ad78"}, "downloads": -1, "filename": "DeepRad-1.0.0.tar.gz", "has_sig": false, "md5_digest": "27cdece3fb96a2e0f3e5d46709888bcc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5380, "upload_time": "2019-05-29T21:07:15", "upload_time_iso_8601": "2019-05-29T21:07:15.812207Z", "url": "https://files.pythonhosted.org/packages/94/16/91aef44e7bf445737a14d37bd5ac81c302b4496187cdd74413b1b654682f/DeepRad-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:21 2020"}