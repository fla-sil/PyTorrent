{"info": {"author": "Rafal Rolczynski", "author_email": "rafal.rolczynski@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "\n### Aspect Based Sentiment Analysis\n\nThe task is to classify the sentiment of potentially long texts for several aspects.\nIn building this package, we focus on two things.\nFirstly, the package works as a service.\nIt can be freely adjusted and extended to your needs.\nIt is standalone and scalable.\nYou just benefit from the fine-tuned State of the Art models.\nSecondly, we wish to explain model decisions,\nso you can infer how much predictions are reliable.\nWe desire to provide the robust and stable ML package. \n\n\nThere are over 100 repositories on GitHub around this problem\n<sup>\n[1](https://github.com/songyouwei/ABSA-PyTorch)\n[2](https://github.com/jimmyyfeng/TD-LSTM)\n[3](https://github.com/davidsbatista/Aspect-Based-Sentiment-Analysis)\n[4](https://github.com/peace195/aspect-based-sentiment-analysis)\n[5](https://github.com/yardstick17/AspectBasedSentimentAnalysis)\n[6](https://github.com/thestrox/Aspect-Based-Sentiment-Analysis)\n[7](https://github.com/AlexYangLi/ABSA_Keras)\n[8](https://github.com/pedrobalage/SemevalAspectBasedSentimentAnalysis)\n[9](https://github.com/ganeshjawahar/mem_absa)\n</sup>.\nAll of them are hard to commercialize and reuse open-sourced research projects. \nTheir purpose is to turn the evaluation score up. \nIt is hard to go through the entire process and reproduce results from scratch. \nThe pre/post-processing is divided into stages that makes it hard to use.\nLast but not least, there is no/little effort to understand model reasoning.\nWe try to clean this excellent research up. \nPlease give a star if you like the project. \nThis is important to keep this project alive.\n\n<br>\n\n### Quick Start\n\nTo start, use the fine-tuned model.\nThe `load` function downloads a model into the package directory, \nsets up the Tensorflow model and returns the ready-to-use pipeline.\nThe pipeline `nlp` wraps the model and keeps non-differential pre/post-processing needed \nto make a prediction and to interpret results.\nPlease take a look at the details [here](aspect_based_sentiment_analysis/pipelines.py).\n\n```python\nimport aspect_based_sentiment_analysis as absa\n\nnlp = absa.load()\ntext = (\"We are great fans of Slack, but we wish the subscriptions \"\n        \"were more accessible to small startups.\")\n\nslack, price = nlp(text, aspects=['slack', 'price'])\nassert price.sentiment == absa.Sentiment.negative\nassert slack.sentiment == absa.Sentiment.positive\n```\n\nNow, we wish to infer how much predictions are reliable.\nIn our task, we are curious about two things at most. \nFirstly, we want to be sure that the model connects the correct\nword or words with the aspect. If the model does it wrong, the sentiment\nconcerns the different entity. Secondly, even if the model recognized\nthe aspect correctly, we need to understand the model reasoning better.\nTo do so, we wish to discovers patterns, a weighted sequence\nof words, and their approximated impact to the prediction. We want to\navoid a situation wherein a single word or weird word combination\ntriggers the model. \n\n```jupyter\n# Verify the model decision\nhtml = absa.probing.explain(slack)\ndisplay(html)\n```\n\n<p align=\"middle\">\n<img src=\"examples/patterns.png\" width=\"600\" alt=\"\"/>\n</p>\n\nHere, we have two things.\nFirstly, we see the model's definition of the \"slack\" aspect.\nThe model pays attention to the word \"slack\" correctly.\nNonetheless, we need to understand that\nthe sentiment rather concerns the whole collocation \"great fans of slack\".\nSecondly, we go through patterns that impact on a prediction.\nWe can cluster patterns into two groups.\nThe patterns in the first group (marked as green) support a decision \n(in this case, push towards the positive sentiment).\nBasically, they represent different combinations of weighted words: great, fans, slack.\nThe patterns in the second group (marked as red) disagree with a decision.\nInterestingly, the model recognizes the complex structure like \"wish ... more\".\nPlease note that this analysis is a rough approximation.\nTake a look at the details [here](aspect_based_sentiment_analysis/probing/recognizers.py).\n\n<br>\n\n### Ready-to-Use Models\n\nIn the table, we present the state of the art results on the most common evaluation dataset \n(SemEval 2014 Task 4 SubTask 2, details [here](http://alt.qcri.org/semeval2014/task4/)).\nThe project assumption is to use the published architectures\n(even if I was tempted to do my own).\nWe recommend `bert-ada` for its simplicity (default).\nTake a look at the our model implementation details [here](aspect_based_sentiment_analysis/models.py).\n\n| Model Name | Acc Rest | Acc Lapt | Release |\n| :--- |  :---:  |  :---:  | :---: |\n||\n| LCF-ATEPC  [[code]](https://github.com/yangheng95/LCF-ATEPC)[[paper]](http://arxiv.org/abs/1912.07976)                        | 90.18  |  82.29  | Jan 2020 |\n| BERT-ADA   [[code]](https://github.com/deepopinion/domain-adapted-atsc)[[paper]](http://arxiv.org/abs/1908.11860)             | 87.89  |  80.23  | Nov 2019 |\n| BAT        [[code]](https://github.com/akkarimi/Adversarial-Training-for-ABSA)[[paper]](https://arxiv.org/pdf/2001.11316.pdf) | 86.03  |  79.35  | Feb 2020 |\n||\n| `bert-ada-rest-0.1` | 86.51 |\n| `bert-ada-lapt-0.1` | | 80.23\n\nThere are two available models for the restaurant and laptop domains.\nThe hyper-parameters optimization with the explanation how to train a model is [here](examples/train_classifier.py).\nYou can easily reproduce our evaluations.\nLook at the performance tests [here](tests/test_performance.py).\n\n<br>\n\n### Installation\n\nYou can use the pip:\n```bash\npip install aspect-based-sentiment-analysis\n```\nOtherwise, clone the code and create the new environment via \n[conda](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#):\n```bash\ngit clone git@github.com:ScalaConsultants/Aspect-Based-Sentiment-Analysis.git\nconda env create -f=environment.yml\nconda activate Aspect-Based-Sentiment-Analysis\n```\n\n<br>\n\n### Further Research\n\nEven the task is narrow and well-defined, there is still massive work to do.\nBelow we present our few open research issues.\nWe encourage you to help us to improve this package.\n\n- Provide a concrete confidence measure.\n- Build the separated model which correlates patterns and linguistics dependencies.\n- Process several aspects at once.\n- Adapt models across different domains. \n- Proper model calibrations (neutral).\n- Robust evaluations (adversarial attacks).\n- Distill the model (compress the tuned model).\n- More interactive visualization tools.\n\n<br>\n\n### References\n\nHow to use BERT for the Aspect-Based Sentiment Analysis:\n- Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence (NAACL 2019)\n[[code]](https://github.com/HSLCY/ABSA-BERT-pair)[[paper]](https://www.aclweb.org/anthology/N19-1035/)\n- BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis (NAACL 2019)\n[[code]](https://github.com/howardhsu/BERT-for-RRC-ABSA)[[paper]](http://arxiv.org/abs/1908.11860)\n- Exploiting BERT for End-to-End Aspect-based Sentiment Analysis\n[[code]](https://github.com/lixin4ever/BERT-E2E-ABSA)[[paper]](http://arxiv.org/abs/1910.00883)\n\nIntroduction to the BERT interpretability:\n- Are Sixteen Heads Really Better than One?\n[[code]](https://github.com/pmichel31415/are-16-heads-really-better-than-1)[[paper]](http://arxiv.org/abs/1905.10650)\n- A Primer in BERTology: What we know about how BERT works\n[[paper]](http://arxiv.org/abs/2002.12327)\n- What Does BERT Look At? An Analysis of BERT's Attention\n[[code]](https://github.com/clarkkev/attention-analysis)[[paper]](http://arxiv.org/abs/1906.04341)\n- Visualizing and Measuring the Geometry of BERT\n[[code]](https://github.com/PAIR-code/interpretability)[[paper]](http://arxiv.org/abs/1906.02715)\n- Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment\n[[paper]](http://arxiv.org/abs/1907.11932)\n- Adversarial Training for Aspect-Based Sentiment Analysis with BERT\n[[paper]](http://arxiv.org/abs/2001.11316)\n- Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT\n[[paper]](http://arxiv.org/abs/2003.04985)\n- exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models\n[[code]](https://github.com/bhoov/exbert)[[paper]](http://arxiv.org/abs/1910.05276)\n- Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings\n[[code]](https://github.com/uhh-lt/bert-sense)[[paper]](http://arxiv.org/abs/1909.10430)\n- Attention is not Explanation\n[[code]](https://github.com/successar/AttentionExplanation)[[paper]](https://arxiv.org/abs/1902.10186)\n- Attention is not not Explanation\n[[code]](https://github.com/sarahwie/attention)[[paper]](http://arxiv.org/abs/1908.04626)[[blog post]](https://medium.com/@yuvalpinter/attention-is-not-not-explanation-dbc25b534017)\n- Hierarchical interpretations for neural network predictions\n[[code]](https://github.com/csinva/hierarchical-dnn-interpretations)[[paper]](https://arxiv.org/abs/1806.05337)\n- Analysis Methods in Neural NLP\n[[code]](https://github.com/boknilev/nlp-analysis-methods)[[paper]](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00254)\n- Visualization for Sequential Neural Networks with Attention\n[[code]](https://github.com/HendrikStrobelt/Seq2Seq-Vis)\n- NeuroX: Toolkit for finding and analyzing important neurons in neural networks\n[[code]](https://github.com/fdalvi/NeuroX)[[paper]](https://arxiv.org/abs/1812.09359)\n\nThe State of the Art results:\n- A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction\n[[code]](https://github.com/yangheng95/LCF-ATEPC)[[paper]](http://arxiv.org/abs/1912.07976)\n- Adapt or Get Left Behind: Domain Adaptation through BERT Language Model Finetuning for Aspect-Target Sentiment Classification\n[[code]](https://github.com/deepopinion/domain-adapted-atsc)[[paper]](http://arxiv.org/abs/1908.11860)\n- Adversarial Training for Aspect-Based Sentiment Analysis with BERT\n[[code]](https://github.com/akkarimi/Adversarial-Training-for-ABSA)[[paper]](https://arxiv.org/pdf/2001.11316.pdf)\n\nOther interesting:\n- Multi-Dimensional Explanation of Ratings from Reviews\n[[paper]](http://arxiv.org/abs/1909.11386)\n- Extracting Syntactic Trees from Transformer Encoder Self-Attentions\n[[paper]](http://aclweb.org/anthology/W18-5444)\n- Master Thesis: Transfer and Multitask Learning for Aspect-Based Sentiment Analysis Using the Google Transformer Architecture\n[[code]](https://github.com/felixSchober/ABSA-Transformer)\n- Create interactive textual heat maps for Jupiter notebooks\n[[code]](https://github.com/AndreasMadsen/python-textualheatmap)\n- A pyTorch implementation of the DeepMoji model: state-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc\n[[code]](https://github.com/huggingface/torchMoji)\n- More you can find [here](https://github.com/jiangqn/Aspect-Based-Sentiment-Analysis).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ScalaConsultants/Aspect-Based-Sentiment-Analysis", "keywords": "", "license": "Apache-2.0", "maintainer": "", "maintainer_email": "", "name": "aspect-based-sentiment-analysis", "package_url": "https://pypi.org/project/aspect-based-sentiment-analysis/", "platform": "", "project_url": "https://pypi.org/project/aspect-based-sentiment-analysis/", "project_urls": {"Homepage": "https://github.com/ScalaConsultants/Aspect-Based-Sentiment-Analysis"}, "release_url": "https://pypi.org/project/aspect-based-sentiment-analysis/1.1.1/", "requires_dist": ["tensorflow (>=2.1)", "transformers (>=2.5)", "pytest", "scikit-learn", "ipython", "google-cloud-storage", "testfixtures", "optuna", "spacy"], "requires_python": "~=3.7", "summary": "Aspect Based Sentiment Analysis: Transformer & Interpretability (TensorFlow)", "version": "1.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h3>Aspect Based Sentiment Analysis</h3>\n<p>The task is to classify the sentiment of potentially long texts for several aspects.\nIn building this package, we focus on two things.\nFirstly, the package works as a service.\nIt can be freely adjusted and extended to your needs.\nIt is standalone and scalable.\nYou just benefit from the fine-tuned State of the Art models.\nSecondly, we wish to explain model decisions,\nso you can infer how much predictions are reliable.\nWe desire to provide the robust and stable ML package.</p>\n<p>There are over 100 repositories on GitHub around this problem\n<sup>\n<a href=\"https://github.com/songyouwei/ABSA-PyTorch\" rel=\"nofollow\">1</a>\n<a href=\"https://github.com/jimmyyfeng/TD-LSTM\" rel=\"nofollow\">2</a>\n<a href=\"https://github.com/davidsbatista/Aspect-Based-Sentiment-Analysis\" rel=\"nofollow\">3</a>\n<a href=\"https://github.com/peace195/aspect-based-sentiment-analysis\" rel=\"nofollow\">4</a>\n<a href=\"https://github.com/yardstick17/AspectBasedSentimentAnalysis\" rel=\"nofollow\">5</a>\n<a href=\"https://github.com/thestrox/Aspect-Based-Sentiment-Analysis\" rel=\"nofollow\">6</a>\n<a href=\"https://github.com/AlexYangLi/ABSA_Keras\" rel=\"nofollow\">7</a>\n<a href=\"https://github.com/pedrobalage/SemevalAspectBasedSentimentAnalysis\" rel=\"nofollow\">8</a>\n<a href=\"https://github.com/ganeshjawahar/mem_absa\" rel=\"nofollow\">9</a>\n</sup>.\nAll of them are hard to commercialize and reuse open-sourced research projects.\nTheir purpose is to turn the evaluation score up.\nIt is hard to go through the entire process and reproduce results from scratch.\nThe pre/post-processing is divided into stages that makes it hard to use.\nLast but not least, there is no/little effort to understand model reasoning.\nWe try to clean this excellent research up.\nPlease give a star if you like the project.\nThis is important to keep this project alive.</p>\n<br>\n<h3>Quick Start</h3>\n<p>To start, use the fine-tuned model.\nThe <code>load</code> function downloads a model into the package directory,\nsets up the Tensorflow model and returns the ready-to-use pipeline.\nThe pipeline <code>nlp</code> wraps the model and keeps non-differential pre/post-processing needed\nto make a prediction and to interpret results.\nPlease take a look at the details <a href=\"aspect_based_sentiment_analysis/pipelines.py\" rel=\"nofollow\">here</a>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">aspect_based_sentiment_analysis</span> <span class=\"k\">as</span> <span class=\"nn\">absa</span>\n\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">absa</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">()</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s2\">\"We are great fans of Slack, but we wish the subscriptions \"</span>\n        <span class=\"s2\">\"were more accessible to small startups.\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">slack</span><span class=\"p\">,</span> <span class=\"n\">price</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">aspects</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'slack'</span><span class=\"p\">,</span> <span class=\"s1\">'price'</span><span class=\"p\">])</span>\n<span class=\"k\">assert</span> <span class=\"n\">price</span><span class=\"o\">.</span><span class=\"n\">sentiment</span> <span class=\"o\">==</span> <span class=\"n\">absa</span><span class=\"o\">.</span><span class=\"n\">Sentiment</span><span class=\"o\">.</span><span class=\"n\">negative</span>\n<span class=\"k\">assert</span> <span class=\"n\">slack</span><span class=\"o\">.</span><span class=\"n\">sentiment</span> <span class=\"o\">==</span> <span class=\"n\">absa</span><span class=\"o\">.</span><span class=\"n\">Sentiment</span><span class=\"o\">.</span><span class=\"n\">positive</span>\n</pre>\n<p>Now, we wish to infer how much predictions are reliable.\nIn our task, we are curious about two things at most.\nFirstly, we want to be sure that the model connects the correct\nword or words with the aspect. If the model does it wrong, the sentiment\nconcerns the different entity. Secondly, even if the model recognized\nthe aspect correctly, we need to understand the model reasoning better.\nTo do so, we wish to discovers patterns, a weighted sequence\nof words, and their approximated impact to the prediction. We want to\navoid a situation wherein a single word or weird word combination\ntriggers the model.</p>\n<pre># Verify the model decision\nhtml = absa.probing.explain(slack)\ndisplay(html)\n</pre>\n<p align=\"middle\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbda8bc34060ccdd0916659054fca187a96e2a03/6578616d706c65732f7061747465726e732e706e67\" width=\"600\">\n</p>\n<p>Here, we have two things.\nFirstly, we see the model's definition of the \"slack\" aspect.\nThe model pays attention to the word \"slack\" correctly.\nNonetheless, we need to understand that\nthe sentiment rather concerns the whole collocation \"great fans of slack\".\nSecondly, we go through patterns that impact on a prediction.\nWe can cluster patterns into two groups.\nThe patterns in the first group (marked as green) support a decision\n(in this case, push towards the positive sentiment).\nBasically, they represent different combinations of weighted words: great, fans, slack.\nThe patterns in the second group (marked as red) disagree with a decision.\nInterestingly, the model recognizes the complex structure like \"wish ... more\".\nPlease note that this analysis is a rough approximation.\nTake a look at the details <a href=\"aspect_based_sentiment_analysis/probing/recognizers.py\" rel=\"nofollow\">here</a>.</p>\n<br>\n<h3>Ready-to-Use Models</h3>\n<p>In the table, we present the state of the art results on the most common evaluation dataset\n(SemEval 2014 Task 4 SubTask 2, details <a href=\"http://alt.qcri.org/semeval2014/task4/\" rel=\"nofollow\">here</a>).\nThe project assumption is to use the published architectures\n(even if I was tempted to do my own).\nWe recommend <code>bert-ada</code> for its simplicity (default).\nTake a look at the our model implementation details <a href=\"aspect_based_sentiment_analysis/models.py\" rel=\"nofollow\">here</a>.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Model Name</th>\n<th align=\"center\">Acc Rest</th>\n<th align=\"center\">Acc Lapt</th>\n<th align=\"center\">Release</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\">LCF-ATEPC  <a href=\"https://github.com/yangheng95/LCF-ATEPC\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1912.07976\" rel=\"nofollow\">[paper]</a></td>\n<td align=\"center\">90.18</td>\n<td align=\"center\">82.29</td>\n<td align=\"center\">Jan 2020</td>\n</tr>\n<tr>\n<td align=\"left\">BERT-ADA   <a href=\"https://github.com/deepopinion/domain-adapted-atsc\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1908.11860\" rel=\"nofollow\">[paper]</a></td>\n<td align=\"center\">87.89</td>\n<td align=\"center\">80.23</td>\n<td align=\"center\">Nov 2019</td>\n</tr>\n<tr>\n<td align=\"left\">BAT        <a href=\"https://github.com/akkarimi/Adversarial-Training-for-ABSA\" rel=\"nofollow\">[code]</a><a href=\"https://arxiv.org/pdf/2001.11316.pdf\" rel=\"nofollow\">[paper]</a></td>\n<td align=\"center\">86.03</td>\n<td align=\"center\">79.35</td>\n<td align=\"center\">Feb 2020</td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"><code>bert-ada-rest-0.1</code></td>\n<td align=\"center\">86.51</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"left\"><code>bert-ada-lapt-0.1</code></td>\n<td align=\"center\"></td>\n<td align=\"center\">80.23</td>\n<td align=\"center\"></td>\n</tr></tbody></table>\n<p>There are two available models for the restaurant and laptop domains.\nThe hyper-parameters optimization with the explanation how to train a model is <a href=\"examples/train_classifier.py\" rel=\"nofollow\">here</a>.\nYou can easily reproduce our evaluations.\nLook at the performance tests <a href=\"tests/test_performance.py\" rel=\"nofollow\">here</a>.</p>\n<br>\n<h3>Installation</h3>\n<p>You can use the pip:</p>\n<pre>pip install aspect-based-sentiment-analysis\n</pre>\n<p>Otherwise, clone the code and create the new environment via\n<a href=\"https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#\" rel=\"nofollow\">conda</a>:</p>\n<pre>git clone git@github.com:ScalaConsultants/Aspect-Based-Sentiment-Analysis.git\nconda env create -f<span class=\"o\">=</span>environment.yml\nconda activate Aspect-Based-Sentiment-Analysis\n</pre>\n<br>\n<h3>Further Research</h3>\n<p>Even the task is narrow and well-defined, there is still massive work to do.\nBelow we present our few open research issues.\nWe encourage you to help us to improve this package.</p>\n<ul>\n<li>Provide a concrete confidence measure.</li>\n<li>Build the separated model which correlates patterns and linguistics dependencies.</li>\n<li>Process several aspects at once.</li>\n<li>Adapt models across different domains.</li>\n<li>Proper model calibrations (neutral).</li>\n<li>Robust evaluations (adversarial attacks).</li>\n<li>Distill the model (compress the tuned model).</li>\n<li>More interactive visualization tools.</li>\n</ul>\n<br>\n<h3>References</h3>\n<p>How to use BERT for the Aspect-Based Sentiment Analysis:</p>\n<ul>\n<li>Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence (NAACL 2019)\n<a href=\"https://github.com/HSLCY/ABSA-BERT-pair\" rel=\"nofollow\">[code]</a><a href=\"https://www.aclweb.org/anthology/N19-1035/\" rel=\"nofollow\">[paper]</a></li>\n<li>BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis (NAACL 2019)\n<a href=\"https://github.com/howardhsu/BERT-for-RRC-ABSA\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1908.11860\" rel=\"nofollow\">[paper]</a></li>\n<li>Exploiting BERT for End-to-End Aspect-based Sentiment Analysis\n<a href=\"https://github.com/lixin4ever/BERT-E2E-ABSA\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1910.00883\" rel=\"nofollow\">[paper]</a></li>\n</ul>\n<p>Introduction to the BERT interpretability:</p>\n<ul>\n<li>Are Sixteen Heads Really Better than One?\n<a href=\"https://github.com/pmichel31415/are-16-heads-really-better-than-1\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1905.10650\" rel=\"nofollow\">[paper]</a></li>\n<li>A Primer in BERTology: What we know about how BERT works\n<a href=\"http://arxiv.org/abs/2002.12327\" rel=\"nofollow\">[paper]</a></li>\n<li>What Does BERT Look At? An Analysis of BERT's Attention\n<a href=\"https://github.com/clarkkev/attention-analysis\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1906.04341\" rel=\"nofollow\">[paper]</a></li>\n<li>Visualizing and Measuring the Geometry of BERT\n<a href=\"https://github.com/PAIR-code/interpretability\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1906.02715\" rel=\"nofollow\">[paper]</a></li>\n<li>Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment\n<a href=\"http://arxiv.org/abs/1907.11932\" rel=\"nofollow\">[paper]</a></li>\n<li>Adversarial Training for Aspect-Based Sentiment Analysis with BERT\n<a href=\"http://arxiv.org/abs/2001.11316\" rel=\"nofollow\">[paper]</a></li>\n<li>Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT\n<a href=\"http://arxiv.org/abs/2003.04985\" rel=\"nofollow\">[paper]</a></li>\n<li>exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models\n<a href=\"https://github.com/bhoov/exbert\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1910.05276\" rel=\"nofollow\">[paper]</a></li>\n<li>Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings\n<a href=\"https://github.com/uhh-lt/bert-sense\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1909.10430\" rel=\"nofollow\">[paper]</a></li>\n<li>Attention is not Explanation\n<a href=\"https://github.com/successar/AttentionExplanation\" rel=\"nofollow\">[code]</a><a href=\"https://arxiv.org/abs/1902.10186\" rel=\"nofollow\">[paper]</a></li>\n<li>Attention is not not Explanation\n<a href=\"https://github.com/sarahwie/attention\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1908.04626\" rel=\"nofollow\">[paper]</a><a href=\"https://medium.com/@yuvalpinter/attention-is-not-not-explanation-dbc25b534017\" rel=\"nofollow\">[blog post]</a></li>\n<li>Hierarchical interpretations for neural network predictions\n<a href=\"https://github.com/csinva/hierarchical-dnn-interpretations\" rel=\"nofollow\">[code]</a><a href=\"https://arxiv.org/abs/1806.05337\" rel=\"nofollow\">[paper]</a></li>\n<li>Analysis Methods in Neural NLP\n<a href=\"https://github.com/boknilev/nlp-analysis-methods\" rel=\"nofollow\">[code]</a><a href=\"https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00254\" rel=\"nofollow\">[paper]</a></li>\n<li>Visualization for Sequential Neural Networks with Attention\n<a href=\"https://github.com/HendrikStrobelt/Seq2Seq-Vis\" rel=\"nofollow\">[code]</a></li>\n<li>NeuroX: Toolkit for finding and analyzing important neurons in neural networks\n<a href=\"https://github.com/fdalvi/NeuroX\" rel=\"nofollow\">[code]</a><a href=\"https://arxiv.org/abs/1812.09359\" rel=\"nofollow\">[paper]</a></li>\n</ul>\n<p>The State of the Art results:</p>\n<ul>\n<li>A Multi-task Learning Model for Chinese-oriented Aspect Polarity Classification and Aspect Term Extraction\n<a href=\"https://github.com/yangheng95/LCF-ATEPC\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1912.07976\" rel=\"nofollow\">[paper]</a></li>\n<li>Adapt or Get Left Behind: Domain Adaptation through BERT Language Model Finetuning for Aspect-Target Sentiment Classification\n<a href=\"https://github.com/deepopinion/domain-adapted-atsc\" rel=\"nofollow\">[code]</a><a href=\"http://arxiv.org/abs/1908.11860\" rel=\"nofollow\">[paper]</a></li>\n<li>Adversarial Training for Aspect-Based Sentiment Analysis with BERT\n<a href=\"https://github.com/akkarimi/Adversarial-Training-for-ABSA\" rel=\"nofollow\">[code]</a><a href=\"https://arxiv.org/pdf/2001.11316.pdf\" rel=\"nofollow\">[paper]</a></li>\n</ul>\n<p>Other interesting:</p>\n<ul>\n<li>Multi-Dimensional Explanation of Ratings from Reviews\n<a href=\"http://arxiv.org/abs/1909.11386\" rel=\"nofollow\">[paper]</a></li>\n<li>Extracting Syntactic Trees from Transformer Encoder Self-Attentions\n<a href=\"http://aclweb.org/anthology/W18-5444\" rel=\"nofollow\">[paper]</a></li>\n<li>Master Thesis: Transfer and Multitask Learning for Aspect-Based Sentiment Analysis Using the Google Transformer Architecture\n<a href=\"https://github.com/felixSchober/ABSA-Transformer\" rel=\"nofollow\">[code]</a></li>\n<li>Create interactive textual heat maps for Jupiter notebooks\n<a href=\"https://github.com/AndreasMadsen/python-textualheatmap\" rel=\"nofollow\">[code]</a></li>\n<li>A pyTorch implementation of the DeepMoji model: state-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc\n<a href=\"https://github.com/huggingface/torchMoji\" rel=\"nofollow\">[code]</a></li>\n<li>More you can find <a href=\"https://github.com/jiangqn/Aspect-Based-Sentiment-Analysis\" rel=\"nofollow\">here</a>.</li>\n</ul>\n\n          </div>"}, "last_serial": 7165161, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "9105ff61312a284a15efcd1bb7ddc6c2", "sha256": "13f7a8ed9a909ea6834f12ba68d094f8c9033cdbdb67d7e29b3709993a7e3997"}, "downloads": -1, "filename": "aspect_based_sentiment_analysis-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9105ff61312a284a15efcd1bb7ddc6c2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "~=3.7", "size": 35107, "upload_time": "2020-04-09T10:32:24", "upload_time_iso_8601": "2020-04-09T10:32:24.141807Z", "url": "https://files.pythonhosted.org/packages/8b/c4/28fea6d325f79bc96b3b47abca101a99f71f6e5b6850b907ad95f86119ac/aspect_based_sentiment_analysis-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "afc158d57e986d511e945c7f11b73082", "sha256": "194bcca1ceee657269862b448bf0c9359f26b072e0005abd0b31086d78e4bfc4"}, "downloads": -1, "filename": "aspect-based-sentiment-analysis-1.0.1.tar.gz", "has_sig": false, "md5_digest": "afc158d57e986d511e945c7f11b73082", "packagetype": "sdist", "python_version": "source", "requires_python": "~=3.7", "size": 21596, "upload_time": "2020-04-09T10:32:27", "upload_time_iso_8601": "2020-04-09T10:32:27.069523Z", "url": "https://files.pythonhosted.org/packages/a2/5a/2c9163b86c33b6be677a6174a4abdc6d584fc63ef445ef15c6cb7ff48e75/aspect-based-sentiment-analysis-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "acbc2475528f0bae6b83db944ac1588f", "sha256": "6dad73cb314dacf678a4c7d844a780ddb2fe05c4ddddf78e0135dc74611ccfe3"}, "downloads": -1, "filename": "aspect_based_sentiment_analysis-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "acbc2475528f0bae6b83db944ac1588f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "~=3.7", "size": 36105, "upload_time": "2020-04-14T18:02:57", "upload_time_iso_8601": "2020-04-14T18:02:57.905248Z", "url": "https://files.pythonhosted.org/packages/11/4f/a5d4d97a91f95d9f39f3e5fcee5172c68d06b41553031295e50e4cb7eeda/aspect_based_sentiment_analysis-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "219b46863c8f0a6eb8c550bc9df622b2", "sha256": "cc3ccd39de785c2077c2e25a1307e1c59b3202f5d84d69b3a58dd17505257bf6"}, "downloads": -1, "filename": "aspect-based-sentiment-analysis-1.1.0.tar.gz", "has_sig": false, "md5_digest": "219b46863c8f0a6eb8c550bc9df622b2", "packagetype": "sdist", "python_version": "source", "requires_python": "~=3.7", "size": 22620, "upload_time": "2020-04-14T18:02:59", "upload_time_iso_8601": "2020-04-14T18:02:59.146729Z", "url": "https://files.pythonhosted.org/packages/a9/94/c9fe87956a2605007659cf774a247a59f95c7bba7e497be37dff23d94ec8/aspect-based-sentiment-analysis-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "a591b2311c2849f257ae94818361d1d4", "sha256": "cf914b0f40bed51f4830c4d629fbe0e9cb3f053ab18527d5058db8610b652e53"}, "downloads": -1, "filename": "aspect_based_sentiment_analysis-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a591b2311c2849f257ae94818361d1d4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "~=3.7", "size": 42197, "upload_time": "2020-05-04T15:26:43", "upload_time_iso_8601": "2020-05-04T15:26:43.665700Z", "url": "https://files.pythonhosted.org/packages/07/9c/98bd05645370d5806e704e45da4bc6cda7aa157c0293273bd8260038ec9a/aspect_based_sentiment_analysis-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1ce3c9577cf7ac4b749476b5437262c1", "sha256": "e4caa14127e495b0aba0fce41c4e682c6f0fd530458b28efbc28e4df238142d6"}, "downloads": -1, "filename": "aspect-based-sentiment-analysis-1.1.1.tar.gz", "has_sig": false, "md5_digest": "1ce3c9577cf7ac4b749476b5437262c1", "packagetype": "sdist", "python_version": "source", "requires_python": "~=3.7", "size": 32403, "upload_time": "2020-05-04T15:26:45", "upload_time_iso_8601": "2020-05-04T15:26:45.336496Z", "url": "https://files.pythonhosted.org/packages/4a/c2/7e60a3d58991a6eb5df73dd56d8189231dec6cd7cc61f05bfa4cc0c46e6a/aspect-based-sentiment-analysis-1.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a591b2311c2849f257ae94818361d1d4", "sha256": "cf914b0f40bed51f4830c4d629fbe0e9cb3f053ab18527d5058db8610b652e53"}, "downloads": -1, "filename": "aspect_based_sentiment_analysis-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a591b2311c2849f257ae94818361d1d4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": "~=3.7", "size": 42197, "upload_time": "2020-05-04T15:26:43", "upload_time_iso_8601": "2020-05-04T15:26:43.665700Z", "url": "https://files.pythonhosted.org/packages/07/9c/98bd05645370d5806e704e45da4bc6cda7aa157c0293273bd8260038ec9a/aspect_based_sentiment_analysis-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1ce3c9577cf7ac4b749476b5437262c1", "sha256": "e4caa14127e495b0aba0fce41c4e682c6f0fd530458b28efbc28e4df238142d6"}, "downloads": -1, "filename": "aspect-based-sentiment-analysis-1.1.1.tar.gz", "has_sig": false, "md5_digest": "1ce3c9577cf7ac4b749476b5437262c1", "packagetype": "sdist", "python_version": "source", "requires_python": "~=3.7", "size": 32403, "upload_time": "2020-05-04T15:26:45", "upload_time_iso_8601": "2020-05-04T15:26:45.336496Z", "url": "https://files.pythonhosted.org/packages/4a/c2/7e60a3d58991a6eb5df73dd56d8189231dec6cd7cc61f05bfa4cc0c46e6a/aspect-based-sentiment-analysis-1.1.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:57 2020"}