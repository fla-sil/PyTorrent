{"info": {"author": "qichun tang", "author_email": "tqichun@gmail.com", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "==========\nAutoFlow\n==========\n\n``AutoFlow`` : **Automatic machine learning workflow modeling platform**\n\n\nIntroduction\n--------------\n\nIn the problem of data mining and machine learning of tabular data,\ndata scientists usually group the features, construct a directed acyclic graph (DAG),\nand form a machine learning workflow.\n\nIn each directed edge of this directed acyclic graph, \nthe tail node represents the feature group before preprocessing, \nand the head node represents the feature group after preprocessing. \nEdge representation data processing or feature engineering algorithms, \nin each edge algorithm selection and hyper-parameter optimization are doing.\n\nUnfortunately, if data scientists want to manually select algorithms and \nhyper-parameters for such a workflow, \nit will be a very tedious task. In order to solve this problem, \nwe developed the ``Hyperflow``, \nwhich can automatically select algorithm and optimize the parameters of \nmachine learning workflow. \nIn other words, it can implement AutoML for tabular data.\n\n.. image:: docs/images/workflow_space.png\n\n\nDocumentation\n--------------\n\nThe documentation can be found `here <https://auto-flow.github.io/autoflow/>`_.\n\nInstallation\n--------------\n\nRequirements\n~~~~~~~~~~~~~~\n\nThis project is built and test on Linux system, so Linux platform is required. \nIf you are using Windows system, `WSL <https://docs.microsoft.com/en-us/windows/wsl/install-win10>`_ is worthy of considerarion.\n\nBesides the listed requirements (see requirements.txt), the `random forest <https://github.com/automl/random_forest_run>`_ \nused in `SMAC3 <https://github.com/automl/SMAC3>`_ requires \n`SWIG <http://www.swig.org/>`_ (>= 3.0, <4.0) as a build dependency. \nIf you are using Ubuntu or another Debain Linux, you can enter following command :\n\n::\n\n    apt-get install swig\n\nOn Arch Linux (or any distribution with swig4 as default implementation):\n\n::\n\n    pacman -Syu swig3\n    ln -s /usr/bin/swig-3 /usr/bin/swig\n\nAutoFlow requires `Python <https://www.python.org/>`_ 3.6 or higher.\n\nInstallation via pip\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    pip install auto-flow\n\n\nManual Installation\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    git clone https://github.com/auto-flow/autoflow.git && cd autoflow\n    python setup.py install\n\nQuick Start\n--------------\n\n`Titanic <https://www.kaggle.com/c/titanic>`_ is perhaps the most familiar machine learning task for data scientists. \nFor tutorial purposes, you can find titanic dataset in ``examples/data/train_classification.csv`` and\n``examples/data/test_classification.csv`` . \nYou can use AutoFlow to finish this ML task instead of manually exploring all the features of the dataset. DO IT !\n\n.. code-block:: bash\n\n   $ cd examples/classification\n\n.. code-block:: python\n\n    import os\n\n    import joblib\n    import pandas as pd\n    from sklearn.model_selection import KFold\n\n    from autoflow import AutoFlowClassifier\n\n    # load data from csv file\n    train_df = pd.read_csv(\"../data/train_classification.csv\")\n    test_df = pd.read_csv(\"../data/test_classification.csv\")\n    # initial_runs  -- initial runs are totally random search, to provide experience for SMAC algorithm.\n    # run_limit     -- is the maximum number of runs.\n    # n_jobs        -- defines how many search processes are started.\n    # included_classifiers -- restrict the search space . lightgbm is the only classifier that needs to be selected\n    # per_run_time_limit -- restrict the run time. if a trial during 60 seconds, it is expired, should be killed.\n    trained_pipeline = AutoFlowClassifier(initial_runs=5, run_limit=10, n_jobs=1, included_classifiers=[\"lightgbm\"],\n                                        per_run_time_limit=60)\n    # describing meaning of columns. `id`, `target` and `ignore` all has specific meaning\n    # `id` is a column name means unique descriptor of each rows,\n    # `target` column in the dataset is what your model will learn to predict\n    # `ignore` is some columns which contains irrelevant information\n    column_descriptions = {\n        \"id\": \"PassengerId\",\n        \"target\": \"Survived\",\n        \"ignore\": \"Name\"\n    }\n    if not os.path.exists(\"autoflow_classification.bz2\"):\n        # pass `train_df`, `test_df` and `column_descriptions` to classifier,\n        # if param `fit_ensemble_params` set as \"auto\", Stack Ensemble will be used\n        # ``splitter`` is train-valid-dataset splitter, in here it is set as 3-Fold Cross Validation\n        trained_pipeline.fit(\n            X_train=train_df, X_test=test_df, column_descriptions=column_descriptions,\n            fit_ensemble_params=False,\n            splitter=KFold(n_splits=3, shuffle=True, random_state=42),\n        )\n        # finally , the best model will be serialize and store in local file system for subsequent use\n        joblib.dump(trained_pipeline, \"autoflow_classification.bz2\")\n        # if you want to see what the workflow AutoFlow is searching, you can use `draw_workflow_space` to visualize\n        hdl_constructor = trained_pipeline.hdl_constructors[0]\n        hdl_constructor.draw_workflow_space()\n    # suppose you are processing predict procedure, firstly, you should load serialized model from file system\n    predict_pipeline = joblib.load(\"autoflow_classification.bz2\")\n    # secondly, use loaded model to do predicting\n    result = predict_pipeline.predict(test_df)\n    print(result)", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/auto-flow/autoflow", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "auto-flow", "package_url": "https://pypi.org/project/auto-flow/", "platform": "Linux", "project_url": "https://pypi.org/project/auto-flow/", "project_urls": {"Homepage": "https://github.com/auto-flow/autoflow"}, "release_url": "https://pypi.org/project/auto-flow/0.1.1/", "requires_dist": null, "requires_python": ">=3.6.*", "summary": "AutoFlow: Automatic machine learning workflow modeling platform.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><tt>AutoFlow</tt> : <strong>Automatic machine learning workflow modeling platform</strong></p>\n<div id=\"introduction\">\n<h2>Introduction</h2>\n<p>In the problem of data mining and machine learning of tabular data,\ndata scientists usually group the features, construct a directed acyclic graph (DAG),\nand form a machine learning workflow.</p>\n<p>In each directed edge of this directed acyclic graph,\nthe tail node represents the feature group before preprocessing,\nand the head node represents the feature group after preprocessing.\nEdge representation data processing or feature engineering algorithms,\nin each edge algorithm selection and hyper-parameter optimization are doing.</p>\n<p>Unfortunately, if data scientists want to manually select algorithms and\nhyper-parameters for such a workflow,\nit will be a very tedious task. In order to solve this problem,\nwe developed the <tt>Hyperflow</tt>,\nwhich can automatically select algorithm and optimize the parameters of\nmachine learning workflow.\nIn other words, it can implement AutoML for tabular data.</p>\n<img alt=\"docs/images/workflow_space.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8ea1f2add7c2a6610bd7b2a01b738046a584c3f0/646f63732f696d616765732f776f726b666c6f775f73706163652e706e67\">\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>The documentation can be found <a href=\"https://auto-flow.github.io/autoflow/\" rel=\"nofollow\">here</a>.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<div id=\"requirements\">\n<h3>Requirements</h3>\n<p>This project is built and test on Linux system, so Linux platform is required.\nIf you are using Windows system, <a href=\"https://docs.microsoft.com/en-us/windows/wsl/install-win10\" rel=\"nofollow\">WSL</a> is worthy of considerarion.</p>\n<p>Besides the listed requirements (see requirements.txt), the <a href=\"https://github.com/automl/random_forest_run\" rel=\"nofollow\">random forest</a>\nused in <a href=\"https://github.com/automl/SMAC3\" rel=\"nofollow\">SMAC3</a> requires\n<a href=\"http://www.swig.org/\" rel=\"nofollow\">SWIG</a> (&gt;= 3.0, &lt;4.0) as a build dependency.\nIf you are using Ubuntu or another Debain Linux, you can enter following command :</p>\n<pre>apt-get install swig\n</pre>\n<p>On Arch Linux (or any distribution with swig4 as default implementation):</p>\n<pre>pacman -Syu swig3\nln -s /usr/bin/swig-3 /usr/bin/swig\n</pre>\n<p>AutoFlow requires <a href=\"https://www.python.org/\" rel=\"nofollow\">Python</a> 3.6 or higher.</p>\n</div>\n<div id=\"installation-via-pip\">\n<h3>Installation via pip</h3>\n<pre>pip install auto-flow\n</pre>\n</div>\n<div id=\"manual-installation\">\n<h3>Manual Installation</h3>\n<pre>git clone https://github.com/auto-flow/autoflow.git &amp;&amp; cd autoflow\npython setup.py install\n</pre>\n</div>\n</div>\n<div id=\"quick-start\">\n<h2>Quick Start</h2>\n<p><a href=\"https://www.kaggle.com/c/titanic\" rel=\"nofollow\">Titanic</a> is perhaps the most familiar machine learning task for data scientists.\nFor tutorial purposes, you can find titanic dataset in <tt>examples/data/train_classification.csv</tt> and\n<tt>examples/data/test_classification.csv</tt> .\nYou can use AutoFlow to finish this ML task instead of manually exploring all the features of the dataset. DO IT !</p>\n<pre>$ <span class=\"nb\">cd</span> examples/classification\n</pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">joblib</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">KFold</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">autoflow</span> <span class=\"kn\">import</span> <span class=\"n\">AutoFlowClassifier</span>\n\n<span class=\"c1\"># load data from csv file</span>\n<span class=\"n\">train_df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s2\">\"../data/train_classification.csv\"</span><span class=\"p\">)</span>\n<span class=\"n\">test_df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s2\">\"../data/test_classification.csv\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># initial_runs  -- initial runs are totally random search, to provide experience for SMAC algorithm.</span>\n<span class=\"c1\"># run_limit     -- is the maximum number of runs.</span>\n<span class=\"c1\"># n_jobs        -- defines how many search processes are started.</span>\n<span class=\"c1\"># included_classifiers -- restrict the search space . lightgbm is the only classifier that needs to be selected</span>\n<span class=\"c1\"># per_run_time_limit -- restrict the run time. if a trial during 60 seconds, it is expired, should be killed.</span>\n<span class=\"n\">trained_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">AutoFlowClassifier</span><span class=\"p\">(</span><span class=\"n\">initial_runs</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">run_limit</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">included_classifiers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"lightgbm\"</span><span class=\"p\">],</span>\n                                    <span class=\"n\">per_run_time_limit</span><span class=\"o\">=</span><span class=\"mi\">60</span><span class=\"p\">)</span>\n<span class=\"c1\"># describing meaning of columns. `id`, `target` and `ignore` all has specific meaning</span>\n<span class=\"c1\"># `id` is a column name means unique descriptor of each rows,</span>\n<span class=\"c1\"># `target` column in the dataset is what your model will learn to predict</span>\n<span class=\"c1\"># `ignore` is some columns which contains irrelevant information</span>\n<span class=\"n\">column_descriptions</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"id\"</span><span class=\"p\">:</span> <span class=\"s2\">\"PassengerId\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"target\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Survived\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"ignore\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Name\"</span>\n<span class=\"p\">}</span>\n<span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"s2\">\"autoflow_classification.bz2\"</span><span class=\"p\">):</span>\n    <span class=\"c1\"># pass `train_df`, `test_df` and `column_descriptions` to classifier,</span>\n    <span class=\"c1\"># if param `fit_ensemble_params` set as \"auto\", Stack Ensemble will be used</span>\n    <span class=\"c1\"># ``splitter`` is train-valid-dataset splitter, in here it is set as 3-Fold Cross Validation</span>\n    <span class=\"n\">trained_pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span>\n        <span class=\"n\">X_train</span><span class=\"o\">=</span><span class=\"n\">train_df</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"o\">=</span><span class=\"n\">test_df</span><span class=\"p\">,</span> <span class=\"n\">column_descriptions</span><span class=\"o\">=</span><span class=\"n\">column_descriptions</span><span class=\"p\">,</span>\n        <span class=\"n\">fit_ensemble_params</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n        <span class=\"n\">splitter</span><span class=\"o\">=</span><span class=\"n\">KFold</span><span class=\"p\">(</span><span class=\"n\">n_splits</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n    <span class=\"c1\"># finally , the best model will be serialize and store in local file system for subsequent use</span>\n    <span class=\"n\">joblib</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">(</span><span class=\"n\">trained_pipeline</span><span class=\"p\">,</span> <span class=\"s2\">\"autoflow_classification.bz2\"</span><span class=\"p\">)</span>\n    <span class=\"c1\"># if you want to see what the workflow AutoFlow is searching, you can use `draw_workflow_space` to visualize</span>\n    <span class=\"n\">hdl_constructor</span> <span class=\"o\">=</span> <span class=\"n\">trained_pipeline</span><span class=\"o\">.</span><span class=\"n\">hdl_constructors</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"n\">hdl_constructor</span><span class=\"o\">.</span><span class=\"n\">draw_workflow_space</span><span class=\"p\">()</span>\n<span class=\"c1\"># suppose you are processing predict procedure, firstly, you should load serialized model from file system</span>\n<span class=\"n\">predict_pipeline</span> <span class=\"o\">=</span> <span class=\"n\">joblib</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"autoflow_classification.bz2\"</span><span class=\"p\">)</span>\n<span class=\"c1\"># secondly, use loaded model to do predicting</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">predict_pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">test_df</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">)</span>\n</pre>\n</div>\n\n          </div>"}, "last_serial": 7031808, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "92296da1bbd06e4de489c06833c24a79", "sha256": "3dd795cdc984b282a412c92862ef2c91a96d2670b8d1db6e51207bb64cf6f18a"}, "downloads": -1, "filename": "auto-flow-0.1.1.tar.gz", "has_sig": false, "md5_digest": "92296da1bbd06e4de489c06833c24a79", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 193200, "upload_time": "2020-04-16T12:24:45", "upload_time_iso_8601": "2020-04-16T12:24:45.694618Z", "url": "https://files.pythonhosted.org/packages/fd/c1/0eaa7dc382458e6a29d7883394d28aae5fd2615d59747b6d4278438950ba/auto-flow-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "92296da1bbd06e4de489c06833c24a79", "sha256": "3dd795cdc984b282a412c92862ef2c91a96d2670b8d1db6e51207bb64cf6f18a"}, "downloads": -1, "filename": "auto-flow-0.1.1.tar.gz", "has_sig": false, "md5_digest": "92296da1bbd06e4de489c06833c24a79", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 193200, "upload_time": "2020-04-16T12:24:45", "upload_time_iso_8601": "2020-04-16T12:24:45.694618Z", "url": "https://files.pythonhosted.org/packages/fd/c1/0eaa7dc382458e6a29d7883394d28aae5fd2615d59747b6d4278438950ba/auto-flow-0.1.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:17 2020"}