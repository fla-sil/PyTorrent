{"info": {"author": "Tim Savannah", "author_email": "kata198@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Internet :: WWW/HTTP", "Topic :: Software Development :: Libraries :: Python Modules", "Topic :: Text Processing :: Markup :: HTML"], "description": "jsonToCsv\n=========\n\nConverts json data to csv via a meta language (format string)\n\nThe output csv is RFC 4180 compliant by default (behaviour can be changed with options).\n\n\nThe Problem\n-----------\n\nThe problem with converting json to csv is that json is a dynamic, multi-typed, nested format. Csv on the other hand is a fixed single-type format.\n\nJsonToCsv solves this by defining a meta language (format string) which can be used to define repeatable and fixed-format steps, allowing the flattening of the wide json domain space into the slim csv space.\n\n\n\nFormat String\n=============\n\nBecause csv is a fixed-format field and json is free-format, a meta language had to be developed to describe the various movements to find and output values into a fixerd format. This section describes that format.\n\n**Format str:**\n\n\tThe format str is a series of operations and keys, plus zero or more \"line item\"s.\n\n**Keys:**\n\n\t\n\tEvery key name listed in the format string is quoted with double-quotes.\n\n\tIf the key is prefixed with an operation, it is used to REACH a value.\n\n\tIf a key is NOT prefixed with an operation, it becomes a value printed.\n\n\tUnless you are using an op to change level, the quoted key should be followed\n\t by a comma to separate.\n\n\tA key may be anywhere before, after, or inside a line item,\n\tand the keys will be output in the order they appear.\n\n\tExamples:\n\n\t\t\"hostname\"   # Print key hostname at current level\n\n\t\t.\"hostname\"[ # The . (map access) operator applied on the \"hostname\" key\n\n\t\t\"hostname\", \"cheese\" # Two keys at this current level\n\t\n\n**Line Item:**\n\n\tA \"line item\" is the key iterated-over to produce each line of the csv.\n\n\tA line item is given with the '+' sign before a key.\n\n\tYou may have multiple line items (so iterate over multiple keys), and you will have\n\n\t  one line of output per each innermost line item found.\n\n\tYou may not close a line item and then try to open another one at another level.\n\n\tIf you have no line items defined (like a single record), one csv line will be produced.\n\n\n\n\tExamples:\n\n\t\t+\"instances\"[  # For each item in the array at current level given by key \n\t                 #   \"instances\", we will generate a csv line.\n\n\t\t.\"Something\"[  # Go into key at root named 'Something'\n\t\t+\"Data\"[     # Iterate over each element in the array found at \"Data\"\n\t\t+\"instances\" # Iterate again over each element in the array found at \"instances\" within each \"Data\"\n\n\n**Map Access:**\n\n\tThe \"map access\" operator means to access a key at the current level\n\n\tand progresses the 'current level' to include this key access.\n\n\tA map access is given with the '.' operator before a key\n\n\n\tExample:\n\n\t\t.\"Data\"[   # Descend the 'current level' by the key \"Data\"\n\n**List-Map Access:**\n\n\tThe \"list-map access\" operator means to search a list of maps at the current level,\n\t  found under the given key, until a key in that map matches a given value.\n\n\tYou use the \"/\" operator prefix to the key, and within the square bracket define a comparitive op.\n\n\tIt will stop on the FIRST match that it finds. Duplicates are not supported because it would create\n\t  an arbitrary number of fields (and csv is fixed-field)\n\n\tFor example, if you had a key \"attributes\" which held a bunch of maps like {\"key\" : ... , \"value\" : ... }\n\n\t  and you want select the map where \"key\" == \"color\", it would look like this:\n\n\t  /\"attributes\"[\"key\"=\"color\"\n\n\n**Moving Between Levels:**\n\n\tYou'll notice that every op descends a level, represented by being followed by a square bracket, \"[\".\n\n\tIf you want to ascend back up to the previous level, simply close the square bracket \"]\".\n\n\tAll open brackets must be closed before the format string ends.\n\n\n**Whitespace Characters:**\n\n\tSpaces and newlines are generally ignored, and can be used to make things look nice.\n\n**Comments:**\n\n\tYou can comment directly in the format string by using the hash [ '#' ] character.\n\n\tEverything following the hash character to the end-of-line will be ignored.\n\n\tThis is useful in conjunction with mulit-line patterns to document what each line is doing.\n\n\tSee the \"Example with inline comments\" section for an example of both.\n\nCommas:\n\n\tCommas should be used to separate items on the same level, so after a quoted-key for printing,\n\tand after a close-bracket \"]\" if more items follow on that upper level.\n\nOrder:\n\n\tKeys are printed as found left-to-right in the format string.\n\n\tYou can descend into levels, back up, print keys, then descend back into those levels as many\n\t  times as you like.\n\n\nNulls:\n\n\t If a value in the json map is \"null\" or undefined,\n\n\t an empty string is given for the value (by default, can be changed to any string).\n\n\t If there is an error following the format string to a key (like a missing key, or bad type),\n\n\t you can pass the '--debug' flag to print on stderr WHY it returned null, each time that it does.\n\nCase sensitive:\n\n\tAll keys are case sensitive.\n\nMulti-Line:\n\n\tBecause non-quoted whitespace is ignored, you can use newlines, spaces, and tabs to make long patterns more readable.\n\n\nTool\n====\n\nThis module ships with a script, jsonToCsv, which can be used standalone to perform the operations.\n\n\tUsage: jsonToCsv [format str]\n\n\t\tFormats a json string ( delivered via stdin ) to csv, based on provided format str.\n\n\t\t\n\t\tOptions:\n\n\n\t\t\t--null-value=XXX          Use \"XXX\" instead of an empty string as the null value\n\n\t\t\t--quote-fields=X          Defaults to \"Smart quoting\", i.e. fields will be quoted\n\n\t\t\t\t\t\t\t\t\t\taccording to RFC 4180 as-needed. You can specify \"true\" or \"false\"\n\n\t\t\t\t\t\t\t\t\t\there explicitly to force a behaviour\n\n\n\n\t\t\t--help                    Show this message\n\n\t\t\t--format-help             Show usage on format string representation\n\n\n\t\t\t--version                 Print the version\n\n\tExample:\n\n\t\tcat myFile.json | jsonToCsv '+\"Results\"[\"name\", \"org\"]'\n\n\n\nModule\n======\n\nThe primary public module is json_to_csv.JsonToCsv\n\nThe constructor requires only the format string [formatStr] ( a string written in a simple specific meta-language used to define the pattern for extraction ).\n\nYou may, however, choose to define an alternate value to represent unreachable or defined-as-null fields [nullValue]\n\n\nModule PyDoc\n------------\n\nYou can access the pydoc here: http://htmlpreview.github.io/?https://github.com/kata198/jsonToCsv/blob/master/doc/index.html\n\n\n\nModule Usage Example\n--------------------\n\nSee: https://github.com/kata198/jsonToCsv/blob/master/example.py and https://github.com/kata198/jsonToCsv/blob/master/example_mutli.py.\n\nFor a basic example of using the module directly for extraction and reformatting into various formats (CSV, TSV, a text table)\n\n\nExtracting Data\n---------------\n\nOnce you've written your formatStr and created the JsonToCsv object, you're ready to start parsing!\n\n\n**extractData**\n\nextractData is the \"core\" method of JsonToCsv. It performs the actual work of taking the json and following the format string to create a series of lines.\n\nThe output of this method is a list of lists, the outer list is each line, and each line is a list where each element represents a field.\n\nSome more complicated use-cases where \"extractData\" is required are:\n\n* Creating alternate formats of output (like TSV or a text table, or plugging into a GUI)\n\n* Analysis of the data, i.e. filtering or modifying\n\n* Joining data from multiple JSON entries (see that section for more info)\n\n* Whatever you need to do\n\nYou can pass the output of this function to the \"dataToStr\" method to convert it into a printable string.\n\n**dataToStr**\n\ndataToStr provides the means to convert data (from extractData) to a printable string.\n\nThe first argument is the list-of-lists that extractData provides\n\nIt then has the following optional arguments:\n\n* separator - Defaults to comma, may use tab for TSV, or whatever you want\n\n* lineSeparator - Defaults to CRLF (\\\\r\\\\n) which is the RFC4180 standard, but you may use something else (like \\\\n).\n\n* quoteFields - This you can set to True or False to explicitly quote or not quote data per RFC4180 standards. The default is the string \"smart\", which means the data will be scanned to see if it needs quoting, and if so, it will quote the data. Otherwise, it will not. Generally you will want to keep this at the default.\n\n\n**convertToCsv**\n\nThe most basic and direct method is the \"convertToCsv\" function. You can pass in a string (raw data) or a dict (already parsed e.g. by 'json' module ), and you'll be output the csv lines, ready to be passed to the \"print\" function. \n\nThis is the same as calling extractData and passing it to dataToStr, except you can only use comma as a separator through this function.\n\nThis function takes the same \"lineSeparator\" and \"quoteFields\" arguments described in \"dataToStr\" above.\n\n\n**findDuplicates**\n\nThis function can help you identify when multiple lines contain the same data in the same field. \n\nYou pass in the data extracted by *extractData*, pick a zero-origin \"fieldNum\", which dictates which field to check on each line for duplicate values.\n\nIf the \"flat\" argument is False (default), the output is a map where the keys are all the field values which had duplicate entries.\n\nIf \"flat\" is True, the output is just a list of list-of field values. Basically, the data from extractData, but ONLY included if it has a duplicate in the chosen field.\n\n\n**joinCsv**\n\njoinCsv will take in two sets of list<list<str>> (i.e. returned frmo \"extractData\"), and two 0-origin numbers, joinFieldNum1 (what is the index of the \"join field\" in the first dataset) and joinFieldNum2.\n\nSo for example, you may have two sets of data, both describing people. \"Social Security Number\" could be the 4th field from zero on one of them, and the 0th on another dataset. So if you want to combine these two datasets, you can use this method to do so, bt joining those fields (i.e. any instances where there's a field match between the two joinFieldNum columns, that index is removed from the second dataset, sand the second dataset is appended to the first.\n\n**multiJoinCsv**\n\nSame as joinCsv, but joinCsv allows no duplicates within a dataset itself. So going with the data above, imagine if the same social security number had two people's names in one dataset.... well which one is rght? A computer can't determine that.\n\nSo this function will give a \"best effort\", in the above example, you'd get person X's dataset attached to whoemver had that social security number listed. So if you have a field duplicated twice in both csvData1 and csvData2, you'll end up with 4 lines total:\n\n\n* A1 B1\n* A2 B1\n* A1 B2\n* A2 B3\n\nThis matches very eagerly, but you may start to get some invalid data at this point.\n\n\n\n\nFULL EXAMPLE:\n--------------\n\n\t.\"Data\"[ +\"Instances\"[ \"hostname\", /\"attrs\"[\"key\"=\"role\" \"value\"], /\"attrs\"[\"key\"=\"created_at\" \"value\", \"who_set\"], .\"Performance\"[ \"cpus\", \"memory\" ] ] ]\n\n\n**Explanation:**\n\n\nThe given json object will first be descended by the \"Data\" key, where a map is expected.\n\nIn this map, \"Instances\" will be the \"line item\", i.e. we will iterate over each item in the \"Instances\" list to generate each line of the csv.\n\nSo, for each map in \"Instances\":\n\n   * We print the \"hostname\" key as the first csv element\n\n   * We descend into a list of maps under the key \"attrs\",\n   \n   * Search for where one of those maps has an entry \"key\" with the value \"role\", and we print the value of the \"value\" key of that map as the second csv element.\n\nThen, we return to previous level.\n\nWe descend again into that list of maps under the key \"attrs\",\n\n   * Search for where one of those maps has an entry \"key\" with the value \"created_at\",\n     and we print the value of the \"value\" key of that map as the third csv element.\n\n   * We then print value of the \"who_set\" key of that same map as the fourth csv element.\n\nThen, we return to the previous level\n\nWe then descend into a map under the key 'Performance'\n\n   * we print the value of the key \"cpus\" at this level as the fifth csv element.\n   * we print the value of the key \"memory\" at this level as the sixth csv element.\n\nThen, we return to the previous level\n\nWe return to the previous level\n\n(we are done iterating at this point)\n\nWe return to the previous level\n\n**Example with inline comments:**\n\nThe following is the meant to parse the following json: https://github.com/kata198/jsonToCsv/blob/master/example_multi.json\n\n\n\tPARSE_STR = '''\n\n\t\t\t\"date\",             # First element of every line will be the value of\n\n\n\n\t\t\t\t\t\t\t\t#  \"date\" at the top level\n\n\t\t\t+\"results\"[         # Iterate over each member of the list under \"results\"\n\n\t\t\t  \"myBeforeKey\",    # Include \"myBeforeKey\" as the next item in every line\n\n\t\t\t\t+\"instances\"[   # Iterate over each member of the list under \"instances\"\n\n\t\t\t\t\t\"hostname\", # Include \"hostname\" under \"instances\" in each line\n\n\t\t\t\t\t\"ip\"        # Next key to add is \"ip\"\n\n\t\t\t\t\t/\"attributes\"[\"name\"=\"status\"  # Descend into a list-of-maps under \"attributes\" and look\n\n\t\t\t\t\t\t\t\t\t\t\t\t   #  for where the key \"name\" has the value \"status\"\n\n\t\t\t\t\t\t\"value\"                    # In the matched-map, print the value of the key \"value\"\n\n\t\t\t\t\t],                             # Leave this matched map, return to one level up\n\n\t\t\t\t\t.\"puppet_data\"[                # Descend into map found at \"puppet_data\" key\n\n\t\t\t\t\t\t\"hostgroup\"                # Print the \"hostgroup\" key at this level\n\n\t\t\t\t\t],                             # Return to previous level\n\n\t\t\t\t\t/\"attributes\"[\"name\"=\"domain\"  # Descend into a list-of-maps under \"attributes\" and look\n\n\t\t\t\t\t\t\t\t\t\t\t\t   #  for where the key \"name\" has the value \"domain\"\n\n\t\t\t\t\t\t\"value\"                    # Print the \"value\" key in this matched map\n\n\t\t\t\t\t],                             # Go back up to previous level\n\n\t\t\t\t\t/\"attributes\"[\"name\"=\"owner\"   # Descend into a list-of-maps at \"attributes\" and look\n\n\t\t\t\t\t\t\t\t\t\t\t\t   #  for where the key \"name\" has the value \"owner\"\n\n\t\t\t\t\t\t\"value\"                    # Print the key \"value\" at this level\n\n\t\t\t\t\t]                              # Go back to previous level\n\n\t\t\t\t]                                  # Go back to previous level\n\n\t\t\t\t\"myAfterKey\"                       # Append to all previous lines the value of key \"myAfterKey\"\n\n\t\t\t],                                     # Go back up a level\n\n\t\t\t\"name\"                                # Append to all previous lines the value of key \"name\"\n\n\t'''", "description_content_type": null, "docs_url": "https://pythonhosted.org/jsonToCsv/", "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kata198/jsonToCsv", "keywords": "json,to,csv,convert,extract,parse,rfc4180,text/csv,jsonToCsv", "license": "LGPLv3", "maintainer": "", "maintainer_email": "", "name": "jsonToCsv", "package_url": "https://pypi.org/project/jsonToCsv/", "platform": "", "project_url": "https://pypi.org/project/jsonToCsv/", "project_urls": {"Homepage": "https://github.com/kata198/jsonToCsv"}, "release_url": "https://pypi.org/project/jsonToCsv/1.0.1/", "requires_dist": null, "requires_python": "", "summary": "Extract data from json and convert to CSV", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"jsontocsv\">\n<h2>jsonToCsv</h2>\n<p>Converts json data to csv via a meta language (format string)</p>\n<p>The output csv is RFC 4180 compliant by default (behaviour can be changed with options).</p>\n<div id=\"the-problem\">\n<h3>The Problem</h3>\n<p>The problem with converting json to csv is that json is a dynamic, multi-typed, nested format. Csv on the other hand is a fixed single-type format.</p>\n<p>JsonToCsv solves this by defining a meta language (format string) which can be used to define repeatable and fixed-format steps, allowing the flattening of the wide json domain space into the slim csv space.</p>\n</div>\n</div>\n<div id=\"format-string\">\n<h2>Format String</h2>\n<p>Because csv is a fixed-format field and json is free-format, a meta language had to be developed to describe the various movements to find and output values into a fixerd format. This section describes that format.</p>\n<p><strong>Format str:</strong></p>\n<blockquote>\nThe format str is a series of operations and keys, plus zero or more \u201cline item\u201ds.</blockquote>\n<p><strong>Keys:</strong></p>\n<blockquote>\n<p>Every key name listed in the format string is quoted with double-quotes.</p>\n<p>If the key is prefixed with an operation, it is used to REACH a value.</p>\n<p>If a key is NOT prefixed with an operation, it becomes a value printed.</p>\n<dl>\n<dt>Unless you are using an op to change level, the quoted key should be followed</dt>\n<dd>by a comma to separate.</dd>\n</dl>\n<p>A key may be anywhere before, after, or inside a line item,\nand the keys will be output in the order they appear.</p>\n<p>Examples:</p>\n<blockquote>\n<p>\u201chostname\u201d   # Print key hostname at current level</p>\n<p>.\u201dhostname\u201d[ # The . (map access) operator applied on the \u201chostname\u201d key</p>\n<p>\u201chostname\u201d, \u201ccheese\u201d # Two keys at this current level</p>\n</blockquote>\n</blockquote>\n<p><strong>Line Item:</strong></p>\n<blockquote>\n<p>A \u201cline item\u201d is the key iterated-over to produce each line of the csv.</p>\n<p>A line item is given with the \u2018+\u2019 sign before a key.</p>\n<p>You may have multiple line items (so iterate over multiple keys), and you will have</p>\n<blockquote>\none line of output per each innermost line item found.</blockquote>\n<p>You may not close a line item and then try to open another one at another level.</p>\n<p>If you have no line items defined (like a single record), one csv line will be produced.</p>\n<p>Examples:</p>\n<blockquote>\n<dl>\n<dt>+\u201dinstances\u201d[  # For each item in the array at current level given by key</dt>\n<dd>#   \u201cinstances\u201d, we will generate a csv line.</dd>\n</dl>\n<p>.\u201dSomething\u201d[  # Go into key at root named \u2018Something\u2019\n+\u201dData\u201d[     # Iterate over each element in the array found at \u201cData\u201d\n+\u201dinstances\u201d # Iterate again over each element in the array found at \u201cinstances\u201d within each \u201cData\u201d</p>\n</blockquote>\n</blockquote>\n<p><strong>Map Access:</strong></p>\n<blockquote>\n<p>The \u201cmap access\u201d operator means to access a key at the current level</p>\n<p>and progresses the \u2018current level\u2019 to include this key access.</p>\n<p>A map access is given with the \u2018.\u2019 operator before a key</p>\n<p>Example:</p>\n<blockquote>\n.\u201dData\u201d[   # Descend the \u2018current level\u2019 by the key \u201cData\u201d</blockquote>\n</blockquote>\n<p><strong>List-Map Access:</strong></p>\n<blockquote>\n<dl>\n<dt>The \u201clist-map access\u201d operator means to search a list of maps at the current level,</dt>\n<dd>found under the given key, until a key in that map matches a given value.</dd>\n</dl>\n<p>You use the \u201c/\u201d operator prefix to the key, and within the square bracket define a comparitive op.</p>\n<dl>\n<dt>It will stop on the FIRST match that it finds. Duplicates are not supported because it would create</dt>\n<dd>an arbitrary number of fields (and csv is fixed-field)</dd>\n</dl>\n<p>For example, if you had a key \u201cattributes\u201d which held a bunch of maps like {\u201ckey\u201d : \u2026 , \u201cvalue\u201d : \u2026 }</p>\n<blockquote>\n<p>and you want select the map where \u201ckey\u201d == \u201ccolor\u201d, it would look like this:</p>\n<p>/\u201dattributes\u201d[\u201ckey\u201d=\u201dcolor\u201d</p>\n</blockquote>\n</blockquote>\n<p><strong>Moving Between Levels:</strong></p>\n<blockquote>\n<p>You\u2019ll notice that every op descends a level, represented by being followed by a square bracket, \u201c[\u201c.</p>\n<p>If you want to ascend back up to the previous level, simply close the square bracket \u201c]\u201d.</p>\n<p>All open brackets must be closed before the format string ends.</p>\n</blockquote>\n<p><strong>Whitespace Characters:</strong></p>\n<blockquote>\nSpaces and newlines are generally ignored, and can be used to make things look nice.</blockquote>\n<p><strong>Comments:</strong></p>\n<blockquote>\n<p>You can comment directly in the format string by using the hash [ \u2018#\u2019 ] character.</p>\n<p>Everything following the hash character to the end-of-line will be ignored.</p>\n<p>This is useful in conjunction with mulit-line patterns to document what each line is doing.</p>\n<p>See the \u201cExample with inline comments\u201d section for an example of both.</p>\n</blockquote>\n<p>Commas:</p>\n<blockquote>\nCommas should be used to separate items on the same level, so after a quoted-key for printing,\nand after a close-bracket \u201c]\u201d if more items follow on that upper level.</blockquote>\n<p>Order:</p>\n<blockquote>\n<p>Keys are printed as found left-to-right in the format string.</p>\n<dl>\n<dt>You can descend into levels, back up, print keys, then descend back into those levels as many</dt>\n<dd>times as you like.</dd>\n</dl>\n</blockquote>\n<p>Nulls:</p>\n<blockquote>\n<p>If a value in the json map is \u201cnull\u201d or undefined,</p>\n<p>an empty string is given for the value (by default, can be changed to any string).</p>\n<p>If there is an error following the format string to a key (like a missing key, or bad type),</p>\n<p>you can pass the \u2018\u2013debug\u2019 flag to print on stderr WHY it returned null, each time that it does.</p>\n</blockquote>\n<p>Case sensitive:</p>\n<blockquote>\nAll keys are case sensitive.</blockquote>\n<p>Multi-Line:</p>\n<blockquote>\nBecause non-quoted whitespace is ignored, you can use newlines, spaces, and tabs to make long patterns more readable.</blockquote>\n</div>\n<div id=\"tool\">\n<h2>Tool</h2>\n<p>This module ships with a script, jsonToCsv, which can be used standalone to perform the operations.</p>\n<blockquote>\n<p>Usage: jsonToCsv [format str]</p>\n<blockquote>\n<p>Formats a json string ( delivered via stdin ) to csv, based on provided format str.</p>\n<p>Options:</p>\n<blockquote>\n<table>\n<col>\n<col>\n<tbody>\n<tr><td>\n<kbd><span class=\"option\">--null-value=<var>XXX</var></span></kbd></td>\n</tr>\n<tr><td>\u00a0</td><td>Use \u201cXXX\u201d instead of an empty string as the null value</td></tr>\n</tbody>\n</table>\n<p>\u2014quote-fields=X          Defaults to \u201cSmart quoting\u201d, i.e. fields will be quoted</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>according to RFC 4180 as-needed. You can specify \u201ctrue\u201d or \u201cfalse\u201d</p>\n<p>here explicitly to force a behaviour</p>\n</blockquote>\n<p>\u2014help                    Show this message</p>\n</blockquote>\n<blockquote>\n<table>\n<col>\n<col>\n<tbody>\n<tr><td>\n<kbd><span class=\"option\">--format-help</span></kbd></td>\n<td>Show usage on format string representation</td></tr>\n</tbody>\n</table>\n<p>\u2014version                 Print the version</p>\n</blockquote>\n</blockquote>\n<p>Example:</p>\n<blockquote>\ncat myFile.json | jsonToCsv \u2018+\u201dResults\u201d[\u201cname\u201d, \u201corg\u201d]\u2019</blockquote>\n</blockquote>\n</div>\n<div id=\"module\">\n<h2>Module</h2>\n<p>The primary public module is json_to_csv.JsonToCsv</p>\n<p>The constructor requires only the format string [formatStr] ( a string written in a simple specific meta-language used to define the pattern for extraction ).</p>\n<p>You may, however, choose to define an alternate value to represent unreachable or defined-as-null fields [nullValue]</p>\n<div id=\"module-pydoc\">\n<h3>Module PyDoc</h3>\n<p>You can access the pydoc here: <a href=\"http://htmlpreview.github.io/?https://github.com/kata198/jsonToCsv/blob/master/doc/index.html\" rel=\"nofollow\">http://htmlpreview.github.io/?https://github.com/kata198/jsonToCsv/blob/master/doc/index.html</a></p>\n</div>\n<div id=\"module-usage-example\">\n<h3>Module Usage Example</h3>\n<p>See: <a href=\"https://github.com/kata198/jsonToCsv/blob/master/example.py\" rel=\"nofollow\">https://github.com/kata198/jsonToCsv/blob/master/example.py</a> and <a href=\"https://github.com/kata198/jsonToCsv/blob/master/example_mutli.py\" rel=\"nofollow\">https://github.com/kata198/jsonToCsv/blob/master/example_mutli.py</a>.</p>\n<p>For a basic example of using the module directly for extraction and reformatting into various formats (CSV, TSV, a text table)</p>\n</div>\n<div id=\"extracting-data\">\n<h3>Extracting Data</h3>\n<p>Once you\u2019ve written your formatStr and created the JsonToCsv object, you\u2019re ready to start parsing!</p>\n<p><strong>extractData</strong></p>\n<p>extractData is the \u201ccore\u201d method of JsonToCsv. It performs the actual work of taking the json and following the format string to create a series of lines.</p>\n<p>The output of this method is a list of lists, the outer list is each line, and each line is a list where each element represents a field.</p>\n<p>Some more complicated use-cases where \u201cextractData\u201d is required are:</p>\n<ul>\n<li>Creating alternate formats of output (like TSV or a text table, or plugging into a GUI)</li>\n<li>Analysis of the data, i.e. filtering or modifying</li>\n<li>Joining data from multiple JSON entries (see that section for more info)</li>\n<li>Whatever you need to do</li>\n</ul>\n<p>You can pass the output of this function to the \u201cdataToStr\u201d method to convert it into a printable string.</p>\n<p><strong>dataToStr</strong></p>\n<p>dataToStr provides the means to convert data (from extractData) to a printable string.</p>\n<p>The first argument is the list-of-lists that extractData provides</p>\n<p>It then has the following optional arguments:</p>\n<ul>\n<li>separator - Defaults to comma, may use tab for TSV, or whatever you want</li>\n<li>lineSeparator - Defaults to CRLF (\\r\\n) which is the RFC4180 standard, but you may use something else (like \\n).</li>\n<li>quoteFields - This you can set to True or False to explicitly quote or not quote data per RFC4180 standards. The default is the string \u201csmart\u201d, which means the data will be scanned to see if it needs quoting, and if so, it will quote the data. Otherwise, it will not. Generally you will want to keep this at the default.</li>\n</ul>\n<p><strong>convertToCsv</strong></p>\n<p>The most basic and direct method is the \u201cconvertToCsv\u201d function. You can pass in a string (raw data) or a dict (already parsed e.g. by \u2018json\u2019 module ), and you\u2019ll be output the csv lines, ready to be passed to the \u201cprint\u201d function.</p>\n<p>This is the same as calling extractData and passing it to dataToStr, except you can only use comma as a separator through this function.</p>\n<p>This function takes the same \u201clineSeparator\u201d and \u201cquoteFields\u201d arguments described in \u201cdataToStr\u201d above.</p>\n<p><strong>findDuplicates</strong></p>\n<p>This function can help you identify when multiple lines contain the same data in the same field.</p>\n<p>You pass in the data extracted by <em>extractData</em>, pick a zero-origin \u201cfieldNum\u201d, which dictates which field to check on each line for duplicate values.</p>\n<p>If the \u201cflat\u201d argument is False (default), the output is a map where the keys are all the field values which had duplicate entries.</p>\n<p>If \u201cflat\u201d is True, the output is just a list of list-of field values. Basically, the data from extractData, but ONLY included if it has a duplicate in the chosen field.</p>\n<p><strong>joinCsv</strong></p>\n<p>joinCsv will take in two sets of list&lt;list&lt;str&gt;&gt; (i.e. returned frmo \u201cextractData\u201d), and two 0-origin numbers, joinFieldNum1 (what is the index of the \u201cjoin field\u201d in the first dataset) and joinFieldNum2.</p>\n<p>So for example, you may have two sets of data, both describing people. \u201cSocial Security Number\u201d could be the 4th field from zero on one of them, and the 0th on another dataset. So if you want to combine these two datasets, you can use this method to do so, bt joining those fields (i.e. any instances where there\u2019s a field match between the two joinFieldNum columns, that index is removed from the second dataset, sand the second dataset is appended to the first.</p>\n<p><strong>multiJoinCsv</strong></p>\n<p>Same as joinCsv, but joinCsv allows no duplicates within a dataset itself. So going with the data above, imagine if the same social security number had two people\u2019s names in one dataset\u2026. well which one is rght? A computer can\u2019t determine that.</p>\n<p>So this function will give a \u201cbest effort\u201d, in the above example, you\u2019d get person X\u2019s dataset attached to whoemver had that social security number listed. So if you have a field duplicated twice in both csvData1 and csvData2, you\u2019ll end up with 4 lines total:</p>\n<ul>\n<li>A1 B1</li>\n<li>A2 B1</li>\n<li>A1 B2</li>\n<li>A2 B3</li>\n</ul>\n<p>This matches very eagerly, but you may start to get some invalid data at this point.</p>\n</div>\n<div id=\"full-example\">\n<h3>FULL EXAMPLE:</h3>\n<blockquote>\n.\u201dData\u201d[ +\u201dInstances\u201d[ \u201chostname\u201d, /\u201dattrs\u201d[\u201ckey\u201d=\u201drole\u201d \u201cvalue\u201d], /\u201dattrs\u201d[\u201ckey\u201d=\u201dcreated_at\u201d \u201cvalue\u201d, \u201cwho_set\u201d], .\u201dPerformance\u201d[ \u201ccpus\u201d, \u201cmemory\u201d ] ] ]</blockquote>\n<p><strong>Explanation:</strong></p>\n<p>The given json object will first be descended by the \u201cData\u201d key, where a map is expected.</p>\n<p>In this map, \u201cInstances\u201d will be the \u201cline item\u201d, i.e. we will iterate over each item in the \u201cInstances\u201d list to generate each line of the csv.</p>\n<p>So, for each map in \u201cInstances\u201d:</p>\n<blockquote>\n<ul>\n<li>We print the \u201chostname\u201d key as the first csv element</li>\n<li>We descend into a list of maps under the key \u201cattrs\u201d,</li>\n<li>Search for where one of those maps has an entry \u201ckey\u201d with the value \u201crole\u201d, and we print the value of the \u201cvalue\u201d key of that map as the second csv element.</li>\n</ul>\n</blockquote>\n<p>Then, we return to previous level.</p>\n<p>We descend again into that list of maps under the key \u201cattrs\u201d,</p>\n<blockquote>\n<ul>\n<li>Search for where one of those maps has an entry \u201ckey\u201d with the value \u201ccreated_at\u201d,\nand we print the value of the \u201cvalue\u201d key of that map as the third csv element.</li>\n<li>We then print value of the \u201cwho_set\u201d key of that same map as the fourth csv element.</li>\n</ul>\n</blockquote>\n<p>Then, we return to the previous level</p>\n<p>We then descend into a map under the key \u2018Performance\u2019</p>\n<blockquote>\n<ul>\n<li>we print the value of the key \u201ccpus\u201d at this level as the fifth csv element.</li>\n<li>we print the value of the key \u201cmemory\u201d at this level as the sixth csv element.</li>\n</ul>\n</blockquote>\n<p>Then, we return to the previous level</p>\n<p>We return to the previous level</p>\n<p>(we are done iterating at this point)</p>\n<p>We return to the previous level</p>\n<p><strong>Example with inline comments:</strong></p>\n<p>The following is the meant to parse the following json: <a href=\"https://github.com/kata198/jsonToCsv/blob/master/example_multi.json\" rel=\"nofollow\">https://github.com/kata198/jsonToCsv/blob/master/example_multi.json</a></p>\n<blockquote>\n<p>PARSE_STR = \u2018\u2019\u2019</p>\n<blockquote>\n<p>\u201cdate\u201d,             # First element of every line will be the value of</p>\n<blockquote>\n#  \u201cdate\u201d at the top level</blockquote>\n<p>+\u201dresults\u201d[         # Iterate over each member of the list under \u201cresults\u201d</p>\n<blockquote>\n<p>\u201cmyBeforeKey\u201d,    # Include \u201cmyBeforeKey\u201d as the next item in every line</p>\n<blockquote>\n<p>+\u201dinstances\u201d[   # Iterate over each member of the list under \u201cinstances\u201d</p>\n<blockquote>\n<p>\u201chostname\u201d, # Include \u201chostname\u201d under \u201cinstances\u201d in each line</p>\n<p>\u201cip\u201d        # Next key to add is \u201cip\u201d</p>\n<p>/\u201dattributes\u201d[\u201cname\u201d=\u201dstatus\u201d  # Descend into a list-of-maps under \u201cattributes\u201d and look</p>\n<blockquote>\n<blockquote>\n#  for where the key \u201cname\u201d has the value \u201cstatus\u201d</blockquote>\n<p>\u201cvalue\u201d                    # In the matched-map, print the value of the key \u201cvalue\u201d</p>\n</blockquote>\n<p>],                             # Leave this matched map, return to one level up</p>\n<p>.\u201dpuppet_data\u201d[                # Descend into map found at \u201cpuppet_data\u201d key</p>\n<blockquote>\n\u201chostgroup\u201d                # Print the \u201chostgroup\u201d key at this level</blockquote>\n<p>],                             # Return to previous level</p>\n<p>/\u201dattributes\u201d[\u201cname\u201d=\u201ddomain\u201d  # Descend into a list-of-maps under \u201cattributes\u201d and look</p>\n<blockquote>\n<blockquote>\n#  for where the key \u201cname\u201d has the value \u201cdomain\u201d</blockquote>\n<p>\u201cvalue\u201d                    # Print the \u201cvalue\u201d key in this matched map</p>\n</blockquote>\n<p>],                             # Go back up to previous level</p>\n<p>/\u201dattributes\u201d[\u201cname\u201d=\u201downer\u201d   # Descend into a list-of-maps at \u201cattributes\u201d and look</p>\n<blockquote>\n<blockquote>\n#  for where the key \u201cname\u201d has the value \u201cowner\u201d</blockquote>\n<p>\u201cvalue\u201d                    # Print the key \u201cvalue\u201d at this level</p>\n</blockquote>\n<p>]                              # Go back to previous level</p>\n</blockquote>\n<p>]                                  # Go back to previous level</p>\n<p>\u201cmyAfterKey\u201d                       # Append to all previous lines the value of key \u201cmyAfterKey\u201d</p>\n</blockquote>\n</blockquote>\n<p>],                                     # Go back up a level</p>\n<p>\u201cname\u201d                                # Append to all previous lines the value of key \u201cname\u201d</p>\n</blockquote>\n<p>\u2018\u2019\u2019</p>\n</blockquote>\n</div>\n</div>\n\n          </div>"}, "last_serial": 2705388, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "2b2d698051b634e7fca0e09aa29b8c87", "sha256": "9466228bc8e854e457b083dffaf9c0d8de0a72aedaade16d40d53e61c6971f6f"}, "downloads": -1, "filename": "jsonToCsv-0.1.0.tar.gz", "has_sig": false, "md5_digest": "2b2d698051b634e7fca0e09aa29b8c87", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13678, "upload_time": "2017-02-19T06:18:00", "upload_time_iso_8601": "2017-02-19T06:18:00.819575Z", "url": "https://files.pythonhosted.org/packages/29/7f/cfbe3bcdd2ef5b6d3d55fcc7d3b767d45b5609c2ac71083ed04f7479e762/jsonToCsv-0.1.0.tar.gz", "yanked": false}], "0.1.0.1": [{"comment_text": "", "digests": {"md5": "e7c44a6f78ced1e0698dfad97231944c", "sha256": "aec53162df2c53141c25a6296101b4aa0dfa99af5e9ab250fccf3a33625bce2c"}, "downloads": -1, "filename": "jsonToCsv-0.1.0.1.tar.gz", "has_sig": false, "md5_digest": "e7c44a6f78ced1e0698dfad97231944c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22511, "upload_time": "2017-02-19T06:42:15", "upload_time_iso_8601": "2017-02-19T06:42:15.394440Z", "url": "https://files.pythonhosted.org/packages/2f/4f/4e160f9a1b1f10001d986463498e5f85db8d7feaad04973ae9e560b64539/jsonToCsv-0.1.0.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "49b535608bd036086222bd9bd5281847", "sha256": "e7b99169790a21a448ed1acbf05518e099d6efd689562aa9b15384b4903007f8"}, "downloads": -1, "filename": "jsonToCsv-0.2.0.tar.gz", "has_sig": false, "md5_digest": "49b535608bd036086222bd9bd5281847", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24316, "upload_time": "2017-02-28T20:11:06", "upload_time_iso_8601": "2017-02-28T20:11:06.880238Z", "url": "https://files.pythonhosted.org/packages/6e/bb/dc9ca47df4412dc8b735525dbed399d3567ee5d21bab54081874792da56d/jsonToCsv-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "4bd1c1cde896aaba5990a9c4e406699d", "sha256": "fef6fec334d96822adde6d9a10f50c261fc6b9d6adf306f266c4a68c8635d6a5"}, "downloads": -1, "filename": "jsonToCsv-0.2.1.tar.gz", "has_sig": false, "md5_digest": "4bd1c1cde896aaba5990a9c4e406699d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24592, "upload_time": "2017-03-13T20:19:48", "upload_time_iso_8601": "2017-03-13T20:19:48.498897Z", "url": "https://files.pythonhosted.org/packages/e4/d5/9a6499007a2d5cb7644e168c832cc8a06823a17eba35d3195dbacef47ac7/jsonToCsv-0.2.1.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "2a65c6ceabadbbc0dca7b18455c77a32", "sha256": "2aeccfb1c63c919bbdaf592467772ad861048df39a9750bba112482e384737f4"}, "downloads": -1, "filename": "jsonToCsv-1.0.0.tar.gz", "has_sig": false, "md5_digest": "2a65c6ceabadbbc0dca7b18455c77a32", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38380, "upload_time": "2017-03-14T03:16:19", "upload_time_iso_8601": "2017-03-14T03:16:19.859590Z", "url": "https://files.pythonhosted.org/packages/f8/44/81f6b678156e413d578fe4381ff930b715ee12cc9dd94c1fbfb0b3125f47/jsonToCsv-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "dc29cc178c96133a574619fac650d3a7", "sha256": "062aeeb809bd155121c43658043b001b0d477332d4f562ae3b379d6f078c1972"}, "downloads": -1, "filename": "jsonToCsv-1.0.1.tar.gz", "has_sig": false, "md5_digest": "dc29cc178c96133a574619fac650d3a7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40223, "upload_time": "2017-03-14T17:09:08", "upload_time_iso_8601": "2017-03-14T17:09:08.678146Z", "url": "https://files.pythonhosted.org/packages/2c/c7/01a57cbd710c7e7ccd8443dd033162be528a5319cb54966dd72d4359611f/jsonToCsv-1.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dc29cc178c96133a574619fac650d3a7", "sha256": "062aeeb809bd155121c43658043b001b0d477332d4f562ae3b379d6f078c1972"}, "downloads": -1, "filename": "jsonToCsv-1.0.1.tar.gz", "has_sig": false, "md5_digest": "dc29cc178c96133a574619fac650d3a7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40223, "upload_time": "2017-03-14T17:09:08", "upload_time_iso_8601": "2017-03-14T17:09:08.678146Z", "url": "https://files.pythonhosted.org/packages/2c/c7/01a57cbd710c7e7ccd8443dd033162be528a5319cb54966dd72d4359611f/jsonToCsv-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:35 2020"}