{"info": {"author": "Federico Tomasi", "author_email": "federico.tomasi@dibris.unige.it", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Operating System :: MacOS", "Operating System :: POSIX", "Operating System :: Unix", "Programming Language :: Python", "Topic :: Scientific/Engineering :: Bio-Informatics", "Topic :: Software Development"], "description": "# MIDAS\n\nThis repository contains python code that implements various estimators of entropy and mutual information.\nIn particular, Renyi Multi Information and Tsallis Multi Information estimators are available.\n\n## Quickstart\nInstall `midas` from the Python Package Index by using `pip`, via\n```bash\npip install midasML\n```\n\nAlternatively, you can clone it from our Github repository with\n\n```bash\n$ git clone https://github.com/SheffieldML/midas\n```\nand then install it with\n\n```bash\n$ python setup.py install\n```\nfrom the main folder of `midas`.\n\n## Working example\n\nTo test `midas`, you can use the following example.\nCreate a toy dataset specifying the correlation between some variables.\n```python\nimport numpy as np\nfrom midas.estimator import RenyiMutualInformationDivergence, MIDAS\nfrom midas.model_assessment import permutation_test_score_groups\nfrom midas.utils import sample_generation\n\nnp.random.seed(30)\nn_samples, n_dim = 30, 20\nrho_s = [.95, .9, .8, 0, 0]\nX, y, feature_names, groups = sample_generation.make_groups_joint(n_samples, n_dim, rho_s=rho_s)\n\nestimator = RenyiMutualInformationDivergence(alpha=0.99, k=3, n_iter=20)\nresult = permutation_test_score_groups(MIDAS(estimator), X, y, groups, n_jobs=-1)\n```\nThe first 3 groups of features are differentially co-regulated in half of the samples with respect to the other half, while the other groups of features are not (i.e., their co-regulation is the same in the two cases.)\nHence, we can use the `RenyiMutualInformationDivergence` to analyse the co-regulation for different classes of samples, by using `MIDAS` class.\n\n`result` is a `pandas.DataFrame` which contains a summary of the result, which is something like\n\n| | score        | perm_scores           | p-value  | group |\n|-----| ------------- |:-------------:| -----:|:-----|\n0 |\t0.614204 |\t[0.119599699041, 0.17002017399, 0.000642361597...|\t0.009901|\t[0, 1, 2, 3]\n1\t| 1.177062\t|[0.00106705500132, 0.0115119749325, 0.00023392...|\t0.009901\t|[4, 5, 6, 7]\n2\t| 0.223355\t|[0.0, 0.0410519694311, 0.00417966412452, 0.007...|\t0.029703\t|[8, 9, 10, 11]\n3\t| 0.010378\t|[0.00187253953604, 0.00757194385644, 0.0002593...|\t0.445545\t|[12, 13, 14, 15]\n4\t| 0.000000\t|[0.00307271647955, 0.0, 0.0129193052203, 0.010...|\t1.000000\t|[16, 17, 18, 19]\n\nThe first three results should have an high score and a low p-value, since the first three groups are differentially co-regulated by design (as specified before through the `rho_s` array). Hence, as in the example above, the method is capable to correctly address groups of variables as differentially co-regulated in the two classes of samples.\n\n## Other examples\nFor other examples, please refer to Jupyter notebooks present in our Github page at\nhttps://github.com/SheffieldML/midas/tree/master/notebooks.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/SheffieldML/midas/tarball/0.1.0", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/SheffieldML/midas", "keywords": "", "license": "FreeBSD", "maintainer": "", "maintainer_email": "", "name": "midasML", "package_url": "https://pypi.org/project/midasML/", "platform": "", "project_url": "https://pypi.org/project/midasML/", "project_urls": {"Download": "https://github.com/SheffieldML/midas/tarball/0.1.0", "Homepage": "https://github.com/SheffieldML/midas"}, "release_url": "https://pypi.org/project/midasML/0.1.0/", "requires_dist": ["numpy (>=1.10.1)", "scipy (>=0.16.1)", "scikit-learn (>=0.18)"], "requires_python": "", "summary": "Multi Information estimator for Differential Co-regulation Analysis", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            # MIDAS<br><br>This repository contains python code that implements various estimators of entropy and mutual information.<br>In particular, Renyi Multi Information and Tsallis Multi Information estimators are available.<br><br>## Quickstart<br>Install `midas` from the Python Package Index by using `pip`, via<br>```bash<br>pip install midasML<br>```<br><br>Alternatively, you can clone it from our Github repository with<br><br>```bash<br>$ git clone https://github.com/SheffieldML/midas<br>```<br>and then install it with<br><br>```bash<br>$ python setup.py install<br>```<br>from the main folder of `midas`.<br><br>## Working example<br><br>To test `midas`, you can use the following example.<br>Create a toy dataset specifying the correlation between some variables.<br>```python<br>import numpy as np<br>from midas.estimator import RenyiMutualInformationDivergence, MIDAS<br>from midas.model_assessment import permutation_test_score_groups<br>from midas.utils import sample_generation<br><br>np.random.seed(30)<br>n_samples, n_dim = 30, 20<br>rho_s = [.95, .9, .8, 0, 0]<br>X, y, feature_names, groups = sample_generation.make_groups_joint(n_samples, n_dim, rho_s=rho_s)<br><br>estimator = RenyiMutualInformationDivergence(alpha=0.99, k=3, n_iter=20)<br>result = permutation_test_score_groups(MIDAS(estimator), X, y, groups, n_jobs=-1)<br>```<br>The first 3 groups of features are differentially co-regulated in half of the samples with respect to the other half, while the other groups of features are not (i.e., their co-regulation is the same in the two cases.)<br>Hence, we can use the `RenyiMutualInformationDivergence` to analyse the co-regulation for different classes of samples, by using `MIDAS` class.<br><br>`result` is a `pandas.DataFrame` which contains a summary of the result, which is something like<br><br>| | score        | perm_scores           | p-value  | group |<br>|-----| ------------- |:-------------:| -----:|:-----|<br>0 |\t0.614204 |\t[0.119599699041, 0.17002017399, 0.000642361597...|\t0.009901|\t[0, 1, 2, 3]<br>1\t| 1.177062\t|[0.00106705500132, 0.0115119749325, 0.00023392...|\t0.009901\t|[4, 5, 6, 7]<br>2\t| 0.223355\t|[0.0, 0.0410519694311, 0.00417966412452, 0.007...|\t0.029703\t|[8, 9, 10, 11]<br>3\t| 0.010378\t|[0.00187253953604, 0.00757194385644, 0.0002593...|\t0.445545\t|[12, 13, 14, 15]<br>4\t| 0.000000\t|[0.00307271647955, 0.0, 0.0129193052203, 0.010...|\t1.000000\t|[16, 17, 18, 19]<br><br>The first three results should have an high score and a low p-value, since the first three groups are differentially co-regulated by design (as specified before through the `rho_s` array). Hence, as in the example above, the method is capable to correctly address groups of variables as differentially co-regulated in the two classes of samples.<br><br>## Other examples<br>For other examples, please refer to Jupyter notebooks present in our Github page at<br>https://github.com/SheffieldML/midas/tree/master/notebooks.<br><br><br>\n          </div>"}, "last_serial": 3690931, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "2c1d3e2ccdb22a7d96fa15def23b2ff1", "sha256": "6fe8beb75aafdcdba45aa14e5a8197b8fca1d6888ed20d5bda9a7b34c3b4ca74"}, "downloads": -1, "filename": "midasML-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2c1d3e2ccdb22a7d96fa15def23b2ff1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 23423, "upload_time": "2018-03-21T10:21:55", "upload_time_iso_8601": "2018-03-21T10:21:55.141017Z", "url": "https://files.pythonhosted.org/packages/d4/f7/94175a7cf6bcb6a610122ffb9a3c59d993151ba77704e4e55ce583270ba8/midasML-0.1.0-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2c1d3e2ccdb22a7d96fa15def23b2ff1", "sha256": "6fe8beb75aafdcdba45aa14e5a8197b8fca1d6888ed20d5bda9a7b34c3b4ca74"}, "downloads": -1, "filename": "midasML-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2c1d3e2ccdb22a7d96fa15def23b2ff1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 23423, "upload_time": "2018-03-21T10:21:55", "upload_time_iso_8601": "2018-03-21T10:21:55.141017Z", "url": "https://files.pythonhosted.org/packages/d4/f7/94175a7cf6bcb6a610122ffb9a3c59d993151ba77704e4e55ce583270ba8/midasML-0.1.0-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:54:53 2020"}