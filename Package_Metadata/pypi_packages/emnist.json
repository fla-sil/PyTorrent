{"info": {"author": "Aaron Hosford", "author_email": "hosford42@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Image Recognition"], "description": "# EMNIST\nExtended MNIST - Python Package\n\n## The EMNIST Dataset\n\nThe EMNIST Dataset is an extension to the original MNIST dataset to also include letters. For more details, see\nthe [EMNIST web page](https://www.nist.gov/itl/iad/image-group/emnist-dataset) and the \n[paper](http://arxiv.org/abs/1702.05373) associated with its release:\n\n  Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017).\n  EMNIST: an extension of MNIST to handwritten letters.\n  Retrieved from http://arxiv.org/abs/1702.05373\n\n## The EMNIST Python Package\n\nThis package is a convenience wrapper around the EMNIST Dataset. The package provides functionality to \nautomatically download and cache the dataset, and to load it as numpy arrays, minimizing the boilerplate \nnecessary to make use of the dataset. (NOTE: The author of the Python package is not affiliated in any way \nwith the authors of the dataset and the associated paper.)\n\n## Installation\n\nTo install the EMNIST Python package along with its dependencies, run the following command:\n\n  pip install emnist\n\nThe dataset itself is automatically downloaded and cached when needed. To preemptively download the data\nand avoid a delay later during the execution of your program, execute the following command after\ninstallation:\n\n  python -c \"import emnist; emnist.ensure_cached_data()\"\n\nAlternately, if you have already downloaded the original IDX-formatted dataset from the EMNIST web page,\ncopy or move it to `~/.cache/emnist/`, where `~` is your home folder, and rename it from `gzip.zip` to \n`emnist.zip`. The package will use the existing file rather than downloading it again.\n\n## Usage\n\nUsage of the EMNIST Python package is designed to be very simple. \n\nTo get a listing of the available subsets:\n\n```python\n  >>> from emnist import list_datasets\n  >>> list_datasets()\n  ['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']\n```\n\n(See the [EMNIST web page](https://www.nist.gov/itl/iad/image-group/emnist-dataset) for details on each of \nthese subsets.)\n\nTo load the training samples for the 'digits' subset:\n\n```python\n  >>> from emnist import extract_training_samples\n  >>> images, labels = extract_training_samples('digits')\n  >>> images.shape\n  (240000, 28, 28)\n  >>> labels.shape\n  (240000,)\n```\n\nTo load the test samples for the 'digits' subset:\n\n```python\n  >>> from emnist import extract_test_samples\n  >>> images, labels = extract_test_samples('digits')\n  >>> images.shape\n  (40000, 28, 28)\n  >>> labels.shape\n  (40000,)\n```\n\nData is extracted directly from the downloaded compressed file to minimize disk usage, and is returned \nas standard numpy arrays.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/hosford42/EMNIST", "keywords": "MNIST EMNIST image recognition data dataset numpy idx neural networkmachine learning", "license": "", "maintainer": "", "maintainer_email": "", "name": "emnist", "package_url": "https://pypi.org/project/emnist/", "platform": "", "project_url": "https://pypi.org/project/emnist/", "project_urls": {"Homepage": "https://github.com/hosford42/EMNIST", "The EMNIST Dataset": "https://www.nist.gov/itl/iad/image-group/emnist-dataset", "The EMNIST Paper": "https://arxiv.org/abs/1702.05373v1"}, "release_url": "https://pypi.org/project/emnist/0.0/", "requires_dist": ["numpy", "requests", "tqdm", "matplotlib ; extra == 'inspect'"], "requires_python": ">=3.0", "summary": "Extended MNIST - Python Package", "version": "0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>EMNIST</h1>\n<p>Extended MNIST - Python Package</p>\n<h2>The EMNIST Dataset</h2>\n<p>The EMNIST Dataset is an extension to the original MNIST dataset to also include letters. For more details, see\nthe <a href=\"https://www.nist.gov/itl/iad/image-group/emnist-dataset\" rel=\"nofollow\">EMNIST web page</a> and the\n<a href=\"http://arxiv.org/abs/1702.05373\" rel=\"nofollow\">paper</a> associated with its release:</p>\n<p>Cohen, G., Afshar, S., Tapson, J., &amp; van Schaik, A. (2017).\nEMNIST: an extension of MNIST to handwritten letters.\nRetrieved from <a href=\"http://arxiv.org/abs/1702.05373\" rel=\"nofollow\">http://arxiv.org/abs/1702.05373</a></p>\n<h2>The EMNIST Python Package</h2>\n<p>This package is a convenience wrapper around the EMNIST Dataset. The package provides functionality to\nautomatically download and cache the dataset, and to load it as numpy arrays, minimizing the boilerplate\nnecessary to make use of the dataset. (NOTE: The author of the Python package is not affiliated in any way\nwith the authors of the dataset and the associated paper.)</p>\n<h2>Installation</h2>\n<p>To install the EMNIST Python package along with its dependencies, run the following command:</p>\n<p>pip install emnist</p>\n<p>The dataset itself is automatically downloaded and cached when needed. To preemptively download the data\nand avoid a delay later during the execution of your program, execute the following command after\ninstallation:</p>\n<p>python -c \"import emnist; emnist.ensure_cached_data()\"</p>\n<p>Alternately, if you have already downloaded the original IDX-formatted dataset from the EMNIST web page,\ncopy or move it to <code>~/.cache/emnist/</code>, where <code>~</code> is your home folder, and rename it from <code>gzip.zip</code> to\n<code>emnist.zip</code>. The package will use the existing file rather than downloading it again.</p>\n<h2>Usage</h2>\n<p>Usage of the EMNIST Python package is designed to be very simple.</p>\n<p>To get a listing of the available subsets:</p>\n<pre>  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">emnist</span> <span class=\"kn\">import</span> <span class=\"n\">list_datasets</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">list_datasets</span><span class=\"p\">()</span>\n  <span class=\"p\">[</span><span class=\"s1\">'balanced'</span><span class=\"p\">,</span> <span class=\"s1\">'byclass'</span><span class=\"p\">,</span> <span class=\"s1\">'bymerge'</span><span class=\"p\">,</span> <span class=\"s1\">'digits'</span><span class=\"p\">,</span> <span class=\"s1\">'letters'</span><span class=\"p\">,</span> <span class=\"s1\">'mnist'</span><span class=\"p\">]</span>\n</pre>\n<p>(See the <a href=\"https://www.nist.gov/itl/iad/image-group/emnist-dataset\" rel=\"nofollow\">EMNIST web page</a> for details on each of\nthese subsets.)</p>\n<p>To load the training samples for the 'digits' subset:</p>\n<pre>  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">emnist</span> <span class=\"kn\">import</span> <span class=\"n\">extract_training_samples</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">extract_training_samples</span><span class=\"p\">(</span><span class=\"s1\">'digits'</span><span class=\"p\">)</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">images</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n  <span class=\"p\">(</span><span class=\"mi\">240000</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">)</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n  <span class=\"p\">(</span><span class=\"mi\">240000</span><span class=\"p\">,)</span>\n</pre>\n<p>To load the test samples for the 'digits' subset:</p>\n<pre>  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">emnist</span> <span class=\"kn\">import</span> <span class=\"n\">extract_test_samples</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">extract_test_samples</span><span class=\"p\">(</span><span class=\"s1\">'digits'</span><span class=\"p\">)</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">images</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n  <span class=\"p\">(</span><span class=\"mi\">40000</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">)</span>\n  <span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n  <span class=\"p\">(</span><span class=\"mi\">40000</span><span class=\"p\">,)</span>\n</pre>\n<p>Data is extracted directly from the downloaded compressed file to minimize disk usage, and is returned\nas standard numpy arrays.</p>\n\n          </div>"}, "last_serial": 5005084, "releases": {"0.0": [{"comment_text": "", "digests": {"md5": "f6c36dd714ec2b518d69f4fc849bfd5c", "sha256": "80a3d062aab1f28fc48c895017051d44b3ae17e5bfc4040660714e9b0682d8fc"}, "downloads": -1, "filename": "emnist-0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f6c36dd714ec2b518d69f4fc849bfd5c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0", "size": 7320, "upload_time": "2019-03-29T21:06:47", "upload_time_iso_8601": "2019-03-29T21:06:47.801452Z", "url": "https://files.pythonhosted.org/packages/d1/f4/78b24acbef9e8fe976dda700f16a3606f3b8363b015bc555f8050fbbd8ac/emnist-0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2b3358bf6991319b9d0a42528e76b1b8", "sha256": "755fcc4b63ed12740a9842fa9e8b22e4df019fc2d11b1f4bd0495fd56613ef5e"}, "downloads": -1, "filename": "emnist-0.0.tar.gz", "has_sig": false, "md5_digest": "2b3358bf6991319b9d0a42528e76b1b8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0", "size": 6437, "upload_time": "2019-03-29T21:06:50", "upload_time_iso_8601": "2019-03-29T21:06:50.101792Z", "url": "https://files.pythonhosted.org/packages/3a/f3/679ed5798a04b21cbd257e37509f2bbef306815a52e4ef580b0f70ed756f/emnist-0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f6c36dd714ec2b518d69f4fc849bfd5c", "sha256": "80a3d062aab1f28fc48c895017051d44b3ae17e5bfc4040660714e9b0682d8fc"}, "downloads": -1, "filename": "emnist-0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f6c36dd714ec2b518d69f4fc849bfd5c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0", "size": 7320, "upload_time": "2019-03-29T21:06:47", "upload_time_iso_8601": "2019-03-29T21:06:47.801452Z", "url": "https://files.pythonhosted.org/packages/d1/f4/78b24acbef9e8fe976dda700f16a3606f3b8363b015bc555f8050fbbd8ac/emnist-0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2b3358bf6991319b9d0a42528e76b1b8", "sha256": "755fcc4b63ed12740a9842fa9e8b22e4df019fc2d11b1f4bd0495fd56613ef5e"}, "downloads": -1, "filename": "emnist-0.0.tar.gz", "has_sig": false, "md5_digest": "2b3358bf6991319b9d0a42528e76b1b8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0", "size": 6437, "upload_time": "2019-03-29T21:06:50", "upload_time_iso_8601": "2019-03-29T21:06:50.101792Z", "url": "https://files.pythonhosted.org/packages/3a/f3/679ed5798a04b21cbd257e37509f2bbef306815a52e4ef580b0f70ed756f/emnist-0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:35 2020"}