{"info": {"author": "Azim Ahmadzadeh, Kankana Sinha", "author_email": "aahmadzadeh1@cs.gsu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "## MVTS Data Toolkit v0.2.6\n### A Toolkit for Pre-processing Multivariate Time Series Data\n\n* **Title:** MVTS Data Toolkit: A Toolkit for Pre-processing Multivariate Time Series Data\n* **Journal:** SoftwareX Journal [>](https://www.journals.elsevier.com/softwarex) (Elsevier) -- [*under-review*]\n* **Authors:** Azim Ahmadzadeh [>](https://www.azim-a.com/), Kankana Sinha [>](https://www.linkedin.com/in/kankana-sinha-4b4b13131/), Berkay Aydin [>](https://grid.cs.gsu.edu/~baydin2/), Rafal A. Angryk [>](https://grid.cs.gsu.edu/~rangryk/)\n* **Demo Author:** Azim Ahmadzadeh\n* **Last Modified:** May 03, 2020\n\n![MVTS_Date_Toolkit Icon](https://bitbucket.org/gsudmlab/mvtsdata_toolkit/raw/c8f7e0edcfd899c93d9356d52b7ed8c6b500de04/__icon/MVTS_Data_Toolkit_icon2.png)\n\n\n**Abstract:** We developed a domain-independent Python package to facilitate the\npreprocessing routines required in preparation of any multi-class, multivariate time\nseries data. It provides a comprehensive set of 48 statistical features for extracting\nthe important characteristics of time series. The feature extraction process is\nautomated in a sequential and parallel fashion, and is supplemented with an extensive\nsummary report about the data. Using other modules, different data normalization\nmethods and imputations are at users' disposal. To cater the class-imbalance issue,\nthat is often intrinsic to real-world datasets, a set of generic but user-friendly,\nsampling methods are also developed.\n\n\n**This package provides:**\n\n*  *Feature Collection:* A collection of 48 statistical features for analysis\nof time series,\n*  *Feature Extraction:* An automated feature-extraction process, with both parallel\nand sequential execution capabilities,\n*  *Visualization:* Several quick and easy visualization methods for analysis of the extracted\n features, \n*  *Data Analysis:* A quick analysis of the mvts data and the extracted features,\n*  *Normalization:* A set of data transformation tools for normalization of the\nextracted features,\n*  *Sampling:* A set of generic methods to provide an array of undersampling and\noversampling remedies for balancing the class-imbalance datasets. \n\n\n----\n[![PyPI license](https://img.shields.io/pypi/l/ansicolortags.svg??style=flat-square&logo=appveyor)](https://opensource.org/licenses/MIT)\n[![PyPI license](https://img.shields.io/badge/PyPI-0.2.6-orange??style=flat-square&logo=appveyor)](https://pypi.org/project/mvtsdatatoolkit/)\n[![PyPI license](https://img.shields.io/badge/Doc-Sphinx-blue??style=flat-square&logo=appveyor)](http://dmlab.cs.gsu.edu/docs/mvtsdata_toolkit/)\n----\n\n#### Requirements\n*  Python >= 3.6\n*  For a list of all required packages, see [requirements.txt](./requirements.txt).\n\n----\n#### Try it online\nClick on the badge below to try the demo provided in the notebook `demo.ipynb`, online:\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/git/https%3A%2F%2Fbitbucket.org%2Fgsudmlab%2Fmvtsdata_toolkit%2Fsrc%2Fmaster/master?filepath=.%2Fdemo.ipynb)\n----\n#### Install it from PyPI\nYou can install this package, directly from Python Package Index (PyPI), using `pip` as follows:\n* Linux/Mac OS:\n\n    ```pip install mvtsdatatoolkit```\n* Windows:\n\n**Note**: On windows, the *Microsooft Visual C++* must be\nupdated. Otherwise the error `Microsoft Visual C++ 14.0 is required`\nmight terminate the installation. To solve this issue, see\nthis [Medium post](https://medium.com/@jacky_ttt/day060-fix-error-microsoft-visual-c-14-0-is-required-629413e798cd)\nthat elaborates on this short [Stackoverflow answer](https://stackoverflow.com/a/40888720). \n\n\n[![PyPI license](https://img.shields.io/badge/PyPI-0.2.6-orange??style=flat-square&logo=appveyor)](https://pypi.org/project/mvtsdatatoolkit/)\n\n----\n#### See Documentation\nCheck out the documentation of the project here:\n\n[![PyPI license](https://img.shields.io/badge/Doc-Sphinx-blue??style=flat-square&logo=appveyor)](http://dmlab.cs.gsu.edu/docs/mvtsdata_toolkit/)\n\n----\n\n### Data Rules:\n\n#### MVTS Files\n\nIt is assumed that the input dataset is a collection of multivariate time series (mvts), following\nthese assumptions:\n\n1.  Each mvts is stored in a `tab`-delimited, csv file. Each column represents either the time\n series or some metadata such as timestamp. An mvts dataset with `t`\ntime series and `k` metadata columns, each of length `d`, has a dimension of\n`d * (t + k)`.\n\n2.  File names can also be used to have some metadata encoded using a *tag* followed by\n `[]`, for each piece of info. The *tag* can be any string of characters and indicates\nwhat that piece of info is about, and the actual information should be stored inside\nthe proceeding square brackets. For example, the file-name `A_id[123]_lab[1].csv`\nindicates that this mvts is assigned the id `123` and the label `1`. If *tag*s are used,\nduring the feature extraction process, the metadata will be extracted and also added\nto the tabular extracted features automatically. To learn more about how the *tag*s can\nbe used see the documentation in [features.feature_extractor.py](mvtsdatatoolkit/features/feature_extractor.py)\n.\n\n3.  If the embedded values contain paired braces within `[]`, (e.g. for id,\n`id[123[001]]`), then the metadata extractor would still be able to extract the info\ncorrectly, however for unpaired braces (e.g. for id,\n`id[123[001]`) it will raise an exception.\n\n----\n## Main Components:\n*  All statistical features can be found in\n[features.feature_collection](mvtsdatatoolkit/features/feature_collection.py).\n*  Code for parallel and sequential feature extraction process can be found in\n[features.feature_extractor](mvtsdatatoolkit/features/feature_extractor.py).\n*  Code for parallel and sequential analysis of raw mvts can be found in\n[data_analysis.mvts_data_analysis](mvtsdatatoolkit/data_analysis/mvts_data_analysis.py). \n*  Code for analysis of the extracted features can be found in\n[data_analysis.extracted_features_analysis](mvtsdatatoolkit/data_analysis/extracted_features_analysis.py).\n*  Code for data normalization can be found in\n[normalizing.normalizer](mvtsdatatoolkit/normalizing/normalizer.py).\n*  Code for sampling methods can be found in\n[sampling.sampler](mvtsdatatoolkit/sampling/sampler.py).\n\n\n----\n\n## Demo\n\nA Jupyer notebook is provided to give a tour of the main\nfunctionalities of the package. Running the demo is fairly\nsimple. You need the notebook and the example input.\n\n#### 1. Notebook\nThe Jupyer notebook [demo](demo.ipynb) is at the root directory.\n\nUsers can try the demo in one of the three ways listed below:\n\n* Online: click on the *binder* badge (see above) and you will be\nable to follow the demo on a remote server online. This is the\nsimplest way to try the demo. A user would only need access to\nthe Internet for this method.\n* Locally with package: `pip` install the `mvtsdatatoolkit` package on your local machine\nand download and run the nodebook from the same (virtual or physical)\nmachine. (See the next section for more details.)\n* Locally with source: Clone the `mvtsdata_toolkit` project, install the dependencies\n(listed in [requirements.txt](./requirements.txt) and run the notebook from the same\n(virtual or physical) machine.\n\n#### 2. Input\nA dataset of 2000 mvts files and a configuration file specifically defined for this\ndataset will be downloaded along the steps of this demo.\n\nThe provided dataset is a subset of the benchmark dataset\ncalled *Space Weather ANalytics for Solar Flares*\n(*SWAN-SF*) [2] .\n\n----\n## Need Help Running Demo Locally?\nFollow the steps below to run the demo notebook on your\nlocal machine using *virtualenv* and without having to\nclone the project. If you are more comfortable with\n*conda*/*anaconda* make appropriate adjustments.\n\n(Commands below are specific to Unix-base systems)\n\n* Create a new directory and `cd` into it:\n```bash\nmkdir mvts_demo\ncd mvts_demo/\n```\n* Inside `mvts_demo` directory create a new *virtualenv*\ncalled `venv` and activate the virtual environment:\n```bash\nvirtualenv -p /usr/bin/python3.6 venv\nsource venv/bin/activate\n```\n* Install `mvtsdatatoolkit` (this will consequently install\n`notebook` library among other required libraries):\n```bash\npip install mvtsdatatoolkit\n``` \n* Download the notebook and start the Jupyter notebook:\n```bash\nwget https://bitbucket.org/gsudmlab/mvtsdata_toolkit/downloads/demo.ipynb\njupyter notebook\n```\n----\n\n## Example Code Snippets\n\nIn following examples, the string `'/PATH/TO/CONFIG.YML'` \npoints to the user's configuration file.\n\n----\n#### Data Analysis\nThis package allows analysis of both raw mvts data and the\nextracted features.\n\nUsing [mvts_data_analysis](mvtsdatatoolkit/data_analysis/mvts_data_analysis.py) module\nusers can easily get a glimpse of their raw data.\n\n```python\nfrom mvtsdatatoolkit.data_analysis import MVTSDataAnalysis\nmda = MVTSDataAnalysis('/PATH/TO/CONFIG.YML')\nmda.compute_summary(first_k=50,\n                    params_name=['TOTUSJH', 'TOTBSQ', 'TOTPOT'])\n```\nThen, `mda.print_stat_of_directory()` gives the size of the data, in total\nand on average, and `mda.summary` returns a dataframe with several\nstatistics on each of the time series. The statistics are `Val-Count`,\n`Null-Count`, `mean`, `min`, `max`, and the quartiles `25th`, `50th` (= median),\n`75th`.\n\nFor large datasets, it is recommended to use the parallel version of this\nmethod, as follows:\n```python\nmda.compute_summary_in_parallel(first_k=50,\n                                n_jobs=4,\n                                params_name=['TOTUSJH', 'TOTBSQ', 'TOTPOT'],)\n```\nwhich utilizes 4 processes to extract the summary statistics\nin parallel, on the first `50` mvts files. For more details about\nthe parallel computation see the paper [1].\n\nUsing [extracted_features_analysis](mvtsdatatoolkit/data_analysis/extracted_features_analysis.py)\nmodule users can also get some analyses from the extracted\nfeatures (see Section Feature Extraction). Suppose the\ndataframe of the extracted features is loaded as a pandas\ndataframe into a variable called `extracted_features_df`.\nThen,\n\n```python\nfrom mvtsdatatoolkit.data_analysis import ExtractedFeaturesAnalysis\nefa = ExtractedFeaturesAnalysis(extracted_features_df, excluded_col=['id'])\nefa.compute_summary()\n```\nthat excludes the column `id` of the extracted features from\nthe analysis and computes a set of summary statistics on all\nextracted features.\n\nAfter the summary is computed, the following methods can be used:\n```python\nefa.get_class_population(label='lab')\nefa.get_missing_values()\nefa.get_five_num_summary()\n```\n\n\n----\n#### Feature Extraction\n\nThis snippet shows how [feature_extractor](mvtsdatatoolkit/features/feature_extractor.py)\nmodule can be used, for extracting 4 statistics (i.e., *min*,\n*max*, *median*, and *mean*), from 3 time series parameteres\n(i.e., *TOTUSJH*, *TOTBSQ*, and *TOTPOT*) available in the\nprovided dataset.\n\n```python\nfrom mvtsdatatoolkit.features import FeatureExtractor\n\nfe = FeatureExtractor(path_to_config='/PATH/TO/CONFIG.YML')\nfe.do_extraction(features_name=['get_min', 'get_max', 'get_median', 'get_mean'],\n                 params_name=['TOTUSJH', 'TOTBSQ', 'TOTPOT'], first_k=50)\n```\nNote that user's configuration file must contain the path\nto the raw mvts using the key `PATH_TO_MVTS`.\n\nTo benefit from the parallel execution, do:\n```python\nfe.do_extraction_in_parallel(n_jobs=4,\n                             features_index=[0, 1, 2, 3],\n                             params_index=[0, 1, 2], first_k=50)\n```\nHere, for the sake of providing a richer example, we used\n`features_index` and `params_index` instead of their names (that\nwas already shown in the previous example). This numeric mapping\nof features and parameters makes it easier to deal with a\nlong array of lengthy names. These two lists will be mapped to\nthe list of parameters and features provided in the user's\nconfiguration file, under the keys `MVTS_PARAMETERS` and\n`STATISTICAL_FEATURES`, respectively.\n\nIn `FeatureExtractor` class, several plotting functionalities are\nimplemented that can be easily used as follows:\n\n```python\nparams = ['TOTUSJH_median', 'TOTUSJH_mean', 'TOTBSQ_median', 'TOTBSQ_mean']\nfe.plot_boxplot(params)\nfe.plot_violinplot(params)\nfe.plot_correlation_heatmap(params)\nfe.plot_covariance_heatmap(params)\nfe.plot_splom(params)\n``` \n\n\n----\n#### Sampling\nAfter the statistical features are extracted from the mvts data,\nto remedy the class-imbalance issue (if exists) a set of generic\nsampling methods are provided in [sampler](mvtsdatatoolkit/sampling/sampler.py)\nmodule.\n\n```python\nfrom mvtsdatatoolkit.sampling.sampler import Sampler\n\nsampler = Sampler(extracted_features_df, label_col_name='lab')\nsampler.sample(desired_populations={'N': 100, 'Y': 100})\n```\nAssumming that the dataset has the class labels `Y` and `N`, this\nsnippet of code randomly samples 100 instances of the `N` class\nand 100 instances of the `Y` class instances. If either of the\nclasses does not have enough samples, then after the entire\nsamples are taken, the remaining needed instances will be\nsampled randomly with replacement. Depending on the provided\npopulations, this method could turn into an *undersampling* or\n*oversampling* function.\n\nUsers can use *ratio* instead of *size* as follows:\n```python\nsampler.sample(desrired_ratios = {'N': 0.50, 'Y': -1})\n```\nwhich means take 50% of the entire population would be sampled\nfrom `N`-class instances, and *all* of `Y`-class instances will\nalso be passed to the sampled data.\n\nFor other approaches, see the [/demo](demo1.ipynb).\n\n\n----\n#### Normalizing\nThe extracted features often require normalization. Using\nthe module [normalizer](mvtsdatatoolkit/normalizing/normalizer.py)\n, the features can be quickly normalized as follows:\n\n```python\n\nfrom mvtsdatatoolkit.normalizing import normalizer\nnormalizer.zero_one_normalize()\ndf_normalized = normalizer.zero_one_normalize(extracted_features_df)\n``` \nAgain, `extracted_features_df` is assumed to be a pandas\ndataframe of the extracted features.\n\nIn this module, the following four normalizers are implemented\non top of the *scikit-learn* library.\n\n*  zero_one_normalizer()\n*  negativeone_one_normalize()\n*  standardize()\n*  robust_standardize()\n\n\n----\nExtra files:\n*  [bitbucket-pipelines.yml](./bitbucket-pipelines.yml) is a\nconfiguration file for pipelining the deployment steps before\neach release.\n*  [CONSTANTS.py](./CONSTANTS.py) keeps track of some constant\nvariables such as root path.\n*  [demo.ipynb](demo.ipynb) is the demo Jupyter notebook that\ncan walk the interested users through the functionalities this\ntoolkit provides.\n*  [README.md](./README.md) has the content of this very manual.\n*  [requirements.txt](./requirements.txt) keeps track of all\ndependencies.\n*  [setup.py](./setup.py) is used to generate the binary files\nneeded for generating the pip-installble version of this package.\n\n----\n#### Citation\n\nCurrently, this package is under review in\n[SoftwareX journal](https://www.journals.elsevier.com/softwarex).\nIf you are interested in using this, I can share the manuscript with\nyou. Till it is published, it can be cited as follows:\n\n```\n@article{ahmadzadeh2020mvts,\n  title={MVTS-Data Toolkit: A Python Package for Preprocessing Multivariate Time Series Data}},\n  author={Azim Ahmadzadeh, Kankana Sinha, Berkay Aydin, Rafal A. Angryk},\n  journal={SoftwareX},\n  volume={},\n  pages={},\n  year={under-review},\n  publisher={Elsevier}\n}\n```\n\n----\n#### References\n[1] A. Ahmadzadeh, K. Sinha, 2020. \"MVTS-Data Toolkit:\nA Python Package for Preprocessing Multivariate Time\nSeries Data\", (under review 2020))\n\n[2] Angryk, R.A., Martens, P.C., Aydin, B., Kempton, D.,\nMahajan, S.S., Basodi, S., Ahmadzadeh, A., Cai, X.,\nBoubrahimi, S.F., Hamdi, S.M., Schuh, M.A. and\nGeorgoulis, M.K., 2019. \"Multivariate Time Series\nDataset for Space Weather Data Analytics\".\nSci. Data, Nature, submitted (2019).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://bitbucket.org/gsudmlab/mvtsdata_toolkit/src/master", "keywords": "multivariate,time series,mvts,imbalance,sampling,features", "license": "MIT", "maintainer": "Azim Ahmadzadeh", "maintainer_email": "aahmadzadeh1@cs.gsu.edu", "name": "mvtsdatatoolkit", "package_url": "https://pypi.org/project/mvtsdatatoolkit/", "platform": "", "project_url": "https://pypi.org/project/mvtsdatatoolkit/", "project_urls": {"Documentation": "http://dmlab.cs.gsu.edu/docs/mvtsdata_toolkit/", "Homepage": "https://bitbucket.org/gsudmlab/mvtsdata_toolkit/src/master", "Source": "https://bitbucket.org/gsudmlab/mvtsdata_toolkit/src/master"}, "release_url": "https://pypi.org/project/mvtsdatatoolkit/0.2.6/", "requires_dist": ["pandas (==0.24.2)", "scipy (==1.3.0)", "tdigest (==0.5.2.2)", "seaborn (==0.9.0)", "scikit-learn (==0.21.2)", "matplotlib (==3.1.0)", "hurry.filesize (==0.9)", "PyYAML (==5.1.2)", "tqdm (==4.36.1)", "zipp (==0.6.0)", "urllib3 (==1.24.3)", "notebook (==6.0.1)"], "requires_python": "", "summary": "A Toolkit for Multivariate Time Series Data", "version": "0.2.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h2>MVTS Data Toolkit v0.2.6</h2>\n<h3>A Toolkit for Pre-processing Multivariate Time Series Data</h3>\n<ul>\n<li><strong>Title:</strong> MVTS Data Toolkit: A Toolkit for Pre-processing Multivariate Time Series Data</li>\n<li><strong>Journal:</strong> SoftwareX Journal <a href=\"https://www.journals.elsevier.com/softwarex\" rel=\"nofollow\">&gt;</a> (Elsevier) -- [<em>under-review</em>]</li>\n<li><strong>Authors:</strong> Azim Ahmadzadeh <a href=\"https://www.azim-a.com/\" rel=\"nofollow\">&gt;</a>, Kankana Sinha <a href=\"https://www.linkedin.com/in/kankana-sinha-4b4b13131/\" rel=\"nofollow\">&gt;</a>, Berkay Aydin <a href=\"https://grid.cs.gsu.edu/%7Ebaydin2/\" rel=\"nofollow\">&gt;</a>, Rafal A. Angryk <a href=\"https://grid.cs.gsu.edu/%7Erangryk/\" rel=\"nofollow\">&gt;</a></li>\n<li><strong>Demo Author:</strong> Azim Ahmadzadeh</li>\n<li><strong>Last Modified:</strong> May 03, 2020</li>\n</ul>\n<p><img alt=\"MVTS_Date_Toolkit Icon\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/276d09ab4cf13774523ffeab703fed79a5f527e5/68747470733a2f2f6269746275636b65742e6f72672f677375646d6c61622f6d767473646174615f746f6f6c6b69742f7261772f633866376530656463666438393963393364393335366435326237656438633662353030646530342f5f5f69636f6e2f4d5654535f446174615f546f6f6c6b69745f69636f6e322e706e67\"></p>\n<p><strong>Abstract:</strong> We developed a domain-independent Python package to facilitate the\npreprocessing routines required in preparation of any multi-class, multivariate time\nseries data. It provides a comprehensive set of 48 statistical features for extracting\nthe important characteristics of time series. The feature extraction process is\nautomated in a sequential and parallel fashion, and is supplemented with an extensive\nsummary report about the data. Using other modules, different data normalization\nmethods and imputations are at users' disposal. To cater the class-imbalance issue,\nthat is often intrinsic to real-world datasets, a set of generic but user-friendly,\nsampling methods are also developed.</p>\n<p><strong>This package provides:</strong></p>\n<ul>\n<li><em>Feature Collection:</em> A collection of 48 statistical features for analysis\nof time series,</li>\n<li><em>Feature Extraction:</em> An automated feature-extraction process, with both parallel\nand sequential execution capabilities,</li>\n<li><em>Visualization:</em> Several quick and easy visualization methods for analysis of the extracted\nfeatures,</li>\n<li><em>Data Analysis:</em> A quick analysis of the mvts data and the extracted features,</li>\n<li><em>Normalization:</em> A set of data transformation tools for normalization of the\nextracted features,</li>\n<li><em>Sampling:</em> A set of generic methods to provide an array of undersampling and\noversampling remedies for balancing the class-imbalance datasets.</li>\n</ul>\n<hr>\n<h2><a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"PyPI license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/efdfa76357d712a0e7a762c4f8ce8311f8bdd24d/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f616e7369636f6c6f72746167732e7376673f3f7374796c653d666c61742d737175617265266c6f676f3d6170707665796f72\"></a>\n<a href=\"https://pypi.org/project/mvtsdatatoolkit/\" rel=\"nofollow\"><img alt=\"PyPI license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f92686c8ad142dccce8757fb4e78ff8b9b847b1c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507950492d302e322e362d6f72616e67653f3f7374796c653d666c61742d737175617265266c6f676f3d6170707665796f72\"></a>\n<a href=\"http://dmlab.cs.gsu.edu/docs/mvtsdata_toolkit/\" rel=\"nofollow\"><img alt=\"PyPI license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ee2da222dcca424ef294d65da6526fc039e48116/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f632d537068696e782d626c75653f3f7374796c653d666c61742d737175617265266c6f676f3d6170707665796f72\"></a></h2>\n<h4>Requirements</h4>\n<ul>\n<li>Python &gt;= 3.6</li>\n<li>For a list of all required packages, see <a href=\"./requirements.txt\" rel=\"nofollow\">requirements.txt</a>.</li>\n</ul>\n<hr>\n<h4>Try it online</h4>\n<p>Click on the badge below to try the demo provided in the notebook <code>demo.ipynb</code>, online:</p>\n<h2><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fbitbucket.org%2Fgsudmlab%2Fmvtsdata_toolkit%2Fsrc%2Fmaster/master?filepath=.%2Fdemo.ipynb\" rel=\"nofollow\"><img alt=\"Binder\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85e91bbb928104e4ce317951541520c6b9c170e1/68747470733a2f2f6d7962696e6465722e6f72672f62616467655f6c6f676f2e737667\"></a></h2>\n<h4>Install it from PyPI</h4>\n<p>You can install this package, directly from Python Package Index (PyPI), using <code>pip</code> as follows:</p>\n<ul>\n<li>\n<p>Linux/Mac OS:</p>\n<p><code>pip install mvtsdatatoolkit</code></p>\n</li>\n<li>\n<p>Windows:</p>\n</li>\n</ul>\n<p><strong>Note</strong>: On windows, the <em>Microsooft Visual C++</em> must be\nupdated. Otherwise the error <code>Microsoft Visual C++ 14.0 is required</code>\nmight terminate the installation. To solve this issue, see\nthis <a href=\"https://medium.com/@jacky_ttt/day060-fix-error-microsoft-visual-c-14-0-is-required-629413e798cd\" rel=\"nofollow\">Medium post</a>\nthat elaborates on this short <a href=\"https://stackoverflow.com/a/40888720\" rel=\"nofollow\">Stackoverflow answer</a>.</p>\n<p><a href=\"https://pypi.org/project/mvtsdatatoolkit/\" rel=\"nofollow\"><img alt=\"PyPI license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f92686c8ad142dccce8757fb4e78ff8b9b847b1c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507950492d302e322e362d6f72616e67653f3f7374796c653d666c61742d737175617265266c6f676f3d6170707665796f72\"></a></p>\n<hr>\n<h4>See Documentation</h4>\n<p>Check out the documentation of the project here:</p>\n<p><a href=\"http://dmlab.cs.gsu.edu/docs/mvtsdata_toolkit/\" rel=\"nofollow\"><img alt=\"PyPI license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ee2da222dcca424ef294d65da6526fc039e48116/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f632d537068696e782d626c75653f3f7374796c653d666c61742d737175617265266c6f676f3d6170707665796f72\"></a></p>\n<hr>\n<h3>Data Rules:</h3>\n<h4>MVTS Files</h4>\n<p>It is assumed that the input dataset is a collection of multivariate time series (mvts), following\nthese assumptions:</p>\n<ol>\n<li>\n<p>Each mvts is stored in a <code>tab</code>-delimited, csv file. Each column represents either the time\nseries or some metadata such as timestamp. An mvts dataset with <code>t</code>\ntime series and <code>k</code> metadata columns, each of length <code>d</code>, has a dimension of\n<code>d * (t + k)</code>.</p>\n</li>\n<li>\n<p>File names can also be used to have some metadata encoded using a <em>tag</em> followed by\n<code>[]</code>, for each piece of info. The <em>tag</em> can be any string of characters and indicates\nwhat that piece of info is about, and the actual information should be stored inside\nthe proceeding square brackets. For example, the file-name <code>A_id[123]_lab[1].csv</code>\nindicates that this mvts is assigned the id <code>123</code> and the label <code>1</code>. If <em>tag</em>s are used,\nduring the feature extraction process, the metadata will be extracted and also added\nto the tabular extracted features automatically. To learn more about how the <em>tag</em>s can\nbe used see the documentation in <a href=\"mvtsdatatoolkit/features/feature_extractor.py\" rel=\"nofollow\">features.feature_extractor.py</a>\n.</p>\n</li>\n<li>\n<p>If the embedded values contain paired braces within <code>[]</code>, (e.g. for id,\n<code>id[123[001]]</code>), then the metadata extractor would still be able to extract the info\ncorrectly, however for unpaired braces (e.g. for id,\n<code>id[123[001]</code>) it will raise an exception.</p>\n</li>\n</ol>\n<hr>\n<h2>Main Components:</h2>\n<ul>\n<li>All statistical features can be found in\n<a href=\"mvtsdatatoolkit/features/feature_collection.py\" rel=\"nofollow\">features.feature_collection</a>.</li>\n<li>Code for parallel and sequential feature extraction process can be found in\n<a href=\"mvtsdatatoolkit/features/feature_extractor.py\" rel=\"nofollow\">features.feature_extractor</a>.</li>\n<li>Code for parallel and sequential analysis of raw mvts can be found in\n<a href=\"mvtsdatatoolkit/data_analysis/mvts_data_analysis.py\" rel=\"nofollow\">data_analysis.mvts_data_analysis</a>.</li>\n<li>Code for analysis of the extracted features can be found in\n<a href=\"mvtsdatatoolkit/data_analysis/extracted_features_analysis.py\" rel=\"nofollow\">data_analysis.extracted_features_analysis</a>.</li>\n<li>Code for data normalization can be found in\n<a href=\"mvtsdatatoolkit/normalizing/normalizer.py\" rel=\"nofollow\">normalizing.normalizer</a>.</li>\n<li>Code for sampling methods can be found in\n<a href=\"mvtsdatatoolkit/sampling/sampler.py\" rel=\"nofollow\">sampling.sampler</a>.</li>\n</ul>\n<hr>\n<h2>Demo</h2>\n<p>A Jupyer notebook is provided to give a tour of the main\nfunctionalities of the package. Running the demo is fairly\nsimple. You need the notebook and the example input.</p>\n<h4>1. Notebook</h4>\n<p>The Jupyer notebook <a href=\"demo.ipynb\" rel=\"nofollow\">demo</a> is at the root directory.</p>\n<p>Users can try the demo in one of the three ways listed below:</p>\n<ul>\n<li>Online: click on the <em>binder</em> badge (see above) and you will be\nable to follow the demo on a remote server online. This is the\nsimplest way to try the demo. A user would only need access to\nthe Internet for this method.</li>\n<li>Locally with package: <code>pip</code> install the <code>mvtsdatatoolkit</code> package on your local machine\nand download and run the nodebook from the same (virtual or physical)\nmachine. (See the next section for more details.)</li>\n<li>Locally with source: Clone the <code>mvtsdata_toolkit</code> project, install the dependencies\n(listed in <a href=\"./requirements.txt\" rel=\"nofollow\">requirements.txt</a> and run the notebook from the same\n(virtual or physical) machine.</li>\n</ul>\n<h4>2. Input</h4>\n<p>A dataset of 2000 mvts files and a configuration file specifically defined for this\ndataset will be downloaded along the steps of this demo.</p>\n<p>The provided dataset is a subset of the benchmark dataset\ncalled <em>Space Weather ANalytics for Solar Flares</em>\n(<em>SWAN-SF</em>) [2] .</p>\n<hr>\n<h2>Need Help Running Demo Locally?</h2>\n<p>Follow the steps below to run the demo notebook on your\nlocal machine using <em>virtualenv</em> and without having to\nclone the project. If you are more comfortable with\n<em>conda</em>/<em>anaconda</em> make appropriate adjustments.</p>\n<p>(Commands below are specific to Unix-base systems)</p>\n<ul>\n<li>Create a new directory and <code>cd</code> into it:</li>\n</ul>\n<pre>mkdir mvts_demo\n<span class=\"nb\">cd</span> mvts_demo/\n</pre>\n<ul>\n<li>Inside <code>mvts_demo</code> directory create a new <em>virtualenv</em>\ncalled <code>venv</code> and activate the virtual environment:</li>\n</ul>\n<pre>virtualenv -p /usr/bin/python3.6 venv\n<span class=\"nb\">source</span> venv/bin/activate\n</pre>\n<ul>\n<li>Install <code>mvtsdatatoolkit</code> (this will consequently install\n<code>notebook</code> library among other required libraries):</li>\n</ul>\n<pre>pip install mvtsdatatoolkit\n</pre>\n<ul>\n<li>Download the notebook and start the Jupyter notebook:</li>\n</ul>\n<pre>wget https://bitbucket.org/gsudmlab/mvtsdata_toolkit/downloads/demo.ipynb\njupyter notebook\n</pre>\n<hr>\n<h2>Example Code Snippets</h2>\n<p>In following examples, the string <code>'/PATH/TO/CONFIG.YML'</code>\npoints to the user's configuration file.</p>\n<hr>\n<h4>Data Analysis</h4>\n<p>This package allows analysis of both raw mvts data and the\nextracted features.</p>\n<p>Using <a href=\"mvtsdatatoolkit/data_analysis/mvts_data_analysis.py\" rel=\"nofollow\">mvts_data_analysis</a> module\nusers can easily get a glimpse of their raw data.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mvtsdatatoolkit.data_analysis</span> <span class=\"kn\">import</span> <span class=\"n\">MVTSDataAnalysis</span>\n<span class=\"n\">mda</span> <span class=\"o\">=</span> <span class=\"n\">MVTSDataAnalysis</span><span class=\"p\">(</span><span class=\"s1\">'/PATH/TO/CONFIG.YML'</span><span class=\"p\">)</span>\n<span class=\"n\">mda</span><span class=\"o\">.</span><span class=\"n\">compute_summary</span><span class=\"p\">(</span><span class=\"n\">first_k</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n                    <span class=\"n\">params_name</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'TOTUSJH'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTBSQ'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTPOT'</span><span class=\"p\">])</span>\n</pre>\n<p>Then, <code>mda.print_stat_of_directory()</code> gives the size of the data, in total\nand on average, and <code>mda.summary</code> returns a dataframe with several\nstatistics on each of the time series. The statistics are <code>Val-Count</code>,\n<code>Null-Count</code>, <code>mean</code>, <code>min</code>, <code>max</code>, and the quartiles <code>25th</code>, <code>50th</code> (= median),\n<code>75th</code>.</p>\n<p>For large datasets, it is recommended to use the parallel version of this\nmethod, as follows:</p>\n<pre><span class=\"n\">mda</span><span class=\"o\">.</span><span class=\"n\">compute_summary_in_parallel</span><span class=\"p\">(</span><span class=\"n\">first_k</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n                                <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span>\n                                <span class=\"n\">params_name</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'TOTUSJH'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTBSQ'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTPOT'</span><span class=\"p\">],)</span>\n</pre>\n<p>which utilizes 4 processes to extract the summary statistics\nin parallel, on the first <code>50</code> mvts files. For more details about\nthe parallel computation see the paper [1].</p>\n<p>Using <a href=\"mvtsdatatoolkit/data_analysis/extracted_features_analysis.py\" rel=\"nofollow\">extracted_features_analysis</a>\nmodule users can also get some analyses from the extracted\nfeatures (see Section Feature Extraction). Suppose the\ndataframe of the extracted features is loaded as a pandas\ndataframe into a variable called <code>extracted_features_df</code>.\nThen,</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mvtsdatatoolkit.data_analysis</span> <span class=\"kn\">import</span> <span class=\"n\">ExtractedFeaturesAnalysis</span>\n<span class=\"n\">efa</span> <span class=\"o\">=</span> <span class=\"n\">ExtractedFeaturesAnalysis</span><span class=\"p\">(</span><span class=\"n\">extracted_features_df</span><span class=\"p\">,</span> <span class=\"n\">excluded_col</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'id'</span><span class=\"p\">])</span>\n<span class=\"n\">efa</span><span class=\"o\">.</span><span class=\"n\">compute_summary</span><span class=\"p\">()</span>\n</pre>\n<p>that excludes the column <code>id</code> of the extracted features from\nthe analysis and computes a set of summary statistics on all\nextracted features.</p>\n<p>After the summary is computed, the following methods can be used:</p>\n<pre><span class=\"n\">efa</span><span class=\"o\">.</span><span class=\"n\">get_class_population</span><span class=\"p\">(</span><span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">'lab'</span><span class=\"p\">)</span>\n<span class=\"n\">efa</span><span class=\"o\">.</span><span class=\"n\">get_missing_values</span><span class=\"p\">()</span>\n<span class=\"n\">efa</span><span class=\"o\">.</span><span class=\"n\">get_five_num_summary</span><span class=\"p\">()</span>\n</pre>\n<hr>\n<h4>Feature Extraction</h4>\n<p>This snippet shows how <a href=\"mvtsdatatoolkit/features/feature_extractor.py\" rel=\"nofollow\">feature_extractor</a>\nmodule can be used, for extracting 4 statistics (i.e., <em>min</em>,\n<em>max</em>, <em>median</em>, and <em>mean</em>), from 3 time series parameteres\n(i.e., <em>TOTUSJH</em>, <em>TOTBSQ</em>, and <em>TOTPOT</em>) available in the\nprovided dataset.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mvtsdatatoolkit.features</span> <span class=\"kn\">import</span> <span class=\"n\">FeatureExtractor</span>\n\n<span class=\"n\">fe</span> <span class=\"o\">=</span> <span class=\"n\">FeatureExtractor</span><span class=\"p\">(</span><span class=\"n\">path_to_config</span><span class=\"o\">=</span><span class=\"s1\">'/PATH/TO/CONFIG.YML'</span><span class=\"p\">)</span>\n<span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">do_extraction</span><span class=\"p\">(</span><span class=\"n\">features_name</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'get_min'</span><span class=\"p\">,</span> <span class=\"s1\">'get_max'</span><span class=\"p\">,</span> <span class=\"s1\">'get_median'</span><span class=\"p\">,</span> <span class=\"s1\">'get_mean'</span><span class=\"p\">],</span>\n                 <span class=\"n\">params_name</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'TOTUSJH'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTBSQ'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTPOT'</span><span class=\"p\">],</span> <span class=\"n\">first_k</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">)</span>\n</pre>\n<p>Note that user's configuration file must contain the path\nto the raw mvts using the key <code>PATH_TO_MVTS</code>.</p>\n<p>To benefit from the parallel execution, do:</p>\n<pre><span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">do_extraction_in_parallel</span><span class=\"p\">(</span><span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span>\n                             <span class=\"n\">features_index</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">],</span>\n                             <span class=\"n\">params_index</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">first_k</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">)</span>\n</pre>\n<p>Here, for the sake of providing a richer example, we used\n<code>features_index</code> and <code>params_index</code> instead of their names (that\nwas already shown in the previous example). This numeric mapping\nof features and parameters makes it easier to deal with a\nlong array of lengthy names. These two lists will be mapped to\nthe list of parameters and features provided in the user's\nconfiguration file, under the keys <code>MVTS_PARAMETERS</code> and\n<code>STATISTICAL_FEATURES</code>, respectively.</p>\n<p>In <code>FeatureExtractor</code> class, several plotting functionalities are\nimplemented that can be easily used as follows:</p>\n<pre><span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'TOTUSJH_median'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTUSJH_mean'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTBSQ_median'</span><span class=\"p\">,</span> <span class=\"s1\">'TOTBSQ_mean'</span><span class=\"p\">]</span>\n<span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">plot_boxplot</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n<span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">plot_violinplot</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n<span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">plot_correlation_heatmap</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n<span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">plot_covariance_heatmap</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n<span class=\"n\">fe</span><span class=\"o\">.</span><span class=\"n\">plot_splom</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n</pre>\n<hr>\n<h4>Sampling</h4>\n<p>After the statistical features are extracted from the mvts data,\nto remedy the class-imbalance issue (if exists) a set of generic\nsampling methods are provided in <a href=\"mvtsdatatoolkit/sampling/sampler.py\" rel=\"nofollow\">sampler</a>\nmodule.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mvtsdatatoolkit.sampling.sampler</span> <span class=\"kn\">import</span> <span class=\"n\">Sampler</span>\n\n<span class=\"n\">sampler</span> <span class=\"o\">=</span> <span class=\"n\">Sampler</span><span class=\"p\">(</span><span class=\"n\">extracted_features_df</span><span class=\"p\">,</span> <span class=\"n\">label_col_name</span><span class=\"o\">=</span><span class=\"s1\">'lab'</span><span class=\"p\">)</span>\n<span class=\"n\">sampler</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">desired_populations</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'N'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"s1\">'Y'</span><span class=\"p\">:</span> <span class=\"mi\">100</span><span class=\"p\">})</span>\n</pre>\n<p>Assumming that the dataset has the class labels <code>Y</code> and <code>N</code>, this\nsnippet of code randomly samples 100 instances of the <code>N</code> class\nand 100 instances of the <code>Y</code> class instances. If either of the\nclasses does not have enough samples, then after the entire\nsamples are taken, the remaining needed instances will be\nsampled randomly with replacement. Depending on the provided\npopulations, this method could turn into an <em>undersampling</em> or\n<em>oversampling</em> function.</p>\n<p>Users can use <em>ratio</em> instead of <em>size</em> as follows:</p>\n<pre><span class=\"n\">sampler</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">desrired_ratios</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'N'</span><span class=\"p\">:</span> <span class=\"mf\">0.50</span><span class=\"p\">,</span> <span class=\"s1\">'Y'</span><span class=\"p\">:</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">})</span>\n</pre>\n<p>which means take 50% of the entire population would be sampled\nfrom <code>N</code>-class instances, and <em>all</em> of <code>Y</code>-class instances will\nalso be passed to the sampled data.</p>\n<p>For other approaches, see the <a href=\"demo1.ipynb\" rel=\"nofollow\">/demo</a>.</p>\n<hr>\n<h4>Normalizing</h4>\n<p>The extracted features often require normalization. Using\nthe module <a href=\"mvtsdatatoolkit/normalizing/normalizer.py\" rel=\"nofollow\">normalizer</a>\n, the features can be quickly normalized as follows:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mvtsdatatoolkit.normalizing</span> <span class=\"kn\">import</span> <span class=\"n\">normalizer</span>\n<span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">zero_one_normalize</span><span class=\"p\">()</span>\n<span class=\"n\">df_normalized</span> <span class=\"o\">=</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">zero_one_normalize</span><span class=\"p\">(</span><span class=\"n\">extracted_features_df</span><span class=\"p\">)</span>\n</pre>\n<p>Again, <code>extracted_features_df</code> is assumed to be a pandas\ndataframe of the extracted features.</p>\n<p>In this module, the following four normalizers are implemented\non top of the <em>scikit-learn</em> library.</p>\n<ul>\n<li>zero_one_normalizer()</li>\n<li>negativeone_one_normalize()</li>\n<li>standardize()</li>\n<li>robust_standardize()</li>\n</ul>\n<hr>\n<p>Extra files:</p>\n<ul>\n<li><a href=\"./bitbucket-pipelines.yml\" rel=\"nofollow\">bitbucket-pipelines.yml</a> is a\nconfiguration file for pipelining the deployment steps before\neach release.</li>\n<li><a href=\"./CONSTANTS.py\" rel=\"nofollow\">CONSTANTS.py</a> keeps track of some constant\nvariables such as root path.</li>\n<li><a href=\"demo.ipynb\" rel=\"nofollow\">demo.ipynb</a> is the demo Jupyter notebook that\ncan walk the interested users through the functionalities this\ntoolkit provides.</li>\n<li><a href=\"./README.md\" rel=\"nofollow\">README.md</a> has the content of this very manual.</li>\n<li><a href=\"./requirements.txt\" rel=\"nofollow\">requirements.txt</a> keeps track of all\ndependencies.</li>\n<li><a href=\"./setup.py\" rel=\"nofollow\">setup.py</a> is used to generate the binary files\nneeded for generating the pip-installble version of this package.</li>\n</ul>\n<hr>\n<h4>Citation</h4>\n<p>Currently, this package is under review in\n<a href=\"https://www.journals.elsevier.com/softwarex\" rel=\"nofollow\">SoftwareX journal</a>.\nIf you are interested in using this, I can share the manuscript with\nyou. Till it is published, it can be cited as follows:</p>\n<pre><code>@article{ahmadzadeh2020mvts,\n  title={MVTS-Data Toolkit: A Python Package for Preprocessing Multivariate Time Series Data}},\n  author={Azim Ahmadzadeh, Kankana Sinha, Berkay Aydin, Rafal A. Angryk},\n  journal={SoftwareX},\n  volume={},\n  pages={},\n  year={under-review},\n  publisher={Elsevier}\n}\n</code></pre>\n<hr>\n<h4>References</h4>\n<p>[1] A. Ahmadzadeh, K. Sinha, 2020. \"MVTS-Data Toolkit:\nA Python Package for Preprocessing Multivariate Time\nSeries Data\", (under review 2020))</p>\n<p>[2] Angryk, R.A., Martens, P.C., Aydin, B., Kempton, D.,\nMahajan, S.S., Basodi, S., Ahmadzadeh, A., Cai, X.,\nBoubrahimi, S.F., Hamdi, S.M., Schuh, M.A. and\nGeorgoulis, M.K., 2019. \"Multivariate Time Series\nDataset for Space Weather Data Analytics\".\nSci. Data, Nature, submitted (2019).</p>\n\n          </div>"}, "last_serial": 7159136, "releases": {"0.1.6": [{"comment_text": "", "digests": {"md5": "bb070b9676f061ffc4d4356b0891e0a2", "sha256": "a878ac84b64fb4b835afc120599b89ed26f00846ef6e38745c04f80b23b1c615"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "bb070b9676f061ffc4d4356b0891e0a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7000, "upload_time": "2020-04-18T17:51:58", "upload_time_iso_8601": "2020-04-18T17:51:58.041042Z", "url": "https://files.pythonhosted.org/packages/9b/b8/d5be9e41bf5b3840204acaa979c3126f883aaa6fd6c10073944043b925ec/mvtsdatatoolkit-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3c53f2bf27509359e32d4110c8cc2d47", "sha256": "e732f9b52ca7e0313fcd6256e2e3e7ccc30394edc9b893ed46455e8f6b6ad6b6"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.6.tar.gz", "has_sig": false, "md5_digest": "3c53f2bf27509359e32d4110c8cc2d47", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8017, "upload_time": "2020-04-18T17:52:00", "upload_time_iso_8601": "2020-04-18T17:52:00.264324Z", "url": "https://files.pythonhosted.org/packages/24/9c/331e445ba018cb37b1f500f7a5c25651da9023764609e17c38b306f5304b/mvtsdatatoolkit-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "9d9e7e63e1c80dc51ef656a31259b6e6", "sha256": "04272d0e03e57cc3dc80e44e4e7a7c61f56b3f945e74da2d0ddf38077403e646"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "9d9e7e63e1c80dc51ef656a31259b6e6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6999, "upload_time": "2020-04-20T16:19:03", "upload_time_iso_8601": "2020-04-20T16:19:03.050404Z", "url": "https://files.pythonhosted.org/packages/6a/cc/402b43fb6e47ddbbc79cee02fee9e742be19a24370079b77f676cfeff9fc/mvtsdatatoolkit-0.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "148d8a929ed2c339c1b2f73220b2b5b1", "sha256": "f8cd63a21d15779efc763a78a3c9e708c1db36018228bdc43aa7c738335e0be4"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.7.tar.gz", "has_sig": false, "md5_digest": "148d8a929ed2c339c1b2f73220b2b5b1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8016, "upload_time": "2020-04-20T16:19:04", "upload_time_iso_8601": "2020-04-20T16:19:04.799878Z", "url": "https://files.pythonhosted.org/packages/ec/94/cb3258983f7a2a676d776b9e29660dfcda79f10e900171a24ff8c1331074/mvtsdatatoolkit-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "16111e9986e2e932fc7a02354dfebefc", "sha256": "d5c74f6b8f702f6cec5ce7c0fdeb413b68b7d89958d9cbb28b57d76819240fa7"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "16111e9986e2e932fc7a02354dfebefc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7135, "upload_time": "2020-04-20T17:15:53", "upload_time_iso_8601": "2020-04-20T17:15:53.077152Z", "url": "https://files.pythonhosted.org/packages/60/94/e1311ed75e6579640650539b39fd53b20d237c847bdddce63129b59b48cd/mvtsdatatoolkit-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cf39d46a2ae426d34e614e5e4926ce77", "sha256": "f524bfe15610f6877e599dde056518f2c646721fe0308cc1c09b3bc9b4ea9ff4"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.8.tar.gz", "has_sig": false, "md5_digest": "cf39d46a2ae426d34e614e5e4926ce77", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8282, "upload_time": "2020-04-20T17:15:54", "upload_time_iso_8601": "2020-04-20T17:15:54.717833Z", "url": "https://files.pythonhosted.org/packages/ec/8b/9b2f4e34469fbd75a0af8ac450ff5b9e139725f07549f3f165e357597785/mvtsdatatoolkit-0.1.8.tar.gz", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "95c3262c1bd695761843769e59b16f12", "sha256": "f0656f8376f305101af7cd90a82fc8867a9c71d237cb87b1b9e0990a110fe757"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.9-py3-none-any.whl", "has_sig": false, "md5_digest": "95c3262c1bd695761843769e59b16f12", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7980, "upload_time": "2020-04-20T17:51:25", "upload_time_iso_8601": "2020-04-20T17:51:25.271999Z", "url": "https://files.pythonhosted.org/packages/d5/23/98c373f84297f6b221d313014691fdfaf4f9a4dfff1963aa407f5cb6e4bd/mvtsdatatoolkit-0.1.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b1c77a6c4734ab84c4f115e3ad2f28e8", "sha256": "6b615897969e4e72bef01932836ca76e7ba71958a12287b97d84ba30a2f81ec6"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.1.9.tar.gz", "has_sig": false, "md5_digest": "b1c77a6c4734ab84c4f115e3ad2f28e8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8361, "upload_time": "2020-04-20T17:51:27", "upload_time_iso_8601": "2020-04-20T17:51:27.183780Z", "url": "https://files.pythonhosted.org/packages/5a/4e/be64b12686cab63c615e4e59d64ace494aa63bb2bc9aa23b8fbb0d58cb28/mvtsdatatoolkit-0.1.9.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "31f8dba74e7346c4153b1d9e8f10d8d6", "sha256": "5a491d15cae09aa8977e5dcc1c795ef43e42dfab0524c51d4501240af6d6b157"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "31f8dba74e7346c4153b1d9e8f10d8d6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 45689, "upload_time": "2020-04-20T23:34:37", "upload_time_iso_8601": "2020-04-20T23:34:37.258785Z", "url": "https://files.pythonhosted.org/packages/45/ec/d7480af39e741b8e57eb683a07c3105d67ec559f67e495dc49f387278407/mvtsdatatoolkit-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "11cbe1ed362f2e0b0c717058fac24964", "sha256": "54653c3db89d046b300a81b6eb0bb4ef037a9aa82a6a5ba3a7dfade1b60db68d"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.0.tar.gz", "has_sig": false, "md5_digest": "11cbe1ed362f2e0b0c717058fac24964", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37059, "upload_time": "2020-04-20T23:34:38", "upload_time_iso_8601": "2020-04-20T23:34:38.745726Z", "url": "https://files.pythonhosted.org/packages/7b/c7/f766f11511e523bf6f5a623889c202e75fa6946d27a99ed5890e8d3f9470/mvtsdatatoolkit-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "2ef8c30d6719f7a11f64cdd256b338c0", "sha256": "51498dafaeb5a12529ea1cc27cbf39130486382f54d2a595d4b8959a265baf2c"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2ef8c30d6719f7a11f64cdd256b338c0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 45692, "upload_time": "2020-04-21T16:31:25", "upload_time_iso_8601": "2020-04-21T16:31:25.842851Z", "url": "https://files.pythonhosted.org/packages/48/fe/b62de6e9509478e7eb27319625b033210758dc089152ffa03520a26913fa/mvtsdatatoolkit-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "74ed3f7e88ad7509dbcb9a193e2a4c51", "sha256": "1c66b81e9f7dc15f94bdef2a328db80e214a81df45f3a02da97d21d6af35f4be"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.1.tar.gz", "has_sig": false, "md5_digest": "74ed3f7e88ad7509dbcb9a193e2a4c51", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37101, "upload_time": "2020-04-21T16:31:28", "upload_time_iso_8601": "2020-04-21T16:31:28.010719Z", "url": "https://files.pythonhosted.org/packages/e2/cf/ea83a8c02c81b99f3c4ea4e3ba9f8f4f67ed4722020f3fda9d66c1ffeaef/mvtsdatatoolkit-0.2.1.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "1251481ff14e1c4221b1983c0c2dca5a", "sha256": "b2daa01bba126c93c29a719594f8b345d7fe4ee8c8f9c706efe23d52a9fa30e3"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "1251481ff14e1c4221b1983c0c2dca5a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46765, "upload_time": "2020-04-25T23:38:48", "upload_time_iso_8601": "2020-04-25T23:38:48.650846Z", "url": "https://files.pythonhosted.org/packages/70/6d/64fa68a738383f0d9fc8d50b5f917d9427207e4c70bee45f78273e5417f8/mvtsdatatoolkit-0.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1c0778d7069a19ef76045ad5249ff4eb", "sha256": "1a06883dbbe8ad8a3b96471542e455abda8ce7bdf8343ac08d9c4270c4b6dc89"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.3.tar.gz", "has_sig": false, "md5_digest": "1c0778d7069a19ef76045ad5249ff4eb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38437, "upload_time": "2020-04-25T23:38:50", "upload_time_iso_8601": "2020-04-25T23:38:50.009341Z", "url": "https://files.pythonhosted.org/packages/68/d3/dd21fcdc3dafc08957dbf467af5bfada8a9319335e8f095ba365a89a4e6c/mvtsdatatoolkit-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "4df2de34678ed2d8ebc57609af032508", "sha256": "2049258b195d2affc7b075b6c0c389b3dc61fac8c78b07447009ce95718ea414"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.4-py3-none-any.whl", "has_sig": false, "md5_digest": "4df2de34678ed2d8ebc57609af032508", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46026, "upload_time": "2020-05-03T01:57:51", "upload_time_iso_8601": "2020-05-03T01:57:51.348994Z", "url": "https://files.pythonhosted.org/packages/1c/e3/8ef27189b063795be0cd044609eb9d9a63fb1ddfa1b2d1ac0a000baa33ec/mvtsdatatoolkit-0.2.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6f38c657ebe9b3506f01c1c7362dba41", "sha256": "84aff685f6104adde38c4e9820ba5a801437d21fe1cc4d9bcb2a573f9348b4ca"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.4.tar.gz", "has_sig": false, "md5_digest": "6f38c657ebe9b3506f01c1c7362dba41", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38966, "upload_time": "2020-05-03T01:57:52", "upload_time_iso_8601": "2020-05-03T01:57:52.956417Z", "url": "https://files.pythonhosted.org/packages/d4/33/8c47a7569cb1ba5ac1e8c99cb82a16833a10b26448b7ffeedec117e010b5/mvtsdatatoolkit-0.2.4.tar.gz", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "bd9d0fa51757608c8951800674ad9d4b", "sha256": "521d9c64b6a4e00c0170d221703d3175a50ca09cf059a50f9e8d085d8f7e8e94"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.5-py3-none-any.whl", "has_sig": false, "md5_digest": "bd9d0fa51757608c8951800674ad9d4b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46024, "upload_time": "2020-05-03T03:35:25", "upload_time_iso_8601": "2020-05-03T03:35:25.150087Z", "url": "https://files.pythonhosted.org/packages/44/b6/bf1e78c29a9581a2e83a48fabb64c0ec614d7d27bc8470de25c848c708e6/mvtsdatatoolkit-0.2.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "25408ba35845a7bffd50b6ff1ae071c8", "sha256": "495c97c19a91486b78ca55c0dddc165ae138b2e0a2253686a942237a1a01253d"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.5.tar.gz", "has_sig": false, "md5_digest": "25408ba35845a7bffd50b6ff1ae071c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38972, "upload_time": "2020-05-03T03:35:26", "upload_time_iso_8601": "2020-05-03T03:35:26.973333Z", "url": "https://files.pythonhosted.org/packages/08/4b/c18d21e30a8c82271bbf05e5a880de56063f452069a6c12767a486fa5116/mvtsdatatoolkit-0.2.5.tar.gz", "yanked": false}], "0.2.6": [{"comment_text": "", "digests": {"md5": "4cb7ace6d71090a35e3fe9257fa06167", "sha256": "26515be8c15cffd6f01e3e2b745973013f533be86e7fdf5ceeebfc0040dbe6c5"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.6-py3-none-any.whl", "has_sig": false, "md5_digest": "4cb7ace6d71090a35e3fe9257fa06167", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46272, "upload_time": "2020-05-03T19:13:29", "upload_time_iso_8601": "2020-05-03T19:13:29.204798Z", "url": "https://files.pythonhosted.org/packages/00/24/5652c0d16a1e448727073f320c21fa145fd21ddee5e012b5b60c8354759f/mvtsdatatoolkit-0.2.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7e149745d2d244ceb46f401d9255c39e", "sha256": "011b285a7738df776a615b62c647cc2054c26a379fd5b0a5ec36f702fc4bc79b"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.6.tar.gz", "has_sig": false, "md5_digest": "7e149745d2d244ceb46f401d9255c39e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39306, "upload_time": "2020-05-03T19:13:30", "upload_time_iso_8601": "2020-05-03T19:13:30.827557Z", "url": "https://files.pythonhosted.org/packages/4d/73/9664dcf9bf53d53d95d704ed7d7722ae1c78bde236808d8981f86a4cbe0e/mvtsdatatoolkit-0.2.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4cb7ace6d71090a35e3fe9257fa06167", "sha256": "26515be8c15cffd6f01e3e2b745973013f533be86e7fdf5ceeebfc0040dbe6c5"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.6-py3-none-any.whl", "has_sig": false, "md5_digest": "4cb7ace6d71090a35e3fe9257fa06167", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46272, "upload_time": "2020-05-03T19:13:29", "upload_time_iso_8601": "2020-05-03T19:13:29.204798Z", "url": "https://files.pythonhosted.org/packages/00/24/5652c0d16a1e448727073f320c21fa145fd21ddee5e012b5b60c8354759f/mvtsdatatoolkit-0.2.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7e149745d2d244ceb46f401d9255c39e", "sha256": "011b285a7738df776a615b62c647cc2054c26a379fd5b0a5ec36f702fc4bc79b"}, "downloads": -1, "filename": "mvtsdatatoolkit-0.2.6.tar.gz", "has_sig": false, "md5_digest": "7e149745d2d244ceb46f401d9255c39e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39306, "upload_time": "2020-05-03T19:13:30", "upload_time_iso_8601": "2020-05-03T19:13:30.827557Z", "url": "https://files.pythonhosted.org/packages/4d/73/9664dcf9bf53d53d95d704ed7d7722ae1c78bde236808d8981f86a4cbe0e/mvtsdatatoolkit-0.2.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:00 2020"}