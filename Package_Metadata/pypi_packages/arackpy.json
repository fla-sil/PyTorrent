{"info": {"author": "Denis Gomes", "author_email": "denis.mp.gomes@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6"], "description": "**arackpy**\n===========\n\n**arackpy** is a web spider used to crawl and scrape web pages. It can be\nhelpful in the event you quickly need some data from a site without the hassle\nof having to sign up and go through hoops for getting access to the information\nyou need.\n\n\nRequirements\n------------\n\n**arackpy** currently supports Python 2.7 and 3.6+ out of the box. Depending on\nthe data you want to extract, future releases will require one or more of the\ndependencies below to be installed to support the various backends:\n\n* BeautifulSoup\n* Selenium\n* requests\n* stem\n* fake_useragent\n\n\nInstallation\n------------\n\nFor the vanilla **arackpy** install do a simple pip install:\n\n    pip install arackpy\n\nThe following packages may also be installed:\n\n    pip install bs4, selenium, requests, stem, fake_useragent\n\n\nQuickstart\n----------\n\nOpen up your favorite python text editor and type the following:\n\n    # hello_spider.py\n\n    from __future__ import division     # for python 2.7\n\n    from arackpy.spider import Spider\n\n\n    class HelloSpider(Spider):\n        \"\"\"A simple spider in just five lines of working code\"\"\"\n\n        start_urls = [\"https://www.python.org\"]\n\n        def parse(self, url, html):\n            \"\"\"Extract data from the raw html\"\"\"\n            print(\"Crawling url, %s\" % url)\n\n\n    if __name__ == \"__main__\":\n        print(\"Press Ctrl-c to stop crawling\")\n        spider = HelloSpider()\n        spider.crawl()\n\nRun the program using:\n\n    python hello_spider.py\n\nNote\n\nPress Ctrl-c to terminate crawling.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://www.bitbucket.com/denisgomes/arackpy", "keywords": "web crawler scraper", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "arackpy", "package_url": "https://pypi.org/project/arackpy/", "platform": "", "project_url": "https://pypi.org/project/arackpy/", "project_urls": {"Homepage": "https://www.bitbucket.com/denisgomes/arackpy"}, "release_url": "https://pypi.org/project/arackpy/0.1.0a1/", "requires_dist": null, "requires_python": "", "summary": "A multithreaded webcrawler and scraper", "version": "0.1.0a1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><strong>arackpy</strong> is a web spider used to crawl and scrape web pages. It can be\nhelpful in the event you quickly need some data from a site without the hassle\nof having to sign up and go through hoops for getting access to the information\nyou need.</p>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<p><strong>arackpy</strong> currently supports Python 2.7 and 3.6+ out of the box. Depending on\nthe data you want to extract, future releases will require one or more of the\ndependencies below to be installed to support the various backends:</p>\n<ul>\n<li>BeautifulSoup</li>\n<li>Selenium</li>\n<li>requests</li>\n<li>stem</li>\n<li>fake_useragent</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>For the vanilla <strong>arackpy</strong> install do a simple pip install:</p>\n<blockquote>\npip install arackpy</blockquote>\n<p>The following packages may also be installed:</p>\n<blockquote>\npip install bs4, selenium, requests, stem, fake_useragent</blockquote>\n</div>\n<div id=\"quickstart\">\n<h2>Quickstart</h2>\n<p>Open up your favorite python text editor and type the following:</p>\n<blockquote>\n<p># hello_spider.py</p>\n<p>from __future__ import division     # for python 2.7</p>\n<p>from arackpy.spider import Spider</p>\n<dl>\n<dt>class HelloSpider(Spider):</dt>\n<dd><p>\u201c\u201d\u201dA simple spider in just five lines of working code\u201d\u201d\u201d</p>\n<p>start_urls = [\u201c<a href=\"https://www.python.org\" rel=\"nofollow\">https://www.python.org</a>\u201d]</p>\n<dl>\n<dt>def parse(self, url, html):</dt>\n<dd>\u201c\u201d\u201dExtract data from the raw html\u201d\u201d\u201d\nprint(\u201cCrawling url, %s\u201d % url)</dd>\n</dl>\n</dd>\n<dt>if __name__ == \u201c__main__\u201d:</dt>\n<dd>print(\u201cPress Ctrl-c to stop crawling\u201d)\nspider = HelloSpider()\nspider.crawl()</dd>\n</dl>\n</blockquote>\n<p>Run the program using:</p>\n<blockquote>\npython hello_spider.py</blockquote>\n<p>Note</p>\n<p>Press Ctrl-c to terminate crawling.</p>\n</div>\n\n          </div>"}, "last_serial": 5538008, "releases": {"0.1.0a1": [{"comment_text": "", "digests": {"md5": "d1ef5e5da30656881f239862ea2dac42", "sha256": "89fa26d64f64859a04214f6e761adc1864349851bdbf31dcbe5d481d204b0861"}, "downloads": -1, "filename": "arackpy-0.1.0a1-py2-none-any.whl", "has_sig": false, "md5_digest": "d1ef5e5da30656881f239862ea2dac42", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16142, "upload_time": "2019-07-16T02:42:22", "upload_time_iso_8601": "2019-07-16T02:42:22.765793Z", "url": "https://files.pythonhosted.org/packages/c0/ed/5de9e81104a250f71955df5b7c1557d8b76ee58355c747f6c9b45466e83d/arackpy-0.1.0a1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5e3398ecdb50d2e4ecc7a6b272c3a5e8", "sha256": "b400954dbcc21d5d0517fdd87ca58a555fefecd76057c2b5008e708543430274"}, "downloads": -1, "filename": "arackpy-0.1.0a1.tar.gz", "has_sig": false, "md5_digest": "5e3398ecdb50d2e4ecc7a6b272c3a5e8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10573, "upload_time": "2019-07-16T02:42:26", "upload_time_iso_8601": "2019-07-16T02:42:26.737735Z", "url": "https://files.pythonhosted.org/packages/f6/90/34d1dae35c432d4d9c0232ae9d596a4f5f19bd4e13e707e85dc9b5b42a7d/arackpy-0.1.0a1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d1ef5e5da30656881f239862ea2dac42", "sha256": "89fa26d64f64859a04214f6e761adc1864349851bdbf31dcbe5d481d204b0861"}, "downloads": -1, "filename": "arackpy-0.1.0a1-py2-none-any.whl", "has_sig": false, "md5_digest": "d1ef5e5da30656881f239862ea2dac42", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16142, "upload_time": "2019-07-16T02:42:22", "upload_time_iso_8601": "2019-07-16T02:42:22.765793Z", "url": "https://files.pythonhosted.org/packages/c0/ed/5de9e81104a250f71955df5b7c1557d8b76ee58355c747f6c9b45466e83d/arackpy-0.1.0a1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5e3398ecdb50d2e4ecc7a6b272c3a5e8", "sha256": "b400954dbcc21d5d0517fdd87ca58a555fefecd76057c2b5008e708543430274"}, "downloads": -1, "filename": "arackpy-0.1.0a1.tar.gz", "has_sig": false, "md5_digest": "5e3398ecdb50d2e4ecc7a6b272c3a5e8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10573, "upload_time": "2019-07-16T02:42:26", "upload_time_iso_8601": "2019-07-16T02:42:26.737735Z", "url": "https://files.pythonhosted.org/packages/f6/90/34d1dae35c432d4d9c0232ae9d596a4f5f19bd4e13e707e85dc9b5b42a7d/arackpy-0.1.0a1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:17:27 2020"}