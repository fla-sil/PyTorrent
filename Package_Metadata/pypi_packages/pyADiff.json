{"info": {"author": "Tamme Claus", "author_email": "tamme.claus@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# pyADiff: A simple, pure python algorithmic differentiation package\n\n[![Documentation Status](https://readthedocs.org/projects/pyadiff/badge/?version=latest)](https://pyadiff.readthedocs.io/en/latest/?badge=latest)\n\n\n`pyADiff` is a (yet) very basic algorithmic differentiation package, which implements forward and adjoint/reverse mode differentiation. If you are looking for a fully-featured and faster library, have a look at [google/jax](https://github.com/google/jax), [autograd](https://github.com/HIPS/autograd) or [dco/c++](https://www.stce.rwth-aachen.de/research/software/dco/cpp) (or many more),  but if you are interested in a package where you are able to quickly \"look under the hood\", you may be right here.\n\n## Motivation\nMy motivation to start this project arose from curiosity while listening to the lecture [\"Computational Differentiation\"](https://www.stce.rwth-aachen.de/teaching/lectures/computational-differentiation) by Prof. Naumann at [RWTH Aachen University](https://www.rwth-aachen.de/). So basically I tried to understand the concepts from the lecture by implementing them by myself. In the end I was (positively) surprised with the outcome and decided to bundle it in a python package. Additionaly this gave me the chance to learn about python packaging, distributing, documentation, ...\n\n## Basic Usage\nSuppose we want to compute the gradient of the function\n\n> f(x\u2080, x\u2081) = 2 x\u2080 x\u2081\u00b2.\n\nThis is a rather trivial task, because by simple calculus, the gradient is:\n\n> \u2207f(x\u2080, x\u2081) = (2 x\u2081\u00b2, 4 x\u2080 x\u2081)\n\nNevertheless we use this example illustrate the use of `pyADiff`.\n```python\nimport pyADiff as ad\n# define the function f\ndef f(x):\n    return 2.*x[0]*x[1]**2.\n# call the gradient function of pyADiff\ndf = ad.gradient(f)\n\nx = [0.5, 2.0]\n# Call the function f and the gradient function df\ny = f(x)\ndy = df(x)\n\nprint(\"f({}) = {}\".format(x, y))  # prints f([0.5, 2.0]) = 4.0\nprint(\"f'({}) = {}\".format(x, dy))  # prints f'([0.5, 2.0]) = [8. 4.]\n```\nWhich corresponds to the evaluation of the analytic gradient.\n\n> \u2207f(0.5, 2) = (2\\*2\u00b2, 4\\*0.5\\*2) = (8, 4)\n\nFor more sophisticated examples see the [Documentation](#documentation) or have a look at the [.ipynb notebooks](/docs/source/documentation/examples)\n\n## Installation\n### Installation using pip\n*TODO*\n\n### Installation from source\nThis will clone the repository and install the `pyADiff` package using the `setup.py` script.\n```shell\n> git clone https://github.com/tam724/pyADiff\n> python pyADiff/setup.py install\n```\n\n## Documentation\nAvailiable on [readthedocs.org](https://pyadiff.readthedocs.io)\n\n## References\n### Algorithmic Differentiation:\n* Uwe Naumann, *Lecture Computational Differentiation*, RWTH Aachen\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tam724/pyADiff", "keywords": "", "license": "GNU GPLv3", "maintainer": "", "maintainer_email": "", "name": "pyADiff", "package_url": "https://pypi.org/project/pyADiff/", "platform": "", "project_url": "https://pypi.org/project/pyADiff/", "project_urls": {"Homepage": "https://github.com/tam724/pyADiff"}, "release_url": "https://pypi.org/project/pyADiff/0.1.1/", "requires_dist": ["numpy (>=1.17)"], "requires_python": ">=3.6", "summary": "A simple, pure python algorithmic differentiation package", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pyADiff: A simple, pure python algorithmic differentiation package</h1>\n<p><a href=\"https://pyadiff.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b7608996d7240ca0ff4ba887298d717eca2d2b29/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f707961646966662f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p><code>pyADiff</code> is a (yet) very basic algorithmic differentiation package, which implements forward and adjoint/reverse mode differentiation. If you are looking for a fully-featured and faster library, have a look at <a href=\"https://github.com/google/jax\" rel=\"nofollow\">google/jax</a>, <a href=\"https://github.com/HIPS/autograd\" rel=\"nofollow\">autograd</a> or <a href=\"https://www.stce.rwth-aachen.de/research/software/dco/cpp\" rel=\"nofollow\">dco/c++</a> (or many more),  but if you are interested in a package where you are able to quickly \"look under the hood\", you may be right here.</p>\n<h2>Motivation</h2>\n<p>My motivation to start this project arose from curiosity while listening to the lecture <a href=\"https://www.stce.rwth-aachen.de/teaching/lectures/computational-differentiation\" rel=\"nofollow\">\"Computational Differentiation\"</a> by Prof. Naumann at <a href=\"https://www.rwth-aachen.de/\" rel=\"nofollow\">RWTH Aachen University</a>. So basically I tried to understand the concepts from the lecture by implementing them by myself. In the end I was (positively) surprised with the outcome and decided to bundle it in a python package. Additionaly this gave me the chance to learn about python packaging, distributing, documentation, ...</p>\n<h2>Basic Usage</h2>\n<p>Suppose we want to compute the gradient of the function</p>\n<blockquote>\n<p>f(x\u2080, x\u2081) = 2 x\u2080 x\u2081\u00b2.</p>\n</blockquote>\n<p>This is a rather trivial task, because by simple calculus, the gradient is:</p>\n<blockquote>\n<p>\u2207f(x\u2080, x\u2081) = (2 x\u2081\u00b2, 4 x\u2080 x\u2081)</p>\n</blockquote>\n<p>Nevertheless we use this example illustrate the use of <code>pyADiff</code>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pyADiff</span> <span class=\"k\">as</span> <span class=\"nn\">ad</span>\n<span class=\"c1\"># define the function f</span>\n<span class=\"k\">def</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"mf\">2.</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">**</span><span class=\"mf\">2.</span>\n<span class=\"c1\"># call the gradient function of pyADiff</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">ad</span><span class=\"o\">.</span><span class=\"n\">gradient</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">2.0</span><span class=\"p\">]</span>\n<span class=\"c1\"># Call the function f and the gradient function df</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"n\">dy</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"f(</span><span class=\"si\">{}</span><span class=\"s2\">) = </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">))</span>  <span class=\"c1\"># prints f([0.5, 2.0]) = 4.0</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"f'(</span><span class=\"si\">{}</span><span class=\"s2\">) = </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">dy</span><span class=\"p\">))</span>  <span class=\"c1\"># prints f'([0.5, 2.0]) = [8. 4.]</span>\n</pre>\n<p>Which corresponds to the evaluation of the analytic gradient.</p>\n<blockquote>\n<p>\u2207f(0.5, 2) = (2*2\u00b2, 4*0.5*2) = (8, 4)</p>\n</blockquote>\n<p>For more sophisticated examples see the <a href=\"#documentation\" rel=\"nofollow\">Documentation</a> or have a look at the <a href=\"/docs/source/documentation/examples\" rel=\"nofollow\">.ipynb notebooks</a></p>\n<h2>Installation</h2>\n<h3>Installation using pip</h3>\n<p><em>TODO</em></p>\n<h3>Installation from source</h3>\n<p>This will clone the repository and install the <code>pyADiff</code> package using the <code>setup.py</code> script.</p>\n<pre>&gt; git clone https://github.com/tam724/pyADiff\n&gt; python pyADiff/setup.py install\n</pre>\n<h2>Documentation</h2>\n<p>Availiable on <a href=\"https://pyadiff.readthedocs.io\" rel=\"nofollow\">readthedocs.org</a></p>\n<h2>References</h2>\n<h3>Algorithmic Differentiation:</h3>\n<ul>\n<li>Uwe Naumann, <em>Lecture Computational Differentiation</em>, RWTH Aachen</li>\n</ul>\n\n          </div>"}, "last_serial": 6151896, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "28d936f1dc2d1ba73323564d3fbd6081", "sha256": "c3e4410ac39d730d90456d558fc1bbf0ae5f8937252e454e1f7cbea5f5305e29"}, "downloads": -1, "filename": "pyADiff-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "28d936f1dc2d1ba73323564d3fbd6081", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21689, "upload_time": "2019-11-17T21:40:15", "upload_time_iso_8601": "2019-11-17T21:40:15.654618Z", "url": "https://files.pythonhosted.org/packages/95/23/54253770a38463b36fd4f03730cbbf6c85d3a6e186c73aa349286ddba6d2/pyADiff-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "49e73ae156113c21c1be1ebbb4bf826f", "sha256": "dc79b6fc0377c1d83f011597414ea458cddf31fdf3c630f34d1370c568ecf2ac"}, "downloads": -1, "filename": "pyADiff-0.1.1.tar.gz", "has_sig": false, "md5_digest": "49e73ae156113c21c1be1ebbb4bf826f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20516, "upload_time": "2019-11-17T21:40:18", "upload_time_iso_8601": "2019-11-17T21:40:18.136268Z", "url": "https://files.pythonhosted.org/packages/5b/cf/4eb683213297a5f9898f51545164ca903890f653d9da8453851533b91a34/pyADiff-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "28d936f1dc2d1ba73323564d3fbd6081", "sha256": "c3e4410ac39d730d90456d558fc1bbf0ae5f8937252e454e1f7cbea5f5305e29"}, "downloads": -1, "filename": "pyADiff-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "28d936f1dc2d1ba73323564d3fbd6081", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21689, "upload_time": "2019-11-17T21:40:15", "upload_time_iso_8601": "2019-11-17T21:40:15.654618Z", "url": "https://files.pythonhosted.org/packages/95/23/54253770a38463b36fd4f03730cbbf6c85d3a6e186c73aa349286ddba6d2/pyADiff-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "49e73ae156113c21c1be1ebbb4bf826f", "sha256": "dc79b6fc0377c1d83f011597414ea458cddf31fdf3c630f34d1370c568ecf2ac"}, "downloads": -1, "filename": "pyADiff-0.1.1.tar.gz", "has_sig": false, "md5_digest": "49e73ae156113c21c1be1ebbb4bf826f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20516, "upload_time": "2019-11-17T21:40:18", "upload_time_iso_8601": "2019-11-17T21:40:18.136268Z", "url": "https://files.pythonhosted.org/packages/5b/cf/4eb683213297a5f9898f51545164ca903890f653d9da8453851533b91a34/pyADiff-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:11:59 2020"}