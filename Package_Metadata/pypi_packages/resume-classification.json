{"info": {"author": "Shreyas Nanaware/Krushna Kumar Nalange", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "# Resume Classification\n\n## Objective\n\nAim of this project is to train a set of resumes of specific domain and create a machine learning model \nto predict the unseen resumes.\n\nCurrently the model is trained using logistic regression on these four domain:\n  - Java\n  - Cloud\n  - Big Data\n  - Machine Learning\n\nResumes are read using a package called **tika** which supports many file formats including the following popular ones:\n\n    - doc\n    - docx\n    - pdf\n\nNOTE: To know more about tika visit the following link: https://pypi.org/project/tika/\n\n## Installation\n\n`pip install resume_classification`\n\n## Dependencies\n\n- numpy==1.17.3\n- pandas==0.25.1\n- tika==1.24\n- nltk==3.4.5\n\n### Python version\n    `Python 3.7.4`\n\n## Project Guidelines\n\n- Train\n\n  In order to train a new set of resumes, the project ought to have a defined folder structure given below:\n\n    <img src=\"pic/Folder_Structure.png\" width=\"600\" height=\"300\">  \n\n  Then run the following commands:\n\n  `from resume_classification import train`\n\n  `train(path-to-resumes-folder)`\n\n  ### Output\n\n  The output will consist of the following metrics\n    - Model Accuracy\n    - F1 Score\n    - Confusion Matrix\n\n - Predict\n\n   Use the following command:\n\n   `from resume_classification import predict`\n\n   `predict(path-to-resumes)`\n\n   **NOTE** for predict module, the path to resume will contain all the unseen resumes in a single folder.\n\n    ### Output\n\n    The output will be a dataframe consisting of `file name` and `predicted domain`.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/shreyas2306/ResumeParser", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "resume-classification", "package_url": "https://pypi.org/project/resume-classification/", "platform": "", "project_url": "https://pypi.org/project/resume-classification/", "project_urls": {"Homepage": "https://github.com/shreyas2306/ResumeParser"}, "release_url": "https://pypi.org/project/resume-classification/1.0/", "requires_dist": ["numpy (==1.17.3)", "pandas (==0.25.1)", "tika (==1.24)", "nltk (==3.4.5)", "setuptools (==41.4.0)", "Wheel (==0.33.6)"], "requires_python": "", "summary": "It a simple package for training and classification of resumes.", "version": "1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Resume Classification</h1>\n<h2>Objective</h2>\n<p>Aim of this project is to train a set of resumes of specific domain and create a machine learning model\nto predict the unseen resumes.</p>\n<p>Currently the model is trained using logistic regression on these four domain:</p>\n<ul>\n<li>Java</li>\n<li>Cloud</li>\n<li>Big Data</li>\n<li>Machine Learning</li>\n</ul>\n<p>Resumes are read using a package called <strong>tika</strong> which supports many file formats including the following popular ones:</p>\n<pre><code>- doc\n- docx\n- pdf\n</code></pre>\n<p>NOTE: To know more about tika visit the following link: <a href=\"https://pypi.org/project/tika/\" rel=\"nofollow\">https://pypi.org/project/tika/</a></p>\n<h2>Installation</h2>\n<p><code>pip install resume_classification</code></p>\n<h2>Dependencies</h2>\n<ul>\n<li>numpy==1.17.3</li>\n<li>pandas==0.25.1</li>\n<li>tika==1.24</li>\n<li>nltk==3.4.5</li>\n</ul>\n<h3>Python version</h3>\n<pre><code>`Python 3.7.4`\n</code></pre>\n<h2>Project Guidelines</h2>\n<ul>\n<li>\n<p>Train</p>\n<p>In order to train a new set of resumes, the project ought to have a defined folder structure given below:</p>\n  <img height=\"300\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a0b39ca6fd9fadac56608849a748d9cd71b37261/7069632f466f6c6465725f5374727563747572652e706e67\" width=\"600\">  \n<p>Then run the following commands:</p>\n<p><code>from resume_classification import train</code></p>\n<p><code>train(path-to-resumes-folder)</code></p>\n<h3>Output</h3>\n<p>The output will consist of the following metrics</p>\n<ul>\n<li>Model Accuracy</li>\n<li>F1 Score</li>\n<li>Confusion Matrix</li>\n</ul>\n</li>\n<li>\n<p>Predict</p>\n<p>Use the following command:</p>\n<p><code>from resume_classification import predict</code></p>\n<p><code>predict(path-to-resumes)</code></p>\n<p><strong>NOTE</strong> for predict module, the path to resume will contain all the unseen resumes in a single folder.</p>\n<h3>Output</h3>\n<p>The output will be a dataframe consisting of <code>file name</code> and <code>predicted domain</code>.</p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 7009668, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "17ae440821739ff820bebfb297a2680a", "sha256": "2dee7ac558839f016f68726cbc24ca29df426ae6611587b933092ac32c605973"}, "downloads": -1, "filename": "resume_classification-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "17ae440821739ff820bebfb297a2680a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 992061, "upload_time": "2020-04-13T12:37:51", "upload_time_iso_8601": "2020-04-13T12:37:51.975631Z", "url": "https://files.pythonhosted.org/packages/13/68/3341f411a8d26eb3a08b81232f4ac7e6f4e34d65cfb7f884fd28ce47033d/resume_classification-1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9f4dd96ae2dba3c2ab6d066f4ae784ba", "sha256": "5fa22e33dad4648a4ef43fd6e03fca5c9a9cbe573cc0628799825e187369fa79"}, "downloads": -1, "filename": "resume_classification-1.0.tar.gz", "has_sig": false, "md5_digest": "9f4dd96ae2dba3c2ab6d066f4ae784ba", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17790, "upload_time": "2020-04-13T12:37:54", "upload_time_iso_8601": "2020-04-13T12:37:54.221909Z", "url": "https://files.pythonhosted.org/packages/c0/9d/589bcca9eabbe0424d30e6297c799cf79b2da8fce2bddd79939f7634d905/resume_classification-1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "17ae440821739ff820bebfb297a2680a", "sha256": "2dee7ac558839f016f68726cbc24ca29df426ae6611587b933092ac32c605973"}, "downloads": -1, "filename": "resume_classification-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "17ae440821739ff820bebfb297a2680a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 992061, "upload_time": "2020-04-13T12:37:51", "upload_time_iso_8601": "2020-04-13T12:37:51.975631Z", "url": "https://files.pythonhosted.org/packages/13/68/3341f411a8d26eb3a08b81232f4ac7e6f4e34d65cfb7f884fd28ce47033d/resume_classification-1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9f4dd96ae2dba3c2ab6d066f4ae784ba", "sha256": "5fa22e33dad4648a4ef43fd6e03fca5c9a9cbe573cc0628799825e187369fa79"}, "downloads": -1, "filename": "resume_classification-1.0.tar.gz", "has_sig": false, "md5_digest": "9f4dd96ae2dba3c2ab6d066f4ae784ba", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17790, "upload_time": "2020-04-13T12:37:54", "upload_time_iso_8601": "2020-04-13T12:37:54.221909Z", "url": "https://files.pythonhosted.org/packages/c0/9d/589bcca9eabbe0424d30e6297c799cf79b2da8fce2bddd79939f7634d905/resume_classification-1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:03:28 2020"}