{"info": {"author": "Locus Energy", "author_email": "dbio@locusenergy.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Topic :: Database"], "description": "DB I/O\n======\n\nA simple Python module for the following database operations: importing\nfrom CSV, querying to CSV, or querying to a table in a database. All\ndatabase-specific knowledge is abstracted.\n\nInstallation\n------------\n\nUse pip or setup utils:\n\n::\n\n  pip install dbio\n\nAdditionally, you will need the Python DB API modules for the\ndatabase(s) that you wish to use. Any databases that are currently\nsupported have the modules listed in the *extras\\_require* dictionary in\n``setup.py``. For example, if you wish to install the modules needed for\nusing MySQL and Vertica, you can augment the above command:\n\n::\n\n    pip install dbio[MySQL, Vertica]\n\nNote that some Python DB API modules may have OS-dependent pre-requisite\npackages to install. Consult the module's installation guide if setup\nfails.\n\nUsage\n-----\n\nTo run an operation from the command line:\n\n::\n\n    dbio dbio_args op_name op_args\n\nFor general help, use ``dbio -h``. For operation specific help and a\nlist of args, use ``dbio op_name -h``. All commands have CSV formatting\noptions that can be specified via the command-line. For the full list,\nview ``dbio -h``.\n\nTo call an operation within Python:\n\n.. code:: python\n\n    import dbio   \n    dbio.op_name(op_args, op_kwargs)\n\nAll operations require an `SQLAlchemy\nURL <http://docs.sqlalchemy.org/en/rel_1_0/core/engines.html#database-urls>`__\nfor each database used in the operation.\n\nFor more detailed information on calling scripts within Python, `check out the documentation <http://pythonhosted.org/dbio/>`__.\n\nLogging is supported via the Python ``logging`` module.\n\nTests can be run with\n\n::\n\n    python setup.py test -a 'py.test args'\n\nOperations\n----------\n\nReplicate\n~~~~~~~~~\n\n::\n\n    dbio replicate query_db_url load_db_url query table\n\nRuns ``query`` against the database pointed to by ``query_db_url``,\nloading the results into ``table`` in the database pointed to by\n``load_db_url``. The rows in the loading database that existed before\nreplication are removed.\n\nOptional flags:\n\n-  ``-f``: indicates that ``query`` is the name of a file.\n-  ``-a``: runs in append mode. Rows that were in the loading database\n   before replication are preserved.\n-  ``-z``: analyzes ``table`` for query optimization after completing the load.\n-  ``-i``: drops or disable indices while loading, recreating them afterwards.\n-  ``-nf``: does not use ``mkfifo()``. Use this if ``mkfifo()`` is not available.\n-  ``-s``: expects an table named 'table_staging' to already exist.\n-  ``-rc``: performs a check to ensure that the query rowcount matches the load table rowcount.\n-  ``-dt``: Adds direct keyword to Vertica copy commands used in loading data.\n   supported by your OS (e.g. Windows).\n\nHow it Works\n^^^^^^^^^^^^\n\n**Replicate** creates a Unix\n`first-in-first-out <http://linux.die.net/man/3/mkfifo>`__ object\n(a.k.a. a \"named pipe\"). Using the ``subprocess`` module, **Load** and\n**Query** are then simultaneously executed, with the loading operation\nacting as the pipe reader, and the query object acting as the pipe\nwriter. This allows query results to be streamed directly into the\ndatabase's preferred method of import.\n\nFor a detailed explanation, see `this blog post <http://blog.locusenergy.com/2015/08/04/moving-bulk-data/>`__.\n\nLoad\n~~~~\n\n::\n\n    dbio load db_url table filename\n\nLoads the contents of a csv file at ``filename`` into ``table`` in the\ndatabase pointed to by ``load_db_url``. The rows in the loading database\nthat existed before replication are removed.\n\nOptional flags:\n\n-  ``-a``: runs in append mode. Rows that were in the loading database\n   before replication are preserved.\n-  ``-z``: analyzes ``table`` after completing the load.\n-  ``-i``: drops or disable indices while loading, recreating them afterwards.\n-  ``-s``: expects a table named 'table_staging' to already exist.\n-  ``-rc``: the number of rows to ensure are present in the table after loading.\n-  ``-dt``: Adds direct keyword to Vertica copy commands used in loading data.\n- csv flags:\n    * ``-qc``: character to enclose fields. If not included, fields are not enclosed.\n    * ``-ns``: string to replace NULL fields. Defaults to \"NULL\".\n    * ``-d``: field separation character. Defaults to \",\".\n    * ``-esc``: escape character. Defaults to \"\\\".\n    * ``-l``: record terminator. Defaults to \"\\n\".\n    * ``-e``: character encoding. Defaults to \"utf-8\"\n\nQuery\n~~~~~\n\n::\n\n    dbio query db_url query filename\n\nRuns ``query`` against the database pointed to by ``query_db_url``,\nplacing the results into a CSV file at ``filename``.\n\nOptional flags:\n\n-  ``-f``: indicates that ``query`` is the name of a file.\n-  ``-b``: specify ``batch_size``, which determines the number of rows. to store in memory before writing to the file. Defaults to 1,000,000.\n- csv flags:\n    * ``-qc``: character to enclose fields. If not included, fields are not enclosed.\n    * ``-ns``: string to replace NULL fields. Defaults to \"NULL\".\n    * ``-d``: field separation character. Defaults to \",\".\n    * ``-esc``: escape character. Defaults to \"\\\".\n    * ``-l``: record terminator. Defaults to \"\\n\".\n    * ``-e``: character encoding. Defaults to \"utf-8\"\n\n\nDatabases\n---------\n\nMySQL\n~~~~~\n\nInclude 'MySQL' in the list of extras when installing.\n\nRequires `MySQL-python <https://pypi.python.org/pypi/MySQL-python>`__.\n\nPostgreSQL\n~~~~~~~~~~\n\nInclude 'PostgreSQL' in the list of extras when installing.\n\nRequires `psycopg2 <https://pypi.python.org/pypi/psycopg2>`__.\n\nSQLite\n~~~~~~\n\nIncluded in the Python standard library. Note that the SQLite python\nlibrary has no method designed for bulk-loading from CSV, so batch\ninsert statements are used, which may cause bottlenecks that are not\npresent for other databases.\n\nVertica:\n~~~~~~~~\n\nInclude 'Vertica' in the list of extras when installing.\n\nRequires `vertica-python <https://github.com/uber/vertica-python>`__ and\n`sqlalchemy-vertica-python <https://github.com/LocusEnergy/sqlalchemy-vertica-python>`__\n\nAlternatively, there is support for using pyodbc to drive the\nconnection.\n\nAdditional Databases\n~~~~~~~~~~~~~~~~~~~~\n\nTo add support for a new database:\n\n1. Create a class inside the ``dbio.databases`` subpackage that extends\n   ``dbio.databases.base.Exportable`` and/or\n   ``dbio.databases.base.Importable`` depending on desired\n   functionality. The DB must have a valid SQLAlchemy Dialect. Existing\n   supported databases are listed\n   `here <http://docs.sqlalchemy.org/en/rel_1_0/core/engines.html#supported-databases>`__,\n   but SQLAlchemy also supports `registering new\n   dialects <http://sqlalchemy.readthedocs.org/en/latest/core/connections.html#registering-new-dialects>`__.\n2. Add a corresponding import and mapping dictionary entry into ``databases.__init__.py``\n\nExamples\n--------\n\nQuery a Vertica database and stream the results into a MySQL table with a schema matching the results:\n\n::\n\n    dbio replicate \"vertica+vertica_python://user:pwd@host:port/database\" \"mysql://user:pwd@host:port/database\" \"SELECT * FROM vertica_table\" mysql_table\n\nLoad foo.csv with \"|\" field delimiters into a PostgreSQL table:\n\n::\n\n    dbio load \"postgresql://user:pwd@host:port/database\" foo_table foo.csv -d \"|\"\n\n\nQuery a SQLite table using a query file and write the results to a CSV with NULL represented by \"NULL\" and lines terminated with \"\\\\n\".\n\n::\n\n    dbio query \"sqlite:///path/to/sqlite/db/file.db\" foo_query.sql foo.csv -f -ns NULL -l \"\\n\"\n\nChangelog\n---------\n- 0.5.0: Adding in ability to add Vertica DIRECT hint when loading data into Vertica\n- 0.4.9: Deleting staging table prior to creating it to ensure that function does not fail for that reason.\n- 0.4.8: Pinning requirement and \"extras\" requirements to specific versions where applicable \n- 0.4.7: When a new staging table is created with the postgres db, grants are copied over as well\n- 0.4.6: Making version number read from all dbio/__init__.py so it doesn't need to copied and pasted everywhere.\n- 0.4.5: Explicit SQLAlchemy transaction creation.\n- 0.4.4: Added SQL logic to Vertica and MySQL to raise errors when loading has any issues, including truncated data.\n- 0.4.3: Minor logging additions.\n- 0.4.2: Added a rowcount check option and randomized pipe names.\n- 0.4.1: Support for existing staging tables.\n- 0.4.0: Support for temporary index disabling.\n- 0.3.4: Link to documentation in README.rst.\n- 0.3.3: Added public documentation and minor fixes.\n- 0.3.2: Fixed minor vertica.py bugs.\n- 0.3.1: Fixed critical CLI bug.\n- 0.3.0: Handle replication CSV formatting automatically.\n- 0.2.0: Add ANALYZE support.\n- 0.1.1: Initial public release.\n", "description_content_type": "", "docs_url": "https://pythonhosted.org/dbio/", "download_url": "https://github.com/LocusEnergy/dbio/tarball/0.4.4", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/locusenergy/dbio", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dbio", "package_url": "https://pypi.org/project/dbio/", "platform": "", "project_url": "https://pypi.org/project/dbio/", "project_urls": {"Download": "https://github.com/LocusEnergy/dbio/tarball/0.4.4", "Homepage": "https://github.com/locusenergy/dbio"}, "release_url": "https://pypi.org/project/dbio/0.5.3/", "requires_dist": null, "requires_python": "", "summary": "Simple module for database I/O operations.", "version": "0.5.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A simple Python module for the following database operations: importing\nfrom CSV, querying to CSV, or querying to a table in a database. All\ndatabase-specific knowledge is abstracted.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Use pip or setup utils:</p>\n<pre>pip install dbio\n</pre>\n<p>Additionally, you will need the Python DB API modules for the\ndatabase(s) that you wish to use. Any databases that are currently\nsupported have the modules listed in the <em>extras_require</em> dictionary in\n<tt>setup.py</tt>. For example, if you wish to install the modules needed for\nusing MySQL and Vertica, you can augment the above command:</p>\n<pre>pip install dbio[MySQL, Vertica]\n</pre>\n<p>Note that some Python DB API modules may have OS-dependent pre-requisite\npackages to install. Consult the module\u2019s installation guide if setup\nfails.</p>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>To run an operation from the command line:</p>\n<pre>dbio dbio_args op_name op_args\n</pre>\n<p>For general help, use <tt>dbio <span class=\"pre\">-h</span></tt>. For operation specific help and a\nlist of args, use <tt>dbio op_name <span class=\"pre\">-h</span></tt>. All commands have CSV formatting\noptions that can be specified via the command-line. For the full list,\nview <tt>dbio <span class=\"pre\">-h</span></tt>.</p>\n<p>To call an operation within Python:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">dbio</span>\n<span class=\"n\">dbio</span><span class=\"o\">.</span><span class=\"n\">op_name</span><span class=\"p\">(</span><span class=\"n\">op_args</span><span class=\"p\">,</span> <span class=\"n\">op_kwargs</span><span class=\"p\">)</span>\n</pre>\n<p>All operations require an <a href=\"http://docs.sqlalchemy.org/en/rel_1_0/core/engines.html#database-urls\" rel=\"nofollow\">SQLAlchemy\nURL</a>\nfor each database used in the operation.</p>\n<p>For more detailed information on calling scripts within Python, <a href=\"http://pythonhosted.org/dbio/\" rel=\"nofollow\">check out the documentation</a>.</p>\n<p>Logging is supported via the Python <tt>logging</tt> module.</p>\n<p>Tests can be run with</p>\n<pre>python setup.py test -a 'py.test args'\n</pre>\n</div>\n<div id=\"operations\">\n<h2>Operations</h2>\n<div id=\"replicate\">\n<h3>Replicate</h3>\n<pre>dbio replicate query_db_url load_db_url query table\n</pre>\n<p>Runs <tt>query</tt> against the database pointed to by <tt>query_db_url</tt>,\nloading the results into <tt>table</tt> in the database pointed to by\n<tt>load_db_url</tt>. The rows in the loading database that existed before\nreplication are removed.</p>\n<p>Optional flags:</p>\n<ul>\n<li><tt><span class=\"pre\">-f</span></tt>: indicates that <tt>query</tt> is the name of a file.</li>\n<li><tt><span class=\"pre\">-a</span></tt>: runs in append mode. Rows that were in the loading database\nbefore replication are preserved.</li>\n<li><tt><span class=\"pre\">-z</span></tt>: analyzes <tt>table</tt> for query optimization after completing the load.</li>\n<li><tt><span class=\"pre\">-i</span></tt>: drops or disable indices while loading, recreating them afterwards.</li>\n<li><tt><span class=\"pre\">-nf</span></tt>: does not use <tt>mkfifo()</tt>. Use this if <tt>mkfifo()</tt> is not available.</li>\n<li><tt><span class=\"pre\">-s</span></tt>: expects an table named \u2018table_staging\u2019 to already exist.</li>\n<li><tt><span class=\"pre\">-rc</span></tt>: performs a check to ensure that the query rowcount matches the load table rowcount.</li>\n<li><tt><span class=\"pre\">-dt</span></tt>: Adds direct keyword to Vertica copy commands used in loading data.\nsupported by your OS (e.g. Windows).</li>\n</ul>\n<div id=\"how-it-works\">\n<h4>How it Works</h4>\n<p><strong>Replicate</strong> creates a Unix\n<a href=\"http://linux.die.net/man/3/mkfifo\" rel=\"nofollow\">first-in-first-out</a> object\n(a.k.a. a \u201cnamed pipe\u201d). Using the <tt>subprocess</tt> module, <strong>Load</strong> and\n<strong>Query</strong> are then simultaneously executed, with the loading operation\nacting as the pipe reader, and the query object acting as the pipe\nwriter. This allows query results to be streamed directly into the\ndatabase\u2019s preferred method of import.</p>\n<p>For a detailed explanation, see <a href=\"http://blog.locusenergy.com/2015/08/04/moving-bulk-data/\" rel=\"nofollow\">this blog post</a>.</p>\n</div>\n</div>\n<div id=\"load\">\n<h3>Load</h3>\n<pre>dbio load db_url table filename\n</pre>\n<p>Loads the contents of a csv file at <tt>filename</tt> into <tt>table</tt> in the\ndatabase pointed to by <tt>load_db_url</tt>. The rows in the loading database\nthat existed before replication are removed.</p>\n<p>Optional flags:</p>\n<ul>\n<li><tt><span class=\"pre\">-a</span></tt>: runs in append mode. Rows that were in the loading database\nbefore replication are preserved.</li>\n<li><tt><span class=\"pre\">-z</span></tt>: analyzes <tt>table</tt> after completing the load.</li>\n<li><tt><span class=\"pre\">-i</span></tt>: drops or disable indices while loading, recreating them afterwards.</li>\n<li><tt><span class=\"pre\">-s</span></tt>: expects a table named \u2018table_staging\u2019 to already exist.</li>\n<li><tt><span class=\"pre\">-rc</span></tt>: the number of rows to ensure are present in the table after loading.</li>\n<li><tt><span class=\"pre\">-dt</span></tt>: Adds direct keyword to Vertica copy commands used in loading data.</li>\n<li><dl>\n<dt>csv flags:</dt>\n<dd><ul>\n<li><tt><span class=\"pre\">-qc</span></tt>: character to enclose fields. If not included, fields are not enclosed.</li>\n<li><tt><span class=\"pre\">-ns</span></tt>: string to replace NULL fields. Defaults to \u201cNULL\u201d.</li>\n<li><tt><span class=\"pre\">-d</span></tt>: field separation character. Defaults to \u201c,\u201d.</li>\n<li><tt><span class=\"pre\">-esc</span></tt>: escape character. Defaults to \u201c\u201d.</li>\n<li><tt><span class=\"pre\">-l</span></tt>: record terminator. Defaults to \u201cn\u201d.</li>\n<li><tt><span class=\"pre\">-e</span></tt>: character encoding. Defaults to \u201cutf-8\u201d</li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n</div>\n<div id=\"query\">\n<h3>Query</h3>\n<pre>dbio query db_url query filename\n</pre>\n<p>Runs <tt>query</tt> against the database pointed to by <tt>query_db_url</tt>,\nplacing the results into a CSV file at <tt>filename</tt>.</p>\n<p>Optional flags:</p>\n<ul>\n<li><tt><span class=\"pre\">-f</span></tt>: indicates that <tt>query</tt> is the name of a file.</li>\n<li><tt><span class=\"pre\">-b</span></tt>: specify <tt>batch_size</tt>, which determines the number of rows. to store in memory before writing to the file. Defaults to 1,000,000.</li>\n<li><dl>\n<dt>csv flags:</dt>\n<dd><ul>\n<li><tt><span class=\"pre\">-qc</span></tt>: character to enclose fields. If not included, fields are not enclosed.</li>\n<li><tt><span class=\"pre\">-ns</span></tt>: string to replace NULL fields. Defaults to \u201cNULL\u201d.</li>\n<li><tt><span class=\"pre\">-d</span></tt>: field separation character. Defaults to \u201c,\u201d.</li>\n<li><tt><span class=\"pre\">-esc</span></tt>: escape character. Defaults to \u201c\u201d.</li>\n<li><tt><span class=\"pre\">-l</span></tt>: record terminator. Defaults to \u201cn\u201d.</li>\n<li><tt><span class=\"pre\">-e</span></tt>: character encoding. Defaults to \u201cutf-8\u201d</li>\n</ul>\n</dd>\n</dl>\n</li>\n</ul>\n</div>\n</div>\n<div id=\"databases\">\n<h2>Databases</h2>\n<div id=\"mysql\">\n<h3>MySQL</h3>\n<p>Include \u2018MySQL\u2019 in the list of extras when installing.</p>\n<p>Requires <a href=\"https://pypi.python.org/pypi/MySQL-python\" rel=\"nofollow\">MySQL-python</a>.</p>\n</div>\n<div id=\"postgresql\">\n<h3>PostgreSQL</h3>\n<p>Include \u2018PostgreSQL\u2019 in the list of extras when installing.</p>\n<p>Requires <a href=\"https://pypi.python.org/pypi/psycopg2\" rel=\"nofollow\">psycopg2</a>.</p>\n</div>\n<div id=\"sqlite\">\n<h3>SQLite</h3>\n<p>Included in the Python standard library. Note that the SQLite python\nlibrary has no method designed for bulk-loading from CSV, so batch\ninsert statements are used, which may cause bottlenecks that are not\npresent for other databases.</p>\n</div>\n<div id=\"vertica\">\n<h3>Vertica:</h3>\n<p>Include \u2018Vertica\u2019 in the list of extras when installing.</p>\n<p>Requires <a href=\"https://github.com/uber/vertica-python\" rel=\"nofollow\">vertica-python</a> and\n<a href=\"https://github.com/LocusEnergy/sqlalchemy-vertica-python\" rel=\"nofollow\">sqlalchemy-vertica-python</a></p>\n<p>Alternatively, there is support for using pyodbc to drive the\nconnection.</p>\n</div>\n<div id=\"additional-databases\">\n<h3>Additional Databases</h3>\n<p>To add support for a new database:</p>\n<ol>\n<li>Create a class inside the <tt>dbio.databases</tt> subpackage that extends\n<tt>dbio.databases.base.Exportable</tt> and/or\n<tt>dbio.databases.base.Importable</tt> depending on desired\nfunctionality. The DB must have a valid SQLAlchemy Dialect. Existing\nsupported databases are listed\n<a href=\"http://docs.sqlalchemy.org/en/rel_1_0/core/engines.html#supported-databases\" rel=\"nofollow\">here</a>,\nbut SQLAlchemy also supports <a href=\"http://sqlalchemy.readthedocs.org/en/latest/core/connections.html#registering-new-dialects\" rel=\"nofollow\">registering new\ndialects</a>.</li>\n<li>Add a corresponding import and mapping dictionary entry into <tt>databases.__init__.py</tt></li>\n</ol>\n</div>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<p>Query a Vertica database and stream the results into a MySQL table with a schema matching the results:</p>\n<pre>dbio replicate \"vertica+vertica_python://user:pwd@host:port/database\" \"mysql://user:pwd@host:port/database\" \"SELECT * FROM vertica_table\" mysql_table\n</pre>\n<p>Load foo.csv with \u201c|\u201d field delimiters into a PostgreSQL table:</p>\n<pre>dbio load \"postgresql://user:pwd@host:port/database\" foo_table foo.csv -d \"|\"\n</pre>\n<p>Query a SQLite table using a query file and write the results to a CSV with NULL represented by \u201cNULL\u201d and lines terminated with \u201c\\n\u201d.</p>\n<pre>dbio query \"sqlite:///path/to/sqlite/db/file.db\" foo_query.sql foo.csv -f -ns NULL -l \"\\n\"\n</pre>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<ul>\n<li>0.5.0: Adding in ability to add Vertica DIRECT hint when loading data into Vertica</li>\n<li>0.4.9: Deleting staging table prior to creating it to ensure that function does not fail for that reason.</li>\n<li>0.4.8: Pinning requirement and \u201cextras\u201d requirements to specific versions where applicable</li>\n<li>0.4.7: When a new staging table is created with the postgres db, grants are copied over as well</li>\n<li>0.4.6: Making version number read from all dbio/__init__.py so it doesn\u2019t need to copied and pasted everywhere.</li>\n<li>0.4.5: Explicit SQLAlchemy transaction creation.</li>\n<li>0.4.4: Added SQL logic to Vertica and MySQL to raise errors when loading has any issues, including truncated data.</li>\n<li>0.4.3: Minor logging additions.</li>\n<li>0.4.2: Added a rowcount check option and randomized pipe names.</li>\n<li>0.4.1: Support for existing staging tables.</li>\n<li>0.4.0: Support for temporary index disabling.</li>\n<li>0.3.4: Link to documentation in README.rst.</li>\n<li>0.3.3: Added public documentation and minor fixes.</li>\n<li>0.3.2: Fixed minor vertica.py bugs.</li>\n<li>0.3.1: Fixed critical CLI bug.</li>\n<li>0.3.0: Handle replication CSV formatting automatically.</li>\n<li>0.2.0: Add ANALYZE support.</li>\n<li>0.1.1: Initial public release.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 3718397, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "f43d257f4a040927d7c5f888bf1c2b48", "sha256": "6ae85118d6b0dfe8654e4bf7533d94816702a441c747e7256fd2b83877cd8b6e"}, "downloads": -1, "filename": "dbio-0.1.1.tar.gz", "has_sig": false, "md5_digest": "f43d257f4a040927d7c5f888bf1c2b48", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10407, "upload_time": "2015-07-31T22:23:12", "upload_time_iso_8601": "2015-07-31T22:23:12.935385Z", "url": "https://files.pythonhosted.org/packages/0d/b0/d06210d49f91a260fdf56394f41afd6f078e5f08e6f904898ead39d9f94e/dbio-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "0bba240028fb899f2775936567b54f5f", "sha256": "6b3ee133bd2a94035e5fe80245342fb49105fe82d51c09938ff6a5f73ac341c4"}, "downloads": -1, "filename": "dbio-0.2.0.tar.gz", "has_sig": false, "md5_digest": "0bba240028fb899f2775936567b54f5f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10805, "upload_time": "2015-08-04T21:26:12", "upload_time_iso_8601": "2015-08-04T21:26:12.643083Z", "url": "https://files.pythonhosted.org/packages/01/cd/f300cfdca12db1152f14db1d341d3947196a0b0bbf0f44b8bf3f56c36c0d/dbio-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "4bfae00120345352f0334cc7a2950317", "sha256": "7561985c7ca9fd89a573b5d8360619f87ee63563d7b1b9f4da53c31bf1e14480"}, "downloads": -1, "filename": "dbio-0.3.0.tar.gz", "has_sig": false, "md5_digest": "4bfae00120345352f0334cc7a2950317", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11047, "upload_time": "2015-08-05T22:33:09", "upload_time_iso_8601": "2015-08-05T22:33:09.229530Z", "url": "https://files.pythonhosted.org/packages/9f/27/30a7004cf4f4b97eb25e29b8b18109b751c11d4222a16297cde67c9fb9bb/dbio-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "fa2658421f5b85aaead968b56b71b8db", "sha256": "00e2ae3e77a40fc3bd454c663aba8675264b458220fe97cf40a184f4c75ac6f5"}, "downloads": -1, "filename": "dbio-0.3.1.tar.gz", "has_sig": false, "md5_digest": "fa2658421f5b85aaead968b56b71b8db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11056, "upload_time": "2015-08-05T23:02:31", "upload_time_iso_8601": "2015-08-05T23:02:31.224290Z", "url": "https://files.pythonhosted.org/packages/cb/a4/dff648b5e56e83be2f27554905ebaa9c543ea4a22a4173b2244fb342d585/dbio-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "80a227c42b856e718bf098d10a4ff2b3", "sha256": "f08da325bef6da61a7266de42bb54bc87e997addaa47b20a2548216e46a07b53"}, "downloads": -1, "filename": "dbio-0.3.2.tar.gz", "has_sig": false, "md5_digest": "80a227c42b856e718bf098d10a4ff2b3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11047, "upload_time": "2015-08-05T23:32:50", "upload_time_iso_8601": "2015-08-05T23:32:50.137583Z", "url": "https://files.pythonhosted.org/packages/4e/3e/278eeee51383501d98a9f7a5f5bb54d9d688c572b3ee3485e652676f3e57/dbio-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "f71dbc84f49761cab6708a5a3c72bc81", "sha256": "67685380829c4dca89606a568714a25d5e6ce68073be70fa309561fcc695fe59"}, "downloads": -1, "filename": "dbio-0.3.3.tar.gz", "has_sig": false, "md5_digest": "f71dbc84f49761cab6708a5a3c72bc81", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11136, "upload_time": "2015-08-06T17:16:24", "upload_time_iso_8601": "2015-08-06T17:16:24.464853Z", "url": "https://files.pythonhosted.org/packages/1f/22/e78417e90f305f9b6e5bd26b642a3f40f3112706e5dc81bf82362fff2a07/dbio-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "ed07e9ed70bcc68eb63bfa24ecfff2ea", "sha256": "91c06fa757155bf2f71940e1fae6878a7361e635ce9d497732a6e12d4e859e39"}, "downloads": -1, "filename": "dbio-0.3.4.tar.gz", "has_sig": false, "md5_digest": "ed07e9ed70bcc68eb63bfa24ecfff2ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11197, "upload_time": "2015-08-06T17:23:32", "upload_time_iso_8601": "2015-08-06T17:23:32.442914Z", "url": "https://files.pythonhosted.org/packages/b1/32/17466de3e5b75308ebc168ea23bd1d12853c1e973cb6e702ca227ec8af11/dbio-0.3.4.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "93c137669321bc9ccc75ff2a0a8b6313", "sha256": "8acfe2e238ec4a2458ebd3e4d892304c1454d1b97e126d43a49e32fed25d821c"}, "downloads": -1, "filename": "dbio-0.4.0.tar.gz", "has_sig": false, "md5_digest": "93c137669321bc9ccc75ff2a0a8b6313", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11873, "upload_time": "2015-08-06T23:52:45", "upload_time_iso_8601": "2015-08-06T23:52:45.470017Z", "url": "https://files.pythonhosted.org/packages/fc/31/5a5552f39ff5c9295ccdcbf23e1f1ec42e61b573e756e37681d929701d77/dbio-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "6f8f281e381244bb6fd0bda47269996d", "sha256": "828124f5e8db791586b1fdd47f2cec2a3ad9f80a3adb07d247c4d99e6cf02cb2"}, "downloads": -1, "filename": "dbio-0.4.1.tar.gz", "has_sig": false, "md5_digest": "6f8f281e381244bb6fd0bda47269996d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12117, "upload_time": "2015-08-13T21:52:07", "upload_time_iso_8601": "2015-08-13T21:52:07.852457Z", "url": "https://files.pythonhosted.org/packages/5b/99/3a27aefc531f66819970c5134d93389c51e9ec0c3e643aa8deca0eb7d298/dbio-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "d32e4198d694418d0dd41877678a0914", "sha256": "c3409ae097208edfc7fe942d281edf0d3f62e95afcdcfca2082af9b8b7656c56"}, "downloads": -1, "filename": "dbio-0.4.2.tar.gz", "has_sig": false, "md5_digest": "d32e4198d694418d0dd41877678a0914", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13127, "upload_time": "2015-08-17T23:04:00", "upload_time_iso_8601": "2015-08-17T23:04:00.002486Z", "url": "https://files.pythonhosted.org/packages/e7/0c/e1cf4acd1058c5f9a3ff7a70fa0edaa128345bc93f5cef15057a8024e5e7/dbio-0.4.2.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "02509a04c28914df6da19fec657d9fea", "sha256": "f7c4f2cb94befb967f15166fea92432ab90c01dcf62a80f18b9c69ca5490da90"}, "downloads": -1, "filename": "dbio-0.4.3.tar.gz", "has_sig": false, "md5_digest": "02509a04c28914df6da19fec657d9fea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13201, "upload_time": "2015-08-19T16:00:42", "upload_time_iso_8601": "2015-08-19T16:00:42.799035Z", "url": "https://files.pythonhosted.org/packages/0c/f4/87aa8aad6ee823af89fa13b0ab001cb4af3c43b14db089a4053cc854f3c5/dbio-0.4.3.tar.gz", "yanked": false}], "0.4.4": [{"comment_text": "", "digests": {"md5": "feb9e6f0ac98b1382522a0b5beaf08a2", "sha256": "e16f715cdf5132e8641d4a4d4de5de4d4331f230424dfa754a17d0e1987f30fe"}, "downloads": -1, "filename": "dbio-0.4.4.tar.gz", "has_sig": false, "md5_digest": "feb9e6f0ac98b1382522a0b5beaf08a2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13395, "upload_time": "2015-08-21T17:12:33", "upload_time_iso_8601": "2015-08-21T17:12:33.966336Z", "url": "https://files.pythonhosted.org/packages/51/b7/b2050e2bf7dd96e42354b85f9eafe6ace4f2ff6be273b648b43282dc26eb/dbio-0.4.4.tar.gz", "yanked": false}], "0.4.5": [{"comment_text": "", "digests": {"md5": "8bf9cc8be77f9347b261ec2678984635", "sha256": "bb78df6bf2626c607e42be244cdda87478a77d69c3f114ccb4629c0ad343be1a"}, "downloads": -1, "filename": "dbio-0.4.5.tar.gz", "has_sig": false, "md5_digest": "8bf9cc8be77f9347b261ec2678984635", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13424, "upload_time": "2015-10-21T01:06:00", "upload_time_iso_8601": "2015-10-21T01:06:00.975563Z", "url": "https://files.pythonhosted.org/packages/a3/5e/9d22c1c1e0f958bccc57df619401199657166c0a5debed709ed1b7acffb1/dbio-0.4.5.tar.gz", "yanked": false}], "0.4.7": [{"comment_text": "", "digests": {"md5": "fe9f77bc917cfb9b95bfcc925e322084", "sha256": "3173b936131c39244b38e3fc9e8245a6b1f38b1df1a0e4bdbb5ca196c818b580"}, "downloads": -1, "filename": "dbio-0.4.7.tar.gz", "has_sig": false, "md5_digest": "fe9f77bc917cfb9b95bfcc925e322084", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14193, "upload_time": "2015-12-09T22:38:43", "upload_time_iso_8601": "2015-12-09T22:38:43.356940Z", "url": "https://files.pythonhosted.org/packages/aa/7e/30ceb5beb9d3e919b9f0987e29761e3b7e4a7a2ac1ddba057e5e444bfd6d/dbio-0.4.7.tar.gz", "yanked": false}], "0.4.8": [{"comment_text": "", "digests": {"md5": "186c757fe78504900353c14f3b3599f5", "sha256": "11eb3d397671f8cc1fc0c905bddad80e70aae2c505e93ee123e8e46fa9be74b2"}, "downloads": -1, "filename": "dbio-0.4.8.tar.gz", "has_sig": false, "md5_digest": "186c757fe78504900353c14f3b3599f5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14269, "upload_time": "2016-01-26T18:52:52", "upload_time_iso_8601": "2016-01-26T18:52:52.301363Z", "url": "https://files.pythonhosted.org/packages/b8/ac/e6f42924cea1fc6c9c94bb188c5823f18ce3bfcdf3e48957bad90545e106/dbio-0.4.8.tar.gz", "yanked": false}], "0.4.9": [{"comment_text": "", "digests": {"md5": "e0a86eecf5568ba52378ab4cf7bdc464", "sha256": "6f019926bb927ab7ab7c663e22e080f82b0f564eb430b8fe94ba83b2bc2fee60"}, "downloads": -1, "filename": "dbio-0.4.9.tar.gz", "has_sig": false, "md5_digest": "e0a86eecf5568ba52378ab4cf7bdc464", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14371, "upload_time": "2016-05-10T13:44:19", "upload_time_iso_8601": "2016-05-10T13:44:19.663233Z", "url": "https://files.pythonhosted.org/packages/8e/59/8e7057df9cfe526a1e5ad45c9c0188b10fd788aca489c6cab7bde8aae93e/dbio-0.4.9.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "5160b909f16d5f59938ec826f60b88b8", "sha256": "4c2fa63bfae8791753f4964e6feb01963b06eb97c5c694fdc8eb23f3cbc3c855"}, "downloads": -1, "filename": "dbio-0.5.0.tar.gz", "has_sig": false, "md5_digest": "5160b909f16d5f59938ec826f60b88b8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14706, "upload_time": "2016-07-01T17:10:04", "upload_time_iso_8601": "2016-07-01T17:10:04.810622Z", "url": "https://files.pythonhosted.org/packages/00/85/bda37e230efa8585ccb1eea2a7bb44d6fc7ee3b791609b8e5db5730fa30e/dbio-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "d5af6e54472024cabd7b187d72fcb065", "sha256": "83810910ba5cf0910e0b325e320a9204a83e296ddfc6772691c4f77932b5b98e"}, "downloads": -1, "filename": "dbio-0.5.1.tar.gz", "has_sig": false, "md5_digest": "d5af6e54472024cabd7b187d72fcb065", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17603, "upload_time": "2017-09-25T23:05:36", "upload_time_iso_8601": "2017-09-25T23:05:36.349176Z", "url": "https://files.pythonhosted.org/packages/87/08/80db8a1fa80065d85bd89590411927027f4cbfc3f9ed5cde72b35e30d120/dbio-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "b7825c9408fb5b47cfbd3c89f8a72dc2", "sha256": "a4311053372cbba71eda312b3ffff9d18f29e35ce84e6bc7711c4c2fca99bbf8"}, "downloads": -1, "filename": "dbio-0.5.2.tar.gz", "has_sig": false, "md5_digest": "b7825c9408fb5b47cfbd3c89f8a72dc2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14612, "upload_time": "2017-09-27T00:55:14", "upload_time_iso_8601": "2017-09-27T00:55:14.117166Z", "url": "https://files.pythonhosted.org/packages/bd/dd/4fd8a903ed8d6a5ac3f394792c83d85529bab9e58916e2b2f36f37da89be/dbio-0.5.2.tar.gz", "yanked": false}], "0.5.3": [{"comment_text": "", "digests": {"md5": "59619fed455893aa904f17e119d341a8", "sha256": "dcec21614bf272504895c7a967cadc14ede9ede8be3a0878f7f9e7fba8251993"}, "downloads": -1, "filename": "dbio-0.5.3.tar.gz", "has_sig": false, "md5_digest": "59619fed455893aa904f17e119d341a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14608, "upload_time": "2018-03-29T22:52:12", "upload_time_iso_8601": "2018-03-29T22:52:12.643199Z", "url": "https://files.pythonhosted.org/packages/36/2f/12769990d9fee60e6a0625f5485b3ebb06c3c0bd15cbaac227067f5371ba/dbio-0.5.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "59619fed455893aa904f17e119d341a8", "sha256": "dcec21614bf272504895c7a967cadc14ede9ede8be3a0878f7f9e7fba8251993"}, "downloads": -1, "filename": "dbio-0.5.3.tar.gz", "has_sig": false, "md5_digest": "59619fed455893aa904f17e119d341a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14608, "upload_time": "2018-03-29T22:52:12", "upload_time_iso_8601": "2018-03-29T22:52:12.643199Z", "url": "https://files.pythonhosted.org/packages/36/2f/12769990d9fee60e6a0625f5485b3ebb06c3c0bd15cbaac227067f5371ba/dbio-0.5.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:56 2020"}