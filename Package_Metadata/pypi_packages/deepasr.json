{"info": {"author": "Sai Kumar Yava", "author_email": "saikumar.geek@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# DeepAsr\nDeepAsr is an open-source & Keras (Tensorflow) implementation of end-to-end Automatic Speech Recognition (ASR) engine and it supports multiple Speech Recognition architectures.\n\nSupported Asr Architectures:\n- Baidu's Deep Speech 2\n- DeepAsrNetwork1\n\n**Using DeepAsr you can**:\n- perform speech-to-text using pre-trained models\n- tune pre-trained models to your needs\n- create new models on your own \n\n**DeepAsr key features**:\n- **Multi GPU support**: You can do much more like distribute the training using the [Strategy](https://www.tensorflow.org/guide/distributed_training), or experiment with [mixed precision](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy) policy.\n- **CuDNN support**: Model using [CuDNNLSTM](https://keras.io/layers/recurrent/) implementation by NVIDIA Developers. CPU devices is also supported.\n- **DataGenerator**: The feature extraction during model training for large the data.\n\n## Installation\nYou can use pip:\n```bash\npip install deepasr\n```\n\n## Getting started\nThe speech recognition is a tough task. You don't need to know all details to use one of the pretrained models.\nHowever it's worth to understand conceptional crucial components:\n- **Input**: Audio files (WAV or FLAC) with mono 16-bit 16 kHz (up to 5 seconds)\n- **FeaturesExtractor**: Convert audio files using MFCC Features or Spectrogram\n- **Model**: CTC model defined in [**Keras**](https://keras.io/) (references: [[1]](https://arxiv.org/abs/1412.5567), [[2]](https://arxiv.org/abs/1512.02595))\n- **Decoder**: Greedy or BeamSearch algorithms with the language model support decode a sequence of probabilities using Alphabet\n- **DataGenerator**: Stream data to the model via generator\n- **Callbacks**: Set of functions monitoring the training\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport deepasr as asr\n\n# get CTCPipeline\ndef get_config(feature_type: str = 'spectrogram', multi_gpu: bool = False):\n    # audio feature extractor\n    features_extractor = asr.features.preprocess(feature_type=feature_type, features_num=161,\n                                                 samplerate=16000,\n                                                 winlen=0.02,\n                                                 winstep=0.025,\n                                                 winfunc=np.hanning)\n\n    # input label encoder\n    alphabet_en = asr.vocab.Alphabet(lang='en')\n    # training model\n    model = asr.model.get_deepspeech2(\n        input_dim=161,\n        output_dim=29,\n        is_mixed_precision=True\n    )\n    # model optimizer\n    optimizer = tf.keras.optimizers.Adam(\n        lr=1e-4,\n        beta_1=0.9,\n        beta_2=0.999,\n        epsilon=1e-8\n    )\n    # output label deocder\n    decoder = asr.decoder.GreedyDecoder()\n    # decoder = asr.decoder.BeamSearchDecoder(beam_width=100, top_paths=1)\n    # CTCPipeline\n    pipeline = asr.pipeline.ctc_pipeline.CTCPipeline(\n        alphabet=alphabet_en, features_extractor=features_extractor, model=model, optimizer=optimizer, decoder=decoder,\n        sample_rate=16000, mono=True, multi_gpu=multi_gpu\n    )\n    return pipeline\n\n\ntrain_data = pd.read_csv('train_data.csv')\n\npipeline = get_config(feature_type = 'fbank', multi_gpu=False)\n\n# train asr model\nhistory = pipeline.fit(train_dataset=train_data, batch_size=128, epochs=500)\n# history = pipeline.fit_generator(train_dataset = train_data, batch_size=32, epochs=500)\n\npipeline.save('./checkpoint')\n```\n\nLoaded pre-trained model has all components. The prediction can be invoked just by calling pipline.predict().\n\n```python\nimport pandas as pd\nimport deepasr as asr\nimport numpy as np\ntest_data = pd.read_csv('test_data.csv')\n\n# get testing audio and transcript from dataset\nindex = np.random.randint(test_data.shape[0])\ndata = test_data.iloc[index]\ntest_file = data[0]\ntest_transcript = data[1]\n# Test Audio file\nprint(\"Audio File:\",test_file)\n# Test Transcript\nprint(\"Audio Transcript:\", test_transcript)\nprint(\"Transcript length:\",len(test_transcript))\n\npipeline = asr.pipeline.load('./checkpoint')\nprint(\"Prediction\", pipeline.predict(test_file))\n```\n\n#### References\n\nThe fundamental repositories:\n- Baidu - [DeepSpeech2 - A PaddlePaddle implementation of DeepSpeech2 architecture for ASR](https://github.com/PaddlePaddle/DeepSpeech)\n- NVIDIA - [Toolkit for efficient experimentation with Speech Recognition, Text2Speech and NLP](https://nvidia.github.io/OpenSeq2Seq)\n- TensorFlow - [The implementation of DeepSpeech2 model](https://github.com/tensorflow/models/tree/master/research/deep_speech)\n- Mozilla - [DeepSpeech - A TensorFlow implementation of Baidu's DeepSpeech architecture](https://github.com/mozilla/DeepSpeech) \n- Espnet - [End-to-End Speech Processing Toolkit](https://github.com/espnet/espnet)\n- Automatic Speech Recognition - [Distill the Automatic Speech Recognition research](https://github.com/rolczynski/Automatic-Speech-Recognition)\n- Python Speech Features - [Speech features for ASR including MFCCs and filterbank energies](https://github.com/jameslyons/python_speech_features)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/scionoftech/DeepAsr", "keywords": "deepspeech,asr,speech recognition,speech to text", "license": "GNU", "maintainer": "", "maintainer_email": "", "name": "deepasr", "package_url": "https://pypi.org/project/deepasr/", "platform": "", "project_url": "https://pypi.org/project/deepasr/", "project_urls": {"Homepage": "https://github.com/scionoftech/DeepAsr"}, "release_url": "https://pypi.org/project/deepasr/0.1.1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Keras(Tensorflow) implementations of Automatic Speech Recognition", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DeepAsr</h1>\n<p>DeepAsr is an open-source &amp; Keras (Tensorflow) implementation of end-to-end Automatic Speech Recognition (ASR) engine and it supports multiple Speech Recognition architectures.</p>\n<p>Supported Asr Architectures:</p>\n<ul>\n<li>Baidu's Deep Speech 2</li>\n<li>DeepAsrNetwork1</li>\n</ul>\n<p><strong>Using DeepAsr you can</strong>:</p>\n<ul>\n<li>perform speech-to-text using pre-trained models</li>\n<li>tune pre-trained models to your needs</li>\n<li>create new models on your own</li>\n</ul>\n<p><strong>DeepAsr key features</strong>:</p>\n<ul>\n<li><strong>Multi GPU support</strong>: You can do much more like distribute the training using the <a href=\"https://www.tensorflow.org/guide/distributed_training\" rel=\"nofollow\">Strategy</a>, or experiment with <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy\" rel=\"nofollow\">mixed precision</a> policy.</li>\n<li><strong>CuDNN support</strong>: Model using <a href=\"https://keras.io/layers/recurrent/\" rel=\"nofollow\">CuDNNLSTM</a> implementation by NVIDIA Developers. CPU devices is also supported.</li>\n<li><strong>DataGenerator</strong>: The feature extraction during model training for large the data.</li>\n</ul>\n<h2>Installation</h2>\n<p>You can use pip:</p>\n<pre>pip install deepasr\n</pre>\n<h2>Getting started</h2>\n<p>The speech recognition is a tough task. You don't need to know all details to use one of the pretrained models.\nHowever it's worth to understand conceptional crucial components:</p>\n<ul>\n<li><strong>Input</strong>: Audio files (WAV or FLAC) with mono 16-bit 16 kHz (up to 5 seconds)</li>\n<li><strong>FeaturesExtractor</strong>: Convert audio files using MFCC Features or Spectrogram</li>\n<li><strong>Model</strong>: CTC model defined in <a href=\"https://keras.io/\" rel=\"nofollow\"><strong>Keras</strong></a> (references: <a href=\"https://arxiv.org/abs/1412.5567\" rel=\"nofollow\">[1]</a>, <a href=\"https://arxiv.org/abs/1512.02595\" rel=\"nofollow\">[2]</a>)</li>\n<li><strong>Decoder</strong>: Greedy or BeamSearch algorithms with the language model support decode a sequence of probabilities using Alphabet</li>\n<li><strong>DataGenerator</strong>: Stream data to the model via generator</li>\n<li><strong>Callbacks</strong>: Set of functions monitoring the training</li>\n</ul>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n<span class=\"kn\">import</span> <span class=\"nn\">deepasr</span> <span class=\"k\">as</span> <span class=\"nn\">asr</span>\n\n<span class=\"c1\"># get CTCPipeline</span>\n<span class=\"k\">def</span> <span class=\"nf\">get_config</span><span class=\"p\">(</span><span class=\"n\">feature_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">'spectrogram'</span><span class=\"p\">,</span> <span class=\"n\">multi_gpu</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">):</span>\n    <span class=\"c1\"># audio feature extractor</span>\n    <span class=\"n\">features_extractor</span> <span class=\"o\">=</span> <span class=\"n\">asr</span><span class=\"o\">.</span><span class=\"n\">features</span><span class=\"o\">.</span><span class=\"n\">preprocess</span><span class=\"p\">(</span><span class=\"n\">feature_type</span><span class=\"o\">=</span><span class=\"n\">feature_type</span><span class=\"p\">,</span> <span class=\"n\">features_num</span><span class=\"o\">=</span><span class=\"mi\">161</span><span class=\"p\">,</span>\n                                                 <span class=\"n\">samplerate</span><span class=\"o\">=</span><span class=\"mi\">16000</span><span class=\"p\">,</span>\n                                                 <span class=\"n\">winlen</span><span class=\"o\">=</span><span class=\"mf\">0.02</span><span class=\"p\">,</span>\n                                                 <span class=\"n\">winstep</span><span class=\"o\">=</span><span class=\"mf\">0.025</span><span class=\"p\">,</span>\n                                                 <span class=\"n\">winfunc</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">hanning</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># input label encoder</span>\n    <span class=\"n\">alphabet_en</span> <span class=\"o\">=</span> <span class=\"n\">asr</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">Alphabet</span><span class=\"p\">(</span><span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s1\">'en'</span><span class=\"p\">)</span>\n    <span class=\"c1\"># training model</span>\n    <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">asr</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_deepspeech2</span><span class=\"p\">(</span>\n        <span class=\"n\">input_dim</span><span class=\"o\">=</span><span class=\"mi\">161</span><span class=\"p\">,</span>\n        <span class=\"n\">output_dim</span><span class=\"o\">=</span><span class=\"mi\">29</span><span class=\"p\">,</span>\n        <span class=\"n\">is_mixed_precision</span><span class=\"o\">=</span><span class=\"kc\">True</span>\n    <span class=\"p\">)</span>\n    <span class=\"c1\"># model optimizer</span>\n    <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span>\n        <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">1e-4</span><span class=\"p\">,</span>\n        <span class=\"n\">beta_1</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">,</span>\n        <span class=\"n\">beta_2</span><span class=\"o\">=</span><span class=\"mf\">0.999</span><span class=\"p\">,</span>\n        <span class=\"n\">epsilon</span><span class=\"o\">=</span><span class=\"mf\">1e-8</span>\n    <span class=\"p\">)</span>\n    <span class=\"c1\"># output label deocder</span>\n    <span class=\"n\">decoder</span> <span class=\"o\">=</span> <span class=\"n\">asr</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"o\">.</span><span class=\"n\">GreedyDecoder</span><span class=\"p\">()</span>\n    <span class=\"c1\"># decoder = asr.decoder.BeamSearchDecoder(beam_width=100, top_paths=1)</span>\n    <span class=\"c1\"># CTCPipeline</span>\n    <span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">asr</span><span class=\"o\">.</span><span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">ctc_pipeline</span><span class=\"o\">.</span><span class=\"n\">CTCPipeline</span><span class=\"p\">(</span>\n        <span class=\"n\">alphabet</span><span class=\"o\">=</span><span class=\"n\">alphabet_en</span><span class=\"p\">,</span> <span class=\"n\">features_extractor</span><span class=\"o\">=</span><span class=\"n\">features_extractor</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">decoder</span><span class=\"o\">=</span><span class=\"n\">decoder</span><span class=\"p\">,</span>\n        <span class=\"n\">sample_rate</span><span class=\"o\">=</span><span class=\"mi\">16000</span><span class=\"p\">,</span> <span class=\"n\">mono</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">multi_gpu</span><span class=\"o\">=</span><span class=\"n\">multi_gpu</span>\n    <span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">pipeline</span>\n\n\n<span class=\"n\">train_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'train_data.csv'</span><span class=\"p\">)</span>\n\n<span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">get_config</span><span class=\"p\">(</span><span class=\"n\">feature_type</span> <span class=\"o\">=</span> <span class=\"s1\">'fbank'</span><span class=\"p\">,</span> <span class=\"n\">multi_gpu</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># train asr model</span>\n<span class=\"n\">history</span> <span class=\"o\">=</span> <span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">train_dataset</span><span class=\"o\">=</span><span class=\"n\">train_data</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n<span class=\"c1\"># history = pipeline.fit_generator(train_dataset = train_data, batch_size=32, epochs=500)</span>\n\n<span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'./checkpoint'</span><span class=\"p\">)</span>\n</pre>\n<p>Loaded pre-trained model has all components. The prediction can be invoked just by calling pipline.predict().</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">deepasr</span> <span class=\"k\">as</span> <span class=\"nn\">asr</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"n\">test_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'test_data.csv'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># get testing audio and transcript from dataset</span>\n<span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"n\">test_data</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">test_data</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[</span><span class=\"n\">index</span><span class=\"p\">]</span>\n<span class=\"n\">test_file</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">test_transcript</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"c1\"># Test Audio file</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Audio File:\"</span><span class=\"p\">,</span><span class=\"n\">test_file</span><span class=\"p\">)</span>\n<span class=\"c1\"># Test Transcript</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Audio Transcript:\"</span><span class=\"p\">,</span> <span class=\"n\">test_transcript</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Transcript length:\"</span><span class=\"p\">,</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">test_transcript</span><span class=\"p\">))</span>\n\n<span class=\"n\">pipeline</span> <span class=\"o\">=</span> <span class=\"n\">asr</span><span class=\"o\">.</span><span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'./checkpoint'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"Prediction\"</span><span class=\"p\">,</span> <span class=\"n\">pipeline</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">test_file</span><span class=\"p\">))</span>\n</pre>\n<h4>References</h4>\n<p>The fundamental repositories:</p>\n<ul>\n<li>Baidu - <a href=\"https://github.com/PaddlePaddle/DeepSpeech\" rel=\"nofollow\">DeepSpeech2 - A PaddlePaddle implementation of DeepSpeech2 architecture for ASR</a></li>\n<li>NVIDIA - <a href=\"https://nvidia.github.io/OpenSeq2Seq\" rel=\"nofollow\">Toolkit for efficient experimentation with Speech Recognition, Text2Speech and NLP</a></li>\n<li>TensorFlow - <a href=\"https://github.com/tensorflow/models/tree/master/research/deep_speech\" rel=\"nofollow\">The implementation of DeepSpeech2 model</a></li>\n<li>Mozilla - <a href=\"https://github.com/mozilla/DeepSpeech\" rel=\"nofollow\">DeepSpeech - A TensorFlow implementation of Baidu's DeepSpeech architecture</a></li>\n<li>Espnet - <a href=\"https://github.com/espnet/espnet\" rel=\"nofollow\">End-to-End Speech Processing Toolkit</a></li>\n<li>Automatic Speech Recognition - <a href=\"https://github.com/rolczynski/Automatic-Speech-Recognition\" rel=\"nofollow\">Distill the Automatic Speech Recognition research</a></li>\n<li>Python Speech Features - <a href=\"https://github.com/jameslyons/python_speech_features\" rel=\"nofollow\">Speech features for ASR including MFCCs and filterbank energies</a></li>\n</ul>\n\n          </div>"}, "last_serial": 7135889, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "48472e8363d66f13152dc19deb5678b4", "sha256": "4643448c802c9a0b8ce3d08b2c23efec8ec3a802bd462e0ea99b9dd738a94297"}, "downloads": -1, "filename": "deepasr-0.0.1.tar.gz", "has_sig": false, "md5_digest": "48472e8363d66f13152dc19deb5678b4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33554, "upload_time": "2020-04-15T07:57:57", "upload_time_iso_8601": "2020-04-15T07:57:57.678500Z", "url": "https://files.pythonhosted.org/packages/d6/d6/492c6fee87105ec48ae4452c2b6b1416bb78ebb3e18e61eeea0cf5d841d5/deepasr-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "64eec764f0fed48bbb621ea18022fc1f", "sha256": "cfa8e9afd5e558010ae72bfc4aee451bb1c51561ac9220555c5d00db3781235f"}, "downloads": -1, "filename": "deepasr-0.0.2.tar.gz", "has_sig": false, "md5_digest": "64eec764f0fed48bbb621ea18022fc1f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33637, "upload_time": "2020-04-15T08:55:54", "upload_time_iso_8601": "2020-04-15T08:55:54.561101Z", "url": "https://files.pythonhosted.org/packages/51/a1/f882759774034c33cad667271c967e07754d6396433ad4e8d6a0289ad080/deepasr-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "eb52248b528aaf333983f3c51d9d62ac", "sha256": "2ddf75bb9fcd92b33ffed8cfdeeff1c1153d58fb4cbea3e8329db812ec576cb2"}, "downloads": -1, "filename": "deepasr-0.0.3.tar.gz", "has_sig": false, "md5_digest": "eb52248b528aaf333983f3c51d9d62ac", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33263, "upload_time": "2020-04-20T10:25:21", "upload_time_iso_8601": "2020-04-20T10:25:21.850617Z", "url": "https://files.pythonhosted.org/packages/5f/51/22912cd9d9626ac1d82fb5bdf937132b12962c3416d59183374b64ff3ed8/deepasr-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "c0111806a5139e15cd48a9f8d0f705ab", "sha256": "8e4cf4297abb8f5efb4eb6b1268861ae7b01a331d9fa443e976792d049d4b01b"}, "downloads": -1, "filename": "deepasr-0.0.4.tar.gz", "has_sig": false, "md5_digest": "c0111806a5139e15cd48a9f8d0f705ab", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33223, "upload_time": "2020-04-20T12:47:23", "upload_time_iso_8601": "2020-04-20T12:47:23.877285Z", "url": "https://files.pythonhosted.org/packages/f2/11/736d6adc7db331de6e1f417ad8649f3879aea32f3e161b0f3e76fed0dbbf/deepasr-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "4b592d46de6fca5d46155f2e08d67182", "sha256": "14230c443868db7d55d7f5b4189b153c3964629bbe94bcbed5a5bd747587ae77"}, "downloads": -1, "filename": "deepasr-0.0.5.tar.gz", "has_sig": false, "md5_digest": "4b592d46de6fca5d46155f2e08d67182", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33341, "upload_time": "2020-04-20T13:15:40", "upload_time_iso_8601": "2020-04-20T13:15:40.693783Z", "url": "https://files.pythonhosted.org/packages/88/c3/4e696c4c5a564b20c414a9942a8da4492cd7596fa6899770a706f772267e/deepasr-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "66884411507ce47569c1e69cd3e01a16", "sha256": "c50349dd86fa70a7999ab676abcc90e0933d82d22d2d8e4319118cc6364158d1"}, "downloads": -1, "filename": "deepasr-0.0.6.tar.gz", "has_sig": false, "md5_digest": "66884411507ce47569c1e69cd3e01a16", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33351, "upload_time": "2020-04-20T13:46:27", "upload_time_iso_8601": "2020-04-20T13:46:27.713427Z", "url": "https://files.pythonhosted.org/packages/21/7a/4e2416317ff8d46e862edada111fc7377b1ed502e58aa24279a7688ec685/deepasr-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "e436b6c4a594ca53ad00df711f3c38ec", "sha256": "0b0946d28f10bfb5bafe63500a18dec8ceb4a467c8ae32b1ba73628c21f723e7"}, "downloads": -1, "filename": "deepasr-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e436b6c4a594ca53ad00df711f3c38ec", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33339, "upload_time": "2020-04-20T13:53:25", "upload_time_iso_8601": "2020-04-20T13:53:25.899209Z", "url": "https://files.pythonhosted.org/packages/64/92/badd207ec639f7c9deb1ff741ed14e7c440619252e508fcea781d3643343/deepasr-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "4bf5d2366bb5385e27ffe3dbbf6d3371", "sha256": "c6ce839ec990b98f0b2d282109072640d11d1be0dd041fd1b33243c5bd8fe4bd"}, "downloads": -1, "filename": "deepasr-0.0.8.tar.gz", "has_sig": false, "md5_digest": "4bf5d2366bb5385e27ffe3dbbf6d3371", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33514, "upload_time": "2020-04-22T08:39:16", "upload_time_iso_8601": "2020-04-22T08:39:16.162626Z", "url": "https://files.pythonhosted.org/packages/a5/2a/33cb49dd6206875cde8f476dba820874b75ae9b1a1fc243b9e08767ca013/deepasr-0.0.8.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "072b3d331c3dfd004844dc7e3416810f", "sha256": "a92881c5b7e87f593b8252858910d8e0ef3635a71a8590dff1d70792d5fca5d4"}, "downloads": -1, "filename": "deepasr-0.0.9.tar.gz", "has_sig": false, "md5_digest": "072b3d331c3dfd004844dc7e3416810f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 33511, "upload_time": "2020-04-22T08:46:07", "upload_time_iso_8601": "2020-04-22T08:46:07.298484Z", "url": "https://files.pythonhosted.org/packages/43/55/fa233877bb2aa0bed773153f1a292b8da486d65bb5df1fdffd737d97e717/deepasr-0.0.9.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "60e1cbc95070fd80536bf8521d7b7a11", "sha256": "0ade0c6d8ca431ae89b847d3ea65dead4cabbf5b9254d0cdda01aaec5a9ec3b4"}, "downloads": -1, "filename": "deepasr-0.1.0.tar.gz", "has_sig": false, "md5_digest": "60e1cbc95070fd80536bf8521d7b7a11", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 34515, "upload_time": "2020-04-30T08:30:51", "upload_time_iso_8601": "2020-04-30T08:30:51.144737Z", "url": "https://files.pythonhosted.org/packages/fd/67/5380d5341891bc0e3085c81d9243465f63fc58b4818a93eb2c26c2c071e6/deepasr-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "e31494f14bbe37515c7f908045cee8f8", "sha256": "38043a784d22d7c3992adbb06972bd4888626bec4df64e1d8b062ff70bd22a50"}, "downloads": -1, "filename": "deepasr-0.1.1.tar.gz", "has_sig": false, "md5_digest": "e31494f14bbe37515c7f908045cee8f8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 34521, "upload_time": "2020-04-30T08:48:03", "upload_time_iso_8601": "2020-04-30T08:48:03.488552Z", "url": "https://files.pythonhosted.org/packages/1e/95/a7a6bf6050db8d747c9cd0d6a469b16986ca489003e34a513aec75023c3d/deepasr-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e31494f14bbe37515c7f908045cee8f8", "sha256": "38043a784d22d7c3992adbb06972bd4888626bec4df64e1d8b062ff70bd22a50"}, "downloads": -1, "filename": "deepasr-0.1.1.tar.gz", "has_sig": false, "md5_digest": "e31494f14bbe37515c7f908045cee8f8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 34521, "upload_time": "2020-04-30T08:48:03", "upload_time_iso_8601": "2020-04-30T08:48:03.488552Z", "url": "https://files.pythonhosted.org/packages/1e/95/a7a6bf6050db8d747c9cd0d6a469b16986ca489003e34a513aec75023c3d/deepasr-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:30 2020"}