{"info": {"author": "Alison Carrera", "author_email": "alison.carrera2007@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Multi-Armed Bandit Algorithms (MAB)\nMulti-Armed Bandit (MAB) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice.\n\nIn the problem, each machine provides a random reward from a probability distribution specific to that machine. The objective of the gambler is to maximize the sum of rewards earned through a sequence of lever pulls. The crucial tradeoff the gambler faces at each trial is between \"exploitation\" of the machine that has the highest expected payoff and \"exploration\" to get more information about the expected payoffs of the other machines. The trade-off between exploration and exploitation is also faced in machine learning.\n\nThe main problems that the MAB help to solve is the split of the population in online experiments.\n\n\n## Installing\n```\npip install mabalgs\n```\n\n## Algorithms (Bandit strategies)\n\n### Non-linear Contextual Bandit Algorithm (ONN_THS)\nIf you are looking for a contextual bandit algorithm, please go to my another repository [ONN_THS](https://github.com/alison-carrera/onn)\n\n### UCB1 (Upper Confidence Bound)\nIs an algorithm for the multi-armed bandit that achieves regret that grows only logarithmically with the number of actions taken, with no prior knowledge of the reward distribution required.\n\n#### Get a selected arm\n```python\nfrom mab import algs\n\n# Constructor receives number of arms.\nucb_with_two_arms = algs.UCB1(2)\nucb_with_two_arms.select()\n```\n\n#### Reward an arm\n```python\nfrom mab import algs\n\n# Constructor receives number of arms.\nucb_with_two_arms = algs.UCB1(2)\nmy_arm = ucb_with_two_arms.select()[0]\nucb_with_two_arms.reward(my_arm)\n```\n\n### UCB-Tuned (Upper Confidence Bound Tuned)\nA strict improvement over both UCB solutions can be made by tuning the upper-bound parameter in UCB1\u2019s decision rule. UCB-Tuned empirically outperforms UCB1 and UCB2 in terms of frequency\nof picking the best arm. Further, indicate that UCB-Tuned is \u201cnot very\u201d sensitive to the variance of the arms. \n\n#### Get a selected arm\n```python\nfrom mab import algs\n\n# Constructor receives number of arms.\nucbt_with_two_arms = algs.UCBTuned(2)\nucbt_with_two_arms.select()\n```\n\n#### Reward an arm\n```python\nfrom mab import algs\n\n# Constructor receives number of arms.\nucbt_with_two_arms = algs.UCBTuned(2)\nmy_arm = ucbt_with_two_arms.select()[0]\nucbt_with_two_arms.reward(my_arm)\n```\n\n### Thompson Sampling\nThompson Sampling is fully Bayesian: it generates a bandit configuration (i.e. a vector of expected rewards) from a posterior distribution, and then acts as if this was the true configuration (i.e. it pulls the lever with the highest expected reward).\n\n\u201cOn the likelihood that one unknown probability exceeds another\nin view of the evidence of two samples\u201d produced the first paper on an equivalent problem to the multi-armed bandit in which a solution to the Bernoulli\ndistribution bandit problem now referred to as Thompson sampling is presented.\n\n#### Get a selected arm\n```python\nfrom mab import algs\n\n# Constructor receives number of arms.\nthomp_with_two_arms = algs.ThompsomSampling(2)\nthomp_with_two_arms.select()\n```\n\n#### Reward an arm\n```python\nfrom mab import algs\n\n# Constructor receives number of arms.\nthomp_with_two_arms = algs.ThompsomSampling(2)\nmy_arm = thomp_with_two_arms.select()[0]\nthomp_with_two_arms.reward(my_arm)\n```\n\n## Comparison of the algorithms using Monte Carlo Simulation\n\nMonte Carlo simulation is the best way to debug / test MAB algorithms. This simulation generates data in real time \nrespecting a probability of delivery (chosen by the executor of the simulation) over time. \nThese probabilities may represent the taste of most users regarding a MAB arm (option) over time, for example.\n\nExample: We want to test a 5-arm MAB that will be used in an ad problem, and MAB must choose which of the 5 ads must\nreceive the most clicks from users. You can use the following probability setting ([0.9, 0.1, 0.1, 0.1, 0.1]) for this.\nEach array element represents an arm and its probability of being clicked.\nWe can observe that Ad 0 (index 0 of array) has 90% chance of clicks while others have 10% chances of clicks.\nThese information can help us to analyze if the algorithm is performing well.\n\nA simulation with the following settings was made:\n\n```\n{0: [0.9, 0.6, 0.2, 0.2, 0.1], 1000: [0.3, 0.8, 0.2, 0.2, 0.2], 4000: [0.7, 0.3, 0.2, 0.2, 0.1]}\n```\n\nThe key of the dictionary tells us the time which the probabilities must be activated in the passing time.\nThe total time of the simulation was 5000 steps and each point of the chart is an average of 1000 simulations with 5000 steps each.\n\nFrom this dictionary we can infer that:\n\n- From time 0 to 1000, arm 0 is the winner.\n- From time 1000 to 4000, arm 1 is the winner\n- From time 4000, arm 0 is the winner.\n\nYou can check a full example of this simulation at this [notebook.](./Monte_Carlo_Simulation_Example.ipynb)\n\n### Results:\n\n![UCB1](./readme-images/ucb1.png)\n\n![UCB-Tuned](./readme-images/ucbt.png)\n\n![Thompsom Sampling](./readme-images/ths.png)\n\n![Cumulative Rewards](./readme-images/rewards.png)\n\nRemembering that all these analyzes were performed in a simulation environment and the results may vary according \nto the type of information the MAB will perform on. For a more sensible choice with real world data, please perform \nan AB test between the algorithms in your scenario.\n\n----------------\n\n# Ranked Multi-Armed Bandit Algorithms\n\n### RBA (Ranked Bandit Algorithm)\nThis is an online learning algorithm which can be used to the ranking problem. In this algorithm we have a certain quantity of\narms to be shown in a certain quantity of a ranked slots (like a netflix film list). Each arm is best in some of the ranking position and\nthis algorithm uses MAB instances to do that.\n\n#### Get selected arms in their ranked positions\n```python\nfrom mab import algs, ranked_algs\n\n# Constructor receives number of arms, number of ranks and a MAB algorithm reference.\nrba_algorithm = ranked_algs.RBA(10, 10, algs.ThompsomSampling) # Any MAB from algs can be used.\nranked_selected_arms = rba_algorithm.select() # Best arms in its best position.\n```\n\n#### Reward an arm in a certain position of the rank\n```python\nfrom mab import algs, ranked_algs\n\n# Constructor receives number of arms, number of ranks and a MAB algorithm reference.\nrba_algorithm = ranked_algs.RBA(10, 10, algs.ThompsomSampling) # Any MAB from algs can be used.\nranked_selected_arms = rba_algorithm.select() # Best arms in its best position.\nrba_algorithm.reward(ranked_selected_arms, 2) # Reward the arm 2 in its position of the rank.\n```\n\n### RBA-M (Ranked Bandit Algorithm - Modified)\nIt's the same thing of the RBA, but with a modification in the arm collisions approach.\nThis new collision approach was made by me and my team partner [F\u00e1bio](https://github.com/fabiosvb). For more details about this approach, please see code documentation.\n\n#### Get selected arms in their ranked positions\n```python\nfrom mab import algs, ranked_algs\n\n# Constructor receives number of arms, number of ranks and a MAB algorithm reference.\nrbam_algorithm = ranked_algs.RBAM(10, 10, algs.ThompsomSampling) # Any MAB from algs can be used.\nranked_selected_arms = rbam_algorithm.select() # Best arms in its best position.\n```\n\n#### Reward an arm in a certain position of the rank\n```python\nfrom mab import algs, ranked_algs\n\n# Constructor receives number of arms, number of ranks and a MAB algorithm reference.\nrbam_algorithm = ranked_algs.RBAM(10, 10, algs.ThompsomSampling) # Any MAB from algs can be used.\nranked_selected_arms = rbam_algorithm.select()  # Best arms in its best position.\nrbam_algorithm.reward(ranked_selected_arms, 2) # Reward the arm 2 in its position of the rank.\n```\n\n## Behavior of the RBA-M algorithm using Monte Carlo Simulation\n\nLike before, we will make a Monte Carlo experimentation using RBA-M Algorithm to show its behavior.\n\nExample: We want to test a 5-arm and 4-rank MAB that will be used in a movie slot recomendation problem, \nand MAB must choose which of the 4 movies banners must receive the most clicks from users in each slot position.\n\nA simulation with the following settings was made:\n\n```\n{\n    0: [[0.1, 0.1, 0.1, 0.9, 0.1],\n        [0.1, 0.1, 0.9, 0.1, 0.1], \n        [0.1, 0.9, 0.1, 0.1, 0.1], \n        [0.9, 0.1, 0.1, 0.1, 0.1], \n        [0.25, 0.25, 0.25, 0.25]], # Rank position click probability.\n                        \n    1500: [[0.9, 0.1, 0.1, 0.1, 0.1], \n           [0.1, 0.9, 0.1, 0.1, 0.1], \n           [0.1, 0.1, 0.9, 0.1, 0.1], \n           [0.1, 0.1, 0.1, 0.9, 0.1], \n           [0.25, 0.25, 0.25, 0.25]] # Rank position click probability.\n           \n} \n```\n\nIn this simulation we have something different. Now, at a given time we need to set the probability of all available arms in each position of the rank, and\nthe last array is the rank position click probability (velocity of convergence at given ranking position).\n\nThe total time of the simulation was 3000 steps and each point of the chart is an average of 1000 simulations with 3000 steps each.\n\nFrom this dictionary we can infer that:\n\n- From time 0 to 1500, arm 3 is the winner at rank 0, arm 2 is the winner at rank 1, arm 1 is the winner at rank 2 and arm 0 is the winner at rank 3.\n- From time 1500 to 3000, arm 0 is the winner at rank 0, arm 1 is the winner at rank 1, arm 2 is the winner at rank 2 and arm 3 is the winner at rank 3.\n- The Rank position click probability is the same to all to give a better understanding of their behaviors.\n\nYou can check a full example of this simulation at this [notebook.](./Monte_Carlo_RBAM.ipynb)\n\n### Results:\n\n![UCB1](./readme-images/ranked/ucb1_ranked.png)\n\n![UCB-Tuned](./readme-images/ranked/ucbt_ranked.png)\n\n![Thompsom Sampling](./readme-images/ranked/ths_ranked.png)\n\n![Cumulative Rewards](./readme-images/ranked/rewards_ranked.png)\n\nRemembering that all these analyzes were performed in a simulation environment and the results may vary according \nto the type of information the RMAB will perform on. For a more sensible choice with real world data, please perform \nan AB test between the algorithms in your scenario.\n\n### RBA vs RBA-M\n\nIf you want to see the behavior of the RBA algorithm, you can execute it using this [notebook.](./Monte_Carlo_RBAM.ipynb) It's just change the 'rbam' to 'rba' in the run method. The behavior between they is the same, just in the 'same weight' case for arms in same positions is that RBA-M performs better.\n\n----------------\n\n## Contributors\n- [Alison de Andrade Carrera](https://github.com/alison-carrera)\n- [F\u00e1bio Silva Vilas Boas](https://github.com/fabiosvb)\n- [Daniel Ara\u00fajo](https://github.com/danielcoaraujo)\n\n## References\n- [Wikipedia MAB](https://en.wikipedia.org/wiki/Multi-armed_bandit)\n- [A Survey of Online Experiment Design\nwith the Stochastic Multi-Armed Bandit](https://arxiv.org/pdf/1510.00757.pdf)\n- [Finite-time Analysis of the Multiarmed Bandit Problem](https://link.springer.com/article/10.1023%2FA%3A1013689704352?LI=true)\n- [Solving multiarmed bandits: A comparison of epsilon-greedy and Thompson sampling](https://towardsdatascience.com/solving-multiarmed-bandits-a-comparison-of-epsilon-greedy-and-thompson-sampling-d97167ca9a50)\n- [Learning Diverse Rankings with Multi-Armed Bandits](https://dl.acm.org/citation.cfm?id=1390255)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/alison-carrera/mabalgs", "keywords": "", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "mabalgs", "package_url": "https://pypi.org/project/mabalgs/", "platform": "", "project_url": "https://pypi.org/project/mabalgs/", "project_urls": {"Homepage": "https://github.com/alison-carrera/mabalgs"}, "release_url": "https://pypi.org/project/mabalgs/0.6.4/", "requires_dist": null, "requires_python": "", "summary": "Multi-armed bandit algorithms", "version": "0.6.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Multi-Armed Bandit Algorithms (MAB)</h1>\n<p>Multi-Armed Bandit (MAB) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice.</p>\n<p>In the problem, each machine provides a random reward from a probability distribution specific to that machine. The objective of the gambler is to maximize the sum of rewards earned through a sequence of lever pulls. The crucial tradeoff the gambler faces at each trial is between \"exploitation\" of the machine that has the highest expected payoff and \"exploration\" to get more information about the expected payoffs of the other machines. The trade-off between exploration and exploitation is also faced in machine learning.</p>\n<p>The main problems that the MAB help to solve is the split of the population in online experiments.</p>\n<h2>Installing</h2>\n<pre><code>pip install mabalgs\n</code></pre>\n<h2>Algorithms (Bandit strategies)</h2>\n<h3>Non-linear Contextual Bandit Algorithm (ONN_THS)</h3>\n<p>If you are looking for a contextual bandit algorithm, please go to my another repository <a href=\"https://github.com/alison-carrera/onn\" rel=\"nofollow\">ONN_THS</a></p>\n<h3>UCB1 (Upper Confidence Bound)</h3>\n<p>Is an algorithm for the multi-armed bandit that achieves regret that grows only logarithmically with the number of actions taken, with no prior knowledge of the reward distribution required.</p>\n<h4>Get a selected arm</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms.</span>\n<span class=\"n\">ucb_with_two_arms</span> <span class=\"o\">=</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">UCB1</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">ucb_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span>\n</pre>\n<h4>Reward an arm</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms.</span>\n<span class=\"n\">ucb_with_two_arms</span> <span class=\"o\">=</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">UCB1</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">my_arm</span> <span class=\"o\">=</span> <span class=\"n\">ucb_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">ucb_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">reward</span><span class=\"p\">(</span><span class=\"n\">my_arm</span><span class=\"p\">)</span>\n</pre>\n<h3>UCB-Tuned (Upper Confidence Bound Tuned)</h3>\n<p>A strict improvement over both UCB solutions can be made by tuning the upper-bound parameter in UCB1\u2019s decision rule. UCB-Tuned empirically outperforms UCB1 and UCB2 in terms of frequency\nof picking the best arm. Further, indicate that UCB-Tuned is \u201cnot very\u201d sensitive to the variance of the arms.</p>\n<h4>Get a selected arm</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms.</span>\n<span class=\"n\">ucbt_with_two_arms</span> <span class=\"o\">=</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">UCBTuned</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">ucbt_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span>\n</pre>\n<h4>Reward an arm</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms.</span>\n<span class=\"n\">ucbt_with_two_arms</span> <span class=\"o\">=</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">UCBTuned</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">my_arm</span> <span class=\"o\">=</span> <span class=\"n\">ucbt_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">ucbt_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">reward</span><span class=\"p\">(</span><span class=\"n\">my_arm</span><span class=\"p\">)</span>\n</pre>\n<h3>Thompson Sampling</h3>\n<p>Thompson Sampling is fully Bayesian: it generates a bandit configuration (i.e. a vector of expected rewards) from a posterior distribution, and then acts as if this was the true configuration (i.e. it pulls the lever with the highest expected reward).</p>\n<p>\u201cOn the likelihood that one unknown probability exceeds another\nin view of the evidence of two samples\u201d produced the first paper on an equivalent problem to the multi-armed bandit in which a solution to the Bernoulli\ndistribution bandit problem now referred to as Thompson sampling is presented.</p>\n<h4>Get a selected arm</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms.</span>\n<span class=\"n\">thomp_with_two_arms</span> <span class=\"o\">=</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">ThompsomSampling</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">thomp_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span>\n</pre>\n<h4>Reward an arm</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms.</span>\n<span class=\"n\">thomp_with_two_arms</span> <span class=\"o\">=</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">ThompsomSampling</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">my_arm</span> <span class=\"o\">=</span> <span class=\"n\">thomp_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">thomp_with_two_arms</span><span class=\"o\">.</span><span class=\"n\">reward</span><span class=\"p\">(</span><span class=\"n\">my_arm</span><span class=\"p\">)</span>\n</pre>\n<h2>Comparison of the algorithms using Monte Carlo Simulation</h2>\n<p>Monte Carlo simulation is the best way to debug / test MAB algorithms. This simulation generates data in real time\nrespecting a probability of delivery (chosen by the executor of the simulation) over time.\nThese probabilities may represent the taste of most users regarding a MAB arm (option) over time, for example.</p>\n<p>Example: We want to test a 5-arm MAB that will be used in an ad problem, and MAB must choose which of the 5 ads must\nreceive the most clicks from users. You can use the following probability setting ([0.9, 0.1, 0.1, 0.1, 0.1]) for this.\nEach array element represents an arm and its probability of being clicked.\nWe can observe that Ad 0 (index 0 of array) has 90% chance of clicks while others have 10% chances of clicks.\nThese information can help us to analyze if the algorithm is performing well.</p>\n<p>A simulation with the following settings was made:</p>\n<pre><code>{0: [0.9, 0.6, 0.2, 0.2, 0.1], 1000: [0.3, 0.8, 0.2, 0.2, 0.2], 4000: [0.7, 0.3, 0.2, 0.2, 0.1]}\n</code></pre>\n<p>The key of the dictionary tells us the time which the probabilities must be activated in the passing time.\nThe total time of the simulation was 5000 steps and each point of the chart is an average of 1000 simulations with 5000 steps each.</p>\n<p>From this dictionary we can infer that:</p>\n<ul>\n<li>From time 0 to 1000, arm 0 is the winner.</li>\n<li>From time 1000 to 4000, arm 1 is the winner</li>\n<li>From time 4000, arm 0 is the winner.</li>\n</ul>\n<p>You can check a full example of this simulation at this <a href=\"./Monte_Carlo_Simulation_Example.ipynb\" rel=\"nofollow\">notebook.</a></p>\n<h3>Results:</h3>\n<p><img alt=\"UCB1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/22e515952daf49247985962509a31ae0c003319f/2e2f726561646d652d696d616765732f756362312e706e67\"></p>\n<p><img alt=\"UCB-Tuned\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4d485348a06b6d2c4607f076f7d784ca25ae8b3c/2e2f726561646d652d696d616765732f756362742e706e67\"></p>\n<p><img alt=\"Thompsom Sampling\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a74d353055a16742920c223467c9a75c1f3fa228/2e2f726561646d652d696d616765732f7468732e706e67\"></p>\n<p><img alt=\"Cumulative Rewards\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b8fed9fb4248aa46c52f4c327503c6e8d8079a95/2e2f726561646d652d696d616765732f726577617264732e706e67\"></p>\n<p>Remembering that all these analyzes were performed in a simulation environment and the results may vary according\nto the type of information the MAB will perform on. For a more sensible choice with real world data, please perform\nan AB test between the algorithms in your scenario.</p>\n<hr>\n<h1>Ranked Multi-Armed Bandit Algorithms</h1>\n<h3>RBA (Ranked Bandit Algorithm)</h3>\n<p>This is an online learning algorithm which can be used to the ranking problem. In this algorithm we have a certain quantity of\narms to be shown in a certain quantity of a ranked slots (like a netflix film list). Each arm is best in some of the ranking position and\nthis algorithm uses MAB instances to do that.</p>\n<h4>Get selected arms in their ranked positions</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span><span class=\"p\">,</span> <span class=\"n\">ranked_algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms, number of ranks and a MAB algorithm reference.</span>\n<span class=\"n\">rba_algorithm</span> <span class=\"o\">=</span> <span class=\"n\">ranked_algs</span><span class=\"o\">.</span><span class=\"n\">RBA</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">ThompsomSampling</span><span class=\"p\">)</span> <span class=\"c1\"># Any MAB from algs can be used.</span>\n<span class=\"n\">ranked_selected_arms</span> <span class=\"o\">=</span> <span class=\"n\">rba_algorithm</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span> <span class=\"c1\"># Best arms in its best position.</span>\n</pre>\n<h4>Reward an arm in a certain position of the rank</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span><span class=\"p\">,</span> <span class=\"n\">ranked_algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms, number of ranks and a MAB algorithm reference.</span>\n<span class=\"n\">rba_algorithm</span> <span class=\"o\">=</span> <span class=\"n\">ranked_algs</span><span class=\"o\">.</span><span class=\"n\">RBA</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">ThompsomSampling</span><span class=\"p\">)</span> <span class=\"c1\"># Any MAB from algs can be used.</span>\n<span class=\"n\">ranked_selected_arms</span> <span class=\"o\">=</span> <span class=\"n\">rba_algorithm</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span> <span class=\"c1\"># Best arms in its best position.</span>\n<span class=\"n\">rba_algorithm</span><span class=\"o\">.</span><span class=\"n\">reward</span><span class=\"p\">(</span><span class=\"n\">ranked_selected_arms</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"c1\"># Reward the arm 2 in its position of the rank.</span>\n</pre>\n<h3>RBA-M (Ranked Bandit Algorithm - Modified)</h3>\n<p>It's the same thing of the RBA, but with a modification in the arm collisions approach.\nThis new collision approach was made by me and my team partner <a href=\"https://github.com/fabiosvb\" rel=\"nofollow\">F\u00e1bio</a>. For more details about this approach, please see code documentation.</p>\n<h4>Get selected arms in their ranked positions</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span><span class=\"p\">,</span> <span class=\"n\">ranked_algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms, number of ranks and a MAB algorithm reference.</span>\n<span class=\"n\">rbam_algorithm</span> <span class=\"o\">=</span> <span class=\"n\">ranked_algs</span><span class=\"o\">.</span><span class=\"n\">RBAM</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">ThompsomSampling</span><span class=\"p\">)</span> <span class=\"c1\"># Any MAB from algs can be used.</span>\n<span class=\"n\">ranked_selected_arms</span> <span class=\"o\">=</span> <span class=\"n\">rbam_algorithm</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span> <span class=\"c1\"># Best arms in its best position.</span>\n</pre>\n<h4>Reward an arm in a certain position of the rank</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">mab</span> <span class=\"kn\">import</span> <span class=\"n\">algs</span><span class=\"p\">,</span> <span class=\"n\">ranked_algs</span>\n\n<span class=\"c1\"># Constructor receives number of arms, number of ranks and a MAB algorithm reference.</span>\n<span class=\"n\">rbam_algorithm</span> <span class=\"o\">=</span> <span class=\"n\">ranked_algs</span><span class=\"o\">.</span><span class=\"n\">RBAM</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">algs</span><span class=\"o\">.</span><span class=\"n\">ThompsomSampling</span><span class=\"p\">)</span> <span class=\"c1\"># Any MAB from algs can be used.</span>\n<span class=\"n\">ranked_selected_arms</span> <span class=\"o\">=</span> <span class=\"n\">rbam_algorithm</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">()</span>  <span class=\"c1\"># Best arms in its best position.</span>\n<span class=\"n\">rbam_algorithm</span><span class=\"o\">.</span><span class=\"n\">reward</span><span class=\"p\">(</span><span class=\"n\">ranked_selected_arms</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span> <span class=\"c1\"># Reward the arm 2 in its position of the rank.</span>\n</pre>\n<h2>Behavior of the RBA-M algorithm using Monte Carlo Simulation</h2>\n<p>Like before, we will make a Monte Carlo experimentation using RBA-M Algorithm to show its behavior.</p>\n<p>Example: We want to test a 5-arm and 4-rank MAB that will be used in a movie slot recomendation problem,\nand MAB must choose which of the 4 movies banners must receive the most clicks from users in each slot position.</p>\n<p>A simulation with the following settings was made:</p>\n<pre><code>{\n    0: [[0.1, 0.1, 0.1, 0.9, 0.1],\n        [0.1, 0.1, 0.9, 0.1, 0.1], \n        [0.1, 0.9, 0.1, 0.1, 0.1], \n        [0.9, 0.1, 0.1, 0.1, 0.1], \n        [0.25, 0.25, 0.25, 0.25]], # Rank position click probability.\n                        \n    1500: [[0.9, 0.1, 0.1, 0.1, 0.1], \n           [0.1, 0.9, 0.1, 0.1, 0.1], \n           [0.1, 0.1, 0.9, 0.1, 0.1], \n           [0.1, 0.1, 0.1, 0.9, 0.1], \n           [0.25, 0.25, 0.25, 0.25]] # Rank position click probability.\n           \n} \n</code></pre>\n<p>In this simulation we have something different. Now, at a given time we need to set the probability of all available arms in each position of the rank, and\nthe last array is the rank position click probability (velocity of convergence at given ranking position).</p>\n<p>The total time of the simulation was 3000 steps and each point of the chart is an average of 1000 simulations with 3000 steps each.</p>\n<p>From this dictionary we can infer that:</p>\n<ul>\n<li>From time 0 to 1500, arm 3 is the winner at rank 0, arm 2 is the winner at rank 1, arm 1 is the winner at rank 2 and arm 0 is the winner at rank 3.</li>\n<li>From time 1500 to 3000, arm 0 is the winner at rank 0, arm 1 is the winner at rank 1, arm 2 is the winner at rank 2 and arm 3 is the winner at rank 3.</li>\n<li>The Rank position click probability is the same to all to give a better understanding of their behaviors.</li>\n</ul>\n<p>You can check a full example of this simulation at this <a href=\"./Monte_Carlo_RBAM.ipynb\" rel=\"nofollow\">notebook.</a></p>\n<h3>Results:</h3>\n<p><img alt=\"UCB1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9979b00744988bd32ed3d578a32a89f6aa7f3084/2e2f726561646d652d696d616765732f72616e6b65642f756362315f72616e6b65642e706e67\"></p>\n<p><img alt=\"UCB-Tuned\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/592277228dc2eb4930d167545096fef8a02fe876/2e2f726561646d652d696d616765732f72616e6b65642f756362745f72616e6b65642e706e67\"></p>\n<p><img alt=\"Thompsom Sampling\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/32da75cd143a06c8fa996a129612fd32c54031e0/2e2f726561646d652d696d616765732f72616e6b65642f7468735f72616e6b65642e706e67\"></p>\n<p><img alt=\"Cumulative Rewards\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/db2f20f0159ab8e7a7146c4a9c5c2852993342e3/2e2f726561646d652d696d616765732f72616e6b65642f726577617264735f72616e6b65642e706e67\"></p>\n<p>Remembering that all these analyzes were performed in a simulation environment and the results may vary according\nto the type of information the RMAB will perform on. For a more sensible choice with real world data, please perform\nan AB test between the algorithms in your scenario.</p>\n<h3>RBA vs RBA-M</h3>\n<p>If you want to see the behavior of the RBA algorithm, you can execute it using this <a href=\"./Monte_Carlo_RBAM.ipynb\" rel=\"nofollow\">notebook.</a> It's just change the 'rbam' to 'rba' in the run method. The behavior between they is the same, just in the 'same weight' case for arms in same positions is that RBA-M performs better.</p>\n<hr>\n<h2>Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/alison-carrera\" rel=\"nofollow\">Alison de Andrade Carrera</a></li>\n<li><a href=\"https://github.com/fabiosvb\" rel=\"nofollow\">F\u00e1bio Silva Vilas Boas</a></li>\n<li><a href=\"https://github.com/danielcoaraujo\" rel=\"nofollow\">Daniel Ara\u00fajo</a></li>\n</ul>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Multi-armed_bandit\" rel=\"nofollow\">Wikipedia MAB</a></li>\n<li><a href=\"https://arxiv.org/pdf/1510.00757.pdf\" rel=\"nofollow\">A Survey of Online Experiment Design\nwith the Stochastic Multi-Armed Bandit</a></li>\n<li><a href=\"https://link.springer.com/article/10.1023%2FA%3A1013689704352?LI=true\" rel=\"nofollow\">Finite-time Analysis of the Multiarmed Bandit Problem</a></li>\n<li><a href=\"https://towardsdatascience.com/solving-multiarmed-bandits-a-comparison-of-epsilon-greedy-and-thompson-sampling-d97167ca9a50\" rel=\"nofollow\">Solving multiarmed bandits: A comparison of epsilon-greedy and Thompson sampling</a></li>\n<li><a href=\"https://dl.acm.org/citation.cfm?id=1390255\" rel=\"nofollow\">Learning Diverse Rankings with Multi-Armed Bandits</a></li>\n</ul>\n\n          </div>"}, "last_serial": 5574206, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "14519e3efc85c90ed43bc2b80a5156c0", "sha256": "f85ad737ada26d2c1914811e5589dc3f17ae68b946415df27c192ae19c076385"}, "downloads": -1, "filename": "mabalgs-0.1.tar.gz", "has_sig": false, "md5_digest": "14519e3efc85c90ed43bc2b80a5156c0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1154, "upload_time": "2019-01-24T17:39:09", "upload_time_iso_8601": "2019-01-24T17:39:09.569626Z", "url": "https://files.pythonhosted.org/packages/16/96/16780715bde8dc37c49f4b644ede988101ad6bfa395bccce268043600676/mabalgs-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "dd14f35d705bda5f57aca97cd7b4b212", "sha256": "329882ff9d42e3414305eec7a877b92585b0df70d9a0adb9e752077a44b8dd9f"}, "downloads": -1, "filename": "mabalgs-0.1.1.tar.gz", "has_sig": false, "md5_digest": "dd14f35d705bda5f57aca97cd7b4b212", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1202, "upload_time": "2019-01-24T17:46:29", "upload_time_iso_8601": "2019-01-24T17:46:29.041062Z", "url": "https://files.pythonhosted.org/packages/d6/f8/b2c9ce46f8f290ff90aa0e29112c2cebd4131ad5783aa838a7ba6e66264a/mabalgs-0.1.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "4cdff41b26345841d9ca1a3e7a2b7c3c", "sha256": "d1850e625079b0358f15d4706cceca495d0657bfec7586be20be1d448f088485"}, "downloads": -1, "filename": "mabalgs-0.2.tar.gz", "has_sig": false, "md5_digest": "4cdff41b26345841d9ca1a3e7a2b7c3c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1194, "upload_time": "2019-01-24T18:06:57", "upload_time_iso_8601": "2019-01-24T18:06:57.347827Z", "url": "https://files.pythonhosted.org/packages/3c/dc/6b36a74d949fbfb17889c0e812f62584ad7aaaaeb270726548497bb09cb7/mabalgs-0.2.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "31dfabd62f5837c28b43d9095fe278d8", "sha256": "b290b5730f18662a82681ba2cf11afdf1f3b917cd8d0fd79f1a439bebbbed946"}, "downloads": -1, "filename": "mabalgs-0.3.tar.gz", "has_sig": false, "md5_digest": "31dfabd62f5837c28b43d9095fe278d8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1499, "upload_time": "2019-01-24T22:55:01", "upload_time_iso_8601": "2019-01-24T22:55:01.069136Z", "url": "https://files.pythonhosted.org/packages/40/41/8cc0881b34c93469f570884b9b7595b2ca11db948c1e931710026662a3f0/mabalgs-0.3.tar.gz", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "08891194778970310859d480246b5864", "sha256": "1834e7820e382f714fa21a612d9a1078fe8586880110f7917e2f9975d0494378"}, "downloads": -1, "filename": "mabalgs-0.4.tar.gz", "has_sig": false, "md5_digest": "08891194778970310859d480246b5864", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2685, "upload_time": "2019-01-25T13:43:04", "upload_time_iso_8601": "2019-01-25T13:43:04.549849Z", "url": "https://files.pythonhosted.org/packages/00/91/8b3246821ca5f1c4a898fc15ccedba12312f2ee69f6a2b452ba43633d166/mabalgs-0.4.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "7e80cd75c75bee3e977fbb17c18b5f58", "sha256": "9f8f7de6908bf58818c464ffaf071a39f2f58f145780b0c66f90941a33c2579e"}, "downloads": -1, "filename": "mabalgs-0.4.1.tar.gz", "has_sig": false, "md5_digest": "7e80cd75c75bee3e977fbb17c18b5f58", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2958, "upload_time": "2019-01-25T13:44:56", "upload_time_iso_8601": "2019-01-25T13:44:56.009506Z", "url": "https://files.pythonhosted.org/packages/50/c3/ef630a9830b51cb50d294d58e54a0af213961c2451d86c4e3b216049630c/mabalgs-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "aedbd20a4ce97fd5612e9e9d60666480", "sha256": "a392d6226810e1c92891ac9aceac693cae977a96f8dee48a615d1b3874e6d38e"}, "downloads": -1, "filename": "mabalgs-0.4.2.tar.gz", "has_sig": false, "md5_digest": "aedbd20a4ce97fd5612e9e9d60666480", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2959, "upload_time": "2019-01-25T13:49:47", "upload_time_iso_8601": "2019-01-25T13:49:47.053065Z", "url": "https://files.pythonhosted.org/packages/89/36/f2dc73d0a4f8688b7541629907fe867ff905d36e7d4b4709c02deb20ed21/mabalgs-0.4.2.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "31c6bb62ece68589e16e0198e7d5a4c8", "sha256": "2ece958f528a3d4519ce3d070d339f4e0260f5630461881ac02e55e639a8f340"}, "downloads": -1, "filename": "mabalgs-0.4.3-py3-none-any.whl", "has_sig": false, "md5_digest": "31c6bb62ece68589e16e0198e7d5a4c8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7615, "upload_time": "2019-01-25T13:57:56", "upload_time_iso_8601": "2019-01-25T13:57:56.056945Z", "url": "https://files.pythonhosted.org/packages/65/77/e6314659db8b43b10d6982a89ba27eb9a237a51c9a472722a62ab37738b7/mabalgs-0.4.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8a613be0b276c49d02de00a9177907fa", "sha256": "1497879b28491a01fcc0cae1c807d33b8359be692b72464a336d950193490454"}, "downloads": -1, "filename": "mabalgs-0.4.3.tar.gz", "has_sig": false, "md5_digest": "8a613be0b276c49d02de00a9177907fa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2957, "upload_time": "2019-01-25T13:58:59", "upload_time_iso_8601": "2019-01-25T13:58:59.676271Z", "url": "https://files.pythonhosted.org/packages/96/25/3f84edf4b0820b04f94de64d5ea155f34a423b27df56cb032ba6e7d0aab6/mabalgs-0.4.3.tar.gz", "yanked": false}], "0.4.4": [{"comment_text": "", "digests": {"md5": "3e2fdc49685a5db66d40bf986f62f770", "sha256": "ed81c4a9653bb3be70f707203c40cdfd0ba808af8b62ee52af91d7d3bb34fb89"}, "downloads": -1, "filename": "mabalgs-0.4.4.tar.gz", "has_sig": false, "md5_digest": "3e2fdc49685a5db66d40bf986f62f770", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3818, "upload_time": "2019-01-25T21:41:14", "upload_time_iso_8601": "2019-01-25T21:41:14.465136Z", "url": "https://files.pythonhosted.org/packages/ca/7a/143e97d9d41ca35217e7baa75302d86222942d112a2d9c0242f9c2a2f52b/mabalgs-0.4.4.tar.gz", "yanked": false}], "0.4.5": [{"comment_text": "", "digests": {"md5": "70920da1b4244f99d2138c968d8767cb", "sha256": "a06b28e6b9e1dc5f7ab95911055546ccecd027c1f7107ad357058b2d8927c672"}, "downloads": -1, "filename": "mabalgs-0.4.5.tar.gz", "has_sig": false, "md5_digest": "70920da1b4244f99d2138c968d8767cb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3828, "upload_time": "2019-01-25T21:47:21", "upload_time_iso_8601": "2019-01-25T21:47:21.801984Z", "url": "https://files.pythonhosted.org/packages/c9/3a/b15b6851b76a2bc1860e78869eb25622144ee933771c0a551c46abf19f10/mabalgs-0.4.5.tar.gz", "yanked": false}], "0.4.6": [{"comment_text": "", "digests": {"md5": "bfc527cb5c66ddfa8f840d6b8c44578c", "sha256": "2cb519ce124a88639387fd4c7a2a62cea3a57c9fec71e112f9435a2b711409dd"}, "downloads": -1, "filename": "mabalgs-0.4.6.tar.gz", "has_sig": false, "md5_digest": "bfc527cb5c66ddfa8f840d6b8c44578c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5080, "upload_time": "2019-01-26T03:23:40", "upload_time_iso_8601": "2019-01-26T03:23:40.235428Z", "url": "https://files.pythonhosted.org/packages/1f/5c/8c909c34a98ae33b4a870ab53b715053291e4e8119b221772f6560b352b3/mabalgs-0.4.6.tar.gz", "yanked": false}], "0.4.7": [{"comment_text": "", "digests": {"md5": "ccaa4bc5edf584843b2be3d658d799f3", "sha256": "d3239a12b3dc0af16fdbe5ee7f427c5d80d2232456b51b5946f91a04816b1567"}, "downloads": -1, "filename": "mabalgs-0.4.7.tar.gz", "has_sig": false, "md5_digest": "ccaa4bc5edf584843b2be3d658d799f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5108, "upload_time": "2019-01-26T03:35:14", "upload_time_iso_8601": "2019-01-26T03:35:14.882271Z", "url": "https://files.pythonhosted.org/packages/a3/93/e7d380ac301b64af672fcb27b1d338c8fb095ed3ffafc5a576698baf310e/mabalgs-0.4.7.tar.gz", "yanked": false}], "0.4.8": [{"comment_text": "", "digests": {"md5": "f20581a8ea4966dc29b69399eded6b5a", "sha256": "092284807fde80e6ee64bc3b0f54caab6621b1875a8c5c0bbdec47e17c32b13d"}, "downloads": -1, "filename": "mabalgs-0.4.8.tar.gz", "has_sig": false, "md5_digest": "f20581a8ea4966dc29b69399eded6b5a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5874, "upload_time": "2019-01-28T14:31:47", "upload_time_iso_8601": "2019-01-28T14:31:47.796789Z", "url": "https://files.pythonhosted.org/packages/c1/14/6f79efac3581f3f6867b2206c2b4b1260dcb3f5973377d72f7b19be289cc/mabalgs-0.4.8.tar.gz", "yanked": false}], "0.4.9": [{"comment_text": "", "digests": {"md5": "3b17dc714bb80964e909cc228c1524e5", "sha256": "ff7c8622675441722971f018addb01a9f561ebc04f63fa396886bf1fa60e2fd4"}, "downloads": -1, "filename": "mabalgs-0.4.9.tar.gz", "has_sig": false, "md5_digest": "3b17dc714bb80964e909cc228c1524e5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5858, "upload_time": "2019-01-28T15:33:04", "upload_time_iso_8601": "2019-01-28T15:33:04.659137Z", "url": "https://files.pythonhosted.org/packages/22/33/378bf1c9284e8648260b46484d7cb4301794835be99f2775701f7974e71c/mabalgs-0.4.9.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "4a8f4b66872ebf2a8586d1e9dfd0059e", "sha256": "8b7345da2e49d558f36ca5629a0f0d7581455d3b876988fd50c80126b62a2d7b"}, "downloads": -1, "filename": "mabalgs-0.5.0.tar.gz", "has_sig": false, "md5_digest": "4a8f4b66872ebf2a8586d1e9dfd0059e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5869, "upload_time": "2019-01-28T15:49:52", "upload_time_iso_8601": "2019-01-28T15:49:52.397558Z", "url": "https://files.pythonhosted.org/packages/ea/d4/7fd2ca738343f070e57cce35652ce748d5d6154e72a0feb65f0016a5d63d/mabalgs-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "8f4ce10c92eb3c451193f6ed6a5bb102", "sha256": "b230dd1e0e23759759564c9b584c65b8b8fa567ca9289857027f81dd91010288"}, "downloads": -1, "filename": "mabalgs-0.5.1.tar.gz", "has_sig": false, "md5_digest": "8f4ce10c92eb3c451193f6ed6a5bb102", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5870, "upload_time": "2019-01-28T15:53:54", "upload_time_iso_8601": "2019-01-28T15:53:54.724831Z", "url": "https://files.pythonhosted.org/packages/9f/1d/f1d73c3c8c970bbae35d342b98801a0bd59072a3affe7179e697545aeee1/mabalgs-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "a1208a2b0846eb106cd1c1ee3269eb72", "sha256": "a8b7cec62866bfbfb93e3b6e84d817ae8eb278657d9c028e7db075e25f5b7c0a"}, "downloads": -1, "filename": "mabalgs-0.5.2.tar.gz", "has_sig": false, "md5_digest": "a1208a2b0846eb106cd1c1ee3269eb72", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5931, "upload_time": "2019-01-28T16:35:35", "upload_time_iso_8601": "2019-01-28T16:35:35.424149Z", "url": "https://files.pythonhosted.org/packages/7b/d9/968aa1b26014e019c4498982afbe3ce58d7e7328052c8e505f836e7bb7a1/mabalgs-0.5.2.tar.gz", "yanked": false}], "0.5.3": [{"comment_text": "", "digests": {"md5": "5ef07b2b898ffae8ae2201c368d8f230", "sha256": "c0843a3f9f733f885230ac68f607406b788d6b72151c9834fc3ab87ea989e444"}, "downloads": -1, "filename": "mabalgs-0.5.3.tar.gz", "has_sig": false, "md5_digest": "5ef07b2b898ffae8ae2201c368d8f230", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6151, "upload_time": "2019-01-31T03:13:13", "upload_time_iso_8601": "2019-01-31T03:13:13.979921Z", "url": "https://files.pythonhosted.org/packages/5e/a6/6503b555dca62a59f08d158b4e974961cb85bc190002aa5524057c8ed1c2/mabalgs-0.5.3.tar.gz", "yanked": false}], "0.5.4": [{"comment_text": "", "digests": {"md5": "1bcff6a7fc3fe04dc91ef400dc76fed0", "sha256": "b370e49645b7a2f5a2ee001120335b2752f800029dcaeb51fe79bd3b7c7cfb78"}, "downloads": -1, "filename": "mabalgs-0.5.4.tar.gz", "has_sig": false, "md5_digest": "1bcff6a7fc3fe04dc91ef400dc76fed0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6150, "upload_time": "2019-01-31T03:15:42", "upload_time_iso_8601": "2019-01-31T03:15:42.007685Z", "url": "https://files.pythonhosted.org/packages/b8/4a/6b3753fc37c864e87012d0b975cb387ce76257f8ff08aa8d0dac3a17f2a1/mabalgs-0.5.4.tar.gz", "yanked": false}], "0.5.5": [{"comment_text": "", "digests": {"md5": "d6a79ce834886e44e27cf3d1e2412d21", "sha256": "d1aef276f47557afff496c39c5229bfa5512690f4a5588e86aac89797c4368a2"}, "downloads": -1, "filename": "mabalgs-0.5.5.tar.gz", "has_sig": false, "md5_digest": "d6a79ce834886e44e27cf3d1e2412d21", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6156, "upload_time": "2019-01-31T03:24:54", "upload_time_iso_8601": "2019-01-31T03:24:54.375794Z", "url": "https://files.pythonhosted.org/packages/2f/ae/1d92b5e40652b6751d276ef1309f8eba7833b80ae5a1dfb9df356ae5e34c/mabalgs-0.5.5.tar.gz", "yanked": false}], "0.5.6": [{"comment_text": "", "digests": {"md5": "4791c0b51ded5bb1c88d50d56390e696", "sha256": "dcbb0d94938d64810b9209ca47d4a13b0faba4c5cdbe673a08285a32243d4815"}, "downloads": -1, "filename": "mabalgs-0.5.6.tar.gz", "has_sig": false, "md5_digest": "4791c0b51ded5bb1c88d50d56390e696", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6150, "upload_time": "2019-01-31T03:26:48", "upload_time_iso_8601": "2019-01-31T03:26:48.367277Z", "url": "https://files.pythonhosted.org/packages/10/21/db7200683c477eb5b8c2c9f03f6003e3ee1c661200545c433d37285cc235/mabalgs-0.5.6.tar.gz", "yanked": false}], "0.5.7": [{"comment_text": "", "digests": {"md5": "a57fd21bcd30e6df6396903f4bd8b686", "sha256": "9e02cdd04e6d9584fa9c1c5747d6722f098d58e392caae17dbf106a004e815ca"}, "downloads": -1, "filename": "mabalgs-0.5.7.tar.gz", "has_sig": false, "md5_digest": "a57fd21bcd30e6df6396903f4bd8b686", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7711, "upload_time": "2019-02-01T16:40:12", "upload_time_iso_8601": "2019-02-01T16:40:12.542379Z", "url": "https://files.pythonhosted.org/packages/54/b4/33f15cee434a58613139484cb0719c1baccd445ca16fd207196501db0b44/mabalgs-0.5.7.tar.gz", "yanked": false}], "0.5.8": [{"comment_text": "", "digests": {"md5": "17dd1af178b88f13714d6b601cc6d8c0", "sha256": "442a1b5f08c43838731c2d4b1bd3e4d672e1c6f3b643c3e832998083fec9a656"}, "downloads": -1, "filename": "mabalgs-0.5.8.tar.gz", "has_sig": false, "md5_digest": "17dd1af178b88f13714d6b601cc6d8c0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12264, "upload_time": "2019-02-25T02:32:11", "upload_time_iso_8601": "2019-02-25T02:32:11.169373Z", "url": "https://files.pythonhosted.org/packages/ee/df/19b8dc362b11e53a940431d334f3d561da1e19c0acdafce2fbcc8c57feae/mabalgs-0.5.8.tar.gz", "yanked": false}], "0.5.9": [{"comment_text": "", "digests": {"md5": "4420149a805dae54880347a5e1266ff0", "sha256": "ee07e744b0c6e773195a2b9daa52a91ba9c1d53a6d796c0361d3f61a784050dc"}, "downloads": -1, "filename": "mabalgs-0.5.9.tar.gz", "has_sig": false, "md5_digest": "4420149a805dae54880347a5e1266ff0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12260, "upload_time": "2019-02-25T02:44:43", "upload_time_iso_8601": "2019-02-25T02:44:43.892168Z", "url": "https://files.pythonhosted.org/packages/5e/2d/13e3f7de1eb7bf65fcdac795c6a59c8674abe9e0c72ff4d4c6b6f65468d6/mabalgs-0.5.9.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "4f749b7a54a2721c46d3ab34e84b1b8e", "sha256": "dd270f62d1a3573cc695daba9e16b93ec7a3c97e84499d9db37bd7d2cf89fb1c"}, "downloads": -1, "filename": "mabalgs-0.6.0.tar.gz", "has_sig": false, "md5_digest": "4f749b7a54a2721c46d3ab34e84b1b8e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9117, "upload_time": "2019-07-23T02:22:33", "upload_time_iso_8601": "2019-07-23T02:22:33.812852Z", "url": "https://files.pythonhosted.org/packages/b1/d7/73b5ba424f328d173f83c02eebf20f6e3d239e93c6f25e9b979e8c0acb78/mabalgs-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "8e973c48debdfd8900a57f45d27290c2", "sha256": "99b518190407d6c19c079224359be296a316eda7b4c35751e4c0626338d899ab"}, "downloads": -1, "filename": "mabalgs-0.6.1.tar.gz", "has_sig": false, "md5_digest": "8e973c48debdfd8900a57f45d27290c2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9068, "upload_time": "2019-07-23T02:27:41", "upload_time_iso_8601": "2019-07-23T02:27:41.714996Z", "url": "https://files.pythonhosted.org/packages/f7/d5/b0c95c499116dfe51fa53db12a479157b618220520a4d1a942c0eb328de9/mabalgs-0.6.1.tar.gz", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "609f954fbea6bd7de0d404e5503a8dfc", "sha256": "79582f089b0e19d0da8ec07427c9618c2d8b6f712125d4736115949d4bbebcfa"}, "downloads": -1, "filename": "mabalgs-0.6.2.tar.gz", "has_sig": false, "md5_digest": "609f954fbea6bd7de0d404e5503a8dfc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9193, "upload_time": "2019-07-23T03:02:50", "upload_time_iso_8601": "2019-07-23T03:02:50.505251Z", "url": "https://files.pythonhosted.org/packages/8c/a3/12c0f8d7887934e0e37267c154b4218b8a94dfe094fed10c687406cca3e5/mabalgs-0.6.2.tar.gz", "yanked": false}], "0.6.3": [{"comment_text": "", "digests": {"md5": "057f2501895251d380e94ef26f02ee00", "sha256": "5972d5c8c338655503a86947f461a67eccc7bcb39840e68099685e2a89c7a1e0"}, "downloads": -1, "filename": "mabalgs-0.6.3.tar.gz", "has_sig": false, "md5_digest": "057f2501895251d380e94ef26f02ee00", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9058, "upload_time": "2019-07-23T18:43:26", "upload_time_iso_8601": "2019-07-23T18:43:26.202088Z", "url": "https://files.pythonhosted.org/packages/aa/d8/62f3b4721cd66b64a0ff906861b489b4c74b19c997da3f58ed8a6b4fda7e/mabalgs-0.6.3.tar.gz", "yanked": false}], "0.6.4": [{"comment_text": "", "digests": {"md5": "a367e822fa844c0d0b4319a0b6c161c8", "sha256": "af490d9322669f66036f26c09b2dff7594a748465c42f52e691ddbb9c01aebc4"}, "downloads": -1, "filename": "mabalgs-0.6.4.tar.gz", "has_sig": false, "md5_digest": "a367e822fa844c0d0b4319a0b6c161c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8931, "upload_time": "2019-07-23T19:59:10", "upload_time_iso_8601": "2019-07-23T19:59:10.553573Z", "url": "https://files.pythonhosted.org/packages/ca/d5/f2af7845435f784c32c7f4f5c27e34f1a949dbf919e35ad64c3fcf07d20f/mabalgs-0.6.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a367e822fa844c0d0b4319a0b6c161c8", "sha256": "af490d9322669f66036f26c09b2dff7594a748465c42f52e691ddbb9c01aebc4"}, "downloads": -1, "filename": "mabalgs-0.6.4.tar.gz", "has_sig": false, "md5_digest": "a367e822fa844c0d0b4319a0b6c161c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8931, "upload_time": "2019-07-23T19:59:10", "upload_time_iso_8601": "2019-07-23T19:59:10.553573Z", "url": "https://files.pythonhosted.org/packages/ca/d5/f2af7845435f784c32c7f4f5c27e34f1a949dbf919e35ad64c3fcf07d20f/mabalgs-0.6.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:42:26 2020"}