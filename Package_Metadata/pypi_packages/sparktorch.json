{"info": {"author": "Derek Miller", "author_email": "dmmiller612@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# SparkTorch\n\n[![Build Status](https://travis-ci.com/dmmiller612/sparktorch.svg?branch=master)](https://travis-ci.org/dmmiller612/sparktorch)\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://github.com/dmmiller612/sparktorch)\n\nThis is an implementation of Pytorch on Apache Spark. The goal of this library is to provide a simple, understandable interface \nin distributing the training of your Pytorch model on Spark. With SparkTorch, you can easily integrate your deep \nlearning model with a ML Spark Pipeline. Underneath the hood, SparkTorch offers two distributed training approaches \nthrough tree reductions and a parameter server. Through the api, the user can specify the style of training, whether \nthat is distributed synchronous or hogwild.\n\n## Why should I use this?\n\nLike SparkFlow, SparkTorch's main objective is to seamlessly work with Spark's ML Pipelines. This library provides three \ncore components:\n\n* Data parallel distributed training for large datasets. SparkTorch offers distributed synchronous and asynchronous training methodologies. \nThis is useful for training very large datasets that do not fit into a single machine.\n* Full integration with Spark's ML library. This ensures that you can save and load pipelines with your trained model.\n* Inference. With SparkTorch, you can load your existing trained model and run inference on billions of records \nin parallel. \n\nOn top of these features, SparkTorch can utilize barrier execution, ensuring that all executors run concurrently during \ntraining (This is required for synchronous training approaches). \n\n## Install\n\nInstall SparkTorch via pip: `pip install sparktorch`\n\nSparkTorch requires Apache Spark >= 2.4.4, and has only been tested on PyTorch versions >= 1.3.0.\n\n## Full Basic Example\n\n```python\nfrom sparktorch import serialize_torch_obj, SparkTorch\nimport torch\nimport torch.nn as nn\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.pipeline import Pipeline\n\nspark = SparkSession.builder.appName(\"examples\").master('local[2]').getOrCreate()\ndf = spark.read.option(\"inferSchema\", \"true\").csv('mnist_train.csv').coalesce(2)\n\nnetwork = nn.Sequential(\n    nn.Linear(784, 256),\n    nn.ReLU(),\n    nn.Linear(256, 256),\n    nn.ReLU(),\n    nn.Linear(256, 10),\n    nn.Softmax(dim=1)\n)\n\n# Build the pytorch object\ntorch_obj = serialize_torch_obj(\n    model=network,\n    criterion=nn.CrossEntropyLoss(),\n    optimizer=torch.optim.Adam,\n    lr=0.0001\n)\n\n# Setup features\nvector_assembler = VectorAssembler(inputCols=df.columns[1:785], outputCol='features')\n\n# Create a SparkTorch Model with torch distributed. Barrier execution is on by default for this mode.\nspark_model = SparkTorch(\n    inputCol='features',\n    labelCol='_c0',\n    predictionCol='predictions',\n    torchObj=torch_obj,\n    iters=50,\n    verbose=1\n)\n\n# Can be used in a pipeline and saved.\np = Pipeline(stages=[vector_assembler, spark_model]).fit(df)\np.save('simple_dnn')\n```\n\n## Run the Examples\n\nYou can run the examples through docker by issuing the following commands at the root of the repository:\n```bash\nmake docker-build\nmake docker-run-dnn\nmake docker-run-cnn\n```\n\nFor the cnn example, you will need to give your docker container at least 8gb of memory.\n\n## Documentation\n\nThis is a small documentation section on how to SparkTorch. Please look at the examples library for more details.\n\n#### Creating a Torch Object\n\nTo create a Torch object for training, you will need to utilize the `serialize_torch_obj` from SparkTorch. To do so, \nsimply add your network, loss criterion, the optimizer class, and any options as a dictionary to supply to the optimizer \n(such as learning rate). A simple example of this is:\n\n```python\nfrom sparktorch import serialize_torch_obj\n\ntorch_obj = serialize_torch_obj(\n    model=network,\n    criterion=nn.CrossEntropyLoss(),\n    optimizer=torch.optim.Adam,\n    lr=0.0001\n)\n```\n\nWhen training neural networks on Spark, one issue that many face is OOM errors. To avoid this issue on the driver, you \ncan create a torch object that is only initialized on the worker nodes. To create this object, you can set up the \nfollowing:\n\n```python\nfrom sparktorch import serialize_torch_obj_lazy\n\ntorch_obj = serialize_torch_obj_lazy(\n    model=Network,\n    criterion=nn.CrossEntropyLoss,\n    optimizer=torch.optim.Adam,\n    optimizer_params={'lr': 0.001},\n    model_parameters={'some_model_param': 5}\n)\n``` \n\nThe Network in the above example must be a nn.module pytorch class. If you need parameters passed into the constructor, \nyou can use the `model_parameters` parameter. The item will be passed in as **kwargs to the constructor. \n\nNOTE: One thing to remember is that if your network is not a sequential, it will need to be saved in a separate file and\navailable in the python path. An example of this can be found in `simple_cnn.py`.\n\n#### Training Options\n\nThere are two main training options with SparkTorch: `async` and `hogwild`. The async mode utilizes the torch distributed \npackage, ensuring that the networks are in sync through each iteration. This is the most supported version. When using \nthis option, you will need to be aware that barrier execution is enforced, meaning that the parallelism will need to match \nthe partitions. \n\nThe Hogwild approach utilizes a Flask Service underneath the hood. When using Hogwild, it is strongly recommended that you use the \n`useBarrier` option to force barrier execution. Below are a list of parameters to SparkTorch and their meaning.\n\n```\ninputCol: Standard Spark InputCol that must be a Vector.\nlabelCol: Standard Spark Label column. Can be null.\ntorchObj: The TorchObj which is described in the `Creating a Torch Object` section.\niters: Number of iterations to run per partition.\npredictionCol: The standard spark prediction column for the dataframe.\npartitions: Ability to repartition during training.\nacquireLock: Used in Hogwild only. Forces locking on the server.\nverbose: Describes whether you want real time logging\npartitionShuffles: Only used in Hogwild. Will reshuffle data after completing training.\nport: Only used in hogwild. Server port.\nuseBarrier: Only used in hogwild. Describes whether you want barrier execution. (Async mode uses barrier by default)\nuseVectorOut: Boolean to describe if you want the model output to be a vector (Defaults to float).\nearlyStopPatience: If greater than 0, it will enforce early stopping based on validation.\nminiBatch: Minibatch size for training per iteration. (Randomly shuffled)\nvalidationPct: Percentage to use for validation.\nmode: which training mode to use. `synchronous` leverages torch distributed. `hogwild` currently uses the flask service.\ndevice: Supply 'cpu' or 'cuda'\n```\n\n#### Saving and Loading Pipelines\n\nSince saving and loading custom ML Transformers in pure python has not been implemented in PySpark, an extension has been\nadded here to make that possible. In order to save a Pyspark Pipeline with Apache Spark, one will need to use the overwrite function:\n\n```python\np = Pipeline(stages=[va, encoded, spark_model]).fit(df)\np.write().overwrite().save(\"location\")\n```\n\nFor loading, a Pipeline wrapper has been provided in the pipeline_utils file. An example is below:\n\n```python\nfrom sparktorch import PysparkPipelineWrapper\nfrom pyspark.ml.pipeline import PipelineModel\n\np = PysparkPipelineWrapper.unwrap(PipelineModel.load('location'))\n``` \nThen you can perform predictions, etc with:\n\n```python\npredictions = p.transform(df)\n```\n\n#### Getting the Pytorch model from the training session\n\nIf you just want to get the Pytorch model after training, you can execute the following code:\n\n```python\nstm = SparkTorch(\n    inputCol='features',\n    labelCol='label',\n    predictionCol='predictions',\n    torchObj=network_with_params,\n    verbose=1,\n    iters=5\n).fit(data)\n\npy_model = stm.getPytorchModel()\n```\n\n\n#### Using a pretrained Pytorch model for inference\n\nIf you already have a trained Pytorch model, you can attach it your existing pipeline by directly creating a SparkTorchModel. \nThis can be done by running the following:\n\n```python\nfrom sparktorch import create_spark_torch_model\n\nnet = ... # Pretrained Network\n\nspark_torch_model = create_spark_torch_model(\n    net, \n    inputCol='features',\n    predictionCol='predictions'\n)\n```\n\n## Running\n\nOne big thing to remember is to add the `--executor cores 1` option to spark to ensure\neach executor is only training one copy of the network. This will especially be needed for gpu training.\n\n## Contributing\n\nContributions are always welcome. This could be fixing a bug, changing documentation, or adding a new feature. To test \nnew changes against existing tests, we have provided a Docker container which takes in an argument of the python version. \nThis allows the user to check their work before pushing to Github, where travis-ci will run.\n\nFor python 3.6\n```\ndocker build -t local-test --build-arg PYTHON_VERSION=3.6 .\ndocker run --rm local-test:latest bash -i -c \"pytest\"\n```\n\n## Literature and Inspiration\n\n* Distributed training: http://seba1511.net/dist_blog/\n* HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent: https://arxiv.org/pdf/1106.5730.pdf\n* Scaling Distributed Machine Learning with the Parameter Server: https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/dmmiller612/sparktorch/archive/0.1.2.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dmmiller612/sparktorch", "keywords": "pytorch,spark,sparktorch,machine learning,deep learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "sparktorch", "package_url": "https://pypi.org/project/sparktorch/", "platform": "", "project_url": "https://pypi.org/project/sparktorch/", "project_urls": {"Download": "https://github.com/dmmiller612/sparktorch/archive/0.1.2.tar.gz", "Homepage": "https://github.com/dmmiller612/sparktorch"}, "release_url": "https://pypi.org/project/sparktorch/0.1.2/", "requires_dist": null, "requires_python": "", "summary": "Deep learning on Apache Spark with Pytorch", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>SparkTorch</h1>\n<p><a href=\"https://travis-ci.org/dmmiller612/sparktorch\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1e4d847c48310920cff15b75816da87850b15c72/68747470733a2f2f7472617669732d63692e636f6d2f646d6d696c6c65723631322f737061726b746f7263682e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://github.com/dmmiller612/sparktorch\" rel=\"nofollow\"><img alt=\"license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ae646c9f8bcc796bfc74debf7ac2c93ee374c6ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e7376673f6d61784167653d32353932303030\"></a></p>\n<p>This is an implementation of Pytorch on Apache Spark. The goal of this library is to provide a simple, understandable interface\nin distributing the training of your Pytorch model on Spark. With SparkTorch, you can easily integrate your deep\nlearning model with a ML Spark Pipeline. Underneath the hood, SparkTorch offers two distributed training approaches\nthrough tree reductions and a parameter server. Through the api, the user can specify the style of training, whether\nthat is distributed synchronous or hogwild.</p>\n<h2>Why should I use this?</h2>\n<p>Like SparkFlow, SparkTorch's main objective is to seamlessly work with Spark's ML Pipelines. This library provides three\ncore components:</p>\n<ul>\n<li>Data parallel distributed training for large datasets. SparkTorch offers distributed synchronous and asynchronous training methodologies.\nThis is useful for training very large datasets that do not fit into a single machine.</li>\n<li>Full integration with Spark's ML library. This ensures that you can save and load pipelines with your trained model.</li>\n<li>Inference. With SparkTorch, you can load your existing trained model and run inference on billions of records\nin parallel.</li>\n</ul>\n<p>On top of these features, SparkTorch can utilize barrier execution, ensuring that all executors run concurrently during\ntraining (This is required for synchronous training approaches).</p>\n<h2>Install</h2>\n<p>Install SparkTorch via pip: <code>pip install sparktorch</code></p>\n<p>SparkTorch requires Apache Spark &gt;= 2.4.4, and has only been tested on PyTorch versions &gt;= 1.3.0.</p>\n<h2>Full Basic Example</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sparktorch</span> <span class=\"kn\">import</span> <span class=\"n\">serialize_torch_obj</span><span class=\"p\">,</span> <span class=\"n\">SparkTorch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.ml.feature</span> <span class=\"kn\">import</span> <span class=\"n\">VectorAssembler</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.sql</span> <span class=\"kn\">import</span> <span class=\"n\">SparkSession</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.ml.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">Pipeline</span>\n\n<span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">SparkSession</span><span class=\"o\">.</span><span class=\"n\">builder</span><span class=\"o\">.</span><span class=\"n\">appName</span><span class=\"p\">(</span><span class=\"s2\">\"examples\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">master</span><span class=\"p\">(</span><span class=\"s1\">'local[2]'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">getOrCreate</span><span class=\"p\">()</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"o\">.</span><span class=\"n\">option</span><span class=\"p\">(</span><span class=\"s2\">\"inferSchema\"</span><span class=\"p\">,</span> <span class=\"s2\">\"true\"</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">csv</span><span class=\"p\">(</span><span class=\"s1\">'mnist_train.csv'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">coalesce</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"n\">network</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">784</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n    <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Softmax</span><span class=\"p\">(</span><span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Build the pytorch object</span>\n<span class=\"n\">torch_obj</span> <span class=\"o\">=</span> <span class=\"n\">serialize_torch_obj</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">network</span><span class=\"p\">,</span>\n    <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">(),</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">,</span>\n    <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.0001</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Setup features</span>\n<span class=\"n\">vector_assembler</span> <span class=\"o\">=</span> <span class=\"n\">VectorAssembler</span><span class=\"p\">(</span><span class=\"n\">inputCols</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">:</span><span class=\"mi\">785</span><span class=\"p\">],</span> <span class=\"n\">outputCol</span><span class=\"o\">=</span><span class=\"s1\">'features'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Create a SparkTorch Model with torch distributed. Barrier execution is on by default for this mode.</span>\n<span class=\"n\">spark_model</span> <span class=\"o\">=</span> <span class=\"n\">SparkTorch</span><span class=\"p\">(</span>\n    <span class=\"n\">inputCol</span><span class=\"o\">=</span><span class=\"s1\">'features'</span><span class=\"p\">,</span>\n    <span class=\"n\">labelCol</span><span class=\"o\">=</span><span class=\"s1\">'_c0'</span><span class=\"p\">,</span>\n    <span class=\"n\">predictionCol</span><span class=\"o\">=</span><span class=\"s1\">'predictions'</span><span class=\"p\">,</span>\n    <span class=\"n\">torchObj</span><span class=\"o\">=</span><span class=\"n\">torch_obj</span><span class=\"p\">,</span>\n    <span class=\"n\">iters</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span>\n    <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># Can be used in a pipeline and saved.</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">stages</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">vector_assembler</span><span class=\"p\">,</span> <span class=\"n\">spark_model</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n<span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s1\">'simple_dnn'</span><span class=\"p\">)</span>\n</pre>\n<h2>Run the Examples</h2>\n<p>You can run the examples through docker by issuing the following commands at the root of the repository:</p>\n<pre>make docker-build\nmake docker-run-dnn\nmake docker-run-cnn\n</pre>\n<p>For the cnn example, you will need to give your docker container at least 8gb of memory.</p>\n<h2>Documentation</h2>\n<p>This is a small documentation section on how to SparkTorch. Please look at the examples library for more details.</p>\n<h4>Creating a Torch Object</h4>\n<p>To create a Torch object for training, you will need to utilize the <code>serialize_torch_obj</code> from SparkTorch. To do so,\nsimply add your network, loss criterion, the optimizer class, and any options as a dictionary to supply to the optimizer\n(such as learning rate). A simple example of this is:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sparktorch</span> <span class=\"kn\">import</span> <span class=\"n\">serialize_torch_obj</span>\n\n<span class=\"n\">torch_obj</span> <span class=\"o\">=</span> <span class=\"n\">serialize_torch_obj</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">network</span><span class=\"p\">,</span>\n    <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">(),</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">,</span>\n    <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.0001</span>\n<span class=\"p\">)</span>\n</pre>\n<p>When training neural networks on Spark, one issue that many face is OOM errors. To avoid this issue on the driver, you\ncan create a torch object that is only initialized on the worker nodes. To create this object, you can set up the\nfollowing:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sparktorch</span> <span class=\"kn\">import</span> <span class=\"n\">serialize_torch_obj_lazy</span>\n\n<span class=\"n\">torch_obj</span> <span class=\"o\">=</span> <span class=\"n\">serialize_torch_obj_lazy</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">Network</span><span class=\"p\">,</span>\n    <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">,</span>\n    <span class=\"n\">optimizer_params</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'lr'</span><span class=\"p\">:</span> <span class=\"mf\">0.001</span><span class=\"p\">},</span>\n    <span class=\"n\">model_parameters</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'some_model_param'</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">}</span>\n<span class=\"p\">)</span>\n</pre>\n<p>The Network in the above example must be a nn.module pytorch class. If you need parameters passed into the constructor,\nyou can use the <code>model_parameters</code> parameter. The item will be passed in as **kwargs to the constructor.</p>\n<p>NOTE: One thing to remember is that if your network is not a sequential, it will need to be saved in a separate file and\navailable in the python path. An example of this can be found in <code>simple_cnn.py</code>.</p>\n<h4>Training Options</h4>\n<p>There are two main training options with SparkTorch: <code>async</code> and <code>hogwild</code>. The async mode utilizes the torch distributed\npackage, ensuring that the networks are in sync through each iteration. This is the most supported version. When using\nthis option, you will need to be aware that barrier execution is enforced, meaning that the parallelism will need to match\nthe partitions.</p>\n<p>The Hogwild approach utilizes a Flask Service underneath the hood. When using Hogwild, it is strongly recommended that you use the\n<code>useBarrier</code> option to force barrier execution. Below are a list of parameters to SparkTorch and their meaning.</p>\n<pre><code>inputCol: Standard Spark InputCol that must be a Vector.\nlabelCol: Standard Spark Label column. Can be null.\ntorchObj: The TorchObj which is described in the `Creating a Torch Object` section.\niters: Number of iterations to run per partition.\npredictionCol: The standard spark prediction column for the dataframe.\npartitions: Ability to repartition during training.\nacquireLock: Used in Hogwild only. Forces locking on the server.\nverbose: Describes whether you want real time logging\npartitionShuffles: Only used in Hogwild. Will reshuffle data after completing training.\nport: Only used in hogwild. Server port.\nuseBarrier: Only used in hogwild. Describes whether you want barrier execution. (Async mode uses barrier by default)\nuseVectorOut: Boolean to describe if you want the model output to be a vector (Defaults to float).\nearlyStopPatience: If greater than 0, it will enforce early stopping based on validation.\nminiBatch: Minibatch size for training per iteration. (Randomly shuffled)\nvalidationPct: Percentage to use for validation.\nmode: which training mode to use. `synchronous` leverages torch distributed. `hogwild` currently uses the flask service.\ndevice: Supply 'cpu' or 'cuda'\n</code></pre>\n<h4>Saving and Loading Pipelines</h4>\n<p>Since saving and loading custom ML Transformers in pure python has not been implemented in PySpark, an extension has been\nadded here to make that possible. In order to save a Pyspark Pipeline with Apache Spark, one will need to use the overwrite function:</p>\n<pre><span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">stages</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">va</span><span class=\"p\">,</span> <span class=\"n\">encoded</span><span class=\"p\">,</span> <span class=\"n\">spark_model</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n<span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">overwrite</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s2\">\"location\"</span><span class=\"p\">)</span>\n</pre>\n<p>For loading, a Pipeline wrapper has been provided in the pipeline_utils file. An example is below:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sparktorch</span> <span class=\"kn\">import</span> <span class=\"n\">PysparkPipelineWrapper</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyspark.ml.pipeline</span> <span class=\"kn\">import</span> <span class=\"n\">PipelineModel</span>\n\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">PysparkPipelineWrapper</span><span class=\"o\">.</span><span class=\"n\">unwrap</span><span class=\"p\">(</span><span class=\"n\">PipelineModel</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'location'</span><span class=\"p\">))</span>\n</pre>\n<p>Then you can perform predictions, etc with:</p>\n<pre><span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n</pre>\n<h4>Getting the Pytorch model from the training session</h4>\n<p>If you just want to get the Pytorch model after training, you can execute the following code:</p>\n<pre><span class=\"n\">stm</span> <span class=\"o\">=</span> <span class=\"n\">SparkTorch</span><span class=\"p\">(</span>\n    <span class=\"n\">inputCol</span><span class=\"o\">=</span><span class=\"s1\">'features'</span><span class=\"p\">,</span>\n    <span class=\"n\">labelCol</span><span class=\"o\">=</span><span class=\"s1\">'label'</span><span class=\"p\">,</span>\n    <span class=\"n\">predictionCol</span><span class=\"o\">=</span><span class=\"s1\">'predictions'</span><span class=\"p\">,</span>\n    <span class=\"n\">torchObj</span><span class=\"o\">=</span><span class=\"n\">network_with_params</span><span class=\"p\">,</span>\n    <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">iters</span><span class=\"o\">=</span><span class=\"mi\">5</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n\n<span class=\"n\">py_model</span> <span class=\"o\">=</span> <span class=\"n\">stm</span><span class=\"o\">.</span><span class=\"n\">getPytorchModel</span><span class=\"p\">()</span>\n</pre>\n<h4>Using a pretrained Pytorch model for inference</h4>\n<p>If you already have a trained Pytorch model, you can attach it your existing pipeline by directly creating a SparkTorchModel.\nThis can be done by running the following:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sparktorch</span> <span class=\"kn\">import</span> <span class=\"n\">create_spark_torch_model</span>\n\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># Pretrained Network</span>\n\n<span class=\"n\">spark_torch_model</span> <span class=\"o\">=</span> <span class=\"n\">create_spark_torch_model</span><span class=\"p\">(</span>\n    <span class=\"n\">net</span><span class=\"p\">,</span> \n    <span class=\"n\">inputCol</span><span class=\"o\">=</span><span class=\"s1\">'features'</span><span class=\"p\">,</span>\n    <span class=\"n\">predictionCol</span><span class=\"o\">=</span><span class=\"s1\">'predictions'</span>\n<span class=\"p\">)</span>\n</pre>\n<h2>Running</h2>\n<p>One big thing to remember is to add the <code>--executor cores 1</code> option to spark to ensure\neach executor is only training one copy of the network. This will especially be needed for gpu training.</p>\n<h2>Contributing</h2>\n<p>Contributions are always welcome. This could be fixing a bug, changing documentation, or adding a new feature. To test\nnew changes against existing tests, we have provided a Docker container which takes in an argument of the python version.\nThis allows the user to check their work before pushing to Github, where travis-ci will run.</p>\n<p>For python 3.6</p>\n<pre><code>docker build -t local-test --build-arg PYTHON_VERSION=3.6 .\ndocker run --rm local-test:latest bash -i -c \"pytest\"\n</code></pre>\n<h2>Literature and Inspiration</h2>\n<ul>\n<li>Distributed training: <a href=\"http://seba1511.net/dist_blog/\" rel=\"nofollow\">http://seba1511.net/dist_blog/</a></li>\n<li>HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent: <a href=\"https://arxiv.org/pdf/1106.5730.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1106.5730.pdf</a></li>\n<li>Scaling Distributed Machine Learning with the Parameter Server: <a href=\"https://www.cs.cmu.edu/%7Emuli/file/parameter_server_osdi14.pdf\" rel=\"nofollow\">https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6258754, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "a8cc00fcd999a0e5937817c92bb85af7", "sha256": "788661d2598df50327456a6fedce8f51524a0428d22090c95fe860f503d86e4a"}, "downloads": -1, "filename": "sparktorch-0.0.1.tar.gz", "has_sig": false, "md5_digest": "a8cc00fcd999a0e5937817c92bb85af7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8689, "upload_time": "2019-11-29T18:41:30", "upload_time_iso_8601": "2019-11-29T18:41:30.075797Z", "url": "https://files.pythonhosted.org/packages/61/da/eb8e751b02bfb525fd66d25fc8c2f661f803d07cca76da8ffc095573e1de/sparktorch-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "24b7fd9fb792bb614e01971f0ddd17c7", "sha256": "07b9e5a19f1b9d8cda91d282c751f427daedfdd7df1a4774d22129e7a5a9e803"}, "downloads": -1, "filename": "sparktorch-0.0.2.tar.gz", "has_sig": false, "md5_digest": "24b7fd9fb792bb614e01971f0ddd17c7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8686, "upload_time": "2019-11-29T18:42:32", "upload_time_iso_8601": "2019-11-29T18:42:32.138999Z", "url": "https://files.pythonhosted.org/packages/fe/1a/a132de959f8837be51ba5996087e826277cf2933d8bbd1bf63d9d5e5ebe4/sparktorch-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "374060b883752b54cd83975d127f8dea", "sha256": "8d2565ec4ae57348c72feefe5ef652093c64da05658807b069ba26a332f9984a"}, "downloads": -1, "filename": "sparktorch-0.0.3.tar.gz", "has_sig": false, "md5_digest": "374060b883752b54cd83975d127f8dea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12945, "upload_time": "2019-11-30T20:07:42", "upload_time_iso_8601": "2019-11-30T20:07:42.417654Z", "url": "https://files.pythonhosted.org/packages/9a/82/626aba9edcb9e5779d9edcc5ccf9144d1ea121e33c288ca2c0c344d91574/sparktorch-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "6db35849050dc82f8c7bab3a47154685", "sha256": "38f74b38af1d2f8bd7e8f2a49bf5535af222731d6f246595656341a67584d8e0"}, "downloads": -1, "filename": "sparktorch-0.0.4.tar.gz", "has_sig": false, "md5_digest": "6db35849050dc82f8c7bab3a47154685", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17872, "upload_time": "2019-12-01T21:24:11", "upload_time_iso_8601": "2019-12-01T21:24:11.924524Z", "url": "https://files.pythonhosted.org/packages/ca/54/908b191655d04cdf30f20d97e5cde3fddde1bc716a4e79afa59391781514/sparktorch-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "c3bb0e469756dd111ac8a351ad8870d8", "sha256": "e27f3ac134d6e15a558a7d28a07bd94203dd4f1c0b77bacfa31256c4c778a247"}, "downloads": -1, "filename": "sparktorch-0.0.5.tar.gz", "has_sig": false, "md5_digest": "c3bb0e469756dd111ac8a351ad8870d8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18841, "upload_time": "2019-12-02T03:32:14", "upload_time_iso_8601": "2019-12-02T03:32:14.119574Z", "url": "https://files.pythonhosted.org/packages/3b/1f/affe3ddaaa822a1702c6b5cb70547f385d864e9dba6d85668574802a5b7d/sparktorch-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "677f76922f3d7eb183f367e627b6c651", "sha256": "aa1d2419c31476994e9715e0b91f241efa7d42e25e57b371945e76bfe19959da"}, "downloads": -1, "filename": "sparktorch-0.0.6.tar.gz", "has_sig": false, "md5_digest": "677f76922f3d7eb183f367e627b6c651", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18822, "upload_time": "2019-12-02T03:57:26", "upload_time_iso_8601": "2019-12-02T03:57:26.566206Z", "url": "https://files.pythonhosted.org/packages/2b/62/a644e1d9ea7e01cc4d7418bfd999e902f933e6db2729917200dcd87adb13/sparktorch-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "83e85d3cb0fee3bcbe9d176a1873bc31", "sha256": "7243d464c6e79f21cad6e811265e14fd8a88ec5cc3a6fec123d798c44e6010b5"}, "downloads": -1, "filename": "sparktorch-0.0.7.tar.gz", "has_sig": false, "md5_digest": "83e85d3cb0fee3bcbe9d176a1873bc31", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20508, "upload_time": "2019-12-03T03:59:13", "upload_time_iso_8601": "2019-12-03T03:59:13.851113Z", "url": "https://files.pythonhosted.org/packages/bc/a9/7ee5a7810a867fc521a088293bc1f8f986362d7855d622217753717f0a24/sparktorch-0.0.7.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "4786427eb5c12e2a8f97b0895c89d4ea", "sha256": "ff477a6f57a74f16ab036d6de1221c968c4c7f659cf4b261de248efdd90bf9dc"}, "downloads": -1, "filename": "sparktorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "4786427eb5c12e2a8f97b0895c89d4ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21777, "upload_time": "2019-12-04T01:55:52", "upload_time_iso_8601": "2019-12-04T01:55:52.871212Z", "url": "https://files.pythonhosted.org/packages/a7/34/3ffe6f3d2a84492164da03c806c53241c6792f57dcd85266997a88208588/sparktorch-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "f11c820cad7038a6763a84c1213c09ba", "sha256": "2ac22c1dec962d8cdedcea57c5ab0009eb1f99f814556df3ab532b06d3e51372"}, "downloads": -1, "filename": "sparktorch-0.1.1.tar.gz", "has_sig": false, "md5_digest": "f11c820cad7038a6763a84c1213c09ba", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21830, "upload_time": "2019-12-05T00:43:14", "upload_time_iso_8601": "2019-12-05T00:43:14.558026Z", "url": "https://files.pythonhosted.org/packages/80/46/c0cfd90f715e0d2217bbab8ebe04854211372acb6305ac67b5b1e58faf9f/sparktorch-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "b002cb9a969cf9bb19849ca25000f10d", "sha256": "024ad19dd3543ae881ca8448c462bae4cbf86eaee5ff53b1d52262c3dd733626"}, "downloads": -1, "filename": "sparktorch-0.1.2.tar.gz", "has_sig": false, "md5_digest": "b002cb9a969cf9bb19849ca25000f10d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21911, "upload_time": "2019-12-07T16:21:07", "upload_time_iso_8601": "2019-12-07T16:21:07.229846Z", "url": "https://files.pythonhosted.org/packages/3f/d5/2821072d9668d83e5076ff251573748a2222e77983c82916b5442d6de520/sparktorch-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b002cb9a969cf9bb19849ca25000f10d", "sha256": "024ad19dd3543ae881ca8448c462bae4cbf86eaee5ff53b1d52262c3dd733626"}, "downloads": -1, "filename": "sparktorch-0.1.2.tar.gz", "has_sig": false, "md5_digest": "b002cb9a969cf9bb19849ca25000f10d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21911, "upload_time": "2019-12-07T16:21:07", "upload_time_iso_8601": "2019-12-07T16:21:07.229846Z", "url": "https://files.pythonhosted.org/packages/3f/d5/2821072d9668d83e5076ff251573748a2222e77983c82916b5442d6de520/sparktorch-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:52 2020"}