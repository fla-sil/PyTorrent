{"info": {"author": "Oluwatosin Olayinka", "author_email": "oaolayin@live.unc.edu", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# PloidPy\n\n## Introduction\nPloidPy is a program written in Python designed to infer ploidy from next-generation reads aligned to a haploid reference genome. The program makes use of a stastical model representing the distribution of specific nucleotide counts and selects the most probable ploidy on the basis of a minimum AIC.\n\n## Installation\nInstallation of PloidPy is relatively simple and can be done easily using pip. The most recent stable version can be installed using the following command:\n```\npip install PloidPy\n```\nAnd the developmental one can be installed directly from the git repository:\n```\npip install git+git://github.com/floutt/PloidPy\n```\n### Dependencies\nIn order to run PloidPy, the following dependencies are required:\n- `Python 3.6+`\n- `NumPy`\n- `SciPy`\n- `Statsmodels`\n- `matplotlib`\n- `seaborn`\n- `pysam`\n\n## Getting Started\nOnce installed, PloidPy can be run on an indexed BAM file. For this tutorial we will download some BAM files created using simulated data from the [ploidyNGS](https://github.com/diriano/ploidyNGS) repository.\n```\nwget https://github.com/diriano/ploidyNGS/raw/master/test_data/simulatedDiploidGenome/Ploidy2.bowtie2.sorted.bam\nwget https://github.com/diriano/ploidyNGS/raw/master/test_data/simulatedTriploidGenome/Ploidy3.bowtie2.sorted.bam\nwget https://github.com/diriano/ploidyNGS/raw/master/test_data/simulatedTetraploidGenome/Ploidy4.bowtie2.sorted.bam\n```\nAfter downloading these files, we have to index all of these files using samtools.\n```\nsamtools index Ploidy2.bowtie2.sorted.bam\nsamtools index Ploidy3.bowtie2.sorted.bam\nsamtools index Ploidy4.bowtie2.sorted.bam\n```\nFrom here we can extract the minor allele count (MAC) and total read coverage from each of the BAM files using `PloidPy process_bam`. In the following example the Phred-like mapping threshold is set to 15 \n```\nPloidPy process_bam --bam Ploidy2.bowtie2.sorted.bam --out diploid.count --quality 15\nPloidPy process_bam --bam Ploidy3.bowtie2.sorted.bam --out triploid.count --quality 15\nPloidPy process_bam --bam Ploidy4.bowtie2.sorted.bam --out tetraploid.count --quality 15\n```\n\nThese commands will produce two different files per command - a gzip-compressed archive containing the count data (`*count.gz`) and a file containing important metadata needed for ploidy evaluation (`*count.info`).\n \nAfter this has been done, one of two steps can be taken. Either inferring ploidy using the unfiltered data with an error component incorporated into the model or filtering the data and running the model with no error component. One can filter out the data from each individual using the following commands:\n```\nPloidPy filter --count_file diploid.count.gz --out diploid.count.filtered\nPloidPy filter  --count_file triploid.count.gz --out triploid.count.filtered\nPloidPy filter  --count_file tetraploid.count.gz --out tetraploid.count.filtered\n```\nThis will create gzip-compressed files with count data filtering out data resulting from sequencing error and, with this, we can evaluate the ploidy of each individual using the `PloidPy assess` subcommand. PloidPy automatically detects whether or not the count file is filtered (by the presence or absence of the `*info` file) and adjusts the model accordingly. In this example, ploidies of 2n to 8n will be evaluated, although this can be done with any set of ploidies greater than or equal to 2n. This can be done with the following commands:\n```\nPloidPy assess --count_file diploid.count.filtered.gz --out diploid.filtered.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file triploid.count.filtered.gz --out triploid.filtered.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file tetraploid.count.filtered.gz --out tetraploid.filtered.tsv --ploidies 2 3 4 5 6 7 8\n```\nThe evaluation on unfiltered can similarly be done with the following commands:\n```\nPloidPy assess --count_file diploid.count.gz --out diploid.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file triploid.count.gz --out triploid.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file tetraploid.count.gz --out tetraploid.tsv --ploidies 2 3 4 5 6 7 8\n```\nAs you can see, in both cases all of the predictions were correct! Additional information can be found in the \\*tsv files. Each column represents the following:\n\n|Column             |Meaning|\n|-------------------|-------|\n|Ploidy             |Ploidy model|\n|Log_Likelihood     |Log likelihood of ploidy model|\n|AIC                |AIC value of ploidy model|\n|Het_Weights        |Weight parameter of each heterozygous state component|\n|Uniform Weight     |Weight parameter of the uniform component of the model|\n|Binomial_Err_Weight|Weight parameter of the binomial error component (only present in unfiltered data)|\n\nAdditionally, the filtered data can be used to produce helpful figures to visualize the joint distribution of TRC and MAC values. This can be done with the following commands:\n```\nPloidPy jdist --count_file diploid.count.filtered --out diploid\nPloidPy jdist --count_file triploid.count.filtered --out triploid\nPloidPy jdist --count_file tetraploid.count.filtered --out tetraploid\n```\n\nA visual overview of this process can be found [here](https://github.com/floutt/PloidPy/blob/master/figures/PloidPy_visual_guide.pdf) as well as some example [joint](https://github.com/floutt/PloidPy/blob/master/figures/diploid_joint_dist.pdf) [distribution](https://github.com/floutt/PloidPy/blob/master/figures/triploid_joint_dist.pdf) [figures](https://github.com/floutt/PloidPy/blob/master/figures/tetraploid_joint_dist.pdf).", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/floutt/PloidPy", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "PloidPy", "package_url": "https://pypi.org/project/PloidPy/", "platform": "", "project_url": "https://pypi.org/project/PloidPy/", "project_urls": {"Homepage": "https://github.com/floutt/PloidPy"}, "release_url": "https://pypi.org/project/PloidPy/1.0.0/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Discrete mixture model based ploidy inference tool", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PloidPy</h1>\n<h2>Introduction</h2>\n<p>PloidPy is a program written in Python designed to infer ploidy from next-generation reads aligned to a haploid reference genome. The program makes use of a stastical model representing the distribution of specific nucleotide counts and selects the most probable ploidy on the basis of a minimum AIC.</p>\n<h2>Installation</h2>\n<p>Installation of PloidPy is relatively simple and can be done easily using pip. The most recent stable version can be installed using the following command:</p>\n<pre><code>pip install PloidPy\n</code></pre>\n<p>And the developmental one can be installed directly from the git repository:</p>\n<pre><code>pip install git+git://github.com/floutt/PloidPy\n</code></pre>\n<h3>Dependencies</h3>\n<p>In order to run PloidPy, the following dependencies are required:</p>\n<ul>\n<li><code>Python 3.6+</code></li>\n<li><code>NumPy</code></li>\n<li><code>SciPy</code></li>\n<li><code>Statsmodels</code></li>\n<li><code>matplotlib</code></li>\n<li><code>seaborn</code></li>\n<li><code>pysam</code></li>\n</ul>\n<h2>Getting Started</h2>\n<p>Once installed, PloidPy can be run on an indexed BAM file. For this tutorial we will download some BAM files created using simulated data from the <a href=\"https://github.com/diriano/ploidyNGS\" rel=\"nofollow\">ploidyNGS</a> repository.</p>\n<pre><code>wget https://github.com/diriano/ploidyNGS/raw/master/test_data/simulatedDiploidGenome/Ploidy2.bowtie2.sorted.bam\nwget https://github.com/diriano/ploidyNGS/raw/master/test_data/simulatedTriploidGenome/Ploidy3.bowtie2.sorted.bam\nwget https://github.com/diriano/ploidyNGS/raw/master/test_data/simulatedTetraploidGenome/Ploidy4.bowtie2.sorted.bam\n</code></pre>\n<p>After downloading these files, we have to index all of these files using samtools.</p>\n<pre><code>samtools index Ploidy2.bowtie2.sorted.bam\nsamtools index Ploidy3.bowtie2.sorted.bam\nsamtools index Ploidy4.bowtie2.sorted.bam\n</code></pre>\n<p>From here we can extract the minor allele count (MAC) and total read coverage from each of the BAM files using <code>PloidPy process_bam</code>. In the following example the Phred-like mapping threshold is set to 15</p>\n<pre><code>PloidPy process_bam --bam Ploidy2.bowtie2.sorted.bam --out diploid.count --quality 15\nPloidPy process_bam --bam Ploidy3.bowtie2.sorted.bam --out triploid.count --quality 15\nPloidPy process_bam --bam Ploidy4.bowtie2.sorted.bam --out tetraploid.count --quality 15\n</code></pre>\n<p>These commands will produce two different files per command - a gzip-compressed archive containing the count data (<code>*count.gz</code>) and a file containing important metadata needed for ploidy evaluation (<code>*count.info</code>).</p>\n<p>After this has been done, one of two steps can be taken. Either inferring ploidy using the unfiltered data with an error component incorporated into the model or filtering the data and running the model with no error component. One can filter out the data from each individual using the following commands:</p>\n<pre><code>PloidPy filter --count_file diploid.count.gz --out diploid.count.filtered\nPloidPy filter  --count_file triploid.count.gz --out triploid.count.filtered\nPloidPy filter  --count_file tetraploid.count.gz --out tetraploid.count.filtered\n</code></pre>\n<p>This will create gzip-compressed files with count data filtering out data resulting from sequencing error and, with this, we can evaluate the ploidy of each individual using the <code>PloidPy assess</code> subcommand. PloidPy automatically detects whether or not the count file is filtered (by the presence or absence of the <code>*info</code> file) and adjusts the model accordingly. In this example, ploidies of 2n to 8n will be evaluated, although this can be done with any set of ploidies greater than or equal to 2n. This can be done with the following commands:</p>\n<pre><code>PloidPy assess --count_file diploid.count.filtered.gz --out diploid.filtered.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file triploid.count.filtered.gz --out triploid.filtered.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file tetraploid.count.filtered.gz --out tetraploid.filtered.tsv --ploidies 2 3 4 5 6 7 8\n</code></pre>\n<p>The evaluation on unfiltered can similarly be done with the following commands:</p>\n<pre><code>PloidPy assess --count_file diploid.count.gz --out diploid.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file triploid.count.gz --out triploid.tsv --ploidies 2 3 4 5 6 7 8\nPloidPy assess --count_file tetraploid.count.gz --out tetraploid.tsv --ploidies 2 3 4 5 6 7 8\n</code></pre>\n<p>As you can see, in both cases all of the predictions were correct! Additional information can be found in the *tsv files. Each column represents the following:</p>\n<table>\n<thead>\n<tr>\n<th>Column</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ploidy</td>\n<td>Ploidy model</td>\n</tr>\n<tr>\n<td>Log_Likelihood</td>\n<td>Log likelihood of ploidy model</td>\n</tr>\n<tr>\n<td>AIC</td>\n<td>AIC value of ploidy model</td>\n</tr>\n<tr>\n<td>Het_Weights</td>\n<td>Weight parameter of each heterozygous state component</td>\n</tr>\n<tr>\n<td>Uniform Weight</td>\n<td>Weight parameter of the uniform component of the model</td>\n</tr>\n<tr>\n<td>Binomial_Err_Weight</td>\n<td>Weight parameter of the binomial error component (only present in unfiltered data)</td>\n</tr></tbody></table>\n<p>Additionally, the filtered data can be used to produce helpful figures to visualize the joint distribution of TRC and MAC values. This can be done with the following commands:</p>\n<pre><code>PloidPy jdist --count_file diploid.count.filtered --out diploid\nPloidPy jdist --count_file triploid.count.filtered --out triploid\nPloidPy jdist --count_file tetraploid.count.filtered --out tetraploid\n</code></pre>\n<p>A visual overview of this process can be found <a href=\"https://github.com/floutt/PloidPy/blob/master/figures/PloidPy_visual_guide.pdf\" rel=\"nofollow\">here</a> as well as some example <a href=\"https://github.com/floutt/PloidPy/blob/master/figures/diploid_joint_dist.pdf\" rel=\"nofollow\">joint</a> <a href=\"https://github.com/floutt/PloidPy/blob/master/figures/triploid_joint_dist.pdf\" rel=\"nofollow\">distribution</a> <a href=\"https://github.com/floutt/PloidPy/blob/master/figures/tetraploid_joint_dist.pdf\" rel=\"nofollow\">figures</a>.</p>\n\n          </div>"}, "last_serial": 7016924, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "da05a864f207cf0e4fb64033689dd0f7", "sha256": "014894d95e39f28c0c54fcb56eea4e8cd212afd91b151d70439d6b29c6a41181"}, "downloads": -1, "filename": "PloidPy-1.0.0.tar.gz", "has_sig": false, "md5_digest": "da05a864f207cf0e4fb64033689dd0f7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 77688, "upload_time": "2020-04-14T12:49:25", "upload_time_iso_8601": "2020-04-14T12:49:25.548742Z", "url": "https://files.pythonhosted.org/packages/4c/86/0fad46449e60622d03acc1aea92bbdb442b1479ae815ee657bdb52ef7a70/PloidPy-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "da05a864f207cf0e4fb64033689dd0f7", "sha256": "014894d95e39f28c0c54fcb56eea4e8cd212afd91b151d70439d6b29c6a41181"}, "downloads": -1, "filename": "PloidPy-1.0.0.tar.gz", "has_sig": false, "md5_digest": "da05a864f207cf0e4fb64033689dd0f7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 77688, "upload_time": "2020-04-14T12:49:25", "upload_time_iso_8601": "2020-04-14T12:49:25.548742Z", "url": "https://files.pythonhosted.org/packages/4c/86/0fad46449e60622d03acc1aea92bbdb442b1479ae815ee657bdb52ef7a70/PloidPy-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:53:24 2020"}