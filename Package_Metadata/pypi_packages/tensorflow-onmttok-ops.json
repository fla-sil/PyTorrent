{"info": {"author": "Emmanuel Ohana", "author_email": "manu.ohana@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "[![Build Status](https://travis-ci.org/eohana/tensorflow-onmttok-ops.svg?branch=master)](https://travis-ci.org/eohana/tensorflow-onmttok-ops)\n[![PyPI version](https://badge.fury.io/py/tensorflow-onmttok-ops.svg)](https://badge.fury.io/py/tensorflow-onmttok-ops)\n\n# OpenNMT Tokenizer TensorFlow Ops\n\n**DISCLAIMER**: This package is not published by the OpenNMT authors.  \nFull credits for [OpenNMT Tokenizer](https://github.com/OpenNMT/Tokenizer)\nand [OpenNMT-tf](https://github.com/OpenNMT/OpenNMT-tf) goes to their respectively\nauthors.\n\nThis project aims to wrap [OpenNMT Tokenizer](https://github.com/OpenNMT/Tokenizer)\ninto TensorFlow Ops.\n\nIt's primarily intended to be used as an addition to the\n[OpenNMT-tf](https://github.com/OpenNMT/OpenNMT-tf) framework,\nin order to remove the need of applying tokenization and/or \ndetokenization outside of a serving environment (e.g. TensorFlow Serving).\n\n## Compatibility\n\n* TensorFlow >= `2.1.0`\n* OpenNMT-tf >= `2.6.0` *for usage in conjunction with OpenNMT-tf*\n\n## Installation\n\nPrerequisites :\n\n* A Linux environment (`manylinux2014` eligible)\n* Python >= `3.5`\n\nInstall the package with pip :\n\n```shell script\npip install tensorflow-onmttok-ops\n```\n\n## Usage\n\n### Available Tokenizer options\n\nThe majority of the OpenNMT Tokenizer\n[options](https://github.com/OpenNMT/Tokenizer/blob/master/docs/options.md)\nare available.  \nHowever, providing `BPE` or `SentencePiece` models is not supported,\nand by extension, setting the tokenizer `mode` to `none` is not supported.\n\nYou therefore **cannot** use the following options :\n\n* `bpe_model_path`\n* `sp_model_path`\n* `sp_nbest_size`\n* `sp_alpha`\n* `vocabulary_path`\n* `vocabulary_threshold`\n\n> **Note:** Tokenizer options are defined at graph construction time\n> and are constants.\n\n### Tokenization\n\n```python\nimport tensorflow_onmttok as tf_onmttok\n\ntokens = tf_onmttok.tokenize([\"Hello, how are you?\"], mode='conservative')\n```\n\n### Detokenization\n\n```python\nimport tensorflow_onmttok as tf_onmttok\n\ntext = tf_onmttok.detokenize([\"How\", \"are\", \"you\", \"?\"], mode='space')\n```\n\n### With OpenNMT-tf\n\nUsage with OpenNMT-tf is pretty straightforward.  \nThis package comes with a built-in tokenizer \nin order to make usage of the ops.\n\n1. Before training your model, register the tokenizer as follows :\n\n    ```python\n    from tensorflow_onmttok import register_opennmt_in_graph_tokenizer\n\n    register_opennmt_in_graph_tokenizer()\n    ```\n\n    See the [complete example](examples/onmt_tf_training.py)\n\n2. Now that the tokenizer is registered, you can use the \n`OpenNMTInGraphTokenizer` class instead of `OpenNMTTokenizer` in your \ntokenization configuration files, e.g. :\n\n    ```yaml\n    type: OpenNMTInGraphTokenizer\n    params:\n      mode: conservative\n      case_feature: true\n    ```\n\n3. That's it ! You can now train your model as usual. \nYour `ExportedModel` will now expect a `text` \ninput instead of `tokens` and `length`.\n\n    > **Note**: Tokenization resources will not be exported\n      to the `assets.extra` directory.\n\n## Build TF Serving with this Ops\n\nThis guide will show you how to build TensorFlow Serving\nwith this ops.\n\n### Prerequisites\n\n* You have already cloned the\nTF Serving `>= 2.1.0` [repository](https://github.com/tensorflow/serving),\nand have all tools installed for building it\n* You have installed CMake `3.1.0` or newer\n\n### Building\n\n#### Add the Ops sources\n\nFirst, download the \n[release](https://github.com/eohana/tensorflow-onmttok-ops/releases)\nof your choice.\n\nInside the TF Serving sources folder, create a directory\nnamed `custom_ops` and copy the content of the `tensorflow_onmttok`\ndirectory into it.\n\n```shell script\n$ cd <tf_serving_sources>\n$ mkdir tensorflow_serving/custom_ops\n$ cp -r <op_sources>/tensorflow_onmttok tensorflow_serving/custom_ops\n```\n\n#### Reference the Ops\n\nEdit `tensorflow_serving/model_servers/BUILD` to reference \nthe Ops build target :\n\n```shell script\nSUPPORTED_TENSORFLOW_OPS = [\n    ...\n    \"//tensorflow_serving/custom_ops/tensorflow_onmttok:onmttok_ops\"\n]\n```\n\n#### Build OpenNMT Tokenizer from sources\n\nThe last step is to build a static version of the\nOpenNMT Tokenizer library.  \nA shell script is provided inside the `tensorflow_onmttok` directory\nthat will build it with CMake.\n\n```shell script\n$ cd <tf_serving_sources>\n$ chmod +x tensorflow_serving/custom_ops/tensorflow_onmttok/build_tokenizer.sh\n$ tensorflow_serving/custom_ops/tensorflow_onmttok/build_tokenizer.sh\n```\n\n> **Note**: Pass `sudo` argument to the `build_tokenizer.sh` script\n  to execute the `make install` command with sudo.\n\n#### Build TensorFlow Serving\n\nYou can now build TensorFlow Serving as usual.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/eohana/tensorflow-onmttok-ops", "keywords": "tensorflow opennmt tokenizer", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "tensorflow-onmttok-ops", "package_url": "https://pypi.org/project/tensorflow-onmttok-ops/", "platform": "", "project_url": "https://pypi.org/project/tensorflow-onmttok-ops/", "project_urls": {"Homepage": "https://github.com/eohana/tensorflow-onmttok-ops"}, "release_url": "https://pypi.org/project/tensorflow-onmttok-ops/0.3.0/", "requires_dist": ["tensorflow (>=2.1.0)"], "requires_python": "", "summary": "OpenNMT Tokenizer as TensorFlow Operations", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/eohana/tensorflow-onmttok-ops\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e350fe8cb8a521c136ebb1b3fd3bee35a22616b5/68747470733a2f2f7472617669732d63692e6f72672f656f68616e612f74656e736f72666c6f772d6f6e6d74746f6b2d6f70732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://badge.fury.io/py/tensorflow-onmttok-ops\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5a93ee6ba18d431fe0ed02945774126cb4980fe5/68747470733a2f2f62616467652e667572792e696f2f70792f74656e736f72666c6f772d6f6e6d74746f6b2d6f70732e737667\"></a></p>\n<h1>OpenNMT Tokenizer TensorFlow Ops</h1>\n<p><strong>DISCLAIMER</strong>: This package is not published by the OpenNMT authors.<br>\nFull credits for <a href=\"https://github.com/OpenNMT/Tokenizer\" rel=\"nofollow\">OpenNMT Tokenizer</a>\nand <a href=\"https://github.com/OpenNMT/OpenNMT-tf\" rel=\"nofollow\">OpenNMT-tf</a> goes to their respectively\nauthors.</p>\n<p>This project aims to wrap <a href=\"https://github.com/OpenNMT/Tokenizer\" rel=\"nofollow\">OpenNMT Tokenizer</a>\ninto TensorFlow Ops.</p>\n<p>It's primarily intended to be used as an addition to the\n<a href=\"https://github.com/OpenNMT/OpenNMT-tf\" rel=\"nofollow\">OpenNMT-tf</a> framework,\nin order to remove the need of applying tokenization and/or\ndetokenization outside of a serving environment (e.g. TensorFlow Serving).</p>\n<h2>Compatibility</h2>\n<ul>\n<li>TensorFlow &gt;= <code>2.1.0</code></li>\n<li>OpenNMT-tf &gt;= <code>2.6.0</code> <em>for usage in conjunction with OpenNMT-tf</em></li>\n</ul>\n<h2>Installation</h2>\n<p>Prerequisites :</p>\n<ul>\n<li>A Linux environment (<code>manylinux2014</code> eligible)</li>\n<li>Python &gt;= <code>3.5</code></li>\n</ul>\n<p>Install the package with pip :</p>\n<pre>pip install tensorflow-onmttok-ops\n</pre>\n<h2>Usage</h2>\n<h3>Available Tokenizer options</h3>\n<p>The majority of the OpenNMT Tokenizer\n<a href=\"https://github.com/OpenNMT/Tokenizer/blob/master/docs/options.md\" rel=\"nofollow\">options</a>\nare available.<br>\nHowever, providing <code>BPE</code> or <code>SentencePiece</code> models is not supported,\nand by extension, setting the tokenizer <code>mode</code> to <code>none</code> is not supported.</p>\n<p>You therefore <strong>cannot</strong> use the following options :</p>\n<ul>\n<li><code>bpe_model_path</code></li>\n<li><code>sp_model_path</code></li>\n<li><code>sp_nbest_size</code></li>\n<li><code>sp_alpha</code></li>\n<li><code>vocabulary_path</code></li>\n<li><code>vocabulary_threshold</code></li>\n</ul>\n<blockquote>\n<p><strong>Note:</strong> Tokenizer options are defined at graph construction time\nand are constants.</p>\n</blockquote>\n<h3>Tokenization</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">tensorflow_onmttok</span> <span class=\"k\">as</span> <span class=\"nn\">tf_onmttok</span>\n\n<span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"n\">tf_onmttok</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">([</span><span class=\"s2\">\"Hello, how are you?\"</span><span class=\"p\">],</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'conservative'</span><span class=\"p\">)</span>\n</pre>\n<h3>Detokenization</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">tensorflow_onmttok</span> <span class=\"k\">as</span> <span class=\"nn\">tf_onmttok</span>\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"n\">tf_onmttok</span><span class=\"o\">.</span><span class=\"n\">detokenize</span><span class=\"p\">([</span><span class=\"s2\">\"How\"</span><span class=\"p\">,</span> <span class=\"s2\">\"are\"</span><span class=\"p\">,</span> <span class=\"s2\">\"you\"</span><span class=\"p\">,</span> <span class=\"s2\">\"?\"</span><span class=\"p\">],</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'space'</span><span class=\"p\">)</span>\n</pre>\n<h3>With OpenNMT-tf</h3>\n<p>Usage with OpenNMT-tf is pretty straightforward.<br>\nThis package comes with a built-in tokenizer\nin order to make usage of the ops.</p>\n<ol>\n<li>\n<p>Before training your model, register the tokenizer as follows :</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">tensorflow_onmttok</span> <span class=\"kn\">import</span> <span class=\"n\">register_opennmt_in_graph_tokenizer</span>\n\n<span class=\"n\">register_opennmt_in_graph_tokenizer</span><span class=\"p\">()</span>\n</pre>\n<p>See the <a href=\"examples/onmt_tf_training.py\" rel=\"nofollow\">complete example</a></p>\n</li>\n<li>\n<p>Now that the tokenizer is registered, you can use the\n<code>OpenNMTInGraphTokenizer</code> class instead of <code>OpenNMTTokenizer</code> in your\ntokenization configuration files, e.g. :</p>\n<pre><span class=\"nt\">type</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">OpenNMTInGraphTokenizer</span>\n<span class=\"nt\">params</span><span class=\"p\">:</span>\n  <span class=\"nt\">mode</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">conservative</span>\n  <span class=\"nt\">case_feature</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">true</span>\n</pre>\n</li>\n<li>\n<p>That's it ! You can now train your model as usual.\nYour <code>ExportedModel</code> will now expect a <code>text</code>\ninput instead of <code>tokens</code> and <code>length</code>.</p>\n<blockquote>\n<p><strong>Note</strong>: Tokenization resources will not be exported\nto the <code>assets.extra</code> directory.</p>\n</blockquote>\n</li>\n</ol>\n<h2>Build TF Serving with this Ops</h2>\n<p>This guide will show you how to build TensorFlow Serving\nwith this ops.</p>\n<h3>Prerequisites</h3>\n<ul>\n<li>You have already cloned the\nTF Serving <code>&gt;= 2.1.0</code> <a href=\"https://github.com/tensorflow/serving\" rel=\"nofollow\">repository</a>,\nand have all tools installed for building it</li>\n<li>You have installed CMake <code>3.1.0</code> or newer</li>\n</ul>\n<h3>Building</h3>\n<h4>Add the Ops sources</h4>\n<p>First, download the\n<a href=\"https://github.com/eohana/tensorflow-onmttok-ops/releases\" rel=\"nofollow\">release</a>\nof your choice.</p>\n<p>Inside the TF Serving sources folder, create a directory\nnamed <code>custom_ops</code> and copy the content of the <code>tensorflow_onmttok</code>\ndirectory into it.</p>\n<pre>$ <span class=\"nb\">cd</span> &lt;tf_serving_sources&gt;\n$ mkdir tensorflow_serving/custom_ops\n$ cp -r &lt;op_sources&gt;/tensorflow_onmttok tensorflow_serving/custom_ops\n</pre>\n<h4>Reference the Ops</h4>\n<p>Edit <code>tensorflow_serving/model_servers/BUILD</code> to reference\nthe Ops build target :</p>\n<pre><span class=\"nv\">SUPPORTED_TENSORFLOW_OPS</span> <span class=\"o\">=</span> <span class=\"o\">[</span>\n    ...\n    <span class=\"s2\">\"//tensorflow_serving/custom_ops/tensorflow_onmttok:onmttok_ops\"</span>\n<span class=\"o\">]</span>\n</pre>\n<h4>Build OpenNMT Tokenizer from sources</h4>\n<p>The last step is to build a static version of the\nOpenNMT Tokenizer library.<br>\nA shell script is provided inside the <code>tensorflow_onmttok</code> directory\nthat will build it with CMake.</p>\n<pre>$ <span class=\"nb\">cd</span> &lt;tf_serving_sources&gt;\n$ chmod +x tensorflow_serving/custom_ops/tensorflow_onmttok/build_tokenizer.sh\n$ tensorflow_serving/custom_ops/tensorflow_onmttok/build_tokenizer.sh\n</pre>\n<blockquote>\n<p><strong>Note</strong>: Pass <code>sudo</code> argument to the <code>build_tokenizer.sh</code> script\nto execute the <code>make install</code> command with sudo.</p>\n</blockquote>\n<h4>Build TensorFlow Serving</h4>\n<p>You can now build TensorFlow Serving as usual.</p>\n\n          </div>"}, "last_serial": 6653864, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "50b934f197f775032c5a76419b6eb7cd", "sha256": "6a984fd6aea0dc8e4639cf3eb84755ce7c458f1098e952b9cc461c3897f4e198"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.1.1-cp35-cp35m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "50b934f197f775032c5a76419b6eb7cd", "packagetype": "bdist_wheel", "python_version": "cp35", "requires_python": null, "size": 141406, "upload_time": "2020-02-14T15:30:23", "upload_time_iso_8601": "2020-02-14T15:30:23.086216Z", "url": "https://files.pythonhosted.org/packages/55/8d/884544f7f7a462c76e880b722c268ff9bdcb35a9c9b2aeb5c46b31bada79/tensorflow_onmttok_ops-0.1.1-cp35-cp35m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f76aaf2e5353b30bcdaf65b6a32e3ba0", "sha256": "783376b0f3d6c5a536dc0256a6ce93e3d1101c5a3a5e05fdf92785d98a631c3d"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.1.1-cp36-cp36m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "f76aaf2e5353b30bcdaf65b6a32e3ba0", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": null, "size": 141404, "upload_time": "2020-02-14T15:29:58", "upload_time_iso_8601": "2020-02-14T15:29:58.506572Z", "url": "https://files.pythonhosted.org/packages/de/db/193af391b8ff97e454674be29ae54948e65cc943f89cc372f14687e37aaa/tensorflow_onmttok_ops-0.1.1-cp36-cp36m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b633a20e3e428bb9217951734c609c0c", "sha256": "671bbdc5d22b86d8d544a732c883e582dd597082288bd3b7333706d81944de70"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.1.1-cp37-cp37m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "b633a20e3e428bb9217951734c609c0c", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": null, "size": 141407, "upload_time": "2020-02-14T15:30:12", "upload_time_iso_8601": "2020-02-14T15:30:12.577753Z", "url": "https://files.pythonhosted.org/packages/3d/57/1abaa31c2e8094f8e95d237c23516111059bfef34cfde4c7a7bdf030c371/tensorflow_onmttok_ops-0.1.1-cp37-cp37m-manylinux2014_x86_64.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "69c39680481f30d20583946b5ace85dc", "sha256": "1408ea28a621bc5852137d791bb8418e4f40105c49816a97f235199892f75f00"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.2.0-cp35-cp35m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "69c39680481f30d20583946b5ace85dc", "packagetype": "bdist_wheel", "python_version": "cp35", "requires_python": null, "size": 141402, "upload_time": "2020-02-17T02:16:51", "upload_time_iso_8601": "2020-02-17T02:16:51.516291Z", "url": "https://files.pythonhosted.org/packages/64/13/8f22bd4ce717caee9a734455dac2f59a7d279512601ef9893a428da4ecb5/tensorflow_onmttok_ops-0.2.0-cp35-cp35m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "76cd140b4d29be1711ad30ebb6e1684d", "sha256": "79387a52c2fefce94ee314ff227f3c0bcd8578dd0551b4fa9b411f91e1a0241f"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.2.0-cp36-cp36m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "76cd140b4d29be1711ad30ebb6e1684d", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": null, "size": 141401, "upload_time": "2020-02-17T02:20:21", "upload_time_iso_8601": "2020-02-17T02:20:21.902400Z", "url": "https://files.pythonhosted.org/packages/cf/6d/69414fde3087549a7dbdbc1c821e456ebe5660d9e30979840f353e0488e4/tensorflow_onmttok_ops-0.2.0-cp36-cp36m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9651ab654d188d58d6dd891d2cf855ea", "sha256": "32e4df240ba438bced3a7e2f602272c1891b950bb665a5020a89495b97de02c5"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.2.0-cp37-cp37m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "9651ab654d188d58d6dd891d2cf855ea", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": null, "size": 141406, "upload_time": "2020-02-17T02:16:27", "upload_time_iso_8601": "2020-02-17T02:16:27.369651Z", "url": "https://files.pythonhosted.org/packages/fb/49/d78f5acb98b02ffa440aded715593da3dc1b721a9f368dee1182b5a42ad7/tensorflow_onmttok_ops-0.2.0-cp37-cp37m-manylinux2014_x86_64.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "8e8ffb3f46f668353bef90342460bf24", "sha256": "6620fcaecb62e6888297ae4cf6569b1ec497d56d9df75b9600860ca0d4ba88f0"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.2.1-cp35-cp35m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "8e8ffb3f46f668353bef90342460bf24", "packagetype": "bdist_wheel", "python_version": "cp35", "requires_python": null, "size": 143336, "upload_time": "2020-02-17T15:58:24", "upload_time_iso_8601": "2020-02-17T15:58:24.746785Z", "url": "https://files.pythonhosted.org/packages/ab/cb/037a281b029664fb9e428f0650a799d416cadddefb853b3da0e7f1915cd2/tensorflow_onmttok_ops-0.2.1-cp35-cp35m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c851b5addaff9e77dc7821105055607", "sha256": "d25e5a25de062620d799b6247dc852cf36d62f7afb165f8dac713426b052509b"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.2.1-cp36-cp36m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "7c851b5addaff9e77dc7821105055607", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": null, "size": 143333, "upload_time": "2020-02-17T15:58:20", "upload_time_iso_8601": "2020-02-17T15:58:20.284290Z", "url": "https://files.pythonhosted.org/packages/68/e1/2c05b98e443f3410aa4c919bec8aad322263dd3ddbbf17f23da6e8eb8563/tensorflow_onmttok_ops-0.2.1-cp36-cp36m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e5309fce065ec75c6cca6cb486d03076", "sha256": "c2cdd58d2f79720d40f1f1915bfbd981d7bbb1239df6587c9296828f2cf556b1"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.2.1-cp37-cp37m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "e5309fce065ec75c6cca6cb486d03076", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": null, "size": 143337, "upload_time": "2020-02-17T15:58:14", "upload_time_iso_8601": "2020-02-17T15:58:14.538788Z", "url": "https://files.pythonhosted.org/packages/85/73/551057a9cfad3e216e5fa138ecdc85b4c48e3d964ce1addc17497310d2cb/tensorflow_onmttok_ops-0.2.1-cp37-cp37m-manylinux2014_x86_64.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "17d789057184ef2e2883e992ebe33e12", "sha256": "51350ca628484fbff70c0df8a3a7094a82099438a803101149ac1ea76b90383e"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.3.0-cp35-cp35m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "17d789057184ef2e2883e992ebe33e12", "packagetype": "bdist_wheel", "python_version": "cp35", "requires_python": null, "size": 143218, "upload_time": "2020-02-18T15:03:58", "upload_time_iso_8601": "2020-02-18T15:03:58.683184Z", "url": "https://files.pythonhosted.org/packages/d8/b6/e9913deb2eb1a59e20d5f200dc100140aedcb4d48bd545fd0cfc67d84b49/tensorflow_onmttok_ops-0.3.0-cp35-cp35m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "51e0d8b2b0fb17819071e874c02fd7e7", "sha256": "e87cfc838e0b6fd511382578441217090daea768fb8dd07171461bb1830098e0"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.3.0-cp36-cp36m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "51e0d8b2b0fb17819071e874c02fd7e7", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": null, "size": 143222, "upload_time": "2020-02-18T15:04:05", "upload_time_iso_8601": "2020-02-18T15:04:05.612116Z", "url": "https://files.pythonhosted.org/packages/73/88/a26ee2f283104dfdd5c42a238d84adf011bbad7fde7cdf5e575eaf8af195/tensorflow_onmttok_ops-0.3.0-cp36-cp36m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c84c441601f886cfdef35f392b7f1a0", "sha256": "9b40b52e5173bebb3cc3e0e47c9c881c88152c16b8e3dcf8e5ebdac975c50e6c"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.3.0-cp37-cp37m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "7c84c441601f886cfdef35f392b7f1a0", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": null, "size": 143220, "upload_time": "2020-02-18T15:03:59", "upload_time_iso_8601": "2020-02-18T15:03:59.333823Z", "url": "https://files.pythonhosted.org/packages/74/de/7d922ccc7ecf8dcbe20ce504d0cb3e06985a5a30f2bf228935193535f5a3/tensorflow_onmttok_ops-0.3.0-cp37-cp37m-manylinux2014_x86_64.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "17d789057184ef2e2883e992ebe33e12", "sha256": "51350ca628484fbff70c0df8a3a7094a82099438a803101149ac1ea76b90383e"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.3.0-cp35-cp35m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "17d789057184ef2e2883e992ebe33e12", "packagetype": "bdist_wheel", "python_version": "cp35", "requires_python": null, "size": 143218, "upload_time": "2020-02-18T15:03:58", "upload_time_iso_8601": "2020-02-18T15:03:58.683184Z", "url": "https://files.pythonhosted.org/packages/d8/b6/e9913deb2eb1a59e20d5f200dc100140aedcb4d48bd545fd0cfc67d84b49/tensorflow_onmttok_ops-0.3.0-cp35-cp35m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "51e0d8b2b0fb17819071e874c02fd7e7", "sha256": "e87cfc838e0b6fd511382578441217090daea768fb8dd07171461bb1830098e0"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.3.0-cp36-cp36m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "51e0d8b2b0fb17819071e874c02fd7e7", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": null, "size": 143222, "upload_time": "2020-02-18T15:04:05", "upload_time_iso_8601": "2020-02-18T15:04:05.612116Z", "url": "https://files.pythonhosted.org/packages/73/88/a26ee2f283104dfdd5c42a238d84adf011bbad7fde7cdf5e575eaf8af195/tensorflow_onmttok_ops-0.3.0-cp36-cp36m-manylinux2014_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7c84c441601f886cfdef35f392b7f1a0", "sha256": "9b40b52e5173bebb3cc3e0e47c9c881c88152c16b8e3dcf8e5ebdac975c50e6c"}, "downloads": -1, "filename": "tensorflow_onmttok_ops-0.3.0-cp37-cp37m-manylinux2014_x86_64.whl", "has_sig": false, "md5_digest": "7c84c441601f886cfdef35f392b7f1a0", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": null, "size": 143220, "upload_time": "2020-02-18T15:03:59", "upload_time_iso_8601": "2020-02-18T15:03:59.333823Z", "url": "https://files.pythonhosted.org/packages/74/de/7d922ccc7ecf8dcbe20ce504d0cb3e06985a5a30f2bf228935193535f5a3/tensorflow_onmttok_ops-0.3.0-cp37-cp37m-manylinux2014_x86_64.whl", "yanked": false}], "timestamp": "Fri May  8 02:56:08 2020"}