{"info": {"author": "Frederik Faye", "author_email": "frederikfaye@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# DeepCalo\n### Python 3 package for doing deep supervised learning on ATLAS data, using Keras\nAuthor: Frederik Faye, The Niels Bohr Institute, 2019\n\n## What is DeepCalo?\nThis package allows you to build, train and tune convolutional neural network (CNN) models using Keras with any backend.\n\nYou can also integrate models for processing non-image data, such as scalars and sequences.\nThe models that can be built have been designed specifically with the ATLAS detector in mind, but you can also just use the framework and all its nice features for any Keras-based project.\n\n## Why should you use it?\n* All hyperparameters are set through a single Python dictionary, making it very easy to experiment with different models.\n* Extensive logging is automatically created for each run of a model, including hyperparameters, plots of model architectures, and weights of the model during training, making it easy to keep track of what you have tried, and what came of it.\n* A lot of advanced features are supported (such as cyclic learning rate schedules, grouped convolutions, DropBlock regularization, squeeze and excite modules, non-standard optimizers such as Yogi and Padam, and much more), and it is easy to add new ones.\n\n### Table of Content\n- [Installation](#installation)\n- [Dependencies](#dependencies)\n- [Usage](#usage)\n    - [Quick start for using generic data](#quickstart)\n    - [Quick start for using ATLAS data](#atlasdata)\n- [Model architectures](#archs)\n    - [CNN](#arch_cnn)\n    - [Network in network](#arch_network_in_network)\n    - [Top](#arch_top)\n    - [Scalar net](#arch_scalar_net)\n    - [FiLM generator](#arch_film_gen)\n    - [Track net](#arch_track_net)\n    - [Gate net](#arch_gate_net)\n    - [Combined](#arch_combined)\n- [Documentation](#docs)\n    - [`data`](#doc_data)\n    - [`params`](#doc_params)\n      - [Keys concerning submodels](#doc_submodels)\n    - [`dirs`](#doc_dirs)\n\n<a name=\"installation\"></a>\n## Installation\n```bash\npip install deepcalo\n```\n\n<a name=\"dependencies\"></a>\n## Dependencies\n```python\nnumpy, pandas, matplotlib, h5py, joblib, keras, tensorflow, keras-drop-block\n```\n\nIf you want to be able to plot the graph of your model, please install `pydot` and `graphviz` (if possible, use `conda install python-graphviz` for `graphviz`).\n\n<a name=\"usage\"></a>\n## Usage\n\n<a name=\"quickstart\"></a>\n### Quick start for using generic data\nThe main functionality lies in the so-called model container, which can be imported as\n```python\nfrom deepcalo import ModelContainer\n```\nSee the [documentation](#docs) below for all the details. However, often an example is a better way of learning. Some examples are found in the `demos` folder.\n\nDownload and run the MNIST tutorial:\n```bash\npython mnist_tutorial.py --exp_dir ./my_mnist_experiment/ -v 1\n```\nThis will train a tiny CNN for a single epoch to discriminate between the digits of the MNIST dataset, which should reach $`>95\\%`$ test accuracy after its first epoch.\n\nOpen the script to see what is going on; the important part is the hyperparameter section. Try playing around with the parameters to see if you can find a network that does better! Also have a look at the contents of the `logs` folder in the experiment directory (`./my_mnist_experiment/`) to see some of the nice logging features this framework has to offer.\n\nThere are a lot more hyperparameters to play around with. See the [documentation](#doc_params) for what is possible.\n\n<a name=\"atlasdata\"></a>\n### Quick start for using ATLAS data\nThe `demos/atlas_specific_usecases` folder contains examples of how to train a model, or load and use an already trained model, both using ATLAS data.\nSee the README in the `demos/atlas_specific_usecases` folder for more details.\n\n**A quick overview of how to construct the recommended models for doing energy regression with this package are described in [this pdf](#https://gitlab.com/ffaye/deepcalo/blob/master/demos/atlas_specific_usecases/train_recommended_models/recipe.pdf).**\n\nThe `demos/atlas_specific_usecases` folder also contains an example of how to carry out a hyperparameter search (using the Bayesian optimization of [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)), using this framework.\n\nAll these examples use ATLAS simulation data to do energy regression (although using these models for PID is entirely possible). The data used herein can be downloaded from the lxplus (CERNBox) directory `/eos/user/l/lehrke/Data/Data/2019-09-26/` (which should be visible to all CERN members).\n\nThe scripts uses the function `deepcalo.utils.load_atlas_data` function, which is tailored to these datasets. If need be, you can modify this function to work with your data, however note that this framework uses the `'channels_last'` format, which is the standard in Keras.\n\n<a name=\"archs\"></a>\n## Model architectures\nThe following is a quick tour of the different out-of-the-box models available. Each model is made for a different kind of input, e.g., images, scalar variables, tracks, or the output from other models.\n\nAll models except the [top](#arch_top) are optional to use. However, models are tied to their input in such a way that if for instance a `tracks` dataset is present in the suppplied [data](#doc_data), the [track net](#arch_track_net) will be integrated into the [combined model](#arch_combined).\n\nYou can find information about how to set the hyperparameters of these models in the [documentation](#doc_params), where each model has its own section.\n\n<a name=\"arch_cnn\"></a>\n### CNN\nBelow, an illustration of the default CNN architecture can be seen. It is comprised of blocks. For all but the first block, a block begins with downsampling and the number of feature maps being doubled.\nThe tuple underneath the input denotes the size of the input (here height, width, channels).\nNote that normalization, the activation function, downsampling and global average pooling can all be turned on or off.\n\nThe output of the CNN is passed on to either the [top](#arch_top), or to the [network in network](#arch_network_in_network).\n\n<p align=\"center\">\n  <img src=\"images/cnn_arch.png\" width=\"350\">\n</p>\n\n<a name=\"arch_network_in_network\"></a>\n### Network in network\n\nThis model takes the outputted feature maps of the [CNN](#arch_cnn) (without global average pooling applied), and applies a [Network in Network](https://arxiv.org/abs/1312.4400) to it, which consists of a series of $`1\\times 1`$ convolutions, typically followed by global average pooling.\n\nThis makes it possible to make CNN architectures without a dense top (e.g. the [AllConv Net](https://arxiv.org/abs/1412.6806)). For instance, if you want to train a CNN with a network in network classifier to be able to distinguish between five categories, make the final $`1 \\times 1`$ convolution in the network in network submodel output five feature maps, apply global average pooling, and set the [top](#arch_top) to have no units (`units:[]`) and `final_activation:'softmax'`.\n\n<p align=\"center\">\n  <img src=\"images/network_in_network_arch.png\" width=\"350\">\n</p>\n\n<a name=\"arch_top\"></a>\n### Top\nThe top model is a simple, dense neural network that takes as input the concatenated outputs of other models, and gives a final output, which can be any 1D size $`\\geq 1`$.\n\n<p align=\"center\">\n  <img src=\"images/top_arch.png\" width=\"350\">\n</p>\n\n<a name=\"arch_scalar_net\"></a>\n### Scalar net\nThe scalar net is again a simple, dense network that processes any scalar variables you may want to include. Its output can be connected to either the [top](#arch_top), the [FiLM generator](#arch_film_gen), or both.\n\n<p align=\"center\">\n  <img src=\"images/scalar_net_arch.png\" width=\"350\">\n</p>\n\n<a name=\"arch_film_gen\"></a>\n### FiLM generator\nThe FiLM generator is a nice way of conditioning the CNN with scalar variables. You can read a good introduction to the technique [here](https://distill.pub/2018/feature-wise-transformations/).\n\nThe FiLM generator can take inputs from both the [scalar net](#arch_scalar_net) and the [track net](#arch_track_net). Its output modulates the [CNN](#arch_cnn).\n\n<p align=\"center\">\n  <img src=\"images/film_gen_arch.png\" width=\"350\">\n</p>\n\n<a name=\"arch_track_net\"></a>\n### Track net\n\nThis model takes the (varying) number of track vectors for a datapoint as input and spits out a fixed size representation of that datapoint, which is then passed on to the [top](#arch_top), the [FiLM generator](#arch_film_gen), or both.\n\nAs the order in which we give our model the track vectors for a datapoint carries no information, the permutation invariant method of [Deep Sets](https://arxiv.org/abs/1703.06114) has been used.\n\nThe $`T`$ in the shape of $`X_{\\mathrm{track}}`$ is the largest number of track vectors of any datapoint in the dataset, where zero-padding has been used if the actual number of tracks for a given datapoint is smaller than $`T`$.\n\nNote that right now, the aggregation part of the track net is a simple sum, as in the [Deep Sets](https://arxiv.org/abs/1703.06114) paper.\n\n<p align=\"center\">\n  <img src=\"images/track_net_arch.png\" width=\"350\">\n</p>\n\n<a name=\"arch_gate_net\"></a>\n### Gate net\nThe [CNN](#arch_cnn) architecture can be expanded to include images, that contain cell information other than just the energy, by using the gate net. This was originally motivated by the inclusion of when in time each cell determined its signal to be, in order to help mitigate out-of-time pileup, but images containing other cell information can be included instead; for instance, the noise of each cell has proven useful for energy regression.\n\nThe cell images containing the extra cell information is collected in an image tensor $`X_{\\mathrm{gate-img}}`$ of the same resolution and dimension as the standard cell image tensor $`X_{\\mathrm{img}}`$.\n$`X_{\\mathrm{gate-img}}`$ is first passed through a gating mechanism (the gate net), which outputs a real number between zero and one for each pixel in each channel. These numbers are then merged with $`X_{\\mathrm{img}}`$, either by element-wise multiplication and then concatenation along the channel axis, or just by element-wise multiplication. The idea is that the element-wise multiplication allows the network to modulate the values of $`X_{\\mathrm{img}}`$ according to the information stored in $`X_{\\mathrm{gate-img}}`$.\nThe resulting, merged tensor is then given as the input to the [CNN](#arch_cnn) (in the stead of $`X_{\\mathrm{img}}`$).\n\n<p align=\"center\">\n  <img src=\"images/gate_net_arch.png\" width=\"450\">\n</p>\n\n<a name=\"arch_combined\"></a>\n### Combined\nIn the final illustration below, you can see how the models all fit together.\n\n<p align=\"center\">\n  <img src=\"images/combined_arch.png\" width=\"600\">\n</p>\n\n\n<a name=\"docs\"></a>\n## Documentation\nThe heart of DeepCalo is the `ModelContainer` class, found in `deepcalo.model_container`, which is documented below.\n\n```python\nclass ModelContainer:\n    \"\"\"\n    A class for organizing the creation, training and evaluation of models.\n    \"\"\"\n\n    def __init__(self, data, params, dirs, save_figs=True, verbose=True):\n```\n### Arguments\n\n<a name=\"doc_data\"></a>\n#### data : *dict*\nDictionary of training, validation and (optionally) test data, organized according to the type of data.\n\n  This dictionary must have either two or three keys, being `train` and `val`, or `train`, `val`, and `test`. Each of these keys points to another *dict* containing different kinds of data. The keys of these dictionaries can be any or all of `'images'`, `'scalars'`, `'tracks'`, `'sample_weights'` and `'targets'`. The documentation for what each of these keys refers to is given below. Note that `'images'`, `'scalars'` and `'tracks'` are considered inputs, and at least one of them must be non-empty.\n\n  Note that the shapes of the datasets contained in `data` are used in the model creation (but a single datapoint is enough to do so).\n\n**images** : *dict of ndarrays*\n- If `'images'` is a key in `data[set_name]` and `data[set_name]['images']` is non-empty (where `set_name` can be either `'train'`, `'val'` or `'test'`), a [CNN](#arch_cnn) will be created and used to process these images.\n\n  To allow you to keep track of different types of images (intended to be used for different kinds of things), the value corresponding to the `'images'` key of `data` is also a *dict*.\n\n  Say you have two different kinds of images that you would like to have processed by the CNN. Let's call them `'low_res_imgs'` and `'high_res_imgs'` (i.e., these are the keys in the `data[set_name]['images']` dictionary), each being 4D numpy array with shape $`(N,H,W,C)`$, where $`H`$ and $`W`$ are different for the two types of images. You can then use the `upsampling` functionality (see [`params`](#doc_params)) to upsample them to a common resolution, so that they can be processed together in the CNN.\n\n  If you want to include and process [gate images](#arch_gate_net), these should be named the exact same as the cells they correspond to, with `'gate_'` preprended; using the example from above, the `data[set_name]['images']` dictionary would then have the four keys  `'low_res_imgs'`, `'gate_low_res_imgs'`, `'high_res_imgs'` and `'gate_high_res_imgs'`. Only if images are named in this manner will a submodel for processing the gate images be created and used.\n\n**scalars** : *ndarray*\n- If `'scalars'` is a key in `data[set_name]` and `data[set_name]['scalars']` is non-empty (where `set_name` can be either `'train'`, `'val'` or `'test'`), a [scalar net](#arch_scalar_net) will be created and used to process these scalars.\n\n  The scalars should come in the form of a $`(N,S)`$ numpy array, where $`N`$ is the number of datapoints in the set, and where $`S`$ is the number of scalars.\n\n**tracks** : *ndarray*\n- If `'tracks'` is a key in `data[set_name]` and `data[set_name]['tracks']` is non-empty (where `set_name` can be either `'train'`, `'val'` or `'test'`), a [track net](#arch_track_net) will be created and used to process these tracks.\n\n  The track vectors should come in the form of a numpy array of shape $`(N,T,F)`$, where $`N`$ is the number of datapoints, $`T`$ is the maximum number of tracks, and where $`F`$ is the length of each track vector, i.e., the number of features.\n\n  As each datapoint can have a variable number of track vectors associated with it, datapoints with $`t<T`$ track vectors should be zero-padded (see `deepcalo.utils.load_atlas_data` for an example of how to zero-pad). All tracks having exclusively zeros as all its features are masked out internally in the track net, and will therefore not contribute to the output of track net.\n\n**multiply_output_with** : *ndarray*\n- If `'multiply_output_with'` is a key in `data[set_name]` and `data[set_name]['multiply_output_with']` is non-empty (where `set_name` can be either `'train'`, `'val'` or `'test'`), then the values of the `'multiply_output_with'` array (which should be 1D) will be multiplied with the values given by the output neuron(s) of the model, for each datapoint. This product is then the final output of the model.\n\n  For instance, if our target is an energy, and the `'multiply_output_with'` array contains the accordion energy, this would make the model predict the correction to the accordion energy, instead of the energy itself.\n\n**sample_weights** : *ndarray*\n- If `'sample_weights'` is a key in `data[set_name]` and `data[set_name]['sample_weights']` is non-empty (where `set_name` can be either `'train'`, `'val'` or `'test'`), then these sample weights will be used in all loss functions and metrics (both during training and evaluation).\n\n**targets** : *ndarray*\n- Contains the targets (or labels) of the task. Is always required. Its shape must match that of the final output of the constructed model.\n\n**Example of valid `data`:**\n```python\nimport numpy as np\n\nset_names = ['train', 'val', 'test'] # Could also just be ['train', 'val']\n\n# Number of datapoints for each set\nn_points = {set_name:int(1e3) for set_name in set_names}\n\n# Dimension of images, which we will call 'example_imgs'\nh,w,c = 14,25,2\n\n# Number of scalars\nn_scalars = 7\n\n# Create the data\ndata = {set_name:{'images':{'example_imgs':np.random.randn(n_points[set_name],h,w,c)},\n                  'scalars':np.random.randn(n_points[set_name],n_scalars),\n                  'tracks':{}, # Is empty, so track_net won't be created and used\n                  'targets':np.random.randn(n_points[set_name]) # Here, the target is a single number per datapoint\n                 } for set_name in set_names}\n```\n\n\n<a name=\"doc_params\"></a>\n#### params : *dict*\n\nThis dictionary contains all the hyperparameters used in constructing, training and evaluating the model. Default parameters can be gotten from the function `deepcalo.utils.get_default_params`.\n\nWhen a dictionary key is referenced below, what is actually meant is the\nvalue corresponding to that key. For instance, although the key `'epochs'`\nis of course a *str*, the documentation below concerns itself with the value\nof this key, which in this case is an *int*.\n\n**epochs** : *int*\n- Number of epochs to train for. If `use_earlystopping` is set to\n`True`, training may stop prior to completing the chosen number of\nepochs.\n\n**batch_size** : *int*\n- Mini-batch size. Note that if several GPUs are used, the mini-batch\n  will be evenly divided among them.\n\n**loss** : *str*\n- Any Keras loss function name. See `get_loss_function` in\n`model_building_functions.py` for implemented custom loss functions,\nas well as how to implement your own.\n\n**metrics** : *list of strs or None*\n- Can be the name of any metric recognized by Keras. This (or these)\nmetric(s) will be shown during training, as well as in the final\nevaluation.\nNote that if a *hp_search* is carried out, the last entry of the list\nwill be the evaluation function used by the Gaussian process\nhyperparameter search. If an empty list or `None`, the `loss` will be\nthe evaluation function used by the Gaussian process hyperparameter search.\n\n**optimizer** : *str or config dict*\n- Which optimizer to use. Any Keras optimizer can be used.\n\n  If you don't want to simply use the defaults parameters of the\n  chosen optimizer, instead give a *config dict*. See [Explanation of\n  *str or config dict*](#doc_config_dict).\n\n**lr_finder** : *dict*\n- Dictionary of learning rate finder (from [Smith, 2015](https://arxiv.org/abs/1506.01186)) parameters.\n  * The `'use'` key is a *bool* deciding whether or not to use the\n  learning rate finder as implemented in `custom_classes.py`.\n  * The `'scan_range'` is a *list* containing the minimum and maximum\n  learning rate to be scanned over.\n  * The `'epochs'` key is an *int* setting the number of epochs to use in the scan.\n  1-4 epochs is typically enough, depending on the size of the training set.\n  * The `'scale'` can be either `'linear'` (default) or `'log'`, resulting in the\n  learning rates being scanned linearly or logarithmically, respectively.\n  * If `'prompt_for_input'` is `True`, the user will be asked to input a\n  range within which the cyclical learning rate schedule (see below)\n  should vary in between upon completing the learning rate finder\n  scan.\n\n**lr_schedule** : *dict*\n- Dictionary of learning rate schedule parameters.\n  * The `'name'` key can be either `None` (when no learning rate schedule\n  will be used), `'CLR'` ([Smith, 2015](https://arxiv.org/abs/1506.01186)),\n  `'OneCycle'` ([Smith et al., 2017](https://arxiv.org/abs/1708.07120)) or `'SGDR'` ([Loshchilov and Hutter, 2017](https://arxiv.org/abs/1608.03983)).\n  * The `'range'` key should be a list with two floats, the first one being the minimum learning rate, and the second being the maximum learning rate.\n  * The `'step_size_factor'` key differs in meaning for the possible learning rate schedules: If $`s`$ is the `'step_size_factor'` value and $`k`$ is the number of mini-batch updates per epoch $`e`$, then for\n   - `'CLR'`, the step size of the cycle (i.e., the number of mini-batch updates per half a cycle) is given by $`ks`$,\n   - `'OneCycle'`, the step size $`k\\times e/s`$, means that $`s`$ is the number of half cycles, including the cooldown to one hundredth the base learning rate. E.g., if $`s=2.25`$, the last $`\\frac{0.25}{2.25}`$ of the total number of mini-batch updates will be used for the cooldown,\n   - `'SGDR'`, $`s`$ is simply the initial number of epochs in a cycle.\n\n Note that `cyclical_momentum==True` in `'OneCycle'` will only work with optimizers that have a `momentum` attribute (such as `'SGD'`).\n\n Besides the above mentioned, keyword arguments specific to each learning rate schedule class can be passed by using the `'kwargs'` key, which should have a dictionary of keyword arguments as its value.\n\n**auto_lr** : *bool*\n- Whether to use the function `get_auto_lr` in\n`model_building_functions.py` that automatically sets a good learning\nrate based on the chosen optimizer and the batch size, taking the\nlearning rate to be propertional to the square root of the batch\nsize. The constant of proportionality varies from optimizer to\noptimizer, and probably from problem to problem - use the learning\nrate finder to find out which constant is suitable for your problem.\n\n**use_earlystopping** : *bool*\n- Use the Keras EarlyStopping callback with `min_delta=0.001` and\n`patience=150` (these can be changed in `model_container.py`).\n\n**restore_best_weights** : *bool*\n- Restore the best weights found during training before evaluating.\n\n**pretrained_model** : *dict*\n- Dictionary of parameters for using (parts of) pretrained models.\n  * The `'use'` key is a boolean deciding whether or not to load\n  pretrained weights.\n  * The `'weights_path'` is the path to the weights\n  of the pretrained network. If `'params_path'` is `None`, the\n  parameters for the pretrained network is assumed to be in the parent\n  folder of the `'weights_path'`.\n  * `'layers_to_load'` is a *list* with the Keras names of the layers (or\n  submodels) whose weights should be transferred from the pretrained\n  model to the one at hand. These names must refer to the same\n  structure in both the pretrained model and in the model at hand.\n  * `'freeze_loaded_layers'` can be either a boolean (when, if `True`,\n  all layers listed in `'layers_to_load'` will be frozen, or not, if\n  `False`) or a *list* of *bool*s with the same length as\n  `'layers_to_load'` (when the first boolean in\n  `'freeze_loaded_layers'` answers whether to freeze the first layer\n  given by `'layers_to_load'` or not, etc.).\n\n**n_gpus** : *int*\n- Number of GPUs used in training. Can typically be inferred from the visible GPUs.\n\n**data_generator** : *dict*\n- Parameters concerning a DataGenerator, which is helpful if your data does not fit in memory, as it loads data in batches. Its current implementation, which is designed to work in conjunction with `deepcalo.utils.load_atlas_data`, can be seen in `deepcalo.data_generator`.\n\n  * The `'use'` key is a *bool* deciding whether to use a DataGenerator.\n  * The `'n_workers'` key is an *int* that sets the number of CPU workers to use for preparing batches.\n  * The `'max_queue_size'` key is an *int* that sets the upper limit to how many batches can be ready at any one time.\n  * The `'path'` key is a *str* that gives the path to the dataset.\n  * The `'n_points'` key is a *dict* with the keys `'train'` and `'val'` (or `'train'`, `'val'` and `'test'`), whose corresponding values is an *int* given the number of datapoints in each set.\n  * The `'load_kwargs'` key is a *dict* containing arguments to be passed to the `__init__` of the `DataGenerator` class.\n\n**usampling** : *dict*\n- Dictionary of parameters for upsampling input images inside the\nnetwork. This can be useful if the ability to downsample (which\nintroduces translational invariance) is important but the input\nimages are small.\n  * The `'use'` key is a boolean deciding whether to upsample or not.\n  `'wanted_size'` refers to the size that all images should be\n  upsampled to before being concatenated.\n  * The `'interpolation'` argument is passed to the Keras layer `UpSample2D`.\n\n  After upsampling, the cell image tensor is normalized so as to\n  maintain the same amount of energy overall, but now spread out over\n  the upsampling pixels.\n\n<a name=\"doc_submodels\"></a>\n##### Keys concerning all submodels:\n**initialization** : *str or config dict*\n- Initialization of the parameters of the submodel. Can be any\ninitializer recognized by Keras.\n\n  If you don't want to simply use the defaults parameters of the\n  chosen initializer, instead give a *config dict*. See [Explanation\n  of *str or config dict*](#doc_config_dict).\n\n**normalization** : *str or config dict or None*\n- Normalization layer. If not `None`, the chosen normalization layer is\nplaced after every dense or convolutional layer in the submodel,\ni.e., before an activation function.\n\n  Can be any of `'batch'`, `'layer'`, `'instance'` or `'group'`.\n  Note that the last three are implemented through a group\n  normalization layer (which encompass the layer and instance\n  normalization). This means that the name of the normalization\n  layer when using `keras.utils.plot_model` will be the name of a\n  group normalization layer when using any of the last three.\n\n  If you don't want to simply use the defaults parameters of the\n  chosen normalization layer, instead give a *config dict*. See\n  [Explanation of *str or config dict*](#doc_config_dict).\n\n**activation** : *str or config dict or None*\n- Activation function of all dense or convolutional layers in the\nsubmodel, except for the very last one, if a `final_activation`\nvariable is present.\n\n  Can be any of `'relu'`, `'leakyrelu'`, `'prelu'`, `'elu'` or\n  `'swish'`.\n  See `get_activation` in `model_building_functions.py` for examples\n  of implementations of custom activation functions.\n\n  Is placed right after every normalization layer\n  in the submodel, or - if `normalization` is `None`, right after\n  every dense or convolutional layer in the submodel.\n\n  If you don't want to simply use the defaults parameters of the\n  chosen activation, instead give a *config dict*. See [Explanation of\n  *str or config dict*](#doc_config_dict).\n\n**layer_reg** : *dict with None or strs or config dicts as values*\n- Layer regularization to be applied to all dense or convolutional\nlayers in the submodel. This dict collects `kernel_regularizer`s,\n`bias_regularizer`s, `activity_regularizer`s, `kernel_constraint`s\nand `bias_constraint`s to be applied.\n\n  If you don't want to simply use the defaults parameters of the\n  chosen regularizer, instead give a *config dict*. See [Explanation\n  of *str or config dict*](#doc_config_dict).\n\n  An example of what is allowed:\n  ```python\n  {'kernel_regularizer':'l2',\n  'bias_regularizer':{'class_name':'l1',\n                      'config':{'l':1e-5}},\n  'activity_regularizer':None,\n  'kernel_constraint':{'class_name':'max_norm',\n                       'config':{'max_value':3}},\n  'bias_constraint':'max_norm'}\n  ```\n\n  Any of these keys can be left out to invoke the default value of\n  `None`. If the *dict* is empty, no layer regularization will be\n  applied.\n\n**dropout** : *float or dict or None*\n- Arguments to be passed to either dropout layers, in the case of\ndense layers (pass the rate as a float), or dropblock layers, in the\ncase of convolutional layers (pass a dict to be unpacked into the\ndropblock layers - see the [dropblock documentation](https://github.com/MLearing/Keras-DropBlock/blob/master/keras_drop_block/drop_block.py) for what to pass).\nThe dropout or dropblock layers will be inserted immediately after\neach dense or convolutional layer.\nIf `None`, no dropout or dropblock layers will be added.\n\n##### Keys concerning submodel `top`:\nSubmodel for collecting inputs (e.g. from other submodels) and giving\nthe output of the full model.\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**units** : *list of ints*\n- List with the number of hidden units in each dense layer in the top\nas elements.\nThis includes the output neuron(s), so the last element in `units`\nshould be the number of desired outputs.\nIf the input to the top has the same shape as the target, it is also possible\nfor `units` to be an empty list, when the final output will be the\n`final_activation` (see below) applied to the input to `top`.\n\n**final_activation** : *str*\n- Activation function to apply to the last dense layer. E.g. for\nbinary classification, use `'sigmoid'`, and use `'linear'` or `None`\n(or `'relu'` to enforce non-negativity) for regression.\n\n##### Keys concerning submodel `cnn`:\nSubmodel for processing images. Will only be used if `img_names` is not None.\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**cnn_type** : *str*\n- The type of CNN that will be constructed. To use the CNN illustrated\n[here](#arch_cnn), set to `'simple'`. Set to `'res'` to use residual\nblocks, as in [He et al., 2016](https://arxiv.org/abs/1603.05027).\nSetting cnn_type to some other string is a good way to implement\nother types of CNNs, which are then integrated into the framework.\nFor instance, to use the ResNet18 of keras_contrib, set to e.g. `'res18'` - see `model_building_functions.py` under `get_cnn` for how this is\ndone.\n\n**conv_dim** : *int*\n- One of `2` or `3`. Whether to use 2D or 3D convolutions.\n\n**block_depths** : *list* of *int*s\n- List with number of convolutional layers for each block as elements.\nSee the illustration [here](#arch_cnn) for what constitutes a block.\n\n  Note that is `cnn_type` is `'res'`, two convolutional layers are\n  used per *int*, e.g. a `block_depth` value of `[1,2,2,2,2]` will\n  result in a CNN with 18 convolutional layers, wheres the CNN would\n  only have 9 convolutional layers if `cnn_type` had been `'simple'`.\n\n**n_init_filters** : *int*\n- How many filters should be used in the first convolutional layer.\n\n**init_kernel_size** : *int* or *tuple*\n- Kernel size of the first convolutional layer.\n\n  If and *int* is given and `conv_dim` is `2`, a kernel size of\n  `(init_kernel_size,init_kernel_size)` is used. If `conv_dim` is\n  instead `3`, a kernel size of `(init_kernel_size,init_kernel_size,2)`\n  is used.\n  If a tuple is given, its length must equal `conv_dim`.\n\n**rest_kernel_size** : *int or tuple*\n- Kernel size of all but the first convolutional layer.\n\n  If and *int* is given and `conv_dim` is `2`, a kernel size of\n  `(init_kernel_size,init_kernel_size)` is used. If `conv_dim` is\n  instead `3`, a kernel size of `(init_kernel_size,init_kernel_size,2)`\n  is used.\n  If a tuple is given, its length must equal `conv_dim`.\n\n**init_strides** : *int* or *tuple*\n- Strides of the first convolutional layer. Default is `1`.\n\n**rest_strides** : *int or tuple*\n- Strides of all but the first convolutional layer. Default is `1`.\n\n**cardinality** : *int*\n- As in [Xie et al., 2016](https://arxiv.org/abs/1611.05431), i.e., grouped convolutions (without the bottleneck using $`1\\times 1 `$ convolutions) will be used instead of the normal convolutions when `cardinality > 1`. Only supported for 2D convolutions.\n\n**use_squeeze_and_excite** : *bool*\n- Whether to use the squeeze and excite block from [Hu et al., 2017](https://arxiv.org/abs/1709.01507). For the `'simple'` `cnn_type` it will be inserted after the activation function (which comes after the normalization layer). For the `'res'` `cnn_type` it will be inserted right before the addition of the skip-connection.\n\n**squeeze_and_excite_ratio** : *int*\n- Ratio to use in squeeze and excite module (see [Hu et al., 2017](https://arxiv.org/abs/1709.01507)), if `use_squeeze_and_excite` is `True`. The ratio should never be less than the number of incoming channels, meaning that one should set `n_init_filters >= ratio` if `use_squeeze_and_excite` is `True`.\n\n**globalavgpool** : *bool*\n- Whether to use global average pooling in the end of the CNN.\n\n**downsampling** : *str or None*\n- One of `None` (no downsampling is used), `'avgpool'` (with\n`pool_size=2`), `'maxpool'` (with `pool_size=2`), or `'strided'`\n(when strided convolutions with stride and kernel size of 2 is used\nto downsample).\n\n  When one dimension is more than 1.5 times larger than another\n  dimension, that (larger) dimension will be downsampling such that it\n  is reduced by a factor of 3, instead of 2. This can be changed in\n  `get_downsampling` in `model_building_functions.py`.\n\n**min_size_for_downsampling** : *int*\n- The minimum that any dimension over which convolutions are made (so\nexcluding samples and channels dimensions) must be if downsampling\nis to take place. This is to prevent downsampling down to too small\nimages.\n\n  E.g., if 2D downsampling is attempted on a `(None,7,6,4)` image\n  tensor while `min_size_for_downsampling` is `6`, the downsampling\n  goes through and the result would be `(None,3,3,4)`. If, on the\n  other hand, `min_size_for_downsampling` was `7`, the third dimension\n  of the image tensor would be too small, and no downsampling would\n  take place.\n\n##### Keys concerning submodel `network_in_network`:\nSubmodel for applying network in network ($`1\\times 1`$ convolutions) to the\noutput of the `cnn`. Will only be used if `img_names` is not None.\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**use** : *bool*\n- Whether to use the network in network model.\n\n**units** : *list of ints*\n- List with the number of filters for each convolutional layer as elements.\n\n**globalavgpool** : *bool*\n- Whether to use global average pooling in the end of the `network_in_network`.\n\n##### Keys concerning submodel `scalar_net`:\nSubmodel for processing scalar variables. Will only be used if `scalar_names` is not None.\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**units** : *list of ints*\n- List with the number of hidden units in each dense layer as\nelements. If empty, the input is passed on without any processing.\n\n**strides** : *int* or *tuple*\n- Strides used in the convolutional layers. Default is `1`.\n\n**connect_to** : *list of strs*\n- Which other submodels should receive the output of `scalar_net` as\n(part of) their input. Can contain either `'top'` and/or\n`'FiLM_gen'`. It can in principle also be empty, but you should\nrather turn off the use of scalar variables by setting\n`scalar_names` to `None`.\n\n##### Keys concerning submodel `FiLM_gen`:\nSubmodel for modulating the feature maps of the `cnn` submodel, called\na FiLM generator. See [this](https://distill.pub/2018/feature-wise-transformations/) for an overview. Will only be used if the `connect_to` list of either of `scalar_net` or `track_net` contains `FiLM_gen` (and those submodels are used).\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**use** : *bool*\n- Whether to use the FiLM generator.\n\n**units** : *list of ints*\n- List with the number of hidden units in each dense layer as\nelements.\n\n##### Keys concerning submodel `track_net`:\nSubmodel for processing tracks. Will only be used if `use_tracks` is `True`.\nUses Deep Sets, see [Zaheer et al., 2017](https://arxiv.org/abs/1703.06114).\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**phi_units** : *list of ints*\n- List with the number of hidden units in each dense layer of the phi\nnetwork (see [Zaheer et al., 2017](https://arxiv.org/abs/1703.06114)) as elements.\nIf empty, the input is passed on to the rho network.\n\n**rho_units** : *list of ints*\n- List with the number of hidden units in each dense layer of the rho\nnetwork (see [Zaheer et al., 2017](https://arxiv.org/abs/1703.06114)) as elements.\nIf empty, the input is passed on without further processing.\n\n**connect_to** : *list of strs*\n- Which other submodels should receive the output of `track_net` as\n(part of) their input. Can contain either `'top'` and/or\n`'FiLM_gen'`. It can in principle also be empty, but you should\nrather turn off the use of tracks by setting `use_tracks` to\n`False`.\n\n##### Keys concerning submodel `gate_net`:\nSubmodel for processing to-be-gated images. Will only be used if any images in\nthe passed data dict starts with `gate_`.\n\nSee \"Keys concerning all submodels\" for keys `initialization`,\n`activation`, `normalization`, `layer_reg` and `dropout`.\n\n**units** : *list of ints*\n- List with the number of hidden units in each dense layer as\nelements. If empty, the input is passed on to `final_activation`.\n\n**use_res** : *bool*\n- Whether to use a residual connection over the dense layers given by\n`units`.\n\n**final_activation** : *str or config dict*\n- Activation function to apply to the last dense layer, or to the\ninput itself, in case `units` is empty.\n\n  The output of the chosen activation function should be in the range\n  [0;1].\n  Custom activations `'gauss'`, ``'gauss_f'`, `'pgauss'` and\n  `'pgauss_f'` have been implemented to use here. The \"p\" stands for\n  \"parametric\", while the \"f\" stands for \"flipped\".\n\n**final_activation_init** : *list*\n- List of initial weights for parametric activation functions\n'pgauss'` and `'pgauss_f'`. These contain a single parameter, namely\nthe width of the Gaussian, and so `final_activation_init` should\ncontain a single float, e.g., `final_activation_init` could be\n`[0.5]`.\n\n  If you don't want to simply use the defaults parameters of the\n  chosen activation, instead give a *config dict*. See [Explanation of\n  *str or config dict*](#doc_config_dict).\n\n##### Explanation of *str or config dict*:\nSay you want to use the `RandomNormal` initializer of Keras to\ninitialize the weights of some submodel. If you want to use the\ndefault value of the parameters of this class (`mean=0.0, stddev=0.05,\nseed=None`), you can simply give the *str* `'RandomNormal'` as the\nvalue for the `initialization` key described above.\nHowever, if you want to pass some other parameters to the class, you\ncan instead give a *config dict* as the value for the\n`initialization` key. A *config dict* must have two keys,\n`'class_name'` and `'config'`. The value corresponding to the\n`'class_name'` key should be a *str*, e.g. `'RandomNormal'`, while the\nvalue corresponding to the `'config'` key should be a dict containing\nthe keyword arguments you wish to pass to the class (an empty `'config'`\ndict will use the default values).\n\nYou could for example give the following as the value corresponding to\nthe `initialization` key:\n`{'class_name':'RandomNormal', 'config':{'stddev':1.0}}`\n\nSee the docs for `layer_reg` above for additional examples.\n\nFor a more technical definition of the *config dict*: It is what is\nreturned from `keras.utils.serialize_keras_object(keras_object)`\nwhere `keras_object` is the class instance you wish to create.\n\nIn most cases, aliases are set up such that multiple names for the\nsame class are valid, e.g. if you want to use batch normalization as\nnormalization in some submodel, you can pass any of `'batch'`,\n`'BatchNormalization'`, `'batch_norm'`, etc, as the `'class_name'`.\n\n<a name=\"doc_dirs\"></a>\n#### dirs : *dict*\nDictionary of directories to put logs in. Should contain the keys `'log'` (the directory to put all the other directories in), `'fig'` (for saving figures), `'saved_models'` (for saving models and/or weights of the models during training) and `'lr_finder'` (for storing the results of the learning rate finder, if used).\n\n The function `deepcalo.utils.create_directories` will return such a dictionary (and create its contained directories).\n\n#### save_figs : *bool*\nWhether to save plots of the model and its submodels.\n\n#### verbose : *bool*\nVerbose output. Set to `2` to disable the progress bar for each epoch.\n\n### Methods\n#### get_model\nCreates the model, as defined by `params`, which it takes as its sole input.\n\n#### train\nTrains the model constructed by `get_model`.\n\n#### evaluate\nEvaluates the model constructed by `get_model`, typically at the end of training using the validation or the test set.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://gitlab.com/ffaye/deepcalo", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "deepcalo", "package_url": "https://pypi.org/project/deepcalo/", "platform": "", "project_url": "https://pypi.org/project/deepcalo/", "project_urls": {"Homepage": "https://gitlab.com/ffaye/deepcalo"}, "release_url": "https://pypi.org/project/deepcalo/0.2.3/", "requires_dist": ["numpy (>=1.15.4)", "keras (>=2.2.4)", "h5py (>=2.8.0)", "joblib (>=0.13.0)", "keras-drop-block (>=0.4.0)"], "requires_python": "", "summary": "Package for doing deep supervised learning on ATLAS data.", "version": "0.2.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DeepCalo</h1>\n<h3>Python 3 package for doing deep supervised learning on ATLAS data, using Keras</h3>\n<p>Author: Frederik Faye, The Niels Bohr Institute, 2019</p>\n<h2>What is DeepCalo?</h2>\n<p>This package allows you to build, train and tune convolutional neural network (CNN) models using Keras with any backend.</p>\n<p>You can also integrate models for processing non-image data, such as scalars and sequences.\nThe models that can be built have been designed specifically with the ATLAS detector in mind, but you can also just use the framework and all its nice features for any Keras-based project.</p>\n<h2>Why should you use it?</h2>\n<ul>\n<li>All hyperparameters are set through a single Python dictionary, making it very easy to experiment with different models.</li>\n<li>Extensive logging is automatically created for each run of a model, including hyperparameters, plots of model architectures, and weights of the model during training, making it easy to keep track of what you have tried, and what came of it.</li>\n<li>A lot of advanced features are supported (such as cyclic learning rate schedules, grouped convolutions, DropBlock regularization, squeeze and excite modules, non-standard optimizers such as Yogi and Padam, and much more), and it is easy to add new ones.</li>\n</ul>\n<h3>Table of Content</h3>\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#dependencies\" rel=\"nofollow\">Dependencies</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#quickstart\" rel=\"nofollow\">Quick start for using generic data</a></li>\n<li><a href=\"#atlasdata\" rel=\"nofollow\">Quick start for using ATLAS data</a></li>\n</ul>\n</li>\n<li><a href=\"#archs\" rel=\"nofollow\">Model architectures</a>\n<ul>\n<li><a href=\"#arch_cnn\" rel=\"nofollow\">CNN</a></li>\n<li><a href=\"#arch_network_in_network\" rel=\"nofollow\">Network in network</a></li>\n<li><a href=\"#arch_top\" rel=\"nofollow\">Top</a></li>\n<li><a href=\"#arch_scalar_net\" rel=\"nofollow\">Scalar net</a></li>\n<li><a href=\"#arch_film_gen\" rel=\"nofollow\">FiLM generator</a></li>\n<li><a href=\"#arch_track_net\" rel=\"nofollow\">Track net</a></li>\n<li><a href=\"#arch_gate_net\" rel=\"nofollow\">Gate net</a></li>\n<li><a href=\"#arch_combined\" rel=\"nofollow\">Combined</a></li>\n</ul>\n</li>\n<li><a href=\"#docs\" rel=\"nofollow\">Documentation</a>\n<ul>\n<li><a href=\"#doc_data\" rel=\"nofollow\"><code>data</code></a></li>\n<li><a href=\"#doc_params\" rel=\"nofollow\"><code>params</code></a>\n<ul>\n<li><a href=\"#doc_submodels\" rel=\"nofollow\">Keys concerning submodels</a></li>\n</ul>\n</li>\n<li><a href=\"#doc_dirs\" rel=\"nofollow\"><code>dirs</code></a></li>\n</ul>\n</li>\n</ul>\n<p><a></a></p>\n<h2>Installation</h2>\n<pre>pip install deepcalo\n</pre>\n<p><a></a></p>\n<h2>Dependencies</h2>\n<pre><span class=\"n\">numpy</span><span class=\"p\">,</span> <span class=\"n\">pandas</span><span class=\"p\">,</span> <span class=\"n\">matplotlib</span><span class=\"p\">,</span> <span class=\"n\">h5py</span><span class=\"p\">,</span> <span class=\"n\">joblib</span><span class=\"p\">,</span> <span class=\"n\">keras</span><span class=\"p\">,</span> <span class=\"n\">tensorflow</span><span class=\"p\">,</span> <span class=\"n\">keras</span><span class=\"o\">-</span><span class=\"n\">drop</span><span class=\"o\">-</span><span class=\"n\">block</span>\n</pre>\n<p>If you want to be able to plot the graph of your model, please install <code>pydot</code> and <code>graphviz</code> (if possible, use <code>conda install python-graphviz</code> for <code>graphviz</code>).</p>\n<p><a></a></p>\n<h2>Usage</h2>\n<p><a></a></p>\n<h3>Quick start for using generic data</h3>\n<p>The main functionality lies in the so-called model container, which can be imported as</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">deepcalo</span> <span class=\"kn\">import</span> <span class=\"n\">ModelContainer</span>\n</pre>\n<p>See the <a href=\"#docs\" rel=\"nofollow\">documentation</a> below for all the details. However, often an example is a better way of learning. Some examples are found in the <code>demos</code> folder.</p>\n<p>Download and run the MNIST tutorial:</p>\n<pre>python mnist_tutorial.py --exp_dir ./my_mnist_experiment/ -v <span class=\"m\">1</span>\n</pre>\n<p>This will train a tiny CNN for a single epoch to discriminate between the digits of the MNIST dataset, which should reach $<code>&gt;95\\%</code>$ test accuracy after its first epoch.</p>\n<p>Open the script to see what is going on; the important part is the hyperparameter section. Try playing around with the parameters to see if you can find a network that does better! Also have a look at the contents of the <code>logs</code> folder in the experiment directory (<code>./my_mnist_experiment/</code>) to see some of the nice logging features this framework has to offer.</p>\n<p>There are a lot more hyperparameters to play around with. See the <a href=\"#doc_params\" rel=\"nofollow\">documentation</a> for what is possible.</p>\n<p><a></a></p>\n<h3>Quick start for using ATLAS data</h3>\n<p>The <code>demos/atlas_specific_usecases</code> folder contains examples of how to train a model, or load and use an already trained model, both using ATLAS data.\nSee the README in the <code>demos/atlas_specific_usecases</code> folder for more details.</p>\n<p><strong>A quick overview of how to construct the recommended models for doing energy regression with this package are described in <a href=\"#https://gitlab.com/ffaye/deepcalo/blob/master/demos/atlas_specific_usecases/train_recommended_models/recipe.pdf\" rel=\"nofollow\">this pdf</a>.</strong></p>\n<p>The <code>demos/atlas_specific_usecases</code> folder also contains an example of how to carry out a hyperparameter search (using the Bayesian optimization of <a href=\"https://github.com/scikit-optimize/scikit-optimize\" rel=\"nofollow\">scikit-optimize</a>), using this framework.</p>\n<p>All these examples use ATLAS simulation data to do energy regression (although using these models for PID is entirely possible). The data used herein can be downloaded from the lxplus (CERNBox) directory <code>/eos/user/l/lehrke/Data/Data/2019-09-26/</code> (which should be visible to all CERN members).</p>\n<p>The scripts uses the function <code>deepcalo.utils.load_atlas_data</code> function, which is tailored to these datasets. If need be, you can modify this function to work with your data, however note that this framework uses the <code>'channels_last'</code> format, which is the standard in Keras.</p>\n<p><a></a></p>\n<h2>Model architectures</h2>\n<p>The following is a quick tour of the different out-of-the-box models available. Each model is made for a different kind of input, e.g., images, scalar variables, tracks, or the output from other models.</p>\n<p>All models except the <a href=\"#arch_top\" rel=\"nofollow\">top</a> are optional to use. However, models are tied to their input in such a way that if for instance a <code>tracks</code> dataset is present in the suppplied <a href=\"#doc_data\" rel=\"nofollow\">data</a>, the <a href=\"#arch_track_net\" rel=\"nofollow\">track net</a> will be integrated into the <a href=\"#arch_combined\" rel=\"nofollow\">combined model</a>.</p>\n<p>You can find information about how to set the hyperparameters of these models in the <a href=\"#doc_params\" rel=\"nofollow\">documentation</a>, where each model has its own section.</p>\n<p><a></a></p>\n<h3>CNN</h3>\n<p>Below, an illustration of the default CNN architecture can be seen. It is comprised of blocks. For all but the first block, a block begins with downsampling and the number of feature maps being doubled.\nThe tuple underneath the input denotes the size of the input (here height, width, channels).\nNote that normalization, the activation function, downsampling and global average pooling can all be turned on or off.</p>\n<p>The output of the CNN is passed on to either the <a href=\"#arch_top\" rel=\"nofollow\">top</a>, or to the <a href=\"#arch_network_in_network\" rel=\"nofollow\">network in network</a>.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8356b592a0c324877bf53487044a1a7e65426d5/696d616765732f636e6e5f617263682e706e67\" width=\"350\">\n</p>\n<p><a></a></p>\n<h3>Network in network</h3>\n<p>This model takes the outputted feature maps of the <a href=\"#arch_cnn\" rel=\"nofollow\">CNN</a> (without global average pooling applied), and applies a <a href=\"https://arxiv.org/abs/1312.4400\" rel=\"nofollow\">Network in Network</a> to it, which consists of a series of $<code>1\\times 1</code>$ convolutions, typically followed by global average pooling.</p>\n<p>This makes it possible to make CNN architectures without a dense top (e.g. the <a href=\"https://arxiv.org/abs/1412.6806\" rel=\"nofollow\">AllConv Net</a>). For instance, if you want to train a CNN with a network in network classifier to be able to distinguish between five categories, make the final $<code>1 \\times 1</code>$ convolution in the network in network submodel output five feature maps, apply global average pooling, and set the <a href=\"#arch_top\" rel=\"nofollow\">top</a> to have no units (<code>units:[]</code>) and <code>final_activation:'softmax'</code>.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3387ae28beebd4d65edf8cb30163b6799f5466d6/696d616765732f6e6574776f726b5f696e5f6e6574776f726b5f617263682e706e67\" width=\"350\">\n</p>\n<p><a></a></p>\n<h3>Top</h3>\n<p>The top model is a simple, dense neural network that takes as input the concatenated outputs of other models, and gives a final output, which can be any 1D size $<code>\\geq 1</code>$.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0e2a768d991dd859b4fa562022f4f22b46fe566a/696d616765732f746f705f617263682e706e67\" width=\"350\">\n</p>\n<p><a></a></p>\n<h3>Scalar net</h3>\n<p>The scalar net is again a simple, dense network that processes any scalar variables you may want to include. Its output can be connected to either the <a href=\"#arch_top\" rel=\"nofollow\">top</a>, the <a href=\"#arch_film_gen\" rel=\"nofollow\">FiLM generator</a>, or both.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6aa3a52af495016998725d194af413b2b1edc365/696d616765732f7363616c61725f6e65745f617263682e706e67\" width=\"350\">\n</p>\n<p><a></a></p>\n<h3>FiLM generator</h3>\n<p>The FiLM generator is a nice way of conditioning the CNN with scalar variables. You can read a good introduction to the technique <a href=\"https://distill.pub/2018/feature-wise-transformations/\" rel=\"nofollow\">here</a>.</p>\n<p>The FiLM generator can take inputs from both the <a href=\"#arch_scalar_net\" rel=\"nofollow\">scalar net</a> and the <a href=\"#arch_track_net\" rel=\"nofollow\">track net</a>. Its output modulates the <a href=\"#arch_cnn\" rel=\"nofollow\">CNN</a>.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e8c43b5312f34334e3b566427e4452cbc59728e7/696d616765732f66696c6d5f67656e5f617263682e706e67\" width=\"350\">\n</p>\n<p><a></a></p>\n<h3>Track net</h3>\n<p>This model takes the (varying) number of track vectors for a datapoint as input and spits out a fixed size representation of that datapoint, which is then passed on to the <a href=\"#arch_top\" rel=\"nofollow\">top</a>, the <a href=\"#arch_film_gen\" rel=\"nofollow\">FiLM generator</a>, or both.</p>\n<p>As the order in which we give our model the track vectors for a datapoint carries no information, the permutation invariant method of <a href=\"https://arxiv.org/abs/1703.06114\" rel=\"nofollow\">Deep Sets</a> has been used.</p>\n<p>The $<code>T</code>$ in the shape of $<code>X_{\\mathrm{track}}</code>$ is the largest number of track vectors of any datapoint in the dataset, where zero-padding has been used if the actual number of tracks for a given datapoint is smaller than $<code>T</code>$.</p>\n<p>Note that right now, the aggregation part of the track net is a simple sum, as in the <a href=\"https://arxiv.org/abs/1703.06114\" rel=\"nofollow\">Deep Sets</a> paper.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0adad85751a1ba7670e994c5ba91333f22615bcd/696d616765732f747261636b5f6e65745f617263682e706e67\" width=\"350\">\n</p>\n<p><a></a></p>\n<h3>Gate net</h3>\n<p>The <a href=\"#arch_cnn\" rel=\"nofollow\">CNN</a> architecture can be expanded to include images, that contain cell information other than just the energy, by using the gate net. This was originally motivated by the inclusion of when in time each cell determined its signal to be, in order to help mitigate out-of-time pileup, but images containing other cell information can be included instead; for instance, the noise of each cell has proven useful for energy regression.</p>\n<p>The cell images containing the extra cell information is collected in an image tensor $<code>X_{\\mathrm{gate-img}}</code>$ of the same resolution and dimension as the standard cell image tensor $<code>X_{\\mathrm{img}}</code>$.\n$<code>X_{\\mathrm{gate-img}}</code>$ is first passed through a gating mechanism (the gate net), which outputs a real number between zero and one for each pixel in each channel. These numbers are then merged with $<code>X_{\\mathrm{img}}</code>$, either by element-wise multiplication and then concatenation along the channel axis, or just by element-wise multiplication. The idea is that the element-wise multiplication allows the network to modulate the values of $<code>X_{\\mathrm{img}}</code>$ according to the information stored in $<code>X_{\\mathrm{gate-img}}</code>$.\nThe resulting, merged tensor is then given as the input to the <a href=\"#arch_cnn\" rel=\"nofollow\">CNN</a> (in the stead of $<code>X_{\\mathrm{img}}</code>$).</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/357549cc586512c26f6a155269875bcbfe91c8b9/696d616765732f676174655f6e65745f617263682e706e67\" width=\"450\">\n</p>\n<p><a></a></p>\n<h3>Combined</h3>\n<p>In the final illustration below, you can see how the models all fit together.</p>\n<p align=\"center\">\n  <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e0e27e320684a2023745e1251973fdcf865459a8/696d616765732f636f6d62696e65645f617263682e706e67\" width=\"600\">\n</p>\n<p><a></a></p>\n<h2>Documentation</h2>\n<p>The heart of DeepCalo is the <code>ModelContainer</code> class, found in <code>deepcalo.model_container</code>, which is documented below.</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">ModelContainer</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">    A class for organizing the creation, training and evaluation of models.</span>\n<span class=\"sd\">    \"\"\"</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">params</span><span class=\"p\">,</span> <span class=\"n\">dirs</span><span class=\"p\">,</span> <span class=\"n\">save_figs</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n</pre>\n<h3>Arguments</h3>\n<p><a></a></p>\n<h4>data : <em>dict</em></h4>\n<p>Dictionary of training, validation and (optionally) test data, organized according to the type of data.</p>\n<p>This dictionary must have either two or three keys, being <code>train</code> and <code>val</code>, or <code>train</code>, <code>val</code>, and <code>test</code>. Each of these keys points to another <em>dict</em> containing different kinds of data. The keys of these dictionaries can be any or all of <code>'images'</code>, <code>'scalars'</code>, <code>'tracks'</code>, <code>'sample_weights'</code> and <code>'targets'</code>. The documentation for what each of these keys refers to is given below. Note that <code>'images'</code>, <code>'scalars'</code> and <code>'tracks'</code> are considered inputs, and at least one of them must be non-empty.</p>\n<p>Note that the shapes of the datasets contained in <code>data</code> are used in the model creation (but a single datapoint is enough to do so).</p>\n<p><strong>images</strong> : <em>dict of ndarrays</em></p>\n<ul>\n<li>\n<p>If <code>'images'</code> is a key in <code>data[set_name]</code> and <code>data[set_name]['images']</code> is non-empty (where <code>set_name</code> can be either <code>'train'</code>, <code>'val'</code> or <code>'test'</code>), a <a href=\"#arch_cnn\" rel=\"nofollow\">CNN</a> will be created and used to process these images.</p>\n<p>To allow you to keep track of different types of images (intended to be used for different kinds of things), the value corresponding to the <code>'images'</code> key of <code>data</code> is also a <em>dict</em>.</p>\n<p>Say you have two different kinds of images that you would like to have processed by the CNN. Let's call them <code>'low_res_imgs'</code> and <code>'high_res_imgs'</code> (i.e., these are the keys in the <code>data[set_name]['images']</code> dictionary), each being 4D numpy array with shape $<code>(N,H,W,C)</code>$, where $<code>H</code>$ and $<code>W</code>$ are different for the two types of images. You can then use the <code>upsampling</code> functionality (see <a href=\"#doc_params\" rel=\"nofollow\"><code>params</code></a>) to upsample them to a common resolution, so that they can be processed together in the CNN.</p>\n<p>If you want to include and process <a href=\"#arch_gate_net\" rel=\"nofollow\">gate images</a>, these should be named the exact same as the cells they correspond to, with <code>'gate_'</code> preprended; using the example from above, the <code>data[set_name]['images']</code> dictionary would then have the four keys  <code>'low_res_imgs'</code>, <code>'gate_low_res_imgs'</code>, <code>'high_res_imgs'</code> and <code>'gate_high_res_imgs'</code>. Only if images are named in this manner will a submodel for processing the gate images be created and used.</p>\n</li>\n</ul>\n<p><strong>scalars</strong> : <em>ndarray</em></p>\n<ul>\n<li>\n<p>If <code>'scalars'</code> is a key in <code>data[set_name]</code> and <code>data[set_name]['scalars']</code> is non-empty (where <code>set_name</code> can be either <code>'train'</code>, <code>'val'</code> or <code>'test'</code>), a <a href=\"#arch_scalar_net\" rel=\"nofollow\">scalar net</a> will be created and used to process these scalars.</p>\n<p>The scalars should come in the form of a $<code>(N,S)</code>$ numpy array, where $<code>N</code>$ is the number of datapoints in the set, and where $<code>S</code>$ is the number of scalars.</p>\n</li>\n</ul>\n<p><strong>tracks</strong> : <em>ndarray</em></p>\n<ul>\n<li>\n<p>If <code>'tracks'</code> is a key in <code>data[set_name]</code> and <code>data[set_name]['tracks']</code> is non-empty (where <code>set_name</code> can be either <code>'train'</code>, <code>'val'</code> or <code>'test'</code>), a <a href=\"#arch_track_net\" rel=\"nofollow\">track net</a> will be created and used to process these tracks.</p>\n<p>The track vectors should come in the form of a numpy array of shape $<code>(N,T,F)</code>$, where $<code>N</code>$ is the number of datapoints, $<code>T</code>$ is the maximum number of tracks, and where $<code>F</code>$ is the length of each track vector, i.e., the number of features.</p>\n<p>As each datapoint can have a variable number of track vectors associated with it, datapoints with $<code>t&lt;T</code>$ track vectors should be zero-padded (see <code>deepcalo.utils.load_atlas_data</code> for an example of how to zero-pad). All tracks having exclusively zeros as all its features are masked out internally in the track net, and will therefore not contribute to the output of track net.</p>\n</li>\n</ul>\n<p><strong>multiply_output_with</strong> : <em>ndarray</em></p>\n<ul>\n<li>\n<p>If <code>'multiply_output_with'</code> is a key in <code>data[set_name]</code> and <code>data[set_name]['multiply_output_with']</code> is non-empty (where <code>set_name</code> can be either <code>'train'</code>, <code>'val'</code> or <code>'test'</code>), then the values of the <code>'multiply_output_with'</code> array (which should be 1D) will be multiplied with the values given by the output neuron(s) of the model, for each datapoint. This product is then the final output of the model.</p>\n<p>For instance, if our target is an energy, and the <code>'multiply_output_with'</code> array contains the accordion energy, this would make the model predict the correction to the accordion energy, instead of the energy itself.</p>\n</li>\n</ul>\n<p><strong>sample_weights</strong> : <em>ndarray</em></p>\n<ul>\n<li>If <code>'sample_weights'</code> is a key in <code>data[set_name]</code> and <code>data[set_name]['sample_weights']</code> is non-empty (where <code>set_name</code> can be either <code>'train'</code>, <code>'val'</code> or <code>'test'</code>), then these sample weights will be used in all loss functions and metrics (both during training and evaluation).</li>\n</ul>\n<p><strong>targets</strong> : <em>ndarray</em></p>\n<ul>\n<li>Contains the targets (or labels) of the task. Is always required. Its shape must match that of the final output of the constructed model.</li>\n</ul>\n<p><strong>Example of valid <code>data</code>:</strong></p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n\n<span class=\"n\">set_names</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'train'</span><span class=\"p\">,</span> <span class=\"s1\">'val'</span><span class=\"p\">,</span> <span class=\"s1\">'test'</span><span class=\"p\">]</span> <span class=\"c1\"># Could also just be ['train', 'val']</span>\n\n<span class=\"c1\"># Number of datapoints for each set</span>\n<span class=\"n\">n_points</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">set_name</span><span class=\"p\">:</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mf\">1e3</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">set_name</span> <span class=\"ow\">in</span> <span class=\"n\">set_names</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># Dimension of images, which we will call 'example_imgs'</span>\n<span class=\"n\">h</span><span class=\"p\">,</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"mi\">14</span><span class=\"p\">,</span><span class=\"mi\">25</span><span class=\"p\">,</span><span class=\"mi\">2</span>\n\n<span class=\"c1\"># Number of scalars</span>\n<span class=\"n\">n_scalars</span> <span class=\"o\">=</span> <span class=\"mi\">7</span>\n\n<span class=\"c1\"># Create the data</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"n\">set_name</span><span class=\"p\">:{</span><span class=\"s1\">'images'</span><span class=\"p\">:{</span><span class=\"s1\">'example_imgs'</span><span class=\"p\">:</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">n_points</span><span class=\"p\">[</span><span class=\"n\">set_name</span><span class=\"p\">],</span><span class=\"n\">h</span><span class=\"p\">,</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"n\">c</span><span class=\"p\">)},</span>\n                  <span class=\"s1\">'scalars'</span><span class=\"p\">:</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">n_points</span><span class=\"p\">[</span><span class=\"n\">set_name</span><span class=\"p\">],</span><span class=\"n\">n_scalars</span><span class=\"p\">),</span>\n                  <span class=\"s1\">'tracks'</span><span class=\"p\">:{},</span> <span class=\"c1\"># Is empty, so track_net won't be created and used</span>\n                  <span class=\"s1\">'targets'</span><span class=\"p\">:</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">n_points</span><span class=\"p\">[</span><span class=\"n\">set_name</span><span class=\"p\">])</span> <span class=\"c1\"># Here, the target is a single number per datapoint</span>\n                 <span class=\"p\">}</span> <span class=\"k\">for</span> <span class=\"n\">set_name</span> <span class=\"ow\">in</span> <span class=\"n\">set_names</span><span class=\"p\">}</span>\n</pre>\n<p><a></a></p>\n<h4>params : <em>dict</em></h4>\n<p>This dictionary contains all the hyperparameters used in constructing, training and evaluating the model. Default parameters can be gotten from the function <code>deepcalo.utils.get_default_params</code>.</p>\n<p>When a dictionary key is referenced below, what is actually meant is the\nvalue corresponding to that key. For instance, although the key <code>'epochs'</code>\nis of course a <em>str</em>, the documentation below concerns itself with the value\nof this key, which in this case is an <em>int</em>.</p>\n<p><strong>epochs</strong> : <em>int</em></p>\n<ul>\n<li>Number of epochs to train for. If <code>use_earlystopping</code> is set to\n<code>True</code>, training may stop prior to completing the chosen number of\nepochs.</li>\n</ul>\n<p><strong>batch_size</strong> : <em>int</em></p>\n<ul>\n<li>Mini-batch size. Note that if several GPUs are used, the mini-batch\nwill be evenly divided among them.</li>\n</ul>\n<p><strong>loss</strong> : <em>str</em></p>\n<ul>\n<li>Any Keras loss function name. See <code>get_loss_function</code> in\n<code>model_building_functions.py</code> for implemented custom loss functions,\nas well as how to implement your own.</li>\n</ul>\n<p><strong>metrics</strong> : <em>list of strs or None</em></p>\n<ul>\n<li>Can be the name of any metric recognized by Keras. This (or these)\nmetric(s) will be shown during training, as well as in the final\nevaluation.\nNote that if a <em>hp_search</em> is carried out, the last entry of the list\nwill be the evaluation function used by the Gaussian process\nhyperparameter search. If an empty list or <code>None</code>, the <code>loss</code> will be\nthe evaluation function used by the Gaussian process hyperparameter search.</li>\n</ul>\n<p><strong>optimizer</strong> : <em>str or config dict</em></p>\n<ul>\n<li>\n<p>Which optimizer to use. Any Keras optimizer can be used.</p>\n<p>If you don't want to simply use the defaults parameters of the\nchosen optimizer, instead give a <em>config dict</em>. See <a href=\"#doc_config_dict\" rel=\"nofollow\">Explanation of\n<em>str or config dict</em></a>.</p>\n</li>\n</ul>\n<p><strong>lr_finder</strong> : <em>dict</em></p>\n<ul>\n<li>Dictionary of learning rate finder (from <a href=\"https://arxiv.org/abs/1506.01186\" rel=\"nofollow\">Smith, 2015</a>) parameters.\n<ul>\n<li>The <code>'use'</code> key is a <em>bool</em> deciding whether or not to use the\nlearning rate finder as implemented in <code>custom_classes.py</code>.</li>\n<li>The <code>'scan_range'</code> is a <em>list</em> containing the minimum and maximum\nlearning rate to be scanned over.</li>\n<li>The <code>'epochs'</code> key is an <em>int</em> setting the number of epochs to use in the scan.\n1-4 epochs is typically enough, depending on the size of the training set.</li>\n<li>The <code>'scale'</code> can be either <code>'linear'</code> (default) or <code>'log'</code>, resulting in the\nlearning rates being scanned linearly or logarithmically, respectively.</li>\n<li>If <code>'prompt_for_input'</code> is <code>True</code>, the user will be asked to input a\nrange within which the cyclical learning rate schedule (see below)\nshould vary in between upon completing the learning rate finder\nscan.</li>\n</ul>\n</li>\n</ul>\n<p><strong>lr_schedule</strong> : <em>dict</em></p>\n<ul>\n<li>Dictionary of learning rate schedule parameters.\n<ul>\n<li>The <code>'name'</code> key can be either <code>None</code> (when no learning rate schedule\nwill be used), <code>'CLR'</code> (<a href=\"https://arxiv.org/abs/1506.01186\" rel=\"nofollow\">Smith, 2015</a>),\n<code>'OneCycle'</code> (<a href=\"https://arxiv.org/abs/1708.07120\" rel=\"nofollow\">Smith et al., 2017</a>) or <code>'SGDR'</code> (<a href=\"https://arxiv.org/abs/1608.03983\" rel=\"nofollow\">Loshchilov and Hutter, 2017</a>).</li>\n<li>The <code>'range'</code> key should be a list with two floats, the first one being the minimum learning rate, and the second being the maximum learning rate.</li>\n<li>The <code>'step_size_factor'</code> key differs in meaning for the possible learning rate schedules: If $<code>s</code>$ is the <code>'step_size_factor'</code> value and $<code>k</code>$ is the number of mini-batch updates per epoch $<code>e</code>$, then for</li>\n</ul>\n<ul>\n<li><code>'CLR'</code>, the step size of the cycle (i.e., the number of mini-batch updates per half a cycle) is given by $<code>ks</code>$,</li>\n<li><code>'OneCycle'</code>, the step size $<code>k\\times e/s</code>$, means that $<code>s</code>$ is the number of half cycles, including the cooldown to one hundredth the base learning rate. E.g., if $<code>s=2.25</code>$, the last $<code>\\frac{0.25}{2.25}</code>$ of the total number of mini-batch updates will be used for the cooldown,</li>\n<li><code>'SGDR'</code>, $<code>s</code>$ is simply the initial number of epochs in a cycle.</li>\n</ul>\n</li>\n</ul>\n<p>Note that <code>cyclical_momentum==True</code> in <code>'OneCycle'</code> will only work with optimizers that have a <code>momentum</code> attribute (such as <code>'SGD'</code>).</p>\n<p>Besides the above mentioned, keyword arguments specific to each learning rate schedule class can be passed by using the <code>'kwargs'</code> key, which should have a dictionary of keyword arguments as its value.</p>\n<p><strong>auto_lr</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use the function <code>get_auto_lr</code> in\n<code>model_building_functions.py</code> that automatically sets a good learning\nrate based on the chosen optimizer and the batch size, taking the\nlearning rate to be propertional to the square root of the batch\nsize. The constant of proportionality varies from optimizer to\noptimizer, and probably from problem to problem - use the learning\nrate finder to find out which constant is suitable for your problem.</li>\n</ul>\n<p><strong>use_earlystopping</strong> : <em>bool</em></p>\n<ul>\n<li>Use the Keras EarlyStopping callback with <code>min_delta=0.001</code> and\n<code>patience=150</code> (these can be changed in <code>model_container.py</code>).</li>\n</ul>\n<p><strong>restore_best_weights</strong> : <em>bool</em></p>\n<ul>\n<li>Restore the best weights found during training before evaluating.</li>\n</ul>\n<p><strong>pretrained_model</strong> : <em>dict</em></p>\n<ul>\n<li>Dictionary of parameters for using (parts of) pretrained models.\n<ul>\n<li>The <code>'use'</code> key is a boolean deciding whether or not to load\npretrained weights.</li>\n<li>The <code>'weights_path'</code> is the path to the weights\nof the pretrained network. If <code>'params_path'</code> is <code>None</code>, the\nparameters for the pretrained network is assumed to be in the parent\nfolder of the <code>'weights_path'</code>.</li>\n<li><code>'layers_to_load'</code> is a <em>list</em> with the Keras names of the layers (or\nsubmodels) whose weights should be transferred from the pretrained\nmodel to the one at hand. These names must refer to the same\nstructure in both the pretrained model and in the model at hand.</li>\n<li><code>'freeze_loaded_layers'</code> can be either a boolean (when, if <code>True</code>,\nall layers listed in <code>'layers_to_load'</code> will be frozen, or not, if\n<code>False</code>) or a <em>list</em> of <em>bool</em>s with the same length as\n<code>'layers_to_load'</code> (when the first boolean in\n<code>'freeze_loaded_layers'</code> answers whether to freeze the first layer\ngiven by <code>'layers_to_load'</code> or not, etc.).</li>\n</ul>\n</li>\n</ul>\n<p><strong>n_gpus</strong> : <em>int</em></p>\n<ul>\n<li>Number of GPUs used in training. Can typically be inferred from the visible GPUs.</li>\n</ul>\n<p><strong>data_generator</strong> : <em>dict</em></p>\n<ul>\n<li>\n<p>Parameters concerning a DataGenerator, which is helpful if your data does not fit in memory, as it loads data in batches. Its current implementation, which is designed to work in conjunction with <code>deepcalo.utils.load_atlas_data</code>, can be seen in <code>deepcalo.data_generator</code>.</p>\n<ul>\n<li>The <code>'use'</code> key is a <em>bool</em> deciding whether to use a DataGenerator.</li>\n<li>The <code>'n_workers'</code> key is an <em>int</em> that sets the number of CPU workers to use for preparing batches.</li>\n<li>The <code>'max_queue_size'</code> key is an <em>int</em> that sets the upper limit to how many batches can be ready at any one time.</li>\n<li>The <code>'path'</code> key is a <em>str</em> that gives the path to the dataset.</li>\n<li>The <code>'n_points'</code> key is a <em>dict</em> with the keys <code>'train'</code> and <code>'val'</code> (or <code>'train'</code>, <code>'val'</code> and <code>'test'</code>), whose corresponding values is an <em>int</em> given the number of datapoints in each set.</li>\n<li>The <code>'load_kwargs'</code> key is a <em>dict</em> containing arguments to be passed to the <code>__init__</code> of the <code>DataGenerator</code> class.</li>\n</ul>\n</li>\n</ul>\n<p><strong>usampling</strong> : <em>dict</em></p>\n<ul>\n<li>\n<p>Dictionary of parameters for upsampling input images inside the\nnetwork. This can be useful if the ability to downsample (which\nintroduces translational invariance) is important but the input\nimages are small.</p>\n<ul>\n<li>The <code>'use'</code> key is a boolean deciding whether to upsample or not.\n<code>'wanted_size'</code> refers to the size that all images should be\nupsampled to before being concatenated.</li>\n<li>The <code>'interpolation'</code> argument is passed to the Keras layer <code>UpSample2D</code>.</li>\n</ul>\n<p>After upsampling, the cell image tensor is normalized so as to\nmaintain the same amount of energy overall, but now spread out over\nthe upsampling pixels.</p>\n</li>\n</ul>\n<p><a></a></p>\n<h5>Keys concerning all submodels:</h5>\n<p><strong>initialization</strong> : <em>str or config dict</em></p>\n<ul>\n<li>\n<p>Initialization of the parameters of the submodel. Can be any\ninitializer recognized by Keras.</p>\n<p>If you don't want to simply use the defaults parameters of the\nchosen initializer, instead give a <em>config dict</em>. See <a href=\"#doc_config_dict\" rel=\"nofollow\">Explanation\nof <em>str or config dict</em></a>.</p>\n</li>\n</ul>\n<p><strong>normalization</strong> : <em>str or config dict or None</em></p>\n<ul>\n<li>\n<p>Normalization layer. If not <code>None</code>, the chosen normalization layer is\nplaced after every dense or convolutional layer in the submodel,\ni.e., before an activation function.</p>\n<p>Can be any of <code>'batch'</code>, <code>'layer'</code>, <code>'instance'</code> or <code>'group'</code>.\nNote that the last three are implemented through a group\nnormalization layer (which encompass the layer and instance\nnormalization). This means that the name of the normalization\nlayer when using <code>keras.utils.plot_model</code> will be the name of a\ngroup normalization layer when using any of the last three.</p>\n<p>If you don't want to simply use the defaults parameters of the\nchosen normalization layer, instead give a <em>config dict</em>. See\n<a href=\"#doc_config_dict\" rel=\"nofollow\">Explanation of <em>str or config dict</em></a>.</p>\n</li>\n</ul>\n<p><strong>activation</strong> : <em>str or config dict or None</em></p>\n<ul>\n<li>\n<p>Activation function of all dense or convolutional layers in the\nsubmodel, except for the very last one, if a <code>final_activation</code>\nvariable is present.</p>\n<p>Can be any of <code>'relu'</code>, <code>'leakyrelu'</code>, <code>'prelu'</code>, <code>'elu'</code> or\n<code>'swish'</code>.\nSee <code>get_activation</code> in <code>model_building_functions.py</code> for examples\nof implementations of custom activation functions.</p>\n<p>Is placed right after every normalization layer\nin the submodel, or - if <code>normalization</code> is <code>None</code>, right after\nevery dense or convolutional layer in the submodel.</p>\n<p>If you don't want to simply use the defaults parameters of the\nchosen activation, instead give a <em>config dict</em>. See <a href=\"#doc_config_dict\" rel=\"nofollow\">Explanation of\n<em>str or config dict</em></a>.</p>\n</li>\n</ul>\n<p><strong>layer_reg</strong> : <em>dict with None or strs or config dicts as values</em></p>\n<ul>\n<li>\n<p>Layer regularization to be applied to all dense or convolutional\nlayers in the submodel. This dict collects <code>kernel_regularizer</code>s,\n<code>bias_regularizer</code>s, <code>activity_regularizer</code>s, <code>kernel_constraint</code>s\nand <code>bias_constraint</code>s to be applied.</p>\n<p>If you don't want to simply use the defaults parameters of the\nchosen regularizer, instead give a <em>config dict</em>. See <a href=\"#doc_config_dict\" rel=\"nofollow\">Explanation\nof <em>str or config dict</em></a>.</p>\n<p>An example of what is allowed:</p>\n<pre><span class=\"p\">{</span><span class=\"s1\">'kernel_regularizer'</span><span class=\"p\">:</span><span class=\"s1\">'l2'</span><span class=\"p\">,</span>\n<span class=\"s1\">'bias_regularizer'</span><span class=\"p\">:{</span><span class=\"s1\">'class_name'</span><span class=\"p\">:</span><span class=\"s1\">'l1'</span><span class=\"p\">,</span>\n                    <span class=\"s1\">'config'</span><span class=\"p\">:{</span><span class=\"s1\">'l'</span><span class=\"p\">:</span><span class=\"mf\">1e-5</span><span class=\"p\">}},</span>\n<span class=\"s1\">'activity_regularizer'</span><span class=\"p\">:</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"s1\">'kernel_constraint'</span><span class=\"p\">:{</span><span class=\"s1\">'class_name'</span><span class=\"p\">:</span><span class=\"s1\">'max_norm'</span><span class=\"p\">,</span>\n                     <span class=\"s1\">'config'</span><span class=\"p\">:{</span><span class=\"s1\">'max_value'</span><span class=\"p\">:</span><span class=\"mi\">3</span><span class=\"p\">}},</span>\n<span class=\"s1\">'bias_constraint'</span><span class=\"p\">:</span><span class=\"s1\">'max_norm'</span><span class=\"p\">}</span>\n</pre>\n<p>Any of these keys can be left out to invoke the default value of\n<code>None</code>. If the <em>dict</em> is empty, no layer regularization will be\napplied.</p>\n</li>\n</ul>\n<p><strong>dropout</strong> : <em>float or dict or None</em></p>\n<ul>\n<li>Arguments to be passed to either dropout layers, in the case of\ndense layers (pass the rate as a float), or dropblock layers, in the\ncase of convolutional layers (pass a dict to be unpacked into the\ndropblock layers - see the <a href=\"https://github.com/MLearing/Keras-DropBlock/blob/master/keras_drop_block/drop_block.py\" rel=\"nofollow\">dropblock documentation</a> for what to pass).\nThe dropout or dropblock layers will be inserted immediately after\neach dense or convolutional layer.\nIf <code>None</code>, no dropout or dropblock layers will be added.</li>\n</ul>\n<h5>Keys concerning submodel <code>top</code>:</h5>\n<p>Submodel for collecting inputs (e.g. from other submodels) and giving\nthe output of the full model.</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of hidden units in each dense layer in the top\nas elements.\nThis includes the output neuron(s), so the last element in <code>units</code>\nshould be the number of desired outputs.\nIf the input to the top has the same shape as the target, it is also possible\nfor <code>units</code> to be an empty list, when the final output will be the\n<code>final_activation</code> (see below) applied to the input to <code>top</code>.</li>\n</ul>\n<p><strong>final_activation</strong> : <em>str</em></p>\n<ul>\n<li>Activation function to apply to the last dense layer. E.g. for\nbinary classification, use <code>'sigmoid'</code>, and use <code>'linear'</code> or <code>None</code>\n(or <code>'relu'</code> to enforce non-negativity) for regression.</li>\n</ul>\n<h5>Keys concerning submodel <code>cnn</code>:</h5>\n<p>Submodel for processing images. Will only be used if <code>img_names</code> is not None.</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>cnn_type</strong> : <em>str</em></p>\n<ul>\n<li>The type of CNN that will be constructed. To use the CNN illustrated\n<a href=\"#arch_cnn\" rel=\"nofollow\">here</a>, set to <code>'simple'</code>. Set to <code>'res'</code> to use residual\nblocks, as in <a href=\"https://arxiv.org/abs/1603.05027\" rel=\"nofollow\">He et al., 2016</a>.\nSetting cnn_type to some other string is a good way to implement\nother types of CNNs, which are then integrated into the framework.\nFor instance, to use the ResNet18 of keras_contrib, set to e.g. <code>'res18'</code> - see <code>model_building_functions.py</code> under <code>get_cnn</code> for how this is\ndone.</li>\n</ul>\n<p><strong>conv_dim</strong> : <em>int</em></p>\n<ul>\n<li>One of <code>2</code> or <code>3</code>. Whether to use 2D or 3D convolutions.</li>\n</ul>\n<p><strong>block_depths</strong> : <em>list</em> of <em>int</em>s</p>\n<ul>\n<li>\n<p>List with number of convolutional layers for each block as elements.\nSee the illustration <a href=\"#arch_cnn\" rel=\"nofollow\">here</a> for what constitutes a block.</p>\n<p>Note that is <code>cnn_type</code> is <code>'res'</code>, two convolutional layers are\nused per <em>int</em>, e.g. a <code>block_depth</code> value of <code>[1,2,2,2,2]</code> will\nresult in a CNN with 18 convolutional layers, wheres the CNN would\nonly have 9 convolutional layers if <code>cnn_type</code> had been <code>'simple'</code>.</p>\n</li>\n</ul>\n<p><strong>n_init_filters</strong> : <em>int</em></p>\n<ul>\n<li>How many filters should be used in the first convolutional layer.</li>\n</ul>\n<p><strong>init_kernel_size</strong> : <em>int</em> or <em>tuple</em></p>\n<ul>\n<li>\n<p>Kernel size of the first convolutional layer.</p>\n<p>If and <em>int</em> is given and <code>conv_dim</code> is <code>2</code>, a kernel size of\n<code>(init_kernel_size,init_kernel_size)</code> is used. If <code>conv_dim</code> is\ninstead <code>3</code>, a kernel size of <code>(init_kernel_size,init_kernel_size,2)</code>\nis used.\nIf a tuple is given, its length must equal <code>conv_dim</code>.</p>\n</li>\n</ul>\n<p><strong>rest_kernel_size</strong> : <em>int or tuple</em></p>\n<ul>\n<li>\n<p>Kernel size of all but the first convolutional layer.</p>\n<p>If and <em>int</em> is given and <code>conv_dim</code> is <code>2</code>, a kernel size of\n<code>(init_kernel_size,init_kernel_size)</code> is used. If <code>conv_dim</code> is\ninstead <code>3</code>, a kernel size of <code>(init_kernel_size,init_kernel_size,2)</code>\nis used.\nIf a tuple is given, its length must equal <code>conv_dim</code>.</p>\n</li>\n</ul>\n<p><strong>init_strides</strong> : <em>int</em> or <em>tuple</em></p>\n<ul>\n<li>Strides of the first convolutional layer. Default is <code>1</code>.</li>\n</ul>\n<p><strong>rest_strides</strong> : <em>int or tuple</em></p>\n<ul>\n<li>Strides of all but the first convolutional layer. Default is <code>1</code>.</li>\n</ul>\n<p><strong>cardinality</strong> : <em>int</em></p>\n<ul>\n<li>As in <a href=\"https://arxiv.org/abs/1611.05431\" rel=\"nofollow\">Xie et al., 2016</a>, i.e., grouped convolutions (without the bottleneck using $<code>1\\times 1</code>$ convolutions) will be used instead of the normal convolutions when <code>cardinality &gt; 1</code>. Only supported for 2D convolutions.</li>\n</ul>\n<p><strong>use_squeeze_and_excite</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use the squeeze and excite block from <a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">Hu et al., 2017</a>. For the <code>'simple'</code> <code>cnn_type</code> it will be inserted after the activation function (which comes after the normalization layer). For the <code>'res'</code> <code>cnn_type</code> it will be inserted right before the addition of the skip-connection.</li>\n</ul>\n<p><strong>squeeze_and_excite_ratio</strong> : <em>int</em></p>\n<ul>\n<li>Ratio to use in squeeze and excite module (see <a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">Hu et al., 2017</a>), if <code>use_squeeze_and_excite</code> is <code>True</code>. The ratio should never be less than the number of incoming channels, meaning that one should set <code>n_init_filters &gt;= ratio</code> if <code>use_squeeze_and_excite</code> is <code>True</code>.</li>\n</ul>\n<p><strong>globalavgpool</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use global average pooling in the end of the CNN.</li>\n</ul>\n<p><strong>downsampling</strong> : <em>str or None</em></p>\n<ul>\n<li>\n<p>One of <code>None</code> (no downsampling is used), <code>'avgpool'</code> (with\n<code>pool_size=2</code>), <code>'maxpool'</code> (with <code>pool_size=2</code>), or <code>'strided'</code>\n(when strided convolutions with stride and kernel size of 2 is used\nto downsample).</p>\n<p>When one dimension is more than 1.5 times larger than another\ndimension, that (larger) dimension will be downsampling such that it\nis reduced by a factor of 3, instead of 2. This can be changed in\n<code>get_downsampling</code> in <code>model_building_functions.py</code>.</p>\n</li>\n</ul>\n<p><strong>min_size_for_downsampling</strong> : <em>int</em></p>\n<ul>\n<li>\n<p>The minimum that any dimension over which convolutions are made (so\nexcluding samples and channels dimensions) must be if downsampling\nis to take place. This is to prevent downsampling down to too small\nimages.</p>\n<p>E.g., if 2D downsampling is attempted on a <code>(None,7,6,4)</code> image\ntensor while <code>min_size_for_downsampling</code> is <code>6</code>, the downsampling\ngoes through and the result would be <code>(None,3,3,4)</code>. If, on the\nother hand, <code>min_size_for_downsampling</code> was <code>7</code>, the third dimension\nof the image tensor would be too small, and no downsampling would\ntake place.</p>\n</li>\n</ul>\n<h5>Keys concerning submodel <code>network_in_network</code>:</h5>\n<p>Submodel for applying network in network ($<code>1\\times 1</code>$ convolutions) to the\noutput of the <code>cnn</code>. Will only be used if <code>img_names</code> is not None.</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>use</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use the network in network model.</li>\n</ul>\n<p><strong>units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of filters for each convolutional layer as elements.</li>\n</ul>\n<p><strong>globalavgpool</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use global average pooling in the end of the <code>network_in_network</code>.</li>\n</ul>\n<h5>Keys concerning submodel <code>scalar_net</code>:</h5>\n<p>Submodel for processing scalar variables. Will only be used if <code>scalar_names</code> is not None.</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of hidden units in each dense layer as\nelements. If empty, the input is passed on without any processing.</li>\n</ul>\n<p><strong>strides</strong> : <em>int</em> or <em>tuple</em></p>\n<ul>\n<li>Strides used in the convolutional layers. Default is <code>1</code>.</li>\n</ul>\n<p><strong>connect_to</strong> : <em>list of strs</em></p>\n<ul>\n<li>Which other submodels should receive the output of <code>scalar_net</code> as\n(part of) their input. Can contain either <code>'top'</code> and/or\n<code>'FiLM_gen'</code>. It can in principle also be empty, but you should\nrather turn off the use of scalar variables by setting\n<code>scalar_names</code> to <code>None</code>.</li>\n</ul>\n<h5>Keys concerning submodel <code>FiLM_gen</code>:</h5>\n<p>Submodel for modulating the feature maps of the <code>cnn</code> submodel, called\na FiLM generator. See <a href=\"https://distill.pub/2018/feature-wise-transformations/\" rel=\"nofollow\">this</a> for an overview. Will only be used if the <code>connect_to</code> list of either of <code>scalar_net</code> or <code>track_net</code> contains <code>FiLM_gen</code> (and those submodels are used).</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>use</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use the FiLM generator.</li>\n</ul>\n<p><strong>units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of hidden units in each dense layer as\nelements.</li>\n</ul>\n<h5>Keys concerning submodel <code>track_net</code>:</h5>\n<p>Submodel for processing tracks. Will only be used if <code>use_tracks</code> is <code>True</code>.\nUses Deep Sets, see <a href=\"https://arxiv.org/abs/1703.06114\" rel=\"nofollow\">Zaheer et al., 2017</a>.</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>phi_units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of hidden units in each dense layer of the phi\nnetwork (see <a href=\"https://arxiv.org/abs/1703.06114\" rel=\"nofollow\">Zaheer et al., 2017</a>) as elements.\nIf empty, the input is passed on to the rho network.</li>\n</ul>\n<p><strong>rho_units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of hidden units in each dense layer of the rho\nnetwork (see <a href=\"https://arxiv.org/abs/1703.06114\" rel=\"nofollow\">Zaheer et al., 2017</a>) as elements.\nIf empty, the input is passed on without further processing.</li>\n</ul>\n<p><strong>connect_to</strong> : <em>list of strs</em></p>\n<ul>\n<li>Which other submodels should receive the output of <code>track_net</code> as\n(part of) their input. Can contain either <code>'top'</code> and/or\n<code>'FiLM_gen'</code>. It can in principle also be empty, but you should\nrather turn off the use of tracks by setting <code>use_tracks</code> to\n<code>False</code>.</li>\n</ul>\n<h5>Keys concerning submodel <code>gate_net</code>:</h5>\n<p>Submodel for processing to-be-gated images. Will only be used if any images in\nthe passed data dict starts with <code>gate_</code>.</p>\n<p>See \"Keys concerning all submodels\" for keys <code>initialization</code>,\n<code>activation</code>, <code>normalization</code>, <code>layer_reg</code> and <code>dropout</code>.</p>\n<p><strong>units</strong> : <em>list of ints</em></p>\n<ul>\n<li>List with the number of hidden units in each dense layer as\nelements. If empty, the input is passed on to <code>final_activation</code>.</li>\n</ul>\n<p><strong>use_res</strong> : <em>bool</em></p>\n<ul>\n<li>Whether to use a residual connection over the dense layers given by\n<code>units</code>.</li>\n</ul>\n<p><strong>final_activation</strong> : <em>str or config dict</em></p>\n<ul>\n<li>\n<p>Activation function to apply to the last dense layer, or to the\ninput itself, in case <code>units</code> is empty.</p>\n<p>The output of the chosen activation function should be in the range\n[0;1].\nCustom activations <code>'gauss'</code>, ``'gauss_f'<code>,</code>'pgauss'` and\n`'pgauss_f'` have been implemented to use here. The \"p\" stands for\n\"parametric\", while the \"f\" stands for \"flipped\".</p>\n</li>\n</ul>\n<p><strong>final_activation_init</strong> : <em>list</em></p>\n<ul>\n<li>\n<p>List of initial weights for parametric activation functions\n'pgauss'<code>and</code>'pgauss_f'<code>. These contain a single parameter, namely the width of the Gaussian, and so</code>final_activation_init<code>should contain a single float, e.g.,</code>final_activation_init<code>could be</code>[0.5]`.</p>\n<p>If you don't want to simply use the defaults parameters of the\nchosen activation, instead give a <em>config dict</em>. See <a href=\"#doc_config_dict\" rel=\"nofollow\">Explanation of\n<em>str or config dict</em></a>.</p>\n</li>\n</ul>\n<h5>Explanation of <em>str or config dict</em>:</h5>\n<p>Say you want to use the <code>RandomNormal</code> initializer of Keras to\ninitialize the weights of some submodel. If you want to use the\ndefault value of the parameters of this class (<code>mean=0.0, stddev=0.05, seed=None</code>), you can simply give the <em>str</em> <code>'RandomNormal'</code> as the\nvalue for the <code>initialization</code> key described above.\nHowever, if you want to pass some other parameters to the class, you\ncan instead give a <em>config dict</em> as the value for the\n<code>initialization</code> key. A <em>config dict</em> must have two keys,\n<code>'class_name'</code> and <code>'config'</code>. The value corresponding to the\n<code>'class_name'</code> key should be a <em>str</em>, e.g. <code>'RandomNormal'</code>, while the\nvalue corresponding to the <code>'config'</code> key should be a dict containing\nthe keyword arguments you wish to pass to the class (an empty <code>'config'</code>\ndict will use the default values).</p>\n<p>You could for example give the following as the value corresponding to\nthe <code>initialization</code> key:\n<code>{'class_name':'RandomNormal', 'config':{'stddev':1.0}}</code></p>\n<p>See the docs for <code>layer_reg</code> above for additional examples.</p>\n<p>For a more technical definition of the <em>config dict</em>: It is what is\nreturned from <code>keras.utils.serialize_keras_object(keras_object)</code>\nwhere <code>keras_object</code> is the class instance you wish to create.</p>\n<p>In most cases, aliases are set up such that multiple names for the\nsame class are valid, e.g. if you want to use batch normalization as\nnormalization in some submodel, you can pass any of <code>'batch'</code>,\n<code>'BatchNormalization'</code>, <code>'batch_norm'</code>, etc, as the <code>'class_name'</code>.</p>\n<p><a></a></p>\n<h4>dirs : <em>dict</em></h4>\n<p>Dictionary of directories to put logs in. Should contain the keys <code>'log'</code> (the directory to put all the other directories in), <code>'fig'</code> (for saving figures), <code>'saved_models'</code> (for saving models and/or weights of the models during training) and <code>'lr_finder'</code> (for storing the results of the learning rate finder, if used).</p>\n<p>The function <code>deepcalo.utils.create_directories</code> will return such a dictionary (and create its contained directories).</p>\n<h4>save_figs : <em>bool</em></h4>\n<p>Whether to save plots of the model and its submodels.</p>\n<h4>verbose : <em>bool</em></h4>\n<p>Verbose output. Set to <code>2</code> to disable the progress bar for each epoch.</p>\n<h3>Methods</h3>\n<h4>get_model</h4>\n<p>Creates the model, as defined by <code>params</code>, which it takes as its sole input.</p>\n<h4>train</h4>\n<p>Trains the model constructed by <code>get_model</code>.</p>\n<h4>evaluate</h4>\n<p>Evaluates the model constructed by <code>get_model</code>, typically at the end of training using the validation or the test set.</p>\n\n          </div>"}, "last_serial": 6156073, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ad4e09d49b3878d56a02251c677eec6f", "sha256": "3a84b3557b898747d3fc6ca801b15078e3667a9a3d6b80f420dfa45d6e49f32d"}, "downloads": -1, "filename": "deepcalo-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ad4e09d49b3878d56a02251c677eec6f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 48022, "upload_time": "2019-04-19T22:46:12", "upload_time_iso_8601": "2019-04-19T22:46:12.379928Z", "url": "https://files.pythonhosted.org/packages/c4/56/7b3b7a9ae75e6593eea601a246a040eddc2a6baa495d77790bead0cb22e6/deepcalo-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "199f816deb89ef04ea9597010d812bbe", "sha256": "d92430caac8bca5c9b7a8726b8381df74687b35eefa535cd4f555482ae0e69df"}, "downloads": -1, "filename": "deepcalo-0.1.0.tar.gz", "has_sig": false, "md5_digest": "199f816deb89ef04ea9597010d812bbe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 64441, "upload_time": "2019-04-19T22:46:14", "upload_time_iso_8601": "2019-04-19T22:46:14.957195Z", "url": "https://files.pythonhosted.org/packages/66/a6/ec8ed7d4552d373fbbbcf482d03317050ba84cc993222dbaa1c94191482d/deepcalo-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "643334c2e4e819edb21b04aa3fdd7408", "sha256": "a70a2d0c15f3734741648e0d6ec9abebbccf8cee95b368a566487bc3e6f79e1e"}, "downloads": -1, "filename": "deepcalo-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "643334c2e4e819edb21b04aa3fdd7408", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 48022, "upload_time": "2019-04-20T08:13:04", "upload_time_iso_8601": "2019-04-20T08:13:04.466880Z", "url": "https://files.pythonhosted.org/packages/88/df/86e5219cfbf4d942789824cc82889a1a3cec35091c5ed1f0424221647f89/deepcalo-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e583af466166173d2806dd0fcf5303d9", "sha256": "0548679a0251c2bb33cbd85d5eb6f16c74dc1ea902dfc21570d1bd99acb095a7"}, "downloads": -1, "filename": "deepcalo-0.1.1.tar.gz", "has_sig": false, "md5_digest": "e583af466166173d2806dd0fcf5303d9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 64450, "upload_time": "2019-04-20T08:13:06", "upload_time_iso_8601": "2019-04-20T08:13:06.937630Z", "url": "https://files.pythonhosted.org/packages/91/43/308340e7a709aa9d50835a028ca949a6843eee395eda038aa8514f80b1b2/deepcalo-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "f43b6a130a90165f6547e53ec87f6e9a", "sha256": "9ae84eec298ffd240a3298eed87bec6de6dc6b48a25c3dd711b83f5276cc7d48"}, "downloads": -1, "filename": "deepcalo-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f43b6a130a90165f6547e53ec87f6e9a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 45767, "upload_time": "2019-04-29T13:46:33", "upload_time_iso_8601": "2019-04-29T13:46:33.058779Z", "url": "https://files.pythonhosted.org/packages/6f/bf/003f49c3cd8c60606001634de360fd290483b5e0c39015227a03b4af1567/deepcalo-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eab7b2c39ffa212a6cb60b972ac8723a", "sha256": "6765ada7bcef77d7e1bfe37842eed4b99328404e64f4307fb2c4d1cb15e8d7c6"}, "downloads": -1, "filename": "deepcalo-0.1.2.tar.gz", "has_sig": false, "md5_digest": "eab7b2c39ffa212a6cb60b972ac8723a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 62205, "upload_time": "2019-04-29T13:46:38", "upload_time_iso_8601": "2019-04-29T13:46:38.050785Z", "url": "https://files.pythonhosted.org/packages/2c/bf/68af61a45ce019b67ada0380fe509e0bff4c51e3b9fa5b4e119c4a0238c9/deepcalo-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "0a322795f3d870956f47e7ad08a2bfbd", "sha256": "28ddcdf1f1cf35ef728e3b74e1c82b835bced8484a6c45036441c9a49c8c6469"}, "downloads": -1, "filename": "deepcalo-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "0a322795f3d870956f47e7ad08a2bfbd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 45765, "upload_time": "2019-04-30T11:35:13", "upload_time_iso_8601": "2019-04-30T11:35:13.470781Z", "url": "https://files.pythonhosted.org/packages/fa/83/f638d845ff293a8b6c11104a2c00cfa9e890823aec156a94aa8aa4ee86d3/deepcalo-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b34184ca9a1df8590ffef82f97984b6d", "sha256": "9d3b39b82964cccaf88ad5106c7e2cf7e40f4c0565af3783ed27c398024c467a"}, "downloads": -1, "filename": "deepcalo-0.1.3.tar.gz", "has_sig": false, "md5_digest": "b34184ca9a1df8590ffef82f97984b6d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 62192, "upload_time": "2019-04-30T11:35:19", "upload_time_iso_8601": "2019-04-30T11:35:19.306778Z", "url": "https://files.pythonhosted.org/packages/fd/21/93c5d91ac0d512c120e54e32c0320c4d64c7ead625da4663100e6d9f65dd/deepcalo-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "18f09ec550a5abdec91f1506a327a5d2", "sha256": "45c9af032ed4c6546aa13163408567704c6d192a5f83c73f00d3d523e86c071d"}, "downloads": -1, "filename": "deepcalo-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "18f09ec550a5abdec91f1506a327a5d2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 49723, "upload_time": "2019-05-09T09:02:31", "upload_time_iso_8601": "2019-05-09T09:02:31.052530Z", "url": "https://files.pythonhosted.org/packages/d8/ad/f73b00aa0f83d00ab0687eb20162225e48c90b84c855033545e5dc3ac34b/deepcalo-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ff65c5a616e0502bad01708cbd5305af", "sha256": "47596d64dfbda4fff53e5b5d5c842d3ca291c4ba915801eec233ab842347a825"}, "downloads": -1, "filename": "deepcalo-0.1.4.tar.gz", "has_sig": false, "md5_digest": "ff65c5a616e0502bad01708cbd5305af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 65353, "upload_time": "2019-05-09T09:02:33", "upload_time_iso_8601": "2019-05-09T09:02:33.010363Z", "url": "https://files.pythonhosted.org/packages/ae/c5/a886450a355237df59c3a604a37ee58295c0734f8f681d393c6a7796f31a/deepcalo-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "670b8b9eafd3f4dde52696692d0868c4", "sha256": "b4853a8f7adb5cc9a5ab01eab67eb9e1a9a45bff47129ed3bbae01258ba3012b"}, "downloads": -1, "filename": "deepcalo-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "670b8b9eafd3f4dde52696692d0868c4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 50884, "upload_time": "2019-05-14T14:38:35", "upload_time_iso_8601": "2019-05-14T14:38:35.337566Z", "url": "https://files.pythonhosted.org/packages/4e/87/54b4b1cfa0cda7604d606a8e0f81beed0456145e47b6cbf6c6790e4aebf1/deepcalo-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d5dba03f98d034c3bee9779665b8ea63", "sha256": "e6ac37839f330ebc2d1d8d2d535fe2e6f30b0b8a6de38927745e8fe20e43b8b7"}, "downloads": -1, "filename": "deepcalo-0.1.5.tar.gz", "has_sig": false, "md5_digest": "d5dba03f98d034c3bee9779665b8ea63", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66498, "upload_time": "2019-05-14T14:38:37", "upload_time_iso_8601": "2019-05-14T14:38:37.293487Z", "url": "https://files.pythonhosted.org/packages/2e/38/cb198e7fda5a64b35ae04aa0d3cce50a4fffb797755cd3aa27cd01a63516/deepcalo-0.1.5.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "3d3ad35eab2b404d94d6146f5c3850f7", "sha256": "c4c77de281b70b6c945e832bf981e6fb48fd0e9d484de8eb588a4609b139127c"}, "downloads": -1, "filename": "deepcalo-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3d3ad35eab2b404d94d6146f5c3850f7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 52766, "upload_time": "2019-08-31T13:23:29", "upload_time_iso_8601": "2019-08-31T13:23:29.555404Z", "url": "https://files.pythonhosted.org/packages/fa/8a/716627e0c24415090bdfdd265947c2051f40cd0a1c140e4e2dd1cf2ee7a3/deepcalo-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "efd0c4bf183a6265d60d23668fb0334c", "sha256": "33ed447ca7482c56576209b489b168e7ef359793a64dc5083b8a2d19e1d3e30f"}, "downloads": -1, "filename": "deepcalo-0.2.0.tar.gz", "has_sig": false, "md5_digest": "efd0c4bf183a6265d60d23668fb0334c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 69651, "upload_time": "2019-08-31T13:23:31", "upload_time_iso_8601": "2019-08-31T13:23:31.874778Z", "url": "https://files.pythonhosted.org/packages/25/66/add91052c3c8a61503519d51552846c855768323ca16a376993a089485a2/deepcalo-0.2.0.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "43e617e65aee850e03628405838b514e", "sha256": "ddae8fe3153c3c90d7177f5234bfca9dcc5e86366445097de8587a6499da6f20"}, "downloads": -1, "filename": "deepcalo-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "43e617e65aee850e03628405838b514e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55046, "upload_time": "2019-11-17T17:10:01", "upload_time_iso_8601": "2019-11-17T17:10:01.575234Z", "url": "https://files.pythonhosted.org/packages/05/dc/0e1fe9d7b393cfaf55661c032e2cc895894e5064c2022b2d810c6f12e5b1/deepcalo-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3fa9a3dbcf24e9435d080a9f9df3feb9", "sha256": "58dc742b04c69432be4e2ff1df76a064d2ded9f941c30d8c4c3f6c7eeb22d0fa"}, "downloads": -1, "filename": "deepcalo-0.2.2.tar.gz", "has_sig": false, "md5_digest": "3fa9a3dbcf24e9435d080a9f9df3feb9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 71950, "upload_time": "2019-11-17T17:10:03", "upload_time_iso_8601": "2019-11-17T17:10:03.356740Z", "url": "https://files.pythonhosted.org/packages/53/2b/6739f8e5d58dcf93e18d0afcd7c0c6a96ac6b8b69d45ef273d84e3143d96/deepcalo-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "d961bb49fee1704eac6e4c9aa2e1a9bf", "sha256": "1f3fd8791a5737f6bae02b2ea8ae5d6fe80bf8985f52a1fad96bf37685041287"}, "downloads": -1, "filename": "deepcalo-0.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "d961bb49fee1704eac6e4c9aa2e1a9bf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55224, "upload_time": "2019-11-18T14:14:09", "upload_time_iso_8601": "2019-11-18T14:14:09.589754Z", "url": "https://files.pythonhosted.org/packages/53/23/357f4dd7ed6f62d1ae71a118cc70ca0d5721f17a4f70d6d1881547986ea1/deepcalo-0.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d3ef90e00e55ff091929281720c00a35", "sha256": "44bc0b04d1f510067eede02876712727dbac533cefeca73b71ec122e80cb762d"}, "downloads": -1, "filename": "deepcalo-0.2.3.tar.gz", "has_sig": false, "md5_digest": "d3ef90e00e55ff091929281720c00a35", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 72137, "upload_time": "2019-11-18T14:14:11", "upload_time_iso_8601": "2019-11-18T14:14:11.444692Z", "url": "https://files.pythonhosted.org/packages/5c/8f/2cbcd109dc860a4fac49f32c849ec006c2e82335524c38c49142c2e1885f/deepcalo-0.2.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d961bb49fee1704eac6e4c9aa2e1a9bf", "sha256": "1f3fd8791a5737f6bae02b2ea8ae5d6fe80bf8985f52a1fad96bf37685041287"}, "downloads": -1, "filename": "deepcalo-0.2.3-py3-none-any.whl", "has_sig": false, "md5_digest": "d961bb49fee1704eac6e4c9aa2e1a9bf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55224, "upload_time": "2019-11-18T14:14:09", "upload_time_iso_8601": "2019-11-18T14:14:09.589754Z", "url": "https://files.pythonhosted.org/packages/53/23/357f4dd7ed6f62d1ae71a118cc70ca0d5721f17a4f70d6d1881547986ea1/deepcalo-0.2.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d3ef90e00e55ff091929281720c00a35", "sha256": "44bc0b04d1f510067eede02876712727dbac533cefeca73b71ec122e80cb762d"}, "downloads": -1, "filename": "deepcalo-0.2.3.tar.gz", "has_sig": false, "md5_digest": "d3ef90e00e55ff091929281720c00a35", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 72137, "upload_time": "2019-11-18T14:14:11", "upload_time_iso_8601": "2019-11-18T14:14:11.444692Z", "url": "https://files.pythonhosted.org/packages/5c/8f/2cbcd109dc860a4fac49f32c849ec006c2e82335524c38c49142c2e1885f/deepcalo-0.2.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:29 2020"}