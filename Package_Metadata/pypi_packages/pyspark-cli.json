{"info": {"author": "Jino Jossy", "author_email": "jinojossy93@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# PySpark CLI\n\nThis will implement a PySpark Project boiler plate code based on user input.\n\nApache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.\n\nPySpark is the Python API for Spark.\n\n## Installation Steps:\n    \n    git clone https://github.com/qburst/PySparkCLI.git\n\n    cd PySparkCLI\n\n    pip3 install -e . --user\n    \n## Create a PySpark Project\n    \n    pysparkcli create [PROJECT_NAME] --master [MASTER_URL] --cores [NUMBER]\n\n    master - The URL of the cluster it connects to. You can also use -m instead of --master.\n    cores - You can also use -c instead of --cores.\n            \n## Run a PySpark Project\n    \n    pysparkcli run [PROJECT_NAME]\n\n## Initiate Stream for Project\n\n    pysparkcli stream [PROJECT_NAME] [STREAM_FILE_NAME]\n    \n## PySpark Project Test cases\n    \n   * Running by **Project name**\n     \n    pysparkcli test [PROJECT_NAME]\n   * Running individual test case with filename: **test_etl_job.py**\n   \n    pysparkcli test [PROJECT_NAME] -t [etl_job]\n    \n## FAQ\n\nCommon issues while installing pysparkcli:\n\n    * pysparkcli: command not found\n        Make sure you add user\u2019s local bin to PATH variable.\n        Add the following code in .bashrc file\n\n        # set PATH so it includes user's private bin if it exists\n        if [ -d \"$HOME/.local/bin\" ] ; then\n            PATH=\"$HOME/.local/bin:$PATH\"\n        fi\n\n\n    * JAVA_HOME is not set\n        Make sure JAVA_HOME is pointing to your JDK and PYSPARK_PYTHON variable is created.\n        You can add them manually by in .bashrc file:\n        \n        Example:\n\n            export PYSPARK_PYTHON=python3\n            export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n\n        Save the file and run the following to update environment.\n\n            source ~/.bashrc\n\n## Project Structure\n\nThe basic project structure is as follows:\n\n```bash\nsample\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 configs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etl_config.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 jobs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etl_job.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 settings\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 default.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 local.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 production.py\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 test_data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 employees\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 part-00000-9abf32a3-db43-42e1-9639-363ef11c0d1c-c000.snappy.parquet\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 employees_report\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 part-00000-4a609ba3-0404-48bb-bb22-2fec3e2f1e68-c000.snappy.parquet\n    \u2514\u2500\u2500 test_etl_job.py\n\n8 directories, 15 files\n```\n## PySparkCLI Demo\n\n[![PySparkCLI Demo](https://img.youtube.com/vi/wuoBKJYSfTE/0.jpg)](https://www.youtube.com/watch?v=wuoBKJYSfTE)\n\n## Contribution Guidelines\n\nCheck out [here](https://github.com/qburst/PySparkCLI/blob/master/CONTRIBUTING.md) for our contribution guidelines.\n\n## Sponsors\n\n[![QBurst](https://www.qburst.com/images/responsive/QBlogo.svg)](https://www.qburst.com)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/qburst/PySparkCLI", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pyspark-cli", "package_url": "https://pypi.org/project/pyspark-cli/", "platform": "", "project_url": "https://pypi.org/project/pyspark-cli/", "project_urls": {"Homepage": "https://github.com/qburst/PySparkCLI"}, "release_url": "https://pypi.org/project/pyspark-cli/1.0.3/", "requires_dist": null, "requires_python": "", "summary": "PySpark Project Buiding Tool", "version": "1.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PySpark CLI</h1>\n<p>This will implement a PySpark Project boiler plate code based on user input.</p>\n<p>Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, MLlib for machine learning, GraphX for graph processing, and Spark Streaming.</p>\n<p>PySpark is the Python API for Spark.</p>\n<h2>Installation Steps:</h2>\n<pre><code>git clone https://github.com/qburst/PySparkCLI.git\n\ncd PySparkCLI\n\npip3 install -e . --user\n</code></pre>\n<h2>Create a PySpark Project</h2>\n<pre><code>pysparkcli create [PROJECT_NAME] --master [MASTER_URL] --cores [NUMBER]\n\nmaster - The URL of the cluster it connects to. You can also use -m instead of --master.\ncores - You can also use -c instead of --cores.\n</code></pre>\n<h2>Run a PySpark Project</h2>\n<pre><code>pysparkcli run [PROJECT_NAME]\n</code></pre>\n<h2>Initiate Stream for Project</h2>\n<pre><code>pysparkcli stream [PROJECT_NAME] [STREAM_FILE_NAME]\n</code></pre>\n<h2>PySpark Project Test cases</h2>\n<ul>\n<li>Running by <strong>Project name</strong></li>\n</ul>\n<pre><code>pysparkcli test [PROJECT_NAME]\n</code></pre>\n<ul>\n<li>Running individual test case with filename: <strong>test_etl_job.py</strong></li>\n</ul>\n<pre><code>pysparkcli test [PROJECT_NAME] -t [etl_job]\n</code></pre>\n<h2>FAQ</h2>\n<p>Common issues while installing pysparkcli:</p>\n<pre><code>* pysparkcli: command not found\n    Make sure you add user\u2019s local bin to PATH variable.\n    Add the following code in .bashrc file\n\n    # set PATH so it includes user's private bin if it exists\n    if [ -d \"$HOME/.local/bin\" ] ; then\n        PATH=\"$HOME/.local/bin:$PATH\"\n    fi\n\n\n* JAVA_HOME is not set\n    Make sure JAVA_HOME is pointing to your JDK and PYSPARK_PYTHON variable is created.\n    You can add them manually by in .bashrc file:\n    \n    Example:\n\n        export PYSPARK_PYTHON=python3\n        export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n\n    Save the file and run the following to update environment.\n\n        source ~/.bashrc\n</code></pre>\n<h2>Project Structure</h2>\n<p>The basic project structure is as follows:</p>\n<pre>sample\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 configs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etl_config.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 <span class=\"nb\">jobs</span>\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etl_job.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 settings\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 default.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 local.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 production.py\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 test_data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 employees\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 part-00000-9abf32a3-db43-42e1-9639-363ef11c0d1c-c000.snappy.parquet\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 employees_report\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 part-00000-4a609ba3-0404-48bb-bb22-2fec3e2f1e68-c000.snappy.parquet\n    \u2514\u2500\u2500 test_etl_job.py\n\n<span class=\"m\">8</span> directories, <span class=\"m\">15</span> files\n</pre>\n<h2>PySparkCLI Demo</h2>\n<p><a href=\"https://www.youtube.com/watch?v=wuoBKJYSfTE\" rel=\"nofollow\"><img alt=\"PySparkCLI Demo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/03c57560ac581cd11ad42f5d05c7c82d2748e4b6/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f77756f424b4a59536654452f302e6a7067\"></a></p>\n<h2>Contribution Guidelines</h2>\n<p>Check out <a href=\"https://github.com/qburst/PySparkCLI/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">here</a> for our contribution guidelines.</p>\n<h2>Sponsors</h2>\n<p><a href=\"https://www.qburst.com\" rel=\"nofollow\"><img alt=\"QBurst\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2e23c9e1c6a438b5b605d1c2cf9177aa0134d66b/68747470733a2f2f7777772e7162757273742e636f6d2f696d616765732f726573706f6e736976652f51426c6f676f2e737667\"></a></p>\n\n          </div>"}, "last_serial": 6864000, "releases": {"0.0.9": [{"comment_text": "", "digests": {"md5": "617090a9deb1264f282fca6bcc603724", "sha256": "f293233da4c5aae6719d0b30463fe8df2fd4f3f732beaac569249224f00a76c0"}, "downloads": -1, "filename": "pyspark_cli-0.0.9-py3.6.egg", "has_sig": false, "md5_digest": "617090a9deb1264f282fca6bcc603724", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 42442, "upload_time": "2020-01-20T10:27:45", "upload_time_iso_8601": "2020-01-20T10:27:45.450980Z", "url": "https://files.pythonhosted.org/packages/4b/aa/b9e64293bb8ea1bf228763d96d1fd3146c3e88cecf8885ab9c8e1291a40f/pyspark_cli-0.0.9-py3.6.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "16c79d8c5dc626fcf47da82eda8009a7", "sha256": "8e0473dbd4681b0a552b2cf51377f00a24293baf2b4ec5d44ede50fadb8bc006"}, "downloads": -1, "filename": "pyspark_cli-0.0.9-py3-none-any.whl", "has_sig": false, "md5_digest": "16c79d8c5dc626fcf47da82eda8009a7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 34708, "upload_time": "2020-01-20T10:27:41", "upload_time_iso_8601": "2020-01-20T10:27:41.161715Z", "url": "https://files.pythonhosted.org/packages/56/9f/a228f2449625b1b0d2105f84ecbf7047eb73f5a2c300af649c2151439520/pyspark_cli-0.0.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eb286bf0fac8f912344789df0c33a306", "sha256": "147e1e9ec29949be923e83ae58fb6de1e30c672bc1bbff284ce89aa24c2952c2"}, "downloads": -1, "filename": "pyspark-cli-0.0.9.tar.gz", "has_sig": false, "md5_digest": "eb286bf0fac8f912344789df0c33a306", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18163, "upload_time": "2020-01-20T10:27:47", "upload_time_iso_8601": "2020-01-20T10:27:47.284668Z", "url": "https://files.pythonhosted.org/packages/5c/ae/e0ed40d3b0c329329743d123912abe754854e3756e9fffe9e2b88f5fd5d5/pyspark-cli-0.0.9.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "3afc19d34a7579bbbedc2d010e3fd8ed", "sha256": "d5cc55fb631f0db218434fd63e939bd56d7681b0a2ef39bb304a348750969544"}, "downloads": -1, "filename": "pyspark_cli-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3afc19d34a7579bbbedc2d010e3fd8ed", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35470, "upload_time": "2020-01-27T08:38:42", "upload_time_iso_8601": "2020-01-27T08:38:42.803618Z", "url": "https://files.pythonhosted.org/packages/bc/40/b061e08b4c812ab121f232d00c3449b9782d455c2fc8e3685ebe054e57e9/pyspark_cli-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2abd8f7d8aee19c81316db409161a6db", "sha256": "fcb63bba47bc28b9c3e59d672b1e6096a7fb5da139a28dceb18fc8b95c1afb8e"}, "downloads": -1, "filename": "pyspark-cli-1.0.0.tar.gz", "has_sig": false, "md5_digest": "2abd8f7d8aee19c81316db409161a6db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18523, "upload_time": "2020-01-27T08:38:44", "upload_time_iso_8601": "2020-01-27T08:38:44.340020Z", "url": "https://files.pythonhosted.org/packages/42/41/6aeb44d8a4a46b59a37e58e0d8e37e1cb646295df5d7bff65bb5e2686dc3/pyspark-cli-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "f8af9960f20e0001c097f6d7a07dbe4a", "sha256": "6fef3aad5869b40e5674de933e8ae5d07fa576536f29d852a466b075648e87c5"}, "downloads": -1, "filename": "pyspark_cli-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f8af9960f20e0001c097f6d7a07dbe4a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 36105, "upload_time": "2020-02-26T06:27:26", "upload_time_iso_8601": "2020-02-26T06:27:26.642031Z", "url": "https://files.pythonhosted.org/packages/71/ea/27f09f4306cd05be974a1b854f8502ad14c4b8bc2e961a946887ac79bddb/pyspark_cli-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "475d6fb10e7dcc39f8248444608cefb9", "sha256": "37c964fb34ddc40254d5f7dd57d8cb1e80c11752b29fd0d12d06fd32d9d97bbb"}, "downloads": -1, "filename": "pyspark-cli-1.0.1.tar.gz", "has_sig": false, "md5_digest": "475d6fb10e7dcc39f8248444608cefb9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18989, "upload_time": "2020-02-26T06:27:29", "upload_time_iso_8601": "2020-02-26T06:27:29.192628Z", "url": "https://files.pythonhosted.org/packages/1a/0c/3ce6ba01714a1242f830d66597e5c30f9590fcb0b3b7e5d4c2cd0b9bc561/pyspark-cli-1.0.1.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "3463e65ab6b084a21878b74b908a1f61", "sha256": "9d7fd7146288f8dc1f3d9e2d15bdc4ef894dcca8d969efa640cd0a88e675bc99"}, "downloads": -1, "filename": "pyspark-cli-1.0.3.tar.gz", "has_sig": false, "md5_digest": "3463e65ab6b084a21878b74b908a1f61", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13202, "upload_time": "2020-03-23T08:13:26", "upload_time_iso_8601": "2020-03-23T08:13:26.859980Z", "url": "https://files.pythonhosted.org/packages/19/e0/6340ef59c7dbbabcf38997ee1006e523b0bc7204a97053988119a964dc14/pyspark-cli-1.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3463e65ab6b084a21878b74b908a1f61", "sha256": "9d7fd7146288f8dc1f3d9e2d15bdc4ef894dcca8d969efa640cd0a88e675bc99"}, "downloads": -1, "filename": "pyspark-cli-1.0.3.tar.gz", "has_sig": false, "md5_digest": "3463e65ab6b084a21878b74b908a1f61", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13202, "upload_time": "2020-03-23T08:13:26", "upload_time_iso_8601": "2020-03-23T08:13:26.859980Z", "url": "https://files.pythonhosted.org/packages/19/e0/6340ef59c7dbbabcf38997ee1006e523b0bc7204a97053988119a964dc14/pyspark-cli-1.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:19 2020"}