{"info": {"author": "delzac", "author_email": "delzac.jh@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# CNTKx\nCNTKx is a deep learning library that builds on and extends Microsoft Cognitive Toolkit [CNTK](https://github.com/Microsoft/CNTK). \nDespite the last planned release of cntk 2.7, cntkx will continue to be in active development, more models and pre-built components coming soon!\n\nFeel free to open an issue for any request or a PR to contribute :)\n\n## Installation\ncntkx is written in pure python and cntk is a dependency to it. Please get a working installation of cntk first. Then:\n\n    pip install cntkx\n\ncntkx only works with `python>=3.6`\n\n\n## Available Components\n| ops | Description |\n| --- | ---|\n| `floor_division` | element-wise floor_division |\n| `remainder` | element-wise remainder of division |\n| `scalar` | cast tensor to scalar (1,) |\n| `cumsum` | Cumulative summation along axis |\n| `upsample` | Upsample by k factor (for image) |\n| `centre_crop` | Crop centre of image |\n| `swish` | Activation |\n| `mish` | Activation |\n| `hardmax` | Activation |\n| `erf` | Error function |\n| `gelu` | Gaussian Error Linear Unit function |\n| `gelu_fast` | fast approximation of Gaussian Error Linear Unit function |\n| `sequence.pad` | Pad at start or end of sequence axis |\n| `sequence.length` | length of sequence |\n| `sequence.position` | position of every sequence element |\n| `sequence.stride` | strides across sequential axis  |\n| `sequence.join` | joins two sequence along their sequential axis  |\n| `sequence.window` | creates sliding window along the sequence axis  |\n| `sequence.window_causal` | creates causal sliding window along the sequence axis  |\n| `sequence.reverse` | reverses the items along the dynamic sequence axis  |\n| `sequence.reduce_mean` | calculates the mean along the dynamic sequence axis  |\n| `sequence.reduce_concat_pool` | drop-in replace for sequence.last  |\n| `random.sample` | Samples an unnormalised log probability distribution |\n| `random.sample_with_bias` | Samples an unnormalised log probability distribution over-weighted to more probable classes |\n| `random.sample_top_k` | Samples from the top_k of an unnormalised log probability distribution |\n| `batchmatmul` | Batch Matrix Multiplication on a static batch axis, similar to tf.matmul |\n\n| Layers | Description |\n| --- | ---|\n| `QRNN` | Quasi-Recurrent Neural Network |\n| `Recurrence` | With option to apply `VariationalDroppout` |\n| `PyramidalBiRecurrence` | Pyramidal bi-directional recurrence |\n| `VariationalDropout` | Single binary dropout mask for entire sequence |\n| `SinusoidalPositionalEmbedding` | Non-learnable positional embedding (no max sequence length) |\n| `PositionalEmbedding` | Learnable Positional Embedding (used in BERT) |\n| `BertEmbeddings` | BERT Embeddings (word + token_type + positional) |\n| `BertPooler` | Pooler used in BERT |\n| `SpatialPyramidPooling` | Fixed pooled representation regardless of image input size |\n| `GatedLinearUnit` | Gated Convolutional Neural Network |\n| `ScaledDotProductAttention` | Attention used in BERT and Transformer (aka 'attention is all you need') |\n| `MultiHeadAttention` | Attention used in BERT and Transformer (aka 'attention is all you need') |\n| `GaussianWindowAttention` | Windowed attention instead of conventional attention where everything is attended at the same time |\n| `SequentialDense` | Applies Dense to a window of sequence item along sequence axis |\n| `SequentialMaxPooling` | Max pool across sequential axis and static axes |\n| `SequentialAveragePooling` | Average pool across sequential axis and static axes |\n| `SequentialConcatPooling` | Concat Average and Mean pool across sequential axis and static axes |\n| `vFSMN` | Vectorised Feedforward Sequential Memory Networks |\n| `cFSMN` | Compact Feedforward Sequential Memory Networks |\n| `BiRecurrence` | BiRecurrence recurrent layer with weight tying option to half parameter requirement |\n| `GlobalConcatPooling` | Global spatial concat pooling of ave and mean |\n|`FilterResponseNormalization`| Drop in replacement for batch norm with superior performance |\n|`Boom`| More parametrically efficient alternative to Position-Wise FeedForward layer found in Transformer |\n|`GaussianAttentionSeqImage`| Memory efficient attention that used 2d gaussian filters for images |\n| `SequenceDropout` | Dropout entire sequence elements |\n| `SEBlock` | Squeeze and Excitation block |\n| `SequenceSEBlock` | Squeeze and Excitation block for variable width image sequence |\n\n\n| Blocks | Description |\n| --- | ---|\n| `WeightDroppedLSTM` | A form of regularised LSTM |\n| `IndyLSTM` | A parameter efficient form of LSTM |\n| `IndRNN` | a RNN with long memory and can be stacked deeply |\n\n| Loss | Description |\n| --- | ---|\n| `gaussian_mdn_loss` | loss function when using Mixture density network |\n| `focal_loss_with_softmax` | A kind of cross entropy that handles extreme class imbalance |\n| `cross_entropy_with_softmax` | Added `label smoothing regularisation` in cross entropy with softmax |\n| `generalised_robust_barron_loss` | generalised robust loss |\n\n| Models | Description |\n| --- | ---|\n| `VGG` | Image Classification |\n| `UNET` | Semantic Segmentation |\n| `Transformer` | Language Modelling |\n| `MDN` | Mixture Density Networks | \n\n\n| Pre-trained models | Description |\n| --- | ---|\n| `Bert` | Bidirectional Encoder Representations from Transformers |\n| [fwd_wt103.hdf5](https://1drv.ms/u/s!AjJ4XyC3prp8mItNxiawGK4gD8iMhA?e=wh7PLB) | The weight parameters of the fastai's pytorch model. To be used to initialise `PretrainedWikitext103LanguageModel` |\n| [fwd_wt103.cntk](https://1drv.ms/u/s!AjJ4XyC3prp8mItPBdfmDYr9QP7J4w?e=k1BXlW) | The converted cntk model of fastai's pytorch model. To be used with `C.load_model` |\n| [fwd_wt103.onnx](https://1drv.ms/u/s!AjJ4XyC3prp8mItO70T_q8HOPwa6aQ?e=h2Fiv5) | The converted ONNX model of fastai's pytorch model. |\n\n\n| Learners | Description |\n| --- | ---|\n| `CyclicalLearningRate` | a method to eliminate the need to find best value and schedule for learning rate |\n| `RAdam` | a variant of `Adam` that doesn't require any warmup |\n\n| Misc | Description |\n| --- | ---|\n| `CTCEncoder` | Helper class to convert data into a format acceptable for cntk's ctc implementation |\n\n\n## C# CNTK Tutorials\nThis library is implemented in pure cntk python API. For help in cntk c#, you can refer to the two repository \n[deep-learning-with-csharp-and-cntk](https://github.com/anastasios-stamoulis/deep-learning-with-csharp-and-cntk) \nand [DeepBelief_Course4_Examples](https://github.com/AllanYiin/DeepBelief_Course4_Examples). \n\n\n## F# CNTK\nFor the F# wrapper of CNTK please visit [FsCNTK](https://github.com/fwaris/FsCNTK), \nit also contains some example implementations like seq2seq, autoencoder, LSTM, GAN.\n\n\n## News\n***2020-05-01***\n### Added `SEBlock` and `SequenceSEBlock`\n`SEBlock` and `SequenceSEBlock` are squeeze-excitation blocks that adaptively recalibrates channel-wise feature\nresponses by explicitly modelling interdependencies between channels. It was show that these blocks can be\nstacked together to form SENet architectures that generalise extremely effectively across different datasets.\n\nIts the winner for ILSVRC2017 classification submission. More details can be found in the\npaper [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) by Jie hu et al.\n\n\n***2020-04-20***\n### Added `SequenceDropout`\n`SequenceDropout` dropouts entire sequence elements along the dynamic sequence axis.\n\n\n\n***2020-04-15***\n### Added `GaussianAttentionSeqImage`\n`GaussianAttentionSeqImage` is a 2d spatial gaussian attention.\nTo use, the encoded image should be formulated as a cntk sequence (example below). This can be useful when \nyou are constraint by gpu memory as 2d gaussian attention is more memory efficient than standard attention.\n\nThis is from the deepmind paper, DRAW: A Recurrent Neural Network for Image Generation by Gregor et al\nMore details can be found in the following https://arxiv.org/abs/1502.04623\n\nExample:\n\n    n = 5\n    num_channels = 3\n    image_height = 64\n    expected_image_width = 1000\n    image_seq = C.sequence.input_variable((num_channels, image_height))  # rgb image with variable width and fixed height\n    decoder_hidden_state = ...  # from decoder somewhere in the network\n    attended_image = Cx.layers.GaussianAttentionSeqImage(n, image_height, expected_image_width)(image_seq, decoder_hidden_state)\n\n    assert attended_image.shape == (num_channels, n, n)\n\n\n***2020-03-29.***\n#### Added `generalised_robust_barron_loss` and `sample_with_bias`\n`generalised_robust_barron_loss` is a generalisation for generalization of the Cauchy/Lorentzian,\nGeman-McClure, Welsch/Leclerc, generalized Charbonnier, Charbonnier/pseudo-Huber/L1-L2, and\nL2 loss functions.\n\nCan be used as a drop-in replacement in any regression task that you have.\n\nFor more details, please refer to [A General and Adaptive Robust Loss Function](https://arxiv.org/abs/1701.03077), Jonathan T. Barron,\nor this [video](https://www.youtube.com/watch?v=BmNKbnF69eY).\nIt is the Best Paper Award Finalist in CVPR 2019.\n\n\nImplemented `sample_with_bias` to sample more likely classes as a replacement \nfor `sample_top_k` which cannot be used inside a `UnfoldFrom`. `sample_with_bias` reduces sampling variance especially when you have a long tail.\n\n\n\n***2020-02-11.***\n#### Added `Boom`\nBoom layer from SHA-RNN by S. Merity creator of QRNN. Alternative to PositionwiseFeedForward. Serves the same function as\nPositionwiseFeedForward found in transformer.\n\nBoom layer minimizes computation and removes an entire matrix of parameters compared to traditional down-projection layers.\n\nFor more detail please read: [Single Headed Attention RNN: Stop Thinking With Your Head](https://arxiv.org/abs/1911.11423) by Stephen Merity.\n\n\n***2019-12-03.***\n#### Added `FilterResponseNormalization` and `ThresholdedLinearUnit`\nAdded cntk implementation of `FilterResponseNormalization`. Filter Response Normalization (FRN) layer \nis a novel combination of a normalization and an activation function,\nthat can be used as a drop-in replacement for other normalizations and activations.\n\nThe method operates on each activation map of each batch sample\nindependently, eliminating the dependency on other batch samples or channels of the same sample.\nThe method outperforms BN and all alternatives in a variety of settings for all batch sizes.\nFRN layer performs \u00e2\u2030\u02c60.7\u00e2\u02c6\u20191.0% better on top-1 validation accuracy than BN with large mini-batch sizes on\nImagenet classification on InceptionV3 and ResnetV2-50 architectures. Further, it performs >1% better\nthan GN on the same problem in the small mini-batch size regime. For object detection problem on COCO dataset,\nFRN layer outperforms all other methods by at least 0.3\u00e2\u02c6\u20190.5% in all batch size regimes.\n\nPlease refer to the paper [Filter Response Normalization Layer: Eliminating Batch Dependence \nin the Training of Deep Neural Networks](https://arxiv.org/abs/1911.09737v1) for more details .\n\n\n\n***2019-11-04.***\n#### Added `ops.floor_division`, `ops.remainder`, `sequence.window_causal` and `SequentialDense`\nAdd in new operations stated above. `sequence.window` now has an additional argument that lets you control striding.\n`sequence.window_causal` creates causal window that doesn't leak future information into the past (preserve causality).\n`SequentialDense` convenience layer added to apply dense to a window of sequence item,\nmuch like `SequentialConvolution` but with better memory performance.\n\n\n\n***2019-11-04.***\n#### Added `SequentialConcatPooling`, `Cx.Sequence.reduce_concat_pool` and `GlobalConcatPooling`\n`Cx.Sequence.reduce_concat_pool` concatenates the last item in the sequence axis with the summarisation\nof the sequence represented by `reduce_max` and `reduce_mean` of the sequence axis. Anytime `C.sequence.last` is used,\nthis can be a drop-in replacement.\n\nExample:\n\n    n = 32\n    a = C.sequence.input_variable(n)\n    b = Cx.sequence.reduce_concat_pool(a)\n\n    assert b.shape == (n * 3, )\n\n\n`SequentialConcatPooling` does spatial concat pooling over the sequential axis.\nConcat pooling is the concatenation of both average pooling and max pooling. In any situation where max or ave \npooling is appropriate, concat pooling can be used as a drop-in replacement and achieve improvements in performance.\n\nExample:\n\n    a = C.sequence.input_variable((3, 10))\n    b = SequentialConcatPooling(filter_shape=(2, 2), strides=2)(a)\n\n    assert b.shape == (6, 10)\n\n    n = [np.random.random((3, 10)).astype(np.float32),\n         np.random.random((3, 10)).astype(np.float32),\n         np.random.random((3, 10)).astype(np.float32),\n         np.random.random((3, 10)).astype(np.float32), ]\n\n    print(b.eval({a: n}))\n\n\n`GlobalConcatPooling` is the standard spatial concat pooling of both max pool and ave pool.\n\n\n***2019-10-15.***\n#### Added `mish` activation function and `RAdam` learner.\n`mish` is an activation function is introduced in [Mish: A Self Regularized Non-Monotonic Neural Activation Function](https://arxiv.org/abs/1908.08681v2)\nby Diganta Misra. Experiments show that `mish` tends to work better than both ReLU and Swish along with other standard\nactivation functions in many deep networks across challenging datasets. For instance,\nin Squeeze Excite Net-18 for CIFAR 100 classification, the network with Mish had an increase in\nTop-1 test accuracy by 0.494% and 1.671% as compared to the same network with Swish and ReLU respectively.\nThe similarity to Swish along with providing a boost in performance and its simplicity in implementation\nmakes it easier for researchers and developers to use Mish in their Neural Network Models.\n\nThis activation function is adopted in `fast ai`.\n\nRectified Adam or `RAdam` is a `Adam` optimiser variant that doesn't require a warmup schedule, which `Adam` tends\nto need to maintain stability. In this cntk implementation, we added a `RAdam` like optimiser based\non the work of [On the adequacy of untuned warmup for adaptive optimization](https://arxiv.org/abs/1910.04209) by Jerry Ma and Denis Yarats.\n\n`RAdam` is adopted in `fast ai` too.\n\n\n\n***2019-09-30.***\n#### Added `BiRecurrence` with weight tying\nMade improvement to weight tying of BiRecurrence by have one parameter tensor token for every state \nin the step function per direction (forward and backward). This will allow forward and backward token\nto have more representational flexibility. Previously, all states use the same forward or backward token.\n\n\n***2019-09-06.***\n#### Added `BiRecurrence` with weight tying\nAdd a wrapper to create a bidirectional recurrent layer using `BiRecurrence`. Included in the implementation\nis an option to half the number of parameters required by  bidirectional recurrent layer. This is done\nby only using one recurrent unit to do both forward and backward computation instead of the usual two.\nA forward and backward token is used to initialise the hidden state so that the recurrent unit can tell\nthe directionality.\n\nMore details can be found in the paper [Efficient Bidirectional Neural Machine Translation](https://arxiv.org/abs/1908.09329)\n\nExample:\n\n    a = C.sequence.input_variable(10)\n    b = BiRecurrence(LSTM(100), weight_tie=True)(a)\n\n    assert b.shape == (200, )\n\n\n***2019-08-29.***\n#### Added `PretrainedWikitext103LanguageModel`\nCNTK implementation of Fast AI's Universal  Language  ModelFine-tuning (ULMFiT) English model has been added.\nThis language model was trained on Wikitext-103 and can be used as a base model for any downstream language task.\n\nIt is also much more efficient to run compare to BERT and other Transformer language models.\n\nFor more details, you can refer to the original paper [here](https://arxiv.org/abs/1801.06146)\n\nExample:\n\n    vocab_size = 238462\n    converted_hdf5_model_file_path = 'PATH/fwd_wt103.hdf5'  # this is not the original pytorch model\n    lm = PretrainedWikitext103LanguageModel(converted_hdf5_model_file_path)\n\n    a = C.sequence.input_variable(vocab_size)\n    prediction = lm(a)  # next-word-prediction\n    features = prediction.features  # features of tokens\n\n    assert prediction.shape == (vocab_size, )\n    assert features.shape == (400, )\n\n| Model | Description |\n| --- | ---|\n| [fwd_wt103.hdf5](https://1drv.ms/u/s!AjJ4XyC3prp8mItNxiawGK4gD8iMhA?e=wh7PLB) | The weight parameters of the fastai's pytorch model. To be used to initialise `PretrainedWikitext103LanguageModel` |\n| [fwd_wt103.cntk](https://1drv.ms/u/s!AjJ4XyC3prp8mItPBdfmDYr9QP7J4w?e=k1BXlW) | The converted cntk model of fastai's pytorch model. To be used with `C.load_model` |\n| [fwd_wt103.onnx](https://1drv.ms/u/s!AjJ4XyC3prp8mItO70T_q8HOPwa6aQ?e=h2Fiv5) | The converted ONNX model of fastai's pytorch model. |\n| [itos_wt103.pkl](http://files.fast.ai/models/wt103/) | Tokens used in pretrained model |\n\n\n***2019-08-08.***\n#### Added `cntkx.ops.gelu` and `cntkx.ops.gelu_fast`\nAdded two cntk implementation of `gelu` activation function. `gelu` activation is used in `BERT`\nand OpenAI's `GPT` and `GPT-2`.\n\nGaussian Error Linear Unit (GELU), a high-performing neuralnetwork activation function.\nThe GELU nonlinearity is the expected transforma-tion of a stochastic regularizer which randomly\napplies the identity or zero mapto a neuron\u00e2\u20ac\u2122s input.  The GELU nonlinearity weights inputs by their\nmagnitude,rather than gates inputs by their sign as in ReLUs.\n\nFor more detail please refer to [Gaussian Error Linear Units (GELU)](https://arxiv.org/abs/1606.08415)\nby Hendrycks and Gimpel.\n\n\n***2019-07-04.***\n#### Added `cntkx.ops.sequence.reduce_mean`\nCalculates the mean along the dynamic sequential axis in CNTK.\n\n\n***2019-06-26.***\n#### Added `cntkx.ops.sequence.reverse`\nAllows the sequence items along the sequence axis to be reversed. This is useful when you want to create a \nBi-directional Auto-Regressive layer because using UnfoldFrom does not work with Recurrence(go_backwards=True) and\n will result in a ValueError.\n\n\nExample:\n\n    import cntk as C\n    import cntkx as Cx\n    from cntk.layers import Recurrence, UnfoldFrom, LSTM\n\n    hidden_dim = 50\n    start_token = C.Constant(0, shape=(hidden_dim,))\n    a = C.sequence.input_variable(1, name='seq1')\n\n    b = UnfoldFrom(Recurrence(LSTM(hidden_dim), go_backwards=True))(start_token, a)\n\n    n = [np.random.random((10, hidden_dim)).astype(np.float32),]\n\n    # This raise 'ValueError: It is not allowed to have multiple different stepping directions in the same loop'\n    b.eval({b.arguments[0]: n})\n\n\nThe workaround would be:\n\n    import cntk as C\n    import cntkx as Cx\n    from cntk.layers import Recurrence, UnfoldFrom, LSTM\n\n    hidden_dim = 50\n    start_token = C.Constant(0, shape=(hidden_dim,))\n    a = C.sequence.input_variable(1, name='seq1')\n    a_reversed = Cx.sequence.reverse(a)\n\n    b = UnfoldFrom(Recurrence(LSTM(hidden_dim)))(start_token, a_reversed)  # remove go_backwards=True\n\n    n = [np.random.random((10, hidden_dim)).astype(np.float32),]    \n    b.eval({b.arguments[0]: n})  # this will run just fine\n\n\n\n***2019-06-21.***\n#### Added `cntkx.ops.random.sample_top_k`\nCNTK implementation of that allows sampling of the top_k unnormalised log-probabilities distribution.\nThis is useful text (or sequence) generation where it is known that greedy decoding will cause\ntext degeneration.\n\nFor more details on this, please refer to [A curious case of neural text degeneration](https://arxiv.org/abs/1904.09751)\n\n\nExample:\n\n    import cntk as C\n    import cntkx as Cx\n\n    a = C.input_variable(5)\n    b = Cx.random.sample_top_k(a, k=3, num_classes=5)\n\n    n = np.array([[1, 2, 3, 4, 5],] * 1000)\n\n    results = b.eval({a: n})\n    assert np.sum(results[:, :2]) == 0\n    assert np.sum(results[:, 2:]) == 1000\n\n***2019-05-04.***\n#### Added `cntkx.layers.vFSMN` and `cntkx.layers.cFSMN`\nCNTK implementation of Bidirectional vectorised Feedforward Sequential Memory Network (vFSMN)\nand Compact Feedforward Sequential Memory Network (cFSMN).\n\nFSMN is a standard fully-connected feedforward neural network equipped\nwith some learnable memory blocks in its hidden layers. The memory blocks\nuse a tapped-delay line structure to encode the long context information into\na fixed-size representation as short-term memory mechanism.\n\nThe authors claim that FSMNs can be learned much more reliably and faster than\nRNNs or LSTMs due to the inherent non-recurrent model structure while significantly\noutperforming RNNs in language and speech modeling.\n\nFor more details please refer to [Feedforward Sequential Memory Networks: A \nNew Structure to Learn Long-term Dependency](https://arxiv.org/abs/1512.08301)\n\ncFSMN is a compact version of FSMN that can result in a reduction of up\nto 60% in model size and speed up the learning by more than 7 times while\nstill significantly outperforming the popular bi-direction LSTMs for both\nframe-level cross-entropy (CE) criterion based training and MMI based sequence training.\n\nFor more details please refer to \"Compact Feedforward Sequential Memory Networks for\nLarge VocabularyContinuous Speech Recognition\" by Zhang, et al.\n\nExample:\n\n    import cntk as C\n    from cntkx.layers import vFSMN, cFSMN\n\n    # unidirectional vFSMN (only past conext used)\n    a = C.sequence.input_variable(10)\n    b = vFSMN(100, C.relu, num_past_context=3, num_future_context=0)(a)\n\n    assert b.shape == (100,)\n\n    # bidirectional vFSMN (enable both past and future context)\n    a = C.sequence.input_variable(10)\n    b = vFSMN(120, C.relu, num_past_context=3, num_future_context=3)(a)\n\n    assert b.shape == (120,)\n\n    # bidirectional cFSMN (enable both past and future context)\n    a = C.sequence.input_variable(100)\n    b = cFSMN(120, 50, C.relu, num_past_context=3, num_future_context=3)(a)\n\n    assert b.shape == (120,)\n\n\n***2019-04-19.***\n#### Added `cntkx.misc.CTCEncoder`\nCNTK's CTC implementation requires that data be formatted in a particular way that's typically in acoustic\nmodeling but unusual in other applications. So class provides an easy way to convert data between\nwhat users typically expect and what cntk demands.\n\nExample:\n    labels = ['a', 'b', 'c']\n    encoder = CTCEncoder(labels)\n\n    labels_tensor = C.sequence.input_variable(len(encoder.classes_))  # number of classes = 4\n    input_tensor = C.sequence.input_variable(100)\n\n    labels_graph = cntk.labels_to_graph(labels_tensor)\n    network_out = model(input_tensor)\n\n    fb = C.forward_backward(labels_graph, network_out, blankTokenId=encoder.blankTokenId)\n\n    ground_truth = ['a', 'b', 'b', 'b', 'c']\n    seq_length = 10  # must be the same length as the sequence length in network_out\n\n    fb.eval({input_tensor: [...],\n             labels_tensor: [encoder.transform(ground_truth, seq_length=seq_length)]})\n\n\n\n***2019-04-14.***\n#### Added `Label Smoothing Regularization`, `seqeuence.window` and `PyramidalBiRecurrence`\nAdded `Label Smoothing Regularization` in `cross_entropy_with_softmax`.\nAdded `sequence.window` that creates non-overlapping window along the sequence axis thereby reducing the \nsequence length and increasing the dimension by the same factor.\n\nImplemented a convenience layer used in acoustic modelling known as `PyramidalBiRecurrence`. Used to create\npyramidal bi-directional LSTM (BLSTM) found in \"Listen, attend and spell\" by Chan et al. (https://arxiv.org/abs/1508.01211)\nTypically used to down sample the sequence length to make memory and runtime manageable.\n\n\n***2019-04-08.***\n#### Added `cntkx.ops.sequence.join`\nAdded a new `op` called `join` where two sequence tensors can be joined along with sequence axis forming a longer sequence.\n\n\n***2019-04-08.***\n#### Added `cntkx.layers.SequentialAveragePooling`\nAdd average pooling layer that works with sequential axis. Current cntk `AveragePooling` doesn't pool across sequence elements.\n\nExample on `cntkx.layers.SequentialAveragePooling`\n\n    # rgb image of height 25 and variable width\n    a = C.sequence.input_variable((3, 25))\n\n    # Convolute across image with (3, 3) kernel with stride (1, 1)\n    b = C.layers.SequentialConvolution(filter_shape=(3, 3), num_filters=16, stride=(1, 1), pad=True)(a)\n\n    assert b.shape == (16, 25)\n\n    # max pool (2,2) in height and width with stride (2,2) in height and width, no padding\n    c = SequentialAveragePooling(filter_shape=(2, 2), strides=(2, 2), pad=False)(b)\n\n    assert c.shape == (16, 12)\n\n\n***2019-04-07.***\n#### Added `cntkx.sequence.stride` and `cntkx.ops.scalar`\n`Cx.sequence.stride` enables striding across the sequential axis, selecting every integer items along the sequence.\n`Cx.scalar` converts tensor into scalar of shape `(1,)` \n\n\n\n***2019-04-06.***\n#### Added `IndyLSTM` and `IndRNN`\nCNTK implementation of [Independently Recurrent Long Short-term Memory cells: IndyLSTMs](https://arxiv.org/abs/1903.08023)\nby Gonnet and Deselaers, and [Independently Recurrent Neural Network (IndRNN): Building A Longer andDeeper RNN](https://arxiv.org/abs/1803.04831)\nby Li, et al.\n\nBoth `IndyLSTM` and `IndRNN` have hidden-to-hidden weights that are diagonal matrix instead of the usual full matrix.\nThus neurons in each layer are independent from each other, and the cross-channel information is \nobtained through stacking multiple layers.\n\n`IndRNN` allows for the use of `C.relu` activation thus allowing multiple `IndRNN` layers to be stacked together deeply.\n\n`IndyLSTM` has parameters linear to the number of nodes in the linear, as opposed to standard LSTM that is quadratic\nmaking `IndyLSTM` potentially faster and smaller as a model.\n\nAuthors of both `IndRNN` and `IndyLSTM` have claimed performance as good as or even better than regular LSTMs.\n\nExample:\n\n    import cntk as C\n    from cntkx.layers import IndyLSTM, IndRNN, Recurrence\n\n    a = C.sequence.input_variable(10)\n    b = Recurrence(IndRNN(20))(a)\n    c = Recurrence(IndyLSTM(20))(a)\n\n    assert b.shape == c.shape == (20,)\n\n\n\n***2019-03-24.***\n#### Added `cntkx.layers.SequentialMaxPooling`\nAdd max pooling layer that works with sequential axis. Current cntk `MaxPooling` doesn't pool across sequence elements.\n\nExample on `cntkx.layers.SequentialMaxPooling`\n\n    # rgb image of height 25 and variable width\n    a = C.sequence.input_variable((3, 25))\n\n    # Convolute across image with (3, 3) kernel with stride (1, 1)\n    b = C.layers.SequentialConvolution(filter_shape=(3, 3), num_filters=16, stride=(1, 1), pad=True)(a)\n\n    assert b.shape == (16, 25)\n\n    # max pool (2,2) in height and width with stride (2,2) in height and width, no padding\n    c = SequentialMaxPooling(filter_shape=(2, 2), strides=(2, 2), pad=False)(b)\n\n    assert c.shape == (16, 12)\n\n\n***2019-03-18.***\n#### Added `cntkx.learners.CyclicalLearningRate`\nCyclical learning rate (CLR) is an implementation to that  practically eliminates the need to \nexperimentally find the best values and schedule  for  the global  learning  rates.\n\nInstead  of  monotonically decreasing the learning rate, this method lets the learning  \nrate  cyclically  vary  between  reasonable  boundary  values. Training  with  \ncyclical  learning  rates  instead of  fixed  values  achieves improved  classification \naccuracy without a need to tune and often in fewer iterations.\n\nMore details can be found in [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186) \nby Leslie N. Smith\n\nThis CLR implementation can be used with the cntk training loop by adding only ***two lines of code***:\n\n    model = C.layers.Dense(10)(C.input_variable(10))\n    sgd_momentum = C.momentum_sgd(model.parameters, 0.1, 0.9)\n    clr = CyclicalLeaningRate(sgd_momentum, minibatch_size=32)  # first line of code\n\n    for epoch in range(10):\n        for batch in range(100):\n            trainer.train_minibatch(...)\n            clr.batch_step()  # second line of code (to be called after every training update)\n\n\n\n\n***2019-03-12.***\n#### Added `cntkx.ops.batchmatmul`\nAdded Batch Matrix Multiplication. This implementation is similar \nto [tensorflow.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul).\n\nExample:\n\n    a = C.sequence.input_variable((3, 4, 5))     # batch matrix\n    b = C.sequence.input_variable((3, 5, 6))     # batch matrix\n    c = Cx.batchmatmul(a, b)\n    assert c.shape == (3, 4, 6)                  # 3 is treated as a batch axis\n\n\n\n***2019-03-10.***\n#### Added `PretrainedBertEncoder` and `PretrainedBertModel`\nBERT, the state-of-the-art language model is now available as a CNTK pretrained model.\n\nCurrently, it is only tested to work with `BERT-Base, Uncased` (uncased_L-12_H-768_A-12) and can be\ndownloaded from [Google AI](https://github.com/google-research/bert)\n\nWhen you have downloaded `BERT-Base, Uncased`, there should be 5 files inside. You will need to `.zip`\nthree of those files into a tensorflow checkpoint file before you can load it into `cntkx`.\n\nThose three files are: `bert_model.ckpt.data-00000-of-00001`, `bert_model.ckpt.index`, `bert_model.ckpt.meta`.\nThen rename the extension of `.zip` into `.ckpt` and you are good to go.\n\nExample below\n\n    text_tensor = C.sequence.input_variable(30522)\n    token_type_tensor = C.sequence.input_variable(2)\n    filepath_to_tf_bert_model = \"YOUR_FILE_DIRECTORY/bert_model.ckpt\"\n\n    model = Cx.layers.PreTrainedBertModel(filepath_to_tf_bert_model, num_heads=12, dropout_rate=0.1)\n    b = model(text_tensor, token_type_tensor)\n\n    assert b.shape == (768,)\n\nFor more details about BERT, you can find the original paper [here](https://arxiv.org/abs/1810.04805), \nand some useful resources [here](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270) \nand [here](http://jalammar.github.io/illustrated-bert/).\n\nNote:\nIt goes without saying also that to use these pre-trained models you will need to have tensorflow installed\nsince we are convert them from tensorflow models.\n\n\n***2019-03-06.***\n#### Added `PositionalEmbedding`, `BertEmbeddings` and `PretrainedBertEmbeddings`\nCNTK implementation of `PositionalEmbedding`, `BertEmbeddings` and tf-to-cntk `PreTrainedBertEmbeddings`.\nBERT is a state-of-the-art language model from Google AI, more details can be found in\n[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805).\n\nGoogle AI's pre-trained BERT tensorflow model can be downloaded [here](https://github.com/google-research/bert).\nTensorflow would need to be installed in your environment if you intend to use `PreTrainedBertEmbeddings`, which\ntakes a tensorflow model and convert it cntk.\n\nExample for `PositionalEmbedding`\n\n    a = C.sequence.input_variable(12)\n    b = PositionalEmbedding(max_seq_length, hidden_dim)(a)\n\n    assert b.shape == (hidden_dim, )\n\nExample for `BertEmbeddings`\n\n    text_tensor = C.sequence.input_variable(100)\n    token_type_tensor = C.sequence.input_variable(2)\n    b = BertEmbeddings(max_seq_length, hidden_dim, 0.1)(text_tensor, token_type_tensor)\n\n    assert b.shape == (hidden_dim, )\n\nExample for `PreTrainedBertEmbeddings`\n\n    text_tensor = C.sequence.input_variable(30522)\n    token_type_tensor = C.sequence.input_variable(2)\n    filepath_to_tf_bert_model = \"YOURFILEPATH\"\n    embeddings = PreTrainedBertEmbeddings(filepath_to_tf_bert_model, 0.1, False)\n    b = embeddings(text_tensor, token_type_tensor)\n\n    assert b.shape == (768, )\n\n\n***2019-03-02.***\n#### Added `VariationalDropout` and `WeightDroppedLSTM`\nCNTK implementation of `Variational Dropout` found in \n[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\nand `Weight Dropped LSTM` proposed in a salesforce research paper \n[Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182).\n\n`Weight Dropped LSTM` is a regularised LSTM that uses DropConnect on hidden-to-hidden weights as a form of recurrent\nregularisation. It also include application of variational dropout on the inputs and outputs of the recurrent units\nfor further regularisation.\n\n`Variational Drpoout` is a regularisation that uses same dropout mask at each time step \n(i.e. across the dynamic sequence axis) as opposed to the naive application of `C.layers.Dropout` to a sequence\nwhich will result in a different dropout mask for every tensor along the sequence axis.\n\n\n    import cntkx as Cx\n    from cntkx.layers import Recurrence, WeightDroppedLSTM\n    import cntk as C\n\n    dropconnect_rate = 0.2\n    variationaldrop_rate = 0.1\n\n    seq = C.sequence.input_variable(56)\n    b = Recurrence(WeightDroppedLSTM(20, dropconnect_rate),\n                   variational_dropout_rate_input=variationaldrop_rate,\n                   variational_dropout_rate_output=variationaldrop_rate)(seq)\n\n    assert b.shape == (100, )\n\n    seq_dropped = VariationalDropout(0.1)(seq)\n\n    assert seq_dropped.shape == seq.shape\n\n\n***2019-02-02.***\n#### Added Gated Linear Unit / Gated CNN\nCNTK implementation of Gated Linear Unit (Gated CNN) founnd in Facebook AI Research Lab's paper:\n[Language Modeling with Gated Convolutional Networks](https://arxiv.org/abs/1612.08083).\nThis paper applies a convolutional approach to language modelling with a novel Gated-CNN model.\n\n    import cntkx as Cx\n    import cntk as C\n\n    seq = C.sequence.input_variable(56)\n    hidden = Cx.layers.GatedLinearUnit(window=2, hidden_dim=100)(seq)\n\n    assert hidden.shape == (100, )\n\n\n***2019-01-21.***\n#### Added `Focal Loss` for multi-class and binary classification\nCNTK implementation of `Focal Loss` enables the training of highly accurate dense object detectors in the\npresence of vast numbers of easy background examples or dataset with extreme class imbalance (e.g. 1:1000).\n\n`Focal Loss` focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from\noverwhelm-ing the model during training. \n\nFor more details please refer to [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)\n\n    import cntkx as Cx\n\n    Cx.focal_loss_with_softmax([[0, 0, 0.8, 0.2]], [[0, 0, 1, 0]]).eval()\n    array([[0.31306446]], dtype=float32)\n\n\n\n***2019-01-18.***\n#### Added Gaussian Window Attention Model\nGaussian window attention model was first introduced by Alex Graves in \n\"Generating sequences with recurrent neural networks\".\n\nIt uses a mixture of gaussian windows to attend to \nportions of the sequence as oppose to the widely used attention model introduced in \n\"Neural machine translation by jointly learning to align and translate\" by Bahdanau, et al. that attends\nto the entire sequence all at once.\n\nGaussian window attention is also directional in its attention on the context sequence. When modeling\nstrongly ordered sequences, gaussian window attention will be a natural choice due to this inductive bias.\n\n    import cntk as C\n    import cntkx as Cx\n\n    seq1 = C.Axis.new_unique_dynamic_axis('seq1')\n    seq2 = C.Axis.new_unique_dynamic_axis('seq2')\n\n    encoded = C.sequence.input_variable(30, sequence_axis=seq1)\n    query = C.sequence.input_variable(28, sequence_axis=seq2)\n\n    a = Cx.layers.GaussianWindowAttention(10)(encoded, query)\n\n    assert a.shape == (30, )\n\n\"Generating sequences with recurrent neural networks\" can be found [here](https://arxiv.org/abs/1308.0850).\n\"Neural machine translation by jointly learning to align and translate\" can be found [here](https://arxiv.org/abs/1409.0473).\n\n***2019-01-16.***\n#### Added Spatial Pyramid Pooling layer\nSpatial pyramid pooling layer is a pooling layer than returns a fixed length representation regardless of the \nimage size/scale. It is frequently used for multi-size image training. It reported SOTA classification results using\na single full-image representation without fine-tuning. For more details on the paper\n\"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition\" by K. He, X. Zhang, S. Ren, J. Sun,\nlink [here](https://arxiv.org/abs/1406.4729).\n\n    import cntk as C\n    import cntkx as Cx\n\n    n = np.random.random((3, 3, 32, 32)).astype(np.float32)\n    a = C.input_variable((3, 32, 32))\n    b = Cx.layers.SpatialPyramidPooling((1, 2, 4))(a)\n\n    assert b.shape == (3 * (4 * 4 + 2 * 2 + 1),)  # representation not dependent on image size\n\n\n***2019-01-15.***\n#### Added Sinusoidal Positional Embedding and `cntkx.ops.erf`\nAdded sinusoidal positional embedding used in [Transformer](https://arxiv.org/abs/1706.03762). For an accessible\nexplanation of transformer, you may look up [here](http://jalammar.github.io/illustrated-transformer/).\n\n    import cntk as C\n    import cntkx as Cx\n\n    a = C.sequence.input_variable(10)\n    b = SinusoidalPositionalEmbedding()(a)\n\n    assert b.shape == (10, )\n\nAdded `cntkx.ops.erf` error function.\n\n***2019-01-12.***\n#### Added Vision models: VGG16, VGG19 and UNET\nVGG is for image classification and UNET is for semantic segmentation. VGG is implemented for completeness \nsake and should not be used for any serious classification task.\n\n\nPaper on VGG can be found [here](https://arxiv.org/abs/1409.1556) titled \"Very Deep Convolutional Networks \nfor Large-Scale Image Recognition\"\n\nPaper for UNET can be found [here](https://arxiv.org/abs/1505.04597) titled \"U-Net: Convolutional Networks \nfor Biomedical Image Segmentation\"\n\nVGG example:\n\n    import cntk as C\n    import cntkx as Cx\n\n    a = C.input_variable((3, 64, 64))\n    b = Cx.layers.VGG19(100)(a)\n\n    assert b.shape == (100,)\n\nUNET example:\n\n    import cntk as C\n    import cntkx as Cx\n\n    a = C.input_variable((3, 512, 512))\n    b = Cx.layers.UNET(num_classes=10, base_num_filters=64, pad=True)(a)\n\n    assert b.shape == (10, 512, 512)\n\nConvenience functions such as `cntkx.ops.upsample` and `centre_crop` have also been added.\n`cntkx.ops.upsample` upsamples an image twice on each spatial dim. `centre_crop` crops a smaller image from\na bigger one in the centre given a reference smaller image.\n\n\n#### Added Transformer attention model and associated components\nThe Transformer was first introduced in the [paper](https://arxiv.org/abs/1706.03762) 'Attention is all you need'.\nThe architecture is based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\nMore recently, [BERT](https://arxiv.org/abs/1810.04805) which broke almost all SOTA language task is also based on \ntransformer and self-attention.\n\n    import cntk as C\n    import cntkx as Cx\n\n    a = C.sequence.input_variable(512)\n    b = C.sequence.input_variable(512)\n\n    transformer = Cx.layers.Transformer()  # using default settings\n    decoded = transformer(a, b)\n\n    assert decoded.shape == (512, )\n\n\n***2018-12-08.***\n#### Added QRNN: Quasi-Recurrent Neural Network (QRNN) and `cntkx.ops.cumsum`\nThe QRNN provides similar accuracy to the LSTM but can be betwen 2 and 17 times faster than the \nhighly optimized NVIDIA cuDNN LSTM implementation depending on the use case.\n\nMore details please refer to the original paper [here](https://arxiv.org/abs/1611.01576).\n\n    import cntk as C\n    import cntkx as Cx\n\n    input_seq = C.sequence.input_variable(input_dim)\n    prediction_seq = Cx.layers.QRNN(hidden_dim=50)(input_seq)\n\n\n\n***2018-12-07.***\n#### New sequence ops: `cntkx.ops.sequence.pad` and `cntkx.ops.sequence.length`\nAdded two new sequence ops. `cntkx.ops.sequence.pad` allows padding on the sequence axis and \n`cntkx.ops.sequence.length` calculates the length of the sequence.\n\n***2018-12-05.***\n#### Mixture Density Network\nMixture density networks are neural networks that can in principle represent arbitrary conditional \nprobability distributions in the same way that a conventional neural network can represent arbitrary functions.\nMDN are very useful when you need to map an input to several correct targets (aka. one-to-many problem).\n\nUpdated with Gaussian Mixture Density Network ops and loss function. Ops will allow you to extract mdn coefficients and sample from the network.\n\nMore details on mdn can be found in this [paper](https://publications.aston.ac.uk/373/1/NCRG_94_004.pdf) by Christopher Bishop.\n\n    import cntk as C\n    import cntkx as Cx\n\n    input_tensor = C.input_variable(1, name=\"input_tensor\")\n    target_tensor = C.input_variable(1, name=\"target_tensor\")\n\n    # model\n    inner = Dense(50, activation=C.relu)(input_tensor)\n    inner = Dense(50, activation=C.relu)(inner)\n    prediction_tensor = Dense((ndim + 2) * nmix, activation=None)(inner)\n\n    sampled = Cx.sample_gaussian_mdn(prediction_tensor, nmix, ndim)  # sampling node\n    loss = Cx.gaussian_mdn_loss(prediction_tensor, target_tensor, nmix=nmix, ndim=ndim)  # loss function\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/delzac/cntkx", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "cntkx", "package_url": "https://pypi.org/project/cntkx/", "platform": "", "project_url": "https://pypi.org/project/cntkx/", "project_urls": {"Homepage": "https://github.com/delzac/cntkx"}, "release_url": "https://pypi.org/project/cntkx/0.1.47/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Extension library of Microsoft Cognitive Toolkit", "version": "0.1.47", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>CNTKx</h1>\n<p>CNTKx is a deep learning library that builds on and extends Microsoft Cognitive Toolkit <a href=\"https://github.com/Microsoft/CNTK\" rel=\"nofollow\">CNTK</a>.\nDespite the last planned release of cntk 2.7, cntkx will continue to be in active development, more models and pre-built components coming soon!</p>\n<p>Feel free to open an issue for any request or a PR to contribute :)</p>\n<h2>Installation</h2>\n<p>cntkx is written in pure python and cntk is a dependency to it. Please get a working installation of cntk first. Then:</p>\n<pre><code>pip install cntkx\n</code></pre>\n<p>cntkx only works with <code>python&gt;=3.6</code></p>\n<h2>Available Components</h2>\n<table>\n<thead>\n<tr>\n<th>ops</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>floor_division</code></td>\n<td>element-wise floor_division</td>\n</tr>\n<tr>\n<td><code>remainder</code></td>\n<td>element-wise remainder of division</td>\n</tr>\n<tr>\n<td><code>scalar</code></td>\n<td>cast tensor to scalar (1,)</td>\n</tr>\n<tr>\n<td><code>cumsum</code></td>\n<td>Cumulative summation along axis</td>\n</tr>\n<tr>\n<td><code>upsample</code></td>\n<td>Upsample by k factor (for image)</td>\n</tr>\n<tr>\n<td><code>centre_crop</code></td>\n<td>Crop centre of image</td>\n</tr>\n<tr>\n<td><code>swish</code></td>\n<td>Activation</td>\n</tr>\n<tr>\n<td><code>mish</code></td>\n<td>Activation</td>\n</tr>\n<tr>\n<td><code>hardmax</code></td>\n<td>Activation</td>\n</tr>\n<tr>\n<td><code>erf</code></td>\n<td>Error function</td>\n</tr>\n<tr>\n<td><code>gelu</code></td>\n<td>Gaussian Error Linear Unit function</td>\n</tr>\n<tr>\n<td><code>gelu_fast</code></td>\n<td>fast approximation of Gaussian Error Linear Unit function</td>\n</tr>\n<tr>\n<td><code>sequence.pad</code></td>\n<td>Pad at start or end of sequence axis</td>\n</tr>\n<tr>\n<td><code>sequence.length</code></td>\n<td>length of sequence</td>\n</tr>\n<tr>\n<td><code>sequence.position</code></td>\n<td>position of every sequence element</td>\n</tr>\n<tr>\n<td><code>sequence.stride</code></td>\n<td>strides across sequential axis</td>\n</tr>\n<tr>\n<td><code>sequence.join</code></td>\n<td>joins two sequence along their sequential axis</td>\n</tr>\n<tr>\n<td><code>sequence.window</code></td>\n<td>creates sliding window along the sequence axis</td>\n</tr>\n<tr>\n<td><code>sequence.window_causal</code></td>\n<td>creates causal sliding window along the sequence axis</td>\n</tr>\n<tr>\n<td><code>sequence.reverse</code></td>\n<td>reverses the items along the dynamic sequence axis</td>\n</tr>\n<tr>\n<td><code>sequence.reduce_mean</code></td>\n<td>calculates the mean along the dynamic sequence axis</td>\n</tr>\n<tr>\n<td><code>sequence.reduce_concat_pool</code></td>\n<td>drop-in replace for sequence.last</td>\n</tr>\n<tr>\n<td><code>random.sample</code></td>\n<td>Samples an unnormalised log probability distribution</td>\n</tr>\n<tr>\n<td><code>random.sample_with_bias</code></td>\n<td>Samples an unnormalised log probability distribution over-weighted to more probable classes</td>\n</tr>\n<tr>\n<td><code>random.sample_top_k</code></td>\n<td>Samples from the top_k of an unnormalised log probability distribution</td>\n</tr>\n<tr>\n<td><code>batchmatmul</code></td>\n<td>Batch Matrix Multiplication on a static batch axis, similar to tf.matmul</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Layers</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>QRNN</code></td>\n<td>Quasi-Recurrent Neural Network</td>\n</tr>\n<tr>\n<td><code>Recurrence</code></td>\n<td>With option to apply <code>VariationalDroppout</code></td>\n</tr>\n<tr>\n<td><code>PyramidalBiRecurrence</code></td>\n<td>Pyramidal bi-directional recurrence</td>\n</tr>\n<tr>\n<td><code>VariationalDropout</code></td>\n<td>Single binary dropout mask for entire sequence</td>\n</tr>\n<tr>\n<td><code>SinusoidalPositionalEmbedding</code></td>\n<td>Non-learnable positional embedding (no max sequence length)</td>\n</tr>\n<tr>\n<td><code>PositionalEmbedding</code></td>\n<td>Learnable Positional Embedding (used in BERT)</td>\n</tr>\n<tr>\n<td><code>BertEmbeddings</code></td>\n<td>BERT Embeddings (word + token_type + positional)</td>\n</tr>\n<tr>\n<td><code>BertPooler</code></td>\n<td>Pooler used in BERT</td>\n</tr>\n<tr>\n<td><code>SpatialPyramidPooling</code></td>\n<td>Fixed pooled representation regardless of image input size</td>\n</tr>\n<tr>\n<td><code>GatedLinearUnit</code></td>\n<td>Gated Convolutional Neural Network</td>\n</tr>\n<tr>\n<td><code>ScaledDotProductAttention</code></td>\n<td>Attention used in BERT and Transformer (aka 'attention is all you need')</td>\n</tr>\n<tr>\n<td><code>MultiHeadAttention</code></td>\n<td>Attention used in BERT and Transformer (aka 'attention is all you need')</td>\n</tr>\n<tr>\n<td><code>GaussianWindowAttention</code></td>\n<td>Windowed attention instead of conventional attention where everything is attended at the same time</td>\n</tr>\n<tr>\n<td><code>SequentialDense</code></td>\n<td>Applies Dense to a window of sequence item along sequence axis</td>\n</tr>\n<tr>\n<td><code>SequentialMaxPooling</code></td>\n<td>Max pool across sequential axis and static axes</td>\n</tr>\n<tr>\n<td><code>SequentialAveragePooling</code></td>\n<td>Average pool across sequential axis and static axes</td>\n</tr>\n<tr>\n<td><code>SequentialConcatPooling</code></td>\n<td>Concat Average and Mean pool across sequential axis and static axes</td>\n</tr>\n<tr>\n<td><code>vFSMN</code></td>\n<td>Vectorised Feedforward Sequential Memory Networks</td>\n</tr>\n<tr>\n<td><code>cFSMN</code></td>\n<td>Compact Feedforward Sequential Memory Networks</td>\n</tr>\n<tr>\n<td><code>BiRecurrence</code></td>\n<td>BiRecurrence recurrent layer with weight tying option to half parameter requirement</td>\n</tr>\n<tr>\n<td><code>GlobalConcatPooling</code></td>\n<td>Global spatial concat pooling of ave and mean</td>\n</tr>\n<tr>\n<td><code>FilterResponseNormalization</code></td>\n<td>Drop in replacement for batch norm with superior performance</td>\n</tr>\n<tr>\n<td><code>Boom</code></td>\n<td>More parametrically efficient alternative to Position-Wise FeedForward layer found in Transformer</td>\n</tr>\n<tr>\n<td><code>GaussianAttentionSeqImage</code></td>\n<td>Memory efficient attention that used 2d gaussian filters for images</td>\n</tr>\n<tr>\n<td><code>SequenceDropout</code></td>\n<td>Dropout entire sequence elements</td>\n</tr>\n<tr>\n<td><code>SEBlock</code></td>\n<td>Squeeze and Excitation block</td>\n</tr>\n<tr>\n<td><code>SequenceSEBlock</code></td>\n<td>Squeeze and Excitation block for variable width image sequence</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Blocks</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>WeightDroppedLSTM</code></td>\n<td>A form of regularised LSTM</td>\n</tr>\n<tr>\n<td><code>IndyLSTM</code></td>\n<td>A parameter efficient form of LSTM</td>\n</tr>\n<tr>\n<td><code>IndRNN</code></td>\n<td>a RNN with long memory and can be stacked deeply</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Loss</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>gaussian_mdn_loss</code></td>\n<td>loss function when using Mixture density network</td>\n</tr>\n<tr>\n<td><code>focal_loss_with_softmax</code></td>\n<td>A kind of cross entropy that handles extreme class imbalance</td>\n</tr>\n<tr>\n<td><code>cross_entropy_with_softmax</code></td>\n<td>Added <code>label smoothing regularisation</code> in cross entropy with softmax</td>\n</tr>\n<tr>\n<td><code>generalised_robust_barron_loss</code></td>\n<td>generalised robust loss</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Models</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>VGG</code></td>\n<td>Image Classification</td>\n</tr>\n<tr>\n<td><code>UNET</code></td>\n<td>Semantic Segmentation</td>\n</tr>\n<tr>\n<td><code>Transformer</code></td>\n<td>Language Modelling</td>\n</tr>\n<tr>\n<td><code>MDN</code></td>\n<td>Mixture Density Networks</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Pre-trained models</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>Bert</code></td>\n<td>Bidirectional Encoder Representations from Transformers</td>\n</tr>\n<tr>\n<td><a href=\"https://1drv.ms/u/s!AjJ4XyC3prp8mItNxiawGK4gD8iMhA?e=wh7PLB\" rel=\"nofollow\">fwd_wt103.hdf5</a></td>\n<td>The weight parameters of the fastai's pytorch model. To be used to initialise <code>PretrainedWikitext103LanguageModel</code></td>\n</tr>\n<tr>\n<td><a href=\"https://1drv.ms/u/s!AjJ4XyC3prp8mItPBdfmDYr9QP7J4w?e=k1BXlW\" rel=\"nofollow\">fwd_wt103.cntk</a></td>\n<td>The converted cntk model of fastai's pytorch model. To be used with <code>C.load_model</code></td>\n</tr>\n<tr>\n<td><a href=\"https://1drv.ms/u/s!AjJ4XyC3prp8mItO70T_q8HOPwa6aQ?e=h2Fiv5\" rel=\"nofollow\">fwd_wt103.onnx</a></td>\n<td>The converted ONNX model of fastai's pytorch model.</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Learners</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>CyclicalLearningRate</code></td>\n<td>a method to eliminate the need to find best value and schedule for learning rate</td>\n</tr>\n<tr>\n<td><code>RAdam</code></td>\n<td>a variant of <code>Adam</code> that doesn't require any warmup</td>\n</tr></tbody></table>\n<table>\n<thead>\n<tr>\n<th>Misc</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>CTCEncoder</code></td>\n<td>Helper class to convert data into a format acceptable for cntk's ctc implementation</td>\n</tr></tbody></table>\n<h2>C# CNTK Tutorials</h2>\n<p>This library is implemented in pure cntk python API. For help in cntk c#, you can refer to the two repository\n<a href=\"https://github.com/anastasios-stamoulis/deep-learning-with-csharp-and-cntk\" rel=\"nofollow\">deep-learning-with-csharp-and-cntk</a>\nand <a href=\"https://github.com/AllanYiin/DeepBelief_Course4_Examples\" rel=\"nofollow\">DeepBelief_Course4_Examples</a>.</p>\n<h2>F# CNTK</h2>\n<p>For the F# wrapper of CNTK please visit <a href=\"https://github.com/fwaris/FsCNTK\" rel=\"nofollow\">FsCNTK</a>,\nit also contains some example implementations like seq2seq, autoencoder, LSTM, GAN.</p>\n<h2>News</h2>\n<p><em><strong>2020-05-01</strong></em></p>\n<h3>Added <code>SEBlock</code> and <code>SequenceSEBlock</code></h3>\n<p><code>SEBlock</code> and <code>SequenceSEBlock</code> are squeeze-excitation blocks that adaptively recalibrates channel-wise feature\nresponses by explicitly modelling interdependencies between channels. It was show that these blocks can be\nstacked together to form SENet architectures that generalise extremely effectively across different datasets.</p>\n<p>Its the winner for ILSVRC2017 classification submission. More details can be found in the\npaper <a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">Squeeze-and-Excitation Networks</a> by Jie hu et al.</p>\n<p><em><strong>2020-04-20</strong></em></p>\n<h3>Added <code>SequenceDropout</code></h3>\n<p><code>SequenceDropout</code> dropouts entire sequence elements along the dynamic sequence axis.</p>\n<p><em><strong>2020-04-15</strong></em></p>\n<h3>Added <code>GaussianAttentionSeqImage</code></h3>\n<p><code>GaussianAttentionSeqImage</code> is a 2d spatial gaussian attention.\nTo use, the encoded image should be formulated as a cntk sequence (example below). This can be useful when\nyou are constraint by gpu memory as 2d gaussian attention is more memory efficient than standard attention.</p>\n<p>This is from the deepmind paper, DRAW: A Recurrent Neural Network for Image Generation by Gregor et al\nMore details can be found in the following <a href=\"https://arxiv.org/abs/1502.04623\" rel=\"nofollow\">https://arxiv.org/abs/1502.04623</a></p>\n<p>Example:</p>\n<pre><code>n = 5\nnum_channels = 3\nimage_height = 64\nexpected_image_width = 1000\nimage_seq = C.sequence.input_variable((num_channels, image_height))  # rgb image with variable width and fixed height\ndecoder_hidden_state = ...  # from decoder somewhere in the network\nattended_image = Cx.layers.GaussianAttentionSeqImage(n, image_height, expected_image_width)(image_seq, decoder_hidden_state)\n\nassert attended_image.shape == (num_channels, n, n)\n</code></pre>\n<p><em><strong>2020-03-29.</strong></em></p>\n<h4>Added <code>generalised_robust_barron_loss</code> and <code>sample_with_bias</code></h4>\n<p><code>generalised_robust_barron_loss</code> is a generalisation for generalization of the Cauchy/Lorentzian,\nGeman-McClure, Welsch/Leclerc, generalized Charbonnier, Charbonnier/pseudo-Huber/L1-L2, and\nL2 loss functions.</p>\n<p>Can be used as a drop-in replacement in any regression task that you have.</p>\n<p>For more details, please refer to <a href=\"https://arxiv.org/abs/1701.03077\" rel=\"nofollow\">A General and Adaptive Robust Loss Function</a>, Jonathan T. Barron,\nor this <a href=\"https://www.youtube.com/watch?v=BmNKbnF69eY\" rel=\"nofollow\">video</a>.\nIt is the Best Paper Award Finalist in CVPR 2019.</p>\n<p>Implemented <code>sample_with_bias</code> to sample more likely classes as a replacement\nfor <code>sample_top_k</code> which cannot be used inside a <code>UnfoldFrom</code>. <code>sample_with_bias</code> reduces sampling variance especially when you have a long tail.</p>\n<p><em><strong>2020-02-11.</strong></em></p>\n<h4>Added <code>Boom</code></h4>\n<p>Boom layer from SHA-RNN by S. Merity creator of QRNN. Alternative to PositionwiseFeedForward. Serves the same function as\nPositionwiseFeedForward found in transformer.</p>\n<p>Boom layer minimizes computation and removes an entire matrix of parameters compared to traditional down-projection layers.</p>\n<p>For more detail please read: <a href=\"https://arxiv.org/abs/1911.11423\" rel=\"nofollow\">Single Headed Attention RNN: Stop Thinking With Your Head</a> by Stephen Merity.</p>\n<p><em><strong>2019-12-03.</strong></em></p>\n<h4>Added <code>FilterResponseNormalization</code> and <code>ThresholdedLinearUnit</code></h4>\n<p>Added cntk implementation of <code>FilterResponseNormalization</code>. Filter Response Normalization (FRN) layer\nis a novel combination of a normalization and an activation function,\nthat can be used as a drop-in replacement for other normalizations and activations.</p>\n<p>The method operates on each activation map of each batch sample\nindependently, eliminating the dependency on other batch samples or channels of the same sample.\nThe method outperforms BN and all alternatives in a variety of settings for all batch sizes.\nFRN layer performs \u00e2\u2030\u02c60.7\u00e2\u02c6\u20191.0% better on top-1 validation accuracy than BN with large mini-batch sizes on\nImagenet classification on InceptionV3 and ResnetV2-50 architectures. Further, it performs &gt;1% better\nthan GN on the same problem in the small mini-batch size regime. For object detection problem on COCO dataset,\nFRN layer outperforms all other methods by at least 0.3\u00e2\u02c6\u20190.5% in all batch size regimes.</p>\n<p>Please refer to the paper <a href=\"https://arxiv.org/abs/1911.09737v1\" rel=\"nofollow\">Filter Response Normalization Layer: Eliminating Batch Dependence\nin the Training of Deep Neural Networks</a> for more details .</p>\n<p><em><strong>2019-11-04.</strong></em></p>\n<h4>Added <code>ops.floor_division</code>, <code>ops.remainder</code>, <code>sequence.window_causal</code> and <code>SequentialDense</code></h4>\n<p>Add in new operations stated above. <code>sequence.window</code> now has an additional argument that lets you control striding.\n<code>sequence.window_causal</code> creates causal window that doesn't leak future information into the past (preserve causality).\n<code>SequentialDense</code> convenience layer added to apply dense to a window of sequence item,\nmuch like <code>SequentialConvolution</code> but with better memory performance.</p>\n<p><em><strong>2019-11-04.</strong></em></p>\n<h4>Added <code>SequentialConcatPooling</code>, <code>Cx.Sequence.reduce_concat_pool</code> and <code>GlobalConcatPooling</code></h4>\n<p><code>Cx.Sequence.reduce_concat_pool</code> concatenates the last item in the sequence axis with the summarisation\nof the sequence represented by <code>reduce_max</code> and <code>reduce_mean</code> of the sequence axis. Anytime <code>C.sequence.last</code> is used,\nthis can be a drop-in replacement.</p>\n<p>Example:</p>\n<pre><code>n = 32\na = C.sequence.input_variable(n)\nb = Cx.sequence.reduce_concat_pool(a)\n\nassert b.shape == (n * 3, )\n</code></pre>\n<p><code>SequentialConcatPooling</code> does spatial concat pooling over the sequential axis.\nConcat pooling is the concatenation of both average pooling and max pooling. In any situation where max or ave\npooling is appropriate, concat pooling can be used as a drop-in replacement and achieve improvements in performance.</p>\n<p>Example:</p>\n<pre><code>a = C.sequence.input_variable((3, 10))\nb = SequentialConcatPooling(filter_shape=(2, 2), strides=2)(a)\n\nassert b.shape == (6, 10)\n\nn = [np.random.random((3, 10)).astype(np.float32),\n     np.random.random((3, 10)).astype(np.float32),\n     np.random.random((3, 10)).astype(np.float32),\n     np.random.random((3, 10)).astype(np.float32), ]\n\nprint(b.eval({a: n}))\n</code></pre>\n<p><code>GlobalConcatPooling</code> is the standard spatial concat pooling of both max pool and ave pool.</p>\n<p><em><strong>2019-10-15.</strong></em></p>\n<h4>Added <code>mish</code> activation function and <code>RAdam</code> learner.</h4>\n<p><code>mish</code> is an activation function is introduced in <a href=\"https://arxiv.org/abs/1908.08681v2\" rel=\"nofollow\">Mish: A Self Regularized Non-Monotonic Neural Activation Function</a>\nby Diganta Misra. Experiments show that <code>mish</code> tends to work better than both ReLU and Swish along with other standard\nactivation functions in many deep networks across challenging datasets. For instance,\nin Squeeze Excite Net-18 for CIFAR 100 classification, the network with Mish had an increase in\nTop-1 test accuracy by 0.494% and 1.671% as compared to the same network with Swish and ReLU respectively.\nThe similarity to Swish along with providing a boost in performance and its simplicity in implementation\nmakes it easier for researchers and developers to use Mish in their Neural Network Models.</p>\n<p>This activation function is adopted in <code>fast ai</code>.</p>\n<p>Rectified Adam or <code>RAdam</code> is a <code>Adam</code> optimiser variant that doesn't require a warmup schedule, which <code>Adam</code> tends\nto need to maintain stability. In this cntk implementation, we added a <code>RAdam</code> like optimiser based\non the work of <a href=\"https://arxiv.org/abs/1910.04209\" rel=\"nofollow\">On the adequacy of untuned warmup for adaptive optimization</a> by Jerry Ma and Denis Yarats.</p>\n<p><code>RAdam</code> is adopted in <code>fast ai</code> too.</p>\n<p><em><strong>2019-09-30.</strong></em></p>\n<h4>Added <code>BiRecurrence</code> with weight tying</h4>\n<p>Made improvement to weight tying of BiRecurrence by have one parameter tensor token for every state\nin the step function per direction (forward and backward). This will allow forward and backward token\nto have more representational flexibility. Previously, all states use the same forward or backward token.</p>\n<p><em><strong>2019-09-06.</strong></em></p>\n<h4>Added <code>BiRecurrence</code> with weight tying</h4>\n<p>Add a wrapper to create a bidirectional recurrent layer using <code>BiRecurrence</code>. Included in the implementation\nis an option to half the number of parameters required by  bidirectional recurrent layer. This is done\nby only using one recurrent unit to do both forward and backward computation instead of the usual two.\nA forward and backward token is used to initialise the hidden state so that the recurrent unit can tell\nthe directionality.</p>\n<p>More details can be found in the paper <a href=\"https://arxiv.org/abs/1908.09329\" rel=\"nofollow\">Efficient Bidirectional Neural Machine Translation</a></p>\n<p>Example:</p>\n<pre><code>a = C.sequence.input_variable(10)\nb = BiRecurrence(LSTM(100), weight_tie=True)(a)\n\nassert b.shape == (200, )\n</code></pre>\n<p><em><strong>2019-08-29.</strong></em></p>\n<h4>Added <code>PretrainedWikitext103LanguageModel</code></h4>\n<p>CNTK implementation of Fast AI's Universal  Language  ModelFine-tuning (ULMFiT) English model has been added.\nThis language model was trained on Wikitext-103 and can be used as a base model for any downstream language task.</p>\n<p>It is also much more efficient to run compare to BERT and other Transformer language models.</p>\n<p>For more details, you can refer to the original paper <a href=\"https://arxiv.org/abs/1801.06146\" rel=\"nofollow\">here</a></p>\n<p>Example:</p>\n<pre><code>vocab_size = 238462\nconverted_hdf5_model_file_path = 'PATH/fwd_wt103.hdf5'  # this is not the original pytorch model\nlm = PretrainedWikitext103LanguageModel(converted_hdf5_model_file_path)\n\na = C.sequence.input_variable(vocab_size)\nprediction = lm(a)  # next-word-prediction\nfeatures = prediction.features  # features of tokens\n\nassert prediction.shape == (vocab_size, )\nassert features.shape == (400, )\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://1drv.ms/u/s!AjJ4XyC3prp8mItNxiawGK4gD8iMhA?e=wh7PLB\" rel=\"nofollow\">fwd_wt103.hdf5</a></td>\n<td>The weight parameters of the fastai's pytorch model. To be used to initialise <code>PretrainedWikitext103LanguageModel</code></td>\n</tr>\n<tr>\n<td><a href=\"https://1drv.ms/u/s!AjJ4XyC3prp8mItPBdfmDYr9QP7J4w?e=k1BXlW\" rel=\"nofollow\">fwd_wt103.cntk</a></td>\n<td>The converted cntk model of fastai's pytorch model. To be used with <code>C.load_model</code></td>\n</tr>\n<tr>\n<td><a href=\"https://1drv.ms/u/s!AjJ4XyC3prp8mItO70T_q8HOPwa6aQ?e=h2Fiv5\" rel=\"nofollow\">fwd_wt103.onnx</a></td>\n<td>The converted ONNX model of fastai's pytorch model.</td>\n</tr>\n<tr>\n<td><a href=\"http://files.fast.ai/models/wt103/\" rel=\"nofollow\">itos_wt103.pkl</a></td>\n<td>Tokens used in pretrained model</td>\n</tr></tbody></table>\n<p><em><strong>2019-08-08.</strong></em></p>\n<h4>Added <code>cntkx.ops.gelu</code> and <code>cntkx.ops.gelu_fast</code></h4>\n<p>Added two cntk implementation of <code>gelu</code> activation function. <code>gelu</code> activation is used in <code>BERT</code>\nand OpenAI's <code>GPT</code> and <code>GPT-2</code>.</p>\n<p>Gaussian Error Linear Unit (GELU), a high-performing neuralnetwork activation function.\nThe GELU nonlinearity is the expected transforma-tion of a stochastic regularizer which randomly\napplies the identity or zero mapto a neuron\u00e2\u20ac\u2122s input.  The GELU nonlinearity weights inputs by their\nmagnitude,rather than gates inputs by their sign as in ReLUs.</p>\n<p>For more detail please refer to <a href=\"https://arxiv.org/abs/1606.08415\" rel=\"nofollow\">Gaussian Error Linear Units (GELU)</a>\nby Hendrycks and Gimpel.</p>\n<p><em><strong>2019-07-04.</strong></em></p>\n<h4>Added <code>cntkx.ops.sequence.reduce_mean</code></h4>\n<p>Calculates the mean along the dynamic sequential axis in CNTK.</p>\n<p><em><strong>2019-06-26.</strong></em></p>\n<h4>Added <code>cntkx.ops.sequence.reverse</code></h4>\n<p>Allows the sequence items along the sequence axis to be reversed. This is useful when you want to create a\nBi-directional Auto-Regressive layer because using UnfoldFrom does not work with Recurrence(go_backwards=True) and\nwill result in a ValueError.</p>\n<p>Example:</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\nfrom cntk.layers import Recurrence, UnfoldFrom, LSTM\n\nhidden_dim = 50\nstart_token = C.Constant(0, shape=(hidden_dim,))\na = C.sequence.input_variable(1, name='seq1')\n\nb = UnfoldFrom(Recurrence(LSTM(hidden_dim), go_backwards=True))(start_token, a)\n\nn = [np.random.random((10, hidden_dim)).astype(np.float32),]\n\n# This raise 'ValueError: It is not allowed to have multiple different stepping directions in the same loop'\nb.eval({b.arguments[0]: n})\n</code></pre>\n<p>The workaround would be:</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\nfrom cntk.layers import Recurrence, UnfoldFrom, LSTM\n\nhidden_dim = 50\nstart_token = C.Constant(0, shape=(hidden_dim,))\na = C.sequence.input_variable(1, name='seq1')\na_reversed = Cx.sequence.reverse(a)\n\nb = UnfoldFrom(Recurrence(LSTM(hidden_dim)))(start_token, a_reversed)  # remove go_backwards=True\n\nn = [np.random.random((10, hidden_dim)).astype(np.float32),]    \nb.eval({b.arguments[0]: n})  # this will run just fine\n</code></pre>\n<p><em><strong>2019-06-21.</strong></em></p>\n<h4>Added <code>cntkx.ops.random.sample_top_k</code></h4>\n<p>CNTK implementation of that allows sampling of the top_k unnormalised log-probabilities distribution.\nThis is useful text (or sequence) generation where it is known that greedy decoding will cause\ntext degeneration.</p>\n<p>For more details on this, please refer to <a href=\"https://arxiv.org/abs/1904.09751\" rel=\"nofollow\">A curious case of neural text degeneration</a></p>\n<p>Example:</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\na = C.input_variable(5)\nb = Cx.random.sample_top_k(a, k=3, num_classes=5)\n\nn = np.array([[1, 2, 3, 4, 5],] * 1000)\n\nresults = b.eval({a: n})\nassert np.sum(results[:, :2]) == 0\nassert np.sum(results[:, 2:]) == 1000\n</code></pre>\n<p><em><strong>2019-05-04.</strong></em></p>\n<h4>Added <code>cntkx.layers.vFSMN</code> and <code>cntkx.layers.cFSMN</code></h4>\n<p>CNTK implementation of Bidirectional vectorised Feedforward Sequential Memory Network (vFSMN)\nand Compact Feedforward Sequential Memory Network (cFSMN).</p>\n<p>FSMN is a standard fully-connected feedforward neural network equipped\nwith some learnable memory blocks in its hidden layers. The memory blocks\nuse a tapped-delay line structure to encode the long context information into\na fixed-size representation as short-term memory mechanism.</p>\n<p>The authors claim that FSMNs can be learned much more reliably and faster than\nRNNs or LSTMs due to the inherent non-recurrent model structure while significantly\noutperforming RNNs in language and speech modeling.</p>\n<p>For more details please refer to <a href=\"https://arxiv.org/abs/1512.08301\" rel=\"nofollow\">Feedforward Sequential Memory Networks: A\nNew Structure to Learn Long-term Dependency</a></p>\n<p>cFSMN is a compact version of FSMN that can result in a reduction of up\nto 60% in model size and speed up the learning by more than 7 times while\nstill significantly outperforming the popular bi-direction LSTMs for both\nframe-level cross-entropy (CE) criterion based training and MMI based sequence training.</p>\n<p>For more details please refer to \"Compact Feedforward Sequential Memory Networks for\nLarge VocabularyContinuous Speech Recognition\" by Zhang, et al.</p>\n<p>Example:</p>\n<pre><code>import cntk as C\nfrom cntkx.layers import vFSMN, cFSMN\n\n# unidirectional vFSMN (only past conext used)\na = C.sequence.input_variable(10)\nb = vFSMN(100, C.relu, num_past_context=3, num_future_context=0)(a)\n\nassert b.shape == (100,)\n\n# bidirectional vFSMN (enable both past and future context)\na = C.sequence.input_variable(10)\nb = vFSMN(120, C.relu, num_past_context=3, num_future_context=3)(a)\n\nassert b.shape == (120,)\n\n# bidirectional cFSMN (enable both past and future context)\na = C.sequence.input_variable(100)\nb = cFSMN(120, 50, C.relu, num_past_context=3, num_future_context=3)(a)\n\nassert b.shape == (120,)\n</code></pre>\n<p><em><strong>2019-04-19.</strong></em></p>\n<h4>Added <code>cntkx.misc.CTCEncoder</code></h4>\n<p>CNTK's CTC implementation requires that data be formatted in a particular way that's typically in acoustic\nmodeling but unusual in other applications. So class provides an easy way to convert data between\nwhat users typically expect and what cntk demands.</p>\n<p>Example:\nlabels = ['a', 'b', 'c']\nencoder = CTCEncoder(labels)</p>\n<pre><code>labels_tensor = C.sequence.input_variable(len(encoder.classes_))  # number of classes = 4\ninput_tensor = C.sequence.input_variable(100)\n\nlabels_graph = cntk.labels_to_graph(labels_tensor)\nnetwork_out = model(input_tensor)\n\nfb = C.forward_backward(labels_graph, network_out, blankTokenId=encoder.blankTokenId)\n\nground_truth = ['a', 'b', 'b', 'b', 'c']\nseq_length = 10  # must be the same length as the sequence length in network_out\n\nfb.eval({input_tensor: [...],\n         labels_tensor: [encoder.transform(ground_truth, seq_length=seq_length)]})\n</code></pre>\n<p><em><strong>2019-04-14.</strong></em></p>\n<h4>Added <code>Label Smoothing Regularization</code>, <code>seqeuence.window</code> and <code>PyramidalBiRecurrence</code></h4>\n<p>Added <code>Label Smoothing Regularization</code> in <code>cross_entropy_with_softmax</code>.\nAdded <code>sequence.window</code> that creates non-overlapping window along the sequence axis thereby reducing the\nsequence length and increasing the dimension by the same factor.</p>\n<p>Implemented a convenience layer used in acoustic modelling known as <code>PyramidalBiRecurrence</code>. Used to create\npyramidal bi-directional LSTM (BLSTM) found in \"Listen, attend and spell\" by Chan et al. (<a href=\"https://arxiv.org/abs/1508.01211\" rel=\"nofollow\">https://arxiv.org/abs/1508.01211</a>)\nTypically used to down sample the sequence length to make memory and runtime manageable.</p>\n<p><em><strong>2019-04-08.</strong></em></p>\n<h4>Added <code>cntkx.ops.sequence.join</code></h4>\n<p>Added a new <code>op</code> called <code>join</code> where two sequence tensors can be joined along with sequence axis forming a longer sequence.</p>\n<p><em><strong>2019-04-08.</strong></em></p>\n<h4>Added <code>cntkx.layers.SequentialAveragePooling</code></h4>\n<p>Add average pooling layer that works with sequential axis. Current cntk <code>AveragePooling</code> doesn't pool across sequence elements.</p>\n<p>Example on <code>cntkx.layers.SequentialAveragePooling</code></p>\n<pre><code># rgb image of height 25 and variable width\na = C.sequence.input_variable((3, 25))\n\n# Convolute across image with (3, 3) kernel with stride (1, 1)\nb = C.layers.SequentialConvolution(filter_shape=(3, 3), num_filters=16, stride=(1, 1), pad=True)(a)\n\nassert b.shape == (16, 25)\n\n# max pool (2,2) in height and width with stride (2,2) in height and width, no padding\nc = SequentialAveragePooling(filter_shape=(2, 2), strides=(2, 2), pad=False)(b)\n\nassert c.shape == (16, 12)\n</code></pre>\n<p><em><strong>2019-04-07.</strong></em></p>\n<h4>Added <code>cntkx.sequence.stride</code> and <code>cntkx.ops.scalar</code></h4>\n<p><code>Cx.sequence.stride</code> enables striding across the sequential axis, selecting every integer items along the sequence.\n<code>Cx.scalar</code> converts tensor into scalar of shape <code>(1,)</code></p>\n<p><em><strong>2019-04-06.</strong></em></p>\n<h4>Added <code>IndyLSTM</code> and <code>IndRNN</code></h4>\n<p>CNTK implementation of <a href=\"https://arxiv.org/abs/1903.08023\" rel=\"nofollow\">Independently Recurrent Long Short-term Memory cells: IndyLSTMs</a>\nby Gonnet and Deselaers, and <a href=\"https://arxiv.org/abs/1803.04831\" rel=\"nofollow\">Independently Recurrent Neural Network (IndRNN): Building A Longer andDeeper RNN</a>\nby Li, et al.</p>\n<p>Both <code>IndyLSTM</code> and <code>IndRNN</code> have hidden-to-hidden weights that are diagonal matrix instead of the usual full matrix.\nThus neurons in each layer are independent from each other, and the cross-channel information is\nobtained through stacking multiple layers.</p>\n<p><code>IndRNN</code> allows for the use of <code>C.relu</code> activation thus allowing multiple <code>IndRNN</code> layers to be stacked together deeply.</p>\n<p><code>IndyLSTM</code> has parameters linear to the number of nodes in the linear, as opposed to standard LSTM that is quadratic\nmaking <code>IndyLSTM</code> potentially faster and smaller as a model.</p>\n<p>Authors of both <code>IndRNN</code> and <code>IndyLSTM</code> have claimed performance as good as or even better than regular LSTMs.</p>\n<p>Example:</p>\n<pre><code>import cntk as C\nfrom cntkx.layers import IndyLSTM, IndRNN, Recurrence\n\na = C.sequence.input_variable(10)\nb = Recurrence(IndRNN(20))(a)\nc = Recurrence(IndyLSTM(20))(a)\n\nassert b.shape == c.shape == (20,)\n</code></pre>\n<p><em><strong>2019-03-24.</strong></em></p>\n<h4>Added <code>cntkx.layers.SequentialMaxPooling</code></h4>\n<p>Add max pooling layer that works with sequential axis. Current cntk <code>MaxPooling</code> doesn't pool across sequence elements.</p>\n<p>Example on <code>cntkx.layers.SequentialMaxPooling</code></p>\n<pre><code># rgb image of height 25 and variable width\na = C.sequence.input_variable((3, 25))\n\n# Convolute across image with (3, 3) kernel with stride (1, 1)\nb = C.layers.SequentialConvolution(filter_shape=(3, 3), num_filters=16, stride=(1, 1), pad=True)(a)\n\nassert b.shape == (16, 25)\n\n# max pool (2,2) in height and width with stride (2,2) in height and width, no padding\nc = SequentialMaxPooling(filter_shape=(2, 2), strides=(2, 2), pad=False)(b)\n\nassert c.shape == (16, 12)\n</code></pre>\n<p><em><strong>2019-03-18.</strong></em></p>\n<h4>Added <code>cntkx.learners.CyclicalLearningRate</code></h4>\n<p>Cyclical learning rate (CLR) is an implementation to that  practically eliminates the need to\nexperimentally find the best values and schedule  for  the global  learning  rates.</p>\n<p>Instead  of  monotonically decreasing the learning rate, this method lets the learning<br>\nrate  cyclically  vary  between  reasonable  boundary  values. Training  with<br>\ncyclical  learning  rates  instead of  fixed  values  achieves improved  classification\naccuracy without a need to tune and often in fewer iterations.</p>\n<p>More details can be found in <a href=\"https://arxiv.org/abs/1506.01186\" rel=\"nofollow\">Cyclical Learning Rates for Training Neural Networks</a>\nby Leslie N. Smith</p>\n<p>This CLR implementation can be used with the cntk training loop by adding only <em><strong>two lines of code</strong></em>:</p>\n<pre><code>model = C.layers.Dense(10)(C.input_variable(10))\nsgd_momentum = C.momentum_sgd(model.parameters, 0.1, 0.9)\nclr = CyclicalLeaningRate(sgd_momentum, minibatch_size=32)  # first line of code\n\nfor epoch in range(10):\n    for batch in range(100):\n        trainer.train_minibatch(...)\n        clr.batch_step()  # second line of code (to be called after every training update)\n</code></pre>\n<p><em><strong>2019-03-12.</strong></em></p>\n<h4>Added <code>cntkx.ops.batchmatmul</code></h4>\n<p>Added Batch Matrix Multiplication. This implementation is similar\nto <a href=\"https://www.tensorflow.org/api_docs/python/tf/linalg/matmul\" rel=\"nofollow\">tensorflow.matmul</a>.</p>\n<p>Example:</p>\n<pre><code>a = C.sequence.input_variable((3, 4, 5))     # batch matrix\nb = C.sequence.input_variable((3, 5, 6))     # batch matrix\nc = Cx.batchmatmul(a, b)\nassert c.shape == (3, 4, 6)                  # 3 is treated as a batch axis\n</code></pre>\n<p><em><strong>2019-03-10.</strong></em></p>\n<h4>Added <code>PretrainedBertEncoder</code> and <code>PretrainedBertModel</code></h4>\n<p>BERT, the state-of-the-art language model is now available as a CNTK pretrained model.</p>\n<p>Currently, it is only tested to work with <code>BERT-Base, Uncased</code> (uncased_L-12_H-768_A-12) and can be\ndownloaded from <a href=\"https://github.com/google-research/bert\" rel=\"nofollow\">Google AI</a></p>\n<p>When you have downloaded <code>BERT-Base, Uncased</code>, there should be 5 files inside. You will need to <code>.zip</code>\nthree of those files into a tensorflow checkpoint file before you can load it into <code>cntkx</code>.</p>\n<p>Those three files are: <code>bert_model.ckpt.data-00000-of-00001</code>, <code>bert_model.ckpt.index</code>, <code>bert_model.ckpt.meta</code>.\nThen rename the extension of <code>.zip</code> into <code>.ckpt</code> and you are good to go.</p>\n<p>Example below</p>\n<pre><code>text_tensor = C.sequence.input_variable(30522)\ntoken_type_tensor = C.sequence.input_variable(2)\nfilepath_to_tf_bert_model = \"YOUR_FILE_DIRECTORY/bert_model.ckpt\"\n\nmodel = Cx.layers.PreTrainedBertModel(filepath_to_tf_bert_model, num_heads=12, dropout_rate=0.1)\nb = model(text_tensor, token_type_tensor)\n\nassert b.shape == (768,)\n</code></pre>\n<p>For more details about BERT, you can find the original paper <a href=\"https://arxiv.org/abs/1810.04805\" rel=\"nofollow\">here</a>,\nand some useful resources <a href=\"https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\" rel=\"nofollow\">here</a>\nand <a href=\"http://jalammar.github.io/illustrated-bert/\" rel=\"nofollow\">here</a>.</p>\n<p>Note:\nIt goes without saying also that to use these pre-trained models you will need to have tensorflow installed\nsince we are convert them from tensorflow models.</p>\n<p><em><strong>2019-03-06.</strong></em></p>\n<h4>Added <code>PositionalEmbedding</code>, <code>BertEmbeddings</code> and <code>PretrainedBertEmbeddings</code></h4>\n<p>CNTK implementation of <code>PositionalEmbedding</code>, <code>BertEmbeddings</code> and tf-to-cntk <code>PreTrainedBertEmbeddings</code>.\nBERT is a state-of-the-art language model from Google AI, more details can be found in\n<a href=\"https://arxiv.org/abs/1810.04805\" rel=\"nofollow\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>.</p>\n<p>Google AI's pre-trained BERT tensorflow model can be downloaded <a href=\"https://github.com/google-research/bert\" rel=\"nofollow\">here</a>.\nTensorflow would need to be installed in your environment if you intend to use <code>PreTrainedBertEmbeddings</code>, which\ntakes a tensorflow model and convert it cntk.</p>\n<p>Example for <code>PositionalEmbedding</code></p>\n<pre><code>a = C.sequence.input_variable(12)\nb = PositionalEmbedding(max_seq_length, hidden_dim)(a)\n\nassert b.shape == (hidden_dim, )\n</code></pre>\n<p>Example for <code>BertEmbeddings</code></p>\n<pre><code>text_tensor = C.sequence.input_variable(100)\ntoken_type_tensor = C.sequence.input_variable(2)\nb = BertEmbeddings(max_seq_length, hidden_dim, 0.1)(text_tensor, token_type_tensor)\n\nassert b.shape == (hidden_dim, )\n</code></pre>\n<p>Example for <code>PreTrainedBertEmbeddings</code></p>\n<pre><code>text_tensor = C.sequence.input_variable(30522)\ntoken_type_tensor = C.sequence.input_variable(2)\nfilepath_to_tf_bert_model = \"YOURFILEPATH\"\nembeddings = PreTrainedBertEmbeddings(filepath_to_tf_bert_model, 0.1, False)\nb = embeddings(text_tensor, token_type_tensor)\n\nassert b.shape == (768, )\n</code></pre>\n<p><em><strong>2019-03-02.</strong></em></p>\n<h4>Added <code>VariationalDropout</code> and <code>WeightDroppedLSTM</code></h4>\n<p>CNTK implementation of <code>Variational Dropout</code> found in\n<a href=\"https://arxiv.org/abs/1512.05287\" rel=\"nofollow\">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a>\nand <code>Weight Dropped LSTM</code> proposed in a salesforce research paper\n<a href=\"https://arxiv.org/abs/1708.02182\" rel=\"nofollow\">Regularizing and Optimizing LSTM Language Models</a>.</p>\n<p><code>Weight Dropped LSTM</code> is a regularised LSTM that uses DropConnect on hidden-to-hidden weights as a form of recurrent\nregularisation. It also include application of variational dropout on the inputs and outputs of the recurrent units\nfor further regularisation.</p>\n<p><code>Variational Drpoout</code> is a regularisation that uses same dropout mask at each time step\n(i.e. across the dynamic sequence axis) as opposed to the naive application of <code>C.layers.Dropout</code> to a sequence\nwhich will result in a different dropout mask for every tensor along the sequence axis.</p>\n<pre><code>import cntkx as Cx\nfrom cntkx.layers import Recurrence, WeightDroppedLSTM\nimport cntk as C\n\ndropconnect_rate = 0.2\nvariationaldrop_rate = 0.1\n\nseq = C.sequence.input_variable(56)\nb = Recurrence(WeightDroppedLSTM(20, dropconnect_rate),\n               variational_dropout_rate_input=variationaldrop_rate,\n               variational_dropout_rate_output=variationaldrop_rate)(seq)\n\nassert b.shape == (100, )\n\nseq_dropped = VariationalDropout(0.1)(seq)\n\nassert seq_dropped.shape == seq.shape\n</code></pre>\n<p><em><strong>2019-02-02.</strong></em></p>\n<h4>Added Gated Linear Unit / Gated CNN</h4>\n<p>CNTK implementation of Gated Linear Unit (Gated CNN) founnd in Facebook AI Research Lab's paper:\n<a href=\"https://arxiv.org/abs/1612.08083\" rel=\"nofollow\">Language Modeling with Gated Convolutional Networks</a>.\nThis paper applies a convolutional approach to language modelling with a novel Gated-CNN model.</p>\n<pre><code>import cntkx as Cx\nimport cntk as C\n\nseq = C.sequence.input_variable(56)\nhidden = Cx.layers.GatedLinearUnit(window=2, hidden_dim=100)(seq)\n\nassert hidden.shape == (100, )\n</code></pre>\n<p><em><strong>2019-01-21.</strong></em></p>\n<h4>Added <code>Focal Loss</code> for multi-class and binary classification</h4>\n<p>CNTK implementation of <code>Focal Loss</code> enables the training of highly accurate dense object detectors in the\npresence of vast numbers of easy background examples or dataset with extreme class imbalance (e.g. 1:1000).</p>\n<p><code>Focal Loss</code> focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from\noverwhelm-ing the model during training.</p>\n<p>For more details please refer to <a href=\"https://arxiv.org/abs/1708.02002\" rel=\"nofollow\">Focal Loss for Dense Object Detection</a></p>\n<pre><code>import cntkx as Cx\n\nCx.focal_loss_with_softmax([[0, 0, 0.8, 0.2]], [[0, 0, 1, 0]]).eval()\narray([[0.31306446]], dtype=float32)\n</code></pre>\n<p><em><strong>2019-01-18.</strong></em></p>\n<h4>Added Gaussian Window Attention Model</h4>\n<p>Gaussian window attention model was first introduced by Alex Graves in\n\"Generating sequences with recurrent neural networks\".</p>\n<p>It uses a mixture of gaussian windows to attend to\nportions of the sequence as oppose to the widely used attention model introduced in\n\"Neural machine translation by jointly learning to align and translate\" by Bahdanau, et al. that attends\nto the entire sequence all at once.</p>\n<p>Gaussian window attention is also directional in its attention on the context sequence. When modeling\nstrongly ordered sequences, gaussian window attention will be a natural choice due to this inductive bias.</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\nseq1 = C.Axis.new_unique_dynamic_axis('seq1')\nseq2 = C.Axis.new_unique_dynamic_axis('seq2')\n\nencoded = C.sequence.input_variable(30, sequence_axis=seq1)\nquery = C.sequence.input_variable(28, sequence_axis=seq2)\n\na = Cx.layers.GaussianWindowAttention(10)(encoded, query)\n\nassert a.shape == (30, )\n</code></pre>\n<p>\"Generating sequences with recurrent neural networks\" can be found <a href=\"https://arxiv.org/abs/1308.0850\" rel=\"nofollow\">here</a>.\n\"Neural machine translation by jointly learning to align and translate\" can be found <a href=\"https://arxiv.org/abs/1409.0473\" rel=\"nofollow\">here</a>.</p>\n<p><em><strong>2019-01-16.</strong></em></p>\n<h4>Added Spatial Pyramid Pooling layer</h4>\n<p>Spatial pyramid pooling layer is a pooling layer than returns a fixed length representation regardless of the\nimage size/scale. It is frequently used for multi-size image training. It reported SOTA classification results using\na single full-image representation without fine-tuning. For more details on the paper\n\"Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition\" by K. He, X. Zhang, S. Ren, J. Sun,\nlink <a href=\"https://arxiv.org/abs/1406.4729\" rel=\"nofollow\">here</a>.</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\nn = np.random.random((3, 3, 32, 32)).astype(np.float32)\na = C.input_variable((3, 32, 32))\nb = Cx.layers.SpatialPyramidPooling((1, 2, 4))(a)\n\nassert b.shape == (3 * (4 * 4 + 2 * 2 + 1),)  # representation not dependent on image size\n</code></pre>\n<p><em><strong>2019-01-15.</strong></em></p>\n<h4>Added Sinusoidal Positional Embedding and <code>cntkx.ops.erf</code></h4>\n<p>Added sinusoidal positional embedding used in <a href=\"https://arxiv.org/abs/1706.03762\" rel=\"nofollow\">Transformer</a>. For an accessible\nexplanation of transformer, you may look up <a href=\"http://jalammar.github.io/illustrated-transformer/\" rel=\"nofollow\">here</a>.</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\na = C.sequence.input_variable(10)\nb = SinusoidalPositionalEmbedding()(a)\n\nassert b.shape == (10, )\n</code></pre>\n<p>Added <code>cntkx.ops.erf</code> error function.</p>\n<p><em><strong>2019-01-12.</strong></em></p>\n<h4>Added Vision models: VGG16, VGG19 and UNET</h4>\n<p>VGG is for image classification and UNET is for semantic segmentation. VGG is implemented for completeness\nsake and should not be used for any serious classification task.</p>\n<p>Paper on VGG can be found <a href=\"https://arxiv.org/abs/1409.1556\" rel=\"nofollow\">here</a> titled \"Very Deep Convolutional Networks\nfor Large-Scale Image Recognition\"</p>\n<p>Paper for UNET can be found <a href=\"https://arxiv.org/abs/1505.04597\" rel=\"nofollow\">here</a> titled \"U-Net: Convolutional Networks\nfor Biomedical Image Segmentation\"</p>\n<p>VGG example:</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\na = C.input_variable((3, 64, 64))\nb = Cx.layers.VGG19(100)(a)\n\nassert b.shape == (100,)\n</code></pre>\n<p>UNET example:</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\na = C.input_variable((3, 512, 512))\nb = Cx.layers.UNET(num_classes=10, base_num_filters=64, pad=True)(a)\n\nassert b.shape == (10, 512, 512)\n</code></pre>\n<p>Convenience functions such as <code>cntkx.ops.upsample</code> and <code>centre_crop</code> have also been added.\n<code>cntkx.ops.upsample</code> upsamples an image twice on each spatial dim. <code>centre_crop</code> crops a smaller image from\na bigger one in the centre given a reference smaller image.</p>\n<h4>Added Transformer attention model and associated components</h4>\n<p>The Transformer was first introduced in the <a href=\"https://arxiv.org/abs/1706.03762\" rel=\"nofollow\">paper</a> 'Attention is all you need'.\nThe architecture is based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\nMore recently, <a href=\"https://arxiv.org/abs/1810.04805\" rel=\"nofollow\">BERT</a> which broke almost all SOTA language task is also based on\ntransformer and self-attention.</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\na = C.sequence.input_variable(512)\nb = C.sequence.input_variable(512)\n\ntransformer = Cx.layers.Transformer()  # using default settings\ndecoded = transformer(a, b)\n\nassert decoded.shape == (512, )\n</code></pre>\n<p><em><strong>2018-12-08.</strong></em></p>\n<h4>Added QRNN: Quasi-Recurrent Neural Network (QRNN) and <code>cntkx.ops.cumsum</code></h4>\n<p>The QRNN provides similar accuracy to the LSTM but can be betwen 2 and 17 times faster than the\nhighly optimized NVIDIA cuDNN LSTM implementation depending on the use case.</p>\n<p>More details please refer to the original paper <a href=\"https://arxiv.org/abs/1611.01576\" rel=\"nofollow\">here</a>.</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\ninput_seq = C.sequence.input_variable(input_dim)\nprediction_seq = Cx.layers.QRNN(hidden_dim=50)(input_seq)\n</code></pre>\n<p><em><strong>2018-12-07.</strong></em></p>\n<h4>New sequence ops: <code>cntkx.ops.sequence.pad</code> and <code>cntkx.ops.sequence.length</code></h4>\n<p>Added two new sequence ops. <code>cntkx.ops.sequence.pad</code> allows padding on the sequence axis and\n<code>cntkx.ops.sequence.length</code> calculates the length of the sequence.</p>\n<p><em><strong>2018-12-05.</strong></em></p>\n<h4>Mixture Density Network</h4>\n<p>Mixture density networks are neural networks that can in principle represent arbitrary conditional\nprobability distributions in the same way that a conventional neural network can represent arbitrary functions.\nMDN are very useful when you need to map an input to several correct targets (aka. one-to-many problem).</p>\n<p>Updated with Gaussian Mixture Density Network ops and loss function. Ops will allow you to extract mdn coefficients and sample from the network.</p>\n<p>More details on mdn can be found in this <a href=\"https://publications.aston.ac.uk/373/1/NCRG_94_004.pdf\" rel=\"nofollow\">paper</a> by Christopher Bishop.</p>\n<pre><code>import cntk as C\nimport cntkx as Cx\n\ninput_tensor = C.input_variable(1, name=\"input_tensor\")\ntarget_tensor = C.input_variable(1, name=\"target_tensor\")\n\n# model\ninner = Dense(50, activation=C.relu)(input_tensor)\ninner = Dense(50, activation=C.relu)(inner)\nprediction_tensor = Dense((ndim + 2) * nmix, activation=None)(inner)\n\nsampled = Cx.sample_gaussian_mdn(prediction_tensor, nmix, ndim)  # sampling node\nloss = Cx.gaussian_mdn_loss(prediction_tensor, target_tensor, nmix=nmix, ndim=ndim)  # loss function\n</code></pre>\n\n          </div>"}, "last_serial": 7142824, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "589a619cfd69160284d5db2491937982", "sha256": "19cd149459f346ac7c55ee73ea8a695cdfc462ceedc6eeee09c12bf4123eec9b"}, "downloads": -1, "filename": "cntkx-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "589a619cfd69160284d5db2491937982", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10994, "upload_time": "2018-12-09T10:35:38", "upload_time_iso_8601": "2018-12-09T10:35:38.401198Z", "url": "https://files.pythonhosted.org/packages/b9/01/22dca62cdaddf8684c12a87f7988eea4a551bb10ebaff3eda45cb7468b49/cntkx-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bc33bd5979b9bb90a40cfd2f55afa533", "sha256": "67080bb58a8f36c6380b938b2883c66db1ffbfa2f62b48c9ae8d3eb14a7dc4c7"}, "downloads": -1, "filename": "cntkx-0.0.1.tar.gz", "has_sig": false, "md5_digest": "bc33bd5979b9bb90a40cfd2f55afa533", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6405, "upload_time": "2018-12-09T10:35:40", "upload_time_iso_8601": "2018-12-09T10:35:40.490598Z", "url": "https://files.pythonhosted.org/packages/72/13/d2177fee5ca28782a816e171be0d74a7424e25aadd548cc2677ae77b2b46/cntkx-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "3011d3cde6a4c6e57f78a8ecebea2650", "sha256": "b0937106f17ba3b3043069c946fb26971c545d11eb26c600f503c507a77606ac"}, "downloads": -1, "filename": "cntkx-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "3011d3cde6a4c6e57f78a8ecebea2650", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22263, "upload_time": "2019-01-12T08:47:25", "upload_time_iso_8601": "2019-01-12T08:47:25.102130Z", "url": "https://files.pythonhosted.org/packages/ed/fe/21baf9847001deccf01d858a5b3f956e157b767afbf86e48470284e745cf/cntkx-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "de353b2ee856cbcf215d71292ed72f63", "sha256": "9f0209f1ff60453ca67d4d15d3f7ffba5ec90ae690cae437ed340e6b78e9bfee"}, "downloads": -1, "filename": "cntkx-0.0.2.tar.gz", "has_sig": false, "md5_digest": "de353b2ee856cbcf215d71292ed72f63", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15115, "upload_time": "2019-01-12T08:47:27", "upload_time_iso_8601": "2019-01-12T08:47:27.666073Z", "url": "https://files.pythonhosted.org/packages/48/43/dc48dc16fce7588ff73f4f997251c87cf16223d8d8139f9638b4d34e9d24/cntkx-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "fbd72596f8f80637c8ed009b71e46719", "sha256": "865d8fa01e881bc06206983e06da875313ca39d8b90e48780ce43db68e43bf63"}, "downloads": -1, "filename": "cntkx-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "fbd72596f8f80637c8ed009b71e46719", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24689, "upload_time": "2019-01-17T16:19:09", "upload_time_iso_8601": "2019-01-17T16:19:09.481490Z", "url": "https://files.pythonhosted.org/packages/8d/6c/e56e08077010179a0caea528b0744762fe7809ef72eba8d2e760b9f96003/cntkx-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a9273c5bf95330428c4f4153c4499a48", "sha256": "c880b5ea82753f1d1635af23d19d2d1d883a8ea8c45d4ea76b6f5f76c3a66348"}, "downloads": -1, "filename": "cntkx-0.0.3.tar.gz", "has_sig": false, "md5_digest": "a9273c5bf95330428c4f4153c4499a48", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16829, "upload_time": "2019-01-17T16:19:12", "upload_time_iso_8601": "2019-01-17T16:19:12.719897Z", "url": "https://files.pythonhosted.org/packages/43/e8/77793d68ac61d99b10e565f24ffed67e041732e8867299e162f89fa57be9/cntkx-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "3b0108aed97f0f6050400472b4901f45", "sha256": "d595451326f775c0f0149251492c2767a2cd73a15174cc6e9fc08cec4568e2e8"}, "downloads": -1, "filename": "cntkx-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "3b0108aed97f0f6050400472b4901f45", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 27894, "upload_time": "2019-01-21T14:41:35", "upload_time_iso_8601": "2019-01-21T14:41:35.468809Z", "url": "https://files.pythonhosted.org/packages/ff/0e/d116d1c77df5381b477fc80709e6fa1660208224e1d75abf94c2f9f8c4c4/cntkx-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5fa41e9284a41888fbda7866f0ee2850", "sha256": "43f7f228740ef95b1d97d14fff887933cb8bcfbb7fd08a2e41d5253054fcf426"}, "downloads": -1, "filename": "cntkx-0.0.4.tar.gz", "has_sig": false, "md5_digest": "5fa41e9284a41888fbda7866f0ee2850", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19547, "upload_time": "2019-01-21T14:41:37", "upload_time_iso_8601": "2019-01-21T14:41:37.122783Z", "url": "https://files.pythonhosted.org/packages/dd/e9/ace1aee34b226231f0cad2e02c2cb9475f62450592741e96dff08b4851b7/cntkx-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "1dd73f18d677657e8e97660bb12d1496", "sha256": "d6a07470668473c667389d5babfd4683a5df91c0e6cc255dc2f0affa7c6500b6"}, "downloads": -1, "filename": "cntkx-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "1dd73f18d677657e8e97660bb12d1496", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 42413, "upload_time": "2019-03-10T16:50:34", "upload_time_iso_8601": "2019-03-10T16:50:34.398291Z", "url": "https://files.pythonhosted.org/packages/aa/34/7b8e65fb45e6a53303fb20101094fd11264512a3c89eeb2698b138127f9a/cntkx-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6241929992e97bde29ac93c7eb2610fe", "sha256": "d327bf5f766d8dd734477dbbf8c44ad0bbb9577ba50eff570f0096c2c2c75349"}, "downloads": -1, "filename": "cntkx-0.0.5.tar.gz", "has_sig": false, "md5_digest": "6241929992e97bde29ac93c7eb2610fe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32918, "upload_time": "2019-03-10T16:50:36", "upload_time_iso_8601": "2019-03-10T16:50:36.895755Z", "url": "https://files.pythonhosted.org/packages/17/be/4c7284a7b281c5760c424a3ffb4337326c7726cf7b0ae1ec3421f534a784/cntkx-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "14924a50fdcd85a28731e806c0782458", "sha256": "d11d99c5fbff2403002e899a3a172f454b482bfecef2cb56c250d7ece7ac146a"}, "downloads": -1, "filename": "cntkx-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "14924a50fdcd85a28731e806c0782458", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 47259, "upload_time": "2019-03-11T01:52:11", "upload_time_iso_8601": "2019-03-11T01:52:11.447700Z", "url": "https://files.pythonhosted.org/packages/fe/ac/26c905347fde38153003f330806933206c4a14d718bdf1d87b8cbfd6b8ec/cntkx-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "678eea409dbe27992e68d37701005863", "sha256": "7492356a60525eb7ccc7fb46478fe6b2b880e0e88b0f0ca0062667fe4eea4f2a"}, "downloads": -1, "filename": "cntkx-0.0.6.tar.gz", "has_sig": false, "md5_digest": "678eea409dbe27992e68d37701005863", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38776, "upload_time": "2019-03-11T01:52:13", "upload_time_iso_8601": "2019-03-11T01:52:13.108949Z", "url": "https://files.pythonhosted.org/packages/03/ee/c38499636982b9b0f03139bb056c22bb1ec1b38955ec85abdb3290faaf19/cntkx-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "709b41d683fa06864059c59359ec314e", "sha256": "bde534e64035e31240a3a0fc57cc57b73c14ac3e6580cf2fd5564f237e62858c"}, "downloads": -1, "filename": "cntkx-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "709b41d683fa06864059c59359ec314e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 48998, "upload_time": "2019-03-12T13:11:37", "upload_time_iso_8601": "2019-03-12T13:11:37.146850Z", "url": "https://files.pythonhosted.org/packages/50/fa/5c1d5d25949a7cd67225c0b658052692c8a3c413c42efe0dce7eea92bf82/cntkx-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a1795bbd85cf47101fe91c35ac877030", "sha256": "54fde696a9effbf1275414a731bf17b4651719202e994dfa0c90bc6d99e49915"}, "downloads": -1, "filename": "cntkx-0.0.7.tar.gz", "has_sig": false, "md5_digest": "a1795bbd85cf47101fe91c35ac877030", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40477, "upload_time": "2019-03-12T13:11:39", "upload_time_iso_8601": "2019-03-12T13:11:39.004294Z", "url": "https://files.pythonhosted.org/packages/8b/44/0750346e7567bbe19eda6af97bd404f287cc573053435c7517823c442d16/cntkx-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "4750abff1a0fa26bde3d2c9ee37d40a2", "sha256": "db950a827335b73c89b34a8d01bd2ab9eb33f067dead4de67649dcb649008d50"}, "downloads": -1, "filename": "cntkx-0.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "4750abff1a0fa26bde3d2c9ee37d40a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 56770, "upload_time": "2019-03-24T10:44:59", "upload_time_iso_8601": "2019-03-24T10:44:59.412418Z", "url": "https://files.pythonhosted.org/packages/de/bc/c19d47d51209309fa16c884a7b6a2da3ed141102fbfd6e56b04052205c12/cntkx-0.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "98451ab0411f59f63bbe3758337e5ab4", "sha256": "0fde7edf503650ef1d7cef28abeb1b6757268bc097a5e1de42eb0ff4820d2acd"}, "downloads": -1, "filename": "cntkx-0.0.8.tar.gz", "has_sig": false, "md5_digest": "98451ab0411f59f63bbe3758337e5ab4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47750, "upload_time": "2019-03-24T10:45:01", "upload_time_iso_8601": "2019-03-24T10:45:01.023997Z", "url": "https://files.pythonhosted.org/packages/1c/d7/1ec98043df76742047fedbe3a497528fe7ec848a21944d84fe39283b8f2f/cntkx-0.0.8.tar.gz", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "6ef09feca0a113a50bbe89c9d24b5de6", "sha256": "7f39beebad044ca11a08f8772ef1685728f8b6bc96d343ce4c598c9584dd54eb"}, "downloads": -1, "filename": "cntkx-0.0.9-py3-none-any.whl", "has_sig": false, "md5_digest": "6ef09feca0a113a50bbe89c9d24b5de6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 71120, "upload_time": "2019-04-01T06:31:39", "upload_time_iso_8601": "2019-04-01T06:31:39.483597Z", "url": "https://files.pythonhosted.org/packages/56/68/83dee4c5f8a6bb8d51fd7e951df61a9898ee5124a00d5381bf66b42df950/cntkx-0.0.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a19f9f13ca11ab443a540885fd71bba7", "sha256": "e62fdbc39538ba700a917419781618767254cc76c3f3271f05579397f3fb21b7"}, "downloads": -1, "filename": "cntkx-0.0.9.zip", "has_sig": false, "md5_digest": "a19f9f13ca11ab443a540885fd71bba7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 77822, "upload_time": "2019-04-01T06:31:42", "upload_time_iso_8601": "2019-04-01T06:31:42.054539Z", "url": "https://files.pythonhosted.org/packages/c3/87/95209bc60d21aa6ef04ccb062e924cbcf05d3db5aea02cbaac65a2d932bf/cntkx-0.0.9.zip", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "80993d4b54a45fb2238e58dab0751ad7", "sha256": "ff145f3b3cae2dc178e081d8d12316930203a7702c612c68c2190d0b89a46512"}, "downloads": -1, "filename": "cntkx-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "80993d4b54a45fb2238e58dab0751ad7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 66095, "upload_time": "2019-04-07T10:23:27", "upload_time_iso_8601": "2019-04-07T10:23:27.656434Z", "url": "https://files.pythonhosted.org/packages/b3/77/054dca742dbfa759fa5c8ab1d33d0f78e857ccb271a29aec87446d8cc6ce/cntkx-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ca5a8d574517e590f871338f9c3ba7ad", "sha256": "317fd238f3a68e92c11b6fbf24fdefdf49df6a94ea1b2e538b8194a239864185"}, "downloads": -1, "filename": "cntkx-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ca5a8d574517e590f871338f9c3ba7ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 56019, "upload_time": "2019-04-07T10:23:30", "upload_time_iso_8601": "2019-04-07T10:23:30.813153Z", "url": "https://files.pythonhosted.org/packages/99/d8/afcb0d8ba2b5ff350a98319a4aae6ea10077603b842cdcb72fe9ada4314b/cntkx-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "533453bf2b09c61bcfc75d7484e4c3f9", "sha256": "db7bb4ba297c6186f378413dd85402490c78aa1c703273c793f9f8dcec038a15"}, "downloads": -1, "filename": "cntkx-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "533453bf2b09c61bcfc75d7484e4c3f9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 68186, "upload_time": "2019-04-08T10:34:08", "upload_time_iso_8601": "2019-04-08T10:34:08.337318Z", "url": "https://files.pythonhosted.org/packages/ac/84/4a921fc388c0e0f142c5fa5d800c51f652f41f9c835f81b119a5f4898b3b/cntkx-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "601d3143c77a929a7b7ed8141a96e684", "sha256": "7563247cd5086c9219900e5e7b6b36683fe66b3e1b320eba07f0f740a79eb89f"}, "downloads": -1, "filename": "cntkx-0.1.1.tar.gz", "has_sig": false, "md5_digest": "601d3143c77a929a7b7ed8141a96e684", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57827, "upload_time": "2019-04-08T10:34:12", "upload_time_iso_8601": "2019-04-08T10:34:12.123842Z", "url": "https://files.pythonhosted.org/packages/0b/76/16655078ba1feb56b25fb238ef78a0cec356d7e685d1a920cbb4ea3589fb/cntkx-0.1.1.tar.gz", "yanked": false}], "0.1.10": [{"comment_text": "", "digests": {"md5": "b703957e4841a6b916f6c236603204a1", "sha256": "50e980c4656cbe3d7750c615a7f3aafd0c0694e29bd8966384672417073a988a"}, "downloads": -1, "filename": "cntkx-0.1.10-py3-none-any.whl", "has_sig": false, "md5_digest": "b703957e4841a6b916f6c236603204a1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 77864, "upload_time": "2019-06-20T17:28:17", "upload_time_iso_8601": "2019-06-20T17:28:17.177266Z", "url": "https://files.pythonhosted.org/packages/b7/19/5dc2e9815d4e02af6bc0ec18d718d51c0fc22b0288b7ae2494b91ee43470/cntkx-0.1.10-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "be5879ce5d4064b98cef8b857d6f30c3", "sha256": "1cef50e250fcb71809f1c41f98d371afc890aee4ba839c3341c5db2e65e624ca"}, "downloads": -1, "filename": "cntkx-0.1.10.tar.gz", "has_sig": false, "md5_digest": "be5879ce5d4064b98cef8b857d6f30c3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 74953, "upload_time": "2019-06-20T17:28:20", "upload_time_iso_8601": "2019-06-20T17:28:20.341614Z", "url": "https://files.pythonhosted.org/packages/0c/0a/8843af68272f353f69a602a8378162d68ee5aea81365f42839282b455312/cntkx-0.1.10.tar.gz", "yanked": false}], "0.1.11": [{"comment_text": "", "digests": {"md5": "3a794c17e4830d4db18d6f365bdbce84", "sha256": "b0a88b893b9dcbf0046d0f0f0250af49655cf38935b3a2b3e6fad6cc40d5038c"}, "downloads": -1, "filename": "cntkx-0.1.11-py3-none-any.whl", "has_sig": false, "md5_digest": "3a794c17e4830d4db18d6f365bdbce84", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 79600, "upload_time": "2019-06-26T07:46:54", "upload_time_iso_8601": "2019-06-26T07:46:54.715774Z", "url": "https://files.pythonhosted.org/packages/45/71/41d3e98aa3419a9b5f09d2dbae5ed5c5e3b7de8a3abf05524129cb279cc1/cntkx-0.1.11-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f263b3730a6b7b511c51ed934193fb4", "sha256": "731c324139c2b313459346ca583c6bbbb72801827406f0a61e4c145bc0bf41ef"}, "downloads": -1, "filename": "cntkx-0.1.11.tar.gz", "has_sig": false, "md5_digest": "7f263b3730a6b7b511c51ed934193fb4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 78682, "upload_time": "2019-06-26T07:46:58", "upload_time_iso_8601": "2019-06-26T07:46:58.244431Z", "url": "https://files.pythonhosted.org/packages/e3/93/2f99068f2a49dd76068c65d682a1442abbb4581365882c732b690bd38d21/cntkx-0.1.11.tar.gz", "yanked": false}], "0.1.12": [{"comment_text": "", "digests": {"md5": "153afc9f400bfb6bad2a3d8c775e0886", "sha256": "69d25570d449fa7827bf67878beb50b7a7f5361fb2aaae42f1960e50f47347a4"}, "downloads": -1, "filename": "cntkx-0.1.12-py3-none-any.whl", "has_sig": false, "md5_digest": "153afc9f400bfb6bad2a3d8c775e0886", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 79933, "upload_time": "2019-07-04T08:07:36", "upload_time_iso_8601": "2019-07-04T08:07:36.279522Z", "url": "https://files.pythonhosted.org/packages/c3/20/f6e7ae580fb5401c1f0b2f6eedc2aa3ea3b03acabc4dc582c4a801ff4340/cntkx-0.1.12-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1465c71c9f12fc667a2cf6802a87b80d", "sha256": "0858c6b6cab0400b0d395a11e6f453cc7ca835442175a9723f47f888d9833181"}, "downloads": -1, "filename": "cntkx-0.1.12.tar.gz", "has_sig": false, "md5_digest": "1465c71c9f12fc667a2cf6802a87b80d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 79446, "upload_time": "2019-07-04T08:07:38", "upload_time_iso_8601": "2019-07-04T08:07:38.038691Z", "url": "https://files.pythonhosted.org/packages/79/61/ab6c402fcb238c626ef6e202a0d739e2fa0bb7da0c36b4a183ae2ee430a7/cntkx-0.1.12.tar.gz", "yanked": false}], "0.1.13": [{"comment_text": "", "digests": {"md5": "aba8d77b8bb7b5cc87e44488d74611b5", "sha256": "c711074e41fb26480940891840ea371221d16ab429c732257098e8d0635bac1f"}, "downloads": -1, "filename": "cntkx-0.1.13-py3-none-any.whl", "has_sig": false, "md5_digest": "aba8d77b8bb7b5cc87e44488d74611b5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 80795, "upload_time": "2019-08-09T16:04:34", "upload_time_iso_8601": "2019-08-09T16:04:34.349747Z", "url": "https://files.pythonhosted.org/packages/ae/76/36a9fb7dff0016393582f64b6ee941735c38f40e732d7ace819fd1e620f5/cntkx-0.1.13-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3bd3019dd664b72bfa81db4c26936610", "sha256": "ff85703f6fda3a8fd3bc5d0b125a9664a3083fbebe9fb2097ad5748eaff256a4"}, "downloads": -1, "filename": "cntkx-0.1.13.tar.gz", "has_sig": false, "md5_digest": "3bd3019dd664b72bfa81db4c26936610", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 81104, "upload_time": "2019-08-09T16:04:37", "upload_time_iso_8601": "2019-08-09T16:04:37.431996Z", "url": "https://files.pythonhosted.org/packages/ce/6b/4f9a07a7959da5b7350274de84c380bd0c9b347a121b6ed85a8eb0fe6802/cntkx-0.1.13.tar.gz", "yanked": false}], "0.1.14": [{"comment_text": "", "digests": {"md5": "1d336158f3e318ba7e31ecec81095a91", "sha256": "60bde7a4803332e1e45f2ff67216c5671eabc6593e8a88c7d4725e134f3bb960"}, "downloads": -1, "filename": "cntkx-0.1.14-py3-none-any.whl", "has_sig": false, "md5_digest": "1d336158f3e318ba7e31ecec81095a91", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84189, "upload_time": "2019-08-29T13:59:47", "upload_time_iso_8601": "2019-08-29T13:59:47.357393Z", "url": "https://files.pythonhosted.org/packages/9f/70/b5c36e6fffde6d5fafde3abe30650d2431d500333a2e1abba461c7a86b9d/cntkx-0.1.14-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "94f93a27467da3feb14de55239eacb69", "sha256": "db37b6c9052aa3b27c1657fcfc4ca553392aee1fdad01988bd5e7126eb6f1607"}, "downloads": -1, "filename": "cntkx-0.1.14.tar.gz", "has_sig": false, "md5_digest": "94f93a27467da3feb14de55239eacb69", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 88806, "upload_time": "2019-08-29T13:59:52", "upload_time_iso_8601": "2019-08-29T13:59:52.331539Z", "url": "https://files.pythonhosted.org/packages/d2/37/2ebabe01b49ba93014574ec879f00c01ce60232f5f2626b44f64d38cde8d/cntkx-0.1.14.tar.gz", "yanked": false}], "0.1.15": [{"comment_text": "", "digests": {"md5": "71770025cc83c105af24c9b5106892e1", "sha256": "4db90cbae958eec41bc6d67a50ccd8657e8c72e8da9847f06fabc3fa0a1c2978"}, "downloads": -1, "filename": "cntkx-0.1.15-py3-none-any.whl", "has_sig": false, "md5_digest": "71770025cc83c105af24c9b5106892e1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84496, "upload_time": "2019-09-03T09:43:05", "upload_time_iso_8601": "2019-09-03T09:43:05.393224Z", "url": "https://files.pythonhosted.org/packages/a5/1b/0e0915f680e8506d0fd2fcb01bf1b8e25e3b3c49f262825e9e1b02109222/cntkx-0.1.15-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "67aef2a1d7cfad71e63676aa0367243c", "sha256": "29a4508cac8e09660bbda47dc98c8948cde868041b9d9ec162a80f55ef6dc3a5"}, "downloads": -1, "filename": "cntkx-0.1.15.tar.gz", "has_sig": false, "md5_digest": "67aef2a1d7cfad71e63676aa0367243c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89256, "upload_time": "2019-09-03T09:43:10", "upload_time_iso_8601": "2019-09-03T09:43:10.952600Z", "url": "https://files.pythonhosted.org/packages/32/77/6ef9a5709afbe51affef47454320be3ddb0693083d2fdd28899796eb54dc/cntkx-0.1.15.tar.gz", "yanked": false}], "0.1.16": [{"comment_text": "", "digests": {"md5": "bab6422c4efcaaeb356bb48a7acf7fb1", "sha256": "c1a085b708fb1158400858083f47a200243b3ff45efa7f9033b12261f302ebc4"}, "downloads": -1, "filename": "cntkx-0.1.16-py3-none-any.whl", "has_sig": false, "md5_digest": "bab6422c4efcaaeb356bb48a7acf7fb1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84497, "upload_time": "2019-09-03T09:59:36", "upload_time_iso_8601": "2019-09-03T09:59:36.392611Z", "url": "https://files.pythonhosted.org/packages/5f/69/f368f70ac4598997d5c54fd8d2540c244eb2728cb67fe8f9c888615dcdca/cntkx-0.1.16-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "16af0753155309a9de39986d6cad241d", "sha256": "b1f726082da22a91c8b5f122dceeb56849d3cdccd3a13868af34a579d7e86771"}, "downloads": -1, "filename": "cntkx-0.1.16.tar.gz", "has_sig": false, "md5_digest": "16af0753155309a9de39986d6cad241d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89254, "upload_time": "2019-09-03T09:59:41", "upload_time_iso_8601": "2019-09-03T09:59:41.644572Z", "url": "https://files.pythonhosted.org/packages/f2/f0/2a0fb6efb90000cf70a444500e1f7c82872f25671e9434aff2e90863c8a9/cntkx-0.1.16.tar.gz", "yanked": false}], "0.1.17": [{"comment_text": "", "digests": {"md5": "990da5409a464679ec9ffcf24a84ec9f", "sha256": "4082d2c7f5e1d6de9100260bb7d5b427c0093af1bc88d520d793581ac8cc9f7d"}, "downloads": -1, "filename": "cntkx-0.1.17-py3-none-any.whl", "has_sig": false, "md5_digest": "990da5409a464679ec9ffcf24a84ec9f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84496, "upload_time": "2019-09-03T10:04:11", "upload_time_iso_8601": "2019-09-03T10:04:11.260392Z", "url": "https://files.pythonhosted.org/packages/c9/ea/a8e8adce5b2ef95310666534b1295c8f93da147cc00f4fd913747722b722/cntkx-0.1.17-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "89d37e67982274e868b56fcad4f12994", "sha256": "4b7b3027dfdb3c14effa3fca0953a3101c1d23cb75c18aea3df382d27f45c861"}, "downloads": -1, "filename": "cntkx-0.1.17.tar.gz", "has_sig": false, "md5_digest": "89d37e67982274e868b56fcad4f12994", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89251, "upload_time": "2019-09-03T10:04:13", "upload_time_iso_8601": "2019-09-03T10:04:13.066323Z", "url": "https://files.pythonhosted.org/packages/96/e6/b3d497b167e5e97832e417a93a52e7ae7796825187e528bae61e84167d82/cntkx-0.1.17.tar.gz", "yanked": false}], "0.1.18": [{"comment_text": "", "digests": {"md5": "4546f0a901e167f165541cf2588785b3", "sha256": "04309a66f161851dcd32ba3427f8164e03e99c31a09ea192975ad753908b38d1"}, "downloads": -1, "filename": "cntkx-0.1.18-py3-none-any.whl", "has_sig": false, "md5_digest": "4546f0a901e167f165541cf2588785b3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84497, "upload_time": "2019-09-03T10:09:36", "upload_time_iso_8601": "2019-09-03T10:09:36.412777Z", "url": "https://files.pythonhosted.org/packages/ba/09/e0249d61350e1d9558fb092010f51324062777067393c0b6ebf03fc42f34/cntkx-0.1.18-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d696a0de9ff39b69de959d96ecaa6c8", "sha256": "5dd7a7e12fc1dad5c8f9c125f23dedcc207680ba6a475390381f4896f2ff0cbd"}, "downloads": -1, "filename": "cntkx-0.1.18.tar.gz", "has_sig": false, "md5_digest": "3d696a0de9ff39b69de959d96ecaa6c8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89264, "upload_time": "2019-09-03T10:09:39", "upload_time_iso_8601": "2019-09-03T10:09:39.275541Z", "url": "https://files.pythonhosted.org/packages/01/a1/05dc150e10b297fb5daea9272116a8fb104c271faa7b27d127416ad3e88d/cntkx-0.1.18.tar.gz", "yanked": false}], "0.1.18.1": [{"comment_text": "", "digests": {"md5": "4e8069783b0c282b268935aef168a327", "sha256": "eb1891c6f9f90c494e23c853ce2fb5f305e2e60727c6cca51938f29bb86c9f5f"}, "downloads": -1, "filename": "cntkx-0.1.18.1-py3-none-any.whl", "has_sig": false, "md5_digest": "4e8069783b0c282b268935aef168a327", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84520, "upload_time": "2019-09-03T10:19:50", "upload_time_iso_8601": "2019-09-03T10:19:50.870083Z", "url": "https://files.pythonhosted.org/packages/e1/9f/a490f98ee8f83d1a3ea74a85897ddacf03100e949ebd76e1f3158f1e77d7/cntkx-0.1.18.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b8bcb91da85ad300ccdcdde14de7c63a", "sha256": "3580fdd9ae2e2fb3d8e7aebbec650f0b4529c70fa94bbfce5c5fe60544f117e9"}, "downloads": -1, "filename": "cntkx-0.1.18.1.tar.gz", "has_sig": false, "md5_digest": "b8bcb91da85ad300ccdcdde14de7c63a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89271, "upload_time": "2019-09-03T10:19:54", "upload_time_iso_8601": "2019-09-03T10:19:54.370180Z", "url": "https://files.pythonhosted.org/packages/8c/c0/025d6c10de53afdf96737cfd25f5bf3e7cf70a8b0bd6500b53231a2a4249/cntkx-0.1.18.1.tar.gz", "yanked": false}], "0.1.18.2": [{"comment_text": "", "digests": {"md5": "94a7c662af8f494c188cb347c57d9508", "sha256": "4e80ce976df451cc80b93b14b00ae4f26f0cc99f75fc95787a0895adaac6f727"}, "downloads": -1, "filename": "cntkx-0.1.18.2-py3-none-any.whl", "has_sig": false, "md5_digest": "94a7c662af8f494c188cb347c57d9508", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 84521, "upload_time": "2019-09-03T11:47:01", "upload_time_iso_8601": "2019-09-03T11:47:01.407020Z", "url": "https://files.pythonhosted.org/packages/a1/68/2451f961acca49de1888871008ffe7c09db3d3f0b97416aacc03e776efcc/cntkx-0.1.18.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "368efe9b74ef6b010f4e9d630919fbbc", "sha256": "5c9367158574b2e238fb91213de88768214bea9707864866149935d4b242e841"}, "downloads": -1, "filename": "cntkx-0.1.18.2.tar.gz", "has_sig": false, "md5_digest": "368efe9b74ef6b010f4e9d630919fbbc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89272, "upload_time": "2019-09-03T11:47:03", "upload_time_iso_8601": "2019-09-03T11:47:03.462192Z", "url": "https://files.pythonhosted.org/packages/f3/09/7a2599a7f7208e39250d58e9eadeb178daa519a7c0804adb87bfcaa5c66f/cntkx-0.1.18.2.tar.gz", "yanked": false}], "0.1.18.3": [{"comment_text": "", "digests": {"md5": "c0d12d51632863bc331880d9c5613bc1", "sha256": "a1524d1e112ab92d8cedef6c15e5cb038b880c3e1d327b61ea5fa49c6eb9195b"}, "downloads": -1, "filename": "cntkx-0.1.18.3-py3-none-any.whl", "has_sig": false, "md5_digest": "c0d12d51632863bc331880d9c5613bc1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 85569, "upload_time": "2019-09-03T11:52:08", "upload_time_iso_8601": "2019-09-03T11:52:08.267057Z", "url": "https://files.pythonhosted.org/packages/56/0f/eea52c5c9d11e241f1e615ba9c210c7cac7e83a203b542c4fccee18fb17c/cntkx-0.1.18.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1e6b536bf95e69379624e130a854ba7a", "sha256": "bc28acde088abb31356bb00b73d776fe1b3384a2fd8046747e2dd70e4388c018"}, "downloads": -1, "filename": "cntkx-0.1.18.3.tar.gz", "has_sig": false, "md5_digest": "1e6b536bf95e69379624e130a854ba7a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 89283, "upload_time": "2019-09-03T11:52:12", "upload_time_iso_8601": "2019-09-03T11:52:12.197243Z", "url": "https://files.pythonhosted.org/packages/57/4a/b235d16f9cfb344b311ecacdf895ff1346dd19f68243ef8fe759ddb59e54/cntkx-0.1.18.3.tar.gz", "yanked": false}], "0.1.19": [{"comment_text": "", "digests": {"md5": "4c468bcfefd0d3c466a5f6a156517ee0", "sha256": "cd3278be723cee25f3da7c04a06a4fee00345724f1be8b112750619861053ac6"}, "downloads": -1, "filename": "cntkx-0.1.19-py3-none-any.whl", "has_sig": false, "md5_digest": "4c468bcfefd0d3c466a5f6a156517ee0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 86335, "upload_time": "2019-09-05T17:44:44", "upload_time_iso_8601": "2019-09-05T17:44:44.596448Z", "url": "https://files.pythonhosted.org/packages/55/0d/0234186568b0010d4b985352612135c2c04654fcc6916d69bcce0f268735/cntkx-0.1.19-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c2e4088cb3f47502fe3aebc9403d97f2", "sha256": "5490b7d27ef77e1633dc23b95fc371644d80cca636151a9023fe8b7c7b07c07f"}, "downloads": -1, "filename": "cntkx-0.1.19.tar.gz", "has_sig": false, "md5_digest": "c2e4088cb3f47502fe3aebc9403d97f2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90805, "upload_time": "2019-09-05T17:44:49", "upload_time_iso_8601": "2019-09-05T17:44:49.022331Z", "url": "https://files.pythonhosted.org/packages/c2/92/b0c0e714e90f46bffa7c21bdbb64fdf480c9cb51bdfc0fe9447174dc10d6/cntkx-0.1.19.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "43635d8679035d0808f728a9eb925235", "sha256": "8c4e2c7f288fc21f10981833db32b9cc02e8d2827d3e0041bb61889135355183"}, "downloads": -1, "filename": "cntkx-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "43635d8679035d0808f728a9eb925235", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 68453, "upload_time": "2019-04-10T04:21:18", "upload_time_iso_8601": "2019-04-10T04:21:18.443343Z", "url": "https://files.pythonhosted.org/packages/0e/8d/ccdbecbd1cfceb824c558613d6f6c1c1abc34e10f511ba8692382d334d31/cntkx-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b25d4d2b9b0ad61ae4083c08a4b3a06c", "sha256": "1f36242ecf99dfccddceeef4ba7e7b4462d7e03fa06e5abcdf89d5497abb7ff1"}, "downloads": -1, "filename": "cntkx-0.1.2.tar.gz", "has_sig": false, "md5_digest": "b25d4d2b9b0ad61ae4083c08a4b3a06c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58064, "upload_time": "2019-04-10T04:21:23", "upload_time_iso_8601": "2019-04-10T04:21:23.045099Z", "url": "https://files.pythonhosted.org/packages/40/d7/3751872bd6a6b431ec8490caae19827124dee6820b7c0123b9398e6060f3/cntkx-0.1.2.tar.gz", "yanked": false}], "0.1.20": [{"comment_text": "", "digests": {"md5": "e187f530e7fe309b2d5d36dde6fbb243", "sha256": "40da9bd3ba9376b5371af33b0c4a38a75d12291afc9ff325090447b1da551aa8"}, "downloads": -1, "filename": "cntkx-0.1.20-py3-none-any.whl", "has_sig": false, "md5_digest": "e187f530e7fe309b2d5d36dde6fbb243", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 86460, "upload_time": "2019-09-07T15:05:43", "upload_time_iso_8601": "2019-09-07T15:05:43.676250Z", "url": "https://files.pythonhosted.org/packages/38/20/23775f702c4a779ff5bb4549a2b96dd29de4b665abdd8c2818e2822755e6/cntkx-0.1.20-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23265bafd80a5326af74272086cc56fe", "sha256": "57ff3f14a1e080c6cfb172588bdd60bae5e630a5297772ea31b2ae153aff7f5e"}, "downloads": -1, "filename": "cntkx-0.1.20.tar.gz", "has_sig": false, "md5_digest": "23265bafd80a5326af74272086cc56fe", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90944, "upload_time": "2019-09-07T15:05:49", "upload_time_iso_8601": "2019-09-07T15:05:49.755632Z", "url": "https://files.pythonhosted.org/packages/df/d8/02cc3ab6a669184e0cc2162920e28ceee1ff0dcb2ab4996954414b538aad/cntkx-0.1.20.tar.gz", "yanked": false}], "0.1.21": [{"comment_text": "", "digests": {"md5": "820d2e02395624afa680694764282a67", "sha256": "5328e91a470d59faddabb19acadc07fbc58f18965f533e7abc6565035b0e5181"}, "downloads": -1, "filename": "cntkx-0.1.21-py3-none-any.whl", "has_sig": false, "md5_digest": "820d2e02395624afa680694764282a67", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 86467, "upload_time": "2019-09-09T07:27:56", "upload_time_iso_8601": "2019-09-09T07:27:56.074783Z", "url": "https://files.pythonhosted.org/packages/ed/43/995d3a0af59daa78d178f9d5f6bd8c14a3e149d7ecc107726c5d2f29dc63/cntkx-0.1.21-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9fdb0610ec53c8b2c856751dd69cb406", "sha256": "ad668b2a438088a09cfbb3217922047357525a317910074bec33d6e53e2749da"}, "downloads": -1, "filename": "cntkx-0.1.21.tar.gz", "has_sig": false, "md5_digest": "9fdb0610ec53c8b2c856751dd69cb406", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 91012, "upload_time": "2019-09-09T07:28:02", "upload_time_iso_8601": "2019-09-09T07:28:02.343314Z", "url": "https://files.pythonhosted.org/packages/53/55/22c1d0b4c7f589343a7826b9af94ed46b22761f077d011b84b245efa2651/cntkx-0.1.21.tar.gz", "yanked": false}], "0.1.22": [{"comment_text": "", "digests": {"md5": "df95d8bfdeb6c0122fa52b340ec2a112", "sha256": "b99abfc33295a28aaa323116adc505e6f639116a4faa00ab220268e81384ead3"}, "downloads": -1, "filename": "cntkx-0.1.22-py3-none-any.whl", "has_sig": false, "md5_digest": "df95d8bfdeb6c0122fa52b340ec2a112", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 85858, "upload_time": "2019-09-30T04:28:40", "upload_time_iso_8601": "2019-09-30T04:28:40.426778Z", "url": "https://files.pythonhosted.org/packages/22/d4/bd83ab5946eeee1fa2ced236ba003a7a37b4f4923f8dc2b096546d7ad77e/cntkx-0.1.22-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3a1c4f61576630a2efb5f8151f30cd56", "sha256": "5356fdfe6bf33d65c083ac08afbbea3d00df6ec6721b6a38a1183d1b18654cee"}, "downloads": -1, "filename": "cntkx-0.1.22.tar.gz", "has_sig": false, "md5_digest": "3a1c4f61576630a2efb5f8151f30cd56", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 91444, "upload_time": "2019-09-30T04:28:45", "upload_time_iso_8601": "2019-09-30T04:28:45.013928Z", "url": "https://files.pythonhosted.org/packages/2c/e7/587a0d8369dfa458ece81eb59758dfb80f96ec5e2a3a17f5b686056c3bbb/cntkx-0.1.22.tar.gz", "yanked": false}], "0.1.23": [{"comment_text": "", "digests": {"md5": "3f3456cbacdc3caa6b18be31d3b9e96c", "sha256": "2824f097d1c917a3cc686d46d6f6d8d373499260f3e136fa5a0aac736329e524"}, "downloads": -1, "filename": "cntkx-0.1.23-py3-none-any.whl", "has_sig": false, "md5_digest": "3f3456cbacdc3caa6b18be31d3b9e96c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 89424, "upload_time": "2019-10-15T12:59:09", "upload_time_iso_8601": "2019-10-15T12:59:09.742783Z", "url": "https://files.pythonhosted.org/packages/a8/dc/e47d1bbd5c157c75a5ab457de8720154b3941afbb67109915bec0d646e1b/cntkx-0.1.23-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "793a4ac505756b3faabef4545cf08110", "sha256": "c455ca286cc4b50592d8872ab761c073a2a5d23c49d0f14ee992b6285ae6863e"}, "downloads": -1, "filename": "cntkx-0.1.23.tar.gz", "has_sig": false, "md5_digest": "793a4ac505756b3faabef4545cf08110", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 94565, "upload_time": "2019-10-15T12:59:13", "upload_time_iso_8601": "2019-10-15T12:59:13.074907Z", "url": "https://files.pythonhosted.org/packages/4c/95/72c81c8122e5abdd484401dc9716c945a2af82a7296fb9f76821c19b968c/cntkx-0.1.23.tar.gz", "yanked": false}], "0.1.24": [{"comment_text": "", "digests": {"md5": "dbd4f8392add1cae0a3490ec40ee2f33", "sha256": "68cb7a6f5a1d90946494daa6f339bbe8aeecd4a13d7970eeafbc58953905233b"}, "downloads": -1, "filename": "cntkx-0.1.24-py3-none-any.whl", "has_sig": false, "md5_digest": "dbd4f8392add1cae0a3490ec40ee2f33", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 89999, "upload_time": "2019-11-04T07:02:41", "upload_time_iso_8601": "2019-11-04T07:02:41.984295Z", "url": "https://files.pythonhosted.org/packages/3c/46/f53532374354d8ffdb022300ca2e53ef6235ff3ed6cda2f5e08af744f8af/cntkx-0.1.24-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a5f9d64c0317d192afad22d906ee5410", "sha256": "c74883b7217fd0e732db02ff3baab84d8bdda7808ad7ee8dc9b8662aab4b90ed"}, "downloads": -1, "filename": "cntkx-0.1.24.tar.gz", "has_sig": false, "md5_digest": "a5f9d64c0317d192afad22d906ee5410", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 95445, "upload_time": "2019-11-04T07:02:46", "upload_time_iso_8601": "2019-11-04T07:02:46.002780Z", "url": "https://files.pythonhosted.org/packages/4b/ca/156f93d96069a6e3d86ffe704693d3dbeb0fef3ff93549cc21910b4194c7/cntkx-0.1.24.tar.gz", "yanked": false}], "0.1.25": [{"comment_text": "", "digests": {"md5": "e4acaf3b54326e6d53361b660e33e391", "sha256": "1aeb87e52ab58900a13c3e584a92e36a230b8f0191460d95ce7187f2a8b7cc58"}, "downloads": -1, "filename": "cntkx-0.1.25-py3-none-any.whl", "has_sig": false, "md5_digest": "e4acaf3b54326e6d53361b660e33e391", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 90488, "upload_time": "2019-11-04T08:26:36", "upload_time_iso_8601": "2019-11-04T08:26:36.336247Z", "url": "https://files.pythonhosted.org/packages/2d/5a/31e771ee30552e5c7969f3fcaa5b6327e042eeb3ef43e657edee7927f296/cntkx-0.1.25-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3c279d448e4d96f05b742f8e4a252957", "sha256": "b366043478f15bb03700ca2786b5394ae143ab855d7b253c61bb38bd1e61455a"}, "downloads": -1, "filename": "cntkx-0.1.25.tar.gz", "has_sig": false, "md5_digest": "3c279d448e4d96f05b742f8e4a252957", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 96286, "upload_time": "2019-11-04T08:26:41", "upload_time_iso_8601": "2019-11-04T08:26:41.752956Z", "url": "https://files.pythonhosted.org/packages/9b/59/17d36f8924d05b77daf79f469f43b2bab1fc9c67dfa1e14dbb3d4508d0d2/cntkx-0.1.25.tar.gz", "yanked": false}], "0.1.26": [{"comment_text": "", "digests": {"md5": "bbc1809b7a47eb778145d43095aaa667", "sha256": "c9c842550227e879d708bf6840d63b588f09d3e4831a4dcd95eb1fa073b64388"}, "downloads": -1, "filename": "cntkx-0.1.26-py3-none-any.whl", "has_sig": false, "md5_digest": "bbc1809b7a47eb778145d43095aaa667", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 90560, "upload_time": "2019-11-05T06:21:26", "upload_time_iso_8601": "2019-11-05T06:21:26.650782Z", "url": "https://files.pythonhosted.org/packages/81/8d/dfe51762825c65b0020f3ab354c95a1764e0a0946c8956198d8a5ea4541f/cntkx-0.1.26-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f0177b819e87c60859052f4381ac86d4", "sha256": "0a13c38757a3dd04b58f2b7977d7267adecbd651487325bd8091f29f7c93410d"}, "downloads": -1, "filename": "cntkx-0.1.26.tar.gz", "has_sig": false, "md5_digest": "f0177b819e87c60859052f4381ac86d4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 96462, "upload_time": "2019-11-05T06:21:32", "upload_time_iso_8601": "2019-11-05T06:21:32.301316Z", "url": "https://files.pythonhosted.org/packages/5d/c3/15c3e502a599d21eb098baf3d30e8708d62af089b18657265ab5f22e69f6/cntkx-0.1.26.tar.gz", "yanked": false}], "0.1.27": [{"comment_text": "", "digests": {"md5": "237995444af6651967a3d8787a8cce75", "sha256": "b0b938d54d402bfaad4b3a330a6e3c60004a93f70bffa6baafcdcf28a104dc6d"}, "downloads": -1, "filename": "cntkx-0.1.27-py3-none-any.whl", "has_sig": false, "md5_digest": "237995444af6651967a3d8787a8cce75", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 90567, "upload_time": "2019-11-05T09:30:30", "upload_time_iso_8601": "2019-11-05T09:30:30.537441Z", "url": "https://files.pythonhosted.org/packages/6c/7b/8a13a393d031f6110538f787b38551315162052d25ea83ef6390c3643d1b/cntkx-0.1.27-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cfcb98d37247cb8ba1aeed38fd4c328f", "sha256": "037283da8b25c226996c9c1b82485ef500bb1b2060ead04d9ffb4980a48acad9"}, "downloads": -1, "filename": "cntkx-0.1.27.tar.gz", "has_sig": false, "md5_digest": "cfcb98d37247cb8ba1aeed38fd4c328f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 96476, "upload_time": "2019-11-05T09:30:38", "upload_time_iso_8601": "2019-11-05T09:30:38.132166Z", "url": "https://files.pythonhosted.org/packages/d2/e0/4cab0a1d7188a2b0798332d4ae7d332bad146c12c3f83a77caac37fad6e4/cntkx-0.1.27.tar.gz", "yanked": false}], "0.1.28": [{"comment_text": "", "digests": {"md5": "1ba4c98a111fad566e0dd0d2dfdbe8f3", "sha256": "db59de97975de0dd6308aa5fc774dd515be969e28ffefc0990aa11cc297d285b"}, "downloads": -1, "filename": "cntkx-0.1.28-py3-none-any.whl", "has_sig": false, "md5_digest": "1ba4c98a111fad566e0dd0d2dfdbe8f3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 92044, "upload_time": "2019-11-24T11:33:05", "upload_time_iso_8601": "2019-11-24T11:33:05.727651Z", "url": "https://files.pythonhosted.org/packages/39/a4/ed3cb83c70f55ca9c39cf5d4426a83c7e267ff6d439cfcd70c451b667676/cntkx-0.1.28-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "122be606e6d204f1156d153c4c7664d7", "sha256": "146346bcaf5c26166e1fde67d9846cc7c4ccd76e9c59439a1851fbe6ba180d44"}, "downloads": -1, "filename": "cntkx-0.1.28.tar.gz", "has_sig": false, "md5_digest": "122be606e6d204f1156d153c4c7664d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 98263, "upload_time": "2019-11-24T11:33:14", "upload_time_iso_8601": "2019-11-24T11:33:14.069402Z", "url": "https://files.pythonhosted.org/packages/e4/37/17e36cc6b64895f1d1dcb0b76bede95e6c8c0c11d74ac8faa0ac99498ec1/cntkx-0.1.28.tar.gz", "yanked": false}], "0.1.29": [{"comment_text": "", "digests": {"md5": "5a653ff81ce70228bd83830155871312", "sha256": "c74adc5edde673760959140e4330e38452a39228f4998e2d0d4461f0c3b1292f"}, "downloads": -1, "filename": "cntkx-0.1.29-py3-none-any.whl", "has_sig": false, "md5_digest": "5a653ff81ce70228bd83830155871312", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 93408, "upload_time": "2019-12-03T13:21:51", "upload_time_iso_8601": "2019-12-03T13:21:51.105367Z", "url": "https://files.pythonhosted.org/packages/d2/b2/d6e5599d4713eb00d99ad961bbb66187ee29d0cb2bd57677765c126b4718/cntkx-0.1.29-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b5b05c59ed9da6880e2b7debcbc0f178", "sha256": "d6c65230d66b3ebc3715cb85424d526cbfceed5d5bced27d6d410c867320561d"}, "downloads": -1, "filename": "cntkx-0.1.29.tar.gz", "has_sig": false, "md5_digest": "b5b05c59ed9da6880e2b7debcbc0f178", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 100569, "upload_time": "2019-12-03T13:22:00", "upload_time_iso_8601": "2019-12-03T13:22:00.922480Z", "url": "https://files.pythonhosted.org/packages/a0/53/656513e3e2b3f25aeb49b558f84e7782c94a3094b1a8950e5609776a606d/cntkx-0.1.29.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "fc594ff099128b7c4eb2600c32224c04", "sha256": "a26175fd09a8ce0d55113c51b328bcb5b1fd90e53ba446c4ab0f168f8a54e141"}, "downloads": -1, "filename": "cntkx-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "fc594ff099128b7c4eb2600c32224c04", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 68464, "upload_time": "2019-04-10T06:38:17", "upload_time_iso_8601": "2019-04-10T06:38:17.237703Z", "url": "https://files.pythonhosted.org/packages/35/90/17cb965592c3909aff79aefc3ceaeeb1775ef5de66037b373f9f2ce285aa/cntkx-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5ad41e547bca4d41cb49085dd66d118d", "sha256": "58c2082dca196f84e2e24979cafecb3e5f867172e08000bafdf9188139730ec8"}, "downloads": -1, "filename": "cntkx-0.1.3.tar.gz", "has_sig": false, "md5_digest": "5ad41e547bca4d41cb49085dd66d118d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 58083, "upload_time": "2019-04-10T06:38:22", "upload_time_iso_8601": "2019-04-10T06:38:22.817616Z", "url": "https://files.pythonhosted.org/packages/f1/94/c31f3ab2194eba0f118a70fc7720a5a7fb9f389db21e7b1b7e2737646825/cntkx-0.1.3.tar.gz", "yanked": false}], "0.1.30": [{"comment_text": "", "digests": {"md5": "254e05e15f420c060931319521bd845a", "sha256": "dfbc05ef25cb979eb8967cfa365175a240e8b11b0753f003bfe3eb3cf2f965b2"}, "downloads": -1, "filename": "cntkx-0.1.30-py3-none-any.whl", "has_sig": false, "md5_digest": "254e05e15f420c060931319521bd845a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 94036, "upload_time": "2020-02-11T12:52:25", "upload_time_iso_8601": "2020-02-11T12:52:25.752349Z", "url": "https://files.pythonhosted.org/packages/72/22/571c9bbbb3793916fef2d7a9cd5b975b63d01a2b9d9fa88bd45cf67fd2a9/cntkx-0.1.30-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d22f99198c1900f8022085fcd606431b", "sha256": "8b9a533b5b81d3483bdad16f30fdfc32643503faa87bb208e4a544a7b49847a3"}, "downloads": -1, "filename": "cntkx-0.1.30.tar.gz", "has_sig": false, "md5_digest": "d22f99198c1900f8022085fcd606431b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 101664, "upload_time": "2020-02-11T12:52:36", "upload_time_iso_8601": "2020-02-11T12:52:36.431198Z", "url": "https://files.pythonhosted.org/packages/d1/c6/6c465a3535c1a8a525b01646e68c3d7432445b5bc0d1b860670f5ecdfa7f/cntkx-0.1.30.tar.gz", "yanked": false}], "0.1.31": [{"comment_text": "", "digests": {"md5": "db108fa4ac62b462dc4534c253ddadb0", "sha256": "40a94f0a57bac06cd3e602808c39c079f76a6948a02ae4211426a50082cc6cee"}, "downloads": -1, "filename": "cntkx-0.1.31-py3-none-any.whl", "has_sig": false, "md5_digest": "db108fa4ac62b462dc4534c253ddadb0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 94030, "upload_time": "2020-02-11T15:11:13", "upload_time_iso_8601": "2020-02-11T15:11:13.195981Z", "url": "https://files.pythonhosted.org/packages/ec/1c/a21567096cec365284676cdf5a83d064fe0e81b68ec248619e9cd1e050aa/cntkx-0.1.31-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "632db20f7126fa4287b7285055cfcc3f", "sha256": "3484d633e072f66915a0d6c8120bf3e574b22183e5249b3356762799ccdd1c4f"}, "downloads": -1, "filename": "cntkx-0.1.31.tar.gz", "has_sig": false, "md5_digest": "632db20f7126fa4287b7285055cfcc3f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 101659, "upload_time": "2020-02-11T15:11:24", "upload_time_iso_8601": "2020-02-11T15:11:24.970079Z", "url": "https://files.pythonhosted.org/packages/b0/96/f3c5a59dd0a67d1dc025c7c2b860f49e34e9de86c5f72fad1a3f5b966ab6/cntkx-0.1.31.tar.gz", "yanked": false}], "0.1.32": [{"comment_text": "", "digests": {"md5": "130ef08318bec153a0ebf2304d6e0552", "sha256": "11fec0e5fef9f836f18cd3e97e9a7703d5f9fbb2ca9dbab0d1d8797727a3420a"}, "downloads": -1, "filename": "cntkx-0.1.32-py3-none-any.whl", "has_sig": false, "md5_digest": "130ef08318bec153a0ebf2304d6e0552", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 96260, "upload_time": "2020-03-29T11:23:53", "upload_time_iso_8601": "2020-03-29T11:23:53.554784Z", "url": "https://files.pythonhosted.org/packages/b9/72/ce85432a54c6c731a18cd83db84476e710a91de21edd39c48072450c426c/cntkx-0.1.32-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1dcaf628c620e1974f8b91868acca51c", "sha256": "b0736d02f476f3ba6228aff7fc408174d655e0b3299fe603a53744e6105d1ef9"}, "downloads": -1, "filename": "cntkx-0.1.32.tar.gz", "has_sig": false, "md5_digest": "1dcaf628c620e1974f8b91868acca51c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 104538, "upload_time": "2020-03-29T11:24:05", "upload_time_iso_8601": "2020-03-29T11:24:05.329587Z", "url": "https://files.pythonhosted.org/packages/00/7a/9b1539882c845b30b6082a517558bae605517bdcc114a989ff39bd026744/cntkx-0.1.32.tar.gz", "yanked": false}], "0.1.33": [{"comment_text": "", "digests": {"md5": "d631cbf0681b055414f224fb05f31796", "sha256": "dd9b4b5e7200875922360b1df6d90e43caba8762a680c22ffcce6f3ee4cb96fa"}, "downloads": -1, "filename": "cntkx-0.1.33-py3-none-any.whl", "has_sig": false, "md5_digest": "d631cbf0681b055414f224fb05f31796", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 96384, "upload_time": "2020-04-02T07:38:21", "upload_time_iso_8601": "2020-04-02T07:38:21.428305Z", "url": "https://files.pythonhosted.org/packages/37/a4/8fac902547471180988ca3b1faa49dff098a771620b8f225f156a70bfe09/cntkx-0.1.33-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "390bddfc50a8eae4351d4ed76b0c654b", "sha256": "d3ebb80b560e0a9b2f3ca5bb14f2ebc3507574e763116f714b72a2470074edcb"}, "downloads": -1, "filename": "cntkx-0.1.33.tar.gz", "has_sig": false, "md5_digest": "390bddfc50a8eae4351d4ed76b0c654b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 104663, "upload_time": "2020-04-02T07:38:36", "upload_time_iso_8601": "2020-04-02T07:38:36.933856Z", "url": "https://files.pythonhosted.org/packages/68/a2/5c1cd4aa5a9fc8409e5637637c6fb0fac47a258fc0258ad8a05cd4faba07/cntkx-0.1.33.tar.gz", "yanked": false}], "0.1.34": [{"comment_text": "", "digests": {"md5": "146dbabbb79d27ae640a58e198eccad3", "sha256": "7e96e90e1a7eb054102d5ca1fc5f6f53f127f4b000edd9905c463814bf1bdcea"}, "downloads": -1, "filename": "cntkx-0.1.34-py3-none-any.whl", "has_sig": false, "md5_digest": "146dbabbb79d27ae640a58e198eccad3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 97265, "upload_time": "2020-04-11T07:04:38", "upload_time_iso_8601": "2020-04-11T07:04:38.545229Z", "url": "https://files.pythonhosted.org/packages/f9/84/002d88362b129f429b90363cdc256e2b7d9a0ae2267e298d7a421fa83739/cntkx-0.1.34-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "573d69201b7bac0418e60b3c23b90c2e", "sha256": "6f9dae52423a520f69e14e1fe38a885f986741fd119e570658fa1a91f7ed4f0e"}, "downloads": -1, "filename": "cntkx-0.1.34.tar.gz", "has_sig": false, "md5_digest": "573d69201b7bac0418e60b3c23b90c2e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 105563, "upload_time": "2020-04-11T07:04:52", "upload_time_iso_8601": "2020-04-11T07:04:52.370607Z", "url": "https://files.pythonhosted.org/packages/82/d0/cf157e74e98e05e003ecf9e72fa77fafaba0455210d30d34b15915b4086c/cntkx-0.1.34.tar.gz", "yanked": false}], "0.1.35": [{"comment_text": "", "digests": {"md5": "dd3c6c8e1fc8f0859d9f6fab1ff8ee85", "sha256": "d2cb94c01a14e3f5958e997a6d819b36d2bfec215ba9d96b1a144f8c2d02365c"}, "downloads": -1, "filename": "cntkx-0.1.35-py3-none-any.whl", "has_sig": false, "md5_digest": "dd3c6c8e1fc8f0859d9f6fab1ff8ee85", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 97452, "upload_time": "2020-04-14T06:50:33", "upload_time_iso_8601": "2020-04-14T06:50:33.662878Z", "url": "https://files.pythonhosted.org/packages/96/ef/5d40974846127806620912f7af3145945e4c8ff731a7fe31b95da392474e/cntkx-0.1.35-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "557490ee2e24e9cb9885c9523d639a42", "sha256": "3b97aca911f0daf1b0f87b04f718e293e362dfd45b36c955cf489d45891aa88c"}, "downloads": -1, "filename": "cntkx-0.1.35.tar.gz", "has_sig": false, "md5_digest": "557490ee2e24e9cb9885c9523d639a42", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 105743, "upload_time": "2020-04-14T06:51:48", "upload_time_iso_8601": "2020-04-14T06:51:48.495681Z", "url": "https://files.pythonhosted.org/packages/45/d5/7fcaa09d022aa56e4b168f2599ce60056c7ebad82b653340fbb6951838d5/cntkx-0.1.35.tar.gz", "yanked": false}], "0.1.36": [{"comment_text": "", "digests": {"md5": "95f683bb2606e17db2f85cf556a50456", "sha256": "7d2eca117458dededbc3a99f5f666a76ebb3aa713f3300db9f74fa564f1012b4"}, "downloads": -1, "filename": "cntkx-0.1.36-py3-none-any.whl", "has_sig": false, "md5_digest": "95f683bb2606e17db2f85cf556a50456", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 97516, "upload_time": "2020-04-14T12:03:48", "upload_time_iso_8601": "2020-04-14T12:03:48.969309Z", "url": "https://files.pythonhosted.org/packages/4a/86/a8a8648a2d3e2260ece2b6ec7013ecb5e99ae4baae72889578c589626c37/cntkx-0.1.36-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "caf36713a2665b8672ffb1a41d79cda1", "sha256": "dba6bae271801fd34437f292b0499f097eac49c9c8b2c217f045b54a89320c3b"}, "downloads": -1, "filename": "cntkx-0.1.36.tar.gz", "has_sig": false, "md5_digest": "caf36713a2665b8672ffb1a41d79cda1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 105787, "upload_time": "2020-04-14T12:04:03", "upload_time_iso_8601": "2020-04-14T12:04:03.327714Z", "url": "https://files.pythonhosted.org/packages/83/60/72017115362e1bb4708c3482f901f5749058201bb6c9689f4759eaba06e8/cntkx-0.1.36.tar.gz", "yanked": false}], "0.1.37": [{"comment_text": "", "digests": {"md5": "ccadaeb1576c1b7ef2b6ce9060531007", "sha256": "90ccb936e267b96fd73ad62f4f03ffc8cb199640886c9b08ee0b48b6fe0856c7"}, "downloads": -1, "filename": "cntkx-0.1.37-py3-none-any.whl", "has_sig": false, "md5_digest": "ccadaeb1576c1b7ef2b6ce9060531007", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 97530, "upload_time": "2020-04-14T12:11:21", "upload_time_iso_8601": "2020-04-14T12:11:21.756376Z", "url": "https://files.pythonhosted.org/packages/fe/c5/68932e48cdd8a75826579972fd40a00c2e64ec478a6d39798933194dc450/cntkx-0.1.37-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b5b6bfb72e96cb0885549565387cd5fc", "sha256": "01700128b0ab10b632eeeeaf48e0eadd8e00514420fda701d7aee1b7444c7caf"}, "downloads": -1, "filename": "cntkx-0.1.37.tar.gz", "has_sig": false, "md5_digest": "b5b6bfb72e96cb0885549565387cd5fc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 105817, "upload_time": "2020-04-14T12:11:36", "upload_time_iso_8601": "2020-04-14T12:11:36.575183Z", "url": "https://files.pythonhosted.org/packages/9e/7d/483141e56df9e9441ce5c7d82168cfd0ad83b9e4f8c0e441048cbe6f5dda/cntkx-0.1.37.tar.gz", "yanked": false}], "0.1.38": [{"comment_text": "", "digests": {"md5": "3ce1d55b4347b79fd1c0fe9314c5e9a1", "sha256": "11ed8131fe89e98e1d4d6302f9170088e704ac0197294b0d2f873dcf497dc6a3"}, "downloads": -1, "filename": "cntkx-0.1.38-py3-none-any.whl", "has_sig": false, "md5_digest": "3ce1d55b4347b79fd1c0fe9314c5e9a1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 99118, "upload_time": "2020-04-15T13:28:22", "upload_time_iso_8601": "2020-04-15T13:28:22.347174Z", "url": "https://files.pythonhosted.org/packages/d8/94/dbda51a49b3d4e66cf1c683848368e4106b23ac7cafa96cfc3b759c0224e/cntkx-0.1.38-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "be24561ed93b169ac1cf46021adbd2fb", "sha256": "c310461c7736240e257f8f38588403acce8245bbb05c5dddb474d6d65dddb89f"}, "downloads": -1, "filename": "cntkx-0.1.38.tar.gz", "has_sig": false, "md5_digest": "be24561ed93b169ac1cf46021adbd2fb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 108104, "upload_time": "2020-04-15T13:28:38", "upload_time_iso_8601": "2020-04-15T13:28:38.305416Z", "url": "https://files.pythonhosted.org/packages/4d/8d/b6ccdb0976b74ec8744f75e06af63dd3e8d42f87d23002a4b1326dd6b04c/cntkx-0.1.38.tar.gz", "yanked": false}], "0.1.39": [{"comment_text": "", "digests": {"md5": "ab594bae9db91786bb2c61f51f85585a", "sha256": "be11c1db00a77811070bab94e75aadd1ec5936c2ed25f037efc98a3d74f03f20"}, "downloads": -1, "filename": "cntkx-0.1.39-py3-none-any.whl", "has_sig": false, "md5_digest": "ab594bae9db91786bb2c61f51f85585a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 99150, "upload_time": "2020-04-16T06:09:27", "upload_time_iso_8601": "2020-04-16T06:09:27.931319Z", "url": "https://files.pythonhosted.org/packages/85/52/dd1828071d0d3de9e4fe99e4ed4bd7830d6777c6a214059d87a4fc8efdfe/cntkx-0.1.39-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "14d1bc5b057b4e973ea0d6e40c4a3bfc", "sha256": "f8d3d34d0351d5c74f6cd8cd054e11ee59420d7d448c10349569949d15ce3a75"}, "downloads": -1, "filename": "cntkx-0.1.39.tar.gz", "has_sig": false, "md5_digest": "14d1bc5b057b4e973ea0d6e40c4a3bfc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 108162, "upload_time": "2020-04-16T06:09:47", "upload_time_iso_8601": "2020-04-16T06:09:47.523999Z", "url": "https://files.pythonhosted.org/packages/4b/f1/51f42d559b8b95020a60db89d87f8e705e2e51c80c6470a3d9c903527247/cntkx-0.1.39.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "9dd2a0ce69cc193f7f3f1b242928d099", "sha256": "6ea0c0dd18c83aab5b06101d5be957d305701e17d664fd1c460cf394c16369cc"}, "downloads": -1, "filename": "cntkx-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "9dd2a0ce69cc193f7f3f1b242928d099", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 68934, "upload_time": "2019-04-10T07:29:24", "upload_time_iso_8601": "2019-04-10T07:29:24.459597Z", "url": "https://files.pythonhosted.org/packages/57/1d/6f882629c9aeb8da185187e9b9b455c0e9ce45b4c5e41610b780f83e6a47/cntkx-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "505a4712ba7acd387e6918d87007f4e2", "sha256": "b0123846b9a273ddec5dc69fcd62e6d6481b3fb4bbc59bdf50cd9d9473232577"}, "downloads": -1, "filename": "cntkx-0.1.4.tar.gz", "has_sig": false, "md5_digest": "505a4712ba7acd387e6918d87007f4e2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 58440, "upload_time": "2019-04-10T07:29:31", "upload_time_iso_8601": "2019-04-10T07:29:31.347504Z", "url": "https://files.pythonhosted.org/packages/c3/d7/c8954d99fb8bfe2359fc4d2c03f09c95641bd7251e1d7b53fde281785b5c/cntkx-0.1.4.tar.gz", "yanked": false}], "0.1.40": [{"comment_text": "", "digests": {"md5": "14ab165194d951d4aa7701a3c7079864", "sha256": "c1e1e7008c3e3133bfc649095424182f8bc9e0a91949b702f29d2354b5212358"}, "downloads": -1, "filename": "cntkx-0.1.40-py3-none-any.whl", "has_sig": false, "md5_digest": "14ab165194d951d4aa7701a3c7079864", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 99381, "upload_time": "2020-04-16T12:20:28", "upload_time_iso_8601": "2020-04-16T12:20:28.031315Z", "url": "https://files.pythonhosted.org/packages/81/a9/daa7a20a70b41e8206a786a809b1416620849576288f8b24e5d06e7cc888/cntkx-0.1.40-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0f965ded113ae1643601a28b316f09ef", "sha256": "407ebc06e485587cac793c28f214d7ba8a82e0d563dbc7ec6416c1bb12476262"}, "downloads": -1, "filename": "cntkx-0.1.40.tar.gz", "has_sig": false, "md5_digest": "0f965ded113ae1643601a28b316f09ef", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 108434, "upload_time": "2020-04-16T12:20:47", "upload_time_iso_8601": "2020-04-16T12:20:47.361254Z", "url": "https://files.pythonhosted.org/packages/18/34/ab798779feaa378d4c19db1ad71b90278980f6459db19db1af4aa139a3f1/cntkx-0.1.40.tar.gz", "yanked": false}], "0.1.41": [{"comment_text": "", "digests": {"md5": "24a8b108333c14587b9f42777b72cb17", "sha256": "16cdd12e38caed8bb72a46fc177419aeaa78de035489e01fca09517bb3c16081"}, "downloads": -1, "filename": "cntkx-0.1.41-py3-none-any.whl", "has_sig": false, "md5_digest": "24a8b108333c14587b9f42777b72cb17", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 99428, "upload_time": "2020-04-18T04:56:11", "upload_time_iso_8601": "2020-04-18T04:56:11.816145Z", "url": "https://files.pythonhosted.org/packages/9c/55/63433ff0c872eb7c9e779668d5085695cbd8437d5bde49288d9a0db4c7a4/cntkx-0.1.41-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1f02a810309278d7a46081316d43bb37", "sha256": "43413f3c91a2c37a277418374638233f191a052f53c0a1db1579f0eaaf9f959a"}, "downloads": -1, "filename": "cntkx-0.1.41.tar.gz", "has_sig": false, "md5_digest": "1f02a810309278d7a46081316d43bb37", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 108481, "upload_time": "2020-04-18T04:56:32", "upload_time_iso_8601": "2020-04-18T04:56:32.130002Z", "url": "https://files.pythonhosted.org/packages/c8/c7/eb8b82df682b0c239e7772e83771da45691ade6552fe454ad16c12c974db/cntkx-0.1.41.tar.gz", "yanked": false}], "0.1.42": [{"comment_text": "", "digests": {"md5": "2feee404e7f3be500268ffea3166180a", "sha256": "21ed1e5ea74e79cb4b42c0c24a34d1df387cc16154afc9f02b944a46cba813e1"}, "downloads": -1, "filename": "cntkx-0.1.42-py3-none-any.whl", "has_sig": false, "md5_digest": "2feee404e7f3be500268ffea3166180a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 100141, "upload_time": "2020-04-19T13:18:47", "upload_time_iso_8601": "2020-04-19T13:18:47.186959Z", "url": "https://files.pythonhosted.org/packages/3c/42/09feeae32e2822d859c9ab474cec807d375a118c836eaf1bcd25f7656725/cntkx-0.1.42-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ae05069c24de0577f05b0a3f247f4ee", "sha256": "023a1e519c505c00ea6ca4642faf08504caa6ed406254f0607bdc4cc01142ac5"}, "downloads": -1, "filename": "cntkx-0.1.42.tar.gz", "has_sig": false, "md5_digest": "3ae05069c24de0577f05b0a3f247f4ee", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 110302, "upload_time": "2020-04-19T13:19:09", "upload_time_iso_8601": "2020-04-19T13:19:09.073937Z", "url": "https://files.pythonhosted.org/packages/01/e7/3bbe0eacbf2e53ca923c94bda112a733ca94e89c68057feca70aaffe6388/cntkx-0.1.42.tar.gz", "yanked": false}], "0.1.43": [{"comment_text": "", "digests": {"md5": "fdbbaa8f03cd0adf2dfce9c75c486772", "sha256": "b03bf1e23145ebd137e4c74ca4f4115a819c7627b82325532f08e5a14b6d2ddd"}, "downloads": -1, "filename": "cntkx-0.1.43-py3-none-any.whl", "has_sig": false, "md5_digest": "fdbbaa8f03cd0adf2dfce9c75c486772", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 100145, "upload_time": "2020-04-20T13:47:17", "upload_time_iso_8601": "2020-04-20T13:47:17.499727Z", "url": "https://files.pythonhosted.org/packages/95/dc/3e60329dc543822d45f650d3980de3a13fa2a8925beab3b00f41daf06d4d/cntkx-0.1.43-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "56970a44d797c8541f608b075096d7ad", "sha256": "c305d5eaa5014f8051b65388f1bd8b6c63c1f33370c9ed53e0069342aae42c50"}, "downloads": -1, "filename": "cntkx-0.1.43.tar.gz", "has_sig": false, "md5_digest": "56970a44d797c8541f608b075096d7ad", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 109162, "upload_time": "2020-04-20T13:47:46", "upload_time_iso_8601": "2020-04-20T13:47:46.757271Z", "url": "https://files.pythonhosted.org/packages/8f/46/b24d297b5c0bf82b993cbc24de2e8c5c597fe5d6f5480d79e2e4d51465da/cntkx-0.1.43.tar.gz", "yanked": false}], "0.1.44": [{"comment_text": "", "digests": {"md5": "12b9a9bae6a7dd0ed93a0f1a2a7c76a2", "sha256": "79addbe21b2f5f5587e1286a3cd2ce6f8fe40165a8d187929be1f7ce92ab41fe"}, "downloads": -1, "filename": "cntkx-0.1.44-py3-none-any.whl", "has_sig": false, "md5_digest": "12b9a9bae6a7dd0ed93a0f1a2a7c76a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 100440, "upload_time": "2020-04-20T15:20:06", "upload_time_iso_8601": "2020-04-20T15:20:06.050309Z", "url": "https://files.pythonhosted.org/packages/24/b7/dfd71e5605e29ff93c0f4a83336e166d8421c4d8ed47729446bd34f86c6e/cntkx-0.1.44-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "80267e32a92c644d7eab2dc49dde0ca5", "sha256": "95b060ffd50c80d7e45915df124f51a1123d43a2fb0bea91476ffc9c6c008b4f"}, "downloads": -1, "filename": "cntkx-0.1.44.tar.gz", "has_sig": false, "md5_digest": "80267e32a92c644d7eab2dc49dde0ca5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 109478, "upload_time": "2020-04-20T15:20:29", "upload_time_iso_8601": "2020-04-20T15:20:29.350070Z", "url": "https://files.pythonhosted.org/packages/af/c0/a4812a1a0e4fee9fb3121a731df146927a9bef43714804091b9bc5b66688/cntkx-0.1.44.tar.gz", "yanked": false}], "0.1.45": [{"comment_text": "", "digests": {"md5": "898f95e2bfa9d179bc94d038bac75737", "sha256": "8f869cfd424fe19f90b634b37ab1c849c5607b6c67a5a659466dbb6a51240314"}, "downloads": -1, "filename": "cntkx-0.1.45-py3-none-any.whl", "has_sig": false, "md5_digest": "898f95e2bfa9d179bc94d038bac75737", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 100460, "upload_time": "2020-04-21T05:19:36", "upload_time_iso_8601": "2020-04-21T05:19:36.748461Z", "url": "https://files.pythonhosted.org/packages/13/a7/0f95852e48aaf4b1546d60578babdab3498a5b59e73f69980297c9050b55/cntkx-0.1.45-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "86934b327a0839e3a769f263dcc40fd2", "sha256": "ce434f51fb5771640ab21971c487ab2cc88f49cfef87a69f15c72a1e7577a2a2"}, "downloads": -1, "filename": "cntkx-0.1.45.tar.gz", "has_sig": false, "md5_digest": "86934b327a0839e3a769f263dcc40fd2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 109492, "upload_time": "2020-04-21T05:20:00", "upload_time_iso_8601": "2020-04-21T05:20:00.189753Z", "url": "https://files.pythonhosted.org/packages/eb/8a/d42d216a8d06b27c538dacb62b3e3e7395959488166b409fef5806309628/cntkx-0.1.45.tar.gz", "yanked": false}], "0.1.46": [{"comment_text": "", "digests": {"md5": "4e3f514b7a0a0fb175a9ae818e818a7b", "sha256": "d6f86880b46ecc04f4dded5a17d84a3e5fe2cd50840bdb0e0249af082c69d1b3"}, "downloads": -1, "filename": "cntkx-0.1.46-py3-none-any.whl", "has_sig": false, "md5_digest": "4e3f514b7a0a0fb175a9ae818e818a7b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 100461, "upload_time": "2020-04-22T06:10:17", "upload_time_iso_8601": "2020-04-22T06:10:17.760133Z", "url": "https://files.pythonhosted.org/packages/67/9d/9045ded711921ca870f8a09b64793b999b67f2da11c33ecd8d449a859f2d/cntkx-0.1.46-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ef4358f7a4a0a0b7509e57a944d075ec", "sha256": "a647349f11638da9bd30d081ea5df918fda46913f50950bb12cf95e2d42f6e3d"}, "downloads": -1, "filename": "cntkx-0.1.46.tar.gz", "has_sig": false, "md5_digest": "ef4358f7a4a0a0b7509e57a944d075ec", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 109497, "upload_time": "2020-04-22T06:10:45", "upload_time_iso_8601": "2020-04-22T06:10:45.512827Z", "url": "https://files.pythonhosted.org/packages/21/eb/d18ec38d46599edd72c809a7c067115ec007e6f59d2dc398996994bbbbf5/cntkx-0.1.46.tar.gz", "yanked": false}], "0.1.47": [{"comment_text": "", "digests": {"md5": "d08e97d7c538bc2e9d181142c21aeb74", "sha256": "3ac1df682c919c1648010400fe24825d9710603fc126f299ee8da1974d47ab4c"}, "downloads": -1, "filename": "cntkx-0.1.47-py3-none-any.whl", "has_sig": false, "md5_digest": "d08e97d7c538bc2e9d181142c21aeb74", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 101239, "upload_time": "2020-05-01T05:42:14", "upload_time_iso_8601": "2020-05-01T05:42:14.696721Z", "url": "https://files.pythonhosted.org/packages/61/ff/85c3e3a4dfc7240b068c338e9caa30e2d84b9815b0bb737eaa47f8ff1d7e/cntkx-0.1.47-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9729b021391c0d5953a86b833f9a3c73", "sha256": "dbef9f20c39a710f37a89108ea208bfdf70253ab7ec2ab55077b89c604d82c2c"}, "downloads": -1, "filename": "cntkx-0.1.47.tar.gz", "has_sig": false, "md5_digest": "9729b021391c0d5953a86b833f9a3c73", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 110817, "upload_time": "2020-05-01T05:42:50", "upload_time_iso_8601": "2020-05-01T05:42:50.935534Z", "url": "https://files.pythonhosted.org/packages/db/65/745dec9c6e090e28b11e95568d4e84c985a43f23d342a9d99efc9d707850/cntkx-0.1.47.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "22d8d8f486960242cf4c6eee7101695e", "sha256": "999f785137e5d8ae478f8cca45474f2bfd375f6db6e44701b155529a71d905f5"}, "downloads": -1, "filename": "cntkx-0.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "22d8d8f486960242cf4c6eee7101695e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 70405, "upload_time": "2019-04-14T12:00:58", "upload_time_iso_8601": "2019-04-14T12:00:58.830729Z", "url": "https://files.pythonhosted.org/packages/bb/70/a548f55ecd3e985dfaf0d73f745e9a302b13d56d10b3cba3c744f024fe69/cntkx-0.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b14278e8893619536edf3b5bd255591f", "sha256": "f631ebe761683fd2d3ffd78710fc4afb2f560ea8edd044976128e7296fba0ca9"}, "downloads": -1, "filename": "cntkx-0.1.5.tar.gz", "has_sig": false, "md5_digest": "b14278e8893619536edf3b5bd255591f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 60614, "upload_time": "2019-04-14T12:01:06", "upload_time_iso_8601": "2019-04-14T12:01:06.911727Z", "url": "https://files.pythonhosted.org/packages/23/97/5d87db798d32705ea5c3d88f0cfa9e78ed574340d87e695332c3af787e00/cntkx-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "7a228ed199a5cab67c160399b6dd1c59", "sha256": "319b303693c27a335f8f0529d3a1d05a10cfc3cee983c3c323bf3c585c9a6997"}, "downloads": -1, "filename": "cntkx-0.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "7a228ed199a5cab67c160399b6dd1c59", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 72464, "upload_time": "2019-04-18T15:23:00", "upload_time_iso_8601": "2019-04-18T15:23:00.966335Z", "url": "https://files.pythonhosted.org/packages/7b/ea/87e9c76af575ba9072b75ecf8985f7350387dd41d578d8d5319e8e6ae755/cntkx-0.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "efd7cb11a5ffae094c4ccef5992aea79", "sha256": "2c060751da5f0b65b6137388539f7cd625a1a2f3bae7949039ebe8eb7b868c8c"}, "downloads": -1, "filename": "cntkx-0.1.6.tar.gz", "has_sig": false, "md5_digest": "efd7cb11a5ffae094c4ccef5992aea79", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 62530, "upload_time": "2019-04-18T15:23:09", "upload_time_iso_8601": "2019-04-18T15:23:09.106201Z", "url": "https://files.pythonhosted.org/packages/d1/28/400930bd638c213084282e6238523211899414071b0be4c595f71e6ea7c4/cntkx-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "51377dcc0f98df1b8c0f94ee7fc708b4", "sha256": "90e67a318cb61bf02a2b33a0fb06df71b32bd8170f934524e82df94b9a2ecb8e"}, "downloads": -1, "filename": "cntkx-0.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "51377dcc0f98df1b8c0f94ee7fc708b4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 73644, "upload_time": "2019-05-02T05:47:09", "upload_time_iso_8601": "2019-05-02T05:47:09.171653Z", "url": "https://files.pythonhosted.org/packages/f6/59/587b0151f964c429bc9af455cffd89de50c6fd292aac97d1d50734126777/cntkx-0.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "43d89b9280ac6e4342862952cbd7f132", "sha256": "a114a5fbd902c390a52dca1c9c6be8ab285dc59a76cd8645eeb7e803165934fa"}, "downloads": -1, "filename": "cntkx-0.1.7.tar.gz", "has_sig": false, "md5_digest": "43d89b9280ac6e4342862952cbd7f132", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 63415, "upload_time": "2019-05-02T05:47:17", "upload_time_iso_8601": "2019-05-02T05:47:17.604431Z", "url": "https://files.pythonhosted.org/packages/94/b2/b27ab195e15ebd14a07dba4c324b57761375f8bca96fe7ca51108f6cef65/cntkx-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "376b74fcfd34345036e206bf8ba9be50", "sha256": "7fb5bf4ac05981867f82b239547a66f97c6668d30abc57e1e0a33d5872bdbaa1"}, "downloads": -1, "filename": "cntkx-0.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "376b74fcfd34345036e206bf8ba9be50", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 75972, "upload_time": "2019-05-04T14:07:12", "upload_time_iso_8601": "2019-05-04T14:07:12.503061Z", "url": "https://files.pythonhosted.org/packages/eb/c2/6626e3a7de08177d5f90cd3e571ef9411a3c6c59d34d8fcf96a76dd986b4/cntkx-0.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "40e926da2f0f53e0148e518078ee55f2", "sha256": "0eca821a18cf92f2d17f871b584253bf4fc7a7441d433d148471ddd76b6b369c"}, "downloads": -1, "filename": "cntkx-0.1.8.tar.gz", "has_sig": false, "md5_digest": "40e926da2f0f53e0148e518078ee55f2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 73093, "upload_time": "2019-05-04T14:07:20", "upload_time_iso_8601": "2019-05-04T14:07:20.702390Z", "url": "https://files.pythonhosted.org/packages/ad/a2/0c69f65069a745eac0b1e7e6d8f14712594ef9ebe706f3ffe8aa4755078b/cntkx-0.1.8.tar.gz", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "bc0f8f1adbfb8f02dc6d66acb8ec16c0", "sha256": "9b21d9abdbf4a93f8a64e11d4599165483c220587145b8a0ba4427b182da0cc0"}, "downloads": -1, "filename": "cntkx-0.1.9-py3-none-any.whl", "has_sig": false, "md5_digest": "bc0f8f1adbfb8f02dc6d66acb8ec16c0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 76951, "upload_time": "2019-05-25T05:31:42", "upload_time_iso_8601": "2019-05-25T05:31:42.723762Z", "url": "https://files.pythonhosted.org/packages/11/25/e37c437dc4b05783bff38bca8e18d53c14d39b2ec6df9c56c95ccff58457/cntkx-0.1.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d555bea7cb14329c49f39eeb6811b4b9", "sha256": "49a9e06a59f4434fca73fabb902e17c25ff3d87e77d3eb29ce9eac78c802f1c2"}, "downloads": -1, "filename": "cntkx-0.1.9.tar.gz", "has_sig": false, "md5_digest": "d555bea7cb14329c49f39eeb6811b4b9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 73285, "upload_time": "2019-05-25T05:31:44", "upload_time_iso_8601": "2019-05-25T05:31:44.250338Z", "url": "https://files.pythonhosted.org/packages/61/6b/b77aa23b3a0ef3961baca6b4a6f4f97e54ff8531a156a9690eff801f5732/cntkx-0.1.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d08e97d7c538bc2e9d181142c21aeb74", "sha256": "3ac1df682c919c1648010400fe24825d9710603fc126f299ee8da1974d47ab4c"}, "downloads": -1, "filename": "cntkx-0.1.47-py3-none-any.whl", "has_sig": false, "md5_digest": "d08e97d7c538bc2e9d181142c21aeb74", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 101239, "upload_time": "2020-05-01T05:42:14", "upload_time_iso_8601": "2020-05-01T05:42:14.696721Z", "url": "https://files.pythonhosted.org/packages/61/ff/85c3e3a4dfc7240b068c338e9caa30e2d84b9815b0bb737eaa47f8ff1d7e/cntkx-0.1.47-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9729b021391c0d5953a86b833f9a3c73", "sha256": "dbef9f20c39a710f37a89108ea208bfdf70253ab7ec2ab55077b89c604d82c2c"}, "downloads": -1, "filename": "cntkx-0.1.47.tar.gz", "has_sig": false, "md5_digest": "9729b021391c0d5953a86b833f9a3c73", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 110817, "upload_time": "2020-05-01T05:42:50", "upload_time_iso_8601": "2020-05-01T05:42:50.935534Z", "url": "https://files.pythonhosted.org/packages/db/65/745dec9c6e090e28b11e95568d4e84c985a43f23d342a9d99efc9d707850/cntkx-0.1.47.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:27 2020"}