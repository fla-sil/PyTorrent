{"info": {"author": "Ted Kaemming, Matthew Hooker, and Keith Bourgoin", "author_email": "samsa-users@googlegroups.com", "bugtrack_url": null, "classifiers": [], "description": "#####\nsamsa\n#####\n\n|travis-ci|_\n\n.. |travis-ci| image:: https://travis-ci.org/getsamsa/samsa.png?branch=master\n.. _travis-ci: https://travis-ci.org/getsamsa/samsa\n\n    One morning, as Gregor Samsa was waking up from anxious dreams, he\n    discovered that in bed he had been changed into a monstrous verminous bug.\n\nSamsa is a cluster-aware Kafka protocol client and routing library for Python.\nIt implements version `0.7 of the protocol`__.\n\nIt's currently under development, but is being used internally to some success.\n\n__ https://cwiki.apache.org/KAFKA/wire-format.html\n\n************\nIntroduction\n************\n\nWhat is Kafka?\n==============\n\nKafka is a distributed publish-subscribe messaging system. Cluster management\nhappens with ZooKeeper.\n\nMessages\n    Messages are units of data to be communicated between clients or services.\n    Messages don't have any have any inherent structure -- as far as Kafka is\n    concerned, the message is just an array of bytes and the application can\n    serialize/deserialize the payload in a way that makes sense to it's own environment.\nBrokers\n    Brokers are nodes/servers that store and serve messages.\nTopics\n    Messages are published to topics, which are similar to channels. Every topic\n    is available on all servers.\nPartitions\n    Topics are divided into partitions, which are distributed across brokers.\n    Each partition is owned by a single broker.\n\nThe clients of a Kafka cluster are generally split into two different categories,\nalthough these roles are not mutually exclusive:\n\nProducer\n    Producers publish messages to topics.\nConsumer\n    Consumers subscribe to messages from topics.\n\nGoals of this Project\n=====================\n\n* Your application code should not be dependent on broker state or Kafka cluster\n  configuration. The only service that it should know about directly is the\n  ZooKeeper cluster.\n* Provide a level of abstraction and functionality similar to that of the Scala\n  client, but using Pythonic idioms and native data structures.\n\nGuarantees\n==========\n\n* Every publish will be written to (at least) one node, as long as a node is up\n  to accept the write.\n\n**********************\nUsage and API Overview\n**********************\n\nCreating a Cluster\n==================\n\n::\n\n    >>> from kazoo.client import KazooClient\n    >>> from samsa.cluster import Cluster\n    >>> zookeeper = KazooClient()\n    >>> zookeeper.start()\n    >>> cluster = Cluster(zookeeper)\n\nBrokers\n=======\n\nTo list all of the brokers by their broker ID within the cluster:\n\n::\n\n    >>> print cluster.brokers.keys()\n    [0, 1]\n\nTo get a ``Broker`` object by ID, provide the ID as the key in a dictionary\nitem lookup::\n\n    >>> print cluster.brokers[0]\n    <samsa.brokers.Broker at 0x1005f4c10: id=0>\n\nTopics\n======\n\n``Cluster`` objects also provide a dictionary-like interface for retrieving\n``Topic`` objects by name. For example::\n\n    >>> topic = cluster.topics['example-topic']\n    >>> print topic\n    <samsa.topics.Topic at 0x1005f4d90: name='example-topic'>\n\nYou can also see how many partitions are available to accept writes within a\ntopic by coercing it's ``PartitionMap`` to a list::\n\n    >>> print list(topic.partitions)\n    [<samsa.partitions.Partition at 0x1005f9b90: topic=<samsa.topics.Topic at 0x1005f4d90: name='example-topic'>, broker=<samsa.brokers.Broker at 0x1005f4c10: id=0>, number=0>]\n\nPublishing\n==========\n\nTo publish to a topic, provide a string or list of strings to be published to\na ``Topic`` instances's ``publish`` method::\n\n    >>> topic.publish('hello world')\n    >>> topic.publish(['hello', 'world'])\n\nIf a list of messages is provided, all messages will be delivered to the same\npartition, in order, on the same broker. Individual messages hold no such\nguarantee, and are subject to end up on any number of hosts as determined by\nthe partitioning method, and can be distributed across a number of partitions,\npotentially losing any ordering between messages.\n\nConsuming\n=========\n\nConsumers are organized into consumer groups, which allows Kafka to provide two\nsemantically different methods of message consumption, based on the consumer\ngroup configuration.\n\nQueue\n    Each consumer in a consumer group receives a message once, which\n    provides for a reasonably even distribution of messages around the group\n    since it is the owner of only a subset of the available partitions within\n    the topic. This is similar to a put/get queue or many AMQP-like interfaces.\nTopic\n    Each consumer is it's own consumer group, and receives all messages\n    sent to the topic since it is the owner of all partitions. This is similar\n    to an evented system, or a publish/subscribe interface.\n\nA Note about Partition Counts\n-----------------------------\n\nAn important thing to note when configuring your broker is that if there are\nmore consumers than partitions, some consumers won't get any messages at all,\nso you should configure your brokers up front to split topics into at least as\nmany partitions as you expect to have consumers.\n\nTo get the minimum number of partitions you should make available, use the\nfollowing equation::\n\n    # of brokers * # of partitions per node = # of consumers in the largest consumer group for this topic\n\nCreating Consumers\n------------------\n\nTo subscribe to a topic, provide a group name to the ``subscribe`` method on a\n``Topic`` instance::\n\n    >>> consumer = topic.subscribe('group-name')\n\nConsumers have to be registered with ZooKeeper before they begin to receive\nmessages. (Remember, only one consumer in a consumer group can be reading from\na partition at any time.)\n\nTo listen for messages on an established consumer::\n\n    >>> for message in consumer:\n    ...     print message\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/getsamsa/samsa", "keywords": null, "license": "Apache License 2.0", "maintainer": null, "maintainer_email": null, "name": "samsa", "package_url": "https://pypi.org/project/samsa/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/samsa/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/getsamsa/samsa"}, "release_url": "https://pypi.org/project/samsa/0.3.11/", "requires_dist": null, "requires_python": null, "summary": "Kafka Client for Kafka 0.7", "version": "0.3.11", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/getsamsa/samsa\" rel=\"nofollow\"><img alt=\"travis-ci\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9dc516127dc2282faf4ed6f52fb5859084239683/68747470733a2f2f7472617669732d63692e6f72672f67657473616d73612f73616d73612e706e673f6272616e63683d6d6173746572\"></a></p>\n<blockquote>\nOne morning, as Gregor Samsa was waking up from anxious dreams, he\ndiscovered that in bed he had been changed into a monstrous verminous bug.</blockquote>\n<p>Samsa is a cluster-aware Kafka protocol client and routing library for Python.\nIt implements version <a href=\"https://cwiki.apache.org/KAFKA/wire-format.html\" rel=\"nofollow\">0.7 of the protocol</a>.</p>\n<p>It\u2019s currently under development, but is being used internally to some success.</p>\n<div id=\"introduction\">\n<h2>Introduction</h2>\n<div id=\"what-is-kafka\">\n<h3>What is Kafka?</h3>\n<p>Kafka is a distributed publish-subscribe messaging system. Cluster management\nhappens with ZooKeeper.</p>\n<dl>\n<dt>Messages</dt>\n<dd>Messages are units of data to be communicated between clients or services.\nMessages don\u2019t have any have any inherent structure \u2013 as far as Kafka is\nconcerned, the message is just an array of bytes and the application can\nserialize/deserialize the payload in a way that makes sense to it\u2019s own environment.</dd>\n<dt>Brokers</dt>\n<dd>Brokers are nodes/servers that store and serve messages.</dd>\n<dt>Topics</dt>\n<dd>Messages are published to topics, which are similar to channels. Every topic\nis available on all servers.</dd>\n<dt>Partitions</dt>\n<dd>Topics are divided into partitions, which are distributed across brokers.\nEach partition is owned by a single broker.</dd>\n</dl>\n<p>The clients of a Kafka cluster are generally split into two different categories,\nalthough these roles are not mutually exclusive:</p>\n<dl>\n<dt>Producer</dt>\n<dd>Producers publish messages to topics.</dd>\n<dt>Consumer</dt>\n<dd>Consumers subscribe to messages from topics.</dd>\n</dl>\n</div>\n<div id=\"goals-of-this-project\">\n<h3>Goals of this Project</h3>\n<ul>\n<li>Your application code should not be dependent on broker state or Kafka cluster\nconfiguration. The only service that it should know about directly is the\nZooKeeper cluster.</li>\n<li>Provide a level of abstraction and functionality similar to that of the Scala\nclient, but using Pythonic idioms and native data structures.</li>\n</ul>\n</div>\n<div id=\"guarantees\">\n<h3>Guarantees</h3>\n<ul>\n<li>Every publish will be written to (at least) one node, as long as a node is up\nto accept the write.</li>\n</ul>\n</div>\n</div>\n<div id=\"usage-and-api-overview\">\n<h2>Usage and API Overview</h2>\n<div id=\"creating-a-cluster\">\n<h3>Creating a Cluster</h3>\n<pre>&gt;&gt;&gt; from kazoo.client import KazooClient\n&gt;&gt;&gt; from samsa.cluster import Cluster\n&gt;&gt;&gt; zookeeper = KazooClient()\n&gt;&gt;&gt; zookeeper.start()\n&gt;&gt;&gt; cluster = Cluster(zookeeper)\n</pre>\n</div>\n<div id=\"brokers\">\n<h3>Brokers</h3>\n<p>To list all of the brokers by their broker ID within the cluster:</p>\n<pre>&gt;&gt;&gt; print cluster.brokers.keys()\n[0, 1]\n</pre>\n<p>To get a <tt>Broker</tt> object by ID, provide the ID as the key in a dictionary\nitem lookup:</p>\n<pre>&gt;&gt;&gt; print cluster.brokers[0]\n&lt;samsa.brokers.Broker at 0x1005f4c10: id=0&gt;\n</pre>\n</div>\n<div id=\"topics\">\n<h3>Topics</h3>\n<p><tt>Cluster</tt> objects also provide a dictionary-like interface for retrieving\n<tt>Topic</tt> objects by name. For example:</p>\n<pre>&gt;&gt;&gt; topic = cluster.topics['example-topic']\n&gt;&gt;&gt; print topic\n&lt;samsa.topics.Topic at 0x1005f4d90: name='example-topic'&gt;\n</pre>\n<p>You can also see how many partitions are available to accept writes within a\ntopic by coercing it\u2019s <tt>PartitionMap</tt> to a list:</p>\n<pre>&gt;&gt;&gt; print list(topic.partitions)\n[&lt;samsa.partitions.Partition at 0x1005f9b90: topic=&lt;samsa.topics.Topic at 0x1005f4d90: name='example-topic'&gt;, broker=&lt;samsa.brokers.Broker at 0x1005f4c10: id=0&gt;, number=0&gt;]\n</pre>\n</div>\n<div id=\"publishing\">\n<h3>Publishing</h3>\n<p>To publish to a topic, provide a string or list of strings to be published to\na <tt>Topic</tt> instances\u2019s <tt>publish</tt> method:</p>\n<pre>&gt;&gt;&gt; topic.publish('hello world')\n&gt;&gt;&gt; topic.publish(['hello', 'world'])\n</pre>\n<p>If a list of messages is provided, all messages will be delivered to the same\npartition, in order, on the same broker. Individual messages hold no such\nguarantee, and are subject to end up on any number of hosts as determined by\nthe partitioning method, and can be distributed across a number of partitions,\npotentially losing any ordering between messages.</p>\n</div>\n<div id=\"consuming\">\n<h3>Consuming</h3>\n<p>Consumers are organized into consumer groups, which allows Kafka to provide two\nsemantically different methods of message consumption, based on the consumer\ngroup configuration.</p>\n<dl>\n<dt>Queue</dt>\n<dd>Each consumer in a consumer group receives a message once, which\nprovides for a reasonably even distribution of messages around the group\nsince it is the owner of only a subset of the available partitions within\nthe topic. This is similar to a put/get queue or many AMQP-like interfaces.</dd>\n<dt>Topic</dt>\n<dd>Each consumer is it\u2019s own consumer group, and receives all messages\nsent to the topic since it is the owner of all partitions. This is similar\nto an evented system, or a publish/subscribe interface.</dd>\n</dl>\n<div id=\"a-note-about-partition-counts\">\n<h4>A Note about Partition Counts</h4>\n<p>An important thing to note when configuring your broker is that if there are\nmore consumers than partitions, some consumers won\u2019t get any messages at all,\nso you should configure your brokers up front to split topics into at least as\nmany partitions as you expect to have consumers.</p>\n<p>To get the minimum number of partitions you should make available, use the\nfollowing equation:</p>\n<pre># of brokers * # of partitions per node = # of consumers in the largest consumer group for this topic\n</pre>\n</div>\n<div id=\"creating-consumers\">\n<h4>Creating Consumers</h4>\n<p>To subscribe to a topic, provide a group name to the <tt>subscribe</tt> method on a\n<tt>Topic</tt> instance:</p>\n<pre>&gt;&gt;&gt; consumer = topic.subscribe('group-name')\n</pre>\n<p>Consumers have to be registered with ZooKeeper before they begin to receive\nmessages. (Remember, only one consumer in a consumer group can be reading from\na partition at any time.)</p>\n<p>To listen for messages on an established consumer:</p>\n<pre>&gt;&gt;&gt; for message in consumer:\n...     print message\n</pre>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 1570109, "releases": {"0.2.2dev": [{"comment_text": "", "digests": {"md5": "bcb98cfefea8bfec7f0cf8717a6a1420", "sha256": "346df1612a38d8e8b322a4b8c04be05bd68ce5d3fff93915574a26fa8d63ed33"}, "downloads": -1, "filename": "samsa-0.2.2dev.tar.gz", "has_sig": false, "md5_digest": "bcb98cfefea8bfec7f0cf8717a6a1420", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27242, "upload_time": "2012-09-11T04:20:01", "upload_time_iso_8601": "2012-09-11T04:20:01.696615Z", "url": "https://files.pythonhosted.org/packages/a5/a3/60612403950c76c5a36bdf4197c476f9eec3ddd223c6d64c798c3ff331b4/samsa-0.2.2dev.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "80f3e637af257a037c2a3fd14d9be2fc", "sha256": "1f28140db7236a80c8c1e87726fffbb30452afe33e5d5a14904f760b55784459"}, "downloads": -1, "filename": "samsa-0.3.tar.gz", "has_sig": false, "md5_digest": "80f3e637af257a037c2a3fd14d9be2fc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27145, "upload_time": "2012-09-12T02:04:21", "upload_time_iso_8601": "2012-09-12T02:04:21.042685Z", "url": "https://files.pythonhosted.org/packages/b2/10/6f4f22a0e38c8a6ab8ba77cdd83f10bdbba9d770f8ca56ae63c4a0dae876/samsa-0.3.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "5120d98bfd59dcc8f07cc7ec7908b725", "sha256": "8ee5a0c0857af05d4c8334217bb4b0a8a8e61e174b34e613217b4bc331042c0c"}, "downloads": -1, "filename": "samsa-0.3.1.tar.gz", "has_sig": false, "md5_digest": "5120d98bfd59dcc8f07cc7ec7908b725", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27651, "upload_time": "2012-10-01T20:32:50", "upload_time_iso_8601": "2012-10-01T20:32:50.347896Z", "url": "https://files.pythonhosted.org/packages/4a/be/270c12cdab2b2ecc534d8ee424cabfc7492b70ba705749df7943261d9040/samsa-0.3.1.tar.gz", "yanked": false}], "0.3.10": [{"comment_text": "", "digests": {"md5": "d1faf248ca3f8cc678b094db58310a4f", "sha256": "920faeb971f75de41418d4a1998c86db58310268e4ab6fb209fb1d520285286a"}, "downloads": -1, "filename": "samsa-0.3.10.tar.gz", "has_sig": false, "md5_digest": "d1faf248ca3f8cc678b094db58310a4f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38211, "upload_time": "2014-01-02T20:03:17", "upload_time_iso_8601": "2014-01-02T20:03:17.843778Z", "url": "https://files.pythonhosted.org/packages/52/f8/c79297f1eeca295af840adcce6b35113e912226d77b61df3d45e462a2698/samsa-0.3.10.tar.gz", "yanked": false}], "0.3.11": [{"comment_text": "", "digests": {"md5": "4fecfc8d81e9690c7ee022b73dfd1f5c", "sha256": "db57d2e88213afbc4e02fb3df62f02a61452cd911a9fd69f7079bc0db4904889"}, "downloads": -1, "filename": "samsa-0.3.11.tar.gz", "has_sig": false, "md5_digest": "4fecfc8d81e9690c7ee022b73dfd1f5c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28021, "upload_time": "2014-03-16T20:13:41", "upload_time_iso_8601": "2014-03-16T20:13:41.435363Z", "url": "https://files.pythonhosted.org/packages/ca/d3/261465fba1404dd44482e084b2f9986641c08f1828c7309738739e18df53/samsa-0.3.11.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "dff4cc60d7769fb0c9c0f125d74ee501", "sha256": "1f2189ecbcddc578bf662804abc9ad4d83b057b50924085a843d1c979f2462c0"}, "downloads": -1, "filename": "samsa-0.3.2.tar.gz", "has_sig": false, "md5_digest": "dff4cc60d7769fb0c9c0f125d74ee501", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30549, "upload_time": "2012-10-26T23:26:22", "upload_time_iso_8601": "2012-10-26T23:26:22.851088Z", "url": "https://files.pythonhosted.org/packages/3d/b3/c4727b18ebd292ab61a85b9af23eaab4ff0efa431fc023b5c77144a73c66/samsa-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "35902607dd70145f7a4e3d24e54c9eac", "sha256": "d76163a7cb66fc9db1da3eb968ee03cb15bdce18745ae07ec34ae77adc116173"}, "downloads": -1, "filename": "samsa-0.3.3.tar.gz", "has_sig": false, "md5_digest": "35902607dd70145f7a4e3d24e54c9eac", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30629, "upload_time": "2012-10-26T23:45:29", "upload_time_iso_8601": "2012-10-26T23:45:29.507828Z", "url": "https://files.pythonhosted.org/packages/e9/f4/084107e3d1157bf4b463f4cd9ca51f87fcd4b01e79750f26349649ff1684/samsa-0.3.3.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "10400d9776be7074f30cadaa90df2443", "sha256": "c4b0a656cc84982c16dd0cc7545c8363294ad70b927300e8af1ff821976985e5"}, "downloads": -1, "filename": "samsa-0.3.4.tar.gz", "has_sig": false, "md5_digest": "10400d9776be7074f30cadaa90df2443", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30641, "upload_time": "2012-10-27T00:31:09", "upload_time_iso_8601": "2012-10-27T00:31:09.203906Z", "url": "https://files.pythonhosted.org/packages/bb/a9/2f3eabb4f7a88d88d9dcea919ffec1945d3b63dc4d0e9f2f4255b2add182/samsa-0.3.4.tar.gz", "yanked": false}], "0.3.5": [{"comment_text": "", "digests": {"md5": "c139ee84c62edd7fd01225363f1ced29", "sha256": "2c3a065f1944f173dcfd2649b4e93adda3f63ad82000e6dec16655e151701782"}, "downloads": -1, "filename": "samsa-0.3.5.tar.gz", "has_sig": false, "md5_digest": "c139ee84c62edd7fd01225363f1ced29", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28142, "upload_time": "2013-04-26T18:51:13", "upload_time_iso_8601": "2013-04-26T18:51:13.548111Z", "url": "https://files.pythonhosted.org/packages/ee/e9/b284be6d2572487749131ae8d365ef0afb936662342705dbc07823f108f8/samsa-0.3.5.tar.gz", "yanked": false}], "0.3.6": [{"comment_text": "", "digests": {"md5": "22888663bf5d96f4d49a92763fe81be6", "sha256": "7637849d041976db6be3f9cb4c235d587f76abce10ff6a0ddd202d46001a41f2"}, "downloads": -1, "filename": "samsa-0.3.6.tar.gz", "has_sig": false, "md5_digest": "22888663bf5d96f4d49a92763fe81be6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35621, "upload_time": "2013-04-30T16:01:01", "upload_time_iso_8601": "2013-04-30T16:01:01.812132Z", "url": "https://files.pythonhosted.org/packages/62/8d/f4dce7e59e02a84cca83e65c52834ac814e6eb45e88b66bf9082c272bb8b/samsa-0.3.6.tar.gz", "yanked": false}], "0.3.8": [{"comment_text": "", "digests": {"md5": "9b1797b26f3ca3a854e91f5989226a9f", "sha256": "77eff1c23b037d892d82ebcf0008d691b525a016445086d119ed320ff846be8e"}, "downloads": -1, "filename": "samsa-0.3.8.tar.gz", "has_sig": false, "md5_digest": "9b1797b26f3ca3a854e91f5989226a9f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37183, "upload_time": "2013-07-30T21:16:16", "upload_time_iso_8601": "2013-07-30T21:16:16.460782Z", "url": "https://files.pythonhosted.org/packages/fb/96/ca35035b36b0b085ed02da2a33bbe74f358d069f54ac1f81bbafe8534d2a/samsa-0.3.8.tar.gz", "yanked": false}], "0.3.9": [{"comment_text": "", "digests": {"md5": "22bd0e165eca57aa85fe8f610f959876", "sha256": "512fdf97bac81aeec4e3a9a7bd8b93cba30bbcdbdfbbb6ddaf3f07a2a5fa36a0"}, "downloads": -1, "filename": "samsa-0.3.9.tar.gz", "has_sig": false, "md5_digest": "22bd0e165eca57aa85fe8f610f959876", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38487, "upload_time": "2013-08-28T20:35:38", "upload_time_iso_8601": "2013-08-28T20:35:38.105223Z", "url": "https://files.pythonhosted.org/packages/7c/b8/383db0fd25b540781e1feff06cc15fce03f9c1a9718ead611650677249b5/samsa-0.3.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4fecfc8d81e9690c7ee022b73dfd1f5c", "sha256": "db57d2e88213afbc4e02fb3df62f02a61452cd911a9fd69f7079bc0db4904889"}, "downloads": -1, "filename": "samsa-0.3.11.tar.gz", "has_sig": false, "md5_digest": "4fecfc8d81e9690c7ee022b73dfd1f5c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28021, "upload_time": "2014-03-16T20:13:41", "upload_time_iso_8601": "2014-03-16T20:13:41.435363Z", "url": "https://files.pythonhosted.org/packages/ca/d3/261465fba1404dd44482e084b2f9986641c08f1828c7309738739e18df53/samsa-0.3.11.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:58:53 2020"}