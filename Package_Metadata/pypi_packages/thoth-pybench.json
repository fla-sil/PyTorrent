{"info": {"author": "Marc-Andre Lemburg", "author_email": "mal@lemburg.com", "bugtrack_url": null, "classifiers": [], "description": "This repository contains an adopted version of \"PyBench\"\nfrom https://openbenchmarking.org/test/pts/pybench.\n\nAdditional changes have been made by the Thoth team to make this great tool\nwork on Python3+. This package is also available on PyPI:\n\n  https://pypi.org/project/thoth-pybench\n\n________________________________________________________________________\n\nPYBENCH - A Python Benchmark Suite\n________________________________________________________________________\n\n     Extendable suite of of low-level benchmarks for measuring\n          the performance of the Python implementation \n                 (interpreter, compiler or VM).\n\npybench is a collection of tests that provides a standardized way to\nmeasure the performance of Python implementations. It takes a very\nclose look at different aspects of Python programs and let's you\ndecide which factors are more important to you than others, rather\nthan wrapping everything up in one number, like the other performance\ntests do (e.g. pystone which is included in the Python Standard\nLibrary).\n\npybench has been used in the past by several Python developers to\ntrack down performance bottlenecks or to demonstrate the impact of\noptimizations and new features in Python.\n\nThe command line interface for pybench is the file pybench.py. Run\nthis script with option '--help' to get a listing of the possible\noptions. Without options, pybench will simply execute the benchmark\nand then print out a report to stdout.\n\n\nMicro-Manual\n------------\n\nRun 'pybench.py -h' to see the help screen.  Run 'pybench.py' to run\nthe benchmark suite using default settings and 'pybench.py -f <file>'\nto have it store the results in a file too.\n\nIt is usually a good idea to run pybench.py multiple times to see\nwhether the environment, timers and benchmark run-times are suitable\nfor doing benchmark tests. \n\nYou can use the comparison feature of pybench.py ('pybench.py -c\n<file>') to check how well the system behaves in comparison to a\nreference run. \n\nIf the differences are well below 10% for each test, then you have a\nsystem that is good for doing benchmark testings.  Of you get random\ndifferences of more than 10% or significant differences between the\nvalues for minimum and average time, then you likely have some\nbackground processes running which cause the readings to become\ninconsistent. Examples include: web-browsers, email clients, RSS\nreaders, music players, backup programs, etc.\n\nIf you are only interested in a few tests of the whole suite, you can\nuse the filtering option, e.g. 'pybench.py -t string' will only\nrun/show the tests that have 'string' in their name.\n\nThis is the current output of pybench.py --help:\n\n\"\"\"\n------------------------------------------------------------------------\nPYBENCH - a benchmark test suite for Python interpreters/compilers.\n------------------------------------------------------------------------\n\nSynopsis:\n pybench.py [option] files...\n\nOptions and default settings:\n  -n arg           number of rounds (10)\n  -f arg           save benchmark to file arg ()\n  -c arg           compare benchmark with the one in file arg ()\n  -s arg           show benchmark in file arg, then exit ()\n  -w arg           set warp factor to arg (10)\n  -t arg           run only tests with names matching arg ()\n  -C arg           set the number of calibration runs to arg (20)\n  -d               hide noise in comparisons (0)\n  -v               verbose output (not recommended) (0)\n  --with-gc        enable garbage collection (0)\n  --with-syscheck  use default sys check interval (0)\n  --timer arg      use given timer (time.time)\n  -h               show this help text\n  --help           show this help text\n  --debug          enable debugging\n  --copyright      show copyright\n  --examples       show examples of usage\n\nVersion:\n 2.0\n\nThe normal operation is to run the suite and display the\nresults. Use -f to save them for later reuse or comparisons.\n\nAvailable timers:\n\n   time.time\n   time.clock\n   systimes.processtime\n\nExamples:\n\npython2.1 pybench.py -f p21.pybench\npython2.5 pybench.py -f p25.pybench\npython pybench.py -s p25.pybench -c p21.pybench\n\"\"\"\n\nLicense\n-------\n\nSee LICENSE file.\n\n\nSample output\n-------------\n\n\"\"\"\n-------------------------------------------------------------------------------\nPYBENCH 2.0\n-------------------------------------------------------------------------------\n* using Python 2.4.2\n* disabled garbage collection\n* system check interval set to maximum: 2147483647\n* using timer: time.time\n\nCalibrating tests. Please wait...\n\nRunning 10 round(s) of the suite at warp factor 10:\n\n* Round 1 done in 6.388 seconds.\n* Round 2 done in 6.485 seconds.\n* Round 3 done in 6.786 seconds.\n...\n* Round 10 done in 6.546 seconds.\n\n-------------------------------------------------------------------------------\nBenchmark: 2006-06-12 12:09:25\n-------------------------------------------------------------------------------\n\n    Rounds: 10\n    Warp:   10\n    Timer:  time.time\n\n    Machine Details:\n       Platform ID:  Linux-2.6.8-24.19-default-x86_64-with-SuSE-9.2-x86-64\n       Processor:    x86_64\n\n    Python:\n       Executable:   /usr/local/bin/python\n       Version:      2.4.2\n       Compiler:     GCC 3.3.4 (pre 3.3.5 20040809)\n       Bits:         64bit\n       Build:        Oct  1 2005 15:24:35 (#1)\n       Unicode:      UCS2\n\n\nTest                             minimum  average  operation  overhead\n-------------------------------------------------------------------------------\n          BuiltinFunctionCalls:    126ms    145ms    0.28us    0.274ms\n           BuiltinMethodLookup:    124ms    130ms    0.12us    0.316ms\n                 CompareFloats:    109ms    110ms    0.09us    0.361ms\n         CompareFloatsIntegers:    100ms    104ms    0.12us    0.271ms\n               CompareIntegers:    137ms    138ms    0.08us    0.542ms\n        CompareInternedStrings:    124ms    127ms    0.08us    1.367ms\n                  CompareLongs:    100ms    104ms    0.10us    0.316ms\n                CompareStrings:    111ms    115ms    0.12us    0.929ms\n                CompareUnicode:    108ms    128ms    0.17us    0.693ms\n                 ConcatStrings:    142ms    155ms    0.31us    0.562ms\n                 ConcatUnicode:    119ms    127ms    0.42us    0.384ms\n               CreateInstances:    123ms    128ms    1.14us    0.367ms\n            CreateNewInstances:    121ms    126ms    1.49us    0.335ms\n       CreateStringsWithConcat:    130ms    135ms    0.14us    0.916ms\n       CreateUnicodeWithConcat:    130ms    135ms    0.34us    0.361ms\n                  DictCreation:    108ms    109ms    0.27us    0.361ms\n             DictWithFloatKeys:    149ms    153ms    0.17us    0.678ms\n           DictWithIntegerKeys:    124ms    126ms    0.11us    0.915ms\n            DictWithStringKeys:    114ms    117ms    0.10us    0.905ms\n                      ForLoops:    110ms    111ms    4.46us    0.063ms\n                    IfThenElse:    118ms    119ms    0.09us    0.685ms\n                   ListSlicing:    116ms    120ms    8.59us    0.103ms\n                NestedForLoops:    125ms    137ms    0.09us    0.019ms\n          NormalClassAttribute:    124ms    136ms    0.11us    0.457ms\n       NormalInstanceAttribute:    110ms    117ms    0.10us    0.454ms\n           PythonFunctionCalls:    107ms    113ms    0.34us    0.271ms\n             PythonMethodCalls:    140ms    149ms    0.66us    0.141ms\n                     Recursion:    156ms    166ms    3.32us    0.452ms\n                  SecondImport:    112ms    118ms    1.18us    0.180ms\n           SecondPackageImport:    118ms    127ms    1.27us    0.180ms\n         SecondSubmoduleImport:    140ms    151ms    1.51us    0.180ms\n       SimpleComplexArithmetic:    128ms    139ms    0.16us    0.361ms\n        SimpleDictManipulation:    134ms    136ms    0.11us    0.452ms\n         SimpleFloatArithmetic:    110ms    113ms    0.09us    0.571ms\n      SimpleIntFloatArithmetic:    106ms    111ms    0.08us    0.548ms\n       SimpleIntegerArithmetic:    106ms    109ms    0.08us    0.544ms\n        SimpleListManipulation:    103ms    113ms    0.10us    0.587ms\n          SimpleLongArithmetic:    112ms    118ms    0.18us    0.271ms\n                    SmallLists:    105ms    116ms    0.17us    0.366ms\n                   SmallTuples:    108ms    128ms    0.24us    0.406ms\n         SpecialClassAttribute:    119ms    136ms    0.11us    0.453ms\n      SpecialInstanceAttribute:    143ms    155ms    0.13us    0.454ms\n                StringMappings:    115ms    121ms    0.48us    0.405ms\n              StringPredicates:    120ms    129ms    0.18us    2.064ms\n                 StringSlicing:    111ms    127ms    0.23us    0.781ms\n                     TryExcept:    125ms    126ms    0.06us    0.681ms\n                TryRaiseExcept:    133ms    137ms    2.14us    0.361ms\n                  TupleSlicing:    117ms    120ms    0.46us    0.066ms\n               UnicodeMappings:    156ms    160ms    4.44us    0.429ms\n             UnicodePredicates:    117ms    121ms    0.22us    2.487ms\n             UnicodeProperties:    115ms    153ms    0.38us    2.070ms\n                UnicodeSlicing:    126ms    129ms    0.26us    0.689ms\n-------------------------------------------------------------------------------\nTotals:                           6283ms   6673ms\n\"\"\"\n________________________________________________________________________\n\nWriting New Tests\n________________________________________________________________________\n\npybench tests are simple modules defining one or more pybench.Test\nsubclasses.\n\nWriting a test essentially boils down to providing two methods:\n.test() which runs .rounds number of .operations test operations each\nand .calibrate() which does the same except that it doesn't actually\nexecute the operations.\n\n\nHere's an example:\n------------------\n\nfrom pybench import Test\n\nclass IntegerCounting(Test):\n\n    # Version number of the test as float (x.yy); this is important\n    # for comparisons of benchmark runs - tests with unequal version\n    # number will not get compared.\n    version = 1.0\n\n    # The number of abstract operations done in each round of the\n    # test. An operation is the basic unit of what you want to\n    # measure. The benchmark will output the amount of run-time per\n    # operation. Note that in order to raise the measured timings\n    # significantly above noise level, it is often required to repeat\n    # sets of operations more than once per test round. The measured\n    # overhead per test round should be less than 1 second.\n    operations = 20\n\n    # Number of rounds to execute per test run. This should be\n    # adjusted to a figure that results in a test run-time of between\n    # 1-2 seconds (at warp 1).\n    rounds = 100000\n\n    def test(self):\n\n\t\"\"\" Run the test.\n\n\t    The test needs to run self.rounds executing\n\t    self.operations number of operations each.\n\n        \"\"\"\n        # Init the test\n        a = 1\n\n        # Run test rounds\n\t#\n        # NOTE: Use xrange() for all test loops unless you want to face\n\t# a 20MB process !\n\t#\n        for i in xrange(self.rounds):\n\n            # Repeat the operations per round to raise the run-time\n            # per operation significantly above the noise level of the\n            # for-loop overhead. \n\n\t    # Execute 20 operations (a += 1):\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n            a += 1\n\n    def calibrate(self):\n\n\t\"\"\" Calibrate the test.\n\n\t    This method should execute everything that is needed to\n\t    setup and run the test - except for the actual operations\n\t    that you intend to measure. pybench uses this method to\n            measure the test implementation overhead.\n\n        \"\"\"\n        # Init the test\n        a = 1\n\n        # Run test rounds (without actually doing any operation)\n        for i in xrange(self.rounds):\n\n\t    # Skip the actual execution of the operations, since we\n\t    # only want to measure the test's administration overhead.\n            pass\n\nRegistering a new test module\n-----------------------------\n\nTo register a test module with pybench, the classes need to be\nimported into the pybench.Setup module. pybench will then scan all the\nsymbols defined in that module for subclasses of pybench.Test and\nautomatically add them to the benchmark suite.\n\n\nBreaking Comparability\n----------------------\n\nIf a change is made to any individual test that means it is no\nlonger strictly comparable with previous runs, the '.version' class\nvariable should be updated. Therefafter, comparisons with previous\nversions of the test will list as \"n/a\" to reflect the change.\n\n\nVersion History\n---------------\n\n  2.0: rewrote parts of pybench which resulted in more repeatable\n       timings:\n        - made timer a parameter\n        - changed the platform default timer to use high-resolution\n          timers rather than process timers (which have a much lower\n          resolution)\n        - added option to select timer\n        - added process time timer (using systimes.py)\n        - changed to use min() as timing estimator (average\n          is still taken as well to provide an idea of the difference)\n        - garbage collection is turned off per default\n        - sys check interval is set to the highest possible value\n        - calibration is now a separate step and done using\n          a different strategy that allows measuring the test\n          overhead more accurately\n        - modified the tests to each give a run-time of between\n          100-200ms using warp 10\n        - changed default warp factor to 10 (from 20)\n        - compared results with timeit.py and confirmed measurements\n        - bumped all test versions to 2.0\n        - updated platform.py to the latest version\n        - changed the output format a bit to make it look\n          nicer\n        - refactored the APIs somewhat\n  1.3+: Steve Holden added the NewInstances test and the filtering \n       option during the NeedForSpeed sprint; this also triggered a long \n       discussion on how to improve benchmark timing and finally\n       resulted in the release of 2.0\n  1.3: initial checkin into the Python SVN repository\n\n\nHave fun,\n--\nMarc-Andre Lemburg\nmal@lemburg.com\n\n\n", "description_content_type": "text/plain", "docs_url": null, "download_url": "https://github.com/thoth-station/thoth-pybench", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://openbenchmarking.org/test/pts/pybench", "keywords": "", "license": "", "maintainer": "Francesco Murdaca", "maintainer_email": "fmurdaca@redhat.com", "name": "thoth-pybench", "package_url": "https://pypi.org/project/thoth-pybench/", "platform": "", "project_url": "https://pypi.org/project/thoth-pybench/", "project_urls": {"Download": "https://github.com/thoth-station/thoth-pybench", "Homepage": "https://openbenchmarking.org/test/pts/pybench"}, "release_url": "https://pypi.org/project/thoth-pybench/0.0.6/", "requires_dist": null, "requires_python": "", "summary": "Adopted PyBench tool to benchmark Python interpreter by the Thoth team.", "version": "0.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            This repository contains an adopted version of \"PyBench\"<br>from https://openbenchmarking.org/test/pts/pybench.<br><br>Additional changes have been made by the Thoth team to make this great tool<br>work on Python3+. This package is also available on PyPI:<br><br>  https://pypi.org/project/thoth-pybench<br><br>________________________________________________________________________<br><br>PYBENCH - A Python Benchmark Suite<br>________________________________________________________________________<br><br>     Extendable suite of of low-level benchmarks for measuring<br>          the performance of the Python implementation <br>                 (interpreter, compiler or VM).<br><br>pybench is a collection of tests that provides a standardized way to<br>measure the performance of Python implementations. It takes a very<br>close look at different aspects of Python programs and let's you<br>decide which factors are more important to you than others, rather<br>than wrapping everything up in one number, like the other performance<br>tests do (e.g. pystone which is included in the Python Standard<br>Library).<br><br>pybench has been used in the past by several Python developers to<br>track down performance bottlenecks or to demonstrate the impact of<br>optimizations and new features in Python.<br><br>The command line interface for pybench is the file pybench.py. Run<br>this script with option '--help' to get a listing of the possible<br>options. Without options, pybench will simply execute the benchmark<br>and then print out a report to stdout.<br><br><br>Micro-Manual<br>------------<br><br>Run 'pybench.py -h' to see the help screen.  Run 'pybench.py' to run<br>the benchmark suite using default settings and 'pybench.py -f &lt;file&gt;'<br>to have it store the results in a file too.<br><br>It is usually a good idea to run pybench.py multiple times to see<br>whether the environment, timers and benchmark run-times are suitable<br>for doing benchmark tests. <br><br>You can use the comparison feature of pybench.py ('pybench.py -c<br>&lt;file&gt;') to check how well the system behaves in comparison to a<br>reference run. <br><br>If the differences are well below 10% for each test, then you have a<br>system that is good for doing benchmark testings.  Of you get random<br>differences of more than 10% or significant differences between the<br>values for minimum and average time, then you likely have some<br>background processes running which cause the readings to become<br>inconsistent. Examples include: web-browsers, email clients, RSS<br>readers, music players, backup programs, etc.<br><br>If you are only interested in a few tests of the whole suite, you can<br>use the filtering option, e.g. 'pybench.py -t string' will only<br>run/show the tests that have 'string' in their name.<br><br>This is the current output of pybench.py --help:<br><br>\"\"\"<br>------------------------------------------------------------------------<br>PYBENCH - a benchmark test suite for Python interpreters/compilers.<br>------------------------------------------------------------------------<br><br>Synopsis:<br> pybench.py [option] files...<br><br>Options and default settings:<br>  -n arg           number of rounds (10)<br>  -f arg           save benchmark to file arg ()<br>  -c arg           compare benchmark with the one in file arg ()<br>  -s arg           show benchmark in file arg, then exit ()<br>  -w arg           set warp factor to arg (10)<br>  -t arg           run only tests with names matching arg ()<br>  -C arg           set the number of calibration runs to arg (20)<br>  -d               hide noise in comparisons (0)<br>  -v               verbose output (not recommended) (0)<br>  --with-gc        enable garbage collection (0)<br>  --with-syscheck  use default sys check interval (0)<br>  --timer arg      use given timer (time.time)<br>  -h               show this help text<br>  --help           show this help text<br>  --debug          enable debugging<br>  --copyright      show copyright<br>  --examples       show examples of usage<br><br>Version:<br> 2.0<br><br>The normal operation is to run the suite and display the<br>results. Use -f to save them for later reuse or comparisons.<br><br>Available timers:<br><br>   time.time<br>   time.clock<br>   systimes.processtime<br><br>Examples:<br><br>python2.1 pybench.py -f p21.pybench<br>python2.5 pybench.py -f p25.pybench<br>python pybench.py -s p25.pybench -c p21.pybench<br>\"\"\"<br><br>License<br>-------<br><br>See LICENSE file.<br><br><br>Sample output<br>-------------<br><br>\"\"\"<br>-------------------------------------------------------------------------------<br>PYBENCH 2.0<br>-------------------------------------------------------------------------------<br>* using Python 2.4.2<br>* disabled garbage collection<br>* system check interval set to maximum: 2147483647<br>* using timer: time.time<br><br>Calibrating tests. Please wait...<br><br>Running 10 round(s) of the suite at warp factor 10:<br><br>* Round 1 done in 6.388 seconds.<br>* Round 2 done in 6.485 seconds.<br>* Round 3 done in 6.786 seconds.<br>...<br>* Round 10 done in 6.546 seconds.<br><br>-------------------------------------------------------------------------------<br>Benchmark: 2006-06-12 12:09:25<br>-------------------------------------------------------------------------------<br><br>    Rounds: 10<br>    Warp:   10<br>    Timer:  time.time<br><br>    Machine Details:<br>       Platform ID:  Linux-2.6.8-24.19-default-x86_64-with-SuSE-9.2-x86-64<br>       Processor:    x86_64<br><br>    Python:<br>       Executable:   /usr/local/bin/python<br>       Version:      2.4.2<br>       Compiler:     GCC 3.3.4 (pre 3.3.5 20040809)<br>       Bits:         64bit<br>       Build:        Oct  1 2005 15:24:35 (#1)<br>       Unicode:      UCS2<br><br><br>Test                             minimum  average  operation  overhead<br>-------------------------------------------------------------------------------<br>          BuiltinFunctionCalls:    126ms    145ms    0.28us    0.274ms<br>           BuiltinMethodLookup:    124ms    130ms    0.12us    0.316ms<br>                 CompareFloats:    109ms    110ms    0.09us    0.361ms<br>         CompareFloatsIntegers:    100ms    104ms    0.12us    0.271ms<br>               CompareIntegers:    137ms    138ms    0.08us    0.542ms<br>        CompareInternedStrings:    124ms    127ms    0.08us    1.367ms<br>                  CompareLongs:    100ms    104ms    0.10us    0.316ms<br>                CompareStrings:    111ms    115ms    0.12us    0.929ms<br>                CompareUnicode:    108ms    128ms    0.17us    0.693ms<br>                 ConcatStrings:    142ms    155ms    0.31us    0.562ms<br>                 ConcatUnicode:    119ms    127ms    0.42us    0.384ms<br>               CreateInstances:    123ms    128ms    1.14us    0.367ms<br>            CreateNewInstances:    121ms    126ms    1.49us    0.335ms<br>       CreateStringsWithConcat:    130ms    135ms    0.14us    0.916ms<br>       CreateUnicodeWithConcat:    130ms    135ms    0.34us    0.361ms<br>                  DictCreation:    108ms    109ms    0.27us    0.361ms<br>             DictWithFloatKeys:    149ms    153ms    0.17us    0.678ms<br>           DictWithIntegerKeys:    124ms    126ms    0.11us    0.915ms<br>            DictWithStringKeys:    114ms    117ms    0.10us    0.905ms<br>                      ForLoops:    110ms    111ms    4.46us    0.063ms<br>                    IfThenElse:    118ms    119ms    0.09us    0.685ms<br>                   ListSlicing:    116ms    120ms    8.59us    0.103ms<br>                NestedForLoops:    125ms    137ms    0.09us    0.019ms<br>          NormalClassAttribute:    124ms    136ms    0.11us    0.457ms<br>       NormalInstanceAttribute:    110ms    117ms    0.10us    0.454ms<br>           PythonFunctionCalls:    107ms    113ms    0.34us    0.271ms<br>             PythonMethodCalls:    140ms    149ms    0.66us    0.141ms<br>                     Recursion:    156ms    166ms    3.32us    0.452ms<br>                  SecondImport:    112ms    118ms    1.18us    0.180ms<br>           SecondPackageImport:    118ms    127ms    1.27us    0.180ms<br>         SecondSubmoduleImport:    140ms    151ms    1.51us    0.180ms<br>       SimpleComplexArithmetic:    128ms    139ms    0.16us    0.361ms<br>        SimpleDictManipulation:    134ms    136ms    0.11us    0.452ms<br>         SimpleFloatArithmetic:    110ms    113ms    0.09us    0.571ms<br>      SimpleIntFloatArithmetic:    106ms    111ms    0.08us    0.548ms<br>       SimpleIntegerArithmetic:    106ms    109ms    0.08us    0.544ms<br>        SimpleListManipulation:    103ms    113ms    0.10us    0.587ms<br>          SimpleLongArithmetic:    112ms    118ms    0.18us    0.271ms<br>                    SmallLists:    105ms    116ms    0.17us    0.366ms<br>                   SmallTuples:    108ms    128ms    0.24us    0.406ms<br>         SpecialClassAttribute:    119ms    136ms    0.11us    0.453ms<br>      SpecialInstanceAttribute:    143ms    155ms    0.13us    0.454ms<br>                StringMappings:    115ms    121ms    0.48us    0.405ms<br>              StringPredicates:    120ms    129ms    0.18us    2.064ms<br>                 StringSlicing:    111ms    127ms    0.23us    0.781ms<br>                     TryExcept:    125ms    126ms    0.06us    0.681ms<br>                TryRaiseExcept:    133ms    137ms    2.14us    0.361ms<br>                  TupleSlicing:    117ms    120ms    0.46us    0.066ms<br>               UnicodeMappings:    156ms    160ms    4.44us    0.429ms<br>             UnicodePredicates:    117ms    121ms    0.22us    2.487ms<br>             UnicodeProperties:    115ms    153ms    0.38us    2.070ms<br>                UnicodeSlicing:    126ms    129ms    0.26us    0.689ms<br>-------------------------------------------------------------------------------<br>Totals:                           6283ms   6673ms<br>\"\"\"<br>________________________________________________________________________<br><br>Writing New Tests<br>________________________________________________________________________<br><br>pybench tests are simple modules defining one or more pybench.Test<br>subclasses.<br><br>Writing a test essentially boils down to providing two methods:<br>.test() which runs .rounds number of .operations test operations each<br>and .calibrate() which does the same except that it doesn't actually<br>execute the operations.<br><br><br>Here's an example:<br>------------------<br><br>from pybench import Test<br><br>class IntegerCounting(Test):<br><br>    # Version number of the test as float (x.yy); this is important<br>    # for comparisons of benchmark runs - tests with unequal version<br>    # number will not get compared.<br>    version = 1.0<br><br>    # The number of abstract operations done in each round of the<br>    # test. An operation is the basic unit of what you want to<br>    # measure. The benchmark will output the amount of run-time per<br>    # operation. Note that in order to raise the measured timings<br>    # significantly above noise level, it is often required to repeat<br>    # sets of operations more than once per test round. The measured<br>    # overhead per test round should be less than 1 second.<br>    operations = 20<br><br>    # Number of rounds to execute per test run. This should be<br>    # adjusted to a figure that results in a test run-time of between<br>    # 1-2 seconds (at warp 1).<br>    rounds = 100000<br><br>    def test(self):<br><br>\t\"\"\" Run the test.<br><br>\t    The test needs to run self.rounds executing<br>\t    self.operations number of operations each.<br><br>        \"\"\"<br>        # Init the test<br>        a = 1<br><br>        # Run test rounds<br>\t#<br>        # NOTE: Use xrange() for all test loops unless you want to face<br>\t# a 20MB process !<br>\t#<br>        for i in xrange(self.rounds):<br><br>            # Repeat the operations per round to raise the run-time<br>            # per operation significantly above the noise level of the<br>            # for-loop overhead. <br><br>\t    # Execute 20 operations (a += 1):<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br>            a += 1<br><br>    def calibrate(self):<br><br>\t\"\"\" Calibrate the test.<br><br>\t    This method should execute everything that is needed to<br>\t    setup and run the test - except for the actual operations<br>\t    that you intend to measure. pybench uses this method to<br>            measure the test implementation overhead.<br><br>        \"\"\"<br>        # Init the test<br>        a = 1<br><br>        # Run test rounds (without actually doing any operation)<br>        for i in xrange(self.rounds):<br><br>\t    # Skip the actual execution of the operations, since we<br>\t    # only want to measure the test's administration overhead.<br>            pass<br><br>Registering a new test module<br>-----------------------------<br><br>To register a test module with pybench, the classes need to be<br>imported into the pybench.Setup module. pybench will then scan all the<br>symbols defined in that module for subclasses of pybench.Test and<br>automatically add them to the benchmark suite.<br><br><br>Breaking Comparability<br>----------------------<br><br>If a change is made to any individual test that means it is no<br>longer strictly comparable with previous runs, the '.version' class<br>variable should be updated. Therefafter, comparisons with previous<br>versions of the test will list as \"n/a\" to reflect the change.<br><br><br>Version History<br>---------------<br><br>  2.0: rewrote parts of pybench which resulted in more repeatable<br>       timings:<br>        - made timer a parameter<br>        - changed the platform default timer to use high-resolution<br>          timers rather than process timers (which have a much lower<br>          resolution)<br>        - added option to select timer<br>        - added process time timer (using systimes.py)<br>        - changed to use min() as timing estimator (average<br>          is still taken as well to provide an idea of the difference)<br>        - garbage collection is turned off per default<br>        - sys check interval is set to the highest possible value<br>        - calibration is now a separate step and done using<br>          a different strategy that allows measuring the test<br>          overhead more accurately<br>        - modified the tests to each give a run-time of between<br>          100-200ms using warp 10<br>        - changed default warp factor to 10 (from 20)<br>        - compared results with timeit.py and confirmed measurements<br>        - bumped all test versions to 2.0<br>        - updated platform.py to the latest version<br>        - changed the output format a bit to make it look<br>          nicer<br>        - refactored the APIs somewhat<br>  1.3+: Steve Holden added the NewInstances test and the filtering <br>       option during the NeedForSpeed sprint; this also triggered a long <br>       discussion on how to improve benchmark timing and finally<br>       resulted in the release of 2.0<br>  1.3: initial checkin into the Python SVN repository<br><br><br>Have fun,<br>--<br>Marc-Andre Lemburg<br>mal@lemburg.com<br><br><br>\n          </div>"}, "last_serial": 6181097, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "edb0cb611a97d3d0d26313b4cf36855f", "sha256": "69f88928b3375e7a6015dcdb09b479fe3af3d92db64574ed20b7b00969fd6fe7"}, "downloads": -1, "filename": "thoth_pybench-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "edb0cb611a97d3d0d26313b4cf36855f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 33677, "upload_time": "2019-11-13T12:43:58", "upload_time_iso_8601": "2019-11-13T12:43:58.342892Z", "url": "https://files.pythonhosted.org/packages/1d/49/a957c98cee11c8a9f611f89d7abb9cf4ddf3487b50e670a4bbb722403334/thoth_pybench-0.0.1-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "30f8d13aa79a8d3411bd5abe1e20bbcb", "sha256": "43a8279a870f5aa2633b53273c1884a99bccb212a7279e00b8e6f283039ad627"}, "downloads": -1, "filename": "thoth_pybench-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "30f8d13aa79a8d3411bd5abe1e20bbcb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 34090, "upload_time": "2019-11-13T13:04:15", "upload_time_iso_8601": "2019-11-13T13:04:15.760485Z", "url": "https://files.pythonhosted.org/packages/0d/2a/8703fd8c749de342cbcfe6d4d7de8dcbe610fd0d71895cf0a5ebc47595c1/thoth_pybench-0.0.2-py3-none-any.whl", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "345f7d00f2b65cf61ce099f1c5055323", "sha256": "c76ddb8eb7638f50918a992e7d1db0cf77b04f74744d1babab99d8e2c9d11c57"}, "downloads": -1, "filename": "thoth_pybench-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "345f7d00f2b65cf61ce099f1c5055323", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35263, "upload_time": "2019-11-20T15:44:51", "upload_time_iso_8601": "2019-11-20T15:44:51.946895Z", "url": "https://files.pythonhosted.org/packages/0c/0f/112ae14ba2a9049f719f3a4bb8df1d266985094ccdd83a5271e9c2203323/thoth_pybench-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0ec5cd2f535f55a0db09b25328946061", "sha256": "2ac817df26d3795a8492144aa5c671248cde19658f1950ffa996b2c77c268443"}, "downloads": -1, "filename": "thoth-pybench-0.0.3.tar.gz", "has_sig": false, "md5_digest": "0ec5cd2f535f55a0db09b25328946061", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34037, "upload_time": "2019-11-20T15:44:53", "upload_time_iso_8601": "2019-11-20T15:44:53.598739Z", "url": "https://files.pythonhosted.org/packages/98/c5/12e52e62d77eee64c77e93032f2734f11328277fd528d26c0e75f37a40a6/thoth-pybench-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "e8045a48c63e7288431710e861199e45", "sha256": "40201fafa17fb3396fc41295980742158ff4abb2f4f7cb936dd3796c9f8eecae"}, "downloads": -1, "filename": "thoth_pybench-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "e8045a48c63e7288431710e861199e45", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35312, "upload_time": "2019-11-20T16:28:04", "upload_time_iso_8601": "2019-11-20T16:28:04.546261Z", "url": "https://files.pythonhosted.org/packages/d1/a1/a6b5c506eb2cbc488d72368aa90935acc8e1560dd0851f89cdbb2dce0b3b/thoth_pybench-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e1348c9a5bdacb83c667f71a45a80b6f", "sha256": "f7d426f841f050ad26bafbfc331b7fbb76d8310a22b62e12a86646451b2a7c5f"}, "downloads": -1, "filename": "thoth-pybench-0.0.4.tar.gz", "has_sig": false, "md5_digest": "e1348c9a5bdacb83c667f71a45a80b6f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34112, "upload_time": "2019-11-20T16:28:07", "upload_time_iso_8601": "2019-11-20T16:28:07.838792Z", "url": "https://files.pythonhosted.org/packages/cc/98/2dcab75882ae68ee308e8fdd6de359910b46359de93f23654fd0eb2a6760/thoth-pybench-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "50568d8a8132a8b6c4f68842ac4ffb7e", "sha256": "29aa43b1dd156c44096390068bb20de5d9c641f2d66901918764cc39675a7511"}, "downloads": -1, "filename": "thoth_pybench-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "50568d8a8132a8b6c4f68842ac4ffb7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35312, "upload_time": "2019-11-20T17:41:59", "upload_time_iso_8601": "2019-11-20T17:41:59.946667Z", "url": "https://files.pythonhosted.org/packages/56/08/166fad8c1db195658e78fc0081a2a4ffad0651d99e1a8132bd4fe27a65a4/thoth_pybench-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0b96ac33a5930cead40f8b4620fafdde", "sha256": "5cb23480abd2b20bb58bf9432a5c91e22e4c876958fce28061cf1289e0f76af8"}, "downloads": -1, "filename": "thoth-pybench-0.0.5.tar.gz", "has_sig": false, "md5_digest": "0b96ac33a5930cead40f8b4620fafdde", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34099, "upload_time": "2019-11-20T17:42:04", "upload_time_iso_8601": "2019-11-20T17:42:04.350103Z", "url": "https://files.pythonhosted.org/packages/23/f4/b65183a71c003dbcc38c00ffec57e2021ae34fe2fd062ed67aeabb223306/thoth-pybench-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "bd0665bfcc4f62bc93c8a6d90eacb154", "sha256": "069eab0893f0280ef6c2c00946caee3abdb82a726947707dad07f2c73ea68cf4"}, "downloads": -1, "filename": "thoth_pybench-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "bd0665bfcc4f62bc93c8a6d90eacb154", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35334, "upload_time": "2019-11-22T12:49:13", "upload_time_iso_8601": "2019-11-22T12:49:13.787703Z", "url": "https://files.pythonhosted.org/packages/b8/21/dd167ddcd940bcc46d5e2776782d28fd85f082410ea17908cff77b2f226e/thoth_pybench-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "33723679db823abba9c4b0e2618da578", "sha256": "cfcf8b7bdbd7a5a65cd67247950c9dcc4369e84985ee0fa8e3a1aa027936a08e"}, "downloads": -1, "filename": "thoth-pybench-0.0.6.tar.gz", "has_sig": false, "md5_digest": "33723679db823abba9c4b0e2618da578", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34137, "upload_time": "2019-11-22T12:49:18", "upload_time_iso_8601": "2019-11-22T12:49:18.804523Z", "url": "https://files.pythonhosted.org/packages/02/af/0104211210c28b4b2e69cb8d2dc103f635114a8b38e8b1fc17856f526de1/thoth-pybench-0.0.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bd0665bfcc4f62bc93c8a6d90eacb154", "sha256": "069eab0893f0280ef6c2c00946caee3abdb82a726947707dad07f2c73ea68cf4"}, "downloads": -1, "filename": "thoth_pybench-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "bd0665bfcc4f62bc93c8a6d90eacb154", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35334, "upload_time": "2019-11-22T12:49:13", "upload_time_iso_8601": "2019-11-22T12:49:13.787703Z", "url": "https://files.pythonhosted.org/packages/b8/21/dd167ddcd940bcc46d5e2776782d28fd85f082410ea17908cff77b2f226e/thoth_pybench-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "33723679db823abba9c4b0e2618da578", "sha256": "cfcf8b7bdbd7a5a65cd67247950c9dcc4369e84985ee0fa8e3a1aa027936a08e"}, "downloads": -1, "filename": "thoth-pybench-0.0.6.tar.gz", "has_sig": false, "md5_digest": "33723679db823abba9c4b0e2618da578", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34137, "upload_time": "2019-11-22T12:49:18", "upload_time_iso_8601": "2019-11-22T12:49:18.804523Z", "url": "https://files.pythonhosted.org/packages/02/af/0104211210c28b4b2e69cb8d2dc103f635114a8b38e8b1fc17856f526de1/thoth-pybench-0.0.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:53:49 2020"}