{"info": {"author": "Winton Wang", "author_email": "365504029@qq.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved", "License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only", "Topic :: Software Development", "Topic :: Software Development :: Libraries"], "description": "=========\nTT-series\n=========\n\nHigh performance engine to store Time series data in Redis.\n\n|travis| |appveyor| |codecov| |codacy| |requirements| |docs| |pypi| |status| |pyversion|\n\n\nTT-series is based on redis sorted sets to store the time-series data, `Sorted set`_ store scores with\nunique numbers under a single key, but it has a weakness to store records, only unique members are allowed\nand trying to record a time-series entry with the same value as a previous will result in only updating the score.\nSo TT-series provide a solution to solve that problem.\n\nTT series normally can support redis version > 3.0, and will support **redis 5.0** in the future.\n\nTips\n====\n\n- **Max Store series length**\n\n    For 32 bit Redis on a 32 bit platform redis sorted sets can support maximum 2**32-1 members,\n    and for 64 bit redis on a 64 bit platform can support maximum 2**64-1 members.\n    But large amount of data would cause more CPU activity, so better keep a balance with length of records is\n    very important.\n\n- **Only Support Python 3.6**\n\n    Because python 3.6 changed the dictionary implementation for better performance,\n    so in Python 3.6 dictionaries are insertion ordered.\n    links: https://stackoverflow.com/questions/39980323/are-dictionaries-ordered-in-python-3-6\n\n- **Performance Tips**\n\n    With hiredis-py which it's targeted at speeding up parsing multi bulk replies from redis-server.\n    So with a large amount of bulk data insertion or getting from redis-server, it can improve a great performance improvement.\n\nInstall\n=======\n\nInstall python package from pip release::\n\n    pip install ttseries\n\n\nDocumentation\n=============\n\nFeatures\n--------\n\n1. Quick inserts 100,000 records (1-2 sec) and get slice of 100,000 records (0.4-0.5 sec).\n\n2. Support Data Serializer, Default Enable with MessagePack.\n\n3. Support Data Compression.\n\n4. In-order to void update previous records, Support Redis Hashes Time-Series storage format.\n\n5. Support Numpy ndarray data type.\n\n5. Support max length to auto to trim records.\n\n\nUsage\n-----\n\n\nTT-series provide three implementation to support different kinds of time-series data type.\n\n- ``RedisSimpleTimeSeries`` : Normally only base on Sorted sets to store records, previous records will impact the new inserting records which are **NOT** unique numbers.\n\n- ``RedisHashTimeSeries``: Use Redis Sorted sets with Hashes to store time-series data, User don't need to consider the data repeatability with records, but sorted sets with hashes would take some extra memories to store the keys.\n\n- ``RedisNumpyTimeSeries``: Support ``numpy.ndarray`` to store time-series records in redis sorted set.\n\n- ``RedisPandasTimeSeries``: Support ``pandas.DataFrame`` to store time-series records in redis sorted set.\n\nSerializer Data\n---------------\n\nTT-series use `MsgPack`_ to serializer data, because compare with other data serializer's solutions,\nMsgPack provide a better performance solution to serialize data. If user don't want to use MsgPack to\nserializer data, just inherit from ``ttseries.BaseSerializer`` class to implement the supported\nserializer class methods.\n\nExamples\n--------\n\n``RedisSimpleTimeSeries`` && ``RedisHashTimeSeries`` && ``RedisNumpyTimeSeries`` && ``RedisPandasTimeSeries``\n\nThree series data implementation provide the same functions and methods, in the usage will\nprovide the difference in the methods.\n\nPrepare data records:\n^^^^^^^^^^^^^^^^^^^^^\n\n.. sourcecode:: python\n\n    from datetime import datetime\n    from redis import StrictRedis\n\n    now = datetime.now()\n    timestamp = now.timestamp()\n\n    series_data = []\n\n    for i in range(1000):\n        series_data.append((timestamp+i,i))\n\n    client = StrictRedis() # redis client\n\n\nAdd records\n^^^^^^^^^^^\n\n.. sourcecode:: python\n\n    from ttseries import RedisSimpleTimeSeries\n\n    simple_series = RedisSimpleTimeSeries(client=client)\n\n    key = \"TEST:SIMPLE\"\n\n    simple_series.add_many(key, series_data)\n\n\n\nCount records length\n^^^^^^^^^^^^^^^^^^^^\n\nGet the length of the records or need just get the length from timestamp span.\n\n.. sourcecode:: python\n\n    # get the records length\n    simple_series.length(key)\n\n    # result: ...: 1000\n\n    # get the records length from start timestamp and end timestamp\n    simple_series.count(key, from_timestamp=timestamp, end_timestamp=timestamp+10)\n\n    # result: ...: 11\n\n\ntrim records\n^^^^^^^^^^^^\n\nTrim the records as the ASC.\n\n.. sourcecode:: python\n\n    simple_series.trim(key,10) # trim 10 length of records\n\n\ndelete timestamp span\n^^^^^^^^^^^^^^^^^^^^^\n\nDelete timestamp provide delete key or delete records from start timestamp to end timestamp.\n\n.. sourcecode:: python\n\n    simple_series.delete(key) # delete key with all records\n\n    simple_series.delete(key, start_timestamp=timestamp) # delete key form start timestamp\n\n\nGet Slice\n^^^^^^^^^\n\nGet slice form records provide start timestamp and end timestamp with **ASC** or **DESC** ordered.\n\nDefault Order: **ASC**\n\nIf user want to get the timestamp great than (>) or less than (<) which not including the timestamp record.\njust use ``(timestamp`` which support ``<timestamp`` or ``>timestamp`` sign format like this.\n\n.. sourcecode:: python\n\n    # get series data from start timestamp ordered as ASC.\n\n    simple_series.get_slice(key, start_timestamp=timestamp, acs=True)\n\n    # get series data from great than start timestamp order as ASC\n    simple_series.get_slice(key, start_timestamp=\"(\"+str(timestamp), asc=True)\n\n    # get series data from start timestamp and limit the numbers with 500\n    time_series.get_slice(key,start_timestamp=timestamp,limit=500)\n\n\niter\n^^^^\n\nyield item from records.\n\n.. sourcecode:: python\n\n    for item in simple_series.iter(key):\n        print(item)\n\n\n\nRedisNumpyTimeSeries\n^^^^^^^^^^^^^^^^^^^^\n\nNumpy array support provide ``numpy.dtype`` or just arrays with data.\n\nUse ``numpy.dtype`` to create records. must provide ``timestamp_column_name`` and ``dtype`` parameters.\n\n.. sourcecode:: python\n\n    import numpy as np\n    from ttseries import RedisNumpyTimeSeries\n\n    dtype = [(\"timestamp\",\"float64\"),(\"value\",\"i\")]\n\n    array = np.array(series_data, dtype=dtype)\n\n    np_series = RedisNumpyTimeSeries(client=client, dtype=dtype, timestamp_column_name=\"timestamp\")\n\n\nOr just numpy array without dtype, but must provide ``timestamp_column_index`` parameter.\n\n.. sourcecode:: python\n\n    array = np.array(series_data)\n\n    np_series = RedisNumpyTimeSeries(client=client,timestamp_column_index=0)\n\n\nRedisPandasTimeSeries\n^^^^^^^^^^^^^^^^^^^^^\n\nPandas TimeSeries use ``pandas.DataFrame`` to store time-series in redis.\nTo initialize the class must provide ``columns`` and ``dtypes`` parameters.\n\n1. ``columns`` parameter indicates the column names of the ``pandas.DataFrame``.\n\n2. ``dtypes`` indicates the dtype of each column in DataFrame, for example: ``{ \"value1\":\"int64\",\"value2\":\"float32\"}``\n   reference link: http://pbpython.com/pandas_dtypes.html\n\n.. sourcecode:: python\n\n    from datetime import datetime\n\n    key = \"AA:MIN\"\n    now = datetime.now()\n    columns = [\"value\"]\n    date_range = pandas.date_range(now, periods=10, freq=\"1min\")\n\n    data_frame = pandas.DataFrame([i + 1 for i in range(len(date_range))],\n                                index=date_range, columns=columns)\n\n\n    dtypes = {\"value\":\"int64\"}\n    pandas_ts = RedisPandasTimeSeries(client=client, columns=columns, dtypes=dtypes)\n\nAdd\n^^^\n\nAdd a time-series record to redis, ``series`` parameter indicates ``pandas.Series`` data type.\nand especial the ``series`` name value data type must be the ``pandas.DatetimeIndex``.\n\n.. sourcecode:: python\n\n    series_item = data_frame.iloc[0]\n    pandas_ts.add(key, series_item)\n\n\nadd_many\n^^^^^^^^\n\nAdd large amount of ``pandas.DataFrame`` into redis, with the ``dataframe`` index data type must be\nthe ``pandas.DatetimeIndex``.\nFor better insert performance, just use ``chunks_size`` to split the dataframe into fixed ``chunks_size``\nrows of dataframes.\n\n.. sourcecode:: python\n\n    pandas_ts.add_many(key, data_frame)\n\n\niter & Get\n^^^^^^^^^^\n\nretrieve records from redis sorted set, both of methods return ``pandas.Series``.\n\n.. sourcecode:: python\n\n    # yield all records data from redis\n    for item in pandas_ts.iter(key):\n        print(item)\n    # return one record with specific timestamp\n    pandas_ts.get(key, 1536157765.464465)\n\nget_slice\n^^^^^^^^^\n\nretrieve records to slice with ``start timestamp`` or ``end timestamp``, with ``limit`` length.\nreturn ``pandas.DataFrame``\n\n.. sourcecode:: python\n\n    # return records from start timestamp 1536157765.464465\n    result_frame = pandas_ts.get_slice(key, start_timestamp=1536157765.464465)\n\n    # return records from start timestamp 1536157765.464465 to end timestamp 1536157780.464465\n    result2_frame = padas_ts.get_slice(key, start_timestamp=1536157765.464465, end_timestamp=1536157780.464465)\n\n\nBenchmark\n=========\n\njust run ``make benchmark-init``, after then start ``make benchmark-test``.\n\nGo to the benchmark directory there exist an example of the benchmark test reports.\n\n\nTODO\n====\n\n1. Support Redis 5.0\n\n3. Support Redis cluster.\n\n\nAuthor\n======\n\n- Winton Wang\n\n\nDonate\n======\n\n\nContact\n=======\n\nEmail: 365504029@qq.com\n\n\nReference\n=========\n\nlinks: https://www.infoq.com/articles/redis-time-series\n\n\n.. _Sorted set: https://redis.io/commands#sorted_set\n.. _MsgPack: http://msgpack.org\n\n.. |travis| image:: https://travis-ci.org/nooperpudd/ttseries.svg?branch=master\n    :target: https://travis-ci.org/nooperpudd/ttseries\n\n.. |appveyor| image:: https://ci.appveyor.com/api/projects/status/ntlhwaagr5dqh341/branch/master?svg=true\n    :target: https://ci.appveyor.com/project/nooperpudd/ttseries\n\n.. |codecov| image:: https://codecov.io/gh/nooperpudd/ttseries/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/nooperpudd/ttseries\n\n.. |codacy| image:: https://api.codacy.com/project/badge/Grade/154fe60c6d2b4e59b8ee18baa56ad0a9\n    :target: https://www.codacy.com/app/nooperpudd/ttseries?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=nooperpudd/ttseries&amp;utm_campaign=Badge_Grade\n\n.. |pypi| image:: https://img.shields.io/pypi/v/ttseries.svg\n    :target: https://pypi.python.org/pypi/ttseries\n\n.. |status| image:: https://img.shields.io/pypi/status/ttseries.svg\n    :target: https://pypi.python.org/pypi/ttseries\n\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/ttseries.svg\n    :target: https://pypi.python.org/pypi/ttseries\n\n.. |requirements| image:: https://requires.io/github/nooperpudd/ttseries/requirements.svg?branch=master\n    :target: https://requires.io/github/nooperpudd/ttseries/requirements/?branch=master\n\n.. |docs| image:: https://readthedocs.org/projects/ttseries/badge/?version=latest\n    :target: http://ttseries.readthedocs.io/en/latest/?badge=latest", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/nooperpudd/ttseries", "keywords": "Time Series,Redis Time Series", "license": "LGPLv3", "maintainer": "", "maintainer_email": "", "name": "ttseries", "package_url": "https://pypi.org/project/ttseries/", "platform": "any", "project_url": "https://pypi.org/project/ttseries/", "project_urls": {"Homepage": "https://github.com/nooperpudd/ttseries"}, "release_url": "https://pypi.org/project/ttseries/0.2.1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Time series data store in Redis", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>High performance engine to store Time series data in Redis.</p>\n<p><a href=\"https://travis-ci.org/nooperpudd/ttseries\" rel=\"nofollow\"><img alt=\"travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0d93afeb628ffc08015d7a886e4f8e2491e36482/68747470733a2f2f7472617669732d63692e6f72672f6e6f6f706572707564642f74747365726965732e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://ci.appveyor.com/project/nooperpudd/ttseries\" rel=\"nofollow\"><img alt=\"appveyor\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d71cf782a66b2e5616fb451f0f1392be5458ae36/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6e746c687761616772356471683334312f6272616e63682f6d61737465723f7376673d74727565\"></a> <a href=\"https://codecov.io/gh/nooperpudd/ttseries\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/325f0af805d6ca8bfc9339710518e5b09223d441/68747470733a2f2f636f6465636f762e696f2f67682f6e6f6f706572707564642f74747365726965732f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a> <a href=\"https://www.codacy.com/app/nooperpudd/ttseries?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=nooperpudd/ttseries&amp;amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"codacy\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d82909b12e0dfea0a12b50062f038f08bf16cc83/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f3135346665363063366432623465353962386565313862616135366164306139\"></a> <a href=\"https://requires.io/github/nooperpudd/ttseries/requirements/?branch=master\" rel=\"nofollow\"><img alt=\"requirements\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/40e78f71b1cce384c90d1b09b5729825a8c8865e/68747470733a2f2f72657175697265732e696f2f6769746875622f6e6f6f706572707564642f74747365726965732f726571756972656d656e74732e7376673f6272616e63683d6d6173746572\"></a> <a href=\"http://ttseries.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"docs\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a5c0cff1ecc5d74b38a60bc1e1b47c4ebfd070eb/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f74747365726965732f62616467652f3f76657273696f6e3d6c6174657374\"></a> <a href=\"https://pypi.python.org/pypi/ttseries\" rel=\"nofollow\"><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6827141360a5ce9608e654de6f80393d0b802b7e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f74747365726965732e737667\"></a> <a href=\"https://pypi.python.org/pypi/ttseries\" rel=\"nofollow\"><img alt=\"status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/49ccc2785397c40d0cff00ddeaa47322a838035c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f7374617475732f74747365726965732e737667\"></a> <a href=\"https://pypi.python.org/pypi/ttseries\" rel=\"nofollow\"><img alt=\"pyversion\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/29f8ff58b0cb1fd20280acaee340365dcc919536/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f74747365726965732e737667\"></a></p>\n<p>TT-series is based on redis sorted sets to store the time-series data, <a href=\"https://redis.io/commands#sorted_set\" rel=\"nofollow\">Sorted set</a> store scores with\nunique numbers under a single key, but it has a weakness to store records, only unique members are allowed\nand trying to record a time-series entry with the same value as a previous will result in only updating the score.\nSo TT-series provide a solution to solve that problem.</p>\n<p>TT series normally can support redis version &gt; 3.0, and will support <strong>redis 5.0</strong> in the future.</p>\n<div id=\"tips\">\n<h2>Tips</h2>\n<ul>\n<li><p><strong>Max Store series length</strong></p>\n<blockquote>\n<p>For 32 bit Redis on a 32 bit platform redis sorted sets can support maximum 2**32-1 members,\nand for 64 bit redis on a 64 bit platform can support maximum 2**64-1 members.\nBut large amount of data would cause more CPU activity, so better keep a balance with length of records is\nvery important.</p>\n</blockquote>\n</li>\n<li><p><strong>Only Support Python 3.6</strong></p>\n<blockquote>\n<p>Because python 3.6 changed the dictionary implementation for better performance,\nso in Python 3.6 dictionaries are insertion ordered.\nlinks: <a href=\"https://stackoverflow.com/questions/39980323/are-dictionaries-ordered-in-python-3-6\" rel=\"nofollow\">https://stackoverflow.com/questions/39980323/are-dictionaries-ordered-in-python-3-6</a></p>\n</blockquote>\n</li>\n<li><p><strong>Performance Tips</strong></p>\n<blockquote>\n<p>With hiredis-py which it\u2019s targeted at speeding up parsing multi bulk replies from redis-server.\nSo with a large amount of bulk data insertion or getting from redis-server, it can improve a great performance improvement.</p>\n</blockquote>\n</li>\n</ul>\n</div>\n<div id=\"install\">\n<h2>Install</h2>\n<p>Install python package from pip release:</p>\n<pre>pip install ttseries\n</pre>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<div id=\"features\">\n<h3>Features</h3>\n<ol>\n<li>Quick inserts 100,000 records (1-2 sec) and get slice of 100,000 records (0.4-0.5 sec).</li>\n<li>Support Data Serializer, Default Enable with MessagePack.</li>\n<li>Support Data Compression.</li>\n<li>In-order to void update previous records, Support Redis Hashes Time-Series storage format.</li>\n<li>Support Numpy ndarray data type.</li>\n</ol>\n<ol>\n<li>Support max length to auto to trim records.</li>\n</ol>\n</div>\n<div id=\"usage\">\n<h3>Usage</h3>\n<p>TT-series provide three implementation to support different kinds of time-series data type.</p>\n<ul>\n<li><tt>RedisSimpleTimeSeries</tt> : Normally only base on Sorted sets to store records, previous records will impact the new inserting records which are <strong>NOT</strong> unique numbers.</li>\n<li><tt>RedisHashTimeSeries</tt>: Use Redis Sorted sets with Hashes to store time-series data, User don\u2019t need to consider the data repeatability with records, but sorted sets with hashes would take some extra memories to store the keys.</li>\n<li><tt>RedisNumpyTimeSeries</tt>: Support <tt>numpy.ndarray</tt> to store time-series records in redis sorted set.</li>\n<li><tt>RedisPandasTimeSeries</tt>: Support <tt>pandas.DataFrame</tt> to store time-series records in redis sorted set.</li>\n</ul>\n</div>\n<div id=\"serializer-data\">\n<h3>Serializer Data</h3>\n<p>TT-series use <a href=\"http://msgpack.org\" rel=\"nofollow\">MsgPack</a> to serializer data, because compare with other data serializer\u2019s solutions,\nMsgPack provide a better performance solution to serialize data. If user don\u2019t want to use MsgPack to\nserializer data, just inherit from <tt>ttseries.BaseSerializer</tt> class to implement the supported\nserializer class methods.</p>\n</div>\n<div id=\"examples\">\n<h3>Examples</h3>\n<p><tt>RedisSimpleTimeSeries</tt> &amp;&amp; <tt>RedisHashTimeSeries</tt> &amp;&amp; <tt>RedisNumpyTimeSeries</tt> &amp;&amp; <tt>RedisPandasTimeSeries</tt></p>\n<p>Three series data implementation provide the same functions and methods, in the usage will\nprovide the difference in the methods.</p>\n<div id=\"prepare-data-records\">\n<h4>Prepare data records:</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>\n<span class=\"kn\">from</span> <span class=\"nn\">redis</span> <span class=\"kn\">import</span> <span class=\"n\">StrictRedis</span>\n\n<span class=\"n\">now</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">now</span><span class=\"p\">()</span>\n<span class=\"n\">timestamp</span> <span class=\"o\">=</span> <span class=\"n\">now</span><span class=\"o\">.</span><span class=\"n\">timestamp</span><span class=\"p\">()</span>\n\n<span class=\"n\">series_data</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">):</span>\n    <span class=\"n\">series_data</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">((</span><span class=\"n\">timestamp</span><span class=\"o\">+</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">i</span><span class=\"p\">))</span>\n\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">StrictRedis</span><span class=\"p\">()</span> <span class=\"c1\"># redis client</span>\n</pre>\n</div>\n<div id=\"add-records\">\n<h4>Add records</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">ttseries</span> <span class=\"kn\">import</span> <span class=\"n\">RedisSimpleTimeSeries</span>\n\n<span class=\"n\">simple_series</span> <span class=\"o\">=</span> <span class=\"n\">RedisSimpleTimeSeries</span><span class=\"p\">(</span><span class=\"n\">client</span><span class=\"o\">=</span><span class=\"n\">client</span><span class=\"p\">)</span>\n\n<span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"s2\">\"TEST:SIMPLE\"</span>\n\n<span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">add_many</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">series_data</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"count-records-length\">\n<h4>Count records length</h4>\n<p>Get the length of the records or need just get the length from timestamp span.</p>\n<pre><span class=\"c1\"># get the records length</span>\n<span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">length</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># result: ...: 1000</span>\n\n<span class=\"c1\"># get the records length from start timestamp and end timestamp</span>\n<span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">count</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">from_timestamp</span><span class=\"o\">=</span><span class=\"n\">timestamp</span><span class=\"p\">,</span> <span class=\"n\">end_timestamp</span><span class=\"o\">=</span><span class=\"n\">timestamp</span><span class=\"o\">+</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># result: ...: 11</span>\n</pre>\n</div>\n<div id=\"trim-records\">\n<h4>trim records</h4>\n<p>Trim the records as the ASC.</p>\n<pre><span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">trim</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">)</span> <span class=\"c1\"># trim 10 length of records</span>\n</pre>\n</div>\n<div id=\"delete-timestamp-span\">\n<h4>delete timestamp span</h4>\n<p>Delete timestamp provide delete key or delete records from start timestamp to end timestamp.</p>\n<pre><span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">)</span> <span class=\"c1\"># delete key with all records</span>\n\n<span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">start_timestamp</span><span class=\"o\">=</span><span class=\"n\">timestamp</span><span class=\"p\">)</span> <span class=\"c1\"># delete key form start timestamp</span>\n</pre>\n</div>\n<div id=\"get-slice\">\n<h4>Get Slice</h4>\n<p>Get slice form records provide start timestamp and end timestamp with <strong>ASC</strong> or <strong>DESC</strong> ordered.</p>\n<p>Default Order: <strong>ASC</strong></p>\n<p>If user want to get the timestamp great than (&gt;) or less than (&lt;) which not including the timestamp record.\njust use <tt>(timestamp</tt> which support <tt>&lt;timestamp</tt> or <tt>&gt;timestamp</tt> sign format like this.</p>\n<pre><span class=\"c1\"># get series data from start timestamp ordered as ASC.</span>\n\n<span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">get_slice</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">start_timestamp</span><span class=\"o\">=</span><span class=\"n\">timestamp</span><span class=\"p\">,</span> <span class=\"n\">acs</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># get series data from great than start timestamp order as ASC</span>\n<span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">get_slice</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">start_timestamp</span><span class=\"o\">=</span><span class=\"s2\">\"(\"</span><span class=\"o\">+</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">timestamp</span><span class=\"p\">),</span> <span class=\"n\">asc</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># get series data from start timestamp and limit the numbers with 500</span>\n<span class=\"n\">time_series</span><span class=\"o\">.</span><span class=\"n\">get_slice</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span><span class=\"n\">start_timestamp</span><span class=\"o\">=</span><span class=\"n\">timestamp</span><span class=\"p\">,</span><span class=\"n\">limit</span><span class=\"o\">=</span><span class=\"mi\">500</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"iter\">\n<h4>iter</h4>\n<p>yield item from records.</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">simple_series</span><span class=\"o\">.</span><span class=\"n\">iter</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"redisnumpytimeseries\">\n<h4>RedisNumpyTimeSeries</h4>\n<p>Numpy array support provide <tt>numpy.dtype</tt> or just arrays with data.</p>\n<p>Use <tt>numpy.dtype</tt> to create records. must provide <tt>timestamp_column_name</tt> and <tt>dtype</tt> parameters.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ttseries</span> <span class=\"kn\">import</span> <span class=\"n\">RedisNumpyTimeSeries</span>\n\n<span class=\"n\">dtype</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"s2\">\"timestamp\"</span><span class=\"p\">,</span><span class=\"s2\">\"float64\"</span><span class=\"p\">),(</span><span class=\"s2\">\"value\"</span><span class=\"p\">,</span><span class=\"s2\">\"i\"</span><span class=\"p\">)]</span>\n\n<span class=\"n\">array</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">series_data</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">)</span>\n\n<span class=\"n\">np_series</span> <span class=\"o\">=</span> <span class=\"n\">RedisNumpyTimeSeries</span><span class=\"p\">(</span><span class=\"n\">client</span><span class=\"o\">=</span><span class=\"n\">client</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">timestamp_column_name</span><span class=\"o\">=</span><span class=\"s2\">\"timestamp\"</span><span class=\"p\">)</span>\n</pre>\n<p>Or just numpy array without dtype, but must provide <tt>timestamp_column_index</tt> parameter.</p>\n<pre><span class=\"n\">array</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">series_data</span><span class=\"p\">)</span>\n\n<span class=\"n\">np_series</span> <span class=\"o\">=</span> <span class=\"n\">RedisNumpyTimeSeries</span><span class=\"p\">(</span><span class=\"n\">client</span><span class=\"o\">=</span><span class=\"n\">client</span><span class=\"p\">,</span><span class=\"n\">timestamp_column_index</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"redispandastimeseries\">\n<h4>RedisPandasTimeSeries</h4>\n<p>Pandas TimeSeries use <tt>pandas.DataFrame</tt> to store time-series in redis.\nTo initialize the class must provide <tt>columns</tt> and <tt>dtypes</tt> parameters.</p>\n<ol>\n<li><tt>columns</tt> parameter indicates the column names of the <tt>pandas.DataFrame</tt>.</li>\n<li><tt>dtypes</tt> indicates the dtype of each column in DataFrame, for example: <tt>{ <span class=\"pre\">\"value1\":\"int64\",\"value2\":\"float32\"}</span></tt>\nreference link: <a href=\"http://pbpython.com/pandas_dtypes.html\" rel=\"nofollow\">http://pbpython.com/pandas_dtypes.html</a></li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span>\n\n<span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"s2\">\"AA:MIN\"</span>\n<span class=\"n\">now</span> <span class=\"o\">=</span> <span class=\"n\">datetime</span><span class=\"o\">.</span><span class=\"n\">now</span><span class=\"p\">()</span>\n<span class=\"n\">columns</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"value\"</span><span class=\"p\">]</span>\n<span class=\"n\">date_range</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">date_range</span><span class=\"p\">(</span><span class=\"n\">now</span><span class=\"p\">,</span> <span class=\"n\">periods</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">freq</span><span class=\"o\">=</span><span class=\"s2\">\"1min\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">data_frame</span> <span class=\"o\">=</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">([</span><span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">1</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">date_range</span><span class=\"p\">))],</span>\n                            <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"n\">date_range</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">columns</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">dtypes</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"value\"</span><span class=\"p\">:</span><span class=\"s2\">\"int64\"</span><span class=\"p\">}</span>\n<span class=\"n\">pandas_ts</span> <span class=\"o\">=</span> <span class=\"n\">RedisPandasTimeSeries</span><span class=\"p\">(</span><span class=\"n\">client</span><span class=\"o\">=</span><span class=\"n\">client</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">columns</span><span class=\"p\">,</span> <span class=\"n\">dtypes</span><span class=\"o\">=</span><span class=\"n\">dtypes</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"add\">\n<h4>Add</h4>\n<p>Add a time-series record to redis, <tt>series</tt> parameter indicates <tt>pandas.Series</tt> data type.\nand especial the <tt>series</tt> name value data type must be the <tt>pandas.DatetimeIndex</tt>.</p>\n<pre><span class=\"n\">series_item</span> <span class=\"o\">=</span> <span class=\"n\">data_frame</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">pandas_ts</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">series_item</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"add-many\">\n<h4>add_many</h4>\n<p>Add large amount of <tt>pandas.DataFrame</tt> into redis, with the <tt>dataframe</tt> index data type must be\nthe <tt>pandas.DatetimeIndex</tt>.\nFor better insert performance, just use <tt>chunks_size</tt> to split the dataframe into fixed <tt>chunks_size</tt>\nrows of dataframes.</p>\n<pre><span class=\"n\">pandas_ts</span><span class=\"o\">.</span><span class=\"n\">add_many</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">data_frame</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"iter-get\">\n<h4>iter &amp; Get</h4>\n<p>retrieve records from redis sorted set, both of methods return <tt>pandas.Series</tt>.</p>\n<pre><span class=\"c1\"># yield all records data from redis</span>\n<span class=\"k\">for</span> <span class=\"n\">item</span> <span class=\"ow\">in</span> <span class=\"n\">pandas_ts</span><span class=\"o\">.</span><span class=\"n\">iter</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">item</span><span class=\"p\">)</span>\n<span class=\"c1\"># return one record with specific timestamp</span>\n<span class=\"n\">pandas_ts</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"mf\">1536157765.464465</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"id1\">\n<h4>get_slice</h4>\n<p>retrieve records to slice with <tt>start timestamp</tt> or <tt>end timestamp</tt>, with <tt>limit</tt> length.\nreturn <tt>pandas.DataFrame</tt></p>\n<pre><span class=\"c1\"># return records from start timestamp 1536157765.464465</span>\n<span class=\"n\">result_frame</span> <span class=\"o\">=</span> <span class=\"n\">pandas_ts</span><span class=\"o\">.</span><span class=\"n\">get_slice</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">start_timestamp</span><span class=\"o\">=</span><span class=\"mf\">1536157765.464465</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># return records from start timestamp 1536157765.464465 to end timestamp 1536157780.464465</span>\n<span class=\"n\">result2_frame</span> <span class=\"o\">=</span> <span class=\"n\">padas_ts</span><span class=\"o\">.</span><span class=\"n\">get_slice</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">start_timestamp</span><span class=\"o\">=</span><span class=\"mf\">1536157765.464465</span><span class=\"p\">,</span> <span class=\"n\">end_timestamp</span><span class=\"o\">=</span><span class=\"mf\">1536157780.464465</span><span class=\"p\">)</span>\n</pre>\n</div>\n</div>\n</div>\n<div id=\"benchmark\">\n<h2>Benchmark</h2>\n<p>just run <tt>make <span class=\"pre\">benchmark-init</span></tt>, after then start <tt>make <span class=\"pre\">benchmark-test</span></tt>.</p>\n<p>Go to the benchmark directory there exist an example of the benchmark test reports.</p>\n</div>\n<div id=\"todo\">\n<h2>TODO</h2>\n<ol>\n<li>Support Redis 5.0</li>\n</ol>\n<ol>\n<li>Support Redis cluster.</li>\n</ol>\n</div>\n<div id=\"author\">\n<h2>Author</h2>\n<ul>\n<li>Winton Wang</li>\n</ul>\n</div>\n<div id=\"donate\">\n<h2>Donate</h2>\n</div>\n<div id=\"contact\">\n<h2>Contact</h2>\n<p>Email: <a href=\"mailto:365504029%40qq.com\">365504029<span>@</span>qq<span>.</span>com</a></p>\n</div>\n<div id=\"reference\">\n<h2>Reference</h2>\n<p>links: <a href=\"https://www.infoq.com/articles/redis-time-series\" rel=\"nofollow\">https://www.infoq.com/articles/redis-time-series</a></p>\n</div>\n\n          </div>"}, "last_serial": 5175979, "releases": {"0.1.3": [{"comment_text": "", "digests": {"md5": "c24d011c0de5df5513a25f73aa7d32d7", "sha256": "b35177553d5a699c970ce063fb557ea3ad1c467576dfc2b33da2e122c913a530"}, "downloads": -1, "filename": "ttseries-0.1.3.tar.gz", "has_sig": false, "md5_digest": "c24d011c0de5df5513a25f73aa7d32d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17124, "upload_time": "2018-06-03T14:27:52", "upload_time_iso_8601": "2018-06-03T14:27:52.379943Z", "url": "https://files.pythonhosted.org/packages/7f/8b/409b861112ab506c28d6a219fb942ec064584666ae924e6e6e5faaf901f2/ttseries-0.1.3.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "faecd131fa81d8bf78b8cbc03e62c7b2", "sha256": "0c1a971b4129a1744bdaba3980b6c4c134c7c2a53407c86c0485c9b62443c633"}, "downloads": -1, "filename": "ttseries-0.1.7.tar.gz", "has_sig": false, "md5_digest": "faecd131fa81d8bf78b8cbc03e62c7b2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 25270, "upload_time": "2018-09-05T15:09:40", "upload_time_iso_8601": "2018-09-05T15:09:40.045651Z", "url": "https://files.pythonhosted.org/packages/a6/48/02be996fec353fee6acf964edaf151cfad61da2a218c4909d721848fc62c/ttseries-0.1.7.tar.gz", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "c8f8ed485ff8a3c300c467a316000a51", "sha256": "6afc6fb9ec771bf8f8c52160802b8db31ebe9d055bca493ffd05cb750ea71486"}, "downloads": -1, "filename": "ttseries-0.1.8.tar.gz", "has_sig": false, "md5_digest": "c8f8ed485ff8a3c300c467a316000a51", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20812, "upload_time": "2018-09-18T14:42:10", "upload_time_iso_8601": "2018-09-18T14:42:10.661431Z", "url": "https://files.pythonhosted.org/packages/70/05/d902e54a18a3ee201857d6c69bb2cc6ac4299cfa0cc37a09a02f553cfd4b/ttseries-0.1.8.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "e39edbba7f95fe65463e4a02287018ce", "sha256": "b60cdadea757e80ff7660e59938c9982848367aa510ed9bc8d7cccf8f2a49c54"}, "downloads": -1, "filename": "ttseries-0.2.0.tar.gz", "has_sig": false, "md5_digest": "e39edbba7f95fe65463e4a02287018ce", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20717, "upload_time": "2019-02-09T06:41:19", "upload_time_iso_8601": "2019-02-09T06:41:19.593431Z", "url": "https://files.pythonhosted.org/packages/2b/a4/ac3dbd9323324606e95d449ac1442573be63b4dc358b4d9b11fb48ac563f/ttseries-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "cf9f6bd47ace71bec50d123d5c1ed853", "sha256": "5f03879fe3631973f4c92c50d3167682f6011655a95a718b17357d34eabdca63"}, "downloads": -1, "filename": "ttseries-0.2.1.tar.gz", "has_sig": false, "md5_digest": "cf9f6bd47ace71bec50d123d5c1ed853", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20371, "upload_time": "2019-04-23T08:18:11", "upload_time_iso_8601": "2019-04-23T08:18:11.386890Z", "url": "https://files.pythonhosted.org/packages/40/11/a52f10a952dd51e2d308002cf9294c404d008257335cc02fe567777388ad/ttseries-0.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cf9f6bd47ace71bec50d123d5c1ed853", "sha256": "5f03879fe3631973f4c92c50d3167682f6011655a95a718b17357d34eabdca63"}, "downloads": -1, "filename": "ttseries-0.2.1.tar.gz", "has_sig": false, "md5_digest": "cf9f6bd47ace71bec50d123d5c1ed853", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20371, "upload_time": "2019-04-23T08:18:11", "upload_time_iso_8601": "2019-04-23T08:18:11.386890Z", "url": "https://files.pythonhosted.org/packages/40/11/a52f10a952dd51e2d308002cf9294c404d008257335cc02fe567777388ad/ttseries-0.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:44:56 2020"}