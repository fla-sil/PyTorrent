{"info": {"author": "Leigh Johnson", "author_email": "hi@leighjohnson.me", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# Raspberry Pi Deep PanTilt\n\n[![image](https://img.shields.io/pypi/v/rpi_deep_pantilt.svg)](https://pypi.python.org/pypi/rpi-deep-pantilt)\n\n<!-- [![image](https://img.shields.io/travis/leigh-johnson/rpi_deep_pantilt.svg)](https://travis-ci.org/leigh-johnson/rpi_deep_pantilt) -->\n\n[![Documentation\nStatus](https://readthedocs.org/projects/rpi-deep-pantilt/badge/?version=latest)](https://rpi-deep-pantilt.readthedocs.io/en/latest/?badge=latest)\n\n# READ THIS FIRST!\n\nA detailed walk-through is available in [Real-time Object Tracking with TensorFlow, Raspberry Pi, and Pan-tilt HAT](https://medium.com/@grepLeigh/real-time-object-tracking-with-tensorflow-raspberry-pi-and-pan-tilt-hat-2aeaef47e134).\n\n# Build List\n\n  - [Raspberry Pi 4 (4GB recommended)](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)\n  - [Raspberry Pi Camera V2](https://www.raspberrypi.org/products/camera-module-v2/)\n  - [Pimoroni Pan-tilt Kit](https://shop.pimoroni.com/products/pan-tilt-hat?variant=22408353287)\n  - Micro SD card 16+ GB\n  - Micro HDMI Cable\n  - [12\" CSI/DSI ribbon for Raspberry Pi Camera](https://www.adafruit.com/product/1648) (optional, but highly recommended)\n  - [Coral Edge TPU USB Accelerator](https://coral.withgoogle.com/products/accelerator) (optional)\n  - [RGB NeoPixel Stick](https://www.adafruit.com/product/1426) (optional, makes lighting conditions more consistent)\n\nAn example of deep object detection and tracking with a Raspberry Pi\n\n  - Free software: MIT license\n  - Documentation: <https://rpi-deep-pantilt.readthedocs.io>.\n\n# Basic Setup\n\nBefore you get started, you should have an up-to-date installation of Raspbian 10 (Buster) running on your Raspberry Pi. You'll also need to configure SSH access into your Pi. \n\n* [Install Raspbian](https://www.raspberrypi.org/documentation/installation/installing-images/README.md)\n* [Configure WiFi](https://www.raspberrypi.org/forums/viewtopic.php?t=191252)\n* [Configure SSH Access](https://www.raspberrypi.org/documentation/remote-access/ssh/)\n\n# Installation\n\n1. Install system dependencies\n\n```bash\nsudo apt-get update && sudo apt-get install -y \\\n    cmake python3-dev libjpeg-dev libatlas-base-dev raspi-gpio libhdf5-dev python3-smbus\n```\n\n2. Install TensorFlow 2.0 (community-built wheel)\n\n```bash\npip install https://github.com/leigh-johnson/Tensorflow-bin/blob/master/tensorflow-2.0.0-cp37-cp37m-linux_armv7l.whl?raw=true\n\n```\n\n3. Install the `rpi-deep-pantilt` package.\n\n```bash\npip install rpi-deep-pantilt\n```\n\n# Example Usage\n\n## Object Detection\n\nThe following will start a PiCamera preview and render detected objects as an overlay. Verify you're able to detect an object before trying to track it. \n\nSupports Edge TPU acceleration by passing the `--edge-tpu` option.\n\n`rpi-deep-pantilt detect`\n\n```\nrpi-deep-pantilt detect --help\n\nUsage: rpi-deep-pantilt detect [OPTIONS]\n\nOptions:\n  --loglevel TEXT  Run object detection without pan-tilt controls. Pass\n                   --loglevel=DEBUG to inspect FPS.\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n```\n\n## Object Tracking\n\nThe following will start a PiCamera preview, render detected objects as an overlay, and track an object's movement with the pan-tilt HAT. \n\nBy default, this will track any `person` in the frame. You can track other objects by passing `--label <label>`. For a list of valid labels, run `rpi-deep-pantilt list-labels`. \n\n`rpi-deep-pantilt track`\n\nSupports Edge TPU acceleration by passing the `--edge-tpu` option.\n\n```\nrpi-deep-pantilt track --help \nUsage: cli.py track [OPTIONS]\n\nOptions:\n  --label TEXT     The class label to track, e.g `orange`. Run `rpi-deep-\n                   pantilt list-labels` to inspect all valid values\n                   [required]\n  --loglevel TEXT\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n```\n\n## Valid labels for Object Detection/Tracking\n\n`rpi-deep-pantilt list-labels`\n\nThe following labels are valid tracking targets.\n\n```\n['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n```\n\n## Face Detection (NEW in v1.1.x)\n\nThe following command will detect all faces. Supports Edge TPU acceleration by passing the `--edge-tpu` option.\n\n```\nrpi-deep-pantilt face-detect --help\nUsage: cli.py face-detect [OPTIONS]\n\nOptions:\n  --loglevel TEXT  Run object detection without pan-tilt controls. Pass\n                   --loglevel=DEBUG to inspect FPS.\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n```\n\n## Face Tracking (NEW in v1.1.x)\n\nThe following command will track between all faces in a frame. Supports Edge TPU acceleration by passing the `--edge-tpu` option.\n\n```\nrpi-deep-pantilt face-detect --help\nUsage: cli.py face-detect [OPTIONS]\n\nOptions:\n  --loglevel TEXT  Run object detection without pan-tilt controls. Pass\n                   --loglevel=DEBUG to inspect FPS.\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n```\n\n# Model Summary\n\nThe following section describes the models used in this project. \n\n## Object Detection & Tracking\n\n### `FLOAT32` model (`ssd_mobilenet_v3_small_coco_2019_08_14`)\n\n`rpi-deep-pantilt detect` and `rpi-deep-pantilt track` perform inferences using this model. Bounding box and class predictions render at roughly *6 FPS* on a *Raspberry Pi 4*.  \n\nThe model is derived from  `ssd_mobilenet_v3_small_coco_2019_08_14` in [tensorflow/models](https://github.com/tensorflow/models). I extended the model with an NMS post-processing layer, then converted to a format compatible with TensorFlow 2.x (FlatBuffer). \n\nI scripted the conversion steps in `tools/tflite-postprocess-ops-float.sh`. \n\n\n### Quantized `UINT8` model (`ssdlite_mobilenet_edgetpu_coco_quant`)\n\nIf you specify `--edge-tpu` option, `rpi-deep-pantilt detect` and `rpi-deep-pantilt track` perform inferences using this model. Rounding box and class predictions render at roughly *24+ FPS (real-time) on Raspberry Pi 4*.\n\nThis model *REQUIRES* a [Coral Edge TPU USB Accelerator](https://coral.withgoogle.com/products/accelerator) to run.\n\nThis model is derived from  `ssdlite_mobilenet_edgetpu_coco_quant` in [tensorflow/models](https://github.com/tensorflow/models). I reversed the frozen `.tflite` model into a protobuf graph to add an NMS post-processing layer, quantized the model in a `.tflite` FlatBuffer format, then converted using Coral's `edgetpu_compiler` tool. \n\nI scripted the conversion steps in `tools/tflite-postprocess-ops-128-uint8-quant.sh` and `tools/tflite-edgetpu.sh`. \n\n## Face Detection & Tracking\n\nI was able to use the same model architechture for FLOAT32 and UINT8 input, `facessd_mobilenet_v2_quantized_320x320_open_image_v4_tflite2`. \n\nThis model is derived from `facessd_mobilenet_v2_quantized_320x320_open_image_v4` in [tensorflow/models](https://github.com/tensorflow/models). \n\n# Credits\n\nThe MobileNetV3-SSD model in this package was derived from [TensorFlow's model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md), with [post-processing ops added](https://gist.github.com/leigh-johnson/155264e343402c761c03bc0640074d8c).\n\nThe PID control scheme in this package was inspired by [Adrian Rosebrock](https://github.com/jrosebr1) tutorial [Pan/tilt face tracking with a Raspberry Pi and OpenCV](https://www.pyimagesearch.com/2019/04/01/pan-tilt-face-tracking-with-a-raspberry-pi-and-opencv/)\n\nThis package was created with\n[Cookiecutter](https://github.com/audreyr/cookiecutter) and the\n[audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage)\nproject template.\n\n\n# History\n\n## 1.0.0 (2019-12-01)\n\n  - First release on PyPI.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/leigh-johnson/rpi-deep-pantilt", "keywords": "computer vision cv tensorflow raspberrypi detection tracking", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "rpi-deep-pantilt", "package_url": "https://pypi.org/project/rpi-deep-pantilt/", "platform": "", "project_url": "https://pypi.org/project/rpi-deep-pantilt/", "project_urls": {"Homepage": "https://github.com/leigh-johnson/rpi-deep-pantilt"}, "release_url": "https://pypi.org/project/rpi-deep-pantilt/1.1.0/", "requires_dist": ["Click (>=7.0)", "pillow", "h5py", "smbus ; platform_machine == \"armv7l\"", "picamera ; platform_machine == \"armv7l\"", "pantilthat (>=0.0.7) ; platform_machine == \"armv7l\"", "tensorflow (==2.0.0) ; platform_machine == \"x86_64\"", "numpy ; platform_machine == \"x86_64\""], "requires_python": ">=3.7", "summary": "An example of deep object detection and tracking with a Raspberry Pi, PiCamera, and Pimoroni Pantilt Hat", "version": "1.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Raspberry Pi Deep PanTilt</h1>\n<p><a href=\"https://pypi.python.org/pypi/rpi-deep-pantilt\" rel=\"nofollow\"><img alt=\"image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4214cfc403f4a88a6a25e31855ac2f0b727006ba/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7270695f646565705f70616e74696c742e737667\"></a></p>\n\n<p><a href=\"https://rpi-deep-pantilt.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/183c20d9f624d0fa957840b26efce87949c0817a/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7270692d646565702d70616e74696c742f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<h1>READ THIS FIRST!</h1>\n<p>A detailed walk-through is available in <a href=\"https://medium.com/@grepLeigh/real-time-object-tracking-with-tensorflow-raspberry-pi-and-pan-tilt-hat-2aeaef47e134\" rel=\"nofollow\">Real-time Object Tracking with TensorFlow, Raspberry Pi, and Pan-tilt HAT</a>.</p>\n<h1>Build List</h1>\n<ul>\n<li><a href=\"https://www.raspberrypi.org/products/raspberry-pi-4-model-b/\" rel=\"nofollow\">Raspberry Pi 4 (4GB recommended)</a></li>\n<li><a href=\"https://www.raspberrypi.org/products/camera-module-v2/\" rel=\"nofollow\">Raspberry Pi Camera V2</a></li>\n<li><a href=\"https://shop.pimoroni.com/products/pan-tilt-hat?variant=22408353287\" rel=\"nofollow\">Pimoroni Pan-tilt Kit</a></li>\n<li>Micro SD card 16+ GB</li>\n<li>Micro HDMI Cable</li>\n<li><a href=\"https://www.adafruit.com/product/1648\" rel=\"nofollow\">12\" CSI/DSI ribbon for Raspberry Pi Camera</a> (optional, but highly recommended)</li>\n<li><a href=\"https://coral.withgoogle.com/products/accelerator\" rel=\"nofollow\">Coral Edge TPU USB Accelerator</a> (optional)</li>\n<li><a href=\"https://www.adafruit.com/product/1426\" rel=\"nofollow\">RGB NeoPixel Stick</a> (optional, makes lighting conditions more consistent)</li>\n</ul>\n<p>An example of deep object detection and tracking with a Raspberry Pi</p>\n<ul>\n<li>Free software: MIT license</li>\n<li>Documentation: <a href=\"https://rpi-deep-pantilt.readthedocs.io\" rel=\"nofollow\">https://rpi-deep-pantilt.readthedocs.io</a>.</li>\n</ul>\n<h1>Basic Setup</h1>\n<p>Before you get started, you should have an up-to-date installation of Raspbian 10 (Buster) running on your Raspberry Pi. You'll also need to configure SSH access into your Pi.</p>\n<ul>\n<li><a href=\"https://www.raspberrypi.org/documentation/installation/installing-images/README.md\" rel=\"nofollow\">Install Raspbian</a></li>\n<li><a href=\"https://www.raspberrypi.org/forums/viewtopic.php?t=191252\" rel=\"nofollow\">Configure WiFi</a></li>\n<li><a href=\"https://www.raspberrypi.org/documentation/remote-access/ssh/\" rel=\"nofollow\">Configure SSH Access</a></li>\n</ul>\n<h1>Installation</h1>\n<ol>\n<li>Install system dependencies</li>\n</ol>\n<pre>sudo apt-get update <span class=\"o\">&amp;&amp;</span> sudo apt-get install -y <span class=\"se\">\\</span>\n    cmake python3-dev libjpeg-dev libatlas-base-dev raspi-gpio libhdf5-dev python3-smbus\n</pre>\n<ol>\n<li>Install TensorFlow 2.0 (community-built wheel)</li>\n</ol>\n<pre>pip install https://github.com/leigh-johnson/Tensorflow-bin/blob/master/tensorflow-2.0.0-cp37-cp37m-linux_armv7l.whl?raw<span class=\"o\">=</span><span class=\"nb\">true</span>\n</pre>\n<ol>\n<li>Install the <code>rpi-deep-pantilt</code> package.</li>\n</ol>\n<pre>pip install rpi-deep-pantilt\n</pre>\n<h1>Example Usage</h1>\n<h2>Object Detection</h2>\n<p>The following will start a PiCamera preview and render detected objects as an overlay. Verify you're able to detect an object before trying to track it.</p>\n<p>Supports Edge TPU acceleration by passing the <code>--edge-tpu</code> option.</p>\n<p><code>rpi-deep-pantilt detect</code></p>\n<pre><code>rpi-deep-pantilt detect --help\n\nUsage: rpi-deep-pantilt detect [OPTIONS]\n\nOptions:\n  --loglevel TEXT  Run object detection without pan-tilt controls. Pass\n                   --loglevel=DEBUG to inspect FPS.\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n</code></pre>\n<h2>Object Tracking</h2>\n<p>The following will start a PiCamera preview, render detected objects as an overlay, and track an object's movement with the pan-tilt HAT.</p>\n<p>By default, this will track any <code>person</code> in the frame. You can track other objects by passing <code>--label &lt;label&gt;</code>. For a list of valid labels, run <code>rpi-deep-pantilt list-labels</code>.</p>\n<p><code>rpi-deep-pantilt track</code></p>\n<p>Supports Edge TPU acceleration by passing the <code>--edge-tpu</code> option.</p>\n<pre><code>rpi-deep-pantilt track --help \nUsage: cli.py track [OPTIONS]\n\nOptions:\n  --label TEXT     The class label to track, e.g `orange`. Run `rpi-deep-\n                   pantilt list-labels` to inspect all valid values\n                   [required]\n  --loglevel TEXT\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n</code></pre>\n<h2>Valid labels for Object Detection/Tracking</h2>\n<p><code>rpi-deep-pantilt list-labels</code></p>\n<p>The following labels are valid tracking targets.</p>\n<pre><code>['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n</code></pre>\n<h2>Face Detection (NEW in v1.1.x)</h2>\n<p>The following command will detect all faces. Supports Edge TPU acceleration by passing the <code>--edge-tpu</code> option.</p>\n<pre><code>rpi-deep-pantilt face-detect --help\nUsage: cli.py face-detect [OPTIONS]\n\nOptions:\n  --loglevel TEXT  Run object detection without pan-tilt controls. Pass\n                   --loglevel=DEBUG to inspect FPS.\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n</code></pre>\n<h2>Face Tracking (NEW in v1.1.x)</h2>\n<p>The following command will track between all faces in a frame. Supports Edge TPU acceleration by passing the <code>--edge-tpu</code> option.</p>\n<pre><code>rpi-deep-pantilt face-detect --help\nUsage: cli.py face-detect [OPTIONS]\n\nOptions:\n  --loglevel TEXT  Run object detection without pan-tilt controls. Pass\n                   --loglevel=DEBUG to inspect FPS.\n  --edge-tpu       Accelerate inferences using Coral USB Edge TPU\n  --help           Show this message and exit.\n</code></pre>\n<h1>Model Summary</h1>\n<p>The following section describes the models used in this project.</p>\n<h2>Object Detection &amp; Tracking</h2>\n<h3><code>FLOAT32</code> model (<code>ssd_mobilenet_v3_small_coco_2019_08_14</code>)</h3>\n<p><code>rpi-deep-pantilt detect</code> and <code>rpi-deep-pantilt track</code> perform inferences using this model. Bounding box and class predictions render at roughly <em>6 FPS</em> on a <em>Raspberry Pi 4</em>.</p>\n<p>The model is derived from  <code>ssd_mobilenet_v3_small_coco_2019_08_14</code> in <a href=\"https://github.com/tensorflow/models\" rel=\"nofollow\">tensorflow/models</a>. I extended the model with an NMS post-processing layer, then converted to a format compatible with TensorFlow 2.x (FlatBuffer).</p>\n<p>I scripted the conversion steps in <code>tools/tflite-postprocess-ops-float.sh</code>.</p>\n<h3>Quantized <code>UINT8</code> model (<code>ssdlite_mobilenet_edgetpu_coco_quant</code>)</h3>\n<p>If you specify <code>--edge-tpu</code> option, <code>rpi-deep-pantilt detect</code> and <code>rpi-deep-pantilt track</code> perform inferences using this model. Rounding box and class predictions render at roughly <em>24+ FPS (real-time) on Raspberry Pi 4</em>.</p>\n<p>This model <em>REQUIRES</em> a <a href=\"https://coral.withgoogle.com/products/accelerator\" rel=\"nofollow\">Coral Edge TPU USB Accelerator</a> to run.</p>\n<p>This model is derived from  <code>ssdlite_mobilenet_edgetpu_coco_quant</code> in <a href=\"https://github.com/tensorflow/models\" rel=\"nofollow\">tensorflow/models</a>. I reversed the frozen <code>.tflite</code> model into a protobuf graph to add an NMS post-processing layer, quantized the model in a <code>.tflite</code> FlatBuffer format, then converted using Coral's <code>edgetpu_compiler</code> tool.</p>\n<p>I scripted the conversion steps in <code>tools/tflite-postprocess-ops-128-uint8-quant.sh</code> and <code>tools/tflite-edgetpu.sh</code>.</p>\n<h2>Face Detection &amp; Tracking</h2>\n<p>I was able to use the same model architechture for FLOAT32 and UINT8 input, <code>facessd_mobilenet_v2_quantized_320x320_open_image_v4_tflite2</code>.</p>\n<p>This model is derived from <code>facessd_mobilenet_v2_quantized_320x320_open_image_v4</code> in <a href=\"https://github.com/tensorflow/models\" rel=\"nofollow\">tensorflow/models</a>.</p>\n<h1>Credits</h1>\n<p>The MobileNetV3-SSD model in this package was derived from <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\" rel=\"nofollow\">TensorFlow's model zoo</a>, with <a href=\"https://gist.github.com/leigh-johnson/155264e343402c761c03bc0640074d8c\" rel=\"nofollow\">post-processing ops added</a>.</p>\n<p>The PID control scheme in this package was inspired by <a href=\"https://github.com/jrosebr1\" rel=\"nofollow\">Adrian Rosebrock</a> tutorial <a href=\"https://www.pyimagesearch.com/2019/04/01/pan-tilt-face-tracking-with-a-raspberry-pi-and-opencv/\" rel=\"nofollow\">Pan/tilt face tracking with a Raspberry Pi and OpenCV</a></p>\n<p>This package was created with\n<a href=\"https://github.com/audreyr/cookiecutter\" rel=\"nofollow\">Cookiecutter</a> and the\n<a href=\"https://github.com/audreyr/cookiecutter-pypackage\" rel=\"nofollow\">audreyr/cookiecutter-pypackage</a>\nproject template.</p>\n<h1>History</h1>\n<h2>1.0.0 (2019-12-01)</h2>\n<ul>\n<li>First release on PyPI.</li>\n</ul>\n\n          </div>"}, "last_serial": 6598990, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "2cb165d48b9e4a5af4208bb0086c335d", "sha256": "d6a00db4a987ebc9ed25aed741fccc623b244dae34d0db971445f0002634b768"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.0.tar.gz", "has_sig": false, "md5_digest": "2cb165d48b9e4a5af4208bb0086c335d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32647, "upload_time": "2019-12-04T06:08:28", "upload_time_iso_8601": "2019-12-04T06:08:28.785737Z", "url": "https://files.pythonhosted.org/packages/57/2e/b193e379f03fc59b51ae613c80d42e79b965a308f30b60265ae6d8a0d373/rpi_deep_pantilt-1.0.0.tar.gz", "yanked": false}], "1.0.0rc0": [{"comment_text": "", "digests": {"md5": "cf83ef5c60b0405b4bc12457fc6ff90a", "sha256": "d7e1460322a6939ea55dae787fe9c3896afabff99d9dfced153043ed172f38b2"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.0rc0.tar.gz", "has_sig": false, "md5_digest": "cf83ef5c60b0405b4bc12457fc6ff90a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 18776, "upload_time": "2019-12-02T02:00:41", "upload_time_iso_8601": "2019-12-02T02:00:41.611296Z", "url": "https://files.pythonhosted.org/packages/51/1f/8e22f89b6e2eb6dcf519dba3c7a1dd2c3658befe4bfe372f2a3a0d9dde94/rpi_deep_pantilt-1.0.0rc0.tar.gz", "yanked": false}], "1.0.0rc1": [{"comment_text": "", "digests": {"md5": "8f9b3d9a3cbddd82569e7cd9c1dc397f", "sha256": "4bd0bcc26d3935554b5bba385aa3bc8cfda20860c56223fba94b13fe4715fdd2"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.0rc1.tar.gz", "has_sig": false, "md5_digest": "8f9b3d9a3cbddd82569e7cd9c1dc397f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 18834, "upload_time": "2019-12-02T02:04:18", "upload_time_iso_8601": "2019-12-02T02:04:18.252592Z", "url": "https://files.pythonhosted.org/packages/83/db/3b31086a8e8201c8725856c03556f3d35cc755928ec8575df64e53389436/rpi_deep_pantilt-1.0.0rc1.tar.gz", "yanked": false}], "1.0.0rc3": [{"comment_text": "", "digests": {"md5": "fa3e39b12447034e52ad5c5526b4506f", "sha256": "9d83ab7b77e542c773121c2c54d186dd0e06cd9507e34b621072cd2678b07ad1"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.0rc3.tar.gz", "has_sig": false, "md5_digest": "fa3e39b12447034e52ad5c5526b4506f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 26853, "upload_time": "2019-12-02T03:44:23", "upload_time_iso_8601": "2019-12-02T03:44:23.158601Z", "url": "https://files.pythonhosted.org/packages/91/d0/aba792a5fc8d50b8e7fcbd24ceb438d106cc9eb294760211468bf3400f6f/rpi_deep_pantilt-1.0.0rc3.tar.gz", "yanked": false}], "1.0.0rc4": [{"comment_text": "", "digests": {"md5": "e6fcd4f8ee4160bf47584600aa720861", "sha256": "089a21668c6b4729da2e9af0aeba8778f3afce9654194cab2908b3a6421b3676"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.0rc4.tar.gz", "has_sig": false, "md5_digest": "e6fcd4f8ee4160bf47584600aa720861", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32204, "upload_time": "2019-12-03T07:25:42", "upload_time_iso_8601": "2019-12-03T07:25:42.192102Z", "url": "https://files.pythonhosted.org/packages/df/7c/88284dc79ccd094c934b7b07f2b08ade14aa3a830762a6a21727008865f8/rpi_deep_pantilt-1.0.0rc4.tar.gz", "yanked": false}], "1.0.0rc5": [{"comment_text": "", "digests": {"md5": "69a78fa3409e4b44e5dc3aa4c4bc772f", "sha256": "b00dd480099a2500b08c6ec9d96edacce6ee4b19f630e27a4d52e1bec38bbe95"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.0rc5.tar.gz", "has_sig": false, "md5_digest": "69a78fa3409e4b44e5dc3aa4c4bc772f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 32025, "upload_time": "2019-12-03T07:48:22", "upload_time_iso_8601": "2019-12-03T07:48:22.654109Z", "url": "https://files.pythonhosted.org/packages/d0/bf/4c25b32bcebd86557db323b4a19ff89b1850c77566536bc6843aac3d2665/rpi_deep_pantilt-1.0.0rc5.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "c90bf19703b013bd2185bfa1491f4403", "sha256": "e11ac84174c2f0119d1e27bc6de84ae52a08913acb526ba396b1cfb085beaa33"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.0.1.tar.gz", "has_sig": false, "md5_digest": "c90bf19703b013bd2185bfa1491f4403", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 33492, "upload_time": "2019-12-09T04:08:40", "upload_time_iso_8601": "2019-12-09T04:08:40.668598Z", "url": "https://files.pythonhosted.org/packages/e3/cb/175536d907392f1417f8c68a66a5a5c56db545536620dc7ee7286307d79b/rpi_deep_pantilt-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "d787cae2537c94c6b1ebfc1df86c3cf4", "sha256": "395ddc2a959b05fba9f977240c38bc6b8b2df0f133b87787a8a27ac15e33c043"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d787cae2537c94c6b1ebfc1df86c3cf4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.7", "size": 28024, "upload_time": "2020-02-09T20:20:05", "upload_time_iso_8601": "2020-02-09T20:20:05.269646Z", "url": "https://files.pythonhosted.org/packages/31/89/1036b52c34b9be8bb49d1cb0633028cc6084579466c6fe63ec86b5e5c6b2/rpi_deep_pantilt-1.1.0-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d787cae2537c94c6b1ebfc1df86c3cf4", "sha256": "395ddc2a959b05fba9f977240c38bc6b8b2df0f133b87787a8a27ac15e33c043"}, "downloads": -1, "filename": "rpi_deep_pantilt-1.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d787cae2537c94c6b1ebfc1df86c3cf4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.7", "size": 28024, "upload_time": "2020-02-09T20:20:05", "upload_time_iso_8601": "2020-02-09T20:20:05.269646Z", "url": "https://files.pythonhosted.org/packages/31/89/1036b52c34b9be8bb49d1cb0633028cc6084579466c6fe63ec86b5e5c6b2/rpi_deep_pantilt-1.1.0-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:00:56 2020"}