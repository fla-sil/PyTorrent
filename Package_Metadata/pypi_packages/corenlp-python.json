{"info": {"author": "Hiroyoshi Komatsu", "author_email": "hiroyoshi.komat@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v2 or later (GPLv2+)", "Programming Language :: Python"], "description": "# A Python wrapper for the Java Stanford Core NLP tools\r\n---------------------------\r\n\r\nThis is a fork of Dustin Smith's [stanford-corenlp-python](https://github.com/dasmith/stanford-corenlp-python), a Python interface to [Stanford CoreNLP](http://nlp.stanford.edu/software/corenlp.shtml). It can either use as a python package, or run as a JSON-RPC server.\r\n\r\n## Updates from the original wrapper\r\n   * Supports Stanford CoreNLP v3.x.x (compatible with recent versions)\r\n   * Fixed many bugs & improved performance\r\n   * Adjusted parameters not to timeout in high load\r\n   * Using jsonrpclib for stability and performance\r\n   * Batch parser for long text which supports sentiment analysis\r\n   * Python 3 compatibility (thanks to Valentin Lorentz)\r\n   * [Packaging](https://pypi.python.org/pypi/corenlp-python)\r\n\r\n## Requirements\r\n   * [pexpect](http://www.noah.org/wiki/pexpect)\r\n   * [jsonrpclib](https://github.com/joshmarshall/jsonrpclib) (optionally)\r\n\r\n## Download and Usage\r\n\r\nTo use this program you must [download](http://nlp.stanford.edu/software/corenlp.shtml#Download) and unpack the zip file containing Stanford's CoreNLP package.  By default, `corenlp.py` looks for the Stanford Core NLP folder as a subdirectory of where the script is being run.\r\n\r\n\r\nIn other words:\r\n\r\n    sudo pip install pexpect unidecode jsonrpclib   # jsonrpclib is optional\r\n    git clone https://bitbucket.org/torotoki/corenlp-python.git\r\n\t  cd corenlp-python\r\n    # assuming the version 3.4.1 of Stanford CoreNLP\r\n    wget http://nlp.stanford.edu/software/stanford-corenlp-full-2014-08-27.zip\r\n    unzip stanford-corenlp-full-2014-08-27.zip\r\n\r\nThen, to launch a server:\r\n\r\n    python corenlp/corenlp.py\r\n\r\nOptionally, you can specify a host or port:\r\n\r\n    python corenlp/corenlp.py -H 0.0.0.0 -p 3456\r\n\r\nThat will run a public JSON-RPC server on port 3456.\r\nAnd you can specify Stanford CoreNLP directory:\r\n\r\n    python corenlp/corenlp.py -S stanford-corenlp-full-2014-08-27/\r\n\r\n\r\nAssuming you are running on port 8080 and CoreNLP directory is `stanford-corenlp-full-2014-08-27/` in current directory, this wrapper supports recently version around of 3.4.1 which has same output format.\r\n\r\nThe code in `client.py` shows an example parse:\r\n\r\n    import jsonrpclib\r\n    from simplejson import loads\r\n    server = jsonrpclib.Server(\"http://localhost:8080\")\r\n\r\n    result = loads(server.parse(\"Hello world.  It is so beautiful\"))\r\n    print \"Result\", result\r\n\r\nThat returns a dictionary containing the keys `sentences` and (when applicable) `corefs`. The key `sentences` contains a list of dictionaries for each sentence, which contain `parsetree`, `text`, `tuples` containing the dependencies, and `words`, containing information about parts of speech, NER, etc:\r\n\r\n\t{u'sentences': [{u'parsetree': u'(ROOT (S (VP (NP (INTJ (UH Hello)) (NP (NN world)))) (. !)))',\r\n\t                 u'text': u'Hello world!',\r\n\t                 u'tuples': [[u'dep', u'world', u'Hello'],\r\n\t                             [u'root', u'ROOT', u'world']],\r\n\t                 u'words': [[u'Hello',\r\n\t                             {u'CharacterOffsetBegin': u'0',\r\n\t                              u'CharacterOffsetEnd': u'5',\r\n\t                              u'Lemma': u'hello',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'UH'}],\r\n\t                            [u'world',\r\n\t                             {u'CharacterOffsetBegin': u'6',\r\n\t                              u'CharacterOffsetEnd': u'11',\r\n\t                              u'Lemma': u'world',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'NN'}],\r\n\t                            [u'!',\r\n\t                             {u'CharacterOffsetBegin': u'11',\r\n\t                              u'CharacterOffsetEnd': u'12',\r\n\t                              u'Lemma': u'!',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'.'}]]},\r\n\t                {u'parsetree': u'(ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (RB so) (JJ beautiful))) (. .)))',\r\n\t                 u'text': u'It is so beautiful.',\r\n\t                 u'tuples': [[u'nsubj', u'beautiful', u'It'],\r\n\t                             [u'cop', u'beautiful', u'is'],\r\n\t                             [u'advmod', u'beautiful', u'so'],\r\n\t                             [u'root', u'ROOT', u'beautiful']],\r\n\t                 u'words': [[u'It',\r\n\t                             {u'CharacterOffsetBegin': u'14',\r\n\t                              u'CharacterOffsetEnd': u'16',\r\n\t                              u'Lemma': u'it',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'PRP'}],\r\n\t                            [u'is',\r\n\t                             {u'CharacterOffsetBegin': u'17',\r\n\t                              u'CharacterOffsetEnd': u'19',\r\n\t                              u'Lemma': u'be',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'VBZ'}],\r\n\t                            [u'so',\r\n\t                             {u'CharacterOffsetBegin': u'20',\r\n\t                              u'CharacterOffsetEnd': u'22',\r\n\t                              u'Lemma': u'so',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'RB'}],\r\n\t                            [u'beautiful',\r\n\t                             {u'CharacterOffsetBegin': u'23',\r\n\t                              u'CharacterOffsetEnd': u'32',\r\n\t                              u'Lemma': u'beautiful',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'JJ'}],\r\n\t                            [u'.',\r\n\t                             {u'CharacterOffsetBegin': u'32',\r\n\t                              u'CharacterOffsetEnd': u'33',\r\n\t                              u'Lemma': u'.',\r\n\t                              u'NamedEntityTag': u'O',\r\n\t                              u'PartOfSpeech': u'.'}]]}],\r\n\tu'coref': [[[[u'It', 1, 0, 0, 1], [u'Hello world', 0, 1, 0, 2]]]]}\r\n\r\nNot to use JSON-RPC, load the module instead:\r\n\r\n    from corenlp import StanfordCoreNLP\r\n    corenlp_dir = \"stanford-corenlp-full-2014-08-27/\"\r\n    corenlp = StanfordCoreNLP(corenlp_dir)  # wait a few minutes...\r\n    corenlp.raw_parse(\"Parse it\")\r\n\r\nIf you need to parse long texts (more than 30-50 sentences), you must use a `batch_parse` function. It reads text files from input directory and returns a generator object of dictionaries parsed each file results:\r\n\r\n    from corenlp import batch_parse\r\n    corenlp_dir = \"stanford-corenlp-full-2014-08-27/\"\r\n    raw_text_directory = \"sample_raw_text/\"\r\n    parsed = batch_parse(raw_text_directory, corenlp_dir)  # It returns a generator object\r\n    print parsed  #=> [{'coref': ..., 'sentences': ..., 'file_name': 'new_sample.txt'}]\r\n\r\nThe function uses XML output feature of Stanford CoreNLP, and you can take all information by `raw_output` option. If true, CoreNLP's XML is returned as a dictionary without converting the format.\r\n\r\n    parsed = batch_parse(raw_text_directory, corenlp_dir, raw_output=True)\r\n\r\n(Note: The function requires xmltodict now, you should install it by `sudo pip install xmltodict`)\r\n\r\n\r\n### Note\r\n\r\n* JSON-RPC server [halts on large text](https://bitbucket.org/torotoki/corenlp-python/issue/7/server-halts-on-large-text). it maybe because of restriction of stdout, you should use the batch parser or [an other wrapper](https://github.com/brendano/stanford_corenlp_pywrapper).\r\n\r\n* JSON-RPC server doesn't support sentiment analysis tools because original CoreNLP tools don't output sentiment results to stdout yet (batch parser's output includes sentiment results retrieved from the original CoreNLP tools's XML output)\r\n\r\n## License\r\n\r\ncorenlp-python is licensed under the GNU General Public License (v2 or later). Note that this is the /full/ GPL, which allows many free uses, but not its use in distributed proprietary software.\r\n\r\n## Developer\r\n   * Hiroyoshi Komatsu [hiroyoshi.komat@gmail.com]\r\n   * Johannes Castner [jac2130@columbia.edu]", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://bitbucket.org/torotoki/corenlp-python", "keywords": null, "license": "UNKNOWN", "maintainer": null, "maintainer_email": null, "name": "corenlp-python", "package_url": "https://pypi.org/project/corenlp-python/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/corenlp-python/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://bitbucket.org/torotoki/corenlp-python"}, "release_url": "https://pypi.org/project/corenlp-python/3.4.1-1/", "requires_dist": null, "requires_python": null, "summary": "A Stanford Core NLP wrapper", "version": "3.4.1-1", "yanked": false, "html_description": "<div class=\"project-description\">\n            # A Python wrapper for the Java Stanford Core NLP tools\n<br>---------------------------\n<br>\n<br>This is a fork of Dustin Smith's [stanford-corenlp-python](https://github.com/dasmith/stanford-corenlp-python), a Python interface to [Stanford CoreNLP](http://nlp.stanford.edu/software/corenlp.shtml). It can either use as a python package, or run as a JSON-RPC server.\n<br>\n<br>## Updates from the original wrapper\n<br>   * Supports Stanford CoreNLP v3.x.x (compatible with recent versions)\n<br>   * Fixed many bugs &amp; improved performance\n<br>   * Adjusted parameters not to timeout in high load\n<br>   * Using jsonrpclib for stability and performance\n<br>   * Batch parser for long text which supports sentiment analysis\n<br>   * Python 3 compatibility (thanks to Valentin Lorentz)\n<br>   * [Packaging](https://pypi.python.org/pypi/corenlp-python)\n<br>\n<br>## Requirements\n<br>   * [pexpect](http://www.noah.org/wiki/pexpect)\n<br>   * [jsonrpclib](https://github.com/joshmarshall/jsonrpclib) (optionally)\n<br>\n<br>## Download and Usage\n<br>\n<br>To use this program you must [download](http://nlp.stanford.edu/software/corenlp.shtml#Download) and unpack the zip file containing Stanford's CoreNLP package.  By default, `corenlp.py` looks for the Stanford Core NLP folder as a subdirectory of where the script is being run.\n<br>\n<br>\n<br>In other words:\n<br>\n<br>    sudo pip install pexpect unidecode jsonrpclib   # jsonrpclib is optional\n<br>    git clone https://bitbucket.org/torotoki/corenlp-python.git\n<br>\t  cd corenlp-python\n<br>    # assuming the version 3.4.1 of Stanford CoreNLP\n<br>    wget http://nlp.stanford.edu/software/stanford-corenlp-full-2014-08-27.zip\n<br>    unzip stanford-corenlp-full-2014-08-27.zip\n<br>\n<br>Then, to launch a server:\n<br>\n<br>    python corenlp/corenlp.py\n<br>\n<br>Optionally, you can specify a host or port:\n<br>\n<br>    python corenlp/corenlp.py -H 0.0.0.0 -p 3456\n<br>\n<br>That will run a public JSON-RPC server on port 3456.\n<br>And you can specify Stanford CoreNLP directory:\n<br>\n<br>    python corenlp/corenlp.py -S stanford-corenlp-full-2014-08-27/\n<br>\n<br>\n<br>Assuming you are running on port 8080 and CoreNLP directory is `stanford-corenlp-full-2014-08-27/` in current directory, this wrapper supports recently version around of 3.4.1 which has same output format.\n<br>\n<br>The code in `client.py` shows an example parse:\n<br>\n<br>    import jsonrpclib\n<br>    from simplejson import loads\n<br>    server = jsonrpclib.Server(\"http://localhost:8080\")\n<br>\n<br>    result = loads(server.parse(\"Hello world.  It is so beautiful\"))\n<br>    print \"Result\", result\n<br>\n<br>That returns a dictionary containing the keys `sentences` and (when applicable) `corefs`. The key `sentences` contains a list of dictionaries for each sentence, which contain `parsetree`, `text`, `tuples` containing the dependencies, and `words`, containing information about parts of speech, NER, etc:\n<br>\n<br>\t{u'sentences': [{u'parsetree': u'(ROOT (S (VP (NP (INTJ (UH Hello)) (NP (NN world)))) (. !)))',\n<br>\t                 u'text': u'Hello world!',\n<br>\t                 u'tuples': [[u'dep', u'world', u'Hello'],\n<br>\t                             [u'root', u'ROOT', u'world']],\n<br>\t                 u'words': [[u'Hello',\n<br>\t                             {u'CharacterOffsetBegin': u'0',\n<br>\t                              u'CharacterOffsetEnd': u'5',\n<br>\t                              u'Lemma': u'hello',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'UH'}],\n<br>\t                            [u'world',\n<br>\t                             {u'CharacterOffsetBegin': u'6',\n<br>\t                              u'CharacterOffsetEnd': u'11',\n<br>\t                              u'Lemma': u'world',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'NN'}],\n<br>\t                            [u'!',\n<br>\t                             {u'CharacterOffsetBegin': u'11',\n<br>\t                              u'CharacterOffsetEnd': u'12',\n<br>\t                              u'Lemma': u'!',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'.'}]]},\n<br>\t                {u'parsetree': u'(ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (RB so) (JJ beautiful))) (. .)))',\n<br>\t                 u'text': u'It is so beautiful.',\n<br>\t                 u'tuples': [[u'nsubj', u'beautiful', u'It'],\n<br>\t                             [u'cop', u'beautiful', u'is'],\n<br>\t                             [u'advmod', u'beautiful', u'so'],\n<br>\t                             [u'root', u'ROOT', u'beautiful']],\n<br>\t                 u'words': [[u'It',\n<br>\t                             {u'CharacterOffsetBegin': u'14',\n<br>\t                              u'CharacterOffsetEnd': u'16',\n<br>\t                              u'Lemma': u'it',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'PRP'}],\n<br>\t                            [u'is',\n<br>\t                             {u'CharacterOffsetBegin': u'17',\n<br>\t                              u'CharacterOffsetEnd': u'19',\n<br>\t                              u'Lemma': u'be',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'VBZ'}],\n<br>\t                            [u'so',\n<br>\t                             {u'CharacterOffsetBegin': u'20',\n<br>\t                              u'CharacterOffsetEnd': u'22',\n<br>\t                              u'Lemma': u'so',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'RB'}],\n<br>\t                            [u'beautiful',\n<br>\t                             {u'CharacterOffsetBegin': u'23',\n<br>\t                              u'CharacterOffsetEnd': u'32',\n<br>\t                              u'Lemma': u'beautiful',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'JJ'}],\n<br>\t                            [u'.',\n<br>\t                             {u'CharacterOffsetBegin': u'32',\n<br>\t                              u'CharacterOffsetEnd': u'33',\n<br>\t                              u'Lemma': u'.',\n<br>\t                              u'NamedEntityTag': u'O',\n<br>\t                              u'PartOfSpeech': u'.'}]]}],\n<br>\tu'coref': [[[[u'It', 1, 0, 0, 1], [u'Hello world', 0, 1, 0, 2]]]]}\n<br>\n<br>Not to use JSON-RPC, load the module instead:\n<br>\n<br>    from corenlp import StanfordCoreNLP\n<br>    corenlp_dir = \"stanford-corenlp-full-2014-08-27/\"\n<br>    corenlp = StanfordCoreNLP(corenlp_dir)  # wait a few minutes...\n<br>    corenlp.raw_parse(\"Parse it\")\n<br>\n<br>If you need to parse long texts (more than 30-50 sentences), you must use a `batch_parse` function. It reads text files from input directory and returns a generator object of dictionaries parsed each file results:\n<br>\n<br>    from corenlp import batch_parse\n<br>    corenlp_dir = \"stanford-corenlp-full-2014-08-27/\"\n<br>    raw_text_directory = \"sample_raw_text/\"\n<br>    parsed = batch_parse(raw_text_directory, corenlp_dir)  # It returns a generator object\n<br>    print parsed  #=&gt; [{'coref': ..., 'sentences': ..., 'file_name': 'new_sample.txt'}]\n<br>\n<br>The function uses XML output feature of Stanford CoreNLP, and you can take all information by `raw_output` option. If true, CoreNLP's XML is returned as a dictionary without converting the format.\n<br>\n<br>    parsed = batch_parse(raw_text_directory, corenlp_dir, raw_output=True)\n<br>\n<br>(Note: The function requires xmltodict now, you should install it by `sudo pip install xmltodict`)\n<br>\n<br>\n<br>### Note\n<br>\n<br>* JSON-RPC server [halts on large text](https://bitbucket.org/torotoki/corenlp-python/issue/7/server-halts-on-large-text). it maybe because of restriction of stdout, you should use the batch parser or [an other wrapper](https://github.com/brendano/stanford_corenlp_pywrapper).\n<br>\n<br>* JSON-RPC server doesn't support sentiment analysis tools because original CoreNLP tools don't output sentiment results to stdout yet (batch parser's output includes sentiment results retrieved from the original CoreNLP tools's XML output)\n<br>\n<br>## License\n<br>\n<br>corenlp-python is licensed under the GNU General Public License (v2 or later). Note that this is the /full/ GPL, which allows many free uses, but not its use in distributed proprietary software.\n<br>\n<br>## Developer\n<br>   * Hiroyoshi Komatsu [hiroyoshi.komat@gmail.com]\n<br>   * Johannes Castner [jac2130@columbia.edu]\n          </div>"}, "last_serial": 1281866, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "b62d579b1b02462b9648e833c4816463", "sha256": "99f7d9977df2bc59d4c29e5b7fdd54e2155f995090097a5537365be0b9fc3d48"}, "downloads": -1, "filename": "corenlp-python-1.0.1.tar.gz", "has_sig": false, "md5_digest": "b62d579b1b02462b9648e833c4816463", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4080, "upload_time": "2013-04-28T18:09:18", "upload_time_iso_8601": "2013-04-28T18:09:18.799244Z", "url": "https://files.pythonhosted.org/packages/50/3b/21c8975115107e313654b46f4ec8249796f02625f6670d054c842b51d74a/corenlp-python-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "116e26287e835d26a1368e8efdf31022", "sha256": "992a4a44f2d2e2eff334d4e24ca76ade7e5a2617003f525cb5b4f559a4506f35"}, "downloads": -1, "filename": "corenlp-python-1.0.2.tar.gz", "has_sig": false, "md5_digest": "116e26287e835d26a1368e8efdf31022", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11297, "upload_time": "2013-04-28T18:37:18", "upload_time_iso_8601": "2013-04-28T18:37:18.676600Z", "url": "https://files.pythonhosted.org/packages/a1/69/a6b01f2d9e55e3dd57964b39c3f28ccb83100deddf193b6e1878d185f6d7/corenlp-python-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "7c0f979dbbf2a4aece4e975d2ef5bb0e", "sha256": "a36826130e20231edf69973f6ad8788b7036511d8838579da1773fc503a755b4"}, "downloads": -1, "filename": "corenlp-python-1.0.3.tar.gz", "has_sig": false, "md5_digest": "7c0f979dbbf2a4aece4e975d2ef5bb0e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13017, "upload_time": "2013-04-29T17:42:51", "upload_time_iso_8601": "2013-04-29T17:42:51.940421Z", "url": "https://files.pythonhosted.org/packages/b8/93/625ac8f8fce844db1c5109f4db31b44d76929097884e177e35703c5b6ee3/corenlp-python-1.0.3.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "63bb46b11542ce0cb403db7a5da0ef60", "sha256": "a17585dfbdaf81dbeaff37b8a1699f3cd63c9e2c989d4e8f27c9f6458f545860"}, "downloads": -1, "filename": "corenlp-python-1.1.0.tar.gz", "has_sig": false, "md5_digest": "63bb46b11542ce0cb403db7a5da0ef60", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14762, "upload_time": "2013-05-17T14:20:47", "upload_time_iso_8601": "2013-05-17T14:20:47.909172Z", "url": "https://files.pythonhosted.org/packages/00/7f/987562aa895c3e7063eb16a97c78ea5244fbe1b42c79a51780cc216688a4/corenlp-python-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "ae7ebd713302307ecf0c5f422f4ab72a", "sha256": "bfbbf8d80b72b87cf3364518dcb28f27601ad8b70552e9973a35bd6b70043070"}, "downloads": -1, "filename": "corenlp-python-1.1.1.tar.gz", "has_sig": false, "md5_digest": "ae7ebd713302307ecf0c5f422f4ab72a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22329, "upload_time": "2013-05-17T23:25:39", "upload_time_iso_8601": "2013-05-17T23:25:39.758922Z", "url": "https://files.pythonhosted.org/packages/88/18/a9cf87b21b70d58230768a15e349fc84fe3d32444920da7588a5fbcbb4f8/corenlp-python-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "12cfb89258473cf5d8654430b5ca303c", "sha256": "d8873191fa892dd4335a9cb71bd7171597629cccc3f8e1d4e84716c90838f4fa"}, "downloads": -1, "filename": "corenlp-python-1.1.2.tar.gz", "has_sig": false, "md5_digest": "12cfb89258473cf5d8654430b5ca303c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20760, "upload_time": "2013-05-24T20:20:00", "upload_time_iso_8601": "2013-05-24T20:20:00.650856Z", "url": "https://files.pythonhosted.org/packages/b8/20/77d302a026299e05dfe09fbb9862aa9b38c9ca2cce8f6910ea5458f8fc08/corenlp-python-1.1.2.tar.gz", "yanked": false}], "1.1.3": [{"comment_text": "", "digests": {"md5": "03547605f88c24c571085858b8b967cd", "sha256": "9040438e3ac007f5bb4deb3fed9aa865b5011b3cc16ea3e1482b11867dc2a5d7"}, "downloads": -1, "filename": "corenlp-python-1.1.3.tar.gz", "has_sig": false, "md5_digest": "03547605f88c24c571085858b8b967cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20319, "upload_time": "2013-06-14T18:45:04", "upload_time_iso_8601": "2013-06-14T18:45:04.836207Z", "url": "https://files.pythonhosted.org/packages/7c/9e/75663bbecfab8a3c5df8f8c4e284bc44bf0e280f65ac7a08e7b7067d93c5/corenlp-python-1.1.3.tar.gz", "yanked": false}], "2.3.0-0": [{"comment_text": "", "digests": {"md5": "49148098d44d50bfc91e1aadf87814a9", "sha256": "63aad0f9767aa92592a6384205aa6b8b0870e546020423335997bcf3d78d4819"}, "downloads": -1, "filename": "corenlp-python-2.3.0-0.tar.gz", "has_sig": false, "md5_digest": "49148098d44d50bfc91e1aadf87814a9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20554, "upload_time": "2013-06-21T05:49:44", "upload_time_iso_8601": "2013-06-21T05:49:44.936698Z", "url": "https://files.pythonhosted.org/packages/ba/89/058a0e570ec1830c6bb02e45814bfb64d5b7fd91d25300f7b4c8acbdba27/corenlp-python-2.3.0-0.tar.gz", "yanked": false}], "3.2.0-3": [{"comment_text": "", "digests": {"md5": "500d3cb5427432d773ad4eea61e1a43e", "sha256": "49dd0a17066b641c3878f42da19d3472d8e910446a41bf92f852a65dbafeb102"}, "downloads": -1, "filename": "corenlp-python-3.2.0-3.tar.gz", "has_sig": false, "md5_digest": "500d3cb5427432d773ad4eea61e1a43e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21192, "upload_time": "2013-09-03T18:29:41", "upload_time_iso_8601": "2013-09-03T18:29:41.622724Z", "url": "https://files.pythonhosted.org/packages/2a/a6/65b8b4c5abf58d4d6db886a70c9f97df48a2c519a3b352cb71bfe9448b5a/corenlp-python-3.2.0-3.tar.gz", "yanked": false}], "3.3.0-1": [{"comment_text": "", "digests": {"md5": "198f151b8fdc58132839afefeb48b057", "sha256": "3b322459b22840eacdc73a09635f8c5be42a179d02f45d057d07904b98e17cd7"}, "downloads": -1, "filename": "corenlp-python-3.3.0-1.tar.gz", "has_sig": false, "md5_digest": "198f151b8fdc58132839afefeb48b057", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21800, "upload_time": "2014-09-09T02:18:10", "upload_time_iso_8601": "2014-09-09T02:18:10.069357Z", "url": "https://files.pythonhosted.org/packages/b5/23/184bbf2844454b8dfe5474232acc45c2befac6dc1d615fd5bd2c5a17cb71/corenlp-python-3.3.0-1.tar.gz", "yanked": false}], "3.3.0-2": [{"comment_text": "", "digests": {"md5": "e26be117638e34eb166bd35d63b308fe", "sha256": "8a343ccbe70432b2710f982cd12154f9fbf0b957c518d2849d1fcb582db65fde"}, "downloads": -1, "filename": "corenlp-python-3.3.0-2.tar.gz", "has_sig": false, "md5_digest": "e26be117638e34eb166bd35d63b308fe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21787, "upload_time": "2014-09-09T02:19:12", "upload_time_iso_8601": "2014-09-09T02:19:12.708910Z", "url": "https://files.pythonhosted.org/packages/4d/75/090a4c4795fa9f95df2b32eb4c5dc150531e23da104c3886f89685e1976e/corenlp-python-3.3.0-2.tar.gz", "yanked": false}], "3.4.1-0": [{"comment_text": "", "digests": {"md5": "9bd1c0167820aec1c5abaaa72ee75dd0", "sha256": "0a46685f753effc0f5360c51529acb9a37fbb0d04eb576cf79c168cbbfd76dc3"}, "downloads": -1, "filename": "corenlp-python-3.4.1-0.tar.gz", "has_sig": false, "md5_digest": "9bd1c0167820aec1c5abaaa72ee75dd0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22023, "upload_time": "2014-10-15T04:53:36", "upload_time_iso_8601": "2014-10-15T04:53:36.253336Z", "url": "https://files.pythonhosted.org/packages/02/b1/b00cb3d3bf7cb719f15c295580bdc5b3bb80fb5efd1fad07b182565a2c43/corenlp-python-3.4.1-0.tar.gz", "yanked": false}], "3.4.1-1": [{"comment_text": "", "digests": {"md5": "1e5c7483f2e2a9d4870dd8de3ef994f1", "sha256": "d1e1aa8ecb4ed3e99af32c75ab203275e1bef19aae5ab98c7bdb72f9835c037e"}, "downloads": -1, "filename": "corenlp-python-3.4.1-1.tar.gz", "has_sig": false, "md5_digest": "1e5c7483f2e2a9d4870dd8de3ef994f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22210, "upload_time": "2014-10-24T19:55:30", "upload_time_iso_8601": "2014-10-24T19:55:30.616604Z", "url": "https://files.pythonhosted.org/packages/49/ae/70dac020f59aa0ac6c3b9dd2994c4f3473a37683d92ec6ab7b00caeb9d7c/corenlp-python-3.4.1-1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1e5c7483f2e2a9d4870dd8de3ef994f1", "sha256": "d1e1aa8ecb4ed3e99af32c75ab203275e1bef19aae5ab98c7bdb72f9835c037e"}, "downloads": -1, "filename": "corenlp-python-3.4.1-1.tar.gz", "has_sig": false, "md5_digest": "1e5c7483f2e2a9d4870dd8de3ef994f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22210, "upload_time": "2014-10-24T19:55:30", "upload_time_iso_8601": "2014-10-24T19:55:30.616604Z", "url": "https://files.pythonhosted.org/packages/49/ae/70dac020f59aa0ac6c3b9dd2994c4f3473a37683d92ec6ab7b00caeb9d7c/corenlp-python-3.4.1-1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:11 2020"}