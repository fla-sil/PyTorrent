{"info": {"author": "BiRG @ Wright State University", "author_email": "foose.3@wright.edu", "bugtrack_url": null, "classifiers": ["Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3.9"], "description": "# pyopls - Orthogonal Projection to Latent Structures in Python. \n[![Build Status](https://travis-ci.org/BiRG/pyopls.svg?branch=master)](https://travis-ci.org/BiRG/pyopls)\n\nThis package provides a scikit-learn-style transformer to perform OPLS.\nOPLS is a pre-processing method to remove variation from the descriptor \nvariables that are orthogonal to the target variable (1).\n\nThis package also provides a class to validate OPLS models using a \n1-component PLS regression with cross-validation and permutation tests (2)\nfor both regression and classification metrics (from permutations of the\ntarget) and feature PLS loadings (from permutations of the features).\n\n## Table of Contents\n1. [Installation](#installation)\n2. [Notes](#notes)\n3. [Examples](#examples) \n   1. [OPLS and PLS-DA](#opls-and-pls-da)\n   2. [Validation](#validation)\n4. [References](#references)\n5. [Data Acknowledgment](#data-acknowledgment)\n\n\n## Installation\npyopls is available via [pypi](https://pypi.org/project/pyopls/):\n```shell\npip install pyopls\n```\nYou may also install directly from this repository for the current\nmaster: \n```shell\npip install git+git://github.com/BiRG/pyopls.git\n```\nNew versions are uploaded to pypi whenever the version number is\nincremented in `setup.py` on the master branch.\n\n\n## Notes\n* The implementation provided here is equivalent to that of the \n  [libPLS MATLAB library](http://libpls.net/), which is a faithful\n  recreation of Trygg and Wold's algorithm.\n  *   This package uses a different definition for R<sup>2</sup>X, however (see\n      below)\n* `OPLS` inherits `sklearn.base.TransformerMixin` (like\n  `sklearn.decomposition.PCA`) but does not inherit \n  `sklearn.base.RegressorMixin` because it is not a regressor like\n  `sklearn.cross_decomposition.PLSRegression`. You can use the output of\n  `OPLS.transform()` as an input to another regressor or classifier.\n* Like `sklearn.cross_decomposition.PLSRegression`, `OPLS` will center\n  both X and Y before performing the algorithm. This makes centering by\n  class in PLS-DA models unnecessary.\n* The `score()` function of `OPLS` performs the R<sup>2</sup>X score, the\n  ratio of the variance in the transformed X to the variance in the\n  original X. A lower score indicates more orthogonal variance removed.\n* `OPLS` only supports 1-column targets.\n\n## Examples\n### OPLS and PLS-DA\nA CSV file containing 1H-NMR spectra for 118 serum samples of patients\nwith colon cancer diagnoses and healthy controls is located in\n`colorectal_cancer_nmr.csv` in the root of this repository (see\nacknowledgment below).\n \nOPLS-processed data require only 1 PLS component. Performing a\n39-component OPLS improves cross-validated accuracy from 70% to 100%,\nAUC from .578 to 1 and DQ<sup>2</sup> (3) from 0.04 to 0.99.\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom pyopls import OPLS\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.model_selection import cross_val_predict, LeaveOneOut\nfrom sklearn.metrics import r2_score, accuracy_score\n\n\nspectra = pd.read_csv('colorectal_cancer_nmr.csv', index_col=0)\nspectra = spectra[spectra.classification.isin(['Colorectal Cancer', 'Healthy Control'])]\ntarget = spectra.classification.apply(lambda x: 1 if x == 'Colorectal Cancer' else -1)\nspectra = spectra.drop('classification', axis=1)\n\nopls = OPLS(39)\nZ = opls.fit_transform(spectra, target)\n\npls = PLSRegression(1)\ny_pred = cross_val_predict(pls, spectra, target, cv=LeaveOneOut())\nq_squared = r2_score(target, y_pred)  # -0.107\ndq_squared = r2_score(target, np.clip(y_pred, -1, 1))  # -0.106\naccuracy = accuracy_score(target, np.sign(y_pred))  # 0.705\n\nprocessed_y_pred = cross_val_predict(pls, Z, target, cv=LeaveOneOut())\nprocessed_q_squared = r2_score(target, processed_y_pred)  # 0.981\nprocessed_dq_squared = r2_score(target, np.clip(processed_y_pred, -1, 1))  # 0.984\nprocessed_accuracy = accuracy_score(target, np.sign(processed_y_pred))  # 1.0\n\nr2_X = opls.score(spectra)  # 7.8e-12 (most variance is removed)\n\nfpr, tpr, thresholds = roc_curve(target, y_pred)\nroc_auc = roc_auc_score(target, y_pred)\nproc_fpr, proc_tpr, proc_thresholds = roc_curve(target, processed_y_pred)\nproc_roc_auc = roc_auc_score(target, processed_y_pred)\n\nplt.figure(0)\nplt.plot(fpr, tpr, lw=2, color='blue', label=f'Unprocessed (AUC={roc_auc:.4f})')\nplt.plot(proc_fpr, proc_tpr, lw=2, color='red',\n         label=f'39-component OPLS (AUC={proc_roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc='lower right')\nplt.show()\n\nplt.figure(1)\npls.fit(Z, target)\ndf = pd.DataFrame(np.column_stack([pls.x_scores_, opls.T_ortho_[:, 0]]),\n                  index=spectra.index, columns=['t', 't_ortho'])                           \npos_df = df[target==1]\nneg_df = df[target==-1]\nplt.scatter(neg_df['t'], neg_df['t_ortho'], c='blue', label='Healthy Control')\nplt.scatter(pos_df['t'], pos_df['t_ortho'], c='red', label='Colorectal Cancer')\nplt.title('PLS Scores')\nplt.xlabel('t_ortho')\nplt.ylabel('t')\nplt.legend(loc='upper right')\nplt.show()\n```\n#### ROC Curve\n![roc curve](roc_curve.png) \n#### Scores Plot\n![scores plot](scores.png)\n### Validation\nThe `fit()` method of `OPLSValidator` will find the optimum number of\ncomponents to remove, then evaluate the results on a 1-component\n`sklearn.cross_decomposition.PLSRegression` model. A permutation test is\nperformed for each metric by permuting the target and for the PLS\nloadings by permuting the features.\n \nThis snippet will determine the best number of components to remove,\nperform permutation tests for regression metrics and perform two-tailed\npermutation tests for each feature (bin) relative to it's loading. The\nfeature permutation tests for the colorectal cancer dataset would take\nquite some time, as they require that the model be fit as many as 874k\ntimes. So instead, we look at the\n[UCI ML Wine Dataset](https://archive.ics.uci.edu/ml/datasets/Wine)\nprovided by\n[scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)\nThe feature permutation tests reveal that hue and malic acid do not\ndifferentate class 1 from class 0.\n\n```python\nimport pandas as pd\nfrom pyopls import OPLSValidator\nfrom sklearn.datasets import load_wine\n\nwine_data = load_wine()\ndf = pd.DataFrame(wine_data['data'], columns=wine_data['feature_names'])\ndf['classification'] = wine_data['target']\ndf = df[df.classification.isin((0, 1))]\ntarget = df.classification.apply(lambda x: 1 if x else -1)  # discriminant for class 1 vs class 0\nX = df[[c for c in df.columns if c!='classification']]\n\nvalidator = OPLSValidator(k=-1).fit(X, target)\n\nZ = validator.opls_.transform(X)\n\nfeature_df = pd.DataFrame()\nfeature_df['feature_name'] = wine_data['feature_names']\nfeature_df['feature_p_value'] = validator.feature_p_values_\nfeature_df['feature_loading'] = validator.pls_.x_loadings_\nprint(feature_df.loc[feature_df.feature_loading.abs().sort_values(ascending=False).index].to_markdown())  # Pandas 1.0+ required for to_markdown\n```\n#### Feature importances\n|    | feature\\_name                | feature\\_p\\_value | feature\\_loading |\n|---:|:-----------------------------|------------------:|-----------------:|\n| 12 | proline                      |      0.00990099   |        0.385955  |\n|  9 | color_intensity              |      0.00990099   |        0.381981  |\n|  0 | alcohol                      |      0.00990099   |        0.379567  |\n|  6 | flavanoids                   |      0.00990099   |        0.359975  |\n|  5 | total_phenols                |      0.00990099   |        0.336182  |\n| 11 | od280/od315_of_diluted_wines |      0.00990099   |        0.299045  |\n|  3 | alcalinity_of_ash            |      0.00990099   |       -0.239887  |\n|  2 | ash                          |      0.00990099   |        0.22916   |\n|  7 | nonflavanoid_phenols         |      0.00990099   |       -0.224338  |\n|  4 | magnesium                    |      0.00990099   |        0.18662   |\n|  8 | proanthocyanins              |      0.00990099   |        0.181767  |\n|  1 | malic_acid                   |      0.564356     |        0.0293328 |\n| 10 | hue                          |      0.623762     |        0.0210777 |\n\n## References\n1. Johan Trygg and Svante Wold. Orthogonal projections to latent structures (O-PLS).\n   *J. Chemometrics* 2002; 16: 119-128. DOI: [10.1002/cem.695](https://dx.doi.org/10.1002/cem.695)\n2. Eugene Edington and Patrick Onghena. \"Calculating P-Values\" in *Randomization tests*, 4th edition.\n   New York: Chapman & Hall/CRC, 2007, pp. 33-53. DOI: [10.1201/9781420011814](https://doi.org/10.1201/9781420011814).\n3. Johan A. Westerhuis, Ewoud J. J. van Velzen, Huub C. J. Hoefsloot, Age K. Smilde. Discriminant Q-squared for \n   improved discrimination in PLSDA models. *Metabolomics* 2008; 4: 293-296. \n   DOI: [10.1007/s11306-008-0126-2](https://doi.org/10.1007/s11306-008-0126-2)\n\n## Data Acknowledgment\nThe test dataset provided at `pyopls/tests/colorectal_cancer_nmr.csv` is\navailable at the NIH Common Fund's National Metabolomics Data Repository\n(NMDR) website, the Metabolomics Workbench,\n[https://metabolomicsworkbench.org] where it has been assigned Project\nID PR000227. The data can be accessed directly via it's Project DOI\n[10.21228/M89P43](https://dx.doi.org/10.21228/M89P43). This work is\nsupported by NIH grant, U2C-DK119886. \n\n*Note*: The test dataset consists only of those spectra belonging to\nsamples labeled \"Colorectal Cancer\" or \"Healthy Control\". The \"target\"\nvariable has the value -1 for samples labeled \"Healthy Control\" and\nvalue +1 for samples labeled \"Colorectal Cancer\".", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/BiRG/pyopls/archive/20.02.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/BiRG/pyopls", "keywords": "metabolomics chemometrics partial-least-squares", "license": "", "maintainer": "", "maintainer_email": "", "name": "pyopls", "package_url": "https://pypi.org/project/pyopls/", "platform": "", "project_url": "https://pypi.org/project/pyopls/", "project_urls": {"Download": "https://github.com/BiRG/pyopls/archive/20.02.tar.gz", "Homepage": "https://github.com/BiRG/pyopls"}, "release_url": "https://pypi.org/project/pyopls/20.3.post1/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Orthogonal Projection to Latent Structures", "version": "20.3.post1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pyopls - Orthogonal Projection to Latent Structures in Python.</h1>\n<p><a href=\"https://travis-ci.org/BiRG/pyopls\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5f3cf7d059f649da0188c2a3b9c1a881630ae704/68747470733a2f2f7472617669732d63692e6f72672f426952472f70796f706c732e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>This package provides a scikit-learn-style transformer to perform OPLS.\nOPLS is a pre-processing method to remove variation from the descriptor\nvariables that are orthogonal to the target variable (1).</p>\n<p>This package also provides a class to validate OPLS models using a\n1-component PLS regression with cross-validation and permutation tests (2)\nfor both regression and classification metrics (from permutations of the\ntarget) and feature PLS loadings (from permutations of the features).</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#notes\" rel=\"nofollow\">Notes</a></li>\n<li><a href=\"#examples\" rel=\"nofollow\">Examples</a>\n<ol>\n<li><a href=\"#opls-and-pls-da\" rel=\"nofollow\">OPLS and PLS-DA</a></li>\n<li><a href=\"#validation\" rel=\"nofollow\">Validation</a></li>\n</ol>\n</li>\n<li><a href=\"#references\" rel=\"nofollow\">References</a></li>\n<li><a href=\"#data-acknowledgment\" rel=\"nofollow\">Data Acknowledgment</a></li>\n</ol>\n<h2>Installation</h2>\n<p>pyopls is available via <a href=\"https://pypi.org/project/pyopls/\" rel=\"nofollow\">pypi</a>:</p>\n<pre>pip install pyopls\n</pre>\n<p>You may also install directly from this repository for the current\nmaster:</p>\n<pre>pip install git+git://github.com/BiRG/pyopls.git\n</pre>\n<p>New versions are uploaded to pypi whenever the version number is\nincremented in <code>setup.py</code> on the master branch.</p>\n<h2>Notes</h2>\n<ul>\n<li>The implementation provided here is equivalent to that of the\n<a href=\"http://libpls.net/\" rel=\"nofollow\">libPLS MATLAB library</a>, which is a faithful\nrecreation of Trygg and Wold's algorithm.\n<ul>\n<li>This package uses a different definition for R<sup>2</sup>X, however (see\nbelow)</li>\n</ul>\n</li>\n<li><code>OPLS</code> inherits <code>sklearn.base.TransformerMixin</code> (like\n<code>sklearn.decomposition.PCA</code>) but does not inherit\n<code>sklearn.base.RegressorMixin</code> because it is not a regressor like\n<code>sklearn.cross_decomposition.PLSRegression</code>. You can use the output of\n<code>OPLS.transform()</code> as an input to another regressor or classifier.</li>\n<li>Like <code>sklearn.cross_decomposition.PLSRegression</code>, <code>OPLS</code> will center\nboth X and Y before performing the algorithm. This makes centering by\nclass in PLS-DA models unnecessary.</li>\n<li>The <code>score()</code> function of <code>OPLS</code> performs the R<sup>2</sup>X score, the\nratio of the variance in the transformed X to the variance in the\noriginal X. A lower score indicates more orthogonal variance removed.</li>\n<li><code>OPLS</code> only supports 1-column targets.</li>\n</ul>\n<h2>Examples</h2>\n<h3>OPLS and PLS-DA</h3>\n<p>A CSV file containing 1H-NMR spectra for 118 serum samples of patients\nwith colon cancer diagnoses and healthy controls is located in\n<code>colorectal_cancer_nmr.csv</code> in the root of this repository (see\nacknowledgment below).</p>\n<p>OPLS-processed data require only 1 PLS component. Performing a\n39-component OPLS improves cross-validated accuracy from 70% to 100%,\nAUC from .578 to 1 and DQ<sup>2</sup> (3) from 0.04 to 0.99.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">roc_curve</span><span class=\"p\">,</span> <span class=\"n\">roc_auc_score</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyopls</span> <span class=\"kn\">import</span> <span class=\"n\">OPLS</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.cross_decomposition</span> <span class=\"kn\">import</span> <span class=\"n\">PLSRegression</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">cross_val_predict</span><span class=\"p\">,</span> <span class=\"n\">LeaveOneOut</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.metrics</span> <span class=\"kn\">import</span> <span class=\"n\">r2_score</span><span class=\"p\">,</span> <span class=\"n\">accuracy_score</span>\n\n\n<span class=\"n\">spectra</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s1\">'colorectal_cancer_nmr.csv'</span><span class=\"p\">,</span> <span class=\"n\">index_col</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">spectra</span> <span class=\"o\">=</span> <span class=\"n\">spectra</span><span class=\"p\">[</span><span class=\"n\">spectra</span><span class=\"o\">.</span><span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">isin</span><span class=\"p\">([</span><span class=\"s1\">'Colorectal Cancer'</span><span class=\"p\">,</span> <span class=\"s1\">'Healthy Control'</span><span class=\"p\">])]</span>\n<span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"n\">spectra</span><span class=\"o\">.</span><span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"mi\">1</span> <span class=\"k\">if</span> <span class=\"n\">x</span> <span class=\"o\">==</span> <span class=\"s1\">'Colorectal Cancer'</span> <span class=\"k\">else</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">spectra</span> <span class=\"o\">=</span> <span class=\"n\">spectra</span><span class=\"o\">.</span><span class=\"n\">drop</span><span class=\"p\">(</span><span class=\"s1\">'classification'</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">opls</span> <span class=\"o\">=</span> <span class=\"n\">OPLS</span><span class=\"p\">(</span><span class=\"mi\">39</span><span class=\"p\">)</span>\n<span class=\"n\">Z</span> <span class=\"o\">=</span> <span class=\"n\">opls</span><span class=\"o\">.</span><span class=\"n\">fit_transform</span><span class=\"p\">(</span><span class=\"n\">spectra</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n\n<span class=\"n\">pls</span> <span class=\"o\">=</span> <span class=\"n\">PLSRegression</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_predict</span><span class=\"p\">(</span><span class=\"n\">pls</span><span class=\"p\">,</span> <span class=\"n\">spectra</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"n\">LeaveOneOut</span><span class=\"p\">())</span>\n<span class=\"n\">q_squared</span> <span class=\"o\">=</span> <span class=\"n\">r2_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>  <span class=\"c1\"># -0.107</span>\n<span class=\"n\">dq_squared</span> <span class=\"o\">=</span> <span class=\"n\">r2_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">clip</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>  <span class=\"c1\"># -0.106</span>\n<span class=\"n\">accuracy</span> <span class=\"o\">=</span> <span class=\"n\">accuracy_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sign</span><span class=\"p\">(</span><span class=\"n\">y_pred</span><span class=\"p\">))</span>  <span class=\"c1\"># 0.705</span>\n\n<span class=\"n\">processed_y_pred</span> <span class=\"o\">=</span> <span class=\"n\">cross_val_predict</span><span class=\"p\">(</span><span class=\"n\">pls</span><span class=\"p\">,</span> <span class=\"n\">Z</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">cv</span><span class=\"o\">=</span><span class=\"n\">LeaveOneOut</span><span class=\"p\">())</span>\n<span class=\"n\">processed_q_squared</span> <span class=\"o\">=</span> <span class=\"n\">r2_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">processed_y_pred</span><span class=\"p\">)</span>  <span class=\"c1\"># 0.981</span>\n<span class=\"n\">processed_dq_squared</span> <span class=\"o\">=</span> <span class=\"n\">r2_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">clip</span><span class=\"p\">(</span><span class=\"n\">processed_y_pred</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))</span>  <span class=\"c1\"># 0.984</span>\n<span class=\"n\">processed_accuracy</span> <span class=\"o\">=</span> <span class=\"n\">accuracy_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sign</span><span class=\"p\">(</span><span class=\"n\">processed_y_pred</span><span class=\"p\">))</span>  <span class=\"c1\"># 1.0</span>\n\n<span class=\"n\">r2_X</span> <span class=\"o\">=</span> <span class=\"n\">opls</span><span class=\"o\">.</span><span class=\"n\">score</span><span class=\"p\">(</span><span class=\"n\">spectra</span><span class=\"p\">)</span>  <span class=\"c1\"># 7.8e-12 (most variance is removed)</span>\n\n<span class=\"n\">fpr</span><span class=\"p\">,</span> <span class=\"n\">tpr</span><span class=\"p\">,</span> <span class=\"n\">thresholds</span> <span class=\"o\">=</span> <span class=\"n\">roc_curve</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>\n<span class=\"n\">roc_auc</span> <span class=\"o\">=</span> <span class=\"n\">roc_auc_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>\n<span class=\"n\">proc_fpr</span><span class=\"p\">,</span> <span class=\"n\">proc_tpr</span><span class=\"p\">,</span> <span class=\"n\">proc_thresholds</span> <span class=\"o\">=</span> <span class=\"n\">roc_curve</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">processed_y_pred</span><span class=\"p\">)</span>\n<span class=\"n\">proc_roc_auc</span> <span class=\"o\">=</span> <span class=\"n\">roc_auc_score</span><span class=\"p\">(</span><span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">processed_y_pred</span><span class=\"p\">)</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">fpr</span><span class=\"p\">,</span> <span class=\"n\">tpr</span><span class=\"p\">,</span> <span class=\"n\">lw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">color</span><span class=\"o\">=</span><span class=\"s1\">'blue'</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"sa\">f</span><span class=\"s1\">'Unprocessed (AUC=</span><span class=\"si\">{</span><span class=\"n\">roc_auc</span><span class=\"si\">:</span><span class=\"s1\">.4f</span><span class=\"si\">}</span><span class=\"s1\">)'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">proc_fpr</span><span class=\"p\">,</span> <span class=\"n\">proc_tpr</span><span class=\"p\">,</span> <span class=\"n\">lw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">color</span><span class=\"o\">=</span><span class=\"s1\">'red'</span><span class=\"p\">,</span>\n         <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"sa\">f</span><span class=\"s1\">'39-component OPLS (AUC=</span><span class=\"si\">{</span><span class=\"n\">proc_roc_auc</span><span class=\"si\">:</span><span class=\"s1\">.4f</span><span class=\"si\">}</span><span class=\"s1\">)'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">([</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">color</span><span class=\"o\">=</span><span class=\"s1\">'gray'</span><span class=\"p\">,</span> <span class=\"n\">lw</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">linestyle</span><span class=\"o\">=</span><span class=\"s1\">'--'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">'False Positive Rate'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">'True Positive Rate'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">'ROC Curve'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">legend</span><span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"s1\">'lower right'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">pls</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">Z</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">column_stack</span><span class=\"p\">([</span><span class=\"n\">pls</span><span class=\"o\">.</span><span class=\"n\">x_scores_</span><span class=\"p\">,</span> <span class=\"n\">opls</span><span class=\"o\">.</span><span class=\"n\">T_ortho_</span><span class=\"p\">[:,</span> <span class=\"mi\">0</span><span class=\"p\">]]),</span>\n                  <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"n\">spectra</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'t'</span><span class=\"p\">,</span> <span class=\"s1\">'t_ortho'</span><span class=\"p\">])</span>                           \n<span class=\"n\">pos_df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">target</span><span class=\"o\">==</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">neg_df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">target</span><span class=\"o\">==-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">scatter</span><span class=\"p\">(</span><span class=\"n\">neg_df</span><span class=\"p\">[</span><span class=\"s1\">'t'</span><span class=\"p\">],</span> <span class=\"n\">neg_df</span><span class=\"p\">[</span><span class=\"s1\">'t_ortho'</span><span class=\"p\">],</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"s1\">'blue'</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">'Healthy Control'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">scatter</span><span class=\"p\">(</span><span class=\"n\">pos_df</span><span class=\"p\">[</span><span class=\"s1\">'t'</span><span class=\"p\">],</span> <span class=\"n\">pos_df</span><span class=\"p\">[</span><span class=\"s1\">'t_ortho'</span><span class=\"p\">],</span> <span class=\"n\">c</span><span class=\"o\">=</span><span class=\"s1\">'red'</span><span class=\"p\">,</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"s1\">'Colorectal Cancer'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">(</span><span class=\"s1\">'PLS Scores'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">xlabel</span><span class=\"p\">(</span><span class=\"s1\">'t_ortho'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">ylabel</span><span class=\"p\">(</span><span class=\"s1\">'t'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">legend</span><span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"s1\">'upper right'</span><span class=\"p\">)</span>\n<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<h4>ROC Curve</h4>\n<p><img alt=\"roc curve\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5d906968580cfc5929d333cc7be54fba79690be3/726f635f63757276652e706e67\"></p>\n<h4>Scores Plot</h4>\n<p><img alt=\"scores plot\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a89327b3cdd2fbe6fb6a80d22a8776f28cc2113b/73636f7265732e706e67\"></p>\n<h3>Validation</h3>\n<p>The <code>fit()</code> method of <code>OPLSValidator</code> will find the optimum number of\ncomponents to remove, then evaluate the results on a 1-component\n<code>sklearn.cross_decomposition.PLSRegression</code> model. A permutation test is\nperformed for each metric by permuting the target and for the PLS\nloadings by permuting the features.</p>\n<p>This snippet will determine the best number of components to remove,\nperform permutation tests for regression metrics and perform two-tailed\npermutation tests for each feature (bin) relative to it's loading. The\nfeature permutation tests for the colorectal cancer dataset would take\nquite some time, as they require that the model be fit as many as 874k\ntimes. So instead, we look at the\n<a href=\"https://archive.ics.uci.edu/ml/datasets/Wine\" rel=\"nofollow\">UCI ML Wine Dataset</a>\nprovided by\n<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html\" rel=\"nofollow\">scikit-learn</a>\nThe feature permutation tests reveal that hue and malic acid do not\ndifferentate class 1 from class 0.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyopls</span> <span class=\"kn\">import</span> <span class=\"n\">OPLSValidator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">load_wine</span>\n\n<span class=\"n\">wine_data</span> <span class=\"o\">=</span> <span class=\"n\">load_wine</span><span class=\"p\">()</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">wine_data</span><span class=\"p\">[</span><span class=\"s1\">'data'</span><span class=\"p\">],</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">wine_data</span><span class=\"p\">[</span><span class=\"s1\">'feature_names'</span><span class=\"p\">])</span>\n<span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s1\">'classification'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">wine_data</span><span class=\"p\">[</span><span class=\"s1\">'target'</span><span class=\"p\">]</span>\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">isin</span><span class=\"p\">((</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">))]</span>\n<span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">classification</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"mi\">1</span> <span class=\"k\">if</span> <span class=\"n\">x</span> <span class=\"k\">else</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>  <span class=\"c1\"># discriminant for class 1 vs class 0</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[[</span><span class=\"n\">c</span> <span class=\"k\">for</span> <span class=\"n\">c</span> <span class=\"ow\">in</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span> <span class=\"k\">if</span> <span class=\"n\">c</span><span class=\"o\">!=</span><span class=\"s1\">'classification'</span><span class=\"p\">]]</span>\n\n<span class=\"n\">validator</span> <span class=\"o\">=</span> <span class=\"n\">OPLSValidator</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n\n<span class=\"n\">Z</span> <span class=\"o\">=</span> <span class=\"n\">validator</span><span class=\"o\">.</span><span class=\"n\">opls_</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n\n<span class=\"n\">feature_df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">()</span>\n<span class=\"n\">feature_df</span><span class=\"p\">[</span><span class=\"s1\">'feature_name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">wine_data</span><span class=\"p\">[</span><span class=\"s1\">'feature_names'</span><span class=\"p\">]</span>\n<span class=\"n\">feature_df</span><span class=\"p\">[</span><span class=\"s1\">'feature_p_value'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">validator</span><span class=\"o\">.</span><span class=\"n\">feature_p_values_</span>\n<span class=\"n\">feature_df</span><span class=\"p\">[</span><span class=\"s1\">'feature_loading'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">validator</span><span class=\"o\">.</span><span class=\"n\">pls_</span><span class=\"o\">.</span><span class=\"n\">x_loadings_</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">feature_df</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"n\">feature_df</span><span class=\"o\">.</span><span class=\"n\">feature_loading</span><span class=\"o\">.</span><span class=\"n\">abs</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">sort_values</span><span class=\"p\">(</span><span class=\"n\">ascending</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">to_markdown</span><span class=\"p\">())</span>  <span class=\"c1\"># Pandas 1.0+ required for to_markdown</span>\n</pre>\n<h4>Feature importances</h4>\n<table>\n<thead>\n<tr>\n<th align=\"right\"></th>\n<th align=\"left\">feature_name</th>\n<th align=\"right\">feature_p_value</th>\n<th align=\"right\">feature_loading</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"right\">12</td>\n<td align=\"left\">proline</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.385955</td>\n</tr>\n<tr>\n<td align=\"right\">9</td>\n<td align=\"left\">color_intensity</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.381981</td>\n</tr>\n<tr>\n<td align=\"right\">0</td>\n<td align=\"left\">alcohol</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.379567</td>\n</tr>\n<tr>\n<td align=\"right\">6</td>\n<td align=\"left\">flavanoids</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.359975</td>\n</tr>\n<tr>\n<td align=\"right\">5</td>\n<td align=\"left\">total_phenols</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.336182</td>\n</tr>\n<tr>\n<td align=\"right\">11</td>\n<td align=\"left\">od280/od315_of_diluted_wines</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.299045</td>\n</tr>\n<tr>\n<td align=\"right\">3</td>\n<td align=\"left\">alcalinity_of_ash</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">-0.239887</td>\n</tr>\n<tr>\n<td align=\"right\">2</td>\n<td align=\"left\">ash</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.22916</td>\n</tr>\n<tr>\n<td align=\"right\">7</td>\n<td align=\"left\">nonflavanoid_phenols</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">-0.224338</td>\n</tr>\n<tr>\n<td align=\"right\">4</td>\n<td align=\"left\">magnesium</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.18662</td>\n</tr>\n<tr>\n<td align=\"right\">8</td>\n<td align=\"left\">proanthocyanins</td>\n<td align=\"right\">0.00990099</td>\n<td align=\"right\">0.181767</td>\n</tr>\n<tr>\n<td align=\"right\">1</td>\n<td align=\"left\">malic_acid</td>\n<td align=\"right\">0.564356</td>\n<td align=\"right\">0.0293328</td>\n</tr>\n<tr>\n<td align=\"right\">10</td>\n<td align=\"left\">hue</td>\n<td align=\"right\">0.623762</td>\n<td align=\"right\">0.0210777</td>\n</tr></tbody></table>\n<h2>References</h2>\n<ol>\n<li>Johan Trygg and Svante Wold. Orthogonal projections to latent structures (O-PLS).\n<em>J. Chemometrics</em> 2002; 16: 119-128. DOI: <a href=\"https://dx.doi.org/10.1002/cem.695\" rel=\"nofollow\">10.1002/cem.695</a></li>\n<li>Eugene Edington and Patrick Onghena. \"Calculating P-Values\" in <em>Randomization tests</em>, 4th edition.\nNew York: Chapman &amp; Hall/CRC, 2007, pp. 33-53. DOI: <a href=\"https://doi.org/10.1201/9781420011814\" rel=\"nofollow\">10.1201/9781420011814</a>.</li>\n<li>Johan A. Westerhuis, Ewoud J. J. van Velzen, Huub C. J. Hoefsloot, Age K. Smilde. Discriminant Q-squared for\nimproved discrimination in PLSDA models. <em>Metabolomics</em> 2008; 4: 293-296.\nDOI: <a href=\"https://doi.org/10.1007/s11306-008-0126-2\" rel=\"nofollow\">10.1007/s11306-008-0126-2</a></li>\n</ol>\n<h2>Data Acknowledgment</h2>\n<p>The test dataset provided at <code>pyopls/tests/colorectal_cancer_nmr.csv</code> is\navailable at the NIH Common Fund's National Metabolomics Data Repository\n(NMDR) website, the Metabolomics Workbench,\n[https://metabolomicsworkbench.org] where it has been assigned Project\nID PR000227. The data can be accessed directly via it's Project DOI\n<a href=\"https://dx.doi.org/10.21228/M89P43\" rel=\"nofollow\">10.21228/M89P43</a>. This work is\nsupported by NIH grant, U2C-DK119886.</p>\n<p><em>Note</em>: The test dataset consists only of those spectra belonging to\nsamples labeled \"Colorectal Cancer\" or \"Healthy Control\". The \"target\"\nvariable has the value -1 for samples labeled \"Healthy Control\" and\nvalue +1 for samples labeled \"Colorectal Cancer\".</p>\n\n          </div>"}, "last_serial": 6752099, "releases": {"20.2": [{"comment_text": "", "digests": {"md5": "2cbd9d516ba835922ac9bf81cf51b61f", "sha256": "848555767ca96018433765283627ec7efc30ff5d9f60fedf915e646222b96f3d"}, "downloads": -1, "filename": "pyopls-20.2.tar.gz", "has_sig": false, "md5_digest": "2cbd9d516ba835922ac9bf81cf51b61f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 15376, "upload_time": "2020-02-18T22:07:08", "upload_time_iso_8601": "2020-02-18T22:07:08.456914Z", "url": "https://files.pythonhosted.org/packages/fd/c1/850f4fd08e8548b8fb99ee745163aa2cd08d2a7568714e5e8a11dc766ee4/pyopls-20.2.tar.gz", "yanked": false}], "20.3": [{"comment_text": "", "digests": {"md5": "18ba751e30ce90ed2be48e03671ff390", "sha256": "5919f44a7cf4b6304e6a8e2685790db30e2f4940b371db0f308d39583cc63fec"}, "downloads": -1, "filename": "pyopls-20.3.tar.gz", "has_sig": false, "md5_digest": "18ba751e30ce90ed2be48e03671ff390", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 17194, "upload_time": "2020-03-05T01:19:35", "upload_time_iso_8601": "2020-03-05T01:19:35.889768Z", "url": "https://files.pythonhosted.org/packages/4f/92/b23f1efe8545b8ffa6f60300ab8a5c23e63c786b413ded7c565a56aef5a1/pyopls-20.3.tar.gz", "yanked": false}], "20.3.post1": [{"comment_text": "", "digests": {"md5": "c0781507fe2849cc1bf2c38a77e4f8d5", "sha256": "046d28315c1f6e4e5bc97040e1247421b36b684cdcafaa6b24312307a261a884"}, "downloads": -1, "filename": "pyopls-20.3.post1.tar.gz", "has_sig": false, "md5_digest": "c0781507fe2849cc1bf2c38a77e4f8d5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 17462, "upload_time": "2020-03-05T01:36:23", "upload_time_iso_8601": "2020-03-05T01:36:23.419020Z", "url": "https://files.pythonhosted.org/packages/27/ea/f36d4d78294303fd0778574cdd19681373472fce135fc4e152c5149f9f88/pyopls-20.3.post1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c0781507fe2849cc1bf2c38a77e4f8d5", "sha256": "046d28315c1f6e4e5bc97040e1247421b36b684cdcafaa6b24312307a261a884"}, "downloads": -1, "filename": "pyopls-20.3.post1.tar.gz", "has_sig": false, "md5_digest": "c0781507fe2849cc1bf2c38a77e4f8d5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 17462, "upload_time": "2020-03-05T01:36:23", "upload_time_iso_8601": "2020-03-05T01:36:23.419020Z", "url": "https://files.pythonhosted.org/packages/27/ea/f36d4d78294303fd0778574cdd19681373472fce135fc4e152c5149f9f88/pyopls-20.3.post1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:00:08 2020"}