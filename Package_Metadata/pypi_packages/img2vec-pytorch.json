{"info": {"author": "Christian Safka", "author_email": "christiansafka@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.6"], "description": "# Image 2 Vec with PyTorch\n\nMedium post on building the first version from scratch:  https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c\n\n### Applications of image embeddings:\n - Ranking for recommender systems\n - Clustering images to different categories\n - Classification tasks\n\n## Available models\n - Resnet-18 (CPU, GPU)\n \t- Returns vector length 512\n - Alexnet (CPU, GPU)\n \t- Returns vector length 4096\n\n## Installation\n\nTested on Python 3.6\n\n#### Dependencies\n\nPytorch: http://pytorch.org/\n\nPillow:  ```pip install Pillow```\n\n##### For running the example, you will additionally need:\n * Sklearn ```pip install scikit-learn```\n\n## Running the example\n```git clone https://github.com/christiansafka/img2vec.git```\n\n```cd img2vec/example```\n\n```python test_img_to_vec.py```\n\n#### Expected output\n```\nWhich filename would you like similarities for?\ncat.jpg\n0.72832 cat2.jpg\n0.641478 catdog.jpg\n0.575845 face.jpg\n0.516689 face2.jpg\n\nWhich filename would you like similarities for?\nface2.jpg\n0.668525 face.jpg\n0.516689 cat.jpg\n0.50084 cat2.jpg\n0.484863 catdog.jpg\n```\nTry adding your own photos!\n\n## Using img2vec as a library\n```python\nfrom img_to_vec import Img2Vec\nfrom PIL import Image\n\n# Initialize Img2Vec with GPU\nimg2vec = Img2Vec(cuda=True)\n\n# Read in an image\nimg = Image.open('test.jpg')\n# Get a vector from img2vec\nvec = img2vec.get_vec(img)\n# Or submit a list\nvectors = img2vec.get_vec(list_of_PIL_images)\n```\n#### Img2Vec Params\n**cuda** = (True, False) &nbsp; # Run on GPU? &nbsp; &nbsp; default: False<br>\n**model** = ('resnet-18', 'alexnet') &nbsp; # Which model to use? &nbsp; &nbsp; default: 'resnet-18'<br>\n\n## Advanced users \n----\n### Additional Parameters\n\n**layer** = 'layer_name' or int &nbsp; # For advanced users, which layer of the model to extract the output from.&nbsp;&nbsp; default: 'avgpool' <br>\n**layer_output_size** = int &nbsp; # Size of the output of your selected layer\n\n### [Resnet-18](http://pytorch-zh.readthedocs.io/en/latest/_modules/torchvision/models/resnet.html)\nDefaults: (layer = 'avgpool', layer_output_size = 512)<br>\nLayer parameter must be an string representing the name of a  layer below\n```python\nconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\nbn1 = nn.BatchNorm2d(64)\nrelu = nn.ReLU(inplace=True)\nmaxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\nlayer1 = self._make_layer(block, 64, layers[0])\nlayer2 = self._make_layer(block, 128, layers[1], stride=2)\nlayer3 = self._make_layer(block, 256, layers[2], stride=2)\nlayer4 = self._make_layer(block, 512, layers[3], stride=2)\navgpool = nn.AvgPool2d(7)\nfc = nn.Linear(512 * block.expansion, num_classes)\n```\n### [Alexnet](http://pytorch-zh.readthedocs.io/en/latest/_modules/torchvision/models/alexnet.html)\nDefaults: (layer = 2, layer_output_size = 4096)<br>\nLayer parameter must be an integer representing one of the layers below\n```python\nalexnet.classifier = nn.Sequential(\n            7. nn.Dropout(),                  < - output_size = 9216\n            6. nn.Linear(256 * 6 * 6, 4096),  < - output_size = 4096\n            5. nn.ReLU(inplace=True),         < - output_size = 4096\n            4. nn.Dropout(),\t\t      < - output_size = 4096\n            3. nn.Linear(4096, 4096),\t      < - output_size = 4096\n            2. nn.ReLU(inplace=True),         < - output_size = 4096\n            1. nn.Linear(4096, num_classes),  < - output_size = 4096\n        )\n```\n\n## To-do\n- Benchmark speed and accuracy\n- Add ability to fine-tune on input data\n- Export documentation to a normal place\n- Package for Pip", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/christiansafka/img2vec", "keywords": "img2vec image vector classification pytorch convert", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "img2vec-pytorch", "package_url": "https://pypi.org/project/img2vec-pytorch/", "platform": "", "project_url": "https://pypi.org/project/img2vec-pytorch/", "project_urls": {"Homepage": "https://github.com/christiansafka/img2vec"}, "release_url": "https://pypi.org/project/img2vec-pytorch/0.2.5/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Use pre-trained models in PyTorch to extract vector embeddings for any image", "version": "0.2.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Image 2 Vec with PyTorch</h1>\n<p>Medium post on building the first version from scratch:  <a href=\"https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c\" rel=\"nofollow\">https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c</a></p>\n<h3>Applications of image embeddings:</h3>\n<ul>\n<li>Ranking for recommender systems</li>\n<li>Clustering images to different categories</li>\n<li>Classification tasks</li>\n</ul>\n<h2>Available models</h2>\n<ul>\n<li>Resnet-18 (CPU, GPU)\n<ul>\n<li>Returns vector length 512</li>\n</ul>\n</li>\n<li>Alexnet (CPU, GPU)\n<ul>\n<li>Returns vector length 4096</li>\n</ul>\n</li>\n</ul>\n<h2>Installation</h2>\n<p>Tested on Python 3.6</p>\n<h4>Dependencies</h4>\n<p>Pytorch: <a href=\"http://pytorch.org/\" rel=\"nofollow\">http://pytorch.org/</a></p>\n<p>Pillow:  <code>pip install Pillow</code></p>\n<h5>For running the example, you will additionally need:</h5>\n<ul>\n<li>Sklearn <code>pip install scikit-learn</code></li>\n</ul>\n<h2>Running the example</h2>\n<p><code>git clone https://github.com/christiansafka/img2vec.git</code></p>\n<p><code>cd img2vec/example</code></p>\n<p><code>python test_img_to_vec.py</code></p>\n<h4>Expected output</h4>\n<pre><code>Which filename would you like similarities for?\ncat.jpg\n0.72832 cat2.jpg\n0.641478 catdog.jpg\n0.575845 face.jpg\n0.516689 face2.jpg\n\nWhich filename would you like similarities for?\nface2.jpg\n0.668525 face.jpg\n0.516689 cat.jpg\n0.50084 cat2.jpg\n0.484863 catdog.jpg\n</code></pre>\n<p>Try adding your own photos!</p>\n<h2>Using img2vec as a library</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">img_to_vec</span> <span class=\"kn\">import</span> <span class=\"n\">Img2Vec</span>\n<span class=\"kn\">from</span> <span class=\"nn\">PIL</span> <span class=\"kn\">import</span> <span class=\"n\">Image</span>\n\n<span class=\"c1\"># Initialize Img2Vec with GPU</span>\n<span class=\"n\">img2vec</span> <span class=\"o\">=</span> <span class=\"n\">Img2Vec</span><span class=\"p\">(</span><span class=\"n\">cuda</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Read in an image</span>\n<span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'test.jpg'</span><span class=\"p\">)</span>\n<span class=\"c1\"># Get a vector from img2vec</span>\n<span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">img2vec</span><span class=\"o\">.</span><span class=\"n\">get_vec</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n<span class=\"c1\"># Or submit a list</span>\n<span class=\"n\">vectors</span> <span class=\"o\">=</span> <span class=\"n\">img2vec</span><span class=\"o\">.</span><span class=\"n\">get_vec</span><span class=\"p\">(</span><span class=\"n\">list_of_PIL_images</span><span class=\"p\">)</span>\n</pre>\n<h4>Img2Vec Params</h4>\n<p><strong>cuda</strong> = (True, False) \u00a0 # Run on GPU? \u00a0 \u00a0 default: False<br>\n<strong>model</strong> = ('resnet-18', 'alexnet') \u00a0 # Which model to use? \u00a0 \u00a0 default: 'resnet-18'<br></p>\n<h2>Advanced users</h2>\n<hr>\n<h3>Additional Parameters</h3>\n<p><strong>layer</strong> = 'layer_name' or int \u00a0 # For advanced users, which layer of the model to extract the output from.\u00a0\u00a0 default: 'avgpool' <br>\n<strong>layer_output_size</strong> = int \u00a0 # Size of the output of your selected layer</p>\n<h3><a href=\"http://pytorch-zh.readthedocs.io/en/latest/_modules/torchvision/models/resnet.html\" rel=\"nofollow\">Resnet-18</a></h3>\n<p>Defaults: (layer = 'avgpool', layer_output_size = 512)<br>\nLayer parameter must be an string representing the name of a  layer below</p>\n<pre><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">bn1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">BatchNorm2d</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">)</span>\n<span class=\"n\">relu</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">maxpool</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">MaxPool2d</span><span class=\"p\">(</span><span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">layer1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_make_layer</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">layer2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_make_layer</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">layer3</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_make_layer</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">layer4</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_make_layer</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">,</span> <span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">],</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">avgpool</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">AvgPool2d</span><span class=\"p\">(</span><span class=\"mi\">7</span><span class=\"p\">)</span>\n<span class=\"n\">fc</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">512</span> <span class=\"o\">*</span> <span class=\"n\">block</span><span class=\"o\">.</span><span class=\"n\">expansion</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">)</span>\n</pre>\n<h3><a href=\"http://pytorch-zh.readthedocs.io/en/latest/_modules/torchvision/models/alexnet.html\" rel=\"nofollow\">Alexnet</a></h3>\n<p>Defaults: (layer = 2, layer_output_size = 4096)<br>\nLayer parameter must be an integer representing one of the layers below</p>\n<pre><span class=\"n\">alexnet</span><span class=\"o\">.</span><span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"mf\">7.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(),</span>                  <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">9216</span>\n            <span class=\"mf\">6.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">256</span> <span class=\"o\">*</span> <span class=\"mi\">6</span> <span class=\"o\">*</span> <span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"mi\">4096</span><span class=\"p\">),</span>  <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>\n            <span class=\"mf\">5.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>         <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>\n            <span class=\"mf\">4.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Dropout</span><span class=\"p\">(),</span>\t\t      <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>\n            <span class=\"mf\">3.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">4096</span><span class=\"p\">,</span> <span class=\"mi\">4096</span><span class=\"p\">),</span>\t      <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>\n            <span class=\"mf\">2.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>         <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>\n            <span class=\"mf\">1.</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">4096</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"p\">),</span>  <span class=\"o\">&lt;</span> <span class=\"o\">-</span> <span class=\"n\">output_size</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span>\n        <span class=\"p\">)</span>\n</pre>\n<h2>To-do</h2>\n<ul>\n<li>Benchmark speed and accuracy</li>\n<li>Add ability to fine-tune on input data</li>\n<li>Export documentation to a normal place</li>\n<li>Package for Pip</li>\n</ul>\n\n          </div>"}, "last_serial": 5949094, "releases": {"0.2.5": [{"comment_text": "", "digests": {"md5": "cd3d3c86116ddc118ae676dedada2758", "sha256": "668e2f8916b388d6bf749736a45c24dfcb541541a881b9ff71221d431275cb9a"}, "downloads": -1, "filename": "img2vec_pytorch-0.2.5.tar.gz", "has_sig": false, "md5_digest": "cd3d3c86116ddc118ae676dedada2758", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4187, "upload_time": "2019-10-09T10:51:14", "upload_time_iso_8601": "2019-10-09T10:51:14.630787Z", "url": "https://files.pythonhosted.org/packages/94/e6/6f1e8d1918d2272c6b9b61b249bc255973f8b2aa15ed79d8e96fd7423a7a/img2vec_pytorch-0.2.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cd3d3c86116ddc118ae676dedada2758", "sha256": "668e2f8916b388d6bf749736a45c24dfcb541541a881b9ff71221d431275cb9a"}, "downloads": -1, "filename": "img2vec_pytorch-0.2.5.tar.gz", "has_sig": false, "md5_digest": "cd3d3c86116ddc118ae676dedada2758", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 4187, "upload_time": "2019-10-09T10:51:14", "upload_time_iso_8601": "2019-10-09T10:51:14.630787Z", "url": "https://files.pythonhosted.org/packages/94/e6/6f1e8d1918d2272c6b9b61b249bc255973f8b2aa15ed79d8e96fd7423a7a/img2vec_pytorch-0.2.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:43 2020"}