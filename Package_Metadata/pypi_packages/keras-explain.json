{"info": {"author": "Primoz Godec", "author_email": "primoz492@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Keras Explain\n\nThis package includes the majority of explanation tools for explaining \nKeras models predictions. Currently, only models with images on input are \nsupported.\nIt supports following approaches:\n\nGradient methods:\n\n- GradCam [[Selvaraju](https://arxiv.org/abs/1610.02391)]\n- Guided GradCam [[Selvaraju](https://arxiv.org/abs/1610.02391)]\n- Guided back-propagation [[Springenberg](https://arxiv.org/abs/1412.6806)]\n- Integrated gradients [[Sundararajan](https://arxiv.org/abs/1703.01365)]\n- Saliency [[Simonyan](https://arxiv.org/abs/1312.6034)]\n- Layer-wise relevance propagation [BETA] [[Bach](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)]\n\nModel-independent methods:\n- Prediction difference [[Zintgraf](https://arxiv.org/abs/1702.04595)]\n- Basic graying out [[Zeiler](https://arxiv.org/abs/1311.2901)]\n- LIME [[Ribeiro](https://arxiv.org/abs/1602.04938)]\n\nAll approaches are easy to apply to your model in two lines of code. \nIf you have any suggestion for new approaches to be included in the package\nplease do not hesitate to suggest. Also all improvements suggestions, bug reports and bug fixes are welcome. \n\nRight now we are in the process of implementing the following approaches:\n\n- Meaningful perturbation by Fong et al.\n- Layer-wise relevance propagation - we are adding layers that are not supported\nyet. \n\n## Usage\n\n### Gradient methods\n\n#### GradCam\n\n    from keras_explain.grad_cam import GradCam\n\n    explainer = GradCam(model, layer=None)\n    exp = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n- `layer` - (optional) The index (index in model.layers) of the layer which \nprediction is explained. \nIf not specified the last layer prediction is explained automatically.\n\nOutput:\n\n- `exp` - explanation. GradCam mark only features which contribute to the \nclassification in a `target class`. \n\n#### Guided GradCam\n\n    from keras_explain.grad_cam import GuidedGradCam\n\n    explainer = GuidedGradCam(model, lyer=None)\n    exp = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n- `layer` - (optional) The index (index in model.layers) of the layer which \nprediction is explained. \nIf not specified the last layer prediction is explained automatically.\n\nOutput:\n\n- `exp` - explanation. GuidedGradCam mark only features which contribute to the \nclassification in a `target class`. \n\n#### Guided back-propagation\n\n    from keras_explain.guided_bp import GuidedBP\n\n    explainer = GuidedBP(model)\n    exp = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n\nOutput:\n\n- `exp` - explanation. Guided back-propagation mark only features which \ncontribute to the classification in a `target class`. \n\n#### Integrated gradients\n\n    from keras_explain.integrated_gradients import IntegratedGradients\n\n    explainer = IntegratedGradients(model)\n    exp = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n\nOutput:\n\n- `exp` - explanation. Integrated gradients mark only features which contribute \nto the classification in a `target class`. \n\n#### Saliency\n\n    from keras_explain.saliency import Saliency\n\n    explainer = Saliency(model, layer=None)\n    exp = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n- `layer` - (optional) The index (index in model.layers) of the layer which \nprediction is explained. \nIf not specified the last layer prediction is explained automatically.\n\nOutput:\n\n- `exp` - explanation. Saliency mark only features which contribute \nto the classification in a `target class`. \n\n#### Layer-wise relevance propagation [BETA]\n\nThis approach does not support all layers yet. We are currently implementing\nmissing layers. If you wish you can implement any layer support yourself\nand submit it as a pull request. Since implementation is very custom any\nsuggestion for improvement is welcome.\n\n    from keras_explain.lrp import LRP\n\n    explainer = LRP(model)\n    exp = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n\nOutput:\n\n- `exp` - explanation. LRP mark only features which contribute \nto the classification in a `target class`. \n\n###Model independent approaches\n\n#### Prediction difference\n\n    from keras_explain.prediction_diff import PredictionDiff\n\n    explainer = PredictionDiff(model)\n    exp_pos, exp_neg = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n\nOutput:\n\n- `exp_pos` - explanation with marked features which contribute \nto the classification in a `target class`. \n- `exp_neg` - explanation with marked features which contribute \nagainst the classification in a `target class`.\n\n#### Basic graying out\n\n    from keras_explain.graying_out import GrayingOut\n\n    explainer = GrayingOut(model)\n    exp_pos, exp_neg = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n\nOutput:\n\n- `exp_pos` - explanation with marked features which contribute \nto the classification in a `target class`. \n- `exp_neg` - explanation with marked features which contribute \nagainst the classification in a `target class`. \n\n#### LIME\n\n    from keras_explain.lime_ribeiro import Lime\n\n    explainer = Lime(model)\n    exp_pos, exp_neg = explainer.explain(image, target_class)\n\nParameters:\n\n- `model` - Keras model which is explained\n- `image` - input which prediction is explained\n- `target_class` - approach explains prediction for a target class\n\nOutput:\n\n- `exp_pos` - explanation with marked features which contribute \nto the classification in a `target class`. \n- `exp_neg` - explanation with marked features which contribute \nagainst the classification in a `target class`.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/primozgodec/keras-explain", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "keras-explain", "package_url": "https://pypi.org/project/keras-explain/", "platform": "", "project_url": "https://pypi.org/project/keras-explain/", "project_urls": {"Homepage": "https://github.com/primozgodec/keras-explain"}, "release_url": "https://pypi.org/project/keras-explain/0.0.1/", "requires_dist": ["Keras (==2.1.6)", "Pillow", "keras-vis-temp", "lime", "pytest"], "requires_python": "", "summary": "Explanation toolbox for Keras models.", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Keras Explain</h1>\n<p>This package includes the majority of explanation tools for explaining\nKeras models predictions. Currently, only models with images on input are\nsupported.\nIt supports following approaches:</p>\n<p>Gradient methods:</p>\n<ul>\n<li>GradCam [<a href=\"https://arxiv.org/abs/1610.02391\" rel=\"nofollow\">Selvaraju</a>]</li>\n<li>Guided GradCam [<a href=\"https://arxiv.org/abs/1610.02391\" rel=\"nofollow\">Selvaraju</a>]</li>\n<li>Guided back-propagation [<a href=\"https://arxiv.org/abs/1412.6806\" rel=\"nofollow\">Springenberg</a>]</li>\n<li>Integrated gradients [<a href=\"https://arxiv.org/abs/1703.01365\" rel=\"nofollow\">Sundararajan</a>]</li>\n<li>Saliency [<a href=\"https://arxiv.org/abs/1312.6034\" rel=\"nofollow\">Simonyan</a>]</li>\n<li>Layer-wise relevance propagation [BETA] [<a href=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140\" rel=\"nofollow\">Bach</a>]</li>\n</ul>\n<p>Model-independent methods:</p>\n<ul>\n<li>Prediction difference [<a href=\"https://arxiv.org/abs/1702.04595\" rel=\"nofollow\">Zintgraf</a>]</li>\n<li>Basic graying out [<a href=\"https://arxiv.org/abs/1311.2901\" rel=\"nofollow\">Zeiler</a>]</li>\n<li>LIME [<a href=\"https://arxiv.org/abs/1602.04938\" rel=\"nofollow\">Ribeiro</a>]</li>\n</ul>\n<p>All approaches are easy to apply to your model in two lines of code.\nIf you have any suggestion for new approaches to be included in the package\nplease do not hesitate to suggest. Also all improvements suggestions, bug reports and bug fixes are welcome.</p>\n<p>Right now we are in the process of implementing the following approaches:</p>\n<ul>\n<li>Meaningful perturbation by Fong et al.</li>\n<li>Layer-wise relevance propagation - we are adding layers that are not supported\nyet.</li>\n</ul>\n<h2>Usage</h2>\n<h3>Gradient methods</h3>\n<h4>GradCam</h4>\n<pre><code>from keras_explain.grad_cam import GradCam\n\nexplainer = GradCam(model, layer=None)\nexp = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n<li><code>layer</code> - (optional) The index (index in model.layers) of the layer which\nprediction is explained.\nIf not specified the last layer prediction is explained automatically.</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp</code> - explanation. GradCam mark only features which contribute to the\nclassification in a <code>target class</code>.</li>\n</ul>\n<h4>Guided GradCam</h4>\n<pre><code>from keras_explain.grad_cam import GuidedGradCam\n\nexplainer = GuidedGradCam(model, lyer=None)\nexp = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n<li><code>layer</code> - (optional) The index (index in model.layers) of the layer which\nprediction is explained.\nIf not specified the last layer prediction is explained automatically.</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp</code> - explanation. GuidedGradCam mark only features which contribute to the\nclassification in a <code>target class</code>.</li>\n</ul>\n<h4>Guided back-propagation</h4>\n<pre><code>from keras_explain.guided_bp import GuidedBP\n\nexplainer = GuidedBP(model)\nexp = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp</code> - explanation. Guided back-propagation mark only features which\ncontribute to the classification in a <code>target class</code>.</li>\n</ul>\n<h4>Integrated gradients</h4>\n<pre><code>from keras_explain.integrated_gradients import IntegratedGradients\n\nexplainer = IntegratedGradients(model)\nexp = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp</code> - explanation. Integrated gradients mark only features which contribute\nto the classification in a <code>target class</code>.</li>\n</ul>\n<h4>Saliency</h4>\n<pre><code>from keras_explain.saliency import Saliency\n\nexplainer = Saliency(model, layer=None)\nexp = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n<li><code>layer</code> - (optional) The index (index in model.layers) of the layer which\nprediction is explained.\nIf not specified the last layer prediction is explained automatically.</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp</code> - explanation. Saliency mark only features which contribute\nto the classification in a <code>target class</code>.</li>\n</ul>\n<h4>Layer-wise relevance propagation [BETA]</h4>\n<p>This approach does not support all layers yet. We are currently implementing\nmissing layers. If you wish you can implement any layer support yourself\nand submit it as a pull request. Since implementation is very custom any\nsuggestion for improvement is welcome.</p>\n<pre><code>from keras_explain.lrp import LRP\n\nexplainer = LRP(model)\nexp = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp</code> - explanation. LRP mark only features which contribute\nto the classification in a <code>target class</code>.</li>\n</ul>\n<p>###Model independent approaches</p>\n<h4>Prediction difference</h4>\n<pre><code>from keras_explain.prediction_diff import PredictionDiff\n\nexplainer = PredictionDiff(model)\nexp_pos, exp_neg = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp_pos</code> - explanation with marked features which contribute\nto the classification in a <code>target class</code>.</li>\n<li><code>exp_neg</code> - explanation with marked features which contribute\nagainst the classification in a <code>target class</code>.</li>\n</ul>\n<h4>Basic graying out</h4>\n<pre><code>from keras_explain.graying_out import GrayingOut\n\nexplainer = GrayingOut(model)\nexp_pos, exp_neg = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp_pos</code> - explanation with marked features which contribute\nto the classification in a <code>target class</code>.</li>\n<li><code>exp_neg</code> - explanation with marked features which contribute\nagainst the classification in a <code>target class</code>.</li>\n</ul>\n<h4>LIME</h4>\n<pre><code>from keras_explain.lime_ribeiro import Lime\n\nexplainer = Lime(model)\nexp_pos, exp_neg = explainer.explain(image, target_class)\n</code></pre>\n<p>Parameters:</p>\n<ul>\n<li><code>model</code> - Keras model which is explained</li>\n<li><code>image</code> - input which prediction is explained</li>\n<li><code>target_class</code> - approach explains prediction for a target class</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li><code>exp_pos</code> - explanation with marked features which contribute\nto the classification in a <code>target class</code>.</li>\n<li><code>exp_neg</code> - explanation with marked features which contribute\nagainst the classification in a <code>target class</code>.</li>\n</ul>\n\n          </div>"}, "last_serial": 4199391, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e50cc4d80b31341d66efbea73820d0f2", "sha256": "8c517ecfc39e34e5a677479b321f681bedba825196dbd7d34867f6a25bce15e3"}, "downloads": -1, "filename": "keras_explain-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e50cc4d80b31341d66efbea73820d0f2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 27017, "upload_time": "2018-08-23T10:22:49", "upload_time_iso_8601": "2018-08-23T10:22:49.196344Z", "url": "https://files.pythonhosted.org/packages/1f/38/bc42ad08465f796e34ac8944762d7e8580f3f31364c49d29cbadf46aa97b/keras_explain-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5a99c39d13a28cc44f130e2973eaa49b", "sha256": "0a03f143b7c7965d6024593cb33e158573eb7cc9f6612d04d2f1cea729d9d80f"}, "downloads": -1, "filename": "keras-explain-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5a99c39d13a28cc44f130e2973eaa49b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22375, "upload_time": "2018-08-23T10:22:51", "upload_time_iso_8601": "2018-08-23T10:22:51.172774Z", "url": "https://files.pythonhosted.org/packages/d6/35/b9b3f20e66b5ec0458112af67565689b3ee77faeb52a12d69ad61cd35ef5/keras-explain-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e50cc4d80b31341d66efbea73820d0f2", "sha256": "8c517ecfc39e34e5a677479b321f681bedba825196dbd7d34867f6a25bce15e3"}, "downloads": -1, "filename": "keras_explain-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e50cc4d80b31341d66efbea73820d0f2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 27017, "upload_time": "2018-08-23T10:22:49", "upload_time_iso_8601": "2018-08-23T10:22:49.196344Z", "url": "https://files.pythonhosted.org/packages/1f/38/bc42ad08465f796e34ac8944762d7e8580f3f31364c49d29cbadf46aa97b/keras_explain-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5a99c39d13a28cc44f130e2973eaa49b", "sha256": "0a03f143b7c7965d6024593cb33e158573eb7cc9f6612d04d2f1cea729d9d80f"}, "downloads": -1, "filename": "keras-explain-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5a99c39d13a28cc44f130e2973eaa49b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22375, "upload_time": "2018-08-23T10:22:51", "upload_time_iso_8601": "2018-08-23T10:22:51.172774Z", "url": "https://files.pythonhosted.org/packages/d6/35/b9b3f20e66b5ec0458112af67565689b3ee77faeb52a12d69ad61cd35ef5/keras-explain-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:12 2020"}