{"info": {"author": "Google Inc.", "author_email": "opensource@google.com", "bugtrack_url": null, "classifiers": [], "description": "# BAM - Benchmarking Attribution Methods\n\nThis repository contains dataset, models, and metrics for benchmarking\nattribution methods (BAM) described in paper [Benchmarking Attribution Methods with Relative Feature Importance](https://arxiv.org/abs/1907.09701). Upon using this library, please cite:\n\n```\n@Article{BAM2019,\n  title = {{Benchmarking Attribution Methods with Relative Feature Importance}},\n  author = {Yang, Mengjiao and Kim, Been},\n  journal   = {CoRR},\n  volume    = {abs/1907.09701},\n  year = {2019}\n}\n```\n\n## Setup\n\nRun the following from the home directory of this repository to install python\ndependencies, download BAM models, download [MSCOCO](http://cocodataset.org) and\n[MiniPlaces](https://github.com/CSAILVision/miniplaces), and construct BAM\ndataset.\n\n```\npip install bam-intp\nsource scripts/download_models.sh\nsource scripts/download_datasets.sh\npython scripts/construct_bam_dataset.py\n```\n\n## Dataset\n\n<img src=\"https://raw.githubusercontent.com/google-research-datasets/bam/master/figures/dataset_demo.png\" width=\"800\">\n\nImages in `data/obj` and `data/scene` are the same but have object and scene\nlabels respectively, as shown in the figure above. `val_loc.txt` records the\ntop-left and bottom-right corner of the object and `val_mask` has the binary\nmasks of the object in the validation set. Additional sets and their usage are\ndescribed in the table below.\n\nName                  | Training | Validation | Usage                             | Description\n:---------------------------------------------------------------------------------| :------: | :--------: | :----------------------------------- | :----------\n`obj`                 | 90,000   | 10,000     | Model contrast                    | Objects and scenes with object labels\n`scene`               | 90,000   | 10,000     | Model contrast & Input dependence | Objects and scenes with scene labels\n`scene_only`          | 90,000   | 10,000     | Input dependence                  | Scene-only images with scene labels\n`dog_bedroom`         | -        | 200        | Relative model contrast           | Dog in bedroom labeled as bedroom\n`bamboo_forest`       | -        | 100        | Input independence                | Scene-only images of bamboo forest\n`bamboo_forest_patch` | -        | 100        | Input independence                | Bamboo forest with functionally insignificant dog patch\n\n## Models\n\nModels in `models/obj`, `models/scene`, and `models/scene_only` are trained on\n`data/obj`, `data/scene`, and `data/scene_only` respectively. Models in\n`models/scenei` for `i` in `{1...10}` are trained on images where dog is added\nto `i` scene classes, and the rest scene classes do not contain any added\nobjects. All models are in TensorFlow's\n[SavedModel](https://www.tensorflow.org/guide/saved_model) format.\n\n## Metrics\n\nBAM metrics compare how interpretability methods perform across models (model\ncontrast), across inputs to the same model (input dependence), and across\nfunctionally equivalent inputs (input independence).\n\n### Model contrast scores\n\nGiven images that contain both objects and scenes, model contrast measures the\ndifference in attributions between the model trained on object labels and the\nmodel trained on scene labels.\n\n<img src=\"https://raw.githubusercontent.com/google-research-datasets/bam/master/figures/mc_demo.png\" width=\"800\">\n\n### Input dependence rate\n\nGiven a model trained on scene labels, input dependence measures the percentage\nof inputs where the addition of objects results in the region being attributed\nas less important.\n\n<img src=\"https://raw.githubusercontent.com/google-research-datasets/bam/master/figures/id_demo.png\" width=\"800\">\n\n### Input independence rate\n\nGiven a model trained on scene-only images, input independence measures the\npercentage of inputs where a functionally insignificant patch (e.g., a dog) does\nnot affect explanations significantly.\n\n<img src=\"https://raw.githubusercontent.com/google-research-datasets/bam/master/figures/ii_demo.png\" width=\"800\">\n\n## Evaluate saliency methods\n\nTo compute model contrast score (MCS) over randomly selected 10 images, you can\nrun\n\n```\npython bam/metrics.py --metrics=MCS --num_imgs=10\n```\n\nTo compute input dependence rate (IDR), change `--metrics` to `IDR`. To compute\ninput independence rate (IIR), you need to first constructs a set of\nfunctionally insignificant patches by running\n\n```\npython scripts/construct_delta_patch.py\n```\n\nand then evaluate IIR by running\n\n```\npython bam/metrics.py --metrics=IIR --num_imgs=10\n```\n\n## Evaluate TCAV\n\n[TCAV](https://github.com/tensorflow/tcav) is a global concept attribution\nmethod whose MCS can be measured by comparing the TCAV scores of a particular\nobject concept for the object model and the scene model. Run the following to\ncompute the TCAV scores of the dog concept for the object model.\n\n```\npython bam/run_tcav.py --model=obj\n```\n\n## Disclaimer\n\nThis is not an officially supported Google product.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/google-research-datasets/bam", "keywords": "", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "bam-intp", "package_url": "https://pypi.org/project/bam-intp/", "platform": "", "project_url": "https://pypi.org/project/bam-intp/", "project_urls": {"Homepage": "https://github.com/google-research-datasets/bam"}, "release_url": "https://pypi.org/project/bam-intp/0.1/", "requires_dist": ["numpy", "tensorflow", "Pillow (>=6.0.0)", "tcav (>=0.2.1)", "saliency (>=0.0.2)", "Cython (>=0.29.12)", "pycocotools (>=2.0.0)", "scikit-learn (>=0.20.3)"], "requires_python": "", "summary": "Benchmarking attribution methods.", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>BAM - Benchmarking Attribution Methods</h1>\n<p>This repository contains dataset, models, and metrics for benchmarking\nattribution methods (BAM) described in paper <a href=\"https://arxiv.org/abs/1907.09701\" rel=\"nofollow\">Benchmarking Attribution Methods with Relative Feature Importance</a>. Upon using this library, please cite:</p>\n<pre><code>@Article{BAM2019,\n  title = {{Benchmarking Attribution Methods with Relative Feature Importance}},\n  author = {Yang, Mengjiao and Kim, Been},\n  journal   = {CoRR},\n  volume    = {abs/1907.09701},\n  year = {2019}\n}\n</code></pre>\n<h2>Setup</h2>\n<p>Run the following from the home directory of this repository to install python\ndependencies, download BAM models, download <a href=\"http://cocodataset.org\" rel=\"nofollow\">MSCOCO</a> and\n<a href=\"https://github.com/CSAILVision/miniplaces\" rel=\"nofollow\">MiniPlaces</a>, and construct BAM\ndataset.</p>\n<pre><code>pip install bam-intp\nsource scripts/download_models.sh\nsource scripts/download_datasets.sh\npython scripts/construct_bam_dataset.py\n</code></pre>\n<h2>Dataset</h2>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d8e5880298dfabefc2158c346934c910a5afb4f8/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f676f6f676c652d72657365617263682d64617461736574732f62616d2f6d61737465722f666967757265732f646174617365745f64656d6f2e706e67\" width=\"800\">\n<p>Images in <code>data/obj</code> and <code>data/scene</code> are the same but have object and scene\nlabels respectively, as shown in the figure above. <code>val_loc.txt</code> records the\ntop-left and bottom-right corner of the object and <code>val_mask</code> has the binary\nmasks of the object in the validation set. Additional sets and their usage are\ndescribed in the table below.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Name</th>\n<th align=\"center\">Training</th>\n<th align=\"center\">Validation</th>\n<th align=\"left\">Usage</th>\n<th align=\"left\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><code>obj</code></td>\n<td align=\"center\">90,000</td>\n<td align=\"center\">10,000</td>\n<td align=\"left\">Model contrast</td>\n<td align=\"left\">Objects and scenes with object labels</td>\n</tr>\n<tr>\n<td align=\"left\"><code>scene</code></td>\n<td align=\"center\">90,000</td>\n<td align=\"center\">10,000</td>\n<td align=\"left\">Model contrast &amp; Input dependence</td>\n<td align=\"left\">Objects and scenes with scene labels</td>\n</tr>\n<tr>\n<td align=\"left\"><code>scene_only</code></td>\n<td align=\"center\">90,000</td>\n<td align=\"center\">10,000</td>\n<td align=\"left\">Input dependence</td>\n<td align=\"left\">Scene-only images with scene labels</td>\n</tr>\n<tr>\n<td align=\"left\"><code>dog_bedroom</code></td>\n<td align=\"center\">-</td>\n<td align=\"center\">200</td>\n<td align=\"left\">Relative model contrast</td>\n<td align=\"left\">Dog in bedroom labeled as bedroom</td>\n</tr>\n<tr>\n<td align=\"left\"><code>bamboo_forest</code></td>\n<td align=\"center\">-</td>\n<td align=\"center\">100</td>\n<td align=\"left\">Input independence</td>\n<td align=\"left\">Scene-only images of bamboo forest</td>\n</tr>\n<tr>\n<td align=\"left\"><code>bamboo_forest_patch</code></td>\n<td align=\"center\">-</td>\n<td align=\"center\">100</td>\n<td align=\"left\">Input independence</td>\n<td align=\"left\">Bamboo forest with functionally insignificant dog patch</td>\n</tr></tbody></table>\n<h2>Models</h2>\n<p>Models in <code>models/obj</code>, <code>models/scene</code>, and <code>models/scene_only</code> are trained on\n<code>data/obj</code>, <code>data/scene</code>, and <code>data/scene_only</code> respectively. Models in\n<code>models/scenei</code> for <code>i</code> in <code>{1...10}</code> are trained on images where dog is added\nto <code>i</code> scene classes, and the rest scene classes do not contain any added\nobjects. All models are in TensorFlow's\n<a href=\"https://www.tensorflow.org/guide/saved_model\" rel=\"nofollow\">SavedModel</a> format.</p>\n<h2>Metrics</h2>\n<p>BAM metrics compare how interpretability methods perform across models (model\ncontrast), across inputs to the same model (input dependence), and across\nfunctionally equivalent inputs (input independence).</p>\n<h3>Model contrast scores</h3>\n<p>Given images that contain both objects and scenes, model contrast measures the\ndifference in attributions between the model trained on object labels and the\nmodel trained on scene labels.</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3865d344f30b1986176f44ab3390ee355f8af261/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f676f6f676c652d72657365617263682d64617461736574732f62616d2f6d61737465722f666967757265732f6d635f64656d6f2e706e67\" width=\"800\">\n<h3>Input dependence rate</h3>\n<p>Given a model trained on scene labels, input dependence measures the percentage\nof inputs where the addition of objects results in the region being attributed\nas less important.</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0151f06291623bcdaba1da4a69c3b05996a35ceb/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f676f6f676c652d72657365617263682d64617461736574732f62616d2f6d61737465722f666967757265732f69645f64656d6f2e706e67\" width=\"800\">\n<h3>Input independence rate</h3>\n<p>Given a model trained on scene-only images, input independence measures the\npercentage of inputs where a functionally insignificant patch (e.g., a dog) does\nnot affect explanations significantly.</p>\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e4ed923a2c73e4319859e4583d1c04341e5e5075/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f676f6f676c652d72657365617263682d64617461736574732f62616d2f6d61737465722f666967757265732f69695f64656d6f2e706e67\" width=\"800\">\n<h2>Evaluate saliency methods</h2>\n<p>To compute model contrast score (MCS) over randomly selected 10 images, you can\nrun</p>\n<pre><code>python bam/metrics.py --metrics=MCS --num_imgs=10\n</code></pre>\n<p>To compute input dependence rate (IDR), change <code>--metrics</code> to <code>IDR</code>. To compute\ninput independence rate (IIR), you need to first constructs a set of\nfunctionally insignificant patches by running</p>\n<pre><code>python scripts/construct_delta_patch.py\n</code></pre>\n<p>and then evaluate IIR by running</p>\n<pre><code>python bam/metrics.py --metrics=IIR --num_imgs=10\n</code></pre>\n<h2>Evaluate TCAV</h2>\n<p><a href=\"https://github.com/tensorflow/tcav\" rel=\"nofollow\">TCAV</a> is a global concept attribution\nmethod whose MCS can be measured by comparing the TCAV scores of a particular\nobject concept for the object model and the scene model. Run the following to\ncompute the TCAV scores of the dog concept for the object model.</p>\n<pre><code>python bam/run_tcav.py --model=obj\n</code></pre>\n<h2>Disclaimer</h2>\n<p>This is not an officially supported Google product.</p>\n\n          </div>"}, "last_serial": 6085126, "releases": {"0.0": [{"comment_text": "", "digests": {"md5": "1caa7dd7b26eb677516758057afc3a32", "sha256": "fc9cd0ade034aa494e6313c020fcad075803d6f419750c2ae26514cb3d303324"}, "downloads": -1, "filename": "bam_intp-0.0-py2-none-any.whl", "has_sig": false, "md5_digest": "1caa7dd7b26eb677516758057afc3a32", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 17478, "upload_time": "2019-11-06T06:16:47", "upload_time_iso_8601": "2019-11-06T06:16:47.098591Z", "url": "https://files.pythonhosted.org/packages/fb/3e/1af5c99f2abc3a1b0a41e88d87879ad1f24426e65ef37277d3de78471215/bam_intp-0.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3e190a02d3e3614dcd1fbe085c75cc9a", "sha256": "ca4f9491455aad2051afc77c6f510a3edf7862be31159f148f1ad9db01beb54d"}, "downloads": -1, "filename": "bam-intp-0.0.tar.gz", "has_sig": false, "md5_digest": "3e190a02d3e3614dcd1fbe085c75cc9a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11458, "upload_time": "2019-11-06T06:16:49", "upload_time_iso_8601": "2019-11-06T06:16:49.409296Z", "url": "https://files.pythonhosted.org/packages/89/dc/803d461578656bf9507aa9c6028068f77f410353f8ada4a24d7c2a694496/bam-intp-0.0.tar.gz", "yanked": false}], "0.1": [{"comment_text": "", "digests": {"md5": "5e713f6c1526cadae91b183e85bf6245", "sha256": "189ab7c5719c80824cc9965b8cd18ff4c2d9ec9059bb2549ebd6e72ca861f4f4"}, "downloads": -1, "filename": "bam_intp-0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "5e713f6c1526cadae91b183e85bf6245", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 17481, "upload_time": "2019-11-06T06:24:11", "upload_time_iso_8601": "2019-11-06T06:24:11.075858Z", "url": "https://files.pythonhosted.org/packages/3a/51/8de62e36ac7e2fa50cddd6baf60d89539a9472f25636b8978b889a144df6/bam_intp-0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "778e1f3388a9e880845e93fe71dd1a22", "sha256": "c7dec94da341bad4818a793c095e619ef5dc678cb9f8c577a2ca049b27cc30e3"}, "downloads": -1, "filename": "bam-intp-0.1.tar.gz", "has_sig": false, "md5_digest": "778e1f3388a9e880845e93fe71dd1a22", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11447, "upload_time": "2019-11-06T06:24:12", "upload_time_iso_8601": "2019-11-06T06:24:12.619741Z", "url": "https://files.pythonhosted.org/packages/e1/e6/ae10032a456f52d9bc4c83c66d9ad809ec869a4c1723a08d6196de5b9973/bam-intp-0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5e713f6c1526cadae91b183e85bf6245", "sha256": "189ab7c5719c80824cc9965b8cd18ff4c2d9ec9059bb2549ebd6e72ca861f4f4"}, "downloads": -1, "filename": "bam_intp-0.1-py2-none-any.whl", "has_sig": false, "md5_digest": "5e713f6c1526cadae91b183e85bf6245", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 17481, "upload_time": "2019-11-06T06:24:11", "upload_time_iso_8601": "2019-11-06T06:24:11.075858Z", "url": "https://files.pythonhosted.org/packages/3a/51/8de62e36ac7e2fa50cddd6baf60d89539a9472f25636b8978b889a144df6/bam_intp-0.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "778e1f3388a9e880845e93fe71dd1a22", "sha256": "c7dec94da341bad4818a793c095e619ef5dc678cb9f8c577a2ca049b27cc30e3"}, "downloads": -1, "filename": "bam-intp-0.1.tar.gz", "has_sig": false, "md5_digest": "778e1f3388a9e880845e93fe71dd1a22", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11447, "upload_time": "2019-11-06T06:24:12", "upload_time_iso_8601": "2019-11-06T06:24:12.619741Z", "url": "https://files.pythonhosted.org/packages/e1/e6/ae10032a456f52d9bc4c83c66d9ad809ec869a4c1723a08d6196de5b9973/bam-intp-0.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:14:58 2020"}