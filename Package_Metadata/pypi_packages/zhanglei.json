{"info": {"author": "Example Author", "author_email": "author@example.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Text Classification with CNN and RNN\n\n### \u9700\u8981\u4fee\u6539\u5730\u65b9\n1\uff0c\u9700\u8981\u4fee\u6539\u5355\u8bcd\u5b57\u5178\uff1b  \n2\uff0c\u6587\u4ef6\u8bfb\u53d6\u4e0d\u6210\u529f\n3\uff0c\u4fee\u6539cnn\u6a21\u578b\u4e2d\u7684\u7c7b\u522b\u6570\u76ee\n----\nupdate\u8fd9\u4e48\u591a\u4e1c\u897f\u53bb\u54ea\u91cc\u4e86 CNN\u505a\u53e5\u5b50\u5206\u7c7b\u7684\u8bba\u6587\u53ef\u4ee5\u53c2\u770b: [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)\n\n\u8fd8\u53ef\u4ee5\u53bb\u8bfbdennybritz\u5927\u725b\u7684\u535a\u5ba2\uff1a[Implementing a CNN for Text Classification in TensorFlow](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n\n\u4ee5\u53ca\u5b57\u7b26\u7ea7CNN\u7684\u8bba\u6587\uff1a[Character-level Convolutional Networks for Text Classification](https://arxiv.org/abs/1509.01626)\n\n\u672c\u6587\u662f\u57fa\u4e8eTensorFlow\u5728\u4e2d\u6587\u6570\u636e\u96c6\u4e0a\u7684\u7b80\u5316\u5b9e\u73b0\uff0c\u4f7f\u7528\u4e86\u5b57\u7b26\u7ea7CNN\u548cRNN\u5bf9\u4e2d\u6587\u6587\u672c\u8fdb\u884c\u5206\u7c7b\uff0c\u8fbe\u5230\u4e86\u8f83\u597d\u7684\u6548\u679c\u3002\n\n\u6587\u4e2d\u6240\u4f7f\u7528\u7684Conv1D\u4e0e\u8bba\u6587\u4e2d\u6709\u4e9b\u4e0d\u540c\uff0c\u8be6\u7ec6\u53c2\u8003\u5b98\u65b9\u6587\u6863\uff1a[tf.nn.conv1d](https://www.tensorflow.org/api_docs/python/tf/nn/conv1d)\n\n## \u73af\u5883\n\n- Python 2/3 (\u611f\u8c22[howie.hu](https://github.com/howie6879)\u8c03\u8bd5Python2\u73af\u5883)\n- TensorFlow 1.3\u4ee5\u4e0a\n- numpy\n- scikit-learn\n- scipy\n\n## \u6570\u636e\u96c6\n\n\u4f7f\u7528THUCNews\u7684\u4e00\u4e2a\u5b50\u96c6\u8fdb\u884c\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\uff0c\u6570\u636e\u96c6\u8bf7\u81ea\u884c\u5230[THUCTC\uff1a\u4e00\u4e2a\u9ad8\u6548\u7684\u4e2d\u6587\u6587\u672c\u5206\u7c7b\u5de5\u5177\u5305](http://thuctc.thunlp.org/)\u4e0b\u8f7d\uff0c\u8bf7\u9075\u5faa\u6570\u636e\u63d0\u4f9b\u65b9\u7684\u5f00\u6e90\u534f\u8bae\u3002\n\n\u672c\u6b21\u8bad\u7ec3\u4f7f\u7528\u4e86\u5176\u4e2d\u768410\u4e2a\u5206\u7c7b\uff0c\u6bcf\u4e2a\u5206\u7c7b6500\u6761\u6570\u636e\u3002\n\n\u7c7b\u522b\u5982\u4e0b\uff1a\n\n```\n\u4f53\u80b2, \u8d22\u7ecf, \u623f\u4ea7, \u5bb6\u5c45, \u6559\u80b2, \u79d1\u6280, \u65f6\u5c1a, \u65f6\u653f, \u6e38\u620f, \u5a31\u4e50\n```\n\n\u8fd9\u4e2a\u5b50\u96c6\u53ef\u4ee5\u5728\u6b64\u4e0b\u8f7d\uff1a\u94fe\u63a5: https://pan.baidu.com/s/1hugrfRu \u5bc6\u7801: qfud\n\n\u6570\u636e\u96c6\u5212\u5206\u5982\u4e0b\uff1a\n\n- \u8bad\u7ec3\u96c6: 5000*10\n- \u9a8c\u8bc1\u96c6: 500*10\n- \u6d4b\u8bd5\u96c6: 1000*10\n\n\u4ece\u539f\u6570\u636e\u96c6\u751f\u6210\u5b50\u96c6\u7684\u8fc7\u7a0b\u8bf7\u53c2\u770b`helper`\u4e0b\u7684\u4e24\u4e2a\u811a\u672c\u3002\u5176\u4e2d\uff0c`copy_data.sh`\u7528\u4e8e\u4ece\u6bcf\u4e2a\u5206\u7c7b\u62f7\u8d1d6500\u4e2a\u6587\u4ef6\uff0c`cnews_group.py`\u7528\u4e8e\u5c06\u591a\u4e2a\u6587\u4ef6\u6574\u5408\u5230\u4e00\u4e2a\u6587\u4ef6\u4e2d\u3002\u6267\u884c\u8be5\u6587\u4ef6\u540e\uff0c\u5f97\u5230\u4e09\u4e2a\u6570\u636e\u6587\u4ef6\uff1a\n\n- cnews.train.txt: \u8bad\u7ec3\u96c6(50000\u6761)\n- cnews.val.txt: \u9a8c\u8bc1\u96c6(5000\u6761)\n- cnews.test.txt: \u6d4b\u8bd5\u96c6(10000\u6761)\n\n## \u9884\u5904\u7406\n\n`data/cnews_loader.py`\u4e3a\u6570\u636e\u7684\u9884\u5904\u7406\u6587\u4ef6\u3002\n\n- `read_file()`: \u8bfb\u53d6\u6587\u4ef6\u6570\u636e;\n- `build_vocab()`: \u6784\u5efa\u8bcd\u6c47\u8868\uff0c\u4f7f\u7528\u5b57\u7b26\u7ea7\u7684\u8868\u793a\uff0c\u8fd9\u4e00\u51fd\u6570\u4f1a\u5c06\u8bcd\u6c47\u8868\u5b58\u50a8\u4e0b\u6765\uff0c\u907f\u514d\u6bcf\u4e00\u6b21\u91cd\u590d\u5904\u7406;\n- `read_vocab()`: \u8bfb\u53d6\u4e0a\u4e00\u6b65\u5b58\u50a8\u7684\u8bcd\u6c47\u8868\uff0c\u8f6c\u6362\u4e3a`{\u8bcd\uff1aid}`\u8868\u793a;\n- `read_category()`: \u5c06\u5206\u7c7b\u76ee\u5f55\u56fa\u5b9a\uff0c\u8f6c\u6362\u4e3a`{\u7c7b\u522b: id}`\u8868\u793a;\n- `to_words()`: \u5c06\u4e00\u6761\u7531id\u8868\u793a\u7684\u6570\u636e\u91cd\u65b0\u8f6c\u6362\u4e3a\u6587\u5b57;\n- `process_file()`: \u5c06\u6570\u636e\u96c6\u4ece\u6587\u5b57\u8f6c\u6362\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684id\u5e8f\u5217\u8868\u793a;\n- `batch_iter()`: \u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u51c6\u5907\u7ecf\u8fc7shuffle\u7684\u6279\u6b21\u7684\u6570\u636e\u3002\n\n\u7ecf\u8fc7\u6570\u636e\u9884\u5904\u7406\uff0c\u6570\u636e\u7684\u683c\u5f0f\u5982\u4e0b\uff1a\n\n| Data | Shape | Data | Shape |\n| :---------- | :---------- | :---------- | :---------- |\n| x_train | [50000, 600] | y_train | [50000, 10] |\n| x_val | [5000, 600] | y_val | [5000, 10] |\n| x_test | [10000, 600] | y_test | [10000, 10] |\n\n## CNN\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\n### \u914d\u7f6e\u9879\n\nCNN\u53ef\u914d\u7f6e\u7684\u53c2\u6570\u5982\u4e0b\u6240\u793a\uff0c\u5728`cnn_model.py`\u4e2d\u3002\n\n```python\nclass TCNNConfig(object):\n    \"\"\"CNN\u914d\u7f6e\u53c2\u6570\"\"\"\n\n    embedding_dim = 64      # \u8bcd\u5411\u91cf\u7ef4\u5ea6\n    seq_length = 600        # \u5e8f\u5217\u957f\u5ea6\n    num_classes = 10        # \u7c7b\u522b\u6570\n    num_filters = 128        # \u5377\u79ef\u6838\u6570\u76ee\n    kernel_size = 5         # \u5377\u79ef\u6838\u5c3a\u5bf8\n    vocab_size = 5000       # \u8bcd\u6c47\u8868\u8fbe\u5c0f\n\n    hidden_dim = 128        # \u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143\n\n    dropout_keep_prob = 0.5 # dropout\u4fdd\u7559\u6bd4\u4f8b\n    learning_rate = 1e-3    # \u5b66\u4e60\u7387\n\n    batch_size = 64         # \u6bcf\u6279\u8bad\u7ec3\u5927\u5c0f\n    num_epochs = 10         # \u603b\u8fed\u4ee3\u8f6e\u6b21\n\n    print_per_batch = 100    # \u6bcf\u591a\u5c11\u8f6e\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\n    save_per_batch = 10      # \u6bcf\u591a\u5c11\u8f6e\u5b58\u5165tensorboard\n```\n\n### CNN\u6a21\u578b\n\n\u5177\u4f53\u53c2\u770b`cnn_model.py`\u7684\u5b9e\u73b0\u3002\n\n\u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a\n\n![images/cnn_architecture](images/cnn_architecture.png)\n\n### \u8bad\u7ec3\u4e0e\u9a8c\u8bc1\n\n\u8fd0\u884c `python run_cnn.py train`\uff0c\u53ef\u4ee5\u5f00\u59cb\u8bad\u7ec3\u3002\n\n> \u82e5\u4e4b\u524d\u8fdb\u884c\u8fc7\u8bad\u7ec3\uff0c\u8bf7\u628atensorboard/textcnn\u5220\u9664\uff0c\u907f\u514dTensorBoard\u591a\u6b21\u8bad\u7ec3\u7ed3\u679c\u91cd\u53e0\u3002\n\n```\nConfiguring CNN model...\nConfiguring TensorBoard and Saver...\nLoading training and validation data...\nTime usage: 0:00:14\nTraining and evaluating...\nEpoch: 1\nIter:      0, Train Loss:    2.3, Train Acc:  10.94%, Val Loss:    2.3, Val Acc:   8.92%, Time: 0:00:01 *\nIter:    100, Train Loss:   0.88, Train Acc:  73.44%, Val Loss:    1.2, Val Acc:  68.46%, Time: 0:00:04 *\nIter:    200, Train Loss:   0.38, Train Acc:  92.19%, Val Loss:   0.75, Val Acc:  77.32%, Time: 0:00:07 *\nIter:    300, Train Loss:   0.22, Train Acc:  92.19%, Val Loss:   0.46, Val Acc:  87.08%, Time: 0:00:09 *\nIter:    400, Train Loss:   0.24, Train Acc:  90.62%, Val Loss:    0.4, Val Acc:  88.62%, Time: 0:00:12 *\nIter:    500, Train Loss:   0.16, Train Acc:  96.88%, Val Loss:   0.36, Val Acc:  90.38%, Time: 0:00:15 *\nIter:    600, Train Loss:  0.084, Train Acc:  96.88%, Val Loss:   0.35, Val Acc:  91.36%, Time: 0:00:17 *\nIter:    700, Train Loss:   0.21, Train Acc:  93.75%, Val Loss:   0.26, Val Acc:  92.58%, Time: 0:00:20 *\nEpoch: 2\nIter:    800, Train Loss:   0.07, Train Acc:  98.44%, Val Loss:   0.24, Val Acc:  94.12%, Time: 0:00:23 *\nIter:    900, Train Loss:  0.092, Train Acc:  96.88%, Val Loss:   0.27, Val Acc:  92.86%, Time: 0:00:25\nIter:   1000, Train Loss:   0.17, Train Acc:  95.31%, Val Loss:   0.28, Val Acc:  92.82%, Time: 0:00:28\nIter:   1100, Train Loss:    0.2, Train Acc:  93.75%, Val Loss:   0.23, Val Acc:  93.26%, Time: 0:00:31\nIter:   1200, Train Loss:  0.081, Train Acc:  98.44%, Val Loss:   0.25, Val Acc:  92.96%, Time: 0:00:33\nIter:   1300, Train Loss:  0.052, Train Acc: 100.00%, Val Loss:   0.24, Val Acc:  93.58%, Time: 0:00:36\nIter:   1400, Train Loss:    0.1, Train Acc:  95.31%, Val Loss:   0.22, Val Acc:  94.12%, Time: 0:00:39\nIter:   1500, Train Loss:   0.12, Train Acc:  98.44%, Val Loss:   0.23, Val Acc:  93.58%, Time: 0:00:41\nEpoch: 3\nIter:   1600, Train Loss:    0.1, Train Acc:  96.88%, Val Loss:   0.26, Val Acc:  92.34%, Time: 0:00:44\nIter:   1700, Train Loss:  0.018, Train Acc: 100.00%, Val Loss:   0.22, Val Acc:  93.46%, Time: 0:00:47\nIter:   1800, Train Loss:  0.036, Train Acc: 100.00%, Val Loss:   0.28, Val Acc:  92.72%, Time: 0:00:50\nNo optimization for a long time, auto-stopping...\n```\n\n\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6700\u4f73\u6548\u679c\u4e3a94.12%\uff0c\u4e14\u53ea\u7ecf\u8fc7\u4e863\u8f6e\u8fed\u4ee3\u5c31\u5df2\u7ecf\u505c\u6b62\u3002\n\n\u51c6\u786e\u7387\u548c\u8bef\u5dee\u5982\u56fe\u6240\u793a\uff1a\n\n![images](images/acc_loss.png)\n\n\n### \u6d4b\u8bd5\n\n\u8fd0\u884c `python run_cnn.py test` \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\n\n```\nConfiguring CNN model...\nLoading test data...\nTesting...\nTest Loss:   0.14, Test Acc:  96.04%\nPrecision, Recall and F1-Score...\n             precision    recall  f1-score   support\n\n         \u4f53\u80b2       0.99      0.99      0.99      1000\n         \u8d22\u7ecf       0.96      0.99      0.97      1000\n         \u623f\u4ea7       1.00      1.00      1.00      1000\n         \u5bb6\u5c45       0.95      0.91      0.93      1000\n         \u6559\u80b2       0.95      0.89      0.92      1000\n         \u79d1\u6280       0.94      0.97      0.95      1000\n         \u65f6\u5c1a       0.95      0.97      0.96      1000\n         \u65f6\u653f       0.94      0.94      0.94      1000\n         \u6e38\u620f       0.97      0.96      0.97      1000\n         \u5a31\u4e50       0.95      0.98      0.97      1000\n\navg / total       0.96      0.96      0.96     10000\n\nConfusion Matrix...\n[[991   0   0   0   2   1   0   4   1   1]\n [  0 992   0   0   2   1   0   5   0   0]\n [  0   1 996   0   1   1   0   0   0   1]\n [  0  14   0 912   7  15   9  29   3  11]\n [  2   9   0  12 892  22  18  21  10  14]\n [  0   0   0  10   1 968   4   3  12   2]\n [  1   0   0   9   4   4 971   0   2   9]\n [  1  16   0   4  18  12   1 941   1   6]\n [  2   4   1   5   4   5  10   1 962   6]\n [  1   0   1   6   4   3   5   0   1 979]]\nTime usage: 0:00:05\n```\n\n\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e8696.04%\uff0c\u4e14\u5404\u7c7b\u7684precision, recall\u548cf1-score\u90fd\u8d85\u8fc7\u4e860.9\u3002\n\n\u4ece\u6df7\u6dc6\u77e9\u9635\u4e5f\u53ef\u4ee5\u770b\u51fa\u5206\u7c7b\u6548\u679c\u975e\u5e38\u4f18\u79c0\u3002\n\n## RNN\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\n\n### \u914d\u7f6e\u9879\n\nRNN\u53ef\u914d\u7f6e\u7684\u53c2\u6570\u5982\u4e0b\u6240\u793a\uff0c\u5728`rnn_model.py`\u4e2d\u3002\n\n```python\nclass TRNNConfig(object):\n    \"\"\"RNN\u914d\u7f6e\u53c2\u6570\"\"\"\n\n    # \u6a21\u578b\u53c2\u6570\n    embedding_dim = 64      # \u8bcd\u5411\u91cf\u7ef4\u5ea6\n    seq_length = 600        # \u5e8f\u5217\u957f\u5ea6\n    num_classes = 10        # \u7c7b\u522b\u6570\n    vocab_size = 5000       # \u8bcd\u6c47\u8868\u8fbe\u5c0f\n\n    num_layers= 2           # \u9690\u85cf\u5c42\u5c42\u6570\n    hidden_dim = 128        # \u9690\u85cf\u5c42\u795e\u7ecf\u5143\n    rnn = 'gru'             # lstm \u6216 gru\n\n    dropout_keep_prob = 0.8 # dropout\u4fdd\u7559\u6bd4\u4f8b\n    learning_rate = 1e-3    # \u5b66\u4e60\u7387\n\n    batch_size = 128         # \u6bcf\u6279\u8bad\u7ec3\u5927\u5c0f\n    num_epochs = 10          # \u603b\u8fed\u4ee3\u8f6e\u6b21\n\n    print_per_batch = 100    # \u6bcf\u591a\u5c11\u8f6e\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\n    save_per_batch = 10      # \u6bcf\u591a\u5c11\u8f6e\u5b58\u5165tensorboard\n```\n\n### RNN\u6a21\u578b\n\n\u5177\u4f53\u53c2\u770b`rnn_model.py`\u7684\u5b9e\u73b0\u3002\n\n\u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a\n\n![images/rnn_architecture](images/rnn_architecture.png)\n\n### \u8bad\u7ec3\u4e0e\u9a8c\u8bc1\n\n> \u8fd9\u90e8\u5206\u7684\u4ee3\u7801\u4e0e run_cnn.py\u6781\u4e3a\u76f8\u4f3c\uff0c\u53ea\u9700\u8981\u5c06\u6a21\u578b\u548c\u90e8\u5206\u76ee\u5f55\u7a0d\u5fae\u4fee\u6539\u3002\n\n\u8fd0\u884c `python run_rnn.py train`\uff0c\u53ef\u4ee5\u5f00\u59cb\u8bad\u7ec3\u3002\n\n> \u82e5\u4e4b\u524d\u8fdb\u884c\u8fc7\u8bad\u7ec3\uff0c\u8bf7\u628atensorboard/textrnn\u5220\u9664\uff0c\u907f\u514dTensorBoard\u591a\u6b21\u8bad\u7ec3\u7ed3\u679c\u91cd\u53e0\u3002\n\n```\nConfiguring RNN model...\nConfiguring TensorBoard and Saver...\nLoading training and validation data...\nTime usage: 0:00:14\nTraining and evaluating...\nEpoch: 1\nIter:      0, Train Loss:    2.3, Train Acc:   8.59%, Val Loss:    2.3, Val Acc:  11.96%, Time: 0:00:08 *\nIter:    100, Train Loss:   0.95, Train Acc:  64.06%, Val Loss:    1.3, Val Acc:  53.06%, Time: 0:01:15 *\nIter:    200, Train Loss:   0.61, Train Acc:  79.69%, Val Loss:   0.94, Val Acc:  69.88%, Time: 0:02:22 *\nIter:    300, Train Loss:   0.49, Train Acc:  85.16%, Val Loss:   0.63, Val Acc:  81.44%, Time: 0:03:29 *\nEpoch: 2\nIter:    400, Train Loss:   0.23, Train Acc:  92.97%, Val Loss:    0.6, Val Acc:  82.86%, Time: 0:04:36 *\nIter:    500, Train Loss:   0.27, Train Acc:  92.97%, Val Loss:   0.47, Val Acc:  86.72%, Time: 0:05:43 *\nIter:    600, Train Loss:   0.13, Train Acc:  98.44%, Val Loss:   0.43, Val Acc:  87.46%, Time: 0:06:50 *\nIter:    700, Train Loss:   0.24, Train Acc:  91.41%, Val Loss:   0.46, Val Acc:  87.12%, Time: 0:07:57\nEpoch: 3\nIter:    800, Train Loss:   0.11, Train Acc:  96.09%, Val Loss:   0.49, Val Acc:  87.02%, Time: 0:09:03\nIter:    900, Train Loss:   0.15, Train Acc:  96.09%, Val Loss:   0.55, Val Acc:  85.86%, Time: 0:10:10\nIter:   1000, Train Loss:   0.17, Train Acc:  96.09%, Val Loss:   0.43, Val Acc:  89.44%, Time: 0:11:18 *\nIter:   1100, Train Loss:   0.25, Train Acc:  93.75%, Val Loss:   0.42, Val Acc:  88.98%, Time: 0:12:25\nEpoch: 4\nIter:   1200, Train Loss:   0.14, Train Acc:  96.09%, Val Loss:   0.39, Val Acc:  89.82%, Time: 0:13:32 *\nIter:   1300, Train Loss:    0.2, Train Acc:  96.09%, Val Loss:   0.43, Val Acc:  88.68%, Time: 0:14:38\nIter:   1400, Train Loss:  0.012, Train Acc: 100.00%, Val Loss:   0.37, Val Acc:  90.58%, Time: 0:15:45 *\nIter:   1500, Train Loss:   0.15, Train Acc:  96.88%, Val Loss:   0.39, Val Acc:  90.58%, Time: 0:16:52\nEpoch: 5\nIter:   1600, Train Loss:  0.075, Train Acc:  97.66%, Val Loss:   0.41, Val Acc:  89.90%, Time: 0:17:59\nIter:   1700, Train Loss:  0.042, Train Acc:  98.44%, Val Loss:   0.41, Val Acc:  90.08%, Time: 0:19:06\nIter:   1800, Train Loss:   0.08, Train Acc:  97.66%, Val Loss:   0.38, Val Acc:  91.36%, Time: 0:20:13 *\nIter:   1900, Train Loss:  0.089, Train Acc:  98.44%, Val Loss:   0.39, Val Acc:  90.18%, Time: 0:21:20\nEpoch: 6\nIter:   2000, Train Loss:  0.092, Train Acc:  96.88%, Val Loss:   0.36, Val Acc:  91.42%, Time: 0:22:27 *\nIter:   2100, Train Loss:  0.062, Train Acc:  98.44%, Val Loss:   0.39, Val Acc:  90.56%, Time: 0:23:34\nIter:   2200, Train Loss:  0.053, Train Acc:  98.44%, Val Loss:   0.39, Val Acc:  90.02%, Time: 0:24:41\nIter:   2300, Train Loss:   0.12, Train Acc:  96.09%, Val Loss:   0.37, Val Acc:  90.84%, Time: 0:25:48\nEpoch: 7\nIter:   2400, Train Loss:  0.014, Train Acc: 100.00%, Val Loss:   0.41, Val Acc:  90.38%, Time: 0:26:55\nIter:   2500, Train Loss:   0.14, Train Acc:  96.88%, Val Loss:   0.37, Val Acc:  91.22%, Time: 0:28:01\nIter:   2600, Train Loss:   0.11, Train Acc:  96.88%, Val Loss:   0.43, Val Acc:  89.76%, Time: 0:29:08\nIter:   2700, Train Loss:  0.089, Train Acc:  97.66%, Val Loss:   0.37, Val Acc:  91.18%, Time: 0:30:15\nEpoch: 8\nIter:   2800, Train Loss: 0.0081, Train Acc: 100.00%, Val Loss:   0.44, Val Acc:  90.66%, Time: 0:31:22\nIter:   2900, Train Loss:  0.017, Train Acc: 100.00%, Val Loss:   0.44, Val Acc:  89.62%, Time: 0:32:29\nIter:   3000, Train Loss:  0.061, Train Acc:  96.88%, Val Loss:   0.43, Val Acc:  90.04%, Time: 0:33:36\nNo optimization for a long time, auto-stopping...\n```\n\n\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6700\u4f73\u6548\u679c\u4e3a91.42%\uff0c\u7ecf\u8fc7\u4e868\u8f6e\u8fed\u4ee3\u505c\u6b62\uff0c\u901f\u5ea6\u76f8\u6bd4CNN\u6162\u5f88\u591a\u3002\n\n\u51c6\u786e\u7387\u548c\u8bef\u5dee\u5982\u56fe\u6240\u793a\uff1a\n\n![images](images/acc_loss_rnn.png)\n\n\n### \u6d4b\u8bd5\n\n\u8fd0\u884c `python run_rnn.py test` \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\n\n```\nTesting...\nTest Loss:   0.21, Test Acc:  94.22%\nPrecision, Recall and F1-Score...\n             precision    recall  f1-score   support\n\n         \u4f53\u80b2       0.99      0.99      0.99      1000\n         \u8d22\u7ecf       0.91      0.99      0.95      1000\n         \u623f\u4ea7       1.00      1.00      1.00      1000\n         \u5bb6\u5c45       0.97      0.73      0.83      1000\n         \u6559\u80b2       0.91      0.92      0.91      1000\n         \u79d1\u6280       0.93      0.96      0.94      1000\n         \u65f6\u5c1a       0.89      0.97      0.93      1000\n         \u65f6\u653f       0.93      0.93      0.93      1000\n         \u6e38\u620f       0.95      0.97      0.96      1000\n         \u5a31\u4e50       0.97      0.96      0.97      1000\n\navg / total       0.94      0.94      0.94     10000\n\nConfusion Matrix...\n[[988   0   0   0   4   0   2   0   5   1]\n [  0 990   1   1   1   1   0   6   0   0]\n [  0   2 996   1   1   0   0   0   0   0]\n [  2  71   1 731  51  20  88  28   3   5]\n [  1   3   0   7 918  23   4  31   9   4]\n [  1   3   0   3   0 964   3   5  21   0]\n [  1   0   1   7   1   3 972   0   6   9]\n [  0  16   0   0  22  26   0 931   2   3]\n [  2   3   0   0   2   2  12   0 972   7]\n [  0   3   1   1   7   3  11   5   9 960]]\nTime usage: 0:00:33\n```\n\n\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e8694.22%\uff0c\u4e14\u5404\u7c7b\u7684precision, recall\u548cf1-score\uff0c\u9664\u4e86\u5bb6\u5c45\u8fd9\u4e00\u7c7b\u522b\uff0c\u90fd\u8d85\u8fc7\u4e860.9\u3002\n\n\u4ece\u6df7\u6dc6\u77e9\u9635\u53ef\u4ee5\u770b\u51fa\u5206\u7c7b\u6548\u679c\u975e\u5e38\u4f18\u79c0\u3002\n\n\u5bf9\u6bd4\u4e24\u4e2a\u6a21\u578b\uff0c\u53ef\u89c1RNN\u9664\u4e86\u5728\u5bb6\u5c45\u5206\u7c7b\u7684\u8868\u73b0\u4e0d\u662f\u5f88\u7406\u60f3\uff0c\u5176\u4ed6\u51e0\u4e2a\u7c7b\u522b\u8f83CNN\u5dee\u522b\u4e0d\u5927\u3002\n\n\u8fd8\u53ef\u4ee5\u901a\u8fc7\u8fdb\u4e00\u6b65\u7684\u8c03\u8282\u53c2\u6570\uff0c\u6765\u8fbe\u5230\u66f4\u597d\u7684\u6548\u679c\u3002\n\n\n## \u9884\u6d4b\n\n\u4e3a\u65b9\u4fbf\u9884\u6d4b\uff0crepo \u4e2d `predict.py` \u63d0\u4f9b\u4e86 CNN \u6a21\u578b\u7684\u9884\u6d4b\u65b9\u6cd5\u3002\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/pypa/sampleproject", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "zhanglei", "package_url": "https://pypi.org/project/zhanglei/", "platform": "", "project_url": "https://pypi.org/project/zhanglei/", "project_urls": {"Homepage": "https://github.com/pypa/sampleproject"}, "release_url": "https://pypi.org/project/zhanglei/0.0.6/", "requires_dist": null, "requires_python": ">=3.6", "summary": "A small example package", "version": "0.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Text Classification with CNN and RNN</h1>\n<h3>\u9700\u8981\u4fee\u6539\u5730\u65b9</h3>\n<h2>1\uff0c\u9700\u8981\u4fee\u6539\u5355\u8bcd\u5b57\u5178\uff1b<br>\n2\uff0c\u6587\u4ef6\u8bfb\u53d6\u4e0d\u6210\u529f\n3\uff0c\u4fee\u6539cnn\u6a21\u578b\u4e2d\u7684\u7c7b\u522b\u6570\u76ee</h2>\n<p>update\u8fd9\u4e48\u591a\u4e1c\u897f\u53bb\u54ea\u91cc\u4e86 CNN\u505a\u53e5\u5b50\u5206\u7c7b\u7684\u8bba\u6587\u53ef\u4ee5\u53c2\u770b: <a href=\"https://arxiv.org/abs/1408.5882\" rel=\"nofollow\">Convolutional Neural Networks for Sentence Classification</a></p>\n<p>\u8fd8\u53ef\u4ee5\u53bb\u8bfbdennybritz\u5927\u725b\u7684\u535a\u5ba2\uff1a<a href=\"http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\" rel=\"nofollow\">Implementing a CNN for Text Classification in TensorFlow</a></p>\n<p>\u4ee5\u53ca\u5b57\u7b26\u7ea7CNN\u7684\u8bba\u6587\uff1a<a href=\"https://arxiv.org/abs/1509.01626\" rel=\"nofollow\">Character-level Convolutional Networks for Text Classification</a></p>\n<p>\u672c\u6587\u662f\u57fa\u4e8eTensorFlow\u5728\u4e2d\u6587\u6570\u636e\u96c6\u4e0a\u7684\u7b80\u5316\u5b9e\u73b0\uff0c\u4f7f\u7528\u4e86\u5b57\u7b26\u7ea7CNN\u548cRNN\u5bf9\u4e2d\u6587\u6587\u672c\u8fdb\u884c\u5206\u7c7b\uff0c\u8fbe\u5230\u4e86\u8f83\u597d\u7684\u6548\u679c\u3002</p>\n<p>\u6587\u4e2d\u6240\u4f7f\u7528\u7684Conv1D\u4e0e\u8bba\u6587\u4e2d\u6709\u4e9b\u4e0d\u540c\uff0c\u8be6\u7ec6\u53c2\u8003\u5b98\u65b9\u6587\u6863\uff1a<a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/conv1d\" rel=\"nofollow\">tf.nn.conv1d</a></p>\n<h2>\u73af\u5883</h2>\n<ul>\n<li>Python 2/3 (\u611f\u8c22<a href=\"https://github.com/howie6879\" rel=\"nofollow\">howie.hu</a>\u8c03\u8bd5Python2\u73af\u5883)</li>\n<li>TensorFlow 1.3\u4ee5\u4e0a</li>\n<li>numpy</li>\n<li>scikit-learn</li>\n<li>scipy</li>\n</ul>\n<h2>\u6570\u636e\u96c6</h2>\n<p>\u4f7f\u7528THUCNews\u7684\u4e00\u4e2a\u5b50\u96c6\u8fdb\u884c\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\uff0c\u6570\u636e\u96c6\u8bf7\u81ea\u884c\u5230<a href=\"http://thuctc.thunlp.org/\" rel=\"nofollow\">THUCTC\uff1a\u4e00\u4e2a\u9ad8\u6548\u7684\u4e2d\u6587\u6587\u672c\u5206\u7c7b\u5de5\u5177\u5305</a>\u4e0b\u8f7d\uff0c\u8bf7\u9075\u5faa\u6570\u636e\u63d0\u4f9b\u65b9\u7684\u5f00\u6e90\u534f\u8bae\u3002</p>\n<p>\u672c\u6b21\u8bad\u7ec3\u4f7f\u7528\u4e86\u5176\u4e2d\u768410\u4e2a\u5206\u7c7b\uff0c\u6bcf\u4e2a\u5206\u7c7b6500\u6761\u6570\u636e\u3002</p>\n<p>\u7c7b\u522b\u5982\u4e0b\uff1a</p>\n<pre><code>\u4f53\u80b2, \u8d22\u7ecf, \u623f\u4ea7, \u5bb6\u5c45, \u6559\u80b2, \u79d1\u6280, \u65f6\u5c1a, \u65f6\u653f, \u6e38\u620f, \u5a31\u4e50\n</code></pre>\n<p>\u8fd9\u4e2a\u5b50\u96c6\u53ef\u4ee5\u5728\u6b64\u4e0b\u8f7d\uff1a\u94fe\u63a5: <a href=\"https://pan.baidu.com/s/1hugrfRu\" rel=\"nofollow\">https://pan.baidu.com/s/1hugrfRu</a> \u5bc6\u7801: qfud</p>\n<p>\u6570\u636e\u96c6\u5212\u5206\u5982\u4e0b\uff1a</p>\n<ul>\n<li>\u8bad\u7ec3\u96c6: 5000*10</li>\n<li>\u9a8c\u8bc1\u96c6: 500*10</li>\n<li>\u6d4b\u8bd5\u96c6: 1000*10</li>\n</ul>\n<p>\u4ece\u539f\u6570\u636e\u96c6\u751f\u6210\u5b50\u96c6\u7684\u8fc7\u7a0b\u8bf7\u53c2\u770b<code>helper</code>\u4e0b\u7684\u4e24\u4e2a\u811a\u672c\u3002\u5176\u4e2d\uff0c<code>copy_data.sh</code>\u7528\u4e8e\u4ece\u6bcf\u4e2a\u5206\u7c7b\u62f7\u8d1d6500\u4e2a\u6587\u4ef6\uff0c<code>cnews_group.py</code>\u7528\u4e8e\u5c06\u591a\u4e2a\u6587\u4ef6\u6574\u5408\u5230\u4e00\u4e2a\u6587\u4ef6\u4e2d\u3002\u6267\u884c\u8be5\u6587\u4ef6\u540e\uff0c\u5f97\u5230\u4e09\u4e2a\u6570\u636e\u6587\u4ef6\uff1a</p>\n<ul>\n<li>cnews.train.txt: \u8bad\u7ec3\u96c6(50000\u6761)</li>\n<li>cnews.val.txt: \u9a8c\u8bc1\u96c6(5000\u6761)</li>\n<li>cnews.test.txt: \u6d4b\u8bd5\u96c6(10000\u6761)</li>\n</ul>\n<h2>\u9884\u5904\u7406</h2>\n<p><code>data/cnews_loader.py</code>\u4e3a\u6570\u636e\u7684\u9884\u5904\u7406\u6587\u4ef6\u3002</p>\n<ul>\n<li><code>read_file()</code>: \u8bfb\u53d6\u6587\u4ef6\u6570\u636e;</li>\n<li><code>build_vocab()</code>: \u6784\u5efa\u8bcd\u6c47\u8868\uff0c\u4f7f\u7528\u5b57\u7b26\u7ea7\u7684\u8868\u793a\uff0c\u8fd9\u4e00\u51fd\u6570\u4f1a\u5c06\u8bcd\u6c47\u8868\u5b58\u50a8\u4e0b\u6765\uff0c\u907f\u514d\u6bcf\u4e00\u6b21\u91cd\u590d\u5904\u7406;</li>\n<li><code>read_vocab()</code>: \u8bfb\u53d6\u4e0a\u4e00\u6b65\u5b58\u50a8\u7684\u8bcd\u6c47\u8868\uff0c\u8f6c\u6362\u4e3a<code>{\u8bcd\uff1aid}</code>\u8868\u793a;</li>\n<li><code>read_category()</code>: \u5c06\u5206\u7c7b\u76ee\u5f55\u56fa\u5b9a\uff0c\u8f6c\u6362\u4e3a<code>{\u7c7b\u522b: id}</code>\u8868\u793a;</li>\n<li><code>to_words()</code>: \u5c06\u4e00\u6761\u7531id\u8868\u793a\u7684\u6570\u636e\u91cd\u65b0\u8f6c\u6362\u4e3a\u6587\u5b57;</li>\n<li><code>process_file()</code>: \u5c06\u6570\u636e\u96c6\u4ece\u6587\u5b57\u8f6c\u6362\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684id\u5e8f\u5217\u8868\u793a;</li>\n<li><code>batch_iter()</code>: \u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u51c6\u5907\u7ecf\u8fc7shuffle\u7684\u6279\u6b21\u7684\u6570\u636e\u3002</li>\n</ul>\n<p>\u7ecf\u8fc7\u6570\u636e\u9884\u5904\u7406\uff0c\u6570\u636e\u7684\u683c\u5f0f\u5982\u4e0b\uff1a</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Data</th>\n<th align=\"left\">Shape</th>\n<th align=\"left\">Data</th>\n<th align=\"left\">Shape</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">x_train</td>\n<td align=\"left\">[50000, 600]</td>\n<td align=\"left\">y_train</td>\n<td align=\"left\">[50000, 10]</td>\n</tr>\n<tr>\n<td align=\"left\">x_val</td>\n<td align=\"left\">[5000, 600]</td>\n<td align=\"left\">y_val</td>\n<td align=\"left\">[5000, 10]</td>\n</tr>\n<tr>\n<td align=\"left\">x_test</td>\n<td align=\"left\">[10000, 600]</td>\n<td align=\"left\">y_test</td>\n<td align=\"left\">[10000, 10]</td>\n</tr></tbody></table>\n<h2>CNN\u5377\u79ef\u795e\u7ecf\u7f51\u7edc</h2>\n<h3>\u914d\u7f6e\u9879</h3>\n<p>CNN\u53ef\u914d\u7f6e\u7684\u53c2\u6570\u5982\u4e0b\u6240\u793a\uff0c\u5728<code>cnn_model.py</code>\u4e2d\u3002</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">TCNNConfig</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\"CNN\u914d\u7f6e\u53c2\u6570\"\"\"</span>\n\n    <span class=\"n\">embedding_dim</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>      <span class=\"c1\"># \u8bcd\u5411\u91cf\u7ef4\u5ea6</span>\n    <span class=\"n\">seq_length</span> <span class=\"o\">=</span> <span class=\"mi\">600</span>        <span class=\"c1\"># \u5e8f\u5217\u957f\u5ea6</span>\n    <span class=\"n\">num_classes</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>        <span class=\"c1\"># \u7c7b\u522b\u6570</span>\n    <span class=\"n\">num_filters</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>        <span class=\"c1\"># \u5377\u79ef\u6838\u6570\u76ee</span>\n    <span class=\"n\">kernel_size</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>         <span class=\"c1\"># \u5377\u79ef\u6838\u5c3a\u5bf8</span>\n    <span class=\"n\">vocab_size</span> <span class=\"o\">=</span> <span class=\"mi\">5000</span>       <span class=\"c1\"># \u8bcd\u6c47\u8868\u8fbe\u5c0f</span>\n\n    <span class=\"n\">hidden_dim</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>        <span class=\"c1\"># \u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143</span>\n\n    <span class=\"n\">dropout_keep_prob</span> <span class=\"o\">=</span> <span class=\"mf\">0.5</span> <span class=\"c1\"># dropout\u4fdd\u7559\u6bd4\u4f8b</span>\n    <span class=\"n\">learning_rate</span> <span class=\"o\">=</span> <span class=\"mf\">1e-3</span>    <span class=\"c1\"># \u5b66\u4e60\u7387</span>\n\n    <span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>         <span class=\"c1\"># \u6bcf\u6279\u8bad\u7ec3\u5927\u5c0f</span>\n    <span class=\"n\">num_epochs</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>         <span class=\"c1\"># \u603b\u8fed\u4ee3\u8f6e\u6b21</span>\n\n    <span class=\"n\">print_per_batch</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>    <span class=\"c1\"># \u6bcf\u591a\u5c11\u8f6e\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c</span>\n    <span class=\"n\">save_per_batch</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>      <span class=\"c1\"># \u6bcf\u591a\u5c11\u8f6e\u5b58\u5165tensorboard</span>\n</pre>\n<h3>CNN\u6a21\u578b</h3>\n<p>\u5177\u4f53\u53c2\u770b<code>cnn_model.py</code>\u7684\u5b9e\u73b0\u3002</p>\n<p>\u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a</p>\n<p><img alt=\"images/cnn_architecture\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/be25bde13f42097fe7fce6090d598967303c954b/696d616765732f636e6e5f6172636869746563747572652e706e67\"></p>\n<h3>\u8bad\u7ec3\u4e0e\u9a8c\u8bc1</h3>\n<p>\u8fd0\u884c <code>python run_cnn.py train</code>\uff0c\u53ef\u4ee5\u5f00\u59cb\u8bad\u7ec3\u3002</p>\n<blockquote>\n<p>\u82e5\u4e4b\u524d\u8fdb\u884c\u8fc7\u8bad\u7ec3\uff0c\u8bf7\u628atensorboard/textcnn\u5220\u9664\uff0c\u907f\u514dTensorBoard\u591a\u6b21\u8bad\u7ec3\u7ed3\u679c\u91cd\u53e0\u3002</p>\n</blockquote>\n<pre><code>Configuring CNN model...\nConfiguring TensorBoard and Saver...\nLoading training and validation data...\nTime usage: 0:00:14\nTraining and evaluating...\nEpoch: 1\nIter:      0, Train Loss:    2.3, Train Acc:  10.94%, Val Loss:    2.3, Val Acc:   8.92%, Time: 0:00:01 *\nIter:    100, Train Loss:   0.88, Train Acc:  73.44%, Val Loss:    1.2, Val Acc:  68.46%, Time: 0:00:04 *\nIter:    200, Train Loss:   0.38, Train Acc:  92.19%, Val Loss:   0.75, Val Acc:  77.32%, Time: 0:00:07 *\nIter:    300, Train Loss:   0.22, Train Acc:  92.19%, Val Loss:   0.46, Val Acc:  87.08%, Time: 0:00:09 *\nIter:    400, Train Loss:   0.24, Train Acc:  90.62%, Val Loss:    0.4, Val Acc:  88.62%, Time: 0:00:12 *\nIter:    500, Train Loss:   0.16, Train Acc:  96.88%, Val Loss:   0.36, Val Acc:  90.38%, Time: 0:00:15 *\nIter:    600, Train Loss:  0.084, Train Acc:  96.88%, Val Loss:   0.35, Val Acc:  91.36%, Time: 0:00:17 *\nIter:    700, Train Loss:   0.21, Train Acc:  93.75%, Val Loss:   0.26, Val Acc:  92.58%, Time: 0:00:20 *\nEpoch: 2\nIter:    800, Train Loss:   0.07, Train Acc:  98.44%, Val Loss:   0.24, Val Acc:  94.12%, Time: 0:00:23 *\nIter:    900, Train Loss:  0.092, Train Acc:  96.88%, Val Loss:   0.27, Val Acc:  92.86%, Time: 0:00:25\nIter:   1000, Train Loss:   0.17, Train Acc:  95.31%, Val Loss:   0.28, Val Acc:  92.82%, Time: 0:00:28\nIter:   1100, Train Loss:    0.2, Train Acc:  93.75%, Val Loss:   0.23, Val Acc:  93.26%, Time: 0:00:31\nIter:   1200, Train Loss:  0.081, Train Acc:  98.44%, Val Loss:   0.25, Val Acc:  92.96%, Time: 0:00:33\nIter:   1300, Train Loss:  0.052, Train Acc: 100.00%, Val Loss:   0.24, Val Acc:  93.58%, Time: 0:00:36\nIter:   1400, Train Loss:    0.1, Train Acc:  95.31%, Val Loss:   0.22, Val Acc:  94.12%, Time: 0:00:39\nIter:   1500, Train Loss:   0.12, Train Acc:  98.44%, Val Loss:   0.23, Val Acc:  93.58%, Time: 0:00:41\nEpoch: 3\nIter:   1600, Train Loss:    0.1, Train Acc:  96.88%, Val Loss:   0.26, Val Acc:  92.34%, Time: 0:00:44\nIter:   1700, Train Loss:  0.018, Train Acc: 100.00%, Val Loss:   0.22, Val Acc:  93.46%, Time: 0:00:47\nIter:   1800, Train Loss:  0.036, Train Acc: 100.00%, Val Loss:   0.28, Val Acc:  92.72%, Time: 0:00:50\nNo optimization for a long time, auto-stopping...\n</code></pre>\n<p>\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6700\u4f73\u6548\u679c\u4e3a94.12%\uff0c\u4e14\u53ea\u7ecf\u8fc7\u4e863\u8f6e\u8fed\u4ee3\u5c31\u5df2\u7ecf\u505c\u6b62\u3002</p>\n<p>\u51c6\u786e\u7387\u548c\u8bef\u5dee\u5982\u56fe\u6240\u793a\uff1a</p>\n<p><img alt=\"images\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e0c599b727d916f3dc86106054690df9df794d75/696d616765732f6163635f6c6f73732e706e67\"></p>\n<h3>\u6d4b\u8bd5</h3>\n<p>\u8fd0\u884c <code>python run_cnn.py test</code> \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002</p>\n<pre><code>Configuring CNN model...\nLoading test data...\nTesting...\nTest Loss:   0.14, Test Acc:  96.04%\nPrecision, Recall and F1-Score...\n             precision    recall  f1-score   support\n\n         \u4f53\u80b2       0.99      0.99      0.99      1000\n         \u8d22\u7ecf       0.96      0.99      0.97      1000\n         \u623f\u4ea7       1.00      1.00      1.00      1000\n         \u5bb6\u5c45       0.95      0.91      0.93      1000\n         \u6559\u80b2       0.95      0.89      0.92      1000\n         \u79d1\u6280       0.94      0.97      0.95      1000\n         \u65f6\u5c1a       0.95      0.97      0.96      1000\n         \u65f6\u653f       0.94      0.94      0.94      1000\n         \u6e38\u620f       0.97      0.96      0.97      1000\n         \u5a31\u4e50       0.95      0.98      0.97      1000\n\navg / total       0.96      0.96      0.96     10000\n\nConfusion Matrix...\n[[991   0   0   0   2   1   0   4   1   1]\n [  0 992   0   0   2   1   0   5   0   0]\n [  0   1 996   0   1   1   0   0   0   1]\n [  0  14   0 912   7  15   9  29   3  11]\n [  2   9   0  12 892  22  18  21  10  14]\n [  0   0   0  10   1 968   4   3  12   2]\n [  1   0   0   9   4   4 971   0   2   9]\n [  1  16   0   4  18  12   1 941   1   6]\n [  2   4   1   5   4   5  10   1 962   6]\n [  1   0   1   6   4   3   5   0   1 979]]\nTime usage: 0:00:05\n</code></pre>\n<p>\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e8696.04%\uff0c\u4e14\u5404\u7c7b\u7684precision, recall\u548cf1-score\u90fd\u8d85\u8fc7\u4e860.9\u3002</p>\n<p>\u4ece\u6df7\u6dc6\u77e9\u9635\u4e5f\u53ef\u4ee5\u770b\u51fa\u5206\u7c7b\u6548\u679c\u975e\u5e38\u4f18\u79c0\u3002</p>\n<h2>RNN\u5faa\u73af\u795e\u7ecf\u7f51\u7edc</h2>\n<h3>\u914d\u7f6e\u9879</h3>\n<p>RNN\u53ef\u914d\u7f6e\u7684\u53c2\u6570\u5982\u4e0b\u6240\u793a\uff0c\u5728<code>rnn_model.py</code>\u4e2d\u3002</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">TRNNConfig</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\"RNN\u914d\u7f6e\u53c2\u6570\"\"\"</span>\n\n    <span class=\"c1\"># \u6a21\u578b\u53c2\u6570</span>\n    <span class=\"n\">embedding_dim</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>      <span class=\"c1\"># \u8bcd\u5411\u91cf\u7ef4\u5ea6</span>\n    <span class=\"n\">seq_length</span> <span class=\"o\">=</span> <span class=\"mi\">600</span>        <span class=\"c1\"># \u5e8f\u5217\u957f\u5ea6</span>\n    <span class=\"n\">num_classes</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>        <span class=\"c1\"># \u7c7b\u522b\u6570</span>\n    <span class=\"n\">vocab_size</span> <span class=\"o\">=</span> <span class=\"mi\">5000</span>       <span class=\"c1\"># \u8bcd\u6c47\u8868\u8fbe\u5c0f</span>\n\n    <span class=\"n\">num_layers</span><span class=\"o\">=</span> <span class=\"mi\">2</span>           <span class=\"c1\"># \u9690\u85cf\u5c42\u5c42\u6570</span>\n    <span class=\"n\">hidden_dim</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>        <span class=\"c1\"># \u9690\u85cf\u5c42\u795e\u7ecf\u5143</span>\n    <span class=\"n\">rnn</span> <span class=\"o\">=</span> <span class=\"s1\">'gru'</span>             <span class=\"c1\"># lstm \u6216 gru</span>\n\n    <span class=\"n\">dropout_keep_prob</span> <span class=\"o\">=</span> <span class=\"mf\">0.8</span> <span class=\"c1\"># dropout\u4fdd\u7559\u6bd4\u4f8b</span>\n    <span class=\"n\">learning_rate</span> <span class=\"o\">=</span> <span class=\"mf\">1e-3</span>    <span class=\"c1\"># \u5b66\u4e60\u7387</span>\n\n    <span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">128</span>         <span class=\"c1\"># \u6bcf\u6279\u8bad\u7ec3\u5927\u5c0f</span>\n    <span class=\"n\">num_epochs</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>          <span class=\"c1\"># \u603b\u8fed\u4ee3\u8f6e\u6b21</span>\n\n    <span class=\"n\">print_per_batch</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>    <span class=\"c1\"># \u6bcf\u591a\u5c11\u8f6e\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c</span>\n    <span class=\"n\">save_per_batch</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>      <span class=\"c1\"># \u6bcf\u591a\u5c11\u8f6e\u5b58\u5165tensorboard</span>\n</pre>\n<h3>RNN\u6a21\u578b</h3>\n<p>\u5177\u4f53\u53c2\u770b<code>rnn_model.py</code>\u7684\u5b9e\u73b0\u3002</p>\n<p>\u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a</p>\n<p><img alt=\"images/rnn_architecture\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e4cd09e5f9c926c7ca7505e3112ffccb7414f6bb/696d616765732f726e6e5f6172636869746563747572652e706e67\"></p>\n<h3>\u8bad\u7ec3\u4e0e\u9a8c\u8bc1</h3>\n<blockquote>\n<p>\u8fd9\u90e8\u5206\u7684\u4ee3\u7801\u4e0e run_cnn.py\u6781\u4e3a\u76f8\u4f3c\uff0c\u53ea\u9700\u8981\u5c06\u6a21\u578b\u548c\u90e8\u5206\u76ee\u5f55\u7a0d\u5fae\u4fee\u6539\u3002</p>\n</blockquote>\n<p>\u8fd0\u884c <code>python run_rnn.py train</code>\uff0c\u53ef\u4ee5\u5f00\u59cb\u8bad\u7ec3\u3002</p>\n<blockquote>\n<p>\u82e5\u4e4b\u524d\u8fdb\u884c\u8fc7\u8bad\u7ec3\uff0c\u8bf7\u628atensorboard/textrnn\u5220\u9664\uff0c\u907f\u514dTensorBoard\u591a\u6b21\u8bad\u7ec3\u7ed3\u679c\u91cd\u53e0\u3002</p>\n</blockquote>\n<pre><code>Configuring RNN model...\nConfiguring TensorBoard and Saver...\nLoading training and validation data...\nTime usage: 0:00:14\nTraining and evaluating...\nEpoch: 1\nIter:      0, Train Loss:    2.3, Train Acc:   8.59%, Val Loss:    2.3, Val Acc:  11.96%, Time: 0:00:08 *\nIter:    100, Train Loss:   0.95, Train Acc:  64.06%, Val Loss:    1.3, Val Acc:  53.06%, Time: 0:01:15 *\nIter:    200, Train Loss:   0.61, Train Acc:  79.69%, Val Loss:   0.94, Val Acc:  69.88%, Time: 0:02:22 *\nIter:    300, Train Loss:   0.49, Train Acc:  85.16%, Val Loss:   0.63, Val Acc:  81.44%, Time: 0:03:29 *\nEpoch: 2\nIter:    400, Train Loss:   0.23, Train Acc:  92.97%, Val Loss:    0.6, Val Acc:  82.86%, Time: 0:04:36 *\nIter:    500, Train Loss:   0.27, Train Acc:  92.97%, Val Loss:   0.47, Val Acc:  86.72%, Time: 0:05:43 *\nIter:    600, Train Loss:   0.13, Train Acc:  98.44%, Val Loss:   0.43, Val Acc:  87.46%, Time: 0:06:50 *\nIter:    700, Train Loss:   0.24, Train Acc:  91.41%, Val Loss:   0.46, Val Acc:  87.12%, Time: 0:07:57\nEpoch: 3\nIter:    800, Train Loss:   0.11, Train Acc:  96.09%, Val Loss:   0.49, Val Acc:  87.02%, Time: 0:09:03\nIter:    900, Train Loss:   0.15, Train Acc:  96.09%, Val Loss:   0.55, Val Acc:  85.86%, Time: 0:10:10\nIter:   1000, Train Loss:   0.17, Train Acc:  96.09%, Val Loss:   0.43, Val Acc:  89.44%, Time: 0:11:18 *\nIter:   1100, Train Loss:   0.25, Train Acc:  93.75%, Val Loss:   0.42, Val Acc:  88.98%, Time: 0:12:25\nEpoch: 4\nIter:   1200, Train Loss:   0.14, Train Acc:  96.09%, Val Loss:   0.39, Val Acc:  89.82%, Time: 0:13:32 *\nIter:   1300, Train Loss:    0.2, Train Acc:  96.09%, Val Loss:   0.43, Val Acc:  88.68%, Time: 0:14:38\nIter:   1400, Train Loss:  0.012, Train Acc: 100.00%, Val Loss:   0.37, Val Acc:  90.58%, Time: 0:15:45 *\nIter:   1500, Train Loss:   0.15, Train Acc:  96.88%, Val Loss:   0.39, Val Acc:  90.58%, Time: 0:16:52\nEpoch: 5\nIter:   1600, Train Loss:  0.075, Train Acc:  97.66%, Val Loss:   0.41, Val Acc:  89.90%, Time: 0:17:59\nIter:   1700, Train Loss:  0.042, Train Acc:  98.44%, Val Loss:   0.41, Val Acc:  90.08%, Time: 0:19:06\nIter:   1800, Train Loss:   0.08, Train Acc:  97.66%, Val Loss:   0.38, Val Acc:  91.36%, Time: 0:20:13 *\nIter:   1900, Train Loss:  0.089, Train Acc:  98.44%, Val Loss:   0.39, Val Acc:  90.18%, Time: 0:21:20\nEpoch: 6\nIter:   2000, Train Loss:  0.092, Train Acc:  96.88%, Val Loss:   0.36, Val Acc:  91.42%, Time: 0:22:27 *\nIter:   2100, Train Loss:  0.062, Train Acc:  98.44%, Val Loss:   0.39, Val Acc:  90.56%, Time: 0:23:34\nIter:   2200, Train Loss:  0.053, Train Acc:  98.44%, Val Loss:   0.39, Val Acc:  90.02%, Time: 0:24:41\nIter:   2300, Train Loss:   0.12, Train Acc:  96.09%, Val Loss:   0.37, Val Acc:  90.84%, Time: 0:25:48\nEpoch: 7\nIter:   2400, Train Loss:  0.014, Train Acc: 100.00%, Val Loss:   0.41, Val Acc:  90.38%, Time: 0:26:55\nIter:   2500, Train Loss:   0.14, Train Acc:  96.88%, Val Loss:   0.37, Val Acc:  91.22%, Time: 0:28:01\nIter:   2600, Train Loss:   0.11, Train Acc:  96.88%, Val Loss:   0.43, Val Acc:  89.76%, Time: 0:29:08\nIter:   2700, Train Loss:  0.089, Train Acc:  97.66%, Val Loss:   0.37, Val Acc:  91.18%, Time: 0:30:15\nEpoch: 8\nIter:   2800, Train Loss: 0.0081, Train Acc: 100.00%, Val Loss:   0.44, Val Acc:  90.66%, Time: 0:31:22\nIter:   2900, Train Loss:  0.017, Train Acc: 100.00%, Val Loss:   0.44, Val Acc:  89.62%, Time: 0:32:29\nIter:   3000, Train Loss:  0.061, Train Acc:  96.88%, Val Loss:   0.43, Val Acc:  90.04%, Time: 0:33:36\nNo optimization for a long time, auto-stopping...\n</code></pre>\n<p>\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6700\u4f73\u6548\u679c\u4e3a91.42%\uff0c\u7ecf\u8fc7\u4e868\u8f6e\u8fed\u4ee3\u505c\u6b62\uff0c\u901f\u5ea6\u76f8\u6bd4CNN\u6162\u5f88\u591a\u3002</p>\n<p>\u51c6\u786e\u7387\u548c\u8bef\u5dee\u5982\u56fe\u6240\u793a\uff1a</p>\n<p><img alt=\"images\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0b6d2e7f006fa520b2e60c9d69fb3f771c1c159d/696d616765732f6163635f6c6f73735f726e6e2e706e67\"></p>\n<h3>\u6d4b\u8bd5</h3>\n<p>\u8fd0\u884c <code>python run_rnn.py test</code> \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002</p>\n<pre><code>Testing...\nTest Loss:   0.21, Test Acc:  94.22%\nPrecision, Recall and F1-Score...\n             precision    recall  f1-score   support\n\n         \u4f53\u80b2       0.99      0.99      0.99      1000\n         \u8d22\u7ecf       0.91      0.99      0.95      1000\n         \u623f\u4ea7       1.00      1.00      1.00      1000\n         \u5bb6\u5c45       0.97      0.73      0.83      1000\n         \u6559\u80b2       0.91      0.92      0.91      1000\n         \u79d1\u6280       0.93      0.96      0.94      1000\n         \u65f6\u5c1a       0.89      0.97      0.93      1000\n         \u65f6\u653f       0.93      0.93      0.93      1000\n         \u6e38\u620f       0.95      0.97      0.96      1000\n         \u5a31\u4e50       0.97      0.96      0.97      1000\n\navg / total       0.94      0.94      0.94     10000\n\nConfusion Matrix...\n[[988   0   0   0   4   0   2   0   5   1]\n [  0 990   1   1   1   1   0   6   0   0]\n [  0   2 996   1   1   0   0   0   0   0]\n [  2  71   1 731  51  20  88  28   3   5]\n [  1   3   0   7 918  23   4  31   9   4]\n [  1   3   0   3   0 964   3   5  21   0]\n [  1   0   1   7   1   3 972   0   6   9]\n [  0  16   0   0  22  26   0 931   2   3]\n [  2   3   0   0   2   2  12   0 972   7]\n [  0   3   1   1   7   3  11   5   9 960]]\nTime usage: 0:00:33\n</code></pre>\n<p>\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230\u4e8694.22%\uff0c\u4e14\u5404\u7c7b\u7684precision, recall\u548cf1-score\uff0c\u9664\u4e86\u5bb6\u5c45\u8fd9\u4e00\u7c7b\u522b\uff0c\u90fd\u8d85\u8fc7\u4e860.9\u3002</p>\n<p>\u4ece\u6df7\u6dc6\u77e9\u9635\u53ef\u4ee5\u770b\u51fa\u5206\u7c7b\u6548\u679c\u975e\u5e38\u4f18\u79c0\u3002</p>\n<p>\u5bf9\u6bd4\u4e24\u4e2a\u6a21\u578b\uff0c\u53ef\u89c1RNN\u9664\u4e86\u5728\u5bb6\u5c45\u5206\u7c7b\u7684\u8868\u73b0\u4e0d\u662f\u5f88\u7406\u60f3\uff0c\u5176\u4ed6\u51e0\u4e2a\u7c7b\u522b\u8f83CNN\u5dee\u522b\u4e0d\u5927\u3002</p>\n<p>\u8fd8\u53ef\u4ee5\u901a\u8fc7\u8fdb\u4e00\u6b65\u7684\u8c03\u8282\u53c2\u6570\uff0c\u6765\u8fbe\u5230\u66f4\u597d\u7684\u6548\u679c\u3002</p>\n<h2>\u9884\u6d4b</h2>\n<p>\u4e3a\u65b9\u4fbf\u9884\u6d4b\uff0crepo \u4e2d <code>predict.py</code> \u63d0\u4f9b\u4e86 CNN \u6a21\u578b\u7684\u9884\u6d4b\u65b9\u6cd5\u3002</p>\n\n          </div>"}, "last_serial": 5831911, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "78e460658aae23958d7cdedeed2e4955", "sha256": "007f21f7b55f4ff4651d531e9975b5c736601a7739fca427645404cede04c7a4"}, "downloads": -1, "filename": "zhanglei-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "78e460658aae23958d7cdedeed2e4955", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10170, "upload_time": "2019-09-15T12:36:26", "upload_time_iso_8601": "2019-09-15T12:36:26.810371Z", "url": "https://files.pythonhosted.org/packages/a7/32/46caf85940dc45066f48754d9eaba2180506a43b8e7176064b2fa9ade1cc/zhanglei-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a168d7e955a5ebcc201950ea118c351", "sha256": "143a77d777670d3bc3037cabf2fc90d4d9ad14020abb90133b4f208874f254fa"}, "downloads": -1, "filename": "zhanglei-0.0.2.tar.gz", "has_sig": false, "md5_digest": "0a168d7e955a5ebcc201950ea118c351", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10547, "upload_time": "2019-09-15T12:36:29", "upload_time_iso_8601": "2019-09-15T12:36:29.638781Z", "url": "https://files.pythonhosted.org/packages/f4/d8/700571433a3ddfaf6345780f526dc73a62fe4e4f7155283ac6e5efc9e64c/zhanglei-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "422f0be1b3791bb44c6bdde92cbc6f9d", "sha256": "1336eaa0bbd131dd82d4fc37115305e33f34bb73a9894d3b1fc95030c47e483c"}, "downloads": -1, "filename": "zhanglei-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "422f0be1b3791bb44c6bdde92cbc6f9d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 11476, "upload_time": "2019-09-15T12:50:26", "upload_time_iso_8601": "2019-09-15T12:50:26.770997Z", "url": "https://files.pythonhosted.org/packages/0d/45/d608d41acff47f42c727032596f7c1508bdddc4d492b6453db3a4d96907b/zhanglei-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f8fcb3133bf336698a48271d3b7af8bb", "sha256": "92fecce212d375de5bb123ae6e22ca25a643d6c6b8492c4344a15622ba0c4bed"}, "downloads": -1, "filename": "zhanglei-0.0.3.tar.gz", "has_sig": false, "md5_digest": "f8fcb3133bf336698a48271d3b7af8bb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10549, "upload_time": "2019-09-15T12:50:30", "upload_time_iso_8601": "2019-09-15T12:50:30.479485Z", "url": "https://files.pythonhosted.org/packages/5d/64/cb19c8e3f4cf186e6f62a64b5c05a97bf86477a8ade098dff99bb1178423/zhanglei-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "0d22b07bfe6e55f517bbaed50092422d", "sha256": "bbfa30e330d13972c1a7f063ef37ce13d61be42de98c4886db211a5e0e0eef62"}, "downloads": -1, "filename": "zhanglei-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "0d22b07bfe6e55f517bbaed50092422d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22199, "upload_time": "2019-09-15T12:56:39", "upload_time_iso_8601": "2019-09-15T12:56:39.678091Z", "url": "https://files.pythonhosted.org/packages/cc/82/82da349e53d719479b1a7b20e3e64d0de08b98fc1b46c9b7fa7247d18ad4/zhanglei-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "03719ac1a7870eb9de0456e6fdeac800", "sha256": "a94201a36d15ba6253200da51278d54580cada5f644975240e98596e23448e22"}, "downloads": -1, "filename": "zhanglei-0.0.4.tar.gz", "has_sig": false, "md5_digest": "03719ac1a7870eb9de0456e6fdeac800", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18426, "upload_time": "2019-09-15T12:56:45", "upload_time_iso_8601": "2019-09-15T12:56:45.382389Z", "url": "https://files.pythonhosted.org/packages/e9/db/f96ab5db5aa8257db5e8848e7defb170f3e6beeb39041e37ddddafe5d0c6/zhanglei-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "9cb2b9a1cedd29f13b8a290b01b55ee5", "sha256": "99bf008ec56b4edfd5b126179730a19c6fb58f8120ddf1a53944a0025a8dc237"}, "downloads": -1, "filename": "zhanglei-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "9cb2b9a1cedd29f13b8a290b01b55ee5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22250, "upload_time": "2019-09-15T13:16:24", "upload_time_iso_8601": "2019-09-15T13:16:24.536257Z", "url": "https://files.pythonhosted.org/packages/48/83/3a758e5e5c3e7f799eb6db93aa2af8ff589216fb230df024e570ff55dfdf/zhanglei-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1763c2523b94ae6373cc08da5aac1f4b", "sha256": "6ae07dcabbacb0ff3a62562dd18ceaa1ef0473fe4535cc71e2f4c36298277501"}, "downloads": -1, "filename": "zhanglei-0.0.5.tar.gz", "has_sig": false, "md5_digest": "1763c2523b94ae6373cc08da5aac1f4b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18478, "upload_time": "2019-09-15T13:16:30", "upload_time_iso_8601": "2019-09-15T13:16:30.143333Z", "url": "https://files.pythonhosted.org/packages/7e/55/d4bceea56a80d9233ba510eef2537268ac05ea83feeb08520a83e68b2c9b/zhanglei-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "fdd96d6822e4d1ec83830065662b5b7e", "sha256": "674cdbe550b8d17da8fcac0a623ee31e1560f131539576a003f8b04ce556d34a"}, "downloads": -1, "filename": "zhanglei-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "fdd96d6822e4d1ec83830065662b5b7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22244, "upload_time": "2019-09-15T13:23:59", "upload_time_iso_8601": "2019-09-15T13:23:59.446105Z", "url": "https://files.pythonhosted.org/packages/6c/1f/db43535908abba64ba41eea1f8444ec17a8d02c8f53ba9d7df8c0aeec32e/zhanglei-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "49605a5242be7d1f60f15b42bff1fcd8", "sha256": "e84e15f613ee27bc8fa858bdc56a21554034e6f889d6a6e21e086eceec03ddbb"}, "downloads": -1, "filename": "zhanglei-0.0.6.tar.gz", "has_sig": false, "md5_digest": "49605a5242be7d1f60f15b42bff1fcd8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18471, "upload_time": "2019-09-15T13:24:01", "upload_time_iso_8601": "2019-09-15T13:24:01.505592Z", "url": "https://files.pythonhosted.org/packages/0e/2e/eb00ac5f06a19d2a2f85c2c40ebcf0c4fe6c6366bb38da8464a03bbc1d2a/zhanglei-0.0.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fdd96d6822e4d1ec83830065662b5b7e", "sha256": "674cdbe550b8d17da8fcac0a623ee31e1560f131539576a003f8b04ce556d34a"}, "downloads": -1, "filename": "zhanglei-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "fdd96d6822e4d1ec83830065662b5b7e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22244, "upload_time": "2019-09-15T13:23:59", "upload_time_iso_8601": "2019-09-15T13:23:59.446105Z", "url": "https://files.pythonhosted.org/packages/6c/1f/db43535908abba64ba41eea1f8444ec17a8d02c8f53ba9d7df8c0aeec32e/zhanglei-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "49605a5242be7d1f60f15b42bff1fcd8", "sha256": "e84e15f613ee27bc8fa858bdc56a21554034e6f889d6a6e21e086eceec03ddbb"}, "downloads": -1, "filename": "zhanglei-0.0.6.tar.gz", "has_sig": false, "md5_digest": "49605a5242be7d1f60f15b42bff1fcd8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18471, "upload_time": "2019-09-15T13:24:01", "upload_time_iso_8601": "2019-09-15T13:24:01.505592Z", "url": "https://files.pythonhosted.org/packages/0e/2e/eb00ac5f06a19d2a2f85c2c40ebcf0c4fe6c6366bb38da8464a03bbc1d2a/zhanglei-0.0.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:17:01 2020"}