{"info": {"author": "Andre Anjos", "author_email": "andre.anjos@idiap.ch", "bugtrack_url": null, "classifiers": [], "description": "=============================================================\n Parts-Based GMM Verification for the Replay Attack Database\n=============================================================\n\nThis `Bob`_ satellite package allows you to run a baseline Parts-Based GMM face\nverification system on the Replay Attack Database. It explains how to setup\nthis package, generate the Universal Background Model (UBM), client models and\nfinally, scores.\n\nIf you use this package and/or its results, please cite the following\npublications:\n\n1. The Replay-Attack Database and baseline GMM results for it::\n\n    @inproceedings{Chingovska_BIOSIG_2012,\n      author = {I. Chingovska AND A. Anjos AND S. Marcel},\n      keywords = {Attack, Counter-Measures, Counter-Spoofing, Face Recognition, Liveness Detection, Replay, Spoofing},\n      month = sep,\n      title = {On the Effectiveness of Local Binary Patterns in Face Anti-spoofing},\n      booktitle = {IEEE BioSIG 2012},\n      year = {2012},\n    }\n\n2. Bob as the core framework used for these results::\n\n    @inproceedings{Anjos_ACMMM_2012,\n        author = {A. Anjos AND L. El Shafey AND R. Wallace AND M. G\\\"unther AND C. McCool AND S. Marcel},\n        title = {Bob: a free signal processing and machine learning toolbox for researchers},\n        year = {2012},\n        month = oct,\n        booktitle = {20th ACM Conference on Multimedia Systems (ACMMM), Nara, Japan},\n        publisher = {ACM Press},\n    }\n\nIf you wish to report problems or improvements concerning this code, please\ncontact the authors of the above mentioned papers.\n\nInstallation\n------------\n\n.. note:: \n\n  If you are reading this page through our GitHub portal and not through PyPI,\n  note **the development tip of the package may not be stable** or become\n  unstable in a matter of moments.\n\n  Go to `http://pypi.python.org/pypi/antispoofing.verification.gmm\n  <http://pypi.python.org/pypi/antispoofing.verification.gmm>`_ to download the\n  latest stable version of this package.\n\nThere are 2 options you can follow to get this package installed and\noperational on your computer: you can use automatic installers like `pip\n<http://pypi.python.org/pypi/pip/>`_ (or `easy_install\n<http://pypi.python.org/pypi/setuptools>`_) or manually download, unpack and\nuse `zc.buildout <http://pypi.python.org/pypi/zc.buildout>`_ to create a\nvirtual work environment just for this package.\n\nUsing an automatic installer\n============================\n\nUsing ``pip`` is the easiest (shell commands are marked with a ``$`` signal)::\n\n  $ pip install antispoofing.verification.gmm\n\nYou can also do the same with ``easy_install``::\n\n  $ easy_install antispoofing.verification.gmm\n\nThis will download and install this package plus any other required\ndependencies. It will also verify if the version of Bob you have installed\nis compatible.\n\nThis scheme works well with virtual environments by `virtualenv\n<http://pypi.python.org/pypi/virtualenv>`_ or if you have root access to your\nmachine. Otherwise, we recommend you use the next option.\n\nUsing ``zc.buildout``\n=====================\n\nDownload the latest version of this package from `PyPI\n<http://pypi.python.org/pypi/antispoofing.verification.gmm>`_ and unpack it in\nyour working area. The installation of the toolkit itself uses `buildout\n<http://www.buildout.org/>`_. You don't need to understand its inner workings\nto use this package. Here is a recipe to get you started::\n  \n  $ python bootstrap.py $ ./bin/buildout\n\nThese 2 commands should download and install all non-installed dependencies and\nget you a fully operational test and development environment.\n\n.. note::\n\n  The python shell used in the first line of the previous command set\n  determines the python interpreter that will be used for all scripts developed\n  inside this package. Because this package makes use of `Bob`_, <you must make\n  sure that the ``bootstrap.py`` script is called with the **same** interpreter\n  used to build Bob, or unexpected problems might occur.\n\n  If Bob is installed by the administrator of your system, it is safe to\n  consider it uses the default python interpreter. In this case, the above 3\n  command lines should work as expected. If you have Bob installed somewhere\n  else on a private directory, edit the file ``buildout.cfg`` **before**\n  running ``./bin/buildout``. Find the section named ``external`` and edit the\n  line ``egg-directories`` to point to the ``lib`` directory of the Bob\n  installation you want to use. For example::\n\n    [external]\n    recipe = xbob.buildout:external\n    egg-directories=/Users/crazyfox/work/bob/build/lib\n\nUser Guide\n----------\n\nConfiguration Tweaking (optional)\n=================================\n\nThe current scripts have been tunned to reproduce the results presented on some\nof our publications (as indicated above), as well as on FP7 Project `TABULA\nRASA <http://www.tabularasa-euproject.org/>`_ reports.  They still accept an\nalternate (python) configuration file that can be passed as input. If nothing\nis passed, a default configuration file located at\n``antispoofing/verification/gmm/config/gmm_replay.py`` is used. Copy that file\nto the current directory and edit it to modify the overall configuration for\nthe mixture-model system or for the (DCT-based) feature extraction. Use the\noption ``--config=myconfig.py`` to set your private configuration if you decide\nto do so. Remember to set the option thoroughly through out all script calls or\nunexpected results may happen.\n\nRunning the Experiments\n=======================\n\nFollow the sequence described here to reproduce paper results.\n\nRun ``feature_extract.py`` to extract the DCT block features. This step is\nthe only that requires the original database videos as input. It will generate,\n**per video frame**, all input features required by the scripts that follow\nthis one::\n\n  $ ./bin/feature_extract.py /root/of/replay/attack/database results/dct\n\nThis will run through the 1300 videos in the database and extract the features\nat the frame intervals defined at the configuration. In a relatively fast\nmachine, it will take about 10-20 seconds per input video, with a frame-skip\nparameter set to 10 (the default). If you want to be thorough, you will need to\nparallelize this script so that the overall database can be processed in a\nreasonable amount of time.\n\nYou can parallelize the execution of the above script (and of some of the\nscripts below as well) if you are a Idiap. Just do the following instead::\n\n  $ ./bin/jman submit --array=1300 ./bin/feature_extract.py /root/of/replay/attack/database results/dct --grid\n\nNotice the ``--array=1300`` and ``--grid`` option by the end of the script. The\nabove instruction tells SGE to run 1300 versions of my script with the same\ninput parameters. The only difference is ``SGE_TASK_ID`` environment variable\nthat is changed at every interation (thanks to the ``--array=1300`` option).\nThe ``--grid`` option the execution of the script analyze first the value of\n``SGE_TASK_ID`` and re-set the internal processing so that particular instance\nof ``feature_extract.py`` only processes one of the 1300 videos that requires\nprocessing. You can check the status of the jobs in the grid with ``jman\nrefresh`` (refer to the `GridTk manual <http://packages.python.org/gridtk>` for\ndetails).\n\n.. note::\n\n  If you are not, you can still take a look at our `GridTk package\n  <http://pypi.python.org/pypi/gridtk>`_ for a logging grid job manager for SGE.\n\nUBM Training\n============\n\nRun ``train_ubm.py`` to create the GMM Universal Background Model from selected\nfeatures (in the enrollment/training subset)::\n  \n  $ ./bin/train_ubm.py results/dct results/ubm.hdf5\n\n.. note::\n\n  Note: if you use ~1k files, it will take a few hours to complete and there is\n  currently no way to parallelize this.  This step requires all features for\n  the training set/enrollment are calculated. The job can take many gigabytes\n  of physical memory from your machine, so we advise you to run it in a machine\n  with, at least, 8 gigabytes of free memory.\n\nUnfortunately, you cannot easily parallelize this job. Nevertheless, you can\nsubmit it to the grid with the following command and avoid it to run on your\nmachine (nice if you have a busy day of work)::\n\n  $ ./bin/jman submit --queue=q_1week --memory=8G ./bin/train_ubm.py results/dct results/ubm.hdf5\n\nEven if you choose a long enough queue, it is still prudent to set the memory\nrequirements for the node you will be assigned to, to guarantee a minimum\namount of memory.\n\nUBM Statistics Generation\n=========================\n\nRun ``generate_statistics.py`` to create the background statistics for all\ndatafiles so we can calculate scores later. This step requires that the UBM is\ntrained and all features are available::\n\n  $ ./bin/generate_statistics.py results/dct results/ubm.hdf5 results/stats\n\nThis will take a lot of time to go through all the videos in the replay\ndatabase. You can optionally submit the command to the grid, if you are at\nIdiap, with the following::\n\n  $ ./bin/jman submit --array=840 ./bin/generate_statistics.py results/dct results/ubm.hdf5 results/stats --grid\n\nThis command will spread the GMM UBM statistics calculation over 840 processes\nthat will run in about 5-10 minutes each. So, the whole job will take a few\nhours to complete - taking into consideration current settings for SGE at\nIdiap.\n\nClient Model training\n=====================\n\n.. note::\n\n  You can do this in parallel with the step above as it only depends on the\n  input features pre-calculated at step 3\n\nGenerate the models for all clients::\n\n  $ ./bin/enrol.py results/dct results/ubm.hdf5 results/models\n\nIf you think the above job is too slow, you can throw it at the grid as well::\n\n  $ ./bin/jman submit --array=35 ./bin/enrol.py results/dct results/ubm.hdf5 results/models --grid\n\nScoring\n=======\n\nIn this step you will score the videos (every N frames up to a certain frame\nnumber) against the generated client models. We do this exhaustively for both\nthe test and development data. Command line execution goes like this::\n\n  $ ./bin/score.py results/stats results/ubm.hdf5 results/models results/scores\n\nLinear scoring is fast, but you can also submit a client-based break-down of\nthis problem like this::\n\n  $ ./bin/jman submit --array=35 ./bin/score.py results/stats results/ubm.hdf5 results/models results/scores --grid\n\nFull Score Files\n================\n\nAfter scores are calculated, you need to put them together to setup development\nand test text files in a 4 or 5 column format. To do that, use the application\n``build_score_files.py``. The next command will generate the baseline\nverification results by thouroughly matching every client video against every\nmodel available in the individual sets, averaging over (the first) 220 frames::\n\n  $ ./bin/build_score_files.py results/scores results/perf --thorough --frames=220\n\nYou can specify to use the attack protocols like this (avoid using the\n`--thourough` option)::\n\n  $ ./bin/build_score_files.py results/scores results/perf --protocol=grandtest --frames=220\n\n.. warning::\n\n  It is possible you see warnings being emitted by the above programs in\n  certain cases. This is **normal**. The warnings correspond to cases in which\n  the program is trying to collect data from a certain frame number in which a\n  face was not detected on the originating video.\n\nReproduce Paper Results\n=======================\n\nTo reproduce our paper results (~82% of attacks passing the verification\nsystem), you must generate two score files as defined above and then call a few\nprograms that compute the threshold on the development set and apply it to the\nlicit and spoofing test sets::\n\n  $ ./bin/eval_threshold.py --scores=results/perf/devel-baseline-thourough-220.4c\n  Threshold: 0.686207566\n  FAR : 0.000% (0/840)\n  FRR : 0.000% (0/60)\n  HTER: 0.000%\n\n  $ ./bin/apply_threshold.py --scores=results/perf/test-grandtest-220.4c --threshold=0.686207566\n  FAR : 82.500% (330/400)\n  FRR : 0.000% (0/80)\n  HTER: 41.250%\n\n.. some links\n\n.. _bob: http://idiap.github.com/bob", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://pypi.python.org/pypi/antispoofing.verification.gmm", "keywords": null, "license": "GPLv3", "maintainer": null, "maintainer_email": null, "name": "antispoofing.verification.gmm", "package_url": "https://pypi.org/project/antispoofing.verification.gmm/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/antispoofing.verification.gmm/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://pypi.python.org/pypi/antispoofing.verification.gmm"}, "release_url": "https://pypi.org/project/antispoofing.verification.gmm/1.0.2/", "requires_dist": null, "requires_python": null, "summary": "Replay-Attack Face Verification Package Based on a Parts-Based Gaussian Mixture Models", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This <a href=\"http://idiap.github.com/bob\" rel=\"nofollow\">Bob</a> satellite package allows you to run a baseline Parts-Based GMM face\nverification system on the Replay Attack Database. It explains how to setup\nthis package, generate the Universal Background Model (UBM), client models and\nfinally, scores.</p>\n<p>If you use this package and/or its results, please cite the following\npublications:</p>\n<ol>\n<li><p>The Replay-Attack Database and baseline GMM results for it:</p>\n<pre>@inproceedings{Chingovska_BIOSIG_2012,\n  author = {I. Chingovska AND A. Anjos AND S. Marcel},\n  keywords = {Attack, Counter-Measures, Counter-Spoofing, Face Recognition, Liveness Detection, Replay, Spoofing},\n  month = sep,\n  title = {On the Effectiveness of Local Binary Patterns in Face Anti-spoofing},\n  booktitle = {IEEE BioSIG 2012},\n  year = {2012},\n}\n</pre>\n</li>\n<li><p>Bob as the core framework used for these results:</p>\n<pre>@inproceedings{Anjos_ACMMM_2012,\n    author = {A. Anjos AND L. El Shafey AND R. Wallace AND M. G\\\"unther AND C. McCool AND S. Marcel},\n    title = {Bob: a free signal processing and machine learning toolbox for researchers},\n    year = {2012},\n    month = oct,\n    booktitle = {20th ACM Conference on Multimedia Systems (ACMMM), Nara, Japan},\n    publisher = {ACM Press},\n}\n</pre>\n</li>\n</ol>\n<p>If you wish to report problems or improvements concerning this code, please\ncontact the authors of the above mentioned papers.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<div>\n<p>Note</p>\n<p>If you are reading this page through our GitHub portal and not through PyPI,\nnote <strong>the development tip of the package may not be stable</strong> or become\nunstable in a matter of moments.</p>\n<p>Go to <a href=\"http://pypi.python.org/pypi/antispoofing.verification.gmm\" rel=\"nofollow\">http://pypi.python.org/pypi/antispoofing.verification.gmm</a> to download the\nlatest stable version of this package.</p>\n</div>\n<p>There are 2 options you can follow to get this package installed and\noperational on your computer: you can use automatic installers like <a href=\"http://pypi.python.org/pypi/pip/\" rel=\"nofollow\">pip</a> (or <a href=\"http://pypi.python.org/pypi/setuptools\" rel=\"nofollow\">easy_install</a>) or manually download, unpack and\nuse <a href=\"http://pypi.python.org/pypi/zc.buildout\" rel=\"nofollow\">zc.buildout</a> to create a\nvirtual work environment just for this package.</p>\n<div id=\"using-an-automatic-installer\">\n<h3>Using an automatic installer</h3>\n<p>Using <tt>pip</tt> is the easiest (shell commands are marked with a <tt>$</tt> signal):</p>\n<pre>$ pip install antispoofing.verification.gmm\n</pre>\n<p>You can also do the same with <tt>easy_install</tt>:</p>\n<pre>$ easy_install antispoofing.verification.gmm\n</pre>\n<p>This will download and install this package plus any other required\ndependencies. It will also verify if the version of Bob you have installed\nis compatible.</p>\n<p>This scheme works well with virtual environments by <a href=\"http://pypi.python.org/pypi/virtualenv\" rel=\"nofollow\">virtualenv</a> or if you have root access to your\nmachine. Otherwise, we recommend you use the next option.</p>\n</div>\n<div id=\"using-zc-buildout\">\n<h3>Using <tt>zc.buildout</tt></h3>\n<p>Download the latest version of this package from <a href=\"http://pypi.python.org/pypi/antispoofing.verification.gmm\" rel=\"nofollow\">PyPI</a> and unpack it in\nyour working area. The installation of the toolkit itself uses <a href=\"http://www.buildout.org/\" rel=\"nofollow\">buildout</a>. You don\u2019t need to understand its inner workings\nto use this package. Here is a recipe to get you started:</p>\n<pre>$ python bootstrap.py $ ./bin/buildout\n</pre>\n<p>These 2 commands should download and install all non-installed dependencies and\nget you a fully operational test and development environment.</p>\n<div>\n<p>Note</p>\n<p>The python shell used in the first line of the previous command set\ndetermines the python interpreter that will be used for all scripts developed\ninside this package. Because this package makes use of <a href=\"http://idiap.github.com/bob\" rel=\"nofollow\">Bob</a>, &lt;you must make\nsure that the <tt>bootstrap.py</tt> script is called with the <strong>same</strong> interpreter\nused to build Bob, or unexpected problems might occur.</p>\n<p>If Bob is installed by the administrator of your system, it is safe to\nconsider it uses the default python interpreter. In this case, the above 3\ncommand lines should work as expected. If you have Bob installed somewhere\nelse on a private directory, edit the file <tt>buildout.cfg</tt> <strong>before</strong>\nrunning <tt>./bin/buildout</tt>. Find the section named <tt>external</tt> and edit the\nline <tt><span class=\"pre\">egg-directories</span></tt> to point to the <tt>lib</tt> directory of the Bob\ninstallation you want to use. For example:</p>\n<pre>[external]\nrecipe = xbob.buildout:external\negg-directories=/Users/crazyfox/work/bob/build/lib\n</pre>\n</div>\n</div>\n</div>\n<div id=\"user-guide\">\n<h2>User Guide</h2>\n<div id=\"configuration-tweaking-optional\">\n<h3>Configuration Tweaking (optional)</h3>\n<p>The current scripts have been tunned to reproduce the results presented on some\nof our publications (as indicated above), as well as on FP7 Project <a href=\"http://www.tabularasa-euproject.org/\" rel=\"nofollow\">TABULA\nRASA</a> reports.  They still accept an\nalternate (python) configuration file that can be passed as input. If nothing\nis passed, a default configuration file located at\n<tt>antispoofing/verification/gmm/config/gmm_replay.py</tt> is used. Copy that file\nto the current directory and edit it to modify the overall configuration for\nthe mixture-model system or for the (DCT-based) feature extraction. Use the\noption <tt><span class=\"pre\">--config=myconfig.py</span></tt> to set your private configuration if you decide\nto do so. Remember to set the option thoroughly through out all script calls or\nunexpected results may happen.</p>\n</div>\n<div id=\"running-the-experiments\">\n<h3>Running the Experiments</h3>\n<p>Follow the sequence described here to reproduce paper results.</p>\n<p>Run <tt>feature_extract.py</tt> to extract the DCT block features. This step is\nthe only that requires the original database videos as input. It will generate,\n<strong>per video frame</strong>, all input features required by the scripts that follow\nthis one:</p>\n<pre>$ ./bin/feature_extract.py /root/of/replay/attack/database results/dct\n</pre>\n<p>This will run through the 1300 videos in the database and extract the features\nat the frame intervals defined at the configuration. In a relatively fast\nmachine, it will take about 10-20 seconds per input video, with a frame-skip\nparameter set to 10 (the default). If you want to be thorough, you will need to\nparallelize this script so that the overall database can be processed in a\nreasonable amount of time.</p>\n<p>You can parallelize the execution of the above script (and of some of the\nscripts below as well) if you are a Idiap. Just do the following instead:</p>\n<pre>$ ./bin/jman submit --array=1300 ./bin/feature_extract.py /root/of/replay/attack/database results/dct --grid\n</pre>\n<p>Notice the <tt><span class=\"pre\">--array=1300</span></tt> and <tt><span class=\"pre\">--grid</span></tt> option by the end of the script. The\nabove instruction tells SGE to run 1300 versions of my script with the same\ninput parameters. The only difference is <tt>SGE_TASK_ID</tt> environment variable\nthat is changed at every interation (thanks to the <tt><span class=\"pre\">--array=1300</span></tt> option).\nThe <tt><span class=\"pre\">--grid</span></tt> option the execution of the script analyze first the value of\n<tt>SGE_TASK_ID</tt> and re-set the internal processing so that particular instance\nof <tt>feature_extract.py</tt> only processes one of the 1300 videos that requires\nprocessing. You can check the status of the jobs in the grid with <tt>jman\nrefresh</tt> (refer to the <cite>GridTk manual &lt;http://packages.python.org/gridtk&gt;</cite> for\ndetails).</p>\n<div>\n<p>Note</p>\n<p>If you are not, you can still take a look at our <a href=\"http://pypi.python.org/pypi/gridtk\" rel=\"nofollow\">GridTk package</a> for a logging grid job manager for SGE.</p>\n</div>\n</div>\n<div id=\"ubm-training\">\n<h3>UBM Training</h3>\n<p>Run <tt>train_ubm.py</tt> to create the GMM Universal Background Model from selected\nfeatures (in the enrollment/training subset):</p>\n<pre>$ ./bin/train_ubm.py results/dct results/ubm.hdf5\n</pre>\n<div>\n<p>Note</p>\n<p>Note: if you use ~1k files, it will take a few hours to complete and there is\ncurrently no way to parallelize this.  This step requires all features for\nthe training set/enrollment are calculated. The job can take many gigabytes\nof physical memory from your machine, so we advise you to run it in a machine\nwith, at least, 8 gigabytes of free memory.</p>\n</div>\n<p>Unfortunately, you cannot easily parallelize this job. Nevertheless, you can\nsubmit it to the grid with the following command and avoid it to run on your\nmachine (nice if you have a busy day of work):</p>\n<pre>$ ./bin/jman submit --queue=q_1week --memory=8G ./bin/train_ubm.py results/dct results/ubm.hdf5\n</pre>\n<p>Even if you choose a long enough queue, it is still prudent to set the memory\nrequirements for the node you will be assigned to, to guarantee a minimum\namount of memory.</p>\n</div>\n<div id=\"ubm-statistics-generation\">\n<h3>UBM Statistics Generation</h3>\n<p>Run <tt>generate_statistics.py</tt> to create the background statistics for all\ndatafiles so we can calculate scores later. This step requires that the UBM is\ntrained and all features are available:</p>\n<pre>$ ./bin/generate_statistics.py results/dct results/ubm.hdf5 results/stats\n</pre>\n<p>This will take a lot of time to go through all the videos in the replay\ndatabase. You can optionally submit the command to the grid, if you are at\nIdiap, with the following:</p>\n<pre>$ ./bin/jman submit --array=840 ./bin/generate_statistics.py results/dct results/ubm.hdf5 results/stats --grid\n</pre>\n<p>This command will spread the GMM UBM statistics calculation over 840 processes\nthat will run in about 5-10 minutes each. So, the whole job will take a few\nhours to complete - taking into consideration current settings for SGE at\nIdiap.</p>\n</div>\n<div id=\"client-model-training\">\n<h3>Client Model training</h3>\n<div>\n<p>Note</p>\n<p>You can do this in parallel with the step above as it only depends on the\ninput features pre-calculated at step 3</p>\n</div>\n<p>Generate the models for all clients:</p>\n<pre>$ ./bin/enrol.py results/dct results/ubm.hdf5 results/models\n</pre>\n<p>If you think the above job is too slow, you can throw it at the grid as well:</p>\n<pre>$ ./bin/jman submit --array=35 ./bin/enrol.py results/dct results/ubm.hdf5 results/models --grid\n</pre>\n</div>\n<div id=\"scoring\">\n<h3>Scoring</h3>\n<p>In this step you will score the videos (every N frames up to a certain frame\nnumber) against the generated client models. We do this exhaustively for both\nthe test and development data. Command line execution goes like this:</p>\n<pre>$ ./bin/score.py results/stats results/ubm.hdf5 results/models results/scores\n</pre>\n<p>Linear scoring is fast, but you can also submit a client-based break-down of\nthis problem like this:</p>\n<pre>$ ./bin/jman submit --array=35 ./bin/score.py results/stats results/ubm.hdf5 results/models results/scores --grid\n</pre>\n</div>\n<div id=\"full-score-files\">\n<h3>Full Score Files</h3>\n<p>After scores are calculated, you need to put them together to setup development\nand test text files in a 4 or 5 column format. To do that, use the application\n<tt>build_score_files.py</tt>. The next command will generate the baseline\nverification results by thouroughly matching every client video against every\nmodel available in the individual sets, averaging over (the first) 220 frames:</p>\n<pre>$ ./bin/build_score_files.py results/scores results/perf --thorough --frames=220\n</pre>\n<p>You can specify to use the attack protocols like this (avoid using the\n<cite>\u2013thourough</cite> option):</p>\n<pre>$ ./bin/build_score_files.py results/scores results/perf --protocol=grandtest --frames=220\n</pre>\n<div>\n<p>Warning</p>\n<p>It is possible you see warnings being emitted by the above programs in\ncertain cases. This is <strong>normal</strong>. The warnings correspond to cases in which\nthe program is trying to collect data from a certain frame number in which a\nface was not detected on the originating video.</p>\n</div>\n</div>\n<div id=\"reproduce-paper-results\">\n<h3>Reproduce Paper Results</h3>\n<p>To reproduce our paper results (~82% of attacks passing the verification\nsystem), you must generate two score files as defined above and then call a few\nprograms that compute the threshold on the development set and apply it to the\nlicit and spoofing test sets:</p>\n<pre>$ ./bin/eval_threshold.py --scores=results/perf/devel-baseline-thourough-220.4c\nThreshold: 0.686207566\nFAR : 0.000% (0/840)\nFRR : 0.000% (0/60)\nHTER: 0.000%\n\n$ ./bin/apply_threshold.py --scores=results/perf/test-grandtest-220.4c --threshold=0.686207566\nFAR : 82.500% (330/400)\nFRR : 0.000% (0/80)\nHTER: 41.250%\n</pre>\n</div>\n</div>\n\n          </div>"}, "last_serial": 819146, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "8ee16e5c4ee0293e25d2cac261f300f1", "sha256": "2d227ea043739f49752ccc6f1861c1b4f6c8dcb0bd8ff09fb7a3ac98523a2ff8"}, "downloads": -1, "filename": "antispoofing.verification.gmm-1.0.0.zip", "has_sig": false, "md5_digest": "8ee16e5c4ee0293e25d2cac261f300f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 51803, "upload_time": "2012-08-30T14:32:56", "upload_time_iso_8601": "2012-08-30T14:32:56.271920Z", "url": "https://files.pythonhosted.org/packages/4c/61/7b033c89d7136a97286ee3f1657eb051760a059b5a93a6ad1748f9d5f588/antispoofing.verification.gmm-1.0.0.zip", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "f558b1424db36fdafcd2f76bc9478126", "sha256": "407e52567d71d62f916376c9db067233bc69effafb4080767bb2a35b6391b4ae"}, "downloads": -1, "filename": "antispoofing.verification.gmm-1.0.1.zip", "has_sig": false, "md5_digest": "f558b1424db36fdafcd2f76bc9478126", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 51901, "upload_time": "2013-02-19T14:30:34", "upload_time_iso_8601": "2013-02-19T14:30:34.851284Z", "url": "https://files.pythonhosted.org/packages/90/d0/4d5de0bdbbc13f1c295f69bea1aa2000aea9aefd6e1407e3e48c920949e6/antispoofing.verification.gmm-1.0.1.zip", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "838967ad3788a7bbed14939ae9073b6a", "sha256": "ef54ba01010dc6887529ef4ab9dc110cbdbc11cf2266963334f812fda27794bc"}, "downloads": -1, "filename": "antispoofing.verification.gmm-1.0.2.zip", "has_sig": false, "md5_digest": "838967ad3788a7bbed14939ae9073b6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50366, "upload_time": "2013-07-19T13:46:41", "upload_time_iso_8601": "2013-07-19T13:46:41.617917Z", "url": "https://files.pythonhosted.org/packages/b5/ca/ccdeea51b1196052aed277fbc7c80a016f79c4412d27636144da947bf3a9/antispoofing.verification.gmm-1.0.2.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "838967ad3788a7bbed14939ae9073b6a", "sha256": "ef54ba01010dc6887529ef4ab9dc110cbdbc11cf2266963334f812fda27794bc"}, "downloads": -1, "filename": "antispoofing.verification.gmm-1.0.2.zip", "has_sig": false, "md5_digest": "838967ad3788a7bbed14939ae9073b6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50366, "upload_time": "2013-07-19T13:46:41", "upload_time_iso_8601": "2013-07-19T13:46:41.617917Z", "url": "https://files.pythonhosted.org/packages/b5/ca/ccdeea51b1196052aed277fbc7c80a016f79c4412d27636144da947bf3a9/antispoofing.verification.gmm-1.0.2.zip", "yanked": false}], "timestamp": "Thu May  7 18:17:59 2020"}