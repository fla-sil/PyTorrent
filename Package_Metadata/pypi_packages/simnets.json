{"info": {"author": "Elhanan Ilani", "author_email": "elhanan.ilani@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: POSIX :: Linux", "Programming Language :: C++", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: Implementation :: CPython", "Topic :: Scientific/Engineering"], "description": "# simnets-tf\n## SimNets implementation in TensorFlow\n\n### Binary installation\nBinary installation requires a cuda toolkit installation >= 7.5. <BR/>\nDownload the .whl file from the GitHub release tab, then type:\n```\npython -m pip install <whl file>\n```\nall requirements should be installed automatically.\n\n### Building from Source\nBuilding from source requires:\n1. A working c++ compiler with c++11 support (gcc >= 4.7)\n2. Cuda toolkit installed (for nvcc)\n3. CMake >= 3.0 (<code>apt install cmake</code>)\n4. TensorFlow installed for the Python interpreter you intend to use\n\n<B>Important:</B> The following command should run without error:\n```\npython -c 'import tensorflow as tf'\n```\nTo build the project type the following commands:<BR/>\n Python 2.7:<BR/>\n ```\n git clone --recursive https://github.com/HUJI-Deep/simnets-tf.git\n cd simnets-tf\n mkdir build\n cd build\n cmake .. -DCMAKE_BUILD_TYPE=Release -DSIMNETS_PYTHON_VERSION=2.7 -DCMAKE_INSTALL_PREFIX=install\n make -j simnet_ops\n ```\n\n Python 3.5:<BR/>\n  ```\n  git clone --recursive https://github.com/HUJI-Deep/simnets-tf.git\n  cd simnets-tf\n  mkdir build\n  cd build\n  cmake .. -DCMAKE_BUILD_TYPE=Release -DSIMNETS_PYTHON_VERSION=3.5 -DCMAKE_INSTALL_PREFIX=install\n  make -j simnet_ops\n  ```\n To test the code you can now type:\n ```\n make test_simnet_ops\n ```\n This should run for about two minutes and return without any errors.<BR/>\n Now you can create a .whl file:\n ```\n make create_wheel\n ```\n\n Finally, to install the simnets-tf package type (remember to use the right interpreter):\n ```\n cd install/dist\n python -m pip install <whl file>\n ```\n The installation is successful if the following runs (again, remember to use the right interpreter):\n ```\n python -c 'import simnets'\n ```\n\n ### Usage example\n #### Keras\n ```python\nimport simnets.keras as sk\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom keras.layers import Input, Flatten, AveragePooling2D, Lambda\nfrom keras import backend as K\nimport numpy as np\n\nbatch_size = 64\nnum_classes = 10\nsim_kernel = 2\nsim_channels = 32\nmex_channels = sim_channels\nepochs = 3\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n\nx_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\nx_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\ninput_shape = (1, img_rows, img_cols)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train = x_train / 255.0 - 0.5\nx_test = x_test / 255.0 - 0.5\n\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n\ndef sum_pooling_layer(x, pool_size):\n    x = AveragePooling2D(pool_size=pool_size, padding='valid')(x)\n    x = Lambda(lambda x: x * pool_size[0] * pool_size[1])(x)\n    return x\n\n\na = Input(shape=(1, img_rows, img_cols))\nb = sk.Similarity(sim_channels,\n                  ksize=[2, 2], strides=[2, 2], similarity_function='L2',\n                  normalization_term=True, padding=[2, 2], out_of_bounds_value=np.nan, ignore_nan_input=True)(a)\nwhile b.shape[-2:] != (1, 1):\n    mex_channels *= 2\n    b = sk.Mex(mex_channels,\n               blocks=[int(b.shape[-3]), 1, 1], strides=[int(b.shape[-3]), 1, 1],\n               softmax_mode=True, normalize_offsets=True,\n               use_unshared_regions=True, unshared_offset_region=[2])(b)\n    b = sum_pooling_layer(b, pool_size=(2, 2))\n\nb = sk.Mex(num_classes,\n           blocks=[mex_channels, 1, 1], strides=[mex_channels, 1, 1],\n           softmax_mode=True, normalize_offsets=True,\n           use_unshared_regions=True, shared_offset_region=[1])(b)\nb = Flatten()(b)\nmodel = Model(inputs=[a], outputs=[b])\n\nprint(model.summary())\n\ndef softmax_loss(y_true, y_pred):\n    return K.categorical_crossentropy(y_pred, y_true, True)\n\nmodel.compile(loss=softmax_loss,\n              optimizer=keras.optimizers.nadam(lr=1e-2, epsilon=1e-6),\n              metrics=['accuracy'])\n\nsk.perform_unsupervised_init(model, 'kmeans', layers=None, data=x_train, batch_size=100)\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\n```\n\n#### Low level\n```python\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom simnets import similarity\nfrom simnets.unsupervised import similarity_unsupervised_init\nimport matplotlib.pyplot as plt\n\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nsess = tf.InteractiveSession()\n\nx = tf.placeholder(tf.float32, shape=[None, 784])\nxr = tf.reshape(x, [-1, 1, 28, 28])\ny_ = tf.placeholder(tf.float32, shape=[None, 10])\n\nshape = [10, 1, 28, 28]\n\ntemplates = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\nweights_var = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\nweights = tf.abs(weights_var)\n\nsim = similarity(xr, templates, weights, similarity_function='L2', ksize=[28,28], strides=[28,28], padding=[0,0])\ny = tf.reshape(sim, [-1, 10])\n\nkmo_init, kmo = similarity_unsupervised_init('kmeans', sim, templates, weights_var)\n\ncross_entropy = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\nsess.run(tf.global_variables_initializer())\n\n\nfor idx in range(300):\n    batch = mnist.train.next_batch(100)\n    if idx == 0:\n        kmo_init.run(feed_dict={x: batch[0], y_: batch[1]})\n    kmo.run(feed_dict={x: batch[0], y_: batch[1]})\n    if (idx + 1) % 100 == 0:\n        print('kmeans', idx+1, '/', 1000)\n\ndef normalize(img):\n    return (img - img.min()) / (img.max() - img.min())\n\ntemplates_np = tf.get_default_session().run(templates)\nplt.figure(1)\nfor i in range(10):\n    plt.subplot(4,3, i+1)\n    plt.imshow(normalize(templates_np[i,0,...]))\nplt.show()\n\nfor idx in range(1000):\n    batch = mnist.train.next_batch(100)\n    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n    if (idx + 1) % 100 == 0:\n        print(idx+1, '/', 1000)\n\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nprint('Accuracy:', accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n\n```\n\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/HUJI-Deep/simnets-tf", "keywords": "tensorflow simnets machine-learning", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "simnets", "package_url": "https://pypi.org/project/simnets/", "platform": "", "project_url": "https://pypi.org/project/simnets/", "project_urls": {"Homepage": "https://github.com/HUJI-Deep/simnets-tf"}, "release_url": "https://pypi.org/project/simnets/0.0.1/", "requires_dist": ["tensorflow-gpu", "keras"], "requires_python": "", "summary": "SimNets implementation in tensorflow", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            # simnets-tf<br>## SimNets implementation in TensorFlow<br><br>### Binary installation<br>Binary installation requires a cuda toolkit installation &gt;= 7.5. &lt;BR/&gt;<br>Download the .whl file from the GitHub release tab, then type:<br>```<br>python -m pip install &lt;whl file&gt;<br>```<br>all requirements should be installed automatically.<br><br>### Building from Source<br>Building from source requires:<br>1. A working c++ compiler with c++11 support (gcc &gt;= 4.7)<br>2. Cuda toolkit installed (for nvcc)<br>3. CMake &gt;= 3.0 (&lt;code&gt;apt install cmake&lt;/code&gt;)<br>4. TensorFlow installed for the Python interpreter you intend to use<br><br>&lt;B&gt;Important:&lt;/B&gt; The following command should run without error:<br>```<br>python -c 'import tensorflow as tf'<br>```<br>To build the project type the following commands:&lt;BR/&gt;<br> Python 2.7:&lt;BR/&gt;<br> ```<br> git clone --recursive https://github.com/HUJI-Deep/simnets-tf.git<br> cd simnets-tf<br> mkdir build<br> cd build<br> cmake .. -DCMAKE_BUILD_TYPE=Release -DSIMNETS_PYTHON_VERSION=2.7 -DCMAKE_INSTALL_PREFIX=install<br> make -j simnet_ops<br> ```<br><br> Python 3.5:&lt;BR/&gt;<br>  ```<br>  git clone --recursive https://github.com/HUJI-Deep/simnets-tf.git<br>  cd simnets-tf<br>  mkdir build<br>  cd build<br>  cmake .. -DCMAKE_BUILD_TYPE=Release -DSIMNETS_PYTHON_VERSION=3.5 -DCMAKE_INSTALL_PREFIX=install<br>  make -j simnet_ops<br>  ```<br> To test the code you can now type:<br> ```<br> make test_simnet_ops<br> ```<br> This should run for about two minutes and return without any errors.&lt;BR/&gt;<br> Now you can create a .whl file:<br> ```<br> make create_wheel<br> ```<br><br> Finally, to install the simnets-tf package type (remember to use the right interpreter):<br> ```<br> cd install/dist<br> python -m pip install &lt;whl file&gt;<br> ```<br> The installation is successful if the following runs (again, remember to use the right interpreter):<br> ```<br> python -c 'import simnets'<br> ```<br><br> ### Usage example<br> #### Keras<br> ```python<br>import simnets.keras as sk<br>import keras<br>from keras.datasets import mnist<br>from keras.models import Model<br>from keras.layers import Input, Flatten, AveragePooling2D, Lambda<br>from keras import backend as K<br>import numpy as np<br><br>batch_size = 64<br>num_classes = 10<br>sim_kernel = 2<br>sim_channels = 32<br>mex_channels = sim_channels<br>epochs = 3<br><br># input image dimensions<br>img_rows, img_cols = 28, 28<br><br># the data, shuffled and split between train and test sets<br>(x_train, y_train), (x_test, y_test) = mnist.load_data()<br><br><br>x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)<br>x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)<br>input_shape = (1, img_rows, img_cols)<br><br>x_train = x_train.astype('float32')<br>x_test = x_test.astype('float32')<br>x_train = x_train / 255.0 - 0.5<br>x_test = x_test / 255.0 - 0.5<br><br>print(x_train.shape[0], 'train samples')<br>print(x_test.shape[0], 'test samples')<br><br># convert class vectors to binary class matrices<br>y_train = keras.utils.to_categorical(y_train, num_classes)<br>y_test = keras.utils.to_categorical(y_test, num_classes)<br><br><br>def sum_pooling_layer(x, pool_size):<br>    x = AveragePooling2D(pool_size=pool_size, padding='valid')(x)<br>    x = Lambda(lambda x: x * pool_size[0] * pool_size[1])(x)<br>    return x<br><br><br>a = Input(shape=(1, img_rows, img_cols))<br>b = sk.Similarity(sim_channels,<br>                  ksize=[2, 2], strides=[2, 2], similarity_function='L2',<br>                  normalization_term=True, padding=[2, 2], out_of_bounds_value=np.nan, ignore_nan_input=True)(a)<br>while b.shape[-2:] != (1, 1):<br>    mex_channels *= 2<br>    b = sk.Mex(mex_channels,<br>               blocks=[int(b.shape[-3]), 1, 1], strides=[int(b.shape[-3]), 1, 1],<br>               softmax_mode=True, normalize_offsets=True,<br>               use_unshared_regions=True, unshared_offset_region=[2])(b)<br>    b = sum_pooling_layer(b, pool_size=(2, 2))<br><br>b = sk.Mex(num_classes,<br>           blocks=[mex_channels, 1, 1], strides=[mex_channels, 1, 1],<br>           softmax_mode=True, normalize_offsets=True,<br>           use_unshared_regions=True, shared_offset_region=[1])(b)<br>b = Flatten()(b)<br>model = Model(inputs=[a], outputs=[b])<br><br>print(model.summary())<br><br>def softmax_loss(y_true, y_pred):<br>    return K.categorical_crossentropy(y_pred, y_true, True)<br><br>model.compile(loss=softmax_loss,<br>              optimizer=keras.optimizers.nadam(lr=1e-2, epsilon=1e-6),<br>              metrics=['accuracy'])<br><br>sk.perform_unsupervised_init(model, 'kmeans', layers=None, data=x_train, batch_size=100)<br><br>model.fit(x_train, y_train,<br>          batch_size=batch_size,<br>          epochs=epochs,<br>          verbose=1,<br>          validation_data=(x_test, y_test))<br>score = model.evaluate(x_test, y_test, verbose=0)<br>print('Test loss:', score[0])<br>print('Test accuracy:', score[1])<br><br>```<br><br>#### Low level<br>```python<br>import tensorflow as tf<br>from tensorflow.examples.tutorials.mnist import input_data<br>from simnets import similarity<br>from simnets.unsupervised import similarity_unsupervised_init<br>import matplotlib.pyplot as plt<br><br>mnist = input_data.read_data_sets('MNIST_data', one_hot=True)<br>sess = tf.InteractiveSession()<br><br>x = tf.placeholder(tf.float32, shape=[None, 784])<br>xr = tf.reshape(x, [-1, 1, 28, 28])<br>y_ = tf.placeholder(tf.float32, shape=[None, 10])<br><br>shape = [10, 1, 28, 28]<br><br>templates = tf.Variable(tf.truncated_normal(shape, stddev=0.1))<br>weights_var = tf.Variable(tf.truncated_normal(shape, stddev=0.1))<br>weights = tf.abs(weights_var)<br><br>sim = similarity(xr, templates, weights, similarity_function='L2', ksize=[28,28], strides=[28,28], padding=[0,0])<br>y = tf.reshape(sim, [-1, 10])<br><br>kmo_init, kmo = similarity_unsupervised_init('kmeans', sim, templates, weights_var)<br><br>cross_entropy = tf.reduce_mean(<br>    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))<br><br>train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)<br><br>sess.run(tf.global_variables_initializer())<br><br><br>for idx in range(300):<br>    batch = mnist.train.next_batch(100)<br>    if idx == 0:<br>        kmo_init.run(feed_dict={x: batch[0], y_: batch[1]})<br>    kmo.run(feed_dict={x: batch[0], y_: batch[1]})<br>    if (idx + 1) % 100 == 0:<br>        print('kmeans', idx+1, '/', 1000)<br><br>def normalize(img):<br>    return (img - img.min()) / (img.max() - img.min())<br><br>templates_np = tf.get_default_session().run(templates)<br>plt.figure(1)<br>for i in range(10):<br>    plt.subplot(4,3, i+1)<br>    plt.imshow(normalize(templates_np[i,0,...]))<br>plt.show()<br><br>for idx in range(1000):<br>    batch = mnist.train.next_batch(100)<br>    train_step.run(feed_dict={x: batch[0], y_: batch[1]})<br>    if (idx + 1) % 100 == 0:<br>        print(idx+1, '/', 1000)<br><br>correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))<br>accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<br>print('Accuracy:', accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))<br><br>```<br><br><br><br>\n          </div>"}, "last_serial": 3970906, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "275cc8a46c62b234ab709e883da2a858", "sha256": "2930edc4f0d8fe4abdf6d979438e682fbf53734ab8d301f29a58b0545838a397"}, "downloads": -1, "filename": "simnets-0.0.1-cp27-none-manylinux1_x86_64.whl", "has_sig": false, "md5_digest": "275cc8a46c62b234ab709e883da2a858", "packagetype": "bdist_wheel", "python_version": "cp27", "requires_python": null, "size": 1760478, "upload_time": "2018-06-17T12:13:51", "upload_time_iso_8601": "2018-06-17T12:13:51.053434Z", "url": "https://files.pythonhosted.org/packages/4c/b7/4ba60509e5e87ad0e758dc7babc58cbaf28fe82562bdd2c3b8df5655d63f/simnets-0.0.1-cp27-none-manylinux1_x86_64.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "275cc8a46c62b234ab709e883da2a858", "sha256": "2930edc4f0d8fe4abdf6d979438e682fbf53734ab8d301f29a58b0545838a397"}, "downloads": -1, "filename": "simnets-0.0.1-cp27-none-manylinux1_x86_64.whl", "has_sig": false, "md5_digest": "275cc8a46c62b234ab709e883da2a858", "packagetype": "bdist_wheel", "python_version": "cp27", "requires_python": null, "size": 1760478, "upload_time": "2018-06-17T12:13:51", "upload_time_iso_8601": "2018-06-17T12:13:51.053434Z", "url": "https://files.pythonhosted.org/packages/4c/b7/4ba60509e5e87ad0e758dc7babc58cbaf28fe82562bdd2c3b8df5655d63f/simnets-0.0.1-cp27-none-manylinux1_x86_64.whl", "yanked": false}], "timestamp": "Fri May  8 03:11:09 2020"}