{"info": {"author": "Thamme Gowda", "author_email": "tgowdan@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Topic :: Text Processing", "Topic :: Text Processing :: Filters", "Topic :: Text Processing :: General", "Topic :: Text Processing :: Linguistic", "Topic :: Utilities"], "description": "# NLCodec\nA set of (low level) Natural Language Encoder-Decoders (codecs), that are useful in preprocessing stage of \nNLP pipeline. These codecs include encoding of sequences into one of the following:\n1. Character\n2. Word\n3. BPE based subword\n\nIt provides python (so embed into your app) and CLI APIs (use it as stand alone tool).\n\nThere are many BPE implementations available already, but this one provides differs:\n1. Pure python implementation that is easy to modify anything to try new ideas. \n  (other implementations require c++ expertise to modify the core) \n2. BPE model is a simple text that can be inspected with `less` or `cut`. It includes info on which pieces were put together and what frequencies etc. \n3. Reasonably faster than the other pure python implementations -- speed in python comes with the cost of extra memory due to indexing.\n\n\n# Installation \nPlease run only one of these\n```bash\n# Clone repo for development mode (preferred  mode)\ngit clone https://github.com/isi-nlp/nlcodec\ncd nlcodec\npip install --editable . \n\n# Install from github, directly\n$ pip install git+https://github.com/isi-nlp/nlcodec.git\n\n\n# Install from pypi\n$ pip install nlcodec\n```\npip installer registers a cli tool named `nlcodec` in PATH\n which serves is the command line interface.\n  You can always trigger either via `python -m nlcodec` or \n `python path/to/nlcodec/__main__.py` if you wish!\n\n\n## Usage \n```bash\n$ python -m nlcodec -h\nusage: __main__.py [-h] [-i INP] [-o OUT] -m MODEL [-idx] [-vs VOCAB_SIZE]\n                   [-l {char,word,bpe}] [-mf MIN_FREQ]\n                   {learn,encode,decode,estimate}\n\npositional arguments:\n  {learn,encode,decode,estimate}\n                        \"task\" or sub-command.\n                            \"learn\" - learns vocabulary. use --level and vocab_size for type and size \n                            \"encode\" - encodes a dataset \n                            \"decode\" - decodes an already encoded dataset\n                            \"estimate\" - estimates quality attributes of an encoding\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i INP, --inp INP     Input file path (default: <_io.TextIOWrapper\n                        name='<stdin>' mode='r' encoding='UTF-8'>)\n  -o OUT, --out OUT     Output file path. Not valid for \"learn\" or \"estimate\"\n                        task (default: <_io.TextIOWrapper name='<stdout>'\n                        mode='w' encoding='UTF-8'>)\n  -m MODEL, --model MODEL\n                        Path to model aka vocabulary file (default: None)\n  -idx, --indices       Indices instead of strings. Valid for task=encode and\n                        task=decode (default: None)\n\nargs for task=learn:\n  -vs VOCAB_SIZE, --vocab_size VOCAB_SIZE\n                        Vocabulary size. Valid only for task=learn. This is\n                        required for \"bpe\", but optional for \"word\" and \"char\"\n                        models, specifying it will trim the vocabulary at\n                        given top most frequent types. (default: -1)\n  -l {char,word,bpe}, --level {char,word,bpe}\n                        Encoding Level; Valid only for task=learn (default:\n                        None)\n  -mf MIN_FREQ, --min_freq MIN_FREQ\n                        Minimum frequency of types for considering inclusion\n                        in vocabulary. Types fewer than this frequency will be\n                        ignored. For --level=word, freq is type freq and\n                        default is 2.for --level=char or --level=bpe,\n                        characters fewer than this value will be excluded.\n                        default=20 (default: None)\n\n```\n\nExample: \n\n```\n# learn\nhead -2000 somefile.tok | nlcodec learn -l bpe -m bpe.model --vocab_size 2000\n\n# encode  with text pieces\nhead  somefile.tok  | nlcodec encode -m bpe.model\n\n# encode with indexes\nhead  somefile.tok  | nlcodec encode -m bpe.model -idx\n\n# decode -- undo encoding\nhead  somefile.tok  | nlcodec decode -m bpe.model\nhead  somefile.tok  | nlcodec decode -m bpe.model -idx\n\n# estimate quality \nhead  somefile.tok  | nlcodec estimate -m bpe.model\n\n```\n\n## Python API\n\n### Using a vocabulary\n```python\nfrom nlcodec import  load_scheme\npath = 'path/to/vocab.model'\nvocab = load_scheme(path)\n\nline = 'this is a sample sentence'\n# encode a line of text into list of ids\nvocab.encode(line)\n\n# parallel encode a bunch of lines using multiple cpus\nvocab.encode_parallel(seqs=[line], n_cpus=2)\n\n# encode a line of text into pieces \nvocab.encode_str(line)\n\n# decode\nvocab.decode(vocab.encode(line))\nvocab.decode_str(vocab.encode_str(line))\n```\n\n### Creating a vocabulary\n```python\nfrom nlcodec import learn_vocab\ninp = ['line 1', 'line 2']\nlevel = 'bpe' # other options = char, word\nmodel = 'path/to/vocab.model'\nlearn_vocab(inp, level, model, vocab_size=8000, min_freq=1, char_coverage=0.9995)\n```\n\n\n### BPE Subword sub optimal splits for regularization\n\n```python\nfrom nlcodec import load_scheme, BPEScheme\npath = 'path/to/bpe-vocab.model'\nbpe: BPEScheme = load_scheme(path)\nsome_type = bpe.table[1000] # select some bpe piece type\n\n# get stochastic split\nsome_type.get_stochastic_split(split_ratio=0.5, name=False)\n# get all possible permutations \nsome_type.get_permutations(name=False)\n\n```\n\n\n# Authors \n+ [Thamme Gowda](https://twitter.com/thammegowda) \n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/thammegowda/bpepp", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/thammegowda/bpepp", "keywords": "", "license": "Apache Software License 2.0", "maintainer": "", "maintainer_email": "", "name": "nlcodec", "package_url": "https://pypi.org/project/nlcodec/", "platform": "any", "project_url": "https://pypi.org/project/nlcodec/", "project_urls": {"Download": "https://github.com/thammegowda/bpepp", "Homepage": "https://github.com/thammegowda/bpepp"}, "release_url": "https://pypi.org/project/nlcodec/0.2.0/", "requires_dist": ["tqdm"], "requires_python": ">=3.7", "summary": "nlcodec is a collection of encoding schemes for natural language sequences", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>NLCodec</h1>\n<p>A set of (low level) Natural Language Encoder-Decoders (codecs), that are useful in preprocessing stage of\nNLP pipeline. These codecs include encoding of sequences into one of the following:</p>\n<ol>\n<li>Character</li>\n<li>Word</li>\n<li>BPE based subword</li>\n</ol>\n<p>It provides python (so embed into your app) and CLI APIs (use it as stand alone tool).</p>\n<p>There are many BPE implementations available already, but this one provides differs:</p>\n<ol>\n<li>Pure python implementation that is easy to modify anything to try new ideas.\n(other implementations require c++ expertise to modify the core)</li>\n<li>BPE model is a simple text that can be inspected with <code>less</code> or <code>cut</code>. It includes info on which pieces were put together and what frequencies etc.</li>\n<li>Reasonably faster than the other pure python implementations -- speed in python comes with the cost of extra memory due to indexing.</li>\n</ol>\n<h1>Installation</h1>\n<p>Please run only one of these</p>\n<pre><span class=\"c1\"># Clone repo for development mode (preferred  mode)</span>\ngit clone https://github.com/isi-nlp/nlcodec\n<span class=\"nb\">cd</span> nlcodec\npip install --editable . \n\n<span class=\"c1\"># Install from github, directly</span>\n$ pip install git+https://github.com/isi-nlp/nlcodec.git\n\n\n<span class=\"c1\"># Install from pypi</span>\n$ pip install nlcodec\n</pre>\n<p>pip installer registers a cli tool named <code>nlcodec</code> in PATH\nwhich serves is the command line interface.\nYou can always trigger either via <code>python -m nlcodec</code> or\n<code>python path/to/nlcodec/__main__.py</code> if you wish!</p>\n<h2>Usage</h2>\n<pre>$ python -m nlcodec -h\nusage: __main__.py <span class=\"o\">[</span>-h<span class=\"o\">]</span> <span class=\"o\">[</span>-i INP<span class=\"o\">]</span> <span class=\"o\">[</span>-o OUT<span class=\"o\">]</span> -m MODEL <span class=\"o\">[</span>-idx<span class=\"o\">]</span> <span class=\"o\">[</span>-vs VOCAB_SIZE<span class=\"o\">]</span>\n                   <span class=\"o\">[</span>-l <span class=\"o\">{</span>char,word,bpe<span class=\"o\">}]</span> <span class=\"o\">[</span>-mf MIN_FREQ<span class=\"o\">]</span>\n                   <span class=\"o\">{</span>learn,encode,decode,estimate<span class=\"o\">}</span>\n\npositional arguments:\n  <span class=\"o\">{</span>learn,encode,decode,estimate<span class=\"o\">}</span>\n                        <span class=\"s2\">\"task\"</span> or sub-command.\n                            <span class=\"s2\">\"learn\"</span> - learns vocabulary. use --level and vocab_size <span class=\"k\">for</span> <span class=\"nb\">type</span> and size \n                            <span class=\"s2\">\"encode\"</span> - encodes a dataset \n                            <span class=\"s2\">\"decode\"</span> - decodes an already encoded dataset\n                            <span class=\"s2\">\"estimate\"</span> - estimates quality attributes of an encoding\n\noptional arguments:\n  -h, --help            show this <span class=\"nb\">help</span> message and <span class=\"nb\">exit</span>\n  -i INP, --inp INP     Input file path <span class=\"o\">(</span>default: &lt;_io.TextIOWrapper\n                        <span class=\"nv\">name</span><span class=\"o\">=</span><span class=\"s1\">'&lt;stdin&gt;'</span> <span class=\"nv\">mode</span><span class=\"o\">=</span><span class=\"s1\">'r'</span> <span class=\"nv\">encoding</span><span class=\"o\">=</span><span class=\"s1\">'UTF-8'</span>&gt;<span class=\"o\">)</span>\n  -o OUT, --out OUT     Output file path. Not valid <span class=\"k\">for</span> <span class=\"s2\">\"learn\"</span> or <span class=\"s2\">\"estimate\"</span>\n                        task <span class=\"o\">(</span>default: &lt;_io.TextIOWrapper <span class=\"nv\">name</span><span class=\"o\">=</span><span class=\"s1\">'&lt;stdout&gt;'</span>\n                        <span class=\"nv\">mode</span><span class=\"o\">=</span><span class=\"s1\">'w'</span> <span class=\"nv\">encoding</span><span class=\"o\">=</span><span class=\"s1\">'UTF-8'</span>&gt;<span class=\"o\">)</span>\n  -m MODEL, --model MODEL\n                        Path to model aka vocabulary file <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n  -idx, --indices       Indices instead of strings. Valid <span class=\"k\">for</span> <span class=\"nv\">task</span><span class=\"o\">=</span>encode and\n                        <span class=\"nv\">task</span><span class=\"o\">=</span>decode <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n\nargs <span class=\"k\">for</span> <span class=\"nv\">task</span><span class=\"o\">=</span>learn:\n  -vs VOCAB_SIZE, --vocab_size VOCAB_SIZE\n                        Vocabulary size. Valid only <span class=\"k\">for</span> <span class=\"nv\">task</span><span class=\"o\">=</span>learn. This is\n                        required <span class=\"k\">for</span> <span class=\"s2\">\"bpe\"</span>, but optional <span class=\"k\">for</span> <span class=\"s2\">\"word\"</span> and <span class=\"s2\">\"char\"</span>\n                        models, specifying it will trim the vocabulary at\n                        given top most frequent types. <span class=\"o\">(</span>default: -1<span class=\"o\">)</span>\n  -l <span class=\"o\">{</span>char,word,bpe<span class=\"o\">}</span>, --level <span class=\"o\">{</span>char,word,bpe<span class=\"o\">}</span>\n                        Encoding Level<span class=\"p\">;</span> Valid only <span class=\"k\">for</span> <span class=\"nv\">task</span><span class=\"o\">=</span>learn <span class=\"o\">(</span>default:\n                        None<span class=\"o\">)</span>\n  -mf MIN_FREQ, --min_freq MIN_FREQ\n                        Minimum frequency of types <span class=\"k\">for</span> considering inclusion\n                        in vocabulary. Types fewer than this frequency will be\n                        ignored. For --level<span class=\"o\">=</span>word, freq is <span class=\"nb\">type</span> freq and\n                        default is <span class=\"m\">2</span>.for --level<span class=\"o\">=</span>char or --level<span class=\"o\">=</span>bpe,\n                        characters fewer than this value will be excluded.\n                        <span class=\"nv\">default</span><span class=\"o\">=</span><span class=\"m\">20</span> <span class=\"o\">(</span>default: None<span class=\"o\">)</span>\n</pre>\n<p>Example:</p>\n<pre><code># learn\nhead -2000 somefile.tok | nlcodec learn -l bpe -m bpe.model --vocab_size 2000\n\n# encode  with text pieces\nhead  somefile.tok  | nlcodec encode -m bpe.model\n\n# encode with indexes\nhead  somefile.tok  | nlcodec encode -m bpe.model -idx\n\n# decode -- undo encoding\nhead  somefile.tok  | nlcodec decode -m bpe.model\nhead  somefile.tok  | nlcodec decode -m bpe.model -idx\n\n# estimate quality \nhead  somefile.tok  | nlcodec estimate -m bpe.model\n\n</code></pre>\n<h2>Python API</h2>\n<h3>Using a vocabulary</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlcodec</span> <span class=\"kn\">import</span>  <span class=\"n\">load_scheme</span>\n<span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"s1\">'path/to/vocab.model'</span>\n<span class=\"n\">vocab</span> <span class=\"o\">=</span> <span class=\"n\">load_scheme</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span>\n\n<span class=\"n\">line</span> <span class=\"o\">=</span> <span class=\"s1\">'this is a sample sentence'</span>\n<span class=\"c1\"># encode a line of text into list of ids</span>\n<span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># parallel encode a bunch of lines using multiple cpus</span>\n<span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">encode_parallel</span><span class=\"p\">(</span><span class=\"n\">seqs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">line</span><span class=\"p\">],</span> <span class=\"n\">n_cpus</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># encode a line of text into pieces </span>\n<span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">encode_str</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># decode</span>\n<span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">))</span>\n<span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">decode_str</span><span class=\"p\">(</span><span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">encode_str</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">))</span>\n</pre>\n<h3>Creating a vocabulary</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlcodec</span> <span class=\"kn\">import</span> <span class=\"n\">learn_vocab</span>\n<span class=\"n\">inp</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'line 1'</span><span class=\"p\">,</span> <span class=\"s1\">'line 2'</span><span class=\"p\">]</span>\n<span class=\"n\">level</span> <span class=\"o\">=</span> <span class=\"s1\">'bpe'</span> <span class=\"c1\"># other options = char, word</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"s1\">'path/to/vocab.model'</span>\n<span class=\"n\">learn_vocab</span><span class=\"p\">(</span><span class=\"n\">inp</span><span class=\"p\">,</span> <span class=\"n\">level</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"o\">=</span><span class=\"mi\">8000</span><span class=\"p\">,</span> <span class=\"n\">min_freq</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">char_coverage</span><span class=\"o\">=</span><span class=\"mf\">0.9995</span><span class=\"p\">)</span>\n</pre>\n<h3>BPE Subword sub optimal splits for regularization</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nlcodec</span> <span class=\"kn\">import</span> <span class=\"n\">load_scheme</span><span class=\"p\">,</span> <span class=\"n\">BPEScheme</span>\n<span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"s1\">'path/to/bpe-vocab.model'</span>\n<span class=\"n\">bpe</span><span class=\"p\">:</span> <span class=\"n\">BPEScheme</span> <span class=\"o\">=</span> <span class=\"n\">load_scheme</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span>\n<span class=\"n\">some_type</span> <span class=\"o\">=</span> <span class=\"n\">bpe</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">[</span><span class=\"mi\">1000</span><span class=\"p\">]</span> <span class=\"c1\"># select some bpe piece type</span>\n\n<span class=\"c1\"># get stochastic split</span>\n<span class=\"n\">some_type</span><span class=\"o\">.</span><span class=\"n\">get_stochastic_split</span><span class=\"p\">(</span><span class=\"n\">split_ratio</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"c1\"># get all possible permutations </span>\n<span class=\"n\">some_type</span><span class=\"o\">.</span><span class=\"n\">get_permutations</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<h1>Authors</h1>\n<ul>\n<li><a href=\"https://twitter.com/thammegowda\" rel=\"nofollow\">Thamme Gowda</a></li>\n</ul>\n\n          </div>"}, "last_serial": 7038219, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "759fdfbb68a554aee2e63b1ba09d60d0", "sha256": "8b7e42fa0980da324d63f2699808a5ed2ad9bda139f80e2e264df5b2cd42bc20"}, "downloads": -1, "filename": "nlcodec-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "759fdfbb68a554aee2e63b1ba09d60d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 25912, "upload_time": "2020-04-17T07:30:06", "upload_time_iso_8601": "2020-04-17T07:30:06.470539Z", "url": "https://files.pythonhosted.org/packages/87/96/24a57da91a3e5fd5a9f878a877acf01004d6bea431a32f5f76ed5f9aa144/nlcodec-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "97415757dd63f22b945d43f1ec269d28", "sha256": "52e99b817a449ce1b42b7a7b4b502873a7af2e6a1987a0d32c0ef71098b8db38"}, "downloads": -1, "filename": "nlcodec-0.2.0.tar.gz", "has_sig": false, "md5_digest": "97415757dd63f22b945d43f1ec269d28", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 20695, "upload_time": "2020-04-17T07:30:09", "upload_time_iso_8601": "2020-04-17T07:30:09.035508Z", "url": "https://files.pythonhosted.org/packages/8c/fd/cb5dab68dacf599668a852df986942b3d970cf676c879d44e0aae6f08866/nlcodec-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "759fdfbb68a554aee2e63b1ba09d60d0", "sha256": "8b7e42fa0980da324d63f2699808a5ed2ad9bda139f80e2e264df5b2cd42bc20"}, "downloads": -1, "filename": "nlcodec-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "759fdfbb68a554aee2e63b1ba09d60d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 25912, "upload_time": "2020-04-17T07:30:06", "upload_time_iso_8601": "2020-04-17T07:30:06.470539Z", "url": "https://files.pythonhosted.org/packages/87/96/24a57da91a3e5fd5a9f878a877acf01004d6bea431a32f5f76ed5f9aa144/nlcodec-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "97415757dd63f22b945d43f1ec269d28", "sha256": "52e99b817a449ce1b42b7a7b4b502873a7af2e6a1987a0d32c0ef71098b8db38"}, "downloads": -1, "filename": "nlcodec-0.2.0.tar.gz", "has_sig": false, "md5_digest": "97415757dd63f22b945d43f1ec269d28", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 20695, "upload_time": "2020-04-17T07:30:09", "upload_time_iso_8601": "2020-04-17T07:30:09.035508Z", "url": "https://files.pythonhosted.org/packages/8c/fd/cb5dab68dacf599668a852df986942b3d970cf676c879d44e0aae6f08866/nlcodec-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:13 2020"}