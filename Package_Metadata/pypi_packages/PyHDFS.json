{"info": {"author": "Jing Wang", "author_email": "99jingw@gmail.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3 :: Only", "Topic :: System :: Filesystems"], "description": "==================\nPython HDFS client\n==================\n\nBecause the world needs `yet <https://github.com/spotify/snakebite>`_ `another <https://github.com/ProjectMeniscus/pywebhdfs>`_ `way <https://pypi.python.org/pypi/hdfs>`_ to talk to HDFS from Python.\n\nUsage\n=====\n\nThis library provides a Python client for `WebHDFS <https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html>`_.\nNameNode HA is supported by passing in both NameNodes.\nResponses are returned as nice Python classes, and any failed operation will raise some subclass of ``HdfsException`` matching the Java exception.\n\nExample usage:\n\n.. code-block:: python\n\n    >>> fs = pyhdfs.HdfsClient(hosts='nn1.example.com:50070,nn2.example.com:50070', user_name='someone')\n    >>> fs.list_status('/')\n    [FileStatus(pathSuffix='benchmarks', permission='777', type='DIRECTORY', ...), FileStatus(...), ...]\n    >>> fs.listdir('/')\n    ['benchmarks', 'hbase', 'solr', 'tmp', 'user', 'var']\n    >>> fs.mkdirs('/fruit/x/y')\n    True\n    >>> fs.create('/fruit/apple', 'delicious')\n    >>> fs.append('/fruit/apple', ' food')\n    >>> with contextlib.closing(fs.open('/fruit/apple')) as f:\n    ...     f.read()\n    ...\n    b'delicious food'\n    >>> fs.get_file_status('/fruit/apple')\n    FileStatus(length=14, owner='someone', type='FILE', ...)\n    >>> fs.get_file_status('/fruit/apple').owner\n    'someone'\n    >>> fs.get_content_summary('/fruit')\n    ContentSummary(directoryCount=3, fileCount=1, length=14, quota=-1, spaceConsumed=14, spaceQuota=-1)\n    >>> list(fs.walk('/fruit'))\n    [('/fruit', ['x'], ['apple']), ('/fruit/x', ['y'], []), ('/fruit/x/y', [], [])]\n    >>> fs.exists('/fruit/apple')\n    True\n    >>> fs.delete('/fruit')\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n      File \".../pyhdfs.py\", line 525, in delete\n      ...\n    pyhdfs.HdfsPathIsNotEmptyDirectoryException: `/fruit is non empty': Directory is not empty\n    >>> fs.delete('/fruit', recursive=True)\n    True\n    >>> fs.exists('/fruit/apple')\n    False\n    >>> issubclass(pyhdfs.HdfsFileNotFoundException, pyhdfs.HdfsIOException)\n    True\n\n\nYou can also pass the hostname as part of the URI:\n\n.. code-block:: python\n\n    fs.list_status('//nn1.example.com:50070;nn2.example.com:50070/')\n\nThe methods and return values generally map directly to `WebHDFS endpoints <https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html>`_.\nThe client also provides convenience methods that mimic Python ``os`` methods and HDFS CLI commands (e.g. ``walk`` and ``copy_to_local``).\n\n``pyhdfs`` logs all HDFS actions at the INFO level, so turning on INFO level logging will give you a debug record for your application.\n\nFor more information, see the `full API docs <http://pyhdfs.readthedocs.io/en/latest/>`_.\n\nInstalling\n==========\n\n``pip install pyhdfs``\n\nPython 3 is required.\n\nDevelopment testing\n===================\n\n.. image:: https://travis-ci.org/jingw/pyhdfs.svg?branch=master\n    :target: https://travis-ci.org/jingw/pyhdfs\n\n.. image:: http://codecov.io/github/jingw/pyhdfs/coverage.svg?branch=master\n    :target: http://codecov.io/github/jingw/pyhdfs?branch=master\n\nFirst run ``install-hdfs.sh x.y.z``, which will download, extract, and run the HDFS NN/DN processes in the current directory.\n(Replace ``x.y.z`` with a real version.)\nThen run the following commands.\nNote they will create and delete ``hdfs://localhost/tmp/pyhdfs_test``.\n\nCommands::\n\n    python3 -m venv env\n    source env/bin/activate\n    pip install -e .\n    pip install -r dev_requirements.txt\n    pytest", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/jingw/pyhdfs", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "PyHDFS", "package_url": "https://pypi.org/project/PyHDFS/", "platform": "", "project_url": "https://pypi.org/project/PyHDFS/", "project_urls": {"Homepage": "https://github.com/jingw/pyhdfs"}, "release_url": "https://pypi.org/project/PyHDFS/0.3.1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Pure Python HDFS client", "version": "0.3.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Because the world needs <a href=\"https://github.com/spotify/snakebite\" rel=\"nofollow\">yet</a> <a href=\"https://github.com/ProjectMeniscus/pywebhdfs\" rel=\"nofollow\">another</a> <a href=\"https://pypi.python.org/pypi/hdfs\" rel=\"nofollow\">way</a> to talk to HDFS from Python.</p>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>This library provides a Python client for <a href=\"https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html\" rel=\"nofollow\">WebHDFS</a>.\nNameNode HA is supported by passing in both NameNodes.\nResponses are returned as nice Python classes, and any failed operation will raise some subclass of <tt>HdfsException</tt> matching the Java exception.</p>\n<p>Example usage:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span> <span class=\"o\">=</span> <span class=\"n\">pyhdfs</span><span class=\"o\">.</span><span class=\"n\">HdfsClient</span><span class=\"p\">(</span><span class=\"n\">hosts</span><span class=\"o\">=</span><span class=\"s1\">'nn1.example.com:50070,nn2.example.com:50070'</span><span class=\"p\">,</span> <span class=\"n\">user_name</span><span class=\"o\">=</span><span class=\"s1\">'someone'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">list_status</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">FileStatus</span><span class=\"p\">(</span><span class=\"n\">pathSuffix</span><span class=\"o\">=</span><span class=\"s1\">'benchmarks'</span><span class=\"p\">,</span> <span class=\"n\">permission</span><span class=\"o\">=</span><span class=\"s1\">'777'</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s1\">'DIRECTORY'</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">),</span> <span class=\"n\">FileStatus</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">),</span> <span class=\"o\">...</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">listdir</span><span class=\"p\">(</span><span class=\"s1\">'/'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s1\">'benchmarks'</span><span class=\"p\">,</span> <span class=\"s1\">'hbase'</span><span class=\"p\">,</span> <span class=\"s1\">'solr'</span><span class=\"p\">,</span> <span class=\"s1\">'tmp'</span><span class=\"p\">,</span> <span class=\"s1\">'user'</span><span class=\"p\">,</span> <span class=\"s1\">'var'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">mkdirs</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/x/y'</span><span class=\"p\">)</span>\n<span class=\"kc\">True</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">,</span> <span class=\"s1\">'delicious'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">,</span> <span class=\"s1\">' food'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">contextlib</span><span class=\"o\">.</span><span class=\"n\">closing</span><span class=\"p\">(</span><span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">))</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>     <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n<span class=\"o\">...</span>\n<span class=\"sa\">b</span><span class=\"s1\">'delicious food'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get_file_status</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">)</span>\n<span class=\"n\">FileStatus</span><span class=\"p\">(</span><span class=\"n\">length</span><span class=\"o\">=</span><span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"n\">owner</span><span class=\"o\">=</span><span class=\"s1\">'someone'</span><span class=\"p\">,</span> <span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"s1\">'FILE'</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get_file_status</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">owner</span>\n<span class=\"s1\">'someone'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">get_content_summary</span><span class=\"p\">(</span><span class=\"s1\">'/fruit'</span><span class=\"p\">)</span>\n<span class=\"n\">ContentSummary</span><span class=\"p\">(</span><span class=\"n\">directoryCount</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">fileCount</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">length</span><span class=\"o\">=</span><span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"n\">quota</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">spaceConsumed</span><span class=\"o\">=</span><span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"n\">spaceQuota</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">walk</span><span class=\"p\">(</span><span class=\"s1\">'/fruit'</span><span class=\"p\">))</span>\n<span class=\"p\">[(</span><span class=\"s1\">'/fruit'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'x'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'apple'</span><span class=\"p\">]),</span> <span class=\"p\">(</span><span class=\"s1\">'/fruit/x'</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s1\">'y'</span><span class=\"p\">],</span> <span class=\"p\">[]),</span> <span class=\"p\">(</span><span class=\"s1\">'/fruit/x/y'</span><span class=\"p\">,</span> <span class=\"p\">[],</span> <span class=\"p\">[])]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">)</span>\n<span class=\"kc\">True</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"s1\">'/fruit'</span><span class=\"p\">)</span>\n<span class=\"n\">Traceback</span> <span class=\"p\">(</span><span class=\"n\">most</span> <span class=\"n\">recent</span> <span class=\"n\">call</span> <span class=\"n\">last</span><span class=\"p\">):</span>\n  <span class=\"n\">File</span> <span class=\"s2\">\"&lt;stdin&gt;\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"o\">&lt;</span><span class=\"n\">module</span><span class=\"o\">&gt;</span>\n  <span class=\"n\">File</span> <span class=\"s2\">\".../pyhdfs.py\"</span><span class=\"p\">,</span> <span class=\"n\">line</span> <span class=\"mi\">525</span><span class=\"p\">,</span> <span class=\"ow\">in</span> <span class=\"n\">delete</span>\n  <span class=\"o\">...</span>\n<span class=\"n\">pyhdfs</span><span class=\"o\">.</span><span class=\"n\">HdfsPathIsNotEmptyDirectoryException</span><span class=\"p\">:</span> <span class=\"err\">`</span><span class=\"o\">/</span><span class=\"n\">fruit</span> <span class=\"ow\">is</span> <span class=\"n\">non</span> <span class=\"n\">empty</span><span class=\"s1\">': Directory is not empty</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">(</span><span class=\"s1\">'/fruit'</span><span class=\"p\">,</span> <span class=\"n\">recursive</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"kc\">True</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">exists</span><span class=\"p\">(</span><span class=\"s1\">'/fruit/apple'</span><span class=\"p\">)</span>\n<span class=\"kc\">False</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">issubclass</span><span class=\"p\">(</span><span class=\"n\">pyhdfs</span><span class=\"o\">.</span><span class=\"n\">HdfsFileNotFoundException</span><span class=\"p\">,</span> <span class=\"n\">pyhdfs</span><span class=\"o\">.</span><span class=\"n\">HdfsIOException</span><span class=\"p\">)</span>\n<span class=\"kc\">True</span>\n</pre>\n<p>You can also pass the hostname as part of the URI:</p>\n<pre><span class=\"n\">fs</span><span class=\"o\">.</span><span class=\"n\">list_status</span><span class=\"p\">(</span><span class=\"s1\">'//nn1.example.com:50070;nn2.example.com:50070/'</span><span class=\"p\">)</span>\n</pre>\n<p>The methods and return values generally map directly to <a href=\"https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html\" rel=\"nofollow\">WebHDFS endpoints</a>.\nThe client also provides convenience methods that mimic Python <tt>os</tt> methods and HDFS CLI commands (e.g. <tt>walk</tt> and <tt>copy_to_local</tt>).</p>\n<p><tt>pyhdfs</tt> logs all HDFS actions at the INFO level, so turning on INFO level logging will give you a debug record for your application.</p>\n<p>For more information, see the <a href=\"http://pyhdfs.readthedocs.io/en/latest/\" rel=\"nofollow\">full API docs</a>.</p>\n</div>\n<div id=\"installing\">\n<h2>Installing</h2>\n<p><tt>pip install pyhdfs</tt></p>\n<p>Python 3 is required.</p>\n</div>\n<div id=\"development-testing\">\n<h2>Development testing</h2>\n<a href=\"https://travis-ci.org/jingw/pyhdfs\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/jingw/pyhdfs.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/440376964ce18c4f2b1efcee56ad8c40091c221d/68747470733a2f2f7472617669732d63692e6f72672f6a696e67772f7079686466732e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"http://codecov.io/github/jingw/pyhdfs?branch=master\" rel=\"nofollow\"><img alt=\"http://codecov.io/github/jingw/pyhdfs/coverage.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e3b96283582726e0c8f68116583828dbad7c9051/687474703a2f2f636f6465636f762e696f2f6769746875622f6a696e67772f7079686466732f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a>\n<p>First run <tt><span class=\"pre\">install-hdfs.sh</span> x.y.z</tt>, which will download, extract, and run the HDFS NN/DN processes in the current directory.\n(Replace <tt>x.y.z</tt> with a real version.)\nThen run the following commands.\nNote they will create and delete <tt><span class=\"pre\">hdfs://localhost/tmp/pyhdfs_test</span></tt>.</p>\n<p>Commands:</p>\n<pre>python3 -m venv env\nsource env/bin/activate\npip install -e .\npip install -r dev_requirements.txt\npytest\n</pre>\n</div>\n\n          </div>"}, "last_serial": 6396569, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ad809e6f7e91d3750a369fd9fe32d354", "sha256": "7442809e1f3288516b6e759ea52f3acf5797ba75b14f339e8bb87902dfe5d2a0"}, "downloads": -1, "filename": "PyHDFS-0.1.0.tar.gz", "has_sig": true, "md5_digest": "ad809e6f7e91d3750a369fd9fe32d354", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9739, "upload_time": "2015-03-05T05:48:01", "upload_time_iso_8601": "2015-03-05T05:48:01.540108Z", "url": "https://files.pythonhosted.org/packages/3c/f5/756a76ba9706ad22b547949dfc4f613fcdcbccb4d2771df10333c3af3169/PyHDFS-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "94632312ac489ef8aa8d28f935fb587e", "sha256": "c1e435b64dd4e046a984a9408f7ebb1f4499182c9bb063aa76b1d73c818fbb0e"}, "downloads": -1, "filename": "PyHDFS-0.1.1.tar.gz", "has_sig": true, "md5_digest": "94632312ac489ef8aa8d28f935fb587e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10818, "upload_time": "2015-03-22T23:50:26", "upload_time_iso_8601": "2015-03-22T23:50:26.808486Z", "url": "https://files.pythonhosted.org/packages/63/d7/ee567570af5e98a6dae8328c2779bbeda3a2972babe2310effad98a004e2/PyHDFS-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "07da54b5c45a33c20080e263cac329e4", "sha256": "cddc4c6b754ca070cbaf6b9a9055945b277c596d644f238c4d0a75d03cc587e1"}, "downloads": -1, "filename": "PyHDFS-0.1.2.tar.gz", "has_sig": true, "md5_digest": "07da54b5c45a33c20080e263cac329e4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11077, "upload_time": "2016-10-29T04:24:43", "upload_time_iso_8601": "2016-10-29T04:24:43.432690Z", "url": "https://files.pythonhosted.org/packages/02/f4/df64ed9a1a1f6d2a788e172adef6613ded9fecd4d1ee93835f1d0cc4cf82/PyHDFS-0.1.2.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "9157f1faf88bef491718c20d606e34d4", "sha256": "1e002580b640f0da3b021075dfa646244cd7e1a1d36d02fc99421e3901d326e8"}, "downloads": -1, "filename": "PyHDFS-0.2.1.tar.gz", "has_sig": true, "md5_digest": "9157f1faf88bef491718c20d606e34d4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13580, "upload_time": "2017-09-23T03:56:37", "upload_time_iso_8601": "2017-09-23T03:56:37.732453Z", "url": "https://files.pythonhosted.org/packages/16/9f/a358e199f2d99229ff470e0063e26111fd0121ef034b853d9b9c0fd26b72/PyHDFS-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "4986ce055ad5b698b43cbb27b79f0c9e", "sha256": "d5c5676ce5c00dc99dd1522fbe1f1a6e3e318f34972f6443cd82f8a85294f230"}, "downloads": -1, "filename": "PyHDFS-0.2.2.tar.gz", "has_sig": false, "md5_digest": "4986ce055ad5b698b43cbb27b79f0c9e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11951, "upload_time": "2019-06-15T03:16:15", "upload_time_iso_8601": "2019-06-15T03:16:15.836020Z", "url": "https://files.pythonhosted.org/packages/1b/c4/707adc71153c245b25b9010b3ed002364199291c98f518dc559ded6ae6e8/PyHDFS-0.2.2.tar.gz", "yanked": false}], "0.3.0": [], "0.3.1": [{"comment_text": "", "digests": {"md5": "d00bcc15060afa416a20262444f2f4ef", "sha256": "63b4d0e3929f9ef9897603c66e1336c7d3d3dc51204ed76cd2f3d4a83719f50a"}, "downloads": -1, "filename": "PyHDFS-0.3.1.tar.gz", "has_sig": false, "md5_digest": "d00bcc15060afa416a20262444f2f4ef", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 12961, "upload_time": "2020-01-05T03:14:53", "upload_time_iso_8601": "2020-01-05T03:14:53.290790Z", "url": "https://files.pythonhosted.org/packages/91/a9/e9bf3dc7c1f673765e6ba9acf7d049a7b90cd734d85dfa832cf704a1eb59/PyHDFS-0.3.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d00bcc15060afa416a20262444f2f4ef", "sha256": "63b4d0e3929f9ef9897603c66e1336c7d3d3dc51204ed76cd2f3d4a83719f50a"}, "downloads": -1, "filename": "PyHDFS-0.3.1.tar.gz", "has_sig": false, "md5_digest": "d00bcc15060afa416a20262444f2f4ef", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 12961, "upload_time": "2020-01-05T03:14:53", "upload_time_iso_8601": "2020-01-05T03:14:53.290790Z", "url": "https://files.pythonhosted.org/packages/91/a9/e9bf3dc7c1f673765e6ba9acf7d049a7b90cd734d85dfa832cf704a1eb59/PyHDFS-0.3.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:04:28 2020"}