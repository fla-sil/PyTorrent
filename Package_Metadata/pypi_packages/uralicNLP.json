{"info": {"author": "Mika H\u00e4m\u00e4l\u00e4inen, Dept. of  Digital Humanities, University of Helsinki", "author_email": "mika.hamalainen@helsinki.fi", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "Programming Language :: Python :: 3", "Topic :: Text Processing :: Linguistic"], "description": "# UralicNLP\n\n[![Build Status](https://travis-ci.com/mikahama/uralicNLP.svg?branch=master)](https://travis-ci.com/mikahama/uralicNLP) [![Updates](https://pyup.io/repos/github/mikahama/uralicNLP/shield.svg)](https://pyup.io/repos/github/mikahama/uralicNLP/) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1143638.svg)](https://doi.org/10.5281/zenodo.1143638)\n\nUralicNLP is a natural language processing library targeted mainly for Uralic languages.\n\nUralicNLP can produce **morphological analysis**, **generate morphological forms**, **lemmatize words** and **give lexical information** about words in Uralic and other languages. At the time of writing, at least the following languages are supported: Finnish, Russian, German, English, Norwegian, Swedish, Arabic, Ingrian, Meadow & Eastern Mari, Votic, Olonets-Karelian, Erzya, Moksha, Hill Mari, Udmurt, Tundra Nenets, Komi-Permyak, North Sami, South Sami and Skolt Sami. This information originates mainly from FST tools and dictionaries developed in the [GiellaLT infrastructure](https://giellalt.uit.no/). Currently, UralicNLP uses the nightly builds for most of the supported languages.\n\n[See the catalog of supported languages](https://uralic.mikakalevi.com/nightly)\n\n## Installation\nThe library can be installed from [PyPi](https://pypi.python.org/pypi/uralicNLP/).\n\n    pip install uralicNLP\n\nIn case you want to use the Constraint Grammar features (*from uralicNLP.cg3 import Cg3*), you will also need to [install VISL CG-3](https://mikalikes.men/how-to-install-visl-cg3-on-mac-windows-and-linux/).\n\nIf you are using Linux and you run into problems with installing HFST, you can find some help on [a blog post on installing hfst](https://mikalikes.men/using-hfst-on-python/)\n\nOn Windows, HFST depends on [32 bit Microsoft Visual C++ Redistributable 2017](https://go.microsoft.com/fwlink/?LinkId=746571). Although, I would recommend using [Windows subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\n\nArabic and English FSTs require [Foma](https://fomafst.github.io/).\n\n## Usage\n\n### List supported languages\nThe API is under constant development and new languages will be added to the Sanat infrastructure. That's why UralicNLP provides a functionality for looking up the list of currently supported languages. The method returns 3 letter ISO codes for the languages.\n\n    from uralicNLP import uralicApi\n    uralicApi.supported_languages()\n    >>{'cg': ['vot', 'lav', 'izh', 'rus', 'lut', 'fao', 'est', 'nob', 'ron', 'olo', 'bxr', 'hun', 'crk', 'chr', 'vep', 'deu', 'mrj', 'gle', 'sjd', 'nio', 'myv', 'som', 'sma', 'sms', 'smn', 'kal', 'bak', 'kca', 'otw', 'ciw', 'fkv', 'nds', 'kpv', 'sme', 'sje', 'evn', 'oji', 'ipk', 'fit', 'fin', 'mns', 'rmf', 'liv', 'cor', 'mdf', 'yrk', 'tat', 'smj'], 'dictionary': ['vot', 'lav', 'rus', 'est', 'nob', 'ron', 'olo', 'hun', 'koi', 'chr', 'deu', 'mrj', 'sjd', 'myv', 'som', 'sma', 'sms', 'smn', 'kal', 'fkv', 'mhr', 'kpv', 'sme', 'sje', 'hdn', 'fin', 'mns', 'mdf', 'vro', 'udm', 'smj'], 'morph': ['vot', 'lav', 'izh', 'rus', 'lut', 'fao', 'est', 'nob', 'swe', 'ron', 'eng', 'olo', 'bxr', 'hun', 'koi', 'crk', 'chr', 'vep', 'deu', 'mrj', 'ara', 'gle', 'sjd', 'nio', 'myv', 'som', 'sma', 'sms', 'smn', 'kal', 'bak', 'kca', 'otw', 'ciw', 'fkv', 'nds', 'mhr', 'kpv', 'sme', 'sje', 'evn', 'oji', 'ipk', 'fit', 'fin', 'mns', 'rmf', 'liv', 'cor', 'mdf', 'yrk', 'vro', 'udm', 'tat', 'smj']}\n\nThe *dictionary* key lists the languages that are supported by the lexical lookup, whereas *morph* lists the languages that have morphological FSTs and *cg* lists the languages that have a CG.\n\n### Download models \n\nIf you have a lot of data to process, it might be a good idea to download the morphological models to your computer locally. This can be done easily. Although, it is possible to use the transducers over Akusanat API by passing *force_local=False*.\n\nOn command line:\n\n    python -m uralicNLP.download --languages fin eng\n\nFrom python code:\n\n    from uralicNLP import uralicApi\n    uralicApi.download(\"fin\")\n\nWhen models are installed, *generate()*, *analyze()* and *lemmatize()* methods will automatically use them instead of the server side API. [More information about the models](https://github.com/mikahama/uralicNLP/wiki/Models).\n\nUse **uralicApi.model_info(language)** to see information about the FSTs and CGs such as license and authors. If you know how to make this information more accurate, please don't hesitate to open an issue on GitHub.\n\n    from uralicNLP import uralicApi\n    uralicApi.model_info(\"fin\")\n\nTo remove the models of a language, run\n\n    from uralicNLP import uralicApi\n    uralicApi.uninstall(\"fin\")\n\n### Lemmatize words\nA word form can be lemmatized with UralicNLP. This does not do any disambiguation but rather returns a list of all the possible lemmas.\n\n    from uralicNLP import uralicApi\n    uralicApi.lemmatize(\"\u0432\u0438\u0440\u0435\u0432\", \"myv\")\n    >>['\u0432\u0438\u0440\u0435\u0432', '\u0432\u0438\u0440\u044c']\n    uralicApi.lemmatize(\"luutapiiri\", \"fin\", word_boundaries=True)\n    >>['luuta|piiri', 'luu|tapiiri']\n\nAn example of lemmatizing the word *\u0432\u0438\u0440\u0435\u0432* in Erzya (myv). By default, a **descriptive** analyzer is used. Use *uralicApi.lemmatize(\"\u0432\u0438\u0440\u0435\u0432\", \"myv\", descrpitive=False)* for a non-descriptive analyzer. If *word_boundaries* is set to True, the lemmatizer will mark word boundaries with a |.\n\n### Morphological analysis\nApart from just getting the lemmas, it's also possible to perform a complete morphological analysis.\n\n    from uralicNLP import uralicApi\n    uralicApi.analyze(\"voita\", \"fin\")\n    >>[['voi+N+Sg+Par', 0.0], ['voi+N+Pl+Par', 0.0], ['voitaa+V+Act+Imprt+Prs+ConNeg+Sg2', 0.0], ['voitaa+V+Act+Imprt+Sg2', 0.0], ['voitaa+V+Act+Ind+Prs+ConNeg', 0.0], ['voittaa+V+Act+Imprt+Prs+ConNeg+Sg2', 0.0], ['voittaa+V+Act+Imprt+Sg2', 0.0], ['voittaa+V+Act+Ind+Prs+ConNeg', 0.0], ['vuo+N+Pl+Par', 0.0]]\n\nAn example of analyzing the word *voita* in Finnish (fin). The default analyzer is **descriptive**. To use a normative analyzer instead, use *uralicApi.analyze(\"voita\", \"fin\", descrpitive=False)*\n\n### Morphological generation\nFrom a lemma and a morphological analysis, it's possible to generate the desired word form. \n\n    from uralicNLP import uralicApi\n    uralicApi.generate(\"k\u00e4si+N+Sg+Par\", \"fin\")\n    >>[['k\u00e4tt\u00e4', 0.0]]\n\nAn example of generating the singular partitive form for the Finnish noun *k\u00e4si*. The result is *k\u00e4tt\u00e4*. The default generator is a **regular normative** generator. *uralicApi.generate(\"k\u00e4si+N+Sg+Par\", \"fin\", dictionary_forms=True)* uses a normative dictionary generator and *uralicApi.generate(\"k\u00e4si+N+Sg+Par\", \"fin\", descrpitive=True)* a descriptive generator.\n\n\n### Access the HFST transducer\n\nIf you need to get a lower level access to [the HFST transducer object](https://hfst.github.io/python/3.12.1/classhfst_1_1HfstTransducer.html), you can use the following code\n\n    from uralicNLP import uralicApi\n    sms_generator = uralicApi.get_transducer(\"sms\", analyzer=False) #generator\n    sms_analyzer = uralicApi.get_transducer(\"sms\", analyzer=True) #analyzer\n\nThe same parameters can be used here as for *generate()* and *analyze()* to specify whether you want to use the normative or descriptive analyzers and so on. The defaults are *get_transducer(language, cache=True, analyzer=True, descrpitive=True, dictionary_forms=True)*.\n\n### Syntax - Constraint Grammar disambiguation\n\n**Note** this requires the models to be installed (see above) and [VISL CG-3](https://mikalikes.men/how-to-install-visl-cg3-on-mac-windows-and-linux/). The disambiguation process is easy.\n\n    from uralicNLP.cg3 import Cg3\n    sentence = \"Kissa voi nauraa\"\n    tokens = sentence.split(\" \") #Do a simple tokenization for the sentence\n    cg = Cg3(\"fin\")\n    print cg.disambiguate(tokens)\n    >>[(u'Kissa', [<Kissa - N, Prop, Sg, Nom, <W:0.000000>>, <kissa - N, Sg, Nom, <W:0.000000>>]), (u'voi', [<voida - V, Act, Ind, Prs, Sg3, <W:0.000000>>]), (u'nauraa', [<nauraa - V, Act, InfA, Sg, Lat, <W:0.000000>>])]\n\nThe return object is a list of tuples. The first item in each tuple is the word form used in the sentence, the second item is a list of *Cg3Word* objects. In the case of a full disambiguation, these lists have only one Cg3Word object, but some times the result of the disambiguation still has some ambiguity. Each Cg3Word object has three variables *lemma*, *form* and *morphology*.\n\n    disambiguations = cg.disambiguate(tokens)\n    for disambiguation in disambiguations:\n        possible_words = disambiguation[1]\n        for possible_word in possible_words:\n            print possible_word.lemma, possible_word.morphology\n    >>Kissa [u'N', u'Prop', u'Sg', u'Nom', u'<W:0.000000>']\n    >>kissa [u'N', u'Sg', u'Nom', u'<W:0.000000>']\n    >>voida [u'V', u'Act', u'Ind', u'Prs', u'Sg3', u'<W:0.000000>']\n    >>nauraa [u'V', u'Act', u'InfA', u'Sg', u'Lat', u'<W:0.000000>']\n\nThe *cg.disambiguate* takes in *remove_symbols* as an optional argument. Its default value is *True* which means that it removes the symbols (segments surrounded by @) from the FST output before feeding it to the CG disambiguator. If the value is set to *False*, the FST morphology is fed in to the CG unmodified.\n\nThe **default FST analyzer is a descriptive one**, to use a normative analyzer, set the *descriptive* parameter to False *cg.disambiguate(tokens,descrpitive=False)*.\n\n#### Multilingual CG\n\nIt is possible to run one CG with tags produced by transducers of multiple languages. \n\n    from uralicNLP.cg3 import Cg3\n    cg = Cg3(\"fin\", morphology_languages=[\"fin\", \"olo\"])\n    print(cg.disambiguate([\"Kissa\",\"on\",\"kotona\", \".\"], language_flags=True))\n\nThe code above will use the Finnish (fin) CG rules to disambiguate the tags produced by Finnish (fin) and Olonetsian (olo) transducers. The *language_flags* parameter can be used to append the language code at the end of each morphological reading to identify the transducer that produced the reading.\n\nIt is also possible to pipe multiple CG analyzers. This will run the initial morphological analysis in the first CG, disambiguate and pass the disambiguated results to the next CG analyzer.\n\n    from uralicNLP.cg3 import Cg3, Cg3Pipe\n\n    cg1 = Cg3(\"fin\")\n    cg2 = Cg3(\"olo\")\n\n    cg_pipe = Cg3Pipe(cg1, cg2)\n    print(cg_pipe.disambiguate([\"Kissa\",\"on\",\"kotona\", \".\"]))\n\nThe example above will create a CG analyzer for Finnish and Olonetsian and pipe them into a *Cg3Pipe* object. The analyzer will first use Finnish CG with a Finnish FST to disambiguate the sentence, and then Olonetsian FST to do further disambiguation. Note that FST is only run in the first CG object of the pipe.\n\n### Dictionaries\nUralicNLP makes it possible to obtain the lexicographic information from the Giella dictionaries. The information can contain data such as translations, example sentences, semantic tags, morphological information and so on. You have to define the language code of the dictionary. \n\nFor example, \"sms\" selects the Skolt Sami dictionary. However, the word used to query can appear in any language. If the word is a lemma in Skolt Sami, the result will appear in \"exact_match\", if it's a word form for a Skolt Sami word, the results will appear in \"lemmatized\", and if it's a word in some other language, the results will appear in \"other\\_languages\". I.e if you search for *cat* in the Skolt Sami dictionary, you will get a result of a form {\"other\\_languages\": [Skolt Sami lexical items that translate to cat]}\n\nAn example of querying the Skolt Sami dictionary with *car*.\n\n\n    from uralicNLP import uralicApi\n    uralicApi.dictionary_search(\"car\", \"sms\")\n    >>{'lemmatized': [], exact_match': [], 'other_languages': [{'lemma': 'autt', ...}, ...]\n\nIt is possible to list all lemmas in the dictionary:\n\n    from uralicNLP import uralicApi\n    uralicApi.dictionary_lemmas(\"sms\")\n    >> ['autt', 'sokk' ...]\n\n#### Fast Dictionary Look-ups\n\nBy default, UralicNLP uses a TinyDB backend. This is easy as it does not require an external database server, but it can be extremely slow. For this reason, UralicNLP provides a [MongoDB backend](https://www.mongodb.com/download-center/community).\n\nMake sure you have both **MongoDB and [pymongo](https://pypi.org/project/pymongo/) installed**.\n\nFirst, you will need to download the dictionary and import it to MongoDB. The following example shows how to do it for Komi-Zyrian.\n\n    from uralicNLP import uralicApi\n\n    uralicApi.download(\"kpv\") #Download the latest dictionary data\n    uralicApi.import_dictionary_to_db(\"kpv\") #Update the MongoDB with the new data\n\nAfter the initial setup, you can use the dictionary queries, but you will need to specify the backend.\n\n    from uralicNLP import uralicApi\n    from uralicNLP.dictionary_backends import MongoDictionary\n    uralicApi.dictionary_lemmas(\"sms\",backend=MongoDictionary)\n    uralicApi.dictionary_search(\"car\", \"sms\",backend=MongoDictionary)\n\nNow you can query the dictionaries fast.\n\n### Parsing UD CoNLL-U annotated TreeBank data\n\nUralicNLP comes with tools for parsing and searching CoNLL-U formatted data. Please refer to [the Wiki for the UD parser documentation](https://github.com/mikahama/uralicNLP/wiki/UD-parser).\n\n### Semantics\n\nUralicNLP provides semantic models for Finnish (SemFi) and other Uralic languages (SemUr) for Komi-Zyrian, Erzya, Moksha and Skolt Sami. [Find out how to use semantic models](https://github.com/mikahama/uralicNLP/wiki/Semantics-(SemFi,-SemUr))\n\n### Other functionalities\n\n- [Machine Translation](https://github.com/mikahama/uralicNLP/wiki/Machine-Translation)\n- [Finnish Dependency Parsing](https://github.com/mikahama/uralicNLP/wiki/Dependency-parsing)\n\n# Cite\n\nIf you use UralicNLP in an academic publication, please cite it as follows:\n\nH\u00e4m\u00e4l\u00e4inen, Mika. (2019). UralicNLP: An NLP Library for Uralic Languages. Journal of open source software, 4(37), [1345]. https://doi.org/10.21105/joss.01345\n\n    @article{uralicnlp_2019, \n        title={{UralicNLP}: An {NLP} Library for {U}ralic Languages},\n        DOI={10.21105/joss.01345}, \n        journal={Journal of Open Source Software}, \n        author={Mika H\u00e4m\u00e4l\u00e4inen}, \n        year={2019}, \n        volume={4},\n        number={37},\n        pages={1345}\n    }\n\nFor citing the FSTs and CGs, see *uralicApi.model_info(language)*.\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mikahama/uralicNLP", "keywords": "Uralic languages,NLP,morphology,hfst,omorfi,dictionary,lexicography", "license": "Apache License, Version 2.0", "maintainer": "", "maintainer_email": "", "name": "uralicNLP", "package_url": "https://pypi.org/project/uralicNLP/", "platform": "", "project_url": "https://pypi.org/project/uralicNLP/", "project_urls": {"Bug Reports": "https://github.com/mikahama/uralicNLP/issues", "Developer": "https://mikakalevi.com/", "Homepage": "https://github.com/mikahama/uralicNLP", "Wiki": "https://github.com/mikahama/uralicNLP/wiki"}, "release_url": "https://pypi.org/project/uralicNLP/1.2.1/", "requires_dist": ["requests", "hfst", "mikatools (>=0.0.6)", "argparse", "future (>=0.18.2)", "tinydb"], "requires_python": "", "summary": "An NLP library for Uralic languages such as Finnish and Sami. Also supports Arabic, Russian etc.", "version": "1.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>UralicNLP</h1>\n<p><a href=\"https://travis-ci.com/mikahama/uralicNLP\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85b5d4f491c9b4b7b487cb37e2ad21c78c59c0fa/68747470733a2f2f7472617669732d63692e636f6d2f6d696b6168616d612f7572616c69634e4c502e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://pyup.io/repos/github/mikahama/uralicNLP/\" rel=\"nofollow\"><img alt=\"Updates\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/157a3ce30592d2d6f9630eef23988006e8c2d415/68747470733a2f2f707975702e696f2f7265706f732f6769746875622f6d696b6168616d612f7572616c69634e4c502f736869656c642e737667\"></a> <a href=\"https://doi.org/10.5281/zenodo.1143638\" rel=\"nofollow\"><img alt=\"DOI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b5f3c73814361abd25738aa3ecc3d32f8401897a/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313134333633382e737667\"></a></p>\n<p>UralicNLP is a natural language processing library targeted mainly for Uralic languages.</p>\n<p>UralicNLP can produce <strong>morphological analysis</strong>, <strong>generate morphological forms</strong>, <strong>lemmatize words</strong> and <strong>give lexical information</strong> about words in Uralic and other languages. At the time of writing, at least the following languages are supported: Finnish, Russian, German, English, Norwegian, Swedish, Arabic, Ingrian, Meadow &amp; Eastern Mari, Votic, Olonets-Karelian, Erzya, Moksha, Hill Mari, Udmurt, Tundra Nenets, Komi-Permyak, North Sami, South Sami and Skolt Sami. This information originates mainly from FST tools and dictionaries developed in the <a href=\"https://giellalt.uit.no/\" rel=\"nofollow\">GiellaLT infrastructure</a>. Currently, UralicNLP uses the nightly builds for most of the supported languages.</p>\n<p><a href=\"https://uralic.mikakalevi.com/nightly\" rel=\"nofollow\">See the catalog of supported languages</a></p>\n<h2>Installation</h2>\n<p>The library can be installed from <a href=\"https://pypi.python.org/pypi/uralicNLP/\" rel=\"nofollow\">PyPi</a>.</p>\n<pre><code>pip install uralicNLP\n</code></pre>\n<p>In case you want to use the Constraint Grammar features (<em>from uralicNLP.cg3 import Cg3</em>), you will also need to <a href=\"https://mikalikes.men/how-to-install-visl-cg3-on-mac-windows-and-linux/\" rel=\"nofollow\">install VISL CG-3</a>.</p>\n<p>If you are using Linux and you run into problems with installing HFST, you can find some help on <a href=\"https://mikalikes.men/using-hfst-on-python/\" rel=\"nofollow\">a blog post on installing hfst</a></p>\n<p>On Windows, HFST depends on <a href=\"https://go.microsoft.com/fwlink/?LinkId=746571\" rel=\"nofollow\">32 bit Microsoft Visual C++ Redistributable 2017</a>. Although, I would recommend using <a href=\"https://docs.microsoft.com/en-us/windows/wsl/install-win10\" rel=\"nofollow\">Windows subsystem for Linux</a>.</p>\n<p>Arabic and English FSTs require <a href=\"https://fomafst.github.io/\" rel=\"nofollow\">Foma</a>.</p>\n<h2>Usage</h2>\n<h3>List supported languages</h3>\n<p>The API is under constant development and new languages will be added to the Sanat infrastructure. That's why UralicNLP provides a functionality for looking up the list of currently supported languages. The method returns 3 letter ISO codes for the languages.</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.supported_languages()\n&gt;&gt;{'cg': ['vot', 'lav', 'izh', 'rus', 'lut', 'fao', 'est', 'nob', 'ron', 'olo', 'bxr', 'hun', 'crk', 'chr', 'vep', 'deu', 'mrj', 'gle', 'sjd', 'nio', 'myv', 'som', 'sma', 'sms', 'smn', 'kal', 'bak', 'kca', 'otw', 'ciw', 'fkv', 'nds', 'kpv', 'sme', 'sje', 'evn', 'oji', 'ipk', 'fit', 'fin', 'mns', 'rmf', 'liv', 'cor', 'mdf', 'yrk', 'tat', 'smj'], 'dictionary': ['vot', 'lav', 'rus', 'est', 'nob', 'ron', 'olo', 'hun', 'koi', 'chr', 'deu', 'mrj', 'sjd', 'myv', 'som', 'sma', 'sms', 'smn', 'kal', 'fkv', 'mhr', 'kpv', 'sme', 'sje', 'hdn', 'fin', 'mns', 'mdf', 'vro', 'udm', 'smj'], 'morph': ['vot', 'lav', 'izh', 'rus', 'lut', 'fao', 'est', 'nob', 'swe', 'ron', 'eng', 'olo', 'bxr', 'hun', 'koi', 'crk', 'chr', 'vep', 'deu', 'mrj', 'ara', 'gle', 'sjd', 'nio', 'myv', 'som', 'sma', 'sms', 'smn', 'kal', 'bak', 'kca', 'otw', 'ciw', 'fkv', 'nds', 'mhr', 'kpv', 'sme', 'sje', 'evn', 'oji', 'ipk', 'fit', 'fin', 'mns', 'rmf', 'liv', 'cor', 'mdf', 'yrk', 'vro', 'udm', 'tat', 'smj']}\n</code></pre>\n<p>The <em>dictionary</em> key lists the languages that are supported by the lexical lookup, whereas <em>morph</em> lists the languages that have morphological FSTs and <em>cg</em> lists the languages that have a CG.</p>\n<h3>Download models</h3>\n<p>If you have a lot of data to process, it might be a good idea to download the morphological models to your computer locally. This can be done easily. Although, it is possible to use the transducers over Akusanat API by passing <em>force_local=False</em>.</p>\n<p>On command line:</p>\n<pre><code>python -m uralicNLP.download --languages fin eng\n</code></pre>\n<p>From python code:</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.download(\"fin\")\n</code></pre>\n<p>When models are installed, <em>generate()</em>, <em>analyze()</em> and <em>lemmatize()</em> methods will automatically use them instead of the server side API. <a href=\"https://github.com/mikahama/uralicNLP/wiki/Models\" rel=\"nofollow\">More information about the models</a>.</p>\n<p>Use <strong>uralicApi.model_info(language)</strong> to see information about the FSTs and CGs such as license and authors. If you know how to make this information more accurate, please don't hesitate to open an issue on GitHub.</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.model_info(\"fin\")\n</code></pre>\n<p>To remove the models of a language, run</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.uninstall(\"fin\")\n</code></pre>\n<h3>Lemmatize words</h3>\n<p>A word form can be lemmatized with UralicNLP. This does not do any disambiguation but rather returns a list of all the possible lemmas.</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.lemmatize(\"\u0432\u0438\u0440\u0435\u0432\", \"myv\")\n&gt;&gt;['\u0432\u0438\u0440\u0435\u0432', '\u0432\u0438\u0440\u044c']\nuralicApi.lemmatize(\"luutapiiri\", \"fin\", word_boundaries=True)\n&gt;&gt;['luuta|piiri', 'luu|tapiiri']\n</code></pre>\n<p>An example of lemmatizing the word <em>\u0432\u0438\u0440\u0435\u0432</em> in Erzya (myv). By default, a <strong>descriptive</strong> analyzer is used. Use <em>uralicApi.lemmatize(\"\u0432\u0438\u0440\u0435\u0432\", \"myv\", descrpitive=False)</em> for a non-descriptive analyzer. If <em>word_boundaries</em> is set to True, the lemmatizer will mark word boundaries with a |.</p>\n<h3>Morphological analysis</h3>\n<p>Apart from just getting the lemmas, it's also possible to perform a complete morphological analysis.</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.analyze(\"voita\", \"fin\")\n&gt;&gt;[['voi+N+Sg+Par', 0.0], ['voi+N+Pl+Par', 0.0], ['voitaa+V+Act+Imprt+Prs+ConNeg+Sg2', 0.0], ['voitaa+V+Act+Imprt+Sg2', 0.0], ['voitaa+V+Act+Ind+Prs+ConNeg', 0.0], ['voittaa+V+Act+Imprt+Prs+ConNeg+Sg2', 0.0], ['voittaa+V+Act+Imprt+Sg2', 0.0], ['voittaa+V+Act+Ind+Prs+ConNeg', 0.0], ['vuo+N+Pl+Par', 0.0]]\n</code></pre>\n<p>An example of analyzing the word <em>voita</em> in Finnish (fin). The default analyzer is <strong>descriptive</strong>. To use a normative analyzer instead, use <em>uralicApi.analyze(\"voita\", \"fin\", descrpitive=False)</em></p>\n<h3>Morphological generation</h3>\n<p>From a lemma and a morphological analysis, it's possible to generate the desired word form.</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.generate(\"k\u00e4si+N+Sg+Par\", \"fin\")\n&gt;&gt;[['k\u00e4tt\u00e4', 0.0]]\n</code></pre>\n<p>An example of generating the singular partitive form for the Finnish noun <em>k\u00e4si</em>. The result is <em>k\u00e4tt\u00e4</em>. The default generator is a <strong>regular normative</strong> generator. <em>uralicApi.generate(\"k\u00e4si+N+Sg+Par\", \"fin\", dictionary_forms=True)</em> uses a normative dictionary generator and <em>uralicApi.generate(\"k\u00e4si+N+Sg+Par\", \"fin\", descrpitive=True)</em> a descriptive generator.</p>\n<h3>Access the HFST transducer</h3>\n<p>If you need to get a lower level access to <a href=\"https://hfst.github.io/python/3.12.1/classhfst_1_1HfstTransducer.html\" rel=\"nofollow\">the HFST transducer object</a>, you can use the following code</p>\n<pre><code>from uralicNLP import uralicApi\nsms_generator = uralicApi.get_transducer(\"sms\", analyzer=False) #generator\nsms_analyzer = uralicApi.get_transducer(\"sms\", analyzer=True) #analyzer\n</code></pre>\n<p>The same parameters can be used here as for <em>generate()</em> and <em>analyze()</em> to specify whether you want to use the normative or descriptive analyzers and so on. The defaults are <em>get_transducer(language, cache=True, analyzer=True, descrpitive=True, dictionary_forms=True)</em>.</p>\n<h3>Syntax - Constraint Grammar disambiguation</h3>\n<p><strong>Note</strong> this requires the models to be installed (see above) and <a href=\"https://mikalikes.men/how-to-install-visl-cg3-on-mac-windows-and-linux/\" rel=\"nofollow\">VISL CG-3</a>. The disambiguation process is easy.</p>\n<pre><code>from uralicNLP.cg3 import Cg3\nsentence = \"Kissa voi nauraa\"\ntokens = sentence.split(\" \") #Do a simple tokenization for the sentence\ncg = Cg3(\"fin\")\nprint cg.disambiguate(tokens)\n&gt;&gt;[(u'Kissa', [&lt;Kissa - N, Prop, Sg, Nom, &lt;W:0.000000&gt;&gt;, &lt;kissa - N, Sg, Nom, &lt;W:0.000000&gt;&gt;]), (u'voi', [&lt;voida - V, Act, Ind, Prs, Sg3, &lt;W:0.000000&gt;&gt;]), (u'nauraa', [&lt;nauraa - V, Act, InfA, Sg, Lat, &lt;W:0.000000&gt;&gt;])]\n</code></pre>\n<p>The return object is a list of tuples. The first item in each tuple is the word form used in the sentence, the second item is a list of <em>Cg3Word</em> objects. In the case of a full disambiguation, these lists have only one Cg3Word object, but some times the result of the disambiguation still has some ambiguity. Each Cg3Word object has three variables <em>lemma</em>, <em>form</em> and <em>morphology</em>.</p>\n<pre><code>disambiguations = cg.disambiguate(tokens)\nfor disambiguation in disambiguations:\n    possible_words = disambiguation[1]\n    for possible_word in possible_words:\n        print possible_word.lemma, possible_word.morphology\n&gt;&gt;Kissa [u'N', u'Prop', u'Sg', u'Nom', u'&lt;W:0.000000&gt;']\n&gt;&gt;kissa [u'N', u'Sg', u'Nom', u'&lt;W:0.000000&gt;']\n&gt;&gt;voida [u'V', u'Act', u'Ind', u'Prs', u'Sg3', u'&lt;W:0.000000&gt;']\n&gt;&gt;nauraa [u'V', u'Act', u'InfA', u'Sg', u'Lat', u'&lt;W:0.000000&gt;']\n</code></pre>\n<p>The <em>cg.disambiguate</em> takes in <em>remove_symbols</em> as an optional argument. Its default value is <em>True</em> which means that it removes the symbols (segments surrounded by @) from the FST output before feeding it to the CG disambiguator. If the value is set to <em>False</em>, the FST morphology is fed in to the CG unmodified.</p>\n<p>The <strong>default FST analyzer is a descriptive one</strong>, to use a normative analyzer, set the <em>descriptive</em> parameter to False <em>cg.disambiguate(tokens,descrpitive=False)</em>.</p>\n<h4>Multilingual CG</h4>\n<p>It is possible to run one CG with tags produced by transducers of multiple languages.</p>\n<pre><code>from uralicNLP.cg3 import Cg3\ncg = Cg3(\"fin\", morphology_languages=[\"fin\", \"olo\"])\nprint(cg.disambiguate([\"Kissa\",\"on\",\"kotona\", \".\"], language_flags=True))\n</code></pre>\n<p>The code above will use the Finnish (fin) CG rules to disambiguate the tags produced by Finnish (fin) and Olonetsian (olo) transducers. The <em>language_flags</em> parameter can be used to append the language code at the end of each morphological reading to identify the transducer that produced the reading.</p>\n<p>It is also possible to pipe multiple CG analyzers. This will run the initial morphological analysis in the first CG, disambiguate and pass the disambiguated results to the next CG analyzer.</p>\n<pre><code>from uralicNLP.cg3 import Cg3, Cg3Pipe\n\ncg1 = Cg3(\"fin\")\ncg2 = Cg3(\"olo\")\n\ncg_pipe = Cg3Pipe(cg1, cg2)\nprint(cg_pipe.disambiguate([\"Kissa\",\"on\",\"kotona\", \".\"]))\n</code></pre>\n<p>The example above will create a CG analyzer for Finnish and Olonetsian and pipe them into a <em>Cg3Pipe</em> object. The analyzer will first use Finnish CG with a Finnish FST to disambiguate the sentence, and then Olonetsian FST to do further disambiguation. Note that FST is only run in the first CG object of the pipe.</p>\n<h3>Dictionaries</h3>\n<p>UralicNLP makes it possible to obtain the lexicographic information from the Giella dictionaries. The information can contain data such as translations, example sentences, semantic tags, morphological information and so on. You have to define the language code of the dictionary.</p>\n<p>For example, \"sms\" selects the Skolt Sami dictionary. However, the word used to query can appear in any language. If the word is a lemma in Skolt Sami, the result will appear in \"exact_match\", if it's a word form for a Skolt Sami word, the results will appear in \"lemmatized\", and if it's a word in some other language, the results will appear in \"other_languages\". I.e if you search for <em>cat</em> in the Skolt Sami dictionary, you will get a result of a form {\"other_languages\": [Skolt Sami lexical items that translate to cat]}</p>\n<p>An example of querying the Skolt Sami dictionary with <em>car</em>.</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.dictionary_search(\"car\", \"sms\")\n&gt;&gt;{'lemmatized': [], exact_match': [], 'other_languages': [{'lemma': 'autt', ...}, ...]\n</code></pre>\n<p>It is possible to list all lemmas in the dictionary:</p>\n<pre><code>from uralicNLP import uralicApi\nuralicApi.dictionary_lemmas(\"sms\")\n&gt;&gt; ['autt', 'sokk' ...]\n</code></pre>\n<h4>Fast Dictionary Look-ups</h4>\n<p>By default, UralicNLP uses a TinyDB backend. This is easy as it does not require an external database server, but it can be extremely slow. For this reason, UralicNLP provides a <a href=\"https://www.mongodb.com/download-center/community\" rel=\"nofollow\">MongoDB backend</a>.</p>\n<p>Make sure you have both <strong>MongoDB and <a href=\"https://pypi.org/project/pymongo/\" rel=\"nofollow\">pymongo</a> installed</strong>.</p>\n<p>First, you will need to download the dictionary and import it to MongoDB. The following example shows how to do it for Komi-Zyrian.</p>\n<pre><code>from uralicNLP import uralicApi\n\nuralicApi.download(\"kpv\") #Download the latest dictionary data\nuralicApi.import_dictionary_to_db(\"kpv\") #Update the MongoDB with the new data\n</code></pre>\n<p>After the initial setup, you can use the dictionary queries, but you will need to specify the backend.</p>\n<pre><code>from uralicNLP import uralicApi\nfrom uralicNLP.dictionary_backends import MongoDictionary\nuralicApi.dictionary_lemmas(\"sms\",backend=MongoDictionary)\nuralicApi.dictionary_search(\"car\", \"sms\",backend=MongoDictionary)\n</code></pre>\n<p>Now you can query the dictionaries fast.</p>\n<h3>Parsing UD CoNLL-U annotated TreeBank data</h3>\n<p>UralicNLP comes with tools for parsing and searching CoNLL-U formatted data. Please refer to <a href=\"https://github.com/mikahama/uralicNLP/wiki/UD-parser\" rel=\"nofollow\">the Wiki for the UD parser documentation</a>.</p>\n<h3>Semantics</h3>\n<p>UralicNLP provides semantic models for Finnish (SemFi) and other Uralic languages (SemUr) for Komi-Zyrian, Erzya, Moksha and Skolt Sami. <a href=\"https://github.com/mikahama/uralicNLP/wiki/Semantics-(SemFi,-SemUr)\" rel=\"nofollow\">Find out how to use semantic models</a></p>\n<h3>Other functionalities</h3>\n<ul>\n<li><a href=\"https://github.com/mikahama/uralicNLP/wiki/Machine-Translation\" rel=\"nofollow\">Machine Translation</a></li>\n<li><a href=\"https://github.com/mikahama/uralicNLP/wiki/Dependency-parsing\" rel=\"nofollow\">Finnish Dependency Parsing</a></li>\n</ul>\n<h1>Cite</h1>\n<p>If you use UralicNLP in an academic publication, please cite it as follows:</p>\n<p>H\u00e4m\u00e4l\u00e4inen, Mika. (2019). UralicNLP: An NLP Library for Uralic Languages. Journal of open source software, 4(37), [1345]. <a href=\"https://doi.org/10.21105/joss.01345\" rel=\"nofollow\">https://doi.org/10.21105/joss.01345</a></p>\n<pre><code>@article{uralicnlp_2019, \n    title={{UralicNLP}: An {NLP} Library for {U}ralic Languages},\n    DOI={10.21105/joss.01345}, \n    journal={Journal of Open Source Software}, \n    author={Mika H\u00e4m\u00e4l\u00e4inen}, \n    year={2019}, \n    volume={4},\n    number={37},\n    pages={1345}\n}\n</code></pre>\n<p>For citing the FSTs and CGs, see <em>uralicApi.model_info(language)</em>.</p>\n\n          </div>"}, "last_serial": 7060434, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "34f03d5d0fab5e9e63eac6ca84c84904", "sha256": "c15a66061a781706e1100c6f3ea69e81dcc982e151f941f794b53a8d751f89c1"}, "downloads": -1, "filename": "uralicNLP-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "34f03d5d0fab5e9e63eac6ca84c84904", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4390, "upload_time": "2017-12-07T13:54:41", "upload_time_iso_8601": "2017-12-07T13:54:41.217383Z", "url": "https://files.pythonhosted.org/packages/6f/d4/568f1ee07d61de775eb6c6895dbea02dd092db2976573a13c13347f7ae1e/uralicNLP-1.0.0-py2.py3-none-any.whl", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "8b6dd7e01affa862d22cbaf057c9e012", "sha256": "a7a75a76af2e71a872c7f94b6d99d2b151a1d47ac201ee68f04c7d015f981f5e"}, "downloads": -1, "filename": "uralicNLP-1.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8b6dd7e01affa862d22cbaf057c9e012", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4382, "upload_time": "2017-12-12T19:18:44", "upload_time_iso_8601": "2017-12-12T19:18:44.734096Z", "url": "https://files.pythonhosted.org/packages/e2/af/2d7e5a3ba3f29b49836704a4aefa9936ec490d42b732efbd0521e5a466e8/uralicNLP-1.0.1-py2.py3-none-any.whl", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "54e30f33bc2ea70c8358cd3756b04c5b", "sha256": "980bd2f57a4bf7a8b140e5554d44db1d7970988b760bc07a099fa847521ef996"}, "downloads": -1, "filename": "uralicNLP-1.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "54e30f33bc2ea70c8358cd3756b04c5b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 8784, "upload_time": "2018-02-01T09:37:42", "upload_time_iso_8601": "2018-02-01T09:37:42.633550Z", "url": "https://files.pythonhosted.org/packages/f1/ee/a8fb47a2601357d8508b1fc373817269043a4c558fc8fce9b70345c9d298/uralicNLP-1.0.2-py2.py3-none-any.whl", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "1cd0d47e7935b3091a1a6a19ff256c94", "sha256": "7cf0f4e8fdf925b59f46e7274e1254874c904520a539bb6e7bad5280a260f068"}, "downloads": -1, "filename": "uralicNLP-1.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1cd0d47e7935b3091a1a6a19ff256c94", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 9764, "upload_time": "2018-07-17T10:34:07", "upload_time_iso_8601": "2018-07-17T10:34:07.807588Z", "url": "https://files.pythonhosted.org/packages/30/6c/b91d67d8d0af307c4691c9f06bbc296e66599403004f43c94254677d39f3/uralicNLP-1.0.3-py2.py3-none-any.whl", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "b5d06613673510ba1cc2c2e763fc6099", "sha256": "c4d5878b192420b5c5650b56aa9fdf78b9b4320f7429e7955e0cc4881b59e0c7"}, "downloads": -1, "filename": "uralicNLP-1.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b5d06613673510ba1cc2c2e763fc6099", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11272, "upload_time": "2018-10-23T14:03:45", "upload_time_iso_8601": "2018-10-23T14:03:45.060266Z", "url": "https://files.pythonhosted.org/packages/7f/80/59ced34306ca12086eda1c1640aa9e64d9b8b7f43db82fe0390a21f005a1/uralicNLP-1.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "97782807d3052154d021ab5c9f183981", "sha256": "f2aedc8090ba6cf7167d542f6ea6369f1f6ad083d92315b77283212220978aa8"}, "downloads": -1, "filename": "uralicNLP-1.0.5.tar.gz", "has_sig": false, "md5_digest": "97782807d3052154d021ab5c9f183981", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8978, "upload_time": "2018-10-23T14:04:03", "upload_time_iso_8601": "2018-10-23T14:04:03.854926Z", "url": "https://files.pythonhosted.org/packages/15/e8/0e85292debe9cb5c5b69c9ab1b22f1a8c753d95302887d9ae2e3d7dc9e28/uralicNLP-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "3c76fcdfdff4360e7be7a26ad3b08f52", "sha256": "fccc7d056986d209569fe4eaeb9506df41ef026b0abaaaa2dc5971f8260e8c68"}, "downloads": -1, "filename": "uralicNLP-1.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3c76fcdfdff4360e7be7a26ad3b08f52", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11261, "upload_time": "2018-10-23T14:08:22", "upload_time_iso_8601": "2018-10-23T14:08:22.286594Z", "url": "https://files.pythonhosted.org/packages/e1/f2/028d47086596e0f8bd9c53d87dcf2847ea3851d5a71fd53facd4667b60e1/uralicNLP-1.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ed66853797ab7908a288ca88dc20df75", "sha256": "7be97a524f873db950e9f0b4ec9d213953e597068ce30d556e50ba5e26369874"}, "downloads": -1, "filename": "uralicNLP-1.0.6.tar.gz", "has_sig": false, "md5_digest": "ed66853797ab7908a288ca88dc20df75", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8970, "upload_time": "2018-10-23T14:08:05", "upload_time_iso_8601": "2018-10-23T14:08:05.766077Z", "url": "https://files.pythonhosted.org/packages/d9/a4/ef54d16d1f69791104560d54bb119113f62f658c046b0d9b12bbea260205/uralicNLP-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "b0f8b273487d03732bf7cf749b8f0500", "sha256": "65214add6fdbe1723c3b81d5fbbd41c0dd323ad4c87f791d9ffcdc5e27a66346"}, "downloads": -1, "filename": "uralicNLP-1.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b0f8b273487d03732bf7cf749b8f0500", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 11317, "upload_time": "2018-10-26T13:56:07", "upload_time_iso_8601": "2018-10-26T13:56:07.430200Z", "url": "https://files.pythonhosted.org/packages/62/8f/e48e2bf584e85c23918d02a4a59931de5a5a5e5f84c1dfb7b2b1be0bd289/uralicNLP-1.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ffd6854540131f82ce8f99592cb4edc8", "sha256": "e60610d64ebbe14632be7f7cd44df3dadaa856210778e47fe4d9b6a5ad6c24c0"}, "downloads": -1, "filename": "uralicNLP-1.0.7.tar.gz", "has_sig": false, "md5_digest": "ffd6854540131f82ce8f99592cb4edc8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11282, "upload_time": "2018-10-26T13:56:17", "upload_time_iso_8601": "2018-10-26T13:56:17.513955Z", "url": "https://files.pythonhosted.org/packages/1b/af/09863a8af4436c6cd466c9d5d131338a5477cb86cf9417b016191149fea2/uralicNLP-1.0.7.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "be13913b58b8fd0510134ca5a1403b0b", "sha256": "c991c659a8d72d629868997722b47ecbc918e854d2c89d7f572ff7100dd38008"}, "downloads": -1, "filename": "uralicNLP-1.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "be13913b58b8fd0510134ca5a1403b0b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 13508, "upload_time": "2019-03-09T07:20:36", "upload_time_iso_8601": "2019-03-09T07:20:36.409766Z", "url": "https://files.pythonhosted.org/packages/dd/70/0d950fe8ec201a487de9bbe5426958c865cf315f983be330da1b63ebf23d/uralicNLP-1.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4f01d7a492ca6ff8b741f2fe5aa8729f", "sha256": "5cefd7ecd2a3d5e6356623216402bc0ff98be748eef23503a3dc313a419663e1"}, "downloads": -1, "filename": "uralicNLP-1.1.0.tar.gz", "has_sig": false, "md5_digest": "4f01d7a492ca6ff8b741f2fe5aa8729f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13265, "upload_time": "2019-03-09T07:20:47", "upload_time_iso_8601": "2019-03-09T07:20:47.674311Z", "url": "https://files.pythonhosted.org/packages/4e/ca/e91fda3e17f940c4207b0e9d13279b36afd92fa3b100ad19d8222f8a2df8/uralicNLP-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "0d3735e065b469c1a60457f505b59780", "sha256": "e7ad12ec0680ef585c334dd85be056f6fda8f66b6a8d5d1a2ab04cdfe27a7ff8"}, "downloads": -1, "filename": "uralicNLP-1.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0d3735e065b469c1a60457f505b59780", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 14493, "upload_time": "2019-04-29T12:12:22", "upload_time_iso_8601": "2019-04-29T12:12:22.203188Z", "url": "https://files.pythonhosted.org/packages/b2/64/dfc3b807d6dc3eac88c3c664df3d4a68e2141aff135807d90ddb714a7537/uralicNLP-1.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f1ca61eda28d5c40defea0fcb49948b8", "sha256": "77ba4494c86d4fc69951ce025ac57c47eb4b6bd933a63bde905f990b3a4e2db1"}, "downloads": -1, "filename": "uralicNLP-1.1.1.tar.gz", "has_sig": false, "md5_digest": "f1ca61eda28d5c40defea0fcb49948b8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14739, "upload_time": "2019-04-29T12:12:39", "upload_time_iso_8601": "2019-04-29T12:12:39.117875Z", "url": "https://files.pythonhosted.org/packages/2f/ba/d6167be4ffb4cf6edff67a4c8bf3f02258584febbc31301d5045b537bb41/uralicNLP-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "a3a248a84e27f7a33cdc63dcf261b8e7", "sha256": "fa8eb396ef9b53eaae47c94f35c46d6e8e7c334375d995ce294bfe1fc4a87f9c"}, "downloads": -1, "filename": "uralicNLP-1.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a3a248a84e27f7a33cdc63dcf261b8e7", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 29945, "upload_time": "2020-02-07T18:02:26", "upload_time_iso_8601": "2020-02-07T18:02:26.202788Z", "url": "https://files.pythonhosted.org/packages/9f/5d/48dea2cba8707e9efa67628c958d7add08d733eddd2202f01b22fff35475/uralicNLP-1.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b4be487aaacc1af4155c71086d459c7f", "sha256": "fd067bbda0d2b79d514fa742ae96f1e5c9b12fc97385c1134c0b5f6e17ecea47"}, "downloads": -1, "filename": "uralicNLP-1.1.2.tar.gz", "has_sig": false, "md5_digest": "b4be487aaacc1af4155c71086d459c7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28642, "upload_time": "2020-02-07T18:02:38", "upload_time_iso_8601": "2020-02-07T18:02:38.486483Z", "url": "https://files.pythonhosted.org/packages/ca/8b/332ab246aee3c54b226b78f8ab06f37093893dc6584f38ad6a3ab88136ea/uralicNLP-1.1.2.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "19f924db223dc248a183ed32b3ed1134", "sha256": "7cf5d1dd6a2f2eafcf51153e42f56170d6bfe874b117dd8e77ab131cc1d0cb1a"}, "downloads": -1, "filename": "uralicNLP-1.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "19f924db223dc248a183ed32b3ed1134", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 31239, "upload_time": "2020-03-29T11:47:18", "upload_time_iso_8601": "2020-03-29T11:47:18.674510Z", "url": "https://files.pythonhosted.org/packages/a8/7b/66924d7d37651bf47253f60c0a90f1d1f7114c51bc367d0eac0c7d588bf7/uralicNLP-1.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "88b8ce329479f65c89d7e81ad78df6d7", "sha256": "44c76b9ddc31d3221886ad7e83bb9a13933d8e03e63e0f92819d124178fc59d1"}, "downloads": -1, "filename": "uralicNLP-1.2.0.tar.gz", "has_sig": false, "md5_digest": "88b8ce329479f65c89d7e81ad78df6d7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30085, "upload_time": "2020-03-29T11:47:29", "upload_time_iso_8601": "2020-03-29T11:47:29.394728Z", "url": "https://files.pythonhosted.org/packages/ae/92/900f2709be170800812cf8b4dbe065c64d57663939df6f1612acd575beb8/uralicNLP-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "e58f44309b7b9ce9c483a32123b37489", "sha256": "5182c6b3b5fd70bcd69f13fdad7a8d0c64a4831944193b2743cc4b5e81867c33"}, "downloads": -1, "filename": "uralicNLP-1.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e58f44309b7b9ce9c483a32123b37489", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33105, "upload_time": "2020-04-20T14:20:21", "upload_time_iso_8601": "2020-04-20T14:20:21.809419Z", "url": "https://files.pythonhosted.org/packages/8b/65/71c6e75d9455bdaf98ec0be3cd9ebea97735028997ab6977be3f7b586963/uralicNLP-1.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c58235268e23fcf2f43d54735f6bb98d", "sha256": "0d0d214aaf22240a3a513b6c01587a80cc44f5ceb84f425491e0b62278872a9c"}, "downloads": -1, "filename": "uralicNLP-1.2.1.tar.gz", "has_sig": false, "md5_digest": "c58235268e23fcf2f43d54735f6bb98d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31723, "upload_time": "2020-04-20T14:20:30", "upload_time_iso_8601": "2020-04-20T14:20:30.101251Z", "url": "https://files.pythonhosted.org/packages/2e/22/c45e1f66221582e211c825426cb3c8d24605a55beefade6b5db79afaf36a/uralicNLP-1.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e58f44309b7b9ce9c483a32123b37489", "sha256": "5182c6b3b5fd70bcd69f13fdad7a8d0c64a4831944193b2743cc4b5e81867c33"}, "downloads": -1, "filename": "uralicNLP-1.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e58f44309b7b9ce9c483a32123b37489", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33105, "upload_time": "2020-04-20T14:20:21", "upload_time_iso_8601": "2020-04-20T14:20:21.809419Z", "url": "https://files.pythonhosted.org/packages/8b/65/71c6e75d9455bdaf98ec0be3cd9ebea97735028997ab6977be3f7b586963/uralicNLP-1.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c58235268e23fcf2f43d54735f6bb98d", "sha256": "0d0d214aaf22240a3a513b6c01587a80cc44f5ceb84f425491e0b62278872a9c"}, "downloads": -1, "filename": "uralicNLP-1.2.1.tar.gz", "has_sig": false, "md5_digest": "c58235268e23fcf2f43d54735f6bb98d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31723, "upload_time": "2020-04-20T14:20:30", "upload_time_iso_8601": "2020-04-20T14:20:30.101251Z", "url": "https://files.pythonhosted.org/packages/2e/22/c45e1f66221582e211c825426cb3c8d24605a55beefade6b5db79afaf36a/uralicNLP-1.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:39:36 2020"}