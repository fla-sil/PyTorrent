{"info": {"author": "Alejandro Caceres, Luke Maxwell", "author_email": "lukemaxwellshouse@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Internet :: WWW/HTTP :: Indexing/Search"], "description": "Autologin: Automatic login for web spiders\n==========================================\n\n.. image:: https://img.shields.io/pypi/v/autologin.svg\n   :target: https://pypi.python.org/pypi/autologin\n   :alt: PyPI Version\n\n.. image:: https://img.shields.io/travis/TeamHG-Memex/autologin/master.svg\n   :target: http://travis-ci.org/TeamHG-Memex/autologin\n   :alt: Build Status\n\n.. image:: https://codecov.io/github/TeamHG-Memex/autologin/coverage.svg?branch=master\n   :target: https://codecov.io/github/TeamHG-Memex/autologin?branch=master\n   :alt: Code Coverage\n\n\nAutologin is a library that makes it easier for web spiders to\n**crawl websites that require login**.\nProvide it with credentials and a URL or the html source of a page\n(normally the homepage), and it will attempt to login for you.\nCookies are returned to be used by your spider.\n\nThe goal of Autologin is to make it easier for web spiders to crawl websites\nthat require authentication\n**without having to re-write login code for each website.**\n\nAutologin can be used as a library, on the command line, or as a service.\nYou can make use of Autologin without generating http requests,\nso you can drop it right into your spider without worrying about\nimpacting rate limits.\n\nIf you are using `Scrapy <scrapy.readthedocs.org>`_ for crawling, check out\n`autologin-middleware <https://github.com/TeamHG-Memex/autologin-middleware>`_,\nwhich is a scrapy middleware that uses autologin http-api to maintain\na logged-in state for a scrapy spider.\n\nAutologin works on Python 2.7 and 3.3+.\n\n.. note:: The library is in the alpha stage.\n   API can still change, especially around the keychain UI.\n\n.. contents::\n\nFeatures\n--------\n\n* Automatically find login forms and fields\n* Obtain authenticated cookies\n* Obtain form requests to submit from your own spider\n* Extract links to login pages\n* Use as a library with or without making http requests\n* Command line client\n* Web service\n* UI for managing login credentials\n* Captcha support\n\n\nQuickstart\n----------\n\nDon't like reading documentation?\n\n::\n\n    from autologin import AutoLogin\n\n    url = 'https://reddit.com'\n    username = 'foo'\n    password = 'bar'\n    al = AutoLogin()\n    cookies = al.auth_cookies_from_url(url, username, password)\n\nYou now have a `cookiejar <https://docs.python.org/2/library/cookielib.html>`_\nthat you can use in your spider.  Don't want a cookiejar?\n\n::\n\n    cookies.__dict__\n\nYou now have a dictionary.\n\n\nInstallation\n------------\n\nInstall the latest release from PyPI::\n\n    $ pip install -U autologin\n\nor the version with the latest changes from Github::\n\n    $ pip install git+https://github.com/TeamHG-Memex/autologin.git\n\nAutologin depends on\n`Formasaurus <https://github.com/TeamHG-Memex/Formasaurus>`_\nfor field and form classification, which has quite a lot of dependencies.\nThese packages may require extra steps to install, so the command above\nmay fail.\nIn this case install dependencies manually, one by one\n(follow their install instructions).\n\nA recent ``pip`` is recommended (update it with ``pip install pip -U``).\nOn Ubuntu, the following packages are required::\n\n    $ apt-get install build-essential libssl-dev libffi-dev \\\n                      libxml2-dev libxslt1-dev \\\n                      python-dev  # or python3-dev for python 3\n\n\nAuth cookies from URL\n---------------------\n\nThis method makes an http request to the URL,\nextracts the login form (if there is one),\nfills the fields and submits the form.\nIt then return any cookies it has picked up::\n\n    cookies = al.auth_cookies_from_url(url, username, password)\n\nNote that it returns all cookies, they may be session cookies rather\nthan authenticated cookies.\n\nThis call is blocking, and uses Crochet to run the Twisted reactor\nand a Scrapy spider in a separate thread.\nIf you have a Scrapy spider (or use Twisted in some other way),\nuse the HTTP API, or the non-blocking API (it's not documented,\nsee ``http_api.AutologinAPI._login``).\n\nThere are also optional arguments for ``AutoLogin.auth_cookies_from_url``:\n\n- ``settings`` is a dictionary with Scrapy settings to override.\n  Useful settings to pass include:\n\n    * ``HTTP_PROXY``, ``HTTPS_PROXY`` set proxies to use for all requests.\n    * ``SPLASH_URL`` if set, `Splash <http://splash.readthedocs.org>`_\n      will be used to make all requests. Use it if your crawler also uses\n      splash and the session is tied to IP and User-Agent, or for Tor sites.\n    * ``USER_AGENT`` overrides default User-Agent.\n\n- ``extra_js`` (experimental)\n  is a string with an extra JS script that should be executed\n  on the login page before making a POST request. For example, it can be used\n  to accept cookie use. It is supported only when ``SPLASH_URL`` is also given\n  in ``settings``.\n\nAn example of using this options::\n\n    cookies = al.auth_cookies_from_url(\n        url, username, password,\n        extra_js='document.getElementById(\"accept-cookies\").click();',\n        settings={\n            'SPLASH_URL': 'http://127.0.0.1:8050',\n            'USER_AGENT': 'Mozilla/2.02 [fr] (WinNT; I)',\n        })\n\n\nLogin request\n-------------\n\nThis method extracts the login form (if there is one),\nfills the fields and returns a dictionary with the form url and args\nfor your spider to submit. No http requests are made::\n\n    >>> al.login_request(html_source, username, password, base_url=None)\n    {'body': 'login=admin&password=secret',\n     'headers': {b'Content-Type': b'application/x-www-form-urlencoded'},\n     'method': 'POST',\n     'url': '/login'}\n\nRelative form action will be resolved against the ``base_url``.\n\n\nCommand Line\n------------\n\n::\n\n    $ autologin\n    usage: autologin [-h] [--splash-url SPLASH_URL] [--http-proxy HTTP_PROXY]\n                     [--https-proxy HTTPS_PROXY] [--extra-js EXTRA_JS]\n                     [--show-in-browser]\n                     username password url\n\nHTTP API\n--------\n\nYou can start the autologin HTTP API with::\n\n    $ autologin-http-api\n\nand use ``/login-cookies`` endpoint. Make a POST request with JSON body.\nThe following arguments are supported:\n\n- ``url`` (required): url of the site where we would like to login\n- ``username`` (optional): if not provided, it will be fetched from the\n  login keychain\n- ``password`` (optional): if not provided, it will be fetched from the\n  login keychain\n- ``extra_js`` (optional, experimental)\n  is a string with an extra JS script that should be executed\n  on the login page before making a POST request. For example, it can be used\n  to accept cookie use. It is supported only when ``SPLASH_URL`` is also given\n  in ``settings``.\n- ``settings`` (optional) - a dictionary with Scrapy settings to override,\n  useful values are described above.\n\nIf ``username`` and ``password`` are not provided, autologin tries to find\nthem in the login keychain. If no matching credentials are found (they are\nmatched by domain, not by precise url), then human is expected to eventually\nprovide them in the keychain UI, or mark domain as \"skipped\".\n\nResponse is JSON with the following fields:\n\n- ``status``, which can take the following values:\n\n    - ``error`` status means an error occurred, ``error`` field has more info\n    - ``skipped`` means that domain is marked as \"skipped\" in keychain UI\n    - ``pending`` means there is an item in keychain UI (or it was just created),\n      and no credentials have been entered yet\n    - ``solved`` means that login was successful and cookies were obtained\n\n- ``error`` - human-readable explanation of the error.\n- ``response`` - last response received by autologin (can be None in some cases).\n  This is a dict with ``cookies``, ``headers``, and either a\n  ``text`` or ``body_b64`` fields (depending on response content type).\n- ``cookies`` - a list of dictionaries in ``Cookie.__dict__`` format. Present only\n  if status is ``solved``.\n- ``start_url`` - a url that was reached after successful login.\n\n\nProxy support\n-------------\n\nProxies can be specified via ``HTTP_PROXY`` and ``HTTPS_PROOXY`` keys\nin ``settings`` argument. Username and password can be specified\nas part of the proxy url (the format is ``protocol://username:password@url``).\n\nIf you are using proxy with Splash, it is assumed that\nyou want to have Splash make requests via given proxy,\nand not make a request **to** Splash via proxy.\n``HTTP_PROXY`` is always used for Splash.\n\n\nCaptcha support\n---------------\n\nThere is experimental captcha support: if the login form contains a captcha,\nwe will try to solve it using an external service (DeathByCaptcha),\nand will submit it as part of login request. This does not affect API in any\nway, you only have to provide environment variables with your DeathByCaptcha\naccount details: ``DEATHBYCAPTCHA_USERNAME`` and ``DEATHBYCAPTCHA_PASSWORD``.\nThis applies to all APIs: ``autologin-http-api``, ``autologin``, and\nthe Python API.\n\nYou also need to install the ``decaptcha`` library::\n\n    pip install git+https://github.com/TeamHG-Memex/decaptcha.git\n\nSupport is still experimental, new Google ReCaptcha/NoCaptcha are not supported.\nAlso, it currently works only with splash (when ``SPLASH_URL`` is passed in\n``settings``).\n\n\nKeychain UI\n-----------\n\nStart keychain UI with::\n\n    $ autologin-server\n\nNote that both ``autologin-server`` and ``autologin-http-api``\nare not protected by any authentication.\n\nKeychain UI stores credentials in an sqlite database. It is located near\nthe library itself by default, which is not always good, especially if you want\nto persist the data between updates or do not have write permissions\nfor that folder. You can configure database location and\n``secret_key`` used by the flask app by creating an ``/etc/autologin.cfg`` or\n``~/.autologin.cfg`` file (should be the same user under which autologin\nservices are running). Here is an example config that changes default secret_key\nand specifies a different database path (both items are optional)::\n\n    [autologin]\n    secret_key = 8a0b923820dcc509a6f75849b\n    db = /var/autologin/db.sqlite\n\n\nContributors\n------------\n\nSource code and bug tracker are on github:\nhttps://github.com/TeamHG-Memex/autologin.\n\nRun tests with ``tox``::\n\n    $ tox\n\nSplash support is not tested directly here, but there are indirect tests for it\nin the `autologin-middleware <https://github.com/TeamHG-Memex/autologin-middleware>`_\ntest suite.\n\n\nLicense\n-------\n\nLicense is MIT.\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/TeamHG-Memex/autologin", "keywords": "login", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "autologin", "package_url": "https://pypi.org/project/autologin/", "platform": "", "project_url": "https://pypi.org/project/autologin/", "project_urls": {"Homepage": "https://github.com/TeamHG-Memex/autologin"}, "release_url": "https://pypi.org/project/autologin/0.1.4/", "requires_dist": null, "requires_python": "", "summary": "A utility for finding login links, forms and autologging into websites with a set of valid credentials.", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/autologin\" rel=\"nofollow\"><img alt=\"PyPI Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6aac8fe9c9fa9e031be23bf1de9754a9ccac00fb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6175746f6c6f67696e2e737667\"></a>\n<a href=\"http://travis-ci.org/TeamHG-Memex/autologin\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e769b335a11e0aa41c801c3340012dfae5bbe83a/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f5465616d48472d4d656d65782f6175746f6c6f67696e2f6d61737465722e737667\"></a>\n<a href=\"https://codecov.io/github/TeamHG-Memex/autologin?branch=master\" rel=\"nofollow\"><img alt=\"Code Coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e21a6649ed69342628673e320d3d270e9e9a984a/68747470733a2f2f636f6465636f762e696f2f6769746875622f5465616d48472d4d656d65782f6175746f6c6f67696e2f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a>\n<p>Autologin is a library that makes it easier for web spiders to\n<strong>crawl websites that require login</strong>.\nProvide it with credentials and a URL or the html source of a page\n(normally the homepage), and it will attempt to login for you.\nCookies are returned to be used by your spider.</p>\n<p>The goal of Autologin is to make it easier for web spiders to crawl websites\nthat require authentication\n<strong>without having to re-write login code for each website.</strong></p>\n<p>Autologin can be used as a library, on the command line, or as a service.\nYou can make use of Autologin without generating http requests,\nso you can drop it right into your spider without worrying about\nimpacting rate limits.</p>\n<p>If you are using <a href=\"scrapy.readthedocs.org\" rel=\"nofollow\">Scrapy</a> for crawling, check out\n<a href=\"https://github.com/TeamHG-Memex/autologin-middleware\" rel=\"nofollow\">autologin-middleware</a>,\nwhich is a scrapy middleware that uses autologin http-api to maintain\na logged-in state for a scrapy spider.</p>\n<p>Autologin works on Python 2.7 and 3.3+.</p>\n<div>\n<p>Note</p>\n<p>The library is in the alpha stage.\nAPI can still change, especially around the keychain UI.</p>\n</div>\n<div id=\"contents\">\n<p>Contents</p>\n<ul>\n<li><a href=\"#features\" id=\"id2\" rel=\"nofollow\">Features</a></li>\n<li><a href=\"#quickstart\" id=\"id3\" rel=\"nofollow\">Quickstart</a></li>\n<li><a href=\"#installation\" id=\"id4\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#auth-cookies-from-url\" id=\"id5\" rel=\"nofollow\">Auth cookies from URL</a></li>\n<li><a href=\"#login-request\" id=\"id6\" rel=\"nofollow\">Login request</a></li>\n<li><a href=\"#command-line\" id=\"id7\" rel=\"nofollow\">Command Line</a></li>\n<li><a href=\"#http-api\" id=\"id8\" rel=\"nofollow\">HTTP API</a></li>\n<li><a href=\"#proxy-support\" id=\"id9\" rel=\"nofollow\">Proxy support</a></li>\n<li><a href=\"#captcha-support\" id=\"id10\" rel=\"nofollow\">Captcha support</a></li>\n<li><a href=\"#keychain-ui\" id=\"id11\" rel=\"nofollow\">Keychain UI</a></li>\n<li><a href=\"#contributors\" id=\"id12\" rel=\"nofollow\">Contributors</a></li>\n<li><a href=\"#license\" id=\"id13\" rel=\"nofollow\">License</a></li>\n</ul>\n</div>\n<div id=\"features\">\n<h2><a href=\"#id2\" rel=\"nofollow\">Features</a></h2>\n<ul>\n<li>Automatically find login forms and fields</li>\n<li>Obtain authenticated cookies</li>\n<li>Obtain form requests to submit from your own spider</li>\n<li>Extract links to login pages</li>\n<li>Use as a library with or without making http requests</li>\n<li>Command line client</li>\n<li>Web service</li>\n<li>UI for managing login credentials</li>\n<li>Captcha support</li>\n</ul>\n</div>\n<div id=\"quickstart\">\n<h2><a href=\"#id3\" rel=\"nofollow\">Quickstart</a></h2>\n<p>Don\u2019t like reading documentation?</p>\n<pre>from autologin import AutoLogin\n\nurl = 'https://reddit.com'\nusername = 'foo'\npassword = 'bar'\nal = AutoLogin()\ncookies = al.auth_cookies_from_url(url, username, password)\n</pre>\n<p>You now have a <a href=\"https://docs.python.org/2/library/cookielib.html\" rel=\"nofollow\">cookiejar</a>\nthat you can use in your spider.  Don\u2019t want a cookiejar?</p>\n<pre>cookies.__dict__\n</pre>\n<p>You now have a dictionary.</p>\n</div>\n<div id=\"installation\">\n<h2><a href=\"#id4\" rel=\"nofollow\">Installation</a></h2>\n<p>Install the latest release from PyPI:</p>\n<pre>$ pip install -U autologin\n</pre>\n<p>or the version with the latest changes from Github:</p>\n<pre>$ pip install git+https://github.com/TeamHG-Memex/autologin.git\n</pre>\n<p>Autologin depends on\n<a href=\"https://github.com/TeamHG-Memex/Formasaurus\" rel=\"nofollow\">Formasaurus</a>\nfor field and form classification, which has quite a lot of dependencies.\nThese packages may require extra steps to install, so the command above\nmay fail.\nIn this case install dependencies manually, one by one\n(follow their install instructions).</p>\n<p>A recent <tt>pip</tt> is recommended (update it with <tt>pip install pip <span class=\"pre\">-U</span></tt>).\nOn Ubuntu, the following packages are required:</p>\n<pre>$ apt-get install build-essential libssl-dev libffi-dev \\\n                  libxml2-dev libxslt1-dev \\\n                  python-dev  # or python3-dev for python 3\n</pre>\n</div>\n<div id=\"auth-cookies-from-url\">\n<h2><a href=\"#id5\" rel=\"nofollow\">Auth cookies from URL</a></h2>\n<p>This method makes an http request to the URL,\nextracts the login form (if there is one),\nfills the fields and submits the form.\nIt then return any cookies it has picked up:</p>\n<pre>cookies = al.auth_cookies_from_url(url, username, password)\n</pre>\n<p>Note that it returns all cookies, they may be session cookies rather\nthan authenticated cookies.</p>\n<p>This call is blocking, and uses Crochet to run the Twisted reactor\nand a Scrapy spider in a separate thread.\nIf you have a Scrapy spider (or use Twisted in some other way),\nuse the HTTP API, or the non-blocking API (it\u2019s not documented,\nsee <tt>http_api.AutologinAPI._login</tt>).</p>\n<p>There are also optional arguments for <tt>AutoLogin.auth_cookies_from_url</tt>:</p>\n<ul>\n<li><p><tt>settings</tt> is a dictionary with Scrapy settings to override.\nUseful settings to pass include:</p>\n<blockquote>\n<ul>\n<li><tt>HTTP_PROXY</tt>, <tt>HTTPS_PROXY</tt> set proxies to use for all requests.</li>\n<li><tt>SPLASH_URL</tt> if set, <a href=\"http://splash.readthedocs.org\" rel=\"nofollow\">Splash</a>\nwill be used to make all requests. Use it if your crawler also uses\nsplash and the session is tied to IP and User-Agent, or for Tor sites.</li>\n<li><tt>USER_AGENT</tt> overrides default User-Agent.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><tt>extra_js</tt> (experimental)\nis a string with an extra JS script that should be executed\non the login page before making a POST request. For example, it can be used\nto accept cookie use. It is supported only when <tt>SPLASH_URL</tt> is also given\nin <tt>settings</tt>.</p>\n</li>\n</ul>\n<p>An example of using this options:</p>\n<pre>cookies = al.auth_cookies_from_url(\n    url, username, password,\n    extra_js='document.getElementById(\"accept-cookies\").click();',\n    settings={\n        'SPLASH_URL': 'http://127.0.0.1:8050',\n        'USER_AGENT': 'Mozilla/2.02 [fr] (WinNT; I)',\n    })\n</pre>\n</div>\n<div id=\"login-request\">\n<h2><a href=\"#id6\" rel=\"nofollow\">Login request</a></h2>\n<p>This method extracts the login form (if there is one),\nfills the fields and returns a dictionary with the form url and args\nfor your spider to submit. No http requests are made:</p>\n<pre>&gt;&gt;&gt; al.login_request(html_source, username, password, base_url=None)\n{'body': 'login=admin&amp;password=secret',\n 'headers': {b'Content-Type': b'application/x-www-form-urlencoded'},\n 'method': 'POST',\n 'url': '/login'}\n</pre>\n<p>Relative form action will be resolved against the <tt>base_url</tt>.</p>\n</div>\n<div id=\"command-line\">\n<h2><a href=\"#id7\" rel=\"nofollow\">Command Line</a></h2>\n<pre>$ autologin\nusage: autologin [-h] [--splash-url SPLASH_URL] [--http-proxy HTTP_PROXY]\n                 [--https-proxy HTTPS_PROXY] [--extra-js EXTRA_JS]\n                 [--show-in-browser]\n                 username password url\n</pre>\n</div>\n<div id=\"http-api\">\n<h2><a href=\"#id8\" rel=\"nofollow\">HTTP API</a></h2>\n<p>You can start the autologin HTTP API with:</p>\n<pre>$ autologin-http-api\n</pre>\n<p>and use <tt><span class=\"pre\">/login-cookies</span></tt> endpoint. Make a POST request with JSON body.\nThe following arguments are supported:</p>\n<ul>\n<li><tt>url</tt> (required): url of the site where we would like to login</li>\n<li><tt>username</tt> (optional): if not provided, it will be fetched from the\nlogin keychain</li>\n<li><tt>password</tt> (optional): if not provided, it will be fetched from the\nlogin keychain</li>\n<li><tt>extra_js</tt> (optional, experimental)\nis a string with an extra JS script that should be executed\non the login page before making a POST request. For example, it can be used\nto accept cookie use. It is supported only when <tt>SPLASH_URL</tt> is also given\nin <tt>settings</tt>.</li>\n<li><tt>settings</tt> (optional) - a dictionary with Scrapy settings to override,\nuseful values are described above.</li>\n</ul>\n<p>If <tt>username</tt> and <tt>password</tt> are not provided, autologin tries to find\nthem in the login keychain. If no matching credentials are found (they are\nmatched by domain, not by precise url), then human is expected to eventually\nprovide them in the keychain UI, or mark domain as \u201cskipped\u201d.</p>\n<p>Response is JSON with the following fields:</p>\n<ul>\n<li><p><tt>status</tt>, which can take the following values:</p>\n<blockquote>\n<ul>\n<li><tt>error</tt> status means an error occurred, <tt>error</tt> field has more info</li>\n<li><tt>skipped</tt> means that domain is marked as \u201cskipped\u201d in keychain UI</li>\n<li><tt>pending</tt> means there is an item in keychain UI (or it was just created),\nand no credentials have been entered yet</li>\n<li><tt>solved</tt> means that login was successful and cookies were obtained</li>\n</ul>\n</blockquote>\n</li>\n<li><p><tt>error</tt> - human-readable explanation of the error.</p>\n</li>\n<li><p><tt>response</tt> - last response received by autologin (can be None in some cases).\nThis is a dict with <tt>cookies</tt>, <tt>headers</tt>, and either a\n<tt>text</tt> or <tt>body_b64</tt> fields (depending on response content type).</p>\n</li>\n<li><p><tt>cookies</tt> - a list of dictionaries in <tt>Cookie.__dict__</tt> format. Present only\nif status is <tt>solved</tt>.</p>\n</li>\n<li><p><tt>start_url</tt> - a url that was reached after successful login.</p>\n</li>\n</ul>\n</div>\n<div id=\"proxy-support\">\n<h2><a href=\"#id9\" rel=\"nofollow\">Proxy support</a></h2>\n<p>Proxies can be specified via <tt>HTTP_PROXY</tt> and <tt>HTTPS_PROOXY</tt> keys\nin <tt>settings</tt> argument. Username and password can be specified\nas part of the proxy url (the format is <tt><span class=\"pre\">protocol://username:password@url</span></tt>).</p>\n<p>If you are using proxy with Splash, it is assumed that\nyou want to have Splash make requests via given proxy,\nand not make a request <strong>to</strong> Splash via proxy.\n<tt>HTTP_PROXY</tt> is always used for Splash.</p>\n</div>\n<div id=\"captcha-support\">\n<h2><a href=\"#id10\" rel=\"nofollow\">Captcha support</a></h2>\n<p>There is experimental captcha support: if the login form contains a captcha,\nwe will try to solve it using an external service (DeathByCaptcha),\nand will submit it as part of login request. This does not affect API in any\nway, you only have to provide environment variables with your DeathByCaptcha\naccount details: <tt>DEATHBYCAPTCHA_USERNAME</tt> and <tt>DEATHBYCAPTCHA_PASSWORD</tt>.\nThis applies to all APIs: <tt><span class=\"pre\">autologin-http-api</span></tt>, <tt>autologin</tt>, and\nthe Python API.</p>\n<p>You also need to install the <tt>decaptcha</tt> library:</p>\n<pre>pip install git+https://github.com/TeamHG-Memex/decaptcha.git\n</pre>\n<p>Support is still experimental, new Google ReCaptcha/NoCaptcha are not supported.\nAlso, it currently works only with splash (when <tt>SPLASH_URL</tt> is passed in\n<tt>settings</tt>).</p>\n</div>\n<div id=\"keychain-ui\">\n<h2><a href=\"#id11\" rel=\"nofollow\">Keychain UI</a></h2>\n<p>Start keychain UI with:</p>\n<pre>$ autologin-server\n</pre>\n<p>Note that both <tt><span class=\"pre\">autologin-server</span></tt> and <tt><span class=\"pre\">autologin-http-api</span></tt>\nare not protected by any authentication.</p>\n<p>Keychain UI stores credentials in an sqlite database. It is located near\nthe library itself by default, which is not always good, especially if you want\nto persist the data between updates or do not have write permissions\nfor that folder. You can configure database location and\n<tt>secret_key</tt> used by the flask app by creating an <tt>/etc/autologin.cfg</tt> or\n<tt><span class=\"pre\">~/.autologin.cfg</span></tt> file (should be the same user under which autologin\nservices are running). Here is an example config that changes default secret_key\nand specifies a different database path (both items are optional):</p>\n<pre>[autologin]\nsecret_key = 8a0b923820dcc509a6f75849b\ndb = /var/autologin/db.sqlite\n</pre>\n</div>\n<div id=\"contributors\">\n<h2><a href=\"#id12\" rel=\"nofollow\">Contributors</a></h2>\n<p>Source code and bug tracker are on github:\n<a href=\"https://github.com/TeamHG-Memex/autologin\" rel=\"nofollow\">https://github.com/TeamHG-Memex/autologin</a>.</p>\n<p>Run tests with <tt>tox</tt>:</p>\n<pre>$ tox\n</pre>\n<p>Splash support is not tested directly here, but there are indirect tests for it\nin the <a href=\"https://github.com/TeamHG-Memex/autologin-middleware\" rel=\"nofollow\">autologin-middleware</a>\ntest suite.</p>\n</div>\n<div id=\"license\">\n<h2><a href=\"#id13\" rel=\"nofollow\">License</a></h2>\n<p>License is MIT.</p>\n</div>\n\n          </div>"}, "last_serial": 4308940, "releases": {"0.1.0": [], "0.1.1": [{"comment_text": "", "digests": {"md5": "64401564dc9d29787ea53be2baddcdd2", "sha256": "1c880eb1d71fd9f7dcc90037618502e79389001478189377ffc1271603ff8a0d"}, "downloads": -1, "filename": "autologin-0.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "64401564dc9d29787ea53be2baddcdd2", "packagetype": "bdist_wheel", "python_version": "3.4", "requires_python": null, "size": 293992, "upload_time": "2016-05-19T15:15:41", "upload_time_iso_8601": "2016-05-19T15:15:41.827952Z", "url": "https://files.pythonhosted.org/packages/6d/c4/f48123db6a6c3aac7dd754c431fc20b6ef7a1ad71eb9a4d6685656fa7632/autologin-0.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27786d7f4668de66824a8c1fdd5d4e9b", "sha256": "33720ae19c22ed511cfa84cdb1226361f4018201abbd16ad593015e5632ecfe5"}, "downloads": -1, "filename": "autologin-0.1.1.tar.gz", "has_sig": false, "md5_digest": "27786d7f4668de66824a8c1fdd5d4e9b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 285339, "upload_time": "2016-05-19T15:13:43", "upload_time_iso_8601": "2016-05-19T15:13:43.225956Z", "url": "https://files.pythonhosted.org/packages/83/ab/54c0625cd31a5285c8147118481a16ee07b697859484524fccd55a9f48e9/autologin-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "7a81247a2e2e08b307bb9d2467525b5e", "sha256": "cecb526a3318170b692551fe8296187524bb94eccc2ce2b8b89c642f2b6af144"}, "downloads": -1, "filename": "autologin-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7a81247a2e2e08b307bb9d2467525b5e", "packagetype": "bdist_wheel", "python_version": "3.4", "requires_python": null, "size": 294929, "upload_time": "2016-05-20T15:58:43", "upload_time_iso_8601": "2016-05-20T15:58:43.992630Z", "url": "https://files.pythonhosted.org/packages/b9/f4/dba91233aaf5fc6722ef51f9a5b348cd98d5ea159fb98f1b8e20af0d2a28/autologin-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e690b9e4bdc1e93684e8701b7c633a18", "sha256": "4009ed13d20cfded21f354d9212c2cab573fb8800ac5f1d239c760e10b45027f"}, "downloads": -1, "filename": "autologin-0.1.2.tar.gz", "has_sig": false, "md5_digest": "e690b9e4bdc1e93684e8701b7c633a18", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 285983, "upload_time": "2016-05-20T15:58:32", "upload_time_iso_8601": "2016-05-20T15:58:32.832091Z", "url": "https://files.pythonhosted.org/packages/e9/5d/cda18653bbe7fa776c3c289c460f0e992aff513ef38540f4bd1e6b86de63/autologin-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "8af5ad3e8f142740ffc9e31065a1b514", "sha256": "4c46966133a5ab4978dd0a196bcc15481f7e8b0e2090627cf6c44523e9f9d04d"}, "downloads": -1, "filename": "autologin-0.1.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8af5ad3e8f142740ffc9e31065a1b514", "packagetype": "bdist_wheel", "python_version": "3.4", "requires_python": null, "size": 295947, "upload_time": "2016-08-31T10:30:12", "upload_time_iso_8601": "2016-08-31T10:30:12.018304Z", "url": "https://files.pythonhosted.org/packages/d0/81/18f17b1c3766564b2cbb341df4aa71bcc6aae7d7b8eb20b6dc9542b779a3/autologin-0.1.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e74f277e37fb51c2ed3298e5b617f328", "sha256": "4fc1634da967457006c1b813491f623e827c5017f0a2e748f2bfbcecc7d51bdd"}, "downloads": -1, "filename": "autologin-0.1.3.tar.gz", "has_sig": false, "md5_digest": "e74f277e37fb51c2ed3298e5b617f328", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 286921, "upload_time": "2016-08-31T10:30:08", "upload_time_iso_8601": "2016-08-31T10:30:08.075693Z", "url": "https://files.pythonhosted.org/packages/7b/c1/52bd544663e89702e5bd65ba54e42f2b785108694dea7dd5aaa7586c0f26/autologin-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "7ac286be0f3859d29a2fa7b0aff042df", "sha256": "1a52cee5f075e15ee7a681e6441814b0438d8f63d2d80226a0f1daf5f784dc28"}, "downloads": -1, "filename": "autologin-0.1.4.tar.gz", "has_sig": false, "md5_digest": "7ac286be0f3859d29a2fa7b0aff042df", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 291664, "upload_time": "2017-05-24T08:49:17", "upload_time_iso_8601": "2017-05-24T08:49:17.894041Z", "url": "https://files.pythonhosted.org/packages/87/ca/52896c16ac0988456837348b7605a7a4db5695735765931601846a9f4c17/autologin-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7ac286be0f3859d29a2fa7b0aff042df", "sha256": "1a52cee5f075e15ee7a681e6441814b0438d8f63d2d80226a0f1daf5f784dc28"}, "downloads": -1, "filename": "autologin-0.1.4.tar.gz", "has_sig": false, "md5_digest": "7ac286be0f3859d29a2fa7b0aff042df", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 291664, "upload_time": "2017-05-24T08:49:17", "upload_time_iso_8601": "2017-05-24T08:49:17.894041Z", "url": "https://files.pythonhosted.org/packages/87/ca/52896c16ac0988456837348b7605a7a4db5695735765931601846a9f4c17/autologin-0.1.4.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:15 2020"}