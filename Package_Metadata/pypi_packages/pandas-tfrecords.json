{"info": {"author": "Sergei Chipiga", "author_email": "chipiga86@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "**************************\npandas-tfrecords converter\n**************************\n\nThis project was born under impression from `spark-tensorflow-connector <https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector>`_ and implements similar functionality in order to save easy pandas dataframe to tfrecords and to restore tfrecords to pandas dataframe.\n\nIt can work as with local files as with AWS S3 files. Please keep in mind, that here tensorflow works with local copies of remote files, which are synced via ``s3fs`` with S3. I did this workaround because my tensorflow ``v2.1.0`` didn't work with S3 directly and raised authentication error ``Credentials have expired attempting to repull from EC2 Metadata Service``, but maybe it's fixed already.\n\n===========\nQuick start\n===========\n\n.. code::\n\n    pip install pandas-tfrecords\n\n\n.. code:: python\n\n    import pandas as pd\n    from pandas_tfrecords import pd2tf, tf2pd\n\n    df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c'], 'C': [[1, 2], [3, 4], [5, 6]]})\n\n    # local\n    pd2tf(df, './tfrecords')\n    my_df = tf2pd('./tfrecords')\n\n    # S3\n    pd2tf(df, 's3://my-bucket/tfrecords')\n    my_df = tf2pd('s3://my-bucket/tfrecords')\n\n===============\nConverted types\n===============\n\n-------------------\npandas -> tfrecords\n-------------------\n\n.. code::\n\n    bytes, str -> tf.string\n    int, np.integer -> tf.int64\n    float, np.floating -> tf.float32\n    list, np.ndarray of bytes, str, int, np.integer, float, np.floating -> sequence of tf.string, tf.int64, tf.float32\n\n-------------------\ntfrecords -> pandas\n-------------------\n\n.. code::\n\n    tf.string -> bytes\n    tf.int64 -> int\n    tf.float32 -> float\n    sequence of tf.string, tf.int64, tf.float32 -> list of bytes, int, float\n\n**NB!** Please pay attention it works only with **one-dimentional** arrays. It means ``[1, 2, 3]`` will be converted to both sides, but ``[[1,2,3]]`` **won't** be converted to any side. It works that, because ``spark-tensorflow-connector`` works similar, and I didn't learn yet how to implement nested sequences. In order to work with **nested** sequences you should use ``reshape``.\n\n===\nAPI\n===\n\n.. code:: python\n\n    pandas_tfrecords.pandas_to_tfrecords(df, folder, compression_type='GZIP', compression_level=9, columns=None, max_mb=50)\n\nArguments:\n\n- ``df`` - pandas dataframe. Please keep in mind above info about nested sequences.\n- ``folder`` - folder to save tfrecords, local or S3. Please be sure that it doesn't contain other files or folders, if you want to read from this folder then.\n- ``compression_type='GZIP'`` - compression types: ``'GZIP'``, ``'ZLIB'``, ``None``. If ``None`` not compressed.\n- ``compression_level=9`` - compression level 0...9.\n- ``columns=None`` - list of columns to save, if ``None`` all columns will be saved.\n- ``max_mb=50`` - maximum size of uncompressed data to save in single file. If dataframe total size is bigger than this limit, then it will be splitted to several files. If ``None`` it isn't limited and single file will be saved.\n\nalias ``pandas_tfrecords.pd2tf``\n\n.. code:: python\n\n    pandas_tfrecords.tfrecords_to_pandas(file_paths, schema=None, compression_type='auto', cast=True)\n\nArguments:\n\n- ``file_paths`` - One or sequence of file paths or folders, local or S3, to read tfrecords from.\n- ``schema=None`` - If ``None`` schema will be detected automatically. But you can specify which columns you want to read only. It should be a dict, which keys are column names and values are column data types: ``str`` (or ``bytes``), ``int``, ``float``, and for sequences it should be wrapped to ``list``: ``[str]`` (or ``[bytes]``), ``[int]``, ``[float]``. For example:\n\n.. code:: python\n\n    df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c'], 'C': [[1, 2], [3, 4], [5, 6]]})\n    print(df)\n       A  B       C\n    0  1  a  [1, 2]\n    1  2  b  [3, 4]\n    2  3  c  [5, 6]\n\n    pd2tf(df, './tfrecords')\n    tf2pd('./tfrecords', schema={'A': int, 'C': [int]})\n       A       C\n    0  1  [1, 2]\n    1  2  [3, 4]\n    2  3  [5, 6]\n\n- ``compression_type='auto'`` - compression type: ``'auto'``, ``'GZIP'``, ``'ZLIB'``, ``None``.\n- ``cast=True`` - if ``True`` it casts ``bytes`` data after converting from ``tf.string``. It tries to cast it to ``int``, ``float`` and ``str`` sequentially. If it's not possible, otherwise keeps as is.\n\nalias ``pandas_tfrecords.tf2pd``\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/schipiga/pandas-tfrecords/", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "pandas-tfrecords", "package_url": "https://pypi.org/project/pandas-tfrecords/", "platform": "", "project_url": "https://pypi.org/project/pandas-tfrecords/", "project_urls": {"Homepage": "https://github.com/schipiga/pandas-tfrecords/"}, "release_url": "https://pypi.org/project/pandas-tfrecords/0.1.4/", "requires_dist": ["s3fs (==0.4.0)", "tensorflow (==2.1.0)", "pandas (==1.0.1)", "numpy (==1.18.1)"], "requires_python": "", "summary": "Converter pandas to tfrecords & tfrecords to pandas", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This project was born under impression from <a href=\"https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector\" rel=\"nofollow\">spark-tensorflow-connector</a> and implements similar functionality in order to save easy pandas dataframe to tfrecords and to restore tfrecords to pandas dataframe.</p>\n<p>It can work as with local files as with AWS S3 files. Please keep in mind, that here tensorflow works with local copies of remote files, which are synced via <tt>s3fs</tt> with S3. I did this workaround because my tensorflow <tt>v2.1.0</tt> didn\u2019t work with S3 directly and raised authentication error <tt>Credentials have expired attempting to repull from EC2 Metadata Service</tt>, but maybe it\u2019s fixed already.</p>\n<div id=\"quick-start\">\n<h2>Quick start</h2>\n<pre>pip install pandas-tfrecords\n</pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pandas_tfrecords</span> <span class=\"kn\">import</span> <span class=\"n\">pd2tf</span><span class=\"p\">,</span> <span class=\"n\">tf2pd</span>\n\n<span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s1\">'A'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">],</span> <span class=\"s1\">'B'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'b'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">],</span> <span class=\"s1\">'C'</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">]]})</span>\n\n<span class=\"c1\"># local</span>\n<span class=\"n\">pd2tf</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s1\">'./tfrecords'</span><span class=\"p\">)</span>\n<span class=\"n\">my_df</span> <span class=\"o\">=</span> <span class=\"n\">tf2pd</span><span class=\"p\">(</span><span class=\"s1\">'./tfrecords'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># S3</span>\n<span class=\"n\">pd2tf</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s1\">'s3://my-bucket/tfrecords'</span><span class=\"p\">)</span>\n<span class=\"n\">my_df</span> <span class=\"o\">=</span> <span class=\"n\">tf2pd</span><span class=\"p\">(</span><span class=\"s1\">'s3://my-bucket/tfrecords'</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"converted-types\">\n<h2>Converted types</h2>\n<div id=\"pandas-tfrecords\">\n<h3>pandas -&gt; tfrecords</h3>\n<pre>bytes, str -&gt; tf.string\nint, np.integer -&gt; tf.int64\nfloat, np.floating -&gt; tf.float32\nlist, np.ndarray of bytes, str, int, np.integer, float, np.floating -&gt; sequence of tf.string, tf.int64, tf.float32\n</pre>\n</div>\n<div id=\"tfrecords-pandas\">\n<h3>tfrecords -&gt; pandas</h3>\n<pre>tf.string -&gt; bytes\ntf.int64 -&gt; int\ntf.float32 -&gt; float\nsequence of tf.string, tf.int64, tf.float32 -&gt; list of bytes, int, float\n</pre>\n<p><strong>NB!</strong> Please pay attention it works only with <strong>one-dimentional</strong> arrays. It means <tt>[1, 2, 3]</tt> will be converted to both sides, but <tt>[[1,2,3]]</tt> <strong>won\u2019t</strong> be converted to any side. It works that, because <tt><span class=\"pre\">spark-tensorflow-connector</span></tt> works similar, and I didn\u2019t learn yet how to implement nested sequences. In order to work with <strong>nested</strong> sequences you should use <tt>reshape</tt>.</p>\n</div>\n</div>\n<div id=\"api\">\n<h2>API</h2>\n<pre><span class=\"n\">pandas_tfrecords</span><span class=\"o\">.</span><span class=\"n\">pandas_to_tfrecords</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">folder</span><span class=\"p\">,</span> <span class=\"n\">compression_type</span><span class=\"o\">=</span><span class=\"s1\">'GZIP'</span><span class=\"p\">,</span> <span class=\"n\">compression_level</span><span class=\"o\">=</span><span class=\"mi\">9</span><span class=\"p\">,</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">max_mb</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">)</span>\n</pre>\n<p>Arguments:</p>\n<ul>\n<li><tt>df</tt> - pandas dataframe. Please keep in mind above info about nested sequences.</li>\n<li><tt>folder</tt> - folder to save tfrecords, local or S3. Please be sure that it doesn\u2019t contain other files or folders, if you want to read from this folder then.</li>\n<li><tt><span class=\"pre\">compression_type='GZIP'</span></tt> - compression types: <tt>'GZIP'</tt>, <tt>'ZLIB'</tt>, <tt>None</tt>. If <tt>None</tt> not compressed.</li>\n<li><tt>compression_level=9</tt> - compression level 0\u20269.</li>\n<li><tt>columns=None</tt> - list of columns to save, if <tt>None</tt> all columns will be saved.</li>\n<li><tt>max_mb=50</tt> - maximum size of uncompressed data to save in single file. If dataframe total size is bigger than this limit, then it will be splitted to several files. If <tt>None</tt> it isn\u2019t limited and single file will be saved.</li>\n</ul>\n<p>alias <tt>pandas_tfrecords.pd2tf</tt></p>\n<pre><span class=\"n\">pandas_tfrecords</span><span class=\"o\">.</span><span class=\"n\">tfrecords_to_pandas</span><span class=\"p\">(</span><span class=\"n\">file_paths</span><span class=\"p\">,</span> <span class=\"n\">schema</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">compression_type</span><span class=\"o\">=</span><span class=\"s1\">'auto'</span><span class=\"p\">,</span> <span class=\"n\">cast</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>Arguments:</p>\n<ul>\n<li><tt>file_paths</tt> - One or sequence of file paths or folders, local or S3, to read tfrecords from.</li>\n<li><tt>schema=None</tt> - If <tt>None</tt> schema will be detected automatically. But you can specify which columns you want to read only. It should be a dict, which keys are column names and values are column data types: <tt>str</tt> (or <tt>bytes</tt>), <tt>int</tt>, <tt>float</tt>, and for sequences it should be wrapped to <tt>list</tt>: <tt>[str]</tt> (or <tt>[bytes]</tt>), <tt>[int]</tt>, <tt>[float]</tt>. For example:</li>\n</ul>\n<pre><span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s1\">'A'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">],</span> <span class=\"s1\">'B'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'b'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">],</span> <span class=\"s1\">'C'</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">]]})</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n   <span class=\"n\">A</span>  <span class=\"n\">B</span>       <span class=\"n\">C</span>\n<span class=\"mi\">0</span>  <span class=\"mi\">1</span>  <span class=\"n\">a</span>  <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n<span class=\"mi\">1</span>  <span class=\"mi\">2</span>  <span class=\"n\">b</span>  <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">]</span>\n<span class=\"mi\">2</span>  <span class=\"mi\">3</span>  <span class=\"n\">c</span>  <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">]</span>\n\n<span class=\"n\">pd2tf</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"s1\">'./tfrecords'</span><span class=\"p\">)</span>\n<span class=\"n\">tf2pd</span><span class=\"p\">(</span><span class=\"s1\">'./tfrecords'</span><span class=\"p\">,</span> <span class=\"n\">schema</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'A'</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"s1\">'C'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]})</span>\n   <span class=\"n\">A</span>       <span class=\"n\">C</span>\n<span class=\"mi\">0</span>  <span class=\"mi\">1</span>  <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]</span>\n<span class=\"mi\">1</span>  <span class=\"mi\">2</span>  <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">]</span>\n<span class=\"mi\">2</span>  <span class=\"mi\">3</span>  <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">]</span>\n</pre>\n<ul>\n<li><tt><span class=\"pre\">compression_type='auto'</span></tt> - compression type: <tt>'auto'</tt>, <tt>'GZIP'</tt>, <tt>'ZLIB'</tt>, <tt>None</tt>.</li>\n<li><tt>cast=True</tt> - if <tt>True</tt> it casts <tt>bytes</tt> data after converting from <tt>tf.string</tt>. It tries to cast it to <tt>int</tt>, <tt>float</tt> and <tt>str</tt> sequentially. If it\u2019s not possible, otherwise keeps as is.</li>\n</ul>\n<p>alias <tt>pandas_tfrecords.tf2pd</tt></p>\n</div>\n\n          </div>"}, "last_serial": 6729653, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "17daca2f10cafd9323ea93808d9815f6", "sha256": "34501ea5dc9952f8f377ef72e0a574a7c0bc90c1f9b226e565cfaed1f571cfba"}, "downloads": -1, "filename": "pandas_tfrecords-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "17daca2f10cafd9323ea93808d9815f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5849, "upload_time": "2020-02-20T19:52:41", "upload_time_iso_8601": "2020-02-20T19:52:41.418789Z", "url": "https://files.pythonhosted.org/packages/69/45/c92728714da752d722ef88607420139f3122c21bf98fdb489c8fb8b48681/pandas_tfrecords-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7ab241e34bdbb1821f1f2f5ecd226b7f", "sha256": "f0a48767ab9bcd6775d304268fd9f45d243e58f741ccdfc5b4319fd8a1d61f23"}, "downloads": -1, "filename": "pandas-tfrecords-0.1.tar.gz", "has_sig": false, "md5_digest": "7ab241e34bdbb1821f1f2f5ecd226b7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5036, "upload_time": "2020-02-20T19:52:43", "upload_time_iso_8601": "2020-02-20T19:52:43.925808Z", "url": "https://files.pythonhosted.org/packages/ab/d5/c3e7881b26b92653126ae743968ef0e6cc17fefa25f7af7aca059ef95ed4/pandas-tfrecords-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "95af9ec9060035a23f5f069d235ccd23", "sha256": "b93e3db7301f4ea799a9601e14fdf3f994906957f25c6b9ae6451219c079d6a8"}, "downloads": -1, "filename": "pandas_tfrecords-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "95af9ec9060035a23f5f069d235ccd23", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6030, "upload_time": "2020-02-21T03:50:40", "upload_time_iso_8601": "2020-02-21T03:50:40.988644Z", "url": "https://files.pythonhosted.org/packages/90/0f/4b3a406e3f8bfe669faacb5da4d5c324180ba5db7dff612877851b4037e2/pandas_tfrecords-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ef4bfddeb18f66c66902673c234cab6", "sha256": "3106717e997b86df82b99475235fd050f8bf142ec76ae14accbe127adc066390"}, "downloads": -1, "filename": "pandas-tfrecords-0.1.1.tar.gz", "has_sig": false, "md5_digest": "9ef4bfddeb18f66c66902673c234cab6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5216, "upload_time": "2020-02-21T03:50:42", "upload_time_iso_8601": "2020-02-21T03:50:42.534900Z", "url": "https://files.pythonhosted.org/packages/30/6c/ef5ca4b2fb5769aaec9a56a86ffaa145b2b9e6f08d63c6cca9fa3f66b60f/pandas-tfrecords-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "63bbcb52522d1a603752fabd2db7e0a4", "sha256": "542943aa2ca500eac7a77a724bf03c2f57cc1405c027e22baecac1bd7dc5a686"}, "downloads": -1, "filename": "pandas_tfrecords-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "63bbcb52522d1a603752fabd2db7e0a4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6091, "upload_time": "2020-02-21T04:02:39", "upload_time_iso_8601": "2020-02-21T04:02:39.433201Z", "url": "https://files.pythonhosted.org/packages/14/07/1f90a8028cc50d044113cec8009ef533d7a4c27842ef15cc1878b9b50199/pandas_tfrecords-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "07669e9ba9b2f8738927d3c6fa1b32c5", "sha256": "3bcaa5e2735dbc969d3c44be68b1849d84559e8c9b3e0c802983a6d90b46f4af"}, "downloads": -1, "filename": "pandas-tfrecords-0.1.2.tar.gz", "has_sig": false, "md5_digest": "07669e9ba9b2f8738927d3c6fa1b32c5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5335, "upload_time": "2020-02-21T04:02:41", "upload_time_iso_8601": "2020-02-21T04:02:41.311323Z", "url": "https://files.pythonhosted.org/packages/9f/91/768bc877c73ee6440476fb8eb265c7d277cf8e47e3b32180a2101a6ba988/pandas-tfrecords-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "4990900fcf2a1238d3ba63ed9de7a5d9", "sha256": "7439b5bdf35ce5c33e283bb3e1cf240ac454f5b215a5b5f747a0e9b74eb358fa"}, "downloads": -1, "filename": "pandas_tfrecords-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "4990900fcf2a1238d3ba63ed9de7a5d9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6092, "upload_time": "2020-02-21T17:55:11", "upload_time_iso_8601": "2020-02-21T17:55:11.910715Z", "url": "https://files.pythonhosted.org/packages/f1/cd/a63e5c37d0a15693da02c1601c32d281a9f5c0048c07b9cc7a53f5251216/pandas_tfrecords-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "418d0e0254f9e4cd812378c54f788dbe", "sha256": "61426b5689200976a681e238e24a7eff5f1fce462b451a2d9c3e2f38ca013df1"}, "downloads": -1, "filename": "pandas-tfrecords-0.1.3.tar.gz", "has_sig": false, "md5_digest": "418d0e0254f9e4cd812378c54f788dbe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5336, "upload_time": "2020-02-21T17:55:13", "upload_time_iso_8601": "2020-02-21T17:55:13.031781Z", "url": "https://files.pythonhosted.org/packages/f7/5c/47c84a82d7ae84c52eddb57eae5443f6e13a01f3a1fde607c41b25e3acc1/pandas-tfrecords-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "a99c08e576cbf29ad0502f4579d99069", "sha256": "4344821d0798107339b80af5117e420a68bbae7af155d0c7611b8f95de36b7bb"}, "downloads": -1, "filename": "pandas_tfrecords-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "a99c08e576cbf29ad0502f4579d99069", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6132, "upload_time": "2020-03-01T19:27:14", "upload_time_iso_8601": "2020-03-01T19:27:14.161886Z", "url": "https://files.pythonhosted.org/packages/e8/f7/72f9264762eabf2f67e8dc0fff4324cb866438c2a37390ab2f6ea36bef1a/pandas_tfrecords-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f396a3d1e13a70ea943371eb29482d11", "sha256": "d14d26ea75fcd0ebe97e8847305a93754a01ff7f34ef21a7eccb375d5ccbf314"}, "downloads": -1, "filename": "pandas-tfrecords-0.1.4.tar.gz", "has_sig": false, "md5_digest": "f396a3d1e13a70ea943371eb29482d11", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5367, "upload_time": "2020-03-01T19:27:15", "upload_time_iso_8601": "2020-03-01T19:27:15.791819Z", "url": "https://files.pythonhosted.org/packages/f1/a3/ecc4b0501596fe8196a647c019a7f9266fd9c9e0ea28caa8c4a5a026a654/pandas-tfrecords-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a99c08e576cbf29ad0502f4579d99069", "sha256": "4344821d0798107339b80af5117e420a68bbae7af155d0c7611b8f95de36b7bb"}, "downloads": -1, "filename": "pandas_tfrecords-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "a99c08e576cbf29ad0502f4579d99069", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6132, "upload_time": "2020-03-01T19:27:14", "upload_time_iso_8601": "2020-03-01T19:27:14.161886Z", "url": "https://files.pythonhosted.org/packages/e8/f7/72f9264762eabf2f67e8dc0fff4324cb866438c2a37390ab2f6ea36bef1a/pandas_tfrecords-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f396a3d1e13a70ea943371eb29482d11", "sha256": "d14d26ea75fcd0ebe97e8847305a93754a01ff7f34ef21a7eccb375d5ccbf314"}, "downloads": -1, "filename": "pandas-tfrecords-0.1.4.tar.gz", "has_sig": false, "md5_digest": "f396a3d1e13a70ea943371eb29482d11", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5367, "upload_time": "2020-03-01T19:27:15", "upload_time_iso_8601": "2020-03-01T19:27:15.791819Z", "url": "https://files.pythonhosted.org/packages/f1/a3/ecc4b0501596fe8196a647c019a7f9266fd9c9e0ea28caa8c4a5a026a654/pandas-tfrecords-0.1.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:59:27 2020"}