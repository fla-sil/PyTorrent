{"info": {"author": "TripleO Team", "author_email": "openstack-discuss@lists.openstack.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Information Technology", "Intended Audience :: System Administrators", "License :: OSI Approved :: Apache Software License", "Topic :: Utilities"], "description": "collect-logs\n============\n\nAn Ansible role for aggregating logs from different nodes.\n\nRequirements\n------------\n\nThis role gathers logs and debug information from a target system and\ncollates them in a designated directory, ``artcl_collect_dir``, on the\nlocalhost.\n\nAdditionally, the role will convert templated bash scripts, created and\nused by TripleO-Quickstart during deployment, into rST files. These rST\nfiles are combined with static rST files and fed into Sphinx to create\nuser friendly post-build-documentation specific to an original\ndeployment.\n\nFinally, the role optionally handles uploading these logs to a rsync\nserver or to an OpenStack Swift object storage. Logs from Swift can be\nexposed with\n`os-loganalyze <https://github.com/openstack-infra/os-loganalyze>`__.\n\nRole Variables\n--------------\n\nCollection related\n~~~~~~~~~~~~~~~~~~\n\n-  ``artcl_collect_list`` \u2013 A list of files and directories to gather\n   from the target. Directories are collected recursively and need to\n   end with a \u201c/\u201d to get collected. Should be specified as a YaML list,\n   e.g.:\n\n.. code:: yaml\n\n   artcl_collect_list:\n       - /etc/nova/\n       - /home/stack/*.log\n       - /var/log/\n\n-  ``artcl_collect_list_append`` \u2013 A list of files and directories to be\n   appended in the default list. This is useful for users that want to\n   keep the original list and just add more relevant paths.\n-  ``artcl_exclude_list`` \u2013 A list of files and directories to exclude\n   from collecting. This list is passed to rsync as an exclude filter\n   and it takes precedence over the collection list. For details see the\n   \u201cFILTER RULES\u201d topic in the rsync man page.\n-  ``artcl_collect_dir`` \u2013 A local directory where the logs should be\n   gathered, without a trailing slash.\n-  ``artcl_gzip_only``: false/true \u2013 When true, gathered files are\n   gzipped one by one in ``artcl_collect_dir``, when false, a tar.gz\n   file will contain all the logs.\n\nDocumentation generation related\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n-  ``artcl_gen_docs``: false/true \u2013 If true, the role will use build\n   artifacts and Sphinx and produce user friendly documentation\n   (default: false)\n-  ``artcl_docs_source_dir`` \u2013 a local directory that serves as the\n   Sphinx source directory.\n-  ``artcl_docs_build_dir`` \u2013 A local directory that serves as the\n   Sphinx build output directory.\n-  ``artcl_create_docs_payload`` \u2013 Dictionary of lists that direct what\n   and how to construct documentation.\n\n   -  ``included_deployment_scripts`` \u2013 List of templated bash scripts\n      to be converted to rST files.\n   -  ``included_deployment_scripts`` \u2013 List of static rST files that\n      will be included in the output documentation.\n   -  ``table_of_contents`` \u2013 List that defines the order in which rST\n      files will be laid out in the output documentation.\n\n-  ``artcl_verify_sphinx_build`` \u2013 false/true \u2013 If true, verify items\n   defined in ``artcl_create_docs_payload.table_of_contents`` exist in\n   sphinx generated index.html (default: false)\n\n.. code:: yaml\n\n   artcl_create_docs_payload:\n     included_deployment_scripts:\n       - undercloud-install\n       - undercloud-post-install\n     included_static_docs:\n       - env-setup-virt\n     table_of_contents:\n       - env-setup-virt\n       - undercloud-install\n       - undercloud-post-install\n\nPublishing related\n~~~~~~~~~~~~~~~~~~\n\n-  ``artcl_publish``: true/false \u2013 If true, the role will attempt to\n   rsync logs to the target specified by ``artcl_rsync_url``. Uses\n   ``BUILD_URL``, ``BUILD_TAG`` vars from the environment (set during a\n   Jenkins job run) and requires the next to variables to be set.\n-  ``artcl_txt_rename``: false/true \u2013 rename text based file to end in\n   .txt.gz to make upstream log servers display them in the browser\n   instead of offering them to download\n-  ``artcl_publish_timeout``: the maximum seconds the role can spend\n   uploading the logs, the default is 1800 (30 minutes)\n-  ``artcl_use_rsync``: false/true \u2013 use rsync to upload the logs\n-  ``artcl_rsync_use_daemon``: false/true \u2013 use rsync daemon instead of\n   ssh to connect\n-  ``artcl_rsync_url`` \u2013 rsync target for uploading the logs. The\n   localhost needs to have passwordless authentication to the target or\n   the ``PROVISIONER_KEY`` Var specificed in the environment.\n-  ``artcl_use_swift``: false/true \u2013 use swift object storage to publish\n   the logs\n-  ``artcl_swift_auth_url`` \u2013 the OpenStack auth URL for Swift\n-  ``artcl_swift_username`` \u2013 OpenStack username for Swift\n-  ``artcl_swift_password`` \u2013 password for the Swift user\n-  ``artcl_swift_tenant_name`` \u2013 OpenStack tenant name for Swift\n-  ``artcl_swift_container`` \u2013 the name of the Swift container to use,\n   default is ``logs``\n-  ``artcl_swift_delete_after`` \u2013 The number of seconds after which\n   Swift will remove the uploaded objects, the default is 2678400\n   seconds = 31 days.\n-  ``artcl_artifact_url`` \u2013 a HTTP URL at which the uploaded logs will\n   be accessible after upload.\n-  ``artcl_collect_sosreport`` \u2013 true/false \u2013 If true, create and\n   collect a sosreport for each host.\n\nExample Playbook\n----------------\n\n.. code:: yaml\n\n   ---\n   - name: Gather logs\n     hosts: all:!localhost\n     roles:\n       - collect-logs\n\nTemplated Bash to rST Conversion Notes\n--------------------------------------\n\nTemplated bash scripts used during deployment are converted to rST files\nduring the ``create-docs`` portion of the role\u2019s call. Shell scripts are\nfed into an awk script and output as restructured text. The awk script\nhas several simple rules:\n\n1. Only lines between ``### ---start_docs`` and ``### ---stop_docs``\n   will be parsed.\n2. Lines containing ``# nodoc`` will be excluded.\n3. Lines containing ``## ::`` indicate subsequent lines should be\n   formatted as code blocks\n4. Other lines beginning with ``## <anything else>`` will have the\n   prepended ``##`` removed. This is how and where general rST\n   formatting is added.\n5. All other lines, including shell comments, will be indented by four\n   spaces.\n\nEnabling sosreport Collection\n-----------------------------\n\n`sosreport <https://github.com/sosreport/sos>`__ is a unified tool for\ncollecting system logs and other debug information. To enable creation\nof sosreport(s) with this role, create a custom config (you can use\ncentosci-logs.yml as a template) and ensure that\n``artcl_collect_sosreport: true`` is set.\n\nLicense\n-------\n\nApache 2.0\n\nAuthor Information\n------------------\n\nRDO-CI Team\n\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://opendev.org/openstack/ansible-role-collect-logs", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "ansible-role-collect-logs", "package_url": "https://pypi.org/project/ansible-role-collect-logs/", "platform": "", "project_url": "https://pypi.org/project/ansible-role-collect-logs/", "project_urls": {"Homepage": "https://opendev.org/openstack/ansible-role-collect-logs"}, "release_url": "https://pypi.org/project/ansible-role-collect-logs/1.0.0/", "requires_dist": ["pbr (>=1.6)", "ansible (>=2.5)"], "requires_python": "", "summary": "ansible-role-collect-logs - An Ansible role for aggregating logs from different nodes.", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>An Ansible role for aggregating logs from different nodes.</p>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<p>This role gathers logs and debug information from a target system and\ncollates them in a designated directory, <tt>artcl_collect_dir</tt>, on the\nlocalhost.</p>\n<p>Additionally, the role will convert templated bash scripts, created and\nused by TripleO-Quickstart during deployment, into rST files. These rST\nfiles are combined with static rST files and fed into Sphinx to create\nuser friendly post-build-documentation specific to an original\ndeployment.</p>\n<p>Finally, the role optionally handles uploading these logs to a rsync\nserver or to an OpenStack Swift object storage. Logs from Swift can be\nexposed with\n<a href=\"https://github.com/openstack-infra/os-loganalyze\" rel=\"nofollow\">os-loganalyze</a>.</p>\n</div>\n<div id=\"role-variables\">\n<h2>Role Variables</h2>\n<div id=\"collection-related\">\n<h3>Collection related</h3>\n<ul>\n<li><tt>artcl_collect_list</tt> \u2013 A list of files and directories to gather\nfrom the target. Directories are collected recursively and need to\nend with a \u201c/\u201d to get collected. Should be specified as a YaML list,\ne.g.:</li>\n</ul>\n<pre><span class=\"nt\">artcl_collect_list</span><span class=\"p\">:</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">/etc/nova/</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">/home/stack/*.log</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">/var/log/</span>\n</pre>\n<ul>\n<li><tt>artcl_collect_list_append</tt> \u2013 A list of files and directories to be\nappended in the default list. This is useful for users that want to\nkeep the original list and just add more relevant paths.</li>\n<li><tt>artcl_exclude_list</tt> \u2013 A list of files and directories to exclude\nfrom collecting. This list is passed to rsync as an exclude filter\nand it takes precedence over the collection list. For details see the\n\u201cFILTER RULES\u201d topic in the rsync man page.</li>\n<li><tt>artcl_collect_dir</tt> \u2013 A local directory where the logs should be\ngathered, without a trailing slash.</li>\n<li><tt>artcl_gzip_only</tt>: false/true \u2013 When true, gathered files are\ngzipped one by one in <tt>artcl_collect_dir</tt>, when false, a tar.gz\nfile will contain all the logs.</li>\n</ul>\n</div>\n<div id=\"documentation-generation-related\">\n<h3>Documentation generation related</h3>\n<ul>\n<li><tt>artcl_gen_docs</tt>: false/true \u2013 If true, the role will use build\nartifacts and Sphinx and produce user friendly documentation\n(default: false)</li>\n<li><tt>artcl_docs_source_dir</tt> \u2013 a local directory that serves as the\nSphinx source directory.</li>\n<li><tt>artcl_docs_build_dir</tt> \u2013 A local directory that serves as the\nSphinx build output directory.</li>\n<li><tt>artcl_create_docs_payload</tt> \u2013 Dictionary of lists that direct what\nand how to construct documentation.<ul>\n<li><tt>included_deployment_scripts</tt> \u2013 List of templated bash scripts\nto be converted to rST files.</li>\n<li><tt>included_deployment_scripts</tt> \u2013 List of static rST files that\nwill be included in the output documentation.</li>\n<li><tt>table_of_contents</tt> \u2013 List that defines the order in which rST\nfiles will be laid out in the output documentation.</li>\n</ul>\n</li>\n<li><tt>artcl_verify_sphinx_build</tt> \u2013 false/true \u2013 If true, verify items\ndefined in <tt>artcl_create_docs_payload.table_of_contents</tt> exist in\nsphinx generated index.html (default: false)</li>\n</ul>\n<pre><span class=\"nt\">artcl_create_docs_payload</span><span class=\"p\">:</span>\n  <span class=\"nt\">included_deployment_scripts</span><span class=\"p\">:</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">undercloud-install</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">undercloud-post-install</span>\n  <span class=\"nt\">included_static_docs</span><span class=\"p\">:</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">env-setup-virt</span>\n  <span class=\"nt\">table_of_contents</span><span class=\"p\">:</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">env-setup-virt</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">undercloud-install</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">undercloud-post-install</span>\n</pre>\n</div>\n<div id=\"publishing-related\">\n<h3>Publishing related</h3>\n<ul>\n<li><tt>artcl_publish</tt>: true/false \u2013 If true, the role will attempt to\nrsync logs to the target specified by <tt>artcl_rsync_url</tt>. Uses\n<tt>BUILD_URL</tt>, <tt>BUILD_TAG</tt> vars from the environment (set during a\nJenkins job run) and requires the next to variables to be set.</li>\n<li><tt>artcl_txt_rename</tt>: false/true \u2013 rename text based file to end in\n.txt.gz to make upstream log servers display them in the browser\ninstead of offering them to download</li>\n<li><tt>artcl_publish_timeout</tt>: the maximum seconds the role can spend\nuploading the logs, the default is 1800 (30 minutes)</li>\n<li><tt>artcl_use_rsync</tt>: false/true \u2013 use rsync to upload the logs</li>\n<li><tt>artcl_rsync_use_daemon</tt>: false/true \u2013 use rsync daemon instead of\nssh to connect</li>\n<li><tt>artcl_rsync_url</tt> \u2013 rsync target for uploading the logs. The\nlocalhost needs to have passwordless authentication to the target or\nthe <tt>PROVISIONER_KEY</tt> Var specificed in the environment.</li>\n<li><tt>artcl_use_swift</tt>: false/true \u2013 use swift object storage to publish\nthe logs</li>\n<li><tt>artcl_swift_auth_url</tt> \u2013 the OpenStack auth URL for Swift</li>\n<li><tt>artcl_swift_username</tt> \u2013 OpenStack username for Swift</li>\n<li><tt>artcl_swift_password</tt> \u2013 password for the Swift user</li>\n<li><tt>artcl_swift_tenant_name</tt> \u2013 OpenStack tenant name for Swift</li>\n<li><tt>artcl_swift_container</tt> \u2013 the name of the Swift container to use,\ndefault is <tt>logs</tt></li>\n<li><tt>artcl_swift_delete_after</tt> \u2013 The number of seconds after which\nSwift will remove the uploaded objects, the default is 2678400\nseconds = 31 days.</li>\n<li><tt>artcl_artifact_url</tt> \u2013 a HTTP URL at which the uploaded logs will\nbe accessible after upload.</li>\n<li><tt>artcl_collect_sosreport</tt> \u2013 true/false \u2013 If true, create and\ncollect a sosreport for each host.</li>\n</ul>\n</div>\n</div>\n<div id=\"example-playbook\">\n<h2>Example Playbook</h2>\n<pre><span class=\"nn\">---</span>\n<span class=\"p-Indicator\">-</span> <span class=\"nt\">name</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">Gather logs</span>\n  <span class=\"nt\">hosts</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">all:!localhost</span>\n  <span class=\"nt\">roles</span><span class=\"p\">:</span>\n    <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">collect-logs</span>\n</pre>\n</div>\n<div id=\"templated-bash-to-rst-conversion-notes\">\n<h2>Templated Bash to rST Conversion Notes</h2>\n<p>Templated bash scripts used during deployment are converted to rST files\nduring the <tt><span class=\"pre\">create-docs</span></tt> portion of the role\u2019s call. Shell scripts are\nfed into an awk script and output as restructured text. The awk script\nhas several simple rules:</p>\n<ol>\n<li>Only lines between <tt>### <span class=\"pre\">---start_docs</span></tt> and <tt>### <span class=\"pre\">---stop_docs</span></tt>\nwill be parsed.</li>\n<li>Lines containing <tt># nodoc</tt> will be excluded.</li>\n<li>Lines containing <tt>## ::</tt> indicate subsequent lines should be\nformatted as code blocks</li>\n<li>Other lines beginning with <tt>## &lt;anything else&gt;</tt> will have the\nprepended <tt>##</tt> removed. This is how and where general rST\nformatting is added.</li>\n<li>All other lines, including shell comments, will be indented by four\nspaces.</li>\n</ol>\n</div>\n<div id=\"enabling-sosreport-collection\">\n<h2>Enabling sosreport Collection</h2>\n<p><a href=\"https://github.com/sosreport/sos\" rel=\"nofollow\">sosreport</a> is a unified tool for\ncollecting system logs and other debug information. To enable creation\nof sosreport(s) with this role, create a custom config (you can use\ncentosci-logs.yml as a template) and ensure that\n<tt>artcl_collect_sosreport: true</tt> is set.</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>Apache 2.0</p>\n</div>\n<div id=\"author-information\">\n<h2>Author Information</h2>\n<p>RDO-CI Team</p>\n</div>\n\n          </div>"}, "last_serial": 5576893, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "24145719d101c1afee39370d8f7afe30", "sha256": "41aa9d800108d934adb347dfcc537608d6dc3ded7383abdc1b4b6fd984c53e8a"}, "downloads": -1, "filename": "ansible_role_collect_logs-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "24145719d101c1afee39370d8f7afe30", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 121030, "upload_time": "2019-07-24T09:51:59", "upload_time_iso_8601": "2019-07-24T09:51:59.706781Z", "url": "https://files.pythonhosted.org/packages/a6/37/08dd01c98a52c1b67864ef819e5dc00149dbebc59898dec536662c07c29a/ansible_role_collect_logs-1.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ae8c04e6470d12053973d9b8814ab8cc", "sha256": "3edb1e61ca64a822893743136fa1ce8c677b13c719d14ddde2a72c1ae8205b74"}, "downloads": -1, "filename": "ansible-role-collect-logs-1.0.0.tar.gz", "has_sig": false, "md5_digest": "ae8c04e6470d12053973d9b8814ab8cc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 107998, "upload_time": "2019-07-24T09:52:04", "upload_time_iso_8601": "2019-07-24T09:52:04.402942Z", "url": "https://files.pythonhosted.org/packages/32/95/58b0cca3f8b2d668cbaa9405b2c72c3df28249fa055ff74287b92f1f3ff1/ansible-role-collect-logs-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "24145719d101c1afee39370d8f7afe30", "sha256": "41aa9d800108d934adb347dfcc537608d6dc3ded7383abdc1b4b6fd984c53e8a"}, "downloads": -1, "filename": "ansible_role_collect_logs-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "24145719d101c1afee39370d8f7afe30", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 121030, "upload_time": "2019-07-24T09:51:59", "upload_time_iso_8601": "2019-07-24T09:51:59.706781Z", "url": "https://files.pythonhosted.org/packages/a6/37/08dd01c98a52c1b67864ef819e5dc00149dbebc59898dec536662c07c29a/ansible_role_collect_logs-1.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ae8c04e6470d12053973d9b8814ab8cc", "sha256": "3edb1e61ca64a822893743136fa1ce8c677b13c719d14ddde2a72c1ae8205b74"}, "downloads": -1, "filename": "ansible-role-collect-logs-1.0.0.tar.gz", "has_sig": false, "md5_digest": "ae8c04e6470d12053973d9b8814ab8cc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 107998, "upload_time": "2019-07-24T09:52:04", "upload_time_iso_8601": "2019-07-24T09:52:04.402942Z", "url": "https://files.pythonhosted.org/packages/32/95/58b0cca3f8b2d668cbaa9405b2c72c3df28249fa055ff74287b92f1f3ff1/ansible-role-collect-logs-1.0.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:18:03 2020"}