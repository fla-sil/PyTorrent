{"info": {"author": "Xi He Xie", "author_email": "axiezai@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# Pipetography\n> Nipype and mrtrix3 based pre-/post- processing pipeline for brain diffusion-MRI and generation of structural connectomes of the brain.\n\n\n```\n%%capture\n#hide\nfrom pipetography.core import *\n```\n\nThis repo currently only has pre-processing capabilities! More will be added in the near future.\n\n## Install\n\nThis pip install function doesn't work yet! Don't do it yet! It will work with the first release!\n\n`pip install pipetography`\n\nSince `pipetography` is a `Nipype` wrapper around `mrtrix3`, `ANTs`, and `FSL`, you have to follow their installation instructions and set them up appropriately on your machine as well:    \n - [mrtrix3](https://mrtrix.readthedocs.io/en/latest/installation/before_install.html)\n\n - [ANTs](https://github.com/ANTsX/ANTs/wiki/Compiling-ANTs-on-Linux-and-Mac-OS)\n\n - [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation)\n\n## How to use\n\n#### Use as connected Nipype nodes for DWI preprocessing\nWe will wrap all of our tasks in `Nipype`'s `Nodes`\n\nNipype wraps the tasks into Nodes and connects them into an automated workflow that can run parallel tasks, the preprocessing workflow includes several functions, some of which require user inputs. We will go over them here.\n\n```\nfrom pipetography.pipeline import pipeline\n\npreproc_dwi = pipeline()\n```\n\n    Creating layout of data directory, might take a while if there are a lot of subjects\n\n\n```\n#example\npreproc_dwi.check_environment()\n```\n\n    FSLOUTPUTTYPE is valid\n    FSLDIR is valid\n    ANTS is valid\n    mrtrix3 is valid\n\n\n```\n#example\n#set output destination:\npreproc_dwi.set_datasink()\n```\n\n    Please indicate an output directory:  'output'\n\n\nTake a look at what's in the `pipeline`:\n\n```\n#example\npreproc_dwi.__dict__\n```\n\n\n\n\n    {'data_dir': 'data',\n     'sub_list': ['11048'],\n     'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0,\n     'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n     'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*',\n     'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n      'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'},\n     'sub_source': data_source,\n     'select_files': select_files,\n     'bfiles_input': select_bfiles,\n     'denoise': denoise,\n     'ringing': ringing_removal,\n     'ants_bfc': ants_bias_correct,\n     'mrt_preproc': mrtrix3_preproc,\n     'atlas_dir': None,\n     'atlas_names': None,\n     'atlas_source': None,\n     'select_atlas': None,\n     'b0extract': dwiextract,\n     'b0mean': mrmath,\n     'fsl_bet': brain_extraction,\n     'linear_coreg': linear_registration,\n     'nonlinear_coreg': nonlinear_registration,\n     'datasink': datasink,\n     'workflow': None}\n\n\n\nWe can set up preprocessing pipeline with default parameters:\n\n```\n#example\npreproc_dwi.default_setup()\n```\n\n    Please indicate directory with atlas volumes:  '/Users/xxie/lab/atlases'\n    Please indicate list of selected atlas names:  ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii']\n\n\n    {'data_dir': 'data', 'sub_list': ['11048'], 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0, 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*', 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'}, 'sub_source': default_workflow.data_source, 'select_files': default_workflow.select_files, 'bfiles_input': default_workflow.select_bfiles, 'denoise': default_workflow.denoise, 'ringing': default_workflow.ringing_removal, 'ants_bfc': default_workflow.ants_bias_correct, 'mrt_preproc': default_workflow.mrtrix3_preproc, 'atlas_dir': \"'/Users/xxie/lab/atlases'\", 'atlas_names': ['[', \"'\", 'B', 'N', '_', 'A', 't', 'l', 'a', 's', '_', '2', '4', '6', '_', '2', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ',', \"'\", 'D', 'K', '_', 'a', 't', 'l', 'a', 's', '8', '6', '_', '1', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ']'], 'atlas_source': default_workflow.atlas_source, 'select_atlas': default_workflow.select_atlases, 'b0extract': default_workflow.dwiextract, 'b0mean': default_workflow.mrmath, 'fsl_bet': default_workflow.brain_extraction, 'linear_coreg': default_workflow.linear_registration, 'nonlinear_coreg': default_workflow.nonlinear_registration, 'datasink': default_workflow.datasink, 'workflow': default_workflow}\n\n\nThen you can simply call `preproc_dwi.draw_pipeline()` to visualize the workflow as a PNG image, or `preproc_dwi.run_pipeline()` to run the default pipeline. OR we can fill this in one by one in detail:\n\nFirst, let's tell the pipeline where we have atlas volumes and which ones to use:\n\n```\n#example\npreproc_dwi.atlas_inputs(atlas_dir = '/Users/xxie/lab/atlases', atlas_names = ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii'])\n```\n\nNext, we give inputs to the `denoise` Node:\n\n```\n#example\npreproc_dwi.denoise_inputs(force = True, quiet = True)\n# we kept everything else default, like output names and number of threads.\n```\n\nGibbs ringing removal:\n\n```\n#example\npreproc_dwi.DeGibbs_inputs() # keep it default\nprint('Output file name is ' + preproc_dwi.ringing.inputs.out_file)\n```\n\n    Output file name is ringing_removed.nii.gz\n\n\nANTs Bias Field Correction:\n\n```\n#example\npreproc_dwi.ants_bfc_inputs() # keep it default:\npreproc_dwi.ants_bfc.inputs.print_traits\n```\n\n\n\n\n    <bound method HasTraits.print_traits of \n    args = <undefined>\n    dims = 4\n    environ = {}\n    in_file = <undefined>\n    out_file = biasfieldcorrected.nii.gz\n    >\n\n\n\n`in_file` is undefined because we will feed it this information once we connect our individual functions.\n\nNext let's set up eddy current/motion correction, we need to tell the pipeline the phase encoding settings and inputs to eddy algorithm:\n\n```\n#example\npreproc_dwi.mrt_preproc_inputs(\n    rpe_options=\"-rpe_none\",\n    pe_dir=\"j-\",\n    eddy_options='\"--slm=linear --verbose\"',\n    nthreads=4,\n)\npreproc_dwi.mrt_preproc.inputs.print_traits\n```\n\n\n\n\n    <bound method HasTraits.print_traits of \n    args = <undefined>\n    eddy_options = \"--slm=linear --verbose\"\n    environ = {}\n    grad_fsl = <undefined>\n    in_file = <undefined>\n    nthreads = 4\n    out_file = preproc.nii.gz\n    pe_dir = j-\n    rpe_options = -rpe_none\n    >\n\n\n\n`grad_fsl` and `in_file` will be input via connected workflow later\n\nNext, we set-up brain extraction from B0 volumes:\n\n```\n#example\n# Extract b0 volumes:\npreproc_dwi.b0extract_inputs() #default\n# Create average B0 volume:\npreproc_dwi.b0mean_inputs() #default\n# Extract brain from B0 average volume:\npreproc_dwi.bet_inputs() #defaults again, using FSL's BET\n```\n\nANTs registration set up:\n\n```\n#example\npreproc_dwi.linear_coreg_inputs() #defaults\npreproc_dwi.nonlinear_coreg_inputs() #defaults\npreproc_dwi.nonlinear_coreg.inputs.print_traits\n```\n\n\n\n\n    <bound method HasTraits.print_traits of \n    args = <undefined>\n    collapse_output_transforms = True\n    convergence_threshold = [1e-06]\n    convergence_window_size = [10]\n    dimension = 3\n    environ = {'NSLOTS': '1'}\n    fixed_image = <undefined>\n    fixed_image_mask = <undefined>\n    fixed_image_masks = <undefined>\n    float = <undefined>\n    initial_moving_transform = <undefined>\n    initial_moving_transform_com = <undefined>\n    initialize_transforms_per_stage = False\n    interpolation = Linear\n    interpolation_parameters = <undefined>\n    invert_initial_moving_transform = <undefined>\n    metric = ['MI']\n    metric_item_trait = <undefined>\n    metric_stage_trait = <undefined>\n    metric_weight = [1.0]\n    metric_weight_item_trait = 1.0\n    metric_weight_stage_trait = <undefined>\n    moving_image = <undefined>\n    moving_image_mask = <undefined>\n    moving_image_masks = <undefined>\n    num_threads = 1\n    number_of_iterations = [[500, 200, 200, 100]]\n    output_inverse_warped_image = <undefined>\n    output_transform_prefix = atlas_in_dwi_syn\n    output_warped_image = atlas_in_dwi_syn.nii.gz\n    radius_bins_item_trait = 5\n    radius_bins_stage_trait = <undefined>\n    radius_or_number_of_bins = [64]\n    restore_state = <undefined>\n    restrict_deformation = <undefined>\n    sampling_percentage = <undefined>\n    sampling_percentage_item_trait = <undefined>\n    sampling_percentage_stage_trait = <undefined>\n    sampling_strategy = <undefined>\n    sampling_strategy_item_trait = <undefined>\n    sampling_strategy_stage_trait = <undefined>\n    save_state = <undefined>\n    shrink_factors = [[8, 4, 2, 1]]\n    sigma_units = ['vox']\n    smoothing_sigmas = [[4.0, 2.0, 1.0, 0.0]]\n    transform_parameters = [(0.1,)]\n    transforms = ['SyN']\n    use_estimate_learning_rate_once = <undefined>\n    use_histogram_matching = True\n    verbose = False\n    winsorize_lower_quantile = 0.0\n    winsorize_upper_quantile = 1.0\n    write_composite_transform = False\n    >\n\n\n\nAll the default settings may not be optimal for your dataset, run the processing for a test image and see the intermediate results and then tweak the available inputs to improve the output image quality.\n\nNow that our pre-processing Nodes are properly setup, we can connect and create a workflow:\n\n```\n#example\npreproc_dwi.connect_nodes(wf_name = 'pipetography_workflow')\npreproc_dwi.draw_pipeline()\n```\n\nLet's take a look at the final workflow we created:\n\n```\n#example\nfrom IPython.display import Image\nImage('data/derivatives/test_run/pipetography_detailed.png')\n```\n\n\n\n\n![png](docs/images/output_31_0.png)\n\n\n\nFinally, to run the entire pipeline with our inputs. When we declare `parallel = True`, we are telling Nipype to run parallel pipelines for each iterable input, the pipeline will prompt an input for the number of processes. If you enter `4`, there will be 4 processes taking up your available computing resources:\n\n```\n#example\npreproc_dwi.run_pipeline(parallel = True)\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/axiezai/pipetography", "keywords": "diffusion-mri,tractography,neuroimaging,nipype", "license": "Apache Software License 2.0", "maintainer": "", "maintainer_email": "", "name": "pipetography", "package_url": "https://pypi.org/project/pipetography/", "platform": "", "project_url": "https://pypi.org/project/pipetography/", "project_urls": {"Homepage": "https://github.com/axiezai/pipetography"}, "release_url": "https://pypi.org/project/pipetography/0.1.0/", "requires_dist": ["dipy", "nibabel", "pybids", "matplotlib", "nipype", "fastcore (==0.1.11)"], "requires_python": ">=3.6", "summary": "Pre/Post-processing pipeline for tractography wrapped around nipype and mrtrix3", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pipetography</h1>\n<blockquote>\n<p>Nipype and mrtrix3 based pre-/post- processing pipeline for brain diffusion-MRI and generation of structural connectomes of the brain.</p>\n</blockquote>\n<pre><code>%%capture\n#hide\nfrom pipetography.core import *\n</code></pre>\n<p>This repo currently only has pre-processing capabilities! More will be added in the near future.</p>\n<h2>Install</h2>\n<p>This pip install function doesn't work yet! Don't do it yet! It will work with the first release!</p>\n<p><code>pip install pipetography</code></p>\n<p>Since <code>pipetography</code> is a <code>Nipype</code> wrapper around <code>mrtrix3</code>, <code>ANTs</code>, and <code>FSL</code>, you have to follow their installation instructions and set them up appropriately on your machine as well:</p>\n<ul>\n<li>\n<p><a href=\"https://mrtrix.readthedocs.io/en/latest/installation/before_install.html\" rel=\"nofollow\">mrtrix3</a></p>\n</li>\n<li>\n<p><a href=\"https://github.com/ANTsX/ANTs/wiki/Compiling-ANTs-on-Linux-and-Mac-OS\" rel=\"nofollow\">ANTs</a></p>\n</li>\n<li>\n<p><a href=\"https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation\" rel=\"nofollow\">FSL</a></p>\n</li>\n</ul>\n<h2>How to use</h2>\n<h4>Use as connected Nipype nodes for DWI preprocessing</h4>\n<p>We will wrap all of our tasks in <code>Nipype</code>'s <code>Nodes</code></p>\n<p>Nipype wraps the tasks into Nodes and connects them into an automated workflow that can run parallel tasks, the preprocessing workflow includes several functions, some of which require user inputs. We will go over them here.</p>\n<pre><code>from pipetography.pipeline import pipeline\n\npreproc_dwi = pipeline()\n</code></pre>\n<pre><code>Creating layout of data directory, might take a while if there are a lot of subjects\n</code></pre>\n<pre><code>#example\npreproc_dwi.check_environment()\n</code></pre>\n<pre><code>FSLOUTPUTTYPE is valid\nFSLDIR is valid\nANTS is valid\nmrtrix3 is valid\n</code></pre>\n<pre><code>#example\n#set output destination:\npreproc_dwi.set_datasink()\n</code></pre>\n<pre><code>Please indicate an output directory:  'output'\n</code></pre>\n<p>Take a look at what's in the <code>pipeline</code>:</p>\n<pre><code>#example\npreproc_dwi.__dict__\n</code></pre>\n<pre><code>{'data_dir': 'data',\n 'sub_list': ['11048'],\n 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0,\n 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*',\n 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz',\n  'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'},\n 'sub_source': data_source,\n 'select_files': select_files,\n 'bfiles_input': select_bfiles,\n 'denoise': denoise,\n 'ringing': ringing_removal,\n 'ants_bfc': ants_bias_correct,\n 'mrt_preproc': mrtrix3_preproc,\n 'atlas_dir': None,\n 'atlas_names': None,\n 'atlas_source': None,\n 'select_atlas': None,\n 'b0extract': dwiextract,\n 'b0mean': mrmath,\n 'fsl_bet': brain_extraction,\n 'linear_coreg': linear_registration,\n 'nonlinear_coreg': nonlinear_registration,\n 'datasink': datasink,\n 'workflow': None}\n</code></pre>\n<p>We can set up preprocessing pipeline with default parameters:</p>\n<pre><code>#example\npreproc_dwi.default_setup()\n</code></pre>\n<pre><code>Please indicate directory with atlas volumes:  '/Users/xxie/lab/atlases'\nPlease indicate list of selected atlas names:  ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii']\n\n\n{'data_dir': 'data', 'sub_list': ['11048'], 'layout': BIDS Layout: ...ers/xxie/lab/pipetography/data | Subjects: 1 | Sessions: 1 | Runs: 0, 'dwi_file': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*', 'sub_template': {'dwi': 'sub-{subject_id}/ses-*/dwi/sub-{subject_id}_ses-*_dwi.nii.gz', 'b_files': 'sub-{subject_id}/ses-1/dwi/sub-{subject_id}_ses-1_dwi.bv*'}, 'sub_source': default_workflow.data_source, 'select_files': default_workflow.select_files, 'bfiles_input': default_workflow.select_bfiles, 'denoise': default_workflow.denoise, 'ringing': default_workflow.ringing_removal, 'ants_bfc': default_workflow.ants_bias_correct, 'mrt_preproc': default_workflow.mrtrix3_preproc, 'atlas_dir': \"'/Users/xxie/lab/atlases'\", 'atlas_names': ['[', \"'\", 'B', 'N', '_', 'A', 't', 'l', 'a', 's', '_', '2', '4', '6', '_', '2', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ',', \"'\", 'D', 'K', '_', 'a', 't', 'l', 'a', 's', '8', '6', '_', '1', 'm', 'm', '.', 'n', 'i', 'i', \"'\", ']'], 'atlas_source': default_workflow.atlas_source, 'select_atlas': default_workflow.select_atlases, 'b0extract': default_workflow.dwiextract, 'b0mean': default_workflow.mrmath, 'fsl_bet': default_workflow.brain_extraction, 'linear_coreg': default_workflow.linear_registration, 'nonlinear_coreg': default_workflow.nonlinear_registration, 'datasink': default_workflow.datasink, 'workflow': default_workflow}\n</code></pre>\n<p>Then you can simply call <code>preproc_dwi.draw_pipeline()</code> to visualize the workflow as a PNG image, or <code>preproc_dwi.run_pipeline()</code> to run the default pipeline. OR we can fill this in one by one in detail:</p>\n<p>First, let's tell the pipeline where we have atlas volumes and which ones to use:</p>\n<pre><code>#example\npreproc_dwi.atlas_inputs(atlas_dir = '/Users/xxie/lab/atlases', atlas_names = ['BN_Atlas_246_2mm.nii','DK_atlas86_1mm.nii'])\n</code></pre>\n<p>Next, we give inputs to the <code>denoise</code> Node:</p>\n<pre><code>#example\npreproc_dwi.denoise_inputs(force = True, quiet = True)\n# we kept everything else default, like output names and number of threads.\n</code></pre>\n<p>Gibbs ringing removal:</p>\n<pre><code>#example\npreproc_dwi.DeGibbs_inputs() # keep it default\nprint('Output file name is ' + preproc_dwi.ringing.inputs.out_file)\n</code></pre>\n<pre><code>Output file name is ringing_removed.nii.gz\n</code></pre>\n<p>ANTs Bias Field Correction:</p>\n<pre><code>#example\npreproc_dwi.ants_bfc_inputs() # keep it default:\npreproc_dwi.ants_bfc.inputs.print_traits\n</code></pre>\n<pre><code>&lt;bound method HasTraits.print_traits of \nargs = &lt;undefined&gt;\ndims = 4\nenviron = {}\nin_file = &lt;undefined&gt;\nout_file = biasfieldcorrected.nii.gz\n&gt;\n</code></pre>\n<p><code>in_file</code> is undefined because we will feed it this information once we connect our individual functions.</p>\n<p>Next let's set up eddy current/motion correction, we need to tell the pipeline the phase encoding settings and inputs to eddy algorithm:</p>\n<pre><code>#example\npreproc_dwi.mrt_preproc_inputs(\n    rpe_options=\"-rpe_none\",\n    pe_dir=\"j-\",\n    eddy_options='\"--slm=linear --verbose\"',\n    nthreads=4,\n)\npreproc_dwi.mrt_preproc.inputs.print_traits\n</code></pre>\n<pre><code>&lt;bound method HasTraits.print_traits of \nargs = &lt;undefined&gt;\neddy_options = \"--slm=linear --verbose\"\nenviron = {}\ngrad_fsl = &lt;undefined&gt;\nin_file = &lt;undefined&gt;\nnthreads = 4\nout_file = preproc.nii.gz\npe_dir = j-\nrpe_options = -rpe_none\n&gt;\n</code></pre>\n<p><code>grad_fsl</code> and <code>in_file</code> will be input via connected workflow later</p>\n<p>Next, we set-up brain extraction from B0 volumes:</p>\n<pre><code>#example\n# Extract b0 volumes:\npreproc_dwi.b0extract_inputs() #default\n# Create average B0 volume:\npreproc_dwi.b0mean_inputs() #default\n# Extract brain from B0 average volume:\npreproc_dwi.bet_inputs() #defaults again, using FSL's BET\n</code></pre>\n<p>ANTs registration set up:</p>\n<pre><code>#example\npreproc_dwi.linear_coreg_inputs() #defaults\npreproc_dwi.nonlinear_coreg_inputs() #defaults\npreproc_dwi.nonlinear_coreg.inputs.print_traits\n</code></pre>\n<pre><code>&lt;bound method HasTraits.print_traits of \nargs = &lt;undefined&gt;\ncollapse_output_transforms = True\nconvergence_threshold = [1e-06]\nconvergence_window_size = [10]\ndimension = 3\nenviron = {'NSLOTS': '1'}\nfixed_image = &lt;undefined&gt;\nfixed_image_mask = &lt;undefined&gt;\nfixed_image_masks = &lt;undefined&gt;\nfloat = &lt;undefined&gt;\ninitial_moving_transform = &lt;undefined&gt;\ninitial_moving_transform_com = &lt;undefined&gt;\ninitialize_transforms_per_stage = False\ninterpolation = Linear\ninterpolation_parameters = &lt;undefined&gt;\ninvert_initial_moving_transform = &lt;undefined&gt;\nmetric = ['MI']\nmetric_item_trait = &lt;undefined&gt;\nmetric_stage_trait = &lt;undefined&gt;\nmetric_weight = [1.0]\nmetric_weight_item_trait = 1.0\nmetric_weight_stage_trait = &lt;undefined&gt;\nmoving_image = &lt;undefined&gt;\nmoving_image_mask = &lt;undefined&gt;\nmoving_image_masks = &lt;undefined&gt;\nnum_threads = 1\nnumber_of_iterations = [[500, 200, 200, 100]]\noutput_inverse_warped_image = &lt;undefined&gt;\noutput_transform_prefix = atlas_in_dwi_syn\noutput_warped_image = atlas_in_dwi_syn.nii.gz\nradius_bins_item_trait = 5\nradius_bins_stage_trait = &lt;undefined&gt;\nradius_or_number_of_bins = [64]\nrestore_state = &lt;undefined&gt;\nrestrict_deformation = &lt;undefined&gt;\nsampling_percentage = &lt;undefined&gt;\nsampling_percentage_item_trait = &lt;undefined&gt;\nsampling_percentage_stage_trait = &lt;undefined&gt;\nsampling_strategy = &lt;undefined&gt;\nsampling_strategy_item_trait = &lt;undefined&gt;\nsampling_strategy_stage_trait = &lt;undefined&gt;\nsave_state = &lt;undefined&gt;\nshrink_factors = [[8, 4, 2, 1]]\nsigma_units = ['vox']\nsmoothing_sigmas = [[4.0, 2.0, 1.0, 0.0]]\ntransform_parameters = [(0.1,)]\ntransforms = ['SyN']\nuse_estimate_learning_rate_once = &lt;undefined&gt;\nuse_histogram_matching = True\nverbose = False\nwinsorize_lower_quantile = 0.0\nwinsorize_upper_quantile = 1.0\nwrite_composite_transform = False\n&gt;\n</code></pre>\n<p>All the default settings may not be optimal for your dataset, run the processing for a test image and see the intermediate results and then tweak the available inputs to improve the output image quality.</p>\n<p>Now that our pre-processing Nodes are properly setup, we can connect and create a workflow:</p>\n<pre><code>#example\npreproc_dwi.connect_nodes(wf_name = 'pipetography_workflow')\npreproc_dwi.draw_pipeline()\n</code></pre>\n<p>Let's take a look at the final workflow we created:</p>\n<pre><code>#example\nfrom IPython.display import Image\nImage('data/derivatives/test_run/pipetography_detailed.png')\n</code></pre>\n<p><img alt=\"png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5dc5d869af438b16708477e7773fdf2123b3bdf2/646f63732f696d616765732f6f75747075745f33315f302e706e67\"></p>\n<p>Finally, to run the entire pipeline with our inputs. When we declare <code>parallel = True</code>, we are telling Nipype to run parallel pipelines for each iterable input, the pipeline will prompt an input for the number of processes. If you enter <code>4</code>, there will be 4 processes taking up your available computing resources:</p>\n<pre><code>#example\npreproc_dwi.run_pipeline(parallel = True)\n</code></pre>\n\n          </div>"}, "last_serial": 6765558, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ad2b74a534bd6ba3b57178ae05a63a6c", "sha256": "fe39ca1134fa03f54323218c4626556f25757fd9adee05fb0f5b2ccc96f87e66"}, "downloads": -1, "filename": "pipetography-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ad2b74a534bd6ba3b57178ae05a63a6c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 17093, "upload_time": "2020-03-06T22:38:24", "upload_time_iso_8601": "2020-03-06T22:38:24.534004Z", "url": "https://files.pythonhosted.org/packages/4b/ff/8f034881edae0a74f55750b065ba7d71a837ab77f406ce43ff09304c6fba/pipetography-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8ec19dd3243f20a5af41731324326cb", "sha256": "7ef8e492059df19ae9654b9baa6839701bbdc1a8bc0eb38ba56e8b581e27b7f7"}, "downloads": -1, "filename": "pipetography-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e8ec19dd3243f20a5af41731324326cb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20882, "upload_time": "2020-03-06T22:38:26", "upload_time_iso_8601": "2020-03-06T22:38:26.617268Z", "url": "https://files.pythonhosted.org/packages/36/97/52e44c9a32d0fcffe4bf4e244b6bcd7991f224d4e8743ff40900dd413ca3/pipetography-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ad2b74a534bd6ba3b57178ae05a63a6c", "sha256": "fe39ca1134fa03f54323218c4626556f25757fd9adee05fb0f5b2ccc96f87e66"}, "downloads": -1, "filename": "pipetography-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ad2b74a534bd6ba3b57178ae05a63a6c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 17093, "upload_time": "2020-03-06T22:38:24", "upload_time_iso_8601": "2020-03-06T22:38:24.534004Z", "url": "https://files.pythonhosted.org/packages/4b/ff/8f034881edae0a74f55750b065ba7d71a837ab77f406ce43ff09304c6fba/pipetography-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8ec19dd3243f20a5af41731324326cb", "sha256": "7ef8e492059df19ae9654b9baa6839701bbdc1a8bc0eb38ba56e8b581e27b7f7"}, "downloads": -1, "filename": "pipetography-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e8ec19dd3243f20a5af41731324326cb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20882, "upload_time": "2020-03-06T22:38:26", "upload_time_iso_8601": "2020-03-06T22:38:26.617268Z", "url": "https://files.pythonhosted.org/packages/36/97/52e44c9a32d0fcffe4bf4e244b6bcd7991f224d4e8743ff40900dd413ca3/pipetography-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:15 2020"}