{"info": {"author": "saaj", "author_email": "mail@saaj.me", "bugtrack_url": null, "classifiers": ["Framework :: CherryPy", "Intended Audience :: Developers", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only", "Programming Language :: Python :: Implementation :: CPython", "Topic :: Database"], "description": ".. image:: https://img.shields.io/badge/dynamic/json.svg?url=https://api.bitbucket.org/2.0/repositories/saaj/chronologer/pipelines/?page=1%26pagelen=1%26sort=-created_on%26target.ref_name=backend&label=build&query=$.values[0].state.result.name&colorB=blue\n   :target: https://bitbucket.org/saaj/chronologer/addon/pipelines/home\n.. image:: https://codecov.io/bitbucket/saaj/chronologer/branch/backend/graph/badge.svg\n   :target: https://codecov.io/bitbucket/saaj/chronologer/branch/backend\n.. image:: https://badge.fury.io/py/Chronologer.svg\n   :target: https://pypi.org/project/Chronologer/\n.. image:: https://images.microbadger.com/badges/image/saaj/chronologer.svg\n   :target: https://microbadger.com/images/saaj/chronologer\n\n===========\nChronologer\n===========\n\n.. figure:: https://bitbucket.org/saaj/chronologer/raw/8b437413ac3ecf50a5f422394332b7d921ce6804/chronologer/static/resource/clui/image/logo/logo-alt240.png\n   :alt: Chronologer\n\nChronologer is a counterpart of Python stdlib's logging ``HTTPHandler`` [1]_ and more.\nIt provides RESTful API for accepting Python logging HTTP POST requests and optional\nUI for browsing and searching the logs. The idea is the same as for database backends\nof logging software, like ``rsyslog-mysql`` [2]_.\n\nUI features are described in the `frontend`_ branch and released as\n``ChronologerUI`` [17]_ package.\n\n.. contents::\n\nScope\n=====\nChronologer is meant for small- and medium-sized logging workloads and audit logging.\nPractically it's limited by its backend's write throughput and capacity. In case of\nMySQL backend vertical scaling can suffice many types of applications.\n\nEspecially it's useful for microservice architecture where file logging is no longer\npractical.\n\nInstallation\n============\nChronologer is available as a Python package [3]_ and as a Docker image [4]_ (includes UI).\nThe former can be installed like ``pip install chronologer[server,mysql,ui]``. The latter\ncan be used like in the following ``docker-compose.yml`` for deployment with MySQL database.\n\n.. sourcecode:: yaml\n\n    version: '2.4'\n    services:\n      web:\n        image: saaj/chronologer\n        environment:\n          CHRONOLOGER_STORAGE_DSN: mysql://chronologer:pass@mysql/chronologer\n          CHRONOLOGER_SECRET: some_long_random_string\n          CHRONOLOGER_USERNAME: logger\n          CHRONOLOGER_PASSWORD: another_long_random_string\n        depends_on:\n          mysql:\n            condition: service_healthy\n        ports:\n          - 8080:8080\n\n      mysql:\n        image: mysql:5.7\n        environment:\n          MYSQL_DATABASE: chronologer\n          MYSQL_USER: chronologer\n          MYSQL_PASSWORD: pass\n          MYSQL_ROOT_PASSWORD: pass\n        healthcheck:\n          test: mysqladmin ping --protocol=tcp --password=pass --silent\n          interval: 5s\n          retries: 4\n\nIt can be run like the following. The second line applies database migrations.\n\n.. sourcecode:: bash\n\n    docker-compose up -d\n    docker-compose run --rm web python -m chronologer -e production migrate\n\nTo open the UI navigate to ``http://localhost:8080/``.\n\nChronologer's configuration can be fine-tuned with several environment variables\ndefined in ``envconf`` [5]_. Default ``envconf`` can be overridden completely, see\n``python -m chronologer --help``.\n\nFor examples of scaling the application server with ``docker-compose`` see\n``perftest/stack`` directory [22]_. There are examples for Nginx and Traefik.\n\nQuickstart\n==========\nHaving Chronologer server running as described above, client logging configuration\nmay look like the following. It requires ``chronologer`` package installed on the\nclient as well (i.e. ``pip install chronologer``).\n\n.. sourcecode:: python\n\n    import logging.config\n\n\n    config = {\n      'version'                  : 1,\n      'disable_existing_loggers' : False,\n      'handlers'                 : {\n        'http' : {\n          'class'        : 'chronologer.client.QueueProxyHandler',\n          'queue'        : {'()': 'queue.Queue', 'maxsize': 10 ** 4},\n          'target'       : 'ext://chronologer.client.BatchJsonHandler',\n          'prefix'       : 'appname',\n          'capacity'     : 128,\n          'host'         : 'chronologer_host:8080',\n          'url'          : '/api/v1/record',\n          'credentials'  : ('logger', 'another_long_random_string'),\n          'flushLevel'   : 'ERROR',\n          'flushTimeout' : 30,\n        },\n      },\n      'root' : {\n        'handlers' : ['http'],\n        'level'    : 'INFO'\n      }\n    }\n    logging.config.dictConfig(config)\n\nThe ``http`` handler buffers records for efficiency. It flushes its buffer to\nthe server when one of the following occurs:\n\n* the buffer, of 128 records, has been filled,\n* a logging record with ``level`` ``ERROR`` or above has been logged,\n* while logging a record there's a record in the buffer created earlier\n  then 30 seconds ago.\n\n``chronologer.client`` itself doesn't have dependencies but Python standard library.\nFor working only with standard library ``logging.handlers.HTTPHandler`` read below.\n\nPath of the logging handler\n===========================\nThis section starts with ``logging.handlers.HTTPHandler`` and explains why\n``chronologer.client`` builds on it and beyond. The naive imperative logging\nconfiguration looks like:\n\n.. sourcecode:: python\n\n    import logging.handlers\n\n    chrono = logging.handlers.HTTPHandler(\n      'localhost:8080', '/api/v1/record', 'POST', credentials = ('logger', ''))\n    handlers = [logging.StreamHandler(), chrono]\n    logging.basicConfig(level = logging.DEBUG, handlers = handlers)\n\nThe same can be expressed declaratively:\n\n.. sourcecode:: python\n\n    import logging.config\n\n    conf = {\n      'version'                  : 1,\n      'disable_existing_loggers' : False,\n      'handlers'                 : {\n        'console' : {\n          'class' : 'logging.StreamHandler',\n        },\n        'http' : {\n          'class'       : 'logging.handlers.HTTPHandler',\n          'host'        : 'localhost:8080',\n          'url'         : '/api/v1/record',\n          'method'      : 'POST',\n          'credentials' : ('logger', ''),\n          'secure'      : False\n        },\n      },\n      'root' : {\n        'handlers' : ['console', 'http'],\n        'level'    : 'DEBUG'\n      }\n    }\n    logging.config.dictConfig(conf)\n\nThis configuration is called naive because the handler is blocking. It may\nwork in trivial cases but generally it's discouraged because the network is\nnot reliable [6]_. Instead Python provides logging queueing in stdlib [7]_:\n\n    Along with ``QueueHandler`` class, ``QueueListener`` is used to let\n    handlers do their work on a separate thread. This is important for web and\n    other applications where threads serving clients need to respond as\n    quickly as possible, while any potentially slow, and especially\n    complementary operations are done in background.\n\nHere follows imperative configuration with memory queueing.\n\n.. sourcecode:: python\n\n    chrono = logging.handlers.HTTPHandler(\n      'localhost:8080', '/api/v1/record', 'POST', credentials = ('logger', ''))\n    q = queue.Queue(maxsize = 4096)\n    qh = logging.handlers.QueueHandler(q)\n    ql = logging.handlers.QueueListener(q, chrono)\n    ql.start()\n    handlers = [logging.StreamHandler(),  qh]\n    logging.basicConfig(level = logging.DEBUG, handlers = handlers)\n\n    # somewhere on shutdown\n    ql.stop()\n\nBecause the queue listener's shutdown procedure is inconvenient this way and it's\nhard to express declaratively, ``QueueProxyHandler`` is suggested.\n\n.. sourcecode:: python\n\n    import logging.handlers\n    import logging.config\n\n\n    class QueueProxyHandler(logging.handlers.QueueHandler):\n      '''Queue handler which creates its own ``QueueListener`` to\n      proxy log records via provided ``queue`` to ``target`` handler.'''\n\n      _listener = None\n      '''Queue listener'''\n\n\n      def __init__(self, queue, target = logging.handlers.HTTPHandler, **kwargs):\n        # user-supplied factory is not converted by default\n        if isinstance(queue, logging.config.ConvertingDict):\n          queue = queue.configurator.configure_custom(queue)\n\n        super().__init__(queue)\n        self._listener = logging.handlers.QueueListener(queue, target(**kwargs))\n        self._listener.start()\n\n      def close(self):\n        super().close()\n        self._listener.stop()\n\n    conf = {\n      'version'                  : 1,\n      'disable_existing_loggers' : False,\n      'handlers'                 : {\n        'console' : {\n          'class' : 'logging.StreamHandler',\n        },\n        'http' : {\n          'class'       : 'somemodule.QueueProxyHandler',\n          'queue'       : {'()': 'queue.Queue', 'maxsize': 4096},\n          'host'        : 'localhost:8080',\n          'url'         : '/api/v1/record',\n          'method'      : 'POST',\n          'credentials' : ('logger', ''),\n          'secure'      : False\n        },\n      },\n      'root' : {\n        'handlers' : ['console', 'http'],\n        'level'    : 'DEBUG'\n      }\n    }\n    logging.config.dictConfig(conf)\n\n.. warning::\n   Always set reasonable ``maxsize`` for the underlying queue to avoid\n   unbound memory growth. ``logging.handlers.QueueHandler`` uses\n   non-blocking ``put_nowait`` to enqueue records and in case the queue\n   is full, it raises and the exception is handled by\n   ``logging.Handler.handleError``. Alternatively a file-based queue, for\n   instance, ``pqueue`` [8]_, can used to allow more capacity in\n   memory-restricted environments.\n\nClient\n======\nFor convenience reasons, the above is available as\n``chronologer.client.QueueProxyHandler``.\n\nIn addition it has logger name prefixing and suffixing capability, and some\nedge case resilience. ``prefix`` is passed to ``QueueProxyHandler`` on creation.\nIt allows many applications logging into the same Chronologer instance to have\nseparate logger namespaces (e.g. including ``aiohttp`` logging whose namespace\nis fixed). ``suffix`` is an extra attribute of ``LogRecord`` which allows to\nfine-tune the logger namespace for easier search of the records.\n\n.. sourcecode:: python\n\n    import logging.config\n\n\n    conf = {\n      'version'                  : 1,\n      'disable_existing_loggers' : False,\n      'handlers'                 : {\n        'console' : {\n          'class' : 'logging.StreamHandler',\n        },\n        'http' : {\n          'class'       : 'chronologer.client.QueueProxyHandler',\n          'queue'       : {'()': 'queue.Queue', 'maxsize': 4096},\n          'prefix'      : 'appname',\n          'host'        : 'localhost:8080',\n          'url'         : '/api/v1/record',\n          'method'      : 'POST',\n          'credentials' : ('logger', ''),\n          'secure'      : False\n        },\n      },\n      'root' : {\n        'handlers' : ['console', 'http'],\n        'level'    : 'DEBUG'\n      }\n    }\n    logging.config.dictConfig(conf)\n\n    logging.getLogger('some').info(\n      'Chronologer!', extra = {'suffix': 'important.transfer'})\n\nThe ``LogRecord`` corresponding to the last line will have ``name`` equal to\n``'appname.some.important.transfer'``. If ``name`` is modified the original is\nsaved as ``origname``.\n\nBut this is unfortunately not it. Looking at ``logging.handlers.HTTPHandler``\ncarefully we can see a few flaws, including but not limited to:\n\n* it doesn't validate response codes, say ``403 Forbidden``, and will silently\n  ignore the error, i.e. not calling ``logging.Handler.handleError``, will\n  leads to data loss,\n* it doesn't support request retries,\n* it doesn't support buffering to improve throughput,\n* it doesn't support other serialisation formats but\n  ``application/x-www-form-urlencoded``.\n\n``chronologer.client.BatchJsonHandler`` tries to address these issues, see\n`Quickstart`_.\n\nJSON input support\n==================\nBesides ``application/x-www-form-urlencoded`` of  ``HTTPHandler`` Chronologer\nsupports ``application/json`` of the same structure. It also supports\n``application/x-ndjson`` [19]_ for bulk ingestion.\n\nJSON of arbitrary structure can be ingested in the *raw mode*. In the mode\nChronologer will not classify input into logging ``meta``, ``data`` and\n``error`` and will not insist on presence of Python ``logging``-specific keys.\nFor example, a file containing newline separated JSON entries can be sent to\nChronologer like:\n\n.. sourcecode:: bash\n\n  curl -H \"content-type: application/x-ndjson\" --user logger: \\\n    --data-binary @/path/to/some/file.ndjson localhost:8080/api/v1/record?raw=1\n\nRecord retention\n================\nWhen ``CHRONOLOGER_RETENTION_DAYS`` is set, daily, around midnight a background\nthread will purge records older than given number of days.\n\nAuthentication\n==============\nChronologer does not provide (neither intends to) a user management. The intent\nis to delegate authentication. The credentials and roles used by the server can\nbe provided by the following environment variables:\n\n* ``CHRONOLOGER_USERNAME``\n* ``CHRONOLOGER_PASSWORD``\n* ``CHRONOLOGER_ROLES`` \u00ad\u2013 space separated role list (see below)\n\nAlternatively a JSON file located by ``CHRONOLOGER_AUTHFILE`` of the following\nstructure can be used to authenticate multiple users:\n\n.. sourcecode:: json\n\n    [\n      {\n        \"username\": \"bob\",\n        \"pbkdf2\": \"f57ef1e3e8f90cb367dedd44091f251b5b15c9c36ddd7923731fa7ee41cbaa82\",\n        \"hashname\": \"sha256\",\n        \"salt\": \"c0139cff\",\n        \"iterations\": 32,\n        \"roles\": [\"writer\"]\n      }, {\n        \"username\": \"obo\",\n        \"pbkdf2\": \"ff680a9237549f698da5345119dec1ed314eb4fdefe59837d0724d747c3169089ae45...\",\n        \"hashname\": \"sha384\",\n        \"salt\": \"9230dbdd5a13f009\",\n        \"iterations\": 4096,\n        \"roles\": [\"basic-reader\", \"query-reader\"]\n      }\n    ]\n\nThe value of ``pbkdf2`` and keys ``hashname``, ``salt``, ``iterations`` correspond to\nPython ``hashlib.pbkdf2_hmac`` [21]_.\n\n.. warning::\n   Note that the auth-scheme is ``Basic`` which means that the password hash is calculated\n   per request. Thus ``iterations`` should be a low value (especially for writing\n   users). To compensate that it is possible to choose passwords with enough entropy.\n\nAuthorisation\n=============\nChronologer defines the following roles:\n\n* ``basic-reader`` allows ``HEAD`` and ``GET`` to ``/api/v1/record``\n* ``query-reader`` in combination with ``basic-reader`` allows the use\n  ``query``, SQL expression, to (further) filter the records\n* ``writer`` allows ``POST`` to ``/api/v1/record``\n\nThe UI (in case ``chronologerui`` is installed) is available to every\nauthenticated user.\n\nAPI\n===\nBy default Chronologer listens port 8080 and is protected by HTTP Basic\nAuthentication, username \"logger\" without password (see environment\nvariables to override these).\n\nChronologer provides *Record* resource.\n\nCreate record\n-------------\n======================== ===============================================\nURL                      ``/api/v1/record``\n------------------------ -----------------------------------------------\nMethod                   ``POST``\n------------------------ -----------------------------------------------\nRequest content-type     ``application/x-www-form-urlencoded``,\n                         ``application/json``, ``application/x-ndjson``\n------------------------ -----------------------------------------------\nRequest body             Representation of ``logging.LogRecord``\n------------------------ -----------------------------------------------\nResponse content-type    ``application/json``\n------------------------ -----------------------------------------------\nResponse body            Representation of created ``model.Record``,\n                         except for ``application/x-ndjson`` input\n                         where only a list of insert record identifiers\n                         is returned\n------------------------ -----------------------------------------------\nSuccessful response code ``201 Created``\n======================== ===============================================\n\nOptional *raw* mode, accepting arbitrary JSON documents, is supported by\npassing ``raw=1`` into the query string.\n\n``application/x-ndjson`` request body can produce ``207 Multi-Status``\nresponse when a successful chunk is followed by a failed chunk,\nsay that contained malformed a JSON line. Multi-status body looks like:\n\n.. sourcecode:: json\n\n  {\n    \"multistatus\": [\n      {\"status\": 201, \"body\": [1, 2, \"...\"]},\n      {\"status\": 400, \"body\": \"Invalid JSON document on line 2012\"},\n    ]\n  }\n\nRetrieve record count\n---------------------\n======================== ===============================================\nURL                      ``/api/v1/record``\n------------------------ -----------------------------------------------\nMethod                   ``HEAD``\n------------------------ -----------------------------------------------\nQuery string             Optional filtering fields (see details below):\n\n                         * ``after`` \u2013 ISO8601 timestamp\n                         * ``before`` \u2013 ISO8601 timestamp\n                         * ``level`` \u2013 integer logging level\n                         * ``name`` \u2013 logging record prefix(es)\n                         * ``query`` \u2013 storage-specific expression\n------------------------ -----------------------------------------------\nResponse headers         * ``X-Record-Count: 42``\n------------------------ -----------------------------------------------\nSuccessful response code ``200 OK``\n======================== ===============================================\n\nRetrieve record timeline\n------------------------\n======================== ===============================================\nURL                      ``/api/v1/record``\n------------------------ -----------------------------------------------\nMethod                   ``HEAD``\n------------------------ -----------------------------------------------\nQuery string             Required fields:\n\n                         * ``group`` \u2013 \"day\" or \"hour\"\n                         * ``timezone`` \u2013 ``pytz``-compatible one\n\n                         Optional filtering fields (see details below):\n\n                         * ``after`` \u2013 ISO8601 timestamp\n                         * ``before`` \u2013 ISO8601 timestamp\n                         * ``level`` \u2013 integer logging level\n                         * ``name`` \u2013 logging record prefix(es)\n                         * ``query`` \u2013 storage-specific expression\n------------------------ -----------------------------------------------\nResponse headers         * ``X-Record-Count: 90,236``\n                         * ``X-Record-Group: 1360450800,1360537200``\n------------------------ -----------------------------------------------\nSuccessful response code ``200 OK``\n======================== ===============================================\n\nRetrieve record range\n---------------------\n======================== ===============================================\nURL                      ``/api/v1/record``\n------------------------ -----------------------------------------------\nMethod                   ``GET``\n------------------------ -----------------------------------------------\nQuery string             Required fields:\n\n                         * ``left`` \u2013 left offset in the result set\n                         * ``right`` \u2013 right offset in the result set\n\n                         Optional filtering fields (see details below):\n\n                         * ``after`` \u2013 ISO8601 timestamp\n                         * ``before`` \u2013 ISO8601 timestamp\n                         * ``level`` \u2013 integer logging level\n                         * ``name`` \u2013 logging record prefix(es)\n                         * ``query`` \u2013 storage-specific expression\n------------------------ -----------------------------------------------\nResponse content-type    ``application/json``\n------------------------ -----------------------------------------------\nResponse body            .. sourcecode:: json\n\n                           [\n                             {\n                               \"name\": \"some.module\",\n                               \"ts\": \"2018-05-10 16:36:53.377493+00:00\",\n                               \"message\": \"Et quoniam eadem...\",\n                               \"id\": 177260,\n                               \"level\": 20\n                             },\n                             \"...\"\n                           ]\n------------------------ -----------------------------------------------\nSuccessful response code ``200 OK``\n======================== ===============================================\n\nRetrieve record\n---------------\n======================== ===============================================\nURL                      ``/api/v1/record/{id}``\n------------------------ -----------------------------------------------\nMethod                   ``GET``\n------------------------ -----------------------------------------------\nResponse content-type    ``application/json``\n------------------------ -----------------------------------------------\nResponse body            .. sourcecode:: json\n\n                           {\n                             \"name\": \"some.module\",\n                             \"logrec\": {\n                               \"data\": {\n                                 \"foo\": 387\n                               },\n                               \"meta\": {\n                                 \"process\": 29406,\n                                 \"module\": \"some.module\",\n                                 \"relativeCreated\": 103.23762893676758,\n                                 \"msecs\": 376.4379024505615,\n                                 \"pathname\": \"logtest.py\",\n                                 \"msg\": \"Et quoniam eadem...\",\n                                 \"stack_info\": null,\n                                 \"processName\": \"MainProcess\",\n                                 \"filename\": \"logtest.py\",\n                                 \"thread\": 140312867051264,\n                                 \"threadName\": \"MainThread\",\n                                 \"lineno\": 20,\n                                 \"funcName\": \"main\",\n                                 \"args\": null\n                               }\n                             },\n                             \"id\": 177260,\n                             \"level\": 20,\n                             \"message\": \"Et quoniam eadem...\",\n                             \"ts\": \"2018-05-10 16:36:53.377493+00:00\"\n                           }\n\n                         ``logrec`` has two nested dictionaries.\n                         ``data`` has what was passed to ``extra`` [16]_\n                         and ``meta`` has internal fields of\n                         ``logging.LogRecord``.\n------------------------ -----------------------------------------------\nSuccessful response code ``200 OK``\n======================== ===============================================\n\nError representation\n--------------------\nErrors for HTTP method requests that allow a response body are represented like:\n\n.. sourcecode:: json\n\n  {\n    \"error\" : {\n      \"type\"    : \"HTTPError\",\n      \"message\" : \"Nothing matches the given URI\"\n    }\n  }\n\nErrors for HTTP method requests that don't allow a response body are represented in the headers:\n\n* ``X-Error-Type: StorageQueryError``\n* ``X-Error-Message: Make sure the query filter is a valid WHERE expression``\n\nResponse encoding\n-----------------\nChronologer supports Gzip and Brotli response body encoding. The latter takes precedence because\nit provides significant improvement for verbose logging records.\n\n.. note::\n   Modern browsers don't advertise, via ``Accept-Encoding``, Brotli support on non-HTTPS\n   connections (due to broken intermediary software concerns). In Firefox it can be forced\n   by appending ``br`` to ``network.http.accept-encoding`` in ``about:config``.\n\nFiltering\n=========\nFilter fields have the following semantics:\n\n* ``after`` \u2013 ISO8601 timestamp.\n  The predicate is true for a record which was created after given timestamp.\n* ``before`` \u2013 ISO8601 timestamp.\n  The predicate is true for a record which was created before given timestamp.\n* ``level`` \u2013 integer logging level.\n  The predicate is true for a record whose severity level is greater or equal to given level.\n* ``name`` \u2013 logging record prefix. Optionally can be a comma-separated list of prefixes.\n  The predicate is true for a record whose logger name starts with any of given prefixes.\n* ``query`` \u2013 storage-specific expression.\n  Requires the user to have ``query-reader`` role. See JSON path description below.\n\n.. warning::\n   Each user who has access to Chronologer with ``query-reader`` role (default user\n   does not have it) effectively has full access to its database, because ``query``\n   expressions are put into the SQL queries directly as there's no intent to\n   abstract native database search features.\n\nMySQL\n=====\nChronologer relies on a compressed InnoDB table which provides good compromise\nbetween reliability, data modelling, search features, performance and size of\nlogged data. The data of logging records are written into ``logrec`` JSON\nfield (see the initial migration [9]_ and examples above).\n\nIt is a good idea to have dedicated MySQL instance for Chronologer. Then, for\ninstance, it is possible to fine-tune MySQL's ACID guarantees, namely\n``innodb_flush_log_at_trx_commit = 0`` allow MySQL to write 1-second batches\n[10]_. Disabling performance schema [11]_ by setting ``performance_schema = 0``\nis also recommended, because it has significant overhead. Basic InnoDB settings\nshould be reasonably configured:\n\n* ``innodb_buffer_pool_size`` [12]_\n* ``innodb_log_buffer_size`` [13]_\n* ``innodb_log_file_size`` [14]_\n\nJSON path query\n---------------\n``query`` passes a storage-specific expression. Particularly, it's useful\nto write post-filtering conditions for ``logrec`` JSON field using\nJSONPath expressions and ``->`` operator [15]_. It may look like the following,\nthough arbitrary ``WHERE`` clause expressions are possible.\n\n* ``\"logrec->'$.data.foo' = 387 AND logrec->'$.meta.lineno' = 20\"``\n* ``\"logrec->'$.meta.threadName' != 'MainThread'\"``\n\nNote that connection to MySQL works in ``ANSI_QUOTES`` mode [18]_, so ``\"``\ncannot be used to form string literals. ``'`` must be used instead.\n\nCompression tuning\n------------------\nInitial migration [9]_ sets ``KEY_BLOCK_SIZE = 4``. It may be sub-optimal for\nthe shape of your log records. MySQL provides guidelines for choosing\n``KEY_BLOCK_SIZE`` [23]_ and monitoring \"compression failures\"\nat runtime [24]_.\n\nIf you want to change ``KEY_BLOCK_SIZE`` for ``record`` table, you can provide\nyour own database migration. Chronologer uses yoyo-migrations [25]_ for\ndatabase migrations. For example, to switch to ``KEY_BLOCK_SIZE = 8``\nmigration file, named ``20190803T1404_key_size.py``, will look like:\n\n.. sourcecode:: python\n\n    from yoyo import step\n\n    step('ALTER TABLE record KEY_BLOCK_SIZE = 8')\n\nIt can be mounted into the migration directory of Chonologer's container\nin your ``docker-compose.yml`` like:\n\n.. sourcecode:: yaml\n\n    volumes:\n      - ./20190803T1404_key_size.py:/opt/chronologer/chronologer/migration/mysql/20190803T1404_key_size.py\n\nThen re-apply migrations with ``migrate`` or run ``serve`` with ``-m`` command\nline flag.\n\nSQLite\n======\nSQLite is supported for very simple, one-off or evaluation cases. Also it doesn't\nsupport compression. ``JSON1`` extension [20]_ is required for JSON Path queries.\n\n* ``\"json_extract(logrec, '$.data.foo') = 387 AND json_extract(logrec, '$.meta.lineno') = 20\"``\n* ``\"json_extract(logrec, '$.meta.threadName') = 'MainThread'\"``\n\nA one-off Chronologer container with SQLite storage can be run on port 8080 like::\n\n  docker run --rm -it -p 8080:8080 -v /tmp/db \\\n    -e CHRONOLOGER_STORAGE_DSN=sqlite:////tmp/db/chrono.sqlite \\\n    -e CHRONOLOGER_SECRET=some_long_random_string \\\n    saaj/chronologer \\\n    python3.7 -m chronologer -e production serve -u www-data -g www-data -m\n\nTwo things to note:\n\n1. ``-m`` to ``serve`` runs migrations before starting the server,\n2. SQLite needs permissions to the directory where a database file\n   resides, to write its temporary files.\n\nR&D roadmap\n===========\nSee the `roadmap`_ issue.\n\nCredits\n=======\nLogo is contributed by `lightypaints`_.\n\n____\n\n.. _frontend: https://bitbucket.org/saaj/chronologer/src/frontend\n.. _roadmap: https://bitbucket.org/saaj/chronologer/issues/1\n.. _lightypaints: https://www.behance.net/lightypaints\n.. [1]  https://docs.python.org/3/library/logging.handlers.html#httphandler\n.. [2]  https://packages.debian.org/sid/rsyslog-mysql\n.. [3]  https://pypi.org/project/Chronologer/\n.. [4]  https://hub.docker.com/r/saaj/chronologer/\n.. [5]  https://bitbucket.org/saaj/chronologer/src/backend/chronologer/envconf.py\n.. [6]  https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing\n.. [7]  https://docs.python.org/3/library/logging.handlers.html#queuelistener\n.. [8]  https://pypi.org/project/pqueue/\n.. [9]  https://bitbucket.org/saaj/chronologer/src/d5d4daa/chronologer/migration/mysql/20171026T1428_initial.py\n.. [10] https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit\n.. [11] https://dev.mysql.com/doc/refman/5.7/en/performance-schema.html\n.. [12] https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_buffer_pool_size\n.. [13] https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_log_buffer_size\n.. [14] https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_log_file_size\n.. [15] https://dev.mysql.com/doc/refman/5.7/en/json-search-functions.html#operator_json-column-path\n.. [16] https://docs.python.org/3/library/logging.html#logging.debug\n.. [17] https://pypi.org/project/ChronologerUI/\n.. [18] https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sqlmode_ansi_quotes\n.. [19] https://github.com/ndjson/ndjson-spec\n.. [20] https://www.sqlite.org/json1.html\n.. [21] https://docs.python.org/3/library/hashlib.html#hashlib.pbkdf2_hmac\n.. [22] https://bitbucket.org/saaj/chronologer/src/backend/perftest/\n.. [23] https://dev.mysql.com/doc/refman/5.7/en/innodb-compression-tuning.html\n.. [24] https://dev.mysql.com/doc/refman/5.7/en/innodb-compression-tuning-monitoring.html\n.. [25] https://pypi.python.org/pypi/yoyo-migrations\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://bitbucket.org/saaj/chronologer/src/backend", "keywords": "python logging http json", "license": "GPL-3.0", "maintainer": "", "maintainer_email": "", "name": "Chronologer", "package_url": "https://pypi.org/project/Chronologer/", "platform": "Any", "project_url": "https://pypi.org/project/Chronologer/", "project_urls": {"Homepage": "https://bitbucket.org/saaj/chronologer/src/backend"}, "release_url": "https://pypi.org/project/Chronologer/0.4.3/", "requires_dist": null, "requires_python": "", "summary": "Python HTTP logging server", "version": "0.4.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://bitbucket.org/saaj/chronologer/addon/pipelines/home\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/dynamic/json.svg?url=https://api.bitbucket.org/2.0/repositories/saaj/chronologer/pipelines/?page=1%26pagelen=1%26sort=-created_on%26target.ref_name=backend&amp;label=build&amp;query=$.values[0].state.result.name&amp;colorB=blue\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5bfd13660183cd789f3a1e7ffa441f22992dac44/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e2e7376673f75726c3d68747470733a2f2f6170692e6269746275636b65742e6f72672f322e302f7265706f7369746f726965732f7361616a2f6368726f6e6f6c6f6765722f706970656c696e65732f3f706167653d31253236706167656c656e3d31253236736f72743d2d637265617465645f6f6e2532367461726765742e7265665f6e616d653d6261636b656e64266c6162656c3d6275696c642671756572793d242e76616c7565735b305d2e73746174652e726573756c742e6e616d6526636f6c6f72423d626c7565\"></a>\n<a href=\"https://codecov.io/bitbucket/saaj/chronologer/branch/backend\" rel=\"nofollow\"><img alt=\"https://codecov.io/bitbucket/saaj/chronologer/branch/backend/graph/badge.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b424fe74452c475b1637812bf3b660b74f83c6c9/68747470733a2f2f636f6465636f762e696f2f6269746275636b65742f7361616a2f6368726f6e6f6c6f6765722f6272616e63682f6261636b656e642f67726170682f62616467652e737667\"></a>\n<a href=\"https://pypi.org/project/Chronologer/\" rel=\"nofollow\"><img alt=\"https://badge.fury.io/py/Chronologer.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/578645069ff1acddabbdd453386487ae184acd8b/68747470733a2f2f62616467652e667572792e696f2f70792f4368726f6e6f6c6f6765722e737667\"></a>\n<a href=\"https://microbadger.com/images/saaj/chronologer\" rel=\"nofollow\"><img alt=\"https://images.microbadger.com/badges/image/saaj/chronologer.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e8466be7a55a41e7893e52635d10e9c0dab13884/68747470733a2f2f696d616765732e6d6963726f6261646765722e636f6d2f6261646765732f696d6167652f7361616a2f6368726f6e6f6c6f6765722e737667\"></a>\n<div id=\"chronologer\">\n<h2><a href=\"#id52\" rel=\"nofollow\">Chronologer</a></h2>\n<div>\n<img alt=\"Chronologer\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ddaf1f62b1f4a51ba80605e9a7eafc7630939085/68747470733a2f2f6269746275636b65742e6f72672f7361616a2f6368726f6e6f6c6f6765722f7261772f386234333734313361633365636635306135663432323339343333326237643932316365363830342f6368726f6e6f6c6f6765722f7374617469632f7265736f757263652f636c75692f696d6167652f6c6f676f2f6c6f676f2d616c743234302e706e67\">\n</div>\n<p>Chronologer is a counterpart of Python stdlib\u2019s logging <tt>HTTPHandler</tt> <a href=\"#id27\" id=\"id1\" rel=\"nofollow\">[1]</a> and more.\nIt provides RESTful API for accepting Python logging HTTP POST requests and optional\nUI for browsing and searching the logs. The idea is the same as for database backends\nof logging software, like <tt><span class=\"pre\">rsyslog-mysql</span></tt> <a href=\"#id28\" id=\"id2\" rel=\"nofollow\">[2]</a>.</p>\n<p>UI features are described in the <a href=\"https://bitbucket.org/saaj/chronologer/src/frontend\" rel=\"nofollow\">frontend</a> branch and released as\n<tt>ChronologerUI</tt> <a href=\"#id43\" id=\"id3\" rel=\"nofollow\">[17]</a> package.</p>\n<div id=\"contents\">\n<p>Contents</p>\n<ul>\n<li><a href=\"#chronologer\" id=\"id52\" rel=\"nofollow\">Chronologer</a><ul>\n<li><a href=\"#scope\" id=\"id53\" rel=\"nofollow\">Scope</a></li>\n<li><a href=\"#installation\" id=\"id54\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#quickstart\" id=\"id55\" rel=\"nofollow\">Quickstart</a></li>\n<li><a href=\"#path-of-the-logging-handler\" id=\"id56\" rel=\"nofollow\">Path of the logging handler</a></li>\n<li><a href=\"#client\" id=\"id57\" rel=\"nofollow\">Client</a></li>\n<li><a href=\"#json-input-support\" id=\"id58\" rel=\"nofollow\">JSON input support</a></li>\n<li><a href=\"#record-retention\" id=\"id59\" rel=\"nofollow\">Record retention</a></li>\n<li><a href=\"#authentication\" id=\"id60\" rel=\"nofollow\">Authentication</a></li>\n<li><a href=\"#authorisation\" id=\"id61\" rel=\"nofollow\">Authorisation</a></li>\n<li><a href=\"#api\" id=\"id62\" rel=\"nofollow\">API</a><ul>\n<li><a href=\"#create-record\" id=\"id63\" rel=\"nofollow\">Create record</a></li>\n<li><a href=\"#retrieve-record-count\" id=\"id64\" rel=\"nofollow\">Retrieve record count</a></li>\n<li><a href=\"#retrieve-record-timeline\" id=\"id65\" rel=\"nofollow\">Retrieve record timeline</a></li>\n<li><a href=\"#retrieve-record-range\" id=\"id66\" rel=\"nofollow\">Retrieve record range</a></li>\n<li><a href=\"#retrieve-record\" id=\"id67\" rel=\"nofollow\">Retrieve record</a></li>\n<li><a href=\"#error-representation\" id=\"id68\" rel=\"nofollow\">Error representation</a></li>\n<li><a href=\"#response-encoding\" id=\"id69\" rel=\"nofollow\">Response encoding</a></li>\n</ul>\n</li>\n<li><a href=\"#filtering\" id=\"id70\" rel=\"nofollow\">Filtering</a></li>\n<li><a href=\"#mysql\" id=\"id71\" rel=\"nofollow\">MySQL</a><ul>\n<li><a href=\"#json-path-query\" id=\"id72\" rel=\"nofollow\">JSON path query</a></li>\n<li><a href=\"#compression-tuning\" id=\"id73\" rel=\"nofollow\">Compression tuning</a></li>\n</ul>\n</li>\n<li><a href=\"#sqlite\" id=\"id74\" rel=\"nofollow\">SQLite</a></li>\n<li><a href=\"#r-d-roadmap\" id=\"id75\" rel=\"nofollow\">R&amp;D roadmap</a></li>\n<li><a href=\"#credits\" id=\"id76\" rel=\"nofollow\">Credits</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"scope\">\n<h3><a href=\"#id53\" rel=\"nofollow\">Scope</a></h3>\n<p>Chronologer is meant for small- and medium-sized logging workloads and audit logging.\nPractically it\u2019s limited by its backend\u2019s write throughput and capacity. In case of\nMySQL backend vertical scaling can suffice many types of applications.</p>\n<p>Especially it\u2019s useful for microservice architecture where file logging is no longer\npractical.</p>\n</div>\n<div id=\"installation\">\n<h3><a href=\"#id54\" rel=\"nofollow\">Installation</a></h3>\n<p>Chronologer is available as a Python package <a href=\"#id29\" id=\"id4\" rel=\"nofollow\">[3]</a> and as a Docker image <a href=\"#id30\" id=\"id5\" rel=\"nofollow\">[4]</a> (includes UI).\nThe former can be installed like <tt>pip install chronologer[server,mysql,ui]</tt>. The latter\ncan be used like in the following <tt><span class=\"pre\">docker-compose.yml</span></tt> for deployment with MySQL database.</p>\n<pre><span class=\"nt\">version</span><span class=\"p\">:</span> <span class=\"s\">'2.4'</span>\n<span class=\"nt\">services</span><span class=\"p\">:</span>\n  <span class=\"nt\">web</span><span class=\"p\">:</span>\n    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">saaj/chronologer</span>\n    <span class=\"nt\">environment</span><span class=\"p\">:</span>\n      <span class=\"nt\">CHRONOLOGER_STORAGE_DSN</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">mysql://chronologer:pass@mysql/chronologer</span>\n      <span class=\"nt\">CHRONOLOGER_SECRET</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">some_long_random_string</span>\n      <span class=\"nt\">CHRONOLOGER_USERNAME</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">logger</span>\n      <span class=\"nt\">CHRONOLOGER_PASSWORD</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">another_long_random_string</span>\n    <span class=\"nt\">depends_on</span><span class=\"p\">:</span>\n      <span class=\"nt\">mysql</span><span class=\"p\">:</span>\n        <span class=\"nt\">condition</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">service_healthy</span>\n    <span class=\"nt\">ports</span><span class=\"p\">:</span>\n      <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">8080:8080</span>\n\n  <span class=\"nt\">mysql</span><span class=\"p\">:</span>\n    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">mysql:5.7</span>\n    <span class=\"nt\">environment</span><span class=\"p\">:</span>\n      <span class=\"nt\">MYSQL_DATABASE</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">chronologer</span>\n      <span class=\"nt\">MYSQL_USER</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">chronologer</span>\n      <span class=\"nt\">MYSQL_PASSWORD</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">pass</span>\n      <span class=\"nt\">MYSQL_ROOT_PASSWORD</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">pass</span>\n    <span class=\"nt\">healthcheck</span><span class=\"p\">:</span>\n      <span class=\"nt\">test</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">mysqladmin ping --protocol=tcp --password=pass --silent</span>\n      <span class=\"nt\">interval</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">5s</span>\n      <span class=\"nt\">retries</span><span class=\"p\">:</span> <span class=\"l-Scalar-Plain\">4</span>\n</pre>\n<p>It can be run like the following. The second line applies database migrations.</p>\n<pre>docker-compose up -d\ndocker-compose run --rm web python -m chronologer -e production migrate\n</pre>\n<p>To open the UI navigate to <tt><span class=\"pre\">http://localhost:8080/</span></tt>.</p>\n<p>Chronologer\u2019s configuration can be fine-tuned with several environment variables\ndefined in <tt>envconf</tt> <a href=\"#id31\" id=\"id6\" rel=\"nofollow\">[5]</a>. Default <tt>envconf</tt> can be overridden completely, see\n<tt>python <span class=\"pre\">-m</span> chronologer <span class=\"pre\">--help</span></tt>.</p>\n<p>For examples of scaling the application server with <tt><span class=\"pre\">docker-compose</span></tt> see\n<tt>perftest/stack</tt> directory <a href=\"#id48\" id=\"id7\" rel=\"nofollow\">[22]</a>. There are examples for Nginx and Traefik.</p>\n</div>\n<div id=\"quickstart\">\n<h3><a href=\"#id55\" rel=\"nofollow\">Quickstart</a></h3>\n<p>Having Chronologer server running as described above, client logging configuration\nmay look like the following. It requires <tt>chronologer</tt> package installed on the\nclient as well (i.e. <tt>pip install chronologer</tt>).</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging.config</span>\n\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"s1\">'version'</span>                  <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n  <span class=\"s1\">'disable_existing_loggers'</span> <span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n  <span class=\"s1\">'handlers'</span>                 <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'http'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span>        <span class=\"p\">:</span> <span class=\"s1\">'chronologer.client.QueueProxyHandler'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'queue'</span>        <span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'()'</span><span class=\"p\">:</span> <span class=\"s1\">'queue.Queue'</span><span class=\"p\">,</span> <span class=\"s1\">'maxsize'</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"o\">**</span> <span class=\"mi\">4</span><span class=\"p\">},</span>\n      <span class=\"s1\">'target'</span>       <span class=\"p\">:</span> <span class=\"s1\">'ext://chronologer.client.BatchJsonHandler'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'prefix'</span>       <span class=\"p\">:</span> <span class=\"s1\">'appname'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'capacity'</span>     <span class=\"p\">:</span> <span class=\"mi\">128</span><span class=\"p\">,</span>\n      <span class=\"s1\">'host'</span>         <span class=\"p\">:</span> <span class=\"s1\">'chronologer_host:8080'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'url'</span>          <span class=\"p\">:</span> <span class=\"s1\">'/api/v1/record'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'credentials'</span>  <span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'logger'</span><span class=\"p\">,</span> <span class=\"s1\">'another_long_random_string'</span><span class=\"p\">),</span>\n      <span class=\"s1\">'flushLevel'</span>   <span class=\"p\">:</span> <span class=\"s1\">'ERROR'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'flushTimeout'</span> <span class=\"p\">:</span> <span class=\"mi\">30</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n  <span class=\"p\">},</span>\n  <span class=\"s1\">'root'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'handlers'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'http'</span><span class=\"p\">],</span>\n    <span class=\"s1\">'level'</span>    <span class=\"p\">:</span> <span class=\"s1\">'INFO'</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">dictConfig</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"p\">)</span>\n</pre>\n<p>The <tt>http</tt> handler buffers records for efficiency. It flushes its buffer to\nthe server when one of the following occurs:</p>\n<ul>\n<li>the buffer, of 128 records, has been filled,</li>\n<li>a logging record with <tt>level</tt> <tt>ERROR</tt> or above has been logged,</li>\n<li>while logging a record there\u2019s a record in the buffer created earlier\nthen 30 seconds ago.</li>\n</ul>\n<p><tt>chronologer.client</tt> itself doesn\u2019t have dependencies but Python standard library.\nFor working only with standard library <tt>logging.handlers.HTTPHandler</tt> read below.</p>\n</div>\n<div id=\"path-of-the-logging-handler\">\n<h3><a href=\"#id56\" rel=\"nofollow\">Path of the logging handler</a></h3>\n<p>This section starts with <tt>logging.handlers.HTTPHandler</tt> and explains why\n<tt>chronologer.client</tt> builds on it and beyond. The naive imperative logging\nconfiguration looks like:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging.handlers</span>\n\n<span class=\"n\">chrono</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">HTTPHandler</span><span class=\"p\">(</span>\n  <span class=\"s1\">'localhost:8080'</span><span class=\"p\">,</span> <span class=\"s1\">'/api/v1/record'</span><span class=\"p\">,</span> <span class=\"s1\">'POST'</span><span class=\"p\">,</span> <span class=\"n\">credentials</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'logger'</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"p\">))</span>\n<span class=\"n\">handlers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">StreamHandler</span><span class=\"p\">(),</span> <span class=\"n\">chrono</span><span class=\"p\">]</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">basicConfig</span><span class=\"p\">(</span><span class=\"n\">level</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">DEBUG</span><span class=\"p\">,</span> <span class=\"n\">handlers</span> <span class=\"o\">=</span> <span class=\"n\">handlers</span><span class=\"p\">)</span>\n</pre>\n<p>The same can be expressed declaratively:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging.config</span>\n\n<span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"s1\">'version'</span>                  <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n  <span class=\"s1\">'disable_existing_loggers'</span> <span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n  <span class=\"s1\">'handlers'</span>                 <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'console'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span> <span class=\"p\">:</span> <span class=\"s1\">'logging.StreamHandler'</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"s1\">'http'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span>       <span class=\"p\">:</span> <span class=\"s1\">'logging.handlers.HTTPHandler'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'host'</span>        <span class=\"p\">:</span> <span class=\"s1\">'localhost:8080'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'url'</span>         <span class=\"p\">:</span> <span class=\"s1\">'/api/v1/record'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'method'</span>      <span class=\"p\">:</span> <span class=\"s1\">'POST'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'credentials'</span> <span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'logger'</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"p\">),</span>\n      <span class=\"s1\">'secure'</span>      <span class=\"p\">:</span> <span class=\"kc\">False</span>\n    <span class=\"p\">},</span>\n  <span class=\"p\">},</span>\n  <span class=\"s1\">'root'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'handlers'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'console'</span><span class=\"p\">,</span> <span class=\"s1\">'http'</span><span class=\"p\">],</span>\n    <span class=\"s1\">'level'</span>    <span class=\"p\">:</span> <span class=\"s1\">'DEBUG'</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">dictConfig</span><span class=\"p\">(</span><span class=\"n\">conf</span><span class=\"p\">)</span>\n</pre>\n<p>This configuration is called naive because the handler is blocking. It may\nwork in trivial cases but generally it\u2019s discouraged because the network is\nnot reliable <a href=\"#id32\" id=\"id8\" rel=\"nofollow\">[6]</a>. Instead Python provides logging queueing in stdlib <a href=\"#id33\" id=\"id9\" rel=\"nofollow\">[7]</a>:</p>\n<blockquote>\nAlong with <tt>QueueHandler</tt> class, <tt>QueueListener</tt> is used to let\nhandlers do their work on a separate thread. This is important for web and\nother applications where threads serving clients need to respond as\nquickly as possible, while any potentially slow, and especially\ncomplementary operations are done in background.</blockquote>\n<p>Here follows imperative configuration with memory queueing.</p>\n<pre><span class=\"n\">chrono</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">HTTPHandler</span><span class=\"p\">(</span>\n  <span class=\"s1\">'localhost:8080'</span><span class=\"p\">,</span> <span class=\"s1\">'/api/v1/record'</span><span class=\"p\">,</span> <span class=\"s1\">'POST'</span><span class=\"p\">,</span> <span class=\"n\">credentials</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"s1\">'logger'</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"p\">))</span>\n<span class=\"n\">q</span> <span class=\"o\">=</span> <span class=\"n\">queue</span><span class=\"o\">.</span><span class=\"n\">Queue</span><span class=\"p\">(</span><span class=\"n\">maxsize</span> <span class=\"o\">=</span> <span class=\"mi\">4096</span><span class=\"p\">)</span>\n<span class=\"n\">qh</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">QueueHandler</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">)</span>\n<span class=\"n\">ql</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">QueueListener</span><span class=\"p\">(</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">chrono</span><span class=\"p\">)</span>\n<span class=\"n\">ql</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n<span class=\"n\">handlers</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">StreamHandler</span><span class=\"p\">(),</span>  <span class=\"n\">qh</span><span class=\"p\">]</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">basicConfig</span><span class=\"p\">(</span><span class=\"n\">level</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">DEBUG</span><span class=\"p\">,</span> <span class=\"n\">handlers</span> <span class=\"o\">=</span> <span class=\"n\">handlers</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># somewhere on shutdown</span>\n<span class=\"n\">ql</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">()</span>\n</pre>\n<p>Because the queue listener\u2019s shutdown procedure is inconvenient this way and it\u2019s\nhard to express declaratively, <tt>QueueProxyHandler</tt> is suggested.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging.handlers</span>\n<span class=\"kn\">import</span> <span class=\"nn\">logging.config</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">QueueProxyHandler</span><span class=\"p\">(</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">QueueHandler</span><span class=\"p\">):</span>\n  <span class=\"sd\">'''Queue handler which creates its own ``QueueListener`` to\n  proxy log records via provided ``queue`` to ``target`` handler.'''</span>\n\n  <span class=\"n\">_listener</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n  <span class=\"sd\">'''Queue listener'''</span>\n\n\n  <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">queue</span><span class=\"p\">,</span> <span class=\"n\">target</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">HTTPHandler</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">):</span>\n    <span class=\"c1\"># user-supplied factory is not converted by default</span>\n    <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"n\">queue</span><span class=\"p\">,</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">ConvertingDict</span><span class=\"p\">):</span>\n      <span class=\"n\">queue</span> <span class=\"o\">=</span> <span class=\"n\">queue</span><span class=\"o\">.</span><span class=\"n\">configurator</span><span class=\"o\">.</span><span class=\"n\">configure_custom</span><span class=\"p\">(</span><span class=\"n\">queue</span><span class=\"p\">)</span>\n\n    <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">queue</span><span class=\"p\">)</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_listener</span> <span class=\"o\">=</span> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">handlers</span><span class=\"o\">.</span><span class=\"n\">QueueListener</span><span class=\"p\">(</span><span class=\"n\">queue</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">))</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_listener</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n  <span class=\"k\">def</span> <span class=\"nf\">close</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_listener</span><span class=\"o\">.</span><span class=\"n\">stop</span><span class=\"p\">()</span>\n\n<span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"s1\">'version'</span>                  <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n  <span class=\"s1\">'disable_existing_loggers'</span> <span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n  <span class=\"s1\">'handlers'</span>                 <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'console'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span> <span class=\"p\">:</span> <span class=\"s1\">'logging.StreamHandler'</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"s1\">'http'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span>       <span class=\"p\">:</span> <span class=\"s1\">'somemodule.QueueProxyHandler'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'queue'</span>       <span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'()'</span><span class=\"p\">:</span> <span class=\"s1\">'queue.Queue'</span><span class=\"p\">,</span> <span class=\"s1\">'maxsize'</span><span class=\"p\">:</span> <span class=\"mi\">4096</span><span class=\"p\">},</span>\n      <span class=\"s1\">'host'</span>        <span class=\"p\">:</span> <span class=\"s1\">'localhost:8080'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'url'</span>         <span class=\"p\">:</span> <span class=\"s1\">'/api/v1/record'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'method'</span>      <span class=\"p\">:</span> <span class=\"s1\">'POST'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'credentials'</span> <span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'logger'</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"p\">),</span>\n      <span class=\"s1\">'secure'</span>      <span class=\"p\">:</span> <span class=\"kc\">False</span>\n    <span class=\"p\">},</span>\n  <span class=\"p\">},</span>\n  <span class=\"s1\">'root'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'handlers'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'console'</span><span class=\"p\">,</span> <span class=\"s1\">'http'</span><span class=\"p\">],</span>\n    <span class=\"s1\">'level'</span>    <span class=\"p\">:</span> <span class=\"s1\">'DEBUG'</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">dictConfig</span><span class=\"p\">(</span><span class=\"n\">conf</span><span class=\"p\">)</span>\n</pre>\n<div>\n<p>Warning</p>\n<p>Always set reasonable <tt>maxsize</tt> for the underlying queue to avoid\nunbound memory growth. <tt>logging.handlers.QueueHandler</tt> uses\nnon-blocking <tt>put_nowait</tt> to enqueue records and in case the queue\nis full, it raises and the exception is handled by\n<tt>logging.Handler.handleError</tt>. Alternatively a file-based queue, for\ninstance, <tt>pqueue</tt> <a href=\"#id34\" id=\"id10\" rel=\"nofollow\">[8]</a>, can used to allow more capacity in\nmemory-restricted environments.</p>\n</div>\n</div>\n<div id=\"client\">\n<h3><a href=\"#id57\" rel=\"nofollow\">Client</a></h3>\n<p>For convenience reasons, the above is available as\n<tt>chronologer.client.QueueProxyHandler</tt>.</p>\n<p>In addition it has logger name prefixing and suffixing capability, and some\nedge case resilience. <tt>prefix</tt> is passed to <tt>QueueProxyHandler</tt> on creation.\nIt allows many applications logging into the same Chronologer instance to have\nseparate logger namespaces (e.g. including <tt>aiohttp</tt> logging whose namespace\nis fixed). <tt>suffix</tt> is an extra attribute of <tt>LogRecord</tt> which allows to\nfine-tune the logger namespace for easier search of the records.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">logging.config</span>\n\n\n<span class=\"n\">conf</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"s1\">'version'</span>                  <span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n  <span class=\"s1\">'disable_existing_loggers'</span> <span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n  <span class=\"s1\">'handlers'</span>                 <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'console'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span> <span class=\"p\">:</span> <span class=\"s1\">'logging.StreamHandler'</span><span class=\"p\">,</span>\n    <span class=\"p\">},</span>\n    <span class=\"s1\">'http'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"s1\">'class'</span>       <span class=\"p\">:</span> <span class=\"s1\">'chronologer.client.QueueProxyHandler'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'queue'</span>       <span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'()'</span><span class=\"p\">:</span> <span class=\"s1\">'queue.Queue'</span><span class=\"p\">,</span> <span class=\"s1\">'maxsize'</span><span class=\"p\">:</span> <span class=\"mi\">4096</span><span class=\"p\">},</span>\n      <span class=\"s1\">'prefix'</span>      <span class=\"p\">:</span> <span class=\"s1\">'appname'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'host'</span>        <span class=\"p\">:</span> <span class=\"s1\">'localhost:8080'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'url'</span>         <span class=\"p\">:</span> <span class=\"s1\">'/api/v1/record'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'method'</span>      <span class=\"p\">:</span> <span class=\"s1\">'POST'</span><span class=\"p\">,</span>\n      <span class=\"s1\">'credentials'</span> <span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'logger'</span><span class=\"p\">,</span> <span class=\"s1\">''</span><span class=\"p\">),</span>\n      <span class=\"s1\">'secure'</span>      <span class=\"p\">:</span> <span class=\"kc\">False</span>\n    <span class=\"p\">},</span>\n  <span class=\"p\">},</span>\n  <span class=\"s1\">'root'</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'handlers'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'console'</span><span class=\"p\">,</span> <span class=\"s1\">'http'</span><span class=\"p\">],</span>\n    <span class=\"s1\">'level'</span>    <span class=\"p\">:</span> <span class=\"s1\">'DEBUG'</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">dictConfig</span><span class=\"p\">(</span><span class=\"n\">conf</span><span class=\"p\">)</span>\n\n<span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">getLogger</span><span class=\"p\">(</span><span class=\"s1\">'some'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span>\n  <span class=\"s1\">'Chronologer!'</span><span class=\"p\">,</span> <span class=\"n\">extra</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'suffix'</span><span class=\"p\">:</span> <span class=\"s1\">'important.transfer'</span><span class=\"p\">})</span>\n</pre>\n<p>The <tt>LogRecord</tt> corresponding to the last line will have <tt>name</tt> equal to\n<tt>'appname.some.important.transfer'</tt>. If <tt>name</tt> is modified the original is\nsaved as <tt>origname</tt>.</p>\n<p>But this is unfortunately not it. Looking at <tt>logging.handlers.HTTPHandler</tt>\ncarefully we can see a few flaws, including but not limited to:</p>\n<ul>\n<li>it doesn\u2019t validate response codes, say <tt>403 Forbidden</tt>, and will silently\nignore the error, i.e. not calling <tt>logging.Handler.handleError</tt>, will\nleads to data loss,</li>\n<li>it doesn\u2019t support request retries,</li>\n<li>it doesn\u2019t support buffering to improve throughput,</li>\n<li>it doesn\u2019t support other serialisation formats but\n<tt><span class=\"pre\">application/x-www-form-urlencoded</span></tt>.</li>\n</ul>\n<p><tt>chronologer.client.BatchJsonHandler</tt> tries to address these issues, see\n<a href=\"#quickstart\" rel=\"nofollow\">Quickstart</a>.</p>\n</div>\n<div id=\"json-input-support\">\n<h3><a href=\"#id58\" rel=\"nofollow\">JSON input support</a></h3>\n<p>Besides <tt><span class=\"pre\">application/x-www-form-urlencoded</span></tt> of  <tt>HTTPHandler</tt> Chronologer\nsupports <tt>application/json</tt> of the same structure. It also supports\n<tt><span class=\"pre\">application/x-ndjson</span></tt> <a href=\"#id45\" id=\"id11\" rel=\"nofollow\">[19]</a> for bulk ingestion.</p>\n<p>JSON of arbitrary structure can be ingested in the <em>raw mode</em>. In the mode\nChronologer will not classify input into logging <tt>meta</tt>, <tt>data</tt> and\n<tt>error</tt> and will not insist on presence of Python <tt>logging</tt>-specific keys.\nFor example, a file containing newline separated JSON entries can be sent to\nChronologer like:</p>\n<pre>curl -H <span class=\"s2\">\"content-type: application/x-ndjson\"</span> --user logger: <span class=\"se\">\\\n</span>  --data-binary @/path/to/some/file.ndjson localhost:8080/api/v1/record?raw<span class=\"o\">=</span><span class=\"m\">1</span>\n</pre>\n</div>\n<div id=\"record-retention\">\n<h3><a href=\"#id59\" rel=\"nofollow\">Record retention</a></h3>\n<p>When <tt>CHRONOLOGER_RETENTION_DAYS</tt> is set, daily, around midnight a background\nthread will purge records older than given number of days.</p>\n</div>\n<div id=\"authentication\">\n<h3><a href=\"#id60\" rel=\"nofollow\">Authentication</a></h3>\n<p>Chronologer does not provide (neither intends to) a user management. The intent\nis to delegate authentication. The credentials and roles used by the server can\nbe provided by the following environment variables:</p>\n<ul>\n<li><tt>CHRONOLOGER_USERNAME</tt></li>\n<li><tt>CHRONOLOGER_PASSWORD</tt></li>\n<li><tt>CHRONOLOGER_ROLES</tt> \u00ad\u2013 space separated role list (see below)</li>\n</ul>\n<p>Alternatively a JSON file located by <tt>CHRONOLOGER_AUTHFILE</tt> of the following\nstructure can be used to authenticate multiple users:</p>\n<pre><span class=\"p\">[</span>\n  <span class=\"p\">{</span>\n    <span class=\"nt\">\"username\"</span><span class=\"p\">:</span> <span class=\"s2\">\"bob\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"pbkdf2\"</span><span class=\"p\">:</span> <span class=\"s2\">\"f57ef1e3e8f90cb367dedd44091f251b5b15c9c36ddd7923731fa7ee41cbaa82\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"hashname\"</span><span class=\"p\">:</span> <span class=\"s2\">\"sha256\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"salt\"</span><span class=\"p\">:</span> <span class=\"s2\">\"c0139cff\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"iterations\"</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"roles\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"writer\"</span><span class=\"p\">]</span>\n  <span class=\"p\">},</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"username\"</span><span class=\"p\">:</span> <span class=\"s2\">\"obo\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"pbkdf2\"</span><span class=\"p\">:</span> <span class=\"s2\">\"ff680a9237549f698da5345119dec1ed314eb4fdefe59837d0724d747c3169089ae45...\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"hashname\"</span><span class=\"p\">:</span> <span class=\"s2\">\"sha384\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"salt\"</span><span class=\"p\">:</span> <span class=\"s2\">\"9230dbdd5a13f009\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"iterations\"</span><span class=\"p\">:</span> <span class=\"mi\">4096</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"roles\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"basic-reader\"</span><span class=\"p\">,</span> <span class=\"s2\">\"query-reader\"</span><span class=\"p\">]</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">]</span>\n</pre>\n<p>The value of <tt>pbkdf2</tt> and keys <tt>hashname</tt>, <tt>salt</tt>, <tt>iterations</tt> correspond to\nPython <tt>hashlib.pbkdf2_hmac</tt> <a href=\"#id47\" id=\"id12\" rel=\"nofollow\">[21]</a>.</p>\n<div>\n<p>Warning</p>\n<p>Note that the auth-scheme is <tt>Basic</tt> which means that the password hash is calculated\nper request. Thus <tt>iterations</tt> should be a low value (especially for writing\nusers). To compensate that it is possible to choose passwords with enough entropy.</p>\n</div>\n</div>\n<div id=\"authorisation\">\n<h3><a href=\"#id61\" rel=\"nofollow\">Authorisation</a></h3>\n<p>Chronologer defines the following roles:</p>\n<ul>\n<li><tt><span class=\"pre\">basic-reader</span></tt> allows <tt>HEAD</tt> and <tt>GET</tt> to <tt>/api/v1/record</tt></li>\n<li><tt><span class=\"pre\">query-reader</span></tt> in combination with <tt><span class=\"pre\">basic-reader</span></tt> allows the use\n<tt>query</tt>, SQL expression, to (further) filter the records</li>\n<li><tt>writer</tt> allows <tt>POST</tt> to <tt>/api/v1/record</tt></li>\n</ul>\n<p>The UI (in case <tt>chronologerui</tt> is installed) is available to every\nauthenticated user.</p>\n</div>\n<div id=\"api\">\n<h3><a href=\"#id62\" rel=\"nofollow\">API</a></h3>\n<p>By default Chronologer listens port 8080 and is protected by HTTP Basic\nAuthentication, username \u201clogger\u201d without password (see environment\nvariables to override these).</p>\n<p>Chronologer provides <em>Record</em> resource.</p>\n<div id=\"create-record\">\n<h4><a href=\"#id63\" rel=\"nofollow\">Create record</a></h4>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>URL</td>\n<td><tt>/api/v1/record</tt></td>\n</tr>\n<tr><td>Method</td>\n<td><tt>POST</tt></td>\n</tr>\n<tr><td>Request content-type</td>\n<td><tt><span class=\"pre\">application/x-www-form-urlencoded</span></tt>,\n<tt>application/json</tt>, <tt><span class=\"pre\">application/x-ndjson</span></tt></td>\n</tr>\n<tr><td>Request body</td>\n<td>Representation of <tt>logging.LogRecord</tt></td>\n</tr>\n<tr><td>Response content-type</td>\n<td><tt>application/json</tt></td>\n</tr>\n<tr><td>Response body</td>\n<td>Representation of created <tt>model.Record</tt>,\nexcept for <tt><span class=\"pre\">application/x-ndjson</span></tt> input\nwhere only a list of insert record identifiers\nis returned</td>\n</tr>\n<tr><td>Successful response code</td>\n<td><tt>201 Created</tt></td>\n</tr>\n</tbody>\n</table>\n<p>Optional <em>raw</em> mode, accepting arbitrary JSON documents, is supported by\npassing <tt>raw=1</tt> into the query string.</p>\n<p><tt><span class=\"pre\">application/x-ndjson</span></tt> request body can produce <tt>207 <span class=\"pre\">Multi-Status</span></tt>\nresponse when a successful chunk is followed by a failed chunk,\nsay that contained malformed a JSON line. Multi-status body looks like:</p>\n<pre><span class=\"p\">{</span>\n  <span class=\"nt\">\"multistatus\"</span><span class=\"p\">:</span> <span class=\"p\">[</span>\n    <span class=\"p\">{</span><span class=\"nt\">\"status\"</span><span class=\"p\">:</span> <span class=\"mi\">201</span><span class=\"p\">,</span> <span class=\"nt\">\"body\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"s2\">\"...\"</span><span class=\"p\">]},</span>\n    <span class=\"p\">{</span><span class=\"nt\">\"status\"</span><span class=\"p\">:</span> <span class=\"mi\">400</span><span class=\"p\">,</span> <span class=\"nt\">\"body\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Invalid JSON document on line 2012\"</span><span class=\"p\">},</span>\n  <span class=\"p\">]</span>\n<span class=\"p\">}</span>\n</pre>\n</div>\n<div id=\"retrieve-record-count\">\n<h4><a href=\"#id64\" rel=\"nofollow\">Retrieve record count</a></h4>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>URL</td>\n<td><tt>/api/v1/record</tt></td>\n</tr>\n<tr><td>Method</td>\n<td><tt>HEAD</tt></td>\n</tr>\n<tr><td>Query string</td>\n<td><p>Optional filtering fields (see details below):</p>\n<ul>\n<li><tt>after</tt> \u2013 ISO8601 timestamp</li>\n<li><tt>before</tt> \u2013 ISO8601 timestamp</li>\n<li><tt>level</tt> \u2013 integer logging level</li>\n<li><tt>name</tt> \u2013 logging record prefix(es)</li>\n<li><tt>query</tt> \u2013 storage-specific expression</li>\n</ul>\n</td>\n</tr>\n<tr><td>Response headers</td>\n<td><ul>\n<li><tt><span class=\"pre\">X-Record-Count:</span> 42</tt></li>\n</ul>\n</td>\n</tr>\n<tr><td>Successful response code</td>\n<td><tt>200 OK</tt></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"retrieve-record-timeline\">\n<h4><a href=\"#id65\" rel=\"nofollow\">Retrieve record timeline</a></h4>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>URL</td>\n<td><tt>/api/v1/record</tt></td>\n</tr>\n<tr><td>Method</td>\n<td><tt>HEAD</tt></td>\n</tr>\n<tr><td>Query string</td>\n<td><p>Required fields:</p>\n<ul>\n<li><tt>group</tt> \u2013 \u201cday\u201d or \u201chour\u201d</li>\n<li><tt>timezone</tt> \u2013 <tt>pytz</tt>-compatible one</li>\n</ul>\n<p>Optional filtering fields (see details below):</p>\n<ul>\n<li><tt>after</tt> \u2013 ISO8601 timestamp</li>\n<li><tt>before</tt> \u2013 ISO8601 timestamp</li>\n<li><tt>level</tt> \u2013 integer logging level</li>\n<li><tt>name</tt> \u2013 logging record prefix(es)</li>\n<li><tt>query</tt> \u2013 storage-specific expression</li>\n</ul>\n</td>\n</tr>\n<tr><td>Response headers</td>\n<td><ul>\n<li><tt><span class=\"pre\">X-Record-Count:</span> 90,236</tt></li>\n<li><tt><span class=\"pre\">X-Record-Group:</span> 1360450800,1360537200</tt></li>\n</ul>\n</td>\n</tr>\n<tr><td>Successful response code</td>\n<td><tt>200 OK</tt></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"retrieve-record-range\">\n<h4><a href=\"#id66\" rel=\"nofollow\">Retrieve record range</a></h4>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>URL</td>\n<td><tt>/api/v1/record</tt></td>\n</tr>\n<tr><td>Method</td>\n<td><tt>GET</tt></td>\n</tr>\n<tr><td>Query string</td>\n<td><p>Required fields:</p>\n<ul>\n<li><tt>left</tt> \u2013 left offset in the result set</li>\n<li><tt>right</tt> \u2013 right offset in the result set</li>\n</ul>\n<p>Optional filtering fields (see details below):</p>\n<ul>\n<li><tt>after</tt> \u2013 ISO8601 timestamp</li>\n<li><tt>before</tt> \u2013 ISO8601 timestamp</li>\n<li><tt>level</tt> \u2013 integer logging level</li>\n<li><tt>name</tt> \u2013 logging record prefix(es)</li>\n<li><tt>query</tt> \u2013 storage-specific expression</li>\n</ul>\n</td>\n</tr>\n<tr><td>Response content-type</td>\n<td><tt>application/json</tt></td>\n</tr>\n<tr><td>Response body</td>\n<td><pre>\n<span class=\"p\">[</span>\n  <span class=\"p\">{</span>\n    <span class=\"nt\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"some.module\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"ts\"</span><span class=\"p\">:</span> <span class=\"s2\">\"2018-05-10 16:36:53.377493+00:00\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"message\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Et quoniam eadem...\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"id\"</span><span class=\"p\">:</span> <span class=\"mi\">177260</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"level\"</span><span class=\"p\">:</span> <span class=\"mi\">20</span>\n  <span class=\"p\">},</span>\n  <span class=\"s2\">\"...\"</span>\n<span class=\"p\">]</span>\n</pre>\n</td>\n</tr>\n<tr><td>Successful response code</td>\n<td><tt>200 OK</tt></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"retrieve-record\">\n<h4><a href=\"#id67\" rel=\"nofollow\">Retrieve record</a></h4>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<tbody>\n<tr><td>URL</td>\n<td><tt><span class=\"pre\">/api/v1/record/{id}</span></tt></td>\n</tr>\n<tr><td>Method</td>\n<td><tt>GET</tt></td>\n</tr>\n<tr><td>Response content-type</td>\n<td><tt>application/json</tt></td>\n</tr>\n<tr><td>Response body</td>\n<td><pre>\n<span class=\"p\">{</span>\n  <span class=\"nt\">\"name\"</span><span class=\"p\">:</span> <span class=\"s2\">\"some.module\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"logrec\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"data\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"nt\">\"foo\"</span><span class=\"p\">:</span> <span class=\"mi\">387</span>\n    <span class=\"p\">},</span>\n    <span class=\"nt\">\"meta\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n      <span class=\"nt\">\"process\"</span><span class=\"p\">:</span> <span class=\"mi\">29406</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"module\"</span><span class=\"p\">:</span> <span class=\"s2\">\"some.module\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"relativeCreated\"</span><span class=\"p\">:</span> <span class=\"mf\">103.23762893676758</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"msecs\"</span><span class=\"p\">:</span> <span class=\"mf\">376.4379024505615</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"pathname\"</span><span class=\"p\">:</span> <span class=\"s2\">\"logtest.py\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"msg\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Et quoniam eadem...\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"stack_info\"</span><span class=\"p\">:</span> <span class=\"kc\">null</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"processName\"</span><span class=\"p\">:</span> <span class=\"s2\">\"MainProcess\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"filename\"</span><span class=\"p\">:</span> <span class=\"s2\">\"logtest.py\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"thread\"</span><span class=\"p\">:</span> <span class=\"mi\">140312867051264</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"threadName\"</span><span class=\"p\">:</span> <span class=\"s2\">\"MainThread\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"lineno\"</span><span class=\"p\">:</span> <span class=\"mi\">20</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"funcName\"</span><span class=\"p\">:</span> <span class=\"s2\">\"main\"</span><span class=\"p\">,</span>\n      <span class=\"nt\">\"args\"</span><span class=\"p\">:</span> <span class=\"kc\">null</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">},</span>\n  <span class=\"nt\">\"id\"</span><span class=\"p\">:</span> <span class=\"mi\">177260</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"level\"</span><span class=\"p\">:</span> <span class=\"mi\">20</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"message\"</span><span class=\"p\">:</span> <span class=\"s2\">\"Et quoniam eadem...\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"ts\"</span><span class=\"p\">:</span> <span class=\"s2\">\"2018-05-10 16:36:53.377493+00:00\"</span>\n<span class=\"p\">}</span>\n</pre>\n<p><tt>logrec</tt> has two nested dictionaries.\n<tt>data</tt> has what was passed to <tt>extra</tt> <a href=\"#id42\" id=\"id13\" rel=\"nofollow\">[16]</a>\nand <tt>meta</tt> has internal fields of\n<tt>logging.LogRecord</tt>.</p>\n</td>\n</tr>\n<tr><td>Successful response code</td>\n<td><tt>200 OK</tt></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"error-representation\">\n<h4><a href=\"#id68\" rel=\"nofollow\">Error representation</a></h4>\n<p>Errors for HTTP method requests that allow a response body are represented like:</p>\n<pre><span class=\"p\">{</span>\n  <span class=\"nt\">\"error\"</span> <span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"type\"</span>    <span class=\"p\">:</span> <span class=\"s2\">\"HTTPError\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"message\"</span> <span class=\"p\">:</span> <span class=\"s2\">\"Nothing matches the given URI\"</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</pre>\n<p>Errors for HTTP method requests that don\u2019t allow a response body are represented in the headers:</p>\n<ul>\n<li><tt><span class=\"pre\">X-Error-Type:</span> StorageQueryError</tt></li>\n<li><tt><span class=\"pre\">X-Error-Message:</span> Make sure the query filter is a valid WHERE expression</tt></li>\n</ul>\n</div>\n<div id=\"response-encoding\">\n<h4><a href=\"#id69\" rel=\"nofollow\">Response encoding</a></h4>\n<p>Chronologer supports Gzip and Brotli response body encoding. The latter takes precedence because\nit provides significant improvement for verbose logging records.</p>\n<div>\n<p>Note</p>\n<p>Modern browsers don\u2019t advertise, via <tt><span class=\"pre\">Accept-Encoding</span></tt>, Brotli support on non-HTTPS\nconnections (due to broken intermediary software concerns). In Firefox it can be forced\nby appending <tt>br</tt> to <tt><span class=\"pre\">network.http.accept-encoding</span></tt> in <tt>about:config</tt>.</p>\n</div>\n</div>\n</div>\n<div id=\"filtering\">\n<h3><a href=\"#id70\" rel=\"nofollow\">Filtering</a></h3>\n<p>Filter fields have the following semantics:</p>\n<ul>\n<li><tt>after</tt> \u2013 ISO8601 timestamp.\nThe predicate is true for a record which was created after given timestamp.</li>\n<li><tt>before</tt> \u2013 ISO8601 timestamp.\nThe predicate is true for a record which was created before given timestamp.</li>\n<li><tt>level</tt> \u2013 integer logging level.\nThe predicate is true for a record whose severity level is greater or equal to given level.</li>\n<li><tt>name</tt> \u2013 logging record prefix. Optionally can be a comma-separated list of prefixes.\nThe predicate is true for a record whose logger name starts with any of given prefixes.</li>\n<li><tt>query</tt> \u2013 storage-specific expression.\nRequires the user to have <tt><span class=\"pre\">query-reader</span></tt> role. See JSON path description below.</li>\n</ul>\n<div>\n<p>Warning</p>\n<p>Each user who has access to Chronologer with <tt><span class=\"pre\">query-reader</span></tt> role (default user\ndoes not have it) effectively has full access to its database, because <tt>query</tt>\nexpressions are put into the SQL queries directly as there\u2019s no intent to\nabstract native database search features.</p>\n</div>\n</div>\n<div id=\"mysql\">\n<h3><a href=\"#id71\" rel=\"nofollow\">MySQL</a></h3>\n<p>Chronologer relies on a compressed InnoDB table which provides good compromise\nbetween reliability, data modelling, search features, performance and size of\nlogged data. The data of logging records are written into <tt>logrec</tt> JSON\nfield (see the initial migration <a href=\"#id35\" id=\"id14\" rel=\"nofollow\">[9]</a> and examples above).</p>\n<p>It is a good idea to have dedicated MySQL instance for Chronologer. Then, for\ninstance, it is possible to fine-tune MySQL\u2019s ACID guarantees, namely\n<tt>innodb_flush_log_at_trx_commit = 0</tt> allow MySQL to write 1-second batches\n<a href=\"#id36\" id=\"id15\" rel=\"nofollow\">[10]</a>. Disabling performance schema <a href=\"#id37\" id=\"id16\" rel=\"nofollow\">[11]</a> by setting <tt>performance_schema = 0</tt>\nis also recommended, because it has significant overhead. Basic InnoDB settings\nshould be reasonably configured:</p>\n<ul>\n<li><tt>innodb_buffer_pool_size</tt> <a href=\"#id38\" id=\"id17\" rel=\"nofollow\">[12]</a></li>\n<li><tt>innodb_log_buffer_size</tt> <a href=\"#id39\" id=\"id18\" rel=\"nofollow\">[13]</a></li>\n<li><tt>innodb_log_file_size</tt> <a href=\"#id40\" id=\"id19\" rel=\"nofollow\">[14]</a></li>\n</ul>\n<div id=\"json-path-query\">\n<h4><a href=\"#id72\" rel=\"nofollow\">JSON path query</a></h4>\n<p><tt>query</tt> passes a storage-specific expression. Particularly, it\u2019s useful\nto write post-filtering conditions for <tt>logrec</tt> JSON field using\nJSONPath expressions and <tt><span class=\"pre\">-&gt;</span></tt> operator <a href=\"#id41\" id=\"id20\" rel=\"nofollow\">[15]</a>. It may look like the following,\nthough arbitrary <tt>WHERE</tt> clause expressions are possible.</p>\n<ul>\n<li><tt><span class=\"pre\">\"logrec-&gt;'$.data.foo'</span> = 387 AND <span class=\"pre\">logrec-&gt;'$.meta.lineno'</span> = 20\"</tt></li>\n<li><tt><span class=\"pre\">\"logrec-&gt;'$.meta.threadName'</span> != 'MainThread'\"</tt></li>\n</ul>\n<p>Note that connection to MySQL works in <tt>ANSI_QUOTES</tt> mode <a href=\"#id44\" id=\"id21\" rel=\"nofollow\">[18]</a>, so <tt>\"</tt>\ncannot be used to form string literals. <tt>'</tt> must be used instead.</p>\n</div>\n<div id=\"compression-tuning\">\n<h4><a href=\"#id73\" rel=\"nofollow\">Compression tuning</a></h4>\n<p>Initial migration <a href=\"#id35\" id=\"id22\" rel=\"nofollow\">[9]</a> sets <tt>KEY_BLOCK_SIZE = 4</tt>. It may be sub-optimal for\nthe shape of your log records. MySQL provides guidelines for choosing\n<tt>KEY_BLOCK_SIZE</tt> <a href=\"#id49\" id=\"id23\" rel=\"nofollow\">[23]</a> and monitoring \u201ccompression failures\u201d\nat runtime <a href=\"#id50\" id=\"id24\" rel=\"nofollow\">[24]</a>.</p>\n<p>If you want to change <tt>KEY_BLOCK_SIZE</tt> for <tt>record</tt> table, you can provide\nyour own database migration. Chronologer uses yoyo-migrations <a href=\"#id51\" id=\"id25\" rel=\"nofollow\">[25]</a> for\ndatabase migrations. For example, to switch to <tt>KEY_BLOCK_SIZE = 8</tt>\nmigration file, named <tt>20190803T1404_key_size.py</tt>, will look like:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">yoyo</span> <span class=\"kn\">import</span> <span class=\"n\">step</span>\n\n<span class=\"n\">step</span><span class=\"p\">(</span><span class=\"s1\">'ALTER TABLE record KEY_BLOCK_SIZE = 8'</span><span class=\"p\">)</span>\n</pre>\n<p>It can be mounted into the migration directory of Chonologer\u2019s container\nin your <tt><span class=\"pre\">docker-compose.yml</span></tt> like:</p>\n<pre><span class=\"nt\">volumes</span><span class=\"p\">:</span>\n  <span class=\"p-Indicator\">-</span> <span class=\"l-Scalar-Plain\">./20190803T1404_key_size.py:/opt/chronologer/chronologer/migration/mysql/20190803T1404_key_size.py</span>\n</pre>\n<p>Then re-apply migrations with <tt>migrate</tt> or run <tt>serve</tt> with <tt><span class=\"pre\">-m</span></tt> command\nline flag.</p>\n</div>\n</div>\n<div id=\"sqlite\">\n<h3><a href=\"#id74\" rel=\"nofollow\">SQLite</a></h3>\n<p>SQLite is supported for very simple, one-off or evaluation cases. Also it doesn\u2019t\nsupport compression. <tt>JSON1</tt> extension <a href=\"#id46\" id=\"id26\" rel=\"nofollow\">[20]</a> is required for JSON Path queries.</p>\n<ul>\n<li><tt>\"json_extract(logrec, <span class=\"pre\">'$.data.foo')</span> = 387 AND json_extract(logrec, <span class=\"pre\">'$.meta.lineno')</span> = 20\"</tt></li>\n<li><tt>\"json_extract(logrec, <span class=\"pre\">'$.meta.threadName')</span> = 'MainThread'\"</tt></li>\n</ul>\n<p>A one-off Chronologer container with SQLite storage can be run on port 8080 like:</p>\n<pre>docker run --rm -it -p 8080:8080 -v /tmp/db \\\n  -e CHRONOLOGER_STORAGE_DSN=sqlite:////tmp/db/chrono.sqlite \\\n  -e CHRONOLOGER_SECRET=some_long_random_string \\\n  saaj/chronologer \\\n  python3.7 -m chronologer -e production serve -u www-data -g www-data -m\n</pre>\n<p>Two things to note:</p>\n<ol>\n<li><tt><span class=\"pre\">-m</span></tt> to <tt>serve</tt> runs migrations before starting the server,</li>\n<li>SQLite needs permissions to the directory where a database file\nresides, to write its temporary files.</li>\n</ol>\n</div>\n<div id=\"r-d-roadmap\">\n<h3><a href=\"#id75\" rel=\"nofollow\">R&amp;D roadmap</a></h3>\n<p>See the <a href=\"https://bitbucket.org/saaj/chronologer/issues/1\" rel=\"nofollow\">roadmap</a> issue.</p>\n</div>\n<div id=\"credits\">\n<h3><a href=\"#id76\" rel=\"nofollow\">Credits</a></h3>\n<p>Logo is contributed by <a href=\"https://www.behance.net/lightypaints\" rel=\"nofollow\">lightypaints</a>.</p>\n<hr class=\"docutils\">\n<table id=\"id27\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id1\" rel=\"nofollow\">[1]</a></td><td><a href=\"https://docs.python.org/3/library/logging.handlers.html#httphandler\" rel=\"nofollow\">https://docs.python.org/3/library/logging.handlers.html#httphandler</a></td></tr>\n</tbody>\n</table>\n<table id=\"id28\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id2\" rel=\"nofollow\">[2]</a></td><td><a href=\"https://packages.debian.org/sid/rsyslog-mysql\" rel=\"nofollow\">https://packages.debian.org/sid/rsyslog-mysql</a></td></tr>\n</tbody>\n</table>\n<table id=\"id29\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id4\" rel=\"nofollow\">[3]</a></td><td><a href=\"https://pypi.org/project/Chronologer/\" rel=\"nofollow\">https://pypi.org/project/Chronologer/</a></td></tr>\n</tbody>\n</table>\n<table id=\"id30\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id5\" rel=\"nofollow\">[4]</a></td><td><a href=\"https://hub.docker.com/r/saaj/chronologer/\" rel=\"nofollow\">https://hub.docker.com/r/saaj/chronologer/</a></td></tr>\n</tbody>\n</table>\n<table id=\"id31\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id6\" rel=\"nofollow\">[5]</a></td><td><a href=\"https://bitbucket.org/saaj/chronologer/src/backend/chronologer/envconf.py\" rel=\"nofollow\">https://bitbucket.org/saaj/chronologer/src/backend/chronologer/envconf.py</a></td></tr>\n</tbody>\n</table>\n<table id=\"id32\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id8\" rel=\"nofollow\">[6]</a></td><td><a href=\"https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing</a></td></tr>\n</tbody>\n</table>\n<table id=\"id33\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id9\" rel=\"nofollow\">[7]</a></td><td><a href=\"https://docs.python.org/3/library/logging.handlers.html#queuelistener\" rel=\"nofollow\">https://docs.python.org/3/library/logging.handlers.html#queuelistener</a></td></tr>\n</tbody>\n</table>\n<table id=\"id34\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id10\" rel=\"nofollow\">[8]</a></td><td><a href=\"https://pypi.org/project/pqueue/\" rel=\"nofollow\">https://pypi.org/project/pqueue/</a></td></tr>\n</tbody>\n</table>\n<table id=\"id35\">\n<col><col>\n<tbody>\n<tr><td>[9]</td><td><em>(<a href=\"#id14\" rel=\"nofollow\">1</a>, <a href=\"#id22\" rel=\"nofollow\">2</a>)</em> <a href=\"https://bitbucket.org/saaj/chronologer/src/d5d4daa/chronologer/migration/mysql/20171026T1428_initial.py\" rel=\"nofollow\">https://bitbucket.org/saaj/chronologer/src/d5d4daa/chronologer/migration/mysql/20171026T1428_initial.py</a></td></tr>\n</tbody>\n</table>\n<table id=\"id36\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id15\" rel=\"nofollow\">[10]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit</a></td></tr>\n</tbody>\n</table>\n<table id=\"id37\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id16\" rel=\"nofollow\">[11]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/performance-schema.html\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/performance-schema.html</a></td></tr>\n</tbody>\n</table>\n<table id=\"id38\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id17\" rel=\"nofollow\">[12]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_buffer_pool_size\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_buffer_pool_size</a></td></tr>\n</tbody>\n</table>\n<table id=\"id39\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id18\" rel=\"nofollow\">[13]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_log_buffer_size\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_log_buffer_size</a></td></tr>\n</tbody>\n</table>\n<table id=\"id40\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id19\" rel=\"nofollow\">[14]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_log_file_size\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_log_file_size</a></td></tr>\n</tbody>\n</table>\n<table id=\"id41\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id20\" rel=\"nofollow\">[15]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/json-search-functions.html#operator_json-column-path\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/json-search-functions.html#operator_json-column-path</a></td></tr>\n</tbody>\n</table>\n<table id=\"id42\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id13\" rel=\"nofollow\">[16]</a></td><td><a href=\"https://docs.python.org/3/library/logging.html#logging.debug\" rel=\"nofollow\">https://docs.python.org/3/library/logging.html#logging.debug</a></td></tr>\n</tbody>\n</table>\n<table id=\"id43\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id3\" rel=\"nofollow\">[17]</a></td><td><a href=\"https://pypi.org/project/ChronologerUI/\" rel=\"nofollow\">https://pypi.org/project/ChronologerUI/</a></td></tr>\n</tbody>\n</table>\n<table id=\"id44\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id21\" rel=\"nofollow\">[18]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sqlmode_ansi_quotes\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sqlmode_ansi_quotes</a></td></tr>\n</tbody>\n</table>\n<table id=\"id45\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id11\" rel=\"nofollow\">[19]</a></td><td><a href=\"https://github.com/ndjson/ndjson-spec\" rel=\"nofollow\">https://github.com/ndjson/ndjson-spec</a></td></tr>\n</tbody>\n</table>\n<table id=\"id46\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id26\" rel=\"nofollow\">[20]</a></td><td><a href=\"https://www.sqlite.org/json1.html\" rel=\"nofollow\">https://www.sqlite.org/json1.html</a></td></tr>\n</tbody>\n</table>\n<table id=\"id47\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id12\" rel=\"nofollow\">[21]</a></td><td><a href=\"https://docs.python.org/3/library/hashlib.html#hashlib.pbkdf2_hmac\" rel=\"nofollow\">https://docs.python.org/3/library/hashlib.html#hashlib.pbkdf2_hmac</a></td></tr>\n</tbody>\n</table>\n<table id=\"id48\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id7\" rel=\"nofollow\">[22]</a></td><td><a href=\"https://bitbucket.org/saaj/chronologer/src/backend/perftest/\" rel=\"nofollow\">https://bitbucket.org/saaj/chronologer/src/backend/perftest/</a></td></tr>\n</tbody>\n</table>\n<table id=\"id49\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id23\" rel=\"nofollow\">[23]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-compression-tuning.html\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/innodb-compression-tuning.html</a></td></tr>\n</tbody>\n</table>\n<table id=\"id50\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id24\" rel=\"nofollow\">[24]</a></td><td><a href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-compression-tuning-monitoring.html\" rel=\"nofollow\">https://dev.mysql.com/doc/refman/5.7/en/innodb-compression-tuning-monitoring.html</a></td></tr>\n</tbody>\n</table>\n<table id=\"id51\">\n<col><col>\n<tbody>\n<tr><td><a href=\"#id25\" rel=\"nofollow\">[25]</a></td><td><a href=\"https://pypi.python.org/pypi/yoyo-migrations\" rel=\"nofollow\">https://pypi.python.org/pypi/yoyo-migrations</a></td></tr>\n</tbody>\n</table>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5628442, "releases": {"0.1.4": [{"comment_text": "", "digests": {"md5": "19f9a3de42dcef476bc1234787302d95", "sha256": "a7ef1c6139d05c8cc139f18216cef076fd14ccd6595dba877c8763ce69d7102f"}, "downloads": -1, "filename": "Chronologer-0.1.4.tar.gz", "has_sig": false, "md5_digest": "19f9a3de42dcef476bc1234787302d95", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 625343, "upload_time": "2018-05-16T20:41:29", "upload_time_iso_8601": "2018-05-16T20:41:29.550970Z", "url": "https://files.pythonhosted.org/packages/19/87/707fffd6b7061bb27988978914bec8d913ecd141caceab8dc88c40341ce1/Chronologer-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "b62211fda1f601b78c7c1a73f64405d0", "sha256": "4900ea6872ee7b7f7fe44e328f86d8921394fc9185a0b1de9c2b29689836b22d"}, "downloads": -1, "filename": "Chronologer-0.1.5.tar.gz", "has_sig": false, "md5_digest": "b62211fda1f601b78c7c1a73f64405d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 626726, "upload_time": "2018-05-21T17:05:21", "upload_time_iso_8601": "2018-05-21T17:05:21.387588Z", "url": "https://files.pythonhosted.org/packages/28/6c/ce75fde520afc8b6f580414cce895673e6e9ed0493cd2dacdb6fefa870b9/Chronologer-0.1.5.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "b6b01ea88f90168d656a0ad5b39f0dbd", "sha256": "38dd640b1d9230c88f8f62520e0907114e20abe87e2d89c60e3a13c517eb7e09"}, "downloads": -1, "filename": "Chronologer-0.2.1.tar.gz", "has_sig": false, "md5_digest": "b6b01ea88f90168d656a0ad5b39f0dbd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21306, "upload_time": "2018-09-30T20:50:05", "upload_time_iso_8601": "2018-09-30T20:50:05.523538Z", "url": "https://files.pythonhosted.org/packages/51/49/9d70c17f2a2dbd0143228b7753e5429ba5c2788b248918072b117094eb4f/Chronologer-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "f334f8c2cd0430aa8fe73aefa8c6329f", "sha256": "02ef482c7061470f66ae29d86b4e5015ed6eca916672e8842d50099a49fdfab5"}, "downloads": -1, "filename": "Chronologer-0.3.0.tar.gz", "has_sig": false, "md5_digest": "f334f8c2cd0430aa8fe73aefa8c6329f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38635, "upload_time": "2019-01-13T20:56:26", "upload_time_iso_8601": "2019-01-13T20:56:26.024531Z", "url": "https://files.pythonhosted.org/packages/d7/bb/0e08a79d4a6cfb3394c92219d0e4b36310fe01c3dc979d3b8ec80565c466/Chronologer-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "67f5798134f62b2c75496f38b343bbf8", "sha256": "2a2ef10cbe2dc3cc3b9519d5f2468168c7bc624a544d66840fca561340bfb85c"}, "downloads": -1, "filename": "Chronologer-0.3.1.tar.gz", "has_sig": false, "md5_digest": "67f5798134f62b2c75496f38b343bbf8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42309, "upload_time": "2019-01-26T14:23:06", "upload_time_iso_8601": "2019-01-26T14:23:06.203221Z", "url": "https://files.pythonhosted.org/packages/3a/87/7157fd126a7088bbbe1e559bb65746f79b22e4bca8f1e40d83d1d7e40841/Chronologer-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "23f374574ae0c2323908201dcd01b33e", "sha256": "761ea0d464115a72d6cc4f0176d8707880014e849f59ef110705f7bc87057bea"}, "downloads": -1, "filename": "Chronologer-0.3.2.tar.gz", "has_sig": false, "md5_digest": "23f374574ae0c2323908201dcd01b33e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42386, "upload_time": "2019-01-26T15:38:04", "upload_time_iso_8601": "2019-01-26T15:38:04.666966Z", "url": "https://files.pythonhosted.org/packages/01/48/f406094517d23ef74c48e052bf17474591b29964227886c63b5ff95fa23e/Chronologer-0.3.2.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "fee798532571140e4fa855a60da62214", "sha256": "b3f04621575b190e0a3aa8967628af32a6ea9469935f27127d67616d6e50d129"}, "downloads": -1, "filename": "Chronologer-0.4.0.tar.gz", "has_sig": false, "md5_digest": "fee798532571140e4fa855a60da62214", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55589, "upload_time": "2019-04-28T18:49:32", "upload_time_iso_8601": "2019-04-28T18:49:32.102644Z", "url": "https://files.pythonhosted.org/packages/7c/95/883d265bb7731fb3876eb2abeba9baa1241277c86628c6f336480f320bc6/Chronologer-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "6990b7c79bf3ed1cfb367a69a7732b85", "sha256": "cb4ff6baf26ad18537c7d302d0c97089bf17e7249961c76f61829b0544a1bf9d"}, "downloads": -1, "filename": "Chronologer-0.4.1.tar.gz", "has_sig": false, "md5_digest": "6990b7c79bf3ed1cfb367a69a7732b85", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55607, "upload_time": "2019-04-28T19:00:15", "upload_time_iso_8601": "2019-04-28T19:00:15.634781Z", "url": "https://files.pythonhosted.org/packages/e0/3d/b53b4e9a6d83bdace3296b65e6c2b3d9a30be63a1088ff1b3c62c3e1a165/Chronologer-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "2668671aa106860329bd18cbc4755145", "sha256": "d09ca576c2e33766d2ced03b5add3a399c1ae6b69048119a6343e8a0ec65960d"}, "downloads": -1, "filename": "Chronologer-0.4.2.tar.gz", "has_sig": false, "md5_digest": "2668671aa106860329bd18cbc4755145", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 55608, "upload_time": "2019-04-28T19:54:05", "upload_time_iso_8601": "2019-04-28T19:54:05.890718Z", "url": "https://files.pythonhosted.org/packages/8e/22/8aad0f5a8b2ac29aacaffc0fae9ddce73aa6dca473267bbcd67c179a955b/Chronologer-0.4.2.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "1f8919fc1fe813a59d61c29688f8be0a", "sha256": "4c1073ba79025b15d80702108413ae0c2ea24bf7b21cc322cf13ad09405ff76f"}, "downloads": -1, "filename": "Chronologer-0.4.3.tar.gz", "has_sig": false, "md5_digest": "1f8919fc1fe813a59d61c29688f8be0a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57373, "upload_time": "2019-08-03T15:17:58", "upload_time_iso_8601": "2019-08-03T15:17:58.330241Z", "url": "https://files.pythonhosted.org/packages/c0/29/decbccf31b18600b81c8b527957eaae8743d2bf69e600391a06375443e54/Chronologer-0.4.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1f8919fc1fe813a59d61c29688f8be0a", "sha256": "4c1073ba79025b15d80702108413ae0c2ea24bf7b21cc322cf13ad09405ff76f"}, "downloads": -1, "filename": "Chronologer-0.4.3.tar.gz", "has_sig": false, "md5_digest": "1f8919fc1fe813a59d61c29688f8be0a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57373, "upload_time": "2019-08-03T15:17:58", "upload_time_iso_8601": "2019-08-03T15:17:58.330241Z", "url": "https://files.pythonhosted.org/packages/c0/29/decbccf31b18600b81c8b527957eaae8743d2bf69e600391a06375443e54/Chronologer-0.4.3.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:19:28 2020"}