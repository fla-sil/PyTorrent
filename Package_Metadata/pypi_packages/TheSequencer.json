{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Operating System :: Unix", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering", "Topic :: Software Development"], "description": "# The Sequencer\nAn algorithm that detects one-dimensional trends (=sequences) in complex datasets. \n\n## Overview\nThe Sequencer is an algorithm that attempts to reveal the main sequence in a dataset, if it exists.  To do so, it reorders objects within a set to produce the most elongated manifold describing their similarities which are measured in a multi-scale manner and using a collection of metrics. To be generic, it combines information from four different metrics: the Euclidean Distance, the Kullback-Leibler Divergence, the Monge-Wasserstein or Earth Mover Distance, and the Energy Distance. It considers different scales of the data by dividing each object in the input data into separate parts (chunks), and estimating pair-wise similarities between the chunks. It then aggregates the information in each of the chunks into a single estimator for each metric+scale.\n\nThe Sequencer uses the shape of the graphs describing the multi-scale similarities. In particular, it uses the fact that continuous trends (sequences) in a dataset lead to more elongated graphs. By defining the elongation of the graphs as a figure of merit, the Sequencer can optimize over its hyper-parameters (the distance metrics and scales) and select the set of metric+scale that are most sensitive to the presence of a sequence in the data. The elongation of the graph is measured using the graph's elongation. Thus, the final output of the Sequencer is the detected sequence and its associated elongation. Small elongation (~1) suggests no clear sequence in the data, and large elongation (~N, where N is the number of objects in the sample) suggests that the Sequencer detected a significant sequence in the data. \n\nThe Sequencer is essentially an Unsupervised Dimensionality Reduction algorithm, since a sequence is a one-dimensional embedding of the input dataset. There are several differences between the Sequencer and other dimensionality reduction techniques like tSNE and UMAP. First, the Sequencer can only embed the input dataset into a single dimension, while algorithms like tSNE and UMAP can embed the data into higher dimensions as well (2D or 3D). The main advantage of the Sequencer is that it uses a figure of merit to optimize over its hyper-parameters, while other dimensionality reduction algorithms depend on a set of hyper-parameters and lack a clear figure of merit with which these can be optimized. As a result, the output of other dimensionality reduction algorithms depends on a set of chosen hyper-parameters, which are often set manually. In our work, we show that in some cases the Sequencer outperforms tSNE and UMAP in finding one-dimensional trends in the data, especially in scientific datasets. We also show that the elongation of a graph can be used to define a figure of merit for algorithms like tSNE and UMAP as well. This figure of merit can be used to select the hyper-parameters that will give rise to the \"best\" tSNE and UMAP embedding (see our paper and the jupyter notebooks in the examples directory).\n\n## Online Interface\nFor those who are not very familiar with python: there is an online interface where one can upload their dataset and the Sequencer will be applied to it: http://sequencer.org/.\n\n## Authors\n* Dalya Baron (Tel Aviv University; dalyabaron@gmail.com)\n* Brice M\u00e9nard (Johns Hopkins University)\n\n## Requirements\nThe Sequencer is implemented in python and requires the following:\n* python 3.7.1\n* numpy 1.18.1\n* scipy 1.3.1\n* networkx 2.4\n\nTo run the Jupyter notebooks in the examples directory, and to compare the Sequencer to tSNE and UMAP, you will also need:\n* matplotlib 3.1.2\n* scikit-learn 0.22.1 (to run tSNE)\n* umap 0.3.9 (to run UMAP; https://github.com/lmcinnes/umap)\n\n## How to install the Sequencer \n\n### Using PyPI:\nAssuming you have installed numpy, scipy, and networkx, then using PyPI install:\n```\npip install TheSequencer\n```\nIf you need to install the required packages, then we suggest to install them manually using anaconda:\n```\nconda install numpy scipy\nconda install networkx\npip install TheSequencer\n```\nIf you also want to run the Jupyter notebooks in the examples directory, then install the following:\n```\nconda install numpy scipy\nconda install networkx\nconda install matplotlib\nconda install scikit-learn\nconda install -c conda-forge umap-learn\npip install TheSequencer\n```\n\n### Manual installation:\nFor a manual installation:\n```\nwget https://github.com/dalya/Sequencer/archive/master.zip\nunzip master.zip\nrm master.zip\ncd Sequencer-master/\n```\nInstall the requirements:\n```\nsudo pip install -r requirements.txt\n```\nInstall the package:\n```\npython setup.py install\n```\n\n## How to use the Sequencer\nThe examples directory consists of several Jupyter notebooks showing how to use the Sequencer. New users are encoraged to start with the notebook `basic_sequencer_functionalities.ipynb`, which explains the basic functionalities of the Sequencer.\n\nBelow there is an example of a simple Sequencer run with default parameters:\n```python\nimport sequencer\n\n# define the Sequencer object\nestimator_list = ['EMD', 'energy', 'KL', 'L2']\nseq = sequencer.Sequencer(grid, objects_list, estimator_list)\n\n# execute the Sequencer\noutput_directory_path = \"sequencer_output_directory\"\nfinal_elongation, final_sequence = seq.execute(output_directory_path)\n```\nThe definition of the `Sequencer` object required a few input parameters: `grid`: the x-axis of the objects and `objects_list`: a list of the objects. This is the input dataset within which we want to find a sequence. The `estimator_list` is a list of strings containing the distance metrics to be considered during the algorithm run. It contains four distance metrics at the moment: `'EMD'`=Earth Mover Distance, `'energy'`=Energy Distance, `'KL'`=Kullback-Leibler Divergence, and `'L2'`=Euclidean Distance. The Sequnecer defines a list of scales it will consider automatically, where the number and values of the scales will be determined by the size of the data. However, users can set the scales by themselves. For example, if we wish to consider only the largest scales, and not to divide the objects into chunks, then:\n```python\n# define the Sequencer object\nestimator_list = ['EMD', 'energy', 'KL', 'L2']\nscale_list = [[1], [1], [1], [1]]\nseq = sequencer.Sequencer(grid, objects_list, estimator_list, scale_list)\n```\nIf instead we are intrested in small-scale information, where we want to split each object into 10 separate parts and examine them separately, then:\n```python\n# define the Sequencer object\nestimator_list = ['EMD', 'energy', 'KL', 'L2']\nscale_list = [[10], [10], [10], [10]]\nseq = sequencer.Sequencer(grid, objects_list, estimator_list, scale_list)\n```\nFinally, if we do not know a-priori on which scale the relevant information is, we might want to examine several scales:\n```python\n# define the Sequencer object\nestimator_list = ['EMD', 'energy', 'KL', 'L2']\nscale_list = [[1, 2, 4, 8], [1, 2, 4, 8], [1, 2, 4, 8], [1, 2, 4, 8]]\nseq = sequencer.Sequencer(grid, objects_list, estimator_list, scale_list)\n```\nThis means that for each metric, the Sequencer will examine four different scales: 1, 2, 4, ans 8. A `scale=2` means that the Sequencer will split the objects into two parts and will search for a sequence in each of the parts separately. It will then aggregate the information from both of the parts into a single estimator. Finally, it will aggregate the information from all the combinations of metrics+scales into a single estimator, where metrics+scales that result in larger elongations will get a higher weight in the final product.\n\nTo execute the `Sequencer` obejct, we needed to define `output_directory_path`, which is a path of a directory to which different Sequencer products will be saved. The final output of the function consists of: (1) `final_elongation`: the elongation of the resulting sequence. An elongation that is close to 1 suggests no clear sequence in the data. An elongation close to N, where N is the number of objects in the sample, suggests that the Sequencer detected a significant sequence in the data. (2) `final_sequence`: the resulting sequence. This is an array that contains the relative order of the different objects in the sample, such that they form the detected sequence.\n\n## Examples directory\nThe [examples directory](https://github.com/dalya/Sequencer/tree/master/examples) contains several Jupyter notebooks that illustrate different aspects of the Sequencer algorithm. Users who are not familiar with the Sequencer are encouraged to go through the examples in the following order:\n1. `basic_sequencer_functionalities.ipynb`: this notebook shows the basic functionalities of the algorithm. It shows how to apply the Sequencer to a simple simulated dataset with default settings. It shows how to extract various interesting properties of the algorithm, such as the intermediate elongations obtained during the calculation. It then shows some non-default settings that the user should be aware of (parallelization, varying scales, output options). \n2. `comparison_with_tsne_and_umap.ipynb`: this notebook compares the Sequencer output to the one-dimensional embedding by tSNE and UMAP for a simulated dataset. Importantly, this notebook presents a method to define a general figure of merit for Dimensionality Reduction algorithms that can be used to optimize their hyper-parameters. Using this figure of merit, we can optimize the hyper-parameters of tSNE and UMAP and compare their resulting sequence to the one obtained with the Sequencer.\n3. `examples_with_natural_images.ipynb`: this notebook shows examples with scrambled natural images. In this notebook, the rows of different natural images are shuffled, and then the Sequencer is applied to the shuffled dataset with the goal of recovering the original image. Finally, the notebook shows the application of tSNE and UMAP to the shuffled images, while varying their hyper-parameters. It illustrates the importance of defining a figure of merit to optimize the hyper-parameters of dimensionality reduction algorithms (the user should go over the notebook `comparison_with_tsne_and_umap.ipynb` before going over this notebook).\n4. `importance_of_multi_scale_approach.ipynb`: this notebook applies the Sequencer to stellar spectra, which are 1D objects with relevant information on many different scales (both small scales and large scales). The notebook shows how to extract the intermediate elongations of different chunks of data, and using these, illustrates the importance of the multi-scale approach of the Sequencer.\n5. `beyond_1D_sequence.ipynb`: the Sequencer provides a one-dimensional embedding of the input dataset. This notebook shows how we can go beyond a 1D sequence using a method somewhat similar to PCA: once the main trend in the data is detected, we can 'strip' it from the data, and apply the Sequencer to detect the second strongest trend in the data, and so on. \n6. `two_dimensional_objects.ipynb`: so far, we applied the Sequencer to datasets consisting of 1D objects. This notebook shows how to apply the Sequencer to a dataset consisting of 2D objects (images).\n\n## Selected results\n### Shuffled image rows\nThe Sequencer reorders the objects in the input dataset according to a detected sequence, if such sequence exists in the dataset. A good example of a perfect one-dimensional sequence is a natural image: the rows within a natural image form a well-defined sequence. Therefore, we can shuffle the rows in a natural image, and apply the Sequencer to the shuffled dataset. The following figure shows the result of applying the Sequencer to a shuffled natural image. The left panel shows the original image. The middle panel shows the same image after we have shuffled its rows. The shuffled image serves as the input dataset to the Sequencer, where each row is considered as a separate object. The output of the Sequencer is shown in the right panel, where we reordered the rows according to the detected sequence. The Sequencer successfully identified the one-dimensional trend spanned by the different rows.\n\n![](images/natural_image_example.png)\n\nWe examine several cases of scrambled natural images in the Jupyter notebook `examples_with_natural_images.ipynb` in the examples directory. For each of the images, we shuffle its rows and apply the Sequencer to the shuffled dataset with the goal of recovering the original image. We also compare the result of the Sequencer to the one-dimensional embedding by tSNE and UMAP.\n\n### Simulated dataset with a sequence on small scales\nThe following figure shows an example of a simulated dataset with a clear one-dimensional sequence. The top left panel shows the input dataset, where each row is a separate object and the color-coding represents the relative intensity in each of its pixels. The objects are constructed to have both small-scale and large-scale fluctuations, and some added noise. In addition, we added several narrow pulses to each of the objects, such that their relative location forms a clear one-dimensional sequence. In the top right panel we show the output of the Sequencer, where we reordered the objects (rows) according to the detected sequence. Although the narrow pulses constitute a small fraction of the total integrated intensity in each object, the Sequencer correctly identified the one-dimensional trend. The success of the Sequencer in detecting this trend is a direct result of our multi-scale approach. The bottom panel shows the best one-dimensional embedding by tSNE and UMAP. One can see that the output of both of the algorithms is driven by the large-scale fluctuations. This result illustrates that tSNE and UMAP are not optimized to find the most elongated manifold in the dataset if it is not distributed over the full scale of the data.\n\n![](images/synthetic_data_seq_box_plots.png)\n\nWe construct the simulated dataset and compare the Sequencer output to the one-dimensional embedding by tSNE and UMAP in the Jupyter notebook `comparison_with_tsne_and_umap.ipynb` in the examples directory. In addition, we show there how to define a general figure of merit for the one-dimensional embedding of any Dimensionality Reduction algorithm, using the graph elongation. We show how this figure of merit can be used to optimize the hyper-parameters of algorithms such as tSNE and UMAP, and thus select the \"best\" one-dimensional embedding.\n\n## Citation \nXXX remains to be written\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dalya/Sequencer", "keywords": "dimensionality reduction t-sne UMAP", "license": "BSD", "maintainer": "Dalya Baron", "maintainer_email": "dalyabaron@gmail.com", "name": "TheSequencer", "package_url": "https://pypi.org/project/TheSequencer/", "platform": "", "project_url": "https://pypi.org/project/TheSequencer/", "project_urls": {"Homepage": "https://github.com/dalya/Sequencer"}, "release_url": "https://pypi.org/project/TheSequencer/0.0.5/", "requires_dist": ["numpy (>=1.13)", "scikit-learn (>=0.20)", "scipy (>=1.0)", "networkx (>=2.4)", "joblib (>=0.13.2)"], "requires_python": ">=3.6", "summary": "An algorithm that detects one-dimensional sequences in complex datasets", "version": "0.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>The Sequencer</h1>\n<p>An algorithm that detects one-dimensional trends (=sequences) in complex datasets.</p>\n<h2>Overview</h2>\n<p>The Sequencer is an algorithm that attempts to reveal the main sequence in a dataset, if it exists.  To do so, it reorders objects within a set to produce the most elongated manifold describing their similarities which are measured in a multi-scale manner and using a collection of metrics. To be generic, it combines information from four different metrics: the Euclidean Distance, the Kullback-Leibler Divergence, the Monge-Wasserstein or Earth Mover Distance, and the Energy Distance. It considers different scales of the data by dividing each object in the input data into separate parts (chunks), and estimating pair-wise similarities between the chunks. It then aggregates the information in each of the chunks into a single estimator for each metric+scale.</p>\n<p>The Sequencer uses the shape of the graphs describing the multi-scale similarities. In particular, it uses the fact that continuous trends (sequences) in a dataset lead to more elongated graphs. By defining the elongation of the graphs as a figure of merit, the Sequencer can optimize over its hyper-parameters (the distance metrics and scales) and select the set of metric+scale that are most sensitive to the presence of a sequence in the data. The elongation of the graph is measured using the graph's elongation. Thus, the final output of the Sequencer is the detected sequence and its associated elongation. Small elongation (~1) suggests no clear sequence in the data, and large elongation (~N, where N is the number of objects in the sample) suggests that the Sequencer detected a significant sequence in the data.</p>\n<p>The Sequencer is essentially an Unsupervised Dimensionality Reduction algorithm, since a sequence is a one-dimensional embedding of the input dataset. There are several differences between the Sequencer and other dimensionality reduction techniques like tSNE and UMAP. First, the Sequencer can only embed the input dataset into a single dimension, while algorithms like tSNE and UMAP can embed the data into higher dimensions as well (2D or 3D). The main advantage of the Sequencer is that it uses a figure of merit to optimize over its hyper-parameters, while other dimensionality reduction algorithms depend on a set of hyper-parameters and lack a clear figure of merit with which these can be optimized. As a result, the output of other dimensionality reduction algorithms depends on a set of chosen hyper-parameters, which are often set manually. In our work, we show that in some cases the Sequencer outperforms tSNE and UMAP in finding one-dimensional trends in the data, especially in scientific datasets. We also show that the elongation of a graph can be used to define a figure of merit for algorithms like tSNE and UMAP as well. This figure of merit can be used to select the hyper-parameters that will give rise to the \"best\" tSNE and UMAP embedding (see our paper and the jupyter notebooks in the examples directory).</p>\n<h2>Online Interface</h2>\n<p>For those who are not very familiar with python: there is an online interface where one can upload their dataset and the Sequencer will be applied to it: <a href=\"http://sequencer.org/\" rel=\"nofollow\">http://sequencer.org/</a>.</p>\n<h2>Authors</h2>\n<ul>\n<li>Dalya Baron (Tel Aviv University; <a href=\"mailto:dalyabaron@gmail.com\">dalyabaron@gmail.com</a>)</li>\n<li>Brice M\u00e9nard (Johns Hopkins University)</li>\n</ul>\n<h2>Requirements</h2>\n<p>The Sequencer is implemented in python and requires the following:</p>\n<ul>\n<li>python 3.7.1</li>\n<li>numpy 1.18.1</li>\n<li>scipy 1.3.1</li>\n<li>networkx 2.4</li>\n</ul>\n<p>To run the Jupyter notebooks in the examples directory, and to compare the Sequencer to tSNE and UMAP, you will also need:</p>\n<ul>\n<li>matplotlib 3.1.2</li>\n<li>scikit-learn 0.22.1 (to run tSNE)</li>\n<li>umap 0.3.9 (to run UMAP; <a href=\"https://github.com/lmcinnes/umap\" rel=\"nofollow\">https://github.com/lmcinnes/umap</a>)</li>\n</ul>\n<h2>How to install the Sequencer</h2>\n<h3>Using PyPI:</h3>\n<p>Assuming you have installed numpy, scipy, and networkx, then using PyPI install:</p>\n<pre><code>pip install TheSequencer\n</code></pre>\n<p>If you need to install the required packages, then we suggest to install them manually using anaconda:</p>\n<pre><code>conda install numpy scipy\nconda install networkx\npip install TheSequencer\n</code></pre>\n<p>If you also want to run the Jupyter notebooks in the examples directory, then install the following:</p>\n<pre><code>conda install numpy scipy\nconda install networkx\nconda install matplotlib\nconda install scikit-learn\nconda install -c conda-forge umap-learn\npip install TheSequencer\n</code></pre>\n<h3>Manual installation:</h3>\n<p>For a manual installation:</p>\n<pre><code>wget https://github.com/dalya/Sequencer/archive/master.zip\nunzip master.zip\nrm master.zip\ncd Sequencer-master/\n</code></pre>\n<p>Install the requirements:</p>\n<pre><code>sudo pip install -r requirements.txt\n</code></pre>\n<p>Install the package:</p>\n<pre><code>python setup.py install\n</code></pre>\n<h2>How to use the Sequencer</h2>\n<p>The examples directory consists of several Jupyter notebooks showing how to use the Sequencer. New users are encoraged to start with the notebook <code>basic_sequencer_functionalities.ipynb</code>, which explains the basic functionalities of the Sequencer.</p>\n<p>Below there is an example of a simple Sequencer run with default parameters:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">sequencer</span>\n\n<span class=\"c1\"># define the Sequencer object</span>\n<span class=\"n\">estimator_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'EMD'</span><span class=\"p\">,</span> <span class=\"s1\">'energy'</span><span class=\"p\">,</span> <span class=\"s1\">'KL'</span><span class=\"p\">,</span> <span class=\"s1\">'L2'</span><span class=\"p\">]</span>\n<span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"n\">sequencer</span><span class=\"o\">.</span><span class=\"n\">Sequencer</span><span class=\"p\">(</span><span class=\"n\">grid</span><span class=\"p\">,</span> <span class=\"n\">objects_list</span><span class=\"p\">,</span> <span class=\"n\">estimator_list</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># execute the Sequencer</span>\n<span class=\"n\">output_directory_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"sequencer_output_directory\"</span>\n<span class=\"n\">final_elongation</span><span class=\"p\">,</span> <span class=\"n\">final_sequence</span> <span class=\"o\">=</span> <span class=\"n\">seq</span><span class=\"o\">.</span><span class=\"n\">execute</span><span class=\"p\">(</span><span class=\"n\">output_directory_path</span><span class=\"p\">)</span>\n</pre>\n<p>The definition of the <code>Sequencer</code> object required a few input parameters: <code>grid</code>: the x-axis of the objects and <code>objects_list</code>: a list of the objects. This is the input dataset within which we want to find a sequence. The <code>estimator_list</code> is a list of strings containing the distance metrics to be considered during the algorithm run. It contains four distance metrics at the moment: <code>'EMD'</code>=Earth Mover Distance, <code>'energy'</code>=Energy Distance, <code>'KL'</code>=Kullback-Leibler Divergence, and <code>'L2'</code>=Euclidean Distance. The Sequnecer defines a list of scales it will consider automatically, where the number and values of the scales will be determined by the size of the data. However, users can set the scales by themselves. For example, if we wish to consider only the largest scales, and not to divide the objects into chunks, then:</p>\n<pre><span class=\"c1\"># define the Sequencer object</span>\n<span class=\"n\">estimator_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'EMD'</span><span class=\"p\">,</span> <span class=\"s1\">'energy'</span><span class=\"p\">,</span> <span class=\"s1\">'KL'</span><span class=\"p\">,</span> <span class=\"s1\">'L2'</span><span class=\"p\">]</span>\n<span class=\"n\">scale_list</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]]</span>\n<span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"n\">sequencer</span><span class=\"o\">.</span><span class=\"n\">Sequencer</span><span class=\"p\">(</span><span class=\"n\">grid</span><span class=\"p\">,</span> <span class=\"n\">objects_list</span><span class=\"p\">,</span> <span class=\"n\">estimator_list</span><span class=\"p\">,</span> <span class=\"n\">scale_list</span><span class=\"p\">)</span>\n</pre>\n<p>If instead we are intrested in small-scale information, where we want to split each object into 10 separate parts and examine them separately, then:</p>\n<pre><span class=\"c1\"># define the Sequencer object</span>\n<span class=\"n\">estimator_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'EMD'</span><span class=\"p\">,</span> <span class=\"s1\">'energy'</span><span class=\"p\">,</span> <span class=\"s1\">'KL'</span><span class=\"p\">,</span> <span class=\"s1\">'L2'</span><span class=\"p\">]</span>\n<span class=\"n\">scale_list</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"mi\">10</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">]]</span>\n<span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"n\">sequencer</span><span class=\"o\">.</span><span class=\"n\">Sequencer</span><span class=\"p\">(</span><span class=\"n\">grid</span><span class=\"p\">,</span> <span class=\"n\">objects_list</span><span class=\"p\">,</span> <span class=\"n\">estimator_list</span><span class=\"p\">,</span> <span class=\"n\">scale_list</span><span class=\"p\">)</span>\n</pre>\n<p>Finally, if we do not know a-priori on which scale the relevant information is, we might want to examine several scales:</p>\n<pre><span class=\"c1\"># define the Sequencer object</span>\n<span class=\"n\">estimator_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'EMD'</span><span class=\"p\">,</span> <span class=\"s1\">'energy'</span><span class=\"p\">,</span> <span class=\"s1\">'KL'</span><span class=\"p\">,</span> <span class=\"s1\">'L2'</span><span class=\"p\">]</span>\n<span class=\"n\">scale_list</span> <span class=\"o\">=</span> <span class=\"p\">[[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">]]</span>\n<span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"n\">sequencer</span><span class=\"o\">.</span><span class=\"n\">Sequencer</span><span class=\"p\">(</span><span class=\"n\">grid</span><span class=\"p\">,</span> <span class=\"n\">objects_list</span><span class=\"p\">,</span> <span class=\"n\">estimator_list</span><span class=\"p\">,</span> <span class=\"n\">scale_list</span><span class=\"p\">)</span>\n</pre>\n<p>This means that for each metric, the Sequencer will examine four different scales: 1, 2, 4, ans 8. A <code>scale=2</code> means that the Sequencer will split the objects into two parts and will search for a sequence in each of the parts separately. It will then aggregate the information from both of the parts into a single estimator. Finally, it will aggregate the information from all the combinations of metrics+scales into a single estimator, where metrics+scales that result in larger elongations will get a higher weight in the final product.</p>\n<p>To execute the <code>Sequencer</code> obejct, we needed to define <code>output_directory_path</code>, which is a path of a directory to which different Sequencer products will be saved. The final output of the function consists of: (1) <code>final_elongation</code>: the elongation of the resulting sequence. An elongation that is close to 1 suggests no clear sequence in the data. An elongation close to N, where N is the number of objects in the sample, suggests that the Sequencer detected a significant sequence in the data. (2) <code>final_sequence</code>: the resulting sequence. This is an array that contains the relative order of the different objects in the sample, such that they form the detected sequence.</p>\n<h2>Examples directory</h2>\n<p>The <a href=\"https://github.com/dalya/Sequencer/tree/master/examples\" rel=\"nofollow\">examples directory</a> contains several Jupyter notebooks that illustrate different aspects of the Sequencer algorithm. Users who are not familiar with the Sequencer are encouraged to go through the examples in the following order:</p>\n<ol>\n<li><code>basic_sequencer_functionalities.ipynb</code>: this notebook shows the basic functionalities of the algorithm. It shows how to apply the Sequencer to a simple simulated dataset with default settings. It shows how to extract various interesting properties of the algorithm, such as the intermediate elongations obtained during the calculation. It then shows some non-default settings that the user should be aware of (parallelization, varying scales, output options).</li>\n<li><code>comparison_with_tsne_and_umap.ipynb</code>: this notebook compares the Sequencer output to the one-dimensional embedding by tSNE and UMAP for a simulated dataset. Importantly, this notebook presents a method to define a general figure of merit for Dimensionality Reduction algorithms that can be used to optimize their hyper-parameters. Using this figure of merit, we can optimize the hyper-parameters of tSNE and UMAP and compare their resulting sequence to the one obtained with the Sequencer.</li>\n<li><code>examples_with_natural_images.ipynb</code>: this notebook shows examples with scrambled natural images. In this notebook, the rows of different natural images are shuffled, and then the Sequencer is applied to the shuffled dataset with the goal of recovering the original image. Finally, the notebook shows the application of tSNE and UMAP to the shuffled images, while varying their hyper-parameters. It illustrates the importance of defining a figure of merit to optimize the hyper-parameters of dimensionality reduction algorithms (the user should go over the notebook <code>comparison_with_tsne_and_umap.ipynb</code> before going over this notebook).</li>\n<li><code>importance_of_multi_scale_approach.ipynb</code>: this notebook applies the Sequencer to stellar spectra, which are 1D objects with relevant information on many different scales (both small scales and large scales). The notebook shows how to extract the intermediate elongations of different chunks of data, and using these, illustrates the importance of the multi-scale approach of the Sequencer.</li>\n<li><code>beyond_1D_sequence.ipynb</code>: the Sequencer provides a one-dimensional embedding of the input dataset. This notebook shows how we can go beyond a 1D sequence using a method somewhat similar to PCA: once the main trend in the data is detected, we can 'strip' it from the data, and apply the Sequencer to detect the second strongest trend in the data, and so on.</li>\n<li><code>two_dimensional_objects.ipynb</code>: so far, we applied the Sequencer to datasets consisting of 1D objects. This notebook shows how to apply the Sequencer to a dataset consisting of 2D objects (images).</li>\n</ol>\n<h2>Selected results</h2>\n<h3>Shuffled image rows</h3>\n<p>The Sequencer reorders the objects in the input dataset according to a detected sequence, if such sequence exists in the dataset. A good example of a perfect one-dimensional sequence is a natural image: the rows within a natural image form a well-defined sequence. Therefore, we can shuffle the rows in a natural image, and apply the Sequencer to the shuffled dataset. The following figure shows the result of applying the Sequencer to a shuffled natural image. The left panel shows the original image. The middle panel shows the same image after we have shuffled its rows. The shuffled image serves as the input dataset to the Sequencer, where each row is considered as a separate object. The output of the Sequencer is shown in the right panel, where we reordered the rows according to the detected sequence. The Sequencer successfully identified the one-dimensional trend spanned by the different rows.</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88c78fb1d2a2a3a3eb5f4e6f72ff766d5e1d50a5/696d616765732f6e61747572616c5f696d6167655f6578616d706c652e706e67\"></p>\n<p>We examine several cases of scrambled natural images in the Jupyter notebook <code>examples_with_natural_images.ipynb</code> in the examples directory. For each of the images, we shuffle its rows and apply the Sequencer to the shuffled dataset with the goal of recovering the original image. We also compare the result of the Sequencer to the one-dimensional embedding by tSNE and UMAP.</p>\n<h3>Simulated dataset with a sequence on small scales</h3>\n<p>The following figure shows an example of a simulated dataset with a clear one-dimensional sequence. The top left panel shows the input dataset, where each row is a separate object and the color-coding represents the relative intensity in each of its pixels. The objects are constructed to have both small-scale and large-scale fluctuations, and some added noise. In addition, we added several narrow pulses to each of the objects, such that their relative location forms a clear one-dimensional sequence. In the top right panel we show the output of the Sequencer, where we reordered the objects (rows) according to the detected sequence. Although the narrow pulses constitute a small fraction of the total integrated intensity in each object, the Sequencer correctly identified the one-dimensional trend. The success of the Sequencer in detecting this trend is a direct result of our multi-scale approach. The bottom panel shows the best one-dimensional embedding by tSNE and UMAP. One can see that the output of both of the algorithms is driven by the large-scale fluctuations. This result illustrates that tSNE and UMAP are not optimized to find the most elongated manifold in the dataset if it is not distributed over the full scale of the data.</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6a988e3f20990b19fd0654b86533e289d0a5e01d/696d616765732f73796e7468657469635f646174615f7365715f626f785f706c6f74732e706e67\"></p>\n<p>We construct the simulated dataset and compare the Sequencer output to the one-dimensional embedding by tSNE and UMAP in the Jupyter notebook <code>comparison_with_tsne_and_umap.ipynb</code> in the examples directory. In addition, we show there how to define a general figure of merit for the one-dimensional embedding of any Dimensionality Reduction algorithm, using the graph elongation. We show how this figure of merit can be used to optimize the hyper-parameters of algorithms such as tSNE and UMAP, and thus select the \"best\" one-dimensional embedding.</p>\n<h2>Citation</h2>\n<p>XXX remains to be written</p>\n\n          </div>"}, "last_serial": 7060688, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "9ce41a0fd5ffed9d7005cbe92f56466e", "sha256": "4814a431953da12f2a506c438ff88db1b87a450517190ace57e39eb8fec7de0c"}, "downloads": -1, "filename": "TheSequencer-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9ce41a0fd5ffed9d7005cbe92f56466e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 20968, "upload_time": "2020-03-16T09:09:51", "upload_time_iso_8601": "2020-03-16T09:09:51.275765Z", "url": "https://files.pythonhosted.org/packages/d1/88/23bf51da58e1b3811e08ccb27673a63ff2c3911aa77e74557760930d7e4b/TheSequencer-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "36b378d3f2816d57b82c2fecf36d39ed", "sha256": "dabf130108d261761c5fa6d6618cc8df218858d8dc3779bb1f7cf19ecaa63909"}, "downloads": -1, "filename": "TheSequencer-0.0.1.tar.gz", "has_sig": false, "md5_digest": "36b378d3f2816d57b82c2fecf36d39ed", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 19318, "upload_time": "2020-03-16T09:09:54", "upload_time_iso_8601": "2020-03-16T09:09:54.210870Z", "url": "https://files.pythonhosted.org/packages/48/40/cbd486e49d418ccd9a7598fa342c2c23bd8b1542801ea61cc068dd70dd02/TheSequencer-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "cb466775a2588a4e2560e6699cd43f5c", "sha256": "6265e1543e405e5e3647b1ae4d6a0b1fe068e8b500f33be17425b9fa33ac3262"}, "downloads": -1, "filename": "TheSequencer-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "cb466775a2588a4e2560e6699cd43f5c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21212, "upload_time": "2020-03-16T10:30:38", "upload_time_iso_8601": "2020-03-16T10:30:38.143246Z", "url": "https://files.pythonhosted.org/packages/31/08/fb40f767bd0589ddc9b48cb06b16113d9ff72aa66045328af6e0bfa94caa/TheSequencer-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "81fe26391b56ee38d9b6015be51a0c66", "sha256": "40d9a0c72d1827d8ee5be9e46bb59ab2fd9ecfa63f94b29f3bd4fa739e8e24c6"}, "downloads": -1, "filename": "TheSequencer-0.0.2.tar.gz", "has_sig": false, "md5_digest": "81fe26391b56ee38d9b6015be51a0c66", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20394, "upload_time": "2020-03-16T10:30:39", "upload_time_iso_8601": "2020-03-16T10:30:39.482783Z", "url": "https://files.pythonhosted.org/packages/f9/26/a5f6051be06dfad3e104a76967d26c3b1ac810fcd3af36eca508bdaec58c/TheSequencer-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "efff0bfa06d60bcd31fbed9c74ae78c8", "sha256": "5162d1ca978f2cbde00408b39481f7a2e0b61000e5277a2b67b1292b40e45960"}, "downloads": -1, "filename": "TheSequencer-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "efff0bfa06d60bcd31fbed9c74ae78c8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21316, "upload_time": "2020-03-17T12:46:31", "upload_time_iso_8601": "2020-03-17T12:46:31.726355Z", "url": "https://files.pythonhosted.org/packages/b5/b4/e7cbe1832f3af8358304780f44cfd8dbd64a1acb2d689f43bd53adb5c9e2/TheSequencer-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9e1adfd6f473e195e9eea285bdf3dcec", "sha256": "60a6b0111e0dab8440597d56ef2000129908b480fd8cfdb1b47fe56c67105173"}, "downloads": -1, "filename": "TheSequencer-0.0.3.tar.gz", "has_sig": false, "md5_digest": "9e1adfd6f473e195e9eea285bdf3dcec", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20469, "upload_time": "2020-03-17T12:46:33", "upload_time_iso_8601": "2020-03-17T12:46:33.173901Z", "url": "https://files.pythonhosted.org/packages/ee/6f/aff3b6ced8fc6640237a61b5d9586c1974e02e69cf6e7dfe9756afbb9011/TheSequencer-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "ade44fd16a5241a0bcb627fe425b66a2", "sha256": "87d2b298b794df463142de4cdf5a220944ec97449f973e946f883d6a11d08157"}, "downloads": -1, "filename": "TheSequencer-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "ade44fd16a5241a0bcb627fe425b66a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 21708, "upload_time": "2020-03-30T09:21:58", "upload_time_iso_8601": "2020-03-30T09:21:58.981662Z", "url": "https://files.pythonhosted.org/packages/a5/93/55f0310a1a1dd3a4117fedbe3a15f43f3cb8a9369ba90bf72f8eec6977ff/TheSequencer-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f736de35f5b4303734ab40e23c7da460", "sha256": "3b1d5ce5058d0b996ede18a92c394c53fa5dcab0f7dc15506beb7273aa6e4de2"}, "downloads": -1, "filename": "TheSequencer-0.0.4.tar.gz", "has_sig": false, "md5_digest": "f736de35f5b4303734ab40e23c7da460", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 20824, "upload_time": "2020-03-30T09:22:00", "upload_time_iso_8601": "2020-03-30T09:22:00.647589Z", "url": "https://files.pythonhosted.org/packages/22/4a/328b1ac0063a64f020acee6be3f17e9fd47ef5515aaefbfb264f93557a34/TheSequencer-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "c440c915bdbc2972b951f561863a794d", "sha256": "3e9971ea0944e34633d195987a65a3d394f1e62cc0951fc4d8c47f43778b8ac9"}, "downloads": -1, "filename": "TheSequencer-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "c440c915bdbc2972b951f561863a794d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22051, "upload_time": "2020-04-20T14:53:56", "upload_time_iso_8601": "2020-04-20T14:53:56.256819Z", "url": "https://files.pythonhosted.org/packages/61/2c/915fcf887a4dd9e9effc96f9287ee6f1739b6d11d12a866f38310dbcff80/TheSequencer-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "931df771f0b5220a3efcf390c633975f", "sha256": "eb88a5a00f47afcf19f8fecde891c1713f2dcdb0b891ddd0858a830fa6fa3beb"}, "downloads": -1, "filename": "TheSequencer-0.0.5.tar.gz", "has_sig": false, "md5_digest": "931df771f0b5220a3efcf390c633975f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 21110, "upload_time": "2020-04-20T14:53:57", "upload_time_iso_8601": "2020-04-20T14:53:57.565517Z", "url": "https://files.pythonhosted.org/packages/07/62/f11ff881cbb5ad92aaa10ae884b4ce62dcc45c89947bbc2eabdd63d1a9d5/TheSequencer-0.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c440c915bdbc2972b951f561863a794d", "sha256": "3e9971ea0944e34633d195987a65a3d394f1e62cc0951fc4d8c47f43778b8ac9"}, "downloads": -1, "filename": "TheSequencer-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "c440c915bdbc2972b951f561863a794d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22051, "upload_time": "2020-04-20T14:53:56", "upload_time_iso_8601": "2020-04-20T14:53:56.256819Z", "url": "https://files.pythonhosted.org/packages/61/2c/915fcf887a4dd9e9effc96f9287ee6f1739b6d11d12a866f38310dbcff80/TheSequencer-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "931df771f0b5220a3efcf390c633975f", "sha256": "eb88a5a00f47afcf19f8fecde891c1713f2dcdb0b891ddd0858a830fa6fa3beb"}, "downloads": -1, "filename": "TheSequencer-0.0.5.tar.gz", "has_sig": false, "md5_digest": "931df771f0b5220a3efcf390c633975f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 21110, "upload_time": "2020-04-20T14:53:57", "upload_time_iso_8601": "2020-04-20T14:53:57.565517Z", "url": "https://files.pythonhosted.org/packages/07/62/f11ff881cbb5ad92aaa10ae884b4ce62dcc45c89947bbc2eabdd63d1a9d5/TheSequencer-0.0.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:00 2020"}