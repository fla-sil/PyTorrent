{"info": {"author": "Murtaza Saifee", "author_email": "saifeeapps@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# HVF Extraction Script\n\nPython module for Humphrey Visual Field (HVF) report data extraction. Extracts data using OCR (tesseract) and image processing techniques (heavily reliant on openCV) to extract data into an object oriented format for further processing.\n\n## Getting Started\n\n### Requirements\n- Python 3.6.7 or higher\n- TesserOCR\n- Regex\n- Pillow\n- OpenCV 4.2.0\n- FuzzyWuzzy\n- Fuzzysearch\n\n### Installation\n\n## Usage\n\nData is managed primarily through the Hvf_Object class, which contains the report metadata (name/ID, test date, field size and strategy, etc), and the 5 data plots (raw sensitivity, total deviation value/percentile plots, and pattern deviation value/percentile plots). Plot data is stored as Hvf_Plot_Array objects (internally as 10x10 Numpy arrays), and individual plot data elements are stored as either Hvf_Value or Hvf_Perc_Icon objects.\n\n### Importing and exporting data\n\nProcessing a single image:\n\n```shell\nfrom hvf_extraction_script import Hvf_Object\nfrom hvf_extraction_script import File_Utils\n\nhvf_img = File_Utils.read_image_from_file(hvf_img_path);\nhvf_obj = Hvf_Object.get_hvf_object_from_image(hvf_img);\n```\n\nSaving as a text file:\n```shell\nserialized_string = hvf_obj.serialize_to_json();\ntxt_file_path = \u201cpath/to/target/file/to/write\u201d;\nFile_Utils.write_string_to_file(serialized_string, target_file_path)\n```\n\nReinstantiating from text file\n```shell\nhvf_txt = File_Utils.read_text_from_file(txt_file_path);\nhvf_obj = Hvf_Object.get_hvf_object_from_text(hvf_txt);\n```\n\nExport to spreadsheet (tab-separated values):\n```shell\n# Takes in a dictionary of filename_string -> hvf_obj\nfrom hvf_extraction_script import Hvf_Export;\n\ndict_of_hvf_objs = {\u201cfile1.PNG\u201d: hvf_obj1, \u201cfile2.PNG\u201d: hvf_obj2, \u201cfile3.PNG\u201d: hvf_obj3 };\nspreadsheet_string = Hvf_Export.export_hvf_list_to_spreadsheet(dict_of_hvf_objs)\nFile_Utils.write_string_to_file(return_string, \"output_spreadsheet.tsv\")\n```\n\nBasic data usage:\nStructure of hvf_obj and underlying objects\n\n\n### Running Unit Tests\n\nSingle Image Testing:\n\nRunning a single image test performs an extraction of an image report, shows its extraction data in pretty-print, and tests serialization/deserialization procedures\n\n```shell\nfrom hvf_extraction_script import Hvf_Test\nfrom hvf_extraction_script import File_Utils\n\nimage_path = \u201cpath/to/image/file.PNG\u201d;\nhvf_image = File_Utils.read_image_from_file(image_path);\nHvf_Test.test_single_image(hvf_image);\n\u2026\n```\n\nUnit Testing:\n\nThe module comes with the ability to run unit tests, but with no pre-loaded unit tests to run. Unit tests are organized into collections under a specified name; they compare data extracted from images against a reference text file . When a unit test image is \u2018added\u2019, the module (in its current state) generates the reference file purely from the extraction; the user must then go and manually edit/replace the text file with the corrections to validate the reference file. The image file and reference test files are stored under hvf_test_cases with corresponding names.\n\nAdding unit tests:\n\n```shell\nimage_path = \u201cpath/to/image/file.PNG\u201d;\nunit_test_name = \u201cunit_test_name\u201d\nHvf_Test.add_unit_test(image_path, unit_test_name)\n\n# Then, manually correct reference text file under hvf_test_cases\n```\n\nRunning unit tests:\n```shell\nHvf_Test.test_unit_tests(unit_test_name)\n...\n[SYSTEM] ================================================================================\n[SYSTEM] Starting test: v1_30\n[SYSTEM] Test v1_30: FAILED ==============================\n[SYSTEM] - Metadata: FULL MATCH\n[SYSTEM] - Raw Value Plot MISMATCH COUNT: 1\n[SYSTEM] --> Element (5, 2) - expected 24, actual 21\n[SYSTEM] - Total Deviation Value Plot: FULL MATCH\n[SYSTEM] - Pattern Deviation Value Plot: FULL MATCH\n[SYSTEM] - Total Deviation Percentile Plot: FULL MATCH\n[SYSTEM] - Pattern Deviation Percentile Plot: FULL MATCH\n[SYSTEM] END Test v1_30 FAILURE REPORT =====================\n[SYSTEM] ================================================================================\n[SYSTEM] UNIT TEST AGGREGATE METRICS:\n[SYSTEM] Total number of tests: 30\n[SYSTEM] Average extraction time per report: 5868ms\n[SYSTEM]\n[SYSTEM] Total number of metadata fields: 510\n[SYSTEM] Total number of metadata field errors: 16\n[SYSTEM] Metadata field error rate: 0.031\n[SYSTEM]\n[SYSTEM] Total number of value data points: 5047\n[SYSTEM] Total number of value data point errors: 44\n[SYSTEM] Value data point error rate: 0.009\n[SYSTEM]\n[SYSTEM] Total number of percentile data points: 3453\n[SYSTEM] Total number of percentile data point errors: 0\n[SYSTEM] Percentile data point error rate: 0.0\n```\n\n## Authors\n- Murtaza Saifee, MD - Ophthalmology resident, UCSF\n\n## Validation\nIn progress\n\n## License\nGPL License\n\n## Using/Contributing\nThis project was developed in the spirit of facilitating vision research. To that end, we encourage all to download, use, critique and improve upon the project. Collaboration requests are also welcomed.\n\n## Acknowledgements\n- PyImageSearch for excellent tutorials on image processing\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/msaifee786/hvf_extraction_script", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "hvf-extraction-script", "package_url": "https://pypi.org/project/hvf-extraction-script/", "platform": "", "project_url": "https://pypi.org/project/hvf-extraction-script/", "project_urls": {"Homepage": "https://github.com/msaifee786/hvf_extraction_script"}, "release_url": "https://pypi.org/project/hvf-extraction-script/0.0.1/", "requires_dist": ["tesserOCR", "regex", "pillow", "opencv-python", "fuzzywuzzy", "fuzzysearch", "python-levenshtein"], "requires_python": ">=3.6", "summary": "Python extraction script for HVF report images", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>HVF Extraction Script</h1>\n<p>Python module for Humphrey Visual Field (HVF) report data extraction. Extracts data using OCR (tesseract) and image processing techniques (heavily reliant on openCV) to extract data into an object oriented format for further processing.</p>\n<h2>Getting Started</h2>\n<h3>Requirements</h3>\n<ul>\n<li>Python 3.6.7 or higher</li>\n<li>TesserOCR</li>\n<li>Regex</li>\n<li>Pillow</li>\n<li>OpenCV 4.2.0</li>\n<li>FuzzyWuzzy</li>\n<li>Fuzzysearch</li>\n</ul>\n<h3>Installation</h3>\n<h2>Usage</h2>\n<p>Data is managed primarily through the Hvf_Object class, which contains the report metadata (name/ID, test date, field size and strategy, etc), and the 5 data plots (raw sensitivity, total deviation value/percentile plots, and pattern deviation value/percentile plots). Plot data is stored as Hvf_Plot_Array objects (internally as 10x10 Numpy arrays), and individual plot data elements are stored as either Hvf_Value or Hvf_Perc_Icon objects.</p>\n<h3>Importing and exporting data</h3>\n<p>Processing a single image:</p>\n<pre>from hvf_extraction_script import Hvf_Object\nfrom hvf_extraction_script import File_Utils\n\n<span class=\"nv\">hvf_img</span> <span class=\"o\">=</span> File_Utils.read_image_from_file<span class=\"o\">(</span>hvf_img_path<span class=\"o\">)</span><span class=\"p\">;</span>\n<span class=\"nv\">hvf_obj</span> <span class=\"o\">=</span> Hvf_Object.get_hvf_object_from_image<span class=\"o\">(</span>hvf_img<span class=\"o\">)</span><span class=\"p\">;</span>\n</pre>\n<p>Saving as a text file:</p>\n<pre><span class=\"nv\">serialized_string</span> <span class=\"o\">=</span> hvf_obj.serialize_to_json<span class=\"o\">()</span><span class=\"p\">;</span>\n<span class=\"nv\">txt_file_path</span> <span class=\"o\">=</span> \u201cpath/to/target/file/to/write\u201d<span class=\"p\">;</span>\nFile_Utils.write_string_to_file<span class=\"o\">(</span>serialized_string, target_file_path<span class=\"o\">)</span>\n</pre>\n<p>Reinstantiating from text file</p>\n<pre><span class=\"nv\">hvf_txt</span> <span class=\"o\">=</span> File_Utils.read_text_from_file<span class=\"o\">(</span>txt_file_path<span class=\"o\">)</span><span class=\"p\">;</span>\n<span class=\"nv\">hvf_obj</span> <span class=\"o\">=</span> Hvf_Object.get_hvf_object_from_text<span class=\"o\">(</span>hvf_txt<span class=\"o\">)</span><span class=\"p\">;</span>\n</pre>\n<p>Export to spreadsheet (tab-separated values):</p>\n<pre><span class=\"c1\"># Takes in a dictionary of filename_string -&gt; hvf_obj</span>\nfrom hvf_extraction_script import Hvf_Export<span class=\"p\">;</span>\n\n<span class=\"nv\">dict_of_hvf_objs</span> <span class=\"o\">=</span> <span class=\"o\">{</span>\u201cfile1.PNG\u201d: hvf_obj1, \u201cfile2.PNG\u201d: hvf_obj2, \u201cfile3.PNG\u201d: hvf_obj3 <span class=\"o\">}</span><span class=\"p\">;</span>\n<span class=\"nv\">spreadsheet_string</span> <span class=\"o\">=</span> Hvf_Export.export_hvf_list_to_spreadsheet<span class=\"o\">(</span>dict_of_hvf_objs<span class=\"o\">)</span>\nFile_Utils.write_string_to_file<span class=\"o\">(</span>return_string, <span class=\"s2\">\"output_spreadsheet.tsv\"</span><span class=\"o\">)</span>\n</pre>\n<p>Basic data usage:\nStructure of hvf_obj and underlying objects</p>\n<h3>Running Unit Tests</h3>\n<p>Single Image Testing:</p>\n<p>Running a single image test performs an extraction of an image report, shows its extraction data in pretty-print, and tests serialization/deserialization procedures</p>\n<pre>from hvf_extraction_script import Hvf_Test\nfrom hvf_extraction_script import File_Utils\n\n<span class=\"nv\">image_path</span> <span class=\"o\">=</span> \u201cpath/to/image/file.PNG\u201d<span class=\"p\">;</span>\n<span class=\"nv\">hvf_image</span> <span class=\"o\">=</span> File_Utils.read_image_from_file<span class=\"o\">(</span>image_path<span class=\"o\">)</span><span class=\"p\">;</span>\nHvf_Test.test_single_image<span class=\"o\">(</span>hvf_image<span class=\"o\">)</span><span class=\"p\">;</span>\n\u2026\n</pre>\n<p>Unit Testing:</p>\n<p>The module comes with the ability to run unit tests, but with no pre-loaded unit tests to run. Unit tests are organized into collections under a specified name; they compare data extracted from images against a reference text file . When a unit test image is \u2018added\u2019, the module (in its current state) generates the reference file purely from the extraction; the user must then go and manually edit/replace the text file with the corrections to validate the reference file. The image file and reference test files are stored under hvf_test_cases with corresponding names.</p>\n<p>Adding unit tests:</p>\n<pre><span class=\"nv\">image_path</span> <span class=\"o\">=</span> \u201cpath/to/image/file.PNG\u201d<span class=\"p\">;</span>\n<span class=\"nv\">unit_test_name</span> <span class=\"o\">=</span> \u201cunit_test_name\u201d\nHvf_Test.add_unit_test<span class=\"o\">(</span>image_path, unit_test_name<span class=\"o\">)</span>\n\n<span class=\"c1\"># Then, manually correct reference text file under hvf_test_cases</span>\n</pre>\n<p>Running unit tests:</p>\n<pre>Hvf_Test.test_unit_tests<span class=\"o\">(</span>unit_test_name<span class=\"o\">)</span>\n...\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> <span class=\"o\">================================================================================</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Starting test: v1_30\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Test v1_30: <span class=\"nv\">FAILED</span> <span class=\"o\">==============================</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> - Metadata: FULL MATCH\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> - Raw Value Plot MISMATCH COUNT: <span class=\"m\">1</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> --&gt; Element <span class=\"o\">(</span><span class=\"m\">5</span>, <span class=\"m\">2</span><span class=\"o\">)</span> - expected <span class=\"m\">24</span>, actual <span class=\"m\">21</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> - Total Deviation Value Plot: FULL MATCH\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> - Pattern Deviation Value Plot: FULL MATCH\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> - Total Deviation Percentile Plot: FULL MATCH\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> - Pattern Deviation Percentile Plot: FULL MATCH\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> END Test v1_30 FAILURE <span class=\"nv\">REPORT</span> <span class=\"o\">=====================</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> <span class=\"o\">================================================================================</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> UNIT TEST AGGREGATE METRICS:\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of tests: <span class=\"m\">30</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Average extraction <span class=\"nb\">time</span> per report: 5868ms\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of metadata fields: <span class=\"m\">510</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of metadata field errors: <span class=\"m\">16</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Metadata field error rate: <span class=\"m\">0</span>.031\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of value data points: <span class=\"m\">5047</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of value data point errors: <span class=\"m\">44</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Value data point error rate: <span class=\"m\">0</span>.009\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of percentile data points: <span class=\"m\">3453</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Total number of percentile data point errors: <span class=\"m\">0</span>\n<span class=\"o\">[</span>SYSTEM<span class=\"o\">]</span> Percentile data point error rate: <span class=\"m\">0</span>.0\n</pre>\n<h2>Authors</h2>\n<ul>\n<li>Murtaza Saifee, MD - Ophthalmology resident, UCSF</li>\n</ul>\n<h2>Validation</h2>\n<p>In progress</p>\n<h2>License</h2>\n<p>GPL License</p>\n<h2>Using/Contributing</h2>\n<p>This project was developed in the spirit of facilitating vision research. To that end, we encourage all to download, use, critique and improve upon the project. Collaboration requests are also welcomed.</p>\n<h2>Acknowledgements</h2>\n<ul>\n<li>PyImageSearch for excellent tutorials on image processing</li>\n</ul>\n\n          </div>"}, "last_serial": 7022492, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "208df29f8c714fe590b6c16204ad0709", "sha256": "0518bc48b0ea9199c9c643e37b53ddbf95a64d48ac19b36ac7aa156988888d18"}, "downloads": -1, "filename": "hvf_extraction_script-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "208df29f8c714fe590b6c16204ad0709", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 15630, "upload_time": "2020-04-15T06:09:04", "upload_time_iso_8601": "2020-04-15T06:09:04.233667Z", "url": "https://files.pythonhosted.org/packages/d0/0d/0d1c08a8b31bb0774e11fccae2047bb832d1eca57eac7faba0fe5d1424da/hvf_extraction_script-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2717368ddcab5f623938b8e95d51ab80", "sha256": "f36fab87a31d6219901b44680cb1c8fc421c806a809253df52386f9b8a03feef"}, "downloads": -1, "filename": "hvf_extraction_script-0.0.1.tar.gz", "has_sig": false, "md5_digest": "2717368ddcab5f623938b8e95d51ab80", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3550, "upload_time": "2020-04-15T06:09:06", "upload_time_iso_8601": "2020-04-15T06:09:06.215010Z", "url": "https://files.pythonhosted.org/packages/2f/a1/61b06e2d213b31f182b398e414b98a3232757ddfd36df5afeb2a67c24306/hvf_extraction_script-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "208df29f8c714fe590b6c16204ad0709", "sha256": "0518bc48b0ea9199c9c643e37b53ddbf95a64d48ac19b36ac7aa156988888d18"}, "downloads": -1, "filename": "hvf_extraction_script-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "208df29f8c714fe590b6c16204ad0709", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 15630, "upload_time": "2020-04-15T06:09:04", "upload_time_iso_8601": "2020-04-15T06:09:04.233667Z", "url": "https://files.pythonhosted.org/packages/d0/0d/0d1c08a8b31bb0774e11fccae2047bb832d1eca57eac7faba0fe5d1424da/hvf_extraction_script-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2717368ddcab5f623938b8e95d51ab80", "sha256": "f36fab87a31d6219901b44680cb1c8fc421c806a809253df52386f9b8a03feef"}, "downloads": -1, "filename": "hvf_extraction_script-0.0.1.tar.gz", "has_sig": false, "md5_digest": "2717368ddcab5f623938b8e95d51ab80", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3550, "upload_time": "2020-04-15T06:09:06", "upload_time_iso_8601": "2020-04-15T06:09:06.215010Z", "url": "https://files.pythonhosted.org/packages/2f/a1/61b06e2d213b31f182b398e414b98a3232757ddfd36df5afeb2a67c24306/hvf_extraction_script-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:44 2020"}