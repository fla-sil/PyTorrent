{"info": {"author": "", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# DataScienceTools\n\nThis repository contains some modules I consider useful in Data Science tasks. Most of them are based on sklearn and require input data to be in pandas DataFrames or Series.\n\n## Table of contents\n\n1. [ Preprocessing ](#preprocessing) <br>\n1.1 [ NumScaler ](#numscaler) <br>\n1.2 [ Imputer ](#imputer) <br>\n1.3 [ FeatureConverter ](#featureconverter) <br>\n1.4 [ OneHotEncoder ](#onehotencoder) <br>\n1.5 [ Bucketizer ](#bucketizer) <br>\n\n2. [ Classifier ](#classifier) <br>\n2.1 [ BestGuessClassifier ](#bestguessclassifier) <br>\n2.2 [ BestGuessRegressor ](#bestguessregressor) <br>\n\n<a name=\"preprocessing\"></a>\n## 1. Preprocessing\n\nThese modules are meant to help with preprocessing tasks. They are built upon sklearn.base.Transformermixin and can be used in sklearn.Pipeline. Possible tasks are scaling, imputing ...\n\n\n<a name=\"numscaler\"></a>\n### 1.1 NumScaler\n\nNumScaler is a wrapper for scalers. Some scalers only take numerical input and can't ignore non numerical data. NumScaler identifies numerical data and passes it to a Scaler (default=sklearn.preprocessing.StandardScaler).\n\n\n<a name=\"imputer\"></a>\n### 1.2 Imputer\n\nImputes missing values based on 'sklearn.base.TransformerMixin'. Numerics values can be imputed by a given metric (default=np.mean) or by a constant value when passed in manual_values. Non numeric values can be imputed by the most frequent value or by a constant value when passed in manual_values.\n\n\n<a name=\"featureconverter\"></a>\n### 1.3 FeatureConverter\n\nThe FeatureConverter helps to integrate common preprocessing steps into sklearn pipelines. Supported preprocessing steps are replacing values, converting to str, int or float, dropping columns or adding flags. Steps will be performed in the following order: create flags, replace values, convert types, drop columns\n\n\n<a name=\"onehotencoder\"></a>\n### 1.4 OneHotEncoder\n\nThis module performs binary encoding on columns containing categorical data.\nIt assumes that all non numeric columns contain categorical data. If categorical data is encoded in numeric columns, use dstools.preprocessing.FeatureConverter to convert these values first. The maximum number of encoded values can be given globally or fine tuned for every column. Values that exceed the maximum number of encoded values are aggregated in a REST class. Missing values can be either put in the REST class or be classified as distinct value. Categrocial columns with exactly two values (including missing values) can be encoded into one column to reduce dimensionality.\n\n<a name=\"bucketizer\"></a>\n### 1.5 Bucketizer\n\nThe Bucketizer puts numeric features into bins. The binned feature can either replace the original feature or can be created additionally. You can bin all numeric features, pass a list of the features to be binned or pass prefix of the features to be binned.\n\n\n<a name=\"classifier\"></a>\n## 2. Classifier\n\nsome text\n\n\n<a name=\"bestguessclassifier\"></a>\n### 2.1 BestGuessClassifier\n\nThe BestGuessClassifier creates a constant numeric best guess for a given metric, e.g. mean absolute squared error. This Classifier is for interval scaled numeric dependent variables. Use this classifier for binnend variables, otherwise use dstools.regressors.BestGuessRegressor.\n\n\n<a name=\"bestguessregressor\"></a>\n### 2.2 BestGuessRegressor\n\nThe BestGuessRegressor creates a constant best guess for a given metric, e.g. mean absolute squared error. This regressor is for interval scaled numeric dependent variables. \n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "DataScienceTools", "package_url": "https://pypi.org/project/DataScienceTools/", "platform": "", "project_url": "https://pypi.org/project/DataScienceTools/", "project_urls": null, "release_url": "https://pypi.org/project/DataScienceTools/0.1.1.dev0/", "requires_dist": ["numpy (>=1.16.2)", "pandas (>=0.23.2)", "scikit-learn (>=0.20.3)", "statsmodels (>=0.9.0)"], "requires_python": ">3.5", "summary": "", "version": "0.1.1.dev0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p># DataScienceTools</p>\n<p>This repository contains some modules I consider useful in Data Science tasks. Most of them are based on sklearn and require input data to be in pandas DataFrames or Series.</p>\n<p>## Table of contents</p>\n<p>1. [ Preprocessing ](#preprocessing) &lt;br&gt;\n1.1 [ NumScaler ](#numscaler) &lt;br&gt;\n1.2 [ Imputer ](#imputer) &lt;br&gt;\n1.3 [ FeatureConverter ](#featureconverter) &lt;br&gt;\n1.4 [ OneHotEncoder ](#onehotencoder) &lt;br&gt;\n1.5 [ Bucketizer ](#bucketizer) &lt;br&gt;</p>\n<p>2. [ Classifier ](#classifier) &lt;br&gt;\n2.1 [ BestGuessClassifier ](#bestguessclassifier) &lt;br&gt;\n2.2 [ BestGuessRegressor ](#bestguessregressor) &lt;br&gt;</p>\n<p>&lt;a name=\u201dpreprocessing\u201d&gt;&lt;/a&gt;\n## 1. Preprocessing</p>\n<p>These modules are meant to help with preprocessing tasks. They are built upon sklearn.base.Transformermixin and can be used in sklearn.Pipeline. Possible tasks are scaling, imputing \u2026</p>\n<p>&lt;a name=\u201dnumscaler\u201d&gt;&lt;/a&gt;\n### 1.1 NumScaler</p>\n<p>NumScaler is a wrapper for scalers. Some scalers only take numerical input and can\u2019t ignore non numerical data. NumScaler identifies numerical data and passes it to a Scaler (default=sklearn.preprocessing.StandardScaler).</p>\n<p>&lt;a name=\u201dimputer\u201d&gt;&lt;/a&gt;\n### 1.2 Imputer</p>\n<p>Imputes missing values based on \u2018sklearn.base.TransformerMixin\u2019. Numerics values can be imputed by a given metric (default=np.mean) or by a constant value when passed in manual_values. Non numeric values can be imputed by the most frequent value or by a constant value when passed in manual_values.</p>\n<p>&lt;a name=\u201dfeatureconverter\u201d&gt;&lt;/a&gt;\n### 1.3 FeatureConverter</p>\n<p>The FeatureConverter helps to integrate common preprocessing steps into sklearn pipelines. Supported preprocessing steps are replacing values, converting to str, int or float, dropping columns or adding flags. Steps will be performed in the following order: create flags, replace values, convert types, drop columns</p>\n<p>&lt;a name=\u201donehotencoder\u201d&gt;&lt;/a&gt;\n### 1.4 OneHotEncoder</p>\n<p>This module performs binary encoding on columns containing categorical data.\nIt assumes that all non numeric columns contain categorical data. If categorical data is encoded in numeric columns, use dstools.preprocessing.FeatureConverter to convert these values first. The maximum number of encoded values can be given globally or fine tuned for every column. Values that exceed the maximum number of encoded values are aggregated in a REST class. Missing values can be either put in the REST class or be classified as distinct value. Categrocial columns with exactly two values (including missing values) can be encoded into one column to reduce dimensionality.</p>\n<p>&lt;a name=\u201dbucketizer\u201d&gt;&lt;/a&gt;\n### 1.5 Bucketizer</p>\n<p>The Bucketizer puts numeric features into bins. The binned feature can either replace the original feature or can be created additionally. You can bin all numeric features, pass a list of the features to be binned or pass prefix of the features to be binned.</p>\n<p>&lt;a name=\u201dclassifier\u201d&gt;&lt;/a&gt;\n## 2. Classifier</p>\n<p>some text</p>\n<p>&lt;a name=\u201dbestguessclassifier\u201d&gt;&lt;/a&gt;\n### 2.1 BestGuessClassifier</p>\n<p>The BestGuessClassifier creates a constant numeric best guess for a given metric, e.g. mean absolute squared error. This Classifier is for interval scaled numeric dependent variables. Use this classifier for binnend variables, otherwise use dstools.regressors.BestGuessRegressor.</p>\n<p>&lt;a name=\u201dbestguessregressor\u201d&gt;&lt;/a&gt;\n### 2.2 BestGuessRegressor</p>\n<p>The BestGuessRegressor creates a constant best guess for a given metric, e.g. mean absolute squared error. This regressor is for interval scaled numeric dependent variables.</p>\n\n          </div>"}, "last_serial": 6167430, "releases": {"0.1.1.dev0": [{"comment_text": "", "digests": {"md5": "163291c676cebf00db25a2b4ae12bc5e", "sha256": "b3145c6476ef5154c1c1ea1bb0ba123b7de3bae2a6aecabd1c3c66caeca67a4b"}, "downloads": -1, "filename": "DataScienceTools-0.1.1.dev0-py3-none-any.whl", "has_sig": false, "md5_digest": "163291c676cebf00db25a2b4ae12bc5e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">3.5", "size": 14897, "upload_time": "2019-11-20T07:52:28", "upload_time_iso_8601": "2019-11-20T07:52:28.830258Z", "url": "https://files.pythonhosted.org/packages/43/21/a724f8402e960d2980ad7bfdf087693e8de2298c44a363cfb3c16f5f7bbc/DataScienceTools-0.1.1.dev0-py3-none-any.whl", "yanked": false}], "0.1.dev0": [{"comment_text": "", "digests": {"md5": "0819c07fcebc944d575791315a407a18", "sha256": "11f6319909c805d96f3833d035590d725f014e78239a7eb58489f8980df83acf"}, "downloads": -1, "filename": "DataScienceTools-0.1.dev0-py3.7.egg", "has_sig": false, "md5_digest": "0819c07fcebc944d575791315a407a18", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": ">3.6", "size": 25575, "upload_time": "2019-11-16T16:48:00", "upload_time_iso_8601": "2019-11-16T16:48:00.067803Z", "url": "https://files.pythonhosted.org/packages/2f/34/4f00619af5b51b5cbbf0d92ba526c2c7941e8b4eb3657fcfa6ab8f2c2849/DataScienceTools-0.1.dev0-py3.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "7a6ff8638a6d49e3332b00bc74730879", "sha256": "3d421247f8a45a687ab7709a02f0ada7a6f2a8ed1169e34262ebb161248907d4"}, "downloads": -1, "filename": "DataScienceTools-0.1.dev0-py3-none-any.whl", "has_sig": false, "md5_digest": "7a6ff8638a6d49e3332b00bc74730879", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">3.6", "size": 13307, "upload_time": "2019-11-16T16:47:57", "upload_time_iso_8601": "2019-11-16T16:47:57.367604Z", "url": "https://files.pythonhosted.org/packages/b2/66/99f9b8731401a0d12f5e9ef53b869c41ea6e4530b2b87bd59b91012931fd/DataScienceTools-0.1.dev0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a1d9725c817ee6626d24ef5820e9b495", "sha256": "b3842919aed41817ded7dac4f81104437448dea2366126ad6685d75a88fa8899"}, "downloads": -1, "filename": "DataScienceTools-0.1.dev0.tar.gz", "has_sig": false, "md5_digest": "a1d9725c817ee6626d24ef5820e9b495", "packagetype": "sdist", "python_version": "source", "requires_python": ">3.6", "size": 8464, "upload_time": "2019-11-16T16:48:01", "upload_time_iso_8601": "2019-11-16T16:48:01.351194Z", "url": "https://files.pythonhosted.org/packages/de/67/66612970271b1b09e5c290d297f683922a98b07f6b3c19ca565c962cd8ac/DataScienceTools-0.1.dev0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "163291c676cebf00db25a2b4ae12bc5e", "sha256": "b3145c6476ef5154c1c1ea1bb0ba123b7de3bae2a6aecabd1c3c66caeca67a4b"}, "downloads": -1, "filename": "DataScienceTools-0.1.1.dev0-py3-none-any.whl", "has_sig": false, "md5_digest": "163291c676cebf00db25a2b4ae12bc5e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">3.5", "size": 14897, "upload_time": "2019-11-20T07:52:28", "upload_time_iso_8601": "2019-11-20T07:52:28.830258Z", "url": "https://files.pythonhosted.org/packages/43/21/a724f8402e960d2980ad7bfdf087693e8de2298c44a363cfb3c16f5f7bbc/DataScienceTools-0.1.1.dev0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:40:13 2020"}