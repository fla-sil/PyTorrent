{"info": {"author": "Vitalii", "author_email": "moskrc@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Environment :: Web Environment", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only", "Topic :: Internet", "Topic :: Internet :: WWW/HTTP :: Indexing/Search", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "## About CrawlerDetect\n\n**CrawlerDetect** is a Python version of PHP class @[CrawlerDetect](https://github.com/JayBizzle/Crawler-Detect).\n\nIt helps to detect  bots/crawlers/spiders via the user agent and other HTTP-headers. Currently able to detect 1,000's of bots/spiders/crawlers.\n\n### Installation\nRun `pip install crawlerdetect`\n\n### Usage\n\n#### Variant 1\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect()\ncrawler_detect.isCrawler('Mozilla/5.0 (compatible; Sosospider/2.0; +http://help.soso.com/webspider.htm)')\n# true if crawler user agent detected\n```\n\n#### Variant 2\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect(user_agent='Mozilla/5.0 (iPhone; CPU iPhone OS 7_1 like Mac OS X) AppleWebKit (KHTML, like Gecko) Mobile (compatible; Yahoo Ad monitoring; https://help.yahoo.com/kb/yahoo-ad-monitoring-SLN24857.html)')\ncrawler_detect.isCrawler()\n# true if crawler user agent detected\n```\n\n#### Variant 3\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect(headers={'DOCUMENT_ROOT': '/home/test/public_html', 'GATEWAY_INTERFACE': 'CGI/1.1', 'HTTP_ACCEPT': '*/*', 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_CACHE_CONTROL': 'no-cache', 'HTTP_CONNECTION': 'Keep-Alive', 'HTTP_FROM': 'googlebot(at)googlebot.com', 'HTTP_HOST': 'www.test.com', 'HTTP_PRAGMA': 'no-cache', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.71 Safari/537.36', 'PATH': '/bin:/usr/bin', 'QUERY_STRING': 'order=closingDate', 'REDIRECT_STATUS': '200', 'REMOTE_ADDR': '127.0.0.1', 'REMOTE_PORT': '3360', 'REQUEST_METHOD': 'GET', 'REQUEST_URI': '/?test=testing', 'SCRIPT_FILENAME': '/home/test/public_html/index.php', 'SCRIPT_NAME': '/index.php', 'SERVER_ADDR': '127.0.0.1', 'SERVER_ADMIN': 'webmaster@test.com', 'SERVER_NAME': 'www.test.com', 'SERVER_PORT': '80', 'SERVER_PROTOCOL': 'HTTP/1.1', 'SERVER_SIGNATURE': '', 'SERVER_SOFTWARE': 'Apache', 'UNIQUE_ID': 'Vx6MENRxerBUSDEQgFLAAAAAS', 'PHP_SELF': '/index.php', 'REQUEST_TIME_FLOAT': 1461619728.0705, 'REQUEST_TIME': 1461619728})\ncrawler_detect.isCrawler()\n# true if crawler user agent detected\n```\n#### Output the name of the bot that matched (if any)\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect()\ncrawler_detect.isCrawler('Mozilla/5.0 (compatible; Sosospider/2.0; +http://help.soso.com/webspider.htm)')\n# true if crawler user agent detected\ncrawler_detect.getMatches()\n# Sosospider\n```\n\n### Contributing\nIf you find a bot/spider/crawler user agent that CrawlerDetect fails to detect, please submit a pull request with the regex pattern added to the array in `providers/crawlers.py` and add the failing user agent to `tests/crawlers.txt`.\n\nFailing that, just create an issue with the user agent you have found, and we'll take it from there :)\n\n### ES6 Library\nTo use this library with NodeJS or any ES6 application based, check out [es6-crawler-detect](https://github.com/JefferyHus/es6-crawler-detect).\n\n### .NET Library\nTo use this library in a .net standard (including .net core) based project, check out [NetCrawlerDetect](https://github.com/gplumb/NetCrawlerDetect).\n\n### Nette Extension\nTo use this library with the Nette framework, checkout [NetteCrawlerDetect](https://github.com/JanGalek/Crawler-Detect).\n\n### Ruby Gem\n\nTo use this library with Ruby on Rails or any Ruby-based application, check out [crawler_detect](https://github.com/loadkpi/crawler_detect) gem.\n\n_Parts of this class are based on the brilliant [MobileDetect](https://github.com/serbanghita/Mobile-Detect)_\n\n[![Analytics](https://ga-beacon.appspot.com/UA-72430465-1/Crawler-Detect/readme?pixel)](https://github.com/JayBizzle/Crawler-Detect)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/moskrc/CrawlerDetect/tarball/0.1.4", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/moskrc/CrawlerDetect", "keywords": "crawler,crawler detect,crawler detector,crawlerdetect,python crawler detect", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "crawlerdetect", "package_url": "https://pypi.org/project/crawlerdetect/", "platform": "any", "project_url": "https://pypi.org/project/crawlerdetect/", "project_urls": {"Documentation": "https://crawlerdetect.readthedocs.io", "Download": "https://github.com/moskrc/CrawlerDetect/tarball/0.1.4", "Homepage": "https://github.com/moskrc/CrawlerDetect"}, "release_url": "https://pypi.org/project/crawlerdetect/0.1.4/", "requires_dist": null, "requires_python": ">=3.4, <4", "summary": "CrawlerDetect is a Python class for detecting bots/crawlers/spiders via the user agent.", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h2>About CrawlerDetect</h2>\n<p><strong>CrawlerDetect</strong> is a Python version of PHP class @<a href=\"https://github.com/JayBizzle/Crawler-Detect\" rel=\"nofollow\">CrawlerDetect</a>.</p>\n<p>It helps to detect  bots/crawlers/spiders via the user agent and other HTTP-headers. Currently able to detect 1,000's of bots/spiders/crawlers.</p>\n<h3>Installation</h3>\n<p>Run <code>pip install crawlerdetect</code></p>\n<h3>Usage</h3>\n<h4>Variant 1</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">crawlerdetect</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerDetect</span>\n<span class=\"n\">crawler_detect</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerDetect</span><span class=\"p\">()</span>\n<span class=\"n\">crawler_detect</span><span class=\"o\">.</span><span class=\"n\">isCrawler</span><span class=\"p\">(</span><span class=\"s1\">'Mozilla/5.0 (compatible; Sosospider/2.0; +http://help.soso.com/webspider.htm)'</span><span class=\"p\">)</span>\n<span class=\"c1\"># true if crawler user agent detected</span>\n</pre>\n<h4>Variant 2</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">crawlerdetect</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerDetect</span>\n<span class=\"n\">crawler_detect</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerDetect</span><span class=\"p\">(</span><span class=\"n\">user_agent</span><span class=\"o\">=</span><span class=\"s1\">'Mozilla/5.0 (iPhone; CPU iPhone OS 7_1 like Mac OS X) AppleWebKit (KHTML, like Gecko) Mobile (compatible; Yahoo Ad monitoring; https://help.yahoo.com/kb/yahoo-ad-monitoring-SLN24857.html)'</span><span class=\"p\">)</span>\n<span class=\"n\">crawler_detect</span><span class=\"o\">.</span><span class=\"n\">isCrawler</span><span class=\"p\">()</span>\n<span class=\"c1\"># true if crawler user agent detected</span>\n</pre>\n<h4>Variant 3</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">crawlerdetect</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerDetect</span>\n<span class=\"n\">crawler_detect</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerDetect</span><span class=\"p\">(</span><span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'DOCUMENT_ROOT'</span><span class=\"p\">:</span> <span class=\"s1\">'/home/test/public_html'</span><span class=\"p\">,</span> <span class=\"s1\">'GATEWAY_INTERFACE'</span><span class=\"p\">:</span> <span class=\"s1\">'CGI/1.1'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_ACCEPT'</span><span class=\"p\">:</span> <span class=\"s1\">'*/*'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_ACCEPT_ENCODING'</span><span class=\"p\">:</span> <span class=\"s1\">'gzip, deflate'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_CACHE_CONTROL'</span><span class=\"p\">:</span> <span class=\"s1\">'no-cache'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_CONNECTION'</span><span class=\"p\">:</span> <span class=\"s1\">'Keep-Alive'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_FROM'</span><span class=\"p\">:</span> <span class=\"s1\">'googlebot(at)googlebot.com'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_HOST'</span><span class=\"p\">:</span> <span class=\"s1\">'www.test.com'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_PRAGMA'</span><span class=\"p\">:</span> <span class=\"s1\">'no-cache'</span><span class=\"p\">,</span> <span class=\"s1\">'HTTP_USER_AGENT'</span><span class=\"p\">:</span> <span class=\"s1\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.71 Safari/537.36'</span><span class=\"p\">,</span> <span class=\"s1\">'PATH'</span><span class=\"p\">:</span> <span class=\"s1\">'/bin:/usr/bin'</span><span class=\"p\">,</span> <span class=\"s1\">'QUERY_STRING'</span><span class=\"p\">:</span> <span class=\"s1\">'order=closingDate'</span><span class=\"p\">,</span> <span class=\"s1\">'REDIRECT_STATUS'</span><span class=\"p\">:</span> <span class=\"s1\">'200'</span><span class=\"p\">,</span> <span class=\"s1\">'REMOTE_ADDR'</span><span class=\"p\">:</span> <span class=\"s1\">'127.0.0.1'</span><span class=\"p\">,</span> <span class=\"s1\">'REMOTE_PORT'</span><span class=\"p\">:</span> <span class=\"s1\">'3360'</span><span class=\"p\">,</span> <span class=\"s1\">'REQUEST_METHOD'</span><span class=\"p\">:</span> <span class=\"s1\">'GET'</span><span class=\"p\">,</span> <span class=\"s1\">'REQUEST_URI'</span><span class=\"p\">:</span> <span class=\"s1\">'/?test=testing'</span><span class=\"p\">,</span> <span class=\"s1\">'SCRIPT_FILENAME'</span><span class=\"p\">:</span> <span class=\"s1\">'/home/test/public_html/index.php'</span><span class=\"p\">,</span> <span class=\"s1\">'SCRIPT_NAME'</span><span class=\"p\">:</span> <span class=\"s1\">'/index.php'</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_ADDR'</span><span class=\"p\">:</span> <span class=\"s1\">'127.0.0.1'</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_ADMIN'</span><span class=\"p\">:</span> <span class=\"s1\">'webmaster@test.com'</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_NAME'</span><span class=\"p\">:</span> <span class=\"s1\">'www.test.com'</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_PORT'</span><span class=\"p\">:</span> <span class=\"s1\">'80'</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_PROTOCOL'</span><span class=\"p\">:</span> <span class=\"s1\">'HTTP/1.1'</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_SIGNATURE'</span><span class=\"p\">:</span> <span class=\"s1\">''</span><span class=\"p\">,</span> <span class=\"s1\">'SERVER_SOFTWARE'</span><span class=\"p\">:</span> <span class=\"s1\">'Apache'</span><span class=\"p\">,</span> <span class=\"s1\">'UNIQUE_ID'</span><span class=\"p\">:</span> <span class=\"s1\">'Vx6MENRxerBUSDEQgFLAAAAAS'</span><span class=\"p\">,</span> <span class=\"s1\">'PHP_SELF'</span><span class=\"p\">:</span> <span class=\"s1\">'/index.php'</span><span class=\"p\">,</span> <span class=\"s1\">'REQUEST_TIME_FLOAT'</span><span class=\"p\">:</span> <span class=\"mf\">1461619728.0705</span><span class=\"p\">,</span> <span class=\"s1\">'REQUEST_TIME'</span><span class=\"p\">:</span> <span class=\"mi\">1461619728</span><span class=\"p\">})</span>\n<span class=\"n\">crawler_detect</span><span class=\"o\">.</span><span class=\"n\">isCrawler</span><span class=\"p\">()</span>\n<span class=\"c1\"># true if crawler user agent detected</span>\n</pre>\n<h4>Output the name of the bot that matched (if any)</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">crawlerdetect</span> <span class=\"kn\">import</span> <span class=\"n\">CrawlerDetect</span>\n<span class=\"n\">crawler_detect</span> <span class=\"o\">=</span> <span class=\"n\">CrawlerDetect</span><span class=\"p\">()</span>\n<span class=\"n\">crawler_detect</span><span class=\"o\">.</span><span class=\"n\">isCrawler</span><span class=\"p\">(</span><span class=\"s1\">'Mozilla/5.0 (compatible; Sosospider/2.0; +http://help.soso.com/webspider.htm)'</span><span class=\"p\">)</span>\n<span class=\"c1\"># true if crawler user agent detected</span>\n<span class=\"n\">crawler_detect</span><span class=\"o\">.</span><span class=\"n\">getMatches</span><span class=\"p\">()</span>\n<span class=\"c1\"># Sosospider</span>\n</pre>\n<h3>Contributing</h3>\n<p>If you find a bot/spider/crawler user agent that CrawlerDetect fails to detect, please submit a pull request with the regex pattern added to the array in <code>providers/crawlers.py</code> and add the failing user agent to <code>tests/crawlers.txt</code>.</p>\n<p>Failing that, just create an issue with the user agent you have found, and we'll take it from there :)</p>\n<h3>ES6 Library</h3>\n<p>To use this library with NodeJS or any ES6 application based, check out <a href=\"https://github.com/JefferyHus/es6-crawler-detect\" rel=\"nofollow\">es6-crawler-detect</a>.</p>\n<h3>.NET Library</h3>\n<p>To use this library in a .net standard (including .net core) based project, check out <a href=\"https://github.com/gplumb/NetCrawlerDetect\" rel=\"nofollow\">NetCrawlerDetect</a>.</p>\n<h3>Nette Extension</h3>\n<p>To use this library with the Nette framework, checkout <a href=\"https://github.com/JanGalek/Crawler-Detect\" rel=\"nofollow\">NetteCrawlerDetect</a>.</p>\n<h3>Ruby Gem</h3>\n<p>To use this library with Ruby on Rails or any Ruby-based application, check out <a href=\"https://github.com/loadkpi/crawler_detect\" rel=\"nofollow\">crawler_detect</a> gem.</p>\n<p><em>Parts of this class are based on the brilliant <a href=\"https://github.com/serbanghita/Mobile-Detect\" rel=\"nofollow\">MobileDetect</a></em></p>\n<p><a href=\"https://github.com/JayBizzle/Crawler-Detect\" rel=\"nofollow\"><img alt=\"Analytics\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/34e9a06bc73081577592c6a4d7ee1a0f67a40d9b/68747470733a2f2f67612d626561636f6e2e61707073706f742e636f6d2f55412d37323433303436352d312f437261776c65722d4465746563742f726561646d653f706978656c\"></a></p>\n\n          </div>"}, "last_serial": 5686345, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "c0d35309076cbd35f3fe10b27f2f8b07", "sha256": "58e4903220f9980000ffca3990ab21be326b36577e12e41e46d5f1121344ef0c"}, "downloads": -1, "filename": "CrawlerDetect-0.0.1.tar.gz", "has_sig": false, "md5_digest": "c0d35309076cbd35f3fe10b27f2f8b07", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15433, "upload_time": "2019-08-15T13:58:18", "upload_time_iso_8601": "2019-08-15T13:58:18.763623Z", "url": "https://files.pythonhosted.org/packages/46/7b/b6a12a89cb7a2e04147e8478ec2917fc18dedfa928954c86f896f4016e96/CrawlerDetect-0.0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "1558094759eff6b19e512606dc44708f", "sha256": "0028720f63e98c46ecb86bdef515089f9366558f01dd31580291daaeb1434209"}, "downloads": -1, "filename": "CrawlerDetect-0.1.1.tar.gz", "has_sig": false, "md5_digest": "1558094759eff6b19e512606dc44708f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15588, "upload_time": "2019-08-16T07:02:43", "upload_time_iso_8601": "2019-08-16T07:02:43.191375Z", "url": "https://files.pythonhosted.org/packages/55/ae/3c922fdb2887e4a966da5b4540864460e5214a12d626eed030d52d950f2d/CrawlerDetect-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "96ab7450cc5831ecae74b740e13f9b95", "sha256": "b961980570c044a9929405652a9658dee53ca10afca17cc2a4feb4c57ec4bc1e"}, "downloads": -1, "filename": "CrawlerDetect-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "96ab7450cc5831ecae74b740e13f9b95", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 16974, "upload_time": "2019-08-16T07:17:35", "upload_time_iso_8601": "2019-08-16T07:17:35.250882Z", "url": "https://files.pythonhosted.org/packages/13/9c/2b2c33b046fd649e48ea7c247e363bbce71c43469e93c968c1ef1aa757bc/CrawlerDetect-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e3fb21bbf864f864ec8f387203114090", "sha256": "4ba2a7528983c39049dac99d9f419ce429e5aaf20092f41f076ca7290ffbe553"}, "downloads": -1, "filename": "CrawlerDetect-0.1.2.tar.gz", "has_sig": false, "md5_digest": "e3fb21bbf864f864ec8f387203114090", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15589, "upload_time": "2019-08-16T07:16:09", "upload_time_iso_8601": "2019-08-16T07:16:09.177424Z", "url": "https://files.pythonhosted.org/packages/41/41/6595d07297195c39ebe8fa6f0d54ea0657e577ecaf799963341841475652/CrawlerDetect-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "9751074e4f93f05c1c6a41d7d0a56664", "sha256": "60edd916190bf030c41cc93c83a4f5aaf6723d659a1673c82258a728b3a5934d"}, "downloads": -1, "filename": "CrawlerDetect-0.1.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9751074e4f93f05c1c6a41d7d0a56664", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.4, <4", "size": 16974, "upload_time": "2019-08-16T07:18:08", "upload_time_iso_8601": "2019-08-16T07:18:08.825062Z", "url": "https://files.pythonhosted.org/packages/be/c3/d4a21d561473602dc0eded3d845998bb4156b84d324a876e329f8589898d/CrawlerDetect-0.1.3-py2.py3-none-any.whl", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "cc710486898fb3658f4eb21b99918752", "sha256": "81793d14796b0707539e62855d18c0eb4af83f97297ca64f64f67a788781a5a2"}, "downloads": -1, "filename": "crawlerdetect-0.1.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cc710486898fb3658f4eb21b99918752", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.4, <4", "size": 17019, "upload_time": "2019-08-16T07:46:31", "upload_time_iso_8601": "2019-08-16T07:46:31.647218Z", "url": "https://files.pythonhosted.org/packages/5d/18/20e696aafb1a685fc5b8f9217e64bc615c73afaec4d2291159e707c62e14/crawlerdetect-0.1.4-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cc710486898fb3658f4eb21b99918752", "sha256": "81793d14796b0707539e62855d18c0eb4af83f97297ca64f64f67a788781a5a2"}, "downloads": -1, "filename": "crawlerdetect-0.1.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cc710486898fb3658f4eb21b99918752", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.4, <4", "size": 17019, "upload_time": "2019-08-16T07:46:31", "upload_time_iso_8601": "2019-08-16T07:46:31.647218Z", "url": "https://files.pythonhosted.org/packages/5d/18/20e696aafb1a685fc5b8f9217e64bc615c73afaec4d2291159e707c62e14/crawlerdetect-0.1.4-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:42:26 2020"}