{"info": {"author": "Nicolas Renaud, CunLiang Geng Sonja Georgrievska, Li Xue", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Programming Language :: Python :: 3.7"], "description": "# DeepRank\n\n**Deep Learning for ranking protein-protein conformations**\n\n[![Build Status](https://secure.travis-ci.org/DeepRank/deeprank.svg?branch=master)](https://travis-ci.org/DeepRank/deeprank)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/9252e59633cf46a7ada0c3c614c175ea)](https://www.codacy.com/app/NicoRenaud/deeprank?utm_source=github.com&utm_medium=referral&utm_content=DeepRank/deeprank&utm_campaign=Badge_Grade)\n[![Coverage Status](https://coveralls.io/repos/github/DeepRank/deeprank/badge.svg?branch=master)](https://coveralls.io/github/DeepRank/deeprank?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/deeprank/badge/?version=latest)](http://deeprank.readthedocs.io/?badge=latest)\n\nThe documentation of the module can be found on readthedocs :\n<http://deeprank.readthedocs.io/en/latest/>\n\n![alt-text](./pics/deeprank.png)\n\n## 1 . Installation\n\nMinimal information to install the module\n\n\n-   clone the repository `git clone https://github.com/DeepRank/deeprank.git`\n-   go there             `cd deeprank`\n-   install the module   `pip install -e ./`\n-   go int the test dir `cd test`\n-   run the test suite `pytest`\n\n\n## 2 . Tutorial\n\nWe give here the tutorial like introduction to the DeepRank machinery. More informatoin can be found in the documentation <http://deeprank.readthedocs.io/en/latest/>.  We quickly illsutrate here the two main steps of Deeprank :\n\n-   the generation of the data\n-   running deep leaning experiments.\n\n### A . Generate the data set (using MPI)\n\nThe generation of the data require only require PDBs files of decoys and their native and the PSSM if needed. All the features/targets and mapped features onto grid points will be auomatically calculated and store in a HDF5 file.\n\n```python\nfrom deeprank.generate import *\nfrom mpi4py import MPI\n\ncomm = MPI.COMM_WORLD\n\n# adress of the BM4 folder\nBM4 = '/path/to/BM4/data/'\n\n# sources to assemble the data base\npdb_source     = ['./1AK4/decoys/']\npdb_native     = ['./1AK4/native/']\npssm_source    = ['./1AK4/pssm_new/']\n\n# output file\nh5file = './1ak4.hdf5'\n\n#init the data assembler\ndatabase = DataGenerator(pdb_source=pdb_source,\n                         pdb_native=pdb_native,\n                         pssm_source=pssm_source,\n                         data_augmentation = 1,\n                         compute_targets  = ['deeprank.targets.dockQ','deeprank.targets.binary_class'],\n                         compute_features = ['deeprank.features.AtomicFeature',\n                                             'deeprank.features.FullPSSM',\n                                             'deeprank.features.PSSM_IC',\n                                             'deeprank.features.BSA',\n                                             'deeprank.features.ResidueDensity'],\n                         hdf5=h5file,mpi_comm=comm)\n\n#create new files\ndatabase.create_database(prog_bar=True)\n\n# map the features\ngrid_info = {\n  'number_of_points' : [30,30,30],\n  'resolution' : [1.,1.,1.],\n  'atomic_densities' : {'CA':3.5,'N':3.5,'O':3.5,'C':3.5},\n}\n\n database.map_features(grid_info,try_sparse=True,time=False,prog_bar=True)\n```\n\nThis script can be exectuted using for example 4 MPI processes with the command:\n\n```\n    NP=4\n    mpiexec -n $NP python generate.py\n```\n\nIn  the first part of the script we define the path where to find the PDBs of the decoys and natives that we want to have in the dataset. All the .pdb files present in _pdb_source_ will be used in the dataset. We need to specify where to find the native conformations to be able to compute RMSD and the dockQ score. For each pdb file detected in _pdb_source_, the code will try to find a native conformation in _pdb_native_.\n\nWe then initialize the `DataGenerator` object. This object (defined in `deeprank/generate/DataGenerator.py`) needs a few input parameters:\n\n-   pdb_source : where to find the pdb to include in the dataset\n-   pdb_native : where to find the corresponding native conformations\n-   compute_targets : list of modules used to compute the targets\n-   compute_features : list of modules used to compute the features\n-   hdf5 : Name of the HDF5 file to store the data set\n\nWe then create the data base with the command `database.create_database()`. This function autmatically create an HDF5 files where each pdb has its own group. In each group we can find the pdb of the complex and its native form, the calculated features and the calculated targets. We can now mapped the features to a grid. This is done via the command `database.map_features()`. As you can see this method requires a dictionary as input. The dictionary contains the instruction to map the data.\n\n-   number_of_points: the number of points in each direction\n-   resolution : the resolution in Angs\n-   atomic_densities : {'atom_name' : vvdw_radius} the atomic densities required\n\nThe atomic densities are mapped following the [protein-ligand paper](https://arxiv.org/abs/1612.02751). The other features are mapped to the grid points using a Gaussian function (other modes are possible but somehow hard coded)\n\n#### Visualization of the mapped features\n\nTo explore the HDf5 file and vizualize the features you can use the dedicated browser <https://github.com/DeepRank/DeepXplorer>. This tool saloows to dig through the hdf5 file and to directly generate the files required to vizualie the features in VMD or PyMol. An iPython comsole is also embedded to analyze the feature values, plot them etc ....\n\n### B . Deep Learning\n\nThe HDF5 files generated above can be used as input for deep learning experiments. You can take a look at the file `test/test_learn.py` for some examples. We give here a quick overview of the process.\n\n```python\nfrom deeprank.learn import *\nfrom deeprank.learn.model3d import cnn as cnn3d\nimport torch.optim as optim\n\n# input database\ndatabase = '1ak4.hdf5'\n\n# declare the dataset instance\ndata_set = DataSet(database,\n            grid_shape=(30,30,30),\n            select_feature={'AtomicDensities_ind' : 'all',\n                            'Feature_ind' : ['coulomb','vdwaals','charge','pssm'] },\n            select_target='DOCKQ',\n            normalize_features = True, normalize_targets=True,\n            pair_chain_feature=np.add,\n            dict_filter={'IRMSD':'<4. or >10.'})\n\n\n# create the networkt\nmodel = NeuralNet(data_set,cnn3d,model_type='3d',task='reg',\n                  cuda=False,plot=True,outdir=out)\n\n# change the optimizer (optional)\nmodel.optimizer = optim.SGD(model.net.parameters(),\n                            lr=0.001,\n                            momentum=0.9,\n                            weight_decay=0.005)\n\n# start the training\nmodel.train(nepoch = 50,divide_trainset=0.8, train_batch_size = 5,num_workers=0)\n```\n\nIn the first part of the script we create a Torch database from the HDF5 file. We can specify one or several HDF5 files and even select some conformations using the `dict_filter` argument. Other options of `DataSet` can be used to specify the features/targets the normalization, etc ...\n\nWe then create a `NeuralNet` instance that takes the dataset as input argument. Several options are available to specify the task to do, the GPU use, etc ... We then have simply to train the model. Simple !\n\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/DeepRank/deeprank", "keywords": "deeprank", "license": "Apache Software License 2.0", "maintainer": "", "maintainer_email": "", "name": "deeprank", "package_url": "https://pypi.org/project/deeprank/", "platform": "", "project_url": "https://pypi.org/project/deeprank/", "project_urls": {"Documentation": "https://deeprank.readthedocs.io", "Homepage": "https://github.com/DeepRank/deeprank", "Issue tracker": "https://github.com/DeepRank/deeprank/issues", "Source Code": "https://github.com/DeepRank/deeprank"}, "release_url": "https://pypi.org/project/deeprank/0.1.0/", "requires_dist": ["numpy (>=1.13)", "scipy", "h5py", "tqdm", "pandas", "mpi4py", "matplotlib", "torchsummary", "torch (<1.4.0)", "pdb2sql (>=0.3.0)", "freesasa (==2.0.3.post6) ; platform_system == \"Darwin\"", "freesasa (==2.0.3.post7) ; platform_system == \"Linux\"", "pycuda ; extra == 'cuda'", "prospector[with_pyroma] ; extra == 'dev'", "autopep8 ; extra == 'dev'", "isort ; extra == 'dev'", "sphinx ; extra == 'doc'", "nose ; extra == 'test'", "coverage ; extra == 'test'", "pytest ; extra == 'test'", "pytest-cov ; extra == 'test'", "codacy-coverage ; extra == 'test'", "coveralls ; extra == 'test'"], "requires_python": "", "summary": "Rank Protein-Protein Interactions using Deep Learning", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DeepRank</h1>\n<p><strong>Deep Learning for ranking protein-protein conformations</strong></p>\n<p><a href=\"https://travis-ci.org/DeepRank/deeprank\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5ec6be6b00fabd3919e38b6e9c8467460bfe40b0/68747470733a2f2f7365637572652e7472617669732d63692e6f72672f4465657052616e6b2f6465657072616e6b2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://www.codacy.com/app/NicoRenaud/deeprank?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=DeepRank/deeprank&amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/64b7da2f53ca7ddfc3c244f62feea97491694e20/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f3932353265353936333363663436613761646130633363363134633137356561\"></a>\n<a href=\"https://coveralls.io/github/DeepRank/deeprank?branch=master\" rel=\"nofollow\"><img alt=\"Coverage Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/71d13ca9b2cfd10e0e5e1b375126e31afa7fd947/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4465657052616e6b2f6465657072616e6b2f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"http://deeprank.readthedocs.io/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bc79bfaf4a87e0e5caed09c5b10b8479a2d8efbc/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6465657072616e6b2f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p>The documentation of the module can be found on readthedocs :\n<a href=\"http://deeprank.readthedocs.io/en/latest/\" rel=\"nofollow\">http://deeprank.readthedocs.io/en/latest/</a></p>\n<p><img alt=\"alt-text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eaab8c854e8e4d47cac3752e1c7f4a3b80fcf170/2e2f706963732f6465657072616e6b2e706e67\"></p>\n<h2>1 . Installation</h2>\n<p>Minimal information to install the module</p>\n<ul>\n<li>clone the repository <code>git clone https://github.com/DeepRank/deeprank.git</code></li>\n<li>go there             <code>cd deeprank</code></li>\n<li>install the module   <code>pip install -e ./</code></li>\n<li>go int the test dir <code>cd test</code></li>\n<li>run the test suite <code>pytest</code></li>\n</ul>\n<h2>2 . Tutorial</h2>\n<p>We give here the tutorial like introduction to the DeepRank machinery. More informatoin can be found in the documentation <a href=\"http://deeprank.readthedocs.io/en/latest/\" rel=\"nofollow\">http://deeprank.readthedocs.io/en/latest/</a>.  We quickly illsutrate here the two main steps of Deeprank :</p>\n<ul>\n<li>the generation of the data</li>\n<li>running deep leaning experiments.</li>\n</ul>\n<h3>A . Generate the data set (using MPI)</h3>\n<p>The generation of the data require only require PDBs files of decoys and their native and the PSSM if needed. All the features/targets and mapped features onto grid points will be auomatically calculated and store in a HDF5 file.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">deeprank.generate</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">from</span> <span class=\"nn\">mpi4py</span> <span class=\"kn\">import</span> <span class=\"n\">MPI</span>\n\n<span class=\"n\">comm</span> <span class=\"o\">=</span> <span class=\"n\">MPI</span><span class=\"o\">.</span><span class=\"n\">COMM_WORLD</span>\n\n<span class=\"c1\"># adress of the BM4 folder</span>\n<span class=\"n\">BM4</span> <span class=\"o\">=</span> <span class=\"s1\">'/path/to/BM4/data/'</span>\n\n<span class=\"c1\"># sources to assemble the data base</span>\n<span class=\"n\">pdb_source</span>     <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'./1AK4/decoys/'</span><span class=\"p\">]</span>\n<span class=\"n\">pdb_native</span>     <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'./1AK4/native/'</span><span class=\"p\">]</span>\n<span class=\"n\">pssm_source</span>    <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'./1AK4/pssm_new/'</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># output file</span>\n<span class=\"n\">h5file</span> <span class=\"o\">=</span> <span class=\"s1\">'./1ak4.hdf5'</span>\n\n<span class=\"c1\">#init the data assembler</span>\n<span class=\"n\">database</span> <span class=\"o\">=</span> <span class=\"n\">DataGenerator</span><span class=\"p\">(</span><span class=\"n\">pdb_source</span><span class=\"o\">=</span><span class=\"n\">pdb_source</span><span class=\"p\">,</span>\n                         <span class=\"n\">pdb_native</span><span class=\"o\">=</span><span class=\"n\">pdb_native</span><span class=\"p\">,</span>\n                         <span class=\"n\">pssm_source</span><span class=\"o\">=</span><span class=\"n\">pssm_source</span><span class=\"p\">,</span>\n                         <span class=\"n\">data_augmentation</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n                         <span class=\"n\">compute_targets</span>  <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'deeprank.targets.dockQ'</span><span class=\"p\">,</span><span class=\"s1\">'deeprank.targets.binary_class'</span><span class=\"p\">],</span>\n                         <span class=\"n\">compute_features</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'deeprank.features.AtomicFeature'</span><span class=\"p\">,</span>\n                                             <span class=\"s1\">'deeprank.features.FullPSSM'</span><span class=\"p\">,</span>\n                                             <span class=\"s1\">'deeprank.features.PSSM_IC'</span><span class=\"p\">,</span>\n                                             <span class=\"s1\">'deeprank.features.BSA'</span><span class=\"p\">,</span>\n                                             <span class=\"s1\">'deeprank.features.ResidueDensity'</span><span class=\"p\">],</span>\n                         <span class=\"n\">hdf5</span><span class=\"o\">=</span><span class=\"n\">h5file</span><span class=\"p\">,</span><span class=\"n\">mpi_comm</span><span class=\"o\">=</span><span class=\"n\">comm</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#create new files</span>\n<span class=\"n\">database</span><span class=\"o\">.</span><span class=\"n\">create_database</span><span class=\"p\">(</span><span class=\"n\">prog_bar</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># map the features</span>\n<span class=\"n\">grid_info</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n  <span class=\"s1\">'number_of_points'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">30</span><span class=\"p\">,</span><span class=\"mi\">30</span><span class=\"p\">,</span><span class=\"mi\">30</span><span class=\"p\">],</span>\n  <span class=\"s1\">'resolution'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mf\">1.</span><span class=\"p\">,</span><span class=\"mf\">1.</span><span class=\"p\">,</span><span class=\"mf\">1.</span><span class=\"p\">],</span>\n  <span class=\"s1\">'atomic_densities'</span> <span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'CA'</span><span class=\"p\">:</span><span class=\"mf\">3.5</span><span class=\"p\">,</span><span class=\"s1\">'N'</span><span class=\"p\">:</span><span class=\"mf\">3.5</span><span class=\"p\">,</span><span class=\"s1\">'O'</span><span class=\"p\">:</span><span class=\"mf\">3.5</span><span class=\"p\">,</span><span class=\"s1\">'C'</span><span class=\"p\">:</span><span class=\"mf\">3.5</span><span class=\"p\">},</span>\n<span class=\"p\">}</span>\n\n <span class=\"n\">database</span><span class=\"o\">.</span><span class=\"n\">map_features</span><span class=\"p\">(</span><span class=\"n\">grid_info</span><span class=\"p\">,</span><span class=\"n\">try_sparse</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span><span class=\"n\">time</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span><span class=\"n\">prog_bar</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>This script can be exectuted using for example 4 MPI processes with the command:</p>\n<pre><code>    NP=4\n    mpiexec -n $NP python generate.py\n</code></pre>\n<p>In  the first part of the script we define the path where to find the PDBs of the decoys and natives that we want to have in the dataset. All the .pdb files present in <em>pdb_source</em> will be used in the dataset. We need to specify where to find the native conformations to be able to compute RMSD and the dockQ score. For each pdb file detected in <em>pdb_source</em>, the code will try to find a native conformation in <em>pdb_native</em>.</p>\n<p>We then initialize the <code>DataGenerator</code> object. This object (defined in <code>deeprank/generate/DataGenerator.py</code>) needs a few input parameters:</p>\n<ul>\n<li>pdb_source : where to find the pdb to include in the dataset</li>\n<li>pdb_native : where to find the corresponding native conformations</li>\n<li>compute_targets : list of modules used to compute the targets</li>\n<li>compute_features : list of modules used to compute the features</li>\n<li>hdf5 : Name of the HDF5 file to store the data set</li>\n</ul>\n<p>We then create the data base with the command <code>database.create_database()</code>. This function autmatically create an HDF5 files where each pdb has its own group. In each group we can find the pdb of the complex and its native form, the calculated features and the calculated targets. We can now mapped the features to a grid. This is done via the command <code>database.map_features()</code>. As you can see this method requires a dictionary as input. The dictionary contains the instruction to map the data.</p>\n<ul>\n<li>number_of_points: the number of points in each direction</li>\n<li>resolution : the resolution in Angs</li>\n<li>atomic_densities : {'atom_name' : vvdw_radius} the atomic densities required</li>\n</ul>\n<p>The atomic densities are mapped following the <a href=\"https://arxiv.org/abs/1612.02751\" rel=\"nofollow\">protein-ligand paper</a>. The other features are mapped to the grid points using a Gaussian function (other modes are possible but somehow hard coded)</p>\n<h4>Visualization of the mapped features</h4>\n<p>To explore the HDf5 file and vizualize the features you can use the dedicated browser <a href=\"https://github.com/DeepRank/DeepXplorer\" rel=\"nofollow\">https://github.com/DeepRank/DeepXplorer</a>. This tool saloows to dig through the hdf5 file and to directly generate the files required to vizualie the features in VMD or PyMol. An iPython comsole is also embedded to analyze the feature values, plot them etc ....</p>\n<h3>B . Deep Learning</h3>\n<p>The HDF5 files generated above can be used as input for deep learning experiments. You can take a look at the file <code>test/test_learn.py</code> for some examples. We give here a quick overview of the process.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">deeprank.learn</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"kn\">from</span> <span class=\"nn\">deeprank.learn.model3d</span> <span class=\"kn\">import</span> <span class=\"n\">cnn</span> <span class=\"k\">as</span> <span class=\"n\">cnn3d</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.optim</span> <span class=\"k\">as</span> <span class=\"nn\">optim</span>\n\n<span class=\"c1\"># input database</span>\n<span class=\"n\">database</span> <span class=\"o\">=</span> <span class=\"s1\">'1ak4.hdf5'</span>\n\n<span class=\"c1\"># declare the dataset instance</span>\n<span class=\"n\">data_set</span> <span class=\"o\">=</span> <span class=\"n\">DataSet</span><span class=\"p\">(</span><span class=\"n\">database</span><span class=\"p\">,</span>\n            <span class=\"n\">grid_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">30</span><span class=\"p\">,</span><span class=\"mi\">30</span><span class=\"p\">,</span><span class=\"mi\">30</span><span class=\"p\">),</span>\n            <span class=\"n\">select_feature</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'AtomicDensities_ind'</span> <span class=\"p\">:</span> <span class=\"s1\">'all'</span><span class=\"p\">,</span>\n                            <span class=\"s1\">'Feature_ind'</span> <span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'coulomb'</span><span class=\"p\">,</span><span class=\"s1\">'vdwaals'</span><span class=\"p\">,</span><span class=\"s1\">'charge'</span><span class=\"p\">,</span><span class=\"s1\">'pssm'</span><span class=\"p\">]</span> <span class=\"p\">},</span>\n            <span class=\"n\">select_target</span><span class=\"o\">=</span><span class=\"s1\">'DOCKQ'</span><span class=\"p\">,</span>\n            <span class=\"n\">normalize_features</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">normalize_targets</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n            <span class=\"n\">pair_chain_feature</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">,</span>\n            <span class=\"n\">dict_filter</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'IRMSD'</span><span class=\"p\">:</span><span class=\"s1\">'&lt;4. or &gt;10.'</span><span class=\"p\">})</span>\n\n\n<span class=\"c1\"># create the networkt</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">NeuralNet</span><span class=\"p\">(</span><span class=\"n\">data_set</span><span class=\"p\">,</span><span class=\"n\">cnn3d</span><span class=\"p\">,</span><span class=\"n\">model_type</span><span class=\"o\">=</span><span class=\"s1\">'3d'</span><span class=\"p\">,</span><span class=\"n\">task</span><span class=\"o\">=</span><span class=\"s1\">'reg'</span><span class=\"p\">,</span>\n                  <span class=\"n\">cuda</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span><span class=\"n\">plot</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span><span class=\"n\">outdir</span><span class=\"o\">=</span><span class=\"n\">out</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># change the optimizer (optional)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span>\n                            <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span>\n                            <span class=\"n\">momentum</span><span class=\"o\">=</span><span class=\"mf\">0.9</span><span class=\"p\">,</span>\n                            <span class=\"n\">weight_decay</span><span class=\"o\">=</span><span class=\"mf\">0.005</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># start the training</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">nepoch</span> <span class=\"o\">=</span> <span class=\"mi\">50</span><span class=\"p\">,</span><span class=\"n\">divide_trainset</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">train_batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>In the first part of the script we create a Torch database from the HDF5 file. We can specify one or several HDF5 files and even select some conformations using the <code>dict_filter</code> argument. Other options of <code>DataSet</code> can be used to specify the features/targets the normalization, etc ...</p>\n<p>We then create a <code>NeuralNet</code> instance that takes the dataset as input argument. Several options are available to specify the task to do, the GPU use, etc ... We then have simply to train the model. Simple !</p>\n\n          </div>"}, "last_serial": 6921176, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "5a0fd905979f5ed70751e1a757d6267e", "sha256": "ee3ce67b11da080ffc4c931a72ca3c44b80f7369812b397b52c8798aa89f085d"}, "downloads": -1, "filename": "deeprank-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5a0fd905979f5ed70751e1a757d6267e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 98486, "upload_time": "2020-03-31T16:01:18", "upload_time_iso_8601": "2020-03-31T16:01:18.720585Z", "url": "https://files.pythonhosted.org/packages/6e/a7/e9b1e70deecb934e42ca604ccd272a53a4f97db1788a6e03131f4b659a17/deeprank-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c2760df45630c1a450e22a41a55091a4", "sha256": "e1b2efe0f64751385fd030a12e7f439b14e4de3fc6b7692e6fcd8638722c5e4a"}, "downloads": -1, "filename": "deeprank-0.1.0.tar.gz", "has_sig": false, "md5_digest": "c2760df45630c1a450e22a41a55091a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 691596, "upload_time": "2020-03-31T16:01:21", "upload_time_iso_8601": "2020-03-31T16:01:21.354691Z", "url": "https://files.pythonhosted.org/packages/e3/d5/93560d9f8ec531c6fc08871ce7c801341a73649ffc5075811db08fa5e05d/deeprank-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5a0fd905979f5ed70751e1a757d6267e", "sha256": "ee3ce67b11da080ffc4c931a72ca3c44b80f7369812b397b52c8798aa89f085d"}, "downloads": -1, "filename": "deeprank-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5a0fd905979f5ed70751e1a757d6267e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 98486, "upload_time": "2020-03-31T16:01:18", "upload_time_iso_8601": "2020-03-31T16:01:18.720585Z", "url": "https://files.pythonhosted.org/packages/6e/a7/e9b1e70deecb934e42ca604ccd272a53a4f97db1788a6e03131f4b659a17/deeprank-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c2760df45630c1a450e22a41a55091a4", "sha256": "e1b2efe0f64751385fd030a12e7f439b14e4de3fc6b7692e6fcd8638722c5e4a"}, "downloads": -1, "filename": "deeprank-0.1.0.tar.gz", "has_sig": false, "md5_digest": "c2760df45630c1a450e22a41a55091a4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 691596, "upload_time": "2020-03-31T16:01:21", "upload_time_iso_8601": "2020-03-31T16:01:21.354691Z", "url": "https://files.pythonhosted.org/packages/e3/d5/93560d9f8ec531c6fc08871ce7c801341a73649ffc5075811db08fa5e05d/deeprank-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:21 2020"}