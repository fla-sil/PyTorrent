{"info": {"author": "Johannes Petrat", "author_email": "petrat.johannes@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Topic :: Software Development :: Build Tools"], "description": "OptML |codecov|\n===============\n\nThis package offers implementations of several black-box optimisation methods to tune\nhyperparameters of machine learning models. Its purpose is to enable data scientists to use\noptimization techniques for rapid protyping. Simply import OptML and supply it with a model and the\nparameters to optimize.\n\nOptML offers a unified interface for models built with Scikit-Learn, Keras, XGBoost (and hopefully\nsoon Statsmodels).\n\nPrerequisites\n-------------\n\nThis package requires scikit-learn with version 0.19.0 or higher. If Scikit-Learn is not yet\ninstalled run ``pip install scikit-learn==0.19.0``. If you want to make use of the\n``HyperoptOptimizer`` then you also need to install\n`hyperopt <https://github.com/hyperopt/hyperopt>`__ (e.g. by ``pip install hyperopt``).\n\nIn order to run with `Keras <https://github.com/fchollet/keras>`__ and\n`XGBoost <https://github.com/dmlc/xgboost>`__ models these libraries have to be install as well, of\ncourse.\n\nInstallation\n------------\n\nIf Scikit-Learn is version 0.19 or higher simply install optml using ``pip install optml`` and\nyou're ready to go.\n\nUsage\n-----\n\nSpecify your ML model and the parameters you want to optimize over. For the parameters you have to\nchoose the type (such as integer, categorical, boolean, etc.) and the range of values it can take.\n\n.. code:: python\n\n    model = SomeMLModel()\n    params = [Parameter(name='param1', param_type='continuous', lower=0.1, upper=5),\n              Parameter(name='param2', param_type='integer', lower=1, upper=5),\n              Parameter(name='param3', param_type='categorical', possible_values=['val1','val2','val3'])]\n\nThen define the evaluation function. This can be anything from RMSE to crossentropy to custom\nfunctions. The first argument of the evaluation function is the array of true labels and the second\nargument is an array with model predictions.\n\n.. code:: python\n\n    def clf_score(y_true,y_pred):\n        return np.sum(y_true==y_pred)/float(len(y_true))\n\nImport and initialize an optimizer and optimize the model for some training data.\n\n.. code:: python\n\n    from optml.bayesian_optimizer import BayesianOptimizer\n    bayesOpt = BayesianOptimizer(model=model, \n                                 hyperparams=params,                                  \n                                 eval_func=clf_score)\n    bayes_best_params, bayes_best_model = bayesOpt.fit(X_train=X_train, y_train=y_train, n_iters=50)\n\nFeatures\n--------\n\nAt the moment this library includes: \\* Random Search \\* Parallelized Gridsearch \\* A simple Genetic\nAlgorithm \\* Bayesian Optimisation (also supporting categorical parameters) \\* Hyperopt (using\n`hyperopt <https://github.com/hyperopt/hyperopt>`__)\n\nHow to Choose an Optimizer\n--------------------------\n\nOptML implements several optimization methods to address a range of requirements that can arise in\ndata science problems. One of the main concerns is the effort required to evaluate a model for a set\nof parameters: If a model takes a long time to train we should choose an optimizer that maximises\nthe potential improvement with every new set of parameters. In this case Bayesian Optimization and\nHyperopt are more applicable. If a model is cheap to train then we can seek to parallelise the\nevaluations.\n\nAlso consider the number of parameters and their ranges. Clearly, it is more difficult to optimize\nover a large search space. It is advised to only include parameters in the optimization if they are\nexpected to improve the final model.\n\nPlease also note that all of OptML's optimizers require parameters to be bounded.\n\n+--------------+------------------+--------------------+----------------+----------------------+-------------------+\n|              | number of        | works with large   | can use        | handles categorical  | stochastic        |\n|              | evaluations      | search space       | training in    | parameters           | optimisation      |\n|              |                  |                    | parallel       |                      |                   |\n+==============+==================+====================+================+======================+===================+\n| Gridsearch   | high             | no                 | yes            | yes                  | no                |\n+--------------+------------------+--------------------+----------------+----------------------+-------------------+\n| Random       | high             | yes                | yes            | yes                  | yes               |\n| Search       |                  |                    |                |                      |                   |\n+--------------+------------------+--------------------+----------------+----------------------+-------------------+\n| Genetic      | high             | yes                | not            | yes                  | yes               |\n| Algorithm    |                  |                    | implemented    |                      |                   |\n+--------------+------------------+--------------------+----------------+----------------------+-------------------+\n| Bayesian     | low              | yes                | not            | yes                  | yes               |\n| Optimizer    |                  |                    | implemented    |                      |                   |\n+--------------+------------------+--------------------+----------------+----------------------+-------------------+\n| Hyperopt     | low              | yes                | yes            | yes                  | yes               |\n+--------------+------------------+--------------------+----------------+----------------------+-------------------+\n\nTODOs\n-----\n\n1. algorithms:\n\n-  implement more options for genetic algorithms\n-  meta heuristics/swarm optimisation\n\n2. functionality\n\n-  early stopping if there is no significant improvement after x iterations\n\n3. usability\n\n-  better documenation\n\nAuthor\n------\n\n-  **Johannes Petrat** - *Initial Release* - `johannespetrat <https://github.com/johannespetrat>`__\n\nLicense\n-------\n\nThis project is licensed under the MIT License - see the `LICENSE.md <LICENSE.md>`__ file for\ndetails\n\n.. |codecov| image:: https://codecov.io/gh/johannespetrat/OptML/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/johannespetrat/OptML", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/johannespetrat/OptML", "keywords": "optimization machine learning hyperparameter bayesian gridsearch", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "optml", "package_url": "https://pypi.org/project/optml/", "platform": "", "project_url": "https://pypi.org/project/optml/", "project_urls": {"Homepage": "https://github.com/johannespetrat/OptML"}, "release_url": "https://pypi.org/project/optml/0.2.3/", "requires_dist": null, "requires_python": "", "summary": "A library for hyperparameter optimization of ML models", "version": "0.2.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This package offers implementations of several black-box optimisation methods to tune\nhyperparameters of machine learning models. Its purpose is to enable data scientists to use\noptimization techniques for rapid protyping. Simply import OptML and supply it with a model and the\nparameters to optimize.</p>\n<p>OptML offers a unified interface for models built with Scikit-Learn, Keras, XGBoost (and hopefully\nsoon Statsmodels).</p>\n<div id=\"prerequisites\">\n<h2>Prerequisites</h2>\n<p>This package requires scikit-learn with version 0.19.0 or higher. If Scikit-Learn is not yet\ninstalled run <tt>pip install <span class=\"pre\">scikit-learn==0.19.0</span></tt>. If you want to make use of the\n<tt>HyperoptOptimizer</tt> then you also need to install\n<a href=\"https://github.com/hyperopt/hyperopt\" rel=\"nofollow\">hyperopt</a> (e.g. by <tt>pip install hyperopt</tt>).</p>\n<p>In order to run with <a href=\"https://github.com/fchollet/keras\" rel=\"nofollow\">Keras</a> and\n<a href=\"https://github.com/dmlc/xgboost\" rel=\"nofollow\">XGBoost</a> models these libraries have to be install as well, of\ncourse.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>If Scikit-Learn is version 0.19 or higher simply install optml using <tt>pip install optml</tt> and\nyou\u2019re ready to go.</p>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Specify your ML model and the parameters you want to optimize over. For the parameters you have to\nchoose the type (such as integer, categorical, boolean, etc.) and the range of values it can take.</p>\n<pre><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SomeMLModel</span><span class=\"p\">()</span>\n<span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'param1'</span><span class=\"p\">,</span> <span class=\"n\">param_type</span><span class=\"o\">=</span><span class=\"s1\">'continuous'</span><span class=\"p\">,</span> <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">,</span> <span class=\"n\">upper</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">),</span>\n          <span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'param2'</span><span class=\"p\">,</span> <span class=\"n\">param_type</span><span class=\"o\">=</span><span class=\"s1\">'integer'</span><span class=\"p\">,</span> <span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">upper</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">),</span>\n          <span class=\"n\">Parameter</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'param3'</span><span class=\"p\">,</span> <span class=\"n\">param_type</span><span class=\"o\">=</span><span class=\"s1\">'categorical'</span><span class=\"p\">,</span> <span class=\"n\">possible_values</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'val1'</span><span class=\"p\">,</span><span class=\"s1\">'val2'</span><span class=\"p\">,</span><span class=\"s1\">'val3'</span><span class=\"p\">])]</span>\n</pre>\n<p>Then define the evaluation function. This can be anything from RMSE to crossentropy to custom\nfunctions. The first argument of the evaluation function is the array of true labels and the second\nargument is an array with model predictions.</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">clf_score</span><span class=\"p\">(</span><span class=\"n\">y_true</span><span class=\"p\">,</span><span class=\"n\">y_pred</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">y_true</span><span class=\"o\">==</span><span class=\"n\">y_pred</span><span class=\"p\">)</span><span class=\"o\">/</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y_true</span><span class=\"p\">))</span>\n</pre>\n<p>Import and initialize an optimizer and optimize the model for some training data.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">optml.bayesian_optimizer</span> <span class=\"kn\">import</span> <span class=\"n\">BayesianOptimizer</span>\n<span class=\"n\">bayesOpt</span> <span class=\"o\">=</span> <span class=\"n\">BayesianOptimizer</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span>\n                             <span class=\"n\">hyperparams</span><span class=\"o\">=</span><span class=\"n\">params</span><span class=\"p\">,</span>\n                             <span class=\"n\">eval_func</span><span class=\"o\">=</span><span class=\"n\">clf_score</span><span class=\"p\">)</span>\n<span class=\"n\">bayes_best_params</span><span class=\"p\">,</span> <span class=\"n\">bayes_best_model</span> <span class=\"o\">=</span> <span class=\"n\">bayesOpt</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"o\">=</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"o\">=</span><span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">n_iters</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<p>At the moment this library includes: * Random Search * Parallelized Gridsearch * A simple Genetic\nAlgorithm * Bayesian Optimisation (also supporting categorical parameters) * Hyperopt (using\n<a href=\"https://github.com/hyperopt/hyperopt\" rel=\"nofollow\">hyperopt</a>)</p>\n</div>\n<div id=\"how-to-choose-an-optimizer\">\n<h2>How to Choose an Optimizer</h2>\n<p>OptML implements several optimization methods to address a range of requirements that can arise in\ndata science problems. One of the main concerns is the effort required to evaluate a model for a set\nof parameters: If a model takes a long time to train we should choose an optimizer that maximises\nthe potential improvement with every new set of parameters. In this case Bayesian Optimization and\nHyperopt are more applicable. If a model is cheap to train then we can seek to parallelise the\nevaluations.</p>\n<p>Also consider the number of parameters and their ranges. Clearly, it is more difficult to optimize\nover a large search space. It is advised to only include parameters in the optimization if they are\nexpected to improve the final model.</p>\n<p>Please also note that all of OptML\u2019s optimizers require parameters to be bounded.</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>\u00a0</th>\n<th>number of\nevaluations</th>\n<th>works with large\nsearch space</th>\n<th>can use\ntraining in\nparallel</th>\n<th>handles categorical\nparameters</th>\n<th>stochastic\noptimisation</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>Gridsearch</td>\n<td>high</td>\n<td>no</td>\n<td>yes</td>\n<td>yes</td>\n<td>no</td>\n</tr>\n<tr><td>Random\nSearch</td>\n<td>high</td>\n<td>yes</td>\n<td>yes</td>\n<td>yes</td>\n<td>yes</td>\n</tr>\n<tr><td>Genetic\nAlgorithm</td>\n<td>high</td>\n<td>yes</td>\n<td>not\nimplemented</td>\n<td>yes</td>\n<td>yes</td>\n</tr>\n<tr><td>Bayesian\nOptimizer</td>\n<td>low</td>\n<td>yes</td>\n<td>not\nimplemented</td>\n<td>yes</td>\n<td>yes</td>\n</tr>\n<tr><td>Hyperopt</td>\n<td>low</td>\n<td>yes</td>\n<td>yes</td>\n<td>yes</td>\n<td>yes</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"todos\">\n<h2>TODOs</h2>\n<ol>\n<li>algorithms:</li>\n</ol>\n<ul>\n<li>implement more options for genetic algorithms</li>\n<li>meta heuristics/swarm optimisation</li>\n</ul>\n<ol>\n<li>functionality</li>\n</ol>\n<ul>\n<li>early stopping if there is no significant improvement after x iterations</li>\n</ul>\n<ol>\n<li>usability</li>\n</ol>\n<ul>\n<li>better documenation</li>\n</ul>\n</div>\n<div id=\"author\">\n<h2>Author</h2>\n<ul>\n<li><strong>Johannes Petrat</strong> - <em>Initial Release</em> - <a href=\"https://github.com/johannespetrat\" rel=\"nofollow\">johannespetrat</a></li>\n</ul>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>This project is licensed under the MIT License - see the <a href=\"LICENSE.md\" rel=\"nofollow\">LICENSE.md</a> file for\ndetails</p>\n</div>\n\n          </div>"}, "last_serial": 3504144, "releases": {"0.0.1.dev1": [{"comment_text": "", "digests": {"md5": "44d448e778a86ff14eba8d491013a011", "sha256": "c62785fd6dca6d335b1bc867095dba9fd60118762eda850e948e042ac597c5ce"}, "downloads": -1, "filename": "optml-0.0.1.dev1.tar.gz", "has_sig": false, "md5_digest": "44d448e778a86ff14eba8d491013a011", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8369, "upload_time": "2017-10-30T10:32:32", "upload_time_iso_8601": "2017-10-30T10:32:32.687812Z", "url": "https://files.pythonhosted.org/packages/20/de/932b305a8d476c041aa2f5b1756677a28fc489c8f5caca10a3a773e42fce/optml-0.0.1.dev1.tar.gz", "yanked": false}], "0.0.2.dev1": [{"comment_text": "", "digests": {"md5": "65aec5e63d14c90986a160f1d0570722", "sha256": "815a31d9c52c18bfb7f08b3ec62a642d84a187ef492c912d3fe1883f9258170a"}, "downloads": -1, "filename": "optml-0.0.2.dev1.tar.gz", "has_sig": false, "md5_digest": "65aec5e63d14c90986a160f1d0570722", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8303, "upload_time": "2017-10-30T11:01:51", "upload_time_iso_8601": "2017-10-30T11:01:51.124052Z", "url": "https://files.pythonhosted.org/packages/e7/34/8a8e0192b527d9cb51c3c3a37f8bebc7519247ecf62f7644be8be3c86dd8/optml-0.0.2.dev1.tar.gz", "yanked": false}], "0.0.3.dev1": [{"comment_text": "", "digests": {"md5": "ec645b3568791db0fa63660dfad25aa7", "sha256": "02dfd4f3c7cfa7a387a5708a9d86ec4efa7902acc3d76a42d551c2182cdea985"}, "downloads": -1, "filename": "optml-0.0.3.dev1.tar.gz", "has_sig": false, "md5_digest": "ec645b3568791db0fa63660dfad25aa7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8640, "upload_time": "2017-10-31T13:57:17", "upload_time_iso_8601": "2017-10-31T13:57:17.825629Z", "url": "https://files.pythonhosted.org/packages/bb/08/68ca8c212c7e69fb0079429b7dc09d3f5cfda2c54670177ab5cc1a8bc7fe/optml-0.0.3.dev1.tar.gz", "yanked": false}], "0.0.5.dev1": [{"comment_text": "", "digests": {"md5": "da07da8dab2bdb442e22e1af81ebdb07", "sha256": "b9716541d85ae1c9cd12ad1e9ba4bd27b54269a350b2c1162cb16cc0e5936510"}, "downloads": -1, "filename": "optml-0.0.5.dev1.tar.gz", "has_sig": false, "md5_digest": "da07da8dab2bdb442e22e1af81ebdb07", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8968, "upload_time": "2017-11-13T10:05:31", "upload_time_iso_8601": "2017-11-13T10:05:31.185676Z", "url": "https://files.pythonhosted.org/packages/5d/17/c64afd7e233423c4aa2687b750cb278b82e18b63fe3eb15869e535c9dd96/optml-0.0.5.dev1.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "f1a0f2d0ec602e5140df4dbefad40544", "sha256": "ead81b2fbdf8eb4991398b7577c172e9d1a588daf1c0114f1b69a1399330465b"}, "downloads": -1, "filename": "optml-0.1.0.tar.gz", "has_sig": false, "md5_digest": "f1a0f2d0ec602e5140df4dbefad40544", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9425, "upload_time": "2017-11-13T10:24:17", "upload_time_iso_8601": "2017-11-13T10:24:17.324611Z", "url": "https://files.pythonhosted.org/packages/da/ac/b33af9d12984689ceb74ebccd196b2250b76d0ce848fb9ba80fc58c3b6eb/optml-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "693c0b567073f05f30a836b67ffd1378", "sha256": "67c74c103f7d16fcd3b5031743a30e66ea6eb0c24970011475ad1d2fc7df827b"}, "downloads": -1, "filename": "optml-0.2.0.tar.gz", "has_sig": false, "md5_digest": "693c0b567073f05f30a836b67ffd1378", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10790, "upload_time": "2018-01-17T13:28:21", "upload_time_iso_8601": "2018-01-17T13:28:21.745598Z", "url": "https://files.pythonhosted.org/packages/f9/a1/8f71fcad42d849287121c4cc0dd49aa4d7cabf0ff82ac8d065a13c75024a/optml-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "95aad2f331084df004791c95831ee6bd", "sha256": "214a89858fd2f5104596003e3fa08f5c6e1575598adc5d2c11ca0e1391c7d5a7"}, "downloads": -1, "filename": "optml-0.2.1.tar.gz", "has_sig": false, "md5_digest": "95aad2f331084df004791c95831ee6bd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10788, "upload_time": "2018-01-17T13:39:37", "upload_time_iso_8601": "2018-01-17T13:39:37.826615Z", "url": "https://files.pythonhosted.org/packages/e0/6d/a4e1d6c35922a508336e3327043baeca0bbdca3f5aa785e331f3d54a62b7/optml-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "c5712e563953a59120ce1db35eaf24dd", "sha256": "e2e82264fa7d063492388fc0365da8768a9a7420728d0800f72a047e6ea96c3f"}, "downloads": -1, "filename": "optml-0.2.2.tar.gz", "has_sig": false, "md5_digest": "c5712e563953a59120ce1db35eaf24dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12944, "upload_time": "2018-01-19T09:11:11", "upload_time_iso_8601": "2018-01-19T09:11:11.650330Z", "url": "https://files.pythonhosted.org/packages/02/5a/da60910d06a26909f90114bfa088e73c201d55afdaf423cc0a62d8b71c5c/optml-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "7cfd21fd2bfd0e68f24f625963407439", "sha256": "6871e13aafbb32a9fa615f4603101dd0480f6c9dcf4a2bdb34c14115df54ebf2"}, "downloads": -1, "filename": "optml-0.2.3.tar.gz", "has_sig": false, "md5_digest": "7cfd21fd2bfd0e68f24f625963407439", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21757, "upload_time": "2018-01-19T10:47:12", "upload_time_iso_8601": "2018-01-19T10:47:12.524614Z", "url": "https://files.pythonhosted.org/packages/53/d5/c9d5d6924dbf02a442cd9f0487252b0a503f78a791e72836843914849eff/optml-0.2.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7cfd21fd2bfd0e68f24f625963407439", "sha256": "6871e13aafbb32a9fa615f4603101dd0480f6c9dcf4a2bdb34c14115df54ebf2"}, "downloads": -1, "filename": "optml-0.2.3.tar.gz", "has_sig": false, "md5_digest": "7cfd21fd2bfd0e68f24f625963407439", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21757, "upload_time": "2018-01-19T10:47:12", "upload_time_iso_8601": "2018-01-19T10:47:12.524614Z", "url": "https://files.pythonhosted.org/packages/53/d5/c9d5d6924dbf02a442cd9f0487252b0a503f78a791e72836843914849eff/optml-0.2.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:01:58 2020"}