{"info": {"author": "Levi Borodenko", "author_email": "Levi.borodenko@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Programming Language :: Python"], "description": "# DGCNN [TensorFlow]\nTensorFlow 2 implementation of _An end-to-end deep learning architecture for graph classification_ based on work by [M. Zhang et al., 2018](https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf).\n\nMoreover, we offer an attention based modification of the above by utilising graph attention [(Veli\u010dkovi\u0107 et al., 2017)](https://arxiv.org/abs/1710.10903) to learn edge weights.\n\n### Installation\n\nSimply run `pip install dgcnn`. The only dependency is `tensorflow>=2.0.0`.\n\n### Usage\n\nThe core data structure is the _graph signal_. If we have N nodes in a graph each having C observed features then the graph signal is the tensor with shape (batch, N, C) corresponding to the data produced by all nodes. Often we have sequences of graph signals in a time series. We will call them _temporal_ graph signals and assume a shape of (batch, time steps, N, C).\nFor each graph signal we also need to have the corresponding adjacency matrices of shape (batch, N, N) or (batch, timesteps, N, N) for temporal and non-temporal data, respectively. While DGCNNs can operate on graphs with different node-counts, C should always be the same and each batch should only contain graphs with the same number of nodes.\n\n#### The `DeepGraphConvolution` Layer\n\nThis adaptable layer contains the whole DGCNN architecture and operates on both temporal and non-temporal data. It takes the graph signals and their corresponding adjacency matrices and performs the following steps (as described in the paper):\n\nWe initialize the layer by providing  <a href=\"https://www.codecogs.com/eqnedit.php?latex=k,&space;c_1,&space;\\dots,&space;c_h&space;\\in&space;\\mathbb{N}\" target=\"_blank\"><img style=\"vertical-align: middle\" src=\"https://latex.codecogs.com/gif.latex?k,&space;c_1,&space;\\dots,&space;c_h&space;\\in&space;\\mathbb{N}\" title=\"k, c_1, \\dots, c_h \\in \\mathbb{N}\" /></a>. The layer has many optional parameters that are described in the table below.\n\n1. It iteratively applies `GraphConvolution` layers h times with variable hidden feature dimensions <a href=\"https://www.codecogs.com/eqnedit.php?latex=c_i\" target=\"_blank\"><img style=\"vertical-align: middle\" src=\"https://latex.codecogs.com/gif.latex?c_i\" title=\"c_i\" /></a>.\n\n2. After that, it concatenates all the outputs of the graph convolutions into one tensor which has the shape (..., N, <a href=\"https://www.codecogs.com/eqnedit.php?latex=\\sum_{i&space;=&space;1}^hc_i\" target=\"_blank\"><img style=\"vertical-align: middle\" src=\"https://latex.codecogs.com/gif.latex?\\sum_{i&space;=&space;1}^hc_i\" title=\"\\sum_{i = 1}^hc_i\" /></a>).\n\n3. Finally it applies `SortPooling` as described in the paper to obtain the output tensor of shape (..., k, <a href=\"https://www.codecogs.com/eqnedit.php?latex=\\sum_{i&space;=&space;1}^hc_i\" target=\"_blank\"><img style=\"vertical-align: middle\" src=\"https://latex.codecogs.com/gif.latex?\\sum_{i&space;=&space;1}^hc_i\" title=\"\\sum_{i = 1}^hc_i\" /></a>).\n\nImport this layer with `from gdcnn.components import DeepGraphConvolution`.\n\nInitiated it with the following parameters:\n\n| Parameter | Function |\n|:------------- | :--------|\n|`hidden_conv_units` (required) | List of the hidden feature dimensions used in the graph convolutions. <a href=\"https://www.codecogs.com/eqnedit.php?latex=k,&space;c_1,&space;\\dots,&space;c_h&space;\\in&space;\\mathbb{N}\" target=\"_blank\"><img style=\"vertical-align: middle\" src=\"https://latex.codecogs.com/gif.latex?c_1,&space;\\dots,&space;c_h\" title=\"c_1, \\dots, c_h\" /></a> in the paper.|\n|`k` (required) |Number of nodes to be kept after SortPooling.|\n|`flatten_signals` (default: False) | If `True`, flattens the last 2 dimensions of the output tensor into 1|\n|`attention_heads` (default: None) | If given, then instead of using <a href=\"https://www.codecogs.com/eqnedit.php?latex=D^{-1}E\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?D^{-1}E\" title=\"D^{-1}E\" /></a> as the transition matrix inside the graph convolutions, we will use an attention based transition matrix. Utilizing `dgcnn.attention.AttentionMechanism` as the internal attention mechanism. This sets the number of attention heads used.|\n|`attention_units` (default: None) | Also needs to be provided if `attention_heads` is set. This is the size of the internal embedding used by the attention mechanism.|\n|`use_sortpooling` (default: True) | Whether or not to apply sortpooling at the end of the procedure. If False, we will simply return the concatinated graph convolution outputs.|\n\nThus, if we have non-temporal graph signals with 10 nodes and 5 features each and we would like to apply a DGCNN containing 3 graph convolutions with hidden feature dimensions of 10, 5 and 2 and SortPooling that keeps the 5 most relevant nodes. Then we would run\n\n```python\nfrom dgcnn.components import DeepGraphConvolution\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras import Model\n\n\n# generating random graph signals as test data\ngraph_signal = np.random.normal(size=(100, 10, 5)\n\n# corresponding fully connected adjacency matrices\nadjacency = np.ones((100, 10, 10))\n\n# inputs to the DGCNN\nX = Input(shape=(10, 5), name=\"graph_signal\")\nE = Input(shape=(10, 10), name=\"adjacency\")\n\n# DGCNN\n# Note that we pass the signals and adjacencies as a tuple.\n# The graph signal always goes first!\noutput = DeepGraphConvolution([10, 5, 2], k=5 )((X, E))\n\n# defining model\nmodel = Model(inputs=[X, E], outputs=output)\n```\n\n#### Further layers and features\n\nThe [documentation](https://leviborodenko.github.io/dgcnn/) contains information on how to use the internal `SortPooling`, `GraphConvolution` and `AttentionMechanism` layers and also describes more optional parameters like regularisers, initialisers and constrains that can be used.\n\n### Contribute\nBug reports, fixes and additional features are always welcome! Make sure to run the tests with `python setup.py test` and write your own for new features. Thanks.", "description_content_type": "text/markdown; charset=UTF-8", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/LeviBorodenko/dgcnn", "keywords": "", "license": "mit", "maintainer": "", "maintainer_email": "", "name": "dgcnn", "package_url": "https://pypi.org/project/dgcnn/", "platform": "any", "project_url": "https://pypi.org/project/dgcnn/", "project_urls": {"Documentation": "https://dgcnn.readthedocs.io/", "Homepage": "https://github.com/LeviBorodenko/dgcnn"}, "release_url": "https://pypi.org/project/dgcnn/0.3.2/", "requires_dist": null, "requires_python": "", "summary": "TensorFlow 2 implementation of Deep Graph Convolutional Neural Networks.", "version": "0.3.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DGCNN [TensorFlow]</h1>\n<p>TensorFlow 2 implementation of <em>An end-to-end deep learning architecture for graph classification</em> based on work by <a href=\"https://www.cse.wustl.edu/%7Emuhan/papers/AAAI_2018_DGCNN.pdf\" rel=\"nofollow\">M. Zhang et al., 2018</a>.</p>\n<p>Moreover, we offer an attention based modification of the above by utilising graph attention <a href=\"https://arxiv.org/abs/1710.10903\" rel=\"nofollow\">(Veli\u010dkovi\u0107 et al., 2017)</a> to learn edge weights.</p>\n<h3>Installation</h3>\n<p>Simply run <code>pip install dgcnn</code>. The only dependency is <code>tensorflow&gt;=2.0.0</code>.</p>\n<h3>Usage</h3>\n<p>The core data structure is the <em>graph signal</em>. If we have N nodes in a graph each having C observed features then the graph signal is the tensor with shape (batch, N, C) corresponding to the data produced by all nodes. Often we have sequences of graph signals in a time series. We will call them <em>temporal</em> graph signals and assume a shape of (batch, time steps, N, C).\nFor each graph signal we also need to have the corresponding adjacency matrices of shape (batch, N, N) or (batch, timesteps, N, N) for temporal and non-temporal data, respectively. While DGCNNs can operate on graphs with different node-counts, C should always be the same and each batch should only contain graphs with the same number of nodes.</p>\n<h4>The <code>DeepGraphConvolution</code> Layer</h4>\n<p>This adaptable layer contains the whole DGCNN architecture and operates on both temporal and non-temporal data. It takes the graph signals and their corresponding adjacency matrices and performs the following steps (as described in the paper):</p>\n<p>We initialize the layer by providing  <a href=\"https://www.codecogs.com/eqnedit.php?latex=k,&amp;space;c_1,&amp;space;%5Cdots,&amp;space;c_h&amp;space;%5Cin&amp;space;%5Cmathbb%7BN%7D\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/daea3070ec75bb1ced6d9e61b62fa79a6a1e50f4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6b2c2673706163653b635f312c2673706163653b5c646f74732c2673706163653b635f682673706163653b5c696e2673706163653b5c6d61746862627b4e7d\"></a>. The layer has many optional parameters that are described in the table below.</p>\n<ol>\n<li>\n<p>It iteratively applies <code>GraphConvolution</code> layers h times with variable hidden feature dimensions <a href=\"https://www.codecogs.com/eqnedit.php?latex=c_i\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/14336eb39764c5918435b3c7671953977a92ad6f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f635f69\"></a>.</p>\n</li>\n<li>\n<p>After that, it concatenates all the outputs of the graph convolutions into one tensor which has the shape (..., N, <a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Csum_%7Bi&amp;space;=&amp;space;1%7D%5Ehc_i\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e558b0c98c614ee01f1afe5534b39123b20e1d01/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5c73756d5f7b692673706163653b3d2673706163653b317d5e68635f69\"></a>).</p>\n</li>\n<li>\n<p>Finally it applies <code>SortPooling</code> as described in the paper to obtain the output tensor of shape (..., k, <a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Csum_%7Bi&amp;space;=&amp;space;1%7D%5Ehc_i\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e558b0c98c614ee01f1afe5534b39123b20e1d01/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5c73756d5f7b692673706163653b3d2673706163653b317d5e68635f69\"></a>).</p>\n</li>\n</ol>\n<p>Import this layer with <code>from gdcnn.components import DeepGraphConvolution</code>.</p>\n<p>Initiated it with the following parameters:</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Parameter</th>\n<th align=\"left\">Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\"><code>hidden_conv_units</code> (required)</td>\n<td align=\"left\">List of the hidden feature dimensions used in the graph convolutions. <a href=\"https://www.codecogs.com/eqnedit.php?latex=k,&amp;space;c_1,&amp;space;%5Cdots,&amp;space;c_h&amp;space;%5Cin&amp;space;%5Cmathbb%7BN%7D\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6bcd4038252410bbac6983b63a6af45833a36323/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f635f312c2673706163653b5c646f74732c2673706163653b635f68\"></a> in the paper.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>k</code> (required)</td>\n<td align=\"left\">Number of nodes to be kept after SortPooling.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>flatten_signals</code> (default: False)</td>\n<td align=\"left\">If <code>True</code>, flattens the last 2 dimensions of the output tensor into 1</td>\n</tr>\n<tr>\n<td align=\"left\"><code>attention_heads</code> (default: None)</td>\n<td align=\"left\">If given, then instead of using <a href=\"https://www.codecogs.com/eqnedit.php?latex=D%5E%7B-1%7DE\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/67db25e055871e099a9f153a6c80bd118532ff77/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445e7b2d317d45\"></a> as the transition matrix inside the graph convolutions, we will use an attention based transition matrix. Utilizing <code>dgcnn.attention.AttentionMechanism</code> as the internal attention mechanism. This sets the number of attention heads used.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>attention_units</code> (default: None)</td>\n<td align=\"left\">Also needs to be provided if <code>attention_heads</code> is set. This is the size of the internal embedding used by the attention mechanism.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>use_sortpooling</code> (default: True)</td>\n<td align=\"left\">Whether or not to apply sortpooling at the end of the procedure. If False, we will simply return the concatinated graph convolution outputs.</td>\n</tr></tbody></table>\n<p>Thus, if we have non-temporal graph signals with 10 nodes and 5 features each and we would like to apply a DGCNN containing 3 graph convolutions with hidden feature dimensions of 10, 5 and 2 and SortPooling that keeps the 5 most relevant nodes. Then we would run</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dgcnn.components</span> <span class=\"kn\">import</span> <span class=\"n\">DeepGraphConvolution</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tensorflow.keras.layers</span> <span class=\"kn\">import</span> <span class=\"n\">Input</span>\n<span class=\"kn\">from</span> <span class=\"nn\">tensorflow.keras</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n\n\n<span class=\"c1\"># generating random graph signals as test data</span>\n<span class=\"n\">graph_signal</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># corresponding fully connected adjacency matrices</span>\n<span class=\"n\">adjacency</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">((</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># inputs to the DGCNN</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"graph_signal\"</span><span class=\"p\">)</span>\n<span class=\"n\">E</span> <span class=\"o\">=</span> <span class=\"n\">Input</span><span class=\"p\">(</span><span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s2\">\"adjacency\"</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># DGCNN</span>\n<span class=\"c1\"># Note that we pass the signals and adjacencies as a tuple.</span>\n<span class=\"c1\"># The graph signal always goes first!</span>\n<span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">DeepGraphConvolution</span><span class=\"p\">([</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">5</span> <span class=\"p\">)((</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">E</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># defining model</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">E</span><span class=\"p\">],</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"n\">output</span><span class=\"p\">)</span>\n</pre>\n<h4>Further layers and features</h4>\n<p>The <a href=\"https://leviborodenko.github.io/dgcnn/\" rel=\"nofollow\">documentation</a> contains information on how to use the internal <code>SortPooling</code>, <code>GraphConvolution</code> and <code>AttentionMechanism</code> layers and also describes more optional parameters like regularisers, initialisers and constrains that can be used.</p>\n<h3>Contribute</h3>\n<p>Bug reports, fixes and additional features are always welcome! Make sure to run the tests with <code>python setup.py test</code> and write your own for new features. Thanks.</p>\n\n          </div>"}, "last_serial": 6558874, "releases": {"0.3": [{"comment_text": "", "digests": {"md5": "c2568ab4bd9f5937938f7db1c722c4ef", "sha256": "b14f121e7eea0eee4ccb63a0cb5ab02d94c6f7082324592614945fe95212f62c"}, "downloads": -1, "filename": "dgcnn-0.3.tar.gz", "has_sig": false, "md5_digest": "c2568ab4bd9f5937938f7db1c722c4ef", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20878, "upload_time": "2020-01-25T19:27:51", "upload_time_iso_8601": "2020-01-25T19:27:51.972030Z", "url": "https://files.pythonhosted.org/packages/39/9c/dcf6f76aa3636a00a4c21917cb451b3d9e6c18081d7f1d9e95208fb0d303/dgcnn-0.3.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "a6d19e53cc40167ef9afd99896d20995", "sha256": "f368b708199eba6a1074f20dfcc4be804e320a3039753b080c79c82410fbda5a"}, "downloads": -1, "filename": "dgcnn-0.3.1.tar.gz", "has_sig": false, "md5_digest": "a6d19e53cc40167ef9afd99896d20995", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21306, "upload_time": "2020-01-27T11:13:12", "upload_time_iso_8601": "2020-01-27T11:13:12.032726Z", "url": "https://files.pythonhosted.org/packages/5f/35/ee00cbedabbf1069ac4409063a794d13fdfe48f1d24887ae6dafadd50aa7/dgcnn-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "39d365107d1e11e3124307c60663bbbd", "sha256": "7ff8a3bca17c2e4e4f8ae89413db39ac7b811e1576e9e81199813b039405b5c4"}, "downloads": -1, "filename": "dgcnn-0.3.2.tar.gz", "has_sig": false, "md5_digest": "39d365107d1e11e3124307c60663bbbd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21460, "upload_time": "2020-02-02T17:00:08", "upload_time_iso_8601": "2020-02-02T17:00:08.707036Z", "url": "https://files.pythonhosted.org/packages/ee/d8/b0ae1cb02e323d2619c9e358db98700ee5f3cc8a306318bbcc72d486d6f1/dgcnn-0.3.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "39d365107d1e11e3124307c60663bbbd", "sha256": "7ff8a3bca17c2e4e4f8ae89413db39ac7b811e1576e9e81199813b039405b5c4"}, "downloads": -1, "filename": "dgcnn-0.3.2.tar.gz", "has_sig": false, "md5_digest": "39d365107d1e11e3124307c60663bbbd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21460, "upload_time": "2020-02-02T17:00:08", "upload_time_iso_8601": "2020-02-02T17:00:08.707036Z", "url": "https://files.pythonhosted.org/packages/ee/d8/b0ae1cb02e323d2619c9e358db98700ee5f3cc8a306318bbcc72d486d6f1/dgcnn-0.3.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:38:44 2020"}