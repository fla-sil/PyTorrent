{"info": {"author": "Geoffrey Yu", "author_email": "gxyu@cs.toronto.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3 :: Only", "Topic :: Software Development :: Debuggers"], "description": "![Skyline for Atom](https://raw.githubusercontent.com/geoffxy/skyline-atom/master/assets/skyline-wordmark.png)\n\n-------------------------------------------------------------------------------\n\nSkyline is a tool used with [Atom](https://atom.io) to profile, visualize, and\ndebug the training performance of [PyTorch](https://pytorch.org) neural\nnetworks.\n\n**Note:** Skyline is still under active development and should be considered an\n\"alpha\" product. Its usage and system requirements are subject to change\nbetween versions. See [Versioning](#versioning) for more details.\n\n- [Installing Skyline](#installing-skyline)\n- [Getting Started](#getting-started)\n- [Providers in Detail](#providers-in-detail)\n- [Versioning](#versioning)\n- [Authors](#authors)\n\n-------------------------------------------------------------------------------\n\n<h2 id=\"installing-skyline\">Installing Skyline</h2>\n\n### Requirements\n\nSkyline works with GPU-based neural networks that are implemented in PyTorch.\nTo run Skyline, you need:\n\n- A system equipped with an NVIDIA GPU\n- PyTorch 1.1.0+\n- Python 3.6+\n\nSkyline is currently only supported on Ubuntu 18.04. It should also work on\nother Ubuntu versions that can run Atom and that have Python 3.6+.\n\n\n### Installation\n\nSkyline consists of two components: a command line tool and an Atom plugin\n(this repository). Both components must be installed to use Skyline. They can\nbe installed using `pip` and `apm`:\n\n```\npip install skyline-cli\napm install skyline\n```\n\nAfter installing Skyline, you will be able to invoke the command line tool by\nrunning `skyline` in your shell.\n\n\n<h2 id=\"getting-started\">Getting Started</h2>\n\nTo use Skyline in your project, you need to first write an *entry point file*,\nwhich is a regular Python file that describes how your model is created and\ntrained. See the [Entry Point](#entry-point) section for more information.\n\nOnce your entry point file is ready, navigate to your project's *root\ndirectory* and run:\n\n```\nskyline interactive path/to/entry/point/file\n```\n\nThen, open up Atom, execute the `Skyline:Toggle` command in the command palette\n(Ctrl-Shift-P), and hit the \"Connect\" button that appears on the right.\n\nTo shutdown Skyline, just execute the `Skyline:Toggle` command again in the\ncommand palette. You can shutdown the interactive profiling session on the\ncommand line by hitting Ctrl-C in your terminal.\n\nYou can also toggle the Skyline through the Atom menus: Packages > Skyline >\nShow/Hide Skyline.\n\n**Important:** To analyze your model, Skyline will actually run your code. This\nmeans that when you invoke `skyline interactive`, you need to make sure that\nyour shell has the proper environments activated (if needed). For example if\nyou use `virtualenv` to manage your model's dependencies, you need to activate\nyour `virtualenv` before starting Skyline.\n\n**Usage Statistics:** Skyline collects usage statistics in order to help us\nmake improvements to the tool. If you do not want Skyline to collect usage\nstatistics, you can disable this functionality through Skyline's package\nsettings in Atom (Atom > Settings/Preferences > Packages > Skyline > Settings).\n\n\n### Projects\n\nTo use Skyline, all of the code that you want to profile interactively must be\nstored under one common directory. Generally, this just means you need to keep\nyour own source code under one common directory. Skyline considers all the\nfiles inside this common directory to be part of a *project*, and calls this\ncommon directory your project's *root directory*.\n\nWhen starting a Skyline interactive profiling session, you must invoke `skyline\ninteractive <entry point>` inside your project's *root directory*.\n\n\n<h3 id=\"entry-point\">Entry Point</h3>\n\nSkyline uses an *entry point* file to learn how to create and train your model.\nAn entry point file is a regular Python file that contains three top-level\nfunctions:\n\n- `skyline_model_provider`\n- `skyline_input_provider`\n- `skyline_iteration_provider`\n\nThese three functions are called *providers* and must be defined with specific\nsignatures. The easiest way to understand how to write the providers is to read\nthrough an example.\n\n\n### Example\n\nSuppose that your project code is kept under a `my_project` directory:\n\n```\nmy_project\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 model.py\n```\n\nand your model is defined in `model.py`:\n\n```python\nimport torch.nn as nn\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3)\n        self.linear = nn.Linear(in_features=387096, out_features=10)\n\n    def forward(self, input):\n        out = self.conv(input)\n        return self.linear(out.view(-1, 387096))\n```\n\nOne way to write the *entry point* file would be:\n\n```python\nimport torch\nimport torch.nn as nn\n\nfrom my_project.model import Model\n\n\nclass ModelWithLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = Model()\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, input, target):\n        output = self.model(input)\n        return self.loss_fn(output, target)\n\n\ndef skyline_model_provider():\n    # Return a GPU-based instance of our model (that returns a loss)\n    return ModelWithLoss().cuda()\n\n\ndef skyline_input_provider(batch_size=32):\n    # Return GPU-based inputs for our model\n    return (\n      torch.randn((batch_size, 3, 256, 256)).cuda(),\n      torch.randint(low=0, high=9, size=(batch_size,)).cuda(),\n    )\n\n\ndef skyline_iteration_provider(model):\n    # Return a function that executes one training iteration\n    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n    def iteration(*inputs):\n        optimizer.zero_grad()\n        out = model(*inputs)\n        out.backward()\n        optimizer.step()\n    return iteration\n```\n\nOne important thing to highlight is our use of a wrapper `ModelWithLoss`\nmodule. Since Skyline needs to be able to call `.backwards()` directly on the\noutput tensor of our model, we need to use this wrapper module to compute and\nreturn the loss of our model's output with respect to the targets (i.e. the\nlabels). We also include the targets as inputs to our wrapped module and in our\ninput provider.\n\nYou can place these *provider* functions either in a new file or directly in\n`model.py`. Whichever file contains the providers will be your project's *entry\npoint file*. In this example, suppose that we defined the providers in a\nseparate file called `entry_point.py` inside `my_project`.\n\nSuppose that `my_project` is in your home directory. To launch Skyline you\nwould run (in your shell):\n\n```\ncd ~/my_project\nskyline interactive entry_point.py\n```\n\n\n<h2 id=\"providers-in-detail\">Providers in Detail</h2>\n\n### Model Provider\n\n```python\ndef skyline_model_provider() -> torch.nn.Module:\n    pass\n```\n\nThe model provider must take no arguments and return an instance of your model\n(a `torch.nn.Module`) that is on the GPU (i.e. you need to call `.cuda()` on\nthe module before returning it).\n\n**Important:** Your model must return a tensor on which `.backward()` can be\ncalled. Generally this means that the `torch.nn.Module` you return must compute\nthe loss with respect to the inputs passed into the model.\n\n\n### Input Provider\n\n```python\ndef skyline_input_provider(batch_size: int = 32) -> Tuple:\n    pass\n```\n\nThe input provider must take a single `batch_size` argument that has a default\nvalue (the batch size you want to profile with). It must return an iterable\n(does not *have* to be a `tuple`) that contains the arguments that you would\nnormally pass to your model's `forward` method. Any `Tensor`s in the returned\niterable must be on the GPU (i.e. you need to call `.cuda()` on them before\nreturning them).\n\n\n### Iteration Provider\n\n```python\ndef skyline_iteration_provider(model: torch.nn.Module) -> Callable:\n    pass\n```\n\nThe iteration provider must take a single `model` argument, which will be an\ninstance of your model. This provider must return a callable (e.g., a function)\nthat, when invoked, runs a single training iteration.\n\n\n<h2 id=\"versioning\">Versioning</h2>\n\nSkyline uses semantic versioning. Before the 1.0.0 release, backwards\ncompatibility between minor versions will not be guaranteed.\n\nThe Skyline command line tool and plugin use *independent* version numbers.\nHowever, it is very likely that minor and major versions of the command line\ntool and plugin will be released together (and hence share major/minor version\nnumbers).\n\nGenerally speaking, the most recent version of the command line tool and plugin\nwill be compatible with each other.\n\n\n<h2 id=\"authors\">Authors</h2>\n\nGeoffrey Yu <gxyu@cs.toronto.edu>\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "neural networks,pytorch,interactive,performance,visualization,profiler,debugger", "license": "Apache-2.0", "maintainer": "Geoffrey Yu", "maintainer_email": "gxyu@cs.toronto.edu", "name": "skyline-cli", "package_url": "https://pypi.org/project/skyline-cli/", "platform": "", "project_url": "https://pypi.org/project/skyline-cli/", "project_urls": null, "release_url": "https://pypi.org/project/skyline-cli/0.4.0/", "requires_dist": ["pyyaml", "nvidia-ml-py3", "protobuf", "numpy", "torch (>=1.1.0)"], "requires_python": ">=3.6", "summary": "Interactive in-editor performance profiling, visualization, and debugging for PyTorch neural networks.", "version": "0.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"Skyline for Atom\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/18b94a1c7e385a98269ce0edacf3878835095d4a/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f67656f666678792f736b796c696e652d61746f6d2f6d61737465722f6173736574732f736b796c696e652d776f72646d61726b2e706e67\"></p>\n<hr>\n<p>Skyline is a tool used with <a href=\"https://atom.io\" rel=\"nofollow\">Atom</a> to profile, visualize, and\ndebug the training performance of <a href=\"https://pytorch.org\" rel=\"nofollow\">PyTorch</a> neural\nnetworks.</p>\n<p><strong>Note:</strong> Skyline is still under active development and should be considered an\n\"alpha\" product. Its usage and system requirements are subject to change\nbetween versions. See <a href=\"#versioning\" rel=\"nofollow\">Versioning</a> for more details.</p>\n<ul>\n<li><a href=\"#installing-skyline\" rel=\"nofollow\">Installing Skyline</a></li>\n<li><a href=\"#getting-started\" rel=\"nofollow\">Getting Started</a></li>\n<li><a href=\"#providers-in-detail\" rel=\"nofollow\">Providers in Detail</a></li>\n<li><a href=\"#versioning\" rel=\"nofollow\">Versioning</a></li>\n<li><a href=\"#authors\" rel=\"nofollow\">Authors</a></li>\n</ul>\n<hr>\n<h2 id=\"installing-skyline\">Installing Skyline</h2>\n<h3>Requirements</h3>\n<p>Skyline works with GPU-based neural networks that are implemented in PyTorch.\nTo run Skyline, you need:</p>\n<ul>\n<li>A system equipped with an NVIDIA GPU</li>\n<li>PyTorch 1.1.0+</li>\n<li>Python 3.6+</li>\n</ul>\n<p>Skyline is currently only supported on Ubuntu 18.04. It should also work on\nother Ubuntu versions that can run Atom and that have Python 3.6+.</p>\n<h3>Installation</h3>\n<p>Skyline consists of two components: a command line tool and an Atom plugin\n(this repository). Both components must be installed to use Skyline. They can\nbe installed using <code>pip</code> and <code>apm</code>:</p>\n<pre><code>pip install skyline-cli\napm install skyline\n</code></pre>\n<p>After installing Skyline, you will be able to invoke the command line tool by\nrunning <code>skyline</code> in your shell.</p>\n<h2 id=\"getting-started\">Getting Started</h2>\n<p>To use Skyline in your project, you need to first write an <em>entry point file</em>,\nwhich is a regular Python file that describes how your model is created and\ntrained. See the <a href=\"#entry-point\" rel=\"nofollow\">Entry Point</a> section for more information.</p>\n<p>Once your entry point file is ready, navigate to your project's <em>root\ndirectory</em> and run:</p>\n<pre><code>skyline interactive path/to/entry/point/file\n</code></pre>\n<p>Then, open up Atom, execute the <code>Skyline:Toggle</code> command in the command palette\n(Ctrl-Shift-P), and hit the \"Connect\" button that appears on the right.</p>\n<p>To shutdown Skyline, just execute the <code>Skyline:Toggle</code> command again in the\ncommand palette. You can shutdown the interactive profiling session on the\ncommand line by hitting Ctrl-C in your terminal.</p>\n<p>You can also toggle the Skyline through the Atom menus: Packages &gt; Skyline &gt;\nShow/Hide Skyline.</p>\n<p><strong>Important:</strong> To analyze your model, Skyline will actually run your code. This\nmeans that when you invoke <code>skyline interactive</code>, you need to make sure that\nyour shell has the proper environments activated (if needed). For example if\nyou use <code>virtualenv</code> to manage your model's dependencies, you need to activate\nyour <code>virtualenv</code> before starting Skyline.</p>\n<p><strong>Usage Statistics:</strong> Skyline collects usage statistics in order to help us\nmake improvements to the tool. If you do not want Skyline to collect usage\nstatistics, you can disable this functionality through Skyline's package\nsettings in Atom (Atom &gt; Settings/Preferences &gt; Packages &gt; Skyline &gt; Settings).</p>\n<h3>Projects</h3>\n<p>To use Skyline, all of the code that you want to profile interactively must be\nstored under one common directory. Generally, this just means you need to keep\nyour own source code under one common directory. Skyline considers all the\nfiles inside this common directory to be part of a <em>project</em>, and calls this\ncommon directory your project's <em>root directory</em>.</p>\n<p>When starting a Skyline interactive profiling session, you must invoke <code>skyline interactive &lt;entry point&gt;</code> inside your project's <em>root directory</em>.</p>\n<h3 id=\"entry-point\">Entry Point</h3>\n<p>Skyline uses an <em>entry point</em> file to learn how to create and train your model.\nAn entry point file is a regular Python file that contains three top-level\nfunctions:</p>\n<ul>\n<li><code>skyline_model_provider</code></li>\n<li><code>skyline_input_provider</code></li>\n<li><code>skyline_iteration_provider</code></li>\n</ul>\n<p>These three functions are called <em>providers</em> and must be defined with specific\nsignatures. The easiest way to understand how to write the providers is to read\nthrough an example.</p>\n<h3>Example</h3>\n<p>Suppose that your project code is kept under a <code>my_project</code> directory:</p>\n<pre><code>my_project\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 model.py\n</code></pre>\n<p>and your model is defined in <code>model.py</code>:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">Model</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"n\">in_channels</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">out_channels</span><span class=\"o\">=</span><span class=\"mi\">6</span><span class=\"p\">,</span> <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">in_features</span><span class=\"o\">=</span><span class=\"mi\">387096</span><span class=\"p\">,</span> <span class=\"n\">out_features</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"nb\">input</span><span class=\"p\">):</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">linear</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">387096</span><span class=\"p\">))</span>\n</pre>\n<p>One way to write the <em>entry point</em> file would be:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">my_project.model</span> <span class=\"kn\">import</span> <span class=\"n\">Model</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ModelWithLoss</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss_fn</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"nb\">input</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">):</span>\n        <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">model</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss_fn</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">skyline_model_provider</span><span class=\"p\">():</span>\n    <span class=\"c1\"># Return a GPU-based instance of our model (that returns a loss)</span>\n    <span class=\"k\">return</span> <span class=\"n\">ModelWithLoss</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">skyline_input_provider</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Return GPU-based inputs for our model</span>\n    <span class=\"k\">return</span> <span class=\"p\">(</span>\n      <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">((</span><span class=\"n\">batch_size</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">(),</span>\n      <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"n\">low</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">high</span><span class=\"o\">=</span><span class=\"mi\">9</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"p\">,))</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">(),</span>\n    <span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">skyline_iteration_provider</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Return a function that executes one training iteration</span>\n    <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">1e-3</span><span class=\"p\">)</span>\n    <span class=\"k\">def</span> <span class=\"nf\">iteration</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">inputs</span><span class=\"p\">):</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"o\">*</span><span class=\"n\">inputs</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n    <span class=\"k\">return</span> <span class=\"n\">iteration</span>\n</pre>\n<p>One important thing to highlight is our use of a wrapper <code>ModelWithLoss</code>\nmodule. Since Skyline needs to be able to call <code>.backwards()</code> directly on the\noutput tensor of our model, we need to use this wrapper module to compute and\nreturn the loss of our model's output with respect to the targets (i.e. the\nlabels). We also include the targets as inputs to our wrapped module and in our\ninput provider.</p>\n<p>You can place these <em>provider</em> functions either in a new file or directly in\n<code>model.py</code>. Whichever file contains the providers will be your project's <em>entry\npoint file</em>. In this example, suppose that we defined the providers in a\nseparate file called <code>entry_point.py</code> inside <code>my_project</code>.</p>\n<p>Suppose that <code>my_project</code> is in your home directory. To launch Skyline you\nwould run (in your shell):</p>\n<pre><code>cd ~/my_project\nskyline interactive entry_point.py\n</code></pre>\n<h2 id=\"providers-in-detail\">Providers in Detail</h2>\n<h3>Model Provider</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">skyline_model_provider</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">:</span>\n    <span class=\"k\">pass</span>\n</pre>\n<p>The model provider must take no arguments and return an instance of your model\n(a <code>torch.nn.Module</code>) that is on the GPU (i.e. you need to call <code>.cuda()</code> on\nthe module before returning it).</p>\n<p><strong>Important:</strong> Your model must return a tensor on which <code>.backward()</code> can be\ncalled. Generally this means that the <code>torch.nn.Module</code> you return must compute\nthe loss with respect to the inputs passed into the model.</p>\n<h3>Input Provider</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">skyline_input_provider</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Tuple</span><span class=\"p\">:</span>\n    <span class=\"k\">pass</span>\n</pre>\n<p>The input provider must take a single <code>batch_size</code> argument that has a default\nvalue (the batch size you want to profile with). It must return an iterable\n(does not <em>have</em> to be a <code>tuple</code>) that contains the arguments that you would\nnormally pass to your model's <code>forward</code> method. Any <code>Tensor</code>s in the returned\niterable must be on the GPU (i.e. you need to call <code>.cuda()</code> on them before\nreturning them).</p>\n<h3>Iteration Provider</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">skyline_iteration_provider</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Callable</span><span class=\"p\">:</span>\n    <span class=\"k\">pass</span>\n</pre>\n<p>The iteration provider must take a single <code>model</code> argument, which will be an\ninstance of your model. This provider must return a callable (e.g., a function)\nthat, when invoked, runs a single training iteration.</p>\n<h2 id=\"versioning\">Versioning</h2>\n<p>Skyline uses semantic versioning. Before the 1.0.0 release, backwards\ncompatibility between minor versions will not be guaranteed.</p>\n<p>The Skyline command line tool and plugin use <em>independent</em> version numbers.\nHowever, it is very likely that minor and major versions of the command line\ntool and plugin will be released together (and hence share major/minor version\nnumbers).</p>\n<p>Generally speaking, the most recent version of the command line tool and plugin\nwill be compatible with each other.</p>\n<h2 id=\"authors\">Authors</h2>\n<p>Geoffrey Yu <a href=\"mailto:gxyu@cs.toronto.edu\">gxyu@cs.toronto.edu</a></p>\n\n          </div>"}, "last_serial": 6725184, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "79968ef9fa4a49771e45c7a0bb475c36", "sha256": "d04421d115ab2a8df64fa7bb9b6837a5c71cd6df5f371c89c0fe0dc3fbb3ce0b"}, "downloads": -1, "filename": "skyline_cli-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "79968ef9fa4a49771e45c7a0bb475c36", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 48105, "upload_time": "2020-01-07T18:46:59", "upload_time_iso_8601": "2020-01-07T18:46:59.956260Z", "url": "https://files.pythonhosted.org/packages/9a/0f/6b0dd8dfc14bdf246aa6cf0b8a8d17a303057d7e9ad63b526295026bf53a/skyline_cli-0.1.0-py3-none-any.whl", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "f2c148fbad401157001263675c1a177f", "sha256": "de707f57b7926e6bc7bf8c37f9ff73ede208b1dbafb6b33689cb774e918cd542"}, "downloads": -1, "filename": "skyline_cli-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f2c148fbad401157001263675c1a177f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 49490, "upload_time": "2020-01-09T20:04:12", "upload_time_iso_8601": "2020-01-09T20:04:12.774341Z", "url": "https://files.pythonhosted.org/packages/a5/5c/e483dba17ef1365ab476e878407c4c089921c63984c04d326fbd9e42894e/skyline_cli-0.1.1-py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "831f9bd75c6bd591932ae826cdd2e2e4", "sha256": "98a42f405054c64e10a5403d4e58d482305582a0391e1263801a5bb10df7bf37"}, "downloads": -1, "filename": "skyline_cli-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "831f9bd75c6bd591932ae826cdd2e2e4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 59547, "upload_time": "2020-01-25T17:38:10", "upload_time_iso_8601": "2020-01-25T17:38:10.338798Z", "url": "https://files.pythonhosted.org/packages/4e/96/2917f69332dc33a0a1d146adf43e5ced4e7c718162035cc21452b704fbd9/skyline_cli-0.2.0-py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "c319502b82f767d089fbb45e454600e4", "sha256": "b44e13bccdd6fc6f5b0f41b08abf5c21af4aaad9e75dd73eaf88df923034bea0"}, "downloads": -1, "filename": "skyline_cli-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c319502b82f767d089fbb45e454600e4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 60603, "upload_time": "2020-01-29T02:57:49", "upload_time_iso_8601": "2020-01-29T02:57:49.481293Z", "url": "https://files.pythonhosted.org/packages/7c/92/0456298b73fb8eba7c8a733139c556102386fea3444b6d4e9040dd71a653/skyline_cli-0.2.1-py3-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "1d3a3f1a80cdd328e2c7170a9c32f0ef", "sha256": "2a42ec756be34ec8cc261ac031d63990418670acdbcd119689c98e9e26def8ba"}, "downloads": -1, "filename": "skyline_cli-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1d3a3f1a80cdd328e2c7170a9c32f0ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 63994, "upload_time": "2020-02-13T16:11:52", "upload_time_iso_8601": "2020-02-13T16:11:52.914781Z", "url": "https://files.pythonhosted.org/packages/50/da/8fd3c3cd895024b61cb0a4b94fb449210a50132e381b8b3d03364fcf814d/skyline_cli-0.3.0-py3-none-any.whl", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "2d5f2151f004079b34ee2c90ac70b4cb", "sha256": "a6e9f19ebc5a02fe89f15f422b8b85d581599c7305985856488501725a0baf5d"}, "downloads": -1, "filename": "skyline_cli-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2d5f2151f004079b34ee2c90ac70b4cb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 69295, "upload_time": "2020-02-29T17:36:02", "upload_time_iso_8601": "2020-02-29T17:36:02.262299Z", "url": "https://files.pythonhosted.org/packages/58/20/ea500f8d31898a5d84218d8abc193557f425042184fcc9d07904a3bf2dd0/skyline_cli-0.4.0-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2d5f2151f004079b34ee2c90ac70b4cb", "sha256": "a6e9f19ebc5a02fe89f15f422b8b85d581599c7305985856488501725a0baf5d"}, "downloads": -1, "filename": "skyline_cli-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2d5f2151f004079b34ee2c90ac70b4cb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 69295, "upload_time": "2020-02-29T17:36:02", "upload_time_iso_8601": "2020-02-29T17:36:02.262299Z", "url": "https://files.pythonhosted.org/packages/58/20/ea500f8d31898a5d84218d8abc193557f425042184fcc9d07904a3bf2dd0/skyline_cli-0.4.0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:08:48 2020"}