{"info": {"author": "Keith Murray", "author_email": "kmurrayis@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "A Latent Semantic Analysis Library\n==================================\n\nAuthor(s): Keith Murray\n\nContact: kmurrayis@gmail.com\n\nRequirements:\n=============\nPython 2.7.6\n\tStandard Libraries:\n\tos, sys, and math\n\tAdded Libraries:\n\tnumpy, scipy, sklearn\n\nInstallation:\n=============\n```python\npip install lsalib\n```\n\n\nUsage:\n======\nThis library is a termDocMatrix class. \nIt was built to follow the Thesis of Sam Way, found here http://digitalcommons.unl.edu/elecengtheses/42/\n\n```python\n>>> import lsalib\n# To use this, initalize a varible,\n>>> lsa = lsalib.termDocMatrix()\n\n# After this, you can add documents to the matrix. This can be done in a number of ways\n# With Strings:\n>>> lsa.add(\"HELLO WORLD! THE WIND RISES, WE MUST TRY TO LIVE\")\n\n# With Dictionaries (a key:count relationship)\n>>> lsa.add({\"tree\":5, \"apple\":3, \"WORLD\":8, \"planes\":2})\n\n# With lists of strings:\n>>> lsa.add([\"apples\", \"oranges\", \"apples\", \"WORLD\", \"HELLO\"])\n\n# With lists of dictionaries which follow the key:count relationship:\n>>> lsa.add([D1, D2, D3, D4])\n```\n\nIt's important to note that there is no processing done on any of the inputs. \nThis means the inputs are case sensitive, any symbol such as a comma tied to a word will\nalso be included in the term list. \nTherefore \"Apples\", \"apples\", and \"apples,\" are all treated as unique words.\nIf this is undesirable, the strings will need to be preprocessed before lsa.add() is called.\n\nAs each document is added to the matrix, a term frequency weighting is applied. \n\n\n\n\n```python\n# Once all documents are added to the matrix, the inverse document frequency weighting\n# can be called:\n>>> lsa.weight_idf()\n\n# And once that has completed, use lsa.nmf to reduce the weighted term doc matrix \n# to it's basis k components for the terms and documents:\n>>> P, Q = lsa.nmf(5)\n\n# P is the basis vector set for the terms, and has a dimensionality of terms x k,\n# Q is the basis vector set for the documents, and has a dimensionality of docs x k,\n# P x Q.T will yield an approximation of the original term document matrix with a certain error\n\n# This error is stored in lsa.er\n>>> print lsa.er\n```\n\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/CrakeNotSnowman/LatentSemanticAnalysis/tree/master/lsalib", "keywords": null, "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "lsalib", "package_url": "https://pypi.org/project/lsalib/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/lsalib/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/CrakeNotSnowman/LatentSemanticAnalysis/tree/master/lsalib"}, "release_url": "https://pypi.org/project/lsalib/0.10.3/", "requires_dist": null, "requires_python": null, "summary": "Basic Latent Semantic Analysis library", "version": "0.10.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            A Latent Semantic Analysis Library<br>==================================<br><br>Author(s): Keith Murray<br><br>Contact: kmurrayis@gmail.com<br><br>Requirements:<br>=============<br>Python 2.7.6<br>\tStandard Libraries:<br>\tos, sys, and math<br>\tAdded Libraries:<br>\tnumpy, scipy, sklearn<br><br>Installation:<br>=============<br>```python<br>pip install lsalib<br>```<br><br><br>Usage:<br>======<br>This library is a termDocMatrix class. <br>It was built to follow the Thesis of Sam Way, found here http://digitalcommons.unl.edu/elecengtheses/42/<br><br>```python<br>&gt;&gt;&gt; import lsalib<br># To use this, initalize a varible,<br>&gt;&gt;&gt; lsa = lsalib.termDocMatrix()<br><br># After this, you can add documents to the matrix. This can be done in a number of ways<br># With Strings:<br>&gt;&gt;&gt; lsa.add(\"HELLO WORLD! THE WIND RISES, WE MUST TRY TO LIVE\")<br><br># With Dictionaries (a key:count relationship)<br>&gt;&gt;&gt; lsa.add({\"tree\":5, \"apple\":3, \"WORLD\":8, \"planes\":2})<br><br># With lists of strings:<br>&gt;&gt;&gt; lsa.add([\"apples\", \"oranges\", \"apples\", \"WORLD\", \"HELLO\"])<br><br># With lists of dictionaries which follow the key:count relationship:<br>&gt;&gt;&gt; lsa.add([D1, D2, D3, D4])<br>```<br><br>It's important to note that there is no processing done on any of the inputs. <br>This means the inputs are case sensitive, any symbol such as a comma tied to a word will<br>also be included in the term list. <br>Therefore \"Apples\", \"apples\", and \"apples,\" are all treated as unique words.<br>If this is undesirable, the strings will need to be preprocessed before lsa.add() is called.<br><br>As each document is added to the matrix, a term frequency weighting is applied. <br><br><br><br><br>```python<br># Once all documents are added to the matrix, the inverse document frequency weighting<br># can be called:<br>&gt;&gt;&gt; lsa.weight_idf()<br><br># And once that has completed, use lsa.nmf to reduce the weighted term doc matrix <br># to it's basis k components for the terms and documents:<br>&gt;&gt;&gt; P, Q = lsa.nmf(5)<br><br># P is the basis vector set for the terms, and has a dimensionality of terms x k,<br># Q is the basis vector set for the documents, and has a dimensionality of docs x k,<br># P x Q.T will yield an approximation of the original term document matrix with a certain error<br><br># This error is stored in lsa.er<br>&gt;&gt;&gt; print lsa.er<br>```<br><br>\n          </div>"}, "last_serial": 1790712, "releases": {"0.10": [{"comment_text": "", "digests": {"md5": "e1b682614d3301f9def664b489790581", "sha256": "b15861933da871216a57d9801501a6214b8203b4f1a9a6ee28a967932aad666a"}, "downloads": -1, "filename": "lsalib-0.10.tar.gz", "has_sig": false, "md5_digest": "e1b682614d3301f9def664b489790581", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3378, "upload_time": "2015-10-28T15:39:20", "upload_time_iso_8601": "2015-10-28T15:39:20.415317Z", "url": "https://files.pythonhosted.org/packages/4c/81/945126ce676406b4319ef26264127df24ed64980d39d0c4dc9078e926f15/lsalib-0.10.tar.gz", "yanked": false}], "0.10.1": [{"comment_text": "", "digests": {"md5": "d0d9fae5b703590849577f935b46793c", "sha256": "c4ae2afe9f03c116889e0a628bbc9935ff06b665a5905dc9442944a8ab85c449"}, "downloads": -1, "filename": "lsalib-0.10.1.tar.gz", "has_sig": false, "md5_digest": "d0d9fae5b703590849577f935b46793c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4379, "upload_time": "2015-10-28T19:34:10", "upload_time_iso_8601": "2015-10-28T19:34:10.414147Z", "url": "https://files.pythonhosted.org/packages/46/93/128e105f6e5c52658c34dca4ff99ed711464213f00c255d1d8e8667a1b0e/lsalib-0.10.1.tar.gz", "yanked": false}], "0.10.2": [{"comment_text": "", "digests": {"md5": "cbbcf449428425da0872de7a55981083", "sha256": "b868e4eea477172d6ea6dcfee925415d36897d93e02abe9dc6a6ea31b1928508"}, "downloads": -1, "filename": "lsalib-0.10.2.tar.gz", "has_sig": false, "md5_digest": "cbbcf449428425da0872de7a55981083", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4417, "upload_time": "2015-10-28T19:41:46", "upload_time_iso_8601": "2015-10-28T19:41:46.591572Z", "url": "https://files.pythonhosted.org/packages/ac/60/372f58865eb922339e07970feed294107bc1721f1a72e852eaca4176e289/lsalib-0.10.2.tar.gz", "yanked": false}], "0.10.3": [{"comment_text": "", "digests": {"md5": "5de242ac12ae57418892b22c7729d362", "sha256": "c5ffba23af637ab4e0e769580dcae3f5629d04868d6f3635103bf0233c926576"}, "downloads": -1, "filename": "lsalib-0.10.3.tar.gz", "has_sig": false, "md5_digest": "5de242ac12ae57418892b22c7729d362", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4442, "upload_time": "2015-10-28T19:57:39", "upload_time_iso_8601": "2015-10-28T19:57:39.583573Z", "url": "https://files.pythonhosted.org/packages/32/bc/4612ba38d4ec5267ec98f1926755750439669f797036e859b8300ae61a20/lsalib-0.10.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5de242ac12ae57418892b22c7729d362", "sha256": "c5ffba23af637ab4e0e769580dcae3f5629d04868d6f3635103bf0233c926576"}, "downloads": -1, "filename": "lsalib-0.10.3.tar.gz", "has_sig": false, "md5_digest": "5de242ac12ae57418892b22c7729d362", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4442, "upload_time": "2015-10-28T19:57:39", "upload_time_iso_8601": "2015-10-28T19:57:39.583573Z", "url": "https://files.pythonhosted.org/packages/32/bc/4612ba38d4ec5267ec98f1926755750439669f797036e859b8300ae61a20/lsalib-0.10.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:30 2020"}