{"info": {"author": "British Antarctic Survey", "author_email": "webapps@bas.ac.uk", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: Other/Proprietary License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Software Development :: Libraries"], "description": "# BAS Metadata Library\n\nPython library for generating metadata records.\n\n## Purpose\n\nThis library is designed to assist in generating metadata records for the discovery of datasets. As a library, this \npackage is intended to be embedded within other tools and services, to avoid the need to implement \nthe complexity and verbosity of specific metadata standards.\n\nThis library is built around the needs of the British Antarctic Survey and NERC Polar Data Centre. This means only \nstandards, and elements of these standards, used by BAS or the UK PDC are supported. Additions that would enable this\nlibrary to be useful to others are welcome as contributions.\n\n### Supported standards\n\n| Standard                                             | Implementation                                       | Library Namespace                             | Introduced In                                                                                    |\n| ---------------------------------------------------- | ---------------------------------------------------- | --------------------------------------------- | ------------------------------------------------------------------------------------------------ |\n| [ISO 19115](https://www.iso.org/standard/26020.html) | [ISO 19139](https://www.iso.org/standard/32557.html) | `bas_metadata_library.standards.iso_19115_v1` | [#46](https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues/46) |\n\n### Supported profiles\n\n| Standard  | Profile                                    | Implementation                                                               | Library Namespace                                                          | Introduced In                                                                                    |\n| --------- | ------------------------------------------ | ---------------------------------------------------------------------------- | -------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ |\n| ISO 19115 | [EU Inspire](https://inspire.ec.europa.eu) | [UK Gemini](https://www.agi.org.uk/agi-groups/standards-committee/uk-gemini) | `bas_metadata_library.standards.iso_19115_v1.profiles.inspire_v1_3`        | [#40](https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues/40) |\n| ISO 19115 | UK Polar Data Centre Discovery Metadata    | -                                                                            | `bas_metadata_library.standards.iso_19115_v1.profiles.uk_pdc_discovery_v1` | [#45](https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues/45) |\n\n## Installation\n\nThis package can be installed using Pip from [PyPi](https://pypi.org/project/bas-metadata-library):\n\n```\n$ pip install bas-metadata-library\n```\n\n## Usage\n\nTo generate an ISO 19115 metadata record and return it as an XML document:\n\n```python\nimport metadata_configs\n\nfrom bas_metadata_library.standards.iso_19115_v1 import MetadataRecordConfig as ISO19115MetadataRecordConfig, \\\n    MetadataRecord as ISO19115MetadataRecord\n\nconfiguration_object = metadata_config.record\nconfiguration = ISO19115MetadataRecordConfig(**configuration_object)\n\nrecord = ISO19115MetadataRecord(configuration)\ndocument = record.generate_xml_document()\n\n# output document\nprint(document)\n```\n\nWhere `metadata_configs.record` is a Python dictionary implementing the BAS metadata generic schema, documented in the\n[BAS Metadata Standards](https://metadata-standards.data.bas.ac.uk) project.\n\n### HTML entities\n\nDo not include HTML entities in input to this generator, as it will be douple escaped by [Lxml](https://lxml.de), the \nunderlying XML processing library.\n\nThis means `&gt;`, the HTML entity for `>`, will be escaped again to `&amp;gt;` which will not be correctly \ninterpreted when decoded. Instead the literal character should be used (e.g. `>`), which Lxml will escape if needed.\n\nThis applies to any unicode character, such as accents (e.g. `\u00e5`) and symbols (e.g. `\u00b5`).\n\n## Implementation\n\nThis library consists of a set of base classes for generating XML based metadata records from a configuration object.\n\nEach [supported standard](#supported-standards) implements these classes to generate each supported element within the \nstandard, using values, or computed values, from the configuration object.\n\nThe configuration object is a python dict, the properties and values of which, including if they are required or \ncontrolled, are defined and validated by a [JSON Schema](https://json-schema.org).\n\nThe class for each metadata standard will validate the configuration object against the relevant JSON schema, create a \nXML tree of elements, and exporting the tree as an XML document. XML is generated using [lxml](https://lxml.de).\n\nSee the [development](#development) section for the [base classes](#library-base-classes) used across all standards and \nhow to [add a new standard](#adding-a-new-standard).\n\n## Setup\n\n```shell\n$ git clone https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator.git\n$ cd metadata-generator\n```\n\n### Local development\n\nDocker and Docker Compose are required to setup a local development environment of this application.\n\n#### Local development - Docker Compose\n\nIf you have access to the [BAS GitLab instance](https://gitlab.data.bas.ac.uk), you can pull the application Docker \nimage from the BAS Docker Registry. Otherwise you will need to build the Docker image locally.\n\n```shell\n# If you have access to gitlab.data.bas.ac.uk\n$ docker login docker-registry.data.bas.ac.uk\n$ docker-compose pull\n# If you don't have access\n$ docker-compose build\n```\n\nTo run the application using the Flask development server (which reloads automatically if source files are changed):\n\n```shell\n$ docker-compose up\n```\n\nTo run other commands against the Flask application (such as [Integration tests](#integration-tests)):\n\n```shell\n# in a separate terminal to `docker-compose up`\n$ docker-compose run app flask [command]\n# E.g.\n$ docker-compose run app flask test\n# List all available commands\n$ docker-compose run app flask\n```\n\n### Staging and production\n\nTerraform is used to provision resources required to operate this application in staging and production environments.\n\nThese resources allow [Configuration schemas](#configuration-schemas) for each standard to be accessed externally.\n\nAccess to the [BAS AWS account](https://gitlab.data.bas.ac.uk/WSF/bas-aws) is needed to provisioning these resources.\n\n**Note:** This provisioning should have already been performed (and applies globally). If changes are made to this \nprovisioning it only needs to be applied once.\n\n```shell\n# start terraform inside a docker container\n$ cd provisioning/terraform\n$ docker-compose run terraform\n# setup terraform\n$ terraform init\n# apply changes\n$ terraform validate\n$ terraform fmt\n$ terraform apply\n# exit container\n$ exit\n$ docker-compose down\n```\n\n#### Teraform remote state\n\nState information for this project is stored remotely using a \n[Backend](https://www.terraform.io/docs/backends/index.html).\n\nSpecifically the [AWS S3](https://www.terraform.io/docs/backends/types/s3.html) backend as part of the \n[BAS Terraform Remote State](https://gitlab.data.bas.ac.uk/WSF/terraform-remote-state) project.\n\nRemote state storage will be automatically initialised when running `terraform init`. Any changes to remote state will\nbe automatically saved to the remote backend, there is no need to push or pull changes.\n\n##### Remote state authentication\n\nPermission to read and/or write remote state information for this project is restricted to authorised users. Contact\nthe [BAS Web & Applications Team](mailto:servicedesk@bas.ac.uk) to request access.\n\nSee the [BAS Terraform Remote State](https://gitlab.data.bas.ac.uk/WSF/terraform-remote-state) project for how these\npermissions to remote state are enforced.\n\n## Development\n\nThis API is developed as a Python library. A bundled Flask application is used to simulate its usage and to act as\nframework for running tests etc.\n\n### Library base classes\n\nThe `bas_metadata_library` module defines a series of modules for each standard (in `bas_metadata_library.standards`) \nas well  as *base* classes used across all standards, that providing common functionality. See existing standards for \nhow these are used.\n\n### Configuration schemas\n\nThis library accepts a 'configuration' for each metadata record. This contains values for elements, or values that are \nused to compute values. For example, a *title* element would use a value taken directly from the record configuration.\n\nTo ensure all required configuration attributes are included, and where relevant that their values are allowed, this\nconfiguration is validated against a schema. This schema uses the [JSON Schema](https://json-schema.org) standard.\n\nThese schemas are made available externally through the BAS Metadata Standards website \n[metadata-standards.data.bas.ac.uk](https://metadata-standards.data.bas.ac.uk). This to allow:\n\n1. other applications that wish to ensure their output will be compatible with this library, but that do not or cannot \n  use this library themselves (i.e. if they don't use Python)\n2. to allow schema inheritance/extension where used for standards that inherit from other standards (such as profiles)\n\nA custom Flask CLI command, `output-config-schemas`, is used to generate these schema files from the various standards \nsupported by this project. It will create JSON files for each configuration schema in `build/config_schemas`. These are\nthen uploaded to the Metadata Standards website through [Continuous Deployment](#continuous-deployment).\n\n**Note:** The build directory, and schema's it contains, is ignored in this repository. Outputted schemas are \nconsidered ephemeral and should be trivial to recreate from modules in this library. The module versions of schemas act \nas the source of truth as they are used for performing validation.\n\n### Adding a new standard\n\nTo add a new standard:\n\n1. create a new module in `bas_metadata_library.standards` - e.g. `bas_metadata_library.standards.foo/__init__.py`\n2. in this module overload the `Namespaces`, `MetadataRecordConfig` and `MetadataRecord` classes as needed, ensuring \n   to include a suitable schema property in `MetadataRecordConfig`\n3. define a series of test configurations (e.g. minimal, typical and complete) for generating test records in \n   `tests/config.py`\n4. update the inbuilt Flask application in `app.py` with a route for generating test records for the new standard\n5. use the inbuilt Flask application to generate the test records and save to `tests/resources/records/[standard]`\n6. add relevant [Integration tests](#integration-tests) with methods to test each metadata element class and that the\n   generated record matches the test records saved in `tests/resources/records/[standard]`\n\n### Code Style\n\nPEP-8 style and formatting guidelines must be used for this project, with the exception of the 80 character line limit.\n\n[Flake8](http://flake8.pycqa.org/) is used to ensure compliance, and is ran on each commit through \n[Continuous Integration](#continuous-integration).\n\nTo check compliance locally:\n\n```shell\n$ docker-compose run app flake8 . --ignore=E501\n```\n\n### Dependencies\n\nPython dependencies should be defined using Pip through the `requirements.txt` file. The Docker image is configured to\ninstall these dependencies into the application image for consistency across different environments. Dependencies should\nbe periodically reviewed and updated as new versions are released.\n\nTo add a new dependency:\n\n```shell\n$ docker-compose run app ash\n$ pip install [dependency]==\n# this will display a list of available versions, add the latest to `requirements.txt`\n$ exit\n$ docker-compose down\n$ docker-compose build\n```\n\nIf you have access to the BAS GitLab instance, push the rebuilt Docker image to the BAS Docker Registry:\n\n```shell\n$ docker login docker-registry.data.bas.ac.uk\n$ docker-compose push\n```\n\n### Dependency vulnerability scanning\n\nTo ensure the security of this API, all dependencies are checked against \n[Snyk](https://app.snyk.io/org/antarctica/project/xxx/history) for vulnerabilities. \n\n**Warning:** Snyk relies on known vulnerabilities and can't check for issues that are not in it's database. As with all \nsecurity tools, Snyk is an aid for spotting common mistakes, not a guarantee of secure code.\n\nSome vulnerabilities have been ignored in this project, see `.snyk` for definitions and the \n[Dependency exceptions](#dependency-vulnerability-exceptions) section for more information.\n\nThrough [Continuous Integration](#continuous-integration), on each commit current dependencies are tested and a snapshot\nuploaded to Snyk. This snapshot is then monitored for vulnerabilities.\n\n#### Dependency vulnerability exceptions\n\nThis project contains known vulnerabilities that have been ignored for a specific reason.\n\n* [Py-Yaml `yaml.load()` function allows Arbitrary Code Execution](https://snyk.io/vuln/SNYK-PYTHON-PYYAML-42159)\n    * currently no known or planned resolution\n    * indirect dependency, required through the `bandit` package\n    * severity is rated *high*\n    * risk judged to be *low* as we don't use the Yaml module in this application\n    * ignored for 1 year for re-review\n\n### Static security scanning\n\nTo ensure the security of this API, source code is checked against [Bandit](https://github.com/PyCQA/bandit) for issues \nsuch as not sanitising user inputs or using weak cryptography. \n\n**Warning:** Bandit is a static analysis tool and can't check for issues that are only be detectable when running the \napplication. As with all security tools, Bandit is an aid for spotting common mistakes, not a guarantee of secure code.\n\nThrough [Continuous Integration](#continuous-integration), each commit is tested.\n\nTo check locally:\n\n```shell\n$ docker-compose run app bandit -r .\n```\n\n### Debugging\n\nTo debug using PyCharm:\n\n* *Run* -> *Edit Configurations*\n* *Add New Configuration* -> *Python*\n\nIn *Configuration* tab:\n\n* Script path: `[absolute path to project]/manage.py`\n* Python interpreter: *Project interpreter* (*app* service in project Docker Compose)\n* Working directory: `[absolute path to project]`\n* Path mappings: `[absolute path to project]=/usr/src/app`\n\n## Testing\n\n### Integration tests\n\nThis project uses integration tests to ensure features work as expected and to guard against regressions and \nvulnerabilities.\n\nTests are written to create metadata records based on a series of configurations defined in `tests/config.py`. These\ndefine 'minimal' to 'complete' test records, intended to test different ways a standard can be used, both for \nindividual elements and whole records.\n\nTest case methods are used to test individual elements. Comparisons against static records are used to test whole \nrecords.\n\nThe Python [UnitTest](https://docs.python.org/3/library/unittest.html) library is used for running tests using Flask's \ntest framework. Test cases are defined in files within `tests/` and are automatically loaded when using the \n`test` Flask CLI command.\n\nTests are automatically ran on each commit through [Continuous Integration](#continuous-integration).\n\nTo run tests manually:\n\n```shell\n$ docker-compose run -e FLASK_ENV=testing app flask test --test-runner text\n```\n\n#### Capturing static test records\n\nTo capture static test records, which verify how records are assembled correctly, a custom Flask CLI command,\n`capture-test-records` is available. This requires the Flask application to first be running. The Requests library is\nused to make requests against application routes and save the response to a relevant directory in \n`tests/resources/records`.\n\n```shell\n# start Flask application\n$ docker-compose up\n# in a separate terminal\n$ docker-compose run app flask capture-test-records\n```\n\nIt is intended that this command will update pre-existing static records, with differences captured in version control\nand reviewed manually to ensure they are correct.\n\n#### PyCharm support\n\nTo run tests using PyCharm:\n\n* *Run* -> *Edit Configurations*\n* *Add New Configuration* -> *Python Tests* -> *Unittests*\n\nIn *Configuration* tab:\n\n* Script path: `[absolute path to project]/tests`\n* Python interpreter: *Project interpreter* (*app* service in project Docker Compose)\n* Working directory: `[absolute path to project]`\n* Path mappings: `[absolute path to project]=/usr/src/app`\n\n**Note:** This configuration can be also be used to debug tests (by choosing *debug* instead of *run*).\n\n#### JUnit support\n\nTo run integration tests to produce a JUnit compatible file, test-results.xml:\n\n```\n$ docker-compose run -e FLASK_ENV=testing app flask test --test-runner junit\n```\n\n### Continuous Integration\n\nAll commits will trigger a Continuous Integration process using GitLab's CI/CD platform, configured in `.gitlab-ci.yml`.\n\nThis process will run the application [Integration tests](#integration-tests).\n\nPip dependencies are also [checked and monitored for vulnerabilities](#dependency-vulnerability-scanning).\n\n## Distribution\n\nBoth source and binary versions of the package are build using [SetupTools](https://setuptools.readthedocs.io), which \ncan then be published to the [Python package index](https://pypi.org/project/bas-metadata-library/) for use in other \napplications. Package settings are defined in `setup.py`.\n\nThis project is built and published to PyPi automatically through [Continuous Deployment](#continuous-deployment).\n\nTo build the source and binary artifact's for this project manually:\n\n```shell\n$ docker-compose run app ash\n# build package to /build, /dist and /bas-metadata-library.egg-info\n$ python setup.py sdist bdist_wheel\n$ exit\n$ docker-compose down\n```\n\nTo publish built artifact's for this project manually to [PyPi testing](https://test.pypi.org):\n\n```shell\n$ docker-compose run app ash\n$ python -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n# project then available at: https://test.pypi.org/project/bas-metadata-library/\n$ exit\n$ docker-compose down\n```\n\nTo publish manually to [PyPi](https://pypi.org):\n\n```shell\n$ docker-compose run app ash\n$ python -m twine upload --repository-url https://pypi.org/legacy/ dist/*\n# project then available at: https://pypi.org/project/bas-metadata-library/\n$ exit\n$ docker-compose down\n```\n\n### Continuous Deployment\n\nA Continuous Deployment process using GitLab's CI/CD platform is configured in `.gitlab-ci.yml`. This will:\n\n* build the source and binary artifact's for this project\n* publish built artifact's for this project to the relevant PyPi repository\n* publish the [JSON Schemas](#configuration-schemas) for this libraries internal configuration format\n\nOn commits to the *master* branch:\n\n* changes will be deployed to [PyPi testing](https://test.pypi.org)\n* configuration schemas will be published to the \n  [Metadata Standards testing](https://metadata-standards-testing.data.bas.ac.uk) website\n\nOn tagged commits:\n\n* changes will be deployed to [PyPi](https://pypi.org)\n* configuration schemas will be published to the [Metadata Standards](https://metadata-standards.data.bas.ac.uk) \n  website\n\n## Release procedure\n\n### At release\n\n1. create a `release` branch\n2. bump version in `setup.py` as per SemVer\n3. close release in `CHANGELOG.md`\n4. push changes, merge the `release` branch into `master` and tag with version\n\nThe project will be built and published to PyPi automatically through [Continuous Deployment](#continuous-deployment).\n\n## Feedback\n\nThe maintainer of this project is the BAS Web & Applications Team, they can be contacted at: \n[servicedesk@bas.ac.uk](mailto:servicedesk@bas.ac.uk).\n\n## Issue tracking\n\nThis project uses issue tracking, see the \n[Issue tracker](https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues) for more \ninformation.\n\n**Note:** Read & write access to this issue tracker is restricted. Contact the project maintainer to request access.\n\n## License\n\n\u00a9 UK Research and Innovation (UKRI), 2019, British Antarctic Survey.\n\nYou may use and re-use this software and associated documentation files free of charge in any format or medium, under \nthe terms of the Open Government Licence v3.0.\n\nYou may obtain a copy of the Open Government Licence at http://www.nationalarchives.gov.uk/doc/open-government-licence/\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/antarctica/metadata-library", "keywords": "", "license": "Open Government Licence v3.0", "maintainer": "", "maintainer_email": "", "name": "bas-metadata-library", "package_url": "https://pypi.org/project/bas-metadata-library/", "platform": "", "project_url": "https://pypi.org/project/bas-metadata-library/", "project_urls": {"Homepage": "https://github.com/antarctica/metadata-library"}, "release_url": "https://pypi.org/project/bas-metadata-library/0.2.2/", "requires_dist": ["jsonschema", "lxml", "rfc3987", "strict-rfc3339", "requests"], "requires_python": "", "summary": "Python library for generating metadata records", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>BAS Metadata Library</h1>\n<p>Python library for generating metadata records.</p>\n<h2>Purpose</h2>\n<p>This library is designed to assist in generating metadata records for the discovery of datasets. As a library, this\npackage is intended to be embedded within other tools and services, to avoid the need to implement\nthe complexity and verbosity of specific metadata standards.</p>\n<p>This library is built around the needs of the British Antarctic Survey and NERC Polar Data Centre. This means only\nstandards, and elements of these standards, used by BAS or the UK PDC are supported. Additions that would enable this\nlibrary to be useful to others are welcome as contributions.</p>\n<h3>Supported standards</h3>\n<table>\n<thead>\n<tr>\n<th>Standard</th>\n<th>Implementation</th>\n<th>Library Namespace</th>\n<th>Introduced In</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://www.iso.org/standard/26020.html\" rel=\"nofollow\">ISO 19115</a></td>\n<td><a href=\"https://www.iso.org/standard/32557.html\" rel=\"nofollow\">ISO 19139</a></td>\n<td><code>bas_metadata_library.standards.iso_19115_v1</code></td>\n<td><a href=\"https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues/46\" rel=\"nofollow\">#46</a></td>\n</tr></tbody></table>\n<h3>Supported profiles</h3>\n<table>\n<thead>\n<tr>\n<th>Standard</th>\n<th>Profile</th>\n<th>Implementation</th>\n<th>Library Namespace</th>\n<th>Introduced In</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ISO 19115</td>\n<td><a href=\"https://inspire.ec.europa.eu\" rel=\"nofollow\">EU Inspire</a></td>\n<td><a href=\"https://www.agi.org.uk/agi-groups/standards-committee/uk-gemini\" rel=\"nofollow\">UK Gemini</a></td>\n<td><code>bas_metadata_library.standards.iso_19115_v1.profiles.inspire_v1_3</code></td>\n<td><a href=\"https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues/40\" rel=\"nofollow\">#40</a></td>\n</tr>\n<tr>\n<td>ISO 19115</td>\n<td>UK Polar Data Centre Discovery Metadata</td>\n<td>-</td>\n<td><code>bas_metadata_library.standards.iso_19115_v1.profiles.uk_pdc_discovery_v1</code></td>\n<td><a href=\"https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues/45\" rel=\"nofollow\">#45</a></td>\n</tr></tbody></table>\n<h2>Installation</h2>\n<p>This package can be installed using Pip from <a href=\"https://pypi.org/project/bas-metadata-library\" rel=\"nofollow\">PyPi</a>:</p>\n<pre><code>$ pip install bas-metadata-library\n</code></pre>\n<h2>Usage</h2>\n<p>To generate an ISO 19115 metadata record and return it as an XML document:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">metadata_configs</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">bas_metadata_library.standards.iso_19115_v1</span> <span class=\"kn\">import</span> <span class=\"n\">MetadataRecordConfig</span> <span class=\"k\">as</span> <span class=\"n\">ISO19115MetadataRecordConfig</span><span class=\"p\">,</span> \\\n    <span class=\"n\">MetadataRecord</span> <span class=\"k\">as</span> <span class=\"n\">ISO19115MetadataRecord</span>\n\n<span class=\"n\">configuration_object</span> <span class=\"o\">=</span> <span class=\"n\">metadata_config</span><span class=\"o\">.</span><span class=\"n\">record</span>\n<span class=\"n\">configuration</span> <span class=\"o\">=</span> <span class=\"n\">ISO19115MetadataRecordConfig</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">configuration_object</span><span class=\"p\">)</span>\n\n<span class=\"n\">record</span> <span class=\"o\">=</span> <span class=\"n\">ISO19115MetadataRecord</span><span class=\"p\">(</span><span class=\"n\">configuration</span><span class=\"p\">)</span>\n<span class=\"n\">document</span> <span class=\"o\">=</span> <span class=\"n\">record</span><span class=\"o\">.</span><span class=\"n\">generate_xml_document</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># output document</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">document</span><span class=\"p\">)</span>\n</pre>\n<p>Where <code>metadata_configs.record</code> is a Python dictionary implementing the BAS metadata generic schema, documented in the\n<a href=\"https://metadata-standards.data.bas.ac.uk\" rel=\"nofollow\">BAS Metadata Standards</a> project.</p>\n<h3>HTML entities</h3>\n<p>Do not include HTML entities in input to this generator, as it will be douple escaped by <a href=\"https://lxml.de\" rel=\"nofollow\">Lxml</a>, the\nunderlying XML processing library.</p>\n<p>This means <code>&amp;gt;</code>, the HTML entity for <code>&gt;</code>, will be escaped again to <code>&amp;amp;gt;</code> which will not be correctly\ninterpreted when decoded. Instead the literal character should be used (e.g. <code>&gt;</code>), which Lxml will escape if needed.</p>\n<p>This applies to any unicode character, such as accents (e.g. <code>\u00e5</code>) and symbols (e.g. <code>\u00b5</code>).</p>\n<h2>Implementation</h2>\n<p>This library consists of a set of base classes for generating XML based metadata records from a configuration object.</p>\n<p>Each <a href=\"#supported-standards\" rel=\"nofollow\">supported standard</a> implements these classes to generate each supported element within the\nstandard, using values, or computed values, from the configuration object.</p>\n<p>The configuration object is a python dict, the properties and values of which, including if they are required or\ncontrolled, are defined and validated by a <a href=\"https://json-schema.org\" rel=\"nofollow\">JSON Schema</a>.</p>\n<p>The class for each metadata standard will validate the configuration object against the relevant JSON schema, create a\nXML tree of elements, and exporting the tree as an XML document. XML is generated using <a href=\"https://lxml.de\" rel=\"nofollow\">lxml</a>.</p>\n<p>See the <a href=\"#development\" rel=\"nofollow\">development</a> section for the <a href=\"#library-base-classes\" rel=\"nofollow\">base classes</a> used across all standards and\nhow to <a href=\"#adding-a-new-standard\" rel=\"nofollow\">add a new standard</a>.</p>\n<h2>Setup</h2>\n<pre>$ git clone https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator.git\n$ <span class=\"nb\">cd</span> metadata-generator\n</pre>\n<h3>Local development</h3>\n<p>Docker and Docker Compose are required to setup a local development environment of this application.</p>\n<h4>Local development - Docker Compose</h4>\n<p>If you have access to the <a href=\"https://gitlab.data.bas.ac.uk\" rel=\"nofollow\">BAS GitLab instance</a>, you can pull the application Docker\nimage from the BAS Docker Registry. Otherwise you will need to build the Docker image locally.</p>\n<pre><span class=\"c1\"># If you have access to gitlab.data.bas.ac.uk</span>\n$ docker login docker-registry.data.bas.ac.uk\n$ docker-compose pull\n<span class=\"c1\"># If you don't have access</span>\n$ docker-compose build\n</pre>\n<p>To run the application using the Flask development server (which reloads automatically if source files are changed):</p>\n<pre>$ docker-compose up\n</pre>\n<p>To run other commands against the Flask application (such as <a href=\"#integration-tests\" rel=\"nofollow\">Integration tests</a>):</p>\n<pre><span class=\"c1\"># in a separate terminal to `docker-compose up`</span>\n$ docker-compose run app flask <span class=\"o\">[</span>command<span class=\"o\">]</span>\n<span class=\"c1\"># E.g.</span>\n$ docker-compose run app flask <span class=\"nb\">test</span>\n<span class=\"c1\"># List all available commands</span>\n$ docker-compose run app flask\n</pre>\n<h3>Staging and production</h3>\n<p>Terraform is used to provision resources required to operate this application in staging and production environments.</p>\n<p>These resources allow <a href=\"#configuration-schemas\" rel=\"nofollow\">Configuration schemas</a> for each standard to be accessed externally.</p>\n<p>Access to the <a href=\"https://gitlab.data.bas.ac.uk/WSF/bas-aws\" rel=\"nofollow\">BAS AWS account</a> is needed to provisioning these resources.</p>\n<p><strong>Note:</strong> This provisioning should have already been performed (and applies globally). If changes are made to this\nprovisioning it only needs to be applied once.</p>\n<pre><span class=\"c1\"># start terraform inside a docker container</span>\n$ <span class=\"nb\">cd</span> provisioning/terraform\n$ docker-compose run terraform\n<span class=\"c1\"># setup terraform</span>\n$ terraform init\n<span class=\"c1\"># apply changes</span>\n$ terraform validate\n$ terraform fmt\n$ terraform apply\n<span class=\"c1\"># exit container</span>\n$ <span class=\"nb\">exit</span>\n$ docker-compose down\n</pre>\n<h4>Teraform remote state</h4>\n<p>State information for this project is stored remotely using a\n<a href=\"https://www.terraform.io/docs/backends/index.html\" rel=\"nofollow\">Backend</a>.</p>\n<p>Specifically the <a href=\"https://www.terraform.io/docs/backends/types/s3.html\" rel=\"nofollow\">AWS S3</a> backend as part of the\n<a href=\"https://gitlab.data.bas.ac.uk/WSF/terraform-remote-state\" rel=\"nofollow\">BAS Terraform Remote State</a> project.</p>\n<p>Remote state storage will be automatically initialised when running <code>terraform init</code>. Any changes to remote state will\nbe automatically saved to the remote backend, there is no need to push or pull changes.</p>\n<h5>Remote state authentication</h5>\n<p>Permission to read and/or write remote state information for this project is restricted to authorised users. Contact\nthe <a href=\"mailto:servicedesk@bas.ac.uk\">BAS Web &amp; Applications Team</a> to request access.</p>\n<p>See the <a href=\"https://gitlab.data.bas.ac.uk/WSF/terraform-remote-state\" rel=\"nofollow\">BAS Terraform Remote State</a> project for how these\npermissions to remote state are enforced.</p>\n<h2>Development</h2>\n<p>This API is developed as a Python library. A bundled Flask application is used to simulate its usage and to act as\nframework for running tests etc.</p>\n<h3>Library base classes</h3>\n<p>The <code>bas_metadata_library</code> module defines a series of modules for each standard (in <code>bas_metadata_library.standards</code>)\nas well  as <em>base</em> classes used across all standards, that providing common functionality. See existing standards for\nhow these are used.</p>\n<h3>Configuration schemas</h3>\n<p>This library accepts a 'configuration' for each metadata record. This contains values for elements, or values that are\nused to compute values. For example, a <em>title</em> element would use a value taken directly from the record configuration.</p>\n<p>To ensure all required configuration attributes are included, and where relevant that their values are allowed, this\nconfiguration is validated against a schema. This schema uses the <a href=\"https://json-schema.org\" rel=\"nofollow\">JSON Schema</a> standard.</p>\n<p>These schemas are made available externally through the BAS Metadata Standards website\n<a href=\"https://metadata-standards.data.bas.ac.uk\" rel=\"nofollow\">metadata-standards.data.bas.ac.uk</a>. This to allow:</p>\n<ol>\n<li>other applications that wish to ensure their output will be compatible with this library, but that do not or cannot\nuse this library themselves (i.e. if they don't use Python)</li>\n<li>to allow schema inheritance/extension where used for standards that inherit from other standards (such as profiles)</li>\n</ol>\n<p>A custom Flask CLI command, <code>output-config-schemas</code>, is used to generate these schema files from the various standards\nsupported by this project. It will create JSON files for each configuration schema in <code>build/config_schemas</code>. These are\nthen uploaded to the Metadata Standards website through <a href=\"#continuous-deployment\" rel=\"nofollow\">Continuous Deployment</a>.</p>\n<p><strong>Note:</strong> The build directory, and schema's it contains, is ignored in this repository. Outputted schemas are\nconsidered ephemeral and should be trivial to recreate from modules in this library. The module versions of schemas act\nas the source of truth as they are used for performing validation.</p>\n<h3>Adding a new standard</h3>\n<p>To add a new standard:</p>\n<ol>\n<li>create a new module in <code>bas_metadata_library.standards</code> - e.g. <code>bas_metadata_library.standards.foo/__init__.py</code></li>\n<li>in this module overload the <code>Namespaces</code>, <code>MetadataRecordConfig</code> and <code>MetadataRecord</code> classes as needed, ensuring\nto include a suitable schema property in <code>MetadataRecordConfig</code></li>\n<li>define a series of test configurations (e.g. minimal, typical and complete) for generating test records in\n<code>tests/config.py</code></li>\n<li>update the inbuilt Flask application in <code>app.py</code> with a route for generating test records for the new standard</li>\n<li>use the inbuilt Flask application to generate the test records and save to <code>tests/resources/records/[standard]</code></li>\n<li>add relevant <a href=\"#integration-tests\" rel=\"nofollow\">Integration tests</a> with methods to test each metadata element class and that the\ngenerated record matches the test records saved in <code>tests/resources/records/[standard]</code></li>\n</ol>\n<h3>Code Style</h3>\n<p>PEP-8 style and formatting guidelines must be used for this project, with the exception of the 80 character line limit.</p>\n<p><a href=\"http://flake8.pycqa.org/\" rel=\"nofollow\">Flake8</a> is used to ensure compliance, and is ran on each commit through\n<a href=\"#continuous-integration\" rel=\"nofollow\">Continuous Integration</a>.</p>\n<p>To check compliance locally:</p>\n<pre>$ docker-compose run app flake8 . --ignore<span class=\"o\">=</span>E501\n</pre>\n<h3>Dependencies</h3>\n<p>Python dependencies should be defined using Pip through the <code>requirements.txt</code> file. The Docker image is configured to\ninstall these dependencies into the application image for consistency across different environments. Dependencies should\nbe periodically reviewed and updated as new versions are released.</p>\n<p>To add a new dependency:</p>\n<pre>$ docker-compose run app ash\n$ pip install <span class=\"o\">[</span>dependency<span class=\"o\">]==</span>\n<span class=\"c1\"># this will display a list of available versions, add the latest to `requirements.txt`</span>\n$ <span class=\"nb\">exit</span>\n$ docker-compose down\n$ docker-compose build\n</pre>\n<p>If you have access to the BAS GitLab instance, push the rebuilt Docker image to the BAS Docker Registry:</p>\n<pre>$ docker login docker-registry.data.bas.ac.uk\n$ docker-compose push\n</pre>\n<h3>Dependency vulnerability scanning</h3>\n<p>To ensure the security of this API, all dependencies are checked against\n<a href=\"https://app.snyk.io/org/antarctica/project/xxx/history\" rel=\"nofollow\">Snyk</a> for vulnerabilities.</p>\n<p><strong>Warning:</strong> Snyk relies on known vulnerabilities and can't check for issues that are not in it's database. As with all\nsecurity tools, Snyk is an aid for spotting common mistakes, not a guarantee of secure code.</p>\n<p>Some vulnerabilities have been ignored in this project, see <code>.snyk</code> for definitions and the\n<a href=\"#dependency-vulnerability-exceptions\" rel=\"nofollow\">Dependency exceptions</a> section for more information.</p>\n<p>Through <a href=\"#continuous-integration\" rel=\"nofollow\">Continuous Integration</a>, on each commit current dependencies are tested and a snapshot\nuploaded to Snyk. This snapshot is then monitored for vulnerabilities.</p>\n<h4>Dependency vulnerability exceptions</h4>\n<p>This project contains known vulnerabilities that have been ignored for a specific reason.</p>\n<ul>\n<li><a href=\"https://snyk.io/vuln/SNYK-PYTHON-PYYAML-42159\" rel=\"nofollow\">Py-Yaml <code>yaml.load()</code> function allows Arbitrary Code Execution</a>\n<ul>\n<li>currently no known or planned resolution</li>\n<li>indirect dependency, required through the <code>bandit</code> package</li>\n<li>severity is rated <em>high</em></li>\n<li>risk judged to be <em>low</em> as we don't use the Yaml module in this application</li>\n<li>ignored for 1 year for re-review</li>\n</ul>\n</li>\n</ul>\n<h3>Static security scanning</h3>\n<p>To ensure the security of this API, source code is checked against <a href=\"https://github.com/PyCQA/bandit\" rel=\"nofollow\">Bandit</a> for issues\nsuch as not sanitising user inputs or using weak cryptography.</p>\n<p><strong>Warning:</strong> Bandit is a static analysis tool and can't check for issues that are only be detectable when running the\napplication. As with all security tools, Bandit is an aid for spotting common mistakes, not a guarantee of secure code.</p>\n<p>Through <a href=\"#continuous-integration\" rel=\"nofollow\">Continuous Integration</a>, each commit is tested.</p>\n<p>To check locally:</p>\n<pre>$ docker-compose run app bandit -r .\n</pre>\n<h3>Debugging</h3>\n<p>To debug using PyCharm:</p>\n<ul>\n<li><em>Run</em> -&gt; <em>Edit Configurations</em></li>\n<li><em>Add New Configuration</em> -&gt; <em>Python</em></li>\n</ul>\n<p>In <em>Configuration</em> tab:</p>\n<ul>\n<li>Script path: <code>[absolute path to project]/manage.py</code></li>\n<li>Python interpreter: <em>Project interpreter</em> (<em>app</em> service in project Docker Compose)</li>\n<li>Working directory: <code>[absolute path to project]</code></li>\n<li>Path mappings: <code>[absolute path to project]=/usr/src/app</code></li>\n</ul>\n<h2>Testing</h2>\n<h3>Integration tests</h3>\n<p>This project uses integration tests to ensure features work as expected and to guard against regressions and\nvulnerabilities.</p>\n<p>Tests are written to create metadata records based on a series of configurations defined in <code>tests/config.py</code>. These\ndefine 'minimal' to 'complete' test records, intended to test different ways a standard can be used, both for\nindividual elements and whole records.</p>\n<p>Test case methods are used to test individual elements. Comparisons against static records are used to test whole\nrecords.</p>\n<p>The Python <a href=\"https://docs.python.org/3/library/unittest.html\" rel=\"nofollow\">UnitTest</a> library is used for running tests using Flask's\ntest framework. Test cases are defined in files within <code>tests/</code> and are automatically loaded when using the\n<code>test</code> Flask CLI command.</p>\n<p>Tests are automatically ran on each commit through <a href=\"#continuous-integration\" rel=\"nofollow\">Continuous Integration</a>.</p>\n<p>To run tests manually:</p>\n<pre>$ docker-compose run -e <span class=\"nv\">FLASK_ENV</span><span class=\"o\">=</span>testing app flask <span class=\"nb\">test</span> --test-runner text\n</pre>\n<h4>Capturing static test records</h4>\n<p>To capture static test records, which verify how records are assembled correctly, a custom Flask CLI command,\n<code>capture-test-records</code> is available. This requires the Flask application to first be running. The Requests library is\nused to make requests against application routes and save the response to a relevant directory in\n<code>tests/resources/records</code>.</p>\n<pre><span class=\"c1\"># start Flask application</span>\n$ docker-compose up\n<span class=\"c1\"># in a separate terminal</span>\n$ docker-compose run app flask capture-test-records\n</pre>\n<p>It is intended that this command will update pre-existing static records, with differences captured in version control\nand reviewed manually to ensure they are correct.</p>\n<h4>PyCharm support</h4>\n<p>To run tests using PyCharm:</p>\n<ul>\n<li><em>Run</em> -&gt; <em>Edit Configurations</em></li>\n<li><em>Add New Configuration</em> -&gt; <em>Python Tests</em> -&gt; <em>Unittests</em></li>\n</ul>\n<p>In <em>Configuration</em> tab:</p>\n<ul>\n<li>Script path: <code>[absolute path to project]/tests</code></li>\n<li>Python interpreter: <em>Project interpreter</em> (<em>app</em> service in project Docker Compose)</li>\n<li>Working directory: <code>[absolute path to project]</code></li>\n<li>Path mappings: <code>[absolute path to project]=/usr/src/app</code></li>\n</ul>\n<p><strong>Note:</strong> This configuration can be also be used to debug tests (by choosing <em>debug</em> instead of <em>run</em>).</p>\n<h4>JUnit support</h4>\n<p>To run integration tests to produce a JUnit compatible file, test-results.xml:</p>\n<pre><code>$ docker-compose run -e FLASK_ENV=testing app flask test --test-runner junit\n</code></pre>\n<h3>Continuous Integration</h3>\n<p>All commits will trigger a Continuous Integration process using GitLab's CI/CD platform, configured in <code>.gitlab-ci.yml</code>.</p>\n<p>This process will run the application <a href=\"#integration-tests\" rel=\"nofollow\">Integration tests</a>.</p>\n<p>Pip dependencies are also <a href=\"#dependency-vulnerability-scanning\" rel=\"nofollow\">checked and monitored for vulnerabilities</a>.</p>\n<h2>Distribution</h2>\n<p>Both source and binary versions of the package are build using <a href=\"https://setuptools.readthedocs.io\" rel=\"nofollow\">SetupTools</a>, which\ncan then be published to the <a href=\"https://pypi.org/project/bas-metadata-library/\" rel=\"nofollow\">Python package index</a> for use in other\napplications. Package settings are defined in <code>setup.py</code>.</p>\n<p>This project is built and published to PyPi automatically through <a href=\"#continuous-deployment\" rel=\"nofollow\">Continuous Deployment</a>.</p>\n<p>To build the source and binary artifact's for this project manually:</p>\n<pre>$ docker-compose run app ash\n<span class=\"c1\"># build package to /build, /dist and /bas-metadata-library.egg-info</span>\n$ python setup.py sdist bdist_wheel\n$ <span class=\"nb\">exit</span>\n$ docker-compose down\n</pre>\n<p>To publish built artifact's for this project manually to <a href=\"https://test.pypi.org\" rel=\"nofollow\">PyPi testing</a>:</p>\n<pre>$ docker-compose run app ash\n$ python -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n<span class=\"c1\"># project then available at: https://test.pypi.org/project/bas-metadata-library/</span>\n$ <span class=\"nb\">exit</span>\n$ docker-compose down\n</pre>\n<p>To publish manually to <a href=\"https://pypi.org\" rel=\"nofollow\">PyPi</a>:</p>\n<pre>$ docker-compose run app ash\n$ python -m twine upload --repository-url https://pypi.org/legacy/ dist/*\n<span class=\"c1\"># project then available at: https://pypi.org/project/bas-metadata-library/</span>\n$ <span class=\"nb\">exit</span>\n$ docker-compose down\n</pre>\n<h3>Continuous Deployment</h3>\n<p>A Continuous Deployment process using GitLab's CI/CD platform is configured in <code>.gitlab-ci.yml</code>. This will:</p>\n<ul>\n<li>build the source and binary artifact's for this project</li>\n<li>publish built artifact's for this project to the relevant PyPi repository</li>\n<li>publish the <a href=\"#configuration-schemas\" rel=\"nofollow\">JSON Schemas</a> for this libraries internal configuration format</li>\n</ul>\n<p>On commits to the <em>master</em> branch:</p>\n<ul>\n<li>changes will be deployed to <a href=\"https://test.pypi.org\" rel=\"nofollow\">PyPi testing</a></li>\n<li>configuration schemas will be published to the\n<a href=\"https://metadata-standards-testing.data.bas.ac.uk\" rel=\"nofollow\">Metadata Standards testing</a> website</li>\n</ul>\n<p>On tagged commits:</p>\n<ul>\n<li>changes will be deployed to <a href=\"https://pypi.org\" rel=\"nofollow\">PyPi</a></li>\n<li>configuration schemas will be published to the <a href=\"https://metadata-standards.data.bas.ac.uk\" rel=\"nofollow\">Metadata Standards</a>\nwebsite</li>\n</ul>\n<h2>Release procedure</h2>\n<h3>At release</h3>\n<ol>\n<li>create a <code>release</code> branch</li>\n<li>bump version in <code>setup.py</code> as per SemVer</li>\n<li>close release in <code>CHANGELOG.md</code></li>\n<li>push changes, merge the <code>release</code> branch into <code>master</code> and tag with version</li>\n</ol>\n<p>The project will be built and published to PyPi automatically through <a href=\"#continuous-deployment\" rel=\"nofollow\">Continuous Deployment</a>.</p>\n<h2>Feedback</h2>\n<p>The maintainer of this project is the BAS Web &amp; Applications Team, they can be contacted at:\n<a href=\"mailto:servicedesk@bas.ac.uk\">servicedesk@bas.ac.uk</a>.</p>\n<h2>Issue tracking</h2>\n<p>This project uses issue tracking, see the\n<a href=\"https://gitlab.data.bas.ac.uk/uk-pdc/metadata-infrastructure/metadata-generator/issues\" rel=\"nofollow\">Issue tracker</a> for more\ninformation.</p>\n<p><strong>Note:</strong> Read &amp; write access to this issue tracker is restricted. Contact the project maintainer to request access.</p>\n<h2>License</h2>\n<p>\u00a9 UK Research and Innovation (UKRI), 2019, British Antarctic Survey.</p>\n<p>You may use and re-use this software and associated documentation files free of charge in any format or medium, under\nthe terms of the Open Government Licence v3.0.</p>\n<p>You may obtain a copy of the Open Government Licence at <a href=\"http://www.nationalarchives.gov.uk/doc/open-government-licence/\" rel=\"nofollow\">http://www.nationalarchives.gov.uk/doc/open-government-licence/</a></p>\n\n          </div>"}, "last_serial": 5697351, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "33854c20231aff5c3f6bd0b84bbe86a1", "sha256": "daed09e4b182e353955a5c14cad57ef52d2a71a02d65c46791e7a9185dbc7963"}, "downloads": -1, "filename": "bas_metadata_library-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "33854c20231aff5c3f6bd0b84bbe86a1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 21769, "upload_time": "2019-06-28T08:02:21", "upload_time_iso_8601": "2019-06-28T08:02:21.697083Z", "url": "https://files.pythonhosted.org/packages/8c/a3/d07c6eb439701a3a8bab66421e0178683983edba278335a83da3f06db3d0/bas_metadata_library-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3613262bf44f6a42d07738cb3289c49c", "sha256": "1f1a5eae3decb96acc4172cf1c54c30e8d79a2188d453b68486c3aea4211e322"}, "downloads": -1, "filename": "bas-metadata-library-0.1.0.tar.gz", "has_sig": false, "md5_digest": "3613262bf44f6a42d07738cb3289c49c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25193, "upload_time": "2019-06-28T08:02:24", "upload_time_iso_8601": "2019-06-28T08:02:24.236007Z", "url": "https://files.pythonhosted.org/packages/b3/82/e5918b4d8ec3d4939117a524bf6bc48a6d5824d60d0ea265b3d4972a2db4/bas-metadata-library-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "e78ecc4a743e17162e942993c3557f5b", "sha256": "fd3fb022a67d01d70b23347c3ef33cae07721cf605a5b6caa0570ab10602be5c"}, "downloads": -1, "filename": "bas_metadata_library-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e78ecc4a743e17162e942993c3557f5b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 21943, "upload_time": "2019-07-18T11:11:57", "upload_time_iso_8601": "2019-07-18T11:11:57.734964Z", "url": "https://files.pythonhosted.org/packages/e8/3b/a3a16c414a518be901d0f80c9378c2bc3c66865821d71e6090bc8309a426/bas_metadata_library-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c5b4f29430a1d1e9e22605fe974094d8", "sha256": "25b3f3b5b4c88160fac018ebd7e34f644cbe727ee487c354aadb122089fed85c"}, "downloads": -1, "filename": "bas-metadata-library-0.1.1.tar.gz", "has_sig": false, "md5_digest": "c5b4f29430a1d1e9e22605fe974094d8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25374, "upload_time": "2019-07-18T11:11:59", "upload_time_iso_8601": "2019-07-18T11:11:59.429871Z", "url": "https://files.pythonhosted.org/packages/f2/de/40744c151fdcfd4865f161f83f20386de383c2ef63c41c21d598453e782a/bas-metadata-library-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "09349f2334757e6194b8889c3ec8ab9f", "sha256": "731d91eaf50062ad0bd3d8873db58731075c0b7a9cc117067af18226f3c9d3f9"}, "downloads": -1, "filename": "bas_metadata_library-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "09349f2334757e6194b8889c3ec8ab9f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28322, "upload_time": "2019-08-17T10:51:17", "upload_time_iso_8601": "2019-08-17T10:51:17.515760Z", "url": "https://files.pythonhosted.org/packages/71/34/1b90f45eb93ba520be326f922ece92e74b97f77bcf0449c5a124aa888354/bas_metadata_library-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d60b0b7156d4cd66c976f4b54c1022c2", "sha256": "a2bf70441c13d4a41db52775773dd95c2731373e46f39152f9703652cb466542"}, "downloads": -1, "filename": "bas-metadata-library-0.2.0.tar.gz", "has_sig": false, "md5_digest": "d60b0b7156d4cd66c976f4b54c1022c2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32449, "upload_time": "2019-08-17T10:51:19", "upload_time_iso_8601": "2019-08-17T10:51:19.478588Z", "url": "https://files.pythonhosted.org/packages/3b/2e/23368d520ed3563c2dbf90a85da7b1267f9f33685c90aa1c30ef0f80b316/bas-metadata-library-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "32c045f2a944dd08162802056c1affd3", "sha256": "716974216c69e06185be4e8b9ff4169e79d3bb719e340c6c9dc0a0406a2b328f"}, "downloads": -1, "filename": "bas_metadata_library-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "32c045f2a944dd08162802056c1affd3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28296, "upload_time": "2019-08-17T12:46:57", "upload_time_iso_8601": "2019-08-17T12:46:57.353236Z", "url": "https://files.pythonhosted.org/packages/70/5f/77703bb58031ea4078d3fe423377e14c56982fb608d38aa0ea9dae81b3ce/bas_metadata_library-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e34c369c498c8d6f0cc5714c2085fa49", "sha256": "fbf5f0e19edcc6c076539a317917cbfbb94567e5357b9cfc84273db3ced1fe53"}, "downloads": -1, "filename": "bas-metadata-library-0.2.1.tar.gz", "has_sig": false, "md5_digest": "e34c369c498c8d6f0cc5714c2085fa49", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32441, "upload_time": "2019-08-17T12:46:59", "upload_time_iso_8601": "2019-08-17T12:46:59.195346Z", "url": "https://files.pythonhosted.org/packages/ae/9b/82c67ea1d020dbba53978f73d44be1bd8eb0525a942487bf432b8f6a3a1c/bas-metadata-library-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "1b83a888bfaeeab11e142aee148d4647", "sha256": "66c175e0cba80a3b48534d4c08d9aca3176075af4658aa7937bae87ceeb77609"}, "downloads": -1, "filename": "bas_metadata_library-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1b83a888bfaeeab11e142aee148d4647", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28305, "upload_time": "2019-08-19T08:42:46", "upload_time_iso_8601": "2019-08-19T08:42:46.062701Z", "url": "https://files.pythonhosted.org/packages/37/af/e69692e9dfdc2c5ca1817dd31ab64eb9883315dbe38e1096ca2ea9d7c35d/bas_metadata_library-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65e39c175ca92d21e830d7d87ded9f7b", "sha256": "6f0dbad7cffadecdfdd7b30ce4ab237063801e03e0ffdcb4c59091dde30f3d14"}, "downloads": -1, "filename": "bas-metadata-library-0.2.2.tar.gz", "has_sig": false, "md5_digest": "65e39c175ca92d21e830d7d87ded9f7b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32459, "upload_time": "2019-08-19T08:42:47", "upload_time_iso_8601": "2019-08-19T08:42:47.514954Z", "url": "https://files.pythonhosted.org/packages/c4/ff/102d67fcc01d14d7eb6c41991ea55f0ee98af0feb98b9cd9c5d24321e401/bas-metadata-library-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1b83a888bfaeeab11e142aee148d4647", "sha256": "66c175e0cba80a3b48534d4c08d9aca3176075af4658aa7937bae87ceeb77609"}, "downloads": -1, "filename": "bas_metadata_library-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1b83a888bfaeeab11e142aee148d4647", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28305, "upload_time": "2019-08-19T08:42:46", "upload_time_iso_8601": "2019-08-19T08:42:46.062701Z", "url": "https://files.pythonhosted.org/packages/37/af/e69692e9dfdc2c5ca1817dd31ab64eb9883315dbe38e1096ca2ea9d7c35d/bas_metadata_library-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65e39c175ca92d21e830d7d87ded9f7b", "sha256": "6f0dbad7cffadecdfdd7b30ce4ab237063801e03e0ffdcb4c59091dde30f3d14"}, "downloads": -1, "filename": "bas-metadata-library-0.2.2.tar.gz", "has_sig": false, "md5_digest": "65e39c175ca92d21e830d7d87ded9f7b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32459, "upload_time": "2019-08-19T08:42:47", "upload_time_iso_8601": "2019-08-19T08:42:47.514954Z", "url": "https://files.pythonhosted.org/packages/c4/ff/102d67fcc01d14d7eb6c41991ea55f0ee98af0feb98b9cd9c5d24321e401/bas-metadata-library-0.2.2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:14:45 2020"}