{"info": {"author": "Eleven", "author_email": "eleven_1111@outlook.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: Implementation", "Topic :: Software Development :: Libraries"], "description": "# Fastorch\n\n[Pytorch](https://github.com/pytorch/pytorch) is convenient and easy to use, while [Keras](https://github.com/keras-team/keras) is designed to experiment quickly. Do you want to possess **both** Pytorch's convenience and Keras'  fast experimentation? The answer is *fastorch.*\n\n\n\n## Traditional classification task training flow in pytorch\n\n```python\n################################# import dependencies ###############################\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n################################# define your network ###############################\nclass network(nn.Module):\n    def __init__(self):\n        super(network, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(1000, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 10),\n        )\n\n    def forward(self, x):\n        return self.fc(x)\n\n################################## prepare dataset ##################################\nclass mydataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __getitem__(self, item):\n        return self.x[item], self.y[item]\n\n    def __len__(self):\n        return self.x.size(0)\n# for simplicity, randomly generate datas, \nX = torch.randn(5000, 1000)\nY = torch.randint(0, 10, size=(5000,))\nBATCH_SIZE = 100\ntrainset = mydataset(X, Y)\ntrain_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n\n########################### assign optimizer and criterion ##########################\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n############################## define and run training ##############################\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nEPOCH = 10\nnet = network().to(device)\nfor epoch in range(EPOCH):\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        out = net(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n        print('Epoch %d -> loss: %.4f' % (epoch, loss.item()))\n\n```\n\nIt's simple and straightforward, but is that enough? Below gives **fastorch resolution.**\n\n\n\n## Training with fastorch\n\n```python\n################################# import dependencies ###############################\nimport torch\nimport fastorch\n\n################################# define your network ###############################\n'''\ninherit from fastorch in your own network\n'''\nclass network(fastorch.models.Model):\n    def __init__(self):\n        super(network, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(1000, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 10),\n        )\n\n    def forward(self, x):\n        return self.fc(x)\n\n################################## prepare dataset ##################################\n# for simplicity, randomly generate datas, \nX = torch.randn(5000, 1000)\nY = torch.randint(0, 10, size=(5000,))\n\n#################################### run training ###################################\nnet = network()\nnet.fit(x=X, y=Y, optimizer='sgd', criterion='cross_entropy', batch_size=BATCH_SIZE, epochs=1, verbose=1)\n'''\nEpoch[1/1]\n 2100/5000 [========>***********] - 1s - 68ms/batch -batch_loss: 2.2993 -batch_acc: 0.1200\n'''\n```\n\n\n\n## Installation\n\nBefore installing Fastorch, please install the following **dependencies**:\n\n- python >= 3.0 (3.6 is recommend)\n- pytorch (1.0+ is recommend)\n\nThen you can install Fastorchby using pip:\n\n```\n$ pip install fastorch\n```\n\n\n\n## Supports\n\nWhen using `fastorch.models.Model`, make sure your network is **inherited** from `fastorch.models.Model`.\n\n### - fastorch.models.Model\n\n**fit**(*train_dataset*=None, *x*=None, *y*=None, *optimizer*=None, *criterion*=None, *transform*=None, *batch_size*=None, *epochs*=1, *verbose*=1, *print_acc*=True, *callbacks*=None, *validation_dataset*=None, *validation_split*=0.0, *validation_data*=None, *validation_transform*=None, *shuffle*=True, *initial_epoch*=0, *steps_per_epoch*=None, *device*=None, **kwargs)\n\n+ *train_dataset*: training dataset, which inherited from `torch.utils.data.Dataset`. Make sure *x* and *y* are not None when *train_dataset* is None.\n+ *x*: training data, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *y*: training target, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *optimizer*: model optimizer, it can be `str` or an instance of `pytorch optimizer`, when passing str('sgd', 'adam'), fastorch will automatically declare the corresponding pytorch optimizer.\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *train_dataset*.\n+ *batch_size*: training batch_size,  default is 32 if not specified.\n+ *epochs*: training stop epochs, default is 1 if not specified.\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n+ *print_acc*: True or False, passing True if you are doing classification task.\n+ *callbacks*: waiting for implemented.\n+ *validation_dataset*:  validation dataset, which inherited from `torch.utils.data.Dataset`. \n+ *validation_split*: split validation data from training data's ratio, make sure *x* and *y* are not None when using this argument.\n+ *validation_data*: tuple of validation x and validation y.\n+ *validation_transform*:  applying `torchvision.transforms` on *validation_data* or data split by *validation_split*.\n+ *shuffle*: whether shuffle the training data.\n+ *initial_epoch*: start training epoch.\n+ *steps_per_epoch*: int or None, if specified, batch_size will be set as total_sample_nums / *steps_per_epoch*.\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n**evaluate**(*dataset*=None, *dataloader*=None, *x*=None, *y*=None, *transform*=None, *batch_size*=None, *verbose*=1, *criterion*=None, *print_acc*=True, *steps*=None, *device*=None, **kwargs)\n\n+ *dataset*: evaluate dataset, which inherited from `torch.utils.data.Dataset`. Make sure *dataloader* or  *x* and *y* are not None when *dataset*is None.\n\n+ *dataloader*: evaluate dataloader, which inherited from `torch.utils.data.Dataloader`. Make sure *dataset*or  *x* and *y* are not None when *dataloader*is None.\n\n+ *x*: test data, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n\n+ *y*: test target, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *dataset*.\n\n+ *batch_size*: evaluate batch_size,  default is 32 if not specified.\n\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n\n+ *print_acc*: True or False, passing True if you are doing classification task.\n\n+ *steps*: int or None, if specified, batch_size will be set as total_sample_nums / *steps*.\n\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n### - fastorch.functional\n\n**fit**(*model*=None, *train_dataset*=None, *x*=None, *y*=None, *optimizer*=None, *criterion*=None, *transform*=None, *batch_size*=None, *epochs*=1, *verbose*=1, *print_acc*=True, *callbacks*=None, *validation_dataset*=None, *validation_split*=0.0, *validation_data*=None, *validation_transform*=None, *shuffle*=True, *initial_epoch*=0, *steps_per_epoch*=None, *device*=None, **kwargs)\n\n+ *model*: your network, must be specify.\n\n+ *train_dataset*: training dataset, which inherited from `torch.utils.data.Dataset`. Make sure *x* and *y* are not None when *train_dataset* is None.\n+ *x*: training data, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *y*: training target, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *optimizer*: model optimizer, it can be `str` or an instance of `pytorch optimizer`, when passing str('sgd', 'adam'), fastorch will automatically declare the corresponding pytorch optimizer.\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *train_dataset*.\n+ *batch_size*: training batch_size,  default is 32 if not specified.\n+ *epochs*: training stop epochs, default is 1 if not specified.\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n+ *print_acc*: True or False, passing True if you are doing classification task.\n+ *callbacks*: waiting for implemented.\n+ *validation_dataset*:  validation dataset, which inherited from `torch.utils.data.Dataset`. \n+ *validation_split*: split validation data from training data's ratio, make sure *x* and *y* are not None when using this argument.\n+ *validation_data*: tuple of validation x and validation y.\n+ *validation_transform*:  applying `torchvision.transforms` on *validation_data* or data split by *validation_split*.\n+ *shuffle*: whether shuffle the training data.\n+ *initial_epoch*: start training epoch.\n+ *steps_per_epoch*: int or None, if specified, batch_size will be set as total_sample_nums / *steps_per_epoch*.\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n**evaluate**((*model*=None, *dataset*=None, *dataloader*=None, *x*=None, *y*=None, *transform*=None, *batch_size*=None, *verbose*=1, *criterion*=None, *print_acc*=True, *steps*=None, *device*=None, **kwargs)\n\n+ *model*: your network, must be specify.\n\n+ *dataset*: evaluate dataset, which inherited from `torch.utils.data.Dataset`. Make sure *dataloader* or  *x* and *y* are not None when *dataset*is None.\n+ *dataloader*: evaluate dataloader, which inherited from `torch.utils.data.Dataloader`. Make sure *dataset*or  *x* and *y* are not None when *dataloader*is None.\n+ *x*: test data, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n+ *y*: test target, it can be `Tensor`\u9286\u4e63ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *dataset*.\n+ *batch_size*: evaluate batch_size,  default is 32 if not specified.\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n+ *print_acc*: True or False, passing True if you are doing classification task.\n+ *steps*: int or None, if specified, batch_size will be set as total_sample_nums / *steps*.\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/eLeVeNnN/fastorch", "keywords": "", "license": "MIT License", "maintainer": "Eleven", "maintainer_email": "eleven_1111@outlook.com", "name": "fastorch", "package_url": "https://pypi.org/project/fastorch/", "platform": "all", "project_url": "https://pypi.org/project/fastorch/", "project_urls": {"Homepage": "https://github.com/eLeVeNnN/fastorch"}, "release_url": "https://pypi.org/project/fastorch/0.0.2/", "requires_dist": ["torch"], "requires_python": "", "summary": "Using pytorch easier and faster", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Fastorch</h1>\n<p><a href=\"https://github.com/pytorch/pytorch\" rel=\"nofollow\">Pytorch</a> is convenient and easy to use, while <a href=\"https://github.com/keras-team/keras\" rel=\"nofollow\">Keras</a> is designed to experiment quickly. Do you want to possess <strong>both</strong> Pytorch's convenience and Keras'  fast experimentation? The answer is <em>fastorch.</em></p>\n<h2>Traditional classification task training flow in pytorch</h2>\n<pre><span class=\"c1\">################################# import dependencies ###############################</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">Dataset</span><span class=\"p\">,</span> <span class=\"n\">DataLoader</span>\n\n<span class=\"c1\">################################# define your network ###############################</span>\n<span class=\"k\">class</span> <span class=\"nc\">network</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">network</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n<span class=\"c1\">################################## prepare dataset ##################################</span>\n<span class=\"k\">class</span> <span class=\"nc\">mydataset</span><span class=\"p\">(</span><span class=\"n\">Dataset</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">y</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__getitem__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">item</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"n\">item</span><span class=\"p\">],</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">y</span><span class=\"p\">[</span><span class=\"n\">item</span><span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"fm\">__len__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"c1\"># for simplicity, randomly generate datas, </span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">5000</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">5000</span><span class=\"p\">,))</span>\n<span class=\"n\">BATCH_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>\n<span class=\"n\">trainset</span> <span class=\"o\">=</span> <span class=\"n\">mydataset</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">Y</span><span class=\"p\">)</span>\n<span class=\"n\">train_loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">trainset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\">########################### assign optimizer and criterion ##########################</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">)</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">CrossEntropyLoss</span><span class=\"p\">()</span>\n\n<span class=\"c1\">############################## define and run training ##############################</span>\n<span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"s2\">\"cuda\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s2\">\"cpu\"</span>\n<span class=\"n\">EPOCH</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">network</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">epoch</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">EPOCH</span><span class=\"p\">):</span>\n    <span class=\"k\">for</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"ow\">in</span> <span class=\"n\">train_loader</span><span class=\"p\">:</span>\n        <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">),</span> <span class=\"n\">y</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">net</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">criterion</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n        <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Epoch </span><span class=\"si\">%d</span><span class=\"s1\"> -&gt; loss: </span><span class=\"si\">%.4f</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"p\">(</span><span class=\"n\">epoch</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()))</span>\n</pre>\n<p>It's simple and straightforward, but is that enough? Below gives <strong>fastorch resolution.</strong></p>\n<h2>Training with fastorch</h2>\n<pre><span class=\"c1\">################################# import dependencies ###############################</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">fastorch</span>\n\n<span class=\"c1\">################################# define your network ###############################</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">inherit from fastorch in your own network</span>\n<span class=\"sd\">'''</span>\n<span class=\"k\">class</span> <span class=\"nc\">network</span><span class=\"p\">(</span><span class=\"n\">fastorch</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">network</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">500</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">500</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n<span class=\"c1\">################################## prepare dataset ##################################</span>\n<span class=\"c1\"># for simplicity, randomly generate datas, </span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">5000</span><span class=\"p\">,</span> <span class=\"mi\">1000</span><span class=\"p\">)</span>\n<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">5000</span><span class=\"p\">,))</span>\n\n<span class=\"c1\">#################################### run training ###################################</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">network</span><span class=\"p\">()</span>\n<span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">=</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">Y</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s1\">'sgd'</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"s1\">'cross_entropy'</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"sd\">'''</span>\n<span class=\"sd\">Epoch[1/1]</span>\n<span class=\"sd\"> 2100/5000 [========&gt;***********] - 1s - 68ms/batch -batch_loss: 2.2993 -batch_acc: 0.1200</span>\n<span class=\"sd\">'''</span>\n</pre>\n<h2>Installation</h2>\n<p>Before installing Fastorch, please install the following <strong>dependencies</strong>:</p>\n<ul>\n<li>python &gt;= 3.0 (3.6 is recommend)</li>\n<li>pytorch (1.0+ is recommend)</li>\n</ul>\n<p>Then you can install Fastorchby using pip:</p>\n<pre><code>$ pip install fastorch\n</code></pre>\n<h2>Supports</h2>\n<p>When using <code>fastorch.models.Model</code>, make sure your network is <strong>inherited</strong> from <code>fastorch.models.Model</code>.</p>\n<h3>- fastorch.models.Model</h3>\n<p><strong>fit</strong>(<em>train_dataset</em>=None, <em>x</em>=None, <em>y</em>=None, <em>optimizer</em>=None, <em>criterion</em>=None, <em>transform</em>=None, <em>batch_size</em>=None, <em>epochs</em>=1, <em>verbose</em>=1, <em>print_acc</em>=True, <em>callbacks</em>=None, <em>validation_dataset</em>=None, <em>validation_split</em>=0.0, <em>validation_data</em>=None, <em>validation_transform</em>=None, <em>shuffle</em>=True, <em>initial_epoch</em>=0, <em>steps_per_epoch</em>=None, <em>device</em>=None, **kwargs)</p>\n<ul>\n<li><em>train_dataset</em>: training dataset, which inherited from <code>torch.utils.data.Dataset</code>. Make sure <em>x</em> and <em>y</em> are not None when <em>train_dataset</em> is None.</li>\n<li><em>x</em>: training data, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>train_dataset</em> is None.</li>\n<li><em>y</em>: training target, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>train_dataset</em> is None.</li>\n<li><em>optimizer</em>: model optimizer, it can be <code>str</code> or an instance of <code>pytorch optimizer</code>, when passing str('sgd', 'adam'), fastorch will automatically declare the corresponding pytorch optimizer.</li>\n<li><em>criterion</em>: loss function, it can be <code>str</code> or an instance of <code>pytorch objective function</code>, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .</li>\n<li>transform:  applying <code>torchvision.transforms</code> on <em>x</em> and <em>y</em> or <em>train_dataset</em>.</li>\n<li><em>batch_size</em>: training batch_size,  default is 32 if not specified.</li>\n<li><em>epochs</em>: training stop epochs, default is 1 if not specified.</li>\n<li><em>verbose</em>: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.</li>\n<li><em>print_acc</em>: True or False, passing True if you are doing classification task.</li>\n<li><em>callbacks</em>: waiting for implemented.</li>\n<li><em>validation_dataset</em>:  validation dataset, which inherited from <code>torch.utils.data.Dataset</code>.</li>\n<li><em>validation_split</em>: split validation data from training data's ratio, make sure <em>x</em> and <em>y</em> are not None when using this argument.</li>\n<li><em>validation_data</em>: tuple of validation x and validation y.</li>\n<li><em>validation_transform</em>:  applying <code>torchvision.transforms</code> on <em>validation_data</em> or data split by <em>validation_split</em>.</li>\n<li><em>shuffle</em>: whether shuffle the training data.</li>\n<li><em>initial_epoch</em>: start training epoch.</li>\n<li><em>steps_per_epoch</em>: int or None, if specified, batch_size will be set as total_sample_nums / <em>steps_per_epoch</em>.</li>\n<li><em>device</em>: specify device, otherwise fastorch will set device according to <code>torch.cuda.is_available()</code>.</li>\n<li>**kwargs: arguments used for <code>torch.utils.data.Dataloader</code>, etc.</li>\n</ul>\n<p><strong>evaluate</strong>(<em>dataset</em>=None, <em>dataloader</em>=None, <em>x</em>=None, <em>y</em>=None, <em>transform</em>=None, <em>batch_size</em>=None, <em>verbose</em>=1, <em>criterion</em>=None, <em>print_acc</em>=True, <em>steps</em>=None, <em>device</em>=None, **kwargs)</p>\n<ul>\n<li>\n<p><em>dataset</em>: evaluate dataset, which inherited from <code>torch.utils.data.Dataset</code>. Make sure <em>dataloader</em> or  <em>x</em> and <em>y</em> are not None when <em>dataset</em>is None.</p>\n</li>\n<li>\n<p><em>dataloader</em>: evaluate dataloader, which inherited from <code>torch.utils.data.Dataloader</code>. Make sure <em>dataset</em>or  <em>x</em> and <em>y</em> are not None when <em>dataloader</em>is None.</p>\n</li>\n<li>\n<p><em>x</em>: test data, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>dataset</em> or <em>dataloader</em> is None.</p>\n</li>\n<li>\n<p><em>y</em>: test target, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>dataset</em> or <em>dataloader</em> is None.</p>\n</li>\n<li>\n<p>transform:  applying <code>torchvision.transforms</code> on <em>x</em> and <em>y</em> or <em>dataset</em>.</p>\n</li>\n<li>\n<p><em>batch_size</em>: evaluate batch_size,  default is 32 if not specified.</p>\n</li>\n<li>\n<p><em>verbose</em>: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.</p>\n</li>\n<li>\n<p><em>criterion</em>: loss function, it can be <code>str</code> or an instance of <code>pytorch objective function</code>, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .</p>\n</li>\n<li>\n<p><em>print_acc</em>: True or False, passing True if you are doing classification task.</p>\n</li>\n<li>\n<p><em>steps</em>: int or None, if specified, batch_size will be set as total_sample_nums / <em>steps</em>.</p>\n</li>\n<li>\n<p><em>device</em>: specify device, otherwise fastorch will set device according to <code>torch.cuda.is_available()</code>.</p>\n</li>\n<li>\n<p>**kwargs: arguments used for <code>torch.utils.data.Dataloader</code>, etc.</p>\n</li>\n</ul>\n<h3>- fastorch.functional</h3>\n<p><strong>fit</strong>(<em>model</em>=None, <em>train_dataset</em>=None, <em>x</em>=None, <em>y</em>=None, <em>optimizer</em>=None, <em>criterion</em>=None, <em>transform</em>=None, <em>batch_size</em>=None, <em>epochs</em>=1, <em>verbose</em>=1, <em>print_acc</em>=True, <em>callbacks</em>=None, <em>validation_dataset</em>=None, <em>validation_split</em>=0.0, <em>validation_data</em>=None, <em>validation_transform</em>=None, <em>shuffle</em>=True, <em>initial_epoch</em>=0, <em>steps_per_epoch</em>=None, <em>device</em>=None, **kwargs)</p>\n<ul>\n<li>\n<p><em>model</em>: your network, must be specify.</p>\n</li>\n<li>\n<p><em>train_dataset</em>: training dataset, which inherited from <code>torch.utils.data.Dataset</code>. Make sure <em>x</em> and <em>y</em> are not None when <em>train_dataset</em> is None.</p>\n</li>\n<li>\n<p><em>x</em>: training data, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>train_dataset</em> is None.</p>\n</li>\n<li>\n<p><em>y</em>: training target, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>train_dataset</em> is None.</p>\n</li>\n<li>\n<p><em>optimizer</em>: model optimizer, it can be <code>str</code> or an instance of <code>pytorch optimizer</code>, when passing str('sgd', 'adam'), fastorch will automatically declare the corresponding pytorch optimizer.</p>\n</li>\n<li>\n<p><em>criterion</em>: loss function, it can be <code>str</code> or an instance of <code>pytorch objective function</code>, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .</p>\n</li>\n<li>\n<p>transform:  applying <code>torchvision.transforms</code> on <em>x</em> and <em>y</em> or <em>train_dataset</em>.</p>\n</li>\n<li>\n<p><em>batch_size</em>: training batch_size,  default is 32 if not specified.</p>\n</li>\n<li>\n<p><em>epochs</em>: training stop epochs, default is 1 if not specified.</p>\n</li>\n<li>\n<p><em>verbose</em>: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.</p>\n</li>\n<li>\n<p><em>print_acc</em>: True or False, passing True if you are doing classification task.</p>\n</li>\n<li>\n<p><em>callbacks</em>: waiting for implemented.</p>\n</li>\n<li>\n<p><em>validation_dataset</em>:  validation dataset, which inherited from <code>torch.utils.data.Dataset</code>.</p>\n</li>\n<li>\n<p><em>validation_split</em>: split validation data from training data's ratio, make sure <em>x</em> and <em>y</em> are not None when using this argument.</p>\n</li>\n<li>\n<p><em>validation_data</em>: tuple of validation x and validation y.</p>\n</li>\n<li>\n<p><em>validation_transform</em>:  applying <code>torchvision.transforms</code> on <em>validation_data</em> or data split by <em>validation_split</em>.</p>\n</li>\n<li>\n<p><em>shuffle</em>: whether shuffle the training data.</p>\n</li>\n<li>\n<p><em>initial_epoch</em>: start training epoch.</p>\n</li>\n<li>\n<p><em>steps_per_epoch</em>: int or None, if specified, batch_size will be set as total_sample_nums / <em>steps_per_epoch</em>.</p>\n</li>\n<li>\n<p><em>device</em>: specify device, otherwise fastorch will set device according to <code>torch.cuda.is_available()</code>.</p>\n</li>\n<li>\n<p>**kwargs: arguments used for <code>torch.utils.data.Dataloader</code>, etc.</p>\n</li>\n</ul>\n<p><strong>evaluate</strong>((<em>model</em>=None, <em>dataset</em>=None, <em>dataloader</em>=None, <em>x</em>=None, <em>y</em>=None, <em>transform</em>=None, <em>batch_size</em>=None, <em>verbose</em>=1, <em>criterion</em>=None, <em>print_acc</em>=True, <em>steps</em>=None, <em>device</em>=None, **kwargs)</p>\n<ul>\n<li>\n<p><em>model</em>: your network, must be specify.</p>\n</li>\n<li>\n<p><em>dataset</em>: evaluate dataset, which inherited from <code>torch.utils.data.Dataset</code>. Make sure <em>dataloader</em> or  <em>x</em> and <em>y</em> are not None when <em>dataset</em>is None.</p>\n</li>\n<li>\n<p><em>dataloader</em>: evaluate dataloader, which inherited from <code>torch.utils.data.Dataloader</code>. Make sure <em>dataset</em>or  <em>x</em> and <em>y</em> are not None when <em>dataloader</em>is None.</p>\n</li>\n<li>\n<p><em>x</em>: test data, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>dataset</em> or <em>dataloader</em> is None.</p>\n</li>\n<li>\n<p><em>y</em>: test target, it can be <code>Tensor</code>\u9286\u4e63ndarray<code>or</code>List`. You need pass <em>x</em> and <em>y</em> when <em>dataset</em> or <em>dataloader</em> is None.</p>\n</li>\n<li>\n<p>transform:  applying <code>torchvision.transforms</code> on <em>x</em> and <em>y</em> or <em>dataset</em>.</p>\n</li>\n<li>\n<p><em>batch_size</em>: evaluate batch_size,  default is 32 if not specified.</p>\n</li>\n<li>\n<p><em>verbose</em>: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.</p>\n</li>\n<li>\n<p><em>criterion</em>: loss function, it can be <code>str</code> or an instance of <code>pytorch objective function</code>, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .</p>\n</li>\n<li>\n<p><em>print_acc</em>: True or False, passing True if you are doing classification task.</p>\n</li>\n<li>\n<p><em>steps</em>: int or None, if specified, batch_size will be set as total_sample_nums / <em>steps</em>.</p>\n</li>\n<li>\n<p><em>device</em>: specify device, otherwise fastorch will set device according to <code>torch.cuda.is_available()</code>.</p>\n</li>\n<li>\n<p>**kwargs: arguments used for <code>torch.utils.data.Dataloader</code>, etc.</p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 7031678, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "3fc6d946c17eb189fb9a4520f4aa2092", "sha256": "e40914d53aae46491c93db0d2e2c7f25ed2c024551367fd1c822f3c4926707f5"}, "downloads": -1, "filename": "fastorch-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3fc6d946c17eb189fb9a4520f4aa2092", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12112, "upload_time": "2020-04-14T12:16:28", "upload_time_iso_8601": "2020-04-14T12:16:28.145770Z", "url": "https://files.pythonhosted.org/packages/c9/9f/3781c44c276d0515efdbfb2af842d6032d5069c2ce6f421bd36363827920/fastorch-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6c908bf29f5db7e0039adbd33cf9c127", "sha256": "e62801bb6eecaea9469266c09df56c06ff01d311736c9e65827262c671df784d"}, "downloads": -1, "filename": "fastorch-0.0.1.tar.gz", "has_sig": false, "md5_digest": "6c908bf29f5db7e0039adbd33cf9c127", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12561, "upload_time": "2020-04-14T12:16:30", "upload_time_iso_8601": "2020-04-14T12:16:30.804266Z", "url": "https://files.pythonhosted.org/packages/33/db/4bffd5e62311f98eab5281489b262e53fa01b7f6de1bf9be042030367cfb/fastorch-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "ee646d19bd15b197cf9f1fd96be5be23", "sha256": "f35e38890e8da51680b7569bdc8165d6add3e3d130717972f63d23fcecf9eb49"}, "downloads": -1, "filename": "fastorch-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ee646d19bd15b197cf9f1fd96be5be23", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11590, "upload_time": "2020-04-16T11:59:25", "upload_time_iso_8601": "2020-04-16T11:59:25.139682Z", "url": "https://files.pythonhosted.org/packages/24/a0/a46dfd8c8f2078fe3ba4307585ba53dd93659d67c78adbf2ed6e74bd5270/fastorch-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d9eb91e11ec99a19c0bbc0c2f32f3da2", "sha256": "8ba5cb79544419c8f25bd76d7357f623bd1e0f0e7954a02cc189829d0559bf8b"}, "downloads": -1, "filename": "fastorch-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d9eb91e11ec99a19c0bbc0c2f32f3da2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11101, "upload_time": "2020-04-16T11:59:27", "upload_time_iso_8601": "2020-04-16T11:59:27.644090Z", "url": "https://files.pythonhosted.org/packages/22/f2/aa44efb69e177effaaff88d0d438098df50667bc427b25965a48a495eb78/fastorch-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ee646d19bd15b197cf9f1fd96be5be23", "sha256": "f35e38890e8da51680b7569bdc8165d6add3e3d130717972f63d23fcecf9eb49"}, "downloads": -1, "filename": "fastorch-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ee646d19bd15b197cf9f1fd96be5be23", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11590, "upload_time": "2020-04-16T11:59:25", "upload_time_iso_8601": "2020-04-16T11:59:25.139682Z", "url": "https://files.pythonhosted.org/packages/24/a0/a46dfd8c8f2078fe3ba4307585ba53dd93659d67c78adbf2ed6e74bd5270/fastorch-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d9eb91e11ec99a19c0bbc0c2f32f3da2", "sha256": "8ba5cb79544419c8f25bd76d7357f623bd1e0f0e7954a02cc189829d0559bf8b"}, "downloads": -1, "filename": "fastorch-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d9eb91e11ec99a19c0bbc0c2f32f3da2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11101, "upload_time": "2020-04-16T11:59:27", "upload_time_iso_8601": "2020-04-16T11:59:27.644090Z", "url": "https://files.pythonhosted.org/packages/22/f2/aa44efb69e177effaaff88d0d438098df50667bc427b25965a48a495eb78/fastorch-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:28 2020"}