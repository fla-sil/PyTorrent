{"info": {"author": "Dhia Abbassi", "author_email": "dhia.absi@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3 :: Only", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules", "Typing :: Typed"], "description": "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/confluent_avro?label=Python)](https://pypi.org/project/confluent-avro/)\n[![Build Status](https://travis-ci.com/DhiaTN/confluent-avro-py.svg?branch=master)](https://travis-ci.com/DhiaTN/avrokafka-py)\n[![Maintainability](https://api.codeclimate.com/v1/badges/fd596527a28dcaea1a2d/maintainability)](https://codeclimate.com/github/DhiaTN/confluent-avro-py/maintainability)\n[![codecov](https://codecov.io/gh/DhiaTN/confluent-avro-py/branch/master/graph/badge.svg)](https://codecov.io/gh/DhiaTN/confluent-avro-py)\n[![PyPI version](https://badge.fury.io/py/confluent_avro.svg)](https://badge.fury.io/py/confluent_avro)\n[![PyPI - License](https://img.shields.io/pypi/l/confluent_avro?color=ff69b4&label=License)](https://opensource.org/licenses/Apache-2.0)\n\n<br />\n<p align=\"center\">\n  <h1 align=\"center\">ConfluentAvro</h1>\n\n  <p align=\"center\">\n    An Avro SerDe implementation that integrates with the <a href=\"https://www.confluent.io/confluent-schema-registry/\">confluent schema registry</a> and serializes and deserializes data according to the defined <a href=\"http://docs.confluent.io/current/schema-registry/docs/serializer-formatter.html#wire-format\">confluent wire format</a>.\n    <br />\n    <br />\n    <a href=\"examples\">View Demo</a>\n    \u00b7\n    <a href=\"https://github.com/DhiaTN/confluent-avro-py/issues\">Report Bug</a>\n    \u00b7\n    <a href=\"https://github.com/DhiaTN/confluent-avro-py/issues\">Request Feature</a>\n  </p>\n</p>\n\n## Getting Started\n\n### Background\n\nTo solve [schema management](https://docs.confluent.io/current/schema-registry/index.html) issues and ensure compatibility in the development of Kafka-based applications, the confluent team introduced the schema registry to store and share the schema between the different apps and apply compatibility checks on each newly registered schema. To make the schema sharing easy, they extend the Avro binary format by prepending the schema id before the actual record instead of including the full schema.\n\n-\u00bb You can find more about Confluent and Schema Registry in [Confluent documentation](https://docs.confluent.io/current/schema-registry/index.html).\n\n### Implementation \n\nConfluentAvro implemented according to the above specification. Before publishing to Kafka topic, the library prepends the schema id to the generated Avro binary and when consuming from Kafka, it retrieves the schema id and fetches the schema from the registry before deserializing the actual data.\n\nThe underline API will automatically register new schemas used for the data serialization and will fetch the corresponding schema when deserializing it. Newly registered schemas and fetched schemas are both cached locally to speed up the process for future records.\n\n\u00bb The ConfluentAvro's bullet points:\n\n- Supports the confluent wire format\n- Integrates with the confluent schema registry\n- Retries with exponential backoff if connection to registry failed\n- Implements caching at the schema registry level\n- The underline decoder/encoder is built once for the same schema and reused for all upcoming records \n- Can be integrated with different Kafka clients\n\n\n### Built With\n\n- [fastavro](https://fastavro.readthedocs.io/en/latest/) (check [fastavro benchmark](https://github.com/DhiaTN/avro-benchmarking-py3))\n- [requests](https://requests.readthedocs.io)\n\n### Installation\n\n```shell script\n\u00bb pip install confluent-avro\n```\n\n### Usage\n\n> Check [examples](examples) for a fully working demo.\n\n##### Consumer App Example:\n\n```python\nfrom kafka import KafkaConsumer\n\nfrom confluent_avro import AvroKeyValueSerde, SchemaRegistry\nfrom confluent_avro.schema_registry import HTTPBasicAuth\n\nKAFKA_TOPIC = \"confluent_avro-example-topic\"\n\nregistry_client = SchemaRegistry(\n    \"https://myschemaregistry.com\",\n    HTTPBasicAuth(\"username\", \"password\"),\n    headers={\"Content-Type\": \"application/vnd.schemaregistry.v1+json\"},\n)\navroSerde = AvroKeyValueSerde(registry_client, KAFKA_TOPIC)\n\nconsumer = KafkaConsumer(\n    KAFKA_TOPIC,\n    group_id=\"random_group_id\",\n    bootstrap_servers=[\"localhost:9092\",]\n)\n\nfor msg in consumer:\n    v = avroSerde.value.deserialize(msg.value)\n    k = avroSerde.key.deserialize(msg.key)\n    print(msg.offset, msg.partition, k, v)\n```\n\n##### Producer App Example:\n\n```python\nfrom kafka import KafkaProducer\n\nfrom confluent_avro import AvroKeyValueSerde, SchemaRegistry\nfrom confluent_avro.schema_registry import HTTPBasicAuth\n\nKAFKA_TOPIC = \"confluent_avro-example-topic\"\n\nregistry_client = SchemaRegistry(\n    \"https://myschemaregistry.com\",\n    HTTPBasicAuth(\"username\", \"password\"),\n    headers={\"Content-Type\": \"application/vnd.schemaregistry.v1+json\"},\n)\n\navroSerde = AvroKeyValueSerde(registry_client, KAFKA_TOPIC)\n\nproducer = KafkaProducer(bootstrap_servers=[\"localhost:9092\"])\nproducer.send(\n    KAFKA_TOPIC,\n    key=avroSerde.key.serialize({...}, key_schema),\n    value=avroSerde.value.serialize({...}, value_schema),\n)\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/DhiaTN/confluent-avro-py", "keywords": "avro,kafka,confluent,schema registry", "license": "", "maintainer": "", "maintainer_email": "", "name": "confluent_avro", "package_url": "https://pypi.org/project/confluent_avro/", "platform": "", "project_url": "https://pypi.org/project/confluent_avro/", "project_urls": {"Homepage": "https://github.com/DhiaTN/confluent-avro-py"}, "release_url": "https://pypi.org/project/confluent_avro/1.7.0/", "requires_dist": ["requests[security] >=2.22.0", "fastavro >=0.22.9", "python-status >=1.0.1", "bumpversion ; extra == \"dev\"", "black ==19.10b0 ; extra == \"dev\"", "isort ; extra == \"dev\"", "mypy ; extra == \"dev\"", "pytest >=5.3.5 ; extra == \"test\"", "pytest-cov ; extra == \"test\"", "pytest-sugar ; extra == \"test\"", "pytest-xdist ; extra == \"test\"", "responses ; extra == \"test\""], "requires_python": ">=3.6", "summary": "An Avro SerDe implementation that integrates with the confluent", "version": "1.7.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://pypi.org/project/confluent-avro/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2e390813e5b0246e6713784a17b4f9c08555e931/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f636f6e666c75656e745f6176726f3f6c6162656c3d507974686f6e\"></a>\n<a href=\"https://travis-ci.com/DhiaTN/avrokafka-py\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/611ba6dde5bd3547b1a8499729c913edc721a6a3/68747470733a2f2f7472617669732d63692e636f6d2f44686961544e2f636f6e666c75656e742d6176726f2d70792e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codeclimate.com/github/DhiaTN/confluent-avro-py/maintainability\" rel=\"nofollow\"><img alt=\"Maintainability\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3bafc263867c761af9645e9c8df87bf6bdef6ea4/68747470733a2f2f6170692e636f6465636c696d6174652e636f6d2f76312f6261646765732f66643539363532376132386463616561316132642f6d61696e7461696e6162696c697479\"></a>\n<a href=\"https://codecov.io/gh/DhiaTN/confluent-avro-py\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6d1e694206724e936af57153ce918d95eb3952ed/68747470733a2f2f636f6465636f762e696f2f67682f44686961544e2f636f6e666c75656e742d6176726f2d70792f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://badge.fury.io/py/confluent_avro\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eddd12086be321ea1df74cc487860d3e551dcf31/68747470733a2f2f62616467652e667572792e696f2f70792f636f6e666c75656e745f6176726f2e737667\"></a>\n<a href=\"https://opensource.org/licenses/Apache-2.0\" rel=\"nofollow\"><img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dc8b80fcc00769b59de4d7aac13b8d22168c3839/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f636f6e666c75656e745f6176726f3f636f6c6f723d666636396234266c6162656c3d4c6963656e7365\"></a></p>\n<br>\n<p align=\"center\">\n  </p><h1>ConfluentAvro</h1>\n  <p align=\"center\">\n    An Avro SerDe implementation that integrates with the <a href=\"https://www.confluent.io/confluent-schema-registry/\" rel=\"nofollow\">confluent schema registry</a> and serializes and deserializes data according to the defined <a href=\"http://docs.confluent.io/current/schema-registry/docs/serializer-formatter.html#wire-format\" rel=\"nofollow\">confluent wire format</a>.\n    <br>\n    <br>\n    <a href=\"examples\" rel=\"nofollow\">View Demo</a>\n    \u00b7\n    <a href=\"https://github.com/DhiaTN/confluent-avro-py/issues\" rel=\"nofollow\">Report Bug</a>\n    \u00b7\n    <a href=\"https://github.com/DhiaTN/confluent-avro-py/issues\" rel=\"nofollow\">Request Feature</a>\n  </p>\n<p></p>\n<h2>Getting Started</h2>\n<h3>Background</h3>\n<p>To solve <a href=\"https://docs.confluent.io/current/schema-registry/index.html\" rel=\"nofollow\">schema management</a> issues and ensure compatibility in the development of Kafka-based applications, the confluent team introduced the schema registry to store and share the schema between the different apps and apply compatibility checks on each newly registered schema. To make the schema sharing easy, they extend the Avro binary format by prepending the schema id before the actual record instead of including the full schema.</p>\n<p>-\u00bb You can find more about Confluent and Schema Registry in <a href=\"https://docs.confluent.io/current/schema-registry/index.html\" rel=\"nofollow\">Confluent documentation</a>.</p>\n<h3>Implementation</h3>\n<p>ConfluentAvro implemented according to the above specification. Before publishing to Kafka topic, the library prepends the schema id to the generated Avro binary and when consuming from Kafka, it retrieves the schema id and fetches the schema from the registry before deserializing the actual data.</p>\n<p>The underline API will automatically register new schemas used for the data serialization and will fetch the corresponding schema when deserializing it. Newly registered schemas and fetched schemas are both cached locally to speed up the process for future records.</p>\n<p>\u00bb The ConfluentAvro's bullet points:</p>\n<ul>\n<li>Supports the confluent wire format</li>\n<li>Integrates with the confluent schema registry</li>\n<li>Retries with exponential backoff if connection to registry failed</li>\n<li>Implements caching at the schema registry level</li>\n<li>The underline decoder/encoder is built once for the same schema and reused for all upcoming records</li>\n<li>Can be integrated with different Kafka clients</li>\n</ul>\n<h3>Built With</h3>\n<ul>\n<li><a href=\"https://fastavro.readthedocs.io/en/latest/\" rel=\"nofollow\">fastavro</a> (check <a href=\"https://github.com/DhiaTN/avro-benchmarking-py3\" rel=\"nofollow\">fastavro benchmark</a>)</li>\n<li><a href=\"https://requests.readthedocs.io\" rel=\"nofollow\">requests</a></li>\n</ul>\n<h3>Installation</h3>\n<pre>\u00bb pip install confluent-avro\n</pre>\n<h3>Usage</h3>\n<blockquote>\n<p>Check <a href=\"examples\" rel=\"nofollow\">examples</a> for a fully working demo.</p>\n</blockquote>\n<h5>Consumer App Example:</h5>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">kafka</span> <span class=\"kn\">import</span> <span class=\"n\">KafkaConsumer</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">confluent_avro</span> <span class=\"kn\">import</span> <span class=\"n\">AvroKeyValueSerde</span><span class=\"p\">,</span> <span class=\"n\">SchemaRegistry</span>\n<span class=\"kn\">from</span> <span class=\"nn\">confluent_avro.schema_registry</span> <span class=\"kn\">import</span> <span class=\"n\">HTTPBasicAuth</span>\n\n<span class=\"n\">KAFKA_TOPIC</span> <span class=\"o\">=</span> <span class=\"s2\">\"confluent_avro-example-topic\"</span>\n\n<span class=\"n\">registry_client</span> <span class=\"o\">=</span> <span class=\"n\">SchemaRegistry</span><span class=\"p\">(</span>\n    <span class=\"s2\">\"https://myschemaregistry.com\"</span><span class=\"p\">,</span>\n    <span class=\"n\">HTTPBasicAuth</span><span class=\"p\">(</span><span class=\"s2\">\"username\"</span><span class=\"p\">,</span> <span class=\"s2\">\"password\"</span><span class=\"p\">),</span>\n    <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"Content-Type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"application/vnd.schemaregistry.v1+json\"</span><span class=\"p\">},</span>\n<span class=\"p\">)</span>\n<span class=\"n\">avroSerde</span> <span class=\"o\">=</span> <span class=\"n\">AvroKeyValueSerde</span><span class=\"p\">(</span><span class=\"n\">registry_client</span><span class=\"p\">,</span> <span class=\"n\">KAFKA_TOPIC</span><span class=\"p\">)</span>\n\n<span class=\"n\">consumer</span> <span class=\"o\">=</span> <span class=\"n\">KafkaConsumer</span><span class=\"p\">(</span>\n    <span class=\"n\">KAFKA_TOPIC</span><span class=\"p\">,</span>\n    <span class=\"n\">group_id</span><span class=\"o\">=</span><span class=\"s2\">\"random_group_id\"</span><span class=\"p\">,</span>\n    <span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"localhost:9092\"</span><span class=\"p\">,]</span>\n<span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">msg</span> <span class=\"ow\">in</span> <span class=\"n\">consumer</span><span class=\"p\">:</span>\n    <span class=\"n\">v</span> <span class=\"o\">=</span> <span class=\"n\">avroSerde</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">deserialize</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">)</span>\n    <span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">avroSerde</span><span class=\"o\">.</span><span class=\"n\">key</span><span class=\"o\">.</span><span class=\"n\">deserialize</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">key</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">offset</span><span class=\"p\">,</span> <span class=\"n\">msg</span><span class=\"o\">.</span><span class=\"n\">partition</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span><span class=\"p\">)</span>\n</pre>\n<h5>Producer App Example:</h5>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">kafka</span> <span class=\"kn\">import</span> <span class=\"n\">KafkaProducer</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">confluent_avro</span> <span class=\"kn\">import</span> <span class=\"n\">AvroKeyValueSerde</span><span class=\"p\">,</span> <span class=\"n\">SchemaRegistry</span>\n<span class=\"kn\">from</span> <span class=\"nn\">confluent_avro.schema_registry</span> <span class=\"kn\">import</span> <span class=\"n\">HTTPBasicAuth</span>\n\n<span class=\"n\">KAFKA_TOPIC</span> <span class=\"o\">=</span> <span class=\"s2\">\"confluent_avro-example-topic\"</span>\n\n<span class=\"n\">registry_client</span> <span class=\"o\">=</span> <span class=\"n\">SchemaRegistry</span><span class=\"p\">(</span>\n    <span class=\"s2\">\"https://myschemaregistry.com\"</span><span class=\"p\">,</span>\n    <span class=\"n\">HTTPBasicAuth</span><span class=\"p\">(</span><span class=\"s2\">\"username\"</span><span class=\"p\">,</span> <span class=\"s2\">\"password\"</span><span class=\"p\">),</span>\n    <span class=\"n\">headers</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s2\">\"Content-Type\"</span><span class=\"p\">:</span> <span class=\"s2\">\"application/vnd.schemaregistry.v1+json\"</span><span class=\"p\">},</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">avroSerde</span> <span class=\"o\">=</span> <span class=\"n\">AvroKeyValueSerde</span><span class=\"p\">(</span><span class=\"n\">registry_client</span><span class=\"p\">,</span> <span class=\"n\">KAFKA_TOPIC</span><span class=\"p\">)</span>\n\n<span class=\"n\">producer</span> <span class=\"o\">=</span> <span class=\"n\">KafkaProducer</span><span class=\"p\">(</span><span class=\"n\">bootstrap_servers</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"localhost:9092\"</span><span class=\"p\">])</span>\n<span class=\"n\">producer</span><span class=\"o\">.</span><span class=\"n\">send</span><span class=\"p\">(</span>\n    <span class=\"n\">KAFKA_TOPIC</span><span class=\"p\">,</span>\n    <span class=\"n\">key</span><span class=\"o\">=</span><span class=\"n\">avroSerde</span><span class=\"o\">.</span><span class=\"n\">key</span><span class=\"o\">.</span><span class=\"n\">serialize</span><span class=\"p\">({</span><span class=\"o\">...</span><span class=\"p\">},</span> <span class=\"n\">key_schema</span><span class=\"p\">),</span>\n    <span class=\"n\">value</span><span class=\"o\">=</span><span class=\"n\">avroSerde</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"o\">.</span><span class=\"n\">serialize</span><span class=\"p\">({</span><span class=\"o\">...</span><span class=\"p\">},</span> <span class=\"n\">value_schema</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 6623633, "releases": {"1.5.0": [{"comment_text": "", "digests": {"md5": "b82288aeae8e02fb1afa05719120b648", "sha256": "bffb1d2023dc0a78e97982f303d6326267413047500ace45b124aba4db83dd3d"}, "downloads": -1, "filename": "confluent_avro-1.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b82288aeae8e02fb1afa05719120b648", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 12704, "upload_time": "2020-02-10T10:49:58", "upload_time_iso_8601": "2020-02-10T10:49:58.686670Z", "url": "https://files.pythonhosted.org/packages/16/0c/befa7bdf05d8f3759438ee83d5e5fdaf98bb7fcddaf172cdd9372351a8e0/confluent_avro-1.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b50fbb5d389ed4433410021ecdbb7dfd", "sha256": "e1fd75cc5882ba2024334580e0ae7b9fdc272dd6c7f4cdd351024c727a36e804"}, "downloads": -1, "filename": "confluent_avro-1.5.0.tar.gz", "has_sig": false, "md5_digest": "b50fbb5d389ed4433410021ecdbb7dfd", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 16881, "upload_time": "2020-02-10T10:50:07", "upload_time_iso_8601": "2020-02-10T10:50:07.309785Z", "url": "https://files.pythonhosted.org/packages/56/74/dd47a80f9ff0d83951db3864e5c7ab446c8125723186ada5d3dacaa2ac63/confluent_avro-1.5.0.tar.gz", "yanked": false}], "1.6.0": [{"comment_text": "", "digests": {"md5": "c60693a12523674c970c7bee546cdcfd", "sha256": "a1d0874ceac438272e2d4a5d403f285974057da49cd2d3210d3cc3605b7e876a"}, "downloads": -1, "filename": "confluent_avro-1.6.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c60693a12523674c970c7bee546cdcfd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13625, "upload_time": "2020-02-10T11:36:51", "upload_time_iso_8601": "2020-02-10T11:36:51.751018Z", "url": "https://files.pythonhosted.org/packages/d4/8b/f742615d567f26cb7a1f9c83fec43259f47610d3954f6acb4d28f1192011/confluent_avro-1.6.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9857374b53e4f8b627efe91ff5c99f1b", "sha256": "9d6feec2fb1cd20c1544beb9301f25113cf6ebb3135673c3aaaaf3f1dbbc833f"}, "downloads": -1, "filename": "confluent_avro-1.6.0.tar.gz", "has_sig": false, "md5_digest": "9857374b53e4f8b627efe91ff5c99f1b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17657, "upload_time": "2020-02-10T11:37:16", "upload_time_iso_8601": "2020-02-10T11:37:16.108919Z", "url": "https://files.pythonhosted.org/packages/8c/08/05e710032737439bd209aee82e018dbd8c0a319e0b9493fd0f1319e9d815/confluent_avro-1.6.0.tar.gz", "yanked": false}], "1.7.0": [{"comment_text": "", "digests": {"md5": "b2ecd0d1b2ec3e76bbcae47944ed6f40", "sha256": "3692ad6fc2a2659261641c29f1115bb2ec25e7c059abfe1199b4dbed14432e8d"}, "downloads": -1, "filename": "confluent_avro-1.7.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b2ecd0d1b2ec3e76bbcae47944ed6f40", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 14176, "upload_time": "2020-02-13T14:11:00", "upload_time_iso_8601": "2020-02-13T14:11:00.782310Z", "url": "https://files.pythonhosted.org/packages/9c/64/b50d83f6c43d877a3ab721e47289de565a73ac60605f4b589ef466560f4f/confluent_avro-1.7.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ce75e58ceebb7c7f2502db7b6c9ab56e", "sha256": "16c106585624786653793822d6b4f9d9b96a8325773a13cd634c958226316807"}, "downloads": -1, "filename": "confluent_avro-1.7.0.tar.gz", "has_sig": false, "md5_digest": "ce75e58ceebb7c7f2502db7b6c9ab56e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18592, "upload_time": "2020-02-13T14:11:11", "upload_time_iso_8601": "2020-02-13T14:11:11.386042Z", "url": "https://files.pythonhosted.org/packages/91/42/eb8dde52a527e79e69396481b440ee70e9a8ffb2d1c286df847db1e4bd09/confluent_avro-1.7.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b2ecd0d1b2ec3e76bbcae47944ed6f40", "sha256": "3692ad6fc2a2659261641c29f1115bb2ec25e7c059abfe1199b4dbed14432e8d"}, "downloads": -1, "filename": "confluent_avro-1.7.0-py3-none-any.whl", "has_sig": false, "md5_digest": "b2ecd0d1b2ec3e76bbcae47944ed6f40", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 14176, "upload_time": "2020-02-13T14:11:00", "upload_time_iso_8601": "2020-02-13T14:11:00.782310Z", "url": "https://files.pythonhosted.org/packages/9c/64/b50d83f6c43d877a3ab721e47289de565a73ac60605f4b589ef466560f4f/confluent_avro-1.7.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ce75e58ceebb7c7f2502db7b6c9ab56e", "sha256": "16c106585624786653793822d6b4f9d9b96a8325773a13cd634c958226316807"}, "downloads": -1, "filename": "confluent_avro-1.7.0.tar.gz", "has_sig": false, "md5_digest": "ce75e58ceebb7c7f2502db7b6c9ab56e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18592, "upload_time": "2020-02-13T14:11:11", "upload_time_iso_8601": "2020-02-13T14:11:11.386042Z", "url": "https://files.pythonhosted.org/packages/91/42/eb8dde52a527e79e69396481b440ee70e9a8ffb2d1c286df847db1e4bd09/confluent_avro-1.7.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:49 2020"}