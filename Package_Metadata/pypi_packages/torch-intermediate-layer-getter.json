{"info": {"author": "Sebastian Amenabar", "author_email": "amenabars@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)"], "description": "Simple easy to use module to get the intermediate results from chosen submodules. Supports submodule annidation. Inspired in [this](https://github.com/pytorch/vision/blob/f76e598d47879dbd917bf5936bbd11ff41632787/torchvision/models/_utils.py#L7) but does not assume that submodules are executed sequentially.\n\n# Installation\n\n```sh\npip install torch_intermediate_layer_getter\n```\n\n# Usage\n## Example\n\n```python\nimport torch\nimport torch.nn as nn\n\nfrom torch_intermediate_layer_getter import IntermediateLayerGetter as MidGetter\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.fc1 = nn.Linear(2, 2)\n        self.fc2 = nn.Linear(2, 2)\n        self.nested = nn.Sequential(\n            nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 3)),\n            nn.Linear(3, 1),\n        )\n        self.interaction_idty = nn.Identity() # Simple trick for operations not performed as modules\n\n    def forward(self, x):\n        x1 = self.fc1(x)\n        x2 = self.fc2(x)\n\n        interaction = x1 * x2\n        self.interaction_idty(interaction)\n\n        x_out = self.nested(interaction)\n\n        return x_out\n        \nmodel = Model()\nreturn_layers = {\n    'fc2': 'fc2',\n    'nested.0.1': 'nested',\n    'interaction_idty': 'interaction',\n}\nmid_getter = MidGetter(model, return_layers=return_layers, keep_output=True)\nmid_outputs, model_output = mid_getter(torch.randn(1, 2))\n\nprint(model_output)\n>> tensor([[0.3219]], grad_fn=<AddmmBackward>)\nprint(mid_outputs)\n>> OrderedDict([('fc2', tensor([[-1.5125,  0.9334]], grad_fn=<AddmmBackward>)),\n  ('interaction', tensor([[-0.0687, -0.1462]], grad_fn=<MulBackward0>)),\n  ('nested', tensor([[-0.1697,  0.1432,  0.2959]], grad_fn=<AddmmBackward>))])\n\n# model_output is None if keep_ouput is False\n# if keep_output is True the model_output contains the final model's output\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sebamenabar/Pytorch-IntermediateLayerGetter", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "torch-intermediate-layer-getter", "package_url": "https://pypi.org/project/torch-intermediate-layer-getter/", "platform": "", "project_url": "https://pypi.org/project/torch-intermediate-layer-getter/", "project_urls": {"Homepage": "https://github.com/sebamenabar/Pytorch-IntermediateLayerGetter"}, "release_url": "https://pypi.org/project/torch-intermediate-layer-getter/0.1.post1/", "requires_dist": null, "requires_python": "", "summary": "Simple easy to use module to get the intermediate results from chosen submodules", "version": "0.1.post1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Simple easy to use module to get the intermediate results from chosen submodules. Supports submodule annidation. Inspired in <a href=\"https://github.com/pytorch/vision/blob/f76e598d47879dbd917bf5936bbd11ff41632787/torchvision/models/_utils.py#L7\" rel=\"nofollow\">this</a> but does not assume that submodules are executed sequentially.</p>\n<h1>Installation</h1>\n<pre>pip install torch_intermediate_layer_getter\n</pre>\n<h1>Usage</h1>\n<h2>Example</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n\n<span class=\"kn\">from</span> <span class=\"nn\">torch_intermediate_layer_getter</span> <span class=\"kn\">import</span> <span class=\"n\">IntermediateLayerGetter</span> <span class=\"k\">as</span> <span class=\"n\">MidGetter</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Model</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">nested</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">),</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">)),</span>\n            <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span>\n        <span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">interaction_idty</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Identity</span><span class=\"p\">()</span> <span class=\"c1\"># Simple trick for operations not performed as modules</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">x2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n        <span class=\"n\">interaction</span> <span class=\"o\">=</span> <span class=\"n\">x1</span> <span class=\"o\">*</span> <span class=\"n\">x2</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">interaction_idty</span><span class=\"p\">(</span><span class=\"n\">interaction</span><span class=\"p\">)</span>\n\n        <span class=\"n\">x_out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">nested</span><span class=\"p\">(</span><span class=\"n\">interaction</span><span class=\"p\">)</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">x_out</span>\n        \n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Model</span><span class=\"p\">()</span>\n<span class=\"n\">return_layers</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'fc2'</span><span class=\"p\">:</span> <span class=\"s1\">'fc2'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'nested.0.1'</span><span class=\"p\">:</span> <span class=\"s1\">'nested'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'interaction_idty'</span><span class=\"p\">:</span> <span class=\"s1\">'interaction'</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n<span class=\"n\">mid_getter</span> <span class=\"o\">=</span> <span class=\"n\">MidGetter</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">return_layers</span><span class=\"o\">=</span><span class=\"n\">return_layers</span><span class=\"p\">,</span> <span class=\"n\">keep_output</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">mid_outputs</span><span class=\"p\">,</span> <span class=\"n\">model_output</span> <span class=\"o\">=</span> <span class=\"n\">mid_getter</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">model_output</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"mf\">0.3219</span><span class=\"p\">]],</span> <span class=\"n\">grad_fn</span><span class=\"o\">=&lt;</span><span class=\"n\">AddmmBackward</span><span class=\"o\">&gt;</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">mid_outputs</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;</span> <span class=\"n\">OrderedDict</span><span class=\"p\">([(</span><span class=\"s1\">'fc2'</span><span class=\"p\">,</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"o\">-</span><span class=\"mf\">1.5125</span><span class=\"p\">,</span>  <span class=\"mf\">0.9334</span><span class=\"p\">]],</span> <span class=\"n\">grad_fn</span><span class=\"o\">=&lt;</span><span class=\"n\">AddmmBackward</span><span class=\"o\">&gt;</span><span class=\"p\">)),</span>\n  <span class=\"p\">(</span><span class=\"s1\">'interaction'</span><span class=\"p\">,</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"o\">-</span><span class=\"mf\">0.0687</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.1462</span><span class=\"p\">]],</span> <span class=\"n\">grad_fn</span><span class=\"o\">=&lt;</span><span class=\"n\">MulBackward0</span><span class=\"o\">&gt;</span><span class=\"p\">)),</span>\n  <span class=\"p\">(</span><span class=\"s1\">'nested'</span><span class=\"p\">,</span> <span class=\"n\">tensor</span><span class=\"p\">([[</span><span class=\"o\">-</span><span class=\"mf\">0.1697</span><span class=\"p\">,</span>  <span class=\"mf\">0.1432</span><span class=\"p\">,</span>  <span class=\"mf\">0.2959</span><span class=\"p\">]],</span> <span class=\"n\">grad_fn</span><span class=\"o\">=&lt;</span><span class=\"n\">AddmmBackward</span><span class=\"o\">&gt;</span><span class=\"p\">))])</span>\n\n<span class=\"c1\"># model_output is None if keep_ouput is False</span>\n<span class=\"c1\"># if keep_output is True the model_output contains the final model's output</span>\n</pre>\n\n          </div>"}, "last_serial": 6082723, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "0d567d522af319466de4050aaf6c0e50", "sha256": "0ad68d85dcbd8ff85a5a1b77f270b64a8f18f2f4bb0118b5903379b211cfb2f2"}, "downloads": -1, "filename": "torch_intermediate_layer_getter-0.1.tar.gz", "has_sig": false, "md5_digest": "0d567d522af319466de4050aaf6c0e50", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 1709, "upload_time": "2019-11-05T19:18:03", "upload_time_iso_8601": "2019-11-05T19:18:03.529627Z", "url": "https://files.pythonhosted.org/packages/9d/97/b32c0683b3453c4906cd365bf6aba911e52eeead753900c390ecbf14f0a2/torch_intermediate_layer_getter-0.1.tar.gz", "yanked": false}], "0.1.post1": [{"comment_text": "", "digests": {"md5": "6bd3245a597e7e0b4c620b1a2413f641", "sha256": "c0e8374528d30f85e2420f6104242c0ca0495cfd7cdc551285305c01a7a21b67"}, "downloads": -1, "filename": "torch_intermediate_layer_getter-0.1.post1.tar.gz", "has_sig": false, "md5_digest": "6bd3245a597e7e0b4c620b1a2413f641", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2961, "upload_time": "2019-11-05T19:51:34", "upload_time_iso_8601": "2019-11-05T19:51:34.128277Z", "url": "https://files.pythonhosted.org/packages/38/98/8a37ff086257cdc9fd3e62f47b76de7d0091e9a43f3c719521411068449a/torch_intermediate_layer_getter-0.1.post1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6bd3245a597e7e0b4c620b1a2413f641", "sha256": "c0e8374528d30f85e2420f6104242c0ca0495cfd7cdc551285305c01a7a21b67"}, "downloads": -1, "filename": "torch_intermediate_layer_getter-0.1.post1.tar.gz", "has_sig": false, "md5_digest": "6bd3245a597e7e0b4c620b1a2413f641", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2961, "upload_time": "2019-11-05T19:51:34", "upload_time_iso_8601": "2019-11-05T19:51:34.128277Z", "url": "https://files.pythonhosted.org/packages/38/98/8a37ff086257cdc9fd3e62f47b76de7d0091e9a43f3c719521411068449a/torch_intermediate_layer_getter-0.1.post1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:22 2020"}