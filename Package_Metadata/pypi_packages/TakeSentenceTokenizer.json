{"info": {"author": "Karina Tiemi Kato", "author_email": "karinat@take.net", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# TakeSentenceTokenizer\n\nTakeSentenceTokenizer is a tool for pre processing and tokenizing sentences. \nThe package is used:\n\t- to convert the first word of the sentence to lower case\n\t- replace words for placeholders: laugh, date, time, ddd, measures (10kg, 20m, 5gb, etc), code, phone number, cnpj, cpf, email, money, url, number (ordinal and cardinal)\n\t- remove emoji\n\t- add accentuation\n\t- tokenize the sentence\n\n## Installation\n\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install TakeSentenceTokenizer\n\n```bash\npip install TakeSentenceTokenizer\n```\n\n## Usage\n\n```python\nimport SentenceTokenizer as st\nsentence = 'nao consigo fazer o cadastro!!'\ntokenizer = st.SentenceTokenizer()\nprocessed_sentence = tokenizer.process_message(sentence)\nprint(processed_sentence)\n\n```\n\n## Author\nKarina Tiemi Kato\n\n## License\n[MIT](https://choosealicense.com/licenses/mit/)\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "Tokenization", "license": "", "maintainer": "", "maintainer_email": "", "name": "TakeSentenceTokenizer", "package_url": "https://pypi.org/project/TakeSentenceTokenizer/", "platform": "", "project_url": "https://pypi.org/project/TakeSentenceTokenizer/", "project_urls": null, "release_url": "https://pypi.org/project/TakeSentenceTokenizer/0.4/", "requires_dist": ["emoji (==0.5.1)"], "requires_python": "", "summary": "TakeSentenceTokenizer is a tool for tokenizing and pre processing messages", "version": "0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TakeSentenceTokenizer</h1>\n<p>TakeSentenceTokenizer is a tool for pre processing and tokenizing sentences.\nThe package is used:\n- to convert the first word of the sentence to lower case\n- replace words for placeholders: laugh, date, time, ddd, measures (10kg, 20m, 5gb, etc), code, phone number, cnpj, cpf, email, money, url, number (ordinal and cardinal)\n- remove emoji\n- add accentuation\n- tokenize the sentence</p>\n<h2>Installation</h2>\n<p>Use the package manager <a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip</a> to install TakeSentenceTokenizer</p>\n<pre>pip install TakeSentenceTokenizer\n</pre>\n<h2>Usage</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">SentenceTokenizer</span> <span class=\"k\">as</span> <span class=\"nn\">st</span>\n<span class=\"n\">sentence</span> <span class=\"o\">=</span> <span class=\"s1\">'nao consigo fazer o cadastro!!'</span>\n<span class=\"n\">tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">st</span><span class=\"o\">.</span><span class=\"n\">SentenceTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">processed_sentence</span> <span class=\"o\">=</span> <span class=\"n\">tokenizer</span><span class=\"o\">.</span><span class=\"n\">process_message</span><span class=\"p\">(</span><span class=\"n\">sentence</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">processed_sentence</span><span class=\"p\">)</span>\n</pre>\n<h2>Author</h2>\n<p>Karina Tiemi Kato</p>\n<h2>License</h2>\n<p><a href=\"https://choosealicense.com/licenses/mit/\" rel=\"nofollow\">MIT</a></p>\n\n          </div>"}, "last_serial": 6800066, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e1eed1bd73cfebe18d97c7ad3defa2f6", "sha256": "c710130bb674ac86fe0317a7e98a9e54a70067603fa04c97f4d4b363c8d0d667"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e1eed1bd73cfebe18d97c7ad3defa2f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 407942, "upload_time": "2020-03-10T16:50:45", "upload_time_iso_8601": "2020-03-10T16:50:45.105581Z", "url": "https://files.pythonhosted.org/packages/33/f1/f7a02f78c7ed12a8fd1f00ab04631d1b1faf643dfec76ab578ccf3fe3b4d/TakeSentenceTokenizer-0.0.1-py3-none-any.whl", "yanked": false}], "0.1": [{"comment_text": "", "digests": {"md5": "5a2d44f4599cf96d74d4a9bae29321dc", "sha256": "46880a8665f2dfe4854102094f5b087d7335cb5aa1960b333594f12a96b39f27"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "5a2d44f4599cf96d74d4a9bae29321dc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 402549, "upload_time": "2020-03-10T21:27:52", "upload_time_iso_8601": "2020-03-10T21:27:52.964233Z", "url": "https://files.pythonhosted.org/packages/41/da/166ad1634d989773095bae7cccd0ef82d1100f1bb60e76b9a25eb20bf4f5/TakeSentenceTokenizer-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e87baedffc23b8b217aa43743445b190", "sha256": "d602aa50e942dac2dcaae3aa2ba33c9889c30b9a1bd4b871486ee562ebedb60b"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.1.tar.gz", "has_sig": false, "md5_digest": "e87baedffc23b8b217aa43743445b190", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3305, "upload_time": "2020-03-10T21:27:53", "upload_time_iso_8601": "2020-03-10T21:27:53.953030Z", "url": "https://files.pythonhosted.org/packages/fd/2c/72b6da89ebc04197067769d26308043476f779317f4816d887b45a4f5cb4/TakeSentenceTokenizer-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "ba48651536be17fae6a0469afef04b58", "sha256": "9cd9c53b02051849e38c31d85fe298859fe0deb1b20d4e34dbe80a8914a0e235"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "ba48651536be17fae6a0469afef04b58", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 402568, "upload_time": "2020-03-11T17:07:09", "upload_time_iso_8601": "2020-03-11T17:07:09.304825Z", "url": "https://files.pythonhosted.org/packages/12/21/f894a4458f60fab49971e1234e2cbe88e141493fed4bfc67cc8591c31f5c/TakeSentenceTokenizer-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fb8f137a48ddb5213f3bfca672cd79f2", "sha256": "2a370ebb0452765f3b006603b103c97d6d0544cde65c538cdc3ac547c3e865fc"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.2.tar.gz", "has_sig": false, "md5_digest": "fb8f137a48ddb5213f3bfca672cd79f2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3609, "upload_time": "2020-03-11T17:07:10", "upload_time_iso_8601": "2020-03-11T17:07:10.570381Z", "url": "https://files.pythonhosted.org/packages/0d/de/817fc5a9c5eca143b93252299b31f55582669c028ff4686f60b3ca8457a1/TakeSentenceTokenizer-0.2.tar.gz", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "a7b2e7af615416a664ea4dec334b3f82", "sha256": "0e4608e96e81c570757f2646fb7fb73a479c3ebced28918106f38a3c20fb3985"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "a7b2e7af615416a664ea4dec334b3f82", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 401631, "upload_time": "2020-03-12T15:33:08", "upload_time_iso_8601": "2020-03-12T15:33:08.709495Z", "url": "https://files.pythonhosted.org/packages/5d/c8/575c1b910a1c5c9d3ab46f113a43f9398de8c6e4bb488e4cbc270c023303/TakeSentenceTokenizer-0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2e3851729c34d53b197256559f964f6a", "sha256": "61f92118c8aa3a47732d335d987d322be60a594bd250b5fef273681efc43c15b"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.4.tar.gz", "has_sig": false, "md5_digest": "2e3851729c34d53b197256559f964f6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3757, "upload_time": "2020-03-12T15:33:09", "upload_time_iso_8601": "2020-03-12T15:33:09.681143Z", "url": "https://files.pythonhosted.org/packages/fc/41/3a3860061b7a37fcf3528eef07789c3e2c9083c7af13fc1100d58d76edb9/TakeSentenceTokenizer-0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a7b2e7af615416a664ea4dec334b3f82", "sha256": "0e4608e96e81c570757f2646fb7fb73a479c3ebced28918106f38a3c20fb3985"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "a7b2e7af615416a664ea4dec334b3f82", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 401631, "upload_time": "2020-03-12T15:33:08", "upload_time_iso_8601": "2020-03-12T15:33:08.709495Z", "url": "https://files.pythonhosted.org/packages/5d/c8/575c1b910a1c5c9d3ab46f113a43f9398de8c6e4bb488e4cbc270c023303/TakeSentenceTokenizer-0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2e3851729c34d53b197256559f964f6a", "sha256": "61f92118c8aa3a47732d335d987d322be60a594bd250b5fef273681efc43c15b"}, "downloads": -1, "filename": "TakeSentenceTokenizer-0.4.tar.gz", "has_sig": false, "md5_digest": "2e3851729c34d53b197256559f964f6a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3757, "upload_time": "2020-03-12T15:33:09", "upload_time_iso_8601": "2020-03-12T15:33:09.681143Z", "url": "https://files.pythonhosted.org/packages/fc/41/3a3860061b7a37fcf3528eef07789c3e2c9083c7af13fc1100d58d76edb9/TakeSentenceTokenizer-0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:58:18 2020"}