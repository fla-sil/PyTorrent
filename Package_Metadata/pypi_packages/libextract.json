{"info": {"author": "Rodrigo Palacios, Eeo Jun", "author_email": "rodrigopala91@gmail.com, packwolf58@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "Libextract: extract data from websites\r\n======================================\r\n\r\n.. image:: https://travis-ci.org/datalib/libextract.svg?branch=master\r\n    :target: https://travis-ci.org/datalib/libextract\r\n\r\n::\r\n\r\n        ___ __              __                  __\r\n       / (_) /_  ___  _  __/ /__________ ______/ /_\r\n      / / / __ \\/ _ \\| |/_/ __/ ___/ __ `/ ___/ __/\r\n     / / / /_/ /  __/>  </ /_/ /  / /_/ / /__/ /_\r\n    /_/_/_.___/\\___/_/|_|\\__/_/   \\__,_/\\___/\\__/\r\n\r\n\r\nLibextract is a `statistics-enabled <https://github.com/datalib/StatsCounter>`_\r\ndata extraction library that works on HTML and XML documents and written in \r\nPython. Originating from `eatiht <http://rodricios.github.io/eatiht/>`_, the\r\nextraction algorithm works by making one simple assumption: *data appear as \r\ncollections of repetitive elements*. You can read about the reasoning \r\n`here <http://rodricios.github.io/posts/solving_the_data_extraction_problem.html>`_. \r\n\r\n\r\nOverview\r\n--------\r\n\r\n`libextract.api.extract(document, encoding='utf-8', count=5)` \r\n    Given an html *document*, and optionally the *encoding*, return\r\n    a list of nodes likely containing data (5 by default).\r\n\r\n\r\nInstallation\r\n------------\r\n\r\n::\r\n\r\n    pip install libextract\r\n\r\nUsage\r\n-----\r\n\r\nDue to our simple definition of \"data\", we open up a single\r\ninterfaceable method. Post-processing is up to you. \r\n\r\n.. code-block:: python\r\n\r\n    from requests import get\r\n    from libextract.api import extract\r\n\r\n    r = get('http://en.wikipedia.org/wiki/Information_extraction')\r\n    textnodes = list(extract(r.content))\r\n\r\n\r\nUsing lxml's built-in methods for post-processing:\r\n\r\n.. code-block:: python\r\n\r\n    >> print(textnodes[0].text_content())\r\n    Information extraction (IE) is the task of automatically extracting structured information...\r\n\r\n\r\nThe extraction algo is agnostic to article text as it is with\r\ntabular data:\r\n\r\n.. code-block:: python\r\n\r\n    height_data = get(\"http://en.wikipedia.org/wiki/Human_height\")\r\n    tabs = list(extract(height_data.content))\r\n    \r\n\r\n.. code-block:: python\r\n\r\n    >> [elem.text_content() for elem in tabs[0].iter('th')]\r\n    ['Country/Region',\r\n     'Average male height',\r\n     'Average female height',\r\n     ...]\r\n\r\nDependencies\r\n~~~~~~~~~~~~\r\n\r\n::\r\n\r\n    lxml\r\n    statscounter\r\n\r\nDisclaimer\r\n~~~~~~~~~~\r\n\r\nThis project is still in its infancy; and advice and suggestions as\r\nto what this library could and should be would be greatly appreciated\r\n\r\n:) \r\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/datalib/libextract", "keywords": "extract extraction main article text html data-extraction data              content-extraction content unsupervised classification machine              learning AI artificial intelligence ML", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "libextract", "package_url": "https://pypi.org/project/libextract/", "platform": "any", "project_url": "https://pypi.org/project/libextract/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/datalib/libextract"}, "release_url": "https://pypi.org/project/libextract/0.0.12/", "requires_dist": null, "requires_python": null, "summary": "A HT/XML web scraping tool", "version": "0.0.12", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/datalib/libextract\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/datalib/libextract.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/657d3a60b1681957d07746af58e7eb9dafb13849/68747470733a2f2f7472617669732d63692e6f72672f646174616c69622f6c6962657874726163742e7376673f6272616e63683d6d6173746572\"></a>\n<pre>    ___ __              __                  __\n   / (_) /_  ___  _  __/ /__________ ______/ /_\n  / / / __ \\/ _ \\| |/_/ __/ ___/ __ `/ ___/ __/\n / / / /_/ /  __/&gt;  &lt;/ /_/ /  / /_/ / /__/ /_\n/_/_/_.___/\\___/_/|_|\\__/_/   \\__,_/\\___/\\__/\n</pre>\n<p>Libextract is a <a href=\"https://github.com/datalib/StatsCounter\" rel=\"nofollow\">statistics-enabled</a>\ndata extraction library that works on HTML and XML documents and written in\nPython. Originating from <a href=\"http://rodricios.github.io/eatiht/\" rel=\"nofollow\">eatiht</a>, the\nextraction algorithm works by making one simple assumption: <em>data appear as\ncollections of repetitive elements</em>. You can read about the reasoning\n<a href=\"http://rodricios.github.io/posts/solving_the_data_extraction_problem.html\" rel=\"nofollow\">here</a>.</p>\n<div id=\"overview\">\n<h2>Overview</h2>\n<dl>\n<dt><cite>libextract.api.extract(document, encoding=\u2019utf-8\u2019, count=5)</cite></dt>\n<dd>Given an html <em>document</em>, and optionally the <em>encoding</em>, return\na list of nodes likely containing data (5 by default).</dd>\n</dl>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install libextract\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>Due to our simple definition of \u201cdata\u201d, we open up a single\ninterfaceable method. Post-processing is up to you.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">requests</span> <span class=\"kn\">import</span> <span class=\"n\">get</span>\n<span class=\"kn\">from</span> <span class=\"nn\">libextract.api</span> <span class=\"kn\">import</span> <span class=\"n\">extract</span>\n\n<span class=\"n\">r</span> <span class=\"o\">=</span> <span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'http://en.wikipedia.org/wiki/Information_extraction'</span><span class=\"p\">)</span>\n<span class=\"n\">textnodes</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">extract</span><span class=\"p\">(</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">content</span><span class=\"p\">))</span>\n</pre>\n<p>Using lxml\u2019s built-in methods for post-processing:</p>\n<pre><span class=\"o\">&gt;&gt;</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">textnodes</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">text_content</span><span class=\"p\">())</span>\n<span class=\"n\">Information</span> <span class=\"n\">extraction</span> <span class=\"p\">(</span><span class=\"n\">IE</span><span class=\"p\">)</span> <span class=\"ow\">is</span> <span class=\"n\">the</span> <span class=\"n\">task</span> <span class=\"n\">of</span> <span class=\"n\">automatically</span> <span class=\"n\">extracting</span> <span class=\"n\">structured</span> <span class=\"n\">information</span><span class=\"o\">...</span>\n</pre>\n<p>The extraction algo is agnostic to article text as it is with\ntabular data:</p>\n<pre><span class=\"n\">height_data</span> <span class=\"o\">=</span> <span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">\"http://en.wikipedia.org/wiki/Human_height\"</span><span class=\"p\">)</span>\n<span class=\"n\">tabs</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">extract</span><span class=\"p\">(</span><span class=\"n\">height_data</span><span class=\"o\">.</span><span class=\"n\">content</span><span class=\"p\">))</span>\n</pre>\n<pre><span class=\"o\">&gt;&gt;</span> <span class=\"p\">[</span><span class=\"n\">elem</span><span class=\"o\">.</span><span class=\"n\">text_content</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">elem</span> <span class=\"ow\">in</span> <span class=\"n\">tabs</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">iter</span><span class=\"p\">(</span><span class=\"s1\">'th'</span><span class=\"p\">)]</span>\n<span class=\"p\">[</span><span class=\"s1\">'Country/Region'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Average male height'</span><span class=\"p\">,</span>\n <span class=\"s1\">'Average female height'</span><span class=\"p\">,</span>\n <span class=\"o\">...</span><span class=\"p\">]</span>\n</pre>\n<div id=\"dependencies\">\n<h3>Dependencies</h3>\n<pre>lxml\nstatscounter\n</pre>\n</div>\n<div id=\"disclaimer\">\n<h3>Disclaimer</h3>\n<p>This project is still in its infancy; and advice and suggestions as\nto what this library could and should be would be greatly appreciated</p>\n<p>:)</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 1610628, "releases": {"0.0.0": [{"comment_text": "", "digests": {"md5": "e02f535506333e116ead701a939c73a0", "sha256": "4a7b10c755d80975f108a5d2b4d30ba0ae095a9e7568e9be78f6812fe42f80fc"}, "downloads": -1, "filename": "libextract-0.0.0.zip", "has_sig": false, "md5_digest": "e02f535506333e116ead701a939c73a0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12497, "upload_time": "2015-04-15T00:14:43", "upload_time_iso_8601": "2015-04-15T00:14:43.034738Z", "url": "https://files.pythonhosted.org/packages/7c/1f/15b14a088599fd77f86762bdbbe3f9ea2dda39b29d32282ccf66ad111742/libextract-0.0.0.zip", "yanked": false}], "0.0.1": [{"comment_text": "", "digests": {"md5": "1461e45585c4fac8c02d813772b48c14", "sha256": "46b4e04f4ac6f7b230740cfb159e8136ee810e78600710682332bafbd29f03bf"}, "downloads": -1, "filename": "libextract-0.0.1.zip", "has_sig": false, "md5_digest": "1461e45585c4fac8c02d813772b48c14", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47025, "upload_time": "2015-04-16T03:01:17", "upload_time_iso_8601": "2015-04-16T03:01:17.652996Z", "url": "https://files.pythonhosted.org/packages/42/68/697b92e622535a1ba4863a72771316a9aa674f374a1b2b6a22473b69f8bf/libextract-0.0.1.zip", "yanked": false}], "0.0.11": [{"comment_text": "", "digests": {"md5": "0e84b3966913af89a695ce70ee1d4cd7", "sha256": "380cc55ac25b3776b1761e4942c7e78ec791ef49b2e2b4c72252a4b6901facb4"}, "downloads": -1, "filename": "libextract-0.0.11.zip", "has_sig": false, "md5_digest": "0e84b3966913af89a695ce70ee1d4cd7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46807, "upload_time": "2015-05-15T10:26:38", "upload_time_iso_8601": "2015-05-15T10:26:38.624555Z", "url": "https://files.pythonhosted.org/packages/55/a4/9edfe15bb0ac126fd7569887d8b8318455db30b739372edb8fb18c14701f/libextract-0.0.11.zip", "yanked": false}], "0.0.12": [{"comment_text": "", "digests": {"md5": "869acc9725a9d883a412c4e74ce400d3", "sha256": "053e846b235fc5dc1d7c8a0fa806207ba676631ebf3f30fb52fb6c6c1e0849cc"}, "downloads": -1, "filename": "libextract-0.0.12.zip", "has_sig": false, "md5_digest": "869acc9725a9d883a412c4e74ce400d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49802, "upload_time": "2015-06-28T22:20:05", "upload_time_iso_8601": "2015-06-28T22:20:05.740162Z", "url": "https://files.pythonhosted.org/packages/88/c8/434eff3237cd0ddc21c45a1ae52de3e94a33aad9c55468ce79da5f93f10c/libextract-0.0.12.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "869acc9725a9d883a412c4e74ce400d3", "sha256": "053e846b235fc5dc1d7c8a0fa806207ba676631ebf3f30fb52fb6c6c1e0849cc"}, "downloads": -1, "filename": "libextract-0.0.12.zip", "has_sig": false, "md5_digest": "869acc9725a9d883a412c4e74ce400d3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49802, "upload_time": "2015-06-28T22:20:05", "upload_time_iso_8601": "2015-06-28T22:20:05.740162Z", "url": "https://files.pythonhosted.org/packages/88/c8/434eff3237cd0ddc21c45a1ae52de3e94a33aad9c55468ce79da5f93f10c/libextract-0.0.12.zip", "yanked": false}], "timestamp": "Fri May  8 00:46:37 2020"}