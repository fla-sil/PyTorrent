{"info": {"author": "DrivenData", "author_email": "info@drivendata.org", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Multimedia :: Video", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Image Recognition"], "description": "# zamba - a command line interface for species classification\n\n[ ![Codeship Status for drivendataorg/chimps-tool](https://app.codeship.com/projects/03e3a040-0b6d-0136-afe4-3aeedc3a22e1/status?branch=master)](https://app.codeship.com/projects/281856)\n\n\n### [HOMEPAGE](http://zamba.drivendata.org/)\n\n### [DOCUMENTATION](http://zamba.drivendata.org/docs/)\n\n_Zamba means \"forest\" in the Lingala language._\n\nZamba is a command-line tool built in Python to automatically identify the species seen in camera trap videos from sites in central Africa. The tool makes predictions for 24 common species in these videos. For more information, see the documentation.\n\nThe `zamba` command will be the entry point for users (see example usage below).\n\n\n## Prerequisites (for more detail, see [the documentation](http://zamba.drivendata.org/docs/))\n\n - [Python](https://www.python.org/) 3.6\n - [ffmpeg](https://www.ffmpeg.org/download.html), codecs for handling the video loading\n\n\n## Installing `zamba` (for more detail, see [the documentation](http://zamba.drivendata.org/docs/))\n\n### GPU or CPU\n\n`zamba` is significantly faster when using a machine with a GPU instead of just a CPU. To use a GPU, you must be using an [nvidia gpu](https://www.nvidia.com/Download/index.aspx?lang=en-us), [installed and configured CUDA](https://developer.nvidia.com/cuda-downloads), and [installed and configured CuDNN](https://developer.nvidia.com/cudnn) per their specifications. Once this is done, you can select to install the version of zamaba that uses `tensorflow` compiled for GPU.\n\nWhen a user installs `zamba` that user must specify to install the GPU or CPU version. If the user fails to make this specification, **no version of tensorflow will be installed, thus everything will fail.**\n\nTo install with **tensorflow cpu** (you do not have a GPU)\n```\n$ pip install zamba[cpu]\n```\n\nTo install with **tensorflow gpu**\n```\n$ pip install zamba[gpu]\n```\n\n\n## Example usage\n\nOnce zamba is installed, you can see the commands with `zamba`:\n\n`zamba`\n\n```\nUsage: zamba [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  predict  Identify species in a video.\n  train    [NOT IMPLEMENTED] Retrain network from...\n  tune     [NOT IMPLEMENTED] Update network with new...\n```\n\nAnd you can see the options you can pass to the `predict` command with:\n\n`zamba predict --help`\n\n```\nUsage: zamba predict [OPTIONS] [DATA_PATH] [PRED_PATH]\n\n  Identify species in a video.\n\n  This is a command line interface for prediction on camera trap footage.\n  Given a path to camera trap footage, the predict function use a deep\n  learning model to predict the presence or absense of a variety of species\n  of common interest to wildlife researchers working with camera trap data.\n\nOptions:\n  --tempdir PATH                 Path to temporary directory. If not\n                                 specified, OS temporary directory is used.\n  --proba_threshold FLOAT        Probability threshold for classification. if\n                                 specified binary predictions are returned\n                                 with 1 being greater than the threshold, 0\n                                 being less than or equal to. If not\n                                 specified, probabilities between 0 and 1 are\n                                 returned.\n  --output_class_names           If True, we just return a video and the name\n                                 of the most likely class. If False, we return\n                                 a probability or indicator (depending on\n                                 --proba_threshold) for every possible class.\n  --model_profile TEXT           Defaults to 'full' which is slow and\n                                 accurate; can be 'fast' which is faster and\n                                 less accurate.\n  --weight_download_region TEXT  Defaults to 'us', can also be 'eu' or 'asia'.\n                                 Region for server to download weights.\n  --verbose                      Displays additional logging information\n                                 during processing.\n  --help                         Show this message and exit.\n```\n\n![demo](https://s3.amazonaws.com/drivendata-public-assets/zamba-demo.gif)\n\n\nOnce `zamba` is installed, you can execute it on any directory of video files. The tool does not recursively search directories, so all of the files must be at the top level of the directory. The algorithm will work the best with 15 second videos since that is what it is trained on, though it will sample frames from longer videos, which may be less reliable.\n\n**NOTE: `zamba` needs to download the \"weights\" files for the neural networks that it uses to make predictions. On first run it will download ~1GB of files with these weights.** Once these are downloaded, the tool will use the local versions and will not need to perform this download again.\n\n`zamba predict path/to/videos`\n\nBy default the output will be written to the file `output.csv` in the current directory. If the file exists, it will be overwritten.\n\n## Running the `zamba` test suite\n\nThe included `Makefile` contains code that uses pytest to run all tests in `zamba/tests`.\n\nThe command is (from the project root),\n\n```\n$ make test\n```\n\n### Testing End-To-End Prediction With `test_cnnensemble.py`\nThe test `tests/test_cnnensemble.py` runs an end-to-end prediction with `CnnEnsemble.predict(data_dir)` using a video that automatically gets downloaded along with the `input` directory (this and all required directories are downloaded upon instantiation of `CnnEnsemble` if they are not already present in the project).\n\nBy default this test is skipped due to the `pytest` decorator\n\n```\n@pytest.mark.skip(reason=\"This test takes hours to run, makes network calls, and is really for local dev only.\")\ndef test_predict():\n    data_dir = Path(__file__).parent.parent / \"models\" / \"cnnensemble\" / \"input\" / \"raw_test\"\n\n    manager = ModelManager('', model_class='cnnensemble', proba_threshold=0.5)\n    manager.predict(data_dir, save=True)\n```\n\nIt is reccomended that the **decorator be commented out in order to test end-to-end prediction locally**. However, this change should never be pushed, as the lightweight machines on codeship will not be happy, or able, to complete the end-to-end prediction.\n\nTo test end-to-end prediction using `make test` on a different set of videos, simply edit `data_dir`.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/drivendataorg/zamba/archive/0.1.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://zamba.drivendata.org", "keywords": "deep learning,camera,africa,classifier", "license": "", "maintainer": "", "maintainer_email": "", "name": "zamba", "package_url": "https://pypi.org/project/zamba/", "platform": "", "project_url": "https://pypi.org/project/zamba/", "project_urls": {"Documentation": "http://zamba.drivendata.org/docs/", "Download": "https://github.com/drivendataorg/zamba/archive/0.1.tar.gz", "DrivenData": "http://drivendata.co", "Homepage": "http://zamba.drivendata.org", "Source Code": "https://github.com/drivendataorg/zamba"}, "release_url": "https://pypi.org/project/zamba/0.1.6/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Zamba is a tool to identify the species seen in camera trap videos from sites in central Africa.", "version": "0.1.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>zamba - a command line interface for species classification</h1>\n<p><a href=\"https://app.codeship.com/projects/281856\" rel=\"nofollow\"> <img alt=\"Codeship Status for drivendataorg/chimps-tool\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d6456279da818596dd9a2f77bb638f1856dcb6c5/68747470733a2f2f6170702e636f6465736869702e636f6d2f70726f6a656374732f30336533613034302d306236642d303133362d616665342d3361656564633361323265312f7374617475733f6272616e63683d6d6173746572\"></a></p>\n<h3><a href=\"http://zamba.drivendata.org/\" rel=\"nofollow\">HOMEPAGE</a></h3>\n<h3><a href=\"http://zamba.drivendata.org/docs/\" rel=\"nofollow\">DOCUMENTATION</a></h3>\n<p><em>Zamba means \"forest\" in the Lingala language.</em></p>\n<p>Zamba is a command-line tool built in Python to automatically identify the species seen in camera trap videos from sites in central Africa. The tool makes predictions for 24 common species in these videos. For more information, see the documentation.</p>\n<p>The <code>zamba</code> command will be the entry point for users (see example usage below).</p>\n<h2>Prerequisites (for more detail, see <a href=\"http://zamba.drivendata.org/docs/\" rel=\"nofollow\">the documentation</a>)</h2>\n<ul>\n<li><a href=\"https://www.python.org/\" rel=\"nofollow\">Python</a> 3.6</li>\n<li><a href=\"https://www.ffmpeg.org/download.html\" rel=\"nofollow\">ffmpeg</a>, codecs for handling the video loading</li>\n</ul>\n<h2>Installing <code>zamba</code> (for more detail, see <a href=\"http://zamba.drivendata.org/docs/\" rel=\"nofollow\">the documentation</a>)</h2>\n<h3>GPU or CPU</h3>\n<p><code>zamba</code> is significantly faster when using a machine with a GPU instead of just a CPU. To use a GPU, you must be using an <a href=\"https://www.nvidia.com/Download/index.aspx?lang=en-us\" rel=\"nofollow\">nvidia gpu</a>, <a href=\"https://developer.nvidia.com/cuda-downloads\" rel=\"nofollow\">installed and configured CUDA</a>, and <a href=\"https://developer.nvidia.com/cudnn\" rel=\"nofollow\">installed and configured CuDNN</a> per their specifications. Once this is done, you can select to install the version of zamaba that uses <code>tensorflow</code> compiled for GPU.</p>\n<p>When a user installs <code>zamba</code> that user must specify to install the GPU or CPU version. If the user fails to make this specification, <strong>no version of tensorflow will be installed, thus everything will fail.</strong></p>\n<p>To install with <strong>tensorflow cpu</strong> (you do not have a GPU)</p>\n<pre><code>$ pip install zamba[cpu]\n</code></pre>\n<p>To install with <strong>tensorflow gpu</strong></p>\n<pre><code>$ pip install zamba[gpu]\n</code></pre>\n<h2>Example usage</h2>\n<p>Once zamba is installed, you can see the commands with <code>zamba</code>:</p>\n<p><code>zamba</code></p>\n<pre><code>Usage: zamba [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  predict  Identify species in a video.\n  train    [NOT IMPLEMENTED] Retrain network from...\n  tune     [NOT IMPLEMENTED] Update network with new...\n</code></pre>\n<p>And you can see the options you can pass to the <code>predict</code> command with:</p>\n<p><code>zamba predict --help</code></p>\n<pre><code>Usage: zamba predict [OPTIONS] [DATA_PATH] [PRED_PATH]\n\n  Identify species in a video.\n\n  This is a command line interface for prediction on camera trap footage.\n  Given a path to camera trap footage, the predict function use a deep\n  learning model to predict the presence or absense of a variety of species\n  of common interest to wildlife researchers working with camera trap data.\n\nOptions:\n  --tempdir PATH                 Path to temporary directory. If not\n                                 specified, OS temporary directory is used.\n  --proba_threshold FLOAT        Probability threshold for classification. if\n                                 specified binary predictions are returned\n                                 with 1 being greater than the threshold, 0\n                                 being less than or equal to. If not\n                                 specified, probabilities between 0 and 1 are\n                                 returned.\n  --output_class_names           If True, we just return a video and the name\n                                 of the most likely class. If False, we return\n                                 a probability or indicator (depending on\n                                 --proba_threshold) for every possible class.\n  --model_profile TEXT           Defaults to 'full' which is slow and\n                                 accurate; can be 'fast' which is faster and\n                                 less accurate.\n  --weight_download_region TEXT  Defaults to 'us', can also be 'eu' or 'asia'.\n                                 Region for server to download weights.\n  --verbose                      Displays additional logging information\n                                 during processing.\n  --help                         Show this message and exit.\n</code></pre>\n<p><img alt=\"demo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cc6842c1f2dc67987e9e179237718b946421637c/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f64726976656e646174612d7075626c69632d6173736574732f7a616d62612d64656d6f2e676966\"></p>\n<p>Once <code>zamba</code> is installed, you can execute it on any directory of video files. The tool does not recursively search directories, so all of the files must be at the top level of the directory. The algorithm will work the best with 15 second videos since that is what it is trained on, though it will sample frames from longer videos, which may be less reliable.</p>\n<p><strong>NOTE: <code>zamba</code> needs to download the \"weights\" files for the neural networks that it uses to make predictions. On first run it will download ~1GB of files with these weights.</strong> Once these are downloaded, the tool will use the local versions and will not need to perform this download again.</p>\n<p><code>zamba predict path/to/videos</code></p>\n<p>By default the output will be written to the file <code>output.csv</code> in the current directory. If the file exists, it will be overwritten.</p>\n<h2>Running the <code>zamba</code> test suite</h2>\n<p>The included <code>Makefile</code> contains code that uses pytest to run all tests in <code>zamba/tests</code>.</p>\n<p>The command is (from the project root),</p>\n<pre><code>$ make test\n</code></pre>\n<h3>Testing End-To-End Prediction With <code>test_cnnensemble.py</code></h3>\n<p>The test <code>tests/test_cnnensemble.py</code> runs an end-to-end prediction with <code>CnnEnsemble.predict(data_dir)</code> using a video that automatically gets downloaded along with the <code>input</code> directory (this and all required directories are downloaded upon instantiation of <code>CnnEnsemble</code> if they are not already present in the project).</p>\n<p>By default this test is skipped due to the <code>pytest</code> decorator</p>\n<pre><code>@pytest.mark.skip(reason=\"This test takes hours to run, makes network calls, and is really for local dev only.\")\ndef test_predict():\n    data_dir = Path(__file__).parent.parent / \"models\" / \"cnnensemble\" / \"input\" / \"raw_test\"\n\n    manager = ModelManager('', model_class='cnnensemble', proba_threshold=0.5)\n    manager.predict(data_dir, save=True)\n</code></pre>\n<p>It is reccomended that the <strong>decorator be commented out in order to test end-to-end prediction locally</strong>. However, this change should never be pushed, as the lightweight machines on codeship will not be happy, or able, to complete the end-to-end prediction.</p>\n<p>To test end-to-end prediction using <code>make test</code> on a different set of videos, simply edit <code>data_dir</code>.</p>\n\n          </div>"}, "last_serial": 3958950, "releases": {"0.1.3": [{"comment_text": "", "digests": {"md5": "3635ca261c5a11c7381d08f6f6f68959", "sha256": "e2f53f8c6c0f51e0d29d74b45f9af59e589c6eda10d05c1aaee052dc5465b65e"}, "downloads": -1, "filename": "zamba-0.1.3.tar.gz", "has_sig": false, "md5_digest": "3635ca261c5a11c7381d08f6f6f68959", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 27763, "upload_time": "2018-05-10T18:27:09", "upload_time_iso_8601": "2018-05-10T18:27:09.007138Z", "url": "https://files.pythonhosted.org/packages/49/3f/3afe679b1e3f6d86bb193451f37da1cc62bddeb6aae6b533f9f4aa0301e8/zamba-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "3218d885108b2b0ea4715a42e5df0d61", "sha256": "4ea6dabd68ba69eb4c87a6a3d7dcecf9a2147a765546217761a909e0e5cf4e23"}, "downloads": -1, "filename": "zamba-0.1.4.tar.gz", "has_sig": false, "md5_digest": "3218d885108b2b0ea4715a42e5df0d61", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 27762, "upload_time": "2018-05-10T18:43:00", "upload_time_iso_8601": "2018-05-10T18:43:00.177491Z", "url": "https://files.pythonhosted.org/packages/3f/ab/f0f18cf2cacc8f127c210e558fac5343043a3e27bdbd74b087696c3dbd3c/zamba-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "945121af4891ff0945bb062d69681d3e", "sha256": "a60a4fa654f01fd57588f7c2df53bb5ede0ef8b9e1d845ae611a888855f5b254"}, "downloads": -1, "filename": "zamba-0.1.5.tar.gz", "has_sig": false, "md5_digest": "945121af4891ff0945bb062d69681d3e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 25468, "upload_time": "2018-05-27T21:21:50", "upload_time_iso_8601": "2018-05-27T21:21:50.539345Z", "url": "https://files.pythonhosted.org/packages/88/a9/d7d42957b0ccff23d80ed4e5270421e98f6d3e37e23815a1ee14a37d25d3/zamba-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "be16d6974c92edc0b0a777ed2b2cbbd6", "sha256": "8f6fb4c2515a651afe4f899b454089adcb86d8f3d7cd7ccf455341f7cf5432ab"}, "downloads": -1, "filename": "zamba-0.1.6.tar.gz", "has_sig": false, "md5_digest": "be16d6974c92edc0b0a777ed2b2cbbd6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 27952, "upload_time": "2018-06-13T19:46:14", "upload_time_iso_8601": "2018-06-13T19:46:14.302375Z", "url": "https://files.pythonhosted.org/packages/32/37/2189f065966fb55f8e9e048f40376bc4a2922667f236ba85ef44274fa253/zamba-0.1.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "be16d6974c92edc0b0a777ed2b2cbbd6", "sha256": "8f6fb4c2515a651afe4f899b454089adcb86d8f3d7cd7ccf455341f7cf5432ab"}, "downloads": -1, "filename": "zamba-0.1.6.tar.gz", "has_sig": false, "md5_digest": "be16d6974c92edc0b0a777ed2b2cbbd6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 27952, "upload_time": "2018-06-13T19:46:14", "upload_time_iso_8601": "2018-06-13T19:46:14.302375Z", "url": "https://files.pythonhosted.org/packages/32/37/2189f065966fb55f8e9e048f40376bc4a2922667f236ba85ef44274fa253/zamba-0.1.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:19:55 2020"}