{"info": {"author": "anki", "author_email": "author@example.com", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Intended Audience :: End Users/Desktop", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Unix Shell", "Topic :: System :: Networking", "Topic :: System :: Shells", "Topic :: System :: System Shells", "Topic :: Terminals"], "description": "<p align=\"center\">\nGet identifiers, names, paths, URLs and words from the previous command output and use them for the next command in <a href=\"https://xon.sh\">xonsh</a>.\n</p>\n\n<table width=\"100%\">\n<col style=\"width:33%\">\n<col style=\"width:33%\">\n<col style=\"width:33%\">\n<tbody>\n<tr>\n<td valign=\"top\">\n<b>Save time</b>. Forget about using mouse, touchpad or trackball to get any words from output to the next command.\n</td>\n<td valign=\"top\">\n<b>Secure</b>. The xontrib-output-search is not writing any output on the hard disk. Only latest not empty output stored in the memory. It works the same way as xonsh shell and the security level is the same.\n</td>\n<td valign=\"top\">\n<b>Universal</b>. Forget about searching autocomplete plugins for every app you use and get the identifiers from the output.\n</td>\n</tr>\n</tbody>\n</table>\n\n<p align=\"center\">  \nIf you like the idea of xontrib-output-search click \u2b50 on the repo and stay tuned by watching releases.\n</p>\n\n## Install\n```shell script\nxpip install -U xontrib-output-search\necho 'xontrib load output_search' >> ~/.xonshrc\n# Reload xonsh\n```\n\n## Usage\nAfter `xontrib load output_search` you have two ways to select tokens from latest not empty output:\n* Press <kbd>Alt</kbd> + <kbd>F</kbd> hotkeys\n* Type `f__` and press <kbd>Tab</kbd> key  \n\n## Features\n#### Words tokenizing\n```shell script\n$ echo \"Hello world\"\nHello world\n$ echo The second word is wo<Alt+F>\n$ echo The second word is world\n```\nURL example:\n```shell script\n$ echo \"Try https://github.com/xxh/xxh\"\nTry https://github.com/xxh/xxh\n$ git clone xx<Alt+F>\n$ git clone https://github.com/xxh/xxh\n```\n\n#### JSON, Python dict and JavaScript object tokenizing\n```shell script\n$ echo '{\"Try\": \"xontrib-output-search\"}'\n{\"Try\": \"xontrib-output-search\"}\n$ echo I should try se<Alt+F>\n$ echo I should try xontrib-output-search\n```    \n\n#### env tokenizing\n```shell script\n$ env | grep ^PATH=\nPATH=/one/two:/three/four\n$ ls fo<Alt+F>\n$ ls /three/four\n```    \n\n#### Complex prefixes autocomplete\n\nGet the URL from previous output after typing `git+`:\n```shell script\n$ echo \"Try https://github.com/anki-code/xontrib-output-search\"\nTry https://github.com/anki-code/xontrib-output-search\n\n$ pip install git+xo<Alt+F>\n$ pip install git+https://github.com/anki-code/xontrib-output-search\n```\nGet the port number from previous output while typing the URL:\n```shell script\n$ echo \"The port number is 4242\"\nThe port number is 4242\n\n$ curl http://127.0.0.1:4<Alt+F>\n$ curl http://127.0.0.1:4242\n```\n\n## Development\n\n### Tokenizers\nTokenizer is a functions which extract tokens from the text.\n\n| Priority | Tokenizer  | Text  | Tokens |\n| ---------| ---------- | ----- | ------ |\n| 1        | **dict**   | `{\"key\": \"val as str\"}` | `['key', 'val as str']` |\n| 2        | **env**    | `PATH=/bin:/etc` | `['PATH', '/bin:/etc', '/bin', '/etc']` |   \n| 3        | **split**  | `Split  me \\n now!` | `['Split', 'me', 'now!']` |   \n| 4        | **strip**  | `{Hello}` | `['Hello']` |   \n\nYou can create your tokenizer and add it to `tokenizers_all` in `tokenize_output.py`.\n\nTokenizing is a recursive process where every tokenizer returns `final` and `new` tokens. \nThe `final` tokens directly go to the result list of tokens. The `new` tokens go to all \ntokenizers again to find new tokens. As result if there is a mix of json and env data \nin the output it will be found and tokenized in appropriate way.  \n\n### Test and debug\nRun tests:\n```shell script\ncd ~\ngit clone https://github.com/anki-code/xontrib-output-search\ncd xontrib-output-search\npytest\n```\nTo debug the tokenizer:\n```shell script\necho \"Hello world\" | python tokenize_outupt.py --pipe\n```\nCheck that `output_search` loaded:\n```shell script\n$ xontrib list output_search\noutput_search  installed  loaded\n\n$ completer list | grep output_search\nxontrib_output_search\n```\n\n## Known issues\n#### `cat file` is not captured\nWorkaround: `cat file | head`.\n\n#### Alt+F combination may not working in PyCharm terminal\nWorkaround: `f__` + <kbd>Tab</kbd>.\n\n## Thanks\nI was inspired by [xontrib-histcpy](https://github.com/con-f-use/xontrib-histcpy). Thanks @con-f-use!\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/anki-code/xontrib-output-search", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "xontrib-output-search", "package_url": "https://pypi.org/project/xontrib-output-search/", "platform": "any", "project_url": "https://pypi.org/project/xontrib-output-search/", "project_urls": {"Code": "https://github.com/anki-code/xontrib-output-search", "Documentation": "https://github.com/anki-code/xontrib-output-search/blob/master/README.md", "Homepage": "https://github.com/anki-code/xontrib-output-search", "Issue tracker": "https://github.com/anki-code/xontrib-output-search/issues"}, "release_url": "https://pypi.org/project/xontrib-output-search/0.4.0/", "requires_dist": ["demjson"], "requires_python": ">=3.6", "summary": "Get identifiers, names, paths, URLs and words from the previous command output and use them for the next command in xonsh.", "version": "0.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\">\nGet identifiers, names, paths, URLs and words from the previous command output and use them for the next command in <a href=\"https://xon.sh\" rel=\"nofollow\">xonsh</a>.\n</p>\n<table>\n<col>\n<col>\n<col>\n<tbody>\n<tr>\n<td>\n<b>Save time</b>. Forget about using mouse, touchpad or trackball to get any words from output to the next command.\n</td>\n<td>\n<b>Secure</b>. The xontrib-output-search is not writing any output on the hard disk. Only latest not empty output stored in the memory. It works the same way as xonsh shell and the security level is the same.\n</td>\n<td>\n<b>Universal</b>. Forget about searching autocomplete plugins for every app you use and get the identifiers from the output.\n</td>\n</tr>\n</tbody>\n</table>\n<p align=\"center\">  \nIf you like the idea of xontrib-output-search click \u2b50 on the repo and stay tuned by watching releases.\n</p>\n<h2>Install</h2>\n<pre>xpip install -U xontrib-output-search\n<span class=\"nb\">echo</span> <span class=\"s1\">'xontrib load output_search'</span> &gt;&gt; ~/.xonshrc\n<span class=\"c1\"># Reload xonsh</span>\n</pre>\n<h2>Usage</h2>\n<p>After <code>xontrib load output_search</code> you have two ways to select tokens from latest not empty output:</p>\n<ul>\n<li>Press <kbd>Alt</kbd> + <kbd>F</kbd> hotkeys</li>\n<li>Type <code>f__</code> and press <kbd>Tab</kbd> key</li>\n</ul>\n<h2>Features</h2>\n<h4>Words tokenizing</h4>\n<pre>$ <span class=\"nb\">echo</span> <span class=\"s2\">\"Hello world\"</span>\nHello world\n$ <span class=\"nb\">echo</span> The second word is wo&lt;Alt+F&gt;\n$ <span class=\"nb\">echo</span> The second word is world\n</pre>\n<p>URL example:</p>\n<pre>$ <span class=\"nb\">echo</span> <span class=\"s2\">\"Try https://github.com/xxh/xxh\"</span>\nTry https://github.com/xxh/xxh\n$ git clone xx&lt;Alt+F&gt;\n$ git clone https://github.com/xxh/xxh\n</pre>\n<h4>JSON, Python dict and JavaScript object tokenizing</h4>\n<pre>$ <span class=\"nb\">echo</span> <span class=\"s1\">'{\"Try\": \"xontrib-output-search\"}'</span>\n<span class=\"o\">{</span><span class=\"s2\">\"Try\"</span>: <span class=\"s2\">\"xontrib-output-search\"</span><span class=\"o\">}</span>\n$ <span class=\"nb\">echo</span> I should try se&lt;Alt+F&gt;\n$ <span class=\"nb\">echo</span> I should try xontrib-output-search\n</pre>\n<h4>env tokenizing</h4>\n<pre>$ env <span class=\"p\">|</span> grep ^PATH<span class=\"o\">=</span>\n<span class=\"nv\">PATH</span><span class=\"o\">=</span>/one/two:/three/four\n$ ls fo&lt;Alt+F&gt;\n$ ls /three/four\n</pre>\n<h4>Complex prefixes autocomplete</h4>\n<p>Get the URL from previous output after typing <code>git+</code>:</p>\n<pre>$ <span class=\"nb\">echo</span> <span class=\"s2\">\"Try https://github.com/anki-code/xontrib-output-search\"</span>\nTry https://github.com/anki-code/xontrib-output-search\n\n$ pip install git+xo&lt;Alt+F&gt;\n$ pip install git+https://github.com/anki-code/xontrib-output-search\n</pre>\n<p>Get the port number from previous output while typing the URL:</p>\n<pre>$ <span class=\"nb\">echo</span> <span class=\"s2\">\"The port number is 4242\"</span>\nThe port number is <span class=\"m\">4242</span>\n\n$ curl http://127.0.0.1:4&lt;Alt+F&gt;\n$ curl http://127.0.0.1:4242\n</pre>\n<h2>Development</h2>\n<h3>Tokenizers</h3>\n<p>Tokenizer is a functions which extract tokens from the text.</p>\n<table>\n<thead>\n<tr>\n<th>Priority</th>\n<th>Tokenizer</th>\n<th>Text</th>\n<th>Tokens</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td><strong>dict</strong></td>\n<td><code>{\"key\": \"val as str\"}</code></td>\n<td><code>['key', 'val as str']</code></td>\n</tr>\n<tr>\n<td>2</td>\n<td><strong>env</strong></td>\n<td><code>PATH=/bin:/etc</code></td>\n<td><code>['PATH', '/bin:/etc', '/bin', '/etc']</code></td>\n</tr>\n<tr>\n<td>3</td>\n<td><strong>split</strong></td>\n<td><code>Split me \\n now!</code></td>\n<td><code>['Split', 'me', 'now!']</code></td>\n</tr>\n<tr>\n<td>4</td>\n<td><strong>strip</strong></td>\n<td><code>{Hello}</code></td>\n<td><code>['Hello']</code></td>\n</tr></tbody></table>\n<p>You can create your tokenizer and add it to <code>tokenizers_all</code> in <code>tokenize_output.py</code>.</p>\n<p>Tokenizing is a recursive process where every tokenizer returns <code>final</code> and <code>new</code> tokens.\nThe <code>final</code> tokens directly go to the result list of tokens. The <code>new</code> tokens go to all\ntokenizers again to find new tokens. As result if there is a mix of json and env data\nin the output it will be found and tokenized in appropriate way.</p>\n<h3>Test and debug</h3>\n<p>Run tests:</p>\n<pre><span class=\"nb\">cd</span> ~\ngit clone https://github.com/anki-code/xontrib-output-search\n<span class=\"nb\">cd</span> xontrib-output-search\npytest\n</pre>\n<p>To debug the tokenizer:</p>\n<pre><span class=\"nb\">echo</span> <span class=\"s2\">\"Hello world\"</span> <span class=\"p\">|</span> python tokenize_outupt.py --pipe\n</pre>\n<p>Check that <code>output_search</code> loaded:</p>\n<pre>$ xontrib list output_search\noutput_search  installed  loaded\n\n$ completer list <span class=\"p\">|</span> grep output_search\nxontrib_output_search\n</pre>\n<h2>Known issues</h2>\n<h4><code>cat file</code> is not captured</h4>\n<p>Workaround: <code>cat file | head</code>.</p>\n<h4>Alt+F combination may not working in PyCharm terminal</h4>\n<p>Workaround: <code>f__</code> + <kbd>Tab</kbd>.</p>\n<h2>Thanks</h2>\n<p>I was inspired by <a href=\"https://github.com/con-f-use/xontrib-histcpy\" rel=\"nofollow\">xontrib-histcpy</a>. Thanks @con-f-use!</p>\n\n          </div>"}, "last_serial": 7170574, "releases": {"0.4.0": [{"comment_text": "", "digests": {"md5": "ac87ced201be5513138d430f63f68c1d", "sha256": "882489364165139392f882e5541a3007316fd7729add17e6df66a301f3f42595"}, "downloads": -1, "filename": "xontrib_output_search-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ac87ced201be5513138d430f63f68c1d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8364, "upload_time": "2020-05-05T09:19:05", "upload_time_iso_8601": "2020-05-05T09:19:05.050690Z", "url": "https://files.pythonhosted.org/packages/30/21/d024e9ea1e9f801cfcd8e36a82fbaf4a2f7127e9ac3beb54031573bc7b56/xontrib_output_search-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6db7eac96beffb39b7c41c1c357c66c", "sha256": "67cf8eb06f4cb666f9124515099d49d8ec3f381580a310dc5f70a9f3fa3637ca"}, "downloads": -1, "filename": "xontrib-output-search-0.4.0.tar.gz", "has_sig": false, "md5_digest": "a6db7eac96beffb39b7c41c1c357c66c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8769, "upload_time": "2020-05-05T09:19:07", "upload_time_iso_8601": "2020-05-05T09:19:07.240061Z", "url": "https://files.pythonhosted.org/packages/66/3d/573afbc88f7ece25d9a4e81c718b76cdf89f769e9b293f9f1fa03659a241/xontrib-output-search-0.4.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ac87ced201be5513138d430f63f68c1d", "sha256": "882489364165139392f882e5541a3007316fd7729add17e6df66a301f3f42595"}, "downloads": -1, "filename": "xontrib_output_search-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "ac87ced201be5513138d430f63f68c1d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8364, "upload_time": "2020-05-05T09:19:05", "upload_time_iso_8601": "2020-05-05T09:19:05.050690Z", "url": "https://files.pythonhosted.org/packages/30/21/d024e9ea1e9f801cfcd8e36a82fbaf4a2f7127e9ac3beb54031573bc7b56/xontrib_output_search-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a6db7eac96beffb39b7c41c1c357c66c", "sha256": "67cf8eb06f4cb666f9124515099d49d8ec3f381580a310dc5f70a9f3fa3637ca"}, "downloads": -1, "filename": "xontrib-output-search-0.4.0.tar.gz", "has_sig": false, "md5_digest": "a6db7eac96beffb39b7c41c1c357c66c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8769, "upload_time": "2020-05-05T09:19:07", "upload_time_iso_8601": "2020-05-05T09:19:07.240061Z", "url": "https://files.pythonhosted.org/packages/66/3d/573afbc88f7ece25d9a4e81c718b76cdf89f769e9b293f9f1fa03659a241/xontrib-output-search-0.4.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:24:44 2020"}