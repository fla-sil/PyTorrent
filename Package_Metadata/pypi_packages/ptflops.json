{"info": {"author": "Vladislav Sovrasov", "author_email": "sovrasov.vlad@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3"], "description": "# Flops counter for convolutional networks in pytorch framework\n[![Pypi version](https://img.shields.io/pypi/v/ptflops.svg)](https://pypi.org/project/ptflops/)\n\nThis script is designed to compute the theoretical amount of multiply-add operations\nin convolutional neural networks. It also can compute the number of parameters and\nprint per-layer computational cost of a given network.\n\nSupported layers:\n- Conv1d/2d/3d (including grouping)\n- ConvTranspose2d (including grouping)\n- BatchNorm1d/2d/3d\n- Activations (ReLU, PReLU, ELU, ReLU6, LeakyReLU)\n- Linear\n- Upsample\n- Poolings (AvgPool1d/2d/3d, MaxPool1d/2d/3d and adaptive ones)\n\nExperimental support:\n- RNN, LSTM, GRU (NLH layout is assumed).\n- RNNCell, LSTMCell, GRUCell.\n\nRequirements: Pytorch >= 0.4.1, torchvision >= 0.2.1\n\nThanks to @warmspringwinds for the initial version of script.\n\n## Usage tips\n\n- This script doesn't take into account `torch.nn.functional.*` operations. For an instance, if one have a semantic segmentation model and use `torch.nn.functional.interpolate` to upscale features, these operations won't contribute to overall amount of flops. To avoid that one can use `torch.nn.Upsample` instead of `torch.nn.functional.interpolate`.\n- `ptflops` launches a given model on a random tensor and estimates amount of computations during inference. Complicated models can have several inputs, some of them could be optional. To construct non-trivial input one can use the `input_constructor` argument of the `get_model_complexity_info`. `input_constructor` is a function that takes the input spatial resolution as a tuple and returns a dict with named input arguments of the model. Next this dict would be passed to the model as keyworded arguments.\n- `verbose` parameter allows to get information about modules that don't contribute to the final numbers.\n- `ignore_modules` option forces `ptflops` to ignore the listed modules. This can be useful\nfor research purposes. For an instance, one can drop all convolutuions from the counting process\nspecifying `ignore_modules=[torch.nn.Conv2d]`.\n\n## Install the latest version\n```bash\npip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n```\n\n## Example\n```python\nimport torchvision.models as models\nimport torch\nfrom ptflops import get_model_complexity_info\n\nwith torch.cuda.device(0):\n  net = models.densenet161()\n  macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n                                           print_per_layer_stat=True, verbose=True)\n  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n  print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n```\n\n## Benchmark\n\n### [torchvision](https://pytorch.org/docs/1.0.0/torchvision/models.html)\n\nModel         | Input Resolution | Params(M) | MACs(G) | Top-1 error | Top-5 error\n---           |---               |---        |---      |---          |---\nalexnet       |224x224           | 61.1      | 0.72    | 43.45       | 20.91\nvgg11         |224x224           | 132.86    | 7.63    | 30.98       | 11.37\nvgg13         |224x224           | 133.05    | 11.34   | 30.07       | 10.75\nvgg16         |224x224           | 138.36    | 15.5    | 28.41       | 9.62\nvgg19         |224x224           | 143.67    | 19.67   | 27.62       | 9.12\nvgg11_bn      |224x224           | 132.87    | 7.64    | 29.62       | 10.19\nvgg13_bn      |224x224           | 133.05    | 11.36   | 28.45       | 9.63\nvgg16_bn      |224x224           | 138.37    | 15.53   | 26.63       | 8.50\nvgg19_bn      |224x224           | 143.68    | 19.7    | 25.76       | 8.15\nresnet18      |224x224           | 11.69     | 1.82    | 30.24       | 10.92\nresnet34      |224x224           | 21.8      | 3.68    | 26.70       | 8.58\nresnet50      |224x224           | 25.56     | 4.12    | 23.85       | 7.13\nresnet101     |224x224           | 44.55     | 7.85    | 22.63       | 6.44\nresnet152     |224x224           | 60.19     | 11.58   | 21.69       | 5.94\nsqueezenet1_0 |224x224           | 1.25      | 0.83    | 41.90       | 19.58\nsqueezenet1_1 |224x224           | 1.24      | 0.36    | 41.81       | 19.38\ndensenet121   |224x224           | 7.98      | 2.88    | 25.35       | 7.83\ndensenet169   |224x224           | 14.15     | 3.42    | 24.00       | 7.00\ndensenet201   |224x224           | 20.01     | 4.37    | 22.80       | 6.43\ndensenet161   |224x224           | 28.68     | 7.82    | 22.35       | 6.20\ninception_v3  |224x224           | 27.16     | 2.85    | 22.55       | 6.44\n\n* Top-1 error - ImageNet single-crop top-1 error (224x224)\n* Top-5 error - ImageNet single-crop top-5 error (224x224)\n\n### [Cadene/pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch)\n\nModel               | Input Resolution | Params(M) | MACs(G)     | Acc@1       | Acc@5\n---                 |---               |---        |---          |---          |---\nalexnet             | 224x224          | 61.1      | 0.72        | 56.432      | 79.194\nbninception         | 224x224          | 11.3      | 2.05        | 73.524      | 91.562\ncafferesnet101      | 224x224          | 44.55     | 7.62        | 76.2        | 92.766\ndensenet121         | 224x224          | 7.98      | 2.88        | 74.646      | 92.136\ndensenet161         | 224x224          | 28.68     | 7.82        | 77.56       | 93.798\ndensenet169         | 224x224          | 14.15     | 3.42        | 76.026      | 92.992\ndensenet201         | 224x224          | 20.01     | 4.37        | 77.152      | 93.548\ndpn107              | 224x224          | 86.92     | 18.42       | 79.746      | 94.684\ndpn131              | 224x224          | 79.25     | 16.13       | 79.432      | 94.574\ndpn68               | 224x224          | 12.61     | 2.36        | 75.868      | 92.774\ndpn68b              | 224x224          | 12.61     | 2.36        | 77.034      | 93.59\ndpn92               | 224x224          | 37.67     | 6.56        | 79.4        | 94.62\ndpn98               | 224x224          | 61.57     | 11.76       | 79.224      | 94.488\nfbresnet152         | 224x224          | 60.27     | 11.6        | 77.386      | 93.594\ninceptionresnetv2   | 299x299          | 55.84     | 13.22       | 80.17       | 95.234\ninceptionv3         | 299x299          | 27.16     | 5.73        | 77.294      | 93.454\ninceptionv4         | 299x299          | 42.68     | 12.31       | 80.062      | 94.926\nnasnetalarge        | 331x331          | 88.75     | 24.04       | 82.566      | 96.086\nnasnetamobile       | 224x224          | 5.29      | 0.59        | 74.08       | 91.74\npnasnet5large       | 331x331          | 86.06     | 25.21       | 82.736      | 95.992\npolynet             | 331x331          | 95.37     | 34.9        | 81.002      | 95.624\nresnet101           | 224x224          | 44.55     | 7.85        | 77.438      | 93.672\nresnet152           | 224x224          | 60.19     | 11.58       | 78.428      | 94.11\nresnet18            | 224x224          | 11.69     | 1.82        | 70.142      | 89.274\nresnet34            | 224x224          | 21.8      | 3.68        | 73.554      | 91.456\nresnet50            | 224x224          | 25.56     | 4.12        | 76.002      | 92.98\nresnext101_32x4d    | 224x224          | 44.18     | 8.03        | 78.188      | 93.886\nresnext101_64x4d    | 224x224          | 83.46     | 15.55       | 78.956      | 94.252\nse_resnet101        | 224x224          | 49.33     | 7.63        | 78.396      | 94.258\nse_resnet152        | 224x224          | 66.82     | 11.37       | 78.658      | 94.374\nse_resnet50         | 224x224          | 28.09     | 3.9         | 77.636      | 93.752\nse_resnext101_32x4d | 224x224          | 48.96     | 8.05        | 80.236      | 95.028\nse_resnext50_32x4d  | 224x224          | 27.56     | 4.28        | 79.076      | 94.434\nsenet154            | 224x224          | 115.09    | 20.82       | 81.304      | 95.498\nsqueezenet1_0       | 224x224          | 1.25      | 0.83        | 58.108      | 80.428\nsqueezenet1_1       | 224x224          | 1.24      | 0.36        | 58.25       | 80.8\nvgg11               | 224x224          | 132.86    | 7.63        | 68.97       | 88.746\nvgg11_bn            | 224x224          | 132.87    | 7.64        | 70.452      | 89.818\nvgg13               | 224x224          | 133.05    | 11.34       | 69.662      | 89.264\nvgg13_bn            | 224x224          | 133.05    | 11.36       | 71.508      | 90.494\nvgg16               | 224x224          | 138.36    | 15.5        | 71.636      | 90.354\nvgg16_bn            | 224x224          | 138.37    | 15.53       | 73.518      | 91.608\nvgg19               | 224x224          | 143.67    | 19.67       | 72.08       | 90.822\nvgg19_bn            | 224x224          | 143.68    | 19.7        | 74.266      | 92.066\nxception            | 299x299          | 22.86     | 8.42        | 78.888      | 94.292\n\n* Acc@1 - ImageNet single-crop top-1 accuracy on validation images of the same size used during the training process.\n* Acc@5 - ImageNet single-crop top-5 accuracy on validation images of the same size used during the training process.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sovrasov/flops-counter.pytorch", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "ptflops", "package_url": "https://pypi.org/project/ptflops/", "platform": "", "project_url": "https://pypi.org/project/ptflops/", "project_urls": {"Homepage": "https://github.com/sovrasov/flops-counter.pytorch"}, "release_url": "https://pypi.org/project/ptflops/0.6.1/", "requires_dist": null, "requires_python": "", "summary": "Flops counter for convolutional networks in pytorch framework", "version": "0.6.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Flops counter for convolutional networks in pytorch framework</h1>\n<p><a href=\"https://pypi.org/project/ptflops/\" rel=\"nofollow\"><img alt=\"Pypi version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2433e8976c9c0cb1c99091edd2848ea9a2deef2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7074666c6f70732e737667\"></a></p>\n<p>This script is designed to compute the theoretical amount of multiply-add operations\nin convolutional neural networks. It also can compute the number of parameters and\nprint per-layer computational cost of a given network.</p>\n<p>Supported layers:</p>\n<ul>\n<li>Conv1d/2d/3d (including grouping)</li>\n<li>ConvTranspose2d (including grouping)</li>\n<li>BatchNorm1d/2d/3d</li>\n<li>Activations (ReLU, PReLU, ELU, ReLU6, LeakyReLU)</li>\n<li>Linear</li>\n<li>Upsample</li>\n<li>Poolings (AvgPool1d/2d/3d, MaxPool1d/2d/3d and adaptive ones)</li>\n</ul>\n<p>Experimental support:</p>\n<ul>\n<li>RNN, LSTM, GRU (NLH layout is assumed).</li>\n<li>RNNCell, LSTMCell, GRUCell.</li>\n</ul>\n<p>Requirements: Pytorch &gt;= 0.4.1, torchvision &gt;= 0.2.1</p>\n<p>Thanks to @warmspringwinds for the initial version of script.</p>\n<h2>Usage tips</h2>\n<ul>\n<li>This script doesn't take into account <code>torch.nn.functional.*</code> operations. For an instance, if one have a semantic segmentation model and use <code>torch.nn.functional.interpolate</code> to upscale features, these operations won't contribute to overall amount of flops. To avoid that one can use <code>torch.nn.Upsample</code> instead of <code>torch.nn.functional.interpolate</code>.</li>\n<li><code>ptflops</code> launches a given model on a random tensor and estimates amount of computations during inference. Complicated models can have several inputs, some of them could be optional. To construct non-trivial input one can use the <code>input_constructor</code> argument of the <code>get_model_complexity_info</code>. <code>input_constructor</code> is a function that takes the input spatial resolution as a tuple and returns a dict with named input arguments of the model. Next this dict would be passed to the model as keyworded arguments.</li>\n<li><code>verbose</code> parameter allows to get information about modules that don't contribute to the final numbers.</li>\n<li><code>ignore_modules</code> option forces <code>ptflops</code> to ignore the listed modules. This can be useful\nfor research purposes. For an instance, one can drop all convolutuions from the counting process\nspecifying <code>ignore_modules=[torch.nn.Conv2d]</code>.</li>\n</ul>\n<h2>Install the latest version</h2>\n<pre>pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n</pre>\n<h2>Example</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision.models</span> <span class=\"k\">as</span> <span class=\"nn\">models</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">ptflops</span> <span class=\"kn\">import</span> <span class=\"n\">get_model_complexity_info</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n  <span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">densenet161</span><span class=\"p\">()</span>\n  <span class=\"n\">macs</span><span class=\"p\">,</span> <span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">get_model_complexity_info</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">),</span> <span class=\"n\">as_strings</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n                                           <span class=\"n\">print_per_layer_stat</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'</span><span class=\"si\">{:&lt;30}</span><span class=\"s1\">  </span><span class=\"si\">{:&lt;8}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"s1\">'Computational complexity: '</span><span class=\"p\">,</span> <span class=\"n\">macs</span><span class=\"p\">))</span>\n  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'</span><span class=\"si\">{:&lt;30}</span><span class=\"s1\">  </span><span class=\"si\">{:&lt;8}</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"s1\">'Number of parameters: '</span><span class=\"p\">,</span> <span class=\"n\">params</span><span class=\"p\">))</span>\n</pre>\n<h2>Benchmark</h2>\n<h3><a href=\"https://pytorch.org/docs/1.0.0/torchvision/models.html\" rel=\"nofollow\">torchvision</a></h3>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Input Resolution</th>\n<th>Params(M)</th>\n<th>MACs(G)</th>\n<th>Top-1 error</th>\n<th>Top-5 error</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alexnet</td>\n<td>224x224</td>\n<td>61.1</td>\n<td>0.72</td>\n<td>43.45</td>\n<td>20.91</td>\n</tr>\n<tr>\n<td>vgg11</td>\n<td>224x224</td>\n<td>132.86</td>\n<td>7.63</td>\n<td>30.98</td>\n<td>11.37</td>\n</tr>\n<tr>\n<td>vgg13</td>\n<td>224x224</td>\n<td>133.05</td>\n<td>11.34</td>\n<td>30.07</td>\n<td>10.75</td>\n</tr>\n<tr>\n<td>vgg16</td>\n<td>224x224</td>\n<td>138.36</td>\n<td>15.5</td>\n<td>28.41</td>\n<td>9.62</td>\n</tr>\n<tr>\n<td>vgg19</td>\n<td>224x224</td>\n<td>143.67</td>\n<td>19.67</td>\n<td>27.62</td>\n<td>9.12</td>\n</tr>\n<tr>\n<td>vgg11_bn</td>\n<td>224x224</td>\n<td>132.87</td>\n<td>7.64</td>\n<td>29.62</td>\n<td>10.19</td>\n</tr>\n<tr>\n<td>vgg13_bn</td>\n<td>224x224</td>\n<td>133.05</td>\n<td>11.36</td>\n<td>28.45</td>\n<td>9.63</td>\n</tr>\n<tr>\n<td>vgg16_bn</td>\n<td>224x224</td>\n<td>138.37</td>\n<td>15.53</td>\n<td>26.63</td>\n<td>8.50</td>\n</tr>\n<tr>\n<td>vgg19_bn</td>\n<td>224x224</td>\n<td>143.68</td>\n<td>19.7</td>\n<td>25.76</td>\n<td>8.15</td>\n</tr>\n<tr>\n<td>resnet18</td>\n<td>224x224</td>\n<td>11.69</td>\n<td>1.82</td>\n<td>30.24</td>\n<td>10.92</td>\n</tr>\n<tr>\n<td>resnet34</td>\n<td>224x224</td>\n<td>21.8</td>\n<td>3.68</td>\n<td>26.70</td>\n<td>8.58</td>\n</tr>\n<tr>\n<td>resnet50</td>\n<td>224x224</td>\n<td>25.56</td>\n<td>4.12</td>\n<td>23.85</td>\n<td>7.13</td>\n</tr>\n<tr>\n<td>resnet101</td>\n<td>224x224</td>\n<td>44.55</td>\n<td>7.85</td>\n<td>22.63</td>\n<td>6.44</td>\n</tr>\n<tr>\n<td>resnet152</td>\n<td>224x224</td>\n<td>60.19</td>\n<td>11.58</td>\n<td>21.69</td>\n<td>5.94</td>\n</tr>\n<tr>\n<td>squeezenet1_0</td>\n<td>224x224</td>\n<td>1.25</td>\n<td>0.83</td>\n<td>41.90</td>\n<td>19.58</td>\n</tr>\n<tr>\n<td>squeezenet1_1</td>\n<td>224x224</td>\n<td>1.24</td>\n<td>0.36</td>\n<td>41.81</td>\n<td>19.38</td>\n</tr>\n<tr>\n<td>densenet121</td>\n<td>224x224</td>\n<td>7.98</td>\n<td>2.88</td>\n<td>25.35</td>\n<td>7.83</td>\n</tr>\n<tr>\n<td>densenet169</td>\n<td>224x224</td>\n<td>14.15</td>\n<td>3.42</td>\n<td>24.00</td>\n<td>7.00</td>\n</tr>\n<tr>\n<td>densenet201</td>\n<td>224x224</td>\n<td>20.01</td>\n<td>4.37</td>\n<td>22.80</td>\n<td>6.43</td>\n</tr>\n<tr>\n<td>densenet161</td>\n<td>224x224</td>\n<td>28.68</td>\n<td>7.82</td>\n<td>22.35</td>\n<td>6.20</td>\n</tr>\n<tr>\n<td>inception_v3</td>\n<td>224x224</td>\n<td>27.16</td>\n<td>2.85</td>\n<td>22.55</td>\n<td>6.44</td>\n</tr></tbody></table>\n<ul>\n<li>Top-1 error - ImageNet single-crop top-1 error (224x224)</li>\n<li>Top-5 error - ImageNet single-crop top-5 error (224x224)</li>\n</ul>\n<h3><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">Cadene/pretrained-models.pytorch</a></h3>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Input Resolution</th>\n<th>Params(M)</th>\n<th>MACs(G)</th>\n<th>Acc@1</th>\n<th>Acc@5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alexnet</td>\n<td>224x224</td>\n<td>61.1</td>\n<td>0.72</td>\n<td>56.432</td>\n<td>79.194</td>\n</tr>\n<tr>\n<td>bninception</td>\n<td>224x224</td>\n<td>11.3</td>\n<td>2.05</td>\n<td>73.524</td>\n<td>91.562</td>\n</tr>\n<tr>\n<td>cafferesnet101</td>\n<td>224x224</td>\n<td>44.55</td>\n<td>7.62</td>\n<td>76.2</td>\n<td>92.766</td>\n</tr>\n<tr>\n<td>densenet121</td>\n<td>224x224</td>\n<td>7.98</td>\n<td>2.88</td>\n<td>74.646</td>\n<td>92.136</td>\n</tr>\n<tr>\n<td>densenet161</td>\n<td>224x224</td>\n<td>28.68</td>\n<td>7.82</td>\n<td>77.56</td>\n<td>93.798</td>\n</tr>\n<tr>\n<td>densenet169</td>\n<td>224x224</td>\n<td>14.15</td>\n<td>3.42</td>\n<td>76.026</td>\n<td>92.992</td>\n</tr>\n<tr>\n<td>densenet201</td>\n<td>224x224</td>\n<td>20.01</td>\n<td>4.37</td>\n<td>77.152</td>\n<td>93.548</td>\n</tr>\n<tr>\n<td>dpn107</td>\n<td>224x224</td>\n<td>86.92</td>\n<td>18.42</td>\n<td>79.746</td>\n<td>94.684</td>\n</tr>\n<tr>\n<td>dpn131</td>\n<td>224x224</td>\n<td>79.25</td>\n<td>16.13</td>\n<td>79.432</td>\n<td>94.574</td>\n</tr>\n<tr>\n<td>dpn68</td>\n<td>224x224</td>\n<td>12.61</td>\n<td>2.36</td>\n<td>75.868</td>\n<td>92.774</td>\n</tr>\n<tr>\n<td>dpn68b</td>\n<td>224x224</td>\n<td>12.61</td>\n<td>2.36</td>\n<td>77.034</td>\n<td>93.59</td>\n</tr>\n<tr>\n<td>dpn92</td>\n<td>224x224</td>\n<td>37.67</td>\n<td>6.56</td>\n<td>79.4</td>\n<td>94.62</td>\n</tr>\n<tr>\n<td>dpn98</td>\n<td>224x224</td>\n<td>61.57</td>\n<td>11.76</td>\n<td>79.224</td>\n<td>94.488</td>\n</tr>\n<tr>\n<td>fbresnet152</td>\n<td>224x224</td>\n<td>60.27</td>\n<td>11.6</td>\n<td>77.386</td>\n<td>93.594</td>\n</tr>\n<tr>\n<td>inceptionresnetv2</td>\n<td>299x299</td>\n<td>55.84</td>\n<td>13.22</td>\n<td>80.17</td>\n<td>95.234</td>\n</tr>\n<tr>\n<td>inceptionv3</td>\n<td>299x299</td>\n<td>27.16</td>\n<td>5.73</td>\n<td>77.294</td>\n<td>93.454</td>\n</tr>\n<tr>\n<td>inceptionv4</td>\n<td>299x299</td>\n<td>42.68</td>\n<td>12.31</td>\n<td>80.062</td>\n<td>94.926</td>\n</tr>\n<tr>\n<td>nasnetalarge</td>\n<td>331x331</td>\n<td>88.75</td>\n<td>24.04</td>\n<td>82.566</td>\n<td>96.086</td>\n</tr>\n<tr>\n<td>nasnetamobile</td>\n<td>224x224</td>\n<td>5.29</td>\n<td>0.59</td>\n<td>74.08</td>\n<td>91.74</td>\n</tr>\n<tr>\n<td>pnasnet5large</td>\n<td>331x331</td>\n<td>86.06</td>\n<td>25.21</td>\n<td>82.736</td>\n<td>95.992</td>\n</tr>\n<tr>\n<td>polynet</td>\n<td>331x331</td>\n<td>95.37</td>\n<td>34.9</td>\n<td>81.002</td>\n<td>95.624</td>\n</tr>\n<tr>\n<td>resnet101</td>\n<td>224x224</td>\n<td>44.55</td>\n<td>7.85</td>\n<td>77.438</td>\n<td>93.672</td>\n</tr>\n<tr>\n<td>resnet152</td>\n<td>224x224</td>\n<td>60.19</td>\n<td>11.58</td>\n<td>78.428</td>\n<td>94.11</td>\n</tr>\n<tr>\n<td>resnet18</td>\n<td>224x224</td>\n<td>11.69</td>\n<td>1.82</td>\n<td>70.142</td>\n<td>89.274</td>\n</tr>\n<tr>\n<td>resnet34</td>\n<td>224x224</td>\n<td>21.8</td>\n<td>3.68</td>\n<td>73.554</td>\n<td>91.456</td>\n</tr>\n<tr>\n<td>resnet50</td>\n<td>224x224</td>\n<td>25.56</td>\n<td>4.12</td>\n<td>76.002</td>\n<td>92.98</td>\n</tr>\n<tr>\n<td>resnext101_32x4d</td>\n<td>224x224</td>\n<td>44.18</td>\n<td>8.03</td>\n<td>78.188</td>\n<td>93.886</td>\n</tr>\n<tr>\n<td>resnext101_64x4d</td>\n<td>224x224</td>\n<td>83.46</td>\n<td>15.55</td>\n<td>78.956</td>\n<td>94.252</td>\n</tr>\n<tr>\n<td>se_resnet101</td>\n<td>224x224</td>\n<td>49.33</td>\n<td>7.63</td>\n<td>78.396</td>\n<td>94.258</td>\n</tr>\n<tr>\n<td>se_resnet152</td>\n<td>224x224</td>\n<td>66.82</td>\n<td>11.37</td>\n<td>78.658</td>\n<td>94.374</td>\n</tr>\n<tr>\n<td>se_resnet50</td>\n<td>224x224</td>\n<td>28.09</td>\n<td>3.9</td>\n<td>77.636</td>\n<td>93.752</td>\n</tr>\n<tr>\n<td>se_resnext101_32x4d</td>\n<td>224x224</td>\n<td>48.96</td>\n<td>8.05</td>\n<td>80.236</td>\n<td>95.028</td>\n</tr>\n<tr>\n<td>se_resnext50_32x4d</td>\n<td>224x224</td>\n<td>27.56</td>\n<td>4.28</td>\n<td>79.076</td>\n<td>94.434</td>\n</tr>\n<tr>\n<td>senet154</td>\n<td>224x224</td>\n<td>115.09</td>\n<td>20.82</td>\n<td>81.304</td>\n<td>95.498</td>\n</tr>\n<tr>\n<td>squeezenet1_0</td>\n<td>224x224</td>\n<td>1.25</td>\n<td>0.83</td>\n<td>58.108</td>\n<td>80.428</td>\n</tr>\n<tr>\n<td>squeezenet1_1</td>\n<td>224x224</td>\n<td>1.24</td>\n<td>0.36</td>\n<td>58.25</td>\n<td>80.8</td>\n</tr>\n<tr>\n<td>vgg11</td>\n<td>224x224</td>\n<td>132.86</td>\n<td>7.63</td>\n<td>68.97</td>\n<td>88.746</td>\n</tr>\n<tr>\n<td>vgg11_bn</td>\n<td>224x224</td>\n<td>132.87</td>\n<td>7.64</td>\n<td>70.452</td>\n<td>89.818</td>\n</tr>\n<tr>\n<td>vgg13</td>\n<td>224x224</td>\n<td>133.05</td>\n<td>11.34</td>\n<td>69.662</td>\n<td>89.264</td>\n</tr>\n<tr>\n<td>vgg13_bn</td>\n<td>224x224</td>\n<td>133.05</td>\n<td>11.36</td>\n<td>71.508</td>\n<td>90.494</td>\n</tr>\n<tr>\n<td>vgg16</td>\n<td>224x224</td>\n<td>138.36</td>\n<td>15.5</td>\n<td>71.636</td>\n<td>90.354</td>\n</tr>\n<tr>\n<td>vgg16_bn</td>\n<td>224x224</td>\n<td>138.37</td>\n<td>15.53</td>\n<td>73.518</td>\n<td>91.608</td>\n</tr>\n<tr>\n<td>vgg19</td>\n<td>224x224</td>\n<td>143.67</td>\n<td>19.67</td>\n<td>72.08</td>\n<td>90.822</td>\n</tr>\n<tr>\n<td>vgg19_bn</td>\n<td>224x224</td>\n<td>143.68</td>\n<td>19.7</td>\n<td>74.266</td>\n<td>92.066</td>\n</tr>\n<tr>\n<td>xception</td>\n<td>299x299</td>\n<td>22.86</td>\n<td>8.42</td>\n<td>78.888</td>\n<td>94.292</td>\n</tr></tbody></table>\n<ul>\n<li>Acc@1 - ImageNet single-crop top-1 accuracy on validation images of the same size used during the training process.</li>\n<li>Acc@5 - ImageNet single-crop top-5 accuracy on validation images of the same size used during the training process.</li>\n</ul>\n\n          </div>"}, "last_serial": 7094266, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "9d2fb8fd73450c163bfbf70463f3362b", "sha256": "fdb76159aa1957367e6a7d31dc69f85788164898174b0a27595dd5bd1c39fcf3"}, "downloads": -1, "filename": "ptflops-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9d2fb8fd73450c163bfbf70463f3362b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5456, "upload_time": "2019-04-09T14:59:31", "upload_time_iso_8601": "2019-04-09T14:59:31.088109Z", "url": "https://files.pythonhosted.org/packages/fd/48/707af5fc4c87623b033d16ee0af4eb9310ed41e5881040cbdffa6fb9d7ec/ptflops-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a915dff6a886636d29320cf00be9c3f2", "sha256": "b24fd5e04c9568e8269baad15545c3fe06a5265fd6e923141da83812b1a0563c"}, "downloads": -1, "filename": "ptflops-0.1.tar.gz", "has_sig": false, "md5_digest": "a915dff6a886636d29320cf00be9c3f2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4149, "upload_time": "2019-04-09T14:59:33", "upload_time_iso_8601": "2019-04-09T14:59:33.141731Z", "url": "https://files.pythonhosted.org/packages/cf/20/7e928eb0aab7cf4a457dbe1b82404be8b8211751927691345ab11a463744/ptflops-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "cae968741f5f8558a6db5ffdf6ff9a1d", "sha256": "130b7920bf5993bb28a5daf1a5ef693be9bcf7d0fdd3764ec87e804df0e33880"}, "downloads": -1, "filename": "ptflops-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "cae968741f5f8558a6db5ffdf6ff9a1d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7758, "upload_time": "2019-05-15T15:40:13", "upload_time_iso_8601": "2019-05-15T15:40:13.890093Z", "url": "https://files.pythonhosted.org/packages/b9/30/a3a6d1bf622be79db86d5a65f56f5f895282bce2192ffa10d962ec0d5f68/ptflops-0.2-py3-none-any.whl", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "21f3f3fa6015d0908a80cbebf6c5df2a", "sha256": "6375c11e240c03476ce923bdbd8147e7cce865d2d1952aa7f3492c4465c4aa5f"}, "downloads": -1, "filename": "ptflops-0.3.tar.gz", "has_sig": false, "md5_digest": "21f3f3fa6015d0908a80cbebf6c5df2a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7141, "upload_time": "2019-06-17T14:32:06", "upload_time_iso_8601": "2019-06-17T14:32:06.465768Z", "url": "https://files.pythonhosted.org/packages/79/50/a509c2167e60f211a87ee74401eb1b3c0901f513eca80f5c84ff0fd2c621/ptflops-0.3.tar.gz", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "117c274c38fc464ad6c5b83b02b051dd", "sha256": "a6233097bc4c5fc4f88bb4dee2f1bba659366e3f7e6b54fe80d9222699e5d813"}, "downloads": -1, "filename": "ptflops-0.4.tar.gz", "has_sig": false, "md5_digest": "117c274c38fc464ad6c5b83b02b051dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7188, "upload_time": "2019-09-23T07:58:54", "upload_time_iso_8601": "2019-09-23T07:58:54.270861Z", "url": "https://files.pythonhosted.org/packages/40/1d/f7dfe67df73bbbd133b691a52e536dc582683b72c864c90120724199a486/ptflops-0.4.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "3c3bbc3a149ade7221b58c8d8997d8c2", "sha256": "88c00f3c39b78749d751e615815b4ab8b49762e94aa85823b84c1f6912b777c6"}, "downloads": -1, "filename": "ptflops-0.5.1.tar.gz", "has_sig": false, "md5_digest": "3c3bbc3a149ade7221b58c8d8997d8c2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7286, "upload_time": "2019-12-09T08:50:56", "upload_time_iso_8601": "2019-12-09T08:50:56.500463Z", "url": "https://files.pythonhosted.org/packages/5c/bc/45b8db2d4e13c1163ee2062d2a88170c81894d6a8735f903a4ed22e1ca4d/ptflops-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "d396c4a61cfbf59953f43134ec630335", "sha256": "e43969007252fbfe05400c401bbaffc3fbce2550a971ac094d0c682606f995e2"}, "downloads": -1, "filename": "ptflops-0.5.2.tar.gz", "has_sig": false, "md5_digest": "d396c4a61cfbf59953f43134ec630335", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7491, "upload_time": "2019-12-30T08:38:31", "upload_time_iso_8601": "2019-12-30T08:38:31.749014Z", "url": "https://files.pythonhosted.org/packages/78/47/ba2c8ca08c97c4e0d1fa8b342a1dfbad51385c81fc61da3421120f2f2e5b/ptflops-0.5.2.tar.gz", "yanked": false}], "0.6": [{"comment_text": "", "digests": {"md5": "6462f876f23bc5a969880ccd0a6ee0f6", "sha256": "32ff10ca49aed57ff8de5074c04b662390f48d592fde0eb739d1d148a2448708"}, "downloads": -1, "filename": "ptflops-0.6.tar.gz", "has_sig": false, "md5_digest": "6462f876f23bc5a969880ccd0a6ee0f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9808, "upload_time": "2020-04-14T13:16:50", "upload_time_iso_8601": "2020-04-14T13:16:50.943194Z", "url": "https://files.pythonhosted.org/packages/a8/23/e87a83c5953e2ffd0c66c29796c9f9db918c7d2df6f9a81e34e82aca7702/ptflops-0.6.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "13c5ba7d2847f2889c356cc03ccbbf2a", "sha256": "22d930329cb9370b067e449938676239d74fe00cc0cf9542f0d2c053da3cb198"}, "downloads": -1, "filename": "ptflops-0.6.1.tar.gz", "has_sig": false, "md5_digest": "13c5ba7d2847f2889c356cc03ccbbf2a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10667, "upload_time": "2020-04-24T16:30:37", "upload_time_iso_8601": "2020-04-24T16:30:37.497060Z", "url": "https://files.pythonhosted.org/packages/08/f2/4a52249d9eccc7b9caed5b0022604e8e1b3b738d9b9927db198963c4f578/ptflops-0.6.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "13c5ba7d2847f2889c356cc03ccbbf2a", "sha256": "22d930329cb9370b067e449938676239d74fe00cc0cf9542f0d2c053da3cb198"}, "downloads": -1, "filename": "ptflops-0.6.1.tar.gz", "has_sig": false, "md5_digest": "13c5ba7d2847f2889c356cc03ccbbf2a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10667, "upload_time": "2020-04-24T16:30:37", "upload_time_iso_8601": "2020-04-24T16:30:37.497060Z", "url": "https://files.pythonhosted.org/packages/08/f2/4a52249d9eccc7b9caed5b0022604e8e1b3b738d9b9927db198963c4f578/ptflops-0.6.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:15:13 2020"}