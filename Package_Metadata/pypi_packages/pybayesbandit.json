{"info": {"author": "Thiago P. Bueno", "author_email": "thiago.pbueno@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# pybayesbandit\n\nBayesian bandits in Python3.\n\n## Quickstart\n\n```text\n$ pip install pybayesbandit\n```\n\n## Usage\n\n```text\n$ pybayesbandit --help\nusage: pybayesbandit [-h] [-p PARAMS [PARAMS ...]] [-d MAXDEPTH] [-t TRIALS]\n                     [-C C] [-e EPISODES] [-hr HORIZON] [--plot] [-v]\n                     {random,ucb,thompson,vi,uct,rollout,aotree} {bernoulli}\n                     {total,simple}\n\nBayesian bandits in Python3.\n\npositional arguments:\n  {random,ucb,thompson,vi,uct,rollout,aotree}\n                        learner type\n  {bernoulli}           bandit type\n  {total,simple}        game setting\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -p PARAMS [PARAMS ...], --params PARAMS [PARAMS ...]\n                        bandit parameters\n  -d MAXDEPTH, --maxdepth MAXDEPTH\n                        maximum number of timesteps in the tree lookahead\n                        (default=10)\n  -t TRIALS, --trials TRIALS\n                        number of trials in Monte-Carlo sampling (default=30)\n  -C C                  UCT exploration constant (default=2.0)\n  -e EPISODES, --episodes EPISODES\n                        number of simulation episodes (default=200)\n  -hr HORIZON, --horizon HORIZON\n                        number of timesteps in each episode (default=100)\n  --plot                plot cumulative regret\n  -v, --verbose         verbose mode\n```\n\n## Examples\n\n```text\n$ pybayesbandit ucb bernoulli total -p 0.5 0.8 0.3 -e 100 -hr 50 -v\n\nRunning pybayesbandit ...\n>> learner  = ucb\n>> bandit   = bernoulli([0.5, 0.8, 0.3])\n>> episodes = 100\n>> horizon  = 50\nDone in 0.257 sec.\n\nResults:\n>> Reward =  32.3900 \u00b1 3.4173\n>> Regret =   7.6530 \u00b1 1.7081\n```\n\n```text\n$ pybayesbandit thompson bernoulli total -p 0.5 0.8 0.3 -e 100 -hr 50 -v\n\nRunning pybayesbandit ...\n>> learner  = thompson\n>> bandit   = bernoulli([0.5, 0.8, 0.3])\n>> episodes = 100\n>> horizon  = 50\nDone in 0.297 sec.\n\nResults:\n>> Reward =  35.2200 \u00b1 3.8822\n>> Regret =   4.4560 \u00b1 2.6086\n```\n\n```text\n$ pybayesbandit uct bernoulli total -p 0.5 0.8 0.3 -e 100 -hr 50 --trials 15 --maxdepth 5 -v\n\nRunning pybayesbandit ...\n>> learner  = uct(trials=15, maxdepth=5, C=2.0)\n>> bandit   = bernoulli([0.5, 0.8, 0.3])\n>> episodes = 100\n>> horizon  = 50\nDone in 7.066 sec.\n\nResults:\n>> Reward =  36.2800 \u00b1 5.4828\n>> Regret =   3.4360 \u00b1 4.5856\n```\n\n## License\n\nCopyright (c) 2018 Thiago Pereira Bueno All Rights Reserved.\n\npybayesbandit is free software: you can redistribute it and/or modify it\nunder the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or (at\nyour option) any later version.\n\npybayesbandit is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License\nalong with pybayesbandit. If not, see http://www.gnu.org/licenses/.", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/thiagopbueno/pybayesbandit", "keywords": "rl,bayesian,bandit-learning,belief-planning", "license": "GNU General Public License v3.0", "maintainer": "", "maintainer_email": "", "name": "pybayesbandit", "package_url": "https://pypi.org/project/pybayesbandit/", "platform": "", "project_url": "https://pypi.org/project/pybayesbandit/", "project_urls": {"Homepage": "https://github.com/thiagopbueno/pybayesbandit"}, "release_url": "https://pypi.org/project/pybayesbandit/0.0.4/", "requires_dist": null, "requires_python": "", "summary": "Bayesian bandits in Python3.", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            # pybayesbandit<br><br>Bayesian bandits in Python3.<br><br>## Quickstart<br><br>```text<br>$ pip install pybayesbandit<br>```<br><br>## Usage<br><br>```text<br>$ pybayesbandit --help<br>usage: pybayesbandit [-h] [-p PARAMS [PARAMS ...]] [-d MAXDEPTH] [-t TRIALS]<br>                     [-C C] [-e EPISODES] [-hr HORIZON] [--plot] [-v]<br>                     {random,ucb,thompson,vi,uct,rollout,aotree} {bernoulli}<br>                     {total,simple}<br><br>Bayesian bandits in Python3.<br><br>positional arguments:<br>  {random,ucb,thompson,vi,uct,rollout,aotree}<br>                        learner type<br>  {bernoulli}           bandit type<br>  {total,simple}        game setting<br><br>optional arguments:<br>  -h, --help            show this help message and exit<br>  -p PARAMS [PARAMS ...], --params PARAMS [PARAMS ...]<br>                        bandit parameters<br>  -d MAXDEPTH, --maxdepth MAXDEPTH<br>                        maximum number of timesteps in the tree lookahead<br>                        (default=10)<br>  -t TRIALS, --trials TRIALS<br>                        number of trials in Monte-Carlo sampling (default=30)<br>  -C C                  UCT exploration constant (default=2.0)<br>  -e EPISODES, --episodes EPISODES<br>                        number of simulation episodes (default=200)<br>  -hr HORIZON, --horizon HORIZON<br>                        number of timesteps in each episode (default=100)<br>  --plot                plot cumulative regret<br>  -v, --verbose         verbose mode<br>```<br><br>## Examples<br><br>```text<br>$ pybayesbandit ucb bernoulli total -p 0.5 0.8 0.3 -e 100 -hr 50 -v<br><br>Running pybayesbandit ...<br>&gt;&gt; learner  = ucb<br>&gt;&gt; bandit   = bernoulli([0.5, 0.8, 0.3])<br>&gt;&gt; episodes = 100<br>&gt;&gt; horizon  = 50<br>Done in 0.257 sec.<br><br>Results:<br>&gt;&gt; Reward =  32.3900 \u00b1 3.4173<br>&gt;&gt; Regret =   7.6530 \u00b1 1.7081<br>```<br><br>```text<br>$ pybayesbandit thompson bernoulli total -p 0.5 0.8 0.3 -e 100 -hr 50 -v<br><br>Running pybayesbandit ...<br>&gt;&gt; learner  = thompson<br>&gt;&gt; bandit   = bernoulli([0.5, 0.8, 0.3])<br>&gt;&gt; episodes = 100<br>&gt;&gt; horizon  = 50<br>Done in 0.297 sec.<br><br>Results:<br>&gt;&gt; Reward =  35.2200 \u00b1 3.8822<br>&gt;&gt; Regret =   4.4560 \u00b1 2.6086<br>```<br><br>```text<br>$ pybayesbandit uct bernoulli total -p 0.5 0.8 0.3 -e 100 -hr 50 --trials 15 --maxdepth 5 -v<br><br>Running pybayesbandit ...<br>&gt;&gt; learner  = uct(trials=15, maxdepth=5, C=2.0)<br>&gt;&gt; bandit   = bernoulli([0.5, 0.8, 0.3])<br>&gt;&gt; episodes = 100<br>&gt;&gt; horizon  = 50<br>Done in 7.066 sec.<br><br>Results:<br>&gt;&gt; Reward =  36.2800 \u00b1 5.4828<br>&gt;&gt; Regret =   3.4360 \u00b1 4.5856<br>```<br><br>## License<br><br>Copyright (c) 2018 Thiago Pereira Bueno All Rights Reserved.<br><br>pybayesbandit is free software: you can redistribute it and/or modify it<br>under the terms of the GNU Lesser General Public License as published by<br>the Free Software Foundation, either version 3 of the License, or (at<br>your option) any later version.<br><br>pybayesbandit is distributed in the hope that it will be useful, but<br>WITHOUT ANY WARRANTY; without even the implied warranty of<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser<br>General Public License for more details.<br><br>You should have received a copy of the GNU Lesser General Public License<br>along with pybayesbandit. If not, see http://www.gnu.org/licenses/.\n          </div>"}, "last_serial": 4508893, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "4543fd6a0f8427674a3c39f0f77aa053", "sha256": "eb1dc934281b2cc4677002053d2d9c21c33ab6e2460b0f9dad30eff368c6f1f6"}, "downloads": -1, "filename": "pybayesbandit-0.0.2.tar.gz", "has_sig": false, "md5_digest": "4543fd6a0f8427674a3c39f0f77aa053", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7809, "upload_time": "2018-11-11T16:51:42", "upload_time_iso_8601": "2018-11-11T16:51:42.843140Z", "url": "https://files.pythonhosted.org/packages/ca/00/ba26bd8da75398c1412b31c108a30d5d622c62f4700b3c4e76dcb2001fb7/pybayesbandit-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "8a721189d78389320a161fb4972ba138", "sha256": "4fd07382e1d3fb997f2c13a69a6dbad1b4f3d55025617437012298b8bc6fed08"}, "downloads": -1, "filename": "pybayesbandit-0.0.4.tar.gz", "has_sig": false, "md5_digest": "8a721189d78389320a161fb4972ba138", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9987, "upload_time": "2018-11-20T19:15:59", "upload_time_iso_8601": "2018-11-20T19:15:59.149380Z", "url": "https://files.pythonhosted.org/packages/7b/e9/f8a51af72b57ef2802fdf8b5ad5ab2856f9272dd414429986204b04a18ba/pybayesbandit-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8a721189d78389320a161fb4972ba138", "sha256": "4fd07382e1d3fb997f2c13a69a6dbad1b4f3d55025617437012298b8bc6fed08"}, "downloads": -1, "filename": "pybayesbandit-0.0.4.tar.gz", "has_sig": false, "md5_digest": "8a721189d78389320a161fb4972ba138", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9987, "upload_time": "2018-11-20T19:15:59", "upload_time_iso_8601": "2018-11-20T19:15:59.149380Z", "url": "https://files.pythonhosted.org/packages/7b/e9/f8a51af72b57ef2802fdf8b5ad5ab2856f9272dd414429986204b04a18ba/pybayesbandit-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:09:22 2020"}