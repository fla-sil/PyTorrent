{"info": {"author": "Ivan Georgiev", "author_email": "ivan.georgiev@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License (GPL)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# unittest-pyspark\nExtensions for testing pyspark with unittest and doctest.\n\nThese utils can be used in standalone Python or in Databricks\nnotebooks.\n\n## Usage With Doctest\n\n```python\nfrom unittest_pyspark import get_spark\nspark = get_spark()\n\ndef go_spark():\n    \"\"\"\n    >>> spark.sql(\"SELECT 'hello world'\").show()\n    +-----------+\n    |hello world|\n    +-----------+\n    |hello world|\n    +-----------+\n    <BLANKLINE>\n    >>> spark.createDataFrame([{'hello':'world'}], 'hello:string').show()\n    +-----+\n    |hello|\n    +-----+\n    |world|\n    +-----+\n    <BLANKLINE>\n    \"\"\"\n    pass\n\nimport doctest\ndoctest.testmod()\n```\n\n## Usage With Unittest\n\nHere is a simple `unittest` test case, which can be used as\ntemplate for pySpark test case. \n\n```python\nimport unittest\nfrom unittest_pyspark import as_list, get_spark\nimport pyspark.sql.types as pst\n\nclass Test_Spark(unittest.TestCase):\n  def setUp(self):\n      self.spark = get_spark()\n\n  def test_i_can_fly(self):\n    input = [ pst.Row(a=1, b=2)]\n    input_df = self.spark.createDataFrame(input)\n\n    expect = [{'a':1}]\n\n    actual_df = input_df.select(\"a\")\n    actual = as_list(actual_df)\n\n    self.assertEqual(actual, expect)\n```\n\nYou can find this entire example in the \n`tests.test_sample` module. To execute it from the command line:\n\n```bash\npython -m unittest tests.test_sample\n```\n\n## Usage With Unittest and Databricks\n\nTo execute the `unittest` test cases in Databricks, add following cell:\n\n```python\nfrom unittest_pyspark.unittest import *\nif __name__ == \"__main__\":\n  execute_test_cases(discover_test_cases())\n```\n\nAbove code will automatically discover all test cases (unittest.TestCase\nsub classes) defined in the global scope and execute them.\n\n## Build package\n\nYou will need `setuptools` and `twine`:\n```bash\npip install --upgrade setuptools\npip install --upgrade wheel\n```\nBuild and upload:\n```bash\npython setup.py sdist bdist_wheel\npython -m twine upload dist/*\n```\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ivangeorgiev/unittest-pyspark", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "unittest-pyspark", "package_url": "https://pypi.org/project/unittest-pyspark/", "platform": "", "project_url": "https://pypi.org/project/unittest-pyspark/", "project_urls": {"Homepage": "https://github.com/ivangeorgiev/unittest-pyspark"}, "release_url": "https://pypi.org/project/unittest-pyspark/0.0.5/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Extension to unittest for pySpark", "version": "0.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>unittest-pyspark</h1>\n<p>Extensions for testing pyspark with unittest and doctest.</p>\n<p>These utils can be used in standalone Python or in Databricks\nnotebooks.</p>\n<h2>Usage With Doctest</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">unittest_pyspark</span> <span class=\"kn\">import</span> <span class=\"n\">get_spark</span>\n<span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">get_spark</span><span class=\"p\">()</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">go_spark</span><span class=\"p\">():</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">    &gt;&gt;&gt; spark.sql(\"SELECT 'hello world'\").show()</span>\n<span class=\"sd\">    +-----------+</span>\n<span class=\"sd\">    |hello world|</span>\n<span class=\"sd\">    +-----------+</span>\n<span class=\"sd\">    |hello world|</span>\n<span class=\"sd\">    +-----------+</span>\n<span class=\"sd\">    &lt;BLANKLINE&gt;</span>\n<span class=\"sd\">    &gt;&gt;&gt; spark.createDataFrame([{'hello':'world'}], 'hello:string').show()</span>\n<span class=\"sd\">    +-----+</span>\n<span class=\"sd\">    |hello|</span>\n<span class=\"sd\">    +-----+</span>\n<span class=\"sd\">    |world|</span>\n<span class=\"sd\">    +-----+</span>\n<span class=\"sd\">    &lt;BLANKLINE&gt;</span>\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">doctest</span>\n<span class=\"n\">doctest</span><span class=\"o\">.</span><span class=\"n\">testmod</span><span class=\"p\">()</span>\n</pre>\n<h2>Usage With Unittest</h2>\n<p>Here is a simple <code>unittest</code> test case, which can be used as\ntemplate for pySpark test case.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">unittest</span>\n<span class=\"kn\">from</span> <span class=\"nn\">unittest_pyspark</span> <span class=\"kn\">import</span> <span class=\"n\">as_list</span><span class=\"p\">,</span> <span class=\"n\">get_spark</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pyspark.sql.types</span> <span class=\"k\">as</span> <span class=\"nn\">pst</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Test_Spark</span><span class=\"p\">(</span><span class=\"n\">unittest</span><span class=\"o\">.</span><span class=\"n\">TestCase</span><span class=\"p\">):</span>\n  <span class=\"k\">def</span> <span class=\"nf\">setUp</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n      <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">spark</span> <span class=\"o\">=</span> <span class=\"n\">get_spark</span><span class=\"p\">()</span>\n\n  <span class=\"k\">def</span> <span class=\"nf\">test_i_can_fly</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"nb\">input</span> <span class=\"o\">=</span> <span class=\"p\">[</span> <span class=\"n\">pst</span><span class=\"o\">.</span><span class=\"n\">Row</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">b</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)]</span>\n    <span class=\"n\">input_df</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">spark</span><span class=\"o\">.</span><span class=\"n\">createDataFrame</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n\n    <span class=\"n\">expect</span> <span class=\"o\">=</span> <span class=\"p\">[{</span><span class=\"s1\">'a'</span><span class=\"p\">:</span><span class=\"mi\">1</span><span class=\"p\">}]</span>\n\n    <span class=\"n\">actual_df</span> <span class=\"o\">=</span> <span class=\"n\">input_df</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"s2\">\"a\"</span><span class=\"p\">)</span>\n    <span class=\"n\">actual</span> <span class=\"o\">=</span> <span class=\"n\">as_list</span><span class=\"p\">(</span><span class=\"n\">actual_df</span><span class=\"p\">)</span>\n\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">assertEqual</span><span class=\"p\">(</span><span class=\"n\">actual</span><span class=\"p\">,</span> <span class=\"n\">expect</span><span class=\"p\">)</span>\n</pre>\n<p>You can find this entire example in the\n<code>tests.test_sample</code> module. To execute it from the command line:</p>\n<pre>python -m unittest tests.test_sample\n</pre>\n<h2>Usage With Unittest and Databricks</h2>\n<p>To execute the <code>unittest</code> test cases in Databricks, add following cell:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">unittest_pyspark.unittest</span> <span class=\"kn\">import</span> <span class=\"o\">*</span>\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s2\">\"__main__\"</span><span class=\"p\">:</span>\n  <span class=\"n\">execute_test_cases</span><span class=\"p\">(</span><span class=\"n\">discover_test_cases</span><span class=\"p\">())</span>\n</pre>\n<p>Above code will automatically discover all test cases (unittest.TestCase\nsub classes) defined in the global scope and execute them.</p>\n<h2>Build package</h2>\n<p>You will need <code>setuptools</code> and <code>twine</code>:</p>\n<pre>pip install --upgrade setuptools\npip install --upgrade wheel\n</pre>\n<p>Build and upload:</p>\n<pre>python setup.py sdist bdist_wheel\npython -m twine upload dist/*\n</pre>\n\n          </div>"}, "last_serial": 6328059, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "f6235ae8565ddddfd8a2c750b046d184", "sha256": "132d8eadcfd84717c177ca4f3fa822a726f949c93a055da045641f92daa1b4d2"}, "downloads": -1, "filename": "unittest_pyspark-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f6235ae8565ddddfd8a2c750b046d184", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 16962, "upload_time": "2019-12-18T13:02:06", "upload_time_iso_8601": "2019-12-18T13:02:06.619528Z", "url": "https://files.pythonhosted.org/packages/ae/93/b036959dc7538a45062dce6976f2fac9396e3deda9e5202d13894166171b/unittest_pyspark-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "efd9544ce38ea6f6a68a5aa28d560032", "sha256": "96d610d5367354df6eb69623535ca719b9463b88be0077e0226bbd33fc91dba8"}, "downloads": -1, "filename": "unittest-pyspark-0.0.2.tar.gz", "has_sig": false, "md5_digest": "efd9544ce38ea6f6a68a5aa28d560032", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3303, "upload_time": "2019-12-18T13:02:08", "upload_time_iso_8601": "2019-12-18T13:02:08.602808Z", "url": "https://files.pythonhosted.org/packages/06/a5/dedca267b9e3c9c196991a9058e90d35228da2f07f983db9a1977506c1d4/unittest-pyspark-0.0.2.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "f7be62262571e6009e9c760c14286f59", "sha256": "69a44fcf2e8359336bc67d379222012c4d1e5563db3b5c7e52e94370d5b2f8f3"}, "downloads": -1, "filename": "unittest_pyspark-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "f7be62262571e6009e9c760c14286f59", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 16959, "upload_time": "2019-12-18T21:08:24", "upload_time_iso_8601": "2019-12-18T21:08:24.398455Z", "url": "https://files.pythonhosted.org/packages/c4/35/a91caa882cb811e75d6942117de81e9160899757734105ffb82f1f659270/unittest_pyspark-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7dc38345cecb4ec6e391e2707815e95", "sha256": "ca2ba2e859b8c564fa61c01ac9c6b163033fb902bfa15b4c25f607606ac9a8e2"}, "downloads": -1, "filename": "unittest-pyspark-0.0.5.tar.gz", "has_sig": false, "md5_digest": "d7dc38345cecb4ec6e391e2707815e95", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3264, "upload_time": "2019-12-18T21:08:26", "upload_time_iso_8601": "2019-12-18T21:08:26.117107Z", "url": "https://files.pythonhosted.org/packages/26/4f/68bf4887b44f8ccb994d46cc732ead42555d3149b4869e88160e985cd945/unittest-pyspark-0.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f7be62262571e6009e9c760c14286f59", "sha256": "69a44fcf2e8359336bc67d379222012c4d1e5563db3b5c7e52e94370d5b2f8f3"}, "downloads": -1, "filename": "unittest_pyspark-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "f7be62262571e6009e9c760c14286f59", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 16959, "upload_time": "2019-12-18T21:08:24", "upload_time_iso_8601": "2019-12-18T21:08:24.398455Z", "url": "https://files.pythonhosted.org/packages/c4/35/a91caa882cb811e75d6942117de81e9160899757734105ffb82f1f659270/unittest_pyspark-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7dc38345cecb4ec6e391e2707815e95", "sha256": "ca2ba2e859b8c564fa61c01ac9c6b163033fb902bfa15b4c25f607606ac9a8e2"}, "downloads": -1, "filename": "unittest-pyspark-0.0.5.tar.gz", "has_sig": false, "md5_digest": "d7dc38345cecb4ec6e391e2707815e95", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3264, "upload_time": "2019-12-18T21:08:26", "upload_time_iso_8601": "2019-12-18T21:08:26.117107Z", "url": "https://files.pythonhosted.org/packages/26/4f/68bf4887b44f8ccb994d46cc732ead42555d3149b4869e88160e985cd945/unittest-pyspark-0.0.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:40:19 2020"}