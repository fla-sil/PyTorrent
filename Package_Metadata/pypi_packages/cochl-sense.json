{"info": {"author": "Cochlear.ai", "author_email": "support@cochlear.ai", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "# Sense Python\n\nThis repository is splitted in two folders :\u00a0\n- `cochl_sense` contains the source code of the cochlear.ai sense nodejs client\n- `examples` contains examples sample\n\n## Quick start\n\nGo in `examples` folder\n\nMake sure that dependencies are install by running `pip install -r requirements.txt`.\n\nYou can then inference a file : `python file.py`\n\n\nIf you want to inference a stream, you will need to install `portaudio` on your system.\nYou can then inference audio from your microphone :\u00a0`python pyaudio.py`\n\n## Use the library\n\nTo use our library, install it by running `pip install cochl-sense`.\n\nYou can now import classes :\n```python\nfrom cochl_sense.file import FileBuilder\nfrom cochl_sense.stream import StreamBuilder\n```\n\n### File\n\n`File` represents a class that can inference audio coming from an audio file.\n\nAn audio file is any source of audio data which duration is known at runtime.\nBecause duration is known at runtime, server will wait for the whole file to be received before \nto start inferencing. All inferenced data will be received in one payload.\n\nA file can be for instance, a mp3 file stored locally, a wav file accessible from an url etc...\n\nSo far wav, flac, mp3, ogg, mp4 are supported.\n\nIf you are using another file encoding format, let us know at support@cochlear.ai so that we can priorize it in our internal roadmap.\n\n`File` implements the following interface : \n\n```python\nclass File:\n    def inference() -> Result: \n```\n\nWhen calling `inference`, a GRPC connection will be established with the backend, audio data of the file will be sent and a `Result` instance will be returned in case of success (described bellow).\n\nNote that network is not reached until `inference` method is called.\n\nNote that `inference` can be called only once per `File` instance.\n\nTo create a `File` instance, you need to use a `FileBuilder` instance. `FileBuilder` is following the builder pattern and calling its `build` method will create a `File` instance.\n\n`FileBuider` implements the following interface :\n\n```python\nclass FileBuilder: \n    #api key of cochlear.ai projects available at https://dashboard.cochlear.ai\n    def with_api_key(key: str) -> FileBuilder:\n    #format of the audio file : can be mp3, flac, wav, ogg, etc...\n    def with_format(format: str) -> FileBuilder:\n    #data reader to the file data\n    def with_reader(reader) ->FileBuilder:\n        #where reader is a type that implements io.BufferedIOBase (see https://docs.python.org/3/library/io.html#io.BufferedIOBase)\n\n    #creates a File instance*/\n    def build() -> File:\n```\n\nNote that `with_api_key`, `with_format` and `with_reader` method needs to be called before calling the `build` method, otherwise an error will be raised.\n\n### Stream\n\n`Stream` represents a class that can inference audio coming from an audio stream.\n\nAn audio stream is any source of data which duration is not known at runtime. \nBecause duration is not known, server will inference audio as it comes. One second of audio will be required before the first result to be returned. After that, one result will be given every 0.5 second of audio.\n\nA stream can be for instance, the audio data comming from a microphone, audio data comming from a web radio etc...\n\nStreams can be stopped at any moment while inferencing.\n\nFor now, the only format that is supported for streaming is a raw data stream (PCM stream). \nRaw data being sent has to be a **mono channel** audio stream. Its sampling rate and data type (int16, int32, float32) has to be given to describe the raw audio data. \n\nFor best performance, we recommand using a sampling rate of 22050Hz and data represented as float32.\n\nMultiple results will be returned by calling a callback function.\n\nIf you are using another stream encoding format that is not supported, let us know at support@cochlear.ai so that we can priorize it in our internal roadmap.\n\n`Stream` implements the following interface : \n\n```python\nclass Stream:\n    def inference(callback):\n        #where callback is a function that takes a Result object defined as below\n```\n\nWhen calling `inference`, a GRPC connection will be established with the backend, audio data of the stream will be sent every 0.5s.\nOnce result is returned by the server, the `callback` function is called.\n\nNote that network is not reached until `inference` method is called.\n\nNote that inference can be called only once per `Stream` instance.\n\nTo create a `Stream` instance, you need to use a `StreamBuilder` instance. `StreamBuilder` is following the builder pattern and calling its `build` method will create a `Stream` instance.\n\n`StreamBuider` implements the following interface :\n\n```python\nclass SrteamBuilder:\n    #api key of cochlear.ai projects available at dashboard.cochlear.ai\n    def with_api_key(key: str) -> StreamBuilder:\n    #type of the pcm stream\n    def with_data_type(datatype: str) -> StreamBuilder:\n    #sampling rate of the pcm stream\n    def with_sampling_rate(samplingRate: int) -> StreamBuilder:\n    #data of the pcm stream\n    def with_streamer(streamer) -> StreamBuilder:\n        #where streamer is a generator of binary string\n\n    #creates a Stream instance*/\n    def build() -> Stream:\n\n    #disable sampling rate check\n    def deactivate_low_sampling_rate_warning() -> StreamBuilder:\n    #max number of events from previous inference to keep in memory\n    def with_max_events_history_size(size: number) -> StreamBuilder:\n}\n```\n\nNote that `with_api_key`, `with_data_type`, `with_sampling_rate` and `with_streamer` method needs to be called before calling the `build` method, otherwise an error will be thrown.\n\n\n### Result\n\nResult is a class that is returned by both file and stream when calling `inference` method.\n\nMultiple results will be returned by a stream by calling a callback function. For a file only one result will be returned.\n\n`Result` implements the following interface :\n```python\nclass Result:\n    #returns all events\n    def all_events() -> List[Event]:\n    #returns all events that match the \"filter function\" defined below\n    def detected_events() -> List[Event]:\n    #group events that match the \"filter function\" and shows segments of time of when events were detected\n    def detected_events_timing() -> Dictionnary[str, List[Tuple[int, int]]]:\n    #return only the \"tag\" of the event that match the \"filter\" function\n    def detected_tags() -> List[str]:\n    #returns the service name :\u00a0\"human-interaction\" or \"emergency\" for instance*/\n    def service() -> List[str]:\n    #returns a raw json object containing service name and an array of events\n    def to_json() -> str:\n    #use a filter function :\u00a0that function takes an event as input and return a boolean. An event will be \"detected\" if the filter function returns true for that event\n    def use_default_filter() -> Result\n :   #the default filter is to consider all events as detected. So by default, allEvents() and detectedEvents() will return the same result\n    def set_filter(filter): Result\n        #where filter is a function that takes an event in input and returns a boolean\n```\n\nNote that if you are inferencing a stream, multiple results will be returned. By default, calling `all_events()` will only returned the newly inferenced result.\nIt's possible to keep track of previous events of the stream. To do so, call the `with_max_events_history_size` method on the `StreamBuilder` class. Its default value is 0,\nand increasing it will allow to \"remember\" previous events. \n\n### Event\n\nAn event contains the following data :\n\n```python\nclass Event:\n    #name of the detected event\n    tag: str\n    #start timestamp of the detected event since the begining of the inference\n    start_time: int\n    #end timestamp of the detected event since the begining of the inference\n    end_time: int\n    #probablity for the event to happen. Its values is between 0 and 1\n    probability: str\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/cochlearai/sense-python", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "cochl-sense", "package_url": "https://pypi.org/project/cochl-sense/", "platform": "", "project_url": "https://pypi.org/project/cochl-sense/", "project_urls": {"Homepage": "https://github.com/cochlearai/sense-python"}, "release_url": "https://pypi.org/project/cochl-sense/1.0.0/", "requires_dist": ["grpcio", "protobuf"], "requires_python": "", "summary": "Python Package for Cochlear.ai sense API", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Sense Python</h1>\n<p>This repository is splitted in two folders :\u00a0</p>\n<ul>\n<li><code>cochl_sense</code> contains the source code of the cochlear.ai sense nodejs client</li>\n<li><code>examples</code> contains examples sample</li>\n</ul>\n<h2>Quick start</h2>\n<p>Go in <code>examples</code> folder</p>\n<p>Make sure that dependencies are install by running <code>pip install -r requirements.txt</code>.</p>\n<p>You can then inference a file : <code>python file.py</code></p>\n<p>If you want to inference a stream, you will need to install <code>portaudio</code> on your system.\nYou can then inference audio from your microphone :\u00a0<code>python pyaudio.py</code></p>\n<h2>Use the library</h2>\n<p>To use our library, install it by running <code>pip install cochl-sense</code>.</p>\n<p>You can now import classes :</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">cochl_sense.file</span> <span class=\"kn\">import</span> <span class=\"n\">FileBuilder</span>\n<span class=\"kn\">from</span> <span class=\"nn\">cochl_sense.stream</span> <span class=\"kn\">import</span> <span class=\"n\">StreamBuilder</span>\n</pre>\n<h3>File</h3>\n<p><code>File</code> represents a class that can inference audio coming from an audio file.</p>\n<p>An audio file is any source of audio data which duration is known at runtime.\nBecause duration is known at runtime, server will wait for the whole file to be received before\nto start inferencing. All inferenced data will be received in one payload.</p>\n<p>A file can be for instance, a mp3 file stored locally, a wav file accessible from an url etc...</p>\n<p>So far wav, flac, mp3, ogg, mp4 are supported.</p>\n<p>If you are using another file encoding format, let us know at <a href=\"mailto:support@cochlear.ai\">support@cochlear.ai</a> so that we can priorize it in our internal roadmap.</p>\n<p><code>File</code> implements the following interface :</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">File</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">inference</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Result</span><span class=\"p\">:</span> \n</pre>\n<p>When calling <code>inference</code>, a GRPC connection will be established with the backend, audio data of the file will be sent and a <code>Result</code> instance will be returned in case of success (described bellow).</p>\n<p>Note that network is not reached until <code>inference</code> method is called.</p>\n<p>Note that <code>inference</code> can be called only once per <code>File</code> instance.</p>\n<p>To create a <code>File</code> instance, you need to use a <code>FileBuilder</code> instance. <code>FileBuilder</code> is following the builder pattern and calling its <code>build</code> method will create a <code>File</code> instance.</p>\n<p><code>FileBuider</code> implements the following interface :</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">FileBuilder</span><span class=\"p\">:</span> \n    <span class=\"c1\">#api key of cochlear.ai projects available at https://dashboard.cochlear.ai</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_api_key</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">FileBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#format of the audio file : can be mp3, flac, wav, ogg, etc...</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_format</span><span class=\"p\">(</span><span class=\"nb\">format</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">FileBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#data reader to the file data</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_reader</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span><span class=\"n\">FileBuilder</span><span class=\"p\">:</span>\n        <span class=\"c1\">#where reader is a type that implements io.BufferedIOBase (see https://docs.python.org/3/library/io.html#io.BufferedIOBase)</span>\n\n    <span class=\"c1\">#creates a File instance*/</span>\n    <span class=\"k\">def</span> <span class=\"nf\">build</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">File</span><span class=\"p\">:</span>\n</pre>\n<p>Note that <code>with_api_key</code>, <code>with_format</code> and <code>with_reader</code> method needs to be called before calling the <code>build</code> method, otherwise an error will be raised.</p>\n<h3>Stream</h3>\n<p><code>Stream</code> represents a class that can inference audio coming from an audio stream.</p>\n<p>An audio stream is any source of data which duration is not known at runtime.\nBecause duration is not known, server will inference audio as it comes. One second of audio will be required before the first result to be returned. After that, one result will be given every 0.5 second of audio.</p>\n<p>A stream can be for instance, the audio data comming from a microphone, audio data comming from a web radio etc...</p>\n<p>Streams can be stopped at any moment while inferencing.</p>\n<p>For now, the only format that is supported for streaming is a raw data stream (PCM stream).\nRaw data being sent has to be a <strong>mono channel</strong> audio stream. Its sampling rate and data type (int16, int32, float32) has to be given to describe the raw audio data.</p>\n<p>For best performance, we recommand using a sampling rate of 22050Hz and data represented as float32.</p>\n<p>Multiple results will be returned by calling a callback function.</p>\n<p>If you are using another stream encoding format that is not supported, let us know at <a href=\"mailto:support@cochlear.ai\">support@cochlear.ai</a> so that we can priorize it in our internal roadmap.</p>\n<p><code>Stream</code> implements the following interface :</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">Stream</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">inference</span><span class=\"p\">(</span><span class=\"n\">callback</span><span class=\"p\">):</span>\n        <span class=\"c1\">#where callback is a function that takes a Result object defined as below</span>\n</pre>\n<p>When calling <code>inference</code>, a GRPC connection will be established with the backend, audio data of the stream will be sent every 0.5s.\nOnce result is returned by the server, the <code>callback</code> function is called.</p>\n<p>Note that network is not reached until <code>inference</code> method is called.</p>\n<p>Note that inference can be called only once per <code>Stream</code> instance.</p>\n<p>To create a <code>Stream</code> instance, you need to use a <code>StreamBuilder</code> instance. <code>StreamBuilder</code> is following the builder pattern and calling its <code>build</code> method will create a <code>Stream</code> instance.</p>\n<p><code>StreamBuider</code> implements the following interface :</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">SrteamBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#api key of cochlear.ai projects available at dashboard.cochlear.ai</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_api_key</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StreamBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#type of the pcm stream</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_data_type</span><span class=\"p\">(</span><span class=\"n\">datatype</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StreamBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#sampling rate of the pcm stream</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_sampling_rate</span><span class=\"p\">(</span><span class=\"n\">samplingRate</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StreamBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#data of the pcm stream</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_streamer</span><span class=\"p\">(</span><span class=\"n\">streamer</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StreamBuilder</span><span class=\"p\">:</span>\n        <span class=\"c1\">#where streamer is a generator of binary string</span>\n\n    <span class=\"c1\">#creates a Stream instance*/</span>\n    <span class=\"k\">def</span> <span class=\"nf\">build</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Stream</span><span class=\"p\">:</span>\n\n    <span class=\"c1\">#disable sampling rate check</span>\n    <span class=\"k\">def</span> <span class=\"nf\">deactivate_low_sampling_rate_warning</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StreamBuilder</span><span class=\"p\">:</span>\n    <span class=\"c1\">#max number of events from previous inference to keep in memory</span>\n    <span class=\"k\">def</span> <span class=\"nf\">with_max_events_history_size</span><span class=\"p\">(</span><span class=\"n\">size</span><span class=\"p\">:</span> <span class=\"n\">number</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StreamBuilder</span><span class=\"p\">:</span>\n<span class=\"p\">}</span>\n</pre>\n<p>Note that <code>with_api_key</code>, <code>with_data_type</code>, <code>with_sampling_rate</code> and <code>with_streamer</code> method needs to be called before calling the <code>build</code> method, otherwise an error will be thrown.</p>\n<h3>Result</h3>\n<p>Result is a class that is returned by both file and stream when calling <code>inference</code> method.</p>\n<p>Multiple results will be returned by a stream by calling a callback function. For a file only one result will be returned.</p>\n<p><code>Result</code> implements the following interface :</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">Result</span><span class=\"p\">:</span>\n    <span class=\"c1\">#returns all events</span>\n    <span class=\"k\">def</span> <span class=\"nf\">all_events</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Event</span><span class=\"p\">]:</span>\n    <span class=\"c1\">#returns all events that match the \"filter function\" defined below</span>\n    <span class=\"k\">def</span> <span class=\"nf\">detected_events</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Event</span><span class=\"p\">]:</span>\n    <span class=\"c1\">#group events that match the \"filter function\" and shows segments of time of when events were detected</span>\n    <span class=\"k\">def</span> <span class=\"nf\">detected_events_timing</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Dictionnary</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]]]:</span>\n    <span class=\"c1\">#return only the \"tag\" of the event that match the \"filter\" function</span>\n    <span class=\"k\">def</span> <span class=\"nf\">detected_tags</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]:</span>\n    <span class=\"c1\">#returns the service name :\u00a0\"human-interaction\" or \"emergency\" for instance*/</span>\n    <span class=\"k\">def</span> <span class=\"nf\">service</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]:</span>\n    <span class=\"c1\">#returns a raw json object containing service name and an array of events</span>\n    <span class=\"k\">def</span> <span class=\"nf\">to_json</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">str</span><span class=\"p\">:</span>\n    <span class=\"c1\">#use a filter function :\u00a0that function takes an event as input and return a boolean. An event will be \"detected\" if the filter function returns true for that event</span>\n    <span class=\"k\">def</span> <span class=\"nf\">use_default_filter</span><span class=\"p\">()</span> <span class=\"o\">-&gt;</span> <span class=\"n\">Result</span>\n <span class=\"p\">:</span>   <span class=\"c1\">#the default filter is to consider all events as detected. So by default, allEvents() and detectedEvents() will return the same result</span>\n    <span class=\"k\">def</span> <span class=\"nf\">set_filter</span><span class=\"p\">(</span><span class=\"nb\">filter</span><span class=\"p\">):</span> <span class=\"n\">Result</span>\n        <span class=\"c1\">#where filter is a function that takes an event in input and returns a boolean</span>\n</pre>\n<p>Note that if you are inferencing a stream, multiple results will be returned. By default, calling <code>all_events()</code> will only returned the newly inferenced result.\nIt's possible to keep track of previous events of the stream. To do so, call the <code>with_max_events_history_size</code> method on the <code>StreamBuilder</code> class. Its default value is 0,\nand increasing it will allow to \"remember\" previous events.</p>\n<h3>Event</h3>\n<p>An event contains the following data :</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">Event</span><span class=\"p\">:</span>\n    <span class=\"c1\">#name of the detected event</span>\n    <span class=\"n\">tag</span><span class=\"p\">:</span> <span class=\"nb\">str</span>\n    <span class=\"c1\">#start timestamp of the detected event since the begining of the inference</span>\n    <span class=\"n\">start_time</span><span class=\"p\">:</span> <span class=\"nb\">int</span>\n    <span class=\"c1\">#end timestamp of the detected event since the begining of the inference</span>\n    <span class=\"n\">end_time</span><span class=\"p\">:</span> <span class=\"nb\">int</span>\n    <span class=\"c1\">#probablity for the event to happen. Its values is between 0 and 1</span>\n    <span class=\"n\">probability</span><span class=\"p\">:</span> <span class=\"nb\">str</span>\n</pre>\n\n          </div>"}, "last_serial": 7181021, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "197dd7cefdb312820e68f8e6e07b4ecb", "sha256": "9fa7bc5ff3120c1d02bebf30bfe19b1e60306091e572b4cd04c609043e92c712"}, "downloads": -1, "filename": "cochl_sense-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "197dd7cefdb312820e68f8e6e07b4ecb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11705, "upload_time": "2020-05-06T15:28:57", "upload_time_iso_8601": "2020-05-06T15:28:57.736473Z", "url": "https://files.pythonhosted.org/packages/1c/f6/f5a2a90896fd0e83d6f2993c99e66ad526aab47dd66f9be063cfe55ec164/cochl_sense-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1648cd95bc49f6315b4c7a4ff4f2ea00", "sha256": "69c8cda03a5d993de1fea0c5bc1716adff26e1b88f5c8b613c12e61f899b290c"}, "downloads": -1, "filename": "cochl-sense-1.0.0.tar.gz", "has_sig": false, "md5_digest": "1648cd95bc49f6315b4c7a4ff4f2ea00", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13118, "upload_time": "2020-05-06T15:28:59", "upload_time_iso_8601": "2020-05-06T15:28:59.793339Z", "url": "https://files.pythonhosted.org/packages/8c/74/0c395e9378f6a91fcbdc65852d8f955bb4c30c04574c573fd782709880a6/cochl-sense-1.0.0.tar.gz", "yanked": false}], "1.0.0b2": [{"comment_text": "", "digests": {"md5": "80a61b75d30dbdb34a83dc1935d61bcc", "sha256": "6f2cb358d4f6d0832d1b046f9f80fdf32b0c5da17261b8430796c29d4b7251b2"}, "downloads": -1, "filename": "cochl_sense-1.0.0b2-py3-none-any.whl", "has_sig": false, "md5_digest": "80a61b75d30dbdb34a83dc1935d61bcc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5756, "upload_time": "2019-07-19T18:27:30", "upload_time_iso_8601": "2019-07-19T18:27:30.347593Z", "url": "https://files.pythonhosted.org/packages/95/aa/634c0780c7273e7c37213a43c4b24dd879ee6db1afcc8bd27bf24cced667/cochl_sense-1.0.0b2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "889411a561665ee2d4a79b270646594b", "sha256": "f6c4f1b476eb0a6c53a389d8cd55155b8fbf29c816c3568fab478be08b5eda9e"}, "downloads": -1, "filename": "cochl-sense-1.0.0b2.tar.gz", "has_sig": false, "md5_digest": "889411a561665ee2d4a79b270646594b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5067, "upload_time": "2019-07-19T18:27:32", "upload_time_iso_8601": "2019-07-19T18:27:32.699454Z", "url": "https://files.pythonhosted.org/packages/0c/f1/1ad7d59bf9bfd18cc77a6adf29aaa9abac104387ca80028b912925600b46/cochl-sense-1.0.0b2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "197dd7cefdb312820e68f8e6e07b4ecb", "sha256": "9fa7bc5ff3120c1d02bebf30bfe19b1e60306091e572b4cd04c609043e92c712"}, "downloads": -1, "filename": "cochl_sense-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "197dd7cefdb312820e68f8e6e07b4ecb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11705, "upload_time": "2020-05-06T15:28:57", "upload_time_iso_8601": "2020-05-06T15:28:57.736473Z", "url": "https://files.pythonhosted.org/packages/1c/f6/f5a2a90896fd0e83d6f2993c99e66ad526aab47dd66f9be063cfe55ec164/cochl_sense-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1648cd95bc49f6315b4c7a4ff4f2ea00", "sha256": "69c8cda03a5d993de1fea0c5bc1716adff26e1b88f5c8b613c12e61f899b290c"}, "downloads": -1, "filename": "cochl-sense-1.0.0.tar.gz", "has_sig": false, "md5_digest": "1648cd95bc49f6315b4c7a4ff4f2ea00", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13118, "upload_time": "2020-05-06T15:28:59", "upload_time_iso_8601": "2020-05-06T15:28:59.793339Z", "url": "https://files.pythonhosted.org/packages/8c/74/0c395e9378f6a91fcbdc65852d8f955bb4c30c04574c573fd782709880a6/cochl-sense-1.0.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:18:21 2020"}