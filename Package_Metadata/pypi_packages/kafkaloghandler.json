{"info": {"author": "Zack Williams", "author_email": "zdw@opennetworking.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Topic :: Internet :: Log Analysis", "Topic :: System :: Logging"], "description": "KafkaLogHandler\n===============\n\nProvides a python ``logging`` compatible handler for producing messages to a\nKafka message bus.\n\nDepends on the confluent_kafka module to connect to Kafka.\n\nDesigned to support both standard and structlog formats, and serializes log\ndata as JSON when published as a Kafka message.  Messages are normalized to be\nmore compatible with Logstash/Filebeat formats.\n\nUsage\n=====\n\n**Example:**\n\n::\n\n  import logger\n\n  from kafkaloghandler import KafkaLogHandler\n\n  log = logging.getLogger()\n\n  klh = KafkaLogHandler(bootstrap_servers=[\"test-kafka:9092\"], topic=\"testtopic\")\n\n  log.addHandler(klh)\n\n  data={'example':'structured data'}\n\n  log.info('message to send to kafka', data=data)\n\n\n**Parameters that can be provided to KafkaLogHandler:**\n\n*bootstrap_servers*\n  List of Kafka bootstrap servers to connect to.\n\n  **default:** ``[\"localhost:9092\"]``\n\n*extra_config*\n  Dictionary of extra `producer configuration\n  <https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md>`_\n  passed to librdkafka.\n\n  NOTE: The ``bootstrap_servers`` parameter will overwrite\n  ``bootstrap.servers``.\n\n  **default:** ``{}``\n\n\n*timeout*\n  Timeout in seconds for flushing producer queue. See librdkafka docs.\n\n  **default:** ``10.0``\n\n*topic*\n  String that sets the topic in Kafka.\n\n  **default:** ``\"kafkaloghandler\"``\n\n*key*\n  String that sets the default key in Kafka, can be used for summarization within Kafka.\n\n  NOTE: This default key can be overridden on a per-message basis by passing a\n  dict to the logger with ``{\"key\": \"new_key_for_this_message\"}`` in it.\n\n  **default:** ``\"klh\"``\n\n*flatten*\n  Flattens nested dictionaries and lists passed as structured logging into the parent\n  dictionary layer, up to a certain depth.\n\n  This is useful when logging to external systems that don't have good support\n  for hierarchical data.\n\n  Example dictionary: ``{'a': {'b': 'c'}}`` would be flattened to ``{'a.b': 'c'}``\n\n  Example list: ``{'a': ['b', 'c']}`` would be flattened to ``{'a.0': 'b', 'a.1': 'c'}``\n\n  If the depth is exceeded, any remaining deeper items will be added to the\n  output under the flattened key.\n\n  Set to ``0`` to turn off flattening.\n\n  **default:** ``5``\n\n*separator*\n  Separator used between items when flattening.\n\n  **default:** ``.``\n\n*blacklist*\n  List of top-level keys to discard from structured logs when outputting JSON.\n\n  **default:** ``[\"_logger\", \"_name\"]``\n\n\nTesting\n=======\n\nUnit tests can be run with ``tox``", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://gerrit.opencord.org/gitweb?p=kafkaloghandler.git", "keywords": "kafka,logging,log handler,message bus", "license": "Apache v2", "maintainer": "", "maintainer_email": "", "name": "kafkaloghandler", "package_url": "https://pypi.org/project/kafkaloghandler/", "platform": "", "project_url": "https://pypi.org/project/kafkaloghandler/", "project_urls": {"Homepage": "https://gerrit.opencord.org/gitweb?p=kafkaloghandler.git"}, "release_url": "https://pypi.org/project/kafkaloghandler/0.9.0/", "requires_dist": null, "requires_python": "", "summary": "Kafka Logging Handler", "version": "0.9.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"kafkaloghandler\">\n<h2>KafkaLogHandler</h2>\n<p>Provides a python <tt>logging</tt> compatible handler for producing messages to a\nKafka message bus.</p>\n<p>Depends on the confluent_kafka module to connect to Kafka.</p>\n<p>Designed to support both standard and structlog formats, and serializes log\ndata as JSON when published as a Kafka message.  Messages are normalized to be\nmore compatible with Logstash/Filebeat formats.</p>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p><strong>Example:</strong></p>\n<pre>import logger\n\nfrom kafkaloghandler import KafkaLogHandler\n\nlog = logging.getLogger()\n\nklh = KafkaLogHandler(bootstrap_servers=[\"test-kafka:9092\"], topic=\"testtopic\")\n\nlog.addHandler(klh)\n\ndata={'example':'structured data'}\n\nlog.info('message to send to kafka', data=data)\n</pre>\n<p><strong>Parameters that can be provided to KafkaLogHandler:</strong></p>\n<dl>\n<dt><em>bootstrap_servers</em></dt>\n<dd><p>List of Kafka bootstrap servers to connect to.</p>\n<p><strong>default:</strong> <tt>[\"localhost:9092\"]</tt></p>\n</dd>\n<dt><em>extra_config</em></dt>\n<dd><p>Dictionary of extra <a href=\"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\" rel=\"nofollow\">producer configuration</a>\npassed to librdkafka.</p>\n<p>NOTE: The <tt>bootstrap_servers</tt> parameter will overwrite\n<tt>bootstrap.servers</tt>.</p>\n<p><strong>default:</strong> <tt>{}</tt></p>\n</dd>\n<dt><em>timeout</em></dt>\n<dd><p>Timeout in seconds for flushing producer queue. See librdkafka docs.</p>\n<p><strong>default:</strong> <tt>10.0</tt></p>\n</dd>\n<dt><em>topic</em></dt>\n<dd><p>String that sets the topic in Kafka.</p>\n<p><strong>default:</strong> <tt>\"kafkaloghandler\"</tt></p>\n</dd>\n<dt><em>key</em></dt>\n<dd><p>String that sets the default key in Kafka, can be used for summarization within Kafka.</p>\n<p>NOTE: This default key can be overridden on a per-message basis by passing a\ndict to the logger with <tt>{\"key\": \"new_key_for_this_message\"}</tt> in it.</p>\n<p><strong>default:</strong> <tt>\"klh\"</tt></p>\n</dd>\n<dt><em>flatten</em></dt>\n<dd><p>Flattens nested dictionaries and lists passed as structured logging into the parent\ndictionary layer, up to a certain depth.</p>\n<p>This is useful when logging to external systems that don\u2019t have good support\nfor hierarchical data.</p>\n<p>Example dictionary: <tt>{'a': {'b': <span class=\"pre\">'c'}}</span></tt> would be flattened to <tt>{'a.b': 'c'}</tt></p>\n<p>Example list: <tt>{'a': ['b', <span class=\"pre\">'c']}</span></tt> would be flattened to <tt>{'a.0': 'b', 'a.1': 'c'}</tt></p>\n<p>If the depth is exceeded, any remaining deeper items will be added to the\noutput under the flattened key.</p>\n<p>Set to <tt>0</tt> to turn off flattening.</p>\n<p><strong>default:</strong> <tt>5</tt></p>\n</dd>\n<dt><em>separator</em></dt>\n<dd><p>Separator used between items when flattening.</p>\n<p><strong>default:</strong> <tt>.</tt></p>\n</dd>\n<dt><em>blacklist</em></dt>\n<dd><p>List of top-level keys to discard from structured logs when outputting JSON.</p>\n<p><strong>default:</strong> <tt>[\"_logger\", \"_name\"]</tt></p>\n</dd>\n</dl>\n</div>\n<div id=\"testing\">\n<h2>Testing</h2>\n<p>Unit tests can be run with <tt>tox</tt></p>\n</div>\n\n          </div>"}, "last_serial": 4783672, "releases": {"0.8.0": [{"comment_text": "", "digests": {"md5": "4c2b01b4562e1ca3fa0fa58a7194b7bf", "sha256": "e95dd124b3ca49fce3133034dd97ec160cdec8e8c4019764c361f71f79fc3eff"}, "downloads": -1, "filename": "kafkaloghandler-0.8.0.tar.gz", "has_sig": false, "md5_digest": "4c2b01b4562e1ca3fa0fa58a7194b7bf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4513, "upload_time": "2018-10-30T05:07:36", "upload_time_iso_8601": "2018-10-30T05:07:36.853625Z", "url": "https://files.pythonhosted.org/packages/ce/0c/b2c3d3d530dfedae8b314a4b7b5d2674cc75b581c1896e0bd27f474b359f/kafkaloghandler-0.8.0.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "dd7fd96b3b738f30f7197ee33fea265a", "sha256": "cdca2ba180616f806ee713184587efdfa105d4cd96b581fc424e1228a3eb7f42"}, "downloads": -1, "filename": "kafkaloghandler-0.9.0.tar.gz", "has_sig": false, "md5_digest": "dd7fd96b3b738f30f7197ee33fea265a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4824, "upload_time": "2018-11-07T17:31:08", "upload_time_iso_8601": "2018-11-07T17:31:08.712719Z", "url": "https://files.pythonhosted.org/packages/8f/1d/6cbc7618da6dd2a36db5dd665a57283520cea41d2bec750f058eebf3c689/kafkaloghandler-0.9.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dd7fd96b3b738f30f7197ee33fea265a", "sha256": "cdca2ba180616f806ee713184587efdfa105d4cd96b581fc424e1228a3eb7f42"}, "downloads": -1, "filename": "kafkaloghandler-0.9.0.tar.gz", "has_sig": false, "md5_digest": "dd7fd96b3b738f30f7197ee33fea265a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4824, "upload_time": "2018-11-07T17:31:08", "upload_time_iso_8601": "2018-11-07T17:31:08.712719Z", "url": "https://files.pythonhosted.org/packages/8f/1d/6cbc7618da6dd2a36db5dd665a57283520cea41d2bec750f058eebf3c689/kafkaloghandler-0.9.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:51 2020"}