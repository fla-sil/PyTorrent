{"info": {"author": "Grzegorz Wierzchowski", "author_email": "gwierzchowski@wp.pl", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Python Software Foundation License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries :: Python Modules"], "description": ".. Keep this file pure reST code (no Sphinx estensions)\n\nImportant links\n==================================\n\nIf you are reading this from github, package official documentation is avaialble on `<http://datconv.readthedocs.io>`_.\n\nIf you are reading documentation, source code is hosted on `<https://github.com/gwierzchowski/datconv>`_. In order to communicate with author, report bug etc. - please use Issues tab on github.\n\n\nDatconv - Universal Data Converter\n==================================\n\n**Datconv** is a program designed to perform configurable comversion of file\nwith data in one format to file with data in another format or database.\n\nProgram should be run using Python 2.7 or Python 3.x interpretter. It also requires\ninstallation of external packages: ``lxml``, ``PyYAML``. For more information see\n``INSTALL.rst`` file distributed in source pack.\n\nBoth input and output files can be text or binary files. However it is\nassumed that those files have following structure:\n\n|    -----\n|    Header \n|    -----\n|    Record 1 \n|    Record 2 \n|    .....\n|    Record N \n|    -----\n|    Footer\n|    -----\n\nThere may be different types of records (i.e. every record has attribute\ncalled record type). Each record may contain different number and kind of \ndata (has different internal structure) even among records of the same type.\n\nProgram has modular architecture with following swichable compoments:\n\n*Reader*\n    Major obligatory component responsible for:\n    \n    * reading input data (i.e. every reader class assumes certain input file format) \n    * driving entire data conversion process (i.e. main processing loop in implemented in this class) \n    * determine internal representation of header, records and footer (this heavily depands on reader and kind of input format).\n    \n*Filter*\n    Optional compoment that is able to: \n    \n    * filter data (i.e. do not pass certain records further - i.e. to Writer)\n    * change data (i.e. change on the fly contents of certain records) \n    * produce data (i.e. cause that certain records, maybe slightly modified, are being sent multiply times to writer) \n    * break conversion process (i.e. cause that conversion stop on certain record). \n\n*Writer*\n    Obligatory component responsible for: \n    \n    * re-packing data from element-tree internal format to strings or objects. \n\n*Output Connector*\n    Obligatory component responsible for: \n    \n    * writing data to destination storage. \n\n*Logger*\n    All messages intended to be presented to user are being send \n    (except few very initial error messages) to Logger classes from Python standard\n    package ``logging``. Datconv can use all logging comfiguration power available in this package.\n\nIn this version of package following compoments are included: \n\n* Readers: XML (sax), CSV (sax), JSON (sax). \n* Filters: Few basic/sample filters.\n* Writers: XML, CSV, XPath (helper module), JSON.\n* Output Connectors: File (Text, MS Excel), Databases (SQLite, PostgreSQL, Crate).\n\nSo Datconv program can be used to convert files between XML, CVS and JSON formats and saving data in those formats to database. \nSax means that used parsers are of event type - i.e. entire data are not being stored in memory (typically only just one record), what means that program is able to process large files without allocating a lot of memory.\nIt may be also usefull in case you have some files in custom program/company specific data format that you want to look up or convert. Then it is enough to write the reader component for your cutom data format compatible with Datconv API and let Datconv do the rest. \nActually this is how I'm currently using this program in my work.\n\nIf you'd prefer to work in JavaScript environment please look at `Pandat Project <https://github.com/pandat-team/pandat/>`_ which has similar design and purpose.\n\nThis program was inspired by design of `Pandoc Project <http://pandoc.org/>`_.\n\nPerformance\n=============\n\nMain design principle of this tool was generality and flexibility rather than performance and \nuse scenarios with very big data. This version of program runs in one thread (on one CPU core) and does not consume a lot of modern computer resources.                                                                                                                                  \nSo in case of processing of very big data consider dividing data into smaller chunks and run few instances of this program in parallell or use rfrom-rto parameters avaialble in readers. Or if you have to process big files in short time and do not need that much flexibility (espacially filtering possibilities) probaly special dedicated program (which will not translate data to internal XML-like format) would process your data faster.\n\nMeasured performance (version 0.6.0):\n\n- Hardware: Powerfull Laptop (2017 year), CPU Frequency 2.9 GHz, SSD Drive\n- Input: XML File: 942MB (400.000 records)\n- Output: JSON File: 639MB\n- Conversioon time without filter: 4 min 41 s\n- With filter (``datconv.filters.delfield``, 2 tags to remove): 4 min 41 s (the same; probably smaller record to write to JSON file compensated effort for Filter invocation).\n- Opposite direction (JSON output converted back to XML): 5 min 51 s.", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/gwierzchowski/datconv", "keywords": "", "license": "PSF", "maintainer": "", "maintainer_email": "", "name": "datconv", "package_url": "https://pypi.org/project/datconv/", "platform": "any", "project_url": "https://pypi.org/project/datconv/", "project_urls": {"Homepage": "https://github.com/gwierzchowski/datconv"}, "release_url": "https://pypi.org/project/datconv/0.8.2/", "requires_dist": null, "requires_python": "", "summary": "Universal data converter - pandoc for data; XML, CSV, JSON are supported", "version": "0.8.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"important-links\">\n<h2>Important links</h2>\n<p>If you are reading this from github, package official documentation is avaialble on <a href=\"http://datconv.readthedocs.io\" rel=\"nofollow\">http://datconv.readthedocs.io</a>.</p>\n<p>If you are reading documentation, source code is hosted on <a href=\"https://github.com/gwierzchowski/datconv\" rel=\"nofollow\">https://github.com/gwierzchowski/datconv</a>. In order to communicate with author, report bug etc. - please use Issues tab on github.</p>\n</div>\n<div id=\"datconv-universal-data-converter\">\n<h2>Datconv - Universal Data Converter</h2>\n<p><strong>Datconv</strong> is a program designed to perform configurable comversion of file\nwith data in one format to file with data in another format or database.</p>\n<p>Program should be run using Python 2.7 or Python 3.x interpretter. It also requires\ninstallation of external packages: <tt>lxml</tt>, <tt>PyYAML</tt>. For more information see\n<tt>INSTALL.rst</tt> file distributed in source pack.</p>\n<p>Both input and output files can be text or binary files. However it is\nassumed that those files have following structure:</p>\n<div>\n<div>\u2014\u2013</div>\n<div>Header</div>\n<div>\u2014\u2013</div>\n<div>Record 1</div>\n<div>Record 2</div>\n<div>\u2026..</div>\n<div>Record N</div>\n<div>\u2014\u2013</div>\n<div>Footer</div>\n<div>\u2014\u2013</div>\n</div>\n<p>There may be different types of records (i.e. every record has attribute\ncalled record type). Each record may contain different number and kind of\ndata (has different internal structure) even among records of the same type.</p>\n<p>Program has modular architecture with following swichable compoments:</p>\n<dl>\n<dt><em>Reader</em></dt>\n<dd><p>Major obligatory component responsible for:</p>\n<ul>\n<li>reading input data (i.e. every reader class assumes certain input file format)</li>\n<li>driving entire data conversion process (i.e. main processing loop in implemented in this class)</li>\n<li>determine internal representation of header, records and footer (this heavily depands on reader and kind of input format).</li>\n</ul>\n</dd>\n<dt><em>Filter</em></dt>\n<dd><p>Optional compoment that is able to:</p>\n<ul>\n<li>filter data (i.e. do not pass certain records further - i.e. to Writer)</li>\n<li>change data (i.e. change on the fly contents of certain records)</li>\n<li>produce data (i.e. cause that certain records, maybe slightly modified, are being sent multiply times to writer)</li>\n<li>break conversion process (i.e. cause that conversion stop on certain record).</li>\n</ul>\n</dd>\n<dt><em>Writer</em></dt>\n<dd><p>Obligatory component responsible for:</p>\n<ul>\n<li>re-packing data from element-tree internal format to strings or objects.</li>\n</ul>\n</dd>\n<dt><em>Output Connector</em></dt>\n<dd><p>Obligatory component responsible for:</p>\n<ul>\n<li>writing data to destination storage.</li>\n</ul>\n</dd>\n<dt><em>Logger</em></dt>\n<dd>All messages intended to be presented to user are being send\n(except few very initial error messages) to Logger classes from Python standard\npackage <tt>logging</tt>. Datconv can use all logging comfiguration power available in this package.</dd>\n</dl>\n<p>In this version of package following compoments are included:</p>\n<ul>\n<li>Readers: XML (sax), CSV (sax), JSON (sax).</li>\n<li>Filters: Few basic/sample filters.</li>\n<li>Writers: XML, CSV, XPath (helper module), JSON.</li>\n<li>Output Connectors: File (Text, MS Excel), Databases (SQLite, PostgreSQL, Crate).</li>\n</ul>\n<p>So Datconv program can be used to convert files between XML, CVS and JSON formats and saving data in those formats to database.\nSax means that used parsers are of event type - i.e. entire data are not being stored in memory (typically only just one record), what means that program is able to process large files without allocating a lot of memory.\nIt may be also usefull in case you have some files in custom program/company specific data format that you want to look up or convert. Then it is enough to write the reader component for your cutom data format compatible with Datconv API and let Datconv do the rest.\nActually this is how I\u2019m currently using this program in my work.</p>\n<p>If you\u2019d prefer to work in JavaScript environment please look at <a href=\"https://github.com/pandat-team/pandat/\" rel=\"nofollow\">Pandat Project</a> which has similar design and purpose.</p>\n<p>This program was inspired by design of <a href=\"http://pandoc.org/\" rel=\"nofollow\">Pandoc Project</a>.</p>\n</div>\n<div id=\"performance\">\n<h2>Performance</h2>\n<p>Main design principle of this tool was generality and flexibility rather than performance and\nuse scenarios with very big data. This version of program runs in one thread (on one CPU core) and does not consume a lot of modern computer resources.\nSo in case of processing of very big data consider dividing data into smaller chunks and run few instances of this program in parallell or use rfrom-rto parameters avaialble in readers. Or if you have to process big files in short time and do not need that much flexibility (espacially filtering possibilities) probaly special dedicated program (which will not translate data to internal XML-like format) would process your data faster.</p>\n<p>Measured performance (version 0.6.0):</p>\n<ul>\n<li>Hardware: Powerfull Laptop (2017 year), CPU Frequency 2.9 GHz, SSD Drive</li>\n<li>Input: XML File: 942MB (400.000 records)</li>\n<li>Output: JSON File: 639MB</li>\n<li>Conversioon time without filter: 4 min 41 s</li>\n<li>With filter (<tt>datconv.filters.delfield</tt>, 2 tags to remove): 4 min 41 s (the same; probably smaller record to write to JSON file compensated effort for Filter invocation).</li>\n<li>Opposite direction (JSON output converted back to XML): 5 min 51 s.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 6369902, "releases": {"0.2.2": [{"comment_text": "", "digests": {"md5": "378e4a0cf3986d384d4145d9c64fcc01", "sha256": "3c10fee5a4f236198c92b2a825b93e2e565d0053350264bf6023b4f771352551"}, "downloads": -1, "filename": "datconv-0.2.2.tar.gz", "has_sig": false, "md5_digest": "378e4a0cf3986d384d4145d9c64fcc01", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23740, "upload_time": "2016-01-15T22:08:32", "upload_time_iso_8601": "2016-01-15T22:08:32.724051Z", "url": "https://files.pythonhosted.org/packages/bf/ab/cec131198dd666271546a27aa9be8fe440b96a7e53cd06d34f9c875b8215/datconv-0.2.2.tar.gz", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "d9a7cf2ea357d3f392c47363797ea430", "sha256": "521546e2c41356a9563d5e4be6ba81837e2ff709a6b6a4c0db3422f7f6f653e1"}, "downloads": -1, "filename": "datconv-0.2.3.tar.gz", "has_sig": false, "md5_digest": "d9a7cf2ea357d3f392c47363797ea430", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24216, "upload_time": "2016-01-20T22:17:48", "upload_time_iso_8601": "2016-01-20T22:17:48.259726Z", "url": "https://files.pythonhosted.org/packages/21/25/8820b61e1e8e03740d12284500e946c6745dd718dc600d3271c20541f45f/datconv-0.2.3.tar.gz", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "80f54e34af6e492af59e8201a5b48d20", "sha256": "02fc65fb62a3adf95e19ac5cf84b22fff514d2f236852442194896765889dfb1"}, "downloads": -1, "filename": "datconv-0.2.4.tar.gz", "has_sig": false, "md5_digest": "80f54e34af6e492af59e8201a5b48d20", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26238, "upload_time": "2016-03-06T08:53:11", "upload_time_iso_8601": "2016-03-06T08:53:11.896885Z", "url": "https://files.pythonhosted.org/packages/17/e6/ebb2310556ff0416f57c3965eeb7e3e97d17afcf5c7355c1354a592440fc/datconv-0.2.4.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "c887acbf20c7752a410c1b0e80f149ac", "sha256": "5ef59a4db476f6f6b135743993ba6d4e53ad57990499b396aa75a9be489bb529"}, "downloads": -1, "filename": "datconv-0.3.0.tar.gz", "has_sig": false, "md5_digest": "c887acbf20c7752a410c1b0e80f149ac", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27073, "upload_time": "2016-05-24T20:50:46", "upload_time_iso_8601": "2016-05-24T20:50:46.764026Z", "url": "https://files.pythonhosted.org/packages/58/cb/e6274ea1b6ba8b8e76366ad483b75d571bb37d8dfa9e3381f4160fdb0864/datconv-0.3.0.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "9faae51773b19d9eb328104bdceb84dd", "sha256": "f7b767bc1f5c9a49feb11561574e023a71937e83c227ef1521df50e5c1eff9f7"}, "downloads": -1, "filename": "datconv-0.3.1.tar.gz", "has_sig": false, "md5_digest": "9faae51773b19d9eb328104bdceb84dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27253, "upload_time": "2016-05-27T22:07:35", "upload_time_iso_8601": "2016-05-27T22:07:35.122278Z", "url": "https://files.pythonhosted.org/packages/d1/23/af54b2d6cc8a31f043a46d86af9ee71b4e2734feb61492c7ecf78c661c35/datconv-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "05190cc0ed3abec5ffade14d5bd0a13a", "sha256": "8555d4c839efa3f33cce381aecc2f7aa4a05425e2d944dc89d554126bb320179"}, "downloads": -1, "filename": "datconv-0.3.2.tar.gz", "has_sig": false, "md5_digest": "05190cc0ed3abec5ffade14d5bd0a13a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27427, "upload_time": "2016-06-01T08:48:33", "upload_time_iso_8601": "2016-06-01T08:48:33.449087Z", "url": "https://files.pythonhosted.org/packages/87/fb/c278d4be96f4619a76ea1d15d11248b6b3936e1e26a6d3838b008ae89902/datconv-0.3.2.tar.gz", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "0f760f998f3260fafabe05547cc081d2", "sha256": "0014faf07e3e25863b0fbf68ab255fcd28f90eb0c30ef447faee7cf93b3d5432"}, "downloads": -1, "filename": "datconv-0.3.4.tar.gz", "has_sig": false, "md5_digest": "0f760f998f3260fafabe05547cc081d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27422, "upload_time": "2017-05-12T22:42:38", "upload_time_iso_8601": "2017-05-12T22:42:38.219289Z", "url": "https://files.pythonhosted.org/packages/7f/84/101a938c6d331aebaafba65b3e117e9d9cf9f4af8fcd3207263388f9ac4d/datconv-0.3.4.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "98f4e757ade8cab66b5bf9bcca0993dc", "sha256": "aa70ddf7f5626af3821583d514293ca711ef7cd6489a99f444921f9595069e85"}, "downloads": -1, "filename": "datconv-0.4.0.tar.gz", "has_sig": false, "md5_digest": "98f4e757ade8cab66b5bf9bcca0993dc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33951, "upload_time": "2017-08-15T16:53:29", "upload_time_iso_8601": "2017-08-15T16:53:29.889653Z", "url": "https://files.pythonhosted.org/packages/3d/bf/f1e9263aaf83121015ebbcce3947ccaa16497809f20978b697e7d32ce6c0/datconv-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "5aed58e124d5b91645557fea2738858a", "sha256": "e741da36c0217dd614147813fd2054e64e53209e8f9ef2e7c18ba33d65b3f275"}, "downloads": -1, "filename": "datconv-0.4.1.tar.gz", "has_sig": false, "md5_digest": "5aed58e124d5b91645557fea2738858a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34243, "upload_time": "2017-08-16T19:55:24", "upload_time_iso_8601": "2017-08-16T19:55:24.278102Z", "url": "https://files.pythonhosted.org/packages/91/4b/5ca937b955b58eb69a41001149a6f12a92eb7e9ea9bac22cfda06a918753/datconv-0.4.1.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "599da05485ada4d3ad0bf99078c4f803", "sha256": "179a2f3ab725bde37a91c1cd001b22f7eef32fcd792027feb4f285609249d3c4"}, "downloads": -1, "filename": "datconv-0.5.0.tar.gz", "has_sig": false, "md5_digest": "599da05485ada4d3ad0bf99078c4f803", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35823, "upload_time": "2018-01-19T20:32:00", "upload_time_iso_8601": "2018-01-19T20:32:00.450063Z", "url": "https://files.pythonhosted.org/packages/7d/a0/d0ae740094cc318cbda6a0b241176264497909ad088fb8549bbe4c63c3f9/datconv-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "01bf6b622af76ba7dbca5b126e78cd1c", "sha256": "e390e01185f1c5e18bc383699768c4bbd2a7fc82d28407f20dc01d5af395c5a4"}, "downloads": -1, "filename": "datconv-0.5.1.tar.gz", "has_sig": false, "md5_digest": "01bf6b622af76ba7dbca5b126e78cd1c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36959, "upload_time": "2018-01-28T10:18:28", "upload_time_iso_8601": "2018-01-28T10:18:28.359700Z", "url": "https://files.pythonhosted.org/packages/3d/e3/fcb725396d582bbf050adf4b5fc30790f4583d23a5a7b90325b8d65c9c29/datconv-0.5.1.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "33d923eaa38d54f6a3eade2e0403f081", "sha256": "44a432cafbd196466b77bf981e5d3ff690914daf1ff0d9da0f0220cecb52ec24"}, "downloads": -1, "filename": "datconv-0.6.0.tar.gz", "has_sig": false, "md5_digest": "33d923eaa38d54f6a3eade2e0403f081", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 57125, "upload_time": "2018-02-25T08:54:30", "upload_time_iso_8601": "2018-02-25T08:54:30.807267Z", "url": "https://files.pythonhosted.org/packages/40/77/cbc7597375ba7fdec8bd788c4d7774b7af114d5fe1a50ce04b6b69bc02de/datconv-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "04fa99aaacc5e74e2c3f8704732cc6b2", "sha256": "c4795d8340cc965bde437ac2d35dbfcf6ba1917ab7637ed276b65cdf3d6d1cb0"}, "downloads": -1, "filename": "datconv-0.6.1.tar.gz", "has_sig": false, "md5_digest": "04fa99aaacc5e74e2c3f8704732cc6b2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 59476, "upload_time": "2018-03-18T17:33:54", "upload_time_iso_8601": "2018-03-18T17:33:54.044842Z", "url": "https://files.pythonhosted.org/packages/26/b5/318725611af3d03d3b02bed713e14fbddb5f6b04edfe4279956c3088c878/datconv-0.6.1.tar.gz", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "f6d7eaee1c0960cb871495fa22fd319b", "sha256": "05155f1fc094b2f43454f95445011244adea58d3fba4aab4412ea2b56d58a5ae"}, "downloads": -1, "filename": "datconv-0.7.2.tar.gz", "has_sig": false, "md5_digest": "f6d7eaee1c0960cb871495fa22fd319b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 64253, "upload_time": "2018-04-19T22:32:38", "upload_time_iso_8601": "2018-04-19T22:32:38.698425Z", "url": "https://files.pythonhosted.org/packages/ae/80/83d30cd46f015c59ad8486de8eda5a9184329adea1cb6d62cea3d66ba328/datconv-0.7.2.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "2d23555d28db847e567f0ae7fb2a51b9", "sha256": "79d0ae0a5c1e9f322f228985120239e7395521f17e77d1b5b15966b4c34be475"}, "downloads": -1, "filename": "datconv-0.8.0.tar.gz", "has_sig": false, "md5_digest": "2d23555d28db847e567f0ae7fb2a51b9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63170, "upload_time": "2018-08-23T07:43:12", "upload_time_iso_8601": "2018-08-23T07:43:12.332427Z", "url": "https://files.pythonhosted.org/packages/b1/39/64d4a4b4756cd6aa2d919e8e8e4dea6e433f3243fb69326a5b1c9e154cb8/datconv-0.8.0.tar.gz", "yanked": false}], "0.8.2": [{"comment_text": "", "digests": {"md5": "6e98045e3093b2040756ffb785ba7fbb", "sha256": "db0f33f3ab1acddbd7fe50c1c81b5c3a27496b1c2eff332277eed4bf29b67790"}, "downloads": -1, "filename": "datconv-0.8.2.tar.gz", "has_sig": false, "md5_digest": "6e98045e3093b2040756ffb785ba7fbb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63429, "upload_time": "2019-12-29T00:16:58", "upload_time_iso_8601": "2019-12-29T00:16:58.858681Z", "url": "https://files.pythonhosted.org/packages/d6/62/6f91962007e5f0ea6bba5f0981780f867aecbe61b3ebc496d2be1ce64657/datconv-0.8.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6e98045e3093b2040756ffb785ba7fbb", "sha256": "db0f33f3ab1acddbd7fe50c1c81b5c3a27496b1c2eff332277eed4bf29b67790"}, "downloads": -1, "filename": "datconv-0.8.2.tar.gz", "has_sig": false, "md5_digest": "6e98045e3093b2040756ffb785ba7fbb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 63429, "upload_time": "2019-12-29T00:16:58", "upload_time_iso_8601": "2019-12-29T00:16:58.858681Z", "url": "https://files.pythonhosted.org/packages/d6/62/6f91962007e5f0ea6bba5f0981780f867aecbe61b3ebc496d2be1ce64657/datconv-0.8.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:06 2020"}