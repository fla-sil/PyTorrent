{"info": {"author": "Shlomi Hod", "author_email": "shlomi.hod@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Text Processing :: Linguistic"], "description": "Responsibly\n===========\n\n.. image:: https://img.shields.io/badge/docs-passing-brightgreen.svg\n    :target: https://docs.responsibly.ai\n\n.. image:: https://img.shields.io/gitter/room/nwjs/nw.js.svg\n   :alt: Join the chat at https://gitter.im/ResponsiblyAI/responsibly\n   :target: https://gitter.im/ResponsiblyAI/responsibly\n\n.. image:: https://img.shields.io/travis/ResponsiblyAI/responsibly/master.svg\n    :target: https://travis-ci.org/ResponsiblyAI/responsibly\n\n.. image::  https://img.shields.io/coveralls/ResponsiblyAI/responsibly/master.svg\n   :target: https://coveralls.io/r/ResponsiblyAI/responsibly\n\n.. image::  https://img.shields.io/scrutinizer/g/ResponsiblyAI/responsibly.svg\n  :target: https://scrutinizer-ci.com/g/ResponsiblyAI/responsibly/?branch=master\n\n.. image::  https://img.shields.io/pypi/v/responsibly.svg\n  :target: https://pypi.org/project/responsibly\n\n.. image::  https://img.shields.io/github/license/ResponsiblyAI/responsibly.svg\n    :target: https://docs.responsibly.ai/about/license.html\n\n**Toolkit for Auditing and Mitigating Bias and Fairness**\n**of Machine Learning Systems \ud83d\udd0e\ud83e\udd16\ud83e\uddf0**\n\n*Responsibly* is developed for **practitioners** and **researchers** in mind,\nbut also for learners. Therefore, it is compatible with\ndata science and machine learning tools of trade in Python,\nsuch as Numpy, Pandas, and especially **scikit-learn**.\n\nThe primary goal is to be one-shop-stop for **auditing** bias\nand fairness of machine learning systems, and the secondary one\nis to mitigate bias and adjust fairness through\n**algorithmic interventions**.\nBesides, there is a particular focus on **NLP** models.\n\n*Responsibly* consists of three sub-packages:\n\n1. ``responsibly.dataset``\n     Collection of common benchmark datasets from fairness research.\n\n2. ``responsibly.fairness``\n     Demographic fairness in binary classification,\n     including metrics and algorithmic interventions.\n\n3. ``responsibly.we``\n     Metrics and debiasing methods for bias (such as gender and race)\n     in word embedding.\n\nFor fairness, *Responsibly*'s functionality is aligned with the book\n`Fairness and Machine Learning\n- Limitations and Opportunities <https://fairmlbook.org>`_\nby Solon Barocas, Moritz Hardt and Arvind Narayanan.\n\nIf you would like to ask for a feature or report a bug,\nplease open a\n`new issue <https://github.com/ResponsiblyAI/responsibly/issues/new>`_\nor write us in `Gitter <https://gitter.im/ResponsiblyAI/responsibly>`_.\n\nRequirements\n------------\n\n-  Python 3.5+\n\nInstallation\n------------\n\nInstall responsibly with pip:\n\n.. code:: sh\n\n   $ pip install responsibly\n\nor directly from the source code:\n\n.. code:: sh\n\n   $ git clone https://github.com/ResponsiblyAI/responsibly.git\n   $ cd responsibly\n   $ python setup.py install\n\nCitation\n--------\n\nIf you have used *Responsibly* in a scientific publication,\nwe would appreciate citations to the following:\n\n::\n\n  @Misc{,\n    author = {Shlomi Hod},\n    title =  {{Responsibly}: Toolkit for Auditing and Mitigating Bias and Fairness of Machine Learning Systems},\n    year =   {2018--},\n    url =    \"http://docs.responsibly.ai/\",\n    note =   {[Online; accessed <today>]}\n  }\n\nRevision History\n================\n\n0.1.1 (2019/08/04)\n------------------\n\n- Fix a dependencies issue with ``smart_open``\n\n- Change URLs to https\n\n0.1.0 (2019/07/31)\n------------------\n\n- Rename the project to ``responsibly`` from ``ethically``\n\n- Word embedding bias\n\n  - Improve functionality of ``BiasWordEmbedding``\n\n- Threshold fairness interventions\n\n  - Fix bugs with ROCs handling\n  - Improve API and add functionality (``plot_thresholds``)\n\n0.0.5 (2019/06/14)\n------------------\n\n- Word embedding bias\n\n  - Fix bug in computing WEAT\n\n  - Computing and plotting factual property\n    association to projections on a bias direction,\n    similar to WEFAT\n\n\n0.0.4 (2019/06/03)\n------------------\n\n- Word embedding bias\n\n  - Unrestricted ``most_similar``\n\n  - Unrestricted ``generate_analogies``\n\n  - Running specific experiments with ``calc_all_weat``\n\n  - Plotting clustering by classification\n    of biased neutral words\n\n\n0.0.3 (2019/04/10)\n------------------\n\n- Fairness in Classification\n\n  - Three demographic fairness criteria\n\n    - Independence\n    - Separation\n    - Sufficiency\n\n  - Equalized odds post-processing algorithmic interventions\n  - Complete two notebook demos (FICO and COMPAS)\n\n- Word embedding bias\n\n  - Measuring bias with WEAT method\n\n- Documentation improvements\n\n- Fixing security issues with dependencies\n\n\n0.0.2 (2018/09/01)\n------------------\n\n- Word embedding bias\n\n  - Generating analogies along the bias direction\n  - Standard evaluations of word embedding (word pairs and analogies)\n  - Plotting indirect bias\n  - Scatter plot of bias direction projections between two word embedding\n  - Improved verbose mode\n\n\n0.0.1 (2018/08/17)\n------------------\n\n-  Gender debiasing for word embedding based on Bolukbasi et al.\n\n\n", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://docs.responsibly.ai", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "responsibly", "package_url": "https://pypi.org/project/responsibly/", "platform": "", "project_url": "https://pypi.org/project/responsibly/", "project_urls": {"Homepage": "https://docs.responsibly.ai"}, "release_url": "https://pypi.org/project/responsibly/0.1.1/", "requires_dist": ["numpy (>=1.15)", "scipy (>=1.1)", "pandas (>=0.23)", "matplotlib (<3,>=2.2)", "seaborn (>=0.9)", "scikit-learn (>=0.19)", "gensim (>=3.7)", "tabulate (>=0.8)", "six (>=1.10)", "click (>=6.0)", "tqdm (>=4.24)", "mlxtend (<0.17,>=0.13)"], "requires_python": "", "summary": "Toolkit for Auditing and Mitigating Bias and Fairness of Machine Learning Systems \ud83d\udd0e\ud83e\udd16\ud83e\uddf0", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"responsibly\">\n<h2>Responsibly</h2>\n<a href=\"https://docs.responsibly.ai\" rel=\"nofollow\"><img alt=\"https://img.shields.io/badge/docs-passing-brightgreen.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e0a325716db49cd1643978115d783c4048a974ac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d70617373696e672d627269676874677265656e2e737667\"></a>\n<a href=\"https://gitter.im/ResponsiblyAI/responsibly\" rel=\"nofollow\"><img alt=\"Join the chat at https://gitter.im/ResponsiblyAI/responsibly\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/319dc552eb84e14bba41bb4a6396da3cf070c024/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6e776a732f6e772e6a732e737667\"></a>\n<a href=\"https://travis-ci.org/ResponsiblyAI/responsibly\" rel=\"nofollow\"><img alt=\"https://img.shields.io/travis/ResponsiblyAI/responsibly/master.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a2ee6aeb2c79ad9c797130f3b8b1e3fa25d41448/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f526573706f6e7369626c7941492f726573706f6e7369626c792f6d61737465722e737667\"></a>\n<a href=\"https://coveralls.io/r/ResponsiblyAI/responsibly\" rel=\"nofollow\"><img alt=\"https://img.shields.io/coveralls/ResponsiblyAI/responsibly/master.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/93436556bc46053a4c38a07d46690f754fdc59bd/68747470733a2f2f696d672e736869656c64732e696f2f636f766572616c6c732f526573706f6e7369626c7941492f726573706f6e7369626c792f6d61737465722e737667\"></a>\n<a href=\"https://scrutinizer-ci.com/g/ResponsiblyAI/responsibly/?branch=master\" rel=\"nofollow\"><img alt=\"https://img.shields.io/scrutinizer/g/ResponsiblyAI/responsibly.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d26fc0a9e51a99e2fd9a77b8b83da3f04b0222c0/68747470733a2f2f696d672e736869656c64732e696f2f7363727574696e697a65722f672f526573706f6e7369626c7941492f726573706f6e7369626c792e737667\"></a>\n<a href=\"https://pypi.org/project/responsibly\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/responsibly.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e61aca7172087b1da084367fb5187cd17a23183/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f726573706f6e7369626c792e737667\"></a>\n<a href=\"https://docs.responsibly.ai/about/license.html\" rel=\"nofollow\"><img alt=\"https://img.shields.io/github/license/ResponsiblyAI/responsibly.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d0700d620fb5382005547bec81339b7c7c714d3f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f526573706f6e7369626c7941492f726573706f6e7369626c792e737667\"></a>\n<p><strong>Toolkit for Auditing and Mitigating Bias and Fairness</strong>\n<strong>of Machine Learning Systems \ud83d\udd0e\ud83e\udd16\ud83e\uddf0</strong></p>\n<p><em>Responsibly</em> is developed for <strong>practitioners</strong> and <strong>researchers</strong> in mind,\nbut also for learners. Therefore, it is compatible with\ndata science and machine learning tools of trade in Python,\nsuch as Numpy, Pandas, and especially <strong>scikit-learn</strong>.</p>\n<p>The primary goal is to be one-shop-stop for <strong>auditing</strong> bias\nand fairness of machine learning systems, and the secondary one\nis to mitigate bias and adjust fairness through\n<strong>algorithmic interventions</strong>.\nBesides, there is a particular focus on <strong>NLP</strong> models.</p>\n<p><em>Responsibly</em> consists of three sub-packages:</p>\n<ol>\n<li><dl>\n<dt><tt>responsibly.dataset</tt></dt>\n<dd>Collection of common benchmark datasets from fairness research.</dd>\n</dl>\n</li>\n<li><dl>\n<dt><tt>responsibly.fairness</tt></dt>\n<dd>Demographic fairness in binary classification,\nincluding metrics and algorithmic interventions.</dd>\n</dl>\n</li>\n<li><dl>\n<dt><tt>responsibly.we</tt></dt>\n<dd>Metrics and debiasing methods for bias (such as gender and race)\nin word embedding.</dd>\n</dl>\n</li>\n</ol>\n<p>For fairness, <em>Responsibly</em>\u2019s functionality is aligned with the book\n<a href=\"https://fairmlbook.org\" rel=\"nofollow\">Fairness and Machine Learning\n- Limitations and Opportunities</a>\nby Solon Barocas, Moritz Hardt and Arvind Narayanan.</p>\n<p>If you would like to ask for a feature or report a bug,\nplease open a\n<a href=\"https://github.com/ResponsiblyAI/responsibly/issues/new\" rel=\"nofollow\">new issue</a>\nor write us in <a href=\"https://gitter.im/ResponsiblyAI/responsibly\" rel=\"nofollow\">Gitter</a>.</p>\n<div id=\"requirements\">\n<h3>Requirements</h3>\n<ul>\n<li>Python 3.5+</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h3>Installation</h3>\n<p>Install responsibly with pip:</p>\n<pre>$ pip install responsibly\n</pre>\n<p>or directly from the source code:</p>\n<pre>$ git clone https://github.com/ResponsiblyAI/responsibly.git\n$ <span class=\"nb\">cd</span> responsibly\n$ python setup.py install\n</pre>\n</div>\n<div id=\"citation\">\n<h3>Citation</h3>\n<p>If you have used <em>Responsibly</em> in a scientific publication,\nwe would appreciate citations to the following:</p>\n<pre>@Misc{,\n  author = {Shlomi Hod},\n  title =  {{Responsibly}: Toolkit for Auditing and Mitigating Bias and Fairness of Machine Learning Systems},\n  year =   {2018--},\n  url =    \"http://docs.responsibly.ai/\",\n  note =   {[Online; accessed &lt;today&gt;]}\n}\n</pre>\n</div>\n</div>\n<div id=\"revision-history\">\n<h2>Revision History</h2>\n<div id=\"id1\">\n<h3>0.1.1 (2019/08/04)</h3>\n<ul>\n<li>Fix a dependencies issue with <tt>smart_open</tt></li>\n<li>Change URLs to https</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h3>0.1.0 (2019/07/31)</h3>\n<ul>\n<li>Rename the project to <tt>responsibly</tt> from <tt>ethically</tt></li>\n<li>Word embedding bias<ul>\n<li>Improve functionality of <tt>BiasWordEmbedding</tt></li>\n</ul>\n</li>\n<li>Threshold fairness interventions<ul>\n<li>Fix bugs with ROCs handling</li>\n<li>Improve API and add functionality (<tt>plot_thresholds</tt>)</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"id3\">\n<h3>0.0.5 (2019/06/14)</h3>\n<ul>\n<li>Word embedding bias<ul>\n<li>Fix bug in computing WEAT</li>\n<li>Computing and plotting factual property\nassociation to projections on a bias direction,\nsimilar to WEFAT</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h3>0.0.4 (2019/06/03)</h3>\n<ul>\n<li>Word embedding bias<ul>\n<li>Unrestricted <tt>most_similar</tt></li>\n<li>Unrestricted <tt>generate_analogies</tt></li>\n<li>Running specific experiments with <tt>calc_all_weat</tt></li>\n<li>Plotting clustering by classification\nof biased neutral words</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"id5\">\n<h3>0.0.3 (2019/04/10)</h3>\n<ul>\n<li>Fairness in Classification<ul>\n<li>Three demographic fairness criteria<ul>\n<li>Independence</li>\n<li>Separation</li>\n<li>Sufficiency</li>\n</ul>\n</li>\n<li>Equalized odds post-processing algorithmic interventions</li>\n<li>Complete two notebook demos (FICO and COMPAS)</li>\n</ul>\n</li>\n<li>Word embedding bias<ul>\n<li>Measuring bias with WEAT method</li>\n</ul>\n</li>\n<li>Documentation improvements</li>\n<li>Fixing security issues with dependencies</li>\n</ul>\n</div>\n<div id=\"id6\">\n<h3>0.0.2 (2018/09/01)</h3>\n<ul>\n<li>Word embedding bias<ul>\n<li>Generating analogies along the bias direction</li>\n<li>Standard evaluations of word embedding (word pairs and analogies)</li>\n<li>Plotting indirect bias</li>\n<li>Scatter plot of bias direction projections between two word embedding</li>\n<li>Improved verbose mode</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"id7\">\n<h3>0.0.1 (2018/08/17)</h3>\n<ul>\n<li>Gender debiasing for word embedding based on Bolukbasi et al.</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5631536, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "1cfc2f13654cc465021939d124bbb044", "sha256": "3ae8dc2855fbc9afe3605f08fcd4ed67fb82af1a32bbcb790348542cd5664c63"}, "downloads": -1, "filename": "responsibly-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1cfc2f13654cc465021939d124bbb044", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28201168, "upload_time": "2019-08-04T07:55:53", "upload_time_iso_8601": "2019-08-04T07:55:53.503083Z", "url": "https://files.pythonhosted.org/packages/5f/11/be4eddcb29418446f067a414c74982f711dc9079a7abed5f1a944ea224ad/responsibly-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e457e63d2ae385e4bf99fa16303c16b8", "sha256": "7f55fce3db8944596e0e9a88763d29c8690c593e5efee676fdddfb7c833f229c"}, "downloads": -1, "filename": "responsibly-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e457e63d2ae385e4bf99fa16303c16b8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28139232, "upload_time": "2019-08-04T07:56:22", "upload_time_iso_8601": "2019-08-04T07:56:22.057560Z", "url": "https://files.pythonhosted.org/packages/0f/9a/3edcb1336e6bb65784465e8ad129502d497515d6beb44f90b322e31fa4f1/responsibly-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "1a87e9fa58f3c914f89d5cddf956ab2a", "sha256": "67b378855640585cbec7c88ba41d98dfb5ae0ee0dd0c5d653703037239d8d8f2"}, "downloads": -1, "filename": "responsibly-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1a87e9fa58f3c914f89d5cddf956ab2a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28201190, "upload_time": "2019-08-04T20:40:47", "upload_time_iso_8601": "2019-08-04T20:40:47.371173Z", "url": "https://files.pythonhosted.org/packages/10/f6/dc0af2236f1b5095d619065ed15d16784e15230151b6750fa7777645a972/responsibly-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2576c89faad15d9d03e0d18829c62148", "sha256": "64e6701389a671543edc46b911203fffeddaab12180e246ddfc2d2bb8b98404c"}, "downloads": -1, "filename": "responsibly-0.1.1.tar.gz", "has_sig": false, "md5_digest": "2576c89faad15d9d03e0d18829c62148", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28139249, "upload_time": "2019-08-04T20:41:39", "upload_time_iso_8601": "2019-08-04T20:41:39.112862Z", "url": "https://files.pythonhosted.org/packages/34/16/e87dc9b02659174646ecc023265c4de84fe326011d3466ada54313db1004/responsibly-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1a87e9fa58f3c914f89d5cddf956ab2a", "sha256": "67b378855640585cbec7c88ba41d98dfb5ae0ee0dd0c5d653703037239d8d8f2"}, "downloads": -1, "filename": "responsibly-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1a87e9fa58f3c914f89d5cddf956ab2a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28201190, "upload_time": "2019-08-04T20:40:47", "upload_time_iso_8601": "2019-08-04T20:40:47.371173Z", "url": "https://files.pythonhosted.org/packages/10/f6/dc0af2236f1b5095d619065ed15d16784e15230151b6750fa7777645a972/responsibly-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2576c89faad15d9d03e0d18829c62148", "sha256": "64e6701389a671543edc46b911203fffeddaab12180e246ddfc2d2bb8b98404c"}, "downloads": -1, "filename": "responsibly-0.1.1.tar.gz", "has_sig": false, "md5_digest": "2576c89faad15d9d03e0d18829c62148", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28139249, "upload_time": "2019-08-04T20:41:39", "upload_time_iso_8601": "2019-08-04T20:41:39.112862Z", "url": "https://files.pythonhosted.org/packages/34/16/e87dc9b02659174646ecc023265c4de84fe326011d3466ada54313db1004/responsibly-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:03:45 2020"}