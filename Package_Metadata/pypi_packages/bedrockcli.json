{"info": {"author": "Ben Fortuna", "author_email": "fortuna@micronode.com", "bugtrack_url": null, "classifiers": [], "description": "# Bedrock - Building blocks for composable Cloud architectures \n\n[principle of least privilege]: https://en.wikipedia.org/wiki/Principle_of_least_privilege\n\n[Docker]: https://docker.com\n[Terraform]: https://terraform.io\n[Cloudformation]: https://aws.amazon.com/cloudformation/\n[Terragrunt]: https://github.com/gruntwork-io/terragrunt\n[Astro]: https://github.com/uber/astro\n\n[Introduction]: #introduction\n\n[Features]: #features\n\n[Getting started]: #getting-started\n[Requirements]: #requirements\n[Configuring]: #configuring\n\n\n[Examples]: #examples\n\n[Development]: #development\n\n[Contributing]: #contributing\n\n#### Table of Contents\n\n1. [Introduction - What is Bedrock?][Introduction]\n2. [Features][Features]\n3. [Getting started - How to use Bedrock][Getting started]\n\t- [Requirements]\n\t- [Configuring]\n    - [Examples - common usage scenarios][Examples]\n4. [Development - Guide for contributing to the Bedrock project][Development]\n    - [Contributing to Bedrock][Contributing]\n\n## Introduction\n\nBedrock is a collection of managed role-based policies and Terraform-based blueprints to assist with provisioning \ninfrastructure and services. When we design modern computing architectures it is important to consider security, \nreliability and efficiency as equally important concerns. With public Cloud architectures in particular, security must \nbe addressed throughout the entire architecture, and not just at the perimiter.\n\nRole-based access control (RBAC) allows us to restrict actors to the minimum required permissions, which is commonly \nreferred to as the [principle of least privilege], and is the basis for the architectural blueprints provided by \nBedrock. \n\n### Terraform\n\nThe Bedrock blueprints are based on popular tools such as [Terraform] and [Cloudformation], and provide both an \ninformative and practical approach to infrastructure provisioning. You are encouraged to explore and critique these \nblueprints as they should continue to evolve over time.\n\n## Features\n\nThe purpose of Bedrock is not only to provide best-practice blueprints for modern architectures, but to explore and\neducate about the challenges, decisions and opinions behind the designs themselves. As such, Bedrock aims to avoid\na \"black box\" approach and is designed to encourage hacking and examining the underlying code.\n\n### Blueprint\n\nBlueprints provide an opinionated approach to provisioning an infrastructure component based on common and/or best-\npractice approaches. \n\nBlueprints may be either platform-based (i.e. AWS, Azure, Openstack, etc.) or service-based (i.e\nNGINX, Bastion, Squid Proxy, etc.). Typically they are identified using one of the following naming conventions:\n\n    <platform>-<service>[-<component>]\n    \n    examples: aws-ec2-autoscaling, aws-ecs-cluster, azure-cdn, openstack-network, etc.\n    \n    or;\n    \n    <service>[-<component>][-<platform>]\n    \n    examples: nginx-reverseproxy-aws, bastion-do, rancher-stack, squidproxy-aws, etc.\n    \n  \n\n### Manifest\n\nA manifest provides a way to define one or more collections of blueprints (a constellation) and associated \nconfigurations that make up a complete architecture.\n\nOften a single blueprint is not sufficient to define a Cloud architecture as they are more likely to be distributed \nacross multiple services. For example, you might have an ECS cluster for web/API applications, RDS or DynamDB for \npersistence, and S3 for archiving.\n\nWithin each of these tiers are additional ancillary services such as route53 for well-known endpoints and/or service \ndiscovery, cloudwatch events/triggers, etc. The collection of blueprints that encapsulates and independent function is \ncalled a constellation. Multiple constellations may be defined in a single manifest such that an entire architecture may \nbe provisioned.\n\nA manifest also provides a higher-order language that can be used to unambiguously describe novel Cloud architectures \nthat are composed of well-defined blueprints.\n\n\n### Exploration\n\nEach Bedrock module is designed to exist independently from the rest, to allow maximum portability and sharing of code.\nYou can go into any module directory and run `terraform init && terraform apply` to execute a blueprint in your\nconfigured environment.\n\nFor example, if you require a Bastion host in your AWS account, do the following:\n\n    # provision IAM roles for creating Bastion host\n    cd terraform/blueprints/bastion/roles\n    terraform init && terraform apply\n     \n    # provision a new Bastion EC2 host\n    cd ../aws\n    terraform init && terraform apply -var bastion_user=bedrock   \n    \n\n### Run Anywhere\n\nYou can also build any Bedrock module as a [Docker] image, that can be run anywhere Docker is supported. Building images\nis supported via a Makefile in the root directory, which you can execute as follows:\n\n    # Build Docker images for Bastion roles and instance\n    make bastion-roles bastion-aws\n    \nThe Makefile will ensure dependencies are build in the right order, and includes support for tagging and push to a\nremote Docker registry:\n\n    # Tag and push to AWS ECR\n    REGISTRY=<aws_account_id>.dkr.ecr.ap-southeast-2.amazonaws.com make tag push bastion-aws\n    \nAfter building an image you can now use the provided scripts to execute the blueprint in the current working directory:\n\n    # provision a new Bastion EC2 host\n    export BEDROCK_REGISTRY=<aws_account_id>.dkr.ecr.ap-southeast-2.amazonaws.com\n    bastion/scripts/bastion-aws.sh init && bastion/scripts/bastion-aws.sh apply\n     \n\n### Automation\n\nAs the Docker images for Bedrock blueprints can be run anywhere that supports Docker, it is now possible to integrate\nwith automated deployment and provisioning tools also. This might include build tools such as Jenkins or Bamboo, and\nalso integrated with Cloud platforms such as AWS via the AWS Developer Tools (CodeBuild, CodePipeline, etc.).\n\nAs an example, we might configure a CodeBuild project to provision a blueprint using configuration from an S3 Bucket.\nUsing S3 Bucket notifications we can trigger a build by simply updating a blueprint configuration. This allows for a\nvery minimal effort approach to provisioning sophisticated and secure architectures whilst retaining the ability to\nmaintain and evolve the designs.\n\n### Comparison with other tools\n\n#### Terragrunt\n\n[Terragrunt] provides a wrapper to Terraform that enforces consistency and reduces code duplication across multiple \nmodules. Whilst Bedrock offers similar module grouping via the manifest file, it does not impose constraints on the code\n in each module, nor does it hide the underlying Terraform code.\n\n#### Astro\n\n[Astro] offers dependency mapping between Terraform modules and concurrent execution. Bedrock provides rudimentary \ndependency mapping (via sequential execution of the manifest), it doesn't yet support concurrent execution.\n\n## Getting started\n\nThe prerequisites for running the examples below are as follows:\n\n### Environment variables\n\nEnsure you have set the following environment variables:\n\n\tAWS_ACCESS_KEY_ID = <your AWS access key>\n\tAWS_SECRET_ACCESS_KEY = <your AWS secret key>\n\tAWS_DEFAULT_REGION = <your AWS region>\n\n### Build Docker images\n\n\t$ cd blueprints && make all\n\t\n### Initial manifests\n\nThe following manifests are required to configure appropriate IAM roles/permissions\n\n\t$ bin/bedrock.py -m manifests/iam.yml init && bin/bedrock.py -m manifests/iam.yml apply\n\n\n### Bedrock Manifest Tool\n\nA collection of helper tools for Bedrock are available in the Python Package Index (pypi.org),\nand can be installed as follows:\n\n    $ pip install brock\n\nThe first manifest you run should initialise your environment, for example:\n\n    ## Contents of bedrock-init.yml\n    name: AWS Initialisation\n    \n    description: Create Bedrock IAM roles and an S3 bucket for storing Terraform state\n    \n    constellations:\n      policies:\n        iam-policies:\n    \n      roles:\n        iam-roles:\n    \n      default:\n        terraform-state-aws:\n\nYou can then run this using the Bedrock Manifest Tool:\n\n    $ bmt init -m bedrock-init.yml\n    $ TF_APPLY_ARGS=-auto-approve bmt apply -m bedrock-init.yml\n    \nThe first command will initialise the Terraform providers/plugins, whilst the second will provision the IAM roles\nand S3 bucket required for Bedrock provisioning.\n\n_NOTE: As of this writing the above manifest will create 15 IAM policies, 2 IAM roles and 1 S3 bucket._\n\nIf you ever need to switch accounts where Terraform state is stored you can do this by reconfiguring\nthe Terraform backend as follows:\n\n    TF_INIT_ARGS=-reconfigure bmt init -m bedrock-init.yml\n    \n\n### Examples\n\n#### Provision a Bastion host\n\nThe following manifest file describes how to deploy an EC2 instance as a Bastion host:\n\n    name: AWS Bastion Host\n    \n    description: Provision an EC2 instance for Bastion\n    \n    constellations:\n      bastion:\n        bastion-roles:\n        bastion-aws:\n          bastion_user: fortuna\n\nYou can execute this file as follows:\n\n    $ bmt apply -m bastion.yml -c ssh_key=@~/.ssh/id_rsa.pub\n    \nThis command will apply the manifest in your AWS account, overriding the `ssh_key`\ninput variable using the public SSH key from your local SSH configuration.\n\n#### Deploy Lambda Layers\n\nThe following manifest will create common Lambda Layers for use in Lambda functions:\n\n    name: Lambda Layers\n    \n    description: Create Lambda Layers to support Bedrock Lambda blueprints\n    \n    constellations:\n      aws-java-sdk-lambda:\n        lambda-layer:\n          layer_name: aws-java-sdk-lambda\n          description: Support for the AWS Lambda SDK for Java\n          content_path: /tools/aws-java-sdk-lambda/build/layer\n          runtimes:\n            - java8\n    \n      groovy-runtime:\n        lambda-layer:\n          layer_name: groovy-runtime\n          description: Support for the Groovy JVM language\n          content_path: /tools/groovy-runtime/build/layer\n          runtimes:\n            - java8\n    \n      python-requests:\n        lambda-layer:\n          layer_name: python-requests\n          description: Python requests package plus dependencies\n          content_path: /tools/python-requests/packages\n          runtimes:\n            - python3.6\n\nNote that this manifest requires an additional volume to provide input for the `content_path` variable:\n\n    $ bmt apply -m lambda-layers.yml -v \"$PWD/tools:/tools\"\n    \n    \n### Requirements\n\nTo make use of Bedrock you must have access to a public Cloud and a local\nenvironment with [Docker] installed.\n\nIf you intend to build the Docker images from source you will also require\nmake to be installed.\n\n### Configuring\n\nConfiguration will depend on the Cloud environment(s) available, but typically\nwill involve setting an API key in your environment that allows [Terraform]\naccess to resources in your account.\n\nWhen using API keys we want to restrict access to the bare minimum required\nto perform the required tasks (Principle of least privilege). As such you\nshould ensure the associated user has just the permissions outlined in the\ntable below:\n\n| Cloud Provider | Service | Permission |\n|----------------|:-------:|:----------:|\n|AWS|Codebuild|Execute|\n|Digital Ocean|API|Full access|\n\n### Terraform\n\nYou can manage your Terraform state using either local storage or with an AWS S3 bucket.\nIt is advisable to use S3 to protect your state, in which case you will require a user with\nthe following IAM permissions:\n\n| IAM Permission | Description | ARN |\n|----------------|-------------|-----|\n|S3 Bucket create|Creates an S3 bucket containing Terraform state|arn:aws:iam::&lt;AWS account ID&gt;:policy/bedrock-terraform-state|\n|IAM Policy create|Creates an IAM policy to allow access to read/write to the S3 Bucket|arn:aws:iam::&lt;AWS account ID&gt;:policy/bedrock-terraform-state|\n\n\n### AWS\n\nFor provisioning blueprints in AWS you will require a user with the following IAM permissions:\n\n| IAM Permission | Description | ARN |\n|----------------|-------------|-----|\n|Terraform state (*)|Read/write permissions to S3 bucket containing Terraform state|arn:aws:iam::&lt;AWS account ID&gt;:policy/bedrock-terraform-state|\n|Assume role|Can assume role required for blueprint provisioning|arn:aws:iam::&lt;AWS account ID&gt;:role/*-bedrock-*|\n\n* Note that the `Terraform state` permission is only required when state is stored in AWS.\n\n## Development\n\n### Building Docker images\n\nIf you want to build the blueprint Docker images locally a `Makefile` is provided that supports the following\ngoals:\n\n    # Build all blueprints with the default settings\n    make all \n\n    # Build a specific set of blueprints    \n    make <blueprint> [<blueprint>...]\n    \n    # Build blueprints with a specific Terraform version\n    BUILD_ARGS=\"--build-arg TERRAFORM_VERSION=0.11.4\" make all    \n    \n    # Generate documentation (README) for all blueprints\n    make docs\n    \n    # Tag and push blueprints to a custom registry\n    REGISTRY=\"https://my.docker.registry/bedrock\" make tag push \n\n\n### Contributing\n\nOpen source software is made stronger by the community that supports it. Through participation you not only contribute \nto the quality of the software, but also gain a deeper insight into the inner workings.\n\nContributions may be in the form of feature enhancements, bug fixes, test cases, documentation and forum participation. \nIf you have a question, just ask. If you have an answer, write it down.\n\nAnd if you are somehow constrained from participation, through corporate policy or otherwise, consider financial \nsupport. After all, if you are profiting from open source it's only fair to give something back to the community that \nmake it all possible.\n\n## Developer Environment\n\nUse the following tools to provision a pre-configured developer environment.\n\n### Vagrant\n\n    $ vagrant up\n    $ ssh -p 2222 -L 8080:localhost:8080 vagrant@localhost  # password: vagrant\n\n### Docker\n\n    $ docker build -t bedrock-env .\n    $ ./developer-env.sh", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/micronode/bedrock", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "bedrockcli", "package_url": "https://pypi.org/project/bedrockcli/", "platform": "", "project_url": "https://pypi.org/project/bedrockcli/", "project_urls": {"Homepage": "https://github.com/micronode/bedrock"}, "release_url": "https://pypi.org/project/bedrockcli/1.0.5/", "requires_dist": null, "requires_python": ">=3.7", "summary": "A collection of Terraform-based blueprints", "version": "1.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Bedrock - Building blocks for composable Cloud architectures</h1>\n<h4>Table of Contents</h4>\n<ol>\n<li><a href=\"#introduction\" rel=\"nofollow\">Introduction - What is Bedrock?</a></li>\n<li><a href=\"#features\" rel=\"nofollow\">Features</a></li>\n<li><a href=\"#getting-started\" rel=\"nofollow\">Getting started - How to use Bedrock</a>\n<ul>\n<li><a href=\"#requirements\" rel=\"nofollow\">Requirements</a></li>\n<li><a href=\"#configuring\" rel=\"nofollow\">Configuring</a></li>\n<li><a href=\"#examples\" rel=\"nofollow\">Examples - common usage scenarios</a></li>\n</ul>\n</li>\n<li><a href=\"#development\" rel=\"nofollow\">Development - Guide for contributing to the Bedrock project</a>\n<ul>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing to Bedrock</a></li>\n</ul>\n</li>\n</ol>\n<h2>Introduction</h2>\n<p>Bedrock is a collection of managed role-based policies and Terraform-based blueprints to assist with provisioning\ninfrastructure and services. When we design modern computing architectures it is important to consider security,\nreliability and efficiency as equally important concerns. With public Cloud architectures in particular, security must\nbe addressed throughout the entire architecture, and not just at the perimiter.</p>\n<p>Role-based access control (RBAC) allows us to restrict actors to the minimum required permissions, which is commonly\nreferred to as the <a href=\"https://en.wikipedia.org/wiki/Principle_of_least_privilege\" rel=\"nofollow\">principle of least privilege</a>, and is the basis for the architectural blueprints provided by\nBedrock.</p>\n<h3>Terraform</h3>\n<p>The Bedrock blueprints are based on popular tools such as <a href=\"https://terraform.io\" rel=\"nofollow\">Terraform</a> and <a href=\"https://aws.amazon.com/cloudformation/\" rel=\"nofollow\">Cloudformation</a>, and provide both an\ninformative and practical approach to infrastructure provisioning. You are encouraged to explore and critique these\nblueprints as they should continue to evolve over time.</p>\n<h2>Features</h2>\n<p>The purpose of Bedrock is not only to provide best-practice blueprints for modern architectures, but to explore and\neducate about the challenges, decisions and opinions behind the designs themselves. As such, Bedrock aims to avoid\na \"black box\" approach and is designed to encourage hacking and examining the underlying code.</p>\n<h3>Blueprint</h3>\n<p>Blueprints provide an opinionated approach to provisioning an infrastructure component based on common and/or best-\npractice approaches.</p>\n<p>Blueprints may be either platform-based (i.e. AWS, Azure, Openstack, etc.) or service-based (i.e\nNGINX, Bastion, Squid Proxy, etc.). Typically they are identified using one of the following naming conventions:</p>\n<pre><code>&lt;platform&gt;-&lt;service&gt;[-&lt;component&gt;]\n\nexamples: aws-ec2-autoscaling, aws-ecs-cluster, azure-cdn, openstack-network, etc.\n\nor;\n\n&lt;service&gt;[-&lt;component&gt;][-&lt;platform&gt;]\n\nexamples: nginx-reverseproxy-aws, bastion-do, rancher-stack, squidproxy-aws, etc.\n</code></pre>\n<h3>Manifest</h3>\n<p>A manifest provides a way to define one or more collections of blueprints (a constellation) and associated\nconfigurations that make up a complete architecture.</p>\n<p>Often a single blueprint is not sufficient to define a Cloud architecture as they are more likely to be distributed\nacross multiple services. For example, you might have an ECS cluster for web/API applications, RDS or DynamDB for\npersistence, and S3 for archiving.</p>\n<p>Within each of these tiers are additional ancillary services such as route53 for well-known endpoints and/or service\ndiscovery, cloudwatch events/triggers, etc. The collection of blueprints that encapsulates and independent function is\ncalled a constellation. Multiple constellations may be defined in a single manifest such that an entire architecture may\nbe provisioned.</p>\n<p>A manifest also provides a higher-order language that can be used to unambiguously describe novel Cloud architectures\nthat are composed of well-defined blueprints.</p>\n<h3>Exploration</h3>\n<p>Each Bedrock module is designed to exist independently from the rest, to allow maximum portability and sharing of code.\nYou can go into any module directory and run <code>terraform init &amp;&amp; terraform apply</code> to execute a blueprint in your\nconfigured environment.</p>\n<p>For example, if you require a Bastion host in your AWS account, do the following:</p>\n<pre><code># provision IAM roles for creating Bastion host\ncd terraform/blueprints/bastion/roles\nterraform init &amp;&amp; terraform apply\n \n# provision a new Bastion EC2 host\ncd ../aws\nterraform init &amp;&amp; terraform apply -var bastion_user=bedrock   \n</code></pre>\n<h3>Run Anywhere</h3>\n<p>You can also build any Bedrock module as a <a href=\"https://docker.com\" rel=\"nofollow\">Docker</a> image, that can be run anywhere Docker is supported. Building images\nis supported via a Makefile in the root directory, which you can execute as follows:</p>\n<pre><code># Build Docker images for Bastion roles and instance\nmake bastion-roles bastion-aws\n</code></pre>\n<p>The Makefile will ensure dependencies are build in the right order, and includes support for tagging and push to a\nremote Docker registry:</p>\n<pre><code># Tag and push to AWS ECR\nREGISTRY=&lt;aws_account_id&gt;.dkr.ecr.ap-southeast-2.amazonaws.com make tag push bastion-aws\n</code></pre>\n<p>After building an image you can now use the provided scripts to execute the blueprint in the current working directory:</p>\n<pre><code># provision a new Bastion EC2 host\nexport BEDROCK_REGISTRY=&lt;aws_account_id&gt;.dkr.ecr.ap-southeast-2.amazonaws.com\nbastion/scripts/bastion-aws.sh init &amp;&amp; bastion/scripts/bastion-aws.sh apply\n</code></pre>\n<h3>Automation</h3>\n<p>As the Docker images for Bedrock blueprints can be run anywhere that supports Docker, it is now possible to integrate\nwith automated deployment and provisioning tools also. This might include build tools such as Jenkins or Bamboo, and\nalso integrated with Cloud platforms such as AWS via the AWS Developer Tools (CodeBuild, CodePipeline, etc.).</p>\n<p>As an example, we might configure a CodeBuild project to provision a blueprint using configuration from an S3 Bucket.\nUsing S3 Bucket notifications we can trigger a build by simply updating a blueprint configuration. This allows for a\nvery minimal effort approach to provisioning sophisticated and secure architectures whilst retaining the ability to\nmaintain and evolve the designs.</p>\n<h3>Comparison with other tools</h3>\n<h4>Terragrunt</h4>\n<p><a href=\"https://github.com/gruntwork-io/terragrunt\" rel=\"nofollow\">Terragrunt</a> provides a wrapper to Terraform that enforces consistency and reduces code duplication across multiple\nmodules. Whilst Bedrock offers similar module grouping via the manifest file, it does not impose constraints on the code\nin each module, nor does it hide the underlying Terraform code.</p>\n<h4>Astro</h4>\n<p><a href=\"https://github.com/uber/astro\" rel=\"nofollow\">Astro</a> offers dependency mapping between Terraform modules and concurrent execution. Bedrock provides rudimentary\ndependency mapping (via sequential execution of the manifest), it doesn't yet support concurrent execution.</p>\n<h2>Getting started</h2>\n<p>The prerequisites for running the examples below are as follows:</p>\n<h3>Environment variables</h3>\n<p>Ensure you have set the following environment variables:</p>\n<pre><code>AWS_ACCESS_KEY_ID = &lt;your AWS access key&gt;\nAWS_SECRET_ACCESS_KEY = &lt;your AWS secret key&gt;\nAWS_DEFAULT_REGION = &lt;your AWS region&gt;\n</code></pre>\n<h3>Build Docker images</h3>\n<pre><code>$ cd blueprints &amp;&amp; make all\n</code></pre>\n<h3>Initial manifests</h3>\n<p>The following manifests are required to configure appropriate IAM roles/permissions</p>\n<pre><code>$ bin/bedrock.py -m manifests/iam.yml init &amp;&amp; bin/bedrock.py -m manifests/iam.yml apply\n</code></pre>\n<h3>Bedrock Manifest Tool</h3>\n<p>A collection of helper tools for Bedrock are available in the Python Package Index (pypi.org),\nand can be installed as follows:</p>\n<pre><code>$ pip install brock\n</code></pre>\n<p>The first manifest you run should initialise your environment, for example:</p>\n<pre><code>## Contents of bedrock-init.yml\nname: AWS Initialisation\n\ndescription: Create Bedrock IAM roles and an S3 bucket for storing Terraform state\n\nconstellations:\n  policies:\n    iam-policies:\n\n  roles:\n    iam-roles:\n\n  default:\n    terraform-state-aws:\n</code></pre>\n<p>You can then run this using the Bedrock Manifest Tool:</p>\n<pre><code>$ bmt init -m bedrock-init.yml\n$ TF_APPLY_ARGS=-auto-approve bmt apply -m bedrock-init.yml\n</code></pre>\n<p>The first command will initialise the Terraform providers/plugins, whilst the second will provision the IAM roles\nand S3 bucket required for Bedrock provisioning.</p>\n<p><em>NOTE: As of this writing the above manifest will create 15 IAM policies, 2 IAM roles and 1 S3 bucket.</em></p>\n<p>If you ever need to switch accounts where Terraform state is stored you can do this by reconfiguring\nthe Terraform backend as follows:</p>\n<pre><code>TF_INIT_ARGS=-reconfigure bmt init -m bedrock-init.yml\n</code></pre>\n<h3>Examples</h3>\n<h4>Provision a Bastion host</h4>\n<p>The following manifest file describes how to deploy an EC2 instance as a Bastion host:</p>\n<pre><code>name: AWS Bastion Host\n\ndescription: Provision an EC2 instance for Bastion\n\nconstellations:\n  bastion:\n    bastion-roles:\n    bastion-aws:\n      bastion_user: fortuna\n</code></pre>\n<p>You can execute this file as follows:</p>\n<pre><code>$ bmt apply -m bastion.yml -c ssh_key=@~/.ssh/id_rsa.pub\n</code></pre>\n<p>This command will apply the manifest in your AWS account, overriding the <code>ssh_key</code>\ninput variable using the public SSH key from your local SSH configuration.</p>\n<h4>Deploy Lambda Layers</h4>\n<p>The following manifest will create common Lambda Layers for use in Lambda functions:</p>\n<pre><code>name: Lambda Layers\n\ndescription: Create Lambda Layers to support Bedrock Lambda blueprints\n\nconstellations:\n  aws-java-sdk-lambda:\n    lambda-layer:\n      layer_name: aws-java-sdk-lambda\n      description: Support for the AWS Lambda SDK for Java\n      content_path: /tools/aws-java-sdk-lambda/build/layer\n      runtimes:\n        - java8\n\n  groovy-runtime:\n    lambda-layer:\n      layer_name: groovy-runtime\n      description: Support for the Groovy JVM language\n      content_path: /tools/groovy-runtime/build/layer\n      runtimes:\n        - java8\n\n  python-requests:\n    lambda-layer:\n      layer_name: python-requests\n      description: Python requests package plus dependencies\n      content_path: /tools/python-requests/packages\n      runtimes:\n        - python3.6\n</code></pre>\n<p>Note that this manifest requires an additional volume to provide input for the <code>content_path</code> variable:</p>\n<pre><code>$ bmt apply -m lambda-layers.yml -v \"$PWD/tools:/tools\"\n</code></pre>\n<h3>Requirements</h3>\n<p>To make use of Bedrock you must have access to a public Cloud and a local\nenvironment with <a href=\"https://docker.com\" rel=\"nofollow\">Docker</a> installed.</p>\n<p>If you intend to build the Docker images from source you will also require\nmake to be installed.</p>\n<h3>Configuring</h3>\n<p>Configuration will depend on the Cloud environment(s) available, but typically\nwill involve setting an API key in your environment that allows <a href=\"https://terraform.io\" rel=\"nofollow\">Terraform</a>\naccess to resources in your account.</p>\n<p>When using API keys we want to restrict access to the bare minimum required\nto perform the required tasks (Principle of least privilege). As such you\nshould ensure the associated user has just the permissions outlined in the\ntable below:</p>\n<table>\n<thead>\n<tr>\n<th>Cloud Provider</th>\n<th align=\"center\">Service</th>\n<th align=\"center\">Permission</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AWS</td>\n<td align=\"center\">Codebuild</td>\n<td align=\"center\">Execute</td>\n</tr>\n<tr>\n<td>Digital Ocean</td>\n<td align=\"center\">API</td>\n<td align=\"center\">Full access</td>\n</tr></tbody></table>\n<h3>Terraform</h3>\n<p>You can manage your Terraform state using either local storage or with an AWS S3 bucket.\nIt is advisable to use S3 to protect your state, in which case you will require a user with\nthe following IAM permissions:</p>\n<table>\n<thead>\n<tr>\n<th>IAM Permission</th>\n<th>Description</th>\n<th>ARN</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>S3 Bucket create</td>\n<td>Creates an S3 bucket containing Terraform state</td>\n<td>arn:aws:iam::&lt;AWS account ID&gt;:policy/bedrock-terraform-state</td>\n</tr>\n<tr>\n<td>IAM Policy create</td>\n<td>Creates an IAM policy to allow access to read/write to the S3 Bucket</td>\n<td>arn:aws:iam::&lt;AWS account ID&gt;:policy/bedrock-terraform-state</td>\n</tr></tbody></table>\n<h3>AWS</h3>\n<p>For provisioning blueprints in AWS you will require a user with the following IAM permissions:</p>\n<table>\n<thead>\n<tr>\n<th>IAM Permission</th>\n<th>Description</th>\n<th>ARN</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Terraform state (*)</td>\n<td>Read/write permissions to S3 bucket containing Terraform state</td>\n<td>arn:aws:iam::&lt;AWS account ID&gt;:policy/bedrock-terraform-state</td>\n</tr>\n<tr>\n<td>Assume role</td>\n<td>Can assume role required for blueprint provisioning</td>\n<td>arn:aws:iam::&lt;AWS account ID&gt;:role/<em>-bedrock-</em></td>\n</tr></tbody></table>\n<ul>\n<li>Note that the <code>Terraform state</code> permission is only required when state is stored in AWS.</li>\n</ul>\n<h2>Development</h2>\n<h3>Building Docker images</h3>\n<p>If you want to build the blueprint Docker images locally a <code>Makefile</code> is provided that supports the following\ngoals:</p>\n<pre><code># Build all blueprints with the default settings\nmake all \n\n# Build a specific set of blueprints    \nmake &lt;blueprint&gt; [&lt;blueprint&gt;...]\n\n# Build blueprints with a specific Terraform version\nBUILD_ARGS=\"--build-arg TERRAFORM_VERSION=0.11.4\" make all    \n\n# Generate documentation (README) for all blueprints\nmake docs\n\n# Tag and push blueprints to a custom registry\nREGISTRY=\"https://my.docker.registry/bedrock\" make tag push \n</code></pre>\n<h3>Contributing</h3>\n<p>Open source software is made stronger by the community that supports it. Through participation you not only contribute\nto the quality of the software, but also gain a deeper insight into the inner workings.</p>\n<p>Contributions may be in the form of feature enhancements, bug fixes, test cases, documentation and forum participation.\nIf you have a question, just ask. If you have an answer, write it down.</p>\n<p>And if you are somehow constrained from participation, through corporate policy or otherwise, consider financial\nsupport. After all, if you are profiting from open source it's only fair to give something back to the community that\nmake it all possible.</p>\n<h2>Developer Environment</h2>\n<p>Use the following tools to provision a pre-configured developer environment.</p>\n<h3>Vagrant</h3>\n<pre><code>$ vagrant up\n$ ssh -p 2222 -L 8080:localhost:8080 vagrant@localhost  # password: vagrant\n</code></pre>\n<h3>Docker</h3>\n<pre><code>$ docker build -t bedrock-env .\n$ ./developer-env.sh\n</code></pre>\n\n          </div>"}, "last_serial": 6010775, "releases": {"1.0.4": [{"comment_text": "", "digests": {"md5": "5c426bd2110aef399783d40c05669f35", "sha256": "955067ecccb47b782fa2f717c78470ee0f0dc82389bac690e1f4a73b4e7774ed"}, "downloads": -1, "filename": "bedrockcli-1.0.4.tar.gz", "has_sig": false, "md5_digest": "5c426bd2110aef399783d40c05669f35", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 16215, "upload_time": "2019-10-22T03:51:50", "upload_time_iso_8601": "2019-10-22T03:51:50.459597Z", "url": "https://files.pythonhosted.org/packages/8e/aa/f5df289db51e98306b0fe49d4404bd3c369604c9bf6f0096f55787a3ba1e/bedrockcli-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "427862746e8a52dce9710e1a050c2b1a", "sha256": "ab7bd81945817908f6d7aa7f893443ef49d2687bbc3d82dd5ee4fc504741bb71"}, "downloads": -1, "filename": "bedrockcli-1.0.5.tar.gz", "has_sig": false, "md5_digest": "427862746e8a52dce9710e1a050c2b1a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 16245, "upload_time": "2019-10-22T06:28:56", "upload_time_iso_8601": "2019-10-22T06:28:56.879952Z", "url": "https://files.pythonhosted.org/packages/16/68/3a3624322e92ff53e3e81a4aecb7b73652b6cfca5fad57d9f320b21ba8dc/bedrockcli-1.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "427862746e8a52dce9710e1a050c2b1a", "sha256": "ab7bd81945817908f6d7aa7f893443ef49d2687bbc3d82dd5ee4fc504741bb71"}, "downloads": -1, "filename": "bedrockcli-1.0.5.tar.gz", "has_sig": false, "md5_digest": "427862746e8a52dce9710e1a050c2b1a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 16245, "upload_time": "2019-10-22T06:28:56", "upload_time_iso_8601": "2019-10-22T06:28:56.879952Z", "url": "https://files.pythonhosted.org/packages/16/68/3a3624322e92ff53e3e81a4aecb7b73652b6cfca5fad57d9f320b21ba8dc/bedrockcli-1.0.5.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:37:54 2020"}