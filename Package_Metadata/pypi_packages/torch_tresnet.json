{"info": {"author": "ZHANG Zack", "author_email": "850734033@qq.com", "bugtrack_url": null, "classifiers": [], "description": "TResNet: High Performance GPU-Dedicated Architecture\n====================================================\n\nPackaged TResNet based on Official PyTorch Implementation\n[`paper <https://arxiv.org/pdf/2003.13630.pdf>`__\\ ]\n[`github <https://github.com/mrT23/TResNet>`__\\ ]\n\nInstallation\n------------\n\nInstall with pip:\n\n::\n\n    pip install torch_tresnet\n\nor directly:\n\n::\n\n    pip install git+https://github.com/tczhangzhi/torch-tresnet\n\nUse\n---\n\nFollow the grammatical conventions of torchvision\n\n::\n\n    from torch_tresnet import tresnet_m, tresnet_l, tresnet_xl, tresnet_m_448, tresnet_l_448, tresnet_xl_448\n\n    # pretrianed on 224*224\n    model = tresnet_m(pretrain=True)\n    model = tresnet_m(pretrain=True, num_classes=10)\n    model = tresnet_m(pretrain=True, num_classes=10, in_chans=3)\n\n    # pretrianed on 448*448\n    model = tresnet_m_448(pretrain=True)\n    model = tresnet_m_448(pretrain=True, num_classes=10)\n    model = tresnet_m_448(pretrain=True, num_classes=10, in_chans=3)\n\nMain Results\n------------\n\nTResNet Models\n^^^^^^^^^^^^^^\n\nTResNet models accuracy and GPU throughput on ImageNet, compared to\nResNet50. All measurements were done on Nvidia V100 GPU, with mixed\nprecision. All models are trained on input resolution of 224.\n\n+------------------+--------------------------------+---------------------------------+------------------------+--------------+\n| Models           | Top Training Speed (img/sec)   | Top Inference Speed (img/sec)   | Max Train Batch Size   | Top-1 Acc.   |\n+==================+================================+=================================+========================+==============+\n| ResNet50         | **805**                        | 2830                            | 288                    | 79.0         |\n+------------------+--------------------------------+---------------------------------+------------------------+--------------+\n| EfficientNetB1   | 440                            | 2740                            | 196                    | 79.2         |\n+------------------+--------------------------------+---------------------------------+------------------------+--------------+\n| TResNet-M        | 730                            | **2930**                        | **512**                | 80.7         |\n+------------------+--------------------------------+---------------------------------+------------------------+--------------+\n| TResNet-L        | 345                            | 1390                            | 316                    | 81.4         |\n+------------------+--------------------------------+---------------------------------+------------------------+--------------+\n| TResNet-XL       | 250                            | 1060                            | 240                    | **82.0**     |\n+------------------+--------------------------------+---------------------------------+------------------------+--------------+\n\nComparison To Other Networks\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nComparison of ResNet50 to top modern networks, with similar top-1\nImageNet accuracy. All measurements were done on Nvidia V100 GPU with\nmixed precision. For gaining optimal speeds, training and inference were\nmeasured on 90% of maximal possible batch size. Except TResNet-M, all\nthe models' ImageNet scores were taken from the `public\nrepository <https://github.com/rwightman/pytorch-image-models>`__, which\nspecialized in providing top implementations for modern networks. Except\nEfficientNet-B1, which has input resolution of 240, all other models\nhave input resolution of 224.\n\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| Model            | Top Training Speed (img/sec)   | Top Inference Speed (img/sec)   | Top-1 Acc.   | Flops[G]   |\n+==================+================================+=================================+==============+============+\n| ResNet50         | **805**                        | 2830                            | 79.0         | 4.1        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| ResNet50-D       | 600                            | 2670                            | 79.3         | 4.4        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| ResNeXt50        | 490                            | 1940                            | 78.5         | 4.3        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| EfficientNetB1   | 440                            | 2740                            | 79.2         | 0.6        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| SEResNeXt50      | 400                            | 1770                            | 79.0         | 4.3        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| MixNet-L         | 400                            | 1400                            | 79.0         | 0.5        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n| TResNet-M        | 730                            | **2930**                        | **80.7**     | 5.5        |\n+------------------+--------------------------------+---------------------------------+--------------+------------+\n\nTransfer Learning SotA Results\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nComparison of TResNet to state-of-the-art models on transfer learning\ndatasets (only ImageNet-based transfer learning results). Models\ninference speed is measured on a mixed precision V100 GPU. Since no\nofficial implementation of Gpipe was provided, its inference speed is\nunknown.\n\n+------------------+-------------------+--------------+-----------------+---------+\n| Dataset          | Model             | Top-1 Acc.   | Speed img/sec   | Input   |\n+==================+===================+==============+=================+=========+\n| CIFAR-10         | Gpipe             | **99.0**     | -               | 480     |\n+------------------+-------------------+--------------+-----------------+---------+\n| CIFAR-10         | TResNet-XL        | **99.0**     | **1060**        | 224     |\n+------------------+-------------------+--------------+-----------------+---------+\n| CIFAR-100        | EfficientNet-B7   | **91.7**     | 70              | 600     |\n+------------------+-------------------+--------------+-----------------+---------+\n| CIFAR-100        | TResNet-XL        | 91.5         | **1060**        | 224     |\n+------------------+-------------------+--------------+-----------------+---------+\n| Stanford Cars    | EfficientNet-B7   | 94.7         | 70              | 600     |\n+------------------+-------------------+--------------+-----------------+---------+\n| Stanford Cars    | TResNet-L         | **96.0**     | **500**         | 368     |\n+------------------+-------------------+--------------+-----------------+---------+\n| Oxford-Flowers   | EfficientNet-B7   | 98.8         | 70              | 600     |\n+------------------+-------------------+--------------+-----------------+---------+\n| Oxford-Flowers   | TResNet-L         | **99.1**     | **500**         | 368     |\n+------------------+-------------------+--------------+-----------------+---------+\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tczhangzhi/torch-tresnet", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torch_tresnet", "package_url": "https://pypi.org/project/torch_tresnet/", "platform": "", "project_url": "https://pypi.org/project/torch_tresnet/", "project_urls": {"Homepage": "https://github.com/tczhangzhi/torch-tresnet"}, "release_url": "https://pypi.org/project/torch_tresnet/1.0.6/", "requires_dist": null, "requires_python": "", "summary": "TResNet: High Performance GPU-Dedicated Architecture", "version": "1.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Packaged TResNet based on Official PyTorch Implementation\n[<a href=\"https://arxiv.org/pdf/2003.13630.pdf\" rel=\"nofollow\">paper</a>]\n[<a href=\"https://github.com/mrT23/TResNet\" rel=\"nofollow\">github</a>]</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Install with pip:</p>\n<pre>pip install torch_tresnet\n</pre>\n<p>or directly:</p>\n<pre>pip install git+https://github.com/tczhangzhi/torch-tresnet\n</pre>\n</div>\n<div id=\"use\">\n<h2>Use</h2>\n<p>Follow the grammatical conventions of torchvision</p>\n<pre>from torch_tresnet import tresnet_m, tresnet_l, tresnet_xl, tresnet_m_448, tresnet_l_448, tresnet_xl_448\n\n# pretrianed on 224*224\nmodel = tresnet_m(pretrain=True)\nmodel = tresnet_m(pretrain=True, num_classes=10)\nmodel = tresnet_m(pretrain=True, num_classes=10, in_chans=3)\n\n# pretrianed on 448*448\nmodel = tresnet_m_448(pretrain=True)\nmodel = tresnet_m_448(pretrain=True, num_classes=10)\nmodel = tresnet_m_448(pretrain=True, num_classes=10, in_chans=3)\n</pre>\n</div>\n<div id=\"main-results\">\n<h2>Main Results</h2>\n<div id=\"tresnet-models\">\n<h3>TResNet Models</h3>\n<p>TResNet models accuracy and GPU throughput on ImageNet, compared to\nResNet50. All measurements were done on Nvidia V100 GPU, with mixed\nprecision. All models are trained on input resolution of 224.</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Models</th>\n<th>Top Training Speed (img/sec)</th>\n<th>Top Inference Speed (img/sec)</th>\n<th>Max Train Batch Size</th>\n<th>Top-1 Acc.</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>ResNet50</td>\n<td><strong>805</strong></td>\n<td>2830</td>\n<td>288</td>\n<td>79.0</td>\n</tr>\n<tr><td>EfficientNetB1</td>\n<td>440</td>\n<td>2740</td>\n<td>196</td>\n<td>79.2</td>\n</tr>\n<tr><td>TResNet-M</td>\n<td>730</td>\n<td><strong>2930</strong></td>\n<td><strong>512</strong></td>\n<td>80.7</td>\n</tr>\n<tr><td>TResNet-L</td>\n<td>345</td>\n<td>1390</td>\n<td>316</td>\n<td>81.4</td>\n</tr>\n<tr><td>TResNet-XL</td>\n<td>250</td>\n<td>1060</td>\n<td>240</td>\n<td><strong>82.0</strong></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"comparison-to-other-networks\">\n<h3>Comparison To Other Networks</h3>\n<p>Comparison of ResNet50 to top modern networks, with similar top-1\nImageNet accuracy. All measurements were done on Nvidia V100 GPU with\nmixed precision. For gaining optimal speeds, training and inference were\nmeasured on 90% of maximal possible batch size. Except TResNet-M, all\nthe models\u2019 ImageNet scores were taken from the <a href=\"https://github.com/rwightman/pytorch-image-models\" rel=\"nofollow\">public\nrepository</a>, which\nspecialized in providing top implementations for modern networks. Except\nEfficientNet-B1, which has input resolution of 240, all other models\nhave input resolution of 224.</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Model</th>\n<th>Top Training Speed (img/sec)</th>\n<th>Top Inference Speed (img/sec)</th>\n<th>Top-1 Acc.</th>\n<th>Flops[G]</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>ResNet50</td>\n<td><strong>805</strong></td>\n<td>2830</td>\n<td>79.0</td>\n<td>4.1</td>\n</tr>\n<tr><td>ResNet50-D</td>\n<td>600</td>\n<td>2670</td>\n<td>79.3</td>\n<td>4.4</td>\n</tr>\n<tr><td>ResNeXt50</td>\n<td>490</td>\n<td>1940</td>\n<td>78.5</td>\n<td>4.3</td>\n</tr>\n<tr><td>EfficientNetB1</td>\n<td>440</td>\n<td>2740</td>\n<td>79.2</td>\n<td>0.6</td>\n</tr>\n<tr><td>SEResNeXt50</td>\n<td>400</td>\n<td>1770</td>\n<td>79.0</td>\n<td>4.3</td>\n</tr>\n<tr><td>MixNet-L</td>\n<td>400</td>\n<td>1400</td>\n<td>79.0</td>\n<td>0.5</td>\n</tr>\n<tr><td>TResNet-M</td>\n<td>730</td>\n<td><strong>2930</strong></td>\n<td><strong>80.7</strong></td>\n<td>5.5</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div id=\"transfer-learning-sota-results\">\n<h3>Transfer Learning SotA Results</h3>\n<p>Comparison of TResNet to state-of-the-art models on transfer learning\ndatasets (only ImageNet-based transfer learning results). Models\ninference speed is measured on a mixed precision V100 GPU. Since no\nofficial implementation of Gpipe was provided, its inference speed is\nunknown.</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Dataset</th>\n<th>Model</th>\n<th>Top-1 Acc.</th>\n<th>Speed img/sec</th>\n<th>Input</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>CIFAR-10</td>\n<td>Gpipe</td>\n<td><strong>99.0</strong></td>\n<td><ul>\n<li>\n</ul>\n</td>\n<td>480</td>\n</tr>\n<tr><td>CIFAR-10</td>\n<td>TResNet-XL</td>\n<td><strong>99.0</strong></td>\n<td><strong>1060</strong></td>\n<td>224</td>\n</tr>\n<tr><td>CIFAR-100</td>\n<td>EfficientNet-B7</td>\n<td><strong>91.7</strong></td>\n<td>70</td>\n<td>600</td>\n</tr>\n<tr><td>CIFAR-100</td>\n<td>TResNet-XL</td>\n<td>91.5</td>\n<td><strong>1060</strong></td>\n<td>224</td>\n</tr>\n<tr><td>Stanford Cars</td>\n<td>EfficientNet-B7</td>\n<td>94.7</td>\n<td>70</td>\n<td>600</td>\n</tr>\n<tr><td>Stanford Cars</td>\n<td>TResNet-L</td>\n<td><strong>96.0</strong></td>\n<td><strong>500</strong></td>\n<td>368</td>\n</tr>\n<tr><td>Oxford-Flowers</td>\n<td>EfficientNet-B7</td>\n<td>98.8</td>\n<td>70</td>\n<td>600</td>\n</tr>\n<tr><td>Oxford-Flowers</td>\n<td>TResNet-L</td>\n<td><strong>99.1</strong></td>\n<td><strong>500</strong></td>\n<td>368</td>\n</tr>\n</tbody>\n</table>\n</div>\n</div>\n\n          </div>"}, "last_serial": 7052929, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "f870861cd62ee758f4e9c8a8f556ef2b", "sha256": "9ba54651768c52806ca9eb80adbf162e021d4abcaca2746a9fc1dc8da8471ef8"}, "downloads": -1, "filename": "torch_tresnet-1.0.1.tar.gz", "has_sig": false, "md5_digest": "f870861cd62ee758f4e9c8a8f556ef2b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6052, "upload_time": "2020-04-19T05:58:51", "upload_time_iso_8601": "2020-04-19T05:58:51.852352Z", "url": "https://files.pythonhosted.org/packages/80/28/6de99b95df670ef897299d8bbf530a549d3b3ae6211413c32d166fd14292/torch_tresnet-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "fca65ca7751820aee91554f26a3c6f10", "sha256": "1588aff67bc7561336a1295fcd609108c23872275e31ec4c0511deb984bd377f"}, "downloads": -1, "filename": "torch_tresnet-1.0.2.tar.gz", "has_sig": false, "md5_digest": "fca65ca7751820aee91554f26a3c6f10", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8314, "upload_time": "2020-04-19T06:15:48", "upload_time_iso_8601": "2020-04-19T06:15:48.563918Z", "url": "https://files.pythonhosted.org/packages/d0/7a/8db93267c20d33b92197e623de104a83209e3d42ae629193da84e9771a7f/torch_tresnet-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "5edd7aaf5c3539c17961d4b312dd093f", "sha256": "4b43ec5223ae9668491f8488e0af70a79d85d909632410e88d0af0f2b4b22fb0"}, "downloads": -1, "filename": "torch_tresnet-1.0.3.tar.gz", "has_sig": false, "md5_digest": "5edd7aaf5c3539c17961d4b312dd093f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8347, "upload_time": "2020-04-19T06:28:11", "upload_time_iso_8601": "2020-04-19T06:28:11.665840Z", "url": "https://files.pythonhosted.org/packages/f1/1a/24e1ffc48773adf5097fc195679e7e5cb145f020f3ff5e98dcf134d0ad08/torch_tresnet-1.0.3.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "1fa84f56a433f14fd2ac111df0db1e2c", "sha256": "714f82f5e4cff0b8f964d0fe0c2fa5fc143eba40243ceada1c21b648caed8478"}, "downloads": -1, "filename": "torch_tresnet-1.0.5.tar.gz", "has_sig": false, "md5_digest": "1fa84f56a433f14fd2ac111df0db1e2c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8136, "upload_time": "2020-04-19T06:49:17", "upload_time_iso_8601": "2020-04-19T06:49:17.210498Z", "url": "https://files.pythonhosted.org/packages/6a/96/f8417a5c74d35bf2f516a808af1b79f70b3412e83a03246976ffaee5cc3d/torch_tresnet-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "a3ec08d0c95d51f7fdd19937666ae6d9", "sha256": "24cc913586c7d3193a1b579c502f9f3277afdd89d1195d96fd19b6973a1b17e5"}, "downloads": -1, "filename": "torch_tresnet-1.0.6.tar.gz", "has_sig": false, "md5_digest": "a3ec08d0c95d51f7fdd19937666ae6d9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7898, "upload_time": "2020-04-19T12:22:14", "upload_time_iso_8601": "2020-04-19T12:22:14.730563Z", "url": "https://files.pythonhosted.org/packages/46/a6/2739adcedb4cee816369738a8ba2b61556b1e549205d1e739b6114cb3a29/torch_tresnet-1.0.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a3ec08d0c95d51f7fdd19937666ae6d9", "sha256": "24cc913586c7d3193a1b579c502f9f3277afdd89d1195d96fd19b6973a1b17e5"}, "downloads": -1, "filename": "torch_tresnet-1.0.6.tar.gz", "has_sig": false, "md5_digest": "a3ec08d0c95d51f7fdd19937666ae6d9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7898, "upload_time": "2020-04-19T12:22:14", "upload_time_iso_8601": "2020-04-19T12:22:14.730563Z", "url": "https://files.pythonhosted.org/packages/46/a6/2739adcedb4cee816369738a8ba2b61556b1e549205d1e739b6114cb3a29/torch_tresnet-1.0.6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:07 2020"}