{"info": {"author": "Liu Changyu", "author_email": "liuchangyu1111@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "\n# DCGAN-PyTorch\n\n### Update (January 29, 2020)\n\nThe mnist and fmnist models are now available. Their usage is identical to the other models: \n```python\nfrom dcgan_pytorch import Generator\nmodel = Generator.from_pretrained('g-mnist') \n```\n\n### Overview\nThis repository contains an op-for-op PyTorch reimplementation of [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](http://xxx.itp.ac.cn/pdf/1511.06434).\n\nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.  \n\nAt the moment, you can easily:  \n * Load pretrained Generate models \n * Use Generate models for extended dataset\n\n_Upcoming features_: In the next few days, you will be able to:\n * Quickly finetune an Generate on your own dataset\n * Export Generate models for production\n\n### Table of contents\n1. [About Deep Convolutional Generative Adversarial Networks](#about-deep-convolutional-generative-adversarial-networks)\n2. [Model Description](#model-description)\n3. [Installation](#installation)\n4. [Usage](#usage)\n    * [Load pretrained models](#loading-pretrained-models)\n    * [Example: Extended dataset](#example-extended-dataset)\n    * [Example: Visual](#example-visual)\n5. [Contributing](#contributing) \n\n### About Deep Convolutional Generative Adversarial Networks\n\nIf you're new to DCGAN, here's an abstract straight from the paper:\n\nIn recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.\n\n### Model Description\n\nWe have two networks, G (Generator) and D (Discriminator).The Generator is a network for generating images. It receives a random noise z and generates images from this noise, which is called G(z).Discriminator is a discriminant network that discriminates whether an image is real. The input is x, x is a picture, and the output is D of x is the probability that x is a real picture, and if it's 1, it's 100% real, and if it's 0, it's not real.\n\n### Installation\n\nInstall from pypi:\n```bash\npip install dcgan_pytorch\n```\n\nInstall from source:\n```bash\ngit clone https://github.com/Lornatang/DCGAN-PyTorch.git\ncd DCGAN-PyTorch\npip install -e .\n``` \n\n### Usage\n\n#### Loading pretrained models\n\nLoad an Deep-Convolutional-Generative-Adversarial-Networks:\n```python\nfrom dcgan_pytorch import Generator\nmodel = Generator.from_name(\"g-mnist\")\n```\n\nLoad a pretrained Deep-Convolutional-Generative-Adversarial-Networks:\n```python\nfrom dcgan_pytorch import Generator\nmodel = Generator.from_pretrained(\"g-mnist\")\n```\n\n#### Example: Extended dataset\n\nAs mentioned in the example, if you load the pre-trained weights of the MNIST dataset, it will create a new `imgs` directory and generate 64 random images in the `imgs` directory.\n\n```python\nimport os\nimport torch\nimport torchvision.utils as vutils\nfrom dcgan_pytorch import Generator\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = Generator.from_pretrained(\"g-mnist\")\nmodel.to(device)\n# switch to evaluate mode\nmodel.eval()\n\ntry:\n    os.makedirs(\"./imgs\")\nexcept OSError:\n    pass\n\nwith torch.no_grad():\n    for i in range(64):\n        noise = torch.randn(64, 100, 1, 1, device=device)\n        fake = model(noise)\n        vutils.save_image(fake.detach(), f\"./imgs/fake_{i:04d}.png\", normalize=True)\n    print(\"The fake image has been generated!\")\n```\n\n#### Example: Visual\n\n```text\ncd $REPO$/framework\nsh start.sh\n```\n\nThen open the browser and type in the browser address [http://127.0.0.1:10001/](http://127.0.0.1:10001/).\nEnjoy it.\n\n### Contributing\n\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.   \n\nI look forward to seeing what the community does with these models! \n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/lornatang/DCGAN-PyTorch", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "dcgan-pytorch", "package_url": "https://pypi.org/project/dcgan-pytorch/", "platform": "", "project_url": "https://pypi.org/project/dcgan-pytorch/", "project_urls": {"Homepage": "https://github.com/lornatang/DCGAN-PyTorch"}, "release_url": "https://pypi.org/project/dcgan-pytorch/0.2.0/", "requires_dist": ["torch"], "requires_python": ">=3.6.0", "summary": "PyTorch implements a simple GAN neural network structure.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DCGAN-PyTorch</h1>\n<h3>Update (January 29, 2020)</h3>\n<p>The mnist and fmnist models are now available. Their usage is identical to the other models:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dcgan_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'g-mnist'</span><span class=\"p\">)</span> \n</pre>\n<h3>Overview</h3>\n<p>This repository contains an op-for-op PyTorch reimplementation of <a href=\"http://xxx.itp.ac.cn/pdf/1511.06434\" rel=\"nofollow\">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a>.</p>\n<p>The goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.</p>\n<p>At the moment, you can easily:</p>\n<ul>\n<li>Load pretrained Generate models</li>\n<li>Use Generate models for extended dataset</li>\n</ul>\n<p><em>Upcoming features</em>: In the next few days, you will be able to:</p>\n<ul>\n<li>Quickly finetune an Generate on your own dataset</li>\n<li>Export Generate models for production</li>\n</ul>\n<h3>Table of contents</h3>\n<ol>\n<li><a href=\"#about-deep-convolutional-generative-adversarial-networks\" rel=\"nofollow\">About Deep Convolutional Generative Adversarial Networks</a></li>\n<li><a href=\"#model-description\" rel=\"nofollow\">Model Description</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#loading-pretrained-models\" rel=\"nofollow\">Load pretrained models</a></li>\n<li><a href=\"#example-extended-dataset\" rel=\"nofollow\">Example: Extended dataset</a></li>\n<li><a href=\"#example-visual\" rel=\"nofollow\">Example: Visual</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n</ol>\n<h3>About Deep Convolutional Generative Adversarial Networks</h3>\n<p>If you're new to DCGAN, here's an abstract straight from the paper:</p>\n<p>In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.</p>\n<h3>Model Description</h3>\n<p>We have two networks, G (Generator) and D (Discriminator).The Generator is a network for generating images. It receives a random noise z and generates images from this noise, which is called G(z).Discriminator is a discriminant network that discriminates whether an image is real. The input is x, x is a picture, and the output is D of x is the probability that x is a real picture, and if it's 1, it's 100% real, and if it's 0, it's not real.</p>\n<h3>Installation</h3>\n<p>Install from pypi:</p>\n<pre>pip install dcgan_pytorch\n</pre>\n<p>Install from source:</p>\n<pre>git clone https://github.com/Lornatang/DCGAN-PyTorch.git\n<span class=\"nb\">cd</span> DCGAN-PyTorch\npip install -e .\n</pre>\n<h3>Usage</h3>\n<h4>Loading pretrained models</h4>\n<p>Load an Deep-Convolutional-Generative-Adversarial-Networks:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dcgan_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_name</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n</pre>\n<p>Load a pretrained Deep-Convolutional-Generative-Adversarial-Networks:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dcgan_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Extended dataset</h4>\n<p>As mentioned in the example, if you load the pre-trained weights of the MNIST dataset, it will create a new <code>imgs</code> directory and generate 64 random images in the <code>imgs</code> directory.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.utils</span> <span class=\"k\">as</span> <span class=\"nn\">vutils</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dcgan_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n\n<span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">\"cuda:0\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s2\">\"cpu\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"c1\"># switch to evaluate mode</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"s2\">\"./imgs\"</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">OSError</span><span class=\"p\">:</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">):</span>\n        <span class=\"n\">noise</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n        <span class=\"n\">fake</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">noise</span><span class=\"p\">)</span>\n        <span class=\"n\">vutils</span><span class=\"o\">.</span><span class=\"n\">save_image</span><span class=\"p\">(</span><span class=\"n\">fake</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">(),</span> <span class=\"sa\">f</span><span class=\"s2\">\"./imgs/fake_</span><span class=\"si\">{</span><span class=\"n\">i</span><span class=\"si\">:</span><span class=\"s2\">04d</span><span class=\"si\">}</span><span class=\"s2\">.png\"</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"The fake image has been generated!\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Visual</h4>\n<pre>cd $REPO$/framework\nsh start.sh\n</pre>\n<p>Then open the browser and type in the browser address <a href=\"http://127.0.0.1:10001/\" rel=\"nofollow\">http://127.0.0.1:10001/</a>.\nEnjoy it.</p>\n<h3>Contributing</h3>\n<p>If you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.</p>\n<p>I look forward to seeing what the community does with these models!</p>\n\n          </div>"}, "last_serial": 6857937, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ae9e5af131c7b26cba94126fc99d7d7d", "sha256": "ac8290c5e2b6823bfe92c1928af7adc2e4db4997c6a36870808d74c387dca02b"}, "downloads": -1, "filename": "dcgan_pytorch-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ae9e5af131c7b26cba94126fc99d7d7d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 7641, "upload_time": "2020-02-16T06:38:31", "upload_time_iso_8601": "2020-02-16T06:38:31.211514Z", "url": "https://files.pythonhosted.org/packages/a6/88/0358b741627e67a89b3ace6a989c4930c419d1682d0787dac07765bdecb7/dcgan_pytorch-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e864c4194985473948a4bf8c8a945ba1", "sha256": "1594ac653bcfb253fcaf9566f60a9f4e10ea23881fabe5dfff43d6fa256d1a55"}, "downloads": -1, "filename": "dcgan_pytorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e864c4194985473948a4bf8c8a945ba1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7497, "upload_time": "2020-02-16T06:38:33", "upload_time_iso_8601": "2020-02-16T06:38:33.566316Z", "url": "https://files.pythonhosted.org/packages/95/55/820a6cff0857a8e0bca8801130e4ff66991b8c553d4f07d17a67320e82f3/dcgan_pytorch-0.1.0.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "fdf6774f03b64833ea73c1c66918880e", "sha256": "596d7318423f7706ffa2a5751d8a19d9dd880d741e57b4e3bfc65e52c6051375"}, "downloads": -1, "filename": "dcgan_pytorch-0.1.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fdf6774f03b64833ea73c1c66918880e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 7324, "upload_time": "2020-02-17T02:45:38", "upload_time_iso_8601": "2020-02-17T02:45:38.327232Z", "url": "https://files.pythonhosted.org/packages/90/8b/678d5c02f93ace59e3e01148f74544eb4cb7861a3add683df03cbbfa2889/dcgan_pytorch-0.1.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bc398e3447f25ee5beaccf9aa0bf831c", "sha256": "06ebff41a37d8afd7e7a3bb57ae92798c15e81db7a7cee702172acd0e2652108"}, "downloads": -1, "filename": "dcgan_pytorch-0.1.3.tar.gz", "has_sig": false, "md5_digest": "bc398e3447f25ee5beaccf9aa0bf831c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7219, "upload_time": "2020-02-17T02:45:40", "upload_time_iso_8601": "2020-02-17T02:45:40.322695Z", "url": "https://files.pythonhosted.org/packages/e8/29/454dbc0f4a6374e50d6504e1f2040041e466daeb4b10abde18ad69e3f2ce/dcgan_pytorch-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "a27595dce2506dcf1afef8d26404404a", "sha256": "38b0f70af882a445ed1f877da98c063d81e7cef0dcc70296d8353629636e2361"}, "downloads": -1, "filename": "dcgan_pytorch-0.1.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a27595dce2506dcf1afef8d26404404a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 7328, "upload_time": "2020-02-17T02:53:15", "upload_time_iso_8601": "2020-02-17T02:53:15.498783Z", "url": "https://files.pythonhosted.org/packages/33/80/59d55f72c75886a2ab77789a7983c38eace9809032a0190c62b2e4179492/dcgan_pytorch-0.1.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b7a8ceaa94e0aa16a5dd1b6c91db3de4", "sha256": "d80c27c5672a23fa0bdf14c11f57c5f7864e2dbb37464f0ffb1348ad9c68c443"}, "downloads": -1, "filename": "dcgan_pytorch-0.1.4.tar.gz", "has_sig": false, "md5_digest": "b7a8ceaa94e0aa16a5dd1b6c91db3de4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7221, "upload_time": "2020-02-17T02:53:20", "upload_time_iso_8601": "2020-02-17T02:53:20.923454Z", "url": "https://files.pythonhosted.org/packages/04/b6/1b782044eefc3a27e041e597fa42cd2faf6cb5f2d1bed7c8db130526af86/dcgan_pytorch-0.1.4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "29d8c50ec01865cd6880800108a45e4b", "sha256": "c068c93a98533f9cf40541f122fa1a674bdd99b340a92d8f6bcf6dd91a9673ac"}, "downloads": -1, "filename": "dcgan_pytorch-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "29d8c50ec01865cd6880800108a45e4b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 7360, "upload_time": "2020-03-22T01:27:31", "upload_time_iso_8601": "2020-03-22T01:27:31.127588Z", "url": "https://files.pythonhosted.org/packages/14/52/81fd76a2efbc2e6e4dc1cb1e2abc44567c65303f32e87cd41f10bc5acc1f/dcgan_pytorch-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ce125811837817526a2435a9582eec2", "sha256": "efde0b8455c8a6e62d295b0e7c48800c0c0f93ca865b22948ef9d948e841f5c9"}, "downloads": -1, "filename": "dcgan_pytorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "9ce125811837817526a2435a9582eec2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 7206, "upload_time": "2020-03-22T01:27:32", "upload_time_iso_8601": "2020-03-22T01:27:32.990702Z", "url": "https://files.pythonhosted.org/packages/31/7b/910e839ce4f45129ee16b843bc71c98c69a8a9c2a8d2c7a8607552b48afd/dcgan_pytorch-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "29d8c50ec01865cd6880800108a45e4b", "sha256": "c068c93a98533f9cf40541f122fa1a674bdd99b340a92d8f6bcf6dd91a9673ac"}, "downloads": -1, "filename": "dcgan_pytorch-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "29d8c50ec01865cd6880800108a45e4b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.6.0", "size": 7360, "upload_time": "2020-03-22T01:27:31", "upload_time_iso_8601": "2020-03-22T01:27:31.127588Z", "url": "https://files.pythonhosted.org/packages/14/52/81fd76a2efbc2e6e4dc1cb1e2abc44567c65303f32e87cd41f10bc5acc1f/dcgan_pytorch-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9ce125811837817526a2435a9582eec2", "sha256": "efde0b8455c8a6e62d295b0e7c48800c0c0f93ca865b22948ef9d948e841f5c9"}, "downloads": -1, "filename": "dcgan_pytorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "9ce125811837817526a2435a9582eec2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 7206, "upload_time": "2020-03-22T01:27:32", "upload_time_iso_8601": "2020-03-22T01:27:32.990702Z", "url": "https://files.pythonhosted.org/packages/31/7b/910e839ce4f45129ee16b843bc71c98c69a8a9c2a8d2c7a8607552b48afd/dcgan_pytorch-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:49 2020"}