{"info": {"author": "Apache CarbonData", "author_email": "", "bugtrack_url": null, "classifiers": ["Environment :: Console", "Environment :: Web Environment", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6"], "description": "# PyCarbon\n\nPyCarbon provides python API for integrating CarbonData with AI framework like  TensorFlow, PyTorch, MXNet. By using PyCarbon, AI framework can read training data faster by leveraging CarbonData's indexing and caching ability. Since CarbonData is a columnar storage, AI developer can also perform projection and filtering to pick required data for training efficiently.\n\n## PyCarbon install\n\n$ git clone https://github.com/apache/carbondata.git\n\n$ cd python/pycarbon\n\n$ pip install . --user\n\n\n## how to use\n\nif you have a CarbonData dataset, you can use PyCarbon to read data. For the generation of CarbonData dataset, you can see the examples:\n`generate_dataset_carbon.py` in tests/hello_world/dataset_with_unischema.\nBut user should do some config first:\n\n - config pyspark and add carbon assembly jar to pyspark/jars folder, which can be compiled from CarbonData project.\n - default Java sdk jar is in carbondata/sdk/sdk/target,  user also can specific the jar location like by --carbon-sdk-path in generate_pycarbon_dataset.py.\n\n - set JAVA_HOME, PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON in you system environment.\n\n### Generating the data:\n```\n\n    python generate_pycarbon_mnist.py --carbon-sdk-path  /your_path/carbondata/sdk/sdk/target/carbondata-sdk.jar \n\n```\n#### Part of code:\n```\n      spark.createDataFrame(sql_rows, MnistSchema.as_spark_schema()) \\\n        .coalesce(carbon_files_count) \\\n        .write \\\n        .save(path=dset_output_url, format='carbon')\n```\nsome details are illustrated in `generate_pycarbon_mnist.py <https://github.com/apache/carbondata/blob/master/python/pycarbon/tests/mnist/dataset_with_unischema/generate_pycarbon_mnist.py>` in test/hello_world.\n\n### PyCarbon Reader API\n\n```\n\ndef make_reader(dataset_url=None,\n                workers_count=10,\n                results_queue_size=100,\n                num_epochs=1,\n                shuffle=True,\n                is_batch=True\n                ):\n  \"\"\"\n  an unified api for different data format dataset\n\n  :param dataset_url: an filepath or a url to a carbon directory,\n      e.g. ``'hdfs://some_hdfs_cluster/user/yevgeni/carbon8'``, or ``'file:///tmp/mydataset'``\n      or ``'s3a://bucket/mydataset'``.\n  :param workers_count: An int for the number of workers to use in the reader pool. This only is used for the\n      thread or process pool. Defaults to 10\n  :param results_queue_size: Size of the results queue to store prefetched rows. Currently only applicable to\n      thread reader pool type.\n  :param shuffle: Whether to shuffle partition (the order in which full partition are read)\n  :param num_epochs: An epoch is a single pass over all rows in the dataset. Setting ``num_epochs`` to\n      ``None`` will result in an infinite number of epochs.\n  :param is_batch: return single record or batch records (default: True)\n  :return: A :class:`Reader` object\n  \"\"\"\n```\n\n### TensorFlow Dataset API\n```python\n\ndef make_dataset(reader):\n  \"\"\"\n  Creates a `tensorflow.data.Dataset <https://www.tensorflow.org/api_docs/python/tf/data/Dataset>`_ object from\n\n  :param reader: An instance of PyCarbon Reader object that would serve as a data source.\n  :return: A ``tf.data.Dataset`` instance.\n  \"\"\"\n```\n\n### TensorFlow Tensor API\n```python\n\ndef make_tensor(reader):\n  \"\"\"Bridges between python-only interface of the Reader (next(Reader)) and tensorflow world.\n\n  This function returns a named tuple of tensors from the dataset, \n\n  :param reader: An instance of Reader object used as the data source\n  \"\"\"\n```\n\n#### Running train and test based on mnist:\n\n```\n    python  tf_example_carbon_unified_api.py --carbon-sdk-path  /your_path/carbondata/sdk/sdk/target/carbondata-sdk.jar \n\n```\n#### Part or code:\n```\n    with make_reader('file:///some/localpath/a_dataset') as reader:\n        dataset = make_dataset(reader)\n        iterator = dataset.make_one_shot_iterator()\n        tensor = iterator.get_next()\n        with tf.Session() as sess:\n            sample = sess.run(tensor)\n            print(sample.id)\n\n```\nsome details are illustrated in `tf_example_carbon_unified_api.py <https://github.com/apache/carbondata/blob/master/python/pycarbon/tests/mnist/dataset_with_unischema/tf_example_carbon_unified_api.py>` in tests/mnist. \n\n####  Part of result:\n\n```\n2020-01-20 21:12:31 INFO  DictionaryBasedVectorResultCollector:72 - Direct pagewise vector fill collector is used to scan and collect the data\n2020-01-20 21:12:32 INFO  UnsafeMemoryManager:176 - Total offheap working memory used after task 2642c969-6c43-4e31-b8b0-450dff1f7821 is 0. Current running tasks are \n2020-01-20 21:12:32 INFO  UnsafeMemoryManager:176 - Total offheap working memory used after task 67ecf75e-e097-486d-b787-8b7db5f1d7c1 is 0. Current running tasks are \nAfter 0 training iterations, the accuracy of the model is: 0.27\nAfter 10 training iterations, the accuracy of the model is: 0.48\nAfter 20 training iterations, the accuracy of the model is: 0.78\nAfter 30 training iterations, the accuracy of the model is: 0.69\nAfter 40 training iterations, the accuracy of the model is: 0.73\nAfter 50 training iterations, the accuracy of the model is: 0.79\nAfter 60 training iterations, the accuracy of the model is: 0.85\nAfter 70 training iterations, the accuracy of the model is: 0.73\nAfter 80 training iterations, the accuracy of the model is: 0.86\nAfter 90 training iterations, the accuracy of the model is: 0.80\nAfter 99 training iterations, the accuracy of the model is: 0.79\nall time: 185.28250288963318\nFinish\n```\n\n### PyTorch Dataset API\n\n```python\ndef make_data_loader(reader, batch_size=1):\n  \"\"\"\n  Initializes a data loader object, with a default collate.\n\n  Number of epochs is defined by the configuration of the reader argument.\n\n  :param reader: PyCarbon Reader instance\n  :param batch_size: the number of items to return per batch; factored into the len() of this reader\n  \"\"\"\n```\n\n####  Part or code:\n```python\n\n  with make_data_loader(make_reader('{}/train'.format(args.dataset_url), is_batch=False, num_epochs=reader_epochs,\n                                      transform_spec=transform),\n                          batch_size=args.batch_size) as train_loader:\n      train(model, device, train_loader, args.log_interval, optimizer, epoch)\n\n```\nsome details are illustrated in `pytorch_example_carbon_unified_api.py <https://github.com/apache/carbondata/blob/master/python/pycarbon/tests/mnist/dataset_with_unischema/pytorch_example_carbon_unified_api.py>` in tests/mnist. \n\n####  Part of result:\n```python\nTrain Epoch: 10 [55680]\tLoss: 0.255295\nTrain Epoch: 10 [56320]\tLoss: 0.132586\nTrain Epoch: 10 [56960]\tLoss: 0.197574\nTrain Epoch: 10 [57600]\tLoss: 0.280921\nTrain Epoch: 10 [58240]\tLoss: 0.072130\nTrain Epoch: 10 [58880]\tLoss: 0.027580\nTrain Epoch: 10 [59520]\tLoss: 0.036734\nTest set: Average loss: 0.0508, Accuracy: 9843/10000 (98%)\n\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/apache/carbondata", "keywords": "", "license": "Apache License, Version 2.0", "maintainer": "", "maintainer_email": "", "name": "pycarbon-sdk", "package_url": "https://pypi.org/project/pycarbon-sdk/", "platform": "", "project_url": "https://pypi.org/project/pycarbon-sdk/", "project_urls": {"Homepage": "https://github.com/apache/carbondata"}, "release_url": "https://pypi.org/project/pycarbon-sdk/0.1.0/", "requires_dist": ["jnius (>=1.1.0)", "pyjnius (>=1.2.0)", "sphinx (==1.2.2) ; extra == 'docs'", "alabaster (==0.7.11) ; extra == 'docs'", "Pillow (>=3.0) ; extra == 'test'", "codecov (>=2.0.15) ; extra == 'test'", "mock (>=2.0.0) ; extra == 'test'", "opencv-python (>=3.2.0.6) ; extra == 'test'", "flake8 ; extra == 'test'", "pylint (>=1.9) ; extra == 'test'", "pytest (>=3.0.0) ; extra == 'test'", "pytest-cov (>=2.5.1) ; extra == 'test'", "pytest-forked (>=0.2) ; extra == 'test'", "pytest-logger (>=0.4.0) ; extra == 'test'", "pytest-timeout (>=1.3.3) ; extra == 'test'", "pytest-xdist ; extra == 'test'", "s3fs (>=0.0.1) ; extra == 'test'", "torchvision (>=0.2.1) ; extra == 'torch'"], "requires_python": "", "summary": "Pycarbon is a library that optimizes data access for AI based on CarbonData files,  and it is based on Petastorm.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PyCarbon</h1>\n<p>PyCarbon provides python API for integrating CarbonData with AI framework like  TensorFlow, PyTorch, MXNet. By using PyCarbon, AI framework can read training data faster by leveraging CarbonData's indexing and caching ability. Since CarbonData is a columnar storage, AI developer can also perform projection and filtering to pick required data for training efficiently.</p>\n<h2>PyCarbon install</h2>\n<p>$ git clone <a href=\"https://github.com/apache/carbondata.git\" rel=\"nofollow\">https://github.com/apache/carbondata.git</a></p>\n<p>$ cd python/pycarbon</p>\n<p>$ pip install . --user</p>\n<h2>how to use</h2>\n<p>if you have a CarbonData dataset, you can use PyCarbon to read data. For the generation of CarbonData dataset, you can see the examples:\n<code>generate_dataset_carbon.py</code> in tests/hello_world/dataset_with_unischema.\nBut user should do some config first:</p>\n<ul>\n<li>\n<p>config pyspark and add carbon assembly jar to pyspark/jars folder, which can be compiled from CarbonData project.</p>\n</li>\n<li>\n<p>default Java sdk jar is in carbondata/sdk/sdk/target,  user also can specific the jar location like by --carbon-sdk-path in generate_pycarbon_dataset.py.</p>\n</li>\n<li>\n<p>set JAVA_HOME, PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON in you system environment.</p>\n</li>\n</ul>\n<h3>Generating the data:</h3>\n<pre><code>\n    python generate_pycarbon_mnist.py --carbon-sdk-path  /your_path/carbondata/sdk/sdk/target/carbondata-sdk.jar \n\n</code></pre>\n<h4>Part of code:</h4>\n<pre><code>      spark.createDataFrame(sql_rows, MnistSchema.as_spark_schema()) \\\n        .coalesce(carbon_files_count) \\\n        .write \\\n        .save(path=dset_output_url, format='carbon')\n</code></pre>\n<p>some details are illustrated in <code>generate_pycarbon_mnist.py &lt;https://github.com/apache/carbondata/blob/master/python/pycarbon/tests/mnist/dataset_with_unischema/generate_pycarbon_mnist.py&gt;</code> in test/hello_world.</p>\n<h3>PyCarbon Reader API</h3>\n<pre><code>\ndef make_reader(dataset_url=None,\n                workers_count=10,\n                results_queue_size=100,\n                num_epochs=1,\n                shuffle=True,\n                is_batch=True\n                ):\n  \"\"\"\n  an unified api for different data format dataset\n\n  :param dataset_url: an filepath or a url to a carbon directory,\n      e.g. ``'hdfs://some_hdfs_cluster/user/yevgeni/carbon8'``, or ``'file:///tmp/mydataset'``\n      or ``'s3a://bucket/mydataset'``.\n  :param workers_count: An int for the number of workers to use in the reader pool. This only is used for the\n      thread or process pool. Defaults to 10\n  :param results_queue_size: Size of the results queue to store prefetched rows. Currently only applicable to\n      thread reader pool type.\n  :param shuffle: Whether to shuffle partition (the order in which full partition are read)\n  :param num_epochs: An epoch is a single pass over all rows in the dataset. Setting ``num_epochs`` to\n      ``None`` will result in an infinite number of epochs.\n  :param is_batch: return single record or batch records (default: True)\n  :return: A :class:`Reader` object\n  \"\"\"\n</code></pre>\n<h3>TensorFlow Dataset API</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">make_dataset</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">):</span>\n  <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">  Creates a `tensorflow.data.Dataset &lt;https://www.tensorflow.org/api_docs/python/tf/data/Dataset&gt;`_ object from</span>\n\n<span class=\"sd\">  :param reader: An instance of PyCarbon Reader object that would serve as a data source.</span>\n<span class=\"sd\">  :return: A ``tf.data.Dataset`` instance.</span>\n<span class=\"sd\">  \"\"\"</span>\n</pre>\n<h3>TensorFlow Tensor API</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">make_tensor</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">):</span>\n  <span class=\"sd\">\"\"\"Bridges between python-only interface of the Reader (next(Reader)) and tensorflow world.</span>\n\n<span class=\"sd\">  This function returns a named tuple of tensors from the dataset, </span>\n\n<span class=\"sd\">  :param reader: An instance of Reader object used as the data source</span>\n<span class=\"sd\">  \"\"\"</span>\n</pre>\n<h4>Running train and test based on mnist:</h4>\n<pre><code>    python  tf_example_carbon_unified_api.py --carbon-sdk-path  /your_path/carbondata/sdk/sdk/target/carbondata-sdk.jar \n\n</code></pre>\n<h4>Part or code:</h4>\n<pre><code>    with make_reader('file:///some/localpath/a_dataset') as reader:\n        dataset = make_dataset(reader)\n        iterator = dataset.make_one_shot_iterator()\n        tensor = iterator.get_next()\n        with tf.Session() as sess:\n            sample = sess.run(tensor)\n            print(sample.id)\n\n</code></pre>\n<p>some details are illustrated in <code>tf_example_carbon_unified_api.py &lt;https://github.com/apache/carbondata/blob/master/python/pycarbon/tests/mnist/dataset_with_unischema/tf_example_carbon_unified_api.py&gt;</code> in tests/mnist.</p>\n<h4>Part of result:</h4>\n<pre><code>2020-01-20 21:12:31 INFO  DictionaryBasedVectorResultCollector:72 - Direct pagewise vector fill collector is used to scan and collect the data\n2020-01-20 21:12:32 INFO  UnsafeMemoryManager:176 - Total offheap working memory used after task 2642c969-6c43-4e31-b8b0-450dff1f7821 is 0. Current running tasks are \n2020-01-20 21:12:32 INFO  UnsafeMemoryManager:176 - Total offheap working memory used after task 67ecf75e-e097-486d-b787-8b7db5f1d7c1 is 0. Current running tasks are \nAfter 0 training iterations, the accuracy of the model is: 0.27\nAfter 10 training iterations, the accuracy of the model is: 0.48\nAfter 20 training iterations, the accuracy of the model is: 0.78\nAfter 30 training iterations, the accuracy of the model is: 0.69\nAfter 40 training iterations, the accuracy of the model is: 0.73\nAfter 50 training iterations, the accuracy of the model is: 0.79\nAfter 60 training iterations, the accuracy of the model is: 0.85\nAfter 70 training iterations, the accuracy of the model is: 0.73\nAfter 80 training iterations, the accuracy of the model is: 0.86\nAfter 90 training iterations, the accuracy of the model is: 0.80\nAfter 99 training iterations, the accuracy of the model is: 0.79\nall time: 185.28250288963318\nFinish\n</code></pre>\n<h3>PyTorch Dataset API</h3>\n<pre><span class=\"k\">def</span> <span class=\"nf\">make_data_loader</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">):</span>\n  <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">  Initializes a data loader object, with a default collate.</span>\n\n<span class=\"sd\">  Number of epochs is defined by the configuration of the reader argument.</span>\n\n<span class=\"sd\">  :param reader: PyCarbon Reader instance</span>\n<span class=\"sd\">  :param batch_size: the number of items to return per batch; factored into the len() of this reader</span>\n<span class=\"sd\">  \"\"\"</span>\n</pre>\n<h4>Part or code:</h4>\n<pre>  <span class=\"k\">with</span> <span class=\"n\">make_data_loader</span><span class=\"p\">(</span><span class=\"n\">make_reader</span><span class=\"p\">(</span><span class=\"s1\">'</span><span class=\"si\">{}</span><span class=\"s1\">/train'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">dataset_url</span><span class=\"p\">),</span> <span class=\"n\">is_batch</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">num_epochs</span><span class=\"o\">=</span><span class=\"n\">reader_epochs</span><span class=\"p\">,</span>\n                                      <span class=\"n\">transform_spec</span><span class=\"o\">=</span><span class=\"n\">transform</span><span class=\"p\">),</span>\n                          <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">batch_size</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">train_loader</span><span class=\"p\">:</span>\n      <span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">log_interval</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">epoch</span><span class=\"p\">)</span>\n</pre>\n<p>some details are illustrated in <code>pytorch_example_carbon_unified_api.py &lt;https://github.com/apache/carbondata/blob/master/python/pycarbon/tests/mnist/dataset_with_unischema/pytorch_example_carbon_unified_api.py&gt;</code> in tests/mnist.</p>\n<h4>Part of result:</h4>\n<pre><span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">55680</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.255295</span>\n<span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">56320</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.132586</span>\n<span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">56960</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.197574</span>\n<span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">57600</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.280921</span>\n<span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">58240</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.072130</span>\n<span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">58880</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.027580</span>\n<span class=\"n\">Train</span> <span class=\"n\">Epoch</span><span class=\"p\">:</span> <span class=\"mi\">10</span> <span class=\"p\">[</span><span class=\"mi\">59520</span><span class=\"p\">]</span>\t<span class=\"n\">Loss</span><span class=\"p\">:</span> <span class=\"mf\">0.036734</span>\n<span class=\"n\">Test</span> <span class=\"nb\">set</span><span class=\"p\">:</span> <span class=\"n\">Average</span> <span class=\"n\">loss</span><span class=\"p\">:</span> <span class=\"mf\">0.0508</span><span class=\"p\">,</span> <span class=\"n\">Accuracy</span><span class=\"p\">:</span> <span class=\"mi\">9843</span><span class=\"o\">/</span><span class=\"mi\">10000</span> <span class=\"p\">(</span><span class=\"mi\">98</span><span class=\"o\">%</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 7014124, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "eb34c0b454ed1d148326faaa379b3fb1", "sha256": "225e359d4b4db8b959588713882e2e5f2001df529a9a193ac57772108e3e9a72"}, "downloads": -1, "filename": "pycarbon_sdk-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "eb34c0b454ed1d148326faaa379b3fb1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 19169, "upload_time": "2020-04-14T02:04:45", "upload_time_iso_8601": "2020-04-14T02:04:45.951551Z", "url": "https://files.pythonhosted.org/packages/57/94/78f8f5b441fac368082cb81132e710da2ba171e6366b0d39c6b0ca933a2d/pycarbon_sdk-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec47776b15f0b913eb74dad91d33253e", "sha256": "83f4e65d5e4fd2977bbcb21e8d66ba0c2123bb49d3efc39e8e95f3f53a91d6f6"}, "downloads": -1, "filename": "pycarbon_sdk-0.1.0-py3.7.egg", "has_sig": false, "md5_digest": "ec47776b15f0b913eb74dad91d33253e", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 35406, "upload_time": "2020-04-14T02:04:48", "upload_time_iso_8601": "2020-04-14T02:04:48.829009Z", "url": "https://files.pythonhosted.org/packages/90/ca/41680596345ce186e8dbd347cb643bf6e6319df569877d1fc168e8c2027c/pycarbon_sdk-0.1.0-py3.7.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "eb34c0b454ed1d148326faaa379b3fb1", "sha256": "225e359d4b4db8b959588713882e2e5f2001df529a9a193ac57772108e3e9a72"}, "downloads": -1, "filename": "pycarbon_sdk-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "eb34c0b454ed1d148326faaa379b3fb1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 19169, "upload_time": "2020-04-14T02:04:45", "upload_time_iso_8601": "2020-04-14T02:04:45.951551Z", "url": "https://files.pythonhosted.org/packages/57/94/78f8f5b441fac368082cb81132e710da2ba171e6366b0d39c6b0ca933a2d/pycarbon_sdk-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec47776b15f0b913eb74dad91d33253e", "sha256": "83f4e65d5e4fd2977bbcb21e8d66ba0c2123bb49d3efc39e8e95f3f53a91d6f6"}, "downloads": -1, "filename": "pycarbon_sdk-0.1.0-py3.7.egg", "has_sig": false, "md5_digest": "ec47776b15f0b913eb74dad91d33253e", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 35406, "upload_time": "2020-04-14T02:04:48", "upload_time_iso_8601": "2020-04-14T02:04:48.829009Z", "url": "https://files.pythonhosted.org/packages/90/ca/41680596345ce186e8dbd347cb643bf6e6319df569877d1fc168e8c2027c/pycarbon_sdk-0.1.0-py3.7.egg", "yanked": false}], "timestamp": "Fri May  8 03:08:46 2020"}