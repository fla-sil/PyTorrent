{"info": {"author": "Plumerai", "author_email": "arash@plumerai.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3 :: Only", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Larq Compute Engine <img src=\"https://user-images.githubusercontent.com/13285808/74535800-84017780-4f2e-11ea-9169-52f5ac83d685.png\" alt=\"larq logo\" height=\"80px\" align=\"right\" />\n\n[![Tests](https://github.com/larq/compute-engine/workflows/Tests/badge.svg)](https://github.com/larq/compute-engine/actions?workflow=Tests) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/larq-compute-engine.svg)](https://pypi.org/project/larq-compute-engine/) [![PyPI](https://img.shields.io/pypi/v/larq-compute-engine.svg)](https://pypi.org/project/larq-compute-engine/) [![PyPI - License](https://img.shields.io/pypi/l/larq-compute-engine.svg)](https://github.com/larq/compute-engine/blob/master/LICENSE) [![Join the community on Spectrum](https://withspectrum.github.io/badge/badge.svg)](https://spectrum.chat/larq)\n\nLarq Compute Engine (LCE) is a highly optimized inference engine for deploying\nextremely quantized neural networks, such as\nBinarized Neural Networks (BNNs). It currently supports various mobile platforms\nand has been benchmarked on a Pixel 1 phone and a Raspberry Pi.\nLCE provides a collection of hand-optimized [TensorFlow Lite](https://www.tensorflow.org/lite)\ncustom operators for supported instruction sets, developed in inline assembly or in C++\nusing compiler intrinsics. LCE leverages optimization techniques\nsuch as **tiling** to maximize the number of cache hits, **vectorization** to maximize\nthe computational throughput, and **multi-threading parallelization** to take\nadvantage of multi-core modern desktop and mobile CPUs.\n\n*Larq Compute Engine is part of a family of libraries for BNN development; you can also check out [Larq](https://github.com/larq/larq) for building and training BNNs and [Larq Zoo](https://github.com/larq/zoo) for pre-trained models.*\n\n## Key Features\n\n- **Effortless end-to-end integration** from training to deployment:\n\n    - Tight integration of LCE with [Larq](https://larq.dev) and\n      TensorFlow provides a smooth end-to-end training and deployment experience.\n\n    - A collection of Larq pre-trained BNN models for common machine learning tasks\n      is available in [Larq Zoo](https://docs.larq.dev/zoo/)\n      and can be used out-of-the-box with LCE.\n\n    - LCE provides a custom [MLIR-based model converter](https://docs.larq.dev/compute-engine/converter) which\n      is fully compatible with TensorFlow Lite and performs additional\n      network level optimizations for Larq models.\n\n- **Lightning fast deployment** on a variety of mobile platforms:\n\n    - LCE enables high performance, on-device machine learning inference by\n      providing hand-optimized kernels and network level optimizations for BNN models.\n\n    - LCE currently supports ARM64-based mobile platforms such as Android phones\n      and Raspberry Pi boards.\n\n    - Thread parallelism support in LCE is essential for modern mobile devices with\n      multi-core CPUs.\n\n## Performance\n\nThe table below presents **single-threaded** performance of Larq Compute Engine on\ndifferent versions of a novel BNN model called QuickNet (trained on ImageNet dataset, soon to be released in [Larq Zoo](https://docs.larq.dev/zoo/))\non a [Pixel 1 phone (2016)](https://support.google.com/pixelphone/answer/7158570?hl=en-GB)\nand a Raspberry Pi 4 Model B ([BCM2711](https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2711/README.md)) board:\n\n| Model                                                                                                                 | Top-1 Accuracy | RPi 4 B, ms (1 thread) | Pixel 1, ms (1 thread) |\n| ------------------------------------------------------------------------------------------------                      | :------------: | :--------------------: | :--------------------: |\n| [QuickNet](https://docs.larq.dev/zoo/api/sota/#quicknet) ([.h5](https://github.com/larq/zoo/releases/download/quicknet-v0.2.0/quicknet_weights.h5))                   | 58.6 %         | 38.5                   | 20.2                   |\n| [QuickNet-Large](https://docs.larq.dev/zoo/api/sota/#quicknetlarge) ([.h5](https://github.com/larq/zoo/releases/download/quicknet_large-v0.2.0/quicknet_large_weights.h5)) | 62.7 %         | 58.3                   | 30.9                   |\n| [QuickNet-XL](https://docs.larq.dev/zoo/api/sota/#quicknetxl) ([.h5](https://github.com/larq/zoo/releases/download/quicknet_xl-v0.1.0/quicknet_xl_weights.h5))                                                                                         | 67.0 %         | 102.0                  | 54.5                   |\n\nFor reference, [dabnn](https://github.com/JDAI-CV/dabnn) (the other main BNN library) reports an inference time of 61.3 ms for [Bi-RealNet](https://docs.larq.dev/zoo/api/literature/#birealnet) (56.4% accuracy) on the Pixel 1 phone,\nwhile LCE achieves an inference time of 46.8 ms for Bi-RealNet on the same device.\nThey furthermore present a modified version, BiRealNet-Stem, which achieves the same accuracy of 56.4% in 43.2 ms.\n\nThe following table presents **multi-threaded** performance of Larq Compute Engine on\na Pixel 1 phone and a Raspberry Pi 4 Model B ([BCM2711](https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2711/README.md))\nboard:\n\n| Model                                                                                                                 | Top-1 Accuracy | RPi 4 B, ms (4 threads) | Pixel 1, ms (4 threads) |\n| ------------------------------------------------------------------------------------------------                      | :------------: | :---------------------: | :---------------------: |\n| [QuickNet](https://docs.larq.dev/zoo/api/sota/#quicknet) ([.h5](https://github.com/larq/zoo/releases/download/quicknet-v0.2.0/quicknet_weights.h5))                   | 58.6 %         | 20.0                    | 11.5                    |\n| [QuickNet-Large](https://docs.larq.dev/zoo/api/sota/#quicknetlarge) ([.h5](https://github.com/larq/zoo/releases/download/quicknet_large-v0.2.0/quicknet_large_weights.h5)) | 62.7 %         | 30.4                    | 16.9                    |\n| [QuickNet-XL](https://docs.larq.dev/zoo/api/sota/#quicknetxl) ([.h5](https://github.com/larq/zoo/releases/download/quicknet_xl-v0.1.0/quicknet_xl_weights.h5))                                                                                         | 67.0 %         | 46.6                    | 28.3                    |\n\n\nBenchmarked on April 20th, 2020 with LCE custom\n[TFLite Model Benchmark Tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark)\n(see [here](https://github.com/larq/compute-engine/tree/master/larq_compute_engine/tflite/benchmark))\nand BNN models with randomized weights and inputs.\n\n## Getting started\n\nFollow these steps to deploy a BNN with LCE:\n\n1. **Pick a Larq model**\n\n    You can use [Larq](https://larq.dev) to build and train your own model or pick a pre-trained model from [Larq Zoo](https://docs.larq.dev/zoo/).\n\n2. **Convert the Larq model**\n\n    LCE is built on top of TensorFlow Lite and uses the TensorFlow Lite [FlatBuffer format](https://google.github.io/flatbuffers/) to convert and serialize Larq models for inference. We provide an [LCE Converter](https://docs.larq.dev/compute-engine/converter) with additional optimization passes to increase the speed of execution of Larq models on supported target platforms.\n\n3. **Build LCE**\n\n    The LCE documentation provides the build instructions for [Android](https://docs.larq.dev/compute-engine/quickstart_android) and [ARM64-based boards](https://docs.larq.dev/compute-engine/build_arm) such as Raspberry Pi. Please follow the provided instructions to create a native LCE build or cross-compile for one of the supported targets.\n\n4. **Run inference**\n\n    LCE uses the [TensorFlow Lite Interpreter](https://www.tensorflow.org/lite/guide/inference) to perform an inference. In addition to the already available built-in TensorFlow Lite operators, optimized LCE operators are registered to the interpreter to execute the Larq specific subgraphs of the model. An example to create and build an LCE compatible TensorFlow Lite interpreter for your own applications is provided [here](https://docs.larq.dev/compute-engine/inference).\n\n## Next steps\n\n- Explore [Larq pre-trained models](https://docs.larq.dev/zoo/).\n- Learn how to [build](https://docs.larq.dev/larq/guides/bnn-architecture/) and\n  [train](https://docs.larq.dev/larq/guides/bnn-optimization/) BNNs for your own\n  application with Larq.\n- If you're a mobile developer, visit [Android quickstart](https://docs.larq.dev/compute-engine/quickstart_android).\n- See our build instructions for Raspberry Pi and Arm64-based boards [here](https://docs.larq.dev/compute-engine/build_arm).\n- Try our [example programs](https://github.com/larq/compute-engine/tree/master/examples).\n\n## About\n\nLarq Compute Engine is being developed by a team of deep learning researchers and engineers at Plumerai to help accelerate both our own research and the general adoption of Binarized Neural Networks.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://larq.dev/", "keywords": "binarized neural networks", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "larq-compute-engine", "package_url": "https://pypi.org/project/larq-compute-engine/", "platform": "", "project_url": "https://pypi.org/project/larq-compute-engine/", "project_urls": {"Homepage": "https://larq.dev/"}, "release_url": "https://pypi.org/project/larq-compute-engine/0.2.1/", "requires_dist": ["packaging (>=19)", "tensorflow (>=1.14) ; extra == 'tensorflow'", "tensorflow-gpu (>=1.14) ; extra == 'tensorflow_gpu'"], "requires_python": ">=3.6", "summary": "Highly optimized inference engine for binarized neural networks.", "version": "0.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Larq Compute Engine <img align=\"right\" alt=\"larq logo\" height=\"80px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5a72490e667c7774d1fe5fc6693dfd95cfbe40ea/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31333238353830382f37343533353830302d38343031373738302d346632652d313165612d393136392d3532663561633833643638352e706e67\"></h1>\n<p><a href=\"https://github.com/larq/compute-engine/actions?workflow=Tests\" rel=\"nofollow\"><img alt=\"Tests\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/86e27f3513834146684e75060a5f70a777b7acd5/68747470733a2f2f6769746875622e636f6d2f6c6172712f636f6d707574652d656e67696e652f776f726b666c6f77732f54657374732f62616467652e737667\"></a> <a href=\"https://pypi.org/project/larq-compute-engine/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0358e2b8217d6377785b2783d0fa9361fcdf822b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6c6172712d636f6d707574652d656e67696e652e737667\"></a> <a href=\"https://pypi.org/project/larq-compute-engine/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7ff1c0b6421fdca4508e63f4189fe05d8d5c55af/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6172712d636f6d707574652d656e67696e652e737667\"></a> <a href=\"https://github.com/larq/compute-engine/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3d75f0d11bbd8a8ae36bbd853a648ef5a17dbbb9/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6c6172712d636f6d707574652d656e67696e652e737667\"></a> <a href=\"https://spectrum.chat/larq\" rel=\"nofollow\"><img alt=\"Join the community on Spectrum\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8299923510866316317464943f9b48d147f835ce/68747470733a2f2f77697468737065637472756d2e6769746875622e696f2f62616467652f62616467652e737667\"></a></p>\n<p>Larq Compute Engine (LCE) is a highly optimized inference engine for deploying\nextremely quantized neural networks, such as\nBinarized Neural Networks (BNNs). It currently supports various mobile platforms\nand has been benchmarked on a Pixel 1 phone and a Raspberry Pi.\nLCE provides a collection of hand-optimized <a href=\"https://www.tensorflow.org/lite\" rel=\"nofollow\">TensorFlow Lite</a>\ncustom operators for supported instruction sets, developed in inline assembly or in C++\nusing compiler intrinsics. LCE leverages optimization techniques\nsuch as <strong>tiling</strong> to maximize the number of cache hits, <strong>vectorization</strong> to maximize\nthe computational throughput, and <strong>multi-threading parallelization</strong> to take\nadvantage of multi-core modern desktop and mobile CPUs.</p>\n<p><em>Larq Compute Engine is part of a family of libraries for BNN development; you can also check out <a href=\"https://github.com/larq/larq\" rel=\"nofollow\">Larq</a> for building and training BNNs and <a href=\"https://github.com/larq/zoo\" rel=\"nofollow\">Larq Zoo</a> for pre-trained models.</em></p>\n<h2>Key Features</h2>\n<ul>\n<li>\n<p><strong>Effortless end-to-end integration</strong> from training to deployment:</p>\n<ul>\n<li>\n<p>Tight integration of LCE with <a href=\"https://larq.dev\" rel=\"nofollow\">Larq</a> and\nTensorFlow provides a smooth end-to-end training and deployment experience.</p>\n</li>\n<li>\n<p>A collection of Larq pre-trained BNN models for common machine learning tasks\nis available in <a href=\"https://docs.larq.dev/zoo/\" rel=\"nofollow\">Larq Zoo</a>\nand can be used out-of-the-box with LCE.</p>\n</li>\n<li>\n<p>LCE provides a custom <a href=\"https://docs.larq.dev/compute-engine/converter\" rel=\"nofollow\">MLIR-based model converter</a> which\nis fully compatible with TensorFlow Lite and performs additional\nnetwork level optimizations for Larq models.</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Lightning fast deployment</strong> on a variety of mobile platforms:</p>\n<ul>\n<li>\n<p>LCE enables high performance, on-device machine learning inference by\nproviding hand-optimized kernels and network level optimizations for BNN models.</p>\n</li>\n<li>\n<p>LCE currently supports ARM64-based mobile platforms such as Android phones\nand Raspberry Pi boards.</p>\n</li>\n<li>\n<p>Thread parallelism support in LCE is essential for modern mobile devices with\nmulti-core CPUs.</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Performance</h2>\n<p>The table below presents <strong>single-threaded</strong> performance of Larq Compute Engine on\ndifferent versions of a novel BNN model called QuickNet (trained on ImageNet dataset, soon to be released in <a href=\"https://docs.larq.dev/zoo/\" rel=\"nofollow\">Larq Zoo</a>)\non a <a href=\"https://support.google.com/pixelphone/answer/7158570?hl=en-GB\" rel=\"nofollow\">Pixel 1 phone (2016)</a>\nand a Raspberry Pi 4 Model B (<a href=\"https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2711/README.md\" rel=\"nofollow\">BCM2711</a>) board:</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">Top-1 Accuracy</th>\n<th align=\"center\">RPi 4 B, ms (1 thread)</th>\n<th align=\"center\">Pixel 1, ms (1 thread)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://docs.larq.dev/zoo/api/sota/#quicknet\" rel=\"nofollow\">QuickNet</a> (<a href=\"https://github.com/larq/zoo/releases/download/quicknet-v0.2.0/quicknet_weights.h5\" rel=\"nofollow\">.h5</a>)</td>\n<td align=\"center\">58.6 %</td>\n<td align=\"center\">38.5</td>\n<td align=\"center\">20.2</td>\n</tr>\n<tr>\n<td><a href=\"https://docs.larq.dev/zoo/api/sota/#quicknetlarge\" rel=\"nofollow\">QuickNet-Large</a> (<a href=\"https://github.com/larq/zoo/releases/download/quicknet_large-v0.2.0/quicknet_large_weights.h5\" rel=\"nofollow\">.h5</a>)</td>\n<td align=\"center\">62.7 %</td>\n<td align=\"center\">58.3</td>\n<td align=\"center\">30.9</td>\n</tr>\n<tr>\n<td><a href=\"https://docs.larq.dev/zoo/api/sota/#quicknetxl\" rel=\"nofollow\">QuickNet-XL</a> (<a href=\"https://github.com/larq/zoo/releases/download/quicknet_xl-v0.1.0/quicknet_xl_weights.h5\" rel=\"nofollow\">.h5</a>)</td>\n<td align=\"center\">67.0 %</td>\n<td align=\"center\">102.0</td>\n<td align=\"center\">54.5</td>\n</tr></tbody></table>\n<p>For reference, <a href=\"https://github.com/JDAI-CV/dabnn\" rel=\"nofollow\">dabnn</a> (the other main BNN library) reports an inference time of 61.3 ms for <a href=\"https://docs.larq.dev/zoo/api/literature/#birealnet\" rel=\"nofollow\">Bi-RealNet</a> (56.4% accuracy) on the Pixel 1 phone,\nwhile LCE achieves an inference time of 46.8 ms for Bi-RealNet on the same device.\nThey furthermore present a modified version, BiRealNet-Stem, which achieves the same accuracy of 56.4% in 43.2 ms.</p>\n<p>The following table presents <strong>multi-threaded</strong> performance of Larq Compute Engine on\na Pixel 1 phone and a Raspberry Pi 4 Model B (<a href=\"https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2711/README.md\" rel=\"nofollow\">BCM2711</a>)\nboard:</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">Top-1 Accuracy</th>\n<th align=\"center\">RPi 4 B, ms (4 threads)</th>\n<th align=\"center\">Pixel 1, ms (4 threads)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://docs.larq.dev/zoo/api/sota/#quicknet\" rel=\"nofollow\">QuickNet</a> (<a href=\"https://github.com/larq/zoo/releases/download/quicknet-v0.2.0/quicknet_weights.h5\" rel=\"nofollow\">.h5</a>)</td>\n<td align=\"center\">58.6 %</td>\n<td align=\"center\">20.0</td>\n<td align=\"center\">11.5</td>\n</tr>\n<tr>\n<td><a href=\"https://docs.larq.dev/zoo/api/sota/#quicknetlarge\" rel=\"nofollow\">QuickNet-Large</a> (<a href=\"https://github.com/larq/zoo/releases/download/quicknet_large-v0.2.0/quicknet_large_weights.h5\" rel=\"nofollow\">.h5</a>)</td>\n<td align=\"center\">62.7 %</td>\n<td align=\"center\">30.4</td>\n<td align=\"center\">16.9</td>\n</tr>\n<tr>\n<td><a href=\"https://docs.larq.dev/zoo/api/sota/#quicknetxl\" rel=\"nofollow\">QuickNet-XL</a> (<a href=\"https://github.com/larq/zoo/releases/download/quicknet_xl-v0.1.0/quicknet_xl_weights.h5\" rel=\"nofollow\">.h5</a>)</td>\n<td align=\"center\">67.0 %</td>\n<td align=\"center\">46.6</td>\n<td align=\"center\">28.3</td>\n</tr></tbody></table>\n<p>Benchmarked on April 20th, 2020 with LCE custom\n<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark\" rel=\"nofollow\">TFLite Model Benchmark Tool</a>\n(see <a href=\"https://github.com/larq/compute-engine/tree/master/larq_compute_engine/tflite/benchmark\" rel=\"nofollow\">here</a>)\nand BNN models with randomized weights and inputs.</p>\n<h2>Getting started</h2>\n<p>Follow these steps to deploy a BNN with LCE:</p>\n<ol>\n<li>\n<p><strong>Pick a Larq model</strong></p>\n<p>You can use <a href=\"https://larq.dev\" rel=\"nofollow\">Larq</a> to build and train your own model or pick a pre-trained model from <a href=\"https://docs.larq.dev/zoo/\" rel=\"nofollow\">Larq Zoo</a>.</p>\n</li>\n<li>\n<p><strong>Convert the Larq model</strong></p>\n<p>LCE is built on top of TensorFlow Lite and uses the TensorFlow Lite <a href=\"https://google.github.io/flatbuffers/\" rel=\"nofollow\">FlatBuffer format</a> to convert and serialize Larq models for inference. We provide an <a href=\"https://docs.larq.dev/compute-engine/converter\" rel=\"nofollow\">LCE Converter</a> with additional optimization passes to increase the speed of execution of Larq models on supported target platforms.</p>\n</li>\n<li>\n<p><strong>Build LCE</strong></p>\n<p>The LCE documentation provides the build instructions for <a href=\"https://docs.larq.dev/compute-engine/quickstart_android\" rel=\"nofollow\">Android</a> and <a href=\"https://docs.larq.dev/compute-engine/build_arm\" rel=\"nofollow\">ARM64-based boards</a> such as Raspberry Pi. Please follow the provided instructions to create a native LCE build or cross-compile for one of the supported targets.</p>\n</li>\n<li>\n<p><strong>Run inference</strong></p>\n<p>LCE uses the <a href=\"https://www.tensorflow.org/lite/guide/inference\" rel=\"nofollow\">TensorFlow Lite Interpreter</a> to perform an inference. In addition to the already available built-in TensorFlow Lite operators, optimized LCE operators are registered to the interpreter to execute the Larq specific subgraphs of the model. An example to create and build an LCE compatible TensorFlow Lite interpreter for your own applications is provided <a href=\"https://docs.larq.dev/compute-engine/inference\" rel=\"nofollow\">here</a>.</p>\n</li>\n</ol>\n<h2>Next steps</h2>\n<ul>\n<li>Explore <a href=\"https://docs.larq.dev/zoo/\" rel=\"nofollow\">Larq pre-trained models</a>.</li>\n<li>Learn how to <a href=\"https://docs.larq.dev/larq/guides/bnn-architecture/\" rel=\"nofollow\">build</a> and\n<a href=\"https://docs.larq.dev/larq/guides/bnn-optimization/\" rel=\"nofollow\">train</a> BNNs for your own\napplication with Larq.</li>\n<li>If you're a mobile developer, visit <a href=\"https://docs.larq.dev/compute-engine/quickstart_android\" rel=\"nofollow\">Android quickstart</a>.</li>\n<li>See our build instructions for Raspberry Pi and Arm64-based boards <a href=\"https://docs.larq.dev/compute-engine/build_arm\" rel=\"nofollow\">here</a>.</li>\n<li>Try our <a href=\"https://github.com/larq/compute-engine/tree/master/examples\" rel=\"nofollow\">example programs</a>.</li>\n</ul>\n<h2>About</h2>\n<p>Larq Compute Engine is being developed by a team of deep learning researchers and engineers at Plumerai to help accelerate both our own research and the general adoption of Binarized Neural Networks.</p>\n\n          </div>"}, "last_serial": 7061291, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "50ab892c2ca9235f245c67f5a40c157a", "sha256": "662c4d9de0a2593688499322c4e8aa40a3476352d6faf96b7ee7bc925aab2f37"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0-cp36-cp36m-macosx_10_15_x86_64.whl", "has_sig": false, "md5_digest": "50ab892c2ca9235f245c67f5a40c157a", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8629096, "upload_time": "2020-02-17T18:51:36", "upload_time_iso_8601": "2020-02-17T18:51:36.096526Z", "url": "https://files.pythonhosted.org/packages/f0/6d/5cc83779717c69db6d1f34270e5fb67740bf3242e11e65c911abc8cfe0e1/larq_compute_engine-0.1.0-cp36-cp36m-macosx_10_15_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b1be7dd97debacfb3e83bdac4f9d84af", "sha256": "698b3fee35e86a8d30e64f76e64653183d4870bba0816c5a0152f7859872ea50"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "b1be7dd97debacfb3e83bdac4f9d84af", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5177600, "upload_time": "2020-02-17T18:51:39", "upload_time_iso_8601": "2020-02-17T18:51:39.065474Z", "url": "https://files.pythonhosted.org/packages/62/43/f40793a803eae70bed3b3aaa1a36963b9837c205d59bef426c29b62c2fa3/larq_compute_engine-0.1.0-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "825155401f75dd9d58720855cf6837d6", "sha256": "3733196c525cf42fd5ae517810729bc530afdc88dbe3a55c417831fb833e7e2e"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0-cp37-cp37m-macosx_10_15_x86_64.whl", "has_sig": false, "md5_digest": "825155401f75dd9d58720855cf6837d6", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8629116, "upload_time": "2020-02-17T18:51:41", "upload_time_iso_8601": "2020-02-17T18:51:41.334708Z", "url": "https://files.pythonhosted.org/packages/3e/67/23e400ad84b452be854f8e424387d6c5ff30d576a33e699ba02809f89353/larq_compute_engine-0.1.0-cp37-cp37m-macosx_10_15_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5239a09b5967fb044d939526222dc3d9", "sha256": "3b2dc96f7a3b656719ce4dfb25a68e4b51b2b375ca97a3ada0fd9b06015ae109"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "5239a09b5967fb044d939526222dc3d9", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5181955, "upload_time": "2020-02-17T18:51:44", "upload_time_iso_8601": "2020-02-17T18:51:44.103888Z", "url": "https://files.pythonhosted.org/packages/f9/f2/d105089a5bc454060859396948d2773e331154c9304731d20de15d966e3f/larq_compute_engine-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}], "0.1.0rc1": [{"comment_text": "", "digests": {"md5": "27588f49f0ce8797cc04656cf359efff", "sha256": "3b8b777a9937d002b5b95f5c7c8b09c6a6b56728dd3c1392953e055aa05954e2"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0rc1-cp36-cp36m-macosx_10_15_x86_64.whl", "has_sig": false, "md5_digest": "27588f49f0ce8797cc04656cf359efff", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8628470, "upload_time": "2020-02-14T14:19:52", "upload_time_iso_8601": "2020-02-14T14:19:52.194498Z", "url": "https://files.pythonhosted.org/packages/e3/bf/9c6457a38bc3a7fbbd7f86ef5d2421514a7c0da7f7d092131189b0bbfa8a/larq_compute_engine-0.1.0rc1-cp36-cp36m-macosx_10_15_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bded4ed2481acfdca37f5e641eb2211e", "sha256": "77d49f189e3797e22533afdec3fa538730b6786831b5d86cd457f5fe27c9052d"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0rc1-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "bded4ed2481acfdca37f5e641eb2211e", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5175376, "upload_time": "2020-02-14T14:19:55", "upload_time_iso_8601": "2020-02-14T14:19:55.790494Z", "url": "https://files.pythonhosted.org/packages/19/40/93dbac2f2b26d149fe43af46593532c4878650c84c0a9c79b0f1ff8de470/larq_compute_engine-0.1.0rc1-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23c5b7f61a0873a72776ca3781907173", "sha256": "a2be91154ee76c7027960f4fb26bb0ad2d5262139bf000723a385ef2177ce406"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0rc1-cp37-cp37m-macosx_10_15_x86_64.whl", "has_sig": false, "md5_digest": "23c5b7f61a0873a72776ca3781907173", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8628489, "upload_time": "2020-02-14T14:19:58", "upload_time_iso_8601": "2020-02-14T14:19:58.318784Z", "url": "https://files.pythonhosted.org/packages/2f/c3/9d657f2a0a233903e29e38df9d8599249bfbcae076dcabdafdfc225beb26/larq_compute_engine-0.1.0rc1-cp37-cp37m-macosx_10_15_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6b3352651dcc099ffe64e6d5af65aad9", "sha256": "046462dfa451f62a74dcc4956e92700f658ae036cd0d7cea736e20f8fbda82c0"}, "downloads": -1, "filename": "larq_compute_engine-0.1.0rc1-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "6b3352651dcc099ffe64e6d5af65aad9", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5179720, "upload_time": "2020-02-14T14:20:01", "upload_time_iso_8601": "2020-02-14T14:20:01.000382Z", "url": "https://files.pythonhosted.org/packages/46/0a/36880089a7335708fcf1d32ea73367a81127139cabc52d3035dc4ff83c9d/larq_compute_engine-0.1.0rc1-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "93b24a75d1db40937968b62f0bc72b9e", "sha256": "4f76ff7f8f699ef6ebf4526d19de008a2fd49fd8cfb7205a31d7d79846830f7c"}, "downloads": -1, "filename": "larq_compute_engine-0.1.1-cp36-cp36m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "93b24a75d1db40937968b62f0bc72b9e", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8628890, "upload_time": "2020-02-20T18:12:40", "upload_time_iso_8601": "2020-02-20T18:12:40.422417Z", "url": "https://files.pythonhosted.org/packages/26/7f/abf2abf75384521e647a6b561ff4715fdf4fbc8fccbebd81f2ed886312c0/larq_compute_engine-0.1.1-cp36-cp36m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5ea097ae23549edad2f7eb35693ec79d", "sha256": "d799f3390df532f6d684a209e387dab24d511ce75e25fb8410ba6eafdb171626"}, "downloads": -1, "filename": "larq_compute_engine-0.1.1-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "5ea097ae23549edad2f7eb35693ec79d", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5177851, "upload_time": "2020-02-20T18:12:42", "upload_time_iso_8601": "2020-02-20T18:12:42.774594Z", "url": "https://files.pythonhosted.org/packages/25/30/b8bea741e39d9aa26d8a2e739beb9dc41317a3c60a87d740f105e726ab7e/larq_compute_engine-0.1.1-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8b04fff1e552d72c12d7c65c2c8a84d6", "sha256": "3146bc65266a50b0093b4ef73a74767a4b8942643a9a58d9048f8279b0866156"}, "downloads": -1, "filename": "larq_compute_engine-0.1.1-cp37-cp37m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "8b04fff1e552d72c12d7c65c2c8a84d6", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8628887, "upload_time": "2020-02-20T18:12:44", "upload_time_iso_8601": "2020-02-20T18:12:44.778050Z", "url": "https://files.pythonhosted.org/packages/26/ab/b4a2a8314a82de36944b5c715761a0c5a04b0cce82138e704a8535edc5a2/larq_compute_engine-0.1.1-cp37-cp37m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b2b01aa181f709203bf88791574ad810", "sha256": "d9bac1cc5aa3ece362420b8825ac2e214b013bb10531f2fcc6a10f3d36cb2021"}, "downloads": -1, "filename": "larq_compute_engine-0.1.1-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "b2b01aa181f709203bf88791574ad810", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5182042, "upload_time": "2020-02-20T18:12:47", "upload_time_iso_8601": "2020-02-20T18:12:47.098636Z", "url": "https://files.pythonhosted.org/packages/d1/ce/7a209943788fccc4502351ea56112e6c28cf1839b84b234a00b98ba8308d/larq_compute_engine-0.1.1-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "9caa47e3c1ce23ae3b2eef0444032977", "sha256": "10c350b81808f01fc39852b19eee19917e613b09ebd7c23d2f2c44d271364856"}, "downloads": -1, "filename": "larq_compute_engine-0.1.2-cp36-cp36m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "9caa47e3c1ce23ae3b2eef0444032977", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8628876, "upload_time": "2020-02-26T16:48:00", "upload_time_iso_8601": "2020-02-26T16:48:00.511273Z", "url": "https://files.pythonhosted.org/packages/2d/f0/1c426ea9fb7f6cb47378c815402d32ceccc00f4b6fab8a0759bd1baf95fe/larq_compute_engine-0.1.2-cp36-cp36m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c89ca93065c06390aade5119617f533b", "sha256": "dd769abbed65f68809ec49667c8c1d1c88f5b82372ff0ed91529e640b8f130a2"}, "downloads": -1, "filename": "larq_compute_engine-0.1.2-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "c89ca93065c06390aade5119617f533b", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5177447, "upload_time": "2020-02-26T16:48:03", "upload_time_iso_8601": "2020-02-26T16:48:03.750162Z", "url": "https://files.pythonhosted.org/packages/98/b0/d353fb42a4082efc4208faff41c426b5787763074d6fa5291e5685ac9a8d/larq_compute_engine-0.1.2-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e6f6067e14ab3164909891d38c9cb797", "sha256": "7d14448cac264fab3653fb0f5ea82c058f84e4facda205e08f20a323050bd263"}, "downloads": -1, "filename": "larq_compute_engine-0.1.2-cp37-cp37m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "e6f6067e14ab3164909891d38c9cb797", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8628840, "upload_time": "2020-02-26T16:48:05", "upload_time_iso_8601": "2020-02-26T16:48:05.790917Z", "url": "https://files.pythonhosted.org/packages/35/43/450cdaf5e5fb3912930f491ce4724e47734f58116938f37f78cd55d8dbd9/larq_compute_engine-0.1.2-cp37-cp37m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3e6b79f9a2a83d1b5812650c30245eba", "sha256": "13a00df7558b83420d6a8d2d326068d2f7ce644e2b8c87e315096964cefdce4e"}, "downloads": -1, "filename": "larq_compute_engine-0.1.2-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "3e6b79f9a2a83d1b5812650c30245eba", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5181658, "upload_time": "2020-02-26T16:48:08", "upload_time_iso_8601": "2020-02-26T16:48:08.311089Z", "url": "https://files.pythonhosted.org/packages/21/6c/40d7240c1dc364f7ea0a730a54a4a4cc39f1cadcd0ccd97ccd16eccba9eb/larq_compute_engine-0.1.2-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "fb2f2a237d985cbe3320b90e43b84f6a", "sha256": "cf95898f5e2c568185a5839ba21fa90b3efee47e48cb3a8bec461eea13a13a64"}, "downloads": -1, "filename": "larq_compute_engine-0.2.0-cp36-cp36m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "fb2f2a237d985cbe3320b90e43b84f6a", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8638880, "upload_time": "2020-03-23T19:06:49", "upload_time_iso_8601": "2020-03-23T19:06:49.820143Z", "url": "https://files.pythonhosted.org/packages/e5/79/ba67166f1a03afc464ff3b72f4f88237f922696646735392f38968a1339b/larq_compute_engine-0.2.0-cp36-cp36m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "162ad3fe022391f445397d4b36be3e95", "sha256": "dad4ae3929ab082ff32ee43a74e701100b613c43cb88b5aa8e8e977e2fcdf089"}, "downloads": -1, "filename": "larq_compute_engine-0.2.0-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "162ad3fe022391f445397d4b36be3e95", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5190740, "upload_time": "2020-03-23T19:06:51", "upload_time_iso_8601": "2020-03-23T19:06:51.394790Z", "url": "https://files.pythonhosted.org/packages/d2/92/ca9eda0517f823dde33840546badc67a6555af69e199e3e698188663408f/larq_compute_engine-0.2.0-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "15a8055cf176327f8aaaf8d027587d5f", "sha256": "70fb756ab91b1b83a348fb10abee57bc556c037d42b14b278958ec4a78cc0a2c"}, "downloads": -1, "filename": "larq_compute_engine-0.2.0-cp37-cp37m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "15a8055cf176327f8aaaf8d027587d5f", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8639076, "upload_time": "2020-03-23T19:06:52", "upload_time_iso_8601": "2020-03-23T19:06:52.906578Z", "url": "https://files.pythonhosted.org/packages/89/cc/18ee63476922e394d22294ac1245ab0277f9a3ff559aa69707734574a066/larq_compute_engine-0.2.0-cp37-cp37m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7f9ec4657fa3cc0b2b745bba42467765", "sha256": "5787f4b3228e89ff3304da340f48ab1217b88725095f4701b33aca76265b4d36"}, "downloads": -1, "filename": "larq_compute_engine-0.2.0-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "7f9ec4657fa3cc0b2b745bba42467765", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5194888, "upload_time": "2020-03-23T19:06:54", "upload_time_iso_8601": "2020-03-23T19:06:54.671784Z", "url": "https://files.pythonhosted.org/packages/a3/cf/91cb0d9536950b337a00d40cf10c6031510aa75cfca4150c0abb9ddab9e2/larq_compute_engine-0.2.0-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "b2ad6aa3a6f9dda01676a5ab3aa21dbe", "sha256": "9f6bb139028301218a064e054d064371805fe9a2edde6e6dab2bf320f911f193"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp36-cp36m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "b2ad6aa3a6f9dda01676a5ab3aa21dbe", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8639883, "upload_time": "2020-04-20T16:23:33", "upload_time_iso_8601": "2020-04-20T16:23:33.667833Z", "url": "https://files.pythonhosted.org/packages/1c/30/52efe339f487fcc41d85a853eb40e30534bb1e242fd22fc726d9d3d59598/larq_compute_engine-0.2.1-cp36-cp36m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ee810b76a020b02f98081e3dc867f6b", "sha256": "d8365b83ace52cef0925a2b7326a66131b4b0317d2d49d869164719c4060e346"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "3ee810b76a020b02f98081e3dc867f6b", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5214665, "upload_time": "2020-04-20T16:23:35", "upload_time_iso_8601": "2020-04-20T16:23:35.302786Z", "url": "https://files.pythonhosted.org/packages/e2/bd/3e9971c9f101ccf341552a91922f6598deed28b8f0b10c93f0d69d031e62/larq_compute_engine-0.2.1-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "03dd87d6ca7723c262a35ae2e73207cb", "sha256": "9d768f4eacfd4a29f8ac34455f9ca4b7b092dc3fe519d855b51dd4263d97f19d"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp37-cp37m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "03dd87d6ca7723c262a35ae2e73207cb", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8639901, "upload_time": "2020-04-20T16:23:36", "upload_time_iso_8601": "2020-04-20T16:23:36.505213Z", "url": "https://files.pythonhosted.org/packages/62/a0/7fb56699e1b9810a01a80680902460c201f750457e1542b319ab427c16c1/larq_compute_engine-0.2.1-cp37-cp37m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "435af3db6cb7ffbaf825a8e7a867911c", "sha256": "f7ff85e6915e650eb584a21ac5009c06d250a4bb672a4d59bbb3b50cc86f8c59"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "435af3db6cb7ffbaf825a8e7a867911c", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5219052, "upload_time": "2020-04-20T16:23:37", "upload_time_iso_8601": "2020-04-20T16:23:37.832685Z", "url": "https://files.pythonhosted.org/packages/0d/ba/b5551daceb4414314bcc101b23392ac21ffdd1fd80f6ed61f623bac3b856/larq_compute_engine-0.2.1-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b2ad6aa3a6f9dda01676a5ab3aa21dbe", "sha256": "9f6bb139028301218a064e054d064371805fe9a2edde6e6dab2bf320f911f193"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp36-cp36m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "b2ad6aa3a6f9dda01676a5ab3aa21dbe", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 8639883, "upload_time": "2020-04-20T16:23:33", "upload_time_iso_8601": "2020-04-20T16:23:33.667833Z", "url": "https://files.pythonhosted.org/packages/1c/30/52efe339f487fcc41d85a853eb40e30534bb1e242fd22fc726d9d3d59598/larq_compute_engine-0.2.1-cp36-cp36m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ee810b76a020b02f98081e3dc867f6b", "sha256": "d8365b83ace52cef0925a2b7326a66131b4b0317d2d49d869164719c4060e346"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp36-cp36m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "3ee810b76a020b02f98081e3dc867f6b", "packagetype": "bdist_wheel", "python_version": "cp36", "requires_python": ">=3.6", "size": 5214665, "upload_time": "2020-04-20T16:23:35", "upload_time_iso_8601": "2020-04-20T16:23:35.302786Z", "url": "https://files.pythonhosted.org/packages/e2/bd/3e9971c9f101ccf341552a91922f6598deed28b8f0b10c93f0d69d031e62/larq_compute_engine-0.2.1-cp36-cp36m-manylinux2010_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "03dd87d6ca7723c262a35ae2e73207cb", "sha256": "9d768f4eacfd4a29f8ac34455f9ca4b7b092dc3fe519d855b51dd4263d97f19d"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp37-cp37m-macosx_10_13_x86_64.whl", "has_sig": false, "md5_digest": "03dd87d6ca7723c262a35ae2e73207cb", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 8639901, "upload_time": "2020-04-20T16:23:36", "upload_time_iso_8601": "2020-04-20T16:23:36.505213Z", "url": "https://files.pythonhosted.org/packages/62/a0/7fb56699e1b9810a01a80680902460c201f750457e1542b319ab427c16c1/larq_compute_engine-0.2.1-cp37-cp37m-macosx_10_13_x86_64.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "435af3db6cb7ffbaf825a8e7a867911c", "sha256": "f7ff85e6915e650eb584a21ac5009c06d250a4bb672a4d59bbb3b50cc86f8c59"}, "downloads": -1, "filename": "larq_compute_engine-0.2.1-cp37-cp37m-manylinux2010_x86_64.whl", "has_sig": false, "md5_digest": "435af3db6cb7ffbaf825a8e7a867911c", "packagetype": "bdist_wheel", "python_version": "cp37", "requires_python": ">=3.6", "size": 5219052, "upload_time": "2020-04-20T16:23:37", "upload_time_iso_8601": "2020-04-20T16:23:37.832685Z", "url": "https://files.pythonhosted.org/packages/0d/ba/b5551daceb4414314bcc101b23392ac21ffdd1fd80f6ed61f623bac3b856/larq_compute_engine-0.2.1-cp37-cp37m-manylinux2010_x86_64.whl", "yanked": false}], "timestamp": "Fri May  8 00:47:50 2020"}