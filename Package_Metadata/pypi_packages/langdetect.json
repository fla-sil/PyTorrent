{"info": {"author": "Michal Mimino Danilak", "author_email": "michal.danilak@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "langdetect\n==========\n\n[![Build Status](https://travis-ci.org/Mimino666/langdetect.svg?branch=master)](https://travis-ci.org/Mimino666/langdetect)\n\nPort of Nakatani Shuyo's [language-detection](https://github.com/shuyo/language-detection) library (version from 03/03/2014) to Python.\n\n\nInstallation\n============\n\n    $ pip install langdetect\n\nSupported Python versions 2.7, 3.4+.\n\n\nLanguages\n=========\n\n``langdetect`` supports 55 languages out of the box ([ISO 639-1 codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)):\n\n    af, ar, bg, bn, ca, cs, cy, da, de, el, en, es, et, fa, fi, fr, gu, he,\n    hi, hr, hu, id, it, ja, kn, ko, lt, lv, mk, ml, mr, ne, nl, no, pa, pl,\n    pt, ro, ru, sk, sl, so, sq, sv, sw, ta, te, th, tl, tr, uk, ur, vi, zh-cn, zh-tw\n\n\nBasic usage\n===========\n\nTo detect the language of the text:\n\n```python\n>>> from langdetect import detect\n>>> detect(\"War doesn't show who's right, just who's left.\")\n'en'\n>>> detect(\"Ein, zwei, drei, vier\")\n'de'\n```\n\nTo find out the probabilities for the top languages:\n\n```python\n>>> from langdetect import detect_langs\n>>> detect_langs(\"Otec matka syn.\")\n[sk:0.572770823327, pl:0.292872522702, cs:0.134356653968]\n```\n\n**NOTE**\n\nLanguage detection algorithm is non-deterministic, which means that if you try to run it on a text which is either too short or too ambiguous, you might get different results everytime you run it.\n\nTo enforce consistent results, call following code before the first language detection:\n\n```python\nfrom langdetect import DetectorFactory\nDetectorFactory.seed = 0\n```\n\nHow to add new language?\n========================\n\nYou need to create a new language profile. The easiest way to do it is to use the [langdetect.jar](https://github.com/shuyo/language-detection/raw/master/lib/langdetect.jar) tool, which can generate language profiles from Wikipedia abstract database files or plain text.\n\nWikipedia abstract database files can be retrieved from \"Wikipedia Downloads\" ([http://download.wikimedia.org/](http://download.wikimedia.org/)). They form '(language code)wiki-(version)-abstract.xml' (e.g. 'enwiki-20101004-abstract.xml' ).\n\nusage: ``java -jar langdetect.jar --genprofile -d [directory path] [language codes]``\n\n- Specify the directory which has abstract databases by -d option.\n- This tool can handle gzip compressed file.\n\nRemark: The database filename in Chinese is like 'zhwiki-(version)-abstract-zh-cn.xml' or zhwiki-(version)-abstract-zh-tw.xml', so that it must be modified 'zh-cnwiki-(version)-abstract.xml' or 'zh-twwiki-(version)-abstract.xml'.\n\nTo generate language profile from a plain text, use the genprofile-text command.\n\nusage: ``java -jar langdetect.jar --genprofile-text -l [language code] [text file path]``\n\nFor more details see [language-detection Wiki](https://code.google.com/archive/p/language-detection/wikis/Tools.wiki).\n\n\nOriginal project\n================\n\nThis library is a direct port of Google's [language-detection](https://code.google.com/p/language-detection/) library from Java to Python. All the classes and methods are unchanged, so for more information see the project's website or wiki.\n\nPresentation of the language detection algorithm: [http://www.slideshare.net/shuyo/language-detection-library-for-java](http://www.slideshare.net/shuyo/language-detection-library-for-java).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Mimino666/langdetect", "keywords": "language detection library", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "langdetect", "package_url": "https://pypi.org/project/langdetect/", "platform": "", "project_url": "https://pypi.org/project/langdetect/", "project_urls": {"Homepage": "https://github.com/Mimino666/langdetect"}, "release_url": "https://pypi.org/project/langdetect/1.0.8/", "requires_dist": ["six"], "requires_python": "", "summary": "Language detection library ported from Google's language-detection.", "version": "1.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>langdetect</h1>\n<p><a href=\"https://travis-ci.org/Mimino666/langdetect\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/327c455d7095fc07ad30152eefac2dda1b1b0b04/68747470733a2f2f7472617669732d63692e6f72672f4d696d696e6f3636362f6c616e676465746563742e7376673f6272616e63683d6d6173746572\"></a></p>\n<p>Port of Nakatani Shuyo's <a href=\"https://github.com/shuyo/language-detection\" rel=\"nofollow\">language-detection</a> library (version from 03/03/2014) to Python.</p>\n<h1>Installation</h1>\n<pre><code>$ pip install langdetect\n</code></pre>\n<p>Supported Python versions 2.7, 3.4+.</p>\n<h1>Languages</h1>\n<p><code>langdetect</code> supports 55 languages out of the box (<a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\" rel=\"nofollow\">ISO 639-1 codes</a>):</p>\n<pre><code>af, ar, bg, bn, ca, cs, cy, da, de, el, en, es, et, fa, fi, fr, gu, he,\nhi, hr, hu, id, it, ja, kn, ko, lt, lv, mk, ml, mr, ne, nl, no, pa, pl,\npt, ro, ru, sk, sl, so, sq, sv, sw, ta, te, th, tl, tr, uk, ur, vi, zh-cn, zh-tw\n</code></pre>\n<h1>Basic usage</h1>\n<p>To detect the language of the text:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">langdetect</span> <span class=\"kn\">import</span> <span class=\"n\">detect</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">detect</span><span class=\"p\">(</span><span class=\"s2\">\"War doesn't show who's right, just who's left.\"</span><span class=\"p\">)</span>\n<span class=\"s1\">'en'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">detect</span><span class=\"p\">(</span><span class=\"s2\">\"Ein, zwei, drei, vier\"</span><span class=\"p\">)</span>\n<span class=\"s1\">'de'</span>\n</pre>\n<p>To find out the probabilities for the top languages:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">langdetect</span> <span class=\"kn\">import</span> <span class=\"n\">detect_langs</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">detect_langs</span><span class=\"p\">(</span><span class=\"s2\">\"Otec matka syn.\"</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"n\">sk</span><span class=\"p\">:</span><span class=\"mf\">0.572770823327</span><span class=\"p\">,</span> <span class=\"n\">pl</span><span class=\"p\">:</span><span class=\"mf\">0.292872522702</span><span class=\"p\">,</span> <span class=\"n\">cs</span><span class=\"p\">:</span><span class=\"mf\">0.134356653968</span><span class=\"p\">]</span>\n</pre>\n<p><strong>NOTE</strong></p>\n<p>Language detection algorithm is non-deterministic, which means that if you try to run it on a text which is either too short or too ambiguous, you might get different results everytime you run it.</p>\n<p>To enforce consistent results, call following code before the first language detection:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">langdetect</span> <span class=\"kn\">import</span> <span class=\"n\">DetectorFactory</span>\n<span class=\"n\">DetectorFactory</span><span class=\"o\">.</span><span class=\"n\">seed</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n</pre>\n<h1>How to add new language?</h1>\n<p>You need to create a new language profile. The easiest way to do it is to use the <a href=\"https://github.com/shuyo/language-detection/raw/master/lib/langdetect.jar\" rel=\"nofollow\">langdetect.jar</a> tool, which can generate language profiles from Wikipedia abstract database files or plain text.</p>\n<p>Wikipedia abstract database files can be retrieved from \"Wikipedia Downloads\" (<a href=\"http://download.wikimedia.org/\" rel=\"nofollow\">http://download.wikimedia.org/</a>). They form '(language code)wiki-(version)-abstract.xml' (e.g. 'enwiki-20101004-abstract.xml' ).</p>\n<p>usage: <code>java -jar langdetect.jar --genprofile -d [directory path] [language codes]</code></p>\n<ul>\n<li>Specify the directory which has abstract databases by -d option.</li>\n<li>This tool can handle gzip compressed file.</li>\n</ul>\n<p>Remark: The database filename in Chinese is like 'zhwiki-(version)-abstract-zh-cn.xml' or zhwiki-(version)-abstract-zh-tw.xml', so that it must be modified 'zh-cnwiki-(version)-abstract.xml' or 'zh-twwiki-(version)-abstract.xml'.</p>\n<p>To generate language profile from a plain text, use the genprofile-text command.</p>\n<p>usage: <code>java -jar langdetect.jar --genprofile-text -l [language code] [text file path]</code></p>\n<p>For more details see <a href=\"https://code.google.com/archive/p/language-detection/wikis/Tools.wiki\" rel=\"nofollow\">language-detection Wiki</a>.</p>\n<h1>Original project</h1>\n<p>This library is a direct port of Google's <a href=\"https://code.google.com/p/language-detection/\" rel=\"nofollow\">language-detection</a> library from Java to Python. All the classes and methods are unchanged, so for more information see the project's website or wiki.</p>\n<p>Presentation of the language detection algorithm: <a href=\"http://www.slideshare.net/shuyo/language-detection-library-for-java\" rel=\"nofollow\">http://www.slideshare.net/shuyo/language-detection-library-for-java</a>.</p>\n\n          </div>"}, "last_serial": 6754795, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "c575d3fc2ea5fc0e4f2c54a83072c1c8", "sha256": "eab4fad9472224d04dc24f9d8a31586d56c2b3b21946019875edbbe703c6f729"}, "downloads": -1, "filename": "langdetect-0.1.0.zip", "has_sig": false, "md5_digest": "c575d3fc2ea5fc0e4f2c54a83072c1c8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 924147, "upload_time": "2014-05-14T00:28:13", "upload_time_iso_8601": "2014-05-14T00:28:13.256342Z", "url": "https://files.pythonhosted.org/packages/c6/be/72922c8d0f2d37291e903149687045f83c9e1e40ba2f0295442719a6c86e/langdetect-0.1.0.zip", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "7ec701e3bbcf2d5c1fa9b29e0677430f", "sha256": "58ecd571ab003b417895cdedaba2b8de1619ec7330a5c711ec9ac281d5feaa47"}, "downloads": -1, "filename": "langdetect-1.0.0.zip", "has_sig": false, "md5_digest": "7ec701e3bbcf2d5c1fa9b29e0677430f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 934451, "upload_time": "2014-05-17T14:51:23", "upload_time_iso_8601": "2014-05-17T14:51:23.294550Z", "url": "https://files.pythonhosted.org/packages/81/5a/bdd083c0adccc7c059e56753565bf1f976ae3ebc3c5166ea3b2dbdf5c82c/langdetect-1.0.0.zip", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "e7fd2d823a734bc3edccd9cc6311f84a", "sha256": "214050b1dd7bb8faae9e056b231311abb6a53441466e964e73013f08935ffa4f"}, "downloads": -1, "filename": "langdetect-1.0.1.zip", "has_sig": false, "md5_digest": "e7fd2d823a734bc3edccd9cc6311f84a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 934465, "upload_time": "2014-05-17T18:28:46", "upload_time_iso_8601": "2014-05-17T18:28:46.467581Z", "url": "https://files.pythonhosted.org/packages/88/0a/aa345201f6639bab39c75530426a932c1405c4c6e8667e52a381e383c42f/langdetect-1.0.1.zip", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "f818569220ce5683b9e77eeeb3dc134e", "sha256": "b6486d76b072a32d10945150f1412b0f3eb3da7bff64fb153ccc741eec49edb9"}, "downloads": -1, "filename": "langdetect-1.0.2.zip", "has_sig": false, "md5_digest": "f818569220ce5683b9e77eeeb3dc134e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 934527, "upload_time": "2015-02-16T16:18:02", "upload_time_iso_8601": "2015-02-16T16:18:02.101853Z", "url": "https://files.pythonhosted.org/packages/18/b5/27d123cbeba5807b5dbeb574e4381d03a0c66025dfd999cc542031d11af6/langdetect-1.0.2.zip", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "ca85b53f06d532657d07fda0ec538372", "sha256": "8644b202f1753ea1959b9a0c148a05275c583c9e65ed95aa48edc3fc73cfab70"}, "downloads": -1, "filename": "langdetect-1.0.3.zip", "has_sig": false, "md5_digest": "ca85b53f06d532657d07fda0ec538372", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 934553, "upload_time": "2015-02-23T13:26:48", "upload_time_iso_8601": "2015-02-23T13:26:48.807300Z", "url": "https://files.pythonhosted.org/packages/5b/ad/fd349da369d4670588182eef4e48479c46bfe6c2bd05d61e44ae71ff3d74/langdetect-1.0.3.zip", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "5392b7624ed891b92d5fe55ad68b5d47", "sha256": "2e456e158ac9e917bce4539606388f08e68ba174cb12369e7acdbdf3333f9a5c"}, "downloads": -1, "filename": "langdetect-1.0.4.zip", "has_sig": false, "md5_digest": "5392b7624ed891b92d5fe55ad68b5d47", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 960964, "upload_time": "2015-03-16T14:40:25", "upload_time_iso_8601": "2015-03-16T14:40:25.736844Z", "url": "https://files.pythonhosted.org/packages/8d/32/0ceaf511f818dbd3b48eeb65e9ad61c5f645446d4f41fefebd85a0b9a4f3/langdetect-1.0.4.zip", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "61ddf98f3977ce9622ebe086220af786", "sha256": "b6eb72f4774fd735e797379b66a760c3b43d8ecad00db0695ac91bb7d20597c8"}, "downloads": -1, "filename": "langdetect-1.0.5.zip", "has_sig": false, "md5_digest": "61ddf98f3977ce9622ebe086220af786", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 993651, "upload_time": "2015-04-01T13:30:05", "upload_time_iso_8601": "2015-04-01T13:30:05.285607Z", "url": "https://files.pythonhosted.org/packages/c2/18/f01433f13d45fc873ddf51e07cb2c533e5af0c478057f634488cb1486913/langdetect-1.0.5.zip", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "4e31fbb1ba3530f2498ca81b2c1e57ab", "sha256": "0275dc679100641bc3328f5ff20d0dc6a4e1c0fac22eac36e45a27cf410a8114"}, "downloads": -1, "filename": "langdetect-1.0.6.zip", "has_sig": false, "md5_digest": "4e31fbb1ba3530f2498ca81b2c1e57ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 995813, "upload_time": "2016-04-03T18:08:02", "upload_time_iso_8601": "2016-04-03T18:08:02.251835Z", "url": "https://files.pythonhosted.org/packages/4f/ad/e6789fd51ce941e2b9cfb77503e16b447c969c148b004c2645935f20ce58/langdetect-1.0.6.zip", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "6675db2d8abccb97246372767270e912", "sha256": "91a170d5f0ade380db809b3ba67f08e95fe6c6c8641f96d67a51ff7e98a9bf30"}, "downloads": -1, "filename": "langdetect-1.0.7.zip", "has_sig": false, "md5_digest": "6675db2d8abccb97246372767270e912", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 998060, "upload_time": "2016-10-03T07:22:09", "upload_time_iso_8601": "2016-10-03T07:22:09.284234Z", "url": "https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "66253576765aec6e5dee83d1e6d62a08", "sha256": "f37495e63607865e47deed08d78f7f8e58172658216ff954b2f14671bcd87740"}, "downloads": -1, "filename": "langdetect-1.0.8-py2-none-any.whl", "has_sig": false, "md5_digest": "66253576765aec6e5dee83d1e6d62a08", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 993190, "upload_time": "2020-03-05T12:23:45", "upload_time_iso_8601": "2020-03-05T12:23:45.640746Z", "url": "https://files.pythonhosted.org/packages/85/37/bca101599caa3b915cc0735ac3bdc8a61c38b3d8b26a13c0f4d91e05bada/langdetect-1.0.8-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "930077845ed76e0ff6e47bdf85aab96e", "sha256": "363795ea005f1243c958e953245dac5d814fabdc025c9afa91588c5fa6b2fa83"}, "downloads": -1, "filename": "langdetect-1.0.8.tar.gz", "has_sig": false, "md5_digest": "930077845ed76e0ff6e47bdf85aab96e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 981459, "upload_time": "2020-03-05T12:23:47", "upload_time_iso_8601": "2020-03-05T12:23:47.711512Z", "url": "https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "66253576765aec6e5dee83d1e6d62a08", "sha256": "f37495e63607865e47deed08d78f7f8e58172658216ff954b2f14671bcd87740"}, "downloads": -1, "filename": "langdetect-1.0.8-py2-none-any.whl", "has_sig": false, "md5_digest": "66253576765aec6e5dee83d1e6d62a08", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 993190, "upload_time": "2020-03-05T12:23:45", "upload_time_iso_8601": "2020-03-05T12:23:45.640746Z", "url": "https://files.pythonhosted.org/packages/85/37/bca101599caa3b915cc0735ac3bdc8a61c38b3d8b26a13c0f4d91e05bada/langdetect-1.0.8-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "930077845ed76e0ff6e47bdf85aab96e", "sha256": "363795ea005f1243c958e953245dac5d814fabdc025c9afa91588c5fa6b2fa83"}, "downloads": -1, "filename": "langdetect-1.0.8.tar.gz", "has_sig": false, "md5_digest": "930077845ed76e0ff6e47bdf85aab96e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 981459, "upload_time": "2020-03-05T12:23:47", "upload_time_iso_8601": "2020-03-05T12:23:47.711512Z", "url": "https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:57 2020"}