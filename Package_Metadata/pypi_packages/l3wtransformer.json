{"info": {"author": "Georges Alkhouri", "author_email": "georges.alkhouri@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "l3wtransformer\n==============\n\n> A word hashing method to reduce the dimensionality of the bag-of-words term vectors. It is based on letter n-gram. Given a word (e.g. good), it first adds word starting and ending marks to the word (e.g. #good#). Then, breaks the word into letter n-grams (e.g. letter trigrams: #go, goo, ood, od#). Finally, the word is represented using a vector of letter n-grams.\n\n[Huang et al.2013, Learning Deep Structured Semantic Models for Web Search using Clickthrough Data]\n\n---\n\nThis implementation supports the transformation from **text into sequences of numbers**, with the numbers indicating the descending word frequency.\n\nFor example:\n\n*Lorem ipsum dolor sit amet, consectetuer adipiscing elit...* is transformed into *23, 1, 80, 86, 47, 50001, 21, 59, 83, 93, 14, 50003, 4, 7*\n\nAlso, after each word flags indicating lower case, upper case, mixed case or initial capitalization are added.\n\n### To do\n\nThere will be an implementation supporting the transformation from **text into bag-of-word vectors**.\n\nInstall\n-------\n\n```\npip install l3wtransformer\n```\n\nUsage\n-----\n\n```\nfrom l3wtransformer import L3wTransformer\n\nl3wt = L3wTransformer()\n\nl3wt.fit_on_texts(['First example.', 'And one more!'])\nl3wt.texts_to_sequences(['One example', '2nd exa.'])\n\n# [[5, 18, 17, 50001, 2, 10, 24, 6, 15, 20, 50003], [16, 50003, 2, 10, 50003]]\n```\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/GeorgesAlkhouri/l3wtransformer", "keywords": "machine-learning natural-language-processing preprocessing", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "l3wtransformer", "package_url": "https://pypi.org/project/l3wtransformer/", "platform": "", "project_url": "https://pypi.org/project/l3wtransformer/", "project_urls": {"Homepage": "https://github.com/GeorgesAlkhouri/l3wtransformer"}, "release_url": "https://pypi.org/project/l3wtransformer/0.3.0/", "requires_dist": ["nltk", "pathos", "numpy", "pytest"], "requires_python": "", "summary": "A word hashing method based on vectors of letter n-grams. Currently transforms text into sequences of numbers.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            l3wtransformer<br>==============<br><br>&gt; A word hashing method to reduce the dimensionality of the bag-of-words term vectors. It is based on letter n-gram. Given a word (e.g. good), it first adds word starting and ending marks to the word (e.g. #good#). Then, breaks the word into letter n-grams (e.g. letter trigrams: #go, goo, ood, od#). Finally, the word is represented using a vector of letter n-grams.<br><br>[Huang et al.2013, Learning Deep Structured Semantic Models for Web Search using Clickthrough Data]<br><br>---<br><br>This implementation supports the transformation from **text into sequences of numbers**, with the numbers indicating the descending word frequency.<br><br>For example:<br><br>*Lorem ipsum dolor sit amet, consectetuer adipiscing elit...* is transformed into *23, 1, 80, 86, 47, 50001, 21, 59, 83, 93, 14, 50003, 4, 7*<br><br>Also, after each word flags indicating lower case, upper case, mixed case or initial capitalization are added.<br><br>### To do<br><br>There will be an implementation supporting the transformation from **text into bag-of-word vectors**.<br><br>Install<br>-------<br><br>```<br>pip install l3wtransformer<br>```<br><br>Usage<br>-----<br><br>```<br>from l3wtransformer import L3wTransformer<br><br>l3wt = L3wTransformer()<br><br>l3wt.fit_on_texts(['First example.', 'And one more!'])<br>l3wt.texts_to_sequences(['One example', '2nd exa.'])<br><br># [[5, 18, 17, 50001, 2, 10, 24, 6, 15, 20, 50003], [16, 50003, 2, 10, 50003]]<br>```<br><br><br>\n          </div>"}, "last_serial": 4427592, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "c9c194de850c68eb5bd86af14102f8df", "sha256": "bb661a1c90d8f275cf34e4535d69128a0bece04e4024fd75857c8fff14956ceb"}, "downloads": -1, "filename": "l3wtransformer-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c9c194de850c68eb5bd86af14102f8df", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 5714, "upload_time": "2017-09-19T12:36:18", "upload_time_iso_8601": "2017-09-19T12:36:18.221435Z", "url": "https://files.pythonhosted.org/packages/3d/38/4a1fa7dfbb0b8d76d7067c2af0aba6b6b51f7bd4427f27a68dd1dc3e1635/l3wtransformer-0.1.0-py2.py3-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "6d5449e2a66e8c11b211851492ad199d", "sha256": "ee11f6924565edee0a1fa2f068ed529294ebd5111ab6e5bb2858ef651b5d6cc4"}, "downloads": -1, "filename": "l3wtransformer-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6d5449e2a66e8c11b211851492ad199d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4566, "upload_time": "2018-10-29T13:36:19", "upload_time_iso_8601": "2018-10-29T13:36:19.621494Z", "url": "https://files.pythonhosted.org/packages/78/c3/35f16fcc0ca32c538b4d3a255ae990272d14eb4010c06035fe527dacf66f/l3wtransformer-0.3.0-py2.py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6d5449e2a66e8c11b211851492ad199d", "sha256": "ee11f6924565edee0a1fa2f068ed529294ebd5111ab6e5bb2858ef651b5d6cc4"}, "downloads": -1, "filename": "l3wtransformer-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6d5449e2a66e8c11b211851492ad199d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 4566, "upload_time": "2018-10-29T13:36:19", "upload_time_iso_8601": "2018-10-29T13:36:19.621494Z", "url": "https://files.pythonhosted.org/packages/78/c3/35f16fcc0ca32c538b4d3a255ae990272d14eb4010c06035fe527dacf66f/l3wtransformer-0.3.0-py2.py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:48:24 2020"}