{"info": {"author": "Nikhil Kothari", "author_email": "nikhilk@twitter", "bugtrack_url": null, "classifiers": [], "description": "Introduction to TensorFX\n========================\n\nTensorFX is an end to end application framework to simplifies machine\nlearning with `TensorFlow <http://tensorflow.org>`__ - both training\nmodels and using them for prediction. It is designed from the ground up\nto make the mainline scenarios simple with higher level building blocks,\nwhile ensuring custom or complex scenarios remain possible by preserving\nthe flexibility of TensorFlow APIs.\n\nThere are some important principles that shape the design of the\nframework:\n\n1. **Simple, consistent set of usage patterns** Local or cloud, single\n   node or distributed execution, in-memory data or big data sharded\n   across files, you should have to write code once, in a single way\n   regardless of how the code executes.\n\n2. **A Toolbox with Useful Abstractions** The right entrypoint for the\n   task at hand, starting with off-the-shelf algorithms that let you\n   focus on feature engineering and hyperparam tuning. If you need to\n   solve something unqiue, you can focus on building TensorFlow graphs,\n   rather than infrastructure code (distributed cluster setup,\n   checkpointing, logging, exporting models etc.).\n\n3. **Declarative** Using YAML, JSON, and simplified Python interfaces to\n   minimize the amount of boilerplate code.\n\nOK, enough context... here is some information to get you started.\n\nGetting Started\n---------------\n\nOnce you have a Python environment (recommendation: use Miniconda),\ninstallation is straightforward:\n\n::\n\n    pip install tensorflow\n    pip install tensorfx\n\nNote that TensorFX depends on TensorFlow 1.0, and supporting libraries\nsuch as numpy and pandas.\n\nDocumentation\n-------------\n\nDocumentation is at https://tensorlab.github.io/tensorfx/. This includes\nAPI reference topics, as well as conceptual and how-to topics. They are\na work-in-progress, but check them out! There are a few samples that\ndemonstrate how to get started as well in the repository. Likewise, more\nto be added over time.\n\nContributions and Development\n-----------------------------\n\nWe welcome contributions in form of ideas, issues, samples as well as\ncode. Since the project is at a super-early stage, and evolving rapidly,\nits best to start a discussion by filing an issue for any contribution.\n\nBuilding and Testing\n~~~~~~~~~~~~~~~~~~~~\n\nIf you want to develop within the repository, clone it, and run the\nfollowing commands:\n\n::\n\n    # Install requirements and setup envionment\n    source init.sh install\n\n    # Build and Test\n    ./build.sh test\n\nRelated Links\n~~~~~~~~~~~~~\n\n-  Development workflow [TODO: Add wiki entry]\n\nHello World - Iris Classification Model\n---------------------------------------\n\nThis sample here is a quick 5-minute introduction to using TensorFX.\nHere is the code for building a feed-forward neural network\nclassification model for the `iris\ndataset <https://archive.ics.uci.edu/ml/datasets/Iris>`__.\n\n::\n\n    import tensorfx as tfx\n    import tensorfx.models.nn as nn\n\n    # Hyperparameters, training parameters, and data\n    args, job = nn.FeedForwardClassificationArguments.parse(parse_job=True)\n    dataset = tfx.data.CsvDataSet(args.data_schema,\n                                  train=args.data_train,\n                                  eval=args.data_eval,\n                                  metadata=args.data_metadata,\n                                  features=args.data_features)\n\n    # Instantiating the model builder\n    classification = nn.FeedForwardClassification(args, dataset)\n\n    # Training\n    trainer = tfx.training.ModelTrainer()\n    model = trainer.train(classification, job)\n\n    # Prediction\n    instances = [\n      '6.3,3.3,6,2.5',   # virginica\n      '4.4,3,1.3,0.2',   # setosa\n      '6.1,2.8,4.7,1.2'  # versicolor\n    ]\n    predictions = model.predict(instances)\n\nHere's an outline steps to perform for basic usage of what TensorFX\noffers:\n\n1. Parse (or build) an Arguments object, usually from the command-line\n   to define hyperparameters. This object corresponds to the kind of\n   model you are training, so, ``FeedForwardClassificationArguments`` in\n   this case.\n2. Create a DataSet to reference training and evaluation data, along\n   with supporting configuration - namely - schema, metadata, and\n   features (more on these below).\n3. Initialize the model builder - in this case\n   ``FeedForwardClassification``.\n4. Initialize the model trainer, and invoke ``train()`` which runs the\n   training process to return a model.\n5. Load some instances you want to run through the model and call\n   ``predict()``.\n\nSchema - schema.yaml\n^^^^^^^^^^^^^^^^^^^^\n\nThe schema describes the structure of your data. This can be defined\nprogrammatically, but is conveniently expressible in declarative YAML\nform, and placed alongside training data.\n\n::\n\n    fields:\n    - name: species\n      type: discrete\n    - name: petal_length\n      type: numeric\n    - name: petal_width\n      type: numeric\n    - name: sepal_length\n      type: numeric\n    - name: sepal_width\n      type: numeric\n\nMetadata - metadata.json\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nMetadata is the result of analyzing training data, based on type\ninformation in the schema. Iris is a tiny dataset, so metadata is\nreadily producable using simple python code looping over the data. For\nreal-world and large datasets, you'll find Spark and BigQuery (on Google\nCloud Platform) as essential data processing runtimes. Stay tuned -\nTensorFX will provide support for these capabilities out of the box.\n\n::\n\n    {\n      \"species\": { \"entries\": [\"setosa\", \"virginica\", \"versicolor\"] },\n      \"petal_length\": { \"min\": 4.3, \"max\": 7.9 },\n      \"petal_width\": { \"min\": 2.0, \"max\": 4.4 },\n      \"sepal_length\": { \"min\": 1.1, \"max\": 6.9 },\n      \"sepal_width\": { \"min\": 0.1, \"max\": 2.5 }\n    }\n\nFeatures - features.yaml\n^^^^^^^^^^^^^^^^^^^^^^^^\n\nLike schema, features can also be defined programmatically, or expressed\nin YAML. Features describe the set of inputs that your models operate\nover, and how they are produced by applying transformations to the\nfields in your data. These transformations are turned into TensorFlow\ngraph constructs and applied consistently to both training and\nprediction data.\n\nIn this particular example, the FeedForwardClassification model requires\ntwo features: X defining the values the model uses for producing\ninferences, and Y, the target label that the model is expected to\npredict which are defined as follows:\n\n::\n\n    features:\n    - name: X\n      type: concat\n      features:\n      - name: petal_width\n        type: scale\n      - name: petal_length\n        type: scale\n      - name: sepal_width\n        type: log\n      - name: sepal_length\n        type: log\n    - name: Y\n      type: target\n      fields: species\n\nRunning the Model\n^^^^^^^^^^^^^^^^^\n\nThe python code in the sample can be run directly, or using a ``train``\ntool, as shown:\n\n::\n\n    python -m tensorfx.tools.train \\\n      --module iris.trainer.main \\\n      --output /tmp/tensorfx/iris/csv \\\n      --data-train iris/data/train.csv \\\n      --data-eval iris/data/eval.csv \\\n      --data-schema iris/data/schema.yaml \\\n      --data-metadata iris/data/metadata.json \\\n      --data-features iris/features.yaml \\\n      --log-level-tensorflow ERROR \\\n      --log-level INFO \\\n      --batch-size 5 \\\n      --max-steps 2000 \\\n      --checkpoint-interval-secs 1 \\\n      --hidden-layers:1 20 \\\n      --hidden-layers:2 10\n\nOnce the training is complete, you can list the contents of the output\ndirectory. You should see the model (the prediction graph, and learnt\nvariables) in the ``model`` subdirectory, alongside checkpoints, and\nsummaries.\n\n::\n\n    ls -R /tmp/tensorfx/iris/csv\n    checkpoints job.yaml    model       summaries\n\n    /tmp/tensorfx/iris/csv/checkpoints:\n    checkpoint                             model.ckpt-2000.index\n    model.ckpt-1.data-00000-of-00001       model.ckpt-2000.meta\n    model.ckpt-1.index                     model.ckpt-2001.data-00000-of-00001\n    model.ckpt-1.meta                      model.ckpt-2001.index\n    model.ckpt-1562.data-00000-of-00001    model.ckpt-2001.meta\n    model.ckpt-1562.index                  model.ckpt-778.data-00000-of-00001\n    model.ckpt-1562.meta                   model.ckpt-778.index\n    model.ckpt-2000.data-00000-of-00001    model.ckpt-778.meta\n\n    /tmp/tensorfx/iris/csv/model:\n    saved_model.pb  variables\n\n    /tmp/tensorfx/iris/csv/model/variables:\n    variables.data-00000-of-00001   variables.index\n\n    /tmp/tensorfx/iris/csv/summaries:\n    eval        prediction  train\n\n    /tmp/tensorfx/iris/csv/summaries/eval:\n    events.out.tfevents.1488351760\n    events.out.tfevents.1488352853\n\n    /tmp/tensorfx/iris/csv/summaries/prediction:\n    events.out.tfevents.1488351765\n\n    /tmp/tensorfx/iris/csv/summaries/train:\n    events.out.tfevents.1488351760\n    events.out.tfevents.1488352852\n\nSummaries are TensorFlow events logged during training. They can be\nobserved while the training job is running (which is essential when\nrunning a long or real training job) to understand how your training is\nprogressing, or how the model is converging (or not!).\n\n::\n\n    tensorboard --logdir /tmp/tensorfx/iris/csv\n\nThis should bring up TensorBoard. Its useful to see the graph structure,\nmetrics and other tensors that are automatically published.\n\n**Training Graph**\n\n.. figure:: https://tensorlab.github.io/tensorfx/_static/images/intro-graph.jpg\n   :alt: Graphs in TensorBoard\n\n   Graphs in TensorBoard\n**Training Metrics -- Accuracy, Loss and Throughput**\n\n.. figure:: https://tensorlab.github.io/tensorfx/_static/images/intro-metrics.jpg\n   :alt: Metrics in TensorBoard\n\n   Metrics in TensorBoard\n**Model Variables -- Weights, Gradients, etc.**\n\n.. figure:: https://tensorlab.github.io/tensorfx/_static/images/intro-watch.jpg\n   :alt: Watchin Learnt Variables\n\n   Watchin Learnt Variables\nAs you can see, the out-of-box model takes care of a number of details.\nThe same code can be run on a single machine, or in a cluster (of\ncourse, iris is too simple of a problem to need that).\n", "description_content_type": null, "docs_url": null, "download_url": null, "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/TensorLab/tensorfx", "keywords": "TensorLab,TensorFlow,Machine Learning,Deep Learning,Google", "license": "Apache Software License", "maintainer": null, "maintainer_email": null, "name": "tensorfx", "package_url": "https://pypi.org/project/tensorfx/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/tensorfx/", "project_urls": {"Homepage": "https://github.com/TensorLab/tensorfx"}, "release_url": "https://pypi.org/project/tensorfx/0.1.3/", "requires_dist": null, "requires_python": null, "summary": "TensorFX Framework", "version": "0.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            Introduction to TensorFX<br>========================<br><br>TensorFX is an end to end application framework to simplifies machine<br>learning with `TensorFlow &lt;http://tensorflow.org&gt;`__ - both training<br>models and using them for prediction. It is designed from the ground up<br>to make the mainline scenarios simple with higher level building blocks,<br>while ensuring custom or complex scenarios remain possible by preserving<br>the flexibility of TensorFlow APIs.<br><br>There are some important principles that shape the design of the<br>framework:<br><br>1. **Simple, consistent set of usage patterns** Local or cloud, single<br>   node or distributed execution, in-memory data or big data sharded<br>   across files, you should have to write code once, in a single way<br>   regardless of how the code executes.<br><br>2. **A Toolbox with Useful Abstractions** The right entrypoint for the<br>   task at hand, starting with off-the-shelf algorithms that let you<br>   focus on feature engineering and hyperparam tuning. If you need to<br>   solve something unqiue, you can focus on building TensorFlow graphs,<br>   rather than infrastructure code (distributed cluster setup,<br>   checkpointing, logging, exporting models etc.).<br><br>3. **Declarative** Using YAML, JSON, and simplified Python interfaces to<br>   minimize the amount of boilerplate code.<br><br>OK, enough context... here is some information to get you started.<br><br>Getting Started<br>---------------<br><br>Once you have a Python environment (recommendation: use Miniconda),<br>installation is straightforward:<br><br>::<br><br>    pip install tensorflow<br>    pip install tensorfx<br><br>Note that TensorFX depends on TensorFlow 1.0, and supporting libraries<br>such as numpy and pandas.<br><br>Documentation<br>-------------<br><br>Documentation is at https://tensorlab.github.io/tensorfx/. This includes<br>API reference topics, as well as conceptual and how-to topics. They are<br>a work-in-progress, but check them out! There are a few samples that<br>demonstrate how to get started as well in the repository. Likewise, more<br>to be added over time.<br><br>Contributions and Development<br>-----------------------------<br><br>We welcome contributions in form of ideas, issues, samples as well as<br>code. Since the project is at a super-early stage, and evolving rapidly,<br>its best to start a discussion by filing an issue for any contribution.<br><br>Building and Testing<br>~~~~~~~~~~~~~~~~~~~~<br><br>If you want to develop within the repository, clone it, and run the<br>following commands:<br><br>::<br><br>    # Install requirements and setup envionment<br>    source init.sh install<br><br>    # Build and Test<br>    ./build.sh test<br><br>Related Links<br>~~~~~~~~~~~~~<br><br>-  Development workflow [TODO: Add wiki entry]<br><br>Hello World - Iris Classification Model<br>---------------------------------------<br><br>This sample here is a quick 5-minute introduction to using TensorFX.<br>Here is the code for building a feed-forward neural network<br>classification model for the `iris<br>dataset &lt;https://archive.ics.uci.edu/ml/datasets/Iris&gt;`__.<br><br>::<br><br>    import tensorfx as tfx<br>    import tensorfx.models.nn as nn<br><br>    # Hyperparameters, training parameters, and data<br>    args, job = nn.FeedForwardClassificationArguments.parse(parse_job=True)<br>    dataset = tfx.data.CsvDataSet(args.data_schema,<br>                                  train=args.data_train,<br>                                  eval=args.data_eval,<br>                                  metadata=args.data_metadata,<br>                                  features=args.data_features)<br><br>    # Instantiating the model builder<br>    classification = nn.FeedForwardClassification(args, dataset)<br><br>    # Training<br>    trainer = tfx.training.ModelTrainer()<br>    model = trainer.train(classification, job)<br><br>    # Prediction<br>    instances = [<br>      '6.3,3.3,6,2.5',   # virginica<br>      '4.4,3,1.3,0.2',   # setosa<br>      '6.1,2.8,4.7,1.2'  # versicolor<br>    ]<br>    predictions = model.predict(instances)<br><br>Here's an outline steps to perform for basic usage of what TensorFX<br>offers:<br><br>1. Parse (or build) an Arguments object, usually from the command-line<br>   to define hyperparameters. This object corresponds to the kind of<br>   model you are training, so, ``FeedForwardClassificationArguments`` in<br>   this case.<br>2. Create a DataSet to reference training and evaluation data, along<br>   with supporting configuration - namely - schema, metadata, and<br>   features (more on these below).<br>3. Initialize the model builder - in this case<br>   ``FeedForwardClassification``.<br>4. Initialize the model trainer, and invoke ``train()`` which runs the<br>   training process to return a model.<br>5. Load some instances you want to run through the model and call<br>   ``predict()``.<br><br>Schema - schema.yaml<br>^^^^^^^^^^^^^^^^^^^^<br><br>The schema describes the structure of your data. This can be defined<br>programmatically, but is conveniently expressible in declarative YAML<br>form, and placed alongside training data.<br><br>::<br><br>    fields:<br>    - name: species<br>      type: discrete<br>    - name: petal_length<br>      type: numeric<br>    - name: petal_width<br>      type: numeric<br>    - name: sepal_length<br>      type: numeric<br>    - name: sepal_width<br>      type: numeric<br><br>Metadata - metadata.json<br>^^^^^^^^^^^^^^^^^^^^^^^^<br><br>Metadata is the result of analyzing training data, based on type<br>information in the schema. Iris is a tiny dataset, so metadata is<br>readily producable using simple python code looping over the data. For<br>real-world and large datasets, you'll find Spark and BigQuery (on Google<br>Cloud Platform) as essential data processing runtimes. Stay tuned -<br>TensorFX will provide support for these capabilities out of the box.<br><br>::<br><br>    {<br>      \"species\": { \"entries\": [\"setosa\", \"virginica\", \"versicolor\"] },<br>      \"petal_length\": { \"min\": 4.3, \"max\": 7.9 },<br>      \"petal_width\": { \"min\": 2.0, \"max\": 4.4 },<br>      \"sepal_length\": { \"min\": 1.1, \"max\": 6.9 },<br>      \"sepal_width\": { \"min\": 0.1, \"max\": 2.5 }<br>    }<br><br>Features - features.yaml<br>^^^^^^^^^^^^^^^^^^^^^^^^<br><br>Like schema, features can also be defined programmatically, or expressed<br>in YAML. Features describe the set of inputs that your models operate<br>over, and how they are produced by applying transformations to the<br>fields in your data. These transformations are turned into TensorFlow<br>graph constructs and applied consistently to both training and<br>prediction data.<br><br>In this particular example, the FeedForwardClassification model requires<br>two features: X defining the values the model uses for producing<br>inferences, and Y, the target label that the model is expected to<br>predict which are defined as follows:<br><br>::<br><br>    features:<br>    - name: X<br>      type: concat<br>      features:<br>      - name: petal_width<br>        type: scale<br>      - name: petal_length<br>        type: scale<br>      - name: sepal_width<br>        type: log<br>      - name: sepal_length<br>        type: log<br>    - name: Y<br>      type: target<br>      fields: species<br><br>Running the Model<br>^^^^^^^^^^^^^^^^^<br><br>The python code in the sample can be run directly, or using a ``train``<br>tool, as shown:<br><br>::<br><br>    python -m tensorfx.tools.train \\<br>      --module iris.trainer.main \\<br>      --output /tmp/tensorfx/iris/csv \\<br>      --data-train iris/data/train.csv \\<br>      --data-eval iris/data/eval.csv \\<br>      --data-schema iris/data/schema.yaml \\<br>      --data-metadata iris/data/metadata.json \\<br>      --data-features iris/features.yaml \\<br>      --log-level-tensorflow ERROR \\<br>      --log-level INFO \\<br>      --batch-size 5 \\<br>      --max-steps 2000 \\<br>      --checkpoint-interval-secs 1 \\<br>      --hidden-layers:1 20 \\<br>      --hidden-layers:2 10<br><br>Once the training is complete, you can list the contents of the output<br>directory. You should see the model (the prediction graph, and learnt<br>variables) in the ``model`` subdirectory, alongside checkpoints, and<br>summaries.<br><br>::<br><br>    ls -R /tmp/tensorfx/iris/csv<br>    checkpoints job.yaml    model       summaries<br><br>    /tmp/tensorfx/iris/csv/checkpoints:<br>    checkpoint                             model.ckpt-2000.index<br>    model.ckpt-1.data-00000-of-00001       model.ckpt-2000.meta<br>    model.ckpt-1.index                     model.ckpt-2001.data-00000-of-00001<br>    model.ckpt-1.meta                      model.ckpt-2001.index<br>    model.ckpt-1562.data-00000-of-00001    model.ckpt-2001.meta<br>    model.ckpt-1562.index                  model.ckpt-778.data-00000-of-00001<br>    model.ckpt-1562.meta                   model.ckpt-778.index<br>    model.ckpt-2000.data-00000-of-00001    model.ckpt-778.meta<br><br>    /tmp/tensorfx/iris/csv/model:<br>    saved_model.pb  variables<br><br>    /tmp/tensorfx/iris/csv/model/variables:<br>    variables.data-00000-of-00001   variables.index<br><br>    /tmp/tensorfx/iris/csv/summaries:<br>    eval        prediction  train<br><br>    /tmp/tensorfx/iris/csv/summaries/eval:<br>    events.out.tfevents.1488351760<br>    events.out.tfevents.1488352853<br><br>    /tmp/tensorfx/iris/csv/summaries/prediction:<br>    events.out.tfevents.1488351765<br><br>    /tmp/tensorfx/iris/csv/summaries/train:<br>    events.out.tfevents.1488351760<br>    events.out.tfevents.1488352852<br><br>Summaries are TensorFlow events logged during training. They can be<br>observed while the training job is running (which is essential when<br>running a long or real training job) to understand how your training is<br>progressing, or how the model is converging (or not!).<br><br>::<br><br>    tensorboard --logdir /tmp/tensorfx/iris/csv<br><br>This should bring up TensorBoard. Its useful to see the graph structure,<br>metrics and other tensors that are automatically published.<br><br>**Training Graph**<br><br>.. figure:: https://tensorlab.github.io/tensorfx/_static/images/intro-graph.jpg<br>   :alt: Graphs in TensorBoard<br><br>   Graphs in TensorBoard<br>**Training Metrics -- Accuracy, Loss and Throughput**<br><br>.. figure:: https://tensorlab.github.io/tensorfx/_static/images/intro-metrics.jpg<br>   :alt: Metrics in TensorBoard<br><br>   Metrics in TensorBoard<br>**Model Variables -- Weights, Gradients, etc.**<br><br>.. figure:: https://tensorlab.github.io/tensorfx/_static/images/intro-watch.jpg<br>   :alt: Watchin Learnt Variables<br><br>   Watchin Learnt Variables<br>As you can see, the out-of-box model takes care of a number of details.<br>The same code can be run on a single machine, or in a cluster (of<br>course, iris is too simple of a problem to need that).<br>\n          </div>"}, "last_serial": 2691164, "releases": {"0.1.3": [{"comment_text": "", "digests": {"md5": "879fbf8fb87fef4c86e1b248f2c1783f", "sha256": "8f8114755dd678fdc839fa7a53b45a61b4872fb77752144d403903c1dd8bd459"}, "downloads": -1, "filename": "tensorfx-0.1.3.tar.gz", "has_sig": false, "md5_digest": "879fbf8fb87fef4c86e1b248f2c1783f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27780, "upload_time": "2017-03-08T10:22:48", "upload_time_iso_8601": "2017-03-08T10:22:48.488320Z", "url": "https://files.pythonhosted.org/packages/7b/af/f5e8e9e72f17e872ac583e06724ab15bfb25e0d0ad4c389d3d8b992f3f94/tensorfx-0.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "879fbf8fb87fef4c86e1b248f2c1783f", "sha256": "8f8114755dd678fdc839fa7a53b45a61b4872fb77752144d403903c1dd8bd459"}, "downloads": -1, "filename": "tensorfx-0.1.3.tar.gz", "has_sig": false, "md5_digest": "879fbf8fb87fef4c86e1b248f2c1783f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27780, "upload_time": "2017-03-08T10:22:48", "upload_time_iso_8601": "2017-03-08T10:22:48.488320Z", "url": "https://files.pythonhosted.org/packages/7b/af/f5e8e9e72f17e872ac583e06724ab15bfb25e0d0ad4c389d3d8b992f3f94/tensorfx-0.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:05 2020"}