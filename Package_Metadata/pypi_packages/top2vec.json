{"info": {"author": "Dimo Angelov", "author_email": "dimo.angelov@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Information Analysis"], "description": "[![](https://img.shields.io/pypi/v/top2vec.svg)](https://pypi.org/project/top2vec/)\n[![](https://img.shields.io/pypi/l/top2vec.svg)](https://github.com/ddangelov/Top2Vec/blob/master/LICENSE)\n[![](https://readthedocs.org/projects/top2vec/badge/?version=latest&token=0c691c6cc79b4906e35e8b7ede01e815baa05041d048945fa18e26810a3517d7)](https://top2vec.readthedocs.io/en/latest/?badge=latest)\n\nTop2Vec\n=======\n\nTopic2Vector is an algorithm for **topic modeling** and **semantic search**. It automatically detects topics present in text\nand generates jointly embedded topic, document and word vectors. Once you train the Top2Vec model \nyou can:\n* Get number of detected topics.\n* Get topics.\n* Get topic sizes. \n* Search topics by keywords.\n* Search documents by topic.\n* Search documents by keywords.\n* Find similar words.\n* Find similar documents.\n* Expose model with [restful-top2vec](https://top2vec.readthedocs.io/en/latest/restful-top2vec.html)\n\nBenefits\n--------\n1. Automatically finds number of topics.\n2. No stop words required.\n3. No need for stemming/lemmatizing.\n4. Works on short text.\n5. Creates jointly embedded topic, document, and word vectors. \n6. Has search functions built in.\n\nHow does it work?\n-----------------\n\nThe assumption the algorithm makes is that many semantically similar documents\nare indicative of an underlying topic. The first step is to create a joint embedding of \ndocument and word vectors. Once documents and words are embedded in a vector \nspace the goal of the algorithm is to find dense clusters of documents, then identify which \nwords attracted those documents together. Each dense area is a topic and the words that\nattracted the documents to the dense area are the topic words.\n\n### The Algorithm:\n\n**1. Create jointly embedded document and word vectors using [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html).**\n>Documents will be placed close to other similar documents and close to the most distinguishing words.\n\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/doc_word_embedding.svg?sanitize=true)\n\n**2. Create lower dimensional embedding of document vectors using [UMAP](https://github.com/lmcinnes/umap).**\n>Document vectors in high dimensional space are very sparse, dimension reduction helps for finding dense areas. Each point is a document vector.\n\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/umap_docs.png)\n\n**3. Find dense areas of documents using [HDBSCAN](https://github.com/scikit-learn-contrib/hdbscan).**\n>The colored areas are the dense areas of documents. Red points are outliers that do not belong to a specific cluster.\n\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/hdbscan_docs.png)\n\n**4. For each dense area calculate the centroid of document vectors in original dimension, this is the topic vector.**\n>The red points are outlier documents and do not get used for calculating the topic vector. The purple points are the document vectors that belong to a dense area, from which the topic vector is calculated. \n\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic_vector.svg?sanitize=true)\n\n**5. Find n-closest word vectors to the resulting topic vector**\n>The closest word vectors in order of proximity become the topic words. \n\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic_words.svg?sanitize=true)\n\nInstallation\n------------\n\nThe easy way to install Top2Vec is:\n\n    pip install top2vec\n\n\nUsage\n-----\n\n```python\n\nfrom top2vec import Top2Vec\n\nmodel = Top2Vec(documents)\n```\nImportant parameters:\n\n  * ``documents``: Input corpus, should be a list of strings.\n\n  * ``speed``: This parameter will determine how fast the model takes to train. \n    The 'fast-learn' option is the fastest and will generate the lowest quality\n    vectors. The 'learn' option will learn better quality vectors but take a longer\n    time to train. The 'deep-learn' option will learn the best quality vectors but \n    will take significant time to train.\n\n  * ``workers``: The amount of worker threads to be used in training the model. Larger\n    amount will lead to faster training.\n\n> Trained models can be saved and loaded.    \n```python\n\nmodel.save(\"filename\")\nmodel = Top2Vec.load(\"filename\")\n```\n\nExample\n-------\n\n### Train Model\nTrain a Top2Vec model on the 20newsgroups dataset.\n```python\n\nfrom top2vec import Top2Vec\nfrom sklearn.datasets import fetch_20newsgroups\n\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n\nmodel = Top2Vec(documents=newsgroups.data, speed=\"learn\", workers=8)\n\n```\n### Get Number of Topics\nThis will return the number of topics that Top2Vec has found in the data.\n```python\n\n>>> model.get_num_topics()\n77\n\n```\n### Get Topic Sizes\nThis will return the number of documents most similar to each topic. Topics are\nin decreasing order of size. \n```python\ntopic_sizes, topic_nums = model.get_topic_sizes()\n```\nReturns:\n\n  * ``topic_sizes``: The number of documents most similar to each topic.\n\n  * ``topic_nums``: The unique index of every topic will be returned. \n\n### Get Topics \nThis will return the topics in decreasing size.\n```python\ntopic_words, word_scores, topic_nums = model.get_topics(77)\n\n```\nReturns:\n\n  * ``topic_words``: For each topic the top 50 words are returned, in order\n    of semantic similarity to topic.\n\n  * ``word_scores``: For each topic the cosine similarity scores of the\n    top 50 words to the topic are returned.  \n\n  * ``topic_nums``: The unique index of every topic will be returned.\n\n### Search Topics\nWe are going to search for topics most similar to **medicine**. \n```python\n\ntopic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"medicine\"], num_topics=5)\n```\nReturns:\n  * ``topic_words``: For each topic the top 50 words are returned, in order\n    of semantic similarity to topic.\n\n  * ``word_scores``: For each topic the cosine similarity scores of the\n    top 50 words to the topic are returned.  \n\n  * ``topic_scores``: For each topic the cosine similarity to the search keywords will be returned.\n\n  * ``topic_nums``: The unique index of every topic will be returned.\n\n```python\n\n>>> topic_nums\n[21, 29, 9, 61, 48]\n\n>>> topic_scores\n[0.4468, 0.381, 0.2779, 0.2566, 0.2515]\n```\n> Topic 21 was the most similar topic to \"medicine\" with a cosine similarity of 0.4468. (Values can be from least similar 0, to most similar 1)\n\n### Generate Word Clouds\n\nUsing a topic number you can generate a word cloud. We are going to genenarate word clouds for the top 5 most similar topics to our **medicine** topic search from above.  \n```python\ntopic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"medicine\"], num_topics=5)\nfor topic in topic_nums:\n    model.generate_topic_wordcloud(topic)\n```\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic21.png)\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic29.png)\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic9.png)\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic61.png)\n![](https://raw.githubusercontent.com/ddangelov/Top2Vec/master/images/topic48.png)\n\n### Search Documents by Topic\n\nWe are going to search by **topic 48**, a topic that appears to be about **science**.\n```python\ndocuments, document_scores, document_ids = model.search_documents_by_topic(topic_num=48, num_docs=5)\n```\nReturns:\n  * ``documents``: The documents in a list, the most similar are first.  \n\n  * ``doc_scores``: Semantic similarity of document to topic. The cosine similarity of the\n    document and topic vector.\n\n  * ``doc_ids``: Unique ids of documents. If ids were not given, the index of document\n    in the original corpus.\n\nFor each of the returned documents we are going to print its content, score and document number.\n```python\ndocuments, document_scores, document_ids = model.search_documents_by_topic(topic_num=48, num_docs=5)\nfor doc, score, doc_id in zip(documents, document_scores, document_ids):\n    print(f\"Document: {doc_id}, Score: {score}\")\n    print(\"-----------\")\n    print(doc)\n    print(\"-----------\")\n    print()\n```\n\n\n    Document: 15227, Score: 0.6322\n    -----------\n      Evolution is both fact and theory.  The THEORY of evolution represents the\n    scientific attempt to explain the FACT of evolution.  The theory of evolution\n    does not provide facts; it explains facts.  It can be safely assumed that ALL\n    scientific theories neither provide nor become facts but rather EXPLAIN facts.\n    I recommend that you do some appropriate reading in general science.  A good\n    starting point with regard to evolution for the layman would be \"Evolution as\n    Fact and Theory\" in \"Hen's Teeth and Horse's Toes\" [pp 253-262] by Stephen Jay\n    Gould.  There is a great deal of other useful information in this publication.\n    -----------\n\n    Document: 14515, Score: 0.6186\n    -----------\n    Just what are these \"scientific facts\"?  I have never heard of such a thing.\n    Science never proves or disproves any theory - history does.\n\n    -Tim\n    -----------\n\n    Document: 9433, Score: 0.5997\n    -----------\n    The same way that any theory is proven false.  You examine the predicitions\n    that the theory makes, and try to observe them.  If you don't, or if you\n    observe things that the theory predicts wouldn't happen, then you have some \n    evidence against the theory.  If the theory can't be modified to \n    incorporate the new observations, then you say that it is false.\n\n    For example, people used to believe that the earth had been created\n    10,000 years ago.  But, as evidence showed that predictions from this \n    theory were not true, it was abandoned.\n    -----------\n\n    Document: 11917, Score: 0.5845\n    -----------\n    The point about its being real or not is that one does not waste time with\n    what reality might be when one wants predictions. The questions if the\n    atoms are there or if something else is there making measurements indicate\n    atoms is not necessary in such a system.\n\n    And one does not have to write a new theory of existence everytime new\n    models are used in Physics.\n    -----------\n\n    ...\n\n### Semantic Search Documents by Keywords\n\nSearch documents for content semantically similar to **cryptography** and **privacy**.\n```python\ndocuments, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"cryptography\", \"privacy\"], num_docs=5)\nfor doc, score, doc_id in zip(documents, document_scores, document_ids):\n    print(f\"Document: {doc_id}, Score: {score}\")\n    print(\"-----------\")\n    print(doc)\n    print(\"-----------\")\n    print()\n``` \n    Document: 16837, Score: 0.6112\n    -----------\n    ...\n    Email and account privacy, anonymity, file encryption,  academic \n    computer policies, relevant legislation and references, EFF, and \n    other privacy and rights issues associated with use of the Internet\n    and global networks in general.\n    ...\n\n    Document: 16254, Score: 0.5722\n    -----------\n    ...\n    The President today announced a new initiative that will bring\n    the Federal Government together with industry in a voluntary\n    program to improve the security and privacy of telephone\n    communications while meeting the legitimate needs of law\n    enforcement.\n    ...\n    -----------\n    ...\n\n### Similar Keywords\n\nSearch for similar words to **space**.\n```python\nwords, word_scores = model.similar_words(keywords=[\"space\"], keywords_neg=[], num_words=20)\nfor word, score in zip(words, word_scores):\n    print(f\"{word} {score}\")\n``` \n    space 1.0\n    nasa 0.6589\n    shuttle 0.5976\n    exploration 0.5448\n    planetary 0.5391\n    missions 0.5069\n    launch 0.4941\n    telescope 0.4821\n    astro 0.4696\n    jsc 0.4549\n    ames 0.4515\n    satellite 0.446\n    station 0.4445\n    orbital 0.4438\n    solar 0.4386\n    astronomy 0.4378\n    observatory 0.4355\n    facility 0.4325\n    propulsion 0.4251\n    aerospace 0.4226\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ddangelov/Top2Vec", "keywords": "topic modeling semantic search word document embedding", "license": "", "maintainer": "", "maintainer_email": "", "name": "top2vec", "package_url": "https://pypi.org/project/top2vec/", "platform": "", "project_url": "https://pypi.org/project/top2vec/", "project_urls": {"Homepage": "https://github.com/ddangelov/Top2Vec"}, "release_url": "https://pypi.org/project/top2vec/1.0.8/", "requires_dist": ["numpy", "pandas", "gensim", "pynndescent (>=0.4umap-learn)", "hdbscan", "wordcloud"], "requires_python": ">=3.6", "summary": "Topic2Vector learns jointly embedded topic, document and word vectors.", "version": "1.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://pypi.org/project/top2vec/\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c8fbed1cc6832951142c5dc6aca90374a802b56b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f746f70327665632e737667\"></a>\n<a href=\"https://github.com/ddangelov/Top2Vec/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b0e185e92d722a9abf3836edb72e434e8c3e7835/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f746f70327665632e737667\"></a>\n<a href=\"https://top2vec.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6fd80a327aa3402e497f327bf1e43610923893a0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f746f70327665632f62616467652f3f76657273696f6e3d6c617465737426746f6b656e3d30633639316336636337396234393036653335653862376564653031653831356261613035303431643034383934356661313865323638313061333531376437\"></a></p>\n<h1>Top2Vec</h1>\n<p>Topic2Vector is an algorithm for <strong>topic modeling</strong> and <strong>semantic search</strong>. It automatically detects topics present in text\nand generates jointly embedded topic, document and word vectors. Once you train the Top2Vec model\nyou can:</p>\n<ul>\n<li>Get number of detected topics.</li>\n<li>Get topics.</li>\n<li>Get topic sizes.</li>\n<li>Search topics by keywords.</li>\n<li>Search documents by topic.</li>\n<li>Search documents by keywords.</li>\n<li>Find similar words.</li>\n<li>Find similar documents.</li>\n<li>Expose model with <a href=\"https://top2vec.readthedocs.io/en/latest/restful-top2vec.html\" rel=\"nofollow\">restful-top2vec</a></li>\n</ul>\n<h2>Benefits</h2>\n<ol>\n<li>Automatically finds number of topics.</li>\n<li>No stop words required.</li>\n<li>No need for stemming/lemmatizing.</li>\n<li>Works on short text.</li>\n<li>Creates jointly embedded topic, document, and word vectors.</li>\n<li>Has search functions built in.</li>\n</ol>\n<h2>How does it work?</h2>\n<p>The assumption the algorithm makes is that many semantically similar documents\nare indicative of an underlying topic. The first step is to create a joint embedding of\ndocument and word vectors. Once documents and words are embedded in a vector\nspace the goal of the algorithm is to find dense clusters of documents, then identify which\nwords attracted those documents together. Each dense area is a topic and the words that\nattracted the documents to the dense area are the topic words.</p>\n<h3>The Algorithm:</h3>\n<p><strong>1. Create jointly embedded document and word vectors using <a href=\"https://radimrehurek.com/gensim/models/doc2vec.html\" rel=\"nofollow\">Doc2Vec</a>.</strong></p>\n<blockquote>\n<p>Documents will be placed close to other similar documents and close to the most distinguishing words.</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c010262eea9ce05d83aef6974c1beeaea4c2dc96/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f646f635f776f72645f656d62656464696e672e7376673f73616e6974697a653d74727565\"></p>\n<p><strong>2. Create lower dimensional embedding of document vectors using <a href=\"https://github.com/lmcinnes/umap\" rel=\"nofollow\">UMAP</a>.</strong></p>\n<blockquote>\n<p>Document vectors in high dimensional space are very sparse, dimension reduction helps for finding dense areas. Each point is a document vector.</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/51a9f5c83c253fa4131ae7442ea63999aa16fe3c/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f756d61705f646f63732e706e67\"></p>\n<p><strong>3. Find dense areas of documents using <a href=\"https://github.com/scikit-learn-contrib/hdbscan\" rel=\"nofollow\">HDBSCAN</a>.</strong></p>\n<blockquote>\n<p>The colored areas are the dense areas of documents. Red points are outliers that do not belong to a specific cluster.</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/41cf10e779eb1e10a8f08b849b630dc63f87a5a0/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f6864627363616e5f646f63732e706e67\"></p>\n<p><strong>4. For each dense area calculate the centroid of document vectors in original dimension, this is the topic vector.</strong></p>\n<blockquote>\n<p>The red points are outlier documents and do not get used for calculating the topic vector. The purple points are the document vectors that belong to a dense area, from which the topic vector is calculated.</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/da3a483bdc88fcb993ac9a8a34f0627d5493d7b8/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f7069635f766563746f722e7376673f73616e6974697a653d74727565\"></p>\n<p><strong>5. Find n-closest word vectors to the resulting topic vector</strong></p>\n<blockquote>\n<p>The closest word vectors in order of proximity become the topic words.</p>\n</blockquote>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c165a853193a80bf2e053b8c295acb6e991a94e8/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f7069635f776f7264732e7376673f73616e6974697a653d74727565\"></p>\n<h2>Installation</h2>\n<p>The easy way to install Top2Vec is:</p>\n<pre><code>pip install top2vec\n</code></pre>\n<h2>Usage</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">top2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Top2Vec</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Top2Vec</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">)</span>\n</pre>\n<p>Important parameters:</p>\n<ul>\n<li>\n<p><code>documents</code>: Input corpus, should be a list of strings.</p>\n</li>\n<li>\n<p><code>speed</code>: This parameter will determine how fast the model takes to train.\nThe 'fast-learn' option is the fastest and will generate the lowest quality\nvectors. The 'learn' option will learn better quality vectors but take a longer\ntime to train. The 'deep-learn' option will learn the best quality vectors but\nwill take significant time to train.</p>\n</li>\n<li>\n<p><code>workers</code>: The amount of worker threads to be used in training the model. Larger\namount will lead to faster training.</p>\n</li>\n</ul>\n<blockquote>\n<p>Trained models can be saved and loaded.</p>\n</blockquote>\n<pre><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"s2\">\"filename\"</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Top2Vec</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"filename\"</span><span class=\"p\">)</span>\n</pre>\n<h2>Example</h2>\n<h3>Train Model</h3>\n<p>Train a Top2Vec model on the 20newsgroups dataset.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">top2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Top2Vec</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">fetch_20newsgroups</span>\n\n<span class=\"n\">newsgroups</span> <span class=\"o\">=</span> <span class=\"n\">fetch_20newsgroups</span><span class=\"p\">(</span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"s1\">'all'</span><span class=\"p\">,</span> <span class=\"n\">remove</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"s1\">'headers'</span><span class=\"p\">,</span> <span class=\"s1\">'footers'</span><span class=\"p\">,</span> <span class=\"s1\">'quotes'</span><span class=\"p\">))</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Top2Vec</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"o\">=</span><span class=\"n\">newsgroups</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">speed</span><span class=\"o\">=</span><span class=\"s2\">\"learn\"</span><span class=\"p\">,</span> <span class=\"n\">workers</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">)</span>\n</pre>\n<h3>Get Number of Topics</h3>\n<p>This will return the number of topics that Top2Vec has found in the data.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_num_topics</span><span class=\"p\">()</span>\n<span class=\"mi\">77</span>\n</pre>\n<h3>Get Topic Sizes</h3>\n<p>This will return the number of documents most similar to each topic. Topics are\nin decreasing order of size.</p>\n<pre><span class=\"n\">topic_sizes</span><span class=\"p\">,</span> <span class=\"n\">topic_nums</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_topic_sizes</span><span class=\"p\">()</span>\n</pre>\n<p>Returns:</p>\n<ul>\n<li>\n<p><code>topic_sizes</code>: The number of documents most similar to each topic.</p>\n</li>\n<li>\n<p><code>topic_nums</code>: The unique index of every topic will be returned.</p>\n</li>\n</ul>\n<h3>Get Topics</h3>\n<p>This will return the topics in decreasing size.</p>\n<pre><span class=\"n\">topic_words</span><span class=\"p\">,</span> <span class=\"n\">word_scores</span><span class=\"p\">,</span> <span class=\"n\">topic_nums</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_topics</span><span class=\"p\">(</span><span class=\"mi\">77</span><span class=\"p\">)</span>\n</pre>\n<p>Returns:</p>\n<ul>\n<li>\n<p><code>topic_words</code>: For each topic the top 50 words are returned, in order\nof semantic similarity to topic.</p>\n</li>\n<li>\n<p><code>word_scores</code>: For each topic the cosine similarity scores of the\ntop 50 words to the topic are returned.</p>\n</li>\n<li>\n<p><code>topic_nums</code>: The unique index of every topic will be returned.</p>\n</li>\n</ul>\n<h3>Search Topics</h3>\n<p>We are going to search for topics most similar to <strong>medicine</strong>.</p>\n<pre><span class=\"n\">topic_words</span><span class=\"p\">,</span> <span class=\"n\">word_scores</span><span class=\"p\">,</span> <span class=\"n\">topic_scores</span><span class=\"p\">,</span> <span class=\"n\">topic_nums</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">search_topics</span><span class=\"p\">(</span><span class=\"n\">keywords</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"medicine\"</span><span class=\"p\">],</span> <span class=\"n\">num_topics</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<p>Returns:</p>\n<ul>\n<li>\n<p><code>topic_words</code>: For each topic the top 50 words are returned, in order\nof semantic similarity to topic.</p>\n</li>\n<li>\n<p><code>word_scores</code>: For each topic the cosine similarity scores of the\ntop 50 words to the topic are returned.</p>\n</li>\n<li>\n<p><code>topic_scores</code>: For each topic the cosine similarity to the search keywords will be returned.</p>\n</li>\n<li>\n<p><code>topic_nums</code>: The unique index of every topic will be returned.</p>\n</li>\n</ul>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">topic_nums</span>\n<span class=\"p\">[</span><span class=\"mi\">21</span><span class=\"p\">,</span> <span class=\"mi\">29</span><span class=\"p\">,</span> <span class=\"mi\">9</span><span class=\"p\">,</span> <span class=\"mi\">61</span><span class=\"p\">,</span> <span class=\"mi\">48</span><span class=\"p\">]</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">topic_scores</span>\n<span class=\"p\">[</span><span class=\"mf\">0.4468</span><span class=\"p\">,</span> <span class=\"mf\">0.381</span><span class=\"p\">,</span> <span class=\"mf\">0.2779</span><span class=\"p\">,</span> <span class=\"mf\">0.2566</span><span class=\"p\">,</span> <span class=\"mf\">0.2515</span><span class=\"p\">]</span>\n</pre>\n<blockquote>\n<p>Topic 21 was the most similar topic to \"medicine\" with a cosine similarity of 0.4468. (Values can be from least similar 0, to most similar 1)</p>\n</blockquote>\n<h3>Generate Word Clouds</h3>\n<p>Using a topic number you can generate a word cloud. We are going to genenarate word clouds for the top 5 most similar topics to our <strong>medicine</strong> topic search from above.</p>\n<pre><span class=\"n\">topic_words</span><span class=\"p\">,</span> <span class=\"n\">word_scores</span><span class=\"p\">,</span> <span class=\"n\">topic_scores</span><span class=\"p\">,</span> <span class=\"n\">topic_nums</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">search_topics</span><span class=\"p\">(</span><span class=\"n\">keywords</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"medicine\"</span><span class=\"p\">],</span> <span class=\"n\">num_topics</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">topic</span> <span class=\"ow\">in</span> <span class=\"n\">topic_nums</span><span class=\"p\">:</span>\n    <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">generate_topic_wordcloud</span><span class=\"p\">(</span><span class=\"n\">topic</span><span class=\"p\">)</span>\n</pre>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/642766903fb32d62f5e0923cf883db9fb9d18424/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f70696332312e706e67\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f1bf16b76a6d83201eee00986108740fe0f0cc4a/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f70696332392e706e67\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9e7183af0f5b28a83821458115c254a78178bee9/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f706963392e706e67\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d430633ba7afafd688e89869366423ab687f9ca5/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f70696336312e706e67\">\n<img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e418f8ce8845d3034d7aa9ce131de7c0b01ed9e2/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6464616e67656c6f762f546f70325665632f6d61737465722f696d616765732f746f70696334382e706e67\"></p>\n<h3>Search Documents by Topic</h3>\n<p>We are going to search by <strong>topic 48</strong>, a topic that appears to be about <strong>science</strong>.</p>\n<pre><span class=\"n\">documents</span><span class=\"p\">,</span> <span class=\"n\">document_scores</span><span class=\"p\">,</span> <span class=\"n\">document_ids</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">search_documents_by_topic</span><span class=\"p\">(</span><span class=\"n\">topic_num</span><span class=\"o\">=</span><span class=\"mi\">48</span><span class=\"p\">,</span> <span class=\"n\">num_docs</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<p>Returns:</p>\n<ul>\n<li>\n<p><code>documents</code>: The documents in a list, the most similar are first.</p>\n</li>\n<li>\n<p><code>doc_scores</code>: Semantic similarity of document to topic. The cosine similarity of the\ndocument and topic vector.</p>\n</li>\n<li>\n<p><code>doc_ids</code>: Unique ids of documents. If ids were not given, the index of document\nin the original corpus.</p>\n</li>\n</ul>\n<p>For each of the returned documents we are going to print its content, score and document number.</p>\n<pre><span class=\"n\">documents</span><span class=\"p\">,</span> <span class=\"n\">document_scores</span><span class=\"p\">,</span> <span class=\"n\">document_ids</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">search_documents_by_topic</span><span class=\"p\">(</span><span class=\"n\">topic_num</span><span class=\"o\">=</span><span class=\"mi\">48</span><span class=\"p\">,</span> <span class=\"n\">num_docs</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"n\">score</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">,</span> <span class=\"n\">document_scores</span><span class=\"p\">,</span> <span class=\"n\">document_ids</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Document: </span><span class=\"si\">{</span><span class=\"n\">doc_id</span><span class=\"si\">}</span><span class=\"s2\">, Score: </span><span class=\"si\">{</span><span class=\"n\">score</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"-----------\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"-----------\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">()</span>\n</pre>\n<pre><code>Document: 15227, Score: 0.6322\n-----------\n  Evolution is both fact and theory.  The THEORY of evolution represents the\nscientific attempt to explain the FACT of evolution.  The theory of evolution\ndoes not provide facts; it explains facts.  It can be safely assumed that ALL\nscientific theories neither provide nor become facts but rather EXPLAIN facts.\nI recommend that you do some appropriate reading in general science.  A good\nstarting point with regard to evolution for the layman would be \"Evolution as\nFact and Theory\" in \"Hen's Teeth and Horse's Toes\" [pp 253-262] by Stephen Jay\nGould.  There is a great deal of other useful information in this publication.\n-----------\n\nDocument: 14515, Score: 0.6186\n-----------\nJust what are these \"scientific facts\"?  I have never heard of such a thing.\nScience never proves or disproves any theory - history does.\n\n-Tim\n-----------\n\nDocument: 9433, Score: 0.5997\n-----------\nThe same way that any theory is proven false.  You examine the predicitions\nthat the theory makes, and try to observe them.  If you don't, or if you\nobserve things that the theory predicts wouldn't happen, then you have some \nevidence against the theory.  If the theory can't be modified to \nincorporate the new observations, then you say that it is false.\n\nFor example, people used to believe that the earth had been created\n10,000 years ago.  But, as evidence showed that predictions from this \ntheory were not true, it was abandoned.\n-----------\n\nDocument: 11917, Score: 0.5845\n-----------\nThe point about its being real or not is that one does not waste time with\nwhat reality might be when one wants predictions. The questions if the\natoms are there or if something else is there making measurements indicate\natoms is not necessary in such a system.\n\nAnd one does not have to write a new theory of existence everytime new\nmodels are used in Physics.\n-----------\n\n...\n</code></pre>\n<h3>Semantic Search Documents by Keywords</h3>\n<p>Search documents for content semantically similar to <strong>cryptography</strong> and <strong>privacy</strong>.</p>\n<pre><span class=\"n\">documents</span><span class=\"p\">,</span> <span class=\"n\">document_scores</span><span class=\"p\">,</span> <span class=\"n\">document_ids</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">search_documents_by_keywords</span><span class=\"p\">(</span><span class=\"n\">keywords</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"cryptography\"</span><span class=\"p\">,</span> <span class=\"s2\">\"privacy\"</span><span class=\"p\">],</span> <span class=\"n\">num_docs</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">doc</span><span class=\"p\">,</span> <span class=\"n\">score</span><span class=\"p\">,</span> <span class=\"n\">doc_id</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">,</span> <span class=\"n\">document_scores</span><span class=\"p\">,</span> <span class=\"n\">document_ids</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Document: </span><span class=\"si\">{</span><span class=\"n\">doc_id</span><span class=\"si\">}</span><span class=\"s2\">, Score: </span><span class=\"si\">{</span><span class=\"n\">score</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"-----------\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"-----------\"</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">()</span>\n</pre>\n<pre><code>Document: 16837, Score: 0.6112\n-----------\n...\nEmail and account privacy, anonymity, file encryption,  academic \ncomputer policies, relevant legislation and references, EFF, and \nother privacy and rights issues associated with use of the Internet\nand global networks in general.\n...\n\nDocument: 16254, Score: 0.5722\n-----------\n...\nThe President today announced a new initiative that will bring\nthe Federal Government together with industry in a voluntary\nprogram to improve the security and privacy of telephone\ncommunications while meeting the legitimate needs of law\nenforcement.\n...\n-----------\n...\n</code></pre>\n<h3>Similar Keywords</h3>\n<p>Search for similar words to <strong>space</strong>.</p>\n<pre><span class=\"n\">words</span><span class=\"p\">,</span> <span class=\"n\">word_scores</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">similar_words</span><span class=\"p\">(</span><span class=\"n\">keywords</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"space\"</span><span class=\"p\">],</span> <span class=\"n\">keywords_neg</span><span class=\"o\">=</span><span class=\"p\">[],</span> <span class=\"n\">num_words</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">word</span><span class=\"p\">,</span> <span class=\"n\">score</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">words</span><span class=\"p\">,</span> <span class=\"n\">word_scores</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">word</span><span class=\"si\">}</span><span class=\"s2\"> </span><span class=\"si\">{</span><span class=\"n\">score</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre>\n<pre><code>space 1.0\nnasa 0.6589\nshuttle 0.5976\nexploration 0.5448\nplanetary 0.5391\nmissions 0.5069\nlaunch 0.4941\ntelescope 0.4821\nastro 0.4696\njsc 0.4549\names 0.4515\nsatellite 0.446\nstation 0.4445\norbital 0.4438\nsolar 0.4386\nastronomy 0.4378\nobservatory 0.4355\nfacility 0.4325\npropulsion 0.4251\naerospace 0.4226\n</code></pre>\n\n          </div>"}, "last_serial": 7048445, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "a4959c9cd574a0e09d91704a5252b5ea", "sha256": "c61bd1f4d82bb0518c54a0e8683aadc697a2a24a577e90b2ed1feb871108c055"}, "downloads": -1, "filename": "top2vec-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "a4959c9cd574a0e09d91704a5252b5ea", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 6095, "upload_time": "2020-03-22T21:51:20", "upload_time_iso_8601": "2020-03-22T21:51:20.061043Z", "url": "https://files.pythonhosted.org/packages/96/87/a5d76bfc3b3d26e8b231c01baf017431fd55213659b2182ebde2bb82a189/top2vec-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2160a90efa2f9783fb1cd8e4ea96a337", "sha256": "5aa1fac81682c9d36911036aa3ed272316283dd870f3ca4e1ada5d644bff096b"}, "downloads": -1, "filename": "top2vec-1.0.0.tar.gz", "has_sig": false, "md5_digest": "2160a90efa2f9783fb1cd8e4ea96a337", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 5090, "upload_time": "2020-03-22T21:51:21", "upload_time_iso_8601": "2020-03-22T21:51:21.601998Z", "url": "https://files.pythonhosted.org/packages/ee/46/3c2e4831779c8c5bed10baa2bc41d6d5bd62b12077c09faf825eace82013/top2vec-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "3310507e49fad4f52f48835e23b529dd", "sha256": "4ebe563b02eeb0b8b3379e5b9c04b5868829a00bb8fded74cd7b64739ab8c703"}, "downloads": -1, "filename": "top2vec-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "3310507e49fad4f52f48835e23b529dd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 6118, "upload_time": "2020-03-22T22:36:02", "upload_time_iso_8601": "2020-03-22T22:36:02.021032Z", "url": "https://files.pythonhosted.org/packages/e3/11/56141f58fb80ac203104a66041dfd3b33325debdca7a12f9ccd1a8c59057/top2vec-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d651b750422868b16b79eb3f8cb884a", "sha256": "380b726493b12d5ba7277ae988412a91cf2959ec4ad3bf0a2a8bf725cb174311"}, "downloads": -1, "filename": "top2vec-1.0.1.tar.gz", "has_sig": false, "md5_digest": "3d651b750422868b16b79eb3f8cb884a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 5087, "upload_time": "2020-03-22T22:36:03", "upload_time_iso_8601": "2020-03-22T22:36:03.536617Z", "url": "https://files.pythonhosted.org/packages/6a/c1/a276d0b2e83b18b1c53ff3d8a602ba328d4c3f16095e41fb1d2f3d87375d/top2vec-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "89b02da9fd8dd6c84f7873a9dbe320b3", "sha256": "392eade69f3a72843eb2872aa7d2eb07e24420b73fcc905782be5f49c9a2de13"}, "downloads": -1, "filename": "top2vec-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "89b02da9fd8dd6c84f7873a9dbe320b3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7399, "upload_time": "2020-03-23T22:00:24", "upload_time_iso_8601": "2020-03-23T22:00:24.905204Z", "url": "https://files.pythonhosted.org/packages/ed/d2/68c93c2668934b9693af657165a8aec2ac9ea756f3d40b6b4ddff227dd80/top2vec-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dde7f14fc8128437c3b67c963cee7329", "sha256": "05ab289d4572c78bc7a269ebf46e90c2102fc6a5f304bc718023c237b56edad1"}, "downloads": -1, "filename": "top2vec-1.0.2.tar.gz", "has_sig": false, "md5_digest": "dde7f14fc8128437c3b67c963cee7329", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7534, "upload_time": "2020-03-23T22:00:26", "upload_time_iso_8601": "2020-03-23T22:00:26.047676Z", "url": "https://files.pythonhosted.org/packages/b2/ad/928c4ae1aded1f764c45f66a9fc2200c932390b1e8b4c8f4eeb21bea059f/top2vec-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "33df975d0a2aa8fcd7732f261d13ffc2", "sha256": "4603679c04c33e8a5ab582d4cbf234907d3648a94761836b911f4060f0cf41f9"}, "downloads": -1, "filename": "top2vec-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "33df975d0a2aa8fcd7732f261d13ffc2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7418, "upload_time": "2020-03-23T22:11:17", "upload_time_iso_8601": "2020-03-23T22:11:17.333419Z", "url": "https://files.pythonhosted.org/packages/b9/9e/c4dafd6a166933a242f9f16eb1640fa44ec8ba59ff0a8d1e8378ea8a74a8/top2vec-1.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8239999c5781d8ea9ae05ff27652276d", "sha256": "d8353780633bd300a0f656e7e760c4c4309decb6986d3cdc0f6a89f6cf41bcd9"}, "downloads": -1, "filename": "top2vec-1.0.3.tar.gz", "has_sig": false, "md5_digest": "8239999c5781d8ea9ae05ff27652276d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7559, "upload_time": "2020-03-23T22:11:18", "upload_time_iso_8601": "2020-03-23T22:11:18.969486Z", "url": "https://files.pythonhosted.org/packages/94/ec/321ecabd5231cdc2a52d1f0865f99a6c3afe8deca2ca05a30798ff6fb601/top2vec-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "032bd62f289361e5115c879bd5ab6a61", "sha256": "b9237f83e460101336d1ca80f81ebeb6f8d06d935efb4c07348246fe5473b8c1"}, "downloads": -1, "filename": "top2vec-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "032bd62f289361e5115c879bd5ab6a61", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7441, "upload_time": "2020-03-23T22:33:22", "upload_time_iso_8601": "2020-03-23T22:33:22.788778Z", "url": "https://files.pythonhosted.org/packages/7e/cf/ad9f74b402175a13d0d86c90aa56cae8a0bc70dafdba9d931f071f2bff13/top2vec-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c85a41ac84a068c299d86b6ee334dc43", "sha256": "3cec50429a14a296d9c4a5f5523e0f7dba96e2cb2a7ca3f42853d95b80f42dcd"}, "downloads": -1, "filename": "top2vec-1.0.4.tar.gz", "has_sig": false, "md5_digest": "c85a41ac84a068c299d86b6ee334dc43", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7598, "upload_time": "2020-03-23T22:33:24", "upload_time_iso_8601": "2020-03-23T22:33:24.270275Z", "url": "https://files.pythonhosted.org/packages/37/bf/f1632883ea08086e7af4ba7ef23ea350097ae50d027854a74c76c3ef778b/top2vec-1.0.4.tar.gz", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "563f5a8f4680d6ea051b44a564c2baf9", "sha256": "ad52ba2b7ecf8c40226d4ce8d8ed6dfebae7580aa541c01f76091fbeb9b48de9"}, "downloads": -1, "filename": "top2vec-1.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "563f5a8f4680d6ea051b44a564c2baf9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7440, "upload_time": "2020-03-23T22:37:27", "upload_time_iso_8601": "2020-03-23T22:37:27.936643Z", "url": "https://files.pythonhosted.org/packages/28/41/ea471a4f97b30d1c429924f43560c59d760cf48211f8a4a89e9e856cb1ab/top2vec-1.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "459c137ae3b3109ada340531c2297c2f", "sha256": "9d180c07d07c6261eb813725db133bf9d971023a88512a1bde9414860a3c6a2b"}, "downloads": -1, "filename": "top2vec-1.0.5.tar.gz", "has_sig": false, "md5_digest": "459c137ae3b3109ada340531c2297c2f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7598, "upload_time": "2020-03-23T22:37:29", "upload_time_iso_8601": "2020-03-23T22:37:29.423831Z", "url": "https://files.pythonhosted.org/packages/c7/b7/1fc4cf58b8777d2d8c218edc5642b4713381bb8952a0d6f135d5069fbc30/top2vec-1.0.5.tar.gz", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "637b6557568d9ec06bc49869736c54a9", "sha256": "1298391b78e452eef0aa41371116d711e3954f9270c0250a4707b5b69a26276d"}, "downloads": -1, "filename": "top2vec-1.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "637b6557568d9ec06bc49869736c54a9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10726, "upload_time": "2020-03-24T22:22:33", "upload_time_iso_8601": "2020-03-24T22:22:33.497181Z", "url": "https://files.pythonhosted.org/packages/09/4c/bca7ef6d39ecc56a1ad205f273131f7faf873d9481c4aaa94eb8ea30cf15/top2vec-1.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "baf7509146e021bb8ad4f61d808360d7", "sha256": "246b33db256de155309aa59e1f95591488e9b2ac18e1ae06cc4620b851e2f11c"}, "downloads": -1, "filename": "top2vec-1.0.6.tar.gz", "has_sig": false, "md5_digest": "baf7509146e021bb8ad4f61d808360d7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 13875, "upload_time": "2020-03-24T22:22:34", "upload_time_iso_8601": "2020-03-24T22:22:34.946785Z", "url": "https://files.pythonhosted.org/packages/4c/0d/4d1cfd15e82d63738ce3d233afac79a5d0353f137457ea2c00caabd5546d/top2vec-1.0.6.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "a0841f8655adfcdbb69a6b32b024e850", "sha256": "49ded65bd50bd02091f8315d926c6776109c6c52bbaa04e78f87791e9f6dce16"}, "downloads": -1, "filename": "top2vec-1.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "a0841f8655adfcdbb69a6b32b024e850", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 11442, "upload_time": "2020-04-07T20:04:11", "upload_time_iso_8601": "2020-04-07T20:04:11.285975Z", "url": "https://files.pythonhosted.org/packages/a6/43/698bf341a061722a1191250d16fce1e91e103a79514b0da8c4d911af9508/top2vec-1.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "98443736d3174a0477be1d042b17a558", "sha256": "65fc3ae7483a34350376455c38c798ed540ab618ef5c90beca1e2f4a697bf30c"}, "downloads": -1, "filename": "top2vec-1.0.7.tar.gz", "has_sig": false, "md5_digest": "98443736d3174a0477be1d042b17a558", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 14845, "upload_time": "2020-04-07T20:04:12", "upload_time_iso_8601": "2020-04-07T20:04:12.773857Z", "url": "https://files.pythonhosted.org/packages/79/9b/e671d749c48f950ab704fba4d4e5d1b634727085f5a20ab87c0a0e3f83bb/top2vec-1.0.7.tar.gz", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "fb56a61a60fdb98c47d2acedac7ea80a", "sha256": "7d74fe17576908b0573f94051e584303fc589f13bd9122812e8db602fccaea3c"}, "downloads": -1, "filename": "top2vec-1.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "fb56a61a60fdb98c47d2acedac7ea80a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 12693, "upload_time": "2020-04-18T14:55:49", "upload_time_iso_8601": "2020-04-18T14:55:49.342747Z", "url": "https://files.pythonhosted.org/packages/6e/61/bc0890f0d05a2205e96e31b357af276ecc7e811ad225aaa34610839c8cc1/top2vec-1.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7bace4282a4d345e3a2e91b2cdad79b0", "sha256": "30a5c1187ea4afbf4597866c79af45da9a70104bf8927f7bb4ac19d954f86b77"}, "downloads": -1, "filename": "top2vec-1.0.8.tar.gz", "has_sig": false, "md5_digest": "7bace4282a4d345e3a2e91b2cdad79b0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 16339, "upload_time": "2020-04-18T14:55:50", "upload_time_iso_8601": "2020-04-18T14:55:50.490016Z", "url": "https://files.pythonhosted.org/packages/b2/93/e3f1a02a052939258feb5d6207c842f21df18e90f716270741f5d29fd0b7/top2vec-1.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fb56a61a60fdb98c47d2acedac7ea80a", "sha256": "7d74fe17576908b0573f94051e584303fc589f13bd9122812e8db602fccaea3c"}, "downloads": -1, "filename": "top2vec-1.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "fb56a61a60fdb98c47d2acedac7ea80a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 12693, "upload_time": "2020-04-18T14:55:49", "upload_time_iso_8601": "2020-04-18T14:55:49.342747Z", "url": "https://files.pythonhosted.org/packages/6e/61/bc0890f0d05a2205e96e31b357af276ecc7e811ad225aaa34610839c8cc1/top2vec-1.0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7bace4282a4d345e3a2e91b2cdad79b0", "sha256": "30a5c1187ea4afbf4597866c79af45da9a70104bf8927f7bb4ac19d954f86b77"}, "downloads": -1, "filename": "top2vec-1.0.8.tar.gz", "has_sig": false, "md5_digest": "7bace4282a4d345e3a2e91b2cdad79b0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 16339, "upload_time": "2020-04-18T14:55:50", "upload_time_iso_8601": "2020-04-18T14:55:50.490016Z", "url": "https://files.pythonhosted.org/packages/b2/93/e3f1a02a052939258feb5d6207c842f21df18e90f716270741f5d29fd0b7/top2vec-1.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:58 2020"}