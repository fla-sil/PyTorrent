{"info": {"author": "Max Goodridge", "author_email": "max.goodridge@hotmail.co.uk", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Workflows\nWorkflows are a cleaner way of implementing DAGs using a Django-inspired class-based syntax.\n\n## Simple Example\nLet's create a single Airflow DAG, whose name is a camelcased version of the class name, and whose operator dependencies are in the order they are defined.\n\nThere is an option to override the default [`dependencies`](https://github.com/maxg203/airflow-workflows/blob/master/workflows.py#L165) method implementation to customise the dependency chain for your use case.\n\n```python\nimport workflows\n\n\nclass ExampleWorkflow(workflows.Workflow):\n    class Meta:\n        schedule_interval = '0 9 * * *'\n\n    do_something_useful = workflows.PythonOperator(\n        python_callable=lambda **kwargs: print('something useful'),\n    )\n    something_else = workflows.PythonOperator(\n        python_callable=lambda **kwargs: print('Something not useful'),\n    )\n\n\nglobals()[ExampleWorkflow.DAG.dag_id] = ExampleWorkflow.DAG\n```\n\n\n## Dynamic DAG Example\nLet's create (in this case three) DAGs, created dynamically and based on the `ExampleWorkflow` class as implemented above. In other words, they will share the same DAG metadata (so schedule in this case).\n\n```python\nimport workflows\n\nworkflow_names = [\n    'Test1',\n    'Test2',\n    'Test3',\n]\n\nfor workflow in workflow_names:\n    WorkflowClass = workflows.create_workflow(\n        workflow,\n        base=ExampleWorkflow,\n    )\n    globals()[WorkflowClass.DAG.dag_id] = WorkflowClass.DAG\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/maxg203/airflow-workflows/archive/0.1.4.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/maxg203/airflow-workflows", "keywords": "airflow,DAG,workflows,ETL", "license": "apache-2.0", "maintainer": "", "maintainer_email": "", "name": "airflow-workflows", "package_url": "https://pypi.org/project/airflow-workflows/", "platform": "", "project_url": "https://pypi.org/project/airflow-workflows/", "project_urls": {"Download": "https://github.com/maxg203/airflow-workflows/archive/0.1.4.tar.gz", "Homepage": "https://github.com/maxg203/airflow-workflows"}, "release_url": "https://pypi.org/project/airflow-workflows/0.1.4/", "requires_dist": null, "requires_python": "", "summary": "Provides a powerful, Django-inspired class-based DAG syntax for Apache Airflow.", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Workflows</h1>\n<p>Workflows are a cleaner way of implementing DAGs using a Django-inspired class-based syntax.</p>\n<h2>Simple Example</h2>\n<p>Let's create a single Airflow DAG, whose name is a camelcased version of the class name, and whose operator dependencies are in the order they are defined.</p>\n<p>There is an option to override the default <a href=\"https://github.com/maxg203/airflow-workflows/blob/master/workflows.py#L165\" rel=\"nofollow\"><code>dependencies</code></a> method implementation to customise the dependency chain for your use case.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">workflows</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">ExampleWorkflow</span><span class=\"p\">(</span><span class=\"n\">workflows</span><span class=\"o\">.</span><span class=\"n\">Workflow</span><span class=\"p\">):</span>\n    <span class=\"k\">class</span> <span class=\"nc\">Meta</span><span class=\"p\">:</span>\n        <span class=\"n\">schedule_interval</span> <span class=\"o\">=</span> <span class=\"s1\">'0 9 * * *'</span>\n\n    <span class=\"n\">do_something_useful</span> <span class=\"o\">=</span> <span class=\"n\">workflows</span><span class=\"o\">.</span><span class=\"n\">PythonOperator</span><span class=\"p\">(</span>\n        <span class=\"n\">python_callable</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'something useful'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n    <span class=\"n\">something_else</span> <span class=\"o\">=</span> <span class=\"n\">workflows</span><span class=\"o\">.</span><span class=\"n\">PythonOperator</span><span class=\"p\">(</span>\n        <span class=\"n\">python_callable</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">:</span> <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Something not useful'</span><span class=\"p\">),</span>\n    <span class=\"p\">)</span>\n\n\n<span class=\"nb\">globals</span><span class=\"p\">()[</span><span class=\"n\">ExampleWorkflow</span><span class=\"o\">.</span><span class=\"n\">DAG</span><span class=\"o\">.</span><span class=\"n\">dag_id</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">ExampleWorkflow</span><span class=\"o\">.</span><span class=\"n\">DAG</span>\n</pre>\n<h2>Dynamic DAG Example</h2>\n<p>Let's create (in this case three) DAGs, created dynamically and based on the <code>ExampleWorkflow</code> class as implemented above. In other words, they will share the same DAG metadata (so schedule in this case).</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">workflows</span>\n\n<span class=\"n\">workflow_names</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"s1\">'Test1'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'Test2'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'Test3'</span><span class=\"p\">,</span>\n<span class=\"p\">]</span>\n\n<span class=\"k\">for</span> <span class=\"n\">workflow</span> <span class=\"ow\">in</span> <span class=\"n\">workflow_names</span><span class=\"p\">:</span>\n    <span class=\"n\">WorkflowClass</span> <span class=\"o\">=</span> <span class=\"n\">workflows</span><span class=\"o\">.</span><span class=\"n\">create_workflow</span><span class=\"p\">(</span>\n        <span class=\"n\">workflow</span><span class=\"p\">,</span>\n        <span class=\"n\">base</span><span class=\"o\">=</span><span class=\"n\">ExampleWorkflow</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n    <span class=\"nb\">globals</span><span class=\"p\">()[</span><span class=\"n\">WorkflowClass</span><span class=\"o\">.</span><span class=\"n\">DAG</span><span class=\"o\">.</span><span class=\"n\">dag_id</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">WorkflowClass</span><span class=\"o\">.</span><span class=\"n\">DAG</span>\n</pre>\n\n          </div>"}, "last_serial": 5326949, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "721561e2fcaa98c10a6a09556ce51da9", "sha256": "14beddaac9404abd6f6075ed733a609635209b78ee03ce617f619f946e164f41"}, "downloads": -1, "filename": "airflow-workflows-0.1.0.tar.gz", "has_sig": false, "md5_digest": "721561e2fcaa98c10a6a09556ce51da9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4401, "upload_time": "2019-05-22T12:36:04", "upload_time_iso_8601": "2019-05-22T12:36:04.288283Z", "url": "https://files.pythonhosted.org/packages/7c/e7/7bf5813d51bc743cb99b1b22bf76cc4f75a9df97c53de1532e4922e280ca/airflow-workflows-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "6b4e24f3e4ad3a574cc83f8a8e3896de", "sha256": "3533ae4a2fab4a7e12e14a77019782239e88aaf913cb9c07c6f3f6d91f333e99"}, "downloads": -1, "filename": "airflow-workflows-0.1.1.tar.gz", "has_sig": false, "md5_digest": "6b4e24f3e4ad3a574cc83f8a8e3896de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4429, "upload_time": "2019-05-22T14:23:30", "upload_time_iso_8601": "2019-05-22T14:23:30.708398Z", "url": "https://files.pythonhosted.org/packages/18/26/f9a537b400983632c77a8274e8eb1242a6e4f294050f758e0dc9c973075f/airflow-workflows-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "fc3a7e766df3b903a8128a37b600cff7", "sha256": "47b03b8e5575721d457e9ab6be0bf77041c8922bce784e48467f90da028e8aa8"}, "downloads": -1, "filename": "airflow-workflows-0.1.2.tar.gz", "has_sig": false, "md5_digest": "fc3a7e766df3b903a8128a37b600cff7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4429, "upload_time": "2019-05-23T14:10:41", "upload_time_iso_8601": "2019-05-23T14:10:41.567429Z", "url": "https://files.pythonhosted.org/packages/ec/77/df4197a514377a99d64a37ed0b20a942e0b05e32f289044c98471e84672c/airflow-workflows-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "76ea76672b3f635f50ebf07f5ab5e849", "sha256": "6e3decf0129616e415fd8fe50cf56066f9814dd81a320f67b618e5e5f6e87a4b"}, "downloads": -1, "filename": "airflow-workflows-0.1.3.tar.gz", "has_sig": false, "md5_digest": "76ea76672b3f635f50ebf07f5ab5e849", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5707, "upload_time": "2019-05-28T11:47:50", "upload_time_iso_8601": "2019-05-28T11:47:50.714785Z", "url": "https://files.pythonhosted.org/packages/58/15/74d9a8ac7d31edbcb3b407870a273e36ec55e48e0fa3e0ec7654b8881e07/airflow-workflows-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "98be40213eb7cd82569b440fa8d38049", "sha256": "f6810b8c298397e3328355e17c2b0b46eddfcea868a7a1591078025620a99816"}, "downloads": -1, "filename": "airflow-workflows-0.1.4.tar.gz", "has_sig": false, "md5_digest": "98be40213eb7cd82569b440fa8d38049", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3597, "upload_time": "2019-05-28T14:11:36", "upload_time_iso_8601": "2019-05-28T14:11:36.750787Z", "url": "https://files.pythonhosted.org/packages/0b/72/2df75f19eb1fb9d8333deb58994829d483b8476e049533867dccf72872a2/airflow-workflows-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "98be40213eb7cd82569b440fa8d38049", "sha256": "f6810b8c298397e3328355e17c2b0b46eddfcea868a7a1591078025620a99816"}, "downloads": -1, "filename": "airflow-workflows-0.1.4.tar.gz", "has_sig": false, "md5_digest": "98be40213eb7cd82569b440fa8d38049", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3597, "upload_time": "2019-05-28T14:11:36", "upload_time_iso_8601": "2019-05-28T14:11:36.750787Z", "url": "https://files.pythonhosted.org/packages/0b/72/2df75f19eb1fb9d8333deb58994829d483b8476e049533867dccf72872a2/airflow-workflows-0.1.4.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:20:29 2020"}