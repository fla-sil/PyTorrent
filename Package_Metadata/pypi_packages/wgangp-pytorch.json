{"info": {"author": "Liu Changyu", "author_email": "liuchangyu1111@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7"], "description": "\n# WassersteinGAN_GP-PyTorch\n\n### Update (Feb 21, 2020)\n\nThe mnist and fmnist models are now available. Their usage is identical to the other models: \n```python\nfrom wgangp_pytorch import Generator\nmodel = Generator.from_pretrained('g-mnist') \n```\n\n### Overview\nThis repository contains an op-for-op PyTorch reimplementation of [Improved Training of Wasserstein GANs](http://xxx.itp.ac.cn/pdf/1704.00028).\n\nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.  \n\nAt the moment, you can easily:  \n * Load pretrained Generate models \n * Use Generate models for extended dataset\n\n_Upcoming features_: In the next few days, you will be able to:\n * Quickly finetune an Generate on your own dataset\n * Export Generate models for production\n\n### Table of contents\n1. [About Wasserstein GAN GP](#about-wasserstein-gan-gp)\n2. [Model Description](#model-description)\n3. [Installation](#installation)\n4. [Usage](#usage)\n    * [Load pretrained models](#loading-pretrained-models)\n    * [Example: Extended dataset](#example-extended-dataset)\n    * [Example: Visual](#example-visual)\n5. [Contributing](#contributing) \n\n### About Wasserstein GAN GP\n\nIf you're new to Wasserstein GAN GP, here's an abstract straight from the paper:\n\nGenerative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.\n\n### Model Description\n\nWe have two networks, G (Generator) and D (Discriminator).The Generator is a network for generating images. It receives a random noise z and generates images from this noise, which is called G(z).Discriminator is a discriminant network that discriminates whether an image is real. The input is x, x is a picture, and the output is D of x is the probability that x is a real picture, and if it's 1, it's 100% real, and if it's 0, it's not real.\n\n### Installation\n\nInstall from pypi:\n```bash\npip install wgangp_pytorch\n```\n\nInstall from source:\n```bash\ngit clone https://github.com/Lornatang/WassersteinGAN_GP-PyTorch.git\ncd WassersteinGAN_gp-PyTorch\npip install -e .\n``` \n\n### Usage\n\n#### Loading pretrained models\n\nLoad an Wasserstein GAN GP:\n```python\nfrom wgangp_pytorch import Generator\nmodel = Generator.from_name(\"g-mnist\")\n```\n\nLoad a pretrained Wasserstein GAN GP:\n```python\nfrom wgangp_pytorch import Generator\nmodel = Generator.from_pretrained(\"g-mnist\")\n```\n\n#### Example: Extended dataset\n\nAs mentioned in the example, if you load the pre-trained weights of the MNIST dataset, it will create a new `imgs` directory and generate 64 random images in the `imgs` directory.\n\n```python\nimport os\nimport torch\nimport torchvision.utils as vutils\nfrom wgangp_pytorch import Generator\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = Generator.from_pretrained(\"g-mnist\")\nmodel.to(device)\n# switch to evaluate mode\nmodel.eval()\n\ntry:\n    os.makedirs(\"./imgs\")\nexcept OSError:\n    pass\n\nwith torch.no_grad():\n    for i in range(64):\n        noise = torch.randn(64, 100, device=device)\n        fake = model(noise)\n        vutils.save_image(fake.detach(), f\"./imgs/fake_{i:04d}.png\", normalize=True)\n    print(\"The fake image has been generated!\")\n```\n\n#### Example: Visual\n\n```text\ncd $REPO$/framework\nsh start.sh\n```\n\nThen open the browser and type in the browser address [http://127.0.0.1:10003/](http://127.0.0.1:10003/).\nEnjoy it.\n\n### Contributing\n\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.   \n\nI look forward to seeing what the community does with these models! \n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Lornatang/WassersteinGAN_GP-PyTorch", "keywords": "", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "wgangp-pytorch", "package_url": "https://pypi.org/project/wgangp-pytorch/", "platform": "", "project_url": "https://pypi.org/project/wgangp-pytorch/", "project_urls": {"Homepage": "https://github.com/Lornatang/WassersteinGAN_GP-PyTorch"}, "release_url": "https://pypi.org/project/wgangp-pytorch/0.1.4/", "requires_dist": ["torch"], "requires_python": ">=3.5.0", "summary": "The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs.", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>WassersteinGAN_GP-PyTorch</h1>\n<h3>Update (Feb 21, 2020)</h3>\n<p>The mnist and fmnist models are now available. Their usage is identical to the other models:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">wgangp_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">'g-mnist'</span><span class=\"p\">)</span> \n</pre>\n<h3>Overview</h3>\n<p>This repository contains an op-for-op PyTorch reimplementation of <a href=\"http://xxx.itp.ac.cn/pdf/1704.00028\" rel=\"nofollow\">Improved Training of Wasserstein GANs</a>.</p>\n<p>The goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. This implementation is a work in progress -- new features are currently being implemented.</p>\n<p>At the moment, you can easily:</p>\n<ul>\n<li>Load pretrained Generate models</li>\n<li>Use Generate models for extended dataset</li>\n</ul>\n<p><em>Upcoming features</em>: In the next few days, you will be able to:</p>\n<ul>\n<li>Quickly finetune an Generate on your own dataset</li>\n<li>Export Generate models for production</li>\n</ul>\n<h3>Table of contents</h3>\n<ol>\n<li><a href=\"#about-wasserstein-gan-gp\" rel=\"nofollow\">About Wasserstein GAN GP</a></li>\n<li><a href=\"#model-description\" rel=\"nofollow\">Model Description</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" rel=\"nofollow\">Usage</a>\n<ul>\n<li><a href=\"#loading-pretrained-models\" rel=\"nofollow\">Load pretrained models</a></li>\n<li><a href=\"#example-extended-dataset\" rel=\"nofollow\">Example: Extended dataset</a></li>\n<li><a href=\"#example-visual\" rel=\"nofollow\">Example: Visual</a></li>\n</ul>\n</li>\n<li><a href=\"#contributing\" rel=\"nofollow\">Contributing</a></li>\n</ol>\n<h3>About Wasserstein GAN GP</h3>\n<p>If you're new to Wasserstein GAN GP, here's an abstract straight from the paper:</p>\n<p>Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.</p>\n<h3>Model Description</h3>\n<p>We have two networks, G (Generator) and D (Discriminator).The Generator is a network for generating images. It receives a random noise z and generates images from this noise, which is called G(z).Discriminator is a discriminant network that discriminates whether an image is real. The input is x, x is a picture, and the output is D of x is the probability that x is a real picture, and if it's 1, it's 100% real, and if it's 0, it's not real.</p>\n<h3>Installation</h3>\n<p>Install from pypi:</p>\n<pre>pip install wgangp_pytorch\n</pre>\n<p>Install from source:</p>\n<pre>git clone https://github.com/Lornatang/WassersteinGAN_GP-PyTorch.git\n<span class=\"nb\">cd</span> WassersteinGAN_gp-PyTorch\npip install -e .\n</pre>\n<h3>Usage</h3>\n<h4>Loading pretrained models</h4>\n<p>Load an Wasserstein GAN GP:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">wgangp_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_name</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n</pre>\n<p>Load a pretrained Wasserstein GAN GP:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">wgangp_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Extended dataset</h4>\n<p>As mentioned in the example, if you load the pre-trained weights of the MNIST dataset, it will create a new <code>imgs</code> directory and generate 64 random images in the <code>imgs</code> directory.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.utils</span> <span class=\"k\">as</span> <span class=\"nn\">vutils</span>\n<span class=\"kn\">from</span> <span class=\"nn\">wgangp_pytorch</span> <span class=\"kn\">import</span> <span class=\"n\">Generator</span>\n\n<span class=\"n\">device</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">(</span><span class=\"s2\">\"cuda:0\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s2\">\"cpu\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">Generator</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s2\">\"g-mnist\"</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"c1\"># switch to evaluate mode</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"s2\">\"./imgs\"</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">OSError</span><span class=\"p\">:</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">):</span>\n        <span class=\"n\">noise</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n        <span class=\"n\">fake</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">noise</span><span class=\"p\">)</span>\n        <span class=\"n\">vutils</span><span class=\"o\">.</span><span class=\"n\">save_image</span><span class=\"p\">(</span><span class=\"n\">fake</span><span class=\"o\">.</span><span class=\"n\">detach</span><span class=\"p\">(),</span> <span class=\"sa\">f</span><span class=\"s2\">\"./imgs/fake_</span><span class=\"si\">{</span><span class=\"n\">i</span><span class=\"si\">:</span><span class=\"s2\">04d</span><span class=\"si\">}</span><span class=\"s2\">.png\"</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">\"The fake image has been generated!\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Example: Visual</h4>\n<pre>cd $REPO$/framework\nsh start.sh\n</pre>\n<p>Then open the browser and type in the browser address <a href=\"http://127.0.0.1:10003/\" rel=\"nofollow\">http://127.0.0.1:10003/</a>.\nEnjoy it.</p>\n<h3>Contributing</h3>\n<p>If you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.</p>\n<p>I look forward to seeing what the community does with these models!</p>\n\n          </div>"}, "last_serial": 6678833, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "a8d9f05028f53b7b407df019c014d464", "sha256": "3df4eab67d45f5ef8c2a475d7b8ee9a11f2059ae3653f70811542bbbe35ad834"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a8d9f05028f53b7b407df019c014d464", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11577, "upload_time": "2020-02-21T16:27:27", "upload_time_iso_8601": "2020-02-21T16:27:27.181697Z", "url": "https://files.pythonhosted.org/packages/f7/fa/646cf9e33373e8604855cacc1c8a9e11f4838b5bfab27feabbc4c1db3c06/wgangp_pytorch-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e806718824229cdc6eaa687410314b89", "sha256": "66b18c36fe86c705a85327e659513d46e695b44a8afdc5fd51d94be4cc8ace7c"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e806718824229cdc6eaa687410314b89", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7287, "upload_time": "2020-02-21T16:27:29", "upload_time_iso_8601": "2020-02-21T16:27:29.750918Z", "url": "https://files.pythonhosted.org/packages/cd/81/bb8cd1b24e3b90c719e9b3e60e79370643d7796709078b40ba69cb961d66/wgangp_pytorch-0.1.0.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "c8c7e2aed6a6f10611b5fec393ccf184", "sha256": "d977f81f167d665f3123e76ed87a570780de444345a0ccbb3fdc7f5f011b0d3f"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c8c7e2aed6a6f10611b5fec393ccf184", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11625, "upload_time": "2020-02-21T16:47:26", "upload_time_iso_8601": "2020-02-21T16:47:26.336872Z", "url": "https://files.pythonhosted.org/packages/03/87/b95067bbe54b95f0b30f8a67e2ae4a27a9c8333bdafee8d49675f5dfafd7/wgangp_pytorch-0.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0e92ed34582b451b48029b6981c83810", "sha256": "1e219497c3bee9c06b13da8963d9492c4a21e3adcb0842b8db98faa10db3ce6d"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.2.tar.gz", "has_sig": false, "md5_digest": "0e92ed34582b451b48029b6981c83810", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7332, "upload_time": "2020-02-21T16:47:27", "upload_time_iso_8601": "2020-02-21T16:47:27.641601Z", "url": "https://files.pythonhosted.org/packages/bf/dc/876c4d38fc0b04cd4f14027119e7410feadc1b0fc896fd05e047c572b6c7/wgangp_pytorch-0.1.2.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "e7cff9c796af5cf807a02119186175f5", "sha256": "db83e37091fb4999118c855c960fa1f11b246023c4d707986c50b46d4a7acb44"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e7cff9c796af5cf807a02119186175f5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11625, "upload_time": "2020-02-22T00:18:17", "upload_time_iso_8601": "2020-02-22T00:18:17.387091Z", "url": "https://files.pythonhosted.org/packages/e8/eb/2983ad3acd279945608ed2485cb5ce9ce6976695d534c23c1a9658b0514f/wgangp_pytorch-0.1.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "66023c018f61a13665d2d58b86e92dec", "sha256": "fbdd840129357f95e6213bdb285417c66374d696ca2a9a7673527e27c652e976"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.4.tar.gz", "has_sig": false, "md5_digest": "66023c018f61a13665d2d58b86e92dec", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7335, "upload_time": "2020-02-22T00:18:18", "upload_time_iso_8601": "2020-02-22T00:18:18.632793Z", "url": "https://files.pythonhosted.org/packages/ae/94/551f1b103d6bb7670622429a483e69dddba2ca7109f208e81b3bd2c00a87/wgangp_pytorch-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e7cff9c796af5cf807a02119186175f5", "sha256": "db83e37091fb4999118c855c960fa1f11b246023c4d707986c50b46d4a7acb44"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e7cff9c796af5cf807a02119186175f5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5.0", "size": 11625, "upload_time": "2020-02-22T00:18:17", "upload_time_iso_8601": "2020-02-22T00:18:17.387091Z", "url": "https://files.pythonhosted.org/packages/e8/eb/2983ad3acd279945608ed2485cb5ce9ce6976695d534c23c1a9658b0514f/wgangp_pytorch-0.1.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "66023c018f61a13665d2d58b86e92dec", "sha256": "fbdd840129357f95e6213bdb285417c66374d696ca2a9a7673527e27c652e976"}, "downloads": -1, "filename": "wgangp_pytorch-0.1.4.tar.gz", "has_sig": false, "md5_digest": "66023c018f61a13665d2d58b86e92dec", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 7335, "upload_time": "2020-02-22T00:18:18", "upload_time_iso_8601": "2020-02-22T00:18:18.632793Z", "url": "https://files.pythonhosted.org/packages/ae/94/551f1b103d6bb7670622429a483e69dddba2ca7109f208e81b3bd2c00a87/wgangp_pytorch-0.1.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:30:04 2020"}