{"info": {"author": "Simon Willison", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# twitter-to-sqlite\n\n[![PyPI](https://img.shields.io/pypi/v/twitter-to-sqlite.svg)](https://pypi.org/project/twitter-to-sqlite/)\n[![CircleCI](https://circleci.com/gh/dogsheep/twitter-to-sqlite.svg?style=svg)](https://circleci.com/gh/dogsheep/twitter-to-sqlite)\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/dogsheep/twitter-to-sqlite/blob/master/LICENSE)\n\nSave data from Twitter to a SQLite database.\n\n## How to install\n\n    $ pip install twitter-to-sqlite\n\n## Authentication\n\nFirst, you will need to create a Twitter application at https://developer.twitter.com/en/apps. You may need to apply for a Twitter developer account - if so, you may find this [example of an email application](https://raw.githubusercontent.com/dogsheep/twitter-to-sqlite/master/email.png) useful that has been approved in the past.\n\nOnce you have created your application, navigate to the \"Keys and tokens\" page and make note of the following:\n\n* Your API key\n* Your API secret key\n* Your access token\n* Your access token secret\n\nYou will need to save all four of these values to a JSON file in order to use this tool.\n\nYou can create that JSON file by running the following command and pasting in the values at the prompts:\n\n    $ twitter-to-sqlite auth\n    Create an app here: https://developer.twitter.com/en/apps\n    Then navigate to 'Keys and tokens' and paste in the following:\n\n    API key: xxx\n    API secret key: xxx\n    Access token: xxx\n    Access token secret: xxx\n\nThis will create a file called `auth.json` in your current directory containing the required values. To save the file at a different path or filename, use the `--auth=myauth.json` option.\n\n## Retrieving tweets by specific accounts\n\nThe `user-timeline` command retrieves all of the tweets posted by the specified user accounts. It defaults to the account belonging to the authenticated user:\n\n    $ twitter-to-sqlite user-timeline twitter.db\n    Importing tweets  [#####-------------------------------]  2799/17780  00:01:39\n\nAll of these commands assume that there is an `auth.json` file in the current directory. You can provide the path to your `auth.json` file using `-a`:\n\n    $ twitter-to-sqlite user-timeline twitter.db -a /path/to/auth.json\n\nTo load tweets for other users, pass their screen names as arguments:\n\n    $ twitter-to-sqlite user-timeline twitter.db cleopaws nichemuseums\n\nTwitter's API only returns up to around 3,200 tweets for most user accounts, but you may find that it returns all available tweets for your own user account.\n\nYou can pass numeric Twitter user IDs instead of screen names using the `--ids` parameter.\n\nYou can use `--since` to retrieve every tweet since the last time you imported for that user, or `--since_id=xxx` to retrieve every tweet since a specific tweet ID.\n\nThis command also accepts `--sql` and `--attach` options, documented below.\n\n## Retrieve user profiles in bulk\n\nIf you have a list of Twitter screen names (or user IDs) you can bulk fetch their fully inflated Twitter profiles using the `users-lookup` command:\n\n    $ twitter-to-sqlite users-lookup users.db simonw cleopaws\n\nYou can pass user IDs instead using the `--ids` option:\n\n    $ twitter-to-sqlite users-lookup users.db 12497 3166449535 --ids\n\nThis command also accepts `--sql` and `--attach` options, documented below.\n\n## Retrieve tweets in bulk\n\nIf you have a list of tweet IDS you can bulk fetch them using the `statuses-lookup` command:\n\n    $ twitter-to-sqlite statuses-lookup tweets.db 1122154819815239680 1122154178493575169\n\nThe `--sql` and `--attach` options are supported.\n\nHere's a recipe to retrieve any tweets that existing tweets are in-reply-to which have not yet been stored in your database:\n\n    $ twitter-to-sqlite statuses-lookup tweets.db \\\n        --sql='\n            select in_reply_to_status_id\n            from tweets\n            where in_reply_to_status_id is not null' \\\n        --skip-existing\n\nThe `--skip-existing` option means that tweets that have already been stored in the database will not be fetched again.\n\n## Retrieving Twitter followers\n\nThe `followers` command retrieves details of every follower of the specified accounts. You can use it to retrieve your own followers, or you can pass one or more screen names to pull the followers for other accounts.\n\nThe following command pulls your followers and saves them in a SQLite database file called `twitter.db`:\n\n    $ twitter-to-sqlite followers twitter.db\n\nThis command is **extremely slow**, because Twitter impose a rate limit of no more than one request per minute to this endpoint! If you are running it against an account with thousands of followers you should expect this to take several hours.\n\nTo retrieve followers for another account, use:\n\n    $ twitter-to-sqlite followers twitter.db cleopaws\n\nThis command also accepts the `--ids`, `--sql` and `--attach` options.\n\nSee [Analyzing my Twitter followers with Datasette](https://simonwillison.net/2018/Jan/28/analyzing-my-twitter-followers/) for the original inspiration for this command.\n\n## Retrieving friends\n\nThe `friends` command works like the `followers` command, but retrieves the specified (or currently authenticated) user's friends - defined as accounts that the user is following.\n\n    $ twitter-to-sqlite friends twitter.db\n\nIt takes the same options as the `followers` command.\n\n## Retrieving favorited tweets\n\nThe `favorites` command retrieves tweets that have been favorited by a specified user. Called without any extra arguments it retrieves tweets favorited by the currently authenticated user:\n\n    $ twitter-to-sqlite favorites faves.db\n\nYou can also use the `--screen_name` or `--user_id` arguments to retrieve favorite tweets for another user:\n\n    $ twitter-to-sqlite favorites faves-obama.db --screen_name=BarackObama\n\n## Retrieving Twitter lists\n\nThe `lists` command retrieves all of the lists belonging to one or more users.\n\n    $ twitter-to-sqlite lists lists.db simonw dogsheep\n\nThis command also accepts the `--sql` and `--attach` and `--ids` options.\n\nTo additionally fetch the list of members for each list, use `--members`.\n\n## Retrieving Twitter list memberships\n\nThe `list-members` command can be used to retrieve details of one or more Twitter lists, including all of their members.\n\n    $ twitter-to-sqlite list-members members.db simonw/the-good-place\n\nYou can pass multiple `screen_name/list_slug` identifiers.\n\nIf you know the numeric IDs of the lists instead, you can use `--ids`:\n\n    $ twitter-to-sqlite list-members members.db 927913322841653248 --ids\n\n## Retrieving just follower and friend IDs\n\nIt's also possible to retrieve just the numeric Twitter IDs of the accounts that specific users are following (\"friends\" in Twitter's API terminology) or followed-by:\n\n    $ twitter-to-sqlite followers-ids members.db simonw cleopaws\n\nThis will populate the `following` table with `followed_id`/`follower_id` pairs for the two specified accounts, listing every account ID that is following either of those two accounts.\n\n    $ twitter-to-sqlite friends-ids members.db simonw cleopaws\n\nThis will do the same thing but pull the IDs that those accounts are following.\n\nBoth of these commands also support `--sql` and `--attach` as an alternative to passing screen names as direct command-line arguments. You can use `--ids` to process the inputs as user IDs rather than screen names.\n\nThe underlying Twitter APIs have a rate limit of 15 requests every 15 minutes - though they do return up to 5,000 IDs in each call. By default both of these subcommands will wait for 61 seconds between API calls in order to stay within the rate limit - you can adjust this behaviour down to just one second delay if you know you will not be making many calls using `--sleep=1`.\n\n## Retrieving tweets from your home timeline\n\nThe `home-timeline` command retrieves up to 800 tweets from the home timeline of the authenticated user - generally this means tweets from people you follow.\n\n    $ twitter-to-sqlite home-timeline twitter.db\n    Importing timeline  [#################--------]  591/800  00:01:14\n\nThe tweets are stored in the `tweets` table, and a record is added to the `timeline_tweets` table noting that this tweet came in due to being spotted in the timeline of your user.\n\nYou can use `--since` to retrieve just tweets that have been posted since the last time this command was run, or `--since_id=xxx` to explicitly pass in a tweet ID to use as the last position.\n\nYou can then view your timeline in Datasette using the following URL:\n\n`/tweets/tweets?_where=id+in+(select+tweet+from+[timeline_tweets])&_sort_desc=id&_facet=user`\n\nThis will filter your tweets table to just tweets that appear in your timeline, ordered by most recent first and use faceting to show you which users are responsible for the most tweets.\n\n## Retrieving your mentions\n\nThe `mentions-timeline` command works like `home-timeline` except it retrieves tweets that mention the authenticated user's account. It records the user account that was mentioned in a `mentions_tweets` table.\n\nIt supports `--since` and `--since_id` in the same was as `home-timeline` does.\n\n## Providing input from a SQL query with --sql and --attach\n\nThis option is available for some subcommands - run `twitter-to-sqlite command-name --help` to check.\n\nYou can provide Twitter screen names (or user IDs or tweet IDs) directly as command-line arguments, or you can provide those screen names or IDs by executing a SQL query.\n\nFor example: consider a SQLite database with an `attendees` table listing names and Twitter accounts - something like this:\n\n| First   | Last       | Twitter      |\n|---------|------------|--------------|\n| Simon   | Willison   | simonw       |\n| Avril   | Lavigne    | AvrilLavigne |\n\nYou can run the `users-lookup` command to pull the Twitter profile of every user listed in that database by loading the screen names using a `--sql` query:\n\n    $ twitter-to-sqlite users-lookup my.db --sql=\"select Twitter from attendees\"\n\nIf your database table contains Twitter IDs, you can select those IDs and pass the `--ids` argument. For example, to fetch the profiles of users who have had their user IDs inserted into the `following` table using the `twitter-to-sqlite friends-ids` command:\n\n    $ twitter-to-sqlite users-lookup my.db --sql=\"select follower_id from following\" --ids\n\nOr to avoid re-fetching users that have already been fetched:\n\n    $ twitter-to-sqlite users-lookup my.db \\\n        --sql=\"select followed_id from following where followed_id not in (\n            select id from users)\" --ids\n\nIf your data lives in a separate database file you can attach it using `--attach`. For example, consider the attendees example above but the data lives in an `attendees.db` file, and you want to fetch the user profiles into a `tweets.db` file. You could do that like this:\n\n    $ twitter-to-sqlite users-lookup tweets.db \\\n        --attach=attendees.db \\\n        --sql=\"select Twitter from attendees.attendees\"\n\nThe filename (without the extension) will be used as the database alias within SQLite. If you want a different alias for some reason you can specify that with a colon like this:\n\n    $ twitter-to-sqlite users-lookup tweets.db \\\n        --attach=foo:attendees.db \\\n        --sql=\"select Twitter from foo.attendees\"\n\n## Running searches\n\nThe `search` command runs a search against the Twitter [standard search API](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets).\n\n    $ twitter-to-sqlite search tweets.db \"dogsheep\"\n\nThis will import up to around 320 tweets that match that search term into the `tweets` table. It will also create a record in the `search_runs` table recording that the search took place, and many-to-many recorsd in the `search_runs_tweets` table recording which tweets were seen for that search at that time.\n\nYou can use the `--since` parameter to check for previous search runs with the same arguments and only retrieve tweets that were posted since the last retrieved matching tweet.\n\nThe following additional options for `search` are supported:\n\n* `--geocode`: `latitude,longitude,radius` where radius is a number followed by mi or km\n* `--lang`: ISO 639-1 language code e.g. `en` or `es`\n* `--locale`: Locale: only `ja` is currently effective\n* `--result_type`: `mixed`, `recent` or `popular`. Defaults to `mixed`\n* `--count`: Number of results per page, defaults to the maximum of 100\n* `--stop_after`: Stop after this many results\n* `--since_id`: Pull tweets since this Tweet ID. You probably want to use `--since` instead of this.\n\n## Capturing tweets in real-time with track and follow\n\nThis functionality is **experimental**. Please [file bug reports](https://github.com/dogsheep/twitter-to-sqlite/issues) if you find any!\n\nTwitter provides a real-time API which can be used to subscribe to tweets as they happen. `twitter-to-sqlite` can use this API to continually update a SQLite database with tweets matching certain keywords, or referencing specific users.\n\n### track\n\nTo track keywords, use the `track` command:\n\n    $ twitter-to-sqlite track tweets.db kakapo\n\nThis command will continue to run until you hit Ctrl+C. It will capture any tweets mentioning the keyword [kakapo](https://en.wikipedia.org/wiki/Kakapo) and store them in the `tweets.db` database file.\n\nYou can pass multiple keywords as a space separated list. This will capture tweets matching either of those keywords:\n\n    $ twitter-to-sqlite track tweets.db kakapo raccoon\n\nYou can enclose phrases in quotes to search for tweets matching both of those keywords:\n\n    $ twitter-to-sqlite track tweets.db 'trash panda'\n\nSee [the Twitter track documentation](https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters#track) for advanced tips on using this command.\n\nAdd the `--verbose` option to see matching tweets (in their verbose JSON form) displayed to the terminal as they are captured:\n\n    $ twitter-to-sqlite track tweets.db raccoon --verbose\n\n### follow\n\nThe `follow` command will capture all tweets that are relevant to one or more specific Twitter users.\n\n    $ twitter-to-sqlite follow tweets.db nytimes\n\nThis includes tweets by those users, tweets that reply to or quote those users and retweets by that user. See [the Twitter follow documentation](https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters#follow) for full details.\n\nThe command accepts one or more screen names.\n\nYou can feed it numeric Twitter user IDs instead of screen names by using the `--ids` flag.\n\nThe command also supports the `--sql` and `--attach` options, and the `--verbose` option for displaying tweets as they are captured.\n\nHere's how to start following tweets from every user ID currently represented as being followed in the `following` table (populated using the `friends-ids` command):\n\n    $ twitter-to-sqlite follow tweets.db \\\n        --sql=\"select distinct followed_id from following\" \\\n        --ids\n\n## Importing data from your Twitter archive\n\nYou can request an archive of your Twitter data by [following these instructions](https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive).\n\nTwitter will send you a link to download a `.zip` file. You can import the contents of that file into a set of tables in a new database file called `archive.db` (each table beginning with the `archive_` prefix) using the `import` command:\n\n    $ twitter-to-sqlite import archive.db ~/Downloads/twitter-2019-06-25-b31f2.zip\n\nThis command does not populate any of the regular tables, since Twitter's export data does not exactly match the schema returned by the Twitter API.\n\nIt will delete and recreate the corresponding `archive_*` tables every time you run it. If this is not what you want, run the command against a new SQLite database file name rather than running it against one that already exists.\n\nIf you have already decompressed your archive, you can run this against the directory that you decompressed it to:\n\n    $ twitter-to-sqlite import archive.db ~/Downloads/twitter-2019-06-25-b31f2/\n\nYou can also run it against one or more specific files within that folder. For example, to import just the follower.js and following.js files:\n\n    $ twitter-to-sqlite import archive.db \\\n        ~/Downloads/twitter-2019-06-25-b31f2/follower.js \\\n        ~/Downloads/twitter-2019-06-25-b31f2/following.js\n\nYou may want to use other commands to populate tables based on data from the archive. For example, to retrieve full API versions of each of the tweets you have favourited in your archive, you could run the following:\n\n    $ twitter-to-sqlite statuses-lookup archive.db \\\n        --sql='select tweetId from archive_like' \\\n        --skip-existing\n\nIf you want these imported tweets to then be reflected in the `favorited_by` table, you can do so by applying the following SQL query:\n\n    $ sqlite3 archive.db\n    SQLite version 3.22.0 2018-01-22 18:45:57\n    Enter \".help\" for usage hints.\n    sqlite> INSERT OR IGNORE INTO favorited_by (tweet, user)\n       ...>     SELECT tweetId, 'YOUR_TWITTER_ID' FROM archive_like;\n    <Ctrl+D>\n\nReplace YOUR_TWITTER_ID with your numeric Twitter ID. If you don't know that ID you can find it out by running the following:\n\n    $ twitter-to-sqlite fetch \\\n        \"https://api.twitter.com/1.1/account/verify_credentials.json\" \\\n        | grep '\"id\"' | head -n 1\n\n## Design notes\n\n* Tweet IDs are stored as integers, to afford sorting by ID in a sensible way\n* While we configure foreign key relationships between tables, we do not ask SQLite to enforce them. This is used by the `following` table to allow the `followers-ids` and `friends-ids` commands to populate it with user IDs even if the user accounts themselves are not yet present in the `users` table.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dogsheep/twitter-to-sqlite", "keywords": "", "license": "Apache License, Version 2.0", "maintainer": "", "maintainer_email": "", "name": "twitter-to-sqlite", "package_url": "https://pypi.org/project/twitter-to-sqlite/", "platform": "", "project_url": "https://pypi.org/project/twitter-to-sqlite/", "project_urls": {"Homepage": "https://github.com/dogsheep/twitter-to-sqlite"}, "release_url": "https://pypi.org/project/twitter-to-sqlite/0.21.1/", "requires_dist": ["sqlite-utils (>=2.4.2)", "requests-oauthlib (~=1.2.0)", "python-dateutil", "pytest ; extra == 'test'"], "requires_python": "", "summary": "Save data from Twitter to a SQLite database", "version": "0.21.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>twitter-to-sqlite</h1>\n<p><a href=\"https://pypi.org/project/twitter-to-sqlite/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/205c7e03abcadc97e3113377bc9bf8cfc10cb6bc/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f747769747465722d746f2d73716c6974652e737667\"></a>\n<a href=\"https://circleci.com/gh/dogsheep/twitter-to-sqlite\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a2115e37e90d13b0e1acfebf2b3ebdb156afaad0/68747470733a2f2f636972636c6563692e636f6d2f67682f646f6773686565702f747769747465722d746f2d73716c6974652e7376673f7374796c653d737667\"></a>\n<a href=\"https://github.com/dogsheep/twitter-to-sqlite/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bad0ad2a7195b40874e3a10488118122d89489fd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322e302d626c75652e737667\"></a></p>\n<p>Save data from Twitter to a SQLite database.</p>\n<h2>How to install</h2>\n<pre><code>$ pip install twitter-to-sqlite\n</code></pre>\n<h2>Authentication</h2>\n<p>First, you will need to create a Twitter application at <a href=\"https://developer.twitter.com/en/apps\" rel=\"nofollow\">https://developer.twitter.com/en/apps</a>. You may need to apply for a Twitter developer account - if so, you may find this <a href=\"https://raw.githubusercontent.com/dogsheep/twitter-to-sqlite/master/email.png\" rel=\"nofollow\">example of an email application</a> useful that has been approved in the past.</p>\n<p>Once you have created your application, navigate to the \"Keys and tokens\" page and make note of the following:</p>\n<ul>\n<li>Your API key</li>\n<li>Your API secret key</li>\n<li>Your access token</li>\n<li>Your access token secret</li>\n</ul>\n<p>You will need to save all four of these values to a JSON file in order to use this tool.</p>\n<p>You can create that JSON file by running the following command and pasting in the values at the prompts:</p>\n<pre><code>$ twitter-to-sqlite auth\nCreate an app here: https://developer.twitter.com/en/apps\nThen navigate to 'Keys and tokens' and paste in the following:\n\nAPI key: xxx\nAPI secret key: xxx\nAccess token: xxx\nAccess token secret: xxx\n</code></pre>\n<p>This will create a file called <code>auth.json</code> in your current directory containing the required values. To save the file at a different path or filename, use the <code>--auth=myauth.json</code> option.</p>\n<h2>Retrieving tweets by specific accounts</h2>\n<p>The <code>user-timeline</code> command retrieves all of the tweets posted by the specified user accounts. It defaults to the account belonging to the authenticated user:</p>\n<pre><code>$ twitter-to-sqlite user-timeline twitter.db\nImporting tweets  [#####-------------------------------]  2799/17780  00:01:39\n</code></pre>\n<p>All of these commands assume that there is an <code>auth.json</code> file in the current directory. You can provide the path to your <code>auth.json</code> file using <code>-a</code>:</p>\n<pre><code>$ twitter-to-sqlite user-timeline twitter.db -a /path/to/auth.json\n</code></pre>\n<p>To load tweets for other users, pass their screen names as arguments:</p>\n<pre><code>$ twitter-to-sqlite user-timeline twitter.db cleopaws nichemuseums\n</code></pre>\n<p>Twitter's API only returns up to around 3,200 tweets for most user accounts, but you may find that it returns all available tweets for your own user account.</p>\n<p>You can pass numeric Twitter user IDs instead of screen names using the <code>--ids</code> parameter.</p>\n<p>You can use <code>--since</code> to retrieve every tweet since the last time you imported for that user, or <code>--since_id=xxx</code> to retrieve every tweet since a specific tweet ID.</p>\n<p>This command also accepts <code>--sql</code> and <code>--attach</code> options, documented below.</p>\n<h2>Retrieve user profiles in bulk</h2>\n<p>If you have a list of Twitter screen names (or user IDs) you can bulk fetch their fully inflated Twitter profiles using the <code>users-lookup</code> command:</p>\n<pre><code>$ twitter-to-sqlite users-lookup users.db simonw cleopaws\n</code></pre>\n<p>You can pass user IDs instead using the <code>--ids</code> option:</p>\n<pre><code>$ twitter-to-sqlite users-lookup users.db 12497 3166449535 --ids\n</code></pre>\n<p>This command also accepts <code>--sql</code> and <code>--attach</code> options, documented below.</p>\n<h2>Retrieve tweets in bulk</h2>\n<p>If you have a list of tweet IDS you can bulk fetch them using the <code>statuses-lookup</code> command:</p>\n<pre><code>$ twitter-to-sqlite statuses-lookup tweets.db 1122154819815239680 1122154178493575169\n</code></pre>\n<p>The <code>--sql</code> and <code>--attach</code> options are supported.</p>\n<p>Here's a recipe to retrieve any tweets that existing tweets are in-reply-to which have not yet been stored in your database:</p>\n<pre><code>$ twitter-to-sqlite statuses-lookup tweets.db \\\n    --sql='\n        select in_reply_to_status_id\n        from tweets\n        where in_reply_to_status_id is not null' \\\n    --skip-existing\n</code></pre>\n<p>The <code>--skip-existing</code> option means that tweets that have already been stored in the database will not be fetched again.</p>\n<h2>Retrieving Twitter followers</h2>\n<p>The <code>followers</code> command retrieves details of every follower of the specified accounts. You can use it to retrieve your own followers, or you can pass one or more screen names to pull the followers for other accounts.</p>\n<p>The following command pulls your followers and saves them in a SQLite database file called <code>twitter.db</code>:</p>\n<pre><code>$ twitter-to-sqlite followers twitter.db\n</code></pre>\n<p>This command is <strong>extremely slow</strong>, because Twitter impose a rate limit of no more than one request per minute to this endpoint! If you are running it against an account with thousands of followers you should expect this to take several hours.</p>\n<p>To retrieve followers for another account, use:</p>\n<pre><code>$ twitter-to-sqlite followers twitter.db cleopaws\n</code></pre>\n<p>This command also accepts the <code>--ids</code>, <code>--sql</code> and <code>--attach</code> options.</p>\n<p>See <a href=\"https://simonwillison.net/2018/Jan/28/analyzing-my-twitter-followers/\" rel=\"nofollow\">Analyzing my Twitter followers with Datasette</a> for the original inspiration for this command.</p>\n<h2>Retrieving friends</h2>\n<p>The <code>friends</code> command works like the <code>followers</code> command, but retrieves the specified (or currently authenticated) user's friends - defined as accounts that the user is following.</p>\n<pre><code>$ twitter-to-sqlite friends twitter.db\n</code></pre>\n<p>It takes the same options as the <code>followers</code> command.</p>\n<h2>Retrieving favorited tweets</h2>\n<p>The <code>favorites</code> command retrieves tweets that have been favorited by a specified user. Called without any extra arguments it retrieves tweets favorited by the currently authenticated user:</p>\n<pre><code>$ twitter-to-sqlite favorites faves.db\n</code></pre>\n<p>You can also use the <code>--screen_name</code> or <code>--user_id</code> arguments to retrieve favorite tweets for another user:</p>\n<pre><code>$ twitter-to-sqlite favorites faves-obama.db --screen_name=BarackObama\n</code></pre>\n<h2>Retrieving Twitter lists</h2>\n<p>The <code>lists</code> command retrieves all of the lists belonging to one or more users.</p>\n<pre><code>$ twitter-to-sqlite lists lists.db simonw dogsheep\n</code></pre>\n<p>This command also accepts the <code>--sql</code> and <code>--attach</code> and <code>--ids</code> options.</p>\n<p>To additionally fetch the list of members for each list, use <code>--members</code>.</p>\n<h2>Retrieving Twitter list memberships</h2>\n<p>The <code>list-members</code> command can be used to retrieve details of one or more Twitter lists, including all of their members.</p>\n<pre><code>$ twitter-to-sqlite list-members members.db simonw/the-good-place\n</code></pre>\n<p>You can pass multiple <code>screen_name/list_slug</code> identifiers.</p>\n<p>If you know the numeric IDs of the lists instead, you can use <code>--ids</code>:</p>\n<pre><code>$ twitter-to-sqlite list-members members.db 927913322841653248 --ids\n</code></pre>\n<h2>Retrieving just follower and friend IDs</h2>\n<p>It's also possible to retrieve just the numeric Twitter IDs of the accounts that specific users are following (\"friends\" in Twitter's API terminology) or followed-by:</p>\n<pre><code>$ twitter-to-sqlite followers-ids members.db simonw cleopaws\n</code></pre>\n<p>This will populate the <code>following</code> table with <code>followed_id</code>/<code>follower_id</code> pairs for the two specified accounts, listing every account ID that is following either of those two accounts.</p>\n<pre><code>$ twitter-to-sqlite friends-ids members.db simonw cleopaws\n</code></pre>\n<p>This will do the same thing but pull the IDs that those accounts are following.</p>\n<p>Both of these commands also support <code>--sql</code> and <code>--attach</code> as an alternative to passing screen names as direct command-line arguments. You can use <code>--ids</code> to process the inputs as user IDs rather than screen names.</p>\n<p>The underlying Twitter APIs have a rate limit of 15 requests every 15 minutes - though they do return up to 5,000 IDs in each call. By default both of these subcommands will wait for 61 seconds between API calls in order to stay within the rate limit - you can adjust this behaviour down to just one second delay if you know you will not be making many calls using <code>--sleep=1</code>.</p>\n<h2>Retrieving tweets from your home timeline</h2>\n<p>The <code>home-timeline</code> command retrieves up to 800 tweets from the home timeline of the authenticated user - generally this means tweets from people you follow.</p>\n<pre><code>$ twitter-to-sqlite home-timeline twitter.db\nImporting timeline  [#################--------]  591/800  00:01:14\n</code></pre>\n<p>The tweets are stored in the <code>tweets</code> table, and a record is added to the <code>timeline_tweets</code> table noting that this tweet came in due to being spotted in the timeline of your user.</p>\n<p>You can use <code>--since</code> to retrieve just tweets that have been posted since the last time this command was run, or <code>--since_id=xxx</code> to explicitly pass in a tweet ID to use as the last position.</p>\n<p>You can then view your timeline in Datasette using the following URL:</p>\n<p><code>/tweets/tweets?_where=id+in+(select+tweet+from+[timeline_tweets])&amp;_sort_desc=id&amp;_facet=user</code></p>\n<p>This will filter your tweets table to just tweets that appear in your timeline, ordered by most recent first and use faceting to show you which users are responsible for the most tweets.</p>\n<h2>Retrieving your mentions</h2>\n<p>The <code>mentions-timeline</code> command works like <code>home-timeline</code> except it retrieves tweets that mention the authenticated user's account. It records the user account that was mentioned in a <code>mentions_tweets</code> table.</p>\n<p>It supports <code>--since</code> and <code>--since_id</code> in the same was as <code>home-timeline</code> does.</p>\n<h2>Providing input from a SQL query with --sql and --attach</h2>\n<p>This option is available for some subcommands - run <code>twitter-to-sqlite command-name --help</code> to check.</p>\n<p>You can provide Twitter screen names (or user IDs or tweet IDs) directly as command-line arguments, or you can provide those screen names or IDs by executing a SQL query.</p>\n<p>For example: consider a SQLite database with an <code>attendees</code> table listing names and Twitter accounts - something like this:</p>\n<table>\n<thead>\n<tr>\n<th>First</th>\n<th>Last</th>\n<th>Twitter</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Simon</td>\n<td>Willison</td>\n<td>simonw</td>\n</tr>\n<tr>\n<td>Avril</td>\n<td>Lavigne</td>\n<td>AvrilLavigne</td>\n</tr></tbody></table>\n<p>You can run the <code>users-lookup</code> command to pull the Twitter profile of every user listed in that database by loading the screen names using a <code>--sql</code> query:</p>\n<pre><code>$ twitter-to-sqlite users-lookup my.db --sql=\"select Twitter from attendees\"\n</code></pre>\n<p>If your database table contains Twitter IDs, you can select those IDs and pass the <code>--ids</code> argument. For example, to fetch the profiles of users who have had their user IDs inserted into the <code>following</code> table using the <code>twitter-to-sqlite friends-ids</code> command:</p>\n<pre><code>$ twitter-to-sqlite users-lookup my.db --sql=\"select follower_id from following\" --ids\n</code></pre>\n<p>Or to avoid re-fetching users that have already been fetched:</p>\n<pre><code>$ twitter-to-sqlite users-lookup my.db \\\n    --sql=\"select followed_id from following where followed_id not in (\n        select id from users)\" --ids\n</code></pre>\n<p>If your data lives in a separate database file you can attach it using <code>--attach</code>. For example, consider the attendees example above but the data lives in an <code>attendees.db</code> file, and you want to fetch the user profiles into a <code>tweets.db</code> file. You could do that like this:</p>\n<pre><code>$ twitter-to-sqlite users-lookup tweets.db \\\n    --attach=attendees.db \\\n    --sql=\"select Twitter from attendees.attendees\"\n</code></pre>\n<p>The filename (without the extension) will be used as the database alias within SQLite. If you want a different alias for some reason you can specify that with a colon like this:</p>\n<pre><code>$ twitter-to-sqlite users-lookup tweets.db \\\n    --attach=foo:attendees.db \\\n    --sql=\"select Twitter from foo.attendees\"\n</code></pre>\n<h2>Running searches</h2>\n<p>The <code>search</code> command runs a search against the Twitter <a href=\"https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\" rel=\"nofollow\">standard search API</a>.</p>\n<pre><code>$ twitter-to-sqlite search tweets.db \"dogsheep\"\n</code></pre>\n<p>This will import up to around 320 tweets that match that search term into the <code>tweets</code> table. It will also create a record in the <code>search_runs</code> table recording that the search took place, and many-to-many recorsd in the <code>search_runs_tweets</code> table recording which tweets were seen for that search at that time.</p>\n<p>You can use the <code>--since</code> parameter to check for previous search runs with the same arguments and only retrieve tweets that were posted since the last retrieved matching tweet.</p>\n<p>The following additional options for <code>search</code> are supported:</p>\n<ul>\n<li><code>--geocode</code>: <code>latitude,longitude,radius</code> where radius is a number followed by mi or km</li>\n<li><code>--lang</code>: ISO 639-1 language code e.g. <code>en</code> or <code>es</code></li>\n<li><code>--locale</code>: Locale: only <code>ja</code> is currently effective</li>\n<li><code>--result_type</code>: <code>mixed</code>, <code>recent</code> or <code>popular</code>. Defaults to <code>mixed</code></li>\n<li><code>--count</code>: Number of results per page, defaults to the maximum of 100</li>\n<li><code>--stop_after</code>: Stop after this many results</li>\n<li><code>--since_id</code>: Pull tweets since this Tweet ID. You probably want to use <code>--since</code> instead of this.</li>\n</ul>\n<h2>Capturing tweets in real-time with track and follow</h2>\n<p>This functionality is <strong>experimental</strong>. Please <a href=\"https://github.com/dogsheep/twitter-to-sqlite/issues\" rel=\"nofollow\">file bug reports</a> if you find any!</p>\n<p>Twitter provides a real-time API which can be used to subscribe to tweets as they happen. <code>twitter-to-sqlite</code> can use this API to continually update a SQLite database with tweets matching certain keywords, or referencing specific users.</p>\n<h3>track</h3>\n<p>To track keywords, use the <code>track</code> command:</p>\n<pre><code>$ twitter-to-sqlite track tweets.db kakapo\n</code></pre>\n<p>This command will continue to run until you hit Ctrl+C. It will capture any tweets mentioning the keyword <a href=\"https://en.wikipedia.org/wiki/Kakapo\" rel=\"nofollow\">kakapo</a> and store them in the <code>tweets.db</code> database file.</p>\n<p>You can pass multiple keywords as a space separated list. This will capture tweets matching either of those keywords:</p>\n<pre><code>$ twitter-to-sqlite track tweets.db kakapo raccoon\n</code></pre>\n<p>You can enclose phrases in quotes to search for tweets matching both of those keywords:</p>\n<pre><code>$ twitter-to-sqlite track tweets.db 'trash panda'\n</code></pre>\n<p>See <a href=\"https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters#track\" rel=\"nofollow\">the Twitter track documentation</a> for advanced tips on using this command.</p>\n<p>Add the <code>--verbose</code> option to see matching tweets (in their verbose JSON form) displayed to the terminal as they are captured:</p>\n<pre><code>$ twitter-to-sqlite track tweets.db raccoon --verbose\n</code></pre>\n<h3>follow</h3>\n<p>The <code>follow</code> command will capture all tweets that are relevant to one or more specific Twitter users.</p>\n<pre><code>$ twitter-to-sqlite follow tweets.db nytimes\n</code></pre>\n<p>This includes tweets by those users, tweets that reply to or quote those users and retweets by that user. See <a href=\"https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/basic-stream-parameters#follow\" rel=\"nofollow\">the Twitter follow documentation</a> for full details.</p>\n<p>The command accepts one or more screen names.</p>\n<p>You can feed it numeric Twitter user IDs instead of screen names by using the <code>--ids</code> flag.</p>\n<p>The command also supports the <code>--sql</code> and <code>--attach</code> options, and the <code>--verbose</code> option for displaying tweets as they are captured.</p>\n<p>Here's how to start following tweets from every user ID currently represented as being followed in the <code>following</code> table (populated using the <code>friends-ids</code> command):</p>\n<pre><code>$ twitter-to-sqlite follow tweets.db \\\n    --sql=\"select distinct followed_id from following\" \\\n    --ids\n</code></pre>\n<h2>Importing data from your Twitter archive</h2>\n<p>You can request an archive of your Twitter data by <a href=\"https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive\" rel=\"nofollow\">following these instructions</a>.</p>\n<p>Twitter will send you a link to download a <code>.zip</code> file. You can import the contents of that file into a set of tables in a new database file called <code>archive.db</code> (each table beginning with the <code>archive_</code> prefix) using the <code>import</code> command:</p>\n<pre><code>$ twitter-to-sqlite import archive.db ~/Downloads/twitter-2019-06-25-b31f2.zip\n</code></pre>\n<p>This command does not populate any of the regular tables, since Twitter's export data does not exactly match the schema returned by the Twitter API.</p>\n<p>It will delete and recreate the corresponding <code>archive_*</code> tables every time you run it. If this is not what you want, run the command against a new SQLite database file name rather than running it against one that already exists.</p>\n<p>If you have already decompressed your archive, you can run this against the directory that you decompressed it to:</p>\n<pre><code>$ twitter-to-sqlite import archive.db ~/Downloads/twitter-2019-06-25-b31f2/\n</code></pre>\n<p>You can also run it against one or more specific files within that folder. For example, to import just the follower.js and following.js files:</p>\n<pre><code>$ twitter-to-sqlite import archive.db \\\n    ~/Downloads/twitter-2019-06-25-b31f2/follower.js \\\n    ~/Downloads/twitter-2019-06-25-b31f2/following.js\n</code></pre>\n<p>You may want to use other commands to populate tables based on data from the archive. For example, to retrieve full API versions of each of the tweets you have favourited in your archive, you could run the following:</p>\n<pre><code>$ twitter-to-sqlite statuses-lookup archive.db \\\n    --sql='select tweetId from archive_like' \\\n    --skip-existing\n</code></pre>\n<p>If you want these imported tweets to then be reflected in the <code>favorited_by</code> table, you can do so by applying the following SQL query:</p>\n<pre><code>$ sqlite3 archive.db\nSQLite version 3.22.0 2018-01-22 18:45:57\nEnter \".help\" for usage hints.\nsqlite&gt; INSERT OR IGNORE INTO favorited_by (tweet, user)\n   ...&gt;     SELECT tweetId, 'YOUR_TWITTER_ID' FROM archive_like;\n&lt;Ctrl+D&gt;\n</code></pre>\n<p>Replace YOUR_TWITTER_ID with your numeric Twitter ID. If you don't know that ID you can find it out by running the following:</p>\n<pre><code>$ twitter-to-sqlite fetch \\\n    \"https://api.twitter.com/1.1/account/verify_credentials.json\" \\\n    | grep '\"id\"' | head -n 1\n</code></pre>\n<h2>Design notes</h2>\n<ul>\n<li>Tweet IDs are stored as integers, to afford sorting by ID in a sensible way</li>\n<li>While we configure foreign key relationships between tables, we do not ask SQLite to enforce them. This is used by the <code>following</code> table to allow the <code>followers-ids</code> and <code>friends-ids</code> commands to populate it with user IDs even if the user accounts themselves are not yet present in the <code>users</code> table.</li>\n</ul>\n\n          </div>"}, "last_serial": 7139457, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "5c1a78dc3256e15424d2649e16f857de", "sha256": "c975f7e895c9aa1673e72bc5dbae53556ad82b36d30957616201d2e272b4a673"}, "downloads": -1, "filename": "twitter_to_sqlite-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "5c1a78dc3256e15424d2649e16f857de", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10411, "upload_time": "2019-09-04T20:44:49", "upload_time_iso_8601": "2019-09-04T20:44:49.950781Z", "url": "https://files.pythonhosted.org/packages/a0/a4/e2c1ab5dcc99de34383b037709f19a4ea592d578af481eb29f0ccb635d19/twitter_to_sqlite-0.1-py3-none-any.whl", "yanked": false}], "0.10": [{"comment_text": "", "digests": {"md5": "d6d38c4344259e0593846feb2ed0fb6d", "sha256": "92ccfff19c8ff5624c6666c12b39a1b1536eebc56d444a50a57a9ce0fd110fcc"}, "downloads": -1, "filename": "twitter_to_sqlite-0.10-py3-none-any.whl", "has_sig": false, "md5_digest": "d6d38c4344259e0593846feb2ed0fb6d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 19685, "upload_time": "2019-10-15T18:54:49", "upload_time_iso_8601": "2019-10-15T18:54:49.831897Z", "url": "https://files.pythonhosted.org/packages/f7/c5/2420eeb5054cd63b27b319d694dffbb0298fdf66a29e74784887414e617f/twitter_to_sqlite-0.10-py3-none-any.whl", "yanked": false}], "0.11": [{"comment_text": "", "digests": {"md5": "45326bf07638c24a29afe77f1a462274", "sha256": "31f116d05ce670a81443f701daddfb1c281024b86f3263345438a9bcd745da52"}, "downloads": -1, "filename": "twitter_to_sqlite-0.11-py3-none-any.whl", "has_sig": false, "md5_digest": "45326bf07638c24a29afe77f1a462274", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20676, "upload_time": "2019-10-16T19:38:12", "upload_time_iso_8601": "2019-10-16T19:38:12.171349Z", "url": "https://files.pythonhosted.org/packages/18/fc/8c30e9acbbfae08c854a90a852b5897b95222c84ded57794a12843b60b49/twitter_to_sqlite-0.11-py3-none-any.whl", "yanked": false}], "0.11.1": [{"comment_text": "", "digests": {"md5": "9a65802c4eb0793729c0f54438301eac", "sha256": "416b4d9512f5e61cc7ea815f84b66db024981ab0c143fd2a807393df85d2194d"}, "downloads": -1, "filename": "twitter_to_sqlite-0.11.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9a65802c4eb0793729c0f54438301eac", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 20692, "upload_time": "2019-10-16T19:47:41", "upload_time_iso_8601": "2019-10-16T19:47:41.836743Z", "url": "https://files.pythonhosted.org/packages/27/af/9145bdc3358ffc59b8c541ed32e76060ee033ae9492ed7e0cc63ed2e382b/twitter_to_sqlite-0.11.1-py3-none-any.whl", "yanked": false}], "0.12": [{"comment_text": "", "digests": {"md5": "0972d7b81bad7c2b2b5dd0f12bf198e7", "sha256": "8b81d0cc2396688a9406246ef7f58687381c908c88f06924f6d52d551e459aa5"}, "downloads": -1, "filename": "twitter_to_sqlite-0.12-py3-none-any.whl", "has_sig": false, "md5_digest": "0972d7b81bad7c2b2b5dd0f12bf198e7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22591, "upload_time": "2019-10-17T17:58:41", "upload_time_iso_8601": "2019-10-17T17:58:41.383956Z", "url": "https://files.pythonhosted.org/packages/28/31/e1e9593c7eae3199f06ee4a833051988175bc04486cb9a955b984a21c876/twitter_to_sqlite-0.12-py3-none-any.whl", "yanked": false}], "0.13": [{"comment_text": "", "digests": {"md5": "88827735b50cac2d9cf689240f8962b9", "sha256": "d9d010772078934284d028d48473040311eed3aae81d58201c893e54318dc817"}, "downloads": -1, "filename": "twitter_to_sqlite-0.13-py3-none-any.whl", "has_sig": false, "md5_digest": "88827735b50cac2d9cf689240f8962b9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22798, "upload_time": "2019-10-30T02:21:41", "upload_time_iso_8601": "2019-10-30T02:21:41.735272Z", "url": "https://files.pythonhosted.org/packages/06/48/595cae6b8e6afe4dae8a9b38674acbbe87627b58fe9fa41cfcae356eaee9/twitter_to_sqlite-0.13-py3-none-any.whl", "yanked": false}], "0.14": [{"comment_text": "", "digests": {"md5": "f25a8a209e6125edb33087c491da91b6", "sha256": "253dbece5193ed47cf386024f1d03f66fd468758a525829a2940be0b83b00a8b"}, "downloads": -1, "filename": "twitter_to_sqlite-0.14-py3-none-any.whl", "has_sig": false, "md5_digest": "f25a8a209e6125edb33087c491da91b6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23464, "upload_time": "2019-11-04T05:33:44", "upload_time_iso_8601": "2019-11-04T05:33:44.291639Z", "url": "https://files.pythonhosted.org/packages/b0/d1/5564277562489b3a47a45f6bd2a8311855192be6127ef1662c61144a98a0/twitter_to_sqlite-0.14-py3-none-any.whl", "yanked": false}], "0.15": [{"comment_text": "", "digests": {"md5": "a1697840771deb2ab55bc5993b254f20", "sha256": "34d805fca85575e05688a13d8f06348e3edc138ed0a1769b975195898f86bc62"}, "downloads": -1, "filename": "twitter_to_sqlite-0.15-py3-none-any.whl", "has_sig": false, "md5_digest": "a1697840771deb2ab55bc5993b254f20", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23622, "upload_time": "2019-11-09T20:13:18", "upload_time_iso_8601": "2019-11-09T20:13:18.510125Z", "url": "https://files.pythonhosted.org/packages/b9/8f/174cbab84f2e749a4c7e11a2fa6321566d3e51a1833e8b6711d5314d17fd/twitter_to_sqlite-0.15-py3-none-any.whl", "yanked": false}], "0.16": [{"comment_text": "", "digests": {"md5": "f7fdf97c5903e80cda0a04b5df59dd20", "sha256": "89d960d21b0e5db50c2b1c68c7b2d71fe40620d80f3dd08cb1df0ed85f8e944a"}, "downloads": -1, "filename": "twitter_to_sqlite-0.16-py3-none-any.whl", "has_sig": false, "md5_digest": "f7fdf97c5903e80cda0a04b5df59dd20", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23949, "upload_time": "2020-02-07T07:44:13", "upload_time_iso_8601": "2020-02-07T07:44:13.106408Z", "url": "https://files.pythonhosted.org/packages/53/1d/7ddd91b8b930074d5fd73610c0165fb2cfa2df268154f09ce9f6211973ad/twitter_to_sqlite-0.16-py3-none-any.whl", "yanked": false}], "0.17": [{"comment_text": "", "digests": {"md5": "2ed32ecb1762770ba155e20f57a6b303", "sha256": "6194a029bee0a2497c083dbb0ffccc1675233d79140376eb2577b3975d25d011"}, "downloads": -1, "filename": "twitter_to_sqlite-0.17-py3-none-any.whl", "has_sig": false, "md5_digest": "2ed32ecb1762770ba155e20f57a6b303", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23984, "upload_time": "2020-03-20T19:23:42", "upload_time_iso_8601": "2020-03-20T19:23:42.929210Z", "url": "https://files.pythonhosted.org/packages/80/dd/b4bd9a360a193cc67a92f0392d5b631df6086baf54c45c4d56008421888b/twitter_to_sqlite-0.17-py3-none-any.whl", "yanked": false}], "0.18": [{"comment_text": "", "digests": {"md5": "dd9c6fc234369628b0659a5e063a2eaa", "sha256": "9a4221b5de6fa5fe48f3f6fa39b670035a8cf98b6a4fa8cb6e244cb70ef18d4d"}, "downloads": -1, "filename": "twitter_to_sqlite-0.18-py3-none-any.whl", "has_sig": false, "md5_digest": "dd9c6fc234369628b0659a5e063a2eaa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24345, "upload_time": "2020-03-20T20:17:56", "upload_time_iso_8601": "2020-03-20T20:17:56.434676Z", "url": "https://files.pythonhosted.org/packages/a5/85/f5bd77497aaf3630f7e24cf6ca8e8e5b98d19320066dbdcd8c339c41838a/twitter_to_sqlite-0.18-py3-none-any.whl", "yanked": false}], "0.19": [{"comment_text": "", "digests": {"md5": "4af72f634b222b21e0cacd1c4df24a5d", "sha256": "f3410bf296a1b7403626dff44a884eb1cfe0238d39e060ff0756a4083c3ecc2a"}, "downloads": -1, "filename": "twitter_to_sqlite-0.19-py3-none-any.whl", "has_sig": false, "md5_digest": "4af72f634b222b21e0cacd1c4df24a5d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 24457, "upload_time": "2020-03-20T23:16:08", "upload_time_iso_8601": "2020-03-20T23:16:08.163407Z", "url": "https://files.pythonhosted.org/packages/1e/da/5d518c70d49b2931a10b2c0ba2ecc842550601632b4595389a3517d9b15f/twitter_to_sqlite-0.19-py3-none-any.whl", "yanked": false}], "0.1a0": [{"comment_text": "", "digests": {"md5": "baad4eda6a2b1529dbb1188132017709", "sha256": "5fa9f50fef0ec1cd56082851c116b4036d92a21ecaa08c014a6f76a7306ebd50"}, "downloads": -1, "filename": "twitter_to_sqlite-0.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "baad4eda6a2b1529dbb1188132017709", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7900, "upload_time": "2019-09-03T20:44:01", "upload_time_iso_8601": "2019-09-03T20:44:01.429074Z", "url": "https://files.pythonhosted.org/packages/da/68/5ddea6bc55f9dd53320e3ccde25039e87bec9fa6ff4fe0f8654e31b004b2/twitter_to_sqlite-0.1a0-py3-none-any.whl", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "be138eb3dc682a96b580e80f99f2b174", "sha256": "0848c04945cdcc069113d3ea6807df4491d2bbbfe87c60c844949026258cf82d"}, "downloads": -1, "filename": "twitter_to_sqlite-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "be138eb3dc682a96b580e80f99f2b174", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10473, "upload_time": "2019-09-04T21:18:25", "upload_time_iso_8601": "2019-09-04T21:18:25.732250Z", "url": "https://files.pythonhosted.org/packages/79/45/de4ccf3bb1dd7ed7fa324850074dd3bc0fe662a82f28b18320098570a859/twitter_to_sqlite-0.2-py3-none-any.whl", "yanked": false}], "0.20": [{"comment_text": "", "digests": {"md5": "f58166b0968983a348b643bef24287d6", "sha256": "fe67882e719f668114d1e9e56ba9246d932d727aeaaa0558a6325b239c05319f"}, "downloads": -1, "filename": "twitter_to_sqlite-0.20-py3-none-any.whl", "has_sig": false, "md5_digest": "f58166b0968983a348b643bef24287d6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25205, "upload_time": "2020-04-01T04:19:08", "upload_time_iso_8601": "2020-04-01T04:19:08.556220Z", "url": "https://files.pythonhosted.org/packages/30/c1/28ecbc57b5067cdcccbeff53033b290fc5e0c1bc561de2c19ed47dcfc0cf/twitter_to_sqlite-0.20-py3-none-any.whl", "yanked": false}], "0.20.1": [{"comment_text": "", "digests": {"md5": "2db361ea128c887defa07b88b563b3c7", "sha256": "c9d38a24129c16b38e8941f742a367f789918f55c5656e6ffdcc49cac90ec970"}, "downloads": -1, "filename": "twitter_to_sqlite-0.20.1-py3-none-any.whl", "has_sig": false, "md5_digest": "2db361ea128c887defa07b88b563b3c7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25239, "upload_time": "2020-04-01T04:34:05", "upload_time_iso_8601": "2020-04-01T04:34:05.038585Z", "url": "https://files.pythonhosted.org/packages/07/ce/22a76b0a47b0d93151cbcd97dea64d5a29037ca2dddb866cfe6398f4e928/twitter_to_sqlite-0.20.1-py3-none-any.whl", "yanked": false}], "0.21": [{"comment_text": "", "digests": {"md5": "1e64f1b350cb8d4fc3a91fcf5a2f6703", "sha256": "f2551f119a0655224789d199b70202b65a5ff46ecf75fbee9990861d31990e20"}, "downloads": -1, "filename": "twitter_to_sqlite-0.21-py3-none-any.whl", "has_sig": false, "md5_digest": "1e64f1b350cb8d4fc3a91fcf5a2f6703", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25673, "upload_time": "2020-04-17T23:47:45", "upload_time_iso_8601": "2020-04-17T23:47:45.216645Z", "url": "https://files.pythonhosted.org/packages/fb/e9/8ea94a2a292a7f414319219b924893d3b93a85d2ad0539d65dec27c1845e/twitter_to_sqlite-0.21-py3-none-any.whl", "yanked": false}], "0.21.1": [{"comment_text": "", "digests": {"md5": "42429c392b781d582b6f85cae6306212", "sha256": "3a722d753cc303823554f7837fcfd90f3eef1e8e124438d57373c9cada7f0cfa"}, "downloads": -1, "filename": "twitter_to_sqlite-0.21.1-py3-none-any.whl", "has_sig": false, "md5_digest": "42429c392b781d582b6f85cae6306212", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25723, "upload_time": "2020-04-30T18:22:28", "upload_time_iso_8601": "2020-04-30T18:22:28.084718Z", "url": "https://files.pythonhosted.org/packages/a8/51/0c31ba39f25efcc8182e89874574fac32c364f0e383fb79fb6dc9dacca67/twitter_to_sqlite-0.21.1-py3-none-any.whl", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "584062071144b423ba369ab501147982", "sha256": "9d9caca4f2129a0ace5622e45b75cc644f30ad1b68ff3b129ff3fe5cc18d968c"}, "downloads": -1, "filename": "twitter_to_sqlite-0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "584062071144b423ba369ab501147982", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10714, "upload_time": "2019-09-04T22:11:36", "upload_time_iso_8601": "2019-09-04T22:11:36.556811Z", "url": "https://files.pythonhosted.org/packages/ed/eb/a03e1d51b4d195aca8fa8b7cb4203e9a816f4e0e035bc02b96eb038d4e70/twitter_to_sqlite-0.3-py3-none-any.whl", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "5cb1380af15fd7f899cd54ebf8d33d31", "sha256": "fedfada7b50302054e98cb3ab9693189ce96b0c34393b5893ba66c2f9169abda"}, "downloads": -1, "filename": "twitter_to_sqlite-0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "5cb1380af15fd7f899cd54ebf8d33d31", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12266, "upload_time": "2019-09-09T22:42:43", "upload_time_iso_8601": "2019-09-09T22:42:43.050607Z", "url": "https://files.pythonhosted.org/packages/6d/3f/950f3eb7040cc06e44bcebf455a20e9cec2459da26dbeb4b55386d803181/twitter_to_sqlite-0.4-py3-none-any.whl", "yanked": false}], "0.5": [{"comment_text": "", "digests": {"md5": "9246f7c567e48b1a1b12f7ef729da063", "sha256": "30364b6d7eaf4e7507406fa22fbef9e6aa878b421cdbf93bb0beaef3a08c3dab"}, "downloads": -1, "filename": "twitter_to_sqlite-0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "9246f7c567e48b1a1b12f7ef729da063", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13414, "upload_time": "2019-09-10T17:40:18", "upload_time_iso_8601": "2019-09-10T17:40:18.939940Z", "url": "https://files.pythonhosted.org/packages/f0/03/18fcc8bbb50a46facbbfb0fd34b57744d9ddec26c2685ebabd4469127737/twitter_to_sqlite-0.5-py3-none-any.whl", "yanked": false}], "0.6": [{"comment_text": "", "digests": {"md5": "0c6b485e42d194a73769c7d9cc2ca4ee", "sha256": "00a9ea33d34fc044e3c9dadb2de60107c1520b0c732df403d4bbf37b7e7719c7"}, "downloads": -1, "filename": "twitter_to_sqlite-0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "0c6b485e42d194a73769c7d9cc2ca4ee", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 15759, "upload_time": "2019-10-06T04:50:13", "upload_time_iso_8601": "2019-10-06T04:50:13.090672Z", "url": "https://files.pythonhosted.org/packages/5a/07/7bd67b69f995205343897bbcfb767d13d4633339cc791716ee148dbe939a/twitter_to_sqlite-0.6-py3-none-any.whl", "yanked": false}], "0.7": [{"comment_text": "", "digests": {"md5": "18a87db4d34133588222716c4309957d", "sha256": "325ee8f7f6362cc412de2e98b45dc01af4f5e402d9811fd3ebc71167b356eb0e"}, "downloads": -1, "filename": "twitter_to_sqlite-0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "18a87db4d34133588222716c4309957d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 16271, "upload_time": "2019-10-07T00:33:40", "upload_time_iso_8601": "2019-10-07T00:33:40.256062Z", "url": "https://files.pythonhosted.org/packages/23/c5/37d64965b71beb6b1765387db59ed7b52fd762c23b1d0f58656146eacdc0/twitter_to_sqlite-0.7-py3-none-any.whl", "yanked": false}], "0.8": [{"comment_text": "", "digests": {"md5": "7d37db4cce0a0e7fc6b3c516f2393bae", "sha256": "40de8b46ffa8a1b187b0a03f4164fbf9adef2d0ce5d0d1a9c6d4356cf25ea7d1"}, "downloads": -1, "filename": "twitter_to_sqlite-0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "7d37db4cce0a0e7fc6b3c516f2393bae", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 18925, "upload_time": "2019-10-11T06:47:28", "upload_time_iso_8601": "2019-10-11T06:47:28.341969Z", "url": "https://files.pythonhosted.org/packages/07/17/f2618f9f98493e93381becd9741c97618aaf3420304f956fab7022406453/twitter_to_sqlite-0.8-py3-none-any.whl", "yanked": false}], "0.9": [{"comment_text": "", "digests": {"md5": "39284f31f5af7c5c0e4f4c2e702f2d85", "sha256": "811860e5d25f77a4fc94ca5e58d3628f81352fc00d5c0a7b1bae2fcf835d54b0"}, "downloads": -1, "filename": "twitter_to_sqlite-0.9-py3-none-any.whl", "has_sig": false, "md5_digest": "39284f31f5af7c5c0e4f4c2e702f2d85", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 19569, "upload_time": "2019-10-11T16:58:10", "upload_time_iso_8601": "2019-10-11T16:58:10.923167Z", "url": "https://files.pythonhosted.org/packages/19/17/dd0b894eb34be76485b0d9af908d91c7e0f780dcdb73a6a8ee06d1bf050a/twitter_to_sqlite-0.9-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "42429c392b781d582b6f85cae6306212", "sha256": "3a722d753cc303823554f7837fcfd90f3eef1e8e124438d57373c9cada7f0cfa"}, "downloads": -1, "filename": "twitter_to_sqlite-0.21.1-py3-none-any.whl", "has_sig": false, "md5_digest": "42429c392b781d582b6f85cae6306212", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25723, "upload_time": "2020-04-30T18:22:28", "upload_time_iso_8601": "2020-04-30T18:22:28.084718Z", "url": "https://files.pythonhosted.org/packages/a8/51/0c31ba39f25efcc8182e89874574fac32c364f0e383fb79fb6dc9dacca67/twitter_to_sqlite-0.21.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:43:32 2020"}