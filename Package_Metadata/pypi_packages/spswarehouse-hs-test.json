{"info": {"author": "Harry Li Consulting, LLC", "author_email": "hcli.consulting@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3"], "description": "# spswarehouse\n\n# Prerequisites\n\n- Anaconda & Python 3\n- Jupyter Notebook\n\n# Installation\n\n- To install, run: `pip install spswarehouse`\n    - This can be done from `Anaconda Prompt` from the Start Menu.\n- Locate the install directory by running: `pip show pip | grep \"Location:\" | cut -d \" \" -f2`\n    - If this doesn't work, run `pip show pip`, then look at the line \"Location:\".\n\nThe files referred to in this `README` are in `<install-directory>/spswarehouse/`.\n\n## Set up dependencies\n\n- Change to the `spswarehouse` directory\n    - `cd <install-directory>\\spswarehouse`\n    - The default for Anaconda3 is `cd Anaconda3\\Lib\\site-packages\\spswarehouse`\n- Run: `pip install -r requirements.txt`\n\nYou can `exit` the Anaconda Prompt; the next step is more easily done in the File Explorer.\n\n## Set up credentials\n\nThe default directory where this module is installed is `Users\\<your name>\\Anaconda3\\Lib\\site-packages\\spswarehouse`. Your credentials are in the `spswarehouse` subdirectory.\n\n- Copy the `credentials.py.template` file to `credentials.py`.\n\n### Snowflake\n\nThis allows you to access the Snowflake data warehouse.\n\n- Fill in your Snowflake `user` and `password`  credentials between quotation marks.\n\n### Google Sheets\n\nThis allows you to access your Google spreadsheets.\n\n- Get the `private_key` for the Google Service account from your team.\n- In `credentials.py`, under `google_config` and `service-account`, fill in the `private_key` between quotation marks.\n- The first time you `import` the `GoogleSheets` module, the service account's email address will be printed, you will share any spreadsheets you want to access with that email address.\n\n# Usage\n\n## Snowflake\n\nYour Snowflake connection is configured in `credentials.py` (see above).\n\nSnowflake access is implemented in by `Warehouse`. You can:\n- Read data using `read_sql()`\n- Reflect a table using `reflect_table()`\n- Run a SQL command using `execute()`\n\n### Table & column name tab-completion\n\nWhen you run `import spswarehouse`, some tab-completion for table and column names is automatically set up.\n\nThe format is:\n\n```\nspswarehouse.<schema_name>.<table name>.c_<column name>\n```\n\nTo reduce load time, tab-completion is automatically set up for only a few schemas when `spswarehouse`is imported.\n\nIf the schema you're using isn't tab-completing you can manually import it.\n\nFor example, to enable tab-competion for the schema `schoolmint`, run:\n\n```\nfrom spswarehouse.table_names import *\n\ninitialize_schema_object(SchoolMint)\nschoolmint = SchoolMint()\n```\n\n### Uploading data\n\nThe `table_utils` module implements uploading data to the Snowflake warehouse.\n\nThe data sources you can upload from are:\n\n- pandas.DataFrame `dataframe`\n- CSV file `csv_filename`\n- Google Sheet `google_sheet`\n\nThe two major methods are `create_table_stmt` and `upload_to_warehouse`. Both support the above data sources as optional arguments:\n\n - `dataframe`\n - `csv_filename`\n - `google_sheet`\n\nFrom Jupyter Notebook, open `snowflake-upload-example.ipynb` for a basic example.\n\n### Column types\n\n`create_table_stmt()` will try to guess column types when given a DataFrame, CSV file, or Google Sheet.  \n\nIf you want to explicitly name and type your columns, you can pass in the `columns` argument instead.\n\nSee the documentation for `guess_col_types()` for best practices for types.\n\n## Google Sheets\n\nMake sure you've set up `credentials.py` first and shared your spreadsheet with the Google service account email. You can also get the email by running:\n\n```\nGoogleSheets.get_google_service_account_email()\n```\n\nThe Info Team service account e-mail is `jupyter-sheets@sps-warehouse.iam.gserviceaccount.com`\n\n`GoogleSheets` is really an instance of `gspread.Client`, so you use the entire\n[`gspread`](https://gspread.readthedocs.io/en/latest/) Python API.\n\n### Accessing data\n\nFrom Jupyter Notebook, open and run `googlesheets-example.ipynb` for a basic example on loading a spreadsheet and reading sheet data into `pandas.DataFrame`.\n\n### Uploading to warehouse\n\nFrom Jupyter Notebook open and run `snowflake-upload-example.ipynb` for a basic example on uploading Google Sheet data to the Snowflake warehouse.\n\n### Column types\n\n# Developer notes\n\n## Google service account key\n\nThis lets us use the Google Sheets API to access sheet data. It only has to be done once and added to `credentials.py.template`.\n\n- Use an existing Google Developer project, or create a new one: https://console.cloud.google.com\n- Enable the Google Sheets API\n  - Go to **API & Services** for the project, then **Libraries**.\n  - Search for \"Google Sheets\" and select the result.\n  - Click **Enable**.\n- Create the OAuth client credentials\n  - Go to **API & Services** for the project, then **Credentials**.\n  - Under **Create credentials**, select **Service account key**\n  - Choose an existing service account or create a new one to associate this key with.\n  - Create the key and download the key as a JSON file.\n- Copy OAuth client credentials to `credentials.py.template` in `google_client` under `service-account`.\n- **Delete the private_key** and leave just the quotation marks when you check in `credentials.template.py`.\n- You will need to distribute the private key securely so it can be added to `credentials.py`.\n\n## PyPI\n\nWe use [PyPI](https://pypi.org/) to distribute the `spswarehouse` module and [Test PyPI](https://test.pypi.org/)  for testing.\n\nThe `spswarehouse` project is [here](https://pypi.org/project/spswarehouse/).\n\n### Set up\n\nCreate PyPI and Test PyPI accounts to test and upload packages.\n\n### Packaging\n\nSee https://packaging.python.org/tutorials/packaging-projects/ for an overview and walk-through of PyPI packaging.\n\nSpecifics for `spswarehouse`:\n\n- Only build the `sdist` package. Otherwise, `credentials.py` and potentially passwords will get distributed in the binary distribution.\n- If you need to include non-Python files, add them to `MANIFEST.in`.\n\n### Testing\n\n- Update version number in `setup.py`.\n- Create the package:\n`python setup.py sdist`\n- Upload to Test PyPI:\n`python -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*`\n- Install on local machine to test: `pip install -i https://test.pypi.org/simple/`\n\n### Pushing a new package\n\nMake sure all of your changes are checked into the GitHub repository and your local repository is up-to-date before you do this.\n\nThe steps are the same as in the above section, omitting the `test.pypi` URLs.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/SummitPublicSchools/spswarehouse", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "spswarehouse-hs-test", "package_url": "https://pypi.org/project/spswarehouse-hs-test/", "platform": "", "project_url": "https://pypi.org/project/spswarehouse-hs-test/", "project_urls": {"Homepage": "https://github.com/SummitPublicSchools/spswarehouse"}, "release_url": "https://pypi.org/project/spswarehouse-hs-test/0.0.3/", "requires_dist": null, "requires_python": "", "summary": "Summit Public Schools Snowflake warehouse", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>spswarehouse</h1>\n<h1>Prerequisites</h1>\n<ul>\n<li>Anaconda &amp; Python 3</li>\n<li>Jupyter Notebook</li>\n</ul>\n<h1>Installation</h1>\n<ul>\n<li>To install, run: <code>pip install spswarehouse</code>\n<ul>\n<li>This can be done from <code>Anaconda Prompt</code> from the Start Menu.</li>\n</ul>\n</li>\n<li>Locate the install directory by running: <code>pip show pip | grep \"Location:\" | cut -d \" \" -f2</code>\n<ul>\n<li>If this doesn't work, run <code>pip show pip</code>, then look at the line \"Location:\".</li>\n</ul>\n</li>\n</ul>\n<p>The files referred to in this <code>README</code> are in <code>&lt;install-directory&gt;/spswarehouse/</code>.</p>\n<h2>Set up dependencies</h2>\n<ul>\n<li>Change to the <code>spswarehouse</code> directory\n<ul>\n<li><code>cd &lt;install-directory&gt;\\spswarehouse</code></li>\n<li>The default for Anaconda3 is <code>cd Anaconda3\\Lib\\site-packages\\spswarehouse</code></li>\n</ul>\n</li>\n<li>Run: <code>pip install -r requirements.txt</code></li>\n</ul>\n<p>You can <code>exit</code> the Anaconda Prompt; the next step is more easily done in the File Explorer.</p>\n<h2>Set up credentials</h2>\n<p>The default directory where this module is installed is <code>Users\\&lt;your name&gt;\\Anaconda3\\Lib\\site-packages\\spswarehouse</code>. Your credentials are in the <code>spswarehouse</code> subdirectory.</p>\n<ul>\n<li>Copy the <code>credentials.py.template</code> file to <code>credentials.py</code>.</li>\n</ul>\n<h3>Snowflake</h3>\n<p>This allows you to access the Snowflake data warehouse.</p>\n<ul>\n<li>Fill in your Snowflake <code>user</code> and <code>password</code>  credentials between quotation marks.</li>\n</ul>\n<h3>Google Sheets</h3>\n<p>This allows you to access your Google spreadsheets.</p>\n<ul>\n<li>Get the <code>private_key</code> for the Google Service account from your team.</li>\n<li>In <code>credentials.py</code>, under <code>google_config</code> and <code>service-account</code>, fill in the <code>private_key</code> between quotation marks.</li>\n<li>The first time you <code>import</code> the <code>GoogleSheets</code> module, the service account's email address will be printed, you will share any spreadsheets you want to access with that email address.</li>\n</ul>\n<h1>Usage</h1>\n<h2>Snowflake</h2>\n<p>Your Snowflake connection is configured in <code>credentials.py</code> (see above).</p>\n<p>Snowflake access is implemented in by <code>Warehouse</code>. You can:</p>\n<ul>\n<li>Read data using <code>read_sql()</code></li>\n<li>Reflect a table using <code>reflect_table()</code></li>\n<li>Run a SQL command using <code>execute()</code></li>\n</ul>\n<h3>Table &amp; column name tab-completion</h3>\n<p>When you run <code>import spswarehouse</code>, some tab-completion for table and column names is automatically set up.</p>\n<p>The format is:</p>\n<pre><code>spswarehouse.&lt;schema_name&gt;.&lt;table name&gt;.c_&lt;column name&gt;\n</code></pre>\n<p>To reduce load time, tab-completion is automatically set up for only a few schemas when <code>spswarehouse</code>is imported.</p>\n<p>If the schema you're using isn't tab-completing you can manually import it.</p>\n<p>For example, to enable tab-competion for the schema <code>schoolmint</code>, run:</p>\n<pre><code>from spswarehouse.table_names import *\n\ninitialize_schema_object(SchoolMint)\nschoolmint = SchoolMint()\n</code></pre>\n<h3>Uploading data</h3>\n<p>The <code>table_utils</code> module implements uploading data to the Snowflake warehouse.</p>\n<p>The data sources you can upload from are:</p>\n<ul>\n<li>pandas.DataFrame <code>dataframe</code></li>\n<li>CSV file <code>csv_filename</code></li>\n<li>Google Sheet <code>google_sheet</code></li>\n</ul>\n<p>The two major methods are <code>create_table_stmt</code> and <code>upload_to_warehouse</code>. Both support the above data sources as optional arguments:</p>\n<ul>\n<li><code>dataframe</code></li>\n<li><code>csv_filename</code></li>\n<li><code>google_sheet</code></li>\n</ul>\n<p>From Jupyter Notebook, open <code>snowflake-upload-example.ipynb</code> for a basic example.</p>\n<h3>Column types</h3>\n<p><code>create_table_stmt()</code> will try to guess column types when given a DataFrame, CSV file, or Google Sheet.</p>\n<p>If you want to explicitly name and type your columns, you can pass in the <code>columns</code> argument instead.</p>\n<p>See the documentation for <code>guess_col_types()</code> for best practices for types.</p>\n<h2>Google Sheets</h2>\n<p>Make sure you've set up <code>credentials.py</code> first and shared your spreadsheet with the Google service account email. You can also get the email by running:</p>\n<pre><code>GoogleSheets.get_google_service_account_email()\n</code></pre>\n<p>The Info Team service account e-mail is <code>jupyter-sheets@sps-warehouse.iam.gserviceaccount.com</code></p>\n<p><code>GoogleSheets</code> is really an instance of <code>gspread.Client</code>, so you use the entire\n<a href=\"https://gspread.readthedocs.io/en/latest/\" rel=\"nofollow\"><code>gspread</code></a> Python API.</p>\n<h3>Accessing data</h3>\n<p>From Jupyter Notebook, open and run <code>googlesheets-example.ipynb</code> for a basic example on loading a spreadsheet and reading sheet data into <code>pandas.DataFrame</code>.</p>\n<h3>Uploading to warehouse</h3>\n<p>From Jupyter Notebook open and run <code>snowflake-upload-example.ipynb</code> for a basic example on uploading Google Sheet data to the Snowflake warehouse.</p>\n<h3>Column types</h3>\n<h1>Developer notes</h1>\n<h2>Google service account key</h2>\n<p>This lets us use the Google Sheets API to access sheet data. It only has to be done once and added to <code>credentials.py.template</code>.</p>\n<ul>\n<li>Use an existing Google Developer project, or create a new one: <a href=\"https://console.cloud.google.com\" rel=\"nofollow\">https://console.cloud.google.com</a></li>\n<li>Enable the Google Sheets API\n<ul>\n<li>Go to <strong>API &amp; Services</strong> for the project, then <strong>Libraries</strong>.</li>\n<li>Search for \"Google Sheets\" and select the result.</li>\n<li>Click <strong>Enable</strong>.</li>\n</ul>\n</li>\n<li>Create the OAuth client credentials\n<ul>\n<li>Go to <strong>API &amp; Services</strong> for the project, then <strong>Credentials</strong>.</li>\n<li>Under <strong>Create credentials</strong>, select <strong>Service account key</strong></li>\n<li>Choose an existing service account or create a new one to associate this key with.</li>\n<li>Create the key and download the key as a JSON file.</li>\n</ul>\n</li>\n<li>Copy OAuth client credentials to <code>credentials.py.template</code> in <code>google_client</code> under <code>service-account</code>.</li>\n<li><strong>Delete the private_key</strong> and leave just the quotation marks when you check in <code>credentials.template.py</code>.</li>\n<li>You will need to distribute the private key securely so it can be added to <code>credentials.py</code>.</li>\n</ul>\n<h2>PyPI</h2>\n<p>We use <a href=\"https://pypi.org/\" rel=\"nofollow\">PyPI</a> to distribute the <code>spswarehouse</code> module and <a href=\"https://test.pypi.org/\" rel=\"nofollow\">Test PyPI</a>  for testing.</p>\n<p>The <code>spswarehouse</code> project is <a href=\"https://pypi.org/project/spswarehouse/\" rel=\"nofollow\">here</a>.</p>\n<h3>Set up</h3>\n<p>Create PyPI and Test PyPI accounts to test and upload packages.</p>\n<h3>Packaging</h3>\n<p>See <a href=\"https://packaging.python.org/tutorials/packaging-projects/\" rel=\"nofollow\">https://packaging.python.org/tutorials/packaging-projects/</a> for an overview and walk-through of PyPI packaging.</p>\n<p>Specifics for <code>spswarehouse</code>:</p>\n<ul>\n<li>Only build the <code>sdist</code> package. Otherwise, <code>credentials.py</code> and potentially passwords will get distributed in the binary distribution.</li>\n<li>If you need to include non-Python files, add them to <code>MANIFEST.in</code>.</li>\n</ul>\n<h3>Testing</h3>\n<ul>\n<li>Update version number in <code>setup.py</code>.</li>\n<li>Create the package:\n<code>python setup.py sdist</code></li>\n<li>Upload to Test PyPI:\n<code>python -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*</code></li>\n<li>Install on local machine to test: <code>pip install -i https://test.pypi.org/simple/</code></li>\n</ul>\n<h3>Pushing a new package</h3>\n<p>Make sure all of your changes are checked into the GitHub repository and your local repository is up-to-date before you do this.</p>\n<p>The steps are the same as in the above section, omitting the <code>test.pypi</code> URLs.</p>\n\n          </div>"}, "last_serial": 5309731, "releases": {"0.0.3": [{"comment_text": "", "digests": {"md5": "147e6fd7f98370601b0019d9f2916b7f", "sha256": "a799b97a087f6eb0e150a2a5faf7840f84041734ca245c98924f7931ac16b9dc"}, "downloads": -1, "filename": "spswarehouse-hs-test-0.0.3.tar.gz", "has_sig": false, "md5_digest": "147e6fd7f98370601b0019d9f2916b7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9748, "upload_time": "2019-05-23T22:20:16", "upload_time_iso_8601": "2019-05-23T22:20:16.299527Z", "url": "https://files.pythonhosted.org/packages/47/be/d8625ded85eeb4f83516318c6e98d3752b9bdc78a949e19ca73f36ccf769/spswarehouse-hs-test-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "147e6fd7f98370601b0019d9f2916b7f", "sha256": "a799b97a087f6eb0e150a2a5faf7840f84041734ca245c98924f7931ac16b9dc"}, "downloads": -1, "filename": "spswarehouse-hs-test-0.0.3.tar.gz", "has_sig": false, "md5_digest": "147e6fd7f98370601b0019d9f2916b7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9748, "upload_time": "2019-05-23T22:20:16", "upload_time_iso_8601": "2019-05-23T22:20:16.299527Z", "url": "https://files.pythonhosted.org/packages/47/be/d8625ded85eeb4f83516318c6e98d3752b9bdc78a949e19ca73f36ccf769/spswarehouse-hs-test-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:04:13 2020"}