{"info": {"author": "Qubole", "author_email": "dev@qubole.com", "bugtrack_url": null, "classifiers": [], "description": "# afctl\n\nThe proposed CLI tool is authored to make creating and deployment of airflow projects faster and smoother. \nAs of now, there is no tool out there that can empower the user to create a boilerplate code structure for airflow \nprojects and make development + deployment of projects seamless.\n\n## Requirements\n* Python 3.5+\n* Docker\n\n## Getting Started\n\n### 1. Installation\n\nCreate a new python virtualenv. You can use the following command. <br />\n```bash\npython3 -m venv <name>\n```\nActivate your virtualenv<br/>\n```bash\nsource /path_to_venv/bin/activate\n```\n\n```bash\npip3 install afctl\n```\n\n\n### 2. Initialize a new afctl project. \nThe project is created in your present working directory. Along with this a configuration file with the same name is \ngenerated in **/home/.afctl_configs** directory.\n\n\n```bash\nafctl init <name of the project>\n```\nEg.\n```bash\nafctl init project_demo\n```\n* The following directory structure will be generated\n```bash\n.\n\u251c\u2500\u2500 deployments\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 project_demo-docker-compose.yml\n\u251c\u2500\u2500 migrations\n\u251c\u2500\u2500 plugins\n\u251c\u2500\u2500 project_demo\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 commons\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dags\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n```\n\nIf you already have a git repository and want to turn it into an afctl project.\nRun the following command :-\n```bash\nafctl init .\n```\n<br>\n\n### 3. Add a new module in the project.\n\n```bash\nafctl generate module -n <name of the module>\n```\n\nThe following directory structure will be generated :\n\n```bash\nafctl generate module -n first_module\nafctl generate module -n second_module\n\n.\n\u251c\u2500\u2500 deployments\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 project_demo-docker-compose.yml\n\u251c\u2500\u2500 migrations\n\u251c\u2500\u2500 plugins\n\u251c\u2500\u2500 project_demo\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 commons\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dags\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 first_module\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 second_module\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 first_module\n    \u2514\u2500\u2500 second_module\n\n```\n\n### 4. Generate dag\n```bash\nafctl generate dag -n <name of dag> -m <name of module>\n```\n\nThe following directory structure will be generate :\n\n```bash\nafctl generate dag -n new -m first_module\n\n.\n\u251c\u2500\u2500 deployments\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 project_demo-docker-compose.yml\n\u251c\u2500\u2500 migrations\n\u251c\u2500\u2500 plugins\n\u251c\u2500\u2500 project_demo\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 commons\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dags\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 first_module\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 new_dag.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 second_module\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 first_module\n    \u2514\u2500\u2500 second_module\n```\n\nThe dag file will look like this :\n\n```python\nfrom airflow import DAG\nfrom datetime import datetime, timedelta\n\ndefault_args = {\n'owner': 'project_demo',\n# 'depends_on_past': ,\n# 'start_date': ,\n# 'email': ,\n# 'email_on_failure': ,\n# 'email_on_retry': ,\n# 'retries': 0\n\n}\n\ndag = DAG(dag_id='new', default_args=default_args, schedule_interval='@once')\n```\n\n### 5. Deploy project locally\n\nYou can add python packages that will be required by your dags in `requirements.txt`. They will automatically get\ninstalled.\n\n* To deploy your project, run the following command (make sure docker is running) :\n\n```bash\nafctl deploy local\n```\n\nIf you do not want to see the logs, you can run \n```bash\nafctl deploy local -d\n```\nThis will run it in detached mode and won't print the logs on the console.\n\n* You can access your airflow webserver on browser at `localhost:8080`\n\n### 6. Deploy project on production\n\n* Here we will be deploying our project to **Qubole**. Sign up at us.qubole.com.\n* add git-origin and access-token (if want to keep the project as private repo\non Github) to the configs. [See how](#manage-configurations)\n* Push the project once completed to Github.\n* Deploying to Qubole will require adding deployment configurations.\n\n```bash\nafctl config add -d qubole -n <name of deployment> -e <env> -c <cluster-label> -t <auth-token>\n```\nThis command will modify your config file. You can see your config file with the following command :\n```bash\nafctl config show\n```\n\nFor example - \n```bash\nafctl config add -d qubole -n demo -e https://api.qubole.com -c airflow_1102 -t khd34djs3\n```\n\n* To deploy run the following command\n```bash\nafctl deploy qubole -n <name>\n```\n\n### The following video also contains all the steps of deploying project using afctl - </br>\nhttps://www.youtube.com/watch?v=A4rcZDGtJME&feature=youtu.be\n\n## Manage configurations\n\nThe configuration file is used for deployment contains the following information.\n```yaml\nglobal:\n-airflow_version:\n-git:\n--origin:\n--access-token:\ndeployment:\n-qubole:\n--local:\n---compose:\n```\n<br>\n\n* `airflow_version` can be added to the project when you initialize the project.\n```bash\nafctl init <name> -v <version>\n```\n\n* global configs (airflow_version, origin, access-token) can all be added/ updated with the following command :\n\n```bash\nafctl config global -o <git-origin> -t <access-token> -v <airflow_version>\n``` \n\n## Usage\n\nCommands right now supported are\n* init\n* config\n* deploy\n* list\n* generate\n\nTo learn more, run \n```bash\nafctl <command> -h\n```\n<br>\n\n### Caution\nNot yet ported for Windows.\n\n#### Credits\nDocker-compose file : https://github.com/puckel/docker-airflow", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/qubole/afctl", "keywords": "airflow cli deployment", "license": "", "maintainer": "", "maintainer_email": "", "name": "afctl", "package_url": "https://pypi.org/project/afctl/", "platform": "", "project_url": "https://pypi.org/project/afctl/", "project_urls": {"Homepage": "https://github.com/qubole/afctl"}, "release_url": "https://pypi.org/project/afctl/0.1.7/", "requires_dist": null, "requires_python": "", "summary": "Python commandline tool to make deployment of Airflow projects easier.", "version": "0.1.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>afctl</h1>\n<p>The proposed CLI tool is authored to make creating and deployment of airflow projects faster and smoother.\nAs of now, there is no tool out there that can empower the user to create a boilerplate code structure for airflow\nprojects and make development + deployment of projects seamless.</p>\n<h2>Requirements</h2>\n<ul>\n<li>Python 3.5+</li>\n<li>Docker</li>\n</ul>\n<h2>Getting Started</h2>\n<h3>1. Installation</h3>\n<p>Create a new python virtualenv. You can use the following command. <br></p>\n<pre>python3 -m venv &lt;name&gt;\n</pre>\n<p>Activate your virtualenv<br></p>\n<pre><span class=\"nb\">source</span> /path_to_venv/bin/activate\n</pre>\n<pre>pip3 install afctl\n</pre>\n<h3>2. Initialize a new afctl project.</h3>\n<p>The project is created in your present working directory. Along with this a configuration file with the same name is\ngenerated in <strong>/home/.afctl_configs</strong> directory.</p>\n<pre>afctl init &lt;name of the project&gt;\n</pre>\n<p>Eg.</p>\n<pre>afctl init project_demo\n</pre>\n<ul>\n<li>The following directory structure will be generated</li>\n</ul>\n<pre>.\n\u251c\u2500\u2500 deployments\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 project_demo-docker-compose.yml\n\u251c\u2500\u2500 migrations\n\u251c\u2500\u2500 plugins\n\u251c\u2500\u2500 project_demo\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 commons\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dags\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n</pre>\n<p>If you already have a git repository and want to turn it into an afctl project.\nRun the following command :-</p>\n<pre>afctl init .\n</pre>\n<br>\n<h3>3. Add a new module in the project.</h3>\n<pre>afctl generate module -n &lt;name of the module&gt;\n</pre>\n<p>The following directory structure will be generated :</p>\n<pre>afctl generate module -n first_module\nafctl generate module -n second_module\n\n.\n\u251c\u2500\u2500 deployments\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 project_demo-docker-compose.yml\n\u251c\u2500\u2500 migrations\n\u251c\u2500\u2500 plugins\n\u251c\u2500\u2500 project_demo\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 commons\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dags\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 first_module\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 second_module\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 first_module\n    \u2514\u2500\u2500 second_module\n</pre>\n<h3>4. Generate dag</h3>\n<pre>afctl generate dag -n &lt;name of dag&gt; -m &lt;name of module&gt;\n</pre>\n<p>The following directory structure will be generate :</p>\n<pre>afctl generate dag -n new -m first_module\n\n.\n\u251c\u2500\u2500 deployments\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 project_demo-docker-compose.yml\n\u251c\u2500\u2500 migrations\n\u251c\u2500\u2500 plugins\n\u251c\u2500\u2500 project_demo\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 commons\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dags\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 first_module\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 new_dag.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 second_module\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 first_module\n    \u2514\u2500\u2500 second_module\n</pre>\n<p>The dag file will look like this :</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">airflow</span> <span class=\"kn\">import</span> <span class=\"n\">DAG</span>\n<span class=\"kn\">from</span> <span class=\"nn\">datetime</span> <span class=\"kn\">import</span> <span class=\"n\">datetime</span><span class=\"p\">,</span> <span class=\"n\">timedelta</span>\n\n<span class=\"n\">default_args</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n<span class=\"s1\">'owner'</span><span class=\"p\">:</span> <span class=\"s1\">'project_demo'</span><span class=\"p\">,</span>\n<span class=\"c1\"># 'depends_on_past': ,</span>\n<span class=\"c1\"># 'start_date': ,</span>\n<span class=\"c1\"># 'email': ,</span>\n<span class=\"c1\"># 'email_on_failure': ,</span>\n<span class=\"c1\"># 'email_on_retry': ,</span>\n<span class=\"c1\"># 'retries': 0</span>\n\n<span class=\"p\">}</span>\n\n<span class=\"n\">dag</span> <span class=\"o\">=</span> <span class=\"n\">DAG</span><span class=\"p\">(</span><span class=\"n\">dag_id</span><span class=\"o\">=</span><span class=\"s1\">'new'</span><span class=\"p\">,</span> <span class=\"n\">default_args</span><span class=\"o\">=</span><span class=\"n\">default_args</span><span class=\"p\">,</span> <span class=\"n\">schedule_interval</span><span class=\"o\">=</span><span class=\"s1\">'@once'</span><span class=\"p\">)</span>\n</pre>\n<h3>5. Deploy project locally</h3>\n<p>You can add python packages that will be required by your dags in <code>requirements.txt</code>. They will automatically get\ninstalled.</p>\n<ul>\n<li>To deploy your project, run the following command (make sure docker is running) :</li>\n</ul>\n<pre>afctl deploy <span class=\"nb\">local</span>\n</pre>\n<p>If you do not want to see the logs, you can run</p>\n<pre>afctl deploy <span class=\"nb\">local</span> -d\n</pre>\n<p>This will run it in detached mode and won't print the logs on the console.</p>\n<ul>\n<li>You can access your airflow webserver on browser at <code>localhost:8080</code></li>\n</ul>\n<h3>6. Deploy project on production</h3>\n<ul>\n<li>Here we will be deploying our project to <strong>Qubole</strong>. Sign up at us.qubole.com.</li>\n<li>add git-origin and access-token (if want to keep the project as private repo\non Github) to the configs. <a href=\"#manage-configurations\" rel=\"nofollow\">See how</a></li>\n<li>Push the project once completed to Github.</li>\n<li>Deploying to Qubole will require adding deployment configurations.</li>\n</ul>\n<pre>afctl config add -d qubole -n &lt;name of deployment&gt; -e &lt;env&gt; -c &lt;cluster-label&gt; -t &lt;auth-token&gt;\n</pre>\n<p>This command will modify your config file. You can see your config file with the following command :</p>\n<pre>afctl config show\n</pre>\n<p>For example -</p>\n<pre>afctl config add -d qubole -n demo -e https://api.qubole.com -c airflow_1102 -t khd34djs3\n</pre>\n<ul>\n<li>To deploy run the following command</li>\n</ul>\n<pre>afctl deploy qubole -n &lt;name&gt;\n</pre>\n<h3>The following video also contains all the steps of deploying project using afctl - <br></h3>\n<p><a href=\"https://www.youtube.com/watch?v=A4rcZDGtJME&amp;feature=youtu.be\" rel=\"nofollow\">https://www.youtube.com/watch?v=A4rcZDGtJME&amp;feature=youtu.be</a></p>\n<h2>Manage configurations</h2>\n<p>The configuration file is used for deployment contains the following information.</p>\n<pre><span class=\"nt\">global</span><span class=\"p\">:</span>\n<span class=\"nt\">-airflow_version</span><span class=\"p\">:</span>\n<span class=\"nt\">-git</span><span class=\"p\">:</span>\n<span class=\"nt\">--origin</span><span class=\"p\">:</span>\n<span class=\"nt\">--access-token</span><span class=\"p\">:</span>\n<span class=\"nt\">deployment</span><span class=\"p\">:</span>\n<span class=\"nt\">-qubole</span><span class=\"p\">:</span>\n<span class=\"nt\">--local</span><span class=\"p\">:</span>\n<span class=\"nt\">---compose</span><span class=\"p\">:</span>\n</pre>\n<br>\n<ul>\n<li><code>airflow_version</code> can be added to the project when you initialize the project.</li>\n</ul>\n<pre>afctl init &lt;name&gt; -v &lt;version&gt;\n</pre>\n<ul>\n<li>global configs (airflow_version, origin, access-token) can all be added/ updated with the following command :</li>\n</ul>\n<pre>afctl config global -o &lt;git-origin&gt; -t &lt;access-token&gt; -v &lt;airflow_version&gt;\n</pre>\n<h2>Usage</h2>\n<p>Commands right now supported are</p>\n<ul>\n<li>init</li>\n<li>config</li>\n<li>deploy</li>\n<li>list</li>\n<li>generate</li>\n</ul>\n<p>To learn more, run</p>\n<pre>afctl &lt;command&gt; -h\n</pre>\n<br>\n<h3>Caution</h3>\n<p>Not yet ported for Windows.</p>\n<h4>Credits</h4>\n<p>Docker-compose file : <a href=\"https://github.com/puckel/docker-airflow\" rel=\"nofollow\">https://github.com/puckel/docker-airflow</a></p>\n\n          </div>"}, "last_serial": 6771436, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "7b7730f6ca76d786e7eda8192f505e92", "sha256": "106716904ec68ba13cde11e32ad87d6502909231728c2234e24c1a772453367f"}, "downloads": -1, "filename": "afctl-0.1.1.tar.gz", "has_sig": false, "md5_digest": "7b7730f6ca76d786e7eda8192f505e92", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27357, "upload_time": "2020-01-22T06:15:31", "upload_time_iso_8601": "2020-01-22T06:15:31.104903Z", "url": "https://files.pythonhosted.org/packages/1d/39/88b8beb50077e344aa88acb2b2ca5dc8658bacd30b1fed773e3d8b9e65bc/afctl-0.1.1.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "a16e9de0b11388aa30ed24c2e386caee", "sha256": "f1182cf33051dd1e78c301c8b895a2a38bcd245796b0f28a7f00e396e5790636"}, "downloads": -1, "filename": "afctl-0.1.5.tar.gz", "has_sig": false, "md5_digest": "a16e9de0b11388aa30ed24c2e386caee", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29120, "upload_time": "2020-01-22T07:38:26", "upload_time_iso_8601": "2020-01-22T07:38:26.274552Z", "url": "https://files.pythonhosted.org/packages/cc/eb/edde99420b798924715c7509fe1e4b03a6de8b3c0b209cde215726a86083/afctl-0.1.5.tar.gz", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "7dd211852667b3ecc62383f93fc480f3", "sha256": "1b23ecb28398ec498e312e868ef4edc1a096851abd13ff06de660f96c951a913"}, "downloads": -1, "filename": "afctl-0.1.6.tar.gz", "has_sig": false, "md5_digest": "7dd211852667b3ecc62383f93fc480f3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29477, "upload_time": "2020-02-07T06:38:00", "upload_time_iso_8601": "2020-02-07T06:38:00.245865Z", "url": "https://files.pythonhosted.org/packages/18/2a/6c29efd57035b3108064cca626d386bad398a185a56589af8591e69c9741/afctl-0.1.6.tar.gz", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "0a698ed0b9fa4e6a50ea23a749ef6276", "sha256": "33e6dd4fd7375a1860369baf71ed784899f5993030e3daf129dc6efdfe3794e2"}, "downloads": -1, "filename": "afctl-0.1.7.tar.gz", "has_sig": false, "md5_digest": "0a698ed0b9fa4e6a50ea23a749ef6276", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30467, "upload_time": "2020-03-08T11:06:25", "upload_time_iso_8601": "2020-03-08T11:06:25.332567Z", "url": "https://files.pythonhosted.org/packages/59/ef/ffab7d65fc6c9930478e7a7d8525a3ee6d5456ac3479aa438eb1b2beeb99/afctl-0.1.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0a698ed0b9fa4e6a50ea23a749ef6276", "sha256": "33e6dd4fd7375a1860369baf71ed784899f5993030e3daf129dc6efdfe3794e2"}, "downloads": -1, "filename": "afctl-0.1.7.tar.gz", "has_sig": false, "md5_digest": "0a698ed0b9fa4e6a50ea23a749ef6276", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30467, "upload_time": "2020-03-08T11:06:25", "upload_time_iso_8601": "2020-03-08T11:06:25.332567Z", "url": "https://files.pythonhosted.org/packages/59/ef/ffab7d65fc6c9930478e7a7d8525a3ee6d5456ac3479aa438eb1b2beeb99/afctl-0.1.7.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:22:48 2020"}