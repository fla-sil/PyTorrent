{"info": {"author": "Satyaki De", "author_email": "satyaki.de@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# DNPR Package\n\nThis package provides very useful data manipulation features for JSON Objects in Python platform. Using this anyone can perform the following operations -\n\n### Functions\n\n## Distinct of JSON Payloads\n\nAs of now, no available package in Python, which can operate on JSON Payloads & to provide unique Payload based on the total number of supplied fields in it. Using this distinct function - you can eliminate that. This is specially useful for NoSQL databases, where distinct might be a challange due to distributed nature of the architecture.\n\n> You need to use the following pattern to invoke this function:\n>\n\n    distinct(Input Json, Output Json)\n\n> Where Input Json is your supplied JSON & Output will be the unique JSON output.\n\n## NVL To check a specific fields NULL Value & replaced with any supplied default value in the JSON Payloads\n\nKeeping a specific business logic in mind, this NVL function will check if there is any NULL value or empty string & based on the business logic it will replace that with the default supplied value as per business logic.\n\n> You need to use the following pattern to invoke this function:\n>\n\n    nvl(Input Json, Prospective Null Column Name, Dafult Value in case of Null, Output Json)\n\n> Where Input Json is your supplied JSON, You have to provide the complete/full column name as per JSON structure, Default Value will be supplied value that you want to replace your null or empty string & Output will be the unique JSON output.\n\n## Use of Partition By clause with the specific fields of JSON Payloads\n\nPartition by would be another place where you can manipulate your JSON data just like any SQL queries.\n\n> You need to use the following pattern to invoke this function:\n>\n\n    partition_by(Input Json, Group By Column List, Group By Operation, Candidate Column Name, Output Column Name, Output Json)\n\n> Where Input JSON is your supplied JSON. Also, you need to provide the group of column list, which will be part of your partition window. Again, you need to provide complete/full column name. Then you need to mention what kind of operation that you want to perform. It can be MAX/MIN/SUM/AVG. Then you need to mention - on what column you want to perform the aggregate in Candidate Column Name field. Output Column name by default is NULL. However, you can provide a different name for aggregate column. In that case, your output JSON doesn't contain the old column name & it will contain this new column name. But, make sure you are using the same path for this new column. \n\n## Use of Regular Expression with the specific fields of JSON Payloads\n\nAnd, finally, we've introduced these following regular expression function on JSON, which I think will be very handy.\n\n> You need to use the following pattern to invoke this function:\n>\n\n    regex_like(Input Json, Target Column, Pattern To Match, Output Json)\n\tregex_replace(Input Json, Target Column, Pattern to Replace, Output Json)\n\tregex_substr(Input Json, Target Column, Pattern to substring, Output Json)\n\n> From the above function, the parameters are self explanatory. For details, please refer the examples.\n\n------------------------------------------------------------------------------------------\n                         callJson_DNPR.py\n------------------------------------------------------------------------------------------\n\n    ##############################################\n    #### Written By: SATYAKI DE               ####\n    #### Written On: 08-Sep-2019              ####\n    ####                                      ####\n    #### Objective: Main calling scripts.     ####\n    ##############################################\n\n    from dnpr.clsDnpr import clsDnpr\n    import datetime as dt\n    import json\n\n    # Disbling Warning\n    def warn(*args, **kwargs):\n        pass\n\n    import warnings\n    warnings.warn = warn\n\n    # Lookup functions from\n\n\n    def main():\n        try:\n            srcJson = [\n                        {\"FirstName\": \"Satyaki\", \"LastName\": \"De\", \"Sal\": 1000},\n                        {\"FirstName\": \"Satyaki\", \"LastName\": \"De\", \"Sal\": 1000},\n                        {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 500},\n                        {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 7000},\n                        {\"FirstName\": \"Deb\", \"LastName\": \"Sen\", \"Sal\": 9500}\n                      ]\n\n            print(\"=\" * 157)\n            print(\"Checking distinct function!\")\n            print(\"=\" * 157)\n            print()\n\n            print(\"*\" * 157)\n            print(\"Input Data: \")\n            srcJsonFormat = json.dumps(srcJson, indent=1)\n            print(str(srcJsonFormat))\n            print(\"*\" * 157)\n\n            # Initializing the class\n            t = clsDnpr()\n\n            print(\"1. Checking distinct functionality!\")\n\n            var1 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var1))\n\n            # Invoking the distinct function\n            tarJson = t.distinct(srcJson)\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat = json.dumps(tarJson, indent=1)\n            print(str(tarJsonFormat))\n            print(\"*\" * 157)\n\n            if not tarJson:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var2 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var2))\n\n            print(\"=\" * 157)\n            print(\"End of distinct function!\")\n            print(\"=\" * 157)\n\n            print(\"2. Checking nvl functionality!\")\n\n            srcJson_1 = [\n                {\"FirstName\": \"Satyaki\", \"LastName\": \"\", \"Sal\": 1000},\n                {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 500},\n                {\"FirstName\": \"Deb\", \"LastName\": \"\", \"Sal\": 9500}\n            ]\n\n            var3 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var3))\n\n            strDef = 'FNU'\n            print(\"Default Value: \", strDef)\n            srcColName = 'LastName'\n            print('Candidate Column for NVL: ', srcColName)\n\n            # Invoking the nvl function\n            tarJson_1 = t.nvl(srcJson_1, srcColName, strDef)\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat_1 = json.dumps(tarJson_1, indent=1)\n            print(str(tarJsonFormat_1))\n            print(\"*\" * 157)\n\n            if not tarJson_1:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var4 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var4))\n\n            print(\"=\" * 157)\n            print(\"End of nvl function!\")\n            print(\"=\" * 157)\n\n            print(\"3. Checking partition-by functionality!\")\n\n            srcJson_2 = [\n                {\"FirstName\": \"Satyaki\", \"LastName\": \"\", \"Sal\": 1000},\n                {\"FirstName\": \"Satyaki\", \"LastName\": \"\", \"Sal\": 700},\n                {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 500},\n                {\"FirstName\": \"Deb\", \"LastName\": \"\", \"Sal\": 9500},\n                {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 4500},\n            ]\n\n            var5 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var5))\n\n            GrList = ['FirstName', 'LastName']\n            print(\"Partition By Columns::: \", str(GrList))\n            grOperation = 'Max'\n            print('Operation toe be performed: ', grOperation)\n            strCandidateColumnName = 'Sal'\n            print('Column Name on which the aggregate function will take place: ', strCandidateColumnName)\n\n            # Invoking the partition by function - MAX\n            tarJson_1 = t.partitionBy(srcJson_2, GrList, grOperation, strCandidateColumnName)\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat_1 = json.dumps(tarJson_1, indent=1)\n            print(str(tarJsonFormat_1))\n            print(\"*\" * 157)\n\n            if not tarJson_1:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var6 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var6))\n\n            var7 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var7))\n\n            grOperation_1 = 'Min'\n            print('Operation toe be performed: ', grOperation_1)\n\n            # Invoking the Partition By function - MIN\n            tarJson_2 = t.partitionBy(srcJson_2, GrList, grOperation_1, strCandidateColumnName)\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat_2 = json.dumps(tarJson_2, indent=1)\n            print(str(tarJsonFormat_2))\n            print(\"*\" * 157)\n\n            if not tarJson_2:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var8 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var8))\n\n            var9 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var9))\n\n            grOperation_2 = 'Avg'\n            print('Operation toe be performed: ', grOperation_2)\n\n            # Invoking the Partition By function - Avg\n            tarJson_3 = t.partitionBy(srcJson_2, GrList, grOperation_2, strCandidateColumnName)\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat_3 = json.dumps(tarJson_3, indent=1)\n            print(str(tarJsonFormat_3))\n            print(\"*\" * 157)\n\n            if not tarJson_3:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var10 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var10))\n\n            var11 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var11))\n\n            grOperation_3 = 'Sum'\n            print('Operation toe be performed: ', grOperation_3)\n\n            # Invoking the Partition By function - Sum\n            tarJson_4 = t.partitionBy(srcJson_2, GrList, grOperation_3, strCandidateColumnName)\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat_4 = json.dumps(tarJson_4, indent=1)\n            print(str(tarJsonFormat_4))\n            print(\"*\" * 157)\n\n            if not tarJson_4:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var12 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var12))\n\n            print(\"=\" * 157)\n            print(\"End of partition function!\")\n            print(\"=\" * 157)\n\n            print(\"4. Checking regular expression functionality!\")\n            print()\n\n            var13 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var13))\n\n            print('::Function Regex_Like:: ')\n            print()\n\n            tarColumn = 'FirstName'\n            print('Target Column for Rexex_Like: ', tarColumn)\n            inpPattern = r\"\\bSa\"\n            print('Input Pattern: ', str(inpPattern))\n\n            # Invoking the regex_like function\n            tarJson = t.regex_like(srcJson, tarColumn, inpPattern)\n\n            print('End of Function Regex_Like!')\n            print()\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat = json.dumps(tarJson, indent=1)\n            print(str(tarJsonFormat))\n            print(\"*\" * 157)\n\n            if not tarJson:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var14 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var14))\n\n            var15 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var15))\n\n            print('::Function Regex_Replace:: ')\n            print()\n\n            tarColumn = 'FirstName'\n            print('Target Column for Rexex_Replace: ', tarColumn)\n            inpPattern = r\"\\bSa\"\n            print('Input Pattern: ', str(inpPattern))\n            replaceString = 'Ka'\n            print('Replacing Character: ', replaceString)\n\n            # Invoking the regex_replace function\n            tarJson = t.regex_replace(srcJson, tarColumn, inpPattern, replaceString)\n\n            print('End of Function Rexex_Replace!')\n            print()\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat = json.dumps(tarJson, indent=1)\n            print(str(tarJsonFormat))\n            print(\"*\" * 157)\n\n            if not tarJson:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var16 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var16)) \n\n            var17 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"Start Time: \", str(var17))\n\n            print('::Function Regex_Substr:: ')\n            print()\n\n            tarColumn = 'FirstName'\n            print('Target Column for Regex_Substr: ', tarColumn)\n            inpPattern = r\"\\bSa\"\n            print('Input Pattern: ', str(inpPattern))\n\n            # Invoking the regex_substr function\n            tarJson = t.regex_substr(srcJson, tarColumn, inpPattern)\n\n            print('End of Function Regex_Substr!')\n            print()\n\n            print(\"*\" * 157)\n            print(\"Output Data: \")\n            tarJsonFormat = json.dumps(tarJson, indent=1)\n            print(str(tarJsonFormat))\n            print(\"*\" * 157)\n\n            if not tarJson:\n                print()\n                print(\"No relevant output data!\")\n                print(\"*\" * 157)\n            else:\n                print()\n                print(\"Relevant output data comes!\")\n                print(\"*\" * 157)\n\n            var18 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n            print(\"End Time: \", str(var18))\n\n            print(\"=\" * 157)\n            print(\"End of regular expression function!\")\n            print(\"=\" * 157)\n\n\n        except ValueError:\n            print(\"No relevant data to proceed!\")\n\n        except Exception as e:\n            print(\"Top level Error: args:{0}, message{1}\".format(e.args, e.message))\n\n    if __name__ == \"__main__\":\n        main()\n\n\n------------------------------------------------------------------------------------------\n                 End Of Sample Code - callJson_DNPR.py\n------------------------------------------------------------------------------------------\n\n> Bug Fix: Let me know - if you face any bug. This is first release.\n>\n> Fixed: Partition By Bug!\n>\n> Notification: Distinct will only work simple JSON payload. We're working on to bring the \n> same feature for complex JSON as well.\n>\n> Dependancy Package: You need to install followig packages in order to run this package -\n>\n>                     pip install pandas\n>                     pip install regex\n------------------------------------------------------------------------------------------\n    Directory Structure shoould be like ->\n------------------------------------------------------------------------------------------\n    -> \\callJson_DNPR.py\n------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/SatyakiDe2019/Dnpr", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "Dnpr", "package_url": "https://pypi.org/project/Dnpr/", "platform": "", "project_url": "https://pypi.org/project/Dnpr/", "project_urls": {"Homepage": "https://github.com/SatyakiDe2019/Dnpr"}, "release_url": "https://pypi.org/project/Dnpr/0.1.0.post1/", "requires_dist": ["markdown", "pandas", "regex"], "requires_python": "", "summary": "Useful Data manipulation functions for JSON. Fixed partition by bug.", "version": "0.1.0.post1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DNPR Package</h1>\n<p>This package provides very useful data manipulation features for JSON Objects in Python platform. Using this anyone can perform the following operations -</p>\n<h3>Functions</h3>\n<h2>Distinct of JSON Payloads</h2>\n<p>As of now, no available package in Python, which can operate on JSON Payloads &amp; to provide unique Payload based on the total number of supplied fields in it. Using this distinct function - you can eliminate that. This is specially useful for NoSQL databases, where distinct might be a challange due to distributed nature of the architecture.</p>\n<blockquote>\n<p>You need to use the following pattern to invoke this function:</p>\n</blockquote>\n<pre><code>distinct(Input Json, Output Json)\n</code></pre>\n<blockquote>\n<p>Where Input Json is your supplied JSON &amp; Output will be the unique JSON output.</p>\n</blockquote>\n<h2>NVL To check a specific fields NULL Value &amp; replaced with any supplied default value in the JSON Payloads</h2>\n<p>Keeping a specific business logic in mind, this NVL function will check if there is any NULL value or empty string &amp; based on the business logic it will replace that with the default supplied value as per business logic.</p>\n<blockquote>\n<p>You need to use the following pattern to invoke this function:</p>\n</blockquote>\n<pre><code>nvl(Input Json, Prospective Null Column Name, Dafult Value in case of Null, Output Json)\n</code></pre>\n<blockquote>\n<p>Where Input Json is your supplied JSON, You have to provide the complete/full column name as per JSON structure, Default Value will be supplied value that you want to replace your null or empty string &amp; Output will be the unique JSON output.</p>\n</blockquote>\n<h2>Use of Partition By clause with the specific fields of JSON Payloads</h2>\n<p>Partition by would be another place where you can manipulate your JSON data just like any SQL queries.</p>\n<blockquote>\n<p>You need to use the following pattern to invoke this function:</p>\n</blockquote>\n<pre><code>partition_by(Input Json, Group By Column List, Group By Operation, Candidate Column Name, Output Column Name, Output Json)\n</code></pre>\n<blockquote>\n<p>Where Input JSON is your supplied JSON. Also, you need to provide the group of column list, which will be part of your partition window. Again, you need to provide complete/full column name. Then you need to mention what kind of operation that you want to perform. It can be MAX/MIN/SUM/AVG. Then you need to mention - on what column you want to perform the aggregate in Candidate Column Name field. Output Column name by default is NULL. However, you can provide a different name for aggregate column. In that case, your output JSON doesn't contain the old column name &amp; it will contain this new column name. But, make sure you are using the same path for this new column.</p>\n</blockquote>\n<h2>Use of Regular Expression with the specific fields of JSON Payloads</h2>\n<p>And, finally, we've introduced these following regular expression function on JSON, which I think will be very handy.</p>\n<blockquote>\n<p>You need to use the following pattern to invoke this function:</p>\n</blockquote>\n<pre><code>regex_like(Input Json, Target Column, Pattern To Match, Output Json)\nregex_replace(Input Json, Target Column, Pattern to Replace, Output Json)\nregex_substr(Input Json, Target Column, Pattern to substring, Output Json)\n</code></pre>\n<blockquote>\n<p>From the above function, the parameters are self explanatory. For details, please refer the examples.</p>\n</blockquote>\n<hr>\n<pre><code>                     callJson_DNPR.py\n</code></pre>\n<hr>\n<pre><code>##############################################\n#### Written By: SATYAKI DE               ####\n#### Written On: 08-Sep-2019              ####\n####                                      ####\n#### Objective: Main calling scripts.     ####\n##############################################\n\nfrom dnpr.clsDnpr import clsDnpr\nimport datetime as dt\nimport json\n\n# Disbling Warning\ndef warn(*args, **kwargs):\n    pass\n\nimport warnings\nwarnings.warn = warn\n\n# Lookup functions from\n\n\ndef main():\n    try:\n        srcJson = [\n                    {\"FirstName\": \"Satyaki\", \"LastName\": \"De\", \"Sal\": 1000},\n                    {\"FirstName\": \"Satyaki\", \"LastName\": \"De\", \"Sal\": 1000},\n                    {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 500},\n                    {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 7000},\n                    {\"FirstName\": \"Deb\", \"LastName\": \"Sen\", \"Sal\": 9500}\n                  ]\n\n        print(\"=\" * 157)\n        print(\"Checking distinct function!\")\n        print(\"=\" * 157)\n        print()\n\n        print(\"*\" * 157)\n        print(\"Input Data: \")\n        srcJsonFormat = json.dumps(srcJson, indent=1)\n        print(str(srcJsonFormat))\n        print(\"*\" * 157)\n\n        # Initializing the class\n        t = clsDnpr()\n\n        print(\"1. Checking distinct functionality!\")\n\n        var1 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var1))\n\n        # Invoking the distinct function\n        tarJson = t.distinct(srcJson)\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat = json.dumps(tarJson, indent=1)\n        print(str(tarJsonFormat))\n        print(\"*\" * 157)\n\n        if not tarJson:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var2 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var2))\n\n        print(\"=\" * 157)\n        print(\"End of distinct function!\")\n        print(\"=\" * 157)\n\n        print(\"2. Checking nvl functionality!\")\n\n        srcJson_1 = [\n            {\"FirstName\": \"Satyaki\", \"LastName\": \"\", \"Sal\": 1000},\n            {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 500},\n            {\"FirstName\": \"Deb\", \"LastName\": \"\", \"Sal\": 9500}\n        ]\n\n        var3 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var3))\n\n        strDef = 'FNU'\n        print(\"Default Value: \", strDef)\n        srcColName = 'LastName'\n        print('Candidate Column for NVL: ', srcColName)\n\n        # Invoking the nvl function\n        tarJson_1 = t.nvl(srcJson_1, srcColName, strDef)\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat_1 = json.dumps(tarJson_1, indent=1)\n        print(str(tarJsonFormat_1))\n        print(\"*\" * 157)\n\n        if not tarJson_1:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var4 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var4))\n\n        print(\"=\" * 157)\n        print(\"End of nvl function!\")\n        print(\"=\" * 157)\n\n        print(\"3. Checking partition-by functionality!\")\n\n        srcJson_2 = [\n            {\"FirstName\": \"Satyaki\", \"LastName\": \"\", \"Sal\": 1000},\n            {\"FirstName\": \"Satyaki\", \"LastName\": \"\", \"Sal\": 700},\n            {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 500},\n            {\"FirstName\": \"Deb\", \"LastName\": \"\", \"Sal\": 9500},\n            {\"FirstName\": \"Archi\", \"LastName\": \"Bose\", \"Sal\": 4500},\n        ]\n\n        var5 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var5))\n\n        GrList = ['FirstName', 'LastName']\n        print(\"Partition By Columns::: \", str(GrList))\n        grOperation = 'Max'\n        print('Operation toe be performed: ', grOperation)\n        strCandidateColumnName = 'Sal'\n        print('Column Name on which the aggregate function will take place: ', strCandidateColumnName)\n\n        # Invoking the partition by function - MAX\n        tarJson_1 = t.partitionBy(srcJson_2, GrList, grOperation, strCandidateColumnName)\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat_1 = json.dumps(tarJson_1, indent=1)\n        print(str(tarJsonFormat_1))\n        print(\"*\" * 157)\n\n        if not tarJson_1:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var6 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var6))\n\n        var7 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var7))\n\n        grOperation_1 = 'Min'\n        print('Operation toe be performed: ', grOperation_1)\n\n        # Invoking the Partition By function - MIN\n        tarJson_2 = t.partitionBy(srcJson_2, GrList, grOperation_1, strCandidateColumnName)\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat_2 = json.dumps(tarJson_2, indent=1)\n        print(str(tarJsonFormat_2))\n        print(\"*\" * 157)\n\n        if not tarJson_2:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var8 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var8))\n\n        var9 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var9))\n\n        grOperation_2 = 'Avg'\n        print('Operation toe be performed: ', grOperation_2)\n\n        # Invoking the Partition By function - Avg\n        tarJson_3 = t.partitionBy(srcJson_2, GrList, grOperation_2, strCandidateColumnName)\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat_3 = json.dumps(tarJson_3, indent=1)\n        print(str(tarJsonFormat_3))\n        print(\"*\" * 157)\n\n        if not tarJson_3:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var10 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var10))\n\n        var11 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var11))\n\n        grOperation_3 = 'Sum'\n        print('Operation toe be performed: ', grOperation_3)\n\n        # Invoking the Partition By function - Sum\n        tarJson_4 = t.partitionBy(srcJson_2, GrList, grOperation_3, strCandidateColumnName)\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat_4 = json.dumps(tarJson_4, indent=1)\n        print(str(tarJsonFormat_4))\n        print(\"*\" * 157)\n\n        if not tarJson_4:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var12 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var12))\n\n        print(\"=\" * 157)\n        print(\"End of partition function!\")\n        print(\"=\" * 157)\n\n        print(\"4. Checking regular expression functionality!\")\n        print()\n\n        var13 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var13))\n\n        print('::Function Regex_Like:: ')\n        print()\n\n        tarColumn = 'FirstName'\n        print('Target Column for Rexex_Like: ', tarColumn)\n        inpPattern = r\"\\bSa\"\n        print('Input Pattern: ', str(inpPattern))\n\n        # Invoking the regex_like function\n        tarJson = t.regex_like(srcJson, tarColumn, inpPattern)\n\n        print('End of Function Regex_Like!')\n        print()\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat = json.dumps(tarJson, indent=1)\n        print(str(tarJsonFormat))\n        print(\"*\" * 157)\n\n        if not tarJson:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var14 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var14))\n\n        var15 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var15))\n\n        print('::Function Regex_Replace:: ')\n        print()\n\n        tarColumn = 'FirstName'\n        print('Target Column for Rexex_Replace: ', tarColumn)\n        inpPattern = r\"\\bSa\"\n        print('Input Pattern: ', str(inpPattern))\n        replaceString = 'Ka'\n        print('Replacing Character: ', replaceString)\n\n        # Invoking the regex_replace function\n        tarJson = t.regex_replace(srcJson, tarColumn, inpPattern, replaceString)\n\n        print('End of Function Rexex_Replace!')\n        print()\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat = json.dumps(tarJson, indent=1)\n        print(str(tarJsonFormat))\n        print(\"*\" * 157)\n\n        if not tarJson:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var16 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var16)) \n\n        var17 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"Start Time: \", str(var17))\n\n        print('::Function Regex_Substr:: ')\n        print()\n\n        tarColumn = 'FirstName'\n        print('Target Column for Regex_Substr: ', tarColumn)\n        inpPattern = r\"\\bSa\"\n        print('Input Pattern: ', str(inpPattern))\n\n        # Invoking the regex_substr function\n        tarJson = t.regex_substr(srcJson, tarColumn, inpPattern)\n\n        print('End of Function Regex_Substr!')\n        print()\n\n        print(\"*\" * 157)\n        print(\"Output Data: \")\n        tarJsonFormat = json.dumps(tarJson, indent=1)\n        print(str(tarJsonFormat))\n        print(\"*\" * 157)\n\n        if not tarJson:\n            print()\n            print(\"No relevant output data!\")\n            print(\"*\" * 157)\n        else:\n            print()\n            print(\"Relevant output data comes!\")\n            print(\"*\" * 157)\n\n        var18 = dt.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n        print(\"End Time: \", str(var18))\n\n        print(\"=\" * 157)\n        print(\"End of regular expression function!\")\n        print(\"=\" * 157)\n\n\n    except ValueError:\n        print(\"No relevant data to proceed!\")\n\n    except Exception as e:\n        print(\"Top level Error: args:{0}, message{1}\".format(e.args, e.message))\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n<hr>\n<pre><code>             End Of Sample Code - callJson_DNPR.py\n</code></pre>\n<hr>\n<blockquote>\n<p>Bug Fix: Let me know - if you face any bug. This is first release.</p>\n<p>Fixed: Partition By Bug!</p>\n<p>Notification: Distinct will only work simple JSON payload. We're working on to bring the\nsame feature for complex JSON as well.</p>\n<p>Dependancy Package: You need to install followig packages in order to run this package -</p>\n<pre><code>                pip install pandas\n                pip install regex\n</code></pre>\n</blockquote>\n<hr>\n<pre><code>Directory Structure shoould be like -&gt;\n</code></pre>\n<hr>\n<pre><code>-&gt; \\callJson_DNPR.py\n</code></pre>\n<hr>\n<hr>\n\n          </div>"}, "last_serial": 5831219, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "71b17f076c199a65c29df98e13a03469", "sha256": "7c80f0dcbfbbd11bea6ceff28d19f15e185e036a16c3b19ecde0b3f5efc68ebf"}, "downloads": -1, "filename": "Dnpr-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "71b17f076c199a65c29df98e13a03469", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 4780, "upload_time": "2019-09-09T05:51:42", "upload_time_iso_8601": "2019-09-09T05:51:42.040739Z", "url": "https://files.pythonhosted.org/packages/b2/47/b0dc9f872bfb44d4d39c6c5ba5f63c18fd240d32e0e788eebff12a5ad261/Dnpr-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "087aa78efc6d1d59300cc461ea79f061", "sha256": "0eea23949dc88943aeb6830e55d8f93ed276ade5c74c193587448150e1fc5eed"}, "downloads": -1, "filename": "Dnpr-0.0.1.tar.gz", "has_sig": false, "md5_digest": "087aa78efc6d1d59300cc461ea79f061", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5041, "upload_time": "2019-09-09T05:51:44", "upload_time_iso_8601": "2019-09-09T05:51:44.578180Z", "url": "https://files.pythonhosted.org/packages/ad/a3/c2a6d2b827a8f0dd556fd31785ddd540ed8f328a5ae447f6cc0bfad31273/Dnpr-0.0.1.tar.gz", "yanked": false}], "0.0.1.post0": [{"comment_text": "", "digests": {"md5": "ec6052b5463506351f54d2cd8ffd0ffd", "sha256": "d44f8fc9ed7a3618003cb44f84f3740d493f423357f80a63c5d596d891301d6b"}, "downloads": -1, "filename": "Dnpr-0.0.1.post0-py3-none-any.whl", "has_sig": false, "md5_digest": "ec6052b5463506351f54d2cd8ffd0ffd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7571, "upload_time": "2019-09-09T06:11:04", "upload_time_iso_8601": "2019-09-09T06:11:04.713462Z", "url": "https://files.pythonhosted.org/packages/6a/f5/38c73a216fef16e8c6c9edb354d5e7a6db7548b0f28123f2b44f3657927c/Dnpr-0.0.1.post0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cbf5b45ce95a79b441aa127480355dc5", "sha256": "4f3a70ea8b5c4ec6457ca98d6fa831944b3cf20e2c85f03d1645d012ade11e49"}, "downloads": -1, "filename": "Dnpr-0.0.1.post0.tar.gz", "has_sig": false, "md5_digest": "cbf5b45ce95a79b441aa127480355dc5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9202, "upload_time": "2019-09-09T06:11:06", "upload_time_iso_8601": "2019-09-09T06:11:06.350780Z", "url": "https://files.pythonhosted.org/packages/e5/f3/fe92b4227532d5f11fb9a461baccd1a2d8bfd7bfb7d84a38ce7d13206b70/Dnpr-0.0.1.post0.tar.gz", "yanked": false}], "0.0.2.post0": [{"comment_text": "", "digests": {"md5": "533b8645c4c77652dbcc545441b0d7a8", "sha256": "34a4146bc1724f0e07bfc709f3e751eef6960a86de019891756ec7d201034b71"}, "downloads": -1, "filename": "Dnpr-0.0.2.post0-py3-none-any.whl", "has_sig": false, "md5_digest": "533b8645c4c77652dbcc545441b0d7a8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7564, "upload_time": "2019-09-09T06:29:59", "upload_time_iso_8601": "2019-09-09T06:29:59.130753Z", "url": "https://files.pythonhosted.org/packages/8b/eb/8a8158b92b9968b4b34debf0601e095ad11c86e95bea57c483d3b8f90aad/Dnpr-0.0.2.post0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6790eccead14656bedb5470fb019e0e1", "sha256": "12a29eb996136d2fff6bc089e6470aa0737506117462133848bbff348fb5c40a"}, "downloads": -1, "filename": "Dnpr-0.0.2.post0.tar.gz", "has_sig": false, "md5_digest": "6790eccead14656bedb5470fb019e0e1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9194, "upload_time": "2019-09-09T06:30:03", "upload_time_iso_8601": "2019-09-09T06:30:03.856280Z", "url": "https://files.pythonhosted.org/packages/e5/18/04fc4b382c718cb4ebf997f5a415e359e399bf45901eab5c4af43b9157b4/Dnpr-0.0.2.post0.tar.gz", "yanked": false}], "0.0.3.post0": [{"comment_text": "", "digests": {"md5": "8e7b787fb7d4ebdb3f652355e75b938e", "sha256": "2c5a14782260c9b1d7a2caadc7f6a0d717e601117f15303a6e299e0554f3ad52"}, "downloads": -1, "filename": "Dnpr-0.0.3.post0-py3-none-any.whl", "has_sig": false, "md5_digest": "8e7b787fb7d4ebdb3f652355e75b938e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7562, "upload_time": "2019-09-09T06:30:00", "upload_time_iso_8601": "2019-09-09T06:30:00.754778Z", "url": "https://files.pythonhosted.org/packages/2f/3a/b0b0aca1bf0d5ac22d15908698a59b5f10160f1ce5b97684e0848cb7c7d2/Dnpr-0.0.3.post0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7ea59a115193bd0fddf5086970677e8", "sha256": "e1818d2e9857796abc7e5d2457921480a2ca8e2a73255589e6eb50182e99ed42"}, "downloads": -1, "filename": "Dnpr-0.0.3.post0.tar.gz", "has_sig": false, "md5_digest": "d7ea59a115193bd0fddf5086970677e8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9192, "upload_time": "2019-09-09T06:30:05", "upload_time_iso_8601": "2019-09-09T06:30:05.509931Z", "url": "https://files.pythonhosted.org/packages/09/0a/039638196367e65fecd9569e276939179d48f2148fdf5362dfa2b74d9b3e/Dnpr-0.0.3.post0.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "725e4d52781cba09e2718244cb7ee8ac", "sha256": "d1e1de8f665aeb565cded9fa65ca7a059c2b6048ad14d7df21a26d3bbf4a9335"}, "downloads": -1, "filename": "Dnpr-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "725e4d52781cba09e2718244cb7ee8ac", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9724, "upload_time": "2019-09-15T09:04:49", "upload_time_iso_8601": "2019-09-15T09:04:49.967657Z", "url": "https://files.pythonhosted.org/packages/af/6a/444b2a752c250ed8e54f4e6050423afd533f8a161007410d691af912dbe5/Dnpr-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "91cb5adffaa13efe5656f58f347d42bd", "sha256": "1ad75372b80f2c2e5648954cffa7677e953430a8b6e23e5964ca11dd014700ff"}, "downloads": -1, "filename": "Dnpr-0.1.0.tar.gz", "has_sig": false, "md5_digest": "91cb5adffaa13efe5656f58f347d42bd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7335, "upload_time": "2019-09-15T09:04:51", "upload_time_iso_8601": "2019-09-15T09:04:51.463510Z", "url": "https://files.pythonhosted.org/packages/23/61/e716be444eb6b7312a859f301215eba8a05ab36cd82bdf2e42f5c3c491f1/Dnpr-0.1.0.tar.gz", "yanked": false}], "0.1.0.post0": [{"comment_text": "", "digests": {"md5": "3c8bd43ba26a9617dc93578bdc98fce1", "sha256": "723447c38e46e10b3bf27245b26b060a28eb00affdc991f5fe09ceaad22b0c8b"}, "downloads": -1, "filename": "Dnpr-0.1.0.post0-py3-none-any.whl", "has_sig": false, "md5_digest": "3c8bd43ba26a9617dc93578bdc98fce1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7813, "upload_time": "2019-09-15T09:21:47", "upload_time_iso_8601": "2019-09-15T09:21:47.372730Z", "url": "https://files.pythonhosted.org/packages/00/a9/cd6b77b999a6bb7f08e22ed2752a20218f222e4935a183808be9b44fdfc0/Dnpr-0.1.0.post0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1fe86a3e42c70ea1c8af0dd0668bcd54", "sha256": "5cc940b9fd171c85c370f5066f6ff8da9c84b9ce69e840d46dc001d6a76a251d"}, "downloads": -1, "filename": "Dnpr-0.1.0.post0.tar.gz", "has_sig": false, "md5_digest": "1fe86a3e42c70ea1c8af0dd0668bcd54", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9553, "upload_time": "2019-09-15T09:21:51", "upload_time_iso_8601": "2019-09-15T09:21:51.392883Z", "url": "https://files.pythonhosted.org/packages/d8/11/33db5e9d9e99352b15dbfbe8239b5e9dd525d3443ea29dc900a3b802168b/Dnpr-0.1.0.post0.tar.gz", "yanked": false}], "0.1.0.post1": [{"comment_text": "", "digests": {"md5": "0705d154fb88e9c7737f0ad4556198a6", "sha256": "fb740b4d9fc13825567efa5d99728b0a9da84160a91c7baa4c0a89d5ca351906"}, "downloads": -1, "filename": "Dnpr-0.1.0.post1-py3-none-any.whl", "has_sig": false, "md5_digest": "0705d154fb88e9c7737f0ad4556198a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7814, "upload_time": "2019-09-15T09:28:24", "upload_time_iso_8601": "2019-09-15T09:28:24.519117Z", "url": "https://files.pythonhosted.org/packages/48/68/4e2ab84aaaf577e1ca5db8eece559ed013fb9a73d29ffe178eabbc341bfc/Dnpr-0.1.0.post1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8afb12fdb6d75e7ec1dea2c21c2563a8", "sha256": "1cd9cc5bb7729c26a7c3f736b4b3cf715e10b7bfa4e64d63e974d96f590e9f38"}, "downloads": -1, "filename": "Dnpr-0.1.0.post1.tar.gz", "has_sig": false, "md5_digest": "8afb12fdb6d75e7ec1dea2c21c2563a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9601, "upload_time": "2019-09-15T09:28:30", "upload_time_iso_8601": "2019-09-15T09:28:30.132430Z", "url": "https://files.pythonhosted.org/packages/b1/2b/76f42760306d7d6401fc44f318efaaa08886efcd50d02f2c44c9f43f8ac6/Dnpr-0.1.0.post1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0705d154fb88e9c7737f0ad4556198a6", "sha256": "fb740b4d9fc13825567efa5d99728b0a9da84160a91c7baa4c0a89d5ca351906"}, "downloads": -1, "filename": "Dnpr-0.1.0.post1-py3-none-any.whl", "has_sig": false, "md5_digest": "0705d154fb88e9c7737f0ad4556198a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7814, "upload_time": "2019-09-15T09:28:24", "upload_time_iso_8601": "2019-09-15T09:28:24.519117Z", "url": "https://files.pythonhosted.org/packages/48/68/4e2ab84aaaf577e1ca5db8eece559ed013fb9a73d29ffe178eabbc341bfc/Dnpr-0.1.0.post1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8afb12fdb6d75e7ec1dea2c21c2563a8", "sha256": "1cd9cc5bb7729c26a7c3f736b4b3cf715e10b7bfa4e64d63e974d96f590e9f38"}, "downloads": -1, "filename": "Dnpr-0.1.0.post1.tar.gz", "has_sig": false, "md5_digest": "8afb12fdb6d75e7ec1dea2c21c2563a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9601, "upload_time": "2019-09-15T09:28:30", "upload_time_iso_8601": "2019-09-15T09:28:30.132430Z", "url": "https://files.pythonhosted.org/packages/b1/2b/76f42760306d7d6401fc44f318efaaa08886efcd50d02f2c44c9f43f8ac6/Dnpr-0.1.0.post1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:07 2020"}