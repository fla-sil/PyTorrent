{"info": {"author": "Google LLC", "author_email": "packages@tensorflow.org", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# Evaluating Models with the Fairness Indicators Dashboard [Beta]\n\n![Fairness Indicators](https://raw.githubusercontent.com/tensorflow/tensorboard/master/docs/images/fairness-indicators.png)\n\nFairness Indicators for TensorBoard enables easy computation of\ncommonly-identified fairness metrics for _binary_ and _multiclass_ classifiers.\nWith the plugin, you can visualize fairness evaluations for your runs and easily\ncompare performance across groups.\n\nIn particular, Fairness Indicators for TensorBoard allows you to evaluate and\nvisualize model performance, sliced across defined groups of users. Feel\nconfident about your results with confidence intervals and evaluations at\nmultiple thresholds.\n\nMany existing tools for evaluating fairness concerns don\u2019t work well on large\nscale datasets and models. At Google, it is important for us to have tools that\ncan work on billion-user systems. Fairness Indicators will allow you to evaluate\nacross any size of use case, in the TensorBoard environment or in\n[Colab](https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/examples/).\n\n## Requirements\n\nTo install Fairness Indicators for TensorBoard, run:\n\n```\npython3 -m virtualenv ~/tensorboard_demo\nsource ~/tensorboard_demo/bin/activate\npip install --upgrade pip\npip install tensorboard_plugin_fairness_indicators\n```\n\n## Demo Colab\n\n[Fairness_Indicators_TensorBoard_Plugin_Example_Colab.ipynb](https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/examples/Fairness_Indicators_TensorBoard_Plugin_Example_Colab.ipynb)\ncontains an end-to-end demo to train and evaluate a model and visualize fairness evaluation\nresults in TensorBoard.\n\n## Usage\n\nTo use the Fairness Indicators with your own data and evaluations:\n\n1.  Train a new model and evaluate using\n    `tensorflow_model_analysis.run_model_analysis` or\n    `tensorflow_model_analysis.ExtractEvaluateAndWriteResult` API in\n    [model_eval_lib](https://github.com/tensorflow/model-analysis/blob/master/tensorflow_model_analysis/api/model_eval_lib.py).\n    For code snippets on how to do this, see the Fairness Indicators colab\n    [here](https://github.com/tensorflow/fairness-indicators).\n\n2.  Write a summary data file using [`demo.py`](https://github.com/tensorflow/fairness-indicators/blob/master/tensorboard_plugin/tensorboard_plugin_fairness_indicators/demo.py), which will be read\n    by TensorBoard to render the Fairness Indicators dashboard (See the\n    [TensorBoard tutorial](https://github.com/tensorflow/tensorboard/blob/master/README.md)\n    for more information on summary data files).\n\n    Flags to be used with the `demo.py` utility:\n\n    -   `--logdir`: Directory where TensorBoard will write the summary\n    -   `--eval_result_output_dir`: Directory containing evaluation results\n        evaluated by TFMA\n\n    ```\n    python demo.py --logdir=<logdir> --eval_result_output_dir=<eval_result_dir>`\n    ```\n\n    Or you can also use `tensorboard_plugin_fairness_indicators.summary_v2` API to write the summary file.\n\n    ```\n    writer = tf.summary.create_file_writer(<logdir>)\n    with writer.as_default():\n        summary_v2.FairnessIndicators(<eval_result_dir>, step=1)\n    writer.close()\n    ```\n\n3.  Run TensorBoard\n\n    Note: This will start a local instance. After the local instance is started, a link\n    will be displayed to the terminal. Open the link in your browser to view the\n    Fairness Indicators dashboard.\n\n    -   `tensorboard --logdir=<logdir>`\n    -   Select the new evaluation run using the drop-down on the left side of\n        the dashboard to visualize results.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tensorflow/fairness-indicators", "keywords": "tensorflow model analysis fairness indicators tensorboard machine learning", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "tensorboard-plugin-fairness-indicators", "package_url": "https://pypi.org/project/tensorboard-plugin-fairness-indicators/", "platform": "", "project_url": "https://pypi.org/project/tensorboard-plugin-fairness-indicators/", "project_urls": {"Homepage": "https://github.com/tensorflow/fairness-indicators"}, "release_url": "https://pypi.org/project/tensorboard-plugin-fairness-indicators/0.0.3/", "requires_dist": ["protobuf (>=3.6.0)", "setuptools (>=40.2.0)", "tensorboard (<3,>=2.1.0)", "tensorflow (<3,>=2.1.0)", "tensorflow-model-analysis (<1,>=0.21.2)", "wheel ; python_version < \"3\"", "wheel (>=0.26) ; python_version >= \"3\""], "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "summary": "Fairness Indicators TensorBoard Plugin", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Evaluating Models with the Fairness Indicators Dashboard [Beta]</h1>\n<p><img alt=\"Fairness Indicators\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/754f09bfc3d77f888958c6e0bb47997e5507b331/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f74656e736f72626f6172642f6d61737465722f646f63732f696d616765732f666169726e6573732d696e64696361746f72732e706e67\"></p>\n<p>Fairness Indicators for TensorBoard enables easy computation of\ncommonly-identified fairness metrics for <em>binary</em> and <em>multiclass</em> classifiers.\nWith the plugin, you can visualize fairness evaluations for your runs and easily\ncompare performance across groups.</p>\n<p>In particular, Fairness Indicators for TensorBoard allows you to evaluate and\nvisualize model performance, sliced across defined groups of users. Feel\nconfident about your results with confidence intervals and evaluations at\nmultiple thresholds.</p>\n<p>Many existing tools for evaluating fairness concerns don\u2019t work well on large\nscale datasets and models. At Google, it is important for us to have tools that\ncan work on billion-user systems. Fairness Indicators will allow you to evaluate\nacross any size of use case, in the TensorBoard environment or in\n<a href=\"https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/examples/\" rel=\"nofollow\">Colab</a>.</p>\n<h2>Requirements</h2>\n<p>To install Fairness Indicators for TensorBoard, run:</p>\n<pre><code>python3 -m virtualenv ~/tensorboard_demo\nsource ~/tensorboard_demo/bin/activate\npip install --upgrade pip\npip install tensorboard_plugin_fairness_indicators\n</code></pre>\n<h2>Demo Colab</h2>\n<p><a href=\"https://github.com/tensorflow/fairness-indicators/blob/master/fairness_indicators/examples/Fairness_Indicators_TensorBoard_Plugin_Example_Colab.ipynb\" rel=\"nofollow\">Fairness_Indicators_TensorBoard_Plugin_Example_Colab.ipynb</a>\ncontains an end-to-end demo to train and evaluate a model and visualize fairness evaluation\nresults in TensorBoard.</p>\n<h2>Usage</h2>\n<p>To use the Fairness Indicators with your own data and evaluations:</p>\n<ol>\n<li>\n<p>Train a new model and evaluate using\n<code>tensorflow_model_analysis.run_model_analysis</code> or\n<code>tensorflow_model_analysis.ExtractEvaluateAndWriteResult</code> API in\n<a href=\"https://github.com/tensorflow/model-analysis/blob/master/tensorflow_model_analysis/api/model_eval_lib.py\" rel=\"nofollow\">model_eval_lib</a>.\nFor code snippets on how to do this, see the Fairness Indicators colab\n<a href=\"https://github.com/tensorflow/fairness-indicators\" rel=\"nofollow\">here</a>.</p>\n</li>\n<li>\n<p>Write a summary data file using <a href=\"https://github.com/tensorflow/fairness-indicators/blob/master/tensorboard_plugin/tensorboard_plugin_fairness_indicators/demo.py\" rel=\"nofollow\"><code>demo.py</code></a>, which will be read\nby TensorBoard to render the Fairness Indicators dashboard (See the\n<a href=\"https://github.com/tensorflow/tensorboard/blob/master/README.md\" rel=\"nofollow\">TensorBoard tutorial</a>\nfor more information on summary data files).</p>\n<p>Flags to be used with the <code>demo.py</code> utility:</p>\n<ul>\n<li><code>--logdir</code>: Directory where TensorBoard will write the summary</li>\n<li><code>--eval_result_output_dir</code>: Directory containing evaluation results\nevaluated by TFMA</li>\n</ul>\n<pre><code>python demo.py --logdir=&lt;logdir&gt; --eval_result_output_dir=&lt;eval_result_dir&gt;`\n</code></pre>\n<p>Or you can also use <code>tensorboard_plugin_fairness_indicators.summary_v2</code> API to write the summary file.</p>\n<pre><code>writer = tf.summary.create_file_writer(&lt;logdir&gt;)\nwith writer.as_default():\n    summary_v2.FairnessIndicators(&lt;eval_result_dir&gt;, step=1)\nwriter.close()\n</code></pre>\n</li>\n<li>\n<p>Run TensorBoard</p>\n<p>Note: This will start a local instance. After the local instance is started, a link\nwill be displayed to the terminal. Open the link in your browser to view the\nFairness Indicators dashboard.</p>\n<ul>\n<li><code>tensorboard --logdir=&lt;logdir&gt;</code></li>\n<li>Select the new evaluation run using the drop-down on the left side of\nthe dashboard to visualize results.</li>\n</ul>\n</li>\n</ol>\n\n          </div>"}, "last_serial": 6556664, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "686170d8f8a884c6115ac8c2434b4ae7", "sha256": "da40dbfdf53a9f7e4280338c2e0605b6f1bcee0b11454c7ce5dc014fe93cd894"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "686170d8f8a884c6115ac8c2434b4ae7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 302814, "upload_time": "2019-10-23T03:38:07", "upload_time_iso_8601": "2019-10-23T03:38:07.292410Z", "url": "https://files.pythonhosted.org/packages/b6/bf/4d2fca415eb9ce59254bf35641c377f4bdd7a526a21ad6611515f6473d77/tensorboard_plugin_fairness_indicators-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "359050103ab98bbede8986b07a59261f", "sha256": "10d6f3bb6e4ea70127175122270fb3f0483bcfc7011d4e5b72b9ac05383cf523"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.1.tar.gz", "has_sig": false, "md5_digest": "359050103ab98bbede8986b07a59261f", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 291935, "upload_time": "2019-10-23T03:38:10", "upload_time_iso_8601": "2019-10-23T03:38:10.237737Z", "url": "https://files.pythonhosted.org/packages/a6/7e/9f4cfd5abbb710d7ac4d7c9c82678b4826e8ebe6f7bd0711516a33ed1806/tensorboard_plugin_fairness_indicators-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "7b80853bb0d1507a42d1600703019d96", "sha256": "64581429844215ceab6a399a8c7d360afdf7b6334371cf46b601841cba7570af"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "7b80853bb0d1507a42d1600703019d96", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 304445, "upload_time": "2019-10-29T18:10:35", "upload_time_iso_8601": "2019-10-29T18:10:35.538502Z", "url": "https://files.pythonhosted.org/packages/7a/d7/4a3f8550635173abed226fe4c214399b56b5676d653e041acedec6a5700f/tensorboard_plugin_fairness_indicators-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d7e2723804aa24805160b0b3194a453", "sha256": "8760914733660f41c1ad0ea7976ea9267462ac0c460961763c50b8754a70c88f"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.2.tar.gz", "has_sig": false, "md5_digest": "3d7e2723804aa24805160b0b3194a453", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 295193, "upload_time": "2019-10-29T18:10:37", "upload_time_iso_8601": "2019-10-29T18:10:37.733930Z", "url": "https://files.pythonhosted.org/packages/f5/e1/e9a93d9e8ed0f5db0f088c6cc5358e4789003f43b80d123b86304c33df79/tensorboard_plugin_fairness_indicators-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "5936c9094910e654fc163bf3b7508340", "sha256": "09c0bcecb99d8da54e886200591d817fb3f0e06992f5f1c00a1cc5f84b161205"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "5936c9094910e654fc163bf3b7508340", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 305791, "upload_time": "2020-02-02T04:03:20", "upload_time_iso_8601": "2020-02-02T04:03:20.329887Z", "url": "https://files.pythonhosted.org/packages/fe/77/8debc3dd02a8915106acf39c1bd6acef9cb3640b1ecc874a257ade0237ec/tensorboard_plugin_fairness_indicators-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d4f707dd8881c2a5cbc2351e29287863", "sha256": "c36a8cc3c4fb517747bdbb1b43a281f04ecdcc708e334f74729e1686f6d66bc5"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.3.tar.gz", "has_sig": false, "md5_digest": "d4f707dd8881c2a5cbc2351e29287863", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 300483, "upload_time": "2020-02-02T04:03:21", "upload_time_iso_8601": "2020-02-02T04:03:21.907473Z", "url": "https://files.pythonhosted.org/packages/14/d8/cdc5060c98da8b850aff4064dd48412406f6d86485bc66b0b9f46cbd3056/tensorboard_plugin_fairness_indicators-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "5936c9094910e654fc163bf3b7508340", "sha256": "09c0bcecb99d8da54e886200591d817fb3f0e06992f5f1c00a1cc5f84b161205"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "5936c9094910e654fc163bf3b7508340", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 305791, "upload_time": "2020-02-02T04:03:20", "upload_time_iso_8601": "2020-02-02T04:03:20.329887Z", "url": "https://files.pythonhosted.org/packages/fe/77/8debc3dd02a8915106acf39c1bd6acef9cb3640b1ecc874a257ade0237ec/tensorboard_plugin_fairness_indicators-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d4f707dd8881c2a5cbc2351e29287863", "sha256": "c36a8cc3c4fb517747bdbb1b43a281f04ecdcc708e334f74729e1686f6d66bc5"}, "downloads": -1, "filename": "tensorboard_plugin_fairness_indicators-0.0.3.tar.gz", "has_sig": false, "md5_digest": "d4f707dd8881c2a5cbc2351e29287863", "packagetype": "sdist", "python_version": "source", "requires_python": ">= 2.7, != 3.0.*, != 3.1.*", "size": 300483, "upload_time": "2020-02-02T04:03:21", "upload_time_iso_8601": "2020-02-02T04:03:21.907473Z", "url": "https://files.pythonhosted.org/packages/14/d8/cdc5060c98da8b850aff4064dd48412406f6d86485bc66b0b9f46cbd3056/tensorboard_plugin_fairness_indicators-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:28 2020"}