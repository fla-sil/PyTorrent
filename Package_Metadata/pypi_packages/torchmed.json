{"info": {"author": "Pierre-Antoine Ganaye", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: POSIX", "Programming Language :: Python :: 3"], "description": "# TorchMed\n\nRead and process medical images in PyTorch.\n\n[![Build Status](https://travis-ci.com/trypag/pytorch-med.svg?token=W7UTQDqNUe21xtLfiqRm&branch=master)](https://travis-ci.com/trypag/pytorch-med)\n[![codecov](https://codecov.io/gh/trypag/pytorch-med/branch/master/graph/badge.svg?token=kL3ASEka4B)](https://codecov.io/gh/trypag/pytorch-med)\n\n---\n\nThis library is designed as a flexible tool to process various types N dimension images.\nThrough a set of image **readers** based on famous projects (SimpleITK, NiBabel, OpenCV, Pillow)\nyou will be able to load your data. Once loaded, specific sub-sampling of the original\ndata is performed with **patterns** (describing what/how to extract) and **samplers**\n(checks where to extract).\n\nWith **readers**, **samplers** and **patterns**, you can compose **datasets** which\na perfectly suited for PyTorch.\n\n## Install\n\nFrom pip:\n\n```bash\npip install torchmed\n```\n\nLocally :\n\n```bash\npython install setup.py\n```\n\n## Usage\n\n### Reader\n\n```python\n>>> import torchmed\n\n>>> image = torchmed.readers.SitkReader('prepro_im_mni_bc.nii.gz')\n>>> label_map = torchmed.readers.SitkReader('prepro_seg_mni.nii.gz')\n# gets image data\n>>> image_array = image.to_torch()\n>>> label_array = label_map.to_torch()\n\n>>> image_array.size()\ntorch.Size([182, 218, 182])\n>>> type(image_array)\n<class 'torch.Tensor'>\n>>> label_array[0,0,0]\ntensor(0.)\n# also available for Numpy\n>>> type(image.to_numpy())\n<class 'numpy.ndarray'>\n```\n\n### Pattern\n\nPatterns are useful to specify how the data should be extracted from an image.\nIt is possible to apply several patterns on one or more images.\n\n```python\n>>> import torchmed\n\n>>> image = torchmed.readers.SitkReader('prepro_im_mni_bc.nii.gz')\n>>> square_patch = torchmed.patterns.SquaredSlidingWindow([182, 7, 182], use_padding=False)\n# initialize the pattern with the image properties\n>>> square_patch.prepare(image_arr)\n\n# can_apply checks if a pattern can be applied at a given position\n>>> square_patch.can_apply(image_arr, [0,0,0])\nFalse\n>>> square_patch.can_apply(image_arr, [91,4,91])\nTrue\n>>> square_patch.can_apply(image_arr, [91,3,91])\nTrue\n>>> square_patch.can_apply(image_arr, [91,2,91])\nFalse\n>>> square_patch.can_apply(image_arr, [91,154,91])\nTrue\n\n# to extract a patch at a correct position\n>>> sample = square_patch(image_arr, [91,154,91])\n>>> sample.size()\ntorch.Size([182, 7, 182])\n```\n\n### Sampler\n\nMulti-processed sampler to automatically search for coordinates where sampling\n(pattern extraction) is possible.\n\n```python\n>>> from torchmed.readers import SitkReader\n>>> from torchmed.samplers import MaskableSampler\n>>> from torchmed.patterns import SquaredSlidingWindow\n\n# maps a name to each image\n>>> file_map = {\n...         'image_ref': SitkReader('prepro_im_mni_bc.nii.gz',\n...             torch_type='torch.FloatTensor'),\n...         'target': SitkReader('prepro_seg_mni.nii.gz',\n...             torch_type='torch.LongTensor')\n...     }\n\n# sliding window pattern\n>>> patch2d = SquaredSlidingWindow(patch_size=[182, 7, 182], use_padding=False)\n# specify a pattern for each input image\n>>> pattern_mapper = {'input': ('image_ref', patch2d),\n...                   'target': ('target', patch2d)}\n# muli-processed sampler with offset\n>>> sampler = MaskableSampler(pattern_mapper, offset=[91, 1, 91], nb_workers=4)\n>>> sampler.build(file_map)\n>>> len(sampler)\n212\n>>> sample = sampler[0]\n>>> type(sample)\n<class 'tuple'>\n>>> sample[0].size()\ntorch.Size([3])\n>>> sample[1].size()\ntorch.Size([182, 7, 182])\n>>> sample[2].size()\ntorch.Size([182, 7, 182])\n```\n\n### Dataset\n\n`MedFile` and `MedFolder` are iterable datasets, returning samples from the input\ndata. Here is an example of how to build a `MedFolder` from a list of images.\nA `MedFolder` takes as input a list of `MedFile`s.\n\n```python\nimport os\nfrom torchmed.datasets import MedFile, MedFolder\n\nself.train_dataset = MedFolder(\n        self.generate_medfiles(os.path.join(base_dir, 'train'), nb_workers))\n\ndef generate_medfiles(self, dir, nb_workers):\n      # database composed of dirname contained in the allowed_data.txt\n      database = open(os.path.join(dir, 'allowed_data.txt'), 'r')\n      patient_list = [line.rstrip('\\n') for line in database]\n      medfiles = []\n\n      # builds a list of MedFiles, one for each folder\n      for patient in patient_list:\n          if patient:\n              patient_dir = os.path.join(dir, patient)\n              patient_data = self.build_patient_data_map(patient_dir)\n              patient_file = MedFile(patient_data, self.build_sampler(nb_workers))\n              medfiles.append(patient_file)\n\n      return medfiles\n\ndef build_patient_data_map(self, dir):\n      # pads each dimension of the image on both sides.\n      pad_reflect = Pad(((1, 1), (3, 3), (1, 1)), 'reflect')\n      file_map = {\n          'image_ref': SitkReader(\n              os.path.join(dir, 'prepro_im_mni_bc.nii.gz'),\n              torch_type='torch.FloatTensor', transform=pad_reflect),\n          'target': SitkReader(\n              os.path.join(dir, 'prepro_seg_mni.nii.gz'),\n              torch_type='torch.LongTensor', transform=pad_reflect)\n      }\n\n      return file_map\n\ndef build_sampler(self, nb_workers):\n    # sliding window of size [184, 7, 184] without padding\n    patch2d = SquaredSlidingWindow(patch_size=[184, 7, 184], use_padding=False)\n    # pattern map links image id to a Sampler\n    pattern_mapper = {'input': ('image_ref', patch2d),\n                      'target': ('target', patch2d)}\n\n    # add a fixed offset to make patch sampling faster (doesn't look for all positions)\n    return MaskableSampler(pattern_mapper, offset=[92, 1, 92],\n                           nb_workers=nb_workers)\n\n```\n\n### Examples\n\nSee the `datasets` folder of the examples for a more pratical use case.\n\n#### Credits\n\nEvaluation metrics are mostly based on MedPy.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/trypag/pytorch-med", "keywords": "", "license": "GNU GPLv3", "maintainer": "", "maintainer_email": "", "name": "torchmed", "package_url": "https://pypi.org/project/torchmed/", "platform": "", "project_url": "https://pypi.org/project/torchmed/", "project_urls": {"Homepage": "https://github.com/trypag/pytorch-med"}, "release_url": "https://pypi.org/project/torchmed/0.0.1a0/", "requires_dist": ["torch (>=1.0.0)", "nibabel", "SimpleITK", "Pillow", "numpy", "pandas", "scipy", "matplotlib", "opencv-python"], "requires_python": ">=3", "summary": "A compagnon library for deep learning on medical imaging", "version": "0.0.1a0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TorchMed</h1>\n<p>Read and process medical images in PyTorch.</p>\n<p><a href=\"https://travis-ci.com/trypag/pytorch-med\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3c81e4cf815b4bedda904b323312a9dd0b1af0b7/68747470733a2f2f7472617669732d63692e636f6d2f7472797061672f7079746f7263682d6d65642e7376673f746f6b656e3d573755545144714e5565323178744c666971526d266272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/trypag/pytorch-med\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3f59bf614a31e1e93711697164beb2e9efb365cf/68747470733a2f2f636f6465636f762e696f2f67682f7472797061672f7079746f7263682d6d65642f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d6b4c334153456b613442\"></a></p>\n<hr>\n<p>This library is designed as a flexible tool to process various types N dimension images.\nThrough a set of image <strong>readers</strong> based on famous projects (SimpleITK, NiBabel, OpenCV, Pillow)\nyou will be able to load your data. Once loaded, specific sub-sampling of the original\ndata is performed with <strong>patterns</strong> (describing what/how to extract) and <strong>samplers</strong>\n(checks where to extract).</p>\n<p>With <strong>readers</strong>, <strong>samplers</strong> and <strong>patterns</strong>, you can compose <strong>datasets</strong> which\na perfectly suited for PyTorch.</p>\n<h2>Install</h2>\n<p>From pip:</p>\n<pre>pip install torchmed\n</pre>\n<p>Locally :</p>\n<pre>python install setup.py\n</pre>\n<h2>Usage</h2>\n<h3>Reader</h3>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">torchmed</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">torchmed</span><span class=\"o\">.</span><span class=\"n\">readers</span><span class=\"o\">.</span><span class=\"n\">SitkReader</span><span class=\"p\">(</span><span class=\"s1\">'prepro_im_mni_bc.nii.gz'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">label_map</span> <span class=\"o\">=</span> <span class=\"n\">torchmed</span><span class=\"o\">.</span><span class=\"n\">readers</span><span class=\"o\">.</span><span class=\"n\">SitkReader</span><span class=\"p\">(</span><span class=\"s1\">'prepro_seg_mni.nii.gz'</span><span class=\"p\">)</span>\n<span class=\"c1\"># gets image data</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">image_array</span> <span class=\"o\">=</span> <span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">to_torch</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">label_array</span> <span class=\"o\">=</span> <span class=\"n\">label_map</span><span class=\"o\">.</span><span class=\"n\">to_torch</span><span class=\"p\">()</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">image_array</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">182</span><span class=\"p\">,</span> <span class=\"mi\">218</span><span class=\"p\">,</span> <span class=\"mi\">182</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"n\">image_array</span><span class=\"p\">)</span>\n<span class=\"o\">&lt;</span><span class=\"k\">class</span> <span class=\"err\">'</span><span class=\"nc\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"s1\">'&gt;</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">label_array</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"mf\">0.</span><span class=\"p\">)</span>\n<span class=\"c1\"># also available for Numpy</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">to_numpy</span><span class=\"p\">())</span>\n<span class=\"o\">&lt;</span><span class=\"k\">class</span> <span class=\"err\">'</span><span class=\"nc\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span><span class=\"s1\">'&gt;</span>\n</pre>\n<h3>Pattern</h3>\n<p>Patterns are useful to specify how the data should be extracted from an image.\nIt is possible to apply several patterns on one or more images.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">torchmed</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">torchmed</span><span class=\"o\">.</span><span class=\"n\">readers</span><span class=\"o\">.</span><span class=\"n\">SitkReader</span><span class=\"p\">(</span><span class=\"s1\">'prepro_im_mni_bc.nii.gz'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span> <span class=\"o\">=</span> <span class=\"n\">torchmed</span><span class=\"o\">.</span><span class=\"n\">patterns</span><span class=\"o\">.</span><span class=\"n\">SquaredSlidingWindow</span><span class=\"p\">([</span><span class=\"mi\">182</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">182</span><span class=\"p\">],</span> <span class=\"n\">use_padding</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"c1\"># initialize the pattern with the image properties</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span><span class=\"o\">.</span><span class=\"n\">prepare</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># can_apply checks if a pattern can be applied at a given position</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span><span class=\"o\">.</span><span class=\"n\">can_apply</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"kc\">False</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span><span class=\"o\">.</span><span class=\"n\">can_apply</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">91</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">91</span><span class=\"p\">])</span>\n<span class=\"kc\">True</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span><span class=\"o\">.</span><span class=\"n\">can_apply</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">91</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">91</span><span class=\"p\">])</span>\n<span class=\"kc\">True</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span><span class=\"o\">.</span><span class=\"n\">can_apply</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">91</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">91</span><span class=\"p\">])</span>\n<span class=\"kc\">False</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">square_patch</span><span class=\"o\">.</span><span class=\"n\">can_apply</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">91</span><span class=\"p\">,</span><span class=\"mi\">154</span><span class=\"p\">,</span><span class=\"mi\">91</span><span class=\"p\">])</span>\n<span class=\"kc\">True</span>\n\n<span class=\"c1\"># to extract a patch at a correct position</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sample</span> <span class=\"o\">=</span> <span class=\"n\">square_patch</span><span class=\"p\">(</span><span class=\"n\">image_arr</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">91</span><span class=\"p\">,</span><span class=\"mi\">154</span><span class=\"p\">,</span><span class=\"mi\">91</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sample</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">182</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">182</span><span class=\"p\">])</span>\n</pre>\n<h3>Sampler</h3>\n<p>Multi-processed sampler to automatically search for coordinates where sampling\n(pattern extraction) is possible.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">torchmed.readers</span> <span class=\"kn\">import</span> <span class=\"n\">SitkReader</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">torchmed.samplers</span> <span class=\"kn\">import</span> <span class=\"n\">MaskableSampler</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">torchmed.patterns</span> <span class=\"kn\">import</span> <span class=\"n\">SquaredSlidingWindow</span>\n\n<span class=\"c1\"># maps a name to each image</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">file_map</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n<span class=\"o\">...</span>         <span class=\"s1\">'image_ref'</span><span class=\"p\">:</span> <span class=\"n\">SitkReader</span><span class=\"p\">(</span><span class=\"s1\">'prepro_im_mni_bc.nii.gz'</span><span class=\"p\">,</span>\n<span class=\"o\">...</span>             <span class=\"n\">torch_type</span><span class=\"o\">=</span><span class=\"s1\">'torch.FloatTensor'</span><span class=\"p\">),</span>\n<span class=\"o\">...</span>         <span class=\"s1\">'target'</span><span class=\"p\">:</span> <span class=\"n\">SitkReader</span><span class=\"p\">(</span><span class=\"s1\">'prepro_seg_mni.nii.gz'</span><span class=\"p\">,</span>\n<span class=\"o\">...</span>             <span class=\"n\">torch_type</span><span class=\"o\">=</span><span class=\"s1\">'torch.LongTensor'</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>     <span class=\"p\">}</span>\n\n<span class=\"c1\"># sliding window pattern</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">patch2d</span> <span class=\"o\">=</span> <span class=\"n\">SquaredSlidingWindow</span><span class=\"p\">(</span><span class=\"n\">patch_size</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">182</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">182</span><span class=\"p\">],</span> <span class=\"n\">use_padding</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"c1\"># specify a pattern for each input image</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pattern_mapper</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'input'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'image_ref'</span><span class=\"p\">,</span> <span class=\"n\">patch2d</span><span class=\"p\">),</span>\n<span class=\"o\">...</span>                   <span class=\"s1\">'target'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'target'</span><span class=\"p\">,</span> <span class=\"n\">patch2d</span><span class=\"p\">)}</span>\n<span class=\"c1\"># muli-processed sampler with offset</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sampler</span> <span class=\"o\">=</span> <span class=\"n\">MaskableSampler</span><span class=\"p\">(</span><span class=\"n\">pattern_mapper</span><span class=\"p\">,</span> <span class=\"n\">offset</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">91</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">91</span><span class=\"p\">],</span> <span class=\"n\">nb_workers</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sampler</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">file_map</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">sampler</span><span class=\"p\">)</span>\n<span class=\"mi\">212</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sample</span> <span class=\"o\">=</span> <span class=\"n\">sampler</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">type</span><span class=\"p\">(</span><span class=\"n\">sample</span><span class=\"p\">)</span>\n<span class=\"o\">&lt;</span><span class=\"k\">class</span> <span class=\"err\">'</span><span class=\"nc\">tuple</span><span class=\"s1\">'&gt;</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sample</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">3</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sample</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">182</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">182</span><span class=\"p\">])</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">sample</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">()</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Size</span><span class=\"p\">([</span><span class=\"mi\">182</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">182</span><span class=\"p\">])</span>\n</pre>\n<h3>Dataset</h3>\n<p><code>MedFile</code> and <code>MedFolder</code> are iterable datasets, returning samples from the input\ndata. Here is an example of how to build a <code>MedFolder</code> from a list of images.\nA <code>MedFolder</code> takes as input a list of <code>MedFile</code>s.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchmed.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">MedFile</span><span class=\"p\">,</span> <span class=\"n\">MedFolder</span>\n\n<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">train_dataset</span> <span class=\"o\">=</span> <span class=\"n\">MedFolder</span><span class=\"p\">(</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">generate_medfiles</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">base_dir</span><span class=\"p\">,</span> <span class=\"s1\">'train'</span><span class=\"p\">),</span> <span class=\"n\">nb_workers</span><span class=\"p\">))</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">generate_medfiles</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"nb\">dir</span><span class=\"p\">,</span> <span class=\"n\">nb_workers</span><span class=\"p\">):</span>\n      <span class=\"c1\"># database composed of dirname contained in the allowed_data.txt</span>\n      <span class=\"n\">database</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"nb\">dir</span><span class=\"p\">,</span> <span class=\"s1\">'allowed_data.txt'</span><span class=\"p\">),</span> <span class=\"s1\">'r'</span><span class=\"p\">)</span>\n      <span class=\"n\">patient_list</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">line</span><span class=\"o\">.</span><span class=\"n\">rstrip</span><span class=\"p\">(</span><span class=\"s1\">'</span><span class=\"se\">\\n</span><span class=\"s1\">'</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">line</span> <span class=\"ow\">in</span> <span class=\"n\">database</span><span class=\"p\">]</span>\n      <span class=\"n\">medfiles</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n      <span class=\"c1\"># builds a list of MedFiles, one for each folder</span>\n      <span class=\"k\">for</span> <span class=\"n\">patient</span> <span class=\"ow\">in</span> <span class=\"n\">patient_list</span><span class=\"p\">:</span>\n          <span class=\"k\">if</span> <span class=\"n\">patient</span><span class=\"p\">:</span>\n              <span class=\"n\">patient_dir</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"nb\">dir</span><span class=\"p\">,</span> <span class=\"n\">patient</span><span class=\"p\">)</span>\n              <span class=\"n\">patient_data</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">build_patient_data_map</span><span class=\"p\">(</span><span class=\"n\">patient_dir</span><span class=\"p\">)</span>\n              <span class=\"n\">patient_file</span> <span class=\"o\">=</span> <span class=\"n\">MedFile</span><span class=\"p\">(</span><span class=\"n\">patient_data</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">build_sampler</span><span class=\"p\">(</span><span class=\"n\">nb_workers</span><span class=\"p\">))</span>\n              <span class=\"n\">medfiles</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">patient_file</span><span class=\"p\">)</span>\n\n      <span class=\"k\">return</span> <span class=\"n\">medfiles</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">build_patient_data_map</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"nb\">dir</span><span class=\"p\">):</span>\n      <span class=\"c1\"># pads each dimension of the image on both sides.</span>\n      <span class=\"n\">pad_reflect</span> <span class=\"o\">=</span> <span class=\"n\">Pad</span><span class=\"p\">(((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)),</span> <span class=\"s1\">'reflect'</span><span class=\"p\">)</span>\n      <span class=\"n\">file_map</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n          <span class=\"s1\">'image_ref'</span><span class=\"p\">:</span> <span class=\"n\">SitkReader</span><span class=\"p\">(</span>\n              <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"nb\">dir</span><span class=\"p\">,</span> <span class=\"s1\">'prepro_im_mni_bc.nii.gz'</span><span class=\"p\">),</span>\n              <span class=\"n\">torch_type</span><span class=\"o\">=</span><span class=\"s1\">'torch.FloatTensor'</span><span class=\"p\">,</span> <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">pad_reflect</span><span class=\"p\">),</span>\n          <span class=\"s1\">'target'</span><span class=\"p\">:</span> <span class=\"n\">SitkReader</span><span class=\"p\">(</span>\n              <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"nb\">dir</span><span class=\"p\">,</span> <span class=\"s1\">'prepro_seg_mni.nii.gz'</span><span class=\"p\">),</span>\n              <span class=\"n\">torch_type</span><span class=\"o\">=</span><span class=\"s1\">'torch.LongTensor'</span><span class=\"p\">,</span> <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">pad_reflect</span><span class=\"p\">)</span>\n      <span class=\"p\">}</span>\n\n      <span class=\"k\">return</span> <span class=\"n\">file_map</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">build_sampler</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">nb_workers</span><span class=\"p\">):</span>\n    <span class=\"c1\"># sliding window of size [184, 7, 184] without padding</span>\n    <span class=\"n\">patch2d</span> <span class=\"o\">=</span> <span class=\"n\">SquaredSlidingWindow</span><span class=\"p\">(</span><span class=\"n\">patch_size</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">184</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">184</span><span class=\"p\">],</span> <span class=\"n\">use_padding</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n    <span class=\"c1\"># pattern map links image id to a Sampler</span>\n    <span class=\"n\">pattern_mapper</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'input'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'image_ref'</span><span class=\"p\">,</span> <span class=\"n\">patch2d</span><span class=\"p\">),</span>\n                      <span class=\"s1\">'target'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'target'</span><span class=\"p\">,</span> <span class=\"n\">patch2d</span><span class=\"p\">)}</span>\n\n    <span class=\"c1\"># add a fixed offset to make patch sampling faster (doesn't look for all positions)</span>\n    <span class=\"k\">return</span> <span class=\"n\">MaskableSampler</span><span class=\"p\">(</span><span class=\"n\">pattern_mapper</span><span class=\"p\">,</span> <span class=\"n\">offset</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">92</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">92</span><span class=\"p\">],</span>\n                           <span class=\"n\">nb_workers</span><span class=\"o\">=</span><span class=\"n\">nb_workers</span><span class=\"p\">)</span>\n</pre>\n<h3>Examples</h3>\n<p>See the <code>datasets</code> folder of the examples for a more pratical use case.</p>\n<h4>Credits</h4>\n<p>Evaluation metrics are mostly based on MedPy.</p>\n\n          </div>"}, "last_serial": 4782905, "releases": {"0.0.1a0": [{"comment_text": "", "digests": {"md5": "bc7983fd2dec09bb564cc046813ded14", "sha256": "9ce70dbe19917bb3fa8795e37a45915c56ba9f07b0d596561555feee6c0367df"}, "downloads": -1, "filename": "torchmed-0.0.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "bc7983fd2dec09bb564cc046813ded14", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 34062, "upload_time": "2019-02-05T16:45:44", "upload_time_iso_8601": "2019-02-05T16:45:44.371704Z", "url": "https://files.pythonhosted.org/packages/20/3a/3d3320e0e839bb4a8715ae15e610ccaa348c01b82381ffe7b253d463e105/torchmed-0.0.1a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7897f126bda4d41b1c429b323f0da8a3", "sha256": "4ab7744b6e164aa718e6cb83a3778b7952d2b0b6a108033a93f2e58dd078b269"}, "downloads": -1, "filename": "torchmed-0.0.1a0.tar.gz", "has_sig": false, "md5_digest": "7897f126bda4d41b1c429b323f0da8a3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 24396, "upload_time": "2019-02-05T16:45:46", "upload_time_iso_8601": "2019-02-05T16:45:46.475647Z", "url": "https://files.pythonhosted.org/packages/96/61/fca68f16686aa44781724f5f7a4ebce054340d4dc68296dc1888c7684906/torchmed-0.0.1a0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bc7983fd2dec09bb564cc046813ded14", "sha256": "9ce70dbe19917bb3fa8795e37a45915c56ba9f07b0d596561555feee6c0367df"}, "downloads": -1, "filename": "torchmed-0.0.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "bc7983fd2dec09bb564cc046813ded14", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 34062, "upload_time": "2019-02-05T16:45:44", "upload_time_iso_8601": "2019-02-05T16:45:44.371704Z", "url": "https://files.pythonhosted.org/packages/20/3a/3d3320e0e839bb4a8715ae15e610ccaa348c01b82381ffe7b253d463e105/torchmed-0.0.1a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7897f126bda4d41b1c429b323f0da8a3", "sha256": "4ab7744b6e164aa718e6cb83a3778b7952d2b0b6a108033a93f2e58dd078b269"}, "downloads": -1, "filename": "torchmed-0.0.1a0.tar.gz", "has_sig": false, "md5_digest": "7897f126bda4d41b1c429b323f0da8a3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 24396, "upload_time": "2019-02-05T16:45:46", "upload_time_iso_8601": "2019-02-05T16:45:46.475647Z", "url": "https://files.pythonhosted.org/packages/96/61/fca68f16686aa44781724f5f7a4ebce054340d4dc68296dc1888c7684906/torchmed-0.0.1a0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:16 2020"}