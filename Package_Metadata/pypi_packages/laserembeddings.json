{"info": {"author": "yannvgn", "author_email": "hi@yannvgn.io", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# LASER embeddings\n\n[![Travis (.org) branch](https://img.shields.io/travis/yannvgn/laserembeddings/master?style=flat-square)](https://travis-ci.org/yannvgn/laserembeddings)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/laserembeddings?style=flat-square)\n[![PyPI](https://img.shields.io/pypi/v/laserembeddings.svg?style=flat-square)](https://pypi.org/project/laserembeddings/)\n[![PyPI - License](https://img.shields.io/pypi/l/laserembeddings.svg?style=flat-square)](https://github.com/yannvgn/laserembeddings/blob/master/LICENSE)\n\n**Out-of-the-box multilingual sentence embeddings.**\n\n![Projection of LASER embeddings: similar sentences have similar embeddings](laserembeddings.gif)\n\n_laserembeddings_ is a pip-packaged, production-ready port of Facebook Research's [LASER](https://github.com/facebookresearch/LASER) (Language-Agnostic SEntence Representations) to compute multilingual sentence embeddings.\n\n\u2728 **Version 1.0.1 is here! What's new?**\n- The encoder was fixed to remove an innocuous warning message that would sometimes appear when using PyTorch 1.4 \ud83d\udc1b\n- Japanese extra is now disabled on Windows (sorry) to prevent installation issues and computation failures in other languages \ud83d\ude15\n\n## Context\n\n[LASER](https://github.com/facebookresearch/LASER) is a collection of scripts and models created by Facebook Research to compute **multilingual sentence embeddings** for zero-shot cross-lingual transfer. \n\nWhat does it mean? LASER is able to transform sentences into **language-independent vectors**. Similar sentences get mapped to close vectors (in terms of cosine distance), regardless of the input language.\n\nThat is great, especially if you don't have training sets for the language(s) you want to process: you can build a classifier on top of LASER embeddings, train it on whatever language(s) you have in your training data, and let it classify texts in any language.\n\n**The aim of the package is to make LASER as easy-to-use and easy-to-deploy as possible: zero-config, production-ready, etc., just a two-liner to install.**\n\n\ud83d\udc49 \ud83d\udc49 \ud83d\udc49 For detailed information, have a look at the amazing [LASER repository](https://github.com/facebookresearch/LASER), read its [presentation article](https://code.fb.com/ai-research/laser-multilingual-sentence-embeddings/) and its [research paper](https://arxiv.org/abs/1812.10464). \ud83d\udc48 \ud83d\udc48 \ud83d\udc48\n\n## Getting started\n\nYou'll need Python 3.6 or higher.\n\n### Installation\n\n```\npip install laserembeddings\n```\n\nTo install laserembeddings with extra dependencies:\n\n```\n# if you need Chinese support:\npip install laserembeddings[zh]\n\n# if you need Japanese support (not available on Windows):\npip install laserembeddings[ja]\n\n# or both:\npip install laserembeddings[zh,ja]\n```\n\n### Downloading the pre-trained models\n\n```\npython -m laserembeddings download-models\n```\n\nThis will download the models to the default `data` directory next to the source code of the package. Use `python -m laserembeddings download-models path/to/model/directory` to download the models to a specific location.\n\n### Usage\n\n```python\nfrom laserembeddings import Laser\n\nlaser = Laser()\n\n# if all sentences are in the same language:\n\nembeddings = laser.embed_sentences(\n    ['let your neural network be polyglot',\n     'use multilingual embeddings!'],\n    lang='en')  # lang is only used for tokenization\n\n# embeddings is a N*1024 (N = number of sentences) NumPy array\n```\n\nIf the sentences are not in the same language, you can pass a list of language codes:\n```python\nembeddings = laser.embed_sentences(\n    ['I love pasta.',\n     \"J'adore les p\u00e2tes.\",\n     'Ich liebe Pasta.'],\n    lang=['en', 'fr', 'de'])\n```\n\nIf you downloaded the models into a specific directory:\n\n```python\nfrom laserembeddings import Laser\n\npath_to_bpe_codes = ...\npath_to_bpe_vocab = ...\npath_to_encoder = ...\n\nlaser = Laser(path_to_bpe_codes, path_to_bpe_vocab, path_to_encoder)\n\n# you can also supply file objects instead of file paths\n```\n\nIf you want to pull the models from S3:\n\n```python\nfrom io import BytesIO, StringIO\nfrom laserembeddings import Laser\nimport boto3\n\ns3 = boto3.resource('s3')\nMODELS_BUCKET = ...\n\nf_bpe_codes = StringIO(s3.Object(MODELS_BUCKET, 'path_to_bpe_codes.fcodes').get()['Body'].read().decode('utf-8'))\nf_bpe_vocab = StringIO(s3.Object(MODELS_BUCKET, 'path_to_bpe_vocabulary.fvocab').get()['Body'].read().decode('utf-8'))\nf_encoder = BytesIO(s3.Object(MODELS_BUCKET, 'path_to_encoder.pt').get()['Body'].read())\n\nlaser = Laser(f_bpe_codes, f_bpe_vocab, f_encoder)\n```\n\n## What are the differences with the original implementation?\n\nSome dependencies of the original project have been replaced with pure-python dependencies, to make this package easy to install and deploy.\n\nHere's a summary of the differences:\n\n| Part of the pipeline | LASER dependency (original project) | laserembeddings dependency (this package) | Reason |\n|----------------------|-------------------------------------|----------------------------------------|--------|\n| Normalization / tokenization | [Moses](https://github.com/moses-smt/mosesdecoder) | [Sacremoses](https://github.com/alvations/sacremoses) | Moses is implemented in Perl |\n| BPE encoding | [fastBPE](https://github.com/glample/fastBPE) | [subword-nmt](https://github.com/rsennrich/subword-nmt) | fastBPE cannot be installed via pip and requires compiling C++ code |\n| Japanese segmentation (optional) | [MeCab](https://github.com/taku910/mecab) / [JapaneseTokenizer](https://github.com/Kensuke-Mitsuzawa/JapaneseTokenizers) | [mecab-python3](https://github.com/SamuraiT/mecab-python3) | mecab-python3 comes with wheels for major platforms (no compilation needed) |\n\n## Will I get the exact same embeddings?\n\n**For most languages, in most of the cases, yes.**\n\nSome slight (and not so slight \ud83d\ude44) differences exist for some languages due to differences in the implementation of the Tokenizer.\n\n**[An exhaustive comparison of the embeddings generated with LASER and laserembeddings](tests/report/comparison-with-LASER.md) is automatically generated and will be updated for each new release.**\n\n## FAQ\n\n**How can I train the encoder?**\n\nYou can't. LASER models are pre-trained and do not need to be fine-tuned. The embeddings are generic and perform well without fine-tuning. See https://github.com/facebookresearch/LASER/issues/3#issuecomment-404175463.\n\n## Credits\n\nThanks a lot to the creators of [LASER](https://github.com/facebookresearch/LASER) for open-sourcing the code of LASER and releasing the pre-trained models. All the kudos should go to them \ud83d\udc4f.\n\nA big thanks to the creators of [Sacremoses](https://github.com/alvations/sacremoses) and [Subword Neural Machine Translation](https://github.com/rsennrich/subword-nmt/) for their great packages.\n\n## Testing\n\nThe first thing you'll need is [Poetry](https://github.com/sdispater/poetry). Please refer to the [installation guidelines](https://poetry.eustace.io/docs/#installation).\n\nClone this repository and install the project:\n```\npoetry install\n```\n\nTo run the tests:\n```\npoetry run pytest\n```\n\n### Testing the similarity between the embeddings computed with LASER and laserembeddings\n\nFirst, install the project with the extra dependencies (Chinese and Japanese support):\n```\npoetry install -E zh -E ja\n```\n\nThen, download the test data:\n```\npoetry run python -m laserembeddings download-test-data\n```\n\n\ud83d\udc49 If you want to know more about the contents and the generation of the test data, check out the [laserembeddings-test-data](https://github.com/yannvgn/laserembeddings-test-data) repository.\n\nThen, run the test with `SIMILARITY_TEST` env. variable set to `1`.\n\n```\nSIMILARITY_TEST=1 poetry run pytest tests/test_laser.py\n```\n\nNow, have a coffee \u2615\ufe0f and wait for the test to finish.\n\nThe similarity report will be generated here: [tests/report/comparison-with-LASER.md](tests/report/comparison-with-LASER.md).\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/yannvgn/laserembeddings", "keywords": "", "license": "BSD-3-Clause", "maintainer": "", "maintainer_email": "", "name": "laserembeddings", "package_url": "https://pypi.org/project/laserembeddings/", "platform": "", "project_url": "https://pypi.org/project/laserembeddings/", "project_urls": {"Homepage": "https://github.com/yannvgn/laserembeddings", "Repository": "https://github.com/yannvgn/laserembeddings"}, "release_url": "https://pypi.org/project/laserembeddings/1.0.1/", "requires_dist": ["torch (>=1.0.1.post2,<2.0.0)", "subword-nmt (>=0.3.6,<0.4.0)", "numpy (>=1.15.4,<2.0.0)", "sacremoses (==0.0.35)", "transliterate (==1.10.2)", "mecab-python3 (>=0.996.3,<0.997.0); (sys_platform != \"win32\") and (extra == \"ja\")", "jieba (>=0.42.1,<0.43.0); extra == \"zh\""], "requires_python": ">=3.6,<4.0", "summary": "Production-ready LASER multilingual embeddings", "version": "1.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>LASER embeddings</h1>\n<p><a href=\"https://travis-ci.org/yannvgn/laserembeddings\" rel=\"nofollow\"><img alt=\"Travis (.org) branch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bf8516813bdc8b1a6c1dfdd90986352e10b0af9c/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f79616e6e76676e2f6c61736572656d62656464696e67732f6d61737465723f7374796c653d666c61742d737175617265\"></a>\n<img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/912003d2d65576765d25d15a39a6bc1423087c22/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6c61736572656d62656464696e67733f7374796c653d666c61742d737175617265\">\n<a href=\"https://pypi.org/project/laserembeddings/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2a9e9864186c3d0154d44283f4e137fde21e2e5d/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c61736572656d62656464696e67732e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://github.com/yannvgn/laserembeddings/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"PyPI - License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/78684f2155ae306b835ab5253bc253337036b265/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6c61736572656d62656464696e67732e7376673f7374796c653d666c61742d737175617265\"></a></p>\n<p><strong>Out-of-the-box multilingual sentence embeddings.</strong></p>\n<p><img alt=\"Projection of LASER embeddings: similar sentences have similar embeddings\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5187b95def0c63b1e4bea21594862ec1f3983f55/6c61736572656d62656464696e67732e676966\"></p>\n<p><em>laserembeddings</em> is a pip-packaged, production-ready port of Facebook Research's <a href=\"https://github.com/facebookresearch/LASER\" rel=\"nofollow\">LASER</a> (Language-Agnostic SEntence Representations) to compute multilingual sentence embeddings.</p>\n<p>\u2728 <strong>Version 1.0.1 is here! What's new?</strong></p>\n<ul>\n<li>The encoder was fixed to remove an innocuous warning message that would sometimes appear when using PyTorch 1.4 \ud83d\udc1b</li>\n<li>Japanese extra is now disabled on Windows (sorry) to prevent installation issues and computation failures in other languages \ud83d\ude15</li>\n</ul>\n<h2>Context</h2>\n<p><a href=\"https://github.com/facebookresearch/LASER\" rel=\"nofollow\">LASER</a> is a collection of scripts and models created by Facebook Research to compute <strong>multilingual sentence embeddings</strong> for zero-shot cross-lingual transfer.</p>\n<p>What does it mean? LASER is able to transform sentences into <strong>language-independent vectors</strong>. Similar sentences get mapped to close vectors (in terms of cosine distance), regardless of the input language.</p>\n<p>That is great, especially if you don't have training sets for the language(s) you want to process: you can build a classifier on top of LASER embeddings, train it on whatever language(s) you have in your training data, and let it classify texts in any language.</p>\n<p><strong>The aim of the package is to make LASER as easy-to-use and easy-to-deploy as possible: zero-config, production-ready, etc., just a two-liner to install.</strong></p>\n<p>\ud83d\udc49 \ud83d\udc49 \ud83d\udc49 For detailed information, have a look at the amazing <a href=\"https://github.com/facebookresearch/LASER\" rel=\"nofollow\">LASER repository</a>, read its <a href=\"https://code.fb.com/ai-research/laser-multilingual-sentence-embeddings/\" rel=\"nofollow\">presentation article</a> and its <a href=\"https://arxiv.org/abs/1812.10464\" rel=\"nofollow\">research paper</a>. \ud83d\udc48 \ud83d\udc48 \ud83d\udc48</p>\n<h2>Getting started</h2>\n<p>You'll need Python 3.6 or higher.</p>\n<h3>Installation</h3>\n<pre><code>pip install laserembeddings\n</code></pre>\n<p>To install laserembeddings with extra dependencies:</p>\n<pre><code># if you need Chinese support:\npip install laserembeddings[zh]\n\n# if you need Japanese support (not available on Windows):\npip install laserembeddings[ja]\n\n# or both:\npip install laserembeddings[zh,ja]\n</code></pre>\n<h3>Downloading the pre-trained models</h3>\n<pre><code>python -m laserembeddings download-models\n</code></pre>\n<p>This will download the models to the default <code>data</code> directory next to the source code of the package. Use <code>python -m laserembeddings download-models path/to/model/directory</code> to download the models to a specific location.</p>\n<h3>Usage</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">laserembeddings</span> <span class=\"kn\">import</span> <span class=\"n\">Laser</span>\n\n<span class=\"n\">laser</span> <span class=\"o\">=</span> <span class=\"n\">Laser</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># if all sentences are in the same language:</span>\n\n<span class=\"n\">embeddings</span> <span class=\"o\">=</span> <span class=\"n\">laser</span><span class=\"o\">.</span><span class=\"n\">embed_sentences</span><span class=\"p\">(</span>\n    <span class=\"p\">[</span><span class=\"s1\">'let your neural network be polyglot'</span><span class=\"p\">,</span>\n     <span class=\"s1\">'use multilingual embeddings!'</span><span class=\"p\">],</span>\n    <span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s1\">'en'</span><span class=\"p\">)</span>  <span class=\"c1\"># lang is only used for tokenization</span>\n\n<span class=\"c1\"># embeddings is a N*1024 (N = number of sentences) NumPy array</span>\n</pre>\n<p>If the sentences are not in the same language, you can pass a list of language codes:</p>\n<pre><span class=\"n\">embeddings</span> <span class=\"o\">=</span> <span class=\"n\">laser</span><span class=\"o\">.</span><span class=\"n\">embed_sentences</span><span class=\"p\">(</span>\n    <span class=\"p\">[</span><span class=\"s1\">'I love pasta.'</span><span class=\"p\">,</span>\n     <span class=\"s2\">\"J'adore les p\u00e2tes.\"</span><span class=\"p\">,</span>\n     <span class=\"s1\">'Ich liebe Pasta.'</span><span class=\"p\">],</span>\n    <span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'en'</span><span class=\"p\">,</span> <span class=\"s1\">'fr'</span><span class=\"p\">,</span> <span class=\"s1\">'de'</span><span class=\"p\">])</span>\n</pre>\n<p>If you downloaded the models into a specific directory:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">laserembeddings</span> <span class=\"kn\">import</span> <span class=\"n\">Laser</span>\n\n<span class=\"n\">path_to_bpe_codes</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n<span class=\"n\">path_to_bpe_vocab</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n<span class=\"n\">path_to_encoder</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n\n<span class=\"n\">laser</span> <span class=\"o\">=</span> <span class=\"n\">Laser</span><span class=\"p\">(</span><span class=\"n\">path_to_bpe_codes</span><span class=\"p\">,</span> <span class=\"n\">path_to_bpe_vocab</span><span class=\"p\">,</span> <span class=\"n\">path_to_encoder</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># you can also supply file objects instead of file paths</span>\n</pre>\n<p>If you want to pull the models from S3:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">io</span> <span class=\"kn\">import</span> <span class=\"n\">BytesIO</span><span class=\"p\">,</span> <span class=\"n\">StringIO</span>\n<span class=\"kn\">from</span> <span class=\"nn\">laserembeddings</span> <span class=\"kn\">import</span> <span class=\"n\">Laser</span>\n<span class=\"kn\">import</span> <span class=\"nn\">boto3</span>\n\n<span class=\"n\">s3</span> <span class=\"o\">=</span> <span class=\"n\">boto3</span><span class=\"o\">.</span><span class=\"n\">resource</span><span class=\"p\">(</span><span class=\"s1\">'s3'</span><span class=\"p\">)</span>\n<span class=\"n\">MODELS_BUCKET</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n\n<span class=\"n\">f_bpe_codes</span> <span class=\"o\">=</span> <span class=\"n\">StringIO</span><span class=\"p\">(</span><span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">Object</span><span class=\"p\">(</span><span class=\"n\">MODELS_BUCKET</span><span class=\"p\">,</span> <span class=\"s1\">'path_to_bpe_codes.fcodes'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()[</span><span class=\"s1\">'Body'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"s1\">'utf-8'</span><span class=\"p\">))</span>\n<span class=\"n\">f_bpe_vocab</span> <span class=\"o\">=</span> <span class=\"n\">StringIO</span><span class=\"p\">(</span><span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">Object</span><span class=\"p\">(</span><span class=\"n\">MODELS_BUCKET</span><span class=\"p\">,</span> <span class=\"s1\">'path_to_bpe_vocabulary.fvocab'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()[</span><span class=\"s1\">'Body'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"s1\">'utf-8'</span><span class=\"p\">))</span>\n<span class=\"n\">f_encoder</span> <span class=\"o\">=</span> <span class=\"n\">BytesIO</span><span class=\"p\">(</span><span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">Object</span><span class=\"p\">(</span><span class=\"n\">MODELS_BUCKET</span><span class=\"p\">,</span> <span class=\"s1\">'path_to_encoder.pt'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">()[</span><span class=\"s1\">'Body'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">())</span>\n\n<span class=\"n\">laser</span> <span class=\"o\">=</span> <span class=\"n\">Laser</span><span class=\"p\">(</span><span class=\"n\">f_bpe_codes</span><span class=\"p\">,</span> <span class=\"n\">f_bpe_vocab</span><span class=\"p\">,</span> <span class=\"n\">f_encoder</span><span class=\"p\">)</span>\n</pre>\n<h2>What are the differences with the original implementation?</h2>\n<p>Some dependencies of the original project have been replaced with pure-python dependencies, to make this package easy to install and deploy.</p>\n<p>Here's a summary of the differences:</p>\n<table>\n<thead>\n<tr>\n<th>Part of the pipeline</th>\n<th>LASER dependency (original project)</th>\n<th>laserembeddings dependency (this package)</th>\n<th>Reason</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Normalization / tokenization</td>\n<td><a href=\"https://github.com/moses-smt/mosesdecoder\" rel=\"nofollow\">Moses</a></td>\n<td><a href=\"https://github.com/alvations/sacremoses\" rel=\"nofollow\">Sacremoses</a></td>\n<td>Moses is implemented in Perl</td>\n</tr>\n<tr>\n<td>BPE encoding</td>\n<td><a href=\"https://github.com/glample/fastBPE\" rel=\"nofollow\">fastBPE</a></td>\n<td><a href=\"https://github.com/rsennrich/subword-nmt\" rel=\"nofollow\">subword-nmt</a></td>\n<td>fastBPE cannot be installed via pip and requires compiling C++ code</td>\n</tr>\n<tr>\n<td>Japanese segmentation (optional)</td>\n<td><a href=\"https://github.com/taku910/mecab\" rel=\"nofollow\">MeCab</a> / <a href=\"https://github.com/Kensuke-Mitsuzawa/JapaneseTokenizers\" rel=\"nofollow\">JapaneseTokenizer</a></td>\n<td><a href=\"https://github.com/SamuraiT/mecab-python3\" rel=\"nofollow\">mecab-python3</a></td>\n<td>mecab-python3 comes with wheels for major platforms (no compilation needed)</td>\n</tr></tbody></table>\n<h2>Will I get the exact same embeddings?</h2>\n<p><strong>For most languages, in most of the cases, yes.</strong></p>\n<p>Some slight (and not so slight \ud83d\ude44) differences exist for some languages due to differences in the implementation of the Tokenizer.</p>\n<p><strong><a href=\"tests/report/comparison-with-LASER.md\" rel=\"nofollow\">An exhaustive comparison of the embeddings generated with LASER and laserembeddings</a> is automatically generated and will be updated for each new release.</strong></p>\n<h2>FAQ</h2>\n<p><strong>How can I train the encoder?</strong></p>\n<p>You can't. LASER models are pre-trained and do not need to be fine-tuned. The embeddings are generic and perform well without fine-tuning. See <a href=\"https://github.com/facebookresearch/LASER/issues/3#issuecomment-404175463\" rel=\"nofollow\">https://github.com/facebookresearch/LASER/issues/3#issuecomment-404175463</a>.</p>\n<h2>Credits</h2>\n<p>Thanks a lot to the creators of <a href=\"https://github.com/facebookresearch/LASER\" rel=\"nofollow\">LASER</a> for open-sourcing the code of LASER and releasing the pre-trained models. All the kudos should go to them \ud83d\udc4f.</p>\n<p>A big thanks to the creators of <a href=\"https://github.com/alvations/sacremoses\" rel=\"nofollow\">Sacremoses</a> and <a href=\"https://github.com/rsennrich/subword-nmt/\" rel=\"nofollow\">Subword Neural Machine Translation</a> for their great packages.</p>\n<h2>Testing</h2>\n<p>The first thing you'll need is <a href=\"https://github.com/sdispater/poetry\" rel=\"nofollow\">Poetry</a>. Please refer to the <a href=\"https://poetry.eustace.io/docs/#installation\" rel=\"nofollow\">installation guidelines</a>.</p>\n<p>Clone this repository and install the project:</p>\n<pre><code>poetry install\n</code></pre>\n<p>To run the tests:</p>\n<pre><code>poetry run pytest\n</code></pre>\n<h3>Testing the similarity between the embeddings computed with LASER and laserembeddings</h3>\n<p>First, install the project with the extra dependencies (Chinese and Japanese support):</p>\n<pre><code>poetry install -E zh -E ja\n</code></pre>\n<p>Then, download the test data:</p>\n<pre><code>poetry run python -m laserembeddings download-test-data\n</code></pre>\n<p>\ud83d\udc49 If you want to know more about the contents and the generation of the test data, check out the <a href=\"https://github.com/yannvgn/laserembeddings-test-data\" rel=\"nofollow\">laserembeddings-test-data</a> repository.</p>\n<p>Then, run the test with <code>SIMILARITY_TEST</code> env. variable set to <code>1</code>.</p>\n<pre><code>SIMILARITY_TEST=1 poetry run pytest tests/test_laser.py\n</code></pre>\n<p>Now, have a coffee \u2615\ufe0f and wait for the test to finish.</p>\n<p>The similarity report will be generated here: <a href=\"tests/report/comparison-with-LASER.md\" rel=\"nofollow\">tests/report/comparison-with-LASER.md</a>.</p>\n\n          </div>"}, "last_serial": 6732152, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "194301dc16960611e7c537d7eee67632", "sha256": "1db711a56f59db7e992d16347ffe7c73f96dd3b175a6f851a856a0b342ff8a55"}, "downloads": -1, "filename": "laserembeddings-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "194301dc16960611e7c537d7eee67632", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 10772, "upload_time": "2019-07-23T18:25:18", "upload_time_iso_8601": "2019-07-23T18:25:18.126805Z", "url": "https://files.pythonhosted.org/packages/c5/f6/f8a6e47c0ade1e082c9bca87d2a66fd3afe3dbf73b1e40c7c6ef950f5b5d/laserembeddings-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9fe63132442a90119bc1f44376061a98", "sha256": "3ac60f3234c81acfe20e0ee657bb8377a053d0d1033ba1b27e9fd0f295228480"}, "downloads": -1, "filename": "laserembeddings-0.1.0.tar.gz", "has_sig": false, "md5_digest": "9fe63132442a90119bc1f44376061a98", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 8589, "upload_time": "2019-07-23T18:25:20", "upload_time_iso_8601": "2019-07-23T18:25:20.594994Z", "url": "https://files.pythonhosted.org/packages/a8/1a/a21af873a34383f1425e3aad967d3864dc9c36516966e6a8ce31d345ebe9/laserembeddings-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "14fa1f155083c5d6194da4df2e6bd8c1", "sha256": "f8da60b17b99281b7799f0731506891b0f94cab3152d3f620da394b5f8638775"}, "downloads": -1, "filename": "laserembeddings-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "14fa1f155083c5d6194da4df2e6bd8c1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13153, "upload_time": "2019-07-23T20:01:09", "upload_time_iso_8601": "2019-07-23T20:01:09.853696Z", "url": "https://files.pythonhosted.org/packages/27/dd/b15b821768fac193c3b319a646ffdfa755213981411901c2d352e5705817/laserembeddings-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "810971f207c52bf72d7829d1b7757f7b", "sha256": "99a8c0cc491d77eca04085aae12d87707594106c80678e137580b64db2514c3c"}, "downloads": -1, "filename": "laserembeddings-0.1.1.tar.gz", "has_sig": false, "md5_digest": "810971f207c52bf72d7829d1b7757f7b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 13540, "upload_time": "2019-07-23T20:01:11", "upload_time_iso_8601": "2019-07-23T20:01:11.703602Z", "url": "https://files.pythonhosted.org/packages/ce/27/621df2bac5567c8db18fdef9ab418d0d0d741b71571c3f78ec0811671672/laserembeddings-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "bee7ebf8029edd9518a125ccaba3c209", "sha256": "135b32fe74a52a885907ec69b2705c86c551e23295ba416b148f9e1ab3f53f40"}, "downloads": -1, "filename": "laserembeddings-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "bee7ebf8029edd9518a125ccaba3c209", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13875, "upload_time": "2019-08-24T10:56:31", "upload_time_iso_8601": "2019-08-24T10:56:31.172768Z", "url": "https://files.pythonhosted.org/packages/71/fa/2038e0c037e0da5f6b785b9a59b0d0bae897acaad0515278b6109ea9ce46/laserembeddings-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eb2cc770cede4ffdc61c1fe29e36c15a", "sha256": "8adf92b2e06ca8c2a5b42ddb7f1cc2313bba39fc31bce5bf74b0c58cefd1c0ab"}, "downloads": -1, "filename": "laserembeddings-0.1.2.tar.gz", "has_sig": false, "md5_digest": "eb2cc770cede4ffdc61c1fe29e36c15a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 14533, "upload_time": "2019-08-24T10:56:33", "upload_time_iso_8601": "2019-08-24T10:56:33.009213Z", "url": "https://files.pythonhosted.org/packages/c1/60/aa9a39ec95d4332ea7b62eadbae2c4e53141e5851c493b50f979ccf74f46/laserembeddings-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "3d08b7361e4195b2a2c1e0b4be249897", "sha256": "fecce40583d2591a0e4fd8afb7437c8facdd1cda68207cb96032f4f581135d08"}, "downloads": -1, "filename": "laserembeddings-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "3d08b7361e4195b2a2c1e0b4be249897", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13846, "upload_time": "2019-10-03T07:19:13", "upload_time_iso_8601": "2019-10-03T07:19:13.290775Z", "url": "https://files.pythonhosted.org/packages/54/d3/af9dbc6a29b4e48d9c53961ac328e96be726d0deeceb642847f235f5f0ba/laserembeddings-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c3bae9e02afaa7036d58f39963b0da1d", "sha256": "3de1868b3be52df8007dc9f67cfee398dc470d4f26446439649b85fe7d706a0d"}, "downloads": -1, "filename": "laserembeddings-0.1.3.tar.gz", "has_sig": false, "md5_digest": "c3bae9e02afaa7036d58f39963b0da1d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 14501, "upload_time": "2019-10-03T07:19:15", "upload_time_iso_8601": "2019-10-03T07:19:15.538779Z", "url": "https://files.pythonhosted.org/packages/48/ae/af5c8f4e03329f37a8638f7c65b5d1bdd4b0358d6a2f2baf469aba532ba7/laserembeddings-0.1.3.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "5d54a39318e3e85610d5de4032b1a7fc", "sha256": "4b3fbb8e63b781d28050365c8791738f7fce06030aa3cb34458d541e14f47ca7"}, "downloads": -1, "filename": "laserembeddings-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "5d54a39318e3e85610d5de4032b1a7fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 12960, "upload_time": "2019-12-19T09:55:22", "upload_time_iso_8601": "2019-12-19T09:55:22.022744Z", "url": "https://files.pythonhosted.org/packages/c1/17/0c4d38a82461676e44eff868502437713feeaf28f44ce7b5daf8390dbaca/laserembeddings-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cacc457cfc8de2d2a01398e6f4629fda", "sha256": "548092a53cc8595dc08d20da4b1b985c72ce48d872ae6df4ef72c900a5edb60a"}, "downloads": -1, "filename": "laserembeddings-1.0.0.tar.gz", "has_sig": false, "md5_digest": "cacc457cfc8de2d2a01398e6f4629fda", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 12078, "upload_time": "2019-12-19T09:55:23", "upload_time_iso_8601": "2019-12-19T09:55:23.782368Z", "url": "https://files.pythonhosted.org/packages/56/51/2a3f2dd97a888ab4b22a44c19c970e48fd5cbc3cd97690bb2286dff15133/laserembeddings-1.0.0.tar.gz", "yanked": false}], "1.0.0a1": [{"comment_text": "", "digests": {"md5": "e7e5a8019edad5c03cc8bc473a9c04a2", "sha256": "e38e0b2e31d86d496aa273e64ca5c6361bbb270a4779d8ffcc6dd02aa3aa365b"}, "downloads": -1, "filename": "laserembeddings-1.0.0a1-py3-none-any.whl", "has_sig": false, "md5_digest": "e7e5a8019edad5c03cc8bc473a9c04a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 14273, "upload_time": "2019-12-05T18:46:35", "upload_time_iso_8601": "2019-12-05T18:46:35.729598Z", "url": "https://files.pythonhosted.org/packages/e1/9f/654948365d6c99dbbd1db2e1d9d1b3f14a1569d0976724c57acb4a03bff4/laserembeddings-1.0.0a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "adb380f3220e88f6ee2b4063a4b4d1a9", "sha256": "8d3761fc8cd578339b9313c36482e94cdb391c173c407977f237d2d7e903d7b4"}, "downloads": -1, "filename": "laserembeddings-1.0.0a1.tar.gz", "has_sig": false, "md5_digest": "adb380f3220e88f6ee2b4063a4b4d1a9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 14866, "upload_time": "2019-12-05T18:46:37", "upload_time_iso_8601": "2019-12-05T18:46:37.569791Z", "url": "https://files.pythonhosted.org/packages/ad/31/f30b94c66ac4629518da1468ad20bce5ecf75097b5ff251240a8f70c48e4/laserembeddings-1.0.0a1.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "ce0da9fdd500ea35c4e23561ef8fbdfa", "sha256": "d8e6fd88e0c525b26cb85789a4cfbe5f5965edd6da530f4c548deb33ecd7542e"}, "downloads": -1, "filename": "laserembeddings-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ce0da9fdd500ea35c4e23561ef8fbdfa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13089, "upload_time": "2020-03-02T09:26:03", "upload_time_iso_8601": "2020-03-02T09:26:03.623386Z", "url": "https://files.pythonhosted.org/packages/c5/6b/93843d90080666571a79f8eb195fa58aa5e45cf24d36158b9c01dba306e2/laserembeddings-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2203ef0a60cbed2891943ef26a00690b", "sha256": "93e953c7ec10a30295be53403b981c36d465339123c863b4353ac3c46ce9cf07"}, "downloads": -1, "filename": "laserembeddings-1.0.1.tar.gz", "has_sig": false, "md5_digest": "2203ef0a60cbed2891943ef26a00690b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 12258, "upload_time": "2020-03-02T09:26:05", "upload_time_iso_8601": "2020-03-02T09:26:05.585203Z", "url": "https://files.pythonhosted.org/packages/99/81/384b41beedc173472bcde17bc16ac09dbf0559ff6e0d9000032a6856c507/laserembeddings-1.0.1.tar.gz", "yanked": false}], "1.0.1a1": [{"comment_text": "", "digests": {"md5": "cafc2fc98fa3aaf5a8400ec7939ba11f", "sha256": "1364c7b5927617c7b9728023187f778de55719decbf2bf7ea86b57f1699e439d"}, "downloads": -1, "filename": "laserembeddings-1.0.1a1-py3-none-any.whl", "has_sig": false, "md5_digest": "cafc2fc98fa3aaf5a8400ec7939ba11f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13094, "upload_time": "2020-03-02T09:14:09", "upload_time_iso_8601": "2020-03-02T09:14:09.250520Z", "url": "https://files.pythonhosted.org/packages/a7/ce/bea110a875b7b96d3627d6f5b88af4e40a5fd23b51f1068b9899e8f7033b/laserembeddings-1.0.1a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e4acd0c1387fff8312c0d5589ef33057", "sha256": "7b911e627155d55fdb0f55e5a5822017a739e75cbb7e30095a0666fa90f84b52"}, "downloads": -1, "filename": "laserembeddings-1.0.1a1.tar.gz", "has_sig": false, "md5_digest": "e4acd0c1387fff8312c0d5589ef33057", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 12214, "upload_time": "2020-03-02T09:14:11", "upload_time_iso_8601": "2020-03-02T09:14:11.215034Z", "url": "https://files.pythonhosted.org/packages/ba/99/e3e70b2619a361aa0053e44d7b7fed312c6044ac162ceaea819d88178179/laserembeddings-1.0.1a1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ce0da9fdd500ea35c4e23561ef8fbdfa", "sha256": "d8e6fd88e0c525b26cb85789a4cfbe5f5965edd6da530f4c548deb33ecd7542e"}, "downloads": -1, "filename": "laserembeddings-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ce0da9fdd500ea35c4e23561ef8fbdfa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6,<4.0", "size": 13089, "upload_time": "2020-03-02T09:26:03", "upload_time_iso_8601": "2020-03-02T09:26:03.623386Z", "url": "https://files.pythonhosted.org/packages/c5/6b/93843d90080666571a79f8eb195fa58aa5e45cf24d36158b9c01dba306e2/laserembeddings-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2203ef0a60cbed2891943ef26a00690b", "sha256": "93e953c7ec10a30295be53403b981c36d465339123c863b4353ac3c46ce9cf07"}, "downloads": -1, "filename": "laserembeddings-1.0.1.tar.gz", "has_sig": false, "md5_digest": "2203ef0a60cbed2891943ef26a00690b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6,<4.0", "size": 12258, "upload_time": "2020-03-02T09:26:05", "upload_time_iso_8601": "2020-03-02T09:26:05.585203Z", "url": "https://files.pythonhosted.org/packages/99/81/384b41beedc173472bcde17bc16ac09dbf0559ff6e0d9000032a6856c507/laserembeddings-1.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:49 2020"}