{"info": {"author": "Luka Shostenko", "author_email": "luka.shostenko@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "lexrank\n=======\n\nLexRank algorithm for text summarization\n\n.. image:: https://travis-ci.org/wikibusiness/lexrank.svg?branch=dev\n    :target: https://travis-ci.org/wikibusiness/lexrank\n\n.. image:: https://badge.fury.io/py/lexrank.svg\n    :target: https://badge.fury.io/py/lexrank\n\nInfo\n----\n\nLexRank is an unsupervised approach to text summarization based on graph-based centrality scoring of sentences. The main idea is that sentences \"recommend\" other similar sentences to the reader. Thus, if one sentence is very similar to many others, it will likely be a sentence of great importance. The importance of this sentence also stems from the importance of the sentences \"recommending\" it. Thus, to get ranked highly and placed in a summary, a sentence must be similar to many sentences that are in turn also similar to many other sentences. This makes intuitive sense and allows the algorithms to be applied to any arbitrary new text.\n\nInstallation\n------------\n\n.. code-block:: shell\n\n    pip install lexrank\n\nUsage\n-----\n\nIn the following example we use\n`BBC news dataset <http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip>`_\nas a corpus of documents.\n\n.. code-block:: python\n\n    from lexrank import STOPWORDS, LexRank\n    from path import Path\n\n    documents = []\n    documents_dir = Path('bbc/politics')\n\n    for file_path in documents_dir.files('*.txt'):\n        with file_path.open(mode='rt', encoding='utf-8') as fp:\n            documents.append(fp.readlines())\n\n    lxr = LexRank(documents, stopwords=STOPWORDS['en'])\n\n    sentences = [\n        'One of David Cameron\\'s closest friends and Conservative allies, '\n        'George Osborne rose rapidly after becoming MP for Tatton in 2001.',\n\n        'Michael Howard promoted him from shadow chief secretary to the '\n        'Treasury to shadow chancellor in May 2005, at the age of 34.',\n\n        'Mr Osborne took a key role in the election campaign and has been at '\n        'the forefront of the debate on how to deal with the recession and '\n        'the UK\\'s spending deficit.',\n\n        'Even before Mr Cameron became leader the two were being likened to '\n        'Labour\\'s Blair/Brown duo. The two have emulated them by becoming '\n        'prime minister and chancellor, but will want to avoid the spats.',\n\n        'Before entering Parliament, he was a special adviser in the '\n        'agriculture department when the Tories were in government and later '\n        'served as political secretary to William Hague.',\n\n        'The BBC understands that as chancellor, Mr Osborne, along with the '\n        'Treasury will retain responsibility for overseeing banks and '\n        'financial regulation.',\n\n        'Mr Osborne said the coalition government was planning to change the '\n        'tax system \\\"to make it fairer for people on low and middle '\n        'incomes\\\", and undertake \\\"long-term structural reform\\\" of the '\n        'banking sector, education and the welfare state.',\n    ]\n\n    # get summary with classical LexRank algorithm\n    summary = lxr.get_summary(sentences, summary_size=2, threshold=.1)\n    print(summary)\n\n    # ['Mr Osborne said the coalition government was planning to change the tax '\n    #  'system \"to make it fairer for people on low and middle incomes\", and '\n    #  'undertake \"long-term structural reform\" of the banking sector, education and '\n    #  'the welfare state.',\n    #  'The BBC understands that as chancellor, Mr Osborne, along with the Treasury '\n    #  'will retain responsibility for overseeing banks and financial regulation.']\n\n\n    # get summary with continuous LexRank\n    summary_cont = lxr.get_summary(sentences, threshold=None)\n    print(summary_cont)\n\n    # ['The BBC understands that as chancellor, Mr Osborne, along with the Treasury '\n    #  'will retain responsibility for overseeing banks and financial regulation.']\n\n    # get LexRank scores for sentences\n    # 'fast_power_method' speeds up the calculation, but requires more RAM\n    scores_cont = lxr.rank_sentences(\n        sentences,\n        threshold=None,\n        fast_power_method=False,\n    )\n    print(scores_cont)\n\n    #  [1.0896493024505858,\n    #  0.9010711968859021,\n    #  1.1139166497016315,\n    #  0.8279523250808547,\n    #  0.8112028559566362,\n    #  1.185228912485382,\n    #  1.0709787574388283]\n\nStop words for 22 languages are included into the package. To define your own mapping of stop words, prepare text files with utf-8 encoding where words are separated by newlines. Then use the command\n\n.. code-block:: bash\n\n    lexrank_assemble_stopwords --source_dir directory_with_txt_files\n\nthat replaces the default mapping. Note that names of .txt files are used as keys in `STOPWORDS` dictionary.\n\nTests\n-----\n\nTests are not supplied with the package, to run them you need to clone the repository and install additional dependencies.\n\n.. code-block:: bash\n\n    # ensure virtualenv is activated\n    make install-dev\n\nRun linter and tests\n\n.. code-block:: bash\n\n    make lint\n    make test\n\n\nReferences\n----------\n\nG\u00fcne\u015f Erkan and Dragomir R. Radev:\n`LexRank: Graph-based Lexical Centrality as Salience in Text Summarization\n<http://www.jair.org/papers/paper1523.html>`_.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/wikibusiness/lexrank/archive/0.1.0.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/wikibusiness/lexrank", "keywords": "lex,rank,lexrank,algorithm,text,summary,summarization", "license": "MIT", "maintainer": "Ocean S.A.", "maintainer_email": "support@ocean.io", "name": "lexrank", "package_url": "https://pypi.org/project/lexrank/", "platform": "", "project_url": "https://pypi.org/project/lexrank/", "project_urls": {"Download": "https://github.com/wikibusiness/lexrank/archive/0.1.0.tar.gz", "Homepage": "https://github.com/wikibusiness/lexrank"}, "release_url": "https://pypi.org/project/lexrank/0.1.0/", "requires_dist": ["numpy (>=1.13.3)", "path.py (>=10.5)", "pyrsistent (>=0.14.0)", "regex (>=2017.11.9)", "scipy (>=0.19.0)", "urlextract (>=0.7)"], "requires_python": ">=3.5.0", "summary": "LexRank text summarization", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>LexRank algorithm for text summarization</p>\n<a href=\"https://travis-ci.org/wikibusiness/lexrank\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/wikibusiness/lexrank.svg?branch=dev\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/78cfde24fff07cf96492622412cb9b8c2a740c98/68747470733a2f2f7472617669732d63692e6f72672f77696b69627573696e6573732f6c657872616e6b2e7376673f6272616e63683d646576\"></a>\n<a href=\"https://badge.fury.io/py/lexrank\" rel=\"nofollow\"><img alt=\"https://badge.fury.io/py/lexrank.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/edf9d6cf1814f1eab10501390d6591415fad0678/68747470733a2f2f62616467652e667572792e696f2f70792f6c657872616e6b2e737667\"></a>\n<div id=\"info\">\n<h2>Info</h2>\n<p>LexRank is an unsupervised approach to text summarization based on graph-based centrality scoring of sentences. The main idea is that sentences \u201crecommend\u201d other similar sentences to the reader. Thus, if one sentence is very similar to many others, it will likely be a sentence of great importance. The importance of this sentence also stems from the importance of the sentences \u201crecommending\u201d it. Thus, to get ranked highly and placed in a summary, a sentence must be similar to many sentences that are in turn also similar to many other sentences. This makes intuitive sense and allows the algorithms to be applied to any arbitrary new text.</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install lexrank\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<p>In the following example we use\n<a href=\"http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip\" rel=\"nofollow\">BBC news dataset</a>\nas a corpus of documents.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lexrank</span> <span class=\"kn\">import</span> <span class=\"n\">STOPWORDS</span><span class=\"p\">,</span> <span class=\"n\">LexRank</span>\n<span class=\"kn\">from</span> <span class=\"nn\">path</span> <span class=\"kn\">import</span> <span class=\"n\">Path</span>\n\n<span class=\"n\">documents</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"n\">documents_dir</span> <span class=\"o\">=</span> <span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'bbc/politics'</span><span class=\"p\">)</span>\n\n<span class=\"k\">for</span> <span class=\"n\">file_path</span> <span class=\"ow\">in</span> <span class=\"n\">documents_dir</span><span class=\"o\">.</span><span class=\"n\">files</span><span class=\"p\">(</span><span class=\"s1\">'*.txt'</span><span class=\"p\">):</span>\n    <span class=\"k\">with</span> <span class=\"n\">file_path</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'rt'</span><span class=\"p\">,</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"s1\">'utf-8'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">fp</span><span class=\"p\">:</span>\n        <span class=\"n\">documents</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">fp</span><span class=\"o\">.</span><span class=\"n\">readlines</span><span class=\"p\">())</span>\n\n<span class=\"n\">lxr</span> <span class=\"o\">=</span> <span class=\"n\">LexRank</span><span class=\"p\">(</span><span class=\"n\">documents</span><span class=\"p\">,</span> <span class=\"n\">stopwords</span><span class=\"o\">=</span><span class=\"n\">STOPWORDS</span><span class=\"p\">[</span><span class=\"s1\">'en'</span><span class=\"p\">])</span>\n\n<span class=\"n\">sentences</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"s1\">'One of David Cameron</span><span class=\"se\">\\'</span><span class=\"s1\">s closest friends and Conservative allies, '</span>\n    <span class=\"s1\">'George Osborne rose rapidly after becoming MP for Tatton in 2001.'</span><span class=\"p\">,</span>\n\n    <span class=\"s1\">'Michael Howard promoted him from shadow chief secretary to the '</span>\n    <span class=\"s1\">'Treasury to shadow chancellor in May 2005, at the age of 34.'</span><span class=\"p\">,</span>\n\n    <span class=\"s1\">'Mr Osborne took a key role in the election campaign and has been at '</span>\n    <span class=\"s1\">'the forefront of the debate on how to deal with the recession and '</span>\n    <span class=\"s1\">'the UK</span><span class=\"se\">\\'</span><span class=\"s1\">s spending deficit.'</span><span class=\"p\">,</span>\n\n    <span class=\"s1\">'Even before Mr Cameron became leader the two were being likened to '</span>\n    <span class=\"s1\">'Labour</span><span class=\"se\">\\'</span><span class=\"s1\">s Blair/Brown duo. The two have emulated them by becoming '</span>\n    <span class=\"s1\">'prime minister and chancellor, but will want to avoid the spats.'</span><span class=\"p\">,</span>\n\n    <span class=\"s1\">'Before entering Parliament, he was a special adviser in the '</span>\n    <span class=\"s1\">'agriculture department when the Tories were in government and later '</span>\n    <span class=\"s1\">'served as political secretary to William Hague.'</span><span class=\"p\">,</span>\n\n    <span class=\"s1\">'The BBC understands that as chancellor, Mr Osborne, along with the '</span>\n    <span class=\"s1\">'Treasury will retain responsibility for overseeing banks and '</span>\n    <span class=\"s1\">'financial regulation.'</span><span class=\"p\">,</span>\n\n    <span class=\"s1\">'Mr Osborne said the coalition government was planning to change the '</span>\n    <span class=\"s1\">'tax system </span><span class=\"se\">\\\"</span><span class=\"s1\">to make it fairer for people on low and middle '</span>\n    <span class=\"s1\">'incomes</span><span class=\"se\">\\\"</span><span class=\"s1\">, and undertake </span><span class=\"se\">\\\"</span><span class=\"s1\">long-term structural reform</span><span class=\"se\">\\\"</span><span class=\"s1\"> of the '</span>\n    <span class=\"s1\">'banking sector, education and the welfare state.'</span><span class=\"p\">,</span>\n<span class=\"p\">]</span>\n\n<span class=\"c1\"># get summary with classical LexRank algorithm</span>\n<span class=\"n\">summary</span> <span class=\"o\">=</span> <span class=\"n\">lxr</span><span class=\"o\">.</span><span class=\"n\">get_summary</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"p\">,</span> <span class=\"n\">summary_size</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">threshold</span><span class=\"o\">=.</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">summary</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># ['Mr Osborne said the coalition government was planning to change the tax '</span>\n<span class=\"c1\">#  'system \"to make it fairer for people on low and middle incomes\", and '</span>\n<span class=\"c1\">#  'undertake \"long-term structural reform\" of the banking sector, education and '</span>\n<span class=\"c1\">#  'the welfare state.',</span>\n<span class=\"c1\">#  'The BBC understands that as chancellor, Mr Osborne, along with the Treasury '</span>\n<span class=\"c1\">#  'will retain responsibility for overseeing banks and financial regulation.']</span>\n\n\n<span class=\"c1\"># get summary with continuous LexRank</span>\n<span class=\"n\">summary_cont</span> <span class=\"o\">=</span> <span class=\"n\">lxr</span><span class=\"o\">.</span><span class=\"n\">get_summary</span><span class=\"p\">(</span><span class=\"n\">sentences</span><span class=\"p\">,</span> <span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">summary_cont</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># ['The BBC understands that as chancellor, Mr Osborne, along with the Treasury '</span>\n<span class=\"c1\">#  'will retain responsibility for overseeing banks and financial regulation.']</span>\n\n<span class=\"c1\"># get LexRank scores for sentences</span>\n<span class=\"c1\"># 'fast_power_method' speeds up the calculation, but requires more RAM</span>\n<span class=\"n\">scores_cont</span> <span class=\"o\">=</span> <span class=\"n\">lxr</span><span class=\"o\">.</span><span class=\"n\">rank_sentences</span><span class=\"p\">(</span>\n    <span class=\"n\">sentences</span><span class=\"p\">,</span>\n    <span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n    <span class=\"n\">fast_power_method</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">scores_cont</span><span class=\"p\">)</span>\n\n<span class=\"c1\">#  [1.0896493024505858,</span>\n<span class=\"c1\">#  0.9010711968859021,</span>\n<span class=\"c1\">#  1.1139166497016315,</span>\n<span class=\"c1\">#  0.8279523250808547,</span>\n<span class=\"c1\">#  0.8112028559566362,</span>\n<span class=\"c1\">#  1.185228912485382,</span>\n<span class=\"c1\">#  1.0709787574388283]</span>\n</pre>\n<p>Stop words for 22 languages are included into the package. To define your own mapping of stop words, prepare text files with utf-8 encoding where words are separated by newlines. Then use the command</p>\n<pre>lexrank_assemble_stopwords --source_dir directory_with_txt_files\n</pre>\n<p>that replaces the default mapping. Note that names of .txt files are used as keys in <cite>STOPWORDS</cite> dictionary.</p>\n</div>\n<div id=\"tests\">\n<h2>Tests</h2>\n<p>Tests are not supplied with the package, to run them you need to clone the repository and install additional dependencies.</p>\n<pre><span class=\"c1\"># ensure virtualenv is activated\n</span>make install-dev\n</pre>\n<p>Run linter and tests</p>\n<pre>make lint\nmake <span class=\"nb\">test</span>\n</pre>\n</div>\n<div id=\"references\">\n<h2>References</h2>\n<p>G\u00fcne\u015f Erkan and Dragomir R. Radev:\n<a href=\"http://www.jair.org/papers/paper1523.html\" rel=\"nofollow\">LexRank: Graph-based Lexical Centrality as Salience in Text Summarization</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 3831121, "releases": {"0.0.1a0": [{"comment_text": "", "digests": {"md5": "6a2bd416756da1a8078d9f0cc642ad45", "sha256": "b9b90b887c73c1aa7dc88a94aeec1e556b0920bf1298ad304e5952602a40be99"}, "downloads": -1, "filename": "lexrank-0.0.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "6a2bd416756da1a8078d9f0cc642ad45", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 68601, "upload_time": "2018-01-10T21:43:44", "upload_time_iso_8601": "2018-01-10T21:43:44.117318Z", "url": "https://files.pythonhosted.org/packages/3d/74/38f6b419ec3d3df803caff129ccb3551946aca87608841e2cf165dde2f1a/lexrank-0.0.1a0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "808307232d03713992d05b67fe0666eb", "sha256": "f9ff04048e3f4586fa94c106234a6c2507277fa47c759feff3a65fb1217abb4d"}, "downloads": -1, "filename": "lexrank-0.0.1a0.tar.gz", "has_sig": false, "md5_digest": "808307232d03713992d05b67fe0666eb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 66830, "upload_time": "2018-01-10T21:43:45", "upload_time_iso_8601": "2018-01-10T21:43:45.481319Z", "url": "https://files.pythonhosted.org/packages/8c/78/c97b4baa52d66987ccbda7282c0df295e09b1b0f799b3a65840b675c6d2a/lexrank-0.0.1a0.tar.gz", "yanked": false}], "0.0.1b0": [{"comment_text": "", "digests": {"md5": "1f78991d5551eb0b8c245d834c5a2a28", "sha256": "09924c6298424615ab4ce1bd5d4b817e41b38151ca39a05218cc332268f309b4"}, "downloads": -1, "filename": "lexrank-0.0.1b0.tar.gz", "has_sig": false, "md5_digest": "1f78991d5551eb0b8c245d834c5a2a28", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 69212, "upload_time": "2018-01-10T22:14:17", "upload_time_iso_8601": "2018-01-10T22:14:17.539332Z", "url": "https://files.pythonhosted.org/packages/40/83/5befa6e5fb2562457fea185d6388e711b56cd7a5fe47686aed5fa83d7acc/lexrank-0.0.1b0.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "3dacaf1f91ce91494e7df5f32f07ec61", "sha256": "d48b8414df52721088c7e1e3077a3c6c7de20263e560a881690bf62d4ee5b0e7"}, "downloads": -1, "filename": "lexrank-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3dacaf1f91ce91494e7df5f32f07ec61", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 69832, "upload_time": "2018-05-03T14:27:17", "upload_time_iso_8601": "2018-05-03T14:27:17.074091Z", "url": "https://files.pythonhosted.org/packages/e1/25/f139d8526e014b6bf6021305492cd7ccffbfa10999802fce4813808b04e4/lexrank-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "110b362e4065a065304a93a7027da234", "sha256": "1a43514596f298e6ff6267c696414222238a59bdea7b2ab63291e581e8ada8ed"}, "downloads": -1, "filename": "lexrank-0.1.0.tar.gz", "has_sig": false, "md5_digest": "110b362e4065a065304a93a7027da234", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 70783, "upload_time": "2018-05-03T14:27:18", "upload_time_iso_8601": "2018-05-03T14:27:18.941301Z", "url": "https://files.pythonhosted.org/packages/9e/1f/24d0ec4384902615e797ce984274573ed253a0ebbbed4b33c3c3b25e2df9/lexrank-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3dacaf1f91ce91494e7df5f32f07ec61", "sha256": "d48b8414df52721088c7e1e3077a3c6c7de20263e560a881690bf62d4ee5b0e7"}, "downloads": -1, "filename": "lexrank-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3dacaf1f91ce91494e7df5f32f07ec61", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5.0", "size": 69832, "upload_time": "2018-05-03T14:27:17", "upload_time_iso_8601": "2018-05-03T14:27:17.074091Z", "url": "https://files.pythonhosted.org/packages/e1/25/f139d8526e014b6bf6021305492cd7ccffbfa10999802fce4813808b04e4/lexrank-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "110b362e4065a065304a93a7027da234", "sha256": "1a43514596f298e6ff6267c696414222238a59bdea7b2ab63291e581e8ada8ed"}, "downloads": -1, "filename": "lexrank-0.1.0.tar.gz", "has_sig": false, "md5_digest": "110b362e4065a065304a93a7027da234", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5.0", "size": 70783, "upload_time": "2018-05-03T14:27:18", "upload_time_iso_8601": "2018-05-03T14:27:18.941301Z", "url": "https://files.pythonhosted.org/packages/9e/1f/24d0ec4384902615e797ce984274573ed253a0ebbbed4b33c3c3b25e2df9/lexrank-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:49 2020"}