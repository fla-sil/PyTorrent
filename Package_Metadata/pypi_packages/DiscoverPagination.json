{"info": {"author": "", "author_email": "dhking@wharton.upenn.edu", "bugtrack_url": null, "classifiers": [], "description": "[![Build Status](https://travis-ci.org/wharton/DiscoverPagination.svg?branch=master)](https://travis-ci.org/wharton/S3WebCache)\n[![PyPI version](https://badge.fury.io/py/DiscoverPagination.svg)](https://badge.fury.io/py/DiscoverPagination)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n# DiscoverPagination\n\nA python package for discovering numbered page delineation in documents.\n\n## Repository\n\n[https://github.com/wharton/DiscoverPagination](https://github.com/wharton/DiscoverPagination)\n\n## Background\nIn the Research and Analytics Department we are asked for several different types of text processing assignments.\nThese usually take the form of \"please extract the X section from Y document type 10k times\" Some of these\nhave a Table of Contents, but it is difficult to use the ToC because we do not know which pages are which.\n\nThis package is designed to discover where pages are marked, and then reference those page numbers to get \nsections of text. Much of the work we do involves SEC filings, which are in a type of XML format. This is \noptimized for that type of document, but should do well in other cases.\n\n\n## Requirements\n - Python 3.6\n - fuzzywuzzy: Fuzzy matching\n - python-Levenshtein: Speeds up fuzzy matching library\n\n\n## Quickstart\n\n### Install\n\n    $ pip install DiscoverPagination\n\n### Usage\n    $ python\n    >> from discoverpagination import *\n    >> with open('./example_texts/0001193125-08-010038.txt') as inputfile:\n    ...       doc = PaginatedDocument(inputfile, clean_xml=True)\n    >> pages = doc[20:22]\n    >> print(pages)\n    [' <P><FONT>19 </FONT></P>\\n', '\\n', '\\n', '<p>\\n', '<HR>\\n', '\\n', ' <P><FONT>The ...\n\n\n## Methods\nThe way the pages are discovered takes several steps and relies on a few assumptions.\n\n### Assumptions\n 1. Pages are marked\n 2. Page markings are in sequential order\n 3. Page markings use numeric characters\n 4. Pages are numbered at the end of page\n 5. Page numbers do not occur mixed with text. (There is an attempt to handle this case.)\n\n### Steps\n 1. Document is read from file\n 2. (OPTIONAL) XML documents are cleaned of tag attributes.\n 3. Document is scanned for page markers line by line, starting with \"1\". (Configurable) \n 4. As each number is found, the line index and text is stored in a Dict keyed to page number.\n 5. The page is incremented after each number is found until no more document lines remain.\n 6. The document is rescanned in reverse order to find page markers.\n 7. Page markers that are the same or nearby to each other are kept.\n 8. A common \"best_match\" format is determined by ranking each type of line.\n 9. The missing page numbers are scanned for with this \"best_match\" in the areas they should be. E.g. A\n    missing page 5 is searched for between pages 4 and 6 with the best pattern.\n 10. If there are still missing pages it uses fuzzy matching to guess based on placement and pattern.\n 11. The document is returned and can be referenced by slicing. doc[10:12] gets lines for pages 10 to 12.\n\n\n## Tests\n\n    python setup.py test\n\n\n## Reference\n\n[fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy)\\\n[python-Levenshtein](https://github.com/ztane/python-Levenshtein/)\\\n[SEC EDGAR](https://www.sec.gov/edgar/aboutedgar.htm)\n\n\n## Contributors\n\n[Douglas H. King](https://github.com/douglascodes)\n\n\n## License\n\n[MIT](./LICENSE.TXT)\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "DiscoverPagination", "package_url": "https://pypi.org/project/DiscoverPagination/", "platform": "", "project_url": "https://pypi.org/project/DiscoverPagination/", "project_urls": null, "release_url": "https://pypi.org/project/DiscoverPagination/0.1.4/", "requires_dist": ["fuzzywuzzy", "python-Levenshtein"], "requires_python": "", "summary": "", "version": "0.1.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.org/wharton/S3WebCache\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/55f30475624e893027ca03e5b406c6308a764ad0/68747470733a2f2f7472617669732d63692e6f72672f77686172746f6e2f446973636f766572506167696e6174696f6e2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://badge.fury.io/py/DiscoverPagination\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aa0eaec07bf479e1302f19462674c356d8de1cc9/68747470733a2f2f62616467652e667572792e696f2f70792f446973636f766572506167696e6174696f6e2e737667\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a></p>\n<h1>DiscoverPagination</h1>\n<p>A python package for discovering numbered page delineation in documents.</p>\n<h2>Repository</h2>\n<p><a href=\"https://github.com/wharton/DiscoverPagination\" rel=\"nofollow\">https://github.com/wharton/DiscoverPagination</a></p>\n<h2>Background</h2>\n<p>In the Research and Analytics Department we are asked for several different types of text processing assignments.\nThese usually take the form of \"please extract the X section from Y document type 10k times\" Some of these\nhave a Table of Contents, but it is difficult to use the ToC because we do not know which pages are which.</p>\n<p>This package is designed to discover where pages are marked, and then reference those page numbers to get\nsections of text. Much of the work we do involves SEC filings, which are in a type of XML format. This is\noptimized for that type of document, but should do well in other cases.</p>\n<h2>Requirements</h2>\n<ul>\n<li>Python 3.6</li>\n<li>fuzzywuzzy: Fuzzy matching</li>\n<li>python-Levenshtein: Speeds up fuzzy matching library</li>\n</ul>\n<h2>Quickstart</h2>\n<h3>Install</h3>\n<pre><code>$ pip install DiscoverPagination\n</code></pre>\n<h3>Usage</h3>\n<pre><code>$ python\n&gt;&gt; from discoverpagination import *\n&gt;&gt; with open('./example_texts/0001193125-08-010038.txt') as inputfile:\n...       doc = PaginatedDocument(inputfile, clean_xml=True)\n&gt;&gt; pages = doc[20:22]\n&gt;&gt; print(pages)\n[' &lt;P&gt;&lt;FONT&gt;19 &lt;/FONT&gt;&lt;/P&gt;\\n', '\\n', '\\n', '&lt;p&gt;\\n', '&lt;HR&gt;\\n', '\\n', ' &lt;P&gt;&lt;FONT&gt;The ...\n</code></pre>\n<h2>Methods</h2>\n<p>The way the pages are discovered takes several steps and relies on a few assumptions.</p>\n<h3>Assumptions</h3>\n<ol>\n<li>Pages are marked</li>\n<li>Page markings are in sequential order</li>\n<li>Page markings use numeric characters</li>\n<li>Pages are numbered at the end of page</li>\n<li>Page numbers do not occur mixed with text. (There is an attempt to handle this case.)</li>\n</ol>\n<h3>Steps</h3>\n<ol>\n<li>Document is read from file</li>\n<li>(OPTIONAL) XML documents are cleaned of tag attributes.</li>\n<li>Document is scanned for page markers line by line, starting with \"1\". (Configurable)</li>\n<li>As each number is found, the line index and text is stored in a Dict keyed to page number.</li>\n<li>The page is incremented after each number is found until no more document lines remain.</li>\n<li>The document is rescanned in reverse order to find page markers.</li>\n<li>Page markers that are the same or nearby to each other are kept.</li>\n<li>A common \"best_match\" format is determined by ranking each type of line.</li>\n<li>The missing page numbers are scanned for with this \"best_match\" in the areas they should be. E.g. A\nmissing page 5 is searched for between pages 4 and 6 with the best pattern.</li>\n<li>If there are still missing pages it uses fuzzy matching to guess based on placement and pattern.</li>\n<li>The document is returned and can be referenced by slicing. doc[10:12] gets lines for pages 10 to 12.</li>\n</ol>\n<h2>Tests</h2>\n<pre><code>python setup.py test\n</code></pre>\n<h2>Reference</h2>\n<p><a href=\"https://github.com/seatgeek/fuzzywuzzy\" rel=\"nofollow\">fuzzywuzzy</a><br>\n<a href=\"https://github.com/ztane/python-Levenshtein/\" rel=\"nofollow\">python-Levenshtein</a><br>\n<a href=\"https://www.sec.gov/edgar/aboutedgar.htm\" rel=\"nofollow\">SEC EDGAR</a></p>\n<h2>Contributors</h2>\n<p><a href=\"https://github.com/douglascodes\" rel=\"nofollow\">Douglas H. King</a></p>\n<h2>License</h2>\n<p><a href=\"./LICENSE.TXT\" rel=\"nofollow\">MIT</a></p>\n\n          </div>"}, "last_serial": 5574506, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "86380f6cec5fbdfad115141b4ea4e784", "sha256": "752d451b5f6786159aa3fbe556a3478753e8e66399d3e7e09fcfc190ba08ea1c"}, "downloads": -1, "filename": "DiscoverPagination-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "86380f6cec5fbdfad115141b4ea4e784", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11313, "upload_time": "2019-07-19T18:36:13", "upload_time_iso_8601": "2019-07-19T18:36:13.582174Z", "url": "https://files.pythonhosted.org/packages/19/98/217518f7c8c6afa49ed6bad96305bbd6f8404893ffe05d08b2fe549b3356/DiscoverPagination-0.1.1-py3-none-any.whl", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "88363b96272ea69cb2fb96be3b65850d", "sha256": "f3d9fe2efdc5f195629aea11f27e19ba9dba46165403e26436c31ee809a2c9de"}, "downloads": -1, "filename": "DiscoverPagination-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "88363b96272ea69cb2fb96be3b65850d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13053, "upload_time": "2019-07-23T21:10:41", "upload_time_iso_8601": "2019-07-23T21:10:41.374596Z", "url": "https://files.pythonhosted.org/packages/e5/4a/8c324ce81e37153102c46f3b1702e798b00a23a65be96351eded624e21a5/DiscoverPagination-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "67c9da3439e7355f3102cc6c92ddabe4", "sha256": "3228467e9d68ffb7a3b273362e1c2527bf6ce0d64cb5a805eefe19adb228a5e8"}, "downloads": -1, "filename": "DiscoverPagination-0.1.4.tar.gz", "has_sig": false, "md5_digest": "67c9da3439e7355f3102cc6c92ddabe4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11823, "upload_time": "2019-07-23T21:10:42", "upload_time_iso_8601": "2019-07-23T21:10:42.701867Z", "url": "https://files.pythonhosted.org/packages/53/f1/aacb5f7623a8fba1a5d74000fed2f55f990d93ed609bbe57141219d6f86d/DiscoverPagination-0.1.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "88363b96272ea69cb2fb96be3b65850d", "sha256": "f3d9fe2efdc5f195629aea11f27e19ba9dba46165403e26436c31ee809a2c9de"}, "downloads": -1, "filename": "DiscoverPagination-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "88363b96272ea69cb2fb96be3b65850d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13053, "upload_time": "2019-07-23T21:10:41", "upload_time_iso_8601": "2019-07-23T21:10:41.374596Z", "url": "https://files.pythonhosted.org/packages/e5/4a/8c324ce81e37153102c46f3b1702e798b00a23a65be96351eded624e21a5/DiscoverPagination-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "67c9da3439e7355f3102cc6c92ddabe4", "sha256": "3228467e9d68ffb7a3b273362e1c2527bf6ce0d64cb5a805eefe19adb228a5e8"}, "downloads": -1, "filename": "DiscoverPagination-0.1.4.tar.gz", "has_sig": false, "md5_digest": "67c9da3439e7355f3102cc6c92ddabe4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11823, "upload_time": "2019-07-23T21:10:42", "upload_time_iso_8601": "2019-07-23T21:10:42.701867Z", "url": "https://files.pythonhosted.org/packages/53/f1/aacb5f7623a8fba1a5d74000fed2f55f990d93ed609bbe57141219d6f86d/DiscoverPagination-0.1.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:38:11 2020"}