{"info": {"author": "Scrapedia", "author_email": "Scrapedia@outlook.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Environment :: Plugins", "Framework :: Scrapy", "Intended Audience :: Developers", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Internet :: WWW/HTTP", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "================\nScrapy-Pipelines\n================\n\nOverview\n========\n\n.. image:: https://bestpractices.coreinfrastructure.org/projects/2828/badge\n   :alt: CII Best Practices\n   :target: https://bestpractices.coreinfrastructure.org/projects/2828\n\n.. image:: https://mperlet.github.io/pybadge/badges/9.43.svg\n   :alt: pylint Score\n\n.. image:: https://img.shields.io/travis/scrapedia/scrapy-pipelines/master.svg\n   :target: http://travis-ci.org/scrapedia/scrapy-pipelines\n   :alt: Travis branch\n\n.. image:: https://codecov.io/gh/scrapedia/scrapy-pipelines/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/scrapedia/scrapy-pipelines\n   :alt: Coverage Report\n\n.. image:: https://codebeat.co/badges/fabc61ba-6a20-4bd1-bf73-a2f091a9ad80\n   :target: https://codebeat.co/projects/github-com-scrapedia-scrapy-pipelines-master\n   :alt: codebeat badge\n\n.. image:: https://api.codacy.com/project/badge/Grade/aeda92e058434a9eb2e8b0512a02235f\n   :target: https://www.codacy.com/app/grammy-jiang/scrapy-pipelines?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=scrapedia/scrapy-pipelines&amp;utm_campaign=Badge_Grade\n\n.. image:: https://pyup.io/repos/github/scrapedia/scrapy-pipelines/shield.svg\n     :target: https://pyup.io/repos/github/scrapedia/scrapy-pipelines/\n     :alt: Updates\n\n.. image:: https://snyk.io/test/github/scrapedia/scrapy-pipelines/badge.svg\n    :target: https://snyk.io/test/github/scrapedia/scrapy-pipelines\n    :alt: Known Vulnerabilities\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/python/black\n    :alt: Code style: black\n\n.. image:: https://img.shields.io/badge/License-GPLv3-blue.svg\n    :target: https://www.gnu.org/licenses/gpl-3.0\n    :alt: License: AGPL v3\n\nThese pipelines enable Scrapy to save items into various backends, including:\n\n* MongoDB\n\nAnd also these pipelines provide multiple ways to save or update the items, and\nreturn id created by backends\n\nRequirements\n=============\n\n.. image:: https://pyup.io/repos/github/scrapedia/r18/python-3-shield.svg\n   :target: https://pyup.io/repos/github/scrapedia/r18/\n   :alt: Python 3\n\n* Python 3.6+\n* Works on Linux, Windows, Mac OSX\n\nInstallation\n============\n\n.. image:: https://img.shields.io/pypi/v/scrapy-pipelines.svg\n   :target: https://pypi.python.org/pypi/scrapy-pipelines\n   :alt: PyPI\n.. image:: https://img.shields.io/pypi/pyversions/scrapy-pipelines.svg\n   :target: https://pypi.python.org/pypi/scrapy-pipelines\n   :alt: PyPI - Python Version\n.. image:: https://img.shields.io/pypi/wheel/scrapy-pipelines.svg\n   :target: https://pypi.python.org/pypi/scrapy-pipelines\n   :alt: PyPI - Wheel\n\nThe quick way:\n\n   pip install scrapy-pipelines\n\nFor more details see the installation section in the documentation:\nhttps://scrapy-pipelines.readthedocs.io/en/latest/intro/installation.html\n\nDocumentation\n=============\n\nDocumentation is available online at\nhttps://scrapy-pipelines.readthedocs.io/en/latest/ and in the docs directory.\n\nCommunity (blog, twitter, mail list, IRC)\n=========================================\n\n*Keeping this section same as Scrapy is intending to benefit back to Scrapy.*\n\nSee https://scrapy.org/community/\n\nContributing\n============\n\n*Keeping this section same as Scrapy is intending to be easier when this repo\nmerge back to Scrapy.*\n\nSee https://doc.scrapy.org/en/master/contributing.html\n\nCode of Conduct\n---------------\n\nPlease note that this project is released with a Contributor Code of Conduct\n(see https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md).\n\nBy participating in this project you agree to abide by its terms.\nPlease report unacceptable behavior to opensource@scrapinghub.com.\n\n\nCompanies using Scrapy\n======================\n\n*Keeping this section same as Scrapy is intending to benefit back to Scrapy.*\n\nSee https://scrapy.org/companies/\n\nCommercial Support\n==================\n\n*Keeping this section same as Scrapy is intending to benefit back to Scrapy.*\n\nSee https://scrapy.org/support/\n\nTODO\n====\n\n* [X] Add indexes creation in open_spider()\n* [X] Add item_completed method\n* [X] Add signals for MongoDB document's id return\n* [ ] Add MongoDB document update\n* [ ] Add Percona Server for MongoDB docker support\n* [ ] Add Redis support\n* [ ] Add InfluxDB support\n* [ ] Add LevelDB support\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/scrapedia/scrapy-pipelines", "keywords": "", "license": "GPLv3", "maintainer": "Scrapedia", "maintainer_email": "Scrapedia@outlook.com", "name": "Scrapy-Pipelines", "package_url": "https://pypi.org/project/Scrapy-Pipelines/", "platform": "", "project_url": "https://pypi.org/project/Scrapy-Pipelines/", "project_urls": {"Homepage": "https://github.com/scrapedia/scrapy-pipelines"}, "release_url": "https://pypi.org/project/Scrapy-Pipelines/0.2/", "requires_dist": ["scrapy", "txmongo"], "requires_python": "", "summary": "A collection of scrapy item pipelines", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"overview\">\n<h2>Overview</h2>\n<a href=\"https://bestpractices.coreinfrastructure.org/projects/2828\" rel=\"nofollow\"><img alt=\"CII Best Practices\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4b33d54271303c32bef269ee3d4ab2b80101ae13/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f323832382f6261646765\"></a>\n<img alt=\"pylint Score\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/55fb69dd313320e8b03ff7d73754b6363d4d75b9/68747470733a2f2f6d7065726c65742e6769746875622e696f2f707962616467652f6261646765732f392e34332e737667\">\n<a href=\"http://travis-ci.org/scrapedia/scrapy-pipelines\" rel=\"nofollow\"><img alt=\"Travis branch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a17d2cee29184841cf60d1025c0b09bed3f650bd/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f7363726170656469612f7363726170792d706970656c696e65732f6d61737465722e737667\"></a>\n<a href=\"https://codecov.io/gh/scrapedia/scrapy-pipelines\" rel=\"nofollow\"><img alt=\"Coverage Report\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/67b432659967b45d1469415ba3b56695374fe55e/68747470733a2f2f636f6465636f762e696f2f67682f7363726170656469612f7363726170792d706970656c696e65732f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<a href=\"https://codebeat.co/projects/github-com-scrapedia-scrapy-pipelines-master\" rel=\"nofollow\"><img alt=\"codebeat badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5b45ee0f60320b13a9ea9efa6a6c9e0bea59d739/68747470733a2f2f636f6465626561742e636f2f6261646765732f66616263363162612d366132302d346264312d626637332d613266303931613961643830\"></a>\n<a href=\"https://www.codacy.com/app/grammy-jiang/scrapy-pipelines?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=scrapedia/scrapy-pipelines&amp;amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"https://api.codacy.com/project/badge/Grade/aeda92e058434a9eb2e8b0512a02235f\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2cd60ef27130ba66755f6a8458a1b3dc513b99b0/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6165646139326530353834333461396562326538623035313261303232333566\"></a>\n<a href=\"https://pyup.io/repos/github/scrapedia/scrapy-pipelines/\" rel=\"nofollow\"><img alt=\"Updates\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ce825f0d4f02f7f0c52c2eabc59aeb07e0bfcac4/68747470733a2f2f707975702e696f2f7265706f732f6769746875622f7363726170656469612f7363726170792d706970656c696e65732f736869656c642e737667\"></a>\n<a href=\"https://snyk.io/test/github/scrapedia/scrapy-pipelines\" rel=\"nofollow\"><img alt=\"Known Vulnerabilities\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/706d0096fa5300ed53c4b33c037a3d9a03ca77c1/68747470733a2f2f736e796b2e696f2f746573742f6769746875622f7363726170656469612f7363726170792d706970656c696e65732f62616467652e737667\"></a>\n<a href=\"https://github.com/python/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0\" rel=\"nofollow\"><img alt=\"License: AGPL v3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8de17537dd1659a5a076ce547de301e27c839e67/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e737667\"></a>\n<p>These pipelines enable Scrapy to save items into various backends, including:</p>\n<ul>\n<li>MongoDB</li>\n</ul>\n<p>And also these pipelines provide multiple ways to save or update the items, and\nreturn id created by backends</p>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<a href=\"https://pyup.io/repos/github/scrapedia/r18/\" rel=\"nofollow\"><img alt=\"Python 3\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e2fc57d609b9460824c66c665ea385587f93e478/68747470733a2f2f707975702e696f2f7265706f732f6769746875622f7363726170656469612f7231382f707974686f6e2d332d736869656c642e737667\"></a>\n<ul>\n<li>Python 3.6+</li>\n<li>Works on Linux, Windows, Mac OSX</li>\n</ul>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<a href=\"https://pypi.python.org/pypi/scrapy-pipelines\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d43ddaecd6da08450e0a7b3aebc2b54ac321a278/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7363726170792d706970656c696e65732e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/scrapy-pipelines\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bd21d22e4abf9cf8c72a65644c663dc024a1dfbe/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f7363726170792d706970656c696e65732e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/scrapy-pipelines\" rel=\"nofollow\"><img alt=\"PyPI - Wheel\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5eb87aecd341b409298b1fa8398494963f6436aa/68747470733a2f2f696d672e736869656c64732e696f2f707970692f776865656c2f7363726170792d706970656c696e65732e737667\"></a>\n<p>The quick way:</p>\n<blockquote>\npip install scrapy-pipelines</blockquote>\n<p>For more details see the installation section in the documentation:\n<a href=\"https://scrapy-pipelines.readthedocs.io/en/latest/intro/installation.html\" rel=\"nofollow\">https://scrapy-pipelines.readthedocs.io/en/latest/intro/installation.html</a></p>\n</div>\n<div id=\"documentation\">\n<h2>Documentation</h2>\n<p>Documentation is available online at\n<a href=\"https://scrapy-pipelines.readthedocs.io/en/latest/\" rel=\"nofollow\">https://scrapy-pipelines.readthedocs.io/en/latest/</a> and in the docs directory.</p>\n</div>\n<div id=\"community-blog-twitter-mail-list-irc\">\n<h2>Community (blog, twitter, mail list, IRC)</h2>\n<p><em>Keeping this section same as Scrapy is intending to benefit back to Scrapy.</em></p>\n<p>See <a href=\"https://scrapy.org/community/\" rel=\"nofollow\">https://scrapy.org/community/</a></p>\n</div>\n<div id=\"contributing\">\n<h2>Contributing</h2>\n<p><em>Keeping this section same as Scrapy is intending to be easier when this repo\nmerge back to Scrapy.</em></p>\n<p>See <a href=\"https://doc.scrapy.org/en/master/contributing.html\" rel=\"nofollow\">https://doc.scrapy.org/en/master/contributing.html</a></p>\n<div id=\"code-of-conduct\">\n<h3>Code of Conduct</h3>\n<p>Please note that this project is released with a Contributor Code of Conduct\n(see <a href=\"https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md\" rel=\"nofollow\">https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md</a>).</p>\n<p>By participating in this project you agree to abide by its terms.\nPlease report unacceptable behavior to <a href=\"mailto:opensource%40scrapinghub.com\">opensource<span>@</span>scrapinghub<span>.</span>com</a>.</p>\n</div>\n</div>\n<div id=\"companies-using-scrapy\">\n<h2>Companies using Scrapy</h2>\n<p><em>Keeping this section same as Scrapy is intending to benefit back to Scrapy.</em></p>\n<p>See <a href=\"https://scrapy.org/companies/\" rel=\"nofollow\">https://scrapy.org/companies/</a></p>\n</div>\n<div id=\"commercial-support\">\n<h2>Commercial Support</h2>\n<p><em>Keeping this section same as Scrapy is intending to benefit back to Scrapy.</em></p>\n<p>See <a href=\"https://scrapy.org/support/\" rel=\"nofollow\">https://scrapy.org/support/</a></p>\n</div>\n<div id=\"todo\">\n<h2>TODO</h2>\n<ul>\n<li>[X] Add indexes creation in open_spider()</li>\n<li>[X] Add item_completed method</li>\n<li>[X] Add signals for MongoDB document\u2019s id return</li>\n<li>[ ] Add MongoDB document update</li>\n<li>[ ] Add Percona Server for MongoDB docker support</li>\n<li>[ ] Add Redis support</li>\n<li>[ ] Add InfluxDB support</li>\n<li>[ ] Add LevelDB support</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 5389392, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "0d7d6da52ddbbe70b929805596516d91", "sha256": "da53a9a8e1a14f237df2b1e8dedca966d192ba159a978c426a300c30d3c1795f"}, "downloads": -1, "filename": "Scrapy_Pipelines-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0d7d6da52ddbbe70b929805596516d91", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 14979, "upload_time": "2019-05-22T13:50:07", "upload_time_iso_8601": "2019-05-22T13:50:07.809836Z", "url": "https://files.pythonhosted.org/packages/56/2d/38ec783e50b9dce565e92a3b8dd67b635f3255db0d534e96c63618a1e851/Scrapy_Pipelines-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f3476b1423ab35b997071beb644b4f38", "sha256": "04d2e630b9a2bdb1276010561cbcb572be22980c97b6cd0a641d7f7c96051c7f"}, "downloads": -1, "filename": "Scrapy-Pipelines-0.1.tar.gz", "has_sig": false, "md5_digest": "f3476b1423ab35b997071beb644b4f38", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19218, "upload_time": "2019-05-22T13:50:10", "upload_time_iso_8601": "2019-05-22T13:50:10.318095Z", "url": "https://files.pythonhosted.org/packages/73/cb/3a778b82e190fa43f28b3786ec88837256af972ff5d1800c1448d9d4edda/Scrapy-Pipelines-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "c67e197b3eba77f03d0ebfa581134572", "sha256": "e5f336e5b69b79e6653dcc5d49a34184580107c7a84941f973ff5e69b64710fa"}, "downloads": -1, "filename": "Scrapy_Pipelines-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "c67e197b3eba77f03d0ebfa581134572", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25017, "upload_time": "2019-06-12T04:24:13", "upload_time_iso_8601": "2019-06-12T04:24:13.601351Z", "url": "https://files.pythonhosted.org/packages/74/10/4fa4c50099386727714960d96822d51908d30ab2ce582da134032586ab01/Scrapy_Pipelines-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "709d033b87674d040029ae36952a0d69", "sha256": "6812b3438a6c1cdfbb024f3448101637fc40db03731a16b5533f93a09617b392"}, "downloads": -1, "filename": "Scrapy-Pipelines-0.2.tar.gz", "has_sig": false, "md5_digest": "709d033b87674d040029ae36952a0d69", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22128, "upload_time": "2019-06-12T04:24:15", "upload_time_iso_8601": "2019-06-12T04:24:15.323623Z", "url": "https://files.pythonhosted.org/packages/13/d6/6ca908c0584ad4f61546d407efaad855094f7003d4a67a6a1b40692f1c29/Scrapy-Pipelines-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c67e197b3eba77f03d0ebfa581134572", "sha256": "e5f336e5b69b79e6653dcc5d49a34184580107c7a84941f973ff5e69b64710fa"}, "downloads": -1, "filename": "Scrapy_Pipelines-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "c67e197b3eba77f03d0ebfa581134572", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 25017, "upload_time": "2019-06-12T04:24:13", "upload_time_iso_8601": "2019-06-12T04:24:13.601351Z", "url": "https://files.pythonhosted.org/packages/74/10/4fa4c50099386727714960d96822d51908d30ab2ce582da134032586ab01/Scrapy_Pipelines-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "709d033b87674d040029ae36952a0d69", "sha256": "6812b3438a6c1cdfbb024f3448101637fc40db03731a16b5533f93a09617b392"}, "downloads": -1, "filename": "Scrapy-Pipelines-0.2.tar.gz", "has_sig": false, "md5_digest": "709d033b87674d040029ae36952a0d69", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22128, "upload_time": "2019-06-12T04:24:15", "upload_time_iso_8601": "2019-06-12T04:24:15.323623Z", "url": "https://files.pythonhosted.org/packages/13/d6/6ca908c0584ad4f61546d407efaad855094f7003d4a67a6a1b40692f1c29/Scrapy-Pipelines-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:44 2020"}