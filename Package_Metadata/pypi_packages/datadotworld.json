{"info": {"author": "data.world", "author_email": "help@data.world", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Database :: Database Engines/Servers", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "=============\ndata.world-py\n=============\n\nA python library for working with data.world datasets.\n\nThis library makes it easy for data.world users to pull and work with data stored on data.world.\nAdditionally, the library provides convenient wrappers for data.world APIs, allowing users to create and update\ndatasets, add and modify files, etc, and possibly implement entire apps on top of data.world.\n\n\nQuick start\n===========\n\nInstall\n-------\n\nYou can install it using ``pip`` directly from PyPI::\n\n    pip install datadotworld\n\nOptionally, you can install the library including pandas support::\n\n    pip install datadotworld[pandas]\n\nIf you use ``conda`` to manage your python distribution, you can install from the community-maintained [conda-forge](https://conda-forge.github.io/) channel::\n\n    conda install -c conda-forge datadotworld-py\n\n\nConfigure\n---------\n\nThis library requires a data.world API authentication token to work.\n\nYour authentication token can be obtained on data.world once you enable Python under\n`Integrations > Python <https://data.world/integrations/python>`_\n\nTo configure the library, run the following command::\n\n    dw configure\n\n\nAlternatively, tokens can be provided via the ``DW_AUTH_TOKEN`` environment variable.\nOn MacOS or Unix machines, run (replacing ``<YOUR_TOKEN>>`` below with the token obtained earlier)::\n\n    export DW_AUTH_TOKEN=<YOUR_TOKEN>\n\nLoad a dataset\n--------------\n\nThe ``load_dataset()`` function facilitates maintaining copies of datasets on the local filesystem.\nIt will download a given dataset's `datapackage <http://specs.frictionlessdata.io/data-package/>`_\nand store it under ``~/.dw/cache``. When used subsequently, ``load_dataset()`` will use the copy stored on disk and will\nwork offline, unless it's called with ``force_update=True`` or ``auto_update=True``. ``force_update=True`` will overwrite your local copy unconditionally. ``auto_update=True`` will only overwrite your local copy if a newer version of the dataset is available on data.world.\n\nOnce loaded, a dataset (data and metadata) can be conveniently accessed via the object returned by ``load_dataset()``.\n\nStart by importing the ``datadotworld`` module:\n\n.. code-block:: python\n\n    import datadotworld as dw\n\nThen, invoke the ``load_dataset()`` function, to download a dataset and work with it locally.\nFor example:\n\n.. code-block:: python\n\n    intro_dataset = dw.load_dataset('jonloyens/an-intro-to-dataworld-dataset')\n\nDataset objects allow access to data via three different properties ``raw_data``, ``tables`` and ``dataframes``.\nEach of these properties is a mapping (dict) whose values are of type ``bytes``, ``list`` and ``pandas.DataFrame``,\nrespectively. Values are lazy loaded and cached once loaded. Their keys are the names of the files\ncontained in the dataset.\n\nFor example:\n\n.. code-block:: python\n\n    >>> intro_dataset.dataframes\n    LazyLoadedDict({\n        'changelog': LazyLoadedValue(<pandas.DataFrame>),\n        'datadotworldbballstats': LazyLoadedValue(<pandas.DataFrame>),\n        'datadotworldbballteam': LazyLoadedValue(<pandas.DataFrame>)})\n\n**IMPORTANT**: Not all files in a dataset are tabular, therefore some will be exposed via ``raw_data`` only.\n\nTables are lists of rows, each represented by a mapping (dict) of column names to their respective values.\n\nFor example:\n\n.. code-block:: python\n\n    >>> stats_table = intro_dataset.tables['datadotworldbballstats']\n    >>> stats_table[0]\n    OrderedDict([('Name', 'Jon'),\n                 ('PointsPerGame', Decimal('20.4')),\n                 ('AssistsPerGame', Decimal('1.3'))])\n\nYou can also review the metadata associated with a file or the entire dataset, using the ``describe`` function.\nFor example:\n\n.. code-block:: python\n\n    >>> intro_dataset.describe()\n    {'homepage': 'https://data.world/jonloyens/an-intro-to-dataworld-dataset',\n     'name': 'jonloyens_an-intro-to-dataworld-dataset',\n     'resources': [{'format': 'csv',\n       'name': 'changelog',\n       'path': 'data/ChangeLog.csv'},\n      {'format': 'csv',\n       'name': 'datadotworldbballstats',\n       'path': 'data/DataDotWorldBBallStats.csv'},\n      {'format': 'csv',\n       'name': 'datadotworldbballteam',\n       'path': 'data/DataDotWorldBBallTeam.csv'}]}\n    >>> intro_dataset.describe('datadotworldbballstats')\n    {'format': 'csv',\n     'name': 'datadotworldbballstats',\n     'path': 'data/DataDotWorldBBallStats.csv',\n     'schema': {'fields': [{'name': 'Name', 'title': 'Name', 'type': 'string'},\n                           {'name': 'PointsPerGame',\n                            'title': 'PointsPerGame',\n                            'type': 'number'},\n                           {'name': 'AssistsPerGame',\n                            'title': 'AssistsPerGame',\n                            'type': 'number'}]}}\n\nQuery a dataset\n---------------\n\nThe ``query()`` function allows datasets to be queried live using ``SQL`` or ``SPARQL`` query languages.\n\nTo query a dataset, invoke the ``query()`` function.\nFor example:\n\n.. code-block:: python\n\n    results = dw.query('jonloyens/an-intro-to-dataworld-dataset', 'SELECT * FROM DataDotWorldBBallStats')\n\nQuery result objects allow access to the data via ``raw_data``, ``table`` and ``dataframe`` properties, of type\n``json``, ``list`` and ``pandas.DataFrame``, respectively.\n\nFor example:\n\n.. code-block:: python\n\n    >>> results.dataframe\n          Name  PointsPerGame  AssistsPerGame\n    0      Jon           20.4             1.3\n    1      Rob           15.5             8.0\n    2   Sharon           30.1            11.2\n    3     Alex            8.2             0.5\n    4  Rebecca           12.3            17.0\n    5   Ariane           18.1             3.0\n    6    Bryon           16.0             8.5\n    7     Matt           13.0             2.1\n\n\nTables are lists of rows, each represented by a mapping (dict) of column names to their respective values.\nFor example:\n\n.. code-block:: python\n\n    >>> results.table[0]\n    OrderedDict([('Name', 'Jon'),\n                 ('PointsPerGame', Decimal('20.4')),\n                 ('AssistsPerGame', Decimal('1.3'))])\n\nTo query using ``SPARQL`` invoke ``query()`` using ``query_type='sparql'``, or else, it will assume\nthe query to be a ``SQL`` query.\n\nJust like in the dataset case, you can view the metadata associated with a query result using the ``describe()``\nfunction.\n\nFor example:\n\n.. code-block:: python\n\n    >>> results.describe()\n    {'fields': [{'name': 'Name', 'type': 'string'},\n                {'name': 'PointsPerGame', 'type': 'number'},\n                {'name': 'AssistsPerGame', 'type': 'number'}]}\n\nWork with files\n---------------\n\nThe ``open_remote_file()`` function allows you to write data to or read data from a file in a\ndata.world dataset.\n\nWriting files\n.............\n\nThe object that is returned from the ``open_remote_file()`` call is similar to a file handle that\nwould be used to write to a local file - it has a ``write()`` method, and contents sent to that\nmethod will be written to the file remotely.\n\n.. code-block:: python\n\n        >>> import datadotworld as dw\n        >>>\n        >>> with dw.open_remote_file('username/test-dataset', 'test.txt') as w:\n        ...   w.write(\"this is a test.\")\n        >>>\n\nOf course, writing a text file isn't the primary use case for data.world - you want to write your\ndata!  The return object from ``open_remote_file()`` should be usable anywhere you could normally\nuse a local file handle in write mode - so you can use it to serialize the contents of a PANDAS\n``DataFrame`` to a CSV file...\n\n.. code-block:: python\n\n        >>> import pandas as pd\n        >>> df = pd.DataFrame({'foo':[1,2,3,4],'bar':['a','b','c','d']})\n        >>> with dw.open_remote_file('username/test-dataset', 'dataframe.csv') as w:\n        ...   df.to_csv(w, index=False)\n\nOr, to write a series of ``dict`` objects as a JSON Lines file...\n\n.. code-block:: python\n\n        >>> import json\n        >>> with dw.open_remote_file('username/test-dataset', 'test.jsonl') as w:\n        ...   json.dump({'foo':42, 'bar':\"A\"}, w)\n        ...   json.dump({'foo':13, 'bar':\"B\"}, w)\n        >>>\n\nOr to write a series of ``dict`` objects as a CSV...\n\n.. code-block:: python\n\n        >>> import csv\n        >>> with dw.open_remote_file('username/test-dataset', 'test.csv') as w:\n        ...   csvw = csv.DictWriter(w, fieldnames=['foo', 'bar'])\n        ...   csvw.writeheader()\n        ...   csvw.writerow({'foo':42, 'bar':\"A\"})\n        ...   csvw.writerow({'foo':13, 'bar':\"B\"})\n        >>>\n\nAnd finally, you can write binary data by streaming ``bytes`` or ``bytearray`` objects, if you open the\nfile in binary mode...\n\n.. code-block:: python\n\n        >>> with dw.open_remote_file('username/test-dataset', 'test.txt', mode='wb') as w:\n        ...   w.write(bytes([100,97,116,97,46,119,111,114,108,100]))\n\nReading files\n.............\n\nYou can also read data from a file in a similar fashion\n\n.. code-block:: python\n\n        >>> with dw.open_remote_file('username/test-dataset', 'test.txt', mode='r') as r:\n        ...   print(r.read)\n\n\nReading from the file into common parsing libraries works naturally, too - when opened in 'r' mode, the\nfile object acts as an Iterator of the lines in the file:\n\n.. code-block:: python\n\n        >>> with dw.open_remote_file('username/test-dataset', 'test.txt', mode='r') as r:\n        ...   csvr = csv.DictReader(r)\n        ...   for row in csvr:\n        ...      print(row['column a'], row['column b'])\n\n\nReading binary files works naturally, too - when opened in 'rb' mode, ``read()`` returns the contents of\nthe file as a byte array, and the file object acts as an iterator of bytes:\n\n.. code-block:: python\n\n        >>> with dw.open_remote_file('username/test-dataset', 'test', mode='rb') as r:\n        ...   bytes = r.read()\n\n\nAdditional API Features\n-----------------------\n\nFor a complete list of available API operations, see\n`official documentation <https://docs.data.world/documentation/api/>`_.\n\nPython wrappers are implemented by the ``ApiClient`` class. To obtain an instance, simply call ``api_client``.\nFor example:\n\n.. code-block:: python\n\n    client = dw.api_client\n\nThe client currently implements the following functions:\n\n* ``create_dataset``\n* ``update_dataset``\n* ``replace_dataset``\n* ``get_dataset``\n* ``delete_dataset``\n* ``add_files_via_url``\n* ``append_records``\n* ``upload_files``\n* ``upload_file``\n* ``delete_files``\n* ``sync_files``\n* ``download_dataset``\n* ``download_file``\n* ``get_user_data``\n* ``fetch_contributing_datasets``\n* ``fetch_liked_datasets``\n* ``fetch_datasets``\n* ``fetch_contributing_projects``\n* ``fetch_liked_projects``\n* ``fetch_projects``\n* ``get_project``\n* ``create_project``\n* ``update_project``\n* ``replace_project``\n* ``add_linked_dataset``\n* ``remove_linked_dataset``\n* ``delete_project``\n* ``get_insight``\n* ``get_insights_for_project``\n* ``create_insight``\n* ``replace_insight``\n* ``update_insight``\n* ``delete_insight``\n\nFor a few examples of what the ``ApiClient`` can be used for, see below.\n\nAdd files from URL\n..................\n\nThe ``add_files_via_url()`` function can be used to add files to a dataset from a URL. \nThis can be done by specifying ``files`` as a dictionary where the keys are the desired file name and each item is an object containing ``url``, ``description`` and ``labels``. \n\nFor example:\n\n.. code-block:: python\n\n    >>> client = dw.api_client\n    >>> client.add_files_via_url('username/test-dataset', files={'sample.xls': {'url':'http://www.sample.com/sample.xls', 'description': 'sample doc', 'labels': ['raw data']}})\n\nAppend records to stream\n........................\n\nThe ``append_record()`` function allows you to append JSON data to a data stream associated with a dataset. Streams do not need to be created in advance. Streams are automatically created the first time a ``streamId`` is used in an append operation. \n\nFor example:\n\n.. code-block:: python\n\n    >>> client = dw.api_client\n    >>> client.append_records('username/test-dataset','streamId', {'data': 'data'})\n\nContents of a stream will appear as part of the respective dataset as a .jsonl file.\n\nYou can find more about those functions using ``help(client)``\n\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/datadotworld/data.world-py", "keywords": "data.world dataset", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "datadotworld", "package_url": "https://pypi.org/project/datadotworld/", "platform": "", "project_url": "https://pypi.org/project/datadotworld/", "project_urls": {"Homepage": "http://github.com/datadotworld/data.world-py"}, "release_url": "https://pypi.org/project/datadotworld/1.7.0/", "requires_dist": ["certifi (>=2017.04.17)", "click (<7.0a,>=6.0)", "configparser (<4.0a,>=3.5.0)", "datapackage (<2.0a,>=1.6.2)", "tableschema (<2.0a,>=1.5.2)", "python-dateutil (<3.0a,>=2.6.0)", "requests (<3.0a,>=2.0.0)", "six (<2.0a,>=1.5.0)", "tabulator (>=1.22.0)", "urllib3 (<2.0a,>=1.15)", "numpy (<=1.16.4) ; extra == 'pandas'", "pandas (<0.25) ; extra == 'pandas'"], "requires_python": "", "summary": "Python library for data.world", "version": "1.7.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A python library for working with data.world datasets.</p>\n<p>This library makes it easy for data.world users to pull and work with data stored on data.world.\nAdditionally, the library provides convenient wrappers for data.world APIs, allowing users to create and update\ndatasets, add and modify files, etc, and possibly implement entire apps on top of data.world.</p>\n<div id=\"quick-start\">\n<h2>Quick start</h2>\n<div id=\"install\">\n<h3>Install</h3>\n<p>You can install it using <tt>pip</tt> directly from PyPI:</p>\n<pre>pip install datadotworld\n</pre>\n<p>Optionally, you can install the library including pandas support:</p>\n<pre>pip install datadotworld[pandas]\n</pre>\n<p>If you use <tt>conda</tt> to manage your python distribution, you can install from the community-maintained [conda-forge](<a href=\"https://conda-forge.github.io/\" rel=\"nofollow\">https://conda-forge.github.io/</a>) channel:</p>\n<pre>conda install -c conda-forge datadotworld-py\n</pre>\n</div>\n<div id=\"configure\">\n<h3>Configure</h3>\n<p>This library requires a data.world API authentication token to work.</p>\n<p>Your authentication token can be obtained on data.world once you enable Python under\n<a href=\"https://data.world/integrations/python\" rel=\"nofollow\">Integrations &gt; Python</a></p>\n<p>To configure the library, run the following command:</p>\n<pre>dw configure\n</pre>\n<p>Alternatively, tokens can be provided via the <tt>DW_AUTH_TOKEN</tt> environment variable.\nOn MacOS or Unix machines, run (replacing <tt>&lt;YOUR_TOKEN&gt;&gt;</tt> below with the token obtained earlier):</p>\n<pre>export DW_AUTH_TOKEN=&lt;YOUR_TOKEN&gt;\n</pre>\n</div>\n<div id=\"load-a-dataset\">\n<h3>Load a dataset</h3>\n<p>The <tt>load_dataset()</tt> function facilitates maintaining copies of datasets on the local filesystem.\nIt will download a given dataset\u2019s <a href=\"http://specs.frictionlessdata.io/data-package/\" rel=\"nofollow\">datapackage</a>\nand store it under <tt><span class=\"pre\">~/.dw/cache</span></tt>. When used subsequently, <tt>load_dataset()</tt> will use the copy stored on disk and will\nwork offline, unless it\u2019s called with <tt>force_update=True</tt> or <tt>auto_update=True</tt>. <tt>force_update=True</tt> will overwrite your local copy unconditionally. <tt>auto_update=True</tt> will only overwrite your local copy if a newer version of the dataset is available on data.world.</p>\n<p>Once loaded, a dataset (data and metadata) can be conveniently accessed via the object returned by <tt>load_dataset()</tt>.</p>\n<p>Start by importing the <tt>datadotworld</tt> module:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">datadotworld</span> <span class=\"k\">as</span> <span class=\"nn\">dw</span>\n</pre>\n<p>Then, invoke the <tt>load_dataset()</tt> function, to download a dataset and work with it locally.\nFor example:</p>\n<pre><span class=\"n\">intro_dataset</span> <span class=\"o\">=</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">load_dataset</span><span class=\"p\">(</span><span class=\"s1\">'jonloyens/an-intro-to-dataworld-dataset'</span><span class=\"p\">)</span>\n</pre>\n<p>Dataset objects allow access to data via three different properties <tt>raw_data</tt>, <tt>tables</tt> and <tt>dataframes</tt>.\nEach of these properties is a mapping (dict) whose values are of type <tt>bytes</tt>, <tt>list</tt> and <tt>pandas.DataFrame</tt>,\nrespectively. Values are lazy loaded and cached once loaded. Their keys are the names of the files\ncontained in the dataset.</p>\n<p>For example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">intro_dataset</span><span class=\"o\">.</span><span class=\"n\">dataframes</span>\n<span class=\"n\">LazyLoadedDict</span><span class=\"p\">({</span>\n    <span class=\"s1\">'changelog'</span><span class=\"p\">:</span> <span class=\"n\">LazyLoadedValue</span><span class=\"p\">(</span><span class=\"o\">&lt;</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">&gt;</span><span class=\"p\">),</span>\n    <span class=\"s1\">'datadotworldbballstats'</span><span class=\"p\">:</span> <span class=\"n\">LazyLoadedValue</span><span class=\"p\">(</span><span class=\"o\">&lt;</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">&gt;</span><span class=\"p\">),</span>\n    <span class=\"s1\">'datadotworldbballteam'</span><span class=\"p\">:</span> <span class=\"n\">LazyLoadedValue</span><span class=\"p\">(</span><span class=\"o\">&lt;</span><span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"o\">&gt;</span><span class=\"p\">)})</span>\n</pre>\n<p><strong>IMPORTANT</strong>: Not all files in a dataset are tabular, therefore some will be exposed via <tt>raw_data</tt> only.</p>\n<p>Tables are lists of rows, each represented by a mapping (dict) of column names to their respective values.</p>\n<p>For example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">stats_table</span> <span class=\"o\">=</span> <span class=\"n\">intro_dataset</span><span class=\"o\">.</span><span class=\"n\">tables</span><span class=\"p\">[</span><span class=\"s1\">'datadotworldbballstats'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">stats_table</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">OrderedDict</span><span class=\"p\">([(</span><span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"s1\">'Jon'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'PointsPerGame'</span><span class=\"p\">,</span> <span class=\"n\">Decimal</span><span class=\"p\">(</span><span class=\"s1\">'20.4'</span><span class=\"p\">)),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'AssistsPerGame'</span><span class=\"p\">,</span> <span class=\"n\">Decimal</span><span class=\"p\">(</span><span class=\"s1\">'1.3'</span><span class=\"p\">))])</span>\n</pre>\n<p>You can also review the metadata associated with a file or the entire dataset, using the <tt>describe</tt> function.\nFor example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">intro_dataset</span><span class=\"o\">.</span><span class=\"n\">describe</span><span class=\"p\">()</span>\n<span class=\"p\">{</span><span class=\"s1\">'homepage'</span><span class=\"p\">:</span> <span class=\"s1\">'https://data.world/jonloyens/an-intro-to-dataworld-dataset'</span><span class=\"p\">,</span>\n <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'jonloyens_an-intro-to-dataworld-dataset'</span><span class=\"p\">,</span>\n <span class=\"s1\">'resources'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'changelog'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'data/ChangeLog.csv'</span><span class=\"p\">},</span>\n  <span class=\"p\">{</span><span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'datadotworldbballstats'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'data/DataDotWorldBBallStats.csv'</span><span class=\"p\">},</span>\n  <span class=\"p\">{</span><span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'datadotworldbballteam'</span><span class=\"p\">,</span>\n   <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'data/DataDotWorldBBallTeam.csv'</span><span class=\"p\">}]}</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">intro_dataset</span><span class=\"o\">.</span><span class=\"n\">describe</span><span class=\"p\">(</span><span class=\"s1\">'datadotworldbballstats'</span><span class=\"p\">)</span>\n<span class=\"p\">{</span><span class=\"s1\">'format'</span><span class=\"p\">:</span> <span class=\"s1\">'csv'</span><span class=\"p\">,</span>\n <span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'datadotworldbballstats'</span><span class=\"p\">,</span>\n <span class=\"s1\">'path'</span><span class=\"p\">:</span> <span class=\"s1\">'data/DataDotWorldBBallStats.csv'</span><span class=\"p\">,</span>\n <span class=\"s1\">'schema'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"s1\">'title'</span><span class=\"p\">:</span> <span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'string'</span><span class=\"p\">},</span>\n                       <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'PointsPerGame'</span><span class=\"p\">,</span>\n                        <span class=\"s1\">'title'</span><span class=\"p\">:</span> <span class=\"s1\">'PointsPerGame'</span><span class=\"p\">,</span>\n                        <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'number'</span><span class=\"p\">},</span>\n                       <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'AssistsPerGame'</span><span class=\"p\">,</span>\n                        <span class=\"s1\">'title'</span><span class=\"p\">:</span> <span class=\"s1\">'AssistsPerGame'</span><span class=\"p\">,</span>\n                        <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'number'</span><span class=\"p\">}]}}</span>\n</pre>\n</div>\n<div id=\"query-a-dataset\">\n<h3>Query a dataset</h3>\n<p>The <tt>query()</tt> function allows datasets to be queried live using <tt>SQL</tt> or <tt>SPARQL</tt> query languages.</p>\n<p>To query a dataset, invoke the <tt>query()</tt> function.\nFor example:</p>\n<pre><span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">query</span><span class=\"p\">(</span><span class=\"s1\">'jonloyens/an-intro-to-dataworld-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'SELECT * FROM DataDotWorldBBallStats'</span><span class=\"p\">)</span>\n</pre>\n<p>Query result objects allow access to the data via <tt>raw_data</tt>, <tt>table</tt> and <tt>dataframe</tt> properties, of type\n<tt>json</tt>, <tt>list</tt> and <tt>pandas.DataFrame</tt>, respectively.</p>\n<p>For example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">dataframe</span>\n      <span class=\"n\">Name</span>  <span class=\"n\">PointsPerGame</span>  <span class=\"n\">AssistsPerGame</span>\n<span class=\"mi\">0</span>      <span class=\"n\">Jon</span>           <span class=\"mf\">20.4</span>             <span class=\"mf\">1.3</span>\n<span class=\"mi\">1</span>      <span class=\"n\">Rob</span>           <span class=\"mf\">15.5</span>             <span class=\"mf\">8.0</span>\n<span class=\"mi\">2</span>   <span class=\"n\">Sharon</span>           <span class=\"mf\">30.1</span>            <span class=\"mf\">11.2</span>\n<span class=\"mi\">3</span>     <span class=\"n\">Alex</span>            <span class=\"mf\">8.2</span>             <span class=\"mf\">0.5</span>\n<span class=\"mi\">4</span>  <span class=\"n\">Rebecca</span>           <span class=\"mf\">12.3</span>            <span class=\"mf\">17.0</span>\n<span class=\"mi\">5</span>   <span class=\"n\">Ariane</span>           <span class=\"mf\">18.1</span>             <span class=\"mf\">3.0</span>\n<span class=\"mi\">6</span>    <span class=\"n\">Bryon</span>           <span class=\"mf\">16.0</span>             <span class=\"mf\">8.5</span>\n<span class=\"mi\">7</span>     <span class=\"n\">Matt</span>           <span class=\"mf\">13.0</span>             <span class=\"mf\">2.1</span>\n</pre>\n<p>Tables are lists of rows, each represented by a mapping (dict) of column names to their respective values.\nFor example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">table</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"n\">OrderedDict</span><span class=\"p\">([(</span><span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"s1\">'Jon'</span><span class=\"p\">),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'PointsPerGame'</span><span class=\"p\">,</span> <span class=\"n\">Decimal</span><span class=\"p\">(</span><span class=\"s1\">'20.4'</span><span class=\"p\">)),</span>\n             <span class=\"p\">(</span><span class=\"s1\">'AssistsPerGame'</span><span class=\"p\">,</span> <span class=\"n\">Decimal</span><span class=\"p\">(</span><span class=\"s1\">'1.3'</span><span class=\"p\">))])</span>\n</pre>\n<p>To query using <tt>SPARQL</tt> invoke <tt>query()</tt> using <tt><span class=\"pre\">query_type='sparql'</span></tt>, or else, it will assume\nthe query to be a <tt>SQL</tt> query.</p>\n<p>Just like in the dataset case, you can view the metadata associated with a query result using the <tt>describe()</tt>\nfunction.</p>\n<p>For example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">describe</span><span class=\"p\">()</span>\n<span class=\"p\">{</span><span class=\"s1\">'fields'</span><span class=\"p\">:</span> <span class=\"p\">[{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'Name'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'string'</span><span class=\"p\">},</span>\n            <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'PointsPerGame'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'number'</span><span class=\"p\">},</span>\n            <span class=\"p\">{</span><span class=\"s1\">'name'</span><span class=\"p\">:</span> <span class=\"s1\">'AssistsPerGame'</span><span class=\"p\">,</span> <span class=\"s1\">'type'</span><span class=\"p\">:</span> <span class=\"s1\">'number'</span><span class=\"p\">}]}</span>\n</pre>\n</div>\n<div id=\"work-with-files\">\n<h3>Work with files</h3>\n<p>The <tt>open_remote_file()</tt> function allows you to write data to or read data from a file in a\ndata.world dataset.</p>\n<div id=\"writing-files\">\n<h4>Writing files</h4>\n<p>The object that is returned from the <tt>open_remote_file()</tt> call is similar to a file handle that\nwould be used to write to a local file - it has a <tt>write()</tt> method, and contents sent to that\nmethod will be written to the file remotely.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">datadotworld</span> <span class=\"k\">as</span> <span class=\"nn\">dw</span>\n<span class=\"o\">&gt;&gt;&gt;</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test.txt'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">w</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"s2\">\"this is a test.\"</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span>\n</pre>\n<p>Of course, writing a text file isn\u2019t the primary use case for data.world - you want to write your\ndata!  The return object from <tt>open_remote_file()</tt> should be usable anywhere you could normally\nuse a local file handle in write mode - so you can use it to serialize the contents of a PANDAS\n<tt>DataFrame</tt> to a CSV file\u2026</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">({</span><span class=\"s1\">'foo'</span><span class=\"p\">:[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">],</span><span class=\"s1\">'bar'</span><span class=\"p\">:[</span><span class=\"s1\">'a'</span><span class=\"p\">,</span><span class=\"s1\">'b'</span><span class=\"p\">,</span><span class=\"s1\">'c'</span><span class=\"p\">,</span><span class=\"s1\">'d'</span><span class=\"p\">]})</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'dataframe.csv'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">w</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>Or, to write a series of <tt>dict</tt> objects as a JSON Lines file\u2026</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">json</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test.jsonl'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">w</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">({</span><span class=\"s1\">'foo'</span><span class=\"p\">:</span><span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"s1\">'bar'</span><span class=\"p\">:</span><span class=\"s2\">\"A\"</span><span class=\"p\">},</span> <span class=\"n\">w</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>   <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">({</span><span class=\"s1\">'foo'</span><span class=\"p\">:</span><span class=\"mi\">13</span><span class=\"p\">,</span> <span class=\"s1\">'bar'</span><span class=\"p\">:</span><span class=\"s2\">\"B\"</span><span class=\"p\">},</span> <span class=\"n\">w</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span>\n</pre>\n<p>Or to write a series of <tt>dict</tt> objects as a CSV\u2026</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">csv</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test.csv'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">w</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"n\">csvw</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"o\">.</span><span class=\"n\">DictWriter</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span> <span class=\"n\">fieldnames</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'foo'</span><span class=\"p\">,</span> <span class=\"s1\">'bar'</span><span class=\"p\">])</span>\n<span class=\"o\">...</span>   <span class=\"n\">csvw</span><span class=\"o\">.</span><span class=\"n\">writeheader</span><span class=\"p\">()</span>\n<span class=\"o\">...</span>   <span class=\"n\">csvw</span><span class=\"o\">.</span><span class=\"n\">writerow</span><span class=\"p\">({</span><span class=\"s1\">'foo'</span><span class=\"p\">:</span><span class=\"mi\">42</span><span class=\"p\">,</span> <span class=\"s1\">'bar'</span><span class=\"p\">:</span><span class=\"s2\">\"A\"</span><span class=\"p\">})</span>\n<span class=\"o\">...</span>   <span class=\"n\">csvw</span><span class=\"o\">.</span><span class=\"n\">writerow</span><span class=\"p\">({</span><span class=\"s1\">'foo'</span><span class=\"p\">:</span><span class=\"mi\">13</span><span class=\"p\">,</span> <span class=\"s1\">'bar'</span><span class=\"p\">:</span><span class=\"s2\">\"B\"</span><span class=\"p\">})</span>\n<span class=\"o\">&gt;&gt;&gt;</span>\n</pre>\n<p>And finally, you can write binary data by streaming <tt>bytes</tt> or <tt>bytearray</tt> objects, if you open the\nfile in binary mode\u2026</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test.txt'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'wb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">w</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"n\">w</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"nb\">bytes</span><span class=\"p\">([</span><span class=\"mi\">100</span><span class=\"p\">,</span><span class=\"mi\">97</span><span class=\"p\">,</span><span class=\"mi\">116</span><span class=\"p\">,</span><span class=\"mi\">97</span><span class=\"p\">,</span><span class=\"mi\">46</span><span class=\"p\">,</span><span class=\"mi\">119</span><span class=\"p\">,</span><span class=\"mi\">111</span><span class=\"p\">,</span><span class=\"mi\">114</span><span class=\"p\">,</span><span class=\"mi\">108</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">]))</span>\n</pre>\n</div>\n<div id=\"reading-files\">\n<h4>Reading files</h4>\n<p>You can also read data from a file in a similar fashion</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test.txt'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'r'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">r</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">)</span>\n</pre>\n<p>Reading from the file into common parsing libraries works naturally, too - when opened in \u2018r\u2019 mode, the\nfile object acts as an Iterator of the lines in the file:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test.txt'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'r'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">r</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"n\">csvr</span> <span class=\"o\">=</span> <span class=\"n\">csv</span><span class=\"o\">.</span><span class=\"n\">DictReader</span><span class=\"p\">(</span><span class=\"n\">r</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>   <span class=\"k\">for</span> <span class=\"n\">row</span> <span class=\"ow\">in</span> <span class=\"n\">csvr</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>      <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'column a'</span><span class=\"p\">],</span> <span class=\"n\">row</span><span class=\"p\">[</span><span class=\"s1\">'column b'</span><span class=\"p\">])</span>\n</pre>\n<p>Reading binary files works naturally, too - when opened in \u2018rb\u2019 mode, <tt>read()</tt> returns the contents of\nthe file as a byte array, and the file object acts as an iterator of bytes:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"k\">with</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">open_remote_file</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"s1\">'test'</span><span class=\"p\">,</span> <span class=\"n\">mode</span><span class=\"o\">=</span><span class=\"s1\">'rb'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">r</span><span class=\"p\">:</span>\n<span class=\"o\">...</span>   <span class=\"nb\">bytes</span> <span class=\"o\">=</span> <span class=\"n\">r</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n</pre>\n</div>\n</div>\n<div id=\"additional-api-features\">\n<h3>Additional API Features</h3>\n<p>For a complete list of available API operations, see\n<a href=\"https://docs.data.world/documentation/api/\" rel=\"nofollow\">official documentation</a>.</p>\n<p>Python wrappers are implemented by the <tt>ApiClient</tt> class. To obtain an instance, simply call <tt>api_client</tt>.\nFor example:</p>\n<pre><span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">api_client</span>\n</pre>\n<p>The client currently implements the following functions:</p>\n<ul>\n<li><tt>create_dataset</tt></li>\n<li><tt>update_dataset</tt></li>\n<li><tt>replace_dataset</tt></li>\n<li><tt>get_dataset</tt></li>\n<li><tt>delete_dataset</tt></li>\n<li><tt>add_files_via_url</tt></li>\n<li><tt>append_records</tt></li>\n<li><tt>upload_files</tt></li>\n<li><tt>upload_file</tt></li>\n<li><tt>delete_files</tt></li>\n<li><tt>sync_files</tt></li>\n<li><tt>download_dataset</tt></li>\n<li><tt>download_file</tt></li>\n<li><tt>get_user_data</tt></li>\n<li><tt>fetch_contributing_datasets</tt></li>\n<li><tt>fetch_liked_datasets</tt></li>\n<li><tt>fetch_datasets</tt></li>\n<li><tt>fetch_contributing_projects</tt></li>\n<li><tt>fetch_liked_projects</tt></li>\n<li><tt>fetch_projects</tt></li>\n<li><tt>get_project</tt></li>\n<li><tt>create_project</tt></li>\n<li><tt>update_project</tt></li>\n<li><tt>replace_project</tt></li>\n<li><tt>add_linked_dataset</tt></li>\n<li><tt>remove_linked_dataset</tt></li>\n<li><tt>delete_project</tt></li>\n<li><tt>get_insight</tt></li>\n<li><tt>get_insights_for_project</tt></li>\n<li><tt>create_insight</tt></li>\n<li><tt>replace_insight</tt></li>\n<li><tt>update_insight</tt></li>\n<li><tt>delete_insight</tt></li>\n</ul>\n<p>For a few examples of what the <tt>ApiClient</tt> can be used for, see below.</p>\n<div id=\"add-files-from-url\">\n<h4>Add files from URL</h4>\n<p>The <tt>add_files_via_url()</tt> function can be used to add files to a dataset from a URL.\nThis can be done by specifying <tt>files</tt> as a dictionary where the keys are the desired file name and each item is an object containing <tt>url</tt>, <tt>description</tt> and <tt>labels</tt>.</p>\n<p>For example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">api_client</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">add_files_via_url</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span> <span class=\"n\">files</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">'sample.xls'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'url'</span><span class=\"p\">:</span><span class=\"s1\">'http://www.sample.com/sample.xls'</span><span class=\"p\">,</span> <span class=\"s1\">'description'</span><span class=\"p\">:</span> <span class=\"s1\">'sample doc'</span><span class=\"p\">,</span> <span class=\"s1\">'labels'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'raw data'</span><span class=\"p\">]}})</span>\n</pre>\n</div>\n<div id=\"append-records-to-stream\">\n<h4>Append records to stream</h4>\n<p>The <tt>append_record()</tt> function allows you to append JSON data to a data stream associated with a dataset. Streams do not need to be created in advance. Streams are automatically created the first time a <tt>streamId</tt> is used in an append operation.</p>\n<p>For example:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">dw</span><span class=\"o\">.</span><span class=\"n\">api_client</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">client</span><span class=\"o\">.</span><span class=\"n\">append_records</span><span class=\"p\">(</span><span class=\"s1\">'username/test-dataset'</span><span class=\"p\">,</span><span class=\"s1\">'streamId'</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s1\">'data'</span><span class=\"p\">:</span> <span class=\"s1\">'data'</span><span class=\"p\">})</span>\n</pre>\n<p>Contents of a stream will appear as part of the respective dataset as a .jsonl file.</p>\n<p>You can find more about those functions using <tt>help(client)</tt></p>\n</div>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5493625, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "c8e53523269b40ab1e75e4564909eb40", "sha256": "6e9d59f985c4e0b259e38d8fe3466ca403044c653af2c4499578c1a7c323b85b"}, "downloads": -1, "filename": "datadotworld-1.0.0.tar.gz", "has_sig": false, "md5_digest": "c8e53523269b40ab1e75e4564909eb40", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36768, "upload_time": "2017-04-14T04:31:43", "upload_time_iso_8601": "2017-04-14T04:31:43.085511Z", "url": "https://files.pythonhosted.org/packages/de/45/52cf506b1870c6d2dab3a08478c003fa14f96336993f9d7caf63ff2d6091/datadotworld-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "12fbcb5831855722922e28d0f41ce0f5", "sha256": "826b8e61ccc3a4c7c9800119d25077b8a2e409f24d207100ce70fd50cee2152f"}, "downloads": -1, "filename": "datadotworld-1.0.1.tar.gz", "has_sig": false, "md5_digest": "12fbcb5831855722922e28d0f41ce0f5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38120, "upload_time": "2017-04-14T14:45:57", "upload_time_iso_8601": "2017-04-14T14:45:57.829878Z", "url": "https://files.pythonhosted.org/packages/97/cb/fa2d7ef087ecfcef33cb6e2e0777ffddacf2707718650d5b54d0464904c7/datadotworld-1.0.1.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "f64a42fcf7a1db795ce8c98307fa47d4", "sha256": "9c837a9e3edcb3a4f2f23e14e36b1d7c933f5f1a7eefed8cdae132921facf7d0"}, "downloads": -1, "filename": "datadotworld-1.1.0.tar.gz", "has_sig": false, "md5_digest": "f64a42fcf7a1db795ce8c98307fa47d4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39330, "upload_time": "2017-04-21T18:13:01", "upload_time_iso_8601": "2017-04-21T18:13:01.420114Z", "url": "https://files.pythonhosted.org/packages/88/9c/024a2691632369e049d46a5b5145015cb2cf2274c3f6691972f23753d863/datadotworld-1.1.0.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "bfffd55f200a987a37dcca9a6adc1aee", "sha256": "d16887a74dba82c0074d428236bb5d32dbf042b2811151b71379ffc7dbde635b"}, "downloads": -1, "filename": "datadotworld-1.2.0.tar.gz", "has_sig": false, "md5_digest": "bfffd55f200a987a37dcca9a6adc1aee", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39962, "upload_time": "2017-05-12T22:38:02", "upload_time_iso_8601": "2017-05-12T22:38:02.148748Z", "url": "https://files.pythonhosted.org/packages/cc/a1/457b6dc68a98d856164e0bb75c9b9200a7e26d089de19553e76564b7b205/datadotworld-1.2.0.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "c64427e60f3828030de07adfa39c632c", "sha256": "22bcabb4dd484be1a3767ebb16f2b46f0d25682d076c715781f44dcaa53a1ced"}, "downloads": -1, "filename": "datadotworld-1.2.1.tar.gz", "has_sig": false, "md5_digest": "c64427e60f3828030de07adfa39c632c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37289, "upload_time": "2017-06-02T04:42:50", "upload_time_iso_8601": "2017-06-02T04:42:50.861538Z", "url": "https://files.pythonhosted.org/packages/b8/30/6e94d655bcd83c0ccc99f8e1397ee92f31936e18669d6810489b6bbd05d4/datadotworld-1.2.1.tar.gz", "yanked": false}], "1.2.2": [{"comment_text": "", "digests": {"md5": "db696cd7b129d327402925d5b5b172a6", "sha256": "45f8f19d3659070b33719b0d09672aad1c53ef6d11e62e345e6bc3d09933bf60"}, "downloads": -1, "filename": "datadotworld-1.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "db696cd7b129d327402925d5b5b172a6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 68091, "upload_time": "2017-06-02T05:22:00", "upload_time_iso_8601": "2017-06-02T05:22:00.745811Z", "url": "https://files.pythonhosted.org/packages/a7/7d/8575fbb521f5b7be22e472aee36fcb3f6aa588ac81353ad0f0da10974a63/datadotworld-1.2.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dff056b29623271f5572989134fe495a", "sha256": "17087fc9228715ab67e61408cb4159662f7ce6b78805ba67f753a8efd9be6715"}, "downloads": -1, "filename": "datadotworld-1.2.2.tar.gz", "has_sig": false, "md5_digest": "dff056b29623271f5572989134fe495a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42085, "upload_time": "2017-06-02T05:22:02", "upload_time_iso_8601": "2017-06-02T05:22:02.221614Z", "url": "https://files.pythonhosted.org/packages/06/0d/19e502c382a6dce8ac8c984e85d0751d24d39aa7accb67faff6e58ef3f46/datadotworld-1.2.2.tar.gz", "yanked": false}], "1.2.3": [{"comment_text": "", "digests": {"md5": "9f13c932c96d66997cde472c2f559035", "sha256": "9f02cc51bc78461cca4f72c31bf1ae119e20e6434ab4a3f38cee843770acf928"}, "downloads": -1, "filename": "datadotworld-1.2.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9f13c932c96d66997cde472c2f559035", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 68118, "upload_time": "2017-06-02T14:17:07", "upload_time_iso_8601": "2017-06-02T14:17:07.796042Z", "url": "https://files.pythonhosted.org/packages/fa/56/ebc8ac3094fd1668ec8ff3ae42555c9090578b2339685ace653a9a51baa1/datadotworld-1.2.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f03a59766ec95af461800d392e5cf776", "sha256": "563a8aebb727799fd0a1a26237b9305b5c5304cb7863d14f6ffa7ed4d6c36d19"}, "downloads": -1, "filename": "datadotworld-1.2.3.tar.gz", "has_sig": false, "md5_digest": "f03a59766ec95af461800d392e5cf776", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42100, "upload_time": "2017-06-02T14:17:08", "upload_time_iso_8601": "2017-06-02T14:17:08.868461Z", "url": "https://files.pythonhosted.org/packages/c2/cf/8cf46db7e225f996df56ebfa9955d1adc40511d381e49864c59c67ad937e/datadotworld-1.2.3.tar.gz", "yanked": false}], "1.2.4": [{"comment_text": "", "digests": {"md5": "207e1b36d105c2ba9745c49b8e6ee7bd", "sha256": "40a6342b71c52c33f39d68a7f506cebbc688a757c009b774f0cb02b7fc457432"}, "downloads": -1, "filename": "datadotworld-1.2.4.tar.gz", "has_sig": false, "md5_digest": "207e1b36d105c2ba9745c49b8e6ee7bd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42088, "upload_time": "2017-06-02T15:34:44", "upload_time_iso_8601": "2017-06-02T15:34:44.185439Z", "url": "https://files.pythonhosted.org/packages/dc/d1/a7af0b8a2bee1dc78c63dc5657bc157fc0b1bcd36e23f0a97a7c73383d2b/datadotworld-1.2.4.tar.gz", "yanked": false}], "1.2.5": [{"comment_text": "", "digests": {"md5": "d63993dac603fb10bb5f410d60784b38", "sha256": "484eaed3e44563274634daf67d134268668fa08fd4b7e72b1a151fe24ca5f531"}, "downloads": -1, "filename": "datadotworld-1.2.5.tar.gz", "has_sig": false, "md5_digest": "d63993dac603fb10bb5f410d60784b38", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 42143, "upload_time": "2017-06-06T14:16:53", "upload_time_iso_8601": "2017-06-06T14:16:53.263564Z", "url": "https://files.pythonhosted.org/packages/72/9b/2b3d40d6a380e1a7d925707c93ee7e416614fa402b1ee1dac3bba754ca5e/datadotworld-1.2.5.tar.gz", "yanked": false}], "1.2.6": [{"comment_text": "", "digests": {"md5": "758ffd29ad07db3c27726286189524ea", "sha256": "d4d74918c09f2a7eab1863403262e4b2175f2685975fb719a155fd93ff0515cb"}, "downloads": -1, "filename": "datadotworld-1.2.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "758ffd29ad07db3c27726286189524ea", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 68644, "upload_time": "2017-07-18T02:23:39", "upload_time_iso_8601": "2017-07-18T02:23:39.821987Z", "url": "https://files.pythonhosted.org/packages/99/b8/d961091c957a1421dd9083031d532ad2a3dbe3393d4a15715dbc2c71167d/datadotworld-1.2.6-py2.py3-none-any.whl", "yanked": false}], "1.2.6rc1": [{"comment_text": "", "digests": {"md5": "7669a90fb337b15e0875c3e94d0ef219", "sha256": "5fdfe2867316846612b99268090d0233da55d890ecf78f38a082dd7de53e6baf"}, "downloads": -1, "filename": "datadotworld-1.2.6rc1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7669a90fb337b15e0875c3e94d0ef219", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 68698, "upload_time": "2017-07-18T02:09:19", "upload_time_iso_8601": "2017-07-18T02:09:19.834265Z", "url": "https://files.pythonhosted.org/packages/93/b0/c13d7c0f6abea8800f68e2c35a44a1c3579fd4017ee1122da92065d027fb/datadotworld-1.2.6rc1-py2.py3-none-any.whl", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "e7bff89df914b592442796c0cb9252aa", "sha256": "8732cd57c1b4654327727c93bfba6675a25c931ea65daa351cec99f5f2bec2b7"}, "downloads": -1, "filename": "datadotworld-1.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e7bff89df914b592442796c0cb9252aa", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 73328, "upload_time": "2017-07-21T15:11:33", "upload_time_iso_8601": "2017-07-21T15:11:33.751569Z", "url": "https://files.pythonhosted.org/packages/36/f7/e5af7a7aed5ff7680d530b3970a3ee50d5c9a80b644a15bfe2ac8bc81921/datadotworld-1.3.0-py2.py3-none-any.whl", "yanked": false}], "1.4.0": [{"comment_text": "", "digests": {"md5": "81facaaf161a737491c7e1aa02966d5d", "sha256": "305abc8d79d1030b44c6b27c8c7c5ee20c8b06f54cf40750044bf096fdf879dd"}, "downloads": -1, "filename": "datadotworld-1.4.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "81facaaf161a737491c7e1aa02966d5d", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 74856, "upload_time": "2017-08-01T22:31:21", "upload_time_iso_8601": "2017-08-01T22:31:21.861553Z", "url": "https://files.pythonhosted.org/packages/a1/5f/a6a2c8e889e26da663f39bcfa86eeb4f6ed9fbf14b8a741134d153a293af/datadotworld-1.4.0-py2.py3-none-any.whl", "yanked": false}], "1.4.1": [{"comment_text": "", "digests": {"md5": "28f7089070cc2ab85cd73c796665f81f", "sha256": "db85be180eb656c068621e713e9edfe9812966b6743355d3c0668bc5e5e514d9"}, "downloads": -1, "filename": "datadotworld-1.4.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "28f7089070cc2ab85cd73c796665f81f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 74883, "upload_time": "2017-08-04T13:59:17", "upload_time_iso_8601": "2017-08-04T13:59:17.391642Z", "url": "https://files.pythonhosted.org/packages/bf/be/e6a7fa3a8aa227e53f79c4545b2acb6f82c3e0bfc89c7d49a11141c3e5c0/datadotworld-1.4.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "328e8a29e10534a4eb18a7f38abafd95", "sha256": "ce4ed25b74ea1ece21b94d8b15e7762b4dc971c68bdc23645ea6a299952708f2"}, "downloads": -1, "filename": "datadotworld-1.4.1.tar.gz", "has_sig": false, "md5_digest": "328e8a29e10534a4eb18a7f38abafd95", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46008, "upload_time": "2017-08-04T13:59:19", "upload_time_iso_8601": "2017-08-04T13:59:19.743734Z", "url": "https://files.pythonhosted.org/packages/44/db/ab7787f785710407410993ba7ce7504af258172e72001e385febf2fa9401/datadotworld-1.4.1.tar.gz", "yanked": false}], "1.4.2": [{"comment_text": "", "digests": {"md5": "d792d4c8daf8851717a240ffc47150c5", "sha256": "23071bdbf15578895ba58dbc827d9e60db98e78aa1177ca1fc4824b3cc77ff2e"}, "downloads": -1, "filename": "datadotworld-1.4.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d792d4c8daf8851717a240ffc47150c5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 75072, "upload_time": "2017-10-08T19:11:23", "upload_time_iso_8601": "2017-10-08T19:11:23.999816Z", "url": "https://files.pythonhosted.org/packages/4c/ea/82fb3f65d229f379d1c1ff9e5b2da4c88de3a56887961a0054fecc488819/datadotworld-1.4.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1d5cb230384a99d6c72ecc1fb0b22b2e", "sha256": "c45b49abc8958f1d133279976bc285a9cc0909d6884d1d0093dcbc415ce13584"}, "downloads": -1, "filename": "datadotworld-1.4.2.tar.gz", "has_sig": false, "md5_digest": "1d5cb230384a99d6c72ecc1fb0b22b2e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46207, "upload_time": "2017-10-08T19:11:25", "upload_time_iso_8601": "2017-10-08T19:11:25.394581Z", "url": "https://files.pythonhosted.org/packages/84/41/0065c8962a095ddbf0c69edd4d714fd1f3443a352e5de5727931e41e8afd/datadotworld-1.4.2.tar.gz", "yanked": false}], "1.5.0": [{"comment_text": "", "digests": {"md5": "5139719148dc29b0b69d8ffae34d02e9", "sha256": "b9e6f9093d625f613e6cfbd10564e1733b94843ee03defd900f7b3d840275a15"}, "downloads": -1, "filename": "datadotworld-1.5.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5139719148dc29b0b69d8ffae34d02e9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 108765, "upload_time": "2017-12-15T16:24:40", "upload_time_iso_8601": "2017-12-15T16:24:40.669853Z", "url": "https://files.pythonhosted.org/packages/92/4d/b394bf3ee10ebc238cda7784ae13bdd0528d1b047c5062068df88faf2d48/datadotworld-1.5.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1bcd82685a85301fe2ca679b671337a0", "sha256": "b01a379f6db93b6101ed8fd01bf99aa505128212f88b4d1ba484cf09c7caa96f"}, "downloads": -1, "filename": "datadotworld-1.5.0.tar.gz", "has_sig": false, "md5_digest": "1bcd82685a85301fe2ca679b671337a0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 61463, "upload_time": "2017-12-15T16:24:41", "upload_time_iso_8601": "2017-12-15T16:24:41.896336Z", "url": "https://files.pythonhosted.org/packages/4c/6d/00bf5a8c873701e35b445bab7c92289d573140d387cbc04e9c9d5197b9b4/datadotworld-1.5.0.tar.gz", "yanked": false}], "1.6.0": [{"comment_text": "", "digests": {"md5": "dff0848ed0cdb3894140dabc5caa6a1f", "sha256": "de2fae6774e6fe29b16bc6a7f16a85d7c1d1c4e66cd3c8d0e7e0f27c1bdd2eb2"}, "downloads": -1, "filename": "datadotworld-1.6.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "dff0848ed0cdb3894140dabc5caa6a1f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 158327, "upload_time": "2018-02-15T19:16:12", "upload_time_iso_8601": "2018-02-15T19:16:12.628904Z", "url": "https://files.pythonhosted.org/packages/13/81/ce7e41d46475d6522ce367023a42a8d9779a2fc3e84e74a3d14c9b65ad51/datadotworld-1.6.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b4770cdb8540db95b55342bff1fe112c", "sha256": "4d3c8a1306e05f08b46384cc0c4a86140ce1efab4e717cf363ead9f18824de72"}, "downloads": -1, "filename": "datadotworld-1.6.0.tar.gz", "has_sig": false, "md5_digest": "b4770cdb8540db95b55342bff1fe112c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 83514, "upload_time": "2018-02-15T19:16:14", "upload_time_iso_8601": "2018-02-15T19:16:14.458752Z", "url": "https://files.pythonhosted.org/packages/10/88/8bdb7e5e095f7b1a0de4cfc378b150f0c22cbdd8b928dc26afd768666730/datadotworld-1.6.0.tar.gz", "yanked": false}], "1.7.0": [{"comment_text": "", "digests": {"md5": "3293a27a2ebbde954b9a29b6c3a36251", "sha256": "48c7a7ea284b1fa7334c84f4cecdc99e3ccb199d3caa34a662422b89e26043f2"}, "downloads": -1, "filename": "datadotworld-1.7.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3293a27a2ebbde954b9a29b6c3a36251", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 158381, "upload_time": "2019-07-06T00:50:52", "upload_time_iso_8601": "2019-07-06T00:50:52.713844Z", "url": "https://files.pythonhosted.org/packages/eb/2d/564c9b9056c414528f7a91c48bc33f2243bd5323ac07d52269002bd3d6c6/datadotworld-1.7.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb04e700b21984b0bbfcb07bce7fd93e", "sha256": "bf9d44e8c0a9a44c31f1b6663609ea6b9c9e02fc59ee81fc4442bf36dfa75de6"}, "downloads": -1, "filename": "datadotworld-1.7.0.tar.gz", "has_sig": false, "md5_digest": "cb04e700b21984b0bbfcb07bce7fd93e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 81114, "upload_time": "2019-07-06T00:50:54", "upload_time_iso_8601": "2019-07-06T00:50:54.641696Z", "url": "https://files.pythonhosted.org/packages/e6/90/5550aea3a39db8f9fd9f1aefbc60dd2b725ad7194bf5ea44c7a025565209/datadotworld-1.7.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3293a27a2ebbde954b9a29b6c3a36251", "sha256": "48c7a7ea284b1fa7334c84f4cecdc99e3ccb199d3caa34a662422b89e26043f2"}, "downloads": -1, "filename": "datadotworld-1.7.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3293a27a2ebbde954b9a29b6c3a36251", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 158381, "upload_time": "2019-07-06T00:50:52", "upload_time_iso_8601": "2019-07-06T00:50:52.713844Z", "url": "https://files.pythonhosted.org/packages/eb/2d/564c9b9056c414528f7a91c48bc33f2243bd5323ac07d52269002bd3d6c6/datadotworld-1.7.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb04e700b21984b0bbfcb07bce7fd93e", "sha256": "bf9d44e8c0a9a44c31f1b6663609ea6b9c9e02fc59ee81fc4442bf36dfa75de6"}, "downloads": -1, "filename": "datadotworld-1.7.0.tar.gz", "has_sig": false, "md5_digest": "cb04e700b21984b0bbfcb07bce7fd93e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 81114, "upload_time": "2019-07-06T00:50:54", "upload_time_iso_8601": "2019-07-06T00:50:54.641696Z", "url": "https://files.pythonhosted.org/packages/e6/90/5550aea3a39db8f9fd9f1aefbc60dd2b725ad7194bf5ea44c7a025565209/datadotworld-1.7.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:25 2020"}