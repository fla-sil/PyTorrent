{"info": {"author": "NAVER Corp.", "author_email": "", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "## Reliable Fidelity and Diversity Metrics for Generative Models\n\n[Paper: Reliable Fidelity and Diversity Metrics for Generative Models](https://arxiv.org/abs/2002.09797)\n\nMuhammad Ferjad Naeem <sup>1,3*</sup>, Seong Joon Oh<sup>2*</sup>, Yunjey Choi<sup>1</sup>, \nYoungjung Uh<sup>1</sup>, Jaejun Yoo<sup>1,4</sup>  \n\n<sub>**Work done at Clova AI Research**</sub>\n\n<sub>\\* Equal contribution</sub>\n<sup>1</sup> <sub>Clova AI Research, NAVER Corp.</sub>\n<sup>2</sup> <sub>Clova AI Research, LINE Plus Corp.</sub>\n<sup>3</sup> <sub>Technische Universit&auml;t M&uuml;nchen</sub>\n<sup>4</sup> <sub>EPFL</sub>\n\nDevising indicative evaluation metrics for the image generation task remains an open problem.\nThe most widely used metric for measuring the similarity between real and generated images has been the Fr&eacute;chet Inception Distance (FID) score. \nBecause it does not differentiate the _fidelity_ and _diversity_ aspects of the generated images, recent papers have introduced variants of precision and recall metrics to diagnose those properties separately.\nIn this paper, we show that even the latest version of the precision and recall (Kynk&auml;&auml;nniemi et al., 2019) metrics are not reliable yet. For example, they fail to detect the match between two identical distributions, they are not robust against outliers, and the evaluation hyperparameters are selected arbitrarily. We propose **density and coverage** metrics that solve the above issues. We analytically and experimentally show that density and coverage provide more interpretable and reliable signals for practitioners than the existing metrics.\n\n## 1. Background\n\n### Precision and recall metrics\n\nPrecision and recall are defined below:\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\fn_cm&space;\\text{precision}:=\\frac{1}{M}\\sum_{j=1}^{M}1_{Y_j\\in\\text{manifold}(X_1,\\cdots,X_N)}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\fn_cm&space;\\text{precision}:=\\frac{1}{M}\\sum_{j=1}^{M}1_{Y_j\\in\\text{manifold}(X_1,\\cdots,X_N)}\" title=\"\\text{precision}:=\\frac{1}{M}\\sum_{j=1}^{M}1_{Y_j\\in\\text{manifold}(X_1,\\cdots,X_N)}\" /></a>\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\fn_cm&space;\\text{recall}:=\\frac{1}{N}\\sum_{i=1}^{N}1_{X_i\\in\\text{manifold}(Y_1,\\cdots,Y_M)}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\fn_cm&space;\\text{recall}:=\\frac{1}{N}\\sum_{i=1}^{N}1_{X_i\\in\\text{manifold}(Y_1,\\cdots,Y_M)}\" title=\"\\text{recall}:=\\frac{1}{N}\\sum_{i=1}^{N}1_{X_i\\in\\text{manifold}(Y_1,\\cdots,Y_M)}\" /></a>\n\nwhere the manifold is the defined as\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\fn_cm&space;\\text{manifold}(X_1,\\cdots,X_N):=&space;\\bigcup_{i=1}^{N}&space;B(X_i,\\text{NND}_k(X_i))\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\fn_cm&space;\\text{manifold}(X_1,\\cdots,X_N):=&space;\\bigcup_{i=1}^{N}&space;B(X_i,\\text{NND}_k(X_i))\" title=\"\\text{manifold}(X_1,\\cdots,X_N):= \\bigcup_{i=1}^{N} B(X_i,\\text{NND}_k(X_i))\" /></a>\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\inline&space;\\fn_cm&space;B(x,r)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\inline&space;\\fn_cm&space;B(x,r)\" title=\"B(x,r)\" /></a> \nis the ball around the point `x` with radius `r`. \n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\inline&space;\\fn_cm&space;\\text{NND}_k(X_i)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\inline&space;\\fn_cm&space;\\text{NND}_k(X_i)\" title=\"\\text{NND}_k(X_i)\" /></a>\nis the distance to the kth-nearest neighbour. \n\n### Density and coverage metrics\n\nDensity and coverage are defined below:\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\fn_cm&space;\\text{density}:=\\frac{1}{kM}\\sum_{j=1}^{M}\\sum_{i=1}^{N}1_{Y_j\\in&space;B(X_i,\\text{NND}_k(X_i))}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\fn_cm&space;\\text{density}:=\\frac{1}{kM}\\sum_{j=1}^{M}\\sum_{i=1}^{N}1_{Y_j\\in&space;B(X_i,\\text{NND}_k(X_i))}\" title=\"\\text{density}:=\\frac{1}{kM}\\sum_{j=1}^{M}\\sum_{i=1}^{N}1_{Y_j\\in B(X_i,\\text{NND}_k(X_i))}\" /></a>\n\n<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\fn_cm&space;\\text{coverage}:=\\frac{1}{N}\\sum_{i=1}^{N}1_{\\exists\\text{&space;}j\\text{&space;s.t.&space;}&space;Y_j\\in&space;B(X_i,\\text{NND}_k(X_i))}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/svg.latex?\\fn_cm&space;\\text{coverage}:=\\frac{1}{N}\\sum_{i=1}^{N}1_{\\exists\\text{&space;}j\\text{&space;s.t.&space;}&space;Y_j\\in&space;B(X_i,\\text{NND}_k(X_i))}\" title=\"\\text{coverage}:=\\frac{1}{N}\\sum_{i=1}^{N}1_{\\exists\\text{ }j\\text{ s.t. } Y_j\\in B(X_i,\\text{NND}_k(X_i))}\" /></a>\n\n\n### Why are DC better than PR?\n\n<p align=\"center\">\n  <img src=\"https://github.com/clovaai/prdc/blob/master/figure/p_vs_d.png?raw=true\" alt=\"Precision versus density.\" width=\"500\"/>\n</p>\n\n**Precision versus Density.** \nBecause of the real outlier sample, the manifold is overestimated. Generating many fake samples around the real outlier is enough to increase the precision measure. \nThe problem of overestimating precision (100%) is resolved using the density estimate (60%). \n\n<p align=\"center\">\n  <img src=\"https://github.com/clovaai/prdc/blob/master/figure/r_vs_c.png?raw=true\" alt=\"Recall versus coverage.\" width=\"600\"/>\n</p>\n\n**Recall versus Coverage.** \nThe real and fake samples are identical across left and right.\nSince models often generate many unrealistic yet diverse samples, the fake manifold is often an overestimation of the true fake distribution. \nIn the figure above, while the fake samples are generally far from the modes in real samples, the recall measure is rewarded by the fact that real samples are contained in the overestimated fake manifold.\n\n\n## 2. Usage\n\n### Installation\n\n```bash\npip3 install prdc\n```\n\n### Example\n\nTest 10000 real and fake samples form the standard normal distribution N(0,I) in 1000-dimensional Euclidean space.\nSet the nearest neighbour `k=5`. We compute precision, recall, density, and coverage estimates below.\n\n```python\nimport numpy as np\nfrom prdc import compute_prdc\n\n\nnum_real_samples = num_fake_samples = 10000\nfeature_dim = 1000\nnearest_k = 5\nreal_features = np.random.normal(loc=0.0, scale=1.0,\n                                 size=[num_real_samples, feature_dim])\n\nfake_features = np.random.normal(loc=0.0, scale=1.0,\n                                 size=[num_fake_samples, feature_dim])\n\nmetrics = compute_prdc(real_features=real_features,\n                       fake_features=fake_features,\n                       nearest_k=nearest_k)\n\nprint(metrics)\n```\nAbove test code will result in the following estimates (may fluctuate due to randomness).\n```python\n{'precision': 0.4772,\n 'recall': 0.4705,\n 'density': 1.0555,\n 'coverage': 0.9735}\n```\n\n## 3. Miscellaneous\n\n### References\n\nKynk&auml;&auml;nniemi et al., 2019. Improved precision and recall metric for assessing generative models. Neurips 2019.\n\n### License\n\n```\nCopyright (c) 2020-present NAVER Corp.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n```\n\n### Cite this work\n\n```\n@article{ferjad2020ganeval,\ntitle = {Reliable Fidelity and Diversity Metrics for Generative Models},\nauthor = {Naeem, Muhammad Ferjad and Oh, Seong Joon and Uh, Youngjung and Choi, Yunjey and Yoo, Jaejun},\nyear = {2020},\njournal = {arXiv},\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/clovaai/prdc", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "prdc", "package_url": "https://pypi.org/project/prdc/", "platform": "", "project_url": "https://pypi.org/project/prdc/", "project_urls": {"Homepage": "https://github.com/clovaai/prdc"}, "release_url": "https://pypi.org/project/prdc/0.2/", "requires_dist": ["numpy", "scikit-learn", "scipy", "joblib"], "requires_python": "", "summary": "Compute precision, recall, density, and coverage metrics for two sets of vectors.", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h2>Reliable Fidelity and Diversity Metrics for Generative Models</h2>\n<p><a href=\"https://arxiv.org/abs/2002.09797\" rel=\"nofollow\">Paper: Reliable Fidelity and Diversity Metrics for Generative Models</a></p>\n<p>Muhammad Ferjad Naeem <sup>1,3*</sup>, Seong Joon Oh<sup>2*</sup>, Yunjey Choi<sup>1</sup>,\nYoungjung Uh<sup>1</sup>, Jaejun Yoo<sup>1,4</sup></p>\n<p><sub><strong>Work done at Clova AI Research</strong></sub></p>\n<p><sub>* Equal contribution</sub>\n<sup>1</sup> <sub>Clova AI Research, NAVER Corp.</sub>\n<sup>2</sup> <sub>Clova AI Research, LINE Plus Corp.</sub>\n<sup>3</sup> <sub>Technische Universit\u00e4t M\u00fcnchen</sub>\n<sup>4</sup> <sub>EPFL</sub></p>\n<p>Devising indicative evaluation metrics for the image generation task remains an open problem.\nThe most widely used metric for measuring the similarity between real and generated images has been the Fr\u00e9chet Inception Distance (FID) score.\nBecause it does not differentiate the <em>fidelity</em> and <em>diversity</em> aspects of the generated images, recent papers have introduced variants of precision and recall metrics to diagnose those properties separately.\nIn this paper, we show that even the latest version of the precision and recall (Kynk\u00e4\u00e4nniemi et al., 2019) metrics are not reliable yet. For example, they fail to detect the match between two identical distributions, they are not robust against outliers, and the evaluation hyperparameters are selected arbitrarily. We propose <strong>density and coverage</strong> metrics that solve the above issues. We analytically and experimentally show that density and coverage provide more interpretable and reliable signals for practitioners than the existing metrics.</p>\n<h2>1. Background</h2>\n<h3>Precision and recall metrics</h3>\n<p>Precision and recall are defined below:</p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cfn_cm&amp;space;%5Ctext%7Bprecision%7D:=%5Cfrac%7B1%7D%7BM%7D%5Csum_%7Bj=1%7D%5E%7BM%7D1_%7BY_j%5Cin%5Ctext%7Bmanifold%7D(X_1,%5Ccdots,X_N)%7D\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9c8838c21b5944f19956edf86df09994bf445ee6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c666e5f636d2673706163653b5c746578747b707265636973696f6e7d3a3d5c667261637b317d7b4d7d5c73756d5f7b6a3d317d5e7b4d7d315f7b595f6a5c696e5c746578747b6d616e69666f6c647d28585f312c5c63646f74732c585f4e297d\"></a></p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cfn_cm&amp;space;%5Ctext%7Brecall%7D:=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi=1%7D%5E%7BN%7D1_%7BX_i%5Cin%5Ctext%7Bmanifold%7D(Y_1,%5Ccdots,Y_M)%7D\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0a4a36bfa4a1641bfa898817850edb262e4005fd/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c666e5f636d2673706163653b5c746578747b726563616c6c7d3a3d5c667261637b317d7b4e7d5c73756d5f7b693d317d5e7b4e7d315f7b585f695c696e5c746578747b6d616e69666f6c647d28595f312c5c63646f74732c595f4d297d\"></a></p>\n<p>where the manifold is the defined as</p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cfn_cm&amp;space;%5Ctext%7Bmanifold%7D(X_1,%5Ccdots,X_N):=&amp;space;%5Cbigcup_%7Bi=1%7D%5E%7BN%7D&amp;space;B(X_i,%5Ctext%7BNND%7D_k(X_i))\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f213f4ef3a5243443e6e6b4bb9f08e73f3a0b282/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c666e5f636d2673706163653b5c746578747b6d616e69666f6c647d28585f312c5c63646f74732c585f4e293a3d2673706163653b5c6269676375705f7b693d317d5e7b4e7d2673706163653b4228585f692c5c746578747b4e4e447d5f6b28585f692929\"></a></p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cinline&amp;space;%5Cfn_cm&amp;space;B(x,r)\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d715ba55795b0ac20e4e64c1960f83c400f2c7f4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c696e6c696e652673706163653b5c666e5f636d2673706163653b4228782c7229\"></a>\nis the ball around the point <code>x</code> with radius <code>r</code>.</p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cinline&amp;space;%5Cfn_cm&amp;space;%5Ctext%7BNND%7D_k(X_i)\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d817cb641a9b2d65e72b7b641a84165622ffee07/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c696e6c696e652673706163653b5c666e5f636d2673706163653b5c746578747b4e4e447d5f6b28585f6929\"></a>\nis the distance to the kth-nearest neighbour.</p>\n<h3>Density and coverage metrics</h3>\n<p>Density and coverage are defined below:</p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cfn_cm&amp;space;%5Ctext%7Bdensity%7D:=%5Cfrac%7B1%7D%7BkM%7D%5Csum_%7Bj=1%7D%5E%7BM%7D%5Csum_%7Bi=1%7D%5E%7BN%7D1_%7BY_j%5Cin&amp;space;B(X_i,%5Ctext%7BNND%7D_k(X_i))%7D\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8e0c57b497f1916ca0d4c9bc810be5ed9e8e813f/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c666e5f636d2673706163653b5c746578747b64656e736974797d3a3d5c667261637b317d7b6b4d7d5c73756d5f7b6a3d317d5e7b4d7d5c73756d5f7b693d317d5e7b4e7d315f7b595f6a5c696e2673706163653b4228585f692c5c746578747b4e4e447d5f6b28585f6929297d\"></a></p>\n<p><a href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cfn_cm&amp;space;%5Ctext%7Bcoverage%7D:=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi=1%7D%5E%7BN%7D1_%7B%5Cexists%5Ctext%7B&amp;space;%7Dj%5Ctext%7B&amp;space;s.t.&amp;space;%7D&amp;space;Y_j%5Cin&amp;space;B(X_i,%5Ctext%7BNND%7D_k(X_i))%7D\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8542734bcb1cffe3838d9509c7356ba62ada60bc/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f5c666e5f636d2673706163653b5c746578747b636f7665726167657d3a3d5c667261637b317d7b4e7d5c73756d5f7b693d317d5e7b4e7d315f7b5c6578697374735c746578747b2673706163653b7d6a5c746578747b2673706163653b732e742e2673706163653b7d2673706163653b595f6a5c696e2673706163653b4228585f692c5c746578747b4e4e447d5f6b28585f6929297d\"></a></p>\n<h3>Why are DC better than PR?</h3>\n<p align=\"center\">\n  <img alt=\"Precision versus density.\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/26c4996115584461992b05257107eafaec8e72fe/68747470733a2f2f6769746875622e636f6d2f636c6f766161692f707264632f626c6f622f6d61737465722f6669677572652f705f76735f642e706e673f7261773d74727565\" width=\"500\">\n</p>\n<p><strong>Precision versus Density.</strong>\nBecause of the real outlier sample, the manifold is overestimated. Generating many fake samples around the real outlier is enough to increase the precision measure.\nThe problem of overestimating precision (100%) is resolved using the density estimate (60%).</p>\n<p align=\"center\">\n  <img alt=\"Recall versus coverage.\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/38bd733514c2467ddb0f59511fc52b1c79db5acb/68747470733a2f2f6769746875622e636f6d2f636c6f766161692f707264632f626c6f622f6d61737465722f6669677572652f725f76735f632e706e673f7261773d74727565\" width=\"600\">\n</p>\n<p><strong>Recall versus Coverage.</strong>\nThe real and fake samples are identical across left and right.\nSince models often generate many unrealistic yet diverse samples, the fake manifold is often an overestimation of the true fake distribution.\nIn the figure above, while the fake samples are generally far from the modes in real samples, the recall measure is rewarded by the fact that real samples are contained in the overestimated fake manifold.</p>\n<h2>2. Usage</h2>\n<h3>Installation</h3>\n<pre>pip3 install prdc\n</pre>\n<h3>Example</h3>\n<p>Test 10000 real and fake samples form the standard normal distribution N(0,I) in 1000-dimensional Euclidean space.\nSet the nearest neighbour <code>k=5</code>. We compute precision, recall, density, and coverage estimates below.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">prdc</span> <span class=\"kn\">import</span> <span class=\"n\">compute_prdc</span>\n\n\n<span class=\"n\">num_real_samples</span> <span class=\"o\">=</span> <span class=\"n\">num_fake_samples</span> <span class=\"o\">=</span> <span class=\"mi\">10000</span>\n<span class=\"n\">feature_dim</span> <span class=\"o\">=</span> <span class=\"mi\">1000</span>\n<span class=\"n\">nearest_k</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n<span class=\"n\">real_features</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span>\n                                 <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">num_real_samples</span><span class=\"p\">,</span> <span class=\"n\">feature_dim</span><span class=\"p\">])</span>\n\n<span class=\"n\">fake_features</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">,</span>\n                                 <span class=\"n\">size</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">num_fake_samples</span><span class=\"p\">,</span> <span class=\"n\">feature_dim</span><span class=\"p\">])</span>\n\n<span class=\"n\">metrics</span> <span class=\"o\">=</span> <span class=\"n\">compute_prdc</span><span class=\"p\">(</span><span class=\"n\">real_features</span><span class=\"o\">=</span><span class=\"n\">real_features</span><span class=\"p\">,</span>\n                       <span class=\"n\">fake_features</span><span class=\"o\">=</span><span class=\"n\">fake_features</span><span class=\"p\">,</span>\n                       <span class=\"n\">nearest_k</span><span class=\"o\">=</span><span class=\"n\">nearest_k</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">metrics</span><span class=\"p\">)</span>\n</pre>\n<p>Above test code will result in the following estimates (may fluctuate due to randomness).</p>\n<pre><span class=\"p\">{</span><span class=\"s1\">'precision'</span><span class=\"p\">:</span> <span class=\"mf\">0.4772</span><span class=\"p\">,</span>\n <span class=\"s1\">'recall'</span><span class=\"p\">:</span> <span class=\"mf\">0.4705</span><span class=\"p\">,</span>\n <span class=\"s1\">'density'</span><span class=\"p\">:</span> <span class=\"mf\">1.0555</span><span class=\"p\">,</span>\n <span class=\"s1\">'coverage'</span><span class=\"p\">:</span> <span class=\"mf\">0.9735</span><span class=\"p\">}</span>\n</pre>\n<h2>3. Miscellaneous</h2>\n<h3>References</h3>\n<p>Kynk\u00e4\u00e4nniemi et al., 2019. Improved precision and recall metric for assessing generative models. Neurips 2019.</p>\n<h3>License</h3>\n<pre><code>Copyright (c) 2020-present NAVER Corp.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n</code></pre>\n<h3>Cite this work</h3>\n<pre><code>@article{ferjad2020ganeval,\ntitle = {Reliable Fidelity and Diversity Metrics for Generative Models},\nauthor = {Naeem, Muhammad Ferjad and Oh, Seong Joon and Uh, Youngjung and Choi, Yunjey and Yoo, Jaejun},\nyear = {2020},\njournal = {arXiv},\n}\n</code></pre>\n\n          </div>"}, "last_serial": 6694307, "releases": {"0.2": [{"comment_text": "", "digests": {"md5": "cc6e220a8d6cae4da5f6b0741bd026b8", "sha256": "570ae82fb57a0b0ea3e6a131354a61e23aca79716b77cb9917f3a98465b72120"}, "downloads": -1, "filename": "prdc-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "cc6e220a8d6cae4da5f6b0741bd026b8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5956, "upload_time": "2020-02-25T04:54:56", "upload_time_iso_8601": "2020-02-25T04:54:56.835044Z", "url": "https://files.pythonhosted.org/packages/53/9b/e4731da221e9d502fb4e7531787d9b24d1791ff86a0d207dd2505ff485fc/prdc-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "19ef2bab582b281db5f758c18522b6a8", "sha256": "247466c31743f334a2714dbd60ef62e523877c4162ddb7dc63a404cada09316f"}, "downloads": -1, "filename": "prdc-0.2.tar.gz", "has_sig": false, "md5_digest": "19ef2bab582b281db5f758c18522b6a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5253, "upload_time": "2020-02-25T04:54:58", "upload_time_iso_8601": "2020-02-25T04:54:58.478249Z", "url": "https://files.pythonhosted.org/packages/16/3f/85c603c872ca28c870f1bd54bbe7020f5921efc1c04a9db32b75cf0c287c/prdc-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "cc6e220a8d6cae4da5f6b0741bd026b8", "sha256": "570ae82fb57a0b0ea3e6a131354a61e23aca79716b77cb9917f3a98465b72120"}, "downloads": -1, "filename": "prdc-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "cc6e220a8d6cae4da5f6b0741bd026b8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5956, "upload_time": "2020-02-25T04:54:56", "upload_time_iso_8601": "2020-02-25T04:54:56.835044Z", "url": "https://files.pythonhosted.org/packages/53/9b/e4731da221e9d502fb4e7531787d9b24d1791ff86a0d207dd2505ff485fc/prdc-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "19ef2bab582b281db5f758c18522b6a8", "sha256": "247466c31743f334a2714dbd60ef62e523877c4162ddb7dc63a404cada09316f"}, "downloads": -1, "filename": "prdc-0.2.tar.gz", "has_sig": false, "md5_digest": "19ef2bab582b281db5f758c18522b6a8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5253, "upload_time": "2020-02-25T04:54:58", "upload_time_iso_8601": "2020-02-25T04:54:58.478249Z", "url": "https://files.pythonhosted.org/packages/16/3f/85c603c872ca28c870f1bd54bbe7020f5921efc1c04a9db32b75cf0c287c/prdc-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:20:07 2020"}