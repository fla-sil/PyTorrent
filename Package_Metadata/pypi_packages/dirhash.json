{"info": {"author": "Anders Huss", "author_email": "andhus@kth.se", "bugtrack_url": null, "classifiers": [], "description": "\n[![Build Status](https://travis-ci.com/andhus/dirhash-python.svg?branch=master)](https://travis-ci.com/andhus/dirhash-python)\n[![codecov](https://codecov.io/gh/andhus/dirhash-python/branch/master/graph/badge.svg)](https://codecov.io/gh/andhus/dirhash-python)\n\n# dirhash\nA lightweight python module and CLI for computing the hash of any\ndirectory based on its files' structure and content.\n- Supports all hashing algorithms of Python's built-in `hashlib` module.\n- Glob/wildcard (\".gitignore style\") path matching for expressive filtering of files to include/exclude.\n- Multiprocessing for up to [6x speed-up](#performance)\n\nThe hash is computed according to the [Dirhash Standard](https://github.com/andhus/dirhash), which is designed to allow for consistent and collision resistant generation/verification of directory hashes across implementations.\n\n## Installation\nFrom PyPI:\n```commandline\npip install dirhash\n```\nOr directly from source:\n```commandline\ngit clone git@github.com:andhus/dirhash-python.git\npip install dirhash/\n```\n\n## Usage\nPython module:\n```python\nfrom dirhash import dirhash\n\ndirpath = \"path/to/directory\"\ndir_md5 = dirhash(dirpath, \"md5\")\npyfiles_md5 = dirhash(dirpath, \"md5\", match=[\"*.py\"])\nno_hidden_sha1 = dirhash(dirpath, \"sha1\", ignore=[\".*\", \".*/\"])\n```\nCLI:\n```commandline\ndirhash path/to/directory -a md5\ndirhash path/to/directory -a md5 --match \"*.py\"\ndirhash path/to/directory -a sha1 --ignore \".*\"  \".*/\"\n```\n\n## Why?\nIf you (or your application) need to verify the integrity of a set of files as well\nas their name and location, you might find this useful. Use-cases range from \nverification of your image classification dataset (before spending GPU-$$$ on \ntraining your fancy Deep Learning model) to validation of generated files in\nregression-testing.\n\nThere isn't really a standard way of doing this. There are plenty of recipes out \nthere (see e.g. these SO-questions for [linux](https://stackoverflow.com/questions/545387/linux-compute-a-single-hash-for-a-given-folder-contents)\nand [python](https://stackoverflow.com/questions/24937495/how-can-i-calculate-a-hash-for-a-filesystem-directory-using-python))\nbut I couldn't find one that is properly tested (there are some gotcha:s to cover!) \nand documented with a compelling user interface. `dirhash` was created with this as \nthe goal.\n\n[checksumdir](https://github.com/cakepietoast/checksumdir) is another python \nmodule/tool with similar intent (that inspired this project) but it lacks much of the\nfunctionality offered here (most notably including file names/structure in the hash)\nand lacks tests.\n\n## Performance\nThe python `hashlib` implementation of common hashing algorithms are highly\noptimised. `dirhash` mainly parses the file tree, pipes data to `hashlib` and \ncombines the output. Reasonable measures have been taken to minimize the overhead \nand for common use-cases, the majority of time is spent reading data from disk \nand executing `hashlib` code.\n\nThe main effort to boost performance is support for multiprocessing, where the\nreading and hashing is parallelized over individual files.\n\nAs a reference, let's compare the performance of the `dirhash` [CLI](https://github.com/andhus/dirhash-python/blob/master/src/dirhash/cli.py) \nwith the shell command:\n\n`find path/to/folder -type f -print0 | sort -z | xargs -0 md5 | md5` \n\nwhich is the top answer for the SO-question: \n[Linux: compute a single hash for a given folder & contents?](https://stackoverflow.com/questions/545387/linux-compute-a-single-hash-for-a-given-folder-contents)\nResults for two test cases are shown below. Both have 1 GiB of random data: in \n\"flat_1k_1MB\", split into 1k files (1 MiB each) in a flat structure, and in \n\"nested_32k_32kB\", into 32k files (32 KiB each) spread over the 256 leaf directories \nin a binary tree of depth 8.\n\nImplementation      | Test Case       | Time (s) | Speed up\n------------------- | --------------- | -------: | -------:\nshell reference     | flat_1k_1MB     | 2.29     | -> 1.0\n`dirhash`           | flat_1k_1MB     | 1.67     | 1.36\n`dirhash`(8 workers)| flat_1k_1MB     | 0.48     | **4.73**\nshell reference     | nested_32k_32kB | 6.82     | -> 1.0\n`dirhash`           | nested_32k_32kB | 3.43     | 2.00\n`dirhash`(8 workers)| nested_32k_32kB | 1.14     | **6.00**\n\nThe benchmark was run a MacBook Pro (2018), further details and source code [here](https://github.com/andhus/dirhash-python/tree/master/benchmark).\n\n## Documentation\nPlease refer to `dirhash -h`, the python [source code](https://github.com/andhus/dirhash-python/blob/master/src/dirhash/__init__.py) and the [Dirhash Standard](https://github.com/andhus/dirhash).\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/andhus/dirhash-python", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dirhash", "package_url": "https://pypi.org/project/dirhash/", "platform": "", "project_url": "https://pypi.org/project/dirhash/", "project_urls": {"Homepage": "https://github.com/andhus/dirhash-python"}, "release_url": "https://pypi.org/project/dirhash/0.2.0/", "requires_dist": ["scantree (>=0.0.1)"], "requires_python": "", "summary": "Python module and CLI for hashing of file system directories.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://travis-ci.com/andhus/dirhash-python\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9212224c6b5549f98425d11acbea736df014c383/68747470733a2f2f7472617669732d63692e636f6d2f616e646875732f646972686173682d707974686f6e2e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/gh/andhus/dirhash-python\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1321fa3579c3f22d2be8cb42a1fc88fe96644841/68747470733a2f2f636f6465636f762e696f2f67682f616e646875732f646972686173682d707974686f6e2f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<h1>dirhash</h1>\n<p>A lightweight python module and CLI for computing the hash of any\ndirectory based on its files' structure and content.</p>\n<ul>\n<li>Supports all hashing algorithms of Python's built-in <code>hashlib</code> module.</li>\n<li>Glob/wildcard (\".gitignore style\") path matching for expressive filtering of files to include/exclude.</li>\n<li>Multiprocessing for up to <a href=\"#performance\" rel=\"nofollow\">6x speed-up</a></li>\n</ul>\n<p>The hash is computed according to the <a href=\"https://github.com/andhus/dirhash\" rel=\"nofollow\">Dirhash Standard</a>, which is designed to allow for consistent and collision resistant generation/verification of directory hashes across implementations.</p>\n<h2>Installation</h2>\n<p>From PyPI:</p>\n<pre>pip install dirhash\n</pre>\n<p>Or directly from source:</p>\n<pre>git clone git@github.com:andhus/dirhash-python.git\npip install dirhash/\n</pre>\n<h2>Usage</h2>\n<p>Python module:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">dirhash</span> <span class=\"kn\">import</span> <span class=\"n\">dirhash</span>\n\n<span class=\"n\">dirpath</span> <span class=\"o\">=</span> <span class=\"s2\">\"path/to/directory\"</span>\n<span class=\"n\">dir_md5</span> <span class=\"o\">=</span> <span class=\"n\">dirhash</span><span class=\"p\">(</span><span class=\"n\">dirpath</span><span class=\"p\">,</span> <span class=\"s2\">\"md5\"</span><span class=\"p\">)</span>\n<span class=\"n\">pyfiles_md5</span> <span class=\"o\">=</span> <span class=\"n\">dirhash</span><span class=\"p\">(</span><span class=\"n\">dirpath</span><span class=\"p\">,</span> <span class=\"s2\">\"md5\"</span><span class=\"p\">,</span> <span class=\"n\">match</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"*.py\"</span><span class=\"p\">])</span>\n<span class=\"n\">no_hidden_sha1</span> <span class=\"o\">=</span> <span class=\"n\">dirhash</span><span class=\"p\">(</span><span class=\"n\">dirpath</span><span class=\"p\">,</span> <span class=\"s2\">\"sha1\"</span><span class=\"p\">,</span> <span class=\"n\">ignore</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\".*\"</span><span class=\"p\">,</span> <span class=\"s2\">\".*/\"</span><span class=\"p\">])</span>\n</pre>\n<p>CLI:</p>\n<pre>dirhash path/to/directory -a md5\ndirhash path/to/directory -a md5 --match \"*.py\"\ndirhash path/to/directory -a sha1 --ignore \".*\"  \".*/\"\n</pre>\n<h2>Why?</h2>\n<p>If you (or your application) need to verify the integrity of a set of files as well\nas their name and location, you might find this useful. Use-cases range from\nverification of your image classification dataset (before spending GPU-$$$ on\ntraining your fancy Deep Learning model) to validation of generated files in\nregression-testing.</p>\n<p>There isn't really a standard way of doing this. There are plenty of recipes out\nthere (see e.g. these SO-questions for <a href=\"https://stackoverflow.com/questions/545387/linux-compute-a-single-hash-for-a-given-folder-contents\" rel=\"nofollow\">linux</a>\nand <a href=\"https://stackoverflow.com/questions/24937495/how-can-i-calculate-a-hash-for-a-filesystem-directory-using-python\" rel=\"nofollow\">python</a>)\nbut I couldn't find one that is properly tested (there are some gotcha:s to cover!)\nand documented with a compelling user interface. <code>dirhash</code> was created with this as\nthe goal.</p>\n<p><a href=\"https://github.com/cakepietoast/checksumdir\" rel=\"nofollow\">checksumdir</a> is another python\nmodule/tool with similar intent (that inspired this project) but it lacks much of the\nfunctionality offered here (most notably including file names/structure in the hash)\nand lacks tests.</p>\n<h2>Performance</h2>\n<p>The python <code>hashlib</code> implementation of common hashing algorithms are highly\noptimised. <code>dirhash</code> mainly parses the file tree, pipes data to <code>hashlib</code> and\ncombines the output. Reasonable measures have been taken to minimize the overhead\nand for common use-cases, the majority of time is spent reading data from disk\nand executing <code>hashlib</code> code.</p>\n<p>The main effort to boost performance is support for multiprocessing, where the\nreading and hashing is parallelized over individual files.</p>\n<p>As a reference, let's compare the performance of the <code>dirhash</code> <a href=\"https://github.com/andhus/dirhash-python/blob/master/src/dirhash/cli.py\" rel=\"nofollow\">CLI</a>\nwith the shell command:</p>\n<p><code>find path/to/folder -type f -print0 | sort -z | xargs -0 md5 | md5</code></p>\n<p>which is the top answer for the SO-question:\n<a href=\"https://stackoverflow.com/questions/545387/linux-compute-a-single-hash-for-a-given-folder-contents\" rel=\"nofollow\">Linux: compute a single hash for a given folder &amp; contents?</a>\nResults for two test cases are shown below. Both have 1 GiB of random data: in\n\"flat_1k_1MB\", split into 1k files (1 MiB each) in a flat structure, and in\n\"nested_32k_32kB\", into 32k files (32 KiB each) spread over the 256 leaf directories\nin a binary tree of depth 8.</p>\n<table>\n<thead>\n<tr>\n<th>Implementation</th>\n<th>Test Case</th>\n<th align=\"right\">Time (s)</th>\n<th align=\"right\">Speed up</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>shell reference</td>\n<td>flat_1k_1MB</td>\n<td align=\"right\">2.29</td>\n<td align=\"right\">-&gt; 1.0</td>\n</tr>\n<tr>\n<td><code>dirhash</code></td>\n<td>flat_1k_1MB</td>\n<td align=\"right\">1.67</td>\n<td align=\"right\">1.36</td>\n</tr>\n<tr>\n<td><code>dirhash</code>(8 workers)</td>\n<td>flat_1k_1MB</td>\n<td align=\"right\">0.48</td>\n<td align=\"right\"><strong>4.73</strong></td>\n</tr>\n<tr>\n<td>shell reference</td>\n<td>nested_32k_32kB</td>\n<td align=\"right\">6.82</td>\n<td align=\"right\">-&gt; 1.0</td>\n</tr>\n<tr>\n<td><code>dirhash</code></td>\n<td>nested_32k_32kB</td>\n<td align=\"right\">3.43</td>\n<td align=\"right\">2.00</td>\n</tr>\n<tr>\n<td><code>dirhash</code>(8 workers)</td>\n<td>nested_32k_32kB</td>\n<td align=\"right\">1.14</td>\n<td align=\"right\"><strong>6.00</strong></td>\n</tr></tbody></table>\n<p>The benchmark was run a MacBook Pro (2018), further details and source code <a href=\"https://github.com/andhus/dirhash-python/tree/master/benchmark\" rel=\"nofollow\">here</a>.</p>\n<h2>Documentation</h2>\n<p>Please refer to <code>dirhash -h</code>, the python <a href=\"https://github.com/andhus/dirhash-python/blob/master/src/dirhash/__init__.py\" rel=\"nofollow\">source code</a> and the <a href=\"https://github.com/andhus/dirhash\" rel=\"nofollow\">Dirhash Standard</a>.</p>\n\n          </div>"}, "last_serial": 7104688, "releases": {"0.1.1": [{"comment_text": "", "digests": {"md5": "f29a18f60abe9676db50ee87ea7f6159", "sha256": "dc88718f06dd7f6c3bb4fdfd1567ae161af152aecb0a74dae28fbfe726166ec3"}, "downloads": -1, "filename": "dirhash-0.1.1.tar.gz", "has_sig": false, "md5_digest": "f29a18f60abe9676db50ee87ea7f6159", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13390, "upload_time": "2019-02-15T06:25:21", "upload_time_iso_8601": "2019-02-15T06:25:21.935756Z", "url": "https://files.pythonhosted.org/packages/e3/7f/7b41eb6b6c9695569bdeaff2bdeab3fa70b6df03f6b6ae016ca8c8370ee5/dirhash-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "9c6846ded01bed1bcb9eefdf59c0465a", "sha256": "e06d1e5a3459fd32061339f33e32682eee9bcd49554afaa19436121efe738693"}, "downloads": -1, "filename": "dirhash-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9c6846ded01bed1bcb9eefdf59c0465a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12749, "upload_time": "2020-04-26T12:09:57", "upload_time_iso_8601": "2020-04-26T12:09:57.418027Z", "url": "https://files.pythonhosted.org/packages/e0/ed/f4d8e1d97100c625808505b130932de787d8269d94b5aa34a52f8c43fed0/dirhash-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fbfee2d939edf0ad07735e7a36a87270", "sha256": "ec5129ee5d71ac6d605c29b17a8cc440ff7a7d569fb085e864ee427a422f4e9d"}, "downloads": -1, "filename": "dirhash-0.2.0.tar.gz", "has_sig": false, "md5_digest": "fbfee2d939edf0ad07735e7a36a87270", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13759, "upload_time": "2020-04-26T12:09:58", "upload_time_iso_8601": "2020-04-26T12:09:58.541044Z", "url": "https://files.pythonhosted.org/packages/c8/c1/0e4b7b7380a1bcb0597b0d9a9bbdc53f1c9ad1fe6b7c871ae5482600d264/dirhash-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9c6846ded01bed1bcb9eefdf59c0465a", "sha256": "e06d1e5a3459fd32061339f33e32682eee9bcd49554afaa19436121efe738693"}, "downloads": -1, "filename": "dirhash-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9c6846ded01bed1bcb9eefdf59c0465a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12749, "upload_time": "2020-04-26T12:09:57", "upload_time_iso_8601": "2020-04-26T12:09:57.418027Z", "url": "https://files.pythonhosted.org/packages/e0/ed/f4d8e1d97100c625808505b130932de787d8269d94b5aa34a52f8c43fed0/dirhash-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fbfee2d939edf0ad07735e7a36a87270", "sha256": "ec5129ee5d71ac6d605c29b17a8cc440ff7a7d569fb085e864ee427a422f4e9d"}, "downloads": -1, "filename": "dirhash-0.2.0.tar.gz", "has_sig": false, "md5_digest": "fbfee2d939edf0ad07735e7a36a87270", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13759, "upload_time": "2020-04-26T12:09:58", "upload_time_iso_8601": "2020-04-26T12:09:58.541044Z", "url": "https://files.pythonhosted.org/packages/c8/c1/0e4b7b7380a1bcb0597b0d9a9bbdc53f1c9ad1fe6b7c871ae5482600d264/dirhash-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:38:16 2020"}