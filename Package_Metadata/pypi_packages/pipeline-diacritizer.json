{"info": {"author": "Hamza Abbad", "author_email": "hamza.abbad@whut.edu.cn", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Text Processing :: Linguistic"], "description": "# Multi-components system for automatic Arabic diacritics restoration\n\n## About\n\nThis tool is a command-line application written in Python 3 that automatically add diacritics to\nraw undiacritized Arabic text. To accomplish this task, it uses several techniques: Deep Learning, rule-based and\nstatistical corrections. The deep learning part was implemented using Tensorflow. It was released as a support for the\nresearch paper:\n[\"Multi-components system for automatic Arabic diacritization\" at ECIR2020](https://ecir2020.org/accepted-papers/).\n\n## Installation\n\nThis tool is available as a Python 3 package `pipeline-diacritizer` installable through `pip`. For installation\ninstructions check the\n[**Download and installation** wiki page](https://github.com/Hamza5/Pipeline-diacritizer/wiki/Download-and-installation). \n\n## Functions\n\nThis tool has 4 main functions: preprocessing of the data, training on the processed data, testing, and\nrestoring the diacritics of an undiacritized text. In addition, it can calculates some statistics on a given dataset and\nthe ratio of Out-of-Vocabulary words in a testing set according to a train set. \n\nThis is a quick introduction to the most important ones, without mentioning all the possible options for each one. For\nadditional options, consider calling any subcommand with the option `--help` or `-h` (ex:\n`pipeline_diacritizer train --help`) or [check the wiki](https://github.com/Hamza5/Pipeline-diacritizer/wiki)\nfor more details.\n\n### Preprocessing\n\nBefore feeding the new data to this application for training or testing, it needs to be converted to the standard format\nof this application: one sentence per line, where a sentence is delimited by a dot, a comma, or an end of line\ncharacter.\n\n```\n$ pipeline_diacritizer process <source_file> <destination_file>\n```\n\nIf the data is not yet partitioned into training, validation and testing sets, the program can help in this task using\nthe following command:\n\n```\n$ pipeline_diacritizer partition <dataset_file>\n```\n\n### Training\n\nTo run the training and validation on selected training/validation sets, use the next command:\n\n```\n$ pipeline_diacritizer train --train-data <train_file> --val-data <val_file>\n```\n\n### Testing\n\nTo evaluate the performances of the application on a testing set, use this command:\n\n```\n$ pipeline_diacritizer test <test_file>\n```\n\n### Diacritization\n\nThe following command restores the diacritics of the Arabic words from the supplied text file and outputs a diacritized\ncopy:\n\n```\n$ pipeline_diacritizer diacritize <text_file>\n```\n\n### Statistics\n\nTo get some statistics about the dataset, such as the count of tokens, arabic words, numbers... use the following\ncommand:\n\n```\n$ pipeline_diacritizer stat <dataset_file>\n``` \n\n### OoV Counting\n\nTo calculate the ratio of the Out-of-Vocabulary words between the train set and the validation/test set, use the next\ncommand:\n\n```\n$ pipeline_diacritizer oov <train_file> <test_file>\n```\n\n## License\n\nPipeline-diacritizer code is licensed under\n[MIT License](https://github.com/Hamza5/Pipeline-diacritizer/blob/master/LICENSE.txt).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Hamza5/Pipeline-diacritizer", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pipeline-diacritizer", "package_url": "https://pypi.org/project/pipeline-diacritizer/", "platform": "", "project_url": "https://pypi.org/project/pipeline-diacritizer/", "project_urls": {"Homepage": "https://github.com/Hamza5/Pipeline-diacritizer"}, "release_url": "https://pypi.org/project/pipeline-diacritizer/1.0.2/", "requires_dist": ["tensorflow (<=1.14.0,>=1.11.0)", "numpy (<=1.16.5,>=1.13.0)"], "requires_python": ">=3.4,<3.8", "summary": "Command-line application to automatically restore the diacritics of an Arabic text.", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Multi-components system for automatic Arabic diacritics restoration</h1>\n<h2>About</h2>\n<p>This tool is a command-line application written in Python 3 that automatically add diacritics to\nraw undiacritized Arabic text. To accomplish this task, it uses several techniques: Deep Learning, rule-based and\nstatistical corrections. The deep learning part was implemented using Tensorflow. It was released as a support for the\nresearch paper:\n<a href=\"https://ecir2020.org/accepted-papers/\" rel=\"nofollow\">\"Multi-components system for automatic Arabic diacritization\" at ECIR2020</a>.</p>\n<h2>Installation</h2>\n<p>This tool is available as a Python 3 package <code>pipeline-diacritizer</code> installable through <code>pip</code>. For installation\ninstructions check the\n<a href=\"https://github.com/Hamza5/Pipeline-diacritizer/wiki/Download-and-installation\" rel=\"nofollow\"><strong>Download and installation</strong> wiki page</a>.</p>\n<h2>Functions</h2>\n<p>This tool has 4 main functions: preprocessing of the data, training on the processed data, testing, and\nrestoring the diacritics of an undiacritized text. In addition, it can calculates some statistics on a given dataset and\nthe ratio of Out-of-Vocabulary words in a testing set according to a train set.</p>\n<p>This is a quick introduction to the most important ones, without mentioning all the possible options for each one. For\nadditional options, consider calling any subcommand with the option <code>--help</code> or <code>-h</code> (ex:\n<code>pipeline_diacritizer train --help</code>) or <a href=\"https://github.com/Hamza5/Pipeline-diacritizer/wiki\" rel=\"nofollow\">check the wiki</a>\nfor more details.</p>\n<h3>Preprocessing</h3>\n<p>Before feeding the new data to this application for training or testing, it needs to be converted to the standard format\nof this application: one sentence per line, where a sentence is delimited by a dot, a comma, or an end of line\ncharacter.</p>\n<pre><code>$ pipeline_diacritizer process &lt;source_file&gt; &lt;destination_file&gt;\n</code></pre>\n<p>If the data is not yet partitioned into training, validation and testing sets, the program can help in this task using\nthe following command:</p>\n<pre><code>$ pipeline_diacritizer partition &lt;dataset_file&gt;\n</code></pre>\n<h3>Training</h3>\n<p>To run the training and validation on selected training/validation sets, use the next command:</p>\n<pre><code>$ pipeline_diacritizer train --train-data &lt;train_file&gt; --val-data &lt;val_file&gt;\n</code></pre>\n<h3>Testing</h3>\n<p>To evaluate the performances of the application on a testing set, use this command:</p>\n<pre><code>$ pipeline_diacritizer test &lt;test_file&gt;\n</code></pre>\n<h3>Diacritization</h3>\n<p>The following command restores the diacritics of the Arabic words from the supplied text file and outputs a diacritized\ncopy:</p>\n<pre><code>$ pipeline_diacritizer diacritize &lt;text_file&gt;\n</code></pre>\n<h3>Statistics</h3>\n<p>To get some statistics about the dataset, such as the count of tokens, arabic words, numbers... use the following\ncommand:</p>\n<pre><code>$ pipeline_diacritizer stat &lt;dataset_file&gt;\n</code></pre>\n<h3>OoV Counting</h3>\n<p>To calculate the ratio of the Out-of-Vocabulary words between the train set and the validation/test set, use the next\ncommand:</p>\n<pre><code>$ pipeline_diacritizer oov &lt;train_file&gt; &lt;test_file&gt;\n</code></pre>\n<h2>License</h2>\n<p>Pipeline-diacritizer code is licensed under\n<a href=\"https://github.com/Hamza5/Pipeline-diacritizer/blob/master/LICENSE.txt\" rel=\"nofollow\">MIT License</a>.</p>\n\n          </div>"}, "last_serial": 6493344, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "940af0e57618cc66e8a08375a439f76f", "sha256": "3a8d9e7fca72240915601d096b459704a527ed2246a2a72f5c44e5e1eae4dd4d"}, "downloads": -1, "filename": "pipeline_diacritizer-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "940af0e57618cc66e8a08375a439f76f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4,<3.8", "size": 18563, "upload_time": "2020-01-21T10:37:49", "upload_time_iso_8601": "2020-01-21T10:37:49.093617Z", "url": "https://files.pythonhosted.org/packages/87/e1/385a48f11b02345d9942d90693594e446a183898e6da39ff65799bc909ac/pipeline_diacritizer-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "852739f6ca0c8ac7955f9af65dea8f09", "sha256": "03e2cfff69efafc86363e9eb14de6086e400ce3c7e54c29747e6c9440adfa525"}, "downloads": -1, "filename": "pipeline_diacritizer-1.0.1.tar.gz", "has_sig": false, "md5_digest": "852739f6ca0c8ac7955f9af65dea8f09", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4,<3.8", "size": 17495, "upload_time": "2020-01-21T10:37:51", "upload_time_iso_8601": "2020-01-21T10:37:51.921839Z", "url": "https://files.pythonhosted.org/packages/70/f3/b5bc90f27ac472ff105445d9eb441eff1b7fb4172700a8e2a718eb9c8e01/pipeline_diacritizer-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "30a27f1e710888ad24592bd9f2299dce", "sha256": "16e12358ba8fa0c4c54da4450abe179eec2114ea8147c477d6ad4629421122d4"}, "downloads": -1, "filename": "pipeline_diacritizer-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "30a27f1e710888ad24592bd9f2299dce", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4,<3.8", "size": 18554, "upload_time": "2020-01-21T10:48:15", "upload_time_iso_8601": "2020-01-21T10:48:15.234239Z", "url": "https://files.pythonhosted.org/packages/17/d6/4d519521a0195827b63eecda67a077713f814606c0f6caa759fcb76c9d21/pipeline_diacritizer-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "df9a64b6b3252072e2c606684d17388e", "sha256": "1cb39f488aa0c383d1e2b2a9ee6f9a908295bdda3fcf10e9fd72cf7d226ee238"}, "downloads": -1, "filename": "pipeline_diacritizer-1.0.2.tar.gz", "has_sig": false, "md5_digest": "df9a64b6b3252072e2c606684d17388e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4,<3.8", "size": 17483, "upload_time": "2020-01-21T10:48:17", "upload_time_iso_8601": "2020-01-21T10:48:17.416730Z", "url": "https://files.pythonhosted.org/packages/79/e6/3a539d9e13b69a063d753f60670a2eb2f2a860c89038051e9402bb98831d/pipeline_diacritizer-1.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "30a27f1e710888ad24592bd9f2299dce", "sha256": "16e12358ba8fa0c4c54da4450abe179eec2114ea8147c477d6ad4629421122d4"}, "downloads": -1, "filename": "pipeline_diacritizer-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "30a27f1e710888ad24592bd9f2299dce", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.4,<3.8", "size": 18554, "upload_time": "2020-01-21T10:48:15", "upload_time_iso_8601": "2020-01-21T10:48:15.234239Z", "url": "https://files.pythonhosted.org/packages/17/d6/4d519521a0195827b63eecda67a077713f814606c0f6caa759fcb76c9d21/pipeline_diacritizer-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "df9a64b6b3252072e2c606684d17388e", "sha256": "1cb39f488aa0c383d1e2b2a9ee6f9a908295bdda3fcf10e9fd72cf7d226ee238"}, "downloads": -1, "filename": "pipeline_diacritizer-1.0.2.tar.gz", "has_sig": false, "md5_digest": "df9a64b6b3252072e2c606684d17388e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4,<3.8", "size": 17483, "upload_time": "2020-01-21T10:48:17", "upload_time_iso_8601": "2020-01-21T10:48:17.416730Z", "url": "https://files.pythonhosted.org/packages/79/e6/3a539d9e13b69a063d753f60670a2eb2f2a860c89038051e9402bb98831d/pipeline_diacritizer-1.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:20 2020"}