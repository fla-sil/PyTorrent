{"info": {"author": "Kaung Htet San", "author_email": "kaung@htetsan.me", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Pyidaungsu\n\nPython library for Myanmar language. Useful in Natural Language Processing and text preprocessing for Myanmar language.\n\n## Installation\n\n```sh\npip install pyidaungsu\n```\n\n## Usage\n\n### Zawgyi-Unicode detection\n\n```sh\nimport pyidaungsu as pds\n\n# font encoding detection\npds.detect(\"\u1011\u1019\u1004\u103a\u1038\u1005\u102c\u1038\u1015\u103c\u102e\u1038\u1015\u103c\u102e\u101c\u102c\u1038\")\n>> \"Unicode\"\n```\n\n### Zawgyi-Unicode conversion\n\n```sh\n# convert to zawgyi\npds.cvt2zgi(\"\u1011\u1019\u1004\u103a\u1038\u1005\u102c\u1038\u1015\u103c\u102e\u1038\u1015\u103c\u102e\u101c\u102c\u1038\")\n>> \"\u1011\u1019\u1004\u1039\u1038\u1005\u102c\u1038\u107f\u1015\u102e\u1038\u107f\u1015\u102e\u101c\u102c\u1038\"\n\n# convert to unicode\npds.cvt2uni(\"\u1011\u1019\u1004\u1039\u1038\u1005\u102c\u1038\u107f\u1015\u102e\u1038\u107f\u1015\u102e\u101c\u102c\u1038\")\n>> \"\u1011\u1019\u1004\u103a\u1038\u1005\u102c\u1038\u1015\u103c\u102e\u1038\u1015\u103c\u102e\u101c\u102c\u1038\"\n```\n\n### Tokenization\n\n```sh\n# syllable level tokenization for Burmese\npds.tokenize(\"Alan Turing\u1000\u102d\u102fArtificial Intelligence\u1014\u1032\u1037Computer\u1010\u103d\u1031\u101b\u1032\u1037\u1016\u1001\u1004\u103a\u1006\u102d\u102f\u1015\u103c\u102e\u1038\u101c\u1030\u101e\u102d\u1019\u103b\u102c\u1038\u1015\u102b\u1010\u101a\u103a\") # lang parameter for default function is 'mm'\n>> ['Alan', 'Turing', '\u1000\u102d\u102f', 'Artificial', 'Intelligence', '\u1014\u1032\u1037', 'Computer', '\u1010\u103d\u1031', '\u101b\u1032\u1037', '\u1016', '\u1001\u1004\u103a', '\u1006\u102d\u102f', '\u1015\u103c\u102e\u1038', '\u101c\u1030', '\u101e\u102d', '\u1019\u103b\u102c\u1038', '\u1015\u102b', '\u1010\u101a\u103a']\n\n# syllable level tokenization for Karen\npds.tokenize(\"\u101e\u101b\u1063\u103a,\u101e\u101b\u1063\u103a\u1019\u102f\u1063\u103a \u1001\u1032\u101c\u1062\u102c\u103a\u101f\u1038\u1011\u102e\u1063\u103a (\u1043\u1045) \u1002\u1064\u1014\u1037\u1063\u103a\u101c\u102e\u1064.\", lang=\"karen\")\n>> ['\u1000\u1060\u102d', '\u101e', '\u101b\u1063\u103a', ',', '\u101e', '\u101b\u1063\u103a', '\u1019\u102f\u1063\u103a', '\u1001\u1032', '\u101c\u1062\u102c\u103a', '\u101f\u1038', '\u1011\u102e\u1063\u103a', '(', '\u1043\u1045', ')', '\u1002\u1064', '\u1014\u1037\u1063\u103a', '\u101c\u102e\u1064', '.']\n\n# word level tokenization\npds.tokenize(\"\u1016\u1031\u1016\u1031\u1014\u1032\u1037\u1019\u1031\u1019\u1031\u104f\u1000\u103b\u1031\u1038\u1007\u1030\u1038\u1010\u101b\u102c\u1038\u1019\u103e\u102c\u1000\u103c\u102e\u1038\u1019\u102c\u1038\u101c\u103e\u1015\u1031\u101e\u100a\u103a\", form=\"word\")\n>> ['\u1016\u1031\u1016\u1031', '\u1014\u1032\u1037', '\u1019\u1031\u1019\u1031', '\u104f', '\u1000\u103b\u1031\u1038\u1007\u1030\u1038\u1010\u101b\u102c\u1038', '\u1019\u103e\u102c', '\u1000\u103c\u102e\u1038\u1019\u102c\u1038', '\u101c\u103e', '\u1015\u1031', '\u101e\u100a\u103a']\n\n```\n\nSyllable-level tokenization supports for 4 languages (Burmese, Karen, Shan, Mon). Word-level tokenization supports only Burmese currently.</br>\nAvailable values for `lang` parameter in `tokenize` function: \"mm\", \"karen\", \"mon\", \"shan\"\n\n## Future work\n\n- [x] Add tokenizer for Burmese (Syllabel and word-level tokenization)\n- [ ] Add more tokenizer (BPE, WordPiece etc.)\n- [ ] Add Part-of-Speech (POS) tagger for Burmese\n- [ ] Add Named-entities Recognition (NER) classifier for Burmese\n- [ ] Add thorough documentation", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/kaunghtetsan275/pyidaungsu/archive/0.0.8.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/kaunghtetsan275/pyidaungsu", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pyidaungsu", "package_url": "https://pypi.org/project/pyidaungsu/", "platform": "", "project_url": "https://pypi.org/project/pyidaungsu/", "project_urls": {"Download": "https://github.com/kaunghtetsan275/pyidaungsu/archive/0.0.8.tar.gz", "Homepage": "https://github.com/kaunghtetsan275/pyidaungsu"}, "release_url": "https://pypi.org/project/pyidaungsu/0.0.8/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Python library for Myanmar language", "version": "0.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pyidaungsu</h1>\n<p>Python library for Myanmar language. Useful in Natural Language Processing and text preprocessing for Myanmar language.</p>\n<h2>Installation</h2>\n<pre>pip install pyidaungsu\n</pre>\n<h2>Usage</h2>\n<h3>Zawgyi-Unicode detection</h3>\n<pre>import pyidaungsu as pds\n\n<span class=\"c1\"># font encoding detection</span>\npds.detect<span class=\"o\">(</span><span class=\"s2\">\"\u1011\u1019\u1004\u103a\u1038\u1005\u102c\u1038\u1015\u103c\u102e\u1038\u1015\u103c\u102e\u101c\u102c\u1038\"</span><span class=\"o\">)</span>\n&gt;&gt; <span class=\"s2\">\"Unicode\"</span>\n</pre>\n<h3>Zawgyi-Unicode conversion</h3>\n<pre><span class=\"c1\"># convert to zawgyi</span>\npds.cvt2zgi<span class=\"o\">(</span><span class=\"s2\">\"\u1011\u1019\u1004\u103a\u1038\u1005\u102c\u1038\u1015\u103c\u102e\u1038\u1015\u103c\u102e\u101c\u102c\u1038\"</span><span class=\"o\">)</span>\n&gt;&gt; <span class=\"s2\">\"\u1011\u1019\u1004\u1039\u1038\u1005\u102c\u1038\u107f\u1015\u102e\u1038\u107f\u1015\u102e\u101c\u102c\u1038\"</span>\n\n<span class=\"c1\"># convert to unicode</span>\npds.cvt2uni<span class=\"o\">(</span><span class=\"s2\">\"\u1011\u1019\u1004\u1039\u1038\u1005\u102c\u1038\u107f\u1015\u102e\u1038\u107f\u1015\u102e\u101c\u102c\u1038\"</span><span class=\"o\">)</span>\n&gt;&gt; <span class=\"s2\">\"\u1011\u1019\u1004\u103a\u1038\u1005\u102c\u1038\u1015\u103c\u102e\u1038\u1015\u103c\u102e\u101c\u102c\u1038\"</span>\n</pre>\n<h3>Tokenization</h3>\n<pre><span class=\"c1\"># syllable level tokenization for Burmese</span>\npds.tokenize<span class=\"o\">(</span><span class=\"s2\">\"Alan Turing\u1000\u102d\u102fArtificial Intelligence\u1014\u1032\u1037Computer\u1010\u103d\u1031\u101b\u1032\u1037\u1016\u1001\u1004\u103a\u1006\u102d\u102f\u1015\u103c\u102e\u1038\u101c\u1030\u101e\u102d\u1019\u103b\u102c\u1038\u1015\u102b\u1010\u101a\u103a\"</span><span class=\"o\">)</span> <span class=\"c1\"># lang parameter for default function is 'mm'</span>\n&gt;&gt; <span class=\"o\">[</span><span class=\"s1\">'Alan'</span>, <span class=\"s1\">'Turing'</span>, <span class=\"s1\">'\u1000\u102d\u102f'</span>, <span class=\"s1\">'Artificial'</span>, <span class=\"s1\">'Intelligence'</span>, <span class=\"s1\">'\u1014\u1032\u1037'</span>, <span class=\"s1\">'Computer'</span>, <span class=\"s1\">'\u1010\u103d\u1031'</span>, <span class=\"s1\">'\u101b\u1032\u1037'</span>, <span class=\"s1\">'\u1016'</span>, <span class=\"s1\">'\u1001\u1004\u103a'</span>, <span class=\"s1\">'\u1006\u102d\u102f'</span>, <span class=\"s1\">'\u1015\u103c\u102e\u1038'</span>, <span class=\"s1\">'\u101c\u1030'</span>, <span class=\"s1\">'\u101e\u102d'</span>, <span class=\"s1\">'\u1019\u103b\u102c\u1038'</span>, <span class=\"s1\">'\u1015\u102b'</span>, <span class=\"s1\">'\u1010\u101a\u103a'</span><span class=\"o\">]</span>\n\n<span class=\"c1\"># syllable level tokenization for Karen</span>\npds.tokenize<span class=\"o\">(</span><span class=\"s2\">\"\u101e\u101b\u1063\u103a,\u101e\u101b\u1063\u103a\u1019\u102f\u1063\u103a \u1001\u1032\u101c\u1062\u102c\u103a\u101f\u1038\u1011\u102e\u1063\u103a (\u1043\u1045) \u1002\u1064\u1014\u1037\u1063\u103a\u101c\u102e\u1064.\"</span>, <span class=\"nv\">lang</span><span class=\"o\">=</span><span class=\"s2\">\"karen\"</span><span class=\"o\">)</span>\n&gt;&gt; <span class=\"o\">[</span><span class=\"s1\">'\u1000\u1060\u102d'</span>, <span class=\"s1\">'\u101e'</span>, <span class=\"s1\">'\u101b\u1063\u103a'</span>, <span class=\"s1\">','</span>, <span class=\"s1\">'\u101e'</span>, <span class=\"s1\">'\u101b\u1063\u103a'</span>, <span class=\"s1\">'\u1019\u102f\u1063\u103a'</span>, <span class=\"s1\">'\u1001\u1032'</span>, <span class=\"s1\">'\u101c\u1062\u102c\u103a'</span>, <span class=\"s1\">'\u101f\u1038'</span>, <span class=\"s1\">'\u1011\u102e\u1063\u103a'</span>, <span class=\"s1\">'('</span>, <span class=\"s1\">'\u1043\u1045'</span>, <span class=\"s1\">')'</span>, <span class=\"s1\">'\u1002\u1064'</span>, <span class=\"s1\">'\u1014\u1037\u1063\u103a'</span>, <span class=\"s1\">'\u101c\u102e\u1064'</span>, <span class=\"s1\">'.'</span><span class=\"o\">]</span>\n\n<span class=\"c1\"># word level tokenization</span>\npds.tokenize<span class=\"o\">(</span><span class=\"s2\">\"\u1016\u1031\u1016\u1031\u1014\u1032\u1037\u1019\u1031\u1019\u1031\u104f\u1000\u103b\u1031\u1038\u1007\u1030\u1038\u1010\u101b\u102c\u1038\u1019\u103e\u102c\u1000\u103c\u102e\u1038\u1019\u102c\u1038\u101c\u103e\u1015\u1031\u101e\u100a\u103a\"</span>, <span class=\"nv\">form</span><span class=\"o\">=</span><span class=\"s2\">\"word\"</span><span class=\"o\">)</span>\n&gt;&gt; <span class=\"o\">[</span><span class=\"s1\">'\u1016\u1031\u1016\u1031'</span>, <span class=\"s1\">'\u1014\u1032\u1037'</span>, <span class=\"s1\">'\u1019\u1031\u1019\u1031'</span>, <span class=\"s1\">'\u104f'</span>, <span class=\"s1\">'\u1000\u103b\u1031\u1038\u1007\u1030\u1038\u1010\u101b\u102c\u1038'</span>, <span class=\"s1\">'\u1019\u103e\u102c'</span>, <span class=\"s1\">'\u1000\u103c\u102e\u1038\u1019\u102c\u1038'</span>, <span class=\"s1\">'\u101c\u103e'</span>, <span class=\"s1\">'\u1015\u1031'</span>, <span class=\"s1\">'\u101e\u100a\u103a'</span><span class=\"o\">]</span>\n</pre>\n<p>Syllable-level tokenization supports for 4 languages (Burmese, Karen, Shan, Mon). Word-level tokenization supports only Burmese currently.<br>\nAvailable values for <code>lang</code> parameter in <code>tokenize</code> function: \"mm\", \"karen\", \"mon\", \"shan\"</p>\n<h2>Future work</h2>\n<ul>\n<li>[x] Add tokenizer for Burmese (Syllabel and word-level tokenization)</li>\n<li>[ ] Add more tokenizer (BPE, WordPiece etc.)</li>\n<li>[ ] Add Part-of-Speech (POS) tagger for Burmese</li>\n<li>[ ] Add Named-entities Recognition (NER) classifier for Burmese</li>\n<li>[ ] Add thorough documentation</li>\n</ul>\n\n          </div>"}, "last_serial": 7172046, "releases": {"0.0.6": [{"comment_text": "", "digests": {"md5": "c3c05fe4a41cb34b0bb998f750f35b11", "sha256": "093306a03c7edf19bdf06e4eea1b17ef63635171debdccf0a1ba5114b0c3acb6"}, "downloads": -1, "filename": "pyidaungsu-0.0.6.tar.gz", "has_sig": false, "md5_digest": "c3c05fe4a41cb34b0bb998f750f35b11", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 31328, "upload_time": "2020-04-12T08:54:45", "upload_time_iso_8601": "2020-04-12T08:54:45.304311Z", "url": "https://files.pythonhosted.org/packages/15/51/ef11aad62afba736a67ea11210ba03603e7c896fe74a1188107d16bba507/pyidaungsu-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "e954e4c7b1deffb6c99e63ad2f1171e1", "sha256": "04d72900d2c0f6bb4e872b14525fd8fcf104188c7b1bae143a534fb97a7ae6b1"}, "downloads": -1, "filename": "pyidaungsu-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e954e4c7b1deffb6c99e63ad2f1171e1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 559990, "upload_time": "2020-04-15T10:36:23", "upload_time_iso_8601": "2020-04-15T10:36:23.940552Z", "url": "https://files.pythonhosted.org/packages/4c/73/90424eff9f65edbc2e2c5e77186d13220ad67c5f38ab66013bb343b1c831/pyidaungsu-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "49c95e9c625315a21a7bb978445b24bc", "sha256": "0c726ed4c2c09b43f99c63c12abf2a80096a2551a70ae520cd1bc82d739dc6c0"}, "downloads": -1, "filename": "pyidaungsu-0.0.8.tar.gz", "has_sig": false, "md5_digest": "49c95e9c625315a21a7bb978445b24bc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 561953, "upload_time": "2020-05-05T13:39:03", "upload_time_iso_8601": "2020-05-05T13:39:03.029540Z", "url": "https://files.pythonhosted.org/packages/2d/96/440814a234bb4cfee39f2f65a38e06d0a1cb783d62c4a466ee08179992ff/pyidaungsu-0.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "49c95e9c625315a21a7bb978445b24bc", "sha256": "0c726ed4c2c09b43f99c63c12abf2a80096a2551a70ae520cd1bc82d739dc6c0"}, "downloads": -1, "filename": "pyidaungsu-0.0.8.tar.gz", "has_sig": false, "md5_digest": "49c95e9c625315a21a7bb978445b24bc", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 561953, "upload_time": "2020-05-05T13:39:03", "upload_time_iso_8601": "2020-05-05T13:39:03.029540Z", "url": "https://files.pythonhosted.org/packages/2d/96/440814a234bb4cfee39f2f65a38e06d0a1cb783d62c4a466ee08179992ff/pyidaungsu-0.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:04:09 2020"}