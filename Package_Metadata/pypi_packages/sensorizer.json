{"info": {"author": "Jesus Gazol", "author_email": "jgaz@equinor.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: MacOS :: MacOS X", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Software Development :: Libraries"], "description": "# Sensorizer\n\nSensorizer is a python library built to simulate a flow of sensor data to disk (Avro) or event hubs, is meant\nto be the starting point of a data pipeline.\n\nThe library has a docker container companion so you can have a source of sensor data in approximately 5 mins,\nsee the docker deployment section if your sink is either an avro file or an Azure Event Hub, if you want an\nadditional sink, have a look at the issues section.\n\nThe main characteristic is that it tries to simulate traffic with\nsimilar timings, that is, it will release up to 400K readings per second,\none by one. Then you can send it to a streaming sink (Azure Event Hub implemented)\nor a disk option (Avro implemented).\n\n## Docker deployment\n\nThe deployment is container based, you can just pull the container:\n```\ndocker pull jgc31416/sensorizer:latest\n```\n\nThen pass the configuration as environment variables, set up the environment variables\ndepending on the sink you want, this is an example for the Avro file sink using an environment file,\nsee /docs folder:\n```\ndocker run --env-file=avro_sink.cfg jgc31416/sensorizer:latest\n```\n\nYou will get the generated files in the container.\n\n\n### Avro file sink\n\nYou might want to map the output folder of the dump file into your container host.\n\n```\nexport NUMBER_OF_SENSORS=\"10000\"\nexport NUMBER_OF_HOURS=\"1\"\nexport SINK_TYPE=\"file\"                            # store sensor readings to a file\nexport RUNNING_MODE=\"batch\"                        # send the readings one by one or in batch mode\nexport EVENT_DUMP_FILENAME=\"/tmp/event_dump.avro\"  # Where to save the data\n```\n\n\n### Event Hub sink\n\n```bash\nexport NUMBER_OF_SENSORS=\"10000\"\nexport NUMBER_OF_HOURS=\"1\"\nexport SINK_TYPE=\"event_hub\"                       # store sensor readings to a file\nexport RUNNING_MODE=\"batch\"                        # send the readings one by one or in batch mode\nexport EVENT_HUB_ADDRESS=\"amqps://<EventHubNamepace>.servicebus.windows.net/<EventHub>\"\nexport EVENT_HUB_SAS_POLICY=\"<PolicyName>\"\nexport EVENT_HUB_SAS_KEY=\"<SAS_KEY>\"\n```\n\n### Distribution of the sensor readings\n\nThe distribution of the sensor readings is the following:\n\n- Frequencies are: 15% 1.0s, 65% 60.0s, 20% 3600.0s (Percentage is over the number of sensors,\ns is seconds per reading)\n- Base reading values: 50% 1, 40% 500, 10% 1000\n\n\n### Sensor format\n\n```python\n@dataclass\nclass TimeserieRecord:\n    \"\"\"\n    Class for time series\n    \"\"\"\n\n    ts: float  # epoch\n    data_type: str  # string(3)\n    plant: str  # string(3)\n    quality: float\n    schema: str  # string(6)\n    tag: str  # UUID\n    value: float\n```\n\n\n\n## Getting started with the library development\n\nClone the project from github and enjoy.\n\n### Prerequisites\n\nThis software has been tested in Linux, it might work in other OSs but it\nis definitely not warrantied.\n\n```\n- Ubuntu latest stable / Debian Stretch / Fedora +25\n- Python 3.7 (Dataclasses and typing in the code)\n- Docker (if you want a container deployment)\n```\n\n### Installing\n\nPython requirements:\n\n```\npip install -r requirements.txt\n```\n\n\n## Running the tests\n\nAs simple as:\n\n```\npytest sensorizer/tests/\n```\n\n\n## Built With\n\n* Python 3.7\n* Docker\n\n## Contributing\n\nSimply put, per branch features, merge to master, so:\n- Fork the repo.\n- Make a feature branch and develop.\n- Test :)\n- Create a pull request for your new feature.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/equinor/sensorizer", "keywords": "IoT,sensor", "license": "GPL 3", "maintainer": "jgaz@equinor.com", "maintainer_email": "jgaz@equinor.com", "name": "sensorizer", "package_url": "https://pypi.org/project/sensorizer/", "platform": "any", "project_url": "https://pypi.org/project/sensorizer/", "project_urls": {"Homepage": "https://github.com/equinor/sensorizer", "Source": "https://github.com/", "Tracker": "https://github.com/"}, "release_url": "https://pypi.org/project/sensorizer/0.0.3/", "requires_dist": ["numpy (>=1.16.3)", "fastavro (>=0.22.13)", "azure-eventhub (==1.3.1)", "pre-commit (>=2.1.1) ; extra == 'dev'", "sphinx (<3,>=2.0.0) ; extra == 'docs'", "towncrier (>=18.5.0) ; extra == 'docs'", "pygments-github-lexers (>=0.0.5) ; extra == 'docs'", "sphinxcontrib-autoprogram (>=0.1.5) ; extra == 'docs'", "pytest (==5.3.5) ; extra == 'testing'", "pytest-cov ; extra == 'testing'"], "requires_python": ">=3.7", "summary": "Timeseries data generation and preparation for batch jobs at scale", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Sensorizer</h1>\n<p>Sensorizer is a python library built to simulate a flow of sensor data to disk (Avro) or event hubs, is meant\nto be the starting point of a data pipeline.</p>\n<p>The library has a docker container companion so you can have a source of sensor data in approximately 5 mins,\nsee the docker deployment section if your sink is either an avro file or an Azure Event Hub, if you want an\nadditional sink, have a look at the issues section.</p>\n<p>The main characteristic is that it tries to simulate traffic with\nsimilar timings, that is, it will release up to 400K readings per second,\none by one. Then you can send it to a streaming sink (Azure Event Hub implemented)\nor a disk option (Avro implemented).</p>\n<h2>Docker deployment</h2>\n<p>The deployment is container based, you can just pull the container:</p>\n<pre><code>docker pull jgc31416/sensorizer:latest\n</code></pre>\n<p>Then pass the configuration as environment variables, set up the environment variables\ndepending on the sink you want, this is an example for the Avro file sink using an environment file,\nsee /docs folder:</p>\n<pre><code>docker run --env-file=avro_sink.cfg jgc31416/sensorizer:latest\n</code></pre>\n<p>You will get the generated files in the container.</p>\n<h3>Avro file sink</h3>\n<p>You might want to map the output folder of the dump file into your container host.</p>\n<pre><code>export NUMBER_OF_SENSORS=\"10000\"\nexport NUMBER_OF_HOURS=\"1\"\nexport SINK_TYPE=\"file\"                            # store sensor readings to a file\nexport RUNNING_MODE=\"batch\"                        # send the readings one by one or in batch mode\nexport EVENT_DUMP_FILENAME=\"/tmp/event_dump.avro\"  # Where to save the data\n</code></pre>\n<h3>Event Hub sink</h3>\n<pre><span class=\"nb\">export</span> <span class=\"nv\">NUMBER_OF_SENSORS</span><span class=\"o\">=</span><span class=\"s2\">\"10000\"</span>\n<span class=\"nb\">export</span> <span class=\"nv\">NUMBER_OF_HOURS</span><span class=\"o\">=</span><span class=\"s2\">\"1\"</span>\n<span class=\"nb\">export</span> <span class=\"nv\">SINK_TYPE</span><span class=\"o\">=</span><span class=\"s2\">\"event_hub\"</span>                       <span class=\"c1\"># store sensor readings to a file</span>\n<span class=\"nb\">export</span> <span class=\"nv\">RUNNING_MODE</span><span class=\"o\">=</span><span class=\"s2\">\"batch\"</span>                        <span class=\"c1\"># send the readings one by one or in batch mode</span>\n<span class=\"nb\">export</span> <span class=\"nv\">EVENT_HUB_ADDRESS</span><span class=\"o\">=</span><span class=\"s2\">\"amqps://&lt;EventHubNamepace&gt;.servicebus.windows.net/&lt;EventHub&gt;\"</span>\n<span class=\"nb\">export</span> <span class=\"nv\">EVENT_HUB_SAS_POLICY</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;PolicyName&gt;\"</span>\n<span class=\"nb\">export</span> <span class=\"nv\">EVENT_HUB_SAS_KEY</span><span class=\"o\">=</span><span class=\"s2\">\"&lt;SAS_KEY&gt;\"</span>\n</pre>\n<h3>Distribution of the sensor readings</h3>\n<p>The distribution of the sensor readings is the following:</p>\n<ul>\n<li>Frequencies are: 15% 1.0s, 65% 60.0s, 20% 3600.0s (Percentage is over the number of sensors,\ns is seconds per reading)</li>\n<li>Base reading values: 50% 1, 40% 500, 10% 1000</li>\n</ul>\n<h3>Sensor format</h3>\n<pre><span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span> <span class=\"nc\">TimeserieRecord</span><span class=\"p\">:</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">    Class for time series</span>\n<span class=\"sd\">    \"\"\"</span>\n\n    <span class=\"n\">ts</span><span class=\"p\">:</span> <span class=\"nb\">float</span>  <span class=\"c1\"># epoch</span>\n    <span class=\"n\">data_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>  <span class=\"c1\"># string(3)</span>\n    <span class=\"n\">plant</span><span class=\"p\">:</span> <span class=\"nb\">str</span>  <span class=\"c1\"># string(3)</span>\n    <span class=\"n\">quality</span><span class=\"p\">:</span> <span class=\"nb\">float</span>\n    <span class=\"n\">schema</span><span class=\"p\">:</span> <span class=\"nb\">str</span>  <span class=\"c1\"># string(6)</span>\n    <span class=\"n\">tag</span><span class=\"p\">:</span> <span class=\"nb\">str</span>  <span class=\"c1\"># UUID</span>\n    <span class=\"n\">value</span><span class=\"p\">:</span> <span class=\"nb\">float</span>\n</pre>\n<h2>Getting started with the library development</h2>\n<p>Clone the project from github and enjoy.</p>\n<h3>Prerequisites</h3>\n<p>This software has been tested in Linux, it might work in other OSs but it\nis definitely not warrantied.</p>\n<pre><code>- Ubuntu latest stable / Debian Stretch / Fedora +25\n- Python 3.7 (Dataclasses and typing in the code)\n- Docker (if you want a container deployment)\n</code></pre>\n<h3>Installing</h3>\n<p>Python requirements:</p>\n<pre><code>pip install -r requirements.txt\n</code></pre>\n<h2>Running the tests</h2>\n<p>As simple as:</p>\n<pre><code>pytest sensorizer/tests/\n</code></pre>\n<h2>Built With</h2>\n<ul>\n<li>Python 3.7</li>\n<li>Docker</li>\n</ul>\n<h2>Contributing</h2>\n<p>Simply put, per branch features, merge to master, so:</p>\n<ul>\n<li>Fork the repo.</li>\n<li>Make a feature branch and develop.</li>\n<li>Test :)</li>\n<li>Create a pull request for your new feature.</li>\n</ul>\n\n          </div>"}, "last_serial": 7106744, "releases": {"0.0.3": [{"comment_text": "", "digests": {"md5": "99c4a9609f05f52cd005ae99a41a956a", "sha256": "9b1d2aa7f0316602b04bdbefcadc721e66cc4a0a52e0089b9bbf8f15c24276b8"}, "downloads": -1, "filename": "sensorizer-0.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "99c4a9609f05f52cd005ae99a41a956a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.7", "size": 18945, "upload_time": "2020-04-26T20:26:38", "upload_time_iso_8601": "2020-04-26T20:26:38.012494Z", "url": "https://files.pythonhosted.org/packages/5f/21/5eedbba960b8c3eca62ba8b9170858af4633ce218c3f4f64cd5204b1cea5/sensorizer-0.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d561c29db1f6644c6721a85f7fbfe8a", "sha256": "254fc5db8678628d3ad45446b04b62cc6865563b39b24f46046bcf1340485c11"}, "downloads": -1, "filename": "sensorizer-0.0.3.tar.gz", "has_sig": false, "md5_digest": "3d561c29db1f6644c6721a85f7fbfe8a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 23944, "upload_time": "2020-04-26T20:26:40", "upload_time_iso_8601": "2020-04-26T20:26:40.289325Z", "url": "https://files.pythonhosted.org/packages/57/d9/399d72eb0ba9cd1ef042ccd0a595cd0e00a595a121840391e1538b122423/sensorizer-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "99c4a9609f05f52cd005ae99a41a956a", "sha256": "9b1d2aa7f0316602b04bdbefcadc721e66cc4a0a52e0089b9bbf8f15c24276b8"}, "downloads": -1, "filename": "sensorizer-0.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "99c4a9609f05f52cd005ae99a41a956a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.7", "size": 18945, "upload_time": "2020-04-26T20:26:38", "upload_time_iso_8601": "2020-04-26T20:26:38.012494Z", "url": "https://files.pythonhosted.org/packages/5f/21/5eedbba960b8c3eca62ba8b9170858af4633ce218c3f4f64cd5204b1cea5/sensorizer-0.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3d561c29db1f6644c6721a85f7fbfe8a", "sha256": "254fc5db8678628d3ad45446b04b62cc6865563b39b24f46046bcf1340485c11"}, "downloads": -1, "filename": "sensorizer-0.0.3.tar.gz", "has_sig": false, "md5_digest": "3d561c29db1f6644c6721a85f7fbfe8a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 23944, "upload_time": "2020-04-26T20:26:40", "upload_time_iso_8601": "2020-04-26T20:26:40.289325Z", "url": "https://files.pythonhosted.org/packages/57/d9/399d72eb0ba9cd1ef042ccd0a595cd0e00a595a121840391e1538b122423/sensorizer-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:55:08 2020"}