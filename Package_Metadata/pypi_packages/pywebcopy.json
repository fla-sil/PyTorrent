{"info": {"author": "Raja Tomar", "author_email": "rajatomar788@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "\n# PyWebCopy &copy; 6\n\n[![PyPI](https://img.shields.io/pypi/v/pywebcopy.svg)](https://pypi.org/project/pywebcopy/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pywebcopy.svg?color=green)](https://pypi.org/project/pywebcopy/)\n[![PyPI - Status](https://img.shields.io/pypi/status/pywebcopy.svg?color=9cf)](https://pypi.org/project/pywebcopy/)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/e8e86b7187f6443abfcf7d943d2e7cca)](https://app.codacy.com/app/rajatomar788/pywebcopy?utm_source=github.com&utm_medium=referral&utm_content=rajatomar788/pywebcopy&utm_campaign=Badge_Grade_Dashboard)\n\n`Created By : Raja Tomar`\n`License : MIT`\n`Email: rajatomar788@gmail.com`\n\nPython websites and webpages cloning at ease.\nWeb Scraping or Saving Complete webpages and websites with python.\n\nWeb scraping and archiving tool written in Python\nArchive any online website and its assets, css, js and\nimages for offilne reading, storage or whatever reasons.\nIt's easy with `pywebcopy`.\n\nWhy it's great? because it -\n\n- respects `robots.txt`\n- saves a webpage with css, js and images with one call\n- clones a complete website with assets and links remapped in one call\n- have direct apis for simplicity and ease\n- subclassing for advanced usage\n- custom html tags handler support\n- lots of configuration for many custom needs\n- provides several scraping packages in one objects for scraping under one class\n  - lxml\n  - requests\n  - beautifulsoup4\n  - pyquery\n  - requests_html\n\nEmail me at `rajatomar788@gmail.com` of any query :)\n\n## 1.1 Installation\n\n`pywebcopy` is available on PyPi and is easily installable using `pip`\n\n```shell\n\n$ pip install pywebcopy\n\n```\n\nYou are ready to go. Read the tutorials below to get started.\n\n## 1.1.1 First steps\n\nYou should always check if the latest pywebcopy is installed successfully.\n\n```python\n>>> import pywebcopy\n>>> pywebcopy.__version___\n6.0.0\n\n```\n\nYour version may be different, now you can continue the tutorial.\n\n## 1.2 Basic Usages\n\nTo save any single page, just type in python console\n\n```Python\nfrom pywebcopy import save_webpage\n\nkwargs = {'project_name': 'some-fancy-name'}\n\nsave_webpage(\n    url='http://example-site.com/index.html',\n    project_folder='path/to/downloads',\n    **kwargs\n)\n\n```\n\nTo save full website (This could overload the target server, So, be careful)\n\n```Python\n\nfrom pywebcopy import save_website\n\nkwargs = {'project_name': 'some-fancy-name'}\n\nsave_website(\n    url='http://example-site.com/index.html',\n    project_folder='path/to/downloads',\n    **kwargs\n)\n\n```\n\n### 1.3 Running Tests\nRunning tests is simple and doesn't require any external library. \nJust run this command from root directory of pywebcopy package.\n\n\n```shell\n$ python -m pywebcopy run-tests\n```\n\n### 1.4 Command Line Interface\n`pywebcopy` have a very easy to use command-line interface which\ncan help you do task without having to worrying about the inner\nlong way.\n- #### Getting list of commands\n    ```shell\n    $ python -m pywebcopy -- --help\n    ```\n- #### Using apis\n    ```shell\n    $ python -m pywebcopy save_webpage http://google.com E://store// --bypass_robots=True\n    or\n    $ python -m pywebcopy save_website http://google.com E://store// --bypass_robots\n    ``` \n- #### Running tests\n    ```shell\n    $ python -m pywebcopy run_tests\n    ```\n\n\n### 1.5 Authentication and Cookies\nMost of the time authentication is needed to access a certain page.\nIts real easy to authenticate with `pywebcopy` because it usage an \n`requests.Session` object for base http activity which can be accessed \nthrough `pywebcopy.SESSION` attribute. And as you know there\nare ton of tutorials on setting up authentication with `requests.Session`.\n\nHere is a basic example of simple http auth -\n```python\nimport pywebcopy\n\n# Update the headers with suitable data\n\npywebcopy.SESSION.headers.update({\n    'auth': {'username': 'password'},\n    'form': {'key1': 'value1'},\n})\n\n# Rest of the code is as usual\nkwargs = {\n    'url': 'http://localhost:5000',\n    'project_folder': 'e://saved_pages//',\n    'project_name': 'my_site'\n}\npywebcopy.config.setup_config(**kwargs)\npywebcopy.save_webpage(**kwargs)\n\n```\n\n\n### 2.1 `WebPage` class\n\n`WebPage` class, the engine of this saving actions.\nYou can use this class to access many more methods to\ncustomise the process with.\n\n- Creating the instance\n\n    You can directly import this class from `pywebcopy` package.\n\n    ```Python\n    from pywebcopy import WebPage    \n    wp = WebPage()\n    ```\n\n- fetching the html source from internet\n\n   You can tell it to fetch the source from the\n   internet, it then uses `requests` module to fetch it\n   for you.\n\n   You can pass in the several `params`\n   which `requests.get()` would accept \n   e.g. *proxies, auth etc.*\n\n   ```python\n    from pywebcopy import WebPage    \n    wp = WebPage()\n\n    # You can choose to load the page explicitly using \n    # `requests` module with params `requests` would take\n\n    url = 'http://google.com'\n    params = {\n        'auth': 'username@password',\n        'proxies': 'localhost:5000',\n    }\n    wp.get(url, **params)\n    ```\n\n- providing your own opened file\n    You can also provide opened source handles\n    directly \n\n    ```Python\n    from pywebcopy import WebPage    \n    wp = WebPage()\n\n    # You can choose to set the source yourself\n    handle = open('file.html', 'rb')\n    wp.set_source(handle)\n    ```\n\n### 2.1.2  `WebPage` properties and methods\n\nApis which `WebPage` object exposes after creating\nthrough any method described above\n\n- `.file_path` property\n    **Read-only** location at which this file will end up \n    when you try to save the parsed html source\n\n    To change this location you have to manipulate the\n    `.utx` property of the `WebPage` class. You can\n    look it up below.\n\n\n- `.project_path` property\n    **Read-only** location at which all the files will end up \n    when you try to save the complete webpage.\n\n    To change this location you have to manipulate the\n    `.utx` property of the `WebPage` class. You can\n    look it up below.\n\n\n- `.save_assets` method\n    This methods saves all the `css`, `js`, `images`, `fonts` etc.\n    in the folder you setup through property `.project_path`.\n\n    ```Python\n\n    from pywebcopy import WebPage\n    wp = WebPage()\n    wp.get('http://google.com')\n\n    wp.save_html()\n    #> a .html file would be saved at\n    ```\n\n\n- `.save_html` method\n    After setting up the `WebPage` instance you can\n    use this method to save a local copy of the parsed\n    and modified html at `.file_path` property value.\n\n    ```Python\n\n    from pywebcopy import WebPage\n    wp = WebPage()\n    wp.get('http://google.com')\n\n    wp.save_html()\n    #> a .html file would be saved at location which\n    #> `.file_path` property returns\n    ```\n\n- `.save_complete` method\n    This is the important api which you would be using\n    frequently for saving or cloning a webpage for later\n    reading or whatever the use case would be.\n\n    This methods saves all the `css`, `js`, `images`, `fonts` etc.\n    in the same order as a most browser would do when you will click on\n    the `save page` option in the right click menu.\n\n    if you want complete webpage with css, js and images\n    ```Python\n    from pywebcopy import WebPage\n    wp = WebPage()\n    wp.get('http://google.com')\n\n    wp.save_complete()\n    ```\n\n## 3.1 Scrapings Support\n\nMultiple scraping packages are wrapped up in one object \nwhich you can use to unlock the best of all those libraries\nat one go without having to go through the hassle of \ninstantiating each one of those libraries\n\n> To use all the methods and properties documented below\n> just create a object once as described\n\n```python\nfrom pywebcopy import MultiParser\n\nimport requests\n\nreq = requests.get('http://google.com')\n\nhtml = req.content\n\n# You can skip the encoding declaration\n# it is start enough to auto-detect :)\nencoding = req.encoding\n\nwp = MultiParser(html, encoding)\n\n# done\n\n```\n\n> All code follows above code\n\n-    #### BeautifulSoup methods are supported\n\n    you can also use any beautiful_soup methods on it\n\n    ```python\n    >>> links = wp.bs4.find_all('a')\n\n    ['//docs.python.org/3/tutorial/', '/about/apps/', 'https://github.com/python/pythondotorg/issues', '/accounts/login/', '/download/other/']\n\n    ```\n\n-   #### `lxml` is completely supported\n\n    You can use any lxml methods on it. Read more about lxml at `http://lxml.de/`\n\n    ```python\n    >>> wp.lxml.xpath('//a', ..)\n    [<Element 'a'>,<Element 'a'>]\n\n    ```\n\n- #### `pyquery` is Fully supported\n\n    You can use PyQuery methods on it .Read more about pyquery at `https://pythonhosted.org/pyquery/`\n\n    ```python\n    >>> wp.pq.select(selector, ..)\n    ...\n    ```\n\n-   #### `lxml.xpath` is also supported\n\n    xpath is also natively supported which retures a :class: `requests_html.Element`\n    See more at `https://html.python-requests.org`\n\n    ```python\n\n    >>> wp.xpath('a')\n    ['<Element 'a' class='btn' href='https://help.github.com/articles/supported-browsers'>']\n    ```\n\n-   #### select only elements containing certain text\n\n    Provided through the `requests_html` module.\n\n    ```python\n    >>> wp.find('a', containing='kenneth')\n    >>> [<Element 'a' href='http://kennethreitz.com/pages'>, ...]\n    ```\n\n## `Crawler` object\nThis is a subclass of `WebPage` class and can be used to mirror any website.\n\n```python\n>>> from pywebcopy import Crawler, config\n>>> url = 'http://some-url.com/some-page.html'\n>>> project_folder = '/home/desktop/'\n>>> project_name = 'my_project'\n>>> kwargs = {'bypass_robots': True}\n# You should always start with setting up the config or use apis\n>>> config.setup_config(url, project_folder, project_name, **kwargs)\n\n# Create a instance of the webpage object\n>>> wp = Crawler()\n\n# If you want to you can use `requests` to fetch the pages\n>>> wp.get(url, **{'auth': ('username', 'password')})\n\n# Then you can access several methods like\n>>> wp.crawl()\n\n```\n\n\n## Common Settings and Errors\n\nYou can easily make a beginners mistake or could get confuse,\nthus here are the common errors and how to correct them if you\nare facing them. \n\n1. `pywebcopy.exceptions.AccessError`\n\n    If you are getting `pywebcopy.exceptions.AccessError` Exception.\n    then check if website allows scraping of its content.\n\n    ```python\n    >>> import pywebcopy\n    >>> pywebcopy.config['bypass_robots'] = True\n\n    # rest of your code follows..\n\n    ```\n\n2. Overwrite existing files when copying\n\n    If you want to overwrite existing files in the directory then\n    use the over_write config key.\n\n    ```python\n\n    import pywebcopy\n    pywebcopy.config['over_write'] = True\n\n    # rest of your code follows..\n\n    ```\n\n3. Changing your project name\n\n    By default the pywebcopy creates a directory inside project_folder\n    with the url you have provided but you can change this using the code \n    below\n\n    ```python\n    >>> import pywebcopy\n    >>> pywebcopy.config['project_name'] = 'my_project'\n\n    # rest of your code follows..\n\n    ```\n\n## How to - Save Single Webpage\n\nParticular webpage can be saved easily using the following methods.\n\nNote: if you get `pywebcopy.exceptions.AccessError` when running any of these code then use the code provided on later sections.\n\n### Method 1 : via api - `save_webpage()`\n\nWebpage can easily be saved using an inbuilt funtion called `.save_webpage()` which takes several\narguments also.\n\n```python\n>>> from pywebcopy import save_webpage\n>>> save_webpage(project_url='http://google.com', project_folder='c://Saved_Webpages/',)\n\n```\n\n### Method 2\n\nThis use case is slightly more powerful as it can provide every functionallity of the WebPage class.\n\n```python\n>>> from pywebcopy import WebPage, config\n>>> url = 'http://some-url.com/some-page.html'\n\n# You should always start with setting up the config or use apis\n>>> config.setup_config(url, project_folder, project_name, **kwargs)\n\n# Create a instance of the webpage object\n>>> wp = WebPage()\n\n# If you want to use `requests` to fetch the page then\n>>> wp.get(url)\n\n# Else if you want to use plain html or urllib then use\n>>> wp.set_source(object_which_have_a_read_method, encoding=encoding)\n>>> wp.url = url   # you need to do this if you are using set_source()\n\n# Then you can access several methods like\n>>> wp.save_complete()\n>>> wp.save_html()\n>>> wp.save_assets()\n\n# This Webpage object contains every methods of the Webpage() class and thus\n# can be reused for later usages.\n\n```\n\n### Method 2 using Plain HTML\n\nI told you earlier that Webpage object is powerful and can be manipulated in any ways.\n\nOne feature is that the raw html is now also accepted.\n\n```python\n\n>>> from pywebcopy import WebPage, config\n\n>>> HTML = open('test.html').read()\n\n>>> base_url = 'http://example.com' # used as a base for downloading imgs, css, js files.\n>>> project_folder = '/saved_pages/'\n>>> config.setup_config(base_url, project_folder)\n\n>>> wp = WebPage()\n>>> wp.set_source(HTML)\n>>> wp.url = base_url\n>>> wp.save_complete()\n\n```\n\n## How to - Clone Whole Websites\n\nUse caution when copying websites as this can overload or damage the\nservers of the site and rarely could be illegal, so check everything before\nyou proceed.\n\n### Method 1 : via api - `save_website()`\n\nUsing the inbuilt api `.save_website()` which takes several arguments.\n\n```python\n>>> from pywebcopy import save_website\n\n>>> save_website(project_url='http://localhost:8000', project_folder='e://tests/')\n\n```\n\n### Method 2 -\n\nBy creating a Crawler() object which provides several other functions as well.\n\n```python\n>>> from pywebcopy import Crawler, config\n\n>>> config.setup_config(project_url='http://localhost:5000/', \nproject_folder='e://tests/', project_name='LocalHost')\n\n>>> crawler = Crawler()\n>>> crawler.crawl()\n\n```\n\n## 1.3 Configuration\n\n`pywebcopy` is highly configurable. You can setup the global object\nusing the methods exposed by the `pywebcopy.config` object.\n\nWays to change the global configurations are below -\n\n- Using the method `.setup_config`  on global `pywebcopy.config` object\n\n    You can manually configure every configuration by using a \n    `.setup_config` call.\n\n    ```Python\n\n    >>> import pywebcopy\n\n    >>> url = 'http://example-site.com/index.html'\n    >>> download_loc = 'path/to/downloads/'\n    >>> project = 'my_project'\n\n    >>> pywebcopy.config.setup_config(url, download_loc, project, **kwargs)\n    # done!\n\n    # Now check\n    >>> pywebcopy.config.get('project_url')\n    'http://example-site.com/index.html'\n\n    >>> pywebcopy.config.get('project_folder')\n    'path/to/downloads'\n\n    >>> pywebcopy.config.get('project_name')\n    'example-site.com'\n\n    ## You can also change any config even after\n    ## the `setup_config` call\n\n    pywebcopy.config['url'] = 'http://url-changed.com'\n    # rest of config remains unchanged\n\n\n    Done!\n\n- Passing in the config vars directly to the \n\n    global apis e.g. `.save_webpage`\n\n    To change any configuration, just pass it to the `api` call.\n\n    Example:\n\n    ```Python\n    from pywebcopy import save_webpage\n\n    kwargs = {\n        'project_url': 'http://google.com',\n        'project_folder': '/home/pages/',\n        'project_name': \n        ...\n    }\n\n    save_webpage(**kwargs)\n\n    ```\n\n    #### List of available `configurations`\n\n    below is the list of `config` keys with their `default` values :\n\n    ```Python\n\n    # writes the trace output and log file content to console directly\n    'DEBUG': False  \n\n    # make zip archive of the downloaded content\n    'zip_project_folder': True\n\n    # delete the project folder after making zip archive of it\n    'delete_project_folder': False\n\n    # to download css file or not\n    'LOAD_CSS': True\n\n    # to download images or not\n    'LOAD_IMAGES': True\n\n    # to download js file or not\n    'LOAD_JAVASCRIPT': True\n\n\n    # to overwrite the existing files if found\n    'OVER_WRITE': False\n\n    # list of allowed file extensions\n    # shortend for readability\n    'ALLOWED_FILE_EXT': ['.html', '.css', ...]\n\n    # log file path\n    'LOG_FILE': None\n\n    # name of the mirror project\n    'PROJECT_NAME': website-name.com\n\n    # define the base directory to store all copied sites data\n    'PROJECT_FOLDER': None\n\n\n    # DANGER ZONE\n    # CHANGE THESE ON YOUR RESPONSIBILITY\n    # NOTE: Do not change unless you know what you're doing\n\n    # requests headers to be shown on requests made to server\n    'http_headers': {...}\n\n    # bypass the robots.txt restrictions\n    'BYPASS_ROBOTS' : False\n\n    ```\n\n## 4.1 Contribution\n\nYou can contribute in many ways\n\n- give it a star on github repo\n- reporting bugs on github repo: <https://github.com/rajatomar788/pywebcopy/> or at my email.\n- creating pull requests on github repo: <https://github.com/rajatomar788/pywebcopy/>\n- sending a thanks mail\n\nIf you have any suggestions or fixes or reports feel free to mail me :)\n\n## 5.1 Undocumented Features\n\nI built many utils and classes in this project to ease\nthe tasks I was trying to do.\n\nBut,\nthese task are also suitable for general purpose use.\n\nSo,\nif you want, you can help in generating suitable `documentation` for these undocumented ones,\nthen you can always create and pull request or email me.\n\n## 6.1 Changelog\n\n### [version 6.0.0]\n- **Breaking Change** New command-line interface using `Python Fire` library.\n- Implemented type checks and path normalising in the `config.setup_paths`.\n- added new dynamic `pywebcopy.__all__` attr generation.\n- `WebPage` class now doesnt take any argument **(breaking change)**\n- `WebPage` class has new methods `WebPage.get` and `WebPage.set_source`\n- Queuing of downloads is replaced with a barrier to manage active threads\n\n\n### [version 5.x]\n\n- Optimization of existing code, upto 5x speed ups in certain cases\n- Removed cluttering, improved readability\n\n### [version 4.x]\n\n- *A complete rewrite and restructuring of core functionality.*\n\n### [version 2.0.0]\n\n#### [changed]\n\n- `core.setup_config` function is changed to `config.setup_config`.\n\n#### [added]\n\n- added `utils.trace` decorator, which  will **print** *function_name*, *args*, *kwargs* and *return value* when debug config key is True.\n- new html-parsers ('html5lib', 'lxml') are supported for better webpages.\n- html-parser is now defaulted to 'lxml'. You can use any through new `config.config` key called `parser`\n\n#### [fixed]\n\n- fixed issue while changing `user-agent` key cracked webpages. You can now use any browser's user-agent id and it will get exact same page downloaded.\n- fixed issue in `generators.extract_css_urls` which was caused by `str` and `bytes` difference in python3.\n- fixed issues in modules importing. (Thanks \"**\u0418\u043b\u044c\u044f \u0418\u0433\u043e\u0440\u0435\u0432\u0438\u0447**\").\n- added `errorhandling` to required functions\n\n### [version 2.0(beta)]\n\n- `init` function is replaced with `save_webpage`\n- three new `config` automation functions are added -\n  - `core.setup_config` (creates every ideal config just from url and download location)\n  - `config.reset_config` (resets the configuration to default state)\n  - `config.update_config` (manual-mode version of `core.setup_config`)  \n- object `structures.WebPage` added\n- merged `generators.generate_style_map` and `generators.generate_relative_paths` to a single function `generators.generate_style_map`\n- rewrite of majority of functions\n- new module `exceptions` added\n\n### [version 1.10]\n\n- `url` is checked and resolved of any redirection before starting any work functions.\n- `init` vars : `mirrors_dir` and `clean_up` were fixed which cleaned the dir before the log was completely written.\n- `init` call now takes `url` arg by default and could raise a error when not supplied\n- professional looking log entries\n- rewritten archiving system now uses `zipfile` and `exceptions` handling to prevent errors and eventual archive corruption\n\n### [version 1.9]\n\n- more redundant code\n- modules are now separated based on type e.g. Core, Generators, Utils etc.\n- new helper functions and class `structures.WebPage`\n- Compatible with Python 2.6, 2.7, 3.6, 3.7\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/rajatomar788/pywebcopy/", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "pywebcopy", "package_url": "https://pypi.org/project/pywebcopy/", "platform": "", "project_url": "https://pypi.org/project/pywebcopy/", "project_urls": {"Homepage": "https://github.com/rajatomar788/pywebcopy/"}, "release_url": "https://pypi.org/project/pywebcopy/6.3.0/", "requires_dist": ["requests", "lxml", "pyquery", "parse", "w3lib", "bs4", "fire", "typing; python_version < \"3.5\""], "requires_python": "", "summary": "Python package for cloning complete webpages and websites to local storage.", "version": "6.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PyWebCopy \u00a9 6</h1>\n<p><a href=\"https://pypi.org/project/pywebcopy/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f615d66e2cf6f47ac6b4f42f4930368a7f66fbd0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7079776562636f70792e737667\"></a>\n<a href=\"https://pypi.org/project/pywebcopy/\" rel=\"nofollow\"><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a0d01434b9f7a6d7d34fe3541f9c8a75a876b866/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f7079776562636f70792e7376673f636f6c6f723d677265656e\"></a>\n<a href=\"https://pypi.org/project/pywebcopy/\" rel=\"nofollow\"><img alt=\"PyPI - Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9aa5e1184e04f76803caf3fc9314981d1e378fcb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f7374617475732f7079776562636f70792e7376673f636f6c6f723d396366\"></a>\n<a href=\"https://app.codacy.com/app/rajatomar788/pywebcopy?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=rajatomar788/pywebcopy&amp;utm_campaign=Badge_Grade_Dashboard\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6d3461bdaca03ace42bb09cfaed53406c5861970/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6538653836623731383766363434336162666366376439343364326537636361\"></a></p>\n<p><code>Created By : Raja Tomar</code>\n<code>License : MIT</code>\n<code>Email: rajatomar788@gmail.com</code></p>\n<p>Python websites and webpages cloning at ease.\nWeb Scraping or Saving Complete webpages and websites with python.</p>\n<p>Web scraping and archiving tool written in Python\nArchive any online website and its assets, css, js and\nimages for offilne reading, storage or whatever reasons.\nIt's easy with <code>pywebcopy</code>.</p>\n<p>Why it's great? because it -</p>\n<ul>\n<li>respects <code>robots.txt</code></li>\n<li>saves a webpage with css, js and images with one call</li>\n<li>clones a complete website with assets and links remapped in one call</li>\n<li>have direct apis for simplicity and ease</li>\n<li>subclassing for advanced usage</li>\n<li>custom html tags handler support</li>\n<li>lots of configuration for many custom needs</li>\n<li>provides several scraping packages in one objects for scraping under one class\n<ul>\n<li>lxml</li>\n<li>requests</li>\n<li>beautifulsoup4</li>\n<li>pyquery</li>\n<li>requests_html</li>\n</ul>\n</li>\n</ul>\n<p>Email me at <code>rajatomar788@gmail.com</code> of any query :)</p>\n<h2>1.1 Installation</h2>\n<p><code>pywebcopy</code> is available on PyPi and is easily installable using <code>pip</code></p>\n<pre>$ pip install pywebcopy\n</pre>\n<p>You are ready to go. Read the tutorials below to get started.</p>\n<h2>1.1.1 First steps</h2>\n<p>You should always check if the latest pywebcopy is installed successfully.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pywebcopy</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">__version___</span>\n<span class=\"mf\">6.0</span><span class=\"o\">.</span><span class=\"mi\">0</span>\n</pre>\n<p>Your version may be different, now you can continue the tutorial.</p>\n<h2>1.2 Basic Usages</h2>\n<p>To save any single page, just type in python console</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">save_webpage</span>\n\n<span class=\"n\">kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'project_name'</span><span class=\"p\">:</span> <span class=\"s1\">'some-fancy-name'</span><span class=\"p\">}</span>\n\n<span class=\"n\">save_webpage</span><span class=\"p\">(</span>\n    <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://example-site.com/index.html'</span><span class=\"p\">,</span>\n    <span class=\"n\">project_folder</span><span class=\"o\">=</span><span class=\"s1\">'path/to/downloads'</span><span class=\"p\">,</span>\n    <span class=\"o\">**</span><span class=\"n\">kwargs</span>\n<span class=\"p\">)</span>\n</pre>\n<p>To save full website (This could overload the target server, So, be careful)</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">save_website</span>\n\n<span class=\"n\">kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'project_name'</span><span class=\"p\">:</span> <span class=\"s1\">'some-fancy-name'</span><span class=\"p\">}</span>\n\n<span class=\"n\">save_website</span><span class=\"p\">(</span>\n    <span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s1\">'http://example-site.com/index.html'</span><span class=\"p\">,</span>\n    <span class=\"n\">project_folder</span><span class=\"o\">=</span><span class=\"s1\">'path/to/downloads'</span><span class=\"p\">,</span>\n    <span class=\"o\">**</span><span class=\"n\">kwargs</span>\n<span class=\"p\">)</span>\n</pre>\n<h3>1.3 Running Tests</h3>\n<p>Running tests is simple and doesn't require any external library.\nJust run this command from root directory of pywebcopy package.</p>\n<pre>$ python -m pywebcopy run-tests\n</pre>\n<h3>1.4 Command Line Interface</h3>\n<p><code>pywebcopy</code> have a very easy to use command-line interface which\ncan help you do task without having to worrying about the inner\nlong way.</p>\n<ul>\n<li>\n<h4>Getting list of commands</h4>\n<pre>$ python -m pywebcopy -- --help\n</pre>\n</li>\n<li>\n<h4>Using apis</h4>\n<pre>$ python -m pywebcopy save_webpage http://google.com E://store// --bypass_robots<span class=\"o\">=</span>True\nor\n$ python -m pywebcopy save_website http://google.com E://store// --bypass_robots\n</pre>\n</li>\n<li>\n<h4>Running tests</h4>\n<pre>$ python -m pywebcopy run_tests\n</pre>\n</li>\n</ul>\n<h3>1.5 Authentication and Cookies</h3>\n<p>Most of the time authentication is needed to access a certain page.\nIts real easy to authenticate with <code>pywebcopy</code> because it usage an\n<code>requests.Session</code> object for base http activity which can be accessed\nthrough <code>pywebcopy.SESSION</code> attribute. And as you know there\nare ton of tutorials on setting up authentication with <code>requests.Session</code>.</p>\n<p>Here is a basic example of simple http auth -</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pywebcopy</span>\n\n<span class=\"c1\"># Update the headers with suitable data</span>\n\n<span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">SESSION</span><span class=\"o\">.</span><span class=\"n\">headers</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">({</span>\n    <span class=\"s1\">'auth'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'username'</span><span class=\"p\">:</span> <span class=\"s1\">'password'</span><span class=\"p\">},</span>\n    <span class=\"s1\">'form'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s1\">'key1'</span><span class=\"p\">:</span> <span class=\"s1\">'value1'</span><span class=\"p\">},</span>\n<span class=\"p\">})</span>\n\n<span class=\"c1\"># Rest of the code is as usual</span>\n<span class=\"n\">kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'url'</span><span class=\"p\">:</span> <span class=\"s1\">'http://localhost:5000'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'project_folder'</span><span class=\"p\">:</span> <span class=\"s1\">'e://saved_pages//'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'project_name'</span><span class=\"p\">:</span> <span class=\"s1\">'my_site'</span>\n<span class=\"p\">}</span>\n<span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">setup_config</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n<span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">save_webpage</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre>\n<h3>2.1 <code>WebPage</code> class</h3>\n<p><code>WebPage</code> class, the engine of this saving actions.\nYou can use this class to access many more methods to\ncustomise the process with.</p>\n<ul>\n<li>\n<p>Creating the instance</p>\n<p>You can directly import this class from <code>pywebcopy</code> package.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span>    \n<span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n</pre>\n</li>\n<li>\n<p>fetching the html source from internet</p>\n<p>You can tell it to fetch the source from the\ninternet, it then uses <code>requests</code> module to fetch it\nfor you.</p>\n<p>You can pass in the several <code>params</code>\nwhich <code>requests.get()</code> would accept\ne.g. <em>proxies, auth etc.</em></p>\n<pre> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span>    \n <span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n\n <span class=\"c1\"># You can choose to load the page explicitly using </span>\n <span class=\"c1\"># `requests` module with params `requests` would take</span>\n\n <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s1\">'http://google.com'</span>\n <span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n     <span class=\"s1\">'auth'</span><span class=\"p\">:</span> <span class=\"s1\">'username@password'</span><span class=\"p\">,</span>\n     <span class=\"s1\">'proxies'</span><span class=\"p\">:</span> <span class=\"s1\">'localhost:5000'</span><span class=\"p\">,</span>\n <span class=\"p\">}</span>\n <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">params</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li>\n<p>providing your own opened file\nYou can also provide opened source handles\ndirectly</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span>    \n<span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># You can choose to set the source yourself</span>\n<span class=\"n\">handle</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'file.html'</span><span class=\"p\">,</span> <span class=\"s1\">'rb'</span><span class=\"p\">)</span>\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">set_source</span><span class=\"p\">(</span><span class=\"n\">handle</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ul>\n<h3>2.1.2  <code>WebPage</code> properties and methods</h3>\n<p>Apis which <code>WebPage</code> object exposes after creating\nthrough any method described above</p>\n<ul>\n<li>\n<p><code>.file_path</code> property\n<strong>Read-only</strong> location at which this file will end up\nwhen you try to save the parsed html source</p>\n<p>To change this location you have to manipulate the\n<code>.utx</code> property of the <code>WebPage</code> class. You can\nlook it up below.</p>\n</li>\n<li>\n<p><code>.project_path</code> property\n<strong>Read-only</strong> location at which all the files will end up\nwhen you try to save the complete webpage.</p>\n<p>To change this location you have to manipulate the\n<code>.utx</code> property of the <code>WebPage</code> class. You can\nlook it up below.</p>\n</li>\n<li>\n<p><code>.save_assets</code> method\nThis methods saves all the <code>css</code>, <code>js</code>, <code>images</code>, <code>fonts</code> etc.\nin the folder you setup through property <code>.project_path</code>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span>\n<span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'http://google.com'</span><span class=\"p\">)</span>\n\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_html</span><span class=\"p\">()</span>\n<span class=\"c1\">#&gt; a .html file would be saved at</span>\n</pre>\n</li>\n<li>\n<p><code>.save_html</code> method\nAfter setting up the <code>WebPage</code> instance you can\nuse this method to save a local copy of the parsed\nand modified html at <code>.file_path</code> property value.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span>\n<span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'http://google.com'</span><span class=\"p\">)</span>\n\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_html</span><span class=\"p\">()</span>\n<span class=\"c1\">#&gt; a .html file would be saved at location which</span>\n<span class=\"c1\">#&gt; `.file_path` property returns</span>\n</pre>\n</li>\n<li>\n<p><code>.save_complete</code> method\nThis is the important api which you would be using\nfrequently for saving or cloning a webpage for later\nreading or whatever the use case would be.</p>\n<p>This methods saves all the <code>css</code>, <code>js</code>, <code>images</code>, <code>fonts</code> etc.\nin the same order as a most browser would do when you will click on\nthe <code>save page</code> option in the right click menu.</p>\n<p>if you want complete webpage with css, js and images</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span>\n<span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'http://google.com'</span><span class=\"p\">)</span>\n\n<span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_complete</span><span class=\"p\">()</span>\n</pre>\n</li>\n</ul>\n<h2>3.1 Scrapings Support</h2>\n<p>Multiple scraping packages are wrapped up in one object\nwhich you can use to unlock the best of all those libraries\nat one go without having to go through the hassle of\ninstantiating each one of those libraries</p>\n<blockquote>\n<p>To use all the methods and properties documented below\njust create a object once as described</p>\n</blockquote>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">MultiParser</span>\n\n<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n\n<span class=\"n\">req</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'http://google.com'</span><span class=\"p\">)</span>\n\n<span class=\"n\">html</span> <span class=\"o\">=</span> <span class=\"n\">req</span><span class=\"o\">.</span><span class=\"n\">content</span>\n\n<span class=\"c1\"># You can skip the encoding declaration</span>\n<span class=\"c1\"># it is start enough to auto-detect :)</span>\n<span class=\"n\">encoding</span> <span class=\"o\">=</span> <span class=\"n\">req</span><span class=\"o\">.</span><span class=\"n\">encoding</span>\n\n<span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">MultiParser</span><span class=\"p\">(</span><span class=\"n\">html</span><span class=\"p\">,</span> <span class=\"n\">encoding</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># done</span>\n</pre>\n<blockquote>\n<p>All code follows above code</p>\n</blockquote>\n<ul>\n<li>\n<h4>BeautifulSoup methods are supported</h4>\n</li>\n</ul>\n<pre><code>you can also use any beautiful_soup methods on it\n\n```python\n&gt;&gt;&gt; links = wp.bs4.find_all('a')\n\n['//docs.python.org/3/tutorial/', '/about/apps/', 'https://github.com/python/pythondotorg/issues', '/accounts/login/', '/download/other/']\n\n```\n</code></pre>\n<ul>\n<li>\n<h4><code>lxml</code> is completely supported</h4>\n<p>You can use any lxml methods on it. Read more about lxml at <code>http://lxml.de/</code></p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">lxml</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'//a'</span><span class=\"p\">,</span> <span class=\"o\">..</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"o\">&lt;</span><span class=\"n\">Element</span> <span class=\"s1\">'a'</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"o\">&lt;</span><span class=\"n\">Element</span> <span class=\"s1\">'a'</span><span class=\"o\">&gt;</span><span class=\"p\">]</span>\n</pre>\n</li>\n<li>\n<h4><code>pyquery</code> is Fully supported</h4>\n<p>You can use PyQuery methods on it .Read more about pyquery at <code>https://pythonhosted.org/pyquery/</code></p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">pq</span><span class=\"o\">.</span><span class=\"n\">select</span><span class=\"p\">(</span><span class=\"n\">selector</span><span class=\"p\">,</span> <span class=\"o\">..</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n</pre>\n</li>\n<li>\n<h4><code>lxml.xpath</code> is also supported</h4>\n<p>xpath is also natively supported which retures a :class: <code>requests_html.Element</code>\nSee more at <code>https://html.python-requests.org</code></p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">xpath</span><span class=\"p\">(</span><span class=\"s1\">'a'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s1\">'&lt;Element '</span><span class=\"n\">a</span><span class=\"s1\">' class='</span><span class=\"n\">btn</span><span class=\"s1\">' href='</span><span class=\"n\">https</span><span class=\"p\">:</span><span class=\"o\">//</span><span class=\"n\">help</span><span class=\"o\">.</span><span class=\"n\">github</span><span class=\"o\">.</span><span class=\"n\">com</span><span class=\"o\">/</span><span class=\"n\">articles</span><span class=\"o\">/</span><span class=\"n\">supported</span><span class=\"o\">-</span><span class=\"n\">browsers</span><span class=\"s1\">'&gt;'</span><span class=\"p\">]</span>\n</pre>\n</li>\n<li>\n<h4>select only elements containing certain text</h4>\n<p>Provided through the <code>requests_html</code> module.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"n\">containing</span><span class=\"o\">=</span><span class=\"s1\">'kenneth'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"o\">&lt;</span><span class=\"n\">Element</span> <span class=\"s1\">'a'</span> <span class=\"n\">href</span><span class=\"o\">=</span><span class=\"s1\">'http://kennethreitz.com/pages'</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">]</span>\n</pre>\n</li>\n</ul>\n<h2><code>Crawler</code> object</h2>\n<p>This is a subclass of <code>WebPage</code> class and can be used to mirror any website.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">Crawler</span><span class=\"p\">,</span> <span class=\"n\">config</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s1\">'http://some-url.com/some-page.html'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">project_folder</span> <span class=\"o\">=</span> <span class=\"s1\">'/home/desktop/'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">project_name</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'bypass_robots'</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">}</span>\n<span class=\"c1\"># You should always start with setting up the config or use apis</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">setup_config</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">project_folder</span><span class=\"p\">,</span> <span class=\"n\">project_name</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Create a instance of the webpage object</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">Crawler</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># If you want to you can use `requests` to fetch the pages</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"p\">{</span><span class=\"s1\">'auth'</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"s1\">'username'</span><span class=\"p\">,</span> <span class=\"s1\">'password'</span><span class=\"p\">)})</span>\n\n<span class=\"c1\"># Then you can access several methods like</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">()</span>\n</pre>\n<h2>Common Settings and Errors</h2>\n<p>You can easily make a beginners mistake or could get confuse,\nthus here are the common errors and how to correct them if you\nare facing them.</p>\n<ol>\n<li>\n<p><code>pywebcopy.exceptions.AccessError</code></p>\n<p>If you are getting <code>pywebcopy.exceptions.AccessError</code> Exception.\nthen check if website allows scraping of its content.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pywebcopy</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">'bypass_robots'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n\n<span class=\"c1\"># rest of your code follows..</span>\n</pre>\n</li>\n<li>\n<p>Overwrite existing files when copying</p>\n<p>If you want to overwrite existing files in the directory then\nuse the over_write config key.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">pywebcopy</span>\n<span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">'over_write'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n\n<span class=\"c1\"># rest of your code follows..</span>\n</pre>\n</li>\n<li>\n<p>Changing your project name</p>\n<p>By default the pywebcopy creates a directory inside project_folder\nwith the url you have provided but you can change this using the code\nbelow</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pywebcopy</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">'project_name'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project'</span>\n\n<span class=\"c1\"># rest of your code follows..</span>\n</pre>\n</li>\n</ol>\n<h2>How to - Save Single Webpage</h2>\n<p>Particular webpage can be saved easily using the following methods.</p>\n<p>Note: if you get <code>pywebcopy.exceptions.AccessError</code> when running any of these code then use the code provided on later sections.</p>\n<h3>Method 1 : via api - <code>save_webpage()</code></h3>\n<p>Webpage can easily be saved using an inbuilt funtion called <code>.save_webpage()</code> which takes several\narguments also.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">save_webpage</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">save_webpage</span><span class=\"p\">(</span><span class=\"n\">project_url</span><span class=\"o\">=</span><span class=\"s1\">'http://google.com'</span><span class=\"p\">,</span> <span class=\"n\">project_folder</span><span class=\"o\">=</span><span class=\"s1\">'c://Saved_Webpages/'</span><span class=\"p\">,)</span>\n</pre>\n<h3>Method 2</h3>\n<p>This use case is slightly more powerful as it can provide every functionallity of the WebPage class.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span><span class=\"p\">,</span> <span class=\"n\">config</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s1\">'http://some-url.com/some-page.html'</span>\n\n<span class=\"c1\"># You should always start with setting up the config or use apis</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">setup_config</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">project_folder</span><span class=\"p\">,</span> <span class=\"n\">project_name</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Create a instance of the webpage object</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># If you want to use `requests` to fetch the page then</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Else if you want to use plain html or urllib then use</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">set_source</span><span class=\"p\">(</span><span class=\"n\">object_which_have_a_read_method</span><span class=\"p\">,</span> <span class=\"n\">encoding</span><span class=\"o\">=</span><span class=\"n\">encoding</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">url</span>   <span class=\"c1\"># you need to do this if you are using set_source()</span>\n\n<span class=\"c1\"># Then you can access several methods like</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_complete</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_html</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_assets</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># This Webpage object contains every methods of the Webpage() class and thus</span>\n<span class=\"c1\"># can be reused for later usages.</span>\n</pre>\n<h3>Method 2 using Plain HTML</h3>\n<p>I told you earlier that Webpage object is powerful and can be manipulated in any ways.</p>\n<p>One feature is that the raw html is now also accepted.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">WebPage</span><span class=\"p\">,</span> <span class=\"n\">config</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">HTML</span> <span class=\"o\">=</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">'test.html'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">base_url</span> <span class=\"o\">=</span> <span class=\"s1\">'http://example.com'</span> <span class=\"c1\"># used as a base for downloading imgs, css, js files.</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">project_folder</span> <span class=\"o\">=</span> <span class=\"s1\">'/saved_pages/'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">setup_config</span><span class=\"p\">(</span><span class=\"n\">base_url</span><span class=\"p\">,</span> <span class=\"n\">project_folder</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span> <span class=\"o\">=</span> <span class=\"n\">WebPage</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">set_source</span><span class=\"p\">(</span><span class=\"n\">HTML</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">base_url</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wp</span><span class=\"o\">.</span><span class=\"n\">save_complete</span><span class=\"p\">()</span>\n</pre>\n<h2>How to - Clone Whole Websites</h2>\n<p>Use caution when copying websites as this can overload or damage the\nservers of the site and rarely could be illegal, so check everything before\nyou proceed.</p>\n<h3>Method 1 : via api - <code>save_website()</code></h3>\n<p>Using the inbuilt api <code>.save_website()</code> which takes several arguments.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">save_website</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">save_website</span><span class=\"p\">(</span><span class=\"n\">project_url</span><span class=\"o\">=</span><span class=\"s1\">'http://localhost:8000'</span><span class=\"p\">,</span> <span class=\"n\">project_folder</span><span class=\"o\">=</span><span class=\"s1\">'e://tests/'</span><span class=\"p\">)</span>\n</pre>\n<h3>Method 2 -</h3>\n<p>By creating a Crawler() object which provides several other functions as well.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">Crawler</span><span class=\"p\">,</span> <span class=\"n\">config</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">setup_config</span><span class=\"p\">(</span><span class=\"n\">project_url</span><span class=\"o\">=</span><span class=\"s1\">'http://localhost:5000/'</span><span class=\"p\">,</span> \n<span class=\"n\">project_folder</span><span class=\"o\">=</span><span class=\"s1\">'e://tests/'</span><span class=\"p\">,</span> <span class=\"n\">project_name</span><span class=\"o\">=</span><span class=\"s1\">'LocalHost'</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">crawler</span> <span class=\"o\">=</span> <span class=\"n\">Crawler</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">crawler</span><span class=\"o\">.</span><span class=\"n\">crawl</span><span class=\"p\">()</span>\n</pre>\n<h2>1.3 Configuration</h2>\n<p><code>pywebcopy</code> is highly configurable. You can setup the global object\nusing the methods exposed by the <code>pywebcopy.config</code> object.</p>\n<p>Ways to change the global configurations are below -</p>\n<ul>\n<li>\n<p>Using the method <code>.setup_config</code>  on global <code>pywebcopy.config</code> object</p>\n<p>You can manually configure every configuration by using a\n<code>.setup_config</code> call.</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">import</span> <span class=\"nn\">pywebcopy</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s1\">'http://example-site.com/index.html'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">download_loc</span> <span class=\"o\">=</span> <span class=\"s1\">'path/to/downloads/'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">project</span> <span class=\"o\">=</span> <span class=\"s1\">'my_project'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">setup_config</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">,</span> <span class=\"n\">download_loc</span><span class=\"p\">,</span> <span class=\"n\">project</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n<span class=\"c1\"># done!</span>\n\n<span class=\"c1\"># Now check</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'project_url'</span><span class=\"p\">)</span>\n<span class=\"s1\">'http://example-site.com/index.html'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'project_folder'</span><span class=\"p\">)</span>\n<span class=\"s1\">'path/to/downloads'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'project_name'</span><span class=\"p\">)</span>\n<span class=\"s1\">'example-site.com'</span>\n\n<span class=\"c1\">## You can also change any config even after</span>\n<span class=\"c1\">## the `setup_config` call</span>\n\n<span class=\"n\">pywebcopy</span><span class=\"o\">.</span><span class=\"n\">config</span><span class=\"p\">[</span><span class=\"s1\">'url'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">'http://url-changed.com'</span>\n<span class=\"c1\"># rest of config remains unchanged</span>\n\n\n<span class=\"n\">Done</span><span class=\"err\">!</span>\n</pre>\n</li>\n<li>\n<p>Passing in the config vars directly to the</p>\n<p>global apis e.g. <code>.save_webpage</code></p>\n<p>To change any configuration, just pass it to the <code>api</code> call.</p>\n<p>Example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pywebcopy</span> <span class=\"kn\">import</span> <span class=\"n\">save_webpage</span>\n\n<span class=\"n\">kwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'project_url'</span><span class=\"p\">:</span> <span class=\"s1\">'http://google.com'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'project_folder'</span><span class=\"p\">:</span> <span class=\"s1\">'/home/pages/'</span><span class=\"p\">,</span>\n    <span class=\"s1\">'project_name'</span><span class=\"p\">:</span> \n    <span class=\"o\">...</span>\n<span class=\"p\">}</span>\n\n<span class=\"n\">save_webpage</span><span class=\"p\">(</span><span class=\"o\">**</span><span class=\"n\">kwargs</span><span class=\"p\">)</span>\n</pre>\n<h4>List of available <code>configurations</code></h4>\n<p>below is the list of <code>config</code> keys with their <code>default</code> values :</p>\n<pre><span class=\"c1\"># writes the trace output and log file content to console directly</span>\n<span class=\"s1\">'DEBUG'</span><span class=\"p\">:</span> <span class=\"kc\">False</span>  \n\n<span class=\"c1\"># make zip archive of the downloaded content</span>\n<span class=\"s1\">'zip_project_folder'</span><span class=\"p\">:</span> <span class=\"kc\">True</span>\n\n<span class=\"c1\"># delete the project folder after making zip archive of it</span>\n<span class=\"s1\">'delete_project_folder'</span><span class=\"p\">:</span> <span class=\"kc\">False</span>\n\n<span class=\"c1\"># to download css file or not</span>\n<span class=\"s1\">'LOAD_CSS'</span><span class=\"p\">:</span> <span class=\"kc\">True</span>\n\n<span class=\"c1\"># to download images or not</span>\n<span class=\"s1\">'LOAD_IMAGES'</span><span class=\"p\">:</span> <span class=\"kc\">True</span>\n\n<span class=\"c1\"># to download js file or not</span>\n<span class=\"s1\">'LOAD_JAVASCRIPT'</span><span class=\"p\">:</span> <span class=\"kc\">True</span>\n\n\n<span class=\"c1\"># to overwrite the existing files if found</span>\n<span class=\"s1\">'OVER_WRITE'</span><span class=\"p\">:</span> <span class=\"kc\">False</span>\n\n<span class=\"c1\"># list of allowed file extensions</span>\n<span class=\"c1\"># shortend for readability</span>\n<span class=\"s1\">'ALLOWED_FILE_EXT'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s1\">'.html'</span><span class=\"p\">,</span> <span class=\"s1\">'.css'</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># log file path</span>\n<span class=\"s1\">'LOG_FILE'</span><span class=\"p\">:</span> <span class=\"kc\">None</span>\n\n<span class=\"c1\"># name of the mirror project</span>\n<span class=\"s1\">'PROJECT_NAME'</span><span class=\"p\">:</span> <span class=\"n\">website</span><span class=\"o\">-</span><span class=\"n\">name</span><span class=\"o\">.</span><span class=\"n\">com</span>\n\n<span class=\"c1\"># define the base directory to store all copied sites data</span>\n<span class=\"s1\">'PROJECT_FOLDER'</span><span class=\"p\">:</span> <span class=\"kc\">None</span>\n\n\n<span class=\"c1\"># DANGER ZONE</span>\n<span class=\"c1\"># CHANGE THESE ON YOUR RESPONSIBILITY</span>\n<span class=\"c1\"># NOTE: Do not change unless you know what you're doing</span>\n\n<span class=\"c1\"># requests headers to be shown on requests made to server</span>\n<span class=\"s1\">'http_headers'</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"o\">...</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># bypass the robots.txt restrictions</span>\n<span class=\"s1\">'BYPASS_ROBOTS'</span> <span class=\"p\">:</span> <span class=\"kc\">False</span>\n</pre>\n</li>\n</ul>\n<h2>4.1 Contribution</h2>\n<p>You can contribute in many ways</p>\n<ul>\n<li>give it a star on github repo</li>\n<li>reporting bugs on github repo: <a href=\"https://github.com/rajatomar788/pywebcopy/\" rel=\"nofollow\">https://github.com/rajatomar788/pywebcopy/</a> or at my email.</li>\n<li>creating pull requests on github repo: <a href=\"https://github.com/rajatomar788/pywebcopy/\" rel=\"nofollow\">https://github.com/rajatomar788/pywebcopy/</a></li>\n<li>sending a thanks mail</li>\n</ul>\n<p>If you have any suggestions or fixes or reports feel free to mail me :)</p>\n<h2>5.1 Undocumented Features</h2>\n<p>I built many utils and classes in this project to ease\nthe tasks I was trying to do.</p>\n<p>But,\nthese task are also suitable for general purpose use.</p>\n<p>So,\nif you want, you can help in generating suitable <code>documentation</code> for these undocumented ones,\nthen you can always create and pull request or email me.</p>\n<h2>6.1 Changelog</h2>\n<h3>[version 6.0.0]</h3>\n<ul>\n<li><strong>Breaking Change</strong> New command-line interface using <code>Python Fire</code> library.</li>\n<li>Implemented type checks and path normalising in the <code>config.setup_paths</code>.</li>\n<li>added new dynamic <code>pywebcopy.__all__</code> attr generation.</li>\n<li><code>WebPage</code> class now doesnt take any argument <strong>(breaking change)</strong></li>\n<li><code>WebPage</code> class has new methods <code>WebPage.get</code> and <code>WebPage.set_source</code></li>\n<li>Queuing of downloads is replaced with a barrier to manage active threads</li>\n</ul>\n<h3>[version 5.x]</h3>\n<ul>\n<li>Optimization of existing code, upto 5x speed ups in certain cases</li>\n<li>Removed cluttering, improved readability</li>\n</ul>\n<h3>[version 4.x]</h3>\n<ul>\n<li><em>A complete rewrite and restructuring of core functionality.</em></li>\n</ul>\n<h3>[version 2.0.0]</h3>\n<h4>[changed]</h4>\n<ul>\n<li><code>core.setup_config</code> function is changed to <code>config.setup_config</code>.</li>\n</ul>\n<h4>[added]</h4>\n<ul>\n<li>added <code>utils.trace</code> decorator, which  will <strong>print</strong> <em>function_name</em>, <em>args</em>, <em>kwargs</em> and <em>return value</em> when debug config key is True.</li>\n<li>new html-parsers ('html5lib', 'lxml') are supported for better webpages.</li>\n<li>html-parser is now defaulted to 'lxml'. You can use any through new <code>config.config</code> key called <code>parser</code></li>\n</ul>\n<h4>[fixed]</h4>\n<ul>\n<li>fixed issue while changing <code>user-agent</code> key cracked webpages. You can now use any browser's user-agent id and it will get exact same page downloaded.</li>\n<li>fixed issue in <code>generators.extract_css_urls</code> which was caused by <code>str</code> and <code>bytes</code> difference in python3.</li>\n<li>fixed issues in modules importing. (Thanks \"<strong>\u0418\u043b\u044c\u044f \u0418\u0433\u043e\u0440\u0435\u0432\u0438\u0447</strong>\").</li>\n<li>added <code>errorhandling</code> to required functions</li>\n</ul>\n<h3>[version 2.0(beta)]</h3>\n<ul>\n<li><code>init</code> function is replaced with <code>save_webpage</code></li>\n<li>three new <code>config</code> automation functions are added -\n<ul>\n<li><code>core.setup_config</code> (creates every ideal config just from url and download location)</li>\n<li><code>config.reset_config</code> (resets the configuration to default state)</li>\n<li><code>config.update_config</code> (manual-mode version of <code>core.setup_config</code>)</li>\n</ul>\n</li>\n<li>object <code>structures.WebPage</code> added</li>\n<li>merged <code>generators.generate_style_map</code> and <code>generators.generate_relative_paths</code> to a single function <code>generators.generate_style_map</code></li>\n<li>rewrite of majority of functions</li>\n<li>new module <code>exceptions</code> added</li>\n</ul>\n<h3>[version 1.10]</h3>\n<ul>\n<li><code>url</code> is checked and resolved of any redirection before starting any work functions.</li>\n<li><code>init</code> vars : <code>mirrors_dir</code> and <code>clean_up</code> were fixed which cleaned the dir before the log was completely written.</li>\n<li><code>init</code> call now takes <code>url</code> arg by default and could raise a error when not supplied</li>\n<li>professional looking log entries</li>\n<li>rewritten archiving system now uses <code>zipfile</code> and <code>exceptions</code> handling to prevent errors and eventual archive corruption</li>\n</ul>\n<h3>[version 1.9]</h3>\n<ul>\n<li>more redundant code</li>\n<li>modules are now separated based on type e.g. Core, Generators, Utils etc.</li>\n<li>new helper functions and class <code>structures.WebPage</code></li>\n<li>Compatible with Python 2.6, 2.7, 3.6, 3.7</li>\n</ul>\n\n          </div>"}, "last_serial": 6954124, "releases": {"1.10": [{"comment_text": "", "digests": {"md5": "a3924d5286631978e6cf935964ccaaec", "sha256": "988fb03f5c752abfc84d54f441881db59f4f260f028ad19c34a79829908f68e7"}, "downloads": -1, "filename": "pywebcopy-1.10.tar.gz", "has_sig": false, "md5_digest": "a3924d5286631978e6cf935964ccaaec", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17364, "upload_time": "2018-08-04T12:18:58", "upload_time_iso_8601": "2018-08-04T12:18:58.178270Z", "url": "https://files.pythonhosted.org/packages/42/69/109cd004d7cf118bf9bee8a0595047d16fe5b4fb789c77e3abbb37e360e0/pywebcopy-1.10.tar.gz", "yanked": false}], "1.9": [{"comment_text": "", "digests": {"md5": "03bbd0e588a2e54534c6caf722e89e61", "sha256": "da93f13ec4b7937adbe61d6e54971930e7c4d185b27e9497e08f31725fb405de"}, "downloads": -1, "filename": "pywebcopy-1.9.tar.gz", "has_sig": false, "md5_digest": "03bbd0e588a2e54534c6caf722e89e61", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15870, "upload_time": "2018-07-23T11:54:27", "upload_time_iso_8601": "2018-07-23T11:54:27.867240Z", "url": "https://files.pythonhosted.org/packages/35/f2/7871cdc213fb32fea892bf01c1b1250837bbadfe4b6ad357dabfd6129b25/pywebcopy-1.9.tar.gz", "yanked": false}], "2.0.0b0": [{"comment_text": "", "digests": {"md5": "2ca91c5424cd46ae97aa730c34591985", "sha256": "f58cbb46e78a0efc4e535e084057283917c1d762e49e6e69785d77256a01aa9a"}, "downloads": -1, "filename": "pywebcopy-2.0.0b0.tar.gz", "has_sig": false, "md5_digest": "2ca91c5424cd46ae97aa730c34591985", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20072, "upload_time": "2018-08-11T15:13:34", "upload_time_iso_8601": "2018-08-11T15:13:34.348647Z", "url": "https://files.pythonhosted.org/packages/41/5c/ad2ba838e425adb11face6091d1d631b261ab11135c82049b9625ceda344/pywebcopy-2.0.0b0.tar.gz", "yanked": false}], "2.0.1": [{"comment_text": "", "digests": {"md5": "56bf61ac4a4f3b3a9da9406ce957c9c2", "sha256": "c86a3a0ffc94c44a260b4ec583828b4d274fa4e05feaf0f21be7dfa077bcaa62"}, "downloads": -1, "filename": "pywebcopy-2.0.1.tar.gz", "has_sig": false, "md5_digest": "56bf61ac4a4f3b3a9da9406ce957c9c2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22019, "upload_time": "2018-08-18T18:46:20", "upload_time_iso_8601": "2018-08-18T18:46:20.624878Z", "url": "https://files.pythonhosted.org/packages/00/5d/798026e4b30c6294d0797425f82199b09a29206fc0c6e7c6237923c3acb1/pywebcopy-2.0.1.tar.gz", "yanked": false}], "2.0.3": [{"comment_text": "", "digests": {"md5": "2b349316953f06021d1e2daee0ce0b08", "sha256": "13e5674ae7f6d3428d27810186fb9a136c73221339b962df5c3b1aa7e9451406"}, "downloads": -1, "filename": "pywebcopy-2.0.3.tar.gz", "has_sig": false, "md5_digest": "2b349316953f06021d1e2daee0ce0b08", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21603, "upload_time": "2018-08-19T13:23:40", "upload_time_iso_8601": "2018-08-19T13:23:40.964283Z", "url": "https://files.pythonhosted.org/packages/bc/dc/38a732b64ad96e36ffc4406c601be56ac3221a8aad195773a8a7e0c0d559/pywebcopy-2.0.3.tar.gz", "yanked": false}], "4.0.0": [{"comment_text": "", "digests": {"md5": "135eebd23d1572336d8006a7e3f93226", "sha256": "8d93ffa8df780516195920e920276411123d0ebb137b14f8f561105bc695bf52"}, "downloads": -1, "filename": "pywebcopy-4.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "135eebd23d1572336d8006a7e3f93226", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 42210, "upload_time": "2018-09-26T11:21:40", "upload_time_iso_8601": "2018-09-26T11:21:40.207846Z", "url": "https://files.pythonhosted.org/packages/17/30/07b1e32ea8b8bbb2d671fcee8c3616329b1cd31e811bc7dd11dcca069bc6/pywebcopy-4.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4f2d0a03a87e8a42586af9f6d23cc22c", "sha256": "b0c43e0a40b2ed2c2d84c342ef16de4d04b94716fcb9955483bbb663b8ebd061"}, "downloads": -1, "filename": "pywebcopy-4.0.0.tar.gz", "has_sig": false, "md5_digest": "4f2d0a03a87e8a42586af9f6d23cc22c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40653, "upload_time": "2018-09-26T11:21:42", "upload_time_iso_8601": "2018-09-26T11:21:42.206935Z", "url": "https://files.pythonhosted.org/packages/fb/52/81bf04403247c119a0ed426527ed02947007726567f8699be2f116cb4bd5/pywebcopy-4.0.0.tar.gz", "yanked": false}], "4.0.0rc0": [{"comment_text": "", "digests": {"md5": "3d0b6634b6f886a622c79143797c5e19", "sha256": "65e397d4e61c6d992ae6299cea7d794482151c169474c3d412e5b948066b8c0c"}, "downloads": -1, "filename": "pywebcopy-4.0.0rc0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3d0b6634b6f886a622c79143797c5e19", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 42219, "upload_time": "2018-09-26T10:58:56", "upload_time_iso_8601": "2018-09-26T10:58:56.538341Z", "url": "https://files.pythonhosted.org/packages/f1/7a/b1bf16e7dc2c21e19126c071c36b9b8f55f7ec5afe2c9d5a621871fc306a/pywebcopy-4.0.0rc0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f5243969673d00613c6506cf0b1c3f0b", "sha256": "694b68a50aae0b1cd68c9c9e2d0a34c646a8f8d3cf2d755a6397be344613d868"}, "downloads": -1, "filename": "pywebcopy-4.0.0rc0.tar.gz", "has_sig": false, "md5_digest": "f5243969673d00613c6506cf0b1c3f0b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40578, "upload_time": "2018-09-26T10:58:59", "upload_time_iso_8601": "2018-09-26T10:58:59.199640Z", "url": "https://files.pythonhosted.org/packages/58/fe/158e328fff45b79c1eb5b7c76a1d55db76ca37e9601a002aa4211bdc0f6e/pywebcopy-4.0.0rc0.tar.gz", "yanked": false}], "4.0.1": [{"comment_text": "", "digests": {"md5": "314f19a7d985088943b0a204faab06c1", "sha256": "aed8e30da0295c45835171e303bb8593ad5945ade1339dac796655b4c091037b"}, "downloads": -1, "filename": "pywebcopy-4.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "314f19a7d985088943b0a204faab06c1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 42200, "upload_time": "2018-10-31T13:50:27", "upload_time_iso_8601": "2018-10-31T13:50:27.467976Z", "url": "https://files.pythonhosted.org/packages/73/d4/b4cc759ffe1561feb523562838ecc47f499032efab8a83ba4269946a7ccb/pywebcopy-4.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4ec32426fe4fee7bebed2a03dc8e7225", "sha256": "36ed0c0028929f1b85175e83261beeeeb84cdaf9c7f6a92efa4df794837b8468"}, "downloads": -1, "filename": "pywebcopy-4.0.1.tar.gz", "has_sig": false, "md5_digest": "4ec32426fe4fee7bebed2a03dc8e7225", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40001, "upload_time": "2018-10-31T13:50:29", "upload_time_iso_8601": "2018-10-31T13:50:29.669070Z", "url": "https://files.pythonhosted.org/packages/f2/f0/d547462cfb8c3e99a3747df54c1b7dbd888b74998d10c3cc95799984fd7a/pywebcopy-4.0.1.tar.gz", "yanked": false}], "5.0.1": [{"comment_text": "", "digests": {"md5": "0ccc40a1ad9da12f12ca678f15589085", "sha256": "a57f978f4ee710f61ce801d841db9f6687a4ae665181e5925d4341688f663990"}, "downloads": -1, "filename": "pywebcopy-5.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0ccc40a1ad9da12f12ca678f15589085", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33367, "upload_time": "2019-01-06T09:25:58", "upload_time_iso_8601": "2019-01-06T09:25:58.148489Z", "url": "https://files.pythonhosted.org/packages/5c/78/c73e87960d6210a07c265c359bdeab9caf2b49bdb4f635febd38996975e6/pywebcopy-5.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6cfc4271b1ddfffc8fd05c9bee2fdde2", "sha256": "388910de9d007257e90c46adcc49652c194f2f8fe18a712e64fee5e1213bffae"}, "downloads": -1, "filename": "pywebcopy-5.0.1.tar.gz", "has_sig": false, "md5_digest": "6cfc4271b1ddfffc8fd05c9bee2fdde2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 34646, "upload_time": "2019-01-06T09:26:00", "upload_time_iso_8601": "2019-01-06T09:26:00.182232Z", "url": "https://files.pythonhosted.org/packages/a3/ae/afea657ab7ac8d20f10bf55282e0c698ea2b74e82c2da07b2c8dc0750516/pywebcopy-5.0.1.tar.gz", "yanked": false}], "6.0.0": [{"comment_text": "", "digests": {"md5": "21054e2219d542435630c59d9a4f6a63", "sha256": "07df846fa4b453b518693ed872dcfcd8223b126098139b20510f4531704db71c"}, "downloads": -1, "filename": "pywebcopy-6.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "21054e2219d542435630c59d9a4f6a63", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 48590, "upload_time": "2019-06-04T06:32:42", "upload_time_iso_8601": "2019-06-04T06:32:42.313843Z", "url": "https://files.pythonhosted.org/packages/ed/af/a0b901160908a3c5b4832441cbc25bba4efec2d9515acfe5345999c4031d/pywebcopy-6.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fa55c6bb87e40a7d17285b4a62161673", "sha256": "7ecbc4b4e6b943e41962b04fa4d20764806b8407af50503c201aed71e5a4680b"}, "downloads": -1, "filename": "pywebcopy-6.0.0.tar.gz", "has_sig": false, "md5_digest": "fa55c6bb87e40a7d17285b4a62161673", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 49813, "upload_time": "2019-06-04T06:32:44", "upload_time_iso_8601": "2019-06-04T06:32:44.663372Z", "url": "https://files.pythonhosted.org/packages/ff/f7/b27dfce53be7ac412adeeaca8bd232e1ed62e0519b1d003ae198b0a01783/pywebcopy-6.0.0.tar.gz", "yanked": false}], "6.1.0": [{"comment_text": "", "digests": {"md5": "00e6142b71b6f638bd39acde79916436", "sha256": "1e6729b86a7eeef310df6dbaa3a6bc18a2f72521a0b954e0f7b6ca17196e598f"}, "downloads": -1, "filename": "pywebcopy-6.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "00e6142b71b6f638bd39acde79916436", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 49503, "upload_time": "2019-12-06T06:13:31", "upload_time_iso_8601": "2019-12-06T06:13:31.152535Z", "url": "https://files.pythonhosted.org/packages/71/ea/11f0cb98d1fab9c58157b36cb8eed6d7c54a10c9e01b764c1994ec63d352/pywebcopy-6.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "33bd313833dd8be332b072c18b43d5b8", "sha256": "fb7d3110194442ba20f19ba59158f9d4ff9c11323b6e4de42e618eec4c404c3f"}, "downloads": -1, "filename": "pywebcopy-6.1.0.tar.gz", "has_sig": false, "md5_digest": "33bd313833dd8be332b072c18b43d5b8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50647, "upload_time": "2019-12-06T06:13:33", "upload_time_iso_8601": "2019-12-06T06:13:33.569664Z", "url": "https://files.pythonhosted.org/packages/77/a2/65c7dfff6f27daf973772667d9f1658bc3ccd70411e6205046c872c76b9b/pywebcopy-6.1.0.tar.gz", "yanked": false}], "6.1.1": [{"comment_text": "", "digests": {"md5": "9256f79d9094b657ab8c04d7d5f47199", "sha256": "6bd6864b0c388124315846de3113b661065e469620c5adeeefd4fb91502e6eed"}, "downloads": -1, "filename": "pywebcopy-6.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9256f79d9094b657ab8c04d7d5f47199", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 49579, "upload_time": "2019-12-08T08:38:12", "upload_time_iso_8601": "2019-12-08T08:38:12.985039Z", "url": "https://files.pythonhosted.org/packages/13/ae/3045edff70bd8c86479317cb9fde3dd42e39134f29235faca4ef4460dca8/pywebcopy-6.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "40cab7d704a1fb130c7534a0faf71909", "sha256": "1138c8197315de969b277bb3bb4018645b83bbf68613c980004144c7e02b156e"}, "downloads": -1, "filename": "pywebcopy-6.1.1.tar.gz", "has_sig": false, "md5_digest": "40cab7d704a1fb130c7534a0faf71909", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 50704, "upload_time": "2019-12-08T08:38:15", "upload_time_iso_8601": "2019-12-08T08:38:15.848602Z", "url": "https://files.pythonhosted.org/packages/96/46/55b8e478ff9e7c4c000c4e5b2aabee66c8d8b885752c4b3f4cae0dbc1f45/pywebcopy-6.1.1.tar.gz", "yanked": false}], "6.2.0": [{"comment_text": "", "digests": {"md5": "0fde5830acb248011c86a0eea1b3f33a", "sha256": "0062c300b01be9d25fbc2ed0848cfe19d0254099f8aff1f001d60154da635fcd"}, "downloads": -1, "filename": "pywebcopy-6.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "0fde5830acb248011c86a0eea1b3f33a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 51397, "upload_time": "2020-03-12T14:33:02", "upload_time_iso_8601": "2020-03-12T14:33:02.418130Z", "url": "https://files.pythonhosted.org/packages/93/fe/d0f556ee892ebeb9e707618b7b574e0306223d47c27493c1eacc36f75b1b/pywebcopy-6.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dbd5895be966ce073ecd9f3f22ec431b", "sha256": "f4c7da0c83da4f42ee44b1d9742eb77576a983e0c001db5248283ee1ecdc4426"}, "downloads": -1, "filename": "pywebcopy-6.2.0.tar.gz", "has_sig": false, "md5_digest": "dbd5895be966ce073ecd9f3f22ec431b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52341, "upload_time": "2020-03-12T14:33:04", "upload_time_iso_8601": "2020-03-12T14:33:04.585797Z", "url": "https://files.pythonhosted.org/packages/a9/5b/30cf40641c55dfc1da05e64fa75f4c06808636b7595cac73e58ce58d9854/pywebcopy-6.2.0.tar.gz", "yanked": false}], "6.3.0": [{"comment_text": "", "digests": {"md5": "4de9aa8a6f27cfae5fecad961729503c", "sha256": "835672f29794edb508f6a35f40c2678edacf538c9b2904033531795ed5df12c0"}, "downloads": -1, "filename": "pywebcopy-6.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4de9aa8a6f27cfae5fecad961729503c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 51397, "upload_time": "2020-04-05T05:57:57", "upload_time_iso_8601": "2020-04-05T05:57:57.998377Z", "url": "https://files.pythonhosted.org/packages/48/61/bf4a5685772fe16954c43810c3a8583fbef1ab33d66b3a25c54e7559fd0a/pywebcopy-6.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "923e70373f3e8b1a8d36b2101189f7f1", "sha256": "8dffa324220ce41b2bbf35f020a1e3456a7c2ea7f32895148695eab8264de924"}, "downloads": -1, "filename": "pywebcopy-6.3.0.tar.gz", "has_sig": false, "md5_digest": "923e70373f3e8b1a8d36b2101189f7f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52359, "upload_time": "2020-04-05T05:58:00", "upload_time_iso_8601": "2020-04-05T05:58:00.029495Z", "url": "https://files.pythonhosted.org/packages/69/c1/e9b8429a34ccbfa446a0a019a21303d9496823b31a2c80f8946cb114c130/pywebcopy-6.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4de9aa8a6f27cfae5fecad961729503c", "sha256": "835672f29794edb508f6a35f40c2678edacf538c9b2904033531795ed5df12c0"}, "downloads": -1, "filename": "pywebcopy-6.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4de9aa8a6f27cfae5fecad961729503c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 51397, "upload_time": "2020-04-05T05:57:57", "upload_time_iso_8601": "2020-04-05T05:57:57.998377Z", "url": "https://files.pythonhosted.org/packages/48/61/bf4a5685772fe16954c43810c3a8583fbef1ab33d66b3a25c54e7559fd0a/pywebcopy-6.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "923e70373f3e8b1a8d36b2101189f7f1", "sha256": "8dffa324220ce41b2bbf35f020a1e3456a7c2ea7f32895148695eab8264de924"}, "downloads": -1, "filename": "pywebcopy-6.3.0.tar.gz", "has_sig": false, "md5_digest": "923e70373f3e8b1a8d36b2101189f7f1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52359, "upload_time": "2020-04-05T05:58:00", "upload_time_iso_8601": "2020-04-05T05:58:00.029495Z", "url": "https://files.pythonhosted.org/packages/69/c1/e9b8429a34ccbfa446a0a019a21303d9496823b31a2c80f8946cb114c130/pywebcopy-6.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:11:35 2020"}