{"info": {"author": "Pete Warden", "author_email": "pete@mailana.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: BSD License", "Topic :: Utilities"], "description": "ParallelCurl\n~~~~~~~~~~~~~~~\n\nThis module provides an easy-to-use interface to allow you to run multiple CURL url fetches in\nparallel in Python, without threads. \n\nTo test it, go to the command line, cd to this folder and run\n\n./test.py\n\nThis should run 100 searches through Google's API, printing the results. To see what sort of\nperformance difference running parallel requests gets you, try altering the default of 10 requests\nrunning in parallel using the optional script argument, and timing how long each takes:\n\ntime ./test.py 1\ntime ./test.py 20\n\nThe first only allows one request to run at once, serializing the calls. I see this taking around\n100 seconds. The second run has 20 in flight at a time, and takes 11 seconds! Be warned though,\nit's possible to overwhelm your target if you fire too many requests at once. You may end up\nwith your IP banned from accessing that server, or hit other API limits.\n\nThe class is designed to make it easy to run multiple curl requests in parallel, rather than\nwaiting for each one to finish before starting the next. Under the hood it uses curl_multi_exec\nbut since I find that interface painfully confusing, I wanted one that corresponded to the tasks\nthat I wanted to run.\n\nTo use it, easy_install pycurl, import pyparallelcurl, then create the ParallelCurl object:\n\nparallelcurl = ParallelCurl(10)\n\nThe first argument to the constructor is the maximum number of outstanding fetches to allow\nbefore blocking to wait for one to finish. You can change this later using setmaxrequests()\nThe second optional argument is an array of curl options in the format used by curl_setopt_array()\n\nNext, start a URL fetch:\n\nparallelcurl.startRequest('http://example.com', on_request_done, {'somekey':'somevalue'})\n\nThe first argument is the address that should be fetched\nThe second is the callback function that will be run once the request is done\nThe third is a 'cookie', that can contain arbitrary data to be passed to the callback\n\nThis startRequest call will return immediately, as long as less than the maximum number of\nrequests are outstanding. Once the request is done, the callback function will be called, eg:\n\non_request_done(content, 'http://example.com', ch, {'somekey':'somevalue'})\n\nThe callback should take four arguments. The first is a string containing the content found at\nthe URL. The second is the original URL requested, the third is the curl handle of the request that\ncan be queried to get the results, and the fourth is the arbitrary 'cookie' value that you \nassociated with this object. This cookie contains user-defined data.\n\nSince you may have requests outstanding at the end of your script, you *MUST* call\n\nparallelcurl.finishallrequests()\n\nbefore you exit. If you don't, the final requests may be left unprocessed! This is actually also\ncalled in the destructor of the class, but it's definitely best practice to call this explictly.\n\nBy Pete Warden <pete@petewarden.com>, freely reusable, see http://petewarden.typepad.com for more", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://packages.python.org/pyparallelcurl", "keywords": "curl parallel", "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "pyparallelcurl", "package_url": "https://pypi.org/project/pyparallelcurl/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/pyparallelcurl/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://packages.python.org/pyparallelcurl"}, "release_url": "https://pypi.org/project/pyparallelcurl/0.0.4/", "requires_dist": null, "requires_python": null, "summary": "A simple interface for fetching URL resources in parallel without threads", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>This module provides an easy-to-use interface to allow you to run multiple CURL url fetches in\nparallel in Python, without threads.</p>\n<p>To test it, go to the command line, cd to this folder and run</p>\n<p>./test.py</p>\n<p>This should run 100 searches through Google\u2019s API, printing the results. To see what sort of\nperformance difference running parallel requests gets you, try altering the default of 10 requests\nrunning in parallel using the optional script argument, and timing how long each takes:</p>\n<p>time ./test.py 1\ntime ./test.py 20</p>\n<p>The first only allows one request to run at once, serializing the calls. I see this taking around\n100 seconds. The second run has 20 in flight at a time, and takes 11 seconds! Be warned though,\nit\u2019s possible to overwhelm your target if you fire too many requests at once. You may end up\nwith your IP banned from accessing that server, or hit other API limits.</p>\n<p>The class is designed to make it easy to run multiple curl requests in parallel, rather than\nwaiting for each one to finish before starting the next. Under the hood it uses curl_multi_exec\nbut since I find that interface painfully confusing, I wanted one that corresponded to the tasks\nthat I wanted to run.</p>\n<p>To use it, easy_install pycurl, import pyparallelcurl, then create the ParallelCurl object:</p>\n<p>parallelcurl = ParallelCurl(10)</p>\n<p>The first argument to the constructor is the maximum number of outstanding fetches to allow\nbefore blocking to wait for one to finish. You can change this later using setmaxrequests()\nThe second optional argument is an array of curl options in the format used by curl_setopt_array()</p>\n<p>Next, start a URL fetch:</p>\n<p>parallelcurl.startRequest(\u2018<a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>\u2019, on_request_done, {\u2018somekey\u2019:\u2019somevalue\u2019})</p>\n<p>The first argument is the address that should be fetched\nThe second is the callback function that will be run once the request is done\nThe third is a \u2018cookie\u2019, that can contain arbitrary data to be passed to the callback</p>\n<p>This startRequest call will return immediately, as long as less than the maximum number of\nrequests are outstanding. Once the request is done, the callback function will be called, eg:</p>\n<p>on_request_done(content, \u2018<a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>\u2019, ch, {\u2018somekey\u2019:\u2019somevalue\u2019})</p>\n<p>The callback should take four arguments. The first is a string containing the content found at\nthe URL. The second is the original URL requested, the third is the curl handle of the request that\ncan be queried to get the results, and the fourth is the arbitrary \u2018cookie\u2019 value that you\nassociated with this object. This cookie contains user-defined data.</p>\n<p>Since you may have requests outstanding at the end of your script, you <em>MUST</em> call</p>\n<p>parallelcurl.finishallrequests()</p>\n<p>before you exit. If you don\u2019t, the final requests may be left unprocessed! This is actually also\ncalled in the destructor of the class, but it\u2019s definitely best practice to call this explictly.</p>\n<p>By Pete Warden &lt;<a href=\"mailto:pete%40petewarden.com\">pete<span>@</span>petewarden<span>.</span>com</a>&gt;, freely reusable, see <a href=\"http://petewarden.typepad.com\" rel=\"nofollow\">http://petewarden.typepad.com</a> for more</p>\n\n          </div>"}, "last_serial": 797508, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "c8c9a378e785457ea6cdb46fbe9afdfa", "sha256": "810fa1d3108db902b9e5174e0ece9ee5f52f0379b5463afedadc30c54c9e6369"}, "downloads": -1, "filename": "pyparallelcurl-0.0.2-py2.6.egg", "has_sig": false, "md5_digest": "c8c9a378e785457ea6cdb46fbe9afdfa", "packagetype": "bdist_egg", "python_version": "2.6", "requires_python": null, "size": 10576, "upload_time": "2010-10-14T01:30:12", "upload_time_iso_8601": "2010-10-14T01:30:12.047397Z", "url": "https://files.pythonhosted.org/packages/cf/b7/2db67edf064feffb109ff08244264fbf57ccdab8dc26b79214ae09b446c3/pyparallelcurl-0.0.2-py2.6.egg", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "ee1ea303d8f9be7d22f5e6b18798f55d", "sha256": "6339534518468d4281a0dafe28c3b172e99ac14b776bd7ddcdf0da0306b86d6a"}, "downloads": -1, "filename": "pyparallelcurl-0.0.3-py2.6.egg", "has_sig": false, "md5_digest": "ee1ea303d8f9be7d22f5e6b18798f55d", "packagetype": "bdist_egg", "python_version": "2.6", "requires_python": null, "size": 10689, "upload_time": "2010-10-14T01:43:52", "upload_time_iso_8601": "2010-10-14T01:43:52.514159Z", "url": "https://files.pythonhosted.org/packages/77/1b/42d38982716452cd2064c2059d4ad7d991700318771cf3ca7733ec2036a4/pyparallelcurl-0.0.3-py2.6.egg", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "547135676f01e83338fb36dd78765360", "sha256": "92653b2830d893966fdf366935624be89a94382b63aad3c8b5d5cf377102e7e6"}, "downloads": -1, "filename": "pyparallelcurl-0.0.4-py2.6.egg", "has_sig": false, "md5_digest": "547135676f01e83338fb36dd78765360", "packagetype": "bdist_egg", "python_version": "2.6", "requires_python": null, "size": 10691, "upload_time": "2010-10-14T01:48:44", "upload_time_iso_8601": "2010-10-14T01:48:44.777091Z", "url": "https://files.pythonhosted.org/packages/98/21/78811ee75e6856f2b4fbce2c7e3c31ce8ca488390e22b03da8370892556d/pyparallelcurl-0.0.4-py2.6.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "547135676f01e83338fb36dd78765360", "sha256": "92653b2830d893966fdf366935624be89a94382b63aad3c8b5d5cf377102e7e6"}, "downloads": -1, "filename": "pyparallelcurl-0.0.4-py2.6.egg", "has_sig": false, "md5_digest": "547135676f01e83338fb36dd78765360", "packagetype": "bdist_egg", "python_version": "2.6", "requires_python": null, "size": 10691, "upload_time": "2010-10-14T01:48:44", "upload_time_iso_8601": "2010-10-14T01:48:44.777091Z", "url": "https://files.pythonhosted.org/packages/98/21/78811ee75e6856f2b4fbce2c7e3c31ce8ca488390e22b03da8370892556d/pyparallelcurl-0.0.4-py2.6.egg", "yanked": false}], "timestamp": "Fri May  8 02:59:56 2020"}