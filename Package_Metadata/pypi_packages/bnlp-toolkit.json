{"info": {"author": "Sagor Sarker", "author_email": "sagorhem3532@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Bengali Natural Language Processing(BNLP)\n\n[![Build Status](https://travis-ci.org/sagorbrur/bnlp.svg?branch=master)](https://travis-ci.org/sagorbrur/bnlp)\n[![PyPI version](https://img.shields.io/pypi/v/bnlp_toolkit)](https://pypi.org/project/bnlp-toolkit/)\n[![release version](https://img.shields.io/github/v/release/sagorbrur/bnlp)](https://github.com/sagorbrur/bnlp/releases/tag/2.0.0)\n[![Support Python Version](https://img.shields.io/badge/python-3.5%7C3.6%7C3.7-brightgreen)](https://pypi.org/project/bnlp-toolkit/)\n[![Documentation Status](https://readthedocs.org/projects/bnlp/badge/?version=latest)](https://bnlp.readthedocs.io/en/latest/?badge=latest)\n[![Gitter](https://badges.gitter.im/bnlp_toolkit/community.svg)](https://gitter.im/bnlp_toolkit/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\nBNLP is a natural language processing toolkit for Bengali Language. This tool will help you to **tokenize Bengali text**, **Embedding Bengali words**, **Bengali POS Tagging**, **Construct Neural Model** for Bengali NLP purposes.\n\n\n# Contents\n- [Current Features](#current-features)\n- [Installation](#installation)\n- [Pretrained Model](#pretrained-model)\n- [Tokenization](#tokenization)\n- [Embedding](#word-embedding)\n- [POS Tagging](#bengali-pos-tagging)\n- [Issue](#issue)\n- [Contributor Guide](#contributor-guide)\n- [Contributor List](#contributor-list)\n\n\n## Current Features\n* [Bengali Tokenization](#tokenization)\n  - SentencePiece Tokenizer\n  - Basic Tokenizer\n  - NLTK Tokenizer\n* [Bengali Word Embedding](#word-embedding)\n  - Bengali Word2Vec\n  - Bengali Fasttext\n  - Bengali GloVe\n\n* [Bengali POS Tagging](#bengali-pos-tagging)\n\n\n## Installation\n\n### PIP installer(python 3.5, 3.6, 3.7 tested okay)\n\n  ```pip install bnlp_toolkit```\n\n### Local Installer\n  ```\n  $git clone https://github.com/sagorbrur/bnlp.git\n  $cd bnlp\n  $python setup.py install\n  ```\n\n\n\n## Pretrained Model\n\n### Download Link\n\n* [Bengali SentencePiece](https://github.com/sagorbrur/bnlp/tree/master/model)\n* [Bengali Word2Vec](https://drive.google.com/open?id=1DxR8Vw61zRxuUm17jzFnOX97j7QtNW7U)\n* [Bengali FastText](https://drive.google.com/open?id=1CFA-SluRyz3s5gmGScsFUcs7AjLfscm2)\n* [Bengali GloVe Wordvectors](https://github.com/sagorbrur/GloVe-Bengali)\n* [Bengali POS Tag model](https://github.com/sagorbrur/bnlp/blob/master/model/bn_pos_model.pkl)\n\n### Training Details\n* Sentencepiece, Word2Vec, Fasttext, GloVe model trained with **Bengali Wikipedia Dump Dataset**\n  - [Bengali Wiki Dump](https://dumps.wikimedia.org/bnwiki/latest/)\n* SentencePiece Training Vocab Size=50000\n* Fasttext trained with total words = 20M, vocab size = 1171011, epoch=50, embedding dimension = 300 and the training loss = 0.318668,\n* Word2Vec word embedding dimension = 300\n* To Know Bengali GloVe Wordvector and training process follow [this](https://github.com/sagorbrur/GloVe-Bengali) repository\n* Bengali CRF POS Tagging was training with [nltr](https://github.com/abhishekgupta92/bangla_pos_tagger/tree/master/data) dataset with 80% accuracy. \n\n\n## Tokenization\n\n* **Bengali SentencePiece Tokenization**\n\n  - tokenization using trained model\n    ```py\n    from bnlp.sentencepiece_tokenizer import SP_Tokenizer\n\n    bsp = SP_Tokenizer()\n    model_path = \"./model/bn_spm.model\"\n    input_text = \"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964\"\n    tokens = bsp.tokenize(model_path, input_text)\n    print(tokens)\n    text2id = bsp.text2id(model_path, input_text)\n    print(text2id)\n    id2text = bsp.id2text(model_path, text2id)\n    print(id2text)\n\n    ```\n  - Training SentencePiece\n    ```py\n    from bnlp.sentencepiece_tokenizer import SP_Tokenizer\n\n    bsp = SP_Tokenizer()\n    data = \"test.txt\"\n    model_prefix = \"test\"\n    vocab_size = 5\n    bsp.train_bsp(data, model_prefix, vocab_size) \n\n    ```\n\n* **Basic Tokenizer**\n\n\n\n  ```py\n  from bnlp.basic_tokenizer import BasicTokenizer\n  basic_t = BasicTokenizer()\n  raw_text = \"\u0986\u09ae\u09bf \u09ac\u09be\u0982\u09b2\u09be\u09df \u0997\u09be\u09a8 \u0997\u09be\u0987\u0964\"\n  tokens = basic_t.tokenize(raw_text)\n  print(tokens)\n\n  # output: [\"\u0986\u09ae\u09bf\", \"\u09ac\u09be\u0982\u09b2\u09be\u09df\", \"\u0997\u09be\u09a8\", \"\u0997\u09be\u0987\", \"\u0964\"]\n\n  ```\n\n* **NLTK Tokenization**\n\n  ```py\n  from bnlp.nltk_tokenizer import NLTK_Tokenizer\n\n  text = \"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964 \u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?\"\n  bnltk = NLTK_Tokenizer()\n  word_tokens = bnltk.word_tokenize(text)\n  sentence_tokens = bnltk.sentence_tokenize(text)\n  print(word_tokens)\n  print(sentence_tokens)\n\n  # output\n  # word_token: [\"\u0986\u09ae\u09bf\", \"\u09ad\u09be\u09a4\", \"\u0996\u09be\u0987\", \"\u0964\", \"\u09b8\u09c7\", \"\u09ac\u09be\u099c\u09be\u09b0\u09c7\", \"\u09af\u09be\u09df\", \"\u0964\", \"\u09a4\u09bf\u09a8\u09bf\", \"\u0995\u09bf\", \"\u09b8\u09a4\u09cd\u09af\u09bf\u0987\", \"\u09ad\u09be\u09b2\u09cb\", \"\u09ae\u09be\u09a8\u09c1\u09b7\", \"?\"]\n  # sentence_token: [\"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964\", \"\u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964\", \"\u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?\"]\n\n  ```\n\n\n## Word Embedding\n\n* **Bengali Word2Vec**\n\n  - Generate Vector using pretrain model\n\n    ```py\n    from bnlp.bengali_word2vec import Bengali_Word2Vec\n\n    bwv = Bengali_Word2Vec()\n    model_path = \"model/bengali_word2vec.model\"\n    word = '\u0986\u09ae\u09be\u09b0'\n    vector = bwv.generate_word_vector(model_path, word)\n    print(vector.shape)\n    print(vector)\n\n    ```\n\n  - Find Most Similar Word Using Pretrained Model\n\n    ```py\n    from bnlp.bengali_word2vec import Bengali_Word2Vec\n\n    bwv = Bengali_Word2Vec()\n    model_path = \"model/bengali_word2vec.model\"\n    word = '\u0986\u09ae\u09be\u09b0'\n    similar = bwv.most_similar(model_path, word)\n    print(similar)\n\n    ```\n  - Train Bengali Word2Vec with your own data\n\n    ```py\n    from bnlp.bengali_word2vec import Bengali_Word2Vec\n    bwv = Bengali_Word2Vec()\n    data_file = \"test.txt\"\n    model_name = \"test_model.model\"\n    vector_name = \"test_vector.vector\"\n    bwv.train_word2vec(data_file, model_name, vector_name)\n\n\n    ```\n\n * **Bengali FastText**\n\n\n    - Generate Vector Using Pretrained Model\n\n\n      ```py\n      from bnlp.bengali_fasttext import Bengali_Fasttext\n\n      bft = Bengali_Fasttext()\n      word = \"\u0997\u09cd\u09b0\u09be\u09ae\"\n      model_path = \"model/bengali_fasttext.bin\"\n      word_vector = bft.generate_word_vector(model_path, word)\n      print(word_vector.shape)\n      print(word_vector)\n\n\n      ```\n    - Train Bengali FastText Model\n\n      ```py\n      from bnlp.bengali_fasttext import Bengali_Fasttext\n\n      bft = Bengali_Fasttext()\n      data = \"data.txt\"\n      model_name = \"saved_model.bin\"\n      epoch = 50\n      bft.train_fasttext(data, model_name, epoch)\n      ```\n\n* **Bengali GloVe Word Vectors**\n\n  We trained glove model with bengali data(wiki+news articles) and published bengali glove word vectors</br>\n  You can download and use it on your different machine learning purposes.\n\n  ```py\n  from bnlp.glove_wordvector import BN_Glove\n  glove_path = \"bn_glove.39M.100d.txt\"\n  word = \"\u0997\u09cd\u09b0\u09be\u09ae\"\n  bng = BN_Glove()\n  res = bng.closest_word(glove_path, word)\n  print(res)\n  vec = bng.word2vec(glove_path, word)\n  print(vec)\n\n  ```\n\n## Bengali POS Tagging\n* **Bengali CRF POS Tagging** \n\n\n  - Find Pos Tag Using Pretrained Model\n\n    ```py\n    from bnlp.bengali_pos import BN_CRF_POS\n    bn_pos = BN_CRF_POS()\n    model_path = \"model/bn_pos_model.pkl\"\n    text = \"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964\"\n    res = bn_pos.pos_tag(model_path, text)\n    print(res)\n    # [('\u0986\u09ae\u09bf', 'PPR'), ('\u09ad\u09be\u09a4', 'NC'), ('\u0996\u09be\u0987', 'VM'), ('\u0964', 'PU')]\n\n    ```\n  - Train POS Tag Model\n\n    ```py\n    from bnlp.bengali_pos import BN_CRF_POS\n    bn_pos = BN_CRF_POS()\n    model_name = \"pos_model.pkl\"\n    tagged_sentences = [[('\u09b0\u09aa\u09cd\u09a4\u09be\u09a8\u09bf', 'JJ'), ('\u09a6\u09cd\u09b0\u09ac\u09cd\u09af', 'NC'), ('-', 'PU'), ('\u09a4\u09be\u099c\u09be', 'JJ'), ('\u0993', 'CCD'), ('\u09b6\u09c1\u0995\u09a8\u09be', 'JJ'), ('\u09ab\u09b2', 'NC'), (',', 'PU'), ('\u0986\u09ab\u09bf\u09ae', 'NC'), (',', 'PU'), ('\u09aa\u09b6\u09c1\u099a\u09b0\u09cd\u09ae', 'NC'), ('\u0993', 'CCD'), ('\u09aa\u09b6\u09ae', 'NC'), ('\u098f\u09ac\u0982', 'CCD'),('\u0995\u09be\u09b0\u09cd\u09aa\u09c7\u099f', 'NC'), ('\u09f7', 'PU')], [('\u09ae\u09be\u099f\u09bf', 'NC'), ('\u09a5\u09c7\u0995\u09c7', 'PP'), ('\u09ac\u09dc\u099c\u09cb\u09b0', 'JQ'), ('\u099a\u09be\u09b0', 'JQ'), ('\u09aa\u09be\u0981\u099a', 'JQ'), ('\u09ab\u09c1\u099f', 'CCL'), ('\u0989\u0981\u099a\u09c1', 'JJ'), ('\u09b9\u09ac\u09c7', 'VM'), ('\u09f7', 'PU')]]\n\n    bn_pos.training(model_name, tagged_sentences)\n\n    ```\n\n## Issue\n* if `ModuleNotFoundError: No module named 'fasttext'` problem arise please do the next line\n\n```pip install fasttext```\n* if `nltk` issue arise please do the following line before importing `bnlp`\n\n```py\nimport nltk\nnltk.download(\"punkt\")\n```\n\n\n## Contributor Guide\n\nCheck [CONTRIBUTING.md](https://github.com/sagorbrur/bnlp/blob/master/CONTRIBUTING.md) page for details.\n\n\n## Thanks To\n\n* [Semantics Lab](http://semanticslab.net/)\n\n## Contributor List\n\n[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/0)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/0)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/1)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/1)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/2)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/2)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/3)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/3)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/4)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/4)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/5)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/5)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/6)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/6)[![](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/images/7)](https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/7)\n\n### Extra Contributor\n* [Mehadi Hasan Menon](https://github.com/menon92)\n* [Kazal Chandra Barman](https://github.com/kazalbrur)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sagorbrur/bnlp", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "bnlp-toolkit", "package_url": "https://pypi.org/project/bnlp-toolkit/", "platform": "", "project_url": "https://pypi.org/project/bnlp-toolkit/", "project_urls": {"Homepage": "https://github.com/sagorbrur/bnlp"}, "release_url": "https://pypi.org/project/bnlp-toolkit/2.2/", "requires_dist": ["sentencepiece", "gensim", "nltk", "fasttext", "numpy", "scipy", "sklearn-crfsuite"], "requires_python": ">=3.5", "summary": "BNLP is a natural language processing toolkit for Bengali Language", "version": "2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Bengali Natural Language Processing(BNLP)</h1>\n<p><a href=\"https://travis-ci.org/sagorbrur/bnlp\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/84dbeb0b0d8c3eec59a468dceef9e046ba98ccc0/68747470733a2f2f7472617669732d63692e6f72672f7361676f72627275722f626e6c702e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pypi.org/project/bnlp-toolkit/\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7b71c5605f352aba48f4e22d06a20804b844b4b0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f626e6c705f746f6f6c6b6974\"></a>\n<a href=\"https://github.com/sagorbrur/bnlp/releases/tag/2.0.0\" rel=\"nofollow\"><img alt=\"release version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a7d48b0bf647a7ad9a9d3e0bda3605d7bbb278b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f7361676f72627275722f626e6c70\"></a>\n<a href=\"https://pypi.org/project/bnlp-toolkit/\" rel=\"nofollow\"><img alt=\"Support Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/49f15865409ae608d9ae45b51566525a09676941/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e35253743332e36253743332e372d627269676874677265656e\"></a>\n<a href=\"https://bnlp.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8d65e69af6563fadc9dc9bd2d980b073d7b4363b/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f626e6c702f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<a href=\"https://gitter.im/bnlp_toolkit/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge\" rel=\"nofollow\"><img alt=\"Gitter\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bed92c4d62de6c793f64d12f8da1e0fd887145fc/68747470733a2f2f6261646765732e6769747465722e696d2f626e6c705f746f6f6c6b69742f636f6d6d756e6974792e737667\"></a></p>\n<p>BNLP is a natural language processing toolkit for Bengali Language. This tool will help you to <strong>tokenize Bengali text</strong>, <strong>Embedding Bengali words</strong>, <strong>Bengali POS Tagging</strong>, <strong>Construct Neural Model</strong> for Bengali NLP purposes.</p>\n<h1>Contents</h1>\n<ul>\n<li><a href=\"#current-features\" rel=\"nofollow\">Current Features</a></li>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#pretrained-model\" rel=\"nofollow\">Pretrained Model</a></li>\n<li><a href=\"#tokenization\" rel=\"nofollow\">Tokenization</a></li>\n<li><a href=\"#word-embedding\" rel=\"nofollow\">Embedding</a></li>\n<li><a href=\"#bengali-pos-tagging\" rel=\"nofollow\">POS Tagging</a></li>\n<li><a href=\"#issue\" rel=\"nofollow\">Issue</a></li>\n<li><a href=\"#contributor-guide\" rel=\"nofollow\">Contributor Guide</a></li>\n<li><a href=\"#contributor-list\" rel=\"nofollow\">Contributor List</a></li>\n</ul>\n<h2>Current Features</h2>\n<ul>\n<li>\n<p><a href=\"#tokenization\" rel=\"nofollow\">Bengali Tokenization</a></p>\n<ul>\n<li>SentencePiece Tokenizer</li>\n<li>Basic Tokenizer</li>\n<li>NLTK Tokenizer</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#word-embedding\" rel=\"nofollow\">Bengali Word Embedding</a></p>\n<ul>\n<li>Bengali Word2Vec</li>\n<li>Bengali Fasttext</li>\n<li>Bengali GloVe</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#bengali-pos-tagging\" rel=\"nofollow\">Bengali POS Tagging</a></p>\n</li>\n</ul>\n<h2>Installation</h2>\n<h3>PIP installer(python 3.5, 3.6, 3.7 tested okay)</h3>\n<p><code>pip install bnlp_toolkit</code></p>\n<h3>Local Installer</h3>\n<pre><code>$git clone https://github.com/sagorbrur/bnlp.git\n$cd bnlp\n$python setup.py install\n</code></pre>\n<h2>Pretrained Model</h2>\n<h3>Download Link</h3>\n<ul>\n<li><a href=\"https://github.com/sagorbrur/bnlp/tree/master/model\" rel=\"nofollow\">Bengali SentencePiece</a></li>\n<li><a href=\"https://drive.google.com/open?id=1DxR8Vw61zRxuUm17jzFnOX97j7QtNW7U\" rel=\"nofollow\">Bengali Word2Vec</a></li>\n<li><a href=\"https://drive.google.com/open?id=1CFA-SluRyz3s5gmGScsFUcs7AjLfscm2\" rel=\"nofollow\">Bengali FastText</a></li>\n<li><a href=\"https://github.com/sagorbrur/GloVe-Bengali\" rel=\"nofollow\">Bengali GloVe Wordvectors</a></li>\n<li><a href=\"https://github.com/sagorbrur/bnlp/blob/master/model/bn_pos_model.pkl\" rel=\"nofollow\">Bengali POS Tag model</a></li>\n</ul>\n<h3>Training Details</h3>\n<ul>\n<li>Sentencepiece, Word2Vec, Fasttext, GloVe model trained with <strong>Bengali Wikipedia Dump Dataset</strong>\n<ul>\n<li><a href=\"https://dumps.wikimedia.org/bnwiki/latest/\" rel=\"nofollow\">Bengali Wiki Dump</a></li>\n</ul>\n</li>\n<li>SentencePiece Training Vocab Size=50000</li>\n<li>Fasttext trained with total words = 20M, vocab size = 1171011, epoch=50, embedding dimension = 300 and the training loss = 0.318668,</li>\n<li>Word2Vec word embedding dimension = 300</li>\n<li>To Know Bengali GloVe Wordvector and training process follow <a href=\"https://github.com/sagorbrur/GloVe-Bengali\" rel=\"nofollow\">this</a> repository</li>\n<li>Bengali CRF POS Tagging was training with <a href=\"https://github.com/abhishekgupta92/bangla_pos_tagger/tree/master/data\" rel=\"nofollow\">nltr</a> dataset with 80% accuracy.</li>\n</ul>\n<h2>Tokenization</h2>\n<ul>\n<li>\n<p><strong>Bengali SentencePiece Tokenization</strong></p>\n<ul>\n<li>tokenization using trained model\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.sentencepiece_tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">SP_Tokenizer</span>\n\n<span class=\"n\">bsp</span> <span class=\"o\">=</span> <span class=\"n\">SP_Tokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"./model/bn_spm.model\"</span>\n<span class=\"n\">input_text</span> <span class=\"o\">=</span> <span class=\"s2\">\"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964\"</span>\n<span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"n\">bsp</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">input_text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">)</span>\n<span class=\"n\">text2id</span> <span class=\"o\">=</span> <span class=\"n\">bsp</span><span class=\"o\">.</span><span class=\"n\">text2id</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">input_text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">text2id</span><span class=\"p\">)</span>\n<span class=\"n\">id2text</span> <span class=\"o\">=</span> <span class=\"n\">bsp</span><span class=\"o\">.</span><span class=\"n\">id2text</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">text2id</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">id2text</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li>Training SentencePiece\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.sentencepiece_tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">SP_Tokenizer</span>\n\n<span class=\"n\">bsp</span> <span class=\"o\">=</span> <span class=\"n\">SP_Tokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"s2\">\"test.txt\"</span>\n<span class=\"n\">model_prefix</span> <span class=\"o\">=</span> <span class=\"s2\">\"test\"</span>\n<span class=\"n\">vocab_size</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n<span class=\"n\">bsp</span><span class=\"o\">.</span><span class=\"n\">train_bsp</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">model_prefix</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"p\">)</span> \n</pre>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Basic Tokenizer</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.basic_tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">BasicTokenizer</span>\n<span class=\"n\">basic_t</span> <span class=\"o\">=</span> <span class=\"n\">BasicTokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">raw_text</span> <span class=\"o\">=</span> <span class=\"s2\">\"\u0986\u09ae\u09bf \u09ac\u09be\u0982\u09b2\u09be\u09df \u0997\u09be\u09a8 \u0997\u09be\u0987\u0964\"</span>\n<span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"n\">basic_t</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"n\">raw_text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># output: [\"\u0986\u09ae\u09bf\", \"\u09ac\u09be\u0982\u09b2\u09be\u09df\", \"\u0997\u09be\u09a8\", \"\u0997\u09be\u0987\", \"\u0964\"]</span>\n</pre>\n</li>\n<li>\n<p><strong>NLTK Tokenization</strong></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.nltk_tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">NLTK_Tokenizer</span>\n\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964 \u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?\"</span>\n<span class=\"n\">bnltk</span> <span class=\"o\">=</span> <span class=\"n\">NLTK_Tokenizer</span><span class=\"p\">()</span>\n<span class=\"n\">word_tokens</span> <span class=\"o\">=</span> <span class=\"n\">bnltk</span><span class=\"o\">.</span><span class=\"n\">word_tokenize</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"n\">sentence_tokens</span> <span class=\"o\">=</span> <span class=\"n\">bnltk</span><span class=\"o\">.</span><span class=\"n\">sentence_tokenize</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">word_tokens</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">sentence_tokens</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># output</span>\n<span class=\"c1\"># word_token: [\"\u0986\u09ae\u09bf\", \"\u09ad\u09be\u09a4\", \"\u0996\u09be\u0987\", \"\u0964\", \"\u09b8\u09c7\", \"\u09ac\u09be\u099c\u09be\u09b0\u09c7\", \"\u09af\u09be\u09df\", \"\u0964\", \"\u09a4\u09bf\u09a8\u09bf\", \"\u0995\u09bf\", \"\u09b8\u09a4\u09cd\u09af\u09bf\u0987\", \"\u09ad\u09be\u09b2\u09cb\", \"\u09ae\u09be\u09a8\u09c1\u09b7\", \"?\"]</span>\n<span class=\"c1\"># sentence_token: [\"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964\", \"\u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964\", \"\u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?\"]</span>\n</pre>\n</li>\n</ul>\n<h2>Word Embedding</h2>\n<ul>\n<li>\n<p><strong>Bengali Word2Vec</strong></p>\n<ul>\n<li>\n<p>Generate Vector using pretrain model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_word2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Bengali_Word2Vec</span>\n\n<span class=\"n\">bwv</span> <span class=\"o\">=</span> <span class=\"n\">Bengali_Word2Vec</span><span class=\"p\">()</span>\n<span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"model/bengali_word2vec.model\"</span>\n<span class=\"n\">word</span> <span class=\"o\">=</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span>\n<span class=\"n\">vector</span> <span class=\"o\">=</span> <span class=\"n\">bwv</span><span class=\"o\">.</span><span class=\"n\">generate_word_vector</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">word</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">vector</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">vector</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li>\n<p>Find Most Similar Word Using Pretrained Model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_word2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Bengali_Word2Vec</span>\n\n<span class=\"n\">bwv</span> <span class=\"o\">=</span> <span class=\"n\">Bengali_Word2Vec</span><span class=\"p\">()</span>\n<span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"model/bengali_word2vec.model\"</span>\n<span class=\"n\">word</span> <span class=\"o\">=</span> <span class=\"s1\">'\u0986\u09ae\u09be\u09b0'</span>\n<span class=\"n\">similar</span> <span class=\"o\">=</span> <span class=\"n\">bwv</span><span class=\"o\">.</span><span class=\"n\">most_similar</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">word</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">similar</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li>\n<p>Train Bengali Word2Vec with your own data</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_word2vec</span> <span class=\"kn\">import</span> <span class=\"n\">Bengali_Word2Vec</span>\n<span class=\"n\">bwv</span> <span class=\"o\">=</span> <span class=\"n\">Bengali_Word2Vec</span><span class=\"p\">()</span>\n<span class=\"n\">data_file</span> <span class=\"o\">=</span> <span class=\"s2\">\"test.txt\"</span>\n<span class=\"n\">model_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"test_model.model\"</span>\n<span class=\"n\">vector_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"test_vector.vector\"</span>\n<span class=\"n\">bwv</span><span class=\"o\">.</span><span class=\"n\">train_word2vec</span><span class=\"p\">(</span><span class=\"n\">data_file</span><span class=\"p\">,</span> <span class=\"n\">model_name</span><span class=\"p\">,</span> <span class=\"n\">vector_name</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Bengali FastText</strong></p>\n<ul>\n<li>\n<p>Generate Vector Using Pretrained Model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_fasttext</span> <span class=\"kn\">import</span> <span class=\"n\">Bengali_Fasttext</span>\n\n<span class=\"n\">bft</span> <span class=\"o\">=</span> <span class=\"n\">Bengali_Fasttext</span><span class=\"p\">()</span>\n<span class=\"n\">word</span> <span class=\"o\">=</span> <span class=\"s2\">\"\u0997\u09cd\u09b0\u09be\u09ae\"</span>\n<span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"model/bengali_fasttext.bin\"</span>\n<span class=\"n\">word_vector</span> <span class=\"o\">=</span> <span class=\"n\">bft</span><span class=\"o\">.</span><span class=\"n\">generate_word_vector</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">word</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">word_vector</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">word_vector</span><span class=\"p\">)</span>\n</pre>\n</li>\n<li>\n<p>Train Bengali FastText Model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_fasttext</span> <span class=\"kn\">import</span> <span class=\"n\">Bengali_Fasttext</span>\n\n<span class=\"n\">bft</span> <span class=\"o\">=</span> <span class=\"n\">Bengali_Fasttext</span><span class=\"p\">()</span>\n<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"s2\">\"data.txt\"</span>\n<span class=\"n\">model_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"saved_model.bin\"</span>\n<span class=\"n\">epoch</span> <span class=\"o\">=</span> <span class=\"mi\">50</span>\n<span class=\"n\">bft</span><span class=\"o\">.</span><span class=\"n\">train_fasttext</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">model_name</span><span class=\"p\">,</span> <span class=\"n\">epoch</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Bengali GloVe Word Vectors</strong></p>\n<p>We trained glove model with bengali data(wiki+news articles) and published bengali glove word vectors<br>\nYou can download and use it on your different machine learning purposes.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.glove_wordvector</span> <span class=\"kn\">import</span> <span class=\"n\">BN_Glove</span>\n<span class=\"n\">glove_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"bn_glove.39M.100d.txt\"</span>\n<span class=\"n\">word</span> <span class=\"o\">=</span> <span class=\"s2\">\"\u0997\u09cd\u09b0\u09be\u09ae\"</span>\n<span class=\"n\">bng</span> <span class=\"o\">=</span> <span class=\"n\">BN_Glove</span><span class=\"p\">()</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">bng</span><span class=\"o\">.</span><span class=\"n\">closest_word</span><span class=\"p\">(</span><span class=\"n\">glove_path</span><span class=\"p\">,</span> <span class=\"n\">word</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">)</span>\n<span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">bng</span><span class=\"o\">.</span><span class=\"n\">word2vec</span><span class=\"p\">(</span><span class=\"n\">glove_path</span><span class=\"p\">,</span> <span class=\"n\">word</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">vec</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ul>\n<h2>Bengali POS Tagging</h2>\n<ul>\n<li>\n<p><strong>Bengali CRF POS Tagging</strong></p>\n<ul>\n<li>\n<p>Find Pos Tag Using Pretrained Model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_pos</span> <span class=\"kn\">import</span> <span class=\"n\">BN_CRF_POS</span>\n<span class=\"n\">bn_pos</span> <span class=\"o\">=</span> <span class=\"n\">BN_CRF_POS</span><span class=\"p\">()</span>\n<span class=\"n\">model_path</span> <span class=\"o\">=</span> <span class=\"s2\">\"model/bn_pos_model.pkl\"</span>\n<span class=\"n\">text</span> <span class=\"o\">=</span> <span class=\"s2\">\"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964\"</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">bn_pos</span><span class=\"o\">.</span><span class=\"n\">pos_tag</span><span class=\"p\">(</span><span class=\"n\">model_path</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">)</span>\n<span class=\"c1\"># [('\u0986\u09ae\u09bf', 'PPR'), ('\u09ad\u09be\u09a4', 'NC'), ('\u0996\u09be\u0987', 'VM'), ('\u0964', 'PU')]</span>\n</pre>\n</li>\n<li>\n<p>Train POS Tag Model</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">bnlp.bengali_pos</span> <span class=\"kn\">import</span> <span class=\"n\">BN_CRF_POS</span>\n<span class=\"n\">bn_pos</span> <span class=\"o\">=</span> <span class=\"n\">BN_CRF_POS</span><span class=\"p\">()</span>\n<span class=\"n\">model_name</span> <span class=\"o\">=</span> <span class=\"s2\">\"pos_model.pkl\"</span>\n<span class=\"n\">tagged_sentences</span> <span class=\"o\">=</span> <span class=\"p\">[[(</span><span class=\"s1\">'\u09b0\u09aa\u09cd\u09a4\u09be\u09a8\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'JJ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09a6\u09cd\u09b0\u09ac\u09cd\u09af'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'-'</span><span class=\"p\">,</span> <span class=\"s1\">'PU'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09a4\u09be\u099c\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'JJ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u0993'</span><span class=\"p\">,</span> <span class=\"s1\">'CCD'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09b6\u09c1\u0995\u09a8\u09be'</span><span class=\"p\">,</span> <span class=\"s1\">'JJ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09ab\u09b2'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">','</span><span class=\"p\">,</span> <span class=\"s1\">'PU'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u0986\u09ab\u09bf\u09ae'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">','</span><span class=\"p\">,</span> <span class=\"s1\">'PU'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09aa\u09b6\u09c1\u099a\u09b0\u09cd\u09ae'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u0993'</span><span class=\"p\">,</span> <span class=\"s1\">'CCD'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09aa\u09b6\u09ae'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u098f\u09ac\u0982'</span><span class=\"p\">,</span> <span class=\"s1\">'CCD'</span><span class=\"p\">),(</span><span class=\"s1\">'\u0995\u09be\u09b0\u09cd\u09aa\u09c7\u099f'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09f7'</span><span class=\"p\">,</span> <span class=\"s1\">'PU'</span><span class=\"p\">)],</span> <span class=\"p\">[(</span><span class=\"s1\">'\u09ae\u09be\u099f\u09bf'</span><span class=\"p\">,</span> <span class=\"s1\">'NC'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09a5\u09c7\u0995\u09c7'</span><span class=\"p\">,</span> <span class=\"s1\">'PP'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09ac\u09dc\u099c\u09cb\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'JQ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u099a\u09be\u09b0'</span><span class=\"p\">,</span> <span class=\"s1\">'JQ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09aa\u09be\u0981\u099a'</span><span class=\"p\">,</span> <span class=\"s1\">'JQ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09ab\u09c1\u099f'</span><span class=\"p\">,</span> <span class=\"s1\">'CCL'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u0989\u0981\u099a\u09c1'</span><span class=\"p\">,</span> <span class=\"s1\">'JJ'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09b9\u09ac\u09c7'</span><span class=\"p\">,</span> <span class=\"s1\">'VM'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'\u09f7'</span><span class=\"p\">,</span> <span class=\"s1\">'PU'</span><span class=\"p\">)]]</span>\n\n<span class=\"n\">bn_pos</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"p\">,</span> <span class=\"n\">tagged_sentences</span><span class=\"p\">)</span>\n</pre>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Issue</h2>\n<ul>\n<li>if <code>ModuleNotFoundError: No module named 'fasttext'</code> problem arise please do the next line</li>\n</ul>\n<p><code>pip install fasttext</code></p>\n<ul>\n<li>if <code>nltk</code> issue arise please do the following line before importing <code>bnlp</code></li>\n</ul>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">nltk</span>\n<span class=\"n\">nltk</span><span class=\"o\">.</span><span class=\"n\">download</span><span class=\"p\">(</span><span class=\"s2\">\"punkt\"</span><span class=\"p\">)</span>\n</pre>\n<h2>Contributor Guide</h2>\n<p>Check <a href=\"https://github.com/sagorbrur/bnlp/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">CONTRIBUTING.md</a> page for details.</p>\n<h2>Thanks To</h2>\n<ul>\n<li><a href=\"http://semanticslab.net/\" rel=\"nofollow\">Semantics Lab</a></li>\n</ul>\n<h2>Contributor List</h2>\n<p><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/0\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ff046879f8c77f26327a5ab10c5f3a0248cebe69/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f30\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/1\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/46c77754b73cee951ea9ab7112e14ae74c1fe5d6/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f31\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/2\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/465373d9cce8fcf0aa25ceb73ae9bdfde53e8c2a/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f32\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/3\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2f8bcf9fb43ec7bba6d4e718bb0b5f2e8a2ecd94/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f33\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/4\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/55cebcbd1ec56b47622a6cb5b01712b8a64c7c2f/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f34\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/5\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/08c19786129ebb6bdcb78cae0db29b451eb2f302/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f35\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/6\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/016ca176e0433d25670af0d425195927779a6ae0/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f36\"></a><a href=\"https://sourcerer.io/fame/sagorbrur/sagorbrur/bnlp/links/7\" rel=\"nofollow\"><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f967f5dc74672b72309dec0c6ab132ef0fa2c188/68747470733a2f2f736f757263657265722e696f2f66616d652f7361676f72627275722f7361676f72627275722f626e6c702f696d616765732f37\"></a></p>\n<h3>Extra Contributor</h3>\n<ul>\n<li><a href=\"https://github.com/menon92\" rel=\"nofollow\">Mehadi Hasan Menon</a></li>\n<li><a href=\"https://github.com/kazalbrur\" rel=\"nofollow\">Kazal Chandra Barman</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6761678, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "75f3413faefe4cfaebd832b91df371ed", "sha256": "d78e5c599a5f66fab31109fcc7d1d69a56325fe785f63000375bdb011410f5b2"}, "downloads": -1, "filename": "bnlp_toolkit-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "75f3413faefe4cfaebd832b91df371ed", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 5853, "upload_time": "2019-11-25T04:42:08", "upload_time_iso_8601": "2019-11-25T04:42:08.188920Z", "url": "https://files.pythonhosted.org/packages/53/20/833fc11f32fedbe47d62e9f27b76016b7ab7d09db53d42ea9f823efa154b/bnlp_toolkit-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "718ef2127910f7771cf8d0b15535b66e", "sha256": "a3fa4264b457980372065b9a9104e53adf52971a00ca2400637f0b5b362dbc57"}, "downloads": -1, "filename": "bnlp_toolkit-1.0.0.tar.gz", "has_sig": false, "md5_digest": "718ef2127910f7771cf8d0b15535b66e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 3951, "upload_time": "2019-11-25T04:42:10", "upload_time_iso_8601": "2019-11-25T04:42:10.342018Z", "url": "https://files.pythonhosted.org/packages/ef/b5/8b099a1ec999556da5d041575e21e9e90ee0bee26c6a25c0610dbe5faa26/bnlp_toolkit-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "514bf62b81ad10d45ef4895ecd5f2a9f", "sha256": "68b525a55d5fa4512f27de83b915f2eb6c65ec2eff6ee44b22939d0f2b0140df"}, "downloads": -1, "filename": "bnlp_toolkit-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "514bf62b81ad10d45ef4895ecd5f2a9f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 7706, "upload_time": "2019-12-01T06:48:44", "upload_time_iso_8601": "2019-12-01T06:48:44.332743Z", "url": "https://files.pythonhosted.org/packages/9a/0b/933ff8fb2b64d7ed37a8a982fa7465a40e7746c554ba71cc30603a2f2053/bnlp_toolkit-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a1086b85463847b2db4491584f5c082d", "sha256": "a336dfef39b213b87e0f43433788e86b21e1731c9af2bf64fc2612daad00e57c"}, "downloads": -1, "filename": "bnlp_toolkit-1.1.0.tar.gz", "has_sig": false, "md5_digest": "a1086b85463847b2db4491584f5c082d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 5647, "upload_time": "2019-12-01T06:48:46", "upload_time_iso_8601": "2019-12-01T06:48:46.290972Z", "url": "https://files.pythonhosted.org/packages/84/51/576b57072afa2741968563cd4d33af9f3cc05a93c79a8956a0b7049b667f/bnlp_toolkit-1.1.0.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "952695f887649e046d63e6669b67de88", "sha256": "8bc33c0683955917935876c919c92c44d1889d0cab84deee49c5691c0d1fcd43"}, "downloads": -1, "filename": "bnlp_toolkit-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "952695f887649e046d63e6669b67de88", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 9307, "upload_time": "2019-12-14T11:52:13", "upload_time_iso_8601": "2019-12-14T11:52:13.288630Z", "url": "https://files.pythonhosted.org/packages/09/ee/6de7c337c1ce0ca89433f2a541cf8ec4aca2299a4e82945fa7b18d60fdff/bnlp_toolkit-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "83a57ea9b9349b1182ac0e93d03e77d5", "sha256": "73998ad81f97f9ce8c6c5cb9e8bbf8326ffab50b2c2d6bf95463fef7e456e5ef"}, "downloads": -1, "filename": "bnlp_toolkit-1.2.0.tar.gz", "has_sig": false, "md5_digest": "83a57ea9b9349b1182ac0e93d03e77d5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 7194, "upload_time": "2019-12-14T11:52:15", "upload_time_iso_8601": "2019-12-14T11:52:15.189693Z", "url": "https://files.pythonhosted.org/packages/2f/da/131803d84645f6e1ba24a8dd684b0eb458ad481c8b043e09ff1abe34e232/bnlp_toolkit-1.2.0.tar.gz", "yanked": false}], "2.0.0": [{"comment_text": "", "digests": {"md5": "eefb2f5a41b29e9b2783ca08af185528", "sha256": "0553425814fa5462906bc1d6d42740a778dad8266fb99efb1b938ccea3825caf"}, "downloads": -1, "filename": "bnlp_toolkit-2.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "eefb2f5a41b29e9b2783ca08af185528", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 11047, "upload_time": "2019-12-16T14:49:43", "upload_time_iso_8601": "2019-12-16T14:49:43.107817Z", "url": "https://files.pythonhosted.org/packages/6e/ec/5db1e21f4e6493a0bff84e9c456492d65cd53c01bfeb58c05eca2ac19072/bnlp_toolkit-2.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0bd3bf3356a9cadfeef8cdc167f167f3", "sha256": "2a9045151747dfdffbb917ebf874e7c03b5d5b8b9e68a07d49b1ad2a7a096795"}, "downloads": -1, "filename": "bnlp_toolkit-2.0.0.tar.gz", "has_sig": false, "md5_digest": "0bd3bf3356a9cadfeef8cdc167f167f3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 8748, "upload_time": "2019-12-16T14:49:45", "upload_time_iso_8601": "2019-12-16T14:49:45.231839Z", "url": "https://files.pythonhosted.org/packages/39/9b/b52630f81e7e168f9e2ee20cb8eb3bbe36814ce44c5fd7b3d6f9173e96fe/bnlp_toolkit-2.0.0.tar.gz", "yanked": false}], "2.1": [{"comment_text": "", "digests": {"md5": "40299f6e440c2871bbe5b54d21deaca0", "sha256": "76bceb2212e041610edf7e23ef934fd3f80c5c10d16b5475f27a9abafc342389"}, "downloads": -1, "filename": "bnlp_toolkit-2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "40299f6e440c2871bbe5b54d21deaca0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10919, "upload_time": "2020-02-12T11:42:45", "upload_time_iso_8601": "2020-02-12T11:42:45.474486Z", "url": "https://files.pythonhosted.org/packages/92/74/3a4d78a255f487df2132a41501cccb603ad5a6d679440a5f59ed0f63844b/bnlp_toolkit-2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "6b837aca484bf959da001eee3102009e", "sha256": "12be58b357e4d0be2ddc0045ee1cc14ef330438e98d651c5ffccdabee04980ad"}, "downloads": -1, "filename": "bnlp_toolkit-2.1.tar.gz", "has_sig": false, "md5_digest": "6b837aca484bf959da001eee3102009e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 8783, "upload_time": "2020-02-12T11:42:47", "upload_time_iso_8601": "2020-02-12T11:42:47.602961Z", "url": "https://files.pythonhosted.org/packages/ab/73/31379b4c3d46da4b9e47bde9b812019df8b7e58364392a1c4dd0680cc7b9/bnlp_toolkit-2.1.tar.gz", "yanked": false}], "2.2": [{"comment_text": "", "digests": {"md5": "53b2bd4a89f70b8a00437b3a92671e8b", "sha256": "27dab4f16d0769b805f04f14d47f28932987799968169220ee3f6bd5ac05e908"}, "downloads": -1, "filename": "bnlp_toolkit-2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "53b2bd4a89f70b8a00437b3a92671e8b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10938, "upload_time": "2020-03-06T12:46:05", "upload_time_iso_8601": "2020-03-06T12:46:05.729703Z", "url": "https://files.pythonhosted.org/packages/9e/09/74e8234af0848efc6c56d7aeb30b9e88d360b988867c3ce1f8bfbf28364e/bnlp_toolkit-2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "933df9a877be6080eba72f1bf82b9979", "sha256": "9ca1decbe59bb098e21122a464307872b3272cdfce7546922bf04c7b27412642"}, "downloads": -1, "filename": "bnlp_toolkit-2.2.tar.gz", "has_sig": false, "md5_digest": "933df9a877be6080eba72f1bf82b9979", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 8773, "upload_time": "2020-03-06T12:46:08", "upload_time_iso_8601": "2020-03-06T12:46:08.539107Z", "url": "https://files.pythonhosted.org/packages/e8/96/172556c9a29d6fd9055c2e78cf07d3a6b14cee8a4b046ac01ff7de70858f/bnlp_toolkit-2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "53b2bd4a89f70b8a00437b3a92671e8b", "sha256": "27dab4f16d0769b805f04f14d47f28932987799968169220ee3f6bd5ac05e908"}, "downloads": -1, "filename": "bnlp_toolkit-2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "53b2bd4a89f70b8a00437b3a92671e8b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10938, "upload_time": "2020-03-06T12:46:05", "upload_time_iso_8601": "2020-03-06T12:46:05.729703Z", "url": "https://files.pythonhosted.org/packages/9e/09/74e8234af0848efc6c56d7aeb30b9e88d360b988867c3ce1f8bfbf28364e/bnlp_toolkit-2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "933df9a877be6080eba72f1bf82b9979", "sha256": "9ca1decbe59bb098e21122a464307872b3272cdfce7546922bf04c7b27412642"}, "downloads": -1, "filename": "bnlp_toolkit-2.2.tar.gz", "has_sig": false, "md5_digest": "933df9a877be6080eba72f1bf82b9979", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 8773, "upload_time": "2020-03-06T12:46:08", "upload_time_iso_8601": "2020-03-06T12:46:08.539107Z", "url": "https://files.pythonhosted.org/packages/e8/96/172556c9a29d6fd9055c2e78cf07d3a6b14cee8a4b046ac01ff7de70858f/bnlp_toolkit-2.2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:36:55 2020"}