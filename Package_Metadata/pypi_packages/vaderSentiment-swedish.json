{"info": {"author": "C.J. Hutto", "author_email": "cjhutto@gatech.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3.5", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Information Analysis", "Topic :: Text Processing :: General", "Topic :: Text Processing :: Linguistic"], "description": "====================================\nSwedish-translated VADER-Sentiment-Analysis\n====================================\n\n\n**Looking for the English version made by https://github.com/cjhutto?**\n**Then go to https://github.com/cjhutto/vaderSentiment instead, since this is a Swedish version of the module.**\n\n.. _Quick reStructuredText: quickref.html\n.. _master quick reference:\n\nVADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is *specifically attuned to sentiments expressed in social media*. It is fully open-sourced under the `[MIT License] <http://choosealicense.com/>`_ (we sincerely appreciate all attributions and readily accept most contributions, but please don't hold us liable).\n\n* `Features and Updates`_\n* Introduction_\n* `Citation Information`_\n* Installation_\n* `Resources and Dataset Descriptions`_\n* `Python Code Example`_\n* `About the Scoring`_\n* `Ports to Other Programming Languages`_\n\nFeatures and Updates\n------------------------------------\nMany thanks to George Berry, Ewan Klein, Pierpaolo Pantone for key contributions to make VADER better.  The new updates includes capabilities regarding:\n\n#. Refactoring for Python 3 compatibility, improved modularity, and incorporation into `[NLTK] <http://www.nltk.org/_modules/nltk/sentiment/vader.html>`_ ...many thanks to Ewan & Pierpaolo.\n#. Restructuring for much improved speed/performance, reducing the time complexity from something like O(N^4) to O(N)...many thanks to George.\n#. Simplified pip install and better support for vaderSentiment module and component import. (Dependency on vader_lexicon.txt file now uses automated file location discovery so you don't need to manually designate its location in the code, or copy the file into your executing code's directory.)\n#. More complete demo in the ``__main__`` for ``vaderSentiment.py``. The demo has:\n\n\t* examples of typical use cases for sentiment analysis, including proper handling of sentences with:\n\n\t\t- typical negations (e.g., \"*inte* bra\")\n\t\t- conventional use of **punctuation** to signal increased sentiment intensity (e.g., \"Bra!!!\")\n\t\t- conventional use of **word-shape** to signal emphasis (e.g., using ALL CAPS for words/phrases)\n\t\t- using **degree modifiers** to alter sentiment intensity (e.g., intensity *boosters* such as \"v\u00e4ldigt\" and intensity *dampeners* such as \"n\u00e5gorlunda\")\n\t\t- understanding many **sentiment-laden slang** words (e.g., 'sux')\n\t\t- understanding many sentiment-laden **slang words as modifiers** such as 'uber' or 'friggin'\n\t\t- understanding many sentiment-laden **emoticons** such as :) and :D\n\t\t- translating **utf-8 encoded emojis** such as \ud83d\udc98 and \ud83d\udc8b and \ud83d\ude01\n\t\t- understanding sentiment-laden **initialisms and acronyms** (for example: 'lol')\n\n\t* more examples of **tricky sentences** that confuse other sentiment analysis tools\n\t* example for how VADER can work in conjunction with NLTK to do **sentiment analysis on longer texts**...i.e., decomposing paragraphs, articles/reports/publications, or novels into sentence-level analyses\n\t* examples of a concept for assessing the sentiment of images, video, or other tagged **multimedia content**\n\t* if you have access to the Internet, the demo has an example of how VADER can work with analyzing sentiment of **texts in other languages** (non-English text sentences).\n\n====================================\nIntroduction\n====================================\n\nThis README file describes the dataset of the paper:\n\n\t|  **VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text**\n\t|  (by C.J. Hutto and Eric Gilbert)\n\t|  Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n\n| For questions, please contact:\n|     C.J. Hutto\n|     Georgia Institute of Technology, Atlanta, GA 30032\n|     cjhutto [at] gatech [dot] edu\n\n\nCitation Information\n------------------------------------\n\nIf you use either the dataset or any of the VADER sentiment analysis tools (VADER sentiment lexicon or Python code for rule-based sentiment analysis engine) in your research, please cite the above paper. For example:\n\n  **Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.**\n\n====================================\nInstallation\n====================================\n\nThere are a couple of ways to install and use VADER sentiment:\n\n#. The simplest is to use the command line to do an installation from `[PyPI] <https://pypi.python.org/pypi/vaderSentiment-swedish>`_ using pip, e.g.,\n    ``> pip install vaderSentiment-swedish``\n#. Or, you might already have VADER and simply need to upgrade to the latest version, e.g.,\n    ``> pip install --upgrade vaderSentiment-swedish``\n#. You could also clone this `[GitHub repository] <https://github.com/AlexGustafsson/vaderSentiment-swedish>`_\n#. You could download and unzip the `[full master branch zip file] <https://github.com/AlexGustafsson/vaderSentiment-swedish/archive/master.zip>`_\n\nIn addition to the VADER sentiment analysis Python module, options 3 or 4 will also download all the additional resources and datasets (described below).\n\n====================================\nResources and Dataset Descriptions\n====================================\n\nThe package here includes **PRIMARY RESOURCES** (items 1-3) as well as additional **DATASETS AND TESTING RESOURCES** (items 4-12):\n\n#. vader_icwsm2014_final.pdf\n    The original paper for the data set, see citation information (above).\n\n#. vader_lexicon.txt\n    FORMAT: the file is tab delimited with TOKEN, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-HUMAN-SENTIMENT-RATINGS\n\tNOTE: The current algorithm makes immediate use of the first two elements (token and mean valence). The final two elements (SD and raw ratings) are provided for rigor.  For example, if you want to follow the same rigorous process that we used for the study, you should find 10 independent humans to evaluate/rate each new token you want to add to the lexicon, make sure the standard deviation doesn't exceed 2.5, and take the average rating for the valence. This will keep the file consistent.\n\n    DESCRIPTION:\n    Empirically validated by multiple independent human judges, VADER incorporates a \"gold-standard\" sentiment lexicon that is especially attuned to microblog-like contexts.\n\n    The VADER sentiment lexicon is sensitive both the **polarity** and the **intensity** of sentiments expressed in social media contexts, and is also generally applicable to sentiment analysis in other domains.\n\n\tSentiment ratings from 10 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability). Over 9,000 token features were rated on a scale from \"[\u20134] Extremely Negative\" to \"[4] Extremely Positive\", with allowance for \"[0] Neutral (or Neither, N/A)\".  We kept every lexical feature that had a non-zero mean rating, and whose standard deviation was less than 2.5 as determined by the aggregate of those ten independent raters.  This left us with just over 7,500 lexical features with validated valence scores that indicated both the sentiment polarity (positive/negative), and the sentiment intensity on a scale from \u20134 to +4. For example, the word \"okay\" has a positive valence of 0.9, \"good\" is 1.9, and \"great\" is 3.1, whereas \"horrible\" is \u20132.5, the frowning emoticon :( is \u20132.2, and \"sucks\" and it's slang derivative \"sux\" are both \u20131.5.\n\n    Manually creating (much less, validating) a comprehensive sentiment lexicon is a labor intensive and sometimes error prone process, so it is no wonder that many opinion mining researchers and practitioners rely so heavily on existing lexicons as primary resources. We are pleased to offer ours as a new resource. We began by constructing a list inspired by examining existing well-established sentiment word-banks (LIWC, ANEW, and GI). To this, we next incorporate numerous lexical features common to sentiment expression in microblogs, including:\n\n    * a full list of Western-style emoticons, for example, :-) denotes a smiley face and generally indicates positive sentiment\n    * sentiment-related acronyms and initialisms (e.g., LOL and WTF are both examples of sentiment-laden initialisms)\n    * commonly used slang with sentiment value (e.g., nah, meh and giggly).\n\n    We empirically confirmed the general applicability of each feature candidate to sentiment expressions using a wisdom-of-the-crowd (WotC) approach (Surowiecki, 2004) to acquire a valid point estimate for the sentiment valence (polarity & intensity) of each context-free candidate feature.\n\n#. vaderSentiment.py\n    The Python code for the rule-based sentiment analysis engine. Implements the grammatical and syntactical rules described in the paper, incorporating empirically derived quantifications for the impact of each rule on the perceived intensity of sentiment in sentence-level text. Importantly, these heuristics go beyond what would normally be captured in a typical bag-of-words model. They incorporate **word-order sensitive relationships** between terms. For example, degree modifiers (also called intensifiers, booster words, or degree adverbs) impact sentiment intensity by either increasing or decreasing the intensity. Consider these examples:\n\n    (a) \"The service here is extremely good\"\n    (b) \"The service here is good\"\n    (c) \"The service here is marginally good\"\n\n    From Table 3 in the paper, we see that for 95% of the data, using a degree modifier increases the positive sentiment intensity of example (a) by 0.227 to 0.36, with a mean difference of 0.293 on a rating scale from 1 to 4. Likewise, example (c) reduces the perceived sentiment intensity by 0.293, on average.\n\n#. tweets_GroundTruth.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TWEET-TEXT\n\n    DESCRIPTION: includes \"tweet-like\" text as inspired by 4,000 tweets pulled from Twitter\u2019s public timeline, plus 200 completely contrived tweet-like texts intended to specifically test syntactical and grammatical conventions of conveying differences in sentiment intensity. The \"tweet-like\" texts incorporate a fictitious username (@anonymous) in places where a username might typically appear, along with a fake URL (http://url_removed) in places where a URL might typically appear, as inspired by the original tweets. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'tweets_anonDataRatings.txt' (described below).\n\n#. tweets_anonDataRatings.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS\n\n    DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n\n#. nytEditorialSnippets_GroundTruth.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TEXT-SNIPPET\n\n    DESCRIPTION: includes 5,190 sentence-level snippets from 500 New York Times opinion news editorials/articles; we used the NLTK tokenizer to segment the articles into sentence phrases, and added sentiment intensity ratings. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'nytEditorialSnippets_anonDataRatings.txt' (described below).\n\n#. nytEditorialSnippets_anonDataRatings.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS\n\n    DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n\n#. movieReviewSnippets_GroundTruth.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TEXT-SNIPPET\n\n    DESCRIPTION: includes 10,605 sentence-level snippets from rotten.tomatoes.com. The snippets were derived from an original set of 2000 movie reviews (1000 positive and 1000 negative) in Pang & Lee (2004); we used the NLTK tokenizer to segment the reviews into sentence phrases, and added sentiment intensity ratings. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'movieReviewSnippets_anonDataRatings.txt' (described below).\n\n#. movieReviewSnippets_anonDataRatings.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS\n\n    DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n\n#. amazonReviewSnippets_GroundTruth.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TEXT-SNIPPET\n\n    DESCRIPTION: includes 3,708 sentence-level snippets from 309 customer reviews on 5 different products. The reviews were originally used in Hu & Liu (2004); we added sentiment intensity ratings. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'amazonReviewSnippets_anonDataRatings.txt' (described below).\n\n#. amazonReviewSnippets_anonDataRatings.txt\n    FORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS\n\n    DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n\n\n#. Comp.Social website with more papers/research:\n    [Comp.Social](http://comp.social.gatech.edu/papers/)\n\n====================================\nPython Code Example\n====================================\n\nFor a **more complete demo**, point your terminal to vader's install directory (e.g., if you installed using pip, it might be ``\\Python3x\\lib\\site-packages\\vaderSentiment``), and then run ``python vaderSentiment.py``.\n\nThe demo has more examples of tricky sentences that confuse other sentiment analysis tools. It also demonstrates how VADER can work in conjunction with NLTK to do sentiment analysis on longer texts...i.e., decomposing paragraphs, articles/reports/publications, or novels into sentence-level analysis.  It also demonstrates a concept for assessing the sentiment of images, video, or other tagged multimedia content.\n\nIf you have access to the Internet, the demo will also show how VADER can work with analyzing sentiment of non-English text sentences.\n\n::\n\n\tfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\t#note: depending on how you installed (e.g., using source code download versus pip install), you may need to import like this:\n\t#from vaderSentiment import SentimentIntensityAnalyzer\n\n\t# --- examples -------\n\t\tsentences = [\"VADER \u00e4r smart, stilig och rolig.\",  # positive sentence example\n                 \"VADER \u00e4r smart, stilig och rolig!\",\n                 # punctuation emphasis handled correctly (sentiment intensity adjusted)\n                 \"VADER \u00e4r v\u00e4ldigt mart, stilig och rolig.\",\n                 # booster words handled correctly (sentiment intensity adjusted)\n                 \"VADER \u00e4r V\u00c4LDIGT SMART, STILIG och ROLIG.\",  # emphasis for ALLCAPS handled\n                 \"VADER \u00e4r V\u00c4LDIGT SMART, stilig och ROLIG!!!\",\n                 # combination of signals - VADER appropriately adjusts intensity\n                 \"VADER \u00e4r v\u00e4ldigt smart, uber stilig och SJUKT ROLIG!!!\",\n                 # booster words & punctuation make this close to ceiling for score\n                 \"VADER \u00e4r inte smart, stilig och inte rolig.\",  # negation sentence example\n                 \"Boken var bra.\",  # positive sentence\n                 \"Det \u00e4r \u00e5tminstone inte en d\u00e5lig bok\",  # negated negative sentence with contraction\n                 \"Boken var bara n\u00e5gorlunda bra.\",\n                 # qualified positive sentence is handled correctly (intensity adjusted)\n                 \"Handlingen var bra, men karakt\u00e4rerna \u00e4r okomponerande och dialogen \u00e4r inte bra.\",\n                 # mixed negation sentence\n                 \"Den h\u00e4r dagen SUX!\",  # negative slang with capitalization emphasis\n                 \"Den h\u00e4r dagen suger bara delvis. Men jag \u00f6verlever, lol\",\n                 # mixed sentiment example with slang and constrastive conjunction \"but\"\n                 \"Se till att du :) eller :D idag!\",  # emoticons handled\n                 \"F\u00e5nga utf-8 emoji s\u00e5 som \ud83d\udc98 och \ud83d\udc8b och \ud83d\ude01\",  # emojis handled\n                 \"Inte d\u00e5lig alls\"  # Capitalized negation\n                 ]\n\n    analyzer = SentimentIntensityAnalyzer()\n    for sentence in sentences:\n        vs = analyzer.polarity_scores(sentence)\n        print(\"{:-<65} {}\".format(sentence, str(vs)))\n\n\nFor a **more complete demo**, go to the install directory and run ``python vaderSentiment.py``. (Be sure you are set to handle UTF-8 encoding in your terminal or IDE.)\n\n====================================\nOutput for the above example code\n====================================\n\n::\n\n\tVADER \u00e4r smart, stilig och rolig.-------------------------------- {'neg': 0.272, 'neu': 0.24, 'pos': 0.488, 'compound': 0.4019}\n\tVADER \u00e4r smart, stilig och rolig!-------------------------------- {'neg': 0.266, 'neu': 0.235, 'pos': 0.5, 'compound': 0.4574}\n\tVADER \u00e4r v\u00e4ldigt mart, stilig och rolig.------------------------- {'neg': 0.247, 'neu': 0.29, 'pos': 0.463, 'compound': 0.4549}\n\tVADER \u00e4r V\u00c4LDIGT SMART, STILIG och ROLIG.------------------------ {'neg': 0.213, 'neu': 0.251, 'pos': 0.536, 'compound': 0.7303}\n\tVADER \u00e4r V\u00c4LDIGT SMART, stilig och ROLIG!!!---------------------- {'neg': 0.211, 'neu': 0.249, 'pos': 0.54, 'compound': 0.7418}\n\tVADER \u00e4r v\u00e4ldigt smart, uber stilig och SJUKT ROLIG!!!----------- {'neg': 0.182, 'neu': 0.321, 'pos': 0.497, 'compound': 0.784}\n\tVADER \u00e4r inte smart, stilig och inte rolig.---------------------- {'neg': 0.174, 'neu': 0.154, 'pos': 0.672, 'compound': 0.8658}\n\tBoken var bra.--------------------------------------------------- {'neg': 0.0, 'neu': 0.328, 'pos': 0.672, 'compound': 0.6249}\n\tDet \u00e4r \u00e5tminstone inte en d\u00e5lig bok------------------------------ {'neg': 0.608, 'neu': 0.181, 'pos': 0.211, 'compound': -0.765}\n\tBoken var bara n\u00e5gorlunda bra.----------------------------------- {'neg': 0.0, 'neu': 0.512, 'pos': 0.488, 'compound': 0.5868}\n\tHandlingen var bra, men karakt\u00e4rerna \u00e4r okomponerande och dialogen \u00e4r inte bra. {'neg': 0.322, 'neu': 0.23, 'pos': 0.448, 'compound': 0.6486}\n\tDen h\u00e4r dagen SUX!----------------------------------------------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n\tDen h\u00e4r dagen suger bara delvis. Men jag \u00f6verlever, lol---------- {'neg': 0.259, 'neu': 0.476, 'pos': 0.265, 'compound': 0.2716}\n\tSe till att du :) eller :D idag!--------------------------------- {'neg': 0.122, 'neu': 0.244, 'pos': 0.635, 'compound': 0.8564}\n\tF\u00e5nga utf-8 emoji s\u00e5 som \ud83d\udc98 och \ud83d\udc8b och \ud83d\ude01--------------------------- {'neg': 0.106, 'neu': 0.894, 'pos': 0.0, 'compound': -0.2247}\n\tInte d\u00e5lig alls-------------------------------------------------- {'neg': 0.438, 'neu': 0.125, 'pos': 0.438, 'compound': 0.0}\n\n\n====================================\nAbout the Scoring\n====================================\n\n* The ``compound`` score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.\n\n  It is also useful for researchers who would like to set standardized thresholds for classifying sentences as either positive, neutral, or negative.\n  Typical threshold values (used in the literature cited on this page) are:\n\n #. **positive sentiment**: ``compound`` score >=  0.05\n #. **neutral  sentiment**: (``compound`` score > -0.05) and (``compound`` score < 0.05)\n #. **negative sentiment**: ``compound`` score <= -0.05\n\n* The ``pos``, ``neu``, and ``neg`` scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation).  These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence.\n\n====================================\nPorts to Other Programming Languages\n====================================\nFeel free to let me know about ports of VADER Sentiment to other programming languages. So far, I know about these helpful ports:\n\n#. Java\n    `VaderSentimentJava <https://github.com/apanimesh061/VaderSentimentJava>`_ by apanimesh061\n\n#. JavaScript\n\t`vaderSentiment-js <https://github.com/vaderSentiment/vaderSentiment-js>`_ by nimaeskandary\n\n#. PHP\n\t`php-vadersentiment <https://github.com/abusby/php-vadersentiment>`_ by abusby\n\n#. Scala\n\t`Sentiment <https://github.com/ziyasal/Sentiment>`_ by ziyasal\n\n#. C#\n\t`vadersharp <https://github.com/codingupastorm/vadersharp>`_ by codingupastorm Jordan Andrews\n\n#. Rust\n\t`vader-sentiment-rust <https://github.com/ckw017/vader-sentiment-rust>`_ by ckw017", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/AlexGustafsson/vaderSentiment-swedish/archive/master.zip", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/AlexGustafsson/vaderSentiment-swedish", "keywords": "vader,sentiment,analysis,swedish,opinion,mining,nlp,text,data,text analysis,opinion analysis,sentiment analysis,text mining,twitter sentiment,opinion mining,social media,twitter,social,media", "license": "MIT License: http://opensource.org/licenses/MIT", "maintainer": "", "maintainer_email": "", "name": "vaderSentiment-swedish", "package_url": "https://pypi.org/project/vaderSentiment-swedish/", "platform": "", "project_url": "https://pypi.org/project/vaderSentiment-swedish/", "project_urls": {"Download": "https://github.com/AlexGustafsson/vaderSentiment-swedish/archive/master.zip", "Homepage": "https://github.com/AlexGustafsson/vaderSentiment-swedish"}, "release_url": "https://pypi.org/project/vaderSentiment-swedish/1.0.3/", "requires_dist": null, "requires_python": "", "summary": "VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.", "version": "1.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>====================================\nSwedish-translated VADER-Sentiment-Analysis</h1>\n<p><strong>Looking for the English version made by <a href=\"https://github.com/cjhutto\" rel=\"nofollow\">https://github.com/cjhutto</a>?</strong>\n<strong>Then go to <a href=\"https://github.com/cjhutto/vaderSentiment\" rel=\"nofollow\">https://github.com/cjhutto/vaderSentiment</a> instead, since this is a Swedish version of the module.</strong></p>\n<p>.. _Quick reStructuredText: quickref.html\n.. _master quick reference:</p>\n<p>VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is <em>specifically attuned to sentiments expressed in social media</em>. It is fully open-sourced under the <code>[MIT License] &lt;http://choosealicense.com/&gt;</code>_ (we sincerely appreciate all attributions and readily accept most contributions, but please don't hold us liable).</p>\n<ul>\n<li><code>Features and Updates</code>_</li>\n<li>Introduction_</li>\n<li><code>Citation Information</code>_</li>\n<li>Installation_</li>\n<li><code>Resources and Dataset Descriptions</code>_</li>\n<li><code>Python Code Example</code>_</li>\n<li><code>About the Scoring</code>_</li>\n<li><code>Ports to Other Programming Languages</code>_</li>\n</ul>\n<h2>Features and Updates</h2>\n<p>Many thanks to George Berry, Ewan Klein, Pierpaolo Pantone for key contributions to make VADER better.  The new updates includes capabilities regarding:</p>\n<p>#. Refactoring for Python 3 compatibility, improved modularity, and incorporation into <code>[NLTK] &lt;http://www.nltk.org/_modules/nltk/sentiment/vader.html&gt;</code>_ ...many thanks to Ewan &amp; Pierpaolo.\n#. Restructuring for much improved speed/performance, reducing the time complexity from something like O(N^4) to O(N)...many thanks to George.\n#. Simplified pip install and better support for vaderSentiment module and component import. (Dependency on vader_lexicon.txt file now uses automated file location discovery so you don't need to manually designate its location in the code, or copy the file into your executing code's directory.)\n#. More complete demo in the <code>__main__</code> for <code>vaderSentiment.py</code>. The demo has:</p>\n<pre><code>* examples of typical use cases for sentiment analysis, including proper handling of sentences with:\n\n\t- typical negations (e.g., \"*inte* bra\")\n\t- conventional use of **punctuation** to signal increased sentiment intensity (e.g., \"Bra!!!\")\n\t- conventional use of **word-shape** to signal emphasis (e.g., using ALL CAPS for words/phrases)\n\t- using **degree modifiers** to alter sentiment intensity (e.g., intensity *boosters* such as \"v\u00e4ldigt\" and intensity *dampeners* such as \"n\u00e5gorlunda\")\n\t- understanding many **sentiment-laden slang** words (e.g., 'sux')\n\t- understanding many sentiment-laden **slang words as modifiers** such as 'uber' or 'friggin'\n\t- understanding many sentiment-laden **emoticons** such as :) and :D\n\t- translating **utf-8 encoded emojis** such as \ud83d\udc98 and \ud83d\udc8b and \ud83d\ude01\n\t- understanding sentiment-laden **initialisms and acronyms** (for example: 'lol')\n\n* more examples of **tricky sentences** that confuse other sentiment analysis tools\n* example for how VADER can work in conjunction with NLTK to do **sentiment analysis on longer texts**...i.e., decomposing paragraphs, articles/reports/publications, or novels into sentence-level analyses\n* examples of a concept for assessing the sentiment of images, video, or other tagged **multimedia content**\n* if you have access to the Internet, the demo has an example of how VADER can work with analyzing sentiment of **texts in other languages** (non-English text sentences).\n</code></pre>\n<h1>====================================\nIntroduction</h1>\n<p>This README file describes the dataset of the paper:</p>\n<pre><code>|  **VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text**\n|  (by C.J. Hutto and Eric Gilbert)\n|  Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n</code></pre>\n<p>| For questions, please contact:\n|     C.J. Hutto\n|     Georgia Institute of Technology, Atlanta, GA 30032\n|     cjhutto [at] gatech [dot] edu</p>\n<h2>Citation Information</h2>\n<p>If you use either the dataset or any of the VADER sentiment analysis tools (VADER sentiment lexicon or Python code for rule-based sentiment analysis engine) in your research, please cite the above paper. For example:</p>\n<p><strong>Hutto, C.J. &amp; Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.</strong></p>\n<h1>====================================\nInstallation</h1>\n<p>There are a couple of ways to install and use VADER sentiment:</p>\n<p>#. The simplest is to use the command line to do an installation from <code>[PyPI] &lt;https://pypi.python.org/pypi/vaderSentiment-swedish&gt;</code>_ using pip, e.g.,\n<code>&gt; pip install vaderSentiment-swedish</code>\n#. Or, you might already have VADER and simply need to upgrade to the latest version, e.g.,\n<code>&gt; pip install --upgrade vaderSentiment-swedish</code>\n#. You could also clone this <code>[GitHub repository] &lt;https://github.com/AlexGustafsson/vaderSentiment-swedish&gt;</code>_\n#. You could download and unzip the <code>[full master branch zip file] &lt;https://github.com/AlexGustafsson/vaderSentiment-swedish/archive/master.zip&gt;</code>_</p>\n<p>In addition to the VADER sentiment analysis Python module, options 3 or 4 will also download all the additional resources and datasets (described below).</p>\n<h1>====================================\nResources and Dataset Descriptions</h1>\n<p>The package here includes <strong>PRIMARY RESOURCES</strong> (items 1-3) as well as additional <strong>DATASETS AND TESTING RESOURCES</strong> (items 4-12):</p>\n<p>#. vader_icwsm2014_final.pdf\nThe original paper for the data set, see citation information (above).</p>\n<p>#. vader_lexicon.txt\nFORMAT: the file is tab delimited with TOKEN, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-HUMAN-SENTIMENT-RATINGS\nNOTE: The current algorithm makes immediate use of the first two elements (token and mean valence). The final two elements (SD and raw ratings) are provided for rigor.  For example, if you want to follow the same rigorous process that we used for the study, you should find 10 independent humans to evaluate/rate each new token you want to add to the lexicon, make sure the standard deviation doesn't exceed 2.5, and take the average rating for the valence. This will keep the file consistent.</p>\n<pre><code>DESCRIPTION:\nEmpirically validated by multiple independent human judges, VADER incorporates a \"gold-standard\" sentiment lexicon that is especially attuned to microblog-like contexts.\n\nThe VADER sentiment lexicon is sensitive both the **polarity** and the **intensity** of sentiments expressed in social media contexts, and is also generally applicable to sentiment analysis in other domains.\n\nSentiment ratings from 10 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability). Over 9,000 token features were rated on a scale from \"[\u20134] Extremely Negative\" to \"[4] Extremely Positive\", with allowance for \"[0] Neutral (or Neither, N/A)\".  We kept every lexical feature that had a non-zero mean rating, and whose standard deviation was less than 2.5 as determined by the aggregate of those ten independent raters.  This left us with just over 7,500 lexical features with validated valence scores that indicated both the sentiment polarity (positive/negative), and the sentiment intensity on a scale from \u20134 to +4. For example, the word \"okay\" has a positive valence of 0.9, \"good\" is 1.9, and \"great\" is 3.1, whereas \"horrible\" is \u20132.5, the frowning emoticon :( is \u20132.2, and \"sucks\" and it's slang derivative \"sux\" are both \u20131.5.\n\nManually creating (much less, validating) a comprehensive sentiment lexicon is a labor intensive and sometimes error prone process, so it is no wonder that many opinion mining researchers and practitioners rely so heavily on existing lexicons as primary resources. We are pleased to offer ours as a new resource. We began by constructing a list inspired by examining existing well-established sentiment word-banks (LIWC, ANEW, and GI). To this, we next incorporate numerous lexical features common to sentiment expression in microblogs, including:\n\n* a full list of Western-style emoticons, for example, :-) denotes a smiley face and generally indicates positive sentiment\n* sentiment-related acronyms and initialisms (e.g., LOL and WTF are both examples of sentiment-laden initialisms)\n* commonly used slang with sentiment value (e.g., nah, meh and giggly).\n\nWe empirically confirmed the general applicability of each feature candidate to sentiment expressions using a wisdom-of-the-crowd (WotC) approach (Surowiecki, 2004) to acquire a valid point estimate for the sentiment valence (polarity &amp; intensity) of each context-free candidate feature.\n</code></pre>\n<p>#. vaderSentiment.py\nThe Python code for the rule-based sentiment analysis engine. Implements the grammatical and syntactical rules described in the paper, incorporating empirically derived quantifications for the impact of each rule on the perceived intensity of sentiment in sentence-level text. Importantly, these heuristics go beyond what would normally be captured in a typical bag-of-words model. They incorporate <strong>word-order sensitive relationships</strong> between terms. For example, degree modifiers (also called intensifiers, booster words, or degree adverbs) impact sentiment intensity by either increasing or decreasing the intensity. Consider these examples:</p>\n<pre><code>(a) \"The service here is extremely good\"\n(b) \"The service here is good\"\n(c) \"The service here is marginally good\"\n\nFrom Table 3 in the paper, we see that for 95% of the data, using a degree modifier increases the positive sentiment intensity of example (a) by 0.227 to 0.36, with a mean difference of 0.293 on a rating scale from 1 to 4. Likewise, example (c) reduces the perceived sentiment intensity by 0.293, on average.\n</code></pre>\n<p>#. tweets_GroundTruth.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TWEET-TEXT</p>\n<pre><code>DESCRIPTION: includes \"tweet-like\" text as inspired by 4,000 tweets pulled from Twitter\u2019s public timeline, plus 200 completely contrived tweet-like texts intended to specifically test syntactical and grammatical conventions of conveying differences in sentiment intensity. The \"tweet-like\" texts incorporate a fictitious username (@anonymous) in places where a username might typically appear, along with a fake URL (http://url_removed) in places where a URL might typically appear, as inspired by the original tweets. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'tweets_anonDataRatings.txt' (described below).\n</code></pre>\n<p>#. tweets_anonDataRatings.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS</p>\n<pre><code>DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n</code></pre>\n<p>#. nytEditorialSnippets_GroundTruth.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TEXT-SNIPPET</p>\n<pre><code>DESCRIPTION: includes 5,190 sentence-level snippets from 500 New York Times opinion news editorials/articles; we used the NLTK tokenizer to segment the articles into sentence phrases, and added sentiment intensity ratings. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'nytEditorialSnippets_anonDataRatings.txt' (described below).\n</code></pre>\n<p>#. nytEditorialSnippets_anonDataRatings.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS</p>\n<pre><code>DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n</code></pre>\n<p>#. movieReviewSnippets_GroundTruth.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TEXT-SNIPPET</p>\n<pre><code>DESCRIPTION: includes 10,605 sentence-level snippets from rotten.tomatoes.com. The snippets were derived from an original set of 2000 movie reviews (1000 positive and 1000 negative) in Pang &amp; Lee (2004); we used the NLTK tokenizer to segment the reviews into sentence phrases, and added sentiment intensity ratings. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'movieReviewSnippets_anonDataRatings.txt' (described below).\n</code></pre>\n<p>#. movieReviewSnippets_anonDataRatings.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS</p>\n<pre><code>DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n</code></pre>\n<p>#. amazonReviewSnippets_GroundTruth.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, and TEXT-SNIPPET</p>\n<pre><code>DESCRIPTION: includes 3,708 sentence-level snippets from 309 customer reviews on 5 different products. The reviews were originally used in Hu &amp; Liu (2004); we added sentiment intensity ratings. The ID and MEAN-SENTIMENT-RATING correspond to the raw sentiment rating data provided in 'amazonReviewSnippets_anonDataRatings.txt' (described below).\n</code></pre>\n<p>#. amazonReviewSnippets_anonDataRatings.txt\nFORMAT: the file is tab delimited with ID, MEAN-SENTIMENT-RATING, STANDARD DEVIATION, and RAW-SENTIMENT-RATINGS</p>\n<pre><code>DESCRIPTION: Sentiment ratings from a minimum of 20 independent human raters (all pre-screened, trained, and quality checked for optimal inter-rater reliability).\n</code></pre>\n<p>#. Comp.Social website with more papers/research:\n<a href=\"http://comp.social.gatech.edu/papers/\" rel=\"nofollow\">Comp.Social</a></p>\n<h1>====================================\nPython Code Example</h1>\n<p>For a <strong>more complete demo</strong>, point your terminal to vader's install directory (e.g., if you installed using pip, it might be <code>\\Python3x\\lib\\site-packages\\vaderSentiment</code>), and then run <code>python vaderSentiment.py</code>.</p>\n<p>The demo has more examples of tricky sentences that confuse other sentiment analysis tools. It also demonstrates how VADER can work in conjunction with NLTK to do sentiment analysis on longer texts...i.e., decomposing paragraphs, articles/reports/publications, or novels into sentence-level analysis.  It also demonstrates a concept for assessing the sentiment of images, video, or other tagged multimedia content.</p>\n<p>If you have access to the Internet, the demo will also show how VADER can work with analyzing sentiment of non-English text sentences.</p>\n<p>::</p>\n<pre><code>from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n#note: depending on how you installed (e.g., using source code download versus pip install), you may need to import like this:\n#from vaderSentiment import SentimentIntensityAnalyzer\n\n# --- examples -------\n\tsentences = [\"VADER \u00e4r smart, stilig och rolig.\",  # positive sentence example\n             \"VADER \u00e4r smart, stilig och rolig!\",\n             # punctuation emphasis handled correctly (sentiment intensity adjusted)\n             \"VADER \u00e4r v\u00e4ldigt mart, stilig och rolig.\",\n             # booster words handled correctly (sentiment intensity adjusted)\n             \"VADER \u00e4r V\u00c4LDIGT SMART, STILIG och ROLIG.\",  # emphasis for ALLCAPS handled\n             \"VADER \u00e4r V\u00c4LDIGT SMART, stilig och ROLIG!!!\",\n             # combination of signals - VADER appropriately adjusts intensity\n             \"VADER \u00e4r v\u00e4ldigt smart, uber stilig och SJUKT ROLIG!!!\",\n             # booster words &amp; punctuation make this close to ceiling for score\n             \"VADER \u00e4r inte smart, stilig och inte rolig.\",  # negation sentence example\n             \"Boken var bra.\",  # positive sentence\n             \"Det \u00e4r \u00e5tminstone inte en d\u00e5lig bok\",  # negated negative sentence with contraction\n             \"Boken var bara n\u00e5gorlunda bra.\",\n             # qualified positive sentence is handled correctly (intensity adjusted)\n             \"Handlingen var bra, men karakt\u00e4rerna \u00e4r okomponerande och dialogen \u00e4r inte bra.\",\n             # mixed negation sentence\n             \"Den h\u00e4r dagen SUX!\",  # negative slang with capitalization emphasis\n             \"Den h\u00e4r dagen suger bara delvis. Men jag \u00f6verlever, lol\",\n             # mixed sentiment example with slang and constrastive conjunction \"but\"\n             \"Se till att du :) eller :D idag!\",  # emoticons handled\n             \"F\u00e5nga utf-8 emoji s\u00e5 som \ud83d\udc98 och \ud83d\udc8b och \ud83d\ude01\",  # emojis handled\n             \"Inte d\u00e5lig alls\"  # Capitalized negation\n             ]\n\nanalyzer = SentimentIntensityAnalyzer()\nfor sentence in sentences:\n    vs = analyzer.polarity_scores(sentence)\n    print(\"{:-&lt;65} {}\".format(sentence, str(vs)))\n</code></pre>\n<p>For a <strong>more complete demo</strong>, go to the install directory and run <code>python vaderSentiment.py</code>. (Be sure you are set to handle UTF-8 encoding in your terminal or IDE.)</p>\n<h1>====================================\nOutput for the above example code</h1>\n<p>::</p>\n<pre><code>VADER \u00e4r smart, stilig och rolig.-------------------------------- {'neg': 0.272, 'neu': 0.24, 'pos': 0.488, 'compound': 0.4019}\nVADER \u00e4r smart, stilig och rolig!-------------------------------- {'neg': 0.266, 'neu': 0.235, 'pos': 0.5, 'compound': 0.4574}\nVADER \u00e4r v\u00e4ldigt mart, stilig och rolig.------------------------- {'neg': 0.247, 'neu': 0.29, 'pos': 0.463, 'compound': 0.4549}\nVADER \u00e4r V\u00c4LDIGT SMART, STILIG och ROLIG.------------------------ {'neg': 0.213, 'neu': 0.251, 'pos': 0.536, 'compound': 0.7303}\nVADER \u00e4r V\u00c4LDIGT SMART, stilig och ROLIG!!!---------------------- {'neg': 0.211, 'neu': 0.249, 'pos': 0.54, 'compound': 0.7418}\nVADER \u00e4r v\u00e4ldigt smart, uber stilig och SJUKT ROLIG!!!----------- {'neg': 0.182, 'neu': 0.321, 'pos': 0.497, 'compound': 0.784}\nVADER \u00e4r inte smart, stilig och inte rolig.---------------------- {'neg': 0.174, 'neu': 0.154, 'pos': 0.672, 'compound': 0.8658}\nBoken var bra.--------------------------------------------------- {'neg': 0.0, 'neu': 0.328, 'pos': 0.672, 'compound': 0.6249}\nDet \u00e4r \u00e5tminstone inte en d\u00e5lig bok------------------------------ {'neg': 0.608, 'neu': 0.181, 'pos': 0.211, 'compound': -0.765}\nBoken var bara n\u00e5gorlunda bra.----------------------------------- {'neg': 0.0, 'neu': 0.512, 'pos': 0.488, 'compound': 0.5868}\nHandlingen var bra, men karakt\u00e4rerna \u00e4r okomponerande och dialogen \u00e4r inte bra. {'neg': 0.322, 'neu': 0.23, 'pos': 0.448, 'compound': 0.6486}\nDen h\u00e4r dagen SUX!----------------------------------------------- {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\nDen h\u00e4r dagen suger bara delvis. Men jag \u00f6verlever, lol---------- {'neg': 0.259, 'neu': 0.476, 'pos': 0.265, 'compound': 0.2716}\nSe till att du :) eller :D idag!--------------------------------- {'neg': 0.122, 'neu': 0.244, 'pos': 0.635, 'compound': 0.8564}\nF\u00e5nga utf-8 emoji s\u00e5 som \ud83d\udc98 och \ud83d\udc8b och \ud83d\ude01--------------------------- {'neg': 0.106, 'neu': 0.894, 'pos': 0.0, 'compound': -0.2247}\nInte d\u00e5lig alls-------------------------------------------------- {'neg': 0.438, 'neu': 0.125, 'pos': 0.438, 'compound': 0.0}\n</code></pre>\n<h1>====================================\nAbout the Scoring</h1>\n<ul>\n<li>\n<p>The <code>compound</code> score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate.</p>\n<p>It is also useful for researchers who would like to set standardized thresholds for classifying sentences as either positive, neutral, or negative.\nTypical threshold values (used in the literature cited on this page) are:</p>\n</li>\n</ul>\n<p>#. <strong>positive sentiment</strong>: <code>compound</code> score &gt;=  0.05\n#. <strong>neutral  sentiment</strong>: (<code>compound</code> score &gt; -0.05) and (<code>compound</code> score &lt; 0.05)\n#. <strong>negative sentiment</strong>: <code>compound</code> score &lt;= -0.05</p>\n<ul>\n<li>The <code>pos</code>, <code>neu</code>, and <code>neg</code> scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation).  These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence.</li>\n</ul>\n<h1>====================================\nPorts to Other Programming Languages</h1>\n<p>Feel free to let me know about ports of VADER Sentiment to other programming languages. So far, I know about these helpful ports:</p>\n<p>#. Java\n<code>VaderSentimentJava &lt;https://github.com/apanimesh061/VaderSentimentJava&gt;</code>_ by apanimesh061</p>\n<p>#. JavaScript\n<code>vaderSentiment-js &lt;https://github.com/vaderSentiment/vaderSentiment-js&gt;</code>_ by nimaeskandary</p>\n<p>#. PHP\n<code>php-vadersentiment &lt;https://github.com/abusby/php-vadersentiment&gt;</code>_ by abusby</p>\n<p>#. Scala\n<code>Sentiment &lt;https://github.com/ziyasal/Sentiment&gt;</code>_ by ziyasal</p>\n<p>#. C#\n<code>vadersharp &lt;https://github.com/codingupastorm/vadersharp&gt;</code>_ by codingupastorm Jordan Andrews</p>\n<p>#. Rust\n<code>vader-sentiment-rust &lt;https://github.com/ckw017/vader-sentiment-rust&gt;</code>_ by ckw017</p>\n\n          </div>"}, "last_serial": 6037091, "releases": {"1.0.1": [{"comment_text": "", "digests": {"md5": "24d75c33c8bff126c9481465d345accb", "sha256": "1fbecad7d17720a464a32dfb4282cc3550ee040178dec6e8e5ee4a13d7406c8a"}, "downloads": -1, "filename": "vaderSentiment-swedish-1.0.1.tar.gz", "has_sig": false, "md5_digest": "24d75c33c8bff126c9481465d345accb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2461234, "upload_time": "2019-10-23T19:08:31", "upload_time_iso_8601": "2019-10-23T19:08:31.352045Z", "url": "https://files.pythonhosted.org/packages/e6/4c/792ff230d9dd87221c08fb96f53ec916372222a008c8f10842bba94c2586/vaderSentiment-swedish-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "719e9b43347459d9b8f8aa6f35499a47", "sha256": "7d5ef873111df3097bb8b9c083e2b30c1f676e7705766991987ffddf421063ae"}, "downloads": -1, "filename": "vaderSentiment-swedish-1.0.2.tar.gz", "has_sig": false, "md5_digest": "719e9b43347459d9b8f8aa6f35499a47", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2455632, "upload_time": "2019-10-27T13:55:31", "upload_time_iso_8601": "2019-10-27T13:55:31.539920Z", "url": "https://files.pythonhosted.org/packages/90/73/d154347aec696d7f071c6d6af8c7d7384b9b70b3a18b9087d79052b6e295/vaderSentiment-swedish-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "55fdf0e75b5412715604b0f061de862a", "sha256": "29fb1c5f24c388dff2ce7118f967bd65d53f7c86b2f3a19ab75da3f767b02d1a"}, "downloads": -1, "filename": "vaderSentiment-swedish-1.0.3.tar.gz", "has_sig": false, "md5_digest": "55fdf0e75b5412715604b0f061de862a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2455623, "upload_time": "2019-10-27T14:03:38", "upload_time_iso_8601": "2019-10-27T14:03:38.242208Z", "url": "https://files.pythonhosted.org/packages/ed/96/d55dcd6933c8bc083ad93cebaecb8e447ff389466e816d81139d493ade42/vaderSentiment-swedish-1.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "55fdf0e75b5412715604b0f061de862a", "sha256": "29fb1c5f24c388dff2ce7118f967bd65d53f7c86b2f3a19ab75da3f767b02d1a"}, "downloads": -1, "filename": "vaderSentiment-swedish-1.0.3.tar.gz", "has_sig": false, "md5_digest": "55fdf0e75b5412715604b0f061de862a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2455623, "upload_time": "2019-10-27T14:03:38", "upload_time_iso_8601": "2019-10-27T14:03:38.242208Z", "url": "https://files.pythonhosted.org/packages/ed/96/d55dcd6933c8bc083ad93cebaecb8e447ff389466e816d81139d493ade42/vaderSentiment-swedish-1.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:38:19 2020"}