{"info": {"author": "Tikitu de Jager", "author_email": "tikitu@logophile.org", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.6", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "===============================\ndripfeed\n===============================\n\n.. image:: https://travis-ci.org/tikitu/dripfeed.png?branch=master\n        :target: https://travis-ci.org/tikitu/dripfeed\n\n.. image:: https://pypip.in/d/dripfeed/badge.png\n        :target: https://crate.io/packages/dripfeed?version=latest\n\n\nCreate an RSS feed of a webcomic archive, for slow catchup.\n\nEver time I discover a new webcomic that's worth following, I lose hours (often night-time hours) to catching up with\nthe archives. This tool exists to avoid this problem: I can create my own dripfeed for the comic, schedule it with cron\nto update two or three times a day, and add the feed to my ordinary feed reader. So long as ``dripfeed`` updates more\noften than the comic author, my dripfeed will catch up eventually, and I can switch to the official feed from then on.\n\nExample usage\n-------------\n\nCreate the feed::\n\n    dripfeed init gunnerkrigg  # name for dripfeed commands like \"update\", \"remove\" (commandline-friendly)\n                  --rss ./gunnerkrigg.rss  # rss file for output (will be created)\n                  --url 'http://gunnerkrigg.com/?p=1'  # where to find the first page\n                  --next \"//img[@src='http://www.gunnerkrigg.com/images/next_a.jpg']/..\"  # XPath for \"next\" link\n                  --name 'Gunnerkrigg Court'  # optional long name for output (doesn't have to be commandline-friendly)\n\nThe ``--next`` parameter is an XPath expression that extracts the ``<a>`` element whose ``href`` points to the next page.\n(This expression will be used for all pages of the comic.)\n\nThis places configuration for ``gunnerkrigg`` in a config file at ``~/.dripfeed.cfg`` (creating the file if it doesn't\nalready exist).\n\nNow running::\n\n    dripfeed update gunnerkrigg\n\nwill update the rss feed at ``./gunnerkrigg.rss`` and store progress in ``~/.dripfeed.cfg``: I'd expect this command to\ngo in a cron job.\n\nErrors are recorded in the RSS feed, and you can run ``dripfeed update`` with a ``--debug`` flag to see a full stack\ntrace of the error.\n\nOutput\n------\n\nThe RSS feed entries are intentionally very very simple: they contain just a link to the page, and some placeholder text\ntelling you which episode you're looking at (counting from episode 1 at the initial URL).\n\nIt would be possible to extend the tool to include some degree of content scraping: more XPath expressions could\noptionally extract the comic image, title, commentary, etc. I *do not* intend to do this; of course you're welcome to\nfork the code and make whatever changes you like, but I will not accept pull requests adding these features. The reason\nis that I want you to visit the original comic pages: making a living from webcomics is tricky enough as it is, and\nmany comics are either directly or indirectly ad-supported. This script is not a syndication tool and is emphatically\nnot intended to make business any harder for the authors whose work I admire.\n\nRequirements\n------------\n\n- Python >= 2.6\n\nLicense\n-------\n\nMIT licensed. See the bundled `LICENSE <https://bitbucket.org/tikitu/dripfeed/src/tip/dripfeed/LICENSE>`_ file for more details.\n\nTODO\n----\n\nNot sure when I'll get around to these, but here are a couple things I would like to do with it (maybe more for\nthe learning experience than because the task really demands it):\n\n* Interactive ``init`` that prompts for necessary args and validates them (especially the xpath).\n* Example config file pushing my favourite webcomics.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://bitbucket.org/tikitu/dripfeed", "keywords": "dripfeed", "license": "Copyright 2014 Tikitu de Jager\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.", "maintainer": null, "maintainer_email": null, "name": "dripfeed", "package_url": "https://pypi.org/project/dripfeed/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/dripfeed/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://bitbucket.org/tikitu/dripfeed"}, "release_url": "https://pypi.org/project/dripfeed/1.0.2/", "requires_dist": null, "requires_python": null, "summary": "Create an RSS feed of a webcomic archive, for slow perusal.", "version": "1.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/tikitu/dripfeed\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/tikitu/dripfeed.png?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/64bd1a43f23b85d2df42e90bed853b39a3ac6879/68747470733a2f2f7472617669732d63692e6f72672f74696b6974752f64726970666565642e706e673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://crate.io/packages/dripfeed?version=latest\" rel=\"nofollow\"><img alt=\"https://pypip.in/d/dripfeed/badge.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cc2c2e085e3616abba443057630f33c12df718c6/68747470733a2f2f70797069702e696e2f642f64726970666565642f62616467652e706e67\"></a>\n<p>Create an RSS feed of a webcomic archive, for slow catchup.</p>\n<p>Ever time I discover a new webcomic that\u2019s worth following, I lose hours (often night-time hours) to catching up with\nthe archives. This tool exists to avoid this problem: I can create my own dripfeed for the comic, schedule it with cron\nto update two or three times a day, and add the feed to my ordinary feed reader. So long as <tt>dripfeed</tt> updates more\noften than the comic author, my dripfeed will catch up eventually, and I can switch to the official feed from then on.</p>\n<div id=\"example-usage\">\n<h2>Example usage</h2>\n<p>Create the feed:</p>\n<pre>dripfeed init gunnerkrigg  # name for dripfeed commands like \"update\", \"remove\" (commandline-friendly)\n              --rss ./gunnerkrigg.rss  # rss file for output (will be created)\n              --url 'http://gunnerkrigg.com/?p=1'  # where to find the first page\n              --next \"//img[@src='http://www.gunnerkrigg.com/images/next_a.jpg']/..\"  # XPath for \"next\" link\n              --name 'Gunnerkrigg Court'  # optional long name for output (doesn't have to be commandline-friendly)\n</pre>\n<p>The <tt><span class=\"pre\">--next</span></tt> parameter is an XPath expression that extracts the <tt>&lt;a&gt;</tt> element whose <tt>href</tt> points to the next page.\n(This expression will be used for all pages of the comic.)</p>\n<p>This places configuration for <tt>gunnerkrigg</tt> in a config file at <tt><span class=\"pre\">~/.dripfeed.cfg</span></tt> (creating the file if it doesn\u2019t\nalready exist).</p>\n<p>Now running:</p>\n<pre>dripfeed update gunnerkrigg\n</pre>\n<p>will update the rss feed at <tt>./gunnerkrigg.rss</tt> and store progress in <tt><span class=\"pre\">~/.dripfeed.cfg</span></tt>: I\u2019d expect this command to\ngo in a cron job.</p>\n<p>Errors are recorded in the RSS feed, and you can run <tt>dripfeed update</tt> with a <tt><span class=\"pre\">--debug</span></tt> flag to see a full stack\ntrace of the error.</p>\n</div>\n<div id=\"output\">\n<h2>Output</h2>\n<p>The RSS feed entries are intentionally very very simple: they contain just a link to the page, and some placeholder text\ntelling you which episode you\u2019re looking at (counting from episode 1 at the initial URL).</p>\n<p>It would be possible to extend the tool to include some degree of content scraping: more XPath expressions could\noptionally extract the comic image, title, commentary, etc. I <em>do not</em> intend to do this; of course you\u2019re welcome to\nfork the code and make whatever changes you like, but I will not accept pull requests adding these features. The reason\nis that I want you to visit the original comic pages: making a living from webcomics is tricky enough as it is, and\nmany comics are either directly or indirectly ad-supported. This script is not a syndication tool and is emphatically\nnot intended to make business any harder for the authors whose work I admire.</p>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<ul>\n<li>Python &gt;= 2.6</li>\n</ul>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>MIT licensed. See the bundled <a href=\"https://bitbucket.org/tikitu/dripfeed/src/tip/dripfeed/LICENSE\" rel=\"nofollow\">LICENSE</a> file for more details.</p>\n</div>\n<div id=\"todo\">\n<h2>TODO</h2>\n<p>Not sure when I\u2019ll get around to these, but here are a couple things I would like to do with it (maybe more for\nthe learning experience than because the task really demands it):</p>\n<ul>\n<li>Interactive <tt>init</tt> that prompts for necessary args and validates them (especially the xpath).</li>\n<li>Example config file pushing my favourite webcomics.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 1086608, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "1a9e1a1164b88d868a7c338c5b8289b3", "sha256": "5b4439c8ac9498a79b36484d7c04772db74e1c69e777047207dae75593438ddd"}, "downloads": -1, "filename": "dripfeed-0.1.0.tar.gz", "has_sig": false, "md5_digest": "1a9e1a1164b88d868a7c338c5b8289b3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8479, "upload_time": "2014-04-22T19:59:14", "upload_time_iso_8601": "2014-04-22T19:59:14.978628Z", "url": "https://files.pythonhosted.org/packages/f6/e6/32f1f253c2263595dd947ef57ca8606320d231faa9d5ce4e08beef243447/dripfeed-0.1.0.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "32fe8621430f180bf3425934a0587ce3", "sha256": "d802e2766fbdc27c4767f6afa51a939b8a207597deff1df3188704608fba6983"}, "downloads": -1, "filename": "dripfeed-0.9.0.tar.gz", "has_sig": false, "md5_digest": "32fe8621430f180bf3425934a0587ce3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8467, "upload_time": "2014-04-22T20:02:30", "upload_time_iso_8601": "2014-04-22T20:02:30.682480Z", "url": "https://files.pythonhosted.org/packages/bd/b2/bda31bc01eec072456a472f6aae4faca104cef413df02551c164fb4a43d5/dripfeed-0.9.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "35e41bc1e36728c6233916fda3a4da1b", "sha256": "532a578b97598a148200ac21e383596fe9910a4a64c6f8b9eca964538e2c2dd0"}, "downloads": -1, "filename": "dripfeed-1.0.0.tar.gz", "has_sig": false, "md5_digest": "35e41bc1e36728c6233916fda3a4da1b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8882, "upload_time": "2014-04-26T19:57:06", "upload_time_iso_8601": "2014-04-26T19:57:06.165734Z", "url": "https://files.pythonhosted.org/packages/c6/01/5572f464301bac1623161141530900fee340e156d7ad9f627232b801dfc0/dripfeed-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "34730df03036630d27e053131368f3f7", "sha256": "dbefd9683464f32aeeaa57c839736b5ea46570d33f298fb0394504ed71e5c872"}, "downloads": -1, "filename": "dripfeed-1.0.1.tar.gz", "has_sig": false, "md5_digest": "34730df03036630d27e053131368f3f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8892, "upload_time": "2014-04-26T20:40:22", "upload_time_iso_8601": "2014-04-26T20:40:22.348888Z", "url": "https://files.pythonhosted.org/packages/01/d7/46bdcc739ed979f50ad2a788fa8d5b4a8e66f61f5000783aa77e1f37e3b7/dripfeed-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "df01fc162284ee9f028aa245d32ab6de", "sha256": "30c8fa2b76d22ba3d80bc17a8722ecb1a018d53fe5f281a75ad80dcfc096e3bd"}, "downloads": -1, "filename": "dripfeed-1.0.2.tar.gz", "has_sig": false, "md5_digest": "df01fc162284ee9f028aa245d32ab6de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8905, "upload_time": "2014-05-09T10:38:42", "upload_time_iso_8601": "2014-05-09T10:38:42.840935Z", "url": "https://files.pythonhosted.org/packages/55/82/9a02a61df7c88e9e20b0277df8a84c13621d3d74897efd0f17105bc2d890/dripfeed-1.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "df01fc162284ee9f028aa245d32ab6de", "sha256": "30c8fa2b76d22ba3d80bc17a8722ecb1a018d53fe5f281a75ad80dcfc096e3bd"}, "downloads": -1, "filename": "dripfeed-1.0.2.tar.gz", "has_sig": false, "md5_digest": "df01fc162284ee9f028aa245d32ab6de", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8905, "upload_time": "2014-05-09T10:38:42", "upload_time_iso_8601": "2014-05-09T10:38:42.840935Z", "url": "https://files.pythonhosted.org/packages/55/82/9a02a61df7c88e9e20b0277df8a84c13621d3d74897efd0f17105bc2d890/dripfeed-1.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:36 2020"}