{"info": {"author": "Fernando Paladini", "author_email": "fnpaladini@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "==========================\npySpark-connector-kairosdb\n==========================\n\npySpark-connector-kairosdb provides you an easy way to get data from KairosDB and make it available on Spark as a DataFrame. It's simple as that::\n\n    #!/usr/bin/env python\n\n    # sconnk means \"py(S)park-(CONN)ector-(K)airosdb\"\n    from sconnk import Connection, Dataframe\n\n    query_data = {\n\t\t\t\"start_relative\": { \"value\": \"5\", \"unit\": \"years\" },\n\t\t\t\"metrics\": [{ \"name\": \"test_\", \"limit\": 5 },\n\t\t\t\t\t\t{ \"name\": \"DP_058424\", \"limit\": 10 },\n\t\t\t\t\t\t{ \"name\": \"teste_gzip\", \"limit\": 5 },\n\t\t\t\t\t\t{ \"name\": \"DP_063321\", \"limit\": 10 }]\n\t}\n\n\t# Creating a connection with KairosDB database (in the given address).\n\tconn = Connection(\"http://localhost:8080/\")\n\n\t# Performing our query on KairosDB.\n\tjson_data = conn.query(query_data)\n\n\t# Creating a new Dataframe object passing the JSON returned by KairosDB API.\n\tdf = Dataframe(json_data).df\n\n\t# Print the dataframe.\n\tdf.show()\n\nRemember this's a ALPHA module without good documentation, examples and even well implemented features. We've a long highway to cross.\n\nFuture\n=========\n\nThis module is in development and we've the following plannings for the future of this module:\n\n* Write good documentation\n* Write tests - a lot of them.\n* Add support to RDD\n* Don't write to JSON file in order to parse it in Spark.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "UNKNOWN", "keywords": null, "license": "LICENSE.txt", "maintainer": null, "maintainer_email": null, "name": "pySpark-connector-kairosdb", "package_url": "https://pypi.org/project/pySpark-connector-kairosdb/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/pySpark-connector-kairosdb/", "project_urls": {"Download": "UNKNOWN", "Homepage": "UNKNOWN"}, "release_url": "https://pypi.org/project/pySpark-connector-kairosdb/0.1.0/", "requires_dist": null, "requires_python": null, "summary": "Useful towel-related stuff.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>pySpark-connector-kairosdb provides you an easy way to get data from KairosDB and make it available on Spark as a DataFrame. It\u2019s simple as that:</p>\n<pre>#!/usr/bin/env python\n\n# sconnk means \"py(S)park-(CONN)ector-(K)airosdb\"\nfrom sconnk import Connection, Dataframe\n\nquery_data = {\n                    \"start_relative\": { \"value\": \"5\", \"unit\": \"years\" },\n                    \"metrics\": [{ \"name\": \"test_\", \"limit\": 5 },\n                                            { \"name\": \"DP_058424\", \"limit\": 10 },\n                                            { \"name\": \"teste_gzip\", \"limit\": 5 },\n                                            { \"name\": \"DP_063321\", \"limit\": 10 }]\n    }\n\n    # Creating a connection with KairosDB database (in the given address).\n    conn = Connection(\"http://localhost:8080/\")\n\n    # Performing our query on KairosDB.\n    json_data = conn.query(query_data)\n\n    # Creating a new Dataframe object passing the JSON returned by KairosDB API.\n    df = Dataframe(json_data).df\n\n    # Print the dataframe.\n    df.show()\n</pre>\n<p>Remember this\u2019s a ALPHA module without good documentation, examples and even well implemented features. We\u2019ve a long highway to cross.</p>\n<div id=\"future\">\n<h2>Future</h2>\n<p>This module is in development and we\u2019ve the following plannings for the future of this module:</p>\n<ul>\n<li>Write good documentation</li>\n<li>Write tests - a lot of them.</li>\n<li>Add support to RDD</li>\n<li>Don\u2019t write to JSON file in order to parse it in Spark.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 1766998, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ad38d0e8f3fbe1be6e05bddcfea5b09f", "sha256": "062a97f39546265aa4c9160b37b785e53b91d6deff7bd21adcd0bb7c0b05b9d5"}, "downloads": -1, "filename": "pySpark-connector-kairosdb-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ad38d0e8f3fbe1be6e05bddcfea5b09f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2725, "upload_time": "2015-10-13T16:14:53", "upload_time_iso_8601": "2015-10-13T16:14:53.191961Z", "url": "https://files.pythonhosted.org/packages/d5/d8/1c0b46f8bf206e31a225788e6ac1601f565d3278f5623da052267048a522/pySpark-connector-kairosdb-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ad38d0e8f3fbe1be6e05bddcfea5b09f", "sha256": "062a97f39546265aa4c9160b37b785e53b91d6deff7bd21adcd0bb7c0b05b9d5"}, "downloads": -1, "filename": "pySpark-connector-kairosdb-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ad38d0e8f3fbe1be6e05bddcfea5b09f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2725, "upload_time": "2015-10-13T16:14:53", "upload_time_iso_8601": "2015-10-13T16:14:53.191961Z", "url": "https://files.pythonhosted.org/packages/d5/d8/1c0b46f8bf206e31a225788e6ac1601f565d3278f5623da052267048a522/pySpark-connector-kairosdb-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:18 2020"}