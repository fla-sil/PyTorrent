{"info": {"author": "The DataLad Team and Contributors", "author_email": "team@datalad.org", "bugtrack_url": null, "classifiers": [], "description": "::\n\n    ____          _           _                 _\n   |  _ \\   __ _ | |_   __ _ | |      __ _   __| |\n   | | | | / _` || __| / _` || |     / _` | / _` |\n   | |_| || (_| || |_ | (_| || |___ | (_| || (_| |\n   |____/  \\__,_| \\__| \\__,_||_____| \\__,_| \\__,_|\n                                      Crawler\n\n|Travis tests status| |codecov.io| |Documentation| |License: MIT|\n|GitHub release| |PyPI version fury.io| |Average time to resolve an\nissue| |Percentage of issues still open|\n\nThis extension enhances DataLad (http://datalad.org) for crawling\nexternal web resources into an automated data distribution. Please see\nthe `extension documentation <http://datalad-crawler.rtfd.org>`__ for a\ndescription on additional commands and functionality.\n\nFor general information on how to use or contribute to DataLad (and this\nextension), please see the `DataLad website <http://datalad.org>`__ or\nthe `main GitHub project page <http://datalad.org>`__.\n\nInstallation\n------------\n\nBefore you install this package, please make sure that you `install a\nrecent version of\ngit-annex <https://git-annex.branchable.com/install>`__. Afterwards,\ninstall the latest version of ``datalad-crawler`` from\n`PyPi <https://pypi.org/project/datalad-crawler>`__. It is recommended\nto use a dedicated `virtualenv <https://virtualenv.pypa.io>`__:\n\n::\n\n   # create and enter a new virtual environment (optional)\n   virtualenv --system-site-packages --python=python3 ~/env/datalad\n   . ~/env/datalad/bin/activate\n\n   # install from PyPi\n   pip install datalad_crawler\n\nSupport\n-------\n\nThe documentation of this project is found here:\nhttp://docs.datalad.org/projects/crawler\n\nAll bugs, concerns and enhancement requests for this software can be\nsubmitted here: https://github.com/datalad/datalad-crawler/issues\n\nIf you have a problem or would like to ask a question about how to use\nDataLad, please `submit a question to\nNeuroStars.org <https://neurostars.org/tags/datalad>`__ with a\n``datalad`` tag. NeuroStars.org is a platform similar to StackOverflow\nbut dedicated to neuroinformatics.\n\nAll previous DataLad questions are available here:\nhttp://neurostars.org/tags/datalad/\n\nAcknowledgements\n----------------\n\nDataLad development is supported by a US-German collaboration in\ncomputational neuroscience (CRCNS) project \u201cDataGit: converging\ncatalogues, warehouses, and deployment logistics into a federated \u2018data\ndistribution\u2019\u201d (Halchenko/Hanke), co-funded by the US National Science\nFoundation (NSF 1429999) and the German Federal Ministry of Education\nand Research (BMBF 01GQ1411). Additional support is provided by the\nGerman federal state of Saxony-Anhalt and the European Regional\nDevelopment Fund (ERDF), Project: Center for Behavioral Brain Sciences,\nImaging Platform. This work is further facilitated by the ReproNim\nproject (NIH 1P41EB019936-01A1).\n\n.. |Travis tests status| image:: https://secure.travis-ci.org/datalad/datalad-crawler.png?branch=master\n   :target: https://travis-ci.org/datalad/datalad-crawler\n.. |codecov.io| image:: https://codecov.io/github/datalad/datalad-crawler/coverage.svg?branch=master\n   :target: https://codecov.io/github/datalad/datalad-crawler?branch=master\n.. |Documentation| image:: https://readthedocs.org/projects/datalad-crawler/badge/?version=latest\n   :target: http://datalad-crawler.rtfd.org\n.. |License: MIT| image:: https://img.shields.io/badge/License-MIT-yellow.svg\n   :target: https://opensource.org/licenses/MIT\n.. |GitHub release| image:: https://img.shields.io/github/release/datalad/datalad-crawler.svg\n   :target: https://GitHub.com/datalad/datalad-crawler/releases/\n.. |PyPI version fury.io| image:: https://badge.fury.io/py/datalad-crawler.svg\n   :target: https://pypi.python.org/pypi/datalad-crawler/\n.. |Average time to resolve an issue| image:: http://isitmaintained.com/badge/resolution/datalad/datalad-crawler.svg\n   :target: http://isitmaintained.com/project/datalad/datalad-crawler\n.. |Percentage of issues still open| image:: http://isitmaintained.com/badge/open/datalad/datalad-crawler.svg\n   :target: http://isitmaintained.com/project/datalad/datalad-crawler\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "datalad_crawler", "package_url": "https://pypi.org/project/datalad_crawler/", "platform": "", "project_url": "https://pypi.org/project/datalad_crawler/", "project_urls": null, "release_url": "https://pypi.org/project/datalad_crawler/0.5.0/", "requires_dist": null, "requires_python": "", "summary": "DataLad extension package for crawling external web resources into an automated data distribution", "version": "0.5.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <pre> ____          _           _                 _\n|  _ \\   __ _ | |_   __ _ | |      __ _   __| |\n| | | | / _` || __| / _` || |     / _` | / _` |\n| |_| || (_| || |_ | (_| || |___ | (_| || (_| |\n|____/  \\__,_| \\__| \\__,_||_____| \\__,_| \\__,_|\n                                   Crawler\n</pre>\n<p><a href=\"https://travis-ci.org/datalad/datalad-crawler\" rel=\"nofollow\"><img alt=\"Travis tests status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ec584e7e8575ce6e0d8d89fce6755766ac308794/68747470733a2f2f7365637572652e7472617669732d63692e6f72672f646174616c61642f646174616c61642d637261776c65722e706e673f6272616e63683d6d6173746572\"></a> <a href=\"https://codecov.io/github/datalad/datalad-crawler?branch=master\" rel=\"nofollow\"><img alt=\"codecov.io\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d3df613a62501ce1d7acff71ffc420c352ae682f/68747470733a2f2f636f6465636f762e696f2f6769746875622f646174616c61642f646174616c61642d637261776c65722f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a> <a href=\"http://datalad-crawler.rtfd.org\" rel=\"nofollow\"><img alt=\"Documentation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/33ced59edbb0563a76b4e47b61317a5383b82ad3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f646174616c61642d637261776c65722f62616467652f3f76657273696f6e3d6c6174657374\"></a> <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a>\n<a href=\"https://GitHub.com/datalad/datalad-crawler/releases/\" rel=\"nofollow\"><img alt=\"GitHub release\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d589b037d030cdce7fc98c7709405d8fa30a6cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f646174616c61642f646174616c61642d637261776c65722e737667\"></a> <a href=\"https://pypi.python.org/pypi/datalad-crawler/\" rel=\"nofollow\"><img alt=\"PyPI version fury.io\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/87b39f5901ff073c5ac2741ae97dc71cd3d1b4e2/68747470733a2f2f62616467652e667572792e696f2f70792f646174616c61642d637261776c65722e737667\"></a> <a href=\"http://isitmaintained.com/project/datalad/datalad-crawler\" rel=\"nofollow\"><img alt=\"Average time to resolve an issue\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c5479fb63b6c0366710260c7f6c515e42b4fde1a/687474703a2f2f697369746d61696e7461696e65642e636f6d2f62616467652f7265736f6c7574696f6e2f646174616c61642f646174616c61642d637261776c65722e737667\"></a> <a href=\"http://isitmaintained.com/project/datalad/datalad-crawler\" rel=\"nofollow\"><img alt=\"Percentage of issues still open\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c7cbbc223c25935ef35c3bad91940f3e00128978/687474703a2f2f697369746d61696e7461696e65642e636f6d2f62616467652f6f70656e2f646174616c61642f646174616c61642d637261776c65722e737667\"></a></p>\n<p>This extension enhances DataLad (<a href=\"http://datalad.org\" rel=\"nofollow\">http://datalad.org</a>) for crawling\nexternal web resources into an automated data distribution. Please see\nthe <a href=\"http://datalad-crawler.rtfd.org\" rel=\"nofollow\">extension documentation</a> for a\ndescription on additional commands and functionality.</p>\n<p>For general information on how to use or contribute to DataLad (and this\nextension), please see the <a href=\"http://datalad.org\" rel=\"nofollow\">DataLad website</a> or\nthe <a href=\"http://datalad.org\" rel=\"nofollow\">main GitHub project page</a>.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>Before you install this package, please make sure that you <a href=\"https://git-annex.branchable.com/install\" rel=\"nofollow\">install a\nrecent version of\ngit-annex</a>. Afterwards,\ninstall the latest version of <tt><span class=\"pre\">datalad-crawler</span></tt> from\n<a href=\"https://pypi.org/project/datalad-crawler\" rel=\"nofollow\">PyPi</a>. It is recommended\nto use a dedicated <a href=\"https://virtualenv.pypa.io\" rel=\"nofollow\">virtualenv</a>:</p>\n<pre># create and enter a new virtual environment (optional)\nvirtualenv --system-site-packages --python=python3 ~/env/datalad\n. ~/env/datalad/bin/activate\n\n# install from PyPi\npip install datalad_crawler\n</pre>\n</div>\n<div id=\"support\">\n<h2>Support</h2>\n<p>The documentation of this project is found here:\n<a href=\"http://docs.datalad.org/projects/crawler\" rel=\"nofollow\">http://docs.datalad.org/projects/crawler</a></p>\n<p>All bugs, concerns and enhancement requests for this software can be\nsubmitted here: <a href=\"https://github.com/datalad/datalad-crawler/issues\" rel=\"nofollow\">https://github.com/datalad/datalad-crawler/issues</a></p>\n<p>If you have a problem or would like to ask a question about how to use\nDataLad, please <a href=\"https://neurostars.org/tags/datalad\" rel=\"nofollow\">submit a question to\nNeuroStars.org</a> with a\n<tt>datalad</tt> tag. NeuroStars.org is a platform similar to StackOverflow\nbut dedicated to neuroinformatics.</p>\n<p>All previous DataLad questions are available here:\n<a href=\"http://neurostars.org/tags/datalad/\" rel=\"nofollow\">http://neurostars.org/tags/datalad/</a></p>\n</div>\n<div id=\"acknowledgements\">\n<h2>Acknowledgements</h2>\n<p>DataLad development is supported by a US-German collaboration in\ncomputational neuroscience (CRCNS) project \u201cDataGit: converging\ncatalogues, warehouses, and deployment logistics into a federated \u2018data\ndistribution\u2019\u201d (Halchenko/Hanke), co-funded by the US National Science\nFoundation (NSF 1429999) and the German Federal Ministry of Education\nand Research (BMBF 01GQ1411). Additional support is provided by the\nGerman federal state of Saxony-Anhalt and the European Regional\nDevelopment Fund (ERDF), Project: Center for Behavioral Brain Sciences,\nImaging Platform. This work is further facilitated by the ReproNim\nproject (NIH 1P41EB019936-01A1).</p>\n</div>\n\n          </div>"}, "last_serial": 6708770, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "fc825d00c7c8c410ba788ddccb0de2e9", "sha256": "4691c1633034f97d44ba0c77d1b84caac3e37d82c8868c1d8dd9d1d96f72ac98"}, "downloads": -1, "filename": "datalad_crawler-0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fc825d00c7c8c410ba788ddccb0de2e9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 127417, "upload_time": "2018-05-11T06:47:09", "upload_time_iso_8601": "2018-05-11T06:47:09.926024Z", "url": "https://files.pythonhosted.org/packages/18/52/d05c0d7a8ad8f8c862db47b5de53462556d1d68cd31aad6db4d79534f721/datalad_crawler-0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "03a5dfd76f6710760f47c452c4b55b79", "sha256": "5add832a7cab5078eae5ddcd4c2c8f6e68755a6e9f587f8c44d76f69a8d9e0a9"}, "downloads": -1, "filename": "datalad_crawler-0.1.tar.gz", "has_sig": false, "md5_digest": "03a5dfd76f6710760f47c452c4b55b79", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120201, "upload_time": "2018-05-11T06:47:11", "upload_time_iso_8601": "2018-05-11T06:47:11.600560Z", "url": "https://files.pythonhosted.org/packages/bc/d4/079faea8fa08c3af33e89f33741ee8a2ed05682af90624ae5f6712603d39/datalad_crawler-0.1.tar.gz", "yanked": false}], "0.1rc1": [{"comment_text": "", "digests": {"md5": "17e2e81f113017fc09ad44095d5d3507", "sha256": "d6231d81b7c3b218ce0a674123c72652dbc7e6864d7a613750a9c0c7d8a175c9"}, "downloads": -1, "filename": "datalad_crawler-0.1rc1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "17e2e81f113017fc09ad44095d5d3507", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 127475, "upload_time": "2018-05-09T15:33:55", "upload_time_iso_8601": "2018-05-09T15:33:55.155034Z", "url": "https://files.pythonhosted.org/packages/aa/1b/54cc49da2dedd577ccb72538830feaf23e62509a6d46be546054372a15a5/datalad_crawler-0.1rc1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a44302943c9eb871c21d327995097246", "sha256": "bdb243e79d6b4b48f93d77eb26da8556520a5f28599a406e48cb4fbdedd8121d"}, "downloads": -1, "filename": "datalad_crawler-0.1rc1.tar.gz", "has_sig": false, "md5_digest": "a44302943c9eb871c21d327995097246", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120211, "upload_time": "2018-05-09T15:33:57", "upload_time_iso_8601": "2018-05-09T15:33:57.080630Z", "url": "https://files.pythonhosted.org/packages/37/5b/ba0e6ced797f1a4c5caa751751bce9ba8f18867acd719199d854736a52e6/datalad_crawler-0.1rc1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "cff51cdee6b6e7bd1c47a8312e2327ae", "sha256": "33837688f4674e839c5db53eb9d5ba508cd3935935e99e177f62f41de4cd8312"}, "downloads": -1, "filename": "datalad_crawler-0.2.tar.gz", "has_sig": false, "md5_digest": "cff51cdee6b6e7bd1c47a8312e2327ae", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 119485, "upload_time": "2018-05-17T14:36:09", "upload_time_iso_8601": "2018-05-17T14:36:09.218479Z", "url": "https://files.pythonhosted.org/packages/b5/67/2035981f22be85d34444c3468cbe58b672533174cdc76b29d5497a716ed1/datalad_crawler-0.2.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "5d65027f77e7cf3027e9981b921146cf", "sha256": "e1e82742eacf15131e18cfad0a5f672238a9c0086ab296d0225bc1da20478828"}, "downloads": -1, "filename": "datalad_crawler-0.3.tar.gz", "has_sig": false, "md5_digest": "5d65027f77e7cf3027e9981b921146cf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 120500, "upload_time": "2019-02-06T20:33:11", "upload_time_iso_8601": "2019-02-06T20:33:11.994692Z", "url": "https://files.pythonhosted.org/packages/03/0f/de78d373ee64fb69be6855b26efdc762dcb037b88421ebb57c1978bfdec6/datalad_crawler-0.3.tar.gz", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "7305cc47bbb5c415b169031622f01a6e", "sha256": "adcc5549791ccbb95bfbb5d1eaddf553e1fb7d2bb2c6802ec3e1703002a297dc"}, "downloads": -1, "filename": "datalad_crawler-0.4.tar.gz", "has_sig": false, "md5_digest": "7305cc47bbb5c415b169031622f01a6e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121168, "upload_time": "2019-03-14T18:52:11", "upload_time_iso_8601": "2019-03-14T18:52:11.028571Z", "url": "https://files.pythonhosted.org/packages/fe/8d/8008c3ea01889a3f0e955394b10aaf1c3d8dc56b67d98d762f7ad8450512/datalad_crawler-0.4.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "e64cc71b9e0fc4b29101f172fec131a1", "sha256": "22c6d7889e02d3bb415d9b4574f688c20dca51bed547b44a8e0ecefee8ffd2b4"}, "downloads": -1, "filename": "datalad_crawler-0.4.1.tar.gz", "has_sig": false, "md5_digest": "e64cc71b9e0fc4b29101f172fec131a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 121890, "upload_time": "2019-06-20T14:52:18", "upload_time_iso_8601": "2019-06-20T14:52:18.165468Z", "url": "https://files.pythonhosted.org/packages/1c/f4/e3e839639ff5da6f683de8642740819f07356927bc382609cbc9575ad61f/datalad_crawler-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "623f1658b18ad0bf931a8f8965d1047f", "sha256": "60aedbef41e7c2478adf02dfb592fa9257e41388a4edeb7a1395ed3f835c138d"}, "downloads": -1, "filename": "datalad_crawler-0.4.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "623f1658b18ad0bf931a8f8965d1047f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 130150, "upload_time": "2019-10-30T03:57:03", "upload_time_iso_8601": "2019-10-30T03:57:03.411311Z", "url": "https://files.pythonhosted.org/packages/3a/97/f6b96260a3015e92a181b28c9044a2319f1c452a2854672fb90b12f073d3/datalad_crawler-0.4.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f12fe7214d6eced0d93cd8dab75a7f1d", "sha256": "6e25082e14053270def315a067efbe9eb5cf3dd5f5b4418b82294ff612a918a0"}, "downloads": -1, "filename": "datalad_crawler-0.4.2.tar.gz", "has_sig": false, "md5_digest": "f12fe7214d6eced0d93cd8dab75a7f1d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124207, "upload_time": "2019-10-30T03:57:05", "upload_time_iso_8601": "2019-10-30T03:57:05.244392Z", "url": "https://files.pythonhosted.org/packages/b1/df/01bbf4fe8f9870a5c914ec55b80ded7b4d5a0fb9a3f19afcc76074f6aa4e/datalad_crawler-0.4.2.tar.gz", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "7df5bf17a7fa28f0f06e2cf9c67d5232", "sha256": "349b64d0d7e4172a7623fdc08a1270f387523e5ff13a133d503432964fcbec2e"}, "downloads": -1, "filename": "datalad_crawler-0.4.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7df5bf17a7fa28f0f06e2cf9c67d5232", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 130144, "upload_time": "2019-10-31T02:29:16", "upload_time_iso_8601": "2019-10-31T02:29:16.980494Z", "url": "https://files.pythonhosted.org/packages/9d/48/a4d8bc860343dd2559205666d7c2440d72f7ba4bae7034cf64ec4edfc8f2/datalad_crawler-0.4.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27ded12a427b5cabb6c41c70d9bca206", "sha256": "2b781f3045a4b51d5aa9b9b604b21408a563bfe09830b33a926185975e35dc9d"}, "downloads": -1, "filename": "datalad_crawler-0.4.3.tar.gz", "has_sig": false, "md5_digest": "27ded12a427b5cabb6c41c70d9bca206", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124278, "upload_time": "2019-10-31T02:29:19", "upload_time_iso_8601": "2019-10-31T02:29:19.090022Z", "url": "https://files.pythonhosted.org/packages/bc/64/ff49706d5ed9e4a3530a2700802820a1f4fbe8e043abf8d1384a9d3ff55a/datalad_crawler-0.4.3.tar.gz", "yanked": false}], "0.4.4": [{"comment_text": "", "digests": {"md5": "3a5adde33064fd54e6c1a49615e05754", "sha256": "d15cbeda9a7501e03556ae99521b098b9eba4cb28b699c93616e051f3de06815"}, "downloads": -1, "filename": "datalad_crawler-0.4.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3a5adde33064fd54e6c1a49615e05754", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 132096, "upload_time": "2019-11-21T04:39:20", "upload_time_iso_8601": "2019-11-21T04:39:20.678252Z", "url": "https://files.pythonhosted.org/packages/36/59/905d591f75c7752592c248e4f98aebf3fde22df87214687af76aa44760f5/datalad_crawler-0.4.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a84c6ec04aa4e4db88d010cc59b9e39", "sha256": "c8d55f84de08616b93b2675819de3c10440c8a34273801d9be3d7c2a7247fde6"}, "downloads": -1, "filename": "datalad_crawler-0.4.4.tar.gz", "has_sig": false, "md5_digest": "0a84c6ec04aa4e4db88d010cc59b9e39", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 125642, "upload_time": "2019-11-21T04:39:22", "upload_time_iso_8601": "2019-11-21T04:39:22.610938Z", "url": "https://files.pythonhosted.org/packages/5e/4a/5e65bb318611d0b7da9eefcd0dfab060c8cbcade8845eddff1a737725422/datalad_crawler-0.4.4.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "ae94d5facb61f8244afd9589934c5446", "sha256": "1312fe35c4c0e7df4c77e98ef8fb5db583b17a7d5773af9dfb68a990fcba4c20"}, "downloads": -1, "filename": "datalad_crawler-0.5.0.tar.gz", "has_sig": false, "md5_digest": "ae94d5facb61f8244afd9589934c5446", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124973, "upload_time": "2020-02-27T04:10:10", "upload_time_iso_8601": "2020-02-27T04:10:10.754224Z", "url": "https://files.pythonhosted.org/packages/36/10/fef4518897ee1d379e5a8d83ad62b1459602a7d60e23ce37c567d05f070b/datalad_crawler-0.5.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ae94d5facb61f8244afd9589934c5446", "sha256": "1312fe35c4c0e7df4c77e98ef8fb5db583b17a7d5773af9dfb68a990fcba4c20"}, "downloads": -1, "filename": "datalad_crawler-0.5.0.tar.gz", "has_sig": false, "md5_digest": "ae94d5facb61f8244afd9589934c5446", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 124973, "upload_time": "2020-02-27T04:10:10", "upload_time_iso_8601": "2020-02-27T04:10:10.754224Z", "url": "https://files.pythonhosted.org/packages/36/10/fef4518897ee1d379e5a8d83ad62b1459602a7d60e23ce37c567d05f070b/datalad_crawler-0.5.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:40:21 2020"}