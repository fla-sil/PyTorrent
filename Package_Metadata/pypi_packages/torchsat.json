{"info": {"author": "sshuair", "author_email": "sshuair@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "<p align=\"center\">\n  <img width=\"60%\" height=\"60%\" src=\"https://github.com/sshuair/torchsat/blob/master/docs/source/_static/img/logo-black.png\">\n</p>\n\n--------------------------------------------------------------------------------\n<p align=\"center\">\n    <a href=\"https://github.com/sshuair/torchsat/actions\"><img src=\"https://github.com/sshuair/torchsat/workflows/pytest/badge.svg\"></a>\n    <a href=\"https://torchsat.readthedocs.io/en/latest/?badge=latest\"><img src=\"https://readthedocs.org/projects/torchsat/badge/?version=latest\"></a>\n    <a href=\"https://github.com/sshuair/torchsat/stargazer\"><img src=\"https://img.shields.io/github/stars/sshuair/torchsat\"></a>\n    <a href=\"https://github.com/sshuair/torchsat/network\"><img src=\"https://img.shields.io/github/forks/sshuair/torchsat\"></a>\n    <a href=\"https://github.com/sshuair/torchsat/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/sshuair/torchsat\"></a>\n</p>\n\nTorchSat is an open-source deep learning framework for satellite imagery analysis based on PyTorch.\n\n>This project is still work in progress. If you want to know more about it, please refer to the [Roadmap](https://github.com/sshuair/torchsat/wiki/Roadmap) .\n\n**Hightlight**\n- :wink: Support multi-channels(> 3 channels, e.g. 8 channels) images and TIFF file as input.\n- :yum: Convenient data augmentation method for classification, sementic segmentation and object detection.\n- :heart_eyes: Lots of models for satellite vision tasks, such as ResNet, DenseNet, UNet, PSPNet, SSD, FasterRCNN ...\n- :smiley: Lots of common satellite datasets loader.\n- :open_mouth: Training script for common satellite vision tasks.\n\n## Install\n\n`python3 setup.py install`\n\n## How to use\n- **Introduction** - \n- **Classification tutorial** - \n- **Data augmentation** - [data-augmentation.ipynb](exsamples/data-augmentation.ipynb)\n- **Data loader** \n- **models** \n- **train script** \n\n## Features\n\n### Data augmentation\n\nWe suppose all the input images, masks and bbox should be NumPy ndarray. The data shape should be **[height, width]** or **[height, width, channels]**.\n\n#### pixel level\n\nPixel-level transforms only change the input image and will leave any additional targets such as masks, bounding boxes unchanged. It support all channel images. Some transforms only support specific input channles.\n\n| Transform            | Image  |  masks | BBoxes |\n| -------------------- | :---:  |  :---: | :----: |\n| ToTensor             |   \u2713    |  \u2713     |   \u2713    |\n| Normalize            |   \u2713    |  \u2713     |   \u2713    |\n| ToGray               |   \u2713    |  \u2713     |   \u2713    |\n| GaussianBlur         |   \u2713    |  \u2713     |   \u2713    |\n| RandomNoise          |   \u2713    |  \u2713     |   \u2713    |\n| RandomBrightness     |   \u2713    |  \u2713     |   \u2713    |\n| RandomContrast       |   \u2713    |  \u2713     |   \u2713    |\n\n#### spatial-level\nSpatial-level transforms will simultaneously change both an input image as well as additional targets such as masks, bounding boxes. It support all channel images.\n\n| Transform            | Image | masks | BBoxes |\n| -------------------- | :---: | :---: | :----: |\n| Resize               |   \u2713   |   \u2713   |   \u2713    |\n| Pad                  |   \u2713   |   \u2713   |   \u2713    |\n| RandomHorizontalFlip |   \u2713   |   \u2713   |   \u2713    |\n| RandomVerticalFlip   |   \u2713   |   \u2713   |   \u2713    |\n| RandomFlip           |   \u2713   |   \u2713   |   \u2713    |\n| CenterCrop           |   \u2713   |   \u2713   |   \u2713    |\n| RandomCrop           |   \u2713   |   \u2713   |   \u2713    |\n| RandomResizedCrop    |   \u2713   |   \u2713   |   \u2713    |\n| ElasticTransform     |   \u2713   |   \u2713   |        |\n| RandomRotation       |   \u2713   |   \u2713   |        |\n| RandomShift          |   \u2713   |   \u2713   |        |\n\n\n### Models\n#### Classification\nAll models support multi-channels as input (e.g. 8 channels).\n- VGG: `vgg11`, `vgg11_bn`, `vgg13`, `vgg13_bn`, `vgg16`, `vgg16_bn`,`vgg19_bn`, `vgg19`\n- ResNet: `resnet18`, `resnet34`, `restnet50`, `resnet101`, `resnet152`\n- DenseNet: `densenet121`, `densenet169`, `densenet201`, `densenet161`\n- Inception: `inception_v3`\n- MobileNet: `mobilenet_v2`\n\n#### Sementic Segmentation\n- UNet: `unet`, `unet34`, `unet101`, `unet152` (with resnet as backbone.)\n\n\n### Dataloader\n#### Classification\n- [SAT-4 and SAT-6 airborne datasets](https:/csc.lsu.edu/~saikat/deepsat/)\n- [EuroSat](http:/madm.dfki.de/downloads)\n- [PatternNet](https:/sites.google.com/view/zhouwx/dataset)\n- [NWPU_redisc45](http://www.escience.cn/people/JunweiHan/NWPU-RESISC45.html#)\n\n\n## Showcase\nIf you extend this repository or build projects that use it, we'd love to hear from you.\n\n\n## Reference\n- [torchvision](https://github.com/pytorch/vision)\n\n## Note\n- If you are looking for the torchvision-enhance, please checkout the [enhance](https://github.com/sshuair/torchvision-enhance/tree/torchvision-enhance) branch. But it was deprecated.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/sshuair/torchsat", "keywords": "pytorch deep learning satellite remote sensing", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torchsat", "package_url": "https://pypi.org/project/torchsat/", "platform": "", "project_url": "https://pypi.org/project/torchsat/", "project_urls": {"Homepage": "https://github.com/sshuair/torchsat"}, "release_url": "https://pypi.org/project/torchsat/0.0.1/", "requires_dist": ["numpy (>=1.13.0)", "scipy (>=1.1.0)", "pillow (>=5.0.0)", "six (>=1.11.0)", "tifffile (>=2019.1.1)", "opencv-python (>=3.2.0.6)", "torch (>=1.0.0)", "torchvision (>=0.2.0)"], "requires_python": "", "summary": "TorchSat is an open-source PyTorch framework for satellite imagery analysis.", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\">\n  <img height=\"60%\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2727a5148799aff6d07aa90fac7e103b678d20d4/68747470733a2f2f6769746875622e636f6d2f737368756169722f746f7263687361742f626c6f622f6d61737465722f646f63732f736f757263652f5f7374617469632f696d672f6c6f676f2d626c61636b2e706e67\" width=\"60%\">\n</p>\n<hr>\n<p align=\"center\">\n    <a href=\"https://github.com/sshuair/torchsat/actions\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ef933cd544bf08f489d62bc75a216ffe7e7363c9/68747470733a2f2f6769746875622e636f6d2f737368756169722f746f7263687361742f776f726b666c6f77732f7079746573742f62616467652e737667\"></a>\n    <a href=\"https://torchsat.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/967cc320461fd1a657db10ea875153bc8983b62f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f746f7263687361742f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n    <a href=\"https://github.com/sshuair/torchsat/stargazer\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2cabcb8ac0cbaa58414b53f0026b80e513f09a49/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737368756169722f746f726368736174\"></a>\n    <a href=\"https://github.com/sshuair/torchsat/network\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c4480e7bcd15a211175bc6f77637f629a9c28ac6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f737368756169722f746f726368736174\"></a>\n    <a href=\"https://github.com/sshuair/torchsat/blob/master/LICENSE\" rel=\"nofollow\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eda4563c8f9afa358ab282bacc9a283036d89c81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f737368756169722f746f726368736174\"></a>\n</p>\n<p>TorchSat is an open-source deep learning framework for satellite imagery analysis based on PyTorch.</p>\n<blockquote>\n<p>This project is still work in progress. If you want to know more about it, please refer to the <a href=\"https://github.com/sshuair/torchsat/wiki/Roadmap\" rel=\"nofollow\">Roadmap</a> .</p>\n</blockquote>\n<p><strong>Hightlight</strong></p>\n<ul>\n<li>:wink: Support multi-channels(&gt; 3 channels, e.g. 8 channels) images and TIFF file as input.</li>\n<li>:yum: Convenient data augmentation method for classification, sementic segmentation and object detection.</li>\n<li>:heart_eyes: Lots of models for satellite vision tasks, such as ResNet, DenseNet, UNet, PSPNet, SSD, FasterRCNN ...</li>\n<li>:smiley: Lots of common satellite datasets loader.</li>\n<li>:open_mouth: Training script for common satellite vision tasks.</li>\n</ul>\n<h2>Install</h2>\n<p><code>python3 setup.py install</code></p>\n<h2>How to use</h2>\n<ul>\n<li><strong>Introduction</strong> -</li>\n<li><strong>Classification tutorial</strong> -</li>\n<li><strong>Data augmentation</strong> - <a href=\"exsamples/data-augmentation.ipynb\" rel=\"nofollow\">data-augmentation.ipynb</a></li>\n<li><strong>Data loader</strong></li>\n<li><strong>models</strong></li>\n<li><strong>train script</strong></li>\n</ul>\n<h2>Features</h2>\n<h3>Data augmentation</h3>\n<p>We suppose all the input images, masks and bbox should be NumPy ndarray. The data shape should be <strong>[height, width]</strong> or <strong>[height, width, channels]</strong>.</p>\n<h4>pixel level</h4>\n<p>Pixel-level transforms only change the input image and will leave any additional targets such as masks, bounding boxes unchanged. It support all channel images. Some transforms only support specific input channles.</p>\n<table>\n<thead>\n<tr>\n<th>Transform</th>\n<th align=\"center\">Image</th>\n<th align=\"center\">masks</th>\n<th align=\"center\">BBoxes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ToTensor</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>Normalize</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>ToGray</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>GaussianBlur</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomNoise</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomBrightness</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomContrast</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr></tbody></table>\n<h4>spatial-level</h4>\n<p>Spatial-level transforms will simultaneously change both an input image as well as additional targets such as masks, bounding boxes. It support all channel images.</p>\n<table>\n<thead>\n<tr>\n<th>Transform</th>\n<th align=\"center\">Image</th>\n<th align=\"center\">masks</th>\n<th align=\"center\">BBoxes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Resize</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>Pad</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomHorizontalFlip</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomVerticalFlip</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomFlip</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>CenterCrop</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomCrop</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>RandomResizedCrop</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n</tr>\n<tr>\n<td>ElasticTransform</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>RandomRotation</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>RandomShift</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\">\u2713</td>\n<td align=\"center\"></td>\n</tr></tbody></table>\n<h3>Models</h3>\n<h4>Classification</h4>\n<p>All models support multi-channels as input (e.g. 8 channels).</p>\n<ul>\n<li>VGG: <code>vgg11</code>, <code>vgg11_bn</code>, <code>vgg13</code>, <code>vgg13_bn</code>, <code>vgg16</code>, <code>vgg16_bn</code>,<code>vgg19_bn</code>, <code>vgg19</code></li>\n<li>ResNet: <code>resnet18</code>, <code>resnet34</code>, <code>restnet50</code>, <code>resnet101</code>, <code>resnet152</code></li>\n<li>DenseNet: <code>densenet121</code>, <code>densenet169</code>, <code>densenet201</code>, <code>densenet161</code></li>\n<li>Inception: <code>inception_v3</code></li>\n<li>MobileNet: <code>mobilenet_v2</code></li>\n</ul>\n<h4>Sementic Segmentation</h4>\n<ul>\n<li>UNet: <code>unet</code>, <code>unet34</code>, <code>unet101</code>, <code>unet152</code> (with resnet as backbone.)</li>\n</ul>\n<h3>Dataloader</h3>\n<h4>Classification</h4>\n<ul>\n<li><a href=\"https:/csc.lsu.edu/%7Esaikat/deepsat/\" rel=\"nofollow\">SAT-4 and SAT-6 airborne datasets</a></li>\n<li><a href=\"http:/madm.dfki.de/downloads\" rel=\"nofollow\">EuroSat</a></li>\n<li><a href=\"https:/sites.google.com/view/zhouwx/dataset\" rel=\"nofollow\">PatternNet</a></li>\n<li><a href=\"http://www.escience.cn/people/JunweiHan/NWPU-RESISC45.html#\" rel=\"nofollow\">NWPU_redisc45</a></li>\n</ul>\n<h2>Showcase</h2>\n<p>If you extend this repository or build projects that use it, we'd love to hear from you.</p>\n<h2>Reference</h2>\n<ul>\n<li><a href=\"https://github.com/pytorch/vision\" rel=\"nofollow\">torchvision</a></li>\n</ul>\n<h2>Note</h2>\n<ul>\n<li>If you are looking for the torchvision-enhance, please checkout the <a href=\"https://github.com/sshuair/torchvision-enhance/tree/torchvision-enhance\" rel=\"nofollow\">enhance</a> branch. But it was deprecated.</li>\n</ul>\n\n          </div>"}, "last_serial": 5880436, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "ee16eff1a714da401db9ad25e76397a6", "sha256": "153af11f7331a0bb828a7dbdde9d82c0ab45a7be72063fb7979f057a3137a4bf"}, "downloads": -1, "filename": "torchsat-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ee16eff1a714da401db9ad25e76397a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46341, "upload_time": "2019-09-24T15:11:11", "upload_time_iso_8601": "2019-09-24T15:11:11.082804Z", "url": "https://files.pythonhosted.org/packages/71/b8/88433405e6d267cfae1e41484da01987cc1dc82dd56c1a45ea927b101655/torchsat-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9dab49c62e45d64a090846fadf3790d2", "sha256": "0437c2768302bc47619cb62541ac8cdef8bd5bcc3d6c088ac0c53e21432add1b"}, "downloads": -1, "filename": "torchsat-0.0.1.tar.gz", "has_sig": false, "md5_digest": "9dab49c62e45d64a090846fadf3790d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31776, "upload_time": "2019-09-24T15:11:15", "upload_time_iso_8601": "2019-09-24T15:11:15.546791Z", "url": "https://files.pythonhosted.org/packages/9b/e6/b132608b96e9425d0ac0aaf88e38b84d78bf945f832da86c4de06fafbff5/torchsat-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ee16eff1a714da401db9ad25e76397a6", "sha256": "153af11f7331a0bb828a7dbdde9d82c0ab45a7be72063fb7979f057a3137a4bf"}, "downloads": -1, "filename": "torchsat-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ee16eff1a714da401db9ad25e76397a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 46341, "upload_time": "2019-09-24T15:11:11", "upload_time_iso_8601": "2019-09-24T15:11:11.082804Z", "url": "https://files.pythonhosted.org/packages/71/b8/88433405e6d267cfae1e41484da01987cc1dc82dd56c1a45ea927b101655/torchsat-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9dab49c62e45d64a090846fadf3790d2", "sha256": "0437c2768302bc47619cb62541ac8cdef8bd5bcc3d6c088ac0c53e21432add1b"}, "downloads": -1, "filename": "torchsat-0.0.1.tar.gz", "has_sig": false, "md5_digest": "9dab49c62e45d64a090846fadf3790d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31776, "upload_time": "2019-09-24T15:11:15", "upload_time_iso_8601": "2019-09-24T15:11:15.546791Z", "url": "https://files.pythonhosted.org/packages/9b/e6/b132608b96e9425d0ac0aaf88e38b84d78bf945f832da86c4de06fafbff5/torchsat-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:13 2020"}