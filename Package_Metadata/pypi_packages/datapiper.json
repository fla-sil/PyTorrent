{"info": {"author": "Petri Savolainen", "author_email": "petri.savolainen@koodaamo.fi", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Natural Language :: English", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "===============================\nOverview\n===============================\n\nDatapiper provides a flexible easy-to-use library for constructing and running\nsimple data batch processing pipelines.\n\nGive Datapiper your list of data processing callables and it will construct a\nrunnable data pipeline for you.\n\nIf you instantiate the pipe with a (iterable) data source, you get a generator\nthat reads from a source and outputs processed data for you:\n\n.. code-block::\n\n   >>> operations = [lambda context, data: data+1]\n   >>> datasource = [1,2,3]\n   >>> p = Piper(operations, source=datasource)\n   >>> print p\n   pipe: source > <lambda>\n   >>> [r for r in p]\n   [2,3,4]\n\nIf you instead instantiate it with a (callable) data sink, you get a coroutine\nthat accepts data from a producer and delivers processed data to a sink:\n\n.. code-block::\n\n   >>> operations = [lambda context, data: data+1]\n   >>> results = []\n   >>> def datasink(data):\n   ...    results.append(data)\n   >>> p = Piper(operations, sink=datasink)\n   >>> print p\n   pipe: <lambda> > sink\n   >>> for v in (1,2,3):\n   ...    p.send(v)\n   ...\n   >>> results\n   [2,3,4] \n\nThe context parameter passed to the data operations callables is meant for\nsharing state between them. It can be initialized to desired value(s) by passing\nit to the Piper class as a (optional) keyword argument. The context parameter can\nbe anything; a dictionary is recommended.\n\nPlease see the tests for more examples.\n\n\n\n\nHistory\n-------\n\n0.1.0 (2017-10-31)\n++++++++++++++++++\n\n* First release on PyPI.\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/koodaamo/datapiper", "keywords": "datapiper", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "datapiper", "package_url": "https://pypi.org/project/datapiper/", "platform": "", "project_url": "https://pypi.org/project/datapiper/", "project_urls": {"Homepage": "https://github.com/koodaamo/datapiper"}, "release_url": "https://pypi.org/project/datapiper/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "Simple data processing tool.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>Datapiper provides a flexible easy-to-use library for constructing and running\nsimple data batch processing pipelines.</p>\n<p>Give Datapiper your list of data processing callables and it will construct a\nrunnable data pipeline for you.</p>\n<p>If you instantiate the pipe with a (iterable) data source, you get a generator\nthat reads from a source and outputs processed data for you:</p>\n<pre>&gt;&gt;&gt; operations = [lambda context, data: data+1]\n&gt;&gt;&gt; datasource = [1,2,3]\n&gt;&gt;&gt; p = Piper(operations, source=datasource)\n&gt;&gt;&gt; print p\npipe: source &gt; &lt;lambda&gt;\n&gt;&gt;&gt; [r for r in p]\n[2,3,4]\n</pre>\n<p>If you instead instantiate it with a (callable) data sink, you get a coroutine\nthat accepts data from a producer and delivers processed data to a sink:</p>\n<pre>&gt;&gt;&gt; operations = [lambda context, data: data+1]\n&gt;&gt;&gt; results = []\n&gt;&gt;&gt; def datasink(data):\n...    results.append(data)\n&gt;&gt;&gt; p = Piper(operations, sink=datasink)\n&gt;&gt;&gt; print p\npipe: &lt;lambda&gt; &gt; sink\n&gt;&gt;&gt; for v in (1,2,3):\n...    p.send(v)\n...\n&gt;&gt;&gt; results\n[2,3,4]\n</pre>\n<p>The context parameter passed to the data operations callables is meant for\nsharing state between them. It can be initialized to desired value(s) by passing\nit to the Piper class as a (optional) keyword argument. The context parameter can\nbe anything; a dictionary is recommended.</p>\n<p>Please see the tests for more examples.</p>\n<div id=\"history\">\n<h2>History</h2>\n<h2 id=\"id1\"><span class=\"section-subtitle\">0.1.0 (2017-10-31)</span></h2>\n<ul>\n<li>First release on PyPI.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 3295543, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "d1f362a6de740974bbc23ceeac70eccc", "sha256": "362afe8010344ab845ab4cf12b2c615631464a3fa6c1055e07a1bac996be26f3"}, "downloads": -1, "filename": "datapiper-0.1.0.zip", "has_sig": false, "md5_digest": "d1f362a6de740974bbc23ceeac70eccc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23749, "upload_time": "2017-10-31T21:58:07", "upload_time_iso_8601": "2017-10-31T21:58:07.184157Z", "url": "https://files.pythonhosted.org/packages/3c/24/6251fe73e543b8d49deb3f3c750b417f84d087c7a6da5c2943aaf57aa3e8/datapiper-0.1.0.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d1f362a6de740974bbc23ceeac70eccc", "sha256": "362afe8010344ab845ab4cf12b2c615631464a3fa6c1055e07a1bac996be26f3"}, "downloads": -1, "filename": "datapiper-0.1.0.zip", "has_sig": false, "md5_digest": "d1f362a6de740974bbc23ceeac70eccc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23749, "upload_time": "2017-10-31T21:58:07", "upload_time_iso_8601": "2017-10-31T21:58:07.184157Z", "url": "https://files.pythonhosted.org/packages/3c/24/6251fe73e543b8d49deb3f3c750b417f84d087c7a6da5c2943aaf57aa3e8/datapiper-0.1.0.zip", "yanked": false}], "timestamp": "Fri May  8 00:40:16 2020"}