{"info": {"author": "Lloyd Windrim", "author_email": "lloydwindrim@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3"], "description": "# deephyp: deep learning for hyperspectral \n\n![PyPI](https://img.shields.io/pypi/v/deephyp) ![PyPI - Downloads](https://img.shields.io/pypi/dm/deephyp?color=brightgreen)\n\nTools for training and using unsupervised autoencoders and supervised deep learning classifiers for hyperspectral data.\n\nDocumentation available [here](https://deephyp.readthedocs.io/en/latest/index.html). Source code available on [Github](https://github.com/lloydwindrim/hyperspectral-autoencoders).\n\nAutoencoders are unsupervised neural networks that are useful for a range of applications such as unsupervised feature learning and dimensionality reduction. Supervised deep learning classifiers can be trained on labelled data to predict the class of spectra. This repository provides a python-based toolbox called **deephyp**, with examples for building, training and testing both dense and convolutional autoencoders and classification neural networks, designed for hyperspectral data. Networks are easy to setup and can be customised with different architectures. Different methods of training can also be implemented. The toolbox is built on tensorflow.\n\n![Alt text](images/diagram.png?raw=true \"Hyperspectral Autoencoder\")\n\nIf you use the toolbox in your research, please cite:\n[Windrim et al. **Unsupervised Feature-Learning for Hyperspectral Data with Autoencoders.** Remote Sensing 11.7 (2019): 864.](https://www.mdpi.com/2072-4292/11/7/864)\nThis paper explains the spectral angle (SA), spectral information divergence (SID) and sum-of-squared errors (SSE) loss functions for training autoencoders.\n\nIf you use the cosine spectral angle (CSA) loss function in your research, please cite: \n[Windrim et al. **Unsupervised feature learning for illumination robustness.** 2016 IEEE International Conference on Image Processing (ICIP).](https://ieeexplore.ieee.org/abstract/document/7533202)\n\nIf you use the classification networks in your research, please cite:\n[Windrim et al. **Hyperspectral CNN Classification with Limited Training Samples.** 2017 Proceedings of the British Machine Vision Conference (BMVC).](https://www.researchgate.net/publication/332818169_Hyperspectral_CNN_Classification_with_Limited_Training_Samples)\n\n## Installation\n\nThe [latest release](https://pypi.org/project/deephyp/) of the toolbox can be installed from the command line using pip:\n```\npip install deephyp\n```\nDependencies can be installed using:\n```\npip install -r requirements.txt\n```\nTo import:\n```\nimport deephyp\n```\n\n## Prerequisites\n\nThe software dependencies needed to run the toolbox are python 2 or python 3 (tested with version 2.7.15 and 3.5.2) with packages:\n* tensorflow (tested with v1.14.0) - not yet compatible with tensorflow v2.0\n* numpy (tested with v1.15.4)\n\nEach of these packages can be installed using [pip](https://pypi.org/project/pip/). The example scripts use some additional packages such as scipy (tested with v1.3.1) and matplotlib (tested with v3.0.3).\n\nNote: if you want to use deephyp but you have tensorflow v2, you can install deephyp in a virtual environment with tensorflow v1.14. [See instructions here](https://www.tensorflow.org/install/pip).\n\n## Quickstart\nTo start training an autoencoder right away, move to the /examples directory in the [github repo](https://github.com/lloydwindrim/hyperspectral-autoencoders) and run the example script:\n```\nautoencoder_train_MLP_basic.py\n```\nIt will download the Pavia Uni dataset and train an autoencoder. You can then run the example script:\n```\nautoencoder_test_MLP_basic.py\n```\nto test the autoencoder that was just trained, and generate some images of the latent hyperspectral image, latent vector and comparisons of the spectra and reconstruction in the results folder.\n\nTo start training a classification network, from the /examples directory run the script:\n```\nclassifier_train_CNN_basic.py\n```\nwhich will download the Pavia Uni dataset and ground truth labels and train a classifier. Then running the example script:\n```\nclassifier_test_CNN_basic.py\n```\nwill load the trained classifier and generate images with the predicted and ground truth labels for comparison.\n\n## Usage\n\nThe toolbox comprises several key processes:\n- [data preparation](#data-preparation)\n- [data iterator](#data-iterator)\n- [building networks](#building-networks)\n- [adding train operations](#adding-training-operations)\n- [training networks](#training-networks)\n- [loading a trained network](#loading-a-trained-network)\n\nEach of these are elaborated on below:\n\n### Data preparation\n\nA class within the toolbox from the data module called HypImg handles the dataset. The class accepts the hyperspectral data  in numpy format, with shape [numRows x numCols x numBands] or [numSamples x numBands]. The networks in the toolbox operate in the spectral domain, not the spatial, so if an image is input with shape [numRows x numCols x numBands], it is reshaped to [numSamples x numBands], collapsing the spatial dimensions into one.\n\n```\nfrom deephyp import data\nhypData = data.HypImg( img )\n```\nor for hyperspectral data with class labels (i.e. for supervised classification):\n```\nhypData = data.HypImg( img, labels )\n```\nThen the data can be pre-processed using a function of the HypImg class. For example, using the 'minmax' approach:\n```\nhypData.pre_process( 'minmax' )\n```\nThe result is stored in the attribute:\n```\nhypData.spectraPrep\n```\nWhen provided, labels are converted to a one-hot format stored as:\n```\nhypData.labelsOnehot\n```\nAny labels with value <= 0 are considered as a background class, and appear as a row of zeros in labelsOnehot. They also do not count towards the number of classes stored in the data handler.\n\nSome hyperspectral datasets in a matlab file format (.mat) can be downloaded from [here](http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes). A matlab file (.mat) can be converted to the numpy format using the [scipy.io.loadmat](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html) function.\n\n### Data iterator\n\nThe Iterator class within the data module has methods for calling batches from the data that are used to train the network. A separate iterator object is made for the training and validation data. For example, an iterator object made from 100 pre-processed hyperspectral training samples with a batchsize of 10 is defined as:\n```\ndataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:100, :], targets=hypData.spectraPrep[:100, :], batchSize=10 )\n```\nSimilarly, an iterator object made from 20 validation samples is defined as:\n```\ndataVal = data.Iterator( dataSamples=hypData.spectraPrep[100:120, :], targets=hypData.spectraPrep[100:120, :] )\n```\nBecause the batchsize is unspecified, all 20 samples are used for the batch.\n\nFor a typical unsupervised autoencoder, the targets that the network is learning to output are the same as the data samples being input into the network, as in the above iterator examples. When training a supervised classifier, the targets are the one-hot class labels:\n```\ndataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:100, :], targets=hypData.labelsOnehot[:100, :], batchSize=10 )\n```\nThe data in any iterator can also be shuffled before it is used to train a network:\n```\ndataTrain.shuffle()\n```\n\n### Building networks\n\nThe autoencoder module has classes used for creating autoencoder neural networks:\n```\nfrom deephyp import autoencoder\n```\nThere are currently two type of autoencoders that can be set up. An MLP autoencoder has purely fully-connected  (i.e. dense) layers:\n```\nnet = autoencoder.mlp_1D_network( inputSize=hypData.numBands )\n```\nAnd a convolutional autoencoder has mostly convolutional layers, with a fully-connected layer used to map the final convolutional layer in the encoder to the latent vector:\n```\nnet = autoencoder.cnn_1D_network( inputSize=hypData.numBands )\n```\nIf not using config files to set up a network, then the input size of the data must be specified. This should be the number of spectral bands. \n\nAdditional aspects of the network architecture can also be specified when initialising the object. For the MLP autoencoder:\n```\nnet = autoencoder.mlp_1D_network( inputSize=hypData.numBands, encoderSize=[50,30,10,5], activationFunc='relu', weightInitOpt='truncated_normal', tiedWeights=[1,0,0,0], skipConnect=False, activationFuncFinal='linear')\n```\n- number of layers in the encoder (and decoder) - this is the length of the list 'encoderSize'\n- number of neurons in each layer of the encoder - these are the values in the 'encoderSize' list. The last value in the list is the number of dimensions in the latent vector.\n- the activation function which proceeds each layer and the function for the final decoder layer - activationFunc and activationFuncFinal\n- the method of initialising network parameters (e.g. xavier improved) - 'weightInitOpt'\n- which layers of the encoder to tie  to the decoder, such that they share a set of parameters - these are the values in the list 'tiedWeights'\n- whether the network uses skip connections between corresponding layers in the encoder and decoder - specified by the boolean argument skipConnect\n\n\nThe convolutional autoencoder has similar arguments for defining the network architecture, but without 'encoderSize' and with some additional arguments:\n```\nnet = autoencoder.cnn_1D_network( inputSize=hypData.numBands, zDim=3, encoderNumFilters=[10,10,10], encoderFilterSize=[20,10,10],  activationFunc='relu', weightInitOpt='truncated_normal',  encoderStride=[1, 1, 1], padding='VALID', tiedWeights=[1,0,0],  skipConnect=False, activationFuncFinal='linear' )\n```\n- number of layers in the encoder (and decoder) - this is the length of the list 'encodernumFilters'\n- number of filters/kernels in each conv layer - these are the values in the 'encodernumFilters' list\n- the size of the filters/kernels in each conv layer - these are the values in the 'encoderFilterSize' list\n- the stride of the filters/kernels in each conv layer - these are the values in the 'encoderStride' list\n- the number of dimensions in the latent vector - zDim\n- the type of padding each conv layer uses - padding\n\n\nAlternatively to defining the architecture by the initialisation arguments, a config.json file can be used:\n```\nnet = autoencoder.mlp_1D_network( configFile='config.json') )\n```\nSome example config files can be found in examples/example_configs.\n\nThe classifier module has classes used for creating supervised classification neural networks:\n```\nfrom deephyp import classifier\n```\nThere is currently one type of classifier that can be set up, which contains a combination of convolutional layers (at the start) and fully-connected layers (at the end):\n```\nnet = classifier.cnn_1D_network( inputSize=hypData.numBands, numClasses=hypData.numClasses )\n```\nIf not using config files the input size and number of classes must be specified for classifier networks. As with the autoencoder class, additional aspects of the architecture can be specified:\n```\nnet = classifier.cnn_1D_network( inputSize=hypData.numBands, numClasses=hypData.numClasses, convFilterSize=[20,10,10], convNumFilters=[10,10,10], convStride = [1,1,1], fcSize=[20,20], activationFunc='relu', weightInitOpt='truncated_normal', padding='VALID' )\n```\n- number of convolutional layers - this is the length of the list 'convNumFilters'\n- number of filters/kernels in each conv layer - these are the values in the 'convNumFilters' list\n- the size of the filters/kernels in each conv layer - these are the values in the 'convFilterSize' list\n- the stride of the filters/kernels in each conv layer - these are the values in the 'convStride' list\n- the type of padding each conv layer uses - padding\n- number of fully-connected layers - this is the length of the list 'fcSize'\n- number of neurons in each fully-connected layer - these are the values in the 'fcSize' list\n- the activation function which proceeds each layer - activationFunc\n- the method of initialising network parameters (e.g. xavier improved) - 'weightInitOpt'\n\nClassifiers can also be setup with config files.\n\n### Adding training operations\n\nOnce a network has been created, a training operation can be added to it. It is possible to add multiple training operations to a network, so each op must be given a name:\n```\nnet.add_train_op( name='experiment_1' )\n```\nWhen adding a train op, details about how the network will be trained with that op can be specified. For example, a train op for an autoencoder which uses the cosine spectral angle (CSA) loss function, a learning rate of 0.001 with no decay, optimised with Adam and no weight decay can be defined by:\n```\nnet.add_train_op( name='experiment_1', lossFunc='CSA', learning_rate=1e-3, decay_steps=None, decay_rate=None, method='Adam', wd_lambda=0.0 )\n```\nThere are several loss functions that can be used to train an autoencoder, many of which were designed specifically for hyperspectral data:\n- [cosine spectral angle (CSA)](https://ieeexplore.ieee.org/abstract/document/7533202)\n- [spectral angle (SA)](https://www.mdpi.com/2072-4292/11/7/864)\n- [spectral information divergence (SID)](https://www.mdpi.com/2072-4292/11/7/864)\n- [sum-of-squared errors (SSE)](https://www.mdpi.com/2072-4292/11/7/864)\n\nNote that when using the CSA, SA and SID loss functions it is expected that the reconstructed spectra have a different magnitude to the target spectra, but a similar shape. The SSE should produce a similar magnitude and shape. Also, since the SID contains *log* in its expression which is undefined for values *<= 0*, it is best to use sigmoid as the activation function (including the final activation function) for networks trained with the SID loss. See train_MLP_sid.py for an example.\n\nThe method of decaying the learning rate can also be customised. For example, to decay exponentially every 100 steps:\n```\nnet.add_train_op( name='experiment_1',learning_rate=1e-3, decay_steps=100, decay_rate=0.9 )\n```\nA piecewise approach of decaying the learning rate can also be used. For example, to change the learning rate from 0.001 to 0.0001 after 100 steps, and then to 0.00001 after a further 200 steps:\n```\nnet.add_train_op( name='experiment_1',learning_rate=1e-3, piecewise_bounds=[100,300], piecewise_values=[1e-4,1e-5] )\n```\nTrain ops are added to classifiers in the same way, with the only difference being the option to balance classes when training, and no specification of the loss function (a cross-entropy loss function is used):\n```\nnet.add_train_op( name='basic_clf', balance_classes=True, learning_rate=1e-3 )\n```\n\n### Training networks\n\nOnce one or multiple training ops have been added to a network, they can be used to learn a model (or multiple models) for that network through training:\n```\nnet.train(dataTrain=dataTrain, dataVal=dataVal, train_op_name='experiment_1', n_epochs=100, save_addr=model_directory, visualiseRateTrain=5, visualiseRateVal=10, save_epochs=[50,100])\n```\nThe train method learns a model using one train op, therefore the train method should be called at least once for each train op that was added. The name of the train op must be specified, and the training and validation iterators created previously must be input. A path to a directory to save the model must also be specified. The example above will train a network for 100 epochs of the training dataset, and save the model at 50 and 100 epochs. The training loss will be displayed every 5 epochs, and the validation loss will be displayed every 10 epochs.\n\nIt is also possible to load a pre-trained model and continue to train it by passing the address of epoch folder containing the model checkpoint as the save_addr argument. For example, if the directory for the model at epoch 50 (epoch_50 folder) was passed to save_addr in the example above, then the model would be trained for an additional 50 epochs to reach 100, and it would be saved in a folder called epoch_100 in the same directory as the epoch_50 folder.\n\nThe interface for training autoencoders and classifiers is the same.\n\n### Loading a trained network\n\nTo load a trained model on a new dataset, ensure the data has been pre-processed similarly using:\n\n```\nimport data\nhypData = data.HypImg( new_img )\nhypData.pre_process( 'minmax' )\n```\nThen set up the network. The network architecture must be the same as the one used for the model being loaded. However, this is easy as the directory where models are saved should contain an automatically generated config.json file, which can be used to set up the network with the same architecture:\n```\nnet = autoencoder.mlp_1D_network( configFile='model_directory/config.json' )\n```\nOnce the architecture has been defined, add a model to the network:\n```\nnet.add_model( addr='model_directory/epoch_100'), modelName='csa_100' )\n```\nBecause multiple models can be added to a single network, the added model must be given a name.\n\nWhen the network is set up and a model has been added, hyperspectral data can be passed through it. To use a trained autoencoder to extract the latent vectors of some spectra:\n```\ndataZ = net.encoder( modelName='csa_100', dataSamples=hypData.spectraPrep )\n```\nMake sure to refer to the name of the model the network should use. The encoded hyperspectral (dataZ) data can also be decoded to get the reconstruction:\n```\ndataY = net.decoder(modelName='csa_100', dataZ=dataZ)\n```\nIt is also possible to encode and decode in one step with:\n```\ndataY = net.encoder_decoder(modelName='csa_100', dataZ=hypData.spectraPrep)\n```\nTo use a trained classifier to predict the classification labels of some spectra:\n```\ndataPred = net.predict_labels( modelName='basic_model', dataSamples=hypData.spectraPrep  )\n```\nTo extract the features in the second last layer of the classifier network:\n```\ndataFeatures = net.predict_features(modelName='basic_model', dataSamples=hypData.spectraPrep, layer=net.numLayers-1)\n```\n\n## Results\n\nAn example of a latent space for the Pavia University dataset, produced with a MLP autoencoder trained using the cosine spectral angle (CSA):\n\n![Alt text](images/mlp_latent_space.png?raw=true \"autoencoder MLP latent space\")\n\nAnd an example of a latent space for the Pavia University dataset, produced with a convolutional autoencoder trained using the cosine spectral angle (CSA):\n\n![Alt text](images/cnn_latent_space.png?raw=true \"autoencoder CNN latent space\")\n\nBoth figures were made running the scripts:\n```\nautoencoder_train_CNN_vs_MLP.py\nautoencoder_test_CNN_vs_MLP.py\n```\n\nA classification result for the Pavia University dataset produced using the CNN classifier:\n\n![Alt text](images/classification_pred.png?raw=true \"CNN classification result\")\n\nThe figure was made by running the scripts:\n```\nclassifier_train_CNN_basic.py\nclassifier_test_CNN_basic.py\n```\n\n\n## Related publications\n\nSome links to publications on deep learning for hyperspectral data:\n\n- autoencoders: [ICIP 2016](https://ieeexplore.ieee.org/abstract/document/7533202), [TIP 2017](https://ieeexplore.ieee.org/abstract/document/8063434), [Remote Sensing 2019](https://www.mdpi.com/2072-4292/11/7/864)\n- CNNs for classification using data augmentation: [BMVC 2017](https://www.researchgate.net/publication/332818169_Hyperspectral_CNN_Classification_with_Limited_Training_Samples)\n- pre-training CNNs: [TGRS 2018](https://ieeexplore.ieee.org/abstract/document/8245897)\n- [PhD thesis](https://ses.library.usyd.edu.au/handle/2123/18734)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://deephyp.readthedocs.io/en/latest/index.html", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "deephyp", "package_url": "https://pypi.org/project/deephyp/", "platform": "", "project_url": "https://pypi.org/project/deephyp/", "project_urls": {"Homepage": "https://deephyp.readthedocs.io/en/latest/index.html"}, "release_url": "https://pypi.org/project/deephyp/0.1.5/", "requires_dist": ["numpy"], "requires_python": "", "summary": "Tools for training and using unsupervised autoencoders and supervised deep learning classifiers for hyperspectral data.", "version": "0.1.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>deephyp: deep learning for hyperspectral</h1>\n<p><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ab5f4f9f2b96682197cd6b15a7b7bfa2f8d5f6b8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f64656570687970\"> <img alt=\"PyPI - Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a83dbfa5a982bbe503d7b915cbdf806be16743a8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f646565706879703f636f6c6f723d627269676874677265656e\"></p>\n<p>Tools for training and using unsupervised autoencoders and supervised deep learning classifiers for hyperspectral data.</p>\n<p>Documentation available <a href=\"https://deephyp.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">here</a>. Source code available on <a href=\"https://github.com/lloydwindrim/hyperspectral-autoencoders\" rel=\"nofollow\">Github</a>.</p>\n<p>Autoencoders are unsupervised neural networks that are useful for a range of applications such as unsupervised feature learning and dimensionality reduction. Supervised deep learning classifiers can be trained on labelled data to predict the class of spectra. This repository provides a python-based toolbox called <strong>deephyp</strong>, with examples for building, training and testing both dense and convolutional autoencoders and classification neural networks, designed for hyperspectral data. Networks are easy to setup and can be customised with different architectures. Different methods of training can also be implemented. The toolbox is built on tensorflow.</p>\n<p><img alt=\"Alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4f58108071490d5520358cecb69a4761475cf84c/696d616765732f6469616772616d2e706e673f7261773d74727565\"></p>\n<p>If you use the toolbox in your research, please cite:\n<a href=\"https://www.mdpi.com/2072-4292/11/7/864\" rel=\"nofollow\">Windrim et al. <strong>Unsupervised Feature-Learning for Hyperspectral Data with Autoencoders.</strong> Remote Sensing 11.7 (2019): 864.</a>\nThis paper explains the spectral angle (SA), spectral information divergence (SID) and sum-of-squared errors (SSE) loss functions for training autoencoders.</p>\n<p>If you use the cosine spectral angle (CSA) loss function in your research, please cite:\n<a href=\"https://ieeexplore.ieee.org/abstract/document/7533202\" rel=\"nofollow\">Windrim et al. <strong>Unsupervised feature learning for illumination robustness.</strong> 2016 IEEE International Conference on Image Processing (ICIP).</a></p>\n<p>If you use the classification networks in your research, please cite:\n<a href=\"https://www.researchgate.net/publication/332818169_Hyperspectral_CNN_Classification_with_Limited_Training_Samples\" rel=\"nofollow\">Windrim et al. <strong>Hyperspectral CNN Classification with Limited Training Samples.</strong> 2017 Proceedings of the British Machine Vision Conference (BMVC).</a></p>\n<h2>Installation</h2>\n<p>The <a href=\"https://pypi.org/project/deephyp/\" rel=\"nofollow\">latest release</a> of the toolbox can be installed from the command line using pip:</p>\n<pre><code>pip install deephyp\n</code></pre>\n<p>Dependencies can be installed using:</p>\n<pre><code>pip install -r requirements.txt\n</code></pre>\n<p>To import:</p>\n<pre><code>import deephyp\n</code></pre>\n<h2>Prerequisites</h2>\n<p>The software dependencies needed to run the toolbox are python 2 or python 3 (tested with version 2.7.15 and 3.5.2) with packages:</p>\n<ul>\n<li>tensorflow (tested with v1.14.0) - not yet compatible with tensorflow v2.0</li>\n<li>numpy (tested with v1.15.4)</li>\n</ul>\n<p>Each of these packages can be installed using <a href=\"https://pypi.org/project/pip/\" rel=\"nofollow\">pip</a>. The example scripts use some additional packages such as scipy (tested with v1.3.1) and matplotlib (tested with v3.0.3).</p>\n<p>Note: if you want to use deephyp but you have tensorflow v2, you can install deephyp in a virtual environment with tensorflow v1.14. <a href=\"https://www.tensorflow.org/install/pip\" rel=\"nofollow\">See instructions here</a>.</p>\n<h2>Quickstart</h2>\n<p>To start training an autoencoder right away, move to the /examples directory in the <a href=\"https://github.com/lloydwindrim/hyperspectral-autoencoders\" rel=\"nofollow\">github repo</a> and run the example script:</p>\n<pre><code>autoencoder_train_MLP_basic.py\n</code></pre>\n<p>It will download the Pavia Uni dataset and train an autoencoder. You can then run the example script:</p>\n<pre><code>autoencoder_test_MLP_basic.py\n</code></pre>\n<p>to test the autoencoder that was just trained, and generate some images of the latent hyperspectral image, latent vector and comparisons of the spectra and reconstruction in the results folder.</p>\n<p>To start training a classification network, from the /examples directory run the script:</p>\n<pre><code>classifier_train_CNN_basic.py\n</code></pre>\n<p>which will download the Pavia Uni dataset and ground truth labels and train a classifier. Then running the example script:</p>\n<pre><code>classifier_test_CNN_basic.py\n</code></pre>\n<p>will load the trained classifier and generate images with the predicted and ground truth labels for comparison.</p>\n<h2>Usage</h2>\n<p>The toolbox comprises several key processes:</p>\n<ul>\n<li><a href=\"#data-preparation\" rel=\"nofollow\">data preparation</a></li>\n<li><a href=\"#data-iterator\" rel=\"nofollow\">data iterator</a></li>\n<li><a href=\"#building-networks\" rel=\"nofollow\">building networks</a></li>\n<li><a href=\"#adding-training-operations\" rel=\"nofollow\">adding train operations</a></li>\n<li><a href=\"#training-networks\" rel=\"nofollow\">training networks</a></li>\n<li><a href=\"#loading-a-trained-network\" rel=\"nofollow\">loading a trained network</a></li>\n</ul>\n<p>Each of these are elaborated on below:</p>\n<h3>Data preparation</h3>\n<p>A class within the toolbox from the data module called HypImg handles the dataset. The class accepts the hyperspectral data  in numpy format, with shape [numRows x numCols x numBands] or [numSamples x numBands]. The networks in the toolbox operate in the spectral domain, not the spatial, so if an image is input with shape [numRows x numCols x numBands], it is reshaped to [numSamples x numBands], collapsing the spatial dimensions into one.</p>\n<pre><code>from deephyp import data\nhypData = data.HypImg( img )\n</code></pre>\n<p>or for hyperspectral data with class labels (i.e. for supervised classification):</p>\n<pre><code>hypData = data.HypImg( img, labels )\n</code></pre>\n<p>Then the data can be pre-processed using a function of the HypImg class. For example, using the 'minmax' approach:</p>\n<pre><code>hypData.pre_process( 'minmax' )\n</code></pre>\n<p>The result is stored in the attribute:</p>\n<pre><code>hypData.spectraPrep\n</code></pre>\n<p>When provided, labels are converted to a one-hot format stored as:</p>\n<pre><code>hypData.labelsOnehot\n</code></pre>\n<p>Any labels with value &lt;= 0 are considered as a background class, and appear as a row of zeros in labelsOnehot. They also do not count towards the number of classes stored in the data handler.</p>\n<p>Some hyperspectral datasets in a matlab file format (.mat) can be downloaded from <a href=\"http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes\" rel=\"nofollow\">here</a>. A matlab file (.mat) can be converted to the numpy format using the <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html\" rel=\"nofollow\">scipy.io.loadmat</a> function.</p>\n<h3>Data iterator</h3>\n<p>The Iterator class within the data module has methods for calling batches from the data that are used to train the network. A separate iterator object is made for the training and validation data. For example, an iterator object made from 100 pre-processed hyperspectral training samples with a batchsize of 10 is defined as:</p>\n<pre><code>dataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:100, :], targets=hypData.spectraPrep[:100, :], batchSize=10 )\n</code></pre>\n<p>Similarly, an iterator object made from 20 validation samples is defined as:</p>\n<pre><code>dataVal = data.Iterator( dataSamples=hypData.spectraPrep[100:120, :], targets=hypData.spectraPrep[100:120, :] )\n</code></pre>\n<p>Because the batchsize is unspecified, all 20 samples are used for the batch.</p>\n<p>For a typical unsupervised autoencoder, the targets that the network is learning to output are the same as the data samples being input into the network, as in the above iterator examples. When training a supervised classifier, the targets are the one-hot class labels:</p>\n<pre><code>dataTrain = data.Iterator( dataSamples=hypData.spectraPrep[:100, :], targets=hypData.labelsOnehot[:100, :], batchSize=10 )\n</code></pre>\n<p>The data in any iterator can also be shuffled before it is used to train a network:</p>\n<pre><code>dataTrain.shuffle()\n</code></pre>\n<h3>Building networks</h3>\n<p>The autoencoder module has classes used for creating autoencoder neural networks:</p>\n<pre><code>from deephyp import autoencoder\n</code></pre>\n<p>There are currently two type of autoencoders that can be set up. An MLP autoencoder has purely fully-connected  (i.e. dense) layers:</p>\n<pre><code>net = autoencoder.mlp_1D_network( inputSize=hypData.numBands )\n</code></pre>\n<p>And a convolutional autoencoder has mostly convolutional layers, with a fully-connected layer used to map the final convolutional layer in the encoder to the latent vector:</p>\n<pre><code>net = autoencoder.cnn_1D_network( inputSize=hypData.numBands )\n</code></pre>\n<p>If not using config files to set up a network, then the input size of the data must be specified. This should be the number of spectral bands.</p>\n<p>Additional aspects of the network architecture can also be specified when initialising the object. For the MLP autoencoder:</p>\n<pre><code>net = autoencoder.mlp_1D_network( inputSize=hypData.numBands, encoderSize=[50,30,10,5], activationFunc='relu', weightInitOpt='truncated_normal', tiedWeights=[1,0,0,0], skipConnect=False, activationFuncFinal='linear')\n</code></pre>\n<ul>\n<li>number of layers in the encoder (and decoder) - this is the length of the list 'encoderSize'</li>\n<li>number of neurons in each layer of the encoder - these are the values in the 'encoderSize' list. The last value in the list is the number of dimensions in the latent vector.</li>\n<li>the activation function which proceeds each layer and the function for the final decoder layer - activationFunc and activationFuncFinal</li>\n<li>the method of initialising network parameters (e.g. xavier improved) - 'weightInitOpt'</li>\n<li>which layers of the encoder to tie  to the decoder, such that they share a set of parameters - these are the values in the list 'tiedWeights'</li>\n<li>whether the network uses skip connections between corresponding layers in the encoder and decoder - specified by the boolean argument skipConnect</li>\n</ul>\n<p>The convolutional autoencoder has similar arguments for defining the network architecture, but without 'encoderSize' and with some additional arguments:</p>\n<pre><code>net = autoencoder.cnn_1D_network( inputSize=hypData.numBands, zDim=3, encoderNumFilters=[10,10,10], encoderFilterSize=[20,10,10],  activationFunc='relu', weightInitOpt='truncated_normal',  encoderStride=[1, 1, 1], padding='VALID', tiedWeights=[1,0,0],  skipConnect=False, activationFuncFinal='linear' )\n</code></pre>\n<ul>\n<li>number of layers in the encoder (and decoder) - this is the length of the list 'encodernumFilters'</li>\n<li>number of filters/kernels in each conv layer - these are the values in the 'encodernumFilters' list</li>\n<li>the size of the filters/kernels in each conv layer - these are the values in the 'encoderFilterSize' list</li>\n<li>the stride of the filters/kernels in each conv layer - these are the values in the 'encoderStride' list</li>\n<li>the number of dimensions in the latent vector - zDim</li>\n<li>the type of padding each conv layer uses - padding</li>\n</ul>\n<p>Alternatively to defining the architecture by the initialisation arguments, a config.json file can be used:</p>\n<pre><code>net = autoencoder.mlp_1D_network( configFile='config.json') )\n</code></pre>\n<p>Some example config files can be found in examples/example_configs.</p>\n<p>The classifier module has classes used for creating supervised classification neural networks:</p>\n<pre><code>from deephyp import classifier\n</code></pre>\n<p>There is currently one type of classifier that can be set up, which contains a combination of convolutional layers (at the start) and fully-connected layers (at the end):</p>\n<pre><code>net = classifier.cnn_1D_network( inputSize=hypData.numBands, numClasses=hypData.numClasses )\n</code></pre>\n<p>If not using config files the input size and number of classes must be specified for classifier networks. As with the autoencoder class, additional aspects of the architecture can be specified:</p>\n<pre><code>net = classifier.cnn_1D_network( inputSize=hypData.numBands, numClasses=hypData.numClasses, convFilterSize=[20,10,10], convNumFilters=[10,10,10], convStride = [1,1,1], fcSize=[20,20], activationFunc='relu', weightInitOpt='truncated_normal', padding='VALID' )\n</code></pre>\n<ul>\n<li>number of convolutional layers - this is the length of the list 'convNumFilters'</li>\n<li>number of filters/kernels in each conv layer - these are the values in the 'convNumFilters' list</li>\n<li>the size of the filters/kernels in each conv layer - these are the values in the 'convFilterSize' list</li>\n<li>the stride of the filters/kernels in each conv layer - these are the values in the 'convStride' list</li>\n<li>the type of padding each conv layer uses - padding</li>\n<li>number of fully-connected layers - this is the length of the list 'fcSize'</li>\n<li>number of neurons in each fully-connected layer - these are the values in the 'fcSize' list</li>\n<li>the activation function which proceeds each layer - activationFunc</li>\n<li>the method of initialising network parameters (e.g. xavier improved) - 'weightInitOpt'</li>\n</ul>\n<p>Classifiers can also be setup with config files.</p>\n<h3>Adding training operations</h3>\n<p>Once a network has been created, a training operation can be added to it. It is possible to add multiple training operations to a network, so each op must be given a name:</p>\n<pre><code>net.add_train_op( name='experiment_1' )\n</code></pre>\n<p>When adding a train op, details about how the network will be trained with that op can be specified. For example, a train op for an autoencoder which uses the cosine spectral angle (CSA) loss function, a learning rate of 0.001 with no decay, optimised with Adam and no weight decay can be defined by:</p>\n<pre><code>net.add_train_op( name='experiment_1', lossFunc='CSA', learning_rate=1e-3, decay_steps=None, decay_rate=None, method='Adam', wd_lambda=0.0 )\n</code></pre>\n<p>There are several loss functions that can be used to train an autoencoder, many of which were designed specifically for hyperspectral data:</p>\n<ul>\n<li><a href=\"https://ieeexplore.ieee.org/abstract/document/7533202\" rel=\"nofollow\">cosine spectral angle (CSA)</a></li>\n<li><a href=\"https://www.mdpi.com/2072-4292/11/7/864\" rel=\"nofollow\">spectral angle (SA)</a></li>\n<li><a href=\"https://www.mdpi.com/2072-4292/11/7/864\" rel=\"nofollow\">spectral information divergence (SID)</a></li>\n<li><a href=\"https://www.mdpi.com/2072-4292/11/7/864\" rel=\"nofollow\">sum-of-squared errors (SSE)</a></li>\n</ul>\n<p>Note that when using the CSA, SA and SID loss functions it is expected that the reconstructed spectra have a different magnitude to the target spectra, but a similar shape. The SSE should produce a similar magnitude and shape. Also, since the SID contains <em>log</em> in its expression which is undefined for values <em>&lt;= 0</em>, it is best to use sigmoid as the activation function (including the final activation function) for networks trained with the SID loss. See train_MLP_sid.py for an example.</p>\n<p>The method of decaying the learning rate can also be customised. For example, to decay exponentially every 100 steps:</p>\n<pre><code>net.add_train_op( name='experiment_1',learning_rate=1e-3, decay_steps=100, decay_rate=0.9 )\n</code></pre>\n<p>A piecewise approach of decaying the learning rate can also be used. For example, to change the learning rate from 0.001 to 0.0001 after 100 steps, and then to 0.00001 after a further 200 steps:</p>\n<pre><code>net.add_train_op( name='experiment_1',learning_rate=1e-3, piecewise_bounds=[100,300], piecewise_values=[1e-4,1e-5] )\n</code></pre>\n<p>Train ops are added to classifiers in the same way, with the only difference being the option to balance classes when training, and no specification of the loss function (a cross-entropy loss function is used):</p>\n<pre><code>net.add_train_op( name='basic_clf', balance_classes=True, learning_rate=1e-3 )\n</code></pre>\n<h3>Training networks</h3>\n<p>Once one or multiple training ops have been added to a network, they can be used to learn a model (or multiple models) for that network through training:</p>\n<pre><code>net.train(dataTrain=dataTrain, dataVal=dataVal, train_op_name='experiment_1', n_epochs=100, save_addr=model_directory, visualiseRateTrain=5, visualiseRateVal=10, save_epochs=[50,100])\n</code></pre>\n<p>The train method learns a model using one train op, therefore the train method should be called at least once for each train op that was added. The name of the train op must be specified, and the training and validation iterators created previously must be input. A path to a directory to save the model must also be specified. The example above will train a network for 100 epochs of the training dataset, and save the model at 50 and 100 epochs. The training loss will be displayed every 5 epochs, and the validation loss will be displayed every 10 epochs.</p>\n<p>It is also possible to load a pre-trained model and continue to train it by passing the address of epoch folder containing the model checkpoint as the save_addr argument. For example, if the directory for the model at epoch 50 (epoch_50 folder) was passed to save_addr in the example above, then the model would be trained for an additional 50 epochs to reach 100, and it would be saved in a folder called epoch_100 in the same directory as the epoch_50 folder.</p>\n<p>The interface for training autoencoders and classifiers is the same.</p>\n<h3>Loading a trained network</h3>\n<p>To load a trained model on a new dataset, ensure the data has been pre-processed similarly using:</p>\n<pre><code>import data\nhypData = data.HypImg( new_img )\nhypData.pre_process( 'minmax' )\n</code></pre>\n<p>Then set up the network. The network architecture must be the same as the one used for the model being loaded. However, this is easy as the directory where models are saved should contain an automatically generated config.json file, which can be used to set up the network with the same architecture:</p>\n<pre><code>net = autoencoder.mlp_1D_network( configFile='model_directory/config.json' )\n</code></pre>\n<p>Once the architecture has been defined, add a model to the network:</p>\n<pre><code>net.add_model( addr='model_directory/epoch_100'), modelName='csa_100' )\n</code></pre>\n<p>Because multiple models can be added to a single network, the added model must be given a name.</p>\n<p>When the network is set up and a model has been added, hyperspectral data can be passed through it. To use a trained autoencoder to extract the latent vectors of some spectra:</p>\n<pre><code>dataZ = net.encoder( modelName='csa_100', dataSamples=hypData.spectraPrep )\n</code></pre>\n<p>Make sure to refer to the name of the model the network should use. The encoded hyperspectral (dataZ) data can also be decoded to get the reconstruction:</p>\n<pre><code>dataY = net.decoder(modelName='csa_100', dataZ=dataZ)\n</code></pre>\n<p>It is also possible to encode and decode in one step with:</p>\n<pre><code>dataY = net.encoder_decoder(modelName='csa_100', dataZ=hypData.spectraPrep)\n</code></pre>\n<p>To use a trained classifier to predict the classification labels of some spectra:</p>\n<pre><code>dataPred = net.predict_labels( modelName='basic_model', dataSamples=hypData.spectraPrep  )\n</code></pre>\n<p>To extract the features in the second last layer of the classifier network:</p>\n<pre><code>dataFeatures = net.predict_features(modelName='basic_model', dataSamples=hypData.spectraPrep, layer=net.numLayers-1)\n</code></pre>\n<h2>Results</h2>\n<p>An example of a latent space for the Pavia University dataset, produced with a MLP autoencoder trained using the cosine spectral angle (CSA):</p>\n<p><img alt=\"Alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/97ea95fccf58ba901e14e80de96f32fbaa949110/696d616765732f6d6c705f6c6174656e745f73706163652e706e673f7261773d74727565\"></p>\n<p>And an example of a latent space for the Pavia University dataset, produced with a convolutional autoencoder trained using the cosine spectral angle (CSA):</p>\n<p><img alt=\"Alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f9f30ca1e4fc6a0baf38f4de4caa8660bad54148/696d616765732f636e6e5f6c6174656e745f73706163652e706e673f7261773d74727565\"></p>\n<p>Both figures were made running the scripts:</p>\n<pre><code>autoencoder_train_CNN_vs_MLP.py\nautoencoder_test_CNN_vs_MLP.py\n</code></pre>\n<p>A classification result for the Pavia University dataset produced using the CNN classifier:</p>\n<p><img alt=\"Alt text\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/013c6ed046cf3ac90c32d9183a3767260bbfb6e8/696d616765732f636c617373696669636174696f6e5f707265642e706e673f7261773d74727565\"></p>\n<p>The figure was made by running the scripts:</p>\n<pre><code>classifier_train_CNN_basic.py\nclassifier_test_CNN_basic.py\n</code></pre>\n<h2>Related publications</h2>\n<p>Some links to publications on deep learning for hyperspectral data:</p>\n<ul>\n<li>autoencoders: <a href=\"https://ieeexplore.ieee.org/abstract/document/7533202\" rel=\"nofollow\">ICIP 2016</a>, <a href=\"https://ieeexplore.ieee.org/abstract/document/8063434\" rel=\"nofollow\">TIP 2017</a>, <a href=\"https://www.mdpi.com/2072-4292/11/7/864\" rel=\"nofollow\">Remote Sensing 2019</a></li>\n<li>CNNs for classification using data augmentation: <a href=\"https://www.researchgate.net/publication/332818169_Hyperspectral_CNN_Classification_with_Limited_Training_Samples\" rel=\"nofollow\">BMVC 2017</a></li>\n<li>pre-training CNNs: <a href=\"https://ieeexplore.ieee.org/abstract/document/8245897\" rel=\"nofollow\">TGRS 2018</a></li>\n<li><a href=\"https://ses.library.usyd.edu.au/handle/2123/18734\" rel=\"nofollow\">PhD thesis</a></li>\n</ul>\n\n          </div>"}, "last_serial": 5970750, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "f1227f1bac87e0c295439f3d5f513101", "sha256": "275cef397ff0440292e9d7191008fb1a8bef33f3b59ddb1a6e7d16703cc611e8"}, "downloads": -1, "filename": "deephyp-0.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "f1227f1bac87e0c295439f3d5f513101", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 23166, "upload_time": "2019-08-26T10:56:48", "upload_time_iso_8601": "2019-08-26T10:56:48.474715Z", "url": "https://files.pythonhosted.org/packages/f7/50/bf77d21c702f32895f6ef62947a89e8f71fd2dc7e4f8d3f222981c17a7c8/deephyp-0.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d333215a943b44f4ccadc8e946196d8d", "sha256": "3e44de04b9e69f58df60bc46f79772d2a6df7c8b4b1e4d63fe76c26d282730de"}, "downloads": -1, "filename": "deephyp-0.1.0.tar.gz", "has_sig": false, "md5_digest": "d333215a943b44f4ccadc8e946196d8d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18738, "upload_time": "2019-08-26T10:56:51", "upload_time_iso_8601": "2019-08-26T10:56:51.331337Z", "url": "https://files.pythonhosted.org/packages/06/ef/6afd89610c808b59ff34e319adf2a352f2fa01346059c56c682e96cc1489/deephyp-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "7334649854cc723a733d96d9a37e2b8b", "sha256": "89653f1de0620f4429fdb724061db522d57149ebc219ba93ad2a89bbe29fd930"}, "downloads": -1, "filename": "deephyp-0.1.1.tar.gz", "has_sig": false, "md5_digest": "7334649854cc723a733d96d9a37e2b8b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18890, "upload_time": "2019-08-28T10:17:29", "upload_time_iso_8601": "2019-08-28T10:17:29.446781Z", "url": "https://files.pythonhosted.org/packages/d0/37/227014430a532327cfb22edd099e903eaa0882c92c31905d1071b4fd25a8/deephyp-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "4cb2c0586e51ee3741dabee2f7432492", "sha256": "aa2c66141719a284e8db0ae2dd8fde468559ad4511dba4cfa4ee87b177d432a2"}, "downloads": -1, "filename": "deephyp-0.1.2-py2-none-any.whl", "has_sig": false, "md5_digest": "4cb2c0586e51ee3741dabee2f7432492", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 23318, "upload_time": "2019-08-28T10:24:30", "upload_time_iso_8601": "2019-08-28T10:24:30.118979Z", "url": "https://files.pythonhosted.org/packages/19/d0/a195f58365a4face820a967e3c04853126987912ef43e5417e75aa4d5125/deephyp-0.1.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "36fa9bac9782a9ed92f98f5ec7d49514", "sha256": "1a701ef40c4d7ad9ae69314d34e626bfc1c0d58e69cb9fbd769c2989f02c9761"}, "downloads": -1, "filename": "deephyp-0.1.2.tar.gz", "has_sig": false, "md5_digest": "36fa9bac9782a9ed92f98f5ec7d49514", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18892, "upload_time": "2019-08-28T10:24:37", "upload_time_iso_8601": "2019-08-28T10:24:37.925613Z", "url": "https://files.pythonhosted.org/packages/e5/5c/e2b42263795059d2f1413ea690128709310cdf6b2ab4340c80683ffd2a79/deephyp-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "9d24effcb26372b14fff15f914fba563", "sha256": "be12eaf0c51b32a40813574d31cf4d5039262ba6fcf24dc02a6f14a8964f5607"}, "downloads": -1, "filename": "deephyp-0.1.3-py2-none-any.whl", "has_sig": false, "md5_digest": "9d24effcb26372b14fff15f914fba563", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 24918, "upload_time": "2019-09-03T14:55:55", "upload_time_iso_8601": "2019-09-03T14:55:55.529539Z", "url": "https://files.pythonhosted.org/packages/7b/30/b112c2caa9e5365d6afa00a2094a25ee66a59ef02b3a1dbe62471d4a0f62/deephyp-0.1.3-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "bf3a7bb8d1d4bd3608c906af67f3e961", "sha256": "846e6180a63509e22fe280e83a4ec6b1c9b9a27d2a9356d392a90b0202239bbb"}, "downloads": -1, "filename": "deephyp-0.1.3.tar.gz", "has_sig": false, "md5_digest": "bf3a7bb8d1d4bd3608c906af67f3e961", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20489, "upload_time": "2019-09-03T14:56:02", "upload_time_iso_8601": "2019-09-03T14:56:02.637540Z", "url": "https://files.pythonhosted.org/packages/a4/29/d1355c7899f4ae356ba058c71b1534de043baeab876c864fdf3d8da61b66/deephyp-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "2e2bf4448e6f2e8992ad37baf00fb3eb", "sha256": "6dc4551fca637c512edb31abcd83606e47f9aeb825e074dfdd213506f6b9d1f2"}, "downloads": -1, "filename": "deephyp-0.1.4-py2-none-any.whl", "has_sig": false, "md5_digest": "2e2bf4448e6f2e8992ad37baf00fb3eb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 24915, "upload_time": "2019-09-22T05:54:02", "upload_time_iso_8601": "2019-09-22T05:54:02.495545Z", "url": "https://files.pythonhosted.org/packages/a5/26/2bc71a53b67af9852f46b09c5c279d3bad2410273fe680a7327d02cd11d7/deephyp-0.1.4-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c214491620b898423d6f296b0050d345", "sha256": "57c7b0b681332926f046ac9b304d99da1e9dcaf6e12c8fc951c7464ff386b9b4"}, "downloads": -1, "filename": "deephyp-0.1.4.tar.gz", "has_sig": false, "md5_digest": "c214491620b898423d6f296b0050d345", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20493, "upload_time": "2019-09-22T05:54:15", "upload_time_iso_8601": "2019-09-22T05:54:15.995404Z", "url": "https://files.pythonhosted.org/packages/af/f3/21d48a21ad87e2e0b0eae5dcadbdecb11a8ab3b115c6f97336724ffea712/deephyp-0.1.4.tar.gz", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "dae9c30c22782b02593f0a3f1eb41e56", "sha256": "61f1752b95dbd741be9df9953f2254e5b243c44c98ba8c97cefa8af66222bec0"}, "downloads": -1, "filename": "deephyp-0.1.5-py2-none-any.whl", "has_sig": false, "md5_digest": "dae9c30c22782b02593f0a3f1eb41e56", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25001, "upload_time": "2019-10-14T10:16:21", "upload_time_iso_8601": "2019-10-14T10:16:21.187885Z", "url": "https://files.pythonhosted.org/packages/17/78/a546557d4eceba480c8f7bbcbb52bdb9e356f9872361e0e2e8f723f57c77/deephyp-0.1.5-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "34a3980929fd1757a9801cd31de5472d", "sha256": "4afbb8cad4e7c44e58e9966912a3661cec58644bfefd9505ad78062295852e60"}, "downloads": -1, "filename": "deephyp-0.1.5.tar.gz", "has_sig": false, "md5_digest": "34a3980929fd1757a9801cd31de5472d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20580, "upload_time": "2019-10-14T10:16:31", "upload_time_iso_8601": "2019-10-14T10:16:31.047402Z", "url": "https://files.pythonhosted.org/packages/b8/d2/a7c753ea1f9509176c58cd64a41109afe9366ccc65d6d6c41f8279945a83/deephyp-0.1.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dae9c30c22782b02593f0a3f1eb41e56", "sha256": "61f1752b95dbd741be9df9953f2254e5b243c44c98ba8c97cefa8af66222bec0"}, "downloads": -1, "filename": "deephyp-0.1.5-py2-none-any.whl", "has_sig": false, "md5_digest": "dae9c30c22782b02593f0a3f1eb41e56", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25001, "upload_time": "2019-10-14T10:16:21", "upload_time_iso_8601": "2019-10-14T10:16:21.187885Z", "url": "https://files.pythonhosted.org/packages/17/78/a546557d4eceba480c8f7bbcbb52bdb9e356f9872361e0e2e8f723f57c77/deephyp-0.1.5-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "34a3980929fd1757a9801cd31de5472d", "sha256": "4afbb8cad4e7c44e58e9966912a3661cec58644bfefd9505ad78062295852e60"}, "downloads": -1, "filename": "deephyp-0.1.5.tar.gz", "has_sig": false, "md5_digest": "34a3980929fd1757a9801cd31de5472d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20580, "upload_time": "2019-10-14T10:16:31", "upload_time_iso_8601": "2019-10-14T10:16:31.047402Z", "url": "https://files.pythonhosted.org/packages/b8/d2/a7c753ea1f9509176c58cd64a41109afe9366ccc65d6d6c41f8279945a83/deephyp-0.1.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:24 2020"}