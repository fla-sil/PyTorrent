{"info": {"author": "source{d}", "author_email": "machine-learning@sourced.tech", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: GNU Affero General Public License v3", "Operating System :: POSIX", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Quality Assurance"], "description": "![Format man](doc/logo.png)\n# style-analyzer\nFix code style faults using \ud83e\udd16\n\n\n[![Read the Docs](https://img.shields.io/readthedocs/style-analyzer.svg)](https://readthedocs.org/projects/style-analyzer/)\n[![Travis build status](https://travis-ci.com/src-d/style-analyzer.svg?branch=master)](https://travis-ci.com/src-d/style-analyzer)\n[![Code coverage](https://codecov.io/github/src-d/style-analyzer/coverage.svg)](https://codecov.io/github/src-d/style-analyzer)\n[![Docker build status](https://img.shields.io/docker/build/srcd/style-analyzer.svg)](https://hub.docker.com/r/srcd/style-analyzer)\n[![PyPi package status](https://img.shields.io/pypi/v/lookout-style.svg)](https://pypi.python.org/pypi/lookout-style)\n![stability: beta](https://svg-badge.appspot.com/badge/stability/beta?color=ff8000)\n[![AGPL 3.0 license](https://img.shields.io/badge/license-AGPL%203.0-blue.svg)](https://opensource.org/licenses/AGPL-3.0)\n\n[Overview](#overview) \u2022 [How To Use](#how-to-use) \u2022 [Science](#science) \u2022 [Contributions](#contributions) \u2022 [License](#license)\n\n## Overview\n\nThis is a collection of analyzers for [Lookout](https://github.com/src-d/lookout) - the open source framework for code review intelligence.\nYou can run them directly on your Git repositories, but most likely you don't want that and instead\njust use the upcoming code review product from [source{d}](https://sourced.tech).\nOverall, this project is a mix of research ideas and their applications to solving real problems.\nConsider it as an experiment at this stage.\n\nCurrently, there is the \"format\" analyzer working and the one \"typos\" incubating. All the current and the future\nones are based on machine learning and never contain any hidden domain knowledge such as static\ncode analysis rules or human-written pattern matchers.\n\n* [`lookout.style.format`](lookout/style/format) - mine \"white box\" code formatting rules with machine learning and validate new code against them.\n* [`lookout.style.typos`](lookout/style/typos) - find typos in identifier names, using the dataset of 60 million identifiers already present in open source repositories on GitHub.\n\n\"format\" analyzer supports only JavaScript for now, though it is not nailed to that language and\nis based on the language-agnostic [Babelfish](https://doc.bblf.sh/) parser. Everything is written in Python.\n\n## How To Use\n\nThere are several ways to run style-analyzer:\n\n* [Developer's setup](doc/how-to/developer.md)\n* [Demonstration setup](doc/how-to/demo.md)\n* [Reports](doc/how-to/reports.md)\n\n## Science\n\nThe implemented analyzers are driven by bleeding edge research. One day we will write papers about them,\nbut first we want to focus on making them work. Below are brief descriptions of how the analyzers\nare designed.\n\n#### format\n\nThe core of the format analyzer is a language model: we learn without labeled data, just by modeling the existing format in a repository given the current code at a given point in a file. We then check whether the proposed changes follow those learnt formatting conventions.\nThe training algorithm is summarized below.\n\n1. Represent a file as a linear sequence of \"virtual\" nodes. Some nodes correspond to the UAST nodes, and some are inserted to mirror the real tokens in the code which are not present in the UAST (e.g. white spaces, keywords, quotes or braces).\n2. Identify the nodes which we use as labels - that is, identify Y-s in the (X, Y) training samples. We have around 50 classes at the moment. Some of the classes are sequences of nodes, e.g. four space indentation increase. We also predict NOOP-s: the empty gaps between non-Y nodes.\n3. Extract features from the nodes surrounding the Y nodes. We take a fixed-size window and record the internal types, roles, positions and unique identifiers (for tokens which are not present in the UAST) for the left and right siblings and the parent hierarchy (2-3 levels). The features for the left and for the right siblings are different so that we avoid the information \"leakage\". For example, the difference in offsets between the left and the right neighbor defines the exact length of the predicted token in between.\n4. We train the random forest model on the collected (X, Y) dataset. We fine-tune it with bayesian optimization.\n5. We extract the rules - the branches of the trees. We prune them in several steps: first we exclude the rules which do not improve the accuracy, second we remove the rule parts which are redundant.\n6. We put 93% rule confidence threshold - that is, precision on the training set - and discard the rest. This gives ~95% joint precision.\n7. The rules which are left is our model - the training result.\n\nThe application algorithm is much simpler - we take the rules and apply them. However, there are several quirks:\n1. In case several rules are triggered, the rule with the highest confidence wins.\n2. There are paired tokens which we predict such as quotes. It is possible that there are two rules which contradict each other - the left and the right quotes are predicted to be different. We pick the most confident prediction and change the second quote accordingly.\n3. We check that the prediction does not break the code. For example, it can insert a newline in the middle of the expression which can change the AST. We run Babelfish on each changed line to see if the AST remains the same.\n4. There is a huge chunk of code to represent the triggered rule in a human-readable format and generate the code for fixes.\n\n#### typos\n\nWe take the dataset with identifiers extracted from [Public Git Archive](https://github.com/src-d/datasets/tree/master/PublicGitArchive).\nWe split them (blog post is pending early November). There are frequencies present for each \"atom\",\nso we consider top frequent ones as ground truth. For each checked \"atom\", we take it's embedding\ncomputed with [fasttext](https://github.com/facebookresearch/fastText), refine it with a deep\nfully-connected neural network, generate candidates with [symspell](https://github.com/wolfgarbe/SymSpell)\nand rank them with [XGBoost](https://github.com/dmlc/xgboost).\n\n## Contributions\n\nContributions are very welcome and desired! Please follow the [code of conduct](doc/code_of_conduct.md)\nand read the [contribution guidelines](doc/contributing.md). If you want to add a new cool style\nfixer backed by machine learning, it is always a good idea to discuss it on\n[Slack](https://sourced.tech/community/#talk).\n\n## License\n\nAGPL-3.0, see [LICENSE.md](LICENSE.md).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/src-d/style-analyzer", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/src-d/style-analyzer", "keywords": "machine learning on source code,babelfish,lookout", "license": "AGPL-3.0", "maintainer": "", "maintainer_email": "", "name": "lookout-style", "package_url": "https://pypi.org/project/lookout-style/", "platform": "", "project_url": "https://pypi.org/project/lookout-style/", "project_urls": {"Download": "https://github.com/src-d/style-analyzer", "Homepage": "https://github.com/src-d/style-analyzer"}, "release_url": "https://pypi.org/project/lookout-style/0.2.0/", "requires_dist": ["sourced-ml (<0.9,>=0.8.2)", "lookout-sdk-ml (<0.20,>=0.19.0)", "scikit-learn (<2.0,>=0.20)", "scikit-optimize (<2.0,>=0.5)", "pandas (<2.0,>=0.22)", "gensim (<3.7.2,>=3.7.1)", "google-compute-engine (<3.0,>=2.8.3)", "xgboost (<2.0,>=0.72)", "tabulate (<2.0,>=0.8.0)", "python-igraph (<2.0,>=0.7.0)", "smart-open (<2.0,>=1.8.1)", "joblib (<1.0,>=0.13.2)", "docker (<4.0,>=3.4.0) ; extra == 'all_cpu'", "tensorflow (<2.0,>=1.0) ; extra == 'all_cpu'", "matplotlib (<3.0,>=2.0) ; extra == 'all_cpu'", "Flask (<2.0,>=1.0.0) ; extra == 'all_cpu'", "Flask-Cors (<4.0,>=3.0.0) ; extra == 'all_cpu'", "docker (<4.0,>=3.4.0) ; extra == 'all_gpu'", "tensorflow-gpu (<2.0,>=1.0) ; extra == 'all_gpu'", "matplotlib (<3.0,>=2.0) ; extra == 'all_gpu'", "Flask (<2.0,>=1.0.0) ; extra == 'all_gpu'", "Flask-Cors (<4.0,>=3.0.0) ; extra == 'all_gpu'", "matplotlib (<3.0,>=2.0) ; extra == 'plot'", "docker (<4.0,>=3.4.0) ; extra == 'test'", "tensorflow (<2.0,>=1.0) ; extra == 'tf'", "tensorflow-gpu (<2.0,>=1.0) ; extra == 'tf_gpu'", "Flask (<2.0,>=1.0.0) ; extra == 'web'", "Flask-Cors (<4.0,>=3.0.0) ; extra == 'web'"], "requires_python": "", "summary": "Machine learning-based assisted code review - code style analyzers.", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"Format man\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9592ebf51b115ef4d2ee81f56a45c9fccd07011b/646f632f6c6f676f2e706e67\"></p>\n<h1>style-analyzer</h1>\n<p>Fix code style faults using \ud83e\udd16</p>\n<p><a href=\"https://readthedocs.org/projects/style-analyzer/\" rel=\"nofollow\"><img alt=\"Read the Docs\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5a4655542795ccce0849e2f2bec46ef7ed4819e2/68747470733a2f2f696d672e736869656c64732e696f2f72656164746865646f63732f7374796c652d616e616c797a65722e737667\"></a>\n<a href=\"https://travis-ci.com/src-d/style-analyzer\" rel=\"nofollow\"><img alt=\"Travis build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1dfdf16e5a12bfeae45477230556c29a67198adb/68747470733a2f2f7472617669732d63692e636f6d2f7372632d642f7374796c652d616e616c797a65722e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://codecov.io/github/src-d/style-analyzer\" rel=\"nofollow\"><img alt=\"Code coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8f1b0bb8038f5ca83767bce37d912bc2c3b41582/68747470733a2f2f636f6465636f762e696f2f6769746875622f7372632d642f7374796c652d616e616c797a65722f636f7665726167652e737667\"></a>\n<a href=\"https://hub.docker.com/r/srcd/style-analyzer\" rel=\"nofollow\"><img alt=\"Docker build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eede5f220ef3b649b05b0e5d45be99a8d9612a1a/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f6275696c642f737263642f7374796c652d616e616c797a65722e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/lookout-style\" rel=\"nofollow\"><img alt=\"PyPi package status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a3884c170ade45789a22bd103c2f9bb2bb4e760c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6f6f6b6f75742d7374796c652e737667\"></a>\n<img alt=\"stability: beta\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c69630991c8be27c4265d42668a81890b81cac31/68747470733a2f2f7376672d62616467652e61707073706f742e636f6d2f62616467652f73746162696c6974792f626574613f636f6c6f723d666638303030\">\n<a href=\"https://opensource.org/licenses/AGPL-3.0\" rel=\"nofollow\"><img alt=\"AGPL 3.0 license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a26167a1b7ac41d99aeabcb9a7d82b1821d1485a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4147504c253230332e302d626c75652e737667\"></a></p>\n<p><a href=\"#overview\" rel=\"nofollow\">Overview</a> \u2022 <a href=\"#how-to-use\" rel=\"nofollow\">How To Use</a> \u2022 <a href=\"#science\" rel=\"nofollow\">Science</a> \u2022 <a href=\"#contributions\" rel=\"nofollow\">Contributions</a> \u2022 <a href=\"#license\" rel=\"nofollow\">License</a></p>\n<h2>Overview</h2>\n<p>This is a collection of analyzers for <a href=\"https://github.com/src-d/lookout\" rel=\"nofollow\">Lookout</a> - the open source framework for code review intelligence.\nYou can run them directly on your Git repositories, but most likely you don't want that and instead\njust use the upcoming code review product from <a href=\"https://sourced.tech\" rel=\"nofollow\">source{d}</a>.\nOverall, this project is a mix of research ideas and their applications to solving real problems.\nConsider it as an experiment at this stage.</p>\n<p>Currently, there is the \"format\" analyzer working and the one \"typos\" incubating. All the current and the future\nones are based on machine learning and never contain any hidden domain knowledge such as static\ncode analysis rules or human-written pattern matchers.</p>\n<ul>\n<li><a href=\"lookout/style/format\" rel=\"nofollow\"><code>lookout.style.format</code></a> - mine \"white box\" code formatting rules with machine learning and validate new code against them.</li>\n<li><a href=\"lookout/style/typos\" rel=\"nofollow\"><code>lookout.style.typos</code></a> - find typos in identifier names, using the dataset of 60 million identifiers already present in open source repositories on GitHub.</li>\n</ul>\n<p>\"format\" analyzer supports only JavaScript for now, though it is not nailed to that language and\nis based on the language-agnostic <a href=\"https://doc.bblf.sh/\" rel=\"nofollow\">Babelfish</a> parser. Everything is written in Python.</p>\n<h2>How To Use</h2>\n<p>There are several ways to run style-analyzer:</p>\n<ul>\n<li><a href=\"doc/how-to/developer.md\" rel=\"nofollow\">Developer's setup</a></li>\n<li><a href=\"doc/how-to/demo.md\" rel=\"nofollow\">Demonstration setup</a></li>\n<li><a href=\"doc/how-to/reports.md\" rel=\"nofollow\">Reports</a></li>\n</ul>\n<h2>Science</h2>\n<p>The implemented analyzers are driven by bleeding edge research. One day we will write papers about them,\nbut first we want to focus on making them work. Below are brief descriptions of how the analyzers\nare designed.</p>\n<h4>format</h4>\n<p>The core of the format analyzer is a language model: we learn without labeled data, just by modeling the existing format in a repository given the current code at a given point in a file. We then check whether the proposed changes follow those learnt formatting conventions.\nThe training algorithm is summarized below.</p>\n<ol>\n<li>Represent a file as a linear sequence of \"virtual\" nodes. Some nodes correspond to the UAST nodes, and some are inserted to mirror the real tokens in the code which are not present in the UAST (e.g. white spaces, keywords, quotes or braces).</li>\n<li>Identify the nodes which we use as labels - that is, identify Y-s in the (X, Y) training samples. We have around 50 classes at the moment. Some of the classes are sequences of nodes, e.g. four space indentation increase. We also predict NOOP-s: the empty gaps between non-Y nodes.</li>\n<li>Extract features from the nodes surrounding the Y nodes. We take a fixed-size window and record the internal types, roles, positions and unique identifiers (for tokens which are not present in the UAST) for the left and right siblings and the parent hierarchy (2-3 levels). The features for the left and for the right siblings are different so that we avoid the information \"leakage\". For example, the difference in offsets between the left and the right neighbor defines the exact length of the predicted token in between.</li>\n<li>We train the random forest model on the collected (X, Y) dataset. We fine-tune it with bayesian optimization.</li>\n<li>We extract the rules - the branches of the trees. We prune them in several steps: first we exclude the rules which do not improve the accuracy, second we remove the rule parts which are redundant.</li>\n<li>We put 93% rule confidence threshold - that is, precision on the training set - and discard the rest. This gives ~95% joint precision.</li>\n<li>The rules which are left is our model - the training result.</li>\n</ol>\n<p>The application algorithm is much simpler - we take the rules and apply them. However, there are several quirks:</p>\n<ol>\n<li>In case several rules are triggered, the rule with the highest confidence wins.</li>\n<li>There are paired tokens which we predict such as quotes. It is possible that there are two rules which contradict each other - the left and the right quotes are predicted to be different. We pick the most confident prediction and change the second quote accordingly.</li>\n<li>We check that the prediction does not break the code. For example, it can insert a newline in the middle of the expression which can change the AST. We run Babelfish on each changed line to see if the AST remains the same.</li>\n<li>There is a huge chunk of code to represent the triggered rule in a human-readable format and generate the code for fixes.</li>\n</ol>\n<h4>typos</h4>\n<p>We take the dataset with identifiers extracted from <a href=\"https://github.com/src-d/datasets/tree/master/PublicGitArchive\" rel=\"nofollow\">Public Git Archive</a>.\nWe split them (blog post is pending early November). There are frequencies present for each \"atom\",\nso we consider top frequent ones as ground truth. For each checked \"atom\", we take it's embedding\ncomputed with <a href=\"https://github.com/facebookresearch/fastText\" rel=\"nofollow\">fasttext</a>, refine it with a deep\nfully-connected neural network, generate candidates with <a href=\"https://github.com/wolfgarbe/SymSpell\" rel=\"nofollow\">symspell</a>\nand rank them with <a href=\"https://github.com/dmlc/xgboost\" rel=\"nofollow\">XGBoost</a>.</p>\n<h2>Contributions</h2>\n<p>Contributions are very welcome and desired! Please follow the <a href=\"doc/code_of_conduct.md\" rel=\"nofollow\">code of conduct</a>\nand read the <a href=\"doc/contributing.md\" rel=\"nofollow\">contribution guidelines</a>. If you want to add a new cool style\nfixer backed by machine learning, it is always a good idea to discuss it on\n<a href=\"https://sourced.tech/community/#talk\" rel=\"nofollow\">Slack</a>.</p>\n<h2>License</h2>\n<p>AGPL-3.0, see <a href=\"LICENSE.md\" rel=\"nofollow\">LICENSE.md</a>.</p>\n\n          </div>"}, "last_serial": 5149704, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "787014c7e4db5ae42e00336b08984033", "sha256": "44a6f084459db2faadaed555c2561f2d3522b9bbf08ca73246f0d78520540a9f"}, "downloads": -1, "filename": "lookout-style-0.0.1.tar.gz", "has_sig": false, "md5_digest": "787014c7e4db5ae42e00336b08984033", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 37144, "upload_time": "2018-08-23T16:45:38", "upload_time_iso_8601": "2018-08-23T16:45:38.893176Z", "url": "https://files.pythonhosted.org/packages/b7/d0/4672e463b439ab1a2f27d6b105704510f23b0a9ee4332a112f228a82f86a/lookout-style-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "01b02ae085ca36d5feda8b83daf0c6c9", "sha256": "27c03cab3bf912c5974ccbfce1a047c32e0a1bde1baf0f30f07a8845e6171e77"}, "downloads": -1, "filename": "lookout-style-0.0.2.tar.gz", "has_sig": false, "md5_digest": "01b02ae085ca36d5feda8b83daf0c6c9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 40537, "upload_time": "2018-09-01T07:44:49", "upload_time_iso_8601": "2018-09-01T07:44:49.544638Z", "url": "https://files.pythonhosted.org/packages/c9/27/32cb4ce8ec226fd1bd62a9b4f0050d36c88d5029aa7b45f50d250552ad46/lookout-style-0.0.2.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "023c936add5b0403d000468f37015cc0", "sha256": "a5820dd795fbbae5e378289d3c04b775d3b47c86909565df8bba98a15c35853b"}, "downloads": -1, "filename": "lookout_style-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "023c936add5b0403d000468f37015cc0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2411390, "upload_time": "2019-02-01T19:28:03", "upload_time_iso_8601": "2019-02-01T19:28:03.001118Z", "url": "https://files.pythonhosted.org/packages/06/9f/76e4f241504a7e2c80092bfe39ff92c409e33520afa312c2568d1e21c5c3/lookout_style-0.1.0-py3-none-any.whl", "yanked": false}], "0.1.0rc2": [{"comment_text": "", "digests": {"md5": "d68c85c9afe520ac6504ccea6168fc78", "sha256": "231223b39e75e069345f820fc2df953723d050ee059e12c6bd2daaa4bd778cf9"}, "downloads": -1, "filename": "lookout_style-0.1.0rc2-py3-none-any.whl", "has_sig": false, "md5_digest": "d68c85c9afe520ac6504ccea6168fc78", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 135195, "upload_time": "2018-12-19T15:59:06", "upload_time_iso_8601": "2018-12-19T15:59:06.463865Z", "url": "https://files.pythonhosted.org/packages/15/c3/c33af435b8d498f16b9a7aee4902017dcd58c702dc134357102b7c1a8692/lookout_style-0.1.0rc2-py3-none-any.whl", "yanked": false}], "0.1.0rc3": [{"comment_text": "", "digests": {"md5": "b169bf30e096be12daa6b81ae189c2f8", "sha256": "79c27a095980c8cae50e4d6df613c02cfd2a1b56268e909af031bfd4bf1c93d7"}, "downloads": -1, "filename": "lookout_style-0.1.0rc3-py3-none-any.whl", "has_sig": false, "md5_digest": "b169bf30e096be12daa6b81ae189c2f8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2409326, "upload_time": "2019-01-22T15:01:26", "upload_time_iso_8601": "2019-01-22T15:01:26.281388Z", "url": "https://files.pythonhosted.org/packages/72/18/48b4c067b39f4aa477b841dc2edb93ebf4be9390416c5335363bcd4a8063/lookout_style-0.1.0rc3-py3-none-any.whl", "yanked": false}], "0.1.0rc4": [{"comment_text": "", "digests": {"md5": "5a8d0ade0e8fdd917ed7661bfaa99615", "sha256": "50484808508f37be5f6317bb352bcbb35b5ee191be7c2177a173a825afb12a78"}, "downloads": -1, "filename": "lookout_style-0.1.0rc4-py3-none-any.whl", "has_sig": false, "md5_digest": "5a8d0ade0e8fdd917ed7661bfaa99615", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2410046, "upload_time": "2019-01-29T20:31:52", "upload_time_iso_8601": "2019-01-29T20:31:52.093566Z", "url": "https://files.pythonhosted.org/packages/a9/77/c670396b84dc6251592e0804cae7fd4d8f444543101c47bf9a6f6be116f6/lookout_style-0.1.0rc4-py3-none-any.whl", "yanked": false}], "0.1.0rc5": [{"comment_text": "", "digests": {"md5": "88e96d9bbf888698db08c4f245dd7025", "sha256": "81b340010c811d365dbb82fe73b03fedb0c2ec8d01128e7c7dd4b9979558c91a"}, "downloads": -1, "filename": "lookout_style-0.1.0rc5-py3-none-any.whl", "has_sig": false, "md5_digest": "88e96d9bbf888698db08c4f245dd7025", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2409457, "upload_time": "2019-01-30T11:38:49", "upload_time_iso_8601": "2019-01-30T11:38:49.185984Z", "url": "https://files.pythonhosted.org/packages/1c/c8/bd8a50a25e3778007f120ccf30f98e193f5b285048c0a0e8737c197c0c39/lookout_style-0.1.0rc5-py3-none-any.whl", "yanked": false}], "0.1.0rc6": [{"comment_text": "", "digests": {"md5": "4e59e55a0e52a9ba4981fcc85349b66b", "sha256": "5ac06f1eb66a42255236b9655bdceec12e2bea60ad5b9334e92de758adfc55e1"}, "downloads": -1, "filename": "lookout_style-0.1.0rc6-py3-none-any.whl", "has_sig": false, "md5_digest": "4e59e55a0e52a9ba4981fcc85349b66b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2410019, "upload_time": "2019-01-31T11:36:22", "upload_time_iso_8601": "2019-01-31T11:36:22.975770Z", "url": "https://files.pythonhosted.org/packages/e9/3f/4090bc08d8962156c6280224b390f31818f1a5f2d8febfa7c43366c8b1d4/lookout_style-0.1.0rc6-py3-none-any.whl", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "f5a7b977d70a914754c7f450fb45647c", "sha256": "ef5c26cee6ab77a2d8f8708f5a1a8c0d9a7ea9de58437b93ec61e2635e4c143e"}, "downloads": -1, "filename": "lookout_style-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "f5a7b977d70a914754c7f450fb45647c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2427833, "upload_time": "2019-02-25T11:53:02", "upload_time_iso_8601": "2019-02-25T11:53:02.846991Z", "url": "https://files.pythonhosted.org/packages/bd/70/b16afd83475f88bbda99f14986e78842eff5f5516c8cf1615630c00989fb/lookout_style-0.1.1-py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "af6324b750b4613f2b9d9458325817eb", "sha256": "e9b4ec3afd473d828dfa18bbafa2996f92e06b4268759d68073efd56c07d3708"}, "downloads": -1, "filename": "lookout_style-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "af6324b750b4613f2b9d9458325817eb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2460600, "upload_time": "2019-04-16T12:11:16", "upload_time_iso_8601": "2019-04-16T12:11:16.604068Z", "url": "https://files.pythonhosted.org/packages/56/26/ea0d906556fb01d04288530c2d20ef5b5861245ff63641166f065a01510d/lookout_style-0.2.0-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "af6324b750b4613f2b9d9458325817eb", "sha256": "e9b4ec3afd473d828dfa18bbafa2996f92e06b4268759d68073efd56c07d3708"}, "downloads": -1, "filename": "lookout_style-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "af6324b750b4613f2b9d9458325817eb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2460600, "upload_time": "2019-04-16T12:11:16", "upload_time_iso_8601": "2019-04-16T12:11:16.604068Z", "url": "https://files.pythonhosted.org/packages/56/26/ea0d906556fb01d04288530c2d20ef5b5861245ff63641166f065a01510d/lookout_style-0.2.0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:43:54 2020"}