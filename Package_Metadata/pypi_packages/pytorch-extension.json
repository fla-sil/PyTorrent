{"info": {"author": "Artit Wangperawong", "author_email": "artitw@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Introduction\n\nThis repository holds NVIDIA-maintained utilities to streamline\nmixed precision and distributed training in Pytorch.\nSome of the code here will be included in upstream Pytorch eventually.\nThe intention of Apex is to make up-to-date utilities available to\nusers as quickly as possible.\n\n## Full API Documentation: [https://nvidia.github.io/apex](https://nvidia.github.io/apex)\n\n## [GTC 2019](https://github.com/mcarilli/mixed_precision_references/tree/master/GTC_2019) and [Pytorch DevCon 2019](https://github.com/mcarilli/mixed_precision_references/tree/master/Pytorch_Devcon_2019) Slides\n\n# Contents\n\n## 1. Amp:  Automatic Mixed Precision\n\n`apex.amp` is a tool to enable mixed precision training by changing only 3 lines of your script.\nUsers can easily experiment with different pure and mixed precision training modes by supplying\ndifferent flags to `amp.initialize`.\n\n[Webinar introducing Amp](https://info.nvidia.com/webinar-mixed-precision-with-pytorch-reg-page.html)\n(The flag `cast_batchnorm` has been renamed to `keep_batchnorm_fp32`).\n\n[API Documentation](https://nvidia.github.io/apex/amp.html)\n\n[Comprehensive Imagenet example](https://github.com/NVIDIA/apex/tree/master/examples/imagenet)\n\n[DCGAN example coming soon...](https://github.com/NVIDIA/apex/tree/master/examples/dcgan)\n\n[Moving to the new Amp API](https://nvidia.github.io/apex/amp.html#transition-guide-for-old-api-users) (for users of the deprecated \"Amp\" and \"FP16_Optimizer\" APIs)\n\n## 2. Distributed Training\n\n`apex.parallel.DistributedDataParallel` is a module wrapper, similar to\n`torch.nn.parallel.DistributedDataParallel`.  It enables convenient multiprocess distributed training,\noptimized for NVIDIA's NCCL communication library.\n\n[API Documentation](https://nvidia.github.io/apex/parallel.html)\n\n[Python Source](https://github.com/NVIDIA/apex/tree/master/apex/parallel)\n\n[Example/Walkthrough](https://github.com/NVIDIA/apex/tree/master/examples/simple/distributed)\n\nThe [Imagenet example](https://github.com/NVIDIA/apex/tree/master/examples/imagenet)\nshows use of `apex.parallel.DistributedDataParallel` along with `apex.amp`.\n\n### Synchronized Batch Normalization\n\n`apex.parallel.SyncBatchNorm` extends `torch.nn.modules.batchnorm._BatchNorm` to\nsupport synchronized BN.\nIt allreduces stats across processes during multiprocess (DistributedDataParallel) training.\nSynchronous BN has been used in cases where only a small\nlocal minibatch can fit on each GPU.\nAllreduced stats increase the effective batch size for the BN layer to the\nglobal batch size across all processes (which, technically, is the correct\nformulation).\nSynchronous BN has been observed to improve converged accuracy in some of our research models.\n\n### Checkpointing\n\nTo properly save and load your `amp` training, we introduce the `amp.state_dict()`, which contains all `loss_scalers` and their corresponding unskipped steps,\nas well as `amp.load_state_dict()` to restore these attributes.\n\nIn order to get bitwise accuracy, we recommend the following workflow:\n```python\n# Initialization\nopt_level = 'O1'\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n\n# Train your model\n...\nwith amp.scale_loss(loss, optimizer) as scaled_loss:\n    scaled_loss.backward()\n...\n\n# Save checkpoint\ncheckpoint = {\n    'model': model.state_dict(),\n    'optimizer': optimizer.state_dict(),\n    'amp': amp.state_dict()\n}\ntorch.save(checkpoint, 'amp_checkpoint.pt')\n...\n\n# Restore\nmodel = ...\noptimizer = ...\ncheckpoint = torch.load('amp_checkpoint.pt')\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\nmodel.load_state_dict(checkpoint['model'])\noptimizer.load_state_dict(checkpoint['optimizer'])\namp.load_state_dict(checkpoint['amp'])\n\n# Continue training\n...\n```\n\nNote that we recommend restoring the model using the same `opt_level`. Also note that we recommend calling the `load_state_dict` methods after `amp.initialize`.\n\n# Requirements\n\nPython 3\n\nCUDA 9 or newer\n\nPyTorch 0.4 or newer.  The CUDA and C++ extensions require pytorch 1.0 or newer.\n\nWe recommend the latest stable release, obtainable from\n[https://pytorch.org/](https://pytorch.org/).  We also test against the latest master branch, obtainable from [https://github.com/pytorch/pytorch](https://github.com/pytorch/pytorch).\n\nIt's often convenient to use Apex in Docker containers.  Compatible options include:\n* [NVIDIA Pytorch containers from NGC](https://ngc.nvidia.com/catalog/containers/nvidia%2Fpytorch), which come with Apex preinstalled.  To use the latest Amp API, you may need to `pip uninstall apex` then reinstall Apex using the **Quick Start** commands below.\n* [official Pytorch -devel Dockerfiles](https://hub.docker.com/r/pytorch/pytorch/tags), e.g. `docker pull pytorch/pytorch:nightly-devel-cuda10.0-cudnn7`, in which you can install Apex using the **Quick Start** commands.\n\nSee the [Docker example folder](https://github.com/NVIDIA/apex/tree/master/examples/docker) for details.\n\n# Quick Start\n\n### Linux\n\nFor performance and full functionality, we recommend installing Apex with\nCUDA and C++ extensions via\n```\n$ git clone https://github.com/NVIDIA/apex\n$ cd apex\n$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n\nApex also supports a Python-only build (required with Pytorch 0.4) via\n```\n$ pip install -v --no-cache-dir ./\n```\nA Python-only build omits:\n- Fused kernels required to use `apex.optimizers.FusedAdam`.\n- Fused kernels required to use `apex.normalization.FusedLayerNorm`.\n- Fused kernels that improve the performance and numerical stability of `apex.parallel.SyncBatchNorm`.\n- Fused kernels that improve the performance of `apex.parallel.DistributedDataParallel` and `apex.amp`.\n`DistributedDataParallel`, `amp`, and `SyncBatchNorm` will still be usable, but they may be slower.\n\nTo enable PyProf support, you need to install the packages required by PyProf. To do so, add the \"--pyprof\" option at installation time:\n```\n$ pip install -v --no-cache-dir --global-option=\"--pyprof\" --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n\n### Windows support\nWindows support is experimental, and Linux is recommended.  `pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .` may work if you were able to build Pytorch from source\non your system.  `pip install -v --no-cache-dir .` (without CUDA/C++ extensions) is more likely to work.  If you installed Pytorch in a Conda environment, make sure to install Apex in that same environment.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/artitw/apex", "keywords": "artificial intelligence pytorch data science deep machine learning", "license": "", "maintainer": "", "maintainer_email": "", "name": "pytorch-extension", "package_url": "https://pypi.org/project/pytorch-extension/", "platform": "", "project_url": "https://pypi.org/project/pytorch-extension/", "project_urls": {"Homepage": "https://github.com/artitw/apex"}, "release_url": "https://pypi.org/project/pytorch-extension/0.1/", "requires_dist": null, "requires_python": "", "summary": "Package for A PyTorch Extension by NVIDIA", "version": "0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Introduction</h1>\n<p>This repository holds NVIDIA-maintained utilities to streamline\nmixed precision and distributed training in Pytorch.\nSome of the code here will be included in upstream Pytorch eventually.\nThe intention of Apex is to make up-to-date utilities available to\nusers as quickly as possible.</p>\n<h2>Full API Documentation: <a href=\"https://nvidia.github.io/apex\" rel=\"nofollow\">https://nvidia.github.io/apex</a></h2>\n<h2><a href=\"https://github.com/mcarilli/mixed_precision_references/tree/master/GTC_2019\" rel=\"nofollow\">GTC 2019</a> and <a href=\"https://github.com/mcarilli/mixed_precision_references/tree/master/Pytorch_Devcon_2019\" rel=\"nofollow\">Pytorch DevCon 2019</a> Slides</h2>\n<h1>Contents</h1>\n<h2>1. Amp:  Automatic Mixed Precision</h2>\n<p><code>apex.amp</code> is a tool to enable mixed precision training by changing only 3 lines of your script.\nUsers can easily experiment with different pure and mixed precision training modes by supplying\ndifferent flags to <code>amp.initialize</code>.</p>\n<p><a href=\"https://info.nvidia.com/webinar-mixed-precision-with-pytorch-reg-page.html\" rel=\"nofollow\">Webinar introducing Amp</a>\n(The flag <code>cast_batchnorm</code> has been renamed to <code>keep_batchnorm_fp32</code>).</p>\n<p><a href=\"https://nvidia.github.io/apex/amp.html\" rel=\"nofollow\">API Documentation</a></p>\n<p><a href=\"https://github.com/NVIDIA/apex/tree/master/examples/imagenet\" rel=\"nofollow\">Comprehensive Imagenet example</a></p>\n<p><a href=\"https://github.com/NVIDIA/apex/tree/master/examples/dcgan\" rel=\"nofollow\">DCGAN example coming soon...</a></p>\n<p><a href=\"https://nvidia.github.io/apex/amp.html#transition-guide-for-old-api-users\" rel=\"nofollow\">Moving to the new Amp API</a> (for users of the deprecated \"Amp\" and \"FP16_Optimizer\" APIs)</p>\n<h2>2. Distributed Training</h2>\n<p><code>apex.parallel.DistributedDataParallel</code> is a module wrapper, similar to\n<code>torch.nn.parallel.DistributedDataParallel</code>.  It enables convenient multiprocess distributed training,\noptimized for NVIDIA's NCCL communication library.</p>\n<p><a href=\"https://nvidia.github.io/apex/parallel.html\" rel=\"nofollow\">API Documentation</a></p>\n<p><a href=\"https://github.com/NVIDIA/apex/tree/master/apex/parallel\" rel=\"nofollow\">Python Source</a></p>\n<p><a href=\"https://github.com/NVIDIA/apex/tree/master/examples/simple/distributed\" rel=\"nofollow\">Example/Walkthrough</a></p>\n<p>The <a href=\"https://github.com/NVIDIA/apex/tree/master/examples/imagenet\" rel=\"nofollow\">Imagenet example</a>\nshows use of <code>apex.parallel.DistributedDataParallel</code> along with <code>apex.amp</code>.</p>\n<h3>Synchronized Batch Normalization</h3>\n<p><code>apex.parallel.SyncBatchNorm</code> extends <code>torch.nn.modules.batchnorm._BatchNorm</code> to\nsupport synchronized BN.\nIt allreduces stats across processes during multiprocess (DistributedDataParallel) training.\nSynchronous BN has been used in cases where only a small\nlocal minibatch can fit on each GPU.\nAllreduced stats increase the effective batch size for the BN layer to the\nglobal batch size across all processes (which, technically, is the correct\nformulation).\nSynchronous BN has been observed to improve converged accuracy in some of our research models.</p>\n<h3>Checkpointing</h3>\n<p>To properly save and load your <code>amp</code> training, we introduce the <code>amp.state_dict()</code>, which contains all <code>loss_scalers</code> and their corresponding unskipped steps,\nas well as <code>amp.load_state_dict()</code> to restore these attributes.</p>\n<p>In order to get bitwise accuracy, we recommend the following workflow:</p>\n<pre><span class=\"c1\"># Initialization</span>\n<span class=\"n\">opt_level</span> <span class=\"o\">=</span> <span class=\"s1\">'O1'</span>\n<span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">amp</span><span class=\"o\">.</span><span class=\"n\">initialize</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">opt_level</span><span class=\"o\">=</span><span class=\"n\">opt_level</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Train your model</span>\n<span class=\"o\">...</span>\n<span class=\"k\">with</span> <span class=\"n\">amp</span><span class=\"o\">.</span><span class=\"n\">scale_loss</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">scaled_loss</span><span class=\"p\">:</span>\n    <span class=\"n\">scaled_loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n<span class=\"o\">...</span>\n\n<span class=\"c1\"># Save checkpoint</span>\n<span class=\"n\">checkpoint</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'model'</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span>\n    <span class=\"s1\">'optimizer'</span><span class=\"p\">:</span> <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span>\n    <span class=\"s1\">'amp'</span><span class=\"p\">:</span> <span class=\"n\">amp</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">()</span>\n<span class=\"p\">}</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">checkpoint</span><span class=\"p\">,</span> <span class=\"s1\">'amp_checkpoint.pt'</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n\n<span class=\"c1\"># Restore</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n<span class=\"n\">checkpoint</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'amp_checkpoint.pt'</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">amp</span><span class=\"o\">.</span><span class=\"n\">initialize</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">opt_level</span><span class=\"o\">=</span><span class=\"n\">opt_level</span><span class=\"p\">)</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">checkpoint</span><span class=\"p\">[</span><span class=\"s1\">'model'</span><span class=\"p\">])</span>\n<span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">checkpoint</span><span class=\"p\">[</span><span class=\"s1\">'optimizer'</span><span class=\"p\">])</span>\n<span class=\"n\">amp</span><span class=\"o\">.</span><span class=\"n\">load_state_dict</span><span class=\"p\">(</span><span class=\"n\">checkpoint</span><span class=\"p\">[</span><span class=\"s1\">'amp'</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Continue training</span>\n<span class=\"o\">...</span>\n</pre>\n<p>Note that we recommend restoring the model using the same <code>opt_level</code>. Also note that we recommend calling the <code>load_state_dict</code> methods after <code>amp.initialize</code>.</p>\n<h1>Requirements</h1>\n<p>Python 3</p>\n<p>CUDA 9 or newer</p>\n<p>PyTorch 0.4 or newer.  The CUDA and C++ extensions require pytorch 1.0 or newer.</p>\n<p>We recommend the latest stable release, obtainable from\n<a href=\"https://pytorch.org/\" rel=\"nofollow\">https://pytorch.org/</a>.  We also test against the latest master branch, obtainable from <a href=\"https://github.com/pytorch/pytorch\" rel=\"nofollow\">https://github.com/pytorch/pytorch</a>.</p>\n<p>It's often convenient to use Apex in Docker containers.  Compatible options include:</p>\n<ul>\n<li><a href=\"https://ngc.nvidia.com/catalog/containers/nvidia%2Fpytorch\" rel=\"nofollow\">NVIDIA Pytorch containers from NGC</a>, which come with Apex preinstalled.  To use the latest Amp API, you may need to <code>pip uninstall apex</code> then reinstall Apex using the <strong>Quick Start</strong> commands below.</li>\n<li><a href=\"https://hub.docker.com/r/pytorch/pytorch/tags\" rel=\"nofollow\">official Pytorch -devel Dockerfiles</a>, e.g. <code>docker pull pytorch/pytorch:nightly-devel-cuda10.0-cudnn7</code>, in which you can install Apex using the <strong>Quick Start</strong> commands.</li>\n</ul>\n<p>See the <a href=\"https://github.com/NVIDIA/apex/tree/master/examples/docker\" rel=\"nofollow\">Docker example folder</a> for details.</p>\n<h1>Quick Start</h1>\n<h3>Linux</h3>\n<p>For performance and full functionality, we recommend installing Apex with\nCUDA and C++ extensions via</p>\n<pre><code>$ git clone https://github.com/NVIDIA/apex\n$ cd apex\n$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n</code></pre>\n<p>Apex also supports a Python-only build (required with Pytorch 0.4) via</p>\n<pre><code>$ pip install -v --no-cache-dir ./\n</code></pre>\n<p>A Python-only build omits:</p>\n<ul>\n<li>Fused kernels required to use <code>apex.optimizers.FusedAdam</code>.</li>\n<li>Fused kernels required to use <code>apex.normalization.FusedLayerNorm</code>.</li>\n<li>Fused kernels that improve the performance and numerical stability of <code>apex.parallel.SyncBatchNorm</code>.</li>\n<li>Fused kernels that improve the performance of <code>apex.parallel.DistributedDataParallel</code> and <code>apex.amp</code>.\n<code>DistributedDataParallel</code>, <code>amp</code>, and <code>SyncBatchNorm</code> will still be usable, but they may be slower.</li>\n</ul>\n<p>To enable PyProf support, you need to install the packages required by PyProf. To do so, add the \"--pyprof\" option at installation time:</p>\n<pre><code>$ pip install -v --no-cache-dir --global-option=\"--pyprof\" --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n</code></pre>\n<h3>Windows support</h3>\n<p>Windows support is experimental, and Linux is recommended.  <code>pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .</code> may work if you were able to build Pytorch from source\non your system.  <code>pip install -v --no-cache-dir .</code> (without CUDA/C++ extensions) is more likely to work.  If you installed Pytorch in a Conda environment, make sure to install Apex in that same environment.</p>\n\n          </div>"}, "last_serial": 6650305, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "876bb343e87d74c877846f7fe549fb76", "sha256": "006077f47c166a6b042102c30e71e7b53d5f322f1fce7861a1d7c6859f898594"}, "downloads": -1, "filename": "pytorch_extension-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "876bb343e87d74c877846f7fe549fb76", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 156103, "upload_time": "2020-02-18T01:46:28", "upload_time_iso_8601": "2020-02-18T01:46:28.796272Z", "url": "https://files.pythonhosted.org/packages/1d/74/2e9110532020880d9ba06085c4b9a163fa8d8993d964bf61aeb217b7896b/pytorch_extension-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8c28655650c56f952f86af76963dc156", "sha256": "a0c231ff62097ac9fab0b0fda2ceb4ca03cad7b93d9b399d48c33995faaf946a"}, "downloads": -1, "filename": "pytorch-extension-0.1.tar.gz", "has_sig": false, "md5_digest": "8c28655650c56f952f86af76963dc156", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 437038, "upload_time": "2020-02-18T01:46:31", "upload_time_iso_8601": "2020-02-18T01:46:31.238788Z", "url": "https://files.pythonhosted.org/packages/fc/82/55f5774e1822dcd92a171389fd9ea9e532c4e44dcc0af00d463ed62537d3/pytorch-extension-0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "876bb343e87d74c877846f7fe549fb76", "sha256": "006077f47c166a6b042102c30e71e7b53d5f322f1fce7861a1d7c6859f898594"}, "downloads": -1, "filename": "pytorch_extension-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "876bb343e87d74c877846f7fe549fb76", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 156103, "upload_time": "2020-02-18T01:46:28", "upload_time_iso_8601": "2020-02-18T01:46:28.796272Z", "url": "https://files.pythonhosted.org/packages/1d/74/2e9110532020880d9ba06085c4b9a163fa8d8993d964bf61aeb217b7896b/pytorch_extension-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8c28655650c56f952f86af76963dc156", "sha256": "a0c231ff62097ac9fab0b0fda2ceb4ca03cad7b93d9b399d48c33995faaf946a"}, "downloads": -1, "filename": "pytorch-extension-0.1.tar.gz", "has_sig": false, "md5_digest": "8c28655650c56f952f86af76963dc156", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 437038, "upload_time": "2020-02-18T01:46:31", "upload_time_iso_8601": "2020-02-18T01:46:31.238788Z", "url": "https://files.pythonhosted.org/packages/fc/82/55f5774e1822dcd92a171389fd9ea9e532c4e44dcc0af00d463ed62537d3/pytorch-extension-0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:13:56 2020"}