{"info": {"author": "Abubakar Abid", "author_email": "a12d@stanford.edu", "bugtrack_url": null, "classifiers": [], "description": "shuffled-stats\r\n===================\r\nA python library for performing inference on datasets with shuffled / unordered labels. \r\n\r\nThis library includes functions for generating datasets and performing linear regression on datasets whose labels (the \"y\") are shuffled with respect to the input features (the \"x\"). In other words, you should use this library to perform linear regression when you don't know which measurement comes from which data point.\r\n\r\nApplications include: experiments done on an entire population of particles at once (`flow cytometry <https://en.wikipedia.org/wiki/Flow_cytometry>`_), datasets shuffled to protect privacy (`medical records <https://experts.illinois.edu/en/publications/protection-of-health-information-in-data-mining>`_), measurements where the ordering is unclear (`signaling with identical tokens <http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620545>`_)\r\n\r\nInstallation\r\n--------------------\r\n\r\n.. code-block:: \r\n\r\n\t$ pip install shuffled_stats\r\n\r\n\r\nExamples (without noise)\r\n-------------------------------\r\nLet's start with some simple examples. We construct some random 2-dimensional input data, and the corresponding labels. We then apply shuffled regression using the :code:`shuffled_stats.linregress` function.\r\n\r\n.. code-block:: python\r\n\r\n\timport numpy as np, shuffled_stats\r\n\r\n\tnp.random.seed(1)\r\n\r\n\tx = np.random.normal(1, 1, (100,2)) #input features\r\n\ty = 3*x[:,0] - 7*x[:,1] #labels\r\n\r\n\tnp.random.shuffle(y) #in-place shuffling of the labels\r\n\r\n\tshuffled_stats.linregress(x,y) #performs shuffled linear regression\r\n\t>>> array([3., -7.])\r\n\r\n\r\nThe original weights, [3, -7], are recovered exactly. \r\n\r\nWe can do another example with defined data points:\r\n\r\n=====  =====  =======\r\nx1      x2    y\r\n=====  =====  =======\r\n1      2      3\r\n2      5      7\r\n-1     -2     -3\r\n5      5      10\r\n2      10      12\r\n=====  =====  =======\r\n\r\nStandard linear regression would clearly reveal that 1*x1 + 1*x2 = y. Let's see what shuffled linear regression reveals with a permuted version of the labels:\r\n\r\n.. code-block:: python\r\n\r\n\tx = np.array([[1,2],[2,5],[-1, -2],[5,5],[2,10]])\r\n\ty = np.array([-3, 10, 7, 3, 12])\r\n\r\n\tshuffled_stats.linregress(x,y) #performs shuffled linear regression\r\n\t>>> array([1., 1.])\r\n\r\n\r\nAgain, the weights are recovered exactly.\r\n\r\nExamples (with noise)\r\n------------------------\r\n\r\n.. code-block:: python\r\n\t\r\n\tnp.random.seed(1) #for reproducibility\r\n\tx = np.random.normal(1, 1, (100,3)) #input features\r\n\tx[:,0] = 1 #making a bias/intercept column \r\n\ty = 4 + 2*x[:,1] - 3*x[:,2] #labels\r\n\r\n\ty = y + np.random.normal(0, .3, (100)) #adding Gaussian noise\r\n\r\n\tw = shuffled_stats.linregress(x,y)\r\n\tnp.round(w,2)\r\n\t>>> array([3.80, 2.09, -2.91])\r\n\r\nWe see that the recovered weights approximate the original weights (4, 2, -3), including the bias term.\r\n\r\nThe library includes a function, :code:`shuffled_stats.generate_dataset`  to quickly generating datasets for testing. Here's an example:\r\n\r\n.. code-block:: python\r\n\t\r\n\tnp.random.seed(1) #for reproducibility\r\n\r\n\tx, y, w0 = shuffled_stats.generate_dataset(n=100, dim=3, bias=True, noise=0.3, mean=2)\r\n\tw = shuffled_stats.linregress(x,y)\r\n\r\n\tprint(np.round(w0,2))\r\n\t>>> array([2.07, -1.47, -0.83])\t\r\n\tprint(np.round(w,2))\r\n\t>>> array([1.79, 1.55, -0.63])\r\n\r\nThe weights are approximately recovered. We can quantify the relative error by using :code:`shuffled_stats.error_in_weights`.\r\n\r\n.. code-block:: python\r\n\t\r\n\tshuffled_stats.error_in_weights(w0,w)\r\n\t>>> 0.13010948373615697\t#13% error\r\n\r\nCan we improve performance by running three separate \"trials\" or \"replications\" of this experiment, each consisting of 100 unordered labels (within each trial, the ordering of the labels is unknown, but labels within a trial must correspond to data points from that trial)? We can test this easily with our library:\r\n\r\n.. code-block:: python\r\n\t\r\n\tnp.random.seed(1) #for reproducibility\r\n\tx, y, w0, groups = shuffled_stats.generate_dataset(n=300, dim=3, weights=[2.07, -1.47, -0.83], bias=True, noise=0.3, mean=2, n_groups=3) #fix weights to the same values as before\r\n\tw = shuffled_stats.linregress(x,y, groups=groups)\r\n\r\n\tprint(np.round(w,2))\r\n\t>>> array([2.09, -1.48, -0.83])\r\n\tshuffled_stats.error_in_weights(w0,w)\r\n\t>>> 0.0099665304764283077 #<1% error\r\n\r\nThe weights are a lot closer this time!\r\n\r\nThe library includes several different estimators (see paper for details). We can choose different estimators to compare results:\r\n\r\n.. code-block:: python\r\n\t\r\n\tnp.random.seed(1) #for reproducibility\r\n\tx, y, w0 = shuffled_stats.generate_dataset(n=100, dim=3, weights=[1,1,1], noise=0.3, mean=1) #the true weights are [1,1]\r\n\tw = shuffled_stats.linregress(x,y, estimator='SM')\r\n\tprint(np.round(w,2))\r\n\t>>> [0.98  0.98  1.03]\r\n\tw = shuffled_stats.linregress(x,y, estimator='LS')\r\n\tprint(np.round(w,2))\r\n\t>>> [0.99  0.92  1.09]\r\n\tw = shuffled_stats.linregress(x,y, estimator='EMD')\r\n\tprint(np.round(w,2))\r\n\t>>> [0.99  0.93  1.09]\r\n\r\n\r\nExamples (on datasets)\r\n---------------------------------\r\n\r\nFinally, we include methods to load datasets from .csv files (:code:`shuffled_stats.load_dataset_in_clusters`) so that the performance of shuffled regression can be compared to that of, for example, ordinary least-squares, on real-world data. Here's an example that uses the :code:`accidents.csv` dataset, from the UCI repository.\r\n\r\n.. code-block:: python\r\n\t\r\n\tfrom sklearn.linear_model import LinearRegression\r\n\t\r\n\tnp.random.seed(1) #for reproducibility\r\n\r\n\tx, y, groups = shuffled_stats.load_dataset_in_clusters('accidents.csv', normalize=True, n_clusters = 2)\r\n\r\n\tlr = LinearRegression(fit_intercept=False) #fit_intercept is false because x already includes a bias column\r\n\t\r\n\tprint(lr.fit(x,y).coef_)\r\n\t>>> [1.02859104,  0.03967381]\r\n\r\n\tprint(shuffled_stats.linregress(x,y))\r\n\t>>> [ 1.12348216  0.02539006]\r\n\r\nNot bad, if I do say so myself! Feel free to explore shuffled regression and reach out to me if you have any questions!", "description_content_type": null, "docs_url": null, "download_url": "https://github.com/abidlabs/shuffled-stats/archive/1.0.5.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/abidlabs/shuffled-stats", "keywords": "statistics,shuffled,permutation,regression", "license": "UNKNOWN", "maintainer": null, "maintainer_email": null, "name": "shuffled-stats", "package_url": "https://pypi.org/project/shuffled-stats/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/shuffled-stats/", "project_urls": {"Download": "https://github.com/abidlabs/shuffled-stats/archive/1.0.5.tar.gz", "Homepage": "https://github.com/abidlabs/shuffled-stats"}, "release_url": "https://pypi.org/project/shuffled-stats/1.0.6/", "requires_dist": null, "requires_python": null, "summary": "Python library for performing inference on datasets with shuffled labels", "version": "1.0.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A python library for performing inference on datasets with shuffled / unordered labels.</p>\n<p>This library includes functions for generating datasets and performing linear regression on datasets whose labels (the \u201cy\u201d) are shuffled with respect to the input features (the \u201cx\u201d). In other words, you should use this library to perform linear regression when you don\u2019t know which measurement comes from which data point.</p>\n<p>Applications include: experiments done on an entire population of particles at once (<a href=\"https://en.wikipedia.org/wiki/Flow_cytometry\" rel=\"nofollow\">flow cytometry</a>), datasets shuffled to protect privacy (<a href=\"https://experts.illinois.edu/en/publications/protection-of-health-information-in-data-mining\" rel=\"nofollow\">medical records</a>), measurements where the ordering is unclear (<a href=\"http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620545\" rel=\"nofollow\">signaling with identical tokens</a>)</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>$ pip install shuffled_stats\n</pre>\n</div>\n<div id=\"examples-without-noise\">\n<h2>Examples (without noise)</h2>\n<p>Let\u2019s start with some simple examples. We construct some random 2-dimensional input data, and the corresponding labels. We then apply shuffled regression using the <code>shuffled_stats.linregress</code> function.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span><span class=\"o\">,</span> <span class=\"nn\">shuffled_stats</span>\n\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span> <span class=\"c1\">#input features</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"mi\">3</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"mi\">7</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"c1\">#labels</span>\n\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"c1\">#in-place shuffling of the labels</span>\n\n<span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"c1\">#performs shuffled linear regression</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">3.</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">7.</span><span class=\"p\">])</span>\n</pre>\n<p>The original weights, [3, -7], are recovered exactly.</p>\n<p>We can do another example with defined data points:</p>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>x1</th>\n<th>x2</th>\n<th>y</th>\n</tr>\n</thead>\n<tbody>\n<tr><td>1</td>\n<td>2</td>\n<td>3</td>\n</tr>\n<tr><td>2</td>\n<td>5</td>\n<td>7</td>\n</tr>\n<tr><td>-1</td>\n<td>-2</td>\n<td>-3</td>\n</tr>\n<tr><td>5</td>\n<td>5</td>\n<td>10</td>\n</tr>\n<tr><td>2</td>\n<td>10</td>\n<td>12</td>\n</tr>\n</tbody>\n</table>\n<p>Standard linear regression would clearly reveal that 1*x1 + 1*x2 = y. Let\u2019s see what shuffled linear regression reveals with a permuted version of the labels:</p>\n<pre><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">],[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">],[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">],[</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">],[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">10</span><span class=\"p\">]])</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">([</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">7</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">12</span><span class=\"p\">])</span>\n\n<span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"c1\">#performs shuffled linear regression</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"mf\">1.</span><span class=\"p\">])</span>\n</pre>\n<p>Again, the weights are recovered exactly.</p>\n</div>\n<div id=\"examples-with-noise\">\n<h2>Examples (with noise)</h2>\n<pre><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">#for reproducibility</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">))</span> <span class=\"c1\">#input features</span>\n<span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span> <span class=\"c1\">#making a bias/intercept column</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"mi\">3</span><span class=\"o\">*</span><span class=\"n\">x</span><span class=\"p\">[:,</span><span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"c1\">#labels</span>\n\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"o\">.</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">))</span> <span class=\"c1\">#adding Gaussian noise</span>\n\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">3.80</span><span class=\"p\">,</span> <span class=\"mf\">2.09</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">2.91</span><span class=\"p\">])</span>\n</pre>\n<p>We see that the recovered weights approximate the original weights (4, 2, -3), including the bias term.</p>\n<p>The library includes a function, <code>shuffled_stats.generate_dataset</code>  to quickly generating datasets for testing. Here\u2019s an example:</p>\n<pre><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">#for reproducibility</span>\n\n<span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">w0</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">generate_dataset</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">noise</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"n\">mean</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w0</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">2.07</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.47</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.83</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">1.79</span><span class=\"p\">,</span> <span class=\"mf\">1.55</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.63</span><span class=\"p\">])</span>\n</pre>\n<p>The weights are approximately recovered. We can quantify the relative error by using <code>shuffled_stats.error_in_weights</code>.</p>\n<pre><span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">error_in_weights</span><span class=\"p\">(</span><span class=\"n\">w0</span><span class=\"p\">,</span><span class=\"n\">w</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"mf\">0.13010948373615697</span> <span class=\"c1\">#13% error</span>\n</pre>\n<p>Can we improve performance by running three separate \u201ctrials\u201d or \u201creplications\u201d of this experiment, each consisting of 100 unordered labels (within each trial, the ordering of the labels is unknown, but labels within a trial must correspond to data points from that trial)? We can test this easily with our library:</p>\n<pre><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">#for reproducibility</span>\n<span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">w0</span><span class=\"p\">,</span> <span class=\"n\">groups</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">generate_dataset</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mf\">2.07</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.47</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.83</span><span class=\"p\">],</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">noise</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"n\">mean</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">n_groups</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span> <span class=\"c1\">#fix weights to the same values as before</span>\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">groups</span><span class=\"o\">=</span><span class=\"n\">groups</span><span class=\"p\">)</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">2.09</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.48</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.83</span><span class=\"p\">])</span>\n<span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">error_in_weights</span><span class=\"p\">(</span><span class=\"n\">w0</span><span class=\"p\">,</span><span class=\"n\">w</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"mf\">0.0099665304764283077</span> <span class=\"c1\">#&lt;1% error</span>\n</pre>\n<p>The weights are a lot closer this time!</p>\n<p>The library includes several different estimators (see paper for details). We can choose different estimators to compare results:</p>\n<pre><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">#for reproducibility</span>\n<span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">w0</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">generate_dataset</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">noise</span><span class=\"o\">=</span><span class=\"mf\">0.3</span><span class=\"p\">,</span> <span class=\"n\">mean</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">#the true weights are [1,1]</span>\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">estimator</span><span class=\"o\">=</span><span class=\"s1\">'SM'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"mf\">0.98</span>  <span class=\"mf\">0.98</span>  <span class=\"mf\">1.03</span><span class=\"p\">]</span>\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">estimator</span><span class=\"o\">=</span><span class=\"s1\">'LS'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"mf\">0.99</span>  <span class=\"mf\">0.92</span>  <span class=\"mf\">1.09</span><span class=\"p\">]</span>\n<span class=\"n\">w</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">estimator</span><span class=\"o\">=</span><span class=\"s1\">'EMD'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">round</span><span class=\"p\">(</span><span class=\"n\">w</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"mf\">0.99</span>  <span class=\"mf\">0.93</span>  <span class=\"mf\">1.09</span><span class=\"p\">]</span>\n</pre>\n</div>\n<div id=\"examples-on-datasets\">\n<h2>Examples (on datasets)</h2>\n<p>Finally, we include methods to load datasets from .csv files (<code>shuffled_stats.load_dataset_in_clusters</code>) so that the performance of shuffled regression can be compared to that of, for example, ordinary least-squares, on real-world data. Here\u2019s an example that uses the <code>accidents.csv</code> dataset, from the UCI repository.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">sklearn.linear_model</span> <span class=\"kn\">import</span> <span class=\"n\">LinearRegression</span>\n\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"c1\">#for reproducibility</span>\n\n<span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">groups</span> <span class=\"o\">=</span> <span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">load_dataset_in_clusters</span><span class=\"p\">(</span><span class=\"s1\">'accidents.csv'</span><span class=\"p\">,</span> <span class=\"n\">normalize</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">n_clusters</span> <span class=\"o\">=</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n\n<span class=\"n\">lr</span> <span class=\"o\">=</span> <span class=\"n\">LinearRegression</span><span class=\"p\">(</span><span class=\"n\">fit_intercept</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span> <span class=\"c1\">#fit_intercept is false because x already includes a bias column</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">lr</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">coef_</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span><span class=\"mf\">1.02859104</span><span class=\"p\">,</span>  <span class=\"mf\">0.03967381</span><span class=\"p\">]</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">shuffled_stats</span><span class=\"o\">.</span><span class=\"n\">linregress</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">))</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"p\">[</span> <span class=\"mf\">1.12348216</span>  <span class=\"mf\">0.02539006</span><span class=\"p\">]</span>\n</pre>\n<p>Not bad, if I do say so myself! Feel free to explore shuffled regression and reach out to me if you have any questions!</p>\n</div>\n\n          </div>"}, "last_serial": 2807851, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "688b326da0f2dff2bd930e2f59a7a719", "sha256": "da658e3531f7d2e904f3c96b79ece3696331595959ebfa03817bc2f7d31b06b0"}, "downloads": -1, "filename": "shuffled_stats-1.0.0.zip", "has_sig": false, "md5_digest": "688b326da0f2dff2bd930e2f59a7a719", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 879, "upload_time": "2017-04-16T04:46:14", "upload_time_iso_8601": "2017-04-16T04:46:14.624610Z", "url": "https://files.pythonhosted.org/packages/c3/44/3998504654b67b2a2a58ac409597d2bfd639d32b1e44cf117809076ba2d9/shuffled_stats-1.0.0.zip", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "73a0f51c1d024c2992548e7483c88443", "sha256": "491f13d2886112096b56abd29fb91eb783c747adce6f74baf68f7c57ef6af9cf"}, "downloads": -1, "filename": "shuffled_stats-1.0.1.zip", "has_sig": false, "md5_digest": "73a0f51c1d024c2992548e7483c88443", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 879, "upload_time": "2017-04-16T05:16:48", "upload_time_iso_8601": "2017-04-16T05:16:48.776453Z", "url": "https://files.pythonhosted.org/packages/0e/20/c0acd0d9664afcef6892cffdf3dc37731891ab60a7c92333e4eb6dc674ca/shuffled_stats-1.0.1.zip", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "212e016d280fd2a6df2121e4e7df9ee4", "sha256": "b02feab6f57ff9acc53aa18d45916a0261199de39c6f62305d3fbff09e33b6bb"}, "downloads": -1, "filename": "shuffled_stats-1.0.3.zip", "has_sig": false, "md5_digest": "212e016d280fd2a6df2121e4e7df9ee4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9168, "upload_time": "2017-04-17T03:57:55", "upload_time_iso_8601": "2017-04-17T03:57:55.148361Z", "url": "https://files.pythonhosted.org/packages/a1/2a/caf378e47a4ea41485e62435e2feac230a649496192ef341c865e728dafc/shuffled_stats-1.0.3.zip", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "1af4bcb24d4961adea0dd43f8439f97f", "sha256": "64020cbdb2fec3624faf236444de0e28cae9b11305bdd23cb50fe374a5f55c9b"}, "downloads": -1, "filename": "shuffled_stats-1.0.4.zip", "has_sig": false, "md5_digest": "1af4bcb24d4961adea0dd43f8439f97f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9191, "upload_time": "2017-04-17T04:20:59", "upload_time_iso_8601": "2017-04-17T04:20:59.729222Z", "url": "https://files.pythonhosted.org/packages/9b/00/4c5d51055afac3417b4c48082f6e49b1e8bbd7e618c380097b9e4f602747/shuffled_stats-1.0.4.zip", "yanked": false}], "1.0.5": [{"comment_text": "", "digests": {"md5": "f0f87d050582f1f01b255ef6d38fab34", "sha256": "3dc7fb7415655acdebe2e4366c330e67c83748825c95eeab8f80f4e2f9d2d8a7"}, "downloads": -1, "filename": "shuffled_stats-1.0.5.zip", "has_sig": false, "md5_digest": "f0f87d050582f1f01b255ef6d38fab34", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9165, "upload_time": "2017-04-17T04:22:35", "upload_time_iso_8601": "2017-04-17T04:22:35.527690Z", "url": "https://files.pythonhosted.org/packages/37/47/095c507ca4f531a8e8254f94dc2077d767201141a82cc4774deb423c49c2/shuffled_stats-1.0.5.zip", "yanked": false}], "1.0.6": [{"comment_text": "", "digests": {"md5": "b590ff597b72e8e6ef48473e9c3949ab", "sha256": "269d98e63dd41004ec994fd92045c588a56bcbd0e7a97f7bd491017ff8bf3601"}, "downloads": -1, "filename": "shuffled_stats-1.0.6.zip", "has_sig": false, "md5_digest": "b590ff597b72e8e6ef48473e9c3949ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9166, "upload_time": "2017-04-17T04:26:00", "upload_time_iso_8601": "2017-04-17T04:26:00.233834Z", "url": "https://files.pythonhosted.org/packages/aa/7e/c929b871c45ef045bc96053315087812b15471c5827fcf2dc9db058fdb31/shuffled_stats-1.0.6.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b590ff597b72e8e6ef48473e9c3949ab", "sha256": "269d98e63dd41004ec994fd92045c588a56bcbd0e7a97f7bd491017ff8bf3601"}, "downloads": -1, "filename": "shuffled_stats-1.0.6.zip", "has_sig": false, "md5_digest": "b590ff597b72e8e6ef48473e9c3949ab", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9166, "upload_time": "2017-04-17T04:26:00", "upload_time_iso_8601": "2017-04-17T04:26:00.233834Z", "url": "https://files.pythonhosted.org/packages/aa/7e/c929b871c45ef045bc96053315087812b15471c5827fcf2dc9db058fdb31/shuffled_stats-1.0.6.zip", "yanked": false}], "timestamp": "Fri May  8 03:12:26 2020"}