{"info": {"author": "Tobias Gustafsson", "author_email": "tobias.l.gustafsson@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: Implementation :: CPython"], "description": "======\nQCache\n======\n\n.. image:: https://travis-ci.org/tobgu/qcache.png?branch=master\n    :target: https://travis-ci.org/tobgu/qcache\n\n.. image:: https://badge.fury.io/py/qcache.svg\n    :target: https://badge.fury.io/py/qcache\n\n.. image:: http://codecov.io/github/tobgu/qcache/coverage.svg?branch=master\n    :target: http://codecov.io/github/tobgu/qcache?branch=master\n\n.. _Memcached: http://memcached.org/\n\nQCache is a key-table cache, an in memory cache server with analytical query capabilities.\n\nWhile the more commonly known key-value caches (such as Memcached_) lets you fetch a value\nbased on a key QCache lets you run queries against a table based on a key.\n\n**********\nMotivation\n**********\nYou are working with table data that you want to run flexible queries against but do not want to\nload them into an SQL database or similar because of any of the following:\n\n- The operational cost and complexity of bringing in an SQL server\n- The tables do not have a homogeneous format\n- The data is short lived\n- Not all data available is ever used, you only want to use resources on demand\n- You want to treat queries as data and build them dynamically using data structures\n  that you are used to (dictionaries and lists or objects and arrays depending on your\n  language background)\n- Expensive JOINs are required to create the table.\n- ...\n\nOr, you are building server software and want to add the possibility for your clients to run\nqueries directly against the data without the need for dreadful translations between a REST\ninterface with some home grown filter language.\n\n\n.. _QCache-client: https://github.com/tobgu/qcache-client\n.. _Go-QCache-client: https://github.com/tobgu/go-qcache-client\n\n********\nFeatures\n********\n- Simple, single thread, single process, server.\n- Expressive JSON-based query language with format and features similar to SQL SELECT. Queries\n  are data that can easily be transformed or enriched.\n- Support for JSON or CSV input and output format\n- Performant queries on tables as large as 10 x 1000000 cells out of the box\n- No need for table definitions, tables are created dynamically based on the data inserted\n- Statistics about hit and miss count, query and insert performance and more available\n  through HTTP API\n- Scales linearly in query capacity with the number of servers. A python client library that\n  uses consistent hashing for key distribution among servers is available\n  here QCache-client_. There's also a basic Go client here Go-QCache-client_.\n  More clients are welcome!\n\n\n************\nRequirements\n************\nPython 2.7 (2.7.9+ if using TLS) for now\n\n\n************\nInstallation\n************\n.. code::\n\n   pip install qcache\n\n*******\nRunning\n*******\n.. code::\n\n   qcache\n\nThis will start qcache on the default port using the default cache size. To get help on available parameters:\n\n.. code::\n\n   qcache --help\n\n\n******\nDocker\n******\nYou can also get the latest version as a Docker image. This is probably the easiest way to try it out if you\nare running Linux or if you have Docker Machine installed.\n\n.. code::\n\n   docker run -p 9401:9401 tobgu/qcache\n\n\n*******\nLicense\n*******\nMIT licensed. See the bundled `LICENSE <https://github.com/tobgu/qcache/blob/master/LICENSE>`_ file for more details.\n\n**************\nQuery examples\n**************\nBelow are examples of the major features of the query language. A JSON object is used to\ndescribe the query. The query should be URL encoded and passed in using the 'q' GET-parameter.\n\nThe query language uses LISP-style prefix notation for simplicity. This makes it easy\nto parse and build queries dynamically since no rules for operator precedence\never need to be applied.\n\nLike so:\n`http://localhost:8888/qcache/datasets/<dataset_key>?q=<URL-encoded-query>`\n\nYou can also POST queries as JSON against:\n`http://localhost:8888/qcache/datasets/<dataset_key>/q/`\n\nThis is a good alternative to GET if your queries are too large to fit in the query string.\n\nSelect all\n==========\nAn empty object will return all rows in the table:\n\n.. code:: python\n\n   {}\n\nProjection\n==========\n.. code:: python\n\n   {\"select\": [\"foo\", \"bar\"]}\n\nNot specifying select is equivalent to SELECT * in SQL\n\nColumn aliasing\n---------------\n.. code:: python\n\n   {\"select\": [[\"=\", \"foo\", \"bar\"]]}\n\nThis will rename column bar to foo in the result.\n\nYou can also make more elaborate calculations in the aliasing expression.\n\n.. code:: python\n\n   {\"select\": [[\"=\", \"baz\", [\"+\", [\"*\", \"bar\", 2], \"foo\"]]]\n\nAs well as simple constant assignments.\n\n.. code:: python\n\n   {\"select\": [[\"=\", \"baz\", 55]]}\n\n\nFiltering\n=========\n\nComparison\n----------\n.. code:: python\n\n   {\"where\": [\"<\", \"foo\", 1]}\n\nThe following operators are supported:\n\n.. code::\n\n   ==, !=, <=, <, >, >=\n\nIn\n--\n.. code:: python\n\n   {\"where\": [\"in\", \"foo\", [1, 2]]}\n\n\nLike/ilike\n----------\nLike and ilike are used for string matching and work similar to LIKE in SQL. Like is case sensitive\nwhile ilike is case insensitive. In addition to string matching using % as wildcard like/ilike also\nsupports regexps.\n\n.. code:: python\n\n   {\"where\": [\"like\", \"foo\", \"'%bar%'\"]}\n\n\nBitwise operators\n-----------------\nThere are two operators for bitwise filtering on integers: `all_bits` and `any_bits`.\n\n* all_bits - evaluates to true if all bits in the supplied argument are set in value tested against.\n* any_bits - evaluates to true if any bits in the supplied argument are set in value tested agains.\n\n.. code:: python\n\n   {\"where\": [\"any_bits\", \"foo\", 31]}\n\n\nClauses\n-------\n.. code:: python\n\n   {\"where\": [\"&\", [\">\", \"foo\", 1],\n                   [\"==\", \"bar\", 2]]}\n\nThe following operators are supported:\n\n.. code::\n\n   &, |\n\n\nNegation\n--------\n.. code:: python\n\n   {\"where\": [\"!\", [\"==\", \"foo\",  1]]}\n\n\nOrdering\n========\n\nAscending\n\n.. code:: python\n\n   {\"order_by\": [\"foo\"]}\n\n\nDescending\n\n.. code:: python\n\n   {\"order_by\": [\"-foo\"]}\n\n\nOffset\n======\nGreat for pagination of long results!\n\n.. code:: python\n\n   {\"offset\": 5}\n\n\nLimit\n=====\nGreat for pagination of long results!\n\n.. code:: python\n\n   {\"limit\": 10}\n\n\nGroup by\n========\n.. code:: python\n\n   {\"group_by\": [\"foo\"]}\n\n\nAggregation\n===========\nAggregation is done as part of the select, just like in SQL.\n\n.. code:: python\n\n   {\"select\": [\"foo\" [\"sum\", \"bar\"]],\n    \"group_by\": [\"foo\"]}\n\n\nDistinct\n========\nDistinct has its own query clause unlike in SQL.\n\n.. code:: python\n\n   {\"select\": [\"foo\", \"bar\"],\n    \"distinct\": [\"foo\"]}\n\n\nSub queries using from\n======================\nFilter, transform and select your data in multiple steps.\n\n.. code:: python\n\n    {\"select\": [[\"=\", \"foo_pct\", [\"*\", 100, [\"/\", \"foo\", \"bar\"]]]],\n     \"from\": {\"select\": [\"foo\", [\"sum\", \"bar\"]],\n              \"group_by\": [\"foo\"]}}\n\n\nSub queries using in\n====================\nFilter your data using the result of a query as filter input.\n\n.. code:: python\n\n    {\"where\", [\"in\", \"foo\", {\"where\": [\"==\", \"bar\", 10]}]}\n\n\nAll together now!\n=================\nA slightly more elaborate example. Get the top 10 foo:s with most bar:s.\n\n.. code:: python\n\n   {\"select\": [\"foo\", [\"sum\", \"bar\"]],\n    \"where\": [\">\", \"bar\", 0],\n    \"order_by\": [\"-bar\"],\n    \"group_by\": [\"foo\"],\n    \"limit\": 10}\n\n\n***********************\nAPI examples using curl\n***********************\nUpload table data to cache (a 404 will be returned if querying on a key that does not exist).\n\n.. code::\n\n   curl -X POST --data-binary @my_csv.csv http://localhost:8888/qcache/dataset/my-key\n\n\nQuery table\n\n.. code::\n\n   curl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"select\\\": [[\\\"count\\\"]], \\\"where\\\": [\\\"<\\\", \\\"baz\\\", 99999999999915],  \\\"offset\\\": 100, \\\"limit\\\": 50}\"\n   curl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"select\\\": [[\\\"count\\\"]], \\\"where\\\": [\\\"in\\\", \\\"baz\\\", [779889,8958854,8281368,6836605,3080972,4072649,7173075,4769116,4766900,4947128,7314959,683531,6395813,7834211,12051932,3735224,12368089,9858334,4424629,4155280]],  \\\"offset\\\": 0, \\\"limit\\\": 50}\"\n   curl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"where\\\": [\\\"==\\\", \\\"foo\\\", \\\"\\\\\\\"95d9f671\\\\\\\"\\\"],  \\\"offset\\\": 0, \\\"limit\\\": 50}\"\n   curl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"select\\\": [[\\\"max\\\", \\\"baz\\\"]],  \\\"offset\\\": 0, \\\"limit\\\": 500000000000}\"\n\n\n***************************\nCustom request HTTP headers\n***************************\n\nThere are a couple of custom HTTP headers that can be used to control the behaviour of Q-Cache.\n\nPosting tables\n==============\n\nX-QCache-types\n--------------\nQCache will usually recognize the data types of submitted data automatically. There may be times when\nstrings are mistaken for numbers because all of the data submitted for a column in a dataset happens\nto be in numbers.\n\nThis header makes it possible to explicitly type column to be a string to. In the example below columns\nfoo and bar are both typed to string.\n\n.. code::\n\n   X-QCache-types: foo=string;bar=string\n\nExplicitly setting the type to string is only relevant when submitting data in CSV. With JSON the data\nhas an unambiguous (well...) data type that is used by QCache.\n\nEnums\n-----\nThe `X-QCache-types` header can also be used to specify columns with enum types.\n\n.. code::\n\n   X-QCache-types: foo=enum;bar=enum\n\nEnums are a good way to store low cardinality string columns space efficiently. They can be compared\nfor equality and inequality but currently do not have a well defined order so filtering by\nlarger than and less than is not possible for example.\n\n\nX-QCache-stand-in-columns\n-------------------------\nIt may be that your submitted data varies a little from dataset to dataset with respect to the columns\navailable in the dataset. You still want to be able to query the datasets in the same way and make\nsome assumptions of which columns that are available. This header lets you do that.\n\nIn the below example column foo will be set to 10 in case it does not exist in the submitted data. bar will\nbe set to the value of the baz column if it is not submitted.\n\nThis header can be used in request both for storing and querying data.\n\n.. code::\n\n   X-QCache-stand-in-columns: foo=10;bar=baz\n\n\nQuery responses\n===============\n\nX-QCache-unsliced-length\n------------------------\nThis header is added to responses and states how many rows the total filtered result was before applying\nany limits or offsets for pagination.\n\n.. code::\n\n   X-QCache-unsliced-length: 8324\n\n\n*************\nMore examples\n*************\nPlease look at the tests in the project or QCache-client_ for some further examples of queries.\nThe unit tests in this project is also a good source for examples.\n\nIf you still have questions don't hesitate to contact the author or write an issue!\n\n**********\nStatistics\n**********\n\n.. code::\n\n   http://localhost:8888/qcache/statistics\n\nA get against the above endpoint will return a JSON object containing cache statistics,\nhit & miss count, query & upload duration. Statistics are reset when querying.\n\n*************\nData encoding\n*************\nJust use UTF-8 when uploading data and in queries and you'll be fine. All responses are UTF-8.\nNo other codecs are supported.\n\n****************\nData compression\n****************\nQCache supports request and response body compression with LZ4 or GZIP using standard HTTP headers.\n\nIn a query request set the following header to receive a compressed response:\n\n.. code::\n\n   Accept-Encoding: lz4,gzip\n\n\nThe response will contain the following header indicating the used encoding\n\n.. code::\n\n   Content-Encoding: lz4\n\nLZ4 will always be preferred if present.\n\nThe above header should also be set indicating the compression algorithm if you are\nsubmitting compressed data.\n\n\n**************************\nPerformance & dimensioning\n**************************\nSince QCache is single thread, single process, the way to scale capacity is by adding more servers.\nIf you have 8 Gb of ram available on a 4 core machine don't start one server using all 8 Gb. Instead\nstart 4 servers with 2 Gb memory each or even 8 servers with 1 Gb each or 16 servers with 512 Mb each.\ndepending on your use case. Assign them to different ports and use a client library to do the key\nbalancing between them. That way you will have 4 - 16 times the query capacity.\n\nQCache is ideal for container deployment. Start one container running one QCache instance.\n\nExpect a memory overhead of about 20% - 30% of the configured cache size for querying and table loading.\nTo be on the safe side you should probably assume a 50% overhead. Eg. if you have 3 Gb available set the\ncache size to 2 Gb.\n\nWhen choosing between CSV and JSON as upload format prefer CSV as the amount of data can be large and it's\nmore compact and faster to insert than JSON.\n\nFor query responses prefer JSON as the amount of data is often small and it's easier to work with than CSV.\n\n.. _Pandas: http://pandas.pydata.org/\n.. _NumPy: http://www.numpy.org/\n.. _Tornado: http://www.tornadoweb.org/en/stable/\n\n***********************************\nStanding on the shoulders of giants\n***********************************\nQCache makes heavy use of the fantastic python libraries Pandas_, NumPy_ and Tornado_.\n\n\n*********************\nIdeas for coming work\n*********************\nThese may or may not be realized, it's far from sure that all of the ideas are good.\n\n* Improve documentation\n* Stream data into dataframe rather than waiting for complete input, chunked HTTP upload or similar.\n* Streaming proxy to allow clients to only know about one endpoint.\n* Configurable URL prefix to allow being mounted at arbitrary position behind a proxy.\n* Make it possible to execute multiple queries and return multiple responses in one request (qs=,/qs/).\n* Allow post with data and query in one request, this will guarantee progress\n  as long as the dataset fits in memory. {\"query\": ..., \"dataset\": ...}\n* Possibility to specify indexes when uploading data (how do the indexes affect size? write performance? read performance?)\n* Possibility to upload files as a way to prime the cache without taking up memory.\n* Namespaces for more diverse statistics based on namespace?\n* Publish performance numbers\n* Other table formats in addition to CSV and JSON?\n* Break out all things dataframe into an own package and provide possibility to update\n  and insert into dataframe based on predicate just like querying is done now.\n* Investigate type hints for pandas categorials on enum-like values to improve storage\n  layout and filter speed. Check new import options from CSV when Pandas 0.19 is available.\n* Support math functions as part of the where clause (see pandas expr.py/ops.py)\n* Some kind of light weight joining? Could create dataset groups that all are allocated to\n  the same cache. Sub queries could then be used to query datasets based on data selected\n  from other datasets in the same dataset group.\n\n************\nContributing\n************\nWant to contribute? That's great!\n\nIf you experience problems please log them on GitHub. If you want to contribute code,\nplease fork the code and submit a pull request.\n\nIf you intend to implement major features or make major changes please raise an issue\nso that we can discuss it first.\n\nRunning tests\n=============\n.. code::\n\n   pip install -r dev-requirements.txt\n   invoke test\n\nTLS\n===\nSome tests rely on a couple of certs found under `tls/`. If these have expired\nthey have to be regenerated. This is done by executing `generate_test_certs.sh`\nfrom the `tls` directory.\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tobgu/qcache", "keywords": "qcache", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "qcache", "package_url": "https://pypi.org/project/qcache/", "platform": "", "project_url": "https://pypi.org/project/qcache/", "project_urls": {"Homepage": "https://github.com/tobgu/qcache"}, "release_url": "https://pypi.org/project/qcache/0.9.3/", "requires_dist": null, "requires_python": "", "summary": "In memory cache server with analytical query capabilities", "version": "0.9.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/tobgu/qcache\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/tobgu/qcache.png?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/489c682c7a3a4ce9e802892b19a8c3559b749aaf/68747470733a2f2f7472617669732d63692e6f72672f746f6267752f7163616368652e706e673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://badge.fury.io/py/qcache\" rel=\"nofollow\"><img alt=\"https://badge.fury.io/py/qcache.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e907a26542f41f8772cf5bf56cdaa1bf5d13f8ae/68747470733a2f2f62616467652e667572792e696f2f70792f7163616368652e737667\"></a>\n<a href=\"http://codecov.io/github/tobgu/qcache?branch=master\" rel=\"nofollow\"><img alt=\"http://codecov.io/github/tobgu/qcache/coverage.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e3196c9604382e62a05eafee50026c21d46a91ec/687474703a2f2f636f6465636f762e696f2f6769746875622f746f6267752f7163616368652f636f7665726167652e7376673f6272616e63683d6d6173746572\"></a>\n<p>QCache is a key-table cache, an in memory cache server with analytical query capabilities.</p>\n<p>While the more commonly known key-value caches (such as <a href=\"http://memcached.org/\" rel=\"nofollow\">Memcached</a>) lets you fetch a value\nbased on a key QCache lets you run queries against a table based on a key.</p>\n<div id=\"motivation\">\n<h2>Motivation</h2>\n<p>You are working with table data that you want to run flexible queries against but do not want to\nload them into an SQL database or similar because of any of the following:</p>\n<ul>\n<li>The operational cost and complexity of bringing in an SQL server</li>\n<li>The tables do not have a homogeneous format</li>\n<li>The data is short lived</li>\n<li>Not all data available is ever used, you only want to use resources on demand</li>\n<li>You want to treat queries as data and build them dynamically using data structures\nthat you are used to (dictionaries and lists or objects and arrays depending on your\nlanguage background)</li>\n<li>Expensive JOINs are required to create the table.</li>\n<li>\u2026</li>\n</ul>\n<p>Or, you are building server software and want to add the possibility for your clients to run\nqueries directly against the data without the need for dreadful translations between a REST\ninterface with some home grown filter language.</p>\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>Simple, single thread, single process, server.</li>\n<li>Expressive JSON-based query language with format and features similar to SQL SELECT. Queries\nare data that can easily be transformed or enriched.</li>\n<li>Support for JSON or CSV input and output format</li>\n<li>Performant queries on tables as large as 10 x 1000000 cells out of the box</li>\n<li>No need for table definitions, tables are created dynamically based on the data inserted</li>\n<li>Statistics about hit and miss count, query and insert performance and more available\nthrough HTTP API</li>\n<li>Scales linearly in query capacity with the number of servers. A python client library that\nuses consistent hashing for key distribution among servers is available\nhere <a href=\"https://github.com/tobgu/qcache-client\" rel=\"nofollow\">QCache-client</a>. There\u2019s also a basic Go client here <a href=\"https://github.com/tobgu/go-qcache-client\" rel=\"nofollow\">Go-QCache-client</a>.\nMore clients are welcome!</li>\n</ul>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<p>Python 2.7 (2.7.9+ if using TLS) for now</p>\n</div>\n<div id=\"installation\">\n<h2>Installation</h2>\n<pre>pip install qcache\n</pre>\n</div>\n<div id=\"running\">\n<h2>Running</h2>\n<pre>qcache\n</pre>\n<p>This will start qcache on the default port using the default cache size. To get help on available parameters:</p>\n<pre>qcache --help\n</pre>\n</div>\n<div id=\"docker\">\n<h2>Docker</h2>\n<p>You can also get the latest version as a Docker image. This is probably the easiest way to try it out if you\nare running Linux or if you have Docker Machine installed.</p>\n<pre>docker run -p 9401:9401 tobgu/qcache\n</pre>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>MIT licensed. See the bundled <a href=\"https://github.com/tobgu/qcache/blob/master/LICENSE\" rel=\"nofollow\">LICENSE</a> file for more details.</p>\n</div>\n<div id=\"query-examples\">\n<h2>Query examples</h2>\n<p>Below are examples of the major features of the query language. A JSON object is used to\ndescribe the query. The query should be URL encoded and passed in using the \u2018q\u2019 GET-parameter.</p>\n<p>The query language uses LISP-style prefix notation for simplicity. This makes it easy\nto parse and build queries dynamically since no rules for operator precedence\never need to be applied.</p>\n<p>Like so:\n<cite>http://localhost:8888/qcache/datasets/&lt;dataset_key&gt;?q=&lt;URL-encoded-query&gt;</cite></p>\n<p>You can also POST queries as JSON against:\n<cite>http://localhost:8888/qcache/datasets/&lt;dataset_key&gt;/q/</cite></p>\n<p>This is a good alternative to GET if your queries are too large to fit in the query string.</p>\n<div id=\"select-all\">\n<h3>Select all</h3>\n<p>An empty object will return all rows in the table:</p>\n<pre><span class=\"p\">{}</span>\n</pre>\n</div>\n<div id=\"projection\">\n<h3>Projection</h3>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">]}</span>\n</pre>\n<p>Not specifying select is equivalent to SELECT * in SQL</p>\n<div id=\"column-aliasing\">\n<h4>Column aliasing</h4>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"s2\">\"=\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">]]}</span>\n</pre>\n<p>This will rename column bar to foo in the result.</p>\n<p>You can also make more elaborate calculations in the aliasing expression.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"s2\">\"=\"</span><span class=\"p\">,</span> <span class=\"s2\">\"baz\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"+\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"*\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">],</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">]]]</span>\n</pre>\n<p>As well as simple constant assignments.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"s2\">\"=\"</span><span class=\"p\">,</span> <span class=\"s2\">\"baz\"</span><span class=\"p\">,</span> <span class=\"mi\">55</span><span class=\"p\">]]}</span>\n</pre>\n</div>\n</div>\n<div id=\"filtering\">\n<h3>Filtering</h3>\n<div id=\"comparison\">\n<h4>Comparison</h4>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"&lt;\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]}</span>\n</pre>\n<p>The following operators are supported:</p>\n<pre>==, !=, &lt;=, &lt;, &gt;, &gt;=\n</pre>\n</div>\n<div id=\"in\">\n<h4>In</h4>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"in\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]]}</span>\n</pre>\n</div>\n<div id=\"like-ilike\">\n<h4>Like/ilike</h4>\n<p>Like and ilike are used for string matching and work similar to LIKE in SQL. Like is case sensitive\nwhile ilike is case insensitive. In addition to string matching using % as wildcard like/ilike also\nsupports regexps.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"like\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"s2\">\"'%bar%'\"</span><span class=\"p\">]}</span>\n</pre>\n</div>\n<div id=\"bitwise-operators\">\n<h4>Bitwise operators</h4>\n<p>There are two operators for bitwise filtering on integers: <cite>all_bits</cite> and <cite>any_bits</cite>.</p>\n<ul>\n<li>all_bits - evaluates to true if all bits in the supplied argument are set in value tested against.</li>\n<li>any_bits - evaluates to true if any bits in the supplied argument are set in value tested agains.</li>\n</ul>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"any_bits\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"mi\">31</span><span class=\"p\">]}</span>\n</pre>\n</div>\n<div id=\"clauses\">\n<h4>Clauses</h4>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"&amp;\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"&gt;\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span>\n                <span class=\"p\">[</span><span class=\"s2\">\"==\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">]]}</span>\n</pre>\n<p>The following operators are supported:</p>\n<pre>&amp;, |\n</pre>\n</div>\n<div id=\"negation\">\n<h4>Negation</h4>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"!\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"==\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span>  <span class=\"mi\">1</span><span class=\"p\">]]}</span>\n</pre>\n</div>\n</div>\n<div id=\"ordering\">\n<h3>Ordering</h3>\n<p>Ascending</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"order_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">]}</span>\n</pre>\n<p>Descending</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"order_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"-foo\"</span><span class=\"p\">]}</span>\n</pre>\n</div>\n<div id=\"offset\">\n<h3>Offset</h3>\n<p>Great for pagination of long results!</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"offset\"</span><span class=\"p\">:</span> <span class=\"mi\">5</span><span class=\"p\">}</span>\n</pre>\n</div>\n<div id=\"limit\">\n<h3>Limit</h3>\n<p>Great for pagination of long results!</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"limit\"</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">}</span>\n</pre>\n</div>\n<div id=\"group-by\">\n<h3>Group by</h3>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"group_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">]}</span>\n</pre>\n</div>\n<div id=\"aggregation\">\n<h3>Aggregation</h3>\n<p>Aggregation is done as part of the select, just like in SQL.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span> <span class=\"p\">[</span><span class=\"s2\">\"sum\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">]],</span>\n <span class=\"s2\">\"group_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">]}</span>\n</pre>\n</div>\n<div id=\"distinct\">\n<h3>Distinct</h3>\n<p>Distinct has its own query clause unlike in SQL.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">],</span>\n <span class=\"s2\">\"distinct\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">]}</span>\n</pre>\n</div>\n<div id=\"sub-queries-using-from\">\n<h3>Sub queries using from</h3>\n<p>Filter, transform and select your data in multiple steps.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[[</span><span class=\"s2\">\"=\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo_pct\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"*\"</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"/\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">]]]],</span>\n <span class=\"s2\">\"from\"</span><span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"sum\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">]],</span>\n          <span class=\"s2\">\"group_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">]}}</span>\n</pre>\n</div>\n<div id=\"sub-queries-using-in\">\n<h3>Sub queries using in</h3>\n<p>Filter your data using the result of a query as filter input.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"in\"</span><span class=\"p\">,</span> <span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"==\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">]}]}</span>\n</pre>\n</div>\n<div id=\"all-together-now\">\n<h3>All together now!</h3>\n<p>A slightly more elaborate example. Get the top 10 foo:s with most bar:s.</p>\n<pre><span class=\"p\">{</span><span class=\"s2\">\"select\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"s2\">\"sum\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">]],</span>\n <span class=\"s2\">\"where\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"&gt;\"</span><span class=\"p\">,</span> <span class=\"s2\">\"bar\"</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span>\n <span class=\"s2\">\"order_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"-bar\"</span><span class=\"p\">],</span>\n <span class=\"s2\">\"group_by\"</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">\"foo\"</span><span class=\"p\">],</span>\n <span class=\"s2\">\"limit\"</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">}</span>\n</pre>\n</div>\n</div>\n<div id=\"api-examples-using-curl\">\n<h2>API examples using curl</h2>\n<p>Upload table data to cache (a 404 will be returned if querying on a key that does not exist).</p>\n<pre>curl -X POST --data-binary @my_csv.csv http://localhost:8888/qcache/dataset/my-key\n</pre>\n<p>Query table</p>\n<pre>curl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"select\\\": [[\\\"count\\\"]], \\\"where\\\": [\\\"&lt;\\\", \\\"baz\\\", 99999999999915],  \\\"offset\\\": 100, \\\"limit\\\": 50}\"\ncurl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"select\\\": [[\\\"count\\\"]], \\\"where\\\": [\\\"in\\\", \\\"baz\\\", [779889,8958854,8281368,6836605,3080972,4072649,7173075,4769116,4766900,4947128,7314959,683531,6395813,7834211,12051932,3735224,12368089,9858334,4424629,4155280]],  \\\"offset\\\": 0, \\\"limit\\\": 50}\"\ncurl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"where\\\": [\\\"==\\\", \\\"foo\\\", \\\"\\\\\\\"95d9f671\\\\\\\"\\\"],  \\\"offset\\\": 0, \\\"limit\\\": 50}\"\ncurl -G localhost:8888/qcache/dataset/my-key --data-urlencode \"q={\\\"select\\\": [[\\\"max\\\", \\\"baz\\\"]],  \\\"offset\\\": 0, \\\"limit\\\": 500000000000}\"\n</pre>\n</div>\n<div id=\"custom-request-http-headers\">\n<h2>Custom request HTTP headers</h2>\n<p>There are a couple of custom HTTP headers that can be used to control the behaviour of Q-Cache.</p>\n<div id=\"posting-tables\">\n<h3>Posting tables</h3>\n<div id=\"x-qcache-types\">\n<h4>X-QCache-types</h4>\n<p>QCache will usually recognize the data types of submitted data automatically. There may be times when\nstrings are mistaken for numbers because all of the data submitted for a column in a dataset happens\nto be in numbers.</p>\n<p>This header makes it possible to explicitly type column to be a string to. In the example below columns\nfoo and bar are both typed to string.</p>\n<pre>X-QCache-types: foo=string;bar=string\n</pre>\n<p>Explicitly setting the type to string is only relevant when submitting data in CSV. With JSON the data\nhas an unambiguous (well\u2026) data type that is used by QCache.</p>\n</div>\n<div id=\"enums\">\n<h4>Enums</h4>\n<p>The <cite>X-QCache-types</cite> header can also be used to specify columns with enum types.</p>\n<pre>X-QCache-types: foo=enum;bar=enum\n</pre>\n<p>Enums are a good way to store low cardinality string columns space efficiently. They can be compared\nfor equality and inequality but currently do not have a well defined order so filtering by\nlarger than and less than is not possible for example.</p>\n</div>\n<div id=\"x-qcache-stand-in-columns\">\n<h4>X-QCache-stand-in-columns</h4>\n<p>It may be that your submitted data varies a little from dataset to dataset with respect to the columns\navailable in the dataset. You still want to be able to query the datasets in the same way and make\nsome assumptions of which columns that are available. This header lets you do that.</p>\n<p>In the below example column foo will be set to 10 in case it does not exist in the submitted data. bar will\nbe set to the value of the baz column if it is not submitted.</p>\n<p>This header can be used in request both for storing and querying data.</p>\n<pre>X-QCache-stand-in-columns: foo=10;bar=baz\n</pre>\n</div>\n</div>\n<div id=\"query-responses\">\n<h3>Query responses</h3>\n<h3 id=\"x-qcache-unsliced-length\"><span class=\"section-subtitle\">X-QCache-unsliced-length</span></h3>\n<p>This header is added to responses and states how many rows the total filtered result was before applying\nany limits or offsets for pagination.</p>\n<pre>X-QCache-unsliced-length: 8324\n</pre>\n</div>\n</div>\n<div id=\"more-examples\">\n<h2>More examples</h2>\n<p>Please look at the tests in the project or <a href=\"https://github.com/tobgu/qcache-client\" rel=\"nofollow\">QCache-client</a> for some further examples of queries.\nThe unit tests in this project is also a good source for examples.</p>\n<p>If you still have questions don\u2019t hesitate to contact the author or write an issue!</p>\n</div>\n<div id=\"statistics\">\n<h2>Statistics</h2>\n<pre>http://localhost:8888/qcache/statistics\n</pre>\n<p>A get against the above endpoint will return a JSON object containing cache statistics,\nhit &amp; miss count, query &amp; upload duration. Statistics are reset when querying.</p>\n</div>\n<div id=\"data-encoding\">\n<h2>Data encoding</h2>\n<p>Just use UTF-8 when uploading data and in queries and you\u2019ll be fine. All responses are UTF-8.\nNo other codecs are supported.</p>\n</div>\n<div id=\"data-compression\">\n<h2>Data compression</h2>\n<p>QCache supports request and response body compression with LZ4 or GZIP using standard HTTP headers.</p>\n<p>In a query request set the following header to receive a compressed response:</p>\n<pre>Accept-Encoding: lz4,gzip\n</pre>\n<p>The response will contain the following header indicating the used encoding</p>\n<pre>Content-Encoding: lz4\n</pre>\n<p>LZ4 will always be preferred if present.</p>\n<p>The above header should also be set indicating the compression algorithm if you are\nsubmitting compressed data.</p>\n</div>\n<div id=\"performance-dimensioning\">\n<h2>Performance &amp; dimensioning</h2>\n<p>Since QCache is single thread, single process, the way to scale capacity is by adding more servers.\nIf you have 8 Gb of ram available on a 4 core machine don\u2019t start one server using all 8 Gb. Instead\nstart 4 servers with 2 Gb memory each or even 8 servers with 1 Gb each or 16 servers with 512 Mb each.\ndepending on your use case. Assign them to different ports and use a client library to do the key\nbalancing between them. That way you will have 4 - 16 times the query capacity.</p>\n<p>QCache is ideal for container deployment. Start one container running one QCache instance.</p>\n<p>Expect a memory overhead of about 20% - 30% of the configured cache size for querying and table loading.\nTo be on the safe side you should probably assume a 50% overhead. Eg. if you have 3 Gb available set the\ncache size to 2 Gb.</p>\n<p>When choosing between CSV and JSON as upload format prefer CSV as the amount of data can be large and it\u2019s\nmore compact and faster to insert than JSON.</p>\n<p>For query responses prefer JSON as the amount of data is often small and it\u2019s easier to work with than CSV.</p>\n</div>\n<div id=\"standing-on-the-shoulders-of-giants\">\n<h2>Standing on the shoulders of giants</h2>\n<p>QCache makes heavy use of the fantastic python libraries <a href=\"http://pandas.pydata.org/\" rel=\"nofollow\">Pandas</a>, <a href=\"http://www.numpy.org/\" rel=\"nofollow\">NumPy</a> and <a href=\"http://www.tornadoweb.org/en/stable/\" rel=\"nofollow\">Tornado</a>.</p>\n</div>\n<div id=\"ideas-for-coming-work\">\n<h2>Ideas for coming work</h2>\n<p>These may or may not be realized, it\u2019s far from sure that all of the ideas are good.</p>\n<ul>\n<li>Improve documentation</li>\n<li>Stream data into dataframe rather than waiting for complete input, chunked HTTP upload or similar.</li>\n<li>Streaming proxy to allow clients to only know about one endpoint.</li>\n<li>Configurable URL prefix to allow being mounted at arbitrary position behind a proxy.</li>\n<li>Make it possible to execute multiple queries and return multiple responses in one request (qs=,/qs/).</li>\n<li>Allow post with data and query in one request, this will guarantee progress\nas long as the dataset fits in memory. {\u201cquery\u201d: \u2026, \u201cdataset\u201d: \u2026}</li>\n<li>Possibility to specify indexes when uploading data (how do the indexes affect size? write performance? read performance?)</li>\n<li>Possibility to upload files as a way to prime the cache without taking up memory.</li>\n<li>Namespaces for more diverse statistics based on namespace?</li>\n<li>Publish performance numbers</li>\n<li>Other table formats in addition to CSV and JSON?</li>\n<li>Break out all things dataframe into an own package and provide possibility to update\nand insert into dataframe based on predicate just like querying is done now.</li>\n<li>Investigate type hints for pandas categorials on enum-like values to improve storage\nlayout and filter speed. Check new import options from CSV when Pandas 0.19 is available.</li>\n<li>Support math functions as part of the where clause (see pandas expr.py/ops.py)</li>\n<li>Some kind of light weight joining? Could create dataset groups that all are allocated to\nthe same cache. Sub queries could then be used to query datasets based on data selected\nfrom other datasets in the same dataset group.</li>\n</ul>\n</div>\n<div id=\"contributing\">\n<h2>Contributing</h2>\n<p>Want to contribute? That\u2019s great!</p>\n<p>If you experience problems please log them on GitHub. If you want to contribute code,\nplease fork the code and submit a pull request.</p>\n<p>If you intend to implement major features or make major changes please raise an issue\nso that we can discuss it first.</p>\n<div id=\"running-tests\">\n<h3>Running tests</h3>\n<pre>pip install -r dev-requirements.txt\ninvoke test\n</pre>\n</div>\n<div id=\"tls\">\n<h3>TLS</h3>\n<p>Some tests rely on a couple of certs found under <cite>tls/</cite>. If these have expired\nthey have to be regenerated. This is done by executing <cite>generate_test_certs.sh</cite>\nfrom the <cite>tls</cite> directory.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 4662852, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "da73065099de9d7ac7a49d1c92c825ea", "sha256": "370481053c14a133e4ce643ce42679fb1bc465c7803cf5347cf7d6474f6d7018"}, "downloads": -1, "filename": "qcache-0.0.1.tar.gz", "has_sig": false, "md5_digest": "da73065099de9d7ac7a49d1c92c825ea", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8535, "upload_time": "2015-10-03T18:16:40", "upload_time_iso_8601": "2015-10-03T18:16:40.611365Z", "url": "https://files.pythonhosted.org/packages/ce/3a/62844fee0e6f3c036f2f141f5ff3b3385e93cf930ba0fe9d53ab3b8c4c4e/qcache-0.0.1.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "8420e5a5f169be8655d16bb8c03a66dd", "sha256": "beb668f62d0d9503b80a5567d209dc183d847aa61692200326cb07d9313a2f4a"}, "downloads": -1, "filename": "qcache-0.1.0.tar.gz", "has_sig": false, "md5_digest": "8420e5a5f169be8655d16bb8c03a66dd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19774, "upload_time": "2015-10-25T16:51:17", "upload_time_iso_8601": "2015-10-25T16:51:17.242109Z", "url": "https://files.pythonhosted.org/packages/eb/6d/b72c4460ced958ba486f3cebc64c035dc2ca77f1233ca291985ee623f4ab/qcache-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "8ccc6ce72c4b3c78f9a0cc1fa57fad4d", "sha256": "639eb150b8c215528daf21ae1789fba5bc8b53a7012fa5d6384c1638a5e87e56"}, "downloads": -1, "filename": "qcache-0.2.0.tar.gz", "has_sig": false, "md5_digest": "8ccc6ce72c4b3c78f9a0cc1fa57fad4d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23776, "upload_time": "2015-12-06T18:07:01", "upload_time_iso_8601": "2015-12-06T18:07:01.048339Z", "url": "https://files.pythonhosted.org/packages/5a/30/e1cf64df71035c48b57831850e4dd2c5c72f6c1ee6adddefa847839df680/qcache-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "53807207f77034eab43fabefecc85405", "sha256": "b07b730d7872563eaaff9af9dc6c5e5d918e999729109c60c47c146584aa0d72"}, "downloads": -1, "filename": "qcache-0.2.1.tar.gz", "has_sig": false, "md5_digest": "53807207f77034eab43fabefecc85405", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24274, "upload_time": "2015-12-15T20:53:13", "upload_time_iso_8601": "2015-12-15T20:53:13.612882Z", "url": "https://files.pythonhosted.org/packages/b1/06/f1c11ddd7fec163f5d35806625870c67806fe84d983d20e890e3d4846cb4/qcache-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "c9eee1fa6fabe991649ef88966a3ede5", "sha256": "5a66f2e7cb8f3a2c4c85bacb7096005180e8daaa9ae45898bec3a098b86060fe"}, "downloads": -1, "filename": "qcache-0.3.0.tar.gz", "has_sig": false, "md5_digest": "c9eee1fa6fabe991649ef88966a3ede5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 25085, "upload_time": "2015-12-23T20:18:30", "upload_time_iso_8601": "2015-12-23T20:18:30.782075Z", "url": "https://files.pythonhosted.org/packages/57/ed/fc25af4b88ff72de5896934f2f91e88fa3576b7b5ce65b6eedd1fc901c57/qcache-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "fa3dda06dc245a950881e9823fc26899", "sha256": "cbcb71ba555f138d7331bea716abc602369f0e94cf36fe2707bb82830deba4b8"}, "downloads": -1, "filename": "qcache-0.4.0.tar.gz", "has_sig": false, "md5_digest": "fa3dda06dc245a950881e9823fc26899", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26927, "upload_time": "2016-01-24T20:19:54", "upload_time_iso_8601": "2016-01-24T20:19:54.998801Z", "url": "https://files.pythonhosted.org/packages/42/f2/27eb1237527094635f28ac9b29476f3baa4d9e986433d4b52819c338d656/qcache-0.4.0.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "4d10aaab9442e924586d012d389bf9e3", "sha256": "30f4119abad527cb7a501c1b30de1a73c004798e22df7108a77e214515143d68"}, "downloads": -1, "filename": "qcache-0.4.1.tar.gz", "has_sig": false, "md5_digest": "4d10aaab9442e924586d012d389bf9e3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27133, "upload_time": "2016-01-31T16:03:06", "upload_time_iso_8601": "2016-01-31T16:03:06.534649Z", "url": "https://files.pythonhosted.org/packages/fd/f8/a18891339381c0b1187dbed36dde15e754eead99471520437373dfce6542/qcache-0.4.1.tar.gz", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "ea29c77d845e8869fe7d528589bf88d0", "sha256": "f984959495d4d1c7bca9b66ef8983d251b3c5270295342cbef31c854c33379b0"}, "downloads": -1, "filename": "qcache-0.4.2.tar.gz", "has_sig": false, "md5_digest": "ea29c77d845e8869fe7d528589bf88d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28808, "upload_time": "2016-06-04T15:04:57", "upload_time_iso_8601": "2016-06-04T15:04:57.392526Z", "url": "https://files.pythonhosted.org/packages/39/fe/0d96604657409084c6363cfeee1f7ab5c1ce98b5fa981d6a90484cad040c/qcache-0.4.2.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "d742ae6851a1d9f33b8401797fc13a01", "sha256": "77723ac812ccef4443408a3d1662394c8ae2785de5769db0b65f65d39e660129"}, "downloads": -1, "filename": "qcache-0.5.0.tar.gz", "has_sig": false, "md5_digest": "d742ae6851a1d9f33b8401797fc13a01", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 29460, "upload_time": "2016-06-19T21:24:57", "upload_time_iso_8601": "2016-06-19T21:24:57.835948Z", "url": "https://files.pythonhosted.org/packages/d3/4a/a6fabb03df7573adbc64e62fd1dae5b16be2fc3e904c3db56a75269ec30a/qcache-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "e111c9388488aa5d63252a475655ea28", "sha256": "00a5aee8872809cdd0b89bef73cb26bf10482892b8659f9996ac1752e92c0911"}, "downloads": -1, "filename": "qcache-0.6.0.tar.gz", "has_sig": false, "md5_digest": "e111c9388488aa5d63252a475655ea28", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26428, "upload_time": "2016-09-18T16:00:08", "upload_time_iso_8601": "2016-09-18T16:00:08.403563Z", "url": "https://files.pythonhosted.org/packages/ec/01/25aa336805d62ec2e9ea7ab05725c9dd36e649ab11e20bebff151b11db62/qcache-0.6.0.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "1c128ea695708330ce70591347b38e68", "sha256": "6849572400cebb347863e60fc1b707d0273a91dd54dd76575bfe8db757ebef53"}, "downloads": -1, "filename": "qcache-0.6.1.tar.gz", "has_sig": false, "md5_digest": "1c128ea695708330ce70591347b38e68", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32197, "upload_time": "2016-09-18T17:12:19", "upload_time_iso_8601": "2016-09-18T17:12:19.448233Z", "url": "https://files.pythonhosted.org/packages/06/ee/a1c0c390e889574bf5af74f77ae7fe4d2f46d35f43105a28386c6103bb45/qcache-0.6.1.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "4f66ed3f6aa39f2288c1ff753c125744", "sha256": "69f13e9c300298a0ac096e2eefd16711e6c9ea5f1096990bb8c00285f2e6614c"}, "downloads": -1, "filename": "qcache-0.7.0.tar.gz", "has_sig": false, "md5_digest": "4f66ed3f6aa39f2288c1ff753c125744", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38172, "upload_time": "2016-11-09T22:34:19", "upload_time_iso_8601": "2016-11-09T22:34:19.071951Z", "url": "https://files.pythonhosted.org/packages/bc/3b/f384b639ea7eec8969b0599ae53906fdb64bd1a61a992346d1159d7461cc/qcache-0.7.0.tar.gz", "yanked": false}], "0.7.1": [{"comment_text": "", "digests": {"md5": "c57c73a8df59544d2c398ff51be5db5b", "sha256": "d4273b5df5640fe4970f332801561403ce9c5502b60126a4160a14e04b43042d"}, "downloads": -1, "filename": "qcache-0.7.1.tar.gz", "has_sig": false, "md5_digest": "c57c73a8df59544d2c398ff51be5db5b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 39409, "upload_time": "2016-11-30T16:54:49", "upload_time_iso_8601": "2016-11-30T16:54:49.059749Z", "url": "https://files.pythonhosted.org/packages/db/af/1c1e73e58d3d196438d9546ed3e7f304419bdcb4eaa729fac2c360a507ad/qcache-0.7.1.tar.gz", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "fa9157817d5277a1ba894cdbf6939d22", "sha256": "c790beecf3141407d1be3edffbf3dc7db76d2a9387a2f78e96f2716d9cffe197"}, "downloads": -1, "filename": "qcache-0.7.2.tar.gz", "has_sig": false, "md5_digest": "fa9157817d5277a1ba894cdbf6939d22", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38189, "upload_time": "2016-12-18T19:10:46", "upload_time_iso_8601": "2016-12-18T19:10:46.300789Z", "url": "https://files.pythonhosted.org/packages/18/5b/26f71a012377c87958f4597d1faded276ee66c0515402b15253018e42c14/qcache-0.7.2.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "5669a7302832f3659bf72e9d8b20f6aa", "sha256": "1786b28b5d25fa71201fb63b788c99a28417da05581eaf64600277277316cca9"}, "downloads": -1, "filename": "qcache-0.8.0.tar.gz", "has_sig": false, "md5_digest": "5669a7302832f3659bf72e9d8b20f6aa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38584, "upload_time": "2017-01-08T15:53:24", "upload_time_iso_8601": "2017-01-08T15:53:24.414135Z", "url": "https://files.pythonhosted.org/packages/06/42/3993b13ad2d2a6245cce54ac9dc0be30eb5f204431f1a739e489f71a63e4/qcache-0.8.0.tar.gz", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "f17a87e98778705ddeed0b446c952b9b", "sha256": "78b8b5b66b85450b586429e93c9e04d7d709d2e0395bf46dc00388c98a70d913"}, "downloads": -1, "filename": "qcache-0.8.1.tar.gz", "has_sig": false, "md5_digest": "f17a87e98778705ddeed0b446c952b9b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 38498, "upload_time": "2017-04-06T05:26:05", "upload_time_iso_8601": "2017-04-06T05:26:05.683664Z", "url": "https://files.pythonhosted.org/packages/0d/05/afb38ea5e45957e9ca59b98916eaf4b4871d8e448d5afaca65dd15712414/qcache-0.8.1.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "5361a7c28bc3f4e704d9bcdea47a921f", "sha256": "b671d7b1ba294b644beee2d8ecbd61f4be764771ab7015387852a682c23e9757"}, "downloads": -1, "filename": "qcache-0.9.0.tar.gz", "has_sig": false, "md5_digest": "5361a7c28bc3f4e704d9bcdea47a921f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36887, "upload_time": "2017-11-14T08:12:04", "upload_time_iso_8601": "2017-11-14T08:12:04.954137Z", "url": "https://files.pythonhosted.org/packages/77/f0/c0dbc17753d04d61a5ebc8e64561baf0aef9d1e6d972c967bd9fd6f02972/qcache-0.9.0.tar.gz", "yanked": false}], "0.9.1": [{"comment_text": "", "digests": {"md5": "6e2048572d0be6f891e8858c99bdc037", "sha256": "c4352107593cb9c370a64368fa656b9ffac617befbe2e5889a4b9ad05dd2a641"}, "downloads": -1, "filename": "qcache-0.9.1.tar.gz", "has_sig": false, "md5_digest": "6e2048572d0be6f891e8858c99bdc037", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36145, "upload_time": "2017-11-15T22:28:15", "upload_time_iso_8601": "2017-11-15T22:28:15.852620Z", "url": "https://files.pythonhosted.org/packages/72/5e/4312c977884e338109c8bdfc4e5a0c0da6183f795a1ce45f5092c4dd0e7d/qcache-0.9.1.tar.gz", "yanked": false}], "0.9.2": [{"comment_text": "", "digests": {"md5": "cc5456d019fbd2dd54076cf3dbc6cdc1", "sha256": "3be1038237669fdcd27f19f0ab234a173a75978d354d376d95fef595e51b0831"}, "downloads": -1, "filename": "qcache-0.9.2.tar.gz", "has_sig": false, "md5_digest": "cc5456d019fbd2dd54076cf3dbc6cdc1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 36697, "upload_time": "2018-05-23T20:08:32", "upload_time_iso_8601": "2018-05-23T20:08:32.593415Z", "url": "https://files.pythonhosted.org/packages/92/93/9a5c7769187200f8a00d51a9994e3a7aad8cf5061a610a4ae10ae08b36ea/qcache-0.9.2.tar.gz", "yanked": false}], "0.9.3": [{"comment_text": "", "digests": {"md5": "979ce0d81add343b2797918ea6610100", "sha256": "c2acd5125e1b126e23fe84d8c4905d329e59886e800357e9773cf748185e3d5f"}, "downloads": -1, "filename": "qcache-0.9.3.tar.gz", "has_sig": false, "md5_digest": "979ce0d81add343b2797918ea6610100", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33733, "upload_time": "2019-01-05T07:20:20", "upload_time_iso_8601": "2019-01-05T07:20:20.929456Z", "url": "https://files.pythonhosted.org/packages/42/60/8474f4d356eac127d72a5c7efa95ac1dd1e7b828f3729317d7e6a934a6da/qcache-0.9.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "979ce0d81add343b2797918ea6610100", "sha256": "c2acd5125e1b126e23fe84d8c4905d329e59886e800357e9773cf748185e3d5f"}, "downloads": -1, "filename": "qcache-0.9.3.tar.gz", "has_sig": false, "md5_digest": "979ce0d81add343b2797918ea6610100", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33733, "upload_time": "2019-01-05T07:20:20", "upload_time_iso_8601": "2019-01-05T07:20:20.929456Z", "url": "https://files.pythonhosted.org/packages/42/60/8474f4d356eac127d72a5c7efa95ac1dd1e7b828f3729317d7e6a934a6da/qcache-0.9.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:10:03 2020"}