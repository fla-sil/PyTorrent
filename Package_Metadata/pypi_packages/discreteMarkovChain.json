{"info": {"author": "Gerlach van der Heide", "author_email": "g.van.der.heide@rug.nl", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Topic :: Scientific/Engineering :: Mathematics"], "description": "discreteMarkovChain\r\n=======================\r\nWhile for statistical and scientific programming languages such as R various packages are available for analyzing Markov chains, equivalent packages in Python are rather scarce. This discreteMarkovChain package for Python addresses the problem of obtaining the steady state distribution of a Markov chain, also known as the stationary distribution, limiting distribution or invariant measure. The package is for Markov chains with discrete and finite state spaces, which are most commonly encountered in practical applications. \r\n\r\nThis package is based on numpy and scipy for efficient computations and limited use of resources. Markov chains with several million states can be solved. The package introduces the `markovChain` class which has the following features. \r\n\r\n* States can be either integers or vectors of integers.\r\n* Steady state distributions can be calculated for continous time Markov chains (CTMC) as well as discrete time Markov chains (DTMC).\r\n* The user can either manually specify the probability/rate matrix of the Markov chain, or let the program do this automatically using an indirect or direct method.\r\n* The indirect method requires the user to specify an initial state and transition function (giving for each state the reachable states and their probabilities/rates). \r\n   * By repeatedly calling the transition function on unvisited states, the state space and the probability matrix are built up automatically.\r\n   * This makes it easy to implement your own Markov chains!\r\n* The direct method requires the user to specify a transition function and a function that gives the complete state space. \r\n   * While the implementation is typically more complex, this may have some computational advantage over the indirect method for large state spaces with vector states.  \r\n* The steady state distribution can be calculated by a method of choice: \r\n   * The power method,\r\n   * Solving a system of linear equations,\r\n   * Determing the first left eigenvector, \r\n   * Searching in Krylov subspace.\r\n* Checks are included to see whether all states in the Markov chain are connected.\r\n* Memory consumption is reduced by using sparse matrices. \r\n\r\nWhen the user calls a certain solution method, the `markovChain` object gets the attribute `pi` which specifies the steady state probability of each state. When the user uses the direct or indirect method, the object gets the `mapping` attribute which is a dictionary that links each index of `pi` with a corresponding state. Using the `mapping` and `pi`, it becomes simple to calculate performance measures for your Markov chain, such as the average cost per time unit or the number of blocked customers in a queue with blocking.\r\n\r\n--------------\r\nInstallation\r\n--------------\r\nThe package can be installed with the command\r\n\r\n::\r\n\r\n    pip install discreteMarkovChain\r\n\r\nor by downloading the source distribution and installing manually with\r\n\r\n::\r\n\r\n    python setup.py install\r\n\r\n------------\r\nExamples\r\n------------\r\nThe `markovChain` class can be used to initialize your own Markov chains. We import it by using\r\n\r\n::\r\n\r\n    from discreteMarkovChain import markovChain\r\n\r\nFirst, lets consider a simple Markov chain with two states, where we already know the probability matrix `P`.\r\n\r\n::\r\n\r\n    P = np.array([[0.5,0.5],[0.6,0.4]])\r\n    mc = markovChain(P)\r\n    mc.computePi('linear') #We can also use 'power', 'krylov' or 'eigen'\r\n    print(mc.pi)\r\n\r\nWe get the following steady state probabilities:\r\n\r\n::\r\n\r\n    [ 0.54545455  0.45454545]\r\n\r\nNow we show an example of a one-dimensional random walk in continuous time between integers `m` and `M`. We move up and down with rates 1. We will use the indirect method to determine the rate matrix for us automatically. The indirect method is rather flexible, and allows the transition function to return a dictionary with reachable states and rates. We first introduce our `randomWalk` class. \r\n\r\n::\r\n\r\n    class randomWalk(markovChain):\r\n        #A random walk where we move up and down with rate 1.0 in each state between bounds m and M.\r\n        #For the transition function to work well, we define some class variables in the __init__ function.\r\n        def __init__(self,m,M):\r\n            super(randomWalk, self).__init__() #always use this as first line when creating your own __init__ \r\n            self.initialState = m\r\n            self.m = m\r\n            self.M = M\r\n            self.uprate = 1.0\r\n            self.downrate = 1.0\r\n        \r\n        def transition(self,state):\r\n            #Specify the reachable states from state and their rates.\r\n            #A dictionary is extremely easy here!\r\n            rates = {}\r\n            if self.m < state < self.M:\r\n                rates[state+1] = self.uprate \r\n                rates[state-1] = self.downrate \r\n            elif state == self.m:\r\n                rates[state+1] = self.uprate \r\n            elif state == self.M:\r\n                rates[state-1] = self.downrate \r\n            return rates\r\n\r\nNow we initialize the random walk with some values for `m` and `M` and calculate the steady-state vector `pi`.\r\n\r\n::\r\n\r\n    mc = randomWalk(0,5)\r\n    mc.computePi()\r\n    mc.printPi()\r\n\r\nThe stationary probabilities are given below.\r\n\r\n::\r\n\r\n    0 0.166666666667\r\n    1 0.166666666667\r\n    2 0.166666666667\r\n    3 0.166666666667\r\n    4 0.166666666667\r\n    5 0.166666666667\r\n\r\nNot unexpectedly, they are the same for each state. We can repeat this for a multi-dimensional random walk. Now we use the direct method. Here, we need to use a transition function returning numpy arrays and we need to define a function that calculates the state space.\r\n\r\n:: \r\n\r\n    from discreteMarkovChain import partition \r\n    \r\n    class randomWalkNumpy(markovChain):\r\n        #Now we do the same thing with a transition function that returns a 2d numpy array.\r\n        #We also specify the statespace function so we can use the direct method.\r\n        #This one is defined immediately for general n.\r\n        def __init__(self,m,M,n,direct=True):\r\n            super(randomWalkNumpy, self).__init__(direct=direct)\r\n            self.initialState = m*np.ones(n,dtype=int)\r\n            self.n = n\r\n            self.m = m\r\n            self.M = M\r\n            self.uprate = 1.0\r\n            self.downrate = 1.0        \r\n           \r\n            #It is useful to define the variable 'events' for the the transition function.\r\n            #The possible events are 'move up' or 'move down' in one of the random walks.\r\n            #The rates of these events are given in 'eventRates'.\r\n            self.events = np.vstack((np.eye(n,dtype=int),-np.eye(n,dtype=int)))\r\n            self.eventRates = np.array([self.uprate]*n+[self.downrate]*n)  \r\n        \r\n        def transition(self,state):\r\n            #First check for the current state which of the 'move up' and 'move down' events are possible.\r\n            up = state < self.M\r\n            down = state > self.m\r\n            possibleEvents = np.concatenate((up,down))  #Combine into one boolean array. \r\n            \r\n            #The possible states after the transition follow by adding the possible 'move up'/'move down' events to the current state.\r\n            newstates = state+self.events[possibleEvents]\r\n            rates = self.eventRates[possibleEvents]\r\n            return newstates,rates   \r\n            \r\n      def statespace(self):\r\n          #Each random walk can be in a state between m and M.\r\n          #The function partition() gives all partitions of integers between min_range and max_range.\r\n          min_range = [self.m]*self.n\r\n          max_range = [self.M]*self.n\r\n          return partition(min_range,max_range) \r\n        \r\n\r\nNow we initialize `n=2` random walks between `m=0` and `M=2` and print the stationary distribution.\r\n\r\n::\r\n\r\n    mc = randomWalkNumpy(0,2,n=2)\r\n    mc.computePi('linear')\r\n    mc.printPi()\r\n    \r\n    [0 0] 0.111111111111\r\n    [1 0] 0.111111111111\r\n    [2 0] 0.111111111111\r\n    [0 1] 0.111111111111\r\n    [1 1] 0.111111111111\r\n    [2 1] 0.111111111111\r\n    [0 2] 0.111111111111\r\n    [1 2] 0.111111111111\r\n    [2 2] 0.111111111111\r\n\r\nWe could also solve much larger models. The example below has random walks in 5 dimensions with 100.000 states. For these larger models, it is often better to use the power method. The linear algebra solver may run into memory problems. \r\n\r\n::\r\n\r\n    mc = randomWalkNumpy(0,9,n=5)\r\n    mc.computePi('power')\r\n\r\nOn a dual core computer from 2006, the rate matrix and `pi` can be calculated within 10 seconds. \r\n\r\n----------------\r\nChanges in v0.22\r\n----------------\r\n* Added documentation for the `markovChain` class and all its methods, including examples. \r\n* Added the function `partition` that can be used to determine the state space when states are consists of all integers between ranges. The optional parameter `max_sum` can be specified if the state vectors should sum up to less than `max_sum` (useful in some queueing and inventory applications).  \r\n* Fixed an error when calling `krylovMethod()`, `linearMethod()` and `eigenMethod()` on Markov chains with one state.\r\n* Included a workaround for an error when calling `eigenMethod()` on Markov chains with two states.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/gvanderheide/discreteMarkovChain", "keywords": "Markov chain stochastic stationary steady state", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "discreteMarkovChain", "package_url": "https://pypi.org/project/discreteMarkovChain/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/discreteMarkovChain/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/gvanderheide/discreteMarkovChain"}, "release_url": "https://pypi.org/project/discreteMarkovChain/0.22/", "requires_dist": null, "requires_python": null, "summary": "Solve Markov chains with a discrete state space.", "version": "0.22", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>While for statistical and scientific programming languages such as R various packages are available for analyzing Markov chains, equivalent packages in Python are rather scarce. This discreteMarkovChain package for Python addresses the problem of obtaining the steady state distribution of a Markov chain, also known as the stationary distribution, limiting distribution or invariant measure. The package is for Markov chains with discrete and finite state spaces, which are most commonly encountered in practical applications.</p>\n<p>This package is based on numpy and scipy for efficient computations and limited use of resources. Markov chains with several million states can be solved. The package introduces the <cite>markovChain</cite> class which has the following features.</p>\n<ul>\n<li>States can be either integers or vectors of integers.</li>\n<li>Steady state distributions can be calculated for continous time Markov chains (CTMC) as well as discrete time Markov chains (DTMC).</li>\n<li>The user can either manually specify the probability/rate matrix of the Markov chain, or let the program do this automatically using an indirect or direct method.</li>\n<li><dl>\n<dt>The indirect method requires the user to specify an initial state and transition function (giving for each state the reachable states and their probabilities/rates).</dt>\n<dd><ul>\n<li>By repeatedly calling the transition function on unvisited states, the state space and the probability matrix are built up automatically.</li>\n<li>This makes it easy to implement your own Markov chains!</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>The direct method requires the user to specify a transition function and a function that gives the complete state space.</dt>\n<dd><ul>\n<li>While the implementation is typically more complex, this may have some computational advantage over the indirect method for large state spaces with vector states.</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li><dl>\n<dt>The steady state distribution can be calculated by a method of choice:</dt>\n<dd><ul>\n<li>The power method,</li>\n<li>Solving a system of linear equations,</li>\n<li>Determing the first left eigenvector,</li>\n<li>Searching in Krylov subspace.</li>\n</ul>\n</dd>\n</dl>\n</li>\n<li>Checks are included to see whether all states in the Markov chain are connected.</li>\n<li>Memory consumption is reduced by using sparse matrices.</li>\n</ul>\n<p>When the user calls a certain solution method, the <cite>markovChain</cite> object gets the attribute <cite>pi</cite> which specifies the steady state probability of each state. When the user uses the direct or indirect method, the object gets the <cite>mapping</cite> attribute which is a dictionary that links each index of <cite>pi</cite> with a corresponding state. Using the <cite>mapping</cite> and <cite>pi</cite>, it becomes simple to calculate performance measures for your Markov chain, such as the average cost per time unit or the number of blocked customers in a queue with blocking.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p>The package can be installed with the command</p>\n<pre>pip install discreteMarkovChain\n</pre>\n<p>or by downloading the source distribution and installing manually with</p>\n<pre>python setup.py install\n</pre>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<p>The <cite>markovChain</cite> class can be used to initialize your own Markov chains. We import it by using</p>\n<pre>from discreteMarkovChain import markovChain\n</pre>\n<p>First, lets consider a simple Markov chain with two states, where we already know the probability matrix <cite>P</cite>.</p>\n<pre>P = np.array([[0.5,0.5],[0.6,0.4]])\nmc = markovChain(P)\nmc.computePi('linear') #We can also use 'power', 'krylov' or 'eigen'\nprint(mc.pi)\n</pre>\n<p>We get the following steady state probabilities:</p>\n<pre>[ 0.54545455  0.45454545]\n</pre>\n<p>Now we show an example of a one-dimensional random walk in continuous time between integers <cite>m</cite> and <cite>M</cite>. We move up and down with rates 1. We will use the indirect method to determine the rate matrix for us automatically. The indirect method is rather flexible, and allows the transition function to return a dictionary with reachable states and rates. We first introduce our <cite>randomWalk</cite> class.</p>\n<pre>class randomWalk(markovChain):\n    #A random walk where we move up and down with rate 1.0 in each state between bounds m and M.\n    #For the transition function to work well, we define some class variables in the __init__ function.\n    def __init__(self,m,M):\n        super(randomWalk, self).__init__() #always use this as first line when creating your own __init__\n        self.initialState = m\n        self.m = m\n        self.M = M\n        self.uprate = 1.0\n        self.downrate = 1.0\n\n    def transition(self,state):\n        #Specify the reachable states from state and their rates.\n        #A dictionary is extremely easy here!\n        rates = {}\n        if self.m &lt; state &lt; self.M:\n            rates[state+1] = self.uprate\n            rates[state-1] = self.downrate\n        elif state == self.m:\n            rates[state+1] = self.uprate\n        elif state == self.M:\n            rates[state-1] = self.downrate\n        return rates\n</pre>\n<p>Now we initialize the random walk with some values for <cite>m</cite> and <cite>M</cite> and calculate the steady-state vector <cite>pi</cite>.</p>\n<pre>mc = randomWalk(0,5)\nmc.computePi()\nmc.printPi()\n</pre>\n<p>The stationary probabilities are given below.</p>\n<pre>0 0.166666666667\n1 0.166666666667\n2 0.166666666667\n3 0.166666666667\n4 0.166666666667\n5 0.166666666667\n</pre>\n<p>Not unexpectedly, they are the same for each state. We can repeat this for a multi-dimensional random walk. Now we use the direct method. Here, we need to use a transition function returning numpy arrays and we need to define a function that calculates the state space.</p>\n<pre>from discreteMarkovChain import partition\n\nclass randomWalkNumpy(markovChain):\n    #Now we do the same thing with a transition function that returns a 2d numpy array.\n    #We also specify the statespace function so we can use the direct method.\n    #This one is defined immediately for general n.\n    def __init__(self,m,M,n,direct=True):\n        super(randomWalkNumpy, self).__init__(direct=direct)\n        self.initialState = m*np.ones(n,dtype=int)\n        self.n = n\n        self.m = m\n        self.M = M\n        self.uprate = 1.0\n        self.downrate = 1.0\n\n        #It is useful to define the variable 'events' for the the transition function.\n        #The possible events are 'move up' or 'move down' in one of the random walks.\n        #The rates of these events are given in 'eventRates'.\n        self.events = np.vstack((np.eye(n,dtype=int),-np.eye(n,dtype=int)))\n        self.eventRates = np.array([self.uprate]*n+[self.downrate]*n)\n\n    def transition(self,state):\n        #First check for the current state which of the 'move up' and 'move down' events are possible.\n        up = state &lt; self.M\n        down = state &gt; self.m\n        possibleEvents = np.concatenate((up,down))  #Combine into one boolean array.\n\n        #The possible states after the transition follow by adding the possible 'move up'/'move down' events to the current state.\n        newstates = state+self.events[possibleEvents]\n        rates = self.eventRates[possibleEvents]\n        return newstates,rates\n\n  def statespace(self):\n      #Each random walk can be in a state between m and M.\n      #The function partition() gives all partitions of integers between min_range and max_range.\n      min_range = [self.m]*self.n\n      max_range = [self.M]*self.n\n      return partition(min_range,max_range)\n</pre>\n<p>Now we initialize <cite>n=2</cite> random walks between <cite>m=0</cite> and <cite>M=2</cite> and print the stationary distribution.</p>\n<pre>mc = randomWalkNumpy(0,2,n=2)\nmc.computePi('linear')\nmc.printPi()\n\n[0 0] 0.111111111111\n[1 0] 0.111111111111\n[2 0] 0.111111111111\n[0 1] 0.111111111111\n[1 1] 0.111111111111\n[2 1] 0.111111111111\n[0 2] 0.111111111111\n[1 2] 0.111111111111\n[2 2] 0.111111111111\n</pre>\n<p>We could also solve much larger models. The example below has random walks in 5 dimensions with 100.000 states. For these larger models, it is often better to use the power method. The linear algebra solver may run into memory problems.</p>\n<pre>mc = randomWalkNumpy(0,9,n=5)\nmc.computePi('power')\n</pre>\n<p>On a dual core computer from 2006, the rate matrix and <cite>pi</cite> can be calculated within 10 seconds.</p>\n</div>\n<div id=\"changes-in-v0-22\">\n<h2>Changes in v0.22</h2>\n<ul>\n<li>Added documentation for the <cite>markovChain</cite> class and all its methods, including examples.</li>\n<li>Added the function <cite>partition</cite> that can be used to determine the state space when states are consists of all integers between ranges. The optional parameter <cite>max_sum</cite> can be specified if the state vectors should sum up to less than <cite>max_sum</cite> (useful in some queueing and inventory applications).</li>\n<li>Fixed an error when calling <cite>krylovMethod()</cite>, <cite>linearMethod()</cite> and <cite>eigenMethod()</cite> on Markov chains with one state.</li>\n<li>Included a workaround for an error when calling <cite>eigenMethod()</cite> on Markov chains with two states.</li>\n</ul>\n</div>\n\n          </div>"}, "last_serial": 2078101, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "3646eab00cb2d0dfe51fe945a2ac0bc0", "sha256": "047787fdc30ad4919b987cea982536d45496f00efeba2c3241f73ebfe54579fe"}, "downloads": -1, "filename": "discreteMarkovChain-0.1.tar.gz", "has_sig": false, "md5_digest": "3646eab00cb2d0dfe51fe945a2ac0bc0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8761, "upload_time": "2016-04-07T15:04:24", "upload_time_iso_8601": "2016-04-07T15:04:24.285457Z", "url": "https://files.pythonhosted.org/packages/3e/4a/02fe8b0bbb6a403417db5b4f5af52e6ac125311ca452ab81da32f1ca4160/discreteMarkovChain-0.1.tar.gz", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec838ea23177c1a3a6b9a576caa90269", "sha256": "46d4ecdfac2ccf14c242a741e4624764889a7d4919c27deb45063e49faffaecb"}, "downloads": -1, "filename": "discreteMarkovChain-0.1.zip", "has_sig": false, "md5_digest": "ec838ea23177c1a3a6b9a576caa90269", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12959, "upload_time": "2016-04-07T15:12:52", "upload_time_iso_8601": "2016-04-07T15:12:52.620965Z", "url": "https://files.pythonhosted.org/packages/1f/f9/39a667ed1a6b657c3d3002b0f55f910fcd79d5482bb6055c3b4c1375648c/discreteMarkovChain-0.1.zip", "yanked": false}], "0.11": [{"comment_text": "", "digests": {"md5": "9e9b4e8c13ca9d8395e7a06c7a791560", "sha256": "898701d4b6fce97c69b643196f56a7097d55051bb16c7f3df714d40ab6e729f6"}, "downloads": -1, "filename": "discreteMarkovChain-0.11.tar.gz", "has_sig": false, "md5_digest": "9e9b4e8c13ca9d8395e7a06c7a791560", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11368, "upload_time": "2016-04-09T14:40:02", "upload_time_iso_8601": "2016-04-09T14:40:02.306933Z", "url": "https://files.pythonhosted.org/packages/36/cb/4055c8c424d6af179d0786f0e910d2fe8b6f36b41ecc4805cf99ad5bbae8/discreteMarkovChain-0.11.tar.gz", "yanked": false}, {"comment_text": "", "digests": {"md5": "21ad7f7074f029abeb9effd4607e20bc", "sha256": "18978e43cde3c522b7d213d702f02092deac5871b404067b7810003862e83f42"}, "downloads": -1, "filename": "discreteMarkovChain-0.11.zip", "has_sig": false, "md5_digest": "21ad7f7074f029abeb9effd4607e20bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19463, "upload_time": "2016-04-09T14:40:25", "upload_time_iso_8601": "2016-04-09T14:40:25.006950Z", "url": "https://files.pythonhosted.org/packages/e3/7a/7c75a81f86a31afceeef994fb230d8d4faba127a0c7f4f55ed88e42d98d4/discreteMarkovChain-0.11.zip", "yanked": false}], "0.22": [{"comment_text": "", "digests": {"md5": "f23fde03fa4dd7eb73b26aadfd01b8d9", "sha256": "6893a74275535baaeabda074a5dec030e916e39b1b5c588580617b218a396302"}, "downloads": -1, "filename": "discreteMarkovChain-0.22-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f23fde03fa4dd7eb73b26aadfd01b8d9", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 20031, "upload_time": "2016-04-22T12:01:01", "upload_time_iso_8601": "2016-04-22T12:01:01.917741Z", "url": "https://files.pythonhosted.org/packages/77/85/d1d2e71296f9cd4f5d8d1e2c198dcb44bbc056722351ca24e70b3c45b090/discreteMarkovChain-0.22-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "359ba96dcb82df1ab69bd6b6223e0cad", "sha256": "862b0c21daaf29a5fd289f23e7da87963a18a164e18da8f5b7d33f3803dd1649"}, "downloads": -1, "filename": "discreteMarkovChain-0.22.tar.gz", "has_sig": false, "md5_digest": "359ba96dcb82df1ab69bd6b6223e0cad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14886, "upload_time": "2016-04-22T12:00:40", "upload_time_iso_8601": "2016-04-22T12:00:40.200253Z", "url": "https://files.pythonhosted.org/packages/34/4f/53f55fdfba4181fd7cca2f09f38e33959b981f792da004d2bb00aa7f1383/discreteMarkovChain-0.22.tar.gz", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d4e5453e8c045d763e8d5dd26e754e6", "sha256": "894c3247819ee1884536007bfbeb39e7f076ecfab1bfc56ba632a3fb6f5c6734"}, "downloads": -1, "filename": "discreteMarkovChain-0.22.zip", "has_sig": false, "md5_digest": "0d4e5453e8c045d763e8d5dd26e754e6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24233, "upload_time": "2016-04-22T12:00:49", "upload_time_iso_8601": "2016-04-22T12:00:49.792050Z", "url": "https://files.pythonhosted.org/packages/57/93/25b0040a5482e9c7117001c5988c83270be8c2041a65ca9312a886b064d4/discreteMarkovChain-0.22.zip", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f23fde03fa4dd7eb73b26aadfd01b8d9", "sha256": "6893a74275535baaeabda074a5dec030e916e39b1b5c588580617b218a396302"}, "downloads": -1, "filename": "discreteMarkovChain-0.22-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f23fde03fa4dd7eb73b26aadfd01b8d9", "packagetype": "bdist_wheel", "python_version": "2.7", "requires_python": null, "size": 20031, "upload_time": "2016-04-22T12:01:01", "upload_time_iso_8601": "2016-04-22T12:01:01.917741Z", "url": "https://files.pythonhosted.org/packages/77/85/d1d2e71296f9cd4f5d8d1e2c198dcb44bbc056722351ca24e70b3c45b090/discreteMarkovChain-0.22-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "359ba96dcb82df1ab69bd6b6223e0cad", "sha256": "862b0c21daaf29a5fd289f23e7da87963a18a164e18da8f5b7d33f3803dd1649"}, "downloads": -1, "filename": "discreteMarkovChain-0.22.tar.gz", "has_sig": false, "md5_digest": "359ba96dcb82df1ab69bd6b6223e0cad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14886, "upload_time": "2016-04-22T12:00:40", "upload_time_iso_8601": "2016-04-22T12:00:40.200253Z", "url": "https://files.pythonhosted.org/packages/34/4f/53f55fdfba4181fd7cca2f09f38e33959b981f792da004d2bb00aa7f1383/discreteMarkovChain-0.22.tar.gz", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d4e5453e8c045d763e8d5dd26e754e6", "sha256": "894c3247819ee1884536007bfbeb39e7f076ecfab1bfc56ba632a3fb6f5c6734"}, "downloads": -1, "filename": "discreteMarkovChain-0.22.zip", "has_sig": false, "md5_digest": "0d4e5453e8c045d763e8d5dd26e754e6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24233, "upload_time": "2016-04-22T12:00:49", "upload_time_iso_8601": "2016-04-22T12:00:49.792050Z", "url": "https://files.pythonhosted.org/packages/57/93/25b0040a5482e9c7117001c5988c83270be8c2041a65ca9312a886b064d4/discreteMarkovChain-0.22.zip", "yanked": false}], "timestamp": "Fri May  8 00:38:09 2020"}