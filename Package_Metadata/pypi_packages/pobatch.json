{"info": {"author": "Samapriya Roy", "author_email": "samapriya.roy@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: GIS"], "description": "# pobatch: porder wrapper for Ordersv2 Batch Client\r\n![35ffb6a5-2b6f-4bd0-92b9-c974f0ede76e_200x200](https://user-images.githubusercontent.com/6677629/58644819-10500980-82d0-11e9-843b-9eea7f735be1.png) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3376975.svg)](https://doi.org/10.5281/zenodo.3376975)\r\n[![PyPI version](https://badge.fury.io/py/pobatch.svg)](https://badge.fury.io/py/pobatch)\r\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\r\n\r\n\r\n**This tool is an add-on to the porder tool, so [read about the project here](https://github.com/samapriya/porder) and make sure you take additional installation steps before starting with this**. This tool fits the need to order large orders in terms of spatial and temporal grids, splitting them into smaller manageable orders while keeping in mind the concurrency limits(number of orders you can place simultaneously). In this case, the user sets a concurrency limit, and the tool automatically checks and waits before placing the next order. The tool can also estimate order size in terms of bytes per order download. The last step is to perform the same, download using porder's downloaders and an order list as created by multiorder tools. The design of this tool is kept simple, meaning you are relying on mixed use or **porder** and **pobatch** to perform these operations. [Ordersv2 is the next iteration of Planet's API](https://developers.planet.com/docs/orders/) in getting Analysis Ready Data (ARD) delivered to you. Orders v2 allows you to improved functionality in this domain, including the capability to submit an number of images in a batch order, and perform operations such as top of atmospheric reflectance, compression, coregistration and also enhanced notifications such as email and webhooks.\r\n\r\n**Please note: This tool is in no way an official tool or Planet offering, but is a personal project created and maintained by Samapriya Roy**\r\n\r\nIf you find this tool useful, star and cite it as below\r\n\r\n```\r\nSamapriya Roy. (2019, August 26). samapriya/pobatch: pobatch: porder wrapper for Ordersv2 Batch Client (Version 0.0.7). Zenodo.\r\nhttp://doi.org/10.5281/zenodo.3376975\r\n```\r\n\r\n## Table of contents\r\n* [Installation](#installation)\r\n* [Getting started](#getting-started)\r\n* [porder wrapper for Ordersv2 Batch Client](#porder-wrapper-for-Ordersv2-Batch-Client)\r\n   * [version](#version)\r\n    * [quota](#quota)\r\n    * [idlist](#idlist)\r\n    * [idsplit](#idsplit)\r\n    * [multiorder](#multiorder)\r\n    * [status](#status)\r\n    * [stats](#stats)\r\n    * [ordsize](#ordsize)\r\n    * [downloader](#downloader)\r\n    * [Example Setup](#example-setup)\r\n\r\n## Installation\r\nThis assumes that you have native python & pip installed in your system, you can test this by going to the terminal (or windows command prompt) and trying\r\n\r\n```python``` and then ```pip list```\r\n\r\nIf you get no errors and you have python 2.7.14 or higher you should be good to go. Please note that I have tested this only on python 2.7.15 but it should run on python 3.\r\n\r\nShapely is notoriously tricky as a library to install on windows machines so follow the steps mentioned from [Shapely\u2019s PyPI package page](https://pypi.org/project/Shapely/). You can download and install from the [Unofficial Wheel files from here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#shapely) download depending on the python version you have. You will get a wheel file or a file ending with .whl. You can now simply browse to the folder or migrate to it in your command prompt, for example in my case I was running Python 2.7.15 and win32 version so the command was\r\n\r\n```pip install Shapely-1.6.4.post1-cp27-cp27m-win32.whl```\r\n\r\nOr you can use [anaconda to install](https://conda-forge.github.io/). Again, both of these options are mentioned on [Shapely\u2019s Official PyPI page](https://pypi.org/project/Shapely/). **Fiona** is a recommended install used by the simplify tool, but it is not necessary. You can find installation instructions [here](https://pypi.org/project/Fiona/1.8.6/#description)\r\n\r\nOnce you have shapely configured. To install **pobatch: porder wrapper for Ordersv2 Batch Client** you can install using two methods\r\n\r\n```pip install pobatch```\r\n\r\non Ubuntu I found it helps to specify the pip type and use sudo\r\n\r\n```sudo pip2 install pobatch or sudo pip3 install pobatch```\r\n\r\nor you can also try\r\n\r\n```\r\ngit clone https://github.com/samapriya/pobatch.git\r\ncd pobatch\r\npython setup.py install\r\n```\r\nFor linux use sudo or --user.\r\n\r\nInstallation is an optional step; the application can also be run directly by executing pobatch.py script. The advantage of having it installed is being able to execute pobatch as any command line tool. I recommend installation within a virtual environment. If you don't want to install, browse into the pobatch folder and try ```python pobatch.py``` to get to the same result.\r\n\r\n\r\n## Getting started\r\n\r\nMake sure you initialized planet client by typing ```planet init``` or ```export``` or ```set PL_API_KEY=Your API Key``` As usual, to print help:\r\n\r\n```\r\nusage: pobatch [-h]\r\n               {version,quota,idlist,idsplit,bundles,multiorder,status,stats,ordsize,downloader}\r\n               ...\r\n\r\nporder wrapper for Ordersv2 Batch Client\r\n\r\npositional arguments:\r\n  {version,quota,idlist,idsplit,bundles,multiorder,status,stats,ordsize,downloader}\r\n    version             Prints porder version and exists\r\n    quota               Prints your Planet Quota Details\r\n    idlist              Get idlist using geometry & filters\r\n    idsplit             Splits ID list incase you want to run them in small\r\n                        batches\r\n    bundles             Check bundles of assets for given item type\r\n    multiorder          Place multiple orders based on idlists in folder\r\n    status              Check order status on submitted orders\r\n    stats               Prints number of orders queued and running for org &\r\n                        user\r\n    ordsize             Estimates total download size for each completed\r\n                        order(Takes times)\r\n    downloader          Download using order url list\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n```\r\n\r\nTo obtain help for a specific functionality, simply call it with _help_ switch, e.g.: `pobatch idsplit -h`. If you didn't install pobatch, then you can run it just by going to *pobatch* directory and running `python pobatch.py [arguments go here]`\r\n\r\n## porder wrapper for Ordersv2 Batch Client\r\nThe tool is built as a wrapper around the [porder tool](https://github.com/samapriya/porder). The **porder tool** contains additionally useful tools such as convert shapefile to geojson, base64 encode your gcs credentials, simplify your geometry to fit the 500 vertices requirements and so on. So the idea is to use both of those tools in conjunction and make desired pipelines as needed. This tools is created to give the user some control over long and tedious order queue and implement push and pull of data in a batch manner.\r\n\r\n### version\r\nThis prints the tool version and escapes. Simple use would be\r\n\r\n```\r\npobatch version\r\n```\r\n\r\n### quota\r\nJust a simple tool to print your planet subscription quota quickly.\r\n\r\n```\r\npobatch quota\r\n```\r\n\r\n### idlist\r\nCreate an idlist for your geometry based on some basic filters, including geometry, start and end date and cloud cover. If no cloud cover is specified, everything from 0 to 100% cloud cover is included. For now the tool can handle geojson,json and kml files. The output is a csv file with ids. The tool also allows you to make sure you get percentage overlap, when selecting image, for clip operations adjust it accordingly (usally --ovp 1 for orders not to fail during clip). The tool now also prints estimated area in Square kilometers for the download and estimated area if you clipped your area with the geometry you are searching (just estimates).\r\n\r\n**I have changed the setup to now do the following two things**\r\n\r\n* The number option is optional, so it can look for all images in the time range, but be careful if the area is too large, _use at own risk_. A better option is to supply the number.\r\n\r\n* It is possible to often forget about the different asset types, so you can now not pass an item and the script will return every possible type of asset for each item type depending on the bundle.\r\n\r\n```\r\npobatch idlist -h\r\nusage: pobatch idlist [-h] --input INPUT --start START --end END --item ITEM\r\n                      [--asset ASSET] --outfile OUTFILE [--cmin CMIN]\r\n                      [--cmax CMAX] [--number NUMBER] [--overlap OVERLAP]\r\n                      [--filters FILTERS [FILTERS ...]]\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n\r\nRequired named arguments.:\r\n  --input INPUT         Input geometry file for now geojson/json/kml\r\n  --start START         Start date in format YYYY-MM-DD\r\n  --end END             End date in format YYYY-MM-DD\r\n  --item ITEM           Item Type PSScene4Band|PSOrthoTile|REOrthoTile etc\r\n  --asset ASSET         Asset Type analytic, analytic_sr,visual etc\r\n  --outfile OUTFILE     Output csv file\r\n\r\nOptional named arguments:\r\n  --cmin CMIN           Minimum cloud cover\r\n  --cmax CMAX           Maximum cloud cover\r\n  --number NUMBER       Total number of assets, give a large number if you are\r\n                        not sure\r\n  --overlap OVERLAP     Percentage overlap of image with search area range\r\n                        between 0 to 100\r\n  --filters FILTERS [FILTERS ...]\r\n                        Add an additional string or range filter\r\n```\r\n\r\nA simple setup would be the following for 800 max item ids and an overlap of 5% with the geometry we pass to the filter\r\n```\r\npobatch idlist --input \"path to geometry.geojson\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic_sr\" --number 800 --outfile \"path to idlist.csv file\" --overlap 5\r\n```\r\n\r\nTo run an experiment to add additional filter, you can now pass an additional string or range filter or both flag for string and range filters, a setup would be. The additional filters are optional\r\n\r\n```\r\npobatch idlist --input \"Path to geojson file\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"Path to idlist.csv\" --filters range:clear_percent:55:100 --number 20\r\n\r\npobatch idlist --input \"Path to geojson file\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"Path to idlist.csv\" --filters string:satellite_id:\"1003,1006,1012,1020,1038\" --number 20\r\n\r\npobatch idlist --input \"Path to geojson file\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"Path to idlist.csv\" --filters string:satellite_id:\"1003,1006,1012,1020,1038\" range:clear_percent:55:100 --number 20\r\n```\r\n\r\nThe idlist tool can now use a multipolygon and iteratively look for scenes.\r\n\r\n### idsplit\r\nThis allows you to split your idlist into small csv files to created batches of orders.\r\n\r\n```\r\nusage: pobatch idsplit [-h] [--idlist IDLIST] [--lines LINES] [--local LOCAL]\r\n\r\noptional arguments:\r\n  -h, --help       show this help message and exit\r\n  --idlist IDLIST  Idlist txt file to split\r\n  --lines LINES    Maximum number of lines in each split files\r\n  --local LOCAL    Output folder where split files will be exported\r\n```\r\n\r\nA simple setup would be\r\n```\r\npobatch idsplit --idlist \"path to idlist.csv\" --lines \"number of lines in each idlist\" --local \"folder path to export split id lists\"\r\n```\r\n\r\n### multiorder\r\nThis tool allows you to actually place the order using the idlist that you created earlier. the ```--op``` argument allows you to take operations, delivery and notifications in a sequence for example ```--op toar clip email``` performs Top of Atmospheric reflectance, followed by clipping to your geometry and send you an email notification once the order has completed, failed or had any any change of status. An important changes is the concept of passing bundles instead of using assets. Bundles are predefined meaning all assets in a bundle are not available for an item your attempt at downloading that attempt will fail.\r\n\r\nFor example if an item id '20181227_125554_0f4c' does not have surface reflectance asset type. So if you try to download this using bundle type analytic_sr_udm2 it will not work, similary if you order an item where a specific operation cannot be performed for example if you order visual and then try to do bandmath with four bands. These examples and more are where **fallback bundles** come in handy. Think of this as providing a list of bundles to keep trying if one bundle type fails. The priority goes left to right. You can provide comma seperated fallback bundles for example as\r\n\r\n```analytic_sr_udm2,analytic``` instead of ```analytic_sr_udm2``` to avoid certain items from failing to download.\r\n\r\nThe list of operations for the ```--op``` are below and ** the order of these operations is important**\r\n\r\nclip|toar|comp\r\n                        osite|zip|zipall|compression|projection|kernel|aws|azu\r\n                        re|gcs|email <Choose indices from>:\r\n                        ndvi|gndvi|bndvi|ndwi|tvi|osavi|evi2|msavi2|sr\r\n\r\n<center>\r\n\r\nop                | description                                                                   |\r\n------------------|-------------------------------------------------------------------------------|\r\nclip | Clip imagery can handle single and multi polygon verify or create geojson.io\r\ntoar | Top of Atmosphere Reflectance imagery generated for imagery\r\nharmonize| Harmonize Dove R (instrument type PS2.SD) data to classic dove (instrument type PS)\r\ncomposite | Composite number of images in a given order\r\nzip | Zip bundles together and creates downloads (each asset has a single bundle so multiple zip files)\r\nzipall | Create a single zip file containing all assets\r\ncompression | Use image compression\r\nprojection | Reproject before downloaing image\r\naws | Option called to specify delivery to AWS\r\nazure | Option called to specify delivery to AZURE\r\ngcs | Option called to specify delivery to GCS\r\nemail | Email notification to your planet registered email\r\n\r\n</center>\r\n\r\n\r\nYou can now add some predefined indices for PlanetScope 4 band items with a maximum of 5 indices for a single setup . This is experimental. The list of indices include\r\n\r\n<center>\r\n\r\nIndex             | Source                                                                        |\r\n------------------|-------------------------------------------------------------------------------|\r\nSimple ratio (SR) | [Jordan 1969](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.2307/1936256)\r\nNormalized Difference Vegetation Index (NDVI) | [Rouse et al 1973](https://ntrs.nasa.gov/search.jsp?R=19740022614)\r\nGreen Normalized Difference Index (GNDVI) | [Gitelson et al 1996](https://www.sciencedirect.com/science/article/abs/pii/S0034425796000727)\r\nBlue Normalized Difference Vegetation Index (BNDVI) | [Wang et al 2007](https://www.sciencedirect.com/science/article/pii/S1672630807600274)\r\nTransformed Vegetation Index (TVI) | [Broge and Leblanc 2000](https://www.sciencedirect.com/science/article/abs/pii/S0034425700001978)\r\nOptimized Soil Adjusted Vegetation Index (OSAVI) | [Rondeaux et al 1996](https://www.sciencedirect.com/science/article/abs/pii/0034425795001867)\r\nEnhanced Vegetation Index (EVI2) | [Jian et al 2008](https://www.sciencedirect.com/science/article/abs/pii/S0034425708001971)\r\nNormalized Difference Water Index (NDWI) | [McFeeters 1996](https://www.tandfonline.com/doi/abs/10.1080/01431169608948714)\r\nModified Soil-adjusted Vegetation Index v2 (MSAVI2) | [Qi 1994](https://www.sciencedirect.com/science/article/abs/pii/0034425794901341?via%3Dihub)\r\n\r\n</center>\r\n\r\nThis tool makes use of the FIFO (first in first out) concept in queue implementation in python. It checks to see if you have reached your concurrent order limit and then waits for 5 minutes before trying to place the order again iteratively.\r\n\r\n```\r\npobatch multiorder -h\r\nusage: pobatch multiorder [-h] --infolder INFOLDER --outfile OUTFILE\r\n                          --errorlog ERRORLOG --max MAX --item ITEM --bundle\r\n                          BUNDLE [--sid SID] [--boundary BOUNDARY]\r\n                          [--projection PROJECTION] [--kernel KERNEL]\r\n                          [--compression COMPRESSION] [--aws AWS]\r\n                          [--azure AZURE] [--gcs GCS] [--op OP [OP ...]]\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n\r\nRequired named arguments.:\r\n  --infolder INFOLDER   Folder with multiple order list\r\n  --outfile OUTFILE     CSV file with list of order urls\r\n  --errorlog ERRORLOG   Path to idlist it could not submit,error message log\r\n                        csv file\r\n  --item ITEM           Item Type PSScene4Band|PSOrthoTile|REOrthoTile etc\r\n  --bundle BUNDLE       Bundle Type: analytic, analytic_sr,analytic_sr_udm2\r\n\r\nOptional named arguments:\r\n  --sid SID             Subscription ID\r\n  --boundary BOUNDARY   Boundary/geometry for clip operation geojson|json|kml\r\n  --projection PROJECTION\r\n                        Projection for reproject operation of type \"EPSG:4326\"\r\n  --kernel KERNEL       Resampling kernel used \"near\", \"bilinear\", \"cubic\",\r\n                        \"cubicspline\", \"lanczos\", \"average\" and \"mode\"\r\n  --compression COMPRESSION\r\n                        Compression type used for tiff_optimize tool,\r\n                        \"lzw\"|\"deflate\"\r\n  --aws AWS             AWS cloud credentials config yml file\r\n  --azure AZURE         Azure cloud credentials config yml file\r\n  --gcs GCS             GCS cloud credentials config yml file\r\n  --op OP [OP ...]      Add operations, delivery & notification clip|toar|comp\r\n                        osite|zip|zipall|compression|projection|kernel|aws|azu\r\n                        re|gcs|email <Choose indices from>:\r\n                        ndvi|gndvi|bndvi|ndwi|tvi|osavi|evi2|msavi2|sr\r\n```\r\n\r\n### status\r\nThe status tool takes the order list created from the multiorder tool and simply queries the current status of the orders in the list. It prints out the index, order name and order status and is for a quick check on multiple orders.\r\n\r\n```\r\nusage: pobatch status [-h] [--orderlist ORDERLIST]\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  --orderlist ORDERLIST\r\n                        Orderlist created earlier\r\n```\r\n\r\n### stats\r\nThe tool allows you to check on number of running and queued orders for both organization and user level. Using this is simple\r\n\r\n```\r\npobatch stats\r\n```\r\n\r\noutput should look like this:\r\n\r\n```\r\nChecking on all running orders...\r\nTotal queued order for organization: 0\r\nTotal running orders for organization: 1\r\n\r\nTotal queued orders for user: 0\r\nTotal running orders for user: 0\r\n```\r\n\r\n### ordsize\r\nThe ordersize tool allows you to print the order sizes in human readable format like KB, MB, GB.\r\n\r\n```\r\nusage: pobatch ordsize [-h] --infile INFILE\r\n\r\noptional arguments:\r\n  -h, --help       show this help message and exit\r\n\r\nRequired named arguments.:\r\n  --infile INFILE  CSV file with order list\r\n```\r\n\r\n### downloader\r\nThe tool now allows you to estimate the total download size for a specific order.\r\n\r\n```\r\nusage: pobatch downloader [-h] --infile INFILE --folder FOLDER --method METHOD\r\n\r\noptional arguments:\r\n  -h, --help       show this help message and exit\r\n\r\nRequired named arguments.:\r\n  --infile INFILE  CSV file with order list\r\n  --folder FOLDER  Local folder to save order files\r\n  --method METHOD  Method to be utilized for downloading\r\n                   download|multipart|multiproc\r\n```\r\n\r\n\r\n### Example Setup\r\n\r\n* Get idlist for geometry using porder (porder is installed as a dependency for this tool)\r\n\r\n```\r\npobatch idlist --input \"geometry file.geojson\" --start \"2018-01-01\" --end \"2019-02-01\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"path to idlist.csv\"\r\n```\r\n\r\n* Split idlist into smaller subparts\r\n\r\n```\r\npobatch idsplit --idlist \"idlist file created earlier\" --lines \"number of lines in split files\" --local \"folder where we save the split id files\"\r\n```\r\n\r\n* Now place order using idlists that you created. This requires you to set up a limit on the maximum number of concurrent orders you can place. This setups clips the image to a geometry, zips them and send you an email notification on completion.\r\n\r\n```\r\npobatch multiorder --infolder \"folder where we save the split id files\" --outfile \"path to an orderlist with order url\" --item \"PSScene4Band\" --asset \"analytic\" --boundary \"path to geometry.geojson\" --op clip zip email\r\n```\r\n\r\n* Let us quickly get the status of the orders placed.\r\n\r\n```\r\npobatch --orderlist \"Full path to the order list\"\r\n```\r\n\r\n* Let us now get the stats for our order number of order running and queuing for the organization and you as the user.\r\n\r\n```\r\npobatch stats\r\n```\r\n\r\n* Estimate order download size for each order (This is optional)\r\n\r\n```\r\npobatch ordsize --infile \"Path to order url list\"\r\n```\r\n\r\n* Finally download the order, and choose the download method (choose from sequential download or download| multipart download or multiproc or multiprocessing download)\r\n\r\n```\r\npobatch downloader --infile \"Path to order url list\" --folder \"download folder\" --method \"multipart\"\r\n```\r\n\r\n### Changelog\r\n\r\n**v0.0.8**\r\n* Cleaned multiorder tool now uses stats endpoint instead concurreny check.\r\n* Enhanced downloaders from porder v0.5.5 with much cleaner file check and download.\r\n* Added status tool to check status of orders placed and stats tool to check on running and queued orders.\r\n* General improvements to tool.\r\n\r\n**v0.0.7**\r\n* Added bundle and subscription id arguments to multiorder tool.\r\n* Updated idlist tool to handle multipolygon geometry better\r\n* General improvements.\r\n\r\n**v0.0.6**\r\n* Fixed bundles and removed deprecated bundle types.\r\n* Created errorlog if issues submitting orders\r\n* Now downloads both complete and partial order outputs.\r\n\r\n**v0.0.5**\r\n* Fixed issues with utf decoding\r\n* Logging and verbose call issue fixed\r\n* Now returns number of items found while searching using idlist\r\n\r\n**v0.0.4**\r\n* Added quota tool to main to prevent compatability issues\r\n* Fixed issues with handling with and without op orders\r\n* Added improvements to make shell runs function properly.\r\n\r\n**v0.0.3**\r\n* Added queue support to downloader for better handling order list\r\n* General improvements to overall tool\r\n\r\n\r\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/samapriya/pobatch", "keywords": "", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "pobatch", "package_url": "https://pypi.org/project/pobatch/", "platform": "", "project_url": "https://pypi.org/project/pobatch/", "project_urls": {"Homepage": "https://github.com/samapriya/pobatch"}, "release_url": "https://pypi.org/project/pobatch/0.0.8/", "requires_dist": ["requests (>=2.19.1)", "planet (>=1.2.3)", "porder (>=0.4.1)"], "requires_python": "", "summary": "porder wrapper for Ordersv2 Batch Client", "version": "0.0.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>pobatch: porder wrapper for Ordersv2 Batch Client</h1>\n<p><img alt=\"35ffb6a5-2b6f-4bd0-92b9-c974f0ede76e_200x200\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6b3206ef2bacc6beecae950e183784f7f8e19cb5/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f363637373632392f35383634343831392d31303530303938302d383264302d313165392d383433622d3965656137663733356265312e706e67\"> <a href=\"https://doi.org/10.5281/zenodo.3376975\" rel=\"nofollow\"><img alt=\"DOI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fff1b3a540e5b479ef802ec59b80bb4aa40aae6b/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e333337363937352e737667\"></a>\n<a href=\"https://badge.fury.io/py/pobatch\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c2079fb8c55bff201c18b5525c7d293a7341d3b9/68747470733a2f2f62616467652e667572792e696f2f70792f706f62617463682e737667\"></a>\n<a href=\"https://opensource.org/licenses/Apache-2.0\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b97ca76cf5d8fd16c7bc4731270e0bbe53df7aa1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667\"></a></p>\n<p><strong>This tool is an add-on to the porder tool, so <a href=\"https://github.com/samapriya/porder\" rel=\"nofollow\">read about the project here</a> and make sure you take additional installation steps before starting with this</strong>. This tool fits the need to order large orders in terms of spatial and temporal grids, splitting them into smaller manageable orders while keeping in mind the concurrency limits(number of orders you can place simultaneously). In this case, the user sets a concurrency limit, and the tool automatically checks and waits before placing the next order. The tool can also estimate order size in terms of bytes per order download. The last step is to perform the same, download using porder's downloaders and an order list as created by multiorder tools. The design of this tool is kept simple, meaning you are relying on mixed use or <strong>porder</strong> and <strong>pobatch</strong> to perform these operations. <a href=\"https://developers.planet.com/docs/orders/\" rel=\"nofollow\">Ordersv2 is the next iteration of Planet's API</a> in getting Analysis Ready Data (ARD) delivered to you. Orders v2 allows you to improved functionality in this domain, including the capability to submit an number of images in a batch order, and perform operations such as top of atmospheric reflectance, compression, coregistration and also enhanced notifications such as email and webhooks.</p>\n<p><strong>Please note: This tool is in no way an official tool or Planet offering, but is a personal project created and maintained by Samapriya Roy</strong></p>\n<p>If you find this tool useful, star and cite it as below</p>\n<pre><code>Samapriya Roy. (2019, August 26). samapriya/pobatch: pobatch: porder wrapper for Ordersv2 Batch Client (Version 0.0.7). Zenodo.\nhttp://doi.org/10.5281/zenodo.3376975\n</code></pre>\n<h2>Table of contents</h2>\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#getting-started\" rel=\"nofollow\">Getting started</a></li>\n<li><a href=\"#porder-wrapper-for-Ordersv2-Batch-Client\" rel=\"nofollow\">porder wrapper for Ordersv2 Batch Client</a>\n<ul>\n<li><a href=\"#version\" rel=\"nofollow\">version</a></li>\n<li><a href=\"#quota\" rel=\"nofollow\">quota</a></li>\n<li><a href=\"#idlist\" rel=\"nofollow\">idlist</a></li>\n<li><a href=\"#idsplit\" rel=\"nofollow\">idsplit</a></li>\n<li><a href=\"#multiorder\" rel=\"nofollow\">multiorder</a></li>\n<li><a href=\"#status\" rel=\"nofollow\">status</a></li>\n<li><a href=\"#stats\" rel=\"nofollow\">stats</a></li>\n<li><a href=\"#ordsize\" rel=\"nofollow\">ordsize</a></li>\n<li><a href=\"#downloader\" rel=\"nofollow\">downloader</a></li>\n<li><a href=\"#example-setup\" rel=\"nofollow\">Example Setup</a></li>\n</ul>\n</li>\n</ul>\n<h2>Installation</h2>\n<p>This assumes that you have native python &amp; pip installed in your system, you can test this by going to the terminal (or windows command prompt) and trying</p>\n<p><code>python</code> and then <code>pip list</code></p>\n<p>If you get no errors and you have python 2.7.14 or higher you should be good to go. Please note that I have tested this only on python 2.7.15 but it should run on python 3.</p>\n<p>Shapely is notoriously tricky as a library to install on windows machines so follow the steps mentioned from <a href=\"https://pypi.org/project/Shapely/\" rel=\"nofollow\">Shapely\u2019s PyPI package page</a>. You can download and install from the <a href=\"https://www.lfd.uci.edu/%7Egohlke/pythonlibs/#shapely\" rel=\"nofollow\">Unofficial Wheel files from here</a> download depending on the python version you have. You will get a wheel file or a file ending with .whl. You can now simply browse to the folder or migrate to it in your command prompt, for example in my case I was running Python 2.7.15 and win32 version so the command was</p>\n<p><code>pip install Shapely-1.6.4.post1-cp27-cp27m-win32.whl</code></p>\n<p>Or you can use <a href=\"https://conda-forge.github.io/\" rel=\"nofollow\">anaconda to install</a>. Again, both of these options are mentioned on <a href=\"https://pypi.org/project/Shapely/\" rel=\"nofollow\">Shapely\u2019s Official PyPI page</a>. <strong>Fiona</strong> is a recommended install used by the simplify tool, but it is not necessary. You can find installation instructions <a href=\"https://pypi.org/project/Fiona/1.8.6/#description\" rel=\"nofollow\">here</a></p>\n<p>Once you have shapely configured. To install <strong>pobatch: porder wrapper for Ordersv2 Batch Client</strong> you can install using two methods</p>\n<p><code>pip install pobatch</code></p>\n<p>on Ubuntu I found it helps to specify the pip type and use sudo</p>\n<p><code>sudo pip2 install pobatch or sudo pip3 install pobatch</code></p>\n<p>or you can also try</p>\n<pre><code>git clone https://github.com/samapriya/pobatch.git\ncd pobatch\npython setup.py install\n</code></pre>\n<p>For linux use sudo or --user.</p>\n<p>Installation is an optional step; the application can also be run directly by executing pobatch.py script. The advantage of having it installed is being able to execute pobatch as any command line tool. I recommend installation within a virtual environment. If you don't want to install, browse into the pobatch folder and try <code>python pobatch.py</code> to get to the same result.</p>\n<h2>Getting started</h2>\n<p>Make sure you initialized planet client by typing <code>planet init</code> or <code>export</code> or <code>set PL_API_KEY=Your API Key</code> As usual, to print help:</p>\n<pre><code>usage: pobatch [-h]\n               {version,quota,idlist,idsplit,bundles,multiorder,status,stats,ordsize,downloader}\n               ...\n\nporder wrapper for Ordersv2 Batch Client\n\npositional arguments:\n  {version,quota,idlist,idsplit,bundles,multiorder,status,stats,ordsize,downloader}\n    version             Prints porder version and exists\n    quota               Prints your Planet Quota Details\n    idlist              Get idlist using geometry &amp; filters\n    idsplit             Splits ID list incase you want to run them in small\n                        batches\n    bundles             Check bundles of assets for given item type\n    multiorder          Place multiple orders based on idlists in folder\n    status              Check order status on submitted orders\n    stats               Prints number of orders queued and running for org &amp;\n                        user\n    ordsize             Estimates total download size for each completed\n                        order(Takes times)\n    downloader          Download using order url list\n\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre>\n<p>To obtain help for a specific functionality, simply call it with <em>help</em> switch, e.g.: <code>pobatch idsplit -h</code>. If you didn't install pobatch, then you can run it just by going to <em>pobatch</em> directory and running <code>python pobatch.py [arguments go here]</code></p>\n<h2>porder wrapper for Ordersv2 Batch Client</h2>\n<p>The tool is built as a wrapper around the <a href=\"https://github.com/samapriya/porder\" rel=\"nofollow\">porder tool</a>. The <strong>porder tool</strong> contains additionally useful tools such as convert shapefile to geojson, base64 encode your gcs credentials, simplify your geometry to fit the 500 vertices requirements and so on. So the idea is to use both of those tools in conjunction and make desired pipelines as needed. This tools is created to give the user some control over long and tedious order queue and implement push and pull of data in a batch manner.</p>\n<h3>version</h3>\n<p>This prints the tool version and escapes. Simple use would be</p>\n<pre><code>pobatch version\n</code></pre>\n<h3>quota</h3>\n<p>Just a simple tool to print your planet subscription quota quickly.</p>\n<pre><code>pobatch quota\n</code></pre>\n<h3>idlist</h3>\n<p>Create an idlist for your geometry based on some basic filters, including geometry, start and end date and cloud cover. If no cloud cover is specified, everything from 0 to 100% cloud cover is included. For now the tool can handle geojson,json and kml files. The output is a csv file with ids. The tool also allows you to make sure you get percentage overlap, when selecting image, for clip operations adjust it accordingly (usally --ovp 1 for orders not to fail during clip). The tool now also prints estimated area in Square kilometers for the download and estimated area if you clipped your area with the geometry you are searching (just estimates).</p>\n<p><strong>I have changed the setup to now do the following two things</strong></p>\n<ul>\n<li>\n<p>The number option is optional, so it can look for all images in the time range, but be careful if the area is too large, <em>use at own risk</em>. A better option is to supply the number.</p>\n</li>\n<li>\n<p>It is possible to often forget about the different asset types, so you can now not pass an item and the script will return every possible type of asset for each item type depending on the bundle.</p>\n</li>\n</ul>\n<pre><code>pobatch idlist -h\nusage: pobatch idlist [-h] --input INPUT --start START --end END --item ITEM\n                      [--asset ASSET] --outfile OUTFILE [--cmin CMIN]\n                      [--cmax CMAX] [--number NUMBER] [--overlap OVERLAP]\n                      [--filters FILTERS [FILTERS ...]]\n\noptional arguments:\n  -h, --help            show this help message and exit\n\nRequired named arguments.:\n  --input INPUT         Input geometry file for now geojson/json/kml\n  --start START         Start date in format YYYY-MM-DD\n  --end END             End date in format YYYY-MM-DD\n  --item ITEM           Item Type PSScene4Band|PSOrthoTile|REOrthoTile etc\n  --asset ASSET         Asset Type analytic, analytic_sr,visual etc\n  --outfile OUTFILE     Output csv file\n\nOptional named arguments:\n  --cmin CMIN           Minimum cloud cover\n  --cmax CMAX           Maximum cloud cover\n  --number NUMBER       Total number of assets, give a large number if you are\n                        not sure\n  --overlap OVERLAP     Percentage overlap of image with search area range\n                        between 0 to 100\n  --filters FILTERS [FILTERS ...]\n                        Add an additional string or range filter\n</code></pre>\n<p>A simple setup would be the following for 800 max item ids and an overlap of 5% with the geometry we pass to the filter</p>\n<pre><code>pobatch idlist --input \"path to geometry.geojson\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic_sr\" --number 800 --outfile \"path to idlist.csv file\" --overlap 5\n</code></pre>\n<p>To run an experiment to add additional filter, you can now pass an additional string or range filter or both flag for string and range filters, a setup would be. The additional filters are optional</p>\n<pre><code>pobatch idlist --input \"Path to geojson file\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"Path to idlist.csv\" --filters range:clear_percent:55:100 --number 20\n\npobatch idlist --input \"Path to geojson file\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"Path to idlist.csv\" --filters string:satellite_id:\"1003,1006,1012,1020,1038\" --number 20\n\npobatch idlist --input \"Path to geojson file\" --start \"YYYY-MM-DD\" --end \"YYYY-MM-DD\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"Path to idlist.csv\" --filters string:satellite_id:\"1003,1006,1012,1020,1038\" range:clear_percent:55:100 --number 20\n</code></pre>\n<p>The idlist tool can now use a multipolygon and iteratively look for scenes.</p>\n<h3>idsplit</h3>\n<p>This allows you to split your idlist into small csv files to created batches of orders.</p>\n<pre><code>usage: pobatch idsplit [-h] [--idlist IDLIST] [--lines LINES] [--local LOCAL]\n\noptional arguments:\n  -h, --help       show this help message and exit\n  --idlist IDLIST  Idlist txt file to split\n  --lines LINES    Maximum number of lines in each split files\n  --local LOCAL    Output folder where split files will be exported\n</code></pre>\n<p>A simple setup would be</p>\n<pre><code>pobatch idsplit --idlist \"path to idlist.csv\" --lines \"number of lines in each idlist\" --local \"folder path to export split id lists\"\n</code></pre>\n<h3>multiorder</h3>\n<p>This tool allows you to actually place the order using the idlist that you created earlier. the <code>--op</code> argument allows you to take operations, delivery and notifications in a sequence for example <code>--op toar clip email</code> performs Top of Atmospheric reflectance, followed by clipping to your geometry and send you an email notification once the order has completed, failed or had any any change of status. An important changes is the concept of passing bundles instead of using assets. Bundles are predefined meaning all assets in a bundle are not available for an item your attempt at downloading that attempt will fail.</p>\n<p>For example if an item id '20181227_125554_0f4c' does not have surface reflectance asset type. So if you try to download this using bundle type analytic_sr_udm2 it will not work, similary if you order an item where a specific operation cannot be performed for example if you order visual and then try to do bandmath with four bands. These examples and more are where <strong>fallback bundles</strong> come in handy. Think of this as providing a list of bundles to keep trying if one bundle type fails. The priority goes left to right. You can provide comma seperated fallback bundles for example as</p>\n<p><code>analytic_sr_udm2,analytic</code> instead of <code>analytic_sr_udm2</code> to avoid certain items from failing to download.</p>\n<p>The list of operations for the <code>--op</code> are below and ** the order of these operations is important**</p>\n<p>clip|toar|comp\nosite|zip|zipall|compression|projection|kernel|aws|azu\nre|gcs|email &lt;Choose indices from&gt;:\nndvi|gndvi|bndvi|ndwi|tvi|osavi|evi2|msavi2|sr</p>\n&lt;center&gt;\n<table>\n<thead>\n<tr>\n<th>op</th>\n<th>description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>clip</td>\n<td>Clip imagery can handle single and multi polygon verify or create geojson.io</td>\n</tr>\n<tr>\n<td>toar</td>\n<td>Top of Atmosphere Reflectance imagery generated for imagery</td>\n</tr>\n<tr>\n<td>harmonize</td>\n<td>Harmonize Dove R (instrument type PS2.SD) data to classic dove (instrument type PS)</td>\n</tr>\n<tr>\n<td>composite</td>\n<td>Composite number of images in a given order</td>\n</tr>\n<tr>\n<td>zip</td>\n<td>Zip bundles together and creates downloads (each asset has a single bundle so multiple zip files)</td>\n</tr>\n<tr>\n<td>zipall</td>\n<td>Create a single zip file containing all assets</td>\n</tr>\n<tr>\n<td>compression</td>\n<td>Use image compression</td>\n</tr>\n<tr>\n<td>projection</td>\n<td>Reproject before downloaing image</td>\n</tr>\n<tr>\n<td>aws</td>\n<td>Option called to specify delivery to AWS</td>\n</tr>\n<tr>\n<td>azure</td>\n<td>Option called to specify delivery to AZURE</td>\n</tr>\n<tr>\n<td>gcs</td>\n<td>Option called to specify delivery to GCS</td>\n</tr>\n<tr>\n<td>email</td>\n<td>Email notification to your planet registered email</td>\n</tr></tbody></table>\n&lt;/center&gt;\n<p>You can now add some predefined indices for PlanetScope 4 band items with a maximum of 5 indices for a single setup . This is experimental. The list of indices include</p>\n&lt;center&gt;\n<table>\n<thead>\n<tr>\n<th>Index</th>\n<th>Source</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Simple ratio (SR)</td>\n<td><a href=\"https://esajournals.onlinelibrary.wiley.com/doi/abs/10.2307/1936256\" rel=\"nofollow\">Jordan 1969</a></td>\n</tr>\n<tr>\n<td>Normalized Difference Vegetation Index (NDVI)</td>\n<td><a href=\"https://ntrs.nasa.gov/search.jsp?R=19740022614\" rel=\"nofollow\">Rouse et al 1973</a></td>\n</tr>\n<tr>\n<td>Green Normalized Difference Index (GNDVI)</td>\n<td><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0034425796000727\" rel=\"nofollow\">Gitelson et al 1996</a></td>\n</tr>\n<tr>\n<td>Blue Normalized Difference Vegetation Index (BNDVI)</td>\n<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1672630807600274\" rel=\"nofollow\">Wang et al 2007</a></td>\n</tr>\n<tr>\n<td>Transformed Vegetation Index (TVI)</td>\n<td><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0034425700001978\" rel=\"nofollow\">Broge and Leblanc 2000</a></td>\n</tr>\n<tr>\n<td>Optimized Soil Adjusted Vegetation Index (OSAVI)</td>\n<td><a href=\"https://www.sciencedirect.com/science/article/abs/pii/0034425795001867\" rel=\"nofollow\">Rondeaux et al 1996</a></td>\n</tr>\n<tr>\n<td>Enhanced Vegetation Index (EVI2)</td>\n<td><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0034425708001971\" rel=\"nofollow\">Jian et al 2008</a></td>\n</tr>\n<tr>\n<td>Normalized Difference Water Index (NDWI)</td>\n<td><a href=\"https://www.tandfonline.com/doi/abs/10.1080/01431169608948714\" rel=\"nofollow\">McFeeters 1996</a></td>\n</tr>\n<tr>\n<td>Modified Soil-adjusted Vegetation Index v2 (MSAVI2)</td>\n<td><a href=\"https://www.sciencedirect.com/science/article/abs/pii/0034425794901341?via%3Dihub\" rel=\"nofollow\">Qi 1994</a></td>\n</tr></tbody></table>\n&lt;/center&gt;\n<p>This tool makes use of the FIFO (first in first out) concept in queue implementation in python. It checks to see if you have reached your concurrent order limit and then waits for 5 minutes before trying to place the order again iteratively.</p>\n<pre><code>pobatch multiorder -h\nusage: pobatch multiorder [-h] --infolder INFOLDER --outfile OUTFILE\n                          --errorlog ERRORLOG --max MAX --item ITEM --bundle\n                          BUNDLE [--sid SID] [--boundary BOUNDARY]\n                          [--projection PROJECTION] [--kernel KERNEL]\n                          [--compression COMPRESSION] [--aws AWS]\n                          [--azure AZURE] [--gcs GCS] [--op OP [OP ...]]\n\noptional arguments:\n  -h, --help            show this help message and exit\n\nRequired named arguments.:\n  --infolder INFOLDER   Folder with multiple order list\n  --outfile OUTFILE     CSV file with list of order urls\n  --errorlog ERRORLOG   Path to idlist it could not submit,error message log\n                        csv file\n  --item ITEM           Item Type PSScene4Band|PSOrthoTile|REOrthoTile etc\n  --bundle BUNDLE       Bundle Type: analytic, analytic_sr,analytic_sr_udm2\n\nOptional named arguments:\n  --sid SID             Subscription ID\n  --boundary BOUNDARY   Boundary/geometry for clip operation geojson|json|kml\n  --projection PROJECTION\n                        Projection for reproject operation of type \"EPSG:4326\"\n  --kernel KERNEL       Resampling kernel used \"near\", \"bilinear\", \"cubic\",\n                        \"cubicspline\", \"lanczos\", \"average\" and \"mode\"\n  --compression COMPRESSION\n                        Compression type used for tiff_optimize tool,\n                        \"lzw\"|\"deflate\"\n  --aws AWS             AWS cloud credentials config yml file\n  --azure AZURE         Azure cloud credentials config yml file\n  --gcs GCS             GCS cloud credentials config yml file\n  --op OP [OP ...]      Add operations, delivery &amp; notification clip|toar|comp\n                        osite|zip|zipall|compression|projection|kernel|aws|azu\n                        re|gcs|email &lt;Choose indices from&gt;:\n                        ndvi|gndvi|bndvi|ndwi|tvi|osavi|evi2|msavi2|sr\n</code></pre>\n<h3>status</h3>\n<p>The status tool takes the order list created from the multiorder tool and simply queries the current status of the orders in the list. It prints out the index, order name and order status and is for a quick check on multiple orders.</p>\n<pre><code>usage: pobatch status [-h] [--orderlist ORDERLIST]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --orderlist ORDERLIST\n                        Orderlist created earlier\n</code></pre>\n<h3>stats</h3>\n<p>The tool allows you to check on number of running and queued orders for both organization and user level. Using this is simple</p>\n<pre><code>pobatch stats\n</code></pre>\n<p>output should look like this:</p>\n<pre><code>Checking on all running orders...\nTotal queued order for organization: 0\nTotal running orders for organization: 1\n\nTotal queued orders for user: 0\nTotal running orders for user: 0\n</code></pre>\n<h3>ordsize</h3>\n<p>The ordersize tool allows you to print the order sizes in human readable format like KB, MB, GB.</p>\n<pre><code>usage: pobatch ordsize [-h] --infile INFILE\n\noptional arguments:\n  -h, --help       show this help message and exit\n\nRequired named arguments.:\n  --infile INFILE  CSV file with order list\n</code></pre>\n<h3>downloader</h3>\n<p>The tool now allows you to estimate the total download size for a specific order.</p>\n<pre><code>usage: pobatch downloader [-h] --infile INFILE --folder FOLDER --method METHOD\n\noptional arguments:\n  -h, --help       show this help message and exit\n\nRequired named arguments.:\n  --infile INFILE  CSV file with order list\n  --folder FOLDER  Local folder to save order files\n  --method METHOD  Method to be utilized for downloading\n                   download|multipart|multiproc\n</code></pre>\n<h3>Example Setup</h3>\n<ul>\n<li>Get idlist for geometry using porder (porder is installed as a dependency for this tool)</li>\n</ul>\n<pre><code>pobatch idlist --input \"geometry file.geojson\" --start \"2018-01-01\" --end \"2019-02-01\" --item \"PSScene4Band\" --asset \"analytic\" --outfile \"path to idlist.csv\"\n</code></pre>\n<ul>\n<li>Split idlist into smaller subparts</li>\n</ul>\n<pre><code>pobatch idsplit --idlist \"idlist file created earlier\" --lines \"number of lines in split files\" --local \"folder where we save the split id files\"\n</code></pre>\n<ul>\n<li>Now place order using idlists that you created. This requires you to set up a limit on the maximum number of concurrent orders you can place. This setups clips the image to a geometry, zips them and send you an email notification on completion.</li>\n</ul>\n<pre><code>pobatch multiorder --infolder \"folder where we save the split id files\" --outfile \"path to an orderlist with order url\" --item \"PSScene4Band\" --asset \"analytic\" --boundary \"path to geometry.geojson\" --op clip zip email\n</code></pre>\n<ul>\n<li>Let us quickly get the status of the orders placed.</li>\n</ul>\n<pre><code>pobatch --orderlist \"Full path to the order list\"\n</code></pre>\n<ul>\n<li>Let us now get the stats for our order number of order running and queuing for the organization and you as the user.</li>\n</ul>\n<pre><code>pobatch stats\n</code></pre>\n<ul>\n<li>Estimate order download size for each order (This is optional)</li>\n</ul>\n<pre><code>pobatch ordsize --infile \"Path to order url list\"\n</code></pre>\n<ul>\n<li>Finally download the order, and choose the download method (choose from sequential download or download| multipart download or multiproc or multiprocessing download)</li>\n</ul>\n<pre><code>pobatch downloader --infile \"Path to order url list\" --folder \"download folder\" --method \"multipart\"\n</code></pre>\n<h3>Changelog</h3>\n<p><strong>v0.0.8</strong></p>\n<ul>\n<li>Cleaned multiorder tool now uses stats endpoint instead concurreny check.</li>\n<li>Enhanced downloaders from porder v0.5.5 with much cleaner file check and download.</li>\n<li>Added status tool to check status of orders placed and stats tool to check on running and queued orders.</li>\n<li>General improvements to tool.</li>\n</ul>\n<p><strong>v0.0.7</strong></p>\n<ul>\n<li>Added bundle and subscription id arguments to multiorder tool.</li>\n<li>Updated idlist tool to handle multipolygon geometry better</li>\n<li>General improvements.</li>\n</ul>\n<p><strong>v0.0.6</strong></p>\n<ul>\n<li>Fixed bundles and removed deprecated bundle types.</li>\n<li>Created errorlog if issues submitting orders</li>\n<li>Now downloads both complete and partial order outputs.</li>\n</ul>\n<p><strong>v0.0.5</strong></p>\n<ul>\n<li>Fixed issues with utf decoding</li>\n<li>Logging and verbose call issue fixed</li>\n<li>Now returns number of items found while searching using idlist</li>\n</ul>\n<p><strong>v0.0.4</strong></p>\n<ul>\n<li>Added quota tool to main to prevent compatability issues</li>\n<li>Fixed issues with handling with and without op orders</li>\n<li>Added improvements to make shell runs function properly.</li>\n</ul>\n<p><strong>v0.0.3</strong></p>\n<ul>\n<li>Added queue support to downloader for better handling order list</li>\n<li>General improvements to overall tool</li>\n</ul>\n\n          </div>"}, "last_serial": 6113489, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "b55e55172c6fa850d0963a6398d2ff66", "sha256": "e0587cc0e32bc25a3178dfc392bb63cb1cbb53a519ccda62a3b909edafe4cb8b"}, "downloads": -1, "filename": "pobatch-0.0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b55e55172c6fa850d0963a6398d2ff66", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 13639, "upload_time": "2019-05-29T06:21:59", "upload_time_iso_8601": "2019-05-29T06:21:59.006297Z", "url": "https://files.pythonhosted.org/packages/2a/41/a2fc03cb5a6adf8306d8dcd0e56d073e1828ab6fa5f1354840f9e2e00019/pobatch-0.0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "49201c87dae3567ecc7b0e3136b50393", "sha256": "d104e879c16da066d3c40fff642e9bd3c8450de1fb533d4c090ba2390b527bc1"}, "downloads": -1, "filename": "pobatch-0.0.1.tar.gz", "has_sig": false, "md5_digest": "49201c87dae3567ecc7b0e3136b50393", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14584, "upload_time": "2019-05-29T06:22:00", "upload_time_iso_8601": "2019-05-29T06:22:00.976115Z", "url": "https://files.pythonhosted.org/packages/6f/bd/bac1bfee858aeab6af83c59fa9f40eaa37334aae7e447b784af6e92398fd/pobatch-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "be21253eb5de4ef3bf0bb5eb3b5e20e4", "sha256": "4522790d12e5da13a7cb32d14aa0e447252809b23e7bd274d57d67c568a564d0"}, "downloads": -1, "filename": "pobatch-0.0.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "be21253eb5de4ef3bf0bb5eb3b5e20e4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 20464, "upload_time": "2019-05-29T14:00:10", "upload_time_iso_8601": "2019-05-29T14:00:10.260202Z", "url": "https://files.pythonhosted.org/packages/71/01/2211aee49b995b9845bf612b1d28e01adf5740f357637e9f195852d36dc6/pobatch-0.0.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d93e072f096f4ad0045a483c74206c4c", "sha256": "ad0b761630fc83f5ff5e37f49c89e0a49bf646f63836124ae6562ac00980f014"}, "downloads": -1, "filename": "pobatch-0.0.2.tar.gz", "has_sig": false, "md5_digest": "d93e072f096f4ad0045a483c74206c4c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22986, "upload_time": "2019-05-29T14:00:11", "upload_time_iso_8601": "2019-05-29T14:00:11.645651Z", "url": "https://files.pythonhosted.org/packages/72/9a/dfda62f030b7b40d323557459594a6ee8d33f2b8681c99f76a12077984ab/pobatch-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "4f7a74a6407d222ec490e4246884923c", "sha256": "0354370f4b57feee3949decbc506fd3fa06eb554e5673949c1b3346aba3f621c"}, "downloads": -1, "filename": "pobatch-0.0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4f7a74a6407d222ec490e4246884923c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 20915, "upload_time": "2019-06-12T12:52:14", "upload_time_iso_8601": "2019-06-12T12:52:14.709714Z", "url": "https://files.pythonhosted.org/packages/d1/ca/cfed61c3dceba7cb0917ea8df2c504624252ce5d0f32a378eeb88822a934/pobatch-0.0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d9053888ef1ae595f5323de4a7b9f27d", "sha256": "42db767a97bced61f13cfd6e1f32bf99ce0d8207e7c3f6a8ba7dc392349836cc"}, "downloads": -1, "filename": "pobatch-0.0.3.tar.gz", "has_sig": false, "md5_digest": "d9053888ef1ae595f5323de4a7b9f27d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23452, "upload_time": "2019-06-12T12:52:16", "upload_time_iso_8601": "2019-06-12T12:52:16.386784Z", "url": "https://files.pythonhosted.org/packages/f7/bd/e78957e5254aee67276007a72964da51ec2dd2867e33e17c5fb52ecf4625/pobatch-0.0.3.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "a0b232528de21a26d8a19a3697f031d7", "sha256": "3794f880f2a88daa146b0ea3392cbdec8f838c920be9370faf671f7a0c400026"}, "downloads": -1, "filename": "pobatch-0.0.5-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "a0b232528de21a26d8a19a3697f031d7", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 20309, "upload_time": "2019-06-30T06:02:42", "upload_time_iso_8601": "2019-06-30T06:02:42.283305Z", "url": "https://files.pythonhosted.org/packages/06/fb/ba2c18c5c0ffc77cb39c52dbb6ca08455b8b59c2cb66ffe5235443f4688c/pobatch-0.0.5-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "518ee0c0a6d2e5175dcfc4a722f9b87f", "sha256": "7eaedd6118cfefcdab796717987b504789536ca6673370cdabe5a91f2cb16031"}, "downloads": -1, "filename": "pobatch-0.0.5.tar.gz", "has_sig": false, "md5_digest": "518ee0c0a6d2e5175dcfc4a722f9b87f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23712, "upload_time": "2019-06-30T06:02:44", "upload_time_iso_8601": "2019-06-30T06:02:44.180000Z", "url": "https://files.pythonhosted.org/packages/6b/a9/974ab246382ccc23e220dbcfe987cbe916499ea4053e50c59f240a7e9569/pobatch-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "c274963881b48281105fd6e382af9f09", "sha256": "e454bf4a482921ca70053cab3075371d25e33dffcf97a587501b24eebdf8ad43"}, "downloads": -1, "filename": "pobatch-0.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c274963881b48281105fd6e382af9f09", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 20805, "upload_time": "2019-08-22T03:46:04", "upload_time_iso_8601": "2019-08-22T03:46:04.355526Z", "url": "https://files.pythonhosted.org/packages/1f/b8/b3db41c4e9840459f5791f1a07e8d65bf4623c598433140770eea1d4bd58/pobatch-0.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "15a3eabcff32f3725d8c6d0c69089ad7", "sha256": "0d36dd313e091fbf4be3b1dd86cb0cc84e09551292ca5624a9aa488d10de01a3"}, "downloads": -1, "filename": "pobatch-0.0.6.tar.gz", "has_sig": false, "md5_digest": "15a3eabcff32f3725d8c6d0c69089ad7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24357, "upload_time": "2019-08-22T03:46:05", "upload_time_iso_8601": "2019-08-22T03:46:05.970800Z", "url": "https://files.pythonhosted.org/packages/70/82/5150f27fb301921b39871cbcee3616cd851951bb396bdec7ad25ebb43232/pobatch-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "3edcb2ca4dc4e9e60faed944f28480b6", "sha256": "2fc8e384af691191b5ea1f2eb247975093d1529a1750c347149bb8018274f494"}, "downloads": -1, "filename": "pobatch-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "3edcb2ca4dc4e9e60faed944f28480b6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 21359, "upload_time": "2019-08-23T16:08:20", "upload_time_iso_8601": "2019-08-23T16:08:20.902675Z", "url": "https://files.pythonhosted.org/packages/db/06/52888aba6dabe2ae70deb26156335c6990633c3f5e223414054d76db6511/pobatch-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "46295a262bdcdde5d355d7e98d3c3046", "sha256": "b9b2b51a050a887a34e263a9e1404be0a3a5cc9935e2cfd6933f382af7a9efda"}, "downloads": -1, "filename": "pobatch-0.0.7.tar.gz", "has_sig": false, "md5_digest": "46295a262bdcdde5d355d7e98d3c3046", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24910, "upload_time": "2019-08-23T16:08:22", "upload_time_iso_8601": "2019-08-23T16:08:22.153107Z", "url": "https://files.pythonhosted.org/packages/bf/f4/f7bc6a09f7bd917d4e3b5d8302af00fd018aa6c7c8345e074b22a43a0f20/pobatch-0.0.7.tar.gz", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "620dc24712c1f20ffa4b1887ac203284", "sha256": "993caddfd070648132fc30752b9dac77609f5b1779f7c20221e3ca923ca02815"}, "downloads": -1, "filename": "pobatch-0.0.8-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "620dc24712c1f20ffa4b1887ac203284", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 23288, "upload_time": "2019-11-11T01:39:28", "upload_time_iso_8601": "2019-11-11T01:39:28.390192Z", "url": "https://files.pythonhosted.org/packages/30/c1/22a0d974cdadd93cc70f541e0cce0a983b9397ef214ed4889f4553b0a521/pobatch-0.0.8-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b0348bd284d3285f17adee286bdfeebe", "sha256": "af215f52dcdc395ccce4f6304b04724ad6fe7793af58d2134ccefac0e322091d"}, "downloads": -1, "filename": "pobatch-0.0.8.tar.gz", "has_sig": false, "md5_digest": "b0348bd284d3285f17adee286bdfeebe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27918, "upload_time": "2019-11-11T01:39:30", "upload_time_iso_8601": "2019-11-11T01:39:30.102313Z", "url": "https://files.pythonhosted.org/packages/b7/1e/511fb02e1646449a422e6759509ad0f735443e9a1be646a75a0e595cf9b1/pobatch-0.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "620dc24712c1f20ffa4b1887ac203284", "sha256": "993caddfd070648132fc30752b9dac77609f5b1779f7c20221e3ca923ca02815"}, "downloads": -1, "filename": "pobatch-0.0.8-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "620dc24712c1f20ffa4b1887ac203284", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 23288, "upload_time": "2019-11-11T01:39:28", "upload_time_iso_8601": "2019-11-11T01:39:28.390192Z", "url": "https://files.pythonhosted.org/packages/30/c1/22a0d974cdadd93cc70f541e0cce0a983b9397ef214ed4889f4553b0a521/pobatch-0.0.8-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b0348bd284d3285f17adee286bdfeebe", "sha256": "af215f52dcdc395ccce4f6304b04724ad6fe7793af58d2134ccefac0e322091d"}, "downloads": -1, "filename": "pobatch-0.0.8.tar.gz", "has_sig": false, "md5_digest": "b0348bd284d3285f17adee286bdfeebe", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27918, "upload_time": "2019-11-11T01:39:30", "upload_time_iso_8601": "2019-11-11T01:39:30.102313Z", "url": "https://files.pythonhosted.org/packages/b7/1e/511fb02e1646449a422e6759509ad0f735443e9a1be646a75a0e595cf9b1/pobatch-0.0.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:52:11 2020"}