{"info": {"author": "Ines Montani", "author_email": "ines@explosion.ai", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# spaCy + StanfordNLP\n\nThis package wraps the [StanfordNLP](https://github.com/stanfordnlp/stanfordnlp)\nlibrary, so you can use Stanford's models as a [spaCy](https://spacy.io)\npipeline. The Stanford models achieved top accuracy in the CoNLL 2017 and 2018\nshared task, which involves tokenization, part-of-speech tagging, morphological\nanalysis, lemmatization and labelled dependency parsing in 58 languages.\n\n[![PyPi](https://img.shields.io/pypi/v/spacy-stanfordnlp.svg?style=flat-square)](https://pypi.python.org/pypi/spacy-stanfordnlp)\n[![GitHub](https://img.shields.io/github/release/explosion/spacy-stanfordnlp/all.svg?style=flat-square)](https://github.com/explosion/spacy-stanfordnlp)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n\nUsing this wrapper, you'll be able to use the following annotations, computed by\nyour pretrained `stanfordnlp` model:\n\n- Statistical tokenization (reflected in the `Doc` and its tokens)\n- Lemmatization (`token.lemma` and `token.lemma_`)\n- Part-of-speech tagging (`token.tag`, `token.tag_`, `token.pos`, `token.pos_`)\n- Dependency parsing (`token.dep`, `token.dep_`, `token.head`)\n- Sentence segmentation (`doc.sents`)\n\n## \ufe0f\ufe0f\ufe0f\u231b\ufe0f Installation\n\n```bash\npip install spacy-stanfordnlp\n```\n\nMake sure to also install one of the\n[pre-trained StanfordNLP models](https://stanfordnlp.github.io/stanfordnlp/installation_download.html). It's recommended to run StanfordNLP on Python 3.6.8+ or Python 3.7.2+.\n\n## \ud83d\udcd6 Usage & Examples\n\nThe `StanfordNLPLanguage` class can be initialized with a loaded StanfordNLP\npipeline and returns a spaCy [`Language` object](https://spacy.io/api/language),\ni.e. the `nlp` object you can use to process text and create a\n[`Doc` object](https://spacy.io/api/doc).\n\n```python\nimport stanfordnlp\nfrom spacy_stanfordnlp import StanfordNLPLanguage\n\nsnlp = stanfordnlp.Pipeline(lang=\"en\")\nnlp = StanfordNLPLanguage(snlp)\n\ndoc = nlp(\"Barack Obama was born in Hawaii. He was elected president in 2008.\")\nfor token in doc:\n    print(token.text, token.lemma_, token.pos_, token.dep_)\n```\n\nIf language data for the given language is available in spaCy, the respective\nlanguage class will be used as the base for the `nlp` object \u2013 for example,\n`English()`. This lets you use spaCy's lexical attributes like `is_stop` or\n`like_num`. The `nlp` object follows the same API as any other spaCy `Language`\nclass \u2013 so you can visualize the `Doc` objects with displaCy, add custom\ncomponents to the pipeline, use the rule-based matcher and do pretty much\nanything else you'd normally do in spaCy.\n\n```python\n# Access spaCy's lexical attributes\nprint([token.is_stop for token in doc])\nprint([token.like_num for token in doc])\n\n# Visualize dependencies\nfrom spacy import displacy\ndisplacy.serve(doc)  # or displacy.render if you're in a Jupyter notebook\n\n# Efficient processing with nlp.pipe\nfor doc in nlp.pipe([\"Lots of texts\", \"Even more texts\", \"...\"]):\n    print(doc.text)\n\n# Combine with your own custom pipeline components\ndef custom_component(doc):\n    # Do something to the doc here\n    return doc\n\nnlp.add_pipe(custom_component)\n\n# Serialize it to a numpy array\nnp_array = doc.to_array(['ORTH', 'LEMMA', 'POS'])\n```\n\n### Experimental: Mixing and matching pipeline components\n\nBy default, the `nlp` object's pipeline will be empty, because all attributes\nare computed once and set in the custom\n[`Tokenizer`](spacy_stanfordnlp/language.py). But since it's a regular `nlp`\nobject, you can add your own components to the pipeline.\n\nFor example, the entity recognizer from one of spaCy's pre-trained models:\n\n```python\nimport spacy\nimport spacy_stanfordnlp\nimport stanfordnlp\n\nsnlp = stanfordnlp.Pipeline(lang=\"en\", models_dir=\"./models\")\nnlp = StanfordNLPLanguage(snlp)\n\n# Load spaCy's pre-trained en_core_web_sm model, get the entity recognizer and\n# add it to the StanfordNLP model's pipeline\nspacy_model = spacy.load(\"en_core_web_sm\")\nner = spacy_model.get_pipe(\"ner\")\nnlp.add_pipe(ner)\n\ndoc = nlp(\"Barack Obama was born in Hawaii. He was elected president in 2008.\")\nprint([(ent.text, ent.label_) for ent in doc.ents])\n# [('Barack Obama', 'PERSON'), ('Hawaii', 'GPE'), ('2008', 'DATE')]\n```\n\nYou could also add and train\n[your own custom text classification component](https://spacy.io/usage/training#textcat).\n\n### Advanced: serialization and entry points\n\nThe spaCy `nlp` object created by `StanfordNLPLanguage` exposes its language as\n`stanfordnlp_xx`.\n\n```python\nfrom spacy.util import get_lang_class\nlang_cls = get_lang_class(\"stanfordnlp_en\")\n```\n\nNormally, the above would fail because spaCy doesn't include a language class\n`stanfordnlp_en`. But because this package exposes a `spacy_languages` entry\npoint in its [`setup.py`](setup.py) that points to `StanfordNLPLanguage`, spaCy\nknows how to initialize it.\n\nThis means that saving to and loading from disk works:\n\n```python\nsnlp = stanfordnlp.Pipeline(lang=\"en\")\nnlp = StanfordNLPLanguage(snlp)\nnlp.to_disk(\"./stanfordnlp-spacy-model\")\n```\n\nAdditional arguments on `spacy.load` are automatically passed down to the\nlanguage class and pipeline components. So when loading the saved model, you can\npass in the `snlp` argument:\n\n```python\nsnlp = stanfordnlp.Pipeline(lang=\"en\")\nnlp = spacy.load(\"./stanfordnlp-spacy-model\", snlp=snlp)\n```\n\nNote that this **will not save any model data by default**. The StanfordNLP\nmodels are very large, so for now, this package expects that you load them\nseparately.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://explosion.ai", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "spacy-stanfordnlp", "package_url": "https://pypi.org/project/spacy-stanfordnlp/", "platform": "", "project_url": "https://pypi.org/project/spacy-stanfordnlp/", "project_urls": {"Homepage": "https://explosion.ai"}, "release_url": "https://pypi.org/project/spacy-stanfordnlp/0.1.3/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Use the latest StanfordNLP research models directly in spaCy", "version": "0.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://explosion.ai\" rel=\"nofollow\"><img align=\"right\" height=\"125\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/657dbf4006ad44b146bd59acc7f61d67177af1a5/68747470733a2f2f6578706c6f73696f6e2e61692f6173736574732f696d672f6c6f676f2e737667\" width=\"125\"></a></p>\n<h1>spaCy + StanfordNLP</h1>\n<p>This package wraps the <a href=\"https://github.com/stanfordnlp/stanfordnlp\" rel=\"nofollow\">StanfordNLP</a>\nlibrary, so you can use Stanford's models as a <a href=\"https://spacy.io\" rel=\"nofollow\">spaCy</a>\npipeline. The Stanford models achieved top accuracy in the CoNLL 2017 and 2018\nshared task, which involves tokenization, part-of-speech tagging, morphological\nanalysis, lemmatization and labelled dependency parsing in 58 languages.</p>\n<p><a href=\"https://pypi.python.org/pypi/spacy-stanfordnlp\" rel=\"nofollow\"><img alt=\"PyPi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd9ddf40820664a044eafdbc5e9606ff2d98091f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f73706163792d7374616e666f72646e6c702e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://github.com/explosion/spacy-stanfordnlp\" rel=\"nofollow\"><img alt=\"GitHub\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d6802e3003d23a0bf75e95c7499ab26379a37a09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6578706c6f73696f6e2f73706163792d7374616e666f72646e6c702f616c6c2e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://github.com/ambv/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1c326c58e924b9f3508f32a8ac6b3ee91f40b090/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e7376673f7374796c653d666c61742d737175617265\"></a></p>\n<p>Using this wrapper, you'll be able to use the following annotations, computed by\nyour pretrained <code>stanfordnlp</code> model:</p>\n<ul>\n<li>Statistical tokenization (reflected in the <code>Doc</code> and its tokens)</li>\n<li>Lemmatization (<code>token.lemma</code> and <code>token.lemma_</code>)</li>\n<li>Part-of-speech tagging (<code>token.tag</code>, <code>token.tag_</code>, <code>token.pos</code>, <code>token.pos_</code>)</li>\n<li>Dependency parsing (<code>token.dep</code>, <code>token.dep_</code>, <code>token.head</code>)</li>\n<li>Sentence segmentation (<code>doc.sents</code>)</li>\n</ul>\n<h2>\ufe0f\ufe0f\ufe0f\u231b\ufe0f Installation</h2>\n<pre>pip install spacy-stanfordnlp\n</pre>\n<p>Make sure to also install one of the\n<a href=\"https://stanfordnlp.github.io/stanfordnlp/installation_download.html\" rel=\"nofollow\">pre-trained StanfordNLP models</a>. It's recommended to run StanfordNLP on Python 3.6.8+ or Python 3.7.2+.</p>\n<h2>\ud83d\udcd6 Usage &amp; Examples</h2>\n<p>The <code>StanfordNLPLanguage</code> class can be initialized with a loaded StanfordNLP\npipeline and returns a spaCy <a href=\"https://spacy.io/api/language\" rel=\"nofollow\"><code>Language</code> object</a>,\ni.e. the <code>nlp</code> object you can use to process text and create a\n<a href=\"https://spacy.io/api/doc\" rel=\"nofollow\"><code>Doc</code> object</a>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">stanfordnlp</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy_stanfordnlp</span> <span class=\"kn\">import</span> <span class=\"n\">StanfordNLPLanguage</span>\n\n<span class=\"n\">snlp</span> <span class=\"o\">=</span> <span class=\"n\">stanfordnlp</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s2\">\"en\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">StanfordNLPLanguage</span><span class=\"p\">(</span><span class=\"n\">snlp</span><span class=\"p\">)</span>\n\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s2\">\"Barack Obama was born in Hawaii. He was elected president in 2008.\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"n\">token</span> <span class=\"ow\">in</span> <span class=\"n\">doc</span><span class=\"p\">:</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">lemma_</span><span class=\"p\">,</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">pos_</span><span class=\"p\">,</span> <span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">dep_</span><span class=\"p\">)</span>\n</pre>\n<p>If language data for the given language is available in spaCy, the respective\nlanguage class will be used as the base for the <code>nlp</code> object \u2013 for example,\n<code>English()</code>. This lets you use spaCy's lexical attributes like <code>is_stop</code> or\n<code>like_num</code>. The <code>nlp</code> object follows the same API as any other spaCy <code>Language</code>\nclass \u2013 so you can visualize the <code>Doc</code> objects with displaCy, add custom\ncomponents to the pipeline, use the rule-based matcher and do pretty much\nanything else you'd normally do in spaCy.</p>\n<pre><span class=\"c1\"># Access spaCy's lexical attributes</span>\n<span class=\"nb\">print</span><span class=\"p\">([</span><span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">is_stop</span> <span class=\"k\">for</span> <span class=\"n\">token</span> <span class=\"ow\">in</span> <span class=\"n\">doc</span><span class=\"p\">])</span>\n<span class=\"nb\">print</span><span class=\"p\">([</span><span class=\"n\">token</span><span class=\"o\">.</span><span class=\"n\">like_num</span> <span class=\"k\">for</span> <span class=\"n\">token</span> <span class=\"ow\">in</span> <span class=\"n\">doc</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Visualize dependencies</span>\n<span class=\"kn\">from</span> <span class=\"nn\">spacy</span> <span class=\"kn\">import</span> <span class=\"n\">displacy</span>\n<span class=\"n\">displacy</span><span class=\"o\">.</span><span class=\"n\">serve</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">)</span>  <span class=\"c1\"># or displacy.render if you're in a Jupyter notebook</span>\n\n<span class=\"c1\"># Efficient processing with nlp.pipe</span>\n<span class=\"k\">for</span> <span class=\"n\">doc</span> <span class=\"ow\">in</span> <span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">pipe</span><span class=\"p\">([</span><span class=\"s2\">\"Lots of texts\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Even more texts\"</span><span class=\"p\">,</span> <span class=\"s2\">\"...\"</span><span class=\"p\">]):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Combine with your own custom pipeline components</span>\n<span class=\"k\">def</span> <span class=\"nf\">custom_component</span><span class=\"p\">(</span><span class=\"n\">doc</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Do something to the doc here</span>\n    <span class=\"k\">return</span> <span class=\"n\">doc</span>\n\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">custom_component</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Serialize it to a numpy array</span>\n<span class=\"n\">np_array</span> <span class=\"o\">=</span> <span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">to_array</span><span class=\"p\">([</span><span class=\"s1\">'ORTH'</span><span class=\"p\">,</span> <span class=\"s1\">'LEMMA'</span><span class=\"p\">,</span> <span class=\"s1\">'POS'</span><span class=\"p\">])</span>\n</pre>\n<h3>Experimental: Mixing and matching pipeline components</h3>\n<p>By default, the <code>nlp</code> object's pipeline will be empty, because all attributes\nare computed once and set in the custom\n<a href=\"spacy_stanfordnlp/language.py\" rel=\"nofollow\"><code>Tokenizer</code></a>. But since it's a regular <code>nlp</code>\nobject, you can add your own components to the pipeline.</p>\n<p>For example, the entity recognizer from one of spaCy's pre-trained models:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">spacy</span>\n<span class=\"kn\">import</span> <span class=\"nn\">spacy_stanfordnlp</span>\n<span class=\"kn\">import</span> <span class=\"nn\">stanfordnlp</span>\n\n<span class=\"n\">snlp</span> <span class=\"o\">=</span> <span class=\"n\">stanfordnlp</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s2\">\"en\"</span><span class=\"p\">,</span> <span class=\"n\">models_dir</span><span class=\"o\">=</span><span class=\"s2\">\"./models\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">StanfordNLPLanguage</span><span class=\"p\">(</span><span class=\"n\">snlp</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Load spaCy's pre-trained en_core_web_sm model, get the entity recognizer and</span>\n<span class=\"c1\"># add it to the StanfordNLP model's pipeline</span>\n<span class=\"n\">spacy_model</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"en_core_web_sm\"</span><span class=\"p\">)</span>\n<span class=\"n\">ner</span> <span class=\"o\">=</span> <span class=\"n\">spacy_model</span><span class=\"o\">.</span><span class=\"n\">get_pipe</span><span class=\"p\">(</span><span class=\"s2\">\"ner\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">add_pipe</span><span class=\"p\">(</span><span class=\"n\">ner</span><span class=\"p\">)</span>\n\n<span class=\"n\">doc</span> <span class=\"o\">=</span> <span class=\"n\">nlp</span><span class=\"p\">(</span><span class=\"s2\">\"Barack Obama was born in Hawaii. He was elected president in 2008.\"</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">([(</span><span class=\"n\">ent</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">ent</span><span class=\"o\">.</span><span class=\"n\">label_</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">ent</span> <span class=\"ow\">in</span> <span class=\"n\">doc</span><span class=\"o\">.</span><span class=\"n\">ents</span><span class=\"p\">])</span>\n<span class=\"c1\"># [('Barack Obama', 'PERSON'), ('Hawaii', 'GPE'), ('2008', 'DATE')]</span>\n</pre>\n<p>You could also add and train\n<a href=\"https://spacy.io/usage/training#textcat\" rel=\"nofollow\">your own custom text classification component</a>.</p>\n<h3>Advanced: serialization and entry points</h3>\n<p>The spaCy <code>nlp</code> object created by <code>StanfordNLPLanguage</code> exposes its language as\n<code>stanfordnlp_xx</code>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">spacy.util</span> <span class=\"kn\">import</span> <span class=\"n\">get_lang_class</span>\n<span class=\"n\">lang_cls</span> <span class=\"o\">=</span> <span class=\"n\">get_lang_class</span><span class=\"p\">(</span><span class=\"s2\">\"stanfordnlp_en\"</span><span class=\"p\">)</span>\n</pre>\n<p>Normally, the above would fail because spaCy doesn't include a language class\n<code>stanfordnlp_en</code>. But because this package exposes a <code>spacy_languages</code> entry\npoint in its <a href=\"setup.py\" rel=\"nofollow\"><code>setup.py</code></a> that points to <code>StanfordNLPLanguage</code>, spaCy\nknows how to initialize it.</p>\n<p>This means that saving to and loading from disk works:</p>\n<pre><span class=\"n\">snlp</span> <span class=\"o\">=</span> <span class=\"n\">stanfordnlp</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s2\">\"en\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">StanfordNLPLanguage</span><span class=\"p\">(</span><span class=\"n\">snlp</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span><span class=\"o\">.</span><span class=\"n\">to_disk</span><span class=\"p\">(</span><span class=\"s2\">\"./stanfordnlp-spacy-model\"</span><span class=\"p\">)</span>\n</pre>\n<p>Additional arguments on <code>spacy.load</code> are automatically passed down to the\nlanguage class and pipeline components. So when loading the saved model, you can\npass in the <code>snlp</code> argument:</p>\n<pre><span class=\"n\">snlp</span> <span class=\"o\">=</span> <span class=\"n\">stanfordnlp</span><span class=\"o\">.</span><span class=\"n\">Pipeline</span><span class=\"p\">(</span><span class=\"n\">lang</span><span class=\"o\">=</span><span class=\"s2\">\"en\"</span><span class=\"p\">)</span>\n<span class=\"n\">nlp</span> <span class=\"o\">=</span> <span class=\"n\">spacy</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">\"./stanfordnlp-spacy-model\"</span><span class=\"p\">,</span> <span class=\"n\">snlp</span><span class=\"o\">=</span><span class=\"n\">snlp</span><span class=\"p\">)</span>\n</pre>\n<p>Note that this <strong>will not save any model data by default</strong>. The StanfordNLP\nmodels are very large, so for now, this package expects that you load them\nseparately.</p>\n\n          </div>"}, "last_serial": 5853003, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "345258090879824c540e6b4bca760fd4", "sha256": "9baf377ed7bc7b0b5e20f8bd30d8512f964ac4e5a7c96d176fcdd4472a6b4987"}, "downloads": -1, "filename": "spacy_stanfordnlp-0.0.1.tar.gz", "has_sig": false, "md5_digest": "345258090879824c540e6b4bca760fd4", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6468, "upload_time": "2019-02-01T00:00:42", "upload_time_iso_8601": "2019-02-01T00:00:42.501264Z", "url": "https://files.pythonhosted.org/packages/0d/e7/1cb6f7537a3aa8ec8a5afa970116a9e3df2d952849e2bd9c14460e1bb1ed/spacy_stanfordnlp-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "09f1dfb7d2cf9c6c269c36146526133a", "sha256": "94c45685339a451ade846b15b52e7681c9f597be72bb24b5772ff2e7cde344b1"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.0.2.tar.gz", "has_sig": false, "md5_digest": "09f1dfb7d2cf9c6c269c36146526133a", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6447, "upload_time": "2019-02-01T00:20:34", "upload_time_iso_8601": "2019-02-01T00:20:34.698612Z", "url": "https://files.pythonhosted.org/packages/a8/13/c43bcc4644061f4cd2b8be9fd92eebfb974153d6679e1c51a4886dbd59de/spacy-stanfordnlp-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "e23c3ab1d52fee6ac054c81748ba7c78", "sha256": "b2d1eecaa80eb77e443028a7265edfe5fdb77cd213d0c8a47f173492065ac8a2"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.0.3.tar.gz", "has_sig": false, "md5_digest": "e23c3ab1d52fee6ac054c81748ba7c78", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 6573, "upload_time": "2019-02-07T23:53:46", "upload_time_iso_8601": "2019-02-07T23:53:46.738868Z", "url": "https://files.pythonhosted.org/packages/74/eb/0e79a3c0283c6ad6e6eed9975ffcade417b6ff14734d05da0d72bb357bf3/spacy-stanfordnlp-0.0.3.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "d193c440e6b352d999441c00fe5a7fc2", "sha256": "3f7acec30a36ad755cc634c4124ab662b6cad815b92024d85b15e2368b74c70d"}, "downloads": -1, "filename": "spacy_stanfordnlp-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d193c440e6b352d999441c00fe5a7fc2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8287, "upload_time": "2019-04-24T15:03:26", "upload_time_iso_8601": "2019-04-24T15:03:26.990779Z", "url": "https://files.pythonhosted.org/packages/63/9d/7de68f8812abaa55001525f03e4589e17759ad79dd1c2cf75dbf302c59ca/spacy_stanfordnlp-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "622b41ed5077ee96bf7c11d57a00de84", "sha256": "e548336abd4ec23996d19af317676c7014bffd049e744d394d1ef89668bcca5e"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.1.0.tar.gz", "has_sig": false, "md5_digest": "622b41ed5077ee96bf7c11d57a00de84", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7084, "upload_time": "2019-04-24T15:03:04", "upload_time_iso_8601": "2019-04-24T15:03:04.885278Z", "url": "https://files.pythonhosted.org/packages/14/9f/e445e341504765fbc3c9bef6d928b2f996cb07aa812c1e62cfe662646a36/spacy-stanfordnlp-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "7da8231e6406e8d55dc6829e30ab0ca0", "sha256": "959c9b2a1819cae72b5b5d8b882ffdf78e9e98dedcf95cc2faaa839380b71a6b"}, "downloads": -1, "filename": "spacy_stanfordnlp-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "7da8231e6406e8d55dc6829e30ab0ca0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8377, "upload_time": "2019-05-11T16:35:05", "upload_time_iso_8601": "2019-05-11T16:35:05.858597Z", "url": "https://files.pythonhosted.org/packages/53/4b/21eef8bb826210315df84a6fdf0f7a9fc6161e7153e9a65061594ffcd178/spacy_stanfordnlp-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23ef5508024580dcc60e6513b6c3ee50", "sha256": "688a88ac602fcae77665b90fe36b3f055df5f1a0e6e93e582ef8df534a5eed77"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.1.1.tar.gz", "has_sig": false, "md5_digest": "23ef5508024580dcc60e6513b6c3ee50", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7167, "upload_time": "2019-05-11T16:34:30", "upload_time_iso_8601": "2019-05-11T16:34:30.838899Z", "url": "https://files.pythonhosted.org/packages/68/42/c3041e9666c52a399ed954a214a22732e2c2e07e1a18c20ca0f6eb2f75ef/spacy-stanfordnlp-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "a176ba3a3f5789e490e0c5f838f8d3d1", "sha256": "911d589fbcd6166f809384ba505331b69e3c3ab852e39c67935a81170d36a102"}, "downloads": -1, "filename": "spacy_stanfordnlp-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "a176ba3a3f5789e490e0c5f838f8d3d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8381, "upload_time": "2019-05-31T09:58:14", "upload_time_iso_8601": "2019-05-31T09:58:14.341544Z", "url": "https://files.pythonhosted.org/packages/61/c2/a0bbc73e0d53dae54934809ab819b4e8fe3616e00e8510c0f0b4d295066c/spacy_stanfordnlp-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3a0b0f94709d4eb2e94ac20ed3e3995e", "sha256": "f9cb9af3c71eba01daf257a9aac73b4dac20711cc1f1f90fae6fc3eb45a91c72"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.1.2.tar.gz", "has_sig": false, "md5_digest": "3a0b0f94709d4eb2e94ac20ed3e3995e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7180, "upload_time": "2019-05-31T09:57:56", "upload_time_iso_8601": "2019-05-31T09:57:56.451574Z", "url": "https://files.pythonhosted.org/packages/30/2e/1aec8610def2f174d6f2c9c10a09c6ea203c585b31b7177eb446697e0500/spacy-stanfordnlp-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "7dbda82f8228a98353b41639e6cb715d", "sha256": "4335f7df96dc13a4df871fa7a344d6501f3ff1e78511f34b93a4226725f02db7"}, "downloads": -1, "filename": "spacy_stanfordnlp-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "7dbda82f8228a98353b41639e6cb715d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8380, "upload_time": "2019-07-09T20:06:50", "upload_time_iso_8601": "2019-07-09T20:06:50.676813Z", "url": "https://files.pythonhosted.org/packages/cc/b9/14959d1df871432446089a46f1bee4f35f23e02355f47ed530b5c9c5b52f/spacy_stanfordnlp-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "70c65c99edd3327a3ed6c69011fb0862", "sha256": "99d770be8203463f8d506cd5a1a7c6826d55446257abc868771ab12dcfb2c4bd"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.1.3.tar.gz", "has_sig": false, "md5_digest": "70c65c99edd3327a3ed6c69011fb0862", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7176, "upload_time": "2019-07-09T20:06:36", "upload_time_iso_8601": "2019-07-09T20:06:36.418698Z", "url": "https://files.pythonhosted.org/packages/90/ab/eb0f658fc9974c70e104b4d81b5b287b468700160824b91795bc25be70fe/spacy-stanfordnlp-0.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7dbda82f8228a98353b41639e6cb715d", "sha256": "4335f7df96dc13a4df871fa7a344d6501f3ff1e78511f34b93a4226725f02db7"}, "downloads": -1, "filename": "spacy_stanfordnlp-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "7dbda82f8228a98353b41639e6cb715d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 8380, "upload_time": "2019-07-09T20:06:50", "upload_time_iso_8601": "2019-07-09T20:06:50.676813Z", "url": "https://files.pythonhosted.org/packages/cc/b9/14959d1df871432446089a46f1bee4f35f23e02355f47ed530b5c9c5b52f/spacy_stanfordnlp-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "70c65c99edd3327a3ed6c69011fb0862", "sha256": "99d770be8203463f8d506cd5a1a7c6826d55446257abc868771ab12dcfb2c4bd"}, "downloads": -1, "filename": "spacy-stanfordnlp-0.1.3.tar.gz", "has_sig": false, "md5_digest": "70c65c99edd3327a3ed6c69011fb0862", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 7176, "upload_time": "2019-07-09T20:06:36", "upload_time_iso_8601": "2019-07-09T20:06:36.418698Z", "url": "https://files.pythonhosted.org/packages/90/ab/eb0f658fc9974c70e104b4d81b5b287b468700160824b91795bc25be70fe/spacy-stanfordnlp-0.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:06:03 2020"}