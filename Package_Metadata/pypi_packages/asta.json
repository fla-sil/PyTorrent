{"info": {"author": "Brendan Whitaker", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Utilities"], "description": "+----+\n|asta|\n+----+\n\nShape annotations for numpy arrays and pytorch/tensorflow tensors.\n\nIntroduction\n------------\nThis library defines subscriptable classes ``Array``, ``Tensor``, and\n``TFTensor`` for use in ``isinstance()`` checks and type annotations.  It also\nadds a decorator, ``@typechecked``, which implements toggleable static type\nenforcement for the classes described above.\n\n\nInstallation\n------------\n$ pip install asta\n$ pip install git+git://github.com/brendanxwhitaker/asta.git\n\n\nBasics\n------\nAsta supports checking dtypes and/or shapes with wildcards and ellipses:\n\n>>> Array[float]                # dtype=np.float64.\n>>> Array[float, 1, 2, 3]       # dtype=np.float64, shape=(1,2,3).\n>>> Array[float, (1, 2, 3)]     # dtype=np.float64, shape=(1,2,3).\n>>> Array[1, 2, 3]              # shape=(1,2,3).\n>>> Array[int, ()]              # dtype=np.int64, shape=().\n>>> Array[str, 1, 2 ..., 3]     # dtype=unicode, shape=(1,2,*...*,3).\n>>> Array[str, 1, 2 -1, 3]      # dtype=unicode, shape=(1,2,*,3).\n>>> Tensor[torch.uint8, 1]      # dtype=torch.uint8, shape=(1,).\n>>> TFTensor[tf.complex128, ()] # dtype=tf.complex128, shape=().\n\n\nWildcard dimensions (-1)\n------------------------\nAn ``-1`` can be used as a wildcard in place of a single dimension size. They\nbehave as a stand-in for any positive integer, and they can be used as many\ntimes as desired within a shape hint.\n\n\nEllipses (...)\n--------------\nAn ``Ellipsis`` object can be used in place of a nonnegative integer number of\npositive integer dimension sizes. The intended use case for this is when you\nknow the prefix of a tensor shape, the batch size for example, but not the\nremaining dimension sizes (perhaps they vary). You can use something like:\n\n>>> Array[32, ...]\n\nto match arrays with shape:\n\n>>> (32,)\n>>> (32, 24)\n>>> (32, 1, 2, 3)\n\nand so on. These should be a LAST RESORT, since as will be discussed below, we\ncan specify dimensions, shapes, or portions of shapes as variables, even if\nthey will change at runtime, e.g. on every iteration of some loop.\n\nMultiple ellipses can be used within a single annotation as well, in case you\nhappen to know that a tensor or array will have a dimension size of 7 somewhere\nin its shape, but you don't know where, or you don't know the total rank.\nSomething like the following:\n\n>>> TFTensor[..., 7, ...]\n\nwill match tensorflow tensors with shape:\n\n>>> (7,)\n>>> (1, 7)\n>>> (7, 3)\n>>> (1, 2, 3, 7, 4, 5, 6)\n\nand so on. Note that two ellipses cannot be used consecutively, e.g.\n\n>>> Array[1, 2, ..., ..., 5]\n\nsince asta won't be able to determine which dimensions should be substituted\nfor which ellipsis object.\n\n\nTypechecked decorator\n---------------------\nAs mentioned above, asta implements a decorator for runtime typechecking using\ntype hints like ``Array[]``. It can be used to decorate functions, instance\nmethods, class methods, metaclass methods, or even entire classes (this is just\nequivalent to decorating each of the class's methods).\n\nThe following gives an example of using the ``@typechecked`` decorator to\nenforce torch tensor shapes and dtypes at runtime. The function ``kl`` will\nraise a TypeError if called with inputs which have any dtype other than\n``torch.float32``, or any shape other than ``(8, 64)``.\n\n>>> import os\n>>> import torch.nn.functional as F\n>>> from asta import Tensor, typechecked\n>>>\n>>> os.environ[\"ASTA_TYPECHECK\"] = \"1\"\n>>>\n>>>\n>>> @typechecked\n>>> def kl(t_1: Tensor[float, 8, 64], t_2: Tensor[float, 8, 64]) -> Tensor[()]:\n>>>     \"\"\" Computes the KL divergence of two Tensors of shape ``(8, 64)``. \"\"\"\n>>>     divergence = F.kl_div(t_1, t_2, reduction=\"sum\")\n>>>     return divergence\n\nA runnable example is given in ``example.py`` in the repository root. For a\nmore fleshed-out, real world example, see ``asta/tests/rl/`` for a typechecked\npolicy gradient implementation.\n\n\nVariable shapes and dimensions\n------------------------------\nAsta also supports variable shape arguments:\n\n>>> from asta import dims, shapes\n>>> BATCH_SIZE = dims.BATCH_SIZE\n>>> SEQ_LEN = dims.SEQ_LEN\n>>> OBS_SHAPE = shapes.OBS_SHAPE\n>>> ...\n>>> dims.BATCH_SIZE = 32\n>>> dims.SEQ_LEN = 256\n>>> shapes.OBS_SHAPE = (4, 5, 6)\n>>> ...\n>>> Tensor[float, BATCH_SIZE, SEQ_LEN]          # shape=(32,256).\n>>> Tensor[float, (BATCH_SIZE,) + OBS_SHAPE]    # shape=(32,4,5,6).\n\nThese can be accessed from ``asta.dims`` for use in annotating top-level\nfunctions and then set after import-time during the execution of a program,\nallowing for shape annotations which depend on control flow or which change\nduring execution:\n\n(utils.py)\n>>> from asta import dims\n>>> HIDDEN_DIM = dims.HIDDEN_DIM\n>>> @typechecked\n>>> def identity(x: Tensor[float, HIDDEN_DIM]) -> Tensor[float, HIDDEN_DIM]:\n>>>     return x\n...\n(main.py)\n>>> from utils import example_fn\n>>> dims.HIDDEN_DIM = 768\n>>> x = torch.ones((768,))\n>>> y = identity(x)\n\nAs seen above, this allows dimension or shape constants, stored in\n``asta.dims`` and ``asta.shapes`` respectively by setting a named attribute, to\npersist as globals across modules. This need not be constants, either. We can\nreset the value of ``dims.<NAME>``, and all typechecked function calls\noccurring after the aforementioned statement executes will reflect the updated\nvalue of ``dims.<NAME>``. Under the hood, this works because ``dims`` and\n``shapes`` are actually instances of classes with the ``__getattr__`` and\n``__setattr__`` functions overridden. They return a placeholder object for any\nattribute accessed, and then update the value of that placeholder whenever that\nattribute is set later on.\n\n\nDimension inference\n-------------------\nAsta also supports arbitrary expressions of symbolic shape arguments:\n\n>>> from asta import symbols\n>>> X = symbols.X\n>>> Y = symbols.Y\n>>> Tensor[float, (X, X**2, X**3)]      # e.g. shape=(2,4,8) or shape=(1,1,1).\n>>> Tensor[float, (X + Y, (X + Y)**2)]  # Multivariate supported as well.\n\nChecks on the above objects will do inference based on the passed tensor,\nconstructing a system of equations based on the actual shape and returning a\nmatch if there exists at least one solution to the system. This means the\nequation solver is lenient, if you pass it a system which has many solutions,\nor infinitely many solutions, it will still return a match. Something like:\n\n>>> from asta import symbols\n>>> X = symbols.X\n>>> Y = symbols.Y\n>>> Tensor[X + Y]\n\nused as an annotation for ``torch.ones((50,))``, for example, yields the\nequation ``X + Y = 50``, which has many solutions for positive integer values\nof ``X`` and ``Y``. But this will not raise an error. Similar to the case with\nEllipses, symbols should only be used as a LAST RESORT, since it is often\npossible to make a lazy-definition of a ``dims`` placeholder prior to the\nfunction call instead, which will be more precise. They are useful, however, if\nyou're averse to peppering your code with dimension storage statements (like\n``dims.W = 256`` or something), or if it doesn't matter what the specific\nvalues of the sizes are, only that they obey some constraint relative to each\nother.\n\n\nConfiguration\n-------------\nThe behavior of the ``@typechecked`` decorator can be configured through a\nconfiguration file, like ``setup.cfg``, ``pyproject.toml``, ``astarc``, or\n``.astarc``. The ``on`` option can also be toggled via an environment variable\ncalled ``ASTA_TYPECHECK``, which, if set to \"1\", will check, and will do\nnothing if set to \"0\". If the option from the environment variable and the\nconfiguration file conflict, asta will default to ``off``.\n\nAn example config file is given below, and in ``asta/defaults/astarc``.\n\n>>> [MASTER]\n>>>\n>>> on=yes\n>>> raise-errors=yes\n>>> print-passes=yes\n>>> check-non-asta-types=no\n>>> check-all-sequence-elements=yes\n\nAnd explanations of the options:\n\n``on`` : Determines whether or not functions are typechecked. Does as little as\n    possible other than calling the wrapped function when set to ``no``.\n``raise-errors`` : If ``yes`` errors will be raised when a typecheck fails,\n    otherwise, the error will only be printed.\n``print-passes`` : If ``yes`` all passed typechecks will be printed, otherwise,\n    they will be silent (similar to mypy/pylint output).\n``check-non-asta-types`` : If ``yes`` asta will attempt to check the types of\n    everything passed to or returned from a function. A wide variety of types\n    are supported. Note: some of the helper functions for these have been\n    adapted from those in the package ``typeguard``. Otherwise, it will only\n    check ``Array``, ``Tensor``, and ``TFTensor``, and composites of these,\n    like ``Dict[str, Tensor[1,2,3]]``.\n``check-all-sequence-elements`` : If ``yes``, it will check the types of all\n    elements in iterable types like ``List[*]``. Otherwise, it will only check the\n    first element in an attempt to be faster.\n\n\nSubscript arguments\n-------------------\nThe valid subscript arguments for ``Array`` and ``Tensor`` are as follows:\n\n    Types\n    -----\n\n        Array\n        -----\n        1. Any python type from the following list:\n            a. int\n            b. float\n            c. bool\n            d. complex\n            e. bytes\n            f. str\n            g. datetime\n            h. timedelta\n        2. Any numpy dtype, e.g. ``np.int64``.\n        3. Omitted (no argument passed).\n\n        Tensor\n        ------\n        1. Any python type from the following list:\n            a. int\n            b. float\n            c. bool\n            d. bytes\n        2. Any ``torch.Tensor``-supported torch dtype, e.g. ``torch.int64``.\n        3. Omitted (no argument passed).\n\n        TFTensor\n        --------\n        1. Any python type from the following list:\n            a. int\n            b. float\n            c. bool\n            d. bytes\n        2. Any ``torch.Tensor``-supported tensorflow dtype, e.g. ``tf.int64``.\n        3. Omitted (no argument passed).\n\n    Shapes\n    ------\n    1. Nonnegative integers.\n    2. ``-1``, a wildcard for any positive integer size.\n    3. Ellipses (``...``), a placeholder for any contiguous sequence of\n    positive integer sizes, including zero-length sequences.\n    4. ``()`` or ``Scalar``, which both indicate a scalar array or tensor.\n    These are interchangeable.\n    5. Dimensions from ``asta.dims``.\n    6. Shapes from ``asta.shapes``.\n    7. Symbols from ``asta.symbols``.\n    8. Omitted (no argument passed).\n\n\nShape constraints and best practices\n------------------------------------\nThere is a key difference between the way scalar values are handled in numpy\nand the way they are handled in torch. Consider an array/tensor of shape\n``(2,2,2)``. When indexing the first element along each dimension, which should\nbe scalar, we call ``a[0,0,0]``, where ``a`` is our array. We do the same to a\ntensor ``t``, and assign the result to variables ``x`` and ``y``, respectively:\n\n>>> a = np.zeros((2,2,2))\n>>> t = torch.zeros((2,2,2))\n>>> x = a[0,0,0]\n>>> y = t[0,0,0]\n\nWhat are the types of ``x`` and ``y``?\n\n>>> type(x)\n<class 'numpy.float64'>\n>>> type(y)\n<class 'torch.Tensor'>\n\nInterestingly enough, while ``a`` is of type ``np.ndarray``, ``x`` is of type\n``np.float64``, a subclass of float, while both ``t`` and ``y`` are tensors.\nNote that ``x`` is not an array:\n\n>>> isinstance(x, np.ndarray)\nFalse\n>>> isinstance(x, float)\nTrue\n\nAnd ``y`` is not a float:\n\n>>> isinstance(y, torch.Tensor)\nTrue\n>>> isinstance(y, float)\nFalse\n\nAsta does not attempt to rectify this discrepancy, and so the behavior of\n``Array`` and ``Tensor`` when it comes to scalars is slightly different. In the\nabove, ``x`` is not an instance of ``Array``, while ``y`` is an instance of\n``Tensor``, even though they are indexed in an identical manner.\n\nUse of the ellipsis placeholder (``...``) in asta is meant to mirror its usage\nin numpy/torch indexing. This is why we allow ``...`` to take the place of an\nemtpy shape. Note that indexing scalar arrays with an ellipsis returns the\narray unchanged:\n\n>>> np.zeros(())\narray(0.)\n>>> a = np.zeros(())\n>>> a[...]\narray(0.)\n\nAnd adding an Ellipsis anywhere in an already-filled index tuple will return a\nscalar array with the expected value:\n\n>>> a = np.zeros((2,2,2))\n>>> a[0,0,0]\n0.0\n>>> a[0,0,0,...]\narray(0.)\n>>> a[0,0,...,0]\narray(0.)\n>>> a[...,0,0,0]\narray(0.)\n\nIn contrast, we take the ``-1`` wildcard argument to represent only a single\npositive integer shape element. So if you wanted to all arrays with shape\n``(1,*,1)``, where ``*`` is nonempty, i.e. don't match arrays of shape\n``(1,1)``, but do match any of the following:\n\n1. ``(1, 1, 1)``\n2. ``(1, 2, 1)``\n3. ``(1, 2, 3, 4, 5, 1)``\n\nYou would use ``Array[1,-1,...,1]``.\n\n\nPerformance\n-----------\nThe runtime checking functionality of asta is NOT meant to be used in\nsituations where performance/speed is critical. Furthermore, use of the values\nof type hints within python code, which ``@typechecked`` decorator relies on,\nis not recommended; the ability to type hint in python is meant to be just\nthat, a hint. The usefulness of using the decorator is as a debugging or\ntesting step when working on large, complicated models or workflows. Many of\nthe native numpy and pytorch array/tensor functions allow arbitrary shaped\ninputs, and it is easy for a malformed shape to pass unnoticed, with no effects\nother than poor downstream performance or results. Asta is meant to be a crude\naide in dealing with this common problem, but by no means a comprehensive one.\n\nThis having been said, the ``isinstance()`` checks used are relatively cheap,\nand shouldn't cause a serious slowdown outside of exceptional cases.\n\nThe recommended usage of this library would be to annotate all critical\nfunctions which take or return ndarrays/tensors, and decorate them with\n``@typechecked``. One could then add a CI test which sets the\n``ASTA_TYPECHECK`` environment variable to ``1`` and runs a sample workflow.\nAny incorrect dtypes or malformed shapes will raise a TypeError, and typechecks\nwhich pass will print to stdout. This behavior is intentional, and meant to\nhelp researchers avoid silent performance degradation due to leaving the\nenvironment variable set, which will cause a slight slowdown which would\notherwise occur silently.\n\n\n========\nINTERNAL\n========\n\n\nTodo\n----\n- Add ``# type: ignore`` comments in test files. The ``[type-arg]`` and\n  ellipses errors will be ignored when the package is installed. They just need\n  to be silenced within the package itself. (DONE)\n- Delete ``demo.py``. (DONE)\n- Implement ``-1`` wildcard shape element suppport. (DONE)\n- Add tests for ``Tensor``. (DONE)\n- Write examples in README. (DONE)\n- Add tests for empty arrays and tensors. (DONE)\n- Consider making Ellipses only match empty shapes and positive integer shapes,\n  but not zero-valued shapes. This would be done under the assumption that most\n  people are not interested in working with empty arrays/tensors. And if they\n  are, they can use the ``.size`` attribute for an easy check. (DONE)\n- Add reprs. (DONE)\n- Fix tensor strategy. (DONE)\n- Add an option to disable typechecked decorator (default=disabled, ``.astarc``\n  file).\n- Add environment variable for typechecking. (DONE)\n- Add tests for ``@typechecked``. (DONE)\n- Consider changing name of decorator to ``@shapechecked``. (NO)\n- Consider dropping the ``Scalar`` object. The less unfamiliar objects, the\n  better. (NO)\n- Add more descriptive error if you pass torch dtype for an Array or numpy\n  dtype for a Tensor. (DONE)\n- Add ``CudaTensor`` class. (DONE)\n- Consider adding support for arbitrary shape/type constraints as subscript\n  arguments. They would be of the form:\n\n    >>> def fn(shape: Tuple[int, ...]) -> bool:\n    >>>     n: int\n    >>>     for i, elem in enumerate(shape):\n    >>>         if i == 0:\n    >>>             n = elem\n    >>>         elif elem == 2 * n:\n    >>>             n = elem\n    >>>         else:\n    >>>             return False\n    >>>     return True\n\n  The above constraint would only pass for shapes ``(n, 2n, 4n, 8n...)``.\n  To enforce it, you would use ``Array[fn]``. (NO)\n- Consider allowing instantiation to support kwargs. (DETAILED BELOW)\n- Consider adding a delimiter in the typecheck decorator output to distinguish\n  the typecheck passes between different functions and signatures. Something\n  like ``===============<asta.typechecked_function()>===============``. (DONE)\n- Consider adding support for tensorflow. (DONE)\n- Consider adding support for passing ``()`` as in ``Array[int, ()]`` to denote\n  scalar arrays instead of ``Scalar`` or ``None``. (DONE)\n- Write tests for ``Scalar``.\n- Write analogues of new ``Array`` tests for ``Tensor``. (DONE)\n- Consider reserving ``None`` shape and type for unintialized shape globals.\n  (NO)\n  Attempting to typecheck with them will raise an error warning that they are\n  uninitialized. Then you can set your dim variable defaults in config module\n  all to ``None``. (DONE)\n- Add uninitialized dimension size error to decorator. See preceding note.\n  (DONE)\n- Add section in README about using ``asta.dims`` for programmatically-set\n  dimension sizes in shape annotations.\n- Fix base class of ``_ArrayMeta`` and ``_TensorMeta`` so that type ignore is\n  not needed in ``decorators.py``.\n- Consider removing library-specific metaclasses.\n- Consider making ``parse_subscript`` a classmethod of ``SubscriptableMeta``.\n  (NO)\n- Remove torch, tensorflow from requirements. You should be able to ues\n  ``Array`` without torch installed. (DONE)\n- When you try to import Tensor when torch is not installed, no error should be\n  raised. But when you then try to use/subscript Tensor, an error should be\n  raised. So it should still be a subscriptable type, but the subscription\n  method should try to import torch. (DONE)\n- Consider adding a ``soft`` mode where the decorator only prints errors\n  instead of raising them, so that a user could see and correct all of them at\n  once. (DONE)\n- Consider adding support for checking arbitrary attributes on arrays and\n  tensors. For example, if working on a reinforcement learning problem, and you\n  wanted to make sure all tensors have the same timestep index, you could seta\n  ``<torch.Tensor>.timestep: int`` attribute and then assert that they all\n  match at function call time. (DONE)\n- This could have syntax like:\n\n    >>> def product(\n    >>>     t1: Tensor(float, 1,2,3, timestep=K),\n    >>>     t2: Tensor(float, 1,2,3, timestep=K + 1),\n    >>> ) -> Tensor(float, 1,2,3):\n\n  This would require implementing an ``__init__()`` for array classes, which\n  would just return an instance of the metaclass with the appropriate class\n  variables set. Alternatively, we could use a dictionary:\n\n    >>> def product(\n    >>>     t1: Tensor[float, 1,2,3, {\"timestep\": K}],\n    >>>     t2: Tensor[float, 1,2,3, {\"timestep\": K + 1}],\n    >>> ) -> Tensor[float, 1,2,3]:\n\n  This is much better because it doesn't break the convention of using\n  subscriptable objects for annotations. (DONE)\n\n- This would also require an implementation of non-contant shapes/variables.\n  For example, if you know all your tensors will have length ``k``, but ``k``\n  is variable, then you import ``K`` from some asta namespace. This will return\n  a placeholder-like object with no set value. At typecheck time, it will be\n  inferred from the first argument checked which makes use of this variable.\n  The typechecker will assert that all other instances of ``K`` have the same\n  value as this initialized one, and if soft checking is enabled, it will print\n  out all of them along with an error message. (DONE)\n\n- Rewrite README.\n- Fix source code headers. (DONE)\n_ Add support for generics:\n    - List (DONE)\n    _ Sequence (DONE)\n    - Dict (DONE)\n    - Set (DONE)\n    - Callable (DONE)\n- Write tests for decorated classes, attributes, equation solver, placeholders,\n  instance/class/metaclass methods, and the above generic subscriptable types.\n- Resolve the discrepancy between default dtypes of tensors (float32 in TF),\n  and default dtype given the primitive float argument (float64). What is the\n  most natural behavior? Follow PLA. (DONE)\n- In line with above, consider making checks for primitive types (int, float,\n  complex, bytes, str) less strict. This should be done if there is time. (NO)\n- Put on PyPI.\n- Bug: disabling/enabling asta per-file is likely broken, since importing check\n  sets the value of an environment variable, which is global during python\n  execution. (DONE)\n- Consider adding ``asta.shp`` and ``asta.dims`` so that integer and tuple\n  dimensions/shapes are in two separate storage modules. This would also mean\n  you could write ``shp.OBS`` intead of ``OBS_SHAPE`` or ``dims.OBS_SHAPE``,\n  which are both rather long and take up a good chunk of the hint size.\n- Decide on whether the storage modules should be plural (shp, dim, symbol) or\n  (shps, dims, symbols)? Singular is shorter and looks nicer, maybe?\n- Placeholder should support addition as tuple concatenation. Does this already\n  work?\n- Placeholders dims (scalars) should support arbitrary mathematical expressions\n  involving symbols.\n- Add configuration parsing. (DONE)\n- Consider just not implementing per-module typecheck enable/disable. It should\n  be all or nothing via either the configuration file option or the environment\n  variable.\n- Consider implementing per-module disable via a global variable in each\n  module. The decorators can see the scope of the module from which they are\n  called, and these scopes are independent, so set ``ASTA_MODULE_DISABLE =\n  True``and asta will skip checking that module.\n- Don't support default precisions because it decreases type transparency.\n  (DONE)\n- Support subcriptable aliases:\n\n    >>> CudaTensor = Tensor[{\"device\": \"cuda:0\"}]\n    >>> FloatCudaTensor = CudaTensor[float]\n\n  Currently, subscripting ``CudaTensor`` as above will overwrite/delete the\n  existing subscript. So just add a class attribute that saves the subscript,\n  and upon subscription, combines the previous subscript with the new\n  subscript, raising an error if an attribute is already set. Actually, on\n  second though, instead of saving the subscript, just save the parsed class\n  attributes. (DONE)\n- Bug: tuples cannot be summed without unpacking ``Tensor[shapes.OB + (1,)]``.\n  (DONE)\n- Bug: Header should still be printed when an error is raised if\n  ``ox.print_passes`` is off. (DONE)\n- ---MERGE---(DONE)\n- Update README (DONE)\n- Add warning when ``ox.print_passes`` is False, so that the user doesn't\n  accidentally leave it on, slowing down their program, and make this happen at\n  import-time, so that if the part where they're calling typechecked functions\n  doesn't happen for a while, they still know immediately. (DONE)\n- ---MERGE---\n- Consider adding an ``args`` module. So if you have a function:\n\n    >>> def fn(k: int) -> Tensor[<k>]:\n    >>>     return torch.ones((k,))\n\n  where the shape is dependent on the arguments, you could annotate it.\n  Syntax would look like this:\n\n    >>> def fn(k: int) -> Tensor[args.k]:\n    >>>     return torch.ones((k,))\n\n- Consider adding probabilistic checking, i.e. if a function has been called\n  100,000 times and none of them have failed, maybe stop checking it,\n  especially if it's taking a long time. We can do inference and estimate the\n  probability that the function will fail.\n- Before we do the above, attempt to jit compile everything in asta.\n- Consider making overwrites of class attributes like:\n\n    >>> Tensor[float][float]\n\n  raise an error saying the attribute has already been defined. Perhaps\n  ``kwattrs`` allows overwriting as long as there are no keys in common or\n  something. Is an error expected behavior, or should we be lenient?\n- Consider adding checks before looping over any iterable to make sure the\n  subscript annotation is an astatype in the case where\n  ``ox.check_non_asta_types`` is false.\n- Consider making ``@typechecked`` callable so we can call:\n\n    >>> @typechecked(print=True)\n    >>> def ...\n\n  So then we can have ``print-all-passes=no`` but still print the one we're\n  debugging.\n\n\n\nAcknowledgements\n----------------\n- Based on the excellent packages 'nptyping' by Ramon Hagenaars and 'typeguard'\n  by Alex Gr\u00f6nholm.\n- Thanks to Michael Crawshaw (@mtcrawshaw) for helpful comments on natural\n  shape constraints and handling of 0-valued dimension sizes.\n\n\n", "description_content_type": "text/plain", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "asta", "package_url": "https://pypi.org/project/asta/", "platform": "", "project_url": "https://pypi.org/project/asta/", "project_urls": null, "release_url": "https://pypi.org/project/asta/0.0.7/", "requires_dist": ["toml", "numpy", "sympy", "oxentiel"], "requires_python": ">=3.7.0", "summary": "Shape annotations for homogeneous numpy arrays and pytorch/tensorflow tensors.", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            +----+<br>|asta|<br>+----+<br><br>Shape annotations for numpy arrays and pytorch/tensorflow tensors.<br><br>Introduction<br>------------<br>This library defines subscriptable classes ``Array``, ``Tensor``, and<br>``TFTensor`` for use in ``isinstance()`` checks and type annotations.  It also<br>adds a decorator, ``@typechecked``, which implements toggleable static type<br>enforcement for the classes described above.<br><br><br>Installation<br>------------<br>$ pip install asta<br>$ pip install git+git://github.com/brendanxwhitaker/asta.git<br><br><br>Basics<br>------<br>Asta supports checking dtypes and/or shapes with wildcards and ellipses:<br><br>&gt;&gt;&gt; Array[float]                # dtype=np.float64.<br>&gt;&gt;&gt; Array[float, 1, 2, 3]       # dtype=np.float64, shape=(1,2,3).<br>&gt;&gt;&gt; Array[float, (1, 2, 3)]     # dtype=np.float64, shape=(1,2,3).<br>&gt;&gt;&gt; Array[1, 2, 3]              # shape=(1,2,3).<br>&gt;&gt;&gt; Array[int, ()]              # dtype=np.int64, shape=().<br>&gt;&gt;&gt; Array[str, 1, 2 ..., 3]     # dtype=unicode, shape=(1,2,*...*,3).<br>&gt;&gt;&gt; Array[str, 1, 2 -1, 3]      # dtype=unicode, shape=(1,2,*,3).<br>&gt;&gt;&gt; Tensor[torch.uint8, 1]      # dtype=torch.uint8, shape=(1,).<br>&gt;&gt;&gt; TFTensor[tf.complex128, ()] # dtype=tf.complex128, shape=().<br><br><br>Wildcard dimensions (-1)<br>------------------------<br>An ``-1`` can be used as a wildcard in place of a single dimension size. They<br>behave as a stand-in for any positive integer, and they can be used as many<br>times as desired within a shape hint.<br><br><br>Ellipses (...)<br>--------------<br>An ``Ellipsis`` object can be used in place of a nonnegative integer number of<br>positive integer dimension sizes. The intended use case for this is when you<br>know the prefix of a tensor shape, the batch size for example, but not the<br>remaining dimension sizes (perhaps they vary). You can use something like:<br><br>&gt;&gt;&gt; Array[32, ...]<br><br>to match arrays with shape:<br><br>&gt;&gt;&gt; (32,)<br>&gt;&gt;&gt; (32, 24)<br>&gt;&gt;&gt; (32, 1, 2, 3)<br><br>and so on. These should be a LAST RESORT, since as will be discussed below, we<br>can specify dimensions, shapes, or portions of shapes as variables, even if<br>they will change at runtime, e.g. on every iteration of some loop.<br><br>Multiple ellipses can be used within a single annotation as well, in case you<br>happen to know that a tensor or array will have a dimension size of 7 somewhere<br>in its shape, but you don't know where, or you don't know the total rank.<br>Something like the following:<br><br>&gt;&gt;&gt; TFTensor[..., 7, ...]<br><br>will match tensorflow tensors with shape:<br><br>&gt;&gt;&gt; (7,)<br>&gt;&gt;&gt; (1, 7)<br>&gt;&gt;&gt; (7, 3)<br>&gt;&gt;&gt; (1, 2, 3, 7, 4, 5, 6)<br><br>and so on. Note that two ellipses cannot be used consecutively, e.g.<br><br>&gt;&gt;&gt; Array[1, 2, ..., ..., 5]<br><br>since asta won't be able to determine which dimensions should be substituted<br>for which ellipsis object.<br><br><br>Typechecked decorator<br>---------------------<br>As mentioned above, asta implements a decorator for runtime typechecking using<br>type hints like ``Array[]``. It can be used to decorate functions, instance<br>methods, class methods, metaclass methods, or even entire classes (this is just<br>equivalent to decorating each of the class's methods).<br><br>The following gives an example of using the ``@typechecked`` decorator to<br>enforce torch tensor shapes and dtypes at runtime. The function ``kl`` will<br>raise a TypeError if called with inputs which have any dtype other than<br>``torch.float32``, or any shape other than ``(8, 64)``.<br><br>&gt;&gt;&gt; import os<br>&gt;&gt;&gt; import torch.nn.functional as F<br>&gt;&gt;&gt; from asta import Tensor, typechecked<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; os.environ[\"ASTA_TYPECHECK\"] = \"1\"<br>&gt;&gt;&gt;<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; @typechecked<br>&gt;&gt;&gt; def kl(t_1: Tensor[float, 8, 64], t_2: Tensor[float, 8, 64]) -&gt; Tensor[()]:<br>&gt;&gt;&gt;     \"\"\" Computes the KL divergence of two Tensors of shape ``(8, 64)``. \"\"\"<br>&gt;&gt;&gt;     divergence = F.kl_div(t_1, t_2, reduction=\"sum\")<br>&gt;&gt;&gt;     return divergence<br><br>A runnable example is given in ``example.py`` in the repository root. For a<br>more fleshed-out, real world example, see ``asta/tests/rl/`` for a typechecked<br>policy gradient implementation.<br><br><br>Variable shapes and dimensions<br>------------------------------<br>Asta also supports variable shape arguments:<br><br>&gt;&gt;&gt; from asta import dims, shapes<br>&gt;&gt;&gt; BATCH_SIZE = dims.BATCH_SIZE<br>&gt;&gt;&gt; SEQ_LEN = dims.SEQ_LEN<br>&gt;&gt;&gt; OBS_SHAPE = shapes.OBS_SHAPE<br>&gt;&gt;&gt; ...<br>&gt;&gt;&gt; dims.BATCH_SIZE = 32<br>&gt;&gt;&gt; dims.SEQ_LEN = 256<br>&gt;&gt;&gt; shapes.OBS_SHAPE = (4, 5, 6)<br>&gt;&gt;&gt; ...<br>&gt;&gt;&gt; Tensor[float, BATCH_SIZE, SEQ_LEN]          # shape=(32,256).<br>&gt;&gt;&gt; Tensor[float, (BATCH_SIZE,) + OBS_SHAPE]    # shape=(32,4,5,6).<br><br>These can be accessed from ``asta.dims`` for use in annotating top-level<br>functions and then set after import-time during the execution of a program,<br>allowing for shape annotations which depend on control flow or which change<br>during execution:<br><br>(utils.py)<br>&gt;&gt;&gt; from asta import dims<br>&gt;&gt;&gt; HIDDEN_DIM = dims.HIDDEN_DIM<br>&gt;&gt;&gt; @typechecked<br>&gt;&gt;&gt; def identity(x: Tensor[float, HIDDEN_DIM]) -&gt; Tensor[float, HIDDEN_DIM]:<br>&gt;&gt;&gt;     return x<br>...<br>(main.py)<br>&gt;&gt;&gt; from utils import example_fn<br>&gt;&gt;&gt; dims.HIDDEN_DIM = 768<br>&gt;&gt;&gt; x = torch.ones((768,))<br>&gt;&gt;&gt; y = identity(x)<br><br>As seen above, this allows dimension or shape constants, stored in<br>``asta.dims`` and ``asta.shapes`` respectively by setting a named attribute, to<br>persist as globals across modules. This need not be constants, either. We can<br>reset the value of ``dims.&lt;NAME&gt;``, and all typechecked function calls<br>occurring after the aforementioned statement executes will reflect the updated<br>value of ``dims.&lt;NAME&gt;``. Under the hood, this works because ``dims`` and<br>``shapes`` are actually instances of classes with the ``__getattr__`` and<br>``__setattr__`` functions overridden. They return a placeholder object for any<br>attribute accessed, and then update the value of that placeholder whenever that<br>attribute is set later on.<br><br><br>Dimension inference<br>-------------------<br>Asta also supports arbitrary expressions of symbolic shape arguments:<br><br>&gt;&gt;&gt; from asta import symbols<br>&gt;&gt;&gt; X = symbols.X<br>&gt;&gt;&gt; Y = symbols.Y<br>&gt;&gt;&gt; Tensor[float, (X, X**2, X**3)]      # e.g. shape=(2,4,8) or shape=(1,1,1).<br>&gt;&gt;&gt; Tensor[float, (X + Y, (X + Y)**2)]  # Multivariate supported as well.<br><br>Checks on the above objects will do inference based on the passed tensor,<br>constructing a system of equations based on the actual shape and returning a<br>match if there exists at least one solution to the system. This means the<br>equation solver is lenient, if you pass it a system which has many solutions,<br>or infinitely many solutions, it will still return a match. Something like:<br><br>&gt;&gt;&gt; from asta import symbols<br>&gt;&gt;&gt; X = symbols.X<br>&gt;&gt;&gt; Y = symbols.Y<br>&gt;&gt;&gt; Tensor[X + Y]<br><br>used as an annotation for ``torch.ones((50,))``, for example, yields the<br>equation ``X + Y = 50``, which has many solutions for positive integer values<br>of ``X`` and ``Y``. But this will not raise an error. Similar to the case with<br>Ellipses, symbols should only be used as a LAST RESORT, since it is often<br>possible to make a lazy-definition of a ``dims`` placeholder prior to the<br>function call instead, which will be more precise. They are useful, however, if<br>you're averse to peppering your code with dimension storage statements (like<br>``dims.W = 256`` or something), or if it doesn't matter what the specific<br>values of the sizes are, only that they obey some constraint relative to each<br>other.<br><br><br>Configuration<br>-------------<br>The behavior of the ``@typechecked`` decorator can be configured through a<br>configuration file, like ``setup.cfg``, ``pyproject.toml``, ``astarc``, or<br>``.astarc``. The ``on`` option can also be toggled via an environment variable<br>called ``ASTA_TYPECHECK``, which, if set to \"1\", will check, and will do<br>nothing if set to \"0\". If the option from the environment variable and the<br>configuration file conflict, asta will default to ``off``.<br><br>An example config file is given below, and in ``asta/defaults/astarc``.<br><br>&gt;&gt;&gt; [MASTER]<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; on=yes<br>&gt;&gt;&gt; raise-errors=yes<br>&gt;&gt;&gt; print-passes=yes<br>&gt;&gt;&gt; check-non-asta-types=no<br>&gt;&gt;&gt; check-all-sequence-elements=yes<br><br>And explanations of the options:<br><br>``on`` : Determines whether or not functions are typechecked. Does as little as<br>    possible other than calling the wrapped function when set to ``no``.<br>``raise-errors`` : If ``yes`` errors will be raised when a typecheck fails,<br>    otherwise, the error will only be printed.<br>``print-passes`` : If ``yes`` all passed typechecks will be printed, otherwise,<br>    they will be silent (similar to mypy/pylint output).<br>``check-non-asta-types`` : If ``yes`` asta will attempt to check the types of<br>    everything passed to or returned from a function. A wide variety of types<br>    are supported. Note: some of the helper functions for these have been<br>    adapted from those in the package ``typeguard``. Otherwise, it will only<br>    check ``Array``, ``Tensor``, and ``TFTensor``, and composites of these,<br>    like ``Dict[str, Tensor[1,2,3]]``.<br>``check-all-sequence-elements`` : If ``yes``, it will check the types of all<br>    elements in iterable types like ``List[*]``. Otherwise, it will only check the<br>    first element in an attempt to be faster.<br><br><br>Subscript arguments<br>-------------------<br>The valid subscript arguments for ``Array`` and ``Tensor`` are as follows:<br><br>    Types<br>    -----<br><br>        Array<br>        -----<br>        1. Any python type from the following list:<br>            a. int<br>            b. float<br>            c. bool<br>            d. complex<br>            e. bytes<br>            f. str<br>            g. datetime<br>            h. timedelta<br>        2. Any numpy dtype, e.g. ``np.int64``.<br>        3. Omitted (no argument passed).<br><br>        Tensor<br>        ------<br>        1. Any python type from the following list:<br>            a. int<br>            b. float<br>            c. bool<br>            d. bytes<br>        2. Any ``torch.Tensor``-supported torch dtype, e.g. ``torch.int64``.<br>        3. Omitted (no argument passed).<br><br>        TFTensor<br>        --------<br>        1. Any python type from the following list:<br>            a. int<br>            b. float<br>            c. bool<br>            d. bytes<br>        2. Any ``torch.Tensor``-supported tensorflow dtype, e.g. ``tf.int64``.<br>        3. Omitted (no argument passed).<br><br>    Shapes<br>    ------<br>    1. Nonnegative integers.<br>    2. ``-1``, a wildcard for any positive integer size.<br>    3. Ellipses (``...``), a placeholder for any contiguous sequence of<br>    positive integer sizes, including zero-length sequences.<br>    4. ``()`` or ``Scalar``, which both indicate a scalar array or tensor.<br>    These are interchangeable.<br>    5. Dimensions from ``asta.dims``.<br>    6. Shapes from ``asta.shapes``.<br>    7. Symbols from ``asta.symbols``.<br>    8. Omitted (no argument passed).<br><br><br>Shape constraints and best practices<br>------------------------------------<br>There is a key difference between the way scalar values are handled in numpy<br>and the way they are handled in torch. Consider an array/tensor of shape<br>``(2,2,2)``. When indexing the first element along each dimension, which should<br>be scalar, we call ``a[0,0,0]``, where ``a`` is our array. We do the same to a<br>tensor ``t``, and assign the result to variables ``x`` and ``y``, respectively:<br><br>&gt;&gt;&gt; a = np.zeros((2,2,2))<br>&gt;&gt;&gt; t = torch.zeros((2,2,2))<br>&gt;&gt;&gt; x = a[0,0,0]<br>&gt;&gt;&gt; y = t[0,0,0]<br><br>What are the types of ``x`` and ``y``?<br><br>&gt;&gt;&gt; type(x)<br>&lt;class 'numpy.float64'&gt;<br>&gt;&gt;&gt; type(y)<br>&lt;class 'torch.Tensor'&gt;<br><br>Interestingly enough, while ``a`` is of type ``np.ndarray``, ``x`` is of type<br>``np.float64``, a subclass of float, while both ``t`` and ``y`` are tensors.<br>Note that ``x`` is not an array:<br><br>&gt;&gt;&gt; isinstance(x, np.ndarray)<br>False<br>&gt;&gt;&gt; isinstance(x, float)<br>True<br><br>And ``y`` is not a float:<br><br>&gt;&gt;&gt; isinstance(y, torch.Tensor)<br>True<br>&gt;&gt;&gt; isinstance(y, float)<br>False<br><br>Asta does not attempt to rectify this discrepancy, and so the behavior of<br>``Array`` and ``Tensor`` when it comes to scalars is slightly different. In the<br>above, ``x`` is not an instance of ``Array``, while ``y`` is an instance of<br>``Tensor``, even though they are indexed in an identical manner.<br><br>Use of the ellipsis placeholder (``...``) in asta is meant to mirror its usage<br>in numpy/torch indexing. This is why we allow ``...`` to take the place of an<br>emtpy shape. Note that indexing scalar arrays with an ellipsis returns the<br>array unchanged:<br><br>&gt;&gt;&gt; np.zeros(())<br>array(0.)<br>&gt;&gt;&gt; a = np.zeros(())<br>&gt;&gt;&gt; a[...]<br>array(0.)<br><br>And adding an Ellipsis anywhere in an already-filled index tuple will return a<br>scalar array with the expected value:<br><br>&gt;&gt;&gt; a = np.zeros((2,2,2))<br>&gt;&gt;&gt; a[0,0,0]<br>0.0<br>&gt;&gt;&gt; a[0,0,0,...]<br>array(0.)<br>&gt;&gt;&gt; a[0,0,...,0]<br>array(0.)<br>&gt;&gt;&gt; a[...,0,0,0]<br>array(0.)<br><br>In contrast, we take the ``-1`` wildcard argument to represent only a single<br>positive integer shape element. So if you wanted to all arrays with shape<br>``(1,*,1)``, where ``*`` is nonempty, i.e. don't match arrays of shape<br>``(1,1)``, but do match any of the following:<br><br>1. ``(1, 1, 1)``<br>2. ``(1, 2, 1)``<br>3. ``(1, 2, 3, 4, 5, 1)``<br><br>You would use ``Array[1,-1,...,1]``.<br><br><br>Performance<br>-----------<br>The runtime checking functionality of asta is NOT meant to be used in<br>situations where performance/speed is critical. Furthermore, use of the values<br>of type hints within python code, which ``@typechecked`` decorator relies on,<br>is not recommended; the ability to type hint in python is meant to be just<br>that, a hint. The usefulness of using the decorator is as a debugging or<br>testing step when working on large, complicated models or workflows. Many of<br>the native numpy and pytorch array/tensor functions allow arbitrary shaped<br>inputs, and it is easy for a malformed shape to pass unnoticed, with no effects<br>other than poor downstream performance or results. Asta is meant to be a crude<br>aide in dealing with this common problem, but by no means a comprehensive one.<br><br>This having been said, the ``isinstance()`` checks used are relatively cheap,<br>and shouldn't cause a serious slowdown outside of exceptional cases.<br><br>The recommended usage of this library would be to annotate all critical<br>functions which take or return ndarrays/tensors, and decorate them with<br>``@typechecked``. One could then add a CI test which sets the<br>``ASTA_TYPECHECK`` environment variable to ``1`` and runs a sample workflow.<br>Any incorrect dtypes or malformed shapes will raise a TypeError, and typechecks<br>which pass will print to stdout. This behavior is intentional, and meant to<br>help researchers avoid silent performance degradation due to leaving the<br>environment variable set, which will cause a slight slowdown which would<br>otherwise occur silently.<br><br><br>========<br>INTERNAL<br>========<br><br><br>Todo<br>----<br>- Add ``# type: ignore`` comments in test files. The ``[type-arg]`` and<br>  ellipses errors will be ignored when the package is installed. They just need<br>  to be silenced within the package itself. (DONE)<br>- Delete ``demo.py``. (DONE)<br>- Implement ``-1`` wildcard shape element suppport. (DONE)<br>- Add tests for ``Tensor``. (DONE)<br>- Write examples in README. (DONE)<br>- Add tests for empty arrays and tensors. (DONE)<br>- Consider making Ellipses only match empty shapes and positive integer shapes,<br>  but not zero-valued shapes. This would be done under the assumption that most<br>  people are not interested in working with empty arrays/tensors. And if they<br>  are, they can use the ``.size`` attribute for an easy check. (DONE)<br>- Add reprs. (DONE)<br>- Fix tensor strategy. (DONE)<br>- Add an option to disable typechecked decorator (default=disabled, ``.astarc``<br>  file).<br>- Add environment variable for typechecking. (DONE)<br>- Add tests for ``@typechecked``. (DONE)<br>- Consider changing name of decorator to ``@shapechecked``. (NO)<br>- Consider dropping the ``Scalar`` object. The less unfamiliar objects, the<br>  better. (NO)<br>- Add more descriptive error if you pass torch dtype for an Array or numpy<br>  dtype for a Tensor. (DONE)<br>- Add ``CudaTensor`` class. (DONE)<br>- Consider adding support for arbitrary shape/type constraints as subscript<br>  arguments. They would be of the form:<br><br>    &gt;&gt;&gt; def fn(shape: Tuple[int, ...]) -&gt; bool:<br>    &gt;&gt;&gt;     n: int<br>    &gt;&gt;&gt;     for i, elem in enumerate(shape):<br>    &gt;&gt;&gt;         if i == 0:<br>    &gt;&gt;&gt;             n = elem<br>    &gt;&gt;&gt;         elif elem == 2 * n:<br>    &gt;&gt;&gt;             n = elem<br>    &gt;&gt;&gt;         else:<br>    &gt;&gt;&gt;             return False<br>    &gt;&gt;&gt;     return True<br><br>  The above constraint would only pass for shapes ``(n, 2n, 4n, 8n...)``.<br>  To enforce it, you would use ``Array[fn]``. (NO)<br>- Consider allowing instantiation to support kwargs. (DETAILED BELOW)<br>- Consider adding a delimiter in the typecheck decorator output to distinguish<br>  the typecheck passes between different functions and signatures. Something<br>  like ``===============&lt;asta.typechecked_function()&gt;===============``. (DONE)<br>- Consider adding support for tensorflow. (DONE)<br>- Consider adding support for passing ``()`` as in ``Array[int, ()]`` to denote<br>  scalar arrays instead of ``Scalar`` or ``None``. (DONE)<br>- Write tests for ``Scalar``.<br>- Write analogues of new ``Array`` tests for ``Tensor``. (DONE)<br>- Consider reserving ``None`` shape and type for unintialized shape globals.<br>  (NO)<br>  Attempting to typecheck with them will raise an error warning that they are<br>  uninitialized. Then you can set your dim variable defaults in config module<br>  all to ``None``. (DONE)<br>- Add uninitialized dimension size error to decorator. See preceding note.<br>  (DONE)<br>- Add section in README about using ``asta.dims`` for programmatically-set<br>  dimension sizes in shape annotations.<br>- Fix base class of ``_ArrayMeta`` and ``_TensorMeta`` so that type ignore is<br>  not needed in ``decorators.py``.<br>- Consider removing library-specific metaclasses.<br>- Consider making ``parse_subscript`` a classmethod of ``SubscriptableMeta``.<br>  (NO)<br>- Remove torch, tensorflow from requirements. You should be able to ues<br>  ``Array`` without torch installed. (DONE)<br>- When you try to import Tensor when torch is not installed, no error should be<br>  raised. But when you then try to use/subscript Tensor, an error should be<br>  raised. So it should still be a subscriptable type, but the subscription<br>  method should try to import torch. (DONE)<br>- Consider adding a ``soft`` mode where the decorator only prints errors<br>  instead of raising them, so that a user could see and correct all of them at<br>  once. (DONE)<br>- Consider adding support for checking arbitrary attributes on arrays and<br>  tensors. For example, if working on a reinforcement learning problem, and you<br>  wanted to make sure all tensors have the same timestep index, you could seta<br>  ``&lt;torch.Tensor&gt;.timestep: int`` attribute and then assert that they all<br>  match at function call time. (DONE)<br>- This could have syntax like:<br><br>    &gt;&gt;&gt; def product(<br>    &gt;&gt;&gt;     t1: Tensor(float, 1,2,3, timestep=K),<br>    &gt;&gt;&gt;     t2: Tensor(float, 1,2,3, timestep=K + 1),<br>    &gt;&gt;&gt; ) -&gt; Tensor(float, 1,2,3):<br><br>  This would require implementing an ``__init__()`` for array classes, which<br>  would just return an instance of the metaclass with the appropriate class<br>  variables set. Alternatively, we could use a dictionary:<br><br>    &gt;&gt;&gt; def product(<br>    &gt;&gt;&gt;     t1: Tensor[float, 1,2,3, {\"timestep\": K}],<br>    &gt;&gt;&gt;     t2: Tensor[float, 1,2,3, {\"timestep\": K + 1}],<br>    &gt;&gt;&gt; ) -&gt; Tensor[float, 1,2,3]:<br><br>  This is much better because it doesn't break the convention of using<br>  subscriptable objects for annotations. (DONE)<br><br>- This would also require an implementation of non-contant shapes/variables.<br>  For example, if you know all your tensors will have length ``k``, but ``k``<br>  is variable, then you import ``K`` from some asta namespace. This will return<br>  a placeholder-like object with no set value. At typecheck time, it will be<br>  inferred from the first argument checked which makes use of this variable.<br>  The typechecker will assert that all other instances of ``K`` have the same<br>  value as this initialized one, and if soft checking is enabled, it will print<br>  out all of them along with an error message. (DONE)<br><br>- Rewrite README.<br>- Fix source code headers. (DONE)<br>_ Add support for generics:<br>    - List (DONE)<br>    _ Sequence (DONE)<br>    - Dict (DONE)<br>    - Set (DONE)<br>    - Callable (DONE)<br>- Write tests for decorated classes, attributes, equation solver, placeholders,<br>  instance/class/metaclass methods, and the above generic subscriptable types.<br>- Resolve the discrepancy between default dtypes of tensors (float32 in TF),<br>  and default dtype given the primitive float argument (float64). What is the<br>  most natural behavior? Follow PLA. (DONE)<br>- In line with above, consider making checks for primitive types (int, float,<br>  complex, bytes, str) less strict. This should be done if there is time. (NO)<br>- Put on PyPI.<br>- Bug: disabling/enabling asta per-file is likely broken, since importing check<br>  sets the value of an environment variable, which is global during python<br>  execution. (DONE)<br>- Consider adding ``asta.shp`` and ``asta.dims`` so that integer and tuple<br>  dimensions/shapes are in two separate storage modules. This would also mean<br>  you could write ``shp.OBS`` intead of ``OBS_SHAPE`` or ``dims.OBS_SHAPE``,<br>  which are both rather long and take up a good chunk of the hint size.<br>- Decide on whether the storage modules should be plural (shp, dim, symbol) or<br>  (shps, dims, symbols)? Singular is shorter and looks nicer, maybe?<br>- Placeholder should support addition as tuple concatenation. Does this already<br>  work?<br>- Placeholders dims (scalars) should support arbitrary mathematical expressions<br>  involving symbols.<br>- Add configuration parsing. (DONE)<br>- Consider just not implementing per-module typecheck enable/disable. It should<br>  be all or nothing via either the configuration file option or the environment<br>  variable.<br>- Consider implementing per-module disable via a global variable in each<br>  module. The decorators can see the scope of the module from which they are<br>  called, and these scopes are independent, so set ``ASTA_MODULE_DISABLE =<br>  True``and asta will skip checking that module.<br>- Don't support default precisions because it decreases type transparency.<br>  (DONE)<br>- Support subcriptable aliases:<br><br>    &gt;&gt;&gt; CudaTensor = Tensor[{\"device\": \"cuda:0\"}]<br>    &gt;&gt;&gt; FloatCudaTensor = CudaTensor[float]<br><br>  Currently, subscripting ``CudaTensor`` as above will overwrite/delete the<br>  existing subscript. So just add a class attribute that saves the subscript,<br>  and upon subscription, combines the previous subscript with the new<br>  subscript, raising an error if an attribute is already set. Actually, on<br>  second though, instead of saving the subscript, just save the parsed class<br>  attributes. (DONE)<br>- Bug: tuples cannot be summed without unpacking ``Tensor[shapes.OB + (1,)]``.<br>  (DONE)<br>- Bug: Header should still be printed when an error is raised if<br>  ``ox.print_passes`` is off. (DONE)<br>- ---MERGE---(DONE)<br>- Update README (DONE)<br>- Add warning when ``ox.print_passes`` is False, so that the user doesn't<br>  accidentally leave it on, slowing down their program, and make this happen at<br>  import-time, so that if the part where they're calling typechecked functions<br>  doesn't happen for a while, they still know immediately. (DONE)<br>- ---MERGE---<br>- Consider adding an ``args`` module. So if you have a function:<br><br>    &gt;&gt;&gt; def fn(k: int) -&gt; Tensor[&lt;k&gt;]:<br>    &gt;&gt;&gt;     return torch.ones((k,))<br><br>  where the shape is dependent on the arguments, you could annotate it.<br>  Syntax would look like this:<br><br>    &gt;&gt;&gt; def fn(k: int) -&gt; Tensor[args.k]:<br>    &gt;&gt;&gt;     return torch.ones((k,))<br><br>- Consider adding probabilistic checking, i.e. if a function has been called<br>  100,000 times and none of them have failed, maybe stop checking it,<br>  especially if it's taking a long time. We can do inference and estimate the<br>  probability that the function will fail.<br>- Before we do the above, attempt to jit compile everything in asta.<br>- Consider making overwrites of class attributes like:<br><br>    &gt;&gt;&gt; Tensor[float][float]<br><br>  raise an error saying the attribute has already been defined. Perhaps<br>  ``kwattrs`` allows overwriting as long as there are no keys in common or<br>  something. Is an error expected behavior, or should we be lenient?<br>- Consider adding checks before looping over any iterable to make sure the<br>  subscript annotation is an astatype in the case where<br>  ``ox.check_non_asta_types`` is false.<br>- Consider making ``@typechecked`` callable so we can call:<br><br>    &gt;&gt;&gt; @typechecked(print=True)<br>    &gt;&gt;&gt; def ...<br><br>  So then we can have ``print-all-passes=no`` but still print the one we're<br>  debugging.<br><br><br><br>Acknowledgements<br>----------------<br>- Based on the excellent packages 'nptyping' by Ramon Hagenaars and 'typeguard'<br>  by Alex Gr\u00f6nholm.<br>- Thanks to Michael Crawshaw (@mtcrawshaw) for helpful comments on natural<br>  shape constraints and handling of 0-valued dimension sizes.<br><br><br>\n          </div>"}, "last_serial": 7045535, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "28fb1c69a1eeef2d2b754b9b8e7c7092", "sha256": "c5feff8323eddca8e9c5bcd9b93c66f849b41a14c9085f4093356e0149018a7a"}, "downloads": -1, "filename": "asta-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "28fb1c69a1eeef2d2b754b9b8e7c7092", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56093, "upload_time": "2020-03-29T04:14:48", "upload_time_iso_8601": "2020-03-29T04:14:48.828573Z", "url": "https://files.pythonhosted.org/packages/6a/60/ca381500576728d015bc9f37001eac0561951189c9217910378054aae169/asta-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "5bcde43d09777ad7578a862ea6ea458e", "sha256": "0e6a0a533e6d4fd3e8d46aad7b3cbd23cf3b49e9bcef15abcb1906e01682c07f"}, "downloads": -1, "filename": "asta-0.0.1.tar.gz", "has_sig": false, "md5_digest": "5bcde43d09777ad7578a862ea6ea458e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44017, "upload_time": "2020-03-29T04:14:53", "upload_time_iso_8601": "2020-03-29T04:14:53.058428Z", "url": "https://files.pythonhosted.org/packages/b0/e7/63708c84b9992cfb9ceb50da8a74a1cdafc8929c980f46341038625016bc/asta-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "1ec3b5d9b101fca856b3c96946d64e5f", "sha256": "cc8869aa5ef79d53a6b20ab71876800ea8a754745c5a3ce7163137324aaf4e84"}, "downloads": -1, "filename": "asta-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1ec3b5d9b101fca856b3c96946d64e5f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56092, "upload_time": "2020-03-29T04:35:36", "upload_time_iso_8601": "2020-03-29T04:35:36.122485Z", "url": "https://files.pythonhosted.org/packages/81/38/e6eb51f1b085c5d6c6a1e47862cfdbd711a3a8aaf5c9efd14d01011872e6/asta-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b347145d6a8101a8569ebf8a495413f2", "sha256": "b8257f499e438c4b7b849cf81ef235632598d051bc4610332334c41314da1ec5"}, "downloads": -1, "filename": "asta-0.0.2.tar.gz", "has_sig": false, "md5_digest": "b347145d6a8101a8569ebf8a495413f2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 43993, "upload_time": "2020-03-29T04:35:39", "upload_time_iso_8601": "2020-03-29T04:35:39.773558Z", "url": "https://files.pythonhosted.org/packages/0c/72/bd05daf7fa9ca0adcbf5455812aa51c536ebe6f85897d264659108846e82/asta-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "438762c448800889a1d69dda10b369b3", "sha256": "77a2345edf343cfbb3965b1daff6652a054275dd4db03b7566a4d4923bc094b2"}, "downloads": -1, "filename": "asta-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "438762c448800889a1d69dda10b369b3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56197, "upload_time": "2020-03-29T12:20:35", "upload_time_iso_8601": "2020-03-29T12:20:35.802177Z", "url": "https://files.pythonhosted.org/packages/81/ce/c18d660cbc44c920245a776beefe81aa5fa508d93140c671b80e9e9a6bcc/asta-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9b740b02340efa637e5422d57206cf3d", "sha256": "62f6dedb2d88d5c860fb3d5c72627a8498be8e76eef1251339fb3a0ef5377778"}, "downloads": -1, "filename": "asta-0.0.3.tar.gz", "has_sig": false, "md5_digest": "9b740b02340efa637e5422d57206cf3d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44092, "upload_time": "2020-03-29T12:20:39", "upload_time_iso_8601": "2020-03-29T12:20:39.243832Z", "url": "https://files.pythonhosted.org/packages/a3/51/47ac50185d42a5a04acd296a731e1702dca4b6f047e9dba4c15ed5842ad9/asta-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "cdca2e1eb89cf2dd86581fccc6553a6f", "sha256": "fa93e37b8003678bb1fa7e141965f4e725cbcbf0036eea67a1ef07398d66e339"}, "downloads": -1, "filename": "asta-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "cdca2e1eb89cf2dd86581fccc6553a6f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56202, "upload_time": "2020-03-29T12:44:07", "upload_time_iso_8601": "2020-03-29T12:44:07.663902Z", "url": "https://files.pythonhosted.org/packages/fd/1e/96a5bf07542a33bc4bd3aa3e3fa32131af231aee8e542de1bd3b2e663944/asta-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f983e4fbd80903c02586174639df76e5", "sha256": "3039ed1c0b4c9f163f8da82648a57b6e51a488abf6719ba0387dcbe6f264c61f"}, "downloads": -1, "filename": "asta-0.0.4.tar.gz", "has_sig": false, "md5_digest": "f983e4fbd80903c02586174639df76e5", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44118, "upload_time": "2020-03-29T12:44:09", "upload_time_iso_8601": "2020-03-29T12:44:09.245499Z", "url": "https://files.pythonhosted.org/packages/04/ed/1e1db35f92c022b4d25d8d86799bbb001a88a6c7aa2d5d9d85aa23b7e72f/asta-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "ccccad0d8586864c1d8a866ab5e50fe4", "sha256": "8328fb1c6a7a0fc648b8eba8d0507220cc9fa7c198bbdb1d65c066b82ebbb5e1"}, "downloads": -1, "filename": "asta-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "ccccad0d8586864c1d8a866ab5e50fe4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56461, "upload_time": "2020-03-29T12:51:03", "upload_time_iso_8601": "2020-03-29T12:51:03.478790Z", "url": "https://files.pythonhosted.org/packages/02/95/eef8c520a5015b397ff25389bd9e59ea5b0abe0186dd9b7f15cb6cf50227/asta-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c4ac83103109c08a5dd54b90471c5694", "sha256": "5c9834a7292cc42e6391f84b2cf9de82d8a5db57e067e67d287693ad44be2ff0"}, "downloads": -1, "filename": "asta-0.0.5.tar.gz", "has_sig": false, "md5_digest": "c4ac83103109c08a5dd54b90471c5694", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44117, "upload_time": "2020-03-29T12:51:05", "upload_time_iso_8601": "2020-03-29T12:51:05.154788Z", "url": "https://files.pythonhosted.org/packages/62/a6/3ce89d0a291dce31d8c5d742ccc6dbddb6b6da4720c46f319c00e65dadf7/asta-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "02be9164361da50f8e714d963bd3e0fd", "sha256": "9d2d5f00ad67ae44f279f989c3c1e626e4c3a679c6dff5c31c322e0a3fc91644"}, "downloads": -1, "filename": "asta-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "02be9164361da50f8e714d963bd3e0fd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56391, "upload_time": "2020-03-29T13:56:57", "upload_time_iso_8601": "2020-03-29T13:56:57.356526Z", "url": "https://files.pythonhosted.org/packages/82/3c/ea4b95ff154f6b4f280230b11b3b3836cab882928723b6636b33bb7e6c5a/asta-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "28f5fa2539392ecc04fbec9a0d02147c", "sha256": "cf95963290e2083cc347c95501bbe8c995864930c7eadb86bb7d312f125ebb1c"}, "downloads": -1, "filename": "asta-0.0.6.tar.gz", "has_sig": false, "md5_digest": "28f5fa2539392ecc04fbec9a0d02147c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44084, "upload_time": "2020-03-29T13:56:59", "upload_time_iso_8601": "2020-03-29T13:56:59.198635Z", "url": "https://files.pythonhosted.org/packages/3e/50/83bd49185e43f7f4b404a267bf5d85c0ac950123d888131f6a51574f5cad/asta-0.0.6.tar.gz", "yanked": false}], "0.0.6a1": [{"comment_text": "", "digests": {"md5": "f3aa561dd1af88b6a69722326e9c92b8", "sha256": "c10a9c385c10aefad3ac591f95fec79626cdf407199fc0f076939fddd1573823"}, "downloads": -1, "filename": "asta-0.0.6a1-py3-none-any.whl", "has_sig": false, "md5_digest": "f3aa561dd1af88b6a69722326e9c92b8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56415, "upload_time": "2020-03-29T13:44:21", "upload_time_iso_8601": "2020-03-29T13:44:21.393338Z", "url": "https://files.pythonhosted.org/packages/d4/19/057b399b3666a77105b113a296d96a992a0e15b304efa23523d1ffcb119a/asta-0.0.6a1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "64d3eba1828cf6f74876109550460bed", "sha256": "e3baa09acc3e13c1924b68bf9ef57d023cae924f7d53083be4fd979aaf3bd14e"}, "downloads": -1, "filename": "asta-0.0.6a1.tar.gz", "has_sig": false, "md5_digest": "64d3eba1828cf6f74876109550460bed", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44079, "upload_time": "2020-03-29T13:44:24", "upload_time_iso_8601": "2020-03-29T13:44:24.674782Z", "url": "https://files.pythonhosted.org/packages/e1/a7/6e2c2a40034d943144226e85abdcba956ac39b5f639132589f56356527a5/asta-0.0.6a1.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "f21ea5fee6360e9810e29bc8b007f628", "sha256": "5a1be67582d2dc74533e3a6798c20c09b19bf1cb082222019abb336929ea49cc"}, "downloads": -1, "filename": "asta-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "f21ea5fee6360e9810e29bc8b007f628", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56415, "upload_time": "2020-04-18T02:58:53", "upload_time_iso_8601": "2020-04-18T02:58:53.414469Z", "url": "https://files.pythonhosted.org/packages/c2/54/715c61c183166541c5822ae24ac2bd827f8ec00cd32073d96285be8e3974/asta-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fd9c0b3ab74738e7eec53fb76344f8e0", "sha256": "5fa170848053ac6f54cfcd07ef1bb8522d7b49008baa7d7e66dc7fcaea54577c"}, "downloads": -1, "filename": "asta-0.0.7.tar.gz", "has_sig": false, "md5_digest": "fd9c0b3ab74738e7eec53fb76344f8e0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44122, "upload_time": "2020-04-18T02:58:54", "upload_time_iso_8601": "2020-04-18T02:58:54.569494Z", "url": "https://files.pythonhosted.org/packages/38/49/3a86f5450b041955c9cae97e534fce5684b6837e3ed75d48c4da5f1cc585/asta-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "f21ea5fee6360e9810e29bc8b007f628", "sha256": "5a1be67582d2dc74533e3a6798c20c09b19bf1cb082222019abb336929ea49cc"}, "downloads": -1, "filename": "asta-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "f21ea5fee6360e9810e29bc8b007f628", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.0", "size": 56415, "upload_time": "2020-04-18T02:58:53", "upload_time_iso_8601": "2020-04-18T02:58:53.414469Z", "url": "https://files.pythonhosted.org/packages/c2/54/715c61c183166541c5822ae24ac2bd827f8ec00cd32073d96285be8e3974/asta-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fd9c0b3ab74738e7eec53fb76344f8e0", "sha256": "5fa170848053ac6f54cfcd07ef1bb8522d7b49008baa7d7e66dc7fcaea54577c"}, "downloads": -1, "filename": "asta-0.0.7.tar.gz", "has_sig": false, "md5_digest": "fd9c0b3ab74738e7eec53fb76344f8e0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.0", "size": 44122, "upload_time": "2020-04-18T02:58:54", "upload_time_iso_8601": "2020-04-18T02:58:54.569494Z", "url": "https://files.pythonhosted.org/packages/38/49/3a86f5450b041955c9cae97e534fce5684b6837e3ed75d48c4da5f1cc585/asta-0.0.7.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:52 2020"}