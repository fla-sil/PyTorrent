{"info": {"author": "Hunter H", "author_email": "huntrar@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Environment :: Web Environment", "Intended Audience :: Developers", "Intended Audience :: End Users/Desktop", "Intended Audience :: System Administrators", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: Text Processing", "Topic :: Utilities"], "description": "scrape |PyPI Version| |Build Status| |Total Downloads|\n======================================================\n\na command-line web scraping tool\n--------------------------------\n\nscrape is a rule-based web crawler and information extraction tool\ncapable of manipulating and merging new and existing documents. XML Path\nLanguage (XPath) and regular expressions are used to define rules for\nfiltering content and web traversal. Output may be converted into text,\ncsv, pdf, and/or HTML formats.\n\nInstallation\n------------\n\n::\n\n    pip install scrape\n\nor\n\n::\n\n    pip install git+https://github.com/huntrar/scrape.git#egg=scrape\n\nor\n\n::\n\n    git clone https://github.com/huntrar/scrape\n    cd scrape\n    python setup.py install\n\nYou must `install\nwkhtmltopdf <https://github.com/pdfkit/pdfkit/wiki/Installing-WKHTMLTOPDF>`__\nto save files to pdf.\n\nUsage\n-----\n\n::\n\n    usage: scrape.py [-h] [-a [ATTRIBUTES [ATTRIBUTES ...]]] [-all]\n                     [-c [CRAWL [CRAWL ...]]] [-C] [--csv] [-cs [CACHE_SIZE]]\n                     [-f [FILTER [FILTER ...]]] [--html] [-i] [-m]\n                     [-max MAX_CRAWLS] [-n] [-ni] [-no] [-o [OUT [OUT ...]]] [-ow]\n                     [-p] [-pt] [-q] [-s] [-t] [-v] [-x [XPATH]]\n                     [QUERY [QUERY ...]]\n\n    a command-line web scraping tool\n\n    positional arguments:\n      QUERY                 URLs/files to scrape\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -a [ATTRIBUTES [ATTRIBUTES ...]], --attributes [ATTRIBUTES [ATTRIBUTES ...]]\n                            extract text using tag attributes\n      -all, --crawl-all     crawl all pages\n      -c [CRAWL [CRAWL ...]], --crawl [CRAWL [CRAWL ...]]\n                            regexp rules for following new pages\n      -C, --clear-cache     clear requests cache\n      --csv                 write files as csv\n      -cs [CACHE_SIZE], --cache-size [CACHE_SIZE]\n                            size of page cache (default: 1000)\n      -f [FILTER [FILTER ...]], --filter [FILTER [FILTER ...]]\n                            regexp rules for filtering text\n      --html                write files as HTML\n      -i, --images          save page images\n      -m, --multiple        save to multiple files\n      -max MAX_CRAWLS, --max-crawls MAX_CRAWLS\n                            max number of pages to crawl\n      -n, --nonstrict       allow crawler to visit any domain\n      -ni, --no-images      do not save page images\n      -no, --no-overwrite   do not overwrite files if they exist\n      -o [OUT [OUT ...]], --out [OUT [OUT ...]]\n                            specify outfile names\n      -ow, --overwrite      overwrite a file if it exists\n      -p, --pdf             write files as pdf\n      -pt, --print          print text output\n      -q, --quiet           suppress program output\n      -s, --single          save to a single file\n      -t, --text            write files as text\n      -v, --version         display current version\n      -x [XPATH], --xpath [XPATH]\n                            filter HTML using XPath\n\nAuthor\n------\n\n-  Hunter Hammond (huntrar@gmail.com)\n\nNotes\n-----\n\n-  Supports both Python 2.x and Python 3.x.\n-  Input to scrape can be links, files, or a combination of the two,\n   allowing you to create new files constructed from both existing and\n   newly scraped content.\n-  Multiple input files/URLs are saved to multiple output\n   files/directories by default. To consolidate them, use the --single\n   flag.\n-  Images are automatically included when saving as pdf or HTML; this\n   involves making additional HTTP requests, adding a significant amount\n   of processing time. If you wish to forgo this feature use the\n   --no-images flag, or set the environment variable\n   SCRAPE\\_DISABLE\\_IMGS.\n-  Requests cache is enabled by default to cache webpages, it can be\n   disabled by setting the environment variable SCRAPE\\_DISABLE\\_CACHE.\n-  Pages are saved temporarily as PART.html files during processing.\n   Unless saving pages as HTML, these files are removed automatically\n   upon conversion or exit.\n-  To crawl pages with no restrictions use the --crawl-all flag, or\n   filter which pages to crawl by URL keywords by passing one or more\n   regexps to --crawl.\n-  If you want the crawler to follow links outside of the given URLs\n   domain, use --nonstrict.\n-  Crawling can be stopped by Ctrl-C or alternatively by setting the\n   number of pages or links to be crawled using --maxpages and\n   --maxlinks. A page may contain zero or many links to more pages.\n-  The text output of scraped files can be printed to stdout rather than\n   saved by entering --print.\n-  Filtering HTML can be done using --xpath, while filtering text is\n   done by entering one or more regexps to --filter.\n-  If you only want to specify specific tag attributes to extract rather\n   than an entire XPath, use --attributes. The default choice is to\n   extract only text attributes, but you can specify one or many\n   different attributes (such as href, src, title, or any attribute\n   available..).\n\n.. |PyPI Version| image:: https://img.shields.io/pypi/v/scrape.svg\n   :target: https://pypi.python.org/pypi/scrape\n.. |Build Status| image:: https://travis-ci.org/huntrar/scrape.svg?branch=master\n   :target: https://travis-ci.org/huntrar/scrape\n.. |Total Downloads| image:: https://pepy.tech/badge/scrape\n   :target: https://pepy.tech/project/scrape\n\n\nNews\n====\n\n0.10.0\n------\n\n - Test python 3.7 and 3.8 in Travis CI/GitHub Actions\n - Replace cgi.escape with html.escape in Python 3 due to removal of cgi.escape in 3.8\n - Reformat using Black\n\n0.9.15\n------\n\n - travis CI does not support 3.7 yet, removing that version from build\n\n0.9.14\n------\n\n - added versions 3.6 and 3.7 to travis CI build, removed 2.6 and 3.3\n - 2.6 and 3.3 deprecated by lxml\n\n0.9.13\n------\n\n - 3.7 added as supported version in setup\n - Updated LICENSE and requirements.txt\n\n0.9.12\n------\n\n - 3.6 added as supported version in setup\n - Updated LICENSE\n\n0.9.11\n------\n\n - Bugfix: MissingSchema during requests get\n - Bugfix: Check for Python 2 should have been for Python 3\n\n0.9.10\n------\n\n - More refactoring\n\n0.9.9\n------\n\n - Converted markdown README to rst\n\n0.9.8\n------\n\n - Changed Utility classifier to Utilities\n\n0.9.7\n------\n\n - Replaced compat.py with six module\n - Made imports relative rather than from PATH\n - More refactoring\n\n0.9.6\n------\n\n - Bugfix: Remove non-links through filtering by protocol\n - Refactorings\n\n0.9.5\n------\n\n - Bugfix: Properly join internal and base URLs for crawling\n\n0.9.4\n------\n\n - Retired support for 3.2 as tldextract doesn't support it\n\n0.9.3\n------\n\n - Moved crawling functions into a Crawler class\n - General refactorings to docstrings, function names, etc.\n - Consolidated max_pages and max_links arguments as max_crawls\n - Added tldextract module for getting URL domain, suffixes\n\n0.9.2\n------\n\n - Added compat.py file\n - Moved compatible builtin definitions to __init__\n - Added requests cache\n\n0.9.1\n------\n\n - Updated version in requirements and setup keywords\n - Removed --use-mirrors for 3.5 support\n\n0.9.0\n------\n\n- Bugfix: Fixed comparison of duplicate URLs when crawling\n\n0.8.11\n------\n\n - Bugfix: Improper check of domain when being restrictive\n\n0.8.10\n------\n\n - Strip '/' from end of urls when crawling\n\n0.8.9\n------\n\n - Added argument for cache link size & fixed up others\n\n0.8.8\n------\n\n - Updated README and setup\n\n0.8.7\n------\n\n - added CSV as a format\n\n0.8.6\n------\n\n - added environ variable SCRAPE_DISABLE_IMGS to not save images\n\n0.8.5\n------\n\n - warn user that saving images during crawling is slow\n\n0.8.4\n------\n\n - moved print_text() from crawl.py back to scrape.py\n\n0.8.3\n------\n\n - fixed bad formatting in readme usage\n\n0.8.2\n------\n\n - ignore-load-errors removed from wkhtmltopdf executable\n\n0.8.1\n------\n\n - removed extra schema adding\n\n0.8.0\n------\n\n - fixed bug where added url schema not reflected in query\n\n0.7.9\n------\n\n - moved file crawling to new file\n - avoid overwrite prompt in tests\n\n0.7.8\n------\n\n - updated program description\n - removed overwriting test due to issues with it\n\n0.7.7\n------\n\n - no longer defaults to overwriting files, added program flags/a prompt\n - adding renaming mechanism if choosing to not overwrite a file\n - some function reorganizing\n\n0.7.6\n------\n\n - added print text to stdout option\n - removed extra newline appended in re_filter\n - wrapped pdfkit import in try/except as it isnt essential\n\n0.7.5\n------\n\n - removed extra urlparse import\n\n0.7.4\n------\n\n - added option to not save images\n - images are now only saved if saving to HTML or PDF\n - checks if outfilename has extension before adding new one\n - fixed domains being sometimes mismatched to urls\n - fixed extension being unnecessary appended to urls (for the most part)\n\n0.7.3\n------\n\n - development status reverted to beta\n\n0.7.2\n------\n\n - now saves images with PART.html files (but not css yet)\n - added module level docstrings\n\n0.7.1\n------\n\n - added EOFError handling\n\n0.7.0\n------\n\n - fixed crawl not returning filenames to add to infilenames\n - fixed re_filter adding duplicate matches\n - fixed domain unboundlocalerror\n\n0.6.9\n------\n\n - fixed bug where query not found in urls due to trailing /\n\n0.6.8\n------\n\n - updated program usage\n\n0.6.7\n------\n\n - fixed bounds check on out file names\n\n0.6.6\n------\n\n - added out file names as a program argument\n - fixed bug where re-writing multiple files\n - fixed bug where writing only the first file when writing single file\n\n0.6.5\n------\n\n - major improvement to remove_whitespace()\n\n0.6.4\n------\n\n - more docstring improvements\n\n0.6.3\n------\n\n - began process of making docstrings conform to pep257\n - increased size of link cache from 10 to 100\n - remove the newline at start of text files\n - add newlines between lines filtered by regex\n - remove_whitespace now removes newlines that are 3 in a row or more\n\n0.6.2\n------\n\n - stylistic changes\n - files are now read in 1K chunks\n\n0.6.1\n------\n\n - remove consecutive whitespace before writing text files\n - empty text files no longer written\n\n0.6.0\n------\n\n - fixed bug where single out file name wasn't properly constructed\n - out file names are all returned as lowercase now\n\n0.5.9\n------\n\n - fixed bug where text wouldn't write unless xpath specified\n\n0.5.8\n------\n\n - can now parse HTML using XPath and save to all formats\n - remove carriage returns in scraped text files\n\n0.5.7\n------\n\n - added maximum out file name length of 24 characters\n\n0.5.6\n------\n\n - fixed urls not being properly added under file_types\n\n0.5.5\n------\n\n - fixed UnboundLocalError in write_single_file\n\n0.5.4\n------\n\n - fixed redefinition of out_file_name in write_to_text\n\n0.5.3\n------\n\n - fixed IndexError in write_to_text\n\n0.5.2\n------\n\n - small fix for finding single out file name\n\n0.5.1\n------\n\n - remade method to find single out file name\n\n0.5.0\n------\n\n - can now save to single or multiple output files/directories\n - added tests for writing to single or multiple files\n - preserves original lines/newlines when parsing/writing files\n\n0.4.11\n------\n\n - changed generator.next() to next(generator) for python 3 compatibility\n\n0.4.10\n------\n\n - forgot to remove all occurrences of xrange\n\n0.4.9\n------\n\n - changed unicode decode to ascii decode when writing html to disk\n\n0.4.8\n------\n\n - added missing python 3 compatibilities\n\n0.4.7\n------\n\n - fixed urlparse importerror in utils.py for python 3 users\n\n0.4.6\n------\n\n - fixed html => text\n - all conversions fixed, test_scrape.py added to keep it this way\n - added pdfkit to requirements.txt\n\n0.4.5\n------\n\n - added docstrings to all functions\n - fixed IOError when trying to convert local html to html\n - fixed IOError when trying to convert local html to pdf\n - fixed saving scraped files to text, was saving PART filenames instead\n\n0.4.4\n------\n\n - prompts for filetype from user if none entered\n - modularized a couple functions\n\n0.4.3\n------\n\n - fixed out_file naming\n - pep8 and pylint reformatting\n\n0.4.2\n------\n\n - removed read_part_files in place of get_part_files as pdfkit reads filenames\n\n0.4.1\n------\n\n - fixed bug preventing writing scraped urls to pdf\n\n0.4.0\n------\n\n - can now read in text and filter it\n - recognizes local files, no need for user to enter special flag\n - moved html/ files to testing/ and added a text file to it\n - added better distinction between input and output files\n - changed instances of file to f_name in utils\n - pep8 reformatting\n\n0.3.9\n------\n\n - add scheme to urls if none present\n - fixed bug where raw_html was calling get_html rather than get_raw_html\n\n0.3.8\n------\n\n - made distinction between links and pages with multiple links on them\n - use --maxpages to set the maximum number of pages to get links from\n - use --maxlinks to set the maximum number of links to parse\n - improved the argument help messages\n - improved notes/description in README\n\n0.3.7\n------\n\n - fixes to page caching and writing PART files\n - use --local to read in local html files\n - use --max to indicate max number of pages to crawl\n - changed program description and keywords\n\n0.3.6\n------\n\n - cleanup using pylint as reference\n\n0.3.5\n------\n\n- updated long program description in readme\n- added pypi monthly downloads image in readme\n\n0.3.4\n------\n\n - updated description header in readme\n\n0.3.3\n------\n\n - added file conversion to program description\n\n0.3.2\n------\n\n - added travis-ci build status to readme\n\n0.3.1\n------\n\n - updated program description and added extra installation instructions\n - added .travis.yml and requirements.txt\n\n0.3.0\n------\n\n - added read option for user inputted html files, currently writes files individually and not grouped, to do next is add grouping option\n - added html/ directory containing test html files\n - made relative imports explicit using absolute_import\n - added proxies to utils.py\n\n0.2.10\n------\n\n - moved OrderedSet class to orderedset.py rather than utils.py\n\n0.2.9\n------\n\n - updated program description and keywords in setup.py\n\n0.2.8\n------\n\n - restricts crawling to seed domain by default, changed --strict to --nonstrict for crawling outside given website\n\n0.2.5\n------\n\n - added requests to install_requires in setup.py\n\n0.2.4\n------\n\n - added attributes flag which specifies which tag attributes to extract from a given page, such as text, href, etc.\n\n0.2.3\n------\n\n - updated flags and flag help messages\n - verbose now by default and reduced number of messages, use --quiet to silence messages\n - changed name of --files flag to --html for saving output as html\n - added --text flag, default is still text\n\n0.2.2\n------\n\n - fixed character encoding issue, all unicode now\n\n0.2.1\n------\n\n - improvements to exception handling for proper PART file removal\n\n0.2.0\n------\n\n - pages are now saved as they are crawled to PART.html files and processed/removed as necessary, this greatly saves on program memory\n - added a page cache with a limit of 10 for greater duplicate protection\n - added --files option for keeping webpages as PART.html instead of saving as text or pdf, this also organizes them into a subdirectory named after the seed url's domain\n - changed --restrict flag to --strict for restricting the domain to the seed domain while crawling\n - more --verbose messages being printed\n\n0.1.10\n------\n\n - now compares urls scheme-less before updating links to prevent http:// and https:// duplicates and replaced set_scheme with remove_scheme in utils.py\n - renamed write_pages to write_links\n\n0.1.9\n------\n\n - added behavior for --crawl keywords in crawl method\n - added a domain check before outputting crawled message or adding to crawled links\n - domain key in args is now set to base domain for proper --restrict behavior\n - clean_url now rstrips / character for proper link crawling\n - resolve_url now rstrips / character for proper out_file writing\n - updated description of --crawl flag\n\n0.1.8\n------\n\n - removed url fragments\n - replaced set_base with urlparse method urljoin\n - out_file name construction now uses urlparse 'path' member\n - raw_links is now an OrderedSet to try to eliminate as much processing as possible\n - added clear method to OrderedSet in utils.py\n\n0.1.7\n------\n\n - removed validate_domain and replaced it with a lambda instead\n - replaced domain with base_url in set_base as should have been done before\n - crawled message no longer prints if url was a duplicate\n\n0.1.6\n------\n\n - uncommented import __version__\n\n0.1.5\n------\n\n - set_domain was replaced by set_base, proper solution for links that are relative\n - fixed verbose behavior\n - updated description in README\n\n0.1.4\n------\n\n - fixed output file generation, was using domain instead of base_url\n - minor code cleanup\n\n0.1.3\n------\n\n - blank lines are no longer written to text unless as a page separator\n - style tags now ignored alongside script tags when getting text\n\n0.1.2\n------\n\n - added shebang\n\n0.1.1\n------\n\n - uncommented import __version__\n\n0.1.0\n------\n\n - reformatting to conform with PEP 8\n - added regexp support for matching crawl keywords and filter text keywords\n - improved url resolution by correcting domains and schemes\n - added --restrict option to restrict crawler links to only those with seed domain\n - made text the default write option rather than pdf, can now use --pdf to change that\n - removed page number being written to text, separator is now just a single blank line\n - improved construction of output file name\n\n0.0.11\n------\n\n - fixed missing comma in install_requires in setup.py\n - also labeled now as beta as there are still some kinks with crawling\n\n0.0.10\n------\n\n - now ignoring pdfkit load errors only if more than one link to try to prevent an empty pdf being created in case of error\n\n0.0.9\n------\n\n - pdfkit now ignores load errors and writes as many pages as possible\n\n0.0.8\n------\n\n - better implementation of crawler, can now scrape entire websites\n - added OrderedSet class to utils.py\n\n0.0.7\n------\n\n - changed --keywords to --filter and positional arg url to urls\n\n0.0.6\n------\n\n - use --keywords flag for filtering text\n - can pass multiple links now\n - will not write empty files anymore\n\n0.0.5\n------\n\n - added --verbose argument for use with pdfkit\n - improved output file name processing\n\n0.0.4\n------\n\n - accepts 0 or 1 url's, allowing a call with just --version\n\n0.0.3\n------\n\n - Moved utils.py to scrape/\n\n0.0.2\n------\n\n - First entry", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/huntrar/scrape", "keywords": "web crawler scraper scrape crawl download filter save webpages websites images docs document documentation pdf csv html lxml", "license": "MIT", "maintainer": "Hunter H", "maintainer_email": "huntrar@gmail.com", "name": "scrape", "package_url": "https://pypi.org/project/scrape/", "platform": "", "project_url": "https://pypi.org/project/scrape/", "project_urls": {"Homepage": "https://github.com/huntrar/scrape"}, "release_url": "https://pypi.org/project/scrape/0.10.0/", "requires_dist": null, "requires_python": "", "summary": "a command-line web scraping tool", "version": "0.10.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"scrape-pypi-version-build-status-total-downloads\">\n<h2>scrape <a href=\"https://pypi.python.org/pypi/scrape\" rel=\"nofollow\"><img alt=\"PyPI Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9eaa79bbed9b44d74e06b26aae15ebdcd8675765/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7363726170652e737667\"></a> <a href=\"https://travis-ci.org/huntrar/scrape\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9f62973e65b80f0de0f1bef4998030eb29a8eaa9/68747470733a2f2f7472617669732d63692e6f72672f68756e747261722f7363726170652e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://pepy.tech/project/scrape\" rel=\"nofollow\"><img alt=\"Total Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/56753a93506195cd9c380ba9cd05d3abd962333f/68747470733a2f2f706570792e746563682f62616467652f736372617065\"></a></h2>\n<div id=\"a-command-line-web-scraping-tool\">\n<h3>a command-line web scraping tool</h3>\n<p>scrape is a rule-based web crawler and information extraction tool\ncapable of manipulating and merging new and existing documents. XML Path\nLanguage (XPath) and regular expressions are used to define rules for\nfiltering content and web traversal. Output may be converted into text,\ncsv, pdf, and/or HTML formats.</p>\n</div>\n<div id=\"installation\">\n<h3>Installation</h3>\n<pre>pip install scrape\n</pre>\n<p>or</p>\n<pre>pip install git+https://github.com/huntrar/scrape.git#egg=scrape\n</pre>\n<p>or</p>\n<pre>git clone https://github.com/huntrar/scrape\ncd scrape\npython setup.py install\n</pre>\n<p>You must <a href=\"https://github.com/pdfkit/pdfkit/wiki/Installing-WKHTMLTOPDF\" rel=\"nofollow\">install\nwkhtmltopdf</a>\nto save files to pdf.</p>\n</div>\n<div id=\"usage\">\n<h3>Usage</h3>\n<pre>usage: scrape.py [-h] [-a [ATTRIBUTES [ATTRIBUTES ...]]] [-all]\n                 [-c [CRAWL [CRAWL ...]]] [-C] [--csv] [-cs [CACHE_SIZE]]\n                 [-f [FILTER [FILTER ...]]] [--html] [-i] [-m]\n                 [-max MAX_CRAWLS] [-n] [-ni] [-no] [-o [OUT [OUT ...]]] [-ow]\n                 [-p] [-pt] [-q] [-s] [-t] [-v] [-x [XPATH]]\n                 [QUERY [QUERY ...]]\n\na command-line web scraping tool\n\npositional arguments:\n  QUERY                 URLs/files to scrape\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -a [ATTRIBUTES [ATTRIBUTES ...]], --attributes [ATTRIBUTES [ATTRIBUTES ...]]\n                        extract text using tag attributes\n  -all, --crawl-all     crawl all pages\n  -c [CRAWL [CRAWL ...]], --crawl [CRAWL [CRAWL ...]]\n                        regexp rules for following new pages\n  -C, --clear-cache     clear requests cache\n  --csv                 write files as csv\n  -cs [CACHE_SIZE], --cache-size [CACHE_SIZE]\n                        size of page cache (default: 1000)\n  -f [FILTER [FILTER ...]], --filter [FILTER [FILTER ...]]\n                        regexp rules for filtering text\n  --html                write files as HTML\n  -i, --images          save page images\n  -m, --multiple        save to multiple files\n  -max MAX_CRAWLS, --max-crawls MAX_CRAWLS\n                        max number of pages to crawl\n  -n, --nonstrict       allow crawler to visit any domain\n  -ni, --no-images      do not save page images\n  -no, --no-overwrite   do not overwrite files if they exist\n  -o [OUT [OUT ...]], --out [OUT [OUT ...]]\n                        specify outfile names\n  -ow, --overwrite      overwrite a file if it exists\n  -p, --pdf             write files as pdf\n  -pt, --print          print text output\n  -q, --quiet           suppress program output\n  -s, --single          save to a single file\n  -t, --text            write files as text\n  -v, --version         display current version\n  -x [XPATH], --xpath [XPATH]\n                        filter HTML using XPath\n</pre>\n</div>\n<div id=\"author\">\n<h3>Author</h3>\n<ul>\n<li>Hunter Hammond (<a href=\"mailto:huntrar%40gmail.com\">huntrar<span>@</span>gmail<span>.</span>com</a>)</li>\n</ul>\n</div>\n<div id=\"notes\">\n<h3>Notes</h3>\n<ul>\n<li>Supports both Python 2.x and Python 3.x.</li>\n<li>Input to scrape can be links, files, or a combination of the two,\nallowing you to create new files constructed from both existing and\nnewly scraped content.</li>\n<li>Multiple input files/URLs are saved to multiple output\nfiles/directories by default. To consolidate them, use the \u2013single\nflag.</li>\n<li>Images are automatically included when saving as pdf or HTML; this\ninvolves making additional HTTP requests, adding a significant amount\nof processing time. If you wish to forgo this feature use the\n\u2013no-images flag, or set the environment variable\nSCRAPE_DISABLE_IMGS.</li>\n<li>Requests cache is enabled by default to cache webpages, it can be\ndisabled by setting the environment variable SCRAPE_DISABLE_CACHE.</li>\n<li>Pages are saved temporarily as PART.html files during processing.\nUnless saving pages as HTML, these files are removed automatically\nupon conversion or exit.</li>\n<li>To crawl pages with no restrictions use the \u2013crawl-all flag, or\nfilter which pages to crawl by URL keywords by passing one or more\nregexps to \u2013crawl.</li>\n<li>If you want the crawler to follow links outside of the given URLs\ndomain, use \u2013nonstrict.</li>\n<li>Crawling can be stopped by Ctrl-C or alternatively by setting the\nnumber of pages or links to be crawled using \u2013maxpages and\n\u2013maxlinks. A page may contain zero or many links to more pages.</li>\n<li>The text output of scraped files can be printed to stdout rather than\nsaved by entering \u2013print.</li>\n<li>Filtering HTML can be done using \u2013xpath, while filtering text is\ndone by entering one or more regexps to \u2013filter.</li>\n<li>If you only want to specify specific tag attributes to extract rather\nthan an entire XPath, use \u2013attributes. The default choice is to\nextract only text attributes, but you can specify one or many\ndifferent attributes (such as href, src, title, or any attribute\navailable..).</li>\n</ul>\n</div>\n</div>\n<div id=\"news\">\n<h2>News</h2>\n<div id=\"id1\">\n<h3>0.10.0</h3>\n<blockquote>\n<ul>\n<li>Test python 3.7 and 3.8 in Travis CI/GitHub Actions</li>\n<li>Replace cgi.escape with html.escape in Python 3 due to removal of cgi.escape in 3.8</li>\n<li>Reformat using Black</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id2\">\n<h3>0.9.15</h3>\n<blockquote>\n<ul>\n<li>travis CI does not support 3.7 yet, removing that version from build</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id3\">\n<h3>0.9.14</h3>\n<blockquote>\n<ul>\n<li>added versions 3.6 and 3.7 to travis CI build, removed 2.6 and 3.3</li>\n<li>2.6 and 3.3 deprecated by lxml</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id4\">\n<h3>0.9.13</h3>\n<blockquote>\n<ul>\n<li>3.7 added as supported version in setup</li>\n<li>Updated LICENSE and requirements.txt</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id5\">\n<h3>0.9.12</h3>\n<blockquote>\n<ul>\n<li>3.6 added as supported version in setup</li>\n<li>Updated LICENSE</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id6\">\n<h3>0.9.11</h3>\n<blockquote>\n<ul>\n<li>Bugfix: MissingSchema during requests get</li>\n<li>Bugfix: Check for Python 2 should have been for Python 3</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id7\">\n<h3>0.9.10</h3>\n<blockquote>\n<ul>\n<li>More refactoring</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id8\">\n<h3>0.9.9</h3>\n<blockquote>\n<ul>\n<li>Converted markdown README to rst</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id9\">\n<h3>0.9.8</h3>\n<blockquote>\n<ul>\n<li>Changed Utility classifier to Utilities</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id10\">\n<h3>0.9.7</h3>\n<blockquote>\n<ul>\n<li>Replaced compat.py with six module</li>\n<li>Made imports relative rather than from PATH</li>\n<li>More refactoring</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id11\">\n<h3>0.9.6</h3>\n<blockquote>\n<ul>\n<li>Bugfix: Remove non-links through filtering by protocol</li>\n<li>Refactorings</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id12\">\n<h3>0.9.5</h3>\n<blockquote>\n<ul>\n<li>Bugfix: Properly join internal and base URLs for crawling</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id13\">\n<h3>0.9.4</h3>\n<blockquote>\n<ul>\n<li>Retired support for 3.2 as tldextract doesn\u2019t support it</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id14\">\n<h3>0.9.3</h3>\n<blockquote>\n<ul>\n<li>Moved crawling functions into a Crawler class</li>\n<li>General refactorings to docstrings, function names, etc.</li>\n<li>Consolidated max_pages and max_links arguments as max_crawls</li>\n<li>Added tldextract module for getting URL domain, suffixes</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id15\">\n<h3>0.9.2</h3>\n<blockquote>\n<ul>\n<li>Added compat.py file</li>\n<li>Moved compatible builtin definitions to __init__</li>\n<li>Added requests cache</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id16\">\n<h3>0.9.1</h3>\n<blockquote>\n<ul>\n<li>Updated version in requirements and setup keywords</li>\n<li>Removed \u2013use-mirrors for 3.5 support</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id17\">\n<h3>0.9.0</h3>\n<ul>\n<li>Bugfix: Fixed comparison of duplicate URLs when crawling</li>\n</ul>\n</div>\n<div id=\"id18\">\n<h3>0.8.11</h3>\n<blockquote>\n<ul>\n<li>Bugfix: Improper check of domain when being restrictive</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id19\">\n<h3>0.8.10</h3>\n<blockquote>\n<ul>\n<li>Strip \u2018/\u2019 from end of urls when crawling</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id20\">\n<h3>0.8.9</h3>\n<blockquote>\n<ul>\n<li>Added argument for cache link size &amp; fixed up others</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id21\">\n<h3>0.8.8</h3>\n<blockquote>\n<ul>\n<li>Updated README and setup</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id22\">\n<h3>0.8.7</h3>\n<blockquote>\n<ul>\n<li>added CSV as a format</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id23\">\n<h3>0.8.6</h3>\n<blockquote>\n<ul>\n<li>added environ variable SCRAPE_DISABLE_IMGS to not save images</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id24\">\n<h3>0.8.5</h3>\n<blockquote>\n<ul>\n<li>warn user that saving images during crawling is slow</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id25\">\n<h3>0.8.4</h3>\n<blockquote>\n<ul>\n<li>moved print_text() from crawl.py back to scrape.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id26\">\n<h3>0.8.3</h3>\n<blockquote>\n<ul>\n<li>fixed bad formatting in readme usage</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id27\">\n<h3>0.8.2</h3>\n<blockquote>\n<ul>\n<li>ignore-load-errors removed from wkhtmltopdf executable</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id28\">\n<h3>0.8.1</h3>\n<blockquote>\n<ul>\n<li>removed extra schema adding</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id29\">\n<h3>0.8.0</h3>\n<blockquote>\n<ul>\n<li>fixed bug where added url schema not reflected in query</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id30\">\n<h3>0.7.9</h3>\n<blockquote>\n<ul>\n<li>moved file crawling to new file</li>\n<li>avoid overwrite prompt in tests</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id31\">\n<h3>0.7.8</h3>\n<blockquote>\n<ul>\n<li>updated program description</li>\n<li>removed overwriting test due to issues with it</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id32\">\n<h3>0.7.7</h3>\n<blockquote>\n<ul>\n<li>no longer defaults to overwriting files, added program flags/a prompt</li>\n<li>adding renaming mechanism if choosing to not overwrite a file</li>\n<li>some function reorganizing</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id33\">\n<h3>0.7.6</h3>\n<blockquote>\n<ul>\n<li>added print text to stdout option</li>\n<li>removed extra newline appended in re_filter</li>\n<li>wrapped pdfkit import in try/except as it isnt essential</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id34\">\n<h3>0.7.5</h3>\n<blockquote>\n<ul>\n<li>removed extra urlparse import</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id35\">\n<h3>0.7.4</h3>\n<blockquote>\n<ul>\n<li>added option to not save images</li>\n<li>images are now only saved if saving to HTML or PDF</li>\n<li>checks if outfilename has extension before adding new one</li>\n<li>fixed domains being sometimes mismatched to urls</li>\n<li>fixed extension being unnecessary appended to urls (for the most part)</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id36\">\n<h3>0.7.3</h3>\n<blockquote>\n<ul>\n<li>development status reverted to beta</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id37\">\n<h3>0.7.2</h3>\n<blockquote>\n<ul>\n<li>now saves images with PART.html files (but not css yet)</li>\n<li>added module level docstrings</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id38\">\n<h3>0.7.1</h3>\n<blockquote>\n<ul>\n<li>added EOFError handling</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id39\">\n<h3>0.7.0</h3>\n<blockquote>\n<ul>\n<li>fixed crawl not returning filenames to add to infilenames</li>\n<li>fixed re_filter adding duplicate matches</li>\n<li>fixed domain unboundlocalerror</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id40\">\n<h3>0.6.9</h3>\n<blockquote>\n<ul>\n<li>fixed bug where query not found in urls due to trailing /</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id41\">\n<h3>0.6.8</h3>\n<blockquote>\n<ul>\n<li>updated program usage</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id42\">\n<h3>0.6.7</h3>\n<blockquote>\n<ul>\n<li>fixed bounds check on out file names</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id43\">\n<h3>0.6.6</h3>\n<blockquote>\n<ul>\n<li>added out file names as a program argument</li>\n<li>fixed bug where re-writing multiple files</li>\n<li>fixed bug where writing only the first file when writing single file</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id44\">\n<h3>0.6.5</h3>\n<blockquote>\n<ul>\n<li>major improvement to remove_whitespace()</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id45\">\n<h3>0.6.4</h3>\n<blockquote>\n<ul>\n<li>more docstring improvements</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id46\">\n<h3>0.6.3</h3>\n<blockquote>\n<ul>\n<li>began process of making docstrings conform to pep257</li>\n<li>increased size of link cache from 10 to 100</li>\n<li>remove the newline at start of text files</li>\n<li>add newlines between lines filtered by regex</li>\n<li>remove_whitespace now removes newlines that are 3 in a row or more</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id47\">\n<h3>0.6.2</h3>\n<blockquote>\n<ul>\n<li>stylistic changes</li>\n<li>files are now read in 1K chunks</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id48\">\n<h3>0.6.1</h3>\n<blockquote>\n<ul>\n<li>remove consecutive whitespace before writing text files</li>\n<li>empty text files no longer written</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id49\">\n<h3>0.6.0</h3>\n<blockquote>\n<ul>\n<li>fixed bug where single out file name wasn\u2019t properly constructed</li>\n<li>out file names are all returned as lowercase now</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id50\">\n<h3>0.5.9</h3>\n<blockquote>\n<ul>\n<li>fixed bug where text wouldn\u2019t write unless xpath specified</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id51\">\n<h3>0.5.8</h3>\n<blockquote>\n<ul>\n<li>can now parse HTML using XPath and save to all formats</li>\n<li>remove carriage returns in scraped text files</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id52\">\n<h3>0.5.7</h3>\n<blockquote>\n<ul>\n<li>added maximum out file name length of 24 characters</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id53\">\n<h3>0.5.6</h3>\n<blockquote>\n<ul>\n<li>fixed urls not being properly added under file_types</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id54\">\n<h3>0.5.5</h3>\n<blockquote>\n<ul>\n<li>fixed UnboundLocalError in write_single_file</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id55\">\n<h3>0.5.4</h3>\n<blockquote>\n<ul>\n<li>fixed redefinition of out_file_name in write_to_text</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id56\">\n<h3>0.5.3</h3>\n<blockquote>\n<ul>\n<li>fixed IndexError in write_to_text</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id57\">\n<h3>0.5.2</h3>\n<blockquote>\n<ul>\n<li>small fix for finding single out file name</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id58\">\n<h3>0.5.1</h3>\n<blockquote>\n<ul>\n<li>remade method to find single out file name</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id59\">\n<h3>0.5.0</h3>\n<blockquote>\n<ul>\n<li>can now save to single or multiple output files/directories</li>\n<li>added tests for writing to single or multiple files</li>\n<li>preserves original lines/newlines when parsing/writing files</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id60\">\n<h3>0.4.11</h3>\n<blockquote>\n<ul>\n<li>changed generator.next() to next(generator) for python 3 compatibility</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id61\">\n<h3>0.4.10</h3>\n<blockquote>\n<ul>\n<li>forgot to remove all occurrences of xrange</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id62\">\n<h3>0.4.9</h3>\n<blockquote>\n<ul>\n<li>changed unicode decode to ascii decode when writing html to disk</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id63\">\n<h3>0.4.8</h3>\n<blockquote>\n<ul>\n<li>added missing python 3 compatibilities</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id64\">\n<h3>0.4.7</h3>\n<blockquote>\n<ul>\n<li>fixed urlparse importerror in utils.py for python 3 users</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id65\">\n<h3>0.4.6</h3>\n<blockquote>\n<ul>\n<li>fixed html =&gt; text</li>\n<li>all conversions fixed, test_scrape.py added to keep it this way</li>\n<li>added pdfkit to requirements.txt</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id66\">\n<h3>0.4.5</h3>\n<blockquote>\n<ul>\n<li>added docstrings to all functions</li>\n<li>fixed IOError when trying to convert local html to html</li>\n<li>fixed IOError when trying to convert local html to pdf</li>\n<li>fixed saving scraped files to text, was saving PART filenames instead</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id67\">\n<h3>0.4.4</h3>\n<blockquote>\n<ul>\n<li>prompts for filetype from user if none entered</li>\n<li>modularized a couple functions</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id68\">\n<h3>0.4.3</h3>\n<blockquote>\n<ul>\n<li>fixed out_file naming</li>\n<li>pep8 and pylint reformatting</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id69\">\n<h3>0.4.2</h3>\n<blockquote>\n<ul>\n<li>removed read_part_files in place of get_part_files as pdfkit reads filenames</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id70\">\n<h3>0.4.1</h3>\n<blockquote>\n<ul>\n<li>fixed bug preventing writing scraped urls to pdf</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id71\">\n<h3>0.4.0</h3>\n<blockquote>\n<ul>\n<li>can now read in text and filter it</li>\n<li>recognizes local files, no need for user to enter special flag</li>\n<li>moved html/ files to testing/ and added a text file to it</li>\n<li>added better distinction between input and output files</li>\n<li>changed instances of file to f_name in utils</li>\n<li>pep8 reformatting</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id72\">\n<h3>0.3.9</h3>\n<blockquote>\n<ul>\n<li>add scheme to urls if none present</li>\n<li>fixed bug where raw_html was calling get_html rather than get_raw_html</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id73\">\n<h3>0.3.8</h3>\n<blockquote>\n<ul>\n<li>made distinction between links and pages with multiple links on them</li>\n<li>use \u2013maxpages to set the maximum number of pages to get links from</li>\n<li>use \u2013maxlinks to set the maximum number of links to parse</li>\n<li>improved the argument help messages</li>\n<li>improved notes/description in README</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id74\">\n<h3>0.3.7</h3>\n<blockquote>\n<ul>\n<li>fixes to page caching and writing PART files</li>\n<li>use \u2013local to read in local html files</li>\n<li>use \u2013max to indicate max number of pages to crawl</li>\n<li>changed program description and keywords</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id75\">\n<h3>0.3.6</h3>\n<blockquote>\n<ul>\n<li>cleanup using pylint as reference</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id76\">\n<h3>0.3.5</h3>\n<ul>\n<li>updated long program description in readme</li>\n<li>added pypi monthly downloads image in readme</li>\n</ul>\n</div>\n<div id=\"id77\">\n<h3>0.3.4</h3>\n<blockquote>\n<ul>\n<li>updated description header in readme</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id78\">\n<h3>0.3.3</h3>\n<blockquote>\n<ul>\n<li>added file conversion to program description</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id79\">\n<h3>0.3.2</h3>\n<blockquote>\n<ul>\n<li>added travis-ci build status to readme</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id80\">\n<h3>0.3.1</h3>\n<blockquote>\n<ul>\n<li>updated program description and added extra installation instructions</li>\n<li>added .travis.yml and requirements.txt</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id81\">\n<h3>0.3.0</h3>\n<blockquote>\n<ul>\n<li>added read option for user inputted html files, currently writes files individually and not grouped, to do next is add grouping option</li>\n<li>added html/ directory containing test html files</li>\n<li>made relative imports explicit using absolute_import</li>\n<li>added proxies to utils.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id82\">\n<h3>0.2.10</h3>\n<blockquote>\n<ul>\n<li>moved OrderedSet class to orderedset.py rather than utils.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id83\">\n<h3>0.2.9</h3>\n<blockquote>\n<ul>\n<li>updated program description and keywords in setup.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id84\">\n<h3>0.2.8</h3>\n<blockquote>\n<ul>\n<li>restricts crawling to seed domain by default, changed \u2013strict to \u2013nonstrict for crawling outside given website</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id85\">\n<h3>0.2.5</h3>\n<blockquote>\n<ul>\n<li>added requests to install_requires in setup.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id86\">\n<h3>0.2.4</h3>\n<blockquote>\n<ul>\n<li>added attributes flag which specifies which tag attributes to extract from a given page, such as text, href, etc.</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id87\">\n<h3>0.2.3</h3>\n<blockquote>\n<ul>\n<li>updated flags and flag help messages</li>\n<li>verbose now by default and reduced number of messages, use \u2013quiet to silence messages</li>\n<li>changed name of \u2013files flag to \u2013html for saving output as html</li>\n<li>added \u2013text flag, default is still text</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id88\">\n<h3>0.2.2</h3>\n<blockquote>\n<ul>\n<li>fixed character encoding issue, all unicode now</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id89\">\n<h3>0.2.1</h3>\n<blockquote>\n<ul>\n<li>improvements to exception handling for proper PART file removal</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id90\">\n<h3>0.2.0</h3>\n<blockquote>\n<ul>\n<li>pages are now saved as they are crawled to PART.html files and processed/removed as necessary, this greatly saves on program memory</li>\n<li>added a page cache with a limit of 10 for greater duplicate protection</li>\n<li>added \u2013files option for keeping webpages as PART.html instead of saving as text or pdf, this also organizes them into a subdirectory named after the seed url\u2019s domain</li>\n<li>changed \u2013restrict flag to \u2013strict for restricting the domain to the seed domain while crawling</li>\n<li>more \u2013verbose messages being printed</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id91\">\n<h3>0.1.10</h3>\n<blockquote>\n<ul>\n<li>now compares urls scheme-less before updating links to prevent <a href=\"http://\" rel=\"nofollow\">http://</a> and <a href=\"https://\" rel=\"nofollow\">https://</a> duplicates and replaced set_scheme with remove_scheme in utils.py</li>\n<li>renamed write_pages to write_links</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id92\">\n<h3>0.1.9</h3>\n<blockquote>\n<ul>\n<li>added behavior for \u2013crawl keywords in crawl method</li>\n<li>added a domain check before outputting crawled message or adding to crawled links</li>\n<li>domain key in args is now set to base domain for proper \u2013restrict behavior</li>\n<li>clean_url now rstrips / character for proper link crawling</li>\n<li>resolve_url now rstrips / character for proper out_file writing</li>\n<li>updated description of \u2013crawl flag</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id93\">\n<h3>0.1.8</h3>\n<blockquote>\n<ul>\n<li>removed url fragments</li>\n<li>replaced set_base with urlparse method urljoin</li>\n<li>out_file name construction now uses urlparse \u2018path\u2019 member</li>\n<li>raw_links is now an OrderedSet to try to eliminate as much processing as possible</li>\n<li>added clear method to OrderedSet in utils.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id94\">\n<h3>0.1.7</h3>\n<blockquote>\n<ul>\n<li>removed validate_domain and replaced it with a lambda instead</li>\n<li>replaced domain with base_url in set_base as should have been done before</li>\n<li>crawled message no longer prints if url was a duplicate</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id95\">\n<h3>0.1.6</h3>\n<blockquote>\n<ul>\n<li>uncommented import __version__</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id96\">\n<h3>0.1.5</h3>\n<blockquote>\n<ul>\n<li>set_domain was replaced by set_base, proper solution for links that are relative</li>\n<li>fixed verbose behavior</li>\n<li>updated description in README</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id97\">\n<h3>0.1.4</h3>\n<blockquote>\n<ul>\n<li>fixed output file generation, was using domain instead of base_url</li>\n<li>minor code cleanup</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id98\">\n<h3>0.1.3</h3>\n<blockquote>\n<ul>\n<li>blank lines are no longer written to text unless as a page separator</li>\n<li>style tags now ignored alongside script tags when getting text</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id99\">\n<h3>0.1.2</h3>\n<blockquote>\n<ul>\n<li>added shebang</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id100\">\n<h3>0.1.1</h3>\n<blockquote>\n<ul>\n<li>uncommented import __version__</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id101\">\n<h3>0.1.0</h3>\n<blockquote>\n<ul>\n<li>reformatting to conform with PEP 8</li>\n<li>added regexp support for matching crawl keywords and filter text keywords</li>\n<li>improved url resolution by correcting domains and schemes</li>\n<li>added \u2013restrict option to restrict crawler links to only those with seed domain</li>\n<li>made text the default write option rather than pdf, can now use \u2013pdf to change that</li>\n<li>removed page number being written to text, separator is now just a single blank line</li>\n<li>improved construction of output file name</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id102\">\n<h3>0.0.11</h3>\n<blockquote>\n<ul>\n<li>fixed missing comma in install_requires in setup.py</li>\n<li>also labeled now as beta as there are still some kinks with crawling</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id103\">\n<h3>0.0.10</h3>\n<blockquote>\n<ul>\n<li>now ignoring pdfkit load errors only if more than one link to try to prevent an empty pdf being created in case of error</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id104\">\n<h3>0.0.9</h3>\n<blockquote>\n<ul>\n<li>pdfkit now ignores load errors and writes as many pages as possible</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id105\">\n<h3>0.0.8</h3>\n<blockquote>\n<ul>\n<li>better implementation of crawler, can now scrape entire websites</li>\n<li>added OrderedSet class to utils.py</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id106\">\n<h3>0.0.7</h3>\n<blockquote>\n<ul>\n<li>changed \u2013keywords to \u2013filter and positional arg url to urls</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id107\">\n<h3>0.0.6</h3>\n<blockquote>\n<ul>\n<li>use \u2013keywords flag for filtering text</li>\n<li>can pass multiple links now</li>\n<li>will not write empty files anymore</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id108\">\n<h3>0.0.5</h3>\n<blockquote>\n<ul>\n<li>added \u2013verbose argument for use with pdfkit</li>\n<li>improved output file name processing</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id109\">\n<h3>0.0.4</h3>\n<blockquote>\n<ul>\n<li>accepts 0 or 1 url\u2019s, allowing a call with just \u2013version</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id110\">\n<h3>0.0.3</h3>\n<blockquote>\n<ul>\n<li>Moved utils.py to scrape/</li>\n</ul>\n</blockquote>\n</div>\n<div id=\"id111\">\n<h3>0.0.2</h3>\n<blockquote>\n<ul>\n<li>First entry</li>\n</ul>\n</blockquote>\n</div>\n</div>\n\n          </div>"}, "last_serial": 6801771, "releases": {"0.0.10": [{"comment_text": "", "digests": {"md5": "c73adbbfacf66207941af3fdb10260a1", "sha256": "49980378e57d1cf0a9281a933d4cd7203d93cf5a664717a8a2afc8914d133830"}, "downloads": -1, "filename": "scrape-0.0.10-py2-none-any.whl", "has_sig": false, "md5_digest": "c73adbbfacf66207941af3fdb10260a1", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7746, "upload_time": "2015-07-10T05:45:04", "upload_time_iso_8601": "2015-07-10T05:45:04.467651Z", "url": "https://files.pythonhosted.org/packages/6d/17/54cc7e4499d0617f751eba4c2c04514ce57473c0bedde3805f73afeb9139/scrape-0.0.10-py2-none-any.whl", "yanked": false}], "0.0.11": [{"comment_text": "", "digests": {"md5": "36389b0419aa079aca2833cf87e9351a", "sha256": "8cd5e46f1964f6d9ac30e52034f5b03e38c457380706288980f0b17565f71495"}, "downloads": -1, "filename": "scrape-0.0.11-py2-none-any.whl", "has_sig": false, "md5_digest": "36389b0419aa079aca2833cf87e9351a", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7866, "upload_time": "2015-07-10T12:04:04", "upload_time_iso_8601": "2015-07-10T12:04:04.974247Z", "url": "https://files.pythonhosted.org/packages/6b/41/8aee5b8ee0a280a116c0c18185523d5b5f222e44eeb2de708d2f5b7a321d/scrape-0.0.11-py2-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "3789960664e09be842b4d4773923ba73", "sha256": "0a08fe7cf9e4c0503cff91078d7f91c7e086ee743aa554c558592426c363eaa3"}, "downloads": -1, "filename": "scrape-0.0.2-py2-none-any.whl", "has_sig": false, "md5_digest": "3789960664e09be842b4d4773923ba73", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5039, "upload_time": "2015-07-07T08:30:01", "upload_time_iso_8601": "2015-07-07T08:30:01.168349Z", "url": "https://files.pythonhosted.org/packages/ab/a3/3d7e7d718dd3159ac575d40f850aa664572087e02bc8ab79a899096643e5/scrape-0.0.2-py2-none-any.whl", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "cd85f4e5fe4e66f860f5654e5f60b8ae", "sha256": "d916819405951d40393e3e8af3d6295be59bf7bc095535043cd133a1f8250bde"}, "downloads": -1, "filename": "scrape-0.0.3-py2-none-any.whl", "has_sig": false, "md5_digest": "cd85f4e5fe4e66f860f5654e5f60b8ae", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5912, "upload_time": "2015-07-07T08:34:40", "upload_time_iso_8601": "2015-07-07T08:34:40.103679Z", "url": "https://files.pythonhosted.org/packages/04/b2/0a9c2de2bf5e8433e63f833d7627a51a5ef3f7442fb75dbb6dac49cfcd05/scrape-0.0.3-py2-none-any.whl", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "5dd7da4d2bdcb4133a801412f5ec94b0", "sha256": "371a0f4895e168ee44b455f7a680092b519253f46cef441a296f929a8d2b3214"}, "downloads": -1, "filename": "scrape-0.0.4-py2-none-any.whl", "has_sig": false, "md5_digest": "5dd7da4d2bdcb4133a801412f5ec94b0", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5959, "upload_time": "2015-07-07T08:49:23", "upload_time_iso_8601": "2015-07-07T08:49:23.515377Z", "url": "https://files.pythonhosted.org/packages/87/2d/0ed4e554c657ff5acca6e7ab3e71f7c01a9284d9a22700ef9964c455f0b8/scrape-0.0.4-py2-none-any.whl", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "844eb0497ac2c35b9636c5b75886752c", "sha256": "791c9f2f457dcab538e72954f082d931889f390e6086b5457a329cd8f988df3b"}, "downloads": -1, "filename": "scrape-0.0.5-py2-none-any.whl", "has_sig": false, "md5_digest": "844eb0497ac2c35b9636c5b75886752c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 6183, "upload_time": "2015-07-07T09:28:25", "upload_time_iso_8601": "2015-07-07T09:28:25.039627Z", "url": "https://files.pythonhosted.org/packages/10/b3/04cc1165a56bc74180ecb06e06ff6e67343136243c1e6453b9a554e10b4b/scrape-0.0.5-py2-none-any.whl", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "479ae083edeb9dbb8d7a4f739aa5af2d", "sha256": "35e7e060f24c760a76ef76059a47b63502794f91ed98c57b11f7ab2a509eae25"}, "downloads": -1, "filename": "scrape-0.0.6-py2-none-any.whl", "has_sig": false, "md5_digest": "479ae083edeb9dbb8d7a4f739aa5af2d", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 6507, "upload_time": "2015-07-07T23:00:40", "upload_time_iso_8601": "2015-07-07T23:00:40.601867Z", "url": "https://files.pythonhosted.org/packages/c4/0e/0fb7824c17f4547d99c2db6f43188719e162275a82b525152a34ba71bc6d/scrape-0.0.6-py2-none-any.whl", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "4ab9ad71b12594dd097ce16932d20b74", "sha256": "6d7fc19ea6a7b773c21033001769df2516da005afaedf114f79c24ffc01b84cb"}, "downloads": -1, "filename": "scrape-0.0.7-py2-none-any.whl", "has_sig": false, "md5_digest": "4ab9ad71b12594dd097ce16932d20b74", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 6722, "upload_time": "2015-07-07T23:32:10", "upload_time_iso_8601": "2015-07-07T23:32:10.276913Z", "url": "https://files.pythonhosted.org/packages/26/1a/7f18dd843cec7153b4f56ef4ae46a408cf34b9afb9256c2fcbede691a3fc/scrape-0.0.7-py2-none-any.whl", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "11da231ef029ebd22393a7e6a8291b77", "sha256": "fc8e2250705bad692ac58187679768d49f5de38176441b1e0d9a62560deb96a4"}, "downloads": -1, "filename": "scrape-0.0.8-py2-none-any.whl", "has_sig": false, "md5_digest": "11da231ef029ebd22393a7e6a8291b77", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7423, "upload_time": "2015-07-08T11:18:24", "upload_time_iso_8601": "2015-07-08T11:18:24.325707Z", "url": "https://files.pythonhosted.org/packages/0b/2a/ebcfa83050939168108bac26df30bf8e8690245eaee89887c9f67737996d/scrape-0.0.8-py2-none-any.whl", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "6177f5674093e6d4983cf0eb8789c254", "sha256": "4fb620bef2e1db923369ce968d634cb1a59021dda8651aabbf293431b5698aa1"}, "downloads": -1, "filename": "scrape-0.0.9-py2-none-any.whl", "has_sig": false, "md5_digest": "6177f5674093e6d4983cf0eb8789c254", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 7517, "upload_time": "2015-07-09T03:31:01", "upload_time_iso_8601": "2015-07-09T03:31:01.180486Z", "url": "https://files.pythonhosted.org/packages/d3/de/80cc2476fd20fc87cda86ed9e1457ed3af4634b95a37e60910c0c9ffabf2/scrape-0.0.9-py2-none-any.whl", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "cfdcd1ce3b3411c891d92acdf4ef76ea", "sha256": "62ff31dff19f68f5626c212dea549946899e3c0747f777eb35d8610a20979b06"}, "downloads": -1, "filename": "scrape-0.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "cfdcd1ce3b3411c891d92acdf4ef76ea", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 8770, "upload_time": "2015-07-11T08:18:38", "upload_time_iso_8601": "2015-07-11T08:18:38.681420Z", "url": "https://files.pythonhosted.org/packages/eb/7d/6c8d991623fad2e5cab8611da5c4e9896b9f437489db434044d1ce356118/scrape-0.1.0-py2-none-any.whl", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "e8c22b9eb6878fed1217e9f5bf66ec6a", "sha256": "b9b5325b995724bb01bc7b07101413e8323c2845aa234f21e97919016e3e1b12"}, "downloads": -1, "filename": "scrape-0.1.1-py2-none-any.whl", "has_sig": false, "md5_digest": "e8c22b9eb6878fed1217e9f5bf66ec6a", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 8806, "upload_time": "2015-07-11T08:19:53", "upload_time_iso_8601": "2015-07-11T08:19:53.704976Z", "url": "https://files.pythonhosted.org/packages/c5/62/31b047e6688eb0ea1d1391a33beb664431b3efbe3805627fa21ecb94c6cb/scrape-0.1.1-py2-none-any.whl", "yanked": false}], "0.1.10": [{"comment_text": "", "digests": {"md5": "f8068e5537e5f49f4155f636e7932699", "sha256": "9f36646eefa84c24895b6b18ed507d9e2024a3151dbe11541ccc4f6fc3beeb5f"}, "downloads": -1, "filename": "scrape-0.1.10-py2-none-any.whl", "has_sig": false, "md5_digest": "f8068e5537e5f49f4155f636e7932699", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 10851, "upload_time": "2015-07-13T05:34:24", "upload_time_iso_8601": "2015-07-13T05:34:24.156538Z", "url": "https://files.pythonhosted.org/packages/ad/00/b50b106d918481b84715a94c9831e7ba56d0c50752f9c07646b0225e8e99/scrape-0.1.10-py2-none-any.whl", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "884583ed8daf75436ce63451e79dae77", "sha256": "312017d88acdb6e9e4bc638372f82ea1a6f8a58b7910134e4cb8cf8f4fd4b8ae"}, "downloads": -1, "filename": "scrape-0.1.2-py2-none-any.whl", "has_sig": false, "md5_digest": "884583ed8daf75436ce63451e79dae77", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 8839, "upload_time": "2015-07-11T08:34:12", "upload_time_iso_8601": "2015-07-11T08:34:12.900133Z", "url": "https://files.pythonhosted.org/packages/aa/4b/89cbc63394ac72b2d386d60337ea34f5eea5b05fb0485ea88e2df3571354/scrape-0.1.2-py2-none-any.whl", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "93e608df4961345061a8e3a56e68c425", "sha256": "c2ccd38e01b3fc504406ca766c8980f47969a2cf075c452d570effe63c15e6f7"}, "downloads": -1, "filename": "scrape-0.1.3-py2-none-any.whl", "has_sig": false, "md5_digest": "93e608df4961345061a8e3a56e68c425", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 8973, "upload_time": "2015-07-11T09:03:23", "upload_time_iso_8601": "2015-07-11T09:03:23.500227Z", "url": "https://files.pythonhosted.org/packages/b9/86/737f84a1c34368633fe9bd40b08013efa450acf536e62710102f5fa0935c/scrape-0.1.3-py2-none-any.whl", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "383ec20ea63bfe46a3f6974e1ac20bc8", "sha256": "5f4cdf684f010726085cd82757c1c652fe20a9fa1a51af20bd5bf297603b0fba"}, "downloads": -1, "filename": "scrape-0.1.4-py2-none-any.whl", "has_sig": false, "md5_digest": "383ec20ea63bfe46a3f6974e1ac20bc8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 9073, "upload_time": "2015-07-11T09:59:40", "upload_time_iso_8601": "2015-07-11T09:59:40.402736Z", "url": "https://files.pythonhosted.org/packages/fe/97/d4a83061303540da4f3c387d00c840ad826f4364ed80b0cf8a58f77a53a9/scrape-0.1.4-py2-none-any.whl", "yanked": false}], "0.1.5": [{"comment_text": "", "digests": {"md5": "5302b9858bab692b20d4e6ae1ad9d231", "sha256": "043bd2d6c7231c51e1ff43681c41ea36ddb1fcf87cb9e98dbe0dbb21636850aa"}, "downloads": -1, "filename": "scrape-0.1.5-py2-none-any.whl", "has_sig": false, "md5_digest": "5302b9858bab692b20d4e6ae1ad9d231", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 9488, "upload_time": "2015-07-11T10:37:05", "upload_time_iso_8601": "2015-07-11T10:37:05.301923Z", "url": "https://files.pythonhosted.org/packages/f5/92/8e9cd6f05ac6e0dbfe0fe3d3d6cb1257267096549dbb046561a178d58f9f/scrape-0.1.5-py2-none-any.whl", "yanked": false}], "0.1.6": [{"comment_text": "", "digests": {"md5": "3278d4047c422f759ec1ba82a37b819b", "sha256": "d49ca290edd0767816d34412e3055a5ef957a865c44d22b429b6d83cec2a1927"}, "downloads": -1, "filename": "scrape-0.1.6-py2-none-any.whl", "has_sig": false, "md5_digest": "3278d4047c422f759ec1ba82a37b819b", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 9489, "upload_time": "2015-07-11T10:40:35", "upload_time_iso_8601": "2015-07-11T10:40:35.951833Z", "url": "https://files.pythonhosted.org/packages/ac/71/354f490c048c1a18c37ff32dff1193ced87ffdc54b9a166cc83b585151c4/scrape-0.1.6-py2-none-any.whl", "yanked": false}], "0.1.7": [{"comment_text": "", "digests": {"md5": "c661f1590a9c1592692fa1cbbc5817cf", "sha256": "f1950e76917da96311e02bef3068eba591a829fd53cbe7d33c79d7902fccced9"}, "downloads": -1, "filename": "scrape-0.1.7-py2-none-any.whl", "has_sig": false, "md5_digest": "c661f1590a9c1592692fa1cbbc5817cf", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 9652, "upload_time": "2015-07-11T11:39:59", "upload_time_iso_8601": "2015-07-11T11:39:59.235838Z", "url": "https://files.pythonhosted.org/packages/d4/7e/a883a7e105048b569c9f3e6babf96614419c09a345305de77a9651be8255/scrape-0.1.7-py2-none-any.whl", "yanked": false}], "0.1.8": [{"comment_text": "", "digests": {"md5": "9e6b6b4da023b7761f0265a7ac129cf9", "sha256": "dde55e67648f3a9c938b70c6761d3f4182f52f12078c1ef306aed5fb1430aeaa"}, "downloads": -1, "filename": "scrape-0.1.8-py2-none-any.whl", "has_sig": false, "md5_digest": "9e6b6b4da023b7761f0265a7ac129cf9", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 10134, "upload_time": "2015-07-13T00:39:21", "upload_time_iso_8601": "2015-07-13T00:39:21.161141Z", "url": "https://files.pythonhosted.org/packages/a5/0d/120f757d9e0c5bb7c7b2d05242a496f48eed73df5de9a10691130bbfe2bf/scrape-0.1.8-py2-none-any.whl", "yanked": false}], "0.1.9": [{"comment_text": "", "digests": {"md5": "33d847c1bf83cc7d721108064ca068b6", "sha256": "4bb967534664a62b74ba777657b38f354e5c66938c5c44de151123fa1a2471ca"}, "downloads": -1, "filename": "scrape-0.1.9-py2-none-any.whl", "has_sig": false, "md5_digest": "33d847c1bf83cc7d721108064ca068b6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 10528, "upload_time": "2015-07-13T03:08:40", "upload_time_iso_8601": "2015-07-13T03:08:40.447117Z", "url": "https://files.pythonhosted.org/packages/8e/2e/72776ed2a4ba42245c01423d88209413f9d87a50a4c158b31a369ee514d3/scrape-0.1.9-py2-none-any.whl", "yanked": false}], "0.10.0": [{"comment_text": "", "digests": {"md5": "fc118eff268ebd78fdd890168474cfc2", "sha256": "66acaaa9f4db205770fe0a71f6471a1cf66efc829e3de6b0a7486492a8a8f892"}, "downloads": -1, "filename": "scrape-0.10.0.tar.gz", "has_sig": false, "md5_digest": "fc118eff268ebd78fdd890168474cfc2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27642, "upload_time": "2020-03-12T21:06:57", "upload_time_iso_8601": "2020-03-12T21:06:57.096724Z", "url": "https://files.pythonhosted.org/packages/71/c8/baa111f5d67173e6244a28ebd7d3bced87c249d3073d08c0323ba95c54dc/scrape-0.10.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "434424f0478c366900c5b00deb4375b6", "sha256": "41585e2d22e98230a00e7225f8178d2e45539e3828982f3d78d74b6e2a7a02fc"}, "downloads": -1, "filename": "scrape-0.2.0-py2-none-any.whl", "has_sig": false, "md5_digest": "434424f0478c366900c5b00deb4375b6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 12370, "upload_time": "2015-07-15T10:23:52", "upload_time_iso_8601": "2015-07-15T10:23:52.571720Z", "url": "https://files.pythonhosted.org/packages/b6/7e/3a2ffe2e4a7430e2a46c027cb0fdb91d1a42385f6bfc854e72aa2b9809bb/scrape-0.2.0-py2-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "ad210c1e02b870d79452161d1d7749a8", "sha256": "6899353b1ddea914391b07c4264e01e6ba43f8cb28639f20600cf21560336dc2"}, "downloads": -1, "filename": "scrape-0.2.1-py2-none-any.whl", "has_sig": false, "md5_digest": "ad210c1e02b870d79452161d1d7749a8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 12486, "upload_time": "2015-07-16T01:44:32", "upload_time_iso_8601": "2015-07-16T01:44:32.241838Z", "url": "https://files.pythonhosted.org/packages/a0/4a/990f775dc3a73e586ebafe88eedd924071b9433f8219965aa9cd04db7fc1/scrape-0.2.1-py2-none-any.whl", "yanked": false}], "0.2.10": [{"comment_text": "", "digests": {"md5": "b7247930174bb9779def0fcd6c4b983c", "sha256": "4f5cf116cdf87cc3068ba0ce78124ca27101cface8c26a775ee71224da27baf4"}, "downloads": -1, "filename": "scrape-0.2.10-py2-none-any.whl", "has_sig": false, "md5_digest": "b7247930174bb9779def0fcd6c4b983c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13895, "upload_time": "2015-09-13T22:09:29", "upload_time_iso_8601": "2015-09-13T22:09:29.868780Z", "url": "https://files.pythonhosted.org/packages/65/d1/f44085546dd29db8e3d03dde3f9c21820fa7ec4ff9960af2727198601962/scrape-0.2.10-py2-none-any.whl", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "e79a6b7844007aa13a9eb6e361704a1e", "sha256": "3296b1b80b829133fc3731c42742bcb765974693ce4288764a46b39e380d1e3f"}, "downloads": -1, "filename": "scrape-0.2.2-py2-none-any.whl", "has_sig": false, "md5_digest": "e79a6b7844007aa13a9eb6e361704a1e", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 12522, "upload_time": "2015-07-19T00:38:05", "upload_time_iso_8601": "2015-07-19T00:38:05.949963Z", "url": "https://files.pythonhosted.org/packages/39/cc/e76caa02ddef56ba2d9df2b6f625948ab637b336e85ffca6e6ce4c18eb97/scrape-0.2.2-py2-none-any.whl", "yanked": false}], "0.2.3": [{"comment_text": "", "digests": {"md5": "be57a1bb3b4bfe62805872223fed228e", "sha256": "b00eb01c887aadd0ae06c59986a1096c1137a22e5bfa0d5b0c2586fa281a565a"}, "downloads": -1, "filename": "scrape-0.2.3-py2-none-any.whl", "has_sig": false, "md5_digest": "be57a1bb3b4bfe62805872223fed228e", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 12729, "upload_time": "2015-07-19T01:41:43", "upload_time_iso_8601": "2015-07-19T01:41:43.753745Z", "url": "https://files.pythonhosted.org/packages/c7/1c/93c18b475cf5d2266bd70d427fb576dc4d436351e927b6fe90f625f9c98d/scrape-0.2.3-py2-none-any.whl", "yanked": false}], "0.2.4": [{"comment_text": "", "digests": {"md5": "63fd180ecfb4eb5620a7480fd6bb7169", "sha256": "e5240677120835aef51fb9e3c38c8e8cd32d706e892ff5698d4b18ff036e3fa7"}, "downloads": -1, "filename": "scrape-0.2.4-py2-none-any.whl", "has_sig": false, "md5_digest": "63fd180ecfb4eb5620a7480fd6bb7169", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13313, "upload_time": "2015-07-20T08:48:27", "upload_time_iso_8601": "2015-07-20T08:48:27.839573Z", "url": "https://files.pythonhosted.org/packages/2e/29/3c4e1cf5fe74c13ecc928917cb0b2399aaef7ce6f2559a8bfea5a10d4a2d/scrape-0.2.4-py2-none-any.whl", "yanked": false}], "0.2.5": [{"comment_text": "", "digests": {"md5": "47018c800621b4573b524c5422e4f3a7", "sha256": "5ba5048bb3ebbe0824ed7100c7bd62cc296e937347cabe808d092b5ed004c9f8"}, "downloads": -1, "filename": "scrape-0.2.5-py2-none-any.whl", "has_sig": false, "md5_digest": "47018c800621b4573b524c5422e4f3a7", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13353, "upload_time": "2015-07-25T04:02:09", "upload_time_iso_8601": "2015-07-25T04:02:09.369766Z", "url": "https://files.pythonhosted.org/packages/58/aa/b49d9cb91436cf6f3d7d5f58fef72c1ba5c5e73b54558ed6e61477b78421/scrape-0.2.5-py2-none-any.whl", "yanked": false}], "0.2.6": [{"comment_text": "", "digests": {"md5": "ccc40dac3a9bce50f508dfd932d9f321", "sha256": "79afcbcd650b7b195abbbb2d37a67b470ec71130becd0a45b8c670a3c834f3bc"}, "downloads": -1, "filename": "scrape-0.2.6-py2-none-any.whl", "has_sig": false, "md5_digest": "ccc40dac3a9bce50f508dfd932d9f321", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13365, "upload_time": "2015-07-25T07:03:12", "upload_time_iso_8601": "2015-07-25T07:03:12.807908Z", "url": "https://files.pythonhosted.org/packages/6e/2c/844ab9a1f9cb98942051599fae157987dfaaac83666f5579c826bcd8f684/scrape-0.2.6-py2-none-any.whl", "yanked": false}], "0.2.7": [{"comment_text": "", "digests": {"md5": "f797a3397d02bbb7800a5e0ea70f30f7", "sha256": "e82dc2da3d70c9db154c7589b8858b598ab8f5071f38d05f352d989669dab148"}, "downloads": -1, "filename": "scrape-0.2.7-py2-none-any.whl", "has_sig": false, "md5_digest": "f797a3397d02bbb7800a5e0ea70f30f7", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13497, "upload_time": "2015-08-05T21:33:20", "upload_time_iso_8601": "2015-08-05T21:33:20.163504Z", "url": "https://files.pythonhosted.org/packages/04/58/29488945ce4f94e4edcde2c5dc3f1f7a5f992d876dfd6957c058970faf3f/scrape-0.2.7-py2-none-any.whl", "yanked": false}], "0.2.8": [{"comment_text": "", "digests": {"md5": "61b22a932b0c12d300f6827178e0a9cb", "sha256": "88083574c806debae137609c392679fa5c5e07ea7b659656801c9f73f071409c"}, "downloads": -1, "filename": "scrape-0.2.8-py2-none-any.whl", "has_sig": false, "md5_digest": "61b22a932b0c12d300f6827178e0a9cb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13559, "upload_time": "2015-08-13T08:45:16", "upload_time_iso_8601": "2015-08-13T08:45:16.980842Z", "url": "https://files.pythonhosted.org/packages/ae/5d/60d6663ae0aa52694ae9effd1720c79f19998af3d0a90eeed7c843bef19e/scrape-0.2.8-py2-none-any.whl", "yanked": false}], "0.2.9": [{"comment_text": "", "digests": {"md5": "45753bbc2b02fe8c2c44cc2c7e52c6f9", "sha256": "1cebd4c23e3adc3610c2d01e6b792fb125921a50e7fb6041eded7d8efea1af30"}, "downloads": -1, "filename": "scrape-0.2.9-py2-none-any.whl", "has_sig": false, "md5_digest": "45753bbc2b02fe8c2c44cc2c7e52c6f9", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 13612, "upload_time": "2015-09-11T10:35:01", "upload_time_iso_8601": "2015-09-11T10:35:01.548945Z", "url": "https://files.pythonhosted.org/packages/26/04/639a07c5d2b5cb1fc2d1da3bbaeab582de410aa2058d8b4214bd0b0b5887/scrape-0.2.9-py2-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "665a8c731f529c107afe1593e660b750", "sha256": "abd432b87b71a1692f17298d84466ee93fc7293e4d378f612c52b1e2357db589"}, "downloads": -1, "filename": "scrape-0.3.0-py2-none-any.whl", "has_sig": false, "md5_digest": "665a8c731f529c107afe1593e660b750", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14774, "upload_time": "2015-09-15T09:23:33", "upload_time_iso_8601": "2015-09-15T09:23:33.205158Z", "url": "https://files.pythonhosted.org/packages/c4/1f/57301d7eb67df0227c53f9fa4ddd68b1e065b4f67ca4d37274f9536cc17a/scrape-0.3.0-py2-none-any.whl", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "3b23d6efbac84febcc3c08cbd815753c", "sha256": "bc28f111b9b3062319737f62495a6580631f45232df6f81b0692436e9f0e12e9"}, "downloads": -1, "filename": "scrape-0.3.1-py2-none-any.whl", "has_sig": false, "md5_digest": "3b23d6efbac84febcc3c08cbd815753c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15132, "upload_time": "2015-09-15T11:05:03", "upload_time_iso_8601": "2015-09-15T11:05:03.987074Z", "url": "https://files.pythonhosted.org/packages/ea/a1/f447d0737576912a344b99c291c7cbfc4d51b12ed67c5e36d90c73ac4c13/scrape-0.3.1-py2-none-any.whl", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "fb11ba197709e7c7a280fafbce794362", "sha256": "583cb8ad70b03b42a151cdf4d7bfdfcea086c29110e97b3ffb00125990a2b796"}, "downloads": -1, "filename": "scrape-0.3.2-py2-none-any.whl", "has_sig": false, "md5_digest": "fb11ba197709e7c7a280fafbce794362", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15260, "upload_time": "2015-09-15T11:24:29", "upload_time_iso_8601": "2015-09-15T11:24:29.591524Z", "url": "https://files.pythonhosted.org/packages/f7/7b/50257782b18233ef30e5d623ea9eec3c382fdf52d0ae04a6f918330c5bc5/scrape-0.3.2-py2-none-any.whl", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "3ce56ea7bd94ff60d083ef03b7dbc6ef", "sha256": "8d4841c3c5011236567a4febfcedf71ef6be832eb2583477da3d912caedc09bd"}, "downloads": -1, "filename": "scrape-0.3.3-py2-none-any.whl", "has_sig": false, "md5_digest": "3ce56ea7bd94ff60d083ef03b7dbc6ef", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15321, "upload_time": "2015-09-15T11:33:14", "upload_time_iso_8601": "2015-09-15T11:33:14.463608Z", "url": "https://files.pythonhosted.org/packages/b0/06/a663194930e7c75ba21b9b80763209cabc1639599ad038fc5dbf89f4a80e/scrape-0.3.3-py2-none-any.whl", "yanked": false}], "0.3.4": [{"comment_text": "", "digests": {"md5": "1862b279d2d53255a9f3652745c0765d", "sha256": "314f1b46eafe0acc73ee04efa5e2dc01a10cca6dbd70ef1d88a81a339efc60a0"}, "downloads": -1, "filename": "scrape-0.3.4-py2-none-any.whl", "has_sig": false, "md5_digest": "1862b279d2d53255a9f3652745c0765d", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15341, "upload_time": "2015-09-15T20:17:25", "upload_time_iso_8601": "2015-09-15T20:17:25.745797Z", "url": "https://files.pythonhosted.org/packages/07/c5/dbfd460dc052bc2a58cdf93feb733e810affba8ef7dbfb10eaa807adae56/scrape-0.3.4-py2-none-any.whl", "yanked": false}], "0.3.5": [{"comment_text": "", "digests": {"md5": "f44c67281520a8085bf0fd649c1052aa", "sha256": "a5a7ee627f410c24b3afee2403c6f2759563017bcf704a34c72182a904971897"}, "downloads": -1, "filename": "scrape-0.3.5-py2-none-any.whl", "has_sig": false, "md5_digest": "f44c67281520a8085bf0fd649c1052aa", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15394, "upload_time": "2015-09-16T09:49:13", "upload_time_iso_8601": "2015-09-16T09:49:13.280343Z", "url": "https://files.pythonhosted.org/packages/14/c6/f0b4aee4210ab3d661dbe2fdb7de0fc8875c610e85962a006b9f3d801b40/scrape-0.3.5-py2-none-any.whl", "yanked": false}], "0.3.6": [{"comment_text": "", "digests": {"md5": "0f1aa6da07643a8a3078aa4b2dce15eb", "sha256": "e697f5549b182219616eb2fe073bb93dc9b1f6ff2c0a3f5b99c66d29a8080066"}, "downloads": -1, "filename": "scrape-0.3.6-py2-none-any.whl", "has_sig": false, "md5_digest": "0f1aa6da07643a8a3078aa4b2dce15eb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15558, "upload_time": "2015-09-17T02:48:54", "upload_time_iso_8601": "2015-09-17T02:48:54.273674Z", "url": "https://files.pythonhosted.org/packages/0f/8b/2f705c115066fedb2da05c491f6af7a30400fe7a13809f9b37ca7e5b8f38/scrape-0.3.6-py2-none-any.whl", "yanked": false}], "0.3.7": [{"comment_text": "", "digests": {"md5": "a6b5cd7e0a736c009e7b1112b5231224", "sha256": "ce0a230f9ca8a93b4d755cd4dfff1700a787e3569c4cd2fb629aff7c69c3fef5"}, "downloads": -1, "filename": "scrape-0.3.7-py2-none-any.whl", "has_sig": false, "md5_digest": "a6b5cd7e0a736c009e7b1112b5231224", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15539, "upload_time": "2015-10-12T07:39:51", "upload_time_iso_8601": "2015-10-12T07:39:51.690078Z", "url": "https://files.pythonhosted.org/packages/a8/5f/6ff6f19cf9c5364dd86be36a2f1a7f204f8b8ddb357adfb4498ee6358f74/scrape-0.3.7-py2-none-any.whl", "yanked": false}], "0.3.8": [{"comment_text": "", "digests": {"md5": "f5a3abcb460376a9da6699ab6f3d54e5", "sha256": "e479021b4100da55d36846420d1fba5973f01417c49c791f4dcf1b4dafbeef28"}, "downloads": -1, "filename": "scrape-0.3.8-py2-none-any.whl", "has_sig": false, "md5_digest": "f5a3abcb460376a9da6699ab6f3d54e5", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 15943, "upload_time": "2015-10-15T04:48:00", "upload_time_iso_8601": "2015-10-15T04:48:00.314436Z", "url": "https://files.pythonhosted.org/packages/4e/10/a11e24648536ba74e41d00a3d117dbed685b6bff873c5c608022d1fc1a6f/scrape-0.3.8-py2-none-any.whl", "yanked": false}], "0.3.9": [{"comment_text": "", "digests": {"md5": "b42a5b211b36589cc8a3c0bdbd7216a8", "sha256": "edce7c68d91732a5fbcfc020ff65790fb339a78dd1d72d043356119b493389fb"}, "downloads": -1, "filename": "scrape-0.3.9-py2-none-any.whl", "has_sig": false, "md5_digest": "b42a5b211b36589cc8a3c0bdbd7216a8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16141, "upload_time": "2015-10-15T05:33:42", "upload_time_iso_8601": "2015-10-15T05:33:42.542880Z", "url": "https://files.pythonhosted.org/packages/f0/ec/ebdeb5ecbf6a4468ce68de0ecadf5e8750e68be3014cd41f77144fe475ec/scrape-0.3.9-py2-none-any.whl", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "8c50ffe3d5f0bdad519d2fdb24a5bf9e", "sha256": "4e26c32f105ce389cadb46a58528a190c980bf2e0976d6476b291a7aae067c56"}, "downloads": -1, "filename": "scrape-0.4.0-py2-none-any.whl", "has_sig": false, "md5_digest": "8c50ffe3d5f0bdad519d2fdb24a5bf9e", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16425, "upload_time": "2015-10-19T05:17:36", "upload_time_iso_8601": "2015-10-19T05:17:36.009815Z", "url": "https://files.pythonhosted.org/packages/51/30/2616d8d4c28a8381459e1428fe55e1ddcd88243bc27cd319096478c386cc/scrape-0.4.0-py2-none-any.whl", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "745ecf8f99ead688d79c5135de463265", "sha256": "253bc6798fc00ec6acfbc3d2c594ddb6347484bda56c320b91be930368f0257c"}, "downloads": -1, "filename": "scrape-0.4.1-py2-none-any.whl", "has_sig": false, "md5_digest": "745ecf8f99ead688d79c5135de463265", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16424, "upload_time": "2015-10-20T02:37:28", "upload_time_iso_8601": "2015-10-20T02:37:28.330147Z", "url": "https://files.pythonhosted.org/packages/bd/45/5dacc1d92bdb5b0a7560bc7ade4dc2b81b2ad11b27d7ee43f2f659f5a2fc/scrape-0.4.1-py2-none-any.whl", "yanked": false}], "0.4.2": [{"comment_text": "", "digests": {"md5": "61b5e8afb8742a7d27a58f83622ebf3a", "sha256": "0706355a965cdb4ec4781f82b57951f419b40baa38bda02be8ed8459981f5c02"}, "downloads": -1, "filename": "scrape-0.4.2-py2-none-any.whl", "has_sig": false, "md5_digest": "61b5e8afb8742a7d27a58f83622ebf3a", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16474, "upload_time": "2015-10-20T03:11:13", "upload_time_iso_8601": "2015-10-20T03:11:13.619542Z", "url": "https://files.pythonhosted.org/packages/67/de/93fbbb4d053b46e60fd56f9bfb24335b9432c3e4a1ea930226621900cd2d/scrape-0.4.2-py2-none-any.whl", "yanked": false}], "0.4.3": [{"comment_text": "", "digests": {"md5": "80dcd0fc675635571d9827c622ae3e26", "sha256": "9945a4765f49223b514fbb2453b3246bde29d09c3082a0b22409d49f58ef122d"}, "downloads": -1, "filename": "scrape-0.4.3-py2-none-any.whl", "has_sig": false, "md5_digest": "80dcd0fc675635571d9827c622ae3e26", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16555, "upload_time": "2015-10-28T02:40:46", "upload_time_iso_8601": "2015-10-28T02:40:46.405268Z", "url": "https://files.pythonhosted.org/packages/0a/ca/b8d4dd4c7e9c7280fb4f07ffb977e077672d33463e4c440a71509cf4310d/scrape-0.4.3-py2-none-any.whl", "yanked": false}], "0.4.4": [{"comment_text": "", "digests": {"md5": "5de90601d185039777af0e4ea0a67ba8", "sha256": "9fed7932f402a29ac81ae551d9896b9edee448c7e7d167d4e1cf7dd36d458ffd"}, "downloads": -1, "filename": "scrape-0.4.4-py2-none-any.whl", "has_sig": false, "md5_digest": "5de90601d185039777af0e4ea0a67ba8", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 16639, "upload_time": "2015-10-28T05:09:18", "upload_time_iso_8601": "2015-10-28T05:09:18.233186Z", "url": "https://files.pythonhosted.org/packages/1b/f2/84f7bf7efdfc25ae9d85ceee908772cd25e6b7fc0276bc5db4912e414dfc/scrape-0.4.4-py2-none-any.whl", "yanked": false}], "0.4.5": [{"comment_text": "", "digests": {"md5": "53d9a2071836ae13445089669774b943", "sha256": "e9b437a2d2a5e4bb9988885b896412cb5e31f2718a6083133fc17872d899d5f0"}, "downloads": -1, "filename": "scrape-0.4.5-py2-none-any.whl", "has_sig": false, "md5_digest": "53d9a2071836ae13445089669774b943", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 17068, "upload_time": "2015-10-29T22:07:17", "upload_time_iso_8601": "2015-10-29T22:07:17.068315Z", "url": "https://files.pythonhosted.org/packages/5e/b0/cf12135b6131342723107793080ce604bd6335b37157383f1b5f63ffeacf/scrape-0.4.5-py2-none-any.whl", "yanked": false}], "0.4.6": [{"comment_text": "", "digests": {"md5": "ed69c8b7c952e4343c283938637e6687", "sha256": "2c6be2f1fe9b317f81b473495f72788bd4f29cde92bb44919553cb83299469d2"}, "downloads": -1, "filename": "scrape-0.4.6-py2-none-any.whl", "has_sig": false, "md5_digest": "ed69c8b7c952e4343c283938637e6687", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 17134, "upload_time": "2015-10-30T20:19:49", "upload_time_iso_8601": "2015-10-30T20:19:49.052461Z", "url": "https://files.pythonhosted.org/packages/e7/24/37c864a4ab59aeb591ea7ed4436f055988349d6b0922c566b7066936f47f/scrape-0.4.6-py2-none-any.whl", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "1bcf47e915af5e449387fa23e81c9be4", "sha256": "44d34a43133ed876101c7fd31fcb5a03daadb50f21b49589f476d0f4f8a5ec41"}, "downloads": -1, "filename": "scrape-0.5.0-py2-none-any.whl", "has_sig": false, "md5_digest": "1bcf47e915af5e449387fa23e81c9be4", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19645, "upload_time": "2015-11-08T05:57:06", "upload_time_iso_8601": "2015-11-08T05:57:06.417567Z", "url": "https://files.pythonhosted.org/packages/bf/b2/391d9a6916f684d5f84003e07eb704a5ef594b17083424768981927879b0/scrape-0.5.0-py2-none-any.whl", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "e72ac3e8494d589ab748895cdbcd8c07", "sha256": "0d4644dc6ae346e9e7e2c171ed812010ade407872bb3dce7f891ee6d923df225"}, "downloads": -1, "filename": "scrape-0.5.1-py2-none-any.whl", "has_sig": false, "md5_digest": "e72ac3e8494d589ab748895cdbcd8c07", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19672, "upload_time": "2015-11-08T06:42:19", "upload_time_iso_8601": "2015-11-08T06:42:19.338850Z", "url": "https://files.pythonhosted.org/packages/2d/b2/a33f6865409913cc5d53b10d22102369ced32865c2f8c5d35eb6cbf3e525/scrape-0.5.1-py2-none-any.whl", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "8c4ecce46d56e14bae38ab5b8c3d30be", "sha256": "b748bef8afe69870429f9cad7eb63b77e793b0b7a2b43537b3f05053160f7506"}, "downloads": -1, "filename": "scrape-0.5.2-py2-none-any.whl", "has_sig": false, "md5_digest": "8c4ecce46d56e14bae38ab5b8c3d30be", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19702, "upload_time": "2015-11-08T06:46:32", "upload_time_iso_8601": "2015-11-08T06:46:32.019256Z", "url": "https://files.pythonhosted.org/packages/bc/8c/b4cf891a6f3e9a48a91f70d37462d38a685ae28a073412af3eae83eb1aca/scrape-0.5.2-py2-none-any.whl", "yanked": false}], "0.5.3": [{"comment_text": "", "digests": {"md5": "8f1520290e7ad7e3289d8da7398fe793", "sha256": "55d94ba723aad9810c6b14fe477e9d4b04ce7d8cceeeec1d58ae109618816146"}, "downloads": -1, "filename": "scrape-0.5.3-py2-none-any.whl", "has_sig": false, "md5_digest": "8f1520290e7ad7e3289d8da7398fe793", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19757, "upload_time": "2015-11-08T07:20:58", "upload_time_iso_8601": "2015-11-08T07:20:58.169416Z", "url": "https://files.pythonhosted.org/packages/94/f1/385b7da7d698cb052447f64eeadd6aeb49350c0bb5c182aafbe6ae856fe3/scrape-0.5.3-py2-none-any.whl", "yanked": false}], "0.5.4": [{"comment_text": "", "digests": {"md5": "9ea45526d475da8c9c04febb23e7f8d4", "sha256": "584900ca9de444c19cecc51e64c040823636022327b186ebac8dcd2a5ad3893b"}, "downloads": -1, "filename": "scrape-0.5.4-py2-none-any.whl", "has_sig": false, "md5_digest": "9ea45526d475da8c9c04febb23e7f8d4", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19783, "upload_time": "2015-11-08T21:31:37", "upload_time_iso_8601": "2015-11-08T21:31:37.393524Z", "url": "https://files.pythonhosted.org/packages/b0/1e/e61bf6731684c30db2a21d0b28621e40e8e5b5e808dd89d1f21c74307132/scrape-0.5.4-py2-none-any.whl", "yanked": false}], "0.5.5": [{"comment_text": "", "digests": {"md5": "52291a8a2115ba4958b01276ec69dd85", "sha256": "1fc2eaddf9b258e3721ad2c2d07144e26ae3dddd04ac63aa77d1493abf682d0d"}, "downloads": -1, "filename": "scrape-0.5.5-py2-none-any.whl", "has_sig": false, "md5_digest": "52291a8a2115ba4958b01276ec69dd85", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19828, "upload_time": "2015-11-10T22:54:14", "upload_time_iso_8601": "2015-11-10T22:54:14.134834Z", "url": "https://files.pythonhosted.org/packages/f5/f3/a263dffb2e9552a3d38c9ff62019a0fb62a249639ea2c26d51ab017f3c36/scrape-0.5.5-py2-none-any.whl", "yanked": false}], "0.5.6": [{"comment_text": "", "digests": {"md5": "c74c909bbe285e80694df271682d0154", "sha256": "687e6f63585b084e168258dc2d1c14b8146826717cf8febb39b27362f448e1f3"}, "downloads": -1, "filename": "scrape-0.5.6-py2-none-any.whl", "has_sig": false, "md5_digest": "c74c909bbe285e80694df271682d0154", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 19871, "upload_time": "2015-11-10T23:07:40", "upload_time_iso_8601": "2015-11-10T23:07:40.031730Z", "url": "https://files.pythonhosted.org/packages/2d/e7/66652ab24454deebacbb13a3ec3b6c1a3fef6bb1aeb933cb45f90a95eef4/scrape-0.5.6-py2-none-any.whl", "yanked": false}], "0.5.7": [{"comment_text": "", "digests": {"md5": "fe9ac75cc508da1bc2e6743e8ec3460c", "sha256": "dc9a6ddd14ca8d2e45b8eef08ac0cdcb35ff0cf56ee9185acbfaa44cbe3f4a57"}, "downloads": -1, "filename": "scrape-0.5.7-py2-none-any.whl", "has_sig": false, "md5_digest": "fe9ac75cc508da1bc2e6743e8ec3460c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 20123, "upload_time": "2015-11-10T23:43:16", "upload_time_iso_8601": "2015-11-10T23:43:16.886649Z", "url": "https://files.pythonhosted.org/packages/6d/c3/cbedc7ee770732b8ad5737f7a2e2cc5e4c3215fce993687be8cbe3742b92/scrape-0.5.7-py2-none-any.whl", "yanked": false}], "0.5.8": [{"comment_text": "", "digests": {"md5": "d97f6fd193edb743dcb576d3cbbd76e5", "sha256": "3982c8e7f07b44ad33e572974a20f82bd5c067c2e538f6b439286f81d165eb45"}, "downloads": -1, "filename": "scrape-0.5.8-py2-none-any.whl", "has_sig": false, "md5_digest": "d97f6fd193edb743dcb576d3cbbd76e5", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21049, "upload_time": "2015-11-19T08:58:59", "upload_time_iso_8601": "2015-11-19T08:58:59.347639Z", "url": "https://files.pythonhosted.org/packages/80/03/2195286c26648bee5ff034a45f7cc96d6b95814c9a6629cac9769ea25b68/scrape-0.5.8-py2-none-any.whl", "yanked": false}], "0.5.9": [{"comment_text": "", "digests": {"md5": "f5fe6035ba7847dfcba98ec7b4e65420", "sha256": "d6bcd6bff32b336296923bb24f3f78f84108999922eb0e3ff7419f7c1a6d7813"}, "downloads": -1, "filename": "scrape-0.5.9-py2-none-any.whl", "has_sig": false, "md5_digest": "f5fe6035ba7847dfcba98ec7b4e65420", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21107, "upload_time": "2015-11-19T09:33:37", "upload_time_iso_8601": "2015-11-19T09:33:37.042339Z", "url": "https://files.pythonhosted.org/packages/dc/16/7c8a5b9e923fc4fb8e2207642ae4217ce8090b5b9316132127de11091556/scrape-0.5.9-py2-none-any.whl", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "e6968cbd772799a026ff0c512c518d14", "sha256": "ac0652618ef1dade75556023861c14e176030cda942a35e50a24d8683d6a9533"}, "downloads": -1, "filename": "scrape-0.6.0-py2-none-any.whl", "has_sig": false, "md5_digest": "e6968cbd772799a026ff0c512c518d14", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21229, "upload_time": "2015-11-23T00:19:32", "upload_time_iso_8601": "2015-11-23T00:19:32.349206Z", "url": "https://files.pythonhosted.org/packages/a2/89/e922a8ff03336da6340ec83cbd16e6cdc789de8eb674b318a76340c28599/scrape-0.6.0-py2-none-any.whl", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "5ac1e13707cc46d0e9084b1e4bc867c1", "sha256": "680c670aef795c8209a918394e1c6dbe3e0fb6a54700e62328819175a7c09768"}, "downloads": -1, "filename": "scrape-0.6.1-py2-none-any.whl", "has_sig": false, "md5_digest": "5ac1e13707cc46d0e9084b1e4bc867c1", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21444, "upload_time": "2015-11-23T01:24:04", "upload_time_iso_8601": "2015-11-23T01:24:04.070662Z", "url": "https://files.pythonhosted.org/packages/2b/fb/cb79129b488b0d84dc515e8d51068817bd0fd428d1cf6bd859298b790c70/scrape-0.6.1-py2-none-any.whl", "yanked": false}], "0.6.2": [{"comment_text": "", "digests": {"md5": "103db1dcbfd5de09df350f759dd1d7d6", "sha256": "9b95e9d4bcf53c70d6d9eece500479ec08c0ac7d5d4ded9346476eaecbd60fc8"}, "downloads": -1, "filename": "scrape-0.6.2-py2-none-any.whl", "has_sig": false, "md5_digest": "103db1dcbfd5de09df350f759dd1d7d6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21556, "upload_time": "2015-11-24T06:03:36", "upload_time_iso_8601": "2015-11-24T06:03:36.712532Z", "url": "https://files.pythonhosted.org/packages/f1/11/aa7164fb4650f159f72d9542ef79c6dcc846107ebddec8cdfc328f4e1f59/scrape-0.6.2-py2-none-any.whl", "yanked": false}], "0.6.3": [{"comment_text": "", "digests": {"md5": "c5775bd3a25a711211e0aca2463867ca", "sha256": "5f3074116f8cf885c18944d1d622fdaf01bd9012f9c56cd0ed536a23647885bf"}, "downloads": -1, "filename": "scrape-0.6.3-py2-none-any.whl", "has_sig": false, "md5_digest": "c5775bd3a25a711211e0aca2463867ca", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21896, "upload_time": "2015-11-26T05:36:23", "upload_time_iso_8601": "2015-11-26T05:36:23.936436Z", "url": "https://files.pythonhosted.org/packages/2b/2a/fe0b3da97c40f63f916e54cd85fadf17f12ba451728a1fccb75d190aa94d/scrape-0.6.3-py2-none-any.whl", "yanked": false}], "0.6.4": [{"comment_text": "", "digests": {"md5": "c8cc44345b1dfdd5094a099da1b783c9", "sha256": "31583b80ab9b6f493cd7e8fa83a15fe584fbcdebaa658daa10807c323367987b"}, "downloads": -1, "filename": "scrape-0.6.4-py2-none-any.whl", "has_sig": false, "md5_digest": "c8cc44345b1dfdd5094a099da1b783c9", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22165, "upload_time": "2015-11-28T05:59:10", "upload_time_iso_8601": "2015-11-28T05:59:10.085909Z", "url": "https://files.pythonhosted.org/packages/a8/0f/fd2e9b0d98249f078fdfda1553cb3492f37ef6d72e0894675815ffd9d4ab/scrape-0.6.4-py2-none-any.whl", "yanked": false}], "0.6.5": [{"comment_text": "", "digests": {"md5": "fb8db4e1c76430726a1fa96b0d75ccef", "sha256": "eda16bf3bbbc074405736a7bbdc7377401bb36a55345580c06b6ab87c9c8b169"}, "downloads": -1, "filename": "scrape-0.6.5-py2-none-any.whl", "has_sig": false, "md5_digest": "fb8db4e1c76430726a1fa96b0d75ccef", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22322, "upload_time": "2015-12-04T22:23:58", "upload_time_iso_8601": "2015-12-04T22:23:58.053730Z", "url": "https://files.pythonhosted.org/packages/89/63/116d92eea5d324d5156c9890bc9b44331ba64a2ac0aa72feb751b1a81313/scrape-0.6.5-py2-none-any.whl", "yanked": false}], "0.6.6": [{"comment_text": "", "digests": {"md5": "8aacb02a8526e17dfdcf3300f15efbae", "sha256": "da6a8dcf745bc97b258567798e12392ce8ef0a4af93dacda35a491a28ca6c070"}, "downloads": -1, "filename": "scrape-0.6.6-py2-none-any.whl", "has_sig": false, "md5_digest": "8aacb02a8526e17dfdcf3300f15efbae", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22560, "upload_time": "2015-12-05T06:38:32", "upload_time_iso_8601": "2015-12-05T06:38:32.773719Z", "url": "https://files.pythonhosted.org/packages/66/4d/6cd8a961455ec9e166838d5c56ae59c126a6b244fa28f7d6cee62c853664/scrape-0.6.6-py2-none-any.whl", "yanked": false}], "0.6.7": [{"comment_text": "", "digests": {"md5": "37d88b42f96d7ca098d75c4d112711a7", "sha256": "241434e44213b95db665b3f0c2fe8b1b4d76fa0f9846d08f0d017f9835f9e726"}, "downloads": -1, "filename": "scrape-0.6.7-py2-none-any.whl", "has_sig": false, "md5_digest": "37d88b42f96d7ca098d75c4d112711a7", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22595, "upload_time": "2015-12-05T06:46:27", "upload_time_iso_8601": "2015-12-05T06:46:27.516293Z", "url": "https://files.pythonhosted.org/packages/a8/cf/c6c97ba0b11a83d9ab52747aba952003ca25f8feb1c0a41c66d9c0d7f596/scrape-0.6.7-py2-none-any.whl", "yanked": false}], "0.6.8": [{"comment_text": "", "digests": {"md5": "3bfba401d3236a58a5e1bffc85e8ba08", "sha256": "58ef554a72c3ecb8b810ce26b9336acf7b0e24732ac0df29b7d6b884767b9fde"}, "downloads": -1, "filename": "scrape-0.6.8-py2-none-any.whl", "has_sig": false, "md5_digest": "3bfba401d3236a58a5e1bffc85e8ba08", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22724, "upload_time": "2015-12-05T06:51:14", "upload_time_iso_8601": "2015-12-05T06:51:14.971925Z", "url": "https://files.pythonhosted.org/packages/a6/1f/f6e52be5e6df5f34ff331de4265a813df33fd5a1d5c2d7e105909e96417b/scrape-0.6.8-py2-none-any.whl", "yanked": false}], "0.6.9": [{"comment_text": "", "digests": {"md5": "9e9259d5c5745adc950648a23fefc476", "sha256": "a7165d443f09b40ce3038ef9bb82899ed4507ef7d440048672643fbdb3de4689"}, "downloads": -1, "filename": "scrape-0.6.9-py2-none-any.whl", "has_sig": false, "md5_digest": "9e9259d5c5745adc950648a23fefc476", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22770, "upload_time": "2015-12-06T23:30:20", "upload_time_iso_8601": "2015-12-06T23:30:20.511130Z", "url": "https://files.pythonhosted.org/packages/da/6a/7cf16f614d71c371fb6a04826ec955e57a577070c640747fa929654aefad/scrape-0.6.9-py2-none-any.whl", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "66373d038fef77e2b4ffbfefaede70eb", "sha256": "cd33c15938f6a3f62c7081a5b915db058bc4c3a4c028951085bc5df4735d99ad"}, "downloads": -1, "filename": "scrape-0.7.0-py2-none-any.whl", "has_sig": false, "md5_digest": "66373d038fef77e2b4ffbfefaede70eb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 22912, "upload_time": "2015-12-07T05:44:10", "upload_time_iso_8601": "2015-12-07T05:44:10.431842Z", "url": "https://files.pythonhosted.org/packages/bf/56/fa4e34faccf4474e690531f2444f1fee0c4eef673d0c6f5273c9282dee07/scrape-0.7.0-py2-none-any.whl", "yanked": false}], "0.7.1": [{"comment_text": "", "digests": {"md5": "0d6026fb52fd7e609c7b2ea5308c9e46", "sha256": "b2bb9d7f30434ae7ab902063e9003c677b401a1664556efd76bc4eff03f504f4"}, "downloads": -1, "filename": "scrape-0.7.1-py2-none-any.whl", "has_sig": false, "md5_digest": "0d6026fb52fd7e609c7b2ea5308c9e46", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 21477, "upload_time": "2015-12-19T23:56:02", "upload_time_iso_8601": "2015-12-19T23:56:02.502805Z", "url": "https://files.pythonhosted.org/packages/58/af/02908e575648772b98d6aa2ff3b9e9a2bd3ace2e0b6252acf6ecb9c5fe18/scrape-0.7.1-py2-none-any.whl", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "3f0762ed736afb735681df53c368564f", "sha256": "c720ccff1edb747f7ac3141419dddbff564b924c08ba256b26eb1f6057dc8612"}, "downloads": -1, "filename": "scrape-0.7.2-py2-none-any.whl", "has_sig": false, "md5_digest": "3f0762ed736afb735681df53c368564f", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 23835, "upload_time": "2016-01-02T01:50:26", "upload_time_iso_8601": "2016-01-02T01:50:26.107515Z", "url": "https://files.pythonhosted.org/packages/ce/59/663643ab596b3eba82752e1c8fd5edf618de5e7adad1cbef35f9bd35c23f/scrape-0.7.2-py2-none-any.whl", "yanked": false}], "0.7.3": [{"comment_text": "", "digests": {"md5": "f9509660a0d4973653b57feb325181a1", "sha256": "acc11bbab2b5c387393c23a77a141dc187404f9ba0554d6f407d0526d53ec361"}, "downloads": -1, "filename": "scrape-0.7.3-py2-none-any.whl", "has_sig": false, "md5_digest": "f9509660a0d4973653b57feb325181a1", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 23861, "upload_time": "2016-01-02T01:53:40", "upload_time_iso_8601": "2016-01-02T01:53:40.880122Z", "url": "https://files.pythonhosted.org/packages/1f/e0/6f842b644e1edbc86173683c7b5e68d4f0a279e0fa96acd28ff5563b29aa/scrape-0.7.3-py2-none-any.whl", "yanked": false}], "0.7.4": [{"comment_text": "", "digests": {"md5": "ab01710b32e9ecfd3feb0c36a370c4af", "sha256": "d91a0ccac4f1999e8627295c3e0df57589f898b77b71b11e8370e2670e0853dd"}, "downloads": -1, "filename": "scrape-0.7.4-py2-none-any.whl", "has_sig": false, "md5_digest": "ab01710b32e9ecfd3feb0c36a370c4af", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 24136, "upload_time": "2016-01-02T09:30:37", "upload_time_iso_8601": "2016-01-02T09:30:37.554324Z", "url": "https://files.pythonhosted.org/packages/d0/6e/be7ef5b41fecd753d4f4fcef9b79bd294322672d15337320161aa5d7a77f/scrape-0.7.4-py2-none-any.whl", "yanked": false}], "0.7.5": [{"comment_text": "", "digests": {"md5": "c45da9e28d01404a639f2c6a1cb41397", "sha256": "bf4b9f92f3dac505905f500f47fc255bea1c43128cd39a06d33c6a62503b5a50"}, "downloads": -1, "filename": "scrape-0.7.5-py2-none-any.whl", "has_sig": false, "md5_digest": "c45da9e28d01404a639f2c6a1cb41397", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 24148, "upload_time": "2016-01-02T09:35:41", "upload_time_iso_8601": "2016-01-02T09:35:41.009551Z", "url": "https://files.pythonhosted.org/packages/d7/67/a56db6d0399ee9667d8190e0903480b1a811477cebe0f90dafa9a673f94a/scrape-0.7.5-py2-none-any.whl", "yanked": false}], "0.7.6": [{"comment_text": "", "digests": {"md5": "f88a0882f2b19d6f15e7c984f7af44eb", "sha256": "2f6d94765aa898b5fdf0323fc58a1c27d6315659ff2d32b09fde33b3b6f6f749"}, "downloads": -1, "filename": "scrape-0.7.6-py2-none-any.whl", "has_sig": false, "md5_digest": "f88a0882f2b19d6f15e7c984f7af44eb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 23272, "upload_time": "2016-01-05T12:36:32", "upload_time_iso_8601": "2016-01-05T12:36:32.031545Z", "url": "https://files.pythonhosted.org/packages/35/54/a0d7813dd7b6b9c03161a8ddf0f9d27ff8c74fca73367213895f79f62b39/scrape-0.7.6-py2-none-any.whl", "yanked": false}], "0.7.7": [{"comment_text": "", "digests": {"md5": "c77008f5f603beeb62ef1aec68110de4", "sha256": "182c6c773cebcdd1e0badf53a1f503b0a750d4e701b4cb7ab5b8ece3203e2d0e"}, "downloads": -1, "filename": "scrape-0.7.7-py2-none-any.whl", "has_sig": false, "md5_digest": "c77008f5f603beeb62ef1aec68110de4", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 24233, "upload_time": "2016-01-22T15:53:05", "upload_time_iso_8601": "2016-01-22T15:53:05.171909Z", "url": "https://files.pythonhosted.org/packages/fc/ef/7e4da0f30c19d8bbaac90c0165771e155f83eb4b9cde351faf18ba61f6a9/scrape-0.7.7-py2-none-any.whl", "yanked": false}], "0.7.8": [{"comment_text": "", "digests": {"md5": "610096f556c0c28bb34faf8346a21ebf", "sha256": "de8cc42bf8d257b2335f6c20dbe1c8552f40ef97da5171dd5fc8bf73163d5b53"}, "downloads": -1, "filename": "scrape-0.7.8-py2-none-any.whl", "has_sig": false, "md5_digest": "610096f556c0c28bb34faf8346a21ebf", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 24380, "upload_time": "2016-01-22T17:02:34", "upload_time_iso_8601": "2016-01-22T17:02:34.583745Z", "url": "https://files.pythonhosted.org/packages/e6/93/2fda07e7c5e1ae1c1ca233007f94049dee541ce1ad01532395e681390522/scrape-0.7.8-py2-none-any.whl", "yanked": false}], "0.7.9": [{"comment_text": "", "digests": {"md5": "7f4559e46cdb29e446c4fa76ab08d4ca", "sha256": "437a8bb4828221169111a7c19244d9d85701a77f36facc7d10063535d5e667f3"}, "downloads": -1, "filename": "scrape-0.7.9-py2-none-any.whl", "has_sig": false, "md5_digest": "7f4559e46cdb29e446c4fa76ab08d4ca", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25028, "upload_time": "2016-01-23T04:54:45", "upload_time_iso_8601": "2016-01-23T04:54:45.208765Z", "url": "https://files.pythonhosted.org/packages/1f/4f/bab623f5447c20ae95dae749ff2e74128151855e6589942338ed48c6e708/scrape-0.7.9-py2-none-any.whl", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "ef71a3583f80be743135b12eae612903", "sha256": "5203217b986c06d1b04d388bc9f2f086f4917af5b922d8f78fae55a6d9ec9a88"}, "downloads": -1, "filename": "scrape-0.8.0-py2-none-any.whl", "has_sig": false, "md5_digest": "ef71a3583f80be743135b12eae612903", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25037, "upload_time": "2016-01-30T06:51:59", "upload_time_iso_8601": "2016-01-30T06:51:59.898532Z", "url": "https://files.pythonhosted.org/packages/00/92/026b19185d2ba22328f683aa8094f0a6b39e3a79df01e458a74883fa8c7e/scrape-0.8.0-py2-none-any.whl", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "c2546b850749f9074540d5d0b20e05ab", "sha256": "a1b9bf7189e8153a7d4394d3a3aaae04bb3fd4273b322c90d512ee1bda71b931"}, "downloads": -1, "filename": "scrape-0.8.1-py2-none-any.whl", "has_sig": false, "md5_digest": "c2546b850749f9074540d5d0b20e05ab", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25049, "upload_time": "2016-01-30T06:55:18", "upload_time_iso_8601": "2016-01-30T06:55:18.171831Z", "url": "https://files.pythonhosted.org/packages/0c/70/be19819a9fefa1ed0f7536267966189516a2f5484450765ba5c7ba3a4392/scrape-0.8.1-py2-none-any.whl", "yanked": false}], "0.8.10": [{"comment_text": "", "digests": {"md5": "5e9557cb3c18fba07202888939f4e37c", "sha256": "b7a6d148dcf7207042303326db51db3bc5b7048fd4c9345aae6e4b57a8412f31"}, "downloads": -1, "filename": "scrape-0.8.10-py2-none-any.whl", "has_sig": false, "md5_digest": "5e9557cb3c18fba07202888939f4e37c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 2667, "upload_time": "2016-06-16T01:15:03", "upload_time_iso_8601": "2016-06-16T01:15:03.860900Z", "url": "https://files.pythonhosted.org/packages/4b/98/589c8960350591be8a41064fe8d28aa1a822ce35c30b944eba58ba327f48/scrape-0.8.10-py2-none-any.whl", "yanked": false}], "0.8.11": [{"comment_text": "", "digests": {"md5": "403aeba1bf0febaa6def41a0a087569e", "sha256": "c5dc1119ec9d0ee409d86ddf3ede3abac33fda170c58be0ada91ebf7698930da"}, "downloads": -1, "filename": "scrape-0.8.11-py2-none-any.whl", "has_sig": false, "md5_digest": "403aeba1bf0febaa6def41a0a087569e", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 26161, "upload_time": "2016-06-16T02:56:47", "upload_time_iso_8601": "2016-06-16T02:56:47.539665Z", "url": "https://files.pythonhosted.org/packages/75/23/2e894e1daa029dad9468db721bdc49b47a9897e7eb340df116c722e1af66/scrape-0.8.11-py2-none-any.whl", "yanked": false}], "0.8.2": [{"comment_text": "", "digests": {"md5": "6bac8d591f07e91edb4d78d628334ad0", "sha256": "52232856af9e249abb7d4717a457ab607b94ace2331d75619236ff074afe201e"}, "downloads": -1, "filename": "scrape-0.8.2-py2-none-any.whl", "has_sig": false, "md5_digest": "6bac8d591f07e91edb4d78d628334ad0", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25047, "upload_time": "2016-02-02T09:22:33", "upload_time_iso_8601": "2016-02-02T09:22:33.437282Z", "url": "https://files.pythonhosted.org/packages/7c/da/26222df0877542b1cc618d8a5fcfeb4de574391f02413e4a43cfe32f8ef1/scrape-0.8.2-py2-none-any.whl", "yanked": false}], "0.8.3": [{"comment_text": "", "digests": {"md5": "d998fcca74122f8cf8fd116bc00d5304", "sha256": "c4b707b4b135ef3abdcaaae7bd7a8bbd0d43b8f9f8a8459ff67bbfacd97a66cd"}, "downloads": -1, "filename": "scrape-0.8.3-py2-none-any.whl", "has_sig": false, "md5_digest": "d998fcca74122f8cf8fd116bc00d5304", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25093, "upload_time": "2016-02-04T01:36:44", "upload_time_iso_8601": "2016-02-04T01:36:44.152172Z", "url": "https://files.pythonhosted.org/packages/ed/13/7a82eebf1ae586b893a167c7cc2c1283959eac6836a1de84d8769fc97550/scrape-0.8.3-py2-none-any.whl", "yanked": false}], "0.8.4": [{"comment_text": "", "digests": {"md5": "df28ab772d3963bf4e4dc63152820a59", "sha256": "849ba0e597cf61629251a4b9261cdd3728e3d2af37379d68161f7354b70091e7"}, "downloads": -1, "filename": "scrape-0.8.4-py2-none-any.whl", "has_sig": false, "md5_digest": "df28ab772d3963bf4e4dc63152820a59", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25088, "upload_time": "2016-02-04T01:58:32", "upload_time_iso_8601": "2016-02-04T01:58:32.783473Z", "url": "https://files.pythonhosted.org/packages/ab/d8/cf0145453eff933836c85854f2472212863fccea8a7de45d643c66be1ac5/scrape-0.8.4-py2-none-any.whl", "yanked": false}], "0.8.5": [{"comment_text": "", "digests": {"md5": "8c9607878a7f7fc4a8aa90139f11864f", "sha256": "eeb223b2740327ecbcc67a89f45a2655aa0ae09173a5c43aede87f00782b685d"}, "downloads": -1, "filename": "scrape-0.8.5-py2-none-any.whl", "has_sig": false, "md5_digest": "8c9607878a7f7fc4a8aa90139f11864f", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25378, "upload_time": "2016-02-04T02:24:56", "upload_time_iso_8601": "2016-02-04T02:24:56.040704Z", "url": "https://files.pythonhosted.org/packages/be/9d/f904c50de5a61f8a27d02406e78cd3cc71823f52db86b0168de50686ecf4/scrape-0.8.5-py2-none-any.whl", "yanked": false}], "0.8.6": [{"comment_text": "", "digests": {"md5": "022d8155e259b9bee1a0105b729a569e", "sha256": "5de78239899af632b91a84aa5b1705726a9567a0e3a404e21b867b0075f08870"}, "downloads": -1, "filename": "scrape-0.8.6-py2-none-any.whl", "has_sig": false, "md5_digest": "022d8155e259b9bee1a0105b729a569e", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25557, "upload_time": "2016-02-17T21:57:53", "upload_time_iso_8601": "2016-02-17T21:57:53.918949Z", "url": "https://files.pythonhosted.org/packages/58/6e/b0fc828c77ec10de704829f060f2016b29728eae8696d7c932743ab8002e/scrape-0.8.6-py2-none-any.whl", "yanked": false}], "0.8.7": [{"comment_text": "", "digests": {"md5": "a0d58c4584618e071853577472fe543c", "sha256": "94319588dcc3f7c7bbc3d680377df4e1cf30cd5d2bdc1e753a77699756cb2994"}, "downloads": -1, "filename": "scrape-0.8.7-py2-none-any.whl", "has_sig": false, "md5_digest": "a0d58c4584618e071853577472fe543c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25802, "upload_time": "2016-03-30T08:58:02", "upload_time_iso_8601": "2016-03-30T08:58:02.830299Z", "url": "https://files.pythonhosted.org/packages/03/1a/2b9c253af8ba3cc7ac6dfde6e913261130ee4693c7febcb45e0137108305/scrape-0.8.7-py2-none-any.whl", "yanked": false}], "0.8.8": [{"comment_text": "", "digests": {"md5": "9180e0dbb94879b671eaad618c47c803", "sha256": "fadda07bd755922d01bc24672ef481751cfcb67bbb3de16b913182eeba80eb3c"}, "downloads": -1, "filename": "scrape-0.8.8-py2-none-any.whl", "has_sig": false, "md5_digest": "9180e0dbb94879b671eaad618c47c803", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 25948, "upload_time": "2016-06-10T20:44:59", "upload_time_iso_8601": "2016-06-10T20:44:59.796822Z", "url": "https://files.pythonhosted.org/packages/45/47/48853b14d852a31f29b896272314c35dcec36a0a3aa6232cd5d3a6d92611/scrape-0.8.8-py2-none-any.whl", "yanked": false}], "0.8.9": [{"comment_text": "", "digests": {"md5": "af7330605b65a12eeca915530d7ae476", "sha256": "10ebd74ffdb10c169caded7505aa91da18b4a7d46f82d7ee228d9416cdb6f2f0"}, "downloads": -1, "filename": "scrape-0.8.9-py2-none-any.whl", "has_sig": false, "md5_digest": "af7330605b65a12eeca915530d7ae476", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 26032, "upload_time": "2016-06-16T00:42:30", "upload_time_iso_8601": "2016-06-16T00:42:30.253942Z", "url": "https://files.pythonhosted.org/packages/e5/86/9c8e8378fdc2e7763a4943b462dc7ae7d1752579d0ef6fbe2ef64fb6ab68/scrape-0.8.9-py2-none-any.whl", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "83365f8418d5067560ea06c38c27f3cb", "sha256": "c1d74af20356eb4df99465f2467143db7e3529c2c5716a73990e47865c6e89e9"}, "downloads": -1, "filename": "scrape-0.9.0-py2-none-any.whl", "has_sig": false, "md5_digest": "83365f8418d5067560ea06c38c27f3cb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 26250, "upload_time": "2016-06-18T02:00:11", "upload_time_iso_8601": "2016-06-18T02:00:11.939449Z", "url": "https://files.pythonhosted.org/packages/d1/dd/2ef9a64eec2fb0432ff905321b8c17409e04a682384ccf6043a37dbab624/scrape-0.9.0-py2-none-any.whl", "yanked": false}], "0.9.1": [{"comment_text": "", "digests": {"md5": "ef53151f0e938b29b04e78087794a1f7", "sha256": "01ba60bd94c2f09a06d9856d5e06c4458c2a7f79ced8b79e3d94a692381c71c7"}, "downloads": -1, "filename": "scrape-0.9.1-py2-none-any.whl", "has_sig": false, "md5_digest": "ef53151f0e938b29b04e78087794a1f7", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 26440, "upload_time": "2016-06-20T06:41:23", "upload_time_iso_8601": "2016-06-20T06:41:23.362022Z", "url": "https://files.pythonhosted.org/packages/00/06/09d5931cc459d8b257a6647d21d2a0fafc2688ff753753757b6c7f8a77a7/scrape-0.9.1-py2-none-any.whl", "yanked": false}], "0.9.10": [{"comment_text": "", "digests": {"md5": "438efd1d23f9a6ec2a4c34fe15b7aa11", "sha256": "2a25d015028abd240ce8e9f0ac86e1706cd91eeb685df2fb8401725e0801c3d7"}, "downloads": -1, "filename": "scrape-0.9.10-py2-none-any.whl", "has_sig": false, "md5_digest": "438efd1d23f9a6ec2a4c34fe15b7aa11", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27518, "upload_time": "2016-06-26T07:49:38", "upload_time_iso_8601": "2016-06-26T07:49:38.655047Z", "url": "https://files.pythonhosted.org/packages/48/9e/6d1e78faf692969123ce17894bd1c55a99ddcb08fc6636bcd5c75172dabf/scrape-0.9.10-py2-none-any.whl", "yanked": false}], "0.9.11": [{"comment_text": "", "digests": {"md5": "95de5252ba7eeb8a0bc6a90973e91d51", "sha256": "657a1c2ff5673d2eae7a6e98e257e7b025040d3e315187a03de60ba2e91937d6"}, "downloads": -1, "filename": "scrape-0.9.11-py2-none-any.whl", "has_sig": false, "md5_digest": "95de5252ba7eeb8a0bc6a90973e91d51", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27649, "upload_time": "2016-08-23T01:23:24", "upload_time_iso_8601": "2016-08-23T01:23:24.772223Z", "url": "https://files.pythonhosted.org/packages/37/65/8a605ad2f02af2685dba1ac9ba7ca53cd4e0336aa61fb8b033c98c2a37bb/scrape-0.9.11-py2-none-any.whl", "yanked": false}], "0.9.12": [{"comment_text": "", "digests": {"md5": "b078d683fe41a57ca8d3ad5b6b1d2edf", "sha256": "fc39eb0eaa805284e4fafd8eca30ea471f0bcb2ebc2a6bf10f2de0e45b7a2251"}, "downloads": -1, "filename": "scrape-0.9.12-py3-none-any.whl", "has_sig": false, "md5_digest": "b078d683fe41a57ca8d3ad5b6b1d2edf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 27716, "upload_time": "2017-01-10T15:07:58", "upload_time_iso_8601": "2017-01-10T15:07:58.096747Z", "url": "https://files.pythonhosted.org/packages/84/a0/9a465292779b30354887a2de8da04be2441779549ddeb1723c2d9564403e/scrape-0.9.12-py3-none-any.whl", "yanked": false}], "0.9.14": [{"comment_text": "", "digests": {"md5": "b0ff78552a465917fc579bc89a3c5542", "sha256": "795913199cf12f5dbf888801e2c0d10534dcf5485d3c35847a0145316d7acc87"}, "downloads": -1, "filename": "scrape-0.9.14.tar.gz", "has_sig": false, "md5_digest": "b0ff78552a465917fc579bc89a3c5542", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26779, "upload_time": "2019-01-05T04:58:47", "upload_time_iso_8601": "2019-01-05T04:58:47.591693Z", "url": "https://files.pythonhosted.org/packages/87/e6/23d47620bd62fe692d01a909557d1201c1c1f1b8ec97f7eaed4fefb2e9bd/scrape-0.9.14.tar.gz", "yanked": false}], "0.9.15": [{"comment_text": "", "digests": {"md5": "43183672306394c945363ad9d383883d", "sha256": "1659769699f2b6e8ef0d375ac7a1527ca5a915d23903f2481f9ec52c698b4047"}, "downloads": -1, "filename": "scrape-0.9.15.tar.gz", "has_sig": false, "md5_digest": "43183672306394c945363ad9d383883d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26837, "upload_time": "2019-01-05T05:04:42", "upload_time_iso_8601": "2019-01-05T05:04:42.051118Z", "url": "https://files.pythonhosted.org/packages/30/b7/0e161d707ccada0d11fb173de3351f481325ddb98765490e287fd1e49e8a/scrape-0.9.15.tar.gz", "yanked": false}], "0.9.2": [{"comment_text": "", "digests": {"md5": "3a7b12b85f34fcafa63db3ff4c2fa42c", "sha256": "62d13200735ccfc1b9e41ca11745646e4bd363ba274ef236b41ca13b310588f1"}, "downloads": -1, "filename": "scrape-0.9.2-py2-none-any.whl", "has_sig": false, "md5_digest": "3a7b12b85f34fcafa63db3ff4c2fa42c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27434, "upload_time": "2016-06-20T22:50:37", "upload_time_iso_8601": "2016-06-20T22:50:37.708812Z", "url": "https://files.pythonhosted.org/packages/95/a4/f009d815d6baecf2d3e1b0c03453ee1e9c6a91adcf477368cf1c1b92ec50/scrape-0.9.2-py2-none-any.whl", "yanked": false}], "0.9.3": [{"comment_text": "", "digests": {"md5": "73a1556e810c246854714841ff350aa6", "sha256": "be27512777934fcb4529e5befcb844d9de994bdb66d36a49044490fb955655a7"}, "downloads": -1, "filename": "scrape-0.9.3-py2-none-any.whl", "has_sig": false, "md5_digest": "73a1556e810c246854714841ff350aa6", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27391, "upload_time": "2016-06-23T06:59:16", "upload_time_iso_8601": "2016-06-23T06:59:16.400190Z", "url": "https://files.pythonhosted.org/packages/c9/3b/ecb857e17c161693bdf7137a664928cfe8f1c849333f90cefea2f9b823b8/scrape-0.9.3-py2-none-any.whl", "yanked": false}], "0.9.4": [{"comment_text": "", "digests": {"md5": "bc5d655960b6ff93b82f61c8c7c39dd0", "sha256": "80a5fd8ef0f8029221e31707f529d03e9bb49158fbb769a8165843cc9965d88d"}, "downloads": -1, "filename": "scrape-0.9.4-py2-none-any.whl", "has_sig": false, "md5_digest": "bc5d655960b6ff93b82f61c8c7c39dd0", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27441, "upload_time": "2016-06-23T07:08:34", "upload_time_iso_8601": "2016-06-23T07:08:34.535032Z", "url": "https://files.pythonhosted.org/packages/57/57/54367e6b8bfacf5353bb5c56a69f0ecf1550c3a1301cf5ccbc6492093bcf/scrape-0.9.4-py2-none-any.whl", "yanked": false}], "0.9.5": [{"comment_text": "", "digests": {"md5": "7a00714985a1999bec1e3b7749c3bc25", "sha256": "eb9a837081cb03f84ede0be2b092dc6e23b662ca5b9f785776492d406beaacb6"}, "downloads": -1, "filename": "scrape-0.9.5-py2-none-any.whl", "has_sig": false, "md5_digest": "7a00714985a1999bec1e3b7749c3bc25", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27576, "upload_time": "2016-06-23T17:22:08", "upload_time_iso_8601": "2016-06-23T17:22:08.725351Z", "url": "https://files.pythonhosted.org/packages/63/f3/844b997c113398606740f4af49ccaf224e38805d6c3123bcebdfd152f40f/scrape-0.9.5-py2-none-any.whl", "yanked": false}], "0.9.6": [{"comment_text": "", "digests": {"md5": "9a0fbc65329a6b30a5aaef16fd1827e5", "sha256": "2064273334208b49fb2aa9cf9dbddefa4a9de44c2b98e4d35cbd55c10faf6f52"}, "downloads": -1, "filename": "scrape-0.9.6-py2-none-any.whl", "has_sig": false, "md5_digest": "9a0fbc65329a6b30a5aaef16fd1827e5", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27711, "upload_time": "2016-06-23T22:41:24", "upload_time_iso_8601": "2016-06-23T22:41:24.946230Z", "url": "https://files.pythonhosted.org/packages/8a/61/1a0c98d1f61dc58dbcad100fa7c2a5aeecb7f6499be7e42695c8b1132194/scrape-0.9.6-py2-none-any.whl", "yanked": false}], "0.9.8": [{"comment_text": "", "digests": {"md5": "26b29eb07418f21c0ec1bc7c6b4037fb", "sha256": "a653b86d514d17f65e6c710f58c1fe65be9947201a35498ffe5ef53f54ee7981"}, "downloads": -1, "filename": "scrape-0.9.8-py2-none-any.whl", "has_sig": false, "md5_digest": "26b29eb07418f21c0ec1bc7c6b4037fb", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27290, "upload_time": "2016-06-24T07:12:32", "upload_time_iso_8601": "2016-06-24T07:12:32.429713Z", "url": "https://files.pythonhosted.org/packages/17/ba/3b8501c6623c22d6b50f86856bc2f8e33f1bdd01fa1b61a57fe1c8eacf3c/scrape-0.9.8-py2-none-any.whl", "yanked": false}], "0.9.9": [{"comment_text": "", "digests": {"md5": "43a43c54be9006154d745bcf6b8f3761", "sha256": "426591ab6571376f4dca216c8ef971140642f74f9566ec0c7539f5afd6e5685b"}, "downloads": -1, "filename": "scrape-0.9.9-py2-none-any.whl", "has_sig": false, "md5_digest": "43a43c54be9006154d745bcf6b8f3761", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 27530, "upload_time": "2016-06-24T22:15:37", "upload_time_iso_8601": "2016-06-24T22:15:37.726406Z", "url": "https://files.pythonhosted.org/packages/d6/1d/d31b72451ae93aa30c662886c091c7b4822e4fe0635ddd995a58de67ea49/scrape-0.9.9-py2-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fc118eff268ebd78fdd890168474cfc2", "sha256": "66acaaa9f4db205770fe0a71f6471a1cf66efc829e3de6b0a7486492a8a8f892"}, "downloads": -1, "filename": "scrape-0.10.0.tar.gz", "has_sig": false, "md5_digest": "fc118eff268ebd78fdd890168474cfc2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27642, "upload_time": "2020-03-12T21:06:57", "upload_time_iso_8601": "2020-03-12T21:06:57.096724Z", "url": "https://files.pythonhosted.org/packages/71/c8/baa111f5d67173e6244a28ebd7d3bced87c249d3073d08c0323ba95c54dc/scrape-0.10.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:56:55 2020"}