{"info": {"author": "Tianyi Zhang, Zhiqiu Lin, Guandao Yang, Christopher De Sa", "author_email": "tz58@cornell.edu", "bugtrack_url": null, "classifiers": [], "description": "# QPyTorch\n[![Downloads](https://pepy.tech/badge/qtorch)](https://pepy.tech/project/qtorch) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n#### News:\n- Updated to version 0.2.0:\n  - **Bug fixed**: previously in our floating point quantization, numbers that are closer to 0 than the smallest \n  representable positive number rounded to the smallest rep positive number. Now we round to 0 or the smallest \n  representable number based on which one is the nearest\n  - **Different Behavior**: To be consistent with PyTorch [Issue #17443](https://github.com/pytorch/pytorch/pull/17443),\n  we round the nearest even now.\n  - We migrate to PyTorch 1.5.0. There are several changes in the C++ API of PyTorch. \n  This new version is not backward-compatible with older PyTorch. \n  - *Note*: if you are using CUDA 10.1, please install CUDA 10.1 Update 1 (or later version). There is a bug in \n  the first version of CUDA 10.1 which leads to compilation error.\n  - *Note*: previous users, please remove the cache in the pytorch extension directory. \n  For example, you can run this command `rm -rf /tmp/torch_extensions/quant_cuda /tmp/torch_extensions/quant_cuda` if \n  you are using the default directory for pytorch extensions.\n\n\nQPyTorch is a low-precision arithmetic simulation package in\nPyTorch. It is designed to support researches on low-precision machine\nlearning, especially for researches in low-precision training. \n\nNotably, QPyTorch supports quantizing different numbers in the training process\nwith customized low-precision formats. This eases the process of investigating\ndifferent precision settings and developing new deep learning architectures. More\nconcretely, QPyTorch implements fused kernels for quantization and integrates\nsmoothly with existing PyTorch kernels (e.g. matrix multiplication, convolution). \n\nRecent researches can be reimplemented easily through QPyTorch. We offer an\nexample replication of [WAGE](https://arxiv.org/abs/1802.04680) in a downstream\nrepo [WAGE](https://github.com/Tiiiger/QPyTorch/blob/master/examples/WAGE). We also provide a list\nof working examples under [Examples](#examples).\n\n*Note*: QPyTorch relies on PyTorch functions for the underlying computation,\nsuch as matrix multiplication. This means that the actual computation is done in\nsingle precision. Therefore, QPyTorch is not intended to be used to study the\nnumerical behavior of different **accumulation** strategies.\n\n*Note*: QPyTorch, as of now, have a different rounding mode with PyTorch. QPyTorch does round-away-from-zero while\nPyTorch does round-to-nearest-even. This will create a discrepancy between the PyTorch half-precision tensor \nand QPyTorch's simulation of half-precision numbers.\n\n## Installation\n\nrequirements:\n\n- Python >= 3.6\n- PyTorch >= 1.5.0\n- GCC >= 4.9 on linux\n- CUDA >= 10.1 on linux\n\nInstall other requirements by:\n```bash\npip install -r requirements.txt\n```\n\nInstall QPyTorch through pip:\n```bash\npip install qtorch\n```\n\nFor more details about compiler requirements, \nplease refer to [PyTorch extension tutorial](https://pytorch.org/tutorials/advanced/cpp_extension.html).\n\n## Documentation\nSee our [readthedocs](https://qpytorch.readthedocs.io/en/latest/) page.\n\n## Tutorials\n- [An overview of QPyTorch's features](https://github.com/Tiiiger/QPyTorch/blob/master/examples/tutorial/Functionality_Overview.ipynb)\n- [CIFAR-10 Low-Precision Training Tutorial](https://github.com/Tiiiger/QPyTorch/blob/master/examples/tutorial/CIFAR10_Low_Precision_Training_Example.ipynb)\n\n## Examples\n- Low-Precision VGGs and ResNets using fixed point, block floating point on CIFAR and ImageNet. [lp_train](https://github.com/Tiiiger/QPyTorch/blob/master/examples/lp_train)\n- Reproduction of WAGE in QPyTorch. [WAGE](https://github.com/Tiiiger/QPyTorch/blob/master/examples/WAGE)\n- Implementation (simulation) of 8-bit Floating Point Training in QPyTorch. [IBM8](https://github.com/Tiiiger/QPyTorch/blob/master/examples/IBM8)\n\n## Team\n* [Tianyi Zhang](https://scholar.google.com/citations?user=OI0HSa0AAAAJ&hl=en)\n* Zhiqiu Lin\n* [Guandao Yang](http://www.guandaoyang.com/)\n* [Christopher De Sa](http://www.cs.cornell.edu/~cdesa/)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "qtorch", "package_url": "https://pypi.org/project/qtorch/", "platform": "", "project_url": "https://pypi.org/project/qtorch/", "project_urls": {"Documentation": "https://qpytorch.readthedocs.io", "Source": "https://github.com/Tiiiger/QPyTorch/graphs/contributors"}, "release_url": "https://pypi.org/project/qtorch/0.2.0/", "requires_dist": ["torch (>=1.5.0)"], "requires_python": ">=3.6", "summary": "Low-Precision Arithmetic Simulation in Pytorch", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>QPyTorch</h1>\n<p><a href=\"https://pepy.tech/project/qtorch\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd271bfebecf56fd34532d59fd98eff759dbc8d3/68747470733a2f2f706570792e746563682f62616467652f71746f726368\"></a> <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a></p>\n<h4>News:</h4>\n<ul>\n<li>Updated to version 0.2.0:\n<ul>\n<li><strong>Bug fixed</strong>: previously in our floating point quantization, numbers that are closer to 0 than the smallest\nrepresentable positive number rounded to the smallest rep positive number. Now we round to 0 or the smallest\nrepresentable number based on which one is the nearest</li>\n<li><strong>Different Behavior</strong>: To be consistent with PyTorch <a href=\"https://github.com/pytorch/pytorch/pull/17443\" rel=\"nofollow\">Issue #17443</a>,\nwe round the nearest even now.</li>\n<li>We migrate to PyTorch 1.5.0. There are several changes in the C++ API of PyTorch.\nThis new version is not backward-compatible with older PyTorch.</li>\n<li><em>Note</em>: if you are using CUDA 10.1, please install CUDA 10.1 Update 1 (or later version). There is a bug in\nthe first version of CUDA 10.1 which leads to compilation error.</li>\n<li><em>Note</em>: previous users, please remove the cache in the pytorch extension directory.\nFor example, you can run this command <code>rm -rf /tmp/torch_extensions/quant_cuda /tmp/torch_extensions/quant_cuda</code> if\nyou are using the default directory for pytorch extensions.</li>\n</ul>\n</li>\n</ul>\n<p>QPyTorch is a low-precision arithmetic simulation package in\nPyTorch. It is designed to support researches on low-precision machine\nlearning, especially for researches in low-precision training.</p>\n<p>Notably, QPyTorch supports quantizing different numbers in the training process\nwith customized low-precision formats. This eases the process of investigating\ndifferent precision settings and developing new deep learning architectures. More\nconcretely, QPyTorch implements fused kernels for quantization and integrates\nsmoothly with existing PyTorch kernels (e.g. matrix multiplication, convolution).</p>\n<p>Recent researches can be reimplemented easily through QPyTorch. We offer an\nexample replication of <a href=\"https://arxiv.org/abs/1802.04680\" rel=\"nofollow\">WAGE</a> in a downstream\nrepo <a href=\"https://github.com/Tiiiger/QPyTorch/blob/master/examples/WAGE\" rel=\"nofollow\">WAGE</a>. We also provide a list\nof working examples under <a href=\"#examples\" rel=\"nofollow\">Examples</a>.</p>\n<p><em>Note</em>: QPyTorch relies on PyTorch functions for the underlying computation,\nsuch as matrix multiplication. This means that the actual computation is done in\nsingle precision. Therefore, QPyTorch is not intended to be used to study the\nnumerical behavior of different <strong>accumulation</strong> strategies.</p>\n<p><em>Note</em>: QPyTorch, as of now, have a different rounding mode with PyTorch. QPyTorch does round-away-from-zero while\nPyTorch does round-to-nearest-even. This will create a discrepancy between the PyTorch half-precision tensor\nand QPyTorch's simulation of half-precision numbers.</p>\n<h2>Installation</h2>\n<p>requirements:</p>\n<ul>\n<li>Python &gt;= 3.6</li>\n<li>PyTorch &gt;= 1.5.0</li>\n<li>GCC &gt;= 4.9 on linux</li>\n<li>CUDA &gt;= 10.1 on linux</li>\n</ul>\n<p>Install other requirements by:</p>\n<pre>pip install -r requirements.txt\n</pre>\n<p>Install QPyTorch through pip:</p>\n<pre>pip install qtorch\n</pre>\n<p>For more details about compiler requirements,\nplease refer to <a href=\"https://pytorch.org/tutorials/advanced/cpp_extension.html\" rel=\"nofollow\">PyTorch extension tutorial</a>.</p>\n<h2>Documentation</h2>\n<p>See our <a href=\"https://qpytorch.readthedocs.io/en/latest/\" rel=\"nofollow\">readthedocs</a> page.</p>\n<h2>Tutorials</h2>\n<ul>\n<li><a href=\"https://github.com/Tiiiger/QPyTorch/blob/master/examples/tutorial/Functionality_Overview.ipynb\" rel=\"nofollow\">An overview of QPyTorch's features</a></li>\n<li><a href=\"https://github.com/Tiiiger/QPyTorch/blob/master/examples/tutorial/CIFAR10_Low_Precision_Training_Example.ipynb\" rel=\"nofollow\">CIFAR-10 Low-Precision Training Tutorial</a></li>\n</ul>\n<h2>Examples</h2>\n<ul>\n<li>Low-Precision VGGs and ResNets using fixed point, block floating point on CIFAR and ImageNet. <a href=\"https://github.com/Tiiiger/QPyTorch/blob/master/examples/lp_train\" rel=\"nofollow\">lp_train</a></li>\n<li>Reproduction of WAGE in QPyTorch. <a href=\"https://github.com/Tiiiger/QPyTorch/blob/master/examples/WAGE\" rel=\"nofollow\">WAGE</a></li>\n<li>Implementation (simulation) of 8-bit Floating Point Training in QPyTorch. <a href=\"https://github.com/Tiiiger/QPyTorch/blob/master/examples/IBM8\" rel=\"nofollow\">IBM8</a></li>\n</ul>\n<h2>Team</h2>\n<ul>\n<li><a href=\"https://scholar.google.com/citations?user=OI0HSa0AAAAJ&amp;hl=en\" rel=\"nofollow\">Tianyi Zhang</a></li>\n<li>Zhiqiu Lin</li>\n<li><a href=\"http://www.guandaoyang.com/\" rel=\"nofollow\">Guandao Yang</a></li>\n<li><a href=\"http://www.cs.cornell.edu/%7Ecdesa/\" rel=\"nofollow\">Christopher De Sa</a></li>\n</ul>\n\n          </div>"}, "last_serial": 7106963, "releases": {"0.0.0": [{"comment_text": "", "digests": {"md5": "e67083a17e040e45c06fcc0d58f39f4e", "sha256": "81f10f8a4ed191c4b5b3d745f772043caf023b30418da290151a654ed0e384e0"}, "downloads": -1, "filename": "qtorch-0.0.0-py3.6.egg", "has_sig": false, "md5_digest": "e67083a17e040e45c06fcc0d58f39f4e", "packagetype": "bdist_egg", "python_version": "3.6", "requires_python": null, "size": 8537, "upload_time": "2019-02-25T05:53:12", "upload_time_iso_8601": "2019-02-25T05:53:12.003399Z", "url": "https://files.pythonhosted.org/packages/7f/4d/7c57bff319bde55c124ac8e4edea0370acd7bfec87b93717e4f12d1819ba/qtorch-0.0.0-py3.6.egg", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "d6b9775242b21362011dc5f5c8316373", "sha256": "b8b3cf33d970804e112b7ff22187d99539ad8872e97231a105c2cc8b476941b9"}, "downloads": -1, "filename": "qtorch-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d6b9775242b21362011dc5f5c8316373", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 13708, "upload_time": "2019-04-24T20:41:51", "upload_time_iso_8601": "2019-04-24T20:41:51.946780Z", "url": "https://files.pythonhosted.org/packages/fd/09/c72bfce8f7b58ba65aaf2e1804297554070d0cc793ec612a46e244180b07/qtorch-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d81b16984501b92ecaacb9857283b409", "sha256": "d75d156d580167fbeb33d9eec3504b5e494b80384284c02dca02dc9dc8d7c47d"}, "downloads": -1, "filename": "qtorch-0.1.0.tar.gz", "has_sig": false, "md5_digest": "d81b16984501b92ecaacb9857283b409", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 2252191, "upload_time": "2019-04-24T20:41:54", "upload_time_iso_8601": "2019-04-24T20:41:54.318779Z", "url": "https://files.pythonhosted.org/packages/05/6e/f3cd17b36b0ddcbf9fcda561eade49f469b1692c77f9397963770346b076/qtorch-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "ba155b56883bb2935786b343a5e9b0c5", "sha256": "ca3ff9430234811347c5e75756ea6688e9e113e78186c5b9f4c6c7936483d025"}, "downloads": -1, "filename": "qtorch-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "ba155b56883bb2935786b343a5e9b0c5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22871, "upload_time": "2019-05-09T22:39:42", "upload_time_iso_8601": "2019-05-09T22:39:42.541342Z", "url": "https://files.pythonhosted.org/packages/ba/7c/bbf38c5760b9ce3cf7ade83014cf1b29af274ef1fc6ccadd82807bcb2d87/qtorch-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "404c755c126ad8b16c094032c651cc4b", "sha256": "602981f82daa7f26e8fc478c5b16d994e8c9778ab643ca03d05c59978df01c17"}, "downloads": -1, "filename": "qtorch-0.1.1.tar.gz", "has_sig": false, "md5_digest": "404c755c126ad8b16c094032c651cc4b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 18524, "upload_time": "2019-05-09T22:39:43", "upload_time_iso_8601": "2019-05-09T22:39:43.991719Z", "url": "https://files.pythonhosted.org/packages/2f/04/6be3be6b90a8c7593bef51062681498063793522dd0b787df4b674884f9a/qtorch-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "780cca3995bef534ffb6e66966de1aa2", "sha256": "975e24c2d032cb6e20af36a7c0e5f846f40d915280a72fde40db6724faaf1d23"}, "downloads": -1, "filename": "qtorch-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "780cca3995bef534ffb6e66966de1aa2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22787, "upload_time": "2020-04-26T21:16:01", "upload_time_iso_8601": "2020-04-26T21:16:01.573398Z", "url": "https://files.pythonhosted.org/packages/60/0e/93736b65669268f94f0d76edf72b49b949f9778fcd0e0098619ae08439ad/qtorch-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65f9b5c5a7a5bef32b78463857d9b060", "sha256": "bfe4f75bd2c816f3bc3678826805bb0cad770766fac88649ba471ad994bd5622"}, "downloads": -1, "filename": "qtorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "65f9b5c5a7a5bef32b78463857d9b060", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 19974, "upload_time": "2020-04-26T21:16:02", "upload_time_iso_8601": "2020-04-26T21:16:02.548985Z", "url": "https://files.pythonhosted.org/packages/88/ce/3eb0f2c8f3c55de4c0a8b9c0520372b364a9d55b9f9648da40f6cdbac77a/qtorch-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "780cca3995bef534ffb6e66966de1aa2", "sha256": "975e24c2d032cb6e20af36a7c0e5f846f40d915280a72fde40db6724faaf1d23"}, "downloads": -1, "filename": "qtorch-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "780cca3995bef534ffb6e66966de1aa2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22787, "upload_time": "2020-04-26T21:16:01", "upload_time_iso_8601": "2020-04-26T21:16:01.573398Z", "url": "https://files.pythonhosted.org/packages/60/0e/93736b65669268f94f0d76edf72b49b949f9778fcd0e0098619ae08439ad/qtorch-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "65f9b5c5a7a5bef32b78463857d9b060", "sha256": "bfe4f75bd2c816f3bc3678826805bb0cad770766fac88649ba471ad994bd5622"}, "downloads": -1, "filename": "qtorch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "65f9b5c5a7a5bef32b78463857d9b060", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 19974, "upload_time": "2020-04-26T21:16:02", "upload_time_iso_8601": "2020-04-26T21:16:02.548985Z", "url": "https://files.pythonhosted.org/packages/88/ce/3eb0f2c8f3c55de4c0a8b9c0520372b364a9d55b9f9648da40f6cdbac77a/qtorch-0.2.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:09:07 2020"}