{"info": {"author": "Ashwin Vinod", "author_email": "ashwinvinodsa@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "![logo](docs/images/logo(1).jpg)\n\n# Visionlib\n![Upload Python Package](https://github.com/ashwinvin/Visionlib/workflows/Upload%20Python%20Package/badge.svg?branch=v1.3.0)\n\nA simple high level API made for assisting in CV-related projects.\n\n## Features\n\n- Track faces using\n  - MTCNN module\n  - Dlib hog Based detector\n  - Opencv Haar cascades\n  - Dnn based model\n- Predict Gender\n- Detect Objects\n  - Yolo v3\n  - tiny-yolo\n\n### Installation\n\n**Note:** Windows compatibility is not tested\n\n#### Dependencies\n\n`sudo apt-get install build-essential cmake pkg-config`\n\n`sudo apt-get install libx11-dev libatlas-base-dev`\n\n`sudo apt-get install libgtk-3-dev libboost-python-dev`\n\nThis should install Dependencies required by dlib.\n\n`pip install visionlib`\n\nThis will install visionlib.\n\n##### Optional\n\nIf You want to install from source\n`git clone https://github.com/ashwinvin/Visionlib.git`\n\n`cd visionlib`\n\n`pip install .`\n\n### Face Detection\n\nDetecting face in an image is easy . This will return the image with bounding box and box coordinates.\n\n`from visionlib.face.detection import FDetector`\n\n`detector = FDetector()`\n\n`detector.detect_face(img, show=True)`\n\nThis would detect face and display it automatically.\n\n`detector.set_detector(\"mtcnn\")`\n\nDon't like the default detector?, change it like this.\n\n#### Examples\n\n![Detection](docs/images/face_detected.jpg)\n\n![Detection](docs/images/face_detected_group.jpg)\n\n### Gender Detection\n\nOnce face is detected, it can be passed on to detect_gender() function to recognise gender. It will return the labels (man, woman) and associated probabilities. Like this\n\n```python\nfrom visionlib.gender.detection import GDetector\ndetector = GDetector()\npred, confidence = detector.detect_gender(img)\n```\n\n\n\n##### Example\n\n![Gender Detection](docs/images/gender_detected_single.jpg)\n\n### Object Detection\n\nDetecting common objects in the scene is enabled through a single function call detect_objects(). It will return the labelled image for the detected objects in the image. By default it uses yolo v3-tiny model.\n\n```python\nfrom visionlib.object.detection import Detection\nimport cv2\ndetector = Detection()\nd_img = detector.detect_objects(img)\n```\n\n#### Example\n\n![object Detection](docs/images/object_detected_objects.jpg)\n\n### Object Classification\n\nYou can also do object classification with the `CDetector` class.\n\n- Currently it has three detector's\n  - Inception v3\n  - VGG 16\n  - Xception\n\n```python\nfrom visionlib.object.classifier.detection import CDetector\npredictions = detector.predict(img)\n```\n\n#### Example\n\n![mug](docs/images/mug.jpg)\n\n##### Output\n\n```\nDetected coffee_mug with confidence 73.33419919013977\nDetected cup with confidence 8.287159353494644\nDetected pitcher with confidence 3.0803868547081947\nDetected coffeepot with confidence 1.2160349637269974\nDetected water_jug with confidence 0.8919732645153999\n\n```\n\n###  Keypoint Detection\n\nYou can pass a detected face into the keypoint detection and get all the detected keypoints.\n- Currently it has two detector's :\n\t- Dlib's 68 keypoint shape detector\n\t- MTCNN's 5 point detector\n\n\n```python\nfrom visionlib.keypoints.detection import KDetector\nkdetector = KDetector()\npoints = kdetector.detect_keypoints(img, rects=boxes)\n```\n\n#### Example\n\n![keypoint detected](docs/images/keypoint_detected.jpg)\n\n#### GPU support\n\nYou can leverage your gpu's power by enabling it like this.\n\n**Face Detection**\n`detector.detect_face(img, show=True, enable_gpu=True)`\n\n**Object Detection**\n`detector.detect_objects(img, enable_gpu=True)`\n\n**Gender Detection**\n`detector.detect_gender(img, enable_gpu=True)`\n\n\n#### Loading videos from YouTube\n\nIf you want load videos from YouTube, you can use the  `load_video()`function.\n\n```\nfrom visionlib.utils.webutils import web\nweb_util = web()\nvideo = web.load_video(url)\n```\n\nYou can now pass the video to any function. It does contain the video but it instead grabs the source URL of the video\n\n#### Documentation\n\nComplete Documentation can be found on \nhttps://ashwinvin.github.io/Visionlib/\n\nFor example check the examples directory\n\n\nNone of the images in the this repository are owned by me.\nThey belong to there respective owners.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/ashwinvin/Visionlib/archive/v1.4.5.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ashwinvin/Visionlib", "keywords": "Deep learning,Vision,cv", "license": "", "maintainer": "", "maintainer_email": "", "name": "visionlib", "package_url": "https://pypi.org/project/visionlib/", "platform": "", "project_url": "https://pypi.org/project/visionlib/", "project_urls": {"Download": "https://github.com/ashwinvin/Visionlib/archive/v1.4.5.tar.gz", "Homepage": "https://github.com/ashwinvin/Visionlib"}, "release_url": "https://pypi.org/project/visionlib/1.4.5/", "requires_dist": ["mtcnn", "opencv-python", "dlib", "wget", "numpy", "pafy", "youtube-dl"], "requires_python": ">=3.6", "summary": "A simple, easy to use and customizeble cv library", "version": "1.4.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"logo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/68624b32ee5047d31537bc96134d0cbdb72b74ec/646f63732f696d616765732f6c6f676f2831292e6a7067\"></p>\n<h1>Visionlib</h1>\n<p><img alt=\"Upload Python Package\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/69eee75508f76e979417880bbe9d9c9290bf5639/68747470733a2f2f6769746875622e636f6d2f61736877696e76696e2f566973696f6e6c69622f776f726b666c6f77732f55706c6f6164253230507974686f6e2532305061636b6167652f62616467652e7376673f6272616e63683d76312e332e30\"></p>\n<p>A simple high level API made for assisting in CV-related projects.</p>\n<h2>Features</h2>\n<ul>\n<li>Track faces using\n<ul>\n<li>MTCNN module</li>\n<li>Dlib hog Based detector</li>\n<li>Opencv Haar cascades</li>\n<li>Dnn based model</li>\n</ul>\n</li>\n<li>Predict Gender</li>\n<li>Detect Objects\n<ul>\n<li>Yolo v3</li>\n<li>tiny-yolo</li>\n</ul>\n</li>\n</ul>\n<h3>Installation</h3>\n<p><strong>Note:</strong> Windows compatibility is not tested</p>\n<h4>Dependencies</h4>\n<p><code>sudo apt-get install build-essential cmake pkg-config</code></p>\n<p><code>sudo apt-get install libx11-dev libatlas-base-dev</code></p>\n<p><code>sudo apt-get install libgtk-3-dev libboost-python-dev</code></p>\n<p>This should install Dependencies required by dlib.</p>\n<p><code>pip install visionlib</code></p>\n<p>This will install visionlib.</p>\n<h5>Optional</h5>\n<p>If You want to install from source\n<code>git clone https://github.com/ashwinvin/Visionlib.git</code></p>\n<p><code>cd visionlib</code></p>\n<p><code>pip install .</code></p>\n<h3>Face Detection</h3>\n<p>Detecting face in an image is easy . This will return the image with bounding box and box coordinates.</p>\n<p><code>from visionlib.face.detection import FDetector</code></p>\n<p><code>detector = FDetector()</code></p>\n<p><code>detector.detect_face(img, show=True)</code></p>\n<p>This would detect face and display it automatically.</p>\n<p><code>detector.set_detector(\"mtcnn\")</code></p>\n<p>Don't like the default detector?, change it like this.</p>\n<h4>Examples</h4>\n<p><img alt=\"Detection\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f60a705adb9cfd333775240436f9e3420a10894c/646f63732f696d616765732f666163655f64657465637465642e6a7067\"></p>\n<p><img alt=\"Detection\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b6019660f7337b05403576676e415ddd1778aaf4/646f63732f696d616765732f666163655f64657465637465645f67726f75702e6a7067\"></p>\n<h3>Gender Detection</h3>\n<p>Once face is detected, it can be passed on to detect_gender() function to recognise gender. It will return the labels (man, woman) and associated probabilities. Like this</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">visionlib.gender.detection</span> <span class=\"kn\">import</span> <span class=\"n\">GDetector</span>\n<span class=\"n\">detector</span> <span class=\"o\">=</span> <span class=\"n\">GDetector</span><span class=\"p\">()</span>\n<span class=\"n\">pred</span><span class=\"p\">,</span> <span class=\"n\">confidence</span> <span class=\"o\">=</span> <span class=\"n\">detector</span><span class=\"o\">.</span><span class=\"n\">detect_gender</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n</pre>\n<h5>Example</h5>\n<p><img alt=\"Gender Detection\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/82592b78475e9e41e605d8223adbf827cb2a5300/646f63732f696d616765732f67656e6465725f64657465637465645f73696e676c652e6a7067\"></p>\n<h3>Object Detection</h3>\n<p>Detecting common objects in the scene is enabled through a single function call detect_objects(). It will return the labelled image for the detected objects in the image. By default it uses yolo v3-tiny model.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">visionlib.object.detection</span> <span class=\"kn\">import</span> <span class=\"n\">Detection</span>\n<span class=\"kn\">import</span> <span class=\"nn\">cv2</span>\n<span class=\"n\">detector</span> <span class=\"o\">=</span> <span class=\"n\">Detection</span><span class=\"p\">()</span>\n<span class=\"n\">d_img</span> <span class=\"o\">=</span> <span class=\"n\">detector</span><span class=\"o\">.</span><span class=\"n\">detect_objects</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n</pre>\n<h4>Example</h4>\n<p><img alt=\"object Detection\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bd7c407929c5394491cc0001f82eec36f384e01d/646f63732f696d616765732f6f626a6563745f64657465637465645f6f626a656374732e6a7067\"></p>\n<h3>Object Classification</h3>\n<p>You can also do object classification with the <code>CDetector</code> class.</p>\n<ul>\n<li>Currently it has three detector's\n<ul>\n<li>Inception v3</li>\n<li>VGG 16</li>\n<li>Xception</li>\n</ul>\n</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">visionlib.object.classifier.detection</span> <span class=\"kn\">import</span> <span class=\"n\">CDetector</span>\n<span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"n\">detector</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n</pre>\n<h4>Example</h4>\n<p><img alt=\"mug\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5396ee82c67ae845363b3c444c17aee3b57f5b5b/646f63732f696d616765732f6d75672e6a7067\"></p>\n<h5>Output</h5>\n<pre><code>Detected coffee_mug with confidence 73.33419919013977\nDetected cup with confidence 8.287159353494644\nDetected pitcher with confidence 3.0803868547081947\nDetected coffeepot with confidence 1.2160349637269974\nDetected water_jug with confidence 0.8919732645153999\n\n</code></pre>\n<h3>Keypoint Detection</h3>\n<p>You can pass a detected face into the keypoint detection and get all the detected keypoints.</p>\n<ul>\n<li>Currently it has two detector's :\n<ul>\n<li>Dlib's 68 keypoint shape detector</li>\n<li>MTCNN's 5 point detector</li>\n</ul>\n</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">visionlib.keypoints.detection</span> <span class=\"kn\">import</span> <span class=\"n\">KDetector</span>\n<span class=\"n\">kdetector</span> <span class=\"o\">=</span> <span class=\"n\">KDetector</span><span class=\"p\">()</span>\n<span class=\"n\">points</span> <span class=\"o\">=</span> <span class=\"n\">kdetector</span><span class=\"o\">.</span><span class=\"n\">detect_keypoints</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">,</span> <span class=\"n\">rects</span><span class=\"o\">=</span><span class=\"n\">boxes</span><span class=\"p\">)</span>\n</pre>\n<h4>Example</h4>\n<p><img alt=\"keypoint detected\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/34f6db14c880281a55af03e90cb91b7734c128a5/646f63732f696d616765732f6b6579706f696e745f64657465637465642e6a7067\"></p>\n<h4>GPU support</h4>\n<p>You can leverage your gpu's power by enabling it like this.</p>\n<p><strong>Face Detection</strong>\n<code>detector.detect_face(img, show=True, enable_gpu=True)</code></p>\n<p><strong>Object Detection</strong>\n<code>detector.detect_objects(img, enable_gpu=True)</code></p>\n<p><strong>Gender Detection</strong>\n<code>detector.detect_gender(img, enable_gpu=True)</code></p>\n<h4>Loading videos from YouTube</h4>\n<p>If you want load videos from YouTube, you can use the  <code>load_video()</code>function.</p>\n<pre><code>from visionlib.utils.webutils import web\nweb_util = web()\nvideo = web.load_video(url)\n</code></pre>\n<p>You can now pass the video to any function. It does contain the video but it instead grabs the source URL of the video</p>\n<h4>Documentation</h4>\n<p>Complete Documentation can be found on\n<a href=\"https://ashwinvin.github.io/Visionlib/\" rel=\"nofollow\">https://ashwinvin.github.io/Visionlib/</a></p>\n<p>For example check the examples directory</p>\n<p>None of the images in the this repository are owned by me.\nThey belong to there respective owners.</p>\n\n          </div>"}, "last_serial": 7150505, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "1b0bb8cd1cbb4497f366b3f4ce3e75f8", "sha256": "1736bec721e4472d3c852b04ef55f33a1d887bf6676d1800600851584b448fbc"}, "downloads": -1, "filename": "visionlib-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1b0bb8cd1cbb4497f366b3f4ce3e75f8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10049225, "upload_time": "2020-04-25T20:00:38", "upload_time_iso_8601": "2020-04-25T20:00:38.982500Z", "url": "https://files.pythonhosted.org/packages/cf/89/8b08f92db976a620b0d2b9e130e59cabc6ea32199cb8a387b224b56346fb/visionlib-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9d99988a3bf7b61d94c879fb474df966", "sha256": "2402b8b73436de36fa09889fa3564ec9b55726fec1125260481405b36e98e65e"}, "downloads": -1, "filename": "visionlib-1.0.0.tar.gz", "has_sig": false, "md5_digest": "9d99988a3bf7b61d94c879fb474df966", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10045519, "upload_time": "2020-04-25T20:01:08", "upload_time_iso_8601": "2020-04-25T20:01:08.047922Z", "url": "https://files.pythonhosted.org/packages/96/be/34b578ee26bcfd5fa2b64e7f9e7c52babdb395a725994364fe71cdd5d0a2/visionlib-1.0.0.tar.gz", "yanked": false}], "1.2.0": [{"comment_text": "", "digests": {"md5": "34888abdd5b0e9537d1c9517e37907a3", "sha256": "7e0fec8c9336cf478d1a0690cd9270bca879e263c7e35149347f3bfe333736d0"}, "downloads": -1, "filename": "visionlib-1.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "34888abdd5b0e9537d1c9517e37907a3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10050546, "upload_time": "2020-04-26T19:52:27", "upload_time_iso_8601": "2020-04-26T19:52:27.717017Z", "url": "https://files.pythonhosted.org/packages/d1/48/6a0a5270ecd67e422803e071f182415189771c717a58c9439a7eda91fb3c/visionlib-1.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b94e40e363d0b717753fbf9893432e52", "sha256": "0bafd5c0d1bf16587f6fcd3d6970f1795b2e492419b57099ff8907fbf4208428"}, "downloads": -1, "filename": "visionlib-1.2.0.tar.gz", "has_sig": false, "md5_digest": "b94e40e363d0b717753fbf9893432e52", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10046861, "upload_time": "2020-04-26T19:52:54", "upload_time_iso_8601": "2020-04-26T19:52:54.975388Z", "url": "https://files.pythonhosted.org/packages/2b/bc/bb6677f8636f76ef3e99f1d85949bb771c5ccf53752b249ef6f91a4eb37b/visionlib-1.2.0.tar.gz", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "8344cee0d32190e08d39b6c5dc327ab3", "sha256": "3321326aa725ed264b538e4cc6a82b3e54967a947d6e7098ead603e098712673"}, "downloads": -1, "filename": "visionlib-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "8344cee0d32190e08d39b6c5dc327ab3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10051448, "upload_time": "2020-04-27T19:51:49", "upload_time_iso_8601": "2020-04-27T19:51:49.080230Z", "url": "https://files.pythonhosted.org/packages/74/f2/56a4395b7d7398e99e3748bc13fbe7bf7f5937962acc378e92c2541efbca/visionlib-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4459554114c325dc9bc28d74f9e511e0", "sha256": "44b9b7378a917e51b7d43415fb6c45e6e1a8a8f4117275640abd944f1a8b4991"}, "downloads": -1, "filename": "visionlib-1.3.0.tar.gz", "has_sig": false, "md5_digest": "4459554114c325dc9bc28d74f9e511e0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10049971, "upload_time": "2020-04-27T19:51:50", "upload_time_iso_8601": "2020-04-27T19:51:50.952705Z", "url": "https://files.pythonhosted.org/packages/2b/99/435643aa396982747aa521db22c4ef9abe61f5daeb4f909e05fac7537645/visionlib-1.3.0.tar.gz", "yanked": false}], "1.4.5": [{"comment_text": "", "digests": {"md5": "1d2b8a8a45e37f00f37af5e2d6247597", "sha256": "d292063a0b4a3bfba4184596a97ca10ce24b0ebdc6866c58b2cd9e28f4b9b0c3"}, "downloads": -1, "filename": "visionlib-1.4.5-py3-none-any.whl", "has_sig": false, "md5_digest": "1d2b8a8a45e37f00f37af5e2d6247597", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10059838, "upload_time": "2020-05-02T09:29:41", "upload_time_iso_8601": "2020-05-02T09:29:41.481702Z", "url": "https://files.pythonhosted.org/packages/c6/21/200dc0b4ae5993bab4258d61b3a07d01f22d541dca2c78fdbba64a677700/visionlib-1.4.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c4796abd7078a13557a80cbb35e0fcf3", "sha256": "b85d019f4ef8be1746a9478a23f778b20010da8f53b3149be0e8781ba7383528"}, "downloads": -1, "filename": "visionlib-1.4.5.tar.gz", "has_sig": false, "md5_digest": "c4796abd7078a13557a80cbb35e0fcf3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10054710, "upload_time": "2020-05-02T09:29:43", "upload_time_iso_8601": "2020-05-02T09:29:43.403792Z", "url": "https://files.pythonhosted.org/packages/fe/23/0d0982e836bd1d0f05624a6a0c7e4410f96a4927a542cc96ab98663caa7c/visionlib-1.4.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1d2b8a8a45e37f00f37af5e2d6247597", "sha256": "d292063a0b4a3bfba4184596a97ca10ce24b0ebdc6866c58b2cd9e28f4b9b0c3"}, "downloads": -1, "filename": "visionlib-1.4.5-py3-none-any.whl", "has_sig": false, "md5_digest": "1d2b8a8a45e37f00f37af5e2d6247597", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10059838, "upload_time": "2020-05-02T09:29:41", "upload_time_iso_8601": "2020-05-02T09:29:41.481702Z", "url": "https://files.pythonhosted.org/packages/c6/21/200dc0b4ae5993bab4258d61b3a07d01f22d541dca2c78fdbba64a677700/visionlib-1.4.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c4796abd7078a13557a80cbb35e0fcf3", "sha256": "b85d019f4ef8be1746a9478a23f778b20010da8f53b3149be0e8781ba7383528"}, "downloads": -1, "filename": "visionlib-1.4.5.tar.gz", "has_sig": false, "md5_digest": "c4796abd7078a13557a80cbb35e0fcf3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10054710, "upload_time": "2020-05-02T09:29:43", "upload_time_iso_8601": "2020-05-02T09:29:43.403792Z", "url": "https://files.pythonhosted.org/packages/fe/23/0d0982e836bd1d0f05624a6a0c7e4410f96a4927a542cc96ab98663caa7c/visionlib-1.4.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:35:17 2020"}