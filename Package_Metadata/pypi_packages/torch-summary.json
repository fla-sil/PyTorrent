{"info": {"author": "Tyler Yep @tyleryep", "author_email": "tyep10@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# torch-summary\n[![Python 3.6+](https://img.shields.io/badge/python-3.6+-blue.svg)](https://www.python.org/downloads/release/python-360/)\n[![PyPI version](https://badge.fury.io/py/torch-summary.svg)](https://badge.fury.io/py/torch-summary)\n[![GitHub license](https://img.shields.io/github/license/TylerYep/torch-summary)](https://github.com/TylerYep/torch-summary/blob/master/LICENSE)\n\nKeras has a neat API to view the visualization of the model which is very helpful while debugging your network. In this project, we attempt to do the same in PyTorch. The goal is to provide information complementary to what is provided by `print(your_model)` in PyTorch.\n\nThis is a rewritten version of the original torchsummary and torchsummaryX projects by @sksq96 and @nmhkahn.\nThere are quite a few pull requests on the original project (which hasn't been updated in over a year), so I decided to take a stab at improving and consolidating some of the features.\n\n**This version now supports:**\n- RNNs, LSTMs, and other recursive layers\n- Branching output to explore model layers using specified depths\n- Returns ModelStatistics object to access summary data\n- Configurable columns of returned data\n\n**Other features:**\n- Verbose mode to show specific weights and bias layers\n- Accepts either input data or simply the input shape to work!\n- Customizable widths and custom batch dimension.\n- More comprehensive testing using pytest\n\n\n# Usage\n`pip install torch-summary`\n\nor\n\n`git clone https://github.com/tyleryep/torch-summary.git`\n\n\n```python\nfrom torchsummary import summary\nsummary(your_model, input_data=(C, H, W))\n```\n\n# Documentation\n```python\n\"\"\"\nSummarize the given PyTorch model. Summarized information includes:\n    1) output shape,\n    2) kernel shape,\n    3) number of the parameters\n    4) operations (Mult-Adds)\nArgs:\n    model (Module): Model to summarize\n    input_data (Sequence of Sizes or Tensors):\n        Example input tensor of the model (dtypes inferred from model input).\n        - OR -\n        Shape of input data as a List/Tuple/torch.Size (dtypes must match model input,\n        default is FloatTensors). NOTE: For scalar parameters, use torch.Size([]).\n    branching (bool): Whether to use the branching layout for the printed output.\n    depth (int): number of nested layers to traverse (e.g. Sequentials)\n    verbose (int):\n        0 (quiet): No output\n        1 (default): Print model summary\n        2 (verbose): Show weight and bias layers in full detail\n    col_names (List): specify which columns to show in the output. Currently supported:\n        ['output_size', 'num_params', 'kernel_size', 'mult_adds']\n    col_width (int): width of each column\n    dtypes (List or None): for multiple inputs or args, must specify the size of both inputs.\n        You must also specify the types of each parameter here.\n    batch_dim (int): batch_dimension of input data\n    device (torch.Device): If specified, uses this torch device for the model and model's input.\n        Else defaults to torch.cuda.is_available().\n    args, kwargs: Other arguments used in `model.forward` function.\n\"\"\"\n```\n\n\n# Examples\n## Get Model Summary as String\n```python\nfrom torchsummary import summary\n\nmodel_stats = summary(your_model, input_data=(C, H, W), verbose=0)\nsummary_str = str(model_stats)\n```\n\n## CNN for MNIST\n\n```python\nclass CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d(0.3)\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n\nmodel = CNN()\nsummary(model, (1, 28, 28))\n```\n\n```\n------------------------------------------------------------------------------------------\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n\u251c\u2500Conv2d: 1-1                            [-1, 10, 24, 24]          260\n\u251c\u2500Conv2d: 1-2                            [-1, 20, 8, 8]            5,020\n\u251c\u2500Dropout2d: 1-3                         [-1, 20, 8, 8]            --\n\u251c\u2500Linear: 1-4                            [-1, 50]                  16,050\n\u251c\u2500Linear: 1-5                            [-1, 10]                  510\n==========================================================================================\nTotal params: 21,840\nTrainable params: 21,840\nNon-trainable params: 0\n------------------------------------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.05\nParams size (MB): 0.08\nEstimated Total Size (MB): 0.14\n------------------------------------------------------------------------------------------\n```\n\n\n## Multiple Inputs w/ Different Data Types\n\n```python\nclass MultipleInputNetDifferentDtypes(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1a = nn.Linear(300, 50)\n        self.fc1b = nn.Linear(50, 10)\n\n        self.fc2a = nn.Linear(300, 50)\n        self.fc2b = nn.Linear(50, 10)\n\n    def forward(self, x1, x2):\n        x1 = F.relu(self.fc1a(x1))\n        x1 = self.fc1b(x1)\n        x2 = x2.type(torch.float)\n        x2 = F.relu(self.fc2a(x2))\n        x2 = self.fc2b(x2)\n        x = torch.cat((x1, x2), 0)\n        return F.log_softmax(x, dim=1)\n\n\nsummary(model, [(1, 300), (1, 300)], dtypes=[torch.float, torch.long])\n```\nAlternatively, you can also pass in the input_data itself, and\ntorchsummary will automatically infer the data types.\n\n```python\ninput_data = torch.randn(1, 300)\nother_input_data = torch.randn(1, 300).long()\nmodel = MultipleInputNetDifferentDtypes()\n\nsummary(model, input_data, other_input_data, ...)\n```\n\n## Explore Different Configurations\n```python\nclass LSTMNet(nn.Module):\n    def __init__(self, vocab_size=20, embed_dim=300, hidden_dim=512, num_layers=2):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.encoder = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers)\n        self.decoder = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x):\n        embed = self.embedding(x)\n        out, hidden = self.encoder(embed)\n        out = self.decoder(out)\n        out = out.view(-1, out.size(2))\n        return out, hidden\n\nsummary(\n    LSTMNet(),\n    (100,),\n    dtypes=[torch.long],\n    branching=False,\n    verbose=2,\n    col_width=16,\n    col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n)\n```\n\n```\n--------------------------------------------------------------------------------------------------------\nLayer (type:depth-idx)         Kernel Shape         Output Shape         Param #          Mult-Adds\n========================================================================================================\nEmbedding: 1-1                 [300, 20]            [-1, 100, 300]       6,000            6,000\nLSTM: 1-2                       --                  [2, 100, 512]        3,768,320        3,760,128\n  weight_ih_l0                 [2048, 300]\n  weight_hh_l0                 [2048, 512]\n  weight_ih_l1                 [2048, 512]\n  weight_hh_l1                 [2048, 512]\nLinear: 1-3                    [512, 20]            [-1, 100, 20]        10,260           10,240\n========================================================================================================\nTotal params: 3,784,580\nTrainable params: 3,784,580\nNon-trainable params: 0\n--------------------------------------------------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 1.03\nParams size (MB): 14.44\nEstimated Total Size (MB): 15.46\n--------------------------------------------------------------------------------------------------------\n```\n\n\n## ResNet\n\n```python\nimport torchvision\n\nmodel = torchvision.models.resnet50()\nsummary(model, (3, 224, 224), depth=3)\n```\n\n\n```\n------------------------------------------------------------------------------------------\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n\u251c\u2500Conv2d: 1-1                            [-1, 64, 112, 112]        9,408\n\u251c\u2500BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n\u251c\u2500ReLU: 1-3                              [-1, 64, 112, 112]        --\n\u251c\u2500MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n\u251c\u2500Sequential: 1-5                        [-1, 256, 56, 56]         --\n|    \u2514\u2500Bottleneck: 2-1                   [-1, 256, 56, 56]         --\n|    |    \u2514\u2500Conv2d: 3-1                  [-1, 64, 56, 56]          4,096\n|    |    \u2514\u2500BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n|    |    \u2514\u2500ReLU: 3-3                    [-1, 64, 56, 56]          --\n|    |    \u2514\u2500Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n|    |    \u2514\u2500BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n|    |    \u2514\u2500ReLU: 3-6                    [-1, 64, 56, 56]          --\n|    |    \u2514\u2500Conv2d: 3-7                  [-1, 256, 56, 56]         16,384\n|    |    \u2514\u2500BatchNorm2d: 3-8             [-1, 256, 56, 56]         512\n|    |    \u2514\u2500Sequential: 3-9              [-1, 256, 56, 56]         --\n|    |    \u2514\u2500ReLU: 3-10                   [-1, 256, 56, 56]         --\n\n  ...\n  ...\n  ...\n\n\u251c\u2500AdaptiveAvgPool2d: 1-9                 [-1, 2048, 1, 1]          --\n\u251c\u2500Linear: 1-10                           [-1, 1000]                2,049,000\n==========================================================================================\nTotal params: 60,192,808\nTrainable params: 60,192,808\nNon-trainable params: 0\n------------------------------------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 344.16\nParams size (MB): 229.62\nEstimated Total Size (MB): 574.35\n------------------------------------------------------------------------------------------\n\n\n```\n\n\n# Other Examples\n```\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 1, 16, 16]              10\n              ReLU-2            [-1, 1, 16, 16]               0\n            Conv2d-3            [-1, 1, 28, 28]              10\n              ReLU-4            [-1, 1, 28, 28]               0\n================================================================\nTotal params: 20\nTrainable params: 20\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.77\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.78\n----------------------------------------------------------------\n```\n\n# References\n- Thanks to @sksq96, @nmhkahn, and @sangyx for providing the original code this project was based off of.\n- For Model Size Estimation @jacobkimmel ([details here](https://github.com/sksq96/pytorch-summary/pull/21))\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tyleryep/torch-summary", "keywords": "torch pytorch torchsummary torch-summary summary keras deep-learning ml", "license": "", "maintainer": "", "maintainer_email": "", "name": "torch-summary", "package_url": "https://pypi.org/project/torch-summary/", "platform": "", "project_url": "https://pypi.org/project/torch-summary/", "project_urls": {"Homepage": "https://github.com/tyleryep/torch-summary"}, "release_url": "https://pypi.org/project/torch-summary/1.1.9/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Model summary in PyTorch, based off of the original torchsummary.", "version": "1.1.9", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>torch-summary</h1>\n<p><a href=\"https://www.python.org/downloads/release/python-360/\" rel=\"nofollow\"><img alt=\"Python 3.6+\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6a042d910c74fbce532a01da853019c164ef42a8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362b2d626c75652e737667\"></a>\n<a href=\"https://badge.fury.io/py/torch-summary\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/deb1d2d46c10aec2576261cda1669cede1af080b/68747470733a2f2f62616467652e667572792e696f2f70792f746f7263682d73756d6d6172792e737667\"></a>\n<a href=\"https://github.com/TylerYep/torch-summary/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"GitHub license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5ec8d3bd86a9ac8284676c63c75141d702b94f49/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f54796c65725965702f746f7263682d73756d6d617279\"></a></p>\n<p>Keras has a neat API to view the visualization of the model which is very helpful while debugging your network. In this project, we attempt to do the same in PyTorch. The goal is to provide information complementary to what is provided by <code>print(your_model)</code> in PyTorch.</p>\n<p>This is a rewritten version of the original torchsummary and torchsummaryX projects by @sksq96 and @nmhkahn.\nThere are quite a few pull requests on the original project (which hasn't been updated in over a year), so I decided to take a stab at improving and consolidating some of the features.</p>\n<p><strong>This version now supports:</strong></p>\n<ul>\n<li>RNNs, LSTMs, and other recursive layers</li>\n<li>Branching output to explore model layers using specified depths</li>\n<li>Returns ModelStatistics object to access summary data</li>\n<li>Configurable columns of returned data</li>\n</ul>\n<p><strong>Other features:</strong></p>\n<ul>\n<li>Verbose mode to show specific weights and bias layers</li>\n<li>Accepts either input data or simply the input shape to work!</li>\n<li>Customizable widths and custom batch dimension.</li>\n<li>More comprehensive testing using pytest</li>\n</ul>\n<h1>Usage</h1>\n<p><code>pip install torch-summary</code></p>\n<p>or</p>\n<p><code>git clone https://github.com/tyleryep/torch-summary.git</code></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchsummary</span> <span class=\"kn\">import</span> <span class=\"n\">summary</span>\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">your_model</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">W</span><span class=\"p\">))</span>\n</pre>\n<h1>Documentation</h1>\n<pre><span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">Summarize the given PyTorch model. Summarized information includes:</span>\n<span class=\"sd\">    1) output shape,</span>\n<span class=\"sd\">    2) kernel shape,</span>\n<span class=\"sd\">    3) number of the parameters</span>\n<span class=\"sd\">    4) operations (Mult-Adds)</span>\n<span class=\"sd\">Args:</span>\n<span class=\"sd\">    model (Module): Model to summarize</span>\n<span class=\"sd\">    input_data (Sequence of Sizes or Tensors):</span>\n<span class=\"sd\">        Example input tensor of the model (dtypes inferred from model input).</span>\n<span class=\"sd\">        - OR -</span>\n<span class=\"sd\">        Shape of input data as a List/Tuple/torch.Size (dtypes must match model input,</span>\n<span class=\"sd\">        default is FloatTensors). NOTE: For scalar parameters, use torch.Size([]).</span>\n<span class=\"sd\">    branching (bool): Whether to use the branching layout for the printed output.</span>\n<span class=\"sd\">    depth (int): number of nested layers to traverse (e.g. Sequentials)</span>\n<span class=\"sd\">    verbose (int):</span>\n<span class=\"sd\">        0 (quiet): No output</span>\n<span class=\"sd\">        1 (default): Print model summary</span>\n<span class=\"sd\">        2 (verbose): Show weight and bias layers in full detail</span>\n<span class=\"sd\">    col_names (List): specify which columns to show in the output. Currently supported:</span>\n<span class=\"sd\">        ['output_size', 'num_params', 'kernel_size', 'mult_adds']</span>\n<span class=\"sd\">    col_width (int): width of each column</span>\n<span class=\"sd\">    dtypes (List or None): for multiple inputs or args, must specify the size of both inputs.</span>\n<span class=\"sd\">        You must also specify the types of each parameter here.</span>\n<span class=\"sd\">    batch_dim (int): batch_dimension of input data</span>\n<span class=\"sd\">    device (torch.Device): If specified, uses this torch device for the model and model's input.</span>\n<span class=\"sd\">        Else defaults to torch.cuda.is_available().</span>\n<span class=\"sd\">    args, kwargs: Other arguments used in `model.forward` function.</span>\n<span class=\"sd\">\"\"\"</span>\n</pre>\n<h1>Examples</h1>\n<h2>Get Model Summary as String</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchsummary</span> <span class=\"kn\">import</span> <span class=\"n\">summary</span>\n\n<span class=\"n\">model_stats</span> <span class=\"o\">=</span> <span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">your_model</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">W</span><span class=\"p\">),</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">summary_str</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">model_stats</span><span class=\"p\">)</span>\n</pre>\n<h2>CNN for MNIST</h2>\n<pre><span class=\"k\">class</span> <span class=\"nc\">CNN</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2_drop</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Dropout2d</span><span class=\"p\">(</span><span class=\"mf\">0.3</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">320</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">max_pool2d</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">),</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">max_pool2d</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2_drop</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)),</span> <span class=\"mi\">2</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">320</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">))</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">log_softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">CNN</span><span class=\"p\">()</span>\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">))</span>\n</pre>\n<pre><code>------------------------------------------------------------------------------------------\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n\u251c\u2500Conv2d: 1-1                            [-1, 10, 24, 24]          260\n\u251c\u2500Conv2d: 1-2                            [-1, 20, 8, 8]            5,020\n\u251c\u2500Dropout2d: 1-3                         [-1, 20, 8, 8]            --\n\u251c\u2500Linear: 1-4                            [-1, 50]                  16,050\n\u251c\u2500Linear: 1-5                            [-1, 10]                  510\n==========================================================================================\nTotal params: 21,840\nTrainable params: 21,840\nNon-trainable params: 0\n------------------------------------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.05\nParams size (MB): 0.08\nEstimated Total Size (MB): 0.14\n------------------------------------------------------------------------------------------\n</code></pre>\n<h2>Multiple Inputs w/ Different Data Types</h2>\n<pre><span class=\"k\">class</span> <span class=\"nc\">MultipleInputNetDifferentDtypes</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1a</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1b</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2a</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2b</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x1</span><span class=\"p\">,</span> <span class=\"n\">x2</span><span class=\"p\">):</span>\n        <span class=\"n\">x1</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1a</span><span class=\"p\">(</span><span class=\"n\">x1</span><span class=\"p\">))</span>\n        <span class=\"n\">x1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1b</span><span class=\"p\">(</span><span class=\"n\">x1</span><span class=\"p\">)</span>\n        <span class=\"n\">x2</span> <span class=\"o\">=</span> <span class=\"n\">x2</span><span class=\"o\">.</span><span class=\"n\">type</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">)</span>\n        <span class=\"n\">x2</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2a</span><span class=\"p\">(</span><span class=\"n\">x2</span><span class=\"p\">))</span>\n        <span class=\"n\">x2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2b</span><span class=\"p\">(</span><span class=\"n\">x2</span><span class=\"p\">)</span>\n        <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cat</span><span class=\"p\">((</span><span class=\"n\">x1</span><span class=\"p\">,</span> <span class=\"n\">x2</span><span class=\"p\">),</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">log_softmax</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"p\">[(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">300</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">300</span><span class=\"p\">)],</span> <span class=\"n\">dtypes</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">float</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">])</span>\n</pre>\n<p>Alternatively, you can also pass in the input_data itself, and\ntorchsummary will automatically infer the data types.</p>\n<pre><span class=\"n\">input_data</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">300</span><span class=\"p\">)</span>\n<span class=\"n\">other_input_data</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">300</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">()</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">MultipleInputNetDifferentDtypes</span><span class=\"p\">()</span>\n\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">input_data</span><span class=\"p\">,</span> <span class=\"n\">other_input_data</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<h2>Explore Different Configurations</h2>\n<pre><span class=\"k\">class</span> <span class=\"nc\">LSTMNet</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">embed_dim</span><span class=\"o\">=</span><span class=\"mi\">300</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"o\">=</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"n\">num_layers</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">hidden_dim</span> <span class=\"o\">=</span> <span class=\"n\">hidden_dim</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">embedding</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Embedding</span><span class=\"p\">(</span><span class=\"n\">vocab_size</span><span class=\"p\">,</span> <span class=\"n\">embed_dim</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">LSTM</span><span class=\"p\">(</span><span class=\"n\">embed_dim</span><span class=\"p\">,</span> <span class=\"n\">hidden_dim</span><span class=\"p\">,</span> <span class=\"n\">num_layers</span><span class=\"o\">=</span><span class=\"n\">num_layers</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"n\">hidden_dim</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">embed</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">embedding</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">hidden</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"p\">(</span><span class=\"n\">embed</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n        <span class=\"k\">return</span> <span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">hidden</span>\n\n<span class=\"n\">summary</span><span class=\"p\">(</span>\n    <span class=\"n\">LSTMNet</span><span class=\"p\">(),</span>\n    <span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,),</span>\n    <span class=\"n\">dtypes</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">long</span><span class=\"p\">],</span>\n    <span class=\"n\">branching</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n    <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"n\">col_width</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">,</span>\n    <span class=\"n\">col_names</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">\"kernel_size\"</span><span class=\"p\">,</span> <span class=\"s2\">\"output_size\"</span><span class=\"p\">,</span> <span class=\"s2\">\"num_params\"</span><span class=\"p\">,</span> <span class=\"s2\">\"mult_adds\"</span><span class=\"p\">],</span>\n<span class=\"p\">)</span>\n</pre>\n<pre><code>--------------------------------------------------------------------------------------------------------\nLayer (type:depth-idx)         Kernel Shape         Output Shape         Param #          Mult-Adds\n========================================================================================================\nEmbedding: 1-1                 [300, 20]            [-1, 100, 300]       6,000            6,000\nLSTM: 1-2                       --                  [2, 100, 512]        3,768,320        3,760,128\n  weight_ih_l0                 [2048, 300]\n  weight_hh_l0                 [2048, 512]\n  weight_ih_l1                 [2048, 512]\n  weight_hh_l1                 [2048, 512]\nLinear: 1-3                    [512, 20]            [-1, 100, 20]        10,260           10,240\n========================================================================================================\nTotal params: 3,784,580\nTrainable params: 3,784,580\nNon-trainable params: 0\n--------------------------------------------------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 1.03\nParams size (MB): 14.44\nEstimated Total Size (MB): 15.46\n--------------------------------------------------------------------------------------------------------\n</code></pre>\n<h2>ResNet</h2>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">resnet50</span><span class=\"p\">()</span>\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">),</span> <span class=\"n\">depth</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n</pre>\n<pre><code>------------------------------------------------------------------------------------------\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n\u251c\u2500Conv2d: 1-1                            [-1, 64, 112, 112]        9,408\n\u251c\u2500BatchNorm2d: 1-2                       [-1, 64, 112, 112]        128\n\u251c\u2500ReLU: 1-3                              [-1, 64, 112, 112]        --\n\u251c\u2500MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n\u251c\u2500Sequential: 1-5                        [-1, 256, 56, 56]         --\n|    \u2514\u2500Bottleneck: 2-1                   [-1, 256, 56, 56]         --\n|    |    \u2514\u2500Conv2d: 3-1                  [-1, 64, 56, 56]          4,096\n|    |    \u2514\u2500BatchNorm2d: 3-2             [-1, 64, 56, 56]          128\n|    |    \u2514\u2500ReLU: 3-3                    [-1, 64, 56, 56]          --\n|    |    \u2514\u2500Conv2d: 3-4                  [-1, 64, 56, 56]          36,864\n|    |    \u2514\u2500BatchNorm2d: 3-5             [-1, 64, 56, 56]          128\n|    |    \u2514\u2500ReLU: 3-6                    [-1, 64, 56, 56]          --\n|    |    \u2514\u2500Conv2d: 3-7                  [-1, 256, 56, 56]         16,384\n|    |    \u2514\u2500BatchNorm2d: 3-8             [-1, 256, 56, 56]         512\n|    |    \u2514\u2500Sequential: 3-9              [-1, 256, 56, 56]         --\n|    |    \u2514\u2500ReLU: 3-10                   [-1, 256, 56, 56]         --\n\n  ...\n  ...\n  ...\n\n\u251c\u2500AdaptiveAvgPool2d: 1-9                 [-1, 2048, 1, 1]          --\n\u251c\u2500Linear: 1-10                           [-1, 1000]                2,049,000\n==========================================================================================\nTotal params: 60,192,808\nTrainable params: 60,192,808\nNon-trainable params: 0\n------------------------------------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 344.16\nParams size (MB): 229.62\nEstimated Total Size (MB): 574.35\n------------------------------------------------------------------------------------------\n\n\n</code></pre>\n<h1>Other Examples</h1>\n<pre><code>----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 1, 16, 16]              10\n              ReLU-2            [-1, 1, 16, 16]               0\n            Conv2d-3            [-1, 1, 28, 28]              10\n              ReLU-4            [-1, 1, 28, 28]               0\n================================================================\nTotal params: 20\nTrainable params: 20\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.77\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.78\n----------------------------------------------------------------\n</code></pre>\n<h1>References</h1>\n<ul>\n<li>Thanks to @sksq96, @nmhkahn, and @sangyx for providing the original code this project was based off of.</li>\n<li>For Model Size Estimation @jacobkimmel (<a href=\"https://github.com/sksq96/pytorch-summary/pull/21\" rel=\"nofollow\">details here</a>)</li>\n</ul>\n\n          </div>"}, "last_serial": 7190295, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "1bfdaff3a801ee545d93b06bcd892371", "sha256": "b1c00dd7a07e111c5d0a7ea65a86fc7a1123864ae40956a2d20f402b3804a9f8"}, "downloads": -1, "filename": "torch_summary-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "1bfdaff3a801ee545d93b06bcd892371", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9156, "upload_time": "2020-03-19T06:06:29", "upload_time_iso_8601": "2020-03-19T06:06:29.343042Z", "url": "https://files.pythonhosted.org/packages/cd/68/6cd1297f1c8f9f301e6a9c3068be3bd3297a0e7c1d4a546dc337424cf7b8/torch_summary-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "27287f22f90615af744476bb751d9ab9", "sha256": "833596378f9dc79b69d3b7901359d90142e2eee0b661115b4282caf9982a7ee3"}, "downloads": -1, "filename": "torch-summary-1.0.0.tar.gz", "has_sig": false, "md5_digest": "27287f22f90615af744476bb751d9ab9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7567, "upload_time": "2020-03-19T06:06:31", "upload_time_iso_8601": "2020-03-19T06:06:31.755776Z", "url": "https://files.pythonhosted.org/packages/a3/fd/1cd94f9eabf6eaf59e7b7159fea8806ccbe35ef100f98dfb94739f5b001a/torch-summary-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "d6468f17265aeec5938cddc56091207d", "sha256": "2131cf65a00326ab8539d1a6d4c0af32f7380f649e04869cabeff0ee1d8476da"}, "downloads": -1, "filename": "torch_summary-1.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d6468f17265aeec5938cddc56091207d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7515, "upload_time": "2020-03-19T06:40:09", "upload_time_iso_8601": "2020-03-19T06:40:09.676745Z", "url": "https://files.pythonhosted.org/packages/21/d9/7face5ce646cdebf2cce8d651d3823a808743d4565457505de16f88cb38d/torch_summary-1.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d26b4f436b5a5be0099700ac91b9b969", "sha256": "2ab1337cc2abe6d9ccb9a652f7a51264e53a9036f5a7b8bf18356b08a7117ff8"}, "downloads": -1, "filename": "torch-summary-1.0.1.tar.gz", "has_sig": false, "md5_digest": "d26b4f436b5a5be0099700ac91b9b969", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6536, "upload_time": "2020-03-19T06:40:11", "upload_time_iso_8601": "2020-03-19T06:40:11.101486Z", "url": "https://files.pythonhosted.org/packages/99/39/f77e4042dce04f89d7060a960515e6eda9c4fdf2baa37aef22e3191456ea/torch-summary-1.0.1.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "4fb835e1e9846745a9d21f844d82b667", "sha256": "f0859dd462487697f25ad10bca6a7220455458ea139bc7d1e60134ca7f01ff66"}, "downloads": -1, "filename": "torch_summary-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "4fb835e1e9846745a9d21f844d82b667", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7914, "upload_time": "2020-03-20T07:42:40", "upload_time_iso_8601": "2020-03-20T07:42:40.765579Z", "url": "https://files.pythonhosted.org/packages/1c/33/9ea399a84305d00df0c08d0f3499e9d99ea4860d74ebec8519a7ad6b5086/torch_summary-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "63389686e24ed006388defcfcb0aa5cf", "sha256": "27008da97f60f82a95a325b5f15baf277ce62cd8f8cdc3cba29ac4ec1462b7d3"}, "downloads": -1, "filename": "torch-summary-1.0.2.tar.gz", "has_sig": false, "md5_digest": "63389686e24ed006388defcfcb0aa5cf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6926, "upload_time": "2020-03-20T07:42:42", "upload_time_iso_8601": "2020-03-20T07:42:42.155993Z", "url": "https://files.pythonhosted.org/packages/df/0e/560cc98582f5a315c3ea758743797e2801857f0c4eff41b6b5e17048bd4c/torch-summary-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "4a1e1c728f46113e6ec353b03dda67ef", "sha256": "7c81ab0c59c07b23b1b6b51d65f863c10a2521eca5e1dc8e3727a2982c379caf"}, "downloads": -1, "filename": "torch_summary-1.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "4a1e1c728f46113e6ec353b03dda67ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8336, "upload_time": "2020-03-21T21:40:25", "upload_time_iso_8601": "2020-03-21T21:40:25.123103Z", "url": "https://files.pythonhosted.org/packages/4c/b5/b31df3a4d0264808a70d6e68be2c9a4defb59e92e1b4e4eea0ffcd9093ae/torch_summary-1.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8188463dd2a8d0ce399184eccf654e9a", "sha256": "b5f38141c3b793dfe8bbeee6a1b75420259851cb0d7b2abcd3b5ba52dcd257ee"}, "downloads": -1, "filename": "torch-summary-1.0.3.tar.gz", "has_sig": false, "md5_digest": "8188463dd2a8d0ce399184eccf654e9a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7419, "upload_time": "2020-03-21T21:40:26", "upload_time_iso_8601": "2020-03-21T21:40:26.770302Z", "url": "https://files.pythonhosted.org/packages/81/50/6e8614a9c35e65c9fed6e323f41ddfbccdf52cd733882bfb8a4252a7d6c7/torch-summary-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "f13c326c2f28e0cdc57b5d9d0e9ca2e1", "sha256": "aac123c409cdbaad6cb174f7587c23f6b726b8817b6eeb3d3a3ca52ebd913d67"}, "downloads": -1, "filename": "torch_summary-1.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "f13c326c2f28e0cdc57b5d9d0e9ca2e1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8530, "upload_time": "2020-03-23T05:14:13", "upload_time_iso_8601": "2020-03-23T05:14:13.719997Z", "url": "https://files.pythonhosted.org/packages/12/a1/4a6f84e833c197059900384527829efeb1f9be1ba064a36fce2bb6aa1f28/torch_summary-1.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9761f5b99e51ce2a8a94fc454a761f47", "sha256": "2b77b7ab8f2e685ae38b0ee5f2d16af4625b5b6cb76de56c52b49ef88032dd97"}, "downloads": -1, "filename": "torch-summary-1.0.4.tar.gz", "has_sig": false, "md5_digest": "9761f5b99e51ce2a8a94fc454a761f47", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7669, "upload_time": "2020-03-23T05:14:15", "upload_time_iso_8601": "2020-03-23T05:14:15.296969Z", "url": "https://files.pythonhosted.org/packages/18/85/6aaae5a6f54747f0c82af058365df6f9cff50fdebc73402bc6ed8ba4b156/torch-summary-1.0.4.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "3bf2d685d227b00db4b233d06f9b2fb2", "sha256": "05321570fa4b389cbd64bb6a0d04ea3e3b6638aab4f38a58795b5bc2bf8bd90b"}, "downloads": -1, "filename": "torch_summary-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3bf2d685d227b00db4b233d06f9b2fb2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8675, "upload_time": "2020-04-05T19:51:31", "upload_time_iso_8601": "2020-04-05T19:51:31.254089Z", "url": "https://files.pythonhosted.org/packages/48/ea/78cb9f3ca59430f6d88d973f850723fec22a8a3621e2fc2a642800129835/torch_summary-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a0176dc7656edb264abefcf3970077e", "sha256": "5d78cf6c672e60358e08f9f2da039c3116e2b2024bfa777b7c035ee6f724590a"}, "downloads": -1, "filename": "torch-summary-1.1.0.tar.gz", "has_sig": false, "md5_digest": "0a0176dc7656edb264abefcf3970077e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7811, "upload_time": "2020-04-05T19:51:32", "upload_time_iso_8601": "2020-04-05T19:51:32.629267Z", "url": "https://files.pythonhosted.org/packages/56/bc/ae2632500c7d4174768cf04683e4ad8ed0841ea0183a05de573e3e5c9932/torch-summary-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "12f2940088d13422d4f7855656ab4608", "sha256": "846e5f9e9df83111ba8af32325972409832432ee81a94c8db89b102340fe6cf2"}, "downloads": -1, "filename": "torch_summary-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "12f2940088d13422d4f7855656ab4608", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9001, "upload_time": "2020-04-08T04:32:55", "upload_time_iso_8601": "2020-04-08T04:32:55.494485Z", "url": "https://files.pythonhosted.org/packages/f1/12/ffab4420af34e066bc9731f7a89c6dbe8edbcd36cab91efb14719f5dabbb/torch_summary-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "105f8bc36f924b135a7ff0cddd14b255", "sha256": "d76a2f709cd06a25a3d3d0512914b4a7a534c27b3ba809f8d5a0fffd698f1723"}, "downloads": -1, "filename": "torch-summary-1.1.1.tar.gz", "has_sig": false, "md5_digest": "105f8bc36f924b135a7ff0cddd14b255", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8116, "upload_time": "2020-04-08T04:32:56", "upload_time_iso_8601": "2020-04-08T04:32:56.753459Z", "url": "https://files.pythonhosted.org/packages/d1/49/8be917b23a91f929ed58c5ab47b12f2a9d095755baba6156a0513151b714/torch-summary-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "615604f824eea80e831a4deb1df5ab9b", "sha256": "d3b79ca83e618b16a67fc72398aeb481843426b1a262eb2dbc326d1e37ae10e3"}, "downloads": -1, "filename": "torch_summary-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "615604f824eea80e831a4deb1df5ab9b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10285, "upload_time": "2020-04-14T21:23:57", "upload_time_iso_8601": "2020-04-14T21:23:57.611105Z", "url": "https://files.pythonhosted.org/packages/14/ce/387ca203888fee98c1eefd36215b7f66fd2dfe92bcce03031ce833d9650b/torch_summary-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aa40f6a0ba56ced11644c6325516b7e9", "sha256": "0a09cb4566db2e6a8bf76fe86b7c3d0fbf08d7cc6d37a511455fec8897745391"}, "downloads": -1, "filename": "torch-summary-1.1.2.tar.gz", "has_sig": false, "md5_digest": "aa40f6a0ba56ced11644c6325516b7e9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8407, "upload_time": "2020-04-14T21:23:58", "upload_time_iso_8601": "2020-04-14T21:23:58.690072Z", "url": "https://files.pythonhosted.org/packages/5d/c0/eb997d74e56ee605fb99a3750cd6ac803edb788f8412f5f180933f853822/torch-summary-1.1.2.tar.gz", "yanked": false}], "1.1.3": [{"comment_text": "", "digests": {"md5": "bb8926319e5ce01fd09f7992df173e10", "sha256": "ae9d253dbf96dd88f011126618a365e5563eb8e13fc6c955d3436f01f5e3dc53"}, "downloads": -1, "filename": "torch_summary-1.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "bb8926319e5ce01fd09f7992df173e10", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10908, "upload_time": "2020-04-17T18:29:10", "upload_time_iso_8601": "2020-04-17T18:29:10.246808Z", "url": "https://files.pythonhosted.org/packages/38/2d/fcc1dc5f4b24094b7a6403ac6073d3fdb602dcb16f35b5d1a6328d5d41c4/torch_summary-1.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "efdc353c8c4ed26ae4c9755113ed2215", "sha256": "460b979f5e0fff829e6cbdfa90f328e3a28bd59009e3eb20d5b31bb9f40e3d39"}, "downloads": -1, "filename": "torch-summary-1.1.3.tar.gz", "has_sig": false, "md5_digest": "efdc353c8c4ed26ae4c9755113ed2215", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8711, "upload_time": "2020-04-17T18:29:11", "upload_time_iso_8601": "2020-04-17T18:29:11.781721Z", "url": "https://files.pythonhosted.org/packages/7e/41/2e5f19cb687fc5ea9604c6e156170827c5a5c8b8c32fdc775679d6ce9c9d/torch-summary-1.1.3.tar.gz", "yanked": false}], "1.1.4": [{"comment_text": "", "digests": {"md5": "4296ce40387ef19914e1606af835a870", "sha256": "2df55af61ce76a081330980ca635fd9c137f38ea0e10aa054f324ec41699d9ba"}, "downloads": -1, "filename": "torch_summary-1.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "4296ce40387ef19914e1606af835a870", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10922, "upload_time": "2020-04-19T18:26:27", "upload_time_iso_8601": "2020-04-19T18:26:27.227650Z", "url": "https://files.pythonhosted.org/packages/7a/b1/0efc6f48f11cc8d5a88bdc719131cb8e67823a0937e7ddee4013f9cffe88/torch_summary-1.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "251e98ab482daa240fb8300af99ad6db", "sha256": "998599f7f8d1acfaf03fbdc3102c2fa713c9fd91317d63925eb0934b46542d6c"}, "downloads": -1, "filename": "torch-summary-1.1.4.tar.gz", "has_sig": false, "md5_digest": "251e98ab482daa240fb8300af99ad6db", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8745, "upload_time": "2020-04-19T18:26:28", "upload_time_iso_8601": "2020-04-19T18:26:28.817750Z", "url": "https://files.pythonhosted.org/packages/03/ea/d4eeac3e8b6e8ae3f8a8ef9baa3436f103c0765f811447896cfd2c27c706/torch-summary-1.1.4.tar.gz", "yanked": false}], "1.1.5": [{"comment_text": "", "digests": {"md5": "73cec76a3c3808813cd714cdb168c210", "sha256": "05ced7ddba670f32a9b1dbe0ea63749542ef9c7dcca7753a0694f8ca944c17be"}, "downloads": -1, "filename": "torch_summary-1.1.5-py3-none-any.whl", "has_sig": false, "md5_digest": "73cec76a3c3808813cd714cdb168c210", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11267, "upload_time": "2020-04-19T20:44:21", "upload_time_iso_8601": "2020-04-19T20:44:21.224322Z", "url": "https://files.pythonhosted.org/packages/a9/22/3f89393df39b4d4a116d79fcc6069d762d66b794b87f7201a1ea2f9da470/torch_summary-1.1.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ce714d09328fcc380e71dd3113709083", "sha256": "a054b1875cea19a72368cba04d5502fd7f77479ab825793fe099b59544b705fd"}, "downloads": -1, "filename": "torch-summary-1.1.5.tar.gz", "has_sig": false, "md5_digest": "ce714d09328fcc380e71dd3113709083", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9067, "upload_time": "2020-04-19T20:44:22", "upload_time_iso_8601": "2020-04-19T20:44:22.655318Z", "url": "https://files.pythonhosted.org/packages/10/a6/05cbb617f42880a03995e2b98d1a2a299dea3a41ffd0c6f94ae5ddf8c92c/torch-summary-1.1.5.tar.gz", "yanked": false}], "1.1.6": [{"comment_text": "", "digests": {"md5": "a0e33a81c9632efbebee4d591eb9eae6", "sha256": "48cbee008df8e297a466c8ad8321eda91b60becf64a1fea8a748ae43e3ac7849"}, "downloads": -1, "filename": "torch_summary-1.1.6-py3-none-any.whl", "has_sig": false, "md5_digest": "a0e33a81c9632efbebee4d591eb9eae6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 11666, "upload_time": "2020-04-24T07:07:58", "upload_time_iso_8601": "2020-04-24T07:07:58.923751Z", "url": "https://files.pythonhosted.org/packages/b2/59/80c40759bff7d5675c90766312306228b5a7154fa397ac00fafc64ab68c7/torch_summary-1.1.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eee6b375d16ac339d45f7313ebf66d00", "sha256": "9e2705719c0e11a93aaabde8c2c923f92ee08f1a86e35cc87a2f65f1333d1244"}, "downloads": -1, "filename": "torch-summary-1.1.6.tar.gz", "has_sig": false, "md5_digest": "eee6b375d16ac339d45f7313ebf66d00", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9327, "upload_time": "2020-04-24T07:08:00", "upload_time_iso_8601": "2020-04-24T07:08:00.306919Z", "url": "https://files.pythonhosted.org/packages/81/00/78f0d1932f4caf37fc0252f012ff9c26acb5b0db3929c269f61f0da49346/torch-summary-1.1.6.tar.gz", "yanked": false}], "1.1.7": [{"comment_text": "", "digests": {"md5": "825c2ff33b50e2ccc7ca78b90a709606", "sha256": "c9fc53c0204f363e4833d28b909002b41f026233e96a1026109b34d4076a6cf3"}, "downloads": -1, "filename": "torch_summary-1.1.7-py3-none-any.whl", "has_sig": false, "md5_digest": "825c2ff33b50e2ccc7ca78b90a709606", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12438, "upload_time": "2020-04-29T04:25:56", "upload_time_iso_8601": "2020-04-29T04:25:56.559485Z", "url": "https://files.pythonhosted.org/packages/91/57/51499c4f342ca5f7a53eb05ee273e04c314b577396c02ba2781c4bbe1fcb/torch_summary-1.1.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "daf9164b9d2226cbe5916db72a8215d2", "sha256": "a9c608642d8b17c8401ab34d541286d326832556ba37dc4e54375ff1b0fac4d2"}, "downloads": -1, "filename": "torch-summary-1.1.7.tar.gz", "has_sig": false, "md5_digest": "daf9164b9d2226cbe5916db72a8215d2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10299, "upload_time": "2020-04-29T04:25:57", "upload_time_iso_8601": "2020-04-29T04:25:57.851358Z", "url": "https://files.pythonhosted.org/packages/ec/91/2c1a96134226555a9a4346a26c3b1d303a0577c88f9bc3800bb45e19288d/torch-summary-1.1.7.tar.gz", "yanked": false}], "1.1.8": [{"comment_text": "", "digests": {"md5": "460e27bc997bacc702f2841c6d7d663c", "sha256": "1e1080ac88c55480bd56898176feb82fa98f4ea0886fa6a227820ab8545cdbd8"}, "downloads": -1, "filename": "torch_summary-1.1.8-py3-none-any.whl", "has_sig": false, "md5_digest": "460e27bc997bacc702f2841c6d7d663c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12455, "upload_time": "2020-05-04T19:00:25", "upload_time_iso_8601": "2020-05-04T19:00:25.532359Z", "url": "https://files.pythonhosted.org/packages/63/e5/12bed5867ee5690724b55b42497299c0764395591998846b7444abe00085/torch_summary-1.1.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f48ed0979a82859513a926d7294ed2c0", "sha256": "db117ca7bf172c5edd02f144c8be8be4761bcb725d58f86dc7c617fa2800d373"}, "downloads": -1, "filename": "torch-summary-1.1.8.tar.gz", "has_sig": false, "md5_digest": "f48ed0979a82859513a926d7294ed2c0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10319, "upload_time": "2020-05-04T19:00:26", "upload_time_iso_8601": "2020-05-04T19:00:26.480673Z", "url": "https://files.pythonhosted.org/packages/05/e9/6bfc17e4b2b3868b95161d87a7d3ca22c72cd349d2697d778701d6497ee8/torch-summary-1.1.8.tar.gz", "yanked": false}], "1.1.9": [{"comment_text": "", "digests": {"md5": "35448816366846fdc05715426acf7cca", "sha256": "2be4e6509eb0bbee8e7d309131f9efe20fe87a3e38e91b0e883b0716fee500a6"}, "downloads": -1, "filename": "torch_summary-1.1.9-py3-none-any.whl", "has_sig": false, "md5_digest": "35448816366846fdc05715426acf7cca", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 12587, "upload_time": "2020-05-07T17:14:39", "upload_time_iso_8601": "2020-05-07T17:14:39.262024Z", "url": "https://files.pythonhosted.org/packages/49/6d/2bd971736e171034f28f1a8da62a18ff3fc4d4bb1390f50fefdc1374636f/torch_summary-1.1.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "409a34a9bfdea0ca69f9d6803150b293", "sha256": "7a2a619d6bae7c12da2f75f0fe7440d698fc11f4ee1974e96405eb9f215e5ba8"}, "downloads": -1, "filename": "torch-summary-1.1.9.tar.gz", "has_sig": false, "md5_digest": "409a34a9bfdea0ca69f9d6803150b293", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10477, "upload_time": "2020-05-07T17:14:40", "upload_time_iso_8601": "2020-05-07T17:14:40.805869Z", "url": "https://files.pythonhosted.org/packages/43/11/450a50cab42633f1254ef85cf5f0f0b67f00ba4c06f76cf936802ed52e3e/torch-summary-1.1.9.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "35448816366846fdc05715426acf7cca", "sha256": "2be4e6509eb0bbee8e7d309131f9efe20fe87a3e38e91b0e883b0716fee500a6"}, "downloads": -1, "filename": "torch_summary-1.1.9-py3-none-any.whl", "has_sig": false, "md5_digest": "35448816366846fdc05715426acf7cca", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 12587, "upload_time": "2020-05-07T17:14:39", "upload_time_iso_8601": "2020-05-07T17:14:39.262024Z", "url": "https://files.pythonhosted.org/packages/49/6d/2bd971736e171034f28f1a8da62a18ff3fc4d4bb1390f50fefdc1374636f/torch_summary-1.1.9-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "409a34a9bfdea0ca69f9d6803150b293", "sha256": "7a2a619d6bae7c12da2f75f0fe7440d698fc11f4ee1974e96405eb9f215e5ba8"}, "downloads": -1, "filename": "torch-summary-1.1.9.tar.gz", "has_sig": false, "md5_digest": "409a34a9bfdea0ca69f9d6803150b293", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 10477, "upload_time": "2020-05-07T17:14:40", "upload_time_iso_8601": "2020-05-07T17:14:40.805869Z", "url": "https://files.pythonhosted.org/packages/43/11/450a50cab42633f1254ef85cf5f0f0b67f00ba4c06f76cf936802ed52e3e/torch-summary-1.1.9.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:09 2020"}