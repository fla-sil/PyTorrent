{"info": {"author": "Google LLC", "author_email": "no-reply@google.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# TF-Agents: A reliable, scalable and easy to use Reinforcement Learning library for TensorFlow.\n\n\n[TF-Agents](https://github.com/tensorflow/agents) makes designing, implementing\nand testing new RL algorithms easier, by providing well tested modular\ncomponents that can be modified and extended. It enables fast code iteration,\nwith good test integration and benchmarking.\n\nTo get started, we recommend checking out one of our Colab tutorials. If you\nneed an intro to RL (or a quick recap),\n[start here](docs/tutorials/0_intro_rl.ipynb). Otherwise, check out our\n[DQN tutorial](docs/tutorials/1_dqn_tutorial.ipynb) to get an agent up and\nrunning in the Cartpole environment.\n\n*NOTE:* Current TF-Agents pre-release is under active development and\ninterfaces may change at any time. Feel free to provide feedback and comments.\n\n## Table of contents\n\n<a href='#Agents'>Agents</a><br>\n<a href='#Tutorials'>Tutorials</a><br>\n<a href='#Multi-Armed Bandits'>Multi-Armed Bandits</a><br>\n<a href='#Examples'>Examples</a><br>\n<a href='#Installation'>Installation</a><br>\n<a href='#Contributing'>Contributing</a><br>\n<a href='#Releases'>Releases</a><br>\n<a href='#Principles'>Principles</a><br>\n<a href='#Citation'>Citation</a><br>\n<a href='#Disclaimer'>Disclaimer</a><br>\n\n<a id='Agents'></a>\n## Agents\n\n\nIn TF-Agents, the core elements of RL algorithms are implemented as `Agents`.\nAn agent encompasses two main responsibilities: defining a Policy to interact\nwith the Environment, and how to learn/train that Policy from collected\nexperience.\n\nCurrently the following algorithms are available under TF-Agents:\n\n* [DQN: __Human level control through deep reinforcement learning__ Mnih et al., 2015](https://deepmind.com/research/dqn/)\n* [DDQN: __Deep Reinforcement Learning with Double Q-learning__ Hasselt et al., 2015](https://arxiv.org/abs/1509.06461)\n* [DDPG: __Continuous control with deep reinforcement learning__ Lillicrap et al., 2015](https://arxiv.org/abs/1509.02971)\n* [TD3: __Addressing Function Approximation Error in Actor-Critic Methods__ Fujimoto et al., 2018](https://arxiv.org/abs/1802.09477)\n* [REINFORCE: __Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning__ Williams, 1992](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n* [PPO: __Proximal Policy Optimization Algorithms__ Schulman et al., 2017](https://arxiv.org/abs/1707.06347)\n* [SAC: __Soft Actor Critic__ Haarnoja et al., 2018](https://arxiv.org/abs/1812.05905)\n\n<a id='Tutorials'></a>\n## Tutorials\n\nSee [`docs/tutorials/`](docs/tutorials) for tutorials on the major components\nprovided.\n\n<a id='Multi-Armed Bandits'></a>\n\n## Multi-Armed Bandits\n\nThe TF-Agents library contains also a Multi-Armed Bandits suite with a few\nenvironments and agents. RL agents can also be used on Bandit environments. For\na tutorial, see\n[`tf_agents/bandits/colabs/bandits_tutorial.ipynb`](https://github.com/tensorflow/agents/tree/master/tf_agents/bandits/colabs/bandits_tutorial.ipynb).\nFor examples ready to run, see\n[`tf_agents/bandits/agents/examples/`](https://github.com/tensorflow/agents/tree/master/tf_agents/bandits/agents/examples/).\n\n<a id='Examples'></a>\n## Examples\nEnd-to-end examples training agents can be found under each agent directory.\ne.g.:\n\n* DQN: [`tf_agents/agents/dqn/examples/v1/train_eval_gym.py`](https://github.com/tensorflow/agents/tree/master/tf_agents/agents/dqn/examples/v1/train_eval_gym.py)\n\n<a id='Installation'></a>\n## Installation\n\nTF-Agents publishes nightly and stable builds. For a list of releases read the\n<a href='#Releases'>Releases</a> section. The commands below cover installing\nTF-Agents stable and nightly from [pypi.org](https://pypi.org) as well as from a\nGitHub clone.\n\n### Stable\n\nRun the commands below to install the most recent stable release (0.3.0), which\nwas tested with TensorFlow 1.15.0 and 2.0.0 as well as Python 2 and 3.\n\n```bash\npip install --user tf-agents\npip install --user tensorflow==2.0.0\n\n# Or For TensorFlow 1.x\npip install --user tensorflow==1.15.0\n\n# To get the matching examples and colabs\ngit clone https://github.com/tensorflow/agents.git\ncd agents\ngit checkout v0.3.0\n\n```\n\nNote: TF-Agents 0.3.0 is not compatible with TensorFlow 2.1.0 unless the nightly\nrelease of `TensorFlow Probability` is installed: `pip install tfp-nightly`\n\n### Nightly\n\nNightly builds include newer features, but may be less stable than the versioned\nreleases. The nightly build is pushed as `tf-agents-nightly`. We suggest\ninstalling nightly versions of TensorFlow (`tf-nightly`) and TensorFlow\nProbability (`tfp-nightly`) as those are the version TF-Agents nightly are\ntested against. Nightly releases are only compatible with Python 3 as of\n17-JAN-2020.\n\nTo install the nightly build version, run the following:\n\n```shell\n# Installing with the `--upgrade` flag ensures you'll get the latest version.\npip install --user --upgrade tf-agents-nightly  # depends on tf-nightly\n# `--force-reinstall helps guarantee the right version.\npip install --user --force-reinstall tf-nightly\npip install --user --force-reinstall tfp-nightly\n```\n\n### From GitHub\n\nAfter cloning the repository, the dependencies can be installed by running\n`pip install -e .[tests]`. TensorFlow needs to be installed independently:\n`pip install --user tf-nightly`.\n\n<a id='Contributing'></a>\n## Contributing\n\nWe're eager to collaborate with you! See [`CONTRIBUTING.md`](CONTRIBUTING.md)\nfor a guide on how to contribute. This project adheres to TensorFlow's\n[code of conduct](CODE_OF_CONDUCT.md). By participating, you are expected to\nuphold this code.\n\n<a id='Releases'></a>\n## Releases\n\nTF Agents does both stable and nightly releases. The nightly releases often are\nfine but can have issues to to upstream libraries being in flux. The table below\nlists the stable releases of TF Agents to help users that may be locked into a\nspecific version of TensorFlow or other related supporting. TensorFlow version\nare the versions of TensorFlow tested with the build, other version might work\nbut were not tested. Nightly releases are only compatible with Python 3. 0.3.0\nwas the last release compatible with Python 2.\n\n| Release  | Branch / Tag      | TensorFlow Version |\n| -------- | ----------- | ------------------ |\n| Nightly  | [master](https://github.com/tensorflow/agents) | tf-nightly         |\n| 0.3.0    | [v0.3.0](https://github.com/tensorflow/agents/tree/v0.3.0) | 1.15.0 and 2.0.0   |\n\nExamples of installing nightly, most recent stable, and a specific version of\nTF-Agents:\n\n```bash\n# Stable\npip install tf-agents\n\n# Nightly\npip install tf-agents-nightly\n\n# Specific version\npip install tf-agents==0.3.0\n\n```\n\n\n<a id='Principles'></a>\n## Principles\n\nThis project adheres to [Google's AI principles](PRINCIPLES.md).\nBy participating, using or contributing to this project you are expected to\nadhere to these principles.\n\n<a id='Citation'></a>\n## Citation\n\nIf you use this code please cite it as:\n\n```\n@misc{TFAgents,\n  title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},\n  author = \"{Sergio Guadarrama, Anoop Korattikara, Oscar Ramirez,\n    Pablo Castro, Ethan Holly, Sam Fishman, Ke Wang, Ekaterina Gonina, Neal Wu,\n    Efi Kokiopoulou, Luciano Sbaiz, Jamie Smith, G\u00e1bor Bart\u00f3k, Jesse Berent,\n    Chris Harris, Vincent Vanhoucke, Eugene Brevdo}\",\n  howpublished = {\\url{https://github.com/tensorflow/agents}},\n  url = \"https://github.com/tensorflow/agents\",\n  year = 2018,\n  note = \"[Online; accessed 25-June-2019]\"\n}\n```\n\n<a id='Disclaimer'></a>\n## Disclaimer\n\nThis is not an official Google product.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/tensorflow/agents", "keywords": "tensorflow agents reinforcement learning machine learning", "license": "Apache 2.0", "maintainer": "", "maintainer_email": "", "name": "tf-agents", "package_url": "https://pypi.org/project/tf-agents/", "platform": "", "project_url": "https://pypi.org/project/tf-agents/", "project_urls": {"Homepage": "http://github.com/tensorflow/agents"}, "release_url": "https://pypi.org/project/tf-agents/0.4.0/", "requires_dist": ["absl-py (>=0.6.1)", "gin-config (==0.1.3)", "numpy (>=1.13.3)", "six (>=1.10.0)", "tensorflow-probability (>=0.8.0)", "atari-py (==0.1.7) ; extra == 'tests'", "gym (==0.12.5) ; extra == 'tests'", "opencv-python (>=3.4.1.15) ; extra == 'tests'", "pybullet ; extra == 'tests'", "scipy (==1.1.0) ; extra == 'tests'"], "requires_python": ">=3", "summary": "TF-Agents: A Reinforcement Learning Library for TensorFlow", "version": "0.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>TF-Agents: A reliable, scalable and easy to use Reinforcement Learning library for TensorFlow.</h1>\n<p><a href=\"https://github.com/tensorflow/agents\" rel=\"nofollow\">TF-Agents</a> makes designing, implementing\nand testing new RL algorithms easier, by providing well tested modular\ncomponents that can be modified and extended. It enables fast code iteration,\nwith good test integration and benchmarking.</p>\n<p>To get started, we recommend checking out one of our Colab tutorials. If you\nneed an intro to RL (or a quick recap),\n<a href=\"docs/tutorials/0_intro_rl.ipynb\" rel=\"nofollow\">start here</a>. Otherwise, check out our\n<a href=\"docs/tutorials/1_dqn_tutorial.ipynb\" rel=\"nofollow\">DQN tutorial</a> to get an agent up and\nrunning in the Cartpole environment.</p>\n<p><em>NOTE:</em> Current TF-Agents pre-release is under active development and\ninterfaces may change at any time. Feel free to provide feedback and comments.</p>\n<h2>Table of contents</h2>\n<p><a href=\"#Agents\" rel=\"nofollow\">Agents</a><br>\n<a href=\"#Tutorials\" rel=\"nofollow\">Tutorials</a><br>\n<a href=\"#Multi-Armed%20Bandits\" rel=\"nofollow\">Multi-Armed Bandits</a><br>\n<a href=\"#Examples\" rel=\"nofollow\">Examples</a><br>\n<a href=\"#Installation\" rel=\"nofollow\">Installation</a><br>\n<a href=\"#Contributing\" rel=\"nofollow\">Contributing</a><br>\n<a href=\"#Releases\" rel=\"nofollow\">Releases</a><br>\n<a href=\"#Principles\" rel=\"nofollow\">Principles</a><br>\n<a href=\"#Citation\" rel=\"nofollow\">Citation</a><br>\n<a href=\"#Disclaimer\" rel=\"nofollow\">Disclaimer</a><br></p>\n<p><a id=\"Agents\"></a></p>\n<h2>Agents</h2>\n<p>In TF-Agents, the core elements of RL algorithms are implemented as <code>Agents</code>.\nAn agent encompasses two main responsibilities: defining a Policy to interact\nwith the Environment, and how to learn/train that Policy from collected\nexperience.</p>\n<p>Currently the following algorithms are available under TF-Agents:</p>\n<ul>\n<li><a href=\"https://deepmind.com/research/dqn/\" rel=\"nofollow\">DQN: <strong>Human level control through deep reinforcement learning</strong> Mnih et al., 2015</a></li>\n<li><a href=\"https://arxiv.org/abs/1509.06461\" rel=\"nofollow\">DDQN: <strong>Deep Reinforcement Learning with Double Q-learning</strong> Hasselt et al., 2015</a></li>\n<li><a href=\"https://arxiv.org/abs/1509.02971\" rel=\"nofollow\">DDPG: <strong>Continuous control with deep reinforcement learning</strong> Lillicrap et al., 2015</a></li>\n<li><a href=\"https://arxiv.org/abs/1802.09477\" rel=\"nofollow\">TD3: <strong>Addressing Function Approximation Error in Actor-Critic Methods</strong> Fujimoto et al., 2018</a></li>\n<li><a href=\"http://www-anw.cs.umass.edu/%7Ebarto/courses/cs687/williams92simple.pdf\" rel=\"nofollow\">REINFORCE: <strong>Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning</strong> Williams, 1992</a></li>\n<li><a href=\"https://arxiv.org/abs/1707.06347\" rel=\"nofollow\">PPO: <strong>Proximal Policy Optimization Algorithms</strong> Schulman et al., 2017</a></li>\n<li><a href=\"https://arxiv.org/abs/1812.05905\" rel=\"nofollow\">SAC: <strong>Soft Actor Critic</strong> Haarnoja et al., 2018</a></li>\n</ul>\n<p><a id=\"Tutorials\"></a></p>\n<h2>Tutorials</h2>\n<p>See <a href=\"docs/tutorials\" rel=\"nofollow\"><code>docs/tutorials/</code></a> for tutorials on the major components\nprovided.</p>\n<p><a id=\"Multi-Armed Bandits\"></a></p>\n<h2>Multi-Armed Bandits</h2>\n<p>The TF-Agents library contains also a Multi-Armed Bandits suite with a few\nenvironments and agents. RL agents can also be used on Bandit environments. For\na tutorial, see\n<a href=\"https://github.com/tensorflow/agents/tree/master/tf_agents/bandits/colabs/bandits_tutorial.ipynb\" rel=\"nofollow\"><code>tf_agents/bandits/colabs/bandits_tutorial.ipynb</code></a>.\nFor examples ready to run, see\n<a href=\"https://github.com/tensorflow/agents/tree/master/tf_agents/bandits/agents/examples/\" rel=\"nofollow\"><code>tf_agents/bandits/agents/examples/</code></a>.</p>\n<p><a id=\"Examples\"></a></p>\n<h2>Examples</h2>\n<p>End-to-end examples training agents can be found under each agent directory.\ne.g.:</p>\n<ul>\n<li>DQN: <a href=\"https://github.com/tensorflow/agents/tree/master/tf_agents/agents/dqn/examples/v1/train_eval_gym.py\" rel=\"nofollow\"><code>tf_agents/agents/dqn/examples/v1/train_eval_gym.py</code></a></li>\n</ul>\n<p><a id=\"Installation\"></a></p>\n<h2>Installation</h2>\n<p>TF-Agents publishes nightly and stable builds. For a list of releases read the\n<a href=\"#Releases\" rel=\"nofollow\">Releases</a> section. The commands below cover installing\nTF-Agents stable and nightly from <a href=\"https://pypi.org\" rel=\"nofollow\">pypi.org</a> as well as from a\nGitHub clone.</p>\n<h3>Stable</h3>\n<p>Run the commands below to install the most recent stable release (0.3.0), which\nwas tested with TensorFlow 1.15.0 and 2.0.0 as well as Python 2 and 3.</p>\n<pre>pip install --user tf-agents\npip install --user <span class=\"nv\">tensorflow</span><span class=\"o\">==</span><span class=\"m\">2</span>.0.0\n\n<span class=\"c1\"># Or For TensorFlow 1.x</span>\npip install --user <span class=\"nv\">tensorflow</span><span class=\"o\">==</span><span class=\"m\">1</span>.15.0\n\n<span class=\"c1\"># To get the matching examples and colabs</span>\ngit clone https://github.com/tensorflow/agents.git\n<span class=\"nb\">cd</span> agents\ngit checkout v0.3.0\n</pre>\n<p>Note: TF-Agents 0.3.0 is not compatible with TensorFlow 2.1.0 unless the nightly\nrelease of <code>TensorFlow Probability</code> is installed: <code>pip install tfp-nightly</code></p>\n<h3>Nightly</h3>\n<p>Nightly builds include newer features, but may be less stable than the versioned\nreleases. The nightly build is pushed as <code>tf-agents-nightly</code>. We suggest\ninstalling nightly versions of TensorFlow (<code>tf-nightly</code>) and TensorFlow\nProbability (<code>tfp-nightly</code>) as those are the version TF-Agents nightly are\ntested against. Nightly releases are only compatible with Python 3 as of\n17-JAN-2020.</p>\n<p>To install the nightly build version, run the following:</p>\n<pre><span class=\"c1\"># Installing with the `--upgrade` flag ensures you'll get the latest version.</span>\npip install --user --upgrade tf-agents-nightly  <span class=\"c1\"># depends on tf-nightly</span>\n<span class=\"c1\"># `--force-reinstall helps guarantee the right version.</span>\npip install --user --force-reinstall tf-nightly\npip install --user --force-reinstall tfp-nightly\n</pre>\n<h3>From GitHub</h3>\n<p>After cloning the repository, the dependencies can be installed by running\n<code>pip install -e .[tests]</code>. TensorFlow needs to be installed independently:\n<code>pip install --user tf-nightly</code>.</p>\n<p><a id=\"Contributing\"></a></p>\n<h2>Contributing</h2>\n<p>We're eager to collaborate with you! See <a href=\"CONTRIBUTING.md\" rel=\"nofollow\"><code>CONTRIBUTING.md</code></a>\nfor a guide on how to contribute. This project adheres to TensorFlow's\n<a href=\"CODE_OF_CONDUCT.md\" rel=\"nofollow\">code of conduct</a>. By participating, you are expected to\nuphold this code.</p>\n<p><a id=\"Releases\"></a></p>\n<h2>Releases</h2>\n<p>TF Agents does both stable and nightly releases. The nightly releases often are\nfine but can have issues to to upstream libraries being in flux. The table below\nlists the stable releases of TF Agents to help users that may be locked into a\nspecific version of TensorFlow or other related supporting. TensorFlow version\nare the versions of TensorFlow tested with the build, other version might work\nbut were not tested. Nightly releases are only compatible with Python 3. 0.3.0\nwas the last release compatible with Python 2.</p>\n<table>\n<thead>\n<tr>\n<th>Release</th>\n<th>Branch / Tag</th>\n<th>TensorFlow Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Nightly</td>\n<td><a href=\"https://github.com/tensorflow/agents\" rel=\"nofollow\">master</a></td>\n<td>tf-nightly</td>\n</tr>\n<tr>\n<td>0.3.0</td>\n<td><a href=\"https://github.com/tensorflow/agents/tree/v0.3.0\" rel=\"nofollow\">v0.3.0</a></td>\n<td>1.15.0 and 2.0.0</td>\n</tr></tbody></table>\n<p>Examples of installing nightly, most recent stable, and a specific version of\nTF-Agents:</p>\n<pre><span class=\"c1\"># Stable</span>\npip install tf-agents\n\n<span class=\"c1\"># Nightly</span>\npip install tf-agents-nightly\n\n<span class=\"c1\"># Specific version</span>\npip install tf-agents<span class=\"o\">==</span><span class=\"m\">0</span>.3.0\n</pre>\n<p><a id=\"Principles\"></a></p>\n<h2>Principles</h2>\n<p>This project adheres to <a href=\"PRINCIPLES.md\" rel=\"nofollow\">Google's AI principles</a>.\nBy participating, using or contributing to this project you are expected to\nadhere to these principles.</p>\n<p><a id=\"Citation\"></a></p>\n<h2>Citation</h2>\n<p>If you use this code please cite it as:</p>\n<pre><code>@misc{TFAgents,\n  title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},\n  author = \"{Sergio Guadarrama, Anoop Korattikara, Oscar Ramirez,\n    Pablo Castro, Ethan Holly, Sam Fishman, Ke Wang, Ekaterina Gonina, Neal Wu,\n    Efi Kokiopoulou, Luciano Sbaiz, Jamie Smith, G\u00e1bor Bart\u00f3k, Jesse Berent,\n    Chris Harris, Vincent Vanhoucke, Eugene Brevdo}\",\n  howpublished = {\\url{https://github.com/tensorflow/agents}},\n  url = \"https://github.com/tensorflow/agents\",\n  year = 2018,\n  note = \"[Online; accessed 25-June-2019]\"\n}\n</code></pre>\n<p><a id=\"Disclaimer\"></a></p>\n<h2>Disclaimer</h2>\n<p>This is not an official Google product.</p>\n\n          </div>"}, "last_serial": 6974322, "releases": {"0.2.0rc0": [{"comment_text": "", "digests": {"md5": "7800ab69dd63af4b2167ce94351966a0", "sha256": "7009b5be1d699b1180f5b9bbf2ec878477ae62586aae722c7b6a62502149e46b"}, "downloads": -1, "filename": "tf_agents-0.2.0rc0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7800ab69dd63af4b2167ce94351966a0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 433994, "upload_time": "2018-12-04T21:19:28", "upload_time_iso_8601": "2018-12-04T21:19:28.604358Z", "url": "https://files.pythonhosted.org/packages/df/51/b4d69e173a4061839f54379772148a4442d77eb1ab02a3ac3cea273c909b/tf_agents-0.2.0rc0-py2.py3-none-any.whl", "yanked": false}], "0.2.0rc1": [{"comment_text": "", "digests": {"md5": "d5cfad15c11f26129b71c34e930710ce", "sha256": "7bd2fc09c9f790a3e56cbd146af8edf2c8bca2fa4bb2d5e2d2586eee0e915afa"}, "downloads": -1, "filename": "tf_agents-0.2.0rc1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d5cfad15c11f26129b71c34e930710ce", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 433996, "upload_time": "2018-12-04T21:50:10", "upload_time_iso_8601": "2018-12-04T21:50:10.434266Z", "url": "https://files.pythonhosted.org/packages/33/3a/134af64155edfe930b0e8561df0b3d2188693a86c2fe40d6eb9df94777da/tf_agents-0.2.0rc1-py2.py3-none-any.whl", "yanked": false}], "0.2.0rc2": [{"comment_text": "", "digests": {"md5": "83615ce467596d54db8dd56e0e1b6fca", "sha256": "9cbb069b80fbf4b9a034d67af3c203bf801b776d2f56436e121f67772c6abd40"}, "downloads": -1, "filename": "tf_agents-0.2.0rc2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "83615ce467596d54db8dd56e0e1b6fca", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 448341, "upload_time": "2019-01-17T17:24:54", "upload_time_iso_8601": "2019-01-17T17:24:54.256921Z", "url": "https://files.pythonhosted.org/packages/ef/fe/4b2c69d92d59f3f752f80c4f23e23fffe4f77f8e06fd0b89a42f252cf19f/tf_agents-0.2.0rc2-py2.py3-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "c7901da1454abd0b92dfa4de14ae8c24", "sha256": "de49f248de8f616e942c1d8b601fd4fb28fd62aed01085cd12d5c80422725543"}, "downloads": -1, "filename": "tf_agents-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c7901da1454abd0b92dfa4de14ae8c24", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 839606, "upload_time": "2019-12-16T20:44:04", "upload_time_iso_8601": "2019-12-16T20:44:04.233091Z", "url": "https://files.pythonhosted.org/packages/0e/a5/07aa82a3cd586d193b2f086b50a2fd0f48bd888ae204389f666eb178cfb3/tf_agents-0.3.0-py2.py3-none-any.whl", "yanked": false}], "0.3.0rc0": [{"comment_text": "", "digests": {"md5": "53c767160e8322af254766287385c8d3", "sha256": "e26bbb810395292b5bd212fac230d29aa7ab309cbcd33670d69a7f75af7a86c2"}, "downloads": -1, "filename": "tf_agents-0.3.0rc0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "53c767160e8322af254766287385c8d3", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 839640, "upload_time": "2019-12-10T19:09:03", "upload_time_iso_8601": "2019-12-10T19:09:03.723357Z", "url": "https://files.pythonhosted.org/packages/0c/42/741a52399cc54c5ebf5c2f0835771570f55511b86688743c76a729d0b079/tf_agents-0.3.0rc0-py2.py3-none-any.whl", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "bba39c3d20585eecc3fb82e222e68085", "sha256": "0559cc87264339ebd2a1f8b3ad4cf1b97d07fa0cb0a869fe4c9dbe9e08cd7124"}, "downloads": -1, "filename": "tf_agents-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "bba39c3d20585eecc3fb82e222e68085", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 903674, "upload_time": "2020-04-08T01:05:11", "upload_time_iso_8601": "2020-04-08T01:05:11.635060Z", "url": "https://files.pythonhosted.org/packages/88/5c/d49f8de64408a7d67ddda09c9eeb0f2fb001c43ff945b3462db27d239b56/tf_agents-0.4.0-py3-none-any.whl", "yanked": false}], "0.4.0rc0": [{"comment_text": "", "digests": {"md5": "028e67300244c68780a56ed2b5b39b28", "sha256": "a374b0f3ad5f539b06ad0e83a014c132a5e02ef083d00e9756ce8c8f85447e71"}, "downloads": -1, "filename": "tf_agents-0.4.0rc0-py3-none-any.whl", "has_sig": false, "md5_digest": "028e67300244c68780a56ed2b5b39b28", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 903703, "upload_time": "2020-03-18T04:10:00", "upload_time_iso_8601": "2020-03-18T04:10:00.197743Z", "url": "https://files.pythonhosted.org/packages/f6/4e/b5e89e7cc6add4e300cf266f2aaf0324f3808eb4c6506a18030b5c4ebdfd/tf_agents-0.4.0rc0-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bba39c3d20585eecc3fb82e222e68085", "sha256": "0559cc87264339ebd2a1f8b3ad4cf1b97d07fa0cb0a869fe4c9dbe9e08cd7124"}, "downloads": -1, "filename": "tf_agents-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "bba39c3d20585eecc3fb82e222e68085", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 903674, "upload_time": "2020-04-08T01:05:11", "upload_time_iso_8601": "2020-04-08T01:05:11.635060Z", "url": "https://files.pythonhosted.org/packages/88/5c/d49f8de64408a7d67ddda09c9eeb0f2fb001c43ff945b3462db27d239b56/tf_agents-0.4.0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 02:54:50 2020"}