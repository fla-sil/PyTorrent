{"info": {"author": "TianyuSu", "author_email": "tyanyu.su@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6"], "description": "# torchfurnace [![Build Status](https://travis-ci.com/tianyu-su/torchfurnace.svg?branch=master)](https://travis-ci.com/tianyu-su/torchfurnace) ![](https://img.shields.io/badge/pytorch-1.1.0-blue) ![](https://img.shields.io/badge/python-3.6-blue)\n\n`torchfurnace` is a tool package for training model, pre-processing dataset and managing experiment record in pytorch AI tasks.\n\n## Quick Start\n\n### Usage\n\n`pip install torchfurnace`\n\n### Example\nVGG16 for CIFAR10\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.optim.lr_scheduler import MultiStepLR\nfrom torchfurnace import Engine, Parser\nfrom torchfurnace.utils.function import accuracy\n\n# define training process of your model\nclass VGGNetEngine(Engine):\n    @staticmethod\n    def _on_forward(training, model, inp, target, optimizer=None) -> dict:\n        ret = {'loss': object, 'acc1': object, 'acc5': object}\n        output = model(inp)\n        loss = F.cross_entropy(output, target)\n\n        if training:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n        ret['loss'] = loss.item()\n        ret['acc1'] = acc1.item()\n        ret['acc5'] = acc5.item()\n        return ret\n\n    @staticmethod\n    def _get_lr_scheduler(optim) -> list:\n        return [MultiStepLR(optim, milestones=[150, 250, 350], gamma=0.1)]\n\ndef main():\n    # define experiment name\n    parser = Parser('TVGG16')\n    args = parser.parse_args()\n    experiment_name = '_'.join([args.dataset, args.exp_suffix])\n\n    # Data\n    ts = transforms.Compose([transforms.ToTensor(), transforms.Normalize(\n        (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n    trainset = CIFAR10(root='data', train=True, download=True, transform=ts)\n    testset = CIFAR10(root='data', train=False, download=True, transform=ts)\n\n    # define model and optimizer\n    net = models.vgg16(pretrained=False, num_classes=10)\n    net.avgpool = nn.AvgPool2d(kernel_size=1, stride=1)\n    net.classifier = nn.Linear(512, 10)\n    optimizer = torch.optim.Adam(net.parameters())\n\n    # new engine instance\n    eng = VGGNetEngine(parser,experiment_name)\n    acc1 = eng.learning(net, optimizer, trainset, testset)\n    print('Acc1:', acc1)\n\nif __name__ == '__main__':\n    import sys\n    run_params = '--dataset CIFAR10 -lr 0.1 -bs 128 -j 2 --epochs 400 --adjust_lr'\n    sys.argv.extend(run_params.split())\n    main()\n\n```\n\n## Introduction\n### Why do this?\n\nThere are some deep learning frameworks to quickly build a training system in pytorch AI tasks, however, I found that most of them are complex framework which have higher cost for learning it and seriously invade original code , for instance, maybe modify your model class to adapt the framework.\n\nSo, `torchfurnace` is born for performing your pytorch AI task quickly, simply and without invasion viz you don't have to change too much defined code.\n\n### What features?\n\n1. `torchfurnace` consists of two independent components including `engine` and `tracer`. `engine` is a core component of proposed framework, and `tracer` is a manager of experiment whose obligation include log writing, model saving and training visualization.\n\n2. `torchfurnace` integrates some practical tools, such as processing raw dataset to LMDB for solving I/O bottleneck and computing the number of parameter size and dataset with std and mean.\n\n### Components\n\n#### Engine\n\n```python\nfrom torchfurnace import Engine\n```\nThis is core component of the proposed framework. `Engine` is an abstract class which controls the whole workflow to finish AI tasks. So, you have to implement `_on_forward` by inheriting the `Engine` when you start. The job of `_on_forward` is to define which criterion to use and how to optimize your model.\n\nFor example (a minimal configuration):\n\n```python\nclass VGGNetEngine(Engine):\n    @staticmethod\n    def _on_forward(training, model, inp, target, optimizer=None) -> dict:\n        ret = {'loss': object, 'acc1': object, 'acc5': object}\n        output = model(inp)\n        loss = F.cross_entropy(output, target)\n\n        if training:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n        ret['loss'] = loss.item()\n        ret['acc1'] = acc1.item()\n        ret['acc5'] = acc5.item()\n        return ret\n```\n\nAbove,  you have done the preparatory work of framework, and then you define model, train dataset, val dataset and optimizer as usual. This highlights the advantages of our method which don't  heavily invade original code. In other words, you don't have to modify your code too much.  As follow, only 3 lines to finish learning. Of course, you can also assign a list type as model and optimizer, however, it's vital each element of models and optimizer must be matched.\n\n```python\nparser = Parser('TVGG11')\neng = VGGNetEngine(parser\uff0cexperiment_name)\neng.learning(model, optimizer, train_ds, val_ds)\n```\n\n\n\nIf you want more customizable features, you can override them with the following listed functions.\n\n#####  overridden function\n\n1. `_get_lr_scheduler`: This function support to define other scheduler in `torch.optim.lr_scheduler`. Default:  StepLR with gamma=0.1 and step_size=30\n2. `_on_start_epoch`: You can add some meters , such as AverageMeter using `from torchfurnace.utils.meter import AverageMeter` in this function when you want to record more information in the training processing. \n3. `_on_start_batch`: define how to get input and target  from your dataset and put them on GPU.\n4. `_add_on_end_batch_log`: You can add some log output information just like other meters in `_on_end_batch`. \n5. `_add_on_end_batch_tb`:  You can add some tensorboard output information just like other meters in `_on_end_batch`. \n6. `_add_record`:  you can add some record after `_on_forward` \n7. `_before_evaluate`: define your operation before calling `_validate`  evaluation mode\n8. `_after_evaluate`: define your operation after calling `_validate` evaluation mode\n\n#### Tracer\n\n```python\nfrom torchfurnace import Tracer\n```\n\nThe  responsibility of this component is to manage  log writing, model saving and training visualization in experiment.\n\nEspecially, this component can run independently, meanwhile, it is integrated in `Engine` as a nested object to manage experiment record.\n\nFor example:\n\n```python\nfrom torchfurnace import Tracer\ntracer = Tracer(root_dir=Path('.'),work_name= 'mine_network')\\\n    .attach(experiment_name='exp', logger_name='log', override=True)\n```\n\n##### save experiment configuration\n\n```python\nimport torchfurnace.utils.tracer_component as tc\ncfg = {\"optimizer\": optim, 'addtion': 'hhh'}\ntracer.store(tc.Config({**cfg, **vars(Parser('my_network').parse_args())}))\n```\n\ncfg: some customize information \n\nParser('my_network').parse_args() : parser snapshot\n\n##### save checkpoint\n\n```python\nimport torchfurnace.utils.tracer_component as tc\nmodel = models.vgg11(pretrained=False)\noptimizer = torch.optim.Adam(model.parameters())\ntracer.store(tc.Model(\n        f\"{model.__class__.__name__}_extinfo.pth.tar\",\n        {\n            'epoch': 99,\n            'arch': str(model),\n            'state_dict': model.state_dict(),\n            'best_acc1': 0.66,\n            'optimizer': optimizer.state_dict(),\n        }, True))\n```\n\nsave checkpoint to appropriate location automatically.\n\n##### load checkpoint\n\n```python\nimport torchfurnace.utils.tracer_component as tc\nmodel = models.vgg11(pretrained=False)\noptimizer = torch.optim.Adam(model.parameters())\n# 'pth' has fix format. It contains two parts,\n#  which are experiment file name and best model file name,\n#  skipping medial path , and they are separate by '/' .\npth = f\"expn/{model.__class__.__name__}_Epk{99}_Acc{0.66}_extinfo_best.pth.tar\"\nret = tracer.load(tc.Model(\n        pth, {\n            'model': model,\n            'optim': optimizer\n        }))\nprint(ret)\n# ret has start_epoch and best_acc1\n```\n\nload checkpoint from appropriate location automatically.\n\n**Note:** `--resume` is assigned just like `pth`\n\n##### display TensorBoard\n\n```python\ntracer.tb_switch(True)\ntracer.tb_switch(False)\n```\n\n##### redirect output\n\n```python\ntracer.debug_switch(True)\ntracer.debug_switch(False)\n```\n\n#### Parser\n\n```python\nfrom torchfurnace import Parser\n```\n\nThis just is an  `ArgumentParser`, but have defined some frequently-used options.\n\n##### print default options\n\n```python\nfrom torchfurnace import Parser\np = Parser()\nargs = p.parse_args()\nprint(args)\n```\n\n```json\n{\n    \"dataset\":\"\",\n    \"batch_size\":1,\n    \"workers\":2,\n    \"lr\":0.01,\n    \"weight_decay\":0.0005,\n    \"momentum\":0.9,\n    \"dropout\":0.5,\n    \"start_epoch\":0,\n    \"epochs\":200,\n    \"gpu\":\"0\",\n    \"exp_suffix\":\"\",\n    \"extension\":\"\",\n    \"resume\":\"\",\n    \"evaluate\":false,\n    \"deterministic\":false,\n    \"adjust_lr\":false,\n    \"print_freq\":10,\n    \"logger_name\":\"log.txt\",\n    \"work_dir\":\"\",\n    \"clean_up\":5,\n    \"debug\":false,\n    \"p_bar\":false,\n    \"no_tb\":true,\n    \"nowtime_exp\":true\n}\n```\n\nAlso, you can open `from torchfurnace import Parser` to get more information.\n\n##### add option to engine\n\n```python\nparser = Parser('TVGG16')\nparser.add_argument('--add',default='addtion',type=str)\n# dynamicly assign to defined option, for example\nparser.add('--epoch','1').add('--debug')\neng = Engine(parser,experiment_name)\n```\n\n#### ImageFolderLMDB\n\n```python\nfrom torchfurnace import ImageFolderLMDB\n```\n\nThis component is a tool to accelerate data reading speed. Especially, your dataset folder should have a specific named regular just like the regular in `from torchvision.datasets import ImageFolder`\n\nLike this:\n\n```\ndemo_dataset/\n\u251c\u2500\u2500 train\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cat\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 001.jpg\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dog\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 001.jpg\n\u2514\u2500\u2500 val\n    \u251c\u2500\u2500 cat\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 001.jpg\n    \u2514\u2500\u2500 dog\n        \u2514\u2500\u2500 001.jpg\n```\n\n##### make LMDB\n\n```python\nImageFolderLMDB.folder2lmdb('demo_dataset', name='train', num_workers=16)\nImageFolderLMDB.folder2lmdb('demo_dataset', name='val', num_workers=16)\n```\n\n##### use LMDB\n\n```python\nfrom torch.utils.data import DataLoader\n_set = ImageFolderLMDB('demo_dataset/train.lmdb')\nloader = DataLoader(_set, batch_size=1, collate_fn=lambda x: x)\n```\n\n#### ImageLMDB\n\n```python\nfrom torchfurnace import ImageLMDB\n```\n\nThis component is a tool for converting .jpg/.png to binary data and storing to LMDB. Because of reading lots of small size image always costing expensive I/O resources, it will improve speed of data loading.\n\n##### make LMDB\n\n```python\ndata_mapping = {\n   'key': [f\"{k}_{no:04}\" for k in ['dog', 'cat'] for no in range(1, 4)],\n   'pic_path': [f\"demo_dataset/{k}{no:03}.jpg\" for k in ['d', 'c'] for no in range(1, 4)]\n}\nImageLMDB.store(data_mapping, 'demo_imgs_db', 4800000, num_workers=16)\n```\n\n`data_mapping` provide key and picture path.\n\n##### read LMDB\n\n```python\nimport matplotlib.pyplot as plt\nread_keys = {\n    'key': [f\"{k}_{no:04}\" for k in ['dog', 'cat'] for no in range(1, 4)]\n}\n\nfor key in data_mapping['key']:\n    img = ImageLMDB.read('demo_imgs_db', key)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\n```\n\nThe data from LMDB format is PIL object, so you can do other image processing, such as random crop, random flip and normalize using `torchvision.transforms.Compose`\n\n#### Compute mean and std\n\nCompute the mean and std value of dataset using GPU.\n\n```python\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torchfurnace.utils.function import get_mean_and_std\n\nts = transforms.Compose([transforms.ToTensor()])\ntrainset = CIFAR10(root='data', train=True, download=True, transform=ts)\nmean, std = get_mean_and_std(trainset)\nprint(mean, std)\n```\n\n#### Model Summary\n\nThis tool comes from [pytorch-summary](https://github.com/sksq96/pytorch-summary/).\n\n```python\nimport torchvision\nfrom torchfurnace.utils.torch_summary import summary, summary_string\nnet = torchvision.models.vgg16()\n\n# this function will output result on screen.  \nsummary(net,(3,224,224))\n\n# this funcion will return a string of description.\ndesc = summary_string(net,(3,224,224))\n```\n\n## Directory Architecture\n\n```text\nTVGG16/\n\u251c\u2500\u2500 logs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 CIFAR10\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 log.txt\n\u251c\u2500\u2500 models\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 CIFAR10\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 architecture.txt\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 checkpoint\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 best\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 run_config.json\n\u2514\u2500\u2500 tensorboard\n    \u2514\u2500\u2500 CIFAR10\n        \u2514\u2500\u2500 events.out.tfevents\n```\n\n`TVGG16`: the root of your work name\n\n`CIFAR10`: one of experiment name\n\n`TVGG16/logs`: all kinds of experiments output files\n\n`TVGG16/models`: all kinds of experiments checkpoints, network architectures and run configurations\n\n`TVGG16/tensorboard`: all kinds of experiments outputs of tensorboard\n\n## Testing & Example\n\nIn this section, you have to `git clone https://github.com/tianyu-su/torchfurnace.git`. \n\n1. `torchfurnace/tests/test_furnace.py` A unit test for `Engine`.\n2. `torchfurnace/tests/test_tracer.py` A unit test for `Tracer`.\n3. `torchfurnace/tests/test_img2lmdb.py` A unit test for convert images to LMDB.\n4. `torchfurnace/tests/test_vgg16.py` A compare experiment with [pytorch-cifar](https://github.com/kuangliu/pytorch-cifar/blob/master/main.py) to validate pipeline of the proposed framework. \n\n## More Usages\n\nFollowing methods are based on default setup.\n\n1. open debug mode:  `--debug`  this mode is easy to debug.\n2. close  tensorboard:  `--no_tb`\n3. open process bar:  `--p_bar`\n4. change total data directory: `--work_dir your_path`\n5. remain best checkpoint Top k: `--clean_up k` \n6. run again with same setup meanwhile remaining old data. `--nowtime_exp`\n7. make special marks for model checkpoint or other aspects: `--ext sp1`\n8. make special marks for experiment name: `--exp_suffix`\n\nOther  settings please look at [ops](#print-default-options).\n\n# TODO\n\n- [ ] `DistributedDataParallel` \n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/tianyu-su/torchfurnace", "keywords": "pytorch,tracer,engine,torchfurnace", "license": "MIT License", "maintainer": "TianyuSu", "maintainer_email": "tyanyu.su@gmail.com", "name": "torchfurnace", "package_url": "https://pypi.org/project/torchfurnace/", "platform": "any", "project_url": "https://pypi.org/project/torchfurnace/", "project_urls": {"Homepage": "https://github.com/tianyu-su/torchfurnace"}, "release_url": "https://pypi.org/project/torchfurnace/0.1.0/", "requires_dist": ["numpy (>=1.18.1)", "tqdm (>=4.42.1)", "lmdb (>=0.98)", "torch (>=1.3.1)", "torchvision (>=0.4.2)", "pyarrow (>=0.11.1)", "six (>=1.14.0)", "Pillow (>=6.1.0)", "tensorboard (>=2.1.0)"], "requires_python": ">=3.6", "summary": "A tool package for training model, pre-processing dataset and managing experiment record in pytorch AI tasks.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>torchfurnace <a href=\"https://travis-ci.com/tianyu-su/torchfurnace\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bcc6572ec9f94d3dc9e6a6a489c993ba85790883/68747470733a2f2f7472617669732d63692e636f6d2f7469616e79752d73752f746f7263686675726e6163652e7376673f6272616e63683d6d6173746572\"></a> <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/22ad2c20d71c26e843208a118a1278e87c536694/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7079746f7263682d312e312e302d626c7565\"> <img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/57dbea179626322e81d286f5ffeac0edd4380532/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362d626c7565\"></h1>\n<p><code>torchfurnace</code> is a tool package for training model, pre-processing dataset and managing experiment record in pytorch AI tasks.</p>\n<h2>Quick Start</h2>\n<h3>Usage</h3>\n<p><code>pip install torchfurnace</code></p>\n<h3>Example</h3>\n<p>VGG16 for CIFAR10</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch.nn.functional</span> <span class=\"k\">as</span> <span class=\"nn\">F</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.models</span> <span class=\"k\">as</span> <span class=\"nn\">models</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"k\">as</span> <span class=\"nn\">transforms</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">CIFAR10</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.optim.lr_scheduler</span> <span class=\"kn\">import</span> <span class=\"n\">MultiStepLR</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">Engine</span><span class=\"p\">,</span> <span class=\"n\">Parser</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchfurnace.utils.function</span> <span class=\"kn\">import</span> <span class=\"n\">accuracy</span>\n\n<span class=\"c1\"># define training process of your model</span>\n<span class=\"k\">class</span> <span class=\"nc\">VGGNetEngine</span><span class=\"p\">(</span><span class=\"n\">Engine</span><span class=\"p\">):</span>\n    <span class=\"nd\">@staticmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_on_forward</span><span class=\"p\">(</span><span class=\"n\">training</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">inp</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">dict</span><span class=\"p\">:</span>\n        <span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'loss'</span><span class=\"p\">:</span> <span class=\"nb\">object</span><span class=\"p\">,</span> <span class=\"s1\">'acc1'</span><span class=\"p\">:</span> <span class=\"nb\">object</span><span class=\"p\">,</span> <span class=\"s1\">'acc5'</span><span class=\"p\">:</span> <span class=\"nb\">object</span><span class=\"p\">}</span>\n        <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">inp</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">training</span><span class=\"p\">:</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n            <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n\n        <span class=\"n\">acc1</span><span class=\"p\">,</span> <span class=\"n\">acc5</span> <span class=\"o\">=</span> <span class=\"n\">accuracy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">topk</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n        <span class=\"n\">ret</span><span class=\"p\">[</span><span class=\"s1\">'loss'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"n\">ret</span><span class=\"p\">[</span><span class=\"s1\">'acc1'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc1</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"n\">ret</span><span class=\"p\">[</span><span class=\"s1\">'acc5'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc5</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">ret</span>\n\n    <span class=\"nd\">@staticmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_get_lr_scheduler</span><span class=\"p\">(</span><span class=\"n\">optim</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">list</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">MultiStepLR</span><span class=\"p\">(</span><span class=\"n\">optim</span><span class=\"p\">,</span> <span class=\"n\">milestones</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">150</span><span class=\"p\">,</span> <span class=\"mi\">250</span><span class=\"p\">,</span> <span class=\"mi\">350</span><span class=\"p\">],</span> <span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)]</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">():</span>\n    <span class=\"c1\"># define experiment name</span>\n    <span class=\"n\">parser</span> <span class=\"o\">=</span> <span class=\"n\">Parser</span><span class=\"p\">(</span><span class=\"s1\">'TVGG16'</span><span class=\"p\">)</span>\n    <span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">parse_args</span><span class=\"p\">()</span>\n    <span class=\"n\">experiment_name</span> <span class=\"o\">=</span> <span class=\"s1\">'_'</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">([</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">dataset</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">exp_suffix</span><span class=\"p\">])</span>\n\n    <span class=\"c1\"># Data</span>\n    <span class=\"n\">ts</span> <span class=\"o\">=</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">([</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">(),</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Normalize</span><span class=\"p\">(</span>\n        <span class=\"p\">(</span><span class=\"mf\">0.4914</span><span class=\"p\">,</span> <span class=\"mf\">0.4822</span><span class=\"p\">,</span> <span class=\"mf\">0.4465</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mf\">0.2023</span><span class=\"p\">,</span> <span class=\"mf\">0.1994</span><span class=\"p\">,</span> <span class=\"mf\">0.2010</span><span class=\"p\">))])</span>\n    <span class=\"n\">trainset</span> <span class=\"o\">=</span> <span class=\"n\">CIFAR10</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s1\">'data'</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">ts</span><span class=\"p\">)</span>\n    <span class=\"n\">testset</span> <span class=\"o\">=</span> <span class=\"n\">CIFAR10</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s1\">'data'</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">ts</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># define model and optimizer</span>\n    <span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">vgg16</span><span class=\"p\">(</span><span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n    <span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">avgpool</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">AvgPool2d</span><span class=\"p\">(</span><span class=\"n\">kernel_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">stride</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">512</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n    <span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n\n    <span class=\"c1\"># new engine instance</span>\n    <span class=\"n\">eng</span> <span class=\"o\">=</span> <span class=\"n\">VGGNetEngine</span><span class=\"p\">(</span><span class=\"n\">parser</span><span class=\"p\">,</span><span class=\"n\">experiment_name</span><span class=\"p\">)</span>\n    <span class=\"n\">acc1</span> <span class=\"o\">=</span> <span class=\"n\">eng</span><span class=\"o\">.</span><span class=\"n\">learning</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">trainset</span><span class=\"p\">,</span> <span class=\"n\">testset</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Acc1:'</span><span class=\"p\">,</span> <span class=\"n\">acc1</span><span class=\"p\">)</span>\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"kn\">import</span> <span class=\"nn\">sys</span>\n    <span class=\"n\">run_params</span> <span class=\"o\">=</span> <span class=\"s1\">'--dataset CIFAR10 -lr 0.1 -bs 128 -j 2 --epochs 400 --adjust_lr'</span>\n    <span class=\"n\">sys</span><span class=\"o\">.</span><span class=\"n\">argv</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">run_params</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">())</span>\n    <span class=\"n\">main</span><span class=\"p\">()</span>\n</pre>\n<h2>Introduction</h2>\n<h3>Why do this?</h3>\n<p>There are some deep learning frameworks to quickly build a training system in pytorch AI tasks, however, I found that most of them are complex framework which have higher cost for learning it and seriously invade original code , for instance, maybe modify your model class to adapt the framework.</p>\n<p>So, <code>torchfurnace</code> is born for performing your pytorch AI task quickly, simply and without invasion viz you don't have to change too much defined code.</p>\n<h3>What features?</h3>\n<ol>\n<li>\n<p><code>torchfurnace</code> consists of two independent components including <code>engine</code> and <code>tracer</code>. <code>engine</code> is a core component of proposed framework, and <code>tracer</code> is a manager of experiment whose obligation include log writing, model saving and training visualization.</p>\n</li>\n<li>\n<p><code>torchfurnace</code> integrates some practical tools, such as processing raw dataset to LMDB for solving I/O bottleneck and computing the number of parameter size and dataset with std and mean.</p>\n</li>\n</ol>\n<h3>Components</h3>\n<h4>Engine</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">Engine</span>\n</pre>\n<p>This is core component of the proposed framework. <code>Engine</code> is an abstract class which controls the whole workflow to finish AI tasks. So, you have to implement <code>_on_forward</code> by inheriting the <code>Engine</code> when you start. The job of <code>_on_forward</code> is to define which criterion to use and how to optimize your model.</p>\n<p>For example (a minimal configuration):</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">VGGNetEngine</span><span class=\"p\">(</span><span class=\"n\">Engine</span><span class=\"p\">):</span>\n    <span class=\"nd\">@staticmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">_on_forward</span><span class=\"p\">(</span><span class=\"n\">training</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">inp</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">dict</span><span class=\"p\">:</span>\n        <span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'loss'</span><span class=\"p\">:</span> <span class=\"nb\">object</span><span class=\"p\">,</span> <span class=\"s1\">'acc1'</span><span class=\"p\">:</span> <span class=\"nb\">object</span><span class=\"p\">,</span> <span class=\"s1\">'acc5'</span><span class=\"p\">:</span> <span class=\"nb\">object</span><span class=\"p\">}</span>\n        <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">inp</span><span class=\"p\">)</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">training</span><span class=\"p\">:</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n            <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n            <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n\n        <span class=\"n\">acc1</span><span class=\"p\">,</span> <span class=\"n\">acc5</span> <span class=\"o\">=</span> <span class=\"n\">accuracy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">,</span> <span class=\"n\">topk</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">))</span>\n        <span class=\"n\">ret</span><span class=\"p\">[</span><span class=\"s1\">'loss'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"n\">ret</span><span class=\"p\">[</span><span class=\"s1\">'acc1'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc1</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"n\">ret</span><span class=\"p\">[</span><span class=\"s1\">'acc5'</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">acc5</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"n\">ret</span>\n</pre>\n<p>Above,  you have done the preparatory work of framework, and then you define model, train dataset, val dataset and optimizer as usual. This highlights the advantages of our method which don't  heavily invade original code. In other words, you don't have to modify your code too much.  As follow, only 3 lines to finish learning. Of course, you can also assign a list type as model and optimizer, however, it's vital each element of models and optimizer must be matched.</p>\n<pre><span class=\"n\">parser</span> <span class=\"o\">=</span> <span class=\"n\">Parser</span><span class=\"p\">(</span><span class=\"s1\">'TVGG11'</span><span class=\"p\">)</span>\n<span class=\"n\">eng</span> <span class=\"o\">=</span> <span class=\"n\">VGGNetEngine</span><span class=\"p\">(</span><span class=\"n\">parser</span><span class=\"err\">\uff0c</span><span class=\"n\">experiment_name</span><span class=\"p\">)</span>\n<span class=\"n\">eng</span><span class=\"o\">.</span><span class=\"n\">learning</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">train_ds</span><span class=\"p\">,</span> <span class=\"n\">val_ds</span><span class=\"p\">)</span>\n</pre>\n<p>If you want more customizable features, you can override them with the following listed functions.</p>\n<h5>overridden function</h5>\n<ol>\n<li><code>_get_lr_scheduler</code>: This function support to define other scheduler in <code>torch.optim.lr_scheduler</code>. Default:  StepLR with gamma=0.1 and step_size=30</li>\n<li><code>_on_start_epoch</code>: You can add some meters , such as AverageMeter using <code>from torchfurnace.utils.meter import AverageMeter</code> in this function when you want to record more information in the training processing.</li>\n<li><code>_on_start_batch</code>: define how to get input and target  from your dataset and put them on GPU.</li>\n<li><code>_add_on_end_batch_log</code>: You can add some log output information just like other meters in <code>_on_end_batch</code>.</li>\n<li><code>_add_on_end_batch_tb</code>:  You can add some tensorboard output information just like other meters in <code>_on_end_batch</code>.</li>\n<li><code>_add_record</code>:  you can add some record after <code>_on_forward</code></li>\n<li><code>_before_evaluate</code>: define your operation before calling <code>_validate</code>  evaluation mode</li>\n<li><code>_after_evaluate</code>: define your operation after calling <code>_validate</code> evaluation mode</li>\n</ol>\n<h4>Tracer</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">Tracer</span>\n</pre>\n<p>The  responsibility of this component is to manage  log writing, model saving and training visualization in experiment.</p>\n<p>Especially, this component can run independently, meanwhile, it is integrated in <code>Engine</code> as a nested object to manage experiment record.</p>\n<p>For example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">Tracer</span>\n<span class=\"n\">tracer</span> <span class=\"o\">=</span> <span class=\"n\">Tracer</span><span class=\"p\">(</span><span class=\"n\">root_dir</span><span class=\"o\">=</span><span class=\"n\">Path</span><span class=\"p\">(</span><span class=\"s1\">'.'</span><span class=\"p\">),</span><span class=\"n\">work_name</span><span class=\"o\">=</span> <span class=\"s1\">'mine_network'</span><span class=\"p\">)</span>\\\n    <span class=\"o\">.</span><span class=\"n\">attach</span><span class=\"p\">(</span><span class=\"n\">experiment_name</span><span class=\"o\">=</span><span class=\"s1\">'exp'</span><span class=\"p\">,</span> <span class=\"n\">logger_name</span><span class=\"o\">=</span><span class=\"s1\">'log'</span><span class=\"p\">,</span> <span class=\"n\">override</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<h5>save experiment configuration</h5>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchfurnace.utils.tracer_component</span> <span class=\"k\">as</span> <span class=\"nn\">tc</span>\n<span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"optimizer\"</span><span class=\"p\">:</span> <span class=\"n\">optim</span><span class=\"p\">,</span> <span class=\"s1\">'addtion'</span><span class=\"p\">:</span> <span class=\"s1\">'hhh'</span><span class=\"p\">}</span>\n<span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">Config</span><span class=\"p\">({</span><span class=\"o\">**</span><span class=\"n\">cfg</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"nb\">vars</span><span class=\"p\">(</span><span class=\"n\">Parser</span><span class=\"p\">(</span><span class=\"s1\">'my_network'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">parse_args</span><span class=\"p\">())}))</span>\n</pre>\n<p>cfg: some customize information</p>\n<p>Parser('my_network').parse_args() : parser snapshot</p>\n<h5>save checkpoint</h5>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchfurnace.utils.tracer_component</span> <span class=\"k\">as</span> <span class=\"nn\">tc</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">vgg11</span><span class=\"p\">(</span><span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n<span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span>\n        <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"vm\">__class__</span><span class=\"o\">.</span><span class=\"vm\">__name__</span><span class=\"si\">}</span><span class=\"s2\">_extinfo.pth.tar\"</span><span class=\"p\">,</span>\n        <span class=\"p\">{</span>\n            <span class=\"s1\">'epoch'</span><span class=\"p\">:</span> <span class=\"mi\">99</span><span class=\"p\">,</span>\n            <span class=\"s1\">'arch'</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">),</span>\n            <span class=\"s1\">'state_dict'</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span>\n            <span class=\"s1\">'best_acc1'</span><span class=\"p\">:</span> <span class=\"mf\">0.66</span><span class=\"p\">,</span>\n            <span class=\"s1\">'optimizer'</span><span class=\"p\">:</span> <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">state_dict</span><span class=\"p\">(),</span>\n        <span class=\"p\">},</span> <span class=\"kc\">True</span><span class=\"p\">))</span>\n</pre>\n<p>save checkpoint to appropriate location automatically.</p>\n<h5>load checkpoint</h5>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchfurnace.utils.tracer_component</span> <span class=\"k\">as</span> <span class=\"nn\">tc</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">vgg11</span><span class=\"p\">(</span><span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">())</span>\n<span class=\"c1\"># 'pth' has fix format. It contains two parts,</span>\n<span class=\"c1\">#  which are experiment file name and best model file name,</span>\n<span class=\"c1\">#  skipping medial path , and they are separate by '/' .</span>\n<span class=\"n\">pth</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"expn/</span><span class=\"si\">{</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"vm\">__class__</span><span class=\"o\">.</span><span class=\"vm\">__name__</span><span class=\"si\">}</span><span class=\"s2\">_Epk</span><span class=\"si\">{</span><span class=\"mi\">99</span><span class=\"si\">}</span><span class=\"s2\">_Acc</span><span class=\"si\">{</span><span class=\"mf\">0.66</span><span class=\"si\">}</span><span class=\"s2\">_extinfo_best.pth.tar\"</span>\n<span class=\"n\">ret</span> <span class=\"o\">=</span> <span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">tc</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span>\n        <span class=\"n\">pth</span><span class=\"p\">,</span> <span class=\"p\">{</span>\n            <span class=\"s1\">'model'</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"p\">,</span>\n            <span class=\"s1\">'optim'</span><span class=\"p\">:</span> <span class=\"n\">optimizer</span>\n        <span class=\"p\">}))</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">ret</span><span class=\"p\">)</span>\n<span class=\"c1\"># ret has start_epoch and best_acc1</span>\n</pre>\n<p>load checkpoint from appropriate location automatically.</p>\n<p><strong>Note:</strong> <code>--resume</code> is assigned just like <code>pth</code></p>\n<h5>display TensorBoard</h5>\n<pre><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">tb_switch</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">tb_switch</span><span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<h5>redirect output</h5>\n<pre><span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">debug_switch</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">tracer</span><span class=\"o\">.</span><span class=\"n\">debug_switch</span><span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<h4>Parser</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">Parser</span>\n</pre>\n<p>This just is an  <code>ArgumentParser</code>, but have defined some frequently-used options.</p>\n<h5>print default options</h5>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">Parser</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">Parser</span><span class=\"p\">()</span>\n<span class=\"n\">args</span> <span class=\"o\">=</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">parse_args</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">args</span><span class=\"p\">)</span>\n</pre>\n<pre><span class=\"p\">{</span>\n    <span class=\"nt\">\"dataset\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"batch_size\"</span><span class=\"p\">:</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"workers\"</span><span class=\"p\">:</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"lr\"</span><span class=\"p\">:</span><span class=\"mf\">0.01</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"weight_decay\"</span><span class=\"p\">:</span><span class=\"mf\">0.0005</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"momentum\"</span><span class=\"p\">:</span><span class=\"mf\">0.9</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"dropout\"</span><span class=\"p\">:</span><span class=\"mf\">0.5</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"start_epoch\"</span><span class=\"p\">:</span><span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"epochs\"</span><span class=\"p\">:</span><span class=\"mi\">200</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"gpu\"</span><span class=\"p\">:</span><span class=\"s2\">\"0\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"exp_suffix\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"extension\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"resume\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"evaluate\"</span><span class=\"p\">:</span><span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"deterministic\"</span><span class=\"p\">:</span><span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"adjust_lr\"</span><span class=\"p\">:</span><span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"print_freq\"</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"logger_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"log.txt\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"work_dir\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"clean_up\"</span><span class=\"p\">:</span><span class=\"mi\">5</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"debug\"</span><span class=\"p\">:</span><span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"p_bar\"</span><span class=\"p\">:</span><span class=\"kc\">false</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"no_tb\"</span><span class=\"p\">:</span><span class=\"kc\">true</span><span class=\"p\">,</span>\n    <span class=\"nt\">\"nowtime_exp\"</span><span class=\"p\">:</span><span class=\"kc\">true</span>\n<span class=\"p\">}</span>\n</pre>\n<p>Also, you can open <code>from torchfurnace import Parser</code> to get more information.</p>\n<h5>add option to engine</h5>\n<pre><span class=\"n\">parser</span> <span class=\"o\">=</span> <span class=\"n\">Parser</span><span class=\"p\">(</span><span class=\"s1\">'TVGG16'</span><span class=\"p\">)</span>\n<span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">add_argument</span><span class=\"p\">(</span><span class=\"s1\">'--add'</span><span class=\"p\">,</span><span class=\"n\">default</span><span class=\"o\">=</span><span class=\"s1\">'addtion'</span><span class=\"p\">,</span><span class=\"nb\">type</span><span class=\"o\">=</span><span class=\"nb\">str</span><span class=\"p\">)</span>\n<span class=\"c1\"># dynamicly assign to defined option, for example</span>\n<span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"s1\">'--epoch'</span><span class=\"p\">,</span><span class=\"s1\">'1'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"s1\">'--debug'</span><span class=\"p\">)</span>\n<span class=\"n\">eng</span> <span class=\"o\">=</span> <span class=\"n\">Engine</span><span class=\"p\">(</span><span class=\"n\">parser</span><span class=\"p\">,</span><span class=\"n\">experiment_name</span><span class=\"p\">)</span>\n</pre>\n<h4>ImageFolderLMDB</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">ImageFolderLMDB</span>\n</pre>\n<p>This component is a tool to accelerate data reading speed. Especially, your dataset folder should have a specific named regular just like the regular in <code>from torchvision.datasets import ImageFolder</code></p>\n<p>Like this:</p>\n<pre><code>demo_dataset/\n\u251c\u2500\u2500 train\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cat\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 001.jpg\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dog\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 001.jpg\n\u2514\u2500\u2500 val\n    \u251c\u2500\u2500 cat\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 001.jpg\n    \u2514\u2500\u2500 dog\n        \u2514\u2500\u2500 001.jpg\n</code></pre>\n<h5>make LMDB</h5>\n<pre><span class=\"n\">ImageFolderLMDB</span><span class=\"o\">.</span><span class=\"n\">folder2lmdb</span><span class=\"p\">(</span><span class=\"s1\">'demo_dataset'</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'train'</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">)</span>\n<span class=\"n\">ImageFolderLMDB</span><span class=\"o\">.</span><span class=\"n\">folder2lmdb</span><span class=\"p\">(</span><span class=\"s1\">'demo_dataset'</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'val'</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">)</span>\n</pre>\n<h5>use LMDB</h5>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torch.utils.data</span> <span class=\"kn\">import</span> <span class=\"n\">DataLoader</span>\n<span class=\"n\">_set</span> <span class=\"o\">=</span> <span class=\"n\">ImageFolderLMDB</span><span class=\"p\">(</span><span class=\"s1\">'demo_dataset/train.lmdb'</span><span class=\"p\">)</span>\n<span class=\"n\">loader</span> <span class=\"o\">=</span> <span class=\"n\">DataLoader</span><span class=\"p\">(</span><span class=\"n\">_set</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">collate_fn</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"p\">)</span>\n</pre>\n<h4>ImageLMDB</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchfurnace</span> <span class=\"kn\">import</span> <span class=\"n\">ImageLMDB</span>\n</pre>\n<p>This component is a tool for converting .jpg/.png to binary data and storing to LMDB. Because of reading lots of small size image always costing expensive I/O resources, it will improve speed of data loading.</p>\n<h5>make LMDB</h5>\n<pre><span class=\"n\">data_mapping</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n   <span class=\"s1\">'key'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">k</span><span class=\"si\">}</span><span class=\"s2\">_</span><span class=\"si\">{</span><span class=\"n\">no</span><span class=\"si\">:</span><span class=\"s2\">04</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">'dog'</span><span class=\"p\">,</span> <span class=\"s1\">'cat'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">no</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)],</span>\n   <span class=\"s1\">'pic_path'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"sa\">f</span><span class=\"s2\">\"demo_dataset/</span><span class=\"si\">{</span><span class=\"n\">k</span><span class=\"si\">}{</span><span class=\"n\">no</span><span class=\"si\">:</span><span class=\"s2\">03</span><span class=\"si\">}</span><span class=\"s2\">.jpg\"</span> <span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">'d'</span><span class=\"p\">,</span> <span class=\"s1\">'c'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">no</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)]</span>\n<span class=\"p\">}</span>\n<span class=\"n\">ImageLMDB</span><span class=\"o\">.</span><span class=\"n\">store</span><span class=\"p\">(</span><span class=\"n\">data_mapping</span><span class=\"p\">,</span> <span class=\"s1\">'demo_imgs_db'</span><span class=\"p\">,</span> <span class=\"mi\">4800000</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">16</span><span class=\"p\">)</span>\n</pre>\n<p><code>data_mapping</code> provide key and picture path.</p>\n<h5>read LMDB</h5>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n<span class=\"n\">read_keys</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'key'</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">k</span><span class=\"si\">}</span><span class=\"s2\">_</span><span class=\"si\">{</span><span class=\"n\">no</span><span class=\"si\">:</span><span class=\"s2\">04</span><span class=\"si\">}</span><span class=\"s2\">\"</span> <span class=\"k\">for</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s1\">'dog'</span><span class=\"p\">,</span> <span class=\"s1\">'cat'</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">no</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">)]</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">for</span> <span class=\"n\">key</span> <span class=\"ow\">in</span> <span class=\"n\">data_mapping</span><span class=\"p\">[</span><span class=\"s1\">'key'</span><span class=\"p\">]:</span>\n    <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">ImageLMDB</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">(</span><span class=\"s1\">'demo_imgs_db'</span><span class=\"p\">,</span> <span class=\"n\">key</span><span class=\"p\">)</span>\n    <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>\n    <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"p\">(</span><span class=\"s1\">'off'</span><span class=\"p\">)</span>\n    <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n</pre>\n<p>The data from LMDB format is PIL object, so you can do other image processing, such as random crop, random flip and normalize using <code>torchvision.transforms.Compose</code></p>\n<h4>Compute mean and std</h4>\n<p>Compute the mean and std value of dataset using GPU.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision.transforms</span> <span class=\"k\">as</span> <span class=\"nn\">transforms</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">CIFAR10</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchfurnace.utils.function</span> <span class=\"kn\">import</span> <span class=\"n\">get_mean_and_std</span>\n\n<span class=\"n\">ts</span> <span class=\"o\">=</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">([</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">()])</span>\n<span class=\"n\">trainset</span> <span class=\"o\">=</span> <span class=\"n\">CIFAR10</span><span class=\"p\">(</span><span class=\"n\">root</span><span class=\"o\">=</span><span class=\"s1\">'data'</span><span class=\"p\">,</span> <span class=\"n\">train</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">download</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">transform</span><span class=\"o\">=</span><span class=\"n\">ts</span><span class=\"p\">)</span>\n<span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">std</span> <span class=\"o\">=</span> <span class=\"n\">get_mean_and_std</span><span class=\"p\">(</span><span class=\"n\">trainset</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">mean</span><span class=\"p\">,</span> <span class=\"n\">std</span><span class=\"p\">)</span>\n</pre>\n<h4>Model Summary</h4>\n<p>This tool comes from <a href=\"https://github.com/sksq96/pytorch-summary/\" rel=\"nofollow\">pytorch-summary</a>.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torchvision</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchfurnace.utils.torch_summary</span> <span class=\"kn\">import</span> <span class=\"n\">summary</span><span class=\"p\">,</span> <span class=\"n\">summary_string</span>\n<span class=\"n\">net</span> <span class=\"o\">=</span> <span class=\"n\">torchvision</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">vgg16</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># this function will output result on screen.  </span>\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">,(</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># this funcion will return a string of description.</span>\n<span class=\"n\">desc</span> <span class=\"o\">=</span> <span class=\"n\">summary_string</span><span class=\"p\">(</span><span class=\"n\">net</span><span class=\"p\">,(</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">))</span>\n</pre>\n<h2>Directory Architecture</h2>\n<pre>TVGG16/\n\u251c\u2500\u2500 logs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 CIFAR10\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 log.txt\n\u251c\u2500\u2500 models\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 CIFAR10\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 architecture.txt\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 checkpoint\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 best\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 run_config.json\n\u2514\u2500\u2500 tensorboard\n    \u2514\u2500\u2500 CIFAR10\n        \u2514\u2500\u2500 events.out.tfevents\n</pre>\n<p><code>TVGG16</code>: the root of your work name</p>\n<p><code>CIFAR10</code>: one of experiment name</p>\n<p><code>TVGG16/logs</code>: all kinds of experiments output files</p>\n<p><code>TVGG16/models</code>: all kinds of experiments checkpoints, network architectures and run configurations</p>\n<p><code>TVGG16/tensorboard</code>: all kinds of experiments outputs of tensorboard</p>\n<h2>Testing &amp; Example</h2>\n<p>In this section, you have to <code>git clone https://github.com/tianyu-su/torchfurnace.git</code>.</p>\n<ol>\n<li><code>torchfurnace/tests/test_furnace.py</code> A unit test for <code>Engine</code>.</li>\n<li><code>torchfurnace/tests/test_tracer.py</code> A unit test for <code>Tracer</code>.</li>\n<li><code>torchfurnace/tests/test_img2lmdb.py</code> A unit test for convert images to LMDB.</li>\n<li><code>torchfurnace/tests/test_vgg16.py</code> A compare experiment with <a href=\"https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\" rel=\"nofollow\">pytorch-cifar</a> to validate pipeline of the proposed framework.</li>\n</ol>\n<h2>More Usages</h2>\n<p>Following methods are based on default setup.</p>\n<ol>\n<li>open debug mode:  <code>--debug</code>  this mode is easy to debug.</li>\n<li>close  tensorboard:  <code>--no_tb</code></li>\n<li>open process bar:  <code>--p_bar</code></li>\n<li>change total data directory: <code>--work_dir your_path</code></li>\n<li>remain best checkpoint Top k: <code>--clean_up k</code></li>\n<li>run again with same setup meanwhile remaining old data. <code>--nowtime_exp</code></li>\n<li>make special marks for model checkpoint or other aspects: <code>--ext sp1</code></li>\n<li>make special marks for experiment name: <code>--exp_suffix</code></li>\n</ol>\n<p>Other  settings please look at <a href=\"#print-default-options\" rel=\"nofollow\">ops</a>.</p>\n<h1>TODO</h1>\n<ul>\n<li>[ ] <code>DistributedDataParallel</code></li>\n</ul>\n\n          </div>"}, "last_serial": 7105952, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "a22a573e9753273bc4061b69ec6a514f", "sha256": "ad403e13c3d8c6078173f07a2688a1c2a4a1294edd1dbba5f2cb15c332abb1f5"}, "downloads": -1, "filename": "torchfurnace-0.0.2.tar.gz", "has_sig": false, "md5_digest": "a22a573e9753273bc4061b69ec6a514f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14022, "upload_time": "2020-03-21T10:02:56", "upload_time_iso_8601": "2020-03-21T10:02:56.063182Z", "url": "https://files.pythonhosted.org/packages/0d/17/c4b94c247056a38a545029aaa9d19fd2f65aeae6d977213060149e0c7aef/torchfurnace-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "44129f8669f1067bde043593e27725f6", "sha256": "77f2eac12c8e2aa5eb087cafd48c9b67175c8e673d306538fb21d40834ca810e"}, "downloads": -1, "filename": "torchfurnace-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "44129f8669f1067bde043593e27725f6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 16937, "upload_time": "2020-03-21T10:20:26", "upload_time_iso_8601": "2020-03-21T10:20:26.925147Z", "url": "https://files.pythonhosted.org/packages/9f/fa/a45c7d3e5ce0714fbc2adf0dd07a2c10f1879a36a449fee59db077334b66/torchfurnace-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eec48d3dccef4263b3d948b898467527", "sha256": "016408d5aae3965613b06605d89798d08de3ce9400ee66530fe722cc3b145bae"}, "downloads": -1, "filename": "torchfurnace-0.0.3.tar.gz", "has_sig": false, "md5_digest": "eec48d3dccef4263b3d948b898467527", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 13046, "upload_time": "2020-03-21T10:20:28", "upload_time_iso_8601": "2020-03-21T10:20:28.192808Z", "url": "https://files.pythonhosted.org/packages/12/d7/2ef11a2ea16b0112db1015768245179d52cb8c0e089385499947f706a8a0/torchfurnace-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "70f439c5b25b6752c041cb46bfe35c1e", "sha256": "930c07ab7ac3a152364c73374d985fcefc99c4209ac3ebd07106df4525330ef1"}, "downloads": -1, "filename": "torchfurnace-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "70f439c5b25b6752c041cb46bfe35c1e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 19229, "upload_time": "2020-03-22T17:31:05", "upload_time_iso_8601": "2020-03-22T17:31:05.689191Z", "url": "https://files.pythonhosted.org/packages/08/cf/82dbef4412e3cf3aa4ff2536f4b48d3f3a34c5144f33887f4cf5f1b9793e/torchfurnace-0.0.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "822cab970a5a3aa8226487cd22a13035", "sha256": "d1e0301b91f6b847b5b28d9bfcbfe44404ebe875a234a12d752f92dc88898401"}, "downloads": -1, "filename": "torchfurnace-0.0.4.tar.gz", "has_sig": false, "md5_digest": "822cab970a5a3aa8226487cd22a13035", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 17287, "upload_time": "2020-03-22T17:31:06", "upload_time_iso_8601": "2020-03-22T17:31:06.960158Z", "url": "https://files.pythonhosted.org/packages/cd/25/5981ea3ac7abe68ea02793d75347778f5cc88d2a348ebdb279ab2f138c0a/torchfurnace-0.0.4.tar.gz", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "87c94e237385df6a770e3ed602a63d6d", "sha256": "83013c5826ec695b6facb4584dc20064e74960bf00d2b245db6c02af4cf86008"}, "downloads": -1, "filename": "torchfurnace-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "87c94e237385df6a770e3ed602a63d6d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22208, "upload_time": "2020-03-23T16:00:27", "upload_time_iso_8601": "2020-03-23T16:00:27.354790Z", "url": "https://files.pythonhosted.org/packages/52/6a/a08f82f8decb91e661f70669a213a3fbbea4206b44bbb87a88afbef53af1/torchfurnace-0.0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2c704d424f054e272fc6b6a94d929eee", "sha256": "ee97c7ac32841f574f1a98dcd82662813c6d0fa20820c7a790f8128b3e59c990"}, "downloads": -1, "filename": "torchfurnace-0.0.5.tar.gz", "has_sig": false, "md5_digest": "2c704d424f054e272fc6b6a94d929eee", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 23211, "upload_time": "2020-03-23T16:00:28", "upload_time_iso_8601": "2020-03-23T16:00:28.761730Z", "url": "https://files.pythonhosted.org/packages/35/ea/5fbb70ea5b4d8bdaee8e8699f03a120eb6706ffa527357b199bd7d41b51a/torchfurnace-0.0.5.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "bbafe691feab2259b0c7f2fe74d04199", "sha256": "e9a3f44a5cc2f0d488ac7acc370d69140e695c8bbe8712bfbd5514bd1a415aee"}, "downloads": -1, "filename": "torchfurnace-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "bbafe691feab2259b0c7f2fe74d04199", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 22199, "upload_time": "2020-03-27T09:10:33", "upload_time_iso_8601": "2020-03-27T09:10:33.044027Z", "url": "https://files.pythonhosted.org/packages/00/7a/b0ec52b521ea11a0cef328245cd640c105a533aa64b56806f8082c7815fe/torchfurnace-0.0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8a8466f6a6854c200ad5cfbbbcaa8386", "sha256": "4010e1ecff473b225fde031e3292bdfc16271f202f0529e58b665bd38131dc93"}, "downloads": -1, "filename": "torchfurnace-0.0.6.tar.gz", "has_sig": false, "md5_digest": "8a8466f6a6854c200ad5cfbbbcaa8386", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 23569, "upload_time": "2020-03-27T09:10:34", "upload_time_iso_8601": "2020-03-27T09:10:34.335396Z", "url": "https://files.pythonhosted.org/packages/85/b6/636ff0711da8a869270b0abe97d4cfa0090d6528eca6f93a5c20c433e4f3/torchfurnace-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "fe7eeb64eba1e49116f4dcef2b9f3d97", "sha256": "7c9cbc62c99d11f33031e8c464b2a1d4a4745d115468bf6bb42b7eadfc99f8e5"}, "downloads": -1, "filename": "torchfurnace-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "fe7eeb64eba1e49116f4dcef2b9f3d97", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 23067, "upload_time": "2020-04-06T10:50:20", "upload_time_iso_8601": "2020-04-06T10:50:20.251283Z", "url": "https://files.pythonhosted.org/packages/1a/41/c4c2dc811930f0589b64cebd195947904ee8ec520aeb7bd38fa111df8110/torchfurnace-0.0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82046f6e9b30297c269cdb2a476eb482", "sha256": "11e1414bb286e193e84b67fc4dc454ac14fe8c79ccd90163da3a26846289a6b9"}, "downloads": -1, "filename": "torchfurnace-0.0.7.tar.gz", "has_sig": false, "md5_digest": "82046f6e9b30297c269cdb2a476eb482", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24557, "upload_time": "2020-04-06T10:50:21", "upload_time_iso_8601": "2020-04-06T10:50:21.391069Z", "url": "https://files.pythonhosted.org/packages/ae/e3/4197026c692dd01c6befdb493a9638b01dc03efda9fd321a2686d553c09b/torchfurnace-0.0.7.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "6869bada2692e8bb87b6e18009cde099", "sha256": "81cd2c52a4e98532a0804431f21782627748f42bbc0bb670d626d5b9454e6869"}, "downloads": -1, "filename": "torchfurnace-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6869bada2692e8bb87b6e18009cde099", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 24736, "upload_time": "2020-04-26T17:17:50", "upload_time_iso_8601": "2020-04-26T17:17:50.522628Z", "url": "https://files.pythonhosted.org/packages/37/14/ed1b9e90c9051b5e36845c4f07f33a7ef079212eadef81acab21f402696e/torchfurnace-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eac4632672081951ead1d8909eee6ae0", "sha256": "8af3841220bca5d90d0f3e71761ec4bbf6f51673a781091299a91bde2f88b097"}, "downloads": -1, "filename": "torchfurnace-0.1.0.tar.gz", "has_sig": false, "md5_digest": "eac4632672081951ead1d8909eee6ae0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 26271, "upload_time": "2020-04-26T17:17:51", "upload_time_iso_8601": "2020-04-26T17:17:51.586619Z", "url": "https://files.pythonhosted.org/packages/96/7f/6019e669e8836ad5979664e8af8cddb97edf32bcd9bdae9398b12d290c05/torchfurnace-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6869bada2692e8bb87b6e18009cde099", "sha256": "81cd2c52a4e98532a0804431f21782627748f42bbc0bb670d626d5b9454e6869"}, "downloads": -1, "filename": "torchfurnace-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6869bada2692e8bb87b6e18009cde099", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 24736, "upload_time": "2020-04-26T17:17:50", "upload_time_iso_8601": "2020-04-26T17:17:50.522628Z", "url": "https://files.pythonhosted.org/packages/37/14/ed1b9e90c9051b5e36845c4f07f33a7ef079212eadef81acab21f402696e/torchfurnace-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eac4632672081951ead1d8909eee6ae0", "sha256": "8af3841220bca5d90d0f3e71761ec4bbf6f51673a781091299a91bde2f88b097"}, "downloads": -1, "filename": "torchfurnace-0.1.0.tar.gz", "has_sig": false, "md5_digest": "eac4632672081951ead1d8909eee6ae0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 26271, "upload_time": "2020-04-26T17:17:51", "upload_time_iso_8601": "2020-04-26T17:17:51.586619Z", "url": "https://files.pythonhosted.org/packages/96/7f/6019e669e8836ad5979664e8af8cddb97edf32bcd9bdae9398b12d290c05/torchfurnace-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:24 2020"}