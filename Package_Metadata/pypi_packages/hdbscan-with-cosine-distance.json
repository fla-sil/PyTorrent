{"info": {"author": "Leland McInnes", "author_email": "leland.mcinnes@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved", "Operating System :: MacOS", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Operating System :: Unix", "Programming Language :: C", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Topic :: Scientific/Engineering", "Topic :: Software Development"], "description": ".. image:: https://img.shields.io/pypi/v/hdbscan.svg\n    :target: https://pypi.python.org/pypi/hdbscan/\n    :alt: PyPI Version\n.. image:: https://anaconda.org/conda-forge/hdbscan/badges/version.svg\n    :target: https://anaconda.org/conda-forge/hdbscan\n    :alt: Conda-forge Versio\n.. image:: https://img.shields.io/pypi/l/hdbscan.svg\n    :target: https://github.com/lmcinnes/hdbscan/blob/master/LICENSE\n    :alt: License\n\n=======\nHDBSCAN\n=======\n\nHDBSCAN - Hierarchical Density-Based Spatial Clustering of Applications\nwith Noise. Performs DBSCAN over varying epsilon values and integrates \nthe result to find a clustering that gives the best stability over epsilon.\nThis allows HDBSCAN to find clusters of varying densities (unlike DBSCAN),\nand be more robust to parameter selection.\n\nIn practice this means that HDBSCAN returns a good clustering straight\naway with little or no parameter tuning -- and the primary parameter,\nminimum cluster size, is intuitive and easy to select.\n\nHDBSCAN is ideal for exploratory data analysis; it's a fast and robust\nalgorithm that you can trust to return meaningful clusters (if there\nare any).\n\nBased on the paper:\n    R. Campello, D. Moulavi, and J. Sander, *Density-Based Clustering Based on\n    Hierarchical Density Estimates*\n    In: Advances in Knowledge Discovery and Data Mining, Springer, pp 160-172.\n    2013\n    \nDocumentation, including tutorials, are available on ReadTheDocs at http://hdbscan.readthedocs.io/en/latest/ .  \n    \nNotebooks `comparing HDBSCAN to other clustering algorithms <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Comparing%20Clustering%20Algorithms.ipynb>`_, explaining `how HDBSCAN works <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb>`_ and `comparing performance with other python clustering implementations <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Benchmarking%20scalability%20of%20clustering%20implementations-v0.7.ipynb>`_ are available.\n\n------------------\nHow to use HDBSCAN\n------------------\n\nThe hdbscan package inherits from sklearn classes, and thus drops in neatly\nnext to other sklearn clusterers with an identical calling API. Similarly it\nsupports input in a variety of formats: an array (or pandas dataframe, or\nsparse matrix) of shape ``(num_samples x num_features)``; an array (or sparse matrix)\ngiving a distance matrix between samples.\n\n.. code:: python\n\n    import hdbscan\n    \n    clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n    cluster_labels = clusterer.fit_predict(data)\n\n-----------\nPerformance\n-----------\n\nSignificant effort has been put into making the hdbscan implementation as fast as \npossible. It is `orders of magnitude faster than the reference implementation <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Python%20vs%20Java.ipynb>`_ in Java,\nand is currently faster than highly optimized single linkage implementations in C and C++.\n`version 0.7 performance can be seen in this notebook <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Benchmarking%20scalability%20of%20clustering%20implementations-v0.7.ipynb>`_ .\nIn particular `performance on low dimensional data is better than sklearn's DBSCAN <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Benchmarking%20scalability%20of%20clustering%20implementations%202D%20v0.7.ipynb>`_ ,\nand via support for caching with joblib, re-clustering with different parameters\ncan be almost free.\n\n------------------------\nAdditional functionality\n------------------------\n\nThe hdbscan package comes equipped with visualization tools to help you\nunderstand your clustering results. After fitting data the clusterer\nobject has attributes for:\n\n* The condensed cluster hierarchy\n* The robust single linkage cluster hierarchy\n* The reachability distance minimal spanning tree\n\nAll of which come equipped with methods for plotting and converting\nto Pandas or NetworkX for further analysis. See the notebook on\n`how HDBSCAN works <http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb>`_ for examples and further details.\n\nThe clusterer objects also have an attribute providing cluster membership\nstrengths, resulting in optional soft clustering (and no further compute \nexpense). Finally each cluster also receives a persistence score giving\nthe stability of the cluster over the range of distance scales present\nin the data. This provides a measure of the relative strength of clusters.\n\n-----------------\nOutlier Detection\n-----------------\n\nThe HDBSCAN clusterer objects also support the GLOSH outlier detection algorithm. \nAfter fitting the clusterer to data the outlier scores can be accessed via the\n``outlier_scores_`` attribute. The result is a vector of score values, one for\neach data point that was fit. Higher scores represent more outlier like objects.\nSelecting outliers via upper quantiles is often a good approach.\n\nBased on the paper:\n    R.J.G.B. Campello, D. Moulavi, A. Zimek and J. Sander \n    *Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection*, \n    ACM Trans. on Knowledge Discovery from Data, Vol 10, 1 (July 2015), 1-51.\n\n---------------------\nRobust single linkage\n---------------------\n\nThe hdbscan package also provides support for the *robust single linkage*\nclustering algorithm of Chaudhuri and Dasgupta. As with the HDBSCAN \nimplementation this is a high performance version of the algorithm \noutperforming scipy's standard single linkage implementation. The\nrobust single linkage hierarchy is available as an attribute of\nthe robust single linkage clusterer, again with the ability to plot\nor export the hierarchy, and to extract flat clusterings at a given\ncut level and gamma value.\n\nExample usage:\n\n.. code:: python\n\n    import hdbscan\n    \n    clusterer = hdbscan.RobustSingleLinkage(cut=0.125, k=7)\n    cluster_labels = clusterer.fit_predict(data)\n    hierarchy = clusterer.cluster_hierarchy_\n    alt_labels = hierarchy.get_clusters(0.100, 5)\n    hierarchy.plot()\n\n\nBased on the paper:\n    K. Chaudhuri and S. Dasgupta.\n    *\"Rates of convergence for the cluster tree.\"*\n    In Advances in Neural Information Processing Systems, 2010.\n\n----------\nInstalling\n----------\n\nEasiest install, if you have Anaconda (thanks to conda-forge which is awesome!):\n\n.. code:: bash\n\n    conda install -c conda-forge hdbscan\n\nPyPI install, presuming you have sklearn and all its requirements installed:\n\n.. code:: bash\n\n    pip install hdbscan\n\nIf pip is having difficulties pulling the dependencies then we'd suggest installing\nthe dependencies manually using anaconda followed by pulling hdbscan from pip:\n\n.. code:: bash\n\n    conda install cython\n    conda install scikit-learn\n    pip install hdbscan\n\nFor a manual install get this package:\n\n.. code:: bash\n\n    wget https://github.com/lmcinnes/hdbscan/archive/master.zip\n    unzip master.zip\n    rm master.zip\n    cd hdbscan-master\n\nInstall the requirements\n\n.. code:: bash\n\n    sudo pip install -r requirements.txt\n    \nor\n\n.. code:: bash\n\n    conda install scikit-learn cython\n\nInstall the package\n\n.. code:: bash\n\n    python setup.py install\n\n---------\nLicensing\n---------\n\nThe hdbscan package is 3-clause BSD licensed. Enjoy.", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/lmcinnes/hdbscan", "keywords": "cluster clustering density hierarchical", "license": "BSD", "maintainer": null, "maintainer_email": null, "name": "hdbscan-with-cosine-distance", "package_url": "https://pypi.org/project/hdbscan-with-cosine-distance/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/hdbscan-with-cosine-distance/", "project_urls": {"Download": "UNKNOWN", "Homepage": "http://github.com/lmcinnes/hdbscan"}, "release_url": "https://pypi.org/project/hdbscan-with-cosine-distance/0.8.1/", "requires_dist": null, "requires_python": null, "summary": "Clustering based on density with variable density clusters", "version": "0.8.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/hdbscan/\" rel=\"nofollow\"><img alt=\"PyPI Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8ed9a0bb9df6d864be94d0da456836840051b3ad/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6864627363616e2e737667\"></a>\n<a href=\"https://anaconda.org/conda-forge/hdbscan\" rel=\"nofollow\"><img alt=\"Conda-forge Versio\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4972b17f1de4e7b6610d08be0403a98b10fc0415/68747470733a2f2f616e61636f6e64612e6f72672f636f6e64612d666f7267652f6864627363616e2f6261646765732f76657273696f6e2e737667\"></a>\n<a href=\"https://github.com/lmcinnes/hdbscan/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/52a9930f655b1ef60a1abe8bb83fde3a7a19fa5f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f6864627363616e2e737667\"></a>\n<div id=\"hdbscan\">\n<h2>HDBSCAN</h2>\n<p>HDBSCAN - Hierarchical Density-Based Spatial Clustering of Applications\nwith Noise. Performs DBSCAN over varying epsilon values and integrates\nthe result to find a clustering that gives the best stability over epsilon.\nThis allows HDBSCAN to find clusters of varying densities (unlike DBSCAN),\nand be more robust to parameter selection.</p>\n<p>In practice this means that HDBSCAN returns a good clustering straight\naway with little or no parameter tuning \u2013 and the primary parameter,\nminimum cluster size, is intuitive and easy to select.</p>\n<p>HDBSCAN is ideal for exploratory data analysis; it\u2019s a fast and robust\nalgorithm that you can trust to return meaningful clusters (if there\nare any).</p>\n<dl>\n<dt>Based on the paper:</dt>\n<dd>R. Campello, D. Moulavi, and J. Sander, <em>Density-Based Clustering Based on\nHierarchical Density Estimates</em>\nIn: Advances in Knowledge Discovery and Data Mining, Springer, pp 160-172.\n2013</dd>\n</dl>\n<p>Documentation, including tutorials, are available on ReadTheDocs at <a href=\"http://hdbscan.readthedocs.io/en/latest/\" rel=\"nofollow\">http://hdbscan.readthedocs.io/en/latest/</a> .</p>\n<p>Notebooks <a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Comparing%20Clustering%20Algorithms.ipynb\" rel=\"nofollow\">comparing HDBSCAN to other clustering algorithms</a>, explaining <a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb\" rel=\"nofollow\">how HDBSCAN works</a> and <a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Benchmarking%20scalability%20of%20clustering%20implementations-v0.7.ipynb\" rel=\"nofollow\">comparing performance with other python clustering implementations</a> are available.</p>\n<div id=\"how-to-use-hdbscan\">\n<h3>How to use HDBSCAN</h3>\n<p>The hdbscan package inherits from sklearn classes, and thus drops in neatly\nnext to other sklearn clusterers with an identical calling API. Similarly it\nsupports input in a variety of formats: an array (or pandas dataframe, or\nsparse matrix) of shape <tt>(num_samples x num_features)</tt>; an array (or sparse matrix)\ngiving a distance matrix between samples.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">hdbscan</span>\n\n<span class=\"n\">clusterer</span> <span class=\"o\">=</span> <span class=\"n\">hdbscan</span><span class=\"o\">.</span><span class=\"n\">HDBSCAN</span><span class=\"p\">(</span><span class=\"n\">min_cluster_size</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">cluster_labels</span> <span class=\"o\">=</span> <span class=\"n\">clusterer</span><span class=\"o\">.</span><span class=\"n\">fit_predict</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n</pre>\n</div>\n<div id=\"performance\">\n<h3>Performance</h3>\n<p>Significant effort has been put into making the hdbscan implementation as fast as\npossible. It is <a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Python%20vs%20Java.ipynb\" rel=\"nofollow\">orders of magnitude faster than the reference implementation</a> in Java,\nand is currently faster than highly optimized single linkage implementations in C and C++.\n<a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Benchmarking%20scalability%20of%20clustering%20implementations-v0.7.ipynb\" rel=\"nofollow\">version 0.7 performance can be seen in this notebook</a> .\nIn particular <a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/Benchmarking%20scalability%20of%20clustering%20implementations%202D%20v0.7.ipynb\" rel=\"nofollow\">performance on low dimensional data is better than sklearn\u2019s DBSCAN</a> ,\nand via support for caching with joblib, re-clustering with different parameters\ncan be almost free.</p>\n</div>\n<div id=\"additional-functionality\">\n<h3>Additional functionality</h3>\n<p>The hdbscan package comes equipped with visualization tools to help you\nunderstand your clustering results. After fitting data the clusterer\nobject has attributes for:</p>\n<ul>\n<li>The condensed cluster hierarchy</li>\n<li>The robust single linkage cluster hierarchy</li>\n<li>The reachability distance minimal spanning tree</li>\n</ul>\n<p>All of which come equipped with methods for plotting and converting\nto Pandas or NetworkX for further analysis. See the notebook on\n<a href=\"http://nbviewer.jupyter.org/github/lmcinnes/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb\" rel=\"nofollow\">how HDBSCAN works</a> for examples and further details.</p>\n<p>The clusterer objects also have an attribute providing cluster membership\nstrengths, resulting in optional soft clustering (and no further compute\nexpense). Finally each cluster also receives a persistence score giving\nthe stability of the cluster over the range of distance scales present\nin the data. This provides a measure of the relative strength of clusters.</p>\n</div>\n<div id=\"outlier-detection\">\n<h3>Outlier Detection</h3>\n<p>The HDBSCAN clusterer objects also support the GLOSH outlier detection algorithm.\nAfter fitting the clusterer to data the outlier scores can be accessed via the\n<tt>outlier_scores_</tt> attribute. The result is a vector of score values, one for\neach data point that was fit. Higher scores represent more outlier like objects.\nSelecting outliers via upper quantiles is often a good approach.</p>\n<dl>\n<dt>Based on the paper:</dt>\n<dd>R.J.G.B. Campello, D. Moulavi, A. Zimek and J. Sander\n<em>Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection</em>,\nACM Trans. on Knowledge Discovery from Data, Vol 10, 1 (July 2015), 1-51.</dd>\n</dl>\n</div>\n<div id=\"robust-single-linkage\">\n<h3>Robust single linkage</h3>\n<p>The hdbscan package also provides support for the <em>robust single linkage</em>\nclustering algorithm of Chaudhuri and Dasgupta. As with the HDBSCAN\nimplementation this is a high performance version of the algorithm\noutperforming scipy\u2019s standard single linkage implementation. The\nrobust single linkage hierarchy is available as an attribute of\nthe robust single linkage clusterer, again with the ability to plot\nor export the hierarchy, and to extract flat clusterings at a given\ncut level and gamma value.</p>\n<p>Example usage:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">hdbscan</span>\n\n<span class=\"n\">clusterer</span> <span class=\"o\">=</span> <span class=\"n\">hdbscan</span><span class=\"o\">.</span><span class=\"n\">RobustSingleLinkage</span><span class=\"p\">(</span><span class=\"n\">cut</span><span class=\"o\">=</span><span class=\"mf\">0.125</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">7</span><span class=\"p\">)</span>\n<span class=\"n\">cluster_labels</span> <span class=\"o\">=</span> <span class=\"n\">clusterer</span><span class=\"o\">.</span><span class=\"n\">fit_predict</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n<span class=\"n\">hierarchy</span> <span class=\"o\">=</span> <span class=\"n\">clusterer</span><span class=\"o\">.</span><span class=\"n\">cluster_hierarchy_</span>\n<span class=\"n\">alt_labels</span> <span class=\"o\">=</span> <span class=\"n\">hierarchy</span><span class=\"o\">.</span><span class=\"n\">get_clusters</span><span class=\"p\">(</span><span class=\"mf\">0.100</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">)</span>\n<span class=\"n\">hierarchy</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">()</span>\n</pre>\n<dl>\n<dt>Based on the paper:</dt>\n<dd>K. Chaudhuri and S. Dasgupta.\n<em>\u201cRates of convergence for the cluster tree.\u201d</em>\nIn Advances in Neural Information Processing Systems, 2010.</dd>\n</dl>\n</div>\n<div id=\"installing\">\n<h3>Installing</h3>\n<p>Easiest install, if you have Anaconda (thanks to conda-forge which is awesome!):</p>\n<pre>conda install -c conda-forge hdbscan\n</pre>\n<p>PyPI install, presuming you have sklearn and all its requirements installed:</p>\n<pre>pip install hdbscan\n</pre>\n<p>If pip is having difficulties pulling the dependencies then we\u2019d suggest installing\nthe dependencies manually using anaconda followed by pulling hdbscan from pip:</p>\n<pre>conda install cython\nconda install scikit-learn\npip install hdbscan\n</pre>\n<p>For a manual install get this package:</p>\n<pre>wget https://github.com/lmcinnes/hdbscan/archive/master.zip\nunzip master.zip\nrm master.zip\n<span class=\"nb\">cd</span> hdbscan-master\n</pre>\n<p>Install the requirements</p>\n<pre>sudo pip install -r requirements.txt\n</pre>\n<p>or</p>\n<pre>conda install scikit-learn cython\n</pre>\n<p>Install the package</p>\n<pre>python setup.py install\n</pre>\n</div>\n<div id=\"licensing\">\n<h3>Licensing</h3>\n<p>The hdbscan package is 3-clause BSD licensed. Enjoy.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 2286931, "releases": {"0.8.1": [{"comment_text": "", "digests": {"md5": "e0ae69fd84f8bf31faded03c6bbca05f", "sha256": "729dfdb948874e321d9ad48669642c5ac5ad68fdaed969f51f156771279adc4c"}, "downloads": -1, "filename": "hdbscan-with-cosine-distance-0.8.1.tar.gz", "has_sig": false, "md5_digest": "e0ae69fd84f8bf31faded03c6bbca05f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3592257, "upload_time": "2016-08-17T19:30:06", "upload_time_iso_8601": "2016-08-17T19:30:06.760539Z", "url": "https://files.pythonhosted.org/packages/ca/72/58f0052eb7d927a5804ee9387c056a2e6ef85657f72f4d3797547bc8c076/hdbscan-with-cosine-distance-0.8.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e0ae69fd84f8bf31faded03c6bbca05f", "sha256": "729dfdb948874e321d9ad48669642c5ac5ad68fdaed969f51f156771279adc4c"}, "downloads": -1, "filename": "hdbscan-with-cosine-distance-0.8.1.tar.gz", "has_sig": false, "md5_digest": "e0ae69fd84f8bf31faded03c6bbca05f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3592257, "upload_time": "2016-08-17T19:30:06", "upload_time_iso_8601": "2016-08-17T19:30:06.760539Z", "url": "https://files.pythonhosted.org/packages/ca/72/58f0052eb7d927a5804ee9387c056a2e6ef85657f72f4d3797547bc8c076/hdbscan-with-cosine-distance-0.8.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:05 2020"}