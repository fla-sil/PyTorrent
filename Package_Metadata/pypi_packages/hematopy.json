{"info": {"author": "Gustavo RPS @ ArgoCrew/ArgoPy", "author_email": "gustavorps+hematopy@argocrew.io", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Healthcare Industry", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Medical Science Apps."], "description": "hematopy\n==============================\n\nPython and Blood\n\nProject Organization\n------------\n\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 Makefile           <- Makefile with commands like `make data` or `make train`\n    \u251c\u2500\u2500 README.md          <- The top-level README for developers using this project.\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 external       <- Data from third party sources.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 interim        <- Intermediate data that has been transformed.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 processed      <- The final, canonical data sets for modeling.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 raw            <- The original, immutable data dump.\n    \u2502\n    \u251c\u2500\u2500 docs               <- A default Sphinx project; see sphinx-doc.org for details\n    \u2502\n    \u251c\u2500\u2500 models             <- Trained and serialized models, model predictions, or model summaries\n    \u2502\n    \u251c\u2500\u2500 notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n    \u2502                         the creator's initials, and a short `-` delimited description, e.g.\n    \u2502                         `1.0-jqp-initial-data-exploration`.\n    \u2502\n    \u251c\u2500\u2500 references         <- Data dictionaries, manuals, and all other explanatory materials.\n    \u2502\n    \u251c\u2500\u2500 reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        <- Generated graphics and figures to be used in reporting\n    \u2502\n    \u251c\u2500\u2500 requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n    \u2502                         generated with `pip freeze > requirements.txt`\n    \u2502\n    \u251c\u2500\u2500 setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n    \u251c\u2500\u2500 src                <- Source code for use in this project.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py    <- Makes src a Python module\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 data           <- Scripts to download or generate data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 make_dataset.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 features       <- Scripts to turn raw data into features for modeling\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 build_features.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 models         <- Scripts to train models and then use trained models to make\n    \u2502   \u2502   \u2502                 predictions\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 predict_model.py\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 train_model.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 visualization  <- Scripts to create exploratory and results oriented visualizations\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 visualize.py\n    \u2502\n    \u2514\u2500\u2500 tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n\n\n--------\n\n<p><small>Project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "blood banner utility", "license": "BSD-3", "maintainer": "", "maintainer_email": "", "name": "hematopy", "package_url": "https://pypi.org/project/hematopy/", "platform": "", "project_url": "https://pypi.org/project/hematopy/", "project_urls": null, "release_url": "https://pypi.org/project/hematopy/0.0.1.dev6/", "requires_dist": null, "requires_python": "", "summary": "Python and Blood", "version": "0.0.1.dev6", "yanked": false, "html_description": "<div class=\"project-description\">\n            hematopy<br>==============================<br><br>Python and Blood<br><br>Project Organization<br>------------<br><br>    \u251c\u2500\u2500 LICENSE<br>    \u251c\u2500\u2500 Makefile           &lt;- Makefile with commands like `make data` or `make train`<br>    \u251c\u2500\u2500 README.md          &lt;- The top-level README for developers using this project.<br>    \u251c\u2500\u2500 data<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 external       &lt;- Data from third party sources.<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 interim        &lt;- Intermediate data that has been transformed.<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 processed      &lt;- The final, canonical data sets for modeling.<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 raw            &lt;- The original, immutable data dump.<br>    \u2502<br>    \u251c\u2500\u2500 docs               &lt;- A default Sphinx project; see sphinx-doc.org for details<br>    \u2502<br>    \u251c\u2500\u2500 models             &lt;- Trained and serialized models, model predictions, or model summaries<br>    \u2502<br>    \u251c\u2500\u2500 notebooks          &lt;- Jupyter notebooks. Naming convention is a number (for ordering),<br>    \u2502                         the creator's initials, and a short `-` delimited description, e.g.<br>    \u2502                         `1.0-jqp-initial-data-exploration`.<br>    \u2502<br>    \u251c\u2500\u2500 references         &lt;- Data dictionaries, manuals, and all other explanatory materials.<br>    \u2502<br>    \u251c\u2500\u2500 reports            &lt;- Generated analysis as HTML, PDF, LaTeX, etc.<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        &lt;- Generated graphics and figures to be used in reporting<br>    \u2502<br>    \u251c\u2500\u2500 requirements.txt   &lt;- The requirements file for reproducing the analysis environment, e.g.<br>    \u2502                         generated with `pip freeze &gt; requirements.txt`<br>    \u2502<br>    \u251c\u2500\u2500 setup.py           &lt;- makes project pip installable (pip install -e .) so src can be imported<br>    \u251c\u2500\u2500 src                &lt;- Source code for use in this project.<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py    &lt;- Makes src a Python module<br>    \u2502   \u2502<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 data           &lt;- Scripts to download or generate data<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 make_dataset.py<br>    \u2502   \u2502<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 features       &lt;- Scripts to turn raw data into features for modeling<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 build_features.py<br>    \u2502   \u2502<br>    \u2502\u00a0\u00a0 \u251c\u2500\u2500 models         &lt;- Scripts to train models and then use trained models to make<br>    \u2502   \u2502   \u2502                 predictions<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 predict_model.py<br>    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 train_model.py<br>    \u2502   \u2502<br>    \u2502\u00a0\u00a0 \u2514\u2500\u2500 visualization  &lt;- Scripts to create exploratory and results oriented visualizations<br>    \u2502\u00a0\u00a0     \u2514\u2500\u2500 visualize.py<br>    \u2502<br>    \u2514\u2500\u2500 tox.ini            &lt;- tox file with settings for running tox; see tox.testrun.org<br><br><br>--------<br><br>&lt;p&gt;&lt;small&gt;Project based on the &lt;a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\"&gt;cookiecutter data science project template&lt;/a&gt;. #cookiecutterdatascience&lt;/small&gt;&lt;/p&gt;<br>\n          </div>"}, "last_serial": 3959007, "releases": {"0.0.1.dev6": [{"comment_text": "", "digests": {"md5": "b08706f995ed9d95b047f76785c4da56", "sha256": "153b0311eff53eba15d1fb298664fac0ccd0fecd4aeb23bd17a021b41bb8c72f"}, "downloads": -1, "filename": "hematopy-0.0.1.dev6.tar.gz", "has_sig": false, "md5_digest": "b08706f995ed9d95b047f76785c4da56", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6305, "upload_time": "2018-06-13T18:09:49", "upload_time_iso_8601": "2018-06-13T18:09:49.540605Z", "url": "https://files.pythonhosted.org/packages/dd/87/f7e87b9f480d172117e220e215082d6935bf5f1b02a3e6ec03e265f043f8/hematopy-0.0.1.dev6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b08706f995ed9d95b047f76785c4da56", "sha256": "153b0311eff53eba15d1fb298664fac0ccd0fecd4aeb23bd17a021b41bb8c72f"}, "downloads": -1, "filename": "hematopy-0.0.1.dev6.tar.gz", "has_sig": false, "md5_digest": "b08706f995ed9d95b047f76785c4da56", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6305, "upload_time": "2018-06-13T18:09:49", "upload_time_iso_8601": "2018-06-13T18:09:49.540605Z", "url": "https://files.pythonhosted.org/packages/dd/87/f7e87b9f480d172117e220e215082d6935bf5f1b02a3e6ec03e265f043f8/hematopy-0.0.1.dev6.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:51:38 2020"}