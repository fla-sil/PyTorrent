{"info": {"author": "Will Sackfield", "author_email": "will.sackfield@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "<img alt=\"text-normaliser\" src=\"text-normaliser.png\" width=\"100%\" max-width=\"888\">\n\nA python package that runs a series of operations over text to decorate a corpus.\n\n[![CircleCI](https://circleci.com/gh/dust10141/text-normaliser.svg?style=svg)](https://circleci.com/gh/dust10141/text-normaliser)\n[![PyPi version](https://pypip.in/v/textnormaliser/badge.png)](https://crate.io/packages/textnormaliser/)\n\n## Raison D'\u00eatre :thought_balloon:\nThis allows text to become normalised before being sent to vector model. A series of text checking, preprocessing and decoration operations are performed on the text to strip insignificant data and to embed new information from rule based models.\n\n## Architecture :triangular_ruler:\n`text-normaliser` has two major modes of operation, checking whether to include the line at all and then normalising the line once it is processed. In order to determine whether it should include the line the following checks are made:\n- **Letter Filtering**, which takes the text, strips everything but the English Latin characters, and checks the resulting length to be appropriate.\n- **Language Filtering**, which takes the text, and determines whether it is English based on a character ngram model.\nIf both of those checks pass, then it performs the following normalisation operations:\n- **Entity Tagging**, which takes the text and tags all the entities within the text with their type (e.g. MONEY, DATE or PERSON).\n- **Part-of-speech Tagging**, which takes the text and performs tagging on the kind of word the word is (e.g. ADJECTIVE or NOUN). This will not tag anything grouped by the Entity Tagging.\n- **Lowercasing**, lowercases all the text to remove flair.\n- **HTML Decoding**, decodes HTML encoded characters to unicode.\n\n## Dependencies :globe_with_meridians:\n* [langdetect](https://pypi.org/project/langdetect/)\n* [tqdm](https://tqdm.github.io/)\n* [NLTK](https://www.nltk.org/)\n* [Spacy](https://spacy.io/)\n* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)\n\n## Installation :inbox_tray:\nThe chief requirements of any installation are based off scrapy and splash, see below for local and cloud based options.\n\n### Locally\n1. Run `python setup.py --install`\n2. Run `python -m spacy download en`\n3. Run `python -m unittest discover -v` for the unit tests.\n\n### Via Pypi\n1. Run `pip install textnormaliser`\n2. Run `python -m spacy download en`\n\n## Usage example :eyes:\nIn order to normalise a corpus of text, execute the following:\n```bash\ntextnormaliser [corpus-file] [output-file]\n```\nThe result will be a new output file of the text that has been normalised. Lets say you had the following input file:\n```\nEuropean authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\n\nYeah, as a Libertarian who leans left socially but right in other areas (used to be fiscally, but the right isn't about smaller government anymore!) I can personally attest to the fact that calling us names just makes us more determined to dig in and shore up.\n\nYou don't win people over by calling them stupid and telling them they are wrong.  You win them over by convincing them that there is something new and better.\n```\nThis would result in the following:\n```\nnorp_european nns_authorities vbd_fined org_google a nn_record money__5_1_billion in_on date_wednesday in_for vbg_abusing prp$_its nn_power in_in dt_the jj_mobile nn_phone nn_market cc_and vbd_ordered dt_the nn_company to_to vb_alter prp$_its nns_practices\nuh_yeah , in_as a norp_libertarian wp_who vbz_leans vbn_left rb_socially cc_but rb_right in_in jj_other nns_areas ( vbn_used to_to vb_be rb_fiscally , cc_but dt_the nn_right vbz_is rb_n't rb_about jjr_smaller nn_government rb_anymore ! ) i md_can rb_personally vb_attest to_to dt_the nn_fact in_that vbg_calling prp_us rb_names rb_just vbz_makes prp_us rbr_more jj_determined to_to vb_dig in_in cc_and vb_shore rp_up .\nprp_you vbp_do rb_n't vb_win nns_people in_over in_by vbg_calling prp_them jj_stupid cc_and vbg_telling prp_them prp_they vbp_are jj_wrong . prp_you vbp_win prp_them rp_over in_by vbg_convincing prp_them in_that ex_there vbz_is nn_something jj_new cc_and jjr_better .\n```\n\n## License :memo:\nThe project is available under the [MIT](https://opensource.org/licenses/MIT) license.\n\n## Acknowledgements\n\n- Icon in README banner is [text](https://thenounproject.com/search/?q=text&i=377463) by Chameleon Design from the Noun Project.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dust10141/text-normaliser", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "textnormaliser", "package_url": "https://pypi.org/project/textnormaliser/", "platform": "", "project_url": "https://pypi.org/project/textnormaliser/", "project_urls": {"Homepage": "https://github.com/dust10141/text-normaliser"}, "release_url": "https://pypi.org/project/textnormaliser/1.0.4/", "requires_dist": null, "requires_python": "", "summary": "A python package that runs a series of operations over text to decorate a corpus", "version": "1.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img alt=\"text-normaliser\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1573425c7702661a40bcf7b8ba6b2caf91df8b63/746578742d6e6f726d616c697365722e706e67\" width=\"100%\">\n<p>A python package that runs a series of operations over text to decorate a corpus.</p>\n<p><a href=\"https://circleci.com/gh/dust10141/text-normaliser\" rel=\"nofollow\"><img alt=\"CircleCI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/803dbfec704bc3f70a8f41e1b940ae8a5d85d409/68747470733a2f2f636972636c6563692e636f6d2f67682f6475737431303134312f746578742d6e6f726d616c697365722e7376673f7374796c653d737667\"></a>\n<a href=\"https://crate.io/packages/textnormaliser/\" rel=\"nofollow\"><img alt=\"PyPi version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3507db8af0962f3b0f37d257a6a12577b57687d4/68747470733a2f2f70797069702e696e2f762f746578746e6f726d616c697365722f62616467652e706e67\"></a></p>\n<h2>Raison D'\u00eatre :thought_balloon:</h2>\n<p>This allows text to become normalised before being sent to vector model. A series of text checking, preprocessing and decoration operations are performed on the text to strip insignificant data and to embed new information from rule based models.</p>\n<h2>Architecture :triangular_ruler:</h2>\n<p><code>text-normaliser</code> has two major modes of operation, checking whether to include the line at all and then normalising the line once it is processed. In order to determine whether it should include the line the following checks are made:</p>\n<ul>\n<li><strong>Letter Filtering</strong>, which takes the text, strips everything but the English Latin characters, and checks the resulting length to be appropriate.</li>\n<li><strong>Language Filtering</strong>, which takes the text, and determines whether it is English based on a character ngram model.\nIf both of those checks pass, then it performs the following normalisation operations:</li>\n<li><strong>Entity Tagging</strong>, which takes the text and tags all the entities within the text with their type (e.g. MONEY, DATE or PERSON).</li>\n<li><strong>Part-of-speech Tagging</strong>, which takes the text and performs tagging on the kind of word the word is (e.g. ADJECTIVE or NOUN). This will not tag anything grouped by the Entity Tagging.</li>\n<li><strong>Lowercasing</strong>, lowercases all the text to remove flair.</li>\n<li><strong>HTML Decoding</strong>, decodes HTML encoded characters to unicode.</li>\n</ul>\n<h2>Dependencies :globe_with_meridians:</h2>\n<ul>\n<li><a href=\"https://pypi.org/project/langdetect/\" rel=\"nofollow\">langdetect</a></li>\n<li><a href=\"https://tqdm.github.io/\" rel=\"nofollow\">tqdm</a></li>\n<li><a href=\"https://www.nltk.org/\" rel=\"nofollow\">NLTK</a></li>\n<li><a href=\"https://spacy.io/\" rel=\"nofollow\">Spacy</a></li>\n<li><a href=\"https://www.crummy.com/software/BeautifulSoup/\" rel=\"nofollow\">BeautifulSoup</a></li>\n</ul>\n<h2>Installation :inbox_tray:</h2>\n<p>The chief requirements of any installation are based off scrapy and splash, see below for local and cloud based options.</p>\n<h3>Locally</h3>\n<ol>\n<li>Run <code>python setup.py --install</code></li>\n<li>Run <code>python -m spacy download en</code></li>\n<li>Run <code>python -m unittest discover -v</code> for the unit tests.</li>\n</ol>\n<h3>Via Pypi</h3>\n<ol>\n<li>Run <code>pip install textnormaliser</code></li>\n<li>Run <code>python -m spacy download en</code></li>\n</ol>\n<h2>Usage example :eyes:</h2>\n<p>In order to normalise a corpus of text, execute the following:</p>\n<pre>textnormaliser <span class=\"o\">[</span>corpus-file<span class=\"o\">]</span> <span class=\"o\">[</span>output-file<span class=\"o\">]</span>\n</pre>\n<p>The result will be a new output file of the text that has been normalised. Lets say you had the following input file:</p>\n<pre><code>European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\n\nYeah, as a Libertarian who leans left socially but right in other areas (used to be fiscally, but the right isn't about smaller government anymore!) I can personally attest to the fact that calling us names just makes us more determined to dig in and shore up.\n\nYou don't win people over by calling them stupid and telling them they are wrong.  You win them over by convincing them that there is something new and better.\n</code></pre>\n<p>This would result in the following:</p>\n<pre><code>norp_european nns_authorities vbd_fined org_google a nn_record money__5_1_billion in_on date_wednesday in_for vbg_abusing prp$_its nn_power in_in dt_the jj_mobile nn_phone nn_market cc_and vbd_ordered dt_the nn_company to_to vb_alter prp$_its nns_practices\nuh_yeah , in_as a norp_libertarian wp_who vbz_leans vbn_left rb_socially cc_but rb_right in_in jj_other nns_areas ( vbn_used to_to vb_be rb_fiscally , cc_but dt_the nn_right vbz_is rb_n't rb_about jjr_smaller nn_government rb_anymore ! ) i md_can rb_personally vb_attest to_to dt_the nn_fact in_that vbg_calling prp_us rb_names rb_just vbz_makes prp_us rbr_more jj_determined to_to vb_dig in_in cc_and vb_shore rp_up .\nprp_you vbp_do rb_n't vb_win nns_people in_over in_by vbg_calling prp_them jj_stupid cc_and vbg_telling prp_them prp_they vbp_are jj_wrong . prp_you vbp_win prp_them rp_over in_by vbg_convincing prp_them in_that ex_there vbz_is nn_something jj_new cc_and jjr_better .\n</code></pre>\n<h2>License :memo:</h2>\n<p>The project is available under the <a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\">MIT</a> license.</p>\n<h2>Acknowledgements</h2>\n<ul>\n<li>Icon in README banner is <a href=\"https://thenounproject.com/search/?q=text&amp;i=377463\" rel=\"nofollow\">text</a> by Chameleon Design from the Noun Project.</li>\n</ul>\n\n          </div>"}, "last_serial": 4616487, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "bcd532a878bdf052179cfbc99b147f89", "sha256": "9806d8115b5c8311d8bd85c2b4702181a746c5cdb7a9dabbc80c19aa8afb2494"}, "downloads": -1, "filename": "textnormaliser-1.0.0-py2.7.egg", "has_sig": false, "md5_digest": "bcd532a878bdf052179cfbc99b147f89", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 6309, "upload_time": "2018-11-24T20:52:20", "upload_time_iso_8601": "2018-11-24T20:52:20.079855Z", "url": "https://files.pythonhosted.org/packages/ce/7e/9a80b73adcd68266c4fdc38c546c647e31c681e05457865e7f6de2c38408/textnormaliser-1.0.0-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "c1e5c429aa38561dca4d5ec4dab3364c", "sha256": "5e67b55c3dda3900997fa17370373842874fcc91501a70e1e2598160ebb29b1e"}, "downloads": -1, "filename": "textnormaliser-1.0.0-py2-none-any.whl", "has_sig": false, "md5_digest": "c1e5c429aa38561dca4d5ec4dab3364c", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 5388, "upload_time": "2018-11-24T20:33:07", "upload_time_iso_8601": "2018-11-24T20:33:07.593575Z", "url": "https://files.pythonhosted.org/packages/61/a0/4c31c8e6417f1795055b2ff0c06f4ee10b5ffdebb514f6f972c60a4b510b/textnormaliser-1.0.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23109ad09ae75c56ce773dc9dfdccd89", "sha256": "042691f0390b0d8e3ee444ae07a3417708d98545779f405d6a0c775189c3ef47"}, "downloads": -1, "filename": "textnormaliser-1.0.0.tar.gz", "has_sig": false, "md5_digest": "23109ad09ae75c56ce773dc9dfdccd89", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4621, "upload_time": "2018-11-24T20:33:09", "upload_time_iso_8601": "2018-11-24T20:33:09.519553Z", "url": "https://files.pythonhosted.org/packages/69/dd/ae524fc03891e3d2e71f5c73eb98e28de1134c37d84be2be0c02a1b6abec/textnormaliser-1.0.0.tar.gz", "yanked": false}], "1.0.1": [{"comment_text": "", "digests": {"md5": "ad85d83f3af4055c4daf0f591ff554f3", "sha256": "eb76d6eabf18f469087fb3e6c5a899cdbddd6c3fc9961175b9ced35ea913dd5e"}, "downloads": -1, "filename": "textnormaliser-1.0.1-py2.7.egg", "has_sig": false, "md5_digest": "ad85d83f3af4055c4daf0f591ff554f3", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 7354, "upload_time": "2018-12-17T19:15:15", "upload_time_iso_8601": "2018-12-17T19:15:15.605583Z", "url": "https://files.pythonhosted.org/packages/ce/8c/38d6197a3b007a9ce9686ed503294418b14dc2c59f4f2daf96cfadd416f1/textnormaliser-1.0.1-py2.7.egg", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "a4e6c8ae0d88698064220813fe9842bd", "sha256": "3dae10e87fcc1d57884bc22e595a59c3c8d69669332e696797ee2e4da57bc460"}, "downloads": -1, "filename": "textnormaliser-1.0.2-py2.7.egg", "has_sig": false, "md5_digest": "a4e6c8ae0d88698064220813fe9842bd", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 7603, "upload_time": "2018-12-19T00:17:02", "upload_time_iso_8601": "2018-12-19T00:17:02.565428Z", "url": "https://files.pythonhosted.org/packages/a8/76/bc4c1c8866b59aa06bd6bfaab3b72a09708e713e2bc8d07dd63925c32741/textnormaliser-1.0.2-py2.7.egg", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "a0450c8e1dcae83cd01ff7c96ff4973a", "sha256": "f752386b745ea1e075b4a5f54c65fdef259b824d2f388ba2d05145d800199927"}, "downloads": -1, "filename": "textnormaliser-1.0.3-py2.7.egg", "has_sig": false, "md5_digest": "a0450c8e1dcae83cd01ff7c96ff4973a", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 7603, "upload_time": "2018-12-19T03:24:31", "upload_time_iso_8601": "2018-12-19T03:24:31.285028Z", "url": "https://files.pythonhosted.org/packages/76/db/7b51eb6bc9738104f0930ab7f83e8fa857cd0c79dc11e33f11754f1e440e/textnormaliser-1.0.3-py2.7.egg", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "60c776be65547b68a9007dcf8d10f9af", "sha256": "25939bb4fbaecb7b747dc5f6b02c69915c93e84816b69781d1cf2e89ea3f0b05"}, "downloads": -1, "filename": "textnormaliser-1.0.4-py2.7.egg", "has_sig": false, "md5_digest": "60c776be65547b68a9007dcf8d10f9af", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 7867, "upload_time": "2018-12-19T12:43:35", "upload_time_iso_8601": "2018-12-19T12:43:35.233141Z", "url": "https://files.pythonhosted.org/packages/07/dc/a9ecd0782d31b2bc4d53f9b6f4e2ab41c63b8136a8e828ccc63a86cdfda2/textnormaliser-1.0.4-py2.7.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "60c776be65547b68a9007dcf8d10f9af", "sha256": "25939bb4fbaecb7b747dc5f6b02c69915c93e84816b69781d1cf2e89ea3f0b05"}, "downloads": -1, "filename": "textnormaliser-1.0.4-py2.7.egg", "has_sig": false, "md5_digest": "60c776be65547b68a9007dcf8d10f9af", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 7867, "upload_time": "2018-12-19T12:43:35", "upload_time_iso_8601": "2018-12-19T12:43:35.233141Z", "url": "https://files.pythonhosted.org/packages/07/dc/a9ecd0782d31b2bc4d53f9b6f4e2ab41c63b8136a8e828ccc63a86cdfda2/textnormaliser-1.0.4-py2.7.egg", "yanked": false}], "timestamp": "Fri May  8 02:54:59 2020"}