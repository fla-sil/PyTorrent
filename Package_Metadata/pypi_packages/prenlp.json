{"info": {"author": "Hoyeon Lee", "author_email": "lyeoni.g@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "# PreNLP\n[![PyPI](https://img.shields.io/pypi/v/prenlp.svg?style=flat-square&color=important)](https://pypi.org/project/prenlp/)\n[![License](https://img.shields.io/github/license/lyeoni/prenlp?style=flat-square)](https://github.com/lyeoni/prenlp/blob/master/LICENSE)\n[![GitHub stars](https://img.shields.io/github/stars/lyeoni/prenlp?style=flat-square)](https://github.com/lyeoni/prenlp/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/lyeoni/prenlp?style=flat-square&color=blueviolet)](https://github.com/lyeoni/prenlp/network/members)\n\nPreprocessing Library for Natural Language Processing\n\n## Installation\n### Requirements\n- Python >= 3.6 \n- Mecab morphological analyzer for Korean\n  ```\n  sh scripts/install_mecab.sh\n  # Only for Mac OS users, run the code below before run install_mecab.sh script.\n  # export MACOSX_DEPLOYMENT_TARGET=10.10\n  # CFLAGS='-stdlib=libc++' pip install konlpy\n  ```\n- C++ Build tools for fastText\n  - g++ >= 4.7.2 or clang >= 3.3\n  - For **Windows**, [Visual Studio C++](https://visualstudio.microsoft.com/downloads/) is recommended.\n\n### With pip\nprenlp can be installed using pip as follows:\n```\npip install prenlp\n```\n\n## Usage\n\n### Data\n\n#### Dataset Loading\n\nPopular datasets for NLP tasks are provided in prenlp. All datasets is stored in `/.data` directory.\n- Sentiment Analysis: IMDb, NSMC\n- Language Modeling: WikiText-2, WikiText-103, WikiText-ko, NamuWiki-ko\n\n|Dataset|Language|Articles|Sentences|Tokens|Vocab|Size|\n|-|-|-|-|-|-|-|\n|WikiText-2|English|720|-|2,551,843|33,278|13.3MB|\n|WikiText-103|English|28,595|-|103,690,236|267,735|517.4MB|\n|WikiText-ko|Korean|477,946|2,333,930|131,184,780|662,949|667MB|\n|NamuWiki-ko|Korean|661,032|16,288,639|715,535,778|1,130,008|3.3GB|\n|WikiText-ko+NamuWiki-ko|Korean|1,138,978|18,622,569|846,720,558|1,360,538|3.95GB|\n\nGeneral use cases are as follows:\n\n##### [WikiText-2 / WikiText-103](https://github.com/lyeoni/prenlp/blob/develop/prenlp/data/dataset/language_modeling.py)\n```python\n>>> wikitext2 = prenlp.data.WikiText2()\n>>> len(wikitext2)\n3\n>>> train, valid, test = prenlp.data.WikiText2()\n>>> train[0]\n'= Valkyria Chronicles III ='\n```\n\n##### [IMDB](https://github.com/lyeoni/prenlp/blob/master/prenlp/data/dataset/sentiment.py)\n```python\n>>> imdb_train, imdb_test = prenlp.data.IMDB()\n>>> imdb_train[0]\n[\"Minor Spoilers<br /><br />Alison Parker (Cristina Raines) is a successful top model, living with the lawyer Michael Lerman (Chris Sarandon) in his apartment. She tried to commit ...\", 'pos']\n```\n\n#### [Normalization](https://github.com/lyeoni/prenlp/blob/master/prenlp/data/normalizer.py)\nFrequently used normalization functions for text pre-processing are provided in prenlp.\n> url, HTML tag, emoticon, email, phone number, etc.\n\nGeneral use cases are as follows:\n```python\n>>> from prenlp.data import Normalizer\n>>> normalizer = Normalizer(url_repl='[URL]', tag_repl='[TAG]', emoji_repl='[EMOJI]', email_repl='[EMAIL]', tel_repl='[TEL]', image_repl='[IMG]')\n\n>>> normalizer.normalize('Visit this link for more details: https://github.com/')\n'Visit this link for more details: [URL]'\n\n>>> normalizer.normalize('Use HTML with the desired attributes: <img src=\"cat.jpg\" height=\"100\" />')\n'Use HTML with the desired attributes: [TAG]'\n\n>>> normalizer.normalize('Hello \ud83e\udd29, I love you \ud83d\udc93 !')\n'Hello [EMOJI], I love you [EMOJI] !'\n\n>>> normalizer.normalize('Contact me at lyeoni.g@gmail.com')\n'Contact me at [EMAIL]'\n\n>>> normalizer.normalize('Call +82 10-1234-5678')\n'Call [TEL]'\n\n>>> normalizer.normalize('Download our logo image, logo123.png, with transparent background.')\n'Download our logo image, [IMG], with transparent background.'\n```\n\n### Tokenizer\nFrequently used (subword) tokenizers for text pre-processing are provided in prenlp.\n> SentencePiece, NLTKMosesTokenizer, Mecab\n\n#### [SentencePiece](https://github.com/lyeoni/prenlp/blob/master/prenlp/tokenizer/tokenizer.py)\n```python\n>>> from prenlp.tokenizer import SentencePiece\n>>> SentencePiece.train(input='corpus.txt', model_prefix='sentencepiece', vocab_size=10000)\n>>> tokenizer = SentencePiece.load('sentencepiece.model')\n>>> tokenizer('Time is the most valuable thing a man can spend.')\n['\u2581Time', '\u2581is', '\u2581the', '\u2581most', '\u2581valuable', '\u2581thing', '\u2581a', '\u2581man', '\u2581can', '\u2581spend', '.']\n>>> tokenizer.tokenize('Time is the most valuable thing a man can spend.')\n['\u2581Time', '\u2581is', '\u2581the', '\u2581most', '\u2581valuable', '\u2581thing', '\u2581a', '\u2581man', '\u2581can', '\u2581spend', '.']\n>>> tokenizer.detokenize(['\u2581Time', '\u2581is', '\u2581the', '\u2581most', '\u2581valuable', '\u2581thing', '\u2581a', '\u2581man', '\u2581can', '\u2581spend', '.'])\nTime is the most valuable thing a man can spend.\n```\n\n#### [Moses tokenizer](https://github.com/lyeoni/prenlp/blob/master/prenlp/tokenizer/tokenizer.py)\n```python\n>>> from prenlp.tokenizer import NLTKMosesTokenizer\n>>> tokenizer = NLTKMosesTokenizer()\n>>> tokenizer('Time is the most valuable thing a man can spend.')\n['Time', 'is', 'the', 'most', 'valuable', 'thing', 'a', 'man', 'can', 'spend', '.']\n```\n\n#### Comparisons with tokenizers on IMDb\nBelow figure shows the classification accuracy from various tokenizer.\n- Code: [NLTKMosesTokenizer](https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_imdb.py), [SentencePiece](https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_imdb_sentencepiece.py)\n<p align=\"center\">\n<img width=\"700\" src=\"https://raw.githubusercontent.com/lyeoni/prenlp/master/images/tokenizer_comparison_IMDb.png\" align=\"middle\">\n</p>\n\n#### Comparisons with tokenizers on NSMC (Korean IMDb)\nBelow figure shows the classification accuracy from various tokenizer.\n- Code: [Mecab](https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_nsmc.py), [SentencePiece](https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_nsmc_sentencepiece.py)\n<p align=\"center\">\n<img width=\"700\" src=\"https://raw.githubusercontent.com/lyeoni/prenlp/master/images/tokenizer_comparison_NSMC.png\" align=\"middle\">\n</p>\n\n## Author\n- Hoyeon Lee @lyeoni\n- email : lyeoni.g@gmail.com\n- facebook : https://www.facebook.com/lyeoni.f\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/lyeoni/prenlp", "keywords": "nlp,text-preprocessing", "license": "", "maintainer": "", "maintainer_email": "", "name": "prenlp", "package_url": "https://pypi.org/project/prenlp/", "platform": "", "project_url": "https://pypi.org/project/prenlp/", "project_urls": {"Homepage": "https://github.com/lyeoni/prenlp"}, "release_url": "https://pypi.org/project/prenlp/0.0.12/", "requires_dist": ["nltk (==3.2.5)", "konlpy", "sentencepiece", "fasttext", "ijson", "py7zr (==0.5b5)"], "requires_python": "", "summary": "Preprocessing Library for Natural Language Processing", "version": "0.0.12", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>PreNLP</h1>\n<p><a href=\"https://pypi.org/project/prenlp/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85cd7a0d575157639362df39a875c15335adf484/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7072656e6c702e7376673f7374796c653d666c61742d73717561726526636f6c6f723d696d706f7274616e74\"></a>\n<a href=\"https://github.com/lyeoni/prenlp/blob/master/LICENSE\" rel=\"nofollow\"><img alt=\"License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5e6dd7aab747bb8b7907f83f0d805ac9cf6d66d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c79656f6e692f7072656e6c703f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://github.com/lyeoni/prenlp/stargazers\" rel=\"nofollow\"><img alt=\"GitHub stars\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8b01a50c9fd14a7aa7df538bce3e674c57bbd0df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c79656f6e692f7072656e6c703f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://github.com/lyeoni/prenlp/network/members\" rel=\"nofollow\"><img alt=\"GitHub forks\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/abdc57b65ec82c66d6a2d93c40f7a7ef36b15709/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6c79656f6e692f7072656e6c703f7374796c653d666c61742d73717561726526636f6c6f723d626c756576696f6c6574\"></a></p>\n<p>Preprocessing Library for Natural Language Processing</p>\n<h2>Installation</h2>\n<h3>Requirements</h3>\n<ul>\n<li>Python &gt;= 3.6</li>\n<li>Mecab morphological analyzer for Korean\n<pre><code>sh scripts/install_mecab.sh\n# Only for Mac OS users, run the code below before run install_mecab.sh script.\n# export MACOSX_DEPLOYMENT_TARGET=10.10\n# CFLAGS='-stdlib=libc++' pip install konlpy\n</code></pre>\n</li>\n<li>C++ Build tools for fastText\n<ul>\n<li>g++ &gt;= 4.7.2 or clang &gt;= 3.3</li>\n<li>For <strong>Windows</strong>, <a href=\"https://visualstudio.microsoft.com/downloads/\" rel=\"nofollow\">Visual Studio C++</a> is recommended.</li>\n</ul>\n</li>\n</ul>\n<h3>With pip</h3>\n<p>prenlp can be installed using pip as follows:</p>\n<pre><code>pip install prenlp\n</code></pre>\n<h2>Usage</h2>\n<h3>Data</h3>\n<h4>Dataset Loading</h4>\n<p>Popular datasets for NLP tasks are provided in prenlp. All datasets is stored in <code>/.data</code> directory.</p>\n<ul>\n<li>Sentiment Analysis: IMDb, NSMC</li>\n<li>Language Modeling: WikiText-2, WikiText-103, WikiText-ko, NamuWiki-ko</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Dataset</th>\n<th>Language</th>\n<th>Articles</th>\n<th>Sentences</th>\n<th>Tokens</th>\n<th>Vocab</th>\n<th>Size</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>WikiText-2</td>\n<td>English</td>\n<td>720</td>\n<td>-</td>\n<td>2,551,843</td>\n<td>33,278</td>\n<td>13.3MB</td>\n</tr>\n<tr>\n<td>WikiText-103</td>\n<td>English</td>\n<td>28,595</td>\n<td>-</td>\n<td>103,690,236</td>\n<td>267,735</td>\n<td>517.4MB</td>\n</tr>\n<tr>\n<td>WikiText-ko</td>\n<td>Korean</td>\n<td>477,946</td>\n<td>2,333,930</td>\n<td>131,184,780</td>\n<td>662,949</td>\n<td>667MB</td>\n</tr>\n<tr>\n<td>NamuWiki-ko</td>\n<td>Korean</td>\n<td>661,032</td>\n<td>16,288,639</td>\n<td>715,535,778</td>\n<td>1,130,008</td>\n<td>3.3GB</td>\n</tr>\n<tr>\n<td>WikiText-ko+NamuWiki-ko</td>\n<td>Korean</td>\n<td>1,138,978</td>\n<td>18,622,569</td>\n<td>846,720,558</td>\n<td>1,360,538</td>\n<td>3.95GB</td>\n</tr></tbody></table>\n<p>General use cases are as follows:</p>\n<h5><a href=\"https://github.com/lyeoni/prenlp/blob/develop/prenlp/data/dataset/language_modeling.py\" rel=\"nofollow\">WikiText-2 / WikiText-103</a></h5>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">wikitext2</span> <span class=\"o\">=</span> <span class=\"n\">prenlp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">WikiText2</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">wikitext2</span><span class=\"p\">)</span>\n<span class=\"mi\">3</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">valid</span><span class=\"p\">,</span> <span class=\"n\">test</span> <span class=\"o\">=</span> <span class=\"n\">prenlp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">WikiText2</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">train</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"s1\">'= Valkyria Chronicles III ='</span>\n</pre>\n<h5><a href=\"https://github.com/lyeoni/prenlp/blob/master/prenlp/data/dataset/sentiment.py\" rel=\"nofollow\">IMDB</a></h5>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">imdb_train</span><span class=\"p\">,</span> <span class=\"n\">imdb_test</span> <span class=\"o\">=</span> <span class=\"n\">prenlp</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">IMDB</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">imdb_train</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n<span class=\"p\">[</span><span class=\"s2\">\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;Alison Parker (Cristina Raines) is a successful top model, living with the lawyer Michael Lerman (Chris Sarandon) in his apartment. She tried to commit ...\"</span><span class=\"p\">,</span> <span class=\"s1\">'pos'</span><span class=\"p\">]</span>\n</pre>\n<h4><a href=\"https://github.com/lyeoni/prenlp/blob/master/prenlp/data/normalizer.py\" rel=\"nofollow\">Normalization</a></h4>\n<p>Frequently used normalization functions for text pre-processing are provided in prenlp.</p>\n<blockquote>\n<p>url, HTML tag, emoticon, email, phone number, etc.</p>\n</blockquote>\n<p>General use cases are as follows:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">prenlp.data</span> <span class=\"kn\">import</span> <span class=\"n\">Normalizer</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span> <span class=\"o\">=</span> <span class=\"n\">Normalizer</span><span class=\"p\">(</span><span class=\"n\">url_repl</span><span class=\"o\">=</span><span class=\"s1\">'[URL]'</span><span class=\"p\">,</span> <span class=\"n\">tag_repl</span><span class=\"o\">=</span><span class=\"s1\">'[TAG]'</span><span class=\"p\">,</span> <span class=\"n\">emoji_repl</span><span class=\"o\">=</span><span class=\"s1\">'[EMOJI]'</span><span class=\"p\">,</span> <span class=\"n\">email_repl</span><span class=\"o\">=</span><span class=\"s1\">'[EMAIL]'</span><span class=\"p\">,</span> <span class=\"n\">tel_repl</span><span class=\"o\">=</span><span class=\"s1\">'[TEL]'</span><span class=\"p\">,</span> <span class=\"n\">image_repl</span><span class=\"o\">=</span><span class=\"s1\">'[IMG]'</span><span class=\"p\">)</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"s1\">'Visit this link for more details: https://github.com/'</span><span class=\"p\">)</span>\n<span class=\"s1\">'Visit this link for more details: [URL]'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"s1\">'Use HTML with the desired attributes: &lt;img src=\"cat.jpg\" height=\"100\" /&gt;'</span><span class=\"p\">)</span>\n<span class=\"s1\">'Use HTML with the desired attributes: [TAG]'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"s1\">'Hello \ud83e\udd29, I love you \ud83d\udc93 !'</span><span class=\"p\">)</span>\n<span class=\"s1\">'Hello [EMOJI], I love you [EMOJI] !'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"s1\">'Contact me at lyeoni.g@gmail.com'</span><span class=\"p\">)</span>\n<span class=\"s1\">'Contact me at [EMAIL]'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"s1\">'Call +82 10-1234-5678'</span><span class=\"p\">)</span>\n<span class=\"s1\">'Call [TEL]'</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">normalizer</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"s1\">'Download our logo image, logo123.png, with transparent background.'</span><span class=\"p\">)</span>\n<span class=\"s1\">'Download our logo image, [IMG], with transparent background.'</span>\n</pre>\n<h3>Tokenizer</h3>\n<p>Frequently used (subword) tokenizers for text pre-processing are provided in prenlp.</p>\n<blockquote>\n<p>SentencePiece, NLTKMosesTokenizer, Mecab</p>\n</blockquote>\n<h4><a href=\"https://github.com/lyeoni/prenlp/blob/master/prenlp/tokenizer/tokenizer.py\" rel=\"nofollow\">SentencePiece</a></h4>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">prenlp.tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">SentencePiece</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">SentencePiece</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"o\">=</span><span class=\"s1\">'corpus.txt'</span><span class=\"p\">,</span> <span class=\"n\">model_prefix</span><span class=\"o\">=</span><span class=\"s1\">'sentencepiece'</span><span class=\"p\">,</span> <span class=\"n\">vocab_size</span><span class=\"o\">=</span><span class=\"mi\">10000</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">SentencePiece</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s1\">'sentencepiece.model'</span><span class=\"p\">)</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokenizer</span><span class=\"p\">(</span><span class=\"s1\">'Time is the most valuable thing a man can spend.'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u2581Time'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581is'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581the'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581most'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581valuable'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581thing'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581a'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581man'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581can'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581spend'</span><span class=\"p\">,</span> <span class=\"s1\">'.'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokenizer</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"s1\">'Time is the most valuable thing a man can spend.'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s1\">'\u2581Time'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581is'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581the'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581most'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581valuable'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581thing'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581a'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581man'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581can'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581spend'</span><span class=\"p\">,</span> <span class=\"s1\">'.'</span><span class=\"p\">]</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokenizer</span><span class=\"o\">.</span><span class=\"n\">detokenize</span><span class=\"p\">([</span><span class=\"s1\">'\u2581Time'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581is'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581the'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581most'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581valuable'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581thing'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581a'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581man'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581can'</span><span class=\"p\">,</span> <span class=\"s1\">'\u2581spend'</span><span class=\"p\">,</span> <span class=\"s1\">'.'</span><span class=\"p\">])</span>\n<span class=\"n\">Time</span> <span class=\"ow\">is</span> <span class=\"n\">the</span> <span class=\"n\">most</span> <span class=\"n\">valuable</span> <span class=\"n\">thing</span> <span class=\"n\">a</span> <span class=\"n\">man</span> <span class=\"n\">can</span> <span class=\"n\">spend</span><span class=\"o\">.</span>\n</pre>\n<h4><a href=\"https://github.com/lyeoni/prenlp/blob/master/prenlp/tokenizer/tokenizer.py\" rel=\"nofollow\">Moses tokenizer</a></h4>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">prenlp.tokenizer</span> <span class=\"kn\">import</span> <span class=\"n\">NLTKMosesTokenizer</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokenizer</span> <span class=\"o\">=</span> <span class=\"n\">NLTKMosesTokenizer</span><span class=\"p\">()</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokenizer</span><span class=\"p\">(</span><span class=\"s1\">'Time is the most valuable thing a man can spend.'</span><span class=\"p\">)</span>\n<span class=\"p\">[</span><span class=\"s1\">'Time'</span><span class=\"p\">,</span> <span class=\"s1\">'is'</span><span class=\"p\">,</span> <span class=\"s1\">'the'</span><span class=\"p\">,</span> <span class=\"s1\">'most'</span><span class=\"p\">,</span> <span class=\"s1\">'valuable'</span><span class=\"p\">,</span> <span class=\"s1\">'thing'</span><span class=\"p\">,</span> <span class=\"s1\">'a'</span><span class=\"p\">,</span> <span class=\"s1\">'man'</span><span class=\"p\">,</span> <span class=\"s1\">'can'</span><span class=\"p\">,</span> <span class=\"s1\">'spend'</span><span class=\"p\">,</span> <span class=\"s1\">'.'</span><span class=\"p\">]</span>\n</pre>\n<h4>Comparisons with tokenizers on IMDb</h4>\n<p>Below figure shows the classification accuracy from various tokenizer.</p>\n<ul>\n<li>Code: <a href=\"https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_imdb.py\" rel=\"nofollow\">NLTKMosesTokenizer</a>, <a href=\"https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_imdb_sentencepiece.py\" rel=\"nofollow\">SentencePiece</a></li>\n</ul>\n<p align=\"center\">\n<img align=\"middle\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/665478edea7b3f08f0d29cd29d1087029a3d139e/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c79656f6e692f7072656e6c702f6d61737465722f696d616765732f746f6b656e697a65725f636f6d70617269736f6e5f494d44622e706e67\" width=\"700\">\n</p>\n<h4>Comparisons with tokenizers on NSMC (Korean IMDb)</h4>\n<p>Below figure shows the classification accuracy from various tokenizer.</p>\n<ul>\n<li>Code: <a href=\"https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_nsmc.py\" rel=\"nofollow\">Mecab</a>, <a href=\"https://github.com/lyeoni/prenlp/blob/master/examples/fasttext_nsmc_sentencepiece.py\" rel=\"nofollow\">SentencePiece</a></li>\n</ul>\n<p align=\"center\">\n<img align=\"middle\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2e87a220f1d87330c15b0f45b0cf1e4e0b13076c/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6c79656f6e692f7072656e6c702f6d61737465722f696d616765732f746f6b656e697a65725f636f6d70617269736f6e5f4e534d432e706e67\" width=\"700\">\n</p>\n<h2>Author</h2>\n<ul>\n<li>Hoyeon Lee @lyeoni</li>\n<li>email : <a href=\"mailto:lyeoni.g@gmail.com\">lyeoni.g@gmail.com</a></li>\n<li>facebook : <a href=\"https://www.facebook.com/lyeoni.f\" rel=\"nofollow\">https://www.facebook.com/lyeoni.f</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6574559, "releases": {"0.0.10": [{"comment_text": "", "digests": {"md5": "178719dc47963ed7be072f4af902b1a1", "sha256": "fcda60ca3a5f45ee06493bf739c32af1504576484f0b72ee722ffa708048131a"}, "downloads": -1, "filename": "prenlp-0.0.10-py3-none-any.whl", "has_sig": false, "md5_digest": "178719dc47963ed7be072f4af902b1a1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 77738, "upload_time": "2020-01-13T08:59:59", "upload_time_iso_8601": "2020-01-13T08:59:59.355223Z", "url": "https://files.pythonhosted.org/packages/b7/73/40c75434cca0d37b2626f8e478ac2538918247b327e7b7455e9e6065359a/prenlp-0.0.10-py3-none-any.whl", "yanked": false}], "0.0.11": [{"comment_text": "", "digests": {"md5": "daf521746f747cc5218a504061eaca2b", "sha256": "d5f7bd2d6521b1559764bedfc3cd40aae797bc46a32693a91174d2769e76e7c9"}, "downloads": -1, "filename": "prenlp-0.0.11-py3-none-any.whl", "has_sig": false, "md5_digest": "daf521746f747cc5218a504061eaca2b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 77972, "upload_time": "2020-02-03T09:52:09", "upload_time_iso_8601": "2020-02-03T09:52:09.377480Z", "url": "https://files.pythonhosted.org/packages/be/ca/1851eda911dd9fa8425806d261172a72971eadcc0eb0c424ae9a8c6115d4/prenlp-0.0.11-py3-none-any.whl", "yanked": false}], "0.0.12": [{"comment_text": "", "digests": {"md5": "d986c8565b893ce337a7ef2cbdb5eafb", "sha256": "b8b0ba0515cf3bbf820ef761827abf9195f2512897ea79bc104c7a5bc86b8875"}, "downloads": -1, "filename": "prenlp-0.0.12-py3-none-any.whl", "has_sig": false, "md5_digest": "d986c8565b893ce337a7ef2cbdb5eafb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 78680, "upload_time": "2020-02-05T07:30:50", "upload_time_iso_8601": "2020-02-05T07:30:50.591274Z", "url": "https://files.pythonhosted.org/packages/d4/06/c662a331f96be59b6ef93081c6b3edfd3412205763083805670546e13d65/prenlp-0.0.12-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "2999e355677340186f608947865c2e4e", "sha256": "528c6a654043c0371a037c3a3539f2edf9ba1c96712b700da0552a981e077b8b"}, "downloads": -1, "filename": "prenlp-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "2999e355677340186f608947865c2e4e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5563, "upload_time": "2019-11-15T08:08:08", "upload_time_iso_8601": "2019-11-15T08:08:08.935726Z", "url": "https://files.pythonhosted.org/packages/db/a1/c96c0350f9f891944e0dc03be4496310b5937725b25c6245db496d9db24f/prenlp-0.0.2-py3-none-any.whl", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "2b85a31bbb75d80fa7a8a82db48a26a3", "sha256": "2ac9dac44c7e7d9388ae94b429e29baa8d3774039b98abfdd783d809c9dd452f"}, "downloads": -1, "filename": "prenlp-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "2b85a31bbb75d80fa7a8a82db48a26a3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 18606, "upload_time": "2019-12-11T08:06:54", "upload_time_iso_8601": "2019-12-11T08:06:54.523822Z", "url": "https://files.pythonhosted.org/packages/4c/8e/e7f4e0c8ec12fc65c957b306c9c55f16d3b1ded5302cf364229cccf464a6/prenlp-0.0.3-py3-none-any.whl", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "85f279c10ad51a88d4f5d01a7ccf8cce", "sha256": "2c9783027b01a8091dca1dd2ec1cecd6e317237dd7d92d45378640cb8eb8eb66"}, "downloads": -1, "filename": "prenlp-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "85f279c10ad51a88d4f5d01a7ccf8cce", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 33985, "upload_time": "2019-12-13T08:54:35", "upload_time_iso_8601": "2019-12-13T08:54:35.312576Z", "url": "https://files.pythonhosted.org/packages/68/3c/5bb60a4b4911a277ac58bb7dc7a621cb06d695ec331df9b335bf143112b1/prenlp-0.0.4-py3-none-any.whl", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "607bffa061837f7f7345244a0133e14a", "sha256": "9d46482cfe0cdb69f068b75df37632c77d465c0759752dc5425a27341c8e4e2d"}, "downloads": -1, "filename": "prenlp-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "607bffa061837f7f7345244a0133e14a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35086, "upload_time": "2019-12-17T09:02:01", "upload_time_iso_8601": "2019-12-17T09:02:01.921559Z", "url": "https://files.pythonhosted.org/packages/4f/1f/db2347c13ea62ad6b4c82b2e8a5831f5068c6cae942141d8d5258a49450c/prenlp-0.0.5-py3-none-any.whl", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "733dd93b50657de77a4cf719362bf65b", "sha256": "eb3896ae02f30c8ef875551a1394c50cd67f4cc3f566fb5c24242aac62f779c9"}, "downloads": -1, "filename": "prenlp-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "733dd93b50657de77a4cf719362bf65b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35205, "upload_time": "2019-12-17T09:29:52", "upload_time_iso_8601": "2019-12-17T09:29:52.709088Z", "url": "https://files.pythonhosted.org/packages/64/fa/1758213114c9bfe09276644b5d99a2d2e4d71e45c5ceffc9b0aaf56a0783/prenlp-0.0.6-py3-none-any.whl", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "d29e3938c10fe278567429779dcdd9d0", "sha256": "6ec19705ed82ec369948cbf293f9d6611de2f1a37f011f67e5c3c465fbde1b9b"}, "downloads": -1, "filename": "prenlp-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "d29e3938c10fe278567429779dcdd9d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 40937, "upload_time": "2019-12-27T08:18:20", "upload_time_iso_8601": "2019-12-27T08:18:20.810149Z", "url": "https://files.pythonhosted.org/packages/80/57/ddecf9506c0a7fc6347da609d82480d5130a48d5e4390e2f64d64c1c5e32/prenlp-0.0.7-py3-none-any.whl", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "7349d6097fec85ad6037caf731e9a129", "sha256": "6611cc0d3ccd9e13d1063d625bb5a829879a8469c1cbff85e10ca6f57f0f723a"}, "downloads": -1, "filename": "prenlp-0.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "7349d6097fec85ad6037caf731e9a129", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 77696, "upload_time": "2020-01-09T10:49:47", "upload_time_iso_8601": "2020-01-09T10:49:47.262778Z", "url": "https://files.pythonhosted.org/packages/86/0a/9b8aa987195c23db6f5f23e2aee25f505db0984350d1ed3ba4b35177369b/prenlp-0.0.8-py3-none-any.whl", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "91ea093e87211eb016621c03f3cc03f9", "sha256": "193d4b045bd4444b8d9d7c9d366afc01df31f1ce5154504660694906a62387a5"}, "downloads": -1, "filename": "prenlp-0.0.9-py3-none-any.whl", "has_sig": false, "md5_digest": "91ea093e87211eb016621c03f3cc03f9", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 77707, "upload_time": "2020-01-10T09:19:11", "upload_time_iso_8601": "2020-01-10T09:19:11.796693Z", "url": "https://files.pythonhosted.org/packages/92/f9/d8e60ee6d6ffdbb7106accdd822e875f70ad285106c3f90f9404f067fcb5/prenlp-0.0.9-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "d986c8565b893ce337a7ef2cbdb5eafb", "sha256": "b8b0ba0515cf3bbf820ef761827abf9195f2512897ea79bc104c7a5bc86b8875"}, "downloads": -1, "filename": "prenlp-0.0.12-py3-none-any.whl", "has_sig": false, "md5_digest": "d986c8565b893ce337a7ef2cbdb5eafb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 78680, "upload_time": "2020-02-05T07:30:50", "upload_time_iso_8601": "2020-02-05T07:30:50.591274Z", "url": "https://files.pythonhosted.org/packages/d4/06/c662a331f96be59b6ef93081c6b3edfd3412205763083805670546e13d65/prenlp-0.0.12-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:19:53 2020"}