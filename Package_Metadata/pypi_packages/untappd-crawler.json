{"info": {"author": "Arun Kumar Ramanathan", "author_email": "rako.aka.arun@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7"], "description": "Tool for crawling and exporting data data from Untappd public site\n==================================================================\n\n\nNote\n----\n\nThis is still early in the development and a bit rough around the edges.\nAny bug reports, feature suggestions, etc are greatly appreciated. :)\n\n\nInstallation and usage\n----------------------\n\n**Installation**\nSince this is a Python package available on PyPi you can install it like \nany other Python package.\n\n.. code-block:: shell\n\n    # on modern systems with Python you can install with pip\n    $ pip install untappd_crawler\n    # on older systems you can install using easy_install\n    $ easy_install untappd_crawler\n\n**Usage**\nThe commands should be mostly self-documenting in how they are defined,\nwhich is made available through the ``help`` command.\n\n.. code-block:: shell\n\n    $ untappd_crawler\n    usage: untappd_crawler -o <output_file_path> [-u <username>] [-b <beer_ids_repeated>]\n\n    arguments:\n      -h, --help            show this help message and exit\n      Rest are in the help\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/therako/untappd_crawler", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "untappd-crawler", "package_url": "https://pypi.org/project/untappd-crawler/", "platform": "", "project_url": "https://pypi.org/project/untappd-crawler/", "project_urls": {"Homepage": "https://github.com/therako/untappd_crawler"}, "release_url": "https://pypi.org/project/untappd-crawler/0.2/", "requires_dist": null, "requires_python": "", "summary": "A CLI client for exporting elasticsearch data to csv", "version": "0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"note\">\n<h2>Note</h2>\n<p>This is still early in the development and a bit rough around the edges.\nAny bug reports, feature suggestions, etc are greatly appreciated. :)</p>\n</div>\n<div id=\"installation-and-usage\">\n<h2>Installation and usage</h2>\n<p><strong>Installation</strong>\nSince this is a Python package available on PyPi you can install it like\nany other Python package.</p>\n<pre><span class=\"c1\"># on modern systems with Python you can install with pip\n</span>$ pip install untappd_crawler\n<span class=\"c1\"># on older systems you can install using easy_install\n</span>$ easy_install untappd_crawler\n</pre>\n<p><strong>Usage</strong>\nThe commands should be mostly self-documenting in how they are defined,\nwhich is made available through the <tt>help</tt> command.</p>\n<pre>$ untappd_crawler\nusage: untappd_crawler -o &lt;output_file_path&gt; <span class=\"o\">[</span>-u &lt;username&gt;<span class=\"o\">]</span> <span class=\"o\">[</span>-b &lt;beer_ids_repeated&gt;<span class=\"o\">]</span>\n\narguments:\n  -h, --help            show this <span class=\"nb\">help</span> message and <span class=\"nb\">exit</span>\n  Rest are in the <span class=\"nb\">help</span>\n</pre>\n</div>\n\n          </div>"}, "last_serial": 3948582, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "1334a6cc701b1ce8d48e8bc1e816980e", "sha256": "fab1ed49edba30063727f5dae9a69de0b8a2a090c70a54d3f6aa056dd1dad0b2"}, "downloads": -1, "filename": "untappd_crawler-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1334a6cc701b1ce8d48e8bc1e816980e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6606, "upload_time": "2018-06-11T00:23:35", "upload_time_iso_8601": "2018-06-11T00:23:35.776225Z", "url": "https://files.pythonhosted.org/packages/44/f6/1afce09abda67a5c2dcae15f19410697acc76cd522b06cfe69a13c00ed39/untappd_crawler-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fbeac598054d923268c951d3cb92eb94", "sha256": "fe3d5703cea33b1caa6a5274dca43c696948222de3f51267e1137921e3b697a8"}, "downloads": -1, "filename": "untappd_crawler-0.1.tar.gz", "has_sig": false, "md5_digest": "fbeac598054d923268c951d3cb92eb94", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4152, "upload_time": "2018-06-11T00:23:36", "upload_time_iso_8601": "2018-06-11T00:23:36.975835Z", "url": "https://files.pythonhosted.org/packages/f0/4e/840cc34110985cbc1b312e1565a87555753cf49b4694f58762854753a60d/untappd_crawler-0.1.tar.gz", "yanked": false}], "0.2": [{"comment_text": "", "digests": {"md5": "bd9e816c1cf18e99841c8dbfe8ae0ad5", "sha256": "1cfaf7d8c1ab9541113d7b3a43d69156d2f51e3a996dc08bd73c06c139286105"}, "downloads": -1, "filename": "untappd_crawler-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "bd9e816c1cf18e99841c8dbfe8ae0ad5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6601, "upload_time": "2018-06-11T01:44:57", "upload_time_iso_8601": "2018-06-11T01:44:57.929856Z", "url": "https://files.pythonhosted.org/packages/eb/47/2b92b9efa19372bd05747ff85cddce9c31b0d5eee553b7b95bde897116a7/untappd_crawler-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "85ad0bcaebb2f2c9644de6a4b8365de8", "sha256": "ae69b0631de506f58bd328ebdff3e53c8ce1d5706bb020be668c2f8daceaf541"}, "downloads": -1, "filename": "untappd_crawler-0.2.tar.gz", "has_sig": false, "md5_digest": "85ad0bcaebb2f2c9644de6a4b8365de8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4163, "upload_time": "2018-06-11T01:44:59", "upload_time_iso_8601": "2018-06-11T01:44:59.080468Z", "url": "https://files.pythonhosted.org/packages/9b/59/4caf6b3e5c86f0f7e3e41ecb94d7a6ed8ab71d80d41d6163c22d82ef1c49/untappd_crawler-0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bd9e816c1cf18e99841c8dbfe8ae0ad5", "sha256": "1cfaf7d8c1ab9541113d7b3a43d69156d2f51e3a996dc08bd73c06c139286105"}, "downloads": -1, "filename": "untappd_crawler-0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "bd9e816c1cf18e99841c8dbfe8ae0ad5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6601, "upload_time": "2018-06-11T01:44:57", "upload_time_iso_8601": "2018-06-11T01:44:57.929856Z", "url": "https://files.pythonhosted.org/packages/eb/47/2b92b9efa19372bd05747ff85cddce9c31b0d5eee553b7b95bde897116a7/untappd_crawler-0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "85ad0bcaebb2f2c9644de6a4b8365de8", "sha256": "ae69b0631de506f58bd328ebdff3e53c8ce1d5706bb020be668c2f8daceaf541"}, "downloads": -1, "filename": "untappd_crawler-0.2.tar.gz", "has_sig": false, "md5_digest": "85ad0bcaebb2f2c9644de6a4b8365de8", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4163, "upload_time": "2018-06-11T01:44:59", "upload_time_iso_8601": "2018-06-11T01:44:59.080468Z", "url": "https://files.pythonhosted.org/packages/9b/59/4caf6b3e5c86f0f7e3e41ecb94d7a6ed8ab71d80d41d6163c22d82ef1c49/untappd_crawler-0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:40:03 2020"}