{"info": {"author": "David P. Fleming", "author_email": "dflemin3@uw.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Astronomy"], "description": "**approxposterior**\n===================\n\n***A Python package for approximate Bayesian inference with computationally-expensive models***\n\n<p>\n<a href=\"https://github.com/dflemin3/approxposterior\">\n<img src=\"https://img.shields.io/badge/GitHub-dflemin3%2Fapproxposterior-blue.svg?style=flat\"></a>\n<a href=\"https://github.com/dflemin3/approxposterior/blob/master/LICENSE\">\n<img src=\"https://img.shields.io/badge/license-MIT-blue.svg?style=flat\"></a>\n<a href=\"https://travis-ci.org/dflemin3/approxposterior\">\n<img src=\"http://img.shields.io/travis/dflemin3/approxposterior/master.svg?style=flat\"></a>\n<a href=\"https://doi.org/10.21105/joss.00781\">\n<img src=\"http://joss.theoj.org/papers/10.21105/joss.00781/status.svg\"></a>\n<a href=\"https://pypi.python.org/pypi/approxposterior/\">\n<img src=\"https://img.shields.io/pypi/pyversions/approxposterior.svg\"></a>\n<a href=\"https://conda.anaconda.org/conda-forge\">\n<img src=\"https://anaconda.org/conda-forge/approxposterior/badges/installer/conda.svg\"></a>\n<a href=\"https://anaconda.org/conda-forge/approxposterior\">\n<img src=\"https://anaconda.org/conda-forge/approxposterior/badges/downloads.svg\"></a>\n<a href=\"https://coveralls.io/github/dflemin3/approxposterior?branch=master\">\n<img src=\"https://coveralls.io/repos/github/dflemin3/approxposterior/badge.svg?branch=master\"></a>\n<a href=\"https://dflemin3.github.io/approxposterior/\">\n<img src=\"https://img.shields.io/badge/Docs-Read%20the%20docs-blue\"></a>\n</p>\n\nOverview\n========\n\n`approxposterior` is a Python package for efficient approximate Bayesian\ninference and Bayesian optimization of computationally-expensive models. `approxposterior`\ntrains a Gaussian process (GP) surrogate for the computationally-expensive model\nand employs an active learning approach to iteratively improve the GPs predictive\nperformance while minimizing the number of calls to the expensive model required\nto generate the GP's training set.\n\n`approxposterior` implements both the [Bayesian Active Learning for Posterior Estimation (BAPE, Kandasamy et al. (2017))](https://www.sciencedirect.com/science/article/abs/pii/S0004370216301394) and [Adaptive Gaussian process approximation for Bayesian inference with expensive likelihood functions (AGP, Wang & Li (2018))](https://www.semanticscholar.org/paper/Adaptive-Gaussian-Process-Approximation-for-with-Wang-Li/a11e3a4144898920835ccff7ef0ed0b159b94bc6) algorithms for estimating posterior probability distributions for use with inference problems with computationally-expensive models. In such situations,\nthe goal is to infer posterior probability distributions for model parameters, given some data, with the additional constraint of minimizing the number of forward model evaluations given the model's assumed large computational cost.  `approxposterior` trains a Gaussian Process (GP) surrogate model for the likelihood evaluation by modeling the covariances in logprobability (logprior + loglikelihood) space. `approxposterior` then uses this GP within an MCMC sampler for each likelihood evaluation to perform the inference. `approxposterior` iteratively improves the GP's predictive performance by leveraging the inherent uncertainty in the GP's predictions to identify high-likelihood regions in parameter space where the GP is uncertain.  `approxposterior` then evaluates the forward model at these points to expand the training set in relevant regions of parameter space, re-training the GP to maximize its predictive ability while minimizing the size of the training set.  Check out [the BAPE paper](https://www.sciencedirect.com/science/article/abs/pii/S0004370216301394) by Kandasamy et al. (2017) and [the AGP paper](https://www.semanticscholar.org/paper/Adaptive-Gaussian-Process-Approximation-for-with-Wang-Li/a11e3a4144898920835ccff7ef0ed0b159b94bc6) by Wang & Li (2018) for in-depth descriptions of the respective algorithms.\n\nDocumentation\n=============\n\nCheck out the documentation at [https://dflemin3.github.io/approxposterior/](https://dflemin3.github.io/approxposterior/) for a more in-depth explanation about the code, detailed API notes, numerous examples with figures.\n\nInstallation\n============\n\nUsing conda:\n\n```bash\nconda install -c conda-forge approxposterior\n```\n\nUsing pip:\n\n```bash\npip install approxposterior\n```\n\nThis step can fail if george (the Python Gaussian Process package) is not properly installed and compiled.\nTo install george, run\n\n```bash\nconda install -c conda-forge george\n```\n\nFrom source:\n\n```bash\ngit clone https://github.com/dflemin3/approxposterior.git\ncd approxposterior\npython setup.py install\n```\n\nA simple example\n================\n\nBelow is a simple application of `approxposterior` based on the Wang & Li (2017) example.\n\n```python\nfrom approxposterior import approx, gpUtils, likelihood as lh, utility as ut\nimport numpy as np\n\n# Define algorithm parameters\nm0 = 50                           # Initial size of training set\nm = 20                            # Number of new points to find each iteration\nnmax = 2                          # Maximum number of iterations\nbounds = [(-5,5), (-5,5)]         # Prior bounds\nalgorithm = \"bape\"                # Use the Kandasamy et al. (2017) formalism\nseed = 57                         # RNG seed\nnp.random.seed(seed)\n\n# emcee MCMC parameters\nsamplerKwargs = {\"nwalkers\" : 20}        # emcee.EnsembleSampler parameters\nmcmcKwargs = {\"iterations\" : int(2.0e4)} # emcee.EnsembleSampler.run_mcmc parameters\n\n# Sample design points from prior\ntheta = lh.rosenbrockSample(m0)\n\n# Evaluate forward model log likelihood + lnprior for each theta\ny = np.zeros(len(theta))\nfor ii in range(len(theta)):\n    y[ii] = lh.rosenbrockLnlike(theta[ii]) + lh.rosenbrockLnprior(theta[ii])\n\n# Default GP with an ExpSquaredKernel\ngp = gpUtils.defaultGP(theta, y, white_noise=-12)\n\n# Initialize object using the Wang & Li (2018) Rosenbrock function example\nap = approx.ApproxPosterior(theta=theta,\n                            y=y,\n                            gp=gp,\n                            lnprior=lh.rosenbrockLnprior,\n                            lnlike=lh.rosenbrockLnlike,\n                            priorSample=lh.rosenbrockSample,\n                            bounds=bounds,\n                            algorithm=algorithm)\n\n# Run!\nap.run(m=m, nmax=nmax, estBurnin=True, nGPRestarts=3, mcmcKwargs=mcmcKwargs,\n       cache=False, samplerKwargs=samplerKwargs, verbose=True, thinChains=False,\n       onlyLastMCMC=True)\n\n# Check out the final posterior distribution!\nimport corner\n\n# Load in chain from last iteration\nsamples = ap.sampler.get_chain(discard=ap.iburns[-1], flat=True, thin=ap.ithins[-1])\n\n# Corner plot!\nfig = corner.corner(samples, quantiles=[0.16, 0.5, 0.84], show_titles=True,\n                    scale_hist=True, plot_contours=True)\n\n# Plot where forward model was evaluated - uncomment to plot!\nfig.axes[2].scatter(ap.theta[m0:,0], ap.theta[m0:,1], s=10, color=\"red\", zorder=20)\n\n# Save figure\nfig.savefig(\"finalPosterior.png\", bbox_inches=\"tight\")\n```\n\nThe final distribution will look something like this:\n\n![finalPosterior](doc/_figures/finalPosterior.png)\n\nThe red points were selected by `approxposterior` by maximizing the BAPE utility function.\nAt each red point, `approxposterior` ran the forward model to evaluate the true likelihood\nand added this input-likelihood pair to the GP's training set. We retrain the GP each time\nto improve its predictive ability. Note how the points are selected in regions of\nhigh posterior density, precisely where we would want to maximize the GP's predictive ability! By using the\nBAPE point selection scheme, `approxposterior` does not waste computational resources by\nevaluating the forward model in low likelihood regions.\n\nCheck out the [examples](https://github.com/dflemin3/approxposterior/tree/master/examples/Notebooks) directory for Jupyter Notebook examples and explanations. Check out the full [documentation](https://dflemin3.github.io/approxposterior/) for a more in-depth explanation of classes, methods, variables, and how to use the code.\n\nContribution\n============\n\nIf you would like to contribute to this code, please feel free to fork the repository, make some edits, and open a pull request.\nIf you find a bug, have a suggestion, etc, please open up an issue!\n\nCitation\n========\n\nIf you use this code, please cite the following:\n\nFleming and VanderPlas (2018):\n\n```bash\n@ARTICLE{Fleming2018,\n   author = {{Fleming}, D.~P. and {VanderPlas}, J.},\n    title = \"{approxposterior: Approximate Posterior Distributions in Python}\",\n  journal = {The Journal of Open Source Software},\n     year = 2018,\n    month = sep,\n   volume = 3,\n    pages = {781},\n      doi = {10.21105/joss.00781},\n   adsurl = {http://adsabs.harvard.edu/abs/2018JOSS....3..781P},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n```\n\nKandasamy et al. (2017):\n\n```bash\n@article{Kandasamy2017,\ntitle = \"Query efficient posterior estimation in scientific experiments via Bayesian active learning\",\njournal = \"Artificial Intelligence\",\nvolume = \"243\",\npages = \"45 - 56\",\nyear = \"2017\",\nissn = \"0004-3702\",\ndoi = \"https://doi.org/10.1016/j.artint.2016.11.002\",\nurl = \"http://www.sciencedirect.com/science/article/pii/S0004370216301394\",\nauthor = \"Kirthevasan Kandasamy and Jeff Schneider and Barnab\u00e1s P\u00f3czos\",\nkeywords = \"Posterior estimation, Active learning, Gaussian processes\"}\n```\n\nWang & Li (2018):\n\n```bash\n@article{Wang2018,\nauthor = {Wang, Hongqiao and Li, Jinglai},\ntitle = {Adaptive Gaussian Process Approximation for Bayesian Inference with Expensive Likelihood Functions},\njournal = {Neural Computation},\nvolume = {30},\nnumber = {11},\npages = {3072-3094},\nyear = {2018},\ndoi = {10.1162/neco\\_a\\_01127},\nURL = { https://doi.org/10.1162/neco_a_01127},\neprint = {https://doi.org/10.1162/neco_a_01127}}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dflemin3/approxposterior", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "approxposterior", "package_url": "https://pypi.org/project/approxposterior/", "platform": "", "project_url": "https://pypi.org/project/approxposterior/", "project_urls": {"Homepage": "https://github.com/dflemin3/approxposterior"}, "release_url": "https://pypi.org/project/approxposterior/0.4/", "requires_dist": ["numpy", "matplotlib (>=2.0.0)", "scipy", "george", "emcee (>=3.0)", "corner", "sklearn", "pybind11", "pytest", "h5py"], "requires_python": "", "summary": "Gaussian Process Approximation to Posterior Distributions", "version": "0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1><strong>approxposterior</strong></h1>\n<p><em><strong>A Python package for approximate Bayesian inference with computationally-expensive models</strong></em></p>\n<p>\n<a href=\"https://github.com/dflemin3/approxposterior\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7b0df7e5fc7a68fd94768c86880f2697b425390d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d64666c656d696e33253246617070726f78706f73746572696f722d626c75652e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://github.com/dflemin3/approxposterior/blob/master/LICENSE\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9e5be039daf9eba6b6bc47b88defd227ac24d66b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://travis-ci.org/dflemin3/approxposterior\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fa1d88104d75b0854a8c9396ee1f885b2302600a/687474703a2f2f696d672e736869656c64732e696f2f7472617669732f64666c656d696e332f617070726f78706f73746572696f722f6d61737465722e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://doi.org/10.21105/joss.00781\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/eb2db2683f68cd589a94c432448ce703beacb8c0/687474703a2f2f6a6f73732e7468656f6a2e6f72672f7061706572732f31302e32313130352f6a6f73732e30303738312f7374617475732e737667\"></a>\n<a href=\"https://pypi.python.org/pypi/approxposterior/\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/678a32dd70a9f85c03c9fd067ed897978c947773/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f617070726f78706f73746572696f722e737667\"></a>\n<a href=\"https://conda.anaconda.org/conda-forge\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5826e00cf73a0ff46f29b9891514d5242c520fdb/68747470733a2f2f616e61636f6e64612e6f72672f636f6e64612d666f7267652f617070726f78706f73746572696f722f6261646765732f696e7374616c6c65722f636f6e64612e737667\"></a>\n<a href=\"https://anaconda.org/conda-forge/approxposterior\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/81e9c14a56b3fe6d4f766302c1cf594f8b08f086/68747470733a2f2f616e61636f6e64612e6f72672f636f6e64612d666f7267652f617070726f78706f73746572696f722f6261646765732f646f776e6c6f6164732e737667\"></a>\n<a href=\"https://coveralls.io/github/dflemin3/approxposterior?branch=master\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2066eab3294dad838ad338649b9d0856bac32d6d/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64666c656d696e332f617070726f78706f73746572696f722f62616467652e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://dflemin3.github.io/approxposterior/\" rel=\"nofollow\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fe7c5695840bb955dc44d0c89984ce9158e0e83d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63732d52656164253230746865253230646f63732d626c7565\"></a>\n</p>\n<h1>Overview</h1>\n<p><code>approxposterior</code> is a Python package for efficient approximate Bayesian\ninference and Bayesian optimization of computationally-expensive models. <code>approxposterior</code>\ntrains a Gaussian process (GP) surrogate for the computationally-expensive model\nand employs an active learning approach to iteratively improve the GPs predictive\nperformance while minimizing the number of calls to the expensive model required\nto generate the GP's training set.</p>\n<p><code>approxposterior</code> implements both the <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0004370216301394\" rel=\"nofollow\">Bayesian Active Learning for Posterior Estimation (BAPE, Kandasamy et al. (2017))</a> and <a href=\"https://www.semanticscholar.org/paper/Adaptive-Gaussian-Process-Approximation-for-with-Wang-Li/a11e3a4144898920835ccff7ef0ed0b159b94bc6\" rel=\"nofollow\">Adaptive Gaussian process approximation for Bayesian inference with expensive likelihood functions (AGP, Wang &amp; Li (2018))</a> algorithms for estimating posterior probability distributions for use with inference problems with computationally-expensive models. In such situations,\nthe goal is to infer posterior probability distributions for model parameters, given some data, with the additional constraint of minimizing the number of forward model evaluations given the model's assumed large computational cost.  <code>approxposterior</code> trains a Gaussian Process (GP) surrogate model for the likelihood evaluation by modeling the covariances in logprobability (logprior + loglikelihood) space. <code>approxposterior</code> then uses this GP within an MCMC sampler for each likelihood evaluation to perform the inference. <code>approxposterior</code> iteratively improves the GP's predictive performance by leveraging the inherent uncertainty in the GP's predictions to identify high-likelihood regions in parameter space where the GP is uncertain.  <code>approxposterior</code> then evaluates the forward model at these points to expand the training set in relevant regions of parameter space, re-training the GP to maximize its predictive ability while minimizing the size of the training set.  Check out <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0004370216301394\" rel=\"nofollow\">the BAPE paper</a> by Kandasamy et al. (2017) and <a href=\"https://www.semanticscholar.org/paper/Adaptive-Gaussian-Process-Approximation-for-with-Wang-Li/a11e3a4144898920835ccff7ef0ed0b159b94bc6\" rel=\"nofollow\">the AGP paper</a> by Wang &amp; Li (2018) for in-depth descriptions of the respective algorithms.</p>\n<h1>Documentation</h1>\n<p>Check out the documentation at <a href=\"https://dflemin3.github.io/approxposterior/\" rel=\"nofollow\">https://dflemin3.github.io/approxposterior/</a> for a more in-depth explanation about the code, detailed API notes, numerous examples with figures.</p>\n<h1>Installation</h1>\n<p>Using conda:</p>\n<pre>conda install -c conda-forge approxposterior\n</pre>\n<p>Using pip:</p>\n<pre>pip install approxposterior\n</pre>\n<p>This step can fail if george (the Python Gaussian Process package) is not properly installed and compiled.\nTo install george, run</p>\n<pre>conda install -c conda-forge george\n</pre>\n<p>From source:</p>\n<pre>git clone https://github.com/dflemin3/approxposterior.git\n<span class=\"nb\">cd</span> approxposterior\npython setup.py install\n</pre>\n<h1>A simple example</h1>\n<p>Below is a simple application of <code>approxposterior</code> based on the Wang &amp; Li (2017) example.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">approxposterior</span> <span class=\"kn\">import</span> <span class=\"n\">approx</span><span class=\"p\">,</span> <span class=\"n\">gpUtils</span><span class=\"p\">,</span> <span class=\"n\">likelihood</span> <span class=\"k\">as</span> <span class=\"n\">lh</span><span class=\"p\">,</span> <span class=\"n\">utility</span> <span class=\"k\">as</span> <span class=\"n\">ut</span>\n<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n\n<span class=\"c1\"># Define algorithm parameters</span>\n<span class=\"n\">m0</span> <span class=\"o\">=</span> <span class=\"mi\">50</span>                           <span class=\"c1\"># Initial size of training set</span>\n<span class=\"n\">m</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>                            <span class=\"c1\"># Number of new points to find each iteration</span>\n<span class=\"n\">nmax</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>                          <span class=\"c1\"># Maximum number of iterations</span>\n<span class=\"n\">bounds</span> <span class=\"o\">=</span> <span class=\"p\">[(</span><span class=\"o\">-</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">5</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">)]</span>         <span class=\"c1\"># Prior bounds</span>\n<span class=\"n\">algorithm</span> <span class=\"o\">=</span> <span class=\"s2\">\"bape\"</span>                <span class=\"c1\"># Use the Kandasamy et al. (2017) formalism</span>\n<span class=\"n\">seed</span> <span class=\"o\">=</span> <span class=\"mi\">57</span>                         <span class=\"c1\"># RNG seed</span>\n<span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># emcee MCMC parameters</span>\n<span class=\"n\">samplerKwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"nwalkers\"</span> <span class=\"p\">:</span> <span class=\"mi\">20</span><span class=\"p\">}</span>        <span class=\"c1\"># emcee.EnsembleSampler parameters</span>\n<span class=\"n\">mcmcKwargs</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"iterations\"</span> <span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mf\">2.0e4</span><span class=\"p\">)}</span> <span class=\"c1\"># emcee.EnsembleSampler.run_mcmc parameters</span>\n\n<span class=\"c1\"># Sample design points from prior</span>\n<span class=\"n\">theta</span> <span class=\"o\">=</span> <span class=\"n\">lh</span><span class=\"o\">.</span><span class=\"n\">rosenbrockSample</span><span class=\"p\">(</span><span class=\"n\">m0</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Evaluate forward model log likelihood + lnprior for each theta</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">))</span>\n<span class=\"k\">for</span> <span class=\"n\">ii</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">)):</span>\n    <span class=\"n\">y</span><span class=\"p\">[</span><span class=\"n\">ii</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">lh</span><span class=\"o\">.</span><span class=\"n\">rosenbrockLnlike</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"n\">ii</span><span class=\"p\">])</span> <span class=\"o\">+</span> <span class=\"n\">lh</span><span class=\"o\">.</span><span class=\"n\">rosenbrockLnprior</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"n\">ii</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Default GP with an ExpSquaredKernel</span>\n<span class=\"n\">gp</span> <span class=\"o\">=</span> <span class=\"n\">gpUtils</span><span class=\"o\">.</span><span class=\"n\">defaultGP</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">white_noise</span><span class=\"o\">=-</span><span class=\"mi\">12</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Initialize object using the Wang &amp; Li (2018) Rosenbrock function example</span>\n<span class=\"n\">ap</span> <span class=\"o\">=</span> <span class=\"n\">approx</span><span class=\"o\">.</span><span class=\"n\">ApproxPosterior</span><span class=\"p\">(</span><span class=\"n\">theta</span><span class=\"o\">=</span><span class=\"n\">theta</span><span class=\"p\">,</span>\n                            <span class=\"n\">y</span><span class=\"o\">=</span><span class=\"n\">y</span><span class=\"p\">,</span>\n                            <span class=\"n\">gp</span><span class=\"o\">=</span><span class=\"n\">gp</span><span class=\"p\">,</span>\n                            <span class=\"n\">lnprior</span><span class=\"o\">=</span><span class=\"n\">lh</span><span class=\"o\">.</span><span class=\"n\">rosenbrockLnprior</span><span class=\"p\">,</span>\n                            <span class=\"n\">lnlike</span><span class=\"o\">=</span><span class=\"n\">lh</span><span class=\"o\">.</span><span class=\"n\">rosenbrockLnlike</span><span class=\"p\">,</span>\n                            <span class=\"n\">priorSample</span><span class=\"o\">=</span><span class=\"n\">lh</span><span class=\"o\">.</span><span class=\"n\">rosenbrockSample</span><span class=\"p\">,</span>\n                            <span class=\"n\">bounds</span><span class=\"o\">=</span><span class=\"n\">bounds</span><span class=\"p\">,</span>\n                            <span class=\"n\">algorithm</span><span class=\"o\">=</span><span class=\"n\">algorithm</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Run!</span>\n<span class=\"n\">ap</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">=</span><span class=\"n\">m</span><span class=\"p\">,</span> <span class=\"n\">nmax</span><span class=\"o\">=</span><span class=\"n\">nmax</span><span class=\"p\">,</span> <span class=\"n\">estBurnin</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">nGPRestarts</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">mcmcKwargs</span><span class=\"o\">=</span><span class=\"n\">mcmcKwargs</span><span class=\"p\">,</span>\n       <span class=\"n\">cache</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">samplerKwargs</span><span class=\"o\">=</span><span class=\"n\">samplerKwargs</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">thinChains</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>\n       <span class=\"n\">onlyLastMCMC</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Check out the final posterior distribution!</span>\n<span class=\"kn\">import</span> <span class=\"nn\">corner</span>\n\n<span class=\"c1\"># Load in chain from last iteration</span>\n<span class=\"n\">samples</span> <span class=\"o\">=</span> <span class=\"n\">ap</span><span class=\"o\">.</span><span class=\"n\">sampler</span><span class=\"o\">.</span><span class=\"n\">get_chain</span><span class=\"p\">(</span><span class=\"n\">discard</span><span class=\"o\">=</span><span class=\"n\">ap</span><span class=\"o\">.</span><span class=\"n\">iburns</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">flat</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">thin</span><span class=\"o\">=</span><span class=\"n\">ap</span><span class=\"o\">.</span><span class=\"n\">ithins</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># Corner plot!</span>\n<span class=\"n\">fig</span> <span class=\"o\">=</span> <span class=\"n\">corner</span><span class=\"o\">.</span><span class=\"n\">corner</span><span class=\"p\">(</span><span class=\"n\">samples</span><span class=\"p\">,</span> <span class=\"n\">quantiles</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mf\">0.16</span><span class=\"p\">,</span> <span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">0.84</span><span class=\"p\">],</span> <span class=\"n\">show_titles</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n                    <span class=\"n\">scale_hist</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">plot_contours</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Plot where forward model was evaluated - uncomment to plot!</span>\n<span class=\"n\">fig</span><span class=\"o\">.</span><span class=\"n\">axes</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">scatter</span><span class=\"p\">(</span><span class=\"n\">ap</span><span class=\"o\">.</span><span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"n\">m0</span><span class=\"p\">:,</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">ap</span><span class=\"o\">.</span><span class=\"n\">theta</span><span class=\"p\">[</span><span class=\"n\">m0</span><span class=\"p\">:,</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"n\">s</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">color</span><span class=\"o\">=</span><span class=\"s2\">\"red\"</span><span class=\"p\">,</span> <span class=\"n\">zorder</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Save figure</span>\n<span class=\"n\">fig</span><span class=\"o\">.</span><span class=\"n\">savefig</span><span class=\"p\">(</span><span class=\"s2\">\"finalPosterior.png\"</span><span class=\"p\">,</span> <span class=\"n\">bbox_inches</span><span class=\"o\">=</span><span class=\"s2\">\"tight\"</span><span class=\"p\">)</span>\n</pre>\n<p>The final distribution will look something like this:</p>\n<p><img alt=\"finalPosterior\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/31c1f738cc968e208303917e83dafdbac9ef7249/646f632f5f666967757265732f66696e616c506f73746572696f722e706e67\"></p>\n<p>The red points were selected by <code>approxposterior</code> by maximizing the BAPE utility function.\nAt each red point, <code>approxposterior</code> ran the forward model to evaluate the true likelihood\nand added this input-likelihood pair to the GP's training set. We retrain the GP each time\nto improve its predictive ability. Note how the points are selected in regions of\nhigh posterior density, precisely where we would want to maximize the GP's predictive ability! By using the\nBAPE point selection scheme, <code>approxposterior</code> does not waste computational resources by\nevaluating the forward model in low likelihood regions.</p>\n<p>Check out the <a href=\"https://github.com/dflemin3/approxposterior/tree/master/examples/Notebooks\" rel=\"nofollow\">examples</a> directory for Jupyter Notebook examples and explanations. Check out the full <a href=\"https://dflemin3.github.io/approxposterior/\" rel=\"nofollow\">documentation</a> for a more in-depth explanation of classes, methods, variables, and how to use the code.</p>\n<h1>Contribution</h1>\n<p>If you would like to contribute to this code, please feel free to fork the repository, make some edits, and open a pull request.\nIf you find a bug, have a suggestion, etc, please open up an issue!</p>\n<h1>Citation</h1>\n<p>If you use this code, please cite the following:</p>\n<p>Fleming and VanderPlas (2018):</p>\n<pre>@ARTICLE<span class=\"o\">{</span>Fleming2018,\n   <span class=\"nv\">author</span> <span class=\"o\">=</span> <span class=\"o\">{{</span>Fleming<span class=\"o\">}</span>, D.~P. and <span class=\"o\">{</span>VanderPlas<span class=\"o\">}</span>, J.<span class=\"o\">}</span>,\n    <span class=\"nv\">title</span> <span class=\"o\">=</span> <span class=\"s2\">\"{approxposterior: Approximate Posterior Distributions in Python}\"</span>,\n  <span class=\"nv\">journal</span> <span class=\"o\">=</span> <span class=\"o\">{</span>The Journal of Open Source Software<span class=\"o\">}</span>,\n     <span class=\"nv\">year</span> <span class=\"o\">=</span> <span class=\"m\">2018</span>,\n    <span class=\"nv\">month</span> <span class=\"o\">=</span> sep,\n   <span class=\"nv\">volume</span> <span class=\"o\">=</span> <span class=\"m\">3</span>,\n    <span class=\"nv\">pages</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">781</span><span class=\"o\">}</span>,\n      <span class=\"nv\">doi</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">10</span>.21105/joss.00781<span class=\"o\">}</span>,\n   <span class=\"nv\">adsurl</span> <span class=\"o\">=</span> <span class=\"o\">{</span>http://adsabs.harvard.edu/abs/2018JOSS....3..781P<span class=\"o\">}</span>,\n  <span class=\"nv\">adsnote</span> <span class=\"o\">=</span> <span class=\"o\">{</span>Provided by the SAO/NASA Astrophysics Data System<span class=\"o\">}</span>\n<span class=\"o\">}</span>\n</pre>\n<p>Kandasamy et al. (2017):</p>\n<pre>@article<span class=\"o\">{</span>Kandasamy2017,\n<span class=\"nv\">title</span> <span class=\"o\">=</span> <span class=\"s2\">\"Query efficient posterior estimation in scientific experiments via Bayesian active learning\"</span>,\n<span class=\"nv\">journal</span> <span class=\"o\">=</span> <span class=\"s2\">\"Artificial Intelligence\"</span>,\n<span class=\"nv\">volume</span> <span class=\"o\">=</span> <span class=\"s2\">\"243\"</span>,\n<span class=\"nv\">pages</span> <span class=\"o\">=</span> <span class=\"s2\">\"45 - 56\"</span>,\n<span class=\"nv\">year</span> <span class=\"o\">=</span> <span class=\"s2\">\"2017\"</span>,\n<span class=\"nv\">issn</span> <span class=\"o\">=</span> <span class=\"s2\">\"0004-3702\"</span>,\n<span class=\"nv\">doi</span> <span class=\"o\">=</span> <span class=\"s2\">\"https://doi.org/10.1016/j.artint.2016.11.002\"</span>,\n<span class=\"nv\">url</span> <span class=\"o\">=</span> <span class=\"s2\">\"http://www.sciencedirect.com/science/article/pii/S0004370216301394\"</span>,\n<span class=\"nv\">author</span> <span class=\"o\">=</span> <span class=\"s2\">\"Kirthevasan Kandasamy and Jeff Schneider and Barnab\u00e1s P\u00f3czos\"</span>,\n<span class=\"nv\">keywords</span> <span class=\"o\">=</span> <span class=\"s2\">\"Posterior estimation, Active learning, Gaussian processes\"</span><span class=\"o\">}</span>\n</pre>\n<p>Wang &amp; Li (2018):</p>\n<pre>@article<span class=\"o\">{</span>Wang2018,\n<span class=\"nv\">author</span> <span class=\"o\">=</span> <span class=\"o\">{</span>Wang, Hongqiao and Li, Jinglai<span class=\"o\">}</span>,\n<span class=\"nv\">title</span> <span class=\"o\">=</span> <span class=\"o\">{</span>Adaptive Gaussian Process Approximation <span class=\"k\">for</span> Bayesian Inference with Expensive Likelihood Functions<span class=\"o\">}</span>,\n<span class=\"nv\">journal</span> <span class=\"o\">=</span> <span class=\"o\">{</span>Neural Computation<span class=\"o\">}</span>,\n<span class=\"nv\">volume</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">30</span><span class=\"o\">}</span>,\n<span class=\"nv\">number</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">11</span><span class=\"o\">}</span>,\n<span class=\"nv\">pages</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">3072</span>-3094<span class=\"o\">}</span>,\n<span class=\"nv\">year</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">2018</span><span class=\"o\">}</span>,\n<span class=\"nv\">doi</span> <span class=\"o\">=</span> <span class=\"o\">{</span><span class=\"m\">10</span>.1162/neco<span class=\"se\">\\_</span>a<span class=\"se\">\\_</span><span class=\"m\">01127</span><span class=\"o\">}</span>,\n<span class=\"nv\">URL</span> <span class=\"o\">=</span> <span class=\"o\">{</span> https://doi.org/10.1162/neco_a_01127<span class=\"o\">}</span>,\n<span class=\"nv\">eprint</span> <span class=\"o\">=</span> <span class=\"o\">{</span>https://doi.org/10.1162/neco_a_01127<span class=\"o\">}}</span>\n</pre>\n\n          </div>"}, "last_serial": 6417447, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "4b8e8a4bba37ec8442221cc4d9a07346", "sha256": "a064eee231d0d309e347882847e2d57d0fed8b9af0efb09de28f46b009d17f73"}, "downloads": -1, "filename": "approxposterior-0.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "4b8e8a4bba37ec8442221cc4d9a07346", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 55526, "upload_time": "2018-03-06T21:46:18", "upload_time_iso_8601": "2018-03-06T21:46:18.818632Z", "url": "https://files.pythonhosted.org/packages/4c/47/b982d10b68e5f64300f7e6b648f6a16beaa19e81f650056d76d7e0ff76f8/approxposterior-0.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "afb07c9a5ed907476e71115573f95c7c", "sha256": "83d9559b325ec45765e00b57992c9f6b8378387b45b9455ea22429b6bbce2d1c"}, "downloads": -1, "filename": "approxposterior-0.1.tar.gz", "has_sig": false, "md5_digest": "afb07c9a5ed907476e71115573f95c7c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20670, "upload_time": "2018-03-06T21:46:20", "upload_time_iso_8601": "2018-03-06T21:46:20.952765Z", "url": "https://files.pythonhosted.org/packages/00/5d/87d6f31c5d4f20b558d0da68f77480897f5bbc1e0cbc60a322224d0f09b6/approxposterior-0.1.tar.gz", "yanked": false}], "0.1.post1": [{"comment_text": "", "digests": {"md5": "eb9715896943f8a405e42b14f540410c", "sha256": "7d39ead04ef7c7dcf32aa414b0888f0e722cd18d8b10c3d8d2fc8391d96f8b8c"}, "downloads": -1, "filename": "approxposterior-0.1.post1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "eb9715896943f8a405e42b14f540410c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 58955, "upload_time": "2018-07-12T01:06:57", "upload_time_iso_8601": "2018-07-12T01:06:57.798067Z", "url": "https://files.pythonhosted.org/packages/97/4c/822a623382fbc1b6c611307d713a44f9980ad5f0987a4613113034938c22/approxposterior-0.1.post1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2c5960721eff02a8f8ddfc96c60bda95", "sha256": "11aea99f57c264ed78e12a05e8ecff8a3260768a334703cf673d34c07f9f7e07"}, "downloads": -1, "filename": "approxposterior-0.1.post1.tar.gz", "has_sig": false, "md5_digest": "2c5960721eff02a8f8ddfc96c60bda95", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 23154, "upload_time": "2018-07-12T01:06:59", "upload_time_iso_8601": "2018-07-12T01:06:59.122918Z", "url": "https://files.pythonhosted.org/packages/e2/1a/04c37e063167efdf8d8c8ce4cd7a252f86a72a6efbb3966a546170e43149/approxposterior-0.1.post1.tar.gz", "yanked": false}], "0.2.post1": [{"comment_text": "", "digests": {"md5": "e567cd6c73acf15affd44a3d08e544bf", "sha256": "d410a25cf42a3f5fb5b81a081341e8e6dac845dc86810cc490659d321e03becd"}, "downloads": -1, "filename": "approxposterior-0.2.post1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e567cd6c73acf15affd44a3d08e544bf", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 41431, "upload_time": "2019-02-13T19:36:42", "upload_time_iso_8601": "2019-02-13T19:36:42.604966Z", "url": "https://files.pythonhosted.org/packages/d2/65/2f527767f5e0a9fbf2f09562d8c799e2170f104748f362139ceaca1847f1/approxposterior-0.2.post1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7318c752c50137ab6c2f3d964c55966a", "sha256": "2e454bc5836049da21c84dc3ed9ba04f846e4039bf3b495746bc45796ebed38a"}, "downloads": -1, "filename": "approxposterior-0.2.post1.tar.gz", "has_sig": false, "md5_digest": "7318c752c50137ab6c2f3d964c55966a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30647, "upload_time": "2019-02-13T19:36:44", "upload_time_iso_8601": "2019-02-13T19:36:44.005313Z", "url": "https://files.pythonhosted.org/packages/79/72/b149c9fffccaed8fafcc940bdb3396a14a329faaaabed451539a73567733/approxposterior-0.2.post1.tar.gz", "yanked": false}], "0.2rc0": [{"comment_text": "", "digests": {"md5": "d7059891cf96ccb75a17b4d8f7bc3c47", "sha256": "e47264b7ad38362bbea95f476c4a0072bea29b0cb23b8dbe9f5f2129f80ef329"}, "downloads": -1, "filename": "approxposterior-0.2rc0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d7059891cf96ccb75a17b4d8f7bc3c47", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 83972, "upload_time": "2019-02-12T23:48:54", "upload_time_iso_8601": "2019-02-12T23:48:54.263587Z", "url": "https://files.pythonhosted.org/packages/23/df/d96bb13e9ff4c8c901d2788bc06e5d172d7f039f5854a8d20648a2e46f4b/approxposterior-0.2rc0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2af04a14b1fbbdb38b4c08c44751138d", "sha256": "95b88bccf0e8ed6ed02079d2dfe30956ced6b0b88057f1f35adf0a6474477ab6"}, "downloads": -1, "filename": "approxposterior-0.2rc0.tar.gz", "has_sig": false, "md5_digest": "2af04a14b1fbbdb38b4c08c44751138d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 30661, "upload_time": "2019-02-12T23:48:56", "upload_time_iso_8601": "2019-02-12T23:48:56.991620Z", "url": "https://files.pythonhosted.org/packages/1f/91/a097f2259adb061eb712b99caae6a235806dbeeeccf5f6e9502c0072a6ec/approxposterior-0.2rc0.tar.gz", "yanked": false}], "0.3": [{"comment_text": "", "digests": {"md5": "99962048665bd0d3aa75a0f578c80d5e", "sha256": "806a8fc5a4067630ef3ba0605debb81731625e799ae05931cac382f6f580818e"}, "downloads": -1, "filename": "approxposterior-0.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "99962048665bd0d3aa75a0f578c80d5e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 40276, "upload_time": "2019-11-27T21:57:07", "upload_time_iso_8601": "2019-11-27T21:57:07.374991Z", "url": "https://files.pythonhosted.org/packages/31/1d/c004d2627d790a048201ec0e6543581fa2984f733035eb6dcbd1b3277a6c/approxposterior-0.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a42b34fdb4453ff80e816ae722917b6", "sha256": "3e45f05cd73832cd91a0e1840fc264f4dbbe7b2ab76a16138ac08af1051460e3"}, "downloads": -1, "filename": "approxposterior-0.3.tar.gz", "has_sig": false, "md5_digest": "0a42b34fdb4453ff80e816ae722917b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26966, "upload_time": "2019-11-27T21:57:08", "upload_time_iso_8601": "2019-11-27T21:57:08.732109Z", "url": "https://files.pythonhosted.org/packages/b2/da/00767555bba9c05833a2242c01f18373adf9df78fd2495b0d257b5cdd48c/approxposterior-0.3.tar.gz", "yanked": false}], "0.4": [{"comment_text": "", "digests": {"md5": "bc3fb683baffe9934be27c633b19087a", "sha256": "b5961ea5c10ddf885ddd3e53ed94c566f04c1e015c9afe037c5b5fb5684167bf"}, "downloads": -1, "filename": "approxposterior-0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bc3fb683baffe9934be27c633b19087a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 48622, "upload_time": "2020-01-08T20:35:58", "upload_time_iso_8601": "2020-01-08T20:35:58.364740Z", "url": "https://files.pythonhosted.org/packages/5c/4e/f22aa54db8c37d6b00512d871f81c762850bb3303e592c8137f2ca71aba5/approxposterior-0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d40472872e2c1b12f7aa1ced1f13de9", "sha256": "5a6a64a7291d17450771f2471f92253511e77c86e82b6dcd04d5ffb4a64c1ebc"}, "downloads": -1, "filename": "approxposterior-0.4.tar.gz", "has_sig": false, "md5_digest": "0d40472872e2c1b12f7aa1ced1f13de9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35686, "upload_time": "2020-01-08T20:36:00", "upload_time_iso_8601": "2020-01-08T20:36:00.518971Z", "url": "https://files.pythonhosted.org/packages/db/0b/4dddfb0660b88840d33027de03ebb3294cc8489f2b3c941ced7f00eb94d7/approxposterior-0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "bc3fb683baffe9934be27c633b19087a", "sha256": "b5961ea5c10ddf885ddd3e53ed94c566f04c1e015c9afe037c5b5fb5684167bf"}, "downloads": -1, "filename": "approxposterior-0.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "bc3fb683baffe9934be27c633b19087a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 48622, "upload_time": "2020-01-08T20:35:58", "upload_time_iso_8601": "2020-01-08T20:35:58.364740Z", "url": "https://files.pythonhosted.org/packages/5c/4e/f22aa54db8c37d6b00512d871f81c762850bb3303e592c8137f2ca71aba5/approxposterior-0.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d40472872e2c1b12f7aa1ced1f13de9", "sha256": "5a6a64a7291d17450771f2471f92253511e77c86e82b6dcd04d5ffb4a64c1ebc"}, "downloads": -1, "filename": "approxposterior-0.4.tar.gz", "has_sig": false, "md5_digest": "0d40472872e2c1b12f7aa1ced1f13de9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 35686, "upload_time": "2020-01-08T20:36:00", "upload_time_iso_8601": "2020-01-08T20:36:00.518971Z", "url": "https://files.pythonhosted.org/packages/db/0b/4dddfb0660b88840d33027de03ebb3294cc8489f2b3c941ced7f00eb94d7/approxposterior-0.4.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:17:35 2020"}