{"info": {"author": "Microsoft Corporation", "author_email": "winmlcvt@microsoft.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3 :: Only"], "description": "# Introduction\nThe keras2onnx model converter enables users to convert Keras models into the [ONNX](https://onnx.ai) model format.\nInitially, the Keras converter was developed in the project [onnxmltools](https://github.com/onnx/onnxmltools). keras2onnx converter development was moved into an [independent repository](https://github.com/onnx/keras-onnx) to support more kinds of Keras models and reduce the complexity of mixing multiple converters.\n\nAll Keras layers have been supported for conversion using keras2onnx since **ONNX opset 7**. Please refer to the [Keras documentation](https://keras.io/layers/about-keras-layers/) for details on Keras layers. The keras2onnx converter also supports the lambda/custom layer by working with the [tf2onnx](https://github.com/onnx/tensorflow-onnx) converter which is embedded directly into the source tree to avoid version conflicts and installation complexity.\n\nWindows Machine Learning (WinML) users can use [WinMLTools](https://docs.microsoft.com/en-us/windows/ai/windows-ml/convert-model-winmltools) to convert their Keras models to the ONNX format. If you want to use the keras2onnx converter, please refer to the [WinML Release Notes](https://docs.microsoft.com/en-us/windows/ai/windows-ml/release-notes) to identify the corresponding ONNX opset for your WinML version.\n\nkeras2onnx has been tested on **Python 3.5, 3.6, and 3.7**, with **tensorflow 1.x** (CI build). It does not support **Python 2.x**.\n\n# Notes\n\n# tf.keras v.s. keras.io\nBoth Keras model types are now supported in the keras2onnx converter. If the user's Keras package was installed from [Keras.io](https://keras.io/), the converter converts the model as it was created by the keras.io package. Otherwise, it will convert it through [tf.keras](https://www.tensorflow.org/guide/keras).<br>\n\nIf you want to override this behaviour, please specify the environment variable TF_KERAS=1 before invoking the converter python API.\n\n# Usage\nBefore running the converter, please notice that tensorflow has to be installed in your python environment,\nyou can choose **tensorflow** package(CPU version) or **tensorflow-gpu**(GPU version)\n\n# Validated pre-trained Keras models\nWe converted successfully for all the keras application models, and several other pretrained models. See below:\n\n|  Model Name        | Category | Notes |\n|----------|-------|------|\n| Xception | Computer Vision |\n| VGG16, VGG19 | Computer Vision |\n| ResNet50 | Computer Vision |\n| InceptionV3, InceptionResNetV2 | Computer Vision |\n| MobileNet, MobileNetV2 | Computer Vision |\n| DenseNet121, DenseNet169, DenseNet201 | Computer Vision |\n| NASNetMobile, NASNetLarge | Computer Vision |\n| [FCN, FCN-Resnet](https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/fcn.py) | Computer Vision |\n| [PSPNet](https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/pspnet.py) | Computer Vision |\n| [Segnet, VGG-Segnet](https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/segnet.py) | Computer Vision |\n| [UNet](https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/unet.py) | Computer Vision |\n| [LPCNet](https://github.com/mozilla/LPCNet) | Speech |\n| [Temporal Convolutional Network](https://github.com/philipperemy/keras-tcn) | Time sequence |\n| [ACGAN (Auxiliary Classifier GAN)](https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py) | GAN |\n| [Adversarial Autoencoder](https://github.com/eriklindernoren/Keras-GAN/blob/master/aae/aae.py) | GAN |\n| [BGAN (Boundary-Seeking GAN)](https://github.com/eriklindernoren/Keras-GAN/blob/master/bgan/bgan.py) | GAN |\n| [BIGAN (Bidirectional GAN)](https://github.com/eriklindernoren/Keras-GAN/blob/master/bigan/bigan.py) | GAN |\n| [CGAN (Conditional GAN)](https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py) | GAN |\n| [Coupled GAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/cogan/cogan.py) | GAN |\n| [Deep Convolutional GAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/discogan/discogan.py) | GAN |\n| [DualGAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/dualgan/dualgan.py) | GAN |\n| [Generative Adversarial Network](https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py) | GAN |\n| [InfoGAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/infogan/infogan.py) | GAN |\n| [LSGAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/lsgan/lsgan.py) | GAN |\n| [Pix2Pix](https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py) | GAN |\n| [Semi-Supervised GAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/sgan/sgan.py) | GAN |\n| [Super-Resolution GAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/srgan/srgan.py) | GAN |\n| [Wasserstein GAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py) | GAN |\n| [Wasserstein GAN GP](https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan_gp/wgan_gp.py) | GAN |\n| [keras-team examples](https://github.com/keras-team/keras/blob/master/examples/) | Text and Sequence | addition_rnn, babi_rnn, imdb_bidirectional_lstm, imdb_cnn_lstm, imdb_lstm, lstm_text_generation, reuters_mlp |\n\nThe following models need customed conversion, see the instruction column.\n\n|  Model Name        | Category | Instruction |\n|----------|-------|-------|\n| [YOLOv3](https://github.com/qqwweee/keras-yolo3) | Computer Vision | [Readme](https://github.com/onnx/keras-onnx/tree/master/applications/yolov3)|\n| [Mask RCNN](https://github.com/matterport/Mask_RCNN) | Computer Vision | [Readme](https://github.com/onnx/keras-onnx/tree/master/applications/mask_rcnn)|\n| [Context-Conditional GAN](https://github.com/eriklindernoren/Keras-GAN/tree/master/ccgan/ccgan.py) | GAN | [Unit test](https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_ccgan.py)|\n| [Cycle GAN](https://github.com/eriklindernoren/Keras-GAN/tree/master/cyclegan/cyclegan.py) | GAN | [Unit test](https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_cyclegan.py)|\n| [Disco GAN](https://github.com/eriklindernoren/Keras-GAN/tree/master/discogan/discogan.py) | GAN | [Unit test](https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_discogan.py)|\n| [PixelDA (Domain Adaptation)](https://github.com/eriklindernoren/Keras-GAN/tree/master/pixelda/pixelda.py) | GAN | [Unit test](https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_pixelda.py)|\n\n\n## Scripts\nIt will be useful to convert the models from Keras to ONNX from a python script.\nYou can use the following API:\n```\nimport keras2onnx\nkeras2onnx.convert_keras(model, name=None, doc_string='', target_opset=None, channel_first_inputs=None):\n    # type: (keras.Model, str, str, int, []) -> onnx.ModelProto\n    \"\"\"\n    :param model: keras model\n    :param name: the converted onnx model internal name\n    :param doc_string:\n    :param target_opset:\n    :param channel_first_inputs: A list of channel first input.\n    :return:\n    \"\"\"\n```\n\nUse the following script to convert keras application models to onnx, and then perform inference:\n```\nimport numpy as np\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input\nimport keras2onnx\nimport onnxruntime\n\n# image preprocessing\nimg_path = 'street.jpg'   # make sure the image is in img_path\nimg_size = 224\nimg = image.load_img(img_path, target_size=(img_size, img_size))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# load keras model\nfrom keras.applications.resnet50 import ResNet50\nmodel = ResNet50(include_top=True, weights='imagenet')\n\n# convert to onnx model\nonnx_model = keras2onnx.convert_keras(model, model.name)\n\n# runtime prediction\ncontent = onnx_model.SerializeToString()\nsess = onnxruntime.InferenceSession(content)\nx = x if isinstance(x, list) else [x]\nfeed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])\npred_onnx = sess.run(None, feed)\n```\n\nAn alternative way to load onnx model to runtime session is to save the model first:\n```\nimport onnx\ntemp_model_file = 'model.onnx'\nonnx.save_model(onnx_model, temp_model_file)\nsess = onnxruntime.InferenceSession(temp_model_file)\n```\n\n## Contribute\nWe welcome contributions in the form of feedback, ideas, or code.\n\n## License\n[MIT License](LICENSE)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/onnx/keras-onnx", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "keras2onnx", "package_url": "https://pypi.org/project/keras2onnx/", "platform": "", "project_url": "https://pypi.org/project/keras2onnx/", "project_urls": {"Homepage": "https://github.com/onnx/keras-onnx"}, "release_url": "https://pypi.org/project/keras2onnx/1.6.1/", "requires_dist": ["numpy", "protobuf", "requests", "onnx", "onnxconverter-common (<1.7.0,>=1.6.0)", "fire"], "requires_python": "", "summary": "Converts Machine Learning models to ONNX for use in Windows ML", "version": "1.6.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Introduction</h1>\n<p>The keras2onnx model converter enables users to convert Keras models into the <a href=\"https://onnx.ai\" rel=\"nofollow\">ONNX</a> model format.\nInitially, the Keras converter was developed in the project <a href=\"https://github.com/onnx/onnxmltools\" rel=\"nofollow\">onnxmltools</a>. keras2onnx converter development was moved into an <a href=\"https://github.com/onnx/keras-onnx\" rel=\"nofollow\">independent repository</a> to support more kinds of Keras models and reduce the complexity of mixing multiple converters.</p>\n<p>All Keras layers have been supported for conversion using keras2onnx since <strong>ONNX opset 7</strong>. Please refer to the <a href=\"https://keras.io/layers/about-keras-layers/\" rel=\"nofollow\">Keras documentation</a> for details on Keras layers. The keras2onnx converter also supports the lambda/custom layer by working with the <a href=\"https://github.com/onnx/tensorflow-onnx\" rel=\"nofollow\">tf2onnx</a> converter which is embedded directly into the source tree to avoid version conflicts and installation complexity.</p>\n<p>Windows Machine Learning (WinML) users can use <a href=\"https://docs.microsoft.com/en-us/windows/ai/windows-ml/convert-model-winmltools\" rel=\"nofollow\">WinMLTools</a> to convert their Keras models to the ONNX format. If you want to use the keras2onnx converter, please refer to the <a href=\"https://docs.microsoft.com/en-us/windows/ai/windows-ml/release-notes\" rel=\"nofollow\">WinML Release Notes</a> to identify the corresponding ONNX opset for your WinML version.</p>\n<p>keras2onnx has been tested on <strong>Python 3.5, 3.6, and 3.7</strong>, with <strong>tensorflow 1.x</strong> (CI build). It does not support <strong>Python 2.x</strong>.</p>\n<h1>Notes</h1>\n<h1>tf.keras v.s. keras.io</h1>\n<p>Both Keras model types are now supported in the keras2onnx converter. If the user's Keras package was installed from <a href=\"https://keras.io/\" rel=\"nofollow\">Keras.io</a>, the converter converts the model as it was created by the keras.io package. Otherwise, it will convert it through <a href=\"https://www.tensorflow.org/guide/keras\" rel=\"nofollow\">tf.keras</a>.<br></p>\n<p>If you want to override this behaviour, please specify the environment variable TF_KERAS=1 before invoking the converter python API.</p>\n<h1>Usage</h1>\n<p>Before running the converter, please notice that tensorflow has to be installed in your python environment,\nyou can choose <strong>tensorflow</strong> package(CPU version) or <strong>tensorflow-gpu</strong>(GPU version)</p>\n<h1>Validated pre-trained Keras models</h1>\n<p>We converted successfully for all the keras application models, and several other pretrained models. See below:</p>\n<table>\n<thead>\n<tr>\n<th>Model Name</th>\n<th>Category</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Xception</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td>VGG16, VGG19</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td>ResNet50</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td>InceptionV3, InceptionResNetV2</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td>MobileNet, MobileNetV2</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td>DenseNet121, DenseNet169, DenseNet201</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td>NASNetMobile, NASNetLarge</td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/fcn.py\" rel=\"nofollow\">FCN, FCN-Resnet</a></td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/pspnet.py\" rel=\"nofollow\">PSPNet</a></td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/segnet.py\" rel=\"nofollow\">Segnet, VGG-Segnet</a></td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/unet.py\" rel=\"nofollow\">UNet</a></td>\n<td>Computer Vision</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/mozilla/LPCNet\" rel=\"nofollow\">LPCNet</a></td>\n<td>Speech</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/philipperemy/keras-tcn\" rel=\"nofollow\">Temporal Convolutional Network</a></td>\n<td>Time sequence</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py\" rel=\"nofollow\">ACGAN (Auxiliary Classifier GAN)</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/aae/aae.py\" rel=\"nofollow\">Adversarial Autoencoder</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/bgan/bgan.py\" rel=\"nofollow\">BGAN (Boundary-Seeking GAN)</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/bigan/bigan.py\" rel=\"nofollow\">BIGAN (Bidirectional GAN)</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py\" rel=\"nofollow\">CGAN (Conditional GAN)</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/cogan/cogan.py\" rel=\"nofollow\">Coupled GAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/discogan/discogan.py\" rel=\"nofollow\">Deep Convolutional GAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/dualgan/dualgan.py\" rel=\"nofollow\">DualGAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\" rel=\"nofollow\">Generative Adversarial Network</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/infogan/infogan.py\" rel=\"nofollow\">InfoGAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/lsgan/lsgan.py\" rel=\"nofollow\">LSGAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\" rel=\"nofollow\">Pix2Pix</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/sgan/sgan.py\" rel=\"nofollow\">Semi-Supervised GAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/srgan/srgan.py\" rel=\"nofollow\">Super-Resolution GAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py\" rel=\"nofollow\">Wasserstein GAN</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan_gp/wgan_gp.py\" rel=\"nofollow\">Wasserstein GAN GP</a></td>\n<td>GAN</td>\n<td></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/keras-team/keras/blob/master/examples/\" rel=\"nofollow\">keras-team examples</a></td>\n<td>Text and Sequence</td>\n<td>addition_rnn, babi_rnn, imdb_bidirectional_lstm, imdb_cnn_lstm, imdb_lstm, lstm_text_generation, reuters_mlp</td>\n</tr></tbody></table>\n<p>The following models need customed conversion, see the instruction column.</p>\n<table>\n<thead>\n<tr>\n<th>Model Name</th>\n<th>Category</th>\n<th>Instruction</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://github.com/qqwweee/keras-yolo3\" rel=\"nofollow\">YOLOv3</a></td>\n<td>Computer Vision</td>\n<td><a href=\"https://github.com/onnx/keras-onnx/tree/master/applications/yolov3\" rel=\"nofollow\">Readme</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/matterport/Mask_RCNN\" rel=\"nofollow\">Mask RCNN</a></td>\n<td>Computer Vision</td>\n<td><a href=\"https://github.com/onnx/keras-onnx/tree/master/applications/mask_rcnn\" rel=\"nofollow\">Readme</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/tree/master/ccgan/ccgan.py\" rel=\"nofollow\">Context-Conditional GAN</a></td>\n<td>GAN</td>\n<td><a href=\"https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_ccgan.py\" rel=\"nofollow\">Unit test</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/tree/master/cyclegan/cyclegan.py\" rel=\"nofollow\">Cycle GAN</a></td>\n<td>GAN</td>\n<td><a href=\"https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_cyclegan.py\" rel=\"nofollow\">Unit test</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/tree/master/discogan/discogan.py\" rel=\"nofollow\">Disco GAN</a></td>\n<td>GAN</td>\n<td><a href=\"https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_discogan.py\" rel=\"nofollow\">Unit test</a></td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/eriklindernoren/Keras-GAN/tree/master/pixelda/pixelda.py\" rel=\"nofollow\">PixelDA (Domain Adaptation)</a></td>\n<td>GAN</td>\n<td><a href=\"https://github.com/onnx/keras-onnx/blob/master/applications/nightly_build/test_pixelda.py\" rel=\"nofollow\">Unit test</a></td>\n</tr></tbody></table>\n<h2>Scripts</h2>\n<p>It will be useful to convert the models from Keras to ONNX from a python script.\nYou can use the following API:</p>\n<pre><code>import keras2onnx\nkeras2onnx.convert_keras(model, name=None, doc_string='', target_opset=None, channel_first_inputs=None):\n    # type: (keras.Model, str, str, int, []) -&gt; onnx.ModelProto\n    \"\"\"\n    :param model: keras model\n    :param name: the converted onnx model internal name\n    :param doc_string:\n    :param target_opset:\n    :param channel_first_inputs: A list of channel first input.\n    :return:\n    \"\"\"\n</code></pre>\n<p>Use the following script to convert keras application models to onnx, and then perform inference:</p>\n<pre><code>import numpy as np\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input\nimport keras2onnx\nimport onnxruntime\n\n# image preprocessing\nimg_path = 'street.jpg'   # make sure the image is in img_path\nimg_size = 224\nimg = image.load_img(img_path, target_size=(img_size, img_size))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\n# load keras model\nfrom keras.applications.resnet50 import ResNet50\nmodel = ResNet50(include_top=True, weights='imagenet')\n\n# convert to onnx model\nonnx_model = keras2onnx.convert_keras(model, model.name)\n\n# runtime prediction\ncontent = onnx_model.SerializeToString()\nsess = onnxruntime.InferenceSession(content)\nx = x if isinstance(x, list) else [x]\nfeed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])\npred_onnx = sess.run(None, feed)\n</code></pre>\n<p>An alternative way to load onnx model to runtime session is to save the model first:</p>\n<pre><code>import onnx\ntemp_model_file = 'model.onnx'\nonnx.save_model(onnx_model, temp_model_file)\nsess = onnxruntime.InferenceSession(temp_model_file)\n</code></pre>\n<h2>Contribute</h2>\n<p>We welcome contributions in the form of feedback, ideas, or code.</p>\n<h2>License</h2>\n<p><a href=\"LICENSE\" rel=\"nofollow\">MIT License</a></p>\n\n          </div>"}, "last_serial": 6946769, "releases": {"1.3.0": [{"comment_text": "", "digests": {"md5": "dede36e79ac57538e6291b8ebf6ecaad", "sha256": "7b755ed49f330510506c9e0b70beedfd966089d529b42afebae301bb33ca6fec"}, "downloads": -1, "filename": "keras2onnx-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "dede36e79ac57538e6291b8ebf6ecaad", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 50495, "upload_time": "2019-02-08T01:33:15", "upload_time_iso_8601": "2019-02-08T01:33:15.276980Z", "url": "https://files.pythonhosted.org/packages/06/49/d65c82afefb063d5143874c21a457ce968a21ecfb44092873565411a5a4a/keras2onnx-1.3.0-py3-none-any.whl", "yanked": false}], "1.3.2": [{"comment_text": "", "digests": {"md5": "42af2b545a2f7bb13148418fbb361345", "sha256": "1bd587ae327742dbff4867f5bf37d233d04042b83a5719018bc31bd6a0d9f8b2"}, "downloads": -1, "filename": "keras2onnx-1.3.2-py3-none-any.whl", "has_sig": false, "md5_digest": "42af2b545a2f7bb13148418fbb361345", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 51752, "upload_time": "2019-03-18T23:19:16", "upload_time_iso_8601": "2019-03-18T23:19:16.530667Z", "url": "https://files.pythonhosted.org/packages/54/aa/80a3f2ed4af13edb63c806891c2fc5737e080d57b759bca4cac1f00b4f84/keras2onnx-1.3.2-py3-none-any.whl", "yanked": false}], "1.4.0": [{"comment_text": "", "digests": {"md5": "84af4d69148a4e4d713e9d57911a0be6", "sha256": "acc622e2d17c24b491d8183296ef603c4808772cf6de86aaee7e767788ee4f7e"}, "downloads": -1, "filename": "keras2onnx-1.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "84af4d69148a4e4d713e9d57911a0be6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 174638, "upload_time": "2019-04-24T19:34:16", "upload_time_iso_8601": "2019-04-24T19:34:16.177553Z", "url": "https://files.pythonhosted.org/packages/d8/17/c1583b741af6400abfd4e6497689acee1b01dc53955321d703a7b5348bd4/keras2onnx-1.4.0-py3-none-any.whl", "yanked": false}], "1.5.0": [{"comment_text": "", "digests": {"md5": "c53b46183a74046d9882555f901c0260", "sha256": "2c51d98fe2bb588e8df89d297263bd6905c760af12ef65b63a211b368c7a1615"}, "downloads": -1, "filename": "keras2onnx-1.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "c53b46183a74046d9882555f901c0260", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 186495, "upload_time": "2019-06-10T23:06:16", "upload_time_iso_8601": "2019-06-10T23:06:16.337074Z", "url": "https://files.pythonhosted.org/packages/1a/b0/6f3012cb0c959203dd3ce05e0fc61c9112f0d4043fdf917cf665d8c53254/keras2onnx-1.5.0-py3-none-any.whl", "yanked": false}], "1.5.1": [{"comment_text": "", "digests": {"md5": "d29b44064801ab0f8d54309a172257cd", "sha256": "57b78532987f859edc7c583a9271d05e3953fb4a60940c00e278df4420a89f33"}, "downloads": -1, "filename": "keras2onnx-1.5.1-py3-none-any.whl", "has_sig": false, "md5_digest": "d29b44064801ab0f8d54309a172257cd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 207915, "upload_time": "2019-07-26T21:24:58", "upload_time_iso_8601": "2019-07-26T21:24:58.310075Z", "url": "https://files.pythonhosted.org/packages/bf/a0/ac1e84e39a115155e57654ae4785f29ed1619f8f80cdbe0344526e4fd04c/keras2onnx-1.5.1-py3-none-any.whl", "yanked": false}], "1.5.2": [{"comment_text": "", "digests": {"md5": "83da4974eb19bc1262dc6b13d9aad04b", "sha256": "6130c48d3831b066275786a4bde066f03a6c93a531214715b304c8724f3d6c8d"}, "downloads": -1, "filename": "keras2onnx-1.5.2-py3-none-any.whl", "has_sig": false, "md5_digest": "83da4974eb19bc1262dc6b13d9aad04b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 216853, "upload_time": "2019-09-27T23:47:39", "upload_time_iso_8601": "2019-09-27T23:47:39.277247Z", "url": "https://files.pythonhosted.org/packages/3b/76/f6b4afe9c0b3b46318498324897b8696cd9f976de8c0e4058ec619850c8d/keras2onnx-1.5.2-py3-none-any.whl", "yanked": false}], "1.6.0": [{"comment_text": "", "digests": {"md5": "29ee01f2e70876378a10eb61fe4bb82c", "sha256": "8a47e0dc740617a58945dc9e46bdfe48013b5e8fa2798db4c03b3ee4d8ae395f"}, "downloads": -1, "filename": "keras2onnx-1.6.0-py3-none-any.whl", "has_sig": false, "md5_digest": "29ee01f2e70876378a10eb61fe4bb82c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 219762, "upload_time": "2019-10-31T01:21:32", "upload_time_iso_8601": "2019-10-31T01:21:32.481149Z", "url": "https://files.pythonhosted.org/packages/60/df/38475abd5ef1e0c5a19f021add159e8a07d10525b2c01f13bf06371aedd4/keras2onnx-1.6.0-py3-none-any.whl", "yanked": false}], "1.6.1": [{"comment_text": "", "digests": {"md5": "1d13994ff080ab9b6302a72796f15795", "sha256": "9063d0bba8cf72526258b7d39ba0bbb747861d365495d540b4ea86ca49581759"}, "downloads": -1, "filename": "keras2onnx-1.6.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1d13994ff080ab9b6302a72796f15795", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 220094, "upload_time": "2020-04-03T21:50:37", "upload_time_iso_8601": "2020-04-03T21:50:37.098976Z", "url": "https://files.pythonhosted.org/packages/0a/f5/ea1d0482b7fdb07889fd3d5b2d0954a5813db0a282888968cc00fde897ec/keras2onnx-1.6.1-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1d13994ff080ab9b6302a72796f15795", "sha256": "9063d0bba8cf72526258b7d39ba0bbb747861d365495d540b4ea86ca49581759"}, "downloads": -1, "filename": "keras2onnx-1.6.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1d13994ff080ab9b6302a72796f15795", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 220094, "upload_time": "2020-04-03T21:50:37", "upload_time_iso_8601": "2020-04-03T21:50:37.098976Z", "url": "https://files.pythonhosted.org/packages/0a/f5/ea1d0482b7fdb07889fd3d5b2d0954a5813db0a282888968cc00fde897ec/keras2onnx-1.6.1-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:50:15 2020"}