{"info": {"author": "Milojko Bjelanovic", "author_email": "mbjelanovic@quantxt.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# qtcurate-sdk-python\nPython SKD for Search and Data extraction\n\n## Theia documentation; Overview and Definitions\n**Theia** is a managed solution to mine and retrieve Entities* or Typed Entities** out of unstructured data. In the following we cover details of configuring and submitting data mining jobs via Python SDK\n\n***Entity** : An entity is a word or phrase and *can be* associated with a meaning. For example, \"AWS\" is an entity and it can be associated with \"Amazon Inc.\"\n\n****Typed Entity** : An entity that is meaningful only if it co-occurs with a number, date or another entity. For example, \"Revenue\" is considered a Typed Entity only if it is found in a context where the actual dollar value is reported:\n\n>Amazon Inc reported $68.8 billion in revenue\n\n## Table of content\n\n- [Installation](#installation)\n- [Authentication](#authentication)\n- [Data Dictionaries](#data-dictionaries)\n- [Create a New Dictionary](#create-a-new-dictionary)\n- [Upload a TSV Dictionary File](#upload-a-tsv-dictionary-file)\n- [Update an Existing Dictionary](#update-an-existing-dictionary)\n- [Delete a Dictionary](#delete-a-dictionary)\n- [List Available Dictionaries](#list-available-dictionaries)\n- [Fetch dictionary](#fetch-dictionary)\n- [Extraction and Mining](#extraction-and-mining)\n- [Mining Content Files](#mining-content-files)\n- [Mining Web URLs](#mining-web-urls)\n- [Mining Data Streams](#mining-data-streams)\n- [Extracting Typed Entities](#extracting-typed-entities)\n- [Status Monitoring](#status-monitoring)\n- [Searching in the Results](#searching-in-the-results)\n- [Exporting the Results](#exporting-the-results)\n- [Exporting in Excel Format](#exporting-in-excel-format)\n- [Exporting in JSON](#exporting-in-json)\n- [Clear temporary data](#clear-temporary-data)\n\n\n### Installation\n\nYou can install it with pip. You have to have Python 3.5 or above\n```\npip install qtcurate\n```\n\n### Authentication\n\nValid API key is required for all operations.\n\n#### Request\n\n\nIf API key is valid, than the response will be `HTTP 200` containing user profile data.\n\nIf API key is missing or not valid, the endpoint will return `HTTP 401`:\n\n#### Response\n\n```\n{\n\"error\": \"unauthorized\",\n\"error_description\": \"Full authentication is required to access this resource\"\n}\n```\n\n\n\"Net Revenue\" is a Typed Entity:\n\n```\n\"Apple reported net revenue of $53.3 billion in 2018.\"\n```\n\n\"Net Revenue\" is not a Typed Entity:\n\n```\n\"Tim Cook will go over net revenue of Apple in the upcoming conference call.\"\n```\n\n\n### Entity Dictionaries\n\nEntity dictionaries are lists of entities that can be used in a data mining task. Each item of a entity dictionary has a `key` and a `value`. The `key` is the associated or normalized phrase and the `value` is the actual word or phrase that represents the entity.\n\n**Theia** scans all input utterances for every word or phrase in the dictionary and if found, map it to the associated value:\n\nDictionary (one item):\n```M&A => merger and acquisition```\n\nInput utterance:\n\n>Merger and acquisitions report published in 2019.\n\nThe above will be labeled with `M&A`\n\n**Theia** uses various strategies for matching of dictionary values allowing users to configure the fuzziness of search. User can also provide a list of synonyms and stop phrases for the value matching. For example, you can only have \"Apple Inc\" as one entity in your dictionary and provide \"inc\", \"corp\", \"corporation\" and \"company\" as synonyms, allowing you to find all occurrences of \"Apple the Company\", \"Apple Corporations\" and \"Apple Corp\" in the content.\n\n\nEntity dictionaries can be created in two ways:\n- By providing dictionary entries in the request payload\n- By uploading a TSV file containing dictionary entries in the format of `key<TAB>value`.\n\n### Data Dictionaries\n\nAuthentication with API KEY\n```\ndic = QtDict(api_key='1234567')\n```\n\n#### Create A New QtDict\nCreate data dictionaries with create() function\nFirst we prepare data\nName is required.\n```\ndic.name(\"Name of QtDict)\n```\nTwo ways to create entries\n```\nkey = \"some key\"\nvalue = \"some value\"\ndic.add_entry(key, value)\n```\nor\n```\ntmp_dictionary = {\"key\": \"some key\", \"value\": \"some value\"}\ndic.entries(tmp_dictionary)\n```\nwhere method entries take a Python dictionary with 2 elements where KEYS have string value \"key\" and \"value\"\nAfter that we can create our QtDict\n```\ndic.create()\n```\n#### Response\n\n```\n{\n\"id\": \"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\",\n\"key\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"name\": \"Name of dictionary\",\n\"global\": false,\n\"entries\": [\n{\n\"key\": \"some key\",\n\"value\": \"some value\"\n}\n]\n}\n```\n\n#### Upload a TSV Dictionary File\n\nUpload TSV data dictionaries with upload function:\n```\ndic.upload(\"file-path.tsv\", \"Name of dictionary\")\n```\nTSV is required file format. Response is the same as create function response.\n\n#### Update an Existing QtDict\n\nTo update an existing QtDict:\n```\ndic.update(\"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\")\n```\nWe use ID as argument of function.\n\n#### Delete a QtDict\n\nTo delete an existing QtDict:\n```\ndic.delete(\"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\")\n\n```\n#### List Available Dictionaries:\n\nTo list all of your existing dictionaries:\n```\ndic.list()\n```\nResponse is a list of dictionaries\n```\n[\n{\n\"id\": \"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\",\n\"key\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"name\": \"My dictionary\",\n\"global\": false,\n\"entries\": []\n}\n{\n...\n}\n]\n```\n\n#### Fetch QtDict:\nTo fetch data from the QtDict\n```\ndic.fetch(\"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\")\n```\nResponse\n```\n{\n\"id\": \"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\",\n\"key\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"name\": \"My dictionary\",\n\"global\": false,\n\"entries\": []\n}\n```\n\n### Extraction and Mining\n\nData extraction and mining is the process of identifying entities found in the unstructured content using entity dictionaries and formatting them it into structured format. Unstructured data can be streamed from content files, data APIs or directly from public URLs.\n\nAuthenticate with API_KEY\n\n```\ntag = DataProcess(api_key=\"1234\")\n```\n\n#### Mining Content Files\n\nFirst, upload all content files for DataProcess:\n```\ntag.upload(\"file.pdf\")\n```\n\nPDF, TXT and HTML formats are supported.\n\n#### Response\n\n```\n{\n\"uuid\": \"c351283c-330c-418b-8fb7-44cf3c7a09d5\",\n\"fileName\": \"file.pdf\",\n\"link\": \"http://portal.document.quantxt.amazonaws.com/user@example.com/c351283c-330c-418b-8fb7-44cf3c7a09d5\",\n\"date\": \"2019-10-25T20:14:41.925+02:00\",\n\"contentType\": \"application/pdf\",\n\"source\": \"file.pdf\"\n}\n```\n\nNow you can mine data via dictionaries. First you have to prepare additional options.\n`title` is optional but it is highly recommended for easier distinction between different tagging jobs.\n\n`vocabValueType` (Optional): can have one of the following values: `NONE`, `STRING`, `DOUBLE`, `DATETIME`. If set, the engine will extract only entities that are associated with an entity of this type.\n`vocabPath` (Required): The path to entity QtDict. Path is returned either after creation of a new QtDict or via listing of existing dictionaries.**There is no limit on the number of files and dictionaries that can be processed via tagging_files function**\n```\ntag.files(\"c351283c-330c-418b-8fb7-44cf3c7a09d5\")\ntag.title(\"My data mining with files and dictionaries\")\ntag.search_rule(\"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\", DictionaryType.NONE)\n\ntag.tagging_files()\n```\n#### Response\n\n```\n{\n\"index\": \"puvqrjfhqq\",\n\"title\": \"My data mining with files and dictionaries\",\n\"get_phrases\": true,\n\"maxTokenPerUtt\": 35,\n\"minTokenPerUtt\": 6,\n\"excludeUttWithoutEntities\": false,\n\"stitle\": null,\n\"files\": [\"c351283c-330c-418b-8fb7-44cf3c7a09d5\"],\n\"searchDictionaries\": [\n{\n\"vocabPath\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"vocabValueType\": \"NONE\"\n}\n]\n}\n```\n\n`index` represents the unique identification for the container that holds output labeled data.\nYou can set index, autotag, maxTokenPerUtt, minTokenPerUtt, excludeUttWithoutEntities with following methods:\n```\ntag.index(\"some index\")\ntag.autotag(True)\ntag.exclude_utt_without_entities(True)\ntag.max_token_per_utt(101)\ntag.min_token_per_utt(101)\ntag.stitle(\"some stitle string\")\n```\n\n\n**Request parameters:**\n\n`chunk`\n(Optional, string) can be `SENTENCE` or `PARAGRAPH` or `NONE`. This will result in splitting of data into semantic chunks before processing. For example, this allows user to split the content of an article in semantic sentences and apply entity dictionaries at sentence level.\n\n`excludeUttWithoutEntities`\n(Optional, boolean) if `true` the output will only include chunks that have at least one label from the input dictionaries.\n\n`get_phrases`\n(Optional, boolean) if `true` auto tagging will be performed.\n\n`minTokenPerUtt` (Optional, int)\n\n`maxTokenPerUtt` (Optional, int)\n\n`stitle` (Optional, string) Override command.\n\nTo delete a data container:\n```\ntag.delete(\"puvqrjfhqq\")\n```\n\n#### Mining Web URLs:\n\nMining can be performed on a list of URLs. All parameters used in tagging files are applicable here.\n```\ntag.mining_url()\n```\n\n**Theia can process both static and dynamic web pages. However, a number of websites use mechanisms to block webpage scrapping. Theia built-in Web parser is not designed to bypass such blocking mechanisms**\n\n#### Mining Data Streams\n\nTagging data from data streams such as third party APIs is supported. Please contact <support@quantxt.com> for details.\n\n\n#### Extracting Typed Entities\n\nEntity dictionaries allow the user to quickly search and label thousands of phrases in unstructured content. There are cases when users want to label a keyword or phrase as an entity only if it is associated with a value. For example:\n\nA \"release => \"Manufactured\" dictionary item will label both of the following utterances:\n\n> The first automobile in the US **released** by Ford.\n> The first automobile in the US **released** in 1908 by Ford.\n\nHowever, if the user is looking for only release year of the car makers, the first utterance won't have much use for him. He can only label the second utterance using a **Typed Entities**.\n\nSupported types for associated entities are:\n\n`REGEX`, `DOUBLE`, `DATETIME`\n\ntypes are passed via `vocabValueType` parameter.\n\nIf a type is set, a dictionary item will be extracted only if a type is found in its close proximity.\nIn the above example, user can set *vocabValueType* in the request to `DOUBLE` to identify **1908** only if it is associated with the entity **released**\n\n#### Status Monitoring\n\nThe progress endpoint allows user to check the progress of a submitted data mining job:\n\n#### Request\n\n```\ntag.progress()\n```\n\nThe search result is an array of active data mining jobs:\n\n```\n[\n{\n\"index\": \"cjaejhvtao\",\n\"progress\": 36,\n\"progress_msg\": \"Collecting data...\"\n}\n]\n\n```\n\n`index` Unique ID of the running job\n\n`progress`  Progress in % (a number between 0 to 100).\n\n`progress_msg` (Optional) Progress message.\n\n\nIt is also possible to check the progress of a specific data mining job:\n\n#### Request\n\n```\ntag.progress(\"cjaejhvtao\")\n```\n\n#### Response\n\n```\n{\n\"index\": \"cjaejhvtao\",\n\"progress\": 36,\n\"progress_msg\": \"Collecting data...\"\n}\n```\n\n### Searching in the Results\n\n\nThe search endpoint allows user to run full-text and [faceted search](https://en.wikipedia.org/wiki/Faceted_search) in the extracted data.\n\n#### Request\n\n```\ntag.search(\"puvqrjfhqq\", param_from, size, f1, f2)\n```\n\n**Request parameters:**\n\n`q`\n(Optional, string) Search query that filters the main content `title` field. It supports boolean `OR`, `AND` and `NOT` parameters.\n\n`f`\n(Optional, string) Query filters must be used in pairs. Filters are created for each input dictionary. For example, to include results that have one or more label from `Vehicle` dictionary the request should look like: `&f=Vehicle&f=*`. To include results that are labeled with `Ford` or `BMW` from the `Vehicle` dictionary, the request would be `&f=Vehicle&f=BMW&f=Vehicle&f=Ford`\n\n`from`\n(Optional, int) Offset for paging results. Defaults to 0. Each page contains 20 items.\n\n`size`\n(Optional, int) Number of results to return. Maximum is 200.\n\n\n#### Response\n\n```\n{\n\"Total\": 2610,\n\"results\": [\n{\n\"title\": \"The Federal Reserve Bank of New York provides gold custody to several central banks, governments and official international organizations on behalf of the Federal Reserve System.\",\n\"id\": \"Wv8fBG4Bc3WI8L9MbaO2\",\n\"link\": \"https://www.hamilton.edu/news/story/hamilton-nyc-program-tours-federal-reserve-museum\",\n\"score\": 0.10268514747565982,\n\"source\": \"abc15.com\",\n\"date\": \"2018-05-24T00:00:00.000Z\",\n\"tags\": [\n\"Federal Reserve\",\n\"New York\"\n]\n}\n],\n\"aggs\": {\n\"Tag\": [{\n\"key\": \"Central bank\",\n\"count\": 878\n}, {\n\"key\": \"Gold\",\n\"count\": 523\n}\n}\n}\n```\n\n`Total`: Number of results.\n\n`result []`: The array that contains result items.\n\n`aggs` : Facets over the results with count of items for each facet.\n\n\n### Exporting the Results\n\nResults can be exported in XLSX or JSON format:\n\n#### Exporting in Excel Format\n\n```\ntag.report_to_xlsx(\"puvqrjfhqq\", \"name-of-output-file.xlsx\")\n```\n\n\n#### Exporting in JSON\n\n```\ntag.report_to_json(\"puvqrjfhqq\", \"name-of-output-file.json\")\n\n```\n\n### Clear temporary data\nBoth classes QtDict and DataProcess have a method clear() to delete all used variable.\n```\ndic.clear()\ntag.clear()\n```\nThe export output is limited to 5000. All `/search` parameters can be passed here to export the desired slice of the data.\n\n\nFor technical questions please contact <support@quantxt.com>\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/quantxt/qtcurate-sdk-python", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "qtcurate", "package_url": "https://pypi.org/project/qtcurate/", "platform": "", "project_url": "https://pypi.org/project/qtcurate/", "project_urls": {"Homepage": "https://github.com/quantxt/qtcurate-sdk-python"}, "release_url": "https://pypi.org/project/qtcurate/1.3.0/", "requires_dist": ["requests"], "requires_python": ">=3.5", "summary": "Theia SDK Search and Data Extraction", "version": "1.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>qtcurate-sdk-python</h1>\n<p>Python SKD for Search and Data extraction</p>\n<h2>Theia documentation; Overview and Definitions</h2>\n<p><strong>Theia</strong> is a managed solution to mine and retrieve Entities* or Typed Entities** out of unstructured data. In the following we cover details of configuring and submitting data mining jobs via Python SDK</p>\n<p>*<strong>Entity</strong> : An entity is a word or phrase and <em>can be</em> associated with a meaning. For example, \"AWS\" is an entity and it can be associated with \"Amazon Inc.\"</p>\n<p>**<strong>Typed Entity</strong> : An entity that is meaningful only if it co-occurs with a number, date or another entity. For example, \"Revenue\" is considered a Typed Entity only if it is found in a context where the actual dollar value is reported:</p>\n<blockquote>\n<p>Amazon Inc reported $68.8 billion in revenue</p>\n</blockquote>\n<h2>Table of content</h2>\n<ul>\n<li><a href=\"#installation\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#authentication\" rel=\"nofollow\">Authentication</a></li>\n<li><a href=\"#data-dictionaries\" rel=\"nofollow\">Data Dictionaries</a></li>\n<li><a href=\"#create-a-new-dictionary\" rel=\"nofollow\">Create a New Dictionary</a></li>\n<li><a href=\"#upload-a-tsv-dictionary-file\" rel=\"nofollow\">Upload a TSV Dictionary File</a></li>\n<li><a href=\"#update-an-existing-dictionary\" rel=\"nofollow\">Update an Existing Dictionary</a></li>\n<li><a href=\"#delete-a-dictionary\" rel=\"nofollow\">Delete a Dictionary</a></li>\n<li><a href=\"#list-available-dictionaries\" rel=\"nofollow\">List Available Dictionaries</a></li>\n<li><a href=\"#fetch-dictionary\" rel=\"nofollow\">Fetch dictionary</a></li>\n<li><a href=\"#extraction-and-mining\" rel=\"nofollow\">Extraction and Mining</a></li>\n<li><a href=\"#mining-content-files\" rel=\"nofollow\">Mining Content Files</a></li>\n<li><a href=\"#mining-web-urls\" rel=\"nofollow\">Mining Web URLs</a></li>\n<li><a href=\"#mining-data-streams\" rel=\"nofollow\">Mining Data Streams</a></li>\n<li><a href=\"#extracting-typed-entities\" rel=\"nofollow\">Extracting Typed Entities</a></li>\n<li><a href=\"#status-monitoring\" rel=\"nofollow\">Status Monitoring</a></li>\n<li><a href=\"#searching-in-the-results\" rel=\"nofollow\">Searching in the Results</a></li>\n<li><a href=\"#exporting-the-results\" rel=\"nofollow\">Exporting the Results</a></li>\n<li><a href=\"#exporting-in-excel-format\" rel=\"nofollow\">Exporting in Excel Format</a></li>\n<li><a href=\"#exporting-in-json\" rel=\"nofollow\">Exporting in JSON</a></li>\n<li><a href=\"#clear-temporary-data\" rel=\"nofollow\">Clear temporary data</a></li>\n</ul>\n<h3>Installation</h3>\n<p>You can install it with pip. You have to have Python 3.5 or above</p>\n<pre><code>pip install qtcurate\n</code></pre>\n<h3>Authentication</h3>\n<p>Valid API key is required for all operations.</p>\n<h4>Request</h4>\n<p>If API key is valid, than the response will be <code>HTTP 200</code> containing user profile data.</p>\n<p>If API key is missing or not valid, the endpoint will return <code>HTTP 401</code>:</p>\n<h4>Response</h4>\n<pre><code>{\n\"error\": \"unauthorized\",\n\"error_description\": \"Full authentication is required to access this resource\"\n}\n</code></pre>\n<p>\"Net Revenue\" is a Typed Entity:</p>\n<pre><code>\"Apple reported net revenue of $53.3 billion in 2018.\"\n</code></pre>\n<p>\"Net Revenue\" is not a Typed Entity:</p>\n<pre><code>\"Tim Cook will go over net revenue of Apple in the upcoming conference call.\"\n</code></pre>\n<h3>Entity Dictionaries</h3>\n<p>Entity dictionaries are lists of entities that can be used in a data mining task. Each item of a entity dictionary has a <code>key</code> and a <code>value</code>. The <code>key</code> is the associated or normalized phrase and the <code>value</code> is the actual word or phrase that represents the entity.</p>\n<p><strong>Theia</strong> scans all input utterances for every word or phrase in the dictionary and if found, map it to the associated value:</p>\n<p>Dictionary (one item):\n<code>M&amp;A =&gt; merger and acquisition</code></p>\n<p>Input utterance:</p>\n<blockquote>\n<p>Merger and acquisitions report published in 2019.</p>\n</blockquote>\n<p>The above will be labeled with <code>M&amp;A</code></p>\n<p><strong>Theia</strong> uses various strategies for matching of dictionary values allowing users to configure the fuzziness of search. User can also provide a list of synonyms and stop phrases for the value matching. For example, you can only have \"Apple Inc\" as one entity in your dictionary and provide \"inc\", \"corp\", \"corporation\" and \"company\" as synonyms, allowing you to find all occurrences of \"Apple the Company\", \"Apple Corporations\" and \"Apple Corp\" in the content.</p>\n<p>Entity dictionaries can be created in two ways:</p>\n<ul>\n<li>By providing dictionary entries in the request payload</li>\n<li>By uploading a TSV file containing dictionary entries in the format of <code>key&lt;TAB&gt;value</code>.</li>\n</ul>\n<h3>Data Dictionaries</h3>\n<p>Authentication with API KEY</p>\n<pre><code>dic = QtDict(api_key='1234567')\n</code></pre>\n<h4>Create A New QtDict</h4>\n<p>Create data dictionaries with create() function\nFirst we prepare data\nName is required.</p>\n<pre><code>dic.name(\"Name of QtDict)\n</code></pre>\n<p>Two ways to create entries</p>\n<pre><code>key = \"some key\"\nvalue = \"some value\"\ndic.add_entry(key, value)\n</code></pre>\n<p>or</p>\n<pre><code>tmp_dictionary = {\"key\": \"some key\", \"value\": \"some value\"}\ndic.entries(tmp_dictionary)\n</code></pre>\n<p>where method entries take a Python dictionary with 2 elements where KEYS have string value \"key\" and \"value\"\nAfter that we can create our QtDict</p>\n<pre><code>dic.create()\n</code></pre>\n<h4>Response</h4>\n<pre><code>{\n\"id\": \"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\",\n\"key\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"name\": \"Name of dictionary\",\n\"global\": false,\n\"entries\": [\n{\n\"key\": \"some key\",\n\"value\": \"some value\"\n}\n]\n}\n</code></pre>\n<h4>Upload a TSV Dictionary File</h4>\n<p>Upload TSV data dictionaries with upload function:</p>\n<pre><code>dic.upload(\"file-path.tsv\", \"Name of dictionary\")\n</code></pre>\n<p>TSV is required file format. Response is the same as create function response.</p>\n<h4>Update an Existing QtDict</h4>\n<p>To update an existing QtDict:</p>\n<pre><code>dic.update(\"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\")\n</code></pre>\n<p>We use ID as argument of function.</p>\n<h4>Delete a QtDict</h4>\n<p>To delete an existing QtDict:</p>\n<pre><code>dic.delete(\"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\")\n\n</code></pre>\n<h4>List Available Dictionaries:</h4>\n<p>To list all of your existing dictionaries:</p>\n<pre><code>dic.list()\n</code></pre>\n<p>Response is a list of dictionaries</p>\n<pre><code>[\n{\n\"id\": \"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\",\n\"key\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"name\": \"My dictionary\",\n\"global\": false,\n\"entries\": []\n}\n{\n...\n}\n]\n</code></pre>\n<h4>Fetch QtDict:</h4>\n<p>To fetch data from the QtDict</p>\n<pre><code>dic.fetch(\"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\")\n</code></pre>\n<p>Response</p>\n<pre><code>{\n\"id\": \"58608b1f-a0ff-45d0-b12a-2fb93af1a9ad\",\n\"key\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"name\": \"My dictionary\",\n\"global\": false,\n\"entries\": []\n}\n</code></pre>\n<h3>Extraction and Mining</h3>\n<p>Data extraction and mining is the process of identifying entities found in the unstructured content using entity dictionaries and formatting them it into structured format. Unstructured data can be streamed from content files, data APIs or directly from public URLs.</p>\n<p>Authenticate with API_KEY</p>\n<pre><code>tag = DataProcess(api_key=\"1234\")\n</code></pre>\n<h4>Mining Content Files</h4>\n<p>First, upload all content files for DataProcess:</p>\n<pre><code>tag.upload(\"file.pdf\")\n</code></pre>\n<p>PDF, TXT and HTML formats are supported.</p>\n<h4>Response</h4>\n<pre><code>{\n\"uuid\": \"c351283c-330c-418b-8fb7-44cf3c7a09d5\",\n\"fileName\": \"file.pdf\",\n\"link\": \"http://portal.document.quantxt.amazonaws.com/user@example.com/c351283c-330c-418b-8fb7-44cf3c7a09d5\",\n\"date\": \"2019-10-25T20:14:41.925+02:00\",\n\"contentType\": \"application/pdf\",\n\"source\": \"file.pdf\"\n}\n</code></pre>\n<p>Now you can mine data via dictionaries. First you have to prepare additional options.\n<code>title</code> is optional but it is highly recommended for easier distinction between different tagging jobs.</p>\n<p><code>vocabValueType</code> (Optional): can have one of the following values: <code>NONE</code>, <code>STRING</code>, <code>DOUBLE</code>, <code>DATETIME</code>. If set, the engine will extract only entities that are associated with an entity of this type.\n<code>vocabPath</code> (Required): The path to entity QtDict. Path is returned either after creation of a new QtDict or via listing of existing dictionaries.<strong>There is no limit on the number of files and dictionaries that can be processed via tagging_files function</strong></p>\n<pre><code>tag.files(\"c351283c-330c-418b-8fb7-44cf3c7a09d5\")\ntag.title(\"My data mining with files and dictionaries\")\ntag.search_rule(\"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\", DictionaryType.NONE)\n\ntag.tagging_files()\n</code></pre>\n<h4>Response</h4>\n<pre><code>{\n\"index\": \"puvqrjfhqq\",\n\"title\": \"My data mining with files and dictionaries\",\n\"get_phrases\": true,\n\"maxTokenPerUtt\": 35,\n\"minTokenPerUtt\": 6,\n\"excludeUttWithoutEntities\": false,\n\"stitle\": null,\n\"files\": [\"c351283c-330c-418b-8fb7-44cf3c7a09d5\"],\n\"searchDictionaries\": [\n{\n\"vocabPath\": \"user-example-com/58608b1f-a0ff-45d0-b12a-2fb93af1a9ad.csv.gz\",\n\"vocabValueType\": \"NONE\"\n}\n]\n}\n</code></pre>\n<p><code>index</code> represents the unique identification for the container that holds output labeled data.\nYou can set index, autotag, maxTokenPerUtt, minTokenPerUtt, excludeUttWithoutEntities with following methods:</p>\n<pre><code>tag.index(\"some index\")\ntag.autotag(True)\ntag.exclude_utt_without_entities(True)\ntag.max_token_per_utt(101)\ntag.min_token_per_utt(101)\ntag.stitle(\"some stitle string\")\n</code></pre>\n<p><strong>Request parameters:</strong></p>\n<p><code>chunk</code>\n(Optional, string) can be <code>SENTENCE</code> or <code>PARAGRAPH</code> or <code>NONE</code>. This will result in splitting of data into semantic chunks before processing. For example, this allows user to split the content of an article in semantic sentences and apply entity dictionaries at sentence level.</p>\n<p><code>excludeUttWithoutEntities</code>\n(Optional, boolean) if <code>true</code> the output will only include chunks that have at least one label from the input dictionaries.</p>\n<p><code>get_phrases</code>\n(Optional, boolean) if <code>true</code> auto tagging will be performed.</p>\n<p><code>minTokenPerUtt</code> (Optional, int)</p>\n<p><code>maxTokenPerUtt</code> (Optional, int)</p>\n<p><code>stitle</code> (Optional, string) Override command.</p>\n<p>To delete a data container:</p>\n<pre><code>tag.delete(\"puvqrjfhqq\")\n</code></pre>\n<h4>Mining Web URLs:</h4>\n<p>Mining can be performed on a list of URLs. All parameters used in tagging files are applicable here.</p>\n<pre><code>tag.mining_url()\n</code></pre>\n<p><strong>Theia can process both static and dynamic web pages. However, a number of websites use mechanisms to block webpage scrapping. Theia built-in Web parser is not designed to bypass such blocking mechanisms</strong></p>\n<h4>Mining Data Streams</h4>\n<p>Tagging data from data streams such as third party APIs is supported. Please contact <a href=\"mailto:support@quantxt.com\">support@quantxt.com</a> for details.</p>\n<h4>Extracting Typed Entities</h4>\n<p>Entity dictionaries allow the user to quickly search and label thousands of phrases in unstructured content. There are cases when users want to label a keyword or phrase as an entity only if it is associated with a value. For example:</p>\n<p>A \"release =&gt; \"Manufactured\" dictionary item will label both of the following utterances:</p>\n<blockquote>\n<p>The first automobile in the US <strong>released</strong> by Ford.\nThe first automobile in the US <strong>released</strong> in 1908 by Ford.</p>\n</blockquote>\n<p>However, if the user is looking for only release year of the car makers, the first utterance won't have much use for him. He can only label the second utterance using a <strong>Typed Entities</strong>.</p>\n<p>Supported types for associated entities are:</p>\n<p><code>REGEX</code>, <code>DOUBLE</code>, <code>DATETIME</code></p>\n<p>types are passed via <code>vocabValueType</code> parameter.</p>\n<p>If a type is set, a dictionary item will be extracted only if a type is found in its close proximity.\nIn the above example, user can set <em>vocabValueType</em> in the request to <code>DOUBLE</code> to identify <strong>1908</strong> only if it is associated with the entity <strong>released</strong></p>\n<h4>Status Monitoring</h4>\n<p>The progress endpoint allows user to check the progress of a submitted data mining job:</p>\n<h4>Request</h4>\n<pre><code>tag.progress()\n</code></pre>\n<p>The search result is an array of active data mining jobs:</p>\n<pre><code>[\n{\n\"index\": \"cjaejhvtao\",\n\"progress\": 36,\n\"progress_msg\": \"Collecting data...\"\n}\n]\n\n</code></pre>\n<p><code>index</code> Unique ID of the running job</p>\n<p><code>progress</code>  Progress in % (a number between 0 to 100).</p>\n<p><code>progress_msg</code> (Optional) Progress message.</p>\n<p>It is also possible to check the progress of a specific data mining job:</p>\n<h4>Request</h4>\n<pre><code>tag.progress(\"cjaejhvtao\")\n</code></pre>\n<h4>Response</h4>\n<pre><code>{\n\"index\": \"cjaejhvtao\",\n\"progress\": 36,\n\"progress_msg\": \"Collecting data...\"\n}\n</code></pre>\n<h3>Searching in the Results</h3>\n<p>The search endpoint allows user to run full-text and <a href=\"https://en.wikipedia.org/wiki/Faceted_search\" rel=\"nofollow\">faceted search</a> in the extracted data.</p>\n<h4>Request</h4>\n<pre><code>tag.search(\"puvqrjfhqq\", param_from, size, f1, f2)\n</code></pre>\n<p><strong>Request parameters:</strong></p>\n<p><code>q</code>\n(Optional, string) Search query that filters the main content <code>title</code> field. It supports boolean <code>OR</code>, <code>AND</code> and <code>NOT</code> parameters.</p>\n<p><code>f</code>\n(Optional, string) Query filters must be used in pairs. Filters are created for each input dictionary. For example, to include results that have one or more label from <code>Vehicle</code> dictionary the request should look like: <code>&amp;f=Vehicle&amp;f=*</code>. To include results that are labeled with <code>Ford</code> or <code>BMW</code> from the <code>Vehicle</code> dictionary, the request would be <code>&amp;f=Vehicle&amp;f=BMW&amp;f=Vehicle&amp;f=Ford</code></p>\n<p><code>from</code>\n(Optional, int) Offset for paging results. Defaults to 0. Each page contains 20 items.</p>\n<p><code>size</code>\n(Optional, int) Number of results to return. Maximum is 200.</p>\n<h4>Response</h4>\n<pre><code>{\n\"Total\": 2610,\n\"results\": [\n{\n\"title\": \"The Federal Reserve Bank of New York provides gold custody to several central banks, governments and official international organizations on behalf of the Federal Reserve System.\",\n\"id\": \"Wv8fBG4Bc3WI8L9MbaO2\",\n\"link\": \"https://www.hamilton.edu/news/story/hamilton-nyc-program-tours-federal-reserve-museum\",\n\"score\": 0.10268514747565982,\n\"source\": \"abc15.com\",\n\"date\": \"2018-05-24T00:00:00.000Z\",\n\"tags\": [\n\"Federal Reserve\",\n\"New York\"\n]\n}\n],\n\"aggs\": {\n\"Tag\": [{\n\"key\": \"Central bank\",\n\"count\": 878\n}, {\n\"key\": \"Gold\",\n\"count\": 523\n}\n}\n}\n</code></pre>\n<p><code>Total</code>: Number of results.</p>\n<p><code>result []</code>: The array that contains result items.</p>\n<p><code>aggs</code> : Facets over the results with count of items for each facet.</p>\n<h3>Exporting the Results</h3>\n<p>Results can be exported in XLSX or JSON format:</p>\n<h4>Exporting in Excel Format</h4>\n<pre><code>tag.report_to_xlsx(\"puvqrjfhqq\", \"name-of-output-file.xlsx\")\n</code></pre>\n<h4>Exporting in JSON</h4>\n<pre><code>tag.report_to_json(\"puvqrjfhqq\", \"name-of-output-file.json\")\n\n</code></pre>\n<h3>Clear temporary data</h3>\n<p>Both classes QtDict and DataProcess have a method clear() to delete all used variable.</p>\n<pre><code>dic.clear()\ntag.clear()\n</code></pre>\n<p>The export output is limited to 5000. All <code>/search</code> parameters can be passed here to export the desired slice of the data.</p>\n<p>For technical questions please contact <a href=\"mailto:support@quantxt.com\">support@quantxt.com</a></p>\n\n          </div>"}, "last_serial": 6763209, "releases": {"1.1.0": [{"comment_text": "", "digests": {"md5": "36c8ace5b56676384f07fabcab8cdad5", "sha256": "23fbddb675dcc0c5626fa58fd4dd84c3d8f47aa4460e5d177df161e03b5d2975"}, "downloads": -1, "filename": "qtcurate-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "36c8ace5b56676384f07fabcab8cdad5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 15373, "upload_time": "2020-02-06T17:22:41", "upload_time_iso_8601": "2020-02-06T17:22:41.707925Z", "url": "https://files.pythonhosted.org/packages/52/19/a89760a6ff29bb5ebf5c375345f452840cc020fd14a252f7db8346fadd03/qtcurate-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "700b692d3a7c739a4b29f5a8a472ed73", "sha256": "9bec9c9186b433d722cef7d509c7f8f6af66b39bd4cd2997edf1f879a4a59c27"}, "downloads": -1, "filename": "qtcurate-1.1.0.tar.gz", "has_sig": false, "md5_digest": "700b692d3a7c739a4b29f5a8a472ed73", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16302, "upload_time": "2020-02-06T17:22:44", "upload_time_iso_8601": "2020-02-06T17:22:44.453768Z", "url": "https://files.pythonhosted.org/packages/e6/49/8201ffb9778e443c8d4d320f3dca3a9f53455df2674a717fa2d4a1e40a9a/qtcurate-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "8ca6b596b9257b01aad4a1d4d23cd70a", "sha256": "7a6cbf6a86fc87db6c44d46399f8437afab2e5d410cdb983ef64187c1b748f6a"}, "downloads": -1, "filename": "qtcurate-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "8ca6b596b9257b01aad4a1d4d23cd70a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 15578, "upload_time": "2020-02-06T17:31:41", "upload_time_iso_8601": "2020-02-06T17:31:41.660628Z", "url": "https://files.pythonhosted.org/packages/69/b2/408cd2708e45027e97267922f04f5b408d78d0f59c1bc3aac54cfc91404f/qtcurate-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4fa952cf79f491bcae93d442d1e15c13", "sha256": "a7aa5577d1825c2c6bec3eb6cb3f97e9b7b3629b8702777b7c5511c3f323d82a"}, "downloads": -1, "filename": "qtcurate-1.1.1.tar.gz", "has_sig": false, "md5_digest": "4fa952cf79f491bcae93d442d1e15c13", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16443, "upload_time": "2020-02-06T17:31:43", "upload_time_iso_8601": "2020-02-06T17:31:43.488861Z", "url": "https://files.pythonhosted.org/packages/ae/9f/e7278468060039f7bc63ec14c8bf3ec8b2b7be14edcda747ba9f9d9178fa/qtcurate-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "e9fd4453ce11ee1ded49508363e90615", "sha256": "d0544902af14662f199f30dc5cbfbdae16b977d8a04f7cfd6ba00c4a1415f46e"}, "downloads": -1, "filename": "qtcurate-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "e9fd4453ce11ee1ded49508363e90615", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 19542, "upload_time": "2020-02-10T08:01:55", "upload_time_iso_8601": "2020-02-10T08:01:55.237910Z", "url": "https://files.pythonhosted.org/packages/7e/5a/b6ace1ee59ad82c5a14f2be9916a4910dbfb65096f5036393ed936152e8e/qtcurate-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b72290b0548b6e4f59d157127e7da5b2", "sha256": "170089b0131c66f4ffb58d0de594aa080c0a533b663fec11f35fe92e499b455b"}, "downloads": -1, "filename": "qtcurate-1.1.2.tar.gz", "has_sig": false, "md5_digest": "b72290b0548b6e4f59d157127e7da5b2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 16248, "upload_time": "2020-02-10T08:01:56", "upload_time_iso_8601": "2020-02-10T08:01:56.922787Z", "url": "https://files.pythonhosted.org/packages/f2/07/97dc8689d58f74971b15399494ef6b3b2d839f08ad759aa3f7e58251a33b/qtcurate-1.1.2.tar.gz", "yanked": false}], "1.3.0": [{"comment_text": "", "digests": {"md5": "3f7f3de3224460d3ca4ae7ee6069353e", "sha256": "2fe61069c94d93c78c1e2977cb0be1b1dd66d09fb7889ef0330d32413662f32b"}, "downloads": -1, "filename": "qtcurate-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3f7f3de3224460d3ca4ae7ee6069353e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 20355, "upload_time": "2020-03-06T16:31:00", "upload_time_iso_8601": "2020-03-06T16:31:00.526427Z", "url": "https://files.pythonhosted.org/packages/d4/25/f1fc07952ae1044e6bf9be4755cb6b698755bd64ded5fdff5a703e3c3c98/qtcurate-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fa29d5c750e9bedd1da9a6ddf6d8eb7b", "sha256": "94f90c518540c47873945eb030e80a09f1bf25f485a65f698d2cd4e376407826"}, "downloads": -1, "filename": "qtcurate-1.3.0.tar.gz", "has_sig": false, "md5_digest": "fa29d5c750e9bedd1da9a6ddf6d8eb7b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 20924, "upload_time": "2020-03-06T16:31:02", "upload_time_iso_8601": "2020-03-06T16:31:02.403119Z", "url": "https://files.pythonhosted.org/packages/33/d1/2f9f18a14c398046b384a3a45b22d1f3fc0d0cf972182b1111b371c49aed/qtcurate-1.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3f7f3de3224460d3ca4ae7ee6069353e", "sha256": "2fe61069c94d93c78c1e2977cb0be1b1dd66d09fb7889ef0330d32413662f32b"}, "downloads": -1, "filename": "qtcurate-1.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3f7f3de3224460d3ca4ae7ee6069353e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 20355, "upload_time": "2020-03-06T16:31:00", "upload_time_iso_8601": "2020-03-06T16:31:00.526427Z", "url": "https://files.pythonhosted.org/packages/d4/25/f1fc07952ae1044e6bf9be4755cb6b698755bd64ded5fdff5a703e3c3c98/qtcurate-1.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fa29d5c750e9bedd1da9a6ddf6d8eb7b", "sha256": "94f90c518540c47873945eb030e80a09f1bf25f485a65f698d2cd4e376407826"}, "downloads": -1, "filename": "qtcurate-1.3.0.tar.gz", "has_sig": false, "md5_digest": "fa29d5c750e9bedd1da9a6ddf6d8eb7b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 20924, "upload_time": "2020-03-06T16:31:02", "upload_time_iso_8601": "2020-03-06T16:31:02.403119Z", "url": "https://files.pythonhosted.org/packages/33/d1/2f9f18a14c398046b384a3a45b22d1f3fc0d0cf972182b1111b371c49aed/qtcurate-1.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:09:10 2020"}