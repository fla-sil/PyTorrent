{"info": {"author": "Aman Srivastava", "author_email": "amans.rlx@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3.6"], "description": "<h1 align=\"center\">embedding-as-service</h1>  \n<p align=\"center\">One-Stop Solution to encode sentence to fixed length vectors from various embedding techniques   \n<br>\u2022 Inspired from <a href=\"https://github.com/hanxiao/bert-as-service\"> bert-as-service</a> </p>  \n<p align=\"center\">  \n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/stargazers\">  \n    <img src=\"https://img.shields.io/github/stars/amansrivastava17/embedding-as-service.svg?colorA=orange&colorB=orange&logo=github\"  \n         alt=\"GitHub stars\">  \n  </a> \n  <a href=\"https://pepy.tech/project/embedding-as-service/\">  \n      <img src=\"https://pepy.tech/badge/embedding-as-service\" alt=\"Downloads\">  \n  </a>   \n  <a href=\"https://pypi.org/project/embedding-as-service/\">  \n      <img src=\"https://img.shields.io/pypi/v/embedding-as-service?colorB=brightgreen\" alt=\"Pypi package\">  \n  </a>  \n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/issues\">\n        <img src=\"https://img.shields.io/github/issues/amansrivastava17/embedding-as-service.svg\"\n             alt=\"GitHub issues\">\n  </a>\n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/blob/master/LICENSE\">  \n        <img src=\"https://img.shields.io/github/license/amansrivastava17/embedding-as-service.svg\"  \n             alt=\"GitHub license\">  \n  </a>\n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/graphs/contributors\">  \n        <img src=\"https://img.shields.io/badge/all_contributors-5-blue.svg\"  \n             alt=\"Contributors\">  \n  </a>  \n</p>  \n\n<p align=\"center\">  \n <a href=\"#what-is-it\">What is it</a> \u2022  \n  <a href=\"#-installation\">Installation</a> \u2022  \n  <a href=\"#-\ufe0fgetting-started\">Getting Started</a> \u2022  \n  <a href=\"#-supported-embeddings-and-models\">Supported Embeddings</a> \u2022  \n  <a href=\"#-api-\">API</a> \u2022   \n</p>  \n</p>\n\n<p align=\"center\">\n    <img src=\".github/demo.gif?raw=true\" width=\"670\", height=\"350\">\n</p>\n\n<h2 align=\"center\">What is it</h3>  \n\n**Encoding/Embedding** is a upstream task of encoding any inputs in the form of text, image, audio, video, transactional data to fixed length vector. Embeddings are quite popular in the field of NLP, there has been various Embeddings models being proposed in recent years by researchers, some of the famous one are bert, xlnet, word2vec etc. The goal of this repo is to build one stop solution for all embeddings techniques available, here we are starting with popular text embeddings for now and later on we aim  to add as much technique for image, audio, video inputs also.  \n\n**`embedding-as-service`** help you to encode any given text to fixed length vector from supported embeddings and models.  \n\n<h2 align=\"center\">\ud83d\udcbe Installation</h2>  \n<p align=\"right\"><a href=\"#embedding-as-service\"><sup>\u25b4 Back to top</sup></a></p>\n\nHere we have given the capability to use `embedding-as-service` like a module or you can run it as a server and handle queries by installing client package `embedding-as-service-client`\n\n#### Using `embedding-as-service` as module  \nInstall the embedding-as-servive via `pip`.   \n```bash  \n$ pip install embedding-as-service\n```  \n> Note that the code MUST be running on **Python >= 3.6**. Again module does not support Python 2!  \n\n#### Using `embedding-as-service` as a server \nHere you also need to install a client module `embedding-as-service-client`\n```bash\n$ pip install embedding-as-service # server\n$ pip install embedding-as-service-client # client\n```\n> Client module need not to be on Python 3.6, it support both Python2 and Python3\n\n<h2 align=\"center\">\u26a1 \ufe0fGetting Started</h2> \n<p align=\"right\"><a href=\"#embedding-as-service\"><sup>\u25b4 Back to top</sup></a></p>\n\n\n#### 1. **Intialise encoder using supported embedding** and models from <a href=\"#-supported-embeddings-and-models\">here</a>\n**If using** `embedding-as-service` **as a module**\n```python  \n>>> from embedding_as_service.text.encode import Encoder  \n>>> en = Encoder(embedding='bert', model='bert_base_cased')  \n```  \n**If using** `embedding-as-service` **as a server**\n```bash\n# start the server by proving embedding, model, port, max_seq_length[default=256], num_workers[default=4]\n$ embedding-as-service-start --embedding bert --model bert_base_cased --port 8080 --max_seq_length 256\n```\n```python\n>>> from embedding_as_service_client import EmbeddingClient\n>>> en = EmbeddingClient(host=<host_server_ip>, port=<host_port>)\n```\n\n#### 2. Get sentences **tokens embedding**  \n```python \n>>> vecs = en.encode(texts=['hello aman', 'how are you?'])  \n>>> vecs  \narray([[[ 1.7049843 ,  0.        ,  1.3486509 , ..., -1.3647075 ,  \n 0.6958289 ,  1.8013777 ], ... [ 0.4913215 ,  0.60877025,  0.73050433, ..., -0.64490885, 0.8525057 ,  0.3080206 ]]], dtype=float32)  \n>>> vecs.shape  \n(2, 128, 768) # batch x max_sequence_length x embedding_size  \n```  \n#### 3. Using **pooling strategy**, click <a href=\"#-pooling-strategies-\">here</a> for more.  \n<details><summary><I>Supported Pooling Methods</I></summary>\n\n|Strategy|Description|\n|---|---|\n| `None` | no pooling at all, useful when you want to use word embedding instead of sentence embedding. This will results in a `[max_seq_len, embedding_size]` encode matrix for a sequence.|\n| `reduce_mean` | take the average of all token embeddings |\n| `reduce_min` | take the minumun of all token embeddings|\n| `reduce_max` | take the maximum of all token embeddings |\n| `reduce_mean_max` | do `reduce_mean` and `reduce_max` separately and then concat them together |\n| `first_token` | get the token embedding of first token of a sentence |\n| `last_token` | get the token embedding of last token of a sentence |\n</details>\n\n\n```python  \n>>> vecs = en.encode(texts=['hello aman', 'how are you?'], pooling='reduce_mean')  \n>>> vecs  \narray([[-0.33547154,  0.34566957,  1.1954105 , ...,  0.33702594,  \n 1.0317835 , -0.785943  ], [-0.3439088 ,  0.36881036,  1.0612687 , ...,  0.28851607, 1.1107115 , -0.6253736 ]], dtype=float32)  \n\n>>> vecs.shape  \n(2, 768) # batch x embedding_size  \n```  \n\n#### 4. Use custom `max_seq_length`, default is 128  \n```python \n>>> en = Encoder(embedding='bert', model='bert_base_cased', max_seq_length=256)  \n>>> vecs = en.encode(texts=['hello aman', 'how are you?'])  \n>>> vecs  \narray([[ 0.48388457, -0.01327741, -0.76577514, ..., -0.54265064,  \n -0.5564591 ,  0.6454179 ], [ 0.53209245,  0.00526248, -0.71091074, ..., -0.5171917 , -0.40458363,  0.6779779 ]], dtype=float32)  \n\n>>> vecs.shape  \n(2, 256, 768) # batch x max_sequence_length x embedding_size  \n```  \n#### 5. Show embedding Tokens  \n```python  \n>>> en.tokenize(texts=['hello aman', 'how are you?'])  \n[['_hello', '_aman'], ['_how', '_are', '_you', '?']]  \n```  \n\n#### 6. Using your own tokenizer  \n```python  \n>>> texts = ['hello aman!', 'how are you']  \n\n# a naive whitespace tokenizer  \n>>> tokens = [s.split() for s in texts]  \n>>> vecs = en.encode(tokens, is_tokenized=True)  \n```  \n<h2 align=\"center\">\ud83d\udccb API </h2>  \n<p align=\"right\"><a href=\"#embedding-as-service\"><sup>\u25b4 Back to top</sup></a></p>\n\n1. **class** <span style=\"color:blue\">`embedding_as_service.text.encoder.Encoder`</span>\n\n  | Argument | Type | Default | Description |\n|--------------------|------|-------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `embedding` | str | *Required* | embedding method to be used, check `Embedding` column <a href=\"#-supported-embeddings-and-models\">here</a>|\n| `model`| str |*Required*| Model to be used for mentioned embedding, check `Model` column <a href=\"#-supported-embeddings-and-models\">here</a>|\n| `max_seq_length`| int |128| Maximum Sequence Length, default is 128|\n\n2. **def** <span style=\"color:blue\">`embedding_as_service.text.encoder.Encoder.encode`</span>\n\n  | Argument | Type | Default | Description |\n|--------------------|------|-------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `Texts` | List[str] or List[List[str]] | *Required* | List of sentences or list of list of sentence tokens in case of `is_tokenized=True`\n| `pooling`| str |(Optional)| Pooling methods to apply, <a href=\"#-pooling-strategies-\">here</a> is available methods|\n| `is_tokenized` | bool | `False` | set as True in case of tokens are passed for encoding |  \n| `batch_size` | int | `128` | maximum number of sequences handled by encoder, larger batch will be partitioned into small batches. |\n\n 3. **def** <span style=\"color:blue\">`embedding_as_service.text.encoder.Encoder.tokenize`</span>\n\n  | Argument | Type | Default | Description |\n|--------------------|------|-------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `Texts` | List[str] | *Required* | List of sentences  \n\n\n<h2 align=\"center\" href=\"#supported-models\">\u2705 Supported Embeddings and Models</h2>  \n<p align=\"right\"><a href=\"#embedding-as-service\"><sup>\u25b4 Back to top</sup></a></p>\n\n\nHere are the list of supported embeddings and their respective models.  \n\n|  |Embedding  | Model  | Embedding dimensions | Paper |   \n|:--|:--|:--:|:--:|--|  \n|:one: |**albert**|`albert_base` | 768| <a href=\"https://arxiv.org/pdf/1909.11942.pdf\"> Read Paper :bookmark:  </a>|  \n||  |`albert_large` | 1024| |  \n||  |`albert_xlarge` | 2048| |  \n||  |`albert_xxlarge` | 4096| |  \n|:two: |**xlnet** |`xlnet_large_cased` | 1024| <a href=\"https://arxiv.org/abs/1906.08237\"> Read Paper :bookmark: </a>|  \n||  |`xlnet_base_cased` | 768| |  \n|:three: |**bert** |`bert_base_uncased` | 768| <a href=\"https://arxiv.org/abs/1810.04805\"> Read Paper :bookmark:  </a>|  \n|||`bert_base_cased` | 768| |  \n||  |`bert_multi_cased` | 768||   \n||  |`bert_large_uncased` | 1024||   \n||  |`bert_large_cased` | 1024| |  \n|:four: |**elmo** |`elmo_bi_lm` | 512| <a href=\"https://allennlp.org/elmo\"> Read Paper :bookmark: </a>|  \n|:five: |**ulmfit** |`ulmfit_forward` | 300|<a href=\"https://arxiv.org/abs/1801.06146\"> Read Paper :bookmark: </a>|   \n|||`ulmfit_backward` | 300| |  \n|:six: |**use**|`use_dan` | 512| <a href=\"https://arxiv.org/abs/1803.11175\"> Read Paper :bookmark: </a>|  \n||  |`use_transformer_large` | 512| |  \n||  |`use_transformer_lite` | 512| |  \n|:seven: |**word2vec**|`google_news_300` | 300| <a href=\"https://arxiv.org/abs/1301.3781\"> Read Paper :bookmark:  </a>|  \n|:eight: |**fasttext**|`wiki_news_300` | 300| <a href=\"https://arxiv.org/abs/1607.01759\"> Read Paper :bookmark: </a>|  \n||  |`wiki_news_300_sub` | 300| |  \n||  |`common_crawl_300` | 300| |  \n||  |`common_crawl_300_sub` | 300| |  \n|:nine: |**glove**|`twitter_200` | 200| <a href=\"https://nlp.stanford.edu/pubs/glove.pdf\"> Read Paper :bookmark:  </a>|  \n||  |`twitter_100` | 100| |  \n||  |`twitter_50` | 50| |  \n||  |`twitter_25` | 25| |  \n||  |`wiki_300` | 300| |  \n||  |`wiki_200` | 200| |  \n||  |`wiki_100` | 100| |  \n||  |`wiki_50` | 50| |  \n||  |`crawl_42B_300` | 300| |  \n||  |`crawl_840B_300` | 300| |\n\n\n\n## Credits \n\nThis software uses the following open source packages:\n\n- [XLnet](https://github.com/zihangdai/xlnet)\n- [tensorflow-hub](https://www.tensorflow.org/hub)\n\n\n## Contributors \u2728\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/aman-srivastava-a8bb1285/\"><img src=\"https://avatars0.githubusercontent.com/u/5950398?v=4\" width=\"100px;\" alt=\"Aman Srivastava\"/><br /><sub><b>Aman Srivastava</b></sub></a><br /><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=amansrivastava17\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=amansrivastava17\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-amansrivastava17\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ashutoshsingh0223\"><img src=\"https://avatars3.githubusercontent.com/u/40604544?v=4\" width=\"100px;\" alt=\"Ashutosh Singh\"/><br /><sub><b>Ashutosh Singh</b></sub></a><br /><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=ashutoshsingh0223\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=ashutoshsingh0223\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-ashutoshsingh0223\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://chiragjn.github.io\"><img src=\"https://avatars2.githubusercontent.com/u/10295418?v=4\" width=\"100px;\" alt=\"Chirag Jain\"/><br /><sub><b>Chirag Jain</b></sub></a><br /><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=chiragjn\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=chiragjn\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-chiragjn\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://github.com/MrPranav101\"><img src=\"https://avatars0.githubusercontent.com/u/43914392?v=4\" width=\"100px;\" alt=\"MrPranav101\"/><br /><sub><b>MrPranav101</b></sub></a><br /><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=MrPranav101\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=MrPranav101\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-MrPranav101\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>    \n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/dhavaltaunk08/\"><img src=\"https://avatars0.githubusercontent.com/u/31320833?v=4\" width=\"100px;\" alt=\"Dhaval Taunk\"/><br /><sub><b>Dhaval Taunk</b></sub></a><br /><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=DhavalTaunk08\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=DhavalTaunk08\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-DhavalTaunk08\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n  </tr>\n</table>\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n\nPlease read the [contribution guidelines](CONTRIBUTION.md) first.\n\n\n<h2>Citing</h2>\n<p align=\"right\"><a href=\"#embedding-as-service\"><sup>\u25b4 Back to top</sup></a></p>\n\nIf you use embedding-as-service in a scientific publication, we would appreciate references to the following BibTex entry:\n\n```latex\n@misc{aman2019embeddingservice,\n  title={embedding-as-service},\n  author={Srivastava, Aman},\n  howpublished={\\url{https://github.com/amansrivastava17/embedding-as-service}},\n  year={2019}\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/amansrivastava17/embedding-as-service", "keywords": "bert nlp tensorflow machine learning sentence encoding embedding serving albert glove word2vec", "license": "", "maintainer": "", "maintainer_email": "", "name": "embedding-as-service-client", "package_url": "https://pypi.org/project/embedding-as-service-client/", "platform": "", "project_url": "https://pypi.org/project/embedding-as-service-client/", "project_urls": {"Homepage": "https://github.com/amansrivastava17/embedding-as-service"}, "release_url": "https://pypi.org/project/embedding-as-service-client/1.0.0/", "requires_dist": ["requests (==2.21.0)", "setuptools (>=41.0.0)"], "requires_python": ">=3.6", "summary": "embedding-as-service: one-stop solution to encode sentence to vectors using various embedding methods", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>embedding-as-service</h1>  \n<p align=\"center\">One-Stop Solution to encode sentence to fixed length vectors from various embedding techniques   \n<br>\u2022 Inspired from <a href=\"https://github.com/hanxiao/bert-as-service\" rel=\"nofollow\"> bert-as-service</a> </p>  \n<p align=\"center\">  \n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/stargazers\" rel=\"nofollow\">  \n    <img alt=\"GitHub stars\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c98f32628e1233ab219150229d62f86397d1e4c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d616e7372697661737461766131372f656d62656464696e672d61732d736572766963652e7376673f636f6c6f72413d6f72616e676526636f6c6f72423d6f72616e6765266c6f676f3d676974687562\">  \n  </a> \n  <a href=\"https://pepy.tech/project/embedding-as-service/\" rel=\"nofollow\">  \n      <img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ffffafd7c2170962381f76e34a4a5588f65aefd7/68747470733a2f2f706570792e746563682f62616467652f656d62656464696e672d61732d73657276696365\">  \n  </a>   \n  <a href=\"https://pypi.org/project/embedding-as-service/\" rel=\"nofollow\">  \n      <img alt=\"Pypi package\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3d82fa368e905b517fcbaa2621333bc0d92f1d09/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f656d62656464696e672d61732d736572766963653f636f6c6f72423d627269676874677265656e\">  \n  </a>  \n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/issues\" rel=\"nofollow\">\n        <img alt=\"GitHub issues\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2ec4bca7ae6afa57b5673193e0f16ce73011d7d3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f616d616e7372697661737461766131372f656d62656464696e672d61732d736572766963652e737667\">\n  </a>\n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/blob/master/LICENSE\" rel=\"nofollow\">  \n        <img alt=\"GitHub license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a1179450784da1609b156f2726267a898df596ff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f616d616e7372697661737461766131372f656d62656464696e672d61732d736572766963652e737667\">  \n  </a>\n  <a href=\"https://github.com/amansrivastava17/embedding-as-service/graphs/contributors\" rel=\"nofollow\">  \n        <img alt=\"Contributors\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/85ce5717c22ce663a3f927c44c56de2be60055e4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c5f636f6e7472696275746f72732d352d626c75652e737667\">  \n  </a>  \n</p>  \n<p align=\"center\">  \n <a href=\"#what-is-it\" rel=\"nofollow\">What is it</a> \u2022  \n  <a href=\"#-installation\" rel=\"nofollow\">Installation</a> \u2022  \n  <a href=\"#-%EF%B8%8Fgetting-started\" rel=\"nofollow\">Getting Started</a> \u2022  \n  <a href=\"#-supported-embeddings-and-models\" rel=\"nofollow\">Supported Embeddings</a> \u2022  \n  <a href=\"#-api-\" rel=\"nofollow\">API</a> \u2022   \n</p>  \n<p></p>\n<p align=\"center\">\n    <img height=\"350\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/acd2fa6182678268df596ebd10a477a15facd9b9/2e6769746875622f64656d6f2e6769663f7261773d74727565\" width=\"670\">\n</p>\n<h2>What is it</h2>  \n<p><strong>Encoding/Embedding</strong> is a upstream task of encoding any inputs in the form of text, image, audio, video, transactional data to fixed length vector. Embeddings are quite popular in the field of NLP, there has been various Embeddings models being proposed in recent years by researchers, some of the famous one are bert, xlnet, word2vec etc. The goal of this repo is to build one stop solution for all embeddings techniques available, here we are starting with popular text embeddings for now and later on we aim  to add as much technique for image, audio, video inputs also.</p>\n<p><strong><code>embedding-as-service</code></strong> help you to encode any given text to fixed length vector from supported embeddings and models.</p>\n<h2>\ud83d\udcbe Installation</h2>  \n<p align=\"right\"><a href=\"#embedding-as-service\" rel=\"nofollow\"><sup>\u25b4 Back to top</sup></a></p>\n<p>Here we have given the capability to use <code>embedding-as-service</code> like a module or you can run it as a server and handle queries by installing client package <code>embedding-as-service-client</code></p>\n<h4>Using <code>embedding-as-service</code> as module</h4>\n<p>Install the embedding-as-servive via <code>pip</code>.</p>\n<pre>$ pip install embedding-as-service\n</pre>\n<blockquote>\n<p>Note that the code MUST be running on <strong>Python &gt;= 3.6</strong>. Again module does not support Python 2!</p>\n</blockquote>\n<h4>Using <code>embedding-as-service</code> as a server</h4>\n<p>Here you also need to install a client module <code>embedding-as-service-client</code></p>\n<pre>$ pip install embedding-as-service <span class=\"c1\"># server</span>\n$ pip install embedding-as-service-client <span class=\"c1\"># client</span>\n</pre>\n<blockquote>\n<p>Client module need not to be on Python 3.6, it support both Python2 and Python3</p>\n</blockquote>\n<h2>\u26a1 \ufe0fGetting Started</h2> \n<p align=\"right\"><a href=\"#embedding-as-service\" rel=\"nofollow\"><sup>\u25b4 Back to top</sup></a></p>\n<h4>1. <strong>Intialise encoder using supported embedding</strong> and models from <a href=\"#-supported-embeddings-and-models\" rel=\"nofollow\">here</a></h4>\n<p><strong>If using</strong> <code>embedding-as-service</code> <strong>as a module</strong></p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">embedding_as_service.text.encode</span> <span class=\"kn\">import</span> <span class=\"n\">Encoder</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">en</span> <span class=\"o\">=</span> <span class=\"n\">Encoder</span><span class=\"p\">(</span><span class=\"n\">embedding</span><span class=\"o\">=</span><span class=\"s1\">'bert'</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s1\">'bert_base_cased'</span><span class=\"p\">)</span>  \n</pre>\n<p><strong>If using</strong> <code>embedding-as-service</code> <strong>as a server</strong></p>\n<pre><span class=\"c1\"># start the server by proving embedding, model, port, max_seq_length[default=256], num_workers[default=4]</span>\n$ embedding-as-service-start --embedding bert --model bert_base_cased --port <span class=\"m\">8080</span> --max_seq_length <span class=\"m\">256</span>\n</pre>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">embedding_as_service_client</span> <span class=\"kn\">import</span> <span class=\"n\">EmbeddingClient</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">en</span> <span class=\"o\">=</span> <span class=\"n\">EmbeddingClient</span><span class=\"p\">(</span><span class=\"n\">host</span><span class=\"o\">=&lt;</span><span class=\"n\">host_server_ip</span><span class=\"o\">&gt;</span><span class=\"p\">,</span> <span class=\"n\">port</span><span class=\"o\">=&lt;</span><span class=\"n\">host_port</span><span class=\"o\">&gt;</span><span class=\"p\">)</span>\n</pre>\n<h4>2. Get sentences <strong>tokens embedding</strong></h4>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span> <span class=\"o\">=</span> <span class=\"n\">en</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">texts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'hello aman'</span><span class=\"p\">,</span> <span class=\"s1\">'how are you?'</span><span class=\"p\">])</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span>  \n<span class=\"n\">array</span><span class=\"p\">([[[</span> <span class=\"mf\">1.7049843</span> <span class=\"p\">,</span>  <span class=\"mf\">0.</span>        <span class=\"p\">,</span>  <span class=\"mf\">1.3486509</span> <span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">1.3647075</span> <span class=\"p\">,</span>  \n <span class=\"mf\">0.6958289</span> <span class=\"p\">,</span>  <span class=\"mf\">1.8013777</span> <span class=\"p\">],</span> <span class=\"o\">...</span> <span class=\"p\">[</span> <span class=\"mf\">0.4913215</span> <span class=\"p\">,</span>  <span class=\"mf\">0.60877025</span><span class=\"p\">,</span>  <span class=\"mf\">0.73050433</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.64490885</span><span class=\"p\">,</span> <span class=\"mf\">0.8525057</span> <span class=\"p\">,</span>  <span class=\"mf\">0.3080206</span> <span class=\"p\">]]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span><span class=\"o\">.</span><span class=\"n\">shape</span>  \n<span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">768</span><span class=\"p\">)</span> <span class=\"c1\"># batch x max_sequence_length x embedding_size  </span>\n</pre>\n<h4>3. Using <strong>pooling strategy</strong>, click <a href=\"#-pooling-strategies-\" rel=\"nofollow\">here</a> for more.</h4>\n<details><summary><i>Supported Pooling Methods</i></summary>\n<table>\n<thead>\n<tr>\n<th>Strategy</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>None</code></td>\n<td>no pooling at all, useful when you want to use word embedding instead of sentence embedding. This will results in a <code>[max_seq_len, embedding_size]</code> encode matrix for a sequence.</td>\n</tr>\n<tr>\n<td><code>reduce_mean</code></td>\n<td>take the average of all token embeddings</td>\n</tr>\n<tr>\n<td><code>reduce_min</code></td>\n<td>take the minumun of all token embeddings</td>\n</tr>\n<tr>\n<td><code>reduce_max</code></td>\n<td>take the maximum of all token embeddings</td>\n</tr>\n<tr>\n<td><code>reduce_mean_max</code></td>\n<td>do <code>reduce_mean</code> and <code>reduce_max</code> separately and then concat them together</td>\n</tr>\n<tr>\n<td><code>first_token</code></td>\n<td>get the token embedding of first token of a sentence</td>\n</tr>\n<tr>\n<td><code>last_token</code></td>\n<td>get the token embedding of last token of a sentence</td>\n</tr></tbody></table>\n</details>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span> <span class=\"o\">=</span> <span class=\"n\">en</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">texts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'hello aman'</span><span class=\"p\">,</span> <span class=\"s1\">'how are you?'</span><span class=\"p\">],</span> <span class=\"n\">pooling</span><span class=\"o\">=</span><span class=\"s1\">'reduce_mean'</span><span class=\"p\">)</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span>  \n<span class=\"n\">array</span><span class=\"p\">([[</span><span class=\"o\">-</span><span class=\"mf\">0.33547154</span><span class=\"p\">,</span>  <span class=\"mf\">0.34566957</span><span class=\"p\">,</span>  <span class=\"mf\">1.1954105</span> <span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span>  <span class=\"mf\">0.33702594</span><span class=\"p\">,</span>  \n <span class=\"mf\">1.0317835</span> <span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.785943</span>  <span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mf\">0.3439088</span> <span class=\"p\">,</span>  <span class=\"mf\">0.36881036</span><span class=\"p\">,</span>  <span class=\"mf\">1.0612687</span> <span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span>  <span class=\"mf\">0.28851607</span><span class=\"p\">,</span> <span class=\"mf\">1.1107115</span> <span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.6253736</span> <span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span><span class=\"o\">.</span><span class=\"n\">shape</span>  \n<span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">768</span><span class=\"p\">)</span> <span class=\"c1\"># batch x embedding_size  </span>\n</pre>\n<h4>4. Use custom <code>max_seq_length</code>, default is 128</h4>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">en</span> <span class=\"o\">=</span> <span class=\"n\">Encoder</span><span class=\"p\">(</span><span class=\"n\">embedding</span><span class=\"o\">=</span><span class=\"s1\">'bert'</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s1\">'bert_base_cased'</span><span class=\"p\">,</span> <span class=\"n\">max_seq_length</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">)</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span> <span class=\"o\">=</span> <span class=\"n\">en</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">texts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'hello aman'</span><span class=\"p\">,</span> <span class=\"s1\">'how are you?'</span><span class=\"p\">])</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span>  \n<span class=\"n\">array</span><span class=\"p\">([[</span> <span class=\"mf\">0.48388457</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.01327741</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.76577514</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.54265064</span><span class=\"p\">,</span>  \n <span class=\"o\">-</span><span class=\"mf\">0.5564591</span> <span class=\"p\">,</span>  <span class=\"mf\">0.6454179</span> <span class=\"p\">],</span> <span class=\"p\">[</span> <span class=\"mf\">0.53209245</span><span class=\"p\">,</span>  <span class=\"mf\">0.00526248</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.71091074</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.5171917</span> <span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.40458363</span><span class=\"p\">,</span>  <span class=\"mf\">0.6779779</span> <span class=\"p\">]],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">float32</span><span class=\"p\">)</span>  \n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span><span class=\"o\">.</span><span class=\"n\">shape</span>  \n<span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">768</span><span class=\"p\">)</span> <span class=\"c1\"># batch x max_sequence_length x embedding_size  </span>\n</pre>\n<h4>5. Show embedding Tokens</h4>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">en</span><span class=\"o\">.</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"n\">texts</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'hello aman'</span><span class=\"p\">,</span> <span class=\"s1\">'how are you?'</span><span class=\"p\">])</span>  \n<span class=\"p\">[[</span><span class=\"s1\">'_hello'</span><span class=\"p\">,</span> <span class=\"s1\">'_aman'</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"s1\">'_how'</span><span class=\"p\">,</span> <span class=\"s1\">'_are'</span><span class=\"p\">,</span> <span class=\"s1\">'_you'</span><span class=\"p\">,</span> <span class=\"s1\">'?'</span><span class=\"p\">]]</span>  \n</pre>\n<h4>6. Using your own tokenizer</h4>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">texts</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'hello aman!'</span><span class=\"p\">,</span> <span class=\"s1\">'how are you'</span><span class=\"p\">]</span>  \n\n<span class=\"c1\"># a naive whitespace tokenizer  </span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">tokens</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">s</span> <span class=\"ow\">in</span> <span class=\"n\">texts</span><span class=\"p\">]</span>  \n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">vecs</span> <span class=\"o\">=</span> <span class=\"n\">en</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">,</span> <span class=\"n\">is_tokenized</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>  \n</pre>\n<h2>\ud83d\udccb API </h2>  \n<p align=\"right\"><a href=\"#embedding-as-service\" rel=\"nofollow\"><sup>\u25b4 Back to top</sup></a></p>\n<ol>\n<li><strong>class</strong> <span><code>embedding_as_service.text.encoder.Encoder</code></span></li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Default</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>embedding</code></td>\n<td>str</td>\n<td><em>Required</em></td>\n<td>embedding method to be used, check <code>Embedding</code> column <a href=\"#-supported-embeddings-and-models\" rel=\"nofollow\">here</a></td>\n</tr>\n<tr>\n<td><code>model</code></td>\n<td>str</td>\n<td><em>Required</em></td>\n<td>Model to be used for mentioned embedding, check <code>Model</code> column <a href=\"#-supported-embeddings-and-models\" rel=\"nofollow\">here</a></td>\n</tr>\n<tr>\n<td><code>max_seq_length</code></td>\n<td>int</td>\n<td>128</td>\n<td>Maximum Sequence Length, default is 128</td>\n</tr></tbody></table>\n<ol>\n<li><strong>def</strong> <span><code>embedding_as_service.text.encoder.Encoder.encode</code></span></li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Default</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>Texts</code></td>\n<td>List[str] or List[List[str]]</td>\n<td><em>Required</em></td>\n<td>List of sentences or list of list of sentence tokens in case of <code>is_tokenized=True</code></td>\n</tr>\n<tr>\n<td><code>pooling</code></td>\n<td>str</td>\n<td>(Optional)</td>\n<td>Pooling methods to apply, <a href=\"#-pooling-strategies-\" rel=\"nofollow\">here</a> is available methods</td>\n</tr>\n<tr>\n<td><code>is_tokenized</code></td>\n<td>bool</td>\n<td><code>False</code></td>\n<td>set as True in case of tokens are passed for encoding</td>\n</tr>\n<tr>\n<td><code>batch_size</code></td>\n<td>int</td>\n<td><code>128</code></td>\n<td>maximum number of sequences handled by encoder, larger batch will be partitioned into small batches.</td>\n</tr></tbody></table>\n<ol>\n<li><strong>def</strong> <span><code>embedding_as_service.text.encoder.Encoder.tokenize</code></span></li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Argument</th>\n<th>Type</th>\n<th>Default</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>Texts</code></td>\n<td>List[str]</td>\n<td><em>Required</em></td>\n<td>List of sentences</td>\n</tr></tbody></table>\n<h2>\u2705 Supported Embeddings and Models</h2>  \n<p align=\"right\"><a href=\"#embedding-as-service\" rel=\"nofollow\"><sup>\u25b4 Back to top</sup></a></p>\n<p>Here are the list of supported embeddings and their respective models.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"left\">Embedding</th>\n<th align=\"center\">Model</th>\n<th align=\"center\">Embedding dimensions</th>\n<th>Paper</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">:one:</td>\n<td align=\"left\"><strong>albert</strong></td>\n<td align=\"center\"><code>albert_base</code></td>\n<td align=\"center\">768</td>\n<td><a href=\"https://arxiv.org/pdf/1909.11942.pdf\" rel=\"nofollow\"> Read Paper :bookmark:  </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>albert_large</code></td>\n<td align=\"center\">1024</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>albert_xlarge</code></td>\n<td align=\"center\">2048</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>albert_xxlarge</code></td>\n<td align=\"center\">4096</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\">:two:</td>\n<td align=\"left\"><strong>xlnet</strong></td>\n<td align=\"center\"><code>xlnet_large_cased</code></td>\n<td align=\"center\">1024</td>\n<td><a href=\"https://arxiv.org/abs/1906.08237\" rel=\"nofollow\"> Read Paper :bookmark: </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>xlnet_base_cased</code></td>\n<td align=\"center\">768</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\">:three:</td>\n<td align=\"left\"><strong>bert</strong></td>\n<td align=\"center\"><code>bert_base_uncased</code></td>\n<td align=\"center\">768</td>\n<td><a href=\"https://arxiv.org/abs/1810.04805\" rel=\"nofollow\"> Read Paper :bookmark:  </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>bert_base_cased</code></td>\n<td align=\"center\">768</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>bert_multi_cased</code></td>\n<td align=\"center\">768</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>bert_large_uncased</code></td>\n<td align=\"center\">1024</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>bert_large_cased</code></td>\n<td align=\"center\">1024</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\">:four:</td>\n<td align=\"left\"><strong>elmo</strong></td>\n<td align=\"center\"><code>elmo_bi_lm</code></td>\n<td align=\"center\">512</td>\n<td><a href=\"https://allennlp.org/elmo\" rel=\"nofollow\"> Read Paper :bookmark: </a></td>\n</tr>\n<tr>\n<td align=\"left\">:five:</td>\n<td align=\"left\"><strong>ulmfit</strong></td>\n<td align=\"center\"><code>ulmfit_forward</code></td>\n<td align=\"center\">300</td>\n<td><a href=\"https://arxiv.org/abs/1801.06146\" rel=\"nofollow\"> Read Paper :bookmark: </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>ulmfit_backward</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\">:six:</td>\n<td align=\"left\"><strong>use</strong></td>\n<td align=\"center\"><code>use_dan</code></td>\n<td align=\"center\">512</td>\n<td><a href=\"https://arxiv.org/abs/1803.11175\" rel=\"nofollow\"> Read Paper :bookmark: </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>use_transformer_large</code></td>\n<td align=\"center\">512</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>use_transformer_lite</code></td>\n<td align=\"center\">512</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\">:seven:</td>\n<td align=\"left\"><strong>word2vec</strong></td>\n<td align=\"center\"><code>google_news_300</code></td>\n<td align=\"center\">300</td>\n<td><a href=\"https://arxiv.org/abs/1301.3781\" rel=\"nofollow\"> Read Paper :bookmark:  </a></td>\n</tr>\n<tr>\n<td align=\"left\">:eight:</td>\n<td align=\"left\"><strong>fasttext</strong></td>\n<td align=\"center\"><code>wiki_news_300</code></td>\n<td align=\"center\">300</td>\n<td><a href=\"https://arxiv.org/abs/1607.01759\" rel=\"nofollow\"> Read Paper :bookmark: </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>wiki_news_300_sub</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>common_crawl_300</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>common_crawl_300_sub</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\">:nine:</td>\n<td align=\"left\"><strong>glove</strong></td>\n<td align=\"center\"><code>twitter_200</code></td>\n<td align=\"center\">200</td>\n<td><a href=\"https://nlp.stanford.edu/pubs/glove.pdf\" rel=\"nofollow\"> Read Paper :bookmark:  </a></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>twitter_100</code></td>\n<td align=\"center\">100</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>twitter_50</code></td>\n<td align=\"center\">50</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>twitter_25</code></td>\n<td align=\"center\">25</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>wiki_300</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>wiki_200</code></td>\n<td align=\"center\">200</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>wiki_100</code></td>\n<td align=\"center\">100</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>wiki_50</code></td>\n<td align=\"center\">50</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>crawl_42B_300</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr>\n<tr>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"center\"><code>crawl_840B_300</code></td>\n<td align=\"center\">300</td>\n<td></td>\n</tr></tbody></table>\n<h2>Credits</h2>\n<p>This software uses the following open source packages:</p>\n<ul>\n<li><a href=\"https://github.com/zihangdai/xlnet\" rel=\"nofollow\">XLnet</a></li>\n<li><a href=\"https://www.tensorflow.org/hub\" rel=\"nofollow\">tensorflow-hub</a></li>\n</ul>\n<h2>Contributors \u2728</h2>\n<p>Thanks goes to these wonderful people (<a href=\"https://allcontributors.org/docs/en/emoji-key\" rel=\"nofollow\">emoji key</a>):</p>\n\n\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/aman-srivastava-a8bb1285/\" rel=\"nofollow\"><img alt=\"Aman Srivastava\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0d3407f9efd88e32a703d33e59ac4a2abfeeb315/68747470733a2f2f61766174617273302e67697468756275736572636f6e74656e742e636f6d2f752f353935303339383f763d34\" width=\"100px;\"><br><sub><b>Aman Srivastava</b></sub></a><br><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=amansrivastava17\" rel=\"nofollow\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=amansrivastava17\" rel=\"nofollow\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-amansrivastava17\" rel=\"nofollow\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://github.com/ashutoshsingh0223\" rel=\"nofollow\"><img alt=\"Ashutosh Singh\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/568cdb6aed16863658fa7de199a6344831a7e467/68747470733a2f2f61766174617273332e67697468756275736572636f6e74656e742e636f6d2f752f34303630343534343f763d34\" width=\"100px;\"><br><sub><b>Ashutosh Singh</b></sub></a><br><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=ashutoshsingh0223\" rel=\"nofollow\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=ashutoshsingh0223\" rel=\"nofollow\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-ashutoshsingh0223\" rel=\"nofollow\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://chiragjn.github.io\" rel=\"nofollow\"><img alt=\"Chirag Jain\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a2f8c579e35426f3f45c69b8fc390c3726cccb36/68747470733a2f2f61766174617273322e67697468756275736572636f6e74656e742e636f6d2f752f31303239353431383f763d34\" width=\"100px;\"><br><sub><b>Chirag Jain</b></sub></a><br><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=chiragjn\" rel=\"nofollow\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=chiragjn\" rel=\"nofollow\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-chiragjn\" rel=\"nofollow\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n    <td align=\"center\"><a href=\"https://github.com/MrPranav101\" rel=\"nofollow\"><img alt=\"MrPranav101\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a536456fc2d5e85bd8badafd96c8b202fbe93e3e/68747470733a2f2f61766174617273302e67697468756275736572636f6e74656e742e636f6d2f752f34333931343339323f763d34\" width=\"100px;\"><br><sub><b>MrPranav101</b></sub></a><br><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=MrPranav101\" rel=\"nofollow\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=MrPranav101\" rel=\"nofollow\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-MrPranav101\" rel=\"nofollow\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>    \n    <td align=\"center\"><a href=\"https://www.linkedin.com/in/dhavaltaunk08/\" rel=\"nofollow\"><img alt=\"Dhaval Taunk\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/13698d60249b39df588ed7b1606b4529345f93c8/68747470733a2f2f61766174617273302e67697468756275736572636f6e74656e742e636f6d2f752f33313332303833333f763d34\" width=\"100px;\"><br><sub><b>Dhaval Taunk</b></sub></a><br><a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=DhavalTaunk08\" rel=\"nofollow\" title=\"Code\">\ud83d\udcbb</a> <a href=\"https://github.com/amansrivastava17/embedding-as-service/commits?author=DhavalTaunk08\" rel=\"nofollow\" title=\"Documentation\">\ud83d\udcd6</a> <a href=\"#infra-DhavalTaunk08\" rel=\"nofollow\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">\ud83d\ude87</a></td>\n  </tr>\n</table>\n\n<p>This project follows the <a href=\"https://github.com/all-contributors/all-contributors\" rel=\"nofollow\">all-contributors</a> specification. Contributions of any kind welcome!</p>\n<p>Please read the <a href=\"CONTRIBUTION.md\" rel=\"nofollow\">contribution guidelines</a> first.</p>\n<h2>Citing</h2>\n<p align=\"right\"><a href=\"#embedding-as-service\" rel=\"nofollow\"><sup>\u25b4 Back to top</sup></a></p>\n<p>If you use embedding-as-service in a scientific publication, we would appreciate references to the following BibTex entry:</p>\n<pre>@misc<span class=\"nb\">{</span>aman2019embeddingservice,\n  title=<span class=\"nb\">{</span>embedding-as-service<span class=\"nb\">}</span>,\n  author=<span class=\"nb\">{</span>Srivastava, Aman<span class=\"nb\">}</span>,\n  howpublished=<span class=\"nb\">{</span><span class=\"k\">\\url</span><span class=\"nb\">{</span>https://github.com/amansrivastava17/embedding-as-service<span class=\"nb\">}}</span>,\n  year=<span class=\"nb\">{</span>2019<span class=\"nb\">}</span>\n<span class=\"nb\">}</span>\n</pre>\n\n          </div>"}, "last_serial": 6427692, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "05186aa5e78d61de8c545d2c2757b0a6", "sha256": "99849bcbf4f7de42b63c582661beaafcae243023ad1514e81ef33870fbb8b929"}, "downloads": -1, "filename": "embedding_as_service_client-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "05186aa5e78d61de8c545d2c2757b0a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 6935, "upload_time": "2020-01-10T06:43:09", "upload_time_iso_8601": "2020-01-10T06:43:09.097396Z", "url": "https://files.pythonhosted.org/packages/7e/38/8b6bcc113fab4cbada63958994f390962b032e093d62133e2d79d2279649/embedding_as_service_client-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "31084d246f268798ca58b27db51587df", "sha256": "ea54bbc920121467badde13523073634c9287af080329d71518583c4c96eed20"}, "downloads": -1, "filename": "embedding_as_service_client-1.0.0.tar.gz", "has_sig": false, "md5_digest": "31084d246f268798ca58b27db51587df", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8623, "upload_time": "2020-01-10T06:43:12", "upload_time_iso_8601": "2020-01-10T06:43:12.292875Z", "url": "https://files.pythonhosted.org/packages/2e/3b/9be440daead1a0d4d42dd39d91357451fb3750035aec05f33b4af5be8ccf/embedding_as_service_client-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "05186aa5e78d61de8c545d2c2757b0a6", "sha256": "99849bcbf4f7de42b63c582661beaafcae243023ad1514e81ef33870fbb8b929"}, "downloads": -1, "filename": "embedding_as_service_client-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "05186aa5e78d61de8c545d2c2757b0a6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 6935, "upload_time": "2020-01-10T06:43:09", "upload_time_iso_8601": "2020-01-10T06:43:09.097396Z", "url": "https://files.pythonhosted.org/packages/7e/38/8b6bcc113fab4cbada63958994f390962b032e093d62133e2d79d2279649/embedding_as_service_client-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "31084d246f268798ca58b27db51587df", "sha256": "ea54bbc920121467badde13523073634c9287af080329d71518583c4c96eed20"}, "downloads": -1, "filename": "embedding_as_service_client-1.0.0.tar.gz", "has_sig": false, "md5_digest": "31084d246f268798ca58b27db51587df", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 8623, "upload_time": "2020-01-10T06:43:12", "upload_time_iso_8601": "2020-01-10T06:43:12.292875Z", "url": "https://files.pythonhosted.org/packages/2e/3b/9be440daead1a0d4d42dd39d91357451fb3750035aec05f33b4af5be8ccf/embedding_as_service_client-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:41 2020"}