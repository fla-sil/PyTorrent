{"info": {"author": "Carl Cheung", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python", "Programming Language :: Python :: 3"], "description": "# Kafka RPC\n\n---\n\n## Introduction\n\nKafka RPC, a RPC protocol that based on [kafka](https://kafka.apache.org/), is meant to provide a swift, stable, reliable remote calling service.\n\nThe reason we love about kafka is its fault tolerance, scalability and wicked large throughput.\n\nSo if you want a RPC service with kafka features, kRPC is the kind of tool you're looking for.\n\n---\n\n### Installation\n\n        pip install kafka-rpc\n\n---\n\n### FAQ\n\n1. What is [RPC](https://en.wikipedia.org/wiki/Remote_procedure_call)?\n\n   RPC is a request\u2013response protocol. An RPC is initiated by the client, which sends a request message to a known remote server to execute a specified procedure with supplied parameters.\n\n   The one that posts the job request is called Client, while the other one that gets the job and responses is called Server.\n\n2. When should I use a RPC?\n\n   When you have to call a function that doesn't belong to local process or computer, but you don't want to build up another complex network framework just to implement restful api or soap, etc.\n   RPC is much faster than restful api and easier to use. This is only a very few lines of code to be adjusted to implement a RPC service.\n\n3. Why [kafka-rpc](https://github.com/zylo117/kafka-rpc/), not the other RPC protocols like [zerorpc](https://github.com/0rpc/zerorpc-python), [grpc](https://github.com/grpc/grpc), [mprpc](https://github.com/studio-ousia/mprpc)?\n\n   Here is the comparison.\n\n   | RPC                                               | MiddleWare | Serialization | Speed(QPS) |                                     Features                                     |\n   | ------------------------------------------------- | :--------: | :-----------: | :--------: | :------------------------------------------------------------------------------: |\n   | [kafka-rpc](https://github.com/zylo117/kafka-rpc/)          |   kafka    |    msgpack    |    200+ (sync) 4700+(async)     | dynamic load rebalance, large throughput, data persistence, faster serialization |\n   | [zerorpc](https://github.com/0rpc/zerorpc-python) |   zeromq   |    msgpack    |    450+    |  dynamic load rebalance(failed when all server are busy), faster serialization   |\n   | [grpc](https://github.com/grpc/grpc)              |  unknown   |   protobuf    | not tested |       dynamic load rebalance, large throughput, support only function rpc        |\n   | [mprpc](https://github.com/studio-ousia/mprpc)    |     no     |    msgpack    |   19000+   |                                    lightspeed                                    |\n\n    Benchmark enviroment:\n\n    Ubuntu 19.10 x64 (5.3.0-21-generic)\n\n    Intel i5-8400\n\n    ---\n\n   The only reason that I developed kafka-rpc is that zerorpc failed me!\n\n   After months of searching and testing, zerorpc was the best rpc service I'd ever used, but it's bugged!\n   Normally, developers won't notice, because most of the time, we use RPC to post the job from one client directly to one server.\n\n   But when you develop a distributing system, you will have to post K jobs of different types from N clients to M servers.\n\n   The problem is that you don't really know which server is currently available, or right one for the job.\n\n   And that's where load balancing comes in.\n\n   Zeromq supports that, and zerorpc supports that too. In reverse proxy mode, zerorpc will post the jobs, but not sending to servers. Available servers will come looking for job actively. So the job will always be coped by the most available, therefore the most performant servers. However, sadly, zerorpc doesn't really queue up the job, so when you have no server available at all, the jobs will not wait in line but instead, be abandoned.\n\n   That's why I need kafka. Unlike most of the MQ, kafka provides data persistence, so no more job abandon. When all servers is unavailable, the job will queue up and wait in line.\n\n   If the client crash, jobs will still be on disk (kafka features), unharmed, with replicas(can you imagine that).\n\n   Also, kafka-rpc supports dynamic scalability, servers can be always added to the cluster or be removed, so jobs will be fairly distribute to all the servers, and will be reroute to another healthy server if assigned server is down.\n\n   Despite the minor disadvantages, they are all good tool developed by great programmers, you're always welcome to contribute to their original repositories and my forked [zerorpc](https://github.com/zylo117/zerorpc-python) and [mprpc](https://github.com/zylo117/mprpc), which support numpy array.\n\n#### Next Step\n\n- [X] optimize the QPS by allow asynchronous calls considering its large throughput advantage\n- [X] use gevent instead of built-in threading to speed up and now it's 40% faster.\n- [ ] rewrite it in cython\n  \n## Usage\n\n### Assuming you already have a object and everything works, like this\n\n#### local_call.py\n\n    # Part1: define a class\n    class Sum:\n        def add(self, x, y):\n            return x + y\n\n    # Part2: instantiate a class to an object\n    s = Sum()\n\n    # Part3: call a method of the object\n    result = s.add(1, 2)  # result = 3\n\n### Then you can use RPC to run Part1 and Part2 on process1, and call Part3, the method of process 1 from process2\n\n#### kafka_rpc_server_demo.py\n\n    from kafka_rpc import KRPCServer\n\n    # Part1: define a class\n    class Sum:\n        def add(self, x, y):\n            return x + y\n\n    # Part2: instantiate a class to an object\n    s = Sum()\n\n    # assuming you kafka broker is on 0.0.0.0:9092\n    krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum')\n    krs.server_forever()\n\n#### kafka_rpc_client_demo.py\n\n    from kafka_rpc import KRPCClient\n\n    # assuming you kafka broker is on 0.0.0.0:9092\n    krc = KRPCClient('0.0.0.0:9092', topic_name='sum')\n    \n    # call method from client to server\n    result = krc.add(1, 2)\n    \n    print(result)\n    \n    krc.close()\n\n    # you can find the returned result in result['ret']\n    # result = {\n    #     'ret': 3,\n    #     'tact_time': 0.007979869842529297,  # total process time\n    #     'tact_time_server': 0.006567955017089844,  # process time on server side\n    #     'server_id': '192.168.1.x'  # client ip\n    # }\n\n## Advanced Usage\n\n1. enable server side concurrency. Respectively, multiple requests must be sent concurrently.\n    \n    #### kafka_rpc_server_concurrency_demo.py\n        \n        import time\n        from kafka_rpc import KRPCServer\n        \n        \n        # Part1: define a class\n        class Sum:\n            def add(self, x, y):\n        \n                # simulate blocking actions like I/O\n                time.sleep(0.1)\n        \n                return x + y\n        \n        \n        # Part2: instantiate a class to an object\n        s = Sum()\n        \n        # assuming you kafka broker is on 0.0.0.0:9092\n        krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', concurrent=128)\n        krs.server_forever()\n\n    #### kafka_rpc_client_async_demo.py\n\n        from concurrent.futures import ThreadPoolExecutor, as_completed\n        from kafka_rpc import KRPCClient\n        \n        pool = ThreadPoolExecutor(128)\n        \n        # assuming you kafka broker is on 0.0.0.0:9092\n        krc = KRPCClient('0.0.0.0:9092', topic_name='sum')\n        \n        # call method concurrently from client to server\n        # use pool.map if you like\n        futures = []\n        for i in range(128):\n            futures.append(pool.submit(krc.add, 1, 2, timeout=20))\n        \n        for future in as_completed(futures):\n            result = future.result()\n            print(result)\n        \n        krc.close()\n\n\n2. enable redis to speed up caching and temporarily store input/output data, by adding use_redis=True to KRPCClient, or specify redis port, db and password. But redis doesn't support async operations, it will crash, it's only faster in sync mode.\n\n        krc = KRPCClient('0.0.0.0:9092', topic_name='sum', use_redis=True, redis_port=6379, redis_db=0, redis_password='kafka_rpc.no.1')\n\n3. enhance the communication security, by adding verify=True or encrypt='whatever_password+you/want' or both to both of the client and the server.But enabling verification and encryption will have a little impact on performance.\n\n        # basic verification and encryption\n        krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', verify=True, encrypt='whatever_password+you/want')\n        krc = KRPCClient('0.0.0.0:9092', 9092, topic_name='sum', verify=True, encrypt='whatever_password+you/want')\n        \n        # advanced verification and encryption with custom hash function, input: bytes, output: bytes\n        krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', verify=True, encrypt='whatever_password+you want', verification=lambda x: sha3_224(x).hexdigest().encode())\n        krc = KRPCClient('0.0.0.0:9092', topic_name='sum', verify=True, encrypt='whatever_password+you/want', verification=lambda x: sha3_224(x).hexdigest().encode())\n\n4. use zstd to compress & decompress data\n    \n        krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', use_compression=True)\n        krc = KRPCClient('0.0.0.0:9092', 9092, topic_name='sum', use_compression=True)\n        \n### Warning\n\nIf use_redis=False, KRPCClient cannot be instantiated more than once\n\nIf use_redis=False, KRPCClient cannot be instantiated more than once\n\nIf use_redis=False, KRPCClient cannot be instantiated more than once\n\nDo you remember now?", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/zylo117/kafka-rpc", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "kafka-rpc", "package_url": "https://pypi.org/project/kafka-rpc/", "platform": "", "project_url": "https://pypi.org/project/kafka-rpc/", "project_urls": {"Homepage": "https://github.com/zylo117/kafka-rpc"}, "release_url": "https://pypi.org/project/kafka-rpc/1.0.11/", "requires_dist": null, "requires_python": "", "summary": "RPC protocol based on kafka", "version": "1.0.11", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Kafka RPC</h1>\n<hr>\n<h2>Introduction</h2>\n<p>Kafka RPC, a RPC protocol that based on <a href=\"https://kafka.apache.org/\" rel=\"nofollow\">kafka</a>, is meant to provide a swift, stable, reliable remote calling service.</p>\n<p>The reason we love about kafka is its fault tolerance, scalability and wicked large throughput.</p>\n<p>So if you want a RPC service with kafka features, kRPC is the kind of tool you're looking for.</p>\n<hr>\n<h3>Installation</h3>\n<pre><code>    pip install kafka-rpc\n</code></pre>\n<hr>\n<h3>FAQ</h3>\n<ol>\n<li>\n<p>What is <a href=\"https://en.wikipedia.org/wiki/Remote_procedure_call\" rel=\"nofollow\">RPC</a>?</p>\n<p>RPC is a request\u2013response protocol. An RPC is initiated by the client, which sends a request message to a known remote server to execute a specified procedure with supplied parameters.</p>\n<p>The one that posts the job request is called Client, while the other one that gets the job and responses is called Server.</p>\n</li>\n<li>\n<p>When should I use a RPC?</p>\n<p>When you have to call a function that doesn't belong to local process or computer, but you don't want to build up another complex network framework just to implement restful api or soap, etc.\nRPC is much faster than restful api and easier to use. This is only a very few lines of code to be adjusted to implement a RPC service.</p>\n</li>\n<li>\n<p>Why <a href=\"https://github.com/zylo117/kafka-rpc/\" rel=\"nofollow\">kafka-rpc</a>, not the other RPC protocols like <a href=\"https://github.com/0rpc/zerorpc-python\" rel=\"nofollow\">zerorpc</a>, <a href=\"https://github.com/grpc/grpc\" rel=\"nofollow\">grpc</a>, <a href=\"https://github.com/studio-ousia/mprpc\" rel=\"nofollow\">mprpc</a>?</p>\n<p>Here is the comparison.</p>\n<table>\n<thead>\n<tr>\n<th>RPC</th>\n<th align=\"center\">MiddleWare</th>\n<th align=\"center\">Serialization</th>\n<th align=\"center\">Speed(QPS)</th>\n<th align=\"center\">Features</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://github.com/zylo117/kafka-rpc/\" rel=\"nofollow\">kafka-rpc</a></td>\n<td align=\"center\">kafka</td>\n<td align=\"center\">msgpack</td>\n<td align=\"center\">200+ (sync) 4700+(async)</td>\n<td align=\"center\">dynamic load rebalance, large throughput, data persistence, faster serialization</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/0rpc/zerorpc-python\" rel=\"nofollow\">zerorpc</a></td>\n<td align=\"center\">zeromq</td>\n<td align=\"center\">msgpack</td>\n<td align=\"center\">450+</td>\n<td align=\"center\">dynamic load rebalance(failed when all server are busy), faster serialization</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/grpc/grpc\" rel=\"nofollow\">grpc</a></td>\n<td align=\"center\">unknown</td>\n<td align=\"center\">protobuf</td>\n<td align=\"center\">not tested</td>\n<td align=\"center\">dynamic load rebalance, large throughput, support only function rpc</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/studio-ousia/mprpc\" rel=\"nofollow\">mprpc</a></td>\n<td align=\"center\">no</td>\n<td align=\"center\">msgpack</td>\n<td align=\"center\">19000+</td>\n<td align=\"center\">lightspeed</td>\n</tr></tbody></table>\n<p>Benchmark enviroment:</p>\n<p>Ubuntu 19.10 x64 (5.3.0-21-generic)</p>\n<p>Intel i5-8400</p>\n<hr>\n<p>The only reason that I developed kafka-rpc is that zerorpc failed me!</p>\n<p>After months of searching and testing, zerorpc was the best rpc service I'd ever used, but it's bugged!\nNormally, developers won't notice, because most of the time, we use RPC to post the job from one client directly to one server.</p>\n<p>But when you develop a distributing system, you will have to post K jobs of different types from N clients to M servers.</p>\n<p>The problem is that you don't really know which server is currently available, or right one for the job.</p>\n<p>And that's where load balancing comes in.</p>\n<p>Zeromq supports that, and zerorpc supports that too. In reverse proxy mode, zerorpc will post the jobs, but not sending to servers. Available servers will come looking for job actively. So the job will always be coped by the most available, therefore the most performant servers. However, sadly, zerorpc doesn't really queue up the job, so when you have no server available at all, the jobs will not wait in line but instead, be abandoned.</p>\n<p>That's why I need kafka. Unlike most of the MQ, kafka provides data persistence, so no more job abandon. When all servers is unavailable, the job will queue up and wait in line.</p>\n<p>If the client crash, jobs will still be on disk (kafka features), unharmed, with replicas(can you imagine that).</p>\n<p>Also, kafka-rpc supports dynamic scalability, servers can be always added to the cluster or be removed, so jobs will be fairly distribute to all the servers, and will be reroute to another healthy server if assigned server is down.</p>\n<p>Despite the minor disadvantages, they are all good tool developed by great programmers, you're always welcome to contribute to their original repositories and my forked <a href=\"https://github.com/zylo117/zerorpc-python\" rel=\"nofollow\">zerorpc</a> and <a href=\"https://github.com/zylo117/mprpc\" rel=\"nofollow\">mprpc</a>, which support numpy array.</p>\n</li>\n</ol>\n<h4>Next Step</h4>\n<ul>\n<li>[X] optimize the QPS by allow asynchronous calls considering its large throughput advantage</li>\n<li>[X] use gevent instead of built-in threading to speed up and now it's 40% faster.</li>\n<li>[ ] rewrite it in cython</li>\n</ul>\n<h2>Usage</h2>\n<h3>Assuming you already have a object and everything works, like this</h3>\n<h4>local_call.py</h4>\n<pre><code># Part1: define a class\nclass Sum:\n    def add(self, x, y):\n        return x + y\n\n# Part2: instantiate a class to an object\ns = Sum()\n\n# Part3: call a method of the object\nresult = s.add(1, 2)  # result = 3\n</code></pre>\n<h3>Then you can use RPC to run Part1 and Part2 on process1, and call Part3, the method of process 1 from process2</h3>\n<h4>kafka_rpc_server_demo.py</h4>\n<pre><code>from kafka_rpc import KRPCServer\n\n# Part1: define a class\nclass Sum:\n    def add(self, x, y):\n        return x + y\n\n# Part2: instantiate a class to an object\ns = Sum()\n\n# assuming you kafka broker is on 0.0.0.0:9092\nkrs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum')\nkrs.server_forever()\n</code></pre>\n<h4>kafka_rpc_client_demo.py</h4>\n<pre><code>from kafka_rpc import KRPCClient\n\n# assuming you kafka broker is on 0.0.0.0:9092\nkrc = KRPCClient('0.0.0.0:9092', topic_name='sum')\n\n# call method from client to server\nresult = krc.add(1, 2)\n\nprint(result)\n\nkrc.close()\n\n# you can find the returned result in result['ret']\n# result = {\n#     'ret': 3,\n#     'tact_time': 0.007979869842529297,  # total process time\n#     'tact_time_server': 0.006567955017089844,  # process time on server side\n#     'server_id': '192.168.1.x'  # client ip\n# }\n</code></pre>\n<h2>Advanced Usage</h2>\n<ol>\n<li>\n<p>enable server side concurrency. Respectively, multiple requests must be sent concurrently.</p>\n<h4>kafka_rpc_server_concurrency_demo.py</h4>\n<pre><code> import time\n from kafka_rpc import KRPCServer\n \n \n # Part1: define a class\n class Sum:\n     def add(self, x, y):\n \n         # simulate blocking actions like I/O\n         time.sleep(0.1)\n \n         return x + y\n \n \n # Part2: instantiate a class to an object\n s = Sum()\n \n # assuming you kafka broker is on 0.0.0.0:9092\n krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', concurrent=128)\n krs.server_forever()\n</code></pre>\n<h4>kafka_rpc_client_async_demo.py</h4>\n<pre><code> from concurrent.futures import ThreadPoolExecutor, as_completed\n from kafka_rpc import KRPCClient\n \n pool = ThreadPoolExecutor(128)\n \n # assuming you kafka broker is on 0.0.0.0:9092\n krc = KRPCClient('0.0.0.0:9092', topic_name='sum')\n \n # call method concurrently from client to server\n # use pool.map if you like\n futures = []\n for i in range(128):\n     futures.append(pool.submit(krc.add, 1, 2, timeout=20))\n \n for future in as_completed(futures):\n     result = future.result()\n     print(result)\n \n krc.close()\n</code></pre>\n</li>\n<li>\n<p>enable redis to speed up caching and temporarily store input/output data, by adding use_redis=True to KRPCClient, or specify redis port, db and password. But redis doesn't support async operations, it will crash, it's only faster in sync mode.</p>\n<pre><code> krc = KRPCClient('0.0.0.0:9092', topic_name='sum', use_redis=True, redis_port=6379, redis_db=0, redis_password='kafka_rpc.no.1')\n</code></pre>\n</li>\n<li>\n<p>enhance the communication security, by adding verify=True or encrypt='whatever_password+you/want' or both to both of the client and the server.But enabling verification and encryption will have a little impact on performance.</p>\n<pre><code> # basic verification and encryption\n krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', verify=True, encrypt='whatever_password+you/want')\n krc = KRPCClient('0.0.0.0:9092', 9092, topic_name='sum', verify=True, encrypt='whatever_password+you/want')\n \n # advanced verification and encryption with custom hash function, input: bytes, output: bytes\n krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', verify=True, encrypt='whatever_password+you want', verification=lambda x: sha3_224(x).hexdigest().encode())\n krc = KRPCClient('0.0.0.0:9092', topic_name='sum', verify=True, encrypt='whatever_password+you/want', verification=lambda x: sha3_224(x).hexdigest().encode())\n</code></pre>\n</li>\n<li>\n<p>use zstd to compress &amp; decompress data</p>\n<pre><code> krs = KRPCServer('0.0.0.0:9092', handle=s, topic_name='sum', use_compression=True)\n krc = KRPCClient('0.0.0.0:9092', 9092, topic_name='sum', use_compression=True)\n</code></pre>\n</li>\n</ol>\n<h3>Warning</h3>\n<p>If use_redis=False, KRPCClient cannot be instantiated more than once</p>\n<p>If use_redis=False, KRPCClient cannot be instantiated more than once</p>\n<p>If use_redis=False, KRPCClient cannot be instantiated more than once</p>\n<p>Do you remember now?</p>\n\n          </div>"}, "last_serial": 6894495, "releases": {"1.0.11": [{"comment_text": "", "digests": {"md5": "8acffc88999acd1b9e3c580c594984ed", "sha256": "bac508cbad0b6fe790424ef03921fa3801e736061393807a091abfb88e3d48f1"}, "downloads": -1, "filename": "kafka-rpc-1.0.11.tar.gz", "has_sig": false, "md5_digest": "8acffc88999acd1b9e3c580c594984ed", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16259, "upload_time": "2020-03-27T08:31:38", "upload_time_iso_8601": "2020-03-27T08:31:38.767923Z", "url": "https://files.pythonhosted.org/packages/be/fc/fcabf4561c65138edc6fcbeed37b349cbf705f1d287815c9ce1c69bda3cb/kafka-rpc-1.0.11.tar.gz", "yanked": false}], "1.0.2": [{"comment_text": "", "digests": {"md5": "85d30f92c2080bf5f955bf660378308a", "sha256": "e12ac78cd1cd7b58424b87113248fa8de63254fd2cc715e8df9243923088f0a9"}, "downloads": -1, "filename": "kafka-rpc-1.0.2.tar.gz", "has_sig": false, "md5_digest": "85d30f92c2080bf5f955bf660378308a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12957, "upload_time": "2020-01-04T03:51:50", "upload_time_iso_8601": "2020-01-04T03:51:50.423955Z", "url": "https://files.pythonhosted.org/packages/3e/1a/1325356e312883a4604096ba4bef09461c76c5f083f5866b666a1d008495/kafka-rpc-1.0.2.tar.gz", "yanked": false}], "1.0.3": [{"comment_text": "", "digests": {"md5": "56b35b7f115d2cde1b3f78cca3bd933f", "sha256": "1ed2d7d509d8095c7234674d5f0994eccc9284d4c12484ecfb41e6bbb290e81d"}, "downloads": -1, "filename": "kafka-rpc-1.0.3.tar.gz", "has_sig": false, "md5_digest": "56b35b7f115d2cde1b3f78cca3bd933f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14025, "upload_time": "2020-01-07T09:27:43", "upload_time_iso_8601": "2020-01-07T09:27:43.034290Z", "url": "https://files.pythonhosted.org/packages/e7/16/c673c3a5c9fadc9a26e4fd045e53d8eb876fa7d89a225f32dda9823e699f/kafka-rpc-1.0.3.tar.gz", "yanked": false}], "1.0.4": [{"comment_text": "", "digests": {"md5": "39ee384d69a1cc55cfbbecbc2d2abecf", "sha256": "cdb1af7399495680487a177e717b4e932e5fafa21f79c6159fc4a7d06f95ca25"}, "downloads": -1, "filename": "kafka-rpc-1.0.4.tar.gz", "has_sig": false, "md5_digest": "39ee384d69a1cc55cfbbecbc2d2abecf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14942, "upload_time": "2020-01-08T06:23:26", "upload_time_iso_8601": "2020-01-08T06:23:26.243288Z", "url": "https://files.pythonhosted.org/packages/29/86/b91655855d6e4f720a1d6f31e7357ddd0467fee268dad097e52c3911c989/kafka-rpc-1.0.4.tar.gz", "yanked": false}], "1.0.7": [{"comment_text": "", "digests": {"md5": "7bf15fbcf640b121b4b5581a53905376", "sha256": "ea275632adbc220ebb5244ed32c7b28359c10d559bdf5c050f971fb6d0da203e"}, "downloads": -1, "filename": "kafka-rpc-1.0.7.tar.gz", "has_sig": false, "md5_digest": "7bf15fbcf640b121b4b5581a53905376", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15663, "upload_time": "2020-01-13T08:51:46", "upload_time_iso_8601": "2020-01-13T08:51:46.602137Z", "url": "https://files.pythonhosted.org/packages/2f/5f/5c82b6005bc89ffc6e6b03c2c9d45ab89f64ca48ce490f300bbdb742d899/kafka-rpc-1.0.7.tar.gz", "yanked": false}], "1.0.8": [{"comment_text": "", "digests": {"md5": "0dd482a08930bb4439ec17ce8932800b", "sha256": "e22cb4285fa8be01e01b1fe8b946f108c7bc1260a7e127fc35715c46ecc77f45"}, "downloads": -1, "filename": "kafka-rpc-1.0.8.tar.gz", "has_sig": false, "md5_digest": "0dd482a08930bb4439ec17ce8932800b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15835, "upload_time": "2020-01-16T06:44:24", "upload_time_iso_8601": "2020-01-16T06:44:24.403440Z", "url": "https://files.pythonhosted.org/packages/81/b3/1892fe6ea456a2bd57852ebe0e0820677a68f2e36f96132ba6588dd0e67d/kafka-rpc-1.0.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8acffc88999acd1b9e3c580c594984ed", "sha256": "bac508cbad0b6fe790424ef03921fa3801e736061393807a091abfb88e3d48f1"}, "downloads": -1, "filename": "kafka-rpc-1.0.11.tar.gz", "has_sig": false, "md5_digest": "8acffc88999acd1b9e3c580c594984ed", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16259, "upload_time": "2020-03-27T08:31:38", "upload_time_iso_8601": "2020-03-27T08:31:38.767923Z", "url": "https://files.pythonhosted.org/packages/be/fc/fcabf4561c65138edc6fcbeed37b349cbf705f1d287815c9ce1c69bda3cb/kafka-rpc-1.0.11.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:50 2020"}