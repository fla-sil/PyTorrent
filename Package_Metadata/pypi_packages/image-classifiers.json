{"info": {"author": "Pavel Yakubovskiy", "author_email": "qubvel@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy"], "description": "\n[![PyPI version](https://badge.fury.io/py/image-classifiers.svg)](https://badge.fury.io/py/image-classifiers) [![Build Status](https://travis-ci.com/qubvel/classification_models.svg?branch=master)](https://travis-ci.com/qubvel/classification_models) \n# Classification models Zoo - Keras (and TensorFlow Keras)\nTrained on [ImageNet](http://www.image-net.org/) classification models. \nThe library is designed to work both with [Keras](https://keras.io/) and [TensorFlow Keras](https://www.tensorflow.org/guide/keras). See example below.\n\n## Important!\nThere was a huge library update **05 of August**. Now classification-models works with both frameworks: `keras` and `tensorflow.keras`.\nIf you have models, trained before that date, to load them, please, use `image-classifiers` (PyPI package name) of 0.2.2 version. You can roll back using `pip install -U image-classifiers==0.2.2`.\n\n### Architectures: \n- [VGG](https://arxiv.org/abs/1409.1556) [16, 19]\n- [ResNet](https://arxiv.org/abs/1512.03385) [18, 34, 50, 101, 152]\n- [ResNeXt](https://arxiv.org/abs/1611.05431) [50, 101]\n- [SE-ResNet](https://arxiv.org/abs/1709.01507) [18, 34, 50, 101, 152]\n- [SE-ResNeXt](https://arxiv.org/abs/1709.01507) [50, 101]\n- [SE-Net](https://arxiv.org/abs/1709.01507) [154]\n- [DenseNet](https://arxiv.org/abs/1608.06993) [121, 169, 201]\n- [Inception ResNet V2](https://arxiv.org/abs/1602.07261)\n- [Inception V3](http://arxiv.org/abs/1512.00567)\n- [Xception](https://arxiv.org/abs/1610.02357)\n- [NASNet](https://arxiv.org/abs/1707.07012) [large, mobile]\n- [MobileNet](https://arxiv.org/pdf/1704.04861.pdf)\n- [MobileNet v2](https://arxiv.org/abs/1801.04381)\n\n### Specification \nThe top-k accuracy were obtained using center single crop on the \n2012 ILSVRC ImageNet validation set and may differ from the original ones. \nThe input size used was 224x224 (min size 256) for all models except:\n - NASNetLarge 331x331 (352)\n - InceptionV3 299x299 (324)\n - InceptionResNetV2 299x299 (324)\n - Xception 299x299 (324)  \n\nThe inference \\*Time was evaluated on 500 batches of size 16. \nAll models have been tested using same hardware and software. \nTime is listed just for comparison of performance.\n\n| Model           |Acc@1|Acc@5|Time*|Source|\n|-----------------|:---:|:---:|:---:|------|\n|vgg16            |70.79|89.74|24.95|[keras](https://github.com/keras-team/keras-applications)|\n|vgg19            |70.89|89.69|24.95|[keras](https://github.com/keras-team/keras-applications)|\n|resnet18         |68.24|88.49|16.07|[mxnet](https://github.com/Microsoft/MMdnn)|\n|resnet34         |72.17|90.74|17.37|[mxnet](https://github.com/Microsoft/MMdnn)|\n|resnet50         |74.81|92.38|22.62|[mxnet](https://github.com/Microsoft/MMdnn)|\n|resnet101        |76.58|93.10|33.03|[mxnet](https://github.com/Microsoft/MMdnn)|\n|resnet152        |76.66|93.08|42.37|[mxnet](https://github.com/Microsoft/MMdnn)|\n|resnet50v2       |69.73|89.31|19.56|[keras](https://github.com/keras-team/keras-applications)|\n|resnet101v2      |71.93|90.41|28.80|[keras](https://github.com/keras-team/keras-applications)|\n|resnet152v2      |72.29|90.61|41.09|[keras](https://github.com/keras-team/keras-applications)|\n|resnext50        |77.36|93.48|37.57|[keras](https://github.com/keras-team/keras-applications)|\n|resnext101       |78.48|94.00|60.07|[keras](https://github.com/keras-team/keras-applications)|\n|densenet121      |74.67|92.04|27.66|[keras](https://github.com/keras-team/keras-applications)|\n|densenet169      |75.85|92.93|33.71|[keras](https://github.com/keras-team/keras-applications)|\n|densenet201      |77.13|93.43|42.40|[keras](https://github.com/keras-team/keras-applications)|\n|inceptionv3      |77.55|93.48|38.94|[keras](https://github.com/keras-team/keras-applications)|\n|xception         |78.87|94.20|42.18|[keras](https://github.com/keras-team/keras-applications)|\n|inceptionresnetv2|80.03|94.89|54.77|[keras](https://github.com/keras-team/keras-applications)|\n|seresnet18       |69.41|88.84|20.19|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|seresnet34       |72.60|90.91|22.20|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|seresnet50       |76.44|93.02|23.64|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|seresnet101      |77.92|94.00|32.55|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|seresnet152      |78.34|94.08|47.88|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|seresnext50      |78.74|94.30|38.29|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|seresnext101     |79.88|94.87|62.80|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|senet154         |81.06|95.24|137.36|[pytorch](https://github.com/Cadene/pretrained-models.pytorch)|\n|nasnetlarge      |**82.12**|**95.72**|116.53|[keras](https://github.com/keras-team/keras-applications)|\n|nasnetmobile     |74.04|91.54|27.73|[keras](https://github.com/keras-team/keras-applications)|\n|mobilenet        |70.36|89.39|15.50|[keras](https://github.com/keras-team/keras-applications)|\n|mobilenetv2      |71.63|90.35|18.31|[keras](https://github.com/keras-team/keras-applications)|\n\n\n### Weights\n| Name                    |Classes   | Models    |\n|-------------------------|:--------:|:---------:|\n|'imagenet'               |1000      |all models |\n|'imagenet11k-place365ch' |11586     |resnet50   |\n|'imagenet11k'            |11221     |resnet152  |\n\n\n### Installation\n\nRequirements:\n- Keras >= 2.2.0 / TensorFlow >= 1.12\n- keras_applications >= 1.0.7\n\n###### Note\n    This library does not have TensorFlow in a requirements for installation. \n    Please, choose suitable version (\u2018cpu\u2019/\u2019gpu\u2019) and install it manually using \n    official Guide (https://www.tensorflow.org/install/).\n\nPyPI stable package:\n```bash\n$ pip install image-classifiers==0.2.2\n```\n\nPyPI latest package:\n```bash\n$ pip install image-classifiers==1.0.0b1\n```\n\nLatest version:\n```bash\n$ pip install git+https://github.com/qubvel/classification_models.git\n```\n\n### Examples \n\n##### Loading model with `imagenet` weights:\n\n```python\n# for keras\nfrom classification_models.keras import Classifiers\n\n# for tensorflow.keras\n# from classification_models.tfkeras import Classifiers\n\nResNet18, preprocess_input = Classifiers.get('resnet18')\nmodel = ResNet18((224, 224, 3), weights='imagenet')\n```\n\nThis way take one additional line of code, however if you would \nlike to train several models you do not need to import them directly, \njust access everything through `Classifiers`.\n\nYou can get all model names using `Classifiers.models_names()` method.\n\n##### Inference example:\n\n```python\nimport numpy as np\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom classification_models.keras import Classifiers\n\nResNet18, preprocess_input = Classifiers.get('resnet18')\n\n# read and prepare image\nx = imread('./imgs/tests/seagull.jpg')\nx = resize(x, (224, 224)) * 255    # cast back to 0-255 range\nx = preprocess_input(x)\nx = np.expand_dims(x, 0)\n\n# load model\nmodel = ResNet18(input_shape=(224,224,3), weights='imagenet', classes=1000)\n\n# processing image\ny = model.predict(x)\n\n# result\nprint(decode_predictions(y))\n```\n\n##### Model fine-tuning example:\n```python\nimport keras\nfrom classification_models.keras import Classifiers\n\nResNet18, preprocess_input = Classifiers.get('resnet18')\n\n# prepare your data\nX = ...\ny = ...\n\nX = preprocess_input(X)\n\nn_classes = 10\n\n# build model\nbase_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(n_classes, activation='softmax')(x)\nmodel = keras.models.Model(inputs=[base_model.input], outputs=[output])\n\n# train\nmodel.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X, y)\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/qubvel/classification_models", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "image-classifiers", "package_url": "https://pypi.org/project/image-classifiers/", "platform": "", "project_url": "https://pypi.org/project/image-classifiers/", "project_urls": {"Homepage": "https://github.com/qubvel/classification_models"}, "release_url": "https://pypi.org/project/image-classifiers/1.0.0/", "requires_dist": ["keras-applications (<=1.0.8,>=1.0.7)", "scikit-image ; extra == 'tests'", "pytest ; extra == 'tests'"], "requires_python": ">=3.0.0", "summary": "Image classification models. Keras.", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><a href=\"https://badge.fury.io/py/image-classifiers\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/27df68025315a48bf57e8dc21ddab9b8a8638655/68747470733a2f2f62616467652e667572792e696f2f70792f696d6167652d636c6173736966696572732e737667\"></a> <a href=\"https://travis-ci.com/qubvel/classification_models\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9c29b53782f4de2760e37361018c991f280e8214/68747470733a2f2f7472617669732d63692e636f6d2f71756276656c2f636c617373696669636174696f6e5f6d6f64656c732e7376673f6272616e63683d6d6173746572\"></a></p>\n<h1>Classification models Zoo - Keras (and TensorFlow Keras)</h1>\n<p>Trained on <a href=\"http://www.image-net.org/\" rel=\"nofollow\">ImageNet</a> classification models.\nThe library is designed to work both with <a href=\"https://keras.io/\" rel=\"nofollow\">Keras</a> and <a href=\"https://www.tensorflow.org/guide/keras\" rel=\"nofollow\">TensorFlow Keras</a>. See example below.</p>\n<h2>Important!</h2>\n<p>There was a huge library update <strong>05 of August</strong>. Now classification-models works with both frameworks: <code>keras</code> and <code>tensorflow.keras</code>.\nIf you have models, trained before that date, to load them, please, use <code>image-classifiers</code> (PyPI package name) of 0.2.2 version. You can roll back using <code>pip install -U image-classifiers==0.2.2</code>.</p>\n<h3>Architectures:</h3>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1409.1556\" rel=\"nofollow\">VGG</a> [16, 19]</li>\n<li><a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow\">ResNet</a> [18, 34, 50, 101, 152]</li>\n<li><a href=\"https://arxiv.org/abs/1611.05431\" rel=\"nofollow\">ResNeXt</a> [50, 101]</li>\n<li><a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">SE-ResNet</a> [18, 34, 50, 101, 152]</li>\n<li><a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">SE-ResNeXt</a> [50, 101]</li>\n<li><a href=\"https://arxiv.org/abs/1709.01507\" rel=\"nofollow\">SE-Net</a> [154]</li>\n<li><a href=\"https://arxiv.org/abs/1608.06993\" rel=\"nofollow\">DenseNet</a> [121, 169, 201]</li>\n<li><a href=\"https://arxiv.org/abs/1602.07261\" rel=\"nofollow\">Inception ResNet V2</a></li>\n<li><a href=\"http://arxiv.org/abs/1512.00567\" rel=\"nofollow\">Inception V3</a></li>\n<li><a href=\"https://arxiv.org/abs/1610.02357\" rel=\"nofollow\">Xception</a></li>\n<li><a href=\"https://arxiv.org/abs/1707.07012\" rel=\"nofollow\">NASNet</a> [large, mobile]</li>\n<li><a href=\"https://arxiv.org/pdf/1704.04861.pdf\" rel=\"nofollow\">MobileNet</a></li>\n<li><a href=\"https://arxiv.org/abs/1801.04381\" rel=\"nofollow\">MobileNet v2</a></li>\n</ul>\n<h3>Specification</h3>\n<p>The top-k accuracy were obtained using center single crop on the\n2012 ILSVRC ImageNet validation set and may differ from the original ones.\nThe input size used was 224x224 (min size 256) for all models except:</p>\n<ul>\n<li>NASNetLarge 331x331 (352)</li>\n<li>InceptionV3 299x299 (324)</li>\n<li>InceptionResNetV2 299x299 (324)</li>\n<li>Xception 299x299 (324)</li>\n</ul>\n<p>The inference *Time was evaluated on 500 batches of size 16.\nAll models have been tested using same hardware and software.\nTime is listed just for comparison of performance.</p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th align=\"center\">Acc@1</th>\n<th align=\"center\">Acc@5</th>\n<th align=\"center\">Time*</th>\n<th>Source</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>vgg16</td>\n<td align=\"center\">70.79</td>\n<td align=\"center\">89.74</td>\n<td align=\"center\">24.95</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>vgg19</td>\n<td align=\"center\">70.89</td>\n<td align=\"center\">89.69</td>\n<td align=\"center\">24.95</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>resnet18</td>\n<td align=\"center\">68.24</td>\n<td align=\"center\">88.49</td>\n<td align=\"center\">16.07</td>\n<td><a href=\"https://github.com/Microsoft/MMdnn\" rel=\"nofollow\">mxnet</a></td>\n</tr>\n<tr>\n<td>resnet34</td>\n<td align=\"center\">72.17</td>\n<td align=\"center\">90.74</td>\n<td align=\"center\">17.37</td>\n<td><a href=\"https://github.com/Microsoft/MMdnn\" rel=\"nofollow\">mxnet</a></td>\n</tr>\n<tr>\n<td>resnet50</td>\n<td align=\"center\">74.81</td>\n<td align=\"center\">92.38</td>\n<td align=\"center\">22.62</td>\n<td><a href=\"https://github.com/Microsoft/MMdnn\" rel=\"nofollow\">mxnet</a></td>\n</tr>\n<tr>\n<td>resnet101</td>\n<td align=\"center\">76.58</td>\n<td align=\"center\">93.10</td>\n<td align=\"center\">33.03</td>\n<td><a href=\"https://github.com/Microsoft/MMdnn\" rel=\"nofollow\">mxnet</a></td>\n</tr>\n<tr>\n<td>resnet152</td>\n<td align=\"center\">76.66</td>\n<td align=\"center\">93.08</td>\n<td align=\"center\">42.37</td>\n<td><a href=\"https://github.com/Microsoft/MMdnn\" rel=\"nofollow\">mxnet</a></td>\n</tr>\n<tr>\n<td>resnet50v2</td>\n<td align=\"center\">69.73</td>\n<td align=\"center\">89.31</td>\n<td align=\"center\">19.56</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>resnet101v2</td>\n<td align=\"center\">71.93</td>\n<td align=\"center\">90.41</td>\n<td align=\"center\">28.80</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>resnet152v2</td>\n<td align=\"center\">72.29</td>\n<td align=\"center\">90.61</td>\n<td align=\"center\">41.09</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>resnext50</td>\n<td align=\"center\">77.36</td>\n<td align=\"center\">93.48</td>\n<td align=\"center\">37.57</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>resnext101</td>\n<td align=\"center\">78.48</td>\n<td align=\"center\">94.00</td>\n<td align=\"center\">60.07</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>densenet121</td>\n<td align=\"center\">74.67</td>\n<td align=\"center\">92.04</td>\n<td align=\"center\">27.66</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>densenet169</td>\n<td align=\"center\">75.85</td>\n<td align=\"center\">92.93</td>\n<td align=\"center\">33.71</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>densenet201</td>\n<td align=\"center\">77.13</td>\n<td align=\"center\">93.43</td>\n<td align=\"center\">42.40</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>inceptionv3</td>\n<td align=\"center\">77.55</td>\n<td align=\"center\">93.48</td>\n<td align=\"center\">38.94</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>xception</td>\n<td align=\"center\">78.87</td>\n<td align=\"center\">94.20</td>\n<td align=\"center\">42.18</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>inceptionresnetv2</td>\n<td align=\"center\">80.03</td>\n<td align=\"center\">94.89</td>\n<td align=\"center\">54.77</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>seresnet18</td>\n<td align=\"center\">69.41</td>\n<td align=\"center\">88.84</td>\n<td align=\"center\">20.19</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>seresnet34</td>\n<td align=\"center\">72.60</td>\n<td align=\"center\">90.91</td>\n<td align=\"center\">22.20</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>seresnet50</td>\n<td align=\"center\">76.44</td>\n<td align=\"center\">93.02</td>\n<td align=\"center\">23.64</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>seresnet101</td>\n<td align=\"center\">77.92</td>\n<td align=\"center\">94.00</td>\n<td align=\"center\">32.55</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>seresnet152</td>\n<td align=\"center\">78.34</td>\n<td align=\"center\">94.08</td>\n<td align=\"center\">47.88</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>seresnext50</td>\n<td align=\"center\">78.74</td>\n<td align=\"center\">94.30</td>\n<td align=\"center\">38.29</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>seresnext101</td>\n<td align=\"center\">79.88</td>\n<td align=\"center\">94.87</td>\n<td align=\"center\">62.80</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>senet154</td>\n<td align=\"center\">81.06</td>\n<td align=\"center\">95.24</td>\n<td align=\"center\">137.36</td>\n<td><a href=\"https://github.com/Cadene/pretrained-models.pytorch\" rel=\"nofollow\">pytorch</a></td>\n</tr>\n<tr>\n<td>nasnetlarge</td>\n<td align=\"center\"><strong>82.12</strong></td>\n<td align=\"center\"><strong>95.72</strong></td>\n<td align=\"center\">116.53</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>nasnetmobile</td>\n<td align=\"center\">74.04</td>\n<td align=\"center\">91.54</td>\n<td align=\"center\">27.73</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>mobilenet</td>\n<td align=\"center\">70.36</td>\n<td align=\"center\">89.39</td>\n<td align=\"center\">15.50</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr>\n<tr>\n<td>mobilenetv2</td>\n<td align=\"center\">71.63</td>\n<td align=\"center\">90.35</td>\n<td align=\"center\">18.31</td>\n<td><a href=\"https://github.com/keras-team/keras-applications\" rel=\"nofollow\">keras</a></td>\n</tr></tbody></table>\n<h3>Weights</h3>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th align=\"center\">Classes</th>\n<th align=\"center\">Models</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>'imagenet'</td>\n<td align=\"center\">1000</td>\n<td align=\"center\">all models</td>\n</tr>\n<tr>\n<td>'imagenet11k-place365ch'</td>\n<td align=\"center\">11586</td>\n<td align=\"center\">resnet50</td>\n</tr>\n<tr>\n<td>'imagenet11k'</td>\n<td align=\"center\">11221</td>\n<td align=\"center\">resnet152</td>\n</tr></tbody></table>\n<h3>Installation</h3>\n<p>Requirements:</p>\n<ul>\n<li>Keras &gt;= 2.2.0 / TensorFlow &gt;= 1.12</li>\n<li>keras_applications &gt;= 1.0.7</li>\n</ul>\n<h6>Note</h6>\n<pre><code>This library does not have TensorFlow in a requirements for installation. \nPlease, choose suitable version (\u2018cpu\u2019/\u2019gpu\u2019) and install it manually using \nofficial Guide (https://www.tensorflow.org/install/).\n</code></pre>\n<p>PyPI stable package:</p>\n<pre>$ pip install image-classifiers<span class=\"o\">==</span><span class=\"m\">0</span>.2.2\n</pre>\n<p>PyPI latest package:</p>\n<pre>$ pip install image-classifiers<span class=\"o\">==</span><span class=\"m\">1</span>.0.0b1\n</pre>\n<p>Latest version:</p>\n<pre>$ pip install git+https://github.com/qubvel/classification_models.git\n</pre>\n<h3>Examples</h3>\n<h5>Loading model with <code>imagenet</code> weights:</h5>\n<pre><span class=\"c1\"># for keras</span>\n<span class=\"kn\">from</span> <span class=\"nn\">classification_models.keras</span> <span class=\"kn\">import</span> <span class=\"n\">Classifiers</span>\n\n<span class=\"c1\"># for tensorflow.keras</span>\n<span class=\"c1\"># from classification_models.tfkeras import Classifiers</span>\n\n<span class=\"n\">ResNet18</span><span class=\"p\">,</span> <span class=\"n\">preprocess_input</span> <span class=\"o\">=</span> <span class=\"n\">Classifiers</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'resnet18'</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ResNet18</span><span class=\"p\">((</span><span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"s1\">'imagenet'</span><span class=\"p\">)</span>\n</pre>\n<p>This way take one additional line of code, however if you would\nlike to train several models you do not need to import them directly,\njust access everything through <code>Classifiers</code>.</p>\n<p>You can get all model names using <code>Classifiers.models_names()</code> method.</p>\n<h5>Inference example:</h5>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">from</span> <span class=\"nn\">skimage.io</span> <span class=\"kn\">import</span> <span class=\"n\">imread</span>\n<span class=\"kn\">from</span> <span class=\"nn\">skimage.transform</span> <span class=\"kn\">import</span> <span class=\"n\">resize</span>\n<span class=\"kn\">from</span> <span class=\"nn\">keras.applications.imagenet_utils</span> <span class=\"kn\">import</span> <span class=\"n\">decode_predictions</span>\n<span class=\"kn\">from</span> <span class=\"nn\">classification_models.keras</span> <span class=\"kn\">import</span> <span class=\"n\">Classifiers</span>\n\n<span class=\"n\">ResNet18</span><span class=\"p\">,</span> <span class=\"n\">preprocess_input</span> <span class=\"o\">=</span> <span class=\"n\">Classifiers</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'resnet18'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># read and prepare image</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">imread</span><span class=\"p\">(</span><span class=\"s1\">'./imgs/tests/seagull.jpg'</span><span class=\"p\">)</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">resize</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">))</span> <span class=\"o\">*</span> <span class=\"mi\">255</span>    <span class=\"c1\"># cast back to 0-255 range</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">preprocess_input</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># load model</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ResNet18</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"s1\">'imagenet'</span><span class=\"p\">,</span> <span class=\"n\">classes</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># processing image</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># result</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">decode_predictions</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">))</span>\n</pre>\n<h5>Model fine-tuning example:</h5>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">keras</span>\n<span class=\"kn\">from</span> <span class=\"nn\">classification_models.keras</span> <span class=\"kn\">import</span> <span class=\"n\">Classifiers</span>\n\n<span class=\"n\">ResNet18</span><span class=\"p\">,</span> <span class=\"n\">preprocess_input</span> <span class=\"o\">=</span> <span class=\"n\">Classifiers</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'resnet18'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># prepare your data</span>\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n<span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n\n<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">preprocess_input</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n\n<span class=\"n\">n_classes</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n\n<span class=\"c1\"># build model</span>\n<span class=\"n\">base_model</span> <span class=\"o\">=</span> <span class=\"n\">ResNet18</span><span class=\"p\">(</span><span class=\"n\">input_shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">224</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">),</span> <span class=\"n\">weights</span><span class=\"o\">=</span><span class=\"s1\">'imagenet'</span><span class=\"p\">,</span> <span class=\"n\">include_top</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">GlobalAveragePooling2D</span><span class=\"p\">()(</span><span class=\"n\">base_model</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">)</span>\n<span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"n\">n_classes</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'softmax'</span><span class=\"p\">)(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">base_model</span><span class=\"o\">.</span><span class=\"n\">input</span><span class=\"p\">],</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">output</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># train</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"s1\">'SGD'</span><span class=\"p\">,</span> <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s1\">'categorical_crossentropy'</span><span class=\"p\">,</span> <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'accuracy'</span><span class=\"p\">])</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n</pre>\n\n          </div>"}, "last_serial": 5927728, "releases": {"0.1.0rc0": [{"comment_text": "", "digests": {"md5": "f2df8e3d21fb108b4072bba453ae3240", "sha256": "51eaab498a68168f6dbd85f6088cb033658226995e3e467cc465ecc45c340d36"}, "downloads": -1, "filename": "image_classifiers-0.1.0rc0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f2df8e3d21fb108b4072bba453ae3240", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.0.0", "size": 12451, "upload_time": "2018-12-21T09:41:47", "upload_time_iso_8601": "2018-12-21T09:41:47.763652Z", "url": "https://files.pythonhosted.org/packages/55/10/80588eb0b79b51d0eb31f47896e8b4f9588f0328cbb44f4abfb5e6a1b8be/image_classifiers-0.1.0rc0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ad55c2d02bcb89c57672710afa633766", "sha256": "296a81db1e02e08ce1642a1153e5c113da1a7aa73fa8f7e9da15b39d82037467"}, "downloads": -1, "filename": "image_classifiers-0.1.0rc0.tar.gz", "has_sig": false, "md5_digest": "ad55c2d02bcb89c57672710afa633766", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 8867, "upload_time": "2018-12-21T09:41:49", "upload_time_iso_8601": "2018-12-21T09:41:49.817648Z", "url": "https://files.pythonhosted.org/packages/cb/1d/64133e814e9f18c58fba4f5226ea562caca5a3c85af5e98faa919ee9b5be/image_classifiers-0.1.0rc0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "cbba207c672ee6a454a11babec6d0dba", "sha256": "89c862834da893ce64bb8728e472df3dbec2cb662d0c12ab29d9a0ff2082df90"}, "downloads": -1, "filename": "image_classifiers-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cbba207c672ee6a454a11babec6d0dba", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.0.0", "size": 76463, "upload_time": "2019-01-17T20:17:20", "upload_time_iso_8601": "2019-01-17T20:17:20.102821Z", "url": "https://files.pythonhosted.org/packages/de/32/a1e74e03f74506d1e4b46bb2732ca5a7b18ac52a36b5e3547e63537ce74c/image_classifiers-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0a902f53b558cf39b3c9b8f1b6d53797", "sha256": "2a0fffb91ea3943a7b7e198c4e207e11a71fd45776cacb3d54852d4f27706242"}, "downloads": -1, "filename": "image_classifiers-0.2.0.tar.gz", "has_sig": false, "md5_digest": "0a902f53b558cf39b3c9b8f1b6d53797", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 45948, "upload_time": "2019-01-17T20:17:21", "upload_time_iso_8601": "2019-01-17T20:17:21.935614Z", "url": "https://files.pythonhosted.org/packages/95/b5/ad75eb085acb0f4c442fc995c23c752321fe353d69abf6459990139415df/image_classifiers-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "36989e41221094f41da424034058acf4", "sha256": "f92255b2e4ab528403551495c72f6ee67bfb23f9ae609300170fda5d0322f4b7"}, "downloads": -1, "filename": "image_classifiers-0.2.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "36989e41221094f41da424034058acf4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.0.0", "size": 20680, "upload_time": "2019-04-18T10:18:44", "upload_time_iso_8601": "2019-04-18T10:18:44.753261Z", "url": "https://files.pythonhosted.org/packages/e2/8e/001d6e0af6fa062823cd183f66dd35cab7223371698fd0e6d4d4f74e3a3c/image_classifiers-0.2.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c5b2932f064273191d7aeb9ef58ab7d9", "sha256": "eb44e021a4565b6e9645e83c070cb3fc689022781eae6f65818585a90182a4b6"}, "downloads": -1, "filename": "image_classifiers-0.2.1.tar.gz", "has_sig": false, "md5_digest": "c5b2932f064273191d7aeb9ef58ab7d9", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 15869, "upload_time": "2019-04-18T10:18:46", "upload_time_iso_8601": "2019-04-18T10:18:46.298844Z", "url": "https://files.pythonhosted.org/packages/05/7f/3b834671a5cea3d6da995900ddfbdc34fcadf051a00e32180cadf79a8b48/image_classifiers-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "f29ef786f48f08fac65b5744d6113a89", "sha256": "fdd7ca9f4e6fe2b4ee2f796a7b858840ca117df226648c7e45b15ebfbcf04df6"}, "downloads": -1, "filename": "image_classifiers-0.2.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f29ef786f48f08fac65b5744d6113a89", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.0.0", "size": 72993, "upload_time": "2019-05-23T14:03:22", "upload_time_iso_8601": "2019-05-23T14:03:22.761012Z", "url": "https://files.pythonhosted.org/packages/8d/7f/31234ee4bc8243f9e8b59b827e8a61436d7269cf75936b0aecc48a08f06c/image_classifiers-0.2.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ed1dbdccc04a5573132184cf99ee29f8", "sha256": "cb6c11ff804f8472c91b960068f532ec6d80a973b1309809daf04e2313d7ad78"}, "downloads": -1, "filename": "image_classifiers-0.2.2.tar.gz", "has_sig": false, "md5_digest": "ed1dbdccc04a5573132184cf99ee29f8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 43383, "upload_time": "2019-05-23T14:03:25", "upload_time_iso_8601": "2019-05-23T14:03:25.229529Z", "url": "https://files.pythonhosted.org/packages/e7/39/03e7844d99e2a47c2f6b26d9086f393a4a115950e7de35e7f9a5bf946df1/image_classifiers-0.2.2.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "fedd8f4ef0525aa52893cfb675922739", "sha256": "6030bdfd1bc334a4e9d018e8962fbe9c8deba3257dc21c237032ff1590da2b98"}, "downloads": -1, "filename": "image_classifiers-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fedd8f4ef0525aa52893cfb675922739", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0.0", "size": 19951, "upload_time": "2019-10-04T10:27:26", "upload_time_iso_8601": "2019-10-04T10:27:26.234780Z", "url": "https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "64847c2f9807a4e656860bc6425be2e3", "sha256": "62022c0ff919d8ba5e3ffb7958b7db916e102e3e65c47c71cf8717ced43c0e4c"}, "downloads": -1, "filename": "image_classifiers-1.0.0.tar.gz", "has_sig": false, "md5_digest": "64847c2f9807a4e656860bc6425be2e3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 18195, "upload_time": "2019-10-04T10:27:28", "upload_time_iso_8601": "2019-10-04T10:27:28.193930Z", "url": "https://files.pythonhosted.org/packages/83/89/cf76a884d63477fc0e964d3494e65095272af60c48ee72b2c74b96da92c7/image_classifiers-1.0.0.tar.gz", "yanked": false}], "1.0.0b1": [{"comment_text": "", "digests": {"md5": "b33afecefd4bc07f729b8b022784baf2", "sha256": "dfd2923ddb953d067ea242950dc0c235425b1cb198e627a02026b795b71a0ab2"}, "downloads": -1, "filename": "image_classifiers-1.0.0b1.tar.gz", "has_sig": false, "md5_digest": "b33afecefd4bc07f729b8b022784baf2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 18161, "upload_time": "2019-08-06T08:39:04", "upload_time_iso_8601": "2019-08-06T08:39:04.159830Z", "url": "https://files.pythonhosted.org/packages/d0/15/c51837c7009063ab9e4d3654eb32a92838fe515023cc7862e06857c9d19b/image_classifiers-1.0.0b1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "fedd8f4ef0525aa52893cfb675922739", "sha256": "6030bdfd1bc334a4e9d018e8962fbe9c8deba3257dc21c237032ff1590da2b98"}, "downloads": -1, "filename": "image_classifiers-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "fedd8f4ef0525aa52893cfb675922739", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.0.0", "size": 19951, "upload_time": "2019-10-04T10:27:26", "upload_time_iso_8601": "2019-10-04T10:27:26.234780Z", "url": "https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "64847c2f9807a4e656860bc6425be2e3", "sha256": "62022c0ff919d8ba5e3ffb7958b7db916e102e3e65c47c71cf8717ced43c0e4c"}, "downloads": -1, "filename": "image_classifiers-1.0.0.tar.gz", "has_sig": false, "md5_digest": "64847c2f9807a4e656860bc6425be2e3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.0.0", "size": 18195, "upload_time": "2019-10-04T10:27:28", "upload_time_iso_8601": "2019-10-04T10:27:28.193930Z", "url": "https://files.pythonhosted.org/packages/83/89/cf76a884d63477fc0e964d3494e65095272af60c48ee72b2c74b96da92c7/image_classifiers-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:55 2020"}