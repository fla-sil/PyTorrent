{"info": {"author": "Shane Stephenson / metriczulu", "author_email": "stephenson.shane.a@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "# Hyperparameter TuneRs\n\n**tuneRs** is a small package for tuning hyperparameters using resampling methods instead of normal crossvalidation.  Estimating model accuracy using resampling methods is much quicker that using k-fold crossvalidation--although resampling tends to underestimate accuracy more that crossvalidation.  Resampling underestimates accuracy in a *consistent* fashion, however, which still makes it valuable for tuning hyperparameters.  Due to it's consistency, choosing hyperparameters based on aggregated samples still gets within the neighborhood of maximal while being much, much faster.  This is a package to help you get there.\n\n**GridSearchResample** uses the grid search method to optimize hyperparameters.\n\n**RandomSearchResample** uses the random search method to optimize hyperparameters.\n## Current Version is v0.57\n\nThis package is currently in the beginning stages and is very bare-bones\n\n## Installation\n\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install tuneRs.\n\n```bash\npip install tuneRs\n```\n\n## Usage\n\nBoth classes are meant to mimic the scikit-learn tuners (to a certain degree).  A simple example would be:\n\n\timport tuneRs\n\t\n\tmodel = SVC(kernel='rbf')\n\t\n\tparameters = {[\"gamma\": [0.001, 0.01, 0.1, 1.0, 10.0],\n\t\t\t\"C\": [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n\n\t# Set up for a random hyperparameter search\n\ttuner = tuneRs.RandomSearchResample(model, parameters, num_iters=300, sample_size=0.3, num_samples=12)\n\n\t# Fit the tuner\n\ttuner.fit(X_train, y_train)\n\t\n\t# Display the best parameters found\n\ttuner.best_params_\n\t\n\t# Display the aggregate resample score of the best parameters <br/>\n\ttuner.best_score_\n\t\n\t# Define our new model\n\tmodel = tuner.best_estimator_\n\t\n\t# Plot the resample accuracy distribution for the model with best hyperparameters <br/>\n\ttuner.plot_best()\n\n## Future Plans\n\nMultiple tuners are currently planned to be added.  The next one will be a Bayesian search method.  A dynamic version of grid search and random search is currently being worked on that iterates fit multiple times on increasingly small areas of the data space.\n\n## License\n\nLol", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/metriczulu/tuneRs/archive/v0.57.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/metriczulu/tuneRs", "keywords": "", "license": "None", "maintainer": "", "maintainer_email": "", "name": "tuneRs", "package_url": "https://pypi.org/project/tuneRs/", "platform": "", "project_url": "https://pypi.org/project/tuneRs/", "project_urls": {"Download": "https://github.com/metriczulu/tuneRs/archive/v0.57.tar.gz", "Homepage": "https://github.com/metriczulu/tuneRs"}, "release_url": "https://pypi.org/project/tuneRs/0.57/", "requires_dist": null, "requires_python": "", "summary": "Package for tuning hyperparameters with resampling methods", "version": "0.57", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Hyperparameter TuneRs</h1>\n<p><strong>tuneRs</strong> is a small package for tuning hyperparameters using resampling methods instead of normal crossvalidation.  Estimating model accuracy using resampling methods is much quicker that using k-fold crossvalidation--although resampling tends to underestimate accuracy more that crossvalidation.  Resampling underestimates accuracy in a <em>consistent</em> fashion, however, which still makes it valuable for tuning hyperparameters.  Due to it's consistency, choosing hyperparameters based on aggregated samples still gets within the neighborhood of maximal while being much, much faster.  This is a package to help you get there.</p>\n<p><strong>GridSearchResample</strong> uses the grid search method to optimize hyperparameters.</p>\n<p><strong>RandomSearchResample</strong> uses the random search method to optimize hyperparameters.</p>\n<h2>Current Version is v0.57</h2>\n<p>This package is currently in the beginning stages and is very bare-bones</p>\n<h2>Installation</h2>\n<p>Use the package manager <a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip</a> to install tuneRs.</p>\n<pre>pip install tuneRs\n</pre>\n<h2>Usage</h2>\n<p>Both classes are meant to mimic the scikit-learn tuners (to a certain degree).  A simple example would be:</p>\n<pre><code>import tuneRs\n\nmodel = SVC(kernel='rbf')\n\nparameters = {[\"gamma\": [0.001, 0.01, 0.1, 1.0, 10.0],\n\t\t\"C\": [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n\n# Set up for a random hyperparameter search\ntuner = tuneRs.RandomSearchResample(model, parameters, num_iters=300, sample_size=0.3, num_samples=12)\n\n# Fit the tuner\ntuner.fit(X_train, y_train)\n\n# Display the best parameters found\ntuner.best_params_\n\n# Display the aggregate resample score of the best parameters &lt;br/&gt;\ntuner.best_score_\n\n# Define our new model\nmodel = tuner.best_estimator_\n\n# Plot the resample accuracy distribution for the model with best hyperparameters &lt;br/&gt;\ntuner.plot_best()\n</code></pre>\n<h2>Future Plans</h2>\n<p>Multiple tuners are currently planned to be added.  The next one will be a Bayesian search method.  A dynamic version of grid search and random search is currently being worked on that iterates fit multiple times on increasingly small areas of the data space.</p>\n<h2>License</h2>\n<p>Lol</p>\n\n          </div>"}, "last_serial": 5877552, "releases": {"0.56": [{"comment_text": "", "digests": {"md5": "3923e90a4ad8750a0820159871f18dc2", "sha256": "d386d5e88cd1c0f9604c66c49e9b332b7dce5fe18d7c94e93c667a88191fca7a"}, "downloads": -1, "filename": "tuneRs-0.56.tar.gz", "has_sig": false, "md5_digest": "3923e90a4ad8750a0820159871f18dc2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 3799, "upload_time": "2019-09-02T20:57:34", "upload_time_iso_8601": "2019-09-02T20:57:34.362894Z", "url": "https://files.pythonhosted.org/packages/a4/28/ebed06718849c84a499ca5b7f9cac41f423d1fb3ac5a060a705eb4de91b8/tuneRs-0.56.tar.gz", "yanked": false}], "0.57": [{"comment_text": "", "digests": {"md5": "3430f7c908d09a51f296f047675fe156", "sha256": "be725a34b94e018637a8b43dd875891e663a2d7a32158dd42d92a172274c4690"}, "downloads": -1, "filename": "tuneRs-0.57.tar.gz", "has_sig": false, "md5_digest": "3430f7c908d09a51f296f047675fe156", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6192, "upload_time": "2019-09-24T01:03:53", "upload_time_iso_8601": "2019-09-24T01:03:53.071218Z", "url": "https://files.pythonhosted.org/packages/89/6d/25c06df8003e8b30ffe5b80dad8983855793ee4076d4fbd25ece3c5e5040/tuneRs-0.57.tar.gz", "yanked": false}], "0.6": [{"comment_text": "", "digests": {"md5": "5a54c1b5190c3d5dbfeb43050e40e3f7", "sha256": "4f0f129270b4bfe5926e34fe88757b08a94004b231ff0941e0da8af1541ed911"}, "downloads": -1, "filename": "tuneRs-0.6.tar.gz", "has_sig": false, "md5_digest": "5a54c1b5190c3d5dbfeb43050e40e3f7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8966, "upload_time": "2019-09-24T04:58:21", "upload_time_iso_8601": "2019-09-24T04:58:21.525672Z", "url": "https://files.pythonhosted.org/packages/ff/50/f1d0bac6abe3f0562029b4e9cf894f1793e3394babbe1c82983b5aef9661/tuneRs-0.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "3430f7c908d09a51f296f047675fe156", "sha256": "be725a34b94e018637a8b43dd875891e663a2d7a32158dd42d92a172274c4690"}, "downloads": -1, "filename": "tuneRs-0.57.tar.gz", "has_sig": false, "md5_digest": "3430f7c908d09a51f296f047675fe156", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6192, "upload_time": "2019-09-24T01:03:53", "upload_time_iso_8601": "2019-09-24T01:03:53.071218Z", "url": "https://files.pythonhosted.org/packages/89/6d/25c06df8003e8b30ffe5b80dad8983855793ee4076d4fbd25ece3c5e5040/tuneRs-0.57.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:44:45 2020"}