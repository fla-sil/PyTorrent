{"info": {"author": "Julien Cousineau", "author_email": "Julien.Cousineau@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# s3-netcdf\nS3-NetCDF is a Python library to read / write NetCDF files to S3. This library partitions large NetCDF files into smaller chunks to retrieve data from s3 cost-effectively.\n\n\n## Installation\n```bash\npip install meracan-s3netcdf\n```\n#### From local folder\n```bash\ngit clone https://github.com/meracan/s3-netcdf.git\npip install -e ./s3-netcdf\n```\n#### With conda env and testing \n```bash\nconda create -n s3netcdf python=3.8\nconda activate s3netcdf\ngit clone https://github.com/meracan/s3-netcdf.git\npip install -e ./s3-netcdf\n\n```\n\n## Methodology\n\nS3-NetCDF creates a master file \".nca\" from an input object. The input contains s3 info, metadata, dimensions, partition group, variables, etc. Data is stored in the partition files (.nc) (no data is stored in the master file).\n\nVariables need to be stored in a partition group. Each partition group has unique variable's dimensions. Multiple variables can be stored under the same partition group (if they have the same dimensions).\n\nThe maximum size of partition file (umcompressed) is set using the option input `ncSize=1.0`(MB). The size is approximative depending on the shape of the array. The partional files are automatically compressed (~100 smaller). The attribute `least_significant_digit={number}` can be added in the variable object to further reduce file size. Remember `f4` and `f8` contains 7 digits 16 digits, respectively. S3 http compression (gzip) is not used since partition files are already compressed.\n\n##### Input\nThe input for creating a master file contains s3 info, metadata, dimensions, partition group, variables, etc.\n\nMetadata attributes are stored in the `metadata` object. It is recommended to use `title`, `institution`, `source`, `history`, `references`, and `comment`.\n\nDimensions, groups and variables are stored in the `nca` object.\n\nInput JSON file needs to be converted into a python object `import json; json.loads(filePath)`. Input example to create a master file: \n```json\n{\n  \"name\":\"input1\",\n  \"cacheLocation\":\"../s3\",\n  \"localOnly\":true,\n  \"bucket\":\"merac-dev\",\n  \"cacheSize\":10.0,\n  \"ncSize\":1.0,\n  \"metadata\":{\"title\":\"title-input1\"},\n  \"nca\": {\n    \"dimensions\" : {\"npe\":3,\"nelem\":500,\"nnode\":1000,\"ntime\":2},\n    \"groups\":{\n      \"elem\":{\"dimensions\":[\"nelem\",\"npe\"],\"variables\":{\n          \"elem\":{\"type\":\"i4\", \"units\":\"\" ,\"standard_name\":\"Elements\" ,\"long_name\":\"Connectivity table (mesh elements)\"}\n        }\n      },\n      \"time\":{\"dimensions\":[\"ntime\"],\"variables\":{\n          \"time\":{\"type\":\"f8\", \"units\":\"hours since 1970-01-01 00:00:00.0\",\"calendar\":\"gregorian\" ,\"standard_name\":\"Datetime\" ,\"long_name\":\"Datetime\"}\n        }\n      },\n      \"nodes\":{\"dimensions\":[\"nnode\"],\"variables\":{\n          \"bed\":{\"type\":\"f4\", \"units\":\"m\" ,\"standard_name\":\"Bed Elevation, m\" ,\"long_name\":\"Description of data source\"},\n          \"friction\":{\"type\":\"f4\", \"units\":\"\" ,\"standard_name\":\"Bed Friction (Manning's)\" ,\"long_name\":\"Description of data source\"}\n        }\n      },\n      \"s\":{\"dimensions\":[\"ntime\",\"nnode\"],\"variables\":{\n          \"a\":{\"type\":\"f4\", \"units\":\"m\" ,\"standard_name\":\"a variable\" ,\"long_name\":\"Description of a\"}\n        }\n      },\n      \"t\":{\"dimensions\":[\"nnode\",\"ntime\"],\"variables\":{\n          \"a\":{\"type\":\"f4\", \"units\":\"m\" ,\"standard_name\":\"a variable\" ,\"long_name\":\"Description of a\"}\n        }\n      }\n    }\n  }\n}\n```\n\nThe input for opening  a master file can be simplified. As a minimum, the input file should contain `name`,`cacheLocation` and `bucket`(if using S3).Input example to open a master file:\n```json\n{\n  \"name\":\"input1\",\n  \"cacheLocation\":\"../s3\",\n  \"bucket\":\"merac-dev\",\n  \n  \"localOnly\":true,\n  \"cacheSize\":10.0,\n  \"ncSize\":1.0\n}\n```\n\n##### S3, caching and localOnly\nPartition files are saved locally (caching) while reading and writing. By default, the `cacheLocation={path}` is the current working directory. \n\nThe input option `cacheSize=1.0` defines the maximum cache size in MB. If exceeded, oldest cached partition files are removed. \n\nThe input option `localOnly=True` will ignore all S3 & caching commands. This is used for testing.\n\nThe name of the `bucket={str}` in the input if files are uploaded to S3.\n\n\n\n## Usage\n#### Basic\n```python\nfrom s3netcdf import NetCDF2D \n# Create/Open master file\nnetcdf2d=NetCDF2D(input)\n\n# Writing\nnetcdf2d[\"{groupname}\",\"{variablename}\",{...indices...}]= np.array(...)\n\n# Reading\nnetcdf2d[\"{groupname}\",\"{variablename}\",{...indices...}]\n```\nAssigning values to indexed arrays is the same as [numpy](https://docs.scipy.org/doc/numpy/user/basics.indexing.html). Note: string values was not tested.\n\n#### Commands\n```python\n# Get information inside the master file\nnetcdf2d.info()\n\n# Get group dimensional shape \nnetcdf2d.groups[\"{groupname}\"].shape\n\n# Get group dimensional partition shape\nnetcdf2d.groups[\"{groupname}\"].child\n\n# Get variable's attributes\nnetcdf2d.groups[\"{groupname}\"].attributes[\"{variablename}\")\n```\n\n#### Caching commands\n```python\n# List partition files locally\nnetcdf2d.cache.getNCs()\n\n# Clear/Delete all partition files locally\n# Warning!\nnetcdf2d.cache.clearNCs()\n\n# Delete NetCDF locally\n# Warning!\n# Delete master file and partitions files\nnetcdf2d.cache.delete()\n```\n\n\n#### S3 commands\n```python\n# List master and partition files, including metedata\nnetcdf2d.s3.list()\n\n# Clear/Delete all partition files in S3\n# Warning!\nnetcdf2d.s3.clearNCs()\n\n# Delete NetCDF in S3\n# Warning!\n# Delete master file and partitions files\nnetcdf2d.s3.delete()\n\n```\n\n## Testing\n```bash\nconda install pytest\nmkdir ../s3\npytest\n```\n\nFor developers and debugging:\n```bash\nmkdir ../s3\n\nPYTHONPATH=../s3-netcdf/ python3 test/test_netcdf2d_func.py\nPYTHONPATH=../s3-netcdf/ python3 test/test_netcdf2d1.py\nPYTHONPATH=../s3-netcdf/ python3 test/test_netcdf2d2.py\n```\n## AWS S3 Credentials\nCredentials (for example), AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION needs to be save in environment variables. For more information, check [link](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html).\n\nThe credentials needs access to `get`, `put` and `delete` (if deleting is required) to the bucket.\n\n## Performance and Benchmark\n\n\n\n## TODO\n- Revise code on the value parsing side: compare shape, value type etc, Should be in different function and not in dataWrapper.\n- Check operation when index assigning: + - * /\n\n\n- Fix bench folder and create better performance tests\n- Find optimize shape to upload\n- travis-ci and encryption keys\n- Complete documentation in code", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/meracan/s3-netcdf", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "meracan-s3netcdf", "package_url": "https://pypi.org/project/meracan-s3netcdf/", "platform": "", "project_url": "https://pypi.org/project/meracan-s3netcdf/", "project_urls": {"Homepage": "https://github.com/meracan/s3-netcdf"}, "release_url": "https://pypi.org/project/meracan-s3netcdf/0.0.2/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Create partition netcdf files on s3", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>s3-netcdf</h1>\n<p>S3-NetCDF is a Python library to read / write NetCDF files to S3. This library partitions large NetCDF files into smaller chunks to retrieve data from s3 cost-effectively.</p>\n<h2>Installation</h2>\n<pre>pip install meracan-s3netcdf\n</pre>\n<h4>From local folder</h4>\n<pre>git clone https://github.com/meracan/s3-netcdf.git\npip install -e ./s3-netcdf\n</pre>\n<h4>With conda env and testing</h4>\n<pre>conda create -n s3netcdf <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">3</span>.8\nconda activate s3netcdf\ngit clone https://github.com/meracan/s3-netcdf.git\npip install -e ./s3-netcdf\n</pre>\n<h2>Methodology</h2>\n<p>S3-NetCDF creates a master file \".nca\" from an input object. The input contains s3 info, metadata, dimensions, partition group, variables, etc. Data is stored in the partition files (.nc) (no data is stored in the master file).</p>\n<p>Variables need to be stored in a partition group. Each partition group has unique variable's dimensions. Multiple variables can be stored under the same partition group (if they have the same dimensions).</p>\n<p>The maximum size of partition file (umcompressed) is set using the option input <code>ncSize=1.0</code>(MB). The size is approximative depending on the shape of the array. The partional files are automatically compressed (~100 smaller). The attribute <code>least_significant_digit={number}</code> can be added in the variable object to further reduce file size. Remember <code>f4</code> and <code>f8</code> contains 7 digits 16 digits, respectively. S3 http compression (gzip) is not used since partition files are already compressed.</p>\n<h5>Input</h5>\n<p>The input for creating a master file contains s3 info, metadata, dimensions, partition group, variables, etc.</p>\n<p>Metadata attributes are stored in the <code>metadata</code> object. It is recommended to use <code>title</code>, <code>institution</code>, <code>source</code>, <code>history</code>, <code>references</code>, and <code>comment</code>.</p>\n<p>Dimensions, groups and variables are stored in the <code>nca</code> object.</p>\n<p>Input JSON file needs to be converted into a python object <code>import json; json.loads(filePath)</code>. Input example to create a master file:</p>\n<pre><span class=\"p\">{</span>\n  <span class=\"nt\">\"name\"</span><span class=\"p\">:</span><span class=\"s2\">\"input1\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"cacheLocation\"</span><span class=\"p\">:</span><span class=\"s2\">\"../s3\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"localOnly\"</span><span class=\"p\">:</span><span class=\"kc\">true</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"bucket\"</span><span class=\"p\">:</span><span class=\"s2\">\"merac-dev\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"cacheSize\"</span><span class=\"p\">:</span><span class=\"mf\">10.0</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"ncSize\"</span><span class=\"p\">:</span><span class=\"mf\">1.0</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"metadata\"</span><span class=\"p\">:{</span><span class=\"nt\">\"title\"</span><span class=\"p\">:</span><span class=\"s2\">\"title-input1\"</span><span class=\"p\">},</span>\n  <span class=\"nt\">\"nca\"</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"nt\">\"dimensions\"</span> <span class=\"p\">:</span> <span class=\"p\">{</span><span class=\"nt\">\"npe\"</span><span class=\"p\">:</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"nt\">\"nelem\"</span><span class=\"p\">:</span><span class=\"mi\">500</span><span class=\"p\">,</span><span class=\"nt\">\"nnode\"</span><span class=\"p\">:</span><span class=\"mi\">1000</span><span class=\"p\">,</span><span class=\"nt\">\"ntime\"</span><span class=\"p\">:</span><span class=\"mi\">2</span><span class=\"p\">},</span>\n    <span class=\"nt\">\"groups\"</span><span class=\"p\">:{</span>\n      <span class=\"nt\">\"elem\"</span><span class=\"p\">:{</span><span class=\"nt\">\"dimensions\"</span><span class=\"p\">:[</span><span class=\"s2\">\"nelem\"</span><span class=\"p\">,</span><span class=\"s2\">\"npe\"</span><span class=\"p\">],</span><span class=\"nt\">\"variables\"</span><span class=\"p\">:{</span>\n          <span class=\"nt\">\"elem\"</span><span class=\"p\">:{</span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"i4\"</span><span class=\"p\">,</span> <span class=\"nt\">\"units\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span> <span class=\"p\">,</span><span class=\"nt\">\"standard_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Elements\"</span> <span class=\"p\">,</span><span class=\"nt\">\"long_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Connectivity table (mesh elements)\"</span><span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n      <span class=\"p\">},</span>\n      <span class=\"nt\">\"time\"</span><span class=\"p\">:{</span><span class=\"nt\">\"dimensions\"</span><span class=\"p\">:[</span><span class=\"s2\">\"ntime\"</span><span class=\"p\">],</span><span class=\"nt\">\"variables\"</span><span class=\"p\">:{</span>\n          <span class=\"nt\">\"time\"</span><span class=\"p\">:{</span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"f8\"</span><span class=\"p\">,</span> <span class=\"nt\">\"units\"</span><span class=\"p\">:</span><span class=\"s2\">\"hours since 1970-01-01 00:00:00.0\"</span><span class=\"p\">,</span><span class=\"nt\">\"calendar\"</span><span class=\"p\">:</span><span class=\"s2\">\"gregorian\"</span> <span class=\"p\">,</span><span class=\"nt\">\"standard_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Datetime\"</span> <span class=\"p\">,</span><span class=\"nt\">\"long_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Datetime\"</span><span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n      <span class=\"p\">},</span>\n      <span class=\"nt\">\"nodes\"</span><span class=\"p\">:{</span><span class=\"nt\">\"dimensions\"</span><span class=\"p\">:[</span><span class=\"s2\">\"nnode\"</span><span class=\"p\">],</span><span class=\"nt\">\"variables\"</span><span class=\"p\">:{</span>\n          <span class=\"nt\">\"bed\"</span><span class=\"p\">:{</span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"f4\"</span><span class=\"p\">,</span> <span class=\"nt\">\"units\"</span><span class=\"p\">:</span><span class=\"s2\">\"m\"</span> <span class=\"p\">,</span><span class=\"nt\">\"standard_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Bed Elevation, m\"</span> <span class=\"p\">,</span><span class=\"nt\">\"long_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Description of data source\"</span><span class=\"p\">},</span>\n          <span class=\"nt\">\"friction\"</span><span class=\"p\">:{</span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"f4\"</span><span class=\"p\">,</span> <span class=\"nt\">\"units\"</span><span class=\"p\">:</span><span class=\"s2\">\"\"</span> <span class=\"p\">,</span><span class=\"nt\">\"standard_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Bed Friction (Manning's)\"</span> <span class=\"p\">,</span><span class=\"nt\">\"long_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Description of data source\"</span><span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n      <span class=\"p\">},</span>\n      <span class=\"nt\">\"s\"</span><span class=\"p\">:{</span><span class=\"nt\">\"dimensions\"</span><span class=\"p\">:[</span><span class=\"s2\">\"ntime\"</span><span class=\"p\">,</span><span class=\"s2\">\"nnode\"</span><span class=\"p\">],</span><span class=\"nt\">\"variables\"</span><span class=\"p\">:{</span>\n          <span class=\"nt\">\"a\"</span><span class=\"p\">:{</span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"f4\"</span><span class=\"p\">,</span> <span class=\"nt\">\"units\"</span><span class=\"p\">:</span><span class=\"s2\">\"m\"</span> <span class=\"p\">,</span><span class=\"nt\">\"standard_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"a variable\"</span> <span class=\"p\">,</span><span class=\"nt\">\"long_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Description of a\"</span><span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n      <span class=\"p\">},</span>\n      <span class=\"nt\">\"t\"</span><span class=\"p\">:{</span><span class=\"nt\">\"dimensions\"</span><span class=\"p\">:[</span><span class=\"s2\">\"nnode\"</span><span class=\"p\">,</span><span class=\"s2\">\"ntime\"</span><span class=\"p\">],</span><span class=\"nt\">\"variables\"</span><span class=\"p\">:{</span>\n          <span class=\"nt\">\"a\"</span><span class=\"p\">:{</span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"s2\">\"f4\"</span><span class=\"p\">,</span> <span class=\"nt\">\"units\"</span><span class=\"p\">:</span><span class=\"s2\">\"m\"</span> <span class=\"p\">,</span><span class=\"nt\">\"standard_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"a variable\"</span> <span class=\"p\">,</span><span class=\"nt\">\"long_name\"</span><span class=\"p\">:</span><span class=\"s2\">\"Description of a\"</span><span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n      <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</pre>\n<p>The input for opening  a master file can be simplified. As a minimum, the input file should contain <code>name</code>,<code>cacheLocation</code> and <code>bucket</code>(if using S3).Input example to open a master file:</p>\n<pre><span class=\"p\">{</span>\n  <span class=\"nt\">\"name\"</span><span class=\"p\">:</span><span class=\"s2\">\"input1\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"cacheLocation\"</span><span class=\"p\">:</span><span class=\"s2\">\"../s3\"</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"bucket\"</span><span class=\"p\">:</span><span class=\"s2\">\"merac-dev\"</span><span class=\"p\">,</span>\n  \n  <span class=\"nt\">\"localOnly\"</span><span class=\"p\">:</span><span class=\"kc\">true</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"cacheSize\"</span><span class=\"p\">:</span><span class=\"mf\">10.0</span><span class=\"p\">,</span>\n  <span class=\"nt\">\"ncSize\"</span><span class=\"p\">:</span><span class=\"mf\">1.0</span>\n<span class=\"p\">}</span>\n</pre>\n<h5>S3, caching and localOnly</h5>\n<p>Partition files are saved locally (caching) while reading and writing. By default, the <code>cacheLocation={path}</code> is the current working directory.</p>\n<p>The input option <code>cacheSize=1.0</code> defines the maximum cache size in MB. If exceeded, oldest cached partition files are removed.</p>\n<p>The input option <code>localOnly=True</code> will ignore all S3 &amp; caching commands. This is used for testing.</p>\n<p>The name of the <code>bucket={str}</code> in the input if files are uploaded to S3.</p>\n<h2>Usage</h2>\n<h4>Basic</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">s3netcdf</span> <span class=\"kn\">import</span> <span class=\"n\">NetCDF2D</span> \n<span class=\"c1\"># Create/Open master file</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">=</span><span class=\"n\">NetCDF2D</span><span class=\"p\">(</span><span class=\"nb\">input</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Writing</span>\n<span class=\"n\">netcdf2d</span><span class=\"p\">[</span><span class=\"s2\">\"</span><span class=\"si\">{groupname}</span><span class=\"s2\">\"</span><span class=\"p\">,</span><span class=\"s2\">\"</span><span class=\"si\">{variablename}</span><span class=\"s2\">\"</span><span class=\"p\">,{</span><span class=\"o\">...</span><span class=\"n\">indices</span><span class=\"o\">...</span><span class=\"p\">}]</span><span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Reading</span>\n<span class=\"n\">netcdf2d</span><span class=\"p\">[</span><span class=\"s2\">\"</span><span class=\"si\">{groupname}</span><span class=\"s2\">\"</span><span class=\"p\">,</span><span class=\"s2\">\"</span><span class=\"si\">{variablename}</span><span class=\"s2\">\"</span><span class=\"p\">,{</span><span class=\"o\">...</span><span class=\"n\">indices</span><span class=\"o\">...</span><span class=\"p\">}]</span>\n</pre>\n<p>Assigning values to indexed arrays is the same as <a href=\"https://docs.scipy.org/doc/numpy/user/basics.indexing.html\" rel=\"nofollow\">numpy</a>. Note: string values was not tested.</p>\n<h4>Commands</h4>\n<pre><span class=\"c1\"># Get information inside the master file</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Get group dimensional shape </span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">groups</span><span class=\"p\">[</span><span class=\"s2\">\"</span><span class=\"si\">{groupname}</span><span class=\"s2\">\"</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n\n<span class=\"c1\"># Get group dimensional partition shape</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">groups</span><span class=\"p\">[</span><span class=\"s2\">\"</span><span class=\"si\">{groupname}</span><span class=\"s2\">\"</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">child</span>\n\n<span class=\"c1\"># Get variable's attributes</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">groups</span><span class=\"p\">[</span><span class=\"s2\">\"</span><span class=\"si\">{groupname}</span><span class=\"s2\">\"</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attributes</span><span class=\"p\">[</span><span class=\"s2\">\"</span><span class=\"si\">{variablename}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre>\n<h4>Caching commands</h4>\n<pre><span class=\"c1\"># List partition files locally</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"o\">.</span><span class=\"n\">getNCs</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Clear/Delete all partition files locally</span>\n<span class=\"c1\"># Warning!</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"o\">.</span><span class=\"n\">clearNCs</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Delete NetCDF locally</span>\n<span class=\"c1\"># Warning!</span>\n<span class=\"c1\"># Delete master file and partitions files</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">cache</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">()</span>\n</pre>\n<h4>S3 commands</h4>\n<pre><span class=\"c1\"># List master and partition files, including metedata</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">list</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Clear/Delete all partition files in S3</span>\n<span class=\"c1\"># Warning!</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">clearNCs</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Delete NetCDF in S3</span>\n<span class=\"c1\"># Warning!</span>\n<span class=\"c1\"># Delete master file and partitions files</span>\n<span class=\"n\">netcdf2d</span><span class=\"o\">.</span><span class=\"n\">s3</span><span class=\"o\">.</span><span class=\"n\">delete</span><span class=\"p\">()</span>\n</pre>\n<h2>Testing</h2>\n<pre>conda install pytest\nmkdir ../s3\npytest\n</pre>\n<p>For developers and debugging:</p>\n<pre>mkdir ../s3\n\n<span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>../s3-netcdf/ python3 test/test_netcdf2d_func.py\n<span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>../s3-netcdf/ python3 test/test_netcdf2d1.py\n<span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>../s3-netcdf/ python3 test/test_netcdf2d2.py\n</pre>\n<h2>AWS S3 Credentials</h2>\n<p>Credentials (for example), AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION needs to be save in environment variables. For more information, check <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html\" rel=\"nofollow\">link</a>.</p>\n<p>The credentials needs access to <code>get</code>, <code>put</code> and <code>delete</code> (if deleting is required) to the bucket.</p>\n<h2>Performance and Benchmark</h2>\n<h2>TODO</h2>\n<ul>\n<li>\n<p>Revise code on the value parsing side: compare shape, value type etc, Should be in different function and not in dataWrapper.</p>\n</li>\n<li>\n<p>Check operation when index assigning: + - * /</p>\n</li>\n<li>\n<p>Fix bench folder and create better performance tests</p>\n</li>\n<li>\n<p>Find optimize shape to upload</p>\n</li>\n<li>\n<p>travis-ci and encryption keys</p>\n</li>\n<li>\n<p>Complete documentation in code</p>\n</li>\n</ul>\n\n          </div>"}, "last_serial": 6780792, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "234bfe05e1c152766233279d80e4c1d2", "sha256": "e340168f391e714223e3ff5cd73b920894e333f6f8cc5690102cb65648e6f6a2"}, "downloads": -1, "filename": "meracan-s3netcdf-0.0.1.tar.gz", "has_sig": false, "md5_digest": "234bfe05e1c152766233279d80e4c1d2", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15677, "upload_time": "2020-03-09T21:44:33", "upload_time_iso_8601": "2020-03-09T21:44:33.581225Z", "url": "https://files.pythonhosted.org/packages/32/f6/4fb566d0fbd5a409acd0b91a6ba5f3232f9061af4bf36cbaec184ddc65f5/meracan-s3netcdf-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "9d928014b84d23465854c1eed443a9d3", "sha256": "f08ecf7003a248b4f4e77e5504e9a8e0e74b81436cbe0da893aa631019636050"}, "downloads": -1, "filename": "meracan-s3netcdf-0.0.2.tar.gz", "has_sig": false, "md5_digest": "9d928014b84d23465854c1eed443a9d3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15656, "upload_time": "2020-03-09T21:57:01", "upload_time_iso_8601": "2020-03-09T21:57:01.611527Z", "url": "https://files.pythonhosted.org/packages/b2/e8/39f6ff58dc01a3957edccad95366922def0e3e5ed09569b256e68a6adc1b/meracan-s3netcdf-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9d928014b84d23465854c1eed443a9d3", "sha256": "f08ecf7003a248b4f4e77e5504e9a8e0e74b81436cbe0da893aa631019636050"}, "downloads": -1, "filename": "meracan-s3netcdf-0.0.2.tar.gz", "has_sig": false, "md5_digest": "9d928014b84d23465854c1eed443a9d3", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 15656, "upload_time": "2020-03-09T21:57:01", "upload_time_iso_8601": "2020-03-09T21:57:01.611527Z", "url": "https://files.pythonhosted.org/packages/b2/e8/39f6ff58dc01a3957edccad95366922def0e3e5ed09569b256e68a6adc1b/meracan-s3netcdf-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:56:15 2020"}