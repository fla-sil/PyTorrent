{"info": {"author": "Viktor Taranenko, Anton Bryzgalov", "author_email": "viktor@samsungnext.com, tony.bryzgaloff@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Plugins", "Intended Audience :: Developers", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# Airflow ClickHouse Plugin\n\nProvides `ClickHouseHook` and `ClickHouseOperator` for [Apache Airflow][airflow] \n    based on [mymarilyn/clickhouse-driver][ch-driver].\n\n# Features\n\n1. SQL queries are templated.\n2. Can run multiple SQL queries per single `ClickHouseOperator`.\n3. Result of the last query of `ClickHouseOperator` instance is pushed to XCom.\n4. Executed queries are logged in a pretty form.\n5. Uses effective native ClickHouse TCP protocol thanks to \n    [clickhouse-driver][ch-driver-docs]. Does not support HTTP protocol.\n\n# Installation\n\n`pip install -U airflow-clickhouse-plugin`\n\n# Usage\n\nSee [examples](#examples) below.\n\n## ClickHouseOperator Reference\n\nTo import `ClickHouseOperator` use:\n    `from airflow.operators.clickhouse_operator import ClickHouseOperator`\n\nSupported kwargs:\n* `sql`: templated query (if argument is a single `str`) or queries (if iterable\n    of `str`'s).\n* `clickhouse_conn_id`: connection id. Connection schema (all properties are \n    optional, defaults correspond to the default ClickHouse configuration):\n  * `host`, default: `localhost`;\n  * `port`, default: `9000` (default native ClickHouse protocol port);\n  * `database`, default: `default`;\n  * `user`, default: `default`;\n  * `password`, default: `''` (empty).\n* `parameters`: passed to clickhouse-driver [execute method][ch-driver-execute].\n  * If multiple queries are provided via `sql` then the parameters are passed to\n      _all_ of them.\n  * Parameters are _not_ templated.\n* `database`: if present, overrides database defined by connection.\n* Other kwargs (including the required `task_id`) are inherited from Airflow \n    [BaseOperator][airflow-base-op].\n\nThe result of the _last_ query is pushed to XCom.\n\n## ClickHouseHook Reference\n\nTo import `ClickHouseHook` use:\n    `from airflow.hooks.clickhouse_hook import ClickHouseHook`\n\nSupported kwargs of constructor (`__init__` method):\n* `clickhouse_conn_id`: connection id. See connection schema above.\n* `database`: if present, overrides database defined by connection.\n\nSupports all of the methods of the Airflow [BaseHook][airflow-base-hook]\n    including:\n* `get_records(sql: str, parameters: dict=None)`: returns result of the query\n    as a list of tuples. Materializes all the records in memory.\n* `get_first(sql: str, parameters: dict=None)`: returns the first row of the\n    result. Does not load the whole dataset into memory because of using\n    [execute_iter][ch-driver-execute-iter].\n* `run(sql, parameters)`: runs a single query (specified argument of type `str`)\n    or multiple queries (if iterable of `str`). `parameters` can have any form\n    supported by [execute][ch-driver-execute] method of clickhouse-driver.\n  * If single query is run then returns its result. If multiple queries are run\n      then returns the result of the last of them.\n  * If multiple queries are given then `parameters` are passed to _all_ of them.\n  * Materializes all the records in memory (uses simple `execute` but not \n      `execute_iter`).\n    * To achieve results streaming by `execute_iter` use it directly via\n        `hook.get_conn().execute_iter(\u2026)`\n        (see [execute_iter reference][ch-driver-execute-iter]).\n  * Every `run` call uses a new connection which is closed when finished.\n* `get_conn()`: returns the underlying\n    [clickhouse_driver.Client][ch-driver-client] instance.\n* `get_pandas_df` is not implemented.\n\n## Examples\n\n### ClickHouseOperator\n\n```python\nfrom airflow import DAG\nfrom airflow.operators.clickhouse_plugin import ClickHouseOperator\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.utils.dates import days_ago\n\nwith DAG(\n        dag_id='update_income_aggregate',\n        start_date=days_ago(2),\n) as dag:\n    ClickHouseOperator(\n        task_id='update_income_aggregate',\n        database='default',\n        sql=(\n            \"INSERT INTO aggregate \"\n                \"SELECT eventDt, sum(price * qty) AS income FROM sales \"\n                \"WHERE eventDt = '{{ ds }}' GROUP BY eventDt\",\n            \"OPTIMIZE TABLE aggregate ON CLUSTER {{ var.value.cluster_name }} \"\n                \"PARTITION toDate('{{ execution_date.format('%Y-%m-01') }}')\",\n            \"SELECT sum(income) FROM aggregate \"\n                \"WHERE eventDt BETWEEN \"\n                \"'{{ execution_date.start_of('month').to_date_string() }}'\"\n                \"AND '{{ execution_date.end_of('month').to_date_string() }}'\",\n            # result of the last query is pushed to XCom\n        ),\n        clickhouse_conn_id='clickhouse_test',\n    ) >> PythonOperator(\n        task_id='print_month_income',\n        provide_context=True,\n        python_callable=lambda task_instance, **_:\n            # pulling XCom value and printing it\n            print(task_instance.xcom_pull(task_ids='update_income_aggregate')),\n    )\n```\n\n### ClickHouseHook\n\n```python\nfrom airflow import DAG\nfrom airflow.hooks.clickhouse_hook import ClickHouseHook\nfrom airflow.hooks.mysql_hook import MySqlHook\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.utils.dates import days_ago\n\n\ndef mysql_to_clickhouse():\n    mysql_hook = MySqlHook()\n    ch_hook = ClickHouseHook()\n    records = mysql_hook.get_records('SELECT * FROM some_mysql_table')\n    ch_hook.run('INSERT INTO some_ch_table VALUES', records)\n\n\nwith DAG(\n        dag_id='mysql_to_clickhouse',\n        start_date=days_ago(2),\n) as dag:\n    dag >> PythonOperator(\n        task_id='mysql_to_clickhouse',\n        python_callable=mysql_to_clickhouse,\n    )\n```\n\nImportant note: don't try to insert values using \n    `ch_hook.run('INSERT INTO some_ch_table VALUES (1)')` literal form.\n    clickhouse-driver [requires][ch-driver-insert] values for `INSERT` query to\n    be provided via `parameters` due to specifics of the native ClickHouse\n    protocol.\n\n# Default connection\n\nBy default the hook and operator use `connection_id='clickhouse_default'`.\n\n# Contributors\n\n* Anton Bryzgalov, [@bryzgaloff](https://github.com/bryzgaloff)\n* Viktor Taranenko, [@viktortnk](https://github.com/viktortnk)\n\n\n[airflow]: https://airflow.apache.org/\n[ch-driver]: https://github.com/mymarilyn/clickhouse-driver\n[ch-driver-docs]: https://clickhouse-driver.readthedocs.io/en/latest/\n[ch-driver-execute]: https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#selecting-data\n[airflow-base-op]: https://airflow.apache.org/docs/stable/_api/airflow/models/baseoperator/index.html\n[airflow-base-hook]: https://airflow.apache.org/docs/stable/_api/airflow/hooks/base_hook/index.html\n[ch-driver-execute-iter]: https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#streaming-results\n[ch-driver-insert]: https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#inserting-data\n[ch-driver-client]: https://clickhouse-driver.readthedocs.io/en/latest/api.html#client\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/whisklabs/airflow-clickhouse-plugin", "keywords": "clickhouse,airflow", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "airflow-clickhouse-plugin", "package_url": "https://pypi.org/project/airflow-clickhouse-plugin/", "platform": "", "project_url": "https://pypi.org/project/airflow-clickhouse-plugin/", "project_urls": {"Homepage": "https://github.com/whisklabs/airflow-clickhouse-plugin"}, "release_url": "https://pypi.org/project/airflow-clickhouse-plugin/0.5.2/", "requires_dist": ["clickhouse-driver (==0.1.2)", "apache-airflow (==1.10.6)"], "requires_python": ">=3.6.*", "summary": "airflow-clickhouse-plugin - Airflow plugin to execute ClickHouse commands and queries", "version": "0.5.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Airflow ClickHouse Plugin</h1>\n<p>Provides <code>ClickHouseHook</code> and <code>ClickHouseOperator</code> for <a href=\"https://airflow.apache.org/\" rel=\"nofollow\">Apache Airflow</a>\nbased on <a href=\"https://github.com/mymarilyn/clickhouse-driver\" rel=\"nofollow\">mymarilyn/clickhouse-driver</a>.</p>\n<h1>Features</h1>\n<ol>\n<li>SQL queries are templated.</li>\n<li>Can run multiple SQL queries per single <code>ClickHouseOperator</code>.</li>\n<li>Result of the last query of <code>ClickHouseOperator</code> instance is pushed to XCom.</li>\n<li>Executed queries are logged in a pretty form.</li>\n<li>Uses effective native ClickHouse TCP protocol thanks to\n<a href=\"https://clickhouse-driver.readthedocs.io/en/latest/\" rel=\"nofollow\">clickhouse-driver</a>. Does not support HTTP protocol.</li>\n</ol>\n<h1>Installation</h1>\n<p><code>pip install -U airflow-clickhouse-plugin</code></p>\n<h1>Usage</h1>\n<p>See <a href=\"#examples\" rel=\"nofollow\">examples</a> below.</p>\n<h2>ClickHouseOperator Reference</h2>\n<p>To import <code>ClickHouseOperator</code> use:\n<code>from airflow.operators.clickhouse_operator import ClickHouseOperator</code></p>\n<p>Supported kwargs:</p>\n<ul>\n<li><code>sql</code>: templated query (if argument is a single <code>str</code>) or queries (if iterable\nof <code>str</code>'s).</li>\n<li><code>clickhouse_conn_id</code>: connection id. Connection schema (all properties are\noptional, defaults correspond to the default ClickHouse configuration):\n<ul>\n<li><code>host</code>, default: <code>localhost</code>;</li>\n<li><code>port</code>, default: <code>9000</code> (default native ClickHouse protocol port);</li>\n<li><code>database</code>, default: <code>default</code>;</li>\n<li><code>user</code>, default: <code>default</code>;</li>\n<li><code>password</code>, default: <code>''</code> (empty).</li>\n</ul>\n</li>\n<li><code>parameters</code>: passed to clickhouse-driver <a href=\"https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#selecting-data\" rel=\"nofollow\">execute method</a>.\n<ul>\n<li>If multiple queries are provided via <code>sql</code> then the parameters are passed to\n<em>all</em> of them.</li>\n<li>Parameters are <em>not</em> templated.</li>\n</ul>\n</li>\n<li><code>database</code>: if present, overrides database defined by connection.</li>\n<li>Other kwargs (including the required <code>task_id</code>) are inherited from Airflow\n<a href=\"https://airflow.apache.org/docs/stable/_api/airflow/models/baseoperator/index.html\" rel=\"nofollow\">BaseOperator</a>.</li>\n</ul>\n<p>The result of the <em>last</em> query is pushed to XCom.</p>\n<h2>ClickHouseHook Reference</h2>\n<p>To import <code>ClickHouseHook</code> use:\n<code>from airflow.hooks.clickhouse_hook import ClickHouseHook</code></p>\n<p>Supported kwargs of constructor (<code>__init__</code> method):</p>\n<ul>\n<li><code>clickhouse_conn_id</code>: connection id. See connection schema above.</li>\n<li><code>database</code>: if present, overrides database defined by connection.</li>\n</ul>\n<p>Supports all of the methods of the Airflow <a href=\"https://airflow.apache.org/docs/stable/_api/airflow/hooks/base_hook/index.html\" rel=\"nofollow\">BaseHook</a>\nincluding:</p>\n<ul>\n<li><code>get_records(sql: str, parameters: dict=None)</code>: returns result of the query\nas a list of tuples. Materializes all the records in memory.</li>\n<li><code>get_first(sql: str, parameters: dict=None)</code>: returns the first row of the\nresult. Does not load the whole dataset into memory because of using\n<a href=\"https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#streaming-results\" rel=\"nofollow\">execute_iter</a>.</li>\n<li><code>run(sql, parameters)</code>: runs a single query (specified argument of type <code>str</code>)\nor multiple queries (if iterable of <code>str</code>). <code>parameters</code> can have any form\nsupported by <a href=\"https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#selecting-data\" rel=\"nofollow\">execute</a> method of clickhouse-driver.\n<ul>\n<li>If single query is run then returns its result. If multiple queries are run\nthen returns the result of the last of them.</li>\n<li>If multiple queries are given then <code>parameters</code> are passed to <em>all</em> of them.</li>\n<li>Materializes all the records in memory (uses simple <code>execute</code> but not\n<code>execute_iter</code>).\n<ul>\n<li>To achieve results streaming by <code>execute_iter</code> use it directly via\n<code>hook.get_conn().execute_iter(\u2026)</code>\n(see <a href=\"https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#streaming-results\" rel=\"nofollow\">execute_iter reference</a>).</li>\n</ul>\n</li>\n<li>Every <code>run</code> call uses a new connection which is closed when finished.</li>\n</ul>\n</li>\n<li><code>get_conn()</code>: returns the underlying\n<a href=\"https://clickhouse-driver.readthedocs.io/en/latest/api.html#client\" rel=\"nofollow\">clickhouse_driver.Client</a> instance.</li>\n<li><code>get_pandas_df</code> is not implemented.</li>\n</ul>\n<h2>Examples</h2>\n<h3>ClickHouseOperator</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">airflow</span> <span class=\"kn\">import</span> <span class=\"n\">DAG</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.operators.clickhouse_plugin</span> <span class=\"kn\">import</span> <span class=\"n\">ClickHouseOperator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.operators.python_operator</span> <span class=\"kn\">import</span> <span class=\"n\">PythonOperator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.utils.dates</span> <span class=\"kn\">import</span> <span class=\"n\">days_ago</span>\n\n<span class=\"k\">with</span> <span class=\"n\">DAG</span><span class=\"p\">(</span>\n        <span class=\"n\">dag_id</span><span class=\"o\">=</span><span class=\"s1\">'update_income_aggregate'</span><span class=\"p\">,</span>\n        <span class=\"n\">start_date</span><span class=\"o\">=</span><span class=\"n\">days_ago</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span>\n<span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">dag</span><span class=\"p\">:</span>\n    <span class=\"n\">ClickHouseOperator</span><span class=\"p\">(</span>\n        <span class=\"n\">task_id</span><span class=\"o\">=</span><span class=\"s1\">'update_income_aggregate'</span><span class=\"p\">,</span>\n        <span class=\"n\">database</span><span class=\"o\">=</span><span class=\"s1\">'default'</span><span class=\"p\">,</span>\n        <span class=\"n\">sql</span><span class=\"o\">=</span><span class=\"p\">(</span>\n            <span class=\"s2\">\"INSERT INTO aggregate \"</span>\n                <span class=\"s2\">\"SELECT eventDt, sum(price * qty) AS income FROM sales \"</span>\n                <span class=\"s2\">\"WHERE eventDt = '{{ ds }}' GROUP BY eventDt\"</span><span class=\"p\">,</span>\n            <span class=\"s2\">\"OPTIMIZE TABLE aggregate ON CLUSTER {{ var.value.cluster_name }} \"</span>\n                <span class=\"s2\">\"PARTITION toDate('{{ execution_date.format('%Y-%m-01') }}')\"</span><span class=\"p\">,</span>\n            <span class=\"s2\">\"SELECT sum(income) FROM aggregate \"</span>\n                <span class=\"s2\">\"WHERE eventDt BETWEEN \"</span>\n                <span class=\"s2\">\"'{{ execution_date.start_of('month').to_date_string() }}'\"</span>\n                <span class=\"s2\">\"AND '{{ execution_date.end_of('month').to_date_string() }}'\"</span><span class=\"p\">,</span>\n            <span class=\"c1\"># result of the last query is pushed to XCom</span>\n        <span class=\"p\">),</span>\n        <span class=\"n\">clickhouse_conn_id</span><span class=\"o\">=</span><span class=\"s1\">'clickhouse_test'</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">PythonOperator</span><span class=\"p\">(</span>\n        <span class=\"n\">task_id</span><span class=\"o\">=</span><span class=\"s1\">'print_month_income'</span><span class=\"p\">,</span>\n        <span class=\"n\">provide_context</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n        <span class=\"n\">python_callable</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">task_instance</span><span class=\"p\">,</span> <span class=\"o\">**</span><span class=\"n\">_</span><span class=\"p\">:</span>\n            <span class=\"c1\"># pulling XCom value and printing it</span>\n            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">task_instance</span><span class=\"o\">.</span><span class=\"n\">xcom_pull</span><span class=\"p\">(</span><span class=\"n\">task_ids</span><span class=\"o\">=</span><span class=\"s1\">'update_income_aggregate'</span><span class=\"p\">)),</span>\n    <span class=\"p\">)</span>\n</pre>\n<h3>ClickHouseHook</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">airflow</span> <span class=\"kn\">import</span> <span class=\"n\">DAG</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.hooks.clickhouse_hook</span> <span class=\"kn\">import</span> <span class=\"n\">ClickHouseHook</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.hooks.mysql_hook</span> <span class=\"kn\">import</span> <span class=\"n\">MySqlHook</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.operators.python_operator</span> <span class=\"kn\">import</span> <span class=\"n\">PythonOperator</span>\n<span class=\"kn\">from</span> <span class=\"nn\">airflow.utils.dates</span> <span class=\"kn\">import</span> <span class=\"n\">days_ago</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">mysql_to_clickhouse</span><span class=\"p\">():</span>\n    <span class=\"n\">mysql_hook</span> <span class=\"o\">=</span> <span class=\"n\">MySqlHook</span><span class=\"p\">()</span>\n    <span class=\"n\">ch_hook</span> <span class=\"o\">=</span> <span class=\"n\">ClickHouseHook</span><span class=\"p\">()</span>\n    <span class=\"n\">records</span> <span class=\"o\">=</span> <span class=\"n\">mysql_hook</span><span class=\"o\">.</span><span class=\"n\">get_records</span><span class=\"p\">(</span><span class=\"s1\">'SELECT * FROM some_mysql_table'</span><span class=\"p\">)</span>\n    <span class=\"n\">ch_hook</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s1\">'INSERT INTO some_ch_table VALUES'</span><span class=\"p\">,</span> <span class=\"n\">records</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">with</span> <span class=\"n\">DAG</span><span class=\"p\">(</span>\n        <span class=\"n\">dag_id</span><span class=\"o\">=</span><span class=\"s1\">'mysql_to_clickhouse'</span><span class=\"p\">,</span>\n        <span class=\"n\">start_date</span><span class=\"o\">=</span><span class=\"n\">days_ago</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">),</span>\n<span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">dag</span><span class=\"p\">:</span>\n    <span class=\"n\">dag</span> <span class=\"o\">&gt;&gt;</span> <span class=\"n\">PythonOperator</span><span class=\"p\">(</span>\n        <span class=\"n\">task_id</span><span class=\"o\">=</span><span class=\"s1\">'mysql_to_clickhouse'</span><span class=\"p\">,</span>\n        <span class=\"n\">python_callable</span><span class=\"o\">=</span><span class=\"n\">mysql_to_clickhouse</span><span class=\"p\">,</span>\n    <span class=\"p\">)</span>\n</pre>\n<p>Important note: don't try to insert values using\n<code>ch_hook.run('INSERT INTO some_ch_table VALUES (1)')</code> literal form.\nclickhouse-driver <a href=\"https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#inserting-data\" rel=\"nofollow\">requires</a> values for <code>INSERT</code> query to\nbe provided via <code>parameters</code> due to specifics of the native ClickHouse\nprotocol.</p>\n<h1>Default connection</h1>\n<p>By default the hook and operator use <code>connection_id='clickhouse_default'</code>.</p>\n<h1>Contributors</h1>\n<ul>\n<li>Anton Bryzgalov, <a href=\"https://github.com/bryzgaloff\" rel=\"nofollow\">@bryzgaloff</a></li>\n<li>Viktor Taranenko, <a href=\"https://github.com/viktortnk\" rel=\"nofollow\">@viktortnk</a></li>\n</ul>\n\n          </div>"}, "last_serial": 6943253, "releases": {"0.5.0": [{"comment_text": "", "digests": {"md5": "944820a059a251343f9f0a1ad772856e", "sha256": "684455f57576cbc533412d56970f1569fa3f75ad73c34b33981a2424ae3c9c66"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "944820a059a251343f9f0a1ad772856e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.*", "size": 7393, "upload_time": "2020-03-30T09:35:52", "upload_time_iso_8601": "2020-03-30T09:35:52.281645Z", "url": "https://files.pythonhosted.org/packages/b7/0e/d62822c5e6ef38c312bc2e355420c4b2937cb846debe153989a139ce5432/airflow_clickhouse_plugin-0.5.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eaad6a1d5587278a5d2f6d40b5805740", "sha256": "9e200bf3e64e65261e64dd62a12aabe2a2c3118005bc6ee7c3c36bb31894ae36"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.0.tar.gz", "has_sig": false, "md5_digest": "eaad6a1d5587278a5d2f6d40b5805740", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.*", "size": 6046, "upload_time": "2020-03-30T09:35:54", "upload_time_iso_8601": "2020-03-30T09:35:54.392805Z", "url": "https://files.pythonhosted.org/packages/cd/c5/f493bc10ee3cfa1dcd624985a9b1a3bc49ff33c731cf638991642757af06/airflow-clickhouse-plugin-0.5.0.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "0df1dbb1bb52fd1a6c4ce844e7242f08", "sha256": "957018080ab8b9670f86108f416f090fc5b1eb046c7a065a171ed1e30bb7ccae"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0df1dbb1bb52fd1a6c4ce844e7242f08", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.*", "size": 8228, "upload_time": "2020-04-03T13:05:00", "upload_time_iso_8601": "2020-04-03T13:05:00.444177Z", "url": "https://files.pythonhosted.org/packages/2d/80/e0beda560c6358fa3ee8d36efac748a0eefa3e66b44509db71cb451b8d2f/airflow_clickhouse_plugin-0.5.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1e1c7ff5d34aa1b2263463741157803e", "sha256": "358a3241abeafd2bbf571769512a21d2fceccaf883cf56925f2f81982a63e523"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.1.tar.gz", "has_sig": false, "md5_digest": "1e1c7ff5d34aa1b2263463741157803e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 6896, "upload_time": "2020-04-03T13:05:01", "upload_time_iso_8601": "2020-04-03T13:05:01.392094Z", "url": "https://files.pythonhosted.org/packages/c1/ac/5bfb4c485742925c0b059b69160fcd49e19e717babd578d55a85715c2404/airflow-clickhouse-plugin-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "4187703c0fdd05c5df813ee76b307213", "sha256": "5ea4c2d611d66be940ba486dfa3ede8f01e26a0e6e8513d66cb60d1e52cf5d3e"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.2-py3-none-any.whl", "has_sig": false, "md5_digest": "4187703c0fdd05c5df813ee76b307213", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.*", "size": 8301, "upload_time": "2020-04-03T13:16:37", "upload_time_iso_8601": "2020-04-03T13:16:37.118591Z", "url": "https://files.pythonhosted.org/packages/2a/9f/130db071e61bc8426b5cd7f31e1cb9f7ae90edb5cf8d2048de60f0e9350c/airflow_clickhouse_plugin-0.5.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "sha256": "0d63391519fefd474acc485cbde3a6986756154dafcce6884c4dce87791696de"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.2.tar.gz", "has_sig": false, "md5_digest": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 7023, "upload_time": "2020-04-03T13:16:38", "upload_time_iso_8601": "2020-04-03T13:16:38.101857Z", "url": "https://files.pythonhosted.org/packages/ee/97/7f6cd4c87b0c3691be180fea0b693fb2cab2474b99a1ee490d59f7176452/airflow-clickhouse-plugin-0.5.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4187703c0fdd05c5df813ee76b307213", "sha256": "5ea4c2d611d66be940ba486dfa3ede8f01e26a0e6e8513d66cb60d1e52cf5d3e"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.2-py3-none-any.whl", "has_sig": false, "md5_digest": "4187703c0fdd05c5df813ee76b307213", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.*", "size": 8301, "upload_time": "2020-04-03T13:16:37", "upload_time_iso_8601": "2020-04-03T13:16:37.118591Z", "url": "https://files.pythonhosted.org/packages/2a/9f/130db071e61bc8426b5cd7f31e1cb9f7ae90edb5cf8d2048de60f0e9350c/airflow_clickhouse_plugin-0.5.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "sha256": "0d63391519fefd474acc485cbde3a6986756154dafcce6884c4dce87791696de"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.2.tar.gz", "has_sig": false, "md5_digest": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 7023, "upload_time": "2020-04-03T13:16:38", "upload_time_iso_8601": "2020-04-03T13:16:38.101857Z", "url": "https://files.pythonhosted.org/packages/ee/97/7f6cd4c87b0c3691be180fea0b693fb2cab2474b99a1ee490d59f7176452/airflow-clickhouse-plugin-0.5.2.tar.gz", "yanked": false}], "timestamp": "Thu May  7 16:20:32 2020"}