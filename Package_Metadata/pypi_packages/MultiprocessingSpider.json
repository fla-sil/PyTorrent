{"info": {"author": "Xpp", "author_email": "Xpp233@foxmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: GNU General Public License v3 (GPLv3)", "Operating System :: MacOS :: MacOS X", "Operating System :: Microsoft :: Windows :: Windows NT/2000", "Operating System :: OS Independent", "Operating System :: POSIX", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3.9", "Topic :: Internet :: WWW/HTTP", "Topic :: Software Development :: Libraries :: Application Frameworks", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# MultiprocessingSpider\n[[\u7b80\u4f53\u4e2d\u6587\u7248]](https://github.com/Xpp521/MultiprocessingSpider/blob/master/README_cn.md \"\u4e2d\u6587\u7248\")\n## Description\nMultiprocessingSpider is a simple and easy to use web crawling and web scraping framework.\n\n## Architecture\n![Architecture](https://raw.githubusercontent.com/Xpp521/Images/master/MultiprocessingSpider_Architecture.jpg)\n\n## Dependencies\n- requests\n\n## Installation\n```\npip install MultiprocessingSpider\n```\n\n## Basic Usage\n#### MultiprocessingSpider\n```python\nfrom MultiprocessingSpider.spiders import MultiprocessingSpider\nfrom MultiprocessingSpider.packages import TaskPackage, ResultPackage\n\n\nclass MyResultPackage(ResultPackage):\n    def __init__(self, prop1, prop2, sleep=True):\n        super().__init__(sleep)\n        self.prop1 = prop1\n        self.prop2 = prop2\n\n\nclass MySpider(MultiprocessingSpider):\n    start_urls = ['https://www.a.com/page1']\n\n    proxies = [\n        {\"http\": \"http://111.111.111.111:80\"},\n        {\"http\": \"http://123.123.123.123:8080\"}\n    ]\n\n    def router(self, url):\n        return self.parse\n\n    def parse(self, response):\n        # Parsing task or new page from \"response\"\n        ...\n        # Yield a task package\n        yield TaskPackage('https://www.a.com/task1')\n        ...\n        # Yield a url or a url list\n        yield 'https://www.a.com/page2'\n        ...\n        yield ['https://www.a.com/page3', 'https://www.a.com/page4']\n\n    @classmethod\n    def subprocess_handler(cls, package, sleep_time, timeout, retry):\n        url = package.url\n        # Request \"url\" and parse data\n        ...\n        # Return result package\n        return MyResultPackage('value1', 'value2')\n\n    @staticmethod\n    def process_result_package(package):\n        # Processing result package\n        if 'value1' == package.prop1:\n            return package\n        else:\n            return None\n\n\nif __name__ == '__main__':\n    s = MySpider()\n\n    # Start the spider\n    s.start()\n\n    # Block current process\n    s.join()\n\n    # Export results to csv file\n    s.to_csv('result.csv')\n\n    # Export results to json file\n    s.to_json('result.json')\n```\n#### FileSpider\n```python\nfrom MultiprocessingSpider.spiders import FileSpider\nfrom MultiprocessingSpider.packages import FilePackage\n\n\nclass MySpider(FileSpider):\n    start_urls = ['https://www.a.com/page1']\n\n    stream = True\n\n    buffer_size = 1024\n\n    overwrite = False\n\n    def router(self, url):\n        return self.parse\n\n    def parse(self, response):\n        # Parsing task or new page from \"response\"\n        ...\n        # Yield a file package\n        yield FilePackage('https://www.a.com/file.png', 'file.png')\n        ...\n        # Yield a new url or a url list\n        yield 'https://www.a.com/page2'\n        ...\n        yield ['https://www.a.com/page3', 'https://www.a.com/page4']\n\n\nif __name__ == '__main__':\n    s = MySpider()\n\n    # Add a url\n    s.add_url('https://www.a.com/page5')\n\n    # Start the spider\n    s.start()\n\n    # Block current process\n    s.join()\n```\n#### FileDownloader\n```python\nfrom MultiprocessingSpider.spiders import FileDownloader\n\n\nif __name__ == '__main__':\n    d = FileDownloader()\n\n    # Start the downloader\n    d.start()\n\n    # Add a file\n    d.add_file('https://www.a.com/file.png', 'file.png')\n\n    # Block current process\n    d.join()\n```\nMore examples \u2192 [GitHub](https://github.com/Xpp521/MultiprocessingSpider/tree/master/examples \"Examples\")\n### License\n[GPLv3.0](https://github.com/Xpp521/MultiprocessingSpider/blob/master/LICENSE.md \"License\")  \nThis is a free library, anyone is welcome to modify : )\n# Release Note\n## v1.1.2\n#### Refactor\n- Remove property \"name\" from \"FileDownloader\".\n- Complete class \"UserAgentGenerator\" in \"MultiprocessingSpider.Utils\".\n- Continue to optimize the setter method of each property. An exception will be raised if the value is invalid. \"sleep_time\" now can be set to 0.\n- Change the sleep strategy of subprocess, subprocess will sleep after receiving the task package to prevent multiple requests from being sent at the same time.\n___\n## v1.1.1\n#### Bug Fixes\n- Fix \"start_urls\" invalidation.\n___\n## v1.1.0\n#### Features\n- Add overwrite option for \"FileSpider\".\n- Add routing system. After overriding \"router\" method, you can yield a single url or a url list in your parse method.\n#### Bug Fixes\n- Fix retry message display error.\n#### Refactor\n- Optimize setter method. Now you can do this: spider.sleep_time = ' 5'.\n- Will not resend request when \"status_code\" is not between 200 and 300.\n##### a) MultiprocessingSpider\n- Rename property \"handled_url_table\" to \"handled_urls\".\n- Remove method \"parse\", add \"example_parse_method\".\n- \"User-Agent\" in \"web_headers\" is now generated randomly.\n- Change url_table parsing order, current rule: \"FIFP\" (first in first parse).\n##### b) FileDownloader\n- Remove \"add_files\" method.\n___\n## v1.0.0\n- The first version.\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/Xpp521/MultiprocessingSpider", "keywords": "crawler,spider,requests,multiprocessing", "license": "GPLv3", "maintainer": "", "maintainer_email": "", "name": "MultiprocessingSpider", "package_url": "https://pypi.org/project/MultiprocessingSpider/", "platform": "", "project_url": "https://pypi.org/project/MultiprocessingSpider/", "project_urls": {"Documentation": "https://github.com/Xpp521/MultiprocessingSpider/wiki", "Homepage": "https://github.com/Xpp521/MultiprocessingSpider", "Source": "https://github.com/Xpp521/MultiprocessingSpider", "Tracker": "https://github.com/Xpp521/MultiprocessingSpider/issues"}, "release_url": "https://pypi.org/project/MultiprocessingSpider/1.1.2/", "requires_dist": ["requests"], "requires_python": ">=3", "summary": "A multiprocessing web crawling and web scraping framework.", "version": "1.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>MultiprocessingSpider</h1>\n<p><a href=\"https://github.com/Xpp521/MultiprocessingSpider/blob/master/README_cn.md\" rel=\"nofollow\" title=\"\u4e2d\u6587\u7248\">[\u7b80\u4f53\u4e2d\u6587\u7248]</a></p>\n<h2>Description</h2>\n<p>MultiprocessingSpider is a simple and easy to use web crawling and web scraping framework.</p>\n<h2>Architecture</h2>\n<p><img alt=\"Architecture\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/813f499e37fc71b434abb4d46ba98257decd6ccd/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f5870703532312f496d616765732f6d61737465722f4d756c746970726f63657373696e675370696465725f4172636869746563747572652e6a7067\"></p>\n<h2>Dependencies</h2>\n<ul>\n<li>requests</li>\n</ul>\n<h2>Installation</h2>\n<pre><code>pip install MultiprocessingSpider\n</code></pre>\n<h2>Basic Usage</h2>\n<h4>MultiprocessingSpider</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">MultiprocessingSpider.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">MultiprocessingSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">MultiprocessingSpider.packages</span> <span class=\"kn\">import</span> <span class=\"n\">TaskPackage</span><span class=\"p\">,</span> <span class=\"n\">ResultPackage</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MyResultPackage</span><span class=\"p\">(</span><span class=\"n\">ResultPackage</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">prop1</span><span class=\"p\">,</span> <span class=\"n\">prop2</span><span class=\"p\">,</span> <span class=\"n\">sleep</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">sleep</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop1</span> <span class=\"o\">=</span> <span class=\"n\">prop1</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">prop2</span> <span class=\"o\">=</span> <span class=\"n\">prop2</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">MultiprocessingSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://www.a.com/page1'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">proxies</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n        <span class=\"p\">{</span><span class=\"s2\">\"http\"</span><span class=\"p\">:</span> <span class=\"s2\">\"http://111.111.111.111:80\"</span><span class=\"p\">},</span>\n        <span class=\"p\">{</span><span class=\"s2\">\"http\"</span><span class=\"p\">:</span> <span class=\"s2\">\"http://123.123.123.123:8080\"</span><span class=\"p\">}</span>\n    <span class=\"p\">]</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">router</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Parsing task or new page from \"response\"</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># Yield a task package</span>\n        <span class=\"k\">yield</span> <span class=\"n\">TaskPackage</span><span class=\"p\">(</span><span class=\"s1\">'https://www.a.com/task1'</span><span class=\"p\">)</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># Yield a url or a url list</span>\n        <span class=\"k\">yield</span> <span class=\"s1\">'https://www.a.com/page2'</span>\n        <span class=\"o\">...</span>\n        <span class=\"k\">yield</span> <span class=\"p\">[</span><span class=\"s1\">'https://www.a.com/page3'</span><span class=\"p\">,</span> <span class=\"s1\">'https://www.a.com/page4'</span><span class=\"p\">]</span>\n\n    <span class=\"nd\">@classmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">subprocess_handler</span><span class=\"p\">(</span><span class=\"bp\">cls</span><span class=\"p\">,</span> <span class=\"n\">package</span><span class=\"p\">,</span> <span class=\"n\">sleep_time</span><span class=\"p\">,</span> <span class=\"n\">timeout</span><span class=\"p\">,</span> <span class=\"n\">retry</span><span class=\"p\">):</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">package</span><span class=\"o\">.</span><span class=\"n\">url</span>\n        <span class=\"c1\"># Request \"url\" and parse data</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># Return result package</span>\n        <span class=\"k\">return</span> <span class=\"n\">MyResultPackage</span><span class=\"p\">(</span><span class=\"s1\">'value1'</span><span class=\"p\">,</span> <span class=\"s1\">'value2'</span><span class=\"p\">)</span>\n\n    <span class=\"nd\">@staticmethod</span>\n    <span class=\"k\">def</span> <span class=\"nf\">process_result_package</span><span class=\"p\">(</span><span class=\"n\">package</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Processing result package</span>\n        <span class=\"k\">if</span> <span class=\"s1\">'value1'</span> <span class=\"o\">==</span> <span class=\"n\">package</span><span class=\"o\">.</span><span class=\"n\">prop1</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"n\">package</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"kc\">None</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">MySpider</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Start the spider</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Block current process</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Export results to csv file</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s1\">'result.csv'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Export results to json file</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">to_json</span><span class=\"p\">(</span><span class=\"s1\">'result.json'</span><span class=\"p\">)</span>\n</pre>\n<h4>FileSpider</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">MultiprocessingSpider.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">FileSpider</span>\n<span class=\"kn\">from</span> <span class=\"nn\">MultiprocessingSpider.packages</span> <span class=\"kn\">import</span> <span class=\"n\">FilePackage</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">MySpider</span><span class=\"p\">(</span><span class=\"n\">FileSpider</span><span class=\"p\">):</span>\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s1\">'https://www.a.com/page1'</span><span class=\"p\">]</span>\n\n    <span class=\"n\">stream</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n\n    <span class=\"n\">buffer_size</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span>\n\n    <span class=\"n\">overwrite</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">router</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"p\">):</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\n        <span class=\"c1\"># Parsing task or new page from \"response\"</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># Yield a file package</span>\n        <span class=\"k\">yield</span> <span class=\"n\">FilePackage</span><span class=\"p\">(</span><span class=\"s1\">'https://www.a.com/file.png'</span><span class=\"p\">,</span> <span class=\"s1\">'file.png'</span><span class=\"p\">)</span>\n        <span class=\"o\">...</span>\n        <span class=\"c1\"># Yield a new url or a url list</span>\n        <span class=\"k\">yield</span> <span class=\"s1\">'https://www.a.com/page2'</span>\n        <span class=\"o\">...</span>\n        <span class=\"k\">yield</span> <span class=\"p\">[</span><span class=\"s1\">'https://www.a.com/page3'</span><span class=\"p\">,</span> <span class=\"s1\">'https://www.a.com/page4'</span><span class=\"p\">]</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">MySpider</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Add a url</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">add_url</span><span class=\"p\">(</span><span class=\"s1\">'https://www.a.com/page5'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Start the spider</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Block current process</span>\n    <span class=\"n\">s</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n</pre>\n<h4>FileDownloader</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">MultiprocessingSpider.spiders</span> <span class=\"kn\">import</span> <span class=\"n\">FileDownloader</span>\n\n\n<span class=\"k\">if</span> <span class=\"vm\">__name__</span> <span class=\"o\">==</span> <span class=\"s1\">'__main__'</span><span class=\"p\">:</span>\n    <span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"n\">FileDownloader</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Start the downloader</span>\n    <span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># Add a file</span>\n    <span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">add_file</span><span class=\"p\">(</span><span class=\"s1\">'https://www.a.com/file.png'</span><span class=\"p\">,</span> <span class=\"s1\">'file.png'</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Block current process</span>\n    <span class=\"n\">d</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">()</span>\n</pre>\n<p>More examples \u2192 <a href=\"https://github.com/Xpp521/MultiprocessingSpider/tree/master/examples\" rel=\"nofollow\" title=\"Examples\">GitHub</a></p>\n<h3>License</h3>\n<p><a href=\"https://github.com/Xpp521/MultiprocessingSpider/blob/master/LICENSE.md\" rel=\"nofollow\" title=\"License\">GPLv3.0</a><br>\nThis is a free library, anyone is welcome to modify : )</p>\n<h1>Release Note</h1>\n<h2>v1.1.2</h2>\n<h4>Refactor</h4>\n<ul>\n<li>Remove property \"name\" from \"FileDownloader\".</li>\n<li>Complete class \"UserAgentGenerator\" in \"MultiprocessingSpider.Utils\".</li>\n<li>Continue to optimize the setter method of each property. An exception will be raised if the value is invalid. \"sleep_time\" now can be set to 0.</li>\n<li>Change the sleep strategy of subprocess, subprocess will sleep after receiving the task package to prevent multiple requests from being sent at the same time.</li>\n</ul>\n<hr>\n<h2>v1.1.1</h2>\n<h4>Bug Fixes</h4>\n<ul>\n<li>Fix \"start_urls\" invalidation.</li>\n</ul>\n<hr>\n<h2>v1.1.0</h2>\n<h4>Features</h4>\n<ul>\n<li>Add overwrite option for \"FileSpider\".</li>\n<li>Add routing system. After overriding \"router\" method, you can yield a single url or a url list in your parse method.</li>\n</ul>\n<h4>Bug Fixes</h4>\n<ul>\n<li>Fix retry message display error.</li>\n</ul>\n<h4>Refactor</h4>\n<ul>\n<li>Optimize setter method. Now you can do this: spider.sleep_time = ' 5'.</li>\n<li>Will not resend request when \"status_code\" is not between 200 and 300.</li>\n</ul>\n<h5>a) MultiprocessingSpider</h5>\n<ul>\n<li>Rename property \"handled_url_table\" to \"handled_urls\".</li>\n<li>Remove method \"parse\", add \"example_parse_method\".</li>\n<li>\"User-Agent\" in \"web_headers\" is now generated randomly.</li>\n<li>Change url_table parsing order, current rule: \"FIFP\" (first in first parse).</li>\n</ul>\n<h5>b) FileDownloader</h5>\n<ul>\n<li>Remove \"add_files\" method.</li>\n</ul>\n<hr>\n<h2>v1.0.0</h2>\n<ul>\n<li>The first version.</li>\n</ul>\n\n          </div>"}, "last_serial": 6947966, "releases": {"1.0.0": [{"comment_text": "", "digests": {"md5": "107cd081188e6864882a9fa2b8390ef2", "sha256": "654689712cfb08bd8ad9019f5c60194b5dcb6d9b23e8237edaac31f98381fdf7"}, "downloads": -1, "filename": "MultiprocessingSpider-1.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "107cd081188e6864882a9fa2b8390ef2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 24853, "upload_time": "2020-02-26T12:00:03", "upload_time_iso_8601": "2020-02-26T12:00:03.971340Z", "url": "https://files.pythonhosted.org/packages/d5/00/477120d46fa374f0fe585c9d9a70983eeec9f0a5fda0f2b798cef1772deb/MultiprocessingSpider-1.0.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e912c81324b0c1edb70fd3d31b2a9ef8", "sha256": "f32444a1fb5b6f306080e0b452898aef8f55f5096213ebb83935d92d594876a3"}, "downloads": -1, "filename": "MultiprocessingSpider-1.0.0.tar.gz", "has_sig": false, "md5_digest": "e912c81324b0c1edb70fd3d31b2a9ef8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 22345, "upload_time": "2020-02-26T12:00:13", "upload_time_iso_8601": "2020-02-26T12:00:13.358019Z", "url": "https://files.pythonhosted.org/packages/66/3f/4a976cf4f3b68e8135d2fe85ab2bb9e98fdbba9bccbf5e697f53ff384feb/MultiprocessingSpider-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "443a661df9f40144f8063fa4c48975c0", "sha256": "a3672c2548085fc76891e58004fa531e49a6d8405233ac951992b3252938d50b"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "443a661df9f40144f8063fa4c48975c0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 24956, "upload_time": "2020-03-19T12:19:11", "upload_time_iso_8601": "2020-03-19T12:19:11.802646Z", "url": "https://files.pythonhosted.org/packages/ef/a7/c86e7a5dedac1de08f50b7c6141072a2396837fe846e7f67500d1124ee62/MultiprocessingSpider-1.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8f5b9f7a243b95eab52a6132f83090c7", "sha256": "862b8cfb46160e36d7e4bc8f439a956d9649dfa67766ac63f2b5127a330fb9b9"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.0.tar.gz", "has_sig": false, "md5_digest": "8f5b9f7a243b95eab52a6132f83090c7", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 23720, "upload_time": "2020-03-19T12:19:13", "upload_time_iso_8601": "2020-03-19T12:19:13.517633Z", "url": "https://files.pythonhosted.org/packages/bf/35/36ba826ba3cc5319cc6dc4a0950efa3fd59d14a820305b24a95b1e309488/MultiprocessingSpider-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "048b6be4452fc15a55e87196d07216d2", "sha256": "637f8c8b251968ae9997547d0852275d96935d632487fcb2161cdd4361361a4a"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "048b6be4452fc15a55e87196d07216d2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 24925, "upload_time": "2020-03-21T11:04:51", "upload_time_iso_8601": "2020-03-21T11:04:51.382539Z", "url": "https://files.pythonhosted.org/packages/d6/24/e9dc184da381101d49f974db96062f0d55bf633f96453bfa19da1ffabd71/MultiprocessingSpider-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2d23c06bbbaac6e912ca185d8226520d", "sha256": "80cc19cc94ef5540242452d45cc4cf45a8d7133b73f79e91701d6feede4a0a0c"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.1.tar.gz", "has_sig": false, "md5_digest": "2d23c06bbbaac6e912ca185d8226520d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 23708, "upload_time": "2020-03-21T11:04:53", "upload_time_iso_8601": "2020-03-21T11:04:53.088872Z", "url": "https://files.pythonhosted.org/packages/bd/95/e6faafd2ccca5ae1cbfe49f98a77bd7970462217ae5b864b97dc71cca85d/MultiprocessingSpider-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "0b1cf3d10c7709a62691092e19a10d3b", "sha256": "d644da61239beb03e337251770399a4d0f1a0941a0457b523b2fb54d25093c38"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0b1cf3d10c7709a62691092e19a10d3b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 27480, "upload_time": "2020-04-04T04:38:46", "upload_time_iso_8601": "2020-04-04T04:38:46.498635Z", "url": "https://files.pythonhosted.org/packages/93/c4/cf3ddf874d0fcf7df369cc7dfb0ec7708fbc1740fc5504b0992478fbcfb9/MultiprocessingSpider-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "85b162f5d5285e0acf5479494558e7bb", "sha256": "ff9ad77b59c567ca5cbd81be17b398f2bc153c9a80f2494970f03f5b9105e79e"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.2.tar.gz", "has_sig": false, "md5_digest": "85b162f5d5285e0acf5479494558e7bb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 26722, "upload_time": "2020-04-04T04:38:48", "upload_time_iso_8601": "2020-04-04T04:38:48.194438Z", "url": "https://files.pythonhosted.org/packages/70/14/d0828b44a5ced215a93b4015558da303c608da5558a3a8a7cb39adc50f9c/MultiprocessingSpider-1.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0b1cf3d10c7709a62691092e19a10d3b", "sha256": "d644da61239beb03e337251770399a4d0f1a0941a0457b523b2fb54d25093c38"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0b1cf3d10c7709a62691092e19a10d3b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3", "size": 27480, "upload_time": "2020-04-04T04:38:46", "upload_time_iso_8601": "2020-04-04T04:38:46.498635Z", "url": "https://files.pythonhosted.org/packages/93/c4/cf3ddf874d0fcf7df369cc7dfb0ec7708fbc1740fc5504b0992478fbcfb9/MultiprocessingSpider-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "85b162f5d5285e0acf5479494558e7bb", "sha256": "ff9ad77b59c567ca5cbd81be17b398f2bc153c9a80f2494970f03f5b9105e79e"}, "downloads": -1, "filename": "MultiprocessingSpider-1.1.2.tar.gz", "has_sig": false, "md5_digest": "85b162f5d5285e0acf5479494558e7bb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3", "size": 26722, "upload_time": "2020-04-04T04:38:48", "upload_time_iso_8601": "2020-04-04T04:38:48.194438Z", "url": "https://files.pythonhosted.org/packages/70/14/d0828b44a5ced215a93b4015558da303c608da5558a3a8a7cb39adc50f9c/MultiprocessingSpider-1.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:21 2020"}