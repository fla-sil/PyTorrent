{"info": {"author": "Intel AI Products Group", "author_email": "", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Software Development :: Libraries", "Topic :: System :: Clustering", "Topic :: System :: Distributed Computing"], "description": "# Experiments API\n\nTraining a deep neural network requires finding a good combination of model hyperparameters. The process of finding good values for each is called hyperparameter optimization. The number of jobs required for each such experiment typically ranges from the low ones into the hundreds.\n\nIndividual workflows for optimization vary, but this is typically an ad-hoc manual process including custom job submit scripts or even pen and paper.\n\nThis project provides an API to support machine learning experiments on Kubernetes. This is done by moving the experiment context into a shared API and standardizing experiment job metadata. This promotes sharing results and tool development. Decoupling parameter space search from job execution further promotes re-use. This project eases job integration with the experiment tracking system by providing a python client library.\n\n[![overview figure](docs/images/overview.png)](https://docs.google.com/drawings/d/1CGDVt9finf_QC_H6lAIW9StmYiNOCLoemAmpNRN47tg/edit)\n\n## Prerequisites\n\n - git\n - make\n - python\n - kubectl and a connected cluster (minikube or a full cluster)\n\n## Installation\n\nTo install the most recent release, run the following:\n```\n$ pip install experiments\n```\n\n## Development\n\nTo check out and install the latest development release, run:\n```\n$ git clone https://github.com/IntelAI/experiments.git\n$ cd experiments\n$ pip install .\n```\nTo test the Experiments API, run the following:\n```\n$ pip install -r requirements_tests.txt\n$ make test\n``` \n\n## Appendix\n\n### Concepts\n\n**Experiment** Describes a hyperparameter space and how to launch a job for a sample in that space. Has a unique name.\n\n**Optimizer** A program that reads an experiment and creates jobs with different hyperparameter settings. This can be done all in one shot, or the optimizer could be a long-running coordinator that monitors the performance of various samples to direct the hyperparameter optimization process. This program is supplied by the user.\n\n**Result** Encodes metadata about a single job run for an experiment. For example, a handful of high level metrics per training epoch and a pointer to an output directory on shared storage. There is one result resource per job. Each result has the same name as the job it represents.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/IntelAI/experiments", "keywords": "kubernetes \"machine learning\" experiments \"hyperparameter tuning\"", "license": "", "maintainer": "", "maintainer_email": "", "name": "experiments", "package_url": "https://pypi.org/project/experiments/", "platform": "", "project_url": "https://pypi.org/project/experiments/", "project_urls": {"Homepage": "https://github.com/IntelAI/experiments"}, "release_url": "https://pypi.org/project/experiments/0.1.0/", "requires_dist": ["docopt", "kubernetes"], "requires_python": "", "summary": "API supporting machine learning experiment tracking on kubernetes", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p># Experiments API</p>\n<p>Training a deep neural network requires finding a good combination of model hyperparameters. The process of finding good values for each is called hyperparameter optimization. The number of jobs required for each such experiment typically ranges from the low ones into the hundreds.</p>\n<p>Individual workflows for optimization vary, but this is typically an ad-hoc manual process including custom job submit scripts or even pen and paper.</p>\n<p>This project provides an API to support machine learning experiments on Kubernetes. This is done by moving the experiment context into a shared API and standardizing experiment job metadata. This promotes sharing results and tool development. Decoupling parameter space search from job execution further promotes re-use. This project eases job integration with the experiment tracking system by providing a python client library.</p>\n<p>[![overview figure](docs/images/overview.png)](<a href=\"https://docs.google.com/drawings/d/1CGDVt9finf_QC_H6lAIW9StmYiNOCLoemAmpNRN47tg/edit\" rel=\"nofollow\">https://docs.google.com/drawings/d/1CGDVt9finf_QC_H6lAIW9StmYiNOCLoemAmpNRN47tg/edit</a>)</p>\n<p>## Prerequisites</p>\n<blockquote>\n<ul>\n<li>git</li>\n<li>make</li>\n<li>python</li>\n<li>kubectl and a connected cluster (minikube or a full cluster)</li>\n</ul>\n</blockquote>\n<p>## Installation</p>\n<p>To install the most recent release, run the following:\n<tt>`\n$ pip install experiments\n`</tt></p>\n<p>## Development</p>\n<p>To check out and install the latest development release, run:\n<tt>`\n$ git clone <span class=\"pre\">https://github.com/IntelAI/experiments.git</span>\n$ cd experiments\n$ pip install .\n`</tt>\nTo test the Experiments API, run the following:\n<tt>`\n$ pip install <span class=\"pre\">-r</span> requirements_tests.txt\n$ make test\n`</tt></p>\n<p>## Appendix</p>\n<p>### Concepts</p>\n<p><strong>Experiment</strong> Describes a hyperparameter space and how to launch a job for a sample in that space. Has a unique name.</p>\n<p><strong>Optimizer</strong> A program that reads an experiment and creates jobs with different hyperparameter settings. This can be done all in one shot, or the optimizer could be a long-running coordinator that monitors the performance of various samples to direct the hyperparameter optimization process. This program is supplied by the user.</p>\n<p><strong>Result</strong> Encodes metadata about a single job run for an experiment. For example, a handful of high level metrics per training epoch and a pointer to an output directory on shared storage. There is one result resource per job. Each result has the same name as the job it represents.</p>\n\n          </div>"}, "last_serial": 3862943, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "73c234f9078de035e19466bdad588d6e", "sha256": "67e3229ceaf6479e2d9c6c72ef0259cf3e2a7cd316f1f1ab86a60d96756e4581"}, "downloads": -1, "filename": "experiments-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "73c234f9078de035e19466bdad588d6e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5220, "upload_time": "2018-05-15T01:31:09", "upload_time_iso_8601": "2018-05-15T01:31:09.258113Z", "url": "https://files.pythonhosted.org/packages/58/5f/e5cae67190c6c8bb09b5fdd29434ea5caa540a89d428c8cdaa49f7b31f36/experiments-0.1.0-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "73c234f9078de035e19466bdad588d6e", "sha256": "67e3229ceaf6479e2d9c6c72ef0259cf3e2a7cd316f1f1ab86a60d96756e4581"}, "downloads": -1, "filename": "experiments-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "73c234f9078de035e19466bdad588d6e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5220, "upload_time": "2018-05-15T01:31:09", "upload_time_iso_8601": "2018-05-15T01:31:09.258113Z", "url": "https://files.pythonhosted.org/packages/58/5f/e5cae67190c6c8bb09b5fdd29434ea5caa540a89d428c8cdaa49f7b31f36/experiments-0.1.0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:44:39 2020"}