{"info": {"author": "Peter Organisciak", "author_email": "organisciak@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "License :: OSI Approved :: University of Illinois/NCSA Open Source License", "Natural Language :: English", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7"], "description": "HTRC-Features [![Build Status](https://travis-ci.org/htrc/htrc-feature-reader.svg?branch=master)](https://travis-ci.org/htrc/htrc-feature-reader) [![PyPI version](https://badge.fury.io/py/htrc-feature-reader.svg)](https://badge.fury.io/py/htrc-feature-reader) [![Anaconda-Server Badge](https://anaconda.org/htrc/htrc-feature-reader/badges/installer/conda.svg)](https://anaconda.org/htrc/htrc-feature-reader)\n=============\n\nTools for working with the [HTRC Extracted Features dataset](https://sharc.hathitrust.org/features), a dataset of page-level text features extracted from 13.7 million digitized works.\n\nThis library provides a `FeatureReader` for parsing files, which are handled as `Volume` objects with collections of `Page` objects. Volumes provide access to metadata (e.g. language), volume-wide feature information (e.g. token counts), and access to Pages. Pages allow you to easily parse page-level features, particularly token lists.\n\nThis library makes heavy use of [Pandas](pandas.pydata.org), returning many data representations as DataFrames. This is the leading way of dealing with structured data in Python, so this library doesn't try to reinvent the wheel. Since refactoring around Pandas, the primary benefit of using the HTRC Feature Reader is performance: reading the json structures and parsing them is generally faster than custom code. You also get convenient access to common information, such as case-folded token counts or part-of-page specific character counts. Details of the public methods provided by this library can be found in the [HTRC Feature Reader docs](http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html).\n\n**Table of Contents**: [Installation](#Installation) | [Usage](#Usage) | \n[Additional Notes](#Additional-Notes)\n\n**Links**: \n[HTRC Feature Reader Documentation](http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html) | [HTRC Extracted Features Dataset](https://sharc.hathitrust.org/features)\n\n**Citation**:\nPeter Organisciak and Boris Capitanu, \"Text Mining in Python through the HTRC Feature Reader,\" *Programming Historian*, (22 November 2016), http://programminghistorian.org/lessons/text-mining-with-extracted-features.\n\n\n## Installation\n\nTo install,\n\n```bash\n    pip install htrc-feature-reader\n```\n\nThat's it! This library is written for Python 3.0+. For Python beginners, you'll need [pip](https://pip.pypa.io/en/stable/installing/).\n\nAlternately, if you are using [Anaconda](https://www.continuum.io/downloads), you can install with\n\n```bash\n    conda install -c htrc htrc-feature-reader\n```\n\nThe `conda` approach is recommended, because it makes sure that some of the hard-to-install dependencies are properly installed.\n\nGiven the nature of data analysis, using iPython with Jupyter notebooks for preparing your scripts interactively is a recommended convenience. Most basically, it can be installed with `pip install ipython[notebook]` and run with `ipython notebook` from the command line, which starts a session that you can access through your browser. If this doesn't work, consult the [iPython documentation](http://ipython.readthedocs.org/).\n\nOptional: [installing the development version](#Installing-the-development-version). \n\n## Usage\n\n*Note: for new Python users, a more in-depth lesson is published by Programming Historian: [Text Mining in Python through the HTRC Feature Reader](http://programminghistorian.org/lessons/text-mining-with-extracted-features). That lesson is also the official citation associated the HTRC Feature Reader library.*\n\n### Reading feature files\n\nThe easiest way to start using this library is to use the Volume interface, which takes a path to an Extracted Features file.\n\n\n```python\nfrom htrc_features import Volume\nvol = Volume('data/ef2-stubby/hvd/34926/hvd.32044093320364.json.bz2')\nvol\n```\n\n\n\n\n<strong><a href='http://hdl.handle.net/2027/hvd.32044093320364'>The Nautilus.</a></strong> by <em>Delaware Museum of Natural History.</em> (1904, 222 pages) - <code>hvd.32044093320364</code>\n\n\n\nThe FeatureReader can also download files at read time, by reference to a HathiTrust volume id. For example, if I want [both of volumes of Pride and Prejudice](https://catalog.hathitrust.org/Record/100323335), I can see that the URLs are babel.hathitrust.org/cgi/pt?id=__hvd.32044013656053__ and babel.hathitrust.org/cgi/pt?id=__hvd.32044013656061__. In the FeatureReader, these can be called with the `ids=[]` argument, as follows:\n\n\n```python\nfor htid in [\"hvd.32044013656053\", \"hvd.32044013656061\"]:\n    vol = Volume(htid)\n    print(vol.title, vol.enumeration_chronology)\n```\n\n    Pride and prejudice. v.1\n    Pride and prejudice. v.2\n\n\nThis downloads the file temporarily, using the HTRC's web-based download link (e.g. https://data.analytics.hathitrust.org/features/get?download-id={{URL}}). One good pairing with this feature is the [HTRC Python SDK](https://github.com/htrc/HTRC-PythonSDK)'s functionality for downloading collections. \n\nFor example, I have a small collection of knitting-related books at https://babel.hathitrust.org/cgi/mb?a=listis&c=1174943610. To read the feature files for those books:\n\n\n```python\nfrom htrc import workset\nvolids = workset.load_hathitrust_collection('https://babel.hathitrust.org/cgi/mb?a=listis&c=1174943610')\nFeatureReader(ids=volids).first().title\n```\n\nRemember that for large jobs, it is faster to download your dataset beforehand, using the `rsync` method.\n\n### Volume\n\nA [Volume](http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html#htrc_features.feature_reader.Volume) contains information about the current work and access to the pages of the work. All the metadata fields from the HTRC JSON file are accessible as properties of the volume object, including _title_, _language_, _imprint_, _oclc_, _pubDate_, and _genre_. The main identifier _id_ and _pageCount_ are also accessible, and you can find the URL for the Full View of the text in the HathiTrust Digital Library - if it exists - with `vol.handle_url`.\n\n\n```python\n\"Volume {} is a {} page text from {} written in {}. You can doublecheck at {}\".format(vol.id, vol.page_count, \n                                                                                      vol.year, vol.language, \n                                                                                      vol.handle_url)\n```\n\n\n\n\n    'Volume hvd.32044013656061 is a 306 page text from 1903 written in eng. You can doublecheck at http://hdl.handle.net/2027/hvd.32044013656061'\n\n\n\nThis is the *Extracted Features* dataset, so the features are easily accessible. To most popular is token counts, which are returned as a Pandas DataFrame:\n\n\n```python\ndf = vol.tokenlist()\ndf.sample(10)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th>pos</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>201</th>\n      <th>body</th>\n      <th>abode</th>\n      <th>NN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <th>body</th>\n      <th>head</th>\n      <th>NN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <th>body</th>\n      <th>for</th>\n      <th>IN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <th>body</th>\n      <th>three</th>\n      <th>CD</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <th>body</th>\n      <th>would</th>\n      <th>MD</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <th>body</th>\n      <th>The</th>\n      <th>DT</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <th>body</th>\n      <th>any</th>\n      <th>DT</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <th>body</th>\n      <th>surprise</th>\n      <th>NN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <th>body</th>\n      <th>make</th>\n      <th>VB</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <th>body</th>\n      <th>I</th>\n      <th>PRP</th>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nOther extracted features are discussed below.\n\nThe full included metadata can be seen with `vol.parser.meta`:\n\n\n```python\nvol.parser.meta.keys()\n```\n\n\n\n\n    dict_keys(['id', 'metadata_schema_version', 'enumeration_chronology', 'type_of_resource', 'title', 'date_created', 'pub_date', 'language', 'access_profile', 'isbn', 'issn', 'lccn', 'oclc', 'page_count', 'feature_schema_version', 'ht_bib_url', 'genre', 'handle_url', 'imprint', 'names', 'source_institution', 'classification', 'issuance', 'bibliographic_format', 'government_document', 'hathitrust_record_number', 'rights_attributes', 'pub_place', 'volume_identifier', 'source_institution_record_number', 'last_update_date'])\n\n\n\nThese fields are mapped to attributes in `Volume`, so `vol.oclc` will return the oclc field from that metadata. As a convenience, `Volume.year` returns the `pub_date` information and `Volume.author` returns the `contributor information`.\n\n\n```python\nvol.year, vol.author\n```\n\n\n\n\n    ('1903', ['Austen, Jane 1775-1817 '])\n\n\n\nIf the minimal metadata included with the extracted feature files is insufficient, you can fetch HT's metadata record from the Bib API with `vol.metadata`.\nRemember that this calls the HTRC servers for each volume, so can add considerable overhead. The result is a MARC file, returned as a [pymarc](https://github.com/edsu/pymarc) record object. For example, to get the publisher information from field `260`:\n\n\n```python\nvol.metadata['260'].value()\n```\n\n\n\n\n    'Boston : Little, Brown, 1903.'\n\n\n\n_At large-scales, using `vol.metadata` is an impolite and inefficient amount of server pinging; there are better ways to query the API than one volume at a time. Read about the [HTRC Solr Proxy](https://wiki.htrc.illinois.edu/display/COM/Solr+Proxy+API+User+Guide)._\n\nAnother source of bibliographic metadata is the HathiTrust Bib API. You can access this information through the URL returned with `vol.ht_bib_url`:\n\n\n```python\nvol.ht_bib_url\n```\n\n\n\n\n    'http://catalog.hathitrust.org/api/volumes/full/htid/hvd.32044013656061.json'\n\n\n\nVolumes also have direct access to volume-wide info of features stored in pages. For example, you can get a list of words per page through [Volume.tokens_per_page()](http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html#htrc_features.feature_reader.Volume.tokens_per_page). We'll discuss these features [below](#Volume-stats-collecting), after looking first at Pages.\n\nNote that for the most part, the properties of the `Page` and `Volume` objects aligns with the names in the HTRC Extracted Features schema, except they are converted to follow [Python naming conventions](https://google.github.io/styleguide/pyguide.html?showone=Naming#Naming): converting the `CamelCase` of the schema to `lowercase_with_underscores`. E.g. `beginLineChars` from the HTRC data is accessible as `Page.begin_line_chars`.\n\n## The fun stuff: playing with token counts and character counts\n\nToken counts are returned by `Volume.tokenlist()` (or `Page.tokenlist()`. By default, part-of-speech tagged, case-sensitive counts are returned for the body.\n\nThe token count information is returned as a DataFrame with a MultiIndex (page, section, token, and part of speech) and one column (count).\n\n\n```python\nprint(vol.tokenlist()[:3])\n```\n\n                             count\n    page section token  pos       \n    1    body    Austen .        1\n                 Pride  NNP      1\n                 and    CC       1\n\n\n`Page.tokenlist()` can be manipulated in various ways. You can case-fold, for example:\n\n\n```python\ntl = vol.tokenlist(case=False)\ntl.sample(5)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>lowercase</th>\n      <th>pos</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>218</th>\n      <th>body</th>\n      <th>what</th>\n      <th>WP</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <th>body</th>\n      <th>pemberley</th>\n      <th>NNP</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <th>body</th>\n      <th>comes</th>\n      <th>VBZ</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <th>body</th>\n      <th>took</th>\n      <th>VBD</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <th>body</th>\n      <th>necessary</th>\n      <th>JJ</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nOr, you can combine part of speech counts into a single integer.\n\n\n```python\ntl = vol.tokenlist(pos=False)\ntl.sample(5)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>264</th>\n      <th>body</th>\n      <th>family</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <th>body</th>\n      <th>journey</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <th>body</th>\n      <th>Perhaps</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <th>body</th>\n      <th>at</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <th>body</th>\n      <th>so</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nSection arguments are valid here: 'header', 'body', 'footer', 'all', and 'group'\n\n\n```python\ntl = vol.tokenlist(section=\"header\", case=False, pos=False)\ntl.head(5)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>lowercase</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9</th>\n      <th rowspan=\"5\" valign=\"top\">header</th>\n      <th>'s</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>and</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>austen</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>jane</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>prejudice</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nYou can also drop the section index altogether if you're content with the default 'body'.\n\n\n```python\nvol.tokenlist(drop_section=True, case=False, pos=False).sample(2)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>lowercase</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>247</th>\n      <th>suppose</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <th>would</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nThe MultiIndex makes it easy to slice the results, and it is althogether more memory-efficient. For example, to return just the nouns (`NN`):\n\n\n```python\ntl = vol.tokenlist()\ntl.xs('NN', level='pos').head(4)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <th>body</th>\n      <th>prejudiceJane</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <th>body</th>\n      <th>Volume</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <th>body</th>\n      <th>vol</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <th>body</th>\n      <th>./\u25a0</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nIf you are new to Pandas DataFrames, you might find it easier to learn by converting the index to columns.\n\n\n```python\nsimpler_tl = df.reset_index()\nsimpler_tl[simpler_tl.pos == 'NN']\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th>pos</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>body</td>\n      <td>prejudiceJane</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>9</td>\n      <td>body</td>\n      <td>Volume</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>10</td>\n      <td>body</td>\n      <td>vol</td>\n      <td>NN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>12</td>\n      <td>body</td>\n      <td>./\u25a0</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>12</td>\n      <td>body</td>\n      <td>/</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43178</th>\n      <td>297</td>\n      <td>body</td>\n      <td>spite</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43187</th>\n      <td>297</td>\n      <td>body</td>\n      <td>uncle</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43191</th>\n      <td>297</td>\n      <td>body</td>\n      <td>warmest</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43195</th>\n      <td>297</td>\n      <td>body</td>\n      <td>wife</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43226</th>\n      <td>305</td>\n      <td>body</td>\n      <td>NON-RECEIPT</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7224 rows \u00d7 5 columns</p>\n</div>\n\n\n\nIf you prefer not to use Pandas, you can always convert the object, with methods like `to_dict` and `to_csv`).\n\n\n```python\ntl[:3].to_csv()\n```\n\n\n\n\n    'page,section,token,pos,count\\n1,body,Austen,.,1\\n1,body,Pride,NNP,1\\n1,body,and,CC,1\\n'\n\n\n\nTo get just the unique tokens, `Volume.tokens` provides them as a set. Here I select a specific page for brevity and a minimum count, but you can run the method without arguments.\n\n\n```python\nvol.tokens(page_select=21, min_count=5)\n```\n\n\n\n\n    {'\"', ',', '.', 'You', 'been', 'have', 'his', 'in', 'of', 'the', 'you'}\n\n\n\nIn addition to token lists, you can also access other section features:\n\n\n```python\nvol.section_features()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokenCount</th>\n      <th>lineCount</th>\n      <th>emptyLineCount</th>\n      <th>capAlphaSeq</th>\n      <th>sentenceCount</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>10</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>49</td>\n      <td>11</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>306 rows \u00d7 5 columns</p>\n</div>\n\n\n\n### Chunking\n\nIf you're working in an instance where you hope to have comparably sized document units, you can use 'chunking' to roll pages into chunks that aim for a specific length. e.g.\n\n\n```python\nby_chunk = vol.tokenlist(chunk=True, chunk_target=10000)\nprint(by_chunk.sample(4))\n# Count words per chunk\nby_chunk.groupby(level='chunk').sum()\n```\n\n                                  count\n    chunk section token      pos       \n    5     body    husbands   NNS      3\n    2     body    frequently RB       3\n                  domestic   JJ       3\n    3     body    :          :       10\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>chunk</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>12453</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9887</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10129</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10054</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10065</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>12327</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n### Multiprocessing\n\nFor large jobs, you'll want to use multiprocessing or multithreading to speed up your process. This is left up to your preferred method, either within Python or by spawning multiple scripts from the command line. Here are two approaches that I like.\n\n#### Dask\n\nDask offers easy multithreading (shared resources) and multiprocessing (separate processes) in Python, and is particularly convenient because it includes a subset of Pandas DataFrames.\n\nHere is a minimal example, that lazily loads token frequencies from a list of volume IDs, and counts them up by part of speech tag.\n\n```python\nimport dask.dataframe as dd\nfrom dask import delayed\n\ndef get_tokenlist(vol):\n    ''' Load a one volume feature reader, get that volume, and return its tokenlist '''\n    return FeatureReader(ids=[volid]).first().tokenlist()\n\ndelayed_dfs = [delayed(get_tokenlist)(volid) for volid in volids]\n\n# Create a dask\nddf = (dd.from_delayed(delayed_dfs)\n         .reset_index()\n         .groupby('pos')[['count']]\n         .sum()\n      )\n\n# Run processing\nddf.compute()\n```\n\nHere is an example of 78 volumes being processed in 24 seconds with 31 threads:\n\n![Counting POS in 78 books about knitting](data/dask-progress.png)\n\nThis example used multithreading. Due to the nature of Python, certain functions won't parallelize well. In our case, the part where the JSON is read from the file and converted to a DataFrame (the light green parts of the graphic) won't speed up because Python dicts lock the Global Interpreter Lock (GIL). However, because Pandas releases the GIL, nearly everything you do after parsing the JSON will be very quick.\n\nTo better understand what happens when `ddf.compute()`, here is a graph for 4 volumes:\n\n![](data/dask-graph.png)\n\n\n#### GNU Parallel\nAs an alternative to multiprocessing in Python, my preference is to have simpler Python scripts and to use GNU Parallel on the command line. To do this, you can set up your Python script to take variable length arguments of feature file paths, and to print to stdout.\n\nThis psuedo-code shows how that you'd use parallel, where the number of parallel processes is 90% the number of cores, and 50 paths are sent to the script at a time (if you send too little at a time, the initialization time of the script can add up).\n\n```bash\nfind feature-files/ -name '*json.bz2' | parallel --eta --jobs 90% -n 50 python your_script.py >output.txt\n```\n\n## Additional Notes\n\n### Installing the development version\n\n    git clone https://github.com/htrc/htrc-feature-reader.git\n    cd htrc-feature-reader\n    python setup.py install\n\n### Iterating through the JSON files\n\nIf you need to do fast, highly customized processing without instantiating Volumes, FeatureReader has a convenient generator for getting the raw JSON as a Python dict: `fr.jsons()`. This simply does the file reading, optional decompression, and JSON parsing.\n\n### Downloading files within the library\n\n`utils` includes an Rsyncing utility, `download_file`. This requires Rsync to be installed on your system.\n\n**Usage:**\n\nDownload one file to the current directory:\n    \n```\nutils.download_file(htids='nyp.33433042068894')\n```\n\nDownload multiple files to the current directory:\n\n```\nids = ['nyp.33433042068894', 'nyp.33433074943592', 'nyp.33433074943600']\nutils.download_file(htids=ids)\n```\n\nDownload file to `/tmp`:\n```\nutils.download_file(htids='nyp.33433042068894', outdir='/tmp')\n```\n\nDownload file to current directory, keeping pairtree directory structure,\ni.e. `./nyp/pairtree_root/33/43/30/42/06/88/94/33433042068894/nyp.33433042068894.json.bz2`:\n\n```\nutils.download_file(htids='nyp.33433042068894', keep_dirs=True)\n    ```\n\n### Getting the Rsync URL\n\nIf you have a HathiTrust Volume ID and want to be able to download the features for a specific book, `hrtc_features.utils` contains an [id_to_rsync](http://htrc.github.io/htrc-feature-reader/htrc_features/utils.m.html#htrc_features.utils.id_to_rsync) function. This uses the [pairtree](http://pythonhosted.org/Pairtree/) library but has a fallback written with that library is not installed, since it isn't compatible with Python 3.\n\n\n```python\nfrom htrc_features import utils\nutils.id_to_rsync('miun.adx6300.0001.001')\n```\n\n\n\n\n    'miun/pairtree_root/ad/x6/30/0,/00/01/,0/01/adx6300,0001,001/miun.adx6300,0001,001.json.bz2'\n\n\n\nSee the [ID to Rsync notebook](examples/ID_to_Rsync_Link.ipynb) for more information on this format and on Rsyncing lists of urls.\n\nThere is also a command line utility installed with the HTRC Feature Reader:\n\n```bash\n$ htid2rsync miun.adx6300.0001.001\nmiun/pairtree_root/ad/x6/30/0,/00/01/,0/01/adx6300,0001,001/miun.adx6300,0001,001.json.bz2\n```\n\n### Advanced Features\n\nIn the beta Extracted Features release, schema 2.0, a few features were separated out to an advanced files. However, *this designation is no longer present starting with schema 3.0*, meaning information like `beginLineChars`, `endLineChars`, and `capAlphaSeq` are always available:\n\n\n```python\n# What is the longest sequence of capital letter on each page?\nvol.cap_alpha_seqs()[:10]\n```\n\n\n\n\n    [0, 1, 0, 0, 0, 0, 0, 0, 4, 1]\n\n\n\n\n```python\nend_line_chars = vol.end_line_chars()\nprint(end_line_chars.head())\n```\n\n                             count\n    page section place char       \n    2    body    end   -         1\n                       :         1\n                       I         1\n                       f         1\n                       t         1\n\n\n\n```python\n# Find pages that have lines ending with \"!\"\nidx = pd.IndexSlice\nprint(end_line_chars.loc[idx[:,:,:,'!'],].head())\n```\n\n                             count\n    page section place char       \n    45   body    end   !         1\n    75   body    end   !         1\n    77   body    end   !         1\n    91   body    end   !         1\n    92   body    end   !         1\n\n\n### Testing\n\nThis library is meant to be compatible with Python 3.2+ and Python 2.7+. Tests are written for py.test and can be run with `setup.py test`, or directly with `python -m py.test -v`.\n\nIf you find a bug, leave an issue on the issue tracker, or contact Peter Organisciak at `organisciak+htrc@gmail.com`.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/organisciak/htrc-feature-reader", "keywords": "hathitrust text-mining text-analysis features", "license": "NCSA", "maintainer": "", "maintainer_email": "", "name": "htrc-feature-reader", "package_url": "https://pypi.org/project/htrc-feature-reader/", "platform": "", "project_url": "https://pypi.org/project/htrc-feature-reader/", "project_urls": {"Homepage": "https://github.com/organisciak/htrc-feature-reader"}, "release_url": "https://pypi.org/project/htrc-feature-reader/2.0.5/", "requires_dist": null, "requires_python": "", "summary": "Library for working with the HTRC Extracted Features dataset", "version": "2.0.5", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>HTRC-Features <a href=\"https://travis-ci.org/htrc/htrc-feature-reader\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8d54948c42134c0186ae2c7aae773f1d864210f7/68747470733a2f2f7472617669732d63692e6f72672f687472632f687472632d666561747572652d7265616465722e7376673f6272616e63683d6d6173746572\"></a> <a href=\"https://badge.fury.io/py/htrc-feature-reader\" rel=\"nofollow\"><img alt=\"PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/861b686746a3bb251f8ccedae6650005b7758e87/68747470733a2f2f62616467652e667572792e696f2f70792f687472632d666561747572652d7265616465722e737667\"></a> <a href=\"https://anaconda.org/htrc/htrc-feature-reader\" rel=\"nofollow\"><img alt=\"Anaconda-Server Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/530938e290f1b098ced3fa5618cd4f5daf632205/68747470733a2f2f616e61636f6e64612e6f72672f687472632f687472632d666561747572652d7265616465722f6261646765732f696e7374616c6c65722f636f6e64612e737667\"></a></h1>\n<p>Tools for working with the <a href=\"https://sharc.hathitrust.org/features\" rel=\"nofollow\">HTRC Extracted Features dataset</a>, a dataset of page-level text features extracted from 13.7 million digitized works.</p>\n<p>This library provides a <code>FeatureReader</code> for parsing files, which are handled as <code>Volume</code> objects with collections of <code>Page</code> objects. Volumes provide access to metadata (e.g. language), volume-wide feature information (e.g. token counts), and access to Pages. Pages allow you to easily parse page-level features, particularly token lists.</p>\n<p>This library makes heavy use of <a href=\"pandas.pydata.org\" rel=\"nofollow\">Pandas</a>, returning many data representations as DataFrames. This is the leading way of dealing with structured data in Python, so this library doesn't try to reinvent the wheel. Since refactoring around Pandas, the primary benefit of using the HTRC Feature Reader is performance: reading the json structures and parsing them is generally faster than custom code. You also get convenient access to common information, such as case-folded token counts or part-of-page specific character counts. Details of the public methods provided by this library can be found in the <a href=\"http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html\" rel=\"nofollow\">HTRC Feature Reader docs</a>.</p>\n<p><strong>Table of Contents</strong>: <a href=\"#Installation\" rel=\"nofollow\">Installation</a> | <a href=\"#Usage\" rel=\"nofollow\">Usage</a> |\n<a href=\"#Additional-Notes\" rel=\"nofollow\">Additional Notes</a></p>\n<p><strong>Links</strong>:\n<a href=\"http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html\" rel=\"nofollow\">HTRC Feature Reader Documentation</a> | <a href=\"https://sharc.hathitrust.org/features\" rel=\"nofollow\">HTRC Extracted Features Dataset</a></p>\n<p><strong>Citation</strong>:\nPeter Organisciak and Boris Capitanu, \"Text Mining in Python through the HTRC Feature Reader,\" <em>Programming Historian</em>, (22 November 2016), <a href=\"http://programminghistorian.org/lessons/text-mining-with-extracted-features\" rel=\"nofollow\">http://programminghistorian.org/lessons/text-mining-with-extracted-features</a>.</p>\n<h2>Installation</h2>\n<p>To install,</p>\n<pre>    pip install htrc-feature-reader\n</pre>\n<p>That's it! This library is written for Python 3.0+. For Python beginners, you'll need <a href=\"https://pip.pypa.io/en/stable/installing/\" rel=\"nofollow\">pip</a>.</p>\n<p>Alternately, if you are using <a href=\"https://www.continuum.io/downloads\" rel=\"nofollow\">Anaconda</a>, you can install with</p>\n<pre>    conda install -c htrc htrc-feature-reader\n</pre>\n<p>The <code>conda</code> approach is recommended, because it makes sure that some of the hard-to-install dependencies are properly installed.</p>\n<p>Given the nature of data analysis, using iPython with Jupyter notebooks for preparing your scripts interactively is a recommended convenience. Most basically, it can be installed with <code>pip install ipython[notebook]</code> and run with <code>ipython notebook</code> from the command line, which starts a session that you can access through your browser. If this doesn't work, consult the <a href=\"http://ipython.readthedocs.org/\" rel=\"nofollow\">iPython documentation</a>.</p>\n<p>Optional: <a href=\"#Installing-the-development-version\" rel=\"nofollow\">installing the development version</a>.</p>\n<h2>Usage</h2>\n<p><em>Note: for new Python users, a more in-depth lesson is published by Programming Historian: <a href=\"http://programminghistorian.org/lessons/text-mining-with-extracted-features\" rel=\"nofollow\">Text Mining in Python through the HTRC Feature Reader</a>. That lesson is also the official citation associated the HTRC Feature Reader library.</em></p>\n<h3>Reading feature files</h3>\n<p>The easiest way to start using this library is to use the Volume interface, which takes a path to an Extracted Features file.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">htrc_features</span> <span class=\"kn\">import</span> <span class=\"n\">Volume</span>\n<span class=\"n\">vol</span> <span class=\"o\">=</span> <span class=\"n\">Volume</span><span class=\"p\">(</span><span class=\"s1\">'data/ef2-stubby/hvd/34926/hvd.32044093320364.json.bz2'</span><span class=\"p\">)</span>\n<span class=\"n\">vol</span>\n</pre>\n<p><strong><a href=\"http://hdl.handle.net/2027/hvd.32044093320364\" rel=\"nofollow\">The Nautilus.</a></strong> by <em>Delaware Museum of Natural History.</em> (1904, 222 pages) - <code>hvd.32044093320364</code></p>\n<p>The FeatureReader can also download files at read time, by reference to a HathiTrust volume id. For example, if I want <a href=\"https://catalog.hathitrust.org/Record/100323335\" rel=\"nofollow\">both of volumes of Pride and Prejudice</a>, I can see that the URLs are babel.hathitrust.org/cgi/pt?id=<strong>hvd.32044013656053</strong> and babel.hathitrust.org/cgi/pt?id=<strong>hvd.32044013656061</strong>. In the FeatureReader, these can be called with the <code>ids=[]</code> argument, as follows:</p>\n<pre><span class=\"k\">for</span> <span class=\"n\">htid</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"s2\">\"hvd.32044013656053\"</span><span class=\"p\">,</span> <span class=\"s2\">\"hvd.32044013656061\"</span><span class=\"p\">]:</span>\n    <span class=\"n\">vol</span> <span class=\"o\">=</span> <span class=\"n\">Volume</span><span class=\"p\">(</span><span class=\"n\">htid</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">title</span><span class=\"p\">,</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">enumeration_chronology</span><span class=\"p\">)</span>\n</pre>\n<pre><code>Pride and prejudice. v.1\nPride and prejudice. v.2\n</code></pre>\n<p>This downloads the file temporarily, using the HTRC's web-based download link (e.g. <a href=\"https://data.analytics.hathitrust.org/features/get?download-id=%7B%7BURL%7D%7D\" rel=\"nofollow\">https://data.analytics.hathitrust.org/features/get?download-id={{URL}}</a>). One good pairing with this feature is the <a href=\"https://github.com/htrc/HTRC-PythonSDK\" rel=\"nofollow\">HTRC Python SDK</a>'s functionality for downloading collections.</p>\n<p>For example, I have a small collection of knitting-related books at <a href=\"https://babel.hathitrust.org/cgi/mb?a=listis&amp;c=1174943610\" rel=\"nofollow\">https://babel.hathitrust.org/cgi/mb?a=listis&amp;c=1174943610</a>. To read the feature files for those books:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">htrc</span> <span class=\"kn\">import</span> <span class=\"n\">workset</span>\n<span class=\"n\">volids</span> <span class=\"o\">=</span> <span class=\"n\">workset</span><span class=\"o\">.</span><span class=\"n\">load_hathitrust_collection</span><span class=\"p\">(</span><span class=\"s1\">'https://babel.hathitrust.org/cgi/mb?a=listis&amp;c=1174943610'</span><span class=\"p\">)</span>\n<span class=\"n\">FeatureReader</span><span class=\"p\">(</span><span class=\"n\">ids</span><span class=\"o\">=</span><span class=\"n\">volids</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">first</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">title</span>\n</pre>\n<p>Remember that for large jobs, it is faster to download your dataset beforehand, using the <code>rsync</code> method.</p>\n<h3>Volume</h3>\n<p>A <a href=\"http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html#htrc_features.feature_reader.Volume\" rel=\"nofollow\">Volume</a> contains information about the current work and access to the pages of the work. All the metadata fields from the HTRC JSON file are accessible as properties of the volume object, including <em>title</em>, <em>language</em>, <em>imprint</em>, <em>oclc</em>, <em>pubDate</em>, and <em>genre</em>. The main identifier <em>id</em> and <em>pageCount</em> are also accessible, and you can find the URL for the Full View of the text in the HathiTrust Digital Library - if it exists - with <code>vol.handle_url</code>.</p>\n<pre><span class=\"s2\">\"Volume </span><span class=\"si\">{}</span><span class=\"s2\"> is a </span><span class=\"si\">{}</span><span class=\"s2\"> page text from </span><span class=\"si\">{}</span><span class=\"s2\"> written in </span><span class=\"si\">{}</span><span class=\"s2\">. You can doublecheck at </span><span class=\"si\">{}</span><span class=\"s2\">\"</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">id</span><span class=\"p\">,</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">page_count</span><span class=\"p\">,</span> \n                                                                                      <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">year</span><span class=\"p\">,</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">language</span><span class=\"p\">,</span> \n                                                                                      <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">handle_url</span><span class=\"p\">)</span>\n</pre>\n<pre><code>'Volume hvd.32044013656061 is a 306 page text from 1903 written in eng. You can doublecheck at http://hdl.handle.net/2027/hvd.32044013656061'\n</code></pre>\n<p>This is the <em>Extracted Features</em> dataset, so the features are easily accessible. To most popular is token counts, which are returned as a Pandas DataFrame:</p>\n<pre><span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">()</span>\n<span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th>pos</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>201</th>\n      <th>body</th>\n      <th>abode</th>\n      <th>NN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <th>body</th>\n      <th>head</th>\n      <th>NN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <th>body</th>\n      <th>for</th>\n      <th>IN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <th>body</th>\n      <th>three</th>\n      <th>CD</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <th>body</th>\n      <th>would</th>\n      <th>MD</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <th>body</th>\n      <th>The</th>\n      <th>DT</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <th>body</th>\n      <th>any</th>\n      <th>DT</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <th>body</th>\n      <th>surprise</th>\n      <th>NN</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <th>body</th>\n      <th>make</th>\n      <th>VB</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <th>body</th>\n      <th>I</th>\n      <th>PRP</th>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>Other extracted features are discussed below.</p>\n<p>The full included metadata can be seen with <code>vol.parser.meta</code>:</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">meta</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">()</span>\n</pre>\n<pre><code>dict_keys(['id', 'metadata_schema_version', 'enumeration_chronology', 'type_of_resource', 'title', 'date_created', 'pub_date', 'language', 'access_profile', 'isbn', 'issn', 'lccn', 'oclc', 'page_count', 'feature_schema_version', 'ht_bib_url', 'genre', 'handle_url', 'imprint', 'names', 'source_institution', 'classification', 'issuance', 'bibliographic_format', 'government_document', 'hathitrust_record_number', 'rights_attributes', 'pub_place', 'volume_identifier', 'source_institution_record_number', 'last_update_date'])\n</code></pre>\n<p>These fields are mapped to attributes in <code>Volume</code>, so <code>vol.oclc</code> will return the oclc field from that metadata. As a convenience, <code>Volume.year</code> returns the <code>pub_date</code> information and <code>Volume.author</code> returns the <code>contributor information</code>.</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">year</span><span class=\"p\">,</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">author</span>\n</pre>\n<pre><code>('1903', ['Austen, Jane 1775-1817 '])\n</code></pre>\n<p>If the minimal metadata included with the extracted feature files is insufficient, you can fetch HT's metadata record from the Bib API with <code>vol.metadata</code>.\nRemember that this calls the HTRC servers for each volume, so can add considerable overhead. The result is a MARC file, returned as a <a href=\"https://github.com/edsu/pymarc\" rel=\"nofollow\">pymarc</a> record object. For example, to get the publisher information from field <code>260</code>:</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">metadata</span><span class=\"p\">[</span><span class=\"s1\">'260'</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">value</span><span class=\"p\">()</span>\n</pre>\n<pre><code>'Boston : Little, Brown, 1903.'\n</code></pre>\n<p><em>At large-scales, using <code>vol.metadata</code> is an impolite and inefficient amount of server pinging; there are better ways to query the API than one volume at a time. Read about the <a href=\"https://wiki.htrc.illinois.edu/display/COM/Solr+Proxy+API+User+Guide\" rel=\"nofollow\">HTRC Solr Proxy</a>.</em></p>\n<p>Another source of bibliographic metadata is the HathiTrust Bib API. You can access this information through the URL returned with <code>vol.ht_bib_url</code>:</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">ht_bib_url</span>\n</pre>\n<pre><code>'http://catalog.hathitrust.org/api/volumes/full/htid/hvd.32044013656061.json'\n</code></pre>\n<p>Volumes also have direct access to volume-wide info of features stored in pages. For example, you can get a list of words per page through <a href=\"http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html#htrc_features.feature_reader.Volume.tokens_per_page\" rel=\"nofollow\">Volume.tokens_per_page()</a>. We'll discuss these features <a href=\"#Volume-stats-collecting\" rel=\"nofollow\">below</a>, after looking first at Pages.</p>\n<p>Note that for the most part, the properties of the <code>Page</code> and <code>Volume</code> objects aligns with the names in the HTRC Extracted Features schema, except they are converted to follow <a href=\"https://google.github.io/styleguide/pyguide.html?showone=Naming#Naming\" rel=\"nofollow\">Python naming conventions</a>: converting the <code>CamelCase</code> of the schema to <code>lowercase_with_underscores</code>. E.g. <code>beginLineChars</code> from the HTRC data is accessible as <code>Page.begin_line_chars</code>.</p>\n<h2>The fun stuff: playing with token counts and character counts</h2>\n<p>Token counts are returned by <code>Volume.tokenlist()</code> (or <code>Page.tokenlist()</code>. By default, part-of-speech tagged, case-sensitive counts are returned for the body.</p>\n<p>The token count information is returned as a DataFrame with a MultiIndex (page, section, token, and part of speech) and one column (count).</p>\n<pre><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">()[:</span><span class=\"mi\">3</span><span class=\"p\">])</span>\n</pre>\n<pre><code>                         count\npage section token  pos       \n1    body    Austen .        1\n             Pride  NNP      1\n             and    CC       1\n</code></pre>\n<p><code>Page.tokenlist()</code> can be manipulated in various ways. You can case-fold, for example:</p>\n<pre><span class=\"n\">tl</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">(</span><span class=\"n\">case</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>lowercase</th>\n      <th>pos</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>218</th>\n      <th>body</th>\n      <th>what</th>\n      <th>WP</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <th>body</th>\n      <th>pemberley</th>\n      <th>NNP</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>213</th>\n      <th>body</th>\n      <th>comes</th>\n      <th>VBZ</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <th>body</th>\n      <th>took</th>\n      <th>VBD</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <th>body</th>\n      <th>necessary</th>\n      <th>JJ</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>Or, you can combine part of speech counts into a single integer.</p>\n<pre><span class=\"n\">tl</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">(</span><span class=\"n\">pos</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>264</th>\n      <th>body</th>\n      <th>family</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <th>body</th>\n      <th>journey</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <th>body</th>\n      <th>Perhaps</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <th>body</th>\n      <th>at</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <th>body</th>\n      <th>so</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>Section arguments are valid here: 'header', 'body', 'footer', 'all', and 'group'</p>\n<pre><span class=\"n\">tl</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">(</span><span class=\"n\">section</span><span class=\"o\">=</span><span class=\"s2\">\"header\"</span><span class=\"p\">,</span> <span class=\"n\">case</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">pos</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>lowercase</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <th>header</th>\n      <th>'s</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>and</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>austen</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>jane</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>prejudice</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>You can also drop the section index altogether if you're content with the default 'body'.</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">(</span><span class=\"n\">drop_section</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">case</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">pos</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>lowercase</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>247</th>\n      <th>suppose</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <th>would</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>The MultiIndex makes it easy to slice the results, and it is althogether more memory-efficient. For example, to return just the nouns (<code>NN</code>):</p>\n<pre><span class=\"n\">tl</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">()</span>\n<span class=\"n\">tl</span><span class=\"o\">.</span><span class=\"n\">xs</span><span class=\"p\">(</span><span class=\"s1\">'NN'</span><span class=\"p\">,</span> <span class=\"n\">level</span><span class=\"o\">=</span><span class=\"s1\">'pos'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <th>body</th>\n      <th>prejudiceJane</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <th>body</th>\n      <th>Volume</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <th>body</th>\n      <th>vol</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <th>body</th>\n      <th>./\u25a0</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<p>If you are new to Pandas DataFrames, you might find it easier to learn by converting the index to columns.</p>\n<pre><span class=\"n\">simpler_tl</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()</span>\n<span class=\"n\">simpler_tl</span><span class=\"p\">[</span><span class=\"n\">simpler_tl</span><span class=\"o\">.</span><span class=\"n\">pos</span> <span class=\"o\">==</span> <span class=\"s1\">'NN'</span><span class=\"p\">]</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th>page</th>\n      <th>section</th>\n      <th>token</th>\n      <th>pos</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>body</td>\n      <td>prejudiceJane</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>9</td>\n      <td>body</td>\n      <td>Volume</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>10</td>\n      <td>body</td>\n      <td>vol</td>\n      <td>NN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>12</td>\n      <td>body</td>\n      <td>./\u25a0</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>12</td>\n      <td>body</td>\n      <td>/</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43178</th>\n      <td>297</td>\n      <td>body</td>\n      <td>spite</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43187</th>\n      <td>297</td>\n      <td>body</td>\n      <td>uncle</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43191</th>\n      <td>297</td>\n      <td>body</td>\n      <td>warmest</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43195</th>\n      <td>297</td>\n      <td>body</td>\n      <td>wife</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43226</th>\n      <td>305</td>\n      <td>body</td>\n      <td>NON-RECEIPT</td>\n      <td>NN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7224 rows \u00d7 5 columns</p>\n</div>\n<p>If you prefer not to use Pandas, you can always convert the object, with methods like <code>to_dict</code> and <code>to_csv</code>).</p>\n<pre><span class=\"n\">tl</span><span class=\"p\">[:</span><span class=\"mi\">3</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">to_csv</span><span class=\"p\">()</span>\n</pre>\n<pre><code>'page,section,token,pos,count\\n1,body,Austen,.,1\\n1,body,Pride,NNP,1\\n1,body,and,CC,1\\n'\n</code></pre>\n<p>To get just the unique tokens, <code>Volume.tokens</code> provides them as a set. Here I select a specific page for brevity and a minimum count, but you can run the method without arguments.</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokens</span><span class=\"p\">(</span><span class=\"n\">page_select</span><span class=\"o\">=</span><span class=\"mi\">21</span><span class=\"p\">,</span> <span class=\"n\">min_count</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</pre>\n<pre><code>{'\"', ',', '.', 'You', 'been', 'have', 'his', 'in', 'of', 'the', 'you'}\n</code></pre>\n<p>In addition to token lists, you can also access other section features:</p>\n<pre><span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">section_features</span><span class=\"p\">()</span>\n</pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th>tokenCount</th>\n      <th>lineCount</th>\n      <th>emptyLineCount</th>\n      <th>capAlphaSeq</th>\n      <th>sentenceCount</th>\n    </tr>\n    <tr>\n      <th>page</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>10</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>49</td>\n      <td>11</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>306 rows \u00d7 5 columns</p>\n</div>\n<h3>Chunking</h3>\n<p>If you're working in an instance where you hope to have comparably sized document units, you can use 'chunking' to roll pages into chunks that aim for a specific length. e.g.</p>\n<pre><span class=\"n\">by_chunk</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">(</span><span class=\"n\">chunk</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">chunk_target</span><span class=\"o\">=</span><span class=\"mi\">10000</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">by_chunk</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">))</span>\n<span class=\"c1\"># Count words per chunk</span>\n<span class=\"n\">by_chunk</span><span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"n\">level</span><span class=\"o\">=</span><span class=\"s1\">'chunk'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">()</span>\n</pre>\n<pre><code>                              count\nchunk section token      pos       \n5     body    husbands   NNS      3\n2     body    frequently RB       3\n              domestic   JJ       3\n3     body    :          :       10\n</code></pre>\n<div>\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<pre><code>.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n</code></pre>\n&lt;/style&gt;\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>chunk</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>12453</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9887</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10129</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10054</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10065</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>12327</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<h3>Multiprocessing</h3>\n<p>For large jobs, you'll want to use multiprocessing or multithreading to speed up your process. This is left up to your preferred method, either within Python or by spawning multiple scripts from the command line. Here are two approaches that I like.</p>\n<h4>Dask</h4>\n<p>Dask offers easy multithreading (shared resources) and multiprocessing (separate processes) in Python, and is particularly convenient because it includes a subset of Pandas DataFrames.</p>\n<p>Here is a minimal example, that lazily loads token frequencies from a list of volume IDs, and counts them up by part of speech tag.</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">dask.dataframe</span> <span class=\"k\">as</span> <span class=\"nn\">dd</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dask</span> <span class=\"kn\">import</span> <span class=\"n\">delayed</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">get_tokenlist</span><span class=\"p\">(</span><span class=\"n\">vol</span><span class=\"p\">):</span>\n    <span class=\"sd\">''' Load a one volume feature reader, get that volume, and return its tokenlist '''</span>\n    <span class=\"k\">return</span> <span class=\"n\">FeatureReader</span><span class=\"p\">(</span><span class=\"n\">ids</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">volid</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">first</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">tokenlist</span><span class=\"p\">()</span>\n\n<span class=\"n\">delayed_dfs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">delayed</span><span class=\"p\">(</span><span class=\"n\">get_tokenlist</span><span class=\"p\">)(</span><span class=\"n\">volid</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">volid</span> <span class=\"ow\">in</span> <span class=\"n\">volids</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># Create a dask</span>\n<span class=\"n\">ddf</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">dd</span><span class=\"o\">.</span><span class=\"n\">from_delayed</span><span class=\"p\">(</span><span class=\"n\">delayed_dfs</span><span class=\"p\">)</span>\n         <span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">()</span>\n         <span class=\"o\">.</span><span class=\"n\">groupby</span><span class=\"p\">(</span><span class=\"s1\">'pos'</span><span class=\"p\">)[[</span><span class=\"s1\">'count'</span><span class=\"p\">]]</span>\n         <span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">()</span>\n      <span class=\"p\">)</span>\n\n<span class=\"c1\"># Run processing</span>\n<span class=\"n\">ddf</span><span class=\"o\">.</span><span class=\"n\">compute</span><span class=\"p\">()</span>\n</pre>\n<p>Here is an example of 78 volumes being processed in 24 seconds with 31 threads:</p>\n<p><img alt=\"Counting POS in 78 books about knitting\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5bd4b028b1640e2b2f5613f81560f80a1d8f1b9e/646174612f6461736b2d70726f67726573732e706e67\"></p>\n<p>This example used multithreading. Due to the nature of Python, certain functions won't parallelize well. In our case, the part where the JSON is read from the file and converted to a DataFrame (the light green parts of the graphic) won't speed up because Python dicts lock the Global Interpreter Lock (GIL). However, because Pandas releases the GIL, nearly everything you do after parsing the JSON will be very quick.</p>\n<p>To better understand what happens when <code>ddf.compute()</code>, here is a graph for 4 volumes:</p>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f8d314fc3830667fceb97e61a1a8e2e8f8c5bcd7/646174612f6461736b2d67726170682e706e67\"></p>\n<h4>GNU Parallel</h4>\n<p>As an alternative to multiprocessing in Python, my preference is to have simpler Python scripts and to use GNU Parallel on the command line. To do this, you can set up your Python script to take variable length arguments of feature file paths, and to print to stdout.</p>\n<p>This psuedo-code shows how that you'd use parallel, where the number of parallel processes is 90% the number of cores, and 50 paths are sent to the script at a time (if you send too little at a time, the initialization time of the script can add up).</p>\n<pre>find feature-files/ -name <span class=\"s1\">'*json.bz2'</span> <span class=\"p\">|</span> parallel --eta --jobs <span class=\"m\">90</span>% -n <span class=\"m\">50</span> python your_script.py &gt;output.txt\n</pre>\n<h2>Additional Notes</h2>\n<h3>Installing the development version</h3>\n<pre><code>git clone https://github.com/htrc/htrc-feature-reader.git\ncd htrc-feature-reader\npython setup.py install\n</code></pre>\n<h3>Iterating through the JSON files</h3>\n<p>If you need to do fast, highly customized processing without instantiating Volumes, FeatureReader has a convenient generator for getting the raw JSON as a Python dict: <code>fr.jsons()</code>. This simply does the file reading, optional decompression, and JSON parsing.</p>\n<h3>Downloading files within the library</h3>\n<p><code>utils</code> includes an Rsyncing utility, <code>download_file</code>. This requires Rsync to be installed on your system.</p>\n<p><strong>Usage:</strong></p>\n<p>Download one file to the current directory:</p>\n<pre><code>utils.download_file(htids='nyp.33433042068894')\n</code></pre>\n<p>Download multiple files to the current directory:</p>\n<pre><code>ids = ['nyp.33433042068894', 'nyp.33433074943592', 'nyp.33433074943600']\nutils.download_file(htids=ids)\n</code></pre>\n<p>Download file to <code>/tmp</code>:</p>\n<pre><code>utils.download_file(htids='nyp.33433042068894', outdir='/tmp')\n</code></pre>\n<p>Download file to current directory, keeping pairtree directory structure,\ni.e. <code>./nyp/pairtree_root/33/43/30/42/06/88/94/33433042068894/nyp.33433042068894.json.bz2</code>:</p>\n<pre><code>utils.download_file(htids='nyp.33433042068894', keep_dirs=True)\n    ```\n\n### Getting the Rsync URL\n\nIf you have a HathiTrust Volume ID and want to be able to download the features for a specific book, `hrtc_features.utils` contains an [id_to_rsync](http://htrc.github.io/htrc-feature-reader/htrc_features/utils.m.html#htrc_features.utils.id_to_rsync) function. This uses the [pairtree](http://pythonhosted.org/Pairtree/) library but has a fallback written with that library is not installed, since it isn't compatible with Python 3.\n\n\n```python\nfrom htrc_features import utils\nutils.id_to_rsync('miun.adx6300.0001.001')\n</code></pre>\n<pre><code>'miun/pairtree_root/ad/x6/30/0,/00/01/,0/01/adx6300,0001,001/miun.adx6300,0001,001.json.bz2'\n</code></pre>\n<p>See the <a href=\"examples/ID_to_Rsync_Link.ipynb\" rel=\"nofollow\">ID to Rsync notebook</a> for more information on this format and on Rsyncing lists of urls.</p>\n<p>There is also a command line utility installed with the HTRC Feature Reader:</p>\n<pre>$ htid2rsync miun.adx6300.0001.001\nmiun/pairtree_root/ad/x6/30/0,/00/01/,0/01/adx6300,0001,001/miun.adx6300,0001,001.json.bz2\n</pre>\n<h3>Advanced Features</h3>\n<p>In the beta Extracted Features release, schema 2.0, a few features were separated out to an advanced files. However, <em>this designation is no longer present starting with schema 3.0</em>, meaning information like <code>beginLineChars</code>, <code>endLineChars</code>, and <code>capAlphaSeq</code> are always available:</p>\n<pre><span class=\"c1\"># What is the longest sequence of capital letter on each page?</span>\n<span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">cap_alpha_seqs</span><span class=\"p\">()[:</span><span class=\"mi\">10</span><span class=\"p\">]</span>\n</pre>\n<pre><code>[0, 1, 0, 0, 0, 0, 0, 0, 4, 1]\n</code></pre>\n<pre><span class=\"n\">end_line_chars</span> <span class=\"o\">=</span> <span class=\"n\">vol</span><span class=\"o\">.</span><span class=\"n\">end_line_chars</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">end_line_chars</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">())</span>\n</pre>\n<pre><code>                         count\npage section place char       \n2    body    end   -         1\n                   :         1\n                   I         1\n                   f         1\n                   t         1\n</code></pre>\n<pre><span class=\"c1\"># Find pages that have lines ending with \"!\"</span>\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">IndexSlice</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">end_line_chars</span><span class=\"o\">.</span><span class=\"n\">loc</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">[:,:,:,</span><span class=\"s1\">'!'</span><span class=\"p\">],]</span><span class=\"o\">.</span><span class=\"n\">head</span><span class=\"p\">())</span>\n</pre>\n<pre><code>                         count\npage section place char       \n45   body    end   !         1\n75   body    end   !         1\n77   body    end   !         1\n91   body    end   !         1\n92   body    end   !         1\n</code></pre>\n<h3>Testing</h3>\n<p>This library is meant to be compatible with Python 3.2+ and Python 2.7+. Tests are written for py.test and can be run with <code>setup.py test</code>, or directly with <code>python -m py.test -v</code>.</p>\n<p>If you find a bug, leave an issue on the issue tracker, or contact Peter Organisciak at <code>organisciak+htrc@gmail.com</code>.</p>\n\n          </div>"}, "last_serial": 7095579, "releases": {"1.3": [{"comment_text": "", "digests": {"md5": "f4424fbe3f0b80915d6a30faa4d8ca2e", "sha256": "fa245a8a986350985d9cefddfe90e8f31ba30a515a7f67f92c21cb16be29b79b"}, "downloads": -1, "filename": "htrc-feature-reader-1.3.tar.gz", "has_sig": false, "md5_digest": "f4424fbe3f0b80915d6a30faa4d8ca2e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8526, "upload_time": "2015-12-23T20:24:17", "upload_time_iso_8601": "2015-12-23T20:24:17.001933Z", "url": "https://files.pythonhosted.org/packages/1c/49/5164365a4c21d773a860a1a79e06b3aa0f1da92eb4d81038a3666723ad32/htrc-feature-reader-1.3.tar.gz", "yanked": false}], "1.41": [{"comment_text": "", "digests": {"md5": "4a1a335ae8640c09ba27c28beede28dc", "sha256": "ab7fce29cdf694ee1a131056c8c154941209b04ec8869823024a80b31b8ef24d"}, "downloads": -1, "filename": "htrc-feature-reader-1.41.tar.gz", "has_sig": false, "md5_digest": "4a1a335ae8640c09ba27c28beede28dc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8703, "upload_time": "2016-01-12T19:05:11", "upload_time_iso_8601": "2016-01-12T19:05:11.556419Z", "url": "https://files.pythonhosted.org/packages/8c/58/f8a4ed6f981051e7b6738cd45ab85503cd0ecacca9b49938d5162faaaa40/htrc-feature-reader-1.41.tar.gz", "yanked": false}], "1.42": [{"comment_text": "", "digests": {"md5": "74c87f4b6788d8a76e228acb21944814", "sha256": "6a2dfbd3f1083bab08958fce952056e850220346bb55c585df5fc3ca7dc58c1a"}, "downloads": -1, "filename": "htrc_feature_reader-1.42-py2.7.egg", "has_sig": false, "md5_digest": "74c87f4b6788d8a76e228acb21944814", "packagetype": "bdist_egg", "python_version": "2.7", "requires_python": null, "size": 19312, "upload_time": "2016-03-30T18:20:35", "upload_time_iso_8601": "2016-03-30T18:20:35.867978Z", "url": "https://files.pythonhosted.org/packages/3b/e6/69a6f3efb5c5bc0c268355e385d6688d47783169e347417cf459799f4871/htrc_feature_reader-1.42-py2.7.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "f9382eebead4bc3e7dddbe61d880c68e", "sha256": "1d5386d23a08390939001be4a02849b9832a5aa40094f0f74bb071f32052b1d0"}, "downloads": -1, "filename": "htrc_feature_reader-1.42-py3.4.egg", "has_sig": false, "md5_digest": "f9382eebead4bc3e7dddbe61d880c68e", "packagetype": "bdist_egg", "python_version": "3.4", "requires_python": null, "size": 19615, "upload_time": "2016-03-30T18:20:47", "upload_time_iso_8601": "2016-03-30T18:20:47.348690Z", "url": "https://files.pythonhosted.org/packages/b2/e6/fc22ed2e91dbaecfc552b011c8ae18d98e026c8ee98c3a96a5fb501f7764/htrc_feature_reader-1.42-py3.4.egg", "yanked": false}, {"comment_text": "", "digests": {"md5": "143d5e3b7e07b612d36d96f19bd49c42", "sha256": "2ad0f0a674f25c9f97deae0495728aace0f79a813d060fa74957da22aa8c934f"}, "downloads": -1, "filename": "htrc-feature-reader-1.42.tar.gz", "has_sig": false, "md5_digest": "143d5e3b7e07b612d36d96f19bd49c42", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8235, "upload_time": "2016-02-23T22:39:37", "upload_time_iso_8601": "2016-02-23T22:39:37.724456Z", "url": "https://files.pythonhosted.org/packages/ec/1e/f5717e065a1d365c2d66138d4aa1aec134eb8a779527ec8c2b7762f83815/htrc-feature-reader-1.42.tar.gz", "yanked": false}], "1.43": [{"comment_text": "", "digests": {"md5": "d2339e51ce54394dc4a74cc45f84be25", "sha256": "d42fafccc4053123bbcde1877a45ed2b51e8c68645a56b3ec760c6cab6d26468"}, "downloads": -1, "filename": "htrc-feature-reader-1.43.tar.gz", "has_sig": false, "md5_digest": "d2339e51ce54394dc4a74cc45f84be25", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15826, "upload_time": "2016-03-30T18:22:20", "upload_time_iso_8601": "2016-03-30T18:22:20.235378Z", "url": "https://files.pythonhosted.org/packages/9e/63/ab651ad3a7b5542536c43a6e6dcd92d89efe13cc58b56b64006a7dc943a7/htrc-feature-reader-1.43.tar.gz", "yanked": false}], "1.45": [{"comment_text": "", "digests": {"md5": "7deaf03e757de09db7cdb6ba91324d90", "sha256": "ef09261d85e47b81d3fc2e305358bbbbda13e197d9f27dbd9c52e39b0c3295b2"}, "downloads": -1, "filename": "htrc-feature-reader-1.45.tar.gz", "has_sig": false, "md5_digest": "7deaf03e757de09db7cdb6ba91324d90", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16157, "upload_time": "2016-04-19T16:38:16", "upload_time_iso_8601": "2016-04-19T16:38:16.698326Z", "url": "https://files.pythonhosted.org/packages/8f/58/eb38aabbd69f8e4bd65364cb23ad3146a441cd8625ea45ad86193c4ad38e/htrc-feature-reader-1.45.tar.gz", "yanked": false}], "1.50": [{"comment_text": "", "digests": {"md5": "0f1a573232aae290f4f26f02b5d460b1", "sha256": "36143abc3da6f89cf6422eb835cf156d2f2f17218e982ca07949cd55458ccf38"}, "downloads": -1, "filename": "htrc-feature-reader-1.50.tar.gz", "has_sig": false, "md5_digest": "0f1a573232aae290f4f26f02b5d460b1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16247, "upload_time": "2016-06-04T00:10:52", "upload_time_iso_8601": "2016-06-04T00:10:52.408459Z", "url": "https://files.pythonhosted.org/packages/58/d0/d783e1587ad8721b901170a95b777c4e07155f6b498388bc54d35dc63f28/htrc-feature-reader-1.50.tar.gz", "yanked": false}], "1.70": [{"comment_text": "", "digests": {"md5": "f37f2f5f72b320411231ca8bacf697dc", "sha256": "55c0b53c9e396aa1aa8f15e56d130f2c75ac619f8963069bdae2626a833744f7"}, "downloads": -1, "filename": "htrc-feature-reader-1.70.tar.gz", "has_sig": false, "md5_digest": "f37f2f5f72b320411231ca8bacf697dc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17034, "upload_time": "2016-08-24T20:03:38", "upload_time_iso_8601": "2016-08-24T20:03:38.778746Z", "url": "https://files.pythonhosted.org/packages/98/f6/fb8e470048227651faf3a949734ddfe098f06e70f7198bceffe8687bbf66/htrc-feature-reader-1.70.tar.gz", "yanked": false}], "1.80": [{"comment_text": "", "digests": {"md5": "1995895b7eeab5ce07ed4113c661f2cd", "sha256": "1be7de6f1e26748ad6b3e27c78956e055f86707567d85a7ce777e3d53b9e8c8d"}, "downloads": -1, "filename": "htrc-feature-reader-1.80.tar.gz", "has_sig": false, "md5_digest": "1995895b7eeab5ce07ed4113c661f2cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17838, "upload_time": "2016-11-08T00:27:53", "upload_time_iso_8601": "2016-11-08T00:27:53.725495Z", "url": "https://files.pythonhosted.org/packages/8f/0b/2c26f144b57d8ccf7a0ddc857509f1de8c25d1237016f4428c21d6c0400d/htrc-feature-reader-1.80.tar.gz", "yanked": false}], "1.81": [{"comment_text": "", "digests": {"md5": "8913668c877723f2d7b6c6eb089dd26a", "sha256": "3b9ab1b30ebf37b541dfa582640679fb6a394440859c6092feef9bc302ac1cd6"}, "downloads": -1, "filename": "htrc-feature-reader-1.81.tar.gz", "has_sig": false, "md5_digest": "8913668c877723f2d7b6c6eb089dd26a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18097, "upload_time": "2016-11-08T17:43:29", "upload_time_iso_8601": "2016-11-08T17:43:29.094470Z", "url": "https://files.pythonhosted.org/packages/cb/d6/c5618b3417cc4131913479284cb298605f3a5216857cbb9ccfcde5805e12/htrc-feature-reader-1.81.tar.gz", "yanked": false}], "1.82": [{"comment_text": "", "digests": {"md5": "458981943c9585042e621c91a55554c6", "sha256": "4e72b20edc8f1734998e5dd3083109f59e8d00d43b0056f95b426f0564e464a4"}, "downloads": -1, "filename": "htrc-feature-reader-1.82.tar.gz", "has_sig": false, "md5_digest": "458981943c9585042e621c91a55554c6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18313, "upload_time": "2016-12-04T21:13:59", "upload_time_iso_8601": "2016-12-04T21:13:59.715531Z", "url": "https://files.pythonhosted.org/packages/71/dc/22eef0bd30531dbeec251b801331b82ca09379dac213a496f133252d4a91/htrc-feature-reader-1.82.tar.gz", "yanked": false}], "1.90": [{"comment_text": "", "digests": {"md5": "c2e74301157344ad4a60cff8b6f1283e", "sha256": "c96396625376a7eae587b5ec742004a5425584da7e94a8929be21446bd1932da"}, "downloads": -1, "filename": "htrc-feature-reader-1.90.tar.gz", "has_sig": false, "md5_digest": "c2e74301157344ad4a60cff8b6f1283e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21562, "upload_time": "2017-05-10T23:15:33", "upload_time_iso_8601": "2017-05-10T23:15:33.740605Z", "url": "https://files.pythonhosted.org/packages/58/e4/fca105536c6f8a6f2a7abcbab1f6b3e4f72a33174c094689800434ca3899/htrc-feature-reader-1.90.tar.gz", "yanked": false}], "1.91": [{"comment_text": "", "digests": {"md5": "427f35c61927555f73193c0d85a9c561", "sha256": "c9344577c21b00fb55311f3d3164eaae1c92d51a78601b4f3811002a5b0f308f"}, "downloads": -1, "filename": "htrc-feature-reader-1.91.tar.gz", "has_sig": false, "md5_digest": "427f35c61927555f73193c0d85a9c561", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21594, "upload_time": "2017-05-10T23:56:57", "upload_time_iso_8601": "2017-05-10T23:56:57.545455Z", "url": "https://files.pythonhosted.org/packages/1c/e4/befd8b063796ea6efae81097ac8e27ed6fc3759820912b9aa07ea6e6812d/htrc-feature-reader-1.91.tar.gz", "yanked": false}], "1.92": [{"comment_text": "", "digests": {"md5": "8906cd100be953823145e78c5001d21e", "sha256": "986eafebce4c07326e7cd1d7e9c6557f93b4c737027d98ad38187f2f2a3a349f"}, "downloads": -1, "filename": "htrc-feature-reader-1.92.tar.gz", "has_sig": false, "md5_digest": "8906cd100be953823145e78c5001d21e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21595, "upload_time": "2017-05-11T19:49:36", "upload_time_iso_8601": "2017-05-11T19:49:36.347614Z", "url": "https://files.pythonhosted.org/packages/e1/c3/b577f7c7f5b51665132db4488ce5b76257b91486881c22d824366adac405/htrc-feature-reader-1.92.tar.gz", "yanked": false}], "1.94": [{"comment_text": "", "digests": {"md5": "f9bd20eccbaa987ac48a59103a48745a", "sha256": "6ea5d7b49df5c50bfe11d54b3723bd0a167b2e75e5d24b9525e5b8f4011a8832"}, "downloads": -1, "filename": "htrc-feature-reader-1.94.tar.gz", "has_sig": false, "md5_digest": "f9bd20eccbaa987ac48a59103a48745a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 22074, "upload_time": "2017-06-05T17:35:27", "upload_time_iso_8601": "2017-06-05T17:35:27.061871Z", "url": "https://files.pythonhosted.org/packages/06/da/2874a234089e0f1d885d95d84e8a622faf256287ace89296df1cfe45c7c5/htrc-feature-reader-1.94.tar.gz", "yanked": false}], "1.96": [{"comment_text": "", "digests": {"md5": "3da942a6d57932cecb2dbe87d60ed1bc", "sha256": "a59ddeb38e4f2ee6fe742dfd644b24afb36d113226faed81c60d76a52ae0f74e"}, "downloads": -1, "filename": "htrc-feature-reader-1.96.tar.gz", "has_sig": false, "md5_digest": "3da942a6d57932cecb2dbe87d60ed1bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20645, "upload_time": "2018-09-26T23:25:16", "upload_time_iso_8601": "2018-09-26T23:25:16.964649Z", "url": "https://files.pythonhosted.org/packages/9f/75/e1aa86565017ed3ef01beabbc7b00a7910e4d06ad055ea443ed7c6e80ac7/htrc-feature-reader-1.96.tar.gz", "yanked": false}], "1.97": [{"comment_text": "", "digests": {"md5": "0ab51690185e0e0d8f5fbe48ff784dc7", "sha256": "e50ac43f4e0641ec58924e1bd7108ac82296f643fe4855361f47568c19b1c036"}, "downloads": -1, "filename": "htrc-feature-reader-1.97.tar.gz", "has_sig": false, "md5_digest": "0ab51690185e0e0d8f5fbe48ff784dc7", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21402, "upload_time": "2019-02-07T01:07:14", "upload_time_iso_8601": "2019-02-07T01:07:14.471016Z", "url": "https://files.pythonhosted.org/packages/c1/0e/f7d04710286f9cd8c7d39484146a092cf36a7bf4db08b530e8a7725c22c6/htrc-feature-reader-1.97.tar.gz", "yanked": false}], "1.98": [{"comment_text": "", "digests": {"md5": "35899ad9326d5ccbe0f923bfe2f10712", "sha256": "4f90a8a9b6b29f7212e7e208403008438a0af71dfbd63570c7cc8d08bea73b64"}, "downloads": -1, "filename": "htrc-feature-reader-1.98.tar.gz", "has_sig": false, "md5_digest": "35899ad9326d5ccbe0f923bfe2f10712", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21427, "upload_time": "2019-02-07T03:38:15", "upload_time_iso_8601": "2019-02-07T03:38:15.376689Z", "url": "https://files.pythonhosted.org/packages/10/11/3bea476e043d2f20c8dfa084d003eb94fca34d112ccb234b785428ad997b/htrc-feature-reader-1.98.tar.gz", "yanked": false}], "1.99": [{"comment_text": "", "digests": {"md5": "2d234a84ad5e5ae0d76d9c97775659f6", "sha256": "6511695748214448b471878c83070cb2979a0326ce6a596c7a50c76cbc604d83"}, "downloads": -1, "filename": "htrc-feature-reader-1.99.tar.gz", "has_sig": false, "md5_digest": "2d234a84ad5e5ae0d76d9c97775659f6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21441, "upload_time": "2019-02-07T04:39:58", "upload_time_iso_8601": "2019-02-07T04:39:58.874917Z", "url": "https://files.pythonhosted.org/packages/49/c6/e5916b4c27d00c600c08da44637732b657c3b2c84f0c2e7cbeb0d2b11b7a/htrc-feature-reader-1.99.tar.gz", "yanked": false}], "2.0.4": [{"comment_text": "", "digests": {"md5": "29846e5af973109c50d4457c5303e386", "sha256": "2eb9fd43ab7ef77a2f936b1d876eaa8e8052f0f18515dcac4c650026d8b16895"}, "downloads": -1, "filename": "htrc-feature-reader-2.0.4.tar.gz", "has_sig": false, "md5_digest": "29846e5af973109c50d4457c5303e386", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 58020, "upload_time": "2020-04-14T20:06:01", "upload_time_iso_8601": "2020-04-14T20:06:01.838318Z", "url": "https://files.pythonhosted.org/packages/11/03/f2a69df982912e486c9bd24a731fd1d4734015f2b1d5df61a5147509e233/htrc-feature-reader-2.0.4.tar.gz", "yanked": false}], "2.0.5": [{"comment_text": "", "digests": {"md5": "0d0b5a57a1cb89ba711b4f8966ac8574", "sha256": "fa936db222e730fed0965fcda0748bc229f1939ff8be694e0d2436e234083526"}, "downloads": -1, "filename": "htrc-feature-reader-2.0.5.tar.gz", "has_sig": false, "md5_digest": "0d0b5a57a1cb89ba711b4f8966ac8574", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52674, "upload_time": "2020-04-24T19:53:22", "upload_time_iso_8601": "2020-04-24T19:53:22.440906Z", "url": "https://files.pythonhosted.org/packages/7a/e5/8d51cfb3a68b49dd34ec18e2065d7a1d61aba7ab377163f724183abcf9d8/htrc-feature-reader-2.0.5.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0d0b5a57a1cb89ba711b4f8966ac8574", "sha256": "fa936db222e730fed0965fcda0748bc229f1939ff8be694e0d2436e234083526"}, "downloads": -1, "filename": "htrc-feature-reader-2.0.5.tar.gz", "has_sig": false, "md5_digest": "0d0b5a57a1cb89ba711b4f8966ac8574", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 52674, "upload_time": "2020-04-24T19:53:22", "upload_time_iso_8601": "2020-04-24T19:53:22.440906Z", "url": "https://files.pythonhosted.org/packages/7a/e5/8d51cfb3a68b49dd34ec18e2065d7a1d61aba7ab377163f724183abcf9d8/htrc-feature-reader-2.0.5.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:12 2020"}