{"info": {"author": "Larry Hastings", "author_email": "larry@hastings.org", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python :: 3 :: Only"], "description": "# correlate\n\n## A clever brute-force correlator for kinda-messy data\n\n##### Copyright 2019-2020 by Larry Hastings\n\n\n## Overview\n\nLet's say you have two sets of data that really represent the same data,\njust in different forms.\nAs an example, maybe your first dataset is Wikipedia's list of all episodes of a TV\nshow, and your second dataset is a directory full of video files of\nthat TV show.  The episode *\"Neurostim\"* appears in both datasets but\nit's represented differently in each.\n\nNow let's say you want to match them up with each other--you want\nto match up the values in the first dataset with their equivalents\nin the second dataset. The thing is, it's real-world data--and\nit's probably a little messy.  Perhaps the two datasets aren't in\nthe exact same order.  And while some matches are obvious, others are less so.\nMaybe one dataset has some values not present in the other and vice-versa.\n\nWhat do you do?  Sure, you could correlate the two datasets by hand.\nBut what if the datasets are really big?\nAnd what do you do if they get updated?  Do you want to update the\ncorrelation by hand too?\n\n**correlate** solves this problem for you.  It correlates values between\ntwo messy but strongly-related datasets.\n\nHow it works: you submit your two datasets to\n**correlate**, showing it each value and mining the data and metadata for\n\"keys\" that map to that value.  You then set **correlate** to work.\nIt thinks for a while, then produces its best guess as to how to match\nthe two sets.  And its best guess is... hey, that's pretty good!\n\nIn essense, **correlate** uses the uniqueness of keys as clues to find\nits matches.  If there's a key present in both datasets, but it only maps\nto one value in each dataset, odds are good that those two values\nshould be matched together.\n\nThat's the basics.  **correlate** also supports some advanced features:\n\n* A key mapping can optionally specify a *weight*.\n* You can map a key *multiple times.*\n* Keys can be *fuzzy keys,* keys that may only partially match each other.\n* The order of values can inform the matches; **correlate** calls this *ranking.*\n\n### Quick Start\n\nThis code:\n\n    import correlate\n\n    c = correlate.Correlator()\n    a, b = c.datasets\n\n    a.set(\"this\", \"greg\")\n    a.set(\"is\", \"greg\")\n    a.set(\"Greg\", \"greg\", weight=5)\n    a.set_keys(\"Carol over here\".split(), \"carol\")\n    a.set_keys(\"My name is Tony\".split(), \"tony\")\n    a.set_keys(\"Hi I'm Steve\".split(), \"steve\", weight=2)\n\n    b.set_keys(\"gosh my name is Greg\".split(), \"Greg\")\n    b.set_keys(\"Carol is my name\".split() , \"Carol\")\n    b.set_keys(\"Pretty sure I'm still Tony\".split(), \"Tony\")\n    b.set_keys(\"I'm Steve\".split(), \"Steve\")\n\n    result = c.correlate()\n    for match in result.matches:\n        print(f\"{match.score:1.3f} {match.value_a:>5} -> {match.value_b}\")\n\nproduces this output:\n\n    5.750  greg -> Greg\n    3.800 steve -> Steve\n    1.286 carol -> Carol\n    1.222  tony -> Tony\n\n\n### A Real-Life Example\n\nThere's a podcast I like.  I download it as MP3 files\nusing an RSS feed, 1990s-style. But the metadata in the RSS\nfeed is junk--the episode titles are inconsistent,\nand the episode numbers are almost wholly absent.\n\nThis podcast also has a\nlist of episodes on its website. This data is *much* cleaner,\nincluding nice proper (unique!) episode numbers.  And it's easily\nscraped.  But it's still not perfect.\nThe two lists of episodes aren't exactly the same, and even the episodes\nthat are present in both are sometimes reordered.\n\nObviously, I want to take the MP3s from the RSS feed,\nand match them up with the nice clean metadata scraped from the website.\nThis gets me the best of both worlds.\n\nBut there are more than *six hundred* episodes of this\nparticular podcast!  Matching those by hand would be a *lot* of work.\nAnd we get a new episode every week.\nAnd sometimes they actually add back in old episodes, or update the\nmetadata on old episodes--changes which would mess up any hand-built\nordering.  And I might want to listen to more than one podcast from\nthis same website someday!\nSo I really didn't want to do all of this by hand.\n\nHappily, after applying just a bit of intelligence to the two\ndatasets, **correlate** did a perfect job.\n\n### Why correlate Works So Well\n\nThe insight that inspired **correlate** is this:\nunique keys in the two datasets are probably very good matches.\nLet's say the key `\"egyptian\"` maps to value *A1* in `dataset_a`\nand value *B1*  in `dataset_b`--and it *only* maps to those two\nvalues.  In that case, *A1* and *B1* are probably a match.\n\nThis leads to a virtuous cycle.\nLet's say the word `\"nickel\"` maps to two values in each of the\ntwo datasets: *A1* and *A2*, and *B1* and *B2*.\nWe could match those four values in two possible ways:\n*A1* -> *B1* and *A2* -> *B2*,\nor *A1* -> *B2* and *A2* -> *B1*.\nBut the key `\"egyptian\"` already showed that *A1* and *B1* are a\ngood match.  If we've already removed those two values from\nconsideration, we're left with *A2* -> *B2*.\nAnd now *that* looks like a good match, too.\n\nIn short, **correlate** capitalizes on the *relative uniqueness*\nof keys.\n\n\n## Getting Started With correlate\n\n### Requirements\n\n**correlate** requires Python 3.6 or newer.  It has no\nother dependencies.\n\nIf you want to run the **correlate** test suite,\nyou'll need to install the `rapidfuzz` package.\n\n\n### The High-Level Conceptual Model\n\nTo correlate two datasets with **correlate**,\nyou first create a `correlate.Correlator` object.\nThis object contains two members\n`dataset_a` and `dataset_b`; these represent\nthe two datasets you want to correlate.\n\nYou fill each dataset with *keys* and *values*.\n\nA *value* is (nearly) any Python object.\nEach value should represent one value from your dataset.\n**correlate** doesn't examine your values--they're completely\nopaque to **correlate**.\n\nA *key* is a Python object that represents some metadata\nabout a value.  Keys \"map\" to values; **correlate** examines\nkeys, using matching keys in the two datasets to\nmatch up the values between them.\n\nKeys are usually strings--for example, the individual words\nfrom the title of some movie, TV show, song, or book.\nBut keys don't have to be strings.  Instances of lots of\nPython data types can be used as keys.\n\nOnce you've filled in the `correlate.Correlator` object\nwith your data, you call its `correlate()` method.  This\ncomputes the matches.  It returns a\n`correlate.CorrelateResult` containing\nthose matches, and lists of any objects from\nthe two datasets that didn't get matched.\n\nThe matches are returned as a list of `correlator.CorrelatorMatch`\nobjects.  Each object contains three members:\n\n* `value_a`, a reference to an object from `dataset_a`,\n* `value_b`, a reference to an object from `dataset_b`,\n* and a floating-point `score`.\n\nEach `CorrelatorMatch` object tells you that\n**correlator** thinks that this `value_a`\nmaps to this `value_b`.  The `score` is a sort of mathematical\nconfidence level--it's a direct result of the keys and\nother metadata you provide to **correlate**.  The list of\nmatches is sorted by `score`--higher scores first, as higher\nscores represent higher confidence in the match.\n\nThat's the basics.  But **correlate** supports some very sophisticated\nbehavior:\n\n* When mapping a key to a value, you may specify an optional *weight*,\n  which represents the relative importance of this key.  The default\n  weight is 1.  Higher scores indicate a higher significance; a weight of\n  2 tells **correlate** that this key mapped to this value is twice as\n  significant.\n* A key can map to a value multiple times.  Each mapping can have its own weight.\n  * If both datasets are ordered, this ordering can optionally influence the match scores.\n  **correlate** calls this *ranking.*  Ranking is an attribute of values, not keys.\n* Keys can be \"fuzzy\", meaning two keys can be a partial match rather than a binary yes/no.\n  Fuzzy keys in **correlate** must inherit from a custom abstract base class called\n  `correlate.FuzzyKey`.\n\n## Sample Code And infer_mv\n\n**correlate** ships with some sample code for you to read,\nto get a feel for what it's like to work with.  Take a look\nat the scripts in the `tests` and `utilities` directories.\n\nIn particular, `utilities` contains a script called `infer_mv`.\n`infer_mv` takes a source directory and a list of files and directories\nto rename, and produces a mapping from the former to the latter.\nIn other words, when you run it, you're saying\n*\"here's a source directory and a list of files and directories to rename.\nFor each file in the list of things to rename, find the\nfilename in the source directory that most closely resembles that file,\nand rename the file so it's exactly like that other filename from the\nsource directory.\"*  (If you ask `infer_mv` to rename a directory,\nit renames all the files and directories inside that directory, recursively.)\n\nThis is useful if, for example, you have a directory where\nyou've already renamed the files the way you you like them, but then\nyou get a fresh copy from somewhere.  Simply run `infer_mv` with your\nexisting directory as the \"source directory\" and the fresh copy\nas the \"files\".  `infer_mv` will figure out how to rename the\nfresh files so they have the filenames how you like them.\n\nNote that `infer_mv` doesn't actually do the work of renaming!\nInstead, `infer_mv` prints out a *shell script* that, if executed,\nperforms the renames.\nWhy?  It's always a good idea to check over the output of **correlate**\nbefore you commit to it.\n\nYou should use `infer_mv` like so:\n\n    % infer_mv ../old_path *\n    # look at output, if it's all fine run\n    % infer_mv ../old_path * | sh\n\nOr you can direct the output of `infer_mv` into a file, then\nedit the file, then execute that.  Or something else!\nWhatever works for you!\n\n\n## Terminology And Requirements\n\n### Values\n\nValues are Python objects that represent individual elements of your two\ndatasets.  **correlate** doesn't examine values, and it makes very few\ndemands on them.  Here are the rules for values:\n\n* Values must support `==`.\n* Value comparison must be *reflexive,* *symmetric,* *transitive,* and *consistent*.\n  For all these examples, `a` `b` and `c` represent values:\n    * *reflexive:* A value must always compare as equal to itself.  `a == a` must evaluate to `True`.\n    * *symmetric:* If `a == b` is `True`, then `b == a` must also be `True`.\n    * *transitive:* If `a == b` is `True`, and `b == c` is `True`, then `a == c` must also be `True`.\n    * *consistent:* If `a == b` is `True`, it must always be `True`,\n       and if `a == b` is `False` it must always be `False`.\n\n### Keys\n\nKeys are Python objects that **correlate** uses to find matches between\nthe two datasets.  If a key maps to a value in `dataset_a` and also\na value in `dataset_b`, those two values might be a good match.\n\nKeys must obey all the same rules as values.  In addition,\nkeys must be *hashable.*\n\n#### Exact Keys\n\nAn \"exact\" key is what **correlate** calls any key that isn't a \"fuzzy\" key.\nStrings, integers, floats, complex, `datetime` objects--they're all fine to use\nas **correlate** keys, and instances of many more types too.\n\nWhen considering matches, exact keys are binary--either they're an exact match\nor they don't match at all.  If you need to understand partial matches you'll have\nto use \"fuzzy\" keys.\n\n\n#### Fuzzy Keys\n\nA \"fuzzy\" key is a key that supports a special protocol for performing \"fuzzy\"\ncomparisons--comparisons where the result can represent imperfect or partial matches.\n\nTechnically speaking, a **correlate** \"fuzzy\" key\nis an instance of a subclass of `correlate.FuzzyKey`.  If a key is an instance of\na subclass of that base class, it's a \"fuzzy\" key, and if it isn't, it's an \"exact\" key.\n\nFuzzy keys must follow the rules for keys above.\nAlso, the type of your fuzzy keys must also obey the same rules as keys;\nthey must be hashable, they must support `==`,\nand their comparison must be reflexive, symmetric, transitive, and consistent.\n\nIn addition, fuzzy keys must support a method called `compare` with this signature:\n`self.compare(other)`.  `other` will be another fuzzy key of the same type.  Your `compare`\nfunction should return a number between (and including) `0` and `1`, indicating how close\na match `self` is to `other`.  If `compare` returns `1`, it's saying this is a perfect\nmatch, that the two values are identical; if it returns `0`, it's a perfect mismatch,\ntelling **correlate** that the two keys have nothing in common.\n\n**correlate** requires that `compare` also obey the four mathematical constraints required\nof comparisons between keys.  In the following rules, `a` and `b` are fuzzy keys of the\nsame type.  `compare` must conform to these familiar four rules:\n\n* *reflexive:* `a.compare(a)` must return `1` (or `1.0`).\n* *symmetric:* If `a.compare(b)` returns *x*, then `b.compare(a)` must also return *x*.\n* *transitive:* If `a.compare(b)` returns *x*, and `b.compare(c)` returns *x*,\n  then `a.compare(c)` must also return *x*.\n* *consistent:* If `a.compare(b)` returns *x*, it must *always* return *x*.\n\nIt's important to note: fuzzy keys of two *different* types are automatically\nconsidered different to each other.  **correlate** won't even bother calling\n`compare()` on them--it automatically assigns the comparison a fuzzy score of `0`.\nThis is true even for subclasses; if you declare `class MyFuzzyNumber(correlate.FuzzyKey)`\nand also `class MyFuzzyInteger(MyFuzzyNumber)`,\n**correlate** will never compare an instance of `MyFuzzyNumber` and `MyFuzzyKey`\nto each other--it automatically assumes they have nothing in common.\n\n(Internally\n**correlate** stores fuzzy keys of different types segregated from each other.\nThis is a vital optimization!)\n\nOn a related note, **correlate** may optionally never\n*actually* call `a.compare(a)`, either.  That is, if the exact same key\nmaps to a value in both `dataset_a` and `dataset_b`, **correlate**\nis permitted to skip calling `compare()` and instead automatically\nassign the comparison a fuzzy score of `1`.  Currently if the situation\narose it *would* call `a.compare(a)`, but that wasn't true at various times\nduring development.\n\n\n## API\n\n`Correlator(default_weight=1)`\n\n> The correlator class.  `default_weight` is the weight used\n> when you map a key to a value without specifying an explicit weight.\n\n`Correlator.dataset_a`\n\n`Correlator.dataset_b`\n\n> Instances of `Correlator.Dataset` objects representing the two sets of data you want to correlate.  Initially empty.\n\n`Correlator.datasets`\n\n> A list containing the two datasets: `[dataset_a, dataset_b]`\n\n\n`Correlator.correlate(*,\n            minimum_score=0,\n            score_ratio_bonus=1,\n            ranking=BestRanking,\n            ranking_bonus=0,\n            ranking_factor=0,\n            reuse_a=False,\n            reuse_b=False)`\n\n> Correlates the two datasets.  Returns a `correlate.CorrelatorResult` object.\n>\n> `minimum_score` is the minimum permissible score for a match.  It must be\n> greater than or equal to 0.\n>\n> `score_ratio_bonus` specifies the weight of a bonus awarded to a match based on the ratio of\n> the actual score computed between these two values divided by the maximum possible score.\n>\n> `ranking` specifies which approch to computing ranking **correlate** should use.\n> The default value of `BestRanking` means **correlate** will try all approaches\n> and choose the one with the highest cumulative score across all matches.\n> Other values include `AbsoluteRanking` and `RelativeRanking`.\n>\n> `ranking_bonus` specifies the weight of the bonus awarded to a match\n> based on the proximity of the two values in their respective datasets, as specified\n> by their rankings.  The closer the two values are to the same position in their\n> respective datasets, the higher a percentage of the `ranking_bonus` will be awarded.\n>\n> `ranking_factor` specifies the ratio of the base score of a match that is multiplied\n> by the proximity of the two values in their respective datasets.  If you ues `ranking_factor=0.4`,\n> then a match only automatically keeps 60% of its original score; some percentage\n> of the remaining 40% will be re-awarded based on the proximity of the two values.\n>\n> (You can't use both a nonzero `ranking_bonus` and a nonzero `ranking_factor` in the\n> same correlation.  Pick at most one!)\n>\n> `reuse_a` permits values in `dataset_a` to be matched to more than one value in `dataset_b`.\n> `reuse_b` is the same but for values in `dataset_b` matching `dataset_a`.\n> If you set both reuse flags to True, the `correlate.CorrelatorResult.matches`\n> list returned will contain *every* possible match.\n\n`Correlator.print_datasets()`\n\n> Prints both datasets in a human-readable form.  Uses `self.print` to print,\n> which defaults to `print`.\n\n`Correlate.Dataset()`\n\n> The class for objects representing a dataset.  Behaves somewhat like\n> a write-only dict.\n\n`Correlator.Dataset.set(key, value, weight=default_weight)`\n\n> Adds a new correlation.\n>\n> You can use `Dataset[key] = value` as a shortcut for `Dataset.set(key, value)`.\n\n`Correlator.Dataset.set_keys(keys, value, weight=default_weight)`\n\n> Map multiple keys to a single value, all using the same weight.\n> `keys` must be an iterable containing keys.\n\n`Correlator.Dataset.value(value, *, ranking=None)`\n\n> Annotates a value with extra metadata.  Currently only one metadatum\n> is supported: `ranking`.\n>\n> `ranking` represents the position of this value in the dataset,\n> if the dataset is ordered.  `ranking` should be an integer\n> representing the ranking; if this value is the 19th in the dataset,\n> you should supply `ranking=19`.\n\n`CorrelatorResult()`\n\n> The class for objects returned by `Correlator.correlate()`.\n> Contains four members:\n>\n> * `matches`, a `list` of `CorrelatorMatch()` objects, sorted with highest score first\n> * `unmatched_a`, the `set` of values from `dataset_a` that were not matched\n> * `unmatched_b`, the `set` of values from `dataset_b` that were not matched\n> * `statistics`, a `dict` containing statistics about the correlation\n\n`CorrelatorResult.normalize(high=None, low=None)`\n\n> Normalizes the scores in `matches`.\n> When `normalize()` is called with its default values, it adjusts every score\n> so that they fall in the range `(0, 1]`.\n> If `high` is not specified, it defaults to the highest score in `matches`.\n> If `low` is not specified, it defaults to the `minimum_score` for the correlation.\n\n\n`CorrelatorMatch()`\n\n> The class for objects representing an individual match made\n> by `Correlator.correlate()`.\n> Contains three members:\n>\n> * `value_a`, a value from `dataset_a`.\n> * `value_b`, a value from `dataset_b`.\n> * `score`, a number representing the confidence in this match.\n>   The higher the `score`, the higher the confidence.\n>   Scores don't have a predefined intrinsic meaning; they're a result\n>   of all the inputs to **correlate.**\n\n`Correlator.str_to_keys(s)`\n\n> A convenience function.\n> Converts string `s` into a list of string keys using a reasonable approach.\n> Lowercases the string, converts some common punctuation into spaces, then splits\n> the string at whitespace boundaries.  Returns a list of strings.\n\n\n### Getting Good Results Out Of Correlate\n\nUnfortunately, you can't always expect perfect results with **correlate**\nevery time.  You'll usually have to play with it at least a little.\n\n#### Ranking\n\nNaturally, the first step with **correlate** is to plug in your data.\nI strongly encourage you to add ranking information if possible.\n\nIf the two datasets are ordered, and equivalent items should appear in\nroughly the same place in each of the two datasets, ranking information\ncan make a *sizeable* improvement in the quality of your matches.\nTo use ranking information, you set the `ranking` for each value in each dataset\nthat you can, and specify either `ranking_bonus` or `ranking_factor` when\nrunning `correlate()`.\nWhich one you use kind of depends on how much confidence you have in the\nordering of your datasets.  If you think your ranking information is pretty\naccurate, you should definitely use `ranking_factor`; this exerts a much\nstronger influence on the matches.\nIf you have a low confidence in the ordering of your datasets,\nchoose `ranking_bonus`, which only provides a little nudge.\n\n#### Minimum Score\n\nOnce you've plugged in all your data, you should run the correlation,\nprint out the result in sorted order with the best\nmatches on top, then scroll to the bottom and see what the *worst*\n5% or 10% of matches look like.\n\nIf literally all your matches are already perfect--congratulations!\nYou're *already* getting good results out of **correlate** and you\ncan stop reading here!  But if you're not that lucky, you've got more\nwork to do.\n\nThe first step in cleaning up **correlate's** output is usually\nto stop it from making bad matches by setting a `minimum_score`.\n\nWhen you have bad matches, it's usually because the two datasets don't map\nperfectly to each other.  If there's a value in `dataset_a` that really\nhas no good match in `dataset_b`, well, **correlate** doesn't really\nhave a way of knowing that.   So it may match that value to something\nanyway.\n\nLook at it this way: the goal of **correlate** is to find matches between\nthe two datasets.  If it's made all the good matches it can, and there's\nonly one item left in each of the the two datasets, and they have *anything*\nin common at all, **correlate** will match those two values together\nout of sheer desparation.\n\nHowever!  Bad matches like these tend to have a very low score.\nAnd usually all those bad matches are clumped together\nat the bottom.  There'll probably be an inflection point\nwhere the scores drop off significantly and the matches go from good to bad.\n\nThis is what `minimum_score` is for.  `minimum_score` tells **correlate**\nthe minimum permissible score for a match.  When you have a clump of bad\nmatches at the bottom, you simply set `minimum_score` to be somewhere\nbetween the highest bad match and the lowest good match--and\nyour problem is solved!\n\n(Technically, **minimum_score** isn't actually the *minimum* score.\nIt's ever-so-slightly *less* than the lowest\npermitted score.  As in, for a match to be considered viable, its score\nmust be *greater than* **minimum_score.**  The default value for\n**minimum_score** is 0, which means **correlate** will keep\nany match with a positive score.)\n\nUnfortunately it's hard to predict what to set `minimum_score` to in advance.\nIts value really depends on your data set--how many keys you have, how good\nthe matches are, what weights you're using, everything.  It's much more\nstraightforward to run the correlation, look over the output, find where the\ncorrelations turn bad, and set a minimum score.  With large data sets there's\ngenerally a sudden and obvious dropoff in score, associated with **correlate**\nmaking poor matches.  That makes it pretty easy: set the minimum score so it\nkeeps the last good match and forgets the rest.  But there's no predicting what\nthat score will be in advance--every data set is different, and it's really\nan emergent property of your keys and weights--so\nyou'll have to calibrate it correctly for each correlation you run.\n\n(Sometimes there are good matches mixed in with the bad ones at the bottom.\nWhen that happens, the first step is generally to fix *that,* so that the\nbad ones are all clumped together at the bottom.  I can't give any general-purpose\nadvice on what to do here; all I can say is, start experimenting with changes\nto your datasets.  Change your keys, adjust your weights, run the correlation\nagain and see what happens.  Usually when I do this, I realize something I can\ndo to improve the data I feed in to **correlate**, and I can fix the problem\nexternally.)\n\n#### Weights\n\nIf you're still not getting the results you want, the next adjustment you\nshould consider is increasing the weight of\nkeys that provide a clear signal.  If the datasets you're comparing\nhave some sort of unique identifier associated with each value--like\nan episode number, or release date--you should experiment with giving those\nkeys a heavier weight.  Heavily-weighted keys like this can help\n**correlate** zero in on the best matches right away.\n\nIt's up to you what that weight\nshould be; I sometimes use weights as heavy as 5 for super-important keys,\nwhich means this one single key will have the same weight as 5 normal\nkeys.  Note that a weight of 5 on the mapping in `dataset_a` and\n`dataset_b` means that, if those keys match, they'll have a base score\nof 25!  If that key only appears once in each dataset, that will almost\n*certainly* result in a match.\n\nBut weighting can be a dual-edged sword.  If your data has mistakes\nin it, a heavy weighting of this bad data magnifies those mistakes.  One bad\nheavily-weighted key on the wrong value can inflate the score of a bad match\nover the correct match.  And that can have a domino effect--if *A1* should match\nto *B1*, but it get mapped to *B43* instead, that means *B1* is probably\ngoing to get mismatched too.  Which deprives another value of its correct\nmatch.  And so on and so on and so on.\n\n#### Too-Common Keys\n\nSimilarly, if there are super-common keys that aren't going to help with\nthe correlation, consider throwing them away and not even feeding them in as\ndata.  Keys that map to most or all of the values in a dataset add little\nclarity, and will mainly serve just to make **correlate** slower.\nI usually throw away the word \"The\", and the name of the podcast or show.\n(When correlating filenames, I may throw away the file extension too.)\n\nThen again, often leaving them in won't hurt anything, and it can occasionally\nbe helpful!  The way **correlate** works, it considers multiple maps of a\nkey to a value as different things--if you map the key `\"The\"` to a value\ntwice, **correlate** understands that those are two separate mappings.\nAnd if there's only one value in each dataset that has two `\"The\"` mappings,\nthat can be a very strong signal indeed.  So it's really up to you.\nThrowing away largely-redundant keys is a speed optimization, but it\nshouldn't affect the quality of your matches.\n\n(A theoretical best of both worlds: for very common keys,\nconsider throwing away the *first* instance.  Though I haven't tried\nthis experiment myself.)\n\n#### Check Your Inputs\n\nAs always, it's helpful to make sure your code is doing what you intend it to.\nSeveral times I've goofed up the mechanism I use to feed data sets into\n**correlate**; for example, instead of feeding in words as keys, I've occasionally\nfed in the individual characters in those words as keys.  (Like, instead of\nthe single key `\"booze\"`, I accidentally fed in the five keys\n`'b'`, `'o'`, `'o'`, `'z'`, and `'e'`.)\nHowever, the **correlate** algorithm works so well,\nit still did a shockingly good job!  (Though it was a *lot* slower.)\n\nI've learned to double-check that I'm inputting the mappings and weights I meant\nto, with a debugger or with turning on the debug print statements in **correlate**\nitself.  Making sure you gave **correlate** the right data can make it not only\nmuch more accurate, it might make it faster too!\n\n**correlate** provides a function that prints out your datasets in a\nconvenient human-readable format: `Correlator.print_datasets()`.\n\n#### Normalize Strings\n\nWhen using strings as keys from real-world sources, I recommend you\n*normalize* the strings:\nlowercase the strings, remove most or all punctuation, break the strings up into\nindividual keys at word boundaries.  In the real world, punctuation\nand capitalization can both be inconsistent, so throwing it away can help\ndispel those sorts of inconsistencies.  **correlate**\nprovides a utility function called `correlate.str_to_keys()` that does this\nfor you--but you can use any approach you like.\n\nYou might also consider *interning* your strings.  In my limited experimentation\nthis provided a small but measurable speedup.\n\n#### Sharpen Your Fuzzy Keys\n\nIf you're using fuzzy keys, make sure you *sharpen* your fuzzy keys.\nFuzzy string-matching libraries have a naughty habit of scoring\nnot-very-similar strings as not *that* much less than almost-exactly-the-same\nstrings.  If you give that data unaltered to **correlate,** that \"everything\nlooks roughly the same\" outlook will be reflected in your results as\nmediocre matches.\n\nIn general, you want to force your fuzzy matches to extremes.\nTwo good techniques:\n\n* Specify a minimum score for fuzzy matches, and replace any fuzzy score\n  below that minimum with `0`.\n  * Possibly remap the remaining range to the entire range.\n    For example, if your minimum score is `0.6`, should you simply\n    return values from `0.6` to `1`?  Or should you stretch the scores\n    over the entire range with `(fuzzy_score - 0.6) / (1 - 0.6)`?\n    You may need to experiment with both to find out what works well for you.\n* Multiply your fuzzy score by itself.  Squaring or even cubing a fuzzy\n  score will preserve high scores and attenuate low scores.\n  Note that the scoring algorithm for fuzzy key matches already *cubes*\n  the fuzzy score.  Additional multiplying of the score by itself is\n  probably unnecessary in most cases.\n\n\n### What Do These Scores Mean?\n\nThe scores you seee in the results are directly related to the data you\ngave to **correlate**.  The scores really only have as much or as\nlittle meaning as you assign to them.\n\nIf you don't enjoy the unpredictable nature of **correlate** scores,\nconsider calling `normalize()` on your Correlate result object.\nThis normalizes the scores as follows: the highest score measured\nwill be adjusted to 1.0, `minimum_score` will be adjusted to 0.0,\nand every other score will be adjusted linearly between those two.\n\nMathematically:\n\n    score = the original score for this match\n    highest_score = highest score of any match\n    minimum_score = the minimum_score passed in to correlate()\n    delta = highest_score - minimum_score\n    normalized_score = (score - minimum_score) / delta\n\n\n## The Algorithm And The Code\n\n> If the implementation is hard to explain, it's a bad idea.\n> --*The Zen Of Python* by Tim Peters\n\nWhat follows is an exhaustive (and exhausting!) chapter\non the implementation of **correlate**.  This is here\npartially for posterity, partially because I like\nreading this sort of thing in other people's project,\nbut mostly to make it easier to reaquaint myself with\nthe code when I have to fix a bug three years from now.\n\n### The High-Level Overview\n\nAt the heart of **correlate** is a brute-force algorithm.  It's what\ncomputer scientists would call an *O*(n\u00b2) algorithm.\n\n**correlate** computes every possible \"match\"--every mapping of a value in\n`dataset_a` to a value in `dataset_b` where the two values have keys in common.\nFor exact keys, it uses set intersections to ignore pairs of values that have\nnothing in common, discarding early matches it knows will have a score of 0.\nSadly, it can't do that for fuzzy keys, which is why fuzzy keys tend to\nslow down  **correlate** even more.\n\nFor each key that matches between the two values, **correlate**\ncomputes a score.  It then adds all those scores together,\ncomputing the final cumulative score for the \"match\",\nwhich it may modifiy based on the various bonuses and factors.\nIt then iterates over these scores in sorted order, highest score first.\nFor every match where neither of the two values have been used\nin a match yet, it counts that as a \"match\" and adds it to the output.\n(This assumes `reuse_a` and `reuse_b` are both `False`.  Also, this\nis a little bit of an oversimplification; see the section about the\n*Match Boiler* below.)\n\nOne important detail: **correlate** is 100%\ndeterministic.  Randomness can creep in around the edges in Python\nprograms; for example, if you ever iterate over a dictionary,\nthe order you will see the keys will vary from run to run.\n**correlate** eliminates these sources of randomness.\nGiven the exact same inputs, it performs the same operations\nin the same order and produces the same result, every time.\n\nThere are a number of concepts involved with how the **correlate**\nalgorithm works, each of which I'll explain in exhausting detail\nin the following sub-sections.\n\n\n## **correlate's** Six Passes And Big-O Complexity\n\nHere's a high-level overview of how **correlate** performs\none correlation.\n**correlate** makes six passes over various sets of data.\n\n**Pass 1**\n\n> Iterate over both datasets and compute the \"streamlined\"\n> data.\n>\n> *Complexity:* *O*(n)\n\n\n**Pass 2**\n\n> Iterate over all keys and compute a sorted list of all matches\n> that have a nonzero score.  (The list represents a match with\n> a pair of indices into the lists of values for each dataset.)\n> This pass also performs all fuzzy key comparisons and caches\n> their results.\n>\n> *Complexity:* *O*(n\u00b2), for the fuzzy key comparisons step\n\n**Pass 3**\n\n> For every match with a nonzero score,\n> compute subtotals for matching all fuzzy keys.\n> We need to add some of these together to compute the final\n> scores for fuzzy key matches.\n>\n> *Complexity:* *O*(n\u00b2)\n\n**Pass 4**\n\n> For every match with a nonzero score:\n>\n> * compute the scores for matching all exact keys,\n> * finalize the scores for fuzzy key match scores,\n> * compute the bonuses (score_ratio_bonus, ranking),\n> * and store the result per-ranking.\n>\n> The score for each match is now finalized.\n>\n> *Complexity:* *O*(n\u00b2)\n\n**Pass 5**\n\n> For every ranking approach being used,\n> compute the final list of successful matches,\n> using the \"match boiler\" and \"greedy algorithm\".\n>\n> *Complexity:* *O*(n log n) (approximate)\n\n**Pass 6**\n\n> Choose the highest-scoring ranking approach,\n> compute unseen_a and unseen_b,\n> and back-substitute the \"indexes\" with their actual values\n> before returning.\n>\n> *Complexity:* *O*(n)\n\nThus the big-O notation for **correlate** overall is *O*(n\u00b2).\n\n\n### Rounds\n\nIf you call **correlate** as follows:\n\n    c = correlate.Correlator()\n    o = object()\n    c.dataset_a.set('a', o)\n    c.dataset_a.set('a', o)\n\nthen key `'a'` really *is* mapped to value `o` twice,\nand those two mappings can have different weights.\nIt's best to think of repeated keys like this as actually\nbeing two different keys--identical, but distinct.\nIt's like having files with the same filename in two\ndifferent directories.  They have the same *filename,* but\nthey're not the same *file.*\n\n**correlate** calls groups of these multiple mappings *\"rounds\"*.\nA \"round\" contains all the keys from the Nth time they were\nrepeated; round 0 contains every key, round 1 contains the second\ninstances of all the keys that were repeated twice, round 2 contains\nall the third instances of all the keys that were repeated three times,\netc.\nRounds are per-value, and there are as\nmany rounds as the maximum number of redundant mappings of\nany single key to any particular value in a dataset.\n\nNaturally, exact keys and fuzzy keys use a different method\nto determine whether or not something is \"the same key\".\nTechnically both types of keys use `==` to determine equivalence.\nHowever, fuzzy keys don't implement `__eq__`, so Python uses\nits default mechanism to determine equivalence, which is really\njust the `is` operator.  Therefore: exact keys are the same\nif `==` says they're the same, and (in practice) fuzzy keys\nare the same if and only if they're the same object.\n\n(Of course, you could implement `__eq__` when you write\nyour own fuzzy subclasses.  I don't know why you would bother.)\n\nConsider this example:\n\n    c = correlate.Correlator()\n    o = object()\n    c.dataset_a.set('a', o, weight=1)\n    c.dataset_a.set('a', o, weight=3)\n    c.dataset_a.set('a', o, weight=5)\n    c.dataset_a.set('b', o)\n    c.dataset_a.set('b', o)\n    c.dataset_a.set('c', o)\n\n    o2 = object()\n    c.dataset_b.set('d', o2)\n    c.dataset_b.set('d', o2)\n    c.dataset_b.set('e', o2)\n    c.dataset_b.set('f', o2)\n\nHere, the value `o` in `dataset_a` would have three rounds:\n\n* Round 0 would contain the keys `{'a', 'b', 'c'}`.\n* Round 1 would contain the keys `{'a', 'b'}`.\n* Round 2 would contain only one key,`{'a'}`.\n\nAnd `o2` in `dataset_b` would have only two rounds:\n\n* Round 0 would contain the keys `{'d', 'e', 'f'}`.\n* Round 1 would contain only one key,`{'d'}`.\n\nAgain, conceptually, the `\"a\"` in round 0 is a different key\nfrom the `\"a\"` in round 1, and so on.\n\nFor exact keys, rounds are directly matched iteratively\nto each other; the exact keys in round 0 for a value in\n`dataset_a` are matched to the round 0 exact keys for a value in\n`dataset_b`, round 1 in `dataset_a` is matched to\nround 1 in `dataset_b`, and so on.\nIf one side runs out of rounds early, you stop; if you compute\nthe intersection of a round and they have nothing in common,\nyou stop.\n\nOne invariant property: each subsequent round has a subset of\nthe keys before it.  The set of keys in round **N+1** *must*\nbe a subset of the keys in round **N**.\n\nWhat about weights?  Higher weights are sorted to lower rounds.\nThe weight for a key *k* in round **N-1** *must* be greater than\nor equal to the weight of *k* in round **N**.\nIn the above example, the `'a'` in round 0 has weight 5, in round 1\nit has weight 3, and in round 2 it has weight 1.\n(It doesn't matter what order you insert them in, **correlate**\ninternally stores the weights in sorted order.)\n\nThus, round 0 always contains every exact key mapped to\na particular value, with their highest weights.\n\nRounds can definitely help find the best matches.  If the\nkey `\"The\"` maps to most of your values once,\nthat's not particularly interesting, and it won't affect the scores\nvery much one way or another.  But if there's only one\nvalue in each dataset that `\"The\"` maps to *twice,*\nthat's a very strong signal indeed!  **correlate** does an\n*excellent* job of noticing unique-ness like that and factoring\nit into the scoring.\n\n### Streamlined Data\n\nThe **correlate** datasets store data in a format designed\nto eliminate redundancy and be easy to modify.  But this representation\nis inconvenient for performing the actual correlate.  Therefore,\nthe first step is to reprocess the data into a \"streamlined\" format.\nThis is an internal-only implementation detail, and in fact the data\nis thrown away at the end of each correlation.  As an end-user you'll\nnever have to deal with it.  It's only documented here just in case you\never need to understand the implementation of **correlate**.\n\nThis streamlined data representation is an important optimization.\nIt greatly speeds up computing a match between two values.  And it\nonly costs a little overhead, compared to all that matching work.\nConsider: if you have 600 values in `dataset_a` and 600 values in\n`dataset_b`, **correlate** will recompute 1,200 streamlined datasets.\nBut it'll then use it in as many as 360,000 comparisons!   Spending\na little time precomputing the data in a convenient format saves a\nlot of time in the long run.\n\n\n### The Scoring Formula, And Conservation Of Score\n\nFor each match it considers, **correlate** computes the intersection of\nthe keys that map to each of those two values in the two datasets,\nthen computes a score based on each of those key matches.\nThis scoring formula is the heart of **correlate**, and it was a key\ninsight--without it **correlate** wouldn't work nearly as well as it does.\n\nIn the abstract, it looks like this:\n\n    for value_a in dataset_a:\n        for value_b in dataset_b:\n            subtotal_score = 0\n            for key_a, weight_a that maps to value_a:\n                for key_b, weight_b that maps to value_b:\n                    score = value of key_a compared to key_b\n                    cumulative_a = the sum of all scores between key_a and all keys in dataset_b\n                    cumulative_b = the sum of all scores between key_b and all keys in dataset_a\n                    score_ratio_a = score / cumulative_a\n                    score_ratio_b = score / cumulative_b\n                    unweighted_score = score * score_ratio_a * score_ratio_b\n                    score_a = weight_a * unweighted_score_a\n                    score_b = weight_b * unweighted_score_b\n                    final_score = score_a * score_b\n                    subtotal_score += final_score\n\nTwo notes before we continue:\n\n* `key_a` and `key_b` must always be *per-round,* for a number\nof reasons, the least of which is because we use their\nweights in computing the `final_score`.\n\n* `subtotal_score` is possibly further adjusted by `score_ratio_bonus`\nand ranking, if used, but those will be discussed later.\n\nThis formula is how **correlate** assigns a mathematical score to\n\"uniqueness\".  The fewer values a key maps to in a dataset,\nthe higher it scores.  A key that's only mapped once in each\ndataset scores 4x higher than a key mapped twice in each dataset.\n\nThis scoring formula has a virtuous-feeling mathematical\nproperty I call *\"conservation of score\".*  Each key that\nyou add to a round in a dataset adds 1 to the total cumulatve\nscore of all possible matches; when you map a key to multiple\nvalues, you divide this score up evenly between those values.\nFor example, if the key `x` is mapped to three values in `dataset_a`\nand four values in `dataset_b`, each of those possible matches\nonly gets 1/12 of that key's score, and the final cumulative\nscore for all matches only goes up by 1/12.  So a key always\nadds 1 to the sum of all scores across all *possible* matches,\nbut only increases the actual final score by the amount of\nsignal it *actually* communicated.\n\nAlso, now you see why repeated keys can be so interesting.\nThey add 1 for *each round* they're in, but that score is only\ndivided by the number of values they're mapped to *in that round!*\n\n\n### Matching And Scoring Exact Keys\n\nThe \"streamlined\" data format for exact keys looks like this:\n\n    exact_rounds[index][round] = (set(d), d)\n\nThat is, it's indexed by \"index\" (which represents the value), then\nby round number.  That gives you a tuple containing a dict mapping\nkeys to weights, and a `set()` of just the keys.\n**correlate** uses `set.intersection()` (which is super fast!)\nto find the set of exact keys the two values have in common for that round.\nThe `len()` of this resulting set is the base cumulative score for that round,\nalthough that number is only directly useful in computing `score_ratio_bonus`.\n\nAlthough **correlate** uses the same scoring formula for both exact keys and\nfuzzy keys in an abstract sense, scoring matches between exact keys is much\nsimpler in practice.\n\nFirst, `key_a` and `key_b` are the same value.  That means we can rewrite the\nequation slightly:\n\n    cumulative_a = the sum of all scores between key_b and all keys in dataset_b\n    cumulative_b = the sum of all scores between key_a and all keys in dataset_a\n\nWhat changed?  We've swapped `key_a` and `key_b`.  Why?  It'll help, keep reading.\n\nSecond, `score` is always either `1` or `0`.  It's `1` when two keys are exactly\nthe same, and `0` otherwise.  If the base `score` for the match is `0`, then the\n`final_score` will be `0` and we can skip all of it.  So we only ever compute\na `final_score` when `score` is `1`.\n\nSince `score` is only ever used as a multiplier, we can remove it.\n\nThird, `cumulative_a` and `cumulative_b` are similarly easy to compute.\nThey're just the number of times that key is mapped to any value in\nthe relevant dataset, *in that round.*  These counts are precomputed\nand stored in the \"streamlined\" data.\n\nSo, finally: if you do the substitutions and drop out the constant `score`\nfactors, `final_score` for exact keys is computed like this:\n\n    final_score = (weight_a * weight_b) / (cumulative_a * cumulative_b)\n\nWhich we can rearrange into:\n\n    final_score = (weight_a / cumulative_b) * (weight_b / cumulative_a)\n\nAt the point we precompute the streamlined data for `dataset_a`,\nwe know `weight_a`, and we can compute `cumulative_b` because it only\nuses terms in `dataset_a`.  So we can pre-compute those terms,\nmaking the final math:\n\n    # when computing the streamlined data\n    precomputed_a = weight_a / cumulative_b\n    precomputed_b = weight_b / cumulative_a\n\n    # ...\n\n    # when computing the score for a matching exact key\n    final_score = precomputed_a * precomputed_b\n\n\n### Fuzzy Keys\n\nOnce upon a time, **correlate** was small and beautiful.\nBut that version only supported exact keys.\nBy the time fuzzy keys were completely implemented and feature-complete\nand working great, **correlate** was much more complex and... \"practical\".\nIt's because fuzzy keys introduce a lot of complex behavior, resulting in\ntricky scenarios that just don't arise with exact keys.\n\nConsider this example:\n\n>    Your two datasets represent lists of farms.  Both datasets list\n>    animals, but might have generic information (\"horse\") or might\n>    have specifics (\"Clydesdale\").  You create a fuzzy key subclass called\n>    `AnimalKey` that can handle matching these together;\n>    `AnimalKey(\"Horse/Clydesdale\")` matches `AnimalKey(\"Horse\")`,\n>    though with a score less than 1 because it isn't a perfect match.\n>\n>    The same farm, *Farm X*, is present in both datasets:\n>\n>    * In `dataset_a`, the keys `AnimalKey(\"Horse/Clydesdale\")`\n>    and `AnimalKey(\"Horse/Shetland Pony\")` map to Farm X.\n>\n>    * In `dataset_b`, the key `AnimalKey(\"Horse\")` maps to Farm X *twice.*\n>\n>    Question: should one of the `\"Horse\"` keys match `\"Horse/Clydesdale\"`,\n>    and the other `\"Horse\"` key match `\"Horse/Shetland Pony\"`?\n>\n>    Of course they should!\n\nThe scoring used for fuzzy keys is conceptually the same as the scoring\nfor exact keys, including the concept of \"rounds\".  In practice, fuzzy key\nscoring is much more complicated; there are some multipliers I elided\nin the description for exact keys because they're always 1, and some other\nthings that are easy to compute for exact keys that we must do the hard way\nfor fuzzy keys.  (There's a whole section at the end of this document about\nthe history of fuzzy key scoring in **correlate**, in case you're interested.)\n\nAlso, it's reasonable for a single value in a dataset to have multiple fuzzy\nkeys of the same type, which means that now we could have multiple keys\nin one dataset in contention for the same key in the other dataset.\nIn the above example with farms and horses, **correlate** will need to\ncompare both `AnimalKey(\"Horse/Clydesdale\")` and `AnimalKey(\"Horse/Shetland Pony\")`\nfrom `dataset_a` to `AnimalKey(\"Horse\")` in `dataset_b`.\n\nBut **correlate** doesn't add up every possible fuzzy score generated by a\nkey; when computing the final score, a fuzzy key is only matched against\none other fuzzy key.  If fuzzy keys *FA1* and *FA2* map to value *VA*\nin `dataset_a`, and fuzzy key *FB* maps to value *VB* in `dataset_b`,\n**correlate** will consider *FA1* -> *FB* and *FA2* -> *FB*\nand only keep the match with the highest score.  This match \"consumes\"\nthose two keys, and they can't be matched again.  (Again: when I say \"key\"\nhere, I mean \"this key in this round\".)\n\nWait!  It gets even *more* complicated!\nIt's entirely possible for a key in one round in `dataset_a` to be\nmatched to a key from a *different* round in `dataset_b`, again like the\nsample of the farms and horses above.  That's right: fuzzy keys can match\nkeys from *different rounds!*\n\nWhere exact keys use very precise \"rounds\", fuzzy keys\nrequire a more dynamic approach.  In essense, an unused key in round *N*\ncan conceptually \"survive\" to rounds *N+1*.  That's what the above example\nwith farms and ponies is showing us; in round 0, if `\"Horse/Clysedale\"`\nin `dataset_a` gets matched to `\"Horse\"` in `dataset_b`,\n`\"Horse/Shetland Pony\"` in `dataset_a` goes unmatched and continues on\nto round 1.  This also made scoring more complicated.  (For more on this,\ncheck out the test suite.  There's a regression test that exercises this\nexact behavior.)\n\nAfter a bunch of rewrites, I found the fastest way to compute fuzzy matches\nwas: for each fuzzy type the two values have in common, compute *all possible\nmatches* between all fuzzy keys mapping to the two values, even mixing\nbetween rounds.\n\nThe streamlined data for fuzzy keys looks like this:\n\n    fuzzy_types[index][type] = [\n                               [(key1, weight, round#0),  (key1, weight, round#1), ...],\n                               [(key2, weight, round#0),  (key2, weight, round#1), ...],\n                            ]\n\n\nThat is, they're indexed by index (a representation of the value),\nthen by fuzzy type.  That gets you a list of lists.  Each inner list\nis a list of tuples of\n\n    (key, weight, round_number)\n\nwhere `key` is always the same in all entries in the list, and\n`round_number` is always the same as that tuple's index in that list.\n\nWhen computing matches between fuzzy keys, **correlate** takes the\ntwo lists of lists and does nested `for` loops over them.  Since the\nkeys don't change, it only needs to look up the fuzzy score once.\nIf the fuzzy score is greater than 0, it stores the match in an\narray.\n\nOnce it's done with the fuzzy key matching, it sorts this array of matches,\nthen use the \"match boiler\" to reduce it down so that every per-round key\nis matched at most once.  (The \"match boiler\" is discussed later; for now\njust assume it's a magic function that does the right thing.  Though I had\nto ensure it was super-stable for this approach to work.)\n\nSorting these fuzzy key matches was tricky.  They aren't merely sorted\nby score; we also must ensure that fuzzy key matches from earlier rounds\nare *always* consumed before matches using that key in later rounds.\nSo we sort by a `sort_by` tuple, computed as follows:\n\n    key_a, round_a = key_and_round_a\n    key_b, round_b = key_and_round_b\n    fuzzy_score = key_a.compare(key_b)\n    lowest_round_number  = min(round_a, round_b)\n    highest_round_number = max(round_a, round_b)\n    sort_by = (fuzzy_score, -lowest_round_number, -highest_round_number)\n\nThe `-lowest_round_number` trick is the very clever bit.  This lets\nus sort with highest values last, which is what the \"match boiler\" wants.\nBut negating it means lower round numbers are now *higher* numbers, which\nlets us prefer keys with lower round numbers.\n\nIn terms of the abstract scoring formula,\n`score` is the fuzzy score, what's returned by calling the `compare()` method.\nAnd `cumulative_a` is the sum of all fuzzy `score` scores\nfor all matches using `key_a`.\n\n\n### Score Ratio Bonus\n\nThere's a \"bonus\" score calculated using `score_ratio_bonus`.  It's scored for the\noverall mapping of a value in `dataset_a` to a value in `dataset_b`.\nThis bonus is one of the last things computed for a match, just before ranking.\n\nThe bonus is calculated as follows:\n\n    value_a = a value from dataset_a\n    value_b = a value from dataset_b\n    actual_a = total actual score for all keys that map to value_a in dataset_a\n    actual_b = total actual score for all keys that map to value_b in dataset_b\n    possible_a = total possible score for all keys that map to value_a in dataset_a\n    possible_b = total possible score for all keys that map to value_b in dataset_b\n    bonus_weight = score_ratio_bonus * (actual_a + actual_b) / (possible_a + possible_b)\n\nThis bonus calculated with `score_ratio_bonus` clears up the\nambiguity when the set of keys mapping to one value is a subset of the keys\nmapping to a different value in the same dataset.  The higher percentage\nof keys that match, the larger this bonus will be.\n\nConsider this example:\n\n    c = correlate.Correlator()\n    c.dataset_a.set('breakin', X)\n\n    c.dataset_b.set('breakin', Y)\n    c.dataset_b.set_keys(['breakin', '2', 'electric', 'boogaloo'], Z)\n\nWhich is the better match, `X->Y` or `X->Z`?\nIn early versions of **correlate**, both matches got the exact same score.\nSo it was the luck of the draw as to which match **correlate** would choose.\n`score_ratio_bonus` disambiguates this scenario.  It awards a larger bonus\nto `X->Y` than it does to `X->Z`,  because a higher percentage of the keys\nmatched between `X` and `Y`.\nThat small boost is usually all that's needed to let **correlate**\ndisambiguate these situations and pick the correct match.\n\nTwo things to note.  First, when I say \"keys\", this is another situation\nwhere the same key mapped twice to the same value is conceptually considered\nto be two different keys.\nIn the example in the **Rounds** subsection above, where `value_a` is `o` and\n`value_b` is `o2`, `possible_a` would be 6 and `possible_b` would be 4.\n\nSecond, the scores used to compute `actual` and `possible` are *unweighted.*\nIf a match between two fuzzy keys resulted in a fuzzy score of `0.3`,\nthat adds `0.3` to both `actual_a` and `actual_b`, but each of those fuzzy\nkeys adds `1.0` to `possible_a` and `possible_b` respectively.\nModifiers like weights are ignored when computing `score_ratio_bonus`.\n\n\n### Choosing Which Matches To Keep: The \"Greedy Algorithm\" And The \"Match Boiler\"\n\nHere's the abstract problem: if you're presented with\na list of match objects called `matches`,\nwhere each match object `M` has three attributes `value_a`, `value_b`,\nand `score`, how would you compute an optimal subset of `matches`\nsuch that:\n\n* every discrete value of `value_a` and `value_b` appears only once, and\n* the sum of the `score` attributes is maximized?\n\nFinding the perfectly optimal solution would require computing every\npossible set of matches, then computing the cumulative score of that\nset, then keeping the set with the highest score.  Unfortuantely,\nthat algorithm is *O*(n\u207f),\nwhich is so amazingly expensive that we can't even consider it.\n(You probably want your results from **correlate** before our sun\nturns into a red giant.)  Instead, **correlate** uses a\ncomparatively cheap \"greedy\" algorithm to compute the subset.\nIt's not *guaranteed* to produce the optimal subset, but in\npractice it seems to produce optimal results on real-world data.\n\nHere's a short description of the **correlate** \"greedy\" algorithm:\n\n* Sort `matches` with highest score first.\n* For every match `M` in `matches`:\n    * if `value_a` hasn't been matched yet,\n    * and `value_b` hasn't been matched yet,\n        * keep `M` as a good match,\n        * remember that `value_a` has been matched,\n        * and remember that `value_b` has been matched.\n\nThe sorting uses Python's built-in sort (Timsort), so it's\n*O*(n log n).  It's implemented in C so it's pretty quick.\nThe `for` loop is *O*(n).\n\nThe bad news: late in development of **correlate** I\nrealized there was a corner case where odds are good the\ngreedy algorithm wouldn't produce an optimal result.\nThe good news: this had a relatively easy fix, and the\nfix didn't make **correlate** any slower in the general case.\n\nSo here's the corner case.  What if two matches in the\nlist are both viable, and they have the *same* score,\nand they have either `value_a` or `value_b` in common?\nIt's ambiguous as to which match the greedy algorithm\nwill choose.  But choosing the wrong one *could* result\nin less-than-optimal scoring in practice.\n\nHere's a specific example:\n\n* `dataset_a` contains fuzzy keys `fka1` and `fka2`.\n* `dataset_b` contains fuzzy keys `fkbH` and `fkbL`.\n  Any match containing `fkbH` has a higher score than any match containing `fkbL`.\n  (H = high scoring, L = low scoring.)\n* The matches`fka1->fkbH` and `fka2->fkbH` have the same score.\n* The match `fka1->fkbL` has a lower score than `fka2->fkbL`.\n\n**correlate** should prefer `fka2->fkbL` to `fka1->fkbL`.\nBut the greedy algorithm can only pick that match if it\npreviously picked `fka1->fkbH`.  And there's no guarantee\nthat it would!  If two items in the list have the same score,\nit's ambiguous which one the greedy algorithm would choose.\nTo handle this properly it needs to look ahead and experiment.\n\nMy solution for this is what I call the \"match boiler\", or the \"boiler\"\nfor short.  The boiler uses a hybrid approach.  By default,\nwhen the scores for matches are unique, it uses the \"greedy\"\nalgorithm.  If it encounters a run of items with matching scores,\nwhere any of those items have `value_a` or `value_b` in common,\nit recursively runs an experiment where it keeps each of those\nitems in turn.  It computes the score from each of these recursive\nexperiments and keeps the one with the highest score.\n\n(If two or more experiments have the same score, it keeps the first one\nit encountered with that score--but, since the input to the match boiler is\na list, sorted with highest scores to the end, technically it's the *last*\nentry in the list that produced the high-scoring experiment.)\n\nWith the \"match boiler\" in place, **correlate** seems to produce optimal\nresults even in these rare ambigous situations.\n\nI'm honestly not sure what the *big-O* notation is for the \"match boiler\".\nThe pathological worst case\nis *probably* on the order of *O*(n log n), where the `log n` component\nrepresents the recursions.\nIn this case, every match has the same score, and they're all connected to\neach other via having `value_a` and `value_b` in common.  I still don't\nthink the \"match boiler\" would be as bad as *O*(n\u00b2).\nThe thing is, sooner or later the recursive step would cut the\n\"group\" of \"connected items\" in half (see next section).  It's guaranteed\n*not* to recurse on every single item.\nSo I assert that roughly cuts the number of recursive\nsteps down to `log n`, in the pathological worst case that you would\nnever see in real-world data.\n\n#### Cheap Recursion And The \"Grouper\"\n\nBut wait!  It gets even more complicated!\n\nCompared to the rest of the algorithm, the recursive step is quite expensive.\nIt does reduce the domain of the problem at every step, so it's guaranteed\nto complete... someday.  But if we're not careful, it'll perform a lot\nof expensive and needless redundant calculations.  So there are a\nbunch of optimizations to the recursive step, mainly to do with the\ngroup of matches that have the same score.\n\nThe first step is to analyze these matches and boil them out\ninto \"connected groups\".  A \"connected group\" is a set of\nmatch objects where either each object has a `value_a` or a\n`value_b` in common with another object in the group.  These\nare interesting, because choosing one of the matches from these\ngroups will remove at least one other value from that group\nfrom consideration.\nThere's a utility function called `grouper()` that computes\nthese connected groups.  (`grouper()` only handles the case\nwhen `reuse_a == reuse_b == False`; there are alternate\nimplementations to handle the other possible cases.)\n\nThe second step is to take those \"connected groups\", and, for\nevery group containing only one match object, \"keep\" it immediately.\nWe already know we're keeping these, and it's cheaper to do it now.\n\nThe third step is to recurse over each of the values of the\nsmallest connected group of size 2 or more.  Why the smallest?\nBecause it's cheaper.  Let's say there are 50 items left\nin the list of matches.  At the top are 6 match objects\nwith the same score.  There's two groups: one of length 2,\nthe other of length 4.\nThe number of operations we'll perform by looping and\nrecursing is, roughly, **N** \u2022 **M**, where **N** is `len(group)`\nand **M** is `len(matches - group)`.  So which one is cheaper:\n\n* 2 x 48, or\n* 4 x 46?\n\nObviously the first one!\n\n(There's a theoretical opportunity for further optimization here:\nwhen recursing, if there's more than one connected group of length 2\nor greater, pass in the list of groups we *didn't*\nconsume to the recursive step.  That would save the recursive\ncall from re-calculating the connected groups.  In practice I imagine this\nhappens rarely, so handling it would result in a couple of `if`\nbranches that never get taken.  Also, it's a little more complicated\nthan it seems, because you'd have to re-use the `grouper()` on\nthe group you're examining before passing it down, because it might\nsplit it into two groups.  In practice it wouldn't speed up anybody's\ncorrelations, and it'd make the code more complicated.  So let's skip it.\nThe code is already more-or-less correct in these rare circumstances\nand that's good enough.)\n\n\n#### The Match Boiler Reused For Fuzzy Key Scoring\n\nOnce my first version of the \"match boiler\" was done, I realized I could reuse\nit for boiling down all fuzzy key matches too.  Fuzzy key matches already\nused basically the same \"greedy\" algorithm that were used for matches,\nand I realized the same corner case existed here too.\n\nMy first attempt was quite complicated, as the \"match boiler\" doesn't\nitself understand rounds.  I added a callback which it'd call every time it\nkept a match, which passed in the keys that got matched.  Since those keys\nwere now \"consumed\", I would inject new matches using those keys from\nsubsequent rounds (if any). This worked, but the code was complicated.\n\nAnd it got even more complicated later when I added the recursive step!\nI had to save and restore all the state of which fuzzy keys had been\nconsumed from which rounds.  I wound up building it into the subclass\nof `MatchBoiler`, which is part of why `MatchBoiler` clones itself\nwhen recursing.  This made the code cleaner but it was still clumsy\nand a bit slow.\n\nThe subsequent rewrite using the `sort_by` tuple was a big win all around:\nit simplified the code, it let me remove the callback, and it let the match\nboiler implicitly handle all the rounds without really understanding them.\n\nBut this is why it's so important that the boiler is super-stable.\nEarlier versions of the match boiler assumed it could re-sort the\ninput array any time it wanted.  But the array passed in was sorted\nby score *then* by round numbers--highest score is most important,\nlowest round number is second-most important.\nAnd the array is sorted with highest score, then lowest round number, last.\nWhen recursing, the match boiler has to prefer the *last* entry in its\ninput that produced the same score--otherwise, it might accidentally\nconsume a key from a later round before consuming that key from an\nearlier round.\n\nI didn't want to teach the boiler to understand this `sort_by` tuple.\nHappily, I didn't have to.  It wasn't much work to ensure that the boiler\nwas super-stable, and once that was true it always produced correct results.\nThis had the added benefit of being a bit faster, too!\n\n\n#### Theoretical Failings Of The Match Boiler\n\nEven with the boiler, you can still contrive scenarios where **correlate**\nwill produce arguably sub-optimal results.  The boiler only tries experiments\nwhere the matches have the same score.  But it's possible that the\ngreedy algorithm may find a local maximum that causes it to miss the\nglobal maximum.\n\nIf `A` and `B` are values in `dataset_a`, and `X` and `Y` are\nvalues in `dataset_b`, and the matches have these scores:\n\n    A->X == 10\n    A->Y == 9\n    B->X == 8\n    B->Y == 1\n\nIn this scenario, the boiler will pick `A->X`, which means it's\nleft with `B->Y`.  Total score: 11.  But if it had picked `A->Y`,\nthat means it would get to pick `B->X`, and the total score would be 17!\nAmazing!\n\nIs that better?  Your first reaction is probably \"of course!\".\nBut in an abstract, hypothetical scenario like this, it's\nhard to say for sure.\n\nAnyway I doubt this is a real problem in practice.  Ensuring **correlate**\nhandles the ambiguous scenario where items had identical scores is already\n\"gilding the lily\", considering how rare it happens with real-world data.\nAnd when would real data behave in this contrived way?  Why\nwould `A` score so highly against `X` and `Y`, but `B` scores\nhigh against `X` but low against `Y`?  If `B` is a good match for `X`,\nand `X` is a good match for `A`, and `A` is a good match for `Y`, then,\nby transitivity, with real-world data, `B` is probably a good match\nfor `Y`.\n\nI think pathological scenarios where the \"match boiler\" will fail like\nthis aren't realistic.  And the only way I can think of to fix it is\nwith the crushingly expensive *O*(n\u207f) algorithm.\nIt's just not worth it.  So, relax!  YAGNI.\n\n\n### Ranking\n\nRanking information can help a great deal.\nIf a value in `dataset_a` is near the beginning, and the order\nof values is significant, then we should prefer matching it to values\nin `dataset_b` near the beginning too.  Matching the first\nvalue in `dataset_a`\nagainst the last value in `dataset_b` is probably bad.\n\nConceptually it works as follows: when scoring a match,\nmeasure the distance between\nthe two values and let that distance influence the score.  The closer\nthe two values are to each other, the higher the resulting score.\n\nBut how do you compute that delta?  What do the ranking numbers mean?\n**correlate** supports two possible interpretations\nof the rankings, what we'll call *absolute* and *relative* ranking.\nThese two approaches differ in how they compare the ranking numbers,\nas follows:\n\n* *Absolute* ranking assmes the ranking numbers are the same\n  for both datasets.  `ranking=5` in `dataset_a` is a perfect\n  match to `ranking=5` in `dataset_b`.\n* *Relative* ranking assumes that the two datasets represent the\n  same range of data, and uses the ratio of the ranking of a value\n  divided by the highest ranking set in that dataset to compute\n  its relative position.  If the highest ranking we saw in a\n  particular dataset was `ranking=150`,\n  then a value that has `ranking=12` set is calculated to be 8%\n  of the way from the beginning to the end.  This percentage\n  is calculated similarly for both datasets, and the distance\n  between two values is the distance between these two percentages.\n\nFor example, if `dataset_a` had 100 items ranked 1 to 100,\nand `dataset_b` had 800 items ranked 1 to 800,\na value to `dataset_a` with `ranking=50` in *absolute* ranking\nwould be considered closest to a value in `dataset_b` with `ranking=50`,\nbut when using *relative* ranking\nit'd be considered closest to a value in `dataset_b` with `ranking=400`.\n\nWhich one does **correlate** use?  It's configurable with the `ranking`\nparameter to `correlate()`.  By default it uses \"best\" ranking.\n\"Best\" ranking means **correlate** will compute scores using *both*\nmethods and choose the approach with the highest overall score.\nYou can override this by supplying a different value to `ranking`\nbut this shouldn't be necessary.  (Theoretically it should be faster\nto use a specific ranking approach.  Unfortunately this hasn't been\noptimized yet, so using only one ranking doesn't really speed things up.)\n\n\nRanking is the last step in computing the score of a match.\nAs for how ranking affects the score, it depends on whether you\nuse `ranking_bonus` or `ranking_factor`.\n\nBoth approaches start with these four calculations:\n\n    semifinal_scores_sum = sum of all \"semifinal\" scores above\n    ranking_a = the ranking value computed for value_a\n    ranking_b = the ranking value computed for value_b\n    ranking_score = 1 - abs(ranking_a - ranking_b)\n\n`ranking_bonus` is then calculated per-match as follows:\n\n    bonus = ranking_score * ranking_bonus\n    final_score = semifinal_scores_sum + bonus\n\n`ranking_factor` is also calculated per-match, as follows:\n\n    unranked_portion = (1 - ranking_factor) * semifinal_scores_sum\n    ranked_portion = ranking_factor * semifinal_scores_sum * ranking_score\n    final_score = unranked_portion + ranked_portion\n\n(If you don't use either, the final score for the match is effectively\n`semifinal_scores_sum`.)\n\nObviously, `ranking` must be set on both values in both datasets to\nproperly compute `ranking_score`.  If it's not set on *both* values\nbeing considered for a match, **correlate** still applies\n`ranking_bonus` or `ranking_factor` as usual, but it skips the\ninitial four calculations and just uses a `ranking_score` of 0.\n\n\n## Final Random Topics\n\n### Debugging\n\nWhen all else fails... what next?\n\n**correlate** can optionally produce an enormous amount of debug output.\nThe main feature is showing every match it tests, and the score arrived\nat for that match, including every step along the way.  This log output\nquickly gets very large; even a comparison of 600x600 elements will produce\ntens of megabytes of output.\n\nUnfortunately, producing this much debugging output incurred a measurable\nperformance penalty--even when you had logging turned off!  It was mostly\nin computing the \"f-strings\" for the log, but also simply the calls to\nthe logging functions added overhead too.\n\nMy solution: by default, each of the debug print statements\nis commented out.\n**correlate** ships with a custom script preprocessor called\n`debug.py` that can toggle debugging on and off, by uncommenting and\nre-commenting the debug code.\n\nHow does it know which lines to uncomment?  Each line of the logging-only\ncode ends with the special marker \"`#debug`\".\n\nTo turn on this logging, run the `debug.py` script in the same directory\nas **correlate's** `__init__.py` script.  Each time you run it, it'll\ntoggle the debug print statements.\nNote that the debug feature in **correlate** requires Python 3.8 or higher,\nbecause it frequently uses the beloved \"equals sign inside f-strings\" syntax.\n\nBy default the logging is sent to stdout.  If you want to override where\nit's sent, write your own `print` function, and assign it to your\n`Correlator` object before calling `correlate()`.\n\nThe format of the log is undocumented and subject to change.  Good luck!\nThe main thing you'll want to do is figure out the \"index\" of the values\nin datasets a and b that you want to compare, then search for `\" (index_a) x (index_b) \"`.\nFor example, if the match you want to see is between value index 35 in `dataset_a`\nand value index 51 in `dataset_b`, search in the log for `\" 35 x 51 \"`.\n(The leading and trailing spaces means your search will skip over,\nfor example, `235 x 514`.)\n\n\n### Alternate Fuzzy Scoring Approaches That Didn't Work\n\nThe math behind fuzzy scoring is a bit surprising, at least to me.\nIf you boil down the formula to its constituent factors,\nyou'll notice one of the factors is `fuzzy_score` *cubed.*\nWhy is it *cubed?*\n\nThe simplest answer: that's the first approach that worked\nproperly.  To really understand why, you'll need to understand the\nhistory of fuzzy scoring in **correlate**--all the approaches\nI tried first that *didn't* work.\n\nInitially, the score for a fuzzy match was simply the fuzzy score\nmultiplied by the weights and other modifiers.\nThis was always a dumb idea; it meant fuzzy matches had *way* more\nimpact on the score than they should have.  This was particularly\ntrue when you got down to the last 10% or 20% of your matches,\nby which point the score contributed by exact keys had\nfallen off a great deal.  This approach stayed in for what is,\nin retrospect, an embarassingly long time; I'd convinced myself\nthat fuzzy keys were innately more *interesting* than exact keys,\nand so this comparative importance was fitting.\n\nOnce I realized how dumb that was, the obvious approach was to score\nthem identically to exact keys--divide the fuzzy score by the product\nof the number of keys this *could* have matched against in each\nof the two datasets.  This was obviously wrong right away.\nIn the \"YTJD\" test, every value had the same fuzzy keys, depending\non the test: every value always had a fuzzy date key, and depending\non the test it might have a fuzzy title key and/or a fuzzy episode number\nkey too.  So each of the 812 values in the first dataset had one\nfuzzy key for each type, and each of the 724 values in the second dataset\ndid too.  Even if we got a perfect fuzzy match, the maximum score\nfor a fuzzy match was now `1.0 / (812 * 724)` which is `0.0000017`.  So now\nwe had the opposite problem: instead of being super important, even a perfect\nfuzzy match contributed practically nothing to the final score.\n\nAfter thinking about it for a while,\nI realized that the exact key score wasn't *really* being\ndivided by the number of *keys* in the two datasets, per se;\nit was being divided by the total possible *score* contributed\nby that key in each of the two datasets.  So instead of\ndividing fuzzy scores by the number of keys, they should be divided\nby the cumulative fuzzy score of all matches involving those two keys.\nThat formula looks like\n`fuzzy_score / (sum_of_fuzzy_scores_for_key_in_A * sum_of_fuzzy_scores_for_key_in_B)`.\n\nThis was a lot closer to correct!  But this formula had a glaring new problem.\nLet's say that in your entire correlation, `dataset_a` only had one\nfuzzy key that maps to a single value,\nand `dataset_a` only had one fuzzy key that also only maps to a single value.\nAnd let's say the fuzzy score you get from matching those two keys\nis `0.000001`--a really terrible match.\nLet's plug those numbers into our formula, shall we.  We get `0.000001 / (0.000001 * 0.000001)`\nwhich is `1000000.0`.  A million!  That's crazy!  We've taken an absolutely\nterrible fuzzy match and inflated its score to be nonsensically high.\nClearly that's not right.\n\nThis leads us to the formula that actually works.  The insight here\nis that the same formula needs to work identically for exact keys.\nIf you take this formula and compute it where every `fuzzy_score`\nis 1 (or 0), it produces the same result as the formula for exact keys.\nSo the final trick is that we can multiply by `fuzzy_score` wherever we need\nto, because multiplying by 1 doesn't change anything.  That means\nthe resulting formula will still be consistent with the exact keys\nscoring formula.  And what worked was the formula where we multiply by\n`fuzzy_score` three times!\n\nHere again is the formula used to compute the score for a fuzzy match,\nsimplified to ignore weights and rounds:\n\n    value_a = a value from dataset_a\n    value_b = a value from dataset_b\n    key_a = a fuzzy key in dataset_a that maps to value_a\n    key_b = a fuzzy key in dataset_b that maps to value_b\n    fuzzy_score = the result of key_a.compare(key_b)\n    cumulative_a = the cumulative score of all successful matches between key_a and all fuzzy keys in dataset_b\n    cumulative_b = the cumulative score of all successful matches between key_b and all fuzzy keys in dataset_a\n    score_ratio_a = fuzzy_score / cumulative_a\n    score_ratio_b = fuzzy_score / cumulative_b\n    unweighted_score = fuzzy_score * score_ratio_a * score_ratio_b\n\nThe final trick really was realizing what `score_ratio_a` represents.\nReally, it represents the ratio of how much *this* fuzzy match for `key_a`\ncontributed to the sum of *all* fuzzy matches for `key_a`\nacross all successful matches in `dataset_a`.\n\n### Why correlate Doesn't Use The Gale-Shapley Algorithm\n\nA friend asked me if the problem **correlate** solves is isomorphic to the Stable Matching Problem:\n\nhttps://en.wikipedia.org/wiki/Stable_matching_problem\n\nBecause, if it was, I could use the Gale-Shapley algorithm:\n\nhttps://en.wikipedia.org/wiki/Gale%E2%80%93Shapley_algorithm\n\nI thought about this for quite a while, and I don't think the problem **correlate**\nsolves maps perfectly onto the stable matching problem.  **correlate** solves a problem that is:\n\n1. simpler,\n2. different, and\n3. harder.\n\nFor inputs that are valid for both Gale-Shapley and **correlate**, I assert that both\nalgorithms will return the same results, but **correlate** will be faster.\n\nIn all the following examples, `A`, `B`, and `C` are values in `dataset_a` (aka \"men\") and `X`, `Y`, and `Z` are values\nin `dataset_b` (aka \"women\").  The expression `A: XY` means \"`A` prefers `X` to `Y`\". The expression `A:X=1.5` means\n\"when matching `A` and `X`, their score is `1.5`\".  When I talk about Gale-Shapley, `dataset_a` will stand for the\nmen and `dataset_b` will stand for the women, which means `A` is a man and `X` is a woman.  Where we need to talk\nabout the matches themselves, we'll call them `P` and `Q`.\n\n#### How is it simpler?\n\nThe stable matching problem only requires a local ordering, where the preferences of any value in either dataset\nare disjoint from the orderings of any other value.  But **correlate** uses an absolute \"score\"--a number--to compute\nthese preferences, and this score is symmetric; if `A:X=1.5`, then `X:A=1.5` too.\n\nOn this related Wikipedia page:\n\nhttps://en.wikipedia.org/wiki/Lattice_of_stable_matchings\n\nwe find a classic example of a tricky stable matching problem:\n\n    A: YXZ\n    B: ZYX\n    C: XZY\n\n    X: BAC\n    Y: CBA\n    Z: ACB\n\nGale-Shapley handles this situation with aplomb.  Does **correlate**?  The answer is... this arrangement of constraints\njust can't *happen* with **correlate**, because it uses scores to establish its preferences, and the scores are symmetric.\nThere are nine possible pairings with those six values. It's impossible to assign a unique score to each of those nine\npairings such that the preferences of each value match those constraints.\n\n(I'm certain.  Not only did I work my way through it, I also wrote a brute-force program that tried every\npossible combination. 362,880 attempts later, I declared failure.)\n\n#### How is it different?\n\nOne minor difference: Gale-Shapley specifies that the two sets be of equal size; **correlate** permits the two sets to be\ndifferent sizes.  But extending Gale-Shapley to handle this isn't a big deal.  Simply extend the algorithm to say that,\nif the size of the two datasets are inequal, swap the datasets if necessary so that the \"men\" are the larger group.\nThen, if you have an unmatched \"man\" who iterates through all the \"women\" and nobody traded up to him, he remains\nunmatched.\n\nThe second thing: Gale-Shapley requires that every value in each dataset expresses a strictly ordered preference\nfor every value in the other dataset. But in **correlate**, two matches can have the same score.\n\nConsider this expression of a **correlate** problem:\n\n    A:X=100\n    A:Y=1\n\n    B:X=100\n    B:Y=2\n\nGale-Shapley as originally stated can't solve that problem, because X doesn't prefer A or B--it likes\nthem both equally.  It wouldn't be hard to extend Gale-Shapley to handle this; in the case where\nit prefers two equally, let it arbitrarily pick one.  For example, if X prefers A and B equally,\nsay \"maybe\" to the first one that asks, and then let that decide for you that you prefer A to B.\n\n#### How is it harder?\n\nHere's the real problem.\n\n**correlate** uses a numerical score to weigh the merits of each match, and seeks to\nmaximize the cumulative score across *all* matches. Gale-Shapley's goals are comparatively\nmodest--any match that's stable is fine. There may be multiple stable matchings; Gale-Shapley\nconsiders them all equally good.\n\nIn practice, I think if you apply the original Gale-Shapley algorithm to an input data set\nwhere the matches have numerical scores, it *would* return the set of matches with the\nhighest cumulative score.  In thinking about it I haven't been able to propose a situation\nwhere it wouldn't.  The problem lies in datasets where two matches have the *same* score--which\nthe original Gale-Shapley algorithm doesn't allow.\n\nEnsuring that **correlate** returns the highest cumulative score in this situation\nrequired adding the sophisticated recursive step to the \"match boiler\".  We'd have to make\na similar modification to Gale-Shapley, giving it a recursive step.  Gale-Shapley is\nalready *O*(n\u00b2); I think the modified version would be *O*(n\u00b2 log n).\n(But, like **correlate**, this worst-case shouldn't happen with real-world data.)\nAnyway, a modified Gale-Shapley that works for all **correlate** inputs is definitely\nmore expensive than what **correlate** has--or what it needs.\n\n#### Mapping Gale-Shapley To The Correlate Greedy Algorithm\n\nAgain, the set of valid inputs for **correlate** and Gale-Shapley aren't\nexactly the same.  But there's a lot of overlap.  Both algorithms can\nhandle an input where:\n\n* every match between a man `A` and a woman `X` is assigned a numerical score,\n* every operation involving any particular man `A` has a unique score,\n* and also for every woman `X`,\n* and there are exactly as many men as there are women.\n\nI assert that, for these mutually acceptable inputs, both algorithms\nproduce the same result.  Here's an informal handwave-y proof.\n\nFirst, since Gale-Shapley doesn't handle preferring two matches equally,\nwe'll only consider datasets where all matches have a unique score.\nThis lets us dispense with the match boiler's \"recursive step\", so all we\nneed is the comparatively simple \"greedy algorithm\".  (Again: this\n\"greedy algorithm\" is much cheaper than Gale-Shapley, but as I'll show,\nit's sufficient for the simple problem domain we face here.)\n\nSo let's run Gale-Shapley on our dataset.  And every time we perform\nan operation, we write it down--we write down \"man `A` asked woman `X`\"\nand whether her reply was *maybe* or *no*.\n\nObserve two things about this list:\n\n* First, order is significant in this list of operations.  If you change\nthe order in which particular men ask particular women, the pattern of\nresulting *maybe* and *no* responses will change.\n\n* Second, the *last* maybe said by each woman is always, effectively, a *yes*.\n\nIterate backwards through this list of operations, and the first time you\nsee any particular woman reply with *maybe*, change that answer to a *yes.*\n\nNext, observe that we can swap any two adjacent operations--with one important\ncaveat.  We must maintain an invariant: for every woman `X` for every operation\ncontaining `X` that happens after `X` says *yes*, `X` must say *no.*\n\nThus, if there are two adjacent operations `P` and `Q`, where `P`\nis currently first, and we want to swap them so `Q` is first,\nand if the following conditions are all true:\n\n* The same woman `X` is asked in both `P` and `Q`.\n* In `Q` the woman `X` says either *maybe* or *yes.*\n* In `P` the woman `X` says *maybe.*\n\nThen we can swap `P` and `Q` if and only if we change `X`'s\nresponse in `P` to *no.*\n\nNow that we can reorder all the operations, let's sort the\noperations by score, with the highest score first.\nLet's call the operation with the highest score `P`,\nand say that it matches man `A` with woman `X`.\n\nWe now know the following are true:\n\n* `X` is the first choice of `A`.  Therefore `A` will ask\n  `X` first.\n* `A` is the first choice of `X`.  Therefore `X` is\n  guaranteed to have said *yes*.\n\nSince the first operation `P` is guaranteed to be a *yes*,\nthat means that every subsequent operation involving either\n`A` or `X` must be a *no*.\n\nWe now iterate down the list to find an operation `Q`\ninvolving man `B` and woman `Y`. We define `Q` as the\nfirst operation such that:\n\n* `Q != P`, and therefore `Q` is after `P` in our ordered list of operations,\n* `B != A`, and\n* `Y != X`.\n\nBy definition `Q` must also be a *yes*.  If there are any operations\nbetween `P` and `Q`, these operations involve either `A` or `X`.\nTherefore they must be *no*.  Therefore `Q` represents the\nhighest remaining preference for both `B` and `Y`.\n\nObserve that the whole list looks like this.  Every *yes* is\nthe first operation for both that man and that woman in which\nthey weren't paired up with a woman or man (respectively) that\nhad already said *yes* to someone else.\n\nTherefore this list of operations now resembles the operations\nperformed by the **correlate** \"greedy\" algorithm, more or less.\nIt sorts the matches by score, then iterates down it.  For every\nman `A` and woman `X`, if neither `A` nor `X` has been matched yet,\nit matches `A` and `X` and remembers that they've been matched.\n\nIt's possible that there's minor variation in the list of\noperations; any operation involving any man or any woman\n*after* they've been matched with a *yes* is extraneous.\nSo you can add or remove them all you like without affecting\nthe results.\n\n\n## Version History\n\n**0.8.1**\n\nFixed compatibility with Python 3.6.  All I needed to do was\nremove some *equals-sign-in-f-strings* usage in spots.\n\n**0.8**\n\nThe result of loving hand-tuned optimization: **correlate** version 0.8\nis now an astonishing *19.5%* faster than version 0.7--and *27.3%* faster\nthan version 0.5!\n\nThe statistics have been improved, including some useful timing information.\nThis really demonstrates how much slower fuzzy keys are.\n\n(To see for yourself, run `python3 tests/ytjd.test.py -v` and compare\nthe slowest test to the fastest, using the same corpus.  On my computer\nthe test without fuzzy keys is 14x faster than the one that uses\nfuzzy keys for everything!)\n\n**0.7**\n\nCareful micro-optimizations for both exact and fuzzy key\ncode paths have made **correlate** up to 7.5% faster!\n\nThe `MatchBoiler` was made even more ridiculously stable.\nIt should now always:\n\n* return `results` in the same order they appeared in in `matches`, and\n* prefer the *last* equivalent item when two or more items\n  produce the same cumulative score.\n\n**0.6.1**\n\nBugfix for major but rare bug: if there are multiple\ngroups of `len() > 1` of \"connected\" match objects with\nthe same score, the match boiler would only keep the\nsmallest one--the rest were accidentally discarded.\n(`match_boiler_2_test()` was added to `tests/regression_test.py`\nto check for this.)\n\n**0.6**\n\nBig performance boost in \"fuzzy boiling\"!  Clever sorting of fuzzy matches,\nand improvements in the stability (as in \"stable sort\") of `MatchBoiler`,\nallowed using an unmodified boiler to process fuzzy matches.  This allowed\nremoval of `FuzzyMatchBoiler` and the `MatchBoiler.filter()` callback mechanism.\n\nMinor performance improvement in `MatchBoiler`: when recursing, find the\nsmallest group of connected matches with the same score,\nand only recursively check each of those,\nrather than all possibly-connected matches with the same score.\n\nRemoved `key_reuse_penalty_factor`.\nIn the early days of **correlate**, it didn't understand rounds; if you mapped the same\nkey to the same value twice, it only remembered one mapping, the one with the\nhighest weight.  Later I added rounds but they didn't seem to add much signal.\nI thought redundant keys were uninteresting.  So I added `key_reuse_penalty_factor`.\nThat let you turn down the signal they provided, in case it\nwas adding more noise than actual useful signal.\nIt wasn't until the realization that `key->value` in round 0 and `key->value`\nin round 1 were conceptually *two different keys* that I really understood\nhow redundant mappings of the same key to the same value should work.  And\nonce rounds maintained distinct counts of `keys / scores` for the scoring\nformula, redundant keys in different rounds became *way* more informative.\nI now think `key_reuse_penalty_factor` is dumb and worse than useless and\nI've removed it.  If you think `key_reuse_penalty_factor` is useful,\nplease contact me and tell me why!  Or, quietly just pre-multiply it into\nyour weights.\n\n\nThe cumulative effect: a speedup of up to 30% in fuzzy match boiling,\nand up to 5% on YTJD tests using a lot of fuzzy keys.  Match boiling got\nslightly faster too.\n\n**0.5.1**\n\nBugfix release.  In the original version, if a match didn't have any matches between\nfuzzy keys (with a positive score), it ignored the weights of its exact keys and just\nused the raw exact score.\n\n**0.5**\n\nInitial public release.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/larryhastings/correlate/", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "correlate", "package_url": "https://pypi.org/project/correlate/", "platform": "", "project_url": "https://pypi.org/project/correlate/", "project_urls": {"Homepage": "https://github.com/larryhastings/correlate/"}, "release_url": "https://pypi.org/project/correlate/0.8.1/", "requires_dist": null, "requires_python": ">=3.6", "summary": "Correlates two sets of data by matching", "version": "0.8.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>correlate</h1>\n<h2>A clever brute-force correlator for kinda-messy data</h2>\n<h5>Copyright 2019-2020 by Larry Hastings</h5>\n<h2>Overview</h2>\n<p>Let's say you have two sets of data that really represent the same data,\njust in different forms.\nAs an example, maybe your first dataset is Wikipedia's list of all episodes of a TV\nshow, and your second dataset is a directory full of video files of\nthat TV show.  The episode <em>\"Neurostim\"</em> appears in both datasets but\nit's represented differently in each.</p>\n<p>Now let's say you want to match them up with each other--you want\nto match up the values in the first dataset with their equivalents\nin the second dataset. The thing is, it's real-world data--and\nit's probably a little messy.  Perhaps the two datasets aren't in\nthe exact same order.  And while some matches are obvious, others are less so.\nMaybe one dataset has some values not present in the other and vice-versa.</p>\n<p>What do you do?  Sure, you could correlate the two datasets by hand.\nBut what if the datasets are really big?\nAnd what do you do if they get updated?  Do you want to update the\ncorrelation by hand too?</p>\n<p><strong>correlate</strong> solves this problem for you.  It correlates values between\ntwo messy but strongly-related datasets.</p>\n<p>How it works: you submit your two datasets to\n<strong>correlate</strong>, showing it each value and mining the data and metadata for\n\"keys\" that map to that value.  You then set <strong>correlate</strong> to work.\nIt thinks for a while, then produces its best guess as to how to match\nthe two sets.  And its best guess is... hey, that's pretty good!</p>\n<p>In essense, <strong>correlate</strong> uses the uniqueness of keys as clues to find\nits matches.  If there's a key present in both datasets, but it only maps\nto one value in each dataset, odds are good that those two values\nshould be matched together.</p>\n<p>That's the basics.  <strong>correlate</strong> also supports some advanced features:</p>\n<ul>\n<li>A key mapping can optionally specify a <em>weight</em>.</li>\n<li>You can map a key <em>multiple times.</em></li>\n<li>Keys can be <em>fuzzy keys,</em> keys that may only partially match each other.</li>\n<li>The order of values can inform the matches; <strong>correlate</strong> calls this <em>ranking.</em></li>\n</ul>\n<h3>Quick Start</h3>\n<p>This code:</p>\n<pre><code>import correlate\n\nc = correlate.Correlator()\na, b = c.datasets\n\na.set(\"this\", \"greg\")\na.set(\"is\", \"greg\")\na.set(\"Greg\", \"greg\", weight=5)\na.set_keys(\"Carol over here\".split(), \"carol\")\na.set_keys(\"My name is Tony\".split(), \"tony\")\na.set_keys(\"Hi I'm Steve\".split(), \"steve\", weight=2)\n\nb.set_keys(\"gosh my name is Greg\".split(), \"Greg\")\nb.set_keys(\"Carol is my name\".split() , \"Carol\")\nb.set_keys(\"Pretty sure I'm still Tony\".split(), \"Tony\")\nb.set_keys(\"I'm Steve\".split(), \"Steve\")\n\nresult = c.correlate()\nfor match in result.matches:\n    print(f\"{match.score:1.3f} {match.value_a:&gt;5} -&gt; {match.value_b}\")\n</code></pre>\n<p>produces this output:</p>\n<pre><code>5.750  greg -&gt; Greg\n3.800 steve -&gt; Steve\n1.286 carol -&gt; Carol\n1.222  tony -&gt; Tony\n</code></pre>\n<h3>A Real-Life Example</h3>\n<p>There's a podcast I like.  I download it as MP3 files\nusing an RSS feed, 1990s-style. But the metadata in the RSS\nfeed is junk--the episode titles are inconsistent,\nand the episode numbers are almost wholly absent.</p>\n<p>This podcast also has a\nlist of episodes on its website. This data is <em>much</em> cleaner,\nincluding nice proper (unique!) episode numbers.  And it's easily\nscraped.  But it's still not perfect.\nThe two lists of episodes aren't exactly the same, and even the episodes\nthat are present in both are sometimes reordered.</p>\n<p>Obviously, I want to take the MP3s from the RSS feed,\nand match them up with the nice clean metadata scraped from the website.\nThis gets me the best of both worlds.</p>\n<p>But there are more than <em>six hundred</em> episodes of this\nparticular podcast!  Matching those by hand would be a <em>lot</em> of work.\nAnd we get a new episode every week.\nAnd sometimes they actually add back in old episodes, or update the\nmetadata on old episodes--changes which would mess up any hand-built\nordering.  And I might want to listen to more than one podcast from\nthis same website someday!\nSo I really didn't want to do all of this by hand.</p>\n<p>Happily, after applying just a bit of intelligence to the two\ndatasets, <strong>correlate</strong> did a perfect job.</p>\n<h3>Why correlate Works So Well</h3>\n<p>The insight that inspired <strong>correlate</strong> is this:\nunique keys in the two datasets are probably very good matches.\nLet's say the key <code>\"egyptian\"</code> maps to value <em>A1</em> in <code>dataset_a</code>\nand value <em>B1</em>  in <code>dataset_b</code>--and it <em>only</em> maps to those two\nvalues.  In that case, <em>A1</em> and <em>B1</em> are probably a match.</p>\n<p>This leads to a virtuous cycle.\nLet's say the word <code>\"nickel\"</code> maps to two values in each of the\ntwo datasets: <em>A1</em> and <em>A2</em>, and <em>B1</em> and <em>B2</em>.\nWe could match those four values in two possible ways:\n<em>A1</em> -&gt; <em>B1</em> and <em>A2</em> -&gt; <em>B2</em>,\nor <em>A1</em> -&gt; <em>B2</em> and <em>A2</em> -&gt; <em>B1</em>.\nBut the key <code>\"egyptian\"</code> already showed that <em>A1</em> and <em>B1</em> are a\ngood match.  If we've already removed those two values from\nconsideration, we're left with <em>A2</em> -&gt; <em>B2</em>.\nAnd now <em>that</em> looks like a good match, too.</p>\n<p>In short, <strong>correlate</strong> capitalizes on the <em>relative uniqueness</em>\nof keys.</p>\n<h2>Getting Started With correlate</h2>\n<h3>Requirements</h3>\n<p><strong>correlate</strong> requires Python 3.6 or newer.  It has no\nother dependencies.</p>\n<p>If you want to run the <strong>correlate</strong> test suite,\nyou'll need to install the <code>rapidfuzz</code> package.</p>\n<h3>The High-Level Conceptual Model</h3>\n<p>To correlate two datasets with <strong>correlate</strong>,\nyou first create a <code>correlate.Correlator</code> object.\nThis object contains two members\n<code>dataset_a</code> and <code>dataset_b</code>; these represent\nthe two datasets you want to correlate.</p>\n<p>You fill each dataset with <em>keys</em> and <em>values</em>.</p>\n<p>A <em>value</em> is (nearly) any Python object.\nEach value should represent one value from your dataset.\n<strong>correlate</strong> doesn't examine your values--they're completely\nopaque to <strong>correlate</strong>.</p>\n<p>A <em>key</em> is a Python object that represents some metadata\nabout a value.  Keys \"map\" to values; <strong>correlate</strong> examines\nkeys, using matching keys in the two datasets to\nmatch up the values between them.</p>\n<p>Keys are usually strings--for example, the individual words\nfrom the title of some movie, TV show, song, or book.\nBut keys don't have to be strings.  Instances of lots of\nPython data types can be used as keys.</p>\n<p>Once you've filled in the <code>correlate.Correlator</code> object\nwith your data, you call its <code>correlate()</code> method.  This\ncomputes the matches.  It returns a\n<code>correlate.CorrelateResult</code> containing\nthose matches, and lists of any objects from\nthe two datasets that didn't get matched.</p>\n<p>The matches are returned as a list of <code>correlator.CorrelatorMatch</code>\nobjects.  Each object contains three members:</p>\n<ul>\n<li><code>value_a</code>, a reference to an object from <code>dataset_a</code>,</li>\n<li><code>value_b</code>, a reference to an object from <code>dataset_b</code>,</li>\n<li>and a floating-point <code>score</code>.</li>\n</ul>\n<p>Each <code>CorrelatorMatch</code> object tells you that\n<strong>correlator</strong> thinks that this <code>value_a</code>\nmaps to this <code>value_b</code>.  The <code>score</code> is a sort of mathematical\nconfidence level--it's a direct result of the keys and\nother metadata you provide to <strong>correlate</strong>.  The list of\nmatches is sorted by <code>score</code>--higher scores first, as higher\nscores represent higher confidence in the match.</p>\n<p>That's the basics.  But <strong>correlate</strong> supports some very sophisticated\nbehavior:</p>\n<ul>\n<li>When mapping a key to a value, you may specify an optional <em>weight</em>,\nwhich represents the relative importance of this key.  The default\nweight is 1.  Higher scores indicate a higher significance; a weight of\n2 tells <strong>correlate</strong> that this key mapped to this value is twice as\nsignificant.</li>\n<li>A key can map to a value multiple times.  Each mapping can have its own weight.\n<ul>\n<li>If both datasets are ordered, this ordering can optionally influence the match scores.\n<strong>correlate</strong> calls this <em>ranking.</em>  Ranking is an attribute of values, not keys.</li>\n</ul>\n</li>\n<li>Keys can be \"fuzzy\", meaning two keys can be a partial match rather than a binary yes/no.\nFuzzy keys in <strong>correlate</strong> must inherit from a custom abstract base class called\n<code>correlate.FuzzyKey</code>.</li>\n</ul>\n<h2>Sample Code And infer_mv</h2>\n<p><strong>correlate</strong> ships with some sample code for you to read,\nto get a feel for what it's like to work with.  Take a look\nat the scripts in the <code>tests</code> and <code>utilities</code> directories.</p>\n<p>In particular, <code>utilities</code> contains a script called <code>infer_mv</code>.\n<code>infer_mv</code> takes a source directory and a list of files and directories\nto rename, and produces a mapping from the former to the latter.\nIn other words, when you run it, you're saying\n<em>\"here's a source directory and a list of files and directories to rename.\nFor each file in the list of things to rename, find the\nfilename in the source directory that most closely resembles that file,\nand rename the file so it's exactly like that other filename from the\nsource directory.\"</em>  (If you ask <code>infer_mv</code> to rename a directory,\nit renames all the files and directories inside that directory, recursively.)</p>\n<p>This is useful if, for example, you have a directory where\nyou've already renamed the files the way you you like them, but then\nyou get a fresh copy from somewhere.  Simply run <code>infer_mv</code> with your\nexisting directory as the \"source directory\" and the fresh copy\nas the \"files\".  <code>infer_mv</code> will figure out how to rename the\nfresh files so they have the filenames how you like them.</p>\n<p>Note that <code>infer_mv</code> doesn't actually do the work of renaming!\nInstead, <code>infer_mv</code> prints out a <em>shell script</em> that, if executed,\nperforms the renames.\nWhy?  It's always a good idea to check over the output of <strong>correlate</strong>\nbefore you commit to it.</p>\n<p>You should use <code>infer_mv</code> like so:</p>\n<pre><code>% infer_mv ../old_path *\n# look at output, if it's all fine run\n% infer_mv ../old_path * | sh\n</code></pre>\n<p>Or you can direct the output of <code>infer_mv</code> into a file, then\nedit the file, then execute that.  Or something else!\nWhatever works for you!</p>\n<h2>Terminology And Requirements</h2>\n<h3>Values</h3>\n<p>Values are Python objects that represent individual elements of your two\ndatasets.  <strong>correlate</strong> doesn't examine values, and it makes very few\ndemands on them.  Here are the rules for values:</p>\n<ul>\n<li>Values must support <code>==</code>.</li>\n<li>Value comparison must be <em>reflexive,</em> <em>symmetric,</em> <em>transitive,</em> and <em>consistent</em>.\nFor all these examples, <code>a</code> <code>b</code> and <code>c</code> represent values:\n<ul>\n<li><em>reflexive:</em> A value must always compare as equal to itself.  <code>a == a</code> must evaluate to <code>True</code>.</li>\n<li><em>symmetric:</em> If <code>a == b</code> is <code>True</code>, then <code>b == a</code> must also be <code>True</code>.</li>\n<li><em>transitive:</em> If <code>a == b</code> is <code>True</code>, and <code>b == c</code> is <code>True</code>, then <code>a == c</code> must also be <code>True</code>.</li>\n<li><em>consistent:</em> If <code>a == b</code> is <code>True</code>, it must always be <code>True</code>,\nand if <code>a == b</code> is <code>False</code> it must always be <code>False</code>.</li>\n</ul>\n</li>\n</ul>\n<h3>Keys</h3>\n<p>Keys are Python objects that <strong>correlate</strong> uses to find matches between\nthe two datasets.  If a key maps to a value in <code>dataset_a</code> and also\na value in <code>dataset_b</code>, those two values might be a good match.</p>\n<p>Keys must obey all the same rules as values.  In addition,\nkeys must be <em>hashable.</em></p>\n<h4>Exact Keys</h4>\n<p>An \"exact\" key is what <strong>correlate</strong> calls any key that isn't a \"fuzzy\" key.\nStrings, integers, floats, complex, <code>datetime</code> objects--they're all fine to use\nas <strong>correlate</strong> keys, and instances of many more types too.</p>\n<p>When considering matches, exact keys are binary--either they're an exact match\nor they don't match at all.  If you need to understand partial matches you'll have\nto use \"fuzzy\" keys.</p>\n<h4>Fuzzy Keys</h4>\n<p>A \"fuzzy\" key is a key that supports a special protocol for performing \"fuzzy\"\ncomparisons--comparisons where the result can represent imperfect or partial matches.</p>\n<p>Technically speaking, a <strong>correlate</strong> \"fuzzy\" key\nis an instance of a subclass of <code>correlate.FuzzyKey</code>.  If a key is an instance of\na subclass of that base class, it's a \"fuzzy\" key, and if it isn't, it's an \"exact\" key.</p>\n<p>Fuzzy keys must follow the rules for keys above.\nAlso, the type of your fuzzy keys must also obey the same rules as keys;\nthey must be hashable, they must support <code>==</code>,\nand their comparison must be reflexive, symmetric, transitive, and consistent.</p>\n<p>In addition, fuzzy keys must support a method called <code>compare</code> with this signature:\n<code>self.compare(other)</code>.  <code>other</code> will be another fuzzy key of the same type.  Your <code>compare</code>\nfunction should return a number between (and including) <code>0</code> and <code>1</code>, indicating how close\na match <code>self</code> is to <code>other</code>.  If <code>compare</code> returns <code>1</code>, it's saying this is a perfect\nmatch, that the two values are identical; if it returns <code>0</code>, it's a perfect mismatch,\ntelling <strong>correlate</strong> that the two keys have nothing in common.</p>\n<p><strong>correlate</strong> requires that <code>compare</code> also obey the four mathematical constraints required\nof comparisons between keys.  In the following rules, <code>a</code> and <code>b</code> are fuzzy keys of the\nsame type.  <code>compare</code> must conform to these familiar four rules:</p>\n<ul>\n<li><em>reflexive:</em> <code>a.compare(a)</code> must return <code>1</code> (or <code>1.0</code>).</li>\n<li><em>symmetric:</em> If <code>a.compare(b)</code> returns <em>x</em>, then <code>b.compare(a)</code> must also return <em>x</em>.</li>\n<li><em>transitive:</em> If <code>a.compare(b)</code> returns <em>x</em>, and <code>b.compare(c)</code> returns <em>x</em>,\nthen <code>a.compare(c)</code> must also return <em>x</em>.</li>\n<li><em>consistent:</em> If <code>a.compare(b)</code> returns <em>x</em>, it must <em>always</em> return <em>x</em>.</li>\n</ul>\n<p>It's important to note: fuzzy keys of two <em>different</em> types are automatically\nconsidered different to each other.  <strong>correlate</strong> won't even bother calling\n<code>compare()</code> on them--it automatically assigns the comparison a fuzzy score of <code>0</code>.\nThis is true even for subclasses; if you declare <code>class MyFuzzyNumber(correlate.FuzzyKey)</code>\nand also <code>class MyFuzzyInteger(MyFuzzyNumber)</code>,\n<strong>correlate</strong> will never compare an instance of <code>MyFuzzyNumber</code> and <code>MyFuzzyKey</code>\nto each other--it automatically assumes they have nothing in common.</p>\n<p>(Internally\n<strong>correlate</strong> stores fuzzy keys of different types segregated from each other.\nThis is a vital optimization!)</p>\n<p>On a related note, <strong>correlate</strong> may optionally never\n<em>actually</em> call <code>a.compare(a)</code>, either.  That is, if the exact same key\nmaps to a value in both <code>dataset_a</code> and <code>dataset_b</code>, <strong>correlate</strong>\nis permitted to skip calling <code>compare()</code> and instead automatically\nassign the comparison a fuzzy score of <code>1</code>.  Currently if the situation\narose it <em>would</em> call <code>a.compare(a)</code>, but that wasn't true at various times\nduring development.</p>\n<h2>API</h2>\n<p><code>Correlator(default_weight=1)</code></p>\n<blockquote>\n<p>The correlator class.  <code>default_weight</code> is the weight used\nwhen you map a key to a value without specifying an explicit weight.</p>\n</blockquote>\n<p><code>Correlator.dataset_a</code></p>\n<p><code>Correlator.dataset_b</code></p>\n<blockquote>\n<p>Instances of <code>Correlator.Dataset</code> objects representing the two sets of data you want to correlate.  Initially empty.</p>\n</blockquote>\n<p><code>Correlator.datasets</code></p>\n<blockquote>\n<p>A list containing the two datasets: <code>[dataset_a, dataset_b]</code></p>\n</blockquote>\n<p><code>Correlator.correlate(*, minimum_score=0, score_ratio_bonus=1, ranking=BestRanking, ranking_bonus=0, ranking_factor=0, reuse_a=False, reuse_b=False)</code></p>\n<blockquote>\n<p>Correlates the two datasets.  Returns a <code>correlate.CorrelatorResult</code> object.</p>\n<p><code>minimum_score</code> is the minimum permissible score for a match.  It must be\ngreater than or equal to 0.</p>\n<p><code>score_ratio_bonus</code> specifies the weight of a bonus awarded to a match based on the ratio of\nthe actual score computed between these two values divided by the maximum possible score.</p>\n<p><code>ranking</code> specifies which approch to computing ranking <strong>correlate</strong> should use.\nThe default value of <code>BestRanking</code> means <strong>correlate</strong> will try all approaches\nand choose the one with the highest cumulative score across all matches.\nOther values include <code>AbsoluteRanking</code> and <code>RelativeRanking</code>.</p>\n<p><code>ranking_bonus</code> specifies the weight of the bonus awarded to a match\nbased on the proximity of the two values in their respective datasets, as specified\nby their rankings.  The closer the two values are to the same position in their\nrespective datasets, the higher a percentage of the <code>ranking_bonus</code> will be awarded.</p>\n<p><code>ranking_factor</code> specifies the ratio of the base score of a match that is multiplied\nby the proximity of the two values in their respective datasets.  If you ues <code>ranking_factor=0.4</code>,\nthen a match only automatically keeps 60% of its original score; some percentage\nof the remaining 40% will be re-awarded based on the proximity of the two values.</p>\n<p>(You can't use both a nonzero <code>ranking_bonus</code> and a nonzero <code>ranking_factor</code> in the\nsame correlation.  Pick at most one!)</p>\n<p><code>reuse_a</code> permits values in <code>dataset_a</code> to be matched to more than one value in <code>dataset_b</code>.\n<code>reuse_b</code> is the same but for values in <code>dataset_b</code> matching <code>dataset_a</code>.\nIf you set both reuse flags to True, the <code>correlate.CorrelatorResult.matches</code>\nlist returned will contain <em>every</em> possible match.</p>\n</blockquote>\n<p><code>Correlator.print_datasets()</code></p>\n<blockquote>\n<p>Prints both datasets in a human-readable form.  Uses <code>self.print</code> to print,\nwhich defaults to <code>print</code>.</p>\n</blockquote>\n<p><code>Correlate.Dataset()</code></p>\n<blockquote>\n<p>The class for objects representing a dataset.  Behaves somewhat like\na write-only dict.</p>\n</blockquote>\n<p><code>Correlator.Dataset.set(key, value, weight=default_weight)</code></p>\n<blockquote>\n<p>Adds a new correlation.</p>\n<p>You can use <code>Dataset[key] = value</code> as a shortcut for <code>Dataset.set(key, value)</code>.</p>\n</blockquote>\n<p><code>Correlator.Dataset.set_keys(keys, value, weight=default_weight)</code></p>\n<blockquote>\n<p>Map multiple keys to a single value, all using the same weight.\n<code>keys</code> must be an iterable containing keys.</p>\n</blockquote>\n<p><code>Correlator.Dataset.value(value, *, ranking=None)</code></p>\n<blockquote>\n<p>Annotates a value with extra metadata.  Currently only one metadatum\nis supported: <code>ranking</code>.</p>\n<p><code>ranking</code> represents the position of this value in the dataset,\nif the dataset is ordered.  <code>ranking</code> should be an integer\nrepresenting the ranking; if this value is the 19th in the dataset,\nyou should supply <code>ranking=19</code>.</p>\n</blockquote>\n<p><code>CorrelatorResult()</code></p>\n<blockquote>\n<p>The class for objects returned by <code>Correlator.correlate()</code>.\nContains four members:</p>\n<ul>\n<li><code>matches</code>, a <code>list</code> of <code>CorrelatorMatch()</code> objects, sorted with highest score first</li>\n<li><code>unmatched_a</code>, the <code>set</code> of values from <code>dataset_a</code> that were not matched</li>\n<li><code>unmatched_b</code>, the <code>set</code> of values from <code>dataset_b</code> that were not matched</li>\n<li><code>statistics</code>, a <code>dict</code> containing statistics about the correlation</li>\n</ul>\n</blockquote>\n<p><code>CorrelatorResult.normalize(high=None, low=None)</code></p>\n<blockquote>\n<p>Normalizes the scores in <code>matches</code>.\nWhen <code>normalize()</code> is called with its default values, it adjusts every score\nso that they fall in the range <code>(0, 1]</code>.\nIf <code>high</code> is not specified, it defaults to the highest score in <code>matches</code>.\nIf <code>low</code> is not specified, it defaults to the <code>minimum_score</code> for the correlation.</p>\n</blockquote>\n<p><code>CorrelatorMatch()</code></p>\n<blockquote>\n<p>The class for objects representing an individual match made\nby <code>Correlator.correlate()</code>.\nContains three members:</p>\n<ul>\n<li><code>value_a</code>, a value from <code>dataset_a</code>.</li>\n<li><code>value_b</code>, a value from <code>dataset_b</code>.</li>\n<li><code>score</code>, a number representing the confidence in this match.\nThe higher the <code>score</code>, the higher the confidence.\nScores don't have a predefined intrinsic meaning; they're a result\nof all the inputs to <strong>correlate.</strong></li>\n</ul>\n</blockquote>\n<p><code>Correlator.str_to_keys(s)</code></p>\n<blockquote>\n<p>A convenience function.\nConverts string <code>s</code> into a list of string keys using a reasonable approach.\nLowercases the string, converts some common punctuation into spaces, then splits\nthe string at whitespace boundaries.  Returns a list of strings.</p>\n</blockquote>\n<h3>Getting Good Results Out Of Correlate</h3>\n<p>Unfortunately, you can't always expect perfect results with <strong>correlate</strong>\nevery time.  You'll usually have to play with it at least a little.</p>\n<h4>Ranking</h4>\n<p>Naturally, the first step with <strong>correlate</strong> is to plug in your data.\nI strongly encourage you to add ranking information if possible.</p>\n<p>If the two datasets are ordered, and equivalent items should appear in\nroughly the same place in each of the two datasets, ranking information\ncan make a <em>sizeable</em> improvement in the quality of your matches.\nTo use ranking information, you set the <code>ranking</code> for each value in each dataset\nthat you can, and specify either <code>ranking_bonus</code> or <code>ranking_factor</code> when\nrunning <code>correlate()</code>.\nWhich one you use kind of depends on how much confidence you have in the\nordering of your datasets.  If you think your ranking information is pretty\naccurate, you should definitely use <code>ranking_factor</code>; this exerts a much\nstronger influence on the matches.\nIf you have a low confidence in the ordering of your datasets,\nchoose <code>ranking_bonus</code>, which only provides a little nudge.</p>\n<h4>Minimum Score</h4>\n<p>Once you've plugged in all your data, you should run the correlation,\nprint out the result in sorted order with the best\nmatches on top, then scroll to the bottom and see what the <em>worst</em>\n5% or 10% of matches look like.</p>\n<p>If literally all your matches are already perfect--congratulations!\nYou're <em>already</em> getting good results out of <strong>correlate</strong> and you\ncan stop reading here!  But if you're not that lucky, you've got more\nwork to do.</p>\n<p>The first step in cleaning up <strong>correlate's</strong> output is usually\nto stop it from making bad matches by setting a <code>minimum_score</code>.</p>\n<p>When you have bad matches, it's usually because the two datasets don't map\nperfectly to each other.  If there's a value in <code>dataset_a</code> that really\nhas no good match in <code>dataset_b</code>, well, <strong>correlate</strong> doesn't really\nhave a way of knowing that.   So it may match that value to something\nanyway.</p>\n<p>Look at it this way: the goal of <strong>correlate</strong> is to find matches between\nthe two datasets.  If it's made all the good matches it can, and there's\nonly one item left in each of the the two datasets, and they have <em>anything</em>\nin common at all, <strong>correlate</strong> will match those two values together\nout of sheer desparation.</p>\n<p>However!  Bad matches like these tend to have a very low score.\nAnd usually all those bad matches are clumped together\nat the bottom.  There'll probably be an inflection point\nwhere the scores drop off significantly and the matches go from good to bad.</p>\n<p>This is what <code>minimum_score</code> is for.  <code>minimum_score</code> tells <strong>correlate</strong>\nthe minimum permissible score for a match.  When you have a clump of bad\nmatches at the bottom, you simply set <code>minimum_score</code> to be somewhere\nbetween the highest bad match and the lowest good match--and\nyour problem is solved!</p>\n<p>(Technically, <strong>minimum_score</strong> isn't actually the <em>minimum</em> score.\nIt's ever-so-slightly <em>less</em> than the lowest\npermitted score.  As in, for a match to be considered viable, its score\nmust be <em>greater than</em> <strong>minimum_score.</strong>  The default value for\n<strong>minimum_score</strong> is 0, which means <strong>correlate</strong> will keep\nany match with a positive score.)</p>\n<p>Unfortunately it's hard to predict what to set <code>minimum_score</code> to in advance.\nIts value really depends on your data set--how many keys you have, how good\nthe matches are, what weights you're using, everything.  It's much more\nstraightforward to run the correlation, look over the output, find where the\ncorrelations turn bad, and set a minimum score.  With large data sets there's\ngenerally a sudden and obvious dropoff in score, associated with <strong>correlate</strong>\nmaking poor matches.  That makes it pretty easy: set the minimum score so it\nkeeps the last good match and forgets the rest.  But there's no predicting what\nthat score will be in advance--every data set is different, and it's really\nan emergent property of your keys and weights--so\nyou'll have to calibrate it correctly for each correlation you run.</p>\n<p>(Sometimes there are good matches mixed in with the bad ones at the bottom.\nWhen that happens, the first step is generally to fix <em>that,</em> so that the\nbad ones are all clumped together at the bottom.  I can't give any general-purpose\nadvice on what to do here; all I can say is, start experimenting with changes\nto your datasets.  Change your keys, adjust your weights, run the correlation\nagain and see what happens.  Usually when I do this, I realize something I can\ndo to improve the data I feed in to <strong>correlate</strong>, and I can fix the problem\nexternally.)</p>\n<h4>Weights</h4>\n<p>If you're still not getting the results you want, the next adjustment you\nshould consider is increasing the weight of\nkeys that provide a clear signal.  If the datasets you're comparing\nhave some sort of unique identifier associated with each value--like\nan episode number, or release date--you should experiment with giving those\nkeys a heavier weight.  Heavily-weighted keys like this can help\n<strong>correlate</strong> zero in on the best matches right away.</p>\n<p>It's up to you what that weight\nshould be; I sometimes use weights as heavy as 5 for super-important keys,\nwhich means this one single key will have the same weight as 5 normal\nkeys.  Note that a weight of 5 on the mapping in <code>dataset_a</code> and\n<code>dataset_b</code> means that, if those keys match, they'll have a base score\nof 25!  If that key only appears once in each dataset, that will almost\n<em>certainly</em> result in a match.</p>\n<p>But weighting can be a dual-edged sword.  If your data has mistakes\nin it, a heavy weighting of this bad data magnifies those mistakes.  One bad\nheavily-weighted key on the wrong value can inflate the score of a bad match\nover the correct match.  And that can have a domino effect--if <em>A1</em> should match\nto <em>B1</em>, but it get mapped to <em>B43</em> instead, that means <em>B1</em> is probably\ngoing to get mismatched too.  Which deprives another value of its correct\nmatch.  And so on and so on and so on.</p>\n<h4>Too-Common Keys</h4>\n<p>Similarly, if there are super-common keys that aren't going to help with\nthe correlation, consider throwing them away and not even feeding them in as\ndata.  Keys that map to most or all of the values in a dataset add little\nclarity, and will mainly serve just to make <strong>correlate</strong> slower.\nI usually throw away the word \"The\", and the name of the podcast or show.\n(When correlating filenames, I may throw away the file extension too.)</p>\n<p>Then again, often leaving them in won't hurt anything, and it can occasionally\nbe helpful!  The way <strong>correlate</strong> works, it considers multiple maps of a\nkey to a value as different things--if you map the key <code>\"The\"</code> to a value\ntwice, <strong>correlate</strong> understands that those are two separate mappings.\nAnd if there's only one value in each dataset that has two <code>\"The\"</code> mappings,\nthat can be a very strong signal indeed.  So it's really up to you.\nThrowing away largely-redundant keys is a speed optimization, but it\nshouldn't affect the quality of your matches.</p>\n<p>(A theoretical best of both worlds: for very common keys,\nconsider throwing away the <em>first</em> instance.  Though I haven't tried\nthis experiment myself.)</p>\n<h4>Check Your Inputs</h4>\n<p>As always, it's helpful to make sure your code is doing what you intend it to.\nSeveral times I've goofed up the mechanism I use to feed data sets into\n<strong>correlate</strong>; for example, instead of feeding in words as keys, I've occasionally\nfed in the individual characters in those words as keys.  (Like, instead of\nthe single key <code>\"booze\"</code>, I accidentally fed in the five keys\n<code>'b'</code>, <code>'o'</code>, <code>'o'</code>, <code>'z'</code>, and <code>'e'</code>.)\nHowever, the <strong>correlate</strong> algorithm works so well,\nit still did a shockingly good job!  (Though it was a <em>lot</em> slower.)</p>\n<p>I've learned to double-check that I'm inputting the mappings and weights I meant\nto, with a debugger or with turning on the debug print statements in <strong>correlate</strong>\nitself.  Making sure you gave <strong>correlate</strong> the right data can make it not only\nmuch more accurate, it might make it faster too!</p>\n<p><strong>correlate</strong> provides a function that prints out your datasets in a\nconvenient human-readable format: <code>Correlator.print_datasets()</code>.</p>\n<h4>Normalize Strings</h4>\n<p>When using strings as keys from real-world sources, I recommend you\n<em>normalize</em> the strings:\nlowercase the strings, remove most or all punctuation, break the strings up into\nindividual keys at word boundaries.  In the real world, punctuation\nand capitalization can both be inconsistent, so throwing it away can help\ndispel those sorts of inconsistencies.  <strong>correlate</strong>\nprovides a utility function called <code>correlate.str_to_keys()</code> that does this\nfor you--but you can use any approach you like.</p>\n<p>You might also consider <em>interning</em> your strings.  In my limited experimentation\nthis provided a small but measurable speedup.</p>\n<h4>Sharpen Your Fuzzy Keys</h4>\n<p>If you're using fuzzy keys, make sure you <em>sharpen</em> your fuzzy keys.\nFuzzy string-matching libraries have a naughty habit of scoring\nnot-very-similar strings as not <em>that</em> much less than almost-exactly-the-same\nstrings.  If you give that data unaltered to <strong>correlate,</strong> that \"everything\nlooks roughly the same\" outlook will be reflected in your results as\nmediocre matches.</p>\n<p>In general, you want to force your fuzzy matches to extremes.\nTwo good techniques:</p>\n<ul>\n<li>Specify a minimum score for fuzzy matches, and replace any fuzzy score\nbelow that minimum with <code>0</code>.\n<ul>\n<li>Possibly remap the remaining range to the entire range.\nFor example, if your minimum score is <code>0.6</code>, should you simply\nreturn values from <code>0.6</code> to <code>1</code>?  Or should you stretch the scores\nover the entire range with <code>(fuzzy_score - 0.6) / (1 - 0.6)</code>?\nYou may need to experiment with both to find out what works well for you.</li>\n</ul>\n</li>\n<li>Multiply your fuzzy score by itself.  Squaring or even cubing a fuzzy\nscore will preserve high scores and attenuate low scores.\nNote that the scoring algorithm for fuzzy key matches already <em>cubes</em>\nthe fuzzy score.  Additional multiplying of the score by itself is\nprobably unnecessary in most cases.</li>\n</ul>\n<h3>What Do These Scores Mean?</h3>\n<p>The scores you seee in the results are directly related to the data you\ngave to <strong>correlate</strong>.  The scores really only have as much or as\nlittle meaning as you assign to them.</p>\n<p>If you don't enjoy the unpredictable nature of <strong>correlate</strong> scores,\nconsider calling <code>normalize()</code> on your Correlate result object.\nThis normalizes the scores as follows: the highest score measured\nwill be adjusted to 1.0, <code>minimum_score</code> will be adjusted to 0.0,\nand every other score will be adjusted linearly between those two.</p>\n<p>Mathematically:</p>\n<pre><code>score = the original score for this match\nhighest_score = highest score of any match\nminimum_score = the minimum_score passed in to correlate()\ndelta = highest_score - minimum_score\nnormalized_score = (score - minimum_score) / delta\n</code></pre>\n<h2>The Algorithm And The Code</h2>\n<blockquote>\n<p>If the implementation is hard to explain, it's a bad idea.\n--<em>The Zen Of Python</em> by Tim Peters</p>\n</blockquote>\n<p>What follows is an exhaustive (and exhausting!) chapter\non the implementation of <strong>correlate</strong>.  This is here\npartially for posterity, partially because I like\nreading this sort of thing in other people's project,\nbut mostly to make it easier to reaquaint myself with\nthe code when I have to fix a bug three years from now.</p>\n<h3>The High-Level Overview</h3>\n<p>At the heart of <strong>correlate</strong> is a brute-force algorithm.  It's what\ncomputer scientists would call an <em>O</em>(n\u00b2) algorithm.</p>\n<p><strong>correlate</strong> computes every possible \"match\"--every mapping of a value in\n<code>dataset_a</code> to a value in <code>dataset_b</code> where the two values have keys in common.\nFor exact keys, it uses set intersections to ignore pairs of values that have\nnothing in common, discarding early matches it knows will have a score of 0.\nSadly, it can't do that for fuzzy keys, which is why fuzzy keys tend to\nslow down  <strong>correlate</strong> even more.</p>\n<p>For each key that matches between the two values, <strong>correlate</strong>\ncomputes a score.  It then adds all those scores together,\ncomputing the final cumulative score for the \"match\",\nwhich it may modifiy based on the various bonuses and factors.\nIt then iterates over these scores in sorted order, highest score first.\nFor every match where neither of the two values have been used\nin a match yet, it counts that as a \"match\" and adds it to the output.\n(This assumes <code>reuse_a</code> and <code>reuse_b</code> are both <code>False</code>.  Also, this\nis a little bit of an oversimplification; see the section about the\n<em>Match Boiler</em> below.)</p>\n<p>One important detail: <strong>correlate</strong> is 100%\ndeterministic.  Randomness can creep in around the edges in Python\nprograms; for example, if you ever iterate over a dictionary,\nthe order you will see the keys will vary from run to run.\n<strong>correlate</strong> eliminates these sources of randomness.\nGiven the exact same inputs, it performs the same operations\nin the same order and produces the same result, every time.</p>\n<p>There are a number of concepts involved with how the <strong>correlate</strong>\nalgorithm works, each of which I'll explain in exhausting detail\nin the following sub-sections.</p>\n<h2><strong>correlate's</strong> Six Passes And Big-O Complexity</h2>\n<p>Here's a high-level overview of how <strong>correlate</strong> performs\none correlation.\n<strong>correlate</strong> makes six passes over various sets of data.</p>\n<p><strong>Pass 1</strong></p>\n<blockquote>\n<p>Iterate over both datasets and compute the \"streamlined\"\ndata.</p>\n<p><em>Complexity:</em> <em>O</em>(n)</p>\n</blockquote>\n<p><strong>Pass 2</strong></p>\n<blockquote>\n<p>Iterate over all keys and compute a sorted list of all matches\nthat have a nonzero score.  (The list represents a match with\na pair of indices into the lists of values for each dataset.)\nThis pass also performs all fuzzy key comparisons and caches\ntheir results.</p>\n<p><em>Complexity:</em> <em>O</em>(n\u00b2), for the fuzzy key comparisons step</p>\n</blockquote>\n<p><strong>Pass 3</strong></p>\n<blockquote>\n<p>For every match with a nonzero score,\ncompute subtotals for matching all fuzzy keys.\nWe need to add some of these together to compute the final\nscores for fuzzy key matches.</p>\n<p><em>Complexity:</em> <em>O</em>(n\u00b2)</p>\n</blockquote>\n<p><strong>Pass 4</strong></p>\n<blockquote>\n<p>For every match with a nonzero score:</p>\n<ul>\n<li>compute the scores for matching all exact keys,</li>\n<li>finalize the scores for fuzzy key match scores,</li>\n<li>compute the bonuses (score_ratio_bonus, ranking),</li>\n<li>and store the result per-ranking.</li>\n</ul>\n<p>The score for each match is now finalized.</p>\n<p><em>Complexity:</em> <em>O</em>(n\u00b2)</p>\n</blockquote>\n<p><strong>Pass 5</strong></p>\n<blockquote>\n<p>For every ranking approach being used,\ncompute the final list of successful matches,\nusing the \"match boiler\" and \"greedy algorithm\".</p>\n<p><em>Complexity:</em> <em>O</em>(n log n) (approximate)</p>\n</blockquote>\n<p><strong>Pass 6</strong></p>\n<blockquote>\n<p>Choose the highest-scoring ranking approach,\ncompute unseen_a and unseen_b,\nand back-substitute the \"indexes\" with their actual values\nbefore returning.</p>\n<p><em>Complexity:</em> <em>O</em>(n)</p>\n</blockquote>\n<p>Thus the big-O notation for <strong>correlate</strong> overall is <em>O</em>(n\u00b2).</p>\n<h3>Rounds</h3>\n<p>If you call <strong>correlate</strong> as follows:</p>\n<pre><code>c = correlate.Correlator()\no = object()\nc.dataset_a.set('a', o)\nc.dataset_a.set('a', o)\n</code></pre>\n<p>then key <code>'a'</code> really <em>is</em> mapped to value <code>o</code> twice,\nand those two mappings can have different weights.\nIt's best to think of repeated keys like this as actually\nbeing two different keys--identical, but distinct.\nIt's like having files with the same filename in two\ndifferent directories.  They have the same <em>filename,</em> but\nthey're not the same <em>file.</em></p>\n<p><strong>correlate</strong> calls groups of these multiple mappings <em>\"rounds\"</em>.\nA \"round\" contains all the keys from the Nth time they were\nrepeated; round 0 contains every key, round 1 contains the second\ninstances of all the keys that were repeated twice, round 2 contains\nall the third instances of all the keys that were repeated three times,\netc.\nRounds are per-value, and there are as\nmany rounds as the maximum number of redundant mappings of\nany single key to any particular value in a dataset.</p>\n<p>Naturally, exact keys and fuzzy keys use a different method\nto determine whether or not something is \"the same key\".\nTechnically both types of keys use <code>==</code> to determine equivalence.\nHowever, fuzzy keys don't implement <code>__eq__</code>, so Python uses\nits default mechanism to determine equivalence, which is really\njust the <code>is</code> operator.  Therefore: exact keys are the same\nif <code>==</code> says they're the same, and (in practice) fuzzy keys\nare the same if and only if they're the same object.</p>\n<p>(Of course, you could implement <code>__eq__</code> when you write\nyour own fuzzy subclasses.  I don't know why you would bother.)</p>\n<p>Consider this example:</p>\n<pre><code>c = correlate.Correlator()\no = object()\nc.dataset_a.set('a', o, weight=1)\nc.dataset_a.set('a', o, weight=3)\nc.dataset_a.set('a', o, weight=5)\nc.dataset_a.set('b', o)\nc.dataset_a.set('b', o)\nc.dataset_a.set('c', o)\n\no2 = object()\nc.dataset_b.set('d', o2)\nc.dataset_b.set('d', o2)\nc.dataset_b.set('e', o2)\nc.dataset_b.set('f', o2)\n</code></pre>\n<p>Here, the value <code>o</code> in <code>dataset_a</code> would have three rounds:</p>\n<ul>\n<li>Round 0 would contain the keys <code>{'a', 'b', 'c'}</code>.</li>\n<li>Round 1 would contain the keys <code>{'a', 'b'}</code>.</li>\n<li>Round 2 would contain only one key,<code>{'a'}</code>.</li>\n</ul>\n<p>And <code>o2</code> in <code>dataset_b</code> would have only two rounds:</p>\n<ul>\n<li>Round 0 would contain the keys <code>{'d', 'e', 'f'}</code>.</li>\n<li>Round 1 would contain only one key,<code>{'d'}</code>.</li>\n</ul>\n<p>Again, conceptually, the <code>\"a\"</code> in round 0 is a different key\nfrom the <code>\"a\"</code> in round 1, and so on.</p>\n<p>For exact keys, rounds are directly matched iteratively\nto each other; the exact keys in round 0 for a value in\n<code>dataset_a</code> are matched to the round 0 exact keys for a value in\n<code>dataset_b</code>, round 1 in <code>dataset_a</code> is matched to\nround 1 in <code>dataset_b</code>, and so on.\nIf one side runs out of rounds early, you stop; if you compute\nthe intersection of a round and they have nothing in common,\nyou stop.</p>\n<p>One invariant property: each subsequent round has a subset of\nthe keys before it.  The set of keys in round <strong>N+1</strong> <em>must</em>\nbe a subset of the keys in round <strong>N</strong>.</p>\n<p>What about weights?  Higher weights are sorted to lower rounds.\nThe weight for a key <em>k</em> in round <strong>N-1</strong> <em>must</em> be greater than\nor equal to the weight of <em>k</em> in round <strong>N</strong>.\nIn the above example, the <code>'a'</code> in round 0 has weight 5, in round 1\nit has weight 3, and in round 2 it has weight 1.\n(It doesn't matter what order you insert them in, <strong>correlate</strong>\ninternally stores the weights in sorted order.)</p>\n<p>Thus, round 0 always contains every exact key mapped to\na particular value, with their highest weights.</p>\n<p>Rounds can definitely help find the best matches.  If the\nkey <code>\"The\"</code> maps to most of your values once,\nthat's not particularly interesting, and it won't affect the scores\nvery much one way or another.  But if there's only one\nvalue in each dataset that <code>\"The\"</code> maps to <em>twice,</em>\nthat's a very strong signal indeed!  <strong>correlate</strong> does an\n<em>excellent</em> job of noticing unique-ness like that and factoring\nit into the scoring.</p>\n<h3>Streamlined Data</h3>\n<p>The <strong>correlate</strong> datasets store data in a format designed\nto eliminate redundancy and be easy to modify.  But this representation\nis inconvenient for performing the actual correlate.  Therefore,\nthe first step is to reprocess the data into a \"streamlined\" format.\nThis is an internal-only implementation detail, and in fact the data\nis thrown away at the end of each correlation.  As an end-user you'll\nnever have to deal with it.  It's only documented here just in case you\never need to understand the implementation of <strong>correlate</strong>.</p>\n<p>This streamlined data representation is an important optimization.\nIt greatly speeds up computing a match between two values.  And it\nonly costs a little overhead, compared to all that matching work.\nConsider: if you have 600 values in <code>dataset_a</code> and 600 values in\n<code>dataset_b</code>, <strong>correlate</strong> will recompute 1,200 streamlined datasets.\nBut it'll then use it in as many as 360,000 comparisons!   Spending\na little time precomputing the data in a convenient format saves a\nlot of time in the long run.</p>\n<h3>The Scoring Formula, And Conservation Of Score</h3>\n<p>For each match it considers, <strong>correlate</strong> computes the intersection of\nthe keys that map to each of those two values in the two datasets,\nthen computes a score based on each of those key matches.\nThis scoring formula is the heart of <strong>correlate</strong>, and it was a key\ninsight--without it <strong>correlate</strong> wouldn't work nearly as well as it does.</p>\n<p>In the abstract, it looks like this:</p>\n<pre><code>for value_a in dataset_a:\n    for value_b in dataset_b:\n        subtotal_score = 0\n        for key_a, weight_a that maps to value_a:\n            for key_b, weight_b that maps to value_b:\n                score = value of key_a compared to key_b\n                cumulative_a = the sum of all scores between key_a and all keys in dataset_b\n                cumulative_b = the sum of all scores between key_b and all keys in dataset_a\n                score_ratio_a = score / cumulative_a\n                score_ratio_b = score / cumulative_b\n                unweighted_score = score * score_ratio_a * score_ratio_b\n                score_a = weight_a * unweighted_score_a\n                score_b = weight_b * unweighted_score_b\n                final_score = score_a * score_b\n                subtotal_score += final_score\n</code></pre>\n<p>Two notes before we continue:</p>\n<ul>\n<li>\n<p><code>key_a</code> and <code>key_b</code> must always be <em>per-round,</em> for a number\nof reasons, the least of which is because we use their\nweights in computing the <code>final_score</code>.</p>\n</li>\n<li>\n<p><code>subtotal_score</code> is possibly further adjusted by <code>score_ratio_bonus</code>\nand ranking, if used, but those will be discussed later.</p>\n</li>\n</ul>\n<p>This formula is how <strong>correlate</strong> assigns a mathematical score to\n\"uniqueness\".  The fewer values a key maps to in a dataset,\nthe higher it scores.  A key that's only mapped once in each\ndataset scores 4x higher than a key mapped twice in each dataset.</p>\n<p>This scoring formula has a virtuous-feeling mathematical\nproperty I call <em>\"conservation of score\".</em>  Each key that\nyou add to a round in a dataset adds 1 to the total cumulatve\nscore of all possible matches; when you map a key to multiple\nvalues, you divide this score up evenly between those values.\nFor example, if the key <code>x</code> is mapped to three values in <code>dataset_a</code>\nand four values in <code>dataset_b</code>, each of those possible matches\nonly gets 1/12 of that key's score, and the final cumulative\nscore for all matches only goes up by 1/12.  So a key always\nadds 1 to the sum of all scores across all <em>possible</em> matches,\nbut only increases the actual final score by the amount of\nsignal it <em>actually</em> communicated.</p>\n<p>Also, now you see why repeated keys can be so interesting.\nThey add 1 for <em>each round</em> they're in, but that score is only\ndivided by the number of values they're mapped to <em>in that round!</em></p>\n<h3>Matching And Scoring Exact Keys</h3>\n<p>The \"streamlined\" data format for exact keys looks like this:</p>\n<pre><code>exact_rounds[index][round] = (set(d), d)\n</code></pre>\n<p>That is, it's indexed by \"index\" (which represents the value), then\nby round number.  That gives you a tuple containing a dict mapping\nkeys to weights, and a <code>set()</code> of just the keys.\n<strong>correlate</strong> uses <code>set.intersection()</code> (which is super fast!)\nto find the set of exact keys the two values have in common for that round.\nThe <code>len()</code> of this resulting set is the base cumulative score for that round,\nalthough that number is only directly useful in computing <code>score_ratio_bonus</code>.</p>\n<p>Although <strong>correlate</strong> uses the same scoring formula for both exact keys and\nfuzzy keys in an abstract sense, scoring matches between exact keys is much\nsimpler in practice.</p>\n<p>First, <code>key_a</code> and <code>key_b</code> are the same value.  That means we can rewrite the\nequation slightly:</p>\n<pre><code>cumulative_a = the sum of all scores between key_b and all keys in dataset_b\ncumulative_b = the sum of all scores between key_a and all keys in dataset_a\n</code></pre>\n<p>What changed?  We've swapped <code>key_a</code> and <code>key_b</code>.  Why?  It'll help, keep reading.</p>\n<p>Second, <code>score</code> is always either <code>1</code> or <code>0</code>.  It's <code>1</code> when two keys are exactly\nthe same, and <code>0</code> otherwise.  If the base <code>score</code> for the match is <code>0</code>, then the\n<code>final_score</code> will be <code>0</code> and we can skip all of it.  So we only ever compute\na <code>final_score</code> when <code>score</code> is <code>1</code>.</p>\n<p>Since <code>score</code> is only ever used as a multiplier, we can remove it.</p>\n<p>Third, <code>cumulative_a</code> and <code>cumulative_b</code> are similarly easy to compute.\nThey're just the number of times that key is mapped to any value in\nthe relevant dataset, <em>in that round.</em>  These counts are precomputed\nand stored in the \"streamlined\" data.</p>\n<p>So, finally: if you do the substitutions and drop out the constant <code>score</code>\nfactors, <code>final_score</code> for exact keys is computed like this:</p>\n<pre><code>final_score = (weight_a * weight_b) / (cumulative_a * cumulative_b)\n</code></pre>\n<p>Which we can rearrange into:</p>\n<pre><code>final_score = (weight_a / cumulative_b) * (weight_b / cumulative_a)\n</code></pre>\n<p>At the point we precompute the streamlined data for <code>dataset_a</code>,\nwe know <code>weight_a</code>, and we can compute <code>cumulative_b</code> because it only\nuses terms in <code>dataset_a</code>.  So we can pre-compute those terms,\nmaking the final math:</p>\n<pre><code># when computing the streamlined data\nprecomputed_a = weight_a / cumulative_b\nprecomputed_b = weight_b / cumulative_a\n\n# ...\n\n# when computing the score for a matching exact key\nfinal_score = precomputed_a * precomputed_b\n</code></pre>\n<h3>Fuzzy Keys</h3>\n<p>Once upon a time, <strong>correlate</strong> was small and beautiful.\nBut that version only supported exact keys.\nBy the time fuzzy keys were completely implemented and feature-complete\nand working great, <strong>correlate</strong> was much more complex and... \"practical\".\nIt's because fuzzy keys introduce a lot of complex behavior, resulting in\ntricky scenarios that just don't arise with exact keys.</p>\n<p>Consider this example:</p>\n<blockquote>\n<p>Your two datasets represent lists of farms.  Both datasets list\nanimals, but might have generic information (\"horse\") or might\nhave specifics (\"Clydesdale\").  You create a fuzzy key subclass called\n<code>AnimalKey</code> that can handle matching these together;\n<code>AnimalKey(\"Horse/Clydesdale\")</code> matches <code>AnimalKey(\"Horse\")</code>,\nthough with a score less than 1 because it isn't a perfect match.</p>\n<p>The same farm, <em>Farm X</em>, is present in both datasets:</p>\n<ul>\n<li>\n<p>In <code>dataset_a</code>, the keys <code>AnimalKey(\"Horse/Clydesdale\")</code>\nand <code>AnimalKey(\"Horse/Shetland Pony\")</code> map to Farm X.</p>\n</li>\n<li>\n<p>In <code>dataset_b</code>, the key <code>AnimalKey(\"Horse\")</code> maps to Farm X <em>twice.</em></p>\n</li>\n</ul>\n<p>Question: should one of the <code>\"Horse\"</code> keys match <code>\"Horse/Clydesdale\"</code>,\nand the other <code>\"Horse\"</code> key match <code>\"Horse/Shetland Pony\"</code>?</p>\n<p>Of course they should!</p>\n</blockquote>\n<p>The scoring used for fuzzy keys is conceptually the same as the scoring\nfor exact keys, including the concept of \"rounds\".  In practice, fuzzy key\nscoring is much more complicated; there are some multipliers I elided\nin the description for exact keys because they're always 1, and some other\nthings that are easy to compute for exact keys that we must do the hard way\nfor fuzzy keys.  (There's a whole section at the end of this document about\nthe history of fuzzy key scoring in <strong>correlate</strong>, in case you're interested.)</p>\n<p>Also, it's reasonable for a single value in a dataset to have multiple fuzzy\nkeys of the same type, which means that now we could have multiple keys\nin one dataset in contention for the same key in the other dataset.\nIn the above example with farms and horses, <strong>correlate</strong> will need to\ncompare both <code>AnimalKey(\"Horse/Clydesdale\")</code> and <code>AnimalKey(\"Horse/Shetland Pony\")</code>\nfrom <code>dataset_a</code> to <code>AnimalKey(\"Horse\")</code> in <code>dataset_b</code>.</p>\n<p>But <strong>correlate</strong> doesn't add up every possible fuzzy score generated by a\nkey; when computing the final score, a fuzzy key is only matched against\none other fuzzy key.  If fuzzy keys <em>FA1</em> and <em>FA2</em> map to value <em>VA</em>\nin <code>dataset_a</code>, and fuzzy key <em>FB</em> maps to value <em>VB</em> in <code>dataset_b</code>,\n<strong>correlate</strong> will consider <em>FA1</em> -&gt; <em>FB</em> and <em>FA2</em> -&gt; <em>FB</em>\nand only keep the match with the highest score.  This match \"consumes\"\nthose two keys, and they can't be matched again.  (Again: when I say \"key\"\nhere, I mean \"this key in this round\".)</p>\n<p>Wait!  It gets even <em>more</em> complicated!\nIt's entirely possible for a key in one round in <code>dataset_a</code> to be\nmatched to a key from a <em>different</em> round in <code>dataset_b</code>, again like the\nsample of the farms and horses above.  That's right: fuzzy keys can match\nkeys from <em>different rounds!</em></p>\n<p>Where exact keys use very precise \"rounds\", fuzzy keys\nrequire a more dynamic approach.  In essense, an unused key in round <em>N</em>\ncan conceptually \"survive\" to rounds <em>N+1</em>.  That's what the above example\nwith farms and ponies is showing us; in round 0, if <code>\"Horse/Clysedale\"</code>\nin <code>dataset_a</code> gets matched to <code>\"Horse\"</code> in <code>dataset_b</code>,\n<code>\"Horse/Shetland Pony\"</code> in <code>dataset_a</code> goes unmatched and continues on\nto round 1.  This also made scoring more complicated.  (For more on this,\ncheck out the test suite.  There's a regression test that exercises this\nexact behavior.)</p>\n<p>After a bunch of rewrites, I found the fastest way to compute fuzzy matches\nwas: for each fuzzy type the two values have in common, compute <em>all possible\nmatches</em> between all fuzzy keys mapping to the two values, even mixing\nbetween rounds.</p>\n<p>The streamlined data for fuzzy keys looks like this:</p>\n<pre><code>fuzzy_types[index][type] = [\n                           [(key1, weight, round#0),  (key1, weight, round#1), ...],\n                           [(key2, weight, round#0),  (key2, weight, round#1), ...],\n                        ]\n</code></pre>\n<p>That is, they're indexed by index (a representation of the value),\nthen by fuzzy type.  That gets you a list of lists.  Each inner list\nis a list of tuples of</p>\n<pre><code>(key, weight, round_number)\n</code></pre>\n<p>where <code>key</code> is always the same in all entries in the list, and\n<code>round_number</code> is always the same as that tuple's index in that list.</p>\n<p>When computing matches between fuzzy keys, <strong>correlate</strong> takes the\ntwo lists of lists and does nested <code>for</code> loops over them.  Since the\nkeys don't change, it only needs to look up the fuzzy score once.\nIf the fuzzy score is greater than 0, it stores the match in an\narray.</p>\n<p>Once it's done with the fuzzy key matching, it sorts this array of matches,\nthen use the \"match boiler\" to reduce it down so that every per-round key\nis matched at most once.  (The \"match boiler\" is discussed later; for now\njust assume it's a magic function that does the right thing.  Though I had\nto ensure it was super-stable for this approach to work.)</p>\n<p>Sorting these fuzzy key matches was tricky.  They aren't merely sorted\nby score; we also must ensure that fuzzy key matches from earlier rounds\nare <em>always</em> consumed before matches using that key in later rounds.\nSo we sort by a <code>sort_by</code> tuple, computed as follows:</p>\n<pre><code>key_a, round_a = key_and_round_a\nkey_b, round_b = key_and_round_b\nfuzzy_score = key_a.compare(key_b)\nlowest_round_number  = min(round_a, round_b)\nhighest_round_number = max(round_a, round_b)\nsort_by = (fuzzy_score, -lowest_round_number, -highest_round_number)\n</code></pre>\n<p>The <code>-lowest_round_number</code> trick is the very clever bit.  This lets\nus sort with highest values last, which is what the \"match boiler\" wants.\nBut negating it means lower round numbers are now <em>higher</em> numbers, which\nlets us prefer keys with lower round numbers.</p>\n<p>In terms of the abstract scoring formula,\n<code>score</code> is the fuzzy score, what's returned by calling the <code>compare()</code> method.\nAnd <code>cumulative_a</code> is the sum of all fuzzy <code>score</code> scores\nfor all matches using <code>key_a</code>.</p>\n<h3>Score Ratio Bonus</h3>\n<p>There's a \"bonus\" score calculated using <code>score_ratio_bonus</code>.  It's scored for the\noverall mapping of a value in <code>dataset_a</code> to a value in <code>dataset_b</code>.\nThis bonus is one of the last things computed for a match, just before ranking.</p>\n<p>The bonus is calculated as follows:</p>\n<pre><code>value_a = a value from dataset_a\nvalue_b = a value from dataset_b\nactual_a = total actual score for all keys that map to value_a in dataset_a\nactual_b = total actual score for all keys that map to value_b in dataset_b\npossible_a = total possible score for all keys that map to value_a in dataset_a\npossible_b = total possible score for all keys that map to value_b in dataset_b\nbonus_weight = score_ratio_bonus * (actual_a + actual_b) / (possible_a + possible_b)\n</code></pre>\n<p>This bonus calculated with <code>score_ratio_bonus</code> clears up the\nambiguity when the set of keys mapping to one value is a subset of the keys\nmapping to a different value in the same dataset.  The higher percentage\nof keys that match, the larger this bonus will be.</p>\n<p>Consider this example:</p>\n<pre><code>c = correlate.Correlator()\nc.dataset_a.set('breakin', X)\n\nc.dataset_b.set('breakin', Y)\nc.dataset_b.set_keys(['breakin', '2', 'electric', 'boogaloo'], Z)\n</code></pre>\n<p>Which is the better match, <code>X-&gt;Y</code> or <code>X-&gt;Z</code>?\nIn early versions of <strong>correlate</strong>, both matches got the exact same score.\nSo it was the luck of the draw as to which match <strong>correlate</strong> would choose.\n<code>score_ratio_bonus</code> disambiguates this scenario.  It awards a larger bonus\nto <code>X-&gt;Y</code> than it does to <code>X-&gt;Z</code>,  because a higher percentage of the keys\nmatched between <code>X</code> and <code>Y</code>.\nThat small boost is usually all that's needed to let <strong>correlate</strong>\ndisambiguate these situations and pick the correct match.</p>\n<p>Two things to note.  First, when I say \"keys\", this is another situation\nwhere the same key mapped twice to the same value is conceptually considered\nto be two different keys.\nIn the example in the <strong>Rounds</strong> subsection above, where <code>value_a</code> is <code>o</code> and\n<code>value_b</code> is <code>o2</code>, <code>possible_a</code> would be 6 and <code>possible_b</code> would be 4.</p>\n<p>Second, the scores used to compute <code>actual</code> and <code>possible</code> are <em>unweighted.</em>\nIf a match between two fuzzy keys resulted in a fuzzy score of <code>0.3</code>,\nthat adds <code>0.3</code> to both <code>actual_a</code> and <code>actual_b</code>, but each of those fuzzy\nkeys adds <code>1.0</code> to <code>possible_a</code> and <code>possible_b</code> respectively.\nModifiers like weights are ignored when computing <code>score_ratio_bonus</code>.</p>\n<h3>Choosing Which Matches To Keep: The \"Greedy Algorithm\" And The \"Match Boiler\"</h3>\n<p>Here's the abstract problem: if you're presented with\na list of match objects called <code>matches</code>,\nwhere each match object <code>M</code> has three attributes <code>value_a</code>, <code>value_b</code>,\nand <code>score</code>, how would you compute an optimal subset of <code>matches</code>\nsuch that:</p>\n<ul>\n<li>every discrete value of <code>value_a</code> and <code>value_b</code> appears only once, and</li>\n<li>the sum of the <code>score</code> attributes is maximized?</li>\n</ul>\n<p>Finding the perfectly optimal solution would require computing every\npossible set of matches, then computing the cumulative score of that\nset, then keeping the set with the highest score.  Unfortuantely,\nthat algorithm is <em>O</em>(n\u207f),\nwhich is so amazingly expensive that we can't even consider it.\n(You probably want your results from <strong>correlate</strong> before our sun\nturns into a red giant.)  Instead, <strong>correlate</strong> uses a\ncomparatively cheap \"greedy\" algorithm to compute the subset.\nIt's not <em>guaranteed</em> to produce the optimal subset, but in\npractice it seems to produce optimal results on real-world data.</p>\n<p>Here's a short description of the <strong>correlate</strong> \"greedy\" algorithm:</p>\n<ul>\n<li>Sort <code>matches</code> with highest score first.</li>\n<li>For every match <code>M</code> in <code>matches</code>:\n<ul>\n<li>if <code>value_a</code> hasn't been matched yet,</li>\n<li>and <code>value_b</code> hasn't been matched yet,\n<ul>\n<li>keep <code>M</code> as a good match,</li>\n<li>remember that <code>value_a</code> has been matched,</li>\n<li>and remember that <code>value_b</code> has been matched.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>The sorting uses Python's built-in sort (Timsort), so it's\n<em>O</em>(n log n).  It's implemented in C so it's pretty quick.\nThe <code>for</code> loop is <em>O</em>(n).</p>\n<p>The bad news: late in development of <strong>correlate</strong> I\nrealized there was a corner case where odds are good the\ngreedy algorithm wouldn't produce an optimal result.\nThe good news: this had a relatively easy fix, and the\nfix didn't make <strong>correlate</strong> any slower in the general case.</p>\n<p>So here's the corner case.  What if two matches in the\nlist are both viable, and they have the <em>same</em> score,\nand they have either <code>value_a</code> or <code>value_b</code> in common?\nIt's ambiguous as to which match the greedy algorithm\nwill choose.  But choosing the wrong one <em>could</em> result\nin less-than-optimal scoring in practice.</p>\n<p>Here's a specific example:</p>\n<ul>\n<li><code>dataset_a</code> contains fuzzy keys <code>fka1</code> and <code>fka2</code>.</li>\n<li><code>dataset_b</code> contains fuzzy keys <code>fkbH</code> and <code>fkbL</code>.\nAny match containing <code>fkbH</code> has a higher score than any match containing <code>fkbL</code>.\n(H = high scoring, L = low scoring.)</li>\n<li>The matches<code>fka1-&gt;fkbH</code> and <code>fka2-&gt;fkbH</code> have the same score.</li>\n<li>The match <code>fka1-&gt;fkbL</code> has a lower score than <code>fka2-&gt;fkbL</code>.</li>\n</ul>\n<p><strong>correlate</strong> should prefer <code>fka2-&gt;fkbL</code> to <code>fka1-&gt;fkbL</code>.\nBut the greedy algorithm can only pick that match if it\npreviously picked <code>fka1-&gt;fkbH</code>.  And there's no guarantee\nthat it would!  If two items in the list have the same score,\nit's ambiguous which one the greedy algorithm would choose.\nTo handle this properly it needs to look ahead and experiment.</p>\n<p>My solution for this is what I call the \"match boiler\", or the \"boiler\"\nfor short.  The boiler uses a hybrid approach.  By default,\nwhen the scores for matches are unique, it uses the \"greedy\"\nalgorithm.  If it encounters a run of items with matching scores,\nwhere any of those items have <code>value_a</code> or <code>value_b</code> in common,\nit recursively runs an experiment where it keeps each of those\nitems in turn.  It computes the score from each of these recursive\nexperiments and keeps the one with the highest score.</p>\n<p>(If two or more experiments have the same score, it keeps the first one\nit encountered with that score--but, since the input to the match boiler is\na list, sorted with highest scores to the end, technically it's the <em>last</em>\nentry in the list that produced the high-scoring experiment.)</p>\n<p>With the \"match boiler\" in place, <strong>correlate</strong> seems to produce optimal\nresults even in these rare ambigous situations.</p>\n<p>I'm honestly not sure what the <em>big-O</em> notation is for the \"match boiler\".\nThe pathological worst case\nis <em>probably</em> on the order of <em>O</em>(n log n), where the <code>log n</code> component\nrepresents the recursions.\nIn this case, every match has the same score, and they're all connected to\neach other via having <code>value_a</code> and <code>value_b</code> in common.  I still don't\nthink the \"match boiler\" would be as bad as <em>O</em>(n\u00b2).\nThe thing is, sooner or later the recursive step would cut the\n\"group\" of \"connected items\" in half (see next section).  It's guaranteed\n<em>not</em> to recurse on every single item.\nSo I assert that roughly cuts the number of recursive\nsteps down to <code>log n</code>, in the pathological worst case that you would\nnever see in real-world data.</p>\n<h4>Cheap Recursion And The \"Grouper\"</h4>\n<p>But wait!  It gets even more complicated!</p>\n<p>Compared to the rest of the algorithm, the recursive step is quite expensive.\nIt does reduce the domain of the problem at every step, so it's guaranteed\nto complete... someday.  But if we're not careful, it'll perform a lot\nof expensive and needless redundant calculations.  So there are a\nbunch of optimizations to the recursive step, mainly to do with the\ngroup of matches that have the same score.</p>\n<p>The first step is to analyze these matches and boil them out\ninto \"connected groups\".  A \"connected group\" is a set of\nmatch objects where either each object has a <code>value_a</code> or a\n<code>value_b</code> in common with another object in the group.  These\nare interesting, because choosing one of the matches from these\ngroups will remove at least one other value from that group\nfrom consideration.\nThere's a utility function called <code>grouper()</code> that computes\nthese connected groups.  (<code>grouper()</code> only handles the case\nwhen <code>reuse_a == reuse_b == False</code>; there are alternate\nimplementations to handle the other possible cases.)</p>\n<p>The second step is to take those \"connected groups\", and, for\nevery group containing only one match object, \"keep\" it immediately.\nWe already know we're keeping these, and it's cheaper to do it now.</p>\n<p>The third step is to recurse over each of the values of the\nsmallest connected group of size 2 or more.  Why the smallest?\nBecause it's cheaper.  Let's say there are 50 items left\nin the list of matches.  At the top are 6 match objects\nwith the same score.  There's two groups: one of length 2,\nthe other of length 4.\nThe number of operations we'll perform by looping and\nrecursing is, roughly, <strong>N</strong> \u2022 <strong>M</strong>, where <strong>N</strong> is <code>len(group)</code>\nand <strong>M</strong> is <code>len(matches - group)</code>.  So which one is cheaper:</p>\n<ul>\n<li>2 x 48, or</li>\n<li>4 x 46?</li>\n</ul>\n<p>Obviously the first one!</p>\n<p>(There's a theoretical opportunity for further optimization here:\nwhen recursing, if there's more than one connected group of length 2\nor greater, pass in the list of groups we <em>didn't</em>\nconsume to the recursive step.  That would save the recursive\ncall from re-calculating the connected groups.  In practice I imagine this\nhappens rarely, so handling it would result in a couple of <code>if</code>\nbranches that never get taken.  Also, it's a little more complicated\nthan it seems, because you'd have to re-use the <code>grouper()</code> on\nthe group you're examining before passing it down, because it might\nsplit it into two groups.  In practice it wouldn't speed up anybody's\ncorrelations, and it'd make the code more complicated.  So let's skip it.\nThe code is already more-or-less correct in these rare circumstances\nand that's good enough.)</p>\n<h4>The Match Boiler Reused For Fuzzy Key Scoring</h4>\n<p>Once my first version of the \"match boiler\" was done, I realized I could reuse\nit for boiling down all fuzzy key matches too.  Fuzzy key matches already\nused basically the same \"greedy\" algorithm that were used for matches,\nand I realized the same corner case existed here too.</p>\n<p>My first attempt was quite complicated, as the \"match boiler\" doesn't\nitself understand rounds.  I added a callback which it'd call every time it\nkept a match, which passed in the keys that got matched.  Since those keys\nwere now \"consumed\", I would inject new matches using those keys from\nsubsequent rounds (if any). This worked, but the code was complicated.</p>\n<p>And it got even more complicated later when I added the recursive step!\nI had to save and restore all the state of which fuzzy keys had been\nconsumed from which rounds.  I wound up building it into the subclass\nof <code>MatchBoiler</code>, which is part of why <code>MatchBoiler</code> clones itself\nwhen recursing.  This made the code cleaner but it was still clumsy\nand a bit slow.</p>\n<p>The subsequent rewrite using the <code>sort_by</code> tuple was a big win all around:\nit simplified the code, it let me remove the callback, and it let the match\nboiler implicitly handle all the rounds without really understanding them.</p>\n<p>But this is why it's so important that the boiler is super-stable.\nEarlier versions of the match boiler assumed it could re-sort the\ninput array any time it wanted.  But the array passed in was sorted\nby score <em>then</em> by round numbers--highest score is most important,\nlowest round number is second-most important.\nAnd the array is sorted with highest score, then lowest round number, last.\nWhen recursing, the match boiler has to prefer the <em>last</em> entry in its\ninput that produced the same score--otherwise, it might accidentally\nconsume a key from a later round before consuming that key from an\nearlier round.</p>\n<p>I didn't want to teach the boiler to understand this <code>sort_by</code> tuple.\nHappily, I didn't have to.  It wasn't much work to ensure that the boiler\nwas super-stable, and once that was true it always produced correct results.\nThis had the added benefit of being a bit faster, too!</p>\n<h4>Theoretical Failings Of The Match Boiler</h4>\n<p>Even with the boiler, you can still contrive scenarios where <strong>correlate</strong>\nwill produce arguably sub-optimal results.  The boiler only tries experiments\nwhere the matches have the same score.  But it's possible that the\ngreedy algorithm may find a local maximum that causes it to miss the\nglobal maximum.</p>\n<p>If <code>A</code> and <code>B</code> are values in <code>dataset_a</code>, and <code>X</code> and <code>Y</code> are\nvalues in <code>dataset_b</code>, and the matches have these scores:</p>\n<pre><code>A-&gt;X == 10\nA-&gt;Y == 9\nB-&gt;X == 8\nB-&gt;Y == 1\n</code></pre>\n<p>In this scenario, the boiler will pick <code>A-&gt;X</code>, which means it's\nleft with <code>B-&gt;Y</code>.  Total score: 11.  But if it had picked <code>A-&gt;Y</code>,\nthat means it would get to pick <code>B-&gt;X</code>, and the total score would be 17!\nAmazing!</p>\n<p>Is that better?  Your first reaction is probably \"of course!\".\nBut in an abstract, hypothetical scenario like this, it's\nhard to say for sure.</p>\n<p>Anyway I doubt this is a real problem in practice.  Ensuring <strong>correlate</strong>\nhandles the ambiguous scenario where items had identical scores is already\n\"gilding the lily\", considering how rare it happens with real-world data.\nAnd when would real data behave in this contrived way?  Why\nwould <code>A</code> score so highly against <code>X</code> and <code>Y</code>, but <code>B</code> scores\nhigh against <code>X</code> but low against <code>Y</code>?  If <code>B</code> is a good match for <code>X</code>,\nand <code>X</code> is a good match for <code>A</code>, and <code>A</code> is a good match for <code>Y</code>, then,\nby transitivity, with real-world data, <code>B</code> is probably a good match\nfor <code>Y</code>.</p>\n<p>I think pathological scenarios where the \"match boiler\" will fail like\nthis aren't realistic.  And the only way I can think of to fix it is\nwith the crushingly expensive <em>O</em>(n\u207f) algorithm.\nIt's just not worth it.  So, relax!  YAGNI.</p>\n<h3>Ranking</h3>\n<p>Ranking information can help a great deal.\nIf a value in <code>dataset_a</code> is near the beginning, and the order\nof values is significant, then we should prefer matching it to values\nin <code>dataset_b</code> near the beginning too.  Matching the first\nvalue in <code>dataset_a</code>\nagainst the last value in <code>dataset_b</code> is probably bad.</p>\n<p>Conceptually it works as follows: when scoring a match,\nmeasure the distance between\nthe two values and let that distance influence the score.  The closer\nthe two values are to each other, the higher the resulting score.</p>\n<p>But how do you compute that delta?  What do the ranking numbers mean?\n<strong>correlate</strong> supports two possible interpretations\nof the rankings, what we'll call <em>absolute</em> and <em>relative</em> ranking.\nThese two approaches differ in how they compare the ranking numbers,\nas follows:</p>\n<ul>\n<li><em>Absolute</em> ranking assmes the ranking numbers are the same\nfor both datasets.  <code>ranking=5</code> in <code>dataset_a</code> is a perfect\nmatch to <code>ranking=5</code> in <code>dataset_b</code>.</li>\n<li><em>Relative</em> ranking assumes that the two datasets represent the\nsame range of data, and uses the ratio of the ranking of a value\ndivided by the highest ranking set in that dataset to compute\nits relative position.  If the highest ranking we saw in a\nparticular dataset was <code>ranking=150</code>,\nthen a value that has <code>ranking=12</code> set is calculated to be 8%\nof the way from the beginning to the end.  This percentage\nis calculated similarly for both datasets, and the distance\nbetween two values is the distance between these two percentages.</li>\n</ul>\n<p>For example, if <code>dataset_a</code> had 100 items ranked 1 to 100,\nand <code>dataset_b</code> had 800 items ranked 1 to 800,\na value to <code>dataset_a</code> with <code>ranking=50</code> in <em>absolute</em> ranking\nwould be considered closest to a value in <code>dataset_b</code> with <code>ranking=50</code>,\nbut when using <em>relative</em> ranking\nit'd be considered closest to a value in <code>dataset_b</code> with <code>ranking=400</code>.</p>\n<p>Which one does <strong>correlate</strong> use?  It's configurable with the <code>ranking</code>\nparameter to <code>correlate()</code>.  By default it uses \"best\" ranking.\n\"Best\" ranking means <strong>correlate</strong> will compute scores using <em>both</em>\nmethods and choose the approach with the highest overall score.\nYou can override this by supplying a different value to <code>ranking</code>\nbut this shouldn't be necessary.  (Theoretically it should be faster\nto use a specific ranking approach.  Unfortunately this hasn't been\noptimized yet, so using only one ranking doesn't really speed things up.)</p>\n<p>Ranking is the last step in computing the score of a match.\nAs for how ranking affects the score, it depends on whether you\nuse <code>ranking_bonus</code> or <code>ranking_factor</code>.</p>\n<p>Both approaches start with these four calculations:</p>\n<pre><code>semifinal_scores_sum = sum of all \"semifinal\" scores above\nranking_a = the ranking value computed for value_a\nranking_b = the ranking value computed for value_b\nranking_score = 1 - abs(ranking_a - ranking_b)\n</code></pre>\n<p><code>ranking_bonus</code> is then calculated per-match as follows:</p>\n<pre><code>bonus = ranking_score * ranking_bonus\nfinal_score = semifinal_scores_sum + bonus\n</code></pre>\n<p><code>ranking_factor</code> is also calculated per-match, as follows:</p>\n<pre><code>unranked_portion = (1 - ranking_factor) * semifinal_scores_sum\nranked_portion = ranking_factor * semifinal_scores_sum * ranking_score\nfinal_score = unranked_portion + ranked_portion\n</code></pre>\n<p>(If you don't use either, the final score for the match is effectively\n<code>semifinal_scores_sum</code>.)</p>\n<p>Obviously, <code>ranking</code> must be set on both values in both datasets to\nproperly compute <code>ranking_score</code>.  If it's not set on <em>both</em> values\nbeing considered for a match, <strong>correlate</strong> still applies\n<code>ranking_bonus</code> or <code>ranking_factor</code> as usual, but it skips the\ninitial four calculations and just uses a <code>ranking_score</code> of 0.</p>\n<h2>Final Random Topics</h2>\n<h3>Debugging</h3>\n<p>When all else fails... what next?</p>\n<p><strong>correlate</strong> can optionally produce an enormous amount of debug output.\nThe main feature is showing every match it tests, and the score arrived\nat for that match, including every step along the way.  This log output\nquickly gets very large; even a comparison of 600x600 elements will produce\ntens of megabytes of output.</p>\n<p>Unfortunately, producing this much debugging output incurred a measurable\nperformance penalty--even when you had logging turned off!  It was mostly\nin computing the \"f-strings\" for the log, but also simply the calls to\nthe logging functions added overhead too.</p>\n<p>My solution: by default, each of the debug print statements\nis commented out.\n<strong>correlate</strong> ships with a custom script preprocessor called\n<code>debug.py</code> that can toggle debugging on and off, by uncommenting and\nre-commenting the debug code.</p>\n<p>How does it know which lines to uncomment?  Each line of the logging-only\ncode ends with the special marker \"<code>#debug</code>\".</p>\n<p>To turn on this logging, run the <code>debug.py</code> script in the same directory\nas <strong>correlate's</strong> <code>__init__.py</code> script.  Each time you run it, it'll\ntoggle the debug print statements.\nNote that the debug feature in <strong>correlate</strong> requires Python 3.8 or higher,\nbecause it frequently uses the beloved \"equals sign inside f-strings\" syntax.</p>\n<p>By default the logging is sent to stdout.  If you want to override where\nit's sent, write your own <code>print</code> function, and assign it to your\n<code>Correlator</code> object before calling <code>correlate()</code>.</p>\n<p>The format of the log is undocumented and subject to change.  Good luck!\nThe main thing you'll want to do is figure out the \"index\" of the values\nin datasets a and b that you want to compare, then search for <code>\" (index_a) x (index_b) \"</code>.\nFor example, if the match you want to see is between value index 35 in <code>dataset_a</code>\nand value index 51 in <code>dataset_b</code>, search in the log for <code>\" 35 x 51 \"</code>.\n(The leading and trailing spaces means your search will skip over,\nfor example, <code>235 x 514</code>.)</p>\n<h3>Alternate Fuzzy Scoring Approaches That Didn't Work</h3>\n<p>The math behind fuzzy scoring is a bit surprising, at least to me.\nIf you boil down the formula to its constituent factors,\nyou'll notice one of the factors is <code>fuzzy_score</code> <em>cubed.</em>\nWhy is it <em>cubed?</em></p>\n<p>The simplest answer: that's the first approach that worked\nproperly.  To really understand why, you'll need to understand the\nhistory of fuzzy scoring in <strong>correlate</strong>--all the approaches\nI tried first that <em>didn't</em> work.</p>\n<p>Initially, the score for a fuzzy match was simply the fuzzy score\nmultiplied by the weights and other modifiers.\nThis was always a dumb idea; it meant fuzzy matches had <em>way</em> more\nimpact on the score than they should have.  This was particularly\ntrue when you got down to the last 10% or 20% of your matches,\nby which point the score contributed by exact keys had\nfallen off a great deal.  This approach stayed in for what is,\nin retrospect, an embarassingly long time; I'd convinced myself\nthat fuzzy keys were innately more <em>interesting</em> than exact keys,\nand so this comparative importance was fitting.</p>\n<p>Once I realized how dumb that was, the obvious approach was to score\nthem identically to exact keys--divide the fuzzy score by the product\nof the number of keys this <em>could</em> have matched against in each\nof the two datasets.  This was obviously wrong right away.\nIn the \"YTJD\" test, every value had the same fuzzy keys, depending\non the test: every value always had a fuzzy date key, and depending\non the test it might have a fuzzy title key and/or a fuzzy episode number\nkey too.  So each of the 812 values in the first dataset had one\nfuzzy key for each type, and each of the 724 values in the second dataset\ndid too.  Even if we got a perfect fuzzy match, the maximum score\nfor a fuzzy match was now <code>1.0 / (812 * 724)</code> which is <code>0.0000017</code>.  So now\nwe had the opposite problem: instead of being super important, even a perfect\nfuzzy match contributed practically nothing to the final score.</p>\n<p>After thinking about it for a while,\nI realized that the exact key score wasn't <em>really</em> being\ndivided by the number of <em>keys</em> in the two datasets, per se;\nit was being divided by the total possible <em>score</em> contributed\nby that key in each of the two datasets.  So instead of\ndividing fuzzy scores by the number of keys, they should be divided\nby the cumulative fuzzy score of all matches involving those two keys.\nThat formula looks like\n<code>fuzzy_score / (sum_of_fuzzy_scores_for_key_in_A * sum_of_fuzzy_scores_for_key_in_B)</code>.</p>\n<p>This was a lot closer to correct!  But this formula had a glaring new problem.\nLet's say that in your entire correlation, <code>dataset_a</code> only had one\nfuzzy key that maps to a single value,\nand <code>dataset_a</code> only had one fuzzy key that also only maps to a single value.\nAnd let's say the fuzzy score you get from matching those two keys\nis <code>0.000001</code>--a really terrible match.\nLet's plug those numbers into our formula, shall we.  We get <code>0.000001 / (0.000001 * 0.000001)</code>\nwhich is <code>1000000.0</code>.  A million!  That's crazy!  We've taken an absolutely\nterrible fuzzy match and inflated its score to be nonsensically high.\nClearly that's not right.</p>\n<p>This leads us to the formula that actually works.  The insight here\nis that the same formula needs to work identically for exact keys.\nIf you take this formula and compute it where every <code>fuzzy_score</code>\nis 1 (or 0), it produces the same result as the formula for exact keys.\nSo the final trick is that we can multiply by <code>fuzzy_score</code> wherever we need\nto, because multiplying by 1 doesn't change anything.  That means\nthe resulting formula will still be consistent with the exact keys\nscoring formula.  And what worked was the formula where we multiply by\n<code>fuzzy_score</code> three times!</p>\n<p>Here again is the formula used to compute the score for a fuzzy match,\nsimplified to ignore weights and rounds:</p>\n<pre><code>value_a = a value from dataset_a\nvalue_b = a value from dataset_b\nkey_a = a fuzzy key in dataset_a that maps to value_a\nkey_b = a fuzzy key in dataset_b that maps to value_b\nfuzzy_score = the result of key_a.compare(key_b)\ncumulative_a = the cumulative score of all successful matches between key_a and all fuzzy keys in dataset_b\ncumulative_b = the cumulative score of all successful matches between key_b and all fuzzy keys in dataset_a\nscore_ratio_a = fuzzy_score / cumulative_a\nscore_ratio_b = fuzzy_score / cumulative_b\nunweighted_score = fuzzy_score * score_ratio_a * score_ratio_b\n</code></pre>\n<p>The final trick really was realizing what <code>score_ratio_a</code> represents.\nReally, it represents the ratio of how much <em>this</em> fuzzy match for <code>key_a</code>\ncontributed to the sum of <em>all</em> fuzzy matches for <code>key_a</code>\nacross all successful matches in <code>dataset_a</code>.</p>\n<h3>Why correlate Doesn't Use The Gale-Shapley Algorithm</h3>\n<p>A friend asked me if the problem <strong>correlate</strong> solves is isomorphic to the Stable Matching Problem:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Stable_matching_problem\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Stable_matching_problem</a></p>\n<p>Because, if it was, I could use the Gale-Shapley algorithm:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Gale%E2%80%93Shapley_algorithm\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Gale%E2%80%93Shapley_algorithm</a></p>\n<p>I thought about this for quite a while, and I don't think the problem <strong>correlate</strong>\nsolves maps perfectly onto the stable matching problem.  <strong>correlate</strong> solves a problem that is:</p>\n<ol>\n<li>simpler,</li>\n<li>different, and</li>\n<li>harder.</li>\n</ol>\n<p>For inputs that are valid for both Gale-Shapley and <strong>correlate</strong>, I assert that both\nalgorithms will return the same results, but <strong>correlate</strong> will be faster.</p>\n<p>In all the following examples, <code>A</code>, <code>B</code>, and <code>C</code> are values in <code>dataset_a</code> (aka \"men\") and <code>X</code>, <code>Y</code>, and <code>Z</code> are values\nin <code>dataset_b</code> (aka \"women\").  The expression <code>A: XY</code> means \"<code>A</code> prefers <code>X</code> to <code>Y</code>\". The expression <code>A:X=1.5</code> means\n\"when matching <code>A</code> and <code>X</code>, their score is <code>1.5</code>\".  When I talk about Gale-Shapley, <code>dataset_a</code> will stand for the\nmen and <code>dataset_b</code> will stand for the women, which means <code>A</code> is a man and <code>X</code> is a woman.  Where we need to talk\nabout the matches themselves, we'll call them <code>P</code> and <code>Q</code>.</p>\n<h4>How is it simpler?</h4>\n<p>The stable matching problem only requires a local ordering, where the preferences of any value in either dataset\nare disjoint from the orderings of any other value.  But <strong>correlate</strong> uses an absolute \"score\"--a number--to compute\nthese preferences, and this score is symmetric; if <code>A:X=1.5</code>, then <code>X:A=1.5</code> too.</p>\n<p>On this related Wikipedia page:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Lattice_of_stable_matchings\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Lattice_of_stable_matchings</a></p>\n<p>we find a classic example of a tricky stable matching problem:</p>\n<pre><code>A: YXZ\nB: ZYX\nC: XZY\n\nX: BAC\nY: CBA\nZ: ACB\n</code></pre>\n<p>Gale-Shapley handles this situation with aplomb.  Does <strong>correlate</strong>?  The answer is... this arrangement of constraints\njust can't <em>happen</em> with <strong>correlate</strong>, because it uses scores to establish its preferences, and the scores are symmetric.\nThere are nine possible pairings with those six values. It's impossible to assign a unique score to each of those nine\npairings such that the preferences of each value match those constraints.</p>\n<p>(I'm certain.  Not only did I work my way through it, I also wrote a brute-force program that tried every\npossible combination. 362,880 attempts later, I declared failure.)</p>\n<h4>How is it different?</h4>\n<p>One minor difference: Gale-Shapley specifies that the two sets be of equal size; <strong>correlate</strong> permits the two sets to be\ndifferent sizes.  But extending Gale-Shapley to handle this isn't a big deal.  Simply extend the algorithm to say that,\nif the size of the two datasets are inequal, swap the datasets if necessary so that the \"men\" are the larger group.\nThen, if you have an unmatched \"man\" who iterates through all the \"women\" and nobody traded up to him, he remains\nunmatched.</p>\n<p>The second thing: Gale-Shapley requires that every value in each dataset expresses a strictly ordered preference\nfor every value in the other dataset. But in <strong>correlate</strong>, two matches can have the same score.</p>\n<p>Consider this expression of a <strong>correlate</strong> problem:</p>\n<pre><code>A:X=100\nA:Y=1\n\nB:X=100\nB:Y=2\n</code></pre>\n<p>Gale-Shapley as originally stated can't solve that problem, because X doesn't prefer A or B--it likes\nthem both equally.  It wouldn't be hard to extend Gale-Shapley to handle this; in the case where\nit prefers two equally, let it arbitrarily pick one.  For example, if X prefers A and B equally,\nsay \"maybe\" to the first one that asks, and then let that decide for you that you prefer A to B.</p>\n<h4>How is it harder?</h4>\n<p>Here's the real problem.</p>\n<p><strong>correlate</strong> uses a numerical score to weigh the merits of each match, and seeks to\nmaximize the cumulative score across <em>all</em> matches. Gale-Shapley's goals are comparatively\nmodest--any match that's stable is fine. There may be multiple stable matchings; Gale-Shapley\nconsiders them all equally good.</p>\n<p>In practice, I think if you apply the original Gale-Shapley algorithm to an input data set\nwhere the matches have numerical scores, it <em>would</em> return the set of matches with the\nhighest cumulative score.  In thinking about it I haven't been able to propose a situation\nwhere it wouldn't.  The problem lies in datasets where two matches have the <em>same</em> score--which\nthe original Gale-Shapley algorithm doesn't allow.</p>\n<p>Ensuring that <strong>correlate</strong> returns the highest cumulative score in this situation\nrequired adding the sophisticated recursive step to the \"match boiler\".  We'd have to make\na similar modification to Gale-Shapley, giving it a recursive step.  Gale-Shapley is\nalready <em>O</em>(n\u00b2); I think the modified version would be <em>O</em>(n\u00b2 log n).\n(But, like <strong>correlate</strong>, this worst-case shouldn't happen with real-world data.)\nAnyway, a modified Gale-Shapley that works for all <strong>correlate</strong> inputs is definitely\nmore expensive than what <strong>correlate</strong> has--or what it needs.</p>\n<h4>Mapping Gale-Shapley To The Correlate Greedy Algorithm</h4>\n<p>Again, the set of valid inputs for <strong>correlate</strong> and Gale-Shapley aren't\nexactly the same.  But there's a lot of overlap.  Both algorithms can\nhandle an input where:</p>\n<ul>\n<li>every match between a man <code>A</code> and a woman <code>X</code> is assigned a numerical score,</li>\n<li>every operation involving any particular man <code>A</code> has a unique score,</li>\n<li>and also for every woman <code>X</code>,</li>\n<li>and there are exactly as many men as there are women.</li>\n</ul>\n<p>I assert that, for these mutually acceptable inputs, both algorithms\nproduce the same result.  Here's an informal handwave-y proof.</p>\n<p>First, since Gale-Shapley doesn't handle preferring two matches equally,\nwe'll only consider datasets where all matches have a unique score.\nThis lets us dispense with the match boiler's \"recursive step\", so all we\nneed is the comparatively simple \"greedy algorithm\".  (Again: this\n\"greedy algorithm\" is much cheaper than Gale-Shapley, but as I'll show,\nit's sufficient for the simple problem domain we face here.)</p>\n<p>So let's run Gale-Shapley on our dataset.  And every time we perform\nan operation, we write it down--we write down \"man <code>A</code> asked woman <code>X</code>\"\nand whether her reply was <em>maybe</em> or <em>no</em>.</p>\n<p>Observe two things about this list:</p>\n<ul>\n<li>\n<p>First, order is significant in this list of operations.  If you change\nthe order in which particular men ask particular women, the pattern of\nresulting <em>maybe</em> and <em>no</em> responses will change.</p>\n</li>\n<li>\n<p>Second, the <em>last</em> maybe said by each woman is always, effectively, a <em>yes</em>.</p>\n</li>\n</ul>\n<p>Iterate backwards through this list of operations, and the first time you\nsee any particular woman reply with <em>maybe</em>, change that answer to a <em>yes.</em></p>\n<p>Next, observe that we can swap any two adjacent operations--with one important\ncaveat.  We must maintain an invariant: for every woman <code>X</code> for every operation\ncontaining <code>X</code> that happens after <code>X</code> says <em>yes</em>, <code>X</code> must say <em>no.</em></p>\n<p>Thus, if there are two adjacent operations <code>P</code> and <code>Q</code>, where <code>P</code>\nis currently first, and we want to swap them so <code>Q</code> is first,\nand if the following conditions are all true:</p>\n<ul>\n<li>The same woman <code>X</code> is asked in both <code>P</code> and <code>Q</code>.</li>\n<li>In <code>Q</code> the woman <code>X</code> says either <em>maybe</em> or <em>yes.</em></li>\n<li>In <code>P</code> the woman <code>X</code> says <em>maybe.</em></li>\n</ul>\n<p>Then we can swap <code>P</code> and <code>Q</code> if and only if we change <code>X</code>'s\nresponse in <code>P</code> to <em>no.</em></p>\n<p>Now that we can reorder all the operations, let's sort the\noperations by score, with the highest score first.\nLet's call the operation with the highest score <code>P</code>,\nand say that it matches man <code>A</code> with woman <code>X</code>.</p>\n<p>We now know the following are true:</p>\n<ul>\n<li><code>X</code> is the first choice of <code>A</code>.  Therefore <code>A</code> will ask\n<code>X</code> first.</li>\n<li><code>A</code> is the first choice of <code>X</code>.  Therefore <code>X</code> is\nguaranteed to have said <em>yes</em>.</li>\n</ul>\n<p>Since the first operation <code>P</code> is guaranteed to be a <em>yes</em>,\nthat means that every subsequent operation involving either\n<code>A</code> or <code>X</code> must be a <em>no</em>.</p>\n<p>We now iterate down the list to find an operation <code>Q</code>\ninvolving man <code>B</code> and woman <code>Y</code>. We define <code>Q</code> as the\nfirst operation such that:</p>\n<ul>\n<li><code>Q != P</code>, and therefore <code>Q</code> is after <code>P</code> in our ordered list of operations,</li>\n<li><code>B != A</code>, and</li>\n<li><code>Y != X</code>.</li>\n</ul>\n<p>By definition <code>Q</code> must also be a <em>yes</em>.  If there are any operations\nbetween <code>P</code> and <code>Q</code>, these operations involve either <code>A</code> or <code>X</code>.\nTherefore they must be <em>no</em>.  Therefore <code>Q</code> represents the\nhighest remaining preference for both <code>B</code> and <code>Y</code>.</p>\n<p>Observe that the whole list looks like this.  Every <em>yes</em> is\nthe first operation for both that man and that woman in which\nthey weren't paired up with a woman or man (respectively) that\nhad already said <em>yes</em> to someone else.</p>\n<p>Therefore this list of operations now resembles the operations\nperformed by the <strong>correlate</strong> \"greedy\" algorithm, more or less.\nIt sorts the matches by score, then iterates down it.  For every\nman <code>A</code> and woman <code>X</code>, if neither <code>A</code> nor <code>X</code> has been matched yet,\nit matches <code>A</code> and <code>X</code> and remembers that they've been matched.</p>\n<p>It's possible that there's minor variation in the list of\noperations; any operation involving any man or any woman\n<em>after</em> they've been matched with a <em>yes</em> is extraneous.\nSo you can add or remove them all you like without affecting\nthe results.</p>\n<h2>Version History</h2>\n<p><strong>0.8.1</strong></p>\n<p>Fixed compatibility with Python 3.6.  All I needed to do was\nremove some <em>equals-sign-in-f-strings</em> usage in spots.</p>\n<p><strong>0.8</strong></p>\n<p>The result of loving hand-tuned optimization: <strong>correlate</strong> version 0.8\nis now an astonishing <em>19.5%</em> faster than version 0.7--and <em>27.3%</em> faster\nthan version 0.5!</p>\n<p>The statistics have been improved, including some useful timing information.\nThis really demonstrates how much slower fuzzy keys are.</p>\n<p>(To see for yourself, run <code>python3 tests/ytjd.test.py -v</code> and compare\nthe slowest test to the fastest, using the same corpus.  On my computer\nthe test without fuzzy keys is 14x faster than the one that uses\nfuzzy keys for everything!)</p>\n<p><strong>0.7</strong></p>\n<p>Careful micro-optimizations for both exact and fuzzy key\ncode paths have made <strong>correlate</strong> up to 7.5% faster!</p>\n<p>The <code>MatchBoiler</code> was made even more ridiculously stable.\nIt should now always:</p>\n<ul>\n<li>return <code>results</code> in the same order they appeared in in <code>matches</code>, and</li>\n<li>prefer the <em>last</em> equivalent item when two or more items\nproduce the same cumulative score.</li>\n</ul>\n<p><strong>0.6.1</strong></p>\n<p>Bugfix for major but rare bug: if there are multiple\ngroups of <code>len() &gt; 1</code> of \"connected\" match objects with\nthe same score, the match boiler would only keep the\nsmallest one--the rest were accidentally discarded.\n(<code>match_boiler_2_test()</code> was added to <code>tests/regression_test.py</code>\nto check for this.)</p>\n<p><strong>0.6</strong></p>\n<p>Big performance boost in \"fuzzy boiling\"!  Clever sorting of fuzzy matches,\nand improvements in the stability (as in \"stable sort\") of <code>MatchBoiler</code>,\nallowed using an unmodified boiler to process fuzzy matches.  This allowed\nremoval of <code>FuzzyMatchBoiler</code> and the <code>MatchBoiler.filter()</code> callback mechanism.</p>\n<p>Minor performance improvement in <code>MatchBoiler</code>: when recursing, find the\nsmallest group of connected matches with the same score,\nand only recursively check each of those,\nrather than all possibly-connected matches with the same score.</p>\n<p>Removed <code>key_reuse_penalty_factor</code>.\nIn the early days of <strong>correlate</strong>, it didn't understand rounds; if you mapped the same\nkey to the same value twice, it only remembered one mapping, the one with the\nhighest weight.  Later I added rounds but they didn't seem to add much signal.\nI thought redundant keys were uninteresting.  So I added <code>key_reuse_penalty_factor</code>.\nThat let you turn down the signal they provided, in case it\nwas adding more noise than actual useful signal.\nIt wasn't until the realization that <code>key-&gt;value</code> in round 0 and <code>key-&gt;value</code>\nin round 1 were conceptually <em>two different keys</em> that I really understood\nhow redundant mappings of the same key to the same value should work.  And\nonce rounds maintained distinct counts of <code>keys / scores</code> for the scoring\nformula, redundant keys in different rounds became <em>way</em> more informative.\nI now think <code>key_reuse_penalty_factor</code> is dumb and worse than useless and\nI've removed it.  If you think <code>key_reuse_penalty_factor</code> is useful,\nplease contact me and tell me why!  Or, quietly just pre-multiply it into\nyour weights.</p>\n<p>The cumulative effect: a speedup of up to 30% in fuzzy match boiling,\nand up to 5% on YTJD tests using a lot of fuzzy keys.  Match boiling got\nslightly faster too.</p>\n<p><strong>0.5.1</strong></p>\n<p>Bugfix release.  In the original version, if a match didn't have any matches between\nfuzzy keys (with a positive score), it ignored the weights of its exact keys and just\nused the raw exact score.</p>\n<p><strong>0.5</strong></p>\n<p>Initial public release.</p>\n\n          </div>"}, "last_serial": 7161704, "releases": {"0.5": [{"comment_text": "", "digests": {"md5": "aa1a83a66f922c303b68c4ced92db9b1", "sha256": "54a772240b0166910c371dfcd9d993f8683872d4835fcfd489ffea13056ff4a7"}, "downloads": -1, "filename": "correlate-0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "aa1a83a66f922c303b68c4ced92db9b1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 44992, "upload_time": "2020-04-07T07:42:38", "upload_time_iso_8601": "2020-04-07T07:42:38.072987Z", "url": "https://files.pythonhosted.org/packages/c0/97/bfa2950015686153fd51b94adf9f70beb63aafabfde49bc7ea4296a37e82/correlate-0.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cc83c6313629e86c5f6ca4ed7a1aeef8", "sha256": "c403380ff945d4d0bb28153902b45a336c3684baf600b5224ba2716d136f3455"}, "downloads": -1, "filename": "correlate-0.5.tar.gz", "has_sig": false, "md5_digest": "cc83c6313629e86c5f6ca4ed7a1aeef8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 85131, "upload_time": "2020-04-07T07:42:40", "upload_time_iso_8601": "2020-04-07T07:42:40.902470Z", "url": "https://files.pythonhosted.org/packages/45/15/7195dda3714caedc5bead5f9d189bcc8ec82c58275edf11a2b70415e7360/correlate-0.5.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "4199960031abbcbcbd6b2a3de8714b76", "sha256": "f018c253f2dc068771446cb88884e03e79768c739164f33a949c5b9cb38529b5"}, "downloads": -1, "filename": "correlate-0.5.1-py3-none-any.whl", "has_sig": false, "md5_digest": "4199960031abbcbcbd6b2a3de8714b76", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 38707, "upload_time": "2020-04-07T11:30:13", "upload_time_iso_8601": "2020-04-07T11:30:13.020536Z", "url": "https://files.pythonhosted.org/packages/44/ad/74313872b4d631aa479918aa6d256b5b17707b366412f152a112bde5cfe8/correlate-0.5.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "102bc39d2164f65e0c765169f2872378", "sha256": "b557700fea65644c18e03f57a80d69a79a09df668bd0b3214140923c2616a5f3"}, "downloads": -1, "filename": "correlate-0.5.1.tar.gz", "has_sig": false, "md5_digest": "102bc39d2164f65e0c765169f2872378", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 79219, "upload_time": "2020-04-07T11:30:14", "upload_time_iso_8601": "2020-04-07T11:30:14.605910Z", "url": "https://files.pythonhosted.org/packages/3f/7b/d9bc869f72c8c3aa7d27908d51b35bd6d63bc280254d7213a0a65f5125db/correlate-0.5.1.tar.gz", "yanked": false}], "0.6": [{"comment_text": "", "digests": {"md5": "2c5da10938082f2365ef44a4d6e2ab5e", "sha256": "cbb152d4f1b600f172df854906e3e340cce25ed9c931a0f8f9de512767cbfae1"}, "downloads": -1, "filename": "correlate-0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "2c5da10938082f2365ef44a4d6e2ab5e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 40528, "upload_time": "2020-04-14T07:43:11", "upload_time_iso_8601": "2020-04-14T07:43:11.845299Z", "url": "https://files.pythonhosted.org/packages/99/d8/42ccb183c606cdd7e31767cbcb6314f0e4d92e20a67c785103eb6a296473/correlate-0.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "39141307af648033ce60517cac589b45", "sha256": "09b2225baeb1a5c4649a5698751579f6bfca45b6398e00c32851916d01f6fe9b"}, "downloads": -1, "filename": "correlate-0.6.tar.gz", "has_sig": false, "md5_digest": "39141307af648033ce60517cac589b45", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 81786, "upload_time": "2020-04-14T07:43:14", "upload_time_iso_8601": "2020-04-14T07:43:14.495003Z", "url": "https://files.pythonhosted.org/packages/2a/5c/fecb320795c33961b6da41699fc6ec0c9912f56abe559aadba40f9d4b9cf/correlate-0.6.tar.gz", "yanked": false}], "0.6.1": [{"comment_text": "", "digests": {"md5": "5f2a9f171b9118c2fb3f7bda4b62e6a2", "sha256": "f839a5855f9a647d2e3b1d52edcc4d12806281a00164ec31e2b2b6bb155d7fd9"}, "downloads": -1, "filename": "correlate-0.6.1-py3-none-any.whl", "has_sig": false, "md5_digest": "5f2a9f171b9118c2fb3f7bda4b62e6a2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 41362, "upload_time": "2020-04-15T06:45:10", "upload_time_iso_8601": "2020-04-15T06:45:10.646113Z", "url": "https://files.pythonhosted.org/packages/16/6f/733ccd34eb77dd30ffe58122d43500105397e90c05232deae62c387443f5/correlate-0.6.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "285d342930750661391ede56e4d09f75", "sha256": "c03b50aca2a3936a725d0b7baeed4de1f8651ad69d300d6ce5049263178d69ce"}, "downloads": -1, "filename": "correlate-0.6.1.tar.gz", "has_sig": false, "md5_digest": "285d342930750661391ede56e4d09f75", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 82934, "upload_time": "2020-04-15T06:45:12", "upload_time_iso_8601": "2020-04-15T06:45:12.831241Z", "url": "https://files.pythonhosted.org/packages/2f/93/d55847d1aadd45bbc5f9c5c2d00dd95f52d30bbfe6f04ea251a7990ac481/correlate-0.6.1.tar.gz", "yanked": false}], "0.7": [{"comment_text": "", "digests": {"md5": "9adfb36119e2b0786cb5a4aff8fb77ce", "sha256": "7c05f2559e52b106337bb91531a49855e271632dceed6bc4786519aa52351c65"}, "downloads": -1, "filename": "correlate-0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "9adfb36119e2b0786cb5a4aff8fb77ce", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 47970, "upload_time": "2020-04-30T07:54:15", "upload_time_iso_8601": "2020-04-30T07:54:15.598648Z", "url": "https://files.pythonhosted.org/packages/fe/84/9f3cc4a375ffad58e1cb32bc8064743b1bd8253be289e49289c42eedf519/correlate-0.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "f7cdc1bc563f6e6a9bec555e4d442423", "sha256": "d41db73c31e1ae884377b86b27f20a674ab04df33de356904f50e10551651cc5"}, "downloads": -1, "filename": "correlate-0.7.tar.gz", "has_sig": false, "md5_digest": "f7cdc1bc563f6e6a9bec555e4d442423", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90069, "upload_time": "2020-04-30T07:54:17", "upload_time_iso_8601": "2020-04-30T07:54:17.877745Z", "url": "https://files.pythonhosted.org/packages/2c/e3/3153e16898f9bd8e0d9522f90a141a7c89b9b5cf3a3d6f497543efd7f2ac/correlate-0.7.tar.gz", "yanked": false}], "0.8": [{"comment_text": "", "digests": {"md5": "1456398ffae08ff6179772d2890a9ce6", "sha256": "db2b1976d1b92904c0861fcb45cd3237fc69abb0bc6201d0d24266ce1a08f860"}, "downloads": -1, "filename": "correlate-0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "1456398ffae08ff6179772d2890a9ce6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 48924, "upload_time": "2020-05-03T06:04:04", "upload_time_iso_8601": "2020-05-03T06:04:04.738437Z", "url": "https://files.pythonhosted.org/packages/2d/48/d1c2b6f345ce6a0ffbdc56b8ee202f33e28700c671acd655e99323310170/correlate-0.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "982821a5644c2a9fc0f5edb4f0338d04", "sha256": "66b42aee1bad3f4e89652a9b0d8f0975606fe99493590c3f3e07866c42a5eb81"}, "downloads": -1, "filename": "correlate-0.8.tar.gz", "has_sig": false, "md5_digest": "982821a5644c2a9fc0f5edb4f0338d04", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 90986, "upload_time": "2020-05-03T06:04:06", "upload_time_iso_8601": "2020-05-03T06:04:06.470169Z", "url": "https://files.pythonhosted.org/packages/e3/59/e2cf9e175c5f2a3a43652d3e76f72fedcb1bb36d774f8b5de6a6fad99cf1/correlate-0.8.tar.gz", "yanked": false}], "0.8.1": [{"comment_text": "", "digests": {"md5": "1520617bdb3eac7fd50faa7f8d13a749", "sha256": "b8d519be6292ca44d6ba2c14af8ee0333e025b7b576b696c31519b509457bedb"}, "downloads": -1, "filename": "correlate-0.8.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1520617bdb3eac7fd50faa7f8d13a749", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 49555, "upload_time": "2020-05-04T06:41:36", "upload_time_iso_8601": "2020-05-04T06:41:36.439738Z", "url": "https://files.pythonhosted.org/packages/63/50/02ce82296e9c91a10de3c30dcedd7c9a434dc6602bc3309afd112c293804/correlate-0.8.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b999db9438ef9bc15c74b2c850788256", "sha256": "cf0b61dbf72f29d33b7bf9301dddca8247c87cc514a08d0ed979fe5ba7e76902"}, "downloads": -1, "filename": "correlate-0.8.1.tar.gz", "has_sig": false, "md5_digest": "b999db9438ef9bc15c74b2c850788256", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 91869, "upload_time": "2020-05-04T06:41:38", "upload_time_iso_8601": "2020-05-04T06:41:38.419813Z", "url": "https://files.pythonhosted.org/packages/bc/f8/8bc2f9287da89c393beafec0fe8c0d877ea5d52e2cdd8b0dd67e6f301e51/correlate-0.8.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1520617bdb3eac7fd50faa7f8d13a749", "sha256": "b8d519be6292ca44d6ba2c14af8ee0333e025b7b576b696c31519b509457bedb"}, "downloads": -1, "filename": "correlate-0.8.1-py3-none-any.whl", "has_sig": false, "md5_digest": "1520617bdb3eac7fd50faa7f8d13a749", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 49555, "upload_time": "2020-05-04T06:41:36", "upload_time_iso_8601": "2020-05-04T06:41:36.439738Z", "url": "https://files.pythonhosted.org/packages/63/50/02ce82296e9c91a10de3c30dcedd7c9a434dc6602bc3309afd112c293804/correlate-0.8.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b999db9438ef9bc15c74b2c850788256", "sha256": "cf0b61dbf72f29d33b7bf9301dddca8247c87cc514a08d0ed979fe5ba7e76902"}, "downloads": -1, "filename": "correlate-0.8.1.tar.gz", "has_sig": false, "md5_digest": "b999db9438ef9bc15c74b2c850788256", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 91869, "upload_time": "2020-05-04T06:41:38", "upload_time_iso_8601": "2020-05-04T06:41:38.419813Z", "url": "https://files.pythonhosted.org/packages/bc/f8/8bc2f9287da89c393beafec0fe8c0d877ea5d52e2cdd8b0dd67e6f301e51/correlate-0.8.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:05 2020"}