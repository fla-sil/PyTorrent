{"info": {"author": "Starkes org.", "author_email": "devStarkes@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Topic :: Internet :: WWW/HTTP", "Topic :: Internet :: WWW/HTTP :: Site Management"], "description": "# Instalatiom\n```sh\npip install webdownloader\n```\n# Downloader\n### Basic functional\n```python\nfrom webdownloader import Downloader\ndownloader = Downloader()\npage_content = downloader.get_page('https://www.google.com/')\nlen(page_content)\n# or you can return full response\nresponse = downloader.get_page('https://www.google.com/', full_response=True)\nresponse.status_code\n# by default it will create 3 attempts to open connection if there is a problem with a server, but you can use custom amount\nresponse = downloader.post_page('https://www.some-not-reliable-site.com/', specific_attempts_count=5)\n```\n### Proxies usage\n```python\nfrom webdownloader import Downloader\ndownloader = Downloader(proxy_string_list=['104.144.176.1:3128', '102.152.145.103:3128', '157.152.145.103:3128'], change_proxies_manually=True)\n# from one random proxy (if one of proxies is not working it will take another one)\npage_content = downloader.get_page('https://www.google.com/')\n# from the same proxy\npage_content = downloader.get_page('https://www.google.com/')\n# from random proxy\ndownloader.change_proxies()\npage_content = downloader.get_page('https://www.google.com/')\n````\n### Cookies and headers\n```python\nfrom webdownloader import Downloader\ndownloader = Downloader()\n# cookies as a dict\npage_content = downloader.get_page('https://www.google.com/', cookies={'TOKEN': '1234567890'})\n# cookies as a string (from browser)\npage_content = downloader.get_page('https://www.google.com/', cookies_text='CONSENT=YES+UK.en+; SID=somesid')\n# by default there is a user agent in headers but you can change all headers\npage_content = downloader.get_page('https://www.google.com/', headers={'User-Agent': 'Mozilla/5.0'})\n# get session sookies\nsession_cookies_dict = downloader.get_session_cookies()\n# save cookies to file\ndownloader.save_cookies_to_file(session_cookies_dict, name='mycookies')\n# load cookies from file\ncookies_dict = downloader.get_cookies_from_file(name='mycookies')\n````\n# License\nMIT", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/devStarkes/webdownloader", "keywords": "webdownloader downloder web extraction parsing scraping mining", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "webdownloader", "package_url": "https://pypi.org/project/webdownloader/", "platform": "", "project_url": "https://pypi.org/project/webdownloader/", "project_urls": {"Homepage": "http://github.com/devStarkes/webdownloader"}, "release_url": "https://pypi.org/project/webdownloader/0.1.2/", "requires_dist": null, "requires_python": "", "summary": "webdownloader is a tool for web data extraction", "version": "0.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p># Instalatiom\n<tt>`sh\npip install webdownloader\n`</tt>\n# Downloader\n### Basic functional\n<tt>`python\nfrom webdownloader import Downloader\ndownloader = Downloader()\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/')</span>\nlen(page_content)\n# or you can return full response\nresponse = <span class=\"pre\">downloader.get_page('https://www.google.com/',</span> full_response=True)\nresponse.status_code\n# by default it will create 3 attempts to open connection if there is a problem with a server, but you can use custom amount\nresponse = <span class=\"pre\">downloader.post_page('https://www.some-not-reliable-site.com/',</span> specific_attempts_count=5)\n`</tt>\n### Proxies usage\n<tt>`python\nfrom webdownloader import Downloader\ndownloader = <span class=\"pre\">Downloader(proxy_string_list=['104.144.176.1:3128',</span> '102.152.145.103:3128', <span class=\"pre\">'157.152.145.103:3128'],</span> change_proxies_manually=True)\n# from one random proxy (if one of proxies is not working it will take another one)\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/')</span>\n# from the same proxy\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/')</span>\n# from random proxy\ndownloader.change_proxies()\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/')</span>\n``</tt>\n### Cookies and headers\n<tt>`python\nfrom webdownloader import Downloader\ndownloader = Downloader()\n# cookies as a dict\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/',</span> <span class=\"pre\">cookies={'TOKEN':</span> <span class=\"pre\">'1234567890'})</span>\n# cookies as a string (from browser)\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/',</span> <span class=\"pre\">cookies_text='CONSENT=YES+UK.en+;</span> SID=somesid')\n# by default there is a user agent in headers but you can change all headers\npage_content = <span class=\"pre\">downloader.get_page('https://www.google.com/',</span> <span class=\"pre\">headers={'User-Agent':</span> <span class=\"pre\">'Mozilla/5.0'})</span>\n# get session sookies\nsession_cookies_dict = downloader.get_session_cookies()\n# save cookies to file\ndownloader.save_cookies_to_file(session_cookies_dict, <span class=\"pre\">name='mycookies')</span>\n# load cookies from file\ncookies_dict = <span class=\"pre\">downloader.get_cookies_from_file(name='mycookies')</span>\n``</tt>\n# License\nMIT</p>\n\n          </div>"}, "last_serial": 4555197, "releases": {"0.1": [{"comment_text": "", "digests": {"md5": "c52ff127fe1d7f83eee76ad9ad76b2f0", "sha256": "299a0531d9a2a7efd37c84476f5fc7c5c28a654905112dfe8371469b534d9bfd"}, "downloads": -1, "filename": "webdownloader-0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c52ff127fe1d7f83eee76ad9ad76b2f0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 5648, "upload_time": "2018-12-02T09:32:44", "upload_time_iso_8601": "2018-12-02T09:32:44.552943Z", "url": "https://files.pythonhosted.org/packages/5a/f0/2fbcf6bbf56a96d03e08b5d1997fca94dbb783ed4d4b58aff93dfe5cf978/webdownloader-0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7cfed5ec795a2fcecec0dcaf8e4c9523", "sha256": "19f40b029430da724c9a55006099dce2c8255962bd95eb341d9f140a8499de82"}, "downloads": -1, "filename": "webdownloader-0.1.tar.gz", "has_sig": false, "md5_digest": "7cfed5ec795a2fcecec0dcaf8e4c9523", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4405, "upload_time": "2018-12-02T09:32:46", "upload_time_iso_8601": "2018-12-02T09:32:46.523684Z", "url": "https://files.pythonhosted.org/packages/7e/6e/93c8c458c6e84aa7e7fe2f4593f9d8f36fe31500652de134fe09dd93e617/webdownloader-0.1.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "05e877d07bc95f3c3b11fab87e63fcc0", "sha256": "285c6a98379dba23c5ee05d484ea1423ac78ce0d602a7d14cebfb7de010495c9"}, "downloads": -1, "filename": "webdownloader-0.1.1.tar.gz", "has_sig": false, "md5_digest": "05e877d07bc95f3c3b11fab87e63fcc0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4409, "upload_time": "2018-12-02T09:40:17", "upload_time_iso_8601": "2018-12-02T09:40:17.733560Z", "url": "https://files.pythonhosted.org/packages/42/ec/e7e4b72ee4d32f0120e348aa43156f126d6754c888b3c14afb5f12db9220/webdownloader-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "33949150d621bc8087fe85a80d0ade84", "sha256": "f76661fbd5f4ecf2ec8bae7672a60fb991b8432905bf84fc9768ea2ee9be2862"}, "downloads": -1, "filename": "webdownloader-0.1.2.tar.gz", "has_sig": false, "md5_digest": "33949150d621bc8087fe85a80d0ade84", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4501, "upload_time": "2018-12-03T10:37:59", "upload_time_iso_8601": "2018-12-03T10:37:59.263764Z", "url": "https://files.pythonhosted.org/packages/5c/11/241c80e6ae5f8117d81c2ff1e586c205a2c907da9217503836c69e4279bf/webdownloader-0.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "33949150d621bc8087fe85a80d0ade84", "sha256": "f76661fbd5f4ecf2ec8bae7672a60fb991b8432905bf84fc9768ea2ee9be2862"}, "downloads": -1, "filename": "webdownloader-0.1.2.tar.gz", "has_sig": false, "md5_digest": "33949150d621bc8087fe85a80d0ade84", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4501, "upload_time": "2018-12-03T10:37:59", "upload_time_iso_8601": "2018-12-03T10:37:59.263764Z", "url": "https://files.pythonhosted.org/packages/5c/11/241c80e6ae5f8117d81c2ff1e586c205a2c907da9217503836c69e4279bf/webdownloader-0.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:31:15 2020"}