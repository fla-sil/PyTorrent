{"info": {"author": "long2ice", "author_email": "long2ice@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "========\nmysql2ch\n========\n\n.. image:: https://img.shields.io/pypi/v/mysql2ch.svg?style=flat\n   :target: https://pypi.python.org/pypi/mysql2ch\n.. image:: https://img.shields.io/docker/cloud/build/long2ice/mysql2ch\n   :target: https://hub.docker.com/repository/docker/long2ice/mysql2ch\n.. image:: https://img.shields.io/github/license/long2ice/mysql2ch\n   :target: https://github.com/long2ice/mysql2ch\n.. image:: https://github.com/long2ice/mysql2ch/workflows/pypi/badge.svg\n   :target: https://github.com/long2ice/mysql2ch/actions?query=workflow:pypi\n\nIntroduction\n============\n\nmysql2ch is used to sync data from MySQL to ClickHouse.\n\n.. image:: https://github.com/long2ice/mysql2ch/raw/master/images/mysql2ch.png\n\nFeatures\n========\n\n* Full data etl and continuous sync.\n* Support DDL sync,current support ``add column`` and ``drop column``.\n* Rich configurable items.\n\nRequirements\n============\n\n* `kafka <https://kafka.apache.org>`_,message queue to store mysql binlog event.\n* `redis <https://redis.io>`_,cache mysql binlog file and position.\n\nInstall\n=======\n\n.. code-block:: shell\n\n    $ pip install mysql2ch\n\n.. note::\n\n    Use pypy3 to speed up.\n\nUsage\n=====\n\nMake a ``.env`` file in execute dir or set system environment variable:\n\n.env\n~~~~\n\n.. code-block:: ini\n\n    # if True,will display sql information\n    DEBUG=True\n    # sentry need\n    ENVIRONMENT=development\n\n    MYSQL_HOST=127.0.0.1\n    MYSQL_PORT=3306\n    MYSQL_USER=root\n    MYSQL_PASSWORD=123456\n    MYSQL_SERVER_ID=101\n\n    REDIS_HOST=127.0.0.1\n    REDIS_PORT=6379\n    REDIS_DB=0\n\n    CLICKHOUSE_HOST=127.0.0.1\n    CLICKHOUSE_PORT=9002\n    CLICKHOUSE_PASSWORD=\n    CLICKHOUSE_USER=default\n\n    SENTRY_DSN=https://3450e192063d47aea7b9733d3d52585f@sentry.test.com/1\n\n    KAFKA_SERVER=127.0.0.1:9092\n    KAFKA_TOPIC=mysql2ch\n\n    # kafka partitions mapping,which means binlog of ``test`` will produce to 0 partition.\n    SCHEMA_TABLE=test.test;\n    PARTITIONS=test=0;\n\n    # init binlog file and position,should set first,after will read from redis.\n    INIT_BINLOG_FILE=binlog.000474\n    INIT_BINLOG_POS=155\n\n    # how many num to submit\n    INSERT_NUMS=20000\n    # how many seconds to submit\n    INSERT_INTERVAL=60\n\nFull data etl\n~~~~~~~~~~~~~\n\nMaybe you need make full data etl before continuous sync data from MySQL to ClickHouse or redo data etl with ``--renew``.\n\n.. code-block:: shell\n\n    $ mysql2ch etl -h\n\n    usage: mysql2ch etl [-h] --schema SCHEMA --tables TABLES [--renew]\n\n    optional arguments:\n      -h, --help       show this help message and exit\n      --schema SCHEMA  Schema to full etl.\n      --tables TABLES  Tables to full etl,multiple tables split with comma.\n      --renew          Etl after try to drop the target tables.\n\n\nProduce\n~~~~~~~\n\nListen all MySQL binlog and produce to kafka.\n\n.. code-block:: shell\n\n    $ mysql2ch produce\n\nConsume\n~~~~~~~\n\nConsume message from kafka and insert to ClickHouse,and you can skip error with ``--skip-error``.\n\n.. code-block:: shell\n\n    $ mysql2ch consume -h\n\n    usage: mysql2ch consume [-h] --schema SCHEMA --tables TABLES [--skip-error] --group-id GROUP_ID [--auto-offset-reset AUTO_OFFSET_RESET]\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      --schema SCHEMA       Schema to consume.\n      --skip-error          Skip error rows.\n      --auto-offset-reset AUTO_OFFSET_RESET\n                            Kafka auto offset reset.\n\n.. note::\n    When one service consume multiple partitions,consumer commit maybe incorrect when insert error.\n\nUse docker-compose(recommended)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: yaml\n\n    version: '3'\n    services:\n      producer:\n        env_file:\n          - .env\n        depends_on:\n          - redis\n        image: long2ice/mysql2ch:latest\n        command: mysql2ch produce\n      # add more service if you need.\n      consumer.test:\n        env_file:\n          - .env\n        depends_on:\n          - redis\n          - producer\n        image: long2ice/mysql2ch:latest\n        # consume binlog of test\n        command: mysql2ch consume --schema test\n      redis:\n        hostname: redis\n        image: redis:latest\n        volumes:\n          - redis:/data\n    volumes:\n      redis:\n\nOptional\n========\n\n`Sentry <https://github.com/getsentry/sentry>`_,error reporting,worked if set ``SENTRY_DSN`` in ``.env``.\n\nLicense\n=======\n\nThis project is licensed under the `MIT <https://github.com/long2ice/mysql2ch/blob/master/LICENSE>`_ License.", "description_content_type": "text/x-rst", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/long2ice/mysql2ch", "keywords": "MySQL ClickHouse Sync", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "mysql2ch", "package_url": "https://pypi.org/project/mysql2ch/", "platform": "any", "project_url": "https://pypi.org/project/mysql2ch/", "project_urls": {"Homepage": "https://github.com/long2ice/mysql2ch"}, "release_url": "https://pypi.org/project/mysql2ch/0.3.0/", "requires_dist": null, "requires_python": "", "summary": "mysql2ch is used to sync data from MySQL to ClickHouse.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/mysql2ch\" rel=\"nofollow\"><img alt=\"https://img.shields.io/pypi/v/mysql2ch.svg?style=flat\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b720136d8c58ab210840f205769fd49fbe0217f7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d7973716c3263682e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://hub.docker.com/repository/docker/long2ice/mysql2ch\" rel=\"nofollow\"><img alt=\"https://img.shields.io/docker/cloud/build/long2ice/mysql2ch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d30d6c56a42206f64c2b0db8f0d70ba84940b8a0/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f636c6f75642f6275696c642f6c6f6e67326963652f6d7973716c326368\"></a>\n<a href=\"https://github.com/long2ice/mysql2ch\" rel=\"nofollow\"><img alt=\"https://img.shields.io/github/license/long2ice/mysql2ch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fdfa7472e236058d5959dd669fcfc41af4d56f34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c6f6e67326963652f6d7973716c326368\"></a>\n<a href=\"https://github.com/long2ice/mysql2ch/actions?query=workflow:pypi\" rel=\"nofollow\"><img alt=\"https://github.com/long2ice/mysql2ch/workflows/pypi/badge.svg\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f5af4778365a28370f9d7f5c8ab7366eb5929b82/68747470733a2f2f6769746875622e636f6d2f6c6f6e67326963652f6d7973716c3263682f776f726b666c6f77732f707970692f62616467652e737667\"></a>\n<p><a href=\"https://blog.long2ice.cn/2020/05/mysql2ch%E4%B8%80%E4%B8%AA%E5%90%8C%E6%AD%A5mysql%E6%95%B0%E6%8D%AE%E5%88%B0clickhouse%E7%9A%84%E9%A1%B9%E7%9B%AE/\" rel=\"nofollow\">\u4e2d\u6587\u6587\u6863</a></p>\n<div id=\"introduction\">\n<h2>Introduction</h2>\n<p>Sync data from MySQL to ClickHouse, support full and increment ETL.</p>\n<img alt=\"https://github.com/long2ice/mysql2ch/raw/master/images/mysql2ch.png\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a8ee288def2910be47c83c6248864f8936852cb5/68747470733a2f2f6769746875622e636f6d2f6c6f6e67326963652f6d7973716c3263682f7261772f6d61737465722f696d616765732f6d7973716c3263682e706e67\">\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>Full data etl and continuous sync.</li>\n<li>Support DDL and DML sync,current support <tt>add column</tt> and <tt>drop column</tt> of DDL, and full support of DML also.</li>\n<li>Rich configurable items.</li>\n</ul>\n</div>\n<div id=\"requirements\">\n<h2>Requirements</h2>\n<ul>\n<li><a href=\"https://kafka.apache.org\" rel=\"nofollow\">kafka</a>,message queue to store mysql binlog event.</li>\n<li><a href=\"https://redis.io\" rel=\"nofollow\">redis</a>,cache mysql binlog file and position and store monitor data.</li>\n</ul>\n</div>\n<div id=\"install\">\n<h2>Install</h2>\n<pre>$ pip install mysql2ch\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<div id=\"config\">\n<h3>Config</h3>\n<p>Example <a href=\"https://github.com/long2ice/mysql2ch/blob/master/config.json\" rel=\"nofollow\">config.json</a>.</p>\n</div>\n<div id=\"full-data-etl\">\n<h3>Full data etl</h3>\n<p>Maybe you need make full data etl before continuous sync data from MySQL to ClickHouse or redo data etl with <tt><span class=\"pre\">--renew</span></tt>.</p>\n<pre>$ mysql2ch etl -h\n\nusage: mysql2ch etl <span class=\"o\">[</span>-h<span class=\"o\">]</span> --schema SCHEMA <span class=\"o\">[</span>--tables TABLES<span class=\"o\">]</span> <span class=\"o\">[</span>--renew<span class=\"o\">]</span>\n\noptional arguments:\n  -h, --help       show this <span class=\"nb\">help</span> message and <span class=\"nb\">exit</span>\n  --schema SCHEMA  Schema to full etl.\n  --tables TABLES  Tables to full etl,multiple tables split with comma.\n  --renew          Etl after try to drop the target tables.\n</pre>\n</div>\n<div id=\"produce\">\n<h3>Produce</h3>\n<p>Listen all MySQL binlog and produce to kafka.</p>\n<pre>$ mysql2ch -c config.json produce\n</pre>\n</div>\n<div id=\"consume\">\n<h3>Consume</h3>\n<p>Consume message from kafka and insert to ClickHouse,and you can skip error with <tt><span class=\"pre\">--skip-error</span></tt>.</p>\n<pre>$ mysql2ch consume -h\n\nusage: mysql2ch consume <span class=\"o\">[</span>-h<span class=\"o\">]</span> --schema SCHEMA <span class=\"o\">[</span>--skip-error<span class=\"o\">]</span> <span class=\"o\">[</span>--auto-offset-reset AUTO_OFFSET_RESET<span class=\"o\">]</span>\n\noptional arguments:\n  -h, --help            show this <span class=\"nb\">help</span> message and <span class=\"nb\">exit</span>\n  --schema SCHEMA       Schema to consume.\n  --skip-error          Skip error rows.\n  --auto-offset-reset AUTO_OFFSET_RESET\n                        Kafka auto offset reset,default earliest.\n</pre>\n</div>\n<div id=\"use-docker-compose-recommended\">\n<h3>Use docker-compose(recommended)</h3>\n<p>Example <a href=\"https://github.com/long2ice/mysql2ch/blob/master/docker-compose.yml\" rel=\"nofollow\">docker-compose.yml</a>.</p>\n</div>\n</div>\n<div id=\"optional\">\n<h2>Optional</h2>\n<p><a href=\"https://github.com/getsentry/sentry\" rel=\"nofollow\">Sentry</a>,error reporting,worked if set <tt>sentry_dsn</tt> in <tt>config.json</tt>.</p>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>This project is licensed under the <a href=\"https://github.com/long2ice/mysql2ch/blob/master/LICENSE\" rel=\"nofollow\">MIT</a> License.</p>\n</div>\n\n          </div>"}, "last_serial": 7155474, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "1f401e07b7efbb64568e22d853c8c83e", "sha256": "587d22badc12d52b3efc0449bdeff28a10bed11a62e959f5c6283a61e6cc192b"}, "downloads": -1, "filename": "mysql2ch-0.0.2.tar.gz", "has_sig": false, "md5_digest": "1f401e07b7efbb64568e22d853c8c83e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15019, "upload_time": "2020-02-25T06:07:23", "upload_time_iso_8601": "2020-02-25T06:07:23.421204Z", "url": "https://files.pythonhosted.org/packages/d5/39/6ee1e4074474280d82b604490d303040825420cba886672de206de08dfa8/mysql2ch-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "59dc1e8a1dceec3375665c49f5a75852", "sha256": "b7a4840e5d0122ac6279d0a06636706ca8179353d26479a06dcf235c32bcb364"}, "downloads": -1, "filename": "mysql2ch-0.0.3.tar.gz", "has_sig": false, "md5_digest": "59dc1e8a1dceec3375665c49f5a75852", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11202, "upload_time": "2020-02-29T13:28:34", "upload_time_iso_8601": "2020-02-29T13:28:34.705456Z", "url": "https://files.pythonhosted.org/packages/93/fc/033f39f3570139d3e1ddc740059c9fefb1a38f21968f3bff0aa860dc5269/mysql2ch-0.0.3.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "ddcdb71cbcb490c0f543f24cd2ff27ee", "sha256": "18a40c8226e806ce7174c2c14303c454447bfcadf4cd67d442186fe3d596ee67"}, "downloads": -1, "filename": "mysql2ch-0.2.0.tar.gz", "has_sig": false, "md5_digest": "ddcdb71cbcb490c0f543f24cd2ff27ee", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12814, "upload_time": "2020-04-17T02:59:16", "upload_time_iso_8601": "2020-04-17T02:59:16.876004Z", "url": "https://files.pythonhosted.org/packages/a5/a9/cd1026ea7d43e87f804c73b4cfa109b47a4173b86ca7aa2f842db69b9b19/mysql2ch-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "2c442beb3cac3d42e4acb290b7e61e22", "sha256": "fb244e841385ede5c1790f5419b9b66fa3f00ac6e0da615e31a57830c8e59094"}, "downloads": -1, "filename": "mysql2ch-0.2.1.tar.gz", "has_sig": false, "md5_digest": "2c442beb3cac3d42e4acb290b7e61e22", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 13400, "upload_time": "2020-04-21T08:20:59", "upload_time_iso_8601": "2020-04-21T08:20:59.237092Z", "url": "https://files.pythonhosted.org/packages/89/a2/a181c209b0ebec7bff8813501d635991c9412f4bbce7e74264fd7d47fa03/mysql2ch-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "ab6b8b2e52455efe27bb8bc29479f163", "sha256": "911eff08802fb39a1eb05af71a6e0a63e23c70ac126bd41415645e0a71ed7bbe"}, "downloads": -1, "filename": "mysql2ch-0.2.2.tar.gz", "has_sig": false, "md5_digest": "ab6b8b2e52455efe27bb8bc29479f163", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14351, "upload_time": "2020-04-24T12:52:02", "upload_time_iso_8601": "2020-04-24T12:52:02.482215Z", "url": "https://files.pythonhosted.org/packages/6d/2c/30660e1cfe67d6689e5b245a48454727f72f4ff99b6ac7b4b71998fa69cf/mysql2ch-0.2.2.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "6b353f6dda16234f7d6cfaa4283ade2a", "sha256": "44b122cedc0db185c7f3ce6272b139a32c8d75d29fcdfaa0e2dbcadcc467f89c"}, "downloads": -1, "filename": "mysql2ch-0.3.0.tar.gz", "has_sig": false, "md5_digest": "6b353f6dda16234f7d6cfaa4283ade2a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14641, "upload_time": "2020-05-03T08:19:47", "upload_time_iso_8601": "2020-05-03T08:19:47.685571Z", "url": "https://files.pythonhosted.org/packages/78/aa/4eb816d5d981034469cd5bb49b10841a6e143e07583e02318745d4fbc6af/mysql2ch-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "6b353f6dda16234f7d6cfaa4283ade2a", "sha256": "44b122cedc0db185c7f3ce6272b139a32c8d75d29fcdfaa0e2dbcadcc467f89c"}, "downloads": -1, "filename": "mysql2ch-0.3.0.tar.gz", "has_sig": false, "md5_digest": "6b353f6dda16234f7d6cfaa4283ade2a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14641, "upload_time": "2020-05-03T08:19:47", "upload_time_iso_8601": "2020-05-03T08:19:47.685571Z", "url": "https://files.pythonhosted.org/packages/78/aa/4eb816d5d981034469cd5bb49b10841a6e143e07583e02318745d4fbc6af/mysql2ch-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:48:04 2020"}