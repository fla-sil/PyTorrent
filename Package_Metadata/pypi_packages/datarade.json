{"info": {"author": "Mike Alfare", "author_email": "alfare@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: Apache Software License", "Operating System :: Microsoft :: Windows", "Programming Language :: Python :: 3.7", "Topic :: Database"], "description": "# Datarade\n\n[![Documentation Status](https://readthedocs.org/projects/datarade/badge/?version=latest)](https://datarade.readthedocs.io/en/latest/?badge=latest)\n\n**This library provides tools that allow datasets to be defined separately from a pipeline.**\n\n---\n\n# Overview\n\nThis library separates the 'how' from the 'what' when sourcing datasets and producing data pipelines. The definition of\na dataset is stored in a git repository and referenced by name in the client application. This allows the definition to\nbe source controlled independently from the client application. Also, by adding branch support, a dataset catalog can\nhold different 'environments' as branches. This allows you to promote your dataset definition and your client\napplication code using your standard CI/CD process while also giving you an area to perform UAT.\n\n# Requirements\n\n- Python 3.7+\n- marshmallow\n- pyyaml\n- requests\n- azure-devops\n- sqlalchemy\n- pyodbc\n- bcp\n\n# Installation\n\nThis package is hosted on PyPI:\n\n```shell script\npip install datarade\n```\n\n# Examples\n\nUse datarade services to obtain metadata about your datasets from your dataset catalog:\n```python\nimport datarade\n\nrepository_url = 'https://raw.githubusercontent.com/fivestack/datarade_test_catalog'\ndataset_catalog = datarade.get_dataset_catalog(\n    repository=repository_url,\n    organization='fivestack',\n    platform='github'\n)  # no username/password since only public repos are currently supported for github\ndataset = datarade.get_dataset(dataset_catalog=dataset_catalog, dataset_name='my_dataset')\nprint(dataset.name)\nprint(dataset.definition)\n```\n\nUse datarade services to write datasets to a database:\n```python\nimport datarade\n\nrepository_url = 'https://raw.githubusercontent.com/mikealfare/dataset_catalog_test/master'\ndataset_catalog = datarade.get_dataset_catalog(\n    repository=repository_url,\n    organization='fivestack',\n    platform='azure-devops',\n    username='USERNAME_TO_ACCESS_THE_GIT_REPO',\n    password='PASSWORD_TO_ACCESS_THE_GIT_REPO'\n)\ndataset_container = datarade.get_dataset_container(\n    driver='mssql',\n    database_name='datarade',\n    host=r'localhost\\DATARADE',\n    username='USERNAME_TO_WRITE_TO_THE_DATABASE',\n    password='PASSWORD_TO_WRITE_TO_THE_DATABASE'\n)\n\n# you can do one off writes like this\ndataset = datarade.get_dataset(dataset_catalog=dataset_catalog, dataset_name='my_dataset')\ndatarade.write_dataset(\n    dataset=dataset,\n    dataset_container=dataset_container,\n    username='USERNAME_TO_READ_THE_DATASET_FROM_THE_SOURCE',\n    password='PASSWORD_TO_READ_THE_DATASET_FROM_THE_SOURCE'\n)\n\n\ndef write_dataset_wrapper(dataset_name: str, username: str = None, password: str = None):\n    \"\"\"\n    But it may be useful to create a function that wraps the configuration like this if you are writing several datasets\n    and only using one DatasetCatalog and one DatasetContainer.\n    \"\"\"\n    dataset = datarade.get_dataset(dataset_catalog=dataset_catalog, dataset_name=dataset_name)\n    datarade.write_dataset(dataset=dataset, dataset_container=dataset_container, username=username, password=password)\n\n\nwrite_dataset_wrapper(\n    dataset_name='my_other_dataset',\n    username='USERNAME_FOR_THIS_SOURCE',\n    password='PASSWORD_FOR_THIS_SOURCE'\n)\n```\n\n# Full Documentation\n\nFor the full documentation, please visit: https://datarade.readthedocs.io/en/latest/\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/fivestack/datarade", "keywords": "datarade mssql database data pipeline", "license": "", "maintainer": "", "maintainer_email": "", "name": "datarade", "package_url": "https://pypi.org/project/datarade/", "platform": "", "project_url": "https://pypi.org/project/datarade/", "project_urls": {"Homepage": "https://github.com/fivestack/datarade"}, "release_url": "https://pypi.org/project/datarade/0.3.0/", "requires_dist": ["marshmallow>=3.4,<4.0", "pyyaml>=5.1,<6.0", "requests>=2.22,<3.0", "azure-devops==6.0.0b2", "sqlalchemy>=1.3,<2.0", "pyodbc>=4.0,<5.0", "bcp>=0.3.0", "sphinx>=2.4,<3.0 ; extra == \"doc\"", "sphinx-autodoc-typehints>=1.10,<2.0 ; extra == \"doc\"", "sphinx_rtd_theme>=0.4,<0.5 ; extra == \"doc\"", "pytest>=5.1,<6.0 ; extra == \"test\"", "pytest-cov>=2.7,<3.0 ; extra == \"test\""], "requires_python": ">=3.7,<4.0", "summary": "This library provides tools that allow datasets to be defined separately from a pipeline.", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Datarade</h1>\n<p><a href=\"https://datarade.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f848d5ee898cab40102c8f05ee5a08bf9e92b198/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f64617461726164652f62616467652f3f76657273696f6e3d6c6174657374\"></a></p>\n<p><strong>This library provides tools that allow datasets to be defined separately from a pipeline.</strong></p>\n<hr>\n<h1>Overview</h1>\n<p>This library separates the 'how' from the 'what' when sourcing datasets and producing data pipelines. The definition of\na dataset is stored in a git repository and referenced by name in the client application. This allows the definition to\nbe source controlled independently from the client application. Also, by adding branch support, a dataset catalog can\nhold different 'environments' as branches. This allows you to promote your dataset definition and your client\napplication code using your standard CI/CD process while also giving you an area to perform UAT.</p>\n<h1>Requirements</h1>\n<ul>\n<li>Python 3.7+</li>\n<li>marshmallow</li>\n<li>pyyaml</li>\n<li>requests</li>\n<li>azure-devops</li>\n<li>sqlalchemy</li>\n<li>pyodbc</li>\n<li>bcp</li>\n</ul>\n<h1>Installation</h1>\n<p>This package is hosted on PyPI:</p>\n<pre>pip install datarade\n</pre>\n<h1>Examples</h1>\n<p>Use datarade services to obtain metadata about your datasets from your dataset catalog:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">datarade</span>\n\n<span class=\"n\">repository_url</span> <span class=\"o\">=</span> <span class=\"s1\">'https://raw.githubusercontent.com/fivestack/datarade_test_catalog'</span>\n<span class=\"n\">dataset_catalog</span> <span class=\"o\">=</span> <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">get_dataset_catalog</span><span class=\"p\">(</span>\n    <span class=\"n\">repository</span><span class=\"o\">=</span><span class=\"n\">repository_url</span><span class=\"p\">,</span>\n    <span class=\"n\">organization</span><span class=\"o\">=</span><span class=\"s1\">'fivestack'</span><span class=\"p\">,</span>\n    <span class=\"n\">platform</span><span class=\"o\">=</span><span class=\"s1\">'github'</span>\n<span class=\"p\">)</span>  <span class=\"c1\"># no username/password since only public repos are currently supported for github</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">get_dataset</span><span class=\"p\">(</span><span class=\"n\">dataset_catalog</span><span class=\"o\">=</span><span class=\"n\">dataset_catalog</span><span class=\"p\">,</span> <span class=\"n\">dataset_name</span><span class=\"o\">=</span><span class=\"s1\">'my_dataset'</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">.</span><span class=\"n\">definition</span><span class=\"p\">)</span>\n</pre>\n<p>Use datarade services to write datasets to a database:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">datarade</span>\n\n<span class=\"n\">repository_url</span> <span class=\"o\">=</span> <span class=\"s1\">'https://raw.githubusercontent.com/mikealfare/dataset_catalog_test/master'</span>\n<span class=\"n\">dataset_catalog</span> <span class=\"o\">=</span> <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">get_dataset_catalog</span><span class=\"p\">(</span>\n    <span class=\"n\">repository</span><span class=\"o\">=</span><span class=\"n\">repository_url</span><span class=\"p\">,</span>\n    <span class=\"n\">organization</span><span class=\"o\">=</span><span class=\"s1\">'fivestack'</span><span class=\"p\">,</span>\n    <span class=\"n\">platform</span><span class=\"o\">=</span><span class=\"s1\">'azure-devops'</span><span class=\"p\">,</span>\n    <span class=\"n\">username</span><span class=\"o\">=</span><span class=\"s1\">'USERNAME_TO_ACCESS_THE_GIT_REPO'</span><span class=\"p\">,</span>\n    <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"s1\">'PASSWORD_TO_ACCESS_THE_GIT_REPO'</span>\n<span class=\"p\">)</span>\n<span class=\"n\">dataset_container</span> <span class=\"o\">=</span> <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">get_dataset_container</span><span class=\"p\">(</span>\n    <span class=\"n\">driver</span><span class=\"o\">=</span><span class=\"s1\">'mssql'</span><span class=\"p\">,</span>\n    <span class=\"n\">database_name</span><span class=\"o\">=</span><span class=\"s1\">'datarade'</span><span class=\"p\">,</span>\n    <span class=\"n\">host</span><span class=\"o\">=</span><span class=\"sa\">r</span><span class=\"s1\">'localhost\\DATARADE'</span><span class=\"p\">,</span>\n    <span class=\"n\">username</span><span class=\"o\">=</span><span class=\"s1\">'USERNAME_TO_WRITE_TO_THE_DATABASE'</span><span class=\"p\">,</span>\n    <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"s1\">'PASSWORD_TO_WRITE_TO_THE_DATABASE'</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># you can do one off writes like this</span>\n<span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">get_dataset</span><span class=\"p\">(</span><span class=\"n\">dataset_catalog</span><span class=\"o\">=</span><span class=\"n\">dataset_catalog</span><span class=\"p\">,</span> <span class=\"n\">dataset_name</span><span class=\"o\">=</span><span class=\"s1\">'my_dataset'</span><span class=\"p\">)</span>\n<span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">write_dataset</span><span class=\"p\">(</span>\n    <span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"n\">dataset</span><span class=\"p\">,</span>\n    <span class=\"n\">dataset_container</span><span class=\"o\">=</span><span class=\"n\">dataset_container</span><span class=\"p\">,</span>\n    <span class=\"n\">username</span><span class=\"o\">=</span><span class=\"s1\">'USERNAME_TO_READ_THE_DATASET_FROM_THE_SOURCE'</span><span class=\"p\">,</span>\n    <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"s1\">'PASSWORD_TO_READ_THE_DATASET_FROM_THE_SOURCE'</span>\n<span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">write_dataset_wrapper</span><span class=\"p\">(</span><span class=\"n\">dataset_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">username</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">password</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">    But it may be useful to create a function that wraps the configuration like this if you are writing several datasets</span>\n<span class=\"sd\">    and only using one DatasetCatalog and one DatasetContainer.</span>\n<span class=\"sd\">    \"\"\"</span>\n    <span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">get_dataset</span><span class=\"p\">(</span><span class=\"n\">dataset_catalog</span><span class=\"o\">=</span><span class=\"n\">dataset_catalog</span><span class=\"p\">,</span> <span class=\"n\">dataset_name</span><span class=\"o\">=</span><span class=\"n\">dataset_name</span><span class=\"p\">)</span>\n    <span class=\"n\">datarade</span><span class=\"o\">.</span><span class=\"n\">write_dataset</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"n\">dataset</span><span class=\"p\">,</span> <span class=\"n\">dataset_container</span><span class=\"o\">=</span><span class=\"n\">dataset_container</span><span class=\"p\">,</span> <span class=\"n\">username</span><span class=\"o\">=</span><span class=\"n\">username</span><span class=\"p\">,</span> <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"n\">password</span><span class=\"p\">)</span>\n\n\n<span class=\"n\">write_dataset_wrapper</span><span class=\"p\">(</span>\n    <span class=\"n\">dataset_name</span><span class=\"o\">=</span><span class=\"s1\">'my_other_dataset'</span><span class=\"p\">,</span>\n    <span class=\"n\">username</span><span class=\"o\">=</span><span class=\"s1\">'USERNAME_FOR_THIS_SOURCE'</span><span class=\"p\">,</span>\n    <span class=\"n\">password</span><span class=\"o\">=</span><span class=\"s1\">'PASSWORD_FOR_THIS_SOURCE'</span>\n<span class=\"p\">)</span>\n</pre>\n<h1>Full Documentation</h1>\n<p>For the full documentation, please visit: <a href=\"https://datarade.readthedocs.io/en/latest/\" rel=\"nofollow\">https://datarade.readthedocs.io/en/latest/</a></p>\n\n          </div>"}, "last_serial": 7070789, "releases": {"0.1.2": [{"comment_text": "", "digests": {"md5": "410e36c7a6fa5473e2c263488bb20493", "sha256": "2fa74c93666a7f17183fe210d56c6d0cf3b56293748f728cd4db51f3539bf422"}, "downloads": -1, "filename": "datarade-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "410e36c7a6fa5473e2c263488bb20493", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 64902, "upload_time": "2019-10-17T22:20:08", "upload_time_iso_8601": "2019-10-17T22:20:08.961443Z", "url": "https://files.pythonhosted.org/packages/2c/bf/5b9bc61f04c1e9c1779d060fce679c805f7e24e2730dfc1bcaf932d0ed5c/datarade-0.1.2-py3-none-any.whl", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "f50d8fd098ddc301d399089191a6cd92", "sha256": "8fb3e14664c6ac0f330c34a1608961a3a2961d25917eca02f74acd4c203943fe"}, "downloads": -1, "filename": "datarade-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "f50d8fd098ddc301d399089191a6cd92", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 14466, "upload_time": "2020-03-19T23:49:43", "upload_time_iso_8601": "2020-03-19T23:49:43.352940Z", "url": "https://files.pythonhosted.org/packages/bb/9f/029312aeae1b7e9553987d70f2b09995985a08f4eb306724160628addd79/datarade-0.2.0-py3-none-any.whl", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "6978d3e889179969e074587c53e50a16", "sha256": "485de924e992a1d05f952efae80cb58a04315a9286f23572ec971348fe0b941d"}, "downloads": -1, "filename": "datarade-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "6978d3e889179969e074587c53e50a16", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 14468, "upload_time": "2020-03-20T19:28:15", "upload_time_iso_8601": "2020-03-20T19:28:15.520762Z", "url": "https://files.pythonhosted.org/packages/04/75/838175e62cc09cd45d773a4fbd726e8481d577e1cf8e92b708a8849deae6/datarade-0.2.1-py3-none-any.whl", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "057cddf3a661f9a2b67864cd9a97d978", "sha256": "62a17242299abafcbac03ba7d67b4447e2c8816be6add0513d42b74779c2bcf4"}, "downloads": -1, "filename": "datarade-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "057cddf3a661f9a2b67864cd9a97d978", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 14468, "upload_time": "2020-03-27T14:51:04", "upload_time_iso_8601": "2020-03-27T14:51:04.272148Z", "url": "https://files.pythonhosted.org/packages/44/e4/9ce7d93264753ad10630f3f5090906e10c641e8cccda7cff304b24b3f557/datarade-0.2.2-py3-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "0deb0f790e33be0bd830a3b88352c6ba", "sha256": "63f3c4271f6bba16d2bca7d4bee5b7bdc5609f5b474546ff7095d1839f15eddc"}, "downloads": -1, "filename": "datarade-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0deb0f790e33be0bd830a3b88352c6ba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 14919, "upload_time": "2020-04-21T19:49:36", "upload_time_iso_8601": "2020-04-21T19:49:36.644917Z", "url": "https://files.pythonhosted.org/packages/33/4c/70e4fed82480a3f4f25bdebad201d31dae2bcace04e6588762c397d1cdb1/datarade-0.3.0-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0deb0f790e33be0bd830a3b88352c6ba", "sha256": "63f3c4271f6bba16d2bca7d4bee5b7bdc5609f5b474546ff7095d1839f15eddc"}, "downloads": -1, "filename": "datarade-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0deb0f790e33be0bd830a3b88352c6ba", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7,<4.0", "size": 14919, "upload_time": "2020-04-21T19:49:36", "upload_time_iso_8601": "2020-04-21T19:49:36.644917Z", "url": "https://files.pythonhosted.org/packages/33/4c/70e4fed82480a3f4f25bdebad201d31dae2bcace04e6588762c397d1cdb1/datarade-0.3.0-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 00:40:14 2020"}