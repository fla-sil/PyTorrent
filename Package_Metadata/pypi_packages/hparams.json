{"info": {"author": "Michael Petrochuk", "author_email": "petrochukm@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "Intended Audience :: Developers", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Scientific/Engineering :: Mathematics", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "<p align=\"center\"><img width=\"544px\" src=\"logo.svg\" /></p>\n\n<h3 align=\"center\">Extensible and Fault-Tolerant Hyperparameter Management</h3>\n\nHParams is a thoughtful approach to configuration management for machine learning projects. It\nenables you to externalize your hyperparameters into a configuration file. In doing so, you can\nreproduce experiments, iterate quickly, and reduce errors.\n\n**Features:**\n\n- Approachable and easy-to-use API\n- Battle-tested over three years\n- Fast with little to no runtime overhead (< 3e-05 seconds) per configured function\n- Robust to most use cases with 100% test coverage and 75 tests\n- Lightweight with only one dependency\n\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/hparams.svg?style=flat-square)\n[![Codecov](https://img.shields.io/codecov/c/github/PetrochukM/HParams/master.svg?style=flat-square)](https://codecov.io/gh/PetrochukM/HParams)\n[![Downloads](http://pepy.tech/badge/hparams)](http://pepy.tech/project/hparams)\n[![Build Status](https://img.shields.io/travis/PetrochukM/HParams/master.svg?style=flat-square)](https://travis-ci.org/PetrochukM/HParams)\n[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg?style=flat-square)](https://opensource.org/licenses/MIT)\n[![Twitter: PetrochukM](https://img.shields.io/twitter/follow/MPetrochuk.svg?style=social)](https://twitter.com/MPetrochuk)\n\n_Logo by [Chloe Yeo](http://www.yeochloe.com/), Corporate Sponsorship by [WellSaid Labs](https://wellsaidlabs.com/)_\n\n## Installation\n\nMake sure you have Python 3. You can then install `hparams` using `pip`:\n\n```bash\npip install hparams\n```\n\nInstall the latest code via:\n\n```bash\npip install git+https://github.com/PetrochukM/HParams.git\n```\n\n## Oops \ud83d\udc1b\n\nWith HParams, you will avoid common but needless hyperparameter mistakes. It will throw a warning\nor error if:\n\n- A hyperparameter is overwritten.\n- A hyperparameter is declared but not set.\n- A hyperparameter is set but not declared.\n- A hyperparameter type is incorrect.\n\nFinally, HParams is built with developer experience in mind. HParams includes 13 errors and 6 warnings\nto help catch and resolve issues quickly.\n\n## Examples\n\nAdd HParams to your project by following one of these common use cases:\n\n### Configure Training \ud83e\udd17\n\nConfigure your training run, like so:\n\n```python\n# main.py\nfrom hparams import configurable, add_config, HParams, HParam\nfrom typing import Union\n\n@configurable\ndef train(batch_size: Union[int, HParam]=HParam(int)):\n    pass\n\nclass Model():\n\n    @configurable\n    def __init__(self, hidden_size=HParam(int), dropout=HParam(float)):\n        pass\n\nadd_config({ 'main': {\n    'train': HParams(batch_size=32),\n    'Model.__init__': HParams(hidden_size=1024, dropout=0.25),\n}})\n```\n\nHParams supports optional configuration typechecking to help you find bugs! \ud83d\udc1b\n\n### Set Defaults\n\nConfigure PyTorch and Tensorflow defaults to match via:\n\n```python\nfrom torch.nn import BatchNorm1d\nfrom hparams import configurable, add_config, HParams\n\n# NOTE: `momentum=0.01` to match Tensorflow defaults\nBatchNorm1d.__init__ = configurable(BatchNorm1d.__init__)\nadd_config({ 'torch.nn.BatchNorm1d.__init__': HParams(momentum=0.01) })\n```\n\nConfigure your random seed globally, like so:\n\n```python\n# config.py\nimport random\nfrom hparams import configurable, add_config, HParams\n\nrandom.seed = configurable(random.seed)\nadd_config({'random.seed': HParams(a=123)})\n```\n\n```python\n# main.py\nimport config\nimport random\n\nrandom.seed()\n```\n\n### CLI\n\nExperiment with hyperparameters through your command line, for example:\n\n```console\nfoo@bar:~$ file.py --torch.optim.adam.Adam.__init__ 'HParams(lr=0.1,betas=(0.999,0.99))'\n```\n\n```python\nimport sys\nfrom torch.optim import Adam\nfrom hparams import configurable, add_config, parse_hparam_args\n\nAdam.__init__ = configurable(Adam.__init__)\nparsed = parse_hparam_args(sys.argv[1:])  # Parse command line arguments\nadd_config(parsed)\n```\n\n### Hyperparameter optimization\n\nHyperparameter optimization is easy to-do, check this out:\n\n```python\nimport itertools\nfrom torch.optim import Adam\nfrom hparams import configurable, add_config, HParams\n\nAdam.__init__ = configurable(Adam.__init__)\n\ndef train():  # Train the model and return the loss.\n    pass\n\nfor betas in itertools.product([0.999, 0.99, 0.9], [0.999, 0.99, 0.9]):\n    add_config({Adam.__init__: HParams(betas=betas)})  # Grid search over the `betas`\n    train()\n```\n\n### Track Hyperparameters\n\nEasily track your hyperparameters using tools like [Comet](comet.ml).\n\n```python\nfrom comet_ml import Experiment\nfrom hparams import get_config\n\nexperiment = Experiment()\nexperiment.log_parameters(get_config())\n```\n\n### Multiprocessing: Partial Support\n\nExport a Python `functools.partial` to use in another process, like so:\n\n```python\nfrom hparams import configurable, HParam\n\n@configurable\ndef func(hparam=HParam()):\n    pass\n\npartial = func.get_configured_partial()\n```\n\nWith this approach, you don't have to transfer the global state to the new process. To transfer the\nglobal state, you'll want to use `get_config` and `add_config`.\n\n## Docs \ud83d\udcd6\n\nThe complete documentation for HParams is available [here](./DOCS.md).\n\n## Contributing\n\nWe've released HParams because a lack of hyperparameter management solutions. We hope that\nother people can benefit from the project. We are thankful for any contributions from the\ncommunity.\n\n### Contributing Guide\n\nRead our [contributing guide](https://github.com/PetrochukM/HParams/blob/master/CONTRIBUTING.md) to\nlearn about our development process, how to propose bugfixes and improvements, and how to build and\ntest your changes to HParams.\n\n## Authors\n\n- [Michael Petrochuk](https://github.com/PetrochukM/) \u2014 Developer\n- [Chloe Yeo](http://www.yeochloe.com/) \u2014 Logo Design\n\n## Citing\n\nIf you find HParams useful for an academic publication, then please use the following BibTeX to\ncite it:\n\n```latex\n@misc{hparams,\nauthor = {Petrochuk, Michael},\ntitle = {HParams: Hyperparameter management solution},\nyear = {2019},\npublisher = {GitHub},\njournal = {GitHub repository},\nhowpublished = {\\url{https://github.com/PetrochukM/HParams}},\n}\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "hyperparameters hparams configurable", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "hparams", "package_url": "https://pypi.org/project/hparams/", "platform": "", "project_url": "https://pypi.org/project/hparams/", "project_urls": null, "release_url": "https://pypi.org/project/hparams/0.3.0/", "requires_dist": ["typeguard"], "requires_python": ">=3.5", "summary": "", "version": "0.3.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/502f5c3251aab28dd9eb09f77ba6fe6d8292e7ff/6c6f676f2e737667\" width=\"544px\"></p>\n<h3>Extensible and Fault-Tolerant Hyperparameter Management</h3>\n<p>HParams is a thoughtful approach to configuration management for machine learning projects. It\nenables you to externalize your hyperparameters into a configuration file. In doing so, you can\nreproduce experiments, iterate quickly, and reduce errors.</p>\n<p><strong>Features:</strong></p>\n<ul>\n<li>Approachable and easy-to-use API</li>\n<li>Battle-tested over three years</li>\n<li>Fast with little to no runtime overhead (&lt; 3e-05 seconds) per configured function</li>\n<li>Robust to most use cases with 100% test coverage and 75 tests</li>\n<li>Lightweight with only one dependency</li>\n</ul>\n<p><img alt=\"PyPI - Python Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f44b6cbe8e84d268b5cd041184dd81ab277e9bb6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f68706172616d732e7376673f7374796c653d666c61742d737175617265\">\n<a href=\"https://codecov.io/gh/PetrochukM/HParams\" rel=\"nofollow\"><img alt=\"Codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ef8b7476b0ecc291ded9f0c6da2c4a022cba2574/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f506574726f6368756b4d2f48506172616d732f6d61737465722e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"http://pepy.tech/project/hparams\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/10f0d4365cd8621b3092d057a17bcd4f4f89d572/687474703a2f2f706570792e746563682f62616467652f68706172616d73\"></a>\n<a href=\"https://travis-ci.org/PetrochukM/HParams\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9ed3cbde78a4d84a7f4645c4b65b9f9feee4f318/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f506574726f6368756b4d2f48506172616d732f6d61737465722e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1ce67aaa3b9058525966a038029d61c2b83ce873/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265\"></a>\n<a href=\"https://twitter.com/MPetrochuk\" rel=\"nofollow\"><img alt=\"Twitter: PetrochukM\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/329c0f4ba2d063a873d98b7e152b3fa00621c89a/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f4d506574726f6368756b2e7376673f7374796c653d736f6369616c\"></a></p>\n<p><em>Logo by <a href=\"http://www.yeochloe.com/\" rel=\"nofollow\">Chloe Yeo</a>, Corporate Sponsorship by <a href=\"https://wellsaidlabs.com/\" rel=\"nofollow\">WellSaid Labs</a></em></p>\n<h2>Installation</h2>\n<p>Make sure you have Python 3. You can then install <code>hparams</code> using <code>pip</code>:</p>\n<pre>pip install hparams\n</pre>\n<p>Install the latest code via:</p>\n<pre>pip install git+https://github.com/PetrochukM/HParams.git\n</pre>\n<h2>Oops \ud83d\udc1b</h2>\n<p>With HParams, you will avoid common but needless hyperparameter mistakes. It will throw a warning\nor error if:</p>\n<ul>\n<li>A hyperparameter is overwritten.</li>\n<li>A hyperparameter is declared but not set.</li>\n<li>A hyperparameter is set but not declared.</li>\n<li>A hyperparameter type is incorrect.</li>\n</ul>\n<p>Finally, HParams is built with developer experience in mind. HParams includes 13 errors and 6 warnings\nto help catch and resolve issues quickly.</p>\n<h2>Examples</h2>\n<p>Add HParams to your project by following one of these common use cases:</p>\n<h3>Configure Training \ud83e\udd17</h3>\n<p>Configure your training run, like so:</p>\n<pre><span class=\"c1\"># main.py</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">configurable</span><span class=\"p\">,</span> <span class=\"n\">add_config</span><span class=\"p\">,</span> <span class=\"n\">HParams</span><span class=\"p\">,</span> <span class=\"n\">HParam</span>\n<span class=\"kn\">from</span> <span class=\"nn\">typing</span> <span class=\"kn\">import</span> <span class=\"n\">Union</span>\n\n<span class=\"nd\">@configurable</span>\n<span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">HParam</span><span class=\"p\">]</span><span class=\"o\">=</span><span class=\"n\">HParam</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">)):</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">class</span> <span class=\"nc\">Model</span><span class=\"p\">():</span>\n\n    <span class=\"nd\">@configurable</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"n\">HParam</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">),</span> <span class=\"n\">dropout</span><span class=\"o\">=</span><span class=\"n\">HParam</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">)):</span>\n        <span class=\"k\">pass</span>\n\n<span class=\"n\">add_config</span><span class=\"p\">({</span> <span class=\"s1\">'main'</span><span class=\"p\">:</span> <span class=\"p\">{</span>\n    <span class=\"s1\">'train'</span><span class=\"p\">:</span> <span class=\"n\">HParams</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">),</span>\n    <span class=\"s1\">'Model.__init__'</span><span class=\"p\">:</span> <span class=\"n\">HParams</span><span class=\"p\">(</span><span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"n\">dropout</span><span class=\"o\">=</span><span class=\"mf\">0.25</span><span class=\"p\">),</span>\n<span class=\"p\">}})</span>\n</pre>\n<p>HParams supports optional configuration typechecking to help you find bugs! \ud83d\udc1b</p>\n<h3>Set Defaults</h3>\n<p>Configure PyTorch and Tensorflow defaults to match via:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torch.nn</span> <span class=\"kn\">import</span> <span class=\"n\">BatchNorm1d</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">configurable</span><span class=\"p\">,</span> <span class=\"n\">add_config</span><span class=\"p\">,</span> <span class=\"n\">HParams</span>\n\n<span class=\"c1\"># NOTE: `momentum=0.01` to match Tensorflow defaults</span>\n<span class=\"n\">BatchNorm1d</span><span class=\"o\">.</span><span class=\"fm\">__init__</span> <span class=\"o\">=</span> <span class=\"n\">configurable</span><span class=\"p\">(</span><span class=\"n\">BatchNorm1d</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">)</span>\n<span class=\"n\">add_config</span><span class=\"p\">({</span> <span class=\"s1\">'torch.nn.BatchNorm1d.__init__'</span><span class=\"p\">:</span> <span class=\"n\">HParams</span><span class=\"p\">(</span><span class=\"n\">momentum</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">)</span> <span class=\"p\">})</span>\n</pre>\n<p>Configure your random seed globally, like so:</p>\n<pre><span class=\"c1\"># config.py</span>\n<span class=\"kn\">import</span> <span class=\"nn\">random</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">configurable</span><span class=\"p\">,</span> <span class=\"n\">add_config</span><span class=\"p\">,</span> <span class=\"n\">HParams</span>\n\n<span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span> <span class=\"o\">=</span> <span class=\"n\">configurable</span><span class=\"p\">(</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">)</span>\n<span class=\"n\">add_config</span><span class=\"p\">({</span><span class=\"s1\">'random.seed'</span><span class=\"p\">:</span> <span class=\"n\">HParams</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"o\">=</span><span class=\"mi\">123</span><span class=\"p\">)})</span>\n</pre>\n<pre><span class=\"c1\"># main.py</span>\n<span class=\"kn\">import</span> <span class=\"nn\">config</span>\n<span class=\"kn\">import</span> <span class=\"nn\">random</span>\n\n<span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">()</span>\n</pre>\n<h3>CLI</h3>\n<p>Experiment with hyperparameters through your command line, for example:</p>\n<pre><span class=\"gp\">foo@bar:~$</span> file.py --torch.optim.adam.Adam.__init__ <span class=\"s1\">'HParams(lr=0.1,betas=(0.999,0.99))'</span>\n</pre>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">sys</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.optim</span> <span class=\"kn\">import</span> <span class=\"n\">Adam</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">configurable</span><span class=\"p\">,</span> <span class=\"n\">add_config</span><span class=\"p\">,</span> <span class=\"n\">parse_hparam_args</span>\n\n<span class=\"n\">Adam</span><span class=\"o\">.</span><span class=\"fm\">__init__</span> <span class=\"o\">=</span> <span class=\"n\">configurable</span><span class=\"p\">(</span><span class=\"n\">Adam</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">)</span>\n<span class=\"n\">parsed</span> <span class=\"o\">=</span> <span class=\"n\">parse_hparam_args</span><span class=\"p\">(</span><span class=\"n\">sys</span><span class=\"o\">.</span><span class=\"n\">argv</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">:])</span>  <span class=\"c1\"># Parse command line arguments</span>\n<span class=\"n\">add_config</span><span class=\"p\">(</span><span class=\"n\">parsed</span><span class=\"p\">)</span>\n</pre>\n<h3>Hyperparameter optimization</h3>\n<p>Hyperparameter optimization is easy to-do, check this out:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">itertools</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch.optim</span> <span class=\"kn\">import</span> <span class=\"n\">Adam</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">configurable</span><span class=\"p\">,</span> <span class=\"n\">add_config</span><span class=\"p\">,</span> <span class=\"n\">HParams</span>\n\n<span class=\"n\">Adam</span><span class=\"o\">.</span><span class=\"fm\">__init__</span> <span class=\"o\">=</span> <span class=\"n\">configurable</span><span class=\"p\">(</span><span class=\"n\">Adam</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">train</span><span class=\"p\">():</span>  <span class=\"c1\"># Train the model and return the loss.</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"k\">for</span> <span class=\"n\">betas</span> <span class=\"ow\">in</span> <span class=\"n\">itertools</span><span class=\"o\">.</span><span class=\"n\">product</span><span class=\"p\">([</span><span class=\"mf\">0.999</span><span class=\"p\">,</span> <span class=\"mf\">0.99</span><span class=\"p\">,</span> <span class=\"mf\">0.9</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mf\">0.999</span><span class=\"p\">,</span> <span class=\"mf\">0.99</span><span class=\"p\">,</span> <span class=\"mf\">0.9</span><span class=\"p\">]):</span>\n    <span class=\"n\">add_config</span><span class=\"p\">({</span><span class=\"n\">Adam</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">:</span> <span class=\"n\">HParams</span><span class=\"p\">(</span><span class=\"n\">betas</span><span class=\"o\">=</span><span class=\"n\">betas</span><span class=\"p\">)})</span>  <span class=\"c1\"># Grid search over the `betas`</span>\n    <span class=\"n\">train</span><span class=\"p\">()</span>\n</pre>\n<h3>Track Hyperparameters</h3>\n<p>Easily track your hyperparameters using tools like <a href=\"comet.ml\" rel=\"nofollow\">Comet</a>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">comet_ml</span> <span class=\"kn\">import</span> <span class=\"n\">Experiment</span>\n<span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">get_config</span>\n\n<span class=\"n\">experiment</span> <span class=\"o\">=</span> <span class=\"n\">Experiment</span><span class=\"p\">()</span>\n<span class=\"n\">experiment</span><span class=\"o\">.</span><span class=\"n\">log_parameters</span><span class=\"p\">(</span><span class=\"n\">get_config</span><span class=\"p\">())</span>\n</pre>\n<h3>Multiprocessing: Partial Support</h3>\n<p>Export a Python <code>functools.partial</code> to use in another process, like so:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">hparams</span> <span class=\"kn\">import</span> <span class=\"n\">configurable</span><span class=\"p\">,</span> <span class=\"n\">HParam</span>\n\n<span class=\"nd\">@configurable</span>\n<span class=\"k\">def</span> <span class=\"nf\">func</span><span class=\"p\">(</span><span class=\"n\">hparam</span><span class=\"o\">=</span><span class=\"n\">HParam</span><span class=\"p\">()):</span>\n    <span class=\"k\">pass</span>\n\n<span class=\"n\">partial</span> <span class=\"o\">=</span> <span class=\"n\">func</span><span class=\"o\">.</span><span class=\"n\">get_configured_partial</span><span class=\"p\">()</span>\n</pre>\n<p>With this approach, you don't have to transfer the global state to the new process. To transfer the\nglobal state, you'll want to use <code>get_config</code> and <code>add_config</code>.</p>\n<h2>Docs \ud83d\udcd6</h2>\n<p>The complete documentation for HParams is available <a href=\"./DOCS.md\" rel=\"nofollow\">here</a>.</p>\n<h2>Contributing</h2>\n<p>We've released HParams because a lack of hyperparameter management solutions. We hope that\nother people can benefit from the project. We are thankful for any contributions from the\ncommunity.</p>\n<h3>Contributing Guide</h3>\n<p>Read our <a href=\"https://github.com/PetrochukM/HParams/blob/master/CONTRIBUTING.md\" rel=\"nofollow\">contributing guide</a> to\nlearn about our development process, how to propose bugfixes and improvements, and how to build and\ntest your changes to HParams.</p>\n<h2>Authors</h2>\n<ul>\n<li><a href=\"https://github.com/PetrochukM/\" rel=\"nofollow\">Michael Petrochuk</a> \u2014 Developer</li>\n<li><a href=\"http://www.yeochloe.com/\" rel=\"nofollow\">Chloe Yeo</a> \u2014 Logo Design</li>\n</ul>\n<h2>Citing</h2>\n<p>If you find HParams useful for an academic publication, then please use the following BibTeX to\ncite it:</p>\n<pre>@misc<span class=\"nb\">{</span>hparams,\nauthor = <span class=\"nb\">{</span>Petrochuk, Michael<span class=\"nb\">}</span>,\ntitle = <span class=\"nb\">{</span>HParams: Hyperparameter management solution<span class=\"nb\">}</span>,\nyear = <span class=\"nb\">{</span>2019<span class=\"nb\">}</span>,\npublisher = <span class=\"nb\">{</span>GitHub<span class=\"nb\">}</span>,\njournal = <span class=\"nb\">{</span>GitHub repository<span class=\"nb\">}</span>,\nhowpublished = <span class=\"nb\">{</span><span class=\"k\">\\url</span><span class=\"nb\">{</span>https://github.com/PetrochukM/HParams<span class=\"nb\">}}</span>,\n<span class=\"nb\">}</span>\n</pre>\n\n          </div>"}, "last_serial": 6072991, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "3d416ac9d61e4e9983b2fab97fccbe81", "sha256": "e69600ee6441c610bb41c6d750bf913f80796d1f155393441d71b9aa4d2cf149"}, "downloads": -1, "filename": "hparams-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "3d416ac9d61e4e9983b2fab97fccbe81", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 10908, "upload_time": "2019-09-25T04:37:33", "upload_time_iso_8601": "2019-09-25T04:37:33.222784Z", "url": "https://files.pythonhosted.org/packages/08/8a/86217bd6df98009ba8ad9fd3c2f932aa755eac526112513ca104dd30ac8c/hparams-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c768cf28bdd64392f61a7df70fc92404", "sha256": "dc2da186fb41c6e54e064b815c31ab52b0abb982a6e2edb8677d1c597ea049a5"}, "downloads": -1, "filename": "hparams-0.1.0.tar.gz", "has_sig": false, "md5_digest": "c768cf28bdd64392f61a7df70fc92404", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 11229, "upload_time": "2019-09-25T04:37:36", "upload_time_iso_8601": "2019-09-25T04:37:36.129091Z", "url": "https://files.pythonhosted.org/packages/28/cb/b313b5cfce656e86bcbea03f50870b743b9bcf51ed318bbb16a242a7afa1/hparams-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "e6c5e04f0ab9f731946281154360a798", "sha256": "846efc02520ed204a094572471b5feff09379b1064bb68389f530268d7ab3835"}, "downloads": -1, "filename": "hparams-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e6c5e04f0ab9f731946281154360a798", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10617, "upload_time": "2019-09-26T05:27:23", "upload_time_iso_8601": "2019-09-26T05:27:23.302961Z", "url": "https://files.pythonhosted.org/packages/ba/95/be8e7819bdaba289c298cbd251e3edfcbb53248ad55cc1235b494bbe5862/hparams-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a5b9dfbe642ff2a96f41a6d549137a31", "sha256": "5d746f95359d6f78ce2e9c451ac854458acc0f77bc018358028508d9ce587d88"}, "downloads": -1, "filename": "hparams-0.1.1.tar.gz", "has_sig": false, "md5_digest": "a5b9dfbe642ff2a96f41a6d549137a31", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 10855, "upload_time": "2019-09-26T05:27:24", "upload_time_iso_8601": "2019-09-26T05:27:24.810886Z", "url": "https://files.pythonhosted.org/packages/bd/7f/d23431211aa386c77270a1257749c78c871140ad218bee205f741714564b/hparams-0.1.1.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "17d9e38d7b07a2114dde770fa2c3a377", "sha256": "44b0227efb3106e1a8a5e6e6ecccaf942c9416d44847e59803f32e3929fa8ca4"}, "downloads": -1, "filename": "hparams-0.2.0-py3-none-any.whl", "has_sig": false, "md5_digest": "17d9e38d7b07a2114dde770fa2c3a377", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10389, "upload_time": "2019-09-29T18:25:58", "upload_time_iso_8601": "2019-09-29T18:25:58.374784Z", "url": "https://files.pythonhosted.org/packages/94/f0/81c69557ebea666ad85b2373d9de50343dd494eec228a022d0c79429336a/hparams-0.2.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "afb7fd4bfb45535e88dc15bb0a435218", "sha256": "808f7e0b9618da4657a54d9b3219043107a32eed6d02db5ee12b49a1a8e54291"}, "downloads": -1, "filename": "hparams-0.2.0.tar.gz", "has_sig": false, "md5_digest": "afb7fd4bfb45535e88dc15bb0a435218", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 10732, "upload_time": "2019-09-29T18:26:01", "upload_time_iso_8601": "2019-09-29T18:26:01.558570Z", "url": "https://files.pythonhosted.org/packages/81/11/630a9e322c4095685b148f7e981401ae9f2d89da42e78ee7ebee353fe0c8/hparams-0.2.0.tar.gz", "yanked": false}], "0.2.1": [{"comment_text": "", "digests": {"md5": "9de91a1dae77f0de6a2b16e27c492861", "sha256": "9459bccc9993acfb1054c72fc2b205ba4000fd0979781144007197ba2cf96dce"}, "downloads": -1, "filename": "hparams-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9de91a1dae77f0de6a2b16e27c492861", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 10666, "upload_time": "2019-10-23T02:12:42", "upload_time_iso_8601": "2019-10-23T02:12:42.881451Z", "url": "https://files.pythonhosted.org/packages/94/a9/8caca7b9e44307d9d552997491e9cf462057dd418ca8ad654115d7efb977/hparams-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c2a69e98cb91dd401c9bdec3b6d2a253", "sha256": "e24be3f719bd5936f46b41a42fee456747679231ac9871e946a6052341b80e7b"}, "downloads": -1, "filename": "hparams-0.2.1.tar.gz", "has_sig": false, "md5_digest": "c2a69e98cb91dd401c9bdec3b6d2a253", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 11200, "upload_time": "2019-10-23T02:12:44", "upload_time_iso_8601": "2019-10-23T02:12:44.240842Z", "url": "https://files.pythonhosted.org/packages/ef/67/3ac2ed9f2adc674c50f1e635dde6ef7cf6a5bcd62b88220253543a6d52d5/hparams-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "0cf83a10d06d22a05c03dea07ab4ed6a", "sha256": "e3be8927a57b2aeb8801b9e045a62393343765aaab308b6dda015d65ebbc2160"}, "downloads": -1, "filename": "hparams-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0cf83a10d06d22a05c03dea07ab4ed6a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 11266, "upload_time": "2019-11-04T03:40:12", "upload_time_iso_8601": "2019-11-04T03:40:12.036816Z", "url": "https://files.pythonhosted.org/packages/2f/ec/bcc7011ec23390ac0ccafd031ad9f850430390b4ed3a8b1550788b7fe586/hparams-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "86d0e3e92866752e4ee6ca635d16bdad", "sha256": "a3b4eec68b8f2795a0d3dd8ef1348ecf447866f2ef33eddfa1a23ad5879953fc"}, "downloads": -1, "filename": "hparams-0.3.0.tar.gz", "has_sig": false, "md5_digest": "86d0e3e92866752e4ee6ca635d16bdad", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 12664, "upload_time": "2019-11-04T03:40:13", "upload_time_iso_8601": "2019-11-04T03:40:13.736334Z", "url": "https://files.pythonhosted.org/packages/39/0f/9831f1e406183f7a241ac02551afa7e31900ee846cdc58f595919b6f15f3/hparams-0.3.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "0cf83a10d06d22a05c03dea07ab4ed6a", "sha256": "e3be8927a57b2aeb8801b9e045a62393343765aaab308b6dda015d65ebbc2160"}, "downloads": -1, "filename": "hparams-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "0cf83a10d06d22a05c03dea07ab4ed6a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 11266, "upload_time": "2019-11-04T03:40:12", "upload_time_iso_8601": "2019-11-04T03:40:12.036816Z", "url": "https://files.pythonhosted.org/packages/2f/ec/bcc7011ec23390ac0ccafd031ad9f850430390b4ed3a8b1550788b7fe586/hparams-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "86d0e3e92866752e4ee6ca635d16bdad", "sha256": "a3b4eec68b8f2795a0d3dd8ef1348ecf447866f2ef33eddfa1a23ad5879953fc"}, "downloads": -1, "filename": "hparams-0.3.0.tar.gz", "has_sig": false, "md5_digest": "86d0e3e92866752e4ee6ca635d16bdad", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 12664, "upload_time": "2019-11-04T03:40:13", "upload_time_iso_8601": "2019-11-04T03:40:13.736334Z", "url": "https://files.pythonhosted.org/packages/39/0f/9831f1e406183f7a241ac02551afa7e31900ee846cdc58f595919b6f15f3/hparams-0.3.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:50:28 2020"}