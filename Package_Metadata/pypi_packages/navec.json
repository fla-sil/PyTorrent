{"info": {"author": "Alexander Kukushkin", "author_email": "alex@alexkuk.ru", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Programming Language :: Python :: 3", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "\n<img src=\"https://github.com/natasha/natasha-logos/blob/master/navec.svg\">\n\n![CI](https://github.com/natasha/navec/workflows/CI/badge.svg) [![codecov](https://codecov.io/gh/natasha/navec/branch/master/graph/badge.svg)](https://codecov.io/gh/natasha/navec)\n\n`navec` is a library of pretrained word embeddings for russian language. It shows competitive or better results than <a href=\"http://rusvectores.org\">RusVectores</a>, loads ~10 times faster (~1 sec), takes ~10 times less space (~50 MB).\n\n> Navec = large russian text datasets + vanila GloVe + quantization\n\n## Downloads\n\nHow to read model filename:\n```\nnavec_hudlit_v1_12B_500K_300d_100q.tar\n                 |    |    |    |\n                 |    |    |     ---- 100 dimentions after quantization\n                 |    |     --------- original vectors have 300 dimentions\n                 |     -------------- vocab size is 500 000 words + 1 for <unk>\n                  ------------------- dataset of 12 billion tokens was used\n```\n\nCurrently two models are published:\n<table>\n\n<tr>\n<th>Model</th>\n<th>Size</th>\n<th>Description</th>\n<th>Sources</th>\n</tr>\n\n<tr>\n<td>\n  <a href=\"https://github.com/natasha/navec/releases/download/v0.0.0/navec_hudlit_v1_12B_500K_300d_100q.tar\">navec_hudlit_v1_12B_500K_300d_100q.tar</a>\n</td>\n<td>50MB</td>\n<td>\n  Should be used by default. Shows best results on <a href=\"#evaluation\">intrinsic evaluations</a>. Model was trained on large corpus of russian literature (~150GB).\n</td>\n<td>\n  <a href=\"https://github.com/natasha/corus#load_librusec\"><code>librusec</code></a>\n</td>\n</tr>\n\n<tr>\n<td>\n<a href=\"https://github.com/natasha/navec/releases/download/v0.0.0/navec_news_v1_1B_250K_300d_100q.tar\">navec_news_v1_1B_250K_300d_100q.tar</a>\n</td>\n<td>25MB</td>\n<td>\n  Try to use this model to news texts. It is two times smaller than `hudlit` but covers same 98% of words in news articles.\n</td>\n<td>\n  <a href=\"//github.com/natasha/corus#load_lenta\"><code>lenta</code></a>\n  <a href=\"//github.com/natasha/corus#load_ria\"><code>ria</code></a>\n  <a href=\"//github.com/natasha/corus#load_taiga_fontanka\"><code>taiga_fontanka</code></a>\n  <a href=\"//github.com/natasha/corus#load_buriy_news\"><code>buriy_news</code></a>\n  <a href=\"//github.com/natasha/corus#load_buriy_webhose\"><code>buriy_webhose</code></a>\n  <a href=\"//github.com/natasha/corus#load_ods_gazeta\"><code>ods_gazeta</code></a>\n  <a href=\"//github.com/natasha/corus#load_ods_interfax\"><code>ods_interfax</code></a>\n</td>\n</tr>\n\n</table>\n\n## Installation\n\n`navec` supports Pyton 3.5+ and PyPy 3.\n\n```bash\n$ pip install navec\n```\n\n## Usage\n\nFirst download `hudlit` emdeddings (see the table above):\n```bash\nwget https://github.com/natasha/navec/releases/download/v0.0.0/navec_hudlit_v1_12B_500K_300d_100q.tar\n```\n\nLoad tar-archive with `Navec.load`, it takes ~1s and ~100MB of RAM:\n```python\n>>> from navec import Navec\n\n>>> path = 'hudlit_12B_500K_300d_100q.tar'\n>>> navec = Navec.load(path)\n```\n\nThen `navec` can be used as a dict object:\n```python\n>>> navec['\u043d\u0430\u0432\u0435\u043a']\narray([ 0.3955571 ,  0.11600914,  0.24605067, -0.35206917, -0.08932345,\n        0.3382279 , -0.5457616 ,  0.07472657, -0.4753835 , -0.3330848 ,\n        ...\n\n>>> '\u043d\u0430\u0430\u0430\u0432\u0435\u0435\u0435\u043a' in navec\nFalse\n\n>>> navec.get('\u043d\u0430\u0430\u0430\u0432\u0435\u0435\u0435\u043a')\nNone\n```\n\nTo get an index of word, use `navec.vocab`:\n```python\n>>> navec.vocab['\u043d\u0430\u0432\u0435\u043a']\n225823\n\n>>> navec.vocab.get('\u043d\u0430\u0430\u0430\u0430\u0432\u0435ee\u043a', navec.vocab.unk_id)\n500000   # == navec.vocab['<unk>']\n```\n\nThere are two special words in vocab, `<unk>` and `<pad>`:\n```python\n>>> navec['<unk>']\narray([ 3.69125791e-02,  9.32818875e-02,  2.01917738e-02, ...\n\n>>> navec['<pad>']\narray([0., 0., 0., 0., 0., 0., ...\n\n```\n\n\n## Evaluation\n\nLet's compore Navec to top 5 RusVectores models (based on <a href=\"https://github.com/natasha/corus#load_simlex\">`simlex`</a> and <a href=\"https://github.com/natasha/corus#load_russe_hj\">`hj`</a> eval datasets). In each column top 3 results are highlighted.\n\n* `init` \u2014 time it takes to load model file to RAM. `tayga_upos_skipgram_300_2_2019` word2vec binary file takes 15.7 seconds to load with `gensim.KeyedVectors.load_word2vec_format`. `tayga_none_fasttextcbow_300_10_2019` fastText large ~2.7 GB file takes 11.3 seconds. Navec `hudlit` with vocab 2 times larger than previous two takes 1 second.\n* `get` \u2014 time is takes to query embedding vector for a single word. Word2vec models win here, to fetch a vector they basically do `dict.get`. FastText and Navec for every query do extra computation. FastText extracts and sums word ngrams, Navec unpacks vector from quantization table. In practice query to embeddings table is small compared to all other computation in network.\n* `disk` \u2014 model file size. It is convenient for deployment and distribution to have small models. Notice that `hudlit` model is 4-20 times smaller with vocab size 2 times bigger.\n* `ram` \u2014 space model takes in RAM after loading. It is convenient to have small memory footprint to fit more computation on single server.\n* `vocab` \u2014 number of words in vocab, number of embedding vectors. Since Navec vectors table takes less space we can have larger vocab. With 500K vocab `hudlit` model has ~2% OVV rate on average.\n\n<!--- emb1 --->\n<table border=\"0\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>init, s</th>\n      <th>get, \u00b5s</th>\n      <th>disk, mb</th>\n      <th>ram, mb</th>\n      <th>vocab</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ruscorpora_upos_cbow_300_20_2019</th>\n      <td>w2v</td>\n      <td>12.1</td>\n      <td><b>1.6</b></td>\n      <td><b>220.6</b></td>\n      <td><b>236.1</b></td>\n      <td>189K</td>\n    </tr>\n    <tr>\n      <th>ruwikiruscorpora_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td>15.7</td>\n      <td><b>1.7</b></td>\n      <td>290.0</td>\n      <td>309.4</td>\n      <td>248K</td>\n    </tr>\n    <tr>\n      <th>tayga_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td>15.7</td>\n      <td><b>1.2</b></td>\n      <td>290.7</td>\n      <td>310.9</td>\n      <td><b>249K</b></td>\n    </tr>\n    <tr>\n      <th>tayga_none_fasttextcbow_300_10_2019</th>\n      <td>fasttext</td>\n      <td>11.3</td>\n      <td>14.3</td>\n      <td>2741.9</td>\n      <td>2746.9</td>\n      <td>192K</td>\n    </tr>\n    <tr>\n      <th>araneum_none_fasttextcbow_300_5_2018</th>\n      <td>fasttext</td>\n      <td><b>7.8</b></td>\n      <td>15.4</td>\n      <td>2752.1</td>\n      <td>2754.7</td>\n      <td>195K</td>\n    </tr>\n    <tr>\n      <th>hudlit_12B_500K_300d_100q</th>\n      <td>navec</td>\n      <td><b>1.0</b></td>\n      <td>19.9</td>\n      <td><b>50.6</b></td>\n      <td><b>95.3</b></td>\n      <td><b>500K</b></td>\n    </tr>\n    <tr>\n      <th>news_1B_250K_300d_100q</th>\n      <td>navec</td>\n      <td><b>0.5</b></td>\n      <td>20.3</td>\n      <td><b>25.4</b></td>\n      <td><b>47.7</b></td>\n      <td><b>250K</b></td>\n    </tr>\n  </tbody>\n</table>\n<!--- emb1 --->\n\nNow let's look at intrinsic evaluation scores. Navec `hudlit` model does not show best results on all datasets but it is usually in top 3. We'll use 6 datasets:\n\n* <a href=\"https://github.com/natasha/corus#load_simlex\">`simlex965`</a>, <a href=\"https://github.com/natasha/corus#load_russe_hj\">`hj`</a> \u2014 two small datasets (965 and 398 tests respectively) used by RusVectores, see the <a href=\"https://arxiv.org/abs/1801.06407\">their paper</a> for more info. Metric is spearman correlation, other datasets use average precision.\n* <a href=\"https://github.com/natasha/corus#load_russe_rt\">`rt`</a>, <a href=\"https://github.com/natasha/corus#load_russe_ae\">`ae`</a>, <a href=\"https://github.com/natasha/corus#load_russe_ae\">`ae2`</a> \u2014 large datasets (114066, 22919, 86772 tests) from RUSSE workshop, see <a href=\"https://russe.nlpub.org/downloads/\">project description</a> for more.\n* <a href=\"https://github.com/natasha/corus#load_toloka_lrwc\">`lrwc`</a> \u2014 relatively new dataset by Yandex.Toloka, see <a href=\"https://research.yandex.com/datasets/toloka\">their page</a>.\n\n<!--- emb2 --->\n<table border=\"0\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>simlex</th>\n      <th>hj</th>\n      <th>rt</th>\n      <th>ae</th>\n      <th>ae2</th>\n      <th>lrwc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ruscorpora_upos_cbow_300_20_2019</th>\n      <td>w2v</td>\n      <td><b>0.359</b></td>\n      <td>0.685</td>\n      <td><b>0.852</b></td>\n      <td>0.758</td>\n      <td><b>0.896</b></td>\n      <td>0.602</td>\n    </tr>\n    <tr>\n      <th>ruwikiruscorpora_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td>0.321</td>\n      <td><b>0.723</b></td>\n      <td>0.817</td>\n      <td><b>0.801</b></td>\n      <td>0.860</td>\n      <td><b>0.629</b></td>\n    </tr>\n    <tr>\n      <th>tayga_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td><b>0.429</b></td>\n      <td><b>0.749</b></td>\n      <td><b>0.871</b></td>\n      <td>0.771</td>\n      <td><b>0.899</b></td>\n      <td><b>0.639</b></td>\n    </tr>\n    <tr>\n      <th>tayga_none_fasttextcbow_300_10_2019</th>\n      <td>fasttext</td>\n      <td><b>0.369</b></td>\n      <td>0.639</td>\n      <td>0.793</td>\n      <td>0.682</td>\n      <td>0.813</td>\n      <td>0.536</td>\n    </tr>\n    <tr>\n      <th>araneum_none_fasttextcbow_300_5_2018</th>\n      <td>fasttext</td>\n      <td>0.349</td>\n      <td>0.671</td>\n      <td>0.801</td>\n      <td>0.706</td>\n      <td>0.793</td>\n      <td>0.579</td>\n    </tr>\n    <tr>\n      <th>hudlit_12B_500K_300d_100q</th>\n      <td>navec</td>\n      <td>0.310</td>\n      <td><b>0.707</b></td>\n      <td><b>0.842</b></td>\n      <td><b>0.931</b></td>\n      <td><b>0.923</b></td>\n      <td><b>0.604</b></td>\n    </tr>\n    <tr>\n      <th>news_1B_250K_300d_100q</th>\n      <td>navec</td>\n      <td>0.230</td>\n      <td>0.590</td>\n      <td>0.784</td>\n      <td><b>0.866</b></td>\n      <td>0.861</td>\n      <td>0.589</td>\n    </tr>\n  </tbody>\n</table>\n<!--- emb2 --->\n\n## Support\n\n- Chat \u2014 https://telegram.me/natural_language_processing\n- Issues \u2014 https://github.com/natasha/navec/issues\n\n## Development\n\nTest\n\n```bash\nmake test\n```\n\nPackage\n\n```bash\nmake version\ngit push\ngit push --tags\n\nmake clean wheel upload\n```\n\nNotice! All commands belows use code from `navec/train`, it is not under CI, it works only with Python 3, it is expected user is familiar with source code. We use Yandex Cloud Compute and Object Storage.\n\nCreate remote worker\n\nTo compute cooc (large HDD, 1Tb for librusec).\n```bash\nyc compute instance create \\\n    --name worker \\\n    --zone ru-central1-a \\\n    --network-interface subnet-name=default,nat-ip-version=ipv4 \\\n    --create-boot-disk image-folder-id=standard-images,image-family=ubuntu-1804,type=network-hdd,size=1000 \\\n    --memory 8 \\\n    --cores 1 \\\n    --core-fraction 100 \\\n    --ssh-key ~/.ssh/id_rsa.pub \\\n    --folder-name default \\\n    --preemptible  # in case computation takes <24h\n```\n\nTo fit embedings (multiple cores). HDD should be > cooc.bin * 3 (for suffle + tmp)\n```bash\nyc compute instance create \\\n    --name worker \\\n    --zone ru-central1-a \\\n    --network-interface subnet-name=default,nat-ip-version=ipv4 \\\n    --create-boot-disk image-folder-id=standard-images,image-family=ubuntu-1804,type=network-hdd,size=700 \\\n    --memory 16 \\\n    --cores 16 \\\n    --core-fraction 100 \\\n    --ssh-key ~/.ssh/id_rsa.pub  \\\n    --folder-name default \\\n    --preemptible\n```\n\nSetup machine\n```bash\nyc compute instance list --folder-name default\nssh yc-user@123.123.123.123\n\nsudo locale-gen en_US.UTF-8\nsudo timedatectl set-timezone Europe/Moscow\nsudo apt-get update\nsudo DEBIAN_FRONTEND=noninteractive apt-get install -y language-pack-ru python3-pip screen unzip git pv cmake\n\nwget https://nlp.stanford.edu/software/GloVe-1.2.zip\nunzip GloVe-1.2.zip\nrm GloVe-1.2.zip\nmv GloVe-1.2 glove\ncd glove\nmake\ncd ..\n\nexport GLOVE_DIR=~/glove/build\n\ngit clone https://github.com/natasha/navec.git\nsudo -H pip3 install -e navec\nsudo -H pip3 install -r navec/requirements/train.txt\n\nscreen\nctrl a d\n```\n\nRemove instance\n```bash\nyc compute instance list --folder-name default\nyc compute instance delete xxxxxxxxx\n````\n\nEnv, used by `navec-train s3|vocab|cooc|emb`\n```bash\nexport S3_KEY=_XxXXXxxx_XXXxxxxXxxx\nexport S3_SECRET=XXxxx_XXXXXXxxxxxxXXXXxxXXx-XxxXXxxxX\nexport S3_BUCKET=XXXXXXX\nexport GLOVE_DIR=~/path/to/glove/build\n```\n\nShare text data (see corus)\n```bash\nnavec-train s3 upload librusec_fb2.plain.gz sources/librusec.gz\nnavec-train s3 upload taiga/proza_ru.zip sources/taiga_proza.zip\n\nnavec-train s3 upload ruwiki-latest-pages-articles.xml.bz2 sources/wiki.xml.bz2\n\nnavec-train s3 upload lenta-ru-news.csv.gz sources/lenta.csv.gz\nnavec-train s3 upload ria.json.gz sources/ria.json.gz\nnavec-train s3 upload taiga/Fontanka.tar.gz sources/taiga_fontanka.tar.gz\nnavec-train s3 upload buriy/news-articles-2014.tar.bz2 sources/buriy_news1.tar.bz2\nnavec-train s3 upload buriy/news-articles-2015-part1.tar.bz2 sources/buriy_news2.tar.bz2\nnavec-train s3 upload buriy/news-articles-2015-part2.tar.bz2 sources/buriy_news3.tar.bz2\nnavec-train s3 upload buriy/webhose-2016.tar.bz2 sources/buriy_webhose.tar.bz2\nnavec-train s3 upload ods/gazeta_v1.csv.zip sources/ods_gazeta.csv.zip\nnavec-train s3 upload ods/interfax_v1.csv.zip sources/ods_interfax.csv.zip\n\nnavec-train s3 download sources/librusec.gz\nnavec-train s3 download sources/taiga_proza.zip\n\nnavec-train s3 download sources/wiki.xml.bz2\n\nnavec-train s3 download sources/lenta.csv.gz\nnavec-train s3 download sources/ria.json.gz\nnavec-train s3 download sources/taiga_fontanka.tar.gz\nnavec-train s3 download sources/buriy_news1.tar.bz2\nnavec-train s3 download sources/buriy_news2.tar.bz2\nnavec-train s3 download sources/buriy_news3.tar.bz2\nnavec-train s3 download sources/buriy_webhose.tar.bz2\nnavec-train s3 download sources/ods_gazeta.csv.zip\nnavec-train s3 download sources/ods_interfax.csv.zip\n```\n\nText to tokens\n```bash\nnavec-train corpus librusec librusec.gz | pv | navec-train tokenize > tokens.txt  # ~12B words\nnavec-train corpus taiga_proza taiga_proza.zip | pv | navec-train tokenize > tokens.txt  # ~3B\n\nnavec-train corpus wiki wiki.xml.bz2 | pv | navec-train tokenize > tokens.txt  # ~0.5B\n\nnavec-train corpus lenta lenta.csv.gz | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus ria ria.json.gz | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus taiga_fontanka taiga_fontanka.tar.gz | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus buriy_news buriy_news1.tar.bz2 | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus buriy_news buriy_news2.tar.bz2 | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus buriy_news buriy_news3.tar.bz2 | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus buriy_webhose buriy_webhose.tar.bz2 | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus ods_gazeta ods_gazeta.csv.zip | pv | navec-train tokenize >> tokens.txt\nnavec-train corpus ods_interfax ods_interfax.csv.zip | pv | navec-train tokenize >> tokens.txt  # ~1B\n\npv tokens.txt | gzip > tokens.txt.gz\nnavec-train s3 upload tokens.txt.gz librusec_tokens.txt.gz\n\nnavec-train s3 upload tokens.txt taiga_proza_tokens.txt\nnavec-train s3 upload tokens.txt news_tokens.txt\nnavec-train s3 upload tokens.txt wiki_tokens.txt\n```\n\nTokens to vocab\n```bash\npv tokens.txt \\\n\t| navec-train vocab count \\\n\t> full_vocab.txt\n\npv full_vocab.txt \\\n\t| navec-train vocab quantile\n\n# librusec\n# ...\n# 0.970      325 882\n# 0.980      511 542\n# 0.990    1 122 624\n# 1.000   22 129 654\n\n# taiga_proza\n# ...\n# 0.960      229 906\n# 0.970      321 810\n# 0.980      517 647\n# 0.990    1 224 277\n# 1.000   14 302 409\n\n# wiki\n# ...\n# 0.950     380 134\n# 0.960     519 817\n# 0.970     757 561\n# 0.980   1 223 201\n# 0.990   2 422 265\n# 1.000   6 664 630\n\n# news\n# ...\n# 0.970    163 833\n# 0.980    243 903\n# 0.990    462 361\n# 1.000  3 744 070\n\n# threashold at ~0.98\n# librusec 500000\n# taiga_proza 500000\n# wiki 750000\n# news 250000\n\ncat full_vocab.txt \\\n\t| head -500000 \\\n\t| LC_ALL=C sort \\\n\t> vocab.txt\n\nnavec-train s3 upload full_vocab.txt librusec_full_vocab.txt\nnavec-train s3 upload vocab.txt librusec_vocab.txt\n\nnavec-train s3 upload full_vocab.txt taiga_proza_full_vocab.txt\nnavec-train s3 upload vocab.txt taiga_proza_vocab.txt\n\nnavec-train s3 upload full_vocab.txt wiki_full_vocab.txt\nnavec-train s3 upload vocab.txt wiki_vocab.txt\n\nnavec-train s3 upload full_vocab.txt news_full_vocab.txt\nnavec-train s3 upload vocab.txt news_vocab.txt\n```\n\nCompute coocurence pairs\n```bash\n# Default limit on max number of open files is 1024, merge fails if\n# number of chunks is large\n\nulimit -n  # 1024\nsudo nano /etc/security/limits.conf\n\n* soft     nofile         65535\n* hard     nofile         65535\n\n# relogin\nulimit -n  # 65535\n\npv tokens.txt \\\n\t| navec-train cooc count vocab.txt --memory 7 --window 10 \\\n\t> cooc.bin\n\n# Monitor\nls /tmp/cooc_*\ntail -c 16 cooc.bin | navec-train cooc parse\n\nnavec-train s3 upload cooc.bin librusec_cooc.bin\nnavec-train s3 upload cooc.bin taiga_proza_cooc.bin\nnavec-train s3 upload cooc.bin wiki_cooc.bin\nnavec-train s3 upload cooc.bin news_cooc.bin\n```\n\nMerge (did not give much boost compared to plain librusec, so all_vocab.txt, all_cooc.bin not used below)\n```bash\nfor i in librusec taiga_proza wiki news; do\n\tnavec-train s3 download $i_vocab.txt;\n\tnavec-train s3 download $i_cooc.bin;\ndone\n\nnavec-train merge vocabs \\\n\tlibrusec_vocab.txt \\\n\ttaiga_proza_vocab.txt \\\n\twiki_vocab.txt \\\n\tnews_vocab.txt \\\n\t| pv > vocab.txt\n\nnavec-train merge coocs vocab.txt \\\n\tlibrusec_cooc.bin:librusec_vocab.txt \\\n\ttaiga_proza_cooc.bin:taiga_proza_vocab.txt \\\n\twiki_cooc.bin:wiki_vocab.txt \\\n\tnews_cooc.bin:news_vocab.txt \\\n\t| pv > cooc.bin\n\nnavec-train s3 upload vocab.txt all_vocab.txt\nnavec-train s3 upload cooc.bin all_cooc.bin\n```\n\nCompute embedings\n```bash\nnavec-train s3 download librusec_vocab.txt vocab.txt\nnavec-train s3 download librusec_cooc.bin cooc.bin\n\nnavec-train s3 download wiki_vocab.txt vocab.txt\nnavec-train s3 download wiki_cooc.bin cooc.bin\n\nnavec-train s3 download news_vocab.txt vocab.txt\nnavec-train s3 download news_cooc.bin cooc.bin\n\npv cooc.bin \\\n\t| navec-train cooc shuffle --memory 15 \\\n\t> shuf_cooc.bin\n\n# Search dim with best score\nfor i in 100 200 300 400 500 600;\n\tdo navec-train emb shuf_cooc.bin vocab.txt emb_${i}d.txt --dim $i --threads 10 --iterations 2;\ndone\n\n# 300 has ok score. 400, 500 are a bit better, but too heavy\nnavec-train emb shuf_cooc.bin vocab.txt emb.txt --dim 300 --threads 16 --iterations 15\n\nnavec-train s3 upload emb.txt librusec_emb.txt\nnavec-train s3 upload emb.txt wiki_emb.txt\nnavec-train s3 upload emb.txt news_emb.txt\n```\n\nQuantize\n```bash\nnavec-train s3 download librusec_emb.txt emb.txt\nnavec-train s3 download wiki_emb.txt emb.txt\nnavec-train s3 download news_emb.txt emb.txt\n\n# Search for best compression that has still ok score\nfor i in 150 100 75 60 50;\n\tdo pv emb.txt | navec-train pq fit $i --sample 100000 --iterations 15 > pq_${i}q.bin;\ndone\n\n# 100 is <1% worse on eval but much lighter\npv emb.txt | navec-train pq fit 100 --sample 100000 --iterations 20 > pq.bin\n\nnavec-train pq pad < pq.bin > t; mv t pq.bin\n\nnavec-train s3 upload pq.bin librusec_pq.bin\nnavec-train s3 upload pq.bin wiki_pq.bin\nnavec-train s3 upload pq.bin news_pq.bin\n```\n\nPack\n```\nnavec-train s3 download librusec_pq.bin pq.bin\nnavec-train s3 download librusec_vocab.txt vocab.txt\n\nnavec-train s3 download news_pq.bin pq.bin\nnavec-train s3 download news_vocab.txt vocab.txt\n\nnavec-train vocab pack < vocab.txt > vocab.bin\n\nnavec-train pack vocab.bin pq.bin hudlit_v1_12B_500K_300d_100q\nnavec-train s3 upload navec_hudlit_v1_12B_500K_300d_100q.tar packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n\nnavec-train pack vocab.bin pq.bin news_v1_1B_250K_300d_100q\nnavec-train s3 upload navec_news_v1_1B_250K_300d_100q.tar packs/navec_news_v1_1B_250K_300d_100q.tar\n```\n\nPublish\n```\nnavec-train s3 download packs/navec_hudlit_v1_12B_500K_300d_100q.tar\nnavec-train s3 download packs/navec_news_v1_1B_250K_300d_100q.tar\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/natasha/navec", "keywords": "embeddings,word2vec,glove,nlp,russian,quantization", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "navec", "package_url": "https://pypi.org/project/navec/", "platform": "", "project_url": "https://pypi.org/project/navec/", "project_urls": {"Homepage": "https://github.com/natasha/navec"}, "release_url": "https://pypi.org/project/navec/0.9.0/", "requires_dist": ["numpy"], "requires_python": "", "summary": "Compact high quality word embeddings for russian language", "version": "0.9.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/08559cd56b5123cd25aa11427e2285f94788e58d/68747470733a2f2f6769746875622e636f6d2f6e6174617368612f6e6174617368612d6c6f676f732f626c6f622f6d61737465722f6e617665632e737667\">\n<p><img alt=\"CI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/41a62aadac7dc995fa79db39fd7a1751d3ad9522/68747470733a2f2f6769746875622e636f6d2f6e6174617368612f6e617665632f776f726b666c6f77732f43492f62616467652e737667\"> <a href=\"https://codecov.io/gh/natasha/navec\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dccba62a923ec41842f9f9803763c823abb1e714/68747470733a2f2f636f6465636f762e696f2f67682f6e6174617368612f6e617665632f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<p><code>navec</code> is a library of pretrained word embeddings for russian language. It shows competitive or better results than <a href=\"http://rusvectores.org\" rel=\"nofollow\">RusVectores</a>, loads ~10 times faster (~1 sec), takes ~10 times less space (~50 MB).</p>\n<blockquote>\n<p>Navec = large russian text datasets + vanila GloVe + quantization</p>\n</blockquote>\n<h2>Downloads</h2>\n<p>How to read model filename:</p>\n<pre><code>navec_hudlit_v1_12B_500K_300d_100q.tar\n                 |    |    |    |\n                 |    |    |     ---- 100 dimentions after quantization\n                 |    |     --------- original vectors have 300 dimentions\n                 |     -------------- vocab size is 500 000 words + 1 for &lt;unk&gt;\n                  ------------------- dataset of 12 billion tokens was used\n</code></pre>\n<p>Currently two models are published:</p>\n<table>\n<tr>\n<th>Model</th>\n<th>Size</th>\n<th>Description</th>\n<th>Sources</th>\n</tr>\n<tr>\n<td>\n  <a href=\"https://github.com/natasha/navec/releases/download/v0.0.0/navec_hudlit_v1_12B_500K_300d_100q.tar\" rel=\"nofollow\">navec_hudlit_v1_12B_500K_300d_100q.tar</a>\n</td>\n<td>50MB</td>\n<td>\n  Should be used by default. Shows best results on <a href=\"#evaluation\" rel=\"nofollow\">intrinsic evaluations</a>. Model was trained on large corpus of russian literature (~150GB).\n</td>\n<td>\n  <a href=\"https://github.com/natasha/corus#load_librusec\" rel=\"nofollow\"><code>librusec</code></a>\n</td>\n</tr>\n<tr>\n<td>\n<a href=\"https://github.com/natasha/navec/releases/download/v0.0.0/navec_news_v1_1B_250K_300d_100q.tar\" rel=\"nofollow\">navec_news_v1_1B_250K_300d_100q.tar</a>\n</td>\n<td>25MB</td>\n<td>\n  Try to use this model to news texts. It is two times smaller than `hudlit` but covers same 98% of words in news articles.\n</td>\n<td>\n  <a href=\"//github.com/natasha/corus#load_lenta\" rel=\"nofollow\"><code>lenta</code></a>\n  <a href=\"//github.com/natasha/corus#load_ria\" rel=\"nofollow\"><code>ria</code></a>\n  <a href=\"//github.com/natasha/corus#load_taiga_fontanka\" rel=\"nofollow\"><code>taiga_fontanka</code></a>\n  <a href=\"//github.com/natasha/corus#load_buriy_news\" rel=\"nofollow\"><code>buriy_news</code></a>\n  <a href=\"//github.com/natasha/corus#load_buriy_webhose\" rel=\"nofollow\"><code>buriy_webhose</code></a>\n  <a href=\"//github.com/natasha/corus#load_ods_gazeta\" rel=\"nofollow\"><code>ods_gazeta</code></a>\n  <a href=\"//github.com/natasha/corus#load_ods_interfax\" rel=\"nofollow\"><code>ods_interfax</code></a>\n</td>\n</tr>\n</table>\n<h2>Installation</h2>\n<p><code>navec</code> supports Pyton 3.5+ and PyPy 3.</p>\n<pre>$ pip install navec\n</pre>\n<h2>Usage</h2>\n<p>First download <code>hudlit</code> emdeddings (see the table above):</p>\n<pre>wget https://github.com/natasha/navec/releases/download/v0.0.0/navec_hudlit_v1_12B_500K_300d_100q.tar\n</pre>\n<p>Load tar-archive with <code>Navec.load</code>, it takes ~1s and ~100MB of RAM:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"kn\">from</span> <span class=\"nn\">navec</span> <span class=\"kn\">import</span> <span class=\"n\">Navec</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"s1\">'hudlit_12B_500K_300d_100q.tar'</span>\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span> <span class=\"o\">=</span> <span class=\"n\">Navec</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">path</span><span class=\"p\">)</span>\n</pre>\n<p>Then <code>navec</code> can be used as a dict object:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span><span class=\"p\">[</span><span class=\"s1\">'\u043d\u0430\u0432\u0435\u043a'</span><span class=\"p\">]</span>\n<span class=\"n\">array</span><span class=\"p\">([</span> <span class=\"mf\">0.3955571</span> <span class=\"p\">,</span>  <span class=\"mf\">0.11600914</span><span class=\"p\">,</span>  <span class=\"mf\">0.24605067</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.35206917</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.08932345</span><span class=\"p\">,</span>\n        <span class=\"mf\">0.3382279</span> <span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.5457616</span> <span class=\"p\">,</span>  <span class=\"mf\">0.07472657</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.4753835</span> <span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mf\">0.3330848</span> <span class=\"p\">,</span>\n        <span class=\"o\">...</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"s1\">'\u043d\u0430\u0430\u0430\u0432\u0435\u0435\u0435\u043a'</span> <span class=\"ow\">in</span> <span class=\"n\">navec</span>\n<span class=\"kc\">False</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'\u043d\u0430\u0430\u0430\u0432\u0435\u0435\u0435\u043a'</span><span class=\"p\">)</span>\n<span class=\"kc\">None</span>\n</pre>\n<p>To get an index of word, use <code>navec.vocab</code>:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"p\">[</span><span class=\"s1\">'\u043d\u0430\u0432\u0435\u043a'</span><span class=\"p\">]</span>\n<span class=\"mi\">225823</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">'\u043d\u0430\u0430\u0430\u0430\u0432\u0435ee\u043a'</span><span class=\"p\">,</span> <span class=\"n\">navec</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">unk_id</span><span class=\"p\">)</span>\n<span class=\"mi\">500000</span>   <span class=\"c1\"># == navec.vocab['&lt;unk&gt;']</span>\n</pre>\n<p>There are two special words in vocab, <code>&lt;unk&gt;</code> and <code>&lt;pad&gt;</code>:</p>\n<pre><span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span><span class=\"p\">[</span><span class=\"s1\">'&lt;unk&gt;'</span><span class=\"p\">]</span>\n<span class=\"n\">array</span><span class=\"p\">([</span> <span class=\"mf\">3.69125791e-02</span><span class=\"p\">,</span>  <span class=\"mf\">9.32818875e-02</span><span class=\"p\">,</span>  <span class=\"mf\">2.01917738e-02</span><span class=\"p\">,</span> <span class=\"o\">...</span>\n\n<span class=\"o\">&gt;&gt;&gt;</span> <span class=\"n\">navec</span><span class=\"p\">[</span><span class=\"s1\">'&lt;pad&gt;'</span><span class=\"p\">]</span>\n<span class=\"n\">array</span><span class=\"p\">([</span><span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"mf\">0.</span><span class=\"p\">,</span> <span class=\"o\">...</span>\n</pre>\n<h2>Evaluation</h2>\n<p>Let's compore Navec to top 5 RusVectores models (based on <a href=\"https://github.com/natasha/corus#load_simlex\" rel=\"nofollow\"><code>simlex</code></a> and <a href=\"https://github.com/natasha/corus#load_russe_hj\" rel=\"nofollow\"><code>hj</code></a> eval datasets). In each column top 3 results are highlighted.</p>\n<ul>\n<li><code>init</code> \u2014 time it takes to load model file to RAM. <code>tayga_upos_skipgram_300_2_2019</code> word2vec binary file takes 15.7 seconds to load with <code>gensim.KeyedVectors.load_word2vec_format</code>. <code>tayga_none_fasttextcbow_300_10_2019</code> fastText large ~2.7 GB file takes 11.3 seconds. Navec <code>hudlit</code> with vocab 2 times larger than previous two takes 1 second.</li>\n<li><code>get</code> \u2014 time is takes to query embedding vector for a single word. Word2vec models win here, to fetch a vector they basically do <code>dict.get</code>. FastText and Navec for every query do extra computation. FastText extracts and sums word ngrams, Navec unpacks vector from quantization table. In practice query to embeddings table is small compared to all other computation in network.</li>\n<li><code>disk</code> \u2014 model file size. It is convenient for deployment and distribution to have small models. Notice that <code>hudlit</code> model is 4-20 times smaller with vocab size 2 times bigger.</li>\n<li><code>ram</code> \u2014 space model takes in RAM after loading. It is convenient to have small memory footprint to fit more computation on single server.</li>\n<li><code>vocab</code> \u2014 number of words in vocab, number of embedding vectors. Since Navec vectors table takes less space we can have larger vocab. With 500K vocab <code>hudlit</code> model has ~2% OVV rate on average.</li>\n</ul>\n\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th>type</th>\n      <th>init, s</th>\n      <th>get, \u00b5s</th>\n      <th>disk, mb</th>\n      <th>ram, mb</th>\n      <th>vocab</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ruscorpora_upos_cbow_300_20_2019</th>\n      <td>w2v</td>\n      <td>12.1</td>\n      <td><b>1.6</b></td>\n      <td><b>220.6</b></td>\n      <td><b>236.1</b></td>\n      <td>189K</td>\n    </tr>\n    <tr>\n      <th>ruwikiruscorpora_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td>15.7</td>\n      <td><b>1.7</b></td>\n      <td>290.0</td>\n      <td>309.4</td>\n      <td>248K</td>\n    </tr>\n    <tr>\n      <th>tayga_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td>15.7</td>\n      <td><b>1.2</b></td>\n      <td>290.7</td>\n      <td>310.9</td>\n      <td><b>249K</b></td>\n    </tr>\n    <tr>\n      <th>tayga_none_fasttextcbow_300_10_2019</th>\n      <td>fasttext</td>\n      <td>11.3</td>\n      <td>14.3</td>\n      <td>2741.9</td>\n      <td>2746.9</td>\n      <td>192K</td>\n    </tr>\n    <tr>\n      <th>araneum_none_fasttextcbow_300_5_2018</th>\n      <td>fasttext</td>\n      <td><b>7.8</b></td>\n      <td>15.4</td>\n      <td>2752.1</td>\n      <td>2754.7</td>\n      <td>195K</td>\n    </tr>\n    <tr>\n      <th>hudlit_12B_500K_300d_100q</th>\n      <td>navec</td>\n      <td><b>1.0</b></td>\n      <td>19.9</td>\n      <td><b>50.6</b></td>\n      <td><b>95.3</b></td>\n      <td><b>500K</b></td>\n    </tr>\n    <tr>\n      <th>news_1B_250K_300d_100q</th>\n      <td>navec</td>\n      <td><b>0.5</b></td>\n      <td>20.3</td>\n      <td><b>25.4</b></td>\n      <td><b>47.7</b></td>\n      <td><b>250K</b></td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Now let's look at intrinsic evaluation scores. Navec <code>hudlit</code> model does not show best results on all datasets but it is usually in top 3. We'll use 6 datasets:</p>\n<ul>\n<li><a href=\"https://github.com/natasha/corus#load_simlex\" rel=\"nofollow\"><code>simlex965</code></a>, <a href=\"https://github.com/natasha/corus#load_russe_hj\" rel=\"nofollow\"><code>hj</code></a> \u2014 two small datasets (965 and 398 tests respectively) used by RusVectores, see the <a href=\"https://arxiv.org/abs/1801.06407\" rel=\"nofollow\">their paper</a> for more info. Metric is spearman correlation, other datasets use average precision.</li>\n<li><a href=\"https://github.com/natasha/corus#load_russe_rt\" rel=\"nofollow\"><code>rt</code></a>, <a href=\"https://github.com/natasha/corus#load_russe_ae\" rel=\"nofollow\"><code>ae</code></a>, <a href=\"https://github.com/natasha/corus#load_russe_ae\" rel=\"nofollow\"><code>ae2</code></a> \u2014 large datasets (114066, 22919, 86772 tests) from RUSSE workshop, see <a href=\"https://russe.nlpub.org/downloads/\" rel=\"nofollow\">project description</a> for more.</li>\n<li><a href=\"https://github.com/natasha/corus#load_toloka_lrwc\" rel=\"nofollow\"><code>lrwc</code></a> \u2014 relatively new dataset by Yandex.Toloka, see <a href=\"https://research.yandex.com/datasets/toloka\" rel=\"nofollow\">their page</a>.</li>\n</ul>\n\n<table>\n  <thead>\n    <tr>\n      <th></th>\n      <th>type</th>\n      <th>simlex</th>\n      <th>hj</th>\n      <th>rt</th>\n      <th>ae</th>\n      <th>ae2</th>\n      <th>lrwc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ruscorpora_upos_cbow_300_20_2019</th>\n      <td>w2v</td>\n      <td><b>0.359</b></td>\n      <td>0.685</td>\n      <td><b>0.852</b></td>\n      <td>0.758</td>\n      <td><b>0.896</b></td>\n      <td>0.602</td>\n    </tr>\n    <tr>\n      <th>ruwikiruscorpora_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td>0.321</td>\n      <td><b>0.723</b></td>\n      <td>0.817</td>\n      <td><b>0.801</b></td>\n      <td>0.860</td>\n      <td><b>0.629</b></td>\n    </tr>\n    <tr>\n      <th>tayga_upos_skipgram_300_2_2019</th>\n      <td>w2v</td>\n      <td><b>0.429</b></td>\n      <td><b>0.749</b></td>\n      <td><b>0.871</b></td>\n      <td>0.771</td>\n      <td><b>0.899</b></td>\n      <td><b>0.639</b></td>\n    </tr>\n    <tr>\n      <th>tayga_none_fasttextcbow_300_10_2019</th>\n      <td>fasttext</td>\n      <td><b>0.369</b></td>\n      <td>0.639</td>\n      <td>0.793</td>\n      <td>0.682</td>\n      <td>0.813</td>\n      <td>0.536</td>\n    </tr>\n    <tr>\n      <th>araneum_none_fasttextcbow_300_5_2018</th>\n      <td>fasttext</td>\n      <td>0.349</td>\n      <td>0.671</td>\n      <td>0.801</td>\n      <td>0.706</td>\n      <td>0.793</td>\n      <td>0.579</td>\n    </tr>\n    <tr>\n      <th>hudlit_12B_500K_300d_100q</th>\n      <td>navec</td>\n      <td>0.310</td>\n      <td><b>0.707</b></td>\n      <td><b>0.842</b></td>\n      <td><b>0.931</b></td>\n      <td><b>0.923</b></td>\n      <td><b>0.604</b></td>\n    </tr>\n    <tr>\n      <th>news_1B_250K_300d_100q</th>\n      <td>navec</td>\n      <td>0.230</td>\n      <td>0.590</td>\n      <td>0.784</td>\n      <td><b>0.866</b></td>\n      <td>0.861</td>\n      <td>0.589</td>\n    </tr>\n  </tbody>\n</table>\n\n<h2>Support</h2>\n<ul>\n<li>Chat \u2014 <a href=\"https://telegram.me/natural_language_processing\" rel=\"nofollow\">https://telegram.me/natural_language_processing</a></li>\n<li>Issues \u2014 <a href=\"https://github.com/natasha/navec/issues\" rel=\"nofollow\">https://github.com/natasha/navec/issues</a></li>\n</ul>\n<h2>Development</h2>\n<p>Test</p>\n<pre>make <span class=\"nb\">test</span>\n</pre>\n<p>Package</p>\n<pre>make version\ngit push\ngit push --tags\n\nmake clean wheel upload\n</pre>\n<p>Notice! All commands belows use code from <code>navec/train</code>, it is not under CI, it works only with Python 3, it is expected user is familiar with source code. We use Yandex Cloud Compute and Object Storage.</p>\n<p>Create remote worker</p>\n<p>To compute cooc (large HDD, 1Tb for librusec).</p>\n<pre>yc compute instance create <span class=\"se\">\\</span>\n    --name worker <span class=\"se\">\\</span>\n    --zone ru-central1-a <span class=\"se\">\\</span>\n    --network-interface subnet-name<span class=\"o\">=</span>default,nat-ip-version<span class=\"o\">=</span>ipv4 <span class=\"se\">\\</span>\n    --create-boot-disk image-folder-id<span class=\"o\">=</span>standard-images,image-family<span class=\"o\">=</span>ubuntu-1804,type<span class=\"o\">=</span>network-hdd,size<span class=\"o\">=</span><span class=\"m\">1000</span> <span class=\"se\">\\</span>\n    --memory <span class=\"m\">8</span> <span class=\"se\">\\</span>\n    --cores <span class=\"m\">1</span> <span class=\"se\">\\</span>\n    --core-fraction <span class=\"m\">100</span> <span class=\"se\">\\</span>\n    --ssh-key ~/.ssh/id_rsa.pub <span class=\"se\">\\</span>\n    --folder-name default <span class=\"se\">\\</span>\n    --preemptible  <span class=\"c1\"># in case computation takes &lt;24h</span>\n</pre>\n<p>To fit embedings (multiple cores). HDD should be &gt; cooc.bin * 3 (for suffle + tmp)</p>\n<pre>yc compute instance create <span class=\"se\">\\</span>\n    --name worker <span class=\"se\">\\</span>\n    --zone ru-central1-a <span class=\"se\">\\</span>\n    --network-interface subnet-name<span class=\"o\">=</span>default,nat-ip-version<span class=\"o\">=</span>ipv4 <span class=\"se\">\\</span>\n    --create-boot-disk image-folder-id<span class=\"o\">=</span>standard-images,image-family<span class=\"o\">=</span>ubuntu-1804,type<span class=\"o\">=</span>network-hdd,size<span class=\"o\">=</span><span class=\"m\">700</span> <span class=\"se\">\\</span>\n    --memory <span class=\"m\">16</span> <span class=\"se\">\\</span>\n    --cores <span class=\"m\">16</span> <span class=\"se\">\\</span>\n    --core-fraction <span class=\"m\">100</span> <span class=\"se\">\\</span>\n    --ssh-key ~/.ssh/id_rsa.pub  <span class=\"se\">\\</span>\n    --folder-name default <span class=\"se\">\\</span>\n    --preemptible\n</pre>\n<p>Setup machine</p>\n<pre>yc compute instance list --folder-name default\nssh yc-user@123.123.123.123\n\nsudo locale-gen en_US.UTF-8\nsudo timedatectl set-timezone Europe/Moscow\nsudo apt-get update\nsudo <span class=\"nv\">DEBIAN_FRONTEND</span><span class=\"o\">=</span>noninteractive apt-get install -y language-pack-ru python3-pip screen unzip git pv cmake\n\nwget https://nlp.stanford.edu/software/GloVe-1.2.zip\nunzip GloVe-1.2.zip\nrm GloVe-1.2.zip\nmv GloVe-1.2 glove\n<span class=\"nb\">cd</span> glove\nmake\n<span class=\"nb\">cd</span> ..\n\n<span class=\"nb\">export</span> <span class=\"nv\">GLOVE_DIR</span><span class=\"o\">=</span>~/glove/build\n\ngit clone https://github.com/natasha/navec.git\nsudo -H pip3 install -e navec\nsudo -H pip3 install -r navec/requirements/train.txt\n\nscreen\nctrl a d\n</pre>\n<p>Remove instance</p>\n<pre>yc compute instance list --folder-name default\nyc compute instance delete xxxxxxxxx\n</pre>\n<p>Env, used by <code>navec-train s3|vocab|cooc|emb</code></p>\n<pre><span class=\"nb\">export</span> <span class=\"nv\">S3_KEY</span><span class=\"o\">=</span>_XxXXXxxx_XXXxxxxXxxx\n<span class=\"nb\">export</span> <span class=\"nv\">S3_SECRET</span><span class=\"o\">=</span>XXxxx_XXXXXXxxxxxxXXXXxxXXx-XxxXXxxxX\n<span class=\"nb\">export</span> <span class=\"nv\">S3_BUCKET</span><span class=\"o\">=</span>XXXXXXX\n<span class=\"nb\">export</span> <span class=\"nv\">GLOVE_DIR</span><span class=\"o\">=</span>~/path/to/glove/build\n</pre>\n<p>Share text data (see corus)</p>\n<pre>navec-train s3 upload librusec_fb2.plain.gz sources/librusec.gz\nnavec-train s3 upload taiga/proza_ru.zip sources/taiga_proza.zip\n\nnavec-train s3 upload ruwiki-latest-pages-articles.xml.bz2 sources/wiki.xml.bz2\n\nnavec-train s3 upload lenta-ru-news.csv.gz sources/lenta.csv.gz\nnavec-train s3 upload ria.json.gz sources/ria.json.gz\nnavec-train s3 upload taiga/Fontanka.tar.gz sources/taiga_fontanka.tar.gz\nnavec-train s3 upload buriy/news-articles-2014.tar.bz2 sources/buriy_news1.tar.bz2\nnavec-train s3 upload buriy/news-articles-2015-part1.tar.bz2 sources/buriy_news2.tar.bz2\nnavec-train s3 upload buriy/news-articles-2015-part2.tar.bz2 sources/buriy_news3.tar.bz2\nnavec-train s3 upload buriy/webhose-2016.tar.bz2 sources/buriy_webhose.tar.bz2\nnavec-train s3 upload ods/gazeta_v1.csv.zip sources/ods_gazeta.csv.zip\nnavec-train s3 upload ods/interfax_v1.csv.zip sources/ods_interfax.csv.zip\n\nnavec-train s3 download sources/librusec.gz\nnavec-train s3 download sources/taiga_proza.zip\n\nnavec-train s3 download sources/wiki.xml.bz2\n\nnavec-train s3 download sources/lenta.csv.gz\nnavec-train s3 download sources/ria.json.gz\nnavec-train s3 download sources/taiga_fontanka.tar.gz\nnavec-train s3 download sources/buriy_news1.tar.bz2\nnavec-train s3 download sources/buriy_news2.tar.bz2\nnavec-train s3 download sources/buriy_news3.tar.bz2\nnavec-train s3 download sources/buriy_webhose.tar.bz2\nnavec-train s3 download sources/ods_gazeta.csv.zip\nnavec-train s3 download sources/ods_interfax.csv.zip\n</pre>\n<p>Text to tokens</p>\n<pre>navec-train corpus librusec librusec.gz <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt; tokens.txt  <span class=\"c1\"># ~12B words</span>\nnavec-train corpus taiga_proza taiga_proza.zip <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt; tokens.txt  <span class=\"c1\"># ~3B</span>\n\nnavec-train corpus wiki wiki.xml.bz2 <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt; tokens.txt  <span class=\"c1\"># ~0.5B</span>\n\nnavec-train corpus lenta lenta.csv.gz <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus ria ria.json.gz <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus taiga_fontanka taiga_fontanka.tar.gz <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus buriy_news buriy_news1.tar.bz2 <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus buriy_news buriy_news2.tar.bz2 <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus buriy_news buriy_news3.tar.bz2 <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus buriy_webhose buriy_webhose.tar.bz2 <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus ods_gazeta ods_gazeta.csv.zip <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt\nnavec-train corpus ods_interfax ods_interfax.csv.zip <span class=\"p\">|</span> pv <span class=\"p\">|</span> navec-train tokenize &gt;&gt; tokens.txt  <span class=\"c1\"># ~1B</span>\n\npv tokens.txt <span class=\"p\">|</span> gzip &gt; tokens.txt.gz\nnavec-train s3 upload tokens.txt.gz librusec_tokens.txt.gz\n\nnavec-train s3 upload tokens.txt taiga_proza_tokens.txt\nnavec-train s3 upload tokens.txt news_tokens.txt\nnavec-train s3 upload tokens.txt wiki_tokens.txt\n</pre>\n<p>Tokens to vocab</p>\n<pre>pv tokens.txt <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> navec-train vocab count <span class=\"se\">\\</span>\n\t&gt; full_vocab.txt\n\npv full_vocab.txt <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> navec-train vocab quantile\n\n<span class=\"c1\"># librusec</span>\n<span class=\"c1\"># ...</span>\n<span class=\"c1\"># 0.970      325 882</span>\n<span class=\"c1\"># 0.980      511 542</span>\n<span class=\"c1\"># 0.990    1 122 624</span>\n<span class=\"c1\"># 1.000   22 129 654</span>\n\n<span class=\"c1\"># taiga_proza</span>\n<span class=\"c1\"># ...</span>\n<span class=\"c1\"># 0.960      229 906</span>\n<span class=\"c1\"># 0.970      321 810</span>\n<span class=\"c1\"># 0.980      517 647</span>\n<span class=\"c1\"># 0.990    1 224 277</span>\n<span class=\"c1\"># 1.000   14 302 409</span>\n\n<span class=\"c1\"># wiki</span>\n<span class=\"c1\"># ...</span>\n<span class=\"c1\"># 0.950     380 134</span>\n<span class=\"c1\"># 0.960     519 817</span>\n<span class=\"c1\"># 0.970     757 561</span>\n<span class=\"c1\"># 0.980   1 223 201</span>\n<span class=\"c1\"># 0.990   2 422 265</span>\n<span class=\"c1\"># 1.000   6 664 630</span>\n\n<span class=\"c1\"># news</span>\n<span class=\"c1\"># ...</span>\n<span class=\"c1\"># 0.970    163 833</span>\n<span class=\"c1\"># 0.980    243 903</span>\n<span class=\"c1\"># 0.990    462 361</span>\n<span class=\"c1\"># 1.000  3 744 070</span>\n\n<span class=\"c1\"># threashold at ~0.98</span>\n<span class=\"c1\"># librusec 500000</span>\n<span class=\"c1\"># taiga_proza 500000</span>\n<span class=\"c1\"># wiki 750000</span>\n<span class=\"c1\"># news 250000</span>\n\ncat full_vocab.txt <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> head -500000 <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> <span class=\"nv\">LC_ALL</span><span class=\"o\">=</span>C sort <span class=\"se\">\\</span>\n\t&gt; vocab.txt\n\nnavec-train s3 upload full_vocab.txt librusec_full_vocab.txt\nnavec-train s3 upload vocab.txt librusec_vocab.txt\n\nnavec-train s3 upload full_vocab.txt taiga_proza_full_vocab.txt\nnavec-train s3 upload vocab.txt taiga_proza_vocab.txt\n\nnavec-train s3 upload full_vocab.txt wiki_full_vocab.txt\nnavec-train s3 upload vocab.txt wiki_vocab.txt\n\nnavec-train s3 upload full_vocab.txt news_full_vocab.txt\nnavec-train s3 upload vocab.txt news_vocab.txt\n</pre>\n<p>Compute coocurence pairs</p>\n<pre><span class=\"c1\"># Default limit on max number of open files is 1024, merge fails if</span>\n<span class=\"c1\"># number of chunks is large</span>\n\n<span class=\"nb\">ulimit</span> -n  <span class=\"c1\"># 1024</span>\nsudo nano /etc/security/limits.conf\n\n* soft     nofile         <span class=\"m\">65535</span>\n* hard     nofile         <span class=\"m\">65535</span>\n\n<span class=\"c1\"># relogin</span>\n<span class=\"nb\">ulimit</span> -n  <span class=\"c1\"># 65535</span>\n\npv tokens.txt <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> navec-train cooc count vocab.txt --memory <span class=\"m\">7</span> --window <span class=\"m\">10</span> <span class=\"se\">\\</span>\n\t&gt; cooc.bin\n\n<span class=\"c1\"># Monitor</span>\nls /tmp/cooc_*\ntail -c <span class=\"m\">16</span> cooc.bin <span class=\"p\">|</span> navec-train cooc parse\n\nnavec-train s3 upload cooc.bin librusec_cooc.bin\nnavec-train s3 upload cooc.bin taiga_proza_cooc.bin\nnavec-train s3 upload cooc.bin wiki_cooc.bin\nnavec-train s3 upload cooc.bin news_cooc.bin\n</pre>\n<p>Merge (did not give much boost compared to plain librusec, so all_vocab.txt, all_cooc.bin not used below)</p>\n<pre><span class=\"k\">for</span> i in librusec taiga_proza wiki news<span class=\"p\">;</span> <span class=\"k\">do</span>\n\tnavec-train s3 download <span class=\"nv\">$i_vocab</span>.txt<span class=\"p\">;</span>\n\tnavec-train s3 download <span class=\"nv\">$i_cooc</span>.bin<span class=\"p\">;</span>\n<span class=\"k\">done</span>\n\nnavec-train merge vocabs <span class=\"se\">\\</span>\n\tlibrusec_vocab.txt <span class=\"se\">\\</span>\n\ttaiga_proza_vocab.txt <span class=\"se\">\\</span>\n\twiki_vocab.txt <span class=\"se\">\\</span>\n\tnews_vocab.txt <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> pv &gt; vocab.txt\n\nnavec-train merge coocs vocab.txt <span class=\"se\">\\</span>\n\tlibrusec_cooc.bin:librusec_vocab.txt <span class=\"se\">\\</span>\n\ttaiga_proza_cooc.bin:taiga_proza_vocab.txt <span class=\"se\">\\</span>\n\twiki_cooc.bin:wiki_vocab.txt <span class=\"se\">\\</span>\n\tnews_cooc.bin:news_vocab.txt <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> pv &gt; cooc.bin\n\nnavec-train s3 upload vocab.txt all_vocab.txt\nnavec-train s3 upload cooc.bin all_cooc.bin\n</pre>\n<p>Compute embedings</p>\n<pre>navec-train s3 download librusec_vocab.txt vocab.txt\nnavec-train s3 download librusec_cooc.bin cooc.bin\n\nnavec-train s3 download wiki_vocab.txt vocab.txt\nnavec-train s3 download wiki_cooc.bin cooc.bin\n\nnavec-train s3 download news_vocab.txt vocab.txt\nnavec-train s3 download news_cooc.bin cooc.bin\n\npv cooc.bin <span class=\"se\">\\</span>\n\t<span class=\"p\">|</span> navec-train cooc shuffle --memory <span class=\"m\">15</span> <span class=\"se\">\\</span>\n\t&gt; shuf_cooc.bin\n\n<span class=\"c1\"># Search dim with best score</span>\n<span class=\"k\">for</span> i in <span class=\"m\">100</span> <span class=\"m\">200</span> <span class=\"m\">300</span> <span class=\"m\">400</span> <span class=\"m\">500</span> <span class=\"m\">600</span><span class=\"p\">;</span>\n\t<span class=\"k\">do</span> navec-train emb shuf_cooc.bin vocab.txt emb_<span class=\"si\">${</span><span class=\"nv\">i</span><span class=\"si\">}</span>d.txt --dim <span class=\"nv\">$i</span> --threads <span class=\"m\">10</span> --iterations <span class=\"m\">2</span><span class=\"p\">;</span>\n<span class=\"k\">done</span>\n\n<span class=\"c1\"># 300 has ok score. 400, 500 are a bit better, but too heavy</span>\nnavec-train emb shuf_cooc.bin vocab.txt emb.txt --dim <span class=\"m\">300</span> --threads <span class=\"m\">16</span> --iterations <span class=\"m\">15</span>\n\nnavec-train s3 upload emb.txt librusec_emb.txt\nnavec-train s3 upload emb.txt wiki_emb.txt\nnavec-train s3 upload emb.txt news_emb.txt\n</pre>\n<p>Quantize</p>\n<pre>navec-train s3 download librusec_emb.txt emb.txt\nnavec-train s3 download wiki_emb.txt emb.txt\nnavec-train s3 download news_emb.txt emb.txt\n\n<span class=\"c1\"># Search for best compression that has still ok score</span>\n<span class=\"k\">for</span> i in <span class=\"m\">150</span> <span class=\"m\">100</span> <span class=\"m\">75</span> <span class=\"m\">60</span> <span class=\"m\">50</span><span class=\"p\">;</span>\n\t<span class=\"k\">do</span> pv emb.txt <span class=\"p\">|</span> navec-train pq fit <span class=\"nv\">$i</span> --sample <span class=\"m\">100000</span> --iterations <span class=\"m\">15</span> &gt; pq_<span class=\"si\">${</span><span class=\"nv\">i</span><span class=\"si\">}</span>q.bin<span class=\"p\">;</span>\n<span class=\"k\">done</span>\n\n<span class=\"c1\"># 100 is &lt;1% worse on eval but much lighter</span>\npv emb.txt <span class=\"p\">|</span> navec-train pq fit <span class=\"m\">100</span> --sample <span class=\"m\">100000</span> --iterations <span class=\"m\">20</span> &gt; pq.bin\n\nnavec-train pq pad &lt; pq.bin &gt; t<span class=\"p\">;</span> mv t pq.bin\n\nnavec-train s3 upload pq.bin librusec_pq.bin\nnavec-train s3 upload pq.bin wiki_pq.bin\nnavec-train s3 upload pq.bin news_pq.bin\n</pre>\n<p>Pack</p>\n<pre><code>navec-train s3 download librusec_pq.bin pq.bin\nnavec-train s3 download librusec_vocab.txt vocab.txt\n\nnavec-train s3 download news_pq.bin pq.bin\nnavec-train s3 download news_vocab.txt vocab.txt\n\nnavec-train vocab pack &lt; vocab.txt &gt; vocab.bin\n\nnavec-train pack vocab.bin pq.bin hudlit_v1_12B_500K_300d_100q\nnavec-train s3 upload navec_hudlit_v1_12B_500K_300d_100q.tar packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n\nnavec-train pack vocab.bin pq.bin news_v1_1B_250K_300d_100q\nnavec-train s3 upload navec_news_v1_1B_250K_300d_100q.tar packs/navec_news_v1_1B_250K_300d_100q.tar\n</code></pre>\n<p>Publish</p>\n<pre><code>navec-train s3 download packs/navec_hudlit_v1_12B_500K_300d_100q.tar\nnavec-train s3 download packs/navec_news_v1_1B_250K_300d_100q.tar\n</code></pre>\n\n          </div>"}, "last_serial": 6976504, "releases": {"0.2.0": [{"comment_text": "", "digests": {"md5": "5096ae92b44ec0ffd4609223cb8c22f6", "sha256": "13ef64bbbc6a3c5d8551165968005ddc89a0eb9c8d630d95d15b0464d4046a09"}, "downloads": -1, "filename": "navec-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "5096ae92b44ec0ffd4609223cb8c22f6", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 15875, "upload_time": "2019-05-30T14:29:33", "upload_time_iso_8601": "2019-05-30T14:29:33.281110Z", "url": "https://files.pythonhosted.org/packages/73/60/5849a854794b3e15efd8a73c231f0f85028823b6836a3b42cf1b2f643a82/navec-0.2.0-py2.py3-none-any.whl", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "abeaa3beb0babb432652f5ac0e8bd40f", "sha256": "c9e3ae23e0dc65624c5e6be9f64ae3f858eb6d56276f416f40c9196cb080581d"}, "downloads": -1, "filename": "navec-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "abeaa3beb0babb432652f5ac0e8bd40f", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 17011, "upload_time": "2019-06-16T11:53:05", "upload_time_iso_8601": "2019-06-16T11:53:05.394764Z", "url": "https://files.pythonhosted.org/packages/c9/c3/294cf334912018cdd706a2061f923debee0c0fbee5b3afd1635ddab2ff46/navec-0.3.0-py2.py3-none-any.whl", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "9b26b447fbfd93e61d5498f566192317", "sha256": "a3af37fa82c27d0551dad283182fbc309b182012e1b4c3af54ac3249b9e7ea1a"}, "downloads": -1, "filename": "navec-0.4.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9b26b447fbfd93e61d5498f566192317", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 16966, "upload_time": "2019-06-18T03:39:51", "upload_time_iso_8601": "2019-06-18T03:39:51.421871Z", "url": "https://files.pythonhosted.org/packages/72/ab/a8e28045d766a8139ee92592fe9eb82f06dab277509c4e3e8e968ea44d52/navec-0.4.0-py2.py3-none-any.whl", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "7f97eba477ac42d9ffddb7091d9bbdf4", "sha256": "1fe5ae65b116197df4f873739f98ccdb9070f0958d70456ba42c147760e1e00a"}, "downloads": -1, "filename": "navec-0.5.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7f97eba477ac42d9ffddb7091d9bbdf4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 16878, "upload_time": "2019-06-18T05:11:19", "upload_time_iso_8601": "2019-06-18T05:11:19.673409Z", "url": "https://files.pythonhosted.org/packages/ca/d0/59872e8481738590ad3e9e30a35725e5e7f5f3610e5263aa38ea195a066c/navec-0.5.0-py2.py3-none-any.whl", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "fa33e6e0986b90cf0cc472d0d7650654", "sha256": "0eefbc373c60101a6d6a1c6d62472987935e5f5504fa9e75cd275bfca23bcf52"}, "downloads": -1, "filename": "navec-0.6.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fa33e6e0986b90cf0cc472d0d7650654", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22474, "upload_time": "2019-07-06T07:58:35", "upload_time_iso_8601": "2019-07-06T07:58:35.129772Z", "url": "https://files.pythonhosted.org/packages/87/b9/a126a91b80eea7e203534ad98a3f70c304b259cc5f63a335be478ca218c9/navec-0.6.0-py2.py3-none-any.whl", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "ae571838f84365eb2b03d3f0468a6995", "sha256": "35669fff6a38ffccaebcce0012e49f9b5bd7833bd8073553942c8855bd2a0f74"}, "downloads": -1, "filename": "navec-0.7.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ae571838f84365eb2b03d3f0468a6995", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22053, "upload_time": "2019-08-28T11:38:15", "upload_time_iso_8601": "2019-08-28T11:38:15.735325Z", "url": "https://files.pythonhosted.org/packages/1b/9f/206177deb68b1dab082725592f7f39283104f5aa89ad8ba56ea683e261cb/navec-0.7.0-py2.py3-none-any.whl", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "9db01a2bf3b4d2f9e41e25ee016ced0d", "sha256": "03a550db424e651506445419ed185e229b29c2a90981f35dc76d0ebbc024161e"}, "downloads": -1, "filename": "navec-0.8.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9db01a2bf3b4d2f9e41e25ee016ced0d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22789, "upload_time": "2020-03-26T04:40:20", "upload_time_iso_8601": "2020-03-26T04:40:20.340463Z", "url": "https://files.pythonhosted.org/packages/3b/c2/afaad8a682aa3d5cac9b383e368f163ddb4da66e8141e366e9cdd63b0568/navec-0.8.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "8395300275e54fb4172b968c8e2fc9bc", "sha256": "24e5731f975c2507739d16956b3886ae51aad35bc473478f7f5eb4bc09753569"}, "downloads": -1, "filename": "navec-0.8.0.tar.gz", "has_sig": false, "md5_digest": "8395300275e54fb4172b968c8e2fc9bc", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18615, "upload_time": "2020-03-26T04:40:22", "upload_time_iso_8601": "2020-03-26T04:40:22.067527Z", "url": "https://files.pythonhosted.org/packages/f1/0b/9f2995a0e52beb739a2170cf82be85742a13df06669f6f02d10ca94c6f78/navec-0.8.0.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "9430c750b05b3b996e8fec19ee7e3acc", "sha256": "c596f44a929c607116b670f8550ae05b06f805fb13550825e0487c4d58f41f03"}, "downloads": -1, "filename": "navec-0.9.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9430c750b05b3b996e8fec19ee7e3acc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23008, "upload_time": "2020-04-08T09:59:12", "upload_time_iso_8601": "2020-04-08T09:59:12.880287Z", "url": "https://files.pythonhosted.org/packages/83/ad/554945ebee66fe83fefd61e043938981dd9e6136882025c506ac6faa6a4c/navec-0.9.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "baf3772cf2f3c1a0fdf2c2fd9b5813f9", "sha256": "a7c75ba1d29281ae4481567e699cd5a3dc18005417d182ef8d51a5516355fa52"}, "downloads": -1, "filename": "navec-0.9.0.tar.gz", "has_sig": false, "md5_digest": "baf3772cf2f3c1a0fdf2c2fd9b5813f9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18869, "upload_time": "2020-04-08T09:59:14", "upload_time_iso_8601": "2020-04-08T09:59:14.848532Z", "url": "https://files.pythonhosted.org/packages/d2/7c/4c593fb58642af4e016e6564b477a8acfc34dc3e561c6abb9874db5e6823/navec-0.9.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9430c750b05b3b996e8fec19ee7e3acc", "sha256": "c596f44a929c607116b670f8550ae05b06f805fb13550825e0487c4d58f41f03"}, "downloads": -1, "filename": "navec-0.9.0-py3-none-any.whl", "has_sig": false, "md5_digest": "9430c750b05b3b996e8fec19ee7e3acc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23008, "upload_time": "2020-04-08T09:59:12", "upload_time_iso_8601": "2020-04-08T09:59:12.880287Z", "url": "https://files.pythonhosted.org/packages/83/ad/554945ebee66fe83fefd61e043938981dd9e6136882025c506ac6faa6a4c/navec-0.9.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "baf3772cf2f3c1a0fdf2c2fd9b5813f9", "sha256": "a7c75ba1d29281ae4481567e699cd5a3dc18005417d182ef8d51a5516355fa52"}, "downloads": -1, "filename": "navec-0.9.0.tar.gz", "has_sig": false, "md5_digest": "baf3772cf2f3c1a0fdf2c2fd9b5813f9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 18869, "upload_time": "2020-04-08T09:59:14", "upload_time_iso_8601": "2020-04-08T09:59:14.848532Z", "url": "https://files.pythonhosted.org/packages/d2/7c/4c593fb58642af4e016e6564b477a8acfc34dc3e561c6abb9874db5e6823/navec-0.9.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:47:13 2020"}