{"info": {"author": "James Brown", "author_email": "jbrown@uber.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Environment :: Web Environment", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Topic :: System :: Monitoring"], "description": "[![Build Status](https://travis-ci.org/uber/hacheck.png)](https://travis-ci.org/uber/hacheck)\n\n**hacheck** is a healthcheck-proxying service. It listens on port 3333, speaks HTTP, and has the following API:\n\n    GET /<protocol>/<service_name>/<port>/<query>\n\nThis will check the following locations for service state:\n\n * `/var/spool/hacheck/all`\n * `/var/spool/hacheck/<service_name>`\n * Depending on the value of `<protocol>`:\n  * if `http`: `http://localhost:<port>/<query>`\n  * if `tcp`: will attempt to connect to port `<port>` on localhost. `<query>` is currently ignored\n  * if `spool`: will only check the spool state\n  * if `mysql` and the `mysql_username` and `mysql_password` are set, will do a login and quit on the requested mysql port; `<query>` is ignored and no logical database is selected.\n\nWhen it does query the actual service check endpoint, **hacheck** MAY cache the value of that query for some amount of time\n\n**hacheck** also comes with the command-line utilities `haup`, `hadown`, and `hastatus`. These take a service name and manipulate the spool files, allowing you to pre-emptively mark a service as \"up\" or \"down\".\n\n### Dependencies\n\n**hacheck** is written in Python and makes extensive use of the [tornado](http://www.tornadoweb.org/en/stable/) asynchronous web framework (specifically, it uses the coroutine stuff in Tornado 3). Unit tests use nose and mock.\n\nIt runs on Python 2.6 and above, as well as Python 3.2 and above.\n\n### Use cases\n\nImagine you want to take down the server `web01` for maintenance. Just SSH to it, then (as root) run `hadown all` and wait however long your HAproxy healthchecking interval is. Do your maintenance, then run `haup all` to put it back in service. So easy!\n\n### Configuration\n\n`hacheck` accepts a `-c` flag which should point to a YAML-formatted configuration file. Some notable properties of this file:\n* `cache_time`: The duration for which check results may be cached\n* `service_name_header`: If set, the name of a header which will be populated with the service name on HTTP checks\n* `log_path`: Either the string `\"stdout\"`, the string `\"stderr\"`, or a fully-qualified path to a file to write logs to. Uses a [WatchedFileHandler](http://docs.python.org/2/library/logging.handlers.html#watchedfilehandler) and ought to play nicely with logrotate\n* `mysql_username`: username to use when logging into mysql for checks\n* `mysql_password`: password to use when logging into mysql for checks\n* `rlimit_nofile`: set the NOFILE rlimit. If the string \"max\", will set the rlimit to the hard rlimit; otherwise, will be interpreted as an integer and set to that value.\n\n### Monitoring\n\n`hacheck` exports some useful monitoring stuff at the `/status` endpoint.\n\nIf the [mutornadomon](https://github.com/uber/mutornadomon) package is available, `hacheck` will import and use it, exposing standard stats about tornado to localhost at `/mutornadomon`\n\n### License\n\nThis work is licensed under the [MIT License](http://opensource.org/licenses/MIT), the contents of which can be found at [LICENSE.txt](LICENSE.txt).\n", "description_content_type": null, "docs_url": null, "download_url": "UNKNOWN", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/uber/hacheck", "keywords": "monitoring,load-balancing,networking", "license": "MIT", "maintainer": null, "maintainer_email": null, "name": "hacheck", "package_url": "https://pypi.org/project/hacheck/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/hacheck/", "project_urls": {"Download": "UNKNOWN", "Homepage": "https://github.com/uber/hacheck"}, "release_url": "https://pypi.org/project/hacheck/0.7.0/", "requires_dist": null, "requires_python": null, "summary": "HAProxy health-check proxying service", "version": "0.7.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            [![Build Status](https://travis-ci.org/uber/hacheck.png)](https://travis-ci.org/uber/hacheck)<br><br>**hacheck** is a healthcheck-proxying service. It listens on port 3333, speaks HTTP, and has the following API:<br><br>    GET /&lt;protocol&gt;/&lt;service_name&gt;/&lt;port&gt;/&lt;query&gt;<br><br>This will check the following locations for service state:<br><br> * `/var/spool/hacheck/all`<br> * `/var/spool/hacheck/&lt;service_name&gt;`<br> * Depending on the value of `&lt;protocol&gt;`:<br>  * if `http`: `http://localhost:&lt;port&gt;/&lt;query&gt;`<br>  * if `tcp`: will attempt to connect to port `&lt;port&gt;` on localhost. `&lt;query&gt;` is currently ignored<br>  * if `spool`: will only check the spool state<br>  * if `mysql` and the `mysql_username` and `mysql_password` are set, will do a login and quit on the requested mysql port; `&lt;query&gt;` is ignored and no logical database is selected.<br><br>When it does query the actual service check endpoint, **hacheck** MAY cache the value of that query for some amount of time<br><br>**hacheck** also comes with the command-line utilities `haup`, `hadown`, and `hastatus`. These take a service name and manipulate the spool files, allowing you to pre-emptively mark a service as \"up\" or \"down\".<br><br>### Dependencies<br><br>**hacheck** is written in Python and makes extensive use of the [tornado](http://www.tornadoweb.org/en/stable/) asynchronous web framework (specifically, it uses the coroutine stuff in Tornado 3). Unit tests use nose and mock.<br><br>It runs on Python 2.6 and above, as well as Python 3.2 and above.<br><br>### Use cases<br><br>Imagine you want to take down the server `web01` for maintenance. Just SSH to it, then (as root) run `hadown all` and wait however long your HAproxy healthchecking interval is. Do your maintenance, then run `haup all` to put it back in service. So easy!<br><br>### Configuration<br><br>`hacheck` accepts a `-c` flag which should point to a YAML-formatted configuration file. Some notable properties of this file:<br>* `cache_time`: The duration for which check results may be cached<br>* `service_name_header`: If set, the name of a header which will be populated with the service name on HTTP checks<br>* `log_path`: Either the string `\"stdout\"`, the string `\"stderr\"`, or a fully-qualified path to a file to write logs to. Uses a [WatchedFileHandler](http://docs.python.org/2/library/logging.handlers.html#watchedfilehandler) and ought to play nicely with logrotate<br>* `mysql_username`: username to use when logging into mysql for checks<br>* `mysql_password`: password to use when logging into mysql for checks<br>* `rlimit_nofile`: set the NOFILE rlimit. If the string \"max\", will set the rlimit to the hard rlimit; otherwise, will be interpreted as an integer and set to that value.<br><br>### Monitoring<br><br>`hacheck` exports some useful monitoring stuff at the `/status` endpoint.<br><br>If the [mutornadomon](https://github.com/uber/mutornadomon) package is available, `hacheck` will import and use it, exposing standard stats about tornado to localhost at `/mutornadomon`<br><br>### License<br><br>This work is licensed under the [MIT License](http://opensource.org/licenses/MIT), the contents of which can be found at [LICENSE.txt](LICENSE.txt).<br>\n          </div>"}, "last_serial": 1391054, "releases": {"0.3": [{"comment_text": "", "digests": {"md5": "80eefd3239294b6aa435282e722d5d9c", "sha256": "dbbe4ce5d8b7d58dee87e2af9f16b70d706cb66e2366ede94e98f32e83ca3352"}, "downloads": -1, "filename": "hacheck-0.3.tar.gz", "has_sig": false, "md5_digest": "80eefd3239294b6aa435282e722d5d9c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5052, "upload_time": "2013-06-19T22:54:42", "upload_time_iso_8601": "2013-06-19T22:54:42.397895Z", "url": "https://files.pythonhosted.org/packages/ef/d0/299e159d56c1c54d6e833a6c9f2758677c68fb299f333146b3fa8c4f591f/hacheck-0.3.tar.gz", "yanked": false}], "0.3.1": [{"comment_text": "", "digests": {"md5": "afdd69f1f51a2cf1563e0829575ed03c", "sha256": "e7122ee19fa5339d4bea2e0aaf5c4fabbd69419a88b7b2ec43807778f8283c22"}, "downloads": -1, "filename": "hacheck-0.3.1.tar.gz", "has_sig": false, "md5_digest": "afdd69f1f51a2cf1563e0829575ed03c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5107, "upload_time": "2013-07-10T03:02:16", "upload_time_iso_8601": "2013-07-10T03:02:16.167748Z", "url": "https://files.pythonhosted.org/packages/5c/90/d851141dee05c700ea97deb2dd89b42c982e40de42468e855dd15fdbd9e1/hacheck-0.3.1.tar.gz", "yanked": false}], "0.3.2": [{"comment_text": "", "digests": {"md5": "9262a2a04db9c31ed439a65f073aae9f", "sha256": "9580b02ce6e722d6fc6bc646f8a9c2fae1f1bfbd4af0fe435f9bcf1494fdd981"}, "downloads": -1, "filename": "hacheck-0.3.2.tar.gz", "has_sig": false, "md5_digest": "9262a2a04db9c31ed439a65f073aae9f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6775, "upload_time": "2013-07-10T20:04:10", "upload_time_iso_8601": "2013-07-10T20:04:10.351884Z", "url": "https://files.pythonhosted.org/packages/98/30/14de3928399060e2ccb83ee037a53e0c81997c55bed9d26e3d98ed985335/hacheck-0.3.2.tar.gz", "yanked": false}], "0.3.3": [{"comment_text": "", "digests": {"md5": "46213daa091412f51c9954db308e161b", "sha256": "ec96b8fb72891599bc7d447a01bebf6af2fb931a050b0dbf8f8e06c7498f2394"}, "downloads": -1, "filename": "hacheck-0.3.3.tar.gz", "has_sig": true, "md5_digest": "46213daa091412f51c9954db308e161b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7595, "upload_time": "2013-09-17T22:25:21", "upload_time_iso_8601": "2013-09-17T22:25:21.134402Z", "url": "https://files.pythonhosted.org/packages/3a/90/1680f64e5d501e063e611941903ba2a914e3324b09f0fbbd479bb69e542c/hacheck-0.3.3.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "92c1261e32d62999069118680d92d89f", "sha256": "7c1543e0cc38aca1d23b12063e50396cc7befaaa88151adea0ae24b00d4d9cc4"}, "downloads": -1, "filename": "hacheck-0.4.1.tar.gz", "has_sig": true, "md5_digest": "92c1261e32d62999069118680d92d89f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8053, "upload_time": "2013-10-18T22:05:39", "upload_time_iso_8601": "2013-10-18T22:05:39.134995Z", "url": "https://files.pythonhosted.org/packages/23/26/e95eba304ea82b6f01ce122ebc8f4ef71c0f5f8726ff1c750c9ebbe10f51/hacheck-0.4.1.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "82b046dab0ed06d3d1145d7741ae3700", "sha256": "d284536518951cc818d6100417ae498b2fbeb8940ced90a18d00a5895dc59f93"}, "downloads": -1, "filename": "hacheck-0.7.0.tar.gz", "has_sig": false, "md5_digest": "82b046dab0ed06d3d1145d7741ae3700", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12387, "upload_time": "2015-01-21T21:01:39", "upload_time_iso_8601": "2015-01-21T21:01:39.450359Z", "url": "https://files.pythonhosted.org/packages/8b/38/742834bddf9100b8e1fdba7fc4df9de0be85081e94bcc1de2f9ce0582cae/hacheck-0.7.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "82b046dab0ed06d3d1145d7741ae3700", "sha256": "d284536518951cc818d6100417ae498b2fbeb8940ced90a18d00a5895dc59f93"}, "downloads": -1, "filename": "hacheck-0.7.0.tar.gz", "has_sig": false, "md5_digest": "82b046dab0ed06d3d1145d7741ae3700", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12387, "upload_time": "2015-01-21T21:01:39", "upload_time_iso_8601": "2015-01-21T21:01:39.450359Z", "url": "https://files.pythonhosted.org/packages/8b/38/742834bddf9100b8e1fdba7fc4df9de0be85081e94bcc1de2f9ce0582cae/hacheck-0.7.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:52:51 2020"}