{"info": {"author": "Eran Barash", "author_email": "barashe@post.bgu.ac.il", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: POSIX :: Linux", "Programming Language :: Python :: 2"], "description": "bacpacs version 0.1.1<br>User's guide\n==============================\n\nOverview\n--------\n\nbacpacs is a bacterial pathogenicity classification python module, based on the following paper: \"BacPaCS \u2013 Bacterial Pathogenicity Classification via Sparse-SVM\", by Eran Barash, Neta Sal-Man, Sivan Sabato, and Michal Ziv-Ukelson (Submitted). It can be used for classification using a pre-trained model, or for generating a new model from labeled training data of sequenced proteomes. The training pipeline:\n\n1. bacpacs selects the 10% longest protein out of the set of all proteins from all training samples.\n\n2. Using CD-HIT, bacpacs clusters the selected proteins. This results in\n   clusters, or protein families (PFs). Each PF is represented by its\n   longest protein.\n\n3. For each organism in the training set, bacpacs compares the\n   organism's proteins to the representatives of the PFs, using CD-HIT-2D.\n   This results in a binary feature vector for each organism. The\n   vector indices represent the different PFs.\n   If a cell with index _i_ has a value `True`, the organism has a protein\n   similar to the representative of PF _i_. Otherwise, the cell's value is `False`.\n\n4. The binary feature vectors of the organisms in the training set (and their known\n   pathogenicity labels), can then be used to train a linear SVM model (using l1\n   norm as penalty). Other models can be trained as well. \n\n\nInstallation and dependencies\n-----------------------------\n\nBacpacs can be installed via one of the following three alternatives:\n1. Run in a linux terminal: `$ pip install bacpacs` (recommended)\n2. Clone or download bacpacs Github [repository](https://github.com/barashe/bacpacs.git) and run `pip install -e path/to/bacpacs`\n3. Clone or download bacpacs Github [repository](https://github.com/barashe/bacpacs.git) and use the command line interface described below. \n\nDependencies:\n\n-   Operating system: Linux. CD-HIT only runs on Linux OS, and so does bacpacs.\n-   CD-HIT: bacpacs requires CD-HIT to be installed. It is also recommended to add CD-HIT to the PATH variable. CD-HIT can be downloaded from its official [website](http://weizhongli-lab.org/cd-hit/).\n\n-   Python 2.7.\n\n-   Python packages: numpy, scipy, scikit-learn, and biopython. If\n    you are missing a package, you can simply install the package using\n    [pip](https://pypi.python.org/pypi/pip/) or\n    [EasyInstall](https://wiki.python.org/moin/EasyInstall).\n\n\nRunning bacpacs as a python module\n-------\nBelow are detailed running examples of the two possible bacpacs schemes:\n1. Predicting data using bacpacs pre-trained model: bacpacs comes with a pre-trained model, used in the bacpacs paper. The pre-trained model can be easily downloaded and used.\n2. Training and using a model: bacpacs can also be used to translate a training set of organisms into a feature vector that can be fed into an SVM training module, and to then translate a test set into a feature vector which uses the same features as the training set. The pathogenicity of the organisms in the test set can then be predicted using the trained model. The organisms in both the training set and the test set are fed as raw amino acid fasta files (faa files).\n3. Trainig a model for prediction using the command line interface.\n4. Using bacpacs trained model for prediction via the command line interface.\n\nThe example code below should be used in Python 2.7. Full documentation of each of the methods appears in the code. This example code can be found in [examples](https://github.com/barashe/bacpacs/tree/master/examples).\n\n\n\n## 1. Predicting data using bacpacs pre-trained model\n\n### Imports\n\nIn[1]\n```python\nimport bacpacs\nfrom sklearn.svm import LinearSVC\n```\n\nThe bacpacs pre-trained model can be found in https://github.com/barashe/bacpacs/tree/master/trained. It can also be downloaded and loaded directly from Python as described below.\n\n### Load the pre-trained model\n\nIn[2]\n```python\nbp, clf = bacpacs.load_trained_model(output_dir='out1')\n```\nOut[2]\n\n    Retrieving files from github\n    Downloading full_bacpacs.pkl\n    Downloading linearsvc_full.pkl\n    Downloading protein_families\n\n\nload_trained_model() returns a Bacpacs object, and a sklearn.svm.LinearSVC trained classifier. We will need bp for feature extraction, and clf for the prediction itself. \nHere 'bacpacs' is an empty folder, and 'out1' is created when invoking load_trained_model(). These names can be set according to preference. An existing output_dir is acceptable as well, but beware of file overrun. \n\n### Download toy data\nUse your real data, or download bacpacs toy data (also available on [Github](https://github.com/barashe/bacpacs/blob/master/toy.tar.gz)):\n\nIn[3]\n```python\nbacpacs.download_toy_data('.')\n```\nOut[3]\n\n    Toy data stored in ./toy\n\nYou can move genomes from toy/train to toy/validate and vice versa, or even delete some. The destination folder can be set by replacing '.' with the desired destination.\n\n### Extract features for test organisms\nThis step takes a while, depending on your machine:\n\nIn[4]\n```python\nbp.genomes_vs_pfs('toy/validate', n_jobs=0)\n```\nOut[4]\n\n    Running genomes against protein families representatives\n    Genome cluster files are stored in out1/pred_clusters\n\n\ngenomes_vs_pfs() uses CD-HIT-2D to run all test genomes against the pre-established protein families. Assigning n_jobs=0 tells CD-HIT-2D to use all available CPUs for each genome. However, the genomes are processed sequentially. Running genomes_vs_pfs() on several machines can save plenty of time. \n<br><br>Next, extract the features and store them in variables:\n\nIn[5]\n\n```python\nX_pred = bp.extract_features(feats_type='pred')\n```\n\n### Read pathogenicity labels from a csv file\nbacpacs.read_labels() takes a csv file with two columns and no headers: the first column should list genome ids, and the second column should list pathogenicity labels. Genome ids should match the original genome file names. For example: for a genome file named org1.faa, the csv file should list an 'org1' genome id. Pathogenicity should be boolean: True for pathogens, False for non-pathogens. Note that we include the corresponding feature matrix (X_pred), to ensure that the order of the returned labels corresponds to the order of the genomes in the feature matrix.\n\nIn[6]\n```python\ny_true = bacpacs.read_labels('toy/labels.csv', X=X_pred)\n```\n### Predict pathogenicity\n\nIn[7]\n```python\ny_pred = clf.predict(X_pred)\n```\nCompute accuracy:\n\nIn[8]\n```python\n(y_pred == y_true).mean()\n```\n\nOut[8]\n\n\n    0.80000000000000004\n\n\n\nOr simply:\n\nIn[9]\n\n```python\nclf.score(X_pred, y_true)\n```\nOut[9]\n\n\n\n    0.80000000000000004\n\n\n\n## 2. Training and using a model\n\n### Imports\n\nIn[1]\n```python\nimport bacpacs\nfrom sklearn.svm import LinearSVC\n```\n\n### Download toy data\nUse your real data, or download the bacpacs toy data (also available on [Github](https://github.com/barashe/bacpacs/blob/master/toy.tar.gz)):\n\n\nIn[2]\n```python\nbacpacs.download_toy_data('.')\n```\nOut[2]\n\n    Toy data stored in ./toy\n\n\n### Initialize a Bacpacs object\n\nIn[3]\n```python\nbp = bacpacs.Bacpacs('out2')\n```\n\n### Merge training data\n\nMerge all training .faa files into one large .faa file.\n\nIn[4]\n```python\nbp.merge_genome_files('toy/train/', output_path=None)\n```\nSpecify an output path to override the default destination directory.\n\nOut[4]\n\n    Saving merged proteins as out/merged.faa\n\n\nNote that it is possible to specify a different output path.\n\n### Reduce the merged file to the 10% longest proteins\n\nIn[5]\n```python\nbp.reduce(long_percent=10, merged_path=None, output_path=None)\n```\n\nOut[5]\n\n    Saving reduced proteins as out/reduced.faa\n\nlong_percent can be set to any value between 1 and 100. The number of selected proteins is rounded down if the requested percentage does not result in a whole number. \nThe default merged_path is <output_directory>/merged.faa and the default output_path is <output_directory>/reduced.faa. Both can be set using the appropriate arguments of 'reduce'.\n\n\n### Cluster the training proteins into protein families\n\nIn[6]\n\n```python\nbp.create_pfs(memory=800, n_jobs=0, cdhit_path=None, reduced_path=None, output_path=None)\n```\n\nOut[6]\n\n    Clustering genomes.\n    cd-hit -i out/reduced.faa -o out/protein_families -c 0.4 -n 2 -M 800 -T 0\n    Clustering finished successfully. Protein families dumped in out/protein_families\n\n\nIf CD-HIT is included in the system's path, there is no need to provide a path to 'cdhit_path'. If cd-hit is not included in the path, a valid path must be provided. \nNote that we are using n_jobs=0, to use all available CPUs. \n\n### Extract features\n\nIn[7]\n```python\nbp.genomes_vs_pfs('toy/train/', feats_type='train', n_jobs=0)\n```\n\nOut[7]\n\n    Running genomes against protein families representatives\n    Genome cluster files are stored in out/train_clusters\n\nIn[8]\n\n```python\nbp.genomes_vs_pfs('toy/validate/', feats_type='pred', n_jobs=0)\n```\n\nOut[8]\n\n    Running genomes against protein families representatives\n    Genome cluster files are stored in out/pred_clusters\n\n\nIn[9]\n\n```python\nX_train = bp.extract_features(feats_type='train')\nX_pred = bp.extract_features(feats_type='pred')\n```\n\n### Read pathogenicity labels from a csv file\nbacpacs.read_labels() takes a csv file with two columns and no headers: the first column should list genome ids, and the second column should list pathogenicity labels. Genome ids should match the original genome file names. For example: for a genome file named org1.faa, the csv file should list an 'org1' genome id. Pathogenicity should be boolean: True for pathogens, False for non-pathogens. Note that we include the corresponding feature matrices (X_train, X_pred), to ensure that the orders of the returned label sets correspond to the orders of the genomes in the feature matrices.\n\nIn[10]\n\n```python\ny_train = bacpacs.read_labels('toy/labels.csv', X_train)\ny_pred = bacpacs.read_labels('toy/labels.csv', X_pred)\n```\n\nLoad a linear SVM object:\n\nIn[11]\n\n```python\nclf = LinearSVC(penalty='l1', dual=False)\n```\n\nFit it with the created features and labels:\n\nIn[12]\n```python\nclf.fit(X_train, y_train)\n```\n\n\nOut[12]\n\n    LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n         intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n         multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n         verbose=0)\n\n\n\nCompute the accuracy pf the model's prediction:\n\nIn[13]\n\n```python\nclf.score(X_pred, y_pred)\n```\n\n\nOut[13]\n\n    0.80000000000000004\n## 3. Training a model for prediction using the command line interface\n\nThe flow of bacpacs using the command line, is very similar to using it as python module as described above. \nTyping \n\nIn[1]\n```bash\npython <path_to_bacpacs> bacpacs/pacpacs.py --h\n```\n\nproduces:\n\nOut[1]\n```linux\nusage: bacpacs.py [-h] -m\n                  {merge,init,train,create_pfs,extract_feats,predict,reduce,genomes_vs_pfs}\n                  -w WORKING_DIRECTORY [-i INPUT]\n                  [--genome_input_dir GENOME_INPUT_DIR] [--pf_path PF_PATH]\n                  [-o OUTPUT] [-t {pred,train}] [-r LONG_RATIO]\n                  [-c CLUSTERS_DIR] [-f FEATS_PATH] [-l LABELS_PATH]\n                  [--clf CLF] [--cdhit CDHIT] [--n_jobs N_JOBS]\n                  [--memory MEMORY]\n\noptional arguments:\n  -h, --help            show this help message and exit\n\nrequired arguments:\n  -m {merge,init,train,create_pfs,extract_feats,predict,reduce,genomes_vs_pfs}, \n  --mode {merge,init,train,create_pfs,extract_feats,predict,reduce,genomes_vs_pfs}\n                        bacpacs operating mode. \n                        init: Initiates a bacpacs working directory. Will create \n                        a \"bp.json\" file, which\n                        stores previous operations history. \n                        merge: Merges the raw training faa files. \n                        Reduce: Selects the longest 10 precent proteins from the \n                        merged fasta file.\n                        create_pfs: Runs CD-HIT to cluster the merged and\n                        reduced fasta file to protein families. genomes_vs_pf:\n                        Creates feature vectors for training/predicting\n                        genomes. Runs CD-HIT-2D for every genome, against the\n                        previously created protein families. \n                        extract_feats: Get features matrix X (pandas.DataFrame) for\n                        training/prediction. \n                        train: Trains a sklearn.svm.LinearSVC model on the extracted feats.\n                        predict: Using either the trained classifier trained\n                        in \"train\", or a classifier from a JSON file (created\n                        by bacpacs.util.clf_to_json) a prediction is made and\n                        stored in a csv file.\n  -w WORKING_DIRECTORY, --working_directory WORKING_DIRECTORY\n                        Working directory in which bacpacs will cache files,\n                        and store resulting features.\n\noptional arguments:\n  -i INPUT, --input INPUT\n                        Input file path\n  --genome_input_dir GENOME_INPUT_DIR\n                        Working directory in which bacpacs will cache files,\n                        and store resulting features.\n  --pf_path PF_PATH     Path to protein families file, created in\n                        \"create_pfs\". Applies to \"pf_vs_genomes\". If not\n                        specified, the last created pf_file is used.\n  -o OUTPUT, --output OUTPUT\n                        Output file path. Applies to all modes except \"init\".\n                        If not specified, default paths in the working\n                        directory are used and printed to the screen.\n  -t {pred,train}, --feats_type {pred,train}\n                        Indication whether genomes are used for training, or\n                        for prediction. Applies to \"genomes_vs_pfs\" and\n                        \"extract_feats\"\n  -r LONG_RATIO, --long_ratio LONG_RATIO\n                        Ratio of long proteins to use in \"reduce\".\n  -c CLUSTERS_DIR, --clusters_dir CLUSTERS_DIR\n                        Path to training/prediction (defined in --feats_type)\n                        clusters. Applies to \"extract_feats\". If not\n                        specified, the directory used by \"genomes_vs_pfs\" to\n                        store clusters is used.\n  -f FEATS_PATH, --feats_path FEATS_PATH\n                        Path to training/prediction csv file. Applies to\n                        \"train\" and \"predict\". If not specified, the path used\n                        to store features in \"extract_feats\" is used.\n  -l LABELS_PATH, --labels_path LABELS_PATH\n                        Path to labels csv file. Applies to \"train\".\n  --clf CLF             Path to scikit-learn classifier, stored in JSON\n                        format, using bacpacs.util.clf_to_json. If not\n                        supplied, a new sklearn.svm.LinearSVC is used.\n  --cdhit CDHIT         Path to CD-HIT. Only required if CD-HIT not in\n                        environmental path. Applies to \"create_pfs\" and\n                        \"genomes_vf_pfs\".\n  --n_jobs N_JOBS       Number of threads for CD-HIT-2D. 0 to use all CPUs.\n                        Applies to \"create_pfs\" and \"genomes_vf_pfs\".\n  --memory MEMORY       Memory limit (in MB) for CD-HIT, 0 for unlimited.\n                        Applies to \"create_pfs\" and \"genomes_vf_pfs\".\n```\n\n### Initialize a working directory\n\nIn[1]\n\n```linux \n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir\n```\n\nOut[1]\n\n```linux\nbacpacs initialized in my_bp_dir\n```\n\n-w is the working directory of this bacpacs run. bp.json is stored in the working directory, and it holds information from all running\nsteps. The working directory is a required argument, which needs to be passed on each operation. \n\n### Merge training data\n\nMerge all training .faa files into one large .faa file.\n\nThe bacpacs project includes a toy.tar.gz file. Untar it using `tar -xzvf toy.tar.gz <destination>`. You could replace `<destination>`\nwith `my_bp_dir/toy`. We'll use the toy set for the rest of the running example.\n\nIn[2]\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m merge --genome_input_dir my_bp_dir/toy/train/\n```\nSpecify an output path to override the default destination directory.\n\nOut[2]\n\n    Saving merged proteins as my_bp_dir/merged.faa\n\n\nNote that it is possible to specify a different output path.\n\n### Reduce the merged file to the 10% longest proteins\n\nIn[3]\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m reduce -r 10\n```\n\nOut[3]\n\n    Saving reduced proteins as my_bp_dir/reduced.faa\n\n`-r` can be set to any value between 1 and 100. The number of selected proteins is rounded down if the requested percentage does not result in a whole number. \nThe default merged_path is <working_directory>/merged.faa and the default output_path is <working_directory>/reduced.faa. Both can be set using `--input` and `--output`.\n\n\n### Cluster the training proteins into protein families\n\nIn[4]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m create_pfs --memory 800 --n_jobs 0\n```\n\nOut[4]\n\n    Clustering genomes.\n    cd-hit -i out/reduced.faa -o out/protein_families -c 0.4 -n 2 -M 800 -T 0\n    Clustering finished successfully. Protein families dumped in my_bp_dir/protein_families\n\n\nIf CD-HIT is included in the system's path, there is no need to provide a path to CD-HIT. If cd-hit is not included in the path, a valid path must be provided using `--cdhit`. \nNote that we are using n_jobs=0, to use all available CPUs. \n\n### Create and extract features\n\nIn[5]\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m genomes_vs_pfs --genome_input_dir my_bp_dir/toy/train -t train \n```\n\nOut[5]\n\n    Running genomes against protein families representatives\n    Genome cluster files are stored in my_bp_dir/train_clusters\n\nIn[6]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m genomes_vs_pfs --genome_input_dir my_bp_dir/toy/validate -t pred\n```\n\nOut[6]\n\n    Running genomes against protein families representatives\n    Genome cluster files are stored in my_bp_dir/pred_clusters\n\n\nIn[7]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m extract_feats -t train\n```\n\nOut[7]\n\n    Training feats stored in my_bp_dir/train_feats.csv\n\n In[8]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m extract_feats -t pred\n```\n\nOut[8]\n\n    Prediction feats stored in my_bp_dir/pred_feats.csv\n\n### Train a Linear SVM classifier\n\nIn[9]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m train --labels_path my_bp_dir/toy/labels.csv\n```\n\nNote the argument --labels_path (or -l in short). The provided path contains a csv file with two columns and no\nheaders: the first column should list genome ids, and the second column should list pathogenicity labels. Genome\nids should match the original genome file names. For example: for a genome file named org1.faa, the csv file should\nlist an 'org1' genome id. Pathogenicity should be boolean: True for pathogens, False for non-pathogens. \n\nOut[9]\n\n    Trained classifier is stored at my_bp_dir/trained_clf.json\n\n### Predict the validation set pathogenicity labels\n\nIn[10]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir -m predict\n```\n\nOut[10]\n\n    Predictions stored at my_bp_dir/predictions.clf\n\n## 4. Using bacpacs trained model for prediction via the command line interface\n\n### Initialize working directory\n\nIn[1]\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir2 -m init --pre_trained\n```\n\nOut[1]\n\n    bacpacs initialized in my_bp_dir2\n\nNow you can simply continue as before, without the clustering and training:\n\n### Create and extract features\n\nThe bacpacs project includes a toy.tar.gz file. Untar it using `tar -xzvf toy.tar.gz <destination>`. You could replace `<destination>`\nwith `my_bp_dir2/toy`. We'll use the toy set for the rest of the running example.\n\nIn[2]\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir2 -m genomes_vs_pfs --genome_input_dir my_bp_dir2/toy/validate -t pred \n```\n\nOut[2]\n\n    Running genomes against protein families representatives\n    Genome cluster files are stored in my_bp_dir2/pred_clusters\n\nIn[3]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir2 -m extract_feats -t pred\n```\n\nOut[3]\n\n    Prediction feats stored in my_bp_dir2/pred_feats.csv\n\n### Predict the validation set pathogenicity labels\n\nIn[4]\n\n```linux\n$ python <path_to_bacpacs>/bacpacs.py -w my_bp_dir2 -m predict\n```\n\nOut[4]\n\n    Predictions stored at my_bp_dir2/predictions.csv\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/barashe/bacpacs", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "bacpacs", "package_url": "https://pypi.org/project/bacpacs/", "platform": "", "project_url": "https://pypi.org/project/bacpacs/", "project_urls": {"Homepage": "https://github.com/barashe/bacpacs"}, "release_url": "https://pypi.org/project/bacpacs/0.1.1/", "requires_dist": ["numpy", "pandas", "scikit-learn", "biopython"], "requires_python": "", "summary": "Bacterial Pathogenicity Classification via Sparse-SVM", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>bacpacs version 0.1.1<br>User's guide</h1>\n<h2>Overview</h2>\n<p>bacpacs is a bacterial pathogenicity classification python module, based on the following paper: \"BacPaCS \u2013 Bacterial Pathogenicity Classification via Sparse-SVM\", by Eran Barash, Neta Sal-Man, Sivan Sabato, and Michal Ziv-Ukelson (Submitted). It can be used for classification using a pre-trained model, or for generating a new model from labeled training data of sequenced proteomes. The training pipeline:</p>\n<ol>\n<li>\n<p>bacpacs selects the 10% longest protein out of the set of all proteins from all training samples.</p>\n</li>\n<li>\n<p>Using CD-HIT, bacpacs clusters the selected proteins. This results in\nclusters, or protein families (PFs). Each PF is represented by its\nlongest protein.</p>\n</li>\n<li>\n<p>For each organism in the training set, bacpacs compares the\norganism's proteins to the representatives of the PFs, using CD-HIT-2D.\nThis results in a binary feature vector for each organism. The\nvector indices represent the different PFs.\nIf a cell with index <em>i</em> has a value <code>True</code>, the organism has a protein\nsimilar to the representative of PF <em>i</em>. Otherwise, the cell's value is <code>False</code>.</p>\n</li>\n<li>\n<p>The binary feature vectors of the organisms in the training set (and their known\npathogenicity labels), can then be used to train a linear SVM model (using l1\nnorm as penalty). Other models can be trained as well.</p>\n</li>\n</ol>\n<h2>Installation and dependencies</h2>\n<p>Bacpacs can be installed via one of the following three alternatives:</p>\n<ol>\n<li>Run in a linux terminal: <code>$ pip install bacpacs</code> (recommended)</li>\n<li>Clone or download bacpacs Github <a href=\"https://github.com/barashe/bacpacs.git\" rel=\"nofollow\">repository</a> and run <code>pip install -e path/to/bacpacs</code></li>\n<li>Clone or download bacpacs Github <a href=\"https://github.com/barashe/bacpacs.git\" rel=\"nofollow\">repository</a> and use the command line interface described below.</li>\n</ol>\n<p>Dependencies:</p>\n<ul>\n<li>\n<p>Operating system: Linux. CD-HIT only runs on Linux OS, and so does bacpacs.</p>\n</li>\n<li>\n<p>CD-HIT: bacpacs requires CD-HIT to be installed. It is also recommended to add CD-HIT to the PATH variable. CD-HIT can be downloaded from its official <a href=\"http://weizhongli-lab.org/cd-hit/\" rel=\"nofollow\">website</a>.</p>\n</li>\n<li>\n<p>Python 2.7.</p>\n</li>\n<li>\n<p>Python packages: numpy, scipy, scikit-learn, and biopython. If\nyou are missing a package, you can simply install the package using\n<a href=\"https://pypi.python.org/pypi/pip/\" rel=\"nofollow\">pip</a> or\n<a href=\"https://wiki.python.org/moin/EasyInstall\" rel=\"nofollow\">EasyInstall</a>.</p>\n</li>\n</ul>\n<h2>Running bacpacs as a python module</h2>\n<p>Below are detailed running examples of the two possible bacpacs schemes:</p>\n<ol>\n<li>Predicting data using bacpacs pre-trained model: bacpacs comes with a pre-trained model, used in the bacpacs paper. The pre-trained model can be easily downloaded and used.</li>\n<li>Training and using a model: bacpacs can also be used to translate a training set of organisms into a feature vector that can be fed into an SVM training module, and to then translate a test set into a feature vector which uses the same features as the training set. The pathogenicity of the organisms in the test set can then be predicted using the trained model. The organisms in both the training set and the test set are fed as raw amino acid fasta files (faa files).</li>\n<li>Trainig a model for prediction using the command line interface.</li>\n<li>Using bacpacs trained model for prediction via the command line interface.</li>\n</ol>\n<p>The example code below should be used in Python 2.7. Full documentation of each of the methods appears in the code. This example code can be found in <a href=\"https://github.com/barashe/bacpacs/tree/master/examples\" rel=\"nofollow\">examples</a>.</p>\n<h2>1. Predicting data using bacpacs pre-trained model</h2>\n<h3>Imports</h3>\n<p>In[1]</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">bacpacs</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.svm</span> <span class=\"kn\">import</span> <span class=\"n\">LinearSVC</span>\n</pre>\n<p>The bacpacs pre-trained model can be found in <a href=\"https://github.com/barashe/bacpacs/tree/master/trained\" rel=\"nofollow\">https://github.com/barashe/bacpacs/tree/master/trained</a>. It can also be downloaded and loaded directly from Python as described below.</p>\n<h3>Load the pre-trained model</h3>\n<p>In[2]</p>\n<pre><span class=\"n\">bp</span><span class=\"p\">,</span> <span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">load_trained_model</span><span class=\"p\">(</span><span class=\"n\">output_dir</span><span class=\"o\">=</span><span class=\"s1\">'out1'</span><span class=\"p\">)</span>\n</pre>\n<p>Out[2]</p>\n<pre><code>Retrieving files from github\nDownloading full_bacpacs.pkl\nDownloading linearsvc_full.pkl\nDownloading protein_families\n</code></pre>\n<p>load_trained_model() returns a Bacpacs object, and a sklearn.svm.LinearSVC trained classifier. We will need bp for feature extraction, and clf for the prediction itself.\nHere 'bacpacs' is an empty folder, and 'out1' is created when invoking load_trained_model(). These names can be set according to preference. An existing output_dir is acceptable as well, but beware of file overrun.</p>\n<h3>Download toy data</h3>\n<p>Use your real data, or download bacpacs toy data (also available on <a href=\"https://github.com/barashe/bacpacs/blob/master/toy.tar.gz\" rel=\"nofollow\">Github</a>):</p>\n<p>In[3]</p>\n<pre><span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">download_toy_data</span><span class=\"p\">(</span><span class=\"s1\">'.'</span><span class=\"p\">)</span>\n</pre>\n<p>Out[3]</p>\n<pre><code>Toy data stored in ./toy\n</code></pre>\n<p>You can move genomes from toy/train to toy/validate and vice versa, or even delete some. The destination folder can be set by replacing '.' with the desired destination.</p>\n<h3>Extract features for test organisms</h3>\n<p>This step takes a while, depending on your machine:</p>\n<p>In[4]</p>\n<pre><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">genomes_vs_pfs</span><span class=\"p\">(</span><span class=\"s1\">'toy/validate'</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Out[4]</p>\n<pre><code>Running genomes against protein families representatives\nGenome cluster files are stored in out1/pred_clusters\n</code></pre>\n<p>genomes_vs_pfs() uses CD-HIT-2D to run all test genomes against the pre-established protein families. Assigning n_jobs=0 tells CD-HIT-2D to use all available CPUs for each genome. However, the genomes are processed sequentially. Running genomes_vs_pfs() on several machines can save plenty of time.\n<br><br>Next, extract the features and store them in variables:</p>\n<p>In[5]</p>\n<pre><span class=\"n\">X_pred</span> <span class=\"o\">=</span> <span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">extract_features</span><span class=\"p\">(</span><span class=\"n\">feats_type</span><span class=\"o\">=</span><span class=\"s1\">'pred'</span><span class=\"p\">)</span>\n</pre>\n<h3>Read pathogenicity labels from a csv file</h3>\n<p>bacpacs.read_labels() takes a csv file with two columns and no headers: the first column should list genome ids, and the second column should list pathogenicity labels. Genome ids should match the original genome file names. For example: for a genome file named org1.faa, the csv file should list an 'org1' genome id. Pathogenicity should be boolean: True for pathogens, False for non-pathogens. Note that we include the corresponding feature matrix (X_pred), to ensure that the order of the returned labels corresponds to the order of the genomes in the feature matrix.</p>\n<p>In[6]</p>\n<pre><span class=\"n\">y_true</span> <span class=\"o\">=</span> <span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">read_labels</span><span class=\"p\">(</span><span class=\"s1\">'toy/labels.csv'</span><span class=\"p\">,</span> <span class=\"n\">X</span><span class=\"o\">=</span><span class=\"n\">X_pred</span><span class=\"p\">)</span>\n</pre>\n<h3>Predict pathogenicity</h3>\n<p>In[7]</p>\n<pre><span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_pred</span><span class=\"p\">)</span>\n</pre>\n<p>Compute accuracy:</p>\n<p>In[8]</p>\n<pre><span class=\"p\">(</span><span class=\"n\">y_pred</span> <span class=\"o\">==</span> <span class=\"n\">y_true</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n</pre>\n<p>Out[8]</p>\n<pre><code>0.80000000000000004\n</code></pre>\n<p>Or simply:</p>\n<p>In[9]</p>\n<pre><span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">score</span><span class=\"p\">(</span><span class=\"n\">X_pred</span><span class=\"p\">,</span> <span class=\"n\">y_true</span><span class=\"p\">)</span>\n</pre>\n<p>Out[9]</p>\n<pre><code>0.80000000000000004\n</code></pre>\n<h2>2. Training and using a model</h2>\n<h3>Imports</h3>\n<p>In[1]</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">bacpacs</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.svm</span> <span class=\"kn\">import</span> <span class=\"n\">LinearSVC</span>\n</pre>\n<h3>Download toy data</h3>\n<p>Use your real data, or download the bacpacs toy data (also available on <a href=\"https://github.com/barashe/bacpacs/blob/master/toy.tar.gz\" rel=\"nofollow\">Github</a>):</p>\n<p>In[2]</p>\n<pre><span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">download_toy_data</span><span class=\"p\">(</span><span class=\"s1\">'.'</span><span class=\"p\">)</span>\n</pre>\n<p>Out[2]</p>\n<pre><code>Toy data stored in ./toy\n</code></pre>\n<h3>Initialize a Bacpacs object</h3>\n<p>In[3]</p>\n<pre><span class=\"n\">bp</span> <span class=\"o\">=</span> <span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">Bacpacs</span><span class=\"p\">(</span><span class=\"s1\">'out2'</span><span class=\"p\">)</span>\n</pre>\n<h3>Merge training data</h3>\n<p>Merge all training .faa files into one large .faa file.</p>\n<p>In[4]</p>\n<pre><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">merge_genome_files</span><span class=\"p\">(</span><span class=\"s1\">'toy/train/'</span><span class=\"p\">,</span> <span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n</pre>\n<p>Specify an output path to override the default destination directory.</p>\n<p>Out[4]</p>\n<pre><code>Saving merged proteins as out/merged.faa\n</code></pre>\n<p>Note that it is possible to specify a different output path.</p>\n<h3>Reduce the merged file to the 10% longest proteins</h3>\n<p>In[5]</p>\n<pre><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">reduce</span><span class=\"p\">(</span><span class=\"n\">long_percent</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">merged_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n</pre>\n<p>Out[5]</p>\n<pre><code>Saving reduced proteins as out/reduced.faa\n</code></pre>\n<p>long_percent can be set to any value between 1 and 100. The number of selected proteins is rounded down if the requested percentage does not result in a whole number.\nThe default merged_path is &lt;output_directory&gt;/merged.faa and the default output_path is &lt;output_directory&gt;/reduced.faa. Both can be set using the appropriate arguments of 'reduce'.</p>\n<h3>Cluster the training proteins into protein families</h3>\n<p>In[6]</p>\n<pre><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">create_pfs</span><span class=\"p\">(</span><span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"mi\">800</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cdhit_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">reduced_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n</pre>\n<p>Out[6]</p>\n<pre><code>Clustering genomes.\ncd-hit -i out/reduced.faa -o out/protein_families -c 0.4 -n 2 -M 800 -T 0\nClustering finished successfully. Protein families dumped in out/protein_families\n</code></pre>\n<p>If CD-HIT is included in the system's path, there is no need to provide a path to 'cdhit_path'. If cd-hit is not included in the path, a valid path must be provided.\nNote that we are using n_jobs=0, to use all available CPUs.</p>\n<h3>Extract features</h3>\n<p>In[7]</p>\n<pre><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">genomes_vs_pfs</span><span class=\"p\">(</span><span class=\"s1\">'toy/train/'</span><span class=\"p\">,</span> <span class=\"n\">feats_type</span><span class=\"o\">=</span><span class=\"s1\">'train'</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Out[7]</p>\n<pre><code>Running genomes against protein families representatives\nGenome cluster files are stored in out/train_clusters\n</code></pre>\n<p>In[8]</p>\n<pre><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">genomes_vs_pfs</span><span class=\"p\">(</span><span class=\"s1\">'toy/validate/'</span><span class=\"p\">,</span> <span class=\"n\">feats_type</span><span class=\"o\">=</span><span class=\"s1\">'pred'</span><span class=\"p\">,</span> <span class=\"n\">n_jobs</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Out[8]</p>\n<pre><code>Running genomes against protein families representatives\nGenome cluster files are stored in out/pred_clusters\n</code></pre>\n<p>In[9]</p>\n<pre><span class=\"n\">X_train</span> <span class=\"o\">=</span> <span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">extract_features</span><span class=\"p\">(</span><span class=\"n\">feats_type</span><span class=\"o\">=</span><span class=\"s1\">'train'</span><span class=\"p\">)</span>\n<span class=\"n\">X_pred</span> <span class=\"o\">=</span> <span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">extract_features</span><span class=\"p\">(</span><span class=\"n\">feats_type</span><span class=\"o\">=</span><span class=\"s1\">'pred'</span><span class=\"p\">)</span>\n</pre>\n<h3>Read pathogenicity labels from a csv file</h3>\n<p>bacpacs.read_labels() takes a csv file with two columns and no headers: the first column should list genome ids, and the second column should list pathogenicity labels. Genome ids should match the original genome file names. For example: for a genome file named org1.faa, the csv file should list an 'org1' genome id. Pathogenicity should be boolean: True for pathogens, False for non-pathogens. Note that we include the corresponding feature matrices (X_train, X_pred), to ensure that the orders of the returned label sets correspond to the orders of the genomes in the feature matrices.</p>\n<p>In[10]</p>\n<pre><span class=\"n\">y_train</span> <span class=\"o\">=</span> <span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">read_labels</span><span class=\"p\">(</span><span class=\"s1\">'toy/labels.csv'</span><span class=\"p\">,</span> <span class=\"n\">X_train</span><span class=\"p\">)</span>\n<span class=\"n\">y_pred</span> <span class=\"o\">=</span> <span class=\"n\">bacpacs</span><span class=\"o\">.</span><span class=\"n\">read_labels</span><span class=\"p\">(</span><span class=\"s1\">'toy/labels.csv'</span><span class=\"p\">,</span> <span class=\"n\">X_pred</span><span class=\"p\">)</span>\n</pre>\n<p>Load a linear SVM object:</p>\n<p>In[11]</p>\n<pre><span class=\"n\">clf</span> <span class=\"o\">=</span> <span class=\"n\">LinearSVC</span><span class=\"p\">(</span><span class=\"n\">penalty</span><span class=\"o\">=</span><span class=\"s1\">'l1'</span><span class=\"p\">,</span> <span class=\"n\">dual</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n</pre>\n<p>Fit it with the created features and labels:</p>\n<p>In[12]</p>\n<pre><span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>\n</pre>\n<p>Out[12]</p>\n<pre><code>LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n     verbose=0)\n</code></pre>\n<p>Compute the accuracy pf the model's prediction:</p>\n<p>In[13]</p>\n<pre><span class=\"n\">clf</span><span class=\"o\">.</span><span class=\"n\">score</span><span class=\"p\">(</span><span class=\"n\">X_pred</span><span class=\"p\">,</span> <span class=\"n\">y_pred</span><span class=\"p\">)</span>\n</pre>\n<p>Out[13]</p>\n<pre><code>0.80000000000000004\n</code></pre>\n<h2>3. Training a model for prediction using the command line interface</h2>\n<p>The flow of bacpacs using the command line, is very similar to using it as python module as described above.\nTyping</p>\n<p>In[1]</p>\n<pre>python &lt;path_to_bacpacs&gt; bacpacs/pacpacs.py --h\n</pre>\n<p>produces:</p>\n<p>Out[1]</p>\n<pre>usage: bacpacs.py [-h] -m\n                  {merge,init,train,create_pfs,extract_feats,predict,reduce,genomes_vs_pfs}\n                  -w WORKING_DIRECTORY [-i INPUT]\n                  [--genome_input_dir GENOME_INPUT_DIR] [--pf_path PF_PATH]\n                  [-o OUTPUT] [-t {pred,train}] [-r LONG_RATIO]\n                  [-c CLUSTERS_DIR] [-f FEATS_PATH] [-l LABELS_PATH]\n                  [--clf CLF] [--cdhit CDHIT] [--n_jobs N_JOBS]\n                  [--memory MEMORY]\n\noptional arguments:\n  -h, --help            show this help message and exit\n\nrequired arguments:\n  -m {merge,init,train,create_pfs,extract_feats,predict,reduce,genomes_vs_pfs}, \n  --mode {merge,init,train,create_pfs,extract_feats,predict,reduce,genomes_vs_pfs}\n                        bacpacs operating mode. \n                        init: Initiates a bacpacs working directory. Will create \n                        a \"bp.json\" file, which\n                        stores previous operations history. \n                        merge: Merges the raw training faa files. \n                        Reduce: Selects the longest 10 precent proteins from the \n                        merged fasta file.\n                        create_pfs: Runs CD-HIT to cluster the merged and\n                        reduced fasta file to protein families. genomes_vs_pf:\n                        Creates feature vectors for training/predicting\n                        genomes. Runs CD-HIT-2D for every genome, against the\n                        previously created protein families. \n                        extract_feats: Get features matrix X (pandas.DataFrame) for\n                        training/prediction. \n                        train: Trains a sklearn.svm.LinearSVC model on the extracted feats.\n                        predict: Using either the trained classifier trained\n                        in \"train\", or a classifier from a JSON file (created\n                        by bacpacs.util.clf_to_json) a prediction is made and\n                        stored in a csv file.\n  -w WORKING_DIRECTORY, --working_directory WORKING_DIRECTORY\n                        Working directory in which bacpacs will cache files,\n                        and store resulting features.\n\noptional arguments:\n  -i INPUT, --input INPUT\n                        Input file path\n  --genome_input_dir GENOME_INPUT_DIR\n                        Working directory in which bacpacs will cache files,\n                        and store resulting features.\n  --pf_path PF_PATH     Path to protein families file, created in\n                        \"create_pfs\". Applies to \"pf_vs_genomes\". If not\n                        specified, the last created pf_file is used.\n  -o OUTPUT, --output OUTPUT\n                        Output file path. Applies to all modes except \"init\".\n                        If not specified, default paths in the working\n                        directory are used and printed to the screen.\n  -t {pred,train}, --feats_type {pred,train}\n                        Indication whether genomes are used for training, or\n                        for prediction. Applies to \"genomes_vs_pfs\" and\n                        \"extract_feats\"\n  -r LONG_RATIO, --long_ratio LONG_RATIO\n                        Ratio of long proteins to use in \"reduce\".\n  -c CLUSTERS_DIR, --clusters_dir CLUSTERS_DIR\n                        Path to training/prediction (defined in --feats_type)\n                        clusters. Applies to \"extract_feats\". If not\n                        specified, the directory used by \"genomes_vs_pfs\" to\n                        store clusters is used.\n  -f FEATS_PATH, --feats_path FEATS_PATH\n                        Path to training/prediction csv file. Applies to\n                        \"train\" and \"predict\". If not specified, the path used\n                        to store features in \"extract_feats\" is used.\n  -l LABELS_PATH, --labels_path LABELS_PATH\n                        Path to labels csv file. Applies to \"train\".\n  --clf CLF             Path to scikit-learn classifier, stored in JSON\n                        format, using bacpacs.util.clf_to_json. If not\n                        supplied, a new sklearn.svm.LinearSVC is used.\n  --cdhit CDHIT         Path to CD-HIT. Only required if CD-HIT not in\n                        environmental path. Applies to \"create_pfs\" and\n                        \"genomes_vf_pfs\".\n  --n_jobs N_JOBS       Number of threads for CD-HIT-2D. 0 to use all CPUs.\n                        Applies to \"create_pfs\" and \"genomes_vf_pfs\".\n  --memory MEMORY       Memory limit (in MB) for CD-HIT, 0 for unlimited.\n                        Applies to \"create_pfs\" and \"genomes_vf_pfs\".\n</pre>\n<h3>Initialize a working directory</h3>\n<p>In[1]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir\n</pre>\n<p>Out[1]</p>\n<pre>bacpacs initialized in my_bp_dir\n</pre>\n<p>-w is the working directory of this bacpacs run. bp.json is stored in the working directory, and it holds information from all running\nsteps. The working directory is a required argument, which needs to be passed on each operation.</p>\n<h3>Merge training data</h3>\n<p>Merge all training .faa files into one large .faa file.</p>\n<p>The bacpacs project includes a toy.tar.gz file. Untar it using <code>tar -xzvf toy.tar.gz &lt;destination&gt;</code>. You could replace <code>&lt;destination&gt;</code>\nwith <code>my_bp_dir/toy</code>. We'll use the toy set for the rest of the running example.</p>\n<p>In[2]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m merge --genome_input_dir my_bp_dir/toy/train/\n</pre>\n<p>Specify an output path to override the default destination directory.</p>\n<p>Out[2]</p>\n<pre><code>Saving merged proteins as my_bp_dir/merged.faa\n</code></pre>\n<p>Note that it is possible to specify a different output path.</p>\n<h3>Reduce the merged file to the 10% longest proteins</h3>\n<p>In[3]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m reduce -r 10\n</pre>\n<p>Out[3]</p>\n<pre><code>Saving reduced proteins as my_bp_dir/reduced.faa\n</code></pre>\n<p><code>-r</code> can be set to any value between 1 and 100. The number of selected proteins is rounded down if the requested percentage does not result in a whole number.\nThe default merged_path is &lt;working_directory&gt;/merged.faa and the default output_path is &lt;working_directory&gt;/reduced.faa. Both can be set using <code>--input</code> and <code>--output</code>.</p>\n<h3>Cluster the training proteins into protein families</h3>\n<p>In[4]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m create_pfs --memory 800 --n_jobs 0\n</pre>\n<p>Out[4]</p>\n<pre><code>Clustering genomes.\ncd-hit -i out/reduced.faa -o out/protein_families -c 0.4 -n 2 -M 800 -T 0\nClustering finished successfully. Protein families dumped in my_bp_dir/protein_families\n</code></pre>\n<p>If CD-HIT is included in the system's path, there is no need to provide a path to CD-HIT. If cd-hit is not included in the path, a valid path must be provided using <code>--cdhit</code>.\nNote that we are using n_jobs=0, to use all available CPUs.</p>\n<h3>Create and extract features</h3>\n<p>In[5]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m genomes_vs_pfs --genome_input_dir my_bp_dir/toy/train -t train \n</pre>\n<p>Out[5]</p>\n<pre><code>Running genomes against protein families representatives\nGenome cluster files are stored in my_bp_dir/train_clusters\n</code></pre>\n<p>In[6]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m genomes_vs_pfs --genome_input_dir my_bp_dir/toy/validate -t pred\n</pre>\n<p>Out[6]</p>\n<pre><code>Running genomes against protein families representatives\nGenome cluster files are stored in my_bp_dir/pred_clusters\n</code></pre>\n<p>In[7]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m extract_feats -t train\n</pre>\n<p>Out[7]</p>\n<pre><code>Training feats stored in my_bp_dir/train_feats.csv\n</code></pre>\n<p>In[8]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m extract_feats -t pred\n</pre>\n<p>Out[8]</p>\n<pre><code>Prediction feats stored in my_bp_dir/pred_feats.csv\n</code></pre>\n<h3>Train a Linear SVM classifier</h3>\n<p>In[9]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m train --labels_path my_bp_dir/toy/labels.csv\n</pre>\n<p>Note the argument --labels_path (or -l in short). The provided path contains a csv file with two columns and no\nheaders: the first column should list genome ids, and the second column should list pathogenicity labels. Genome\nids should match the original genome file names. For example: for a genome file named org1.faa, the csv file should\nlist an 'org1' genome id. Pathogenicity should be boolean: True for pathogens, False for non-pathogens.</p>\n<p>Out[9]</p>\n<pre><code>Trained classifier is stored at my_bp_dir/trained_clf.json\n</code></pre>\n<h3>Predict the validation set pathogenicity labels</h3>\n<p>In[10]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir -m predict\n</pre>\n<p>Out[10]</p>\n<pre><code>Predictions stored at my_bp_dir/predictions.clf\n</code></pre>\n<h2>4. Using bacpacs trained model for prediction via the command line interface</h2>\n<h3>Initialize working directory</h3>\n<p>In[1]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir2 -m init --pre_trained\n</pre>\n<p>Out[1]</p>\n<pre><code>bacpacs initialized in my_bp_dir2\n</code></pre>\n<p>Now you can simply continue as before, without the clustering and training:</p>\n<h3>Create and extract features</h3>\n<p>The bacpacs project includes a toy.tar.gz file. Untar it using <code>tar -xzvf toy.tar.gz &lt;destination&gt;</code>. You could replace <code>&lt;destination&gt;</code>\nwith <code>my_bp_dir2/toy</code>. We'll use the toy set for the rest of the running example.</p>\n<p>In[2]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir2 -m genomes_vs_pfs --genome_input_dir my_bp_dir2/toy/validate -t pred \n</pre>\n<p>Out[2]</p>\n<pre><code>Running genomes against protein families representatives\nGenome cluster files are stored in my_bp_dir2/pred_clusters\n</code></pre>\n<p>In[3]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir2 -m extract_feats -t pred\n</pre>\n<p>Out[3]</p>\n<pre><code>Prediction feats stored in my_bp_dir2/pred_feats.csv\n</code></pre>\n<h3>Predict the validation set pathogenicity labels</h3>\n<p>In[4]</p>\n<pre>$ python &lt;path_to_bacpacs&gt;/bacpacs.py -w my_bp_dir2 -m predict\n</pre>\n<p>Out[4]</p>\n<pre><code>Predictions stored at my_bp_dir2/predictions.csv\n</code></pre>\n\n          </div>"}, "last_serial": 4219678, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "3f16cbef23b2c66b04ca349bf66a641f", "sha256": "c805543cf6bacc3928cc25e8c05dcdb22bdab9f7382047032c2aa9beffa946c5"}, "downloads": -1, "filename": "bacpacs-0.0.2-py2-none-any.whl", "has_sig": false, "md5_digest": "3f16cbef23b2c66b04ca349bf66a641f", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 9775, "upload_time": "2018-06-29T11:52:28", "upload_time_iso_8601": "2018-06-29T11:52:28.956556Z", "url": "https://files.pythonhosted.org/packages/c8/3b/d939b281fc015d421364a73f3591c7735a056b44d6d5e54b00d4a922c7ad/bacpacs-0.0.2-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4b93be8f5dedfa3edba366b1ccebfbcf", "sha256": "75801feb9d312ebf835e334f26e283ffc71195c858e8bdf509c5ff181dfdc1a8"}, "downloads": -1, "filename": "bacpacs-0.0.2.tar.gz", "has_sig": false, "md5_digest": "4b93be8f5dedfa3edba366b1ccebfbcf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9216, "upload_time": "2018-06-29T11:52:30", "upload_time_iso_8601": "2018-06-29T11:52:30.330405Z", "url": "https://files.pythonhosted.org/packages/8c/c0/bcbae967be68854a6e9e173c6a167f3ecb53aa71fb83160468f6e7db900d/bacpacs-0.0.2.tar.gz", "yanked": false}], "0.1.0": [{"comment_text": "", "digests": {"md5": "56bd7dee21ea8d7bbd9122e7aa0a7012", "sha256": "42d0f69e7b1c874c1956e9b42670c515d18386504d4017a27820852bd8073234"}, "downloads": -1, "filename": "bacpacs-0.1.0-py2-none-any.whl", "has_sig": false, "md5_digest": "56bd7dee21ea8d7bbd9122e7aa0a7012", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14667, "upload_time": "2018-08-29T16:54:03", "upload_time_iso_8601": "2018-08-29T16:54:03.365188Z", "url": "https://files.pythonhosted.org/packages/b3/3b/5ac5663192562be7f108153e93c1f629d0580d2f3265aa66548309a84eff/bacpacs-0.1.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "cb2a83f8f74b4c3ff4372db85f66aba9", "sha256": "9c0a3c791f0ec615b25168401f8a37a94479f10e397dd13851085abbb1d7a1fe"}, "downloads": -1, "filename": "bacpacs-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cb2a83f8f74b4c3ff4372db85f66aba9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15820, "upload_time": "2018-08-29T16:54:04", "upload_time_iso_8601": "2018-08-29T16:54:04.984317Z", "url": "https://files.pythonhosted.org/packages/66/fd/0ad7a333b4717bd11eba5ca37c38fb62daeb58af37c968a889abf59bbfa8/bacpacs-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "64425aeddfeb02d5f88e69846d61cdfa", "sha256": "64f8293df707385b382d10ddde3ddfc288baaf8753afe452a9be1577e142b9cc"}, "downloads": -1, "filename": "bacpacs-0.1.1-py2-none-any.whl", "has_sig": false, "md5_digest": "64425aeddfeb02d5f88e69846d61cdfa", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14661, "upload_time": "2018-08-29T17:18:52", "upload_time_iso_8601": "2018-08-29T17:18:52.854585Z", "url": "https://files.pythonhosted.org/packages/66/ff/b696225032a90316a78e9ccb95b0c98ff0e24976dbafd89f82ca39901d8b/bacpacs-0.1.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "855f33b3ff95171d6f9c5a8ef59a1d64", "sha256": "181b722e973ff230089cd307c1128e11b85c747573efb982237d03a0d7fe3289"}, "downloads": -1, "filename": "bacpacs-0.1.1.tar.gz", "has_sig": false, "md5_digest": "855f33b3ff95171d6f9c5a8ef59a1d64", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15804, "upload_time": "2018-08-29T17:18:54", "upload_time_iso_8601": "2018-08-29T17:18:54.294373Z", "url": "https://files.pythonhosted.org/packages/40/e2/7b9c848c939e7f8a5514443bbe293b28cc2f16f194e65a0f404ffb7a7935/bacpacs-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "64425aeddfeb02d5f88e69846d61cdfa", "sha256": "64f8293df707385b382d10ddde3ddfc288baaf8753afe452a9be1577e142b9cc"}, "downloads": -1, "filename": "bacpacs-0.1.1-py2-none-any.whl", "has_sig": false, "md5_digest": "64425aeddfeb02d5f88e69846d61cdfa", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 14661, "upload_time": "2018-08-29T17:18:52", "upload_time_iso_8601": "2018-08-29T17:18:52.854585Z", "url": "https://files.pythonhosted.org/packages/66/ff/b696225032a90316a78e9ccb95b0c98ff0e24976dbafd89f82ca39901d8b/bacpacs-0.1.1-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "855f33b3ff95171d6f9c5a8ef59a1d64", "sha256": "181b722e973ff230089cd307c1128e11b85c747573efb982237d03a0d7fe3289"}, "downloads": -1, "filename": "bacpacs-0.1.1.tar.gz", "has_sig": false, "md5_digest": "855f33b3ff95171d6f9c5a8ef59a1d64", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15804, "upload_time": "2018-08-29T17:18:54", "upload_time_iso_8601": "2018-08-29T17:18:54.294373Z", "url": "https://files.pythonhosted.org/packages/40/e2/7b9c848c939e7f8a5514443bbe293b28cc2f16f194e65a0f404ffb7a7935/bacpacs-0.1.1.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:15:05 2020"}