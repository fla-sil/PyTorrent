{"info": {"author": "Valentin Haenel", "author_email": "valentin@haenel.co", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "License :: OSI Approved :: MIT License", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: System :: Archiving :: Compression", "Topic :: Utilities"], "description": "Bloscpack\n=========\n\n:Author: Valentin H\u00e4nel\n:Contact: valentin@haenel.co\n:List: http://groups.google.com/group/blosc\n:Github: https://github.com/Blosc/bloscpack\n:PyPi: https://pypi.python.org/pypi/bloscpack\n:Anaconda: https://anaconda.org/pypi/bloscpack\n:Ohloh: https://www.ohloh.net/p/bloscpack\n:Version: |version|\n:Travis CI: |travis|\n:Coveralls: |coveralls|\n:Python Versions: |pyversions|\n:License: |license|\n:And...: |powered|\n\n.. |version| image::    https://img.shields.io/pypi/v/bloscpack.svg\n        :target: https://pypi.python.org/pypi/bloscpack\n\n.. |travis| image:: https://img.shields.io/travis/Blosc/bloscpack/master.svg\n        :target: https://travis-ci.org/Blosc/bloscpack\n\n.. |coveralls| image:: https://coveralls.io/repos/Blosc/bloscpack/badge.svg?branch=master&service=github\n        :target: https://coveralls.io/github/Blosc/bloscpack?branch=master\n\n.. |license| image:: https://img.shields.io/pypi/l/bloscpack.svg\n        :target: https://pypi.python.org/pypi/bloscpack\n\n.. |powered| image:: https://img.shields.io/badge/Powerd--By-Blosc-blue.svg\n        :target: https://blosc.org\n\n.. |pyversions| image:: https://img.shields.io/pypi/pyversions/bloscpack.svg\n        :target: https://pypi.python.org/pypi/bloscpack\n\n.. contents:: Table of Contents\n   :depth: 1\n\nDescription\n-----------\n\nCommand line interface to and serialization format for `Blosc\n<http://blosc.org/>`_, a high performance, multi-threaded, blocking and\nshuffling compressor. Uses `python-blosc\n<https://github.com/Blosc/python-blosc>`_ bindings to interface with Blosc.\nAlso comes with native support for efficiently serializing and deserializing\nNumpy arrays.\n\nCode of Conduct\n---------------\n\nThe Blosc community has adopted a `Code of Conduct\n<https://github.com/Blosc/CodeOfConduct>`_ that we expect project participants\nto adhere to. Please read the full text so that you can understand what actions\nwill and will not be tolerated.\n\nDependencies\n------------\n\n* Python 2.7, 3.4, 3.5, 3.6 or 3.7\n* `python-blosc  <https://github.com/Blosc/python-blosc>`_ (provides Blosc) and\n  `Numpy <http://www.numpy.org/>`_ (as listed in ``requirements.txt``) for\n  running the code\n* The Python packages listed in ``test_requirements.txt`` for testing and\n  releasing\n\nStability of File Format\n------------------------\n\nThe tool is considered alpha-stage, experimental, research software. It is not\nunlikely that **the internal storage format for the compressed files will\nchange in future**. Please **do not depend critically on the files generated\n(unless you know what you are doing)** by Bloscpack. See the warranty disclaimer\nin the licence at the end of this file.\n\nInstallation\n------------\n\nDisclaimer: There are a myriad ways of installing Python packages (and their\ndependencies) these days and it is a futile endeavour to explain the procedures\nin great detail again and again. Below are three methods that are known to\nwork. Depending on the method you choose and the system your are using you may\nrequire any or all of: super user privileges, a C++ compiler and/or a virtual\nenvironment. If you do run into problems or are unsure, it's best to send an\nemail to the aforementioned mailing list asking for help.\n\nThe package is available on PyPi, so you may use pip to install the\ndependencies and bloscpack itself:\n\n.. code-block:: console\n\n    $ pip install bloscpack\n\nIf you want to install straight from GitHub, use pip's VCS support:\n\n.. code-block:: console\n\n    $ pip install git+https://github.com/Blosc/bloscpack\n\nOr, of course, download the source code or clone the repository and then use\nthe standard ``setup.py``:\n\n.. code-block:: console\n\n    $ git clone https://github.com/Blosc/bloscpack\n    $ cd bloscpack\n    $ python setup.py install\n\nUsage\n-----\n\nBloscpack is accessible from the command line using the ``blpk`` executable\nthis has a number of global options and four subcommands: ``[c | compress]``,\n``[d | decompress]``, ``[a | append]`` and ``[i | info]`` most of which each\nhave their own options.\n\nHelp for global options and subcommands:\n\n.. code-block:: console\n\n    $ blpk --help\n    [...]\n\nHelp for each one of the subcommands:\n\n.. code-block:: console\n\n    $ blpk compress --help\n    [...]\n    $ blpk decompress --help\n    [...]\n    $ blpk info --help\n    [...]\n    $ blpk append --help\n    [...]\n\nExamples\n--------\n\nBasics\n~~~~~~\n\nBasic compression:\n\n.. code-block:: console\n\n    $ blpk compress data.dat\n\nOr:\n\n.. code-block:: console\n\n    $ blpk c data.dat\n\n... will compress the file ``data.dat`` to ``data.dat.blp``\n\nBasic decompression:\n\n.. code-block:: console\n\n    $ blpk decompress data.dat.blp data.dcmp\n\nOr:\n\n.. code-block:: console\n\n    $ blpk d data.dat.blp data.dcmp\n\n... will decompress the file ``data.dat.blp`` to the file ``data.dcmp``. If you\nleave out the ``[<out_file>]`` argument, Bloscpack will complain that the file\n``data.dat`` exists already and refuse to overwrite it:\n\n.. code-block:: console\n\n    $ blpk decompress data.dat.blp\n    blpk: error: output file 'data.dat' exists!\n\nIf you know what you are doing, you can use the global option ``[-f |\n--force]`` to override the overwrite checks:\n\n.. code-block:: console\n\n    $ blpk --force decompress data.dat.blp\n\nIncidentally this works for compression too:\n\n.. code-block:: console\n\n    $ blpk compress data.dat\n    blpk: error: output file 'data.dat.blp' exists!\n    $ blpk --force compress data.dat\n\nLastly, if you want a different filename:\n\n.. code-block:: console\n\n    $ blpk compress data.dat custom.filename.blp\n\n... will compress the file ``data.dat`` to ``custom.filename.blp``\n\nSettings\n~~~~~~~~\n\nBy default, the number of threads that Blosc uses during compression and\ndecompression is determined by the number of cores detected on your system.\nYou can change this using the ``[-n | --nthreads]`` option:\n\n.. code-block:: console\n\n    $ blpk --nthreads 1 compress data.dat\n\nCompression with Blosc is controlled with the following options:\n\n* ``[-t | --typesize]``\n  Typesize used by Blosc (default: 8):\n  ``$ blpk compress --typesize 8 data.dat``\n* ``[-l | --level]``\n  Compression level (default: 7):\n  ``$ blpk compress --level 3 data.dat``\n* ``[-s | --no-shuffle]``\n  Deactivate shuffle:\n  ``$ blpk compress --no-shuffle data.dat``\n* ``[-c | --codec]``\n  Use alternative codec:\n  ``$ blpk compress --codec lz4 data.dat``\n\nIn addition, there are the following options that control the Bloscpack file:\n\n* ``[-z | --chunk-size]``\n  Desired approximate size of the chunks, where you can use human readable\n  strings like ``8M`` or ``128K`` or ``max`` to use the maximum chunk size of\n  apprx. ``2GB`` (default: ``1MB``):\n  ``$ blpk compress --chunk-size 128K data.dat`` or\n  ``$ blpk c -z max data.dat``\n* ``[-k | --checksum <checksum>]``\n  Chose which checksum to use. The following values are permissible:\n  ``None``, ``adler32``, ``crc32``, ``md5``,\n  ``sha1``, ``sha224``, ``sha256``, ``sha384``,\n  ``sha512``, (default: ``adler32``). As described in the header format, each\n  compressed chunk can be stored with a checksum, which aids corruption\n  detection on decompression:\n  ``$ blpk compress --checksum crc32 data.dat``\n* ``[-o | --no-offsets]``\n  By default, offsets to the individual chunks are stored. These are included\n  to allow for partial decompression in the future. This option disables that\n  feature. Also, a certain number of offsets (default: 10 * 'nchunks') are\n  preallocated to allow for appending data to the file:\n  ``$ blpk compress --no-offsets data.dat``\n\nInfo Subcommand\n~~~~~~~~~~~~~~~\n\nIf you just need some info on how the file was compressed ``[i | info]``:\n\n.. code-block:: console\n\n    $ blpk info data.dat.blp\n    blpk: BloscpackHeader:\n    blpk:     format_version: 3\n    blpk:     offsets: True\n    blpk:     metadata: False\n    blpk:     checksum: 'adler32'\n    blpk:     typesize: 8\n    blpk:     chunk_size: 1.0M (1048576B)\n    blpk:     last_chunk: 900.0K (921600B)\n    blpk:     nchunks: 1526\n    blpk:     max_app_chunks: 15260\n    blpk: 'offsets':\n    blpk: [134320,459218,735869,986505,1237646,...]\n    blpk: First chunk blosc header:\n    blpk: OrderedDict([('version', 2), ('versionlz', 1), ('flags', 1), ('typesize', 8), ('nbytes', 1048576), ('blocksize', 131072), ('ctbytes', 324894)])\n    blpk: First chunk blosc flags:\n    blpk: OrderedDict([('byte_shuffle', True), ('pure_memcpy', False), ('bit_shuffle', False), ('split_blocks', False), ('codec', 'blosclz')])\n\nImportantly, the header and flag information are for the first chunk only.\nUsually this isn't a problem because bloscpack compressed files do tend to have\nhomogeneous settings like codec used, typesize etc... However, there is nothing\nthat will stop you from appending to an existing bloscpack file using different\nsettings. For example, half the file might be compressed using 'blosclz'\nwhereas the other half of the file might be compressed with 'lz4'. In any case,\njust be aware that the output is to be seen as an indication that is likely to\nbe correct for all chunks but must not be so necessarily.\n\nAdding Metdata\n~~~~~~~~~~~~~~\n\nUsing the ``[-m | --metadata]`` option you can include JSON from a file:\n\n.. code-block:: console\n\n   $ cat meta.json\n   {\"dtype\": \"float64\", \"shape\": [200000000], \"container\": \"numpy\"}\n   $ blpk compress --chunk-size=512M --metadata meta.json data.dat\n   $ blpk info data.dat.blp\n   blpk: BloscpackHeader:\n   blpk:     format_version: 3\n   blpk:     offsets: True\n   blpk:     metadata: True\n   blpk:     checksum: 'adler32'\n   blpk:     typesize: 8\n   blpk:     chunk_size: 512.0M (536870912B)\n   blpk:     last_chunk: 501.88M (526258176B)\n   blpk:     nchunks: 3\n   blpk:     max_app_chunks: 30\n   blpk: 'offsets':\n   blpk: [922,78074943,140783242,...]\n   blpk: 'metadata':\n   blpk: {   u'container': u'numpy', u'dtype': u'float64', u'shape': [200000000]}\n   blpk: MetadataHeader:\n   blpk:     magic_format: 'JSON'\n   blpk:     meta_options: '00000000'\n   blpk:     meta_checksum: 'adler32'\n   blpk:     meta_codec: 'zlib'\n   blpk:     meta_level: 6\n   blpk:     meta_size: 59.0B (59B)\n   blpk:     max_meta_size: 590.0B (590B)\n   blpk:     meta_comp_size: 58.0B (58B)\n   blpk:     user_codec: ''\n\nIt will be printed when decompressing:\n\n.. code-block:: console\n\n    $ blpk decompress data.dat.blp\n    blpk: Metadata is:\n    blpk: '{u'dtype': u'float64', u'shape': [200000000], u'container': u'numpy'}'\n\nAppending\n~~~~~~~~~\n\nYou can also append data to an existing bloscpack compressed file:\n\n.. code-block:: console\n\n   $ blpk append data.dat.blp data.dat\n\nHowever there are certain limitations on the amount of data can be appended.\nFor example, if there is an offsets section, there must be enough room to store\nthe offsets for the appended chunks. If no offsets exists, you may append as\nmuch data as possible given the limitations governed by the maximum number of\nchunks and the chunk-size. Additionally, there are limitations on the\ncompression options. For example, one cannot change the checksum used. It is\nhowever possible to change the compression level, the typesize and the shuffle\noption for the appended chunks.\n\nAlso note that appending is still considered experimental as of ``v0.5.0``.\n\nVerbose and Debug mode\n~~~~~~~~~~~~~~~~~~~~~~\n\nLastly there are two mutually exclusive options to control how much output is\nproduced.\n\nThe first causes basic info to be printed, ``[-v | --verbose]``:\n\n.. code-block:: console\n\n    $ blpk --verbose compress --chunk-size 0.5G data.dat\n    blpk: using 4 threads\n    blpk: getting ready for compression\n    blpk: input file is: 'data.dat'\n    blpk: output file is: 'data.dat.blp'\n    blpk: input file size: 1.49G (1600000000B)\n    blpk: nchunks: 3\n    blpk: chunk_size: 512.0M (536870912B)\n    blpk: last_chunk_size: 501.88M (526258176B)\n    blpk: output file size: 198.39M (208028617B)\n    blpk: compression ratio: 7.691250\n    blpk: done\n\n... and ``[-d | --debug]`` prints a detailed account of what is going on:\n\n.. code-block:: console\n\n    $ blpk --debug compress --chunk-size 0.5G data.dat\n    blpk: command line argument parsing complete\n    blpk: command line arguments are:\n    blpk:     force: False\n    blpk:     verbose: False\n    blpk:     offsets: True\n    blpk:     checksum: adler32\n    blpk:     subcommand: compress\n    blpk:     out_file: None\n    blpk:     metadata: None\n    blpk:     cname: blosclz\n    blpk:     in_file: data.dat\n    blpk:     chunk_size: 536870912\n    blpk:     debug: True\n    blpk:     shuffle: True\n    blpk:     typesize: 8\n    blpk:     clevel: 7\n    blpk:     nthreads: 4\n    blpk: using 4 threads\n    blpk: getting ready for compression\n    blpk: input file is: 'data.dat'\n    blpk: output file is: 'data.dat.blp'\n    blpk: input file size: 1.49G (1600000000B)\n    blpk: nchunks: 3\n    blpk: chunk_size: 512.0M (536870912B)\n    blpk: last_chunk_size: 501.88M (526258176B)\n    blpk: BloscArgs:\n    blpk:     typesize: 8\n    blpk:     clevel: 7\n    blpk:     shuffle: True\n    blpk:     cname: 'blosclz'\n    blpk: BloscpackArgs:\n    blpk:     offsets: True\n    blpk:     checksum: 'adler32'\n    blpk:     max_app_chunks: <function <lambda> at 0x1182de8>\n    blpk: metadata_args will be silently ignored\n    blpk: max_app_chunks is a callable\n    blpk: max_app_chunks was set to: 30\n    blpk: BloscpackHeader:\n    blpk:     format_version: 3\n    blpk:     offsets: True\n    blpk:     metadata: False\n    blpk:     checksum: 'adler32'\n    blpk:     typesize: 8\n    blpk:     chunk_size: 512.0M (536870912B)\n    blpk:     last_chunk: 501.88M (526258176B)\n    blpk:     nchunks: 3\n    blpk:     max_app_chunks: 30\n    blpk: raw_bloscpack_header: 'blpk\\x03\\x01\\x01\\x08\\x00\\x00\\x00 \\x00\\x10^\\x1f\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n    blpk: Handle chunk '0'\n    blpk: checksum (adler32): '\\x1f\\xed\\x1e\\xf4'\n    blpk: chunk handled, in: 512.0M (536870912B) out: 74.46M (78074017B)\n    blpk: Handle chunk '1'\n    blpk: checksum (adler32): ')\\x1e\\x08\\x88'\n    blpk: chunk handled, in: 512.0M (536870912B) out: 59.8M (62708295B)\n    blpk: Handle chunk '2' (last)\n    blpk: checksum (adler32): '\\xe8\\x18\\xa4\\xac'\n    blpk: chunk handled, in: 501.88M (526258176B) out: 64.13M (67245997B)\n    blpk: Writing '3' offsets: '[296, 78074317, 140782616]'\n    blpk: Raw offsets: '(\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\xcdQ\\xa7\\x04\\x00\\x00\\x00\\x00\\x18,d\\x08\\x00\\x00\\x00\\x00'\n    blpk: output file size: 198.39M (208028617B)\n    blpk: compression ratio: 7.691250\n    blpk: done\n\n\nPython API\n----------\n\nBloscpack has a versatile yet simple API consisting of a series of 'arguments'\nobjects and high-level functions that can be invoked dependding on your input\nand output needs.\n\nNomenclature wise, Python 3 has done a lot for Bloscpack, because we always\nneed to represent compressed data as bytes deliberatey. This makes it easier\nand more natural to distinguish between text, such a filenames and binary and\nbytes objects such as compressed data.\n\nArguments\n~~~~~~~~~\n\nThe three argument types are:\n\n* ``BloscArgs``\n* ``BloscpackArgs``\n* ``MetadataArgs``\n\nas defined in ``bloscpack/args.py``.  Instantiating any of them will create an\nobject with the defaults setup. The defaults are defined in\n``bloscpack/defaults.py``. You can use these in the high-level functions listed\nbelow.\n\nYou can override any and all defaults by passing in the respective\nkeyword-arguments, for example:\n\n\n.. code-block:: pycon\n\n   >>> b = BloscArgs()               # will create a default args object\n   >>> b = BloscArgs(clevel=4)       # change compression level to 4\n   >>> b = BloscArgs(typesize=4,     # change the typesize to 4\n   >>> ...           clevel=9,       # change the compression level to 9\n   >>> ...           shuffle=False,  # deactivate the shuffle filter\n   >>> ...           cname='lz4')    # let lz4 be the internal codec\n\n\n.. code-block:: python\n\n    class BloscArgs(MutableMappingObject):\n        \"\"\" Object to hold Blosc arguments.\n\n        Parameters\n        ----------\n        typesize : int\n            The typesize used\n        clevel : int\n            Compression level\n        shuffle : boolean\n            Whether or not to activate the shuffle filter\n        cname: str\n            Name of the internal code to use\n\n        \"\"\"\n\n.. code-block:: python\n\n    class BloscpackArgs(MutableMappingObject):\n        \"\"\" Object to hold BloscPack arguments.\n\n        Parameters\n        ----------\n        offsets : boolean\n            Whether to include space for offsets\n        checksum : str\n            Name of the checksum to use or None/'None'\n        max_app_chunks : int or callable on number of chunks\n            How much space to reserve in the offsets for chunks to be appended.\n\n        \"\"\"\n\n.. code-block:: python\n\n    class MetadataArgs(MutableMappingObject):\n        \"\"\" Object to hold the metadata arguments.\n\n        Parameters\n        ----------\n        magic_format : 8 bytes\n            Format identifier for the metadata\n        meta_checksum : str\n            Checksum to be used for the metadata\n        meta_codec : str\n            Codec to be used to compress the metadata\n        meta_level : int\n            Compression level for metadata\n        max_meta_size : int or callable on metadata size\n            How much space to reserve for additional metadata\n\n        \"\"\"\n\nFile / Bytes\n~~~~~~~~~~~~\n\nThe following high-level functions exist for compressing and decompressing to\nand from files and byte objects:\n\n\n* ``pack_file_to_file``\n* ``unpack_file_from_file``\n* ``pack_bytes_to_file``\n* ``unpack_bytes_from_file``\n* ``pack_bytes_to_bytes``\n* ``unpack_bytes_from_bytes``\n\nBeyond the target arguments such as the files and the bytes, each ``pack_*``\nfunction takes the following arguments:\n\n.. code-block::\n\n    chunk_size : int\n        the desired chunk size in bytes\n    metadata : dict\n        the metadata dict\n    blosc_args : BloscArgs\n        blosc args\n    bloscpack_args : BloscpackArgs\n        bloscpack args\n    metadata_args : MetadataArgs\n        metadata args\n\nBelow are their sigantures:\n\n.. code-block:: python\n\n    def pack_file_to_file(in_file, out_file,\n                          chunk_size=DEFAULT_CHUNK_SIZE,\n                          metadata=None,\n                          blosc_args=None,\n                          bloscpack_args=None,\n                          metadata_args=None):\n\n    def unpack_file_from_file(in_file, out_file):\n\n\n    def pack_bytes_to_file(bytes_, out_file,\n                           chunk_size=DEFAULT_CHUNK_SIZE,\n                           metadata=None,\n                           blosc_args=None,\n                           bloscpack_args=None,\n                           metadata_args=None):\n\n    def unpack_bytes_from_file(compressed_file):\n\n    def pack_bytes_to_bytes(bytes_,\n                            chunk_size=DEFAULT_CHUNK_SIZE,\n                            metadata=None,\n                            blosc_args=None,\n                            bloscpack_args=None,\n                            metadata_args=None,\n                            ):\n\n\n    def unpack_bytes_from_bytes(bytes_):\n\nNumpy\n~~~~~\n\nNumpy arrays can be serialized as Bloscpack files, here is a very brief example:\n\n.. code-block:: pycon\n\n    >>> a = np.linspace(0, 1, 3e8)\n    >>> print a.size, a.dtype\n    300000000 float64\n    >>> bp.pack_ndarray_to_file(a, 'a.blp')\n    >>> b = bp.unpack_ndarray_from_file('a.blp')\n    >>> (a == b).all()\n    True\n\nLooking at the generated file, we can see the Numpy metadata being saved:\n\n.. code-block:: console\n\n    $ lh a.blp\n    -rw------- 1 esc esc 266M Aug 13 23:21 a.blp\n\n    $ blpk info a.blp\n    blpk: BloscpackHeader:\n    blpk:     format_version: 3\n    blpk:     offsets: True\n    blpk:     metadata: True\n    blpk:     checksum: 'adler32'\n    blpk:     typesize: 8\n    blpk:     chunk_size: 1.0M (1048576B)\n    blpk:     last_chunk: 838.0K (858112B)\n    blpk:     nchunks: 2289\n    blpk:     max_app_chunks: 22890\n    blpk: 'offsets':\n    blpk: [202170,408064,554912,690452,819679,...]\n    blpk: 'metadata':\n    blpk: {   u'container': u'numpy',\n    blpk:     u'dtype': u'<f8',\n    blpk:     u'order': u'C',\n    blpk:     u'shape': [300000000]}\n    blpk: MetadataHeader:\n    blpk:     magic_format: 'JSON'\n    blpk:     meta_options: '00000000'\n    blpk:     meta_checksum: 'adler32'\n    blpk:     meta_codec: 'zlib'\n    blpk:     meta_level: 6\n    blpk:     meta_size: 67.0B (67B)\n    blpk:     max_meta_size: 670.0B (670B)\n    blpk:     meta_comp_size: 62.0B (62B)\n    blpk:     user_codec: ''\n\nAlternatively, we can also use a string as storage:\n\n.. code-block:: pycon\n\n    >>> a = np.linspace(0, 1, 3e8)\n    >>> c = pack_ndarray_to_bytes(a)\n    >>> b = unpack_ndarray_from_bytes(c)\n    >>> (a == b).all()\n    True\n\nOr use alternate compressors:\n\n.. code-block:: pycon\n\n    >>> a = np.linspace(0, 1, 3e8)\n    >>> c = pack_ndarray_to_bytes(a, blosc_args=BloscArgs(cname='lz4'))\n    >>> b = unpack_ndarray_from_bytes(c)\n    >>> (a == b).all()\n    True\n\n\n.. code-block:: python\n\n    def pack_ndarray_to_file(ndarray, filename,\n                             chunk_size=DEFAULT_CHUNK_SIZE,\n                             blosc_args=None,\n                             bloscpack_args=None,\n                             metadata_args=None):\n\n    def pack_ndarray_to_bytes(ndarray,\n                              chunk_size=DEFAULT_CHUNK_SIZE,\n                              blosc_args=None,\n                              bloscpack_args=None,\n                              metadata_args=None):\n\n    def unpack_ndarray_from_file(filename):\n\n    def unpack_ndarray_from_bytes(str_):\n\nIf you are interested in the performance of Bloscpack compared to other\nserialization formats for Numpy arrays, please look at the benchmarks presented\nin `the Bloscpack paper from the EuroScipy 2013 conference proceedings\n<http://arxiv.org/abs/1404.6383>`_.\n\nTesting\n-------\n\nInstalling Dependencies\n~~~~~~~~~~~~~~~~~~~~~~~\n\nTesting requires some additional libraries, which you can install from PyPi\nwith:\n\n.. code-block:: console\n\n    $ pip install -r test_requirements.txt\n    [...]\n\n\nBasic Tests\n~~~~~~~~~~~\n\nBasic tests, runs quickly:\n\n.. code-block:: console\n\n    $ nosetests\n    [...]\n\n\nHeavier Tests\n~~~~~~~~~~~~~\n\nExtended tests using a larger file, may take some time, but will be nice to\nmemory:\n\n.. code-block:: console\n\n    $ nosetests test/test_file_io.py:pack_unpack_hard\n    [...]\n\nExtended tests using a huge file. This one take forever and needs loads (5G-6G)\nof memory and loads of disk-space (10G). Use ``-s`` to print progress:\n\n.. code-block:: console\n\n    $ nosetests -s test/test_file_io.py:pack_unpack_extreme\n    [...]\n\nNote that, some compression/decompression tests create temporary files (on\nUNIXoid systems this is under ``/tmp/blpk*``) which are deleted upon completion\nof the respective test, both successful and unsuccessful, or when the test is\naborted with e.g. ``ctrl-c`` (using ``atexit`` magic).\n\nUnder rare circumstances, for example when aborting the deletion which is\ntriggered on abort you may be left with large files polluting your temporary\nspace.  Depending on your partitioning scheme etc.. doing this repeatedly, may\nlead to you running out of space on the file-system.\n\nCommand Line Interface Tests\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe command line interface is tested with `cram <https://bitheap.org/cram/>`_:\n\n.. code-block:: console\n\n   $ cram --verbose test_cmdline/*.cram\n   [...]\n\n\nCoverage\n~~~~~~~~\n\nTo determine coverage you can pool together the coverage from the cram tests and\nthe unit tests:\n\n.. code-block:: console\n\n    $ COVERAGE=1 cram --verbose test_cmdline/*.cram\n    [...]\n    $nosetests --with-coverage --cover-package=bloscpack\n    [...]\n\nTest Runner\n~~~~~~~~~~~\n\nTo run the command line interface tests and the unit tests and analyse\ncoverage, use the convenience ``test.sh`` runner:\n\n.. code-block:: console\n\n   $ ./test.sh\n   [...]\n\nBenchmark\n---------\n\nUsing the provided ``bench/blpk_vs_gzip.py`` script on a ``Intel(R) Core(TM)\ni7-3667U CPU @ 2.00GHz`` CPU with 2 cores and 4 threads (active\nhyperthreading), cpu frequency scaling activated but set to the ``performance``\ngovernor (all cores scaled to ``2.0 GHz``), 8GB of DDR3 memory and a Luks encrypted\nSSD, we get:\n\n.. code-block:: console\n\n    $ PYTHONPATH=. ./bench/blpk_vs_gzip.py\n    create the test data..........done\n\n    Input file size: 1.49G\n    Will now run bloscpack...\n    Time: 2.06 seconds\n    Output file size: 198.55M\n    Ratio: 7.69\n    Will now run gzip...\n    Time: 134.20 seconds\n    Output file size: 924.05M\n    Ratio: 1.65\n\nAs was expected from previous benchmarks of Blosc using the python-blosc\nbindings, Blosc is both much faster and has a better compression ratio for this\nkind of structured data. One thing to note here, is that we are not dropping\nthe system file cache after every step, so the file to read will be cached in\nmemory. To get a more accurate picture we can use the ``--drop-caches`` switch\nof the benchmark which requires you however, to run the benchmark as root,\nsince dropping the caches requires root privileges:\n\n.. code-block:: console\n\n    $ PYTHONPATH=. ./bench/blpk_vs_gzip.py --drop-caches\n    will drop caches\n    create the test data..........done\n\n    Input file size: 1.49G\n    Will now run bloscpack...\n    Time: 13.49 seconds\n    Output file size: 198.55M\n    Ratio: 7.69\n    Will now run gzip...\n    Time: 137.49 seconds\n    Output file size: 924.05M\n    Ratio: 1.65\n\nOptimizing Chunk Size\n---------------------\n\nYou can use the provided ``bench/compression_time_vs_chunk_size.py`` file\nto optimize the chunk-size for a given machine. For example:\n\n.. code-block:: console\n\n    $ sudo env PATH=$PATH PYTHONPATH=.  bench/compression_time_vs_chunk_size.py\n    create the test data..........done\n    chunk_size    comp-time       decomp-time      ratio\n    512.0K        8.106235        10.243908        7.679094\n    724.08K       4.424007        12.284307        7.092846\n    1.0M          6.243544        11.978932        7.685173\n    1.41M         4.715511        10.780901        7.596981\n    2.0M          4.548568        10.676304        7.688216\n    2.83M         4.851359        11.668394        7.572480\n    4.0M          4.557665        10.127647        7.689736\n    5.66M         4.589349        9.579627         7.667467\n    8.0M          5.290080        10.525652        7.690499\n\nRunning the script requires super user privileges, since you need to\nsynchronize disk writes and drop the file system caches for less noisy results.\nAlso, you should probably run this script a couple of times and inspect the\nvariability of the results.\n\n\nBloscpack Format\n----------------\n\nThe input is split into chunks since a) we wish to put less stress on main\nmemory and b) because Blosc has a buffer limit of ``2GB`` (Version ``1.0.0`` and\nabove). By default the chunk-size is a moderate ``1MB`` which should be fine,\neven for less powerful machines.\n\nIn addition to the chunks some additional information must be added to the file\nfor housekeeping:\n\n:header:\n    a 32 bit header containing various pieces of information\n:meta:\n    a variable length metadata section, may contain user data\n:offsets:\n    a variable length section containing chunk offsets\n:chunk:\n    the blosc chunk(s)\n:checksum:\n    a checksum following each chunk, if desired\n\nThe layout of the file is then::\n\n    |-header-|-meta-|-offsets-|-chunk-|-checksum-|-chunk-|-checksum-|...|\n\nDescription of the header\n~~~~~~~~~~~~~~~~~~~~~~~~~\nThe following 32 bit header is used for Bloscpack as of version ``0.3.0``.  The\ndesign goals of the header format are to contain as much information as\npossible to achieve interesting things in the future and to be as general as\npossible such that the persistence layer of `Blaze\n<https://github.com/ContinuumIO/blaze>`_/`BLZ\n<https://github.com/ContinuumIO/blz/tree/master>`_ can be implemented without\nmodification of the header format.\n\nThe following ASCII representation shows the layout of the header::\n\n    |-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n    | b   l   p   k | ^ | ^ | ^ | ^ |   chunk-size  |  last-chunk   |\n                      |   |   |   |\n          version ----+   |   |   |\n          options --------+   |   |\n         checksum ------------+   |\n         typesize ----------------+\n\n    |-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n    |            nchunks            |        max-app-chunks         |\n\nThe first 4 bytes are the magic string ``blpk``. Then there are 4 bytes which\nhold information about the activated features in this file.  This is followed\nby 4 bytes for the ``chunk-size``, another 4 bytes for the ``last-chunk-size``,\n8 bytes for the number of chunks, ``nchunks`` and lastly 8 bytes for the total\nnumber of chunks that can be appended to this file, ``max-app-chunks``.\n\nEffectively, storing the number of chunks as a signed 8 byte integer, limits\nthe number of chunks to ``2**63-1 = 9223372036854775807``, but this should not\nbe relevant in practice, since, even with the moderate default value of ``1MB``\nfor chunk-size, we can still store files as large as ``8ZB`` (!) Given that\nin 2012 the maximum size of a single file in the Zettabye File System (zfs) is\n``16EB``, Bloscpack should be safe for a few more years.\n\nDescription of the header entries\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAll entries are little-endian.\n\n:version:\n    (``uint8``)\n    format version of the Bloscpack header, to ensure exceptions in case of\n    forward incompatibilities.\n:options:\n    (``bitfield``)\n    A bitfield which allows for setting certain options in this file.\n\n    :``bit 0 (0x01)``:\n        If the offsets to the chunks are present in this file.\n    :``bit 1 (0x02)``:\n        If metadata is present in this file.\n\n:checksum:\n    (``uint8``)\n    The checksum used. The following checksums, available in the python\n    standard library should be supported. The checksum is always computed on\n    the compressed data and placed after the chunk.\n\n    :``0``:\n        ``no checksum``\n    :``1``:\n        ``zlib.adler32``\n    :``2``:\n        ``zlib.crc32``\n    :``3``:\n        ``hashlib.md5``\n    :``4``:\n        ``hashlib.sha1``\n    :``5``:\n        ``hashlib.sha224``\n    :``6``:\n        ``hashlib.sha256``\n    :``7``:\n        ``hashlib.sha384``\n    :``8``:\n        ``hashlib.sha512``\n:typesize:\n    (``uint8``)\n    The typesize of the data in the chunks. Currently, assume that the typesize\n    is uniform. The space allocated is the same as in the Blosc header.\n:chunk-size:\n    (``int32``)\n    Denotes the chunk-size. Since the maximum buffer size of Blosc is 2GB\n    having a signed 32 bit int is enough (``2GB = 2**31 bytes``). The special\n    value of ``-1`` denotes that the chunk-size is unknown or possibly\n    non-uniform.\n:last-chunk:\n    (``int32``)\n    Denotes the size of the last chunk. As with the ``chunk-size`` an ``int32``\n    is enough. Again, ``-1`` denotes that this value is unknown.\n:nchunks:\n    (``int64``)\n    The total number of chunks used in the file. Given a chunk-size of one\n    byte, the total number of chunks is ``2**63``. This amounts to a maximum\n    file-size of 8EB (``8EB = 2*63 bytes``) which should be enough for the next\n    couple of years. Again, ``-1`` denotes that the number of is unknown.\n:max-app-chunks:\n    (``int64``)\n    The maximum number of chunks that can be appended to this file, excluding\n    ``nchunks``. This is only useful if there is an offsets section and if\n    nchunks is known (not ``-1``), if either of these conditions do not apply\n    this should be ``0``.\n\nThe overall file-size can be computed as ``chunk-size * (nchunks - 1) +\nlast-chunk-size``. In a streaming scenario ``-1`` can be used as a placeholder.\nFor example if the total number of chunks, or the size of the last chunk is not\nknown at the time the header is created.\n\nThe following constraints exist on the header entries:\n\n* ``last-chunk`` must be less than or equal to ``chunk-size``.\n* ``nchunks + max_app_chunks`` must be less than or equal to the maximum value\n  of an ``int64``.\n\n\nDescription of the metadata section\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis section goes after the header. It consists of a metadata-section header\nfollowed by a serialized and potentially compressed data section, followed by\npreallocated space to resize the data section, possibly followed by a checksum.\n\nThe layout of the section is thus::\n\n    |-metadata-header-|-data-|-prealloc-|-checksum-|\n\nThe header has the following layout::\n\n   |-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n   |         magic-format          | ^ | ^ | ^ | ^ |   meta-size   |\n                                     |   |   |   |\n                 meta-options -------+   |   |   |\n                 meta-checksum ----------+   |   |\n                 meta-codec -----------------+   |\n                 meta-level ---------------------+\n\n   |-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n   | max-meta-size |meta-comp-size |            user-codec         |\n\n:magic-format:\n    (``8 byte ASCII string``)\n    The data will usually be some kind of binary serialized string data, for\n    example ``JSON``, ``BSON``, ``YAML`` or Protocol-Buffers. The format\n    identifier is to be placed in this field.\n:meta-options:\n    (``bitfield``)\n    A bitfield which allows for setting certain options in this metadata\n    section. Currently unused\n:meta-checksum:\n    The checksum used for the metadata. The same checksums as for the data are\n    available.\n:meta-codec:\n    (``unit8``)\n    The codec used for compressing the metadata. As of Bloscpack version\n    ``0.3.0`` the following codecs are supported.\n\n    :``0``:\n        no codec\n    :``1``:\n        ``zlib`` (DEFLATE)\n\n:meta-level:\n    (``unit8``)\n    The compression level used for the codec. If ``codec`` is ``0`` i.e. the\n    metadata is not compressed, this must be ``0`` too.\n:meta-size:\n    (``uint32``)\n    The size of the uncompressed metadata.\n:max-meta-size:\n    (``uint32``)\n    The total allocated space for the data section.\n:meta-comp-size:\n    (``uint32``)\n    If the metadata is compressed, this gives the total space the metadata\n    occupies. If the data is not compressed this is the same as ``meta-size``.\n    In a sense this is the true amount of space in the metadata section that is\n    used.\n:user-codec:\n    Space reserved for usage of additional codecs. E.g. 4 byte magic string for\n    codec identification and 4 bytes for encoding of codec parameters.\n\nThe total space left for enlarging the metadata section is simply:\n``max-meta-size - meta-comp-size``.\n\nJSON Example of serialized metadata::\n\n  '{\"dtype\": \"float64\", \"shape\": [1024], \"others\": []}'\n\nIf compression is requested, but not beneficial, because the compressed size\nwould be larger than the uncompressed size, compression of the metadata is\nautomatically deactivated.\n\nAs of Bloscpack version ``0.3.0`` only the JSON serializer is supported and\nused the string ``JSON`` followed by four whitespace bytes as identifier.\nSince JSON and any other of the suggested serializers has limitations, only a\nsubset of Python structures can be stored, so probably some additional object\nhandling must be done prior to serialize certain kinds of metadata.\n\nDescription of the offsets entries\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFollowing the metadata section, comes a variable length section of chunk\noffsets. Offsets of the chunks into the file are to be used for accelerated\nseeking. The offsets (if activated) follow the header. Each offset is a 64 bit\nsigned little-endian integer (``int64``). A value of ``-1`` denotes an unknown\noffset. Initially, all offsets should be initialized to ``-1`` and filled in\nafter writing all chunks. Thus, If the compression of the file fails\nprematurely or is aborted, all offsets should have the value ``-1``.  Also, any\nunused offset entries preallocated to allow the file to grow should be set to\n``-1``. Each offset denotes the exact position of the chunk in the file such\nthat seeking to the offset, will position the file pointer such that, reading\nthe next 16 bytes gives the Blosc header, which is at the start of the desired\nchunk.\n\nDescription of the chunk format\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAs mentioned previously, each chunk is just a Blosc compressed string including\nheader. The Blosc header (as of ``v1.0.0``) is 16 bytes as follows::\n\n    |-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n      ^   ^   ^   ^ |     nbytes    |   blocksize   |    ctbytes    |\n      |   |   |   |\n      |   |   |   +--typesize\n      |   |   +------flags\n      |   +----------versionlz\n      +--------------version\n\nThe first four are simply bytes, the last three are are each unsigned ints\n(``uint32``) each occupying 4 bytes. The header is always little-endian.\n``ctbytes`` is the length of the buffer including header and ``nbytes`` is the\nlength of the data when uncompressed. A more detailed description of the Blosc\nheader can be found in the `README_HEADER.rst of the Blosc repository\n<https://github.com/FrancescAlted/blosc/blob/master/README_HEADER.rst>`_\n\nOverhead\n~~~~~~~~\n\nDepending on which configuration for the file is used a constant, or linear\noverhead may be added to the file. The Bloscpack header adds 32 bytes in any\ncase. If the data is non-compressible, Blosc will add 16 bytes of header to\neach chunk. The metadata section obviously adds a constant overhead, and if\nused, both the checksum and the offsets will add overhead to the file. The\noffsets add 8 bytes per chunk and the checksum adds a fixed constant value\nwhich depends on the checksum to each chunk. For example, 32 bytes for the\n``adler32`` checksum.\n\nCoding Conventions\n------------------\n\n* Numpy rst style docstrings\n* README cli examples should use long options\n* testing: expected before received ``nt.assert_equal(expected, received)``\n* Debug messages: as close to where the data was generated\n* Single quotes around ambiguities in messages ``overwriting existing file: 'testfile'``\n* Exceptions instead of exit\n* nose test generators parameterized tests\n* Use the Wikipedia definition of compression ratio:\n  http://en.wikipedia.org/wiki/Data_compression_ratio\n\nHow to Optimize Logging\n-----------------------\n\nSome care must be taken when logging in the inner loop. For example consider the\nfollowing two commits:\n\n* https://github.com/Blosc/bloscpack/commit/0854930514eebaf7dbc6c4dcf3589dbcb9f2fdc9\n\n* https://github.com/Blosc/bloscpack/commit/355bf90a8c13a2a1f792d43228c2a68c61476621\n\nIf there are a larger number of chunks, calls to ``double_pretty_size`` will be\nexecuted (and may be costly) *even* if no logging is needed.\n\nConsider the following script, ``loop-bench.py``:\n\n.. code-block:: python\n\n    import numpy as np\n    import bloscpack as bp\n    import blosc\n\n    shuffle = True\n    clevel = 9\n    cname = 'lz4'\n\n    a = np.arange(2.5e8)\n\n    bargs = bp.args.BloscArgs(clevel=clevel, shuffle=shuffle, cname=cname)\n    bpargs = bp.BloscpackArgs(offsets=False, checksum='None', max_app_chunks=0)\n\nTiming with ``v0.7.0``:\n\n.. code-block:: pycon\n\n    In [1]: %run loop-bench.py\n\n    In [2]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n    1 loops, best of 3: 423 ms per loop\n\n    In [3]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n    1 loops, best of 3: 421 ms per loop\n\n    In [4]: bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n\n    In [5]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n    1 loops, best of 3: 727 ms per loop\n\n    In [6]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n    1 loops, best of 3: 725 ms per loop\n\nAnd then using a development version that contains the two optimization commits:\n\n.. code-block:: pycon\n\n    In [1]: %run loop-bench.py\n\n    In [2]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n    1 loops, best of 3: 357 ms per loop\n\n    In [3]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n    1 loops, best of 3: 357 ms per loop\n\n    In [4]: bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n\n    In [5]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n    1 loops, best of 3: 658 ms per loop\n\n    In [6]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n    1 loops, best of 3: 655 ms per loop\n\nComparison to HDF5/PyTables\n---------------------------\n\nSince Blosc has already been supported for use in HDF5 files from within\nPyTables, one might be tempted to question why yet another file format has to\nbe invented. This section aims to differentiate between HDF5/PyTables and\neffectively argues that they are not competitors.\n\n* Lightweight vs. Heavyweight. Bloscpack is a lightweight format. The format\n  specification can easily be digested within a day and the dependencies are\n  minimal. PyTables is a complex piece of software and the HDF5 file format\n  specification is a large document.\n\n* Persistence vs. Database. Bloscpack is designed to allow for fast\n  serialization and deserialization of in-memory data. PyTables is more of a\n  database which for example allows complex queries to be computed on the\n  data.\n\nAdditionally there are two network uses cases which Bloscpack is suited for\n(but does not have support for as of yet):\n\n#. Streaming: Since bloscpack without offsets can be written in a single\n   pass it is ideally suited for streaming over a network, where you can\n   compress send and decompress individual chunks in a streaming fashion.\n\n#. Expose a file over HTTP and do partial reads from it, for example when\n   storing a compressed file in S3. You can easily just store a file on a\n   web server and then use the header information to read and decompress\n   individual chunks.\n\nPrior Art\n---------\n\nThe following is a  list of important resources that were read during the\nconception and initial stages of Bloscpack.\n\n* The `6pack utility included with FastLZ\n  <https://github.com/ariya/FastLZ/blob/master/6pack.c>`_ (the codec that\n  BloscLZ was derived from) was the initial inspiration for writing a command\n  line interface to Blosc.\n\n* The `Wikipedia article on the PNG format\n  <http://en.wikipedia.org/wiki/Portable_Network_Graphics>`_ contains some\n  interesting details about the PNG header and file headers in general.\n\n* The `XZ File Format Specification\n  <http://tukaani.org/xz/xz-file-format.txt>`_ gave rise to some ideas and\n  techniques about writing file format specifications and using checksums for\n  data integrity. Although the format and the document itself was a bit to\n  heavyweight for my tastes.\n\n* The `Snappy framing format\n  <http://code.google.com/p/snappy/source/browse/trunk/framing_format.txt>`_\n  and the `file container format for LZ4\n  <http://fastcompression.blogspot.de/2012/04/file-container-format-for-lz4.html>`_\n  were also consulted, but I can't remember if and what inspiration they gave\n  rise to.\n\n* The homepages of `zlib <http://www.zlib.net/>`_ and `gzip\n  <http://www.gzip.org/>`_ were also consulted at some point. The command line\n  interface of `gzip/gunzip` was deemed to be from a different era and as a\n  result git-style subcommands are used in Bloscpack.\n\nResources and Related Publications\n----------------------------------\n\n* `Main Blosc website <http://www.blosc.org>`_\n* `Francesc Alted. *The Data Access Problem* EuroScipy 2009 Keynote Presentation <http://www.blosc.org/docs/StarvingCPUs.pdf>`_\n* `Francesc Alted. *Why modern CPUs are starving and what can be done about it*, Computing in Science & Engineering, Vol. 12, No. 2. (March 2010), pp. 68-71 <http://www.blosc.org/docs/StarvingCPUs-CISE-2010.pdf>`_\n* Francesc Alted: Sending Data from Memory to CPU (and back) faster than memcpy(). PyData London 2014 `slides0 <http://www.slideshare.net/PyData/blosc-py-data-2014>`_ `video0 <http://www.youtube.com/watch?v=IzqlWUTndTo>`_\n* `The Blosc Github organization <https://github.com/Blosc>`_\n* `Valentin Haenel. *Introducing Bloscpack* EuroScipy 2013 Presentation <https://github.com/esc/euroscipy2013-talk-bloscpack>`_\n* `Valentin Haenel. *Bloscpack: a compressed lightweight serialization format for numerical data*. Proceedings of the 6th European Conference on Python in Science (EuroSciPy 2013) <http://arxiv.org/abs/1404.6383>`_.\n* Valentin Haenel. *Fast Serialization of Numpy Arrays with Bloscpack*. PyData Berlin 2014 `slides1 <http://slides.zetatech.org/haenel-bloscpack-talk-2014-PyDataBerlin.pdf>`_, `video1 <https://www.youtube.com/watch?v=TZdqeEd7iTM>`_\n\nMaintainers Notes on Cutting a Release\n--------------------------------------\n\n#. Set the version as environment variable ``VERSION=vX.X.X``\n#. Update the changelog and ``ANNOUNCE.rst``\n#. Commit using ``git commit -m \"$VERSION changelog and ANNOUNCE.rst\"``\n#. Set the version number in ``bloscpack/version.py``\n#. Commit with ``git commit -m \"$VERSION\"``\n#. Make the tag using ``git tag -s -m \"Bloscpack $VERSION\" $VERSION``\n#. Push commits to Blosc github ``git push blosc master``\n#. Push commits to own github ``git push esc master``\n#. Push the tag to Blosc github ``git push blosc $VERSION``\n#. Push the tag to own github ``git push esc $VERSION``\n#. Make a source distribution using ``python setup.py sdist bdist_wheel``\n#. Upload to PyPi using ``twine upload dist/bloscpack-$VERSION*``\n#. Bump version number to next dev version and reset ``ANNOUNCE.rst``\n#. Announce release on the Blosc list\n#. Announce release via Twitter\n\nTODO\n----\n\nDocumentation\n~~~~~~~~~~~~~\n\n* Refactor monolithic readme into Sphinx and publish\n* Cleanup and double check the docstrings for the public API classes\n\nCommand Line\n~~~~~~~~~~~~\n\n* quiet verbosity level\n* Expose the ability to set 'max_app_chunks' from the command line\n* Allow to save metadata to a file during decompression\n* subcommand e or estimate to estimate the size of the uncompressed data.\n* subcommand v or verify to verify the integrity of the data\n* add --raw-input and --raw-output switches to allow stuff like:\n  cat file | blpk --raw-input --raw-output compress > file.blp\n* Establish and document proper exit codes\n* Document the metadata saved during Numpy serialization\n\nProfiling and Optimization\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Use the faster version of struct where you have a single string\n* Memory profiler, might be able to reduce memory used by reusing the buffer\n  during compression and decompression\n* Benchmark different codecs\n* Use line profiler to check code\n* Select different defaults for Numpy arrays, no offsets? no pre-alloc?\n\nLibrary Features\n~~~~~~~~~~~~~~~~\n\n* possibly provide a BloscPackFile abstraction, like GzipFile\n* Allow to not-prealloc additional space for metadata\n* Refactor certain collections of functions that operate on data into objects\n\n  * Offsets (maybe)\n\n* partial decompression?\n* since we now have potentially small chunks, the progressbar becomes relevant\n  again\n* configuration file to store commonly used options on a given machine\n* print the compression time, either as verbose or debug\n* Investigate if we can use a StringIO object that returns memoryviews on read.\n* Implement a memoryview Compressed/PlainSource\n* Use a bytearray to read chunks from a file. Then re-use that bytearray\n  during every read to avoid allocating deallocating strings the whole time.\n* The keyword arguments to many functions are global dicts, this is a bad idea,\n  Make the immutable with a forzendict.\n* Check that the checksum is really being checked for all PlainSinks\n* Bunch of NetworkSource/Sinks\n* HTTPSource/Sink\n\nMiscellaneous\n~~~~~~~~~~~~~\n\n* Announce on scipy/numpy lists, comp.compression, freshmeat, ohloh ...\n\nPackaging and Infrastructure\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Debian packages (for python-blosc and bloscpack)\n* Conda recipes (for python-blosc and bloscpack)\n* Use tox for testing multiple python versions\n* Build on travis and drone.io using pre-compiled\n\n\nChangelog\n---------\n\n* v0.16.0     - Thu 27 Dec 2018\n\n  * Update of Python API and docs\n  * various minor fixes\n\n* v0.15.0     - Wed 31 Oct 2018\n\n  * Halloween Release!\n  * Adding the Blosc code of conduct (#79 by @esc)\n  * Two new high-level functions: 'pack_bytes_to_bytes' and\n    'unpack_bytes_from_bytes' (#83 by @esc)\n  * Fix incorrect check for typesize-chunksize mismatch (#81 by @esc)\n  * Fix test to append without shuffle (#82 by @esc)\n  * Fix tests to respect snappy not being available by default (#85 by @esc)\n  * Fix tests to account for new default blocksize (#86 by @esc)\n  * Enable testing on Python 3.7 via Travis (#84 by @esc)\n\n* v0.14.0     - Thu Oct 18 2018\n\n  * Remove official support for Python 2.6 (#77 by @esc)\n\n* v0.13.0     - Thu May 24 2018\n\n  * Add license file and include in sdist packages (#75 by @toddrme2178)\n  * Print codec on info (#73 by @esc)\n  * Decode Blosc flags (#72 by @esc)\n  * Fix an embarrassing typo (#71 by @esc)\n  * Test zstd (#70 by @esc)\n  * Document args object (#69 by @esc)\n  * Various pep8 fixes by @esc\n  * Support for uploading wheels and using twine by @esc\n  * Fix use of coverage by @esc\n  * Better support for Python 2.6 by @esc\n\n* v0.12.0     - Fri Mar 09 2018\n\n  * Allow Pythonic None as checksum (#60 by @esc)\n  * Fix failing tests to comply with latest Blosc (#63 and #64 by FrancescElies)\n  * Support testing with Python 3.6 via Travis (#65 by @esc)\n  * Unpinn Blosc in conda recipe (who uses this?) (#61 by @esc)\n  * Cleanup README (#66 by @esc)\n  * Fix Trove classifiers (#67 by @esc)\n  * Random pep8 fixes by @esc\n\n* v0.11.0     - Mon Aug 22 2016\n\n  * Unpinn python-blosc and fix unit-tests (#51 and #57 fixed by @oogali)\n  * Improve the computation of the chunksize when it is not divisible by\n    typesize (#52 by FrancescAlted)\n\n* v0.10.0     - Thu Dec 10 2015\n\n  * Fix for compressing sliced arrays (#43 reported by @mistycheney)\n  * Fix ``un/pack_bytes_file`` to be available from toplevel\n  * Fix the badges to come (mostly) from https://img.shields.io\n  * Fixes for travis-ci, test Python 3.5 too\n  * Pin Blosc version to 1.2.7 via `requirements.txt` and `setup.py` due to\n    breakage with Blosc 1.2.8.\n\n* v0.9.0     - Tue Aug 18 2015\n\n  * Use ``ast.literal_eval`` instead of ``np.safe_eval`` which is much faster (#39 @cpcloud)\n  * Support for packing/unpacking bytes to/from file (#41)\n\n* v0.8.0     - Sun Jul 12 2015\n\n  * Python 3.x compatibility (#14)\n\n* v0.7.3     - Sat Jul 11 2015\n\n  * Fix deserialization of numpy arrays with nested dtypes that were created\n    with versions v0.7.1 and before. (#37)\n\n* v0.7.2     - Wed Mar 25 2015\n\n  * Fix support for zero length arrays (and input in general) (#17 reported by @dmbelov)\n  * Catch when ``typesize`` doesn't divide ``chunk_size`` (#18 reported by @dmbelov)\n  * Fix serialization of object arrays (#16 reported by @dmbelov)\n  * Reject Object dtype arrays since they cannot be compressed with Bloscpack\n  * Provide backwards compatibility for older Numpy serializations\n  * Fix win32 compatibility of tests (#27 fixed by @mindw)\n  * Fix using setuptools for scripts and dependencies (#28 fixed by @mindw)\n  * Various misc fixes\n\n* v0.7.1     - Sun Jun 29 2014\n\n  * Fix a bug related to setting the correct typesize when compressing Numpy\n    arrays\n  * Optimization of debug statements in the inner loops\n\n* v0.7.0     - Wed May 28 2014\n\n  * Modularize cram tests, even has something akin to a harness\n  * Refactored, tweaked and simplified Source/Sink code and semantics\n  * Various documentation improvements: listing prior art, comparison to HDF5\n  * Improve benchmarking scripts\n  * Introduce a BloscArgs object for saner handling of the BloscArgs\n  * Introduce a BloscpackArgs object for saner handling of the BloscpackArgs\n  * Introduce MetadataHeader and MetdataArgs objects too\n  * Fix all (hopefully) incorrect uses of the term 'compression ratio'\n  * Various miscellaneous fixes and improvements\n\n* v0.6.0     - Fri Mar 28 2014\n\n  * Complete refactor of Bloscpack codebase to support modularization\n  * Support for `drone.io <https://drone.io/>`_ CI service\n  * Improved dependency specification for Python 2.6\n  * Improved installation instructions\n\n* v0.5.2     - Fri Mar 07 2014\n\n  * Fix project url in setup.py\n\n* v0.5.1     - Sat Feb 22 2014\n\n  * Documentation fixes and improvements\n\n* v0.5.0     - Sun Feb 02 2014\n\n  * Moved project to the `Blosc organization on Github <https://github.com/Blosc>`_\n\n* v0.5.0-rc1 - Thu Jan 30 2014\n\n  * Support for Blosc 1.3.x (alternative codecs)\n\n* v0.4.1     - Fri Sep 27 2013\n\n  * Fixed the `pack_unpack_hard` test suite\n  * Fixed handling Numpy record and nested record arrays\n\n* v0.4.0     - Sun Sep 15 2013\n\n  * Fix a bug when serializing numpy arrays to strings\n\n* v0.4.0-rc2 - Tue Sep 03 2013\n\n  * Package available via PyPi (since 0.4.0-rc1)\n  * Support for packing/unpacking numpy arrays to/from string\n  * Check that string and record arrays work\n  * Fix installation problems with PyPi package (Thanks to Olivier Grisel)\n\n* v0.4.0-rc1 - Sun Aug 18 2013\n\n  * BloscpackHeader class introduced\n  * The info subcommand shows human readable sizes when printing the header\n  * Now using Travis-CI for testing and Coveralls for coverage\n  * Further work on the Plain/Compressed-Source/Sink abstractions\n  * Start using memoryview in places\n  * Learned to serialize Numpy arrays\n\n* v0.3.0     - Sun Aug 04 2013\n\n  * Minor readme fixes\n  * Increase number of cram tests\n\n* v0.3.0-rc1 - Thu Aug 01 2013\n\n  * Bloscpack format changes (format version 3)\n\n    * Variable length metadata section with it's own header\n    * Ability to preallocate offsets for appending data (``max_app_chunks``)\n\n  * Refactor compression and decompression to use file pointers instead of\n    file name strings, allows using StringIO/cStringIO.\n  * Sanitize calculation of nchunks and chunk-size\n  * Special keyword ``max`` for use with chunk-size in the CLI\n  * Support appending to a file and ``append`` subcommand\n    (including the ability to preallocate offsets)\n  * Support rudimentary ``info`` subcommand\n  * Add tests of the command line interface using ``cram``\n  * Minor bugfixes and corrections as usual\n\n* v0.2.1     - Mon Nov 26 2012\n\n  * Backport to Python 2.6\n  * Typo fixes in documentation\n\n* v0.2.0     - Fri Sep 21 2012\n\n  * Use ``atexit`` magic to remove test data on abort\n  * Change prefix of temp directory to ``/tmp/blpk*``\n  * Merge header RFC into monolithic readme\n\n* v0.2.0-rc2 - Tue Sep 18 2012\n\n  * Don't bail out if the file is smaller than default chunk\n  * Set the default ``typesize`` to ``8`` bytes\n  * Upgrade dependencies to python-blosc ``v1.0.5`` and fix tests\n  * Make extreme test less resource intensive\n  * Minor bugfixes and corrections\n\n* v0.2.0-rc1 - Thu Sep 13 2012\n\n  * Implement new header format as described in RFC\n  * Implement checksumming compressed chunks with various checksums\n  * Implement offsets of the chunks into the file\n  * Efforts to make the library re-entrant, better control of side-effects\n  * README is now rst not md (flirting with sphinx)\n  * Tons of trivial fixes, typos, wording, refactoring, renaming, pep8 etc..\n\n* v0.1.1     - Sun Jul 15 2012\n\n  * Fix the memory issue with the tests\n  * Two new suites: ``hard`` and ``extreme``\n  * Minor typo fixes and corrections\n\n* v0.1.0     - Thu Jun 14 2012\n\n  * Freeze the first 8 bytes of the header (hopefully for ever)\n  * Fail to decompress on non-matching format version\n  * Minor typo fixes and corrections\n\n* v0.1.0-rc3 - Tue Jun 12 2012\n\n  * Limit the chunk-size benchmark to a narrower range\n  * After more careful experiments, a default chunk-size of ``1MB`` was\n    deemed most appropriate\n\n  * Fixed a terrible bug, where during testing and benchmarking, temporary\n    files were not removed, oups...\n\n  * Adapted the header to have space for more chunks, include special marker\n    for unknown chunk number (``-1``) and format version of the compressed\n    file\n  * Added a note in the README about instability of the file format\n  * Various minor fixes and enhancements\n\n* v0.1.0-rc2 - Sat Jun 09 2012\n\n  * Default chunk-size now ``4MB``\n  * Human readable chunk-size argument\n  * Last chunk now contains remainder\n  * Pure python benchmark to compare against gzip\n  * Benchmark to measure the effect of chunk-size\n  * Various minor fixes and enhancements\n\n* v0.1.0-rc1 - Sun May 27 2012\n\n  * Initial version\n  * Compression/decompression\n  * Command line argument parser\n  * README, setup.py, tests and benchmark\n\nThanks\n------\n\n* Francesc Alted for writing Blosc in the first place, for providing continual\n  code-review and feedback on Bloscpack and for co-authoring the Bloscpack\n  file-format specification.\n\nAuthor, Copyright and License\n-----------------------------\n\n\u00a9 2012-2018 Valentin Haenel <valentin@haenel.co>\n\nBloscpack is licensed under the terms of the MIT License.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/blosc/bloscpack", "keywords": "compression,applied information theory", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "bloscpack", "package_url": "https://pypi.org/project/bloscpack/", "platform": "", "project_url": "https://pypi.org/project/bloscpack/", "project_urls": {"Homepage": "https://github.com/blosc/bloscpack"}, "release_url": "https://pypi.org/project/bloscpack/0.16.0/", "requires_dist": ["blosc", "numpy", "six", "deprecated", "nose; extra == 'tests'", "cram (>=0.6); extra == 'tests'", "mock; extra == 'tests'", "coverage; extra == 'tests'", "coveralls; extra == 'tests'", "twine; extra == 'tests'", "wheel; extra == 'tests'"], "requires_python": "", "summary": "Command line interface to and serialization format for Blosc", "version": "0.16.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <table>\n<col>\n<col>\n<tbody>\n<tr><th>Author:</th>\n<td>Valentin H\u00e4nel</td></tr>\n<tr><th>Contact:</th>\n<td><a href=\"mailto:valentin%40haenel.co\">valentin<span>@</span>haenel<span>.</span>co</a></td></tr>\n<tr><th>List:</th><td><a href=\"http://groups.google.com/group/blosc\" rel=\"nofollow\">http://groups.google.com/group/blosc</a></td>\n</tr>\n<tr><th>Github:</th><td><a href=\"https://github.com/Blosc/bloscpack\" rel=\"nofollow\">https://github.com/Blosc/bloscpack</a></td>\n</tr>\n<tr><th>PyPi:</th><td><a href=\"https://pypi.python.org/pypi/bloscpack\" rel=\"nofollow\">https://pypi.python.org/pypi/bloscpack</a></td>\n</tr>\n<tr><th>Anaconda:</th><td><a href=\"https://anaconda.org/pypi/bloscpack\" rel=\"nofollow\">https://anaconda.org/pypi/bloscpack</a></td>\n</tr>\n<tr><th>Ohloh:</th><td><a href=\"https://www.ohloh.net/p/bloscpack\" rel=\"nofollow\">https://www.ohloh.net/p/bloscpack</a></td>\n</tr>\n<tr><th>Version:</th>\n<td><a href=\"https://pypi.python.org/pypi/bloscpack\" rel=\"nofollow\"><img alt=\"version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7573e0c9c5fbfb2de7bda3b0fe2adb737f647065/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f626c6f73637061636b2e737667\"></a></td></tr>\n<tr><th>Travis CI:</th><td><a href=\"https://travis-ci.org/Blosc/bloscpack\" rel=\"nofollow\"><img alt=\"travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/50820fd8ff388d236a28b4cef3df5cc539a8383d/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f426c6f73632f626c6f73637061636b2f6d61737465722e737667\"></a></td>\n</tr>\n<tr><th>Coveralls:</th><td><a href=\"https://coveralls.io/github/Blosc/bloscpack?branch=master\" rel=\"nofollow\"><img alt=\"coveralls\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a3890f197c340b99638ef6b92ae76d3f940410a0/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f426c6f73632f626c6f73637061636b2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562\"></a></td>\n</tr>\n<tr><th>Python Versions:</th></tr>\n<tr><td>\u00a0</td><td><a href=\"https://pypi.python.org/pypi/bloscpack\" rel=\"nofollow\"><img alt=\"pyversions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aa1162b3d42a2e5f955798cf6caf530f1fe4b162/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f626c6f73637061636b2e737667\"></a></td>\n</tr>\n<tr><th>License:</th><td><a href=\"https://pypi.python.org/pypi/bloscpack\" rel=\"nofollow\"><img alt=\"license\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f872ea9a25c2b0b75674f5e2d6002f706b417252/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f626c6f73637061636b2e737667\"></a></td>\n</tr>\n<tr><th>And\u2026:</th><td><a href=\"https://blosc.org\" rel=\"nofollow\"><img alt=\"powered\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/339e89c6bb31abe44b956fdf4b3c452b411d56d2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506f776572642d2d42792d426c6f73632d626c75652e737667\"></a></td>\n</tr>\n</tbody>\n</table>\n<div id=\"table-of-contents\">\n<p>Table of Contents</p>\n<ul>\n<li><a href=\"#description\" id=\"id4\" rel=\"nofollow\">Description</a></li>\n<li><a href=\"#code-of-conduct\" id=\"id5\" rel=\"nofollow\">Code of Conduct</a></li>\n<li><a href=\"#dependencies\" id=\"id6\" rel=\"nofollow\">Dependencies</a></li>\n<li><a href=\"#stability-of-file-format\" id=\"id7\" rel=\"nofollow\">Stability of File Format</a></li>\n<li><a href=\"#installation\" id=\"id8\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#usage\" id=\"id9\" rel=\"nofollow\">Usage</a></li>\n<li><a href=\"#examples\" id=\"id10\" rel=\"nofollow\">Examples</a></li>\n<li><a href=\"#python-api\" id=\"id11\" rel=\"nofollow\">Python API</a></li>\n<li><a href=\"#testing\" id=\"id12\" rel=\"nofollow\">Testing</a></li>\n<li><a href=\"#benchmark\" id=\"id13\" rel=\"nofollow\">Benchmark</a></li>\n<li><a href=\"#optimizing-chunk-size\" id=\"id14\" rel=\"nofollow\">Optimizing Chunk Size</a></li>\n<li><a href=\"#bloscpack-format\" id=\"id15\" rel=\"nofollow\">Bloscpack Format</a></li>\n<li><a href=\"#coding-conventions\" id=\"id16\" rel=\"nofollow\">Coding Conventions</a></li>\n<li><a href=\"#how-to-optimize-logging\" id=\"id17\" rel=\"nofollow\">How to Optimize Logging</a></li>\n<li><a href=\"#comparison-to-hdf5-pytables\" id=\"id18\" rel=\"nofollow\">Comparison to HDF5/PyTables</a></li>\n<li><a href=\"#prior-art\" id=\"id19\" rel=\"nofollow\">Prior Art</a></li>\n<li><a href=\"#resources-and-related-publications\" id=\"id20\" rel=\"nofollow\">Resources and Related Publications</a></li>\n<li><a href=\"#maintainers-notes-on-cutting-a-release\" id=\"id21\" rel=\"nofollow\">Maintainers Notes on Cutting a Release</a></li>\n<li><a href=\"#todo\" id=\"id22\" rel=\"nofollow\">TODO</a></li>\n<li><a href=\"#changelog\" id=\"id23\" rel=\"nofollow\">Changelog</a></li>\n<li><a href=\"#thanks\" id=\"id24\" rel=\"nofollow\">Thanks</a></li>\n<li><a href=\"#author-copyright-and-license\" id=\"id25\" rel=\"nofollow\">Author, Copyright and License</a></li>\n</ul>\n</div>\n<div id=\"description\">\n<h2><a href=\"#id4\" rel=\"nofollow\">Description</a></h2>\n<p>Command line interface to and serialization format for <a href=\"http://blosc.org/\" rel=\"nofollow\">Blosc</a>, a high performance, multi-threaded, blocking and\nshuffling compressor. Uses <a href=\"https://github.com/Blosc/python-blosc\" rel=\"nofollow\">python-blosc</a> bindings to interface with Blosc.\nAlso comes with native support for efficiently serializing and deserializing\nNumpy arrays.</p>\n</div>\n<div id=\"code-of-conduct\">\n<h2><a href=\"#id5\" rel=\"nofollow\">Code of Conduct</a></h2>\n<p>The Blosc community has adopted a <a href=\"https://github.com/Blosc/CodeOfConduct\" rel=\"nofollow\">Code of Conduct</a> that we expect project participants\nto adhere to. Please read the full text so that you can understand what actions\nwill and will not be tolerated.</p>\n</div>\n<div id=\"dependencies\">\n<h2><a href=\"#id6\" rel=\"nofollow\">Dependencies</a></h2>\n<ul>\n<li>Python 2.7, 3.4, 3.5, 3.6 or 3.7</li>\n<li><a href=\"https://github.com/Blosc/python-blosc\" rel=\"nofollow\">python-blosc</a> (provides Blosc) and\n<a href=\"http://www.numpy.org/\" rel=\"nofollow\">Numpy</a> (as listed in <tt>requirements.txt</tt>) for\nrunning the code</li>\n<li>The Python packages listed in <tt>test_requirements.txt</tt> for testing and\nreleasing</li>\n</ul>\n</div>\n<div id=\"stability-of-file-format\">\n<h2><a href=\"#id7\" rel=\"nofollow\">Stability of File Format</a></h2>\n<p>The tool is considered alpha-stage, experimental, research software. It is not\nunlikely that <strong>the internal storage format for the compressed files will\nchange in future</strong>. Please <strong>do not depend critically on the files generated\n(unless you know what you are doing)</strong> by Bloscpack. See the warranty disclaimer\nin the licence at the end of this file.</p>\n</div>\n<div id=\"installation\">\n<h2><a href=\"#id8\" rel=\"nofollow\">Installation</a></h2>\n<p>Disclaimer: There are a myriad ways of installing Python packages (and their\ndependencies) these days and it is a futile endeavour to explain the procedures\nin great detail again and again. Below are three methods that are known to\nwork. Depending on the method you choose and the system your are using you may\nrequire any or all of: super user privileges, a C++ compiler and/or a virtual\nenvironment. If you do run into problems or are unsure, it\u2019s best to send an\nemail to the aforementioned mailing list asking for help.</p>\n<p>The package is available on PyPi, so you may use pip to install the\ndependencies and bloscpack itself:</p>\n<pre><span class=\"gp\">$</span> pip install bloscpack\n</pre>\n<p>If you want to install straight from GitHub, use pip\u2019s VCS support:</p>\n<pre><span class=\"gp\">$</span> pip install git+https://github.com/Blosc/bloscpack\n</pre>\n<p>Or, of course, download the source code or clone the repository and then use\nthe standard <tt>setup.py</tt>:</p>\n<pre><span class=\"gp\">$</span> git clone https://github.com/Blosc/bloscpack\n<span class=\"gp\">$</span> <span class=\"nb\">cd</span> bloscpack\n<span class=\"gp\">$</span> python setup.py install\n</pre>\n</div>\n<div id=\"usage\">\n<h2><a href=\"#id9\" rel=\"nofollow\">Usage</a></h2>\n<p>Bloscpack is accessible from the command line using the <tt>blpk</tt> executable\nthis has a number of global options and four subcommands: <tt>[c | compress]</tt>,\n<tt>[d | decompress]</tt>, <tt>[a | append]</tt> and <tt>[i | info]</tt> most of which each\nhave their own options.</p>\n<p>Help for global options and subcommands:</p>\n<pre><span class=\"gp\">$</span> blpk --help\n<span class=\"go\">[...]</span>\n</pre>\n<p>Help for each one of the subcommands:</p>\n<pre><span class=\"gp\">$</span> blpk compress --help\n<span class=\"go\">[...]\n</span><span class=\"gp\">$</span> blpk decompress --help\n<span class=\"go\">[...]\n</span><span class=\"gp\">$</span> blpk info --help\n<span class=\"go\">[...]\n</span><span class=\"gp\">$</span> blpk append --help\n<span class=\"go\">[...]</span>\n</pre>\n</div>\n<div id=\"examples\">\n<h2><a href=\"#id10\" rel=\"nofollow\">Examples</a></h2>\n<div id=\"basics\">\n<h3>Basics</h3>\n<p>Basic compression:</p>\n<pre><span class=\"gp\">$</span> blpk compress data.dat\n</pre>\n<p>Or:</p>\n<pre><span class=\"gp\">$</span> blpk c data.dat\n</pre>\n<p>\u2026 will compress the file <tt>data.dat</tt> to <tt>data.dat.blp</tt></p>\n<p>Basic decompression:</p>\n<pre><span class=\"gp\">$</span> blpk decompress data.dat.blp data.dcmp\n</pre>\n<p>Or:</p>\n<pre><span class=\"gp\">$</span> blpk d data.dat.blp data.dcmp\n</pre>\n<p>\u2026 will decompress the file <tt>data.dat.blp</tt> to the file <tt>data.dcmp</tt>. If you\nleave out the <tt>[&lt;out_file&gt;]</tt> argument, Bloscpack will complain that the file\n<tt>data.dat</tt> exists already and refuse to overwrite it:</p>\n<pre><span class=\"gp\">$</span> blpk decompress data.dat.blp\n<span class=\"go\">blpk: error: output file 'data.dat' exists!</span>\n</pre>\n<p>If you know what you are doing, you can use the global option <tt><span class=\"pre\">[-f</span> |\n<span class=\"pre\">--force]</span></tt> to override the overwrite checks:</p>\n<pre><span class=\"gp\">$</span> blpk --force decompress data.dat.blp\n</pre>\n<p>Incidentally this works for compression too:</p>\n<pre><span class=\"gp\">$</span> blpk compress data.dat\n<span class=\"go\">blpk: error: output file 'data.dat.blp' exists!\n</span><span class=\"gp\">$</span> blpk --force compress data.dat\n</pre>\n<p>Lastly, if you want a different filename:</p>\n<pre><span class=\"gp\">$</span> blpk compress data.dat custom.filename.blp\n</pre>\n<p>\u2026 will compress the file <tt>data.dat</tt> to <tt>custom.filename.blp</tt></p>\n</div>\n<div id=\"settings\">\n<h3>Settings</h3>\n<p>By default, the number of threads that Blosc uses during compression and\ndecompression is determined by the number of cores detected on your system.\nYou can change this using the <tt><span class=\"pre\">[-n</span> | <span class=\"pre\">--nthreads]</span></tt> option:</p>\n<pre><span class=\"gp\">$</span> blpk --nthreads <span class=\"m\">1</span> compress data.dat\n</pre>\n<p>Compression with Blosc is controlled with the following options:</p>\n<ul>\n<li><tt><span class=\"pre\">[-t</span> | <span class=\"pre\">--typesize]</span></tt>\nTypesize used by Blosc (default: 8):\n<tt>$ blpk compress <span class=\"pre\">--typesize</span> 8 data.dat</tt></li>\n<li><tt><span class=\"pre\">[-l</span> | <span class=\"pre\">--level]</span></tt>\nCompression level (default: 7):\n<tt>$ blpk compress <span class=\"pre\">--level</span> 3 data.dat</tt></li>\n<li><tt><span class=\"pre\">[-s</span> | <span class=\"pre\">--no-shuffle]</span></tt>\nDeactivate shuffle:\n<tt>$ blpk compress <span class=\"pre\">--no-shuffle</span> data.dat</tt></li>\n<li><tt><span class=\"pre\">[-c</span> | <span class=\"pre\">--codec]</span></tt>\nUse alternative codec:\n<tt>$ blpk compress <span class=\"pre\">--codec</span> lz4 data.dat</tt></li>\n</ul>\n<p>In addition, there are the following options that control the Bloscpack file:</p>\n<ul>\n<li><tt><span class=\"pre\">[-z</span> | <span class=\"pre\">--chunk-size]</span></tt>\nDesired approximate size of the chunks, where you can use human readable\nstrings like <tt>8M</tt> or <tt>128K</tt> or <tt>max</tt> to use the maximum chunk size of\napprx. <tt>2GB</tt> (default: <tt>1MB</tt>):\n<tt>$ blpk compress <span class=\"pre\">--chunk-size</span> 128K data.dat</tt> or\n<tt>$ blpk c <span class=\"pre\">-z</span> max data.dat</tt></li>\n<li><tt><span class=\"pre\">[-k</span> | <span class=\"pre\">--checksum</span> &lt;checksum&gt;]</tt>\nChose which checksum to use. The following values are permissible:\n<tt>None</tt>, <tt>adler32</tt>, <tt>crc32</tt>, <tt>md5</tt>,\n<tt>sha1</tt>, <tt>sha224</tt>, <tt>sha256</tt>, <tt>sha384</tt>,\n<tt>sha512</tt>, (default: <tt>adler32</tt>). As described in the header format, each\ncompressed chunk can be stored with a checksum, which aids corruption\ndetection on decompression:\n<tt>$ blpk compress <span class=\"pre\">--checksum</span> crc32 data.dat</tt></li>\n<li><tt><span class=\"pre\">[-o</span> | <span class=\"pre\">--no-offsets]</span></tt>\nBy default, offsets to the individual chunks are stored. These are included\nto allow for partial decompression in the future. This option disables that\nfeature. Also, a certain number of offsets (default: 10 * \u2018nchunks\u2019) are\npreallocated to allow for appending data to the file:\n<tt>$ blpk compress <span class=\"pre\">--no-offsets</span> data.dat</tt></li>\n</ul>\n</div>\n<div id=\"info-subcommand\">\n<h3>Info Subcommand</h3>\n<p>If you just need some info on how the file was compressed <tt>[i | info]</tt>:</p>\n<pre><span class=\"gp\">$</span> blpk info data.dat.blp\n<span class=\"go\">blpk: BloscpackHeader:\nblpk:     format_version: 3\nblpk:     offsets: True\nblpk:     metadata: False\nblpk:     checksum: 'adler32'\nblpk:     typesize: 8\nblpk:     chunk_size: 1.0M (1048576B)\nblpk:     last_chunk: 900.0K (921600B)\nblpk:     nchunks: 1526\nblpk:     max_app_chunks: 15260\nblpk: 'offsets':\nblpk: [134320,459218,735869,986505,1237646,...]\nblpk: First chunk blosc header:\nblpk: OrderedDict([('version', 2), ('versionlz', 1), ('flags', 1), ('typesize', 8), ('nbytes', 1048576), ('blocksize', 131072), ('ctbytes', 324894)])\nblpk: First chunk blosc flags:\nblpk: OrderedDict([('byte_shuffle', True), ('pure_memcpy', False), ('bit_shuffle', False), ('split_blocks', False), ('codec', 'blosclz')])</span>\n</pre>\n<p>Importantly, the header and flag information are for the first chunk only.\nUsually this isn\u2019t a problem because bloscpack compressed files do tend to have\nhomogeneous settings like codec used, typesize etc\u2026 However, there is nothing\nthat will stop you from appending to an existing bloscpack file using different\nsettings. For example, half the file might be compressed using \u2018blosclz\u2019\nwhereas the other half of the file might be compressed with \u2018lz4\u2019. In any case,\njust be aware that the output is to be seen as an indication that is likely to\nbe correct for all chunks but must not be so necessarily.</p>\n</div>\n<div id=\"adding-metdata\">\n<h3>Adding Metdata</h3>\n<p>Using the <tt><span class=\"pre\">[-m</span> | <span class=\"pre\">--metadata]</span></tt> option you can include JSON from a file:</p>\n<pre><span class=\"gp\">$</span> cat meta.json\n<span class=\"go\">{\"dtype\": \"float64\", \"shape\": [200000000], \"container\": \"numpy\"}\n</span><span class=\"gp\">$</span> blpk compress --chunk-size<span class=\"o\">=</span>512M --metadata meta.json data.dat\n<span class=\"gp\">$</span> blpk info data.dat.blp\n<span class=\"go\">blpk: BloscpackHeader:\nblpk:     format_version: 3\nblpk:     offsets: True\nblpk:     metadata: True\nblpk:     checksum: 'adler32'\nblpk:     typesize: 8\nblpk:     chunk_size: 512.0M (536870912B)\nblpk:     last_chunk: 501.88M (526258176B)\nblpk:     nchunks: 3\nblpk:     max_app_chunks: 30\nblpk: 'offsets':\nblpk: [922,78074943,140783242,...]\nblpk: 'metadata':\nblpk: {   u'container': u'numpy', u'dtype': u'float64', u'shape': [200000000]}\nblpk: MetadataHeader:\nblpk:     magic_format: 'JSON'\nblpk:     meta_options: '00000000'\nblpk:     meta_checksum: 'adler32'\nblpk:     meta_codec: 'zlib'\nblpk:     meta_level: 6\nblpk:     meta_size: 59.0B (59B)\nblpk:     max_meta_size: 590.0B (590B)\nblpk:     meta_comp_size: 58.0B (58B)\nblpk:     user_codec: ''</span>\n</pre>\n<p>It will be printed when decompressing:</p>\n<pre><span class=\"gp\">$</span> blpk decompress data.dat.blp\n<span class=\"go\">blpk: Metadata is:\nblpk: '{u'dtype': u'float64', u'shape': [200000000], u'container': u'numpy'}'</span>\n</pre>\n</div>\n<div id=\"appending\">\n<h3>Appending</h3>\n<p>You can also append data to an existing bloscpack compressed file:</p>\n<pre><span class=\"gp\">$</span> blpk append data.dat.blp data.dat\n</pre>\n<p>However there are certain limitations on the amount of data can be appended.\nFor example, if there is an offsets section, there must be enough room to store\nthe offsets for the appended chunks. If no offsets exists, you may append as\nmuch data as possible given the limitations governed by the maximum number of\nchunks and the chunk-size. Additionally, there are limitations on the\ncompression options. For example, one cannot change the checksum used. It is\nhowever possible to change the compression level, the typesize and the shuffle\noption for the appended chunks.</p>\n<p>Also note that appending is still considered experimental as of <tt>v0.5.0</tt>.</p>\n</div>\n<div id=\"verbose-and-debug-mode\">\n<h3>Verbose and Debug mode</h3>\n<p>Lastly there are two mutually exclusive options to control how much output is\nproduced.</p>\n<p>The first causes basic info to be printed, <tt><span class=\"pre\">[-v</span> | <span class=\"pre\">--verbose]</span></tt>:</p>\n<pre><span class=\"gp\">$</span> blpk --verbose compress --chunk-size <span class=\"m\">0</span>.5G data.dat\n<span class=\"go\">blpk: using 4 threads\nblpk: getting ready for compression\nblpk: input file is: 'data.dat'\nblpk: output file is: 'data.dat.blp'\nblpk: input file size: 1.49G (1600000000B)\nblpk: nchunks: 3\nblpk: chunk_size: 512.0M (536870912B)\nblpk: last_chunk_size: 501.88M (526258176B)\nblpk: output file size: 198.39M (208028617B)\nblpk: compression ratio: 7.691250\nblpk: done</span>\n</pre>\n<p>\u2026 and <tt><span class=\"pre\">[-d</span> | <span class=\"pre\">--debug]</span></tt> prints a detailed account of what is going on:</p>\n<pre><span class=\"gp\">$</span> blpk --debug compress --chunk-size <span class=\"m\">0</span>.5G data.dat\n<span class=\"go\">blpk: command line argument parsing complete\nblpk: command line arguments are:\nblpk:     force: False\nblpk:     verbose: False\nblpk:     offsets: True\nblpk:     checksum: adler32\nblpk:     subcommand: compress\nblpk:     out_file: None\nblpk:     metadata: None\nblpk:     cname: blosclz\nblpk:     in_file: data.dat\nblpk:     chunk_size: 536870912\nblpk:     debug: True\nblpk:     shuffle: True\nblpk:     typesize: 8\nblpk:     clevel: 7\nblpk:     nthreads: 4\nblpk: using 4 threads\nblpk: getting ready for compression\nblpk: input file is: 'data.dat'\nblpk: output file is: 'data.dat.blp'\nblpk: input file size: 1.49G (1600000000B)\nblpk: nchunks: 3\nblpk: chunk_size: 512.0M (536870912B)\nblpk: last_chunk_size: 501.88M (526258176B)\nblpk: BloscArgs:\nblpk:     typesize: 8\nblpk:     clevel: 7\nblpk:     shuffle: True\nblpk:     cname: 'blosclz'\nblpk: BloscpackArgs:\nblpk:     offsets: True\nblpk:     checksum: 'adler32'\nblpk:     max_app_chunks: &lt;function &lt;lambda&gt; at 0x1182de8&gt;\nblpk: metadata_args will be silently ignored\nblpk: max_app_chunks is a callable\nblpk: max_app_chunks was set to: 30\nblpk: BloscpackHeader:\nblpk:     format_version: 3\nblpk:     offsets: True\nblpk:     metadata: False\nblpk:     checksum: 'adler32'\nblpk:     typesize: 8\nblpk:     chunk_size: 512.0M (536870912B)\nblpk:     last_chunk: 501.88M (526258176B)\nblpk:     nchunks: 3\nblpk:     max_app_chunks: 30\nblpk: raw_bloscpack_header: 'blpk\\x03\\x01\\x01\\x08\\x00\\x00\\x00 \\x00\\x10^\\x1f\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\nblpk: Handle chunk '0'\nblpk: checksum (adler32): '\\x1f\\xed\\x1e\\xf4'\nblpk: chunk handled, in: 512.0M (536870912B) out: 74.46M (78074017B)\nblpk: Handle chunk '1'\nblpk: checksum (adler32): ')\\x1e\\x08\\x88'\nblpk: chunk handled, in: 512.0M (536870912B) out: 59.8M (62708295B)\nblpk: Handle chunk '2' (last)\nblpk: checksum (adler32): '\\xe8\\x18\\xa4\\xac'\nblpk: chunk handled, in: 501.88M (526258176B) out: 64.13M (67245997B)\nblpk: Writing '3' offsets: '[296, 78074317, 140782616]'\nblpk: Raw offsets: '(\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\xcdQ\\xa7\\x04\\x00\\x00\\x00\\x00\\x18,d\\x08\\x00\\x00\\x00\\x00'\nblpk: output file size: 198.39M (208028617B)\nblpk: compression ratio: 7.691250\nblpk: done</span>\n</pre>\n</div>\n</div>\n<div id=\"python-api\">\n<h2><a href=\"#id11\" rel=\"nofollow\">Python API</a></h2>\n<p>Bloscpack has a versatile yet simple API consisting of a series of \u2018arguments\u2019\nobjects and high-level functions that can be invoked dependding on your input\nand output needs.</p>\n<p>Nomenclature wise, Python 3 has done a lot for Bloscpack, because we always\nneed to represent compressed data as bytes deliberatey. This makes it easier\nand more natural to distinguish between text, such a filenames and binary and\nbytes objects such as compressed data.</p>\n<div id=\"arguments\">\n<h3>Arguments</h3>\n<p>The three argument types are:</p>\n<ul>\n<li><tt>BloscArgs</tt></li>\n<li><tt>BloscpackArgs</tt></li>\n<li><tt>MetadataArgs</tt></li>\n</ul>\n<p>as defined in <tt>bloscpack/args.py</tt>.  Instantiating any of them will create an\nobject with the defaults setup. The defaults are defined in\n<tt>bloscpack/defaults.py</tt>. You can use these in the high-level functions listed\nbelow.</p>\n<p>You can override any and all defaults by passing in the respective\nkeyword-arguments, for example:</p>\n<pre><span class=\"n\"></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">BloscArgs</span><span class=\"p\">()</span>               <span class=\"c1\"># will create a default args object</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">BloscArgs</span><span class=\"p\">(</span><span class=\"n\">clevel</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>       <span class=\"c1\"># change compression level to 4</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">BloscArgs</span><span class=\"p\">(</span><span class=\"n\">typesize</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span>     <span class=\"c1\"># change the typesize to 4</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"o\">...</span>           <span class=\"n\">clevel</span><span class=\"o\">=</span><span class=\"mi\">9</span><span class=\"p\">,</span>       <span class=\"c1\"># change the compression level to 9</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"o\">...</span>           <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span>  <span class=\"c1\"># deactivate the shuffle filter</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"o\">...</span>           <span class=\"n\">cname</span><span class=\"o\">=</span><span class=\"s1\">'lz4'</span><span class=\"p\">)</span>    <span class=\"c1\"># let lz4 be the internal codec</span>\n</pre>\n<pre><span class=\"k\">class</span> <span class=\"nc\">BloscArgs</span><span class=\"p\">(</span><span class=\"n\">MutableMappingObject</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\" Object to hold Blosc arguments.\n\n    Parameters\n    ----------\n    typesize : int\n        The typesize used\n    clevel : int\n        Compression level\n    shuffle : boolean\n        Whether or not to activate the shuffle filter\n    cname: str\n        Name of the internal code to use\n\n    \"\"\"</span>\n</pre>\n<pre><span class=\"k\">class</span> <span class=\"nc\">BloscpackArgs</span><span class=\"p\">(</span><span class=\"n\">MutableMappingObject</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\" Object to hold BloscPack arguments.\n\n    Parameters\n    ----------\n    offsets : boolean\n        Whether to include space for offsets\n    checksum : str\n        Name of the checksum to use or None/'None'\n    max_app_chunks : int or callable on number of chunks\n        How much space to reserve in the offsets for chunks to be appended.\n\n    \"\"\"</span>\n</pre>\n<pre><span class=\"k\">class</span> <span class=\"nc\">MetadataArgs</span><span class=\"p\">(</span><span class=\"n\">MutableMappingObject</span><span class=\"p\">):</span>\n    <span class=\"sd\">\"\"\" Object to hold the metadata arguments.\n\n    Parameters\n    ----------\n    magic_format : 8 bytes\n        Format identifier for the metadata\n    meta_checksum : str\n        Checksum to be used for the metadata\n    meta_codec : str\n        Codec to be used to compress the metadata\n    meta_level : int\n        Compression level for metadata\n    max_meta_size : int or callable on metadata size\n        How much space to reserve for additional metadata\n\n    \"\"\"</span>\n</pre>\n</div>\n<div id=\"file-bytes\">\n<h3>File / Bytes</h3>\n<p>The following high-level functions exist for compressing and decompressing to\nand from files and byte objects:</p>\n<ul>\n<li><tt>pack_file_to_file</tt></li>\n<li><tt>unpack_file_from_file</tt></li>\n<li><tt>pack_bytes_to_file</tt></li>\n<li><tt>unpack_bytes_from_file</tt></li>\n<li><tt>pack_bytes_to_bytes</tt></li>\n<li><tt>unpack_bytes_from_bytes</tt></li>\n</ul>\n<p>Beyond the target arguments such as the files and the bytes, each <tt>pack_*</tt>\nfunction takes the following arguments:</p>\n<pre>chunk_size : int\n    the desired chunk size in bytes\nmetadata : dict\n    the metadata dict\nblosc_args : BloscArgs\n    blosc args\nbloscpack_args : BloscpackArgs\n    bloscpack args\nmetadata_args : MetadataArgs\n    metadata args\n</pre>\n<p>Below are their sigantures:</p>\n<pre><span class=\"k\">def</span> <span class=\"nf\">pack_file_to_file</span><span class=\"p\">(</span><span class=\"n\">in_file</span><span class=\"p\">,</span> <span class=\"n\">out_file</span><span class=\"p\">,</span>\n                      <span class=\"n\">chunk_size</span><span class=\"o\">=</span><span class=\"n\">DEFAULT_CHUNK_SIZE</span><span class=\"p\">,</span>\n                      <span class=\"n\">metadata</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                      <span class=\"n\">blosc_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                      <span class=\"n\">bloscpack_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                      <span class=\"n\">metadata_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">unpack_file_from_file</span><span class=\"p\">(</span><span class=\"n\">in_file</span><span class=\"p\">,</span> <span class=\"n\">out_file</span><span class=\"p\">):</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">pack_bytes_to_file</span><span class=\"p\">(</span><span class=\"n\">bytes_</span><span class=\"p\">,</span> <span class=\"n\">out_file</span><span class=\"p\">,</span>\n                       <span class=\"n\">chunk_size</span><span class=\"o\">=</span><span class=\"n\">DEFAULT_CHUNK_SIZE</span><span class=\"p\">,</span>\n                       <span class=\"n\">metadata</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                       <span class=\"n\">blosc_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                       <span class=\"n\">bloscpack_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                       <span class=\"n\">metadata_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">unpack_bytes_from_file</span><span class=\"p\">(</span><span class=\"n\">compressed_file</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">pack_bytes_to_bytes</span><span class=\"p\">(</span><span class=\"n\">bytes_</span><span class=\"p\">,</span>\n                        <span class=\"n\">chunk_size</span><span class=\"o\">=</span><span class=\"n\">DEFAULT_CHUNK_SIZE</span><span class=\"p\">,</span>\n                        <span class=\"n\">metadata</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                        <span class=\"n\">blosc_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                        <span class=\"n\">bloscpack_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                        <span class=\"n\">metadata_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                        <span class=\"p\">):</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">unpack_bytes_from_bytes</span><span class=\"p\">(</span><span class=\"n\">bytes_</span><span class=\"p\">):</span>\n</pre>\n</div>\n<div id=\"id3\">\n<h3>Numpy</h3>\n<p>Numpy arrays can be serialized as Bloscpack files, here is a very brief example:</p>\n<pre><span class=\"n\"></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">linspace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mf\">3e8</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span> <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">,</span> <span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">dtype</span>\n<span class=\"go\">300000000 float64\n</span><span class=\"n\"></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">pack_ndarray_to_file</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"s1\">'a.blp'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">unpack_ndarray_from_file</span><span class=\"p\">(</span><span class=\"s1\">'a.blp'</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">==</span> <span class=\"n\">b</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">all</span><span class=\"p\">()</span>\n<span class=\"go\">True</span>\n</pre>\n<p>Looking at the generated file, we can see the Numpy metadata being saved:</p>\n<pre><span class=\"gp\">$</span> lh a.blp\n<span class=\"go\">-rw------- 1 esc esc 266M Aug 13 23:21 a.blp\n\n</span><span class=\"gp\">$</span> blpk info a.blp\n<span class=\"go\">blpk: BloscpackHeader:\nblpk:     format_version: 3\nblpk:     offsets: True\nblpk:     metadata: True\nblpk:     checksum: 'adler32'\nblpk:     typesize: 8\nblpk:     chunk_size: 1.0M (1048576B)\nblpk:     last_chunk: 838.0K (858112B)\nblpk:     nchunks: 2289\nblpk:     max_app_chunks: 22890\nblpk: 'offsets':\nblpk: [202170,408064,554912,690452,819679,...]\nblpk: 'metadata':\nblpk: {   u'container': u'numpy',\nblpk:     u'dtype': u'&lt;f8',\nblpk:     u'order': u'C',\nblpk:     u'shape': [300000000]}\nblpk: MetadataHeader:\nblpk:     magic_format: 'JSON'\nblpk:     meta_options: '00000000'\nblpk:     meta_checksum: 'adler32'\nblpk:     meta_codec: 'zlib'\nblpk:     meta_level: 6\nblpk:     meta_size: 67.0B (67B)\nblpk:     max_meta_size: 670.0B (670B)\nblpk:     meta_comp_size: 62.0B (62B)\nblpk:     user_codec: ''</span>\n</pre>\n<p>Alternatively, we can also use a string as storage:</p>\n<pre><span class=\"n\"></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">linspace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mf\">3e8</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">pack_ndarray_to_bytes</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">unpack_ndarray_from_bytes</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">==</span> <span class=\"n\">b</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">all</span><span class=\"p\">()</span>\n<span class=\"go\">True</span>\n</pre>\n<p>Or use alternate compressors:</p>\n<pre><span class=\"n\"></span><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">linspace</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mf\">3e8</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"n\">pack_ndarray_to_bytes</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">blosc_args</span><span class=\"o\">=</span><span class=\"n\">BloscArgs</span><span class=\"p\">(</span><span class=\"n\">cname</span><span class=\"o\">=</span><span class=\"s1\">'lz4'</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">unpack_ndarray_from_bytes</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"p\">(</span><span class=\"n\">a</span> <span class=\"o\">==</span> <span class=\"n\">b</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">all</span><span class=\"p\">()</span>\n<span class=\"go\">True</span>\n</pre>\n<pre><span class=\"k\">def</span> <span class=\"nf\">pack_ndarray_to_file</span><span class=\"p\">(</span><span class=\"n\">ndarray</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">,</span>\n                         <span class=\"n\">chunk_size</span><span class=\"o\">=</span><span class=\"n\">DEFAULT_CHUNK_SIZE</span><span class=\"p\">,</span>\n                         <span class=\"n\">blosc_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                         <span class=\"n\">bloscpack_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                         <span class=\"n\">metadata_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">pack_ndarray_to_bytes</span><span class=\"p\">(</span><span class=\"n\">ndarray</span><span class=\"p\">,</span>\n                          <span class=\"n\">chunk_size</span><span class=\"o\">=</span><span class=\"n\">DEFAULT_CHUNK_SIZE</span><span class=\"p\">,</span>\n                          <span class=\"n\">blosc_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                          <span class=\"n\">bloscpack_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n                          <span class=\"n\">metadata_args</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">unpack_ndarray_from_file</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">unpack_ndarray_from_bytes</span><span class=\"p\">(</span><span class=\"n\">str_</span><span class=\"p\">):</span>\n</pre>\n<p>If you are interested in the performance of Bloscpack compared to other\nserialization formats for Numpy arrays, please look at the benchmarks presented\nin <a href=\"http://arxiv.org/abs/1404.6383\" rel=\"nofollow\">the Bloscpack paper from the EuroScipy 2013 conference proceedings</a>.</p>\n</div>\n</div>\n<div id=\"testing\">\n<h2><a href=\"#id12\" rel=\"nofollow\">Testing</a></h2>\n<div id=\"installing-dependencies\">\n<h3>Installing Dependencies</h3>\n<p>Testing requires some additional libraries, which you can install from PyPi\nwith:</p>\n<pre><span class=\"gp\">$</span> pip install -r test_requirements.txt\n<span class=\"go\">[...]</span>\n</pre>\n</div>\n<div id=\"basic-tests\">\n<h3>Basic Tests</h3>\n<p>Basic tests, runs quickly:</p>\n<pre><span class=\"gp\">$</span> nosetests\n<span class=\"go\">[...]</span>\n</pre>\n</div>\n<div id=\"heavier-tests\">\n<h3>Heavier Tests</h3>\n<p>Extended tests using a larger file, may take some time, but will be nice to\nmemory:</p>\n<pre><span class=\"gp\">$</span> nosetests test/test_file_io.py:pack_unpack_hard\n<span class=\"go\">[...]</span>\n</pre>\n<p>Extended tests using a huge file. This one take forever and needs loads (5G-6G)\nof memory and loads of disk-space (10G). Use <tt><span class=\"pre\">-s</span></tt> to print progress:</p>\n<pre><span class=\"gp\">$</span> nosetests -s test/test_file_io.py:pack_unpack_extreme\n<span class=\"go\">[...]</span>\n</pre>\n<p>Note that, some compression/decompression tests create temporary files (on\nUNIXoid systems this is under <tt>/tmp/blpk*</tt>) which are deleted upon completion\nof the respective test, both successful and unsuccessful, or when the test is\naborted with e.g. <tt><span class=\"pre\">ctrl-c</span></tt> (using <tt>atexit</tt> magic).</p>\n<p>Under rare circumstances, for example when aborting the deletion which is\ntriggered on abort you may be left with large files polluting your temporary\nspace.  Depending on your partitioning scheme etc.. doing this repeatedly, may\nlead to you running out of space on the file-system.</p>\n</div>\n<div id=\"command-line-interface-tests\">\n<h3>Command Line Interface Tests</h3>\n<p>The command line interface is tested with <a href=\"https://bitheap.org/cram/\" rel=\"nofollow\">cram</a>:</p>\n<pre><span class=\"gp\">$</span> cram --verbose test_cmdline/*.cram\n<span class=\"go\">[...]</span>\n</pre>\n</div>\n<div id=\"coverage\">\n<h3>Coverage</h3>\n<p>To determine coverage you can pool together the coverage from the cram tests and\nthe unit tests:</p>\n<pre><span class=\"gp\">$</span> <span class=\"nv\">COVERAGE</span><span class=\"o\">=</span><span class=\"m\">1</span> cram --verbose test_cmdline/*.cram\n<span class=\"go\">[...]\n</span><span class=\"gp\">$</span>nosetests --with-coverage --cover-package<span class=\"o\">=</span>bloscpack\n<span class=\"go\">[...]</span>\n</pre>\n</div>\n<div id=\"test-runner\">\n<h3>Test Runner</h3>\n<p>To run the command line interface tests and the unit tests and analyse\ncoverage, use the convenience <tt>test.sh</tt> runner:</p>\n<pre><span class=\"gp\">$</span> ./test.sh\n<span class=\"go\">[...]</span>\n</pre>\n</div>\n</div>\n<div id=\"benchmark\">\n<h2><a href=\"#id13\" rel=\"nofollow\">Benchmark</a></h2>\n<p>Using the provided <tt>bench/blpk_vs_gzip.py</tt> script on a <tt>Intel(R) Core(TM)\n<span class=\"pre\">i7-3667U</span> CPU @ 2.00GHz</tt> CPU with 2 cores and 4 threads (active\nhyperthreading), cpu frequency scaling activated but set to the <tt>performance</tt>\ngovernor (all cores scaled to <tt>2.0 GHz</tt>), 8GB of DDR3 memory and a Luks encrypted\nSSD, we get:</p>\n<pre><span class=\"gp\">$</span> <span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>. ./bench/blpk_vs_gzip.py\n<span class=\"go\">create the test data..........done\n\nInput file size: 1.49G\nWill now run bloscpack...\nTime: 2.06 seconds\nOutput file size: 198.55M\nRatio: 7.69\nWill now run gzip...\nTime: 134.20 seconds\nOutput file size: 924.05M\nRatio: 1.65</span>\n</pre>\n<p>As was expected from previous benchmarks of Blosc using the python-blosc\nbindings, Blosc is both much faster and has a better compression ratio for this\nkind of structured data. One thing to note here, is that we are not dropping\nthe system file cache after every step, so the file to read will be cached in\nmemory. To get a more accurate picture we can use the <tt><span class=\"pre\">--drop-caches</span></tt> switch\nof the benchmark which requires you however, to run the benchmark as root,\nsince dropping the caches requires root privileges:</p>\n<pre><span class=\"gp\">$</span> <span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>. ./bench/blpk_vs_gzip.py --drop-caches\n<span class=\"go\">will drop caches\ncreate the test data..........done\n\nInput file size: 1.49G\nWill now run bloscpack...\nTime: 13.49 seconds\nOutput file size: 198.55M\nRatio: 7.69\nWill now run gzip...\nTime: 137.49 seconds\nOutput file size: 924.05M\nRatio: 1.65</span>\n</pre>\n</div>\n<div id=\"optimizing-chunk-size\">\n<h2><a href=\"#id14\" rel=\"nofollow\">Optimizing Chunk Size</a></h2>\n<p>You can use the provided <tt>bench/compression_time_vs_chunk_size.py</tt> file\nto optimize the chunk-size for a given machine. For example:</p>\n<pre><span class=\"gp\">$</span> sudo env <span class=\"nv\">PATH</span><span class=\"o\">=</span><span class=\"nv\">$PATH</span> <span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>.  bench/compression_time_vs_chunk_size.py\n<span class=\"go\">create the test data..........done\nchunk_size    comp-time       decomp-time      ratio\n512.0K        8.106235        10.243908        7.679094\n724.08K       4.424007        12.284307        7.092846\n1.0M          6.243544        11.978932        7.685173\n1.41M         4.715511        10.780901        7.596981\n2.0M          4.548568        10.676304        7.688216\n2.83M         4.851359        11.668394        7.572480\n4.0M          4.557665        10.127647        7.689736\n5.66M         4.589349        9.579627         7.667467\n8.0M          5.290080        10.525652        7.690499</span>\n</pre>\n<p>Running the script requires super user privileges, since you need to\nsynchronize disk writes and drop the file system caches for less noisy results.\nAlso, you should probably run this script a couple of times and inspect the\nvariability of the results.</p>\n</div>\n<div id=\"bloscpack-format\">\n<h2><a href=\"#id15\" rel=\"nofollow\">Bloscpack Format</a></h2>\n<p>The input is split into chunks since a) we wish to put less stress on main\nmemory and b) because Blosc has a buffer limit of <tt>2GB</tt> (Version <tt>1.0.0</tt> and\nabove). By default the chunk-size is a moderate <tt>1MB</tt> which should be fine,\neven for less powerful machines.</p>\n<p>In addition to the chunks some additional information must be added to the file\nfor housekeeping:</p>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th>header:</th><td>a 32 bit header containing various pieces of information</td>\n</tr>\n<tr><th>meta:</th><td>a variable length metadata section, may contain user data</td>\n</tr>\n<tr><th>offsets:</th><td>a variable length section containing chunk offsets</td>\n</tr>\n<tr><th>chunk:</th><td>the blosc chunk(s)</td>\n</tr>\n<tr><th>checksum:</th><td>a checksum following each chunk, if desired</td>\n</tr>\n</tbody>\n</table>\n<p>The layout of the file is then:</p>\n<pre>|-header-|-meta-|-offsets-|-chunk-|-checksum-|-chunk-|-checksum-|...|\n</pre>\n<div id=\"description-of-the-header\">\n<h3>Description of the header</h3>\n<p>The following 32 bit header is used for Bloscpack as of version <tt>0.3.0</tt>.  The\ndesign goals of the header format are to contain as much information as\npossible to achieve interesting things in the future and to be as general as\npossible such that the persistence layer of <a href=\"https://github.com/ContinuumIO/blaze\" rel=\"nofollow\">Blaze</a>/<a href=\"https://github.com/ContinuumIO/blz/tree/master\" rel=\"nofollow\">BLZ</a> can be implemented without\nmodification of the header format.</p>\n<p>The following ASCII representation shows the layout of the header:</p>\n<pre>|-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n| b   l   p   k | ^ | ^ | ^ | ^ |   chunk-size  |  last-chunk   |\n                  |   |   |   |\n      version ----+   |   |   |\n      options --------+   |   |\n     checksum ------------+   |\n     typesize ----------------+\n\n|-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n|            nchunks            |        max-app-chunks         |\n</pre>\n<p>The first 4 bytes are the magic string <tt>blpk</tt>. Then there are 4 bytes which\nhold information about the activated features in this file.  This is followed\nby 4 bytes for the <tt><span class=\"pre\">chunk-size</span></tt>, another 4 bytes for the <tt><span class=\"pre\">last-chunk-size</span></tt>,\n8 bytes for the number of chunks, <tt>nchunks</tt> and lastly 8 bytes for the total\nnumber of chunks that can be appended to this file, <tt><span class=\"pre\">max-app-chunks</span></tt>.</p>\n<p>Effectively, storing the number of chunks as a signed 8 byte integer, limits\nthe number of chunks to <tt><span class=\"pre\">2**63-1</span> = 9223372036854775807</tt>, but this should not\nbe relevant in practice, since, even with the moderate default value of <tt>1MB</tt>\nfor chunk-size, we can still store files as large as <tt>8ZB</tt> (!) Given that\nin 2012 the maximum size of a single file in the Zettabye File System (zfs) is\n<tt>16EB</tt>, Bloscpack should be safe for a few more years.</p>\n</div>\n<div id=\"description-of-the-header-entries\">\n<h3>Description of the header entries</h3>\n<p>All entries are little-endian.</p>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th>version:</th><td><p>(<tt>uint8</tt>)\nformat version of the Bloscpack header, to ensure exceptions in case of\nforward incompatibilities.</p>\n</td>\n</tr>\n<tr><th>options:</th><td><p>(<tt>bitfield</tt>)\nA bitfield which allows for setting certain options in this file.</p>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th><tt>bit 0 (0x01)</tt>:</th><td>If the offsets to the chunks are present in this file.</td>\n</tr>\n<tr><th><tt>bit 1 (0x02)</tt>:</th><td>If metadata is present in this file.</td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n<tr><th>checksum:</th><td><p>(<tt>uint8</tt>)\nThe checksum used. The following checksums, available in the python\nstandard library should be supported. The checksum is always computed on\nthe compressed data and placed after the chunk.</p>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th><tt>0</tt>:</th><td><tt>no checksum</tt></td>\n</tr>\n<tr><th><tt>1</tt>:</th><td><tt>zlib.adler32</tt></td>\n</tr>\n<tr><th><tt>2</tt>:</th><td><tt>zlib.crc32</tt></td>\n</tr>\n<tr><th><tt>3</tt>:</th><td><tt>hashlib.md5</tt></td>\n</tr>\n<tr><th><tt>4</tt>:</th><td><tt>hashlib.sha1</tt></td>\n</tr>\n<tr><th><tt>5</tt>:</th><td><tt>hashlib.sha224</tt></td>\n</tr>\n<tr><th><tt>6</tt>:</th><td><tt>hashlib.sha256</tt></td>\n</tr>\n<tr><th><tt>7</tt>:</th><td><tt>hashlib.sha384</tt></td>\n</tr>\n<tr><th><tt>8</tt>:</th><td><tt>hashlib.sha512</tt></td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n<tr><th>typesize:</th><td><p>(<tt>uint8</tt>)\nThe typesize of the data in the chunks. Currently, assume that the typesize\nis uniform. The space allocated is the same as in the Blosc header.</p>\n</td>\n</tr>\n<tr><th>chunk-size:</th><td><p>(<tt>int32</tt>)\nDenotes the chunk-size. Since the maximum buffer size of Blosc is 2GB\nhaving a signed 32 bit int is enough (<tt>2GB = <span class=\"pre\">2**31</span> bytes</tt>). The special\nvalue of <tt><span class=\"pre\">-1</span></tt> denotes that the chunk-size is unknown or possibly\nnon-uniform.</p>\n</td>\n</tr>\n<tr><th>last-chunk:</th><td><p>(<tt>int32</tt>)\nDenotes the size of the last chunk. As with the <tt><span class=\"pre\">chunk-size</span></tt> an <tt>int32</tt>\nis enough. Again, <tt><span class=\"pre\">-1</span></tt> denotes that this value is unknown.</p>\n</td>\n</tr>\n<tr><th>nchunks:</th><td><p>(<tt>int64</tt>)\nThe total number of chunks used in the file. Given a chunk-size of one\nbyte, the total number of chunks is <tt><span class=\"pre\">2**63</span></tt>. This amounts to a maximum\nfile-size of 8EB (<tt>8EB = 2*63 bytes</tt>) which should be enough for the next\ncouple of years. Again, <tt><span class=\"pre\">-1</span></tt> denotes that the number of is unknown.</p>\n</td>\n</tr>\n<tr><th>max-app-chunks:</th><td><p>(<tt>int64</tt>)\nThe maximum number of chunks that can be appended to this file, excluding\n<tt>nchunks</tt>. This is only useful if there is an offsets section and if\nnchunks is known (not <tt><span class=\"pre\">-1</span></tt>), if either of these conditions do not apply\nthis should be <tt>0</tt>.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>The overall file-size can be computed as <tt><span class=\"pre\">chunk-size</span> * (nchunks - 1) +\n<span class=\"pre\">last-chunk-size</span></tt>. In a streaming scenario <tt><span class=\"pre\">-1</span></tt> can be used as a placeholder.\nFor example if the total number of chunks, or the size of the last chunk is not\nknown at the time the header is created.</p>\n<p>The following constraints exist on the header entries:</p>\n<ul>\n<li><tt><span class=\"pre\">last-chunk</span></tt> must be less than or equal to <tt><span class=\"pre\">chunk-size</span></tt>.</li>\n<li><tt>nchunks + max_app_chunks</tt> must be less than or equal to the maximum value\nof an <tt>int64</tt>.</li>\n</ul>\n</div>\n<div id=\"description-of-the-metadata-section\">\n<h3>Description of the metadata section</h3>\n<p>This section goes after the header. It consists of a metadata-section header\nfollowed by a serialized and potentially compressed data section, followed by\npreallocated space to resize the data section, possibly followed by a checksum.</p>\n<p>The layout of the section is thus:</p>\n<pre>|-metadata-header-|-data-|-prealloc-|-checksum-|\n</pre>\n<p>The header has the following layout:</p>\n<pre>|-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n|         magic-format          | ^ | ^ | ^ | ^ |   meta-size   |\n                                  |   |   |   |\n              meta-options -------+   |   |   |\n              meta-checksum ----------+   |   |\n              meta-codec -----------------+   |\n              meta-level ---------------------+\n\n|-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n| max-meta-size |meta-comp-size |            user-codec         |\n</pre>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th>magic-format:</th><td><p>(<tt>8 byte ASCII string</tt>)\nThe data will usually be some kind of binary serialized string data, for\nexample <tt>JSON</tt>, <tt>BSON</tt>, <tt>YAML</tt> or Protocol-Buffers. The format\nidentifier is to be placed in this field.</p>\n</td>\n</tr>\n<tr><th>meta-options:</th><td><p>(<tt>bitfield</tt>)\nA bitfield which allows for setting certain options in this metadata\nsection. Currently unused</p>\n</td>\n</tr>\n<tr><th>meta-checksum:</th><td><p>The checksum used for the metadata. The same checksums as for the data are\navailable.</p>\n</td>\n</tr>\n<tr><th>meta-codec:</th><td><p>(<tt>unit8</tt>)\nThe codec used for compressing the metadata. As of Bloscpack version\n<tt>0.3.0</tt> the following codecs are supported.</p>\n<table>\n<col>\n<col>\n<tbody>\n<tr><th><tt>0</tt>:</th><td>no codec</td>\n</tr>\n<tr><th><tt>1</tt>:</th><td><tt>zlib</tt> (DEFLATE)</td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n<tr><th>meta-level:</th><td><p>(<tt>unit8</tt>)\nThe compression level used for the codec. If <tt>codec</tt> is <tt>0</tt> i.e. the\nmetadata is not compressed, this must be <tt>0</tt> too.</p>\n</td>\n</tr>\n<tr><th>meta-size:</th><td><p>(<tt>uint32</tt>)\nThe size of the uncompressed metadata.</p>\n</td>\n</tr>\n<tr><th>max-meta-size:</th><td><p>(<tt>uint32</tt>)\nThe total allocated space for the data section.</p>\n</td>\n</tr>\n<tr><th>meta-comp-size:</th><td><p>(<tt>uint32</tt>)\nIf the metadata is compressed, this gives the total space the metadata\noccupies. If the data is not compressed this is the same as <tt><span class=\"pre\">meta-size</span></tt>.\nIn a sense this is the true amount of space in the metadata section that is\nused.</p>\n</td>\n</tr>\n<tr><th>user-codec:</th><td><p>Space reserved for usage of additional codecs. E.g. 4 byte magic string for\ncodec identification and 4 bytes for encoding of codec parameters.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>The total space left for enlarging the metadata section is simply:\n<tt><span class=\"pre\">max-meta-size</span> - <span class=\"pre\">meta-comp-size</span></tt>.</p>\n<p>JSON Example of serialized metadata:</p>\n<pre>'{\"dtype\": \"float64\", \"shape\": [1024], \"others\": []}'\n</pre>\n<p>If compression is requested, but not beneficial, because the compressed size\nwould be larger than the uncompressed size, compression of the metadata is\nautomatically deactivated.</p>\n<p>As of Bloscpack version <tt>0.3.0</tt> only the JSON serializer is supported and\nused the string <tt>JSON</tt> followed by four whitespace bytes as identifier.\nSince JSON and any other of the suggested serializers has limitations, only a\nsubset of Python structures can be stored, so probably some additional object\nhandling must be done prior to serialize certain kinds of metadata.</p>\n</div>\n<div id=\"description-of-the-offsets-entries\">\n<h3>Description of the offsets entries</h3>\n<p>Following the metadata section, comes a variable length section of chunk\noffsets. Offsets of the chunks into the file are to be used for accelerated\nseeking. The offsets (if activated) follow the header. Each offset is a 64 bit\nsigned little-endian integer (<tt>int64</tt>). A value of <tt><span class=\"pre\">-1</span></tt> denotes an unknown\noffset. Initially, all offsets should be initialized to <tt><span class=\"pre\">-1</span></tt> and filled in\nafter writing all chunks. Thus, If the compression of the file fails\nprematurely or is aborted, all offsets should have the value <tt><span class=\"pre\">-1</span></tt>.  Also, any\nunused offset entries preallocated to allow the file to grow should be set to\n<tt><span class=\"pre\">-1</span></tt>. Each offset denotes the exact position of the chunk in the file such\nthat seeking to the offset, will position the file pointer such that, reading\nthe next 16 bytes gives the Blosc header, which is at the start of the desired\nchunk.</p>\n</div>\n<div id=\"description-of-the-chunk-format\">\n<h3>Description of the chunk format</h3>\n<p>As mentioned previously, each chunk is just a Blosc compressed string including\nheader. The Blosc header (as of <tt>v1.0.0</tt>) is 16 bytes as follows:</p>\n<pre>|-0-|-1-|-2-|-3-|-4-|-5-|-6-|-7-|-8-|-9-|-A-|-B-|-C-|-D-|-E-|-F-|\n  ^   ^   ^   ^ |     nbytes    |   blocksize   |    ctbytes    |\n  |   |   |   |\n  |   |   |   +--typesize\n  |   |   +------flags\n  |   +----------versionlz\n  +--------------version\n</pre>\n<p>The first four are simply bytes, the last three are are each unsigned ints\n(<tt>uint32</tt>) each occupying 4 bytes. The header is always little-endian.\n<tt>ctbytes</tt> is the length of the buffer including header and <tt>nbytes</tt> is the\nlength of the data when uncompressed. A more detailed description of the Blosc\nheader can be found in the <a href=\"https://github.com/FrancescAlted/blosc/blob/master/README_HEADER.rst\" rel=\"nofollow\">README_HEADER.rst of the Blosc repository</a></p>\n</div>\n<div id=\"overhead\">\n<h3>Overhead</h3>\n<p>Depending on which configuration for the file is used a constant, or linear\noverhead may be added to the file. The Bloscpack header adds 32 bytes in any\ncase. If the data is non-compressible, Blosc will add 16 bytes of header to\neach chunk. The metadata section obviously adds a constant overhead, and if\nused, both the checksum and the offsets will add overhead to the file. The\noffsets add 8 bytes per chunk and the checksum adds a fixed constant value\nwhich depends on the checksum to each chunk. For example, 32 bytes for the\n<tt>adler32</tt> checksum.</p>\n</div>\n</div>\n<div id=\"coding-conventions\">\n<h2><a href=\"#id16\" rel=\"nofollow\">Coding Conventions</a></h2>\n<ul>\n<li>Numpy rst style docstrings</li>\n<li>README cli examples should use long options</li>\n<li>testing: expected before received <tt>nt.assert_equal(expected, received)</tt></li>\n<li>Debug messages: as close to where the data was generated</li>\n<li>Single quotes around ambiguities in messages <tt>overwriting existing file: 'testfile'</tt></li>\n<li>Exceptions instead of exit</li>\n<li>nose test generators parameterized tests</li>\n<li>Use the Wikipedia definition of compression ratio:\n<a href=\"http://en.wikipedia.org/wiki/Data_compression_ratio\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Data_compression_ratio</a></li>\n</ul>\n</div>\n<div id=\"how-to-optimize-logging\">\n<h2><a href=\"#id17\" rel=\"nofollow\">How to Optimize Logging</a></h2>\n<p>Some care must be taken when logging in the inner loop. For example consider the\nfollowing two commits:</p>\n<ul>\n<li><a href=\"https://github.com/Blosc/bloscpack/commit/0854930514eebaf7dbc6c4dcf3589dbcb9f2fdc9\" rel=\"nofollow\">https://github.com/Blosc/bloscpack/commit/0854930514eebaf7dbc6c4dcf3589dbcb9f2fdc9</a></li>\n<li><a href=\"https://github.com/Blosc/bloscpack/commit/355bf90a8c13a2a1f792d43228c2a68c61476621\" rel=\"nofollow\">https://github.com/Blosc/bloscpack/commit/355bf90a8c13a2a1f792d43228c2a68c61476621</a></li>\n</ul>\n<p>If there are a larger number of chunks, calls to <tt>double_pretty_size</tt> will be\nexecuted (and may be costly) <em>even</em> if no logging is needed.</p>\n<p>Consider the following script, <tt><span class=\"pre\">loop-bench.py</span></tt>:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n<span class=\"kn\">import</span> <span class=\"nn\">bloscpack</span> <span class=\"k\">as</span> <span class=\"nn\">bp</span>\n<span class=\"kn\">import</span> <span class=\"nn\">blosc</span>\n\n<span class=\"n\">shuffle</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">clevel</span> <span class=\"o\">=</span> <span class=\"mi\">9</span>\n<span class=\"n\">cname</span> <span class=\"o\">=</span> <span class=\"s1\">'lz4'</span>\n\n<span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mf\">2.5e8</span><span class=\"p\">)</span>\n\n<span class=\"n\">bargs</span> <span class=\"o\">=</span> <span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">args</span><span class=\"o\">.</span><span class=\"n\">BloscArgs</span><span class=\"p\">(</span><span class=\"n\">clevel</span><span class=\"o\">=</span><span class=\"n\">clevel</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"n\">shuffle</span><span class=\"p\">,</span> <span class=\"n\">cname</span><span class=\"o\">=</span><span class=\"n\">cname</span><span class=\"p\">)</span>\n<span class=\"n\">bpargs</span> <span class=\"o\">=</span> <span class=\"n\">bp</span><span class=\"o\">.</span><span class=\"n\">BloscpackArgs</span><span class=\"p\">(</span><span class=\"n\">offsets</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">checksum</span><span class=\"o\">=</span><span class=\"s1\">'None'</span><span class=\"p\">,</span> <span class=\"n\">max_app_chunks</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n</pre>\n<p>Timing with <tt>v0.7.0</tt>:</p>\n<pre><span class=\"go\">In [1]: %run loop-bench.py\n\nIn [2]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n1 loops, best of 3: 423 ms per loop\n\nIn [3]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n1 loops, best of 3: 421 ms per loop\n\nIn [4]: bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n\nIn [5]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n1 loops, best of 3: 727 ms per loop\n\nIn [6]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n1 loops, best of 3: 725 ms per loop</span>\n</pre>\n<p>And then using a development version that contains the two optimization commits:</p>\n<pre><span class=\"go\">In [1]: %run loop-bench.py\n\nIn [2]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n1 loops, best of 3: 357 ms per loop\n\nIn [3]: %timeit bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n1 loops, best of 3: 357 ms per loop\n\nIn [4]: bpc = bp.pack_ndarray_str(a, blosc_args=bargs, bloscpack_args=bpargs)\n\nIn [5]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n1 loops, best of 3: 658 ms per loop\n\nIn [6]: %timeit a3 = bp.unpack_ndarray_str(bpc)\n1 loops, best of 3: 655 ms per loop</span>\n</pre>\n</div>\n<div id=\"comparison-to-hdf5-pytables\">\n<h2><a href=\"#id18\" rel=\"nofollow\">Comparison to HDF5/PyTables</a></h2>\n<p>Since Blosc has already been supported for use in HDF5 files from within\nPyTables, one might be tempted to question why yet another file format has to\nbe invented. This section aims to differentiate between HDF5/PyTables and\neffectively argues that they are not competitors.</p>\n<ul>\n<li>Lightweight vs. Heavyweight. Bloscpack is a lightweight format. The format\nspecification can easily be digested within a day and the dependencies are\nminimal. PyTables is a complex piece of software and the HDF5 file format\nspecification is a large document.</li>\n<li>Persistence vs. Database. Bloscpack is designed to allow for fast\nserialization and deserialization of in-memory data. PyTables is more of a\ndatabase which for example allows complex queries to be computed on the\ndata.</li>\n</ul>\n<p>Additionally there are two network uses cases which Bloscpack is suited for\n(but does not have support for as of yet):</p>\n<ol>\n<li>Streaming: Since bloscpack without offsets can be written in a single\npass it is ideally suited for streaming over a network, where you can\ncompress send and decompress individual chunks in a streaming fashion.</li>\n<li>Expose a file over HTTP and do partial reads from it, for example when\nstoring a compressed file in S3. You can easily just store a file on a\nweb server and then use the header information to read and decompress\nindividual chunks.</li>\n</ol>\n</div>\n<div id=\"prior-art\">\n<h2><a href=\"#id19\" rel=\"nofollow\">Prior Art</a></h2>\n<p>The following is a  list of important resources that were read during the\nconception and initial stages of Bloscpack.</p>\n<ul>\n<li>The <a href=\"https://github.com/ariya/FastLZ/blob/master/6pack.c\" rel=\"nofollow\">6pack utility included with FastLZ</a> (the codec that\nBloscLZ was derived from) was the initial inspiration for writing a command\nline interface to Blosc.</li>\n<li>The <a href=\"http://en.wikipedia.org/wiki/Portable_Network_Graphics\" rel=\"nofollow\">Wikipedia article on the PNG format</a> contains some\ninteresting details about the PNG header and file headers in general.</li>\n<li>The <a href=\"http://tukaani.org/xz/xz-file-format.txt\" rel=\"nofollow\">XZ File Format Specification</a> gave rise to some ideas and\ntechniques about writing file format specifications and using checksums for\ndata integrity. Although the format and the document itself was a bit to\nheavyweight for my tastes.</li>\n<li>The <a href=\"http://code.google.com/p/snappy/source/browse/trunk/framing_format.txt\" rel=\"nofollow\">Snappy framing format</a>\nand the <a href=\"http://fastcompression.blogspot.de/2012/04/file-container-format-for-lz4.html\" rel=\"nofollow\">file container format for LZ4</a>\nwere also consulted, but I can\u2019t remember if and what inspiration they gave\nrise to.</li>\n<li>The homepages of <a href=\"http://www.zlib.net/\" rel=\"nofollow\">zlib</a> and <a href=\"http://www.gzip.org/\" rel=\"nofollow\">gzip</a> were also consulted at some point. The command line\ninterface of <cite>gzip/gunzip</cite> was deemed to be from a different era and as a\nresult git-style subcommands are used in Bloscpack.</li>\n</ul>\n</div>\n<div id=\"resources-and-related-publications\">\n<h2><a href=\"#id20\" rel=\"nofollow\">Resources and Related Publications</a></h2>\n<ul>\n<li><a href=\"http://www.blosc.org\" rel=\"nofollow\">Main Blosc website</a></li>\n<li><a href=\"http://www.blosc.org/docs/StarvingCPUs.pdf\" rel=\"nofollow\">Francesc Alted. *The Data Access Problem* EuroScipy 2009 Keynote Presentation</a></li>\n<li><a href=\"http://www.blosc.org/docs/StarvingCPUs-CISE-2010.pdf\" rel=\"nofollow\">Francesc Alted. *Why modern CPUs are starving and what can be done about it*, Computing in Science &amp; Engineering, Vol. 12, No. 2. (March 2010), pp. 68-71</a></li>\n<li>Francesc Alted: Sending Data from Memory to CPU (and back) faster than memcpy(). PyData London 2014 <a href=\"http://www.slideshare.net/PyData/blosc-py-data-2014\" rel=\"nofollow\">slides0</a> <a href=\"http://www.youtube.com/watch?v=IzqlWUTndTo\" rel=\"nofollow\">video0</a></li>\n<li><a href=\"https://github.com/Blosc\" rel=\"nofollow\">The Blosc Github organization</a></li>\n<li><a href=\"https://github.com/esc/euroscipy2013-talk-bloscpack\" rel=\"nofollow\">Valentin Haenel. *Introducing Bloscpack* EuroScipy 2013 Presentation</a></li>\n<li><a href=\"http://arxiv.org/abs/1404.6383\" rel=\"nofollow\">Valentin Haenel. *Bloscpack: a compressed lightweight serialization format for numerical data*. Proceedings of the 6th European Conference on Python in Science (EuroSciPy 2013)</a>.</li>\n<li>Valentin Haenel. <em>Fast Serialization of Numpy Arrays with Bloscpack</em>. PyData Berlin 2014 <a href=\"http://slides.zetatech.org/haenel-bloscpack-talk-2014-PyDataBerlin.pdf\" rel=\"nofollow\">slides1</a>, <a href=\"https://www.youtube.com/watch?v=TZdqeEd7iTM\" rel=\"nofollow\">video1</a></li>\n</ul>\n</div>\n<div id=\"maintainers-notes-on-cutting-a-release\">\n<h2><a href=\"#id21\" rel=\"nofollow\">Maintainers Notes on Cutting a Release</a></h2>\n<ol>\n<li>Set the version as environment variable <tt>VERSION=vX.X.X</tt></li>\n<li>Update the changelog and <tt>ANNOUNCE.rst</tt></li>\n<li>Commit using <tt>git commit <span class=\"pre\">-m</span> \"$VERSION changelog and ANNOUNCE.rst\"</tt></li>\n<li>Set the version number in <tt>bloscpack/version.py</tt></li>\n<li>Commit with <tt>git commit <span class=\"pre\">-m</span> \"$VERSION\"</tt></li>\n<li>Make the tag using <tt>git tag <span class=\"pre\">-s</span> <span class=\"pre\">-m</span> \"Bloscpack $VERSION\" $VERSION</tt></li>\n<li>Push commits to Blosc github <tt>git push blosc master</tt></li>\n<li>Push commits to own github <tt>git push esc master</tt></li>\n<li>Push the tag to Blosc github <tt>git push blosc $VERSION</tt></li>\n<li>Push the tag to own github <tt>git push esc $VERSION</tt></li>\n<li>Make a source distribution using <tt>python setup.py sdist bdist_wheel</tt></li>\n<li>Upload to PyPi using <tt>twine upload <span class=\"pre\">dist/bloscpack-$VERSION*</span></tt></li>\n<li>Bump version number to next dev version and reset <tt>ANNOUNCE.rst</tt></li>\n<li>Announce release on the Blosc list</li>\n<li>Announce release via Twitter</li>\n</ol>\n</div>\n<div id=\"todo\">\n<h2><a href=\"#id22\" rel=\"nofollow\">TODO</a></h2>\n<div id=\"documentation\">\n<h3>Documentation</h3>\n<ul>\n<li>Refactor monolithic readme into Sphinx and publish</li>\n<li>Cleanup and double check the docstrings for the public API classes</li>\n</ul>\n</div>\n<div id=\"command-line\">\n<h3>Command Line</h3>\n<ul>\n<li>quiet verbosity level</li>\n<li>Expose the ability to set \u2018max_app_chunks\u2019 from the command line</li>\n<li>Allow to save metadata to a file during decompression</li>\n<li>subcommand e or estimate to estimate the size of the uncompressed data.</li>\n<li>subcommand v or verify to verify the integrity of the data</li>\n<li>add \u2013raw-input and \u2013raw-output switches to allow stuff like:\ncat file | blpk \u2013raw-input \u2013raw-output compress &gt; file.blp</li>\n<li>Establish and document proper exit codes</li>\n<li>Document the metadata saved during Numpy serialization</li>\n</ul>\n</div>\n<div id=\"profiling-and-optimization\">\n<h3>Profiling and Optimization</h3>\n<ul>\n<li>Use the faster version of struct where you have a single string</li>\n<li>Memory profiler, might be able to reduce memory used by reusing the buffer\nduring compression and decompression</li>\n<li>Benchmark different codecs</li>\n<li>Use line profiler to check code</li>\n<li>Select different defaults for Numpy arrays, no offsets? no pre-alloc?</li>\n</ul>\n</div>\n<div id=\"library-features\">\n<h3>Library Features</h3>\n<ul>\n<li>possibly provide a BloscPackFile abstraction, like GzipFile</li>\n<li>Allow to not-prealloc additional space for metadata</li>\n<li>Refactor certain collections of functions that operate on data into objects<ul>\n<li>Offsets (maybe)</li>\n</ul>\n</li>\n<li>partial decompression?</li>\n<li>since we now have potentially small chunks, the progressbar becomes relevant\nagain</li>\n<li>configuration file to store commonly used options on a given machine</li>\n<li>print the compression time, either as verbose or debug</li>\n<li>Investigate if we can use a StringIO object that returns memoryviews on read.</li>\n<li>Implement a memoryview Compressed/PlainSource</li>\n<li>Use a bytearray to read chunks from a file. Then re-use that bytearray\nduring every read to avoid allocating deallocating strings the whole time.</li>\n<li>The keyword arguments to many functions are global dicts, this is a bad idea,\nMake the immutable with a forzendict.</li>\n<li>Check that the checksum is really being checked for all PlainSinks</li>\n<li>Bunch of NetworkSource/Sinks</li>\n<li>HTTPSource/Sink</li>\n</ul>\n</div>\n<div id=\"miscellaneous\">\n<h3>Miscellaneous</h3>\n<ul>\n<li>Announce on scipy/numpy lists, comp.compression, freshmeat, ohloh \u2026</li>\n</ul>\n</div>\n<div id=\"packaging-and-infrastructure\">\n<h3>Packaging and Infrastructure</h3>\n<ul>\n<li>Debian packages (for python-blosc and bloscpack)</li>\n<li>Conda recipes (for python-blosc and bloscpack)</li>\n<li>Use tox for testing multiple python versions</li>\n<li>Build on travis and drone.io using pre-compiled</li>\n</ul>\n</div>\n</div>\n<div id=\"changelog\">\n<h2><a href=\"#id23\" rel=\"nofollow\">Changelog</a></h2>\n<ul>\n<li>v0.16.0     - Thu 27 Dec 2018<ul>\n<li>Update of Python API and docs</li>\n<li>various minor fixes</li>\n</ul>\n</li>\n<li>v0.15.0     - Wed 31 Oct 2018<ul>\n<li>Halloween Release!</li>\n<li>Adding the Blosc code of conduct (#79 by @esc)</li>\n<li>Two new high-level functions: \u2018pack_bytes_to_bytes\u2019 and\n\u2018unpack_bytes_from_bytes\u2019 (#83 by @esc)</li>\n<li>Fix incorrect check for typesize-chunksize mismatch (#81 by @esc)</li>\n<li>Fix test to append without shuffle (#82 by @esc)</li>\n<li>Fix tests to respect snappy not being available by default (#85 by @esc)</li>\n<li>Fix tests to account for new default blocksize (#86 by @esc)</li>\n<li>Enable testing on Python 3.7 via Travis (#84 by @esc)</li>\n</ul>\n</li>\n<li>v0.14.0     - Thu Oct 18 2018<ul>\n<li>Remove official support for Python 2.6 (#77 by @esc)</li>\n</ul>\n</li>\n<li>v0.13.0     - Thu May 24 2018<ul>\n<li>Add license file and include in sdist packages (#75 by @toddrme2178)</li>\n<li>Print codec on info (#73 by @esc)</li>\n<li>Decode Blosc flags (#72 by @esc)</li>\n<li>Fix an embarrassing typo (#71 by @esc)</li>\n<li>Test zstd (#70 by @esc)</li>\n<li>Document args object (#69 by @esc)</li>\n<li>Various pep8 fixes by @esc</li>\n<li>Support for uploading wheels and using twine by @esc</li>\n<li>Fix use of coverage by @esc</li>\n<li>Better support for Python 2.6 by @esc</li>\n</ul>\n</li>\n<li>v0.12.0     - Fri Mar 09 2018<ul>\n<li>Allow Pythonic None as checksum (#60 by @esc)</li>\n<li>Fix failing tests to comply with latest Blosc (#63 and #64 by FrancescElies)</li>\n<li>Support testing with Python 3.6 via Travis (#65 by @esc)</li>\n<li>Unpinn Blosc in conda recipe (who uses this?) (#61 by @esc)</li>\n<li>Cleanup README (#66 by @esc)</li>\n<li>Fix Trove classifiers (#67 by @esc)</li>\n<li>Random pep8 fixes by @esc</li>\n</ul>\n</li>\n<li>v0.11.0     - Mon Aug 22 2016<ul>\n<li>Unpinn python-blosc and fix unit-tests (#51 and #57 fixed by @oogali)</li>\n<li>Improve the computation of the chunksize when it is not divisible by\ntypesize (#52 by FrancescAlted)</li>\n</ul>\n</li>\n<li>v0.10.0     - Thu Dec 10 2015<ul>\n<li>Fix for compressing sliced arrays (#43 reported by @mistycheney)</li>\n<li>Fix <tt>un/pack_bytes_file</tt> to be available from toplevel</li>\n<li>Fix the badges to come (mostly) from <a href=\"https://img.shields.io\" rel=\"nofollow\">https://img.shields.io</a></li>\n<li>Fixes for travis-ci, test Python 3.5 too</li>\n<li>Pin Blosc version to 1.2.7 via <cite>requirements.txt</cite> and <cite>setup.py</cite> due to\nbreakage with Blosc 1.2.8.</li>\n</ul>\n</li>\n<li>v0.9.0     - Tue Aug 18 2015<ul>\n<li>Use <tt>ast.literal_eval</tt> instead of <tt>np.safe_eval</tt> which is much faster (#39 @cpcloud)</li>\n<li>Support for packing/unpacking bytes to/from file (#41)</li>\n</ul>\n</li>\n<li>v0.8.0     - Sun Jul 12 2015<ul>\n<li>Python 3.x compatibility (#14)</li>\n</ul>\n</li>\n<li>v0.7.3     - Sat Jul 11 2015<ul>\n<li>Fix deserialization of numpy arrays with nested dtypes that were created\nwith versions v0.7.1 and before. (#37)</li>\n</ul>\n</li>\n<li>v0.7.2     - Wed Mar 25 2015<ul>\n<li>Fix support for zero length arrays (and input in general) (#17 reported by @dmbelov)</li>\n<li>Catch when <tt>typesize</tt> doesn\u2019t divide <tt>chunk_size</tt> (#18 reported by @dmbelov)</li>\n<li>Fix serialization of object arrays (#16 reported by @dmbelov)</li>\n<li>Reject Object dtype arrays since they cannot be compressed with Bloscpack</li>\n<li>Provide backwards compatibility for older Numpy serializations</li>\n<li>Fix win32 compatibility of tests (#27 fixed by @mindw)</li>\n<li>Fix using setuptools for scripts and dependencies (#28 fixed by @mindw)</li>\n<li>Various misc fixes</li>\n</ul>\n</li>\n<li>v0.7.1     - Sun Jun 29 2014<ul>\n<li>Fix a bug related to setting the correct typesize when compressing Numpy\narrays</li>\n<li>Optimization of debug statements in the inner loops</li>\n</ul>\n</li>\n<li>v0.7.0     - Wed May 28 2014<ul>\n<li>Modularize cram tests, even has something akin to a harness</li>\n<li>Refactored, tweaked and simplified Source/Sink code and semantics</li>\n<li>Various documentation improvements: listing prior art, comparison to HDF5</li>\n<li>Improve benchmarking scripts</li>\n<li>Introduce a BloscArgs object for saner handling of the BloscArgs</li>\n<li>Introduce a BloscpackArgs object for saner handling of the BloscpackArgs</li>\n<li>Introduce MetadataHeader and MetdataArgs objects too</li>\n<li>Fix all (hopefully) incorrect uses of the term \u2018compression ratio\u2019</li>\n<li>Various miscellaneous fixes and improvements</li>\n</ul>\n</li>\n<li>v0.6.0     - Fri Mar 28 2014<ul>\n<li>Complete refactor of Bloscpack codebase to support modularization</li>\n<li>Support for <a href=\"https://drone.io/\" rel=\"nofollow\">drone.io</a> CI service</li>\n<li>Improved dependency specification for Python 2.6</li>\n<li>Improved installation instructions</li>\n</ul>\n</li>\n<li>v0.5.2     - Fri Mar 07 2014<ul>\n<li>Fix project url in setup.py</li>\n</ul>\n</li>\n<li>v0.5.1     - Sat Feb 22 2014<ul>\n<li>Documentation fixes and improvements</li>\n</ul>\n</li>\n<li>v0.5.0     - Sun Feb 02 2014<ul>\n<li>Moved project to the <a href=\"https://github.com/Blosc\" rel=\"nofollow\">Blosc organization on Github</a></li>\n</ul>\n</li>\n<li>v0.5.0-rc1 - Thu Jan 30 2014<ul>\n<li>Support for Blosc 1.3.x (alternative codecs)</li>\n</ul>\n</li>\n<li>v0.4.1     - Fri Sep 27 2013<ul>\n<li>Fixed the <cite>pack_unpack_hard</cite> test suite</li>\n<li>Fixed handling Numpy record and nested record arrays</li>\n</ul>\n</li>\n<li>v0.4.0     - Sun Sep 15 2013<ul>\n<li>Fix a bug when serializing numpy arrays to strings</li>\n</ul>\n</li>\n<li>v0.4.0-rc2 - Tue Sep 03 2013<ul>\n<li>Package available via PyPi (since 0.4.0-rc1)</li>\n<li>Support for packing/unpacking numpy arrays to/from string</li>\n<li>Check that string and record arrays work</li>\n<li>Fix installation problems with PyPi package (Thanks to Olivier Grisel)</li>\n</ul>\n</li>\n<li>v0.4.0-rc1 - Sun Aug 18 2013<ul>\n<li>BloscpackHeader class introduced</li>\n<li>The info subcommand shows human readable sizes when printing the header</li>\n<li>Now using Travis-CI for testing and Coveralls for coverage</li>\n<li>Further work on the Plain/Compressed-Source/Sink abstractions</li>\n<li>Start using memoryview in places</li>\n<li>Learned to serialize Numpy arrays</li>\n</ul>\n</li>\n<li>v0.3.0     - Sun Aug 04 2013<ul>\n<li>Minor readme fixes</li>\n<li>Increase number of cram tests</li>\n</ul>\n</li>\n<li>v0.3.0-rc1 - Thu Aug 01 2013<ul>\n<li>Bloscpack format changes (format version 3)<ul>\n<li>Variable length metadata section with it\u2019s own header</li>\n<li>Ability to preallocate offsets for appending data (<tt>max_app_chunks</tt>)</li>\n</ul>\n</li>\n<li>Refactor compression and decompression to use file pointers instead of\nfile name strings, allows using StringIO/cStringIO.</li>\n<li>Sanitize calculation of nchunks and chunk-size</li>\n<li>Special keyword <tt>max</tt> for use with chunk-size in the CLI</li>\n<li>Support appending to a file and <tt>append</tt> subcommand\n(including the ability to preallocate offsets)</li>\n<li>Support rudimentary <tt>info</tt> subcommand</li>\n<li>Add tests of the command line interface using <tt>cram</tt></li>\n<li>Minor bugfixes and corrections as usual</li>\n</ul>\n</li>\n<li>v0.2.1     - Mon Nov 26 2012<ul>\n<li>Backport to Python 2.6</li>\n<li>Typo fixes in documentation</li>\n</ul>\n</li>\n<li>v0.2.0     - Fri Sep 21 2012<ul>\n<li>Use <tt>atexit</tt> magic to remove test data on abort</li>\n<li>Change prefix of temp directory to <tt>/tmp/blpk*</tt></li>\n<li>Merge header RFC into monolithic readme</li>\n</ul>\n</li>\n<li>v0.2.0-rc2 - Tue Sep 18 2012<ul>\n<li>Don\u2019t bail out if the file is smaller than default chunk</li>\n<li>Set the default <tt>typesize</tt> to <tt>8</tt> bytes</li>\n<li>Upgrade dependencies to python-blosc <tt>v1.0.5</tt> and fix tests</li>\n<li>Make extreme test less resource intensive</li>\n<li>Minor bugfixes and corrections</li>\n</ul>\n</li>\n<li>v0.2.0-rc1 - Thu Sep 13 2012<ul>\n<li>Implement new header format as described in RFC</li>\n<li>Implement checksumming compressed chunks with various checksums</li>\n<li>Implement offsets of the chunks into the file</li>\n<li>Efforts to make the library re-entrant, better control of side-effects</li>\n<li>README is now rst not md (flirting with sphinx)</li>\n<li>Tons of trivial fixes, typos, wording, refactoring, renaming, pep8 etc..</li>\n</ul>\n</li>\n<li>v0.1.1     - Sun Jul 15 2012<ul>\n<li>Fix the memory issue with the tests</li>\n<li>Two new suites: <tt>hard</tt> and <tt>extreme</tt></li>\n<li>Minor typo fixes and corrections</li>\n</ul>\n</li>\n<li>v0.1.0     - Thu Jun 14 2012<ul>\n<li>Freeze the first 8 bytes of the header (hopefully for ever)</li>\n<li>Fail to decompress on non-matching format version</li>\n<li>Minor typo fixes and corrections</li>\n</ul>\n</li>\n<li>v0.1.0-rc3 - Tue Jun 12 2012<ul>\n<li>Limit the chunk-size benchmark to a narrower range</li>\n<li>After more careful experiments, a default chunk-size of <tt>1MB</tt> was\ndeemed most appropriate</li>\n<li>Fixed a terrible bug, where during testing and benchmarking, temporary\nfiles were not removed, oups\u2026</li>\n<li>Adapted the header to have space for more chunks, include special marker\nfor unknown chunk number (<tt><span class=\"pre\">-1</span></tt>) and format version of the compressed\nfile</li>\n<li>Added a note in the README about instability of the file format</li>\n<li>Various minor fixes and enhancements</li>\n</ul>\n</li>\n<li>v0.1.0-rc2 - Sat Jun 09 2012<ul>\n<li>Default chunk-size now <tt>4MB</tt></li>\n<li>Human readable chunk-size argument</li>\n<li>Last chunk now contains remainder</li>\n<li>Pure python benchmark to compare against gzip</li>\n<li>Benchmark to measure the effect of chunk-size</li>\n<li>Various minor fixes and enhancements</li>\n</ul>\n</li>\n<li>v0.1.0-rc1 - Sun May 27 2012<ul>\n<li>Initial version</li>\n<li>Compression/decompression</li>\n<li>Command line argument parser</li>\n<li>README, setup.py, tests and benchmark</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"thanks\">\n<h2><a href=\"#id24\" rel=\"nofollow\">Thanks</a></h2>\n<ul>\n<li>Francesc Alted for writing Blosc in the first place, for providing continual\ncode-review and feedback on Bloscpack and for co-authoring the Bloscpack\nfile-format specification.</li>\n</ul>\n</div>\n<div id=\"author-copyright-and-license\">\n<h2><a href=\"#id25\" rel=\"nofollow\">Author, Copyright and License</a></h2>\n<p>\u00a9 2012-2018 Valentin Haenel &lt;<a href=\"mailto:valentin%40haenel.co\">valentin<span>@</span>haenel<span>.</span>co</a>&gt;</p>\n<p>Bloscpack is licensed under the terms of the MIT License.</p>\n<p>Permission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \u201cSoftware\u201d), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:</p>\n<p>The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.</p>\n<p>THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.</p>\n</div>\n\n          </div>"}, "last_serial": 4638232, "releases": {"0.10.0": [{"comment_text": "", "digests": {"md5": "967927ac01bb6d9fdd74b3ac02954b7f", "sha256": "c97150f0d5e06efcdf87452cb92f25d13511f5f9e6b75be7d9e0f4df3758f707"}, "downloads": -1, "filename": "bloscpack-0.10.0.tar.gz", "has_sig": false, "md5_digest": "967927ac01bb6d9fdd74b3ac02954b7f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 90035, "upload_time": "2015-12-10T19:44:33", "upload_time_iso_8601": "2015-12-10T19:44:33.283550Z", "url": "https://files.pythonhosted.org/packages/68/d4/b47594bb8840e42fb257c392f2e1f177df68ee4e00a8e1a3e9ae7dc761b4/bloscpack-0.10.0.tar.gz", "yanked": false}], "0.11.0": [{"comment_text": "", "digests": {"md5": "ddc06a1c36a0251a8145a850ddd46c63", "sha256": "8c735ca961ca01141f741a23320d2acb7c1191863b26505bc8fc8e53110ac33b"}, "downloads": -1, "filename": "bloscpack-0.11.0.tar.gz", "has_sig": false, "md5_digest": "ddc06a1c36a0251a8145a850ddd46c63", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 89839, "upload_time": "2016-08-22T21:46:20", "upload_time_iso_8601": "2016-08-22T21:46:20.509968Z", "url": "https://files.pythonhosted.org/packages/74/72/1eb769495e4b5b640f73bc547ef15f188c8f0ab1117722c4e09c606b297d/bloscpack-0.11.0.tar.gz", "yanked": false}], "0.12.0": [{"comment_text": "", "digests": {"md5": "2bca1769cde1fd079d96366019f41f2b", "sha256": "410094ef97e1af4882231435855ada7acdefdcbbdb37a8c8378ffca9dbfef5a9"}, "downloads": -1, "filename": "bloscpack-0.12.0-py3-none-any.whl", "has_sig": false, "md5_digest": "2bca1769cde1fd079d96366019f41f2b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 70211, "upload_time": "2018-03-09T21:10:58", "upload_time_iso_8601": "2018-03-09T21:10:58.154496Z", "url": "https://files.pythonhosted.org/packages/20/ad/c8b6018e3290bad030d09c98676fa9d4c4d70bcbae30aac4ff7422651f8f/bloscpack-0.12.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "23591f4a20349607aad001e6192565b2", "sha256": "46ee1be1ff433b82c994a0afe1eea73df6136b5fed99a4e0da7a7c9b6859addb"}, "downloads": -1, "filename": "bloscpack-0.12.0.tar.gz", "has_sig": false, "md5_digest": "23591f4a20349607aad001e6192565b2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 90032, "upload_time": "2018-03-09T20:43:24", "upload_time_iso_8601": "2018-03-09T20:43:24.596658Z", "url": "https://files.pythonhosted.org/packages/1e/82/a602e0099f305e7ad226ff6d49f60047f6310a2e3bd7770ba6b7502e0c48/bloscpack-0.12.0.tar.gz", "yanked": false}], "0.13.0": [{"comment_text": "", "digests": {"md5": "4aa3033d351add578457ca277711b4c0", "sha256": "41ca46f9516109c08b3846fe6f11637104ce857fa4c512d80b3912d54a40799c"}, "downloads": -1, "filename": "bloscpack-0.13.0-py3-none-any.whl", "has_sig": false, "md5_digest": "4aa3033d351add578457ca277711b4c0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 72232, "upload_time": "2018-05-24T14:36:36", "upload_time_iso_8601": "2018-05-24T14:36:36.481603Z", "url": "https://files.pythonhosted.org/packages/6e/e3/c6634808d84be7cbc7c3a0acca93068d4ec92ead7a80c5911f937613f166/bloscpack-0.13.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "14ab521a3ff323f58c4473cfefda6304", "sha256": "a31a24bb3ac60a0de5ba4fffb5aa232dbb3cd97b49dbeea1fcf69561a7ca2d31"}, "downloads": -1, "filename": "bloscpack-0.13.0.tar.gz", "has_sig": false, "md5_digest": "14ab521a3ff323f58c4473cfefda6304", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 93410, "upload_time": "2018-05-24T14:36:37", "upload_time_iso_8601": "2018-05-24T14:36:37.984214Z", "url": "https://files.pythonhosted.org/packages/ca/cb/58790dcefa146616843d464f11ec42ae86e1d2f503b4271b3e4ab1f94591/bloscpack-0.13.0.tar.gz", "yanked": false}], "0.14.0": [{"comment_text": "", "digests": {"md5": "20b5161326c9fb9ca94fa4c01ee57536", "sha256": "cfd56b9d45c17706d55342c72e823fbcfb57a7f2c78159290f99f59291d3d773"}, "downloads": -1, "filename": "bloscpack-0.14.0-py3-none-any.whl", "has_sig": false, "md5_digest": "20b5161326c9fb9ca94fa4c01ee57536", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 54208, "upload_time": "2018-10-18T17:54:36", "upload_time_iso_8601": "2018-10-18T17:54:36.545272Z", "url": "https://files.pythonhosted.org/packages/b6/1c/d0dab5a6bc5bac2478906000134a574a1f6d23783586fdf763dcb3f185a1/bloscpack-0.14.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "518bc5f3917a151de20faf613446959c", "sha256": "04e3db97054071639805f4fbe7486f93bd176d5775fb61edddae9783a6a7fb76"}, "downloads": -1, "filename": "bloscpack-0.14.0.tar.gz", "has_sig": false, "md5_digest": "518bc5f3917a151de20faf613446959c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 92849, "upload_time": "2018-10-18T17:54:38", "upload_time_iso_8601": "2018-10-18T17:54:38.386912Z", "url": "https://files.pythonhosted.org/packages/22/7d/ea2c85468cc3652804b228cfa81ef8c8bb754b6efb88dfdeab383d62e7a9/bloscpack-0.14.0.tar.gz", "yanked": false}], "0.15.0": [{"comment_text": "", "digests": {"md5": "dffed4bd092441a9f83ac03c826ccbdf", "sha256": "d6938ea45e690a70878dfe13abace5e68d3042ee00c888cdb27841c08a99e58d"}, "downloads": -1, "filename": "bloscpack-0.15.0-py3-none-any.whl", "has_sig": false, "md5_digest": "dffed4bd092441a9f83ac03c826ccbdf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 54612, "upload_time": "2018-10-31T09:29:51", "upload_time_iso_8601": "2018-10-31T09:29:51.636727Z", "url": "https://files.pythonhosted.org/packages/22/fb/83b9986eacb94cf91f36ac4b24c7d9606500798e5c2ee0448f1ba47458c0/bloscpack-0.15.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9f710c5fe274daf8975310278ec23121", "sha256": "1fd53e5bec6f6fb98051cd324c68e65028bdf5efabab5f4d09b769fd1d8103e1"}, "downloads": -1, "filename": "bloscpack-0.15.0.tar.gz", "has_sig": false, "md5_digest": "9f710c5fe274daf8975310278ec23121", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 94705, "upload_time": "2018-10-31T09:29:54", "upload_time_iso_8601": "2018-10-31T09:29:54.330437Z", "url": "https://files.pythonhosted.org/packages/b4/2a/cfbb6889ba57e92e6a31038b6a9412d5d657f3dbf97c086b0a7eb43aa1a6/bloscpack-0.15.0.tar.gz", "yanked": false}], "0.16.0": [{"comment_text": "", "digests": {"md5": "b74651e0bc939baac606f5035fed1af1", "sha256": "6431bcfdac0f02146a7136e86171ea15d18bb9acef40250f38347de74b93459b"}, "downloads": -1, "filename": "bloscpack-0.16.0-py2-none-any.whl", "has_sig": false, "md5_digest": "b74651e0bc939baac606f5035fed1af1", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 75690, "upload_time": "2018-12-27T15:24:51", "upload_time_iso_8601": "2018-12-27T15:24:51.824341Z", "url": "https://files.pythonhosted.org/packages/29/a6/13817614d96bf61a29bfdd6c3ccdc759f1df38902cb9e20b6805253430c5/bloscpack-0.16.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1a2ddb0c0f399b81211cdc45f7c546da", "sha256": "35f440d8114e6f4c909612485fec35862019625995d79c3adb701c736e660ff5"}, "downloads": -1, "filename": "bloscpack-0.16.0.tar.gz", "has_sig": false, "md5_digest": "1a2ddb0c0f399b81211cdc45f7c546da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 99059, "upload_time": "2018-12-27T15:25:00", "upload_time_iso_8601": "2018-12-27T15:25:00.940095Z", "url": "https://files.pythonhosted.org/packages/39/c6/ca9b5567caad38b118bf0cbd92d122b067ebc7961742793c6b4c02895bef/bloscpack-0.16.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "2d7fa9e43a64ba0c47a53aa9a5ee74ca", "sha256": "05be7e4a479376df011220aea38c5138951d5c49a80e3fc4ca37cbe05fbc1a1d"}, "downloads": -1, "filename": "bloscpack-0.4.0.tar.gz", "has_sig": false, "md5_digest": "2d7fa9e43a64ba0c47a53aa9a5ee74ca", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43840, "upload_time": "2013-09-15T15:04:42", "upload_time_iso_8601": "2013-09-15T15:04:42.728163Z", "url": "https://files.pythonhosted.org/packages/d4/7f/954d7bbc5ba40dc8aa79887fdc8b09968b0bc535e84513a11ba86df9d44f/bloscpack-0.4.0.tar.gz", "yanked": false}], "0.4.0-rc1": [{"comment_text": "", "digests": {"md5": "72b2fea62b42633766bf8d9f60ba0962", "sha256": "d47559969d4c8de305f6fc5bacc9ea39eea1e34a704da4b2c5ca56aeb2d55f0d"}, "downloads": -1, "filename": "bloscpack-0.4.0-rc1.tar.gz", "has_sig": false, "md5_digest": "72b2fea62b42633766bf8d9f60ba0962", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 31611, "upload_time": "2013-08-18T20:57:40", "upload_time_iso_8601": "2013-08-18T20:57:40.736528Z", "url": "https://files.pythonhosted.org/packages/62/c9/db1a740217ab0f63a6e521b5a20e0ef22e8f3f916ae4deb408fad7628dac/bloscpack-0.4.0-rc1.tar.gz", "yanked": false}], "0.4.0-rc2": [{"comment_text": "", "digests": {"md5": "4aba889305fc8ed69a3964773bb8f4a1", "sha256": "3a98685f635c84fec992128f546fb266ff5d9af5736dc2d188e7cce550bce71d"}, "downloads": -1, "filename": "bloscpack-0.4.0-rc2.tar.gz", "has_sig": false, "md5_digest": "4aba889305fc8ed69a3964773bb8f4a1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 43764, "upload_time": "2013-09-03T08:34:13", "upload_time_iso_8601": "2013-09-03T08:34:13.739174Z", "url": "https://files.pythonhosted.org/packages/69/2e/03a155a2714ef9541216a5b081aa85e9789561b9d3369b3cdab272ee25a5/bloscpack-0.4.0-rc2.tar.gz", "yanked": false}], "0.4.1": [{"comment_text": "", "digests": {"md5": "6f8479d1fbea46f3127657b19126405d", "sha256": "7bdd86ec08a210a82b0a7aa4fbf1e374ea8f0b864dc05737ea468356faae3c5a"}, "downloads": -1, "filename": "bloscpack-0.4.1.tar.gz", "has_sig": false, "md5_digest": "6f8479d1fbea46f3127657b19126405d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 44103, "upload_time": "2013-09-27T09:03:37", "upload_time_iso_8601": "2013-09-27T09:03:37.069209Z", "url": "https://files.pythonhosted.org/packages/65/42/6503128489fcfe512c5b0de18b01f63b496adda317e2485d1bd979eec1e9/bloscpack-0.4.1.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "f22993ed19b3fc02373f8cca85c64f88", "sha256": "9889ad1a79434de8adb49ad6a12c40ac542850e0a133ed1376cdbec27462f7f8"}, "downloads": -1, "filename": "bloscpack-0.5.0.tar.gz", "has_sig": false, "md5_digest": "f22993ed19b3fc02373f8cca85c64f88", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45171, "upload_time": "2014-02-02T16:33:55", "upload_time_iso_8601": "2014-02-02T16:33:55.158353Z", "url": "https://files.pythonhosted.org/packages/13/ad/a03100517fc285b2b5ec8f0bf8337290338878b603db1abfd15d0783acf9/bloscpack-0.5.0.tar.gz", "yanked": false}], "0.5.0-rc1": [{"comment_text": "", "digests": {"md5": "6192dd9c53c48b9b7737fa9087b2644b", "sha256": "63ba3c42bb515548e4f2be1c1e1ef70695b5bfed22ef0eae40c6f8cbc83f25d5"}, "downloads": -1, "filename": "bloscpack-0.5.0-rc1.tar.gz", "has_sig": false, "md5_digest": "6192dd9c53c48b9b7737fa9087b2644b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45030, "upload_time": "2014-01-30T19:22:20", "upload_time_iso_8601": "2014-01-30T19:22:20.448006Z", "url": "https://files.pythonhosted.org/packages/4c/b3/6ad13bf8955c1c4ce6e04cb64176842fcec0064eae4d97c0df16d19e334f/bloscpack-0.5.0-rc1.tar.gz", "yanked": false}], "0.5.1": [{"comment_text": "", "digests": {"md5": "df60a4541d8d5d377a36b95db2bdf96b", "sha256": "65734d77190aa709f8e40f3d140e6dc4675067d55a9bcee220f6b5ba1817d404"}, "downloads": -1, "filename": "bloscpack-0.5.1.tar.gz", "has_sig": false, "md5_digest": "df60a4541d8d5d377a36b95db2bdf96b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45616, "upload_time": "2014-02-22T16:01:01", "upload_time_iso_8601": "2014-02-22T16:01:01.266443Z", "url": "https://files.pythonhosted.org/packages/46/51/63c0bf963810d3f9c78709b615cd592bff611f57e91449587d2cb5ce4a34/bloscpack-0.5.1.tar.gz", "yanked": false}], "0.5.2": [{"comment_text": "", "digests": {"md5": "bbf8963d6b64b9f19bd4c38bc2fe217d", "sha256": "a85fe3b2bb7604c5d82e773c36dafeb24436241ee81848d94c4df1a6170e23ad"}, "downloads": -1, "filename": "bloscpack-0.5.2.tar.gz", "has_sig": false, "md5_digest": "bbf8963d6b64b9f19bd4c38bc2fe217d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 45669, "upload_time": "2014-03-07T18:20:20", "upload_time_iso_8601": "2014-03-07T18:20:20.791348Z", "url": "https://files.pythonhosted.org/packages/bf/9c/fca850fb1235c707849a4436610f629397f1fe4255023eabc6235b89f54f/bloscpack-0.5.2.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "6ebe36eee12c8da2fee53a6f31827c61", "sha256": "a704bea04cae765e6f0be6e5b656803c6ead46ea4489c382dcd55cfd804a8aa0"}, "downloads": -1, "filename": "bloscpack-0.6.0.tar.gz", "has_sig": false, "md5_digest": "6ebe36eee12c8da2fee53a6f31827c61", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 60571, "upload_time": "2014-03-28T18:26:24", "upload_time_iso_8601": "2014-03-28T18:26:24.420161Z", "url": "https://files.pythonhosted.org/packages/9f/4c/41ed49a8e9db19d20b6a29e678335be4555880e401b79b01804711a52bdb/bloscpack-0.6.0.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "e1211d120d2cfbfca059c3fbf1f4246a", "sha256": "d0a9efe1630e06285a5e970ca8f7c323ffdcb1a26f055c885f72f08d4910d88f"}, "downloads": -1, "filename": "bloscpack-0.7.0.tar.gz", "has_sig": false, "md5_digest": "e1211d120d2cfbfca059c3fbf1f4246a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 66851, "upload_time": "2014-05-28T19:54:24", "upload_time_iso_8601": "2014-05-28T19:54:24.605210Z", "url": "https://files.pythonhosted.org/packages/4a/dd/4e756cf460573525fd1335498fcce2c091f8d1d5b641de312716e09259ad/bloscpack-0.7.0.tar.gz", "yanked": false}], "0.7.1": [{"comment_text": "", "digests": {"md5": "9210d0645d281ddb20ba5246abe5d357", "sha256": "cadfc2e5df234f52ea35fe2f8c10d7c8312758a4ed62f74d9d23b4358f899159"}, "downloads": -1, "filename": "bloscpack-0.7.1.tar.gz", "has_sig": false, "md5_digest": "9210d0645d281ddb20ba5246abe5d357", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 68346, "upload_time": "2014-06-29T08:59:13", "upload_time_iso_8601": "2014-06-29T08:59:13.016780Z", "url": "https://files.pythonhosted.org/packages/45/ae/964f8bb6c2bb3949ae1a5e00c6d6134b530456bfac7b98468c328e7dd40b/bloscpack-0.7.1.tar.gz", "yanked": false}], "0.7.2": [{"comment_text": "", "digests": {"md5": "305fb0703a8f12fb004c646152575e50", "sha256": "9dac6d7800b6715a86945e5493aa08c0d2400d9de5d49a15641c17ef962614cc"}, "downloads": -1, "filename": "bloscpack-0.7.2.tar.gz", "has_sig": false, "md5_digest": "305fb0703a8f12fb004c646152575e50", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 87506, "upload_time": "2015-03-25T17:49:35", "upload_time_iso_8601": "2015-03-25T17:49:35.773905Z", "url": "https://files.pythonhosted.org/packages/98/4a/5dc9162c4fac13b170697adffaa42efc40f9b6d8be21f18a0eb59421e3f0/bloscpack-0.7.2.tar.gz", "yanked": false}], "0.7.3": [{"comment_text": "", "digests": {"md5": "9aa272455cadb42c961ce9d52aee1612", "sha256": "ae0d217a9993b6f395b5632aeb6426de95ea05d87184edb77a3df85ef1952f47"}, "downloads": -1, "filename": "bloscpack-0.7.3.tar.gz", "has_sig": false, "md5_digest": "9aa272455cadb42c961ce9d52aee1612", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 88035, "upload_time": "2015-07-11T17:05:18", "upload_time_iso_8601": "2015-07-11T17:05:18.047359Z", "url": "https://files.pythonhosted.org/packages/a3/33/245298b97eece6c80435906af22172c0b54bc31356e0414b0da037e71000/bloscpack-0.7.3.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "fbc9fe552151b3290cccbaf7b0865439", "sha256": "5b66d4870a16c852f9765f45884f0791674d4403f70c9110b25187920abaa688"}, "downloads": -1, "filename": "bloscpack-0.8.0.tar.gz", "has_sig": false, "md5_digest": "fbc9fe552151b3290cccbaf7b0865439", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 88648, "upload_time": "2015-07-11T23:47:12", "upload_time_iso_8601": "2015-07-11T23:47:12.006339Z", "url": "https://files.pythonhosted.org/packages/02/04/49924a4a7682b0ed6387240522d3db95d8a9b677a4c48dc96afbf663d419/bloscpack-0.8.0.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "802729123606219d980f0e278118da89", "sha256": "f9877bb03dd611669b12bfd4f0ece78241fa8761a460507fd4651313b6f16f4f"}, "downloads": -1, "filename": "bloscpack-0.9.0.tar.gz", "has_sig": false, "md5_digest": "802729123606219d980f0e278118da89", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 89156, "upload_time": "2015-08-18T19:39:54", "upload_time_iso_8601": "2015-08-18T19:39:54.904676Z", "url": "https://files.pythonhosted.org/packages/58/b6/edbefa50c68cf38993ac4645884cf117709cfd6d2b2f69771ba4e166d915/bloscpack-0.9.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b74651e0bc939baac606f5035fed1af1", "sha256": "6431bcfdac0f02146a7136e86171ea15d18bb9acef40250f38347de74b93459b"}, "downloads": -1, "filename": "bloscpack-0.16.0-py2-none-any.whl", "has_sig": false, "md5_digest": "b74651e0bc939baac606f5035fed1af1", "packagetype": "bdist_wheel", "python_version": "py2", "requires_python": null, "size": 75690, "upload_time": "2018-12-27T15:24:51", "upload_time_iso_8601": "2018-12-27T15:24:51.824341Z", "url": "https://files.pythonhosted.org/packages/29/a6/13817614d96bf61a29bfdd6c3ccdc759f1df38902cb9e20b6805253430c5/bloscpack-0.16.0-py2-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1a2ddb0c0f399b81211cdc45f7c546da", "sha256": "35f440d8114e6f4c909612485fec35862019625995d79c3adb701c736e660ff5"}, "downloads": -1, "filename": "bloscpack-0.16.0.tar.gz", "has_sig": false, "md5_digest": "1a2ddb0c0f399b81211cdc45f7c546da", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 99059, "upload_time": "2018-12-27T15:25:00", "upload_time_iso_8601": "2018-12-27T15:25:00.940095Z", "url": "https://files.pythonhosted.org/packages/39/c6/ca9b5567caad38b118bf0cbd92d122b067ebc7961742793c6b4c02895bef/bloscpack-0.16.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 22:37:00 2020"}