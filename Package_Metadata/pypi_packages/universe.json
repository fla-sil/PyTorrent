{"info": {"author": "OpenAI", "author_email": "universe@openai.com", "bugtrack_url": null, "classifiers": [], "description": "universe\n***************\n\n.. image:: https://travis-ci.org/openai/universe.svg?branch=master\n    :target: https://travis-ci.org/openai/universe\n\n`Universe <https://openai.com/blog/universe/>`_ is a software\nplatform for measuring and training an AI's general intelligence\nacross the world's supply of games, websites and other\napplications. This is the ``universe`` open-source library, which\nprovides a simple `Gym <https://github.com/openai/gym>`__\ninterface to each Universe environment.\n\nUniverse allows anyone to train and evaluate AI agents on an extremely\nwide range of real-time, complex environments.\n\nUniverse makes it possible for any existing program to become an\nOpenAI Gym environment, without needing special access to the\nprogram's internals, source code, or APIs. It does this by packaging\nthe program into a Docker container, and presenting the AI with the\nsame interface a human uses: sending keyboard and mouse events, and\nreceiving screen pixels. Our initial release contains over 1,000\nenvironments in which an AI agent can take actions and gather\nobservations.\n\nAdditionally, some environments include a reward signal sent to the\nagent, to guide reinforcement learning. We've included a few hundred\nenvironments with reward signals. These environments also include\nautomated start menu clickthroughs, allowing your agent to skip to the\ninteresting part of the environment.\n\nWe'd like the community's `help <https://openai.com/blog/universe/#help>`_\nto grow the number of available environments, including integrating\nincreasingly large and complex games.\n\nThe following classes of tasks are packaged inside of\npublicly-available Docker containers, and can be run today with no\nwork on your part:\n\n- Atari and CartPole environments over VNC: ``gym-core.Pong-v3``, ``gym-core.CartPole-v0``, etc.\n- Flashgames over VNC: ``flashgames.DuskDrive-v0``, etc.\n- Browser tasks (\"World of Bits\") over VNC: ``wob.mini.TicTacToe-v0``, etc.\n\nWe've scoped out integrations for many other games, including\ncompleting a high-quality GTA V integration (thanks to `Craig Quiter <http://deepdrive.io/>`_ and NVIDIA), but these aren't included in today's release.\n\n.. contents:: **Contents of this document**\n   :depth: 2\n\n\nGetting started\n===============\n\nInstallation\n------------\n\nSupported systems\n~~~~~~~~~~~~~~~~~\n\nWe currently support Linux and OSX running Python 2.7 or 3.5.\n\nWe recommend setting up a `conda environment <http://conda.pydata.org/docs/using/envs.html>`__\nbefore getting started, to keep all your Universe-related packages in the same place.\n\nInstall Universe\n~~~~~~~~~~~~~~~~\nTo get started, first install ``universe``:\n\n.. code:: shell\n\n    git clone https://github.com/openai/universe.git\n    cd universe\n    pip install -e .\n\nIf this errors out, you may be missing some required packages. Here's\nthe list of required packages we know about so far (please let us know\nif you had to install any others).\n\nOn Ubuntu 16.04:\n\n.. code:: shell\n\n    pip install numpy\n    sudo apt-get install golang libjpeg-turbo8-dev make\n\nOn Ubuntu 14.04:\n\n.. code:: shell\n\n    sudo add-apt-repository ppa:ubuntu-lxc/lxd-stable  # for newer golang\n    sudo apt-get update\n    sudo apt-get install golang libjpeg-turbo8-dev make\n\nOn OSX:\n\nYou might need to install Command Line Tools by running:\n\n.. code:: shell\n\n    xcode-select --install\n\nOr ``numpy``, ``libjpeg-turbo`` and ``incremental`` packages:\n\n.. code:: shell\n\n    pip install numpy incremental\n    brew install golang libjpeg-turbo\n\nInstall Docker\n~~~~~~~~~~~~~~\n\nThe majority of the environments in Universe run inside Docker\ncontainers, so you will need to `install Docker\n<https://docs.docker.com/engine/installation/>`__ (on OSX, we\nrecommend `Docker for Mac\n<https://docs.docker.com/docker-for-mac/>`__). You should be able to\nrun ``docker ps`` and get something like this:\n\n.. code:: shell\n\n     $ docker ps\n     CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n\nNotes on installation\n~~~~~~~~~~~~~~~~~~~~~\n\n* When installing ``universe``, you may see ``warning`` messages.  These lines occur when installing numpy and are normal.\n* You'll need a ``go version`` of at least 1.5. Ubuntu 14.04 has an older Go, so you'll need to `upgrade <https://golang.org/doc/install>`_ your Go installation.\n* We run Python 3.5 internally, so the Python 3.5 variants will be much more thoroughly performance tested. Please let us know if you see any issues on 2.7.\n* While we don't officially support Windows, we expect our code to be very close to working there. We'd be happy to take pull requests that take our Windows compatibility to 100%.\n\nSystem overview\n---------------\n\nA Universe **environment** is similar to any other Gym environment:\nthe agent submits actions and receives observations using the ``step()``\nmethod.\n\nInternally, a Universe environment consists of two pieces: a **client** and a **remote**:\n\n* The **client** is a `VNCEnv\n  <https://github.com/openai/universe/blob/master/universe/envs/vnc_env.py>`_\n  instance which lives in the same process as the agent. It performs\n  functions like receiving the agent's actions, proxying them to the\n  **remote**, queuing up rewards for the agent, and maintaining a\n  local view of the current episode state.\n* The **remote** is the running environment dynamics, usually a\n  program running inside of a Docker container. It can run anywhere --\n  locally, on a remote server, or in the cloud. (We have a separate\n  page describing how to manage `remotes <doc/remotes.rst>`__.)\n* The client and the remote communicate with one another using the\n  `VNC <https://en.wikipedia.org/wiki/Virtual_Network_Computing>`__\n  remote desktop system, as well as over an auxiliary WebSocket\n  channel for reward, diagnostic, and control messages. (For more\n  information on client-remote communication, see the separate page on\n  the `Universe internal communication protocols\n  <doc/protocols.rst>`__.)\n\nThe code in this repository corresponds to the **client** side of the\nUniverse environments. Additionally, you can freely access the Docker\nimages for the **remotes**. We'll release the source repositories for\nthe remotes in the future, along with tools to enable users to\nintegrate new environments. Please sign up for our `beta\n<https://docs.google.com/forms/d/e/1FAIpQLScAiW-kIS0mz6hdzzFZJJFlXlicDvQs1TX9XMEkipNwjV5VlA/viewform>`_\nif you'd like early access.\n\nRun your first agent\n--------------------\n\nNow that you've installed the ``universe`` library, you should make\nsure it actually works. You can paste the example below into your\n``python`` REPL. (You may need to press enter an extra time to make\nsure the ``while`` loop is executing.)\n\n.. code:: python\n\n  import gym\n  import universe  # register the universe environments\n\n  env = gym.make('flashgames.DuskDrive-v0')\n  env.configure(remotes=1)  # automatically creates a local docker container\n  observation_n = env.reset()\n\n  while True:\n    action_n = [[('KeyEvent', 'ArrowUp', True)] for ob in observation_n]  # your agent here\n    observation_n, reward_n, done_n, info = env.step(action_n)\n    env.render()\n\nThe example will instantiate a client in your Python process,\nautomatically pull the ``quay.io/openai/universe.flashgames`` image,\nand will start that image as the remote. (In our `remotes\n<doc/remotes.rst>`__ documentation page, we explain other ways you can run\nremotes.)\n\nIt will take a few minutes for the image to pull the first time. After that,\nif all goes well, a window like the one below will soon pop up. Your\nagent, which is just pressing the up arrow repeatedly, is now\nplaying a Flash racing game called `Dusk Drive\n<http://www.kongregate.com/games/longanimals/dusk-drive>`__. Your agent\nis programmatically controlling a VNC client, connected to a VNC\nserver running inside of a Docker container in the cloud, rendering a\nheadless Chrome with Flash enabled:\n\n.. image:: https://github.com/openai/universe/blob/master/doc/dusk-drive.png?raw=true\n     :width: 600px\n\nYou can even connect your own VNC client to the environment, either\njust to observe or to interfere with your agent. Our ``flashgames``\nand ``gym-core`` images conveniently bundle a browser-based VNC\nclient, which can be accessed at\n``http://localhost:15900/viewer/?password=openai``. If you're on Mac,\nconnecting to a VNC server is as easy as running: ``open\nvnc://localhost:5900``.\n\n(If using docker-machine, you'll need to replace \"localhost\" with the\nIP address of your Docker daemon, and use ``openai`` as the password.)\n\nBreaking down the example\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSo we managed to run an agent, what did all the code actually\nmean? We'll go line-by-line through the example.\n\n* First, we import the `gym <https://github.com/openai/gym>`__ library,\n  which is the base on which Universe is built. We also import\n  ``universe``, which `registers\n  <https://github.com/openai/universe/blob/master/universe/__init__.py>`__\n  all the Universe environments.\n\n.. code:: python\n\n  import gym\n  import universe # register the universe environments\n\n* Next, we create the environment instance. Behind the scenes, ``gym``\n  looks up the `registration\n  <https://github.com/openai/universe/blob/master/universe/__init__.py>`__\n  for ``flashgames.DuskDrive-v0``, and instantiates a `VNCEnv\n  <https://github.com/openai/universe/blob/master/universe/envs/vnc_env.py#L88>`__\n  object which has been `wrapped\n  <https://github.com/openai/universe/blob/master/universe/wrappers/__init__.py#L42>`__\n  to add a few useful diagnostics and utilities. The ``VNCEnv`` object\n  is the *client* part of the environment, and it is not yet connected\n  to a *remote*.\n\n.. code:: python\n\n  env = gym.make('flashgames.DuskDrive-v0')\n\n* The call to ``configure()`` connects the client to a remote\n  environment server. When called with ``configure(remotes=1)``,\n  Universe will automatically create a Docker image running locally on\n  your computer. The local client connects to the remote using VNC.\n  (More information on client-remote communication can be found in the\n  page on `universe internal communication protocols\n  <doc/protocols.rst>`__. More on configuring remotes is at `remotes <doc/remotes.rst>`__.)\n\n.. code:: python\n\n  env.configure(remotes=1)\n\n* When starting a new environment, you call ``env.reset()``. Universe\n  environments run in real-time, rather than stepping synchronously\n  with the agent's actions, so ``reset`` is asynchronous and returns\n  immediately. Since the environment will not have waited to finish\n  connecting to the VNC server before returning, the initial observations\n  from ``reset`` will be ``None`` to indicate that there is\n  not yet a valid observation.\n\n  Similarly, the environment keeps running in the background even\n  if the agent does not call ``env.step()``.  This means that an agent\n  that successfully learns from a Universe environment cannot take\n  \"thinking breaks\":  it must keep sending actions to the environment at all times.\n\n  Additionally, Universe introduces the *vectorized* Gym\n  API. Rather than controlling a single environment at a time, the agent\n  can control a fixed-size vector of ``n`` environments, each with its\n  own remote. The return value from ``reset`` is therefore a *vector*\n  of observations. For more information, see the separate page on\n  `environment semantics <doc/env_semantics.rst>`__)\n\n.. code:: python\n\n  observation_n = env.reset()\n\n* At each ``step()`` call, the agent submits a vector of actions; one for\n  each environment instance it is controlling. Each VNC action is a\n  list of events; above, each action is the single event \"press the\n  ``ArrowUp`` key\". The agent could press and release the key in one\n  action by instead submitting ``[('KeyEvent', 'ArrowUp', True),\n  ('KeyEvent', 'ArrowUp', False)]`` for each observation.\n\n  In fact, the agent could largely have the same effect by just\n  submitting ``('KeyEvent', 'ArrowUp', True)`` once and then calling\n  ``env.step([[] for ob in observation_n])`` thereafter, without ever\n  releasing the key using ``('KeyEvent', 'ArrowUp', False)``. The\n  browser running inside the remote would continue to statefully\n  represent the arrow key as being pressed. Sending other unrelated\n  keypresses would not disrupt the up arrow keypress; only explicitly\n  releasing the key would cancel it.  There's one slight subtlety:\n  when the episode resets, the browser will reset, and will forget\n  about the keypress; you'd need to submit a new ``ArrowUp`` at the\n  start of each episode.\n\n.. code:: python\n\n  action_n = [[('KeyEvent', 'ArrowUp', True)] for ob in observation_n]\n\n* After we submit the action to the environment and render one frame,\n  ``step()`` returns a list of *observations*, a list of *rewards*, a\n  list of *\"done\" booleans* indicating whether the episode has ended,\n  and then finally an *info dictionary* of the form ``{'n': [{},\n  ...]}``, in which you can access the info for environment ``i`` as\n  ``info['n'][i]``.\n\n  Each environment's ``info`` message contains useful diagnostic\n  information, including latency data, client and remote timings,\n  VNC update counts, and reward message counts.\n\n.. code:: python\n\n    observation_n, reward_n, done_n, info = env.step(action_n)\n    env.render()\n\n* We call ``step`` in what looks like a busy loop. In reality, there\n  is a `Throttle\n  <https://github.com/openai/universe/blob/master/universe/wrappers/__init__.py#L18>`__\n  wrapper on the client which defaults to a target frame rate of 60fps, or one\n  frame every 16.7ms. If you call it more frequently than that,\n  ``step`` will `sleep\n  <https://github.com/openai/universe/blob/master/universe/wrappers/throttle.py>`__\n  with any leftover time.\n\n\nTesting\n=======\n\nWe are using `pytest <http://doc.pytest.org/en/latest/>`__ for tests. You can run them via:\n\n.. code:: shell\n\n    pytest\n\nRun ``pytest --help`` for useful options, such as ``pytest -s`` (disables output capture) or ``pytest -k <expression>`` (runs only specific tests).\n\nAdditional documentation\n========================\n\nMore documentation not covered in this README can be found in the\n`doc folder <doc>`__ of this repository.\n\nGetting help\n============\n\nIf you encounter a problem that is not addressed in this README page\nor in the `extra docs <doc>`__, then try our wiki page of `solutions\nto common problems\n<https://github.com/openai/universe/wiki/Solutions-to-common-problems>`__ -\nand add to it if your solution isn't there!\n\nYou can also search through the `issues\n<https://github.com/openai/universe/issues?utf8=%E2%9C%93&q=is%3Aissue>`__\non this repository and our `discussion board\n<https://discuss.openai.com/c/Universe>`__ to see if another user has posted\nabout the same problem or to ask for help from the community.\n\nIf you still can't solve your problem after trying all of the above\nsteps, please post an issue on this repository.\n\nWhat's next?\n============\n\n* Get started training RL algorithms! You can try out the `Universe Starter Agent <https://github.com/openai/universe-starter-agent>`_, an implementation of the `A3C algorithm <https://arxiv.org/abs/1602.01783>`_ that can solve several VNC environments.\n\n* For more information on how to manage remotes, see the separate documentation page on `remotes <doc/remotes.rst>`__.\n\n* Sign up for a `beta <https://docs.google.com/forms/d/e/1FAIpQLScAiW-kIS0mz6hdzzFZJJFlXlicDvQs1TX9XMEkipNwjV5VlA/viewform>`_ to get early access to upcoming Universe releases, such as tools to integrate new Universe environments or a dataset of recorded human demonstrations.\n\n\nChangelog\n---------\n- 2017-02-08: The old location for wrappers.SafeActionSpace has been moved to wrappers.experimental.SafeActionSpace. SoftmaxClickMouse has also been moved to wrappers.experimental.SoftmaxClickMouse\n- 2017-01-08: The wrappers.SafeActionSpace has been moved to wrappers.experimental.SafeActionSpace. The old location will remain with a deprecation warning until 2017-02-08.\n- 2016-12-27: BACKWARDS INCOMPATIBILITY: The gym monitor is now a\n  wrapper. Rather than starting monitoring as\n  `env.monitor.start(directory)`, envs are now wrapped as follows:\n  `env = wrappers.Monitor(env, directory)`. This change is on master\n  and will be released with 0.21.0.\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/openai/universe", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "universe", "package_url": "https://pypi.org/project/universe/", "platform": "UNKNOWN", "project_url": "https://pypi.org/project/universe/", "project_urls": {"Homepage": "https://github.com/openai/universe"}, "release_url": "https://pypi.org/project/universe/0.21.3/", "requires_dist": null, "requires_python": "", "summary": "Universe: a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites and other applications.", "version": "0.21.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.org/openai/universe\" rel=\"nofollow\"><img alt=\"https://travis-ci.org/openai/universe.svg?branch=master\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ad726aea6567d90d876a218dac16cd0718dc94ca/68747470733a2f2f7472617669732d63692e6f72672f6f70656e61692f756e6976657273652e7376673f6272616e63683d6d6173746572\"></a>\n<p><a href=\"https://openai.com/blog/universe/\" rel=\"nofollow\">Universe</a> is a software\nplatform for measuring and training an AI\u2019s general intelligence\nacross the world\u2019s supply of games, websites and other\napplications. This is the <tt>universe</tt> open-source library, which\nprovides a simple <a href=\"https://github.com/openai/gym\" rel=\"nofollow\">Gym</a>\ninterface to each Universe environment.</p>\n<p>Universe allows anyone to train and evaluate AI agents on an extremely\nwide range of real-time, complex environments.</p>\n<p>Universe makes it possible for any existing program to become an\nOpenAI Gym environment, without needing special access to the\nprogram\u2019s internals, source code, or APIs. It does this by packaging\nthe program into a Docker container, and presenting the AI with the\nsame interface a human uses: sending keyboard and mouse events, and\nreceiving screen pixels. Our initial release contains over 1,000\nenvironments in which an AI agent can take actions and gather\nobservations.</p>\n<p>Additionally, some environments include a reward signal sent to the\nagent, to guide reinforcement learning. We\u2019ve included a few hundred\nenvironments with reward signals. These environments also include\nautomated start menu clickthroughs, allowing your agent to skip to the\ninteresting part of the environment.</p>\n<p>We\u2019d like the community\u2019s <a href=\"https://openai.com/blog/universe/#help\" rel=\"nofollow\">help</a>\nto grow the number of available environments, including integrating\nincreasingly large and complex games.</p>\n<p>The following classes of tasks are packaged inside of\npublicly-available Docker containers, and can be run today with no\nwork on your part:</p>\n<ul>\n<li>Atari and CartPole environments over VNC: <tt><span class=\"pre\">gym-core.Pong-v3</span></tt>, <tt><span class=\"pre\">gym-core.CartPole-v0</span></tt>, etc.</li>\n<li>Flashgames over VNC: <tt><span class=\"pre\">flashgames.DuskDrive-v0</span></tt>, etc.</li>\n<li>Browser tasks (\u201cWorld of Bits\u201d) over VNC: <tt><span class=\"pre\">wob.mini.TicTacToe-v0</span></tt>, etc.</li>\n</ul>\n<p>We\u2019ve scoped out integrations for many other games, including\ncompleting a high-quality GTA V integration (thanks to <a href=\"http://deepdrive.io/\" rel=\"nofollow\">Craig Quiter</a> and NVIDIA), but these aren\u2019t included in today\u2019s release.</p>\n<div id=\"contents-of-this-document\">\n<p><strong>Contents of this document</strong></p>\n<ul>\n<li><a href=\"#getting-started\" id=\"id3\" rel=\"nofollow\">Getting started</a><ul>\n<li><a href=\"#installation\" id=\"id4\" rel=\"nofollow\">Installation</a></li>\n<li><a href=\"#system-overview\" id=\"id5\" rel=\"nofollow\">System overview</a></li>\n<li><a href=\"#run-your-first-agent\" id=\"id6\" rel=\"nofollow\">Run your first agent</a></li>\n</ul>\n</li>\n<li><a href=\"#testing\" id=\"id7\" rel=\"nofollow\">Testing</a></li>\n<li><a href=\"#additional-documentation\" id=\"id8\" rel=\"nofollow\">Additional documentation</a></li>\n<li><a href=\"#getting-help\" id=\"id9\" rel=\"nofollow\">Getting help</a></li>\n<li><a href=\"#what-s-next\" id=\"id10\" rel=\"nofollow\">What\u2019s next?</a><ul>\n<li><a href=\"#changelog\" id=\"id11\" rel=\"nofollow\">Changelog</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"getting-started\">\n<h2><a href=\"#id3\" rel=\"nofollow\">Getting started</a></h2>\n<div id=\"installation\">\n<h3><a href=\"#id4\" rel=\"nofollow\">Installation</a></h3>\n<div id=\"supported-systems\">\n<h4>Supported systems</h4>\n<p>We currently support Linux and OSX running Python 2.7 or 3.5.</p>\n<p>We recommend setting up a <a href=\"http://conda.pydata.org/docs/using/envs.html\" rel=\"nofollow\">conda environment</a>\nbefore getting started, to keep all your Universe-related packages in the same place.</p>\n</div>\n<div id=\"install-universe\">\n<h4>Install Universe</h4>\n<p>To get started, first install <tt>universe</tt>:</p>\n<pre>git clone https://github.com/openai/universe.git\n<span class=\"nb\">cd</span> universe\npip install -e .\n</pre>\n<p>If this errors out, you may be missing some required packages. Here\u2019s\nthe list of required packages we know about so far (please let us know\nif you had to install any others).</p>\n<p>On Ubuntu 16.04:</p>\n<pre>pip install numpy\nsudo apt-get install golang libjpeg-turbo8-dev make\n</pre>\n<p>On Ubuntu 14.04:</p>\n<pre>sudo add-apt-repository ppa:ubuntu-lxc/lxd-stable  <span class=\"c1\"># for newer golang\n</span>sudo apt-get update\nsudo apt-get install golang libjpeg-turbo8-dev make\n</pre>\n<p>On OSX:</p>\n<p>You might need to install Command Line Tools by running:</p>\n<pre>xcode-select --install\n</pre>\n<p>Or <tt>numpy</tt>, <tt><span class=\"pre\">libjpeg-turbo</span></tt> and <tt>incremental</tt> packages:</p>\n<pre>pip install numpy incremental\nbrew install golang libjpeg-turbo\n</pre>\n</div>\n<div id=\"install-docker\">\n<h4>Install Docker</h4>\n<p>The majority of the environments in Universe run inside Docker\ncontainers, so you will need to <a href=\"https://docs.docker.com/engine/installation/\" rel=\"nofollow\">install Docker</a> (on OSX, we\nrecommend <a href=\"https://docs.docker.com/docker-for-mac/\" rel=\"nofollow\">Docker for Mac</a>). You should be able to\nrun <tt>docker ps</tt> and get something like this:</p>\n<pre>$ docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n</pre>\n</div>\n<div id=\"notes-on-installation\">\n<h4>Notes on installation</h4>\n<ul>\n<li>When installing <tt>universe</tt>, you may see <tt>warning</tt> messages.  These lines occur when installing numpy and are normal.</li>\n<li>You\u2019ll need a <tt>go version</tt> of at least 1.5. Ubuntu 14.04 has an older Go, so you\u2019ll need to <a href=\"https://golang.org/doc/install\" rel=\"nofollow\">upgrade</a> your Go installation.</li>\n<li>We run Python 3.5 internally, so the Python 3.5 variants will be much more thoroughly performance tested. Please let us know if you see any issues on 2.7.</li>\n<li>While we don\u2019t officially support Windows, we expect our code to be very close to working there. We\u2019d be happy to take pull requests that take our Windows compatibility to 100%.</li>\n</ul>\n</div>\n</div>\n<div id=\"system-overview\">\n<h3><a href=\"#id5\" rel=\"nofollow\">System overview</a></h3>\n<p>A Universe <strong>environment</strong> is similar to any other Gym environment:\nthe agent submits actions and receives observations using the <tt>step()</tt>\nmethod.</p>\n<p>Internally, a Universe environment consists of two pieces: a <strong>client</strong> and a <strong>remote</strong>:</p>\n<ul>\n<li>The <strong>client</strong> is a <a href=\"https://github.com/openai/universe/blob/master/universe/envs/vnc_env.py\" rel=\"nofollow\">VNCEnv</a>\ninstance which lives in the same process as the agent. It performs\nfunctions like receiving the agent\u2019s actions, proxying them to the\n<strong>remote</strong>, queuing up rewards for the agent, and maintaining a\nlocal view of the current episode state.</li>\n<li>The <strong>remote</strong> is the running environment dynamics, usually a\nprogram running inside of a Docker container. It can run anywhere \u2013\nlocally, on a remote server, or in the cloud. (We have a separate\npage describing how to manage <a href=\"doc/remotes.rst\" rel=\"nofollow\">remotes</a>.)</li>\n<li>The client and the remote communicate with one another using the\n<a href=\"https://en.wikipedia.org/wiki/Virtual_Network_Computing\" rel=\"nofollow\">VNC</a>\nremote desktop system, as well as over an auxiliary WebSocket\nchannel for reward, diagnostic, and control messages. (For more\ninformation on client-remote communication, see the separate page on\nthe <a href=\"doc/protocols.rst\" rel=\"nofollow\">Universe internal communication protocols</a>.)</li>\n</ul>\n<p>The code in this repository corresponds to the <strong>client</strong> side of the\nUniverse environments. Additionally, you can freely access the Docker\nimages for the <strong>remotes</strong>. We\u2019ll release the source repositories for\nthe remotes in the future, along with tools to enable users to\nintegrate new environments. Please sign up for our <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScAiW-kIS0mz6hdzzFZJJFlXlicDvQs1TX9XMEkipNwjV5VlA/viewform\" rel=\"nofollow\">beta</a>\nif you\u2019d like early access.</p>\n</div>\n<div id=\"run-your-first-agent\">\n<h3><a href=\"#id6\" rel=\"nofollow\">Run your first agent</a></h3>\n<p>Now that you\u2019ve installed the <tt>universe</tt> library, you should make\nsure it actually works. You can paste the example below into your\n<tt>python</tt> REPL. (You may need to press enter an extra time to make\nsure the <tt>while</tt> loop is executing.)</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">gym</span>\n<span class=\"kn\">import</span> <span class=\"nn\">universe</span>  <span class=\"c1\"># register the universe environments</span>\n\n<span class=\"n\">env</span> <span class=\"o\">=</span> <span class=\"n\">gym</span><span class=\"o\">.</span><span class=\"n\">make</span><span class=\"p\">(</span><span class=\"s1\">'flashgames.DuskDrive-v0'</span><span class=\"p\">)</span>\n<span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">configure</span><span class=\"p\">(</span><span class=\"n\">remotes</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>  <span class=\"c1\"># automatically creates a local docker container</span>\n<span class=\"n\">observation_n</span> <span class=\"o\">=</span> <span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">reset</span><span class=\"p\">()</span>\n\n<span class=\"k\">while</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n  <span class=\"n\">action_n</span> <span class=\"o\">=</span> <span class=\"p\">[[(</span><span class=\"s1\">'KeyEvent'</span><span class=\"p\">,</span> <span class=\"s1\">'ArrowUp'</span><span class=\"p\">,</span> <span class=\"kc\">True</span><span class=\"p\">)]</span> <span class=\"k\">for</span> <span class=\"n\">ob</span> <span class=\"ow\">in</span> <span class=\"n\">observation_n</span><span class=\"p\">]</span>  <span class=\"c1\"># your agent here</span>\n  <span class=\"n\">observation_n</span><span class=\"p\">,</span> <span class=\"n\">reward_n</span><span class=\"p\">,</span> <span class=\"n\">done_n</span><span class=\"p\">,</span> <span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">(</span><span class=\"n\">action_n</span><span class=\"p\">)</span>\n  <span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">render</span><span class=\"p\">()</span>\n</pre>\n<p>The example will instantiate a client in your Python process,\nautomatically pull the <tt>quay.io/openai/universe.flashgames</tt> image,\nand will start that image as the remote. (In our <a href=\"doc/remotes.rst\" rel=\"nofollow\">remotes</a> documentation page, we explain other ways you can run\nremotes.)</p>\n<p>It will take a few minutes for the image to pull the first time. After that,\nif all goes well, a window like the one below will soon pop up. Your\nagent, which is just pressing the up arrow repeatedly, is now\nplaying a Flash racing game called <a href=\"http://www.kongregate.com/games/longanimals/dusk-drive\" rel=\"nofollow\">Dusk Drive</a>. Your agent\nis programmatically controlling a VNC client, connected to a VNC\nserver running inside of a Docker container in the cloud, rendering a\nheadless Chrome with Flash enabled:</p>\n<img alt=\"https://github.com/openai/universe/blob/master/doc/dusk-drive.png?raw=true\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9448809a2f98852a088df32cc31306613d69a88c/68747470733a2f2f6769746875622e636f6d2f6f70656e61692f756e6976657273652f626c6f622f6d61737465722f646f632f6475736b2d64726976652e706e673f7261773d74727565\" width=\"600px\">\n<p>You can even connect your own VNC client to the environment, either\njust to observe or to interfere with your agent. Our <tt>flashgames</tt>\nand <tt><span class=\"pre\">gym-core</span></tt> images conveniently bundle a browser-based VNC\nclient, which can be accessed at\n<tt><span class=\"pre\">http://localhost:15900/viewer/?password=openai</span></tt>. If you\u2019re on Mac,\nconnecting to a VNC server is as easy as running: <tt>open\n<span class=\"pre\">vnc://localhost:5900</span></tt>.</p>\n<p>(If using docker-machine, you\u2019ll need to replace \u201clocalhost\u201d with the\nIP address of your Docker daemon, and use <tt>openai</tt> as the password.)</p>\n<div id=\"breaking-down-the-example\">\n<h4>Breaking down the example</h4>\n<p>So we managed to run an agent, what did all the code actually\nmean? We\u2019ll go line-by-line through the example.</p>\n<ul>\n<li>First, we import the <a href=\"https://github.com/openai/gym\" rel=\"nofollow\">gym</a> library,\nwhich is the base on which Universe is built. We also import\n<tt>universe</tt>, which <a href=\"https://github.com/openai/universe/blob/master/universe/__init__.py\" rel=\"nofollow\">registers</a>\nall the Universe environments.</li>\n</ul>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">gym</span>\n<span class=\"kn\">import</span> <span class=\"nn\">universe</span> <span class=\"c1\"># register the universe environments</span>\n</pre>\n<ul>\n<li>Next, we create the environment instance. Behind the scenes, <tt>gym</tt>\nlooks up the <a href=\"https://github.com/openai/universe/blob/master/universe/__init__.py\" rel=\"nofollow\">registration</a>\nfor <tt><span class=\"pre\">flashgames.DuskDrive-v0</span></tt>, and instantiates a <a href=\"https://github.com/openai/universe/blob/master/universe/envs/vnc_env.py#L88\" rel=\"nofollow\">VNCEnv</a>\nobject which has been <a href=\"https://github.com/openai/universe/blob/master/universe/wrappers/__init__.py#L42\" rel=\"nofollow\">wrapped</a>\nto add a few useful diagnostics and utilities. The <tt>VNCEnv</tt> object\nis the <em>client</em> part of the environment, and it is not yet connected\nto a <em>remote</em>.</li>\n</ul>\n<pre><span class=\"n\">env</span> <span class=\"o\">=</span> <span class=\"n\">gym</span><span class=\"o\">.</span><span class=\"n\">make</span><span class=\"p\">(</span><span class=\"s1\">'flashgames.DuskDrive-v0'</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li>The call to <tt>configure()</tt> connects the client to a remote\nenvironment server. When called with <tt>configure(remotes=1)</tt>,\nUniverse will automatically create a Docker image running locally on\nyour computer. The local client connects to the remote using VNC.\n(More information on client-remote communication can be found in the\npage on <a href=\"doc/protocols.rst\" rel=\"nofollow\">universe internal communication protocols</a>. More on configuring remotes is at <a href=\"doc/remotes.rst\" rel=\"nofollow\">remotes</a>.)</li>\n</ul>\n<pre><span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">configure</span><span class=\"p\">(</span><span class=\"n\">remotes</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li><p>When starting a new environment, you call <tt>env.reset()</tt>. Universe\nenvironments run in real-time, rather than stepping synchronously\nwith the agent\u2019s actions, so <tt>reset</tt> is asynchronous and returns\nimmediately. Since the environment will not have waited to finish\nconnecting to the VNC server before returning, the initial observations\nfrom <tt>reset</tt> will be <tt>None</tt> to indicate that there is\nnot yet a valid observation.</p>\n<p>Similarly, the environment keeps running in the background even\nif the agent does not call <tt>env.step()</tt>.  This means that an agent\nthat successfully learns from a Universe environment cannot take\n\u201cthinking breaks\u201d:  it must keep sending actions to the environment at all times.</p>\n<p>Additionally, Universe introduces the <em>vectorized</em> Gym\nAPI. Rather than controlling a single environment at a time, the agent\ncan control a fixed-size vector of <tt>n</tt> environments, each with its\nown remote. The return value from <tt>reset</tt> is therefore a <em>vector</em>\nof observations. For more information, see the separate page on\n<a href=\"doc/env_semantics.rst\" rel=\"nofollow\">environment semantics</a>)</p>\n</li>\n</ul>\n<pre><span class=\"n\">observation_n</span> <span class=\"o\">=</span> <span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">reset</span><span class=\"p\">()</span>\n</pre>\n<ul>\n<li><p>At each <tt>step()</tt> call, the agent submits a vector of actions; one for\neach environment instance it is controlling. Each VNC action is a\nlist of events; above, each action is the single event \u201cpress the\n<tt>ArrowUp</tt> key\u201d. The agent could press and release the key in one\naction by instead submitting <tt><span class=\"pre\">[('KeyEvent',</span> 'ArrowUp', True),\n('KeyEvent', 'ArrowUp', False)]</tt> for each observation.</p>\n<p>In fact, the agent could largely have the same effect by just\nsubmitting <tt>('KeyEvent', 'ArrowUp', True)</tt> once and then calling\n<tt><span class=\"pre\">env.step([[]</span> for ob in observation_n])</tt> thereafter, without ever\nreleasing the key using <tt>('KeyEvent', 'ArrowUp', False)</tt>. The\nbrowser running inside the remote would continue to statefully\nrepresent the arrow key as being pressed. Sending other unrelated\nkeypresses would not disrupt the up arrow keypress; only explicitly\nreleasing the key would cancel it.  There\u2019s one slight subtlety:\nwhen the episode resets, the browser will reset, and will forget\nabout the keypress; you\u2019d need to submit a new <tt>ArrowUp</tt> at the\nstart of each episode.</p>\n</li>\n</ul>\n<pre><span class=\"n\">action_n</span> <span class=\"o\">=</span> <span class=\"p\">[[(</span><span class=\"s1\">'KeyEvent'</span><span class=\"p\">,</span> <span class=\"s1\">'ArrowUp'</span><span class=\"p\">,</span> <span class=\"kc\">True</span><span class=\"p\">)]</span> <span class=\"k\">for</span> <span class=\"n\">ob</span> <span class=\"ow\">in</span> <span class=\"n\">observation_n</span><span class=\"p\">]</span>\n</pre>\n<ul>\n<li><p>After we submit the action to the environment and render one frame,\n<tt>step()</tt> returns a list of <em>observations</em>, a list of <em>rewards</em>, a\nlist of <em>\u201cdone\u201d booleans</em> indicating whether the episode has ended,\nand then finally an <em>info dictionary</em> of the form <tt>{'n': <span class=\"pre\">[{},</span>\n<span class=\"pre\">...]}</span></tt>, in which you can access the info for environment <tt>i</tt> as\n<tt><span class=\"pre\">info['n'][i]</span></tt>.</p>\n<p>Each environment\u2019s <tt>info</tt> message contains useful diagnostic\ninformation, including latency data, client and remote timings,\nVNC update counts, and reward message counts.</p>\n</li>\n</ul>\n<pre><span class=\"n\">observation_n</span><span class=\"p\">,</span> <span class=\"n\">reward_n</span><span class=\"p\">,</span> <span class=\"n\">done_n</span><span class=\"p\">,</span> <span class=\"n\">info</span> <span class=\"o\">=</span> <span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">(</span><span class=\"n\">action_n</span><span class=\"p\">)</span>\n<span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">render</span><span class=\"p\">()</span>\n</pre>\n<ul>\n<li>We call <tt>step</tt> in what looks like a busy loop. In reality, there\nis a <a href=\"https://github.com/openai/universe/blob/master/universe/wrappers/__init__.py#L18\" rel=\"nofollow\">Throttle</a>\nwrapper on the client which defaults to a target frame rate of 60fps, or one\nframe every 16.7ms. If you call it more frequently than that,\n<tt>step</tt> will <a href=\"https://github.com/openai/universe/blob/master/universe/wrappers/throttle.py\" rel=\"nofollow\">sleep</a>\nwith any leftover time.</li>\n</ul>\n</div>\n</div>\n</div>\n<div id=\"testing\">\n<h2><a href=\"#id7\" rel=\"nofollow\">Testing</a></h2>\n<p>We are using <a href=\"http://doc.pytest.org/en/latest/\" rel=\"nofollow\">pytest</a> for tests. You can run them via:</p>\n<pre>pytest\n</pre>\n<p>Run <tt>pytest <span class=\"pre\">--help</span></tt> for useful options, such as <tt>pytest <span class=\"pre\">-s</span></tt> (disables output capture) or <tt>pytest <span class=\"pre\">-k</span> &lt;expression&gt;</tt> (runs only specific tests).</p>\n</div>\n<div id=\"additional-documentation\">\n<h2><a href=\"#id8\" rel=\"nofollow\">Additional documentation</a></h2>\n<p>More documentation not covered in this README can be found in the\n<a href=\"doc\" rel=\"nofollow\">doc folder</a> of this repository.</p>\n</div>\n<div id=\"getting-help\">\n<h2><a href=\"#id9\" rel=\"nofollow\">Getting help</a></h2>\n<p>If you encounter a problem that is not addressed in this README page\nor in the <a href=\"doc\" rel=\"nofollow\">extra docs</a>, then try our wiki page of <a href=\"https://github.com/openai/universe/wiki/Solutions-to-common-problems\" rel=\"nofollow\">solutions\nto common problems</a> -\nand add to it if your solution isn\u2019t there!</p>\n<p>You can also search through the <a href=\"https://github.com/openai/universe/issues?utf8=%E2%9C%93&amp;q=is%3Aissue\" rel=\"nofollow\">issues</a>\non this repository and our <a href=\"https://discuss.openai.com/c/Universe\" rel=\"nofollow\">discussion board</a> to see if another user has posted\nabout the same problem or to ask for help from the community.</p>\n<p>If you still can\u2019t solve your problem after trying all of the above\nsteps, please post an issue on this repository.</p>\n</div>\n<div id=\"what-s-next\">\n<h2><a href=\"#id10\" rel=\"nofollow\">What\u2019s next?</a></h2>\n<ul>\n<li>Get started training RL algorithms! You can try out the <a href=\"https://github.com/openai/universe-starter-agent\" rel=\"nofollow\">Universe Starter Agent</a>, an implementation of the <a href=\"https://arxiv.org/abs/1602.01783\" rel=\"nofollow\">A3C algorithm</a> that can solve several VNC environments.</li>\n<li>For more information on how to manage remotes, see the separate documentation page on <a href=\"doc/remotes.rst\" rel=\"nofollow\">remotes</a>.</li>\n<li>Sign up for a <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScAiW-kIS0mz6hdzzFZJJFlXlicDvQs1TX9XMEkipNwjV5VlA/viewform\" rel=\"nofollow\">beta</a> to get early access to upcoming Universe releases, such as tools to integrate new Universe environments or a dataset of recorded human demonstrations.</li>\n</ul>\n<div id=\"changelog\">\n<h3><a href=\"#id11\" rel=\"nofollow\">Changelog</a></h3>\n<ul>\n<li>2017-02-08: The old location for wrappers.SafeActionSpace has been moved to wrappers.experimental.SafeActionSpace. SoftmaxClickMouse has also been moved to wrappers.experimental.SoftmaxClickMouse</li>\n<li>2017-01-08: The wrappers.SafeActionSpace has been moved to wrappers.experimental.SafeActionSpace. The old location will remain with a deprecation warning until 2017-02-08.</li>\n<li>2016-12-27: BACKWARDS INCOMPATIBILITY: The gym monitor is now a\nwrapper. Rather than starting monitoring as\n<cite>env.monitor.start(directory)</cite>, envs are now wrapped as follows:\n<cite>env = wrappers.Monitor(env, directory)</cite>. This change is on master\nand will be released with 0.21.0.</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 2684611, "releases": {"0.20.1": [{"comment_text": "", "digests": {"md5": "bd33eba1225dd52793cd980449b3f682", "sha256": "7fe08bd510a9a4f8315132050e5c0b377277d9a8306df4ff5779048f88498fca"}, "downloads": -1, "filename": "universe-0.20.1.tar.gz", "has_sig": false, "md5_digest": "bd33eba1225dd52793cd980449b3f682", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128864, "upload_time": "2016-12-05T05:57:59", "upload_time_iso_8601": "2016-12-05T05:57:59.973159Z", "url": "https://files.pythonhosted.org/packages/63/e4/15187e506e59cfeee21b46541ed14593a644f58410dc7d133dbe462b5072/universe-0.20.1.tar.gz", "yanked": false}], "0.20.2": [{"comment_text": "", "digests": {"md5": "ebfc2cfc761407f5ea5dcf3645079eaf", "sha256": "4c8afd65944c7b4d943be6554ff38940cbd6631dcd2e642e8f7140ee2d742148"}, "downloads": -1, "filename": "universe-0.20.2.tar.gz", "has_sig": false, "md5_digest": "ebfc2cfc761407f5ea5dcf3645079eaf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128841, "upload_time": "2016-12-05T06:17:17", "upload_time_iso_8601": "2016-12-05T06:17:17.426056Z", "url": "https://files.pythonhosted.org/packages/4c/4d/341e06ec7ef3c1efdc6c16e94cebc4b3cff5857bd9c55520fae14781f5ea/universe-0.20.2.tar.gz", "yanked": false}], "0.20.3": [{"comment_text": "", "digests": {"md5": "8f99977f53742f41749fd6504974e864", "sha256": "b5c2dba5a5c5de0532a91fcbe16a6f21e59bb6450cc9ff21d3ebc85700a122de"}, "downloads": -1, "filename": "universe-0.20.3.tar.gz", "has_sig": false, "md5_digest": "8f99977f53742f41749fd6504974e864", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128859, "upload_time": "2016-12-06T19:41:34", "upload_time_iso_8601": "2016-12-06T19:41:34.192538Z", "url": "https://files.pythonhosted.org/packages/72/3a/91f7fd85861fe78ba3971d451ce3e674c4bc3873954a0b978f5924c6a588/universe-0.20.3.tar.gz", "yanked": false}], "0.20.4": [{"comment_text": "", "digests": {"md5": "a16925b01dd5610a96307ae07d43694d", "sha256": "58fdcf9470d2585b96cd7bdca258d06ed2ba43f9b88c97a89a00178dcb74e166"}, "downloads": -1, "filename": "universe-0.20.4.tar.gz", "has_sig": false, "md5_digest": "a16925b01dd5610a96307ae07d43694d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 128345, "upload_time": "2016-12-09T04:18:58", "upload_time_iso_8601": "2016-12-09T04:18:58.914710Z", "url": "https://files.pythonhosted.org/packages/60/be/5136f273e1057f5928c25963f21d45002530930a07a185abf921903bd7af/universe-0.20.4.tar.gz", "yanked": false}], "0.21.0": [{"comment_text": "", "digests": {"md5": "600c681a0ad1e56ceb8767bc576bb6a9", "sha256": "40f5186a61f51431895eb7e8b31192785b96bcb52ea5ccb3275c408b84d72163"}, "downloads": -1, "filename": "universe-0.21.0.tar.gz", "has_sig": false, "md5_digest": "600c681a0ad1e56ceb8767bc576bb6a9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 131149, "upload_time": "2016-12-24T03:15:28", "upload_time_iso_8601": "2016-12-24T03:15:28.949890Z", "url": "https://files.pythonhosted.org/packages/16/33/671fdf8981aab96dbb33011da03095c13c0694c91e328b3accc06ff32913/universe-0.21.0.tar.gz", "yanked": false}], "0.21.1": [{"comment_text": "", "digests": {"md5": "29eb1fd33e8c5f98d7ff5790f4daf2aa", "sha256": "b880a80dd2384a5372f746849e458de74bebf680acb2dc6ba2644cf51ebb856f"}, "downloads": -1, "filename": "universe-0.21.1.tar.gz", "has_sig": false, "md5_digest": "29eb1fd33e8c5f98d7ff5790f4daf2aa", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 132043, "upload_time": "2017-01-05T18:25:58", "upload_time_iso_8601": "2017-01-05T18:25:58.769894Z", "url": "https://files.pythonhosted.org/packages/00/dd/d036911df74524c7a258590546cb41a8bd38d0180416755e70308b359459/universe-0.21.1.tar.gz", "yanked": false}], "0.21.2": [{"comment_text": "", "digests": {"md5": "ae9970faffa20b101068d771e0be2405", "sha256": "afca2d929b8cd453d2a3ce5c1bc866b99cbc2a2e4131391af3c9ef6f055fd7cf"}, "downloads": -1, "filename": "universe-0.21.2.tar.gz", "has_sig": false, "md5_digest": "ae9970faffa20b101068d771e0be2405", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 133975, "upload_time": "2017-01-12T01:49:08", "upload_time_iso_8601": "2017-01-12T01:49:08.616959Z", "url": "https://files.pythonhosted.org/packages/df/6a/69740da80e743db5810f90a8116baedc6ab314706d03fe47c83aee8c140b/universe-0.21.2.tar.gz", "yanked": false}], "0.21.3": [{"comment_text": "", "digests": {"md5": "a6df6fc3179e75d3011fc3a7660188a6", "sha256": "9fc9835b3d2fe787fd2fd6079696eb1de40ca1f6f0e8246427b11fadd856640f"}, "downloads": -1, "filename": "universe-0.21.3.tar.gz", "has_sig": false, "md5_digest": "a6df6fc3179e75d3011fc3a7660188a6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 136998, "upload_time": "2017-03-05T22:23:32", "upload_time_iso_8601": "2017-03-05T22:23:32.713175Z", "url": "https://files.pythonhosted.org/packages/5b/5e/26ee56c16cdc83a07a3251e3425856f2ade84928de55b3fa11590ce2b912/universe-0.21.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a6df6fc3179e75d3011fc3a7660188a6", "sha256": "9fc9835b3d2fe787fd2fd6079696eb1de40ca1f6f0e8246427b11fadd856640f"}, "downloads": -1, "filename": "universe-0.21.3.tar.gz", "has_sig": false, "md5_digest": "a6df6fc3179e75d3011fc3a7660188a6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 136998, "upload_time": "2017-03-05T22:23:32", "upload_time_iso_8601": "2017-03-05T22:23:32.713175Z", "url": "https://files.pythonhosted.org/packages/5b/5e/26ee56c16cdc83a07a3251e3425856f2ade84928de55b3fa11590ce2b912/universe-0.21.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:40:12 2020"}