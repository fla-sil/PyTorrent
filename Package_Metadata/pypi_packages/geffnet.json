{"info": {"author": "Ross Wightman", "author_email": "hello@rwightman.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Education", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Software Development", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "# (Generic) EfficientNets for PyTorch\n\nA 'generic' implementation of EfficientNet, MixNet, MobileNetV3, etc. that covers most of the compute/parameter efficient architectures derived from the MobileNet V1/V2 block sequence, including those found via automated neural architecture search. \n\nAll models are implemented by GenEfficientNet or MobileNetV3 classes, with string based architecture definitions to configure the block layouts (idea from [here](https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_models.py))\n\n## What's New\n\n### March 23, 2020\n * Add EfficientNet-Lite models w/ weights ported from [Tensorflow TPU](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite)\n * Add PyTorch trained MobileNet-V3 Large weights trained from stratch with this code to 75.77% top-1\n * IMPORTANT CHANGE (if training from scratch) - weight init changed to better match Tensorflow impl, set `fix_group_fanout=False` in `initialize_weight_goog` for old behavior\n\n### Feb 12, 2020\n * Add EfficientNet-L2 and B0-B7 NoisyStudent weights ported from [Tensorflow TPU](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)\n * Port new EfficientNet-B8 (RandAugment) weights from TF TPU, these are different than the B8 AdvProp, different input normalization.\n * Add RandAugment PyTorch trained EfficientNet-ES (EdgeTPU-Small) weights with 78.1 top-1. Trained by [Andrew Lavin](https://github.com/andravin)\n\n### Jan 22, 2020\n * Update weights for EfficientNet B0, B2, B3 and MixNet-XL with latest RandAugment trained weights. Trained with (https://github.com/rwightman/pytorch-image-models)\n * Fix torchscript compatibility for PyTorch 1.4, add torchscript support for MixedConv2d using ModuleDict\n * Test models, torchscript, onnx export with PyTorch 1.4 -- no issues\n\n### Nov 22, 2019\n * New top-1 high! Ported official TF EfficientNet AdvProp (https://arxiv.org/abs/1911.09665) weights and B8 model spec. Created a new set of `ap` models since they use a different\n preprocessing (Inception mean/std) from the original EfficientNet base/AA/RA weights.\n\n### Nov 15, 2019\n * Ported official TF MobileNet-V3 float32 large/small/minimalistic weights\n * Modifications to MobileNet-V3 model and components to support some additional config needed for differences between TF MobileNet-V3 and mine\n\n### Oct 30, 2019\n * Many of the models will now work with torch.jit.script, MixNet being the biggest exception\n * Improved interface for enabling torchscript or ONNX export compatible modes (via config)\n * Add JIT optimized mem-efficient Swish/Mish autograd.fn in addition to memory-efficient autgrad.fn\n * Activation factory to select best version of activation by name or override one globally\n * Add pretrained checkpoint load helper that handles input conv and classifier changes\n\n### Oct 27, 2019\n * Add CondConv EfficientNet variants ported from https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv\n * Add RandAug weights for TF EfficientNet B5 and B7 from https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\n * Bring over MixNet-XL model and depth scaling algo from my pytorch-image-models code base\n * Switch activations and global pooling to modules\n * Add memory-efficient Swish/Mish impl\n * Add as_sequential() method to all models and allow as an argument in entrypoint fns\n * Move MobileNetV3 into own file since it has a different head\n * Remove ChamNet, MobileNet V2/V1 since they will likely never be used here\n\n## Models\n\nImplemented models include:\n  * EfficientNet NoisyStudent (B0-B7, L2) (https://arxiv.org/abs/1911.04252)\n  * EfficientNet AdvProp (B0-B8) (https://arxiv.org/abs/1911.09665)\n  * EfficientNet (B0-B8) (https://arxiv.org/abs/1905.11946)\n  * EfficientNet-EdgeTPU (S, M, L) (https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html)\n  * EfficientNet-CondConv (https://arxiv.org/abs/1904.04971)\n  * EfficientNet-Lite (https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite)\n  * MixNet (https://arxiv.org/abs/1907.09595)\n  * MNASNet B1, A1 (Squeeze-Excite), and Small (https://arxiv.org/abs/1807.11626)\n  * MobileNet-V3 (https://arxiv.org/abs/1905.02244)\n  * FBNet-C (https://arxiv.org/abs/1812.03443)\n  * Single-Path NAS (https://arxiv.org/abs/1904.02877)\n\nI originally implemented and trained some these models with code [here](https://github.com/rwightman/pytorch-image-models), this repository contains just the GenEfficientNet models, validation, and associated ONNX/Caffe2 export code. \n\n## Pretrained\n\nI've managed to train several of the models to accuracies close to or above the originating papers and official impl. My training code is here: https://github.com/rwightman/pytorch-image-models\n\n\n|Model | Prec@1 (Err) | Prec@5 (Err) | Param#(M) | MAdds(M) | Image Scaling | Resolution | Crop |\n|---|---|---|---|---|---|---|---|\n| efficientnet_b3 | 81.866 (18.134) | 95.836 (4.164) | 12.23 | TBD | bicubic | 320 | 1.0 |\n| efficientnet_b3 | 81.508 (18.492) | 95.672 (4.328) | 12.23 | TBD | bicubic | 300 | 0.904 |\n| mixnet_xl | 81.074 (18.926) | 95.282 (4.718) | 11.90 | TBD | bicubic | 256 | 1.0 |\n| efficientnet_b2 | 80.612 (19.388) | 95.318 (4.682) | 9.1 | TBD | bicubic | 288 | 1.0 |\n| mixnet_xl | 80.476 (19.524) | 94.936 (5.064) | 11.90 | TBD | bicubic | 224 | 0.875 |\n| efficientnet_b2 | 80.288 (19.712) | 95.166 (4.834) | 9.1 | 1003 | bicubic | 260 | 0.890 |\n| mixnet_l | 78.976 (21.024 | 94.184 (5.816) | 7.33 | TBD | bicubic | 224 | 0.875 |\n| efficientnet_b1 | 78.692 (21.308) | 94.086 (5.914) | 7.8 | 694 | bicubic | 240 | 0.882 |\n| efficientnet_es | 78.066 (21.934) | 93.926 (6.074) | 5.44 | TBD | bicubic | 224 | 0.875 |\n| efficientnet_b0 | 77.698 (22.302) | 93.532 (6.468) | 5.3 | 390 | bicubic | 224 | 0.875 |\n| mixnet_m | 77.256 (22.744) | 93.418 (6.582) | 5.01 | 353 | bicubic | 224 | 0.875 |\n| mixnet_s | 75.988 (24.012) | 92.794 (7.206) | 4.13 | TBD | bicubic | 224 | 0.875 |\n| mobilenetv3_large_100 | 75.766 (24.234) | 92.542 (7.458) | 5.5M | bicubic | 224 | 0.875 |\n| mobilenetv3_rw | 75.634 (24.366) | 92.708 (7.292) | 5.5 | 219 | bicubic | 224 | 0.875 |\n| mnasnet_a1 | 75.448 (24.552) | 92.604 (7.396) | 3.9 | 312 | bicubic | 224 | 0.875 |\n| fbnetc_100 | 75.124 (24.876) | 92.386 (7.614) | 5.6 | 385 | bilinear | 224 | 0.875 |\n| mnasnet_b1 | 74.658 (25.342) | 92.114 (7.886) | 4.4 | 315 | bicubic | 224 | 0.875 |\n| spnasnet_100 | 74.084 (25.916)  | 91.818 (8.182) | 4.4 | TBD | bilinear | 224 | 0.875 |\n\n\nMore pretrained models to come...\n\n\n## Ported Weights\n\nThe weights ported from Tensorflow checkpoints for the EfficientNet models do pretty much match accuracy in Tensorflow once a SAME convolution padding equivalent is added, and the same crop factors, image scaling, etc (see table) are used via cmd line args.\n\n**IMPORTANT:** \n* Tensorflow ported weights for EfficientNet AdvProp (AP), EfficientNet EdgeTPU, EfficientNet-CondConv, EfficientNet-Lite, and MobileNet-V3 models use Inception style (0.5, 0.5, 0.5) for mean and std.\n* Enabling the Tensorflow preprocessing pipeline with `--tf-preprocessing` at validation time will improve scores by 0.1-0.5%, very close to original TF impl.\n\nTo run validation for tf_efficientnet_b5:\n`python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b5 -b 64 --img-size 456 --crop-pct 0.934 --interpolation bicubic`\n\nTo run validation w/ TF preprocessing for tf_efficientnet_b5:\n`python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b5 -b 64 --img-size 456 --tf-preprocessing`\n\nTo run validation for a model with Inception preprocessing, ie EfficientNet-B8 AdvProp:\n`python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b8_ap -b 48 --num-gpu 2 --img-size 672 --crop-pct 0.954 --mean 0.5 --std 0.5`\n\n|Model | Prec@1 (Err) | Prec@5 (Err) | Param # | Image Scaling  | Image Size | Crop | \n|---|---|---|---|---|---|---|\n| tf_efficientnet_l2_ns *tfp | 88.352 (11.648) | 98.652 (1.348) | 480 | bicubic | 800 | N/A |\n| tf_efficientnet_l2_ns      | TBD | TBD | 480 | bicubic | 800 | 0.961 |\n| tf_efficientnet_l2_ns_475      | 88.234 (11.766) | 98.546 (1.454) | 480 | bicubic | 475 | 0.936 |\n| tf_efficientnet_l2_ns_475 *tfp | 88.172 (11.828) | 98.566 (1.434) | 480 | bicubic | 475 | N/A |\n| tf_efficientnet_b7_ns *tfp | 86.844 (13.156) | 98.084 (1.916) | 66.35 | bicubic | 600 | N/A |\n| tf_efficientnet_b7_ns      | 86.840 (13.160) | 98.094 (1.906) | 66.35 | bicubic | 600 | N/A |\n| tf_efficientnet_b6_ns      | 86.452 (13.548) | 97.882 (2.118) | 43.04 | bicubic | 528 | N/A |\n| tf_efficientnet_b6_ns *tfp | 86.444 (13.556) | 97.880 (2.120) | 43.04 | bicubic | 528 | N/A |\n| tf_efficientnet_b5_ns *tfp | 86.064 (13.936) | 97.746 (2.254) | 30.39 | bicubic | 456 | N/A |\n| tf_efficientnet_b5_ns      | 86.088 (13.912) | 97.752 (2.248) | 30.39 | bicubic | 456 | N/A |\n| tf_efficientnet_b8_ap *tfp | 85.436 (14.564) | 97.272 (2.728) | 87.4 | bicubic | 672 | N/A |\n| tf_efficientnet_b8 *tfp    | 85.384 (14.616) | 97.394 (2.606) | 87.4 | bicubic | 672 | N/A |\n| tf_efficientnet_b8         | 85.370 (14.630) | 97.390 (2.610) | 87.4 | bicubic | 672 | 0.954 |\n| tf_efficientnet_b8_ap      | 85.368 (14.632) | 97.294 (2.706) | 87.4 | bicubic | 672 | 0.954 |\n| tf_efficientnet_b4_ns *tfp | 85.298 (14.702) | 97.504 (2.496) | 19.34 | bicubic | 380 | N/A |\n| tf_efficientnet_b4_ns      | 85.162 (14.838) | 97.470 (2.530) | 19.34 | bicubic | 380 | 0.922 |\n| tf_efficientnet_b7_ap *tfp | 85.154 (14.846) | 97.244 (2.756) | 66.35 | bicubic | 600 | N/A |\n| tf_efficientnet_b7_ap      | 85.118 (14.882) | 97.252 (2.748) | 66.35 | bicubic | 600 | 0.949 |\n| tf_efficientnet_b7 *tfp | 84.940 (15.060) | 97.214 (2.786) | 66.35 | bicubic | 600 | N/A |\n| tf_efficientnet_b7      | 84.932 (15.068) | 97.208 (2.792) | 66.35 | bicubic | 600 | 0.949 |\n| tf_efficientnet_b6_ap      | 84.786 (15.214) | 97.138 (2.862) | 43.04 | bicubic | 528 | 0.942 |\n| tf_efficientnet_b6_ap *tfp | 84.760 (15.240) | 97.124 (2.876) | 43.04 | bicubic | 528 | N/A |\n| tf_efficientnet_b5_ap *tfp | 84.276 (15.724) | 96.932 (3.068) | 30.39 | bicubic | 456 | N/A |\n| tf_efficientnet_b5_ap      | 84.254 (15.746) | 96.976 (3.024) | 30.39 | bicubic | 456 | 0.934 |\n| tf_efficientnet_b6 *tfp  | 84.140 (15.860) | 96.852 (3.148) | 43.04 | bicubic | 528 | N/A |\n| tf_efficientnet_b6       | 84.110 (15.890) | 96.886 (3.114) | 43.04 | bicubic | 528 | 0.942 |\n| tf_efficientnet_b3_ns *tfp | 84.054 (15.946) | 96.918 (3.082) | 12.23 | bicubic | 300 | N/A |\n| tf_efficientnet_b3_ns      | 84.048 (15.952) | 96.910 (3.090) | 12.23 | bicubic | 300 | .904 |\n| tf_efficientnet_b5 *tfp  | 83.822 (16.178) | 96.756 (3.244) | 30.39 | bicubic | 456 | N/A |\n| tf_efficientnet_b5       | 83.812 (16.188) | 96.748 (3.252) | 30.39 | bicubic | 456 | 0.934 |\n| tf_efficientnet_b4_ap *tfp | 83.278 (16.722) | 96.376 (3.624) | 19.34 | bicubic | 380 | N/A |\n| tf_efficientnet_b4_ap      | 83.248 (16.752) | 96.388 (3.612) | 19.34 | bicubic | 380 | 0.922 |\n| tf_efficientnet_b4       | 83.022 (16.978) | 96.300 (3.700) | 19.34 | bicubic | 380 | 0.922 |\n| tf_efficientnet_b4 *tfp  | 82.948 (17.052) | 96.308 (3.692) | 19.34 | bicubic | 380 | N/A |\n| tf_efficientnet_b2_ns *tfp | 82.436 (17.564) | 96.268 (3.732) | 9.11 | bicubic | 260 | N/A |\n| tf_efficientnet_b2_ns      | 82.380 (17.620) | 96.248 (3.752) | 9.11 | bicubic | 260 | 0.89 |\n| tf_efficientnet_b3_ap *tfp | 81.882 (18.118) | 95.662 (4.338) | 12.23 | bicubic | 300 | N/A |\n| tf_efficientnet_b3_ap      | 81.828 (18.172) | 95.624 (4.376) | 12.23 | bicubic | 300 | 0.904 |\n| tf_efficientnet_b3       | 81.636 (18.364) | 95.718 (4.282) | 12.23 | bicubic | 300 | 0.904 |\n| tf_efficientnet_b3 *tfp  | 81.576 (18.424) | 95.662 (4.338) | 12.23 | bicubic | 300 | N/A |\n| tf_efficientnet_lite4      | 81.528 (18.472) | 95.668 (4.332) | 13.00  | bilinear | 380 | 0.92 |\n| tf_efficientnet_b1_ns *tfp | 81.514 (18.486) | 95.776 (4.224) | 7.79 | bicubic | 240 | N/A |\n| tf_efficientnet_lite4 *tfp | 81.502 (18.498) | 95.676 (4.324) | 13.00  | bilinear | 380 | N/A |\n| tf_efficientnet_b1_ns      | 81.388 (18.612) | 95.738 (4.262) | 7.79 | bicubic | 240 | 0.88 |\n| tf_efficientnet_el       | 80.534 (19.466) | 95.190 (4.810) | 10.59 | bicubic | 300 | 0.904 |\n| tf_efficientnet_el *tfp  | 80.476 (19.524) | 95.200 (4.800) | 10.59 | bicubic | 300 | N/A |\n| tf_efficientnet_b2_ap *tfp | 80.420 (19.580) | 95.040 (4.960) | 9.11 | bicubic | 260 | N/A |\n| tf_efficientnet_b2_ap    | 80.306 (19.694) | 95.028 (4.972) | 9.11 | bicubic | 260 | 0.890 |\n| tf_efficientnet_b2 *tfp  | 80.188 (19.812) | 94.974 (5.026) | 9.11 | bicubic | 260 | N/A |\n| tf_efficientnet_b2       | 80.086 (19.914) | 94.908 (5.092) | 9.11 | bicubic | 260 | 0.890 |\n| tf_efficientnet_lite3       | 79.812 (20.188) | 94.914 (5.086) | 8.20  | bilinear | 300 | 0.904 |\n| tf_efficientnet_lite3 *tfp  | 79.734 (20.266) | 94.838 (5.162) | 8.20  | bilinear | 300 | N/A |\n| tf_efficientnet_b1_ap *tfp | 79.532 (20.468) | 94.378 (5.622) | 7.79 | bicubic | 240 | N/A |\n| tf_efficientnet_cc_b1_8e *tfp | 79.464 (20.536)| 94.492 (5.508) | 39.7 | bicubic | 240 | 0.88 |\n| tf_efficientnet_cc_b1_8e | 79.298 (20.702) | 94.364 (5.636) | 39.7 | bicubic | 240 | 0.88 |\n| tf_efficientnet_b1_ap    | 79.278 (20.722) | 94.308 (5.692) | 7.79 | bicubic | 240 | 0.88 |\n| tf_efficientnet_b1 *tfp  | 79.172 (20.828) | 94.450 (5.550) | 7.79 | bicubic | 240 | N/A |\n| tf_efficientnet_em *tfp  | 78.958 (21.042) | 94.458 (5.542) | 6.90 | bicubic | 240 | N/A |\n| tf_efficientnet_b0_ns *tfp | 78.806 (21.194) | 94.496 (5.504) | 5.29 | bicubic | 224 | N/A |\n| tf_mixnet_l *tfp         | 78.846 (21.154) | 94.212 (5.788) | 7.33 | bilinear | 224 | N/A |\n| tf_efficientnet_b1       | 78.826 (21.174) | 94.198 (5.802) | 7.79 | bicubic | 240 | 0.88 |\n| tf_mixnet_l              | 78.770 (21.230) | 94.004 (5.996) | 7.33 | bicubic | 224 | 0.875 |\n| tf_efficientnet_em       | 78.742 (21.258) | 94.332 (5.668) | 6.90 | bicubic | 240 | 0.875 |\n| tf_efficientnet_b0_ns    | 78.658 (21.342) | 94.376 (5.624) | 5.29 | bicubic | 224 | 0.875 |\n| tf_efficientnet_cc_b0_8e *tfp | 78.314 (21.686) | 93.790 (6.210) | 24.0 | bicubic | 224 | 0.875 |\n| tf_efficientnet_cc_b0_8e | 77.908 (22.092) | 93.656 (6.344) | 24.0 | bicubic | 224 | 0.875 |\n| tf_efficientnet_cc_b0_4e *tfp | 77.746 (22.254) | 93.552 (6.448) | 13.3 | bicubic | 224 | 0.875 |\n| tf_efficientnet_cc_b0_4e | 77.304 (22.696) | 93.332 (6.668) | 13.3 | bicubic | 224 | 0.875 |\n| tf_efficientnet_es *tfp  | 77.616 (22.384) | 93.750 (6.250) | 5.44 | bicubic | 224 | N/A |\n| tf_efficientnet_lite2 *tfp  | 77.544 (22.456) | 93.800 (6.200) | 6.09  | bilinear | 260 | N/A |\n| tf_efficientnet_lite2       | 77.460 (22.540) | 93.746 (6.254) | 6.09  | bicubic | 260 | 0.89 |\n| tf_efficientnet_b0_ap *tfp | 77.514 (22.486) | 93.576 (6.424) | 5.29  | bicubic | 224 | N/A |\n| tf_efficientnet_es       | 77.264 (22.736) | 93.600 (6.400) | 5.44 | bicubic | 224 | N/A |\n| tf_efficientnet_b0 *tfp  | 77.258 (22.742) | 93.478 (6.522) | 5.29  | bicubic | 224 | N/A |\n| tf_efficientnet_b0_ap    | 77.084 (22.916) | 93.254 (6.746) | 5.29  | bicubic | 224 | 0.875 |\n| tf_mixnet_m *tfp         | 77.072 (22.928) | 93.368 (6.632) | 5.01 | bilinear | 224 | N/A |\n| tf_mixnet_m              | 76.950 (23.050) | 93.156 (6.844) | 5.01 | bicubic | 224 | 0.875 |\n| tf_efficientnet_b0       | 76.848 (23.152) | 93.228 (6.772) | 5.29  | bicubic | 224 | 0.875 |\n| tf_efficientnet_lite1 *tfp  | 76.764 (23.236) | 93.326 (6.674) | 5.42  | bilinear | 240 | N/A |\n| tf_efficientnet_lite1       | 76.638 (23.362) | 93.232 (6.768) | 5.42  | bicubic | 240 | 0.882 |\n| tf_mixnet_s *tfp         | 75.800 (24.200) | 92.788 (7.212) | 4.13 | bilinear | 224 | N/A |\n| tf_mobilenetv3_large_100 *tfp | 75.768 (24.232) | 92.710 (7.290) | 5.48 | bilinear | 224 | N/A |\n| tf_mixnet_s              | 75.648 (24.352) | 92.636 (7.364) | 4.13 | bicubic | 224 | 0.875 |\n| tf_mobilenetv3_large_100 | 75.516 (24.484) | 92.600 (7.400) | 5.48 | bilinear | 224 | 0.875 |\n| tf_efficientnet_lite0 *tfp  | 75.074 (24.926) | 92.314 (7.686) | 4.65  | bilinear | 224 | N/A |\n| tf_efficientnet_lite0       | 74.842 (25.158) | 92.170 (7.830) | 4.65  | bicubic | 224 | 0.875 |\n| tf_mobilenetv3_large_075 *tfp | 73.730 (26.270) | 91.616 (8.384) | 3.99 | bilinear | 224 |N/A |\n| tf_mobilenetv3_large_075 | 73.442 (26.558) | 91.352 (8.648) | 3.99 | bilinear | 224 | 0.875 |\n| tf_mobilenetv3_large_minimal_100 *tfp | 72.678 (27.322) | 90.860 (9.140) | 3.92 | bilinear | 224 | N/A |\n| tf_mobilenetv3_large_minimal_100 | 72.244 (27.756) | 90.636 (9.364) | 3.92 | bilinear | 224 | 0.875 |\n| tf_mobilenetv3_small_100 *tfp | 67.918 (32.082) | 87.958 (12.042 | 2.54 | bilinear | 224 | N/A |\n| tf_mobilenetv3_small_100 | 67.918 (32.082) | 87.662 (12.338) | 2.54 | bilinear | 224 | 0.875 |\n| tf_mobilenetv3_small_075 *tfp | 66.142 (33.858) | 86.498 (13.502) | 2.04 | bilinear | 224 | N/A |\n| tf_mobilenetv3_small_075 | 65.718 (34.282) | 86.136 (13.864) | 2.04 | bilinear | 224 | 0.875 |\n| tf_mobilenetv3_small_minimal_100 *tfp | 63.378 (36.622) | 84.802 (15.198) | 2.04 | bilinear | 224 | N/A |\n| tf_mobilenetv3_small_minimal_100 | 62.898 (37.102) | 84.230 (15.770) | 2.04 | bilinear | 224 | 0.875 |\n\n\n*tfp models validated with `tf-preprocessing` pipeline\n\nGoogle tf and tflite weights ported from official Tensorflow repositories\n* https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\n* https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\n* https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\n\n## Usage\n\n### Environment\n\nAll development and testing has been done in Conda Python 3 environments on Linux x86-64 systems, specifically Python 3.6.x and 3.7.x.\n\nUsers have reported that a Python 3 Anaconda install in Windows works. I have not verified this myself.\n\nPyTorch versions 1.2. 1.3.1, 1.4 have been tested with this code.\n\nI've tried to keep the dependencies minimal, the setup is as per the PyTorch default install instructions for Conda:\n```\nconda create -n torch-env\nconda activate torch-env\nconda install -c pytorch pytorch torchvision cudatoolkit=10\n```\n\n### PyTorch Hub\n\nModels can be accessed via the PyTorch Hub API\n\n```\n>>> torch.hub.list('rwightman/gen-efficientnet-pytorch')\n['efficientnet_b0', ...]\n>>> model = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n>>> model.eval()\n>>> output = model(torch.randn(1,3,224,224))\n```\n\n### Pip\nThis package can be installed via pip.\n\nInstall (after conda env/install):\n```\npip install geffnet\n```\n\nEval use:\n```\n>>> import geffnet\n>>> m = geffnet.create_model('mobilenetv3_rw', pretrained=True)\n>>> m.eval()\n```\n\nTrain use:\n```\n>>> import geffnet\n>>> # models can also be created by using the entrypoint directly\n>>> m = geffnet.efficientnet_b2(pretrained=True, drop_rate=0.25, drop_connect_rate=0.2)\n>>> m.train()\n```\n\nCreate in a nn.Sequential container, for fast.ai, etc:\n```\n>>> import geffnet\n>>> m = geffnet.mixnet_l(pretrained=True, drop_rate=0.25, drop_connect_rate=0.2, as_sequential=True)\n```\n\n### Exporting\n\nScripts to export models to ONNX and then to Caffe2 are included, along with a Caffe2 script to verify.\n\nAs an example, to export the MobileNet-V3 pretrained model and then run an Imagenet validation:\n```\npython onnx_export.py --model tf_mobilenetv3_large_100 ./mobilenetv3_100.onnx\npython onnx_optimize.py ./mobilenetv3_100.onnx --output ./mobilenetv3_100-opt.onnx\npython onnx_to_caffe.py ./mobilenetv3_100-opt.onnx --c2-prefix mobilenetv3\npython caffe2_validate.py /imagenet/validation/ --c2-init ./mobilenetv3.init.pb --c2-predict ./mobilenetv3.predict.pb --interpolation bicubic\n```\n**NOTE** the TF ported weights with the 'SAME' conv padding activated cannot be exported to ONNX unless `_EXPORTABLE` flag in `config.py` is set to True. Use `config.set_exportable(True)` as in the updated `onnx_export.py` example script.\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/rwightman/gen-efficientnet-pytorch", "keywords": "pytorch pretrained models efficientnet mixnet mobilenetv3 mnasnet", "license": "", "maintainer": "", "maintainer_email": "", "name": "geffnet", "package_url": "https://pypi.org/project/geffnet/", "platform": "", "project_url": "https://pypi.org/project/geffnet/", "project_urls": {"Homepage": "https://github.com/rwightman/gen-efficientnet-pytorch"}, "release_url": "https://pypi.org/project/geffnet/0.9.8/", "requires_dist": ["torch (>=1.2)", "torchvision"], "requires_python": ">=3.6", "summary": "(Generic) EfficientNets for PyTorch", "version": "0.9.8", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>(Generic) EfficientNets for PyTorch</h1>\n<p>A 'generic' implementation of EfficientNet, MixNet, MobileNetV3, etc. that covers most of the compute/parameter efficient architectures derived from the MobileNet V1/V2 block sequence, including those found via automated neural architecture search.</p>\n<p>All models are implemented by GenEfficientNet or MobileNetV3 classes, with string based architecture definitions to configure the block layouts (idea from <a href=\"https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_models.py\" rel=\"nofollow\">here</a>)</p>\n<h2>What's New</h2>\n<h3>March 23, 2020</h3>\n<ul>\n<li>Add EfficientNet-Lite models w/ weights ported from <a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite\" rel=\"nofollow\">Tensorflow TPU</a></li>\n<li>Add PyTorch trained MobileNet-V3 Large weights trained from stratch with this code to 75.77% top-1</li>\n<li>IMPORTANT CHANGE (if training from scratch) - weight init changed to better match Tensorflow impl, set <code>fix_group_fanout=False</code> in <code>initialize_weight_goog</code> for old behavior</li>\n</ul>\n<h3>Feb 12, 2020</h3>\n<ul>\n<li>Add EfficientNet-L2 and B0-B7 NoisyStudent weights ported from <a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\" rel=\"nofollow\">Tensorflow TPU</a></li>\n<li>Port new EfficientNet-B8 (RandAugment) weights from TF TPU, these are different than the B8 AdvProp, different input normalization.</li>\n<li>Add RandAugment PyTorch trained EfficientNet-ES (EdgeTPU-Small) weights with 78.1 top-1. Trained by <a href=\"https://github.com/andravin\" rel=\"nofollow\">Andrew Lavin</a></li>\n</ul>\n<h3>Jan 22, 2020</h3>\n<ul>\n<li>Update weights for EfficientNet B0, B2, B3 and MixNet-XL with latest RandAugment trained weights. Trained with (<a href=\"https://github.com/rwightman/pytorch-image-models\" rel=\"nofollow\">https://github.com/rwightman/pytorch-image-models</a>)</li>\n<li>Fix torchscript compatibility for PyTorch 1.4, add torchscript support for MixedConv2d using ModuleDict</li>\n<li>Test models, torchscript, onnx export with PyTorch 1.4 -- no issues</li>\n</ul>\n<h3>Nov 22, 2019</h3>\n<ul>\n<li>New top-1 high! Ported official TF EfficientNet AdvProp (<a href=\"https://arxiv.org/abs/1911.09665\" rel=\"nofollow\">https://arxiv.org/abs/1911.09665</a>) weights and B8 model spec. Created a new set of <code>ap</code> models since they use a different\npreprocessing (Inception mean/std) from the original EfficientNet base/AA/RA weights.</li>\n</ul>\n<h3>Nov 15, 2019</h3>\n<ul>\n<li>Ported official TF MobileNet-V3 float32 large/small/minimalistic weights</li>\n<li>Modifications to MobileNet-V3 model and components to support some additional config needed for differences between TF MobileNet-V3 and mine</li>\n</ul>\n<h3>Oct 30, 2019</h3>\n<ul>\n<li>Many of the models will now work with torch.jit.script, MixNet being the biggest exception</li>\n<li>Improved interface for enabling torchscript or ONNX export compatible modes (via config)</li>\n<li>Add JIT optimized mem-efficient Swish/Mish autograd.fn in addition to memory-efficient autgrad.fn</li>\n<li>Activation factory to select best version of activation by name or override one globally</li>\n<li>Add pretrained checkpoint load helper that handles input conv and classifier changes</li>\n</ul>\n<h3>Oct 27, 2019</h3>\n<ul>\n<li>Add CondConv EfficientNet variants ported from <a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv\" rel=\"nofollow\">https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/condconv</a></li>\n<li>Add RandAug weights for TF EfficientNet B5 and B7 from <a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\" rel=\"nofollow\">https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet</a></li>\n<li>Bring over MixNet-XL model and depth scaling algo from my pytorch-image-models code base</li>\n<li>Switch activations and global pooling to modules</li>\n<li>Add memory-efficient Swish/Mish impl</li>\n<li>Add as_sequential() method to all models and allow as an argument in entrypoint fns</li>\n<li>Move MobileNetV3 into own file since it has a different head</li>\n<li>Remove ChamNet, MobileNet V2/V1 since they will likely never be used here</li>\n</ul>\n<h2>Models</h2>\n<p>Implemented models include:</p>\n<ul>\n<li>EfficientNet NoisyStudent (B0-B7, L2) (<a href=\"https://arxiv.org/abs/1911.04252\" rel=\"nofollow\">https://arxiv.org/abs/1911.04252</a>)</li>\n<li>EfficientNet AdvProp (B0-B8) (<a href=\"https://arxiv.org/abs/1911.09665\" rel=\"nofollow\">https://arxiv.org/abs/1911.09665</a>)</li>\n<li>EfficientNet (B0-B8) (<a href=\"https://arxiv.org/abs/1905.11946\" rel=\"nofollow\">https://arxiv.org/abs/1905.11946</a>)</li>\n<li>EfficientNet-EdgeTPU (S, M, L) (<a href=\"https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html\" rel=\"nofollow\">https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.html</a>)</li>\n<li>EfficientNet-CondConv (<a href=\"https://arxiv.org/abs/1904.04971\" rel=\"nofollow\">https://arxiv.org/abs/1904.04971</a>)</li>\n<li>EfficientNet-Lite (<a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite\" rel=\"nofollow\">https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite</a>)</li>\n<li>MixNet (<a href=\"https://arxiv.org/abs/1907.09595\" rel=\"nofollow\">https://arxiv.org/abs/1907.09595</a>)</li>\n<li>MNASNet B1, A1 (Squeeze-Excite), and Small (<a href=\"https://arxiv.org/abs/1807.11626\" rel=\"nofollow\">https://arxiv.org/abs/1807.11626</a>)</li>\n<li>MobileNet-V3 (<a href=\"https://arxiv.org/abs/1905.02244\" rel=\"nofollow\">https://arxiv.org/abs/1905.02244</a>)</li>\n<li>FBNet-C (<a href=\"https://arxiv.org/abs/1812.03443\" rel=\"nofollow\">https://arxiv.org/abs/1812.03443</a>)</li>\n<li>Single-Path NAS (<a href=\"https://arxiv.org/abs/1904.02877\" rel=\"nofollow\">https://arxiv.org/abs/1904.02877</a>)</li>\n</ul>\n<p>I originally implemented and trained some these models with code <a href=\"https://github.com/rwightman/pytorch-image-models\" rel=\"nofollow\">here</a>, this repository contains just the GenEfficientNet models, validation, and associated ONNX/Caffe2 export code.</p>\n<h2>Pretrained</h2>\n<p>I've managed to train several of the models to accuracies close to or above the originating papers and official impl. My training code is here: <a href=\"https://github.com/rwightman/pytorch-image-models\" rel=\"nofollow\">https://github.com/rwightman/pytorch-image-models</a></p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Prec@1 (Err)</th>\n<th>Prec@5 (Err)</th>\n<th>Param#(M)</th>\n<th>MAdds(M)</th>\n<th>Image Scaling</th>\n<th>Resolution</th>\n<th>Crop</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>efficientnet_b3</td>\n<td>81.866 (18.134)</td>\n<td>95.836 (4.164)</td>\n<td>12.23</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>320</td>\n<td>1.0</td>\n</tr>\n<tr>\n<td>efficientnet_b3</td>\n<td>81.508 (18.492)</td>\n<td>95.672 (4.328)</td>\n<td>12.23</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>300</td>\n<td>0.904</td>\n</tr>\n<tr>\n<td>mixnet_xl</td>\n<td>81.074 (18.926)</td>\n<td>95.282 (4.718)</td>\n<td>11.90</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>256</td>\n<td>1.0</td>\n</tr>\n<tr>\n<td>efficientnet_b2</td>\n<td>80.612 (19.388)</td>\n<td>95.318 (4.682)</td>\n<td>9.1</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>288</td>\n<td>1.0</td>\n</tr>\n<tr>\n<td>mixnet_xl</td>\n<td>80.476 (19.524)</td>\n<td>94.936 (5.064)</td>\n<td>11.90</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>efficientnet_b2</td>\n<td>80.288 (19.712)</td>\n<td>95.166 (4.834)</td>\n<td>9.1</td>\n<td>1003</td>\n<td>bicubic</td>\n<td>260</td>\n<td>0.890</td>\n</tr>\n<tr>\n<td>mixnet_l</td>\n<td>78.976 (21.024</td>\n<td>94.184 (5.816)</td>\n<td>7.33</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>efficientnet_b1</td>\n<td>78.692 (21.308)</td>\n<td>94.086 (5.914)</td>\n<td>7.8</td>\n<td>694</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.882</td>\n</tr>\n<tr>\n<td>efficientnet_es</td>\n<td>78.066 (21.934)</td>\n<td>93.926 (6.074)</td>\n<td>5.44</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>efficientnet_b0</td>\n<td>77.698 (22.302)</td>\n<td>93.532 (6.468)</td>\n<td>5.3</td>\n<td>390</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>mixnet_m</td>\n<td>77.256 (22.744)</td>\n<td>93.418 (6.582)</td>\n<td>5.01</td>\n<td>353</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>mixnet_s</td>\n<td>75.988 (24.012)</td>\n<td>92.794 (7.206)</td>\n<td>4.13</td>\n<td>TBD</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>mobilenetv3_large_100</td>\n<td>75.766 (24.234)</td>\n<td>92.542 (7.458)</td>\n<td>5.5M</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n<td></td>\n</tr>\n<tr>\n<td>mobilenetv3_rw</td>\n<td>75.634 (24.366)</td>\n<td>92.708 (7.292)</td>\n<td>5.5</td>\n<td>219</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>mnasnet_a1</td>\n<td>75.448 (24.552)</td>\n<td>92.604 (7.396)</td>\n<td>3.9</td>\n<td>312</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>fbnetc_100</td>\n<td>75.124 (24.876)</td>\n<td>92.386 (7.614)</td>\n<td>5.6</td>\n<td>385</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>mnasnet_b1</td>\n<td>74.658 (25.342)</td>\n<td>92.114 (7.886)</td>\n<td>4.4</td>\n<td>315</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>spnasnet_100</td>\n<td>74.084 (25.916)</td>\n<td>91.818 (8.182)</td>\n<td>4.4</td>\n<td>TBD</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr></tbody></table>\n<p>More pretrained models to come...</p>\n<h2>Ported Weights</h2>\n<p>The weights ported from Tensorflow checkpoints for the EfficientNet models do pretty much match accuracy in Tensorflow once a SAME convolution padding equivalent is added, and the same crop factors, image scaling, etc (see table) are used via cmd line args.</p>\n<p><strong>IMPORTANT:</strong></p>\n<ul>\n<li>Tensorflow ported weights for EfficientNet AdvProp (AP), EfficientNet EdgeTPU, EfficientNet-CondConv, EfficientNet-Lite, and MobileNet-V3 models use Inception style (0.5, 0.5, 0.5) for mean and std.</li>\n<li>Enabling the Tensorflow preprocessing pipeline with <code>--tf-preprocessing</code> at validation time will improve scores by 0.1-0.5%, very close to original TF impl.</li>\n</ul>\n<p>To run validation for tf_efficientnet_b5:\n<code>python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b5 -b 64 --img-size 456 --crop-pct 0.934 --interpolation bicubic</code></p>\n<p>To run validation w/ TF preprocessing for tf_efficientnet_b5:\n<code>python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b5 -b 64 --img-size 456 --tf-preprocessing</code></p>\n<p>To run validation for a model with Inception preprocessing, ie EfficientNet-B8 AdvProp:\n<code>python validate.py /path/to/imagenet/validation/ --model tf_efficientnet_b8_ap -b 48 --num-gpu 2 --img-size 672 --crop-pct 0.954 --mean 0.5 --std 0.5</code></p>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Prec@1 (Err)</th>\n<th>Prec@5 (Err)</th>\n<th>Param #</th>\n<th>Image Scaling</th>\n<th>Image Size</th>\n<th>Crop</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>tf_efficientnet_l2_ns *tfp</td>\n<td>88.352 (11.648)</td>\n<td>98.652 (1.348)</td>\n<td>480</td>\n<td>bicubic</td>\n<td>800</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_l2_ns</td>\n<td>TBD</td>\n<td>TBD</td>\n<td>480</td>\n<td>bicubic</td>\n<td>800</td>\n<td>0.961</td>\n</tr>\n<tr>\n<td>tf_efficientnet_l2_ns_475</td>\n<td>88.234 (11.766)</td>\n<td>98.546 (1.454)</td>\n<td>480</td>\n<td>bicubic</td>\n<td>475</td>\n<td>0.936</td>\n</tr>\n<tr>\n<td>tf_efficientnet_l2_ns_475 *tfp</td>\n<td>88.172 (11.828)</td>\n<td>98.566 (1.434)</td>\n<td>480</td>\n<td>bicubic</td>\n<td>475</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b7_ns *tfp</td>\n<td>86.844 (13.156)</td>\n<td>98.084 (1.916)</td>\n<td>66.35</td>\n<td>bicubic</td>\n<td>600</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b7_ns</td>\n<td>86.840 (13.160)</td>\n<td>98.094 (1.906)</td>\n<td>66.35</td>\n<td>bicubic</td>\n<td>600</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b6_ns</td>\n<td>86.452 (13.548)</td>\n<td>97.882 (2.118)</td>\n<td>43.04</td>\n<td>bicubic</td>\n<td>528</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b6_ns *tfp</td>\n<td>86.444 (13.556)</td>\n<td>97.880 (2.120)</td>\n<td>43.04</td>\n<td>bicubic</td>\n<td>528</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b5_ns *tfp</td>\n<td>86.064 (13.936)</td>\n<td>97.746 (2.254)</td>\n<td>30.39</td>\n<td>bicubic</td>\n<td>456</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b5_ns</td>\n<td>86.088 (13.912)</td>\n<td>97.752 (2.248)</td>\n<td>30.39</td>\n<td>bicubic</td>\n<td>456</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b8_ap *tfp</td>\n<td>85.436 (14.564)</td>\n<td>97.272 (2.728)</td>\n<td>87.4</td>\n<td>bicubic</td>\n<td>672</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b8 *tfp</td>\n<td>85.384 (14.616)</td>\n<td>97.394 (2.606)</td>\n<td>87.4</td>\n<td>bicubic</td>\n<td>672</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b8</td>\n<td>85.370 (14.630)</td>\n<td>97.390 (2.610)</td>\n<td>87.4</td>\n<td>bicubic</td>\n<td>672</td>\n<td>0.954</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b8_ap</td>\n<td>85.368 (14.632)</td>\n<td>97.294 (2.706)</td>\n<td>87.4</td>\n<td>bicubic</td>\n<td>672</td>\n<td>0.954</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b4_ns *tfp</td>\n<td>85.298 (14.702)</td>\n<td>97.504 (2.496)</td>\n<td>19.34</td>\n<td>bicubic</td>\n<td>380</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b4_ns</td>\n<td>85.162 (14.838)</td>\n<td>97.470 (2.530)</td>\n<td>19.34</td>\n<td>bicubic</td>\n<td>380</td>\n<td>0.922</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b7_ap *tfp</td>\n<td>85.154 (14.846)</td>\n<td>97.244 (2.756)</td>\n<td>66.35</td>\n<td>bicubic</td>\n<td>600</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b7_ap</td>\n<td>85.118 (14.882)</td>\n<td>97.252 (2.748)</td>\n<td>66.35</td>\n<td>bicubic</td>\n<td>600</td>\n<td>0.949</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b7 *tfp</td>\n<td>84.940 (15.060)</td>\n<td>97.214 (2.786)</td>\n<td>66.35</td>\n<td>bicubic</td>\n<td>600</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b7</td>\n<td>84.932 (15.068)</td>\n<td>97.208 (2.792)</td>\n<td>66.35</td>\n<td>bicubic</td>\n<td>600</td>\n<td>0.949</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b6_ap</td>\n<td>84.786 (15.214)</td>\n<td>97.138 (2.862)</td>\n<td>43.04</td>\n<td>bicubic</td>\n<td>528</td>\n<td>0.942</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b6_ap *tfp</td>\n<td>84.760 (15.240)</td>\n<td>97.124 (2.876)</td>\n<td>43.04</td>\n<td>bicubic</td>\n<td>528</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b5_ap *tfp</td>\n<td>84.276 (15.724)</td>\n<td>96.932 (3.068)</td>\n<td>30.39</td>\n<td>bicubic</td>\n<td>456</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b5_ap</td>\n<td>84.254 (15.746)</td>\n<td>96.976 (3.024)</td>\n<td>30.39</td>\n<td>bicubic</td>\n<td>456</td>\n<td>0.934</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b6 *tfp</td>\n<td>84.140 (15.860)</td>\n<td>96.852 (3.148)</td>\n<td>43.04</td>\n<td>bicubic</td>\n<td>528</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b6</td>\n<td>84.110 (15.890)</td>\n<td>96.886 (3.114)</td>\n<td>43.04</td>\n<td>bicubic</td>\n<td>528</td>\n<td>0.942</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b3_ns *tfp</td>\n<td>84.054 (15.946)</td>\n<td>96.918 (3.082)</td>\n<td>12.23</td>\n<td>bicubic</td>\n<td>300</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b3_ns</td>\n<td>84.048 (15.952)</td>\n<td>96.910 (3.090)</td>\n<td>12.23</td>\n<td>bicubic</td>\n<td>300</td>\n<td>.904</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b5 *tfp</td>\n<td>83.822 (16.178)</td>\n<td>96.756 (3.244)</td>\n<td>30.39</td>\n<td>bicubic</td>\n<td>456</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b5</td>\n<td>83.812 (16.188)</td>\n<td>96.748 (3.252)</td>\n<td>30.39</td>\n<td>bicubic</td>\n<td>456</td>\n<td>0.934</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b4_ap *tfp</td>\n<td>83.278 (16.722)</td>\n<td>96.376 (3.624)</td>\n<td>19.34</td>\n<td>bicubic</td>\n<td>380</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b4_ap</td>\n<td>83.248 (16.752)</td>\n<td>96.388 (3.612)</td>\n<td>19.34</td>\n<td>bicubic</td>\n<td>380</td>\n<td>0.922</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b4</td>\n<td>83.022 (16.978)</td>\n<td>96.300 (3.700)</td>\n<td>19.34</td>\n<td>bicubic</td>\n<td>380</td>\n<td>0.922</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b4 *tfp</td>\n<td>82.948 (17.052)</td>\n<td>96.308 (3.692)</td>\n<td>19.34</td>\n<td>bicubic</td>\n<td>380</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b2_ns *tfp</td>\n<td>82.436 (17.564)</td>\n<td>96.268 (3.732)</td>\n<td>9.11</td>\n<td>bicubic</td>\n<td>260</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b2_ns</td>\n<td>82.380 (17.620)</td>\n<td>96.248 (3.752)</td>\n<td>9.11</td>\n<td>bicubic</td>\n<td>260</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b3_ap *tfp</td>\n<td>81.882 (18.118)</td>\n<td>95.662 (4.338)</td>\n<td>12.23</td>\n<td>bicubic</td>\n<td>300</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b3_ap</td>\n<td>81.828 (18.172)</td>\n<td>95.624 (4.376)</td>\n<td>12.23</td>\n<td>bicubic</td>\n<td>300</td>\n<td>0.904</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b3</td>\n<td>81.636 (18.364)</td>\n<td>95.718 (4.282)</td>\n<td>12.23</td>\n<td>bicubic</td>\n<td>300</td>\n<td>0.904</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b3 *tfp</td>\n<td>81.576 (18.424)</td>\n<td>95.662 (4.338)</td>\n<td>12.23</td>\n<td>bicubic</td>\n<td>300</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite4</td>\n<td>81.528 (18.472)</td>\n<td>95.668 (4.332)</td>\n<td>13.00</td>\n<td>bilinear</td>\n<td>380</td>\n<td>0.92</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b1_ns *tfp</td>\n<td>81.514 (18.486)</td>\n<td>95.776 (4.224)</td>\n<td>7.79</td>\n<td>bicubic</td>\n<td>240</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite4 *tfp</td>\n<td>81.502 (18.498)</td>\n<td>95.676 (4.324)</td>\n<td>13.00</td>\n<td>bilinear</td>\n<td>380</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b1_ns</td>\n<td>81.388 (18.612)</td>\n<td>95.738 (4.262)</td>\n<td>7.79</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.88</td>\n</tr>\n<tr>\n<td>tf_efficientnet_el</td>\n<td>80.534 (19.466)</td>\n<td>95.190 (4.810)</td>\n<td>10.59</td>\n<td>bicubic</td>\n<td>300</td>\n<td>0.904</td>\n</tr>\n<tr>\n<td>tf_efficientnet_el *tfp</td>\n<td>80.476 (19.524)</td>\n<td>95.200 (4.800)</td>\n<td>10.59</td>\n<td>bicubic</td>\n<td>300</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b2_ap *tfp</td>\n<td>80.420 (19.580)</td>\n<td>95.040 (4.960)</td>\n<td>9.11</td>\n<td>bicubic</td>\n<td>260</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b2_ap</td>\n<td>80.306 (19.694)</td>\n<td>95.028 (4.972)</td>\n<td>9.11</td>\n<td>bicubic</td>\n<td>260</td>\n<td>0.890</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b2 *tfp</td>\n<td>80.188 (19.812)</td>\n<td>94.974 (5.026)</td>\n<td>9.11</td>\n<td>bicubic</td>\n<td>260</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b2</td>\n<td>80.086 (19.914)</td>\n<td>94.908 (5.092)</td>\n<td>9.11</td>\n<td>bicubic</td>\n<td>260</td>\n<td>0.890</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite3</td>\n<td>79.812 (20.188)</td>\n<td>94.914 (5.086)</td>\n<td>8.20</td>\n<td>bilinear</td>\n<td>300</td>\n<td>0.904</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite3 *tfp</td>\n<td>79.734 (20.266)</td>\n<td>94.838 (5.162)</td>\n<td>8.20</td>\n<td>bilinear</td>\n<td>300</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b1_ap *tfp</td>\n<td>79.532 (20.468)</td>\n<td>94.378 (5.622)</td>\n<td>7.79</td>\n<td>bicubic</td>\n<td>240</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_cc_b1_8e *tfp</td>\n<td>79.464 (20.536)</td>\n<td>94.492 (5.508)</td>\n<td>39.7</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.88</td>\n</tr>\n<tr>\n<td>tf_efficientnet_cc_b1_8e</td>\n<td>79.298 (20.702)</td>\n<td>94.364 (5.636)</td>\n<td>39.7</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.88</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b1_ap</td>\n<td>79.278 (20.722)</td>\n<td>94.308 (5.692)</td>\n<td>7.79</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.88</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b1 *tfp</td>\n<td>79.172 (20.828)</td>\n<td>94.450 (5.550)</td>\n<td>7.79</td>\n<td>bicubic</td>\n<td>240</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_em *tfp</td>\n<td>78.958 (21.042)</td>\n<td>94.458 (5.542)</td>\n<td>6.90</td>\n<td>bicubic</td>\n<td>240</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b0_ns *tfp</td>\n<td>78.806 (21.194)</td>\n<td>94.496 (5.504)</td>\n<td>5.29</td>\n<td>bicubic</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mixnet_l *tfp</td>\n<td>78.846 (21.154)</td>\n<td>94.212 (5.788)</td>\n<td>7.33</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b1</td>\n<td>78.826 (21.174)</td>\n<td>94.198 (5.802)</td>\n<td>7.79</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.88</td>\n</tr>\n<tr>\n<td>tf_mixnet_l</td>\n<td>78.770 (21.230)</td>\n<td>94.004 (5.996)</td>\n<td>7.33</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_em</td>\n<td>78.742 (21.258)</td>\n<td>94.332 (5.668)</td>\n<td>6.90</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b0_ns</td>\n<td>78.658 (21.342)</td>\n<td>94.376 (5.624)</td>\n<td>5.29</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_cc_b0_8e *tfp</td>\n<td>78.314 (21.686)</td>\n<td>93.790 (6.210)</td>\n<td>24.0</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_cc_b0_8e</td>\n<td>77.908 (22.092)</td>\n<td>93.656 (6.344)</td>\n<td>24.0</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_cc_b0_4e *tfp</td>\n<td>77.746 (22.254)</td>\n<td>93.552 (6.448)</td>\n<td>13.3</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_cc_b0_4e</td>\n<td>77.304 (22.696)</td>\n<td>93.332 (6.668)</td>\n<td>13.3</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_es *tfp</td>\n<td>77.616 (22.384)</td>\n<td>93.750 (6.250)</td>\n<td>5.44</td>\n<td>bicubic</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite2 *tfp</td>\n<td>77.544 (22.456)</td>\n<td>93.800 (6.200)</td>\n<td>6.09</td>\n<td>bilinear</td>\n<td>260</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite2</td>\n<td>77.460 (22.540)</td>\n<td>93.746 (6.254)</td>\n<td>6.09</td>\n<td>bicubic</td>\n<td>260</td>\n<td>0.89</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b0_ap *tfp</td>\n<td>77.514 (22.486)</td>\n<td>93.576 (6.424)</td>\n<td>5.29</td>\n<td>bicubic</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_es</td>\n<td>77.264 (22.736)</td>\n<td>93.600 (6.400)</td>\n<td>5.44</td>\n<td>bicubic</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b0 *tfp</td>\n<td>77.258 (22.742)</td>\n<td>93.478 (6.522)</td>\n<td>5.29</td>\n<td>bicubic</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b0_ap</td>\n<td>77.084 (22.916)</td>\n<td>93.254 (6.746)</td>\n<td>5.29</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mixnet_m *tfp</td>\n<td>77.072 (22.928)</td>\n<td>93.368 (6.632)</td>\n<td>5.01</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mixnet_m</td>\n<td>76.950 (23.050)</td>\n<td>93.156 (6.844)</td>\n<td>5.01</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_b0</td>\n<td>76.848 (23.152)</td>\n<td>93.228 (6.772)</td>\n<td>5.29</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite1 *tfp</td>\n<td>76.764 (23.236)</td>\n<td>93.326 (6.674)</td>\n<td>5.42</td>\n<td>bilinear</td>\n<td>240</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite1</td>\n<td>76.638 (23.362)</td>\n<td>93.232 (6.768)</td>\n<td>5.42</td>\n<td>bicubic</td>\n<td>240</td>\n<td>0.882</td>\n</tr>\n<tr>\n<td>tf_mixnet_s *tfp</td>\n<td>75.800 (24.200)</td>\n<td>92.788 (7.212)</td>\n<td>4.13</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_large_100 *tfp</td>\n<td>75.768 (24.232)</td>\n<td>92.710 (7.290)</td>\n<td>5.48</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mixnet_s</td>\n<td>75.648 (24.352)</td>\n<td>92.636 (7.364)</td>\n<td>4.13</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_large_100</td>\n<td>75.516 (24.484)</td>\n<td>92.600 (7.400)</td>\n<td>5.48</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite0 *tfp</td>\n<td>75.074 (24.926)</td>\n<td>92.314 (7.686)</td>\n<td>4.65</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_efficientnet_lite0</td>\n<td>74.842 (25.158)</td>\n<td>92.170 (7.830)</td>\n<td>4.65</td>\n<td>bicubic</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_large_075 *tfp</td>\n<td>73.730 (26.270)</td>\n<td>91.616 (8.384)</td>\n<td>3.99</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_large_075</td>\n<td>73.442 (26.558)</td>\n<td>91.352 (8.648)</td>\n<td>3.99</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_large_minimal_100 *tfp</td>\n<td>72.678 (27.322)</td>\n<td>90.860 (9.140)</td>\n<td>3.92</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_large_minimal_100</td>\n<td>72.244 (27.756)</td>\n<td>90.636 (9.364)</td>\n<td>3.92</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_small_100 *tfp</td>\n<td>67.918 (32.082)</td>\n<td>87.958 (12.042</td>\n<td>2.54</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_small_100</td>\n<td>67.918 (32.082)</td>\n<td>87.662 (12.338)</td>\n<td>2.54</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_small_075 *tfp</td>\n<td>66.142 (33.858)</td>\n<td>86.498 (13.502)</td>\n<td>2.04</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_small_075</td>\n<td>65.718 (34.282)</td>\n<td>86.136 (13.864)</td>\n<td>2.04</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_small_minimal_100 *tfp</td>\n<td>63.378 (36.622)</td>\n<td>84.802 (15.198)</td>\n<td>2.04</td>\n<td>bilinear</td>\n<td>224</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>tf_mobilenetv3_small_minimal_100</td>\n<td>62.898 (37.102)</td>\n<td>84.230 (15.770)</td>\n<td>2.04</td>\n<td>bilinear</td>\n<td>224</td>\n<td>0.875</td>\n</tr></tbody></table>\n<p>*tfp models validated with <code>tf-preprocessing</code> pipeline</p>\n<p>Google tf and tflite weights ported from official Tensorflow repositories</p>\n<ul>\n<li><a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet\" rel=\"nofollow\">https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet</a></li>\n<li><a href=\"https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet\" rel=\"nofollow\">https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet</a></li>\n<li><a href=\"https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\" rel=\"nofollow\">https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet</a></li>\n</ul>\n<h2>Usage</h2>\n<h3>Environment</h3>\n<p>All development and testing has been done in Conda Python 3 environments on Linux x86-64 systems, specifically Python 3.6.x and 3.7.x.</p>\n<p>Users have reported that a Python 3 Anaconda install in Windows works. I have not verified this myself.</p>\n<p>PyTorch versions 1.2. 1.3.1, 1.4 have been tested with this code.</p>\n<p>I've tried to keep the dependencies minimal, the setup is as per the PyTorch default install instructions for Conda:</p>\n<pre><code>conda create -n torch-env\nconda activate torch-env\nconda install -c pytorch pytorch torchvision cudatoolkit=10\n</code></pre>\n<h3>PyTorch Hub</h3>\n<p>Models can be accessed via the PyTorch Hub API</p>\n<pre><code>&gt;&gt;&gt; torch.hub.list('rwightman/gen-efficientnet-pytorch')\n['efficientnet_b0', ...]\n&gt;&gt;&gt; model = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n&gt;&gt;&gt; model.eval()\n&gt;&gt;&gt; output = model(torch.randn(1,3,224,224))\n</code></pre>\n<h3>Pip</h3>\n<p>This package can be installed via pip.</p>\n<p>Install (after conda env/install):</p>\n<pre><code>pip install geffnet\n</code></pre>\n<p>Eval use:</p>\n<pre><code>&gt;&gt;&gt; import geffnet\n&gt;&gt;&gt; m = geffnet.create_model('mobilenetv3_rw', pretrained=True)\n&gt;&gt;&gt; m.eval()\n</code></pre>\n<p>Train use:</p>\n<pre><code>&gt;&gt;&gt; import geffnet\n&gt;&gt;&gt; # models can also be created by using the entrypoint directly\n&gt;&gt;&gt; m = geffnet.efficientnet_b2(pretrained=True, drop_rate=0.25, drop_connect_rate=0.2)\n&gt;&gt;&gt; m.train()\n</code></pre>\n<p>Create in a nn.Sequential container, for fast.ai, etc:</p>\n<pre><code>&gt;&gt;&gt; import geffnet\n&gt;&gt;&gt; m = geffnet.mixnet_l(pretrained=True, drop_rate=0.25, drop_connect_rate=0.2, as_sequential=True)\n</code></pre>\n<h3>Exporting</h3>\n<p>Scripts to export models to ONNX and then to Caffe2 are included, along with a Caffe2 script to verify.</p>\n<p>As an example, to export the MobileNet-V3 pretrained model and then run an Imagenet validation:</p>\n<pre><code>python onnx_export.py --model tf_mobilenetv3_large_100 ./mobilenetv3_100.onnx\npython onnx_optimize.py ./mobilenetv3_100.onnx --output ./mobilenetv3_100-opt.onnx\npython onnx_to_caffe.py ./mobilenetv3_100-opt.onnx --c2-prefix mobilenetv3\npython caffe2_validate.py /imagenet/validation/ --c2-init ./mobilenetv3.init.pb --c2-predict ./mobilenetv3.predict.pb --interpolation bicubic\n</code></pre>\n<p><strong>NOTE</strong> the TF ported weights with the 'SAME' conv padding activated cannot be exported to ONNX unless <code>_EXPORTABLE</code> flag in <code>config.py</code> is set to True. Use <code>config.set_exportable(True)</code> as in the updated <code>onnx_export.py</code> example script.</p>\n\n          </div>"}, "last_serial": 6867282, "releases": {"0.9.0": [{"comment_text": "", "digests": {"md5": "13684c7449b35871564a559211e769eb", "sha256": "c0284e281b64649b3f5ab6be5db3788088694727f42d702f592f7cea3306e0a8"}, "downloads": -1, "filename": "geffnet-0.9.0-py3-none-any.whl", "has_sig": false, "md5_digest": "13684c7449b35871564a559211e769eb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 28364, "upload_time": "2019-10-28T01:35:15", "upload_time_iso_8601": "2019-10-28T01:35:15.931112Z", "url": "https://files.pythonhosted.org/packages/d3/a0/5b5461dbf41721a63efee2f5903ffbfef4459718aa4e5f0599dcee0b8ef1/geffnet-0.9.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "80aedd2bd7fbdf953a9173970e6b8542", "sha256": "b1387f109bbda91814462ef52bb1606a6aa3f598b418bcf49fd9530f09db2199"}, "downloads": -1, "filename": "geffnet-0.9.0.tar.gz", "has_sig": false, "md5_digest": "80aedd2bd7fbdf953a9173970e6b8542", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24630, "upload_time": "2019-10-28T01:35:18", "upload_time_iso_8601": "2019-10-28T01:35:18.113552Z", "url": "https://files.pythonhosted.org/packages/50/18/7e3cd97f842da5590b0ec7e6638fdc1135c2f3d3c570a618bd28edc31327/geffnet-0.9.0.tar.gz", "yanked": false}], "0.9.1": [{"comment_text": "", "digests": {"md5": "fb74ef1dc9902c3047b0e1cfe8f80679", "sha256": "ca3545809d63decc4579fde69e8c3f6bc930bcd5cc945859835c929b611a98a0"}, "downloads": -1, "filename": "geffnet-0.9.1-py3-none-any.whl", "has_sig": false, "md5_digest": "fb74ef1dc9902c3047b0e1cfe8f80679", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 28544, "upload_time": "2019-10-28T04:11:57", "upload_time_iso_8601": "2019-10-28T04:11:57.369738Z", "url": "https://files.pythonhosted.org/packages/d4/13/191bd490ba34f65abd21e232c208abb5265d1aa9162350834cd4739aaf81/geffnet-0.9.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c7d901c390f43e9489e9b03c1eb1b360", "sha256": "87ea400f9a449336bd8d70b3b04dd2a863bf8d2ea8084e710e3bd2897c589b31"}, "downloads": -1, "filename": "geffnet-0.9.1.tar.gz", "has_sig": false, "md5_digest": "c7d901c390f43e9489e9b03c1eb1b360", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 24972, "upload_time": "2019-10-28T04:11:58", "upload_time_iso_8601": "2019-10-28T04:11:58.707581Z", "url": "https://files.pythonhosted.org/packages/bc/d6/6004bff707bd553bca9ade8bc29a28be2c00fee72d2b5c23689a716e7f13/geffnet-0.9.1.tar.gz", "yanked": false}], "0.9.2": [{"comment_text": "", "digests": {"md5": "598db3877860c49a9651cb2edc6ff610", "sha256": "f669d6b8eaf985ee3a17b54a80ed6d7c9f54d14c23439e1ccea65ab4dc610537"}, "downloads": -1, "filename": "geffnet-0.9.2-py3-none-any.whl", "has_sig": false, "md5_digest": "598db3877860c49a9651cb2edc6ff610", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 31784, "upload_time": "2019-10-30T20:39:35", "upload_time_iso_8601": "2019-10-30T20:39:35.507064Z", "url": "https://files.pythonhosted.org/packages/5d/cd/b5c1e9aea6fc8a5585a286a33266d5a34d7091f339b87ebc9dddc0342fb5/geffnet-0.9.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "36043716d4184fb040bafaabbc12fc1c", "sha256": "70aca8d91704e7320c1818200751f175ed50a0bb94be790019d4f6204c80cc3e"}, "downloads": -1, "filename": "geffnet-0.9.2.tar.gz", "has_sig": false, "md5_digest": "36043716d4184fb040bafaabbc12fc1c", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 27160, "upload_time": "2019-10-30T20:39:36", "upload_time_iso_8601": "2019-10-30T20:39:36.881565Z", "url": "https://files.pythonhosted.org/packages/26/81/e143b6a0da32695209d415d2431e14770901c947c8118a7aaceb02b2de73/geffnet-0.9.2.tar.gz", "yanked": false}], "0.9.3": [{"comment_text": "", "digests": {"md5": "27bf7e127364379ae2e98fdc028ae3d2", "sha256": "dec63568a349c01171c5bd06b61e08dbe1a50d204a58d4d8beba2b7f8c9add17"}, "downloads": -1, "filename": "geffnet-0.9.3-py3-none-any.whl", "has_sig": false, "md5_digest": "27bf7e127364379ae2e98fdc028ae3d2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 31220, "upload_time": "2019-10-31T07:15:06", "upload_time_iso_8601": "2019-10-31T07:15:06.990873Z", "url": "https://files.pythonhosted.org/packages/5c/9f/793352436b784f979412174b867480122ab76449158dfdd6248ca564c97e/geffnet-0.9.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "015502466e43267101902ee5c9fda31d", "sha256": "f3e9e0bd911e7e318f856cac27c0fc97c0f1d540cdac77af600f35b3e6191624"}, "downloads": -1, "filename": "geffnet-0.9.3.tar.gz", "has_sig": false, "md5_digest": "015502466e43267101902ee5c9fda31d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 26833, "upload_time": "2019-10-31T07:15:08", "upload_time_iso_8601": "2019-10-31T07:15:08.777608Z", "url": "https://files.pythonhosted.org/packages/b7/cc/4e419988ef24de82202d529e63faaaf226e2cb2fef082a42c82c2d58fe8b/geffnet-0.9.3.tar.gz", "yanked": false}], "0.9.5": [{"comment_text": "", "digests": {"md5": "25b8a1ef26390c1208c84cc12da6ccd2", "sha256": "52bd55654b9bc660ce2926987b50e11736e928ae3507a4505885483a3a0fe8aa"}, "downloads": -1, "filename": "geffnet-0.9.5-py3-none-any.whl", "has_sig": false, "md5_digest": "25b8a1ef26390c1208c84cc12da6ccd2", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 34402, "upload_time": "2019-11-23T20:45:09", "upload_time_iso_8601": "2019-11-23T20:45:09.594458Z", "url": "https://files.pythonhosted.org/packages/94/6d/1e8071e9f73f30ff64428ec46db5abfe9c4d6a0c48db3b3e5aa6e20efbf8/geffnet-0.9.5-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec4fb4e6134b816d2c7f012678edbd32", "sha256": "8598da3a5cfc31f932c6d80d5f5d52df8073aa8da7bed2467cca836cbca46007"}, "downloads": -1, "filename": "geffnet-0.9.5.tar.gz", "has_sig": false, "md5_digest": "ec4fb4e6134b816d2c7f012678edbd32", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 31198, "upload_time": "2019-11-23T20:45:11", "upload_time_iso_8601": "2019-11-23T20:45:11.331687Z", "url": "https://files.pythonhosted.org/packages/1a/63/359318552e9952cb5b4abf2c8b74ee00e0afd994f858a8edba61efa48569/geffnet-0.9.5.tar.gz", "yanked": false}], "0.9.6": [{"comment_text": "", "digests": {"md5": "3af541b3857e9fa80b35cd169c9e7527", "sha256": "7cdce3ebc79938bec00ea613221074d798b0027a2d293d25285e5eaac65a1340"}, "downloads": -1, "filename": "geffnet-0.9.6-py3-none-any.whl", "has_sig": false, "md5_digest": "3af541b3857e9fa80b35cd169c9e7527", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 34928, "upload_time": "2020-01-23T00:41:17", "upload_time_iso_8601": "2020-01-23T00:41:17.748227Z", "url": "https://files.pythonhosted.org/packages/54/5f/a5f3c53208a499ad182c78ea273edb06b3520e4b160a475f327749cc2ac5/geffnet-0.9.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a718cbd79c0985210d3619702339db74", "sha256": "f28cf9b8eee3223ba4c9f94161c8f6ec70b809ec6ac44f754aca1b01b099246b"}, "downloads": -1, "filename": "geffnet-0.9.6.tar.gz", "has_sig": false, "md5_digest": "a718cbd79c0985210d3619702339db74", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 32315, "upload_time": "2020-01-23T00:41:19", "upload_time_iso_8601": "2020-01-23T00:41:19.184833Z", "url": "https://files.pythonhosted.org/packages/60/7c/585f244fd3872d88e4ff9183270954ce23cb2a4d0ba69e143f7ee2fa1248/geffnet-0.9.6.tar.gz", "yanked": false}], "0.9.7": [{"comment_text": "", "digests": {"md5": "eea5791cd8430f01c2467735fdf0357a", "sha256": "f0b3c268cd55cd3f5ed68cfaa0bef9ce7c55a028cca0a78d3dbe2d65820c18d9"}, "downloads": -1, "filename": "geffnet-0.9.7-py3-none-any.whl", "has_sig": false, "md5_digest": "eea5791cd8430f01c2467735fdf0357a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 36076, "upload_time": "2020-02-17T17:56:17", "upload_time_iso_8601": "2020-02-17T17:56:17.913470Z", "url": "https://files.pythonhosted.org/packages/fa/4d/51b9d986fbb726da2746743e2daabad76b236a5ab4708a542b8b5ae9c657/geffnet-0.9.7-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ec4f35e0d7260c9c07422dbb8b4c91fb", "sha256": "5ae195ba3eed139269f9509e694001517634bd7097ca8e7a1c7e995d099e7078"}, "downloads": -1, "filename": "geffnet-0.9.7.tar.gz", "has_sig": false, "md5_digest": "ec4f35e0d7260c9c07422dbb8b4c91fb", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 34425, "upload_time": "2020-02-17T17:56:19", "upload_time_iso_8601": "2020-02-17T17:56:19.717663Z", "url": "https://files.pythonhosted.org/packages/69/d2/5eaa352f949e44c8f8ae24bfe352d364b3c94c1b96ddeeca9ef402009de9/geffnet-0.9.7.tar.gz", "yanked": false}], "0.9.8": [{"comment_text": "", "digests": {"md5": "915047e6089d2ed61814cdda5b353a6f", "sha256": "4b139e1159185271d4e118f2e85e9942c24b0082d25a0830cfc1eabbc4e091d6"}, "downloads": -1, "filename": "geffnet-0.9.8-py3-none-any.whl", "has_sig": false, "md5_digest": "915047e6089d2ed61814cdda5b353a6f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 37008, "upload_time": "2020-03-23T17:51:17", "upload_time_iso_8601": "2020-03-23T17:51:17.712018Z", "url": "https://files.pythonhosted.org/packages/04/a1/806cd0cbc1312f034e39cb4b3969430d8fe4f6cd0cb003dd223ba20e0d4d/geffnet-0.9.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9e940f0d8f8084cb89bca135d85efb88", "sha256": "a07985b0cd902025ff3f29e170aa90c139e331dc520bf566a522fae42de2cf53"}, "downloads": -1, "filename": "geffnet-0.9.8.tar.gz", "has_sig": false, "md5_digest": "9e940f0d8f8084cb89bca135d85efb88", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 35975, "upload_time": "2020-03-23T17:51:19", "upload_time_iso_8601": "2020-03-23T17:51:19.502258Z", "url": "https://files.pythonhosted.org/packages/6c/ba/40984000371774217477e451dae795f2e0c35467ca496c72aa9a76dbe781/geffnet-0.9.8.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "915047e6089d2ed61814cdda5b353a6f", "sha256": "4b139e1159185271d4e118f2e85e9942c24b0082d25a0830cfc1eabbc4e091d6"}, "downloads": -1, "filename": "geffnet-0.9.8-py3-none-any.whl", "has_sig": false, "md5_digest": "915047e6089d2ed61814cdda5b353a6f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6", "size": 37008, "upload_time": "2020-03-23T17:51:17", "upload_time_iso_8601": "2020-03-23T17:51:17.712018Z", "url": "https://files.pythonhosted.org/packages/04/a1/806cd0cbc1312f034e39cb4b3969430d8fe4f6cd0cb003dd223ba20e0d4d/geffnet-0.9.8-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9e940f0d8f8084cb89bca135d85efb88", "sha256": "a07985b0cd902025ff3f29e170aa90c139e331dc520bf566a522fae42de2cf53"}, "downloads": -1, "filename": "geffnet-0.9.8.tar.gz", "has_sig": false, "md5_digest": "9e940f0d8f8084cb89bca135d85efb88", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 35975, "upload_time": "2020-03-23T17:51:19", "upload_time_iso_8601": "2020-03-23T17:51:19.502258Z", "url": "https://files.pythonhosted.org/packages/6c/ba/40984000371774217477e451dae795f2e0c35467ca496c72aa9a76dbe781/geffnet-0.9.8.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:58:32 2020"}