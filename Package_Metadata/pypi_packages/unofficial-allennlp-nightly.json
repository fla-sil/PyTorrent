{"info": {"author": "Allen Institute for Artificial Intelligence", "author_email": "allennlp@allenai.org", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Science/Research", "License :: OSI Approved :: Apache Software License", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "<p align=\"center\"><img width=\"40%\" src=\"docs/img/allennlp-logo-dark.png\" /></p>\n\n[![Build Status](http://build.allennlp.org/app/rest/builds/buildType:(id:AllenNLP_AllenNLPCommits)/statusIcon)](http://build.allennlp.org/viewType.html?buildTypeId=AllenNLP_AllenNLPCommits&guest=1)\n[![codecov](https://codecov.io/gh/allenai/allennlp/branch/master/graph/badge.svg)](https://codecov.io/gh/allenai/allennlp)\n\nAn [Apache 2.0](https://github.com/allenai/allennlp/blob/master/LICENSE) NLP research library, built on PyTorch,\nfor developing state-of-the-art deep learning models on a wide variety of linguistic tasks.\n\n## Quick Links\n\n* [Website](https://allennlp.org/)\n* [Tutorial](https://allennlp.org/tutorials)\n* [Forum](https://discourse.allennlp.org)\n* [Documentation](https://allenai.github.io/allennlp-docs/)\n* [Contributing Guidelines](CONTRIBUTING.md)\n* [Pretrained Models](https://github.com/allenai/allennlp-hub/blob/master/allennlp_hub/pretrained/allennlp_pretrained.py)\n* [Continuous Build](http://build.allennlp.org/)\n\n## Package Overview\n\n<table>\n<tr>\n    <td><b> allennlp </b></td>\n    <td> an open-source NLP research library, built on PyTorch </td>\n</tr>\n<tr>\n    <td><b> allennlp.commands </b></td>\n    <td> functionality for a CLI and web service </td>\n</tr>\n<tr>\n    <td><b> allennlp.data </b></td>\n    <td> a data processing module for loading datasets and encoding strings as integers for representation in matrices </td>\n</tr>\n<tr>\n    <td><b> allennlp.models </b></td>\n    <td> a collection of state-of-the-art models </td>\n</tr>\n<tr>\n    <td><b> allennlp.modules </b></td>\n    <td> a collection of PyTorch modules for use with text </td>\n</tr>\n<tr>\n    <td><b> allennlp.nn </b></td>\n    <td> tensor utility functions, such as initializers and activation functions </td>\n</tr>\n<tr>\n    <td><b> allennlp.training </b></td>\n    <td> functionality for training models </td>\n</tr>\n</table>\n\n## Installation\n\nAllenNLP requires Python 3.6.1 or later. The preferred way to install AllenNLP is via `pip`.  Just run `pip install allennlp` in your Python environment and you're good to go!\n\nIf you need pointers on setting up an appropriate Python environment or would like to install AllenNLP using a different method, see below.\n\nWindows is currently not officially supported, although we try to fix issues when they are easily addressed.\n\n### Installing via pip\n\n#### Setting up a virtual environment\n\n[Conda](https://conda.io/) can be used set up a virtual environment with the\nversion of Python required for AllenNLP.  If you already have a Python 3.6 or 3.7\nenvironment you want to use, you can skip to the 'installing via pip' section.\n\n1.  [Download and install Conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html).\n\n2.  Create a Conda environment with Python 3.7\n\n    ```bash\n    conda create -n allennlp python=3.7\n    ```\n\n3.  Activate the Conda environment. You will need to activate the Conda environment in each terminal in which you want to use AllenNLP.\n\n    ```bash\n    conda activate allennlp\n    ```\n\n#### Installing the library and dependencies\n\nInstalling the library and dependencies is simple using `pip`.\n\n   ```bash\n   pip install allennlp\n   ```\n\nThat's it! You're now ready to build and train AllenNLP models.\nAllenNLP installs a script when you install the python package, meaning you can run allennlp commands just by typing `allennlp` into a terminal.\n\nYou can now test your installation with `allennlp test-install`.\n\n### Installing using Docker\n\nDocker provides a virtual machine with everything set up to run AllenNLP--\nwhether you will leverage a GPU or just run on a CPU.  Docker provides more\nisolation and consistency, and also makes it easy to distribute your\nenvironment to a compute cluster.\n\nOnce you have [installed Docker](https://docs.docker.com/engine/installation/)\njust run the following command to get an environment that will run on either the cpu or gpu.\n\n   ```bash\n   mkdir -p $HOME/.allennlp/\n   docker run --rm -v $HOME/.allennlp:/root/.allennlp allennlp/allennlp:v0.9.0\n   ```\n\nYou can test the Docker environment with `docker run --rm -v $HOME/.allennlp:/root/.allennlp allennlp/allennlp:v0.9.0 test-install`.\n\n### Installing from source\n\nYou can also install AllenNLP by cloning our git repository:\n\n  ```bash\n  git clone https://github.com/allenai/allennlp.git\n  ```\n\nCreate a Python 3.7 virtual environment, and install AllenNLP in `editable` mode by running:\n\n  ```bash\n  pip install --editable .\n  pip install -r dev-requirements.txt\n  ```\n\nThis will make `allennlp` available on your system but it will use the sources from the local clone\nyou made of the source repository.\n\nYou can test your installation with `allennlp test-install`.\n`./scripts/verify.py` will run the full suite of tests used by our continuous build environment.\n\n## Running AllenNLP\n\nOnce you've installed AllenNLP, you can run the command-line interface either\nwith the `allennlp` command (if you installed via `pip`) or `allennlp` (if you installed via source).\n\n```\n$ allennlp\nRun AllenNLP\n\noptional arguments:\n  -h, --help     show this help message and exit\n  --version      show program's version number and exit\n\nCommands:\n\n    train        Train a model.\n    evaluate     Evaluate the specified model + dataset.\n    predict      Use a trained model to make predictions.\n    elmo         Create word vectors using a pretrained ELMo model.\n    fine-tune    Continue training a model on a new dataset.\n    dry-run      Create a vocabulary, compute dataset statistics and other\n                 training utilities.\n    make-vocab   Create a vocabulary, compute dataset statistics and other\n                 training utilities.\n    test-install\n                 Run the unit tests.\n    find-lr      Find a learning rate range.\n    print-results\n                 Print results from allennlp serialization directories to the\n                 console.\n```\n\n## Docker images\n\nAllenNLP releases Docker images to [Docker Hub](https://hub.docker.com/r/allennlp/) for each release.  For information on how to run these releases, see [Installing using Docker](#installing-using-docker).\n\n### Building a Docker image\n\nFor various reasons you may need to create your own AllenNLP Docker image.\nThe same image can be used either with a CPU or a GPU.\n\nFirst, you need to [install Docker](https://www.docker.com/get-started).\nThen run the following command (it will take some time, as it completely builds the environment needed to run AllenNLP.)\n\n```bash\ndocker build -f Dockerfile.pip --tag allennlp/allennlp:latest .\n```\n\nYou should now be able to see this image listed by running `docker images allennlp`.\n\n```\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nallennlp/allennlp            latest              b66aee6cb593        5 minutes ago       2.38GB\n```\n\n### Running the Docker image\n\nYou can run the image with `docker run --rm -it allennlp/allennlp:latest`.  The `--rm` flag cleans up the image on exit and the `-it` flags make the session interactive so you can use the bash shell the Docker image starts.\n\nYou can test your installation by running  `allennlp test-install`.\n\n## Issues\n\nEveryone is welcome to file issues with either feature requests, bug reports, or general questions.  As a small team with our own internal goals, we may ask for contributions if a prompt fix doesn't fit into our roadmap.  We allow users a two week window to follow up on questions, after which we will close issues.  They can be re-opened if there is further discussion.\n\n## Contributions\n\nThe AllenNLP team at AI2 (@allenai) welcomes contributions from the greater AllenNLP community, and, if you would like to get a change into the library, this is likely the fastest approach.  If you would like to contribute a larger feature, we recommend first creating an issue with a proposed design for discussion.  This will prevent you from spending significant time on an implementation which has a technical limitation someone could have pointed out early on.  Small contributions can be made directly in a pull request.\n\nPull requests (PRs) must have one approving review and no requested changes before they are merged.  As AllenNLP is primarily driven by AI2 (@allenai) we reserve the right to reject or revert contributions that we don't think are good additions.\n\n## Citing\n\nIf you use AllenNLP in your research, please cite [AllenNLP: A Deep Semantic Natural Language Processing Platform](https://www.semanticscholar.org/paper/AllenNLP%3A-A-Deep-Semantic-Natural-Language-Platform-Gardner-Grus/a5502187140cdd98d76ae711973dbcdaf1fef46d).\n\n```bibtex\n@inproceedings{Gardner2017AllenNLP,\n  title={AllenNLP: A Deep Semantic Natural Language Processing Platform},\n  author={Matt Gardner and Joel Grus and Mark Neumann and Oyvind Tafjord\n    and Pradeep Dasigi and Nelson F. Liu and Matthew Peters and\n    Michael Schmitz and Luke S. Zettlemoyer},\n  year={2017},\n  Eprint = {arXiv:1803.07640},\n}\n```\n\n## Team\n\nAllenNLP is an open-source project backed by [the Allen Institute for Artificial Intelligence (AI2)](https://allenai.org/).\nAI2 is a non-profit institute with the mission to contribute to humanity through high-impact AI research and engineering.\nTo learn more about who specifically contributed to this codebase, see [our contributors](https://github.com/allenai/allennlp/graphs/contributors) page.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/allenai/allennlp", "keywords": "allennlp NLP deep learning machine reading", "license": "Apache", "maintainer": "", "maintainer_email": "", "name": "unofficial-allennlp-nightly", "package_url": "https://pypi.org/project/unofficial-allennlp-nightly/", "platform": "", "project_url": "https://pypi.org/project/unofficial-allennlp-nightly/", "project_urls": {"Homepage": "https://github.com/allenai/allennlp"}, "release_url": "https://pypi.org/project/unofficial-allennlp-nightly/0.9.2/", "requires_dist": ["torch (!=1.3.0,>=1.2.0)", "overrides (==2.8.0)", "nltk", "spacy (<2.3,>=2.1.0)", "numpy", "tensorboardX (>=1.2)", "boto3", "requests (>=2.18)", "tqdm (>=4.19)", "h5py", "scikit-learn", "scipy", "pytest", "flaky", "responses (>=0.7)", "conllu (==2.2.2)", "transformers (>=2.4.0)", "jsonpickle", "jsonnet (>=0.10.0) ; sys_platform != \"win32\""], "requires_python": ">=3.6.1", "summary": "An open-source NLP research library, built on PyTorch.", "version": "0.9.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\"><img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3187b1df1aa3de073971d80e9f3621bb96afc8c2/646f63732f696d672f616c6c656e6e6c702d6c6f676f2d6461726b2e706e67\" width=\"40%\"></p>\n<p><a href=\"http://build.allennlp.org/viewType.html?buildTypeId=AllenNLP_AllenNLPCommits&amp;guest=1\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/cb770c1a5e595697694924d0fd8f3376a46bcb0f/687474703a2f2f6275696c642e616c6c656e6e6c702e6f72672f6170702f726573742f6275696c64732f6275696c64547970653a2869643a416c6c656e4e4c505f416c6c656e4e4c50436f6d6d697473292f73746174757349636f6e\"></a>\n<a href=\"https://codecov.io/gh/allenai/allennlp\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/470492c6b69f9f569f578350c83140148dff8667/68747470733a2f2f636f6465636f762e696f2f67682f616c6c656e61692f616c6c656e6e6c702f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a></p>\n<p>An <a href=\"https://github.com/allenai/allennlp/blob/master/LICENSE\" rel=\"nofollow\">Apache 2.0</a> NLP research library, built on PyTorch,\nfor developing state-of-the-art deep learning models on a wide variety of linguistic tasks.</p>\n<h2>Quick Links</h2>\n<ul>\n<li><a href=\"https://allennlp.org/\" rel=\"nofollow\">Website</a></li>\n<li><a href=\"https://allennlp.org/tutorials\" rel=\"nofollow\">Tutorial</a></li>\n<li><a href=\"https://discourse.allennlp.org\" rel=\"nofollow\">Forum</a></li>\n<li><a href=\"https://allenai.github.io/allennlp-docs/\" rel=\"nofollow\">Documentation</a></li>\n<li><a href=\"CONTRIBUTING.md\" rel=\"nofollow\">Contributing Guidelines</a></li>\n<li><a href=\"https://github.com/allenai/allennlp-hub/blob/master/allennlp_hub/pretrained/allennlp_pretrained.py\" rel=\"nofollow\">Pretrained Models</a></li>\n<li><a href=\"http://build.allennlp.org/\" rel=\"nofollow\">Continuous Build</a></li>\n</ul>\n<h2>Package Overview</h2>\n<table>\n<tr>\n    <td><b> allennlp </b></td>\n    <td> an open-source NLP research library, built on PyTorch </td>\n</tr>\n<tr>\n    <td><b> allennlp.commands </b></td>\n    <td> functionality for a CLI and web service </td>\n</tr>\n<tr>\n    <td><b> allennlp.data </b></td>\n    <td> a data processing module for loading datasets and encoding strings as integers for representation in matrices </td>\n</tr>\n<tr>\n    <td><b> allennlp.models </b></td>\n    <td> a collection of state-of-the-art models </td>\n</tr>\n<tr>\n    <td><b> allennlp.modules </b></td>\n    <td> a collection of PyTorch modules for use with text </td>\n</tr>\n<tr>\n    <td><b> allennlp.nn </b></td>\n    <td> tensor utility functions, such as initializers and activation functions </td>\n</tr>\n<tr>\n    <td><b> allennlp.training </b></td>\n    <td> functionality for training models </td>\n</tr>\n</table>\n<h2>Installation</h2>\n<p>AllenNLP requires Python 3.6.1 or later. The preferred way to install AllenNLP is via <code>pip</code>.  Just run <code>pip install allennlp</code> in your Python environment and you're good to go!</p>\n<p>If you need pointers on setting up an appropriate Python environment or would like to install AllenNLP using a different method, see below.</p>\n<p>Windows is currently not officially supported, although we try to fix issues when they are easily addressed.</p>\n<h3>Installing via pip</h3>\n<h4>Setting up a virtual environment</h4>\n<p><a href=\"https://conda.io/\" rel=\"nofollow\">Conda</a> can be used set up a virtual environment with the\nversion of Python required for AllenNLP.  If you already have a Python 3.6 or 3.7\nenvironment you want to use, you can skip to the 'installing via pip' section.</p>\n<ol>\n<li>\n<p><a href=\"https://conda.io/projects/conda/en/latest/user-guide/install/index.html\" rel=\"nofollow\">Download and install Conda</a>.</p>\n</li>\n<li>\n<p>Create a Conda environment with Python 3.7</p>\n<pre>conda create -n allennlp <span class=\"nv\">python</span><span class=\"o\">=</span><span class=\"m\">3</span>.7\n</pre>\n</li>\n<li>\n<p>Activate the Conda environment. You will need to activate the Conda environment in each terminal in which you want to use AllenNLP.</p>\n<pre>conda activate allennlp\n</pre>\n</li>\n</ol>\n<h4>Installing the library and dependencies</h4>\n<p>Installing the library and dependencies is simple using <code>pip</code>.</p>\n<pre>pip install allennlp\n</pre>\n<p>That's it! You're now ready to build and train AllenNLP models.\nAllenNLP installs a script when you install the python package, meaning you can run allennlp commands just by typing <code>allennlp</code> into a terminal.</p>\n<p>You can now test your installation with <code>allennlp test-install</code>.</p>\n<h3>Installing using Docker</h3>\n<p>Docker provides a virtual machine with everything set up to run AllenNLP--\nwhether you will leverage a GPU or just run on a CPU.  Docker provides more\nisolation and consistency, and also makes it easy to distribute your\nenvironment to a compute cluster.</p>\n<p>Once you have <a href=\"https://docs.docker.com/engine/installation/\" rel=\"nofollow\">installed Docker</a>\njust run the following command to get an environment that will run on either the cpu or gpu.</p>\n<pre>mkdir -p <span class=\"nv\">$HOME</span>/.allennlp/\ndocker run --rm -v <span class=\"nv\">$HOME</span>/.allennlp:/root/.allennlp allennlp/allennlp:v0.9.0\n</pre>\n<p>You can test the Docker environment with <code>docker run --rm -v $HOME/.allennlp:/root/.allennlp allennlp/allennlp:v0.9.0 test-install</code>.</p>\n<h3>Installing from source</h3>\n<p>You can also install AllenNLP by cloning our git repository:</p>\n<pre>git clone https://github.com/allenai/allennlp.git\n</pre>\n<p>Create a Python 3.7 virtual environment, and install AllenNLP in <code>editable</code> mode by running:</p>\n<pre>pip install --editable .\npip install -r dev-requirements.txt\n</pre>\n<p>This will make <code>allennlp</code> available on your system but it will use the sources from the local clone\nyou made of the source repository.</p>\n<p>You can test your installation with <code>allennlp test-install</code>.\n<code>./scripts/verify.py</code> will run the full suite of tests used by our continuous build environment.</p>\n<h2>Running AllenNLP</h2>\n<p>Once you've installed AllenNLP, you can run the command-line interface either\nwith the <code>allennlp</code> command (if you installed via <code>pip</code>) or <code>allennlp</code> (if you installed via source).</p>\n<pre><code>$ allennlp\nRun AllenNLP\n\noptional arguments:\n  -h, --help     show this help message and exit\n  --version      show program's version number and exit\n\nCommands:\n\n    train        Train a model.\n    evaluate     Evaluate the specified model + dataset.\n    predict      Use a trained model to make predictions.\n    elmo         Create word vectors using a pretrained ELMo model.\n    fine-tune    Continue training a model on a new dataset.\n    dry-run      Create a vocabulary, compute dataset statistics and other\n                 training utilities.\n    make-vocab   Create a vocabulary, compute dataset statistics and other\n                 training utilities.\n    test-install\n                 Run the unit tests.\n    find-lr      Find a learning rate range.\n    print-results\n                 Print results from allennlp serialization directories to the\n                 console.\n</code></pre>\n<h2>Docker images</h2>\n<p>AllenNLP releases Docker images to <a href=\"https://hub.docker.com/r/allennlp/\" rel=\"nofollow\">Docker Hub</a> for each release.  For information on how to run these releases, see <a href=\"#installing-using-docker\" rel=\"nofollow\">Installing using Docker</a>.</p>\n<h3>Building a Docker image</h3>\n<p>For various reasons you may need to create your own AllenNLP Docker image.\nThe same image can be used either with a CPU or a GPU.</p>\n<p>First, you need to <a href=\"https://www.docker.com/get-started\" rel=\"nofollow\">install Docker</a>.\nThen run the following command (it will take some time, as it completely builds the environment needed to run AllenNLP.)</p>\n<pre>docker build -f Dockerfile.pip --tag allennlp/allennlp:latest .\n</pre>\n<p>You should now be able to see this image listed by running <code>docker images allennlp</code>.</p>\n<pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nallennlp/allennlp            latest              b66aee6cb593        5 minutes ago       2.38GB\n</code></pre>\n<h3>Running the Docker image</h3>\n<p>You can run the image with <code>docker run --rm -it allennlp/allennlp:latest</code>.  The <code>--rm</code> flag cleans up the image on exit and the <code>-it</code> flags make the session interactive so you can use the bash shell the Docker image starts.</p>\n<p>You can test your installation by running  <code>allennlp test-install</code>.</p>\n<h2>Issues</h2>\n<p>Everyone is welcome to file issues with either feature requests, bug reports, or general questions.  As a small team with our own internal goals, we may ask for contributions if a prompt fix doesn't fit into our roadmap.  We allow users a two week window to follow up on questions, after which we will close issues.  They can be re-opened if there is further discussion.</p>\n<h2>Contributions</h2>\n<p>The AllenNLP team at AI2 (@allenai) welcomes contributions from the greater AllenNLP community, and, if you would like to get a change into the library, this is likely the fastest approach.  If you would like to contribute a larger feature, we recommend first creating an issue with a proposed design for discussion.  This will prevent you from spending significant time on an implementation which has a technical limitation someone could have pointed out early on.  Small contributions can be made directly in a pull request.</p>\n<p>Pull requests (PRs) must have one approving review and no requested changes before they are merged.  As AllenNLP is primarily driven by AI2 (@allenai) we reserve the right to reject or revert contributions that we don't think are good additions.</p>\n<h2>Citing</h2>\n<p>If you use AllenNLP in your research, please cite <a href=\"https://www.semanticscholar.org/paper/AllenNLP%3A-A-Deep-Semantic-Natural-Language-Platform-Gardner-Grus/a5502187140cdd98d76ae711973dbcdaf1fef46d\" rel=\"nofollow\">AllenNLP: A Deep Semantic Natural Language Processing Platform</a>.</p>\n<pre><span class=\"nc\">@inproceedings</span><span class=\"p\">{</span><span class=\"nl\">Gardner2017AllenNLP</span><span class=\"p\">,</span>\n  <span class=\"na\">title</span><span class=\"p\">=</span><span class=\"s\">{AllenNLP: A Deep Semantic Natural Language Processing Platform}</span><span class=\"p\">,</span>\n  <span class=\"na\">author</span><span class=\"p\">=</span><span class=\"s\">{Matt Gardner and Joel Grus and Mark Neumann and Oyvind Tafjord</span>\n<span class=\"s\">    and Pradeep Dasigi and Nelson F. Liu and Matthew Peters and</span>\n<span class=\"s\">    Michael Schmitz and Luke S. Zettlemoyer}</span><span class=\"p\">,</span>\n  <span class=\"na\">year</span><span class=\"p\">=</span><span class=\"s\">{2017}</span><span class=\"p\">,</span>\n  <span class=\"na\">Eprint</span> <span class=\"p\">=</span> <span class=\"s\">{arXiv:1803.07640}</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre>\n<h2>Team</h2>\n<p>AllenNLP is an open-source project backed by <a href=\"https://allenai.org/\" rel=\"nofollow\">the Allen Institute for Artificial Intelligence (AI2)</a>.\nAI2 is a non-profit institute with the mission to contribute to humanity through high-impact AI research and engineering.\nTo learn more about who specifically contributed to this codebase, see <a href=\"https://github.com/allenai/allennlp/graphs/contributors\" rel=\"nofollow\">our contributors</a> page.</p>\n\n          </div>"}, "last_serial": 6603688, "releases": {"0.9.1": [{"comment_text": "", "digests": {"md5": "46c2a84e75fca844e5b518363ee402a5", "sha256": "7e0d2aa6b2e3b57aa4d628b2581568367cea6d33818c5e0f71c8de29a6f6387d"}, "downloads": -1, "filename": "unofficial_allennlp_nightly-0.9.1-py3-none-any.whl", "has_sig": false, "md5_digest": "46c2a84e75fca844e5b518363ee402a5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.1", "size": 6694006, "upload_time": "2020-02-10T08:22:21", "upload_time_iso_8601": "2020-02-10T08:22:21.532005Z", "url": "https://files.pythonhosted.org/packages/32/a1/530d51a38045beb8c8cfe10873e1fc11b785783beaeb75b08692c19e8c01/unofficial_allennlp_nightly-0.9.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c64f12c4c8c42fd2ab704ad2f856f157", "sha256": "2d9045f4f5f58da54f51f6bac7e09baa7de0e413e87f95265587b552bdcb1a7a"}, "downloads": -1, "filename": "unofficial-allennlp-nightly-0.9.1.tar.gz", "has_sig": false, "md5_digest": "c64f12c4c8c42fd2ab704ad2f856f157", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.1", "size": 5555126, "upload_time": "2020-02-10T08:22:25", "upload_time_iso_8601": "2020-02-10T08:22:25.548475Z", "url": "https://files.pythonhosted.org/packages/b7/dc/2591555b830d41559e1e509262494f193fdc0569b25aa4b89bf996268dc1/unofficial-allennlp-nightly-0.9.1.tar.gz", "yanked": false}], "0.9.1.dev0": [{"comment_text": "", "digests": {"md5": "7bd7b4ee4b3bdcf0a34898f98ad39467", "sha256": "3e00247571e30d3268526a399ee992f60639c11c8a9a62d5ba6ca05b12b19e48"}, "downloads": -1, "filename": "unofficial_allennlp_nightly-0.9.1.dev0-py3-none-any.whl", "has_sig": false, "md5_digest": "7bd7b4ee4b3bdcf0a34898f98ad39467", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.1", "size": 5990650, "upload_time": "2020-02-10T16:55:19", "upload_time_iso_8601": "2020-02-10T16:55:19.757964Z", "url": "https://files.pythonhosted.org/packages/00/73/166dda68e52509004bcabafed90d5e986d10810988d5aa1ab735dec1c8a1/unofficial_allennlp_nightly-0.9.1.dev0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4e6b8df20ffe56eec8899a1421357c1b", "sha256": "0399d1473ff944727a73decb6a17b21ce9479f0d9f3330e2b8daecd37483e430"}, "downloads": -1, "filename": "unofficial-allennlp-nightly-0.9.1.dev0.tar.gz", "has_sig": false, "md5_digest": "4e6b8df20ffe56eec8899a1421357c1b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.1", "size": 7930863, "upload_time": "2020-02-10T16:55:24", "upload_time_iso_8601": "2020-02-10T16:55:24.594785Z", "url": "https://files.pythonhosted.org/packages/ef/7d/1bd6e1e3a75b3fa256dcaf9b120e6d09f218fc87853fd827ce0800b53e3a/unofficial-allennlp-nightly-0.9.1.dev0.tar.gz", "yanked": false}], "0.9.2": [{"comment_text": "", "digests": {"md5": "1e19e29f1deff112ab4ea4cfabc0c126", "sha256": "33658a4a6fffa550586d5d9d2373f344a5acf8e3b7dd2b8f25d5d0d21cce715e"}, "downloads": -1, "filename": "unofficial_allennlp_nightly-0.9.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1e19e29f1deff112ab4ea4cfabc0c126", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.1", "size": 5685554, "upload_time": "2020-02-10T11:26:58", "upload_time_iso_8601": "2020-02-10T11:26:58.657463Z", "url": "https://files.pythonhosted.org/packages/1e/d8/c08112e0db7710b98243e87c1b21c7064e9207d5f93f935e3a818e3bc373/unofficial_allennlp_nightly-0.9.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "39054fcf64969964387045f0acd5265e", "sha256": "e8a9bacb5757b0ad97314b8d2499f2eafcf77918242e3a68a0da6628a1929279"}, "downloads": -1, "filename": "unofficial-allennlp-nightly-0.9.2.tar.gz", "has_sig": false, "md5_digest": "39054fcf64969964387045f0acd5265e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.1", "size": 4577412, "upload_time": "2020-02-10T11:27:09", "upload_time_iso_8601": "2020-02-10T11:27:09.505563Z", "url": "https://files.pythonhosted.org/packages/52/2e/62b9903b80c33b8058e67f4bcebee9dd1e4136ac6993f696c21a5ac5224e/unofficial-allennlp-nightly-0.9.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "1e19e29f1deff112ab4ea4cfabc0c126", "sha256": "33658a4a6fffa550586d5d9d2373f344a5acf8e3b7dd2b8f25d5d0d21cce715e"}, "downloads": -1, "filename": "unofficial_allennlp_nightly-0.9.2-py3-none-any.whl", "has_sig": false, "md5_digest": "1e19e29f1deff112ab4ea4cfabc0c126", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.1", "size": 5685554, "upload_time": "2020-02-10T11:26:58", "upload_time_iso_8601": "2020-02-10T11:26:58.657463Z", "url": "https://files.pythonhosted.org/packages/1e/d8/c08112e0db7710b98243e87c1b21c7064e9207d5f93f935e3a818e3bc373/unofficial_allennlp_nightly-0.9.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "39054fcf64969964387045f0acd5265e", "sha256": "e8a9bacb5757b0ad97314b8d2499f2eafcf77918242e3a68a0da6628a1929279"}, "downloads": -1, "filename": "unofficial-allennlp-nightly-0.9.2.tar.gz", "has_sig": false, "md5_digest": "39054fcf64969964387045f0acd5265e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.1", "size": 4577412, "upload_time": "2020-02-10T11:27:09", "upload_time_iso_8601": "2020-02-10T11:27:09.505563Z", "url": "https://files.pythonhosted.org/packages/52/2e/62b9903b80c33b8058e67f4bcebee9dd1e4136ac6993f696c21a5ac5224e/unofficial-allennlp-nightly-0.9.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:40:09 2020"}