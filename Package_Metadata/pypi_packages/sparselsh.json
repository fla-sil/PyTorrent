{"info": {"author": "Brandon Roberts", "author_email": "brandon@bxroberts.org", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: Software Development :: Libraries"], "description": "# SparseLSH\n\nA locality sensitive hashing library with an emphasis on large, highly-dimensional datasets.\n\n## Features\n\n- Fast and memory-efficient calculations using sparse matrices.\n- Built-in support for key-value storage backends: pure-python, Redis (memory-bound), LevelDB, BerkeleyDB\n- Multiple hash indexes support (based on Kay Zhu's lshash)\n- Built-in support for common distance/objective functions for ranking outputs.\n\n## Details\n\nSparseLSH is based on a fork of Kay Zhu's lshash, and is suited for datasets that won't\nfit into main memory or are highly dimensional. Using sparse matrices\nallows for speedups of easily over an order of magnitude compared to using dense, list-based\nor numpy array-based vector math. Sparse matrices also makes it possible to deal with\nthese datasets purely in memory using python dicts or through Redis. When this isn't\nappropriate, you can use one of the disk-based key-value stores, LevelDB and BerkeleyDB.\nSerialization is done using cPickle (for raw C speedups), falling back to python\npickle if it's not available.\n\nBTC Donations: `1NejrUgQDm34CFyMHuaff9PNsd8zhd7SgR`\n\n## Installation\n\nThe easy way:\n\n    pip install sparselsh\n\nOr you can clone this repo and follow these instructions:\n\n`SparseLSH` depends on the following libraries:\n- [numpy](http://www.numpy.org/)\n- [scipy](http://www.scipy.org/)\n\nOptionally (for in-memory and disk-based persistence):\n- [redis](https://pypi.python.org/pypi/redis/)\n- [leveldb](https://code.google.com/p/py-leveldb/)\n- [bsddb](https://pypi.python.org/pypi/bsddb3/6.0.1) (built-in on Python 2.7.x)\n\nTo install (minimal install):\n\n    python setup.py install\n\nIf you would like to use the LevelDB or Redis\nstorage backends, you can install the dependencies\nfrom the `optional-requirements.txt`:\n\n    pip install -r optional-requirements.txt\n\n## Quickstart\n\nTo create 4-bit hashes for input data of 7 dimensions:\n\n    from sparselsh import LSH\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix( [\n        [ 3, 0, 0, 0, 0, 0, -1],\n        [ 0, 1, 0, 0, 0, 0,  1],\n        [ 1, 1, 1, 1, 1, 1,  1] ])\n\n    # One class number for each input point\n    y = [ 0, 3, 10]\n\n    X_sim = csr_matrix( [ [ 1, 1, 1, 1, 1, 1, 0]])\n\n    lsh = LSH( 4,\n               X.shape[1],\n               num_hashtables=1,\n               storage_config={\"dict\":None})\n\n    for ix in range(X.shape[0]):\n        x = X.getrow(ix)\n        c = y[ix]\n        lsh.index( x, extra_data=c)\n\n    # find the point in X nearest to X_sim\n    points = lsh.query(X_sim, num_results=1)\n\nThe query will result in a list of matrix-class tuple & similarity\nscore tuples. A lower score is better in this case:\n\n    [((<1x7 sparse matrix of type '<type 'numpy.int64'>'\n        with 7 stored elements in Compressed Sparse Row format>, 10), 1)]\n\nWe can look at the most similar matched item by accessing the sparse array\nand invoking it's `todense` function:\n\n    In [11]: print points[0][0][0].todense()\n    [[1 1 1 1 1 1 1]]\n\n## Main Interface\n\nMost of the parameters are supplied at class init time:\n\n    LSH( hash_size,\n         input_dim,\n         num_of_hashtables=1,\n         storage_config=None,\n         matrices_filename=None,\n         overwrite=False)\n\nParameters:\n\n    hash_size:\n        The length of the resulting binary hash. This controls how many \"buckets\"\n        there will be for items to be sorted into.\n\n    input_dim:\n        The dimension of the input vector. This needs to be the same as the input\n        points.\n\n    num_hashtables = 1:\n        (optional) The number of hash tables used. More hashtables increases the\n        probability of hash-collisions and the more similar items are likely\n        to be found for a query item.\n\n    storage = None:\n        (optional) A dict representing the storage backend and configuration\n        options. The following storage backends are supported with the following\n        configurations:\n            In-Memory Python Dictionary:\n                {\"dict\": None} # Takes no options\n            Redis:\n                {\"redis\": {\"host\": \"127.0.0.1\", \"port\": 6379, \"db\": 0}\n            LevelDB:\n                {\"leveldb\":{\"db\": \"ldb\"}}\n                Where \"ldb\" specifies the directory to store the LevelDB database.\n                (In this case it will be `./ldb/`)\n            Berkeley DB:\n                {\"berkeleydb\":{\"filename\": \"./db\"}}\n                Where \"filename\" is the location of the database file.\n\n    matrices_filename = None:\n        (optional) Specify the path to the .npz file random matrices are stored\n        or to be stored if the file does not exist yet. If you change the input\n        dimensions or the number of hashtables, you'll need to set the following\n        option, overwrite, to True, or delete this file.\n\n    overwrite = False:\n        (optional) Whether to overwrite the matrices file if it already exists.\n\n### Index (Add points to hash table):\n\n- To index a data point of a given `LSH` instance:\n\n    lsh.index(input_point, extra_data=None)\n\nParameters:\n\n    input_point:\n        The input data point is an array or tuple of numbers of input_dim.\n\n    extra_data = None:\n        (optional) Extra data to be added along with the input_point.\n        This can be used to hold values like class labels, URIs, titles, etc.\n\nThis function returns nothing.\n\n### Query (Search for similar points)\n\nTo query a data point against a given `LSH` instance:\n\n    lsh.query(query_point, num_results=None, distance_func=\"euclidean\")\n\nParameters:\n\n    query_point:\n        The query data point is a sparse CSR matrix.\n\n    num_results = None:\n        (optional) Integer, specifies the max amount of results to be\n        returned. If not specified all candidates will be returned as a\n        list in ranked order.\n        NOTE: You do not save processing by limiting the results. Currently,\n        a similarity ranking and sort is done on all items in the hashtable\n        regardless if this parameter.\n\n    distance_func = \"euclidean\":\n        (optional) Distance function to use to rank the candidates. By default\n        euclidean distance function will be used.\n\nReturns a list of tuples, each of which has the original input point (which\nwill be a tuple of csr-matrix, extra_data or just the csr-matrix if no extra\ndata was supplied) and a similarity score.\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/brandonrobertz/sparselsh/tarball/v1.1.2", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/brandonrobertz/sparselsh", "keywords": "clustering,sparse,lsh", "license": "", "maintainer": "", "maintainer_email": "", "name": "sparselsh", "package_url": "https://pypi.org/project/sparselsh/", "platform": "", "project_url": "https://pypi.org/project/sparselsh/", "project_urls": {"Download": "https://github.com/brandonrobertz/sparselsh/tarball/v1.1.2", "Homepage": "https://github.com/brandonrobertz/sparselsh"}, "release_url": "https://pypi.org/project/sparselsh/1.1.3/", "requires_dist": ["numpy (==1.8.1)", "scipy (==0.14.0)"], "requires_python": "", "summary": "A locality sensitive hashing library with an emphasis on large (sparse) datasets.", "version": "1.1.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>SparseLSH</h1>\n<p>A locality sensitive hashing library with an emphasis on large, highly-dimensional datasets.</p>\n<h2>Features</h2>\n<ul>\n<li>Fast and memory-efficient calculations using sparse matrices.</li>\n<li>Built-in support for key-value storage backends: pure-python, Redis (memory-bound), LevelDB, BerkeleyDB</li>\n<li>Multiple hash indexes support (based on Kay Zhu's lshash)</li>\n<li>Built-in support for common distance/objective functions for ranking outputs.</li>\n</ul>\n<h2>Details</h2>\n<p>SparseLSH is based on a fork of Kay Zhu's lshash, and is suited for datasets that won't\nfit into main memory or are highly dimensional. Using sparse matrices\nallows for speedups of easily over an order of magnitude compared to using dense, list-based\nor numpy array-based vector math. Sparse matrices also makes it possible to deal with\nthese datasets purely in memory using python dicts or through Redis. When this isn't\nappropriate, you can use one of the disk-based key-value stores, LevelDB and BerkeleyDB.\nSerialization is done using cPickle (for raw C speedups), falling back to python\npickle if it's not available.</p>\n<p>BTC Donations: <code>1NejrUgQDm34CFyMHuaff9PNsd8zhd7SgR</code></p>\n<h2>Installation</h2>\n<p>The easy way:</p>\n<pre><code>pip install sparselsh\n</code></pre>\n<p>Or you can clone this repo and follow these instructions:</p>\n<p><code>SparseLSH</code> depends on the following libraries:</p>\n<ul>\n<li><a href=\"http://www.numpy.org/\" rel=\"nofollow\">numpy</a></li>\n<li><a href=\"http://www.scipy.org/\" rel=\"nofollow\">scipy</a></li>\n</ul>\n<p>Optionally (for in-memory and disk-based persistence):</p>\n<ul>\n<li><a href=\"https://pypi.python.org/pypi/redis/\" rel=\"nofollow\">redis</a></li>\n<li><a href=\"https://code.google.com/p/py-leveldb/\" rel=\"nofollow\">leveldb</a></li>\n<li><a href=\"https://pypi.python.org/pypi/bsddb3/6.0.1\" rel=\"nofollow\">bsddb</a> (built-in on Python 2.7.x)</li>\n</ul>\n<p>To install (minimal install):</p>\n<pre><code>python setup.py install\n</code></pre>\n<p>If you would like to use the LevelDB or Redis\nstorage backends, you can install the dependencies\nfrom the <code>optional-requirements.txt</code>:</p>\n<pre><code>pip install -r optional-requirements.txt\n</code></pre>\n<h2>Quickstart</h2>\n<p>To create 4-bit hashes for input data of 7 dimensions:</p>\n<pre><code>from sparselsh import LSH\nfrom scipy.sparse import csr_matrix\n\nX = csr_matrix( [\n    [ 3, 0, 0, 0, 0, 0, -1],\n    [ 0, 1, 0, 0, 0, 0,  1],\n    [ 1, 1, 1, 1, 1, 1,  1] ])\n\n# One class number for each input point\ny = [ 0, 3, 10]\n\nX_sim = csr_matrix( [ [ 1, 1, 1, 1, 1, 1, 0]])\n\nlsh = LSH( 4,\n           X.shape[1],\n           num_hashtables=1,\n           storage_config={\"dict\":None})\n\nfor ix in range(X.shape[0]):\n    x = X.getrow(ix)\n    c = y[ix]\n    lsh.index( x, extra_data=c)\n\n# find the point in X nearest to X_sim\npoints = lsh.query(X_sim, num_results=1)\n</code></pre>\n<p>The query will result in a list of matrix-class tuple &amp; similarity\nscore tuples. A lower score is better in this case:</p>\n<pre><code>[((&lt;1x7 sparse matrix of type '&lt;type 'numpy.int64'&gt;'\n    with 7 stored elements in Compressed Sparse Row format&gt;, 10), 1)]\n</code></pre>\n<p>We can look at the most similar matched item by accessing the sparse array\nand invoking it's <code>todense</code> function:</p>\n<pre><code>In [11]: print points[0][0][0].todense()\n[[1 1 1 1 1 1 1]]\n</code></pre>\n<h2>Main Interface</h2>\n<p>Most of the parameters are supplied at class init time:</p>\n<pre><code>LSH( hash_size,\n     input_dim,\n     num_of_hashtables=1,\n     storage_config=None,\n     matrices_filename=None,\n     overwrite=False)\n</code></pre>\n<p>Parameters:</p>\n<pre><code>hash_size:\n    The length of the resulting binary hash. This controls how many \"buckets\"\n    there will be for items to be sorted into.\n\ninput_dim:\n    The dimension of the input vector. This needs to be the same as the input\n    points.\n\nnum_hashtables = 1:\n    (optional) The number of hash tables used. More hashtables increases the\n    probability of hash-collisions and the more similar items are likely\n    to be found for a query item.\n\nstorage = None:\n    (optional) A dict representing the storage backend and configuration\n    options. The following storage backends are supported with the following\n    configurations:\n        In-Memory Python Dictionary:\n            {\"dict\": None} # Takes no options\n        Redis:\n            {\"redis\": {\"host\": \"127.0.0.1\", \"port\": 6379, \"db\": 0}\n        LevelDB:\n            {\"leveldb\":{\"db\": \"ldb\"}}\n            Where \"ldb\" specifies the directory to store the LevelDB database.\n            (In this case it will be `./ldb/`)\n        Berkeley DB:\n            {\"berkeleydb\":{\"filename\": \"./db\"}}\n            Where \"filename\" is the location of the database file.\n\nmatrices_filename = None:\n    (optional) Specify the path to the .npz file random matrices are stored\n    or to be stored if the file does not exist yet. If you change the input\n    dimensions or the number of hashtables, you'll need to set the following\n    option, overwrite, to True, or delete this file.\n\noverwrite = False:\n    (optional) Whether to overwrite the matrices file if it already exists.\n</code></pre>\n<h3>Index (Add points to hash table):</h3>\n<ul>\n<li>\n<p>To index a data point of a given <code>LSH</code> instance:</p>\n<p>lsh.index(input_point, extra_data=None)</p>\n</li>\n</ul>\n<p>Parameters:</p>\n<pre><code>input_point:\n    The input data point is an array or tuple of numbers of input_dim.\n\nextra_data = None:\n    (optional) Extra data to be added along with the input_point.\n    This can be used to hold values like class labels, URIs, titles, etc.\n</code></pre>\n<p>This function returns nothing.</p>\n<h3>Query (Search for similar points)</h3>\n<p>To query a data point against a given <code>LSH</code> instance:</p>\n<pre><code>lsh.query(query_point, num_results=None, distance_func=\"euclidean\")\n</code></pre>\n<p>Parameters:</p>\n<pre><code>query_point:\n    The query data point is a sparse CSR matrix.\n\nnum_results = None:\n    (optional) Integer, specifies the max amount of results to be\n    returned. If not specified all candidates will be returned as a\n    list in ranked order.\n    NOTE: You do not save processing by limiting the results. Currently,\n    a similarity ranking and sort is done on all items in the hashtable\n    regardless if this parameter.\n\ndistance_func = \"euclidean\":\n    (optional) Distance function to use to rank the candidates. By default\n    euclidean distance function will be used.\n</code></pre>\n<p>Returns a list of tuples, each of which has the original input point (which\nwill be a tuple of csr-matrix, extra_data or just the csr-matrix if no extra\ndata was supplied) and a similarity score.</p>\n\n          </div>"}, "last_serial": 4789413, "releases": {"1.1.0": [{"comment_text": "", "digests": {"md5": "0cee0a27e9cf6c80f6a52bb83e40f3e6", "sha256": "2eb7652f68a4df9cbdb003d1fcd8f4d764ced67bc060fb7c3b7c176e242cf401"}, "downloads": -1, "filename": "sparselsh-1.1.0.tar.gz", "has_sig": false, "md5_digest": "0cee0a27e9cf6c80f6a52bb83e40f3e6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9374, "upload_time": "2017-02-09T01:34:30", "upload_time_iso_8601": "2017-02-09T01:34:30.778543Z", "url": "https://files.pythonhosted.org/packages/82/ae/77d04d1596c4870254fe6973b704d976d596a5f4133acd815a5f6aae6683/sparselsh-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "1f2374437d7d6e88f0bfa46ce4792a02", "sha256": "fb9476bfd65ad0137b1e053737c666070af32b7de57579ddab0d7e46ade893ab"}, "downloads": -1, "filename": "sparselsh-1.1.1.tar.gz", "has_sig": false, "md5_digest": "1f2374437d7d6e88f0bfa46ce4792a02", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9434, "upload_time": "2017-02-09T01:42:56", "upload_time_iso_8601": "2017-02-09T01:42:56.610659Z", "url": "https://files.pythonhosted.org/packages/f4/8c/fe266fc6d8c202e1369bfe553abe8a35906bc4d91776c4b4146e6a9c4086/sparselsh-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "8864e90bfb0d09d09ac261a3694857f5", "sha256": "fea2bf3cb9f9d289e640fe5637dfc3a6dff38b0f64011ec9d47031f564993e34"}, "downloads": -1, "filename": "sparselsh-1.1.2.tar.gz", "has_sig": false, "md5_digest": "8864e90bfb0d09d09ac261a3694857f5", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9420, "upload_time": "2017-02-09T01:54:05", "upload_time_iso_8601": "2017-02-09T01:54:05.395908Z", "url": "https://files.pythonhosted.org/packages/d8/12/5c57b94519b1e425e92ca02536755792cbc27e66d407609dc578e74a53fe/sparselsh-1.1.2.tar.gz", "yanked": false}], "1.1.3": [{"comment_text": "", "digests": {"md5": "9d6c4445241824ef633fa27905a92155", "sha256": "f3e29c80f86a495a20892323e5016e8c7e745f2539e54525fdec8f7720e66eeb"}, "downloads": -1, "filename": "sparselsh-1.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "9d6c4445241824ef633fa27905a92155", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10992, "upload_time": "2019-02-07T02:59:12", "upload_time_iso_8601": "2019-02-07T02:59:12.916516Z", "url": "https://files.pythonhosted.org/packages/ec/b8/e5f65f14935e3030a68d0c19f2d088aeb272cb7a3aca966b6f7a9e62189b/sparselsh-1.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "167edd6bca9ac978a9b58947b90e3b72", "sha256": "aa0b4fc6741caf6fa1ce89f8c1f8da4e22b05388cfc6158fdd83ccd9d02b2401"}, "downloads": -1, "filename": "sparselsh-1.1.3.tar.gz", "has_sig": false, "md5_digest": "167edd6bca9ac978a9b58947b90e3b72", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10066, "upload_time": "2019-02-07T02:59:14", "upload_time_iso_8601": "2019-02-07T02:59:14.448798Z", "url": "https://files.pythonhosted.org/packages/e8/b2/8b3e724f02f6d71e4fdb77af4fb7d6f231e4b641b69330dad9bee516bdc1/sparselsh-1.1.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9d6c4445241824ef633fa27905a92155", "sha256": "f3e29c80f86a495a20892323e5016e8c7e745f2539e54525fdec8f7720e66eeb"}, "downloads": -1, "filename": "sparselsh-1.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "9d6c4445241824ef633fa27905a92155", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10992, "upload_time": "2019-02-07T02:59:12", "upload_time_iso_8601": "2019-02-07T02:59:12.916516Z", "url": "https://files.pythonhosted.org/packages/ec/b8/e5f65f14935e3030a68d0c19f2d088aeb272cb7a3aca966b6f7a9e62189b/sparselsh-1.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "167edd6bca9ac978a9b58947b90e3b72", "sha256": "aa0b4fc6741caf6fa1ce89f8c1f8da4e22b05388cfc6158fdd83ccd9d02b2401"}, "downloads": -1, "filename": "sparselsh-1.1.3.tar.gz", "has_sig": false, "md5_digest": "167edd6bca9ac978a9b58947b90e3b72", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 10066, "upload_time": "2019-02-07T02:59:14", "upload_time_iso_8601": "2019-02-07T02:59:14.448798Z", "url": "https://files.pythonhosted.org/packages/e8/b2/8b3e724f02f6d71e4fdb77af4fb7d6f231e4b641b69330dad9bee516bdc1/sparselsh-1.1.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:05:49 2020"}