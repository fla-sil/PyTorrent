{"info": {"author": "Baris Ozmen", "author_email": "hbaristr@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "Programming Language :: Python :: 3"], "description": "# DeepAugment\n\n![pypi](https://img.shields.io/pypi/v/deepaugment.svg?style=flat)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\nDeepAugment discovers augmentation strategies tailored for your images. It uses Bayesian Optimization for optimizing data augmentation hyperparameters. The tool:\n1. reduces error rate of CNN models (shown 60% decrease in error for CIFAR-10 on WRN-28-10 compared to no augmentation)\n2. saves time by automating the process\n\nResources: [slides](https://docs.google.com/presentation/d/1toRUTT9X26ACngr6DXCKmPravyqmaGjy-eIU5cTbG1A/edit#slide=id.g4cc092dbc6_0_0)\n\n## Installation/Usage\nTutorial: [google-colab](https://drive.google.com/open?id=1KCAv2i_F3E3m_PKh56nbbZY8WnaASvgl)\n\n```console\n$ pip install deepaugment\n```\n\n### Simple usage (with any dataset)\n```Python\nfrom deepaugment.deepaugment import DeepAugment\n\ndeepaug = DeepAugment(my_images, my_labels)\n\nbest_policies = deepaug.optimize(300)\n```\n\n### Simple usage (with CIFAR-10 on keras)\n```Python\ndeepaug = DeepAugment(\"cifar10\")\n\nbest_policies = deepaug.optimize(300)\n```\n\n### Advanced usage\n```Python\nfrom keras.datasets import fashion_mnist\n\n# my configuration\nmy_config = {\n    \"model\": \"basiccnn\",\n    \"method\": \"bayesian_optimization\",\n    \"train_set_size\": 2000,\n    \"opt_samples\": 3,\n    \"opt_last_n_epochs\": 3,\n    \"opt_initial_points\": 10,\n    \"child_epochs\": 50,\n    \"child_first_train_epochs\": 0,\n    \"child_batch_size\": 64\n}\n\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n# X_train.shape -> (N, M, M, 3)\n# y_train.shape -> (N)\ndeepaug = DeepAugment(iamges=x_train, labels=y_train, config=my_config)\n\nbest_policies = deepaug.optimize(300)\n```\n\n## Results\n### CIFAR-10 best policies tested on WRN-28-10 \n- Method: Wide-ResNet-28-10 trained with CIFAR-10 augmented images by best found policies, and with unaugmented images (everything else same).\n- Result: **60% reduction in error** (8.5% accuracy increase) by DeepAugment\n<img src=\"https://user-images.githubusercontent.com/14996155/53362039-1d82e400-38ee-11e9-8f5e-e6f1602865a8.png\" width=\"400\"> <img src=\"https://user-images.githubusercontent.com/14996155/53362042-21af0180-38ee-11e9-9253-96ce8ddcc17c.png\" width=\"400\">\n\n## Design goals\nDeepAugment is designed as a scalable and modular partner to AutoAugment ([Cubuk et al., 2018](https://arxiv.org/abs/1805.09501)). AutoAugment was one of the most exciting publications in 2018. It was the first method using Reinforcement Learning for this problem. AutoAugmentation, however, has no complete open-sourced implementation (controller module not available) preventing users to run it for their own datasets, and takes 15,000 iterations to learn (according to paper) augmentation policies, which requires massive computational resources. Thus most people could not benefit from it even if its source code would be fully available.\n\nDeepAugment addresses these two problems. Its main design goals are: \n1. **minimize the computational complexity of optimization while maintaining quality of results**\n2. **be modular and user-friendly**\n\nFirst goal is achieved by following changes compared to AutoAugment:\n1. Bayesian Optimization instead of Reinforcement Learning \n    * which requires much less number of iterations (~100 times)\n2. Minimized Child Model\n    * decreasing computational complexity of each training (~20 times)\n3. Less stochastic augmentation search space design\n    * decreasing number of iterations needed\n\nFor achieving the second goal, user interface is designed in a way that it gives user broad configuration possibilities and model selections (e.g. selecting the child model or inputting a self-designed child model).\n\n## Importance\n### Practical importance\nDeepAugment makes optimization of data augmentation scalable, and thus enables users to optimize augmentation policies without needing massive computational resources. \nAs an estimate of its computational cost, it takes **4.2 hours** (500 iterations) on CIFAR-10 dataset which costs around **$13** using AWS p3.x2large instance. \n### Academic importance\nTo our knowlege, DeepAugment is the first method which utilizes Bayesian Optimization for the problem of data augmentation hyperparameter optimization.\n\n## How it works\n\nThree major components of DeepAugment are controller, augmenter, and child model. Overal workflow is that controller samples new augmentation policies, augmenter transforms images by the new policy, and child model is trained from scratch by augmented images. Then, a reward is calculated from child model's training history. This reward is returned back to the controller, and it updates its surrogate model with this reward and associated augmentation policy. Then, controller samples new policies again and same steps repeats. This process cycles until user-determined maximum number of iterations reached.\n\nController can be set for using either Bayesian Optimization (default) or Random Search. If set to Bayesian Optimization, samples new policies by a Random Forest Estimator and Expected Improvement acquistion function.\n\n<img width=\"600\" alt=\"simplified_workflow\" src=\"https://user-images.githubusercontent.com/14996155/52587711-797a4280-2def-11e9-84f8-2368fd709ab9.png\">\n\n### Why Bayesian Optimization?\n\nIn hyperparameter optimization, main choices are random search, grid search, bayesian optimization (BO), and reinforcement learning (RL) (in the order of method complexity). Google's [AutoAugment](https://arxiv.org/abs/1805.09501) uses RL for data augmentation hyperparameter tuning, but it takes 15,000 iterations to learn policies (which means training the child CNN model 15,000 times). Thus, it requires massive computational resources. Bayesian Optimization on the other hand learns good polices in 100-300 iterations, making it +40X faster. Additionally, it is better than grid search and random search in terms of accuracy, cost, and computation time in hyperparameter tuning([ref](https://mlconf.com/lets-talk-bayesian-optimization/)) (we can think optimization of augmentation policies as a hyperparameter tuning problem where hyperparameters are concerning with augmentations instead of the deep learning architecture). This result is not surprising since despite Grid Search or Random Search BO selects new hyperparameter as informed with previous results for tried hyperparameters.\n\n<img width=\"500\" alt=\"optimization-comparison\" src=\"https://user-images.githubusercontent.com/14996155/53222123-4ae73d80-3621-11e9-9457-44e76012d11c.png\">\n\n### How does Bayesian Optimization work?\n\nAim of Bayesian Optimization (BO) is finding **set of parameters** which maximize the value of an **objective function**. It builds a surrogate model for predicting value of objective function for unexplored parameters. Working cycle of BO can be summarized as:\n1. Build a surrogate model of the objective function \n2. Find parameters that perform best on the surrogate (or pick random hyperparameters)\n3. Execute objective function with these parameters\n4. Update the surrogate model with these parameters and result (value) of objective function\n5. Repeat steps 2-4 until maximimum number of iterations reached\n\nFor more detailed explanation, read [this blogpost](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f) explaining BO in high-level, or take a glance at [this review paper](https://ieeexplore.ieee.org/document/7352306)\n\n### Augmentation policy\n\nA policy describes the augmentation will be applied on a dataset. Each policy consists variables for two augmentation types, their magnitude and the portion of the data to be augmented. An example policy is as following: \n\n<img width=\"400\" alt=\"example policy\" src=\"https://user-images.githubusercontent.com/14996155/52595719-59ed1500-2e03-11e9-9a40-a79462006924.png\">\n\nThere are currently 20 types of augmentation techniques (above, right) that each aug. type variable can take. All techniques are (this list might grow in later versions):\n```Python\nAUG_TYPES = [ \"crop\", \"gaussian-blur\", \"rotate\", \"shear\", \"translate-x\", \"translate-y\", \"sharpen\", \"emboss\", \"additive-gaussian-noise\", \"dropout\", \"coarse-dropout\", \"gamma-contrast\", \"brighten\", \"invert\", \"fog\", \"clouds\", \"add-to-hue-and-saturation\", \"coarse-salt-pepper\", \"horizontal-flip\", \"vertical-flip\"]\n```\n### Child model\n[source](https://github.com/barisozmen/deepaugment/blob/master/deepaugment/childcnn.py#L232-L269)\n\nChild model is trained over and over from scratch during the optimization process. Its number of training depends on the number of iterations chosen by the user, which is expected to be around 100-300 for obtaining good results. Child model is therefore the computational bottleneck of the algorithm. With the current design, training time is ~30 seconds for 32x32 images on AWS instance p3.x2large using V100 GPU (112 TensorFLOPS). It has 1,250,858 trainable parameters for 32x32 images. Below is the diagram of child model:\n<img width=\"800\" alt=\"child-cnn\" src=\"https://user-images.githubusercontent.com/14996155/52545277-10e98200-2d6b-11e9-9639-48b671711eba.png\">\n\n#### Other choices for child CNN model\nStandard Child model is a basic CNN where its diagram and details given above. However, you are not limited with that model. You can use your own keras model by assigning it into config dictionary as:\n```Python\nmy_config = {\"model\": my_keras_model_object}\ndeepaug = DeepAugment(my_images, my_labels, my_config)\n```\nOr use an implemented small model, such as WideResNet-40-2 (while it is bigger than Basic CNN):\n```Python\nmy_config = {\"model\": \"wrn_40_2\"} # depth(40) and wideness-factor(2) can be changed. e.g. wrn_20_4\n```\nOr use a big model (not recommended unless you have massive computational resources):\n```Python\nmy_config = {\"model\": \"InceptionV3\"}\n```\n```Python\nmy_config = {\"model\": \"MobileNetV2\"}\n```\n\n### Reward function\n[source](https://github.com/barisozmen/deepaugment/blob/master/deepaugment/objective.py#L69-L89)\n\nReward function is calculated as mean of K highest validation accuracies of the child model which is not smaller than corresponding training accuracy by 0.05. K can be determined by the user by updating `opt_last_n_epochs` key in config as argument to `DeepAugment()` class (K is 3 by default).\n\n## Configuration options\n\nDeepAugment can be given a config dictionary during initialization. It is expected to have following keys:\n\n* **model**: child model type. Options: \"basiccnn\", \"inceptionv3\", \"mobilenetv2\", \"wrn_<DEPTH>_<WIDENING-FACTOR>\", or keras.models.Model object\n* **method:** \"bayesian_optimization\" or \"random\" (for random search)\n* **train_set_size:** size of the training set during optimization. It should be small enough that computation will not take too long.\n* **opt_samples:** number of samples optimizer will run for each augmentation-policy. Training of the child model is stochastic and validation accuracy results might be slightly different from run to run. The tool trains child model three times by default and takes average, in order to have more robust accuracy results.\n* **opt_last_n_epochs:** number of non-overfitting epochs whose validation accuracy average will be used as reward. For each training, `opt_last_n_epochs` highest validation accuracies (where its difference to training accuracy is not more than 10%) are averaged and taken as reward.\n* **opt_initial_points:** number of random initial policies will be tried by Bayesian Optimizer. It will be the `n_initial_points` argument for skopt Optimizer (see its [documentation](https://scikit-optimize.github.io/#skopt.Optimizer))\n* **child_epochs:** number of epochs for the child model\n* **child_first_train_epochs:** if not 0, child model is pre-trained without any augmentation and its resulting weights are load for each training with augmentation. The purpose is training child model 10-20 epochs once and thereby saving 10-20 epochs for each training of optimizer iterations which is +100 times.\n* **child_batch_size:** batch size for the child model\n* **per_aug_weights_path:** path for pre-augmented training weights. Unneccessary if `child_first_train_epochs=0`\n* **logging:** logging object for getting news about the optimization.\n* **notebook_path:** path for recording all trainings in all iterations. For each iteration, training history, trial-no, sample-no, calculated reward and mean recent validation accuracy is recorded. Records is updated at each trial for ensuring records are not lost in case optimization interrupted unintentionally. Records can be found at \"/reports/experiments/<EXPERIMENT-NAME-AS-YEAR-MONTH-DAY-HOUR-MINUTE>/notebook.csv\"\n\nDefault configurations are as following:\n```Python\nDEFAULT_CONFIG = {\n    \"model\": \"basiccnn\", # \n    \"method\": \"bayesian_optimization\",\n    \"train_set_size\": 2000,\n    \"opt_samples\": 3,\n    \"opt_last_n_epochs\": 3,\n    \"opt_initial_points\": 10,\n    \"child_epochs\": 50,\n    \"child_first_train_epochs\": 0,\n    \"child_batch_size\": 64,\n    \"pre_aug_weights_path\": \"pre_aug_weights.h5\",\n    \"logging\": logging,\n    \"notebook_path\": f\"{EXPERIMENT_FOLDER_PATH}/notebook.csv\",\n}\n```\n## Versioning rules\nA three-number system is used, like *1.2.3*. Each increment of version is one of the following types:\n - minor: if bugs are fixed, or documentation changed significantly. *1.2.3 -> 1.2.4*\n - major: if a feature implemented differently, or a new feature added. *1.2.3 -> 1.3.0*\n - disruptive: if a feature is removed or renamed. *1.2.3 -> 2.0.0* (Backward compatibility is not guaranteed)\n\nNote: Versions from *0.0.0* to *1.0.0* are considered as **alpha phase** and do not follow this strategy. \n\n## Data pipeline\n<img width=\"600\" alt=\"data-pipeline-2\" src=\"https://user-images.githubusercontent.com/14996155/52740938-0d334680-2f89-11e9-8d68-117d139d9ab8.png\">\n<img width=\"600\" alt=\"data-pipeline-1\" src=\"https://user-images.githubusercontent.com/14996155/52740937-0c9ab000-2f89-11e9-9e94-beca71caed41.png\">\n\n## Class diagram\nCreated by [pyreverse](https://www.logilab.org/blogentry/6883)\n![classes_deepaugment](https://user-images.githubusercontent.com/14996155/52743629-4969a580-2f8f-11e9-8eb2-35aa1af161bb.png)\n\n## Package diagram\nCreated by [pyreverse](https://www.logilab.org/blogentry/6883)\n<img width=\"600\" alt=\"package-diagram\" src=\"https://user-images.githubusercontent.com/14996155/52743630-4a023c00-2f8f-11e9-9b12-32b2ded6071b.png\">\n\n## References\n[1] Cubuk et al., 2018. AutoAugment: Learning Augmentation Policies from Data\n([arxiv](https://arxiv.org/abs/1805.09501))\n\n[2] Zoph et al., 2016. Neural Architecture Search with Reinforcement Learning\n([arxiv](https://arxiv.org/abs/1611.01578))\n\n[3] Shahriari et al., 2016. A review of Bayesian Optimization\n([ieee](https://ieeexplore.ieee.org/document/7352306))\n\n[4] Dewancker et al. Bayesian Optimization Primer ([white-paper](https://app.sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf))\n\n[5] DeVries, Taylor 2017. Improved Regularization of CNN's with Cutout\n([arxiv](https://arxiv.org/abs/1708.04552))\n\nBlogs: \n- A conceptual explanation of Bayesian Optimization ([towardsdatascience](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f))\n- Comparison experiment: Bayesian Opt. vs Grid Search vs Random Search ([mlconf](https://mlconf.com/lets-talk-bayesian-optimization/))\n\nLibraries:\n- [scikit-optimize](scikit-optimize.github.io/)\n- [mgaug](github.com/aleju/imgaug)\n- [AutoAugment-unofficial](github.com/barisozmen/autoaugment-unofficial)\n- [Automold]() (Self-driving car image-augmentation library)\n\n--------\n\n## Contact\nBaris Ozmen, hbaristr@gmail.com\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/barisozmen/deepaugment/tarball/1.1.2", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/barisozmen/deepaugment", "keywords": "", "license": "BSD", "maintainer": "", "maintainer_email": "", "name": "deepaugment", "package_url": "https://pypi.org/project/deepaugment/", "platform": "", "project_url": "https://pypi.org/project/deepaugment/", "project_urls": {"Download": "https://github.com/barisozmen/deepaugment/tarball/1.1.2", "Homepage": "https://github.com/barisozmen/deepaugment"}, "release_url": "https://pypi.org/project/deepaugment/1.1.2/", "requires_dist": ["matplotlib (==3.0.2)", "tensorflow (==1.12.0)", "keras (==2.2.4)", "imgaug (==0.2.7)", "setuptools (==40.6.3)", "keras-applications (==1.0.6)", "pandas (==0.23.4)", "scikit-optimize (==0.5.2)", "click (==7.0)", "numpy (==1.15.4)", "opencv-contrib-python"], "requires_python": "", "summary": "Discover augmentation strategies tailored for your data", "version": "1.1.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>DeepAugment</h1>\n<p><img alt=\"pypi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/668d6e3e4f6c750ee2b5a865b61012b6630a53b8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f646565706175676d656e742e7376673f7374796c653d666c6174\">\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img alt=\"License: MIT\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8645b002dd7ec1b54275a80574942e7a318e03c6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667\"></a>\n<a href=\"https://github.com/ambv/black\" rel=\"nofollow\"><img alt=\"Code style: black\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fbfdc7754183ecf079bc71ddeabaf88f6cbc5c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\"></a></p>\n<p>DeepAugment discovers augmentation strategies tailored for your images. It uses Bayesian Optimization for optimizing data augmentation hyperparameters. The tool:</p>\n<ol>\n<li>reduces error rate of CNN models (shown 60% decrease in error for CIFAR-10 on WRN-28-10 compared to no augmentation)</li>\n<li>saves time by automating the process</li>\n</ol>\n<p>Resources: <a href=\"https://docs.google.com/presentation/d/1toRUTT9X26ACngr6DXCKmPravyqmaGjy-eIU5cTbG1A/edit#slide=id.g4cc092dbc6_0_0\" rel=\"nofollow\">slides</a></p>\n<h2>Installation/Usage</h2>\n<p>Tutorial: <a href=\"https://drive.google.com/open?id=1KCAv2i_F3E3m_PKh56nbbZY8WnaASvgl\" rel=\"nofollow\">google-colab</a></p>\n<pre><span class=\"gp\">$</span> pip install deepaugment\n</pre>\n<h3>Simple usage (with any dataset)</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">deepaugment.deepaugment</span> <span class=\"kn\">import</span> <span class=\"n\">DeepAugment</span>\n\n<span class=\"n\">deepaug</span> <span class=\"o\">=</span> <span class=\"n\">DeepAugment</span><span class=\"p\">(</span><span class=\"n\">my_images</span><span class=\"p\">,</span> <span class=\"n\">my_labels</span><span class=\"p\">)</span>\n\n<span class=\"n\">best_policies</span> <span class=\"o\">=</span> <span class=\"n\">deepaug</span><span class=\"o\">.</span><span class=\"n\">optimize</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">)</span>\n</pre>\n<h3>Simple usage (with CIFAR-10 on keras)</h3>\n<pre><span class=\"n\">deepaug</span> <span class=\"o\">=</span> <span class=\"n\">DeepAugment</span><span class=\"p\">(</span><span class=\"s2\">\"cifar10\"</span><span class=\"p\">)</span>\n\n<span class=\"n\">best_policies</span> <span class=\"o\">=</span> <span class=\"n\">deepaug</span><span class=\"o\">.</span><span class=\"n\">optimize</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">)</span>\n</pre>\n<h3>Advanced usage</h3>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">keras.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">fashion_mnist</span>\n\n<span class=\"c1\"># my configuration</span>\n<span class=\"n\">my_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"model\"</span><span class=\"p\">:</span> <span class=\"s2\">\"basiccnn\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"method\"</span><span class=\"p\">:</span> <span class=\"s2\">\"bayesian_optimization\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"train_set_size\"</span><span class=\"p\">:</span> <span class=\"mi\">2000</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"opt_samples\"</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"opt_last_n_epochs\"</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"opt_initial_points\"</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"child_epochs\"</span><span class=\"p\">:</span> <span class=\"mi\">50</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"child_first_train_epochs\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"child_batch_size\"</span><span class=\"p\">:</span> <span class=\"mi\">64</span>\n<span class=\"p\">}</span>\n\n<span class=\"p\">(</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">x_test</span><span class=\"p\">,</span> <span class=\"n\">y_test</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">fashion_mnist</span><span class=\"o\">.</span><span class=\"n\">load_data</span><span class=\"p\">()</span>\n<span class=\"c1\"># X_train.shape -&gt; (N, M, M, 3)</span>\n<span class=\"c1\"># y_train.shape -&gt; (N)</span>\n<span class=\"n\">deepaug</span> <span class=\"o\">=</span> <span class=\"n\">DeepAugment</span><span class=\"p\">(</span><span class=\"n\">iamges</span><span class=\"o\">=</span><span class=\"n\">x_train</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"o\">=</span><span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">config</span><span class=\"o\">=</span><span class=\"n\">my_config</span><span class=\"p\">)</span>\n\n<span class=\"n\">best_policies</span> <span class=\"o\">=</span> <span class=\"n\">deepaug</span><span class=\"o\">.</span><span class=\"n\">optimize</span><span class=\"p\">(</span><span class=\"mi\">300</span><span class=\"p\">)</span>\n</pre>\n<h2>Results</h2>\n<h3>CIFAR-10 best policies tested on WRN-28-10</h3>\n<ul>\n<li>Method: Wide-ResNet-28-10 trained with CIFAR-10 augmented images by best found policies, and with unaugmented images (everything else same).</li>\n<li>Result: <strong>60% reduction in error</strong> (8.5% accuracy increase) by DeepAugment\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/42c13225cb754fbe77140704ed3990bae52b82f4/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35333336323033392d31643832653430302d333865652d313165392d386635652d6536663136303238363561382e706e67\" width=\"400\"> <img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f7a942865448da1feb713e270e013dbf1976035d/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35333336323034322d32316166303138302d333865652d313165392d393235332d3936636538646463633137632e706e67\" width=\"400\"></li>\n</ul>\n<h2>Design goals</h2>\n<p>DeepAugment is designed as a scalable and modular partner to AutoAugment (<a href=\"https://arxiv.org/abs/1805.09501\" rel=\"nofollow\">Cubuk et al., 2018</a>). AutoAugment was one of the most exciting publications in 2018. It was the first method using Reinforcement Learning for this problem. AutoAugmentation, however, has no complete open-sourced implementation (controller module not available) preventing users to run it for their own datasets, and takes 15,000 iterations to learn (according to paper) augmentation policies, which requires massive computational resources. Thus most people could not benefit from it even if its source code would be fully available.</p>\n<p>DeepAugment addresses these two problems. Its main design goals are:</p>\n<ol>\n<li><strong>minimize the computational complexity of optimization while maintaining quality of results</strong></li>\n<li><strong>be modular and user-friendly</strong></li>\n</ol>\n<p>First goal is achieved by following changes compared to AutoAugment:</p>\n<ol>\n<li>Bayesian Optimization instead of Reinforcement Learning\n<ul>\n<li>which requires much less number of iterations (~100 times)</li>\n</ul>\n</li>\n<li>Minimized Child Model\n<ul>\n<li>decreasing computational complexity of each training (~20 times)</li>\n</ul>\n</li>\n<li>Less stochastic augmentation search space design\n<ul>\n<li>decreasing number of iterations needed</li>\n</ul>\n</li>\n</ol>\n<p>For achieving the second goal, user interface is designed in a way that it gives user broad configuration possibilities and model selections (e.g. selecting the child model or inputting a self-designed child model).</p>\n<h2>Importance</h2>\n<h3>Practical importance</h3>\n<p>DeepAugment makes optimization of data augmentation scalable, and thus enables users to optimize augmentation policies without needing massive computational resources.\nAs an estimate of its computational cost, it takes <strong>4.2 hours</strong> (500 iterations) on CIFAR-10 dataset which costs around <strong>$13</strong> using AWS p3.x2large instance.</p>\n<h3>Academic importance</h3>\n<p>To our knowlege, DeepAugment is the first method which utilizes Bayesian Optimization for the problem of data augmentation hyperparameter optimization.</p>\n<h2>How it works</h2>\n<p>Three major components of DeepAugment are controller, augmenter, and child model. Overal workflow is that controller samples new augmentation policies, augmenter transforms images by the new policy, and child model is trained from scratch by augmented images. Then, a reward is calculated from child model's training history. This reward is returned back to the controller, and it updates its surrogate model with this reward and associated augmentation policy. Then, controller samples new policies again and same steps repeats. This process cycles until user-determined maximum number of iterations reached.</p>\n<p>Controller can be set for using either Bayesian Optimization (default) or Random Search. If set to Bayesian Optimization, samples new policies by a Random Forest Estimator and Expected Improvement acquistion function.</p>\n<img alt=\"simplified_workflow\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/0a46366c5f95cea7834191d3d7c47e68f931e011/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323538373731312d37393761343238302d326465662d313165392d383466382d3233363866643730396162392e706e67\" width=\"600\">\n<h3>Why Bayesian Optimization?</h3>\n<p>In hyperparameter optimization, main choices are random search, grid search, bayesian optimization (BO), and reinforcement learning (RL) (in the order of method complexity). Google's <a href=\"https://arxiv.org/abs/1805.09501\" rel=\"nofollow\">AutoAugment</a> uses RL for data augmentation hyperparameter tuning, but it takes 15,000 iterations to learn policies (which means training the child CNN model 15,000 times). Thus, it requires massive computational resources. Bayesian Optimization on the other hand learns good polices in 100-300 iterations, making it +40X faster. Additionally, it is better than grid search and random search in terms of accuracy, cost, and computation time in hyperparameter tuning(<a href=\"https://mlconf.com/lets-talk-bayesian-optimization/\" rel=\"nofollow\">ref</a>) (we can think optimization of augmentation policies as a hyperparameter tuning problem where hyperparameters are concerning with augmentations instead of the deep learning architecture). This result is not surprising since despite Grid Search or Random Search BO selects new hyperparameter as informed with previous results for tried hyperparameters.</p>\n<img alt=\"optimization-comparison\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/db9f9d3c92eb6e740f93242d9d2bd2698b2ee03d/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35333232323132332d34616537336438302d333632312d313165392d393435372d3434653736303132643131632e706e67\" width=\"500\">\n<h3>How does Bayesian Optimization work?</h3>\n<p>Aim of Bayesian Optimization (BO) is finding <strong>set of parameters</strong> which maximize the value of an <strong>objective function</strong>. It builds a surrogate model for predicting value of objective function for unexplored parameters. Working cycle of BO can be summarized as:</p>\n<ol>\n<li>Build a surrogate model of the objective function</li>\n<li>Find parameters that perform best on the surrogate (or pick random hyperparameters)</li>\n<li>Execute objective function with these parameters</li>\n<li>Update the surrogate model with these parameters and result (value) of objective function</li>\n<li>Repeat steps 2-4 until maximimum number of iterations reached</li>\n</ol>\n<p>For more detailed explanation, read <a href=\"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\" rel=\"nofollow\">this blogpost</a> explaining BO in high-level, or take a glance at <a href=\"https://ieeexplore.ieee.org/document/7352306\" rel=\"nofollow\">this review paper</a></p>\n<h3>Augmentation policy</h3>\n<p>A policy describes the augmentation will be applied on a dataset. Each policy consists variables for two augmentation types, their magnitude and the portion of the data to be augmented. An example policy is as following:</p>\n<img alt=\"example policy\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b2e66341065de0412f33ce5a0f7e9849578fd32e/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323539353731392d35396564313530302d326530332d313165392d396134302d6137393436323030363932342e706e67\" width=\"400\">\n<p>There are currently 20 types of augmentation techniques (above, right) that each aug. type variable can take. All techniques are (this list might grow in later versions):</p>\n<pre><span class=\"n\">AUG_TYPES</span> <span class=\"o\">=</span> <span class=\"p\">[</span> <span class=\"s2\">\"crop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"gaussian-blur\"</span><span class=\"p\">,</span> <span class=\"s2\">\"rotate\"</span><span class=\"p\">,</span> <span class=\"s2\">\"shear\"</span><span class=\"p\">,</span> <span class=\"s2\">\"translate-x\"</span><span class=\"p\">,</span> <span class=\"s2\">\"translate-y\"</span><span class=\"p\">,</span> <span class=\"s2\">\"sharpen\"</span><span class=\"p\">,</span> <span class=\"s2\">\"emboss\"</span><span class=\"p\">,</span> <span class=\"s2\">\"additive-gaussian-noise\"</span><span class=\"p\">,</span> <span class=\"s2\">\"dropout\"</span><span class=\"p\">,</span> <span class=\"s2\">\"coarse-dropout\"</span><span class=\"p\">,</span> <span class=\"s2\">\"gamma-contrast\"</span><span class=\"p\">,</span> <span class=\"s2\">\"brighten\"</span><span class=\"p\">,</span> <span class=\"s2\">\"invert\"</span><span class=\"p\">,</span> <span class=\"s2\">\"fog\"</span><span class=\"p\">,</span> <span class=\"s2\">\"clouds\"</span><span class=\"p\">,</span> <span class=\"s2\">\"add-to-hue-and-saturation\"</span><span class=\"p\">,</span> <span class=\"s2\">\"coarse-salt-pepper\"</span><span class=\"p\">,</span> <span class=\"s2\">\"horizontal-flip\"</span><span class=\"p\">,</span> <span class=\"s2\">\"vertical-flip\"</span><span class=\"p\">]</span>\n</pre>\n<h3>Child model</h3>\n<p><a href=\"https://github.com/barisozmen/deepaugment/blob/master/deepaugment/childcnn.py#L232-L269\" rel=\"nofollow\">source</a></p>\n<p>Child model is trained over and over from scratch during the optimization process. Its number of training depends on the number of iterations chosen by the user, which is expected to be around 100-300 for obtaining good results. Child model is therefore the computational bottleneck of the algorithm. With the current design, training time is ~30 seconds for 32x32 images on AWS instance p3.x2large using V100 GPU (112 TensorFLOPS). It has 1,250,858 trainable parameters for 32x32 images. Below is the diagram of child model:\n<img alt=\"child-cnn\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/fd492e398fc5acccba83622384d6bc07fa9c5a2b/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323534353237372d31306539383230302d326436622d313165392d393633392d3438623637313731316562612e706e67\" width=\"800\"></p>\n<h4>Other choices for child CNN model</h4>\n<p>Standard Child model is a basic CNN where its diagram and details given above. However, you are not limited with that model. You can use your own keras model by assigning it into config dictionary as:</p>\n<pre><span class=\"n\">my_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"model\"</span><span class=\"p\">:</span> <span class=\"n\">my_keras_model_object</span><span class=\"p\">}</span>\n<span class=\"n\">deepaug</span> <span class=\"o\">=</span> <span class=\"n\">DeepAugment</span><span class=\"p\">(</span><span class=\"n\">my_images</span><span class=\"p\">,</span> <span class=\"n\">my_labels</span><span class=\"p\">,</span> <span class=\"n\">my_config</span><span class=\"p\">)</span>\n</pre>\n<p>Or use an implemented small model, such as WideResNet-40-2 (while it is bigger than Basic CNN):</p>\n<pre><span class=\"n\">my_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"model\"</span><span class=\"p\">:</span> <span class=\"s2\">\"wrn_40_2\"</span><span class=\"p\">}</span> <span class=\"c1\"># depth(40) and wideness-factor(2) can be changed. e.g. wrn_20_4</span>\n</pre>\n<p>Or use a big model (not recommended unless you have massive computational resources):</p>\n<pre><span class=\"n\">my_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"model\"</span><span class=\"p\">:</span> <span class=\"s2\">\"InceptionV3\"</span><span class=\"p\">}</span>\n</pre>\n<pre><span class=\"n\">my_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s2\">\"model\"</span><span class=\"p\">:</span> <span class=\"s2\">\"MobileNetV2\"</span><span class=\"p\">}</span>\n</pre>\n<h3>Reward function</h3>\n<p><a href=\"https://github.com/barisozmen/deepaugment/blob/master/deepaugment/objective.py#L69-L89\" rel=\"nofollow\">source</a></p>\n<p>Reward function is calculated as mean of K highest validation accuracies of the child model which is not smaller than corresponding training accuracy by 0.05. K can be determined by the user by updating <code>opt_last_n_epochs</code> key in config as argument to <code>DeepAugment()</code> class (K is 3 by default).</p>\n<h2>Configuration options</h2>\n<p>DeepAugment can be given a config dictionary during initialization. It is expected to have following keys:</p>\n<ul>\n<li><strong>model</strong>: child model type. Options: \"basiccnn\", \"inceptionv3\", \"mobilenetv2\", \"wrn_&lt;DEPTH&gt;_&lt;WIDENING-FACTOR&gt;\", or keras.models.Model object</li>\n<li><strong>method:</strong> \"bayesian_optimization\" or \"random\" (for random search)</li>\n<li><strong>train_set_size:</strong> size of the training set during optimization. It should be small enough that computation will not take too long.</li>\n<li><strong>opt_samples:</strong> number of samples optimizer will run for each augmentation-policy. Training of the child model is stochastic and validation accuracy results might be slightly different from run to run. The tool trains child model three times by default and takes average, in order to have more robust accuracy results.</li>\n<li><strong>opt_last_n_epochs:</strong> number of non-overfitting epochs whose validation accuracy average will be used as reward. For each training, <code>opt_last_n_epochs</code> highest validation accuracies (where its difference to training accuracy is not more than 10%) are averaged and taken as reward.</li>\n<li><strong>opt_initial_points:</strong> number of random initial policies will be tried by Bayesian Optimizer. It will be the <code>n_initial_points</code> argument for skopt Optimizer (see its <a href=\"https://scikit-optimize.github.io/#skopt.Optimizer\" rel=\"nofollow\">documentation</a>)</li>\n<li><strong>child_epochs:</strong> number of epochs for the child model</li>\n<li><strong>child_first_train_epochs:</strong> if not 0, child model is pre-trained without any augmentation and its resulting weights are load for each training with augmentation. The purpose is training child model 10-20 epochs once and thereby saving 10-20 epochs for each training of optimizer iterations which is +100 times.</li>\n<li><strong>child_batch_size:</strong> batch size for the child model</li>\n<li><strong>per_aug_weights_path:</strong> path for pre-augmented training weights. Unneccessary if <code>child_first_train_epochs=0</code></li>\n<li><strong>logging:</strong> logging object for getting news about the optimization.</li>\n<li><strong>notebook_path:</strong> path for recording all trainings in all iterations. For each iteration, training history, trial-no, sample-no, calculated reward and mean recent validation accuracy is recorded. Records is updated at each trial for ensuring records are not lost in case optimization interrupted unintentionally. Records can be found at \"/reports/experiments/&lt;EXPERIMENT-NAME-AS-YEAR-MONTH-DAY-HOUR-MINUTE&gt;/notebook.csv\"</li>\n</ul>\n<p>Default configurations are as following:</p>\n<pre><span class=\"n\">DEFAULT_CONFIG</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">\"model\"</span><span class=\"p\">:</span> <span class=\"s2\">\"basiccnn\"</span><span class=\"p\">,</span> <span class=\"c1\"># </span>\n    <span class=\"s2\">\"method\"</span><span class=\"p\">:</span> <span class=\"s2\">\"bayesian_optimization\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"train_set_size\"</span><span class=\"p\">:</span> <span class=\"mi\">2000</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"opt_samples\"</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"opt_last_n_epochs\"</span><span class=\"p\">:</span> <span class=\"mi\">3</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"opt_initial_points\"</span><span class=\"p\">:</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"child_epochs\"</span><span class=\"p\">:</span> <span class=\"mi\">50</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"child_first_train_epochs\"</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"child_batch_size\"</span><span class=\"p\">:</span> <span class=\"mi\">64</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"pre_aug_weights_path\"</span><span class=\"p\">:</span> <span class=\"s2\">\"pre_aug_weights.h5\"</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"logging\"</span><span class=\"p\">:</span> <span class=\"n\">logging</span><span class=\"p\">,</span>\n    <span class=\"s2\">\"notebook_path\"</span><span class=\"p\">:</span> <span class=\"sa\">f</span><span class=\"s2\">\"</span><span class=\"si\">{</span><span class=\"n\">EXPERIMENT_FOLDER_PATH</span><span class=\"si\">}</span><span class=\"s2\">/notebook.csv\"</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</pre>\n<h2>Versioning rules</h2>\n<p>A three-number system is used, like <em>1.2.3</em>. Each increment of version is one of the following types:</p>\n<ul>\n<li>minor: if bugs are fixed, or documentation changed significantly. <em>1.2.3 -&gt; 1.2.4</em></li>\n<li>major: if a feature implemented differently, or a new feature added. <em>1.2.3 -&gt; 1.3.0</em></li>\n<li>disruptive: if a feature is removed or renamed. <em>1.2.3 -&gt; 2.0.0</em> (Backward compatibility is not guaranteed)</li>\n</ul>\n<p>Note: Versions from <em>0.0.0</em> to <em>1.0.0</em> are considered as <strong>alpha phase</strong> and do not follow this strategy.</p>\n<h2>Data pipeline</h2>\n<img alt=\"data-pipeline-2\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/abe074f12ea459e79b53646d9f97979b1e70a343/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323734303933382d30643333343638302d326638392d313165392d386436382d3131376431333964396162382e706e67\" width=\"600\">\n<img alt=\"data-pipeline-1\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9e83ce169aeebbd02f71aedbada568c39be33644/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323734303933372d30633961623030302d326638392d313165392d396539342d6265636137316361656434312e706e67\" width=\"600\">\n<h2>Class diagram</h2>\n<p>Created by <a href=\"https://www.logilab.org/blogentry/6883\" rel=\"nofollow\">pyreverse</a>\n<img alt=\"classes_deepaugment\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/4a96611b45ba4e951899e3b3bcd27ff1661ca0b7/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323734333632392d34393639613538302d326638662d313165392d386562322d3335616131616631363162622e706e67\"></p>\n<h2>Package diagram</h2>\n<p>Created by <a href=\"https://www.logilab.org/blogentry/6883\" rel=\"nofollow\">pyreverse</a>\n<img alt=\"package-diagram\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/88b2abc070a8d8eff2ad7ef655962aa7dd29129f/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31343939363135352f35323734333633302d34613032336330302d326638662d313165392d396231322d3332623264656436303731622e706e67\" width=\"600\"></p>\n<h2>References</h2>\n<p>[1] Cubuk et al., 2018. AutoAugment: Learning Augmentation Policies from Data\n(<a href=\"https://arxiv.org/abs/1805.09501\" rel=\"nofollow\">arxiv</a>)</p>\n<p>[2] Zoph et al., 2016. Neural Architecture Search with Reinforcement Learning\n(<a href=\"https://arxiv.org/abs/1611.01578\" rel=\"nofollow\">arxiv</a>)</p>\n<p>[3] Shahriari et al., 2016. A review of Bayesian Optimization\n(<a href=\"https://ieeexplore.ieee.org/document/7352306\" rel=\"nofollow\">ieee</a>)</p>\n<p>[4] Dewancker et al. Bayesian Optimization Primer (<a href=\"https://app.sigopt.com/static/pdf/SigOpt_Bayesian_Optimization_Primer.pdf\" rel=\"nofollow\">white-paper</a>)</p>\n<p>[5] DeVries, Taylor 2017. Improved Regularization of CNN's with Cutout\n(<a href=\"https://arxiv.org/abs/1708.04552\" rel=\"nofollow\">arxiv</a>)</p>\n<p>Blogs:</p>\n<ul>\n<li>A conceptual explanation of Bayesian Optimization (<a href=\"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\" rel=\"nofollow\">towardsdatascience</a>)</li>\n<li>Comparison experiment: Bayesian Opt. vs Grid Search vs Random Search (<a href=\"https://mlconf.com/lets-talk-bayesian-optimization/\" rel=\"nofollow\">mlconf</a>)</li>\n</ul>\n<p>Libraries:</p>\n<ul>\n<li><a href=\"scikit-optimize.github.io/\" rel=\"nofollow\">scikit-optimize</a></li>\n<li><a href=\"github.com/aleju/imgaug\" rel=\"nofollow\">mgaug</a></li>\n<li><a href=\"github.com/barisozmen/autoaugment-unofficial\" rel=\"nofollow\">AutoAugment-unofficial</a></li>\n<li><a href=\"\" rel=\"nofollow\">Automold</a> (Self-driving car image-augmentation library)</li>\n</ul>\n<hr>\n<h2>Contact</h2>\n<p>Baris Ozmen, <a href=\"mailto:hbaristr@gmail.com\">hbaristr@gmail.com</a></p>\n\n          </div>"}, "last_serial": 4907638, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "167a3e70009581b3d08159eb16482123", "sha256": "e4832587a7b26ab74bf820f85e2cf3df5967d2776d8703fde2dc6936c86268b5"}, "downloads": -1, "filename": "deepaugment-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "167a3e70009581b3d08159eb16482123", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 18095, "upload_time": "2019-02-08T08:49:52", "upload_time_iso_8601": "2019-02-08T08:49:52.007679Z", "url": "https://files.pythonhosted.org/packages/1a/94/7338e77a91422972fd81859e1844da3f71a2c96e4aa198a56a5418e72162/deepaugment-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "2d1d4137ed5430049a5f868c54a5b0fd", "sha256": "55e9966d70a27563703b4cf8fe2cec6b128a2a549e82eb07751a8a688ec91645"}, "downloads": -1, "filename": "deepaugment-0.1.0.tar.gz", "has_sig": false, "md5_digest": "2d1d4137ed5430049a5f868c54a5b0fd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16061, "upload_time": "2019-02-08T08:49:54", "upload_time_iso_8601": "2019-02-08T08:49:54.045901Z", "url": "https://files.pythonhosted.org/packages/a5/ef/b603f6150a0e74eadf4c8501be04c6d0c624013be3cd88fc2e6dc3efcb41/deepaugment-0.1.0.tar.gz", "yanked": false}], "0.10.0": [{"comment_text": "", "digests": {"md5": "466b0823e145aa00e0c9aebf734e3aaa", "sha256": "eef452436a7e4c5cf724bc87b845398fb82acdf5b2563d2ef8bc108e994cf677"}, "downloads": -1, "filename": "deepaugment-0.10.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "466b0823e145aa00e0c9aebf734e3aaa", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 28559, "upload_time": "2019-02-14T03:44:56", "upload_time_iso_8601": "2019-02-14T03:44:56.871204Z", "url": "https://files.pythonhosted.org/packages/2a/a3/296d713f32a4d2e162a1cfb5a6de771324f6640995a3c40c33287c8e7ab1/deepaugment-0.10.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9e1550c5f8285236b4c9725c4cef40b4", "sha256": "3adcdfe268e7b3931e8b65484dfe834ec0d2c1c6ea37f411d68f365038cd9a64"}, "downloads": -1, "filename": "deepaugment-0.10.0.tar.gz", "has_sig": false, "md5_digest": "9e1550c5f8285236b4c9725c4cef40b4", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24319, "upload_time": "2019-02-14T03:44:58", "upload_time_iso_8601": "2019-02-14T03:44:58.509667Z", "url": "https://files.pythonhosted.org/packages/ad/7b/8d625715712a34d43e74c7faa47012675a8aa8934b124205301fb3e6adf8/deepaugment-0.10.0.tar.gz", "yanked": false}], "0.11.0": [{"comment_text": "", "digests": {"md5": "ac47255da16d2a47dc5dc0e4971b0929", "sha256": "b017fd62335ba8b01670892c827bb0c088bff994ae368bb45c7e507734cd7d6c"}, "downloads": -1, "filename": "deepaugment-0.11.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ac47255da16d2a47dc5dc0e4971b0929", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 28559, "upload_time": "2019-02-14T03:46:35", "upload_time_iso_8601": "2019-02-14T03:46:35.966199Z", "url": "https://files.pythonhosted.org/packages/a6/85/0fa3126ba3e994e5875e2e52e30f4ab883233da593207dd7dbbc3b58781f/deepaugment-0.11.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9a98eb74cf290af1284d75e901f72844", "sha256": "3ffcb350645acf7d529115acedadf0f7250b8fbfeac50e8b21f22d21432685f2"}, "downloads": -1, "filename": "deepaugment-0.11.0.tar.gz", "has_sig": false, "md5_digest": "9a98eb74cf290af1284d75e901f72844", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24326, "upload_time": "2019-02-14T03:46:37", "upload_time_iso_8601": "2019-02-14T03:46:37.463750Z", "url": "https://files.pythonhosted.org/packages/36/3e/a1e873a28a740c7ad23bd46d56da8d1fdffd3bfcf6ed0064c44a507533a9/deepaugment-0.11.0.tar.gz", "yanked": false}], "0.12.0": [{"comment_text": "", "digests": {"md5": "450289fb4b790292962091b448d8a952", "sha256": "f47c6110ad9e4c6f425bf9c024472808394e5b763ff68d9ebdd8eb23e000053a"}, "downloads": -1, "filename": "deepaugment-0.12.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "450289fb4b790292962091b448d8a952", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 28557, "upload_time": "2019-02-14T03:49:43", "upload_time_iso_8601": "2019-02-14T03:49:43.583864Z", "url": "https://files.pythonhosted.org/packages/8e/6a/ad4a3ba8a6f249de3648d0954ffc6da0e850c28f432c563432177130802a/deepaugment-0.12.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "de66582c5b05d6fc6f5b521685542f2e", "sha256": "d5328170781f3251bdf68d31f9bd06102627d52b9d25a532bd3646623e34509a"}, "downloads": -1, "filename": "deepaugment-0.12.0.tar.gz", "has_sig": false, "md5_digest": "de66582c5b05d6fc6f5b521685542f2e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24309, "upload_time": "2019-02-14T03:49:45", "upload_time_iso_8601": "2019-02-14T03:49:45.052057Z", "url": "https://files.pythonhosted.org/packages/d5/a3/4c5da6b0064193f140014307397f3aabfd469478a737e8de0852f13d5510/deepaugment-0.12.0.tar.gz", "yanked": false}], "0.12.1": [{"comment_text": "", "digests": {"md5": "2f6f2afd45c676d8f5848f5f88335546", "sha256": "636bcd69ac8231e1bb097ffc6f38127ff44127606a17c51caa5ea9b66507e133"}, "downloads": -1, "filename": "deepaugment-0.12.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "2f6f2afd45c676d8f5848f5f88335546", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 29082, "upload_time": "2019-02-18T03:36:44", "upload_time_iso_8601": "2019-02-18T03:36:44.414425Z", "url": "https://files.pythonhosted.org/packages/86/de/dea5d73d0c67c7e0f653ceb149ef1e937db1c6f73597bd00e3c09d095a07/deepaugment-0.12.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3e33bad01657518a290e6a2dbd42e314", "sha256": "f8f47aa774570536fd028d1bb6df403af3f81ef63dfb7549b88fecb2fbef8713"}, "downloads": -1, "filename": "deepaugment-0.12.1.tar.gz", "has_sig": false, "md5_digest": "3e33bad01657518a290e6a2dbd42e314", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24824, "upload_time": "2019-02-18T03:36:46", "upload_time_iso_8601": "2019-02-18T03:36:46.316368Z", "url": "https://files.pythonhosted.org/packages/a0/c3/630dab9b6f5d43918d49103417eaa414261073d3dd77ac4ab6469eaa1b17/deepaugment-0.12.1.tar.gz", "yanked": false}], "0.12.2": [{"comment_text": "", "digests": {"md5": "9ff9041d3f464de467d0162a6cbbd91c", "sha256": "c5889f5d3ee93d8655a1f79dede8b158b7e25e39aa5cb8c56af12f46ab987c2a"}, "downloads": -1, "filename": "deepaugment-0.12.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9ff9041d3f464de467d0162a6cbbd91c", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 29091, "upload_time": "2019-02-20T00:24:25", "upload_time_iso_8601": "2019-02-20T00:24:25.878530Z", "url": "https://files.pythonhosted.org/packages/cd/c9/cd2ef76b24c368cf0de7b87a6a03c78164fb527bb2276dcb20d93d08d472/deepaugment-0.12.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a5f5dbbebc0235661d154e0883e4e0e9", "sha256": "92a9b79520b48615699dfbb7fdc6d1b865dba26907cdf1b571751de2436ed925"}, "downloads": -1, "filename": "deepaugment-0.12.2.tar.gz", "has_sig": false, "md5_digest": "a5f5dbbebc0235661d154e0883e4e0e9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24784, "upload_time": "2019-02-20T00:24:27", "upload_time_iso_8601": "2019-02-20T00:24:27.612136Z", "url": "https://files.pythonhosted.org/packages/c8/31/e35c6dded0de97fa99c7fe0c076714cded310916bec0a1ec516578ccee2f/deepaugment-0.12.2.tar.gz", "yanked": false}], "0.12.3": [{"comment_text": "", "digests": {"md5": "1275ea038f948d0cf20ae0990402d219", "sha256": "286ab6373c5cebc60057ab8bca1d7f8f0fe4e71039a68e149aa1574315949695"}, "downloads": -1, "filename": "deepaugment-0.12.3-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "1275ea038f948d0cf20ae0990402d219", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 29116, "upload_time": "2019-02-20T00:56:37", "upload_time_iso_8601": "2019-02-20T00:56:37.799949Z", "url": "https://files.pythonhosted.org/packages/6e/9a/37d2499f5f29a3ce6b11c6b30ba6c951d952888f4aa1f7fbb7e902c1a355/deepaugment-0.12.3-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "005ff202ea20ac58f1316cb45167b76f", "sha256": "0516e7dd144287cd024fcbfc04813e330d75b0f0a13e721e821fbc96aa585900"}, "downloads": -1, "filename": "deepaugment-0.12.3.tar.gz", "has_sig": false, "md5_digest": "005ff202ea20ac58f1316cb45167b76f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24844, "upload_time": "2019-02-20T00:56:40", "upload_time_iso_8601": "2019-02-20T00:56:40.251947Z", "url": "https://files.pythonhosted.org/packages/41/f3/ac7b1c8cdbce4eabe37b902dd8f69a969c1144303dca076d837e5769c26d/deepaugment-0.12.3.tar.gz", "yanked": false}], "0.12.4": [{"comment_text": "", "digests": {"md5": "ba666e8f1ce8ec1d267afaafd13333c4", "sha256": "01b92425ef2aa73d0de236f8bd8e1df71f11e490d7e9b4a5ffdf7f4ea65c8337"}, "downloads": -1, "filename": "deepaugment-0.12.4-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "ba666e8f1ce8ec1d267afaafd13333c4", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 29678, "upload_time": "2019-02-23T23:26:40", "upload_time_iso_8601": "2019-02-23T23:26:40.955151Z", "url": "https://files.pythonhosted.org/packages/1e/58/144a4467a56e71f2edacc8491ef044c7b31ed40de79e4b5b4544228acf4c/deepaugment-0.12.4-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "70d30cb0a6527c74da018de05789b983", "sha256": "8dc2287461c753d86a79acb14de7cbe467b3a8567346e53e1d99344dd8748db2"}, "downloads": -1, "filename": "deepaugment-0.12.4.tar.gz", "has_sig": false, "md5_digest": "70d30cb0a6527c74da018de05789b983", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 26036, "upload_time": "2019-02-23T23:26:42", "upload_time_iso_8601": "2019-02-23T23:26:42.686343Z", "url": "https://files.pythonhosted.org/packages/32/6c/229513b5335bf398f5f0fde075631a1dddf961216d21c8ae7ae0124d57fc/deepaugment-0.12.4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "f57ff9916ac462c18dfe09553418e92e", "sha256": "764fff954bf6fb59e16833640ff77db2867a13fb0e549622a41f2aaad0018374"}, "downloads": -1, "filename": "deepaugment-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f57ff9916ac462c18dfe09553418e92e", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22546, "upload_time": "2019-02-11T09:44:44", "upload_time_iso_8601": "2019-02-11T09:44:44.865936Z", "url": "https://files.pythonhosted.org/packages/8e/d0/158bac81711ce7c447f59447d69f80e9ddb12acddd38252916dbba1931d4/deepaugment-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "fbbd300c323ffa1f1216a31bb1801be1", "sha256": "723ebd9e61ed510c2c236a9376ec6aa91a965ba414d0fc6f5a143bebfd1ea291"}, "downloads": -1, "filename": "deepaugment-0.2.0.tar.gz", "has_sig": false, "md5_digest": "fbbd300c323ffa1f1216a31bb1801be1", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20300, "upload_time": "2019-02-11T09:39:10", "upload_time_iso_8601": "2019-02-11T09:39:10.417428Z", "url": "https://files.pythonhosted.org/packages/fd/79/681054d9c3bc7eb9a8c7466e5e772a978a49ccc974059c278e78b1a760b8/deepaugment-0.2.0.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "d51a9227a94be6ef3aca637c6818daa1", "sha256": "b9b6178313f9fa428ede51e58bd9b6dbaf2f11537cea341c80259054610fd6cd"}, "downloads": -1, "filename": "deepaugment-0.3.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "d51a9227a94be6ef3aca637c6818daa1", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22479, "upload_time": "2019-02-11T10:33:34", "upload_time_iso_8601": "2019-02-11T10:33:34.185647Z", "url": "https://files.pythonhosted.org/packages/6e/f3/96eb0d2f32df6ea8908d37662ad2818b7bfb7193238a950dff8d7597b968/deepaugment-0.3.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ab79f66bb7477542d5701baafc7f4b4d", "sha256": "c52767348627ad1a75aea5a89747ba67dfa1bedbc9c42c0ca87fa97688fe1a0a"}, "downloads": -1, "filename": "deepaugment-0.3.0.tar.gz", "has_sig": false, "md5_digest": "ab79f66bb7477542d5701baafc7f4b4d", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20169, "upload_time": "2019-02-11T10:33:39", "upload_time_iso_8601": "2019-02-11T10:33:39.816801Z", "url": "https://files.pythonhosted.org/packages/2e/6a/13be05afae7265c9fd3a23837c39f0d97973bdc640ceac835a5302f78631/deepaugment-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "f53cde0b5138a3e1e54360eed9966b26", "sha256": "78ab2918c490405519d4444e3f66949ac3c28f75dba9688199aed2504c693cd3"}, "downloads": -1, "filename": "deepaugment-0.4.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "f53cde0b5138a3e1e54360eed9966b26", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22476, "upload_time": "2019-02-11T10:50:29", "upload_time_iso_8601": "2019-02-11T10:50:29.853378Z", "url": "https://files.pythonhosted.org/packages/9b/ae/75dc7c8db37d2c39deb37dc497a467d1a116ed4b5adfc9acf0ce81b6867a/deepaugment-0.4.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e08c931fb909b8d69f283a980cbe8f52", "sha256": "3cde5e3ffc34521ed6d6aa6532e4b3c7ddbcbd1ce893621becee5c6187dc98e4"}, "downloads": -1, "filename": "deepaugment-0.4.0.tar.gz", "has_sig": false, "md5_digest": "e08c931fb909b8d69f283a980cbe8f52", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20026, "upload_time": "2019-02-11T10:50:31", "upload_time_iso_8601": "2019-02-11T10:50:31.667046Z", "url": "https://files.pythonhosted.org/packages/4c/a4/45ad64ce98b67e5b41d1648a4d9bc1f8f62d7a657b48e573dae305f6d85b/deepaugment-0.4.0.tar.gz", "yanked": false}], "0.5.0": [{"comment_text": "", "digests": {"md5": "6ade93902730e94dd44c829011a14453", "sha256": "7ae2f6877008ebc776aa9f65383737d38a031a116e0699af8ff513f78407a126"}, "downloads": -1, "filename": "deepaugment-0.5.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "6ade93902730e94dd44c829011a14453", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 22704, "upload_time": "2019-02-11T18:57:17", "upload_time_iso_8601": "2019-02-11T18:57:17.152793Z", "url": "https://files.pythonhosted.org/packages/db/d2/a17baa1a2a3b820c60fe28f4235ac0d39a1d80ce4b232102749da472afc0/deepaugment-0.5.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d734ed829d8fd4bdd1d319cdca918650", "sha256": "5ebbf79d63f1c7253ac97aa70561e8832a9a1cb8e0211a0fb135ac32af3e9afa"}, "downloads": -1, "filename": "deepaugment-0.5.0.tar.gz", "has_sig": false, "md5_digest": "d734ed829d8fd4bdd1d319cdca918650", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20185, "upload_time": "2019-02-11T18:57:18", "upload_time_iso_8601": "2019-02-11T18:57:18.696253Z", "url": "https://files.pythonhosted.org/packages/d8/8b/c1950d1b4362f303ffb30c87035bc5cebd49f1fceb4622b322e76446132b/deepaugment-0.5.0.tar.gz", "yanked": false}], "0.6.0": [{"comment_text": "", "digests": {"md5": "fbf445a828f11b9e4d5281a3ba8438f0", "sha256": "75a1acfa3ff058c6f72d9aec0d0db085384547cb665fbb06f48de560988466e2"}, "downloads": -1, "filename": "deepaugment-0.6.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "fbf445a828f11b9e4d5281a3ba8438f0", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 32055, "upload_time": "2019-02-11T19:13:19", "upload_time_iso_8601": "2019-02-11T19:13:19.724001Z", "url": "https://files.pythonhosted.org/packages/0c/5f/613e562ac2061fbc8de37d83bdaa0e37ac6a8e372574f27bb060d69fa8eb/deepaugment-0.6.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b0309cd3ca941735d2cef2b8d60adced", "sha256": "9077642442164af1ab13f266a039b45a151e55286f58d31da9556f082f6cd031"}, "downloads": -1, "filename": "deepaugment-0.6.0.tar.gz", "has_sig": false, "md5_digest": "b0309cd3ca941735d2cef2b8d60adced", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28105, "upload_time": "2019-02-11T19:13:20", "upload_time_iso_8601": "2019-02-11T19:13:20.954802Z", "url": "https://files.pythonhosted.org/packages/ec/0c/35e69a74e5ef95d17f97e8c02f3f223ff2430d472dbb4707f0555eb5855e/deepaugment-0.6.0.tar.gz", "yanked": false}], "0.7.0": [{"comment_text": "", "digests": {"md5": "7a7b3af4dca04d8345c451236b36d51b", "sha256": "571bd1f32f8989d59dc2ea8a1b1d6d47ecbdb4b8069d2b9729c27845e821a2f0"}, "downloads": -1, "filename": "deepaugment-0.7.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7a7b3af4dca04d8345c451236b36d51b", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 32541, "upload_time": "2019-02-12T01:28:23", "upload_time_iso_8601": "2019-02-12T01:28:23.310358Z", "url": "https://files.pythonhosted.org/packages/da/f3/012cf390209973bb14f22edf1cec9d783f42224a5050a4f2fb8950969422/deepaugment-0.7.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "36c77c28ce9762a6eebb4ada9a666354", "sha256": "37c1e7bca3b130a895f0a232a99796c78ef51c583be034ae336f8e72500a7ae0"}, "downloads": -1, "filename": "deepaugment-0.7.0.tar.gz", "has_sig": false, "md5_digest": "36c77c28ce9762a6eebb4ada9a666354", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 28885, "upload_time": "2019-02-12T01:28:24", "upload_time_iso_8601": "2019-02-12T01:28:24.989671Z", "url": "https://files.pythonhosted.org/packages/e7/09/1eeca7b5089b522b997f986321db84fee42dc04ab5aaf28b2586ba119274/deepaugment-0.7.0.tar.gz", "yanked": false}], "0.8.0": [{"comment_text": "", "digests": {"md5": "c1362cb28a154f93bd7a4f000a88f329", "sha256": "528722520669c53ec9ebab6e707243706f4780c7453ba882ac9aa649f4c7f270"}, "downloads": -1, "filename": "deepaugment-0.8.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "c1362cb28a154f93bd7a4f000a88f329", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 28546, "upload_time": "2019-02-14T03:36:32", "upload_time_iso_8601": "2019-02-14T03:36:32.001059Z", "url": "https://files.pythonhosted.org/packages/2a/7c/0eff29ef864fb70197f56a06153ee8cc701a134f0a2b2a9fbc2ade491296/deepaugment-0.8.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ab9297c39ae0bad2e9365ac4bee59d21", "sha256": "a4805a72076ccca65e77f4a924c2356006e253163d1ae5bac72c601fb27eb552"}, "downloads": -1, "filename": "deepaugment-0.8.0.tar.gz", "has_sig": false, "md5_digest": "ab9297c39ae0bad2e9365ac4bee59d21", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24316, "upload_time": "2019-02-14T03:36:33", "upload_time_iso_8601": "2019-02-14T03:36:33.720093Z", "url": "https://files.pythonhosted.org/packages/79/8a/edcb79761efddf3759145c36c363543b43981372e47d066d23bb8f4153c7/deepaugment-0.8.0.tar.gz", "yanked": false}], "0.9.0": [{"comment_text": "", "digests": {"md5": "8af0d58f4309483ea206fd3f8d81cceb", "sha256": "8bce78dd41fde1ad5978a2190b4232e157ff59db2ab00574a824cb9fe51a97f5"}, "downloads": -1, "filename": "deepaugment-0.9.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "8af0d58f4309483ea206fd3f8d81cceb", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 28547, "upload_time": "2019-02-14T03:42:00", "upload_time_iso_8601": "2019-02-14T03:42:00.985646Z", "url": "https://files.pythonhosted.org/packages/69/67/45c3401aca6c73d8237d6a4b0a0e27814886dc1379494c3b4cdbfb2e81a1/deepaugment-0.9.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e7dfa1c7716195a735fc945ef60a84df", "sha256": "221f80ec257d6f4ddd780ff2b9b6d2e6b0bd05a603afbe14c45df02094bc9d62"}, "downloads": -1, "filename": "deepaugment-0.9.0.tar.gz", "has_sig": false, "md5_digest": "e7dfa1c7716195a735fc945ef60a84df", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24323, "upload_time": "2019-02-14T03:42:03", "upload_time_iso_8601": "2019-02-14T03:42:03.059821Z", "url": "https://files.pythonhosted.org/packages/01/4d/4c35248ba064737ace754a4872e918501364e4cc63638fccb91be78b87d8/deepaugment-0.9.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "286f8fd7da516020896721dc84d35e4a", "sha256": "220640cd2ee146971adc23439f590756a1b026da786066adc653d80c8d72a559"}, "downloads": -1, "filename": "deepaugment-1.0.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "286f8fd7da516020896721dc84d35e4a", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 32758, "upload_time": "2019-03-04T05:52:43", "upload_time_iso_8601": "2019-03-04T05:52:43.177592Z", "url": "https://files.pythonhosted.org/packages/90/91/3d60beb3f5e5118449dba5bd0e95f133f5a170c0bba530cdfd63c064e6cd/deepaugment-1.0.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "44241b7e48627bac4a6384c2d67c665e", "sha256": "0037beb98f3da7f87d00d98b65097da082a7eecd4174cf85fdd97fb472e51b58"}, "downloads": -1, "filename": "deepaugment-1.0.0.tar.gz", "has_sig": false, "md5_digest": "44241b7e48627bac4a6384c2d67c665e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32325, "upload_time": "2019-03-04T05:52:44", "upload_time_iso_8601": "2019-03-04T05:52:44.486977Z", "url": "https://files.pythonhosted.org/packages/b8/bc/604758d46e2c993d89788a4a09ca2de51504ee123f3f8474aba2629bb601/deepaugment-1.0.0.tar.gz", "yanked": false}], "1.1.0": [{"comment_text": "", "digests": {"md5": "7f16b577f289c57082a8810300e6c832", "sha256": "299afb805e3e6f67e4376cc03779f6e143db636a0e5a8b184fa9552e27cf0fc7"}, "downloads": -1, "filename": "deepaugment-1.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "7f16b577f289c57082a8810300e6c832", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33213, "upload_time": "2019-03-04T05:57:35", "upload_time_iso_8601": "2019-03-04T05:57:35.662386Z", "url": "https://files.pythonhosted.org/packages/1a/e3/57e88c9fcb700d7ac8aeea3464f4f48ea67318ef09db4e537b28da4f97ed/deepaugment-1.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "609029156183e47a334975552292e9cd", "sha256": "d6553a10cd48e8b180d7dfbaf684a791ca6990300603b6ee17d190361ec4c103"}, "downloads": -1, "filename": "deepaugment-1.1.0.tar.gz", "has_sig": false, "md5_digest": "609029156183e47a334975552292e9cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 32770, "upload_time": "2019-03-04T05:57:37", "upload_time_iso_8601": "2019-03-04T05:57:37.151823Z", "url": "https://files.pythonhosted.org/packages/a6/6c/dc58cc3f10d9e1a510792082568bd8249c354d0223002e01be5438dbcc16/deepaugment-1.1.0.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "cb4f401c2e592cbfc82c49378a4342d5", "sha256": "cbf33158799f211ad75b59d195a437c1a619b9536fbff045ad2e598534c499dc"}, "downloads": -1, "filename": "deepaugment-1.1.1-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "cb4f401c2e592cbfc82c49378a4342d5", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33807, "upload_time": "2019-03-05T21:28:46", "upload_time_iso_8601": "2019-03-05T21:28:46.202099Z", "url": "https://files.pythonhosted.org/packages/cf/f8/908640ca57180743a3693a5f0c88117067a560e574027e571955c1013652/deepaugment-1.1.1-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "74ee4325d3c772e4af96390dde3afa73", "sha256": "de5f38513129b5eea02b829079c0898eeb152fae3f7e9f46a9ff6caa4519fe48"}, "downloads": -1, "filename": "deepaugment-1.1.1.tar.gz", "has_sig": false, "md5_digest": "74ee4325d3c772e4af96390dde3afa73", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33535, "upload_time": "2019-03-05T21:28:48", "upload_time_iso_8601": "2019-03-05T21:28:48.316748Z", "url": "https://files.pythonhosted.org/packages/eb/f7/a09fb17e507b3c22ab4782618279e6846cda713107929c7be2fff610f202/deepaugment-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "e930e56f97dc60c31e7ac18448cdded9", "sha256": "5453ce2e4f6b559acd2d932c22a87313674c968e6eba6a497030b66bd6ff9805"}, "downloads": -1, "filename": "deepaugment-1.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e930e56f97dc60c31e7ac18448cdded9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33777, "upload_time": "2019-03-06T23:51:27", "upload_time_iso_8601": "2019-03-06T23:51:27.618053Z", "url": "https://files.pythonhosted.org/packages/99/f9/40211d827039df475091639c6aded9a1786849f898b9c619e24c15efc82a/deepaugment-1.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a716e4f10643c78c7d9339d8faa5210e", "sha256": "7b9eeb7d063c4f04594ca25a4457c1944c10cdca7376b1c12e024be299650603"}, "downloads": -1, "filename": "deepaugment-1.1.2.tar.gz", "has_sig": false, "md5_digest": "a716e4f10643c78c7d9339d8faa5210e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33528, "upload_time": "2019-03-06T23:51:28", "upload_time_iso_8601": "2019-03-06T23:51:28.842529Z", "url": "https://files.pythonhosted.org/packages/09/ac/991b27a857152fc0a3dfa7bec6ae4af7a54cf27769bd13e9b995ea0f62d2/deepaugment-1.1.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e930e56f97dc60c31e7ac18448cdded9", "sha256": "5453ce2e4f6b559acd2d932c22a87313674c968e6eba6a497030b66bd6ff9805"}, "downloads": -1, "filename": "deepaugment-1.1.2-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "e930e56f97dc60c31e7ac18448cdded9", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 33777, "upload_time": "2019-03-06T23:51:27", "upload_time_iso_8601": "2019-03-06T23:51:27.618053Z", "url": "https://files.pythonhosted.org/packages/99/f9/40211d827039df475091639c6aded9a1786849f898b9c619e24c15efc82a/deepaugment-1.1.2-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "a716e4f10643c78c7d9339d8faa5210e", "sha256": "7b9eeb7d063c4f04594ca25a4457c1944c10cdca7376b1c12e024be299650603"}, "downloads": -1, "filename": "deepaugment-1.1.2.tar.gz", "has_sig": false, "md5_digest": "a716e4f10643c78c7d9339d8faa5210e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 33528, "upload_time": "2019-03-06T23:51:28", "upload_time_iso_8601": "2019-03-06T23:51:28.842529Z", "url": "https://files.pythonhosted.org/packages/09/ac/991b27a857152fc0a3dfa7bec6ae4af7a54cf27769bd13e9b995ea0f62d2/deepaugment-1.1.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:39:30 2020"}