{"info": {"author": "X.Yang", "author_email": "pistonyang@gmail.com", "bugtrack_url": null, "classifiers": ["Programming Language :: Python :: 3"], "description": "# Pytorch-Toolbox\n![](https://github.com/PistonY/torch-toolbox/workflows/Torch-Toolbox-CI/badge.svg)\n\nStable Version: v0.1.4(recommend to use.)\n\nAutomatic upload to PyPI has been finished.\n\nThis is toolbox project for Pytorch. Aiming to make you write Pytorch code more easier, readable and concise.\n\nYou could also regard this as a auxiliary tool for Pytorch. It will contain what you use most frequently tools.\n\n\n## Installing\nA easy way to install this is by using pip:\n```shell\npip install torchtoolbox\n```\nIf you want to install the nightly version:\n```shell\npip install -U git+https://github.com/PistonY/torch-toolbox.git@master\n```\n## Todo\n- [x] cv2 transforms.\n- [ ] Prepare tensorboard support with metric collection.\n\n## Usage\nToolbox have two mainly parts:\n1. Additional tools to make you use Pytorch easier.\n2. Some fashion work which don't exist in Pytorch core.\n\n### Tools\n#### 0. Now CV2 transforms have been released.\nSupport as list:(need test)\n```python\n__all__ = [\"Compose\", \"ToTensor\", \"ToCVImage\", \"Normalize\", \"Resize\", \"Scale\", \"CenterCrop\", \"Pad\",\n           \"Lambda\", \"RandomApply\", \"RandomChoice\", \"RandomOrder\", \"RandomCrop\", \"RandomHorizontalFlip\",\n           \"RandomVerticalFlip\", \"RandomResizedCrop\", \"RandomSizedCrop\", \"FiveCrop\", \"TenCrop\", \"LinearTransformation\",\n           \"ColorJitter\", \"RandomRotation\", \"RandomAffine\", \"Grayscale\", \"RandomGrayscale\",\n           \"RandomPerspective\", \"RandomErasing\", \"RandomGaussianNoise\", \"RandomPoissonNoise\", \"RandomSPNoise\",\n           \"RandomTransforms\", \"Cutout\"]\n```\nPart of this code refers to [opencv_transforms_torchvision](https://github.com/YU-Zhiyang/opencv_transforms_torchvision)\n- [albumentations](https://github.com/albumentations-team/albumentations) is also recommend to use which is cv2 backend transform tools.\n\n#### 1. Show your model parameters and FLOPs.\n```python\nimport torch\nfrom torchtoolbox.tools import summary\nfrom torchvision.models.mobilenet import mobilenet_v2\nmodel = mobilenet_v2()\nsummary(model, torch.rand((1, 3, 224, 224)))\n``` \nHere are some short outputs.\n```\n        Layer (type)               Output Shape          Params    FLOPs(M+A) #\n================================================================================\n            Conv2d-1          [1, 64, 112, 112]            9408       235225088\n       BatchNorm2d-2          [1, 64, 112, 112]             256         1605632\n              ReLU-3          [1, 64, 112, 112]               0               0\n         MaxPool2d-4            [1, 64, 56, 56]               0               0\n          ...                      ...                      ...              ...\n          Linear-158                  [1, 1000]         1281000         2560000\n     MobileNetV2-159                  [1, 1000]               0               0\n================================================================================\n        Total parameters: 3,538,984  3.5M\n    Trainable parameters: 3,504,872\nNon-trainable parameters: 34,112\nTotal flops(M)  : 305,252,872  305.3M\nTotal flops(M+A): 610,505,744  610.5M\n--------------------------------------------------------------------------------\nParameters size (MB): 13.50\n```\n\n#### 2. Metric collection\nWhen we train a model we usually need to calculate some metrics like accuracy(top1-acc), loss etc.\nNow toolbox support as below:\n1. Accuracy: top-1 acc.\n2. TopKAccuracy: topK-acc.\n3. NumericalCost: This is a number metric collection which support `mean`, `max`, `min` calculate type.\n4. FeatureVerification.\n    - This is widely used in margin based algorithm.\n\n```python\n```python\nfrom torchtoolbox import metric\n\n# define first\ntop1_acc = metric.Accuracy(name='Top1 Accuracy')\ntop5_acc = metric.TopKAccuracy(top=5, name='Top5 Accuracy')\nloss_record = metric.NumericalCost(name='Loss')\n\n# reset before using\ntop1_acc.reset()\ntop5_acc.reset()\nloss_record.reset()\n\n...\nmodel.eval()\nfor data, labels in val_data:\n    data = data.to(device, non_blocking=True)\n    labels = labels.to(device, non_blocking=True)\n\n    outputs = model(data)\n    losses = Loss(outputs, labels)\n    # update/record\n    top1_acc.update(outputs, labels)\n    top5_acc.update(outputs, labels)\n    loss_record.update(losses)\n    test_msg = 'Test Epoch {}: {}:{:.5}, {}:{:.5}, {}:{:.5}\\n'.format(\n    epoch, top1_acc.name, top1_acc.get(), top5_acc.name, top5_acc.get(),\n    loss_record.name, loss_record.get())\n\nprint(test_msg)\n``` \nThen you may get outputs like this\n```\nTest Epoch 101: Top1 Accuracy:0.7332, Top5 Accuracy:0.91514, Loss:1.0605\n```\n\n#### 3. Model Initializer\nNow ToolBox support `XavierInitializer` and `KaimingInitializer`.\n```python\nfrom torchtoolbox.nn.init import KaimingInitializer\n\nmodel = XXX\ninitializer = KaimingInitializer()\nmodel.apply(initializer)\n\n```\n#### 4. AdaptiveSequential\nMake Pytorch `nn.Sequential` could handle multi input/output layer.\n```python\nfrom torch import nn\nfrom torchtoolbox.nn import AdaptiveSequential\nimport torch\n\n\nclass n_to_n(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 3, 1, 1, bias=False)\n        self.conv2 = nn.Conv2d(3, 3, 1, 1, bias=False)\n\n    def forward(self, x1, x2):\n        y1 = self.conv1(x1)\n        y2 = self.conv2(x2)\n        return y1, y2\n\n\nclass n_to_one(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 3, 1, 1, bias=False)\n        self.conv2 = nn.Conv2d(3, 3, 1, 1, bias=False)\n\n    def forward(self, x1, x2):\n        y1 = self.conv1(x1)\n        y2 = self.conv2(x2)\n        return y1 + y2\n\n\nclass one_to_n(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 3, 1, 1, bias=False)\n        self.conv2 = nn.Conv2d(3, 3, 1, 1, bias=False)\n\n    def forward(self, x):\n        y1 = self.conv1(x)\n        y2 = self.conv2(x)\n        return y1, y2\n\nseq = AdaptiveSequential(one_to_n(), n_to_n(), n_to_one()).cuda()\ntd = torch.rand(1, 3, 32, 32).cuda()\n\nout = seq(td)\nprint(out.size())\n\n# output\n# torch.Size([1, 3, 32, 32])\n```\n#### 5. Make and Use LMDB dataset.\nIf you meet IO speed limit, you may think about [LMDB](https://lmdb.readthedocs.io/en/release/) format dataset.\nLMDB is a tiny database with some excellent properties.\n\nEasy to generate a LMDB format dataset.\n```python\nfrom torchtoolbox.tools.convert_lmdb import generate_lmdb_dataset, raw_reader\nfrom torchvision.datasets import ImageFolder\n\ndt = ImageFolder(..., loader=raw_reader)\nsave_dir = XXX \ndataset_name = YYY\ngenerate_lmdb_dataset(dt, save_dir=save_dir, name=dataset_name)\n\n```\n\nThen if you use `ImageFolder` like dataset you can easily use `ImageLMDB` to load you dataset.\n```python\nfrom torchtoolbox.data import ImageLMDB\n\ndt = ImageLMDB(db_path=save_dir, db_name=dataset_name, ...)\n```\n\n#### 6. Non-Lable dataset\nThis dataset only return images.\n\nMore details please refers to [codes](https://github.com/PistonY/torch-toolbox/blob/4838af996b972cd666fadb9fb6bd6dab2103ccad/torchtoolbox/data/datasets.py#L13)\n\n### Fashion work\n#### 1. LabelSmoothingLoss\n\n```python\nfrom torchtoolbox.nn import LabelSmoothingLoss\n# The num classes of your task should be defined.\nclasses = 10\n# Loss\nLoss = LabelSmoothingLoss(classes, smoothing=0.1)\n\n...\nfor i, (data, labels) in enumerate(train_data):\n    data = data.to(device, non_blocking=True)\n    labels = labels.to(device, non_blocking=True)\n\n    optimizer.zero_grad()\n    outputs = model(data)\n    # just use as usual.\n    loss = Loss(outputs, labels)\n    loss.backward()\n    optimizer.step()\n```\n\n#### 2. CosineWarmupLr\nCosine lr scheduler with warm-up epochs.It's helpful to improve acc for classification models.\n```python\nfrom torchtoolbox.optimizer import CosineWarmupLr\n\noptimizer = optim.SGD(...)\n# define scheduler\n# `batches_pre_epoch` means how many batches(times update/step the model) within one epoch.\n# `warmup_epochs` means increase lr how many epochs to `base_lr`.\n# you can find more details in file.\nlr_scheduler = CosineWarmupLr(optimizer, batches_pre_epoch, epochs,\n                              base_lr=lr, warmup_epochs=warmup_epochs)\n...\nfor i, (data, labels) in enumerate(train_data):\n    ...\n    optimizer.step()\n    # remember to step/update status here.\n    lr_scheduler.step()\n    ...\n```\n\n#### 3. SwitchNorm2d/3d\n```python\nfrom torchtoolbox.nn import SwitchNorm2d, SwitchNorm3d\n```\nJust use it like Batchnorm2d/3d.\nMore details please refer to origin paper \n[Differentiable Learning-to-Normalize via Switchable Normalization](https://arxiv.org/pdf/1806.10779.pdf) \n[OpenSourse](https://github.com/switchablenorms/Switchable-Normalization)\n\n\n#### 4. Swish activation\n```python\nfrom torchtoolbox.nn import Swish\n```\nJust use it like Relu.\nMore details please refer to origin paper \n[SEARCHING FOR ACTIVATION FUNCTIONS](https://arxiv.org/pdf/1710.05941.pdf)\n\n#### 5. Lookahead optimizer\nA wrapper optimizer seems better than Adam. \n[Lookahead Optimizer: k steps forward, 1 step back](https://arxiv.org/abs/1907.08610)\n```python\nfrom torchtoolbox.optimizer import Lookahead\nfrom torch import optim\n\noptimizer = optim.Adam(...)\noptimizer = Lookahead(optimizer)\n```\n\n#### 5. Mixup training\nMixup method to train a classification model.\n[mixup: BEYOND EMPIRICAL RISK MINIMIZATION](https://arxiv.org/pdf/1710.09412.pdf)\n\n```python\nfrom torchtoolbox.tools import mixup_data, mixup_criterion\n\n# set beta distributed parm, 0.2 is recommend.\nalpha = 0.2\nfor i, (data, labels) in enumerate(train_data):\n    data = data.to(device, non_blocking=True)\n    labels = labels.to(device, non_blocking=True)\n\n    data, labels_a, labels_b, lam = mixup_data(data, labels, alpha)\n    optimizer.zero_grad()\n    outputs = model(data)\n    loss = mixup_criterion(Loss, outputs, labels_a, labels_b, lam)\n\n    loss.backward()\n    optimizer.update()\n```\n\n#### 6. Cutout\nA image transform method.\n[Improved Regularization of Convolutional Neural Networks with Cutout](https://arxiv.org/pdf/1708.04552.pdf)\n```python\nfrom torchvision import transforms\nfrom torchtoolbox.transform import Cutout\n\n_train_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    Cutout(),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.4, 0.4, 0.4),\n    transforms.ToTensor(),\n    normalize,\n])\n```\n\n#### 7. No decay bias\nIf you train a model with big batch size, eg. 64k, you may need this,\n[Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes](https://arxiv.org/pdf/1807.11205.pdf)\n\n```python\nfrom torchtoolbox.tools import split_weights\nfrom torch import optim\n\nmodel = XXX\nparameters = split_weights(model)\noptimizer = optim.SGD(parameters, ...)\n\n```\n\n#### 8. Margin based classification loss\nNow support:\n1. ArcLoss\n2. CosLoss\n3. L2Softmax\n4. CircleLoss\n\n```python\nfrom torchtoolbox.nn.loss import ArcLoss, CosLoss, L2Softmax\n```\n\nYou could use this like `nn.CrossEntropyLoss`\n\n\n## Contribution\n\nWelcome pull requests and issues!!!\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/PistonY/torch-toolbox", "keywords": "", "license": "BSD 3-Clause", "maintainer": "", "maintainer_email": "", "name": "torchtoolbox", "package_url": "https://pypi.org/project/torchtoolbox/", "platform": "", "project_url": "https://pypi.org/project/torchtoolbox/", "project_urls": {"Homepage": "https://github.com/PistonY/torch-toolbox"}, "release_url": "https://pypi.org/project/torchtoolbox/0.1.4.1/", "requires_dist": ["numpy", "tqdm", "pyarrow", "six", "lmdb", "scikit-learn", "scipy", "opencv-python"], "requires_python": "", "summary": "ToolBox to make using Pytorch much easier.", "version": "0.1.4.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Pytorch-Toolbox</h1>\n<p><img alt=\"\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8bc6d28f70aeec7931eb8f6cb0818e4651bc7141/68747470733a2f2f6769746875622e636f6d2f506973746f6e592f746f7263682d746f6f6c626f782f776f726b666c6f77732f546f7263682d546f6f6c626f782d43492f62616467652e737667\"></p>\n<p>Stable Version: v0.1.4(recommend to use.)</p>\n<p>Automatic upload to PyPI has been finished.</p>\n<p>This is toolbox project for Pytorch. Aiming to make you write Pytorch code more easier, readable and concise.</p>\n<p>You could also regard this as a auxiliary tool for Pytorch. It will contain what you use most frequently tools.</p>\n<h2>Installing</h2>\n<p>A easy way to install this is by using pip:</p>\n<pre>pip install torchtoolbox\n</pre>\n<p>If you want to install the nightly version:</p>\n<pre>pip install -U git+https://github.com/PistonY/torch-toolbox.git@master\n</pre>\n<h2>Todo</h2>\n<ul>\n<li>[x] cv2 transforms.</li>\n<li>[ ] Prepare tensorboard support with metric collection.</li>\n</ul>\n<h2>Usage</h2>\n<p>Toolbox have two mainly parts:</p>\n<ol>\n<li>Additional tools to make you use Pytorch easier.</li>\n<li>Some fashion work which don't exist in Pytorch core.</li>\n</ol>\n<h3>Tools</h3>\n<h4>0. Now CV2 transforms have been released.</h4>\n<p>Support as list:(need test)</p>\n<pre><span class=\"n\">__all__</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">\"Compose\"</span><span class=\"p\">,</span> <span class=\"s2\">\"ToTensor\"</span><span class=\"p\">,</span> <span class=\"s2\">\"ToCVImage\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Normalize\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Resize\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Scale\"</span><span class=\"p\">,</span> <span class=\"s2\">\"CenterCrop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Pad\"</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"Lambda\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomApply\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomChoice\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomOrder\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomCrop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomHorizontalFlip\"</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"RandomVerticalFlip\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomResizedCrop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomSizedCrop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"FiveCrop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"TenCrop\"</span><span class=\"p\">,</span> <span class=\"s2\">\"LinearTransformation\"</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"ColorJitter\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomRotation\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomAffine\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Grayscale\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomGrayscale\"</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"RandomPerspective\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomErasing\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomGaussianNoise\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomPoissonNoise\"</span><span class=\"p\">,</span> <span class=\"s2\">\"RandomSPNoise\"</span><span class=\"p\">,</span>\n           <span class=\"s2\">\"RandomTransforms\"</span><span class=\"p\">,</span> <span class=\"s2\">\"Cutout\"</span><span class=\"p\">]</span>\n</pre>\n<p>Part of this code refers to <a href=\"https://github.com/YU-Zhiyang/opencv_transforms_torchvision\" rel=\"nofollow\">opencv_transforms_torchvision</a></p>\n<ul>\n<li><a href=\"https://github.com/albumentations-team/albumentations\" rel=\"nofollow\">albumentations</a> is also recommend to use which is cv2 backend transform tools.</li>\n</ul>\n<h4>1. Show your model parameters and FLOPs.</h4>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.tools</span> <span class=\"kn\">import</span> <span class=\"n\">summary</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.models.mobilenet</span> <span class=\"kn\">import</span> <span class=\"n\">mobilenet_v2</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">mobilenet_v2</span><span class=\"p\">()</span>\n<span class=\"n\">summary</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">,</span> <span class=\"mi\">224</span><span class=\"p\">)))</span>\n</pre>\n<p>Here are some short outputs.</p>\n<pre><code>        Layer (type)               Output Shape          Params    FLOPs(M+A) #\n================================================================================\n            Conv2d-1          [1, 64, 112, 112]            9408       235225088\n       BatchNorm2d-2          [1, 64, 112, 112]             256         1605632\n              ReLU-3          [1, 64, 112, 112]               0               0\n         MaxPool2d-4            [1, 64, 56, 56]               0               0\n          ...                      ...                      ...              ...\n          Linear-158                  [1, 1000]         1281000         2560000\n     MobileNetV2-159                  [1, 1000]               0               0\n================================================================================\n        Total parameters: 3,538,984  3.5M\n    Trainable parameters: 3,504,872\nNon-trainable parameters: 34,112\nTotal flops(M)  : 305,252,872  305.3M\nTotal flops(M+A): 610,505,744  610.5M\n--------------------------------------------------------------------------------\nParameters size (MB): 13.50\n</code></pre>\n<h4>2. Metric collection</h4>\n<p>When we train a model we usually need to calculate some metrics like accuracy(top1-acc), loss etc.\nNow toolbox support as below:</p>\n<ol>\n<li>Accuracy: top-1 acc.</li>\n<li>TopKAccuracy: topK-acc.</li>\n<li>NumericalCost: This is a number metric collection which support <code>mean</code>, <code>max</code>, <code>min</code> calculate type.</li>\n<li>FeatureVerification.\n<ul>\n<li>This is widely used in margin based algorithm.</li>\n</ul>\n</li>\n</ol>\n<pre><span class=\"err\">```</span><span class=\"n\">python</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox</span> <span class=\"kn\">import</span> <span class=\"n\">metric</span>\n\n<span class=\"c1\"># define first</span>\n<span class=\"n\">top1_acc</span> <span class=\"o\">=</span> <span class=\"n\">metric</span><span class=\"o\">.</span><span class=\"n\">Accuracy</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Top1 Accuracy'</span><span class=\"p\">)</span>\n<span class=\"n\">top5_acc</span> <span class=\"o\">=</span> <span class=\"n\">metric</span><span class=\"o\">.</span><span class=\"n\">TopKAccuracy</span><span class=\"p\">(</span><span class=\"n\">top</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Top5 Accuracy'</span><span class=\"p\">)</span>\n<span class=\"n\">loss_record</span> <span class=\"o\">=</span> <span class=\"n\">metric</span><span class=\"o\">.</span><span class=\"n\">NumericalCost</span><span class=\"p\">(</span><span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'Loss'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># reset before using</span>\n<span class=\"n\">top1_acc</span><span class=\"o\">.</span><span class=\"n\">reset</span><span class=\"p\">()</span>\n<span class=\"n\">top5_acc</span><span class=\"o\">.</span><span class=\"n\">reset</span><span class=\"p\">()</span>\n<span class=\"n\">loss_record</span><span class=\"o\">.</span><span class=\"n\">reset</span><span class=\"p\">()</span>\n\n<span class=\"o\">...</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">eval</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"ow\">in</span> <span class=\"n\">val_data</span><span class=\"p\">:</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">non_blocking</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">non_blocking</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"n\">losses</span> <span class=\"o\">=</span> <span class=\"n\">Loss</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n    <span class=\"c1\"># update/record</span>\n    <span class=\"n\">top1_acc</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n    <span class=\"n\">top5_acc</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n    <span class=\"n\">loss_record</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">(</span><span class=\"n\">losses</span><span class=\"p\">)</span>\n    <span class=\"n\">test_msg</span> <span class=\"o\">=</span> <span class=\"s1\">'Test Epoch </span><span class=\"si\">{}</span><span class=\"s1\">: </span><span class=\"si\">{}</span><span class=\"s1\">:</span><span class=\"si\">{:.5}</span><span class=\"s1\">, </span><span class=\"si\">{}</span><span class=\"s1\">:</span><span class=\"si\">{:.5}</span><span class=\"s1\">, </span><span class=\"si\">{}</span><span class=\"s1\">:</span><span class=\"si\">{:.5}</span><span class=\"se\">\\n</span><span class=\"s1\">'</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span>\n    <span class=\"n\">epoch</span><span class=\"p\">,</span> <span class=\"n\">top1_acc</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">top1_acc</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span> <span class=\"n\">top5_acc</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">top5_acc</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(),</span>\n    <span class=\"n\">loss_record</span><span class=\"o\">.</span><span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">loss_record</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">())</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">test_msg</span><span class=\"p\">)</span>\n</pre>\n<p>Then you may get outputs like this</p>\n<pre><code>Test Epoch 101: Top1 Accuracy:0.7332, Top5 Accuracy:0.91514, Loss:1.0605\n</code></pre>\n<h4>3. Model Initializer</h4>\n<p>Now ToolBox support <code>XavierInitializer</code> and <code>KaimingInitializer</code>.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.nn.init</span> <span class=\"kn\">import</span> <span class=\"n\">KaimingInitializer</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">XXX</span>\n<span class=\"n\">initializer</span> <span class=\"o\">=</span> <span class=\"n\">KaimingInitializer</span><span class=\"p\">()</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">apply</span><span class=\"p\">(</span><span class=\"n\">initializer</span><span class=\"p\">)</span>\n</pre>\n<h4>4. AdaptiveSequential</h4>\n<p>Make Pytorch <code>nn.Sequential</code> could handle multi input/output layer.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.nn</span> <span class=\"kn\">import</span> <span class=\"n\">AdaptiveSequential</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">n_to_n</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x1</span><span class=\"p\">,</span> <span class=\"n\">x2</span><span class=\"p\">):</span>\n        <span class=\"n\">y1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x1</span><span class=\"p\">)</span>\n        <span class=\"n\">y2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x2</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">y1</span><span class=\"p\">,</span> <span class=\"n\">y2</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">n_to_one</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x1</span><span class=\"p\">,</span> <span class=\"n\">x2</span><span class=\"p\">):</span>\n        <span class=\"n\">y1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x1</span><span class=\"p\">)</span>\n        <span class=\"n\">y2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x2</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">y1</span> <span class=\"o\">+</span> <span class=\"n\">y2</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">one_to_n</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">y1</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">y2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">conv2</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">y1</span><span class=\"p\">,</span> <span class=\"n\">y2</span>\n\n<span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"n\">AdaptiveSequential</span><span class=\"p\">(</span><span class=\"n\">one_to_n</span><span class=\"p\">(),</span> <span class=\"n\">n_to_n</span><span class=\"p\">(),</span> <span class=\"n\">n_to_one</span><span class=\"p\">())</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n<span class=\"n\">td</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"p\">()</span>\n\n<span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">seq</span><span class=\"p\">(</span><span class=\"n\">td</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">size</span><span class=\"p\">())</span>\n\n<span class=\"c1\"># output</span>\n<span class=\"c1\"># torch.Size([1, 3, 32, 32])</span>\n</pre>\n<h4>5. Make and Use LMDB dataset.</h4>\n<p>If you meet IO speed limit, you may think about <a href=\"https://lmdb.readthedocs.io/en/release/\" rel=\"nofollow\">LMDB</a> format dataset.\nLMDB is a tiny database with some excellent properties.</p>\n<p>Easy to generate a LMDB format dataset.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.tools.convert_lmdb</span> <span class=\"kn\">import</span> <span class=\"n\">generate_lmdb_dataset</span><span class=\"p\">,</span> <span class=\"n\">raw_reader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchvision.datasets</span> <span class=\"kn\">import</span> <span class=\"n\">ImageFolder</span>\n\n<span class=\"n\">dt</span> <span class=\"o\">=</span> <span class=\"n\">ImageFolder</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">,</span> <span class=\"n\">loader</span><span class=\"o\">=</span><span class=\"n\">raw_reader</span><span class=\"p\">)</span>\n<span class=\"n\">save_dir</span> <span class=\"o\">=</span> <span class=\"n\">XXX</span> \n<span class=\"n\">dataset_name</span> <span class=\"o\">=</span> <span class=\"n\">YYY</span>\n<span class=\"n\">generate_lmdb_dataset</span><span class=\"p\">(</span><span class=\"n\">dt</span><span class=\"p\">,</span> <span class=\"n\">save_dir</span><span class=\"o\">=</span><span class=\"n\">save_dir</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"n\">dataset_name</span><span class=\"p\">)</span>\n</pre>\n<p>Then if you use <code>ImageFolder</code> like dataset you can easily use <code>ImageLMDB</code> to load you dataset.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.data</span> <span class=\"kn\">import</span> <span class=\"n\">ImageLMDB</span>\n\n<span class=\"n\">dt</span> <span class=\"o\">=</span> <span class=\"n\">ImageLMDB</span><span class=\"p\">(</span><span class=\"n\">db_path</span><span class=\"o\">=</span><span class=\"n\">save_dir</span><span class=\"p\">,</span> <span class=\"n\">db_name</span><span class=\"o\">=</span><span class=\"n\">dataset_name</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<h4>6. Non-Lable dataset</h4>\n<p>This dataset only return images.</p>\n<p>More details please refers to <a href=\"https://github.com/PistonY/torch-toolbox/blob/4838af996b972cd666fadb9fb6bd6dab2103ccad/torchtoolbox/data/datasets.py#L13\" rel=\"nofollow\">codes</a></p>\n<h3>Fashion work</h3>\n<h4>1. LabelSmoothingLoss</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.nn</span> <span class=\"kn\">import</span> <span class=\"n\">LabelSmoothingLoss</span>\n<span class=\"c1\"># The num classes of your task should be defined.</span>\n<span class=\"n\">classes</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n<span class=\"c1\"># Loss</span>\n<span class=\"n\">Loss</span> <span class=\"o\">=</span> <span class=\"n\">LabelSmoothingLoss</span><span class=\"p\">(</span><span class=\"n\">classes</span><span class=\"p\">,</span> <span class=\"n\">smoothing</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n\n<span class=\"o\">...</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"p\">):</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">non_blocking</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">non_blocking</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n    <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"c1\"># just use as usual.</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">Loss</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n</pre>\n<h4>2. CosineWarmupLr</h4>\n<p>Cosine lr scheduler with warm-up epochs.It's helpful to improve acc for classification models.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.optimizer</span> <span class=\"kn\">import</span> <span class=\"n\">CosineWarmupLr</span>\n\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"c1\"># define scheduler</span>\n<span class=\"c1\"># `batches_pre_epoch` means how many batches(times update/step the model) within one epoch.</span>\n<span class=\"c1\"># `warmup_epochs` means increase lr how many epochs to `base_lr`.</span>\n<span class=\"c1\"># you can find more details in file.</span>\n<span class=\"n\">lr_scheduler</span> <span class=\"o\">=</span> <span class=\"n\">CosineWarmupLr</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">,</span> <span class=\"n\">batches_pre_epoch</span><span class=\"p\">,</span> <span class=\"n\">epochs</span><span class=\"p\">,</span>\n                              <span class=\"n\">base_lr</span><span class=\"o\">=</span><span class=\"n\">lr</span><span class=\"p\">,</span> <span class=\"n\">warmup_epochs</span><span class=\"o\">=</span><span class=\"n\">warmup_epochs</span><span class=\"p\">)</span>\n<span class=\"o\">...</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"p\">):</span>\n    <span class=\"o\">...</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n    <span class=\"c1\"># remember to step/update status here.</span>\n    <span class=\"n\">lr_scheduler</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n    <span class=\"o\">...</span>\n</pre>\n<h4>3. SwitchNorm2d/3d</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.nn</span> <span class=\"kn\">import</span> <span class=\"n\">SwitchNorm2d</span><span class=\"p\">,</span> <span class=\"n\">SwitchNorm3d</span>\n</pre>\n<p>Just use it like Batchnorm2d/3d.\nMore details please refer to origin paper\n<a href=\"https://arxiv.org/pdf/1806.10779.pdf\" rel=\"nofollow\">Differentiable Learning-to-Normalize via Switchable Normalization</a>\n<a href=\"https://github.com/switchablenorms/Switchable-Normalization\" rel=\"nofollow\">OpenSourse</a></p>\n<h4>4. Swish activation</h4>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.nn</span> <span class=\"kn\">import</span> <span class=\"n\">Swish</span>\n</pre>\n<p>Just use it like Relu.\nMore details please refer to origin paper\n<a href=\"https://arxiv.org/pdf/1710.05941.pdf\" rel=\"nofollow\">SEARCHING FOR ACTIVATION FUNCTIONS</a></p>\n<h4>5. Lookahead optimizer</h4>\n<p>A wrapper optimizer seems better than Adam.\n<a href=\"https://arxiv.org/abs/1907.08610\" rel=\"nofollow\">Lookahead Optimizer: k steps forward, 1 step back</a></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.optimizer</span> <span class=\"kn\">import</span> <span class=\"n\">Lookahead</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">optim</span>\n\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">Adam</span><span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">Lookahead</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">)</span>\n</pre>\n<h4>5. Mixup training</h4>\n<p>Mixup method to train a classification model.\n<a href=\"https://arxiv.org/pdf/1710.09412.pdf\" rel=\"nofollow\">mixup: BEYOND EMPIRICAL RISK MINIMIZATION</a></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.tools</span> <span class=\"kn\">import</span> <span class=\"n\">mixup_data</span><span class=\"p\">,</span> <span class=\"n\">mixup_criterion</span>\n\n<span class=\"c1\"># set beta distributed parm, 0.2 is recommend.</span>\n<span class=\"n\">alpha</span> <span class=\"o\">=</span> <span class=\"mf\">0.2</span>\n<span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">train_data</span><span class=\"p\">):</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">non_blocking</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">labels</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">non_blocking</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n    <span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels_a</span><span class=\"p\">,</span> <span class=\"n\">labels_b</span><span class=\"p\">,</span> <span class=\"n\">lam</span> <span class=\"o\">=</span> <span class=\"n\">mixup_data</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"p\">)</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">zero_grad</span><span class=\"p\">()</span>\n    <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">mixup_criterion</span><span class=\"p\">(</span><span class=\"n\">Loss</span><span class=\"p\">,</span> <span class=\"n\">outputs</span><span class=\"p\">,</span> <span class=\"n\">labels_a</span><span class=\"p\">,</span> <span class=\"n\">labels_b</span><span class=\"p\">,</span> <span class=\"n\">lam</span><span class=\"p\">)</span>\n\n    <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">update</span><span class=\"p\">()</span>\n</pre>\n<h4>6. Cutout</h4>\n<p>A image transform method.\n<a href=\"https://arxiv.org/pdf/1708.04552.pdf\" rel=\"nofollow\">Improved Regularization of Convolutional Neural Networks with Cutout</a></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchvision</span> <span class=\"kn\">import</span> <span class=\"n\">transforms</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.transform</span> <span class=\"kn\">import</span> <span class=\"n\">Cutout</span>\n\n<span class=\"n\">_train_transform</span> <span class=\"o\">=</span> <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Compose</span><span class=\"p\">([</span>\n    <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">RandomResizedCrop</span><span class=\"p\">(</span><span class=\"mi\">224</span><span class=\"p\">),</span>\n    <span class=\"n\">Cutout</span><span class=\"p\">(),</span>\n    <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">RandomHorizontalFlip</span><span class=\"p\">(),</span>\n    <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ColorJitter</span><span class=\"p\">(</span><span class=\"mf\">0.4</span><span class=\"p\">,</span> <span class=\"mf\">0.4</span><span class=\"p\">,</span> <span class=\"mf\">0.4</span><span class=\"p\">),</span>\n    <span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">ToTensor</span><span class=\"p\">(),</span>\n    <span class=\"n\">normalize</span><span class=\"p\">,</span>\n<span class=\"p\">])</span>\n</pre>\n<h4>7. No decay bias</h4>\n<p>If you train a model with big batch size, eg. 64k, you may need this,\n<a href=\"https://arxiv.org/pdf/1807.11205.pdf\" rel=\"nofollow\">Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes</a></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.tools</span> <span class=\"kn\">import</span> <span class=\"n\">split_weights</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">optim</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">XXX</span>\n<span class=\"n\">parameters</span> <span class=\"o\">=</span> <span class=\"n\">split_weights</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">)</span>\n<span class=\"n\">optimizer</span> <span class=\"o\">=</span> <span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">SGD</span><span class=\"p\">(</span><span class=\"n\">parameters</span><span class=\"p\">,</span> <span class=\"o\">...</span><span class=\"p\">)</span>\n</pre>\n<h4>8. Margin based classification loss</h4>\n<p>Now support:</p>\n<ol>\n<li>ArcLoss</li>\n<li>CosLoss</li>\n<li>L2Softmax</li>\n<li>CircleLoss</li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">torchtoolbox.nn.loss</span> <span class=\"kn\">import</span> <span class=\"n\">ArcLoss</span><span class=\"p\">,</span> <span class=\"n\">CosLoss</span><span class=\"p\">,</span> <span class=\"n\">L2Softmax</span>\n</pre>\n<p>You could use this like <code>nn.CrossEntropyLoss</code></p>\n<h2>Contribution</h2>\n<p>Welcome pull requests and issues!!!</p>\n\n          </div>"}, "last_serial": 6983077, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e954b879c0741e4885df0afc30229130", "sha256": "56fc2a0d53ad9d4255a346a8254cca45cd11ab6387d5781cddcc231013f45f1b"}, "downloads": -1, "filename": "torchtoolbox-0.0.1.tar.gz", "has_sig": false, "md5_digest": "e954b879c0741e4885df0afc30229130", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5678, "upload_time": "2019-07-01T07:14:03", "upload_time_iso_8601": "2019-07-01T07:14:03.602660Z", "url": "https://files.pythonhosted.org/packages/22/51/5ffc4f617475e564e64e3b777f34d90633aac98f5812b78a71fb2e6d91b2/torchtoolbox-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "696bb98428883d3ff5e1f4cc13f674ad", "sha256": "a3410580bb6ffd0a0e3c94b09f711558f32229236579a8004920d8e4c47c4d70"}, "downloads": -1, "filename": "torchtoolbox-0.0.2.tar.gz", "has_sig": false, "md5_digest": "696bb98428883d3ff5e1f4cc13f674ad", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7651, "upload_time": "2019-07-09T09:21:59", "upload_time_iso_8601": "2019-07-09T09:21:59.276674Z", "url": "https://files.pythonhosted.org/packages/1b/2a/f8186129d477f06b1eb7ea3736e33baaedc5ea2ff13047997815f885894b/torchtoolbox-0.0.2.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "32ab328ca360928e3b7aed29f4bb9c13", "sha256": "3e9654886c2940e40a6536981b9380711b591650a27c7542c7eb81ddf754d04a"}, "downloads": -1, "filename": "torchtoolbox-0.0.4.tar.gz", "has_sig": false, "md5_digest": "32ab328ca360928e3b7aed29f4bb9c13", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19682, "upload_time": "2019-08-28T10:20:48", "upload_time_iso_8601": "2019-08-28T10:20:48.716041Z", "url": "https://files.pythonhosted.org/packages/14/40/9431a5c189ee16a0c1e442ae0b7ff659387da36058e2cdee669869957376/torchtoolbox-0.0.4.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "0eb52f5b70cf246f52b6911cdd626db6", "sha256": "ebd1b292d1056e9a6d9b8a51662e639844c09bda96d45e97e42c845b3c135fab"}, "downloads": -1, "filename": "torchtoolbox-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0eb52f5b70cf246f52b6911cdd626db6", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 33915, "upload_time": "2019-12-17T09:04:18", "upload_time_iso_8601": "2019-12-17T09:04:18.538358Z", "url": "https://files.pythonhosted.org/packages/60/bb/d6a731a46e5dcb28495323033ef01ad93647d0965a645147e5e921bfcb8d/torchtoolbox-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "9a36099306cbe5f831a693ce11cb23af", "sha256": "3b805c3603aa77cdbed5d42c70e3d15481ea086fe8668b2329c344dde65d4644"}, "downloads": -1, "filename": "torchtoolbox-0.1.1.tar.gz", "has_sig": false, "md5_digest": "9a36099306cbe5f831a693ce11cb23af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27513, "upload_time": "2019-12-17T09:04:22", "upload_time_iso_8601": "2019-12-17T09:04:22.394717Z", "url": "https://files.pythonhosted.org/packages/d7/77/d58c37478b731fdaac8ac5ad3131eff095aa893e3a98daddd836208d8296/torchtoolbox-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "c6c74f6cbee8aeb6727ef0b884235b87", "sha256": "427fc30aa14d069249ade9714a2caa7a9f0cd37cf5356a7b388fcbcb3c39d63a"}, "downloads": -1, "filename": "torchtoolbox-0.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "c6c74f6cbee8aeb6727ef0b884235b87", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 33927, "upload_time": "2019-12-18T03:22:42", "upload_time_iso_8601": "2019-12-18T03:22:42.911644Z", "url": "https://files.pythonhosted.org/packages/12/e1/4e4fa67ce73b985d852a30434a9cb6d8418b85559ec0439e75044cb0c697/torchtoolbox-0.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1b13d2b91649901abdd8637dff6dc72f", "sha256": "efe82426abccff1113abeb7e94f61bd18d063055fb7b0e783efb71378451fa17"}, "downloads": -1, "filename": "torchtoolbox-0.1.2.tar.gz", "has_sig": false, "md5_digest": "1b13d2b91649901abdd8637dff6dc72f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 27295, "upload_time": "2019-12-18T03:22:44", "upload_time_iso_8601": "2019-12-18T03:22:44.675552Z", "url": "https://files.pythonhosted.org/packages/3a/03/209ef76c1ae0a95035fc07c135c5f3fc23eb959ffcd8ab549e26595f9116/torchtoolbox-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "a7a5ee577d036f41271fb6d9227eee57", "sha256": "d71ecb31259bdd628cada804ee5a8bc7890f0b837dc3c99bcea32ca766e2d881"}, "downloads": -1, "filename": "torchtoolbox-0.1.3-py3-none-any.whl", "has_sig": false, "md5_digest": "a7a5ee577d036f41271fb6d9227eee57", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55110, "upload_time": "2020-03-05T08:20:51", "upload_time_iso_8601": "2020-03-05T08:20:51.782845Z", "url": "https://files.pythonhosted.org/packages/02/51/63486af2b1a834187067d160b69d15c795af29e69d718727f7d7e42e501a/torchtoolbox-0.1.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "1e81a0a76c7228265250a89b2464efaf", "sha256": "d138732ca8e0f1b8ae4918b086ff36d0e95d69f4eb0e1aad31e160bd3fc57485"}, "downloads": -1, "filename": "torchtoolbox-0.1.3.tar.gz", "has_sig": false, "md5_digest": "1e81a0a76c7228265250a89b2464efaf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 46660, "upload_time": "2020-03-05T08:20:53", "upload_time_iso_8601": "2020-03-05T08:20:53.413708Z", "url": "https://files.pythonhosted.org/packages/7e/25/6563a08cfd72810147b825d638f16dda94861e5bd21d9ada64c3c1800c26/torchtoolbox-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "74c1215bcdd2ac3c105ec3d8523d83e0", "sha256": "abd45f41e744194c50a2c32751a4a156efb748d8975387e1b567190e78c022af"}, "downloads": -1, "filename": "torchtoolbox-0.1.4-py3-none-any.whl", "has_sig": false, "md5_digest": "74c1215bcdd2ac3c105ec3d8523d83e0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55854, "upload_time": "2020-04-08T09:15:58", "upload_time_iso_8601": "2020-04-08T09:15:58.167919Z", "url": "https://files.pythonhosted.org/packages/8c/3e/2fb126d913f6956a454fc45d8cdb01bee85329d7a596559741d8937806a5/torchtoolbox-0.1.4-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "03671fa010bd9eae85fa87de32dec8af", "sha256": "e3184baeebd3fb6084272e4e1286b416d43ba1655edd3984eb8c96ca864d9b11"}, "downloads": -1, "filename": "torchtoolbox-0.1.4.tar.gz", "has_sig": false, "md5_digest": "03671fa010bd9eae85fa87de32dec8af", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47398, "upload_time": "2020-04-08T09:16:00", "upload_time_iso_8601": "2020-04-08T09:16:00.041712Z", "url": "https://files.pythonhosted.org/packages/ae/f2/6512b3b09bf77f7254f320165fbffa9570793632297aae65be5d3fbedf1d/torchtoolbox-0.1.4.tar.gz", "yanked": false}], "0.1.4.1": [{"comment_text": "", "digests": {"md5": "dfe6e60756c2b5e4b1761dda6f63a20f", "sha256": "241c803781b686c11f00dd2567bffc97ceeda501eb42ed5407bf5e468eea8e78"}, "downloads": -1, "filename": "torchtoolbox-0.1.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "dfe6e60756c2b5e4b1761dda6f63a20f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55945, "upload_time": "2020-04-09T03:32:46", "upload_time_iso_8601": "2020-04-09T03:32:46.554959Z", "url": "https://files.pythonhosted.org/packages/76/6c/25f066977b6821796c3cf11e981921c1cb030eafec0ff736d271b6b09878/torchtoolbox-0.1.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4331e1171bf181258450dad6f246e786", "sha256": "324d6d410452637e65603d736a897b85f2bfe34bb3637af7cb8008f22b40ce60"}, "downloads": -1, "filename": "torchtoolbox-0.1.4.1.tar.gz", "has_sig": false, "md5_digest": "4331e1171bf181258450dad6f246e786", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47467, "upload_time": "2020-04-09T03:32:48", "upload_time_iso_8601": "2020-04-09T03:32:48.136804Z", "url": "https://files.pythonhosted.org/packages/62/eb/5e14eca434d5c4e968d988b227fb97cb8e7ac06022a864ba37e87ff5ce98/torchtoolbox-0.1.4.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dfe6e60756c2b5e4b1761dda6f63a20f", "sha256": "241c803781b686c11f00dd2567bffc97ceeda501eb42ed5407bf5e468eea8e78"}, "downloads": -1, "filename": "torchtoolbox-0.1.4.1-py3-none-any.whl", "has_sig": false, "md5_digest": "dfe6e60756c2b5e4b1761dda6f63a20f", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 55945, "upload_time": "2020-04-09T03:32:46", "upload_time_iso_8601": "2020-04-09T03:32:46.554959Z", "url": "https://files.pythonhosted.org/packages/76/6c/25f066977b6821796c3cf11e981921c1cb030eafec0ff736d271b6b09878/torchtoolbox-0.1.4.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "4331e1171bf181258450dad6f246e786", "sha256": "324d6d410452637e65603d736a897b85f2bfe34bb3637af7cb8008f22b40ce60"}, "downloads": -1, "filename": "torchtoolbox-0.1.4.1.tar.gz", "has_sig": false, "md5_digest": "4331e1171bf181258450dad6f246e786", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 47467, "upload_time": "2020-04-09T03:32:48", "upload_time_iso_8601": "2020-04-09T03:32:48.136804Z", "url": "https://files.pythonhosted.org/packages/62/eb/5e14eca434d5c4e968d988b227fb97cb8e7ac06022a864ba37e87ff5ce98/torchtoolbox-0.1.4.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:06 2020"}