{"info": {"author": "Manuel Schoelling, Christoph Moehl", "author_email": "manuel.schoelling@dzne.de, christoph.moehl@dzne.de", "bugtrack_url": null, "classifiers": [], "description": "[![Build Status](https://travis-ci.com/yapic/yapic_io.svg?branch=master)](https://travis-ci.com/yapic/yapic_io)\n[![Documentation Status](https://readthedocs.org/projects/yapic-io/badge/?version=latest)](https://yapic-io.readthedocs.io/en/latest/?badge=latest)\n\n# yapic_io\n\n\n\n\nyapic_io provides flexible data binding to image collections of arbitrary size.\n\n\nIts aim is to provide a convenient image data interface for training of\nfully convolutional neural networks, as well as automatic handling of\nprediction data output for a trained classifier.\n\nyapic_io is designed as a convenient image data input/output interface for\nlibraries such as Theano or TensorFlow.\n\n\nFollowing problems occuring with training/classification are handeled by yapic_io:\n\n- Images of different sizes in z,x, and y can be applied to the\n  same convolutional network. This is implemented by sliding windows. The size these windows correspond to the size of the convolutional network's input layer.\n\n- Due to lazy data loading, images can be extremely large.\n\n- Image dimensions can be up to 4D (multchannel z-stack), as e.g. required\n  for bioimages.\n\n- Data augmentation for classifier training in built in.\n\n- Made for sparsly labelled datasets: Training data is only (randomly) picked\n  from regions where labels are present.\n\n- Usually, input layers of CNNs are larger than output layers. Thus, pixels\n  located at image edges are normally not classified. With yapic_io also\n  edge pixels are classified. This is achieved by mirroring pixel data in edge\n  regions. As a result, output classification images have identical dimensions as source images and can be overlayed easily.\n\n\n\n## Example\n\nClassifier training:\n\n```\n>>> from yapic_io import TiffConnector, Dataset, TrainingBatch\n>>>\n>>> #define data locations\n>>> pixel_image_dir = 'yapic_io/test_data/tiffconnector_1/im/*.tif'\n>>> label_image_dir = 'yapic_io/test_data/tiffconnector_1/labels/*.tif'\n>>> savepath = 'yapic_io/test_data/tmp/'\n>>>\n>>>\n>>> tpl_size = (1,5,4) # size of network output layer in zxy\n>>> padding = (0,2,2) # padding of network input layer in zxy, in respect to output layer\n>>>\n>>> c = TiffConnector(pixel_image_dir, label_image_dir, savepath=savepath)\n>>> train_data = TrainingBatch(Dataset(c), tpl_size, padding_zxy=padding)\n>>>\n>>> counter=0\n>>> for mini in train_data:\n...     weights = mini.weights\n...     #shape of weights is (6,3,1,5,4) : batchsize 6 , 3 label-classes, 1 z, 5 x, 4 y\n...\n...     pixels = mini.pixels()\n...     # shape of pixels is (6,3,1,9,8) : 3 channels, 1 z, 9 x, 4 y (more xy due to padding)\n...\n...     #here: apply training on mini.pixels and mini.weights (use theano, tensorflow...)\n...     my_train_function(pixels, weights)\n...\n...     counter += 1\n...     if counter > 10: #m is infinite\n...         break\n```\nPrediction:\n```\n>>> from yapic_io import TiffConnector, Dataset, PredictionBatch\n>>>\n>>> #mock classification function\n>>> def classify(pixels, value):\n...     return np.ones(pixels.shape) * value\n>>>\n>>> #define data loacations\n>>> pixel_image_dir = 'yapic_io/test_data/tiffconnector_1/im/*.tif'\n>>> label_image_dir = 'yapic_io/test_data/tiffconnector_1/labels/*.tif'\n>>> savepath = 'yapic_io/test_data/tmp/'\n>>>\n>>> tpl_size = (1,5,4) # size of network output layer in zxy\n>>> padding = (0,2,2) # padding of network input layer in zxy, in respect to output layer\n>>>\n>>> c = TiffConnector(pixel_image_dir, label_image_dir, savepath=savepath)\n>>> prediction_data = PredictionBatch(Dataset(c))\n>>> len(prediction_data) #give the total number of templates that cover the whole bound tifffiles\n510\n>>>\n>>> #classify the whole bound dataset\n>>> counter = 0 #needed for mock data\n>>> for item in prediction_data:\n...     pixels_for_classifier = item.pixels() #input for classifier\n...     mock_classifier_result = classify(pixels, counter) #classifier output\n...\n...     #pass classifier results for each class to data source\n...     item.put_probmap_data(mock_classifier_result)\n...\n...     counter += 1 #counter for generation of mockdata\n>>>\n```\n\n## Buils API docs\n\n```\ncd docs\nsphinx-apidoc -o source ../yapic_io\nmake html\n```\n\n\nDeveloped by the CRFS (Core Research Facilities) of the DZNE (German Center\nfor Neurodegenerative Diseases).", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "yapic-io", "package_url": "https://pypi.org/project/yapic-io/", "platform": "", "project_url": "https://pypi.org/project/yapic-io/", "project_urls": null, "release_url": "https://pypi.org/project/yapic-io/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "io data handling module for various image sources as interface for pixel classification tools", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>[![Build Status](<a href=\"https://travis-ci.com/yapic/yapic_io.svg?branch=master)%5D(https://travis-ci.com/yapic/yapic_io\" rel=\"nofollow\">https://travis-ci.com/yapic/yapic_io.svg?branch=master)](https://travis-ci.com/yapic/yapic_io</a>)\n[![Documentation Status](<a href=\"https://readthedocs.org/projects/yapic-io/badge/?version=latest)%5D(https://yapic-io.readthedocs.io/en/latest/\" rel=\"nofollow\">https://readthedocs.org/projects/yapic-io/badge/?version=latest)](https://yapic-io.readthedocs.io/en/latest/</a>?badge=latest)</p>\n<p># yapic_io</p>\n<p>yapic_io provides flexible data binding to image collections of arbitrary size.</p>\n<p>Its aim is to provide a convenient image data interface for training of\nfully convolutional neural networks, as well as automatic handling of\nprediction data output for a trained classifier.</p>\n<p>yapic_io is designed as a convenient image data input/output interface for\nlibraries such as Theano or TensorFlow.</p>\n<p>Following problems occuring with training/classification are handeled by yapic_io:</p>\n<ul>\n<li>Images of different sizes in z,x, and y can be applied to the\nsame convolutional network. This is implemented by sliding windows. The size these windows correspond to the size of the convolutional network\u2019s input layer.</li>\n<li>Due to lazy data loading, images can be extremely large.</li>\n<li>Image dimensions can be up to 4D (multchannel z-stack), as e.g. required\nfor bioimages.</li>\n<li>Data augmentation for classifier training in built in.</li>\n<li>Made for sparsly labelled datasets: Training data is only (randomly) picked\nfrom regions where labels are present.</li>\n<li>Usually, input layers of CNNs are larger than output layers. Thus, pixels\nlocated at image edges are normally not classified. With yapic_io also\nedge pixels are classified. This is achieved by mirroring pixel data in edge\nregions. As a result, output classification images have identical dimensions as source images and can be overlayed easily.</li>\n</ul>\n<p>## Example</p>\n<p>Classifier training:</p>\n<p><tt>`\n&gt;&gt;&gt; from yapic_io import TiffConnector, Dataset, TrainingBatch\n&gt;&gt;&gt;\n&gt;&gt;&gt; #define data locations\n&gt;&gt;&gt; pixel_image_dir = <span class=\"pre\">'yapic_io/test_data/tiffconnector_1/im/*.tif'</span>\n&gt;&gt;&gt; label_image_dir = <span class=\"pre\">'yapic_io/test_data/tiffconnector_1/labels/*.tif'</span>\n&gt;&gt;&gt; savepath = 'yapic_io/test_data/tmp/'\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; tpl_size = (1,5,4) # size of network output layer in zxy\n&gt;&gt;&gt; padding = (0,2,2) # padding of network input layer in zxy, in respect to output layer\n&gt;&gt;&gt;\n&gt;&gt;&gt; c = TiffConnector(pixel_image_dir, label_image_dir, savepath=savepath)\n&gt;&gt;&gt; train_data = TrainingBatch(Dataset(c), tpl_size, padding_zxy=padding)\n&gt;&gt;&gt;\n&gt;&gt;&gt; counter=0\n&gt;&gt;&gt; for mini in train_data:\n...\u00a0\u00a0\u00a0\u00a0 weights = mini.weights\n...\u00a0\u00a0\u00a0\u00a0 #shape of weights is (6,3,1,5,4) : batchsize 6 , 3 <span class=\"pre\">label-classes,</span> 1 z, 5 x, 4 y\n...\n...\u00a0\u00a0\u00a0\u00a0 pixels = mini.pixels()\n...\u00a0\u00a0\u00a0\u00a0 # shape of pixels is (6,3,1,9,8) : 3 channels, 1 z, 9 x, 4 y (more xy due to padding)\n...\n...\u00a0\u00a0\u00a0\u00a0 #here: apply training on mini.pixels and mini.weights (use theano, <span class=\"pre\">tensorflow...)</span>\n...\u00a0\u00a0\u00a0\u00a0 my_train_function(pixels, weights)\n...\n...\u00a0\u00a0\u00a0\u00a0 counter += 1\n...\u00a0\u00a0\u00a0\u00a0 if counter &gt; 10: #m is infinite\n...\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 break\n`</tt>\nPrediction:\n<tt>`\n&gt;&gt;&gt; from yapic_io import TiffConnector, Dataset, PredictionBatch\n&gt;&gt;&gt;\n&gt;&gt;&gt; #mock classification function\n&gt;&gt;&gt; def classify(pixels, value):\n...\u00a0\u00a0\u00a0\u00a0 return np.ones(pixels.shape) * value\n&gt;&gt;&gt;\n&gt;&gt;&gt; #define data loacations\n&gt;&gt;&gt; pixel_image_dir = <span class=\"pre\">'yapic_io/test_data/tiffconnector_1/im/*.tif'</span>\n&gt;&gt;&gt; label_image_dir = <span class=\"pre\">'yapic_io/test_data/tiffconnector_1/labels/*.tif'</span>\n&gt;&gt;&gt; savepath = 'yapic_io/test_data/tmp/'\n&gt;&gt;&gt;\n&gt;&gt;&gt; tpl_size = (1,5,4) # size of network output layer in zxy\n&gt;&gt;&gt; padding = (0,2,2) # padding of network input layer in zxy, in respect to output layer\n&gt;&gt;&gt;\n&gt;&gt;&gt; c = TiffConnector(pixel_image_dir, label_image_dir, savepath=savepath)\n&gt;&gt;&gt; prediction_data = PredictionBatch(Dataset(c))\n&gt;&gt;&gt; len(prediction_data) #give the total number of templates that cover the whole bound tifffiles\n510\n&gt;&gt;&gt;\n&gt;&gt;&gt; #classify the whole bound dataset\n&gt;&gt;&gt; counter = 0 #needed for mock data\n&gt;&gt;&gt; for item in prediction_data:\n...\u00a0\u00a0\u00a0\u00a0 pixels_for_classifier = item.pixels() #input for classifier\n...\u00a0\u00a0\u00a0\u00a0 mock_classifier_result = classify(pixels, counter) #classifier output\n...\n...\u00a0\u00a0\u00a0\u00a0 #pass classifier results for each class to data source\n...\u00a0\u00a0\u00a0\u00a0 item.put_probmap_data(mock_classifier_result)\n...\n...\u00a0\u00a0\u00a0\u00a0 counter += 1 #counter for generation of mockdata\n&gt;&gt;&gt;\n`</tt></p>\n<p>## Buils API docs</p>\n<p><tt>`\ncd docs\n<span class=\"pre\">sphinx-apidoc</span> <span class=\"pre\">-o</span> source <span class=\"pre\">../yapic_io</span>\nmake html\n`</tt></p>\n<p>Developed by the CRFS (Core Research Facilities) of the DZNE (German Center\nfor Neurodegenerative Diseases).</p>\n\n          </div>"}, "last_serial": 5272694, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "ef45a06b8330f920f6d1791dc9333d3f", "sha256": "e2759f2066820ef60266ae98e1d384e5cb0230f522bd071971b4e2e6b4d68197"}, "downloads": -1, "filename": "yapic_io-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ef45a06b8330f920f6d1791dc9333d3f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24718, "upload_time": "2019-05-15T14:12:01", "upload_time_iso_8601": "2019-05-15T14:12:01.867028Z", "url": "https://files.pythonhosted.org/packages/2f/63/dd7953436f97a6237c9a23783429b14d28648f487108143972e6aa32598d/yapic_io-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "ef45a06b8330f920f6d1791dc9333d3f", "sha256": "e2759f2066820ef60266ae98e1d384e5cb0230f522bd071971b4e2e6b4d68197"}, "downloads": -1, "filename": "yapic_io-0.1.0.tar.gz", "has_sig": false, "md5_digest": "ef45a06b8330f920f6d1791dc9333d3f", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 24718, "upload_time": "2019-05-15T14:12:01", "upload_time_iso_8601": "2019-05-15T14:12:01.867028Z", "url": "https://files.pythonhosted.org/packages/2f/63/dd7953436f97a6237c9a23783429b14d28648f487108143972e6aa32598d/yapic_io-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:23:04 2020"}