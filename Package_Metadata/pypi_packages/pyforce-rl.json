{"info": {"author": "Ole Meyer", "author_email": "dev@olemeyer.com", "bugtrack_url": null, "classifiers": [], "description": "\n<p  align=\"center\"><img  src=\"https://docs.google.com/drawings/d/e/2PACX-1vQTqWkqIzSlT3zldytD8L0kj6MZVpE_5ZslrDAvMhLEG-anipK2UPJuHm3ImGhVVTVYiZrsbTlKf3Yo/pub?w=756&h=265\"  height=\"200px\"  /></p>\n\n\n\n[![Status](https://img.shields.io/badge/status-active-success.svg)]()\n\n\n\n\n\n\n</div>\n\n\n\n\n\n---\n\n\n\n\n\n\n\n\n\n## \ud83e\uddd0 About <a name = \"about\"></a>\n\nA simple and modular reinforcement learning library based on PyTorch.\n\n\n## \ud83c\udfc1 Getting Started <a name = \"getting_started\"></a>\n\n\n\n\n\n    pip install pyforce-rl\n\n\n\n\n## \ud83c\udf88 Usage <a name=\"usage\"></a>\n\n\n\n```python\nfrom pyforce.env import wrap_openai_gym\nfrom pyforce.nn import default_network_components\nfrom pyforce.agents import PPOAgent\nimport gym\nimport torch\n\ndevice=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nenv=wrap_openai_gym(gym.make(\"LunarLanderContinuous-v2\"))\n\nobservation_processor,hidden_layers,action_mapper=default_network_components(env)\n\nagent=PPOAgent(\n    observation_processor,\n    hidden_layers,\n    action_mapper,\n    save_path=\"./evals/ppo_example\",\n    value_lr=5e-4,\n    policy_lr=5e-4\n).to(device)\n\nagent.train(env,episodes=1000,train_freq=2048,eval_freq=50,render=True, batch_size=128,gamma=.99,tau=.95,clip=.2,n_steps=32,entropy_coef=.01)\n```\n\n\n\n\n## \ud83d\ude80 Implement custom RL Agents <a name = \"deployment\"></a>\n\n\n\n```python\nfrom pyforce.agents.base import BaseAgent\nfrom torch import nn\n\nclass  MyAgent(BaseAgent):\n\ndef  __init__(self,observationprocessor,hiddenlayers,actionmapper,save_path=None):\n\n\tsuper().__init__(save_path)\n\n\tself.policy_net = nn.Sequential(observationprocessor, hiddenlayers, actionmapper)\n\tself.value_net = ...\n\ndef  forward(self, state):\n\treturn  self.policy_net(state)\n\ndef  get_action(self, state, eval, args):\n\t#return action + possible additional information to be stored in the memory\n\treturn  self(state).sample(), {} \n\ndef  after_step(self, done, eval, args):\n\tif  not  eval:\n\t\tif  self.env_steps % args[\"train_freq\"] == 0 and len(self.memory) > 0:\n\t\t\t#do training\n\n\tif done and eval:\n\t\t#do evaluation\n```\n\n\n## \u26cf\ufe0f Built Using <a name = \"built_using\"></a>\n\n\n\n\n\n-  [PyTorch](https://pytorch.com/) - ML Framework\n\n\n\n-  [OpenAI Gym](https://gym.openai.com/) - Environment API\n\n\n\n-  [NumPy](https://numpy.org/) - Numerical calculations outside PyTorch\n\n\n\n<!--\n\n\n\n## \u270d\ufe0f Authors <a name = \"authors\"></a>\n\n\n\n\n\n-  [@olemeyer](https://github.com/olemeyer)\n\n\n\n\n\nSee also the list of [contributors](https://github.com/kylelobo/The-Documentation-Compendium/contributors) who participated in this project.\n\n\n\n\n\n## \ud83c\udf89 Acknowledgements <a name = \"acknowledgement\"></a>\n\n\n\n\n\n-  [Cherry-RL](http://cherry-rl.net/) & [Keras-RL](https://keras-rl.readthedocs.io/en/latest/) for Inspiration\n\n-->\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pyforce-rl", "package_url": "https://pypi.org/project/pyforce-rl/", "platform": "", "project_url": "https://pypi.org/project/pyforce-rl/", "project_urls": null, "release_url": "https://pypi.org/project/pyforce-rl/0.0.10/", "requires_dist": ["tqdm", "gym", "numpy", "torch"], "requires_python": "", "summary": "PyForce - A simple reinforcement learning library", "version": "0.0.10", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"center\"><img height=\"200px\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/df51b9d78812383b3369ab17aa6670f0d0d37837/68747470733a2f2f646f63732e676f6f676c652e636f6d2f64726177696e67732f642f652f32504143582d3176515471576b71497a536c54337a6c64797444384c306b6a364d5a5670455f355a736c724441764d684c45472d616e69704b3255504a75486d33496d47685656545659695a727362546c4b6633596f2f7075623f773d37353626683d323635\"></p>\n<p><a href=\"\" rel=\"nofollow\"><img alt=\"Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3df82fcca92ffecd57766052c224210c0f7e8a9c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374617475732d6163746976652d737563636573732e737667\"></a></p>\n\n<hr>\n<h2>\ud83e\uddd0 About <a></a></h2>\n<p>A simple and modular reinforcement learning library based on PyTorch.</p>\n<h2>\ud83c\udfc1 Getting Started <a></a></h2>\n<pre><code>pip install pyforce-rl\n</code></pre>\n<h2>\ud83c\udf88 Usage <a></a></h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pyforce.env</span> <span class=\"kn\">import</span> <span class=\"n\">wrap_openai_gym</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyforce.nn</span> <span class=\"kn\">import</span> <span class=\"n\">default_network_components</span>\n<span class=\"kn\">from</span> <span class=\"nn\">pyforce.agents</span> <span class=\"kn\">import</span> <span class=\"n\">PPOAgent</span>\n<span class=\"kn\">import</span> <span class=\"nn\">gym</span>\n<span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n\n<span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s2\">\"cuda:0\"</span> <span class=\"k\">if</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cuda</span><span class=\"o\">.</span><span class=\"n\">is_available</span><span class=\"p\">()</span> <span class=\"k\">else</span> <span class=\"s2\">\"cpu\"</span>\n\n<span class=\"n\">env</span><span class=\"o\">=</span><span class=\"n\">wrap_openai_gym</span><span class=\"p\">(</span><span class=\"n\">gym</span><span class=\"o\">.</span><span class=\"n\">make</span><span class=\"p\">(</span><span class=\"s2\">\"LunarLanderContinuous-v2\"</span><span class=\"p\">))</span>\n\n<span class=\"n\">observation_processor</span><span class=\"p\">,</span><span class=\"n\">hidden_layers</span><span class=\"p\">,</span><span class=\"n\">action_mapper</span><span class=\"o\">=</span><span class=\"n\">default_network_components</span><span class=\"p\">(</span><span class=\"n\">env</span><span class=\"p\">)</span>\n\n<span class=\"n\">agent</span><span class=\"o\">=</span><span class=\"n\">PPOAgent</span><span class=\"p\">(</span>\n    <span class=\"n\">observation_processor</span><span class=\"p\">,</span>\n    <span class=\"n\">hidden_layers</span><span class=\"p\">,</span>\n    <span class=\"n\">action_mapper</span><span class=\"p\">,</span>\n    <span class=\"n\">save_path</span><span class=\"o\">=</span><span class=\"s2\">\"./evals/ppo_example\"</span><span class=\"p\">,</span>\n    <span class=\"n\">value_lr</span><span class=\"o\">=</span><span class=\"mf\">5e-4</span><span class=\"p\">,</span>\n    <span class=\"n\">policy_lr</span><span class=\"o\">=</span><span class=\"mf\">5e-4</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">to</span><span class=\"p\">(</span><span class=\"n\">device</span><span class=\"p\">)</span>\n\n<span class=\"n\">agent</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">env</span><span class=\"p\">,</span><span class=\"n\">episodes</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span><span class=\"n\">train_freq</span><span class=\"o\">=</span><span class=\"mi\">2048</span><span class=\"p\">,</span><span class=\"n\">eval_freq</span><span class=\"o\">=</span><span class=\"mi\">50</span><span class=\"p\">,</span><span class=\"n\">render</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span><span class=\"n\">gamma</span><span class=\"o\">=.</span><span class=\"mi\">99</span><span class=\"p\">,</span><span class=\"n\">tau</span><span class=\"o\">=.</span><span class=\"mi\">95</span><span class=\"p\">,</span><span class=\"n\">clip</span><span class=\"o\">=.</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">n_steps</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">,</span><span class=\"n\">entropy_coef</span><span class=\"o\">=.</span><span class=\"mi\">01</span><span class=\"p\">)</span>\n</pre>\n<h2>\ud83d\ude80 Implement custom RL Agents <a></a></h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">pyforce.agents.base</span> <span class=\"kn\">import</span> <span class=\"n\">BaseAgent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">torch</span> <span class=\"kn\">import</span> <span class=\"n\">nn</span>\n\n<span class=\"k\">class</span>  <span class=\"nc\">MyAgent</span><span class=\"p\">(</span><span class=\"n\">BaseAgent</span><span class=\"p\">):</span>\n\n<span class=\"k\">def</span>  <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"n\">observationprocessor</span><span class=\"p\">,</span><span class=\"n\">hiddenlayers</span><span class=\"p\">,</span><span class=\"n\">actionmapper</span><span class=\"p\">,</span><span class=\"n\">save_path</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n\n\t<span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"n\">save_path</span><span class=\"p\">)</span>\n\n\t<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">policy_net</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span><span class=\"n\">observationprocessor</span><span class=\"p\">,</span> <span class=\"n\">hiddenlayers</span><span class=\"p\">,</span> <span class=\"n\">actionmapper</span><span class=\"p\">)</span>\n\t<span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">value_net</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n\n<span class=\"k\">def</span>  <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">):</span>\n\t<span class=\"k\">return</span>  <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">policy_net</span><span class=\"p\">(</span><span class=\"n\">state</span><span class=\"p\">)</span>\n\n<span class=\"k\">def</span>  <span class=\"nf\">get_action</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">state</span><span class=\"p\">,</span> <span class=\"nb\">eval</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"p\">):</span>\n\t<span class=\"c1\">#return action + possible additional information to be stored in the memory</span>\n\t<span class=\"k\">return</span>  <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">state</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sample</span><span class=\"p\">(),</span> <span class=\"p\">{}</span> \n\n<span class=\"k\">def</span>  <span class=\"nf\">after_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">done</span><span class=\"p\">,</span> <span class=\"nb\">eval</span><span class=\"p\">,</span> <span class=\"n\">args</span><span class=\"p\">):</span>\n\t<span class=\"k\">if</span>  <span class=\"ow\">not</span>  <span class=\"nb\">eval</span><span class=\"p\">:</span>\n\t\t<span class=\"k\">if</span>  <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">env_steps</span> <span class=\"o\">%</span> <span class=\"n\">args</span><span class=\"p\">[</span><span class=\"s2\">\"train_freq\"</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"mi\">0</span> <span class=\"ow\">and</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">memory</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n\t\t\t<span class=\"c1\">#do training</span>\n\n\t<span class=\"k\">if</span> <span class=\"n\">done</span> <span class=\"ow\">and</span> <span class=\"nb\">eval</span><span class=\"p\">:</span>\n\t\t<span class=\"c1\">#do evaluation</span>\n</pre>\n<h2>\u26cf\ufe0f Built Using <a></a></h2>\n<ul>\n<li>\n<p><a href=\"https://pytorch.com/\" rel=\"nofollow\">PyTorch</a> - ML Framework</p>\n</li>\n<li>\n<p><a href=\"https://gym.openai.com/\" rel=\"nofollow\">OpenAI Gym</a> - Environment API</p>\n</li>\n<li>\n<p><a href=\"https://numpy.org/\" rel=\"nofollow\">NumPy</a> - Numerical calculations outside PyTorch</p>\n</li>\n</ul>\n\n\n          </div>"}, "last_serial": 7170439, "releases": {"0.0.10": [{"comment_text": "", "digests": {"md5": "7d36de9d8cb2cb5e73e0e16c6f1f4311", "sha256": "dc6f7d9a89d0f5e602bc7454dd76d1eb54b11d17c6299c3104ee6da85b5f9e01"}, "downloads": -1, "filename": "pyforce_rl-0.0.10-py3-none-any.whl", "has_sig": false, "md5_digest": "7d36de9d8cb2cb5e73e0e16c6f1f4311", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17395, "upload_time": "2020-05-05T08:55:12", "upload_time_iso_8601": "2020-05-05T08:55:12.429344Z", "url": "https://files.pythonhosted.org/packages/b0/31/363d98e52fefa10bafcac1bf21d0d3e1308d9716244fb7743d46d58cc4e5/pyforce_rl-0.0.10-py3-none-any.whl", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "603453784cf63f04b9066eb49e36e0d3", "sha256": "562ca7a3e02e150cb20e6c3513b0a423e4909842d02f3040bb3e703542954080"}, "downloads": -1, "filename": "pyforce_rl-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "603453784cf63f04b9066eb49e36e0d3", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12364, "upload_time": "2020-03-27T06:09:52", "upload_time_iso_8601": "2020-03-27T06:09:52.658919Z", "url": "https://files.pythonhosted.org/packages/1b/68/a4954f949daa432c0f511733d285d56cd7f6c8e53e04cdff7af34439c532/pyforce_rl-0.0.2-py3-none-any.whl", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "9d627b63c1a8a62910f0b6fe80f12ba5", "sha256": "18e1e72aa43ac3fcf405e8e544921fbbef734f0aa7600dfdbed9829eb875182a"}, "downloads": -1, "filename": "pyforce_rl-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "9d627b63c1a8a62910f0b6fe80f12ba5", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13045, "upload_time": "2020-03-28T15:36:21", "upload_time_iso_8601": "2020-03-28T15:36:21.124205Z", "url": "https://files.pythonhosted.org/packages/46/bf/8ad5c52c30a7188acc08e1a3c1aa49f3dce8e2c4bb726a4e477280056cd4/pyforce_rl-0.0.3-py3-none-any.whl", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "40a01aef5ef158c414a20fdfbb2ea60a", "sha256": "33d66b697df3a6c6cf021df2ee3c9ddbdf83cafb6abf82fc29c8cb8ecc70b3a9"}, "downloads": -1, "filename": "pyforce_rl-0.0.4-py3-none-any.whl", "has_sig": false, "md5_digest": "40a01aef5ef158c414a20fdfbb2ea60a", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 13050, "upload_time": "2020-03-28T15:53:44", "upload_time_iso_8601": "2020-03-28T15:53:44.552485Z", "url": "https://files.pythonhosted.org/packages/80/29/3fa2a931fe3ac40c14e5e73c8a75f5b3d45cddc28df29037f64d44cba7d9/pyforce_rl-0.0.4-py3-none-any.whl", "yanked": false}], "0.0.5": [{"comment_text": "", "digests": {"md5": "243ecf4b41b5d0c829c4b4a9774ee5ab", "sha256": "12ac3574a234782bd8dbb17e3a408371390fb1deed7b575fb31c8e9076e9858d"}, "downloads": -1, "filename": "pyforce_rl-0.0.5-py3-none-any.whl", "has_sig": false, "md5_digest": "243ecf4b41b5d0c829c4b4a9774ee5ab", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17206, "upload_time": "2020-04-13T10:28:26", "upload_time_iso_8601": "2020-04-13T10:28:26.366674Z", "url": "https://files.pythonhosted.org/packages/6e/32/b04733a598a5b3cbedb8e46ec8e3f0e36db980e21779d9b5882975921100/pyforce_rl-0.0.5-py3-none-any.whl", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "f20eea70b58b470494382e2628f78edf", "sha256": "d981d2c4564c8ec5c0f948fb64724d3c33365ddcd72f1f177360664ee167ae0f"}, "downloads": -1, "filename": "pyforce_rl-0.0.6-py3-none-any.whl", "has_sig": false, "md5_digest": "f20eea70b58b470494382e2628f78edf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17210, "upload_time": "2020-04-13T14:00:55", "upload_time_iso_8601": "2020-04-13T14:00:55.388702Z", "url": "https://files.pythonhosted.org/packages/83/e7/21ec73371e3dabd3c8beebbcc9d66f22215dc8f327a8604b47b106d2b5d8/pyforce_rl-0.0.6-py3-none-any.whl", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "6c919c1c42afc7449fc6e02c902acf16", "sha256": "cf033d443a12a70aaffab3a4ff93f12bffd3f6c97d0e068b56add3d57a64e8fe"}, "downloads": -1, "filename": "pyforce_rl-0.0.7-py3-none-any.whl", "has_sig": false, "md5_digest": "6c919c1c42afc7449fc6e02c902acf16", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17267, "upload_time": "2020-04-14T07:30:12", "upload_time_iso_8601": "2020-04-14T07:30:12.141470Z", "url": "https://files.pythonhosted.org/packages/ca/77/ccf47fe31599075f43b578cd910ec7c11808a3033dc850cd55ddf359e1c0/pyforce_rl-0.0.7-py3-none-any.whl", "yanked": false}], "0.0.8": [{"comment_text": "", "digests": {"md5": "4e9ae913f14a163710d837c8f5bd4343", "sha256": "44426cd9b7df80cf8f5a4bc15f74c70878d367459342c82512ab3e398b5d2b20"}, "downloads": -1, "filename": "pyforce_rl-0.0.8-py3-none-any.whl", "has_sig": false, "md5_digest": "4e9ae913f14a163710d837c8f5bd4343", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17399, "upload_time": "2020-04-14T08:00:32", "upload_time_iso_8601": "2020-04-14T08:00:32.576733Z", "url": "https://files.pythonhosted.org/packages/7a/c2/9aaa5b061ce84d5bc82d939ec066cbad2416bee49dde3a4d1b3b97b9fbfb/pyforce_rl-0.0.8-py3-none-any.whl", "yanked": false}], "0.0.9": [{"comment_text": "", "digests": {"md5": "a019c30c62612505519b41347826c4fa", "sha256": "79a6efb4797dbf47d63301b5618c2d646a4d1d7543a87620e67cf86c6a047354"}, "downloads": -1, "filename": "pyforce_rl-0.0.9-py3-none-any.whl", "has_sig": false, "md5_digest": "a019c30c62612505519b41347826c4fa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17407, "upload_time": "2020-04-15T21:13:00", "upload_time_iso_8601": "2020-04-15T21:13:00.419605Z", "url": "https://files.pythonhosted.org/packages/c8/5a/7fb069ac5b646060535318a490ed1a98f23d3118da70f46182d82f86ea6a/pyforce_rl-0.0.9-py3-none-any.whl", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7d36de9d8cb2cb5e73e0e16c6f1f4311", "sha256": "dc6f7d9a89d0f5e602bc7454dd76d1eb54b11d17c6299c3104ee6da85b5f9e01"}, "downloads": -1, "filename": "pyforce_rl-0.0.10-py3-none-any.whl", "has_sig": false, "md5_digest": "7d36de9d8cb2cb5e73e0e16c6f1f4311", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17395, "upload_time": "2020-05-05T08:55:12", "upload_time_iso_8601": "2020-05-05T08:55:12.429344Z", "url": "https://files.pythonhosted.org/packages/b0/31/363d98e52fefa10bafcac1bf21d0d3e1308d9716244fb7743d46d58cc4e5/pyforce_rl-0.0.10-py3-none-any.whl", "yanked": false}], "timestamp": "Fri May  8 03:05:36 2020"}