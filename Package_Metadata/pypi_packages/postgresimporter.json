{"info": {"author": "romnn", "author_email": "contact@romnn.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3 :: Only", "Topic :: Software Development :: Build Tools"], "description": "postgresimporter\n----------------\n\n\n.. image:: https://travis-ci.com/romnnn/postgresimporter.svg?branch=master\n   :target: https://travis-ci.com/romnnn/postgresimporter\n   :alt: Build Status\n\n\n.. image:: https://img.shields.io/pypi/l/postgresimporter\n   :target: https://pypi.org/project/postgresimporter/\n   :alt: PyPI License\n\n\n.. image:: https://img.shields.io/pypi/v/postgresimporter\n   :target: https://pypi.org/project/postgresimporter/\n   :alt: PyPI Version\n\n\n.. image:: https://img.shields.io/pypi/pyversions/postgresimporter\n   :target: https://pypi.org/project/postgresimporter/\n   :alt: PyPI Python versions\n\n\nThis repository provides a python wrapper script based on `pgfutter <https://github.com/lukasmartinelli/pgfutter>`_\nto load dumped csv data into a ``postgres`` database. It exposes customization hooks\nand comes as a container or standalone script.\n\nInstallation\n~~~~~~~~~~~~\n\n**Note**\\ : If you want to use ``docker``\\ , skip installation and see below.\n\n.. code-block:: bash\n\n   pip install postgresimporter # using pip\n   pipx install postgresimporter # using pipx\n\nUsage\n~~~~~\n\nPIP\n\"\"\"\n\nIf you installed the python executable and already have a local postgres database running, run\n\n.. code-block:: bash\n\n   postgresimporter \\\n       path/to/my/csv/files \\\n       --db-host=localhost \\\n       --db-port=5432 \\\n       --db-user=postgres \\\n       --db-password=example \\\n       --combine-tables \\\n       --exclude-regex=\"^.*sample.*$\" \\\n       --post-load path/to/my/hooks/post-load.sql\n\nDocker\n\"\"\"\"\"\"\n\nThe same command when using the ``docker`` container looks like this:\n\n.. code-block:: bash\n\n   docker run \\\n       --network host \\\n       -v path/to/my/csv/files:/import \\\n       -v path/to/my/hooks/post-load.sql:/post-load.sql \\\n       -e DB_HOST=localhost \\\n       -e DB_PORT=5432 \\\n       -e DB_USER=postgres \\\n       -e DB_PASSWORD=example \\\n       romnn/postgresimporter \\\n       --post-load=/post-load.sql --combine-tables --exclude-regex=\"^.*sample.*$\" /import\n\n*Note*\\ : When using ``docker``\\ , environment variables (\\ ``-e``\\ ) must be used in favor of command \nline arguments for specifying database connection parameters.\n\nThe tools will scan the ``sources`` directory you specify for any ``.zip`` files and unzip them.\nAfterwards, it will scan for any ``.csv`` files and load them into a table named just like the \nfile. Afterwards, it will try to combine any tables with the same prefix. \n\nUsage\n~~~~~\n\nSee ``--help`` for **Configuration options**.\n\nIf you want to spawn a complete setup including the loader, a ``postgres`` database and\n``pgadmin`` as a postgres admin UI, you can use the provided ``docker-compose`` config:\n\n.. code-block:: bash\n\n   docker-compose -f deployment/postgresimporter.compose.yml -f deployment/postgres.compose.yml up\n   docker-compose -f deployment/postgresimporter.compose.yml -f deployment/postgres.compose.yml down\n\nTo specify arguments for the ``postgresimporter``\\ , modify ``deployment/postgresimporter.compose.yml``.\n\n**Notice**\\ : Before using the provided database container, make sure to stop any already running instances of postgres.\nWhen using linux, do:\n\n.. code-block::\n\n   sudo /etc/init.d/postgresql stop\n\nHooks\n~~~~~\n\nThe tool comes with some example hooks and the ability to add your own hooks scripts.\nYou might have a file ``importdir/animals_1.csv`` and ``importdir/animals_2.csv`` that looks like this:\n\n.. code-block::\n\n   name,origin,height\n   Grizzly,\"North America\",220\n   Giraffe,\"Africa\",600\n   Wallabie,\"Australia\",180\n\nAfter importing ``importdir/``\\ , you will have three tables:\n\n.. list-table::\n   :header-rows: 1\n\n   * - Table\n     - Content\n   * - ``import.animals``\n     - ``importdir/animals_1`` and ``importdir/animals_2`` combined\n   * - ``import.animals_1``\n     - All from ``importdir/animals_1.csv``\n   * - ``import.animals_2``\n     - All from ``importdir/animals_2.csv``\n\n\nAll of these tables will have the schema defined by the csv file.\nHowever, all values will naturally be of type ``text``.\nWith the ``--post-load`` you might want to execute a post load sql script that defines\na typed table and inserts the data like so:\n\n.. code-block:: postgresql\n\n   CREATE TABLE public.animals (\n       name VARCHAR(200) PRIMARY KEY,\n       origin VARCHAR(200),\n       height INTEGER\n   );\n\n   INSERT INTO public.animals\n   SELECT name, origin, height::int\n   FROM import.animals\n\nConfiguration options\n~~~~~~~~~~~~~~~~~~~~~\n\n.. list-table::\n   :header-rows: 1\n\n   * - Option\n     - Description\n     - Default\n     - Required\n   * - ``sources``\n     - List of csv files to load. Entries can either be directories or files.\n     - None\n     - yes\n   * - ``--disable-unzip``\n     - Disables unzipping of any ``*.zip`` archives in the source directory\n     - False\n     - no\n   * - ``--disable-import``\n     - Disables import of any ``*.csv`` files into the database\n     - False\n     - no\n   * - ``--disable-check``\n     - Disables checking csv row count and database row count after import\n     - False\n     - no\n   * - ``--combine-tables``\n     - Enabled combining of imported csv file tables into one table named by prefix (e.g. weather_1 & weather_2 -> weather)\n     - False\n     - no\n   * - ``--exclude-regex``\n     - Files matching this regex will not be processed\n     - None\n     - no\n   * - ``--pre-load``\n     - List of ``*.sql`` scripts to be executed before importing into the database (e.g. to clean the database). Entries can either be directories or files.\n     - None\n     - no\n   * - ``--post-load``\n     - List of ``*.sql`` scripts to be executed after import (e.g. normalization). . Entries can either be directories or files.\n     - None\n     - no\n   * - ``--all``\n     - Unzip and import all archives and zip files again\n     - False\n     - no\n   * - ``--db-name``\n     - PostgreSQL database name\n     - postgres\n     - no\n   * - ``--db-host``\n     - PostgreSQL database host\n     - localhost\n     - no\n   * - ``--db-port``\n     - PostgreSQL database port\n     - 5432\n     - no\n   * - ``--db-user``\n     - PostgreSQL database user\n     - postgres\n     - no\n   * - ``--db-password``\n     - PostgreSQL database password\n     - None\n     - no\n   * - ``--log-level``\n     - Log level (DEBUG, INFO, WARNING, ERROR or FATAL)\n     - INFO\n     - no\n\n\nNote: You can also specify database connection settings via ``DB_NAME``\\ , ``DB_HOST``\\ , ``DB_PORT``\\ , ``DB_USER`` and ``DB_PASSWORD`` environment variables.\n\nLocal installation\n~~~~~~~~~~~~~~~~~~\n\nClone this repository and run (assuming you have ``python`` 3.5+ and \n`pgfutter <https://github.com/lukasmartinelli/pgfutter>`_ installed):\n\n.. code-block:: bash\n\n   pip install -r requirements.txt  # using pip\n   pipenv install --dev  # or using pipenv\n\nDevelopment\n~~~~~~~~~~~\n\nIf you do not have ``pipx`` and ``pipenv``\\ , install with\n\n.. code-block:: bash\n\n   python3 -m pip install --user pipx\n   python3 -m pipx ensurepath\n   pipx install pipenv\n\nInstall all dependencies with\n\n.. code-block:: bash\n\n   pipenv install --dev\n\nTo format, sort imports and check PEP8 conformity, run\n\n.. code-block:: bash\n\n   pipenv run black .\n   pipenv run isort\n   pipenv run flake8\n\nThese above checks are also configured as a git pre commit hook together with the TestSuite.\nBefore you commit, make sure to run ``./pre-commit.sh`` to resolve any\nerrors in advance.\n\nAfter merging new changes, a new version is deployed to `pypi.org <https://pypi.org>`_ when the version is tagged\nwith ``bump2version (patch|minor|major)``.\n\nTesting\n~~~~~~~\n\nThis project is not under active maintenance and not tested for production use.\nHowever, a small test suite is provided and can be run with:\n\n.. code-block:: bash\n\n   python -m postgresimporter.tests.run_tests", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/romnnn/postgresimporter", "keywords": "postgres,PostgreSQL,database,import,load,dump,CSV", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "postgresimporter", "package_url": "https://pypi.org/project/postgresimporter/", "platform": "", "project_url": "https://pypi.org/project/postgresimporter/", "project_urls": {"Homepage": "https://github.com/romnnn/postgresimporter"}, "release_url": "https://pypi.org/project/postgresimporter/1.0.0/", "requires_dist": null, "requires_python": "", "summary": "A simple python wrapper script based on pgfutter to load multiple dumped csv files into a postgres database.", "version": "1.0.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://travis-ci.com/romnnn/postgresimporter\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/95588060a6d9dbef9965379297d26d0eff773d20/68747470733a2f2f7472617669732d63692e636f6d2f726f6d6e6e6e2f706f737467726573696d706f727465722e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pypi.org/project/postgresimporter/\" rel=\"nofollow\"><img alt=\"PyPI License\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/6e1b8af6418aba5d4325096b71bf58599c34a64d/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f706f737467726573696d706f72746572\"></a>\n<a href=\"https://pypi.org/project/postgresimporter/\" rel=\"nofollow\"><img alt=\"PyPI Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/32c87fb0f780b8091baed049432c283c16d4f3f2/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f706f737467726573696d706f72746572\"></a>\n<a href=\"https://pypi.org/project/postgresimporter/\" rel=\"nofollow\"><img alt=\"PyPI Python versions\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/afdc93739a9cb88a73aef61d5d2ae173cb043c6f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f706f737467726573696d706f72746572\"></a>\n<p>This repository provides a python wrapper script based on <a href=\"https://github.com/lukasmartinelli/pgfutter\" rel=\"nofollow\">pgfutter</a>\nto load dumped csv data into a <tt>postgres</tt> database. It exposes customization hooks\nand comes as a container or standalone script.</p>\n<div id=\"installation\">\n<h2>Installation</h2>\n<p><strong>Note</strong>: If you want to use <tt>docker</tt>, skip installation and see below.</p>\n<pre>pip install postgresimporter <span class=\"c1\"># using pip\n</span>pipx install postgresimporter <span class=\"c1\"># using pipx</span>\n</pre>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<div id=\"pip\">\n<h3>PIP</h3>\n<p>If you installed the python executable and already have a local postgres database running, run</p>\n<pre>postgresimporter <span class=\"se\">\\\n</span>    path/to/my/csv/files <span class=\"se\">\\\n</span>    --db-host<span class=\"o\">=</span>localhost <span class=\"se\">\\\n</span>    --db-port<span class=\"o\">=</span><span class=\"m\">5432</span> <span class=\"se\">\\\n</span>    --db-user<span class=\"o\">=</span>postgres <span class=\"se\">\\\n</span>    --db-password<span class=\"o\">=</span>example <span class=\"se\">\\\n</span>    --combine-tables <span class=\"se\">\\\n</span>    --exclude-regex<span class=\"o\">=</span><span class=\"s2\">\"^.*sample.*</span>$<span class=\"s2\">\"</span> <span class=\"se\">\\\n</span>    --post-load path/to/my/hooks/post-load.sql\n</pre>\n</div>\n<div id=\"docker\">\n<h3>Docker</h3>\n<p>The same command when using the <tt>docker</tt> container looks like this:</p>\n<pre>docker run <span class=\"se\">\\\n</span>    --network host <span class=\"se\">\\\n</span>    -v path/to/my/csv/files:/import <span class=\"se\">\\\n</span>    -v path/to/my/hooks/post-load.sql:/post-load.sql <span class=\"se\">\\\n</span>    -e <span class=\"nv\">DB_HOST</span><span class=\"o\">=</span>localhost <span class=\"se\">\\\n</span>    -e <span class=\"nv\">DB_PORT</span><span class=\"o\">=</span><span class=\"m\">5432</span> <span class=\"se\">\\\n</span>    -e <span class=\"nv\">DB_USER</span><span class=\"o\">=</span>postgres <span class=\"se\">\\\n</span>    -e <span class=\"nv\">DB_PASSWORD</span><span class=\"o\">=</span>example <span class=\"se\">\\\n</span>    romnn/postgresimporter <span class=\"se\">\\\n</span>    --post-load<span class=\"o\">=</span>/post-load.sql --combine-tables --exclude-regex<span class=\"o\">=</span><span class=\"s2\">\"^.*sample.*</span>$<span class=\"s2\">\"</span> /import\n</pre>\n<p><em>Note</em>: When using <tt>docker</tt>, environment variables (<tt><span class=\"pre\">-e</span></tt>) must be used in favor of command\nline arguments for specifying database connection parameters.</p>\n<p>The tools will scan the <tt>sources</tt> directory you specify for any <tt>.zip</tt> files and unzip them.\nAfterwards, it will scan for any <tt>.csv</tt> files and load them into a table named just like the\nfile. Afterwards, it will try to combine any tables with the same prefix.</p>\n</div>\n</div>\n<div id=\"id1\">\n<h2>Usage</h2>\n<p>See <tt><span class=\"pre\">--help</span></tt> for <strong>Configuration options</strong>.</p>\n<p>If you want to spawn a complete setup including the loader, a <tt>postgres</tt> database and\n<tt>pgadmin</tt> as a postgres admin UI, you can use the provided <tt><span class=\"pre\">docker-compose</span></tt> config:</p>\n<pre>docker-compose -f deployment/postgresimporter.compose.yml -f deployment/postgres.compose.yml up\ndocker-compose -f deployment/postgresimporter.compose.yml -f deployment/postgres.compose.yml down\n</pre>\n<p>To specify arguments for the <tt>postgresimporter</tt>, modify <tt>deployment/postgresimporter.compose.yml</tt>.</p>\n<p><strong>Notice</strong>: Before using the provided database container, make sure to stop any already running instances of postgres.\nWhen using linux, do:</p>\n<pre>sudo /etc/init.d/postgresql stop\n</pre>\n</div>\n<div id=\"hooks\">\n<h2>Hooks</h2>\n<p>The tool comes with some example hooks and the ability to add your own hooks scripts.\nYou might have a file <tt>importdir/animals_1.csv</tt> and <tt>importdir/animals_2.csv</tt> that looks like this:</p>\n<pre>name,origin,height\nGrizzly,\"North America\",220\nGiraffe,\"Africa\",600\nWallabie,\"Australia\",180\n</pre>\n<p>After importing <tt>importdir/</tt>, you will have three tables:</p>\n<table>\n<colgroup>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Table</th>\n<th>Content</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><tt>import.animals</tt></td>\n<td><tt>importdir/animals_1</tt> and <tt>importdir/animals_2</tt> combined</td>\n</tr>\n<tr><td><tt>import.animals_1</tt></td>\n<td>All from <tt>importdir/animals_1.csv</tt></td>\n</tr>\n<tr><td><tt>import.animals_2</tt></td>\n<td>All from <tt>importdir/animals_2.csv</tt></td>\n</tr>\n</tbody>\n</table>\n<p>All of these tables will have the schema defined by the csv file.\nHowever, all values will naturally be of type <tt>text</tt>.\nWith the <tt><span class=\"pre\">--post-load</span></tt> you might want to execute a post load sql script that defines\na typed table and inserts the data like so:</p>\n<pre><span class=\"k\">CREATE</span> <span class=\"k\">TABLE</span> <span class=\"n\">public</span><span class=\"mf\">.</span><span class=\"n\">animals</span> <span class=\"p\">(</span>\n    <span class=\"k\">name</span> <span class=\"nb\">VARCHAR</span><span class=\"p\">(</span><span class=\"mf\">200</span><span class=\"p\">)</span> <span class=\"k\">PRIMARY</span> <span class=\"k\">KEY</span><span class=\"p\">,</span>\n    <span class=\"n\">origin</span> <span class=\"nb\">VARCHAR</span><span class=\"p\">(</span><span class=\"mf\">200</span><span class=\"p\">),</span>\n    <span class=\"n\">height</span> <span class=\"nb\">INTEGER</span>\n<span class=\"p\">);</span>\n\n<span class=\"k\">INSERT</span> <span class=\"k\">INTO</span> <span class=\"n\">public</span><span class=\"mf\">.</span><span class=\"n\">animals</span>\n<span class=\"k\">SELECT</span> <span class=\"k\">name</span><span class=\"p\">,</span> <span class=\"n\">origin</span><span class=\"p\">,</span> <span class=\"n\">height</span><span class=\"o\">::</span><span class=\"nb\">int</span>\n<span class=\"k\">FROM</span> <span class=\"n\">import</span><span class=\"mf\">.</span><span class=\"n\">animals</span>\n</pre>\n</div>\n<div id=\"configuration-options\">\n<h2>Configuration options</h2>\n<table>\n<colgroup>\n<col>\n<col>\n<col>\n<col>\n</colgroup>\n<thead>\n<tr><th>Option</th>\n<th>Description</th>\n<th>Default</th>\n<th>Required</th>\n</tr>\n</thead>\n<tbody>\n<tr><td><tt>sources</tt></td>\n<td>List of csv files to load. Entries can either be directories or files.</td>\n<td>None</td>\n<td>yes</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--disable-unzip</span></tt></td>\n<td>Disables unzipping of any <tt>*.zip</tt> archives in the source directory</td>\n<td>False</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--disable-import</span></tt></td>\n<td>Disables import of any <tt>*.csv</tt> files into the database</td>\n<td>False</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--disable-check</span></tt></td>\n<td>Disables checking csv row count and database row count after import</td>\n<td>False</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--combine-tables</span></tt></td>\n<td>Enabled combining of imported csv file tables into one table named by prefix (e.g. weather_1 &amp; weather_2 -&gt; weather)</td>\n<td>False</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--exclude-regex</span></tt></td>\n<td>Files matching this regex will not be processed</td>\n<td>None</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--pre-load</span></tt></td>\n<td>List of <tt>*.sql</tt> scripts to be executed before importing into the database (e.g. to clean the database). Entries can either be directories or files.</td>\n<td>None</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--post-load</span></tt></td>\n<td>List of <tt>*.sql</tt> scripts to be executed after import (e.g. normalization). . Entries can either be directories or files.</td>\n<td>None</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--all</span></tt></td>\n<td>Unzip and import all archives and zip files again</td>\n<td>False</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--db-name</span></tt></td>\n<td>PostgreSQL database name</td>\n<td>postgres</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--db-host</span></tt></td>\n<td>PostgreSQL database host</td>\n<td>localhost</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--db-port</span></tt></td>\n<td>PostgreSQL database port</td>\n<td>5432</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--db-user</span></tt></td>\n<td>PostgreSQL database user</td>\n<td>postgres</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--db-password</span></tt></td>\n<td>PostgreSQL database password</td>\n<td>None</td>\n<td>no</td>\n</tr>\n<tr><td><tt><span class=\"pre\">--log-level</span></tt></td>\n<td>Log level (DEBUG, INFO, WARNING, ERROR or FATAL)</td>\n<td>INFO</td>\n<td>no</td>\n</tr>\n</tbody>\n</table>\n<p>Note: You can also specify database connection settings via <tt>DB_NAME</tt>, <tt>DB_HOST</tt>, <tt>DB_PORT</tt>, <tt>DB_USER</tt> and <tt>DB_PASSWORD</tt> environment variables.</p>\n</div>\n<div id=\"local-installation\">\n<h2>Local installation</h2>\n<p>Clone this repository and run (assuming you have <tt>python</tt> 3.5+ and\n<a href=\"https://github.com/lukasmartinelli/pgfutter\" rel=\"nofollow\">pgfutter</a> installed):</p>\n<pre>pip install -r requirements.txt  <span class=\"c1\"># using pip\n</span>pipenv install --dev  <span class=\"c1\"># or using pipenv</span>\n</pre>\n</div>\n<div id=\"development\">\n<h2>Development</h2>\n<p>If you do not have <tt>pipx</tt> and <tt>pipenv</tt>, install with</p>\n<pre>python3 -m pip install --user pipx\npython3 -m pipx ensurepath\npipx install pipenv\n</pre>\n<p>Install all dependencies with</p>\n<pre>pipenv install --dev\n</pre>\n<p>To format, sort imports and check PEP8 conformity, run</p>\n<pre>pipenv run black .\npipenv run isort\npipenv run flake8\n</pre>\n<p>These above checks are also configured as a git pre commit hook together with the TestSuite.\nBefore you commit, make sure to run <tt><span class=\"pre\">./pre-commit.sh</span></tt> to resolve any\nerrors in advance.</p>\n<p>After merging new changes, a new version is deployed to <a href=\"https://pypi.org\" rel=\"nofollow\">pypi.org</a> when the version is tagged\nwith <tt>bump2version (patch|minor|major)</tt>.</p>\n</div>\n<div id=\"testing\">\n<h2>Testing</h2>\n<p>This project is not under active maintenance and not tested for production use.\nHowever, a small test suite is provided and can be run with:</p>\n<pre>python -m postgresimporter.tests.run_tests\n</pre>\n</div>\n\n          </div>"}, "last_serial": 6347666, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "e02c2d194a2f59e1b3d1b82513b25340", "sha256": "524aeea12a6c30304825b21061f19eb9db9af9a40ae6de12200cfc16bc6561be"}, "downloads": -1, "filename": "postgresimporter-0.1.0.tar.gz", "has_sig": false, "md5_digest": "e02c2d194a2f59e1b3d1b82513b25340", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 11981, "upload_time": "2019-12-03T06:22:48", "upload_time_iso_8601": "2019-12-03T06:22:48.946516Z", "url": "https://files.pythonhosted.org/packages/08/70/ca27b69f7227a67af2a2dff8130a6e8de8a366761c2dbcd1fc71bfde0bc2/postgresimporter-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "3761cc0565f834ac45f51f9edf86ef9b", "sha256": "6a113afb83f78982e5394d56bc37e28abf7a744e5ecd285434d5f64f81323006"}, "downloads": -1, "filename": "postgresimporter-0.1.1.tar.gz", "has_sig": false, "md5_digest": "3761cc0565f834ac45f51f9edf86ef9b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12053, "upload_time": "2019-12-03T06:37:04", "upload_time_iso_8601": "2019-12-03T06:37:04.918334Z", "url": "https://files.pythonhosted.org/packages/39/e0/83da3e5d0a2f4c4d694b735de589881c6e09da03b9a23b3353e118efd90f/postgresimporter-0.1.1.tar.gz", "yanked": false}], "0.1.2": [{"comment_text": "", "digests": {"md5": "41c5a860b834328701a7b29354309a57", "sha256": "03a5cf660d5f95fccc3da7d711460ba69b33150cbae986d11b4b425e69b7fdab"}, "downloads": -1, "filename": "postgresimporter-0.1.2.tar.gz", "has_sig": false, "md5_digest": "41c5a860b834328701a7b29354309a57", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12118, "upload_time": "2019-12-04T12:38:16", "upload_time_iso_8601": "2019-12-04T12:38:16.961769Z", "url": "https://files.pythonhosted.org/packages/1e/19/8e48f6abdd074c801abeaf9314ef0f4d43f103f765fbb2fec402b35c6f42/postgresimporter-0.1.2.tar.gz", "yanked": false}], "0.1.3": [{"comment_text": "", "digests": {"md5": "86827b49c095d759c2785150e5acfd78", "sha256": "1aeca816e29533b926d5edc87cfca194f5926a8fad5ac0d6df7090b8a02c0ce4"}, "downloads": -1, "filename": "postgresimporter-0.1.3.tar.gz", "has_sig": false, "md5_digest": "86827b49c095d759c2785150e5acfd78", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12285, "upload_time": "2019-12-22T15:34:39", "upload_time_iso_8601": "2019-12-22T15:34:39.075166Z", "url": "https://files.pythonhosted.org/packages/c7/7f/beb53ad49a0d456efdd952707a969cf31618e8dc42b85b4e3a6b6f88f294/postgresimporter-0.1.3.tar.gz", "yanked": false}], "0.1.4": [{"comment_text": "", "digests": {"md5": "979f23ef4643d7f2145c87b595391296", "sha256": "3e3c51d689cd74fa7ba21ef23c53ceea46844de2e4d0bdbf82732dcff1959242"}, "downloads": -1, "filename": "postgresimporter-0.1.4.tar.gz", "has_sig": false, "md5_digest": "979f23ef4643d7f2145c87b595391296", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12286, "upload_time": "2019-12-22T15:34:40", "upload_time_iso_8601": "2019-12-22T15:34:40.515809Z", "url": "https://files.pythonhosted.org/packages/04/b0/49b3f2c48bcd51e8bb520f4c43e67a5dc9515df68954ef5eab6ec369b616/postgresimporter-0.1.4.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "08a8dbe402579a8b8a02ed8a0beaa040", "sha256": "c04e9ec70b65ccb6730cf7722a079f801f52238c7812eb6f445ea97fc0c2170f"}, "downloads": -1, "filename": "postgresimporter-0.2.0.tar.gz", "has_sig": false, "md5_digest": "08a8dbe402579a8b8a02ed8a0beaa040", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12288, "upload_time": "2019-12-22T15:34:44", "upload_time_iso_8601": "2019-12-22T15:34:44.459473Z", "url": "https://files.pythonhosted.org/packages/02/1a/881f4e2124470f22732c75c08b98a9e1e21ff40e3696ca795f78c78f4692/postgresimporter-0.2.0.tar.gz", "yanked": false}], "1.0.0": [{"comment_text": "", "digests": {"md5": "7a64e9f0f39520cb64b8430f9eed7b1e", "sha256": "280c7801ab0719538d502e29f5b19b1a26003004a93edbc5c15f98f8bf528b61"}, "downloads": -1, "filename": "postgresimporter-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7a64e9f0f39520cb64b8430f9eed7b1e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12286, "upload_time": "2019-12-22T15:38:44", "upload_time_iso_8601": "2019-12-22T15:38:44.208311Z", "url": "https://files.pythonhosted.org/packages/31/a2/92be100953511f2998983d7223f8f9ba0b54a0059ec781805f67f951cfde/postgresimporter-1.0.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "7a64e9f0f39520cb64b8430f9eed7b1e", "sha256": "280c7801ab0719538d502e29f5b19b1a26003004a93edbc5c15f98f8bf528b61"}, "downloads": -1, "filename": "postgresimporter-1.0.0.tar.gz", "has_sig": false, "md5_digest": "7a64e9f0f39520cb64b8430f9eed7b1e", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12286, "upload_time": "2019-12-22T15:38:44", "upload_time_iso_8601": "2019-12-22T15:38:44.208311Z", "url": "https://files.pythonhosted.org/packages/31/a2/92be100953511f2998983d7223f8f9ba0b54a0059ec781805f67f951cfde/postgresimporter-1.0.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:51:20 2020"}