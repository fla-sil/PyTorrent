{"info": {"author": "Linsen Dong", "author_email": "linsen001@e.ntu.edu.sg", "bugtrack_url": null, "classifiers": [], "description": "# Baconian:  Boosting model-based reinforcement learning \n[![Build Status](https://travis-ci.com/cap-ntu/baconian-project.svg?branch=master)](https://travis-ci.com/cap-ntu/baconian-project)\n[![Documentation Status](https://readthedocs.org/projects/baconian-public/badge/?version=latest)](https://baconian-public.readthedocs.io/en/latest/?badge=latest)\n![GitHub issues](https://img.shields.io/github/issues/cap-ntu/baconian-project)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/ea83a8fef57b4d8f8c9c2590337c8bc1)](https://www.codacy.com/app/Lukeeeeee/baconian?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=Lukeeeeee/baconian&amp;utm_campaign=Badge_Grade)\n[![codecov](https://codecov.io/gh/Lukeeeeee/baconian-project/branch/master/graph/badge.svg)](https://codecov.io/gh/Lukeeeeee/baconian-project)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/m/lukeeeeee/baconian-project.svg)\n![GitHub](https://img.shields.io/github/license/Lukeeeeee/baconian-project.svg)\n\nBaconian [be\u02c8konin] is a toolbox for model-based reinforcement learning with user-friendly experiment setting-up, logging \nand visualization modules developed by [CAP](http://cap.scse.ntu.edu.sg/). We aim to develop a flexible, re-usable and \nmodularized framework that can allow the users to easily set-up their model-based RL experiments by reusing modules we \nprovide.\n### Installation \n\nYou can easily install by (with python 3.5/3.6/3.7, Ubuntu 16.04/18.04): \n```bash\n# install tensorflow with/without GPU based on your machine\npip install tensorflow-gpu==1.15.2\n# or\npip install tensorflow==1.15.2 \n\npip install baconian\n```\n\nFor more advance usage like using Mujoco environment, please refer to our documentation page.\n\n### Release news:\n- 2020.04.29 v0.2.2 Fix some memory issues in SampleData module, and simplify some APIs.\n- 2020.02.10 We are including external reward & terminal function of Gym/mujoco tasks with well-written documents.\n- 2020.01.30 Update some dependent packages versions, and release some preliminary benchmark results with hyper-parameters.\n\nFor previous news, please go [here](./old_news.md) \n\n### Documentation\nWe support python 3.5, 3.6, and 3.7 with Ubuntu 16.04 or 18.04.\nDocumentation is available at http://baconian-public.readthedocs.io/\n\n### Algorithms Reference:\n\n#### Model-based: \n\n#### 1. Dyna\nSutton, Richard S. \"Dyna, an integrated architecture for learning, planning, and reacting.\" ACM Sigart Bulletin 2.4 (1991): 160-163.\n#### 2. LQR\nAbbeel, P. \"Optimal Control for Linear Dynamical Systems and Quadratic Cost (\u2018LQR\u2019).\" (2012).\n#### 3. iLQR\nAbbeel, P. \"Optimal Control for Linear Dynamical Systems and Quadratic Cost (\u2018LQR\u2019).\" (2012).\n#### 4. MPC\nGarcia, Carlos E., David M. Prett, and Manfred Morari. \"Model predictive control: theory and practice\u2014a survey.\" Automatica 25.3 (1989): 335-348.\n#### 5. Model-ensemble\nKurutach, Thanard, et al. \"Model-ensemble trust-region policy optimization.\" arXiv preprint arXiv:1802.10592 (2018).\n\n#### Model-free\n\n#### 1. DQN\nMnih, Volodymyr, et al. \"Playing atari with deep reinforcement learning.\" arXiv preprint arXiv:1312.5602 (2013).\n#### 2. PPO\nSchulman, John, et al. \"Proximal policy optimization algorithms.\" arXiv preprint arXiv:1707.06347 (2017).\n#### 3. DDPG\nLillicrap, Timothy P., et al. \"Continuous control with deep reinforcement learning.\" arXiv preprint arXiv:1509.02971 (2015).\n\n### Algorithms in Progress\n#### 1. Random Shooting\nRao, Anil V. \"A survey of numerical methods for optimal control.\" Advances in the Astronautical Sciences 135.1 (2009): 497-528.\n#### 2. MB-MF\nNagabandi, Anusha, et al. \"Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning.\" 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2018.\n#### 3. GPS\nLevine, Sergey, et al. \"End-to-end training of deep visuomotor policies.\" The Journal of Machine Learning Research 17.1 (2016): 1334-1373.\n\n### Acknowledgement \nThanks to the following open-source projects:\n\n- garage: https://github.com/rlworkgroup/garage\n- rllab: https://github.com/rll/rllab\n- baselines: https://github.com/openai/baselines\n- gym: https://github.com/openai/gym\n- trpo: https://github.com/pat-coady/trpo\n\n### Citing Baconian\nIf you find Baconian is useful for your research, please consider cite our demo paper here:\n```\n@article{\nlinsen2019baconian, \ntitle={Baconian: A Unified Opensource Framework for Model-Based Reinforcement Learning}, \nauthor={Linsen, Dong and Guanyu, Gao and Yuanlong, Li and Yonggang, Wen}, \njournal={arXiv preprint arXiv:1904.10762},\nyear={2019} \n}\n```\n### Report an issue \nIf you find any bugs on issues, please open an issue or send an email to me \n(linsen001@e.ntu.edu.sg) with detailed information. I appreciate your help!\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/cap-ntu/baconian-project", "keywords": "", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "baconian", "package_url": "https://pypi.org/project/baconian/", "platform": "", "project_url": "https://pypi.org/project/baconian/", "project_urls": {"Homepage": "https://github.com/cap-ntu/baconian-project"}, "release_url": "https://pypi.org/project/baconian/0.2.6/", "requires_dist": ["pip (>=20.0)", "pybullet (>=2.7.4)", "absl-py (>=0.7.0)", "astor (>=0.7.1)", "cffi (>=1.12.2)", "chardet (>=3.0.4)", "Cython (>=0.29.6)", "future (>=0.17.1)", "gast (>=0.2.2)", "glfw (>=1.7.1)", "GPUtil (>=1.4.0)", "grpcio (>=1.19.0)", "gym (==0.12.0)", "h5py (>=2.9.0)", "json-tricks (>=3.13.0)", "lockfile (>=0.12.2)", "Markdown (>=3.0.1)", "numpy (>=1.16.2)", "overrides (>=1.9)", "pbr (>=5.1.3)", "Pillow (>=5.4.1)", "pycparser (>=2.19)", "pyglet (>=1.3.2)", "PyOpenGL (>=3.1.0)", "requests (>=2.21.0)", "scipy (>=1.2.1)", "six (>=1.12.0)", "setuptools (>=41.0.0)", "tensorflow-probability (==0.7.0)", "transitions (>=0.6.9)", "typeguard (>=2.1.0)", "urllib3 (>=1.24.2)", "Werkzeug (>=0.15.3)", "coverage (>=4.5.2)", "codecov (>=2.0.15)", "pandas (>=0.24.2)", "autograd (>=1.2)", "gpflow (==1.4.1)", "matplotlib (>=3.0.3)", "seaborn (>=0.9.0)", "roboschool (==1.0.48)", "opencv-python (>=4.1.0.25)", "scikit-learn (>=0.21.1)", "atari-py (>=0.1.14)"], "requires_python": ">=3.5", "summary": "model-based reinforcement learning toolbox", "version": "0.2.6", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Baconian:  Boosting model-based reinforcement learning</h1>\n<p><a href=\"https://travis-ci.com/cap-ntu/baconian-project\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/46a89a5cc4b7d24dfb1cdf233655c6de4fca7b9e/68747470733a2f2f7472617669732d63692e636f6d2f6361702d6e74752f6261636f6e69616e2d70726f6a6563742e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://baconian-public.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img alt=\"Documentation Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b6af35a3ad3636fcb195acbbfea2818dcf654b85/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6261636f6e69616e2d7075626c69632f62616467652f3f76657273696f6e3d6c6174657374\"></a>\n<img alt=\"GitHub issues\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7cf1301f261a08c24b42cfd91c2d716c4a117cb1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6361702d6e74752f6261636f6e69616e2d70726f6a656374\">\n<a href=\"https://www.codacy.com/app/Lukeeeeee/baconian?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=Lukeeeeee/baconian&amp;utm_campaign=Badge_Grade\" rel=\"nofollow\"><img alt=\"Codacy Badge\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/5df3a0290ce30a1291d1c4fb9c3341e28fce3ab9/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6561383361386665663537623464386638633963323539303333376338626331\"></a>\n<a href=\"https://codecov.io/gh/Lukeeeeee/baconian-project\" rel=\"nofollow\"><img alt=\"codecov\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/898a5d8256fab435235beabe6098b51c0f355451/68747470733a2f2f636f6465636f762e696f2f67682f4c756b6565656565652f6261636f6e69616e2d70726f6a6563742f6272616e63682f6d61737465722f67726170682f62616467652e737667\"></a>\n<img alt=\"GitHub commit activity\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/9abf58d12d8f57975d4df85f8baf9095d1957042/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6c756b6565656565652f6261636f6e69616e2d70726f6a6563742e737667\">\n<img alt=\"GitHub\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/37a86dcff87df87401bf4d6feca2c460812026be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4c756b6565656565652f6261636f6e69616e2d70726f6a6563742e737667\"></p>\n<p>Baconian [be\u02c8konin] is a toolbox for model-based reinforcement learning with user-friendly experiment setting-up, logging\nand visualization modules developed by <a href=\"http://cap.scse.ntu.edu.sg/\" rel=\"nofollow\">CAP</a>. We aim to develop a flexible, re-usable and\nmodularized framework that can allow the users to easily set-up their model-based RL experiments by reusing modules we\nprovide.</p>\n<h3>Installation</h3>\n<p>You can easily install by (with python 3.5/3.6/3.7, Ubuntu 16.04/18.04):</p>\n<pre><span class=\"c1\"># install tensorflow with/without GPU based on your machine</span>\npip install tensorflow-gpu<span class=\"o\">==</span><span class=\"m\">1</span>.15.2\n<span class=\"c1\"># or</span>\npip install <span class=\"nv\">tensorflow</span><span class=\"o\">==</span><span class=\"m\">1</span>.15.2 \n\npip install baconian\n</pre>\n<p>For more advance usage like using Mujoco environment, please refer to our documentation page.</p>\n<h3>Release news:</h3>\n<ul>\n<li>2020.04.29 v0.2.2 Fix some memory issues in SampleData module, and simplify some APIs.</li>\n<li>2020.02.10 We are including external reward &amp; terminal function of Gym/mujoco tasks with well-written documents.</li>\n<li>2020.01.30 Update some dependent packages versions, and release some preliminary benchmark results with hyper-parameters.</li>\n</ul>\n<p>For previous news, please go <a href=\"./old_news.md\" rel=\"nofollow\">here</a></p>\n<h3>Documentation</h3>\n<p>We support python 3.5, 3.6, and 3.7 with Ubuntu 16.04 or 18.04.\nDocumentation is available at <a href=\"http://baconian-public.readthedocs.io/\" rel=\"nofollow\">http://baconian-public.readthedocs.io/</a></p>\n<h3>Algorithms Reference:</h3>\n<h4>Model-based:</h4>\n<h4>1. Dyna</h4>\n<p>Sutton, Richard S. \"Dyna, an integrated architecture for learning, planning, and reacting.\" ACM Sigart Bulletin 2.4 (1991): 160-163.</p>\n<h4>2. LQR</h4>\n<p>Abbeel, P. \"Optimal Control for Linear Dynamical Systems and Quadratic Cost (\u2018LQR\u2019).\" (2012).</p>\n<h4>3. iLQR</h4>\n<p>Abbeel, P. \"Optimal Control for Linear Dynamical Systems and Quadratic Cost (\u2018LQR\u2019).\" (2012).</p>\n<h4>4. MPC</h4>\n<p>Garcia, Carlos E., David M. Prett, and Manfred Morari. \"Model predictive control: theory and practice\u2014a survey.\" Automatica 25.3 (1989): 335-348.</p>\n<h4>5. Model-ensemble</h4>\n<p>Kurutach, Thanard, et al. \"Model-ensemble trust-region policy optimization.\" arXiv preprint arXiv:1802.10592 (2018).</p>\n<h4>Model-free</h4>\n<h4>1. DQN</h4>\n<p>Mnih, Volodymyr, et al. \"Playing atari with deep reinforcement learning.\" arXiv preprint arXiv:1312.5602 (2013).</p>\n<h4>2. PPO</h4>\n<p>Schulman, John, et al. \"Proximal policy optimization algorithms.\" arXiv preprint arXiv:1707.06347 (2017).</p>\n<h4>3. DDPG</h4>\n<p>Lillicrap, Timothy P., et al. \"Continuous control with deep reinforcement learning.\" arXiv preprint arXiv:1509.02971 (2015).</p>\n<h3>Algorithms in Progress</h3>\n<h4>1. Random Shooting</h4>\n<p>Rao, Anil V. \"A survey of numerical methods for optimal control.\" Advances in the Astronautical Sciences 135.1 (2009): 497-528.</p>\n<h4>2. MB-MF</h4>\n<p>Nagabandi, Anusha, et al. \"Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning.\" 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2018.</p>\n<h4>3. GPS</h4>\n<p>Levine, Sergey, et al. \"End-to-end training of deep visuomotor policies.\" The Journal of Machine Learning Research 17.1 (2016): 1334-1373.</p>\n<h3>Acknowledgement</h3>\n<p>Thanks to the following open-source projects:</p>\n<ul>\n<li>garage: <a href=\"https://github.com/rlworkgroup/garage\" rel=\"nofollow\">https://github.com/rlworkgroup/garage</a></li>\n<li>rllab: <a href=\"https://github.com/rll/rllab\" rel=\"nofollow\">https://github.com/rll/rllab</a></li>\n<li>baselines: <a href=\"https://github.com/openai/baselines\" rel=\"nofollow\">https://github.com/openai/baselines</a></li>\n<li>gym: <a href=\"https://github.com/openai/gym\" rel=\"nofollow\">https://github.com/openai/gym</a></li>\n<li>trpo: <a href=\"https://github.com/pat-coady/trpo\" rel=\"nofollow\">https://github.com/pat-coady/trpo</a></li>\n</ul>\n<h3>Citing Baconian</h3>\n<p>If you find Baconian is useful for your research, please consider cite our demo paper here:</p>\n<pre><code>@article{\nlinsen2019baconian, \ntitle={Baconian: A Unified Opensource Framework for Model-Based Reinforcement Learning}, \nauthor={Linsen, Dong and Guanyu, Gao and Yuanlong, Li and Yonggang, Wen}, \njournal={arXiv preprint arXiv:1904.10762},\nyear={2019} \n}\n</code></pre>\n<h3>Report an issue</h3>\n<p>If you find any bugs on issues, please open an issue or send an email to me\n(<a href=\"mailto:linsen001@e.ntu.edu.sg\">linsen001@e.ntu.edu.sg</a>) with detailed information. I appreciate your help!</p>\n\n          </div>"}, "last_serial": 7143544, "releases": {"0.2.6": [{"comment_text": "", "digests": {"md5": "9358c7bcd2ca7da24cd5eff12ef108d1", "sha256": "c8839558daec21ed05e533a586e2486b8546a49e4fe5c38789a433cdd556623c"}, "downloads": -1, "filename": "baconian-0.2.6-py3-none-any.whl", "has_sig": false, "md5_digest": "9358c7bcd2ca7da24cd5eff12ef108d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 578278, "upload_time": "2020-05-01T08:55:28", "upload_time_iso_8601": "2020-05-01T08:55:28.999512Z", "url": "https://files.pythonhosted.org/packages/38/8b/ce5a268dbe530c2179dd6a08e9dc1767c8cb1abe52324627d9597ac5f796/baconian-0.2.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0f90d783c58dfc82e3f3585de0b4ef0f", "sha256": "a0b39f2ee21f4a23cd5907d1e71e9c9af6291c4f659a55f4b0ebd79546514be4"}, "downloads": -1, "filename": "baconian-0.2.6.tar.gz", "has_sig": false, "md5_digest": "0f90d783c58dfc82e3f3585de0b4ef0f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 140281, "upload_time": "2020-05-01T08:55:30", "upload_time_iso_8601": "2020-05-01T08:55:30.371684Z", "url": "https://files.pythonhosted.org/packages/82/f7/dd96bfdf2a403bdde5f246d356c4ba913b2b85eae201affa18eb029b59bd/baconian-0.2.6.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "9358c7bcd2ca7da24cd5eff12ef108d1", "sha256": "c8839558daec21ed05e533a586e2486b8546a49e4fe5c38789a433cdd556623c"}, "downloads": -1, "filename": "baconian-0.2.6-py3-none-any.whl", "has_sig": false, "md5_digest": "9358c7bcd2ca7da24cd5eff12ef108d1", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5", "size": 578278, "upload_time": "2020-05-01T08:55:28", "upload_time_iso_8601": "2020-05-01T08:55:28.999512Z", "url": "https://files.pythonhosted.org/packages/38/8b/ce5a268dbe530c2179dd6a08e9dc1767c8cb1abe52324627d9597ac5f796/baconian-0.2.6-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0f90d783c58dfc82e3f3585de0b4ef0f", "sha256": "a0b39f2ee21f4a23cd5907d1e71e9c9af6291c4f659a55f4b0ebd79546514be4"}, "downloads": -1, "filename": "baconian-0.2.6.tar.gz", "has_sig": false, "md5_digest": "0f90d783c58dfc82e3f3585de0b4ef0f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 140281, "upload_time": "2020-05-01T08:55:30", "upload_time_iso_8601": "2020-05-01T08:55:30.371684Z", "url": "https://files.pythonhosted.org/packages/82/f7/dd96bfdf2a403bdde5f246d356c4ba913b2b85eae201affa18eb029b59bd/baconian-0.2.6.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:15:05 2020"}