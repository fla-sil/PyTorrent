{"info": {"author": "Bjarke M\u00f8nsted", "author_email": "", "bugtrack_url": null, "classifiers": ["Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# ESA-Wiki\nExplicit Semantic Analysis based on Wikipedia\n\nThis is a python library which contains code to 1) construct a semantic interpreter based on data from Wikipedia and 2) apply this to various kinds of texts.\n\nTo construct an interpreter, first obtain a Wikipedia XML dump from http://dumps.wikimedia.org/enwiki/\n\n1) Then run `python3 -m esa_wiki.xml_parse <file>` with the downloaded file as its argument. This outputs some temporary files containing information on the words, links and articles encountered.\n\n2) Next, run `python3 -m esa_wiki.generate_indices` to generate lists of indices corresponding to unique words and articles encountered\n\n3) Finally, run `python3 -m esa_wiki.matrix_builder` to construct a very large sparse interpretation matrix. Each row corresponds to a unique word, each column to a 'concept', i.e. a Wikipedia article, and each entry is the TF-IDF score for word i in article j. The Matrix is saved in separate chunks to conserve memory.\n\nmedium_wiki.xml can be used as an example file for demonstration/testing purposes, as it contains only the first 100 or so Wikipedia articles.\n\ncunning_linguistics.py then contains classes to perform text analysis and harvest tweets for analysis.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "esa-wiki", "package_url": "https://pypi.org/project/esa-wiki/", "platform": "", "project_url": "https://pypi.org/project/esa-wiki/", "project_urls": null, "release_url": "https://pypi.org/project/esa-wiki/0.0.1/", "requires_dist": null, "requires_python": "", "summary": "Explicit Semantic Analysis", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>ESA-Wiki</h1>\n<p>Explicit Semantic Analysis based on Wikipedia</p>\n<p>This is a python library which contains code to 1) construct a semantic interpreter based on data from Wikipedia and 2) apply this to various kinds of texts.</p>\n<p>To construct an interpreter, first obtain a Wikipedia XML dump from <a href=\"http://dumps.wikimedia.org/enwiki/\" rel=\"nofollow\">http://dumps.wikimedia.org/enwiki/</a></p>\n<ol>\n<li>\n<p>Then run <code>python3 -m esa_wiki.xml_parse &lt;file&gt;</code> with the downloaded file as its argument. This outputs some temporary files containing information on the words, links and articles encountered.</p>\n</li>\n<li>\n<p>Next, run <code>python3 -m esa_wiki.generate_indices</code> to generate lists of indices corresponding to unique words and articles encountered</p>\n</li>\n<li>\n<p>Finally, run <code>python3 -m esa_wiki.matrix_builder</code> to construct a very large sparse interpretation matrix. Each row corresponds to a unique word, each column to a 'concept', i.e. a Wikipedia article, and each entry is the TF-IDF score for word i in article j. The Matrix is saved in separate chunks to conserve memory.</p>\n</li>\n</ol>\n<p>medium_wiki.xml can be used as an example file for demonstration/testing purposes, as it contains only the first 100 or so Wikipedia articles.</p>\n<p>cunning_linguistics.py then contains classes to perform text analysis and harvest tweets for analysis.</p>\n\n          </div>"}, "last_serial": 4894948, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "a6ab72790cf81ec66ea90b2d8f83f277", "sha256": "3571a5fe21f8692761a2f1a4f3b663f91942e878f53bc6ea2078868c5888e5ee"}, "downloads": -1, "filename": "esa_wiki-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a6ab72790cf81ec66ea90b2d8f83f277", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17323, "upload_time": "2019-03-04T15:29:51", "upload_time_iso_8601": "2019-03-04T15:29:51.406693Z", "url": "https://files.pythonhosted.org/packages/0e/e0/9d54bc3e1ddadf03eb26cd730d61f2ac13201d1d629aca0952a624ab3d4b/esa_wiki-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aa056bc065caa1de49f6a6d3d80d5790", "sha256": "78a4bd39e7d340ea8dc76fad00248d6ab1e464649b09f88909e47ac99038c0d3"}, "downloads": -1, "filename": "esa_wiki-0.0.1.tar.gz", "has_sig": false, "md5_digest": "aa056bc065caa1de49f6a6d3d80d5790", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15011, "upload_time": "2019-03-04T15:29:53", "upload_time_iso_8601": "2019-03-04T15:29:53.662232Z", "url": "https://files.pythonhosted.org/packages/a2/0e/fa497789f9a3c1a50fdba2ee60d7d765266ddaff51720d78594b7b6f9177/esa_wiki-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "a6ab72790cf81ec66ea90b2d8f83f277", "sha256": "3571a5fe21f8692761a2f1a4f3b663f91942e878f53bc6ea2078868c5888e5ee"}, "downloads": -1, "filename": "esa_wiki-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a6ab72790cf81ec66ea90b2d8f83f277", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 17323, "upload_time": "2019-03-04T15:29:51", "upload_time_iso_8601": "2019-03-04T15:29:51.406693Z", "url": "https://files.pythonhosted.org/packages/0e/e0/9d54bc3e1ddadf03eb26cd730d61f2ac13201d1d629aca0952a624ab3d4b/esa_wiki-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "aa056bc065caa1de49f6a6d3d80d5790", "sha256": "78a4bd39e7d340ea8dc76fad00248d6ab1e464649b09f88909e47ac99038c0d3"}, "downloads": -1, "filename": "esa_wiki-0.0.1.tar.gz", "has_sig": false, "md5_digest": "aa056bc065caa1de49f6a6d3d80d5790", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 15011, "upload_time": "2019-03-04T15:29:53", "upload_time_iso_8601": "2019-03-04T15:29:53.662232Z", "url": "https://files.pythonhosted.org/packages/a2/0e/fa497789f9a3c1a50fdba2ee60d7d765266ddaff51720d78594b7b6f9177/esa_wiki-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:44 2020"}