{"info": {"author": "Yuda Munarko", "author_email": "yuda.munarko@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: GNU General Public License (GPL)", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# NLIMED\nNatural Language Interface for Model Entity Discovery (NLIMED) is an interface to search model entities (i.e. flux of sodium across the basolateral plasma membrane, the concentration of potassium in the portion of tissue fluid) in the biosimulation models in repositories. The interface utilises the RDF inside biosimulation models and metadata from BioPortal. Currently, the interface can retrieve model entities from the Physiome Model Repository (PMR, https://models.physiomeproject.org) and the BioModels (https://www.ebi.ac.uk/biomodels/).\n\nIn general, NLIMED works by converting natural language query into SPARQL, so it may help users by avoiding the rigid syntax of SPARQL, query path consisting multiple predicates, and detail knowledge about ontologies.\n\nNote: model entities extracted from BioModels are those having ontologies indexed by BioPortal.\n\nLicense :: OSI Approved :: GNU General Public License (GPL)\n\n## References\nThe main reference of this work is: https://doi.org/10.1101/756304\n\nCite the following works when you implement NLIMED with parser of:\n1. CoreNLP: https://stanfordnlp.github.io/CoreNLP/citing.html\n2. NLTK: https://arxiv.org/abs/cs/0205028\n3. NCBO: https://www.ncbi.nlm.nih.gov/pubmed/21347171\n\n## Installation\nWe sugest you to install NLIMED from PyPI. If you already installed [pip](https://pip.pypa.io/en/stable/installing/), run the following command:\n  ```\n  pip install NLIMED\n  ```\nThis installation will also resolve nltk dependency.\nIn a case you already have old NLIMED installation, you may update it use:\n  ```\n  pip install NLIMED -U\n  ```\nAs an alternative, you can clone and download this github repository and use the following command:\n  ```\n  git clone https://github.com/napakalas/NLIMED.git\n  cd NLIMED\n  pip install -e .\n  ```\n\n## Configuration\n\nNLIMED implements Stanford Parser, NLTK Parser, and NCBO parser. You may select one of them for your system.\n  * NLTK Parser:\n    - NLTK is automatically deploy as a dependency.\n  * NCBO parser:\n    - You have to get a [bioportal](https://bioportal.bioontology.org/help#Getting_an_API_key) apikey  and run the NLIMED config command.\n\n  * Stanford Parser:\n    - Download the [CoreNLP](https://stanfordnlp.github.io/CoreNLP/download.html) zip file and then extract it on your deployment folder.\n\n    - Based on stanford-corenlp version downloaded, you will find a different zip file and extracted folder names. For example, in this works, we get:\n      - a zip file : stanford-corenlp-full-2018-10-05.zip\n      - a folder   : stanford-corenlp-full-2018-10-05\n\n  * **Configuring Stanford and NCBO parsers**\n    If you intent to implement NLTK only, you don't need to configure. NLIMED configuration is needed for Stanford and NCBO parsers.\n    - Configuration using command prompt or terminal, use this syntax:\n\n      ```\n      NLIMED --config --apikey {your-ncbo-api-key} --corenlp-home {CoreNLP-folder-full-path}\n      ```\n      As an example if your NCBO apikey is \"fc5d5241-1e8e-4b44-b401-310ca39573f6\" and your CoreNLP folder is \"/path/stanford-corenlp-full-2018-10-05/\", the call will be:\n      ```\n      NLIMED --config --apikey \"fc5d5241-1e8e-4b44-b401-310ca39573f6\" --corenlp-home \"/Users/user1/Documents/Stanford NLP/stanford-corenlp-full-2018-10-05/\"\n      ```\n    - Configuration usin python code, example:\n\n      ```python\n      from NLIMED import config\n      config(apikey='fc5d5241-1e8e-4b44-b401-310ca39573f6', corenlp_home='/Users/user1/Documents/Stanford NLP/stanford-corenlp-full-2018-10-05/')\n      ```\n      Show configuration:\n      ```python\n      from NLIMED import getConfig\n      getConfig()\n      ```\n\n## Issues\n\n1. When using Stanford parser, you may find the following error message:\n\n    ```\n    ...\n    requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000215465682B0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n    ```\n    The possible cause is:\n    - You are not properly configure CoreNLP folder. Please recheck the correct location and then rerun the configuration command.\n    - In some devices, CoreNLP local web services is slowly started, so it is not ready when utise by NLIMED. You can wait for a minute then rerun your command or code.\n\n    Alternative solution solution:\n    You may also start the services manually on command line or terminal. Go to your CoreNLP folder and run:\n    ```\n    java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n    ```\n    Then check the services availability on your web browser through link: http://localhost:9000/\n\n2. Any other issues please follow [issues](https://github.com/napakalas/NLIMED/issues).\n\n## Experiment\nWe conducted an experiment to measure NLIMED performance in term of:\n1. precision, recall and F-Measure\n2. comparison to NCBO Annotator, and\n3. features contribution\n\nYou can get the [experiment](https://github.com/napakalas/NLIMED/tree/master/experiment) code and DataTest from this repository. Run the code using Jupyter Notebook.\n\n## How NLIMED works?\nHere is the process inside NLIMED converting natural language query (NLQ) and SPARQL and then retrieving model entities from biomodel repositories:\n1. NLQ Annotation -- Annotating NLQ to ontologies\n  - NLQ is parsed using selected parser (Stanford, NLTK, or NCBO), resulting candidate noun phrases (CNPs).\n  - Measuring association level of each CNP to ontologies. The measurement utilises four type of textual features, i.e. preferred label, synonym, description, and local definition by this formula:\n\n    ![Image](https://raw.githubusercontent.com/napakalas/NLIMED/master/resource/Eq-NLIMED.gif?raw=true)\n\n    where:\n    - <code>p<sub>i</sub>, s<sub>i</sub>, and d<sub>i</sub></code> are the present (1) or the absent (0) of term in preffered label, synonym, and definition consecutively.\n    - <code>f<sub>i</sub></code> is the number of term in description.\n    - <code>lp<sub>i</sub>, ls<sub>i</sub>, ld<sub>i</sub>, and lf<sub>i</sub></code> are the number of terms in preffered label, synonym, definition, and description consecutively.\n    - <code>nt</code> is the number of terms in a phrase\n    - <code>N</code> is the number of ontologies having the term\n    - <code>S</code> is the number of model entities in the collection.\n    - <code>ts<sub>i</sub></code> is the number of model entities having the term\n    - <code>&alpha;, &beta;, &gamma;, and &delta;</code> are multipliers to set the features importance level. The multipliers values are decided empirically based on the repositories.\n\n  - Select CNPs with highest association, having longest term, and not overlapping with other CNP. The selected CNPs should cover all terms in NLQ.\n  - Select the top pl of ontologies from selected CNPs\n  - Combine all possible ontologies with no overlapping CNPs\n2. SPARQL Generation\n  - Construct SPARQLs for each ontotology combinations\n3. Retrieve model entities by sending each SPARQLs to model repository SPARQL endpoints.\n\n## Running NLIMED from console (query to get model entities)\nNLIMED can be run directly on command prompt or terminal. There are 2 mandatory arguments and 7 optional arguments. To get help about the required arguments, run:\n```terminal\nNLIMED -h\n```\nthen you will get:\n```terminal\nusage: NLIMED [-h] -r {pmr,bm,all} -p {stanford,nltk,ncbo} -q QUERY\n                 [-pl PL] [-s {models,sparql,annotation,verbose}] [-a ALPHA]\n                 [-b BETA] [-g GAMMA] [-d DELTA]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -r {pmr,bm,all}, --repo {pmr,bm,all}\n                        repository name\n  -p {stanford,nltk,ncbo}, --parser {stanford,nltk,ncbo}\n                        parser tool\n  -q QUERY, --query QUERY\n                        query -- any text containing words\n  -pl PL                precision level, >=1\n  -s {models,sparql,annotation,verbose}, --show {models,sparql,annotation,verbose}\n                        results presentation type\n  -a ALPHA, --alpha ALPHA\n                        Minimum alpha is 0\n  -b BETA, --beta BETA  Minimum beta is 0\n  -g GAMMA, --gamma GAMMA\n                        Minimum gamma is 0\n  -d DELTA, --delta DELTA\n                        Minimum delta is 0\n```\nHere is the description of those arguments:\n* -r {pmr,bm,all} or --repo {pmr,bm,all} (mandatory) is the name of repository. pmr is the Physiome Repository Model, bm is BioSimulations, all is for both repositories\n* -p {stanford,nltk,ncbo} or --parser {stanford,nltk,ncbo} (mandatory) is the type of parser for query annotation.\n* -q QUERY or --query QUERY (mandatory) is the query text. For a multi words query, the words should be double quoted.\n* -pl PL (optional) is precision level indicating the number of ontologies used to construct SPARQL. Larger number will utilised more ontologies which may generate more SPARQL and produce more results. Minimum value is 1. Default value is 1.\n* -s {models,sparql,annotation,verbose} or --show {models,sparql,annotation,verbose} (optional) is for selecting presented results. models shows models, sparql shows all possible SPARQLs, annotation shows annotation results, and verbore shows annotation results, SPARQLs, and models\n* -a ALPHA or --alpha ALPHA (optional) is to set up the weight of preffered label feature. Minimum alpha is 0. Default value is 4.\n* -b BETA or --beta BETA (optional) is to set up the weight of synonym feature. Minimum beta is 0. Default value is 0.7.\n-g GAMMA or --gamma GAMMA (optional) is to set up the weight of definition feature. Minimum gamma is 0. Default value is 0.5.\n-d DELTA, --delta DELTA (optional) is to set up the weight of description feature. Minimum gamma is 0. Default value is 0.8.\n\n### Running example\n* running with minimum setup for repository = Physiome Model Repository, parser = NLTK, query = \"flux of sodium\", and other default arguments values:\n  ```\n  NLIMED -r pmr -p nltk -q \"flux of sodium\"\n  ```\n* running with full setup for repository=BioModels, parser=Stanford, query=\"flux of sodium\", precision level = 2, alpha = 2, beta = 1, gamma = 1, and delta = 1\n  ```\n  NLIMED -r bm -p stanford -q \"flux of sodium\" -pl 2 -a 2 -b 1 -g 1 -d 1\n  ```\n  Note: running with Stanford parser may cause delay local server startup for the first run. However, for the next run, the delay is disappeared.\n\n* running for repository = Physiome Model Repository, parser = NCBO, query = \"flux of sodium\", precision level = 3,and other default arguments\n\n  ```\n  NLIMED -r pmr -p ncbo -q \"flux of sodium\" -pl 3\n  ```\n  Note: running with NCBO Parser parser is slower than other parsers because it is using a web service depended on the Internet connection.\n\n\n## Utilising NLIMED in your Python code\n\nThe main class for retrieving model entities from repositories is NLIMED in NLIMED.py. Utilising this class, we can annotate query into ontologies, get all possible SPARQL, and get model entities. We suggest you to create one NLIMED object for all your queries since it will reuse the loaded indexes so it can save your device resources.\n\n### Get Model Entities\nThe following codes are used to retrieve model entities from the PMR or Biomodels.\n* Returning model entities from the PMR using Stanford parser with standard setting for query: \"mitochondrial calcium ion transmembrane transport\"\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='stanford')\n  query = 'mitochondrial calcium ion transmembrane transport'\n  result = nlimed.getModels(query=query,format='json')\n\n  \"\"\"\n  where:\n  - repo : repository {'pmr','bm'}\n  - parser : parser tool {'stanford','nltk','ncbo'}\n  - query : query text\n  - format : the returning format data {'json','print'}\n  \"\"\"\n  ```\n  The code resulting a json format data consisting 27 model entities related to the query\n  ```\n  {\n    'vars': ['graph', 'Model_entity', 'desc'],\n    'results': [{\n      'graph': 'https://models.physiomeproject.org/workspace/colegrove_albrecht_friel_2000',\n      'Model_entity': 'colegrove_albrecht_friel_2000.cellml#id_00011'\n    },\n      ....\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n      'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000025'\n    },\n      ...\n    ]\n  }\n  ```\n\n* It also possible to increase the precision level, so NLIMED can show more results. Here we are returning model entities from the PMR using Stanford parser and precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8.\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='stanford', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8)\n  query = 'mitochondrial calcium ion transmembrane transport'\n  result = nlimed.getModels(query=query,format='json')\n\n  \"\"\"\n  where:\n  - repo (mandatory) : repository {'pmr','bm'}\n  - parser : parser tool {'stanford','nltk','ncbo'}\n  - pl (optional) : precision level, the minimum value is 1\n  - alpha (optional) : preffered label weight, the minimum value is 0\n  - beta (optional) : synonym weight, the minimum value is 0\n  - gamma (optional) : definition weight, the minimum value is 0\n  - delta (optional) : description weight, the minimum value is 0\n  - query : query text\n  - format : the returning format data {'json','print'}\n  \"\"\"\n  ```\n  The code resulting a json format data consisting 141 model entities related to the query\n  ```\n  {\n    'vars': ['graph', 'Model_entity', 'desc'],\n    'results': [{\n      'graph': 'https://models.physiomeproject.org/workspace/colegrove_albrecht_friel_2000',\n      'Model_entity': 'colegrove_albrecht_friel_2000.cellml#id_00011'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n      'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000025'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/winslow_rice_jafri_marban_ororke_1999',\n      'Model_entity': 'winslow_rice_jafri_marban_ororke_1999.cellml#sarcolemmal_calcium_pump_i_p_Ca'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/michailova_mcculloch_2001',\n      'Model_entity': 'michailova_mcculloch_2001.cellml#id_00118'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/hinch_greenstein_tanskanen_xu_winslow_2004',\n      'Model_entity': 'hinch_greenstein_tanskanen_xu_winslow_2004.cellml#id_00038'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/w/andre/SAN-ORd',\n      'Model_entity': 'Ohara_Rudy_2011.cellml#id_00011'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/bertram_satin_zhang_smolen_sherman_2004',\n      'Model_entity': 'bertram_satin_zhang_smolen_sherman_2004_a.cellml#calcium_handling_Jserca'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/bertram_sherman_2004',\n      'Model_entity': 'bertram_sherman_2004.cellml#id_00029'\n    }, {\n      'graph': 'https://models.physiomeproject.org/workspace/noble_2000',\n      'Model_entity': 'noble_2000_a.cellml#id_00024'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/bindschadler_sneyd_2001',\n      'Model_entity': 'bindschadler_sneyd_2001.cellml#id_00003'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/fridlyand_tamarina_philipson_2003',\n      'Model_entity': 'fridlyand_tamarina_philipson_2003.cellml#id_00025'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/puglisi_bers_2001',\n      'Model_entity': 'puglisi_bers_2001.cellml#id_00112'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/terkildsen_niederer_crampin_hunter_smith_2008',\n      'Model_entity': 'Hinch_et_al_2004.cellml#id_00010'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/55c',\n      'Model_entity': 'Hinch_et_al_2004.cellml#id_00010'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/luo_rudy_1994',\n      'Model_entity': 'luo_rudy_1994.cellml#id_00019'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n      'Model_entity': 'viswanathan_shaw_rudy_1999_a.cellml#sarcolemmal_calcium_pump_i_p_Ca'\n    }, {\n      'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n      'Model_entity': 'viswanathan_shaw_rudy_1999_a.cellml#id_00078'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/goforth_bertram_khan_zhang_sherman_satin_2002',\n      'Model_entity': 'goforth_bertram_khan_zhang_sherman_satin_2002.cellml#id_00041'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/albrecht_colegrove_friel_2002',\n      'Model_entity': 'albrecht_colegrove_friel_2002.cellml#id_00030'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n      'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000019'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/albrecht_colegrove_hongpaisan_pivovarova_andrews_friel_2001',\n      'Model_entity': 'albrecht_colegrove_hongpaisan_pivovarova_andrews_friel_2001.cellml#id_00021'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/riemer_sobie_tung_1998',\n      'Model_entity': 'riemer_sobie_tung_1998.cellml#id_00063'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/faber_rudy_2000',\n      'Model_entity': 'faber_rudy_2000.cellml#id_00074'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/jafri_rice_winslow_1998',\n      'Model_entity': 'jafri_rice_winslow_1998_a.cellml#id_00017'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/tentusscher_noble_noble_panfilov_2004',\n      'Model_entity': 'tentusscher_noble_noble_panfilov_2004_c.cellml#id_00050'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n      'Model_entity': 'viswanathan_shaw_rudy_1999_c.cellml#id_00095'\n    }]\n  }\n  ```\n* Get model entities from BioModels with standard setting using NLTK Parser:\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='bm', parser='nltk')\n  query = 'mitochondrial calcium ion transmembrane transport'\n  result = nlimed.getModels(query=query,format='json')\n  ```\n  The code produce 6 model entities:\n  ```\n  {\n  'vars': ['model', 'type', 'element', 'notes', 'name'],\n    'results': [{\n      'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354',\n      'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n      'element': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n      'name': 'UniporterFromCytosol'\n    },\n      ...\n    , {\n      'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355',\n      'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n      'element': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n      'name': 'CytToMito'\n    },\n      ...\n    ]\n  }\n  ```\n* Get model entities from BioModels with precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8 and NLTK parser\n```python\nfrom NLIMED import NLIMED\nnlimed = NLIMED(repo='bm', parser='nltk', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8)\nquery = 'mitochondrial calcium ion transmembrane transport'\nresult = nlimed.getModels(query=query,format='json')\n```\nResulting 12 model entities:\n```\n'vars': ['model', 'type', 'element', 'notes', 'name'],\n  'results': [{\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'name': 'UniporterFromCytosol'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'name': 'CytToMito'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'type': 'http://biomodels.net/biology-qualifiers#isVersionOf',\n    'element': 'http://purl.obolibrary.org/obo/GO:0006851'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'type': 'http://biomodels.net/biology-qualifiers#isVersionOf',\n    'element': 'http://purl.obolibrary.org/obo/GO:0006851'\n  },\n    ...\n  ]\n}\n```\n### Get Query Annotation\nIn a case you just need to utilise the annotation function, you can use getAnnotated function. By this, the system will not request Internet connection for SPARQL request. However, if you use NCBO Annotator, Internet connection is still required.\n* Code example to annotated query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='stanford', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8)\n  query = 'concentration of potassium in the portion of tissue fluid'\n  result = nlimed.getAnnotated(query=query,format='json')\n  ```\n  Result:\n  ```\n  {\n    'phrases': ['concentration', 'potassium', 'portion tissue fluid'],\n    'result': [\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.061734018829371\n      ]\n    ]\n  }\n  ```\n  The query is separated into three phrases, then each phrase is classify into an ontology. There is a score 5.061734018829371 indicating the weight of ontologies combination.\n\n* Code example to annotated query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser, pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='stanford', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8)\n  query = 'flux of sodium'\n  result = nlimed.getAnnotated(query=query,format='json')\n  ```\n  Result:\n  ```\n  {\n    'phrases': ['concentration', 'potassium', 'portion tissue fluid'],\n    'result': [\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.061734018829371\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.020508088576971\n      ],\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.06090745289317\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.019681522640769\n      ],\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.307255058507058\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.266029128254657\n      ],\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.3064284925708565\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.265202562318455\n      ]\n    ]\n  }\n  ```\n  Just the same as the previous result, the query is separated into three phrases, then each phrase is classify into an ontology. Since we use higher precisin level, the function presents more ontologies combination with a different score. Higher score means higher probability of relevant annotation.\n\n### Get SPARQL\nIt is also possible to get SPARQL only without model entities. It utilise getSparql function which generated all possible SPARQL based on annotation results.\n\n* Get SPARQL code for query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='stanford')\n  query = 'flux of sodium'\n  result = nlimed.getSparql(query=query,format='json')\n  ```\n  Resulting a list of SPARQL:\n  ```\n  [\n    'SELECT ?graph ?Model_entity ?desc\n      WHERE { GRAPH ?graph {\n        ?e  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/FMA_9673> .\n        ?c  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/CHEBI_29103> .\n        ?a  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://identifiers.org/opb/OPB_00340> .\n        ?Model_entity  <http://www.bhi.washington.edu/SemSim#isComputationalComponentFor> ?a .\n        ?a  <http://www.bhi.washington.edu/SemSim#physicalPropertyOf> ?c .\n        ?c  <http://www.obofoundry.org/ro/ro.owl#part_of> ?e .\n        OPTIONAL{?Model_entity <http://purl.org/dc/terms/description> ?desc .} }}'\n  ]\n  ```\n* Get SPARQL code for query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser with precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8 and NLTK parser\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='stanford', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8)\n  query = 'flux of sodium'\n  result = nlimed.getSparql(query=query,format='json')\n  ```\n  The result can be 0 or more than one SPARQL based on the RDF Graph Index.\n  ```\n  [\n  'SELECT ?graph ?Model_entity ?desc\n    WHERE { GRAPH ?graph {  ?c  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/CHEBI_29103> .\n      ?e  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/FMA_9673> .\n      ?a  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://identifiers.org/opb/OPB_00340> .\n      ?Model_entity  <http://www.bhi.washington.edu/SemSim#isComputationalComponentFor> ?a .\n      ?a  <http://www.bhi.washington.edu/SemSim#physicalPropertyOf> ?c .\n      ?c  <http://www.obofoundry.org/ro/ro.owl#part_of> ?e .\n      OPTIONAL{?Model_entity <http://purl.org/dc/terms/description> ?desc .} }}'\n  ]\n  ```\n\n## Recreate Indexes (RDF Graph Index and Text Feature Index)\n\nAll indexes are already provided in this project. However, if you want to recreate all indexes you can use the following script on command prompt or terminal. Please be patient, it may take times to be finished.\n\n### Indexing the pmr\n\n```\nNLIMED --build-index pmr\n```\n\n### Indexing biomodels\n\n```\nNLIMED --build-index bm\n```\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/napakalas/NLIMED", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "NLIMED", "package_url": "https://pypi.org/project/NLIMED/", "platform": "", "project_url": "https://pypi.org/project/NLIMED/", "project_urls": {"Homepage": "https://github.com/napakalas/NLIMED"}, "release_url": "https://pypi.org/project/NLIMED/0.0.1/", "requires_dist": ["nltk", "SPARQLWrapper"], "requires_python": "", "summary": "Natural Language Interface for Model Entity Discovery (NLIMED) is an interface to search model entities in the biosimulation models in repositories.", "version": "0.0.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>NLIMED</h1>\n<p>Natural Language Interface for Model Entity Discovery (NLIMED) is an interface to search model entities (i.e. flux of sodium across the basolateral plasma membrane, the concentration of potassium in the portion of tissue fluid) in the biosimulation models in repositories. The interface utilises the RDF inside biosimulation models and metadata from BioPortal. Currently, the interface can retrieve model entities from the Physiome Model Repository (PMR, <a href=\"https://models.physiomeproject.org\" rel=\"nofollow\">https://models.physiomeproject.org</a>) and the BioModels (<a href=\"https://www.ebi.ac.uk/biomodels/\" rel=\"nofollow\">https://www.ebi.ac.uk/biomodels/</a>).</p>\n<p>In general, NLIMED works by converting natural language query into SPARQL, so it may help users by avoiding the rigid syntax of SPARQL, query path consisting multiple predicates, and detail knowledge about ontologies.</p>\n<p>Note: model entities extracted from BioModels are those having ontologies indexed by BioPortal.</p>\n<p>License :: OSI Approved :: GNU General Public License (GPL)</p>\n<h2>References</h2>\n<p>The main reference of this work is: <a href=\"https://doi.org/10.1101/756304\" rel=\"nofollow\">https://doi.org/10.1101/756304</a></p>\n<p>Cite the following works when you implement NLIMED with parser of:</p>\n<ol>\n<li>CoreNLP: <a href=\"https://stanfordnlp.github.io/CoreNLP/citing.html\" rel=\"nofollow\">https://stanfordnlp.github.io/CoreNLP/citing.html</a></li>\n<li>NLTK: <a href=\"https://arxiv.org/abs/cs/0205028\" rel=\"nofollow\">https://arxiv.org/abs/cs/0205028</a></li>\n<li>NCBO: <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/21347171\" rel=\"nofollow\">https://www.ncbi.nlm.nih.gov/pubmed/21347171</a></li>\n</ol>\n<h2>Installation</h2>\n<p>We sugest you to install NLIMED from PyPI. If you already installed <a href=\"https://pip.pypa.io/en/stable/installing/\" rel=\"nofollow\">pip</a>, run the following command:</p>\n<pre><code>pip install NLIMED\n</code></pre>\n<p>This installation will also resolve nltk dependency.\nIn a case you already have old NLIMED installation, you may update it use:</p>\n<pre><code>pip install NLIMED -U\n</code></pre>\n<p>As an alternative, you can clone and download this github repository and use the following command:</p>\n<pre><code>git clone https://github.com/napakalas/NLIMED.git\ncd NLIMED\npip install -e .\n</code></pre>\n<h2>Configuration</h2>\n<p>NLIMED implements Stanford Parser, NLTK Parser, and NCBO parser. You may select one of them for your system.</p>\n<ul>\n<li>\n<p>NLTK Parser:</p>\n<ul>\n<li>NLTK is automatically deploy as a dependency.</li>\n</ul>\n</li>\n<li>\n<p>NCBO parser:</p>\n<ul>\n<li>You have to get a <a href=\"https://bioportal.bioontology.org/help#Getting_an_API_key\" rel=\"nofollow\">bioportal</a> apikey  and run the NLIMED config command.</li>\n</ul>\n</li>\n<li>\n<p>Stanford Parser:</p>\n<ul>\n<li>\n<p>Download the <a href=\"https://stanfordnlp.github.io/CoreNLP/download.html\" rel=\"nofollow\">CoreNLP</a> zip file and then extract it on your deployment folder.</p>\n</li>\n<li>\n<p>Based on stanford-corenlp version downloaded, you will find a different zip file and extracted folder names. For example, in this works, we get:</p>\n<ul>\n<li>a zip file : stanford-corenlp-full-2018-10-05.zip</li>\n<li>a folder   : stanford-corenlp-full-2018-10-05</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Configuring Stanford and NCBO parsers</strong>\nIf you intent to implement NLTK only, you don't need to configure. NLIMED configuration is needed for Stanford and NCBO parsers.</p>\n<ul>\n<li>\n<p>Configuration using command prompt or terminal, use this syntax:</p>\n<pre><code>NLIMED --config --apikey {your-ncbo-api-key} --corenlp-home {CoreNLP-folder-full-path}\n</code></pre>\n<p>As an example if your NCBO apikey is \"fc5d5241-1e8e-4b44-b401-310ca39573f6\" and your CoreNLP folder is \"/path/stanford-corenlp-full-2018-10-05/\", the call will be:</p>\n<pre><code>NLIMED --config --apikey \"fc5d5241-1e8e-4b44-b401-310ca39573f6\" --corenlp-home \"/Users/user1/Documents/Stanford NLP/stanford-corenlp-full-2018-10-05/\"\n</code></pre>\n</li>\n<li>\n<p>Configuration usin python code, example:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">config</span>\n<span class=\"n\">config</span><span class=\"p\">(</span><span class=\"n\">apikey</span><span class=\"o\">=</span><span class=\"s1\">'fc5d5241-1e8e-4b44-b401-310ca39573f6'</span><span class=\"p\">,</span> <span class=\"n\">corenlp_home</span><span class=\"o\">=</span><span class=\"s1\">'/Users/user1/Documents/Stanford NLP/stanford-corenlp-full-2018-10-05/'</span><span class=\"p\">)</span>\n</pre>\n<p>Show configuration:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">getConfig</span>\n<span class=\"n\">getConfig</span><span class=\"p\">()</span>\n</pre>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Issues</h2>\n<ol>\n<li>\n<p>When using Stanford parser, you may find the following error message:</p>\n<pre><code>...\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /?properties=%7B%22outputFormat%22%3A+%22json%22%2C+%22annotators%22%3A+%22tokenize%2Cpos%2Clemma%2Cssplit%2Cparse%22%2C+%22ssplit.eolonly%22%3A+%22true%22%2C+%22tokenize.whitespace%22%3A+%22false%22%7D (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x00000215465682B0&gt;: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n</code></pre>\n<p>The possible cause is:</p>\n<ul>\n<li>You are not properly configure CoreNLP folder. Please recheck the correct location and then rerun the configuration command.</li>\n<li>In some devices, CoreNLP local web services is slowly started, so it is not ready when utise by NLIMED. You can wait for a minute then rerun your command or code.</li>\n</ul>\n<p>Alternative solution solution:\nYou may also start the services manually on command line or terminal. Go to your CoreNLP folder and run:</p>\n<pre><code>java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n</code></pre>\n<p>Then check the services availability on your web browser through link: <a href=\"http://localhost:9000/\" rel=\"nofollow\">http://localhost:9000/</a></p>\n</li>\n<li>\n<p>Any other issues please follow <a href=\"https://github.com/napakalas/NLIMED/issues\" rel=\"nofollow\">issues</a>.</p>\n</li>\n</ol>\n<h2>Experiment</h2>\n<p>We conducted an experiment to measure NLIMED performance in term of:</p>\n<ol>\n<li>precision, recall and F-Measure</li>\n<li>comparison to NCBO Annotator, and</li>\n<li>features contribution</li>\n</ol>\n<p>You can get the <a href=\"https://github.com/napakalas/NLIMED/tree/master/experiment\" rel=\"nofollow\">experiment</a> code and DataTest from this repository. Run the code using Jupyter Notebook.</p>\n<h2>How NLIMED works?</h2>\n<p>Here is the process inside NLIMED converting natural language query (NLQ) and SPARQL and then retrieving model entities from biomodel repositories:</p>\n<ol>\n<li>NLQ Annotation -- Annotating NLQ to ontologies</li>\n</ol>\n<ul>\n<li>\n<p>NLQ is parsed using selected parser (Stanford, NLTK, or NCBO), resulting candidate noun phrases (CNPs).</p>\n</li>\n<li>\n<p>Measuring association level of each CNP to ontologies. The measurement utilises four type of textual features, i.e. preferred label, synonym, description, and local definition by this formula:</p>\n<p><img alt=\"Image\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/b261c2250d53943475474444d3daace0a74350ee/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6e6170616b616c61732f4e4c494d45442f6d61737465722f7265736f757263652f45712d4e4c494d45442e6769663f7261773d74727565\"></p>\n<p>where:</p>\n<ul>\n<li><code>p<sub>i</sub>, s<sub>i</sub>, and d<sub>i</sub></code> are the present (1) or the absent (0) of term in preffered label, synonym, and definition consecutively.</li>\n<li><code>f<sub>i</sub></code> is the number of term in description.</li>\n<li><code>lp<sub>i</sub>, ls<sub>i</sub>, ld<sub>i</sub>, and lf<sub>i</sub></code> are the number of terms in preffered label, synonym, definition, and description consecutively.</li>\n<li><code>nt</code> is the number of terms in a phrase</li>\n<li><code>N</code> is the number of ontologies having the term</li>\n<li><code>S</code> is the number of model entities in the collection.</li>\n<li><code>ts<sub>i</sub></code> is the number of model entities having the term</li>\n<li><code>\u03b1, \u03b2, \u03b3, and \u03b4</code> are multipliers to set the features importance level. The multipliers values are decided empirically based on the repositories.</li>\n</ul>\n</li>\n<li>\n<p>Select CNPs with highest association, having longest term, and not overlapping with other CNP. The selected CNPs should cover all terms in NLQ.</p>\n</li>\n<li>\n<p>Select the top pl of ontologies from selected CNPs</p>\n</li>\n<li>\n<p>Combine all possible ontologies with no overlapping CNPs</p>\n</li>\n</ul>\n<ol>\n<li>SPARQL Generation</li>\n</ol>\n<ul>\n<li>Construct SPARQLs for each ontotology combinations</li>\n</ul>\n<ol>\n<li>Retrieve model entities by sending each SPARQLs to model repository SPARQL endpoints.</li>\n</ol>\n<h2>Running NLIMED from console (query to get model entities)</h2>\n<p>NLIMED can be run directly on command prompt or terminal. There are 2 mandatory arguments and 7 optional arguments. To get help about the required arguments, run:</p>\n<pre>NLIMED -h\n</pre>\n<p>then you will get:</p>\n<pre>usage: NLIMED [-h] -r {pmr,bm,all} -p {stanford,nltk,ncbo} -q QUERY\n                 [-pl PL] [-s {models,sparql,annotation,verbose}] [-a ALPHA]\n                 [-b BETA] [-g GAMMA] [-d DELTA]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -r {pmr,bm,all}, --repo {pmr,bm,all}\n                        repository name\n  -p {stanford,nltk,ncbo}, --parser {stanford,nltk,ncbo}\n                        parser tool\n  -q QUERY, --query QUERY\n                        query -- any text containing words\n  -pl PL                precision level, &gt;=1\n  -s {models,sparql,annotation,verbose}, --show {models,sparql,annotation,verbose}\n                        results presentation type\n  -a ALPHA, --alpha ALPHA\n                        Minimum alpha is 0\n  -b BETA, --beta BETA  Minimum beta is 0\n  -g GAMMA, --gamma GAMMA\n                        Minimum gamma is 0\n  -d DELTA, --delta DELTA\n                        Minimum delta is 0\n</pre>\n<p>Here is the description of those arguments:</p>\n<ul>\n<li>-r {pmr,bm,all} or --repo {pmr,bm,all} (mandatory) is the name of repository. pmr is the Physiome Repository Model, bm is BioSimulations, all is for both repositories</li>\n<li>-p {stanford,nltk,ncbo} or --parser {stanford,nltk,ncbo} (mandatory) is the type of parser for query annotation.</li>\n<li>-q QUERY or --query QUERY (mandatory) is the query text. For a multi words query, the words should be double quoted.</li>\n<li>-pl PL (optional) is precision level indicating the number of ontologies used to construct SPARQL. Larger number will utilised more ontologies which may generate more SPARQL and produce more results. Minimum value is 1. Default value is 1.</li>\n<li>-s {models,sparql,annotation,verbose} or --show {models,sparql,annotation,verbose} (optional) is for selecting presented results. models shows models, sparql shows all possible SPARQLs, annotation shows annotation results, and verbore shows annotation results, SPARQLs, and models</li>\n<li>-a ALPHA or --alpha ALPHA (optional) is to set up the weight of preffered label feature. Minimum alpha is 0. Default value is 4.</li>\n<li>-b BETA or --beta BETA (optional) is to set up the weight of synonym feature. Minimum beta is 0. Default value is 0.7.\n-g GAMMA or --gamma GAMMA (optional) is to set up the weight of definition feature. Minimum gamma is 0. Default value is 0.5.\n-d DELTA, --delta DELTA (optional) is to set up the weight of description feature. Minimum gamma is 0. Default value is 0.8.</li>\n</ul>\n<h3>Running example</h3>\n<ul>\n<li>\n<p>running with minimum setup for repository = Physiome Model Repository, parser = NLTK, query = \"flux of sodium\", and other default arguments values:</p>\n<pre><code>NLIMED -r pmr -p nltk -q \"flux of sodium\"\n</code></pre>\n</li>\n<li>\n<p>running with full setup for repository=BioModels, parser=Stanford, query=\"flux of sodium\", precision level = 2, alpha = 2, beta = 1, gamma = 1, and delta = 1</p>\n<pre><code>NLIMED -r bm -p stanford -q \"flux of sodium\" -pl 2 -a 2 -b 1 -g 1 -d 1\n</code></pre>\n<p>Note: running with Stanford parser may cause delay local server startup for the first run. However, for the next run, the delay is disappeared.</p>\n</li>\n<li>\n<p>running for repository = Physiome Model Repository, parser = NCBO, query = \"flux of sodium\", precision level = 3,and other default arguments</p>\n<pre><code>NLIMED -r pmr -p ncbo -q \"flux of sodium\" -pl 3\n</code></pre>\n<p>Note: running with NCBO Parser parser is slower than other parsers because it is using a web service depended on the Internet connection.</p>\n</li>\n</ul>\n<h2>Utilising NLIMED in your Python code</h2>\n<p>The main class for retrieving model entities from repositories is NLIMED in NLIMED.py. Utilising this class, we can annotate query into ontologies, get all possible SPARQL, and get model entities. We suggest you to create one NLIMED object for all your queries since it will reuse the loaded indexes so it can save your device resources.</p>\n<h3>Get Model Entities</h3>\n<p>The following codes are used to retrieve model entities from the PMR or Biomodels.</p>\n<ul>\n<li>\n<p>Returning model entities from the PMR using Stanford parser with standard setting for query: \"mitochondrial calcium ion transmembrane transport\"</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'pmr'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'stanford'</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'mitochondrial calcium ion transmembrane transport'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getModels</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n\n<span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">where:</span>\n<span class=\"sd\">- repo : repository {'pmr','bm'}</span>\n<span class=\"sd\">- parser : parser tool {'stanford','nltk','ncbo'}</span>\n<span class=\"sd\">- query : query text</span>\n<span class=\"sd\">- format : the returning format data {'json','print'}</span>\n<span class=\"sd\">\"\"\"</span>\n</pre>\n<p>The code resulting a json format data consisting 27 model entities related to the query</p>\n<pre><code>{\n  'vars': ['graph', 'Model_entity', 'desc'],\n  'results': [{\n    'graph': 'https://models.physiomeproject.org/workspace/colegrove_albrecht_friel_2000',\n    'Model_entity': 'colegrove_albrecht_friel_2000.cellml#id_00011'\n  },\n    ....\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n    'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000025'\n  },\n    ...\n  ]\n}\n</code></pre>\n</li>\n<li>\n<p>It also possible to increase the precision level, so NLIMED can show more results. Here we are returning model entities from the PMR using Stanford parser and precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'pmr'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'stanford'</span><span class=\"p\">,</span> <span class=\"n\">pl</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">delta</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'mitochondrial calcium ion transmembrane transport'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getModels</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n\n<span class=\"sd\">\"\"\"</span>\n<span class=\"sd\">where:</span>\n<span class=\"sd\">- repo (mandatory) : repository {'pmr','bm'}</span>\n<span class=\"sd\">- parser : parser tool {'stanford','nltk','ncbo'}</span>\n<span class=\"sd\">- pl (optional) : precision level, the minimum value is 1</span>\n<span class=\"sd\">- alpha (optional) : preffered label weight, the minimum value is 0</span>\n<span class=\"sd\">- beta (optional) : synonym weight, the minimum value is 0</span>\n<span class=\"sd\">- gamma (optional) : definition weight, the minimum value is 0</span>\n<span class=\"sd\">- delta (optional) : description weight, the minimum value is 0</span>\n<span class=\"sd\">- query : query text</span>\n<span class=\"sd\">- format : the returning format data {'json','print'}</span>\n<span class=\"sd\">\"\"\"</span>\n</pre>\n<p>The code resulting a json format data consisting 141 model entities related to the query</p>\n<pre><code>{\n  'vars': ['graph', 'Model_entity', 'desc'],\n  'results': [{\n    'graph': 'https://models.physiomeproject.org/workspace/colegrove_albrecht_friel_2000',\n    'Model_entity': 'colegrove_albrecht_friel_2000.cellml#id_00011'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n    'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000025'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/winslow_rice_jafri_marban_ororke_1999',\n    'Model_entity': 'winslow_rice_jafri_marban_ororke_1999.cellml#sarcolemmal_calcium_pump_i_p_Ca'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/michailova_mcculloch_2001',\n    'Model_entity': 'michailova_mcculloch_2001.cellml#id_00118'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/hinch_greenstein_tanskanen_xu_winslow_2004',\n    'Model_entity': 'hinch_greenstein_tanskanen_xu_winslow_2004.cellml#id_00038'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/w/andre/SAN-ORd',\n    'Model_entity': 'Ohara_Rudy_2011.cellml#id_00011'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/bertram_satin_zhang_smolen_sherman_2004',\n    'Model_entity': 'bertram_satin_zhang_smolen_sherman_2004_a.cellml#calcium_handling_Jserca'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/bertram_sherman_2004',\n    'Model_entity': 'bertram_sherman_2004.cellml#id_00029'\n  }, {\n    'graph': 'https://models.physiomeproject.org/workspace/noble_2000',\n    'Model_entity': 'noble_2000_a.cellml#id_00024'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/bindschadler_sneyd_2001',\n    'Model_entity': 'bindschadler_sneyd_2001.cellml#id_00003'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/fridlyand_tamarina_philipson_2003',\n    'Model_entity': 'fridlyand_tamarina_philipson_2003.cellml#id_00025'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/puglisi_bers_2001',\n    'Model_entity': 'puglisi_bers_2001.cellml#id_00112'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/terkildsen_niederer_crampin_hunter_smith_2008',\n    'Model_entity': 'Hinch_et_al_2004.cellml#id_00010'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/55c',\n    'Model_entity': 'Hinch_et_al_2004.cellml#id_00010'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/luo_rudy_1994',\n    'Model_entity': 'luo_rudy_1994.cellml#id_00019'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n    'Model_entity': 'viswanathan_shaw_rudy_1999_a.cellml#sarcolemmal_calcium_pump_i_p_Ca'\n  }, {\n    'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n    'Model_entity': 'viswanathan_shaw_rudy_1999_a.cellml#id_00078'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/goforth_bertram_khan_zhang_sherman_satin_2002',\n    'Model_entity': 'goforth_bertram_khan_zhang_sherman_satin_2002.cellml#id_00041'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/albrecht_colegrove_friel_2002',\n    'Model_entity': 'albrecht_colegrove_friel_2002.cellml#id_00030'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n    'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000019'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/albrecht_colegrove_hongpaisan_pivovarova_andrews_friel_2001',\n    'Model_entity': 'albrecht_colegrove_hongpaisan_pivovarova_andrews_friel_2001.cellml#id_00021'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/riemer_sobie_tung_1998',\n    'Model_entity': 'riemer_sobie_tung_1998.cellml#id_00063'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/faber_rudy_2000',\n    'Model_entity': 'faber_rudy_2000.cellml#id_00074'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/jafri_rice_winslow_1998',\n    'Model_entity': 'jafri_rice_winslow_1998_a.cellml#id_00017'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/tentusscher_noble_noble_panfilov_2004',\n    'Model_entity': 'tentusscher_noble_noble_panfilov_2004_c.cellml#id_00050'\n  },\n    ...\n  , {\n    'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n    'Model_entity': 'viswanathan_shaw_rudy_1999_c.cellml#id_00095'\n  }]\n}\n</code></pre>\n</li>\n<li>\n<p>Get model entities from BioModels with standard setting using NLTK Parser:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'bm'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'nltk'</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'mitochondrial calcium ion transmembrane transport'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getModels</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n</pre>\n<p>The code produce 6 model entities:</p>\n<pre><code>{\n'vars': ['model', 'type', 'element', 'notes', 'name'],\n  'results': [{\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'name': 'UniporterFromCytosol'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'name': 'CytToMito'\n  },\n    ...\n  ]\n}\n</code></pre>\n</li>\n<li>\n<p>Get model entities from BioModels with precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8 and NLTK parser</p>\n</li>\n</ul>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'bm'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'nltk'</span><span class=\"p\">,</span> <span class=\"n\">pl</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">delta</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'mitochondrial calcium ion transmembrane transport'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getModels</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n</pre>\n<p>Resulting 12 model entities:</p>\n<pre><code>'vars': ['model', 'type', 'element', 'notes', 'name'],\n  'results': [{\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'name': 'UniporterFromCytosol'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'name': 'CytToMito'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'type': 'http://biomodels.net/biology-qualifiers#isVersionOf',\n    'element': 'http://purl.obolibrary.org/obo/GO:0006851'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'type': 'http://biomodels.net/biology-qualifiers#isVersionOf',\n    'element': 'http://purl.obolibrary.org/obo/GO:0006851'\n  },\n    ...\n  ]\n}\n</code></pre>\n<h3>Get Query Annotation</h3>\n<p>In a case you just need to utilise the annotation function, you can use getAnnotated function. By this, the system will not request Internet connection for SPARQL request. However, if you use NCBO Annotator, Internet connection is still required.</p>\n<ul>\n<li>\n<p>Code example to annotated query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'pmr'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'stanford'</span><span class=\"p\">,</span> <span class=\"n\">pl</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">delta</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'concentration of potassium in the portion of tissue fluid'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getAnnotated</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n</pre>\n<p>Result:</p>\n<pre><code>{\n  'phrases': ['concentration', 'potassium', 'portion tissue fluid'],\n  'result': [\n    [\n      ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.061734018829371\n    ]\n  ]\n}\n</code></pre>\n<p>The query is separated into three phrases, then each phrase is classify into an ontology. There is a score 5.061734018829371 indicating the weight of ontologies combination.</p>\n</li>\n<li>\n<p>Code example to annotated query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser, pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'pmr'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'stanford'</span><span class=\"p\">,</span> <span class=\"n\">pl</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">delta</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'flux of sodium'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getAnnotated</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n</pre>\n<p>Result:</p>\n<pre><code>{\n  'phrases': ['concentration', 'potassium', 'portion tissue fluid'],\n  'result': [\n    [\n      ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.061734018829371\n    ],\n    [\n      ['https://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.020508088576971\n    ],\n    [\n      ['http://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.06090745289317\n    ],\n    [\n      ['https://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.019681522640769\n    ],\n    [\n      ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.307255058507058\n    ],\n    [\n      ['https://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.266029128254657\n    ],\n    [\n      ['http://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.3064284925708565\n    ],\n    [\n      ['https://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.265202562318455\n    ]\n  ]\n}\n</code></pre>\n<p>Just the same as the previous result, the query is separated into three phrases, then each phrase is classify into an ontology. Since we use higher precisin level, the function presents more ontologies combination with a different score. Higher score means higher probability of relevant annotation.</p>\n</li>\n</ul>\n<h3>Get SPARQL</h3>\n<p>It is also possible to get SPARQL only without model entities. It utilise getSparql function which generated all possible SPARQL based on annotation results.</p>\n<ul>\n<li>Get SPARQL code for query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'pmr'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'stanford'</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'flux of sodium'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getSparql</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n</pre>\nResulting a list of SPARQL:\n<pre><code>[\n  'SELECT ?graph ?Model_entity ?desc\n    WHERE { GRAPH ?graph {\n      ?e  &lt;http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition&gt; &lt;http://purl.obolibrary.org/obo/FMA_9673&gt; .\n      ?c  &lt;http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition&gt; &lt;http://purl.obolibrary.org/obo/CHEBI_29103&gt; .\n      ?a  &lt;http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition&gt; &lt;http://identifiers.org/opb/OPB_00340&gt; .\n      ?Model_entity  &lt;http://www.bhi.washington.edu/SemSim#isComputationalComponentFor&gt; ?a .\n      ?a  &lt;http://www.bhi.washington.edu/SemSim#physicalPropertyOf&gt; ?c .\n      ?c  &lt;http://www.obofoundry.org/ro/ro.owl#part_of&gt; ?e .\n      OPTIONAL{?Model_entity &lt;http://purl.org/dc/terms/description&gt; ?desc .} }}'\n]\n</code></pre>\n</li>\n<li>Get SPARQL code for query \"concentration of potassium in the portion of tissue fluid\" in the PMR using Stanford parser with precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8 and NLTK parser\n<pre><span class=\"kn\">from</span> <span class=\"nn\">NLIMED</span> <span class=\"kn\">import</span> <span class=\"n\">NLIMED</span>\n<span class=\"n\">nlimed</span> <span class=\"o\">=</span> <span class=\"n\">NLIMED</span><span class=\"p\">(</span><span class=\"n\">repo</span><span class=\"o\">=</span><span class=\"s1\">'pmr'</span><span class=\"p\">,</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"s1\">'stanford'</span><span class=\"p\">,</span> <span class=\"n\">pl</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">alpha</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">beta</span><span class=\"o\">=</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"n\">delta</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">)</span>\n<span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"s1\">'flux of sodium'</span>\n<span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"n\">nlimed</span><span class=\"o\">.</span><span class=\"n\">getSparql</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"n\">query</span><span class=\"p\">,</span><span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s1\">'json'</span><span class=\"p\">)</span>\n</pre>\nThe result can be 0 or more than one SPARQL based on the RDF Graph Index.\n<pre><code>[\n'SELECT ?graph ?Model_entity ?desc\n  WHERE { GRAPH ?graph {  ?c  &lt;http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition&gt; &lt;http://purl.obolibrary.org/obo/CHEBI_29103&gt; .\n    ?e  &lt;http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition&gt; &lt;http://purl.obolibrary.org/obo/FMA_9673&gt; .\n    ?a  &lt;http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition&gt; &lt;http://identifiers.org/opb/OPB_00340&gt; .\n    ?Model_entity  &lt;http://www.bhi.washington.edu/SemSim#isComputationalComponentFor&gt; ?a .\n    ?a  &lt;http://www.bhi.washington.edu/SemSim#physicalPropertyOf&gt; ?c .\n    ?c  &lt;http://www.obofoundry.org/ro/ro.owl#part_of&gt; ?e .\n    OPTIONAL{?Model_entity &lt;http://purl.org/dc/terms/description&gt; ?desc .} }}'\n]\n</code></pre>\n</li>\n</ul>\n<h2>Recreate Indexes (RDF Graph Index and Text Feature Index)</h2>\n<p>All indexes are already provided in this project. However, if you want to recreate all indexes you can use the following script on command prompt or terminal. Please be patient, it may take times to be finished.</p>\n<h3>Indexing the pmr</h3>\n<pre><code>NLIMED --build-index pmr\n</code></pre>\n<h3>Indexing biomodels</h3>\n<pre><code>NLIMED --build-index bm\n</code></pre>\n\n          </div>"}, "last_serial": 6020785, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "e1660285688dd22686a00053e9fa52fc", "sha256": "caa80eeb8b1682559935354f168047eb78aff8169b2d2eb87aae704ae6f99311"}, "downloads": -1, "filename": "NLIMED-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e1660285688dd22686a00053e9fa52fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2189275, "upload_time": "2019-10-23T22:28:35", "upload_time_iso_8601": "2019-10-23T22:28:35.009796Z", "url": "https://files.pythonhosted.org/packages/4f/61/c7b00b78f53d0eace50cf0aa8aef291d409acfeacf279ecbfebb957a4eab/NLIMED-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d8fe1077ce82ff4009c5ad23fff9e4a", "sha256": "cf21ec6d25072c1293646b0e036c0d586fa6817967570a6a68241d4c4e677b57"}, "downloads": -1, "filename": "NLIMED-0.0.1.tar.gz", "has_sig": false, "md5_digest": "0d8fe1077ce82ff4009c5ad23fff9e4a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2036004, "upload_time": "2019-10-23T22:28:38", "upload_time_iso_8601": "2019-10-23T22:28:38.451194Z", "url": "https://files.pythonhosted.org/packages/3f/4f/f8d4cd75ffebbfebb5633e66c3200503a6c7b50a0d29575877689eeca97b/NLIMED-0.0.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "e1660285688dd22686a00053e9fa52fc", "sha256": "caa80eeb8b1682559935354f168047eb78aff8169b2d2eb87aae704ae6f99311"}, "downloads": -1, "filename": "NLIMED-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "e1660285688dd22686a00053e9fa52fc", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 2189275, "upload_time": "2019-10-23T22:28:35", "upload_time_iso_8601": "2019-10-23T22:28:35.009796Z", "url": "https://files.pythonhosted.org/packages/4f/61/c7b00b78f53d0eace50cf0aa8aef291d409acfeacf279ecbfebb957a4eab/NLIMED-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0d8fe1077ce82ff4009c5ad23fff9e4a", "sha256": "cf21ec6d25072c1293646b0e036c0d586fa6817967570a6a68241d4c4e677b57"}, "downloads": -1, "filename": "NLIMED-0.0.1.tar.gz", "has_sig": false, "md5_digest": "0d8fe1077ce82ff4009c5ad23fff9e4a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2036004, "upload_time": "2019-10-23T22:28:38", "upload_time_iso_8601": "2019-10-23T22:28:38.451194Z", "url": "https://files.pythonhosted.org/packages/3f/4f/f8d4cd75ffebbfebb5633e66c3200503a6c7b50a0d29575877689eeca97b/NLIMED-0.0.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:45:12 2020"}