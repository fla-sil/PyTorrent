{"info": {"author": "Milan Straka", "author_email": "straka@ufal.mff.cuni.cz", "bugtrack_url": null, "classifiers": ["Development Status :: 5 - Production/Stable", "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)", "Programming Language :: C++", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Topic :: Software Development :: Libraries"], "description": "ufal.morphodita\n===============\n\nThe ``ufal.morphodita`` is a Python binding to MorphoDiTa library <http://ufal.mff.cuni.cz/morphodita>.\n\nThe bindings is a straightforward conversion of the ``C++`` bindings API.\nIn Python 2, strings can be both ``unicode`` and UTF-8 encoded ``str``, and the\nlibrary always produces ``unicode``. In Python 3, strings must be only ``str``.\n\n\nWrapped C++ API\n---------------\n\nThe C++ API being wrapped follows. For a API reference of the original\nC++ API, see <http://ufal.mff.cuni.cz/morphodita/api-reference>.\n\n::\n\n  Helper Structures\n  -----------------\n  \n    typedef vector<int> Indices;\n  \n    typedef vector<string> Forms;\n  \n    struct TaggedForm {\n      string form;\n      string tag;\n    };\n    typedef vector<TaggedForm> TaggedForms;\n  \n    struct TaggedLemma {\n      string lemma;\n      string tag;\n    };\n    typedef vector<TaggedLemma> TaggedLemmas;\n    typedef vector<TaggedLemmas> Analyses;\n  \n    struct TaggedLemmaForms {\n      string lemma;\n      TaggedForms forms;\n    };\n    typedef vector<TaggedLemmaForms> TaggedLemmasForms;\n  \n    struct TokenRange {\n      size_t start;\n      size_t length;\n    };\n    typedef vector<TokenRange> TokenRanges;\n  \n    struct DerivatedLemma {\n      std::string lemma;\n    };\n    typedef vector<DerivatedLemma> DerivatedLemmas;\n  \n  \n  Main Classes\n  ------------\n  \n    class Version {\n     public:\n      unsigned major;\n      unsigned minor;\n      unsigned patch;\n      string prerelease;\n  \n      static Version current();\n    };\n  \n    class Tokenizer {\n     public:\n      virtual void setText(const char* text);\n      virtual bool nextSentence(Forms* forms, TokenRanges* tokens);\n  \n      static Tokenizer* newVerticalTokenizer();\n      static Tokenizer* newCzechTokenizer();\n      static Tokenizer* newEnglishTokenizer();\n      static Tokenizer* newGenericTokenizer();\n    };\n  \n    class Derivator {\n     public:\n      virtual bool parent(const char* lemma, DerivatedLemma& parent) const;\n      virtual bool children(const char* lemma, DerivatedLemmas& children) const;\n    };\n  \n    class DerivationFormatter {\n     public:\n      virtual string formatDerivation(const char* lemma) const;\n  \n      static DerivationFormatter* newNoneDerivationFormatter();\n      static DerivationFormatter* newRootDerivationFormatter(const Derivator* derivator);\n      static DerivationFormatter* newPathDerivationFormatter(const Derivator* derivator);\n      static DerivationFormatter* newTreeDerivationFormatter(const Derivator* derivator);\n      static DerivationFormatter* newDerivationFormatter(const char* name, const Derivator* derivator);\n    };\n  \n    class Morpho {\n     public:\n      static Morpho* load(const char* fname);\n  \n      enum { NO_GUESSER = 0, GUESSER = 1 };\n  \n      virtual int analyze(const char* form, int guesser, TaggedLemmas& lemmas) const;\n      virtual int generate(const char* lemma, const char* tag_wildcard, int guesser, TaggedLemmasForms& forms) const;\n      virtual string rawLemma(const char* lemma) const;\n      virtual string lemmaId(const char* lemma) const;\n      virtual string rawForm(const char* form) const;\n  \n      virtual Tokenizer* newTokenizer() const;\n  \n      virtual Derivator* getDerivator() const;\n    };\n  \n    class Tagger {\n     public:\n      static Tagger* load(const char* fname);\n  \n      virtual const Morpho* getMorpho() const;\n  \n      virtual void tag(const Forms& forms, TaggedLemmas& tags, int guesser = -1) const;\n  \n      virtual void tagAnalyzed(const Forms& forms, const Analyses& analyses, Indices& tags) const;\n  \n      Tokenizer* newTokenizer() const;\n    };\n  \n    class TagsetConverter {\n     public:\n      static TagsetConverter* newIdentityConverter();\n      static TagsetConverter* newPdtToConll2009Converter();\n      static TagsetConverter* newStripLemmaCommentConverter(const Morpho& morpho);\n      static TagsetConverter* newStripLemmaIdConverter(const Morpho& morpho);\n  \n      virtual void convert(TaggedLemma& lemma) const;\n      virtual void convertAnalyzed(TaggedLemmas& lemmas) const;\n      virtual void convertGenerated(TaggedLemmasForms& forms) const;\n    };\n\n\nExamples\n========\n\nrun_morpho_cli\n--------------\n\nSimple example performing morphological analysis and generation::\n\n  import sys\n  \n  from ufal.morphodita import *\n  \n  # In Python2, wrap sys.stdin and sys.stdout to work with unicode.\n  if sys.version_info[0] < 3:\n    import codecs\n    import locale\n    encoding = locale.getpreferredencoding()\n    sys.stdin = codecs.getreader(encoding)(sys.stdin)\n    sys.stdout = codecs.getwriter(encoding)(sys.stdout)\n  \n  if len(sys.argv) < 2:\n    sys.stderr.write('Usage: %s dict_file\\n' % sys.argv[0])\n    sys.exit(1)\n  \n  sys.stderr.write('Loading dictionary: ')\n  morpho = Morpho.load(sys.argv[1])\n  if not morpho:\n    sys.stderr.write(\"Cannot load dictionary from file '%s'\\n\" % sys.argv[1])\n    sys.exit(1)\n  sys.stderr.write('done\\n')\n  \n  lemmas = TaggedLemmas()\n  lemmas_forms = TaggedLemmasForms()\n  line = sys.stdin.readline()\n  while line:\n    tokens = line.rstrip('\\r\\n').split('\\t')\n    if len(tokens) == 1: # analyze\n      result = morpho.analyze(tokens[0], morpho.GUESSER, lemmas)\n  \n      guesser = \"Guesser \" if result == morpho.GUESSER else \"\"\n      for lemma in lemmas:\n        sys.stdout.write('%sLemma: %s %s\\n' % (guesser, lemma.lemma, lemma.tag))\n    elif len(tokens) == 2: # generate\n      result = morpho.generate(tokens[0], tokens[1], morpho.GUESSER, lemmas_forms)\n  \n      guesser = \"Guesser \" if result == morpho.GUESSER else \"\"\n      for lemma_forms in lemmas_forms:\n        sys.stdout.write('%sLemma: %s\\n' % (guesser, lemma_forms.lemma))\n        for form in lemma_forms.forms:\n          sys.stdout.write('  %s %s\\n' % (form.form, form.tag))\n  \n    line = sys.stdin.readline()\n\nrun_tagger\n----------\n\nSimple example performing tokenization and PoS tagging::\n\n  import sys\n  \n  from ufal.morphodita import *\n  \n  def encode_entities(text):\n    return text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('\"', '&quot;')\n  \n  # In Python2, wrap sys.stdin and sys.stdout to work with unicode.\n  if sys.version_info[0] < 3:\n    import codecs\n    import locale\n    encoding = locale.getpreferredencoding()\n    sys.stdin = codecs.getreader(encoding)(sys.stdin)\n    sys.stdout = codecs.getwriter(encoding)(sys.stdout)\n  \n  if len(sys.argv) == 1:\n    sys.stderr.write('Usage: %s tagger_file\\n' % sys.argv[0])\n    sys.exit(1)\n  \n  sys.stderr.write('Loading tagger: ')\n  tagger = Tagger.load(sys.argv[1])\n  if not tagger:\n    sys.stderr.write(\"Cannot load tagger from file '%s'\\n\" % sys.argv[1])\n    sys.exit(1)\n  sys.stderr.write('done\\n')\n  \n  forms = Forms()\n  lemmas = TaggedLemmas()\n  tokens = TokenRanges()\n  tokenizer = tagger.newTokenizer()\n  if tokenizer is None:\n    sys.stderr.write(\"No tokenizer is defined for the supplied model!\")\n    sys.exit(1)\n  \n  not_eof = True\n  while not_eof:\n    text = ''\n  \n    # Read block\n    while True:\n      line = sys.stdin.readline()\n      not_eof = bool(line)\n      if not not_eof: break\n      line = line.rstrip('\\r\\n')\n      text += line\n      text += '\\n';\n      if not line: break\n  \n  \n  \n    # Tag\n    tokenizer.setText(text)\n    t = 0\n    while tokenizer.nextSentence(forms, tokens):\n      tagger.tag(forms, lemmas)\n  \n      for i in range(len(lemmas)):\n        lemma = lemmas[i]\n        token = tokens[i]\n        sys.stdout.write('%s%s<token lemma=\"%s\" tag=\"%s\">%s</token>%s' % (\n          encode_entities(text[t : token.start]),\n          \"<sentence>\" if i == 0 else \"\",\n          encode_entities(lemma.lemma),\n          encode_entities(lemma.tag),\n          encode_entities(text[token.start : token.start + token.length]),\n          \"</sentence>\" if i + 1 == len(lemmas) else \"\",\n        ))\n        t = token.start + token.length\n    sys.stdout.write(encode_entities(text[t : ]))\n\n\nAUTHORS\n=======\n\nMilan Straka <straka@ufal.mff.cuni.cz>\n\nJana Strakov\u00e1 <strakova@ufal.mff.cuni.cz>\n\n\nCOPYRIGHT AND LICENCE\n=====================\n\nCopyright 2015 Institute of Formal and Applied Linguistics, Faculty of\nMathematics and Physics, Charles University in Prague, Czech Republic.\n\nThis Source Code Form is subject to the terms of the Mozilla Public\nLicense, v. 2.0. If a copy of the MPL was not distributed with this\nfile, You can obtain one at http://mozilla.org/MPL/2.0/.", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://ufal.mff.cuni.cz/morphodita", "keywords": "", "license": "MPL 2.0", "maintainer": "", "maintainer_email": "", "name": "ufal.morphodita", "package_url": "https://pypi.org/project/ufal.morphodita/", "platform": "", "project_url": "https://pypi.org/project/ufal.morphodita/", "project_urls": {"Homepage": "http://ufal.mff.cuni.cz/morphodita"}, "release_url": "https://pypi.org/project/ufal.morphodita/1.9.2.3/", "requires_dist": null, "requires_python": "", "summary": "Bindings to MorphoDiTa library", "version": "1.9.2.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <div id=\"ufal-morphodita\">\n<h2>ufal.morphodita</h2>\n<p>The <tt>ufal.morphodita</tt> is a Python binding to MorphoDiTa library &lt;<a href=\"http://ufal.mff.cuni.cz/morphodita\" rel=\"nofollow\">http://ufal.mff.cuni.cz/morphodita</a>&gt;.</p>\n<p>The bindings is a straightforward conversion of the <tt>C++</tt> bindings API.\nIn Python 2, strings can be both <tt>unicode</tt> and UTF-8 encoded <tt>str</tt>, and the\nlibrary always produces <tt>unicode</tt>. In Python 3, strings must be only <tt>str</tt>.</p>\n<div id=\"wrapped-c-api\">\n<h3>Wrapped C++ API</h3>\n<p>The C++ API being wrapped follows. For a API reference of the original\nC++ API, see &lt;<a href=\"http://ufal.mff.cuni.cz/morphodita/api-reference\" rel=\"nofollow\">http://ufal.mff.cuni.cz/morphodita/api-reference</a>&gt;.</p>\n<pre>Helper Structures\n-----------------\n\n  typedef vector&lt;int&gt; Indices;\n\n  typedef vector&lt;string&gt; Forms;\n\n  struct TaggedForm {\n    string form;\n    string tag;\n  };\n  typedef vector&lt;TaggedForm&gt; TaggedForms;\n\n  struct TaggedLemma {\n    string lemma;\n    string tag;\n  };\n  typedef vector&lt;TaggedLemma&gt; TaggedLemmas;\n  typedef vector&lt;TaggedLemmas&gt; Analyses;\n\n  struct TaggedLemmaForms {\n    string lemma;\n    TaggedForms forms;\n  };\n  typedef vector&lt;TaggedLemmaForms&gt; TaggedLemmasForms;\n\n  struct TokenRange {\n    size_t start;\n    size_t length;\n  };\n  typedef vector&lt;TokenRange&gt; TokenRanges;\n\n  struct DerivatedLemma {\n    std::string lemma;\n  };\n  typedef vector&lt;DerivatedLemma&gt; DerivatedLemmas;\n\n\nMain Classes\n------------\n\n  class Version {\n   public:\n    unsigned major;\n    unsigned minor;\n    unsigned patch;\n    string prerelease;\n\n    static Version current();\n  };\n\n  class Tokenizer {\n   public:\n    virtual void setText(const char* text);\n    virtual bool nextSentence(Forms* forms, TokenRanges* tokens);\n\n    static Tokenizer* newVerticalTokenizer();\n    static Tokenizer* newCzechTokenizer();\n    static Tokenizer* newEnglishTokenizer();\n    static Tokenizer* newGenericTokenizer();\n  };\n\n  class Derivator {\n   public:\n    virtual bool parent(const char* lemma, DerivatedLemma&amp; parent) const;\n    virtual bool children(const char* lemma, DerivatedLemmas&amp; children) const;\n  };\n\n  class DerivationFormatter {\n   public:\n    virtual string formatDerivation(const char* lemma) const;\n\n    static DerivationFormatter* newNoneDerivationFormatter();\n    static DerivationFormatter* newRootDerivationFormatter(const Derivator* derivator);\n    static DerivationFormatter* newPathDerivationFormatter(const Derivator* derivator);\n    static DerivationFormatter* newTreeDerivationFormatter(const Derivator* derivator);\n    static DerivationFormatter* newDerivationFormatter(const char* name, const Derivator* derivator);\n  };\n\n  class Morpho {\n   public:\n    static Morpho* load(const char* fname);\n\n    enum { NO_GUESSER = 0, GUESSER = 1 };\n\n    virtual int analyze(const char* form, int guesser, TaggedLemmas&amp; lemmas) const;\n    virtual int generate(const char* lemma, const char* tag_wildcard, int guesser, TaggedLemmasForms&amp; forms) const;\n    virtual string rawLemma(const char* lemma) const;\n    virtual string lemmaId(const char* lemma) const;\n    virtual string rawForm(const char* form) const;\n\n    virtual Tokenizer* newTokenizer() const;\n\n    virtual Derivator* getDerivator() const;\n  };\n\n  class Tagger {\n   public:\n    static Tagger* load(const char* fname);\n\n    virtual const Morpho* getMorpho() const;\n\n    virtual void tag(const Forms&amp; forms, TaggedLemmas&amp; tags, int guesser = -1) const;\n\n    virtual void tagAnalyzed(const Forms&amp; forms, const Analyses&amp; analyses, Indices&amp; tags) const;\n\n    Tokenizer* newTokenizer() const;\n  };\n\n  class TagsetConverter {\n   public:\n    static TagsetConverter* newIdentityConverter();\n    static TagsetConverter* newPdtToConll2009Converter();\n    static TagsetConverter* newStripLemmaCommentConverter(const Morpho&amp; morpho);\n    static TagsetConverter* newStripLemmaIdConverter(const Morpho&amp; morpho);\n\n    virtual void convert(TaggedLemma&amp; lemma) const;\n    virtual void convertAnalyzed(TaggedLemmas&amp; lemmas) const;\n    virtual void convertGenerated(TaggedLemmasForms&amp; forms) const;\n  };\n</pre>\n</div>\n</div>\n<div id=\"examples\">\n<h2>Examples</h2>\n<div id=\"run-morpho-cli\">\n<h3>run_morpho_cli</h3>\n<p>Simple example performing morphological analysis and generation:</p>\n<pre>import sys\n\nfrom ufal.morphodita import *\n\n# In Python2, wrap sys.stdin and sys.stdout to work with unicode.\nif sys.version_info[0] &lt; 3:\n  import codecs\n  import locale\n  encoding = locale.getpreferredencoding()\n  sys.stdin = codecs.getreader(encoding)(sys.stdin)\n  sys.stdout = codecs.getwriter(encoding)(sys.stdout)\n\nif len(sys.argv) &lt; 2:\n  sys.stderr.write('Usage: %s dict_file\\n' % sys.argv[0])\n  sys.exit(1)\n\nsys.stderr.write('Loading dictionary: ')\nmorpho = Morpho.load(sys.argv[1])\nif not morpho:\n  sys.stderr.write(\"Cannot load dictionary from file '%s'\\n\" % sys.argv[1])\n  sys.exit(1)\nsys.stderr.write('done\\n')\n\nlemmas = TaggedLemmas()\nlemmas_forms = TaggedLemmasForms()\nline = sys.stdin.readline()\nwhile line:\n  tokens = line.rstrip('\\r\\n').split('\\t')\n  if len(tokens) == 1: # analyze\n    result = morpho.analyze(tokens[0], morpho.GUESSER, lemmas)\n\n    guesser = \"Guesser \" if result == morpho.GUESSER else \"\"\n    for lemma in lemmas:\n      sys.stdout.write('%sLemma: %s %s\\n' % (guesser, lemma.lemma, lemma.tag))\n  elif len(tokens) == 2: # generate\n    result = morpho.generate(tokens[0], tokens[1], morpho.GUESSER, lemmas_forms)\n\n    guesser = \"Guesser \" if result == morpho.GUESSER else \"\"\n    for lemma_forms in lemmas_forms:\n      sys.stdout.write('%sLemma: %s\\n' % (guesser, lemma_forms.lemma))\n      for form in lemma_forms.forms:\n        sys.stdout.write('  %s %s\\n' % (form.form, form.tag))\n\n  line = sys.stdin.readline()\n</pre>\n</div>\n<div id=\"run-tagger\">\n<h3>run_tagger</h3>\n<p>Simple example performing tokenization and PoS tagging:</p>\n<pre>import sys\n\nfrom ufal.morphodita import *\n\ndef encode_entities(text):\n  return text.replace('&amp;', '&amp;amp;').replace('&lt;', '&amp;lt;').replace('&gt;', '&amp;gt;').replace('\"', '&amp;quot;')\n\n# In Python2, wrap sys.stdin and sys.stdout to work with unicode.\nif sys.version_info[0] &lt; 3:\n  import codecs\n  import locale\n  encoding = locale.getpreferredencoding()\n  sys.stdin = codecs.getreader(encoding)(sys.stdin)\n  sys.stdout = codecs.getwriter(encoding)(sys.stdout)\n\nif len(sys.argv) == 1:\n  sys.stderr.write('Usage: %s tagger_file\\n' % sys.argv[0])\n  sys.exit(1)\n\nsys.stderr.write('Loading tagger: ')\ntagger = Tagger.load(sys.argv[1])\nif not tagger:\n  sys.stderr.write(\"Cannot load tagger from file '%s'\\n\" % sys.argv[1])\n  sys.exit(1)\nsys.stderr.write('done\\n')\n\nforms = Forms()\nlemmas = TaggedLemmas()\ntokens = TokenRanges()\ntokenizer = tagger.newTokenizer()\nif tokenizer is None:\n  sys.stderr.write(\"No tokenizer is defined for the supplied model!\")\n  sys.exit(1)\n\nnot_eof = True\nwhile not_eof:\n  text = ''\n\n  # Read block\n  while True:\n    line = sys.stdin.readline()\n    not_eof = bool(line)\n    if not not_eof: break\n    line = line.rstrip('\\r\\n')\n    text += line\n    text += '\\n';\n    if not line: break\n\n\n\n  # Tag\n  tokenizer.setText(text)\n  t = 0\n  while tokenizer.nextSentence(forms, tokens):\n    tagger.tag(forms, lemmas)\n\n    for i in range(len(lemmas)):\n      lemma = lemmas[i]\n      token = tokens[i]\n      sys.stdout.write('%s%s&lt;token lemma=\"%s\" tag=\"%s\"&gt;%s&lt;/token&gt;%s' % (\n        encode_entities(text[t : token.start]),\n        \"&lt;sentence&gt;\" if i == 0 else \"\",\n        encode_entities(lemma.lemma),\n        encode_entities(lemma.tag),\n        encode_entities(text[token.start : token.start + token.length]),\n        \"&lt;/sentence&gt;\" if i + 1 == len(lemmas) else \"\",\n      ))\n      t = token.start + token.length\n  sys.stdout.write(encode_entities(text[t : ]))\n</pre>\n</div>\n</div>\n<div id=\"authors\">\n<h2>AUTHORS</h2>\n<p>Milan Straka &lt;<a href=\"mailto:straka%40ufal.mff.cuni.cz\">straka<span>@</span>ufal<span>.</span>mff<span>.</span>cuni<span>.</span>cz</a>&gt;</p>\n<p>Jana Strakov\u00e1 &lt;<a href=\"mailto:strakova%40ufal.mff.cuni.cz\">strakova<span>@</span>ufal<span>.</span>mff<span>.</span>cuni<span>.</span>cz</a>&gt;</p>\n</div>\n<div id=\"copyright-and-licence\">\n<h2>COPYRIGHT AND LICENCE</h2>\n<p>Copyright 2015 Institute of Formal and Applied Linguistics, Faculty of\nMathematics and Physics, Charles University in Prague, Czech Republic.</p>\n<p>This Source Code Form is subject to the terms of the Mozilla Public\nLicense, v. 2.0. If a copy of the MPL was not distributed with this\nfile, You can obtain one at <a href=\"http://mozilla.org/MPL/2.0/\" rel=\"nofollow\">http://mozilla.org/MPL/2.0/</a>.</p>\n</div>\n\n          </div>"}, "last_serial": 5286507, "releases": {"1.0.0.2": [{"comment_text": "", "digests": {"md5": "3ea466ae39acaaa1bee2d16493578676", "sha256": "a3e060c202dd4e6c23e649c6609fd665bde1b6cd9c14c58a3d1eec6485ef7252"}, "downloads": -1, "filename": "ufal.morphodita-1.0.0.2.tar.gz", "has_sig": false, "md5_digest": "3ea466ae39acaaa1bee2d16493578676", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 224376, "upload_time": "2014-04-07T13:46:24", "upload_time_iso_8601": "2014-04-07T13:46:24.053532Z", "url": "https://files.pythonhosted.org/packages/43/7b/d1d0242bef1367bf33f1bb1a662338c733a2f95f5de92d52a02065626c7a/ufal.morphodita-1.0.0.2.tar.gz", "yanked": false}], "1.1.0.1": [{"comment_text": "", "digests": {"md5": "0b32ee6b2bddd8a14e827fc2f0d9cb1a", "sha256": "4accd91b108a5ac58707318090947b5d192f31da2fb77e8bf111db32817812a2"}, "downloads": -1, "filename": "ufal.morphodita-1.1.0.1.tar.gz", "has_sig": false, "md5_digest": "0b32ee6b2bddd8a14e827fc2f0d9cb1a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 226447, "upload_time": "2014-04-09T09:17:37", "upload_time_iso_8601": "2014-04-09T09:17:37.767064Z", "url": "https://files.pythonhosted.org/packages/f6/a1/df2470cef2f3292c6af6c01ba88c9d431876de6712b28c8aa4ed82715a0a/ufal.morphodita-1.1.0.1.tar.gz", "yanked": false}], "1.2.0.1": [{"comment_text": "", "digests": {"md5": "69ce45db6c14a6eb4d61489d74bafd56", "sha256": "a9379567159637566b3e99351a2af70119ee39d133b5018850675d29b9a03b54"}, "downloads": -1, "filename": "ufal.morphodita-1.2.0.1.tar.gz", "has_sig": false, "md5_digest": "69ce45db6c14a6eb4d61489d74bafd56", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 227377, "upload_time": "2014-04-22T07:47:45", "upload_time_iso_8601": "2014-04-22T07:47:45.120971Z", "url": "https://files.pythonhosted.org/packages/94/30/69293d57782c1d4eb16db8025a84526df3be40c7278056595bd5bac5b74d/ufal.morphodita-1.2.0.1.tar.gz", "yanked": false}], "1.3.0.1": [{"comment_text": "", "digests": {"md5": "743eeb775011d9c78b6520ba16655666", "sha256": "85866eb80e219581a56d03b5e9ad27e0614c495906880c84fdd4293c08554382"}, "downloads": -1, "filename": "ufal.morphodita-1.3.0.1.tar.gz", "has_sig": false, "md5_digest": "743eeb775011d9c78b6520ba16655666", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 243440, "upload_time": "2014-08-30T12:08:48", "upload_time_iso_8601": "2014-08-30T12:08:48.386946Z", "url": "https://files.pythonhosted.org/packages/61/92/afca6affd9ab2a4fe839679e15afc4b506464711b8fb35005228796670fa/ufal.morphodita-1.3.0.1.tar.gz", "yanked": false}], "1.9.1.1": [], "1.9.2.1": [{"comment_text": "", "digests": {"md5": "e4c597ce7d971a7e2a2c700f3064b6b6", "sha256": "57544371cbb1e7f596046586321e637834490f9ecacbc84ae859a4c6f2434a70"}, "downloads": -1, "filename": "ufal.morphodita-1.9.2.1.tar.gz", "has_sig": false, "md5_digest": "e4c597ce7d971a7e2a2c700f3064b6b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 182193, "upload_time": "2016-09-22T12:36:53", "upload_time_iso_8601": "2016-09-22T12:36:53.196835Z", "url": "https://files.pythonhosted.org/packages/40/80/f54153a09154e670d68d22ab10caa0ecb3896443b93301f58df6705ebba9/ufal.morphodita-1.9.2.1.tar.gz", "yanked": false}], "1.9.2.3": [{"comment_text": "", "digests": {"md5": "8a6683a24f93e4f07a93d2182112c2d9", "sha256": "fd0ab31d0968361f6a98a0e01c1bc8a3753569310c0b8593317e9c3c70d7db95"}, "downloads": -1, "filename": "ufal.morphodita-1.9.2.3.tar.gz", "has_sig": false, "md5_digest": "8a6683a24f93e4f07a93d2182112c2d9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 187535, "upload_time": "2019-05-18T19:54:02", "upload_time_iso_8601": "2019-05-18T19:54:02.718974Z", "url": "https://files.pythonhosted.org/packages/70/bb/ea007eddc55c83cb0126558f5520c2c6775e7fed7492b255f7ada9fb5330/ufal.morphodita-1.9.2.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "8a6683a24f93e4f07a93d2182112c2d9", "sha256": "fd0ab31d0968361f6a98a0e01c1bc8a3753569310c0b8593317e9c3c70d7db95"}, "downloads": -1, "filename": "ufal.morphodita-1.9.2.3.tar.gz", "has_sig": false, "md5_digest": "8a6683a24f93e4f07a93d2182112c2d9", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 187535, "upload_time": "2019-05-18T19:54:02", "upload_time_iso_8601": "2019-05-18T19:54:02.718974Z", "url": "https://files.pythonhosted.org/packages/70/bb/ea007eddc55c83cb0126558f5520c2c6775e7fed7492b255f7ada9fb5330/ufal.morphodita-1.9.2.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:41:45 2020"}