{"info": {"author": "Brandon Schabell", "author_email": "brandonschabell@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "\n# Tensorflow Object Detection API\nCreating accurate machine learning models capable of localizing and identifying\nmultiple objects in a single image remains a core challenge in computer vision.\nThe TensorFlow Object Detection API is an open source framework built on top of\nTensorFlow that makes it easy to construct, train and deploy object detection\nmodels.  At Google we\u2019ve certainly found this codebase to be useful for our\ncomputer vision needs, and we hope that you will as well.\n<p align=\"center\">\n  <img src=\"g3doc/img/kites_detections_output.jpg\" width=676 height=450>\n</p>\nContributions to the codebase are welcome and we would love to hear back from\nyou if you find this API useful.  Finally if you use the Tensorflow Object\nDetection API for a research publication, please consider citing:\n\n```\n\"Speed/accuracy trade-offs for modern convolutional object detectors.\"\nHuang J, Rathod V, Sun C, Zhu M, Korattikara A, Fathi A, Fischer I, Wojna Z,\nSong Y, Guadarrama S, Murphy K, CVPR 2017\n```\n\\[[link](https://arxiv.org/abs/1611.10012)\\]\\[[bibtex](\nhttps://scholar.googleusercontent.com/scholar.bib?q=info:l291WsrB-hQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWUIIlnPZ_L9jxvPwcC49kDlELtaeIyU-&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1)\\]\n\n<p align=\"center\">\n  <img src=\"g3doc/img/tf-od-api-logo.png\" width=140 height=195>\n</p>\n\n## Maintainers\n\n* Jonathan Huang, github: [jch1](https://github.com/jch1)\n* Vivek Rathod, github: [tombstone](https://github.com/tombstone)\n* Ronny Votel, github: [ronnyvotel](https://github.com/ronnyvotel)\n* Derek Chow, github: [derekjchow](https://github.com/derekjchow)\n* Chen Sun, github: [jesu9](https://github.com/jesu9)\n* Menglong Zhu, github: [dreamdragon](https://github.com/dreamdragon)\n* Alireza Fathi, github: [afathi3](https://github.com/afathi3)\n* Zhichao Lu, github: [pkulzc](https://github.com/pkulzc)\n\n\n## Table of contents\n\nSetup:\n\n  * <a href='g3doc/installation.md'>Installation</a><br>\n\nQuick Start:\n\n  * <a href='object_detection_tutorial.ipynb'>\n      Quick Start: Jupyter notebook for off-the-shelf inference</a><br>\n  * <a href=\"g3doc/running_pets.md\">Quick Start: Training a pet detector</a><br>\n\nCustomizing a Pipeline:\n\n  * <a href='g3doc/configuring_jobs.md'>\n      Configuring an object detection pipeline</a><br>\n  * <a href='g3doc/preparing_inputs.md'>Preparing inputs</a><br>\n\nRunning:\n\n  * <a href='g3doc/running_locally.md'>Running locally</a><br>\n  * <a href='g3doc/running_on_cloud.md'>Running on the cloud</a><br>\n\nExtras:\n\n  * <a href='g3doc/detection_model_zoo.md'>Tensorflow detection model zoo</a><br>\n  * <a href='g3doc/exporting_models.md'>\n      Exporting a trained model for inference</a><br>\n  * <a href='g3doc/defining_your_own_model.md'>\n      Defining your own model architecture</a><br>\n  * <a href='g3doc/using_your_own_dataset.md'>\n      Bringing in your own dataset</a><br>\n  * <a href='g3doc/evaluation_protocols.md'>\n      Supported object detection evaluation protocols</a><br>\n  * <a href='g3doc/oid_inference_and_evaluation.md'>\n      Inference and evaluation on the Open Images dataset</a><br>\n  * <a href='g3doc/instance_segmentation.md'>\n      Run an instance segmentation model</a><br>\n  * <a href='g3doc/challenge_evaluation.md'>\n      Run the evaluation for the Open Images Challenge 2018</a><br>\n  * <a href='g3doc/tpu_compatibility.md'>\n      TPU compatible detection pipelines</a><br>\n  * <a href='g3doc/running_on_mobile_tensorflowlite.md'>\n      Running object detection on mobile devices with TensorFlow Lite</a><br>\n\n## Getting Help\n\nTo get help with issues you may encounter using the Tensorflow Object Detection\nAPI, create a new question on [StackOverflow](https://stackoverflow.com/) with\nthe tags \"tensorflow\" and \"object-detection\".\n\nPlease report bugs (actually broken code, not usage questions) to the\ntensorflow/models GitHub\n[issue tracker](https://github.com/tensorflow/models/issues), prefixing the\nissue name with \"object_detection\".\n\nPlease check [FAQ](g3doc/faq.md) for frequently asked questions before\nreporting an issue.\n\n\n## Release information\n\n### Sep 17, 2018\n\nWe have released Faster R-CNN detectors with ResNet-50 / ResNet-101 feature\nextractors trained on the [iNaturalist Species Detection Dataset](https://github.com/visipedia/inat_comp/blob/master/2017/README.md#bounding-boxes).\nThe models are trained on the training split of the iNaturalist data for 4M\niterations, they achieve 55% and 58% mean AP@.5 over 2854 classes respectively.\nFor more details please refer to this [paper](https://arxiv.org/abs/1707.06642).\n\n<b>Thanks to contributors</b>: Chen Sun\n\n### July 13, 2018\n\nThere are many new updates in this release, extending the functionality and\ncapability of the API:\n\n* Moving from slim-based training to [Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator)-based\ntraining.\n* Support for [RetinaNet](https://arxiv.org/abs/1708.02002), and a [MobileNet](https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html)\nadaptation of RetinaNet.\n* A novel SSD-based architecture called the [Pooling Pyramid Network](https://arxiv.org/abs/1807.03284) (PPN).\n* Releasing several [TPU](https://cloud.google.com/tpu/)-compatible models.\nThese can be found in the `samples/configs/` directory with a comment in the\npipeline configuration files indicating TPU compatibility.\n* Support for quantized training.\n* Updated documentation for new binaries, Cloud training, and [Tensorflow Lite](https://www.tensorflow.org/mobile/tflite/).\n\nSee also our [expanded announcement blogpost](https://ai.googleblog.com/2018/07/accelerated-training-and-inference-with.html) and accompanying tutorial at the [TensorFlow blog](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193).\n\n<b>Thanks to contributors</b>: Sara Robinson, Aakanksha Chowdhery, Derek Chow,\nPengchong Jin, Jonathan Huang, Vivek Rathod, Zhichao Lu, Ronny Votel\n\n\n### June 25, 2018\n\nAdditional evaluation tools for the [Open Images Challenge 2018](https://storage.googleapis.com/openimages/web/challenge.html) are out.\nCheck out our short tutorial on data preparation and running evaluation [here](g3doc/challenge_evaluation.md)!\n\n<b>Thanks to contributors</b>: Alina Kuznetsova\n\n### June 5, 2018\n\nWe have released the implementation of evaluation metrics for both tracks of the [Open Images Challenge 2018](https://storage.googleapis.com/openimages/web/challenge.html) as a part of the Object Detection API - see the [evaluation protocols](g3doc/evaluation_protocols.md) for more details.\nAdditionally, we have released a tool for hierarchical labels expansion for the Open Images Challenge: check out [oid_hierarchical_labels_expansion.py](dataset_tools/oid_hierarchical_labels_expansion.py).\n\n<b>Thanks to contributors</b>: Alina Kuznetsova, Vittorio Ferrari, Jasper Uijlings\n\n### April 30, 2018\n\nWe have released a Faster R-CNN detector with ResNet-101 feature extractor trained on [AVA](https://research.google.com/ava/) v2.1.\nCompared with other commonly used object detectors, it changes the action classification loss function to per-class Sigmoid loss to handle boxes with multiple labels.\nThe model is trained on the training split of AVA v2.1 for 1.5M iterations, it achieves mean AP of 11.25% over 60 classes on the validation split of AVA v2.1.\nFor more details please refer to this [paper](https://arxiv.org/abs/1705.08421).\n\n<b>Thanks to contributors</b>: Chen Sun, David Ross\n\n### April 2, 2018\n\nSupercharge your mobile phones with the next generation mobile object detector!\nWe are adding support for MobileNet V2 with SSDLite presented in\n[MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381).\nThis model is 35% faster than Mobilenet V1 SSD on a Google Pixel phone CPU (200ms vs. 270ms) at the same accuracy.\nAlong with the model definition, we are also releasing a model checkpoint trained on the COCO dataset.\n\n<b>Thanks to contributors</b>: Menglong Zhu, Mark Sandler, Zhichao Lu, Vivek Rathod, Jonathan Huang\n\n### February 9, 2018\n\nWe now support instance segmentation!!  In this API update we support a number of instance segmentation models similar to those discussed in the [Mask R-CNN paper](https://arxiv.org/abs/1703.06870). For further details refer to\n[our slides](http://presentations.cocodataset.org/Places17-GMRI.pdf) from the 2017 Coco + Places Workshop.\nRefer to the section on [Running an Instance Segmentation Model](g3doc/instance_segmentation.md) for instructions on how to configure a model\nthat predicts masks in addition to object bounding boxes.\n\n<b>Thanks to contributors</b>: Alireza Fathi, Zhichao Lu, Vivek Rathod, Ronny Votel, Jonathan Huang\n\n### November 17, 2017\n\nAs a part of the Open Images V3 release we have released:\n\n* An implementation of the Open Images evaluation metric and the [protocol](g3doc/evaluation_protocols.md#open-images).\n* Additional tools to separate inference of detection and evaluation (see [this tutorial](g3doc/oid_inference_and_evaluation.md)).\n* A new detection model trained on the Open Images V2 data release (see [Open Images model](g3doc/detection_model_zoo.md#open-images-models)).\n\nSee more information on the [Open Images website](https://github.com/openimages/dataset)!\n\n<b>Thanks to contributors</b>: Stefan Popov, Alina Kuznetsova\n\n### November 6, 2017\n\nWe have re-released faster versions of our (pre-trained) models in the\n<a href='g3doc/detection_model_zoo.md'>model zoo</a>.  In addition to what\nwas available before, we are also adding Faster R-CNN models trained on COCO\nwith Inception V2 and Resnet-50 feature extractors, as well as a Faster R-CNN\nwith Resnet-101 model trained on the KITTI dataset.\n\n<b>Thanks to contributors</b>: Jonathan Huang, Vivek Rathod, Derek Chow,\nTal Remez, Chen Sun.\n\n### October 31, 2017\n\nWe have released a new state-of-the-art model for object detection using\nthe Faster-RCNN with the\n[NASNet-A image featurization](https://arxiv.org/abs/1707.07012). This\nmodel achieves mAP of 43.1% on the test-dev validation dataset for COCO,\nimproving on the best available model in the zoo by 6% in terms\nof absolute mAP.\n\n<b>Thanks to contributors</b>: Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc Le\n\n### August 11, 2017\n\nWe have released an update to the [Android Detect\ndemo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)\nwhich will now run models trained using the Tensorflow Object\nDetection API on an Android device.  By default, it currently runs a\nfrozen SSD w/Mobilenet detector trained on COCO, but we encourage\nyou to try out other detection models!\n\n<b>Thanks to contributors</b>: Jonathan Huang, Andrew Harp\n\n\n### June 15, 2017\n\nIn addition to our base Tensorflow detection model definitions, this\nrelease includes:\n\n* A selection of trainable detection models, including:\n  * Single Shot Multibox Detector (SSD) with MobileNet,\n  * SSD with Inception V2,\n  * Region-Based Fully Convolutional Networks (R-FCN) with Resnet 101,\n  * Faster RCNN with Resnet 101,\n  * Faster RCNN with Inception Resnet v2\n* Frozen weights (trained on the COCO dataset) for each of the above models to\n  be used for out-of-the-box inference purposes.\n* A [Jupyter notebook](object_detection_tutorial.ipynb) for performing\n  out-of-the-box inference with one of our released models\n* Convenient [local training](g3doc/running_locally.md) scripts as well as\n  distributed training and evaluation pipelines via\n  [Google Cloud](g3doc/running_on_cloud.md).\n\n\n<b>Thanks to contributors</b>: Jonathan Huang, Vivek Rathod, Derek Chow,\nChen Sun, Menglong Zhu, Matthew Tang, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, Jasper Uijlings,\nViacheslav Kovalevskyi, Kevin Murphy\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/brandonschabell/models/tree/master/research/object_detection", "keywords": "", "license": "Apache License 2.0", "maintainer": "", "maintainer_email": "", "name": "object-detection", "package_url": "https://pypi.org/project/object-detection/", "platform": "", "project_url": "https://pypi.org/project/object-detection/", "project_urls": {"Homepage": "https://github.com/brandonschabell/models/tree/master/research/object_detection"}, "release_url": "https://pypi.org/project/object-detection/0.0.3/", "requires_dist": ["tensorflow", "Cython", "contextlib2", "pillow", "lxml", "jupyter", "matplotlib"], "requires_python": ">=3.5, !=3.7.*", "summary": "A package build from Tensorflow's object detection API.", "version": "0.0.3", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Tensorflow Object Detection API</h1>\n<p>Creating accurate machine learning models capable of localizing and identifying\nmultiple objects in a single image remains a core challenge in computer vision.\nThe TensorFlow Object Detection API is an open source framework built on top of\nTensorFlow that makes it easy to construct, train and deploy object detection\nmodels.  At Google we\u2019ve certainly found this codebase to be useful for our\ncomputer vision needs, and we hope that you will as well.</p>\n<p align=\"center\">\n  <img height=\"450\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/20c7f802f12c7a41448037b3ee7a77ed5a61b06f/6733646f632f696d672f6b697465735f646574656374696f6e735f6f75747075742e6a7067\" width=\"676\">\n</p>\nContributions to the codebase are welcome and we would love to hear back from\nyou if you find this API useful.  Finally if you use the Tensorflow Object\nDetection API for a research publication, please consider citing:\n<pre><code>\"Speed/accuracy trade-offs for modern convolutional object detectors.\"\nHuang J, Rathod V, Sun C, Zhu M, Korattikara A, Fathi A, Fischer I, Wojna Z,\nSong Y, Guadarrama S, Murphy K, CVPR 2017\n</code></pre>\n<p>[<a href=\"https://arxiv.org/abs/1611.10012\" rel=\"nofollow\">link</a>][<a href=\"https://scholar.googleusercontent.com/scholar.bib?q=info:l291WsrB-hQJ:scholar.google.com/&amp;output=citation&amp;scisig=AAGBfm0AAAAAWUIIlnPZ_L9jxvPwcC49kDlELtaeIyU-&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en&amp;scfhb=1\" rel=\"nofollow\">bibtex</a>]</p>\n<p align=\"center\">\n  <img height=\"195\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/40f695f2ae4a18b7d9811075fc3b83da4233ec51/6733646f632f696d672f74662d6f642d6170692d6c6f676f2e706e67\" width=\"140\">\n</p>\n<h2>Maintainers</h2>\n<ul>\n<li>Jonathan Huang, github: <a href=\"https://github.com/jch1\" rel=\"nofollow\">jch1</a></li>\n<li>Vivek Rathod, github: <a href=\"https://github.com/tombstone\" rel=\"nofollow\">tombstone</a></li>\n<li>Ronny Votel, github: <a href=\"https://github.com/ronnyvotel\" rel=\"nofollow\">ronnyvotel</a></li>\n<li>Derek Chow, github: <a href=\"https://github.com/derekjchow\" rel=\"nofollow\">derekjchow</a></li>\n<li>Chen Sun, github: <a href=\"https://github.com/jesu9\" rel=\"nofollow\">jesu9</a></li>\n<li>Menglong Zhu, github: <a href=\"https://github.com/dreamdragon\" rel=\"nofollow\">dreamdragon</a></li>\n<li>Alireza Fathi, github: <a href=\"https://github.com/afathi3\" rel=\"nofollow\">afathi3</a></li>\n<li>Zhichao Lu, github: <a href=\"https://github.com/pkulzc\" rel=\"nofollow\">pkulzc</a></li>\n</ul>\n<h2>Table of contents</h2>\n<p>Setup:</p>\n<ul>\n<li><a href=\"g3doc/installation.md\" rel=\"nofollow\">Installation</a><br></li>\n</ul>\n<p>Quick Start:</p>\n<ul>\n<li>\n<a href=\"object_detection_tutorial.ipynb\" rel=\"nofollow\">\n  Quick Start: Jupyter notebook for off-the-shelf inference</a><br>\n</li>\n<li><a href=\"g3doc/running_pets.md\" rel=\"nofollow\">Quick Start: Training a pet detector</a><br></li>\n</ul>\n<p>Customizing a Pipeline:</p>\n<ul>\n<li>\n<a href=\"g3doc/configuring_jobs.md\" rel=\"nofollow\">\n  Configuring an object detection pipeline</a><br>\n</li>\n<li><a href=\"g3doc/preparing_inputs.md\" rel=\"nofollow\">Preparing inputs</a><br></li>\n</ul>\n<p>Running:</p>\n<ul>\n<li><a href=\"g3doc/running_locally.md\" rel=\"nofollow\">Running locally</a><br></li>\n<li><a href=\"g3doc/running_on_cloud.md\" rel=\"nofollow\">Running on the cloud</a><br></li>\n</ul>\n<p>Extras:</p>\n<ul>\n<li><a href=\"g3doc/detection_model_zoo.md\" rel=\"nofollow\">Tensorflow detection model zoo</a><br></li>\n<li>\n<a href=\"g3doc/exporting_models.md\" rel=\"nofollow\">\n  Exporting a trained model for inference</a><br>\n</li>\n<li>\n<a href=\"g3doc/defining_your_own_model.md\" rel=\"nofollow\">\n  Defining your own model architecture</a><br>\n</li>\n<li>\n<a href=\"g3doc/using_your_own_dataset.md\" rel=\"nofollow\">\n  Bringing in your own dataset</a><br>\n</li>\n<li>\n<a href=\"g3doc/evaluation_protocols.md\" rel=\"nofollow\">\n  Supported object detection evaluation protocols</a><br>\n</li>\n<li>\n<a href=\"g3doc/oid_inference_and_evaluation.md\" rel=\"nofollow\">\n  Inference and evaluation on the Open Images dataset</a><br>\n</li>\n<li>\n<a href=\"g3doc/instance_segmentation.md\" rel=\"nofollow\">\n  Run an instance segmentation model</a><br>\n</li>\n<li>\n<a href=\"g3doc/challenge_evaluation.md\" rel=\"nofollow\">\n  Run the evaluation for the Open Images Challenge 2018</a><br>\n</li>\n<li>\n<a href=\"g3doc/tpu_compatibility.md\" rel=\"nofollow\">\n  TPU compatible detection pipelines</a><br>\n</li>\n<li>\n<a href=\"g3doc/running_on_mobile_tensorflowlite.md\" rel=\"nofollow\">\n  Running object detection on mobile devices with TensorFlow Lite</a><br>\n</li>\n</ul>\n<h2>Getting Help</h2>\n<p>To get help with issues you may encounter using the Tensorflow Object Detection\nAPI, create a new question on <a href=\"https://stackoverflow.com/\" rel=\"nofollow\">StackOverflow</a> with\nthe tags \"tensorflow\" and \"object-detection\".</p>\n<p>Please report bugs (actually broken code, not usage questions) to the\ntensorflow/models GitHub\n<a href=\"https://github.com/tensorflow/models/issues\" rel=\"nofollow\">issue tracker</a>, prefixing the\nissue name with \"object_detection\".</p>\n<p>Please check <a href=\"g3doc/faq.md\" rel=\"nofollow\">FAQ</a> for frequently asked questions before\nreporting an issue.</p>\n<h2>Release information</h2>\n<h3>Sep 17, 2018</h3>\n<p>We have released Faster R-CNN detectors with ResNet-50 / ResNet-101 feature\nextractors trained on the <a href=\"https://github.com/visipedia/inat_comp/blob/master/2017/README.md#bounding-boxes\" rel=\"nofollow\">iNaturalist Species Detection Dataset</a>.\nThe models are trained on the training split of the iNaturalist data for 4M\niterations, they achieve 55% and 58% mean AP@.5 over 2854 classes respectively.\nFor more details please refer to this <a href=\"https://arxiv.org/abs/1707.06642\" rel=\"nofollow\">paper</a>.</p>\n<p><b>Thanks to contributors</b>: Chen Sun</p>\n<h3>July 13, 2018</h3>\n<p>There are many new updates in this release, extending the functionality and\ncapability of the API:</p>\n<ul>\n<li>Moving from slim-based training to <a href=\"https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator\" rel=\"nofollow\">Estimator</a>-based\ntraining.</li>\n<li>Support for <a href=\"https://arxiv.org/abs/1708.02002\" rel=\"nofollow\">RetinaNet</a>, and a <a href=\"https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html\" rel=\"nofollow\">MobileNet</a>\nadaptation of RetinaNet.</li>\n<li>A novel SSD-based architecture called the <a href=\"https://arxiv.org/abs/1807.03284\" rel=\"nofollow\">Pooling Pyramid Network</a> (PPN).</li>\n<li>Releasing several <a href=\"https://cloud.google.com/tpu/\" rel=\"nofollow\">TPU</a>-compatible models.\nThese can be found in the <code>samples/configs/</code> directory with a comment in the\npipeline configuration files indicating TPU compatibility.</li>\n<li>Support for quantized training.</li>\n<li>Updated documentation for new binaries, Cloud training, and <a href=\"https://www.tensorflow.org/mobile/tflite/\" rel=\"nofollow\">Tensorflow Lite</a>.</li>\n</ul>\n<p>See also our <a href=\"https://ai.googleblog.com/2018/07/accelerated-training-and-inference-with.html\" rel=\"nofollow\">expanded announcement blogpost</a> and accompanying tutorial at the <a href=\"https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\" rel=\"nofollow\">TensorFlow blog</a>.</p>\n<p><b>Thanks to contributors</b>: Sara Robinson, Aakanksha Chowdhery, Derek Chow,\nPengchong Jin, Jonathan Huang, Vivek Rathod, Zhichao Lu, Ronny Votel</p>\n<h3>June 25, 2018</h3>\n<p>Additional evaluation tools for the <a href=\"https://storage.googleapis.com/openimages/web/challenge.html\" rel=\"nofollow\">Open Images Challenge 2018</a> are out.\nCheck out our short tutorial on data preparation and running evaluation <a href=\"g3doc/challenge_evaluation.md\" rel=\"nofollow\">here</a>!</p>\n<p><b>Thanks to contributors</b>: Alina Kuznetsova</p>\n<h3>June 5, 2018</h3>\n<p>We have released the implementation of evaluation metrics for both tracks of the <a href=\"https://storage.googleapis.com/openimages/web/challenge.html\" rel=\"nofollow\">Open Images Challenge 2018</a> as a part of the Object Detection API - see the <a href=\"g3doc/evaluation_protocols.md\" rel=\"nofollow\">evaluation protocols</a> for more details.\nAdditionally, we have released a tool for hierarchical labels expansion for the Open Images Challenge: check out <a href=\"dataset_tools/oid_hierarchical_labels_expansion.py\" rel=\"nofollow\">oid_hierarchical_labels_expansion.py</a>.</p>\n<p><b>Thanks to contributors</b>: Alina Kuznetsova, Vittorio Ferrari, Jasper Uijlings</p>\n<h3>April 30, 2018</h3>\n<p>We have released a Faster R-CNN detector with ResNet-101 feature extractor trained on <a href=\"https://research.google.com/ava/\" rel=\"nofollow\">AVA</a> v2.1.\nCompared with other commonly used object detectors, it changes the action classification loss function to per-class Sigmoid loss to handle boxes with multiple labels.\nThe model is trained on the training split of AVA v2.1 for 1.5M iterations, it achieves mean AP of 11.25% over 60 classes on the validation split of AVA v2.1.\nFor more details please refer to this <a href=\"https://arxiv.org/abs/1705.08421\" rel=\"nofollow\">paper</a>.</p>\n<p><b>Thanks to contributors</b>: Chen Sun, David Ross</p>\n<h3>April 2, 2018</h3>\n<p>Supercharge your mobile phones with the next generation mobile object detector!\nWe are adding support for MobileNet V2 with SSDLite presented in\n<a href=\"https://arxiv.org/abs/1801.04381\" rel=\"nofollow\">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a>.\nThis model is 35% faster than Mobilenet V1 SSD on a Google Pixel phone CPU (200ms vs. 270ms) at the same accuracy.\nAlong with the model definition, we are also releasing a model checkpoint trained on the COCO dataset.</p>\n<p><b>Thanks to contributors</b>: Menglong Zhu, Mark Sandler, Zhichao Lu, Vivek Rathod, Jonathan Huang</p>\n<h3>February 9, 2018</h3>\n<p>We now support instance segmentation!!  In this API update we support a number of instance segmentation models similar to those discussed in the <a href=\"https://arxiv.org/abs/1703.06870\" rel=\"nofollow\">Mask R-CNN paper</a>. For further details refer to\n<a href=\"http://presentations.cocodataset.org/Places17-GMRI.pdf\" rel=\"nofollow\">our slides</a> from the 2017 Coco + Places Workshop.\nRefer to the section on <a href=\"g3doc/instance_segmentation.md\" rel=\"nofollow\">Running an Instance Segmentation Model</a> for instructions on how to configure a model\nthat predicts masks in addition to object bounding boxes.</p>\n<p><b>Thanks to contributors</b>: Alireza Fathi, Zhichao Lu, Vivek Rathod, Ronny Votel, Jonathan Huang</p>\n<h3>November 17, 2017</h3>\n<p>As a part of the Open Images V3 release we have released:</p>\n<ul>\n<li>An implementation of the Open Images evaluation metric and the <a href=\"g3doc/evaluation_protocols.md#open-images\" rel=\"nofollow\">protocol</a>.</li>\n<li>Additional tools to separate inference of detection and evaluation (see <a href=\"g3doc/oid_inference_and_evaluation.md\" rel=\"nofollow\">this tutorial</a>).</li>\n<li>A new detection model trained on the Open Images V2 data release (see <a href=\"g3doc/detection_model_zoo.md#open-images-models\" rel=\"nofollow\">Open Images model</a>).</li>\n</ul>\n<p>See more information on the <a href=\"https://github.com/openimages/dataset\" rel=\"nofollow\">Open Images website</a>!</p>\n<p><b>Thanks to contributors</b>: Stefan Popov, Alina Kuznetsova</p>\n<h3>November 6, 2017</h3>\n<p>We have re-released faster versions of our (pre-trained) models in the\n<a href=\"g3doc/detection_model_zoo.md\" rel=\"nofollow\">model zoo</a>.  In addition to what\nwas available before, we are also adding Faster R-CNN models trained on COCO\nwith Inception V2 and Resnet-50 feature extractors, as well as a Faster R-CNN\nwith Resnet-101 model trained on the KITTI dataset.</p>\n<p><b>Thanks to contributors</b>: Jonathan Huang, Vivek Rathod, Derek Chow,\nTal Remez, Chen Sun.</p>\n<h3>October 31, 2017</h3>\n<p>We have released a new state-of-the-art model for object detection using\nthe Faster-RCNN with the\n<a href=\"https://arxiv.org/abs/1707.07012\" rel=\"nofollow\">NASNet-A image featurization</a>. This\nmodel achieves mAP of 43.1% on the test-dev validation dataset for COCO,\nimproving on the best available model in the zoo by 6% in terms\nof absolute mAP.</p>\n<p><b>Thanks to contributors</b>: Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc Le</p>\n<h3>August 11, 2017</h3>\n<p>We have released an update to the <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\" rel=\"nofollow\">Android Detect\ndemo</a>\nwhich will now run models trained using the Tensorflow Object\nDetection API on an Android device.  By default, it currently runs a\nfrozen SSD w/Mobilenet detector trained on COCO, but we encourage\nyou to try out other detection models!</p>\n<p><b>Thanks to contributors</b>: Jonathan Huang, Andrew Harp</p>\n<h3>June 15, 2017</h3>\n<p>In addition to our base Tensorflow detection model definitions, this\nrelease includes:</p>\n<ul>\n<li>A selection of trainable detection models, including:\n<ul>\n<li>Single Shot Multibox Detector (SSD) with MobileNet,</li>\n<li>SSD with Inception V2,</li>\n<li>Region-Based Fully Convolutional Networks (R-FCN) with Resnet 101,</li>\n<li>Faster RCNN with Resnet 101,</li>\n<li>Faster RCNN with Inception Resnet v2</li>\n</ul>\n</li>\n<li>Frozen weights (trained on the COCO dataset) for each of the above models to\nbe used for out-of-the-box inference purposes.</li>\n<li>A <a href=\"object_detection_tutorial.ipynb\" rel=\"nofollow\">Jupyter notebook</a> for performing\nout-of-the-box inference with one of our released models</li>\n<li>Convenient <a href=\"g3doc/running_locally.md\" rel=\"nofollow\">local training</a> scripts as well as\ndistributed training and evaluation pipelines via\n<a href=\"g3doc/running_on_cloud.md\" rel=\"nofollow\">Google Cloud</a>.</li>\n</ul>\n<p><b>Thanks to contributors</b>: Jonathan Huang, Vivek Rathod, Derek Chow,\nChen Sun, Menglong Zhu, Matthew Tang, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, Jasper Uijlings,\nViacheslav Kovalevskyi, Kevin Murphy</p>\n\n          </div>"}, "last_serial": 4708363, "releases": {"0.0.3": [{"comment_text": "", "digests": {"md5": "550e4b502d29a7a4fea8067b18335b90", "sha256": "a487aa0eada8105a9bb026b0993f251f6e0b8b0ae8fb69c2de3381394aa49b9c"}, "downloads": -1, "filename": "object_detection-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "550e4b502d29a7a4fea8067b18335b90", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, !=3.7.*", "size": 1488520, "upload_time": "2019-01-17T15:00:22", "upload_time_iso_8601": "2019-01-17T15:00:22.399316Z", "url": "https://files.pythonhosted.org/packages/b7/37/24d57adb29a0242aca08b99cb2ad08c2b427c05c988f169622c401a6f9ed/object_detection-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82bff11e01a8e9648c4cd9971852a815", "sha256": "8dae59bb3c7b4a6d7fcf8c2862971afdd9cd966deafba14f521fb11b3df3d069"}, "downloads": -1, "filename": "object_detection-0.0.3.tar.gz", "has_sig": false, "md5_digest": "82bff11e01a8e9648c4cd9971852a815", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5, !=3.7.*", "size": 504105, "upload_time": "2019-01-17T15:00:25", "upload_time_iso_8601": "2019-01-17T15:00:25.414181Z", "url": "https://files.pythonhosted.org/packages/61/40/00826e52abc78b1fac0c3fbabdbede418de13cd177fb1abdc5e9f2f6ff99/object_detection-0.0.3.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "550e4b502d29a7a4fea8067b18335b90", "sha256": "a487aa0eada8105a9bb026b0993f251f6e0b8b0ae8fb69c2de3381394aa49b9c"}, "downloads": -1, "filename": "object_detection-0.0.3-py3-none-any.whl", "has_sig": false, "md5_digest": "550e4b502d29a7a4fea8067b18335b90", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.5, !=3.7.*", "size": 1488520, "upload_time": "2019-01-17T15:00:22", "upload_time_iso_8601": "2019-01-17T15:00:22.399316Z", "url": "https://files.pythonhosted.org/packages/b7/37/24d57adb29a0242aca08b99cb2ad08c2b427c05c988f169622c401a6f9ed/object_detection-0.0.3-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "82bff11e01a8e9648c4cd9971852a815", "sha256": "8dae59bb3c7b4a6d7fcf8c2862971afdd9cd966deafba14f521fb11b3df3d069"}, "downloads": -1, "filename": "object_detection-0.0.3.tar.gz", "has_sig": false, "md5_digest": "82bff11e01a8e9648c4cd9971852a815", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5, !=3.7.*", "size": 504105, "upload_time": "2019-01-17T15:00:25", "upload_time_iso_8601": "2019-01-17T15:00:25.414181Z", "url": "https://files.pythonhosted.org/packages/61/40/00826e52abc78b1fac0c3fbabdbede418de13cd177fb1abdc5e9f2f6ff99/object_detection-0.0.3.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:43:50 2020"}