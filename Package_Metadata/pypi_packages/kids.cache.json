{"info": {"author": "Valentin LAB", "author_email": "valentin.lab@kalysto.org", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python", "Topic :: Software Development", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "==========\nkids.cache\n==========\n\n\n.. image:: http://img.shields.io/pypi/v/kids.cache.svg?style=flat\n   :target: https://pypi.python.org/pypi/kids.cache/\n   :alt: Latest PyPI version\n\n.. image:: http://img.shields.io/pypi/dm/kids.cache.svg?style=flat\n   :target: https://pypi.python.org/pypi/kids.cache/\n   :alt: Number of PyPI downloads\n\n.. image:: http://img.shields.io/travis/0k/kids.cache/master.svg?style=flat\n   :target: https://travis-ci.org/0k/kids.cache/\n   :alt: Travis CI build status\n\n.. image:: http://img.shields.io/coveralls/0k/kids.cache/master.svg?style=flat\n   :target: https://coveralls.io/r/0k/kids.cache\n   :alt: Test coverage\n\n\n``kids.cache`` is a Python library providing a cache decorator.\nIt's part of 'Kids' (for Keep It Dead Simple) library. It has\nno dependency to any python library.\n\nIts main concern is to offer a very simple default usage scheme,\nwithout forgetting to offer full power inside when needed.\n\n\n\nMaturity\n========\n\nThis code is around ~100 lines of python, and it has a 100% test\ncoverage.\n\nHowever it still considered beta stage currently.\n\n\nCompatibility\n=============\n\n\nIt is small and simple and should work anywhere.\n\nTo put it in longer details: the current code is simple enough that it\nuse a common subset of python that is compatible with any platform on\npython 2.7 and python >= 3... and this without any specific\nmodification.\n\nEven then, You'll be happy to know that, this code is tested for\ncompatibility at each commit with python 2.7, 3.4, 3.5, 3.6 on linux\nand windows platform.\n\n\nFeatures\n========\n\n- Use one simple call to ``@cache``, and a majority of all hidden complexity\n  will vanish.\n\n  - works out of the box everywhere you can stick a decorator\n    (function, methods, property, classes...).\n  - support to be called before or after common decorators as\n    ``@property``, ``@classmethod``, ``@staticmethod``.\n\n- With ``@cache`` several design pattern can be achieved:\n\n  - *memoization* when used on function with arguments.\n  - *lazy evaluation* when placed on properties.\n  - *singleton* patterns when placed on classes.\n\n- Full customization at disposition:\n\n  - cache clearing or cache stats functionality.\n  - support of any cache store mecanism from `cachetools`_ package.\n  - support of custom key function which allows:\n\n    - support of your exotic unhashable objects\n    - fine tune which function calls can be considered identic\n    - hand pick function dependencies in object (for method)\n\n\n.. _cachetools: https://github.com/tkem/cachetools\n\n\nBasic Usage\n===========\n\nFunction\n--------\n\nThis cache decorator is quite straightforward to use::\n\n    >>> from kids.cache import cache\n\n    >>> @cache\n    ... def answer_to_everything():\n    ...     print(\"many insightfull calculation\")\n    ...     return 42\n\nThen the function ``answer_to_everything`` would only do the\ncalculation the first time called, and would save the result, and\ndirectly return it the next calls::\n\n    >>> answer_to_everything()\n    many insightfull calculation\n    42\n\n    >>> answer_to_everything()\n    42\n\nThe body of the function was not executed anymore and the cache value\nwas used.\n\nIt'll work with arguments::\n\n    >>> @cache\n    ... def mysum(*args):\n    ...     print(\"calculating...\")\n    ...     return sum(args)\n\n    >>> mysum(2, 2, 3)\n    calculating...\n    7\n    >>> mysum(1, 1, 1, 1)\n    calculating...\n    4\n    >>> mysum(2, 2, 3)\n    7\n    >>> mysum(1, 1, 1, 1)\n    4\n\nAnd notice that by default, object are not typed, thus::\n\n    >>> mysum(1.0, 1, 1, 1)\n    4\n\nDid trigger the cache, despite the first argument is a float and not\nan integer.\n\n\nMethods\n-------\n\nWith methods::\n\n    >>> class MyObject(object):\n    ...    def __init__(self, a, b):\n    ...        self.a, self.b = a, b\n    ...\n    ...    @cache\n    ...    def total(self):\n    ...        print(\"calculating...\")\n    ...        return self.a + self.b\n\n    >>> xx = MyObject(2, 3)\n    >>> xx.total()\n    calculating...\n    5\n    >>> xx.total()\n    5\n\nCache is not shared between instances::\n\n    >>> yy = MyObject(2, 3)\n    >>> yy.total()\n    calculating...\n    5\n\nOf course, if you change the inner values of the instance, this\nwill NOT be detected by the caching method::\n\n    >>> xx.a = 5\n    >>> xx.total()\n    5\n\nLook at advanced usages to see how to changes some of these behaviors.\n\n\nProperty\n--------\n\nYou can use the ``cache`` decorator with properties, and\nprovides a good way to have lazy evaluated attributes::\n\n    >>> class WithProperty(MyObject):\n    ...\n    ...    @property\n    ...    @cache\n    ...    def total(self):\n    ...        print(\"evaluating...\")\n    ...        return self.a + self.b\n\n    >>> xx = WithProperty(1, 1)\n    >>> xx.total\n    evaluating...\n    2\n    >>> xx.total\n    2\n\nYou can use ``@cache`` decorator before or after ``@property``\ndecorator::\n\n    >>> class WithProperty(MyObject):\n    ...\n    ...    @cache\n    ...    @property\n    ...    def total(self):\n    ...        print(\"evaluating...\")\n    ...        return self.a + self.b\n\n    >>> xx = WithProperty(2, 2)\n    >>> xx.total\n    evaluating...\n    4\n    >>> xx.total\n    4\n\nclassmethod\n-----------\n\nYou can use the ``cache`` decorator with classmethods, and\nprovides a good way to share cache between instances::\n\n    >>> class WithClassMethod(MyObject):\n    ...\n    ...    a = 2\n    ...    b = 3\n    ...\n    ...    @classmethod\n    ...    @cache\n    ...    def total(cls):\n    ...        print(\"evaluating...\")\n    ...        return cls.a + cls.b\n\n    >>> WithClassMethod.total()\n    evaluating...\n    5\n    >>> WithClassMethod.total()\n    5\n\nYou can use ``@cache`` decorator before or after ``@property``\ndecorator::\n\n    >>> class WithClassMethod(MyObject):\n    ...\n    ...    a = 1\n    ...    b = 6\n    ...\n    ...    @cache\n    ...    @classmethod\n    ...    def total(cls):\n    ...        print(\"evaluating...\")\n    ...        return cls.a + cls.b\n\n    >>> WithClassMethod.total()\n    evaluating...\n    7\n    >>> WithClassMethod.total()\n    7\n\nstaticmethod\n------------\n\nYou can use the ``cache`` decorator with staticmethods::\n\n    >>> class WithStaticMethod(MyObject):\n    ...\n    ...    @staticmethod\n    ...    @cache\n    ...    def total(a, b):\n    ...        print(\"evaluating...\")\n    ...        return a + b\n\n    >>> WithStaticMethod.total(1, 3)\n    evaluating...\n    4\n    >>> WithStaticMethod.total(1, 3)\n    4\n\nYou can use ``@cache`` decorator before or after ``@property``\ndecorator::\n\n    >>> class WithStaticMethod(MyObject):\n    ...\n    ...    @cache\n    ...    @staticmethod\n    ...    def total(a, b):\n    ...        print(\"evaluating...\")\n    ...        return a + b\n\n    >>> WithStaticMethod.total(2, 6)\n    evaluating...\n    8\n    >>> WithStaticMethod.total(2, 6)\n    8\n\n\nclass\n-----\n\nUsing ``cache`` with classes will allow variations around the \nnotion of singletons. A singleton shares the same id in memory,\nso this shows a classical non-singleton behavior::\n\n    >>> a, b = object(), object()\n    >>> id(a) == id(b)\n    False\n\n\nFactory based singleton\n~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can use the ``cache`` decorator with classes, effectively\nimplementing a factory pattern for creating singleton::\n\n    >>> @cache\n    ... class MySingleton(MyObject):\n    ...     def __new__(cls):\n    ...         print(\"instanciating...\")\n    ...         return MyObject.__new__(cls)\n    ...     def __init__(self):\n    ...         print(\"initializing...\")\n\n    >>> a, b = MySingleton(), MySingleton()\n    instanciating...\n    initializing...\n    >>> id(a) == id(b)\n    True\n\nNotice that both instance are the same object, so it was only\ninstanciated and initialized once.\n\nBut be warned: this is not anymore a class::\n\n    >>> MySingleton\n    <function MySingleton at ...>\n\n\nInstanciation based singletons\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSlightly different, the class singleton pattern can be achieved by\ncaching ``__new__``::\n\n    >>> class MySingleton(MyObject):\n    ...     @cache\n    ...     def __new__(cls):\n    ...         print(\"instanciating...\")\n    ...         return MyObject.__new__(cls)\n    ...     def __init__(self):\n    ...         print(\"initializing...\")\n\n    >>> a, b = MySingleton(), MySingleton()\n    instanciating...\n    initializing...\n    initializing...\n    >>> id(a) == id(b)\n    True\n\nNotice that both instance are the same object, so it was only\ninstanciated once. But the ``__init__`` was called both times.\nThis is sometimes perfectly valid, but you might want to avoid this\nalso.\n\nSo if you don't want this, you should cache also ``__init__`` method::\n\n    >>> class MySingleton(MyObject):\n    ...     @cache\n    ...     def __new__(cls):\n    ...         print(\"instanciating...\")\n    ...         return MyObject.__new__(cls)\n    ...     @cache\n    ...     def __init__(self):\n    ...         print(\"initializing...\")\n\n    >>> a, b = MySingleton(), MySingleton()\n    instanciating...\n    initializing...\n    >>> id(a) == id(b)\n    True\n\nFor both cases you'll keep your full object untouched of course::\n\n    >>> MySingleton\n    <class 'MySingleton'>\n\n\nSingleton with arguments\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nActually, these are only singletons if you call them successively with\nthe same arguments.\n\nOr to be more precise, you can share your classes when their\ninstanciation's arguments are the same::\n\n    >>> @cache\n    ... class MySingleton(MyObject):\n    ...     def __init__(self, a):\n    ...         self.a = a\n    ...         print(\"evaluating...\")\n\n    >>> a, b = MySingleton(1), MySingleton(2)\n    evaluating...\n    evaluating...\n    >>> id(a) == id(b)\n    False\n\nBut::\n\n    >>> c = MySingleton(1)\n    >>> id(a) == id(c)\n    True\n\nIf you want a singleton that give you the same instance even if your\nsuccessive calls differs, you should check the advanced usage section\nand the ``key`` argument.\n\n\nAdvanced Usage\n==============\n\nMost of the advanced usage implies to call the ``@cache`` decorator with\narguments. Please notice that::\n\n    >>> @cache\n    ... def mysum1(*args):\n    ...     print(\"calculating...\")\n    ...     return sum(args)\n\nOr::\n\n    >>> @cache()\n    ... def mysum2(*args):\n    ...     print(\"calculating...\")\n    ...     return sum(args)\n\nis equivalent::\n\n    >>> mysum1(1,1)\n    calculating...\n    2\n    >>> mysum1(1,1)\n    2\n\n    >>> mysum2(1,1)\n    calculating...\n    2\n    >>> mysum2(1,1)\n    2\n\n\nProvide a key function\n----------------------\n\nProviding a key function can be extremely powerfull and will allow to\nfine tune when the cache should be recalculated.\n\n``hashing`` functions will receive exactly the same arguments than the\nmain function called. It must return an hashable structure\n(combination of ``tuples``, ``int``, ``string``... avoid list, dicts and\nsets). This will identify uniquely the result.\n\nFor example you could::\n\n    >>> class WithKey(MyObject):\n    ...    @cache(key=lambda s: (id(s), s.a, s.b))\n    ...    def total(self):\n    ...        print(\"calculating...\")\n    ...        return self.a + self.b\n\n    >>> xx = WithKey(2, 3)\n    >>> xx.total()\n    calculating...\n    5\n    >>> xx.total()\n    5\n\nIt should detect changes of the given values of the instance::\n\n    >>> xx.a = 5\n    >>> xx.total()\n    calculating...\n    8\n\nWithout bothering to recalculate when other values change::\n\n    >>> xx.c = 7\n    >>> xx.total()\n    8\n\nBut it should still make a difference between instances::\n\n    >>> yy = WithKey(2, 3)\n    >>> yy.total()\n    calculating...\n    5\n\nThis last example is important as you could have wanted to share the\ncache between all instances. You could have done this easily by\navoiding returning ``id(s)`` in the ``key`` function.\n\n\nTyped key functions\n-------------------\n\nYou could ask for ``typed`` argument to NOT be treated the same::\n\n    >>> @cache(typed=True)\n    ... def mysum(*args):\n    ...     print(\"calculating...\")\n    ...     return sum(args)\n    >>> mysum(1, 1)\n    calculating...\n    2\n\n    >>> mysum(1.0, 1)\n    calculating...\n    2.0\n\n\ndefault key functions\n---------------------\n\nThe default key function if not provided is a bold try to make ``list``\nand ``dict``, ``set`` also keyable despite these not being hashable.\n\nThe name of the key function is called ``hippie_hashing``, and this is\nthe default value for the key argument::\n\n    >>> from kids.cache import hippie_hashing\n\n    >>> @cache(key=hippie_hashing)\n    ... def mylength(obj):\n    ...     return len(obj)\n\nThis allows you to use the function with list, dict or combination of these::\n\n    >>> mylength([set([3]), 2, {1: 2}])\n    3\n\nEven your objects could be used as key, as long as they are hashable::\n\n    >>> class MyObj(object):  ## object subclasses have a default hash\n    ...     length = 5\n    ...     def __len__(self, ):\n    ...         print('calculating...')\n    ...         return self.length\n\n    >>> myobj = MyObj()\n    >>> mylength(myobj)\n    calculating...\n    5\n\n    >>> mylength(myobj)\n    5\n\nBe assured that hash collision (they happen!) won't generate cache collisions::\n\n    >>> class MyCollidingHashObj(MyObj):\n    ...     def __init__(self, length):\n    ...          self.length = length\n    ...     def __hash__(self):\n    ...          return 1\n\n    >>> hash_collide1 = MyCollidingHashObj(6)\n    >>> hash_collide2 = MyCollidingHashObj(7)\n\n    >>> mylength(hash_collide1)\n    calculating...\n    6\n    >>> mylength(hash_collide2)\n    calculating...\n    7\n\nBut try to avoid them for performance's sake !! And you should\nprobably be aware that if your object compare equal, then THERE WILL\nBE a cache collision (but at this point, this is probably what you\nwanted, heh ?)::\n\n    >>> class MyEqCollidingHashObj(MyCollidingHashObj):\n    ...     def __eq__(self, value):\n    ...          return True\n    ...     def __hash__(self):\n    ...          return 1\n\n    >>> eq_and_hash_collide1 = MyEqCollidingHashObj(8)\n    >>> eq_and_hash_collide2 = MyEqCollidingHashObj(9)\n\n    >>> mylength(eq_and_hash_collide1)\n    calculating...\n    8\n    >>> mylength(eq_and_hash_collide2)\n    8\n\nHuh oh. This is not what was probably expected in this example, but\nyou really had to work hard to make this happen. And most of the time,\nyou'll probably find this convenient and will use it at you advantage.\nIt's a little bit like an extension of the ``key`` mecanism that is\nthe objects responsability.\n\n.. note:: Please verify also that if your object compares the same, their\n  hash HAS TO BE the same. For this very reason, in Python3, when you\n  define the ``__eq__`` method, it'll remove the default ``__hash__``\n  from objects.\n\n\nOf course, ``hippie_hashing`` will fail on special unhashable object::\n\n    >>> class Unhashable(object):\n    ...    def __hash__(self):\n    ...        raise ValueError(\"unhashable!\")\n\n    >>> hippie_hashing(Unhashable())  ## doctest: +ELLIPSIS\n    Traceback (most recent call last):\n    ...\n    ValueError: <Unhashable ...> can not be hashed. Try providing a custom key function.\n\nIf you are not a hippie, you should consider using ``strict=True`` and a\nmuch more limited method will be used to make a key from your\narguments::\n\n    >>> @cache(strict=True)\n    ... def mylength(obj):\n    ...     return len(obj)\n\n    >>> mylength(\"hello\")\n    5\n\nBut then, don't be surprised if it fails with dict, list, or set arguments::\n\n    >>> mylength([set([3]), 2, {1: 2}])\n    Traceback (most recent call last):\n    ...\n    TypeError: unhashable type: 'list'\n\n\nAnd ``typed=True`` can be used in combination with ``strict=True``::\n\n    >>> @cache(strict=True, typed=True)\n    ... def mysum(*args):\n    ...     print(\"calculating...\")\n    ...     return sum(args)\n    >>> mysum(1, 1)\n    calculating...\n    2\n\n    >>> mysum(1.0, 1)\n    calculating...\n    2.0\n\nA good key function can:\n\n- make some cache timeout (but you should then look at cache store\n  section to limit the size of the cache)\n- finely select which argument are pertinent to the method to avoid\n  re-evaluating the function when it is non-necessary.\n- allow you to cache callables that have very special arguments that\n  can't be hashed properly.\n\n\nCleaning Cache\n--------------\n\n``kids.cache`` uses some ``lru_cache`` ideas of python 3\nimplementation, and each function cached received a ``cache_clear``\nmethod::\n\n    >>> @cache\n    ... def mysum(*args):\n    ...     print(\"calculate...\")\n    ...     return sum(args)\n\n    >>> mysum(1,1)\n    calculate...\n    2\n    >>> mysum(1,1)\n    2\n\nBy calling ``cache_clear`` method, we flush all previous cached value::\n\n    >>> mysum.cache_clear()\n    >>> mysum(1,1)\n    calculate...\n    2\n\n\nCache stats\n-----------\n\n``kids.cache`` uses some ``lru_cache`` ideas of python 3\nimplementation, and each function cached received a ``cache_info``\nmethod::\n\n    >>> @cache\n    ... def mysum(*args):\n    ...     print(\"calculate...\")\n    ...     return sum(args)\n\n    >>> mysum(1,1)\n    calculate...\n    2\n    >>> mysum(1,1)\n    2\n\n    >>> mysum.cache_info()\n    CacheInfo(type='dict', hits=1, misses=1, maxsize=None, currsize=1)\n\n\nCache Store\n-----------\n\n``kids.cache`` can use any dict-like structure as a cache store. This\nmeans you can provide some more clever cache stores. For example, you\ncan use ``cachetools`` caches under the hood to manage the caching store.\n\nKeep in mind that the default cache store is... a dict ! which is not\na good idea if your program will run for a long time and you have\ncached function calls that will be different throughout the running\ntime: the cache store will then grow for each new call making the\nmemory usage of your process grow... perhaps out of bounds.\n\nIn these scenario, you must think about using managed cache stores that\nwill clean and remove old unused cache entries. There are many cache\nstore provided in ``cachetools`` and ``kids.cache`` supports them all.\n\nSo if you need any caching store from ``cachetools`` you can provide\nit::\n\n    >>> from cachetools import LRUCache\n\nLRU stands for Least Recent Used... ::\n\n    >>> @cache(use=LRUCache(maxsize=2))\n    ... def mysum(*args):\n    ...     print(\"calculate...\")\n    ...     return sum(args)\n\n    >>> mysum(1, 1)\n    calculate...\n    2\n    >>> mysum(1, 2)\n    calculate...\n    3\n    >>> mysum(1, 3)\n    calculate...\n    4\n\nWe have exceeded the cache memory and the least recent used have been\ntossed away::\n\n    >>> mysum(1, 1)\n    calculate...\n    2\n\nBut we still have this one in memory::\n\n    >>> mysum(1, 3)\n    4\n\n\nContributing\n============\n\nAny suggestion or issue is welcome. Push request are very welcome,\nplease check out the guidelines.\n\n\nPush Request Guidelines\n-----------------------\n\nYou can send any code. I'll look at it and will integrate it myself in\nthe code base and leave you as the author. This process can take time and\nit'll take less time if you follow the following guidelines:\n\n- check your code with PEP8 or pylint. Try to stick to 80 columns wide.\n- separate your commits per smallest concern.\n- each commit should pass the tests (to allow easy bisect)\n- each functionality/bugfix commit should contain the code, tests,\n  and doc.\n- prior minor commit with typographic or code cosmetic changes are\n  very welcome. These should be tagged in their commit summary with\n  ``!minor``.\n- the commit message should follow gitchangelog rules (check the git\n  log to get examples)\n- if the commit fixes an issue or finished the implementation of a\n  feature, please mention it in the summary.\n\nIf you have some questions about guidelines which is not answered here,\nplease check the current ``git log``, you might find previous commit that\nwould show you how to deal with your issue.\n\n\nLicense\n=======\n\nCopyright (c) 2017 Valentin Lab.\n\nLicensed under the `BSD License`_.\n\n.. _BSD License: http://raw.github.com/0k/kids.cache/master/LICENSE\n\nChangelog\n=========\n\n\n0.0.7 (2017-11-16)\n------------------\n\nFix\n~~~\n- ReST inconsistency between generated changelog and ``README.rst``.\n  [Valentin Lab]\n\n  This prevented PyPI page to be rendered properly.\n\n\n0.0.6 (2017-11-16)\n------------------\n\nFix\n~~~\n- Fixed import time performance issue due to obsolete namespacing\n  pattern. (fixes #9) [Valentin Lab]\n\n\n0.0.4 (2015-04-27)\n------------------\n\nNew\n~~~\n- Support being called before or after ``staticmethod`` decorator.\n  [Valentin Lab]\n- Support being called before or after ``classmethod`` decorator.\n  [Valentin Lab]\n\nChanges\n~~~~~~~\n- Documenting the singleton pattern usage when used in conjunction with\n  ``class``. [Valentin Lab]\n\n\n0.0.3 (2015-02-24)\n------------------\n\nFix\n~~~\n- Nasty cache collision if two custom objects shared the same hash and\n  type but where not ``equal``. [Valentin Lab]\n\n  And as a matter of fact, this happens. For instance, all instance of\n  ``object`` or any subclass will inherit a special ``hash`` method that\n  uses ``id``, but in some version of python (the recent ones), the ``id``\n  value is divided by ``16``. And hash collisions are to be expected\n  anyway, and of course should not cause cache collisions.\n\n\n0.0.2 (2015-02-02)\n------------------\n\nNew\n~~~\n- Added type to cache stats, removed dependency to ``cachetools``.\n  [Valentin Lab]\n\nChanges\n~~~~~~~\n- Default cache store's ``currsize`` use the ``len()`` instead of None.\n  [Valentin Lab]\n\n  And this makes sense for the default dict implementation.\n\nFix\n~~~\n- Wrong attribution for ``cache_clear`` and ``cache_info`` functions.\n  [Valentin Lab]\n- Similar ``set`` could get different hash. [Valentin Lab]\n\n  ``set`` weren't sorted prior to introspection for hashing.\n\n\n0.0.1 (2014-05-23)\n------------------\n- First import. [Valentin Lab]\n\n\n\n", "description_content_type": null, "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/0k/kids.cache", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "kids.cache", "package_url": "https://pypi.org/project/kids.cache/", "platform": "", "project_url": "https://pypi.org/project/kids.cache/", "project_urls": {"Homepage": "http://github.com/0k/kids.cache"}, "release_url": "https://pypi.org/project/kids.cache/0.0.7/", "requires_dist": ["cachetools; extra == 'test'", "nose; extra == 'test'"], "requires_python": "", "summary": "Kids caching library.", "version": "0.0.7", "yanked": false, "html_description": "<div class=\"project-description\">\n            <a href=\"https://pypi.python.org/pypi/kids.cache/\" rel=\"nofollow\"><img alt=\"Latest PyPI version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e7b8adeb6ba80af1a54f2ac411c0f58c85cdf304/687474703a2f2f696d672e736869656c64732e696f2f707970692f762f6b6964732e63616368652e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://pypi.python.org/pypi/kids.cache/\" rel=\"nofollow\"><img alt=\"Number of PyPI downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/bd42b8eaaedb719c3f065cc73dc0146e3dcbd720/687474703a2f2f696d672e736869656c64732e696f2f707970692f646d2f6b6964732e63616368652e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://travis-ci.org/0k/kids.cache/\" rel=\"nofollow\"><img alt=\"Travis CI build status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/a599d204b8a452b7f4d95e5b1160d9e8a8eb7b1b/687474703a2f2f696d672e736869656c64732e696f2f7472617669732f306b2f6b6964732e63616368652f6d61737465722e7376673f7374796c653d666c6174\"></a>\n<a href=\"https://coveralls.io/r/0k/kids.cache\" rel=\"nofollow\"><img alt=\"Test coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f648d97752098514aea7c936eb2ae3bf91edcadd/687474703a2f2f696d672e736869656c64732e696f2f636f766572616c6c732f306b2f6b6964732e63616368652f6d61737465722e7376673f7374796c653d666c6174\"></a>\n<p><tt>kids.cache</tt> is a Python library providing a cache decorator.\nIt\u2019s part of \u2018Kids\u2019 (for Keep It Dead Simple) library. It has\nno dependency to any python library.</p>\n<p>Its main concern is to offer a very simple default usage scheme,\nwithout forgetting to offer full power inside when needed.</p>\n<div id=\"maturity\">\n<h2>Maturity</h2>\n<p>This code is around ~100 lines of python, and it has a 100% test\ncoverage.</p>\n<p>However it still considered beta stage currently.</p>\n</div>\n<div id=\"compatibility\">\n<h2>Compatibility</h2>\n<p>It is small and simple and should work anywhere.</p>\n<p>To put it in longer details: the current code is simple enough that it\nuse a common subset of python that is compatible with any platform on\npython 2.7 and python &gt;= 3\u2026 and this without any specific\nmodification.</p>\n<p>Even then, You\u2019ll be happy to know that, this code is tested for\ncompatibility at each commit with python 2.7, 3.4, 3.5, 3.6 on linux\nand windows platform.</p>\n</div>\n<div id=\"features\">\n<h2>Features</h2>\n<ul>\n<li>Use one simple call to <tt>@cache</tt>, and a majority of all hidden complexity\nwill vanish.<ul>\n<li>works out of the box everywhere you can stick a decorator\n(function, methods, property, classes\u2026).</li>\n<li>support to be called before or after common decorators as\n<tt>@property</tt>, <tt>@classmethod</tt>, <tt>@staticmethod</tt>.</li>\n</ul>\n</li>\n<li>With <tt>@cache</tt> several design pattern can be achieved:<ul>\n<li><em>memoization</em> when used on function with arguments.</li>\n<li><em>lazy evaluation</em> when placed on properties.</li>\n<li><em>singleton</em> patterns when placed on classes.</li>\n</ul>\n</li>\n<li>Full customization at disposition:<ul>\n<li>cache clearing or cache stats functionality.</li>\n<li>support of any cache store mecanism from <a href=\"https://github.com/tkem/cachetools\" rel=\"nofollow\">cachetools</a> package.</li>\n<li>support of custom key function which allows:<ul>\n<li>support of your exotic unhashable objects</li>\n<li>fine tune which function calls can be considered identic</li>\n<li>hand pick function dependencies in object (for method)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"basic-usage\">\n<h2>Basic Usage</h2>\n<div id=\"function\">\n<h3>Function</h3>\n<p>This cache decorator is quite straightforward to use:</p>\n<pre>&gt;&gt;&gt; from kids.cache import cache\n\n&gt;&gt;&gt; @cache\n... def answer_to_everything():\n...     print(\"many insightfull calculation\")\n...     return 42\n</pre>\n<p>Then the function <tt>answer_to_everything</tt> would only do the\ncalculation the first time called, and would save the result, and\ndirectly return it the next calls:</p>\n<pre>&gt;&gt;&gt; answer_to_everything()\nmany insightfull calculation\n42\n\n&gt;&gt;&gt; answer_to_everything()\n42\n</pre>\n<p>The body of the function was not executed anymore and the cache value\nwas used.</p>\n<p>It\u2019ll work with arguments:</p>\n<pre>&gt;&gt;&gt; @cache\n... def mysum(*args):\n...     print(\"calculating...\")\n...     return sum(args)\n\n&gt;&gt;&gt; mysum(2, 2, 3)\ncalculating...\n7\n&gt;&gt;&gt; mysum(1, 1, 1, 1)\ncalculating...\n4\n&gt;&gt;&gt; mysum(2, 2, 3)\n7\n&gt;&gt;&gt; mysum(1, 1, 1, 1)\n4\n</pre>\n<p>And notice that by default, object are not typed, thus:</p>\n<pre>&gt;&gt;&gt; mysum(1.0, 1, 1, 1)\n4\n</pre>\n<p>Did trigger the cache, despite the first argument is a float and not\nan integer.</p>\n</div>\n<div id=\"methods\">\n<h3>Methods</h3>\n<p>With methods:</p>\n<pre>&gt;&gt;&gt; class MyObject(object):\n...    def __init__(self, a, b):\n...        self.a, self.b = a, b\n...\n...    @cache\n...    def total(self):\n...        print(\"calculating...\")\n...        return self.a + self.b\n\n&gt;&gt;&gt; xx = MyObject(2, 3)\n&gt;&gt;&gt; xx.total()\ncalculating...\n5\n&gt;&gt;&gt; xx.total()\n5\n</pre>\n<p>Cache is not shared between instances:</p>\n<pre>&gt;&gt;&gt; yy = MyObject(2, 3)\n&gt;&gt;&gt; yy.total()\ncalculating...\n5\n</pre>\n<p>Of course, if you change the inner values of the instance, this\nwill NOT be detected by the caching method:</p>\n<pre>&gt;&gt;&gt; xx.a = 5\n&gt;&gt;&gt; xx.total()\n5\n</pre>\n<p>Look at advanced usages to see how to changes some of these behaviors.</p>\n</div>\n<div id=\"property\">\n<h3>Property</h3>\n<p>You can use the <tt>cache</tt> decorator with properties, and\nprovides a good way to have lazy evaluated attributes:</p>\n<pre>&gt;&gt;&gt; class WithProperty(MyObject):\n...\n...    @property\n...    @cache\n...    def total(self):\n...        print(\"evaluating...\")\n...        return self.a + self.b\n\n&gt;&gt;&gt; xx = WithProperty(1, 1)\n&gt;&gt;&gt; xx.total\nevaluating...\n2\n&gt;&gt;&gt; xx.total\n2\n</pre>\n<p>You can use <tt>@cache</tt> decorator before or after <tt>@property</tt>\ndecorator:</p>\n<pre>&gt;&gt;&gt; class WithProperty(MyObject):\n...\n...    @cache\n...    @property\n...    def total(self):\n...        print(\"evaluating...\")\n...        return self.a + self.b\n\n&gt;&gt;&gt; xx = WithProperty(2, 2)\n&gt;&gt;&gt; xx.total\nevaluating...\n4\n&gt;&gt;&gt; xx.total\n4\n</pre>\n</div>\n<div id=\"classmethod\">\n<h3>classmethod</h3>\n<p>You can use the <tt>cache</tt> decorator with classmethods, and\nprovides a good way to share cache between instances:</p>\n<pre>&gt;&gt;&gt; class WithClassMethod(MyObject):\n...\n...    a = 2\n...    b = 3\n...\n...    @classmethod\n...    @cache\n...    def total(cls):\n...        print(\"evaluating...\")\n...        return cls.a + cls.b\n\n&gt;&gt;&gt; WithClassMethod.total()\nevaluating...\n5\n&gt;&gt;&gt; WithClassMethod.total()\n5\n</pre>\n<p>You can use <tt>@cache</tt> decorator before or after <tt>@property</tt>\ndecorator:</p>\n<pre>&gt;&gt;&gt; class WithClassMethod(MyObject):\n...\n...    a = 1\n...    b = 6\n...\n...    @cache\n...    @classmethod\n...    def total(cls):\n...        print(\"evaluating...\")\n...        return cls.a + cls.b\n\n&gt;&gt;&gt; WithClassMethod.total()\nevaluating...\n7\n&gt;&gt;&gt; WithClassMethod.total()\n7\n</pre>\n</div>\n<div id=\"staticmethod\">\n<h3>staticmethod</h3>\n<p>You can use the <tt>cache</tt> decorator with staticmethods:</p>\n<pre>&gt;&gt;&gt; class WithStaticMethod(MyObject):\n...\n...    @staticmethod\n...    @cache\n...    def total(a, b):\n...        print(\"evaluating...\")\n...        return a + b\n\n&gt;&gt;&gt; WithStaticMethod.total(1, 3)\nevaluating...\n4\n&gt;&gt;&gt; WithStaticMethod.total(1, 3)\n4\n</pre>\n<p>You can use <tt>@cache</tt> decorator before or after <tt>@property</tt>\ndecorator:</p>\n<pre>&gt;&gt;&gt; class WithStaticMethod(MyObject):\n...\n...    @cache\n...    @staticmethod\n...    def total(a, b):\n...        print(\"evaluating...\")\n...        return a + b\n\n&gt;&gt;&gt; WithStaticMethod.total(2, 6)\nevaluating...\n8\n&gt;&gt;&gt; WithStaticMethod.total(2, 6)\n8\n</pre>\n</div>\n<div id=\"class\">\n<h3>class</h3>\n<p>Using <tt>cache</tt> with classes will allow variations around the\nnotion of singletons. A singleton shares the same id in memory,\nso this shows a classical non-singleton behavior:</p>\n<pre>&gt;&gt;&gt; a, b = object(), object()\n&gt;&gt;&gt; id(a) == id(b)\nFalse\n</pre>\n<div id=\"factory-based-singleton\">\n<h4>Factory based singleton</h4>\n<p>You can use the <tt>cache</tt> decorator with classes, effectively\nimplementing a factory pattern for creating singleton:</p>\n<pre>&gt;&gt;&gt; @cache\n... class MySingleton(MyObject):\n...     def __new__(cls):\n...         print(\"instanciating...\")\n...         return MyObject.__new__(cls)\n...     def __init__(self):\n...         print(\"initializing...\")\n\n&gt;&gt;&gt; a, b = MySingleton(), MySingleton()\ninstanciating...\ninitializing...\n&gt;&gt;&gt; id(a) == id(b)\nTrue\n</pre>\n<p>Notice that both instance are the same object, so it was only\ninstanciated and initialized once.</p>\n<p>But be warned: this is not anymore a class:</p>\n<pre>&gt;&gt;&gt; MySingleton\n&lt;function MySingleton at ...&gt;\n</pre>\n</div>\n<div id=\"instanciation-based-singletons\">\n<h4>Instanciation based singletons</h4>\n<p>Slightly different, the class singleton pattern can be achieved by\ncaching <tt>__new__</tt>:</p>\n<pre>&gt;&gt;&gt; class MySingleton(MyObject):\n...     @cache\n...     def __new__(cls):\n...         print(\"instanciating...\")\n...         return MyObject.__new__(cls)\n...     def __init__(self):\n...         print(\"initializing...\")\n\n&gt;&gt;&gt; a, b = MySingleton(), MySingleton()\ninstanciating...\ninitializing...\ninitializing...\n&gt;&gt;&gt; id(a) == id(b)\nTrue\n</pre>\n<p>Notice that both instance are the same object, so it was only\ninstanciated once. But the <tt>__init__</tt> was called both times.\nThis is sometimes perfectly valid, but you might want to avoid this\nalso.</p>\n<p>So if you don\u2019t want this, you should cache also <tt>__init__</tt> method:</p>\n<pre>&gt;&gt;&gt; class MySingleton(MyObject):\n...     @cache\n...     def __new__(cls):\n...         print(\"instanciating...\")\n...         return MyObject.__new__(cls)\n...     @cache\n...     def __init__(self):\n...         print(\"initializing...\")\n\n&gt;&gt;&gt; a, b = MySingleton(), MySingleton()\ninstanciating...\ninitializing...\n&gt;&gt;&gt; id(a) == id(b)\nTrue\n</pre>\n<p>For both cases you\u2019ll keep your full object untouched of course:</p>\n<pre>&gt;&gt;&gt; MySingleton\n&lt;class 'MySingleton'&gt;\n</pre>\n</div>\n<div id=\"singleton-with-arguments\">\n<h4>Singleton with arguments</h4>\n<p>Actually, these are only singletons if you call them successively with\nthe same arguments.</p>\n<p>Or to be more precise, you can share your classes when their\ninstanciation\u2019s arguments are the same:</p>\n<pre>&gt;&gt;&gt; @cache\n... class MySingleton(MyObject):\n...     def __init__(self, a):\n...         self.a = a\n...         print(\"evaluating...\")\n\n&gt;&gt;&gt; a, b = MySingleton(1), MySingleton(2)\nevaluating...\nevaluating...\n&gt;&gt;&gt; id(a) == id(b)\nFalse\n</pre>\n<p>But:</p>\n<pre>&gt;&gt;&gt; c = MySingleton(1)\n&gt;&gt;&gt; id(a) == id(c)\nTrue\n</pre>\n<p>If you want a singleton that give you the same instance even if your\nsuccessive calls differs, you should check the advanced usage section\nand the <tt>key</tt> argument.</p>\n</div>\n</div>\n</div>\n<div id=\"advanced-usage\">\n<h2>Advanced Usage</h2>\n<p>Most of the advanced usage implies to call the <tt>@cache</tt> decorator with\narguments. Please notice that:</p>\n<pre>&gt;&gt;&gt; @cache\n... def mysum1(*args):\n...     print(\"calculating...\")\n...     return sum(args)\n</pre>\n<p>Or:</p>\n<pre>&gt;&gt;&gt; @cache()\n... def mysum2(*args):\n...     print(\"calculating...\")\n...     return sum(args)\n</pre>\n<p>is equivalent:</p>\n<pre>&gt;&gt;&gt; mysum1(1,1)\ncalculating...\n2\n&gt;&gt;&gt; mysum1(1,1)\n2\n\n&gt;&gt;&gt; mysum2(1,1)\ncalculating...\n2\n&gt;&gt;&gt; mysum2(1,1)\n2\n</pre>\n<div id=\"provide-a-key-function\">\n<h3>Provide a key function</h3>\n<p>Providing a key function can be extremely powerfull and will allow to\nfine tune when the cache should be recalculated.</p>\n<p><tt>hashing</tt> functions will receive exactly the same arguments than the\nmain function called. It must return an hashable structure\n(combination of <tt>tuples</tt>, <tt>int</tt>, <tt>string</tt>\u2026 avoid list, dicts and\nsets). This will identify uniquely the result.</p>\n<p>For example you could:</p>\n<pre>&gt;&gt;&gt; class WithKey(MyObject):\n...    @cache(key=lambda s: (id(s), s.a, s.b))\n...    def total(self):\n...        print(\"calculating...\")\n...        return self.a + self.b\n\n&gt;&gt;&gt; xx = WithKey(2, 3)\n&gt;&gt;&gt; xx.total()\ncalculating...\n5\n&gt;&gt;&gt; xx.total()\n5\n</pre>\n<p>It should detect changes of the given values of the instance:</p>\n<pre>&gt;&gt;&gt; xx.a = 5\n&gt;&gt;&gt; xx.total()\ncalculating...\n8\n</pre>\n<p>Without bothering to recalculate when other values change:</p>\n<pre>&gt;&gt;&gt; xx.c = 7\n&gt;&gt;&gt; xx.total()\n8\n</pre>\n<p>But it should still make a difference between instances:</p>\n<pre>&gt;&gt;&gt; yy = WithKey(2, 3)\n&gt;&gt;&gt; yy.total()\ncalculating...\n5\n</pre>\n<p>This last example is important as you could have wanted to share the\ncache between all instances. You could have done this easily by\navoiding returning <tt>id(s)</tt> in the <tt>key</tt> function.</p>\n</div>\n<div id=\"typed-key-functions\">\n<h3>Typed key functions</h3>\n<p>You could ask for <tt>typed</tt> argument to NOT be treated the same:</p>\n<pre>&gt;&gt;&gt; @cache(typed=True)\n... def mysum(*args):\n...     print(\"calculating...\")\n...     return sum(args)\n&gt;&gt;&gt; mysum(1, 1)\ncalculating...\n2\n\n&gt;&gt;&gt; mysum(1.0, 1)\ncalculating...\n2.0\n</pre>\n</div>\n<div id=\"default-key-functions\">\n<h3>default key functions</h3>\n<p>The default key function if not provided is a bold try to make <tt>list</tt>\nand <tt>dict</tt>, <tt>set</tt> also keyable despite these not being hashable.</p>\n<p>The name of the key function is called <tt>hippie_hashing</tt>, and this is\nthe default value for the key argument:</p>\n<pre>&gt;&gt;&gt; from kids.cache import hippie_hashing\n\n&gt;&gt;&gt; @cache(key=hippie_hashing)\n... def mylength(obj):\n...     return len(obj)\n</pre>\n<p>This allows you to use the function with list, dict or combination of these:</p>\n<pre>&gt;&gt;&gt; mylength([set([3]), 2, {1: 2}])\n3\n</pre>\n<p>Even your objects could be used as key, as long as they are hashable:</p>\n<pre>&gt;&gt;&gt; class MyObj(object):  ## object subclasses have a default hash\n...     length = 5\n...     def __len__(self, ):\n...         print('calculating...')\n...         return self.length\n\n&gt;&gt;&gt; myobj = MyObj()\n&gt;&gt;&gt; mylength(myobj)\ncalculating...\n5\n\n&gt;&gt;&gt; mylength(myobj)\n5\n</pre>\n<p>Be assured that hash collision (they happen!) won\u2019t generate cache collisions:</p>\n<pre>&gt;&gt;&gt; class MyCollidingHashObj(MyObj):\n...     def __init__(self, length):\n...          self.length = length\n...     def __hash__(self):\n...          return 1\n\n&gt;&gt;&gt; hash_collide1 = MyCollidingHashObj(6)\n&gt;&gt;&gt; hash_collide2 = MyCollidingHashObj(7)\n\n&gt;&gt;&gt; mylength(hash_collide1)\ncalculating...\n6\n&gt;&gt;&gt; mylength(hash_collide2)\ncalculating...\n7\n</pre>\n<p>But try to avoid them for performance\u2019s sake !! And you should\nprobably be aware that if your object compare equal, then THERE WILL\nBE a cache collision (but at this point, this is probably what you\nwanted, heh ?):</p>\n<pre>&gt;&gt;&gt; class MyEqCollidingHashObj(MyCollidingHashObj):\n...     def __eq__(self, value):\n...          return True\n...     def __hash__(self):\n...          return 1\n\n&gt;&gt;&gt; eq_and_hash_collide1 = MyEqCollidingHashObj(8)\n&gt;&gt;&gt; eq_and_hash_collide2 = MyEqCollidingHashObj(9)\n\n&gt;&gt;&gt; mylength(eq_and_hash_collide1)\ncalculating...\n8\n&gt;&gt;&gt; mylength(eq_and_hash_collide2)\n8\n</pre>\n<p>Huh oh. This is not what was probably expected in this example, but\nyou really had to work hard to make this happen. And most of the time,\nyou\u2019ll probably find this convenient and will use it at you advantage.\nIt\u2019s a little bit like an extension of the <tt>key</tt> mecanism that is\nthe objects responsability.</p>\n<div>\n<p>Note</p>\n<p>Please verify also that if your object compares the same, their\nhash HAS TO BE the same. For this very reason, in Python3, when you\ndefine the <tt>__eq__</tt> method, it\u2019ll remove the default <tt>__hash__</tt>\nfrom objects.</p>\n</div>\n<p>Of course, <tt>hippie_hashing</tt> will fail on special unhashable object:</p>\n<pre>&gt;&gt;&gt; class Unhashable(object):\n...    def __hash__(self):\n...        raise ValueError(\"unhashable!\")\n\n&gt;&gt;&gt; hippie_hashing(Unhashable())  ## doctest: +ELLIPSIS\nTraceback (most recent call last):\n...\nValueError: &lt;Unhashable ...&gt; can not be hashed. Try providing a custom key function.\n</pre>\n<p>If you are not a hippie, you should consider using <tt>strict=True</tt> and a\nmuch more limited method will be used to make a key from your\narguments:</p>\n<pre>&gt;&gt;&gt; @cache(strict=True)\n... def mylength(obj):\n...     return len(obj)\n\n&gt;&gt;&gt; mylength(\"hello\")\n5\n</pre>\n<p>But then, don\u2019t be surprised if it fails with dict, list, or set arguments:</p>\n<pre>&gt;&gt;&gt; mylength([set([3]), 2, {1: 2}])\nTraceback (most recent call last):\n...\nTypeError: unhashable type: 'list'\n</pre>\n<p>And <tt>typed=True</tt> can be used in combination with <tt>strict=True</tt>:</p>\n<pre>&gt;&gt;&gt; @cache(strict=True, typed=True)\n... def mysum(*args):\n...     print(\"calculating...\")\n...     return sum(args)\n&gt;&gt;&gt; mysum(1, 1)\ncalculating...\n2\n\n&gt;&gt;&gt; mysum(1.0, 1)\ncalculating...\n2.0\n</pre>\n<p>A good key function can:</p>\n<ul>\n<li>make some cache timeout (but you should then look at cache store\nsection to limit the size of the cache)</li>\n<li>finely select which argument are pertinent to the method to avoid\nre-evaluating the function when it is non-necessary.</li>\n<li>allow you to cache callables that have very special arguments that\ncan\u2019t be hashed properly.</li>\n</ul>\n</div>\n<div id=\"cleaning-cache\">\n<h3>Cleaning Cache</h3>\n<p><tt>kids.cache</tt> uses some <tt>lru_cache</tt> ideas of python 3\nimplementation, and each function cached received a <tt>cache_clear</tt>\nmethod:</p>\n<pre>&gt;&gt;&gt; @cache\n... def mysum(*args):\n...     print(\"calculate...\")\n...     return sum(args)\n\n&gt;&gt;&gt; mysum(1,1)\ncalculate...\n2\n&gt;&gt;&gt; mysum(1,1)\n2\n</pre>\n<p>By calling <tt>cache_clear</tt> method, we flush all previous cached value:</p>\n<pre>&gt;&gt;&gt; mysum.cache_clear()\n&gt;&gt;&gt; mysum(1,1)\ncalculate...\n2\n</pre>\n</div>\n<div id=\"cache-stats\">\n<h3>Cache stats</h3>\n<p><tt>kids.cache</tt> uses some <tt>lru_cache</tt> ideas of python 3\nimplementation, and each function cached received a <tt>cache_info</tt>\nmethod:</p>\n<pre>&gt;&gt;&gt; @cache\n... def mysum(*args):\n...     print(\"calculate...\")\n...     return sum(args)\n\n&gt;&gt;&gt; mysum(1,1)\ncalculate...\n2\n&gt;&gt;&gt; mysum(1,1)\n2\n\n&gt;&gt;&gt; mysum.cache_info()\nCacheInfo(type='dict', hits=1, misses=1, maxsize=None, currsize=1)\n</pre>\n</div>\n<div id=\"cache-store\">\n<h3>Cache Store</h3>\n<p><tt>kids.cache</tt> can use any dict-like structure as a cache store. This\nmeans you can provide some more clever cache stores. For example, you\ncan use <tt>cachetools</tt> caches under the hood to manage the caching store.</p>\n<p>Keep in mind that the default cache store is\u2026 a dict ! which is not\na good idea if your program will run for a long time and you have\ncached function calls that will be different throughout the running\ntime: the cache store will then grow for each new call making the\nmemory usage of your process grow\u2026 perhaps out of bounds.</p>\n<p>In these scenario, you must think about using managed cache stores that\nwill clean and remove old unused cache entries. There are many cache\nstore provided in <tt>cachetools</tt> and <tt>kids.cache</tt> supports them all.</p>\n<p>So if you need any caching store from <tt>cachetools</tt> you can provide\nit:</p>\n<pre>&gt;&gt;&gt; from cachetools import LRUCache\n</pre>\n<p>LRU stands for Least Recent Used\u2026</p>\n<pre>&gt;&gt;&gt; @cache(use=LRUCache(maxsize=2))\n... def mysum(*args):\n...     print(\"calculate...\")\n...     return sum(args)\n\n&gt;&gt;&gt; mysum(1, 1)\ncalculate...\n2\n&gt;&gt;&gt; mysum(1, 2)\ncalculate...\n3\n&gt;&gt;&gt; mysum(1, 3)\ncalculate...\n4\n</pre>\n<p>We have exceeded the cache memory and the least recent used have been\ntossed away:</p>\n<pre>&gt;&gt;&gt; mysum(1, 1)\ncalculate...\n2\n</pre>\n<p>But we still have this one in memory:</p>\n<pre>&gt;&gt;&gt; mysum(1, 3)\n4\n</pre>\n</div>\n</div>\n<div id=\"contributing\">\n<h2>Contributing</h2>\n<p>Any suggestion or issue is welcome. Push request are very welcome,\nplease check out the guidelines.</p>\n<div id=\"push-request-guidelines\">\n<h3>Push Request Guidelines</h3>\n<p>You can send any code. I\u2019ll look at it and will integrate it myself in\nthe code base and leave you as the author. This process can take time and\nit\u2019ll take less time if you follow the following guidelines:</p>\n<ul>\n<li>check your code with PEP8 or pylint. Try to stick to 80 columns wide.</li>\n<li>separate your commits per smallest concern.</li>\n<li>each commit should pass the tests (to allow easy bisect)</li>\n<li>each functionality/bugfix commit should contain the code, tests,\nand doc.</li>\n<li>prior minor commit with typographic or code cosmetic changes are\nvery welcome. These should be tagged in their commit summary with\n<tt>!minor</tt>.</li>\n<li>the commit message should follow gitchangelog rules (check the git\nlog to get examples)</li>\n<li>if the commit fixes an issue or finished the implementation of a\nfeature, please mention it in the summary.</li>\n</ul>\n<p>If you have some questions about guidelines which is not answered here,\nplease check the current <tt>git log</tt>, you might find previous commit that\nwould show you how to deal with your issue.</p>\n</div>\n</div>\n<div id=\"license\">\n<h2>License</h2>\n<p>Copyright (c) 2017 Valentin Lab.</p>\n<p>Licensed under the <a href=\"http://raw.github.com/0k/kids.cache/master/LICENSE\" rel=\"nofollow\">BSD License</a>.</p>\n</div>\n<div id=\"changelog\">\n<h2>Changelog</h2>\n<div id=\"id1\">\n<h3>0.0.7 (2017-11-16)</h3>\n<h3 id=\"fix\"><span class=\"section-subtitle\">Fix</span></h3>\n<ul>\n<li><p>ReST inconsistency between generated changelog and <tt>README.rst</tt>.\n[Valentin Lab]</p>\n<p>This prevented PyPI page to be rendered properly.</p>\n</li>\n</ul>\n</div>\n<div id=\"id2\">\n<h3>0.0.6 (2017-11-16)</h3>\n<h3 id=\"id3\"><span class=\"section-subtitle\">Fix</span></h3>\n<ul>\n<li>Fixed import time performance issue due to obsolete namespacing\npattern. (fixes #9) [Valentin Lab]</li>\n</ul>\n</div>\n<div id=\"id4\">\n<h3>0.0.4 (2015-04-27)</h3>\n<div id=\"new\">\n<h4>New</h4>\n<ul>\n<li>Support being called before or after <tt>staticmethod</tt> decorator.\n[Valentin Lab]</li>\n<li>Support being called before or after <tt>classmethod</tt> decorator.\n[Valentin Lab]</li>\n</ul>\n</div>\n<div id=\"changes\">\n<h4>Changes</h4>\n<ul>\n<li>Documenting the singleton pattern usage when used in conjunction with\n<tt>class</tt>. [Valentin Lab]</li>\n</ul>\n</div>\n</div>\n<div id=\"id5\">\n<h3>0.0.3 (2015-02-24)</h3>\n<h3 id=\"id6\"><span class=\"section-subtitle\">Fix</span></h3>\n<ul>\n<li><p>Nasty cache collision if two custom objects shared the same hash and\ntype but where not <tt>equal</tt>. [Valentin Lab]</p>\n<p>And as a matter of fact, this happens. For instance, all instance of\n<tt>object</tt> or any subclass will inherit a special <tt>hash</tt> method that\nuses <tt>id</tt>, but in some version of python (the recent ones), the <tt>id</tt>\nvalue is divided by <tt>16</tt>. And hash collisions are to be expected\nanyway, and of course should not cause cache collisions.</p>\n</li>\n</ul>\n</div>\n<div id=\"id7\">\n<h3>0.0.2 (2015-02-02)</h3>\n<div id=\"id8\">\n<h4>New</h4>\n<ul>\n<li>Added type to cache stats, removed dependency to <tt>cachetools</tt>.\n[Valentin Lab]</li>\n</ul>\n</div>\n<div id=\"id9\">\n<h4>Changes</h4>\n<ul>\n<li><p>Default cache store\u2019s <tt>currsize</tt> use the <tt>len()</tt> instead of None.\n[Valentin Lab]</p>\n<p>And this makes sense for the default dict implementation.</p>\n</li>\n</ul>\n</div>\n<div id=\"id10\">\n<h4>Fix</h4>\n<ul>\n<li><p>Wrong attribution for <tt>cache_clear</tt> and <tt>cache_info</tt> functions.\n[Valentin Lab]</p>\n</li>\n<li><p>Similar <tt>set</tt> could get different hash. [Valentin Lab]</p>\n<p><tt>set</tt> weren\u2019t sorted prior to introspection for hashing.</p>\n</li>\n</ul>\n</div>\n</div>\n<div id=\"id11\">\n<h3>0.0.1 (2014-05-23)</h3>\n<ul>\n<li>First import. [Valentin Lab]</li>\n</ul>\n</div>\n</div>\n\n          </div>"}, "last_serial": 3338720, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "1b591f86be15eaf2bf2fcd1039f78909", "sha256": "37b17d029ec9a78c90e35b917db41c86f0b38a86c9f0ee413d7dd82ba77b50c8"}, "downloads": -1, "filename": "kids.cache-0.0.1.tar.gz", "has_sig": false, "md5_digest": "1b591f86be15eaf2bf2fcd1039f78909", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9624, "upload_time": "2015-01-19T16:02:22", "upload_time_iso_8601": "2015-01-19T16:02:22.690650Z", "url": "https://files.pythonhosted.org/packages/0e/95/5717ae3313e459c6e28aa8ca9a890b39d29fdcfafc7a595c8e06c6a4f5bd/kids.cache-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "1dae57aea1bffc08de7c41af4b9cddd6", "sha256": "ac64954e27aa3aaafb251373e404025e1df18732ee35b004e6f3a432a6f542ae"}, "downloads": -1, "filename": "kids.cache-0.0.2.tar.gz", "has_sig": false, "md5_digest": "1dae57aea1bffc08de7c41af4b9cddd6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12237, "upload_time": "2015-02-02T02:35:51", "upload_time_iso_8601": "2015-02-02T02:35:51.940308Z", "url": "https://files.pythonhosted.org/packages/90/3b/3f5286170e8ddb908f225ba3e9bbd93e98adacae0d97ac79309a8b835c95/kids.cache-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "cb18864258d732c9f1261c351822a1d0", "sha256": "b50622ca7923d313d410dda44ec41bb07d65cff6c94ea21e5d3c892616b288e4"}, "downloads": -1, "filename": "kids.cache-0.0.3.tar.gz", "has_sig": false, "md5_digest": "cb18864258d732c9f1261c351822a1d0", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 12657, "upload_time": "2015-02-24T12:39:29", "upload_time_iso_8601": "2015-02-24T12:39:29.699193Z", "url": "https://files.pythonhosted.org/packages/d9/e4/05f3c88d8279105627943316bcac7a1e105481b7995caa450bf09dd79fbb/kids.cache-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "55bd14986f1ed774bbad2d1e9dfb2bbf", "sha256": "31178b7f4d29f42c8df2f3d721864f11f34d556255e73e6bbec160e4114065fa"}, "downloads": -1, "filename": "kids.cache-0.0.4.tar.gz", "has_sig": false, "md5_digest": "55bd14986f1ed774bbad2d1e9dfb2bbf", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 16946, "upload_time": "2015-04-27T04:42:31", "upload_time_iso_8601": "2015-04-27T04:42:31.273086Z", "url": "https://files.pythonhosted.org/packages/38/bd/8f1a488775a29cdc3be7a03c9d0a073601f0fb5a12be99598d6235ad3005/kids.cache-0.0.4.tar.gz", "yanked": false}], "0.0.6": [{"comment_text": "", "digests": {"md5": "b17e0cd513d0d91a9645bb15a04880f7", "sha256": "71897b8e9d4c2d41ffc2e25a6c75e76b9d2e50bd00e3c469e69bb114b3e278c3"}, "downloads": -1, "filename": "kids.cache-0.0.6-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b17e0cd513d0d91a9645bb15a04880f7", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 17918, "upload_time": "2017-11-16T10:10:22", "upload_time_iso_8601": "2017-11-16T10:10:22.546540Z", "url": "https://files.pythonhosted.org/packages/a5/53/d9576aaa99d77864208b0966bbe885cbc5f3b13c618c4dbffb0046fa0030/kids.cache-0.0.6-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "d7d526e6679ee584477b7036571910b6", "sha256": "1681ab0f3d2abfdec7834708773340e169529ddc380c3960f6ea24d2caf04783"}, "downloads": -1, "filename": "kids.cache-0.0.6.tar.gz", "has_sig": false, "md5_digest": "d7d526e6679ee584477b7036571910b6", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20023, "upload_time": "2017-11-16T10:10:24", "upload_time_iso_8601": "2017-11-16T10:10:24.617156Z", "url": "https://files.pythonhosted.org/packages/be/4e/f82122261dfaeaf508f3a06a51e5388fd78aa57b04855e9f457b22705b2b/kids.cache-0.0.6.tar.gz", "yanked": false}], "0.0.7": [{"comment_text": "", "digests": {"md5": "124d31ea2402ba1b33e733b22e4120d8", "sha256": "685b30a8aea1d225d0490f73a54955213b36d794e8d332a93c1db3e46e1ef11d"}, "downloads": -1, "filename": "kids.cache-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "124d31ea2402ba1b33e733b22e4120d8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 18039, "upload_time": "2017-11-16T14:40:31", "upload_time_iso_8601": "2017-11-16T14:40:31.544537Z", "url": "https://files.pythonhosted.org/packages/86/d2/22a34ea6a4181a764ebad7097e5b25264436eeead4030b243b5ccfd95cfe/kids.cache-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8c79b089133e2ddb95ee78c4b0a5028", "sha256": "6630bead0d43ef700a8eb4729fdc09e8fbfeba7211a2563f4bd67e5659f97853"}, "downloads": -1, "filename": "kids.cache-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e8c79b089133e2ddb95ee78c4b0a5028", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20105, "upload_time": "2017-11-16T14:40:35", "upload_time_iso_8601": "2017-11-16T14:40:35.123852Z", "url": "https://files.pythonhosted.org/packages/36/fe/12a3ac5da6f3b5b70da5e59db908b24d0fa1797954a3210bb7146020153c/kids.cache-0.0.7.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "124d31ea2402ba1b33e733b22e4120d8", "sha256": "685b30a8aea1d225d0490f73a54955213b36d794e8d332a93c1db3e46e1ef11d"}, "downloads": -1, "filename": "kids.cache-0.0.7-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "124d31ea2402ba1b33e733b22e4120d8", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": null, "size": 18039, "upload_time": "2017-11-16T14:40:31", "upload_time_iso_8601": "2017-11-16T14:40:31.544537Z", "url": "https://files.pythonhosted.org/packages/86/d2/22a34ea6a4181a764ebad7097e5b25264436eeead4030b243b5ccfd95cfe/kids.cache-0.0.7-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e8c79b089133e2ddb95ee78c4b0a5028", "sha256": "6630bead0d43ef700a8eb4729fdc09e8fbfeba7211a2563f4bd67e5659f97853"}, "downloads": -1, "filename": "kids.cache-0.0.7.tar.gz", "has_sig": false, "md5_digest": "e8c79b089133e2ddb95ee78c4b0a5028", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 20105, "upload_time": "2017-11-16T14:40:35", "upload_time_iso_8601": "2017-11-16T14:40:35.123852Z", "url": "https://files.pythonhosted.org/packages/36/fe/12a3ac5da6f3b5b70da5e59db908b24d0fa1797954a3210bb7146020153c/kids.cache-0.0.7.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:49:47 2020"}