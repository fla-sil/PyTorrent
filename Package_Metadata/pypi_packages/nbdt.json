{"info": {"author": "Alvin Wan", "author_email": "hi@alvinwan.com", "bugtrack_url": null, "classifiers": ["Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Neural-Backed Decision Trees\n\n[Project Page](http://nbdt.alvinwan.com) &nbsp;//&nbsp; [Paper](http://nbdt.alvinwan.com/paper/) &nbsp;//&nbsp; [No-code Web Demo](http://nbdt.alvinwan.com/demo/) &nbsp;//&nbsp; [Colab Notebook](https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb)\n\n*By Alvin Wan, \\*Lisa Dunlap, \\*Daniel Ho, Jihan Yin, Scott Lee, Henry Jin, Suzanne Petryk, Sarah Adel Bargal, Joseph E. Gonzalez*\n<sub>*denotes equal contribution</sub>\n\nRun decision trees that achieve state-of-the-art accuracy for explainable models on CIFAR10, CIFAR100, TinyImagenet200, and ImageNet. NBDTs achieve accuracies within 1% of the original neural network on CIFAR10, CIFAR100, and TinyImagenet200 with the recently state-of-the-art WideResNet; and within 2% of the original neural network on ImageNet, using recently state-of-the-art EfficientNet. We attain an ImageNet top-1 accuracy of 75.13%.\n\n**Table of Contents**\n\n- [Quickstart: Running and loading NBDTs](#quickstart)\n- [Convert your own neural network into a decision tree](#convert-neural-networks-to-decision-trees)\n- [Training and evaluation](#training-and-evaluation)\n- [Results](#results)\n- [Setup for Development](#setup-for-development)\n- [Citation](#citation)\n\n![pipeline](https://user-images.githubusercontent.com/2068077/76384774-1ffb8480-631d-11ea-973f-7cac2a60bb10.jpg)\n\nPer the pipeline illustration above, we (1) [generate the hierarchy](https://github.com/alvinwan/neural-backed-decision-trees#1-Hierarchies) and (2) train the neural network [with a tree supervision loss](https://github.com/alvinwan/neural-backed-decision-trees#2-Tree-Supervision-Loss). Then, we (3) [run inference](https://github.com/alvinwan/neural-backed-decision-trees#3-Inference) by featurizing images using the network backbone and running embedded decision rules.\n\n# Quickstart\n\n## Running Pretrained NBDT on Examples\n\n<i>Don't want to download? Try your own images on the [web demo](http://nbdt.alvinwan.com/demo/).</i>\n\nPip install the `nbdt` utility and run it on an image of your choosing. This can be a local image path or an image URL. Below, we evaluate on an image of a cat, from the web. This cat is pictured below.\n\n```bash\npip install nbdt\nnbdt https://images.pexels.com/photos/126407/pexels-photo-126407.jpeg?auto=compress&cs=tinysrgb&dpr=2&w=32\n```\n\nThis outputs both the class prediction and all the intermediate decisions, like below:\n\n```\nPrediction: cat // Decisions: animal (99.47%), chordate (99.20%), carnivore (99.42%), cat (99.86%)\n```\n\nBy default, this evaluation utility uses WideResNet pretrained on CIFAR10. You can also pass classes not seen in CIFAR10. Below, we pass a picture of a bear and a zebra. This zebra is also pictured below.\n\n```bash\nnbdt https://images.pexels.com/photos/750539/pexels-photo-750539.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=32\nnbdt https://images.pexels.com/photos/158109/kodiak-brown-bear-adult-portrait-wildlife-158109.jpeg?auto=compress&cs=tinysrgb&dpr=2&w=32\n```\n\nLike before, this outputs the class prediction and intermediate decisions. Although the *Bear* and *Zebra* classes were not seen at train time, the model still correctly picks *Animal* over *Vehicle* for both. Note that for *Zebra*, the obvious closest class is *Horse*, matching the model's prediction below.\n\n```\nPrediction: horse // Decisions: animal (99.31%), ungulate (99.25%), horse (99.62%)\nPrediction: dog // Decisions: animal (99.51%), chordate (99.35%), carnivore (99.69%), dog (99.22%)\n```\n\n<img src=\"https://images.pexels.com/photos/126407/pexels-photo-126407.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=125\" height=125 align=left>\n<img src=\"https://images.pexels.com/photos/158109/kodiak-brown-bear-adult-portrait-wildlife-158109.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=125\" height=125 align=left>\n<img src=\"https://images.pexels.com/photos/1490908/pexels-photo-1490908.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=125\" height=125 align=left>\n<img src=\"https://images.pexels.com/photos/750539/pexels-photo-750539.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=125\" height=125>\n\n<sub>*Pictures are taken from [pexels.com](http://pexels.com), which are free to use per the [Pexels license](https://www.pexels.com/photo-license/).*</sub>\n\n## Loading Pretrained NBDTs in Code\n\n<i>Don't want to download? Try inference on a pre-filled [Google Colab Notebook](https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb).</i>\n\nIf you haven't already, pip install the `nbdt` utility.\n\n```bash\npip install nbdt\n```\n\nThen, pick an NBDT inference mode (hard or soft), dataset, and backbone. By default, we support ResNet18 and WideResNet28x10 for CIFAR10, CIFAR100, and TinyImagenet200. See [nbdt-pytorch-image-models](https://github.com/alvinwan/nbdt-pytorch-image-models) for EfficientNet-EdgeTPUSmall on ImageNet.\n\n<sub>[Try below script on Google Colab](https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb)</sub>\n\n```python\nfrom nbdt.model import SoftNBDT\nfrom nbdt.models import ResNet18, wrn28_10_cifar10, wrn28_10_cifar100, wrn28_10  # use wrn28_10 for TinyImagenet200\n\nmodel = wrn28_10_cifar10()\nmodel = SoftNBDT(\n  pretrained=True,\n  dataset='CIFAR10',\n  arch='wrn28_10_cifar10',\n  model=model)\n```\n\nNote `torchvision.models.resnet18` only supports 224x224 input. However, `nbdt.models.resnet.ResNet18` supports variable size inputs. See [Models](#models) for instructions on using your favorite image classification neural network.\n\n**Example in ~30 lines**: See [`nbdt/bin/nbdt`](https://github.com/alvinwan/neural-backed-decision-trees/blob/master/nbdt/bin/nbdt), which loads the pretrained model, loads an image, and runs inference on the image in ~30 lines. This file is the executable `nbdt` in the previous section. Try this in a [Google Colab Notebook](https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb).\n\n# Convert Neural Networks to Decision Trees\n\n<!--<i>Don't want to download? Try on MNIST in a pre-filled [Google Colab Notebook]().</i>-->\n\n**To convert your neural network** into a neural-backed decision tree, perform the following 3 steps:\n\n1. **First**, if you haven't already, pip install the `nbdt` utility: `pip install nbdt`\n2. **Second, during training**, wrap your loss `criterion` with a custom NBDT loss. Below, we demonstrate the soft tree supervision loss on the CIFAR10 dataset. By default, we support `CIFAR10`, `CIFAR100`, `TinyImagenet200`, and `Imagenet1000`.\n\n  ```python\n  from nbdt.loss import SoftTreeSupLoss\n  criterion = SoftTreeSupLoss(dataset='CIFAR10', criterion=criterion)  # `criterion` is your original loss function e.g., nn.CrossEntropyLoss\n  ```\n\n3. **Third, during inference or validation**, wrap your `model` with a custom NBDT wrapper as shown below. This is only to run prediction as an NBDT during validation or inference time. Do not wrap your model like below, during training.\n\n  ```python\n  from nbdt.model import SoftNBDT\n  model = SoftNBDT(dataset='CIFAR10', model=model)  # `model` is your original model\n  ```\n\n**Example integration with repository**: See [`nbdt-pytorch-image-models`](https://github.com/alvinwan/nbdt-pytorch-image-models), which applies this 3-step integration to a popular image classification repository `pytorch-image-models`.\n\n<!--**Example notebook with MNIST training**: Try the [Google Colab Notebook]() with example training for MNIST, applying this 3-step integration to a simple pipeline.-->\n\n<details><summary><b>Example integration with a random neural network in 16 lines</b> <i>[click to expand]</i></summary>\n<div>\n\nYou can also include arbitrary image classification neural networks not explicitly supported in this repository. For example, after installing [`pretrained-models.pytorch`](https://github.com/Cadene/pretrained-models.pytorch#quick-examples) using pip, you can instantiate and pass any pretrained model into our NBDT utility functions.\n\n```python\nfrom nbdt.model import SoftNBDT\nfrom nbdt.loss import SoftTreeSupLoss\nfrom nbdt.hierarchy import generate_hierarchy\nimport pretrainedmodels\n\nmodel = pretrainedmodels.__dict__['fbresnet152'](num_classes=1000, pretrained='imagenet')\n\n# 1. generate hierarchy from pretrained model\ngenerate_hierarchy(dataset='Imagenet1000', arch='fbresnet152', model=model)\n\n# 2. Fine-tune model with tree supervision loss\ncriterion = ...\ncriterion = SoftTreeSupLoss(dataset='Imagenet1000', hierarchy='induced-fbresnet152', criterion=criterion)\n\n# 3. Run inference using embedded decision rules\nmodel = SoftNBDT(model=model, dataset='Imagenet1000', hierarchy='induced-fbresnet152')\n```\n\nFor more information on generating different hierarchies, see [Induced Hierarchy](#induced-hierarchy).\n\n</div>\n</details>\n\n<details><summary><b>Want to build and use your own induced hierarchy?</b> <i>[click to expand]</i></summary>\n<div>\n\nUse the `nbdt-hierarchy` utility to generate a new induced hierarchy from a pretrained model.\n\n```bash\nnbdt-hierarchy --arch=efficientnet_b0 --dataset=Imagenet1000\n```\n\nThen, pass the hierarchy name to the loss and models. You may alternatively pass the fully-qualified `path_graph` path.\n\n```python\nfrom nbdt.loss import SoftTreeSupLoss\nfrom nbdt.model import SoftNBDT\n\ncriterion = SoftTreeSupLoss(dataset='Imagenet1000', criterion=criterion, hierarchy='induced-efficientnet_b0')\nmodel = SoftNBDT(dataset='Imagenet1000', model=model, hierarchy='induced-efficientnet_b0')\n```\n\nFor more information on generating different hierarchies, see [Induced Hierarchy](#induced-hierarchy).\n\n</div>\n</details>\n\n# Training and Evaluation\n\n**To reproduce experimental results**, start by cloning the repository and installing all requirements.\n\n```bash\ngit clone git@github.com:alvinwan/neural-backed-decision-trees.git  # or http addr if you don't have private-public github key setup\ncd neural-backed-decision-trees\npython setup.py develop\n```\n\nTo reproduce the core experimental results in our paper -- ignoring ablation studies -- simply run the following bash script:\n\n```bash\nbash scripts/gen_train_eval_wideresnet.sh\n```\n\nWant more transparent step-by-step instructions? The bash scripts above are explained in more detail in the following sections: [Induced Hierarchy](https://github.com/alvinwan/neural-backed-decision-trees#Induced-Hierarchy), [Soft Tree Supervision Loss](https://github.com/alvinwan/neural-backed-decision-trees#Tree-Supervision-Loss), and [Soft Inference](https://github.com/alvinwan/neural-backed-decision-trees#Soft-Inference). These scripts reproduce our CIFAR10, CIFAR100, and TinyImagenet200 results. To reproduce our ImageNet results, see [`nbdt-pytorch-image-models`](https://github.com/alvinwan/nbdt-pytorch-image-models).\n\nFor all scripts, you can use any [`torchvision`](https://pytorch.org/docs/stable/torchvision/models.html) model or any [`pytorchcv`](https://github.com/osmr/imgclsmob/tree/master/pytorch) model, as we directly support both model zoos. Customization for each step is explained below.\n\n## 1. Hierarchies\n\n### Induced Hierarchy\n\nRun the following to generate and test induced hierarchies for CIFAR10 based off of the WideResNet model.\n\n```bash\nnbdt-hierarchy --arch=wrn28_10_cifar10 --dataset=CIFAR10\n```\n\n<details><summary><b>See how it works and how to configure.</b> <i>[click to expand]</i></summary>\n<div>\n\n![induced_structure](https://user-images.githubusercontent.com/2068077/76388304-0e6aaa80-6326-11ea-8c9b-6d08cb89fafe.jpg)\n\nThe script loads the pretrained model (Step A), populates the leaves of the tree with fully-connected layer weights (Step B) and performs hierarchical agglomerative clustering (Step C). Note that the above command can be rerun with different architectures, different datasets, or random neural network checkpoints to produce different hierarchies.\n\n```bash\n# different architecture: ResNet18\nnbdt-hierarchy --arch=ResNet18 --dataset=CIFAR10\n\n# different dataset: ImageNet\nnbdt-hierarchy --arch=efficientnet_b7 --dataset=Imagenet1000\n\n# arbitrary checkpoint\nwget https://download.pytorch.org/models/resnet18-5c106cde.pth -O resnet18.pth\nnbdt-hierarchy --checkpoint=resnet18.pth --dataset=Imagenet1000\n```\n\nYou can also run the hierarchy generation from source directly, without using the command-line tool, by passing in a pretrained model.\n\n```\nfrom nbdt.hierarchy import generate_hierarchy\nfrom nbdt.models import wrn28_10_cifar10\n\nmodel = wrn28_10_cifar10(pretrained=True)\ngenerate_hierarchy(dataset='Imagenet1000', arch='wrn28_10_cifar10', model=model)\n```\n\n</div>\n</details>\n\n<details><summary><b>See example visualization.</b> <i>[click to expand]</i></summary>\n<div>\n\nBy default, the generation script outputs the HTML file containing a d3\nvisualization. All visualizations are stored in `out/`. We will generate another visualization with larger font size and includes wordnet IDs where available.\n\n```\nnbdt-hierarchy --vis-sublabels --vis-zoom=1.25 --dataset=CIFAR10 --arch=wrn28_10_cifar10\n```\n\nThe above script's output will end with the following.\n\n```\n==> Reading from ./nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json\nFound just 1 root.\n==> Wrote HTML to out/induced-wrn28_10_cifar10-tree.html\n```\n\nOpen up `out/induced-wrn28_10_cifar10-tree.html` in your browser to view the d3 tree visualization.\n\n<img width=\"873\" alt=\"Screen Shot 2020-03-24 at 1 51 49 AM\" src=\"https://user-images.githubusercontent.com/2068077/77406559-1426ae00-6d72-11ea-90da-ae3e78b7b206.png\">\n\n</div>\n</details>\n\n<details><summary><b>Want to reproduce hierarchy visualizations from the paper?</b> <i>[click to expand]</i></summary>\n<div>\n\nTo generate figures from the paper, use a larger zoom and do not include sublabels. The checkpoints used to generate the induced hierarchy visualizations are included in this repository's hub of models.\n\n```\nnbdt-hierarchy --vis-zoom=2.5 --dataset=CIFAR10 --arch=ResNet10 --vis-force-labels-left conveyance vertebrate chordate vehicle motor_vehicle mammal placental\nnbdt-hierarchy --vis-zoom=2.5 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --vis-leaf-images --vis-image-resize-factor=1.5 --vis-force-labels-left motor_vehicle craft chordate vertebrate carnivore ungulate craft\nnbdt-hierarchy --vis-zoom=2.5 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --vis-color-nodes whole --vis-no-color-leaves --vis-force-labels-left motor_vehicle craft chordate vertebrate carnivore ungulate craft\n```\n\n<img width=\"275\" alt=\"CIFAR10-induced-wrn28_10_cifar10\" src=\"https://user-images.githubusercontent.com/2068077/77971875-bd0a6700-72a4-11ea-80e8-c1308fce6c74.jpg\">\n<img width=\"275\" alt=\"CIFAR10_ResNet10_Tree\" src=\"https://user-images.githubusercontent.com/2068077/77971877-bed42a80-72a4-11ea-8019-e398a90829ff.jpg\">\n<img width=\"275\" src=\"https://user-images.githubusercontent.com/2068077/77971990-0a86d400-72a5-11ea-826b-c2ea7bbf3d80.jpg\">\n\n</div>\n</details>\n\n\n### WordNet Hierarchy\n\nRun the following to generate and test WordNet hierarchies for CIFAR10, CIFAR100, and TinyImagenet200. The script also downloads the NLTK WordNet corpus.\n\n```bash\nbash scripts/generate_hierarchies_wordnet.sh\n```\n\n<details><summary><b>See how it works.</b> <i>[click to expand]</i></summary>\n<div>\n\nThe below just explains the above `generate_hierarchies_wordnet.sh`, using CIFAR10. You do not need to run the following after running the above bash script.\n\n```bash\n# Generate mapping from classes to WNID. This is required for CIFAR10 and CIFAR100.\nnbdt-wnids --dataset=CIFAR10\n\n# Generate hierarchy, using the WNIDs. This is required for all datasets: CIFAR10, CIFAR100, TinyImagenet200\nnbdt-hierarchy --method=wordnet --dataset=CIFAR10\n```\n</details>\n\n<details><summary><b>See example visualization.</b> <i>[click to expand]</i></summary>\n<div>\n\nWe can generate a visualization with a slightly improved zoom and with wordnet IDs. By default, the script builds the Wordnet hierarchy for CIFAR10.\n\n```\nnbdt-hierarchy --method=wordnet --vis-zoom=1.25 --vis-sublabels\n```\n\n<img width=\"1002\" alt=\"Screen Shot 2020-03-24 at 2 02 16 AM\" src=\"https://user-images.githubusercontent.com/2068077/77407533-81870e80-6d73-11ea-9841-14b2caf13285.png\">\n\n</div>\n</details>\n\n\n### Random Hierarchy\n\nUse `--method=random` to randomly generate a binary-ish hierarchy. Optionally, use the `--seed` (`--seed=-1` to *not* shuffle leaves) and `--branching-factor` flags. When debugging, we set branching factor to the number of classes. For example, the sanity check hierarchy for CIFAR10 is\n\n```bash\nnbdt-hierarchy --seed=-1 --branching-factor=10 --dataset=CIFAR10\n```\n\n## 2. Tree Supervision Loss\n\nIn the below training commands, we uniformly use `--path-resume=<path/to/checkpoint> --lr=0.01` to fine-tune instead of training from scratch. Our results using a recently state-of-the-art pretrained checkpoint (WideResNet) were fine-tuned. Run the following to fine-tune WideResNet with soft tree supervision loss on CIFAR10.\n\n```bash\npython main.py --lr=0.01 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --pretrained --loss=SoftTreeSupLoss\n```\n\n<details><summary><b>See how it works and how to configure.</b> <i>[click to expand]</i></summary>\n<div>\n\n![tree_supervision_loss](https://user-images.githubusercontent.com/2068077/77226784-3208ce80-6b38-11ea-84bb-5128e3836665.jpg)\n\nThe tree supervision loss features two variants: a hard version and a soft version. Simply change the loss to `HardTreeSupLoss` or `SoftTreeSupLoss`, depending on the one you want.\n\n```bash\n# fine-tune the wrn pretrained checkpoint on CIFAR10 with hard tree supervision loss\npython main.py --lr=0.01 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --pretrained --loss=HardTreeSupLoss\n\n# fine-tune the wrn pretrained checkpoint on CIFAR10 with soft tree supervision loss\npython main.py --lr=0.01 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --pretrained --loss=SoftTreeSupLoss\n```\n\nTo train from scratch, use `--lr=0.1` and do not pass the `--path-resume` or `--pretrained` flags. We fine-tune WideResnet on CIFAR10, CIFAR100, but where the baseline neural network accuracy is reproducible, we train from scratch.\n</div>\n</details>\n\n## 3. Inference\n\nLike with the tree supervision loss variants, there are two inference variants: one is hard and one is soft. Below, we run soft inference on the model we just trained with the soft loss.\n\nRun the following bash script to obtain these numbers.\n\n```bash\npython main.py --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --loss=SoftTreeSupLoss --eval --resume --analysis=SoftEmbeddedDecisionRules\n```\n\n<details><summary><b>See how it works and how to configure.</b> <i>[click to expand]</i></summary>\n<div>\n\n![inference_modes](https://user-images.githubusercontent.com/2068077/76388544-9f418600-6326-11ea-9214-17356c71a066.jpg)\n\nNote the following commands are nearly identical to the corresponding train commands -- we drop the `lr`, `pretrained` flags and add `resume`, `eval`, and the `analysis` type (hard or soft inference). The best results in our paper, oddly enough, were obtained by running hard and soft inference *both* on the neural network supervised by a soft tree supervision loss. This is reflected in the commands below.\n\n```bash\n# running soft inference on soft-supervised model\npython main.py --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --loss=SoftTreeSupLoss --eval --resume --analysis=SoftEmbeddedDecisionRules\n\n# running hard inference on soft-supervised model\npython main.py --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --loss=SoftTreeSupLoss --eval --resume --analysis=HardEmbeddedDecisionRules\n```\n</div>\n</details>\n\n# Results\n\nWe compare against all previous decision-tree-based methods that report on CIFAR10, CIFAR100, and/or ImageNet, including methods that hinder interpretability by using impure leaves or a random forest. We report the baseline with the highest accuracy, of all these methods: Deep  Neural  Decision  Forest  (DNDF  updated with ResNet18), Explainable Observer-Classifier (XOC), Deep ConvolutionalDecision Jungle (DCDJ), Network of Experts (NofE), Deep Decision Network(DDN), and Adaptive Neural Trees (ANT).\n\n|                      | CIFAR10 | CIFAR100 | TinyImagenet200 | ImageNet |\n|----------------------|---------|----------|-----------------|----------|\n| NBDT-S (Ours)        | 97.57%  | 82.87%   | 66.66%          | 75.13%   |\n| NBDT-H (Ours)        | 97.55%  | 82.21%   | 64.39%          | 74.79%   |\n| Best Pre-NBDT Acc    | 94.32%  | 76.24%   | 44.56%          | 61.29%   |\n| Best Pre-NBDT Method | DNDF    | NofE     | DNDF            | NofE     |\n| Our improvement      | 3.25%   | 6.63%    | 22.1%           | 13.84%   |\n\nAs the last row denotes, we outperform all previous decision-tree-based methods by anywhere from 3% (CIFAR10) to 13%+ (ImageNet). Note that accuracies in our pretrained checkpoints for small to medium datasets (CIFAR10, CIFAR100, and TinyImagenet200) may fluctuate by 0.1-0.2%, as we retrained all models with the current public version of this repository.\n\n# Setup for Development\n\nAs discussed above, you can use the `nbdt` python library to integrate NBDT training into any existing training pipeline. However, if you wish to use the barebones training utilities here, refer to the following sections for adding custom models and datasets.\n\nIf you have not already, start by cloning the repository and installing all requirements.\n\n```bash\ngit clone git@github.com:alvinwan/neural-backed-decision-trees.git  # or http addr if you don't have private-public github key setup\ncd neural-backed-decision-trees\npython setup.py develop\n```\n\nAs a sample, we've included copies of the WideResNet bash script but for ResNet18.\n\n```bash\nbash scripts/gen_train_eval_resnet.sh\n```\n\nFor any models that have pretrained checkpoints for the datasets of interest (e.g., CIFAR10, CIFAR100, and ImageNet models from `pytorchcv` or ImageNet models from `torchvision`), modify `scripts/gen_train_eval_pretrained.sh`; it suffices to change the model name. For all models that do not have pretrained checkpoint for the dataset of interest, modify `scripts/gen_train_eval_nopretrained.sh`.\n\n## Models\n\nWithout any modifications to `main.py`, you can replace ResNet18 with your favorite network: Pass  any [`torchvision.models`](https://pytorch.org/docs/stable/torchvision/models.html) model or any [`pytorchcv`](https://github.com/osmr/imgclsmob/tree/master/pytorch) model to `--arch`, as we directly support both model zoos. Note that the former only supports models pretrained on ImageNet. The latter supports models pretrained on CIFAR10, CIFAR100, andd ImageNet; for each dataset, the corresponding model name includes the dataset e.g., `wrn28_10_cifar10`. However, neither supports models pretrained on TinyImagenet.\n\nTo add a new model from scratch:\n\n1. Create a new file containing your network, such as `./nbdt/models/yournet.py`. This file should contain an `__all__` only exposing functions that return a model. These functions should accept `pretrained: bool` and `progress: bool`, then forward all other keyword arguments to the model constructor.\n2. Expose your new file via `./nbdt/models/__init__.py`: `from .yournet import *`.\n3. Train the original neural network on the target dataset. e.g., `python main.py --arch=yournet18`.\n\n## Dataset\n\nWithout any modifications to `main.py`, you can use any image classification dataset found at [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html) by passing it to `--dataset`. To add a new dataset from scratch:\n\n1. Create a new file containing your dataset, such as `./nbdt/data/yourdata.py`. Say the data class is `YourData10`. Like before, only expose the dataset class via `__all__`. This dataset class should support a `.classes` attribute which returns a list of human-readable class names.\n2. Expose your new file via `'./nbdt/data/__init__.py'`: `from .yourdata import *`.\n3. Create a text file with wordnet IDs in `./nbdt/wnids/{dataset}.txt`. This list should be in the same order that your dataset's `.classes` is. You may optionally use the utility `nbdt-wnids` to generate wnids (see note below)\n4. Train the original neural network on the target dataset. e.g., `python main.py --dataset=YourData10`\n\n> **\\*Note**: You may optionally use the utility `nbdt-wnids` to generate wnids:\n> ```\n> nbdt-wnids --dataset=YourData10\n> ```\n> , where `YourData` is your dataset name. If a provided class name from `YourData.classes` does not exist in the WordNet corpus, the script will generate a fake wnid. This does not affect training but subsequent analysis scripts will be unable to provide WordNet-imputed node meanings.\n\n# Citation\n\nIf you find this work useful for your research, please cite our\u00a0[paper](http://nbdt.alvinwan.com/paper/):\n\n```\n@article{wan2020nbdt,\n   title={NBDT: Neural-Backed Decision Trees},\n   author={Alvin Wan and Lisa Dunlap and Daniel Ho and Jihan Yin and Scott Lee and Henry Jin and Suzanne Petryk and Sarah Adel Bargal and Joseph E. Gonzalez},\n   year={2020},\n   eprint={},\n   archivePrefix={arXiv},\n   primaryClass={cs.CV}\n}\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "https://github.com/alvinwan/neural-backed-decision-trees/archive/0.0.4.zip", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/alvinwan/neural-backed-decision-trees", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "nbdt", "package_url": "https://pypi.org/project/nbdt/", "platform": "", "project_url": "https://pypi.org/project/nbdt/", "project_urls": {"Download": "https://github.com/alvinwan/neural-backed-decision-trees/archive/0.0.4.zip", "Homepage": "https://github.com/alvinwan/neural-backed-decision-trees"}, "release_url": "https://pypi.org/project/nbdt/0.0.4/", "requires_dist": null, "requires_python": ">=3.5", "summary": "Making decision trees competitive with state-of-the-art neural networks on CIFAR10, CIFAR100, TinyImagenet200, Imagenet. Transform any image classification neural network into an interpretable neural-backed decision tree.", "version": "0.0.4", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Neural-Backed Decision Trees</h1>\n<p><a href=\"http://nbdt.alvinwan.com\" rel=\"nofollow\">Project Page</a> \u00a0//\u00a0 <a href=\"http://nbdt.alvinwan.com/paper/\" rel=\"nofollow\">Paper</a> \u00a0//\u00a0 <a href=\"http://nbdt.alvinwan.com/demo/\" rel=\"nofollow\">No-code Web Demo</a> \u00a0//\u00a0 <a href=\"https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb\" rel=\"nofollow\">Colab Notebook</a></p>\n<p><em>By Alvin Wan, *Lisa Dunlap, *Daniel Ho, Jihan Yin, Scott Lee, Henry Jin, Suzanne Petryk, Sarah Adel Bargal, Joseph E. Gonzalez</em>\n<sub>*denotes equal contribution</sub></p>\n<p>Run decision trees that achieve state-of-the-art accuracy for explainable models on CIFAR10, CIFAR100, TinyImagenet200, and ImageNet. NBDTs achieve accuracies within 1% of the original neural network on CIFAR10, CIFAR100, and TinyImagenet200 with the recently state-of-the-art WideResNet; and within 2% of the original neural network on ImageNet, using recently state-of-the-art EfficientNet. We attain an ImageNet top-1 accuracy of 75.13%.</p>\n<p><strong>Table of Contents</strong></p>\n<ul>\n<li><a href=\"#quickstart\" rel=\"nofollow\">Quickstart: Running and loading NBDTs</a></li>\n<li><a href=\"#convert-neural-networks-to-decision-trees\" rel=\"nofollow\">Convert your own neural network into a decision tree</a></li>\n<li><a href=\"#training-and-evaluation\" rel=\"nofollow\">Training and evaluation</a></li>\n<li><a href=\"#results\" rel=\"nofollow\">Results</a></li>\n<li><a href=\"#setup-for-development\" rel=\"nofollow\">Setup for Development</a></li>\n<li><a href=\"#citation\" rel=\"nofollow\">Citation</a></li>\n</ul>\n<p><img alt=\"pipeline\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/98ba3adbb4647733dcd0e686839ea1718e85c0cb/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37363338343737342d31666662383438302d363331642d313165612d393733662d3763616332613630626231302e6a7067\"></p>\n<p>Per the pipeline illustration above, we (1) <a href=\"https://github.com/alvinwan/neural-backed-decision-trees#1-Hierarchies\" rel=\"nofollow\">generate the hierarchy</a> and (2) train the neural network <a href=\"https://github.com/alvinwan/neural-backed-decision-trees#2-Tree-Supervision-Loss\" rel=\"nofollow\">with a tree supervision loss</a>. Then, we (3) <a href=\"https://github.com/alvinwan/neural-backed-decision-trees#3-Inference\" rel=\"nofollow\">run inference</a> by featurizing images using the network backbone and running embedded decision rules.</p>\n<h1>Quickstart</h1>\n<h2>Running Pretrained NBDT on Examples</h2>\n<p><i>Don't want to download? Try your own images on the <a href=\"http://nbdt.alvinwan.com/demo/\" rel=\"nofollow\">web demo</a>.</i></p>\n<p>Pip install the <code>nbdt</code> utility and run it on an image of your choosing. This can be a local image path or an image URL. Below, we evaluate on an image of a cat, from the web. This cat is pictured below.</p>\n<pre>pip install nbdt\nnbdt https://images.pexels.com/photos/126407/pexels-photo-126407.jpeg?auto<span class=\"o\">=</span>compress<span class=\"p\">&amp;</span><span class=\"nv\">cs</span><span class=\"o\">=</span>tinysrgb<span class=\"p\">&amp;</span><span class=\"nv\">dpr</span><span class=\"o\">=</span><span class=\"m\">2</span><span class=\"p\">&amp;</span><span class=\"nv\">w</span><span class=\"o\">=</span><span class=\"m\">32</span>\n</pre>\n<p>This outputs both the class prediction and all the intermediate decisions, like below:</p>\n<pre><code>Prediction: cat // Decisions: animal (99.47%), chordate (99.20%), carnivore (99.42%), cat (99.86%)\n</code></pre>\n<p>By default, this evaluation utility uses WideResNet pretrained on CIFAR10. You can also pass classes not seen in CIFAR10. Below, we pass a picture of a bear and a zebra. This zebra is also pictured below.</p>\n<pre>nbdt https://images.pexels.com/photos/750539/pexels-photo-750539.jpeg?auto<span class=\"o\">=</span>compress<span class=\"p\">&amp;</span><span class=\"nv\">cs</span><span class=\"o\">=</span>tinysrgb<span class=\"p\">&amp;</span><span class=\"nv\">dpr</span><span class=\"o\">=</span><span class=\"m\">2</span><span class=\"p\">&amp;</span><span class=\"nv\">h</span><span class=\"o\">=</span><span class=\"m\">32</span>\nnbdt https://images.pexels.com/photos/158109/kodiak-brown-bear-adult-portrait-wildlife-158109.jpeg?auto<span class=\"o\">=</span>compress<span class=\"p\">&amp;</span><span class=\"nv\">cs</span><span class=\"o\">=</span>tinysrgb<span class=\"p\">&amp;</span><span class=\"nv\">dpr</span><span class=\"o\">=</span><span class=\"m\">2</span><span class=\"p\">&amp;</span><span class=\"nv\">w</span><span class=\"o\">=</span><span class=\"m\">32</span>\n</pre>\n<p>Like before, this outputs the class prediction and intermediate decisions. Although the <em>Bear</em> and <em>Zebra</em> classes were not seen at train time, the model still correctly picks <em>Animal</em> over <em>Vehicle</em> for both. Note that for <em>Zebra</em>, the obvious closest class is <em>Horse</em>, matching the model's prediction below.</p>\n<pre><code>Prediction: horse // Decisions: animal (99.31%), ungulate (99.25%), horse (99.62%)\nPrediction: dog // Decisions: animal (99.51%), chordate (99.35%), carnivore (99.69%), dog (99.22%)\n</code></pre>\n<img align=\"left\" height=\"125\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3c5367c0019108d9701d01e68ac1f74aa6cdd009/68747470733a2f2f696d616765732e706578656c732e636f6d2f70686f746f732f3132363430372f706578656c732d70686f746f2d3132363430372e6a7065673f6175746f3d636f6d70726573732663733d74696e7973726762266470723d3226683d313235\">\n<img align=\"left\" height=\"125\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/993c03526e3ea2ff263657330e3d037c6e6fd341/68747470733a2f2f696d616765732e706578656c732e636f6d2f70686f746f732f3135383130392f6b6f6469616b2d62726f776e2d626561722d6164756c742d706f7274726169742d77696c646c6966652d3135383130392e6a7065673f6175746f3d636f6d70726573732663733d74696e7973726762266470723d3226683d313235\">\n<img align=\"left\" height=\"125\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e6787c5eb44aeb4d6b4eadec40c76d9ce8c16ccd/68747470733a2f2f696d616765732e706578656c732e636f6d2f70686f746f732f313439303930382f706578656c732d70686f746f2d313439303930382e6a7065673f6175746f3d636f6d70726573732663733d74696e7973726762266470723d3226683d313235\">\n<img height=\"125\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d9d5e248d27ba08502f69a09b846b490627ee99d/68747470733a2f2f696d616765732e706578656c732e636f6d2f70686f746f732f3735303533392f706578656c732d70686f746f2d3735303533392e6a7065673f6175746f3d636f6d70726573732663733d74696e7973726762266470723d3226683d313235\">\n<p><sub><em>Pictures are taken from <a href=\"http://pexels.com\" rel=\"nofollow\">pexels.com</a>, which are free to use per the <a href=\"https://www.pexels.com/photo-license/\" rel=\"nofollow\">Pexels license</a>.</em></sub></p>\n<h2>Loading Pretrained NBDTs in Code</h2>\n<p><i>Don't want to download? Try inference on a pre-filled <a href=\"https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb\" rel=\"nofollow\">Google Colab Notebook</a>.</i></p>\n<p>If you haven't already, pip install the <code>nbdt</code> utility.</p>\n<pre>pip install nbdt\n</pre>\n<p>Then, pick an NBDT inference mode (hard or soft), dataset, and backbone. By default, we support ResNet18 and WideResNet28x10 for CIFAR10, CIFAR100, and TinyImagenet200. See <a href=\"https://github.com/alvinwan/nbdt-pytorch-image-models\" rel=\"nofollow\">nbdt-pytorch-image-models</a> for EfficientNet-EdgeTPUSmall on ImageNet.</p>\n<p><sub><a href=\"https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb\" rel=\"nofollow\">Try below script on Google Colab</a></sub></p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nbdt.model</span> <span class=\"kn\">import</span> <span class=\"n\">SoftNBDT</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nbdt.models</span> <span class=\"kn\">import</span> <span class=\"n\">ResNet18</span><span class=\"p\">,</span> <span class=\"n\">wrn28_10_cifar10</span><span class=\"p\">,</span> <span class=\"n\">wrn28_10_cifar100</span><span class=\"p\">,</span> <span class=\"n\">wrn28_10</span>  <span class=\"c1\"># use wrn28_10 for TinyImagenet200</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">wrn28_10_cifar10</span><span class=\"p\">()</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SoftNBDT</span><span class=\"p\">(</span>\n  <span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n  <span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'CIFAR10'</span><span class=\"p\">,</span>\n  <span class=\"n\">arch</span><span class=\"o\">=</span><span class=\"s1\">'wrn28_10_cifar10'</span><span class=\"p\">,</span>\n  <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">)</span>\n</pre>\n<p>Note <code>torchvision.models.resnet18</code> only supports 224x224 input. However, <code>nbdt.models.resnet.ResNet18</code> supports variable size inputs. See <a href=\"#models\" rel=\"nofollow\">Models</a> for instructions on using your favorite image classification neural network.</p>\n<p><strong>Example in ~30 lines</strong>: See <a href=\"https://github.com/alvinwan/neural-backed-decision-trees/blob/master/nbdt/bin/nbdt\" rel=\"nofollow\"><code>nbdt/bin/nbdt</code></a>, which loads the pretrained model, loads an image, and runs inference on the image in ~30 lines. This file is the executable <code>nbdt</code> in the previous section. Try this in a <a href=\"https://colab.research.google.com/github/alvinwan/neural-backed-decision-trees/blob/master/examples/load_pretrained_nbdts.ipynb\" rel=\"nofollow\">Google Colab Notebook</a>.</p>\n<h1>Convert Neural Networks to Decision Trees</h1>\n\n<p><strong>To convert your neural network</strong> into a neural-backed decision tree, perform the following 3 steps:</p>\n<ol>\n<li><strong>First</strong>, if you haven't already, pip install the <code>nbdt</code> utility: <code>pip install nbdt</code></li>\n<li><strong>Second, during training</strong>, wrap your loss <code>criterion</code> with a custom NBDT loss. Below, we demonstrate the soft tree supervision loss on the CIFAR10 dataset. By default, we support <code>CIFAR10</code>, <code>CIFAR100</code>, <code>TinyImagenet200</code>, and <code>Imagenet1000</code>.</li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nbdt.loss</span> <span class=\"kn\">import</span> <span class=\"n\">SoftTreeSupLoss</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">SoftTreeSupLoss</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'CIFAR10'</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">criterion</span><span class=\"p\">)</span>  <span class=\"c1\"># `criterion` is your original loss function e.g., nn.CrossEntropyLoss</span>\n</pre>\n<ol>\n<li><strong>Third, during inference or validation</strong>, wrap your <code>model</code> with a custom NBDT wrapper as shown below. This is only to run prediction as an NBDT during validation or inference time. Do not wrap your model like below, during training.</li>\n</ol>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nbdt.model</span> <span class=\"kn\">import</span> <span class=\"n\">SoftNBDT</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SoftNBDT</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'CIFAR10'</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">)</span>  <span class=\"c1\"># `model` is your original model</span>\n</pre>\n<p><strong>Example integration with repository</strong>: See <a href=\"https://github.com/alvinwan/nbdt-pytorch-image-models\" rel=\"nofollow\"><code>nbdt-pytorch-image-models</code></a>, which applies this 3-step integration to a popular image classification repository <code>pytorch-image-models</code>.</p>\n\n<details><summary><b>Example integration with a random neural network in 16 lines</b> <i>[click to expand]</i></summary>\n<div>\n<p>You can also include arbitrary image classification neural networks not explicitly supported in this repository. For example, after installing <a href=\"https://github.com/Cadene/pretrained-models.pytorch#quick-examples\" rel=\"nofollow\"><code>pretrained-models.pytorch</code></a> using pip, you can instantiate and pass any pretrained model into our NBDT utility functions.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nbdt.model</span> <span class=\"kn\">import</span> <span class=\"n\">SoftNBDT</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nbdt.loss</span> <span class=\"kn\">import</span> <span class=\"n\">SoftTreeSupLoss</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nbdt.hierarchy</span> <span class=\"kn\">import</span> <span class=\"n\">generate_hierarchy</span>\n<span class=\"kn\">import</span> <span class=\"nn\">pretrainedmodels</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">pretrainedmodels</span><span class=\"o\">.</span><span class=\"vm\">__dict__</span><span class=\"p\">[</span><span class=\"s1\">'fbresnet152'</span><span class=\"p\">](</span><span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">pretrained</span><span class=\"o\">=</span><span class=\"s1\">'imagenet'</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 1. generate hierarchy from pretrained model</span>\n<span class=\"n\">generate_hierarchy</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'Imagenet1000'</span><span class=\"p\">,</span> <span class=\"n\">arch</span><span class=\"o\">=</span><span class=\"s1\">'fbresnet152'</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 2. Fine-tune model with tree supervision loss</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">SoftTreeSupLoss</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'Imagenet1000'</span><span class=\"p\">,</span> <span class=\"n\">hierarchy</span><span class=\"o\">=</span><span class=\"s1\">'induced-fbresnet152'</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">criterion</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 3. Run inference using embedded decision rules</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SoftNBDT</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'Imagenet1000'</span><span class=\"p\">,</span> <span class=\"n\">hierarchy</span><span class=\"o\">=</span><span class=\"s1\">'induced-fbresnet152'</span><span class=\"p\">)</span>\n</pre>\n<p>For more information on generating different hierarchies, see <a href=\"#induced-hierarchy\" rel=\"nofollow\">Induced Hierarchy</a>.</p>\n</div>\n</details>\n<details><summary><b>Want to build and use your own induced hierarchy?</b> <i>[click to expand]</i></summary>\n<div>\n<p>Use the <code>nbdt-hierarchy</code> utility to generate a new induced hierarchy from a pretrained model.</p>\n<pre>nbdt-hierarchy --arch<span class=\"o\">=</span>efficientnet_b0 --dataset<span class=\"o\">=</span>Imagenet1000\n</pre>\n<p>Then, pass the hierarchy name to the loss and models. You may alternatively pass the fully-qualified <code>path_graph</code> path.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">nbdt.loss</span> <span class=\"kn\">import</span> <span class=\"n\">SoftTreeSupLoss</span>\n<span class=\"kn\">from</span> <span class=\"nn\">nbdt.model</span> <span class=\"kn\">import</span> <span class=\"n\">SoftNBDT</span>\n\n<span class=\"n\">criterion</span> <span class=\"o\">=</span> <span class=\"n\">SoftTreeSupLoss</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'Imagenet1000'</span><span class=\"p\">,</span> <span class=\"n\">criterion</span><span class=\"o\">=</span><span class=\"n\">criterion</span><span class=\"p\">,</span> <span class=\"n\">hierarchy</span><span class=\"o\">=</span><span class=\"s1\">'induced-efficientnet_b0'</span><span class=\"p\">)</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">SoftNBDT</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"o\">=</span><span class=\"s1\">'Imagenet1000'</span><span class=\"p\">,</span> <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">hierarchy</span><span class=\"o\">=</span><span class=\"s1\">'induced-efficientnet_b0'</span><span class=\"p\">)</span>\n</pre>\n<p>For more information on generating different hierarchies, see <a href=\"#induced-hierarchy\" rel=\"nofollow\">Induced Hierarchy</a>.</p>\n</div>\n</details>\n<h1>Training and Evaluation</h1>\n<p><strong>To reproduce experimental results</strong>, start by cloning the repository and installing all requirements.</p>\n<pre>git clone git@github.com:alvinwan/neural-backed-decision-trees.git  <span class=\"c1\"># or http addr if you don't have private-public github key setup</span>\n<span class=\"nb\">cd</span> neural-backed-decision-trees\npython setup.py develop\n</pre>\n<p>To reproduce the core experimental results in our paper -- ignoring ablation studies -- simply run the following bash script:</p>\n<pre>bash scripts/gen_train_eval_wideresnet.sh\n</pre>\n<p>Want more transparent step-by-step instructions? The bash scripts above are explained in more detail in the following sections: <a href=\"https://github.com/alvinwan/neural-backed-decision-trees#Induced-Hierarchy\" rel=\"nofollow\">Induced Hierarchy</a>, <a href=\"https://github.com/alvinwan/neural-backed-decision-trees#Tree-Supervision-Loss\" rel=\"nofollow\">Soft Tree Supervision Loss</a>, and <a href=\"https://github.com/alvinwan/neural-backed-decision-trees#Soft-Inference\" rel=\"nofollow\">Soft Inference</a>. These scripts reproduce our CIFAR10, CIFAR100, and TinyImagenet200 results. To reproduce our ImageNet results, see <a href=\"https://github.com/alvinwan/nbdt-pytorch-image-models\" rel=\"nofollow\"><code>nbdt-pytorch-image-models</code></a>.</p>\n<p>For all scripts, you can use any <a href=\"https://pytorch.org/docs/stable/torchvision/models.html\" rel=\"nofollow\"><code>torchvision</code></a> model or any <a href=\"https://github.com/osmr/imgclsmob/tree/master/pytorch\" rel=\"nofollow\"><code>pytorchcv</code></a> model, as we directly support both model zoos. Customization for each step is explained below.</p>\n<h2>1. Hierarchies</h2>\n<h3>Induced Hierarchy</h3>\n<p>Run the following to generate and test induced hierarchies for CIFAR10 based off of the WideResNet model.</p>\n<pre>nbdt-hierarchy --arch<span class=\"o\">=</span>wrn28_10_cifar10 --dataset<span class=\"o\">=</span>CIFAR10\n</pre>\n<details><summary><b>See how it works and how to configure.</b> <i>[click to expand]</i></summary>\n<div>\n<p><img alt=\"induced_structure\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e684941b77e14016f7289d042cd1eb5530206474/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37363338383330342d30653661616138302d363332362d313165612d386339622d3664303863623839666166652e6a7067\"></p>\n<p>The script loads the pretrained model (Step A), populates the leaves of the tree with fully-connected layer weights (Step B) and performs hierarchical agglomerative clustering (Step C). Note that the above command can be rerun with different architectures, different datasets, or random neural network checkpoints to produce different hierarchies.</p>\n<pre><span class=\"c1\"># different architecture: ResNet18</span>\nnbdt-hierarchy --arch<span class=\"o\">=</span>ResNet18 --dataset<span class=\"o\">=</span>CIFAR10\n\n<span class=\"c1\"># different dataset: ImageNet</span>\nnbdt-hierarchy --arch<span class=\"o\">=</span>efficientnet_b7 --dataset<span class=\"o\">=</span>Imagenet1000\n\n<span class=\"c1\"># arbitrary checkpoint</span>\nwget https://download.pytorch.org/models/resnet18-5c106cde.pth -O resnet18.pth\nnbdt-hierarchy --checkpoint<span class=\"o\">=</span>resnet18.pth --dataset<span class=\"o\">=</span>Imagenet1000\n</pre>\n<p>You can also run the hierarchy generation from source directly, without using the command-line tool, by passing in a pretrained model.</p>\n<pre><code>from nbdt.hierarchy import generate_hierarchy\nfrom nbdt.models import wrn28_10_cifar10\n\nmodel = wrn28_10_cifar10(pretrained=True)\ngenerate_hierarchy(dataset='Imagenet1000', arch='wrn28_10_cifar10', model=model)\n</code></pre>\n</div>\n</details>\n<details><summary><b>See example visualization.</b> <i>[click to expand]</i></summary>\n<div>\n<p>By default, the generation script outputs the HTML file containing a d3\nvisualization. All visualizations are stored in <code>out/</code>. We will generate another visualization with larger font size and includes wordnet IDs where available.</p>\n<pre><code>nbdt-hierarchy --vis-sublabels --vis-zoom=1.25 --dataset=CIFAR10 --arch=wrn28_10_cifar10\n</code></pre>\n<p>The above script's output will end with the following.</p>\n<pre><code>==&gt; Reading from ./nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json\nFound just 1 root.\n==&gt; Wrote HTML to out/induced-wrn28_10_cifar10-tree.html\n</code></pre>\n<p>Open up <code>out/induced-wrn28_10_cifar10-tree.html</code> in your browser to view the d3 tree visualization.</p>\n<img alt=\"Screen Shot 2020-03-24 at 1 51 49 AM\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8741917cc41d8806b8e3d35da72c759678198381/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37373430363535392d31343236616530302d366437322d313165612d393064612d6165336537386237623230362e706e67\" width=\"873\">\n</div>\n</details>\n<details><summary><b>Want to reproduce hierarchy visualizations from the paper?</b> <i>[click to expand]</i></summary>\n<div>\n<p>To generate figures from the paper, use a larger zoom and do not include sublabels. The checkpoints used to generate the induced hierarchy visualizations are included in this repository's hub of models.</p>\n<pre><code>nbdt-hierarchy --vis-zoom=2.5 --dataset=CIFAR10 --arch=ResNet10 --vis-force-labels-left conveyance vertebrate chordate vehicle motor_vehicle mammal placental\nnbdt-hierarchy --vis-zoom=2.5 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --vis-leaf-images --vis-image-resize-factor=1.5 --vis-force-labels-left motor_vehicle craft chordate vertebrate carnivore ungulate craft\nnbdt-hierarchy --vis-zoom=2.5 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --vis-color-nodes whole --vis-no-color-leaves --vis-force-labels-left motor_vehicle craft chordate vertebrate carnivore ungulate craft\n</code></pre>\n<img alt=\"CIFAR10-induced-wrn28_10_cifar10\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7ec8074e216b627d970fa15d8a2ca7b374a0c94f/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37373937313837352d62643061363730302d373261342d313165612d383065382d6331333038666365366337342e6a7067\" width=\"275\">\n<img alt=\"CIFAR10_ResNet10_Tree\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ea222d0c4669f0b886fe5bc8ab5fa710ff516dca/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37373937313837372d62656434326138302d373261342d313165612d383031392d6533393861393038323966662e6a7067\" width=\"275\">\n<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dd61a194e46596dd95e3ba627b0bbe396f50b502/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37373937313939302d30613836643430302d373261352d313165612d383236622d6332656137626266336438302e6a7067\" width=\"275\">\n</div>\n</details>\n<h3>WordNet Hierarchy</h3>\n<p>Run the following to generate and test WordNet hierarchies for CIFAR10, CIFAR100, and TinyImagenet200. The script also downloads the NLTK WordNet corpus.</p>\n<pre>bash scripts/generate_hierarchies_wordnet.sh\n</pre>\n<details><summary><b>See how it works.</b> <i>[click to expand]</i></summary>\n<div>\n<p>The below just explains the above <code>generate_hierarchies_wordnet.sh</code>, using CIFAR10. You do not need to run the following after running the above bash script.</p>\n<pre><span class=\"c1\"># Generate mapping from classes to WNID. This is required for CIFAR10 and CIFAR100.</span>\nnbdt-wnids --dataset<span class=\"o\">=</span>CIFAR10\n\n<span class=\"c1\"># Generate hierarchy, using the WNIDs. This is required for all datasets: CIFAR10, CIFAR100, TinyImagenet200</span>\nnbdt-hierarchy --method<span class=\"o\">=</span>wordnet --dataset<span class=\"o\">=</span>CIFAR10\n</pre>\n</div></details>\n<details><summary><b>See example visualization.</b> <i>[click to expand]</i></summary>\n<div>\n<p>We can generate a visualization with a slightly improved zoom and with wordnet IDs. By default, the script builds the Wordnet hierarchy for CIFAR10.</p>\n<pre><code>nbdt-hierarchy --method=wordnet --vis-zoom=1.25 --vis-sublabels\n</code></pre>\n<img alt=\"Screen Shot 2020-03-24 at 2 02 16 AM\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1be033116320ca0fc051b1b2991b2ccdaa74e981/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37373430373533332d38313837306538302d366437332d313165612d393834312d3134623263616631333238352e706e67\" width=\"1002\">\n</div>\n</details>\n<h3>Random Hierarchy</h3>\n<p>Use <code>--method=random</code> to randomly generate a binary-ish hierarchy. Optionally, use the <code>--seed</code> (<code>--seed=-1</code> to <em>not</em> shuffle leaves) and <code>--branching-factor</code> flags. When debugging, we set branching factor to the number of classes. For example, the sanity check hierarchy for CIFAR10 is</p>\n<pre>nbdt-hierarchy --seed<span class=\"o\">=</span>-1 --branching-factor<span class=\"o\">=</span><span class=\"m\">10</span> --dataset<span class=\"o\">=</span>CIFAR10\n</pre>\n<h2>2. Tree Supervision Loss</h2>\n<p>In the below training commands, we uniformly use <code>--path-resume=&lt;path/to/checkpoint&gt; --lr=0.01</code> to fine-tune instead of training from scratch. Our results using a recently state-of-the-art pretrained checkpoint (WideResNet) were fine-tuned. Run the following to fine-tune WideResNet with soft tree supervision loss on CIFAR10.</p>\n<pre>python main.py --lr<span class=\"o\">=</span><span class=\"m\">0</span>.01 --dataset<span class=\"o\">=</span>CIFAR10 --arch<span class=\"o\">=</span>wrn28_10_cifar10 --hierarchy<span class=\"o\">=</span>induced-wrn28_10_cifar10 --pretrained --loss<span class=\"o\">=</span>SoftTreeSupLoss\n</pre>\n<details><summary><b>See how it works and how to configure.</b> <i>[click to expand]</i></summary>\n<div>\n<p><img alt=\"tree_supervision_loss\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/f78e9a16ccdc3df75e358fdd0c3b440f83993ea2/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37373232363738342d33323038636538302d366233382d313165612d383462622d3531323865333833363636352e6a7067\"></p>\n<p>The tree supervision loss features two variants: a hard version and a soft version. Simply change the loss to <code>HardTreeSupLoss</code> or <code>SoftTreeSupLoss</code>, depending on the one you want.</p>\n<pre><span class=\"c1\"># fine-tune the wrn pretrained checkpoint on CIFAR10 with hard tree supervision loss</span>\npython main.py --lr<span class=\"o\">=</span><span class=\"m\">0</span>.01 --dataset<span class=\"o\">=</span>CIFAR10 --arch<span class=\"o\">=</span>wrn28_10_cifar10 --hierarchy<span class=\"o\">=</span>induced-wrn28_10_cifar10 --pretrained --loss<span class=\"o\">=</span>HardTreeSupLoss\n\n<span class=\"c1\"># fine-tune the wrn pretrained checkpoint on CIFAR10 with soft tree supervision loss</span>\npython main.py --lr<span class=\"o\">=</span><span class=\"m\">0</span>.01 --dataset<span class=\"o\">=</span>CIFAR10 --arch<span class=\"o\">=</span>wrn28_10_cifar10 --hierarchy<span class=\"o\">=</span>induced-wrn28_10_cifar10 --pretrained --loss<span class=\"o\">=</span>SoftTreeSupLoss\n</pre>\n<p>To train from scratch, use <code>--lr=0.1</code> and do not pass the <code>--path-resume</code> or <code>--pretrained</code> flags. We fine-tune WideResnet on CIFAR10, CIFAR100, but where the baseline neural network accuracy is reproducible, we train from scratch.</p>\n</div>\n</details>\n<h2>3. Inference</h2>\n<p>Like with the tree supervision loss variants, there are two inference variants: one is hard and one is soft. Below, we run soft inference on the model we just trained with the soft loss.</p>\n<p>Run the following bash script to obtain these numbers.</p>\n<pre>python main.py --dataset<span class=\"o\">=</span>CIFAR10 --arch<span class=\"o\">=</span>wrn28_10_cifar10 --hierarchy<span class=\"o\">=</span>induced-wrn28_10_cifar10 --loss<span class=\"o\">=</span>SoftTreeSupLoss --eval --resume --analysis<span class=\"o\">=</span>SoftEmbeddedDecisionRules\n</pre>\n<details><summary><b>See how it works and how to configure.</b> <i>[click to expand]</i></summary>\n<div>\n<p><img alt=\"inference_modes\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/1a13438a7000f4cdacd1985387c60281d2e64150/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f323036383037372f37363338383534342d39663431383630302d363332362d313165612d393231342d3137333536633731613036362e6a7067\"></p>\n<p>Note the following commands are nearly identical to the corresponding train commands -- we drop the <code>lr</code>, <code>pretrained</code> flags and add <code>resume</code>, <code>eval</code>, and the <code>analysis</code> type (hard or soft inference). The best results in our paper, oddly enough, were obtained by running hard and soft inference <em>both</em> on the neural network supervised by a soft tree supervision loss. This is reflected in the commands below.</p>\n<pre><span class=\"c1\"># running soft inference on soft-supervised model</span>\npython main.py --dataset<span class=\"o\">=</span>CIFAR10 --arch<span class=\"o\">=</span>wrn28_10_cifar10 --hierarchy<span class=\"o\">=</span>induced-wrn28_10_cifar10 --loss<span class=\"o\">=</span>SoftTreeSupLoss --eval --resume --analysis<span class=\"o\">=</span>SoftEmbeddedDecisionRules\n\n<span class=\"c1\"># running hard inference on soft-supervised model</span>\npython main.py --dataset<span class=\"o\">=</span>CIFAR10 --arch<span class=\"o\">=</span>wrn28_10_cifar10 --hierarchy<span class=\"o\">=</span>induced-wrn28_10_cifar10 --loss<span class=\"o\">=</span>SoftTreeSupLoss --eval --resume --analysis<span class=\"o\">=</span>HardEmbeddedDecisionRules\n</pre>\n</div>\n</details>\n<h1>Results</h1>\n<p>We compare against all previous decision-tree-based methods that report on CIFAR10, CIFAR100, and/or ImageNet, including methods that hinder interpretability by using impure leaves or a random forest. We report the baseline with the highest accuracy, of all these methods: Deep  Neural  Decision  Forest  (DNDF  updated with ResNet18), Explainable Observer-Classifier (XOC), Deep ConvolutionalDecision Jungle (DCDJ), Network of Experts (NofE), Deep Decision Network(DDN), and Adaptive Neural Trees (ANT).</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>CIFAR10</th>\n<th>CIFAR100</th>\n<th>TinyImagenet200</th>\n<th>ImageNet</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NBDT-S (Ours)</td>\n<td>97.57%</td>\n<td>82.87%</td>\n<td>66.66%</td>\n<td>75.13%</td>\n</tr>\n<tr>\n<td>NBDT-H (Ours)</td>\n<td>97.55%</td>\n<td>82.21%</td>\n<td>64.39%</td>\n<td>74.79%</td>\n</tr>\n<tr>\n<td>Best Pre-NBDT Acc</td>\n<td>94.32%</td>\n<td>76.24%</td>\n<td>44.56%</td>\n<td>61.29%</td>\n</tr>\n<tr>\n<td>Best Pre-NBDT Method</td>\n<td>DNDF</td>\n<td>NofE</td>\n<td>DNDF</td>\n<td>NofE</td>\n</tr>\n<tr>\n<td>Our improvement</td>\n<td>3.25%</td>\n<td>6.63%</td>\n<td>22.1%</td>\n<td>13.84%</td>\n</tr></tbody></table>\n<p>As the last row denotes, we outperform all previous decision-tree-based methods by anywhere from 3% (CIFAR10) to 13%+ (ImageNet). Note that accuracies in our pretrained checkpoints for small to medium datasets (CIFAR10, CIFAR100, and TinyImagenet200) may fluctuate by 0.1-0.2%, as we retrained all models with the current public version of this repository.</p>\n<h1>Setup for Development</h1>\n<p>As discussed above, you can use the <code>nbdt</code> python library to integrate NBDT training into any existing training pipeline. However, if you wish to use the barebones training utilities here, refer to the following sections for adding custom models and datasets.</p>\n<p>If you have not already, start by cloning the repository and installing all requirements.</p>\n<pre>git clone git@github.com:alvinwan/neural-backed-decision-trees.git  <span class=\"c1\"># or http addr if you don't have private-public github key setup</span>\n<span class=\"nb\">cd</span> neural-backed-decision-trees\npython setup.py develop\n</pre>\n<p>As a sample, we've included copies of the WideResNet bash script but for ResNet18.</p>\n<pre>bash scripts/gen_train_eval_resnet.sh\n</pre>\n<p>For any models that have pretrained checkpoints for the datasets of interest (e.g., CIFAR10, CIFAR100, and ImageNet models from <code>pytorchcv</code> or ImageNet models from <code>torchvision</code>), modify <code>scripts/gen_train_eval_pretrained.sh</code>; it suffices to change the model name. For all models that do not have pretrained checkpoint for the dataset of interest, modify <code>scripts/gen_train_eval_nopretrained.sh</code>.</p>\n<h2>Models</h2>\n<p>Without any modifications to <code>main.py</code>, you can replace ResNet18 with your favorite network: Pass  any <a href=\"https://pytorch.org/docs/stable/torchvision/models.html\" rel=\"nofollow\"><code>torchvision.models</code></a> model or any <a href=\"https://github.com/osmr/imgclsmob/tree/master/pytorch\" rel=\"nofollow\"><code>pytorchcv</code></a> model to <code>--arch</code>, as we directly support both model zoos. Note that the former only supports models pretrained on ImageNet. The latter supports models pretrained on CIFAR10, CIFAR100, andd ImageNet; for each dataset, the corresponding model name includes the dataset e.g., <code>wrn28_10_cifar10</code>. However, neither supports models pretrained on TinyImagenet.</p>\n<p>To add a new model from scratch:</p>\n<ol>\n<li>Create a new file containing your network, such as <code>./nbdt/models/yournet.py</code>. This file should contain an <code>__all__</code> only exposing functions that return a model. These functions should accept <code>pretrained: bool</code> and <code>progress: bool</code>, then forward all other keyword arguments to the model constructor.</li>\n<li>Expose your new file via <code>./nbdt/models/__init__.py</code>: <code>from .yournet import *</code>.</li>\n<li>Train the original neural network on the target dataset. e.g., <code>python main.py --arch=yournet18</code>.</li>\n</ol>\n<h2>Dataset</h2>\n<p>Without any modifications to <code>main.py</code>, you can use any image classification dataset found at <a href=\"https://pytorch.org/docs/stable/torchvision/datasets.html\" rel=\"nofollow\"><code>torchvision.datasets</code></a> by passing it to <code>--dataset</code>. To add a new dataset from scratch:</p>\n<ol>\n<li>Create a new file containing your dataset, such as <code>./nbdt/data/yourdata.py</code>. Say the data class is <code>YourData10</code>. Like before, only expose the dataset class via <code>__all__</code>. This dataset class should support a <code>.classes</code> attribute which returns a list of human-readable class names.</li>\n<li>Expose your new file via <code>'./nbdt/data/__init__.py'</code>: <code>from .yourdata import *</code>.</li>\n<li>Create a text file with wordnet IDs in <code>./nbdt/wnids/{dataset}.txt</code>. This list should be in the same order that your dataset's <code>.classes</code> is. You may optionally use the utility <code>nbdt-wnids</code> to generate wnids (see note below)</li>\n<li>Train the original neural network on the target dataset. e.g., <code>python main.py --dataset=YourData10</code></li>\n</ol>\n<blockquote>\n<p><strong>*Note</strong>: You may optionally use the utility <code>nbdt-wnids</code> to generate wnids:</p>\n<pre><code>nbdt-wnids --dataset=YourData10\n</code></pre>\n<p>, where <code>YourData</code> is your dataset name. If a provided class name from <code>YourData.classes</code> does not exist in the WordNet corpus, the script will generate a fake wnid. This does not affect training but subsequent analysis scripts will be unable to provide WordNet-imputed node meanings.</p>\n</blockquote>\n<h1>Citation</h1>\n<p>If you find this work useful for your research, please cite our\u00a0<a href=\"http://nbdt.alvinwan.com/paper/\" rel=\"nofollow\">paper</a>:</p>\n<pre><code>@article{wan2020nbdt,\n   title={NBDT: Neural-Backed Decision Trees},\n   author={Alvin Wan and Lisa Dunlap and Daniel Ho and Jihan Yin and Scott Lee and Henry Jin and Suzanne Petryk and Sarah Adel Bargal and Joseph E. Gonzalez},\n   year={2020},\n   eprint={},\n   archivePrefix={arXiv},\n   primaryClass={cs.CV}\n}\n</code></pre>\n\n          </div>"}, "last_serial": 6916920, "releases": {"0.0.2": [{"comment_text": "", "digests": {"md5": "b6627c45dad6fb0d9edafe6bab3ff1a8", "sha256": "3afce3bc57da3d7d1592351c40df7f6b6934e2b322b60f32a0dc203f610b16ec"}, "downloads": -1, "filename": "nbdt-0.0.2.tar.gz", "has_sig": false, "md5_digest": "b6627c45dad6fb0d9edafe6bab3ff1a8", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 114574, "upload_time": "2020-03-25T23:51:25", "upload_time_iso_8601": "2020-03-25T23:51:25.759102Z", "url": "https://files.pythonhosted.org/packages/20/b5/c8bc8d1c3ea0d03f825a90fe4aec87c86aac4533b604c167c993a7ab0209/nbdt-0.0.2.tar.gz", "yanked": false}], "0.0.3": [{"comment_text": "", "digests": {"md5": "4ab2a5f0e34b71e8891f4c10ac6108b6", "sha256": "8f594ec461588ffff22e2311a5773703dc2fd4f50a9f393f74a782a3c13a02bc"}, "downloads": -1, "filename": "nbdt-0.0.3.tar.gz", "has_sig": false, "md5_digest": "4ab2a5f0e34b71e8891f4c10ac6108b6", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 115446, "upload_time": "2020-03-26T00:02:43", "upload_time_iso_8601": "2020-03-26T00:02:43.695225Z", "url": "https://files.pythonhosted.org/packages/51/92/2387d6e9cf8e8749a91025331b72454f3357b16aee7ed2c4d9f9407b469f/nbdt-0.0.3.tar.gz", "yanked": false}], "0.0.4": [{"comment_text": "", "digests": {"md5": "4b3a8a0725f2942266985539a0a288f0", "sha256": "da5873b68e62d7215a72bbb46e8b6f0fc2044380e73b111e654422c5601a3d14"}, "downloads": -1, "filename": "nbdt-0.0.4.tar.gz", "has_sig": false, "md5_digest": "4b3a8a0725f2942266985539a0a288f0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 119265, "upload_time": "2020-03-30T23:49:42", "upload_time_iso_8601": "2020-03-30T23:49:42.745820Z", "url": "https://files.pythonhosted.org/packages/d9/3a/75fb13e538bb75df5bb4802a7296311e88923eec0c1f76e9da5e2887f6b9/nbdt-0.0.4.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "4b3a8a0725f2942266985539a0a288f0", "sha256": "da5873b68e62d7215a72bbb46e8b6f0fc2044380e73b111e654422c5601a3d14"}, "downloads": -1, "filename": "nbdt-0.0.4.tar.gz", "has_sig": false, "md5_digest": "4b3a8a0725f2942266985539a0a288f0", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 119265, "upload_time": "2020-03-30T23:49:42", "upload_time_iso_8601": "2020-03-30T23:49:42.745820Z", "url": "https://files.pythonhosted.org/packages/d9/3a/75fb13e538bb75df5bb4802a7296311e88923eec0c1f76e9da5e2887f6b9/nbdt-0.0.4.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:46:57 2020"}