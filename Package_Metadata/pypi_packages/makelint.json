{"info": {"author": "Josh Bialkowski", "author_email": "josh.bialkowski@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "=========\nMake Lint\n=========\n\nA highly-compatible \"build\" system for linting python files.\n\n-------\nPurpose\n-------\n\nThe purpose of this program is to lint/check your python code. Why do you\nneed specialized software to do this?\n\n1. Python static analysis tools (``pylint``, ``flake8``, etc) are slow. If you\n   have more than a couple dozen files then linting every file can take quite\n   a long time.\n2. These tools generally load the module to understand what the python code\n   is doing. This means that the checker depends not just on the file you're\n   checking, but the full transitive closure of it's dependencies\n\nThis program maintains a database of dependencies so that you can be confident\nthat a particular lint check is still valid. You can know for certain not just\nthat a particular file hasn't changed, but also none of the files it depends on\nhas changed. This allows you to skip re-checking unchanged files.\n\nIt is the intent of this project to (eventually) support standard build-systems\nlike ``make`` or ``ninja``, but it also implements a self-contained solution.\nIn particular it allows an \"opt-out\" workflow (rather than an opt-in) meaning\ntwo things:\n\n1. You don't need to re-run configure (or cmake) when you add new files\n   (and, lets face it, you are probably suffering from some configure\n   bloat, aren't you).\n2. When new python is added to the code base, it is automatically included\n   for checking. A human being must make an explicit decision to exclude it.\n   Developers cannot \"forget\" to add it to the build system for linting.\n\n-----\nUsage\n-----\n\n.. dynamic: usage-begin\n\n.. code:: text\n\n    usage:\n    pymakelint [-h] [-v] [-l {debug,info,warning,error}] [--dump-config]\n               [-c CONFIG_FILE] [<config-overrides> [...]]\n\n    Incremental execution system for python code analysis (linting).\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -v, --version         show program's version number and exit\n      -l {debug,info,warning,error}, --log-level {debug,info,warning,error}\n      --dump-config         If specified, print the default configuration to\n                            stdout and exit\n      -c CONFIG_FILE, --config-file CONFIG_FILE\n                            path to configuration file\n\n    Configuration:\n      Override configfile options\n\n      --include-patterns [INCLUDE_PATTERNS [INCLUDE_PATTERNS ...]]\n                            A list of python regular expression patterns which are\n                            used to include files during the directory walk. They\n                            are matched against relative paths of files (relative\n                            to the root of the search). They are not matched\n                            against directories. The default is `[\".*\\.py\"]`.\n      --exclude-patterns [EXCLUDE_PATTERNS [EXCLUDE_PATTERNS ...]]\n                            A list of python regular expression patterns which are\n                            used to exclude files during the directory walk. They\n                            are matched against relative paths of files (relative\n                            to the root of the search). If the pattern matches a\n                            directory the whole directory is skipped. If it\n                            matches an individual file then that file is skipped.\n      --source-tree SOURCE_TREE\n                            The root of the search tree for inclusion.\n      --target-tree TARGET_TREE\n                            The root of the tree where the outputs are written.\n      --tools [TOOLS [TOOLS ...]]\n                            A list of tools to execute. The default is [\"pylint\",\n                            \"flake8\"]. This can either be a string (a simple\n                            command which takes one argument), or it can be an\n                            object with a get_stamp() and an execute() method. See\n                            SimpleTool for ane example.\n      --fail-fast [FAIL_FAST]\n                            If true, exit on the first failure, don't keep going.\n                            Useful if you want a speedy CI gate.\n      --merged-log MERGED_LOG\n                            If specified, output logs for failed jobs will be\n                            merged into a single file at this location. Useful if\n                            you have a large number of issues to del with.\n      --quiet [QUIET]       Don't print fancy progress bars to stdout.\n      --jobs JOBS           Number of parallel jobs to execute.\n\n.. dynamic: usage-end\n\n-------------\nConfiguration\n-------------\n\nMost command line options can also be specified in a configuration file.\nConfiguration files are python files. If not specified on the command line,\nthe tool will automatically look for and load the configuration file at\n``<source_tree>/.makelint.py``.\n\nYou can use ``--dump-config`` to dump the default configuration to a file and\nuse that as a starting point. The default config is also pasted below.\n\n.. dynamic: config-begin\n\n.. code:: text\n\n    # A list of python regular expression patterns which are used to include files\n    # during the directory walk. They are matched against relative paths of files\n    # (relative to the root of the search). They are not matched against\n    # directories. The default is `[\".*\\.py\"]`.\n    include_patterns = ['.*\\\\.py']\n\n    # A list of python regular expression patterns which are used to exclude files\n    # during the directory walk. They are matched against relative paths of files\n    # (relative to the root of the search). If the pattern matches a directory the\n    # whole directory is skipped. If it matches an individual file then that file is\n    # skipped.\n    exclude_patterns = []\n\n    # The root of the search tree for inclusion.\n    source_tree = None\n\n    # The root of the tree where the outputs are written.\n    target_tree = None\n\n    # A list of tools to execute. The default is [\"pylint\", \"flake8\"]. This can\n    # either be a string (a simple command which takes one argument), or it can be\n    # an object with a get_stamp() and an execute() method. See SimpleTool for ane\n    # example.\n    tools = ['flake8', 'pylint']\n\n    # A dictionary specifying the environment to use for the tools. Add your\n    # virtualenv configurations here.\n    env = {\n      \"LANG\": \"en_US.UTF-8\",\n      \"LANGUAGE\": \"en_US\",\n      \"PATH\": [\n        \"/usr/local/sbin\",\n        \"/usr/local/bin\",\n        \"/usr/sbin\",\n        \"/usr/bin\",\n        \"/sbin\",\n        \"/bin\"\n      ]\n    }\n\n    # If true, exit on the first failure, don't keep going. Useful if you want a\n    # speedy CI gate.\n    fail_fast = False\n\n    # If specified, output logs for failed jobs will be merged into a single file\n    # at this location. Useful if you have a large number of issues to del with.\n    merged_log = None\n\n    # Don't print fancy progress bars to stdout.\n    quiet = False\n\n    # Number of parallel jobs to execute.\n    jobs = 12  # multiprocessing.cpu_count()\n\n\n.. dynamic: config-end\n\n------\nDesign\n------\n\n.. dynamic: design-begin\n\nDiscovery/Indexing\n==================\n\nThe first phase is discovery and indexing. This is done at build time, rather\nthan configure-time, because, let's face it, your build system already suffers\nfrom enough configure time bloat. Also, as mentioned above, this supports an\nopt-out system.\n\nThe discovery step performs a filesystem walk in order to build up an index\nof files to be checked. You can use a configuration file or command line\noptions to setup inclusion and exclusion filters for the discovery process.\nIn general, though, each directory that is scanned produces a list of files to\nlint. If the timestamp of a tracked directory changes, it is rescanned for new\nfiles, or new directories.\n\nThe output of the discovery phase is a manifest file per-directory tracked.\nThe creation of this manifest depends on the modification time of the directory\nit corresponds to and will be re-built if the directory is changed. If a new\nsubdirectory is added, the system will recursively index that new directory.\nIf a directory is removed, it will recursively purge that directory from the\nmanifest index.\n\nContent Digest\n==============\n\nThe second phase is content summary and digest creation. The sha1 of each\ntracked file is computed and stored in a digest file (one per source file).\nThe digest file depends on the modification time of the source file.\n\nDependency Inference\n====================\n\nThe third phase is dependency inference. During this phase each tracked\nsource file is indexed to get a complete dependency footprint. Note that this\nis done by importing each module file in a clean interpreter process, and\nthen inspecting the ``__file__`` attribute of all modules loaded by\ninterpreter. Note that this has a couple of implications:\n\n* Dynamically loaded modules may not be discovered as dependencies\n* Any import work will increase the runtime of this phase\n\nThe outputs for this phase is a dependency manifest: one per source file. The\nmanifest contains a list of files that are dependencies. The dependencies of\nthis manifest are the modification times of the digest sidecar file for\neach of the  source file itself, as well as all of it's dependencies. If any of\nthese digest files are modified, the manifest is rebuilt. There is a fastpath,\nhowever, in that if none of the digests themselves have changed the manifest\nmodification time is updated but the dependency scan is skipped.\n\nExecuting tools\n===============\n\nOnce the depency footprints are updated we can finally start executing the\nactual tools. There are two outputs of a tool execution : a stampfile\n(one per source file) and a logfile. The stampfile is skipped on failure and\nthe logfile is removed on success.\n\n.. dynamic: design-end\n\n\n", "description_content_type": "", "docs_url": null, "download_url": "https://github.com/cheshirekow/makelint/archive/0.1.0.tar.gz", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/cheshirekow/makelint", "keywords": "lint,static-analysis,code-checker", "license": "", "maintainer": "", "maintainer_email": "", "name": "makelint", "package_url": "https://pypi.org/project/makelint/", "platform": "", "project_url": "https://pypi.org/project/makelint/", "project_urls": {"Download": "https://github.com/cheshirekow/makelint/archive/0.1.0.tar.gz", "Homepage": "https://github.com/cheshirekow/makelint"}, "release_url": "https://pypi.org/project/makelint/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "A highly-compatible \"build\" system for linting python files.", "version": "0.1.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p>A highly-compatible \u201cbuild\u201d system for linting python files.</p>\n<div id=\"purpose\">\n<h2>Purpose</h2>\n<p>The purpose of this program is to lint/check your python code. Why do you\nneed specialized software to do this?</p>\n<ol>\n<li>Python static analysis tools (<tt>pylint</tt>, <tt>flake8</tt>, etc) are slow. If you\nhave more than a couple dozen files then linting every file can take quite\na long time.</li>\n<li>These tools generally load the module to understand what the python code\nis doing. This means that the checker depends not just on the file you\u2019re\nchecking, but the full transitive closure of it\u2019s dependencies</li>\n</ol>\n<p>This program maintains a database of dependencies so that you can be confident\nthat a particular lint check is still valid. You can know for certain not just\nthat a particular file hasn\u2019t changed, but also none of the files it depends on\nhas changed. This allows you to skip re-checking unchanged files.</p>\n<p>It is the intent of this project to (eventually) support standard build-systems\nlike <tt>make</tt> or <tt>ninja</tt>, but it also implements a self-contained solution.\nIn particular it allows an \u201copt-out\u201d workflow (rather than an opt-in) meaning\ntwo things:</p>\n<ol>\n<li>You don\u2019t need to re-run configure (or cmake) when you add new files\n(and, lets face it, you are probably suffering from some configure\nbloat, aren\u2019t you).</li>\n<li>When new python is added to the code base, it is automatically included\nfor checking. A human being must make an explicit decision to exclude it.\nDevelopers cannot \u201cforget\u201d to add it to the build system for linting.</li>\n</ol>\n</div>\n<div id=\"usage\">\n<h2>Usage</h2>\n<pre>usage:\npymakelint [-h] [-v] [-l {debug,info,warning,error}] [--dump-config]\n           [-c CONFIG_FILE] [&lt;config-overrides&gt; [...]]\n\nIncremental execution system for python code analysis (linting).\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  -l {debug,info,warning,error}, --log-level {debug,info,warning,error}\n  --dump-config         If specified, print the default configuration to\n                        stdout and exit\n  -c CONFIG_FILE, --config-file CONFIG_FILE\n                        path to configuration file\n\nConfiguration:\n  Override configfile options\n\n  --include-patterns [INCLUDE_PATTERNS [INCLUDE_PATTERNS ...]]\n                        A list of python regular expression patterns which are\n                        used to include files during the directory walk. They\n                        are matched against relative paths of files (relative\n                        to the root of the search). They are not matched\n                        against directories. The default is `[\".*\\.py\"]`.\n  --exclude-patterns [EXCLUDE_PATTERNS [EXCLUDE_PATTERNS ...]]\n                        A list of python regular expression patterns which are\n                        used to exclude files during the directory walk. They\n                        are matched against relative paths of files (relative\n                        to the root of the search). If the pattern matches a\n                        directory the whole directory is skipped. If it\n                        matches an individual file then that file is skipped.\n  --source-tree SOURCE_TREE\n                        The root of the search tree for inclusion.\n  --target-tree TARGET_TREE\n                        The root of the tree where the outputs are written.\n  --tools [TOOLS [TOOLS ...]]\n                        A list of tools to execute. The default is [\"pylint\",\n                        \"flake8\"]. This can either be a string (a simple\n                        command which takes one argument), or it can be an\n                        object with a get_stamp() and an execute() method. See\n                        SimpleTool for ane example.\n  --fail-fast [FAIL_FAST]\n                        If true, exit on the first failure, don't keep going.\n                        Useful if you want a speedy CI gate.\n  --merged-log MERGED_LOG\n                        If specified, output logs for failed jobs will be\n                        merged into a single file at this location. Useful if\n                        you have a large number of issues to del with.\n  --quiet [QUIET]       Don't print fancy progress bars to stdout.\n  --jobs JOBS           Number of parallel jobs to execute.\n</pre>\n</div>\n<div id=\"configuration\">\n<h2>Configuration</h2>\n<p>Most command line options can also be specified in a configuration file.\nConfiguration files are python files. If not specified on the command line,\nthe tool will automatically look for and load the configuration file at\n<tt><span class=\"pre\">&lt;source_tree&gt;/.makelint.py</span></tt>.</p>\n<p>You can use <tt><span class=\"pre\">--dump-config</span></tt> to dump the default configuration to a file and\nuse that as a starting point. The default config is also pasted below.</p>\n<pre># A list of python regular expression patterns which are used to include files\n# during the directory walk. They are matched against relative paths of files\n# (relative to the root of the search). They are not matched against\n# directories. The default is `[\".*\\.py\"]`.\ninclude_patterns = ['.*\\\\.py']\n\n# A list of python regular expression patterns which are used to exclude files\n# during the directory walk. They are matched against relative paths of files\n# (relative to the root of the search). If the pattern matches a directory the\n# whole directory is skipped. If it matches an individual file then that file is\n# skipped.\nexclude_patterns = []\n\n# The root of the search tree for inclusion.\nsource_tree = None\n\n# The root of the tree where the outputs are written.\ntarget_tree = None\n\n# A list of tools to execute. The default is [\"pylint\", \"flake8\"]. This can\n# either be a string (a simple command which takes one argument), or it can be\n# an object with a get_stamp() and an execute() method. See SimpleTool for ane\n# example.\ntools = ['flake8', 'pylint']\n\n# A dictionary specifying the environment to use for the tools. Add your\n# virtualenv configurations here.\nenv = {\n  \"LANG\": \"en_US.UTF-8\",\n  \"LANGUAGE\": \"en_US\",\n  \"PATH\": [\n    \"/usr/local/sbin\",\n    \"/usr/local/bin\",\n    \"/usr/sbin\",\n    \"/usr/bin\",\n    \"/sbin\",\n    \"/bin\"\n  ]\n}\n\n# If true, exit on the first failure, don't keep going. Useful if you want a\n# speedy CI gate.\nfail_fast = False\n\n# If specified, output logs for failed jobs will be merged into a single file\n# at this location. Useful if you have a large number of issues to del with.\nmerged_log = None\n\n# Don't print fancy progress bars to stdout.\nquiet = False\n\n# Number of parallel jobs to execute.\njobs = 12  # multiprocessing.cpu_count()\n</pre>\n</div>\n<div id=\"design\">\n<h2>Design</h2>\n<div id=\"discovery-indexing\">\n<h3>Discovery/Indexing</h3>\n<p>The first phase is discovery and indexing. This is done at build time, rather\nthan configure-time, because, let\u2019s face it, your build system already suffers\nfrom enough configure time bloat. Also, as mentioned above, this supports an\nopt-out system.</p>\n<p>The discovery step performs a filesystem walk in order to build up an index\nof files to be checked. You can use a configuration file or command line\noptions to setup inclusion and exclusion filters for the discovery process.\nIn general, though, each directory that is scanned produces a list of files to\nlint. If the timestamp of a tracked directory changes, it is rescanned for new\nfiles, or new directories.</p>\n<p>The output of the discovery phase is a manifest file per-directory tracked.\nThe creation of this manifest depends on the modification time of the directory\nit corresponds to and will be re-built if the directory is changed. If a new\nsubdirectory is added, the system will recursively index that new directory.\nIf a directory is removed, it will recursively purge that directory from the\nmanifest index.</p>\n</div>\n<div id=\"content-digest\">\n<h3>Content Digest</h3>\n<p>The second phase is content summary and digest creation. The sha1 of each\ntracked file is computed and stored in a digest file (one per source file).\nThe digest file depends on the modification time of the source file.</p>\n</div>\n<div id=\"dependency-inference\">\n<h3>Dependency Inference</h3>\n<p>The third phase is dependency inference. During this phase each tracked\nsource file is indexed to get a complete dependency footprint. Note that this\nis done by importing each module file in a clean interpreter process, and\nthen inspecting the <tt>__file__</tt> attribute of all modules loaded by\ninterpreter. Note that this has a couple of implications:</p>\n<ul>\n<li>Dynamically loaded modules may not be discovered as dependencies</li>\n<li>Any import work will increase the runtime of this phase</li>\n</ul>\n<p>The outputs for this phase is a dependency manifest: one per source file. The\nmanifest contains a list of files that are dependencies. The dependencies of\nthis manifest are the modification times of the digest sidecar file for\neach of the  source file itself, as well as all of it\u2019s dependencies. If any of\nthese digest files are modified, the manifest is rebuilt. There is a fastpath,\nhowever, in that if none of the digests themselves have changed the manifest\nmodification time is updated but the dependency scan is skipped.</p>\n</div>\n<div id=\"executing-tools\">\n<h3>Executing tools</h3>\n<p>Once the depency footprints are updated we can finally start executing the\nactual tools. There are two outputs of a tool execution : a stampfile\n(one per source file) and a logfile. The stampfile is skipped on failure and\nthe logfile is removed on success.</p>\n</div>\n</div>\n\n          </div>"}, "last_serial": 5293523, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "90631d2245d28499a882998df53dd698", "sha256": "82a88c286f751ab868f5aa1f77a9fece19a18380d2b4c9c6e8b3ec158bc68ad3"}, "downloads": -1, "filename": "makelint-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "90631d2245d28499a882998df53dd698", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28096, "upload_time": "2019-05-20T17:53:19", "upload_time_iso_8601": "2019-05-20T17:53:19.187469Z", "url": "https://files.pythonhosted.org/packages/b5/82/2ac4873d8e5b76970acc55011291ba0638a7993ec5ce4d5ede56922986e7/makelint-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "16ea500231e981e83cec004fda3626c3", "sha256": "bcd5673f9945c741ed47259e0ca2eff1b1a53464810ed50bd51fca89b11d04d2"}, "downloads": -1, "filename": "makelint-0.1.0.tar.gz", "has_sig": false, "md5_digest": "16ea500231e981e83cec004fda3626c3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14351, "upload_time": "2019-05-20T17:53:21", "upload_time_iso_8601": "2019-05-20T17:53:21.432311Z", "url": "https://files.pythonhosted.org/packages/c9/fe/9bcf7a2630d6f5e7efd0af25a8298cbea4ba268dab4b2010d55c979c2db8/makelint-0.1.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "90631d2245d28499a882998df53dd698", "sha256": "82a88c286f751ab868f5aa1f77a9fece19a18380d2b4c9c6e8b3ec158bc68ad3"}, "downloads": -1, "filename": "makelint-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "90631d2245d28499a882998df53dd698", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 28096, "upload_time": "2019-05-20T17:53:19", "upload_time_iso_8601": "2019-05-20T17:53:19.187469Z", "url": "https://files.pythonhosted.org/packages/b5/82/2ac4873d8e5b76970acc55011291ba0638a7993ec5ce4d5ede56922986e7/makelint-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "16ea500231e981e83cec004fda3626c3", "sha256": "bcd5673f9945c741ed47259e0ca2eff1b1a53464810ed50bd51fca89b11d04d2"}, "downloads": -1, "filename": "makelint-0.1.0.tar.gz", "has_sig": false, "md5_digest": "16ea500231e981e83cec004fda3626c3", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 14351, "upload_time": "2019-05-20T17:53:21", "upload_time_iso_8601": "2019-05-20T17:53:21.432311Z", "url": "https://files.pythonhosted.org/packages/c9/fe/9bcf7a2630d6f5e7efd0af25a8298cbea4ba268dab4b2010d55c979c2db8/makelint-0.1.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:41:49 2020"}