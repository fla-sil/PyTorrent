{"info": {"author": "Long Chen", "author_email": "looooong.chen@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# tfAugmentor\nAn image augmentation library for tensorflow. The libray is designed to be easily used with tf.data.Dataset. The augmentor accepts tf.data.Dataset object or a nested tuple of numpy array. \n\n## new features\n- support tf 2.x\n- API change for easier use, can directly process tf.data.Dataset object\n\n## Installation\ntfAugmentor is written in Python and can be easily installed via:\n```python\npip install tfAugmentor\n```\nTo run tfAugmentor properly, the following library should be installed as well:\n- tensorflow (developed under tf 2.1), should work with 2.x version, 1.x version is not supported\n- tensorflow-addons\n- numpy (developed under numpy 1.18)\n- tensorflow-probability (optional)\n\n## Quick Start\ntfAugmentor is implemented to work seamlessly with tf.data. The tf.data.Dataset object can be directly processed by tfAugmentor. But you can also use it independently as a off-line augmentation tool.\n\nTo instantiate an `Augmentor` object, three arguments are required:\n\n```python\nclass Augmentor(object):\n    def __init__(self, signature, image=[], label=[]):\n\t\t...\n```\n\n- signature: a nested tuple of string, representing the structure of the dataset to be processesd e.g. ('image', 'segmentation')\n- image, label: only the items in these two lists will be augmented, segmentation masks should be put in the label list so that the labels will kept valid\n\n### simple example\n```python\nimport tfAugmentor as tfaug\n\n# new tfAugmentor object\naug = tfaug.Augmentor(('image', 'semantic_mask'), image=['image'], label=['semantic_mask'])\n\n# add augumentation operations\naug.flip_left_right(probability=0.5)\naug.rotate90(probability=0.5)\naug.elastic_deform(strength=2, scale=20, probability=1)\n\n# assume we have three numpy arrays\nX_image = ... # shape [batch, height, width, channel]\nY_semantic_mask = ... # shape [batch, height, width, 1]\n\n# create tf.data.Dataset object\ntf_dataset = tf.data.Dataset.from_tensor_slices((X_image, Y_semantic_mask)))\n# do the actual augmentation\nds1 = aug(tf_dataset, keep_size=True)\n\n# or you can directly pass the numpy arrays, a tf.data.Dataset object will be returned \nds2 = aug((X_image, Y_semantic_mask)), keep_size=True)\n```\n\nIf you pass the data as a python dictionary, the signature is not necessary any more. For example:\n\n```python\nimport tfAugmentor as tfaug\n\n# new tfAugmentor object\naug = tfaug.Augmentor(image=['image'], label=['semantic_mask'])\n\n# add augumentation operations\naug.flip_left_right(probability=0.5)\naug.rotate90(probability=0.5)\naug.elastic_deform(strength=2, scale=20, probability=1)\n\n# assume we have three numpy arrays\nX_image = ... # shape [batch, height, width, channel]\nY_semantic_mask = ... # shape [batch, height, width, 1]\n\nds_dict = {'image': X_image,\n           'semantic_mask': Y_semantic_mask}\n# create tf.data.Dataset object\ntf_dataset = tf.data.Dataset.from_tensor_slices(ds_dict)\n# do the actual augmentation\nds1 = aug(tf_dataset, keep_size=True)\n\n# or directly pass the data\nds2 = aug(ds_dict, keep_size=True)\n```\n\n\nNote:\n- All added augmentations will be executed one by one, but you can create multiply tfAugmentor to relize different augmentations in parallel\n- all data should have a 4-D shape of `[batch, height, width, channels]` with the first dimension being the same, unprocessed items (itmes not in the 'image' or 'label' list) can have any dataset shape  \n\n### complex example\n\n```python\nimport tfAugmentor as tfaug\n\n# since 'class' is neither in 'image' nor in 'label', it will not be touched \naug1 = tfaug.Augmentor((('image_rgb', 'image_depth'), ('semantic_mask', 'class')), image=['image_rgb', 'image_depth'], label=['semantic_mask'])\naug1 = tfaug.Augmentor((('image_rgb', 'image_depth'), ('semantic_mask', 'class')), image=['image_rgb', 'image_depth'], label=['semantic_mask'])\n\n# add different augumentation operations to aug1 and aug2 \naug1.flip_left_right(probability=0.5)\naug1.random_crop_resize(sacle_range=(0.7, 0.9), probability=0.5)\naug2.elastic_deform(strength=2, scale=20, probability=1)\n\n# assume we have the 1000 data samples\nX_rgb = ...  # shape [1000 x 512 x 512 x 3]\nX_depth = ... # shape [1000 x 512 x 512 x 1]\nY_semantic_mask = ... # shape [1000 x 512 x 512 x 1]\nY_class = ... # shape [1000 x 1]\n\n# create tf.data.Dataset object\nds_origin = tf.data.Dataset.from_tensor_slices(((X_rgb, X_depth), (Y_semantic_mask, Y_class))))\n# do the actual augmentation\nds1 = aug1(ds_origin, keep_size=True)\nds2 = aug2(ds_origin, keep_size=True)\n# combine them\nds = ds_origin.concatenate(ds1)\nds = ds.concatenate(ds1)\n\n```\n\n## Main Features\n\n### Mirroring\n```python\naug.flip_left_right(probability) # flip the image left right  \naug.flip_up_down(probability) # flip the image up down\n```\n### Rotating\n```python\na.rotate90(probability) # rotate by 90 degree clockwise\na.rotate180(probability) # rotate by 180 degree clockwise\na.rotate270(probability) # rotate by 270 degree clockwise\na.rotate(angle, probability) # rotate by *angel* degree clockwise\na.random_rotate(probability) # randomly rotate the image\n```\n### crop and resize\n```python\na.random_crop_resize(scale_range=(0.5, 0.8), probability) # randomly crop a sub-image and resize to the same size of the original image\na.random_crop_resize(scale_range=0.8, probability) # fixed crop size, random crop position\n```\n\n### elastic deformation\n```\na.elastic_deform(strength, scale, probability)\n```", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/looooongChen/tfAugmentor", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "tfAugmentor", "package_url": "https://pypi.org/project/tfAugmentor/", "platform": "", "project_url": "https://pypi.org/project/tfAugmentor/", "project_urls": {"Homepage": "https://github.com/looooongChen/tfAugmentor"}, "release_url": "https://pypi.org/project/tfAugmentor/1.2.1/", "requires_dist": null, "requires_python": "", "summary": "An image augmentation library for tensorflow. Easy use with tf.data.Dataset", "version": "1.2.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>tfAugmentor</h1>\n<p>An image augmentation library for tensorflow. The libray is designed to be easily used with tf.data.Dataset. The augmentor accepts tf.data.Dataset object or a nested tuple of numpy array.</p>\n<h2>new features</h2>\n<ul>\n<li>support tf 2.x</li>\n<li>API change for easier use, can directly process tf.data.Dataset object</li>\n</ul>\n<h2>Installation</h2>\n<p>tfAugmentor is written in Python and can be easily installed via:</p>\n<pre><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">tfAugmentor</span>\n</pre>\n<p>To run tfAugmentor properly, the following library should be installed as well:</p>\n<ul>\n<li>tensorflow (developed under tf 2.1), should work with 2.x version, 1.x version is not supported</li>\n<li>tensorflow-addons</li>\n<li>numpy (developed under numpy 1.18)</li>\n<li>tensorflow-probability (optional)</li>\n</ul>\n<h2>Quick Start</h2>\n<p>tfAugmentor is implemented to work seamlessly with tf.data. The tf.data.Dataset object can be directly processed by tfAugmentor. But you can also use it independently as a off-line augmentation tool.</p>\n<p>To instantiate an <code>Augmentor</code> object, three arguments are required:</p>\n<pre><span class=\"k\">class</span> <span class=\"nc\">Augmentor</span><span class=\"p\">(</span><span class=\"nb\">object</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">signature</span><span class=\"p\">,</span> <span class=\"n\">image</span><span class=\"o\">=</span><span class=\"p\">[],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"p\">[]):</span>\n\t\t<span class=\"o\">...</span>\n</pre>\n<ul>\n<li>signature: a nested tuple of string, representing the structure of the dataset to be processesd e.g. ('image', 'segmentation')</li>\n<li>image, label: only the items in these two lists will be augmented, segmentation masks should be put in the label list so that the labels will kept valid</li>\n</ul>\n<h3>simple example</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">tfAugmentor</span> <span class=\"k\">as</span> <span class=\"nn\">tfaug</span>\n\n<span class=\"c1\"># new tfAugmentor object</span>\n<span class=\"n\">aug</span> <span class=\"o\">=</span> <span class=\"n\">tfaug</span><span class=\"o\">.</span><span class=\"n\">Augmentor</span><span class=\"p\">((</span><span class=\"s1\">'image'</span><span class=\"p\">,</span> <span class=\"s1\">'semantic_mask'</span><span class=\"p\">),</span> <span class=\"n\">image</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'image'</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'semantic_mask'</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># add augumentation operations</span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">flip_left_right</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">rotate90</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">elastic_deform</span><span class=\"p\">(</span><span class=\"n\">strength</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># assume we have three numpy arrays</span>\n<span class=\"n\">X_image</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [batch, height, width, channel]</span>\n<span class=\"n\">Y_semantic_mask</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [batch, height, width, 1]</span>\n\n<span class=\"c1\"># create tf.data.Dataset object</span>\n<span class=\"n\">tf_dataset</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">((</span><span class=\"n\">X_image</span><span class=\"p\">,</span> <span class=\"n\">Y_semantic_mask</span><span class=\"p\">)))</span>\n<span class=\"c1\"># do the actual augmentation</span>\n<span class=\"n\">ds1</span> <span class=\"o\">=</span> <span class=\"n\">aug</span><span class=\"p\">(</span><span class=\"n\">tf_dataset</span><span class=\"p\">,</span> <span class=\"n\">keep_size</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># or you can directly pass the numpy arrays, a tf.data.Dataset object will be returned </span>\n<span class=\"n\">ds2</span> <span class=\"o\">=</span> <span class=\"n\">aug</span><span class=\"p\">((</span><span class=\"n\">X_image</span><span class=\"p\">,</span> <span class=\"n\">Y_semantic_mask</span><span class=\"p\">)),</span> <span class=\"n\">keep_size</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>If you pass the data as a python dictionary, the signature is not necessary any more. For example:</p>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">tfAugmentor</span> <span class=\"k\">as</span> <span class=\"nn\">tfaug</span>\n\n<span class=\"c1\"># new tfAugmentor object</span>\n<span class=\"n\">aug</span> <span class=\"o\">=</span> <span class=\"n\">tfaug</span><span class=\"o\">.</span><span class=\"n\">Augmentor</span><span class=\"p\">(</span><span class=\"n\">image</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'image'</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'semantic_mask'</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># add augumentation operations</span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">flip_left_right</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">rotate90</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">elastic_deform</span><span class=\"p\">(</span><span class=\"n\">strength</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># assume we have three numpy arrays</span>\n<span class=\"n\">X_image</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [batch, height, width, channel]</span>\n<span class=\"n\">Y_semantic_mask</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [batch, height, width, 1]</span>\n\n<span class=\"n\">ds_dict</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s1\">'image'</span><span class=\"p\">:</span> <span class=\"n\">X_image</span><span class=\"p\">,</span>\n           <span class=\"s1\">'semantic_mask'</span><span class=\"p\">:</span> <span class=\"n\">Y_semantic_mask</span><span class=\"p\">}</span>\n<span class=\"c1\"># create tf.data.Dataset object</span>\n<span class=\"n\">tf_dataset</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">(</span><span class=\"n\">ds_dict</span><span class=\"p\">)</span>\n<span class=\"c1\"># do the actual augmentation</span>\n<span class=\"n\">ds1</span> <span class=\"o\">=</span> <span class=\"n\">aug</span><span class=\"p\">(</span><span class=\"n\">tf_dataset</span><span class=\"p\">,</span> <span class=\"n\">keep_size</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># or directly pass the data</span>\n<span class=\"n\">ds2</span> <span class=\"o\">=</span> <span class=\"n\">aug</span><span class=\"p\">(</span><span class=\"n\">ds_dict</span><span class=\"p\">,</span> <span class=\"n\">keep_size</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n</pre>\n<p>Note:</p>\n<ul>\n<li>All added augmentations will be executed one by one, but you can create multiply tfAugmentor to relize different augmentations in parallel</li>\n<li>all data should have a 4-D shape of <code>[batch, height, width, channels]</code> with the first dimension being the same, unprocessed items (itmes not in the 'image' or 'label' list) can have any dataset shape</li>\n</ul>\n<h3>complex example</h3>\n<pre><span class=\"kn\">import</span> <span class=\"nn\">tfAugmentor</span> <span class=\"k\">as</span> <span class=\"nn\">tfaug</span>\n\n<span class=\"c1\"># since 'class' is neither in 'image' nor in 'label', it will not be touched </span>\n<span class=\"n\">aug1</span> <span class=\"o\">=</span> <span class=\"n\">tfaug</span><span class=\"o\">.</span><span class=\"n\">Augmentor</span><span class=\"p\">(((</span><span class=\"s1\">'image_rgb'</span><span class=\"p\">,</span> <span class=\"s1\">'image_depth'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'semantic_mask'</span><span class=\"p\">,</span> <span class=\"s1\">'class'</span><span class=\"p\">)),</span> <span class=\"n\">image</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'image_rgb'</span><span class=\"p\">,</span> <span class=\"s1\">'image_depth'</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'semantic_mask'</span><span class=\"p\">])</span>\n<span class=\"n\">aug1</span> <span class=\"o\">=</span> <span class=\"n\">tfaug</span><span class=\"o\">.</span><span class=\"n\">Augmentor</span><span class=\"p\">(((</span><span class=\"s1\">'image_rgb'</span><span class=\"p\">,</span> <span class=\"s1\">'image_depth'</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"s1\">'semantic_mask'</span><span class=\"p\">,</span> <span class=\"s1\">'class'</span><span class=\"p\">)),</span> <span class=\"n\">image</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'image_rgb'</span><span class=\"p\">,</span> <span class=\"s1\">'image_depth'</span><span class=\"p\">],</span> <span class=\"n\">label</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'semantic_mask'</span><span class=\"p\">])</span>\n\n<span class=\"c1\"># add different augumentation operations to aug1 and aug2 </span>\n<span class=\"n\">aug1</span><span class=\"o\">.</span><span class=\"n\">flip_left_right</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">aug1</span><span class=\"o\">.</span><span class=\"n\">random_crop_resize</span><span class=\"p\">(</span><span class=\"n\">sacle_range</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mf\">0.7</span><span class=\"p\">,</span> <span class=\"mf\">0.9</span><span class=\"p\">),</span> <span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>\n<span class=\"n\">aug2</span><span class=\"o\">.</span><span class=\"n\">elastic_deform</span><span class=\"p\">(</span><span class=\"n\">strength</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">scale</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"n\">probability</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># assume we have the 1000 data samples</span>\n<span class=\"n\">X_rgb</span> <span class=\"o\">=</span> <span class=\"o\">...</span>  <span class=\"c1\"># shape [1000 x 512 x 512 x 3]</span>\n<span class=\"n\">X_depth</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [1000 x 512 x 512 x 1]</span>\n<span class=\"n\">Y_semantic_mask</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [1000 x 512 x 512 x 1]</span>\n<span class=\"n\">Y_class</span> <span class=\"o\">=</span> <span class=\"o\">...</span> <span class=\"c1\"># shape [1000 x 1]</span>\n\n<span class=\"c1\"># create tf.data.Dataset object</span>\n<span class=\"n\">ds_origin</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">Dataset</span><span class=\"o\">.</span><span class=\"n\">from_tensor_slices</span><span class=\"p\">(((</span><span class=\"n\">X_rgb</span><span class=\"p\">,</span> <span class=\"n\">X_depth</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"n\">Y_semantic_mask</span><span class=\"p\">,</span> <span class=\"n\">Y_class</span><span class=\"p\">))))</span>\n<span class=\"c1\"># do the actual augmentation</span>\n<span class=\"n\">ds1</span> <span class=\"o\">=</span> <span class=\"n\">aug1</span><span class=\"p\">(</span><span class=\"n\">ds_origin</span><span class=\"p\">,</span> <span class=\"n\">keep_size</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"n\">ds2</span> <span class=\"o\">=</span> <span class=\"n\">aug2</span><span class=\"p\">(</span><span class=\"n\">ds_origin</span><span class=\"p\">,</span> <span class=\"n\">keep_size</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"c1\"># combine them</span>\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">ds_origin</span><span class=\"o\">.</span><span class=\"n\">concatenate</span><span class=\"p\">(</span><span class=\"n\">ds1</span><span class=\"p\">)</span>\n<span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">ds</span><span class=\"o\">.</span><span class=\"n\">concatenate</span><span class=\"p\">(</span><span class=\"n\">ds1</span><span class=\"p\">)</span>\n</pre>\n<h2>Main Features</h2>\n<h3>Mirroring</h3>\n<pre><span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">flip_left_right</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># flip the image left right  </span>\n<span class=\"n\">aug</span><span class=\"o\">.</span><span class=\"n\">flip_up_down</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># flip the image up down</span>\n</pre>\n<h3>Rotating</h3>\n<pre><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">rotate90</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># rotate by 90 degree clockwise</span>\n<span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">rotate180</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># rotate by 180 degree clockwise</span>\n<span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">rotate270</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># rotate by 270 degree clockwise</span>\n<span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">rotate</span><span class=\"p\">(</span><span class=\"n\">angle</span><span class=\"p\">,</span> <span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># rotate by *angel* degree clockwise</span>\n<span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">random_rotate</span><span class=\"p\">(</span><span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># randomly rotate the image</span>\n</pre>\n<h3>crop and resize</h3>\n<pre><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">random_crop_resize</span><span class=\"p\">(</span><span class=\"n\">scale_range</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mf\">0.5</span><span class=\"p\">,</span> <span class=\"mf\">0.8</span><span class=\"p\">),</span> <span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># randomly crop a sub-image and resize to the same size of the original image</span>\n<span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">random_crop_resize</span><span class=\"p\">(</span><span class=\"n\">scale_range</span><span class=\"o\">=</span><span class=\"mf\">0.8</span><span class=\"p\">,</span> <span class=\"n\">probability</span><span class=\"p\">)</span> <span class=\"c1\"># fixed crop size, random crop position</span>\n</pre>\n<h3>elastic deformation</h3>\n<pre><code>a.elastic_deform(strength, scale, probability)\n</code></pre>\n\n          </div>"}, "last_serial": 7021878, "releases": {"1.0.2": [{"comment_text": "", "digests": {"md5": "f19355e919b604a10ff75360a59608ac", "sha256": "fbba479ea990a93a0f0984dea49915e358055a571ee37b4eb3e89115ad4182f0"}, "downloads": -1, "filename": "tfAugmentor-1.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "f19355e919b604a10ff75360a59608ac", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 7982, "upload_time": "2019-05-19T00:12:50", "upload_time_iso_8601": "2019-05-19T00:12:50.728343Z", "url": "https://files.pythonhosted.org/packages/4c/82/f4b80821d6eccead5c772d42b363257f6f59112326c5bc471370b0fe49db/tfAugmentor-1.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "ba1ab1d2a9e7381e19ad0efa2464947c", "sha256": "acfa4a022263e81cdff76fe227ed4ecb5aed95f44ee64a26a8e20d77b7ac573b"}, "downloads": -1, "filename": "tfAugmentor-1.0.2.tar.gz", "has_sig": false, "md5_digest": "ba1ab1d2a9e7381e19ad0efa2464947c", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 7161, "upload_time": "2019-05-19T00:12:52", "upload_time_iso_8601": "2019-05-19T00:12:52.125453Z", "url": "https://files.pythonhosted.org/packages/60/f9/dd2484a630a441135b7bdd0886aaa25dd355fea0df731d69f879932c55d8/tfAugmentor-1.0.2.tar.gz", "yanked": false}], "1.1.1": [{"comment_text": "", "digests": {"md5": "c92d6e3cbe8f6865a38a37149ec70387", "sha256": "acfb67c3406cc69249f1cd64eeec343776c055d7d9fd380c386dd859139aec42"}, "downloads": -1, "filename": "tfAugmentor-1.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c92d6e3cbe8f6865a38a37149ec70387", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8924, "upload_time": "2020-04-14T04:25:11", "upload_time_iso_8601": "2020-04-14T04:25:11.261268Z", "url": "https://files.pythonhosted.org/packages/8a/e9/3e4ec43fbfceb9df0214f1c4be025e68ee20a3acb9d7a81ee2ac16b3d33a/tfAugmentor-1.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b23d5e86b03ad9fb5dbb9407a3f91769", "sha256": "761bf080212ef82c6c15e6b3362655e991f1c28c32418f5a86bb210953b0e54e"}, "downloads": -1, "filename": "tfAugmentor-1.1.1.tar.gz", "has_sig": false, "md5_digest": "b23d5e86b03ad9fb5dbb9407a3f91769", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 8177, "upload_time": "2020-04-14T04:25:12", "upload_time_iso_8601": "2020-04-14T04:25:12.685459Z", "url": "https://files.pythonhosted.org/packages/53/9d/a0ef3ac1715fffb8861f6632cb19a18439ea62d5d0bcc291a505dbf50885/tfAugmentor-1.1.1.tar.gz", "yanked": false}], "1.1.2": [{"comment_text": "", "digests": {"md5": "0b86e380f13cdebe88f8c867090999f8", "sha256": "400956e0b662963a5e7dab0414c9dd2d35e5299a2b660f6627bfd4f69e95fbc9"}, "downloads": -1, "filename": "tfAugmentor-1.1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "0b86e380f13cdebe88f8c867090999f8", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9067, "upload_time": "2020-04-14T23:53:11", "upload_time_iso_8601": "2020-04-14T23:53:11.669827Z", "url": "https://files.pythonhosted.org/packages/d7/b5/f735735e3ccb0c865c8f81ea3737618fd81bff597f7863aee3568e8e342d/tfAugmentor-1.1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "865e553f0ae8bc355e3b24b7e95b524b", "sha256": "b94195f067adc21de9989ff7500c9709020d8ef0581fa2d859c10e8f34127bf3"}, "downloads": -1, "filename": "tfAugmentor-1.1.2.tar.gz", "has_sig": false, "md5_digest": "865e553f0ae8bc355e3b24b7e95b524b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9147, "upload_time": "2020-04-14T23:53:13", "upload_time_iso_8601": "2020-04-14T23:53:13.155189Z", "url": "https://files.pythonhosted.org/packages/df/f8/259cd519f15cbbfd6bbcb323a0ee718b79b1189201a1b7a9fa72584833c5/tfAugmentor-1.1.2.tar.gz", "yanked": false}], "1.2": [{"comment_text": "", "digests": {"md5": "3321b7acbc73d3a25653870e6d01a898", "sha256": "e7abda1531acc194ac305715264f0ee44ae48b373c11dd9ca6557c7003e0283c"}, "downloads": -1, "filename": "tfAugmentor-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "3321b7acbc73d3a25653870e6d01a898", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9090, "upload_time": "2020-04-15T01:48:57", "upload_time_iso_8601": "2020-04-15T01:48:57.975620Z", "url": "https://files.pythonhosted.org/packages/65/10/043bc5cb46838f9134132375977c0a8786f81d1c1f3242d675a016e322ce/tfAugmentor-1.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "989cea23c522c4dd01b65780e8176a09", "sha256": "fded76c40623c3b8e4797c1ef98a5207cf5d0abc7626a9c387d1d26940bd8244"}, "downloads": -1, "filename": "tfAugmentor-1.2.tar.gz", "has_sig": false, "md5_digest": "989cea23c522c4dd01b65780e8176a09", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9289, "upload_time": "2020-04-15T01:48:59", "upload_time_iso_8601": "2020-04-15T01:48:59.431481Z", "url": "https://files.pythonhosted.org/packages/ee/4e/8afc77c27daa9ecd2fe7ab85e9f509cdd8a56a63cdc46b32a11165bcc4b2/tfAugmentor-1.2.tar.gz", "yanked": false}], "1.2.1": [{"comment_text": "", "digests": {"md5": "c7f76dc6b71953506c2abb0ea75ea3bf", "sha256": "b867f5cccb076536be55066b755410a33742211b5450da2861fbae6894ecf94a"}, "downloads": -1, "filename": "tfAugmentor-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c7f76dc6b71953506c2abb0ea75ea3bf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9127, "upload_time": "2020-04-15T03:43:48", "upload_time_iso_8601": "2020-04-15T03:43:48.274103Z", "url": "https://files.pythonhosted.org/packages/ea/04/f3c3e6c624e7127ea38191016a4db8b635f9ccab4d2be2ef7d1ffc501d3d/tfAugmentor-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dfa69fa9028cbbac52da74f2067e680b", "sha256": "b8d6987dacfed0737210e3ac5fa4fa15667af1ab3f7ad1f7d9cd73df36d8ca16"}, "downloads": -1, "filename": "tfAugmentor-1.2.1.tar.gz", "has_sig": false, "md5_digest": "dfa69fa9028cbbac52da74f2067e680b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9340, "upload_time": "2020-04-15T03:42:33", "upload_time_iso_8601": "2020-04-15T03:42:33.178453Z", "url": "https://files.pythonhosted.org/packages/d7/aa/fa96b612f5d44691102d9ff9baf8f767efbd4ab9dbd3b053ba64826c6bc6/tfAugmentor-1.2.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "c7f76dc6b71953506c2abb0ea75ea3bf", "sha256": "b867f5cccb076536be55066b755410a33742211b5450da2861fbae6894ecf94a"}, "downloads": -1, "filename": "tfAugmentor-1.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "c7f76dc6b71953506c2abb0ea75ea3bf", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 9127, "upload_time": "2020-04-15T03:43:48", "upload_time_iso_8601": "2020-04-15T03:43:48.274103Z", "url": "https://files.pythonhosted.org/packages/ea/04/f3c3e6c624e7127ea38191016a4db8b635f9ccab4d2be2ef7d1ffc501d3d/tfAugmentor-1.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "dfa69fa9028cbbac52da74f2067e680b", "sha256": "b8d6987dacfed0737210e3ac5fa4fa15667af1ab3f7ad1f7d9cd73df36d8ca16"}, "downloads": -1, "filename": "tfAugmentor-1.2.1.tar.gz", "has_sig": false, "md5_digest": "dfa69fa9028cbbac52da74f2067e680b", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9340, "upload_time": "2020-04-15T03:42:33", "upload_time_iso_8601": "2020-04-15T03:42:33.178453Z", "url": "https://files.pythonhosted.org/packages/d7/aa/fa96b612f5d44691102d9ff9baf8f767efbd4ab9dbd3b053ba64826c6bc6/tfAugmentor-1.2.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 02:54:41 2020"}