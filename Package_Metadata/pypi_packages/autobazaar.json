{"info": {"author": "MIT Data To AI Lab", "author_email": "dailabmit@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Natural Language :: English", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering :: Artificial Intelligence"], "description": "<p align=\"left\">\n<img width=15% src=\"https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png\" alt=\u201cAutoBazaar\u201d />\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n\n[![PyPi](https://img.shields.io/pypi/v/autobazaar.svg)](https://pypi.python.org/pypi/autobazaar)\n[![Travis](https://travis-ci.org/HDI-Project/AutoBazaar.svg?branch=master)](https://travis-ci.org/HDI-Project/AutoBazaar)\n[![Downloads](https://pepy.tech/badge/autobazaar)](https://pepy.tech/project/autobazaar)\n\n# AutoBazaar\n\n* License: [MIT](https://github.com/HDI-Project/AutoBazaar/blob/master/LICENSE)\n* Documentation: https://HDI-Project.github.io/AutoBazaar/\n* Homepage: https://github.com/HDI-Project/AutoBazaar\n* Paper: https://arxiv.org/pdf/1905.08942.pdf\n\n## Overview\n\nAutoBazaar is an AutoML system created using [The Machine Learning Bazaar](https://arxiv.org/abs/1905.08942),\na research project and framework for building ML and AutoML systems by the Data To AI Lab at MIT.\nSee [below](#citing-autobazaar) for more references.\n\nIt comes in the form of a python library which can be used directly inside any other python\nproject, as well as a CLI which allows searching for pipelines to solve a problem directly\nfrom the command line.\n\n# Install\n\n## Requirements\n\n**AutoBazaar** has been developed and tested on [Python 3.5, 3.6 and 3.7](https://www.python.org/downloads/)\n\nAlso, although it is not strictly required, the usage of a\n[virtualenv](https://virtualenv.pypa.io/en/latest/) is highly recommended in order to avoid\ninterfering with other software installed in the system where **AutoBazaar** is run.\n\n## Install with pip\n\nThe easiest and recommended way to install **AutoBazaar** is using\n[pip](https://pip.pypa.io/en/stable/):\n\n```bash\npip install autobazaar\n```\n\nThis will pull and install the latest stable release from [PyPI](https://pypi.org/).\n\nIf you want to install from source or contribute to the project please read the\n[Contributing Guide](https://HDI-Project.github.io/AutoBazaar/contributing.html#get-started).\n\n# Data Format\n\nAutoBazaar works with datasets in the [D3M Schema Format](https://github.com/mitll/d3m-schema)\nas input.\n\nThis dataset schema, developed by MIT Lincoln Labs Laboratory for DARPA's Data-Driven Discovery\nof Models (D3M) Program, requires the data to be in plainly readable formats such as CSV files or\nJPG images, and to be set within a folder hierarchy alongside some metadata specifications\nin JSON format, which include information about all the data contained, as well as the problem\nthat we are trying to solve.\n\nFor more details about the schema and about how to format your data to be compliant with it,\nrefer to the [Schema Documentation](https://github.com/mitll/d3m-schema/tree/master/documentation)\n\nAs an example, you can browse some datasets which have been included in this repository for\ndemonstration purposes:\n- [185_baseball](https://github.com/HDI-Project/AutoBazaar/tree/master/data/185_baseball): Single Table Regression\n- [196_autoMpg](https://github.com/HDI-Project/AutoBazaar/tree/master/data/196_autoMpg): Single Table Classification\n\n<!--Additionally, you can find a collection with ~500 datasets already formatted in the\n[d3m-data-dai S3 Bucket](https://d3m-data-dai.s3.amazonaws.com/index.html).-->\n\n# Quickstart\n\nIn this short tutorial we will guide you through a series of steps that will help you getting\nstarted with **AutoBazaar** using its CLI command `abz`.\n\nFor more details about its usage and the available options, please execute `abz --help`\non your command line.\n\n## 1. Prepare your Data\n\nMake sure to have your data prepared in the [Data Format](#data-format) explained above inside\nand uncompressed folder in a filesystem directly accessible by **AutoBazaar**.\n\nIn order to check, whether your dataset is available and ready to use, you can execute\nthe `abz` command in your command line with its `list` subcommand.\nIf your dataset is in a different place than inside a folder called `data` within your\ncurrent working directory, do not forget to add the `-i` argument to your command indicating\nthe path to the folder that contains your dataset.\n\n```bash\n$ abz list -i /path/to/your/datasets/folder\n```\n\nThe output should be a table which includes the details of all the datasets found inside\nthe indicated directory:\n\n```\n             data_modality                task_type task_subtype             metric size_human  train_samples\ndataset\n185_baseball  single_table           classification  multi_class            f1Macro       148K           1073\n196_autoMpg   single_table               regression   univariate   meanSquaredError        32K            298\n30_personae           text           classification       binary                 f1       1,4M            116\n32_wikiqa      multi_table           classification       binary                 f1       4,9M          23406\n60_jester     single_table  collaborative_filtering               meanAbsoluteError        44M         880719\n```\n\n**Note:** If you see an error saying that `No matching datasets found`, please review your\ndataset format and make sure to have indicated the right path.\n\nFor the rest of this quickstart, we will be using the `185_baseball` dataset that you can\nfind inside the [data folder](https://github.com/HDI-Project/AutoBazaar/tree/master/data)\ncontained in this repository.\n\n## 2. Start the search process\n\nOnce your data is ready, you can start the AutoBazaar search process using the `abz search`\ncommand.\nTo do this, you will need to provide again the path to where your datasets are contained, as\nwell as the name of the datasets that you want to process.\n\n```bash\n$ abz search -i /path/to/your/datasets/folder name_of_your_dataset\n```\n\nThis will evaluate the default pipeline without performing additional tuning iteration on it.\n\nIn order to start an actual tuning process, you will need to provide at least one of the\nfollowing additional options:\n\n* `-b, --budget`: Maximum number of tuning iterations to perform.\n* `-t, --timeout`: Maximum time that the system needs to run, in seconds.\n* `-c, --checkpoints`: Comma separated string containing the different checkpoints where\n  the best pipeline so far must be stored and evaluated against the test dataset. There must be\n  no spaces between the checkpoint times. For example, to store the best pipeline every 10 minutes\n  until 30 minutes have passed, you would use the option `-c 600,1200,1800`.\n\nFor example, to search process the `185_baseball` dataset during 30 seconds evaluating the\nbest pipeline so far every 10 seconds but with a maximum of 10 tuning iterations, we would\nuse the following command:\n\n```bash\nabz search 185_baseball -c10,20,30 -b10\n```\n\nFor further details about the available options, please execute `abz search --help` in your\nterminal.\n\n## 3. Explore the results\n\nOnce the **AutoBazaar** has finished searching for the best pipeline, a table will be printed\nin stdout with a summary of the best pipeline found for each dataset.\nIf multiple checkpoints were provided, details about the best pipeline in each checkpoint\nwill also be included.\n\nThe output will be a table similar to this one:\n\n```\n                                          pipeline     score      rank  cv_score   metric data_modality       task_type task_subtype    elapsed  iterations  load_time  trivial_time  fit_time    cv_time error  step\ndataset\n185_baseball  fce28425-e45c-4620-9d3c-d329b8684bea  0.316961  0.682957  0.317043  f1Macro  single_table  classification  multi_class  10.024457         0.0   0.011041      0.026212       NaN        NaN  None  None\n185_baseball  f7428924-79ee-439d-bc32-998a9efea619  0.675132  0.390927  0.609073  f1Macro  single_table  classification  multi_class  21.412262         1.0   0.011041      0.026212   9.99484        NaN  None  None\n185_baseball  397780a5-6bf6-48c9-9a85-06b0d08c5a9d  0.675132  0.357361  0.642639  f1Macro  single_table  classification  multi_class  31.712946         2.0   0.011041      0.026212   9.99484  12.618179  None  None\n```\n\nAlternatively, a `-r` option can be passed with the name of a CSV file, and the results will\nbe stored there:\n\n```bash\nabz search 185_baseball -c10,20,30 -b10 -r results.csv\n```\n\n## What's next?\n\nFor more details about **AutoBazaar** and all its possibilities and features, please check the\n[project documentation site](https://HDI-Project.github.io/AutoBazaar/)!\n\n# Credits\n\nAutoBazaar is an open-source project from the Data to AI Lab at MIT built by the following team:\n\n* Micah Smith <micahs@mit.edu>\n* Carles Sala <csala@mit.edu>\n* Max Kanter <max.kanter@featurelabs.com>\n* Kalyan Veeramachaneni <kalyanv@mit.edu>\n\n## Citing AutoBazaar\n\nIf you use AutoBazaar for your research, please consider citing the following paper (https://arxiv.org/pdf/1905.08942.pdf):\n\n```\n@article{smith2019mlbazaar,\n  author = {Smith, Micah J. and Sala, Carles and Kanter, James Max and Veeramachaneni, Kalyan},\n  title = {The Machine Learning Bazaar: Harnessing the ML Ecosystem for Effective System Development},\n  journal = {arXiv e-prints},\n  year = {2019},\n  eid = {arXiv:1905.08942},\n  pages = {arxiv:1904.09535},\n  archivePrefix = {arXiv},\n  eprint = {1905.08942},\n}\n```\n\n\n# History\n\n## 0.2.0 - 2019-11-26\n\nSecond Release:\n\n* Improved CLI interface\n* Improved Dataset support\n* New Docker image\n* Newer dependencies\n\nThis is the version used to generate the results explained in the third version of [\nThe Machine Learning Bazaar Paper](https://arxiv.org/abs/1905.08942v3)\n\n## 0.1.0 - 2019-06-24\n\nFirst Release.\n\nThis is a slightly cleaned up version of the software used to generate the results\nexplained in the first version of [The Machine Learning Bazaar Paper](\nhttps://arxiv.org/abs/1905.08942v1)\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/HDI-project/AutoBazaar", "keywords": "automl machine learning hyperparameters tuning classification regression autobazaar", "license": "MIT license", "maintainer": "", "maintainer_email": "", "name": "autobazaar", "package_url": "https://pypi.org/project/autobazaar/", "platform": "", "project_url": "https://pypi.org/project/autobazaar/", "project_urls": {"Homepage": "https://github.com/HDI-project/AutoBazaar"}, "release_url": "https://pypi.org/project/autobazaar/0.2.0/", "requires_dist": ["baytune (<0.3,>=0.2.1)", "mlblocks (<0.4,>=0.3.2)", "mlprimitives (<0.3,>=0.2.2.dev)", "scikit-learn (<0.21,>=0.20)", "mit-d3m (<0.3,>=0.2.1)", "numpy (<=1.16.5)", "gitpython (==3.0.2)", "bumpversion (>=0.5.3) ; extra == 'dev'", "pip (>=10.0.0) ; extra == 'dev'", "watchdog (>=0.8.3) ; extra == 'dev'", "m2r (>=0.2.0) ; extra == 'dev'", "Sphinx (>=1.7.1) ; extra == 'dev'", "sphinx-rtd-theme (>=0.2.4) ; extra == 'dev'", "autodocsumm (>=0.1.10) ; extra == 'dev'", "flake8 (>=3.5.0) ; extra == 'dev'", "isort (>=4.3.4) ; extra == 'dev'", "autoflake (>=1.1) ; extra == 'dev'", "autopep8 (>=1.3.5) ; extra == 'dev'", "twine (>=1.10.0) ; extra == 'dev'", "wheel (>=0.30.0) ; extra == 'dev'", "tox (>=2.9.1) ; extra == 'dev'", "coverage (>=4.5.1) ; extra == 'dev'", "pytest (>=3.4.2) ; extra == 'dev'", "pytest-cov (>=2.6.0) ; extra == 'dev'", "pytest (>=3.4.2) ; extra == 'tests'", "pytest-cov (>=2.6.0) ; extra == 'tests'"], "requires_python": ">=3.5", "summary": "The Machine Learning Bazaar", "version": "0.2.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p align=\"left\">\n<img alt=\"\u201cAutoBazaar\u201d\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/80df0970db0e9e95cce463bc9fa595caf90dd1c7/68747470733a2f2f6461692e6c6964732e6d69742e6564752f77702d636f6e74656e742f75706c6f6164732f323031382f30362f4c6f676f5f4441495f686967687265732e706e67\" width=\"15%\">\n<i>An open source project from Data to AI Lab at MIT.</i>\n</p>\n<p><a href=\"https://pypi.python.org/pypi/autobazaar\" rel=\"nofollow\"><img alt=\"PyPi\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/99d278f0c29942de158db02a3791a5275b3a3ecf/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6175746f62617a6161722e737667\"></a>\n<a href=\"https://travis-ci.org/HDI-Project/AutoBazaar\" rel=\"nofollow\"><img alt=\"Travis\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/2892308872e5ff5507ae90afd833f86cadd64997/68747470733a2f2f7472617669732d63692e6f72672f4844492d50726f6a6563742f4175746f42617a6161722e7376673f6272616e63683d6d6173746572\"></a>\n<a href=\"https://pepy.tech/project/autobazaar\" rel=\"nofollow\"><img alt=\"Downloads\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d50d3081443e49250e1e5caec7bdcac58f47fc16/68747470733a2f2f706570792e746563682f62616467652f6175746f62617a616172\"></a></p>\n<h1>AutoBazaar</h1>\n<ul>\n<li>License: <a href=\"https://github.com/HDI-Project/AutoBazaar/blob/master/LICENSE\" rel=\"nofollow\">MIT</a></li>\n<li>Documentation: <a href=\"https://HDI-Project.github.io/AutoBazaar/\" rel=\"nofollow\">https://HDI-Project.github.io/AutoBazaar/</a></li>\n<li>Homepage: <a href=\"https://github.com/HDI-Project/AutoBazaar\" rel=\"nofollow\">https://github.com/HDI-Project/AutoBazaar</a></li>\n<li>Paper: <a href=\"https://arxiv.org/pdf/1905.08942.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1905.08942.pdf</a></li>\n</ul>\n<h2>Overview</h2>\n<p>AutoBazaar is an AutoML system created using <a href=\"https://arxiv.org/abs/1905.08942\" rel=\"nofollow\">The Machine Learning Bazaar</a>,\na research project and framework for building ML and AutoML systems by the Data To AI Lab at MIT.\nSee <a href=\"#citing-autobazaar\" rel=\"nofollow\">below</a> for more references.</p>\n<p>It comes in the form of a python library which can be used directly inside any other python\nproject, as well as a CLI which allows searching for pipelines to solve a problem directly\nfrom the command line.</p>\n<h1>Install</h1>\n<h2>Requirements</h2>\n<p><strong>AutoBazaar</strong> has been developed and tested on <a href=\"https://www.python.org/downloads/\" rel=\"nofollow\">Python 3.5, 3.6 and 3.7</a></p>\n<p>Also, although it is not strictly required, the usage of a\n<a href=\"https://virtualenv.pypa.io/en/latest/\" rel=\"nofollow\">virtualenv</a> is highly recommended in order to avoid\ninterfering with other software installed in the system where <strong>AutoBazaar</strong> is run.</p>\n<h2>Install with pip</h2>\n<p>The easiest and recommended way to install <strong>AutoBazaar</strong> is using\n<a href=\"https://pip.pypa.io/en/stable/\" rel=\"nofollow\">pip</a>:</p>\n<pre>pip install autobazaar\n</pre>\n<p>This will pull and install the latest stable release from <a href=\"https://pypi.org/\" rel=\"nofollow\">PyPI</a>.</p>\n<p>If you want to install from source or contribute to the project please read the\n<a href=\"https://HDI-Project.github.io/AutoBazaar/contributing.html#get-started\" rel=\"nofollow\">Contributing Guide</a>.</p>\n<h1>Data Format</h1>\n<p>AutoBazaar works with datasets in the <a href=\"https://github.com/mitll/d3m-schema\" rel=\"nofollow\">D3M Schema Format</a>\nas input.</p>\n<p>This dataset schema, developed by MIT Lincoln Labs Laboratory for DARPA's Data-Driven Discovery\nof Models (D3M) Program, requires the data to be in plainly readable formats such as CSV files or\nJPG images, and to be set within a folder hierarchy alongside some metadata specifications\nin JSON format, which include information about all the data contained, as well as the problem\nthat we are trying to solve.</p>\n<p>For more details about the schema and about how to format your data to be compliant with it,\nrefer to the <a href=\"https://github.com/mitll/d3m-schema/tree/master/documentation\" rel=\"nofollow\">Schema Documentation</a></p>\n<p>As an example, you can browse some datasets which have been included in this repository for\ndemonstration purposes:</p>\n<ul>\n<li><a href=\"https://github.com/HDI-Project/AutoBazaar/tree/master/data/185_baseball\" rel=\"nofollow\">185_baseball</a>: Single Table Regression</li>\n<li><a href=\"https://github.com/HDI-Project/AutoBazaar/tree/master/data/196_autoMpg\" rel=\"nofollow\">196_autoMpg</a>: Single Table Classification</li>\n</ul>\n\n<h1>Quickstart</h1>\n<p>In this short tutorial we will guide you through a series of steps that will help you getting\nstarted with <strong>AutoBazaar</strong> using its CLI command <code>abz</code>.</p>\n<p>For more details about its usage and the available options, please execute <code>abz --help</code>\non your command line.</p>\n<h2>1. Prepare your Data</h2>\n<p>Make sure to have your data prepared in the <a href=\"#data-format\" rel=\"nofollow\">Data Format</a> explained above inside\nand uncompressed folder in a filesystem directly accessible by <strong>AutoBazaar</strong>.</p>\n<p>In order to check, whether your dataset is available and ready to use, you can execute\nthe <code>abz</code> command in your command line with its <code>list</code> subcommand.\nIf your dataset is in a different place than inside a folder called <code>data</code> within your\ncurrent working directory, do not forget to add the <code>-i</code> argument to your command indicating\nthe path to the folder that contains your dataset.</p>\n<pre>$ abz list -i /path/to/your/datasets/folder\n</pre>\n<p>The output should be a table which includes the details of all the datasets found inside\nthe indicated directory:</p>\n<pre><code>             data_modality                task_type task_subtype             metric size_human  train_samples\ndataset\n185_baseball  single_table           classification  multi_class            f1Macro       148K           1073\n196_autoMpg   single_table               regression   univariate   meanSquaredError        32K            298\n30_personae           text           classification       binary                 f1       1,4M            116\n32_wikiqa      multi_table           classification       binary                 f1       4,9M          23406\n60_jester     single_table  collaborative_filtering               meanAbsoluteError        44M         880719\n</code></pre>\n<p><strong>Note:</strong> If you see an error saying that <code>No matching datasets found</code>, please review your\ndataset format and make sure to have indicated the right path.</p>\n<p>For the rest of this quickstart, we will be using the <code>185_baseball</code> dataset that you can\nfind inside the <a href=\"https://github.com/HDI-Project/AutoBazaar/tree/master/data\" rel=\"nofollow\">data folder</a>\ncontained in this repository.</p>\n<h2>2. Start the search process</h2>\n<p>Once your data is ready, you can start the AutoBazaar search process using the <code>abz search</code>\ncommand.\nTo do this, you will need to provide again the path to where your datasets are contained, as\nwell as the name of the datasets that you want to process.</p>\n<pre>$ abz search -i /path/to/your/datasets/folder name_of_your_dataset\n</pre>\n<p>This will evaluate the default pipeline without performing additional tuning iteration on it.</p>\n<p>In order to start an actual tuning process, you will need to provide at least one of the\nfollowing additional options:</p>\n<ul>\n<li><code>-b, --budget</code>: Maximum number of tuning iterations to perform.</li>\n<li><code>-t, --timeout</code>: Maximum time that the system needs to run, in seconds.</li>\n<li><code>-c, --checkpoints</code>: Comma separated string containing the different checkpoints where\nthe best pipeline so far must be stored and evaluated against the test dataset. There must be\nno spaces between the checkpoint times. For example, to store the best pipeline every 10 minutes\nuntil 30 minutes have passed, you would use the option <code>-c 600,1200,1800</code>.</li>\n</ul>\n<p>For example, to search process the <code>185_baseball</code> dataset during 30 seconds evaluating the\nbest pipeline so far every 10 seconds but with a maximum of 10 tuning iterations, we would\nuse the following command:</p>\n<pre>abz search 185_baseball -c10,20,30 -b10\n</pre>\n<p>For further details about the available options, please execute <code>abz search --help</code> in your\nterminal.</p>\n<h2>3. Explore the results</h2>\n<p>Once the <strong>AutoBazaar</strong> has finished searching for the best pipeline, a table will be printed\nin stdout with a summary of the best pipeline found for each dataset.\nIf multiple checkpoints were provided, details about the best pipeline in each checkpoint\nwill also be included.</p>\n<p>The output will be a table similar to this one:</p>\n<pre><code>                                          pipeline     score      rank  cv_score   metric data_modality       task_type task_subtype    elapsed  iterations  load_time  trivial_time  fit_time    cv_time error  step\ndataset\n185_baseball  fce28425-e45c-4620-9d3c-d329b8684bea  0.316961  0.682957  0.317043  f1Macro  single_table  classification  multi_class  10.024457         0.0   0.011041      0.026212       NaN        NaN  None  None\n185_baseball  f7428924-79ee-439d-bc32-998a9efea619  0.675132  0.390927  0.609073  f1Macro  single_table  classification  multi_class  21.412262         1.0   0.011041      0.026212   9.99484        NaN  None  None\n185_baseball  397780a5-6bf6-48c9-9a85-06b0d08c5a9d  0.675132  0.357361  0.642639  f1Macro  single_table  classification  multi_class  31.712946         2.0   0.011041      0.026212   9.99484  12.618179  None  None\n</code></pre>\n<p>Alternatively, a <code>-r</code> option can be passed with the name of a CSV file, and the results will\nbe stored there:</p>\n<pre>abz search 185_baseball -c10,20,30 -b10 -r results.csv\n</pre>\n<h2>What's next?</h2>\n<p>For more details about <strong>AutoBazaar</strong> and all its possibilities and features, please check the\n<a href=\"https://HDI-Project.github.io/AutoBazaar/\" rel=\"nofollow\">project documentation site</a>!</p>\n<h1>Credits</h1>\n<p>AutoBazaar is an open-source project from the Data to AI Lab at MIT built by the following team:</p>\n<ul>\n<li>Micah Smith <a href=\"mailto:micahs@mit.edu\">micahs@mit.edu</a></li>\n<li>Carles Sala <a href=\"mailto:csala@mit.edu\">csala@mit.edu</a></li>\n<li>Max Kanter <a href=\"mailto:max.kanter@featurelabs.com\">max.kanter@featurelabs.com</a></li>\n<li>Kalyan Veeramachaneni <a href=\"mailto:kalyanv@mit.edu\">kalyanv@mit.edu</a></li>\n</ul>\n<h2>Citing AutoBazaar</h2>\n<p>If you use AutoBazaar for your research, please consider citing the following paper (<a href=\"https://arxiv.org/pdf/1905.08942.pdf\" rel=\"nofollow\">https://arxiv.org/pdf/1905.08942.pdf</a>):</p>\n<pre><code>@article{smith2019mlbazaar,\n  author = {Smith, Micah J. and Sala, Carles and Kanter, James Max and Veeramachaneni, Kalyan},\n  title = {The Machine Learning Bazaar: Harnessing the ML Ecosystem for Effective System Development},\n  journal = {arXiv e-prints},\n  year = {2019},\n  eid = {arXiv:1905.08942},\n  pages = {arxiv:1904.09535},\n  archivePrefix = {arXiv},\n  eprint = {1905.08942},\n}\n</code></pre>\n<h1>History</h1>\n<h2>0.2.0 - 2019-11-26</h2>\n<p>Second Release:</p>\n<ul>\n<li>Improved CLI interface</li>\n<li>Improved Dataset support</li>\n<li>New Docker image</li>\n<li>Newer dependencies</li>\n</ul>\n<p>This is the version used to generate the results explained in the third version of <a href=\"https://arxiv.org/abs/1905.08942v3\" rel=\"nofollow\">\nThe Machine Learning Bazaar Paper</a></p>\n<h2>0.1.0 - 2019-06-24</h2>\n<p>First Release.</p>\n<p>This is a slightly cleaned up version of the software used to generate the results\nexplained in the first version of <a href=\"https://arxiv.org/abs/1905.08942v1\" rel=\"nofollow\">The Machine Learning Bazaar Paper</a></p>\n\n          </div>"}, "last_serial": 6203470, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "9f12b627af19cbf55b7fc0177407bea2", "sha256": "819cdd9b97bf4df2e3a77ad5c633b0bab77f87243121da299c524d8b5fd8f03e"}, "downloads": -1, "filename": "autobazaar-0.1.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "9f12b627af19cbf55b7fc0177407bea2", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.4", "size": 20086, "upload_time": "2019-06-24T19:54:13", "upload_time_iso_8601": "2019-06-24T19:54:13.845386Z", "url": "https://files.pythonhosted.org/packages/21/d0/1b59be7690f157baa39ec99ad0b41538f8c564bbf7f8e2f24e488784dc57/autobazaar-0.1.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "915a0acd985183df93ea8252765e4d44", "sha256": "cc50aae6e3a42c62e593bf242b6565cbbc055757a2e22967cdf34ad688f51c45"}, "downloads": -1, "filename": "autobazaar-0.1.0.tar.gz", "has_sig": false, "md5_digest": "915a0acd985183df93ea8252765e4d44", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.4", "size": 63514, "upload_time": "2019-06-24T19:54:16", "upload_time_iso_8601": "2019-06-24T19:54:16.074080Z", "url": "https://files.pythonhosted.org/packages/d9/20/17cabf515546923c03cf451af23590400629a249ff777525ac841c804f75/autobazaar-0.1.0.tar.gz", "yanked": false}], "0.2.0": [{"comment_text": "", "digests": {"md5": "b04b34d3ee3e8963dde7ac1188558679", "sha256": "e6936d5b69db9356bd65f33ec195b58730bfa80b189a08aa7c548121ad0fcddd"}, "downloads": -1, "filename": "autobazaar-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b04b34d3ee3e8963dde7ac1188558679", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5", "size": 20874, "upload_time": "2019-11-26T19:22:05", "upload_time_iso_8601": "2019-11-26T19:22:05.951008Z", "url": "https://files.pythonhosted.org/packages/7d/16/ebb2ebeaca8b3d2370b97b5c602e6fb2abbcfbd93a054fb26a72af0dfc7e/autobazaar-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "71139035d28330fa63a402ac79d45693", "sha256": "d70a092b5d85af8f4e49fcf112e8578e9cd543f2c988a458d857b5cf92ae46dc"}, "downloads": -1, "filename": "autobazaar-0.2.0.tar.gz", "has_sig": false, "md5_digest": "71139035d28330fa63a402ac79d45693", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 63785, "upload_time": "2019-11-26T19:22:08", "upload_time_iso_8601": "2019-11-26T19:22:08.963749Z", "url": "https://files.pythonhosted.org/packages/df/ec/266bcc1febfe560778cfb4a2d3ebc3c3e8e98f8c4f103cd397dc044b05e4/autobazaar-0.2.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "b04b34d3ee3e8963dde7ac1188558679", "sha256": "e6936d5b69db9356bd65f33ec195b58730bfa80b189a08aa7c548121ad0fcddd"}, "downloads": -1, "filename": "autobazaar-0.2.0-py2.py3-none-any.whl", "has_sig": false, "md5_digest": "b04b34d3ee3e8963dde7ac1188558679", "packagetype": "bdist_wheel", "python_version": "py2.py3", "requires_python": ">=3.5", "size": 20874, "upload_time": "2019-11-26T19:22:05", "upload_time_iso_8601": "2019-11-26T19:22:05.951008Z", "url": "https://files.pythonhosted.org/packages/7d/16/ebb2ebeaca8b3d2370b97b5c602e6fb2abbcfbd93a054fb26a72af0dfc7e/autobazaar-0.2.0-py2.py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "71139035d28330fa63a402ac79d45693", "sha256": "d70a092b5d85af8f4e49fcf112e8578e9cd543f2c988a458d857b5cf92ae46dc"}, "downloads": -1, "filename": "autobazaar-0.2.0.tar.gz", "has_sig": false, "md5_digest": "71139035d28330fa63a402ac79d45693", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.5", "size": 63785, "upload_time": "2019-11-26T19:22:08", "upload_time_iso_8601": "2019-11-26T19:22:08.963749Z", "url": "https://files.pythonhosted.org/packages/df/ec/266bcc1febfe560778cfb4a2d3ebc3c3e8e98f8c4f103cd397dc044b05e4/autobazaar-0.2.0.tar.gz", "yanked": false}], "timestamp": "Thu May  7 18:16:21 2020"}