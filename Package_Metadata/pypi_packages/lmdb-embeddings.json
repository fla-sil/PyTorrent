{"info": {"author": "Dom Hudson", "author_email": "dom.hudson@thoughtriver.com", "bugtrack_url": null, "classifiers": [], "description": "![tr_logo_cmyk_tr_logo_cmyk](https://user-images.githubusercontent.com/10864294/29792093-382146cc-8c37-11e7-9e70-6f71b3d0800b.png)\n[![Build Status](https://travis-ci.org/ThoughtRiver/lmdb-embeddings.svg?branch=master)](https://travis-ci.org/ThoughtRiver/lmdb-embeddings)\n\n# LMDB Embeddings\nQuery word vectors (embeddings) very quickly with very little querying time overhead and far less memory usage than gensim or other equivalent solutions. This is made possible by [Lightning Memory-Mapped Database](https://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database).\n\nInspired by [Delft](https://github.com/kermitt2/delft). As explained in their readme, this approach permits us to have the pre-trained embeddings immediately \"warm\" (no load time), to free memory and to use any number of embeddings similtaneously with a very negligible impact on runtime when using SSD.\n\nFor instance, in a traditional approach `glove-840B` takes around 2 minutes to load and 4GB in memory. Managed with LMDB, `glove-840B` can be accessed immediately and takes only a couple MB in memory, for a negligible impact on runtime (around 1% slower).\n\n## Installation\n```bash\npip install lmdb-embeddings\n```\n\n## Reading vectors\n```python\nfrom lmdb_embeddings.reader import LmdbEmbeddingsReader\nfrom lmdb_embeddings.exceptions import MissingWordError\n\nembeddings = LmdbEmbeddingsReader('/path/to/word/vectors/eg/GoogleNews-vectors-negative300')\n\ntry:\n    vector = embeddings.get_word_vector('google')\nexcept MissingWordError:\n    # 'google' is not in the database.\n    pass\n```\n\n## Writing vectors\nAn example to write an LMDB vector file from a gensim model. As any iterator that yields word and vector pairs is supported, if you have the vectors in an alternative format then it is just a matter of altering the `iter_embeddings` method below appropriately.\n\nI will be writing a CLI interface to convert standard formats soon.\n\n```python\nfrom gensim.models.keyedvectors import KeyedVectors\nfrom lmdb_embeddings.writer import LmdbEmbeddingsWriter\n\n\nGOOGLE_NEWS_PATH = 'GoogleNews-vectors-negative300.bin.gz'\nOUTPUT_DATABASE_FOLDER = 'GoogleNews-vectors-negative300'\n\n\nprint('Loading gensim model...')\ngensim_model = KeyedVectors.load_word2vec_format(GOOGLE_NEWS_PATH, binary=True)\n\n\ndef iter_embeddings():\n    for word in gensim_model.vocab.keys():\n        yield word, gensim_model[word]\n\nprint('Writing vectors to a LMDB database...')\n\nwriter = LmdbEmbeddingsWriter(iter_embeddings()).write(OUTPUT_DATABASE_FOLDER)\n\n# These vectors can now be loaded with the LmdbEmbeddingsReader.\n```\n\n## LRU Cache\nA reader with an LRU (Least Recently Used) cache is included. This will save the embeddings for the 50,000 most recently queried words and return the same object instead of querying the database each time. Its interface is the same as the standard reader.\nSee [functools.lru_cache](https://docs.python.org/3/library/functools.html#functools.lru_cache) in the standard library.\n\n```python\nfrom lmdb_embeddings.reader import LruCachedLmdbEmbeddingsReader\nfrom lmdb_embeddings.exceptions import MissingWordError\n\nembeddings = LruCachedLmdbEmbeddingsReader('/path/to/word/vectors/eg/GoogleNews-vectors-negative300')\n\ntry:\n    vector = embeddings.get_word_vector('google')\nexcept MissingWordError:\n    # 'google' is not in the database.\n    pass\n```\n\n## Customisation\nBy default, LMDB Embeddings uses pickle to serialize the vectors to bytes (optimized and pickled with the highest available protocol). However, it is very easy to use an alternative approach - simply inject the serializer and unserializer as callables into the `LmdbEmbeddingsWriter` and `LmdbEmbeddingsReader`.\n\nA [msgpack](https://msgpack.org/index.html) serializer is included and can be used in the same way.\n\n```python\nfrom lmdb_embeddings.writer import LmdbEmbeddingsWriter\nfrom lmdb_embeddings.serializers import MsgpackSerializer\n\nwriter = LmdbEmbeddingsWriter(\n    iter_embeddings(),\n    serializer=MsgpackSerializer().serialize\n).write(OUTPUT_DATABASE_FOLDER)\n```\n\n```python\nfrom lmdb_embeddings.reader import LmdbEmbeddingsReader\nfrom lmdb_embeddings.serializers import MsgpackSerializer\n\nreader = LmdbEmbeddingsReader(\n    OUTPUT_DATABASE_FOLDER,\n    unserializer=MsgpackSerializer().unserialize\n)\n```\n\n## Running tests\n```\npytest\n```\n\n## Author\n\n- Github: [DomHudson](https://github.com/DomHudson)\n\n## Contributing\n\nContributions, issues and feature requests are welcome!\n\n## Show your support\n\nGive a \u2b50\ufe0f if this project helped you!\n\n## License\n\nCopyright \u00a9 2019 [ThoughtRiver](https://github.com/thoughtriver). <br />\nThis project is [GPL-3.0](https://github.com/ThoughtRiver/lmdb-embeddings/blob/master/LICENSE) licensed.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://www.thoughtriver.com", "keywords": "", "license": "GNU General Public License v3.0", "maintainer": "", "maintainer_email": "", "name": "lmdb-embeddings", "package_url": "https://pypi.org/project/lmdb-embeddings/", "platform": "", "project_url": "https://pypi.org/project/lmdb-embeddings/", "project_urls": {"Homepage": "https://www.thoughtriver.com"}, "release_url": "https://pypi.org/project/lmdb-embeddings/0.4.0/", "requires_dist": ["lmdb", "msgpack", "msgpack-numpy", "numpy", "flake8 ; extra == 'develop'", "pytest ; extra == 'develop'", "pytest-cov ; extra == 'develop'"], "requires_python": "", "summary": "Fast querying of word embeddings using the LMDB \"Lightning\" Database.", "version": "0.4.0", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"tr_logo_cmyk_tr_logo_cmyk\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3ab2c0b7915e85a49d1a689d467e035e4205fec4/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f31303836343239342f32393739323039332d33383231343663632d386333372d313165372d396537302d3666373162336430383030622e706e67\">\n<a href=\"https://travis-ci.org/ThoughtRiver/lmdb-embeddings\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/d376735428ece31a1a1942825e8db894f19f7fa2/68747470733a2f2f7472617669732d63692e6f72672f54686f7567687452697665722f6c6d64622d656d62656464696e67732e7376673f6272616e63683d6d6173746572\"></a></p>\n<h1>LMDB Embeddings</h1>\n<p>Query word vectors (embeddings) very quickly with very little querying time overhead and far less memory usage than gensim or other equivalent solutions. This is made possible by <a href=\"https://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database\" rel=\"nofollow\">Lightning Memory-Mapped Database</a>.</p>\n<p>Inspired by <a href=\"https://github.com/kermitt2/delft\" rel=\"nofollow\">Delft</a>. As explained in their readme, this approach permits us to have the pre-trained embeddings immediately \"warm\" (no load time), to free memory and to use any number of embeddings similtaneously with a very negligible impact on runtime when using SSD.</p>\n<p>For instance, in a traditional approach <code>glove-840B</code> takes around 2 minutes to load and 4GB in memory. Managed with LMDB, <code>glove-840B</code> can be accessed immediately and takes only a couple MB in memory, for a negligible impact on runtime (around 1% slower).</p>\n<h2>Installation</h2>\n<pre>pip install lmdb-embeddings\n</pre>\n<h2>Reading vectors</h2>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.reader</span> <span class=\"kn\">import</span> <span class=\"n\">LmdbEmbeddingsReader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">MissingWordError</span>\n\n<span class=\"n\">embeddings</span> <span class=\"o\">=</span> <span class=\"n\">LmdbEmbeddingsReader</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/word/vectors/eg/GoogleNews-vectors-negative300'</span><span class=\"p\">)</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">vector</span> <span class=\"o\">=</span> <span class=\"n\">embeddings</span><span class=\"o\">.</span><span class=\"n\">get_word_vector</span><span class=\"p\">(</span><span class=\"s1\">'google'</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"n\">MissingWordError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># 'google' is not in the database.</span>\n    <span class=\"k\">pass</span>\n</pre>\n<h2>Writing vectors</h2>\n<p>An example to write an LMDB vector file from a gensim model. As any iterator that yields word and vector pairs is supported, if you have the vectors in an alternative format then it is just a matter of altering the <code>iter_embeddings</code> method below appropriately.</p>\n<p>I will be writing a CLI interface to convert standard formats soon.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">gensim.models.keyedvectors</span> <span class=\"kn\">import</span> <span class=\"n\">KeyedVectors</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.writer</span> <span class=\"kn\">import</span> <span class=\"n\">LmdbEmbeddingsWriter</span>\n\n\n<span class=\"n\">GOOGLE_NEWS_PATH</span> <span class=\"o\">=</span> <span class=\"s1\">'GoogleNews-vectors-negative300.bin.gz'</span>\n<span class=\"n\">OUTPUT_DATABASE_FOLDER</span> <span class=\"o\">=</span> <span class=\"s1\">'GoogleNews-vectors-negative300'</span>\n\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Loading gensim model...'</span><span class=\"p\">)</span>\n<span class=\"n\">gensim_model</span> <span class=\"o\">=</span> <span class=\"n\">KeyedVectors</span><span class=\"o\">.</span><span class=\"n\">load_word2vec_format</span><span class=\"p\">(</span><span class=\"n\">GOOGLE_NEWS_PATH</span><span class=\"p\">,</span> <span class=\"n\">binary</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">iter_embeddings</span><span class=\"p\">():</span>\n    <span class=\"k\">for</span> <span class=\"n\">word</span> <span class=\"ow\">in</span> <span class=\"n\">gensim_model</span><span class=\"o\">.</span><span class=\"n\">vocab</span><span class=\"o\">.</span><span class=\"n\">keys</span><span class=\"p\">():</span>\n        <span class=\"k\">yield</span> <span class=\"n\">word</span><span class=\"p\">,</span> <span class=\"n\">gensim_model</span><span class=\"p\">[</span><span class=\"n\">word</span><span class=\"p\">]</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'Writing vectors to a LMDB database...'</span><span class=\"p\">)</span>\n\n<span class=\"n\">writer</span> <span class=\"o\">=</span> <span class=\"n\">LmdbEmbeddingsWriter</span><span class=\"p\">(</span><span class=\"n\">iter_embeddings</span><span class=\"p\">())</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">OUTPUT_DATABASE_FOLDER</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># These vectors can now be loaded with the LmdbEmbeddingsReader.</span>\n</pre>\n<h2>LRU Cache</h2>\n<p>A reader with an LRU (Least Recently Used) cache is included. This will save the embeddings for the 50,000 most recently queried words and return the same object instead of querying the database each time. Its interface is the same as the standard reader.\nSee <a href=\"https://docs.python.org/3/library/functools.html#functools.lru_cache\" rel=\"nofollow\">functools.lru_cache</a> in the standard library.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.reader</span> <span class=\"kn\">import</span> <span class=\"n\">LruCachedLmdbEmbeddingsReader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.exceptions</span> <span class=\"kn\">import</span> <span class=\"n\">MissingWordError</span>\n\n<span class=\"n\">embeddings</span> <span class=\"o\">=</span> <span class=\"n\">LruCachedLmdbEmbeddingsReader</span><span class=\"p\">(</span><span class=\"s1\">'/path/to/word/vectors/eg/GoogleNews-vectors-negative300'</span><span class=\"p\">)</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">vector</span> <span class=\"o\">=</span> <span class=\"n\">embeddings</span><span class=\"o\">.</span><span class=\"n\">get_word_vector</span><span class=\"p\">(</span><span class=\"s1\">'google'</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"n\">MissingWordError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># 'google' is not in the database.</span>\n    <span class=\"k\">pass</span>\n</pre>\n<h2>Customisation</h2>\n<p>By default, LMDB Embeddings uses pickle to serialize the vectors to bytes (optimized and pickled with the highest available protocol). However, it is very easy to use an alternative approach - simply inject the serializer and unserializer as callables into the <code>LmdbEmbeddingsWriter</code> and <code>LmdbEmbeddingsReader</code>.</p>\n<p>A <a href=\"https://msgpack.org/index.html\" rel=\"nofollow\">msgpack</a> serializer is included and can be used in the same way.</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.writer</span> <span class=\"kn\">import</span> <span class=\"n\">LmdbEmbeddingsWriter</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.serializers</span> <span class=\"kn\">import</span> <span class=\"n\">MsgpackSerializer</span>\n\n<span class=\"n\">writer</span> <span class=\"o\">=</span> <span class=\"n\">LmdbEmbeddingsWriter</span><span class=\"p\">(</span>\n    <span class=\"n\">iter_embeddings</span><span class=\"p\">(),</span>\n    <span class=\"n\">serializer</span><span class=\"o\">=</span><span class=\"n\">MsgpackSerializer</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">serialize</span>\n<span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">OUTPUT_DATABASE_FOLDER</span><span class=\"p\">)</span>\n</pre>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.reader</span> <span class=\"kn\">import</span> <span class=\"n\">LmdbEmbeddingsReader</span>\n<span class=\"kn\">from</span> <span class=\"nn\">lmdb_embeddings.serializers</span> <span class=\"kn\">import</span> <span class=\"n\">MsgpackSerializer</span>\n\n<span class=\"n\">reader</span> <span class=\"o\">=</span> <span class=\"n\">LmdbEmbeddingsReader</span><span class=\"p\">(</span>\n    <span class=\"n\">OUTPUT_DATABASE_FOLDER</span><span class=\"p\">,</span>\n    <span class=\"n\">unserializer</span><span class=\"o\">=</span><span class=\"n\">MsgpackSerializer</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">unserialize</span>\n<span class=\"p\">)</span>\n</pre>\n<h2>Running tests</h2>\n<pre><code>pytest\n</code></pre>\n<h2>Author</h2>\n<ul>\n<li>Github: <a href=\"https://github.com/DomHudson\" rel=\"nofollow\">DomHudson</a></li>\n</ul>\n<h2>Contributing</h2>\n<p>Contributions, issues and feature requests are welcome!</p>\n<h2>Show your support</h2>\n<p>Give a \u2b50\ufe0f if this project helped you!</p>\n<h2>License</h2>\n<p>Copyright \u00a9 2019 <a href=\"https://github.com/thoughtriver\" rel=\"nofollow\">ThoughtRiver</a>. <br>\nThis project is <a href=\"https://github.com/ThoughtRiver/lmdb-embeddings/blob/master/LICENSE\" rel=\"nofollow\">GPL-3.0</a> licensed.</p>\n\n          </div>"}, "last_serial": 6689560, "releases": {"0.2.1": [{"comment_text": "", "digests": {"md5": "9c1e2374f19bceccf64126b1513cc03b", "sha256": "cc600ed3a65d392869402739e00380cc2dfd52c79d37da86fd45120f93b03519"}, "downloads": -1, "filename": "lmdb_embeddings-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "9c1e2374f19bceccf64126b1513cc03b", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22289, "upload_time": "2018-10-20T22:00:33", "upload_time_iso_8601": "2018-10-20T22:00:33.471549Z", "url": "https://files.pythonhosted.org/packages/6e/77/48747e7f68aa4b1bfb8b4027a2b7e83070090750b72075cd4ba80f28f4d0/lmdb_embeddings-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "eff2df4559d17e56a7bb28bf077626eb", "sha256": "de8283a6e61a9b5f18bd83112dac57edf40e913dd7bd9e011da94d223b8b002e"}, "downloads": -1, "filename": "lmdb_embeddings-0.2.1.tar.gz", "has_sig": false, "md5_digest": "eff2df4559d17e56a7bb28bf077626eb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5150, "upload_time": "2018-10-20T22:00:34", "upload_time_iso_8601": "2018-10-20T22:00:34.833512Z", "url": "https://files.pythonhosted.org/packages/fa/ce/2176cca225f7553818807bc67a8c61ee32d4721377ec42de23a9d64ec1cf/lmdb_embeddings-0.2.1.tar.gz", "yanked": false}], "0.3.0": [{"comment_text": "", "digests": {"md5": "d600ae6df8fb01c3b54742c5a500c3d0", "sha256": "41369eb6ae85192f4e2598da328e304d1e7ccdfea146e13cd4891366225bc12b"}, "downloads": -1, "filename": "lmdb_embeddings-0.3.0-py3-none-any.whl", "has_sig": false, "md5_digest": "d600ae6df8fb01c3b54742c5a500c3d0", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 21855, "upload_time": "2019-12-16T15:48:51", "upload_time_iso_8601": "2019-12-16T15:48:51.098252Z", "url": "https://files.pythonhosted.org/packages/07/ee/08e912db7ffd60180da91546bfd2e45bd339f3668e8942c27ae1a30d7ab8/lmdb_embeddings-0.3.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "3b84deef9adffdf87caf96732c743c2a", "sha256": "4e8b9306923fd7fa17e2ff1d2b84a54ad145be338a4eeeb82895231aadffc655"}, "downloads": -1, "filename": "lmdb_embeddings-0.3.0.tar.gz", "has_sig": false, "md5_digest": "3b84deef9adffdf87caf96732c743c2a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5561, "upload_time": "2019-12-16T15:34:59", "upload_time_iso_8601": "2019-12-16T15:34:59.041209Z", "url": "https://files.pythonhosted.org/packages/30/e5/72f2840cd95aa39ee47cc40c05dd46b8435d36a99acf35778cf88b9faac4/lmdb_embeddings-0.3.0.tar.gz", "yanked": false}], "0.4.0": [{"comment_text": "", "digests": {"md5": "dcb5629ec9b5525559e9c6a084a1a88c", "sha256": "9bc044cc3d0c1bd77619b37ff72f61740c5de65622d2e0ca09ba7b53ae585360"}, "downloads": -1, "filename": "lmdb_embeddings-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "dcb5629ec9b5525559e9c6a084a1a88c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22347, "upload_time": "2020-02-24T16:29:02", "upload_time_iso_8601": "2020-02-24T16:29:02.242780Z", "url": "https://files.pythonhosted.org/packages/ed/b6/cad65efff9ba4fc7bea66f67bb4d19327aae51c246560984bc866bf10853/lmdb_embeddings-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e9105709d2972df62f24acc435b4dcb2", "sha256": "a941cdc7e2a77a5ea23035d97902b1f8fb78ef1124863bae5eae2ebe595367a6"}, "downloads": -1, "filename": "lmdb_embeddings-0.4.0.tar.gz", "has_sig": false, "md5_digest": "e9105709d2972df62f24acc435b4dcb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6458, "upload_time": "2020-02-24T16:29:03", "upload_time_iso_8601": "2020-02-24T16:29:03.877023Z", "url": "https://files.pythonhosted.org/packages/4e/3c/8bb801825472ed55e8e4b38e1945e6e04ee6b1df2ec7168a09b3f09baed3/lmdb_embeddings-0.4.0.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "dcb5629ec9b5525559e9c6a084a1a88c", "sha256": "9bc044cc3d0c1bd77619b37ff72f61740c5de65622d2e0ca09ba7b53ae585360"}, "downloads": -1, "filename": "lmdb_embeddings-0.4.0-py3-none-any.whl", "has_sig": false, "md5_digest": "dcb5629ec9b5525559e9c6a084a1a88c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 22347, "upload_time": "2020-02-24T16:29:02", "upload_time_iso_8601": "2020-02-24T16:29:02.242780Z", "url": "https://files.pythonhosted.org/packages/ed/b6/cad65efff9ba4fc7bea66f67bb4d19327aae51c246560984bc866bf10853/lmdb_embeddings-0.4.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "e9105709d2972df62f24acc435b4dcb2", "sha256": "a941cdc7e2a77a5ea23035d97902b1f8fb78ef1124863bae5eae2ebe595367a6"}, "downloads": -1, "filename": "lmdb_embeddings-0.4.0.tar.gz", "has_sig": false, "md5_digest": "e9105709d2972df62f24acc435b4dcb2", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6458, "upload_time": "2020-02-24T16:29:03", "upload_time_iso_8601": "2020-02-24T16:29:03.877023Z", "url": "https://files.pythonhosted.org/packages/4e/3c/8bb801825472ed55e8e4b38e1945e6e04ee6b1df2ec7168a09b3f09baed3/lmdb_embeddings-0.4.0.tar.gz", "yanked": false}], "timestamp": "Fri May  8 00:44:49 2020"}