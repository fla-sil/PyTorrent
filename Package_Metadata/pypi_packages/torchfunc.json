{"info": {"author": "Szymon Maszke", "author_email": "szymon.maszke@protonmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7", "Topic :: Scientific/Engineering", "Topic :: Scientific/Engineering :: Artificial Intelligence", "Topic :: Software Development :: Libraries", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "![torchfunc Logo](https://github.com/szymonmaszke/torchfunc/blob/master/assets/banner.png)\n\n--------------------------------------------------------------------------------\n\n| Version | Docs | Tests | Coverage | Style | PyPI | Python | PyTorch | Docker | Roadmap |\n|---------|------|-------|----------|-------|------|--------|---------|--------|---------|\n| [![Version](https://img.shields.io/static/v1?label=&message=0.1.1&color=377EF0&style=for-the-badge)](https://github.com/szymonmaszke/torchfunc/releases) | [![Documentation](https://img.shields.io/static/v1?label=&message=docs&color=EE4C2C&style=for-the-badge)](https://szymonmaszke.github.io/torchfunc/)  | ![Tests](https://github.com/szymonmaszke/torchfunc/workflows/test/badge.svg) | ![Coverage](https://img.shields.io/codecov/c/github/szymonmaszke/torchfunc?label=%20&logo=codecov&style=for-the-badge) | [![codebeat](https://img.shields.io/static/v1?label=&message=CB&color=27A8E0&style=for-the-badge)](https://codebeat.co/projects/github-com-szymonmaszke-torchfunc-master) | [![PyPI](https://img.shields.io/static/v1?label=&message=PyPI&color=377EF0&style=for-the-badge)](https://pypi.org/project/torchfunc/) | [![Python](https://img.shields.io/static/v1?label=&message=3.7&color=377EF0&style=for-the-badge&logo=python&logoColor=F8C63D)](https://www.python.org/) | [![PyTorch](https://img.shields.io/static/v1?label=&message=1.2.0&color=EE4C2C&style=for-the-badge)](https://pytorch.org/) | [![Docker](https://img.shields.io/static/v1?label=&message=docker&color=309cef&style=for-the-badge)](https://cloud.docker.com/u/szymonmaszke/repository/docker/szymonmaszke/torchfunc) | [![Roadmap](https://img.shields.io/static/v1?label=&message=roadmap&color=009688&style=for-the-badge)](https://github.com/szymonmaszke/torchfunc/blob/master/ROADMAP.md) |\n\n[**torchfunc**](https://szymonmaszke.github.io/torchfunc/) is library revolving around [PyTorch](https://pytorch.org/) with a goal to help you with:\n\n\n* Improving and analysing performance of your neural network (e.g. Tensor Cores compatibility)\n* Record/analyse internal state of `torch.nn.Module` as data passes through it\n* Do the above based on external conditions (using single `Callable` to specify it)\n* Day-to-day neural network related duties (model size, seeding, performance measurements etc.)\n* Get information about your host operating system, CUDA devices and others\n\n# Quick examples\n\n- __Get instant performance tips about your module. All problems described by comments\nwill be shown by `torchfunc.performance.tips`:__\n\n```python\nclass Model(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.convolution = torch.nn.Sequential(\n            torch.nn.Conv2d(1, 32, 3),\n            torch.nn.ReLU(inplace=True),  # Inplace may harm kernel fusion\n            torch.nn.Conv2d(32, 128, 3, groups=32),  # Depthwise is slower in PyTorch\n            torch.nn.ReLU(inplace=True),  # Same as before\n            torch.nn.Conv2d(128, 250, 3),  # Wrong output size for TensorCores\n        )\n\n        self.classifier = torch.nn.Sequential(\n            torch.nn.Linear(250, 64),  # Wrong input size for TensorCores\n            torch.nn.ReLU(),  # Fine, no info about this layer\n            torch.nn.Linear(64, 10),  # Wrong output size for TensorCores\n        )\n\n    def forward(self, inputs):\n        convolved = torch.nn.AdaptiveAvgPool2d(1)(self.convolution(inputs)).flatten()\n        return self.classifier(convolved)\n\n# All you have to do\nprint(torchfunc.performance.tips(Model()))\n```\n\n- __Seed globaly (including `numpy` and `cuda`), freeze weights, check inference time and model size:__\n\n```python\n# Inb4 MNIST, you can use any module with those functions\nmodel = torch.nn.Linear(784, 10)\ntorchfunc.seed(0)\nfrozen = torchfunc.module.freeze(model, bias=False)\n\nwith torchfunc.Timer() as timer:\n  frozen(torch.randn(32, 784)\n  print(timer.checkpoint()) # Time since the beginning\n  frozen(torch.randn(128, 784)\n  print(timer.checkpoint()) # Since last checkpoint\n\nprint(f\"Overall time {timer}; Model size: {torchfunc.sizeof(frozen)}\")\n```\n\n- __Record and sum per-layer activation statistics as data passes through network:__\n\n```python\n# Still MNIST but any module can be put in it's place\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(784, 100),\n    torch.nn.ReLU(),\n    torch.nn.Linear(100, 50),\n    torch.nn.ReLU(),\n    torch.nn.Linear(50, 10),\n)\n# Recorder which sums all inputs to layers\nrecorder = torchfunc.hooks.recorders.ForwardPre(reduction=lambda x, y: x+y)\n# Record only for torch.nn.Linear\nrecorder.children(model, types=(torch.nn.Linear,))\n# Train your network normally (or pass data through it)\n...\n# Activations of all neurons of first layer! \nprint(recorder[1]) # You can also post-process this data easily with apply\n```\n\nFor other examples (and how to use condition), see [documentation]()\n\n# Installation\n\n## [pip](<https://pypi.org/project/torchfunc/>)\n\n### Latest release:\n\n```shell\npip install --user torchfunc\n```\n\n### Nightly:\n\n```shell\npip install --user torchfunc-nightly\n```\n\n## [Docker](https://cloud.docker.com/repository/docker/szymonmaszke/torchfunc)\n\n__CPU standalone__ and various versions of __GPU enabled__ images are available\nat [dockerhub](https://cloud.docker.com/repository/docker/szymonmaszke/torchfunc).\n\nFor CPU quickstart, issue:\n\n```shell  \ndocker pull szymonmaszke/torchfunc:18.04\n```\n\nNightly builds are also available, just prefix tag with `nightly_`. If you are going for `GPU` image make sure you have\n[nvidia/docker](https://github.com/NVIDIA/nvidia-docker) installed and it's runtime set.\n\n# Contributing\n\nIf you find any issue or you think some functionality may be useful to others and fits this library, please [open new Issue](https://help.github.com/en/articles/creating-an-issue) or [create Pull Request](https://help.github.com/en/articles/creating-a-pull-request-from-a-fork).\n\nTo get an overview of things one can do to help this project, see [Roadmap](https://github.com/szymonmaszke/torchfunc/blob/master/ROADMAP.md).\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/szymonmaszke/torchfunc", "keywords": "pytorch torch functions performance visualize utils utilities recording", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "torchfunc", "package_url": "https://pypi.org/project/torchfunc/", "platform": "", "project_url": "https://pypi.org/project/torchfunc/", "project_urls": {"Documentation": "https://szymonmaszke.github.io/torchfunc/#torchfunc", "Homepage": "https://github.com/szymonmaszke/torchfunc", "Issues": "https://github.com/szymonmaszke/torchfunc/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc", "Website": "https://szymonmaszke.github.io/torchfunc"}, "release_url": "https://pypi.org/project/torchfunc/0.1.1/", "requires_dist": ["torch (>=1.2.0)"], "requires_python": ">=3.7", "summary": "PyTorch functions to improve performance, analyse models and make your life easier.", "version": "0.1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <p><img alt=\"torchfunc Logo\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/916d38cadc0189459a1a8b08fdc0721ce926a644/68747470733a2f2f6769746875622e636f6d2f737a796d6f6e6d61737a6b652f746f72636866756e632f626c6f622f6d61737465722f6173736574732f62616e6e65722e706e67\"></p>\n<hr>\n<table>\n<thead>\n<tr>\n<th>Version</th>\n<th>Docs</th>\n<th>Tests</th>\n<th>Coverage</th>\n<th>Style</th>\n<th>PyPI</th>\n<th>Python</th>\n<th>PyTorch</th>\n<th>Docker</th>\n<th>Roadmap</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"https://github.com/szymonmaszke/torchfunc/releases\" rel=\"nofollow\"><img alt=\"Version\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3f6b5ce473a6927500ca9c3ac8e20df046106bb6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d302e312e3126636f6c6f723d333737454630267374796c653d666f722d7468652d6261646765\"></a></td>\n<td><a href=\"https://szymonmaszke.github.io/torchfunc/\" rel=\"nofollow\"><img alt=\"Documentation\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/611e23036e6193a0da20bfe66381e1f1c7ff1a62/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d646f637326636f6c6f723d454534433243267374796c653d666f722d7468652d6261646765\"></a></td>\n<td><img alt=\"Tests\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/aaef4f7b191a972da0d4ebfcc2ce66995f8a25db/68747470733a2f2f6769746875622e636f6d2f737a796d6f6e6d61737a6b652f746f72636866756e632f776f726b666c6f77732f746573742f62616467652e737667\"></td>\n<td><img alt=\"Coverage\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/dd8c9aeae90d2852ffbf15277d90624b7e08c360/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f737a796d6f6e6d61737a6b652f746f72636866756e633f6c6162656c3d253230266c6f676f3d636f6465636f76267374796c653d666f722d7468652d6261646765\"></td>\n<td><a href=\"https://codebeat.co/projects/github-com-szymonmaszke-torchfunc-master\" rel=\"nofollow\"><img alt=\"codebeat\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/ea0f4f3654b82001e1efa1c895ee7f2bd69a88d7/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d434226636f6c6f723d323741384530267374796c653d666f722d7468652d6261646765\"></a></td>\n<td><a href=\"https://pypi.org/project/torchfunc/\" rel=\"nofollow\"><img alt=\"PyPI\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/8215dcd37002b6dcc738f2b879bfe91408b52b43/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d5079504926636f6c6f723d333737454630267374796c653d666f722d7468652d6261646765\"></a></td>\n<td><a href=\"https://www.python.org/\" rel=\"nofollow\"><img alt=\"Python\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/e943f6124f85256ff36ef114ea9584568562d902/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d332e3726636f6c6f723d333737454630267374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d463843363344\"></a></td>\n<td><a href=\"https://pytorch.org/\" rel=\"nofollow\"><img alt=\"PyTorch\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/c035085c8b545442841e88147fed51413f100fee/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d312e322e3026636f6c6f723d454534433243267374796c653d666f722d7468652d6261646765\"></a></td>\n<td><a href=\"https://cloud.docker.com/u/szymonmaszke/repository/docker/szymonmaszke/torchfunc\" rel=\"nofollow\"><img alt=\"Docker\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/72872e5a621755bfa1dcadaa1447fb18ac0ad0e8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d646f636b657226636f6c6f723d333039636566267374796c653d666f722d7468652d6261646765\"></a></td>\n<td><a href=\"https://github.com/szymonmaszke/torchfunc/blob/master/ROADMAP.md\" rel=\"nofollow\"><img alt=\"Roadmap\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/3cad79f6a687445b96ba7dec634948d25b72d434/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d266d6573736167653d726f61646d617026636f6c6f723d303039363838267374796c653d666f722d7468652d6261646765\"></a></td>\n</tr></tbody></table>\n<p><a href=\"https://szymonmaszke.github.io/torchfunc/\" rel=\"nofollow\"><strong>torchfunc</strong></a> is library revolving around <a href=\"https://pytorch.org/\" rel=\"nofollow\">PyTorch</a> with a goal to help you with:</p>\n<ul>\n<li>Improving and analysing performance of your neural network (e.g. Tensor Cores compatibility)</li>\n<li>Record/analyse internal state of <code>torch.nn.Module</code> as data passes through it</li>\n<li>Do the above based on external conditions (using single <code>Callable</code> to specify it)</li>\n<li>Day-to-day neural network related duties (model size, seeding, performance measurements etc.)</li>\n<li>Get information about your host operating system, CUDA devices and others</li>\n</ul>\n<h1>Quick examples</h1>\n<ul>\n<li><strong>Get instant performance tips about your module. All problems described by comments\nwill be shown by <code>torchfunc.performance.tips</code>:</strong></li>\n</ul>\n<pre><span class=\"k\">class</span> <span class=\"nc\">Model</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">convolution</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>  <span class=\"c1\"># Inplace may harm kernel fusion</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"n\">groups</span><span class=\"o\">=</span><span class=\"mi\">32</span><span class=\"p\">),</span>  <span class=\"c1\"># Depthwise is slower in PyTorch</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(</span><span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">),</span>  <span class=\"c1\"># Same as before</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Conv2d</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">250</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">),</span>  <span class=\"c1\"># Wrong output size for TensorCores</span>\n        <span class=\"p\">)</span>\n\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">classifier</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">250</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">),</span>  <span class=\"c1\"># Wrong input size for TensorCores</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>  <span class=\"c1\"># Fine, no info about this layer</span>\n            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">64</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>  <span class=\"c1\"># Wrong output size for TensorCores</span>\n        <span class=\"p\">)</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">inputs</span><span class=\"p\">):</span>\n        <span class=\"n\">convolved</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">AdaptiveAvgPool2d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">convolution</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"p\">))</span><span class=\"o\">.</span><span class=\"n\">flatten</span><span class=\"p\">()</span>\n        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">classifier</span><span class=\"p\">(</span><span class=\"n\">convolved</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># All you have to do</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">torchfunc</span><span class=\"o\">.</span><span class=\"n\">performance</span><span class=\"o\">.</span><span class=\"n\">tips</span><span class=\"p\">(</span><span class=\"n\">Model</span><span class=\"p\">()))</span>\n</pre>\n<ul>\n<li><strong>Seed globaly (including <code>numpy</code> and <code>cuda</code>), freeze weights, check inference time and model size:</strong></li>\n</ul>\n<pre><span class=\"c1\"># Inb4 MNIST, you can use any module with those functions</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">784</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"n\">torchfunc</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">frozen</span> <span class=\"o\">=</span> <span class=\"n\">torchfunc</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">freeze</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">bias</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n<span class=\"k\">with</span> <span class=\"n\">torchfunc</span><span class=\"o\">.</span><span class=\"n\">Timer</span><span class=\"p\">()</span> <span class=\"k\">as</span> <span class=\"n\">timer</span><span class=\"p\">:</span>\n  <span class=\"n\">frozen</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">)</span>\n  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">timer</span><span class=\"o\">.</span><span class=\"n\">checkpoint</span><span class=\"p\">())</span> <span class=\"c1\"># Time since the beginning</span>\n  <span class=\"n\">frozen</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">784</span><span class=\"p\">)</span>\n  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">timer</span><span class=\"o\">.</span><span class=\"n\">checkpoint</span><span class=\"p\">())</span> <span class=\"c1\"># Since last checkpoint</span>\n\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">\"Overall time </span><span class=\"si\">{</span><span class=\"n\">timer</span><span class=\"si\">}</span><span class=\"s2\">; Model size: </span><span class=\"si\">{</span><span class=\"n\">torchfunc</span><span class=\"o\">.</span><span class=\"n\">sizeof</span><span class=\"p\">(</span><span class=\"n\">frozen</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s2\">\"</span><span class=\"p\">)</span>\n</pre>\n<ul>\n<li><strong>Record and sum per-layer activation statistics as data passes through network:</strong></li>\n</ul>\n<pre><span class=\"c1\"># Still MNIST but any module can be put in it's place</span>\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">784</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">),</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"mi\">50</span><span class=\"p\">),</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n    <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">50</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n<span class=\"p\">)</span>\n<span class=\"c1\"># Recorder which sums all inputs to layers</span>\n<span class=\"n\">recorder</span> <span class=\"o\">=</span> <span class=\"n\">torchfunc</span><span class=\"o\">.</span><span class=\"n\">hooks</span><span class=\"o\">.</span><span class=\"n\">recorders</span><span class=\"o\">.</span><span class=\"n\">ForwardPre</span><span class=\"p\">(</span><span class=\"n\">reduction</span><span class=\"o\">=</span><span class=\"k\">lambda</span> <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"n\">x</span><span class=\"o\">+</span><span class=\"n\">y</span><span class=\"p\">)</span>\n<span class=\"c1\"># Record only for torch.nn.Linear</span>\n<span class=\"n\">recorder</span><span class=\"o\">.</span><span class=\"n\">children</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">types</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">,))</span>\n<span class=\"c1\"># Train your network normally (or pass data through it)</span>\n<span class=\"o\">...</span>\n<span class=\"c1\"># Activations of all neurons of first layer! </span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">recorder</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">])</span> <span class=\"c1\"># You can also post-process this data easily with apply</span>\n</pre>\n<p>For other examples (and how to use condition), see <a href=\"\" rel=\"nofollow\">documentation</a></p>\n<h1>Installation</h1>\n<h2><a href=\"https://pypi.org/project/torchfunc/\" rel=\"nofollow\">pip</a></h2>\n<h3>Latest release:</h3>\n<pre>pip install --user torchfunc\n</pre>\n<h3>Nightly:</h3>\n<pre>pip install --user torchfunc-nightly\n</pre>\n<h2><a href=\"https://cloud.docker.com/repository/docker/szymonmaszke/torchfunc\" rel=\"nofollow\">Docker</a></h2>\n<p><strong>CPU standalone</strong> and various versions of <strong>GPU enabled</strong> images are available\nat <a href=\"https://cloud.docker.com/repository/docker/szymonmaszke/torchfunc\" rel=\"nofollow\">dockerhub</a>.</p>\n<p>For CPU quickstart, issue:</p>\n<pre>docker pull szymonmaszke/torchfunc:18.04\n</pre>\n<p>Nightly builds are also available, just prefix tag with <code>nightly_</code>. If you are going for <code>GPU</code> image make sure you have\n<a href=\"https://github.com/NVIDIA/nvidia-docker\" rel=\"nofollow\">nvidia/docker</a> installed and it's runtime set.</p>\n<h1>Contributing</h1>\n<p>If you find any issue or you think some functionality may be useful to others and fits this library, please <a href=\"https://help.github.com/en/articles/creating-an-issue\" rel=\"nofollow\">open new Issue</a> or <a href=\"https://help.github.com/en/articles/creating-a-pull-request-from-a-fork\" rel=\"nofollow\">create Pull Request</a>.</p>\n<p>To get an overview of things one can do to help this project, see <a href=\"https://github.com/szymonmaszke/torchfunc/blob/master/ROADMAP.md\" rel=\"nofollow\">Roadmap</a>.</p>\n\n          </div>"}, "last_serial": 5891254, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "efd8e6294896e46e06f6e12224ca29dd", "sha256": "b892eb9f8cda71aaa2636f3e3d360c23a4b3d5b1a481a98bb503243623bba561"}, "downloads": -1, "filename": "torchfunc-0.1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "efd8e6294896e46e06f6e12224ca29dd", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 24756, "upload_time": "2019-09-16T01:07:22", "upload_time_iso_8601": "2019-09-16T01:07:22.748240Z", "url": "https://files.pythonhosted.org/packages/1f/ea/01db0b5e897861bc2423a9358a3a39d72473e562003e238ac19155b0b88c/torchfunc-0.1.0-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "b8ba7494a919bff7d8b52dee7d518d7f", "sha256": "ea419e6f505d22a9a6dc7e696eabcccbd506d31287d1beedb6536729c8896ff9"}, "downloads": -1, "filename": "torchfunc-0.1.0.tar.gz", "has_sig": false, "md5_digest": "b8ba7494a919bff7d8b52dee7d518d7f", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 19737, "upload_time": "2019-09-16T01:07:24", "upload_time_iso_8601": "2019-09-16T01:07:24.903857Z", "url": "https://files.pythonhosted.org/packages/96/88/10d4353eccfc8416507243334dad3e452a7c09f2ea952cd7d09eeaba3a62/torchfunc-0.1.0.tar.gz", "yanked": false}], "0.1.1": [{"comment_text": "", "digests": {"md5": "de0154fdb1f1144c10a3d547dddde3aa", "sha256": "6e97b24b21dca991d854d1d84ae66fa44eedb383c5d044115bdab60ddc782455"}, "downloads": -1, "filename": "torchfunc-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "de0154fdb1f1144c10a3d547dddde3aa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 28917, "upload_time": "2019-09-26T15:30:27", "upload_time_iso_8601": "2019-09-26T15:30:27.558874Z", "url": "https://files.pythonhosted.org/packages/85/bc/f72e70a813bd40e23ef4206ed9df159b13c4a0c46488084da88b92c45362/torchfunc-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "503fe07507695f08e45b612840fa9b9d", "sha256": "8771d82842eb4138e4cfeb7c22a7f93233b126ec4b6889a4e20fea654fc8cee6"}, "downloads": -1, "filename": "torchfunc-0.1.1.tar.gz", "has_sig": false, "md5_digest": "503fe07507695f08e45b612840fa9b9d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 22582, "upload_time": "2019-09-26T15:30:29", "upload_time_iso_8601": "2019-09-26T15:30:29.116634Z", "url": "https://files.pythonhosted.org/packages/8e/b1/f1666ebfdd4ddc4146b6dc406bd970a9a2c829b8e58c72422e88e4693b94/torchfunc-0.1.1.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "de0154fdb1f1144c10a3d547dddde3aa", "sha256": "6e97b24b21dca991d854d1d84ae66fa44eedb383c5d044115bdab60ddc782455"}, "downloads": -1, "filename": "torchfunc-0.1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "de0154fdb1f1144c10a3d547dddde3aa", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7", "size": 28917, "upload_time": "2019-09-26T15:30:27", "upload_time_iso_8601": "2019-09-26T15:30:27.558874Z", "url": "https://files.pythonhosted.org/packages/85/bc/f72e70a813bd40e23ef4206ed9df159b13c4a0c46488084da88b92c45362/torchfunc-0.1.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "503fe07507695f08e45b612840fa9b9d", "sha256": "8771d82842eb4138e4cfeb7c22a7f93233b126ec4b6889a4e20fea654fc8cee6"}, "downloads": -1, "filename": "torchfunc-0.1.1.tar.gz", "has_sig": false, "md5_digest": "503fe07507695f08e45b612840fa9b9d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7", "size": 22582, "upload_time": "2019-09-26T15:30:29", "upload_time_iso_8601": "2019-09-26T15:30:29.116634Z", "url": "https://files.pythonhosted.org/packages/8e/b1/f1666ebfdd4ddc4146b6dc406bd970a9a2c829b8e58c72422e88e4693b94/torchfunc-0.1.1.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:50:26 2020"}