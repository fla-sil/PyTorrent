{"info": {"author": "M\u00e1rcio Porto", "author_email": "mflporto@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# rlib\n\n[![Build Status](https://travis-ci.org/MarcioPorto/rlib.svg?branch=master)](https://travis-ci.org/MarcioPorto/rlib)\n\n`rlib` is a small deep reinforcement learning library with implementations of popular deep RL algorithms. Each algorithm is highly modular and customizable, making this library a great choice for anyone who wants to test the performance of different algorithms in the same environment. `rlib` uses PyTorch as the library of choice for its initial version, but support for TensorFlow is on the roadmap.\n\n## Installation\n\n```\npip install rlib\n```\n\n## Usage\n\nUsing `rlib` is this simple:\n\n```python\nfrom rlib.algorithms.dqn import DQNAgent\nfrom rlib.environments.gym import GymEnvironment\n\n\ne = gym.make('CartPole-v0')\n\nobservation_size = 4\naction_size = 2\n\ndqn = DQNAgent(observation_size, action_size)\nenv = GymEnvironment(e, dqn)\nenv.train()\nenv.test()\n```\n\n## Advanced\n\n### TensorBoard and GIFRecorder\n\n1. Initialize `Logger` and/or `GIFRecorder` objects. \n\n```python\nos.makedirs('your/log/dir', exist_ok=True)\n\nlogger = Logger(output_dir)\ngifs_recorder = GIFRecorder(output_dir, duration=3.0)\n```\n\n2. Initialize a new environment using these objects.\n\n```python\nenv = GymEnvironment(e, dqn, logger=logger, gifs_recorder=gifs_recorder)\n```\n\n3. To check Tensorboard logs, run:\n\n```\ntensorboard --logdir=your/log/dir\n```\n\n### Custom models\n\n1. Define your own custom model.\n\n```python\nclass NeuralNet(torch.nn.Module):\n    def __init__(self):\n        super(NeuralNet, self).__init__()\n        self.fc1 = nn.Linear(4, 8) \n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(8, 2)  \n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out\n```\n\n2. Check the documentation for the algorithm you are using for the appropriate argument name. For DQN:\n\n```python\ndqn = DQNAgent(\n    observation_size, action_size,\n    qnetwork_local=NeuralNet(),\n    qnetwork_target=NeuralNet(),\n)\n```\n\n### Saving model weights\n\n1. Set the `model_output_dir` argument when creating a new instance of an algorithm to the directory where you want your model to be saved.\n\n## Testing\n\nTo run all tests:\n\n```\npython -m unittest discover test/\n```\n\n## Contributing\n\n### Installation\n\nFeel free to open issues with any bugs found or any feature requests. Pull requests are always welcome for new functionality.\n\n```\nvirtualenv -p python3 venv\ncd rlib/\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\nTo make sure your installation worked, run one of the algorithms in the test folder:\n\n```\npython test/algorithms/dqn_test.py\n```\n\n## License\n\n`rlib` is released under the [MIT License](https://github.com/MarcioPorto/rlib/blob/master/LICENSE.md).\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/MarcioPorto/rlib", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "rlib", "package_url": "https://pypi.org/project/rlib/", "platform": "", "project_url": "https://pypi.org/project/rlib/", "project_urls": {"Homepage": "https://github.com/MarcioPorto/rlib"}, "release_url": "https://pypi.org/project/rlib/0.0.2/", "requires_dist": null, "requires_python": "", "summary": "Implementations of popular Deep Reinforcement Learning algorithms", "version": "0.0.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>rlib</h1>\n<p><a href=\"https://travis-ci.org/MarcioPorto/rlib\" rel=\"nofollow\"><img alt=\"Build Status\" src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/7903c0941a218e221243c763f0b37a4c8470e22b/68747470733a2f2f7472617669732d63692e6f72672f4d617263696f506f72746f2f726c69622e7376673f6272616e63683d6d6173746572\"></a></p>\n<p><code>rlib</code> is a small deep reinforcement learning library with implementations of popular deep RL algorithms. Each algorithm is highly modular and customizable, making this library a great choice for anyone who wants to test the performance of different algorithms in the same environment. <code>rlib</code> uses PyTorch as the library of choice for its initial version, but support for TensorFlow is on the roadmap.</p>\n<h2>Installation</h2>\n<pre><code>pip install rlib\n</code></pre>\n<h2>Usage</h2>\n<p>Using <code>rlib</code> is this simple:</p>\n<pre><span class=\"kn\">from</span> <span class=\"nn\">rlib.algorithms.dqn</span> <span class=\"kn\">import</span> <span class=\"n\">DQNAgent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">rlib.environments.gym</span> <span class=\"kn\">import</span> <span class=\"n\">GymEnvironment</span>\n\n\n<span class=\"n\">e</span> <span class=\"o\">=</span> <span class=\"n\">gym</span><span class=\"o\">.</span><span class=\"n\">make</span><span class=\"p\">(</span><span class=\"s1\">'CartPole-v0'</span><span class=\"p\">)</span>\n\n<span class=\"n\">observation_size</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>\n<span class=\"n\">action_size</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>\n\n<span class=\"n\">dqn</span> <span class=\"o\">=</span> <span class=\"n\">DQNAgent</span><span class=\"p\">(</span><span class=\"n\">observation_size</span><span class=\"p\">,</span> <span class=\"n\">action_size</span><span class=\"p\">)</span>\n<span class=\"n\">env</span> <span class=\"o\">=</span> <span class=\"n\">GymEnvironment</span><span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"n\">dqn</span><span class=\"p\">)</span>\n<span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">()</span>\n<span class=\"n\">env</span><span class=\"o\">.</span><span class=\"n\">test</span><span class=\"p\">()</span>\n</pre>\n<h2>Advanced</h2>\n<h3>TensorBoard and GIFRecorder</h3>\n<ol>\n<li>Initialize <code>Logger</code> and/or <code>GIFRecorder</code> objects.</li>\n</ol>\n<pre><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">makedirs</span><span class=\"p\">(</span><span class=\"s1\">'your/log/dir'</span><span class=\"p\">,</span> <span class=\"n\">exist_ok</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"n\">logger</span> <span class=\"o\">=</span> <span class=\"n\">Logger</span><span class=\"p\">(</span><span class=\"n\">output_dir</span><span class=\"p\">)</span>\n<span class=\"n\">gifs_recorder</span> <span class=\"o\">=</span> <span class=\"n\">GIFRecorder</span><span class=\"p\">(</span><span class=\"n\">output_dir</span><span class=\"p\">,</span> <span class=\"n\">duration</span><span class=\"o\">=</span><span class=\"mf\">3.0</span><span class=\"p\">)</span>\n</pre>\n<ol>\n<li>Initialize a new environment using these objects.</li>\n</ol>\n<pre><span class=\"n\">env</span> <span class=\"o\">=</span> <span class=\"n\">GymEnvironment</span><span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">,</span> <span class=\"n\">dqn</span><span class=\"p\">,</span> <span class=\"n\">logger</span><span class=\"o\">=</span><span class=\"n\">logger</span><span class=\"p\">,</span> <span class=\"n\">gifs_recorder</span><span class=\"o\">=</span><span class=\"n\">gifs_recorder</span><span class=\"p\">)</span>\n</pre>\n<ol>\n<li>To check Tensorboard logs, run:</li>\n</ol>\n<pre><code>tensorboard --logdir=your/log/dir\n</code></pre>\n<h3>Custom models</h3>\n<ol>\n<li>Define your own custom model.</li>\n</ol>\n<pre><span class=\"k\">class</span> <span class=\"nc\">NeuralNet</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">(</span><span class=\"n\">NeuralNet</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">)</span> \n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">relu</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span> <span class=\"o\">=</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>  \n\n    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc1</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">fc2</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">out</span>\n</pre>\n<ol>\n<li>Check the documentation for the algorithm you are using for the appropriate argument name. For DQN:</li>\n</ol>\n<pre><span class=\"n\">dqn</span> <span class=\"o\">=</span> <span class=\"n\">DQNAgent</span><span class=\"p\">(</span>\n    <span class=\"n\">observation_size</span><span class=\"p\">,</span> <span class=\"n\">action_size</span><span class=\"p\">,</span>\n    <span class=\"n\">qnetwork_local</span><span class=\"o\">=</span><span class=\"n\">NeuralNet</span><span class=\"p\">(),</span>\n    <span class=\"n\">qnetwork_target</span><span class=\"o\">=</span><span class=\"n\">NeuralNet</span><span class=\"p\">(),</span>\n<span class=\"p\">)</span>\n</pre>\n<h3>Saving model weights</h3>\n<ol>\n<li>Set the <code>model_output_dir</code> argument when creating a new instance of an algorithm to the directory where you want your model to be saved.</li>\n</ol>\n<h2>Testing</h2>\n<p>To run all tests:</p>\n<pre><code>python -m unittest discover test/\n</code></pre>\n<h2>Contributing</h2>\n<h3>Installation</h3>\n<p>Feel free to open issues with any bugs found or any feature requests. Pull requests are always welcome for new functionality.</p>\n<pre><code>virtualenv -p python3 venv\ncd rlib/\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre>\n<p>To make sure your installation worked, run one of the algorithms in the test folder:</p>\n<pre><code>python test/algorithms/dqn_test.py\n</code></pre>\n<h2>License</h2>\n<p><code>rlib</code> is released under the <a href=\"https://github.com/MarcioPorto/rlib/blob/master/LICENSE.md\" rel=\"nofollow\">MIT License</a>.</p>\n\n          </div>"}, "last_serial": 4956872, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "211afcfdb95ba503c847edb02f448abb", "sha256": "7fd4dad0e679761969390ddaba414b0723eadd07c6ac5af5f92ebd3712bbe6e4"}, "downloads": -1, "filename": "rlib-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "211afcfdb95ba503c847edb02f448abb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 35118, "upload_time": "2019-03-17T22:27:08", "upload_time_iso_8601": "2019-03-17T22:27:08.916920Z", "url": "https://files.pythonhosted.org/packages/e0/16/2e986e96884014daca65931616c9c77d38d149540d1d329e2515570d83c6/rlib-0.0.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "af47c3d6e25ae32dc70e169e3adc43cd", "sha256": "abd02e41e81f9a58591ea1a48d28f9f13eb910cf458232fc12aa23f5ccf8439e"}, "downloads": -1, "filename": "rlib-0.0.1.tar.gz", "has_sig": false, "md5_digest": "af47c3d6e25ae32dc70e169e3adc43cd", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 19372, "upload_time": "2019-03-17T22:27:11", "upload_time_iso_8601": "2019-03-17T22:27:11.321471Z", "url": "https://files.pythonhosted.org/packages/9d/b2/fe74560b32c8dfd3b64d6f671b1c323e5fc30a9abf924985d91b05dcde71/rlib-0.0.1.tar.gz", "yanked": false}], "0.0.2": [{"comment_text": "", "digests": {"md5": "2cd25487712428f885a47b39cdfd79eb", "sha256": "7dbe468fb6020e6980479bb9853d7cff999e96862a6013efe8a2b3a5d2477f67"}, "downloads": -1, "filename": "rlib-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "2cd25487712428f885a47b39cdfd79eb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 37344, "upload_time": "2019-03-19T03:41:38", "upload_time_iso_8601": "2019-03-19T03:41:38.677107Z", "url": "https://files.pythonhosted.org/packages/06/e8/4d8ef94541cd7e81e4fd597ebc8843dc48e8b7085b1b077d22c6ebc68444/rlib-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0cebd7d4b63b371ee2b83b91a9880feb", "sha256": "4715f8f91a80f70c481199b406ad16931324bae0bbe2509ec5f08102d4610704"}, "downloads": -1, "filename": "rlib-0.0.2.tar.gz", "has_sig": false, "md5_digest": "0cebd7d4b63b371ee2b83b91a9880feb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21055, "upload_time": "2019-03-19T03:41:40", "upload_time_iso_8601": "2019-03-19T03:41:40.144299Z", "url": "https://files.pythonhosted.org/packages/01/68/16d21c4b9b5550d4549945e4cb21f11a3b87f04fcc898c3c8769efc16a09/rlib-0.0.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2cd25487712428f885a47b39cdfd79eb", "sha256": "7dbe468fb6020e6980479bb9853d7cff999e96862a6013efe8a2b3a5d2477f67"}, "downloads": -1, "filename": "rlib-0.0.2-py3-none-any.whl", "has_sig": false, "md5_digest": "2cd25487712428f885a47b39cdfd79eb", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 37344, "upload_time": "2019-03-19T03:41:38", "upload_time_iso_8601": "2019-03-19T03:41:38.677107Z", "url": "https://files.pythonhosted.org/packages/06/e8/4d8ef94541cd7e81e4fd597ebc8843dc48e8b7085b1b077d22c6ebc68444/rlib-0.0.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "0cebd7d4b63b371ee2b83b91a9880feb", "sha256": "4715f8f91a80f70c481199b406ad16931324bae0bbe2509ec5f08102d4610704"}, "downloads": -1, "filename": "rlib-0.0.2.tar.gz", "has_sig": false, "md5_digest": "0cebd7d4b63b371ee2b83b91a9880feb", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 21055, "upload_time": "2019-03-19T03:41:40", "upload_time_iso_8601": "2019-03-19T03:41:40.144299Z", "url": "https://files.pythonhosted.org/packages/01/68/16d21c4b9b5550d4549945e4cb21f11a3b87f04fcc898c3c8769efc16a09/rlib-0.0.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:02:17 2020"}