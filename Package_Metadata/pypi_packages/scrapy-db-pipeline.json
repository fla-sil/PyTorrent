{"info": {"author": "chemf", "author_email": "eoyohe@gmail.com", "bugtrack_url": null, "classifiers": ["Framework :: Scrapy", "License :: OSI Approved :: MIT License", "Programming Language :: Python"], "description": "scrapy database pipeline\n========================\n\nIntroduction\n------------\n\nUse pipeline to persist item to the database, just provide the tablename\n\nINSTALL\n-------\n\n.. code:: shell\n\n    pip install scrapy_db_pipeline\n\nUsage\n-----\n\nconfigure on setting.py\n\n.. code:: python\n\n    DB_HOST = 'localhost'\n    DB_USER = 'root'\n    DB_PASSWORD = 'password'\n    DB_NAME = 'db_name\n\n    ITEM_PIPELINES = {\n       #...\n       'scrapy_db_pipeline.pipelines.DBStorePipeline': 300,\n       #...\n    }\n\nwrite your item\n\n.. code:: python\n\n    class CalendarItem(scrapy.Item):\n        __table_name__ = 'your_table_name'\n        some_item = scrapy.Field()  \n\n**tips**: You must create the table before running Scrapy. Because I\ncan't know what the type of your field on the database table.\n\nTODO:\n-----\n\ndatabase support (if I have time):\n\n-  [x] mysql\n-  [ ] ....", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/feng409/scrapy_db_pipeline", "keywords": "scrapy pipeline", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "scrapy-db-pipeline", "package_url": "https://pypi.org/project/scrapy-db-pipeline/", "platform": "", "project_url": "https://pypi.org/project/scrapy-db-pipeline/", "project_urls": {"Homepage": "https://github.com/feng409/scrapy_db_pipeline"}, "release_url": "https://pypi.org/project/scrapy-db-pipeline/1.1/", "requires_dist": null, "requires_python": "", "summary": "persist item to the database table", "version": "1.1", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>scrapy database pipeline</h1>\n<h2>Introduction</h2>\n<p>Use pipeline to persist item to the database, just provide the tablename</p>\n<h2>INSTALL</h2>\n<p>.. code:: shell</p>\n<pre><code>pip install scrapy_db_pipeline\n</code></pre>\n<h2>Usage</h2>\n<p>configure on setting.py</p>\n<p>.. code:: python</p>\n<pre><code>DB_HOST = 'localhost'\nDB_USER = 'root'\nDB_PASSWORD = 'password'\nDB_NAME = 'db_name\n\nITEM_PIPELINES = {\n   #...\n   'scrapy_db_pipeline.pipelines.DBStorePipeline': 300,\n   #...\n}\n</code></pre>\n<p>write your item</p>\n<p>.. code:: python</p>\n<pre><code>class CalendarItem(scrapy.Item):\n    __table_name__ = 'your_table_name'\n    some_item = scrapy.Field()  \n</code></pre>\n<p><strong>tips</strong>: You must create the table before running Scrapy. Because I\ncan't know what the type of your field on the database table.</p>\n<h2>TODO:</h2>\n<p>database support (if I have time):</p>\n<ul>\n<li>[x] mysql</li>\n<li>[ ] ....</li>\n</ul>\n\n          </div>"}, "last_serial": 6264230, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "a12cb44af768206e488e41e3d092a487", "sha256": "5429ac8711a6eaa25d19d1d3085cb1121b63bbb5b2abc6b97e8af35a6b492a26"}, "downloads": -1, "filename": "scrapy_db_pipeline-1.0.tar.gz", "has_sig": false, "md5_digest": "a12cb44af768206e488e41e3d092a487", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 2228, "upload_time": "2019-11-14T14:16:29", "upload_time_iso_8601": "2019-11-14T14:16:29.043933Z", "url": "https://files.pythonhosted.org/packages/dd/b5/562d1f4c6018046345d567c26780d1c2c038e7be132eeb903d7e77fd2245/scrapy_db_pipeline-1.0.tar.gz", "yanked": false}], "1.1": [{"comment_text": "", "digests": {"md5": "2861aed9c1ddec071a80cb5675232bef", "sha256": "17a2e2540260c7eb32bd0ef301fda15103b89793c3a44ff46520325661bec2d8"}, "downloads": -1, "filename": "scrapy_db_pipeline-1.1-py3.7.egg", "has_sig": false, "md5_digest": "2861aed9c1ddec071a80cb5675232bef", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 4671, "upload_time": "2019-12-09T02:45:28", "upload_time_iso_8601": "2019-12-09T02:45:28.493369Z", "url": "https://files.pythonhosted.org/packages/5b/6d/e9fd366d9d9172edb3f8c34159c64640577f9ca61ff3ac4fb07dbcc085c5/scrapy_db_pipeline-1.1-py3.7.egg", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "2861aed9c1ddec071a80cb5675232bef", "sha256": "17a2e2540260c7eb32bd0ef301fda15103b89793c3a44ff46520325661bec2d8"}, "downloads": -1, "filename": "scrapy_db_pipeline-1.1-py3.7.egg", "has_sig": false, "md5_digest": "2861aed9c1ddec071a80cb5675232bef", "packagetype": "bdist_egg", "python_version": "3.7", "requires_python": null, "size": 4671, "upload_time": "2019-12-09T02:45:28", "upload_time_iso_8601": "2019-12-09T02:45:28.493369Z", "url": "https://files.pythonhosted.org/packages/5b/6d/e9fd366d9d9172edb3f8c34159c64640577f9ca61ff3ac4fb07dbcc085c5/scrapy_db_pipeline-1.1-py3.7.egg", "yanked": false}], "timestamp": "Fri May  8 02:56:48 2020"}