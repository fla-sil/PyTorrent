{"info": {"author": "Ruhollah Shemirani", "author_email": "shemirani.r@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "# Extreme Pseudo-Sampler\nEPS is a feature selection and feature ranking method. We have described the technique and used to extract a gene selection for and RNA-Seq Case-Control study in a [paper](https://www.frontiersin.org/articles/10.3389/fgene.2018.00297/full). \n## How it works\nThis library uses TensorFlow in 4 steps. \n1. It first creates a Variational Auto-Encoder (VAE) to map each point from feature space to a distribution in the latent space. You can read more about VAEs [here](https://arxiv.org/abs/1312.6114).\n2. It then uses a regression model to classify samples in the latent space with good accuracy using a simple line. It then finds the furthest points to that line on both sides of it. We call these extreme samples. \n3. It then randomly generates new samples around our extreme samples using a normal distribution, called Extreme Pseudo-Samples. Using the same trained VAE, these newly generated samples are mapped back into the feature space. \n4. A new regression model is trained to classify our generated Pseudo-Samples. We then use the regression line to rank the most important features in these Extreme Pseudo-Samples. \n\n## Installation\nUsing setup_tools, install the package using the following command:\n\n`python3 -m pip install pseudo-sampler`\n\nOr you can download the code and import it to your project manually. Or use virtual environments.\n## Usage\nImport the main class called EPS from the package:\n\n`from pseudo-sampler.eps import EPS`\n\nYou can then create an EPS instant using the following snippet:\n\n`eps = EPS(data, labels, layers, learning_rate = 1e-4, batch_size = 100, VAE_activation=tf.nn.relu, normalize=True) `\n\nData should be a float numpy array with N*D dimensions. Where N is the total number of samples and D is the number of features in the feature space. \nLabels should be a numpy array with length N containing 1s and 0s for cases and controls. \nLayers is an integer python list containing the number of perceptrons in every layer of your Deep Variational Auto-Encoder; only in the encoder side (decoder side will be mirrored) . For example if you want to have a Deep Network with the following structure:\nInput -> 250 -> 120 -> 60 -> Latent Space with 30 dimensions -> 60 -> 120 -> 250 -> Output \nYou can represent it by passing the following as your layers argument. \n\n`layers = [250,120,60,30]`\n\nLearning rate, batch size and activation function are used to create the VAE. \nThe input data by default will be normalized to be between 0 and 1. In case they already are in that interval, you can set the normalization flag off. \nAfter creating an EPS instance, you can run your EPS experiment with the following command:\n\n`feature_ranks = eps.run(vae_epochs=50,regression_epochs=500,vae_address=\u2018./vae_mode.ckpt\u2019)`\n\nYou can set the number of epochs for VAE and Linear Regression models separately. Trained VAE models are saved mid-operation as back-up. You can set the backup address using vae_address argument.\nEPS.run function returns a list of indices of features sorted based on their importance in classification of EPS.\n\n## Future Work\nIn the near future, I plan to add the ability of using VAE classifier for classification purposes and not just feature ranking. I also plan to add more customization options for models. Such as the number of distributions available for generating EPS. \n\n\n\n\n\n [Github-flavored Markdown](https://guides.github.com/features/mastering-markdown/)\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/roohy/eps", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "pseudo-sampler", "package_url": "https://pypi.org/project/pseudo-sampler/", "platform": "", "project_url": "https://pypi.org/project/pseudo-sampler/", "project_urls": {"Homepage": "https://github.com/roohy/eps"}, "release_url": "https://pypi.org/project/pseudo-sampler/0.2.2/", "requires_dist": null, "requires_python": "", "summary": "Extreme Pseudo Sampling Package", "version": "0.2.2", "yanked": false, "html_description": "<div class=\"project-description\">\n            <h1>Extreme Pseudo-Sampler</h1>\n<p>EPS is a feature selection and feature ranking method. We have described the technique and used to extract a gene selection for and RNA-Seq Case-Control study in a <a href=\"https://www.frontiersin.org/articles/10.3389/fgene.2018.00297/full\" rel=\"nofollow\">paper</a>.</p>\n<h2>How it works</h2>\n<p>This library uses TensorFlow in 4 steps.</p>\n<ol>\n<li>It first creates a Variational Auto-Encoder (VAE) to map each point from feature space to a distribution in the latent space. You can read more about VAEs <a href=\"https://arxiv.org/abs/1312.6114\" rel=\"nofollow\">here</a>.</li>\n<li>It then uses a regression model to classify samples in the latent space with good accuracy using a simple line. It then finds the furthest points to that line on both sides of it. We call these extreme samples.</li>\n<li>It then randomly generates new samples around our extreme samples using a normal distribution, called Extreme Pseudo-Samples. Using the same trained VAE, these newly generated samples are mapped back into the feature space.</li>\n<li>A new regression model is trained to classify our generated Pseudo-Samples. We then use the regression line to rank the most important features in these Extreme Pseudo-Samples.</li>\n</ol>\n<h2>Installation</h2>\n<p>Using setup_tools, install the package using the following command:</p>\n<p><code>python3 -m pip install pseudo-sampler</code></p>\n<p>Or you can download the code and import it to your project manually. Or use virtual environments.</p>\n<h2>Usage</h2>\n<p>Import the main class called EPS from the package:</p>\n<p><code>from pseudo-sampler.eps import EPS</code></p>\n<p>You can then create an EPS instant using the following snippet:</p>\n<p><code>eps = EPS(data, labels, layers, learning_rate = 1e-4, batch_size = 100, VAE_activation=tf.nn.relu, normalize=True)</code></p>\n<p>Data should be a float numpy array with N*D dimensions. Where N is the total number of samples and D is the number of features in the feature space.\nLabels should be a numpy array with length N containing 1s and 0s for cases and controls.\nLayers is an integer python list containing the number of perceptrons in every layer of your Deep Variational Auto-Encoder; only in the encoder side (decoder side will be mirrored) . For example if you want to have a Deep Network with the following structure:\nInput -&gt; 250 -&gt; 120 -&gt; 60 -&gt; Latent Space with 30 dimensions -&gt; 60 -&gt; 120 -&gt; 250 -&gt; Output\nYou can represent it by passing the following as your layers argument.</p>\n<p><code>layers = [250,120,60,30]</code></p>\n<p>Learning rate, batch size and activation function are used to create the VAE.\nThe input data by default will be normalized to be between 0 and 1. In case they already are in that interval, you can set the normalization flag off.\nAfter creating an EPS instance, you can run your EPS experiment with the following command:</p>\n<p><code>feature_ranks = eps.run(vae_epochs=50,regression_epochs=500,vae_address=\u2018./vae_mode.ckpt\u2019)</code></p>\n<p>You can set the number of epochs for VAE and Linear Regression models separately. Trained VAE models are saved mid-operation as back-up. You can set the backup address using vae_address argument.\nEPS.run function returns a list of indices of features sorted based on their importance in classification of EPS.</p>\n<h2>Future Work</h2>\n<p>In the near future, I plan to add the ability of using VAE classifier for classification purposes and not just feature ranking. I also plan to add more customization options for models. Such as the number of distributions available for generating EPS.</p>\n<p><a href=\"https://guides.github.com/features/mastering-markdown/\" rel=\"nofollow\">Github-flavored Markdown</a></p>\n\n          </div>"}, "last_serial": 4852104, "releases": {"0.2.1": [{"comment_text": "", "digests": {"md5": "95937fa5b7a8f48a4daa1f147396c69c", "sha256": "0365119ea6e346ac2f7ef244fc53931e198b1c17f61c963ebbe60c87173885e8"}, "downloads": -1, "filename": "pseudo_sampler-0.2.1-py3-none-any.whl", "has_sig": false, "md5_digest": "95937fa5b7a8f48a4daa1f147396c69c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 10596, "upload_time": "2019-02-08T03:13:01", "upload_time_iso_8601": "2019-02-08T03:13:01.016954Z", "url": "https://files.pythonhosted.org/packages/d0/d7/ea384066d4406d4e4fe8b6d1625968dbafa6550c9b6c9800e86caa2ebcb0/pseudo_sampler-0.2.1-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "7065da166ffe012bf76fcfa6b6687588", "sha256": "b359cb138bf425d12df36c11cff51478b3a9872b5ebc4e9effb875fcc407441b"}, "downloads": -1, "filename": "pseudo-sampler-0.2.1.tar.gz", "has_sig": false, "md5_digest": "7065da166ffe012bf76fcfa6b6687588", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 4162, "upload_time": "2019-02-08T03:13:05", "upload_time_iso_8601": "2019-02-08T03:13:05.239859Z", "url": "https://files.pythonhosted.org/packages/bb/e5/001a7229cc5624df2632dd72f169718e0067b08ad27c9acd468128cce414/pseudo-sampler-0.2.1.tar.gz", "yanked": false}], "0.2.2": [{"comment_text": "", "digests": {"md5": "59a425fcb00ef5b4afc12b21ad653aa4", "sha256": "501c11b7efebf1e4c24e6581d57669d7d8a1472beb33a8b3a26b51c11a894a04"}, "downloads": -1, "filename": "pseudo_sampler-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "59a425fcb00ef5b4afc12b21ad653aa4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12078, "upload_time": "2019-02-21T22:14:33", "upload_time_iso_8601": "2019-02-21T22:14:33.452412Z", "url": "https://files.pythonhosted.org/packages/73/fb/9000d559d0e1746f34cdef20421758219f8d4afe3482e4d355466e29b4e5/pseudo_sampler-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c880b74fe8cb4ab703c7dbb718ce9886", "sha256": "8b41ee2a11c0b68c9353a1d8b16a4d9d42fd90ad9e333a71774a20e4261f9290"}, "downloads": -1, "filename": "pseudo_sampler-0.2.2.tar.gz", "has_sig": false, "md5_digest": "c880b74fe8cb4ab703c7dbb718ce9886", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5711, "upload_time": "2019-02-21T22:14:34", "upload_time_iso_8601": "2019-02-21T22:14:34.663842Z", "url": "https://files.pythonhosted.org/packages/8e/a4/fc398991779b7c545dcd1a5bc3b47eb2c38b236a7f658b39b5ff7ae385a8/pseudo_sampler-0.2.2.tar.gz", "yanked": false}]}, "urls": [{"comment_text": "", "digests": {"md5": "59a425fcb00ef5b4afc12b21ad653aa4", "sha256": "501c11b7efebf1e4c24e6581d57669d7d8a1472beb33a8b3a26b51c11a894a04"}, "downloads": -1, "filename": "pseudo_sampler-0.2.2-py3-none-any.whl", "has_sig": false, "md5_digest": "59a425fcb00ef5b4afc12b21ad653aa4", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 12078, "upload_time": "2019-02-21T22:14:33", "upload_time_iso_8601": "2019-02-21T22:14:33.452412Z", "url": "https://files.pythonhosted.org/packages/73/fb/9000d559d0e1746f34cdef20421758219f8d4afe3482e4d355466e29b4e5/pseudo_sampler-0.2.2-py3-none-any.whl", "yanked": false}, {"comment_text": "", "digests": {"md5": "c880b74fe8cb4ab703c7dbb718ce9886", "sha256": "8b41ee2a11c0b68c9353a1d8b16a4d9d42fd90ad9e333a71774a20e4261f9290"}, "downloads": -1, "filename": "pseudo_sampler-0.2.2.tar.gz", "has_sig": false, "md5_digest": "c880b74fe8cb4ab703c7dbb718ce9886", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 5711, "upload_time": "2019-02-21T22:14:34", "upload_time_iso_8601": "2019-02-21T22:14:34.663842Z", "url": "https://files.pythonhosted.org/packages/8e/a4/fc398991779b7c545dcd1a5bc3b47eb2c38b236a7f658b39b5ff7ae385a8/pseudo_sampler-0.2.2.tar.gz", "yanked": false}], "timestamp": "Fri May  8 03:15:58 2020"}